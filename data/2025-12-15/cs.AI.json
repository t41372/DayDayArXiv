{
  "date": "2025-12-15",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-12-15 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\nä»Šå¤© arXiv çš„è®ºæ–‡äº•å–·ï¼Œ**Agentic AIï¼ˆæ™ºèƒ½ä½“ï¼‰çš„è®°å¿†ä¸æ¨ç†**ã€**AI for Scienceï¼ˆææ–™ä¸åŒ»å­¦ï¼‰** ä»¥åŠ **å¤§æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡** æ˜¯ç»å¯¹çš„ä¸»è§’ã€‚ä»¤äººå°è±¡æ·±åˆ»çš„åŒ…æ‹¬ NVIDIA æ¨å‡ºçš„ **Nemotron-Cascade** æ¨ç†æ¨¡å‹ï¼Œä¸€ç¯‡å…³äº **Agent è®°å¿†æœºåˆ¶** çš„è¯¦å°½ç»¼è¿°ï¼Œä»¥åŠå¤šç¯‡å…³äºé€šè¿‡ **å¼ºåŒ–å­¦ä¹ ** æå‡æ¨¡å‹æ¨ç†å’Œæé—®èƒ½åŠ›çš„ç ”ç©¶ã€‚\n\nä¸‹é¢æˆ‘ä»¬ç›´å…¥ä¸»é¢˜ï¼Œçœ‹çœ‹ä»Šå¤©å€¼å¾—å…³æ³¨çš„ç¡¬æ ¸å¹²è´§ã€‚\n\n---\n\n### ğŸš€ ç„¦ç‚¹ï¼šAgent è®°å¿†ã€æ¨ç†ä¸å¼ºåŒ–å­¦ä¹  (Agents, Reasoning & RL)\n\nä»Šå¤©çš„é‡å¤´æˆæ˜¯æ™ºèƒ½ä½“çš„è¿›åŒ–ï¼Œä»è®°å¿†æœºåˆ¶åˆ°æ¨ç†èƒ½åŠ›çš„å¼ºåŒ–ã€‚\n\n**1. [NVIDIAæ–°ä½œ] Nemotron-Cascadeï¼šæ‰©å±•çº§è”å¼ºåŒ–å­¦ä¹ ä»¥æ„å»ºé€šç”¨æ¨ç†æ¨¡å‹**\n**Nemotron-Cascade: Scaling Cascaded Reinforcement Learning for General-Purpose Reasoning Models**\n> **ä¸€å¥è¯ç‚¹è¯„ï¼š** NVIDIA æå‡ºçš„ **Cascade RL** ä½¿å¾— 14B æ¨¡å‹åœ¨ç¼–ç¨‹ç«èµ›ä¸­è¶…è¶Šäº† DeepSeek-R1 çš„ SFT æ•™å¸ˆæ¨¡å‹ï¼Œæ¨ç†èƒ½åŠ›å¤§å¹…æå‡ã€‚\n>\n**æ ¸å¿ƒå‘ç°ï¼š** ä½œè€…æå‡ºäº†ä¸€ç§çº§è”åŸŸå¼ºåŒ–å­¦ä¹ ï¼ˆCascaded Domain-wise RLï¼‰æ–¹æ³•ã€‚ä¸æ··åˆæ•°æ®çš„ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼Œä»–ä»¬æŒ‰é¡ºåºç¼–æ’ä¸åŒé¢†åŸŸçš„ RL è®­ç»ƒã€‚å…³é”®å‘ç°æ˜¯ï¼šRLHF ä¸ä»…æ˜¯ä¸ºäº†å¯¹é½ï¼Œæ›´æ˜¯é¢„å¤„ç†æ­¥éª¤ï¼›åç»­çš„é¢†åŸŸ RL è®­ç»ƒï¼ˆRLVRï¼‰ä¸ä»…ä¸é—å¿˜æ—§çŸ¥è¯†ï¼Œè¿˜èƒ½æå‡ä¹‹å‰é¢†åŸŸçš„è¡¨ç°ã€‚\n**Implicationï¼š** ä¸ºé€šç”¨æ¨ç†æ¨¡å‹ï¼ˆSystem 2 æ€ç»´ï¼‰çš„è®­ç»ƒæä¾›äº†ä¸€æ¡é«˜æ•ˆçš„å·¥ç¨‹åŒ–è·¯å¾„ã€‚\n\n**2. [å¿…è¯»ç»¼è¿°] AI Agent æ—¶ä»£çš„è®°å¿†æœºåˆ¶**\n**Memory in the Age of AI Agents**\n> **ä¸€å¥è¯ç‚¹è¯„ï¼š** æƒ³è¦åš Agentï¼Œè¿™ç¯‡å…³äº Memory çš„åˆ†ç±»å­¦ç»¼è¿°æ˜¯å¿…è¯»çš„ï¼Œå®ƒé‡æ–°å®šä¹‰äº† Agent çš„â€œå¤§è„‘â€ç»“æ„ã€‚\n>\n**æ ¸å¿ƒå‘ç°ï¼š** æ–‡ç« æŒ‡å‡ºç°æœ‰çš„é•¿/çŸ­æœŸè®°å¿†åˆ†ç±»å·²ä¸å¤Ÿç”¨ã€‚ä½œè€…æå‡ºäº†æ–°çš„åˆ†ç±»ç»´åº¦ï¼š\n*   **å½¢å¼ (Forms)ï¼š** Token çº§ã€å‚æ•°åŒ– (Parametric)ã€æ½œåœ¨ (Latent) è®°å¿†ã€‚\n*   **åŠŸèƒ½ (Functions)ï¼š** äº‹å®æ€§ (Factual)ã€ç»éªŒæ€§ (Experiential)ã€å·¥ä½œ (Working) è®°å¿†ã€‚\n*   **åŠ¨æ€ (Dynamics)ï¼š** è®°å¿†çš„å½¢æˆã€æ¼”å˜å’Œæ£€ç´¢ã€‚\næ–‡ç« è¿˜æ¢³ç†äº†ç›¸å…³ benchmark å’Œæ¡†æ¶ï¼Œæ˜¯æ„å»ºä¸‹ä¸€ä»£ Agent çš„åŸºç¡€è“å›¾ã€‚\n\n**3. [æœ‰è¶£çš„Agentæ•™å­¦] è‹æ ¼æ‹‰åº•å¼å­¦ç”Ÿï¼šæ•™å¤§æ¨¡å‹é€šè¿‡æé—®æ¥å­¦ä¹ **\n**Socratic Students: Teaching Language Models to Learn by Asking Questions**\n> **ä¸€å¥è¯ç‚¹è¯„ï¼š** ä¸è¦åªè®© LLM å›ç­”é—®é¢˜ï¼Œè¦æ•™ä¼šå®ƒä»¬â€œä¸æ‡‚å°±é—®â€ã€‚\n>\n**æ ¸å¿ƒå‘ç°ï¼š** è®¸å¤šé«˜é£é™©ä»»åŠ¡ï¼ˆå¦‚åŒ»ç–—ã€è¾…å¯¼ï¼‰éœ€è¦ä¸»åŠ¨æé—®ã€‚ä½œè€…æå‡ºäº† **ODQS (Outcome-Driven Question optimization Strategy)**ï¼Œé€šè¿‡ DPO (ç›´æ¥åå¥½ä¼˜åŒ–) è®­ç»ƒæ¨¡å‹åœ¨åªæœ‰æœ‰é™è½®æ¬¡å¯¹è¯æœºä¼šæ—¶ï¼Œå¦‚ä½•å‘â€œè€å¸ˆâ€æå‡ºé«˜è´¨é‡çš„é—®é¢˜ä»¥è§£å†³ä»»åŠ¡ã€‚\n**ç»“æœï¼š** åœ¨ GSM8K æ•°å­¦é¢˜ä¸Šï¼ŒPass@5 æå‡äº†æƒŠäººçš„ 54.7%ã€‚\n\n**4. [ç«¯ä¾§Agent] MOBIMEMï¼šé€šè¿‡è®°å¿†ä¸­å¿ƒæ¶æ„å®ç° Agent çš„è‡ªæˆ‘è¿›åŒ–**\n**Beyond Training: Enabling Self-Evolution of Agents with MOBIMEM**\n> **ä¸€å¥è¯ç‚¹è¯„ï¼š** è®©æ‰‹æœºä¸Šçš„ Agent è¶Šç”¨è¶Šé¡ºæ‰‹ï¼Œä¸”ä¸éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚\n>\n**æ ¸å¿ƒå‘ç°ï¼š** é’ˆå¯¹ç§»åŠ¨ç«¯ Agent éš¾ä»¥æŒç»­å¾®è°ƒçš„é—®é¢˜ï¼Œæå‡ºäº† **MOBIMEM**ã€‚å®ƒåŒ…å«ä¸‰ç§è®°å¿†åŸè¯­ï¼šProfile Memory (ç”¨æˆ·ç”»åƒ)ã€Experience Memory (ä»»åŠ¡é€»è¾‘æ¨¡ç‰ˆ)ã€Action Memory (ç»†ç²’åº¦æ“ä½œåºåˆ—)ã€‚é€šè¿‡è¿™ç§å¤–æŒ‚è®°å¿†å’Œ OS çº§åˆ«çš„è°ƒåº¦ï¼Œåœ¨ Android ç¯å¢ƒä¸‹ä»»åŠ¡æˆåŠŸç‡æå‡äº† 50.3%ã€‚\n\n**5. [é«˜æ•ˆä¿®å‰ª] OPTIMAï¼šLLM çš„æœ€ä½³ä¸€æ¬¡æ€§å‰ªæ**\n**OPTIMA: Optimal One-shot Pruning for LLMs via Quadratic Programming Reconstruction**\n> **ä¸€å¥è¯ç‚¹è¯„ï¼š** åœ¨å•å¼  H100 ä¸Šï¼Œ40å°æ—¶å†…æŠŠ 8B æ¨¡å‹å‰ªæå®Œæ¯•ï¼Œä¸”ç²¾åº¦æŸå¤±æå°ã€‚\n>\n**æ ¸å¿ƒå‘ç°ï¼š** æå‡ºäº†ä¸€ç§åŸºäºäºŒæ¬¡è§„åˆ’ (Quadratic Programming) çš„å‰ªæé‡æ„æ–¹æ³•ã€‚ç›¸æ¯”äºç®€å•çš„å¯å‘å¼å‰ªæï¼ŒOPTIMA å°†æƒé‡é‡æ„è½¬åŒ–ä¸ºè¡Œçº§ QP é—®é¢˜æ±‚è§£ï¼Œåˆ©ç”¨å…±äº« Hessian ç»“æ„åŠ é€Ÿã€‚è¿™ä¸ºåè®­ç»ƒé˜¶æ®µçš„æ¨¡å‹â€œç˜¦èº«â€æä¾›äº†æ–°çš„ SOTA æ–¹æ¡ˆã€‚\n\n---\n\n### ğŸ§¬ AI for Scienceï¼šææ–™ã€ç”Ÿç‰©ä¸åŒ»å­¦\n\n**6. [ææ–™å‘ç°] ç”¨äºè‡ªä¸»åŠŸèƒ½ææ–™å‘ç°çš„åˆ†å±‚å¤šæ™ºèƒ½ä½“ LLM æ¨ç†**\n**Hierarchical Multi-agent Large Language Model Reasoning for Autonomous Functional Materials Discovery**\n> **ä¸€å¥è¯ç‚¹è¯„ï¼š** å‘Šåˆ«è¯•é”™æ³•ï¼Œç”¨æ‡‚å¾—â€œåŒè¡Œè¯„å®¡â€çš„ AI Agent å›¢é˜Ÿæ¥åŠ é€Ÿææ–™å‘ç°ã€‚\n>\n**æ ¸å¿ƒå‘ç°ï¼š** æå‡ºäº† **MASTER** æ¡†æ¶ï¼Œè®© LLM è‡ªä¸»è®¾è®¡ã€æ‰§è¡Œå’Œè§£é‡ŠåŸå­æ¨¡æ‹Ÿï¼ˆDFTï¼‰ã€‚å¼•å…¥äº†å¤šæ™ºèƒ½ä½“ç­–ç•¥ï¼ŒåŒ…æ‹¬åŒè¡Œè¯„å®¡ï¼ˆPeer Reviewï¼‰å’Œåˆ†è¯Šæ’åºã€‚åœ¨å‚¬åŒ–å‰‚ææ–™æœç´¢ä»»åŠ¡ä¸­ï¼Œç›¸æ¯”è¯•é”™æ³•å‡å°‘äº† 90% çš„è®¡ç®—é‡ã€‚\n\n**7. [é‡ç—‡åŒ»å­¦] ä½¿ç”¨å¤šä¸­å¿ƒæ•°æ®å¼€å‘å’Œå¤–éƒ¨éªŒè¯é‡ç—‡æ‚£è€…çš„å¤šæ¨¡æ€ AI æ­»äº¡ç‡é¢„æµ‹æ¨¡å‹**\n**Development and external validation of a multimodal artificial intelligence mortality prediction model of critically ill patients using multicenter data**\n> **ä¸€å¥è¯ç‚¹è¯„ï¼š** åŸºäº 20 ä¸‡ ICU ç—…ä¾‹çš„å¤§è§„æ¨¡éªŒè¯ï¼Œè¯æ˜äº†å¤šæ¨¡æ€æ•°æ®ï¼ˆç»“æ„åŒ–æ•°æ®+ä¸´åºŠç¬”è®°+Xå…‰ç‰‡ï¼‰å¯¹é¢„æµ‹æ­»äº¡ç‡è‡³å…³é‡è¦ã€‚\n>\n**æ ¸å¿ƒå‘ç°ï¼š** åˆ©ç”¨ MIMIC-III/IVã€eICU ç­‰æ•°æ®é›†ï¼Œå¼€å‘äº†ä¸€ä¸ªé¢„æµ‹ ICU å…¥é™¢ 24 å°æ—¶åæ­»äº¡é£é™©çš„æ¨¡å‹ã€‚å…³é”®åœ¨äºåŠ å…¥**éç»“æ„åŒ–æ•°æ®**ï¼ˆä¸´åºŠç¬”è®°å’Œèƒ¸éƒ¨ X å…‰ï¼‰åï¼Œæ¨¡å‹æ€§èƒ½ï¼ˆAUROCï¼‰ä» 0.87 æå‡åˆ°äº† 0.89ã€‚å¼ºè°ƒäº†å¤–éƒ¨éªŒè¯çš„é‡è¦æ€§ã€‚\n\n**8. [ç—…ç†å­¦] è¯­ä¹‰å¢å¼ºçš„ç”ŸæˆåŸºç¡€æ¨¡å‹æ”¹è¿›ç—…ç†å›¾åƒåˆæˆ**\n**A Semantically Enhanced Generative Foundation Model Improves Pathological Image Synthesis**\n> **ä¸€å¥è¯ç‚¹è¯„ï¼š** è§£å†³äº†ç—…ç†å›¾åƒæ•°æ®ç¨€ç¼ºå’Œéšç§é—®é¢˜ï¼Œç”Ÿæˆè´¨é‡è¶³ä»¥é€šè¿‡ç—…ç†å­¦å®¶çš„æ³•çœ¼ã€‚\n>\n**æ ¸å¿ƒå‘ç°ï¼š** å‘å¸ƒäº† **CRAFTS** æ¨¡å‹ï¼ŒåŸºäº 280 ä¸‡å›¾æ–‡å¯¹è®­ç»ƒã€‚å¼•å…¥äº†ç›¸å…³æ€§è°ƒèŠ‚å¯¹é½æœºåˆ¶ï¼ŒæŠ‘åˆ¶è¯­ä¹‰æ¼‚ç§»å’Œå½¢æ€å¹»è§‰ã€‚ç”Ÿæˆçš„å›¾åƒè¦†ç›– 30 ç§ç™Œç—‡ç±»å‹ï¼Œå¯ç”¨äºå¢å¼ºä¸‹æ¸¸ä¸´åºŠä»»åŠ¡çš„æ•°æ®é›†ã€‚\n\n**9. [åç›´è§‰å‘ç°] è§†è§‰å¯èƒ½ä¼šç ´åå¤šæ¨¡æ€åŒ»ç–—å†³ç­–**\n**Why Text Prevails: Vision May Undermine Multimodal Medical Decision Making**\n> **ä¸€å¥è¯ç‚¹è¯„ï¼š** åœ¨åŒ»ç–—è¯Šæ–­é‡Œï¼Œç°åœ¨çš„ MLLM åŠ äº†å›¾åè€Œä¸å¦‚åªçœ‹å­—ï¼Ÿ\n>\n**æ ¸å¿ƒå‘ç°ï¼š** åœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…åˆ†ç±»å’Œèƒ¸éƒ¨ X å…‰åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œç ”ç©¶å‘ç°**çº¯æ–‡æœ¬æ¨ç†**çš„è¡¨ç°ä¼˜äºè§†è§‰æˆ–å¤šæ¨¡æ€è¾“å…¥ã€‚ç°æœ‰çš„ MLLM ç¼ºä¹æ‰å®çš„è§†è§‰ç†è§£èƒ½åŠ›ï¼Œæœ‰æ—¶è§†è§‰ä¿¡æ¯åè€Œæˆäº†å¹²æ‰°å™ªå£°ã€‚\n\n---\n\n### ğŸ¨ è§†è§‰ã€3D ä¸ ç”Ÿæˆå¼ AI\n\n**10. [3Dç¼–è¾‘] Steer3Dï¼šé€šè¿‡æ–‡æœ¬å¯æ§çš„ Image-to-3D å®ç°å‰é¦ˆ 3D ç¼–è¾‘**\n**Feedforward 3D Editing via Text-Steerable Image-to-3D**\n> **ä¸€å¥è¯ç‚¹è¯„ï¼š** ç±»ä¼¼äº ControlNet çš„æ€è·¯ï¼Œä½†ç”¨äº 3D ç”Ÿæˆï¼Œé€Ÿåº¦æå¿«ã€‚\n>\n**æ ¸å¿ƒå‘ç°ï¼š** æå‡º **Steer3D**ï¼Œä¸€ç§å‰é¦ˆæ–¹æ³•ï¼Œä¸º Image-to-3D æ¨¡å‹æ·»åŠ æ–‡æœ¬æ“æ§èƒ½åŠ›ã€‚åŸºäºæµåŒ¹é…ï¼ˆFlow-matchingï¼‰å’Œ DPO è®­ç»ƒï¼Œæ¯”ç°æœ‰æ–¹æ³•å¿« 2.4 åˆ° 28.5 å€ï¼Œä¸”æ›´å¥½åœ°éµå¾ªè¯­è¨€æŒ‡ä»¤ã€‚\n\n**11. [äº¤äº’å¼ç”Ÿæˆ] DiffusionBrowserï¼šé€šè¿‡å¤šåˆ†æ”¯è§£ç å™¨å®ç°äº¤äº’å¼æ‰©æ•£é¢„è§ˆ**\n**DiffusionBrowser: Interactive Diffusion Previews via Multi-Branch Decoders**\n> **ä¸€å¥è¯ç‚¹è¯„ï¼š** è§£å†³äº†è§†é¢‘ç”Ÿæˆâ€œå¼€ç›²ç›’â€çš„ç—›è‹¦ï¼Œç”Ÿæˆè¿‡ç¨‹ä¸­éšæ—¶é¢„è§ˆã€‚\n>\n**æ ¸å¿ƒå‘ç°ï¼š** è§†é¢‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¤ªæ…¢ä¸”ä¸é€æ˜ã€‚ä½œè€…è®¾è®¡äº†ä¸€ä¸ªè½»é‡çº§è§£ç å™¨ï¼Œå¯ä»¥åœ¨å»å™ªè¿‡ç¨‹çš„ä»»ä½•æ—¶é—´æ­¥ç”Ÿæˆé¢„è§ˆï¼ˆRGB + åœºæ™¯ä¿¡æ¯ï¼‰ã€‚æ”¯æŒç”¨æˆ·åœ¨ç”Ÿæˆä¸­é€”è¿›è¡Œå¹²é¢„å’Œå¼•å¯¼ã€‚\n\n**12. [YOLOæŒ‘æˆ˜è€…] VajraV1ï¼šYOLO å®¶æ—ä¸­æœ€å‡†ç¡®çš„å®æ—¶ç›®æ ‡æ£€æµ‹å™¨**\n**VajraV1 -- The most accurate Real Time Object Detector of the YOLO family**\n> **ä¸€å¥è¯ç‚¹è¯„ï¼š** åå­—å¾ˆéœ¸æ°”ï¼ˆVajraæ„ä¸ºé‡‘åˆšæµï¼‰ï¼Œå®£ç§°åœ¨å®æ—¶æ£€æµ‹é¢†åŸŸå‡»è´¥äº† YOLOv12/v13ã€‚\n>\n**æ ¸å¿ƒå‘ç°ï¼š** æŠ€æœ¯æŠ¥å‘Šã€‚VajraV1 ç»“åˆäº†è¿‡å¾€ YOLO æ¨¡å‹çš„æœ‰æ•ˆè®¾è®¡ã€‚åœ¨ COCO ä¸Šï¼Œå…¶ Nano ç‰ˆæœ¬ mAP è¾¾åˆ° 44.3%ï¼ŒXlarge ç‰ˆæœ¬è¾¾åˆ° 56.2%ï¼Œåœ¨ä¿æŒå®æ—¶é€Ÿåº¦çš„åŒæ—¶åˆ·æ–°äº†ç²¾åº¦è®°å½•ã€‚\n\n---\n\n### âš–ï¸ å®‰å…¨ã€æ³•å¾‹ä¸ç¤¾ä¼šå½±å“\n\n**13. [æ³•å¾‹å“²å­¦] ç®—æ³•ç¼ªæ–¯ä¸å…¬å…±é¢†åŸŸï¼šä¸ºä½•ç‰ˆæƒæ³•å“²å­¦æ’é™¤äº†ç”Ÿæˆå¼ AI è¾“å‡ºçš„ä¿æŠ¤**\n**The algorithmic muse and the public domain: Why copyrights legal philosophy precludes protection for generative AI outputs**\n> **ä¸€å¥è¯ç‚¹è¯„ï¼š** æ³•å¾‹ç•Œé‡ç£…è§‚ç‚¹â€”â€”AI ç”Ÿæˆçš„å†…å®¹åº”é»˜è®¤å½’å±äºâ€œå…¬å…±é¢†åŸŸâ€ã€‚\n>\n**æ ¸å¿ƒè§‚ç‚¹ï¼š** æ–‡ç« ä»ç‰ˆæƒæ³•å“²å­¦ï¼ˆåŠŸåˆ©ä¸»ä¹‰ã€åŠ³åŠ¨æŠ¥é…¬ç­‰ï¼‰è®ºè¯ï¼Œåˆ‡æ–­äº†äººç±»åˆ›é€ æ€§ä¸è¡¨è¾¾å½¢å¼ç›´æ¥è”ç³»çš„ GenAI è¾“å‡ºï¼Œæ— æ³•è·å¾—ç‰ˆæƒä¿æŠ¤ã€‚å¦‚æœç»™äºˆä¿æŠ¤ï¼Œå°†å¯¼è‡´æ•°å­—å…¬åœ°çš„â€œåœˆåœ°è¿åŠ¨â€ï¼Œé˜»ç¢åˆ›æ–°ã€‚\n\n**14. [AIå¿ƒç†å­¦] LLM èƒ½ç†è§£æˆ‘ä»¬ä¸èƒ½è¯´çš„è¯å—ï¼Ÿè·¨å±‚é¢çš„å •èƒæ±¡ååŒ–æµ‹é‡**\n**Can LLMs Understand What We Cannot Say? Measuring Multilevel Alignment Through Abortion Stigma...**\n> **ä¸€å¥è¯ç‚¹è¯„ï¼š** AI åœ¨å¤„ç†æ•æ„Ÿã€è¢«æ±¡ååŒ–çš„è¯é¢˜ï¼ˆå¦‚å •èƒï¼‰æ—¶ï¼Œå¹¶ä¸çœŸæ­£â€œç†è§£â€äººç±»çš„å¿ƒç†å¤æ‚æ€§ã€‚\n>\n**æ ¸å¿ƒå‘ç°ï¼š** æµ‹è¯•äº† 5 ä¸ªä¸»æµ LLMï¼Œå‘ç°å®ƒä»¬æ— æ³•è¿è´¯åœ°é€šè¿‡è®¤çŸ¥ã€äººé™…å’Œç»“æ„å±‚é¢æ¥è¡¨å¾â€œæ±¡ååŒ–â€ã€‚æ¨¡å‹å€¾å‘äºä½ä¼°è®¤çŸ¥æ±¡åï¼Œé«˜ä¼°äººé™…æ±¡åï¼Œå¹¶å­˜åœ¨äººå£ç»Ÿè®¡å­¦åè§ã€‚è¿™æ„å‘³ç€ç›®å‰çš„å¯¹é½ï¼ˆAlignmentï¼‰åªæ˜¯è¡¨é¢ä¸Šçš„è¯­è¨€åˆè§„ï¼Œè€Œéæ·±å±‚ç†è§£ã€‚\n\n**15. [å®‰å…¨æ¡†æ¶] Cisco é›†æˆ AI å®‰å…¨ä¸ä¿éšœæ¡†æ¶æŠ¥å‘Š**\n**Cisco Integrated AI Security and Safety Framework Report**\n> **ä¸€å¥è¯ç‚¹è¯„ï¼š** æ€ç§‘å‘å¸ƒçš„å·¥ä¸šçº§ AI å®‰å…¨åˆ†ç±»å­¦ï¼Œé€‚åˆä¼ä¸šçº¢é˜Ÿæ¼”ç»ƒå’Œé£é™©æ’æŸ¥ã€‚\n>\n**æ ¸å¿ƒå†…å®¹ï¼š** æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ç”Ÿå‘½å‘¨æœŸæ¡†æ¶ï¼Œæ¶µç›–å†…å®¹å®‰å…¨ã€æ¨¡å‹å®Œæ•´æ€§ã€è¿è¡Œæ—¶æ“çºµï¼ˆå¦‚ Prompt æ³¨å…¥ï¼‰å’Œç”Ÿæ€ç³»ç»Ÿé£é™©ï¼ˆå¦‚å¤šæ™ºèƒ½ä½“å‹¾ç»“ï¼‰ã€‚å¼¥è¡¥äº†ç°æœ‰æ¡†æ¶ï¼ˆå¦‚ MITRE ATLASï¼‰è¦†ç›–é¢å•ä¸€çš„é—®é¢˜ã€‚",
  "papers": [
    {
      "arxiv_id": "2512.19716v1",
      "title": "Development and external validation of a multimodal artificial intelligence mortality prediction model of critically ill patients using multicenter data",
      "title_zh": "åŸºäºå¤šä¸­å¿ƒæ•°æ®çš„å±é‡ç—‡æ‚£è€…å¤šæ¨¡æ€äººå·¥æ™ºèƒ½æ­»äº¡é¢„æµ‹æ¨¡å‹çš„å¼€å‘ä¸å¤–éƒ¨éªŒè¯",
      "authors": [
        "Behrooz Mamandipoor",
        "Chun-Nan Hsu",
        "Martin Krause",
        "Ulrich H. Schmidt",
        "Rodney A. Gabriel"
      ],
      "abstract": "Early prediction of in-hospital mortality in critically ill patients can aid clinicians in optimizing treatment. The objective was to develop a multimodal deep learning model, using structured and unstructured clinical data, to predict in-hospital mortality risk among critically ill patients after their initial 24 hour intensive care unit (ICU) admission. We used data from MIMIC-III, MIMIC-IV, eICU, and HiRID. A multimodal model was developed on the MIMIC datasets, featuring time series components occurring within the first 24 hours of ICU admission and predicting risk of subsequent inpatient mortality. Inputs included time-invariant variables, time-variant variables, clinical notes, and chest X-ray images. External validation occurred in a temporally separated MIMIC population, HiRID, and eICU datasets. A total of 203,434 ICU admissions from more than 200 hospitals between 2001 to 2022 were included, in which mortality rate ranged from 5.2% to 7.9% across the four datasets. The model integrating structured data points had AUROC, AUPRC, and Brier scores of 0.92, 0.53, and 0.19, respectively. We externally validated the model on eight different institutions within the eICU dataset, demonstrating AUROCs ranging from 0.84-0.92. When including only patients with available clinical notes and imaging data, inclusion of notes and imaging into the model, the AUROC, AUPRC, and Brier score improved from 0.87 to 0.89, 0.43 to 0.48, and 0.37 to 0.17, respectively. Our findings highlight the importance of incorporating multiple sources of patient information for mortality prediction and the importance of external validation.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘å¹¶éªŒè¯äº†ä¸€ç§å¤šæ¨¡æ€äººå·¥æ™ºèƒ½æ­»äº¡é¢„æµ‹æ¨¡å‹ï¼Œæ—¨åœ¨åˆ©ç”¨é‡ç—‡ç›‘æŠ¤ç—…æˆ¿(ICU)å…¥é™¢åæœ€åˆ24å°æ—¶çš„å¤šä¸­å¿ƒæ•°æ®é¢„æµ‹å±é‡æ‚£è€…çš„ä½é™¢æ­»äº¡é£é™©ã€‚ç ”ç©¶é‡‡ç”¨äº†æ¥è‡ªMIMIC-III, MIMIC-IV, eICUå’ŒHiRIDçš„è¶…è¿‡20ä¸‡æ¬¡ICUå…¥é™¢æ•°æ®ï¼Œæ•´åˆäº†åŒ…æ‹¬æ—¶é—´ä¸å˜å˜é‡(time-invariant variables)ã€æ—¶é—´åºåˆ—å˜é‡(time-variant variables)ã€ä¸´åºŠç¬”è®°(clinical notes)å’Œèƒ¸éƒ¨Xå°„çº¿å›¾åƒ(chest X-ray images)åœ¨å†…çš„å¤šæºä¿¡æ¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ•´åˆç»“æ„åŒ–æ•°æ®çš„æ¨¡å‹åœ¨AUROCä¸Šè¾¾åˆ°äº†0.92ï¼Œå¹¶åœ¨å¤šä¸ªå¤–éƒ¨æœºæ„çš„éªŒè¯ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„é²æ£’æ€§ï¼Œå…¶AUROCä»‹äº0.84è‡³0.92ä¹‹é—´ã€‚å½“è¿›ä¸€æ­¥çº³å…¥ä¸´åºŠç¬”è®°å’Œå½±åƒæ•°æ®æ—¶ï¼Œæ¨¡å‹çš„AUROCã€AUPRCå’ŒBrier scoresç­‰æ€§èƒ½æŒ‡æ ‡å‡å¾—åˆ°æ˜¾è‘—æå‡ã€‚è¯¥ç ”ç©¶ç»“æœçªæ˜¾äº†æ•´åˆå¤šæºæ‚£è€…ä¿¡æ¯å¯¹äºæ­»äº¡ç‡é¢„æµ‹çš„é‡è¦æ€§ï¼Œå¹¶å……åˆ†è¯æ˜äº†æ¨¡å‹åœ¨è·¨åŒ»ç–—æœºæ„å¤–éƒ¨éªŒè¯(external validation)ä¸­çš„å¯é æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "75 pages (33 main text + references, 35 supplementary materials), 5 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2512.19716v1",
      "published_date": "2025-12-15 23:43:19 UTC",
      "updated_date": "2025-12-15 23:43:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:49:14.012482+00:00"
    },
    {
      "arxiv_id": "2512.13956v1",
      "title": "Multi-Agent Collaborative Framework for Intelligent IT Operations: An AOI System with Context-Aware Compression and Dynamic Task Scheduling",
      "title_zh": "æ™ºèƒ½ IT è¿ç»´å¤šæ™ºèƒ½ä½“ååŒæ¡†æ¶ï¼šå…·å¤‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥å‹ç¼©ä¸åŠ¨æ€ä»»åŠ¡è°ƒåº¦çš„ AOI ç³»ç»Ÿ",
      "authors": [
        "Zishan Bai",
        "Enze Ge",
        "Junfeng Hao"
      ],
      "abstract": "The proliferation of cloud-native architectures, characterized by microservices and dynamic orchestration, has rendered modern IT infrastructures exceedingly complex and volatile. This complexity generates overwhelming volumes of operational data, leading to critical bottlenecks in conventional systems: inefficient information processing, poor task coordination, and loss of contextual continuity during fault diagnosis and remediation. To address these challenges, we propose AOI (AI-Oriented Operations), a novel multi-agent collaborative framework that integrates three specialized agents with an LLM-based Context Compressor. Its core innovations include: (1) a dynamic task scheduling strategy that adaptively prioritizes operations based on real-time system states, and (2) a three-layer memory architecture comprising Working, Episodic, and Semantic layers that optimizes context retention and retrieval. Extensive experiments on both synthetic and real-world benchmarks demonstrate that AOI effectively mitigates information overload, achieving a 72.4% context compression ratio while preserving 92.8% of critical information and significantly enhances operational efficiency, attaining a 94.2% task success rate and reducing the Mean Time to Repair (MTTR) by 34.4% compared to the best baseline. This work presents a paradigm shift towards scalable, adaptive, and context-aware autonomous operations, enabling robust management of next-generation IT infrastructures with minimal human intervention.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AOI (AI-Oriented Operations)ï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹äº‘åŸç”Ÿæ¶æ„å¤æ‚æ€§è®¾è®¡çš„å¤šæ™ºèƒ½ä½“åä½œæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°ä»£ITè¿ç»´ä¸­çš„ä¿¡æ¯å¤„ç†ä½æ•ˆå’Œä¸Šä¸‹æ–‡ä¸¢å¤±ç­‰æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é›†æˆäº†ä¸‰ä¸ªä¸“é—¨çš„æ™ºèƒ½ä½“ä¸åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„Context Compressorï¼Œå¹¶é€šè¿‡åŠ¨æ€ä»»åŠ¡è°ƒåº¦ç­–ç•¥(Dynamic task scheduling)æ ¹æ®å®æ—¶ç³»ç»ŸçŠ¶æ€è‡ªé€‚åº”åœ°ç¡®å®šæ“ä½œä¼˜å…ˆçº§ã€‚æ­¤å¤–ï¼ŒAOIå¼•å…¥äº†åŒ…å«Workingã€Episodicå’ŒSemanticå±‚çš„ä¸‰å±‚è®°å¿†æ¶æ„ï¼Œæ˜¾è‘—ä¼˜åŒ–äº†æ•…éšœè¯Šæ–­å’Œä¿®å¤è¿‡ç¨‹ä¸­çš„ä¸Šä¸‹æ–‡ä¿ç•™ä¸æ£€ç´¢ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨ä¿æŒ92.8%å…³é”®ä¿¡æ¯çš„åŒæ—¶å®ç°äº†72.4%çš„ä¸Šä¸‹æ–‡å‹ç¼©ç‡ï¼Œå¹¶å°†ä»»åŠ¡æˆåŠŸç‡æå‡è‡³94.2%ã€‚ä¸ç°æœ‰åŸºå‡†ç›¸æ¯”ï¼ŒAOIå°†å¹³å‡ä¿®å¤æ—¶é—´(MTTR)ç¼©çŸ­äº†34.4%ï¼Œä¸ºå®ç°å¯æ‰©å±•ä¸”å…·æœ‰ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„è‡ªä¸»è¿ç»´æä¾›äº†æ–°çš„èŒƒå¼ï¼Œæœ‰æ•ˆå‡å°‘äº†äººå·¥å¹²é¢„ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13956v1",
      "published_date": "2025-12-15 23:22:02 UTC",
      "updated_date": "2025-12-15 23:22:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:49:30.184769+00:00"
    },
    {
      "arxiv_id": "2512.13955v1",
      "title": "MURIM: Multidimensional Reputation-based Incentive Mechanism for Federated Learning",
      "title_zh": "MURIMï¼šé¢å‘è”é‚¦å­¦ä¹ çš„å¤šç»´å£°èª‰æ¿€åŠ±æœºåˆ¶",
      "authors": [
        "Sindhuja Madabushi",
        "Dawood Wasif",
        "Jin-Hee Cho"
      ],
      "abstract": "Federated Learning (FL) has emerged as a leading privacy-preserving machine learning paradigm, enabling participants to share model updates instead of raw data. However, FL continues to face key challenges, including weak client incentives, privacy risks, and resource constraints. Assessing client reliability is essential for fair incentive allocation and ensuring that each client's data contributes meaningfully to the global model. To this end, we propose MURIM, a MUlti-dimensional Reputation-based Incentive Mechanism that jointly considers client reliability, privacy, resource capacity, and fairness while preventing malicious or unreliable clients from earning undeserved rewards. MURIM allocates incentives based on client contribution, latency, and reputation, supported by a reliability verification module. Extensive experiments on MNIST, FMNIST, and ADULT Income datasets demonstrate that MURIM achieves up to 18% improvement in fairness metrics, reduces privacy attack success rates by 5-9%, and improves robustness against poisoning and noisy-gradient attacks by up to 85% compared to state-of-the-art baselines. Overall, MURIM effectively mitigates adversarial threats, promotes fair and truthful participation, and preserves stable model convergence across heterogeneous and dynamic federated settings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Federated Learning (FL) ä¸­å­˜åœ¨çš„æ¿€åŠ±æœºåˆ¶è–„å¼±ã€éšç§é£é™©å’Œèµ„æºå—é™ç­‰æ ¸å¿ƒæŒ‘æˆ˜ï¼Œæå‡ºäº† MURIMï¼Œä¸€ç§åŸºäºå¤šç»´ä¿¡èª‰çš„æ¿€åŠ±æœºåˆ¶ã€‚MURIM é€šè¿‡ç»¼åˆè€ƒè™‘å®¢æˆ·ç«¯çš„å¯é æ€§ã€éšç§ã€èµ„æºå®¹é‡å’Œå…¬å¹³æ€§ï¼Œæ—¨åœ¨ç¡®ä¿æ¯ä¸ªå‚ä¸è€…çš„è´¡çŒ®éƒ½èƒ½å¯¹å…¨å±€æ¨¡å‹äº§ç”Ÿå®è´¨æ€§æ„ä¹‰ã€‚è¯¥æœºåˆ¶åŒ…å«ä¸€ä¸ªå¯é æ€§éªŒè¯æ¨¡å—ï¼Œå¹¶æ ¹æ®å®¢æˆ·ç«¯çš„è´¡çŒ®åº¦ã€å»¶è¿ŸåŠä¿¡èª‰åˆ†é…å¥–åŠ±ï¼Œæœ‰æ•ˆé˜²æ­¢äº†æ¶æ„æˆ–ä¸å¯é å®¢æˆ·ç«¯è·å–ä¸å½“æŠ¥é…¬ã€‚åœ¨ MNISTã€FMNIST å’Œ ADULT Income ç­‰æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯è¡¨æ˜ï¼ŒMURIM åœ¨å…¬å¹³æ€§æŒ‡æ ‡ä¸Šå®ç°äº† 18% çš„æå‡ï¼Œå¹¶å°†éšç§æ”»å‡»æˆåŠŸç‡é™ä½äº† 5-9%ã€‚åŒæ—¶ï¼Œè¯¥æ–¹æ¡ˆåœ¨æŠµå¾¡ poisoning attacks å’Œ noisy-gradient attacks æ–¹é¢çš„é²æ£’æ€§æ¯”ç°æœ‰åŸºå‡†æ¨¡å‹æé«˜äº†é«˜è¾¾ 85%ã€‚æ€»ä½“è€Œè¨€ï¼ŒMURIM æœ‰æ•ˆç¼“è§£äº†å¯¹æŠ—æ€§å¨èƒï¼Œä¿ƒè¿›äº†å…¬å¹³ä¸”çœŸå®çš„å‚ä¸ï¼Œå¹¶åœ¨å¼‚æ„å’ŒåŠ¨æ€çš„è”é‚¦å­¦ä¹ ç¯å¢ƒä¸­ä¿æŒäº†ç¨³å®šçš„æ¨¡å‹æ”¶æ•›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13955v1",
      "published_date": "2025-12-15 23:18:32 UTC",
      "updated_date": "2025-12-15 23:18:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:49:42.474387+00:00"
    },
    {
      "arxiv_id": "2512.13935v1",
      "title": "Informing Acquisition Functions via Foundation Models for Molecular Discovery",
      "title_zh": "åˆ©ç”¨åŸºç¡€æ¨¡å‹æŒ‡å¯¼åˆ†å­å‘ç°ä¸­çš„é‡‡é›†å‡½æ•°",
      "authors": [
        "Qi Chen",
        "Fabio Ramos",
        "AlÃ¡n Aspuru-Guzik",
        "Florian Shkurti"
      ],
      "abstract": "Bayesian Optimization (BO) is a key methodology for accelerating molecular discovery by estimating the mapping from molecules to their properties while seeking the optimal candidate. Typically, BO iteratively updates a probabilistic surrogate model of this mapping and optimizes acquisition functions derived from the model to guide molecule selection. However, its performance is limited in low-data regimes with insufficient prior knowledge and vast candidate spaces. Large language models (LLMs) and chemistry foundation models offer rich priors to enhance BO, but high-dimensional features, costly in-context learning, and the computational burden of deep Bayesian surrogates hinder their full utilization. To address these challenges, we propose a likelihood-free BO method that bypasses explicit surrogate modeling and directly leverages priors from general LLMs and chemistry-specific foundation models to inform acquisition functions. Our method also learns a tree-structured partition of the molecular search space with local acquisition functions, enabling efficient candidate selection via Monte Carlo Tree Search. By further incorporating coarse-grained LLM-based clustering, it substantially improves scalability to large candidate sets by restricting acquisition function evaluations to clusters with statistically higher property values. We show through extensive experiments and ablations that the proposed method substantially improves scalability, robustness, and sample efficiency in LLM-guided BO for molecular discovery.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Bayesian Optimization (BO) åœ¨åˆ†å­å‘ç°ä¸­å°æ ·æœ¬å’Œåºå¤§å€™é€‰ç©ºé—´é¢ä¸´çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨åŸºç¡€æ¨¡å‹è¾…åŠ©é‡‡é›†å‡½æ•° (Acquisition Functions) çš„æ–°å‹æ–¹æ³•ã€‚è¯¥æ–¹æ¡ˆé‡‡ç”¨æ— ä¼¼ç„¶ (likelihood-free) çš„æ¡†æ¶ï¼Œé¿å¼€äº†ä¼ ç»Ÿçš„æ˜¾å¼ä»£ç†æ¨¡å‹æ„å»ºï¼Œç›´æ¥å°†é€šç”¨ LLMs å’ŒåŒ–å­¦é¢†åŸŸåŸºç¡€æ¨¡å‹æä¾›çš„ä¸°å¯Œå…ˆéªŒçŸ¥è¯†æ³¨å…¥é‡‡é›†å‡½æ•°ã€‚ä¸ºäº†æå‡æœç´¢æ•ˆç‡ï¼Œç ”ç©¶è®¾è®¡äº†æ ‘çŠ¶ç©ºé—´åˆ’åˆ†æœºåˆ¶ï¼Œå¹¶ç»“åˆ Monte Carlo Tree Search (MCTS) è¿›è¡Œå€™é€‰åˆ†å­çš„ç²¾å‡†ç­›é€‰ã€‚æ­¤å¤–ï¼Œé€šè¿‡åŸºäº LLM çš„ç²—ç²’åº¦èšç±»æŠ€æœ¯ï¼Œç³»ç»Ÿèƒ½å¤Ÿå°†è¯„ä¼°é‡ç‚¹é”å®šåœ¨å…·æœ‰é«˜å±æ€§æ½œåŠ›çš„å­ç©ºé—´ï¼Œæ˜¾è‘—å¢å¼ºäº†å¤„ç†å¤§è§„æ¨¡å€™é€‰é›†çš„å¯æ‰©å±•æ€§ã€‚å¤§é‡å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ LLM å¼•å¯¼çš„åˆ†å­å‘ç°ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šçš„æ ·æœ¬æ•ˆç‡ã€é²æ£’æ€§å’Œè®¡ç®—æ•ˆç‡ï¼Œæœ‰æ•ˆç¼“è§£äº†é«˜ç»´ç‰¹å¾å’Œæ·±åº¦ Bayesian ä»£ç†æ¨¡å‹å¸¦æ¥çš„æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13935v1",
      "published_date": "2025-12-15 22:19:21 UTC",
      "updated_date": "2025-12-15 22:19:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:49:31.503894+00:00"
    },
    {
      "arxiv_id": "2512.13930v1",
      "title": "Hierarchical Multi-agent Large Language Model Reasoning for Autonomous Functional Materials Discovery",
      "title_zh": "ç”¨äºè‡ªä¸»åŠŸèƒ½ææ–™å‘ç°çš„å±‚çº§åŒ–å¤šæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹æ¨ç†",
      "authors": [
        "Samuel Rothfarb",
        "Megan C. Davis",
        "Ivana Matanovic",
        "Baikun Li",
        "Edward F. Holby",
        "Wilton J. M. Kort-Kamp"
      ],
      "abstract": "Artificial intelligence is reshaping scientific exploration, but most methods automate procedural tasks without engaging in scientific reasoning, limiting autonomy in discovery. We introduce Materials Agents for Simulation and Theory in Electronic-structure Reasoning (MASTER), an active learning framework where large language models autonomously design, execute, and interpret atomistic simulations. In MASTER, a multimodal system translates natural language into density functional theory workflows, while higher-level reasoning agents guide discovery through a hierarchy of strategies, including a single agent baseline and three multi-agent approaches: peer review, triage-ranking, and triage-forms. Across two chemical applications, CO adsorption on Cu-surface transition metal (M) adatoms and on M-N-C catalysts, reasoning-driven exploration reduces required atomistic simulations by up to 90% relative to trial-and-error selection. Reasoning trajectories reveal chemically grounded decisions that cannot be explained by stochastic sampling or semantic bias. Altogether, multi-agent collaboration accelerates materials discovery and marks a new paradigm for autonomous scientific exploration.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MASTER (Materials Agents for Simulation and Theory in Electronic-structure Reasoning)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å®ç°è‡ªä¸»ç§‘å­¦å‘ç°çš„ä¸»åŠ¨å­¦ä¹  (active learning) æ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³äº†ç°æœ‰ AI æ–¹æ³•åœ¨ç§‘å­¦æ¨ç†èƒ½åŠ›ä¸Šçš„å±€é™ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¤šæ¨¡æ€ç³»ç»Ÿå°†è‡ªç„¶è¯­è¨€è½¬åŒ–ä¸ºå¯†åº¦æ³›å‡½ç†è®º (density functional theory, DFT) å·¥ä½œæµï¼Œå¹¶é€šè¿‡åˆ†å±‚æ¨ç†æ™ºèƒ½ä½“æŒ‡å¯¼ææ–™å‘ç°è¿‡ç¨‹ã€‚MASTER æ•´åˆäº†å•æ™ºèƒ½ä½“åŸºå‡†ä»¥åŠåŒè¡Œè¯„å®¡ (peer review)ã€åˆ†å±‚æ’åº (triage-ranking) å’Œåˆ†å±‚è¡¨æ ¼ (triage-forms) ä¸‰ç§å¤šæ™ºèƒ½ä½“åä½œç­–ç•¥ã€‚åœ¨é’ˆå¯¹é“œè¡¨é¢è¿‡æ¸¡é‡‘å±åŸå­çš„ä¸€æ°§åŒ–ç¢³ (CO) å¸é™„ä»¥åŠ M-N-C å‚¬åŒ–å‰‚çš„æµ‹è¯•ä¸­ï¼Œè¿™ç§åŸºäºæ¨ç†çš„æ¢ç´¢ç­–ç•¥è¾ƒä¼ ç»Ÿè¯•é”™æ³•å‡å°‘äº†é«˜è¾¾ 90% çš„åŸå­æ¨¡æ‹Ÿéœ€æ±‚ã€‚ç ”ç©¶ç»“æœè¯å®ï¼Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æ¨ç†è½¨è¿¹å…·æœ‰æ˜ç¡®çš„åŒ–å­¦ä¾æ®ï¼Œè€Œééšæœºé‡‡æ ·æˆ–è¯­ä¹‰åå·®ã€‚è¿™ä¸€æˆæœæ˜¾è‘—åŠ é€Ÿäº†åŠŸèƒ½ææ–™çš„ç ”å‘è¿›ç¨‹ï¼Œä¸ºè‡ªä¸»åŒ–ç§‘å­¦æ¢ç´¢ç¡®ç«‹äº†å…¨æ–°çš„èŒƒå¼ã€‚",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "Keywords: Multi-agent reasoning; Large language models; Active learning; AI-driven simulation; Materials discovery; Density functional theory; Surface chemistry",
      "pdf_url": "https://arxiv.org/pdf/2512.13930v1",
      "published_date": "2025-12-15 22:08:18 UTC",
      "updated_date": "2025-12-15 22:08:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:49:40.417263+00:00"
    },
    {
      "arxiv_id": "2512.13914v1",
      "title": "Context Branching for LLM Conversations: A Version Control Approach to Exploratory Programming",
      "title_zh": "LLM å¯¹è¯ä¸Šä¸‹æ–‡åˆ†æ”¯ï¼šä¸€ç§æ¢ç´¢æ€§ç¼–ç¨‹çš„ç‰ˆæœ¬æ§åˆ¶æ–¹æ³•",
      "authors": [
        "Bhargav Chickmagalur Nanjundappa",
        "Spandan Maaheshwari"
      ],
      "abstract": "Large Language Models (LLMs) have become integral to software engineering workflows, yet their effectiveness degrades significantly in multi-turn conversations. Recent studies demonstrate an average 39% performance drop when instructions are delivered across multiple turns, with models making premature assumptions and failing to course correct (Laban et al., 2025). This degradation is particularly problematic in exploratory programming tasks where developers need to investigate alternative approaches without committing to a single path. Current solutions force users into a false dichotomy: continue in a context-polluted conversation where the LLM becomes increasingly confused, or start fresh and lose all accumulated context.\n  We present ContextBranch, a conversation management system that applies version control semantics to LLM interactions. ContextBranch provides four core primitives--checkpoint, branch, switch, and inject--enabling users to capture conversation state, explore alternatives in isolation, and selectively merge insights. We evaluate ContextBranch through a controlled experiment with 30 software engineering scenarios featuring intentionally polluting explorations. Branched conversations achieved higher response quality compared to linear conversations, with large improvements in focus and context awareness. Benefits were concentrated in complex scenarios involving conceptually distant explorations. Branching reduced context size by 58.1% (31.0 to 13.0 messages), eliminating irrelevant exploratory content. Our work establishes conversation branching as a fundamental primitive for AI-assisted exploratory work, demonstrating that isolation prevents context pollution when exploring alternatives.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ContextBranchï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„ä¼šè¯ç®¡ç†ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³å¤šè½®å¯¹è¯ä¸­å› ä¸Šä¸‹æ–‡æ±¡æŸ“ (context pollution) å¯¼è‡´çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚åœ¨æ¢ç´¢æ€§ç¼–ç¨‹ (exploratory programming) ä»»åŠ¡ä¸­ï¼ŒContextBranch å¼•å…¥äº†ç‰ˆæœ¬æ§åˆ¶ (version control) è¯­ä¹‰ï¼Œæä¾›äº† checkpointã€branchã€switch å’Œ inject å››ä¸ªæ ¸å¿ƒåŸè¯­ï¼Œå…è®¸ç”¨æˆ·æ•è·å¯¹è¯çŠ¶æ€å¹¶åœ¨éš”ç¦»ç¯å¢ƒä¸­æ¢ç´¢å¤‡é€‰æ–¹æ¡ˆã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œä¸ä¼ ç»Ÿçš„çº¿æ€§å¯¹è¯ç›¸æ¯”ï¼Œåˆ†æ”¯åŒ–å¯¹è¯åœ¨å“åº”è´¨é‡ã€ä¸“æ³¨åº¦å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥æ–¹é¢è¡¨ç°æ›´ä¼˜ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠå¤æ‚æ¢ç´¢çš„åœºæ™¯ä¸­ã€‚è¯¥ç³»ç»ŸæˆåŠŸå°†å¹³å‡ä¸Šä¸‹æ–‡è§„æ¨¡å‡å°‘äº† 58.1%ï¼Œé€šè¿‡æœ‰æ•ˆéš”ç¦»æ— å…³å†…å®¹æ¶ˆé™¤äº†æ¨¡å‹å› å†—ä½™ä¿¡æ¯äº§ç”Ÿçš„å›°æƒ‘ã€‚ç ”ç©¶ç»“æœè¯æ˜äº†å¯¹è¯åˆ†æ”¯æ˜¯ AI è¾…åŠ©æ¢ç´¢æ€§å·¥ä½œçš„åŸºæœ¬åŸè¯­ï¼Œä¸ºè§£å†³å¤§è§„æ¨¡æ¨¡å‹åœ¨å¤æ‚è½¯ä»¶å·¥ç¨‹ä»»åŠ¡ä¸­çš„ä¸Šä¸‹æ–‡ç®¡ç†éš¾é¢˜æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "11 pages, 4 figures, 2 tables, 1 code snippet, 4 algorithms",
      "pdf_url": "https://arxiv.org/pdf/2512.13914v1",
      "published_date": "2025-12-15 21:49:13 UTC",
      "updated_date": "2025-12-15 21:49:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:49:27.988775+00:00"
    },
    {
      "arxiv_id": "2512.13912v1",
      "title": "Intelligent matter consisting of active particles",
      "title_zh": "ç”±æ´»æ€§ç²’å­æ„æˆçš„æ™ºèƒ½ç‰©è´¨",
      "authors": [
        "Julian Jeggle",
        "Raphael Wittkowski"
      ],
      "abstract": "In this book chapter, we review how systems of simple motile agents can be used as a pathway to intelligent systems. It is a well known result from nature that large groups of entities following simple rules, such as swarms of animals, can give rise to much more complex collective behavior in a display of emergence. This begs the question whether we can emulate this behavior in synthetic matter and drive it to a point where the collective behavior reaches the complexity level of intelligent systems. Here, we will use a formalized notion of \"intelligent matter\" and compare it to recent results in the field of active matter. First, we will explore the approach of emergent computing in which specialized active matter systems are designed to directly solve a given task through emergent behavior. This we will then contrast with the approach of physical reservoir computing powered by the dynamics of active particle systems. In this context, we will also describe a novel reservoir computing scheme for active particles driven ultrasonically or via light refraction.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡ç®€å•çš„è¿åŠ¨æ™ºèƒ½ä½“ (motile agents) ç³»ç»Ÿæ„å»ºæ™ºèƒ½ç³»ç»Ÿï¼Œå¹¶æå‡ºäº† â€œæ™ºèƒ½ç‰©è´¨â€ (intelligent matter) çš„å½¢å¼åŒ–æ¦‚å¿µã€‚å€Ÿé‰´è‡ªç„¶ç•Œä¸­ç¾¤é›†è¡Œä¸ºçš„çªç° (emergence) ç‰¹æ€§ï¼Œæ–‡ç« ç ”ç©¶äº†åœ¨åˆæˆç‰©è´¨ä¸­æ¨¡æ‹Ÿå¤æ‚é›†ä½“è¡Œä¸ºå¹¶ä½¿å…¶è¾¾åˆ°æ™ºèƒ½ç³»ç»Ÿå¤æ‚åº¦çš„å¯èƒ½æ€§ã€‚ä½œè€…é¦–å…ˆåˆ†æäº†çªç°è®¡ç®— (emergent computing) æ–¹æ³•ï¼Œå³è®¾è®¡ç‰¹å®šçš„ä¸»åŠ¨ç‰©è´¨ (active matter) ç³»ç»Ÿé€šè¿‡çªç°è¡Œä¸ºç›´æ¥è§£å†³ä»»åŠ¡ï¼Œå¹¶å°†å…¶ä¸ç‰©ç†å‚¨å¤‡æ± è®¡ç®— (physical reservoir computing) æ–¹æ³•è¿›è¡Œå¯¹æ¯”ã€‚æ­¤å¤–ï¼Œæ–‡ä¸­è¿˜è¯¦ç»†æè¿°äº†ä¸€ç§æ–°å‹çš„å‚¨å¤‡æ± è®¡ç®—æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆä¸“é—¨é’ˆå¯¹ç”±è¶…å£°æ³¢æˆ–å…‰æŠ˜å°„é©±åŠ¨çš„ä¸»åŠ¨ç²’å­ç³»ç»Ÿã€‚è¿™é¡¹ç»¼è¿°ä¸ºç†è§£ä¸»åŠ¨ç²’å­åŠ¨åŠ›å­¦ä¸è®¡ç®—èƒ½åŠ›ä¹‹é—´çš„è”ç³»æä¾›äº†é‡è¦å‚è€ƒï¼Œå±•ç¤ºäº†ä¸»åŠ¨ç‰©è´¨ä½œä¸ºå®ç°äººå·¥æ™ºèƒ½ç³»ç»Ÿæ–°é€”å¾„çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cond-mat.soft",
        "cond-mat.dis-nn",
        "cs.AI",
        "cs.LG",
        "physics.app-ph"
      ],
      "primary_category": "cond-mat.soft",
      "comment": "14 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.13912v1",
      "published_date": "2025-12-15 21:39:01 UTC",
      "updated_date": "2025-12-15 21:39:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:49:42.206691+00:00"
    },
    {
      "arxiv_id": "2512.13910v1",
      "title": "Exploring Machine Learning, Deep Learning, and Explainable AI Methods for Seasonal Precipitation Prediction in South America",
      "title_zh": "å—ç¾æ´²å­£èŠ‚æ€§é™æ°´é¢„æµ‹ä¸­çš„æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ åŠå¯è§£é‡Šäººå·¥æ™ºèƒ½æ–¹æ³•æ¢ç´¢",
      "authors": [
        "Matheus CorrÃªa Domingos",
        "Valdivino Alexandre de Santiago JÃºnior",
        "Juliana Aparecida Anochi",
        "Elcio Hideiti Shiguemori",
        "LuÃ­sa Mirelle Costa dos Santos",
        "HÃ©rcules Carlos dos Santos Pereira",
        "AndrÃ© Estevam Costa Oliveira"
      ],
      "abstract": "Forecasting meteorological variables is challenging due to the complexity of their processes, requiring advanced models for accuracy. Accurate precipitation forecasts are vital for society. Reliable predictions help communities mitigate climatic impacts. Based on the current relevance of artificial intelligence (AI), classical machine learning (ML) and deep learning (DL) techniques have been used as an alternative or complement to dynamic modeling. However, there is still a lack of broad investigations into the feasibility of purely data-driven approaches for precipitation forecasting. This study aims at addressing this issue where different classical ML and DL approaches for forecasting precipitation in South America, taking into account all 2019 seasons, are considered in a detailed investigation. The selected classical ML techniques were Random Forests and extreme gradient boosting (XGBoost), while the DL counterparts were a 1D convolutional neural network (CNN 1D), a long short-term memory (LSTM) model, and a gated recurrent unit (GRU) model. Additionally, the Brazilian Global Atmospheric Model (BAM) was used as a representative of the traditional dynamic modeling approach. We also relied on explainable artificial intelligence (XAI) to provide some explanations for the models behaviors. LSTM showed strong predictive performance while BAM, the traditional dynamic model representative, had the worst results. Despite presented the higher latency, LSTM was most accurate for heavy precipitation. If cost is a concern, XGBoost offers lower latency with slightly accuracy loss. The results of this research confirm the viability of DL models for climate forecasting, solidifying a global trend in major meteorological and climate forecasting centers.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨æœºå™¨å­¦ä¹ (Machine Learning)ã€æ·±åº¦å­¦ä¹ (Deep Learning)å’Œå¯è§£é‡Šäººå·¥æ™ºèƒ½(Explainable AI)æ–¹æ³•å¯¹å—ç¾æ´²å­£èŠ‚æ€§é™æ°´è¿›è¡Œé¢„æµ‹çš„å¯è¡Œæ€§ã€‚ç ”ç©¶å¯¹æ¯”äº†Random Forestså’ŒXGBoostç­‰ç»å…¸æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œä»¥åŠCNN 1Dã€LSTMå’ŒGRUç­‰æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¹¶å°†å…¶ä¸ä¼ ç»Ÿçš„åŠ¨åŠ›å­¦æ¨¡å‹BAMè¿›è¡Œäº†å¤šç»´åº¦è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLSTMåœ¨é¢„æµ‹æ€§èƒ½ä¸Šè¡¨ç°å¼ºåŠ²ï¼Œå°¤å…¶åœ¨å¼ºé™æ°´é¢„æµ‹çš„å‡†ç¡®æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œè€Œä¼ ç»Ÿçš„åŠ¨åŠ›å­¦æ¨¡å‹BAMçš„æ•ˆæœæœ€å·®ã€‚è™½ç„¶LSTMå…·æœ‰è¾ƒé«˜çš„é¢„æµ‹å»¶è¿Ÿï¼Œä½†åœ¨æ•æ‰é‡åº¦é™æ°´äº‹ä»¶æ–¹é¢æœ€ä¸ºç²¾å‡†ï¼›è‹¥è€ƒè™‘è®¡ç®—æˆæœ¬ï¼ŒXGBooståˆ™æä¾›äº†ä½å»¶è¿Ÿä¸”ç²¾åº¦æŸå¤±è¾ƒå°çš„å¹³è¡¡æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜åˆ©ç”¨XAIæŠ€æœ¯å¯¹æ¨¡å‹è¡Œä¸ºè¿›è¡Œäº†åŸç†è§£é‡Šï¼Œæ­ç¤ºäº†æ•°æ®é©±åŠ¨æ–¹æ³•çš„å†…åœ¨é€»è¾‘ã€‚è¯¥ç ”ç©¶ç»“æœè¯å®äº†æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨æ°”è±¡å’Œæ°”å€™é¢„æµ‹é¢†åŸŸçš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºå—ç¾æ´²é™æ°´é¢„æŠ¥æä¾›äº†æ›´å¯é çš„æ›¿ä»£æˆ–è¡¥å……æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13910v1",
      "published_date": "2025-12-15 21:37:27 UTC",
      "updated_date": "2025-12-15 21:37:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:49:49.578769+00:00"
    },
    {
      "arxiv_id": "2512.13907v2",
      "title": "Assessing High-Risk AI Systems under the EU AI Act: From Legal Requirements to Technical Verification",
      "title_zh": "æ¬§ç›Ÿã€Šäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹æ¡†æ¶ä¸‹çš„é«˜é£é™©äººå·¥æ™ºèƒ½ç³»ç»Ÿè¯„ä¼°ï¼šä»æ³•å¾‹è¦æ±‚åˆ°æŠ€æœ¯éªŒè¯",
      "authors": [
        "Alessio Buscemi",
        "Tom Deckenbrunnen",
        "Fahria Kabir",
        "Kateryna Mishchenko",
        "Nishat Mowla"
      ],
      "abstract": "The implementation of the AI Act requires practical mechanisms to verify compliance with legal obligations, yet concrete and operational mappings from high-level requirements to verifiable assessment activities remain limited, contributing to uneven readiness across Member States. This paper presents a structured mapping that translates high-level AI Act requirements into concrete, implementable verification activities applicable across the AI lifecycle. The mapping is derived through a systematic process in which legal requirements are decomposed into operational sub-requirements and grounded in authoritative standards and recognised practices. From this basis, verification activities are identified and characterised along two dimensions: the type of verification performed and the lifecycle target to which it applies. By making explicit the link between regulatory intent and technical and organisational assurance practices, the proposed mapping reduces interpretive uncertainty and provides a reusable reference for consistent, technology-agnostic compliance verification under the AI Act.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¬§ç›Ÿã€Šäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹(EU AI Act) è½åœ°è¿‡ç¨‹ä¸­é«˜å±‚æ³•å¾‹è¦æ±‚ä¸æŠ€æœ¯éªŒè¯æ´»åŠ¨ä¹‹é—´ç¼ºä¹å…·ä½“æ˜ å°„çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“æ„åŒ–çš„å¯¹åº”æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†æ³•æ¡ˆä¸­çš„é«˜çº§åˆ«è¦æ±‚ç³»ç»Ÿåœ°åˆ†è§£ä¸ºå¯æ“ä½œçš„å­è¦æ±‚ï¼Œå¹¶å°†å…¶ä¸æƒå¨æ ‡å‡†å’Œå…¬è®¤å®è·µç›¸ç»“åˆï¼Œè½¬åŒ–ä¸ºè´¯ç©¿äººå·¥æ™ºèƒ½ç”Ÿå‘½å‘¨æœŸ(AI lifecycle)çš„å¯æ‰§è¡ŒéªŒè¯æ´»åŠ¨ã€‚ç ”ç©¶ä»éªŒè¯ç±»å‹å’Œç”Ÿå‘½å‘¨æœŸç›®æ ‡ä¸¤ä¸ªç»´åº¦å¯¹è¿™äº›æ´»åŠ¨è¿›è¡Œäº†åˆ†ç±»ä¸å®šä¹‰ï¼Œæ˜ç¡®äº†ç›‘ç®¡æ„å›¾ä¸æŠ€æœ¯åŠç»„ç»‡ä¿éšœå®è·µä¹‹é—´çš„å…³è”ã€‚é€šè¿‡è¿™ç§æ˜ å°„ï¼Œè¯¥ç ”ç©¶æœ‰æ•ˆå‡å°‘äº†æ³•å¾‹è§£é‡Šçš„ä¸ç¡®å®šæ€§ï¼Œä¸ºå®ç°ã€Šäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹ä¸‹ä¸€è‡´ä¸”ä¸æŠ€æœ¯æ— å…³çš„åˆè§„éªŒè¯æä¾›äº†å¯å¤ç”¨çš„å‚è€ƒä¾æ®ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13907v2",
      "published_date": "2025-12-15 21:24:29 UTC",
      "updated_date": "2025-12-22 13:38:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:50:10.799394+00:00"
    },
    {
      "arxiv_id": "2512.13904v1",
      "title": "Generative AI for Video Translation: A Scalable Architecture for Multilingual Video Conferencing",
      "title_zh": "è§†é¢‘ç¿»è¯‘ä¸­çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼šé¢å‘å¤šè¯­è¨€è§†é¢‘ä¼šè®®çš„å¯æ‰©å±•æ¶æ„",
      "authors": [
        "Amirkia Rafiei Oskooei",
        "Eren Caglar",
        "Ibrahim Sahin",
        "Ayse Kayabay",
        "Mehmet S. Aktas"
      ],
      "abstract": "The real-time deployment of cascaded generative AI pipelines for applications like video translation is constrained by significant system-level challenges. These include the cumulative latency of sequential model inference and the quadratic ($\\mathcal{O}(N^2)$) computational complexity that renders multi-user video conferencing applications unscalable. This paper proposes and evaluates a practical system-level framework designed to mitigate these critical bottlenecks. The proposed architecture incorporates a turn-taking mechanism to reduce computational complexity from quadratic to linear in multi-user scenarios, and a segmented processing protocol to manage inference latency for a perceptually real-time experience. We implement a proof-of-concept pipeline and conduct a rigorous performance analysis across a multi-tiered hardware setup, including commodity (NVIDIA RTX 4060), cloud (NVIDIA T4), and enterprise (NVIDIA A100) GPUs. Our objective evaluation demonstrates that the system achieves real-time throughput ($Ï„< 1.0$) on modern hardware. A subjective user study further validates the approach, showing that a predictable, initial processing delay is highly acceptable to users in exchange for a smooth, uninterrupted playback experience. The work presents a validated, end-to-end system design that offers a practical roadmap for deploying scalable, real-time generative AI applications in multilingual communication platforms.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šç”¨æˆ·è§†é¢‘ä¼šè®®ä¸­ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI)è§†é¢‘ç¿»è¯‘é¢ä¸´çš„ç´¯ç§¯å»¶è¿Ÿå’ŒäºŒæ¬¡æ–¹è®¡ç®—å¤æ‚åº¦($\\mathcal{O}(N^2)$)ç­‰å…³é”®æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªå®ç”¨çš„ç³»ç»Ÿçº§æ¡†æ¶ã€‚è¯¥æ¶æ„é€šè¿‡å¼•å…¥è½®æ›¿æœºåˆ¶(turn-taking mechanism)å°†è®¡ç®—å¤æ‚åº¦ä»äºŒæ¬¡æ–¹é™ä½è‡³çº¿æ€§ï¼Œå¹¶åˆ©ç”¨åˆ†æ®µå¤„ç†åè®®(segmented processing protocol)ç®¡ç†æ¨ç†å»¶è¿Ÿï¼Œä»è€Œæä¾›æ„Ÿå®˜ä¸Šçš„å®æ—¶ä½“éªŒã€‚ç ”ç©¶å›¢é˜Ÿåœ¨NVIDIA RTX 4060ã€T4å’ŒA100ç­‰ç¡¬ä»¶ä¸Šè¿›è¡Œäº†æ€§èƒ½åˆ†æï¼Œç»“æœè¡¨æ˜è¯¥ç³»ç»Ÿåœ¨ç°ä»£ç¡¬ä»¶ä¸Šå®ç°äº†å®æ—¶ååé‡($\\tau < 1.0$)ã€‚ä¸»è§‚ç”¨æˆ·ç ”ç©¶è¿›ä¸€æ­¥éªŒè¯ï¼Œåˆå§‹çš„å¯é¢„æµ‹å¤„ç†å»¶è¿Ÿåœ¨æ¢å–æµç•…æ’­æ”¾çš„æƒ…å†µä¸‹å…·æœ‰æé«˜çš„ç”¨æˆ·æ¥å—åº¦ã€‚è¯¥é¡¹å·¥ä½œä¸ºåœ¨å¤šè¯­è¨€é€šä¿¡å¹³å°ä¸­éƒ¨ç½²å¯æ‰©å±•ã€å®æ—¶çš„Generative AIåº”ç”¨æä¾›äº†ç»è¿‡éªŒè¯çš„ç«¯åˆ°ç«¯ç³»ç»Ÿè®¾è®¡è·¯çº¿å›¾ã€‚",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.MM",
      "comment": "Accepted manuscript. Published in Applied Sciences, 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.13904v1",
      "published_date": "2025-12-15 21:21:09 UTC",
      "updated_date": "2025-12-15 21:21:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:49:58.166404+00:00"
    },
    {
      "arxiv_id": "2512.13892v2",
      "title": "One Permutation Is All You Need: Fast, Reliable Variable Importance and Model Stress-Testing",
      "title_zh": "ä¸€æ¬¡ç½®æ¢è¶³çŸ£ï¼šå¿«é€Ÿä¸”å¯é çš„å˜é‡é‡è¦æ€§è¯„ä¼°ä¸æ¨¡å‹å‹åŠ›æµ‹è¯•",
      "authors": [
        "Albert Dorador"
      ],
      "abstract": "Reliable estimation of feature contributions in machine learning models is essential for trust, transparency and regulatory compliance, especially when models are proprietary or otherwise operate as black boxes. While permutation-based methods are a standard tool for this task, classical implementations rely on repeated random permutations, introducing computational overhead and stochastic instability. In this paper, we show that by replacing multiple random permutations with a single, deterministic, and optimal permutation, we achieve a method that retains the core principles of permutation-based importance while being non-random, faster, and more stable. We validate this approach across nearly 200 scenarios, including real-world household finance and credit risk applications, demonstrating improved bias-variance tradeoffs and accuracy in challenging regimes such as small sample sizes, high dimensionality, and low signal-to-noise ratios. Finally, we introduce Systemic Variable Importance, a natural extension designed for model stress-testing that explicitly accounts for feature correlations. This framework provides a transparent way to quantify how shocks or perturbations propagate through correlated inputs, revealing dependencies that standard variable importance measures miss. Two real-world case studies demonstrate how this metric can be used to audit models for hidden reliance on protected attributes (e.g., gender or race), enabling regulators and practitioners to assess fairness and systemic risk in a principled and computationally efficient manner.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ç‰¹å¾è´¡çŒ®è¯„ä¼°çš„å¯é æ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ä»…éœ€å•æ¬¡ç½®æ¢çš„ä¼˜åŒ–æ–¹æ³•ï¼Œç”¨å•ä¸€ã€ç¡®å®šæ€§ä¸”æœ€ä¼˜çš„ç½®æ¢(Optimal Permutation)å–ä»£ä¼ ç»Ÿçš„å¤šæ¬¡éšæœºç½®æ¢ã€‚è¯¥æ–¹æ³•åœ¨ä¿ç•™ç½®æ¢é‡è¦æ€§(Permutation-based Importance)æ ¸å¿ƒåŸåˆ™çš„åŒæ—¶ï¼Œæ¶ˆé™¤äº†éšæœºæ€§å¹¶æ˜¾è‘—æå‡äº†è®¡ç®—é€Ÿåº¦ä¸ç¨³å®šæ€§ã€‚é€šè¿‡åœ¨è¿‘200ä¸ªåœºæ™¯ä»¥åŠçœŸå®é‡‘èå’Œä¿¡ç”¨é£é™©åº”ç”¨ä¸­çš„éªŒè¯ï¼Œè¯¥æ–¹æ³•åœ¨å°æ ·æœ¬ã€é«˜ç»´åº¦å’Œä½ä¿¡å™ªæ¯”ç­‰ä¸¥è‹›ç¯å¢ƒä¸‹å±•ç°å‡ºæ›´ä¼˜çš„åå·®-æ–¹å·®æƒè¡¡(Bias-variance Tradeoff)å’Œå‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†ç³»ç»Ÿæ€§å˜é‡é‡è¦æ€§(Systemic Variable Importance)æ¡†æ¶ç”¨äºæ¨¡å‹å‹åŠ›æµ‹è¯•ï¼Œèƒ½å¤Ÿæ˜¾å¼å¤„ç†ç‰¹å¾ç›¸å…³æ€§å¹¶é‡åŒ–æ‰°åŠ¨åœ¨è¾“å…¥é—´çš„ä¼ æ’­ã€‚é€šè¿‡å®é™…æ¡ˆä¾‹ç ”ç©¶ï¼Œè¯¥æŒ‡æ ‡è¯æ˜äº†å…¶åœ¨å®¡è®¡æ¨¡å‹å¯¹å—ä¿æŠ¤å±æ€§(å¦‚æ€§åˆ«æˆ–ç§æ—)çš„éšæ€§ä¾èµ–ã€è¯„ä¼°ç®—æ³•å…¬å¹³æ€§åŠç³»ç»Ÿæ€§é£é™©æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºç›‘ç®¡å’Œå®è·µæä¾›äº†é€æ˜ä¸”é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13892v2",
      "published_date": "2025-12-15 20:50:54 UTC",
      "updated_date": "2025-12-23 12:54:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:50:25.013161+00:00"
    },
    {
      "arxiv_id": "2512.13886v2",
      "title": "OPTIMA: Optimal One-shot Pruning for LLMs via Quadratic Programming Reconstruction",
      "title_zh": "OPTIMAï¼šåŸºäºäºŒæ¬¡è§„åˆ’é‡æ„çš„å¤§è¯­è¨€æ¨¡å‹æœ€ä¼˜å•æ¬¡å‰ªæ",
      "authors": [
        "Mohammad Mozaffari",
        "Samuel Kushnir",
        "Maryam Mehri Dehnavi",
        "Amir Yazdanbakhsh"
      ],
      "abstract": "Post-training model pruning is a promising solution, yet it faces a trade-off: simple heuristics that zero weights are fast but degrade accuracy, while principled joint optimization methods recover accuracy but are computationally infeasible at modern scale. One-shot methods such as SparseGPT offer a practical trade-off in optimality by applying efficient, approximate heuristic weight updates. To close this gap, we introduce OPTIMA, a practical one-shot post-training pruning method that balances accuracy and scalability. OPTIMA casts layer-wise weight reconstruction after mask selection as independent, row-wise Quadratic Programs (QPs) that share a common layer Hessian. Solving these QPs yields the per-row globally optimal update with respect to the reconstruction objective given the estimated Hessian. The shared-Hessian structure makes the problem highly amenable to batching on accelerators. We implement an accelerator-friendly QP solver that accumulates one Hessian per layer and solves many small QPs in parallel, enabling one-shot post-training pruning at scale on a single accelerator without fine-tuning. OPTIMA integrates with existing mask selectors and consistently improves zero-shot performance across multiple LLM families and sparsity regimes, yielding up to 3.97% absolute accuracy improvement. On an NVIDIA H100, OPTIMA prunes a 8B-parameter transformer end-to-end in 40 hours with 60GB peak memory. Together, these results set a new state-of-the-art accuracy-efficiency trade-offs for one-shot post-training pruning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„è®­ç»ƒåå‰ªæé—®é¢˜ï¼Œæå‡ºäº†OPTIMAæ–¹æ³•ï¼Œæ—¨åœ¨å¹³è¡¡æ¨¡å‹å‡†ç¡®æ€§ä¸è®¡ç®—çš„å¯æ‰©å±•æ€§ã€‚OPTIMAå°†æ©ç é€‰æ‹©åçš„é€å±‚æƒé‡é‡æ„å»ºæ¨¡ä¸ºç‹¬ç«‹çš„è¡Œå‘äºŒæ¬¡è§„åˆ’(Quadratic Programs)é—®é¢˜ï¼Œè¿™äº›é—®é¢˜å…±äº«ä¸€ä¸ªå…¬å…±çš„å±‚æµ·æ£®çŸ©é˜µ(Hessian)ã€‚é€šè¿‡æ±‚è§£è¿™äº›äºŒæ¬¡è§„åˆ’é—®é¢˜ï¼ŒOPTIMAèƒ½å¤Ÿåœ¨ç»™å®šä¼°è®¡æµ·æ£®çŸ©é˜µçš„æƒ…å†µä¸‹ï¼Œå®ç°é‡æ„ç›®æ ‡å‡½æ•°ä¸‹æ¯è¡Œæƒé‡çš„å…¨å±€æœ€ä¼˜æ›´æ–°ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å…±äº«æµ·æ£®çŸ©é˜µçš„ç»“æ„å®ç°äº†åœ¨åŠ é€Ÿå™¨ä¸Šçš„é«˜æ•ˆæ‰¹å¤„ç†ï¼Œå¹¶å¼€å‘äº†ä¸“ç”¨çš„QPæ±‚è§£å™¨ï¼Œæ”¯æŒåœ¨å•ä¸ªåŠ é€Ÿå™¨ä¸Šè¿›è¡Œå¤§è§„æ¨¡One-shotå‰ªæè€Œæ— éœ€å¾®è°ƒã€‚OPTIMAå¯ä¸ç°æœ‰çš„æ©ç é€‰æ‹©å™¨é›†æˆï¼Œåœ¨å¤šä¸ªLLMå®¶æ—å’Œç¨€ç–åº¦è®¾ç½®ä¸‹æ˜¾è‘—æå‡äº†é›¶æ ·æœ¬(zero-shot)æ€§èƒ½ï¼Œæœ€é«˜å®ç°3.97%çš„ç»å¯¹å‡†ç¡®ç‡æå‡ã€‚å®éªŒè¯æ˜ï¼Œåœ¨NVIDIA H100ä¸Šå¯¹8Bå‚æ•°æ¨¡å‹è¿›è¡Œç«¯åˆ°ç«¯å‰ªæä»…éœ€40å°æ—¶ï¼Œè¿™ä¸ºOne-shotè®­ç»ƒåå‰ªæç¡®ç«‹äº†æ–°çš„å‡†ç¡®ç‡ä¸æ•ˆç‡æƒè¡¡çš„state-of-the-artã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13886v2",
      "published_date": "2025-12-15 20:41:29 UTC",
      "updated_date": "2025-12-31 02:49:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:50:43.696186+00:00"
    },
    {
      "arxiv_id": "2512.14762v1",
      "title": "Workflows vs Agents for Code Translation",
      "title_zh": "ä»£ç ç¿»è¯‘ä¸­çš„å·¥ä½œæµä¸æ™ºèƒ½ä½“å¯¹æ¯”",
      "authors": [
        "Henry Gray",
        "Tom Yotam",
        "Octavian Udrea"
      ],
      "abstract": "Translating algorithms from high-level languages like MATLAB to hardware description languages (HDLs) is a resource-intensive but necessary step for deployment on FPGAs and ASICs. While large language models (LLMs) offer a path to automation, their limited training on HDL code makes end-to-end transpilation brittle and prone to syntax errors. We compare two LLM-driven methods for syntax repair in a MATLAB-to-HDL pipeline: a structured, expert-designed flow that follows a fixed sequence of operations, and a more autonomous agentic approach that uses the Model Context Protocol (MCP) \\cite{anthropic2024mcp} to dynamically select its own tools. We study 42 MATLAB signal-processing functions and isolate the syntax-repair stage. Across three model scales, the agentic approach is more effective at resolving initial syntax errors, unblocking a greater number of candidates to proceed through the pipeline. This upstream improvement yields measurable downstream improvements, most notably on mid-sized models, where it increases the simulation reach rate by over 20 percentage points. We hypothesize the gains come from short prompts, aggressive context management, and conditional tool use. Conditional retrieval helps at 8B and 30B; at 235B final-success gains are small and a naive RAG variant attains the highest final success. Our findings suggest that these agentic frameworks, when properly designed, are most effective at compensating for the capacity limits of small and mid-sized models.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹æ¯”äº†ä¸¤ç§åŸºäºLLMsçš„æ–¹æ³•åœ¨MATLABåˆ°HDLä»£ç ç¿»è¯‘æµç¨‹ä¸­çš„è¯­æ³•ä¿®å¤(syntax repair)è¡¨ç°ï¼šä¸€ç§æ˜¯éµå¾ªå›ºå®šæ“ä½œåºåˆ—çš„ç»“æ„åŒ–Workflowï¼Œå¦ä¸€ç§æ˜¯åˆ©ç”¨Model Context Protocol (MCP)åŠ¨æ€é€‰æ‹©å·¥å…·çš„è‡ªä¸»Agenticæ–¹æ³•ã€‚ç ”ç©¶å›¢é˜Ÿé’ˆå¯¹42ä¸ªMATLABä¿¡å·å¤„ç†å‡½æ•°ï¼Œåœ¨ä¸‰ç§ä¸åŒè§„æ¨¡çš„æ¨¡å‹ä¸Šæµ‹è¯•äº†è¯­æ³•ä¿®å¤é˜¶æ®µã€‚ç»“æœæ˜¾ç¤ºï¼ŒAgenticæ–¹æ³•åœ¨è§£å†³åˆå§‹è¯­æ³•é”™è¯¯æ–¹é¢æ¯”ä¼ ç»Ÿçš„Workflowæ›´æœ‰æ•ˆï¼Œä»è€Œæ˜¾è‘—æå‡äº†ä¸‹æ¸¸ä»»åŠ¡çš„æ¨¡æ‹Ÿè¾¾åˆ°ç‡(simulation reach rate)ï¼Œå°¤å…¶åœ¨ä¸­å‹æ¨¡å‹ä¸Šæå‡è¶…è¿‡äº†20ä¸ªç™¾åˆ†ç‚¹ã€‚åˆ†æè®¤ä¸ºï¼ŒAgenticæ¡†æ¶çš„ä¼˜åŠ¿æºäºæ›´çŸ­çš„æç¤ºè¯ã€é«˜æ•ˆçš„ä¸Šä¸‹æ–‡ç®¡ç†å’Œæ¡ä»¶åŒ–å·¥å…·ä½¿ç”¨ã€‚æœ€ç»ˆç ”ç©¶æŒ‡å‡ºï¼Œè¿™ç±»Agenticæ¡†æ¶åœ¨å¼¥è¡¥ä¸­å°å‹æ¨¡å‹çš„èƒ½åŠ›å±€é™æ–¹é¢æœ€ä¸ºæœ‰æ•ˆï¼Œè€Œå¯¹äº235Bè§„æ¨¡çš„è¶…å¤§å‹æ¨¡å‹ï¼Œå…¶æ€§èƒ½æå‡åˆ™ç›¸å¯¹æœ‰é™ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.14762v1",
      "published_date": "2025-12-15 20:35:11 UTC",
      "updated_date": "2025-12-15 20:35:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:50:45.018430+00:00"
    },
    {
      "arxiv_id": "2512.13880v1",
      "title": "Privacy-Enhancing Infant Cry Classification with Federated Transformers and Denoising Regularization",
      "title_zh": "åŸºäºè”é‚¦ Transformer ä¸å»å™ªæ­£åˆ™åŒ–çš„éšç§å¢å¼ºå‹å©´å„¿å“­å£°åˆ†ç±»",
      "authors": [
        "Geofrey Owino",
        "Bernard Shibwabo"
      ],
      "abstract": "Infant cry classification can aid early assessment of infant needs. However, deployment of such solutions is limited by privacy concerns around audio data, sensitivity to background noise, and domain shift across recording environments. We present an end-to-end infant cry analysis pipeline that integrates a denoising autoencoder (DAE), a convolutional tokenizer, and a Transformer encoder trained using communication-efficient federated learning (FL). The system performs on-device denoising, adaptive segmentation, post hoc calibration, and energy-based out-of-distribution (OOD) abstention. Federated training employs a regularized control variate update with 8-bit adapter deltas under secure aggregation. Using the Baby Chillanto and Donate-a-Cry datasets with ESC-50 noise overlays, the model achieves a macro F1 score of 0.938, an AUC of 0.962, and an Expected Calibration Error (ECE) of 0.032, while reducing per-round client upload from approximately 36 to 42 MB to 3.3 MB. Real-time edge inference on an NVIDIA Jetson Nano (4 GB, TensorRT FP16) achieves 96 ms per one-second spectrogram frame. These results demonstrate a practical path toward privacy-preserving, noise-robust, and communication-efficient infant cry classification suitable for federated deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å©´å„¿å•¼å“­åˆ†ç±»ä¸­çš„éšç§æ³„éœ²ã€èƒŒæ™¯å™ªå£°å’Œé¢†åŸŸåç§»é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§èåˆè”é‚¦å­¦ä¹ (Federated Learning)ä¸Transformeræ¶æ„çš„éšç§ä¿æŠ¤åˆ†ç±»æµç¨‹ã€‚ç³»ç»Ÿé›†æˆäº†å»å™ªè‡ªç¼–ç å™¨(Denoising Autoencoder)ã€å·ç§¯åˆ†è¯å™¨(Convolutional Tokenizer)å’ŒTransformerç¼–ç å™¨ï¼Œæ”¯æŒè®¾å¤‡ç«¯å»å™ªã€åéªŒæ ¡å‡†åŠåŸºäºèƒ½é‡çš„åˆ†å¸ƒå¤–(Out-of-Distribution)æ‹’ç»æœºåˆ¶ã€‚åœ¨è”é‚¦è®­ç»ƒé˜¶æ®µï¼Œç ”ç©¶é€šè¿‡å¼•å…¥8ä½é€‚é…å™¨å¢é‡(8-bit Adapter Deltas)å’Œæ­£åˆ™åŒ–æ§åˆ¶å˜é‡æ›´æ–°ï¼Œæ˜¾è‘—é™ä½äº†é€šä¿¡å¼€é”€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨åŒ…å«èƒŒæ™¯å™ªå£°çš„æ•°æ®é›†ä¸Šè¾¾åˆ°äº†0.938çš„å®F1åˆ†æ•°å’Œ0.962çš„AUCï¼ŒåŒæ—¶å°†å•è½®ä¸Šä¼ æ•°æ®é‡ä»çº¦40MBç¼©å‡è‡³3.3MBã€‚åœ¨NVIDIA Jetson Nanoä¸Šçš„éƒ¨ç½²æµ‹è¯•è¯æ˜äº†å…¶æ¯ç§’ä»…éœ€96æ¯«ç§’çš„å®æ—¶è¾¹ç¼˜æ¨ç†èƒ½åŠ›ï¼Œä¸ºå¼€å‘éšç§å®‰å…¨ã€å™ªå£°é²æ£’ä¸”é€šä¿¡é«˜æ•ˆçš„å©´å„¿éœ€æ±‚è¯„ä¼°æŠ€æœ¯æä¾›äº†å®è·µè·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper was accepted for presentation and presented at the 2025 International Conference on Computer Engineering, Network, and Intelligent Multimedia (CENIM 2025)",
      "pdf_url": "https://arxiv.org/pdf/2512.13880v1",
      "published_date": "2025-12-15 20:33:24 UTC",
      "updated_date": "2025-12-15 20:33:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:50:38.908937+00:00"
    },
    {
      "arxiv_id": "2512.15787v1",
      "title": "Toward Agentic Environments: GenAI and the Convergence of AI, Sustainability, and Human-Centric Spaces",
      "title_zh": "è¿ˆå‘æ™ºèƒ½ä½“ç¯å¢ƒï¼šç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä¸äººå·¥æ™ºèƒ½ã€å¯æŒç»­å‘å±•åŠä»¥äººä¸ºä¸­å¿ƒç©ºé—´çš„èåˆ",
      "authors": [
        "Przemek Pospieszny",
        "Dominika P. Brodowicz"
      ],
      "abstract": "In recent years, advances in artificial intelligence (AI), particularly generative AI (GenAI) and large language models (LLMs), have made human-computer interactions more frequent, efficient, and accessible across sectors ranging from banking to healthcare. AI tools embedded in digital devices support decision-making and operational management at both individual and organizational levels, including resource allocation, workflow automation, and real-time data analysis. However, the prevailing cloud-centric deployment of AI carries a substantial environmental footprint due to high computational demands. In this context, this paper introduces the concept of agentic environments, a sustainability-oriented AI framework that extends beyond reactive systems by leveraging GenAI, multi-agent systems, and edge computing to reduce the environmental impact of technology. Agentic environments enable more efficient resource use, improved quality of life, and sustainability-by-design, while simultaneously enhancing data privacy through decentralized, edge-driven solutions. Drawing on secondary research as well as primary data from focus groups and semi-structured interviews with AI professionals from leading technology companies, the paper proposes a conceptual framework for agentic environments examined through three lenses: the personal sphere, professional and commercial use, and urban operations. The findings highlight the potential of agentic environments to foster sustainable ecosystems through optimized resource utilization and strengthened data privacy. The study concludes with recommendations for edge-driven deployment models to reduce reliance on energy-intensive cloud infrastructures.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (GenAI) ä¸å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å„è¡Œä¸šçš„å¹¿æ³›åº”ç”¨ï¼Œå¹¶é’ˆå¯¹å½“å‰äº‘ä¸­å¿ƒåŒ–éƒ¨ç½²å¸¦æ¥çš„å·¨å¤§ç¯å¢ƒå½±å“ï¼Œæå‡ºäº†ä»£ç†ç¯å¢ƒ (agentic environments) çš„æ¦‚å¿µã€‚ä½œä¸ºä¸€ç§é¢å‘å¯æŒç»­å‘å±•çš„ AI æ¡†æ¶ï¼Œå®ƒé€šè¿‡æ•´åˆ GenAIã€å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ (multi-agent systems) å’Œè¾¹ç¼˜è®¡ç®— (edge computing) æŠ€æœ¯ï¼Œæ—¨åœ¨é™ä½è®¡ç®—èƒ½è€—å¹¶å¢å¼ºæ•°æ®éšç§ã€‚ç ”ç©¶é€šè¿‡äºŒæ¬¡ç ”ç©¶ä»¥åŠå¯¹ç§‘æŠ€è¡Œä¸šä¸“ä¸šäººå£«çš„ç„¦ç‚¹å°ç»„å’ŒåŠç»“æ„åŒ–è®¿è°ˆï¼Œä»ä¸ªäººã€ä¸“ä¸šå•†ä¸šåŠåŸå¸‚è¿è¥ä¸‰ä¸ªå±‚é¢æ„å»ºäº†æ¦‚å¿µæ¡†æ¶ã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†ä»£ç†ç¯å¢ƒåœ¨ä¼˜åŒ–èµ„æºåˆ©ç”¨å’Œæ„å»ºå¯æŒç»­ç”Ÿæ€ç³»ç»Ÿæ–¹é¢çš„æ½œåŠ›ï¼Œå¹¶æå€¡é€šè¿‡è¾¹ç¼˜é©±åŠ¨ (edge-driven) çš„éƒ¨ç½²æ¨¡å¼æ¥å‡å°‘å¯¹é«˜èƒ½è€—äº‘åŸºç¡€è®¾æ–½çš„ä¾èµ–ã€‚è¯¥æ¡†æ¶ä¸ºå®ç°ä»¥äººä¸ºæœ¬ä¸”å…·å¤‡å¯æŒç»­æ€§çš„æ™ºèƒ½ç©ºé—´æä¾›äº†ç†è®ºæ”¯æŒä¸å®è·µå»ºè®®ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Preprint, Paper submitted for publication in Sustainable Development (Wiley)",
      "pdf_url": "https://arxiv.org/pdf/2512.15787v1",
      "published_date": "2025-12-15 20:15:02 UTC",
      "updated_date": "2025-12-15 20:15:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:51:07.298579+00:00"
    },
    {
      "arxiv_id": "2512.13860v1",
      "title": "Verification-Guided Context Optimization for Tool Calling via Hierarchical LLMs-as-Editors",
      "title_zh": "åŸºäºå±‚çº§åŒ– LLM ç¼–è¾‘å™¨çš„éªŒè¯å¼•å¯¼å‹å·¥å…·è°ƒç”¨ä¸Šä¸‹æ–‡ä¼˜åŒ–",
      "authors": [
        "Henger Li",
        "Shuangjie You",
        "Flavio Di Palo",
        "Yiyue Qian",
        "Ayush Jain"
      ],
      "abstract": "Tool calling enables large language models (LLMs) to interact with external environments through tool invocation, providing a practical way to overcome the limitations of pretraining. However, the effectiveness of tool use depends heavily on the quality of the associated documentation and knowledge base context. These materials are usually written for human users and are often misaligned with how LLMs interpret information. This problem is even more pronounced in industrial settings, where hundreds of tools with overlapping functionality create challenges in scalability, variability, and ambiguity. We propose Verification-Guided Context Optimization (VGCO), a framework that uses LLMs as editors to automatically refine tool-related documentation and knowledge base context. VGCO works in two stages. First, Evaluation collects real-world failure cases and identifies mismatches between tools and their context. Second, Optimization performs hierarchical editing through offline learning with structure-aware, in-context optimization. The novelty of our LLM editors has three main aspects. First, they use a hierarchical structure that naturally integrates into the tool-calling workflow. Second, they are state-aware, action-specific, and verification-guided, which constrains the search space and enables efficient, targeted improvements. Third, they enable cost-efficient sub-task specialization, either by prompt engineering large editor models or by post-training smaller editor models. Unlike prior work that emphasizes multi-turn reasoning, VGCO focuses on the single-turn, large-scale tool-calling problem and achieves significant improvements in accuracy, robustness, and generalization across LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Verification-Guided Context Optimization (VGCO) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å·¥å…·è°ƒç”¨ (Tool calling) è¿‡ç¨‹ä¸­ï¼Œç”±äºäººç±»ç¼–å†™çš„æ–‡æ¡£ä¸æ¨¡å‹è§£è¯»ä¹‹é—´ä¸åŒ¹é…è€Œå¯¼è‡´çš„æ€§èƒ½å—é™é—®é¢˜ã€‚é’ˆå¯¹å·¥ä¸šçº§åœºæ™¯ä¸­å¤§é‡å·¥å…·åŠŸèƒ½é‡å å¸¦æ¥çš„æŒ‘æˆ˜ï¼ŒVGCO é‡‡ç”¨åˆ†å±‚çš„å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºç¼–è¾‘å™¨ (LLMs-as-Editors) æ¥è‡ªåŠ¨ä¼˜åŒ–å·¥å…·æ–‡æ¡£å’ŒçŸ¥è¯†åº“ä¸Šä¸‹æ–‡ã€‚è¯¥æ¡†æ¶åŒ…å«è¯„ä¼° (Evaluation) å’Œä¼˜åŒ– (Optimization) ä¸¤ä¸ªé˜¶æ®µï¼Œé€šè¿‡æ”¶é›†å¤±è´¥æ¡ˆä¾‹è¯†åˆ«ä¸åŒ¹é…ç‚¹ï¼Œå¹¶åˆ©ç”¨ç»“æ„æ„ŸçŸ¥çš„ä¸Šä¸‹æ–‡å†…å­¦ä¹ è¿›è¡Œåˆ†å±‚ç¼–è¾‘ã€‚VGCO çš„ç¼–è¾‘å™¨å…·å¤‡çŠ¶æ€æ„ŸçŸ¥ã€åŠ¨ä½œç‰¹å®šä»¥åŠéªŒè¯å¼•å¯¼ (verification-guided) çš„ç‰¹æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆçº¦æŸæœç´¢ç©ºé—´å¹¶å®ç°é’ˆå¯¹æ€§æ”¹è¿›ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ¡ˆé€šè¿‡æç¤ºå·¥ç¨‹æˆ–å¯¹å°å‹æ¨¡å‹è¿›è¡Œåè®­ç»ƒï¼Œå®ç°äº†é«˜æ€§ä»·æ¯”çš„å­ä»»åŠ¡ä¸“ä¸šåŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVGCO åœ¨å¤„ç†å•è½®ã€å¤§è§„æ¨¡å·¥å…·è°ƒç”¨é—®é¢˜ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†å„ LLMs çš„å‡†ç¡®æ€§ã€é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by AAAI 2026 Workshop on Agentic AI Benchmarks and Applications for Enterprise Tasks",
      "pdf_url": "https://arxiv.org/pdf/2512.13860v1",
      "published_date": "2025-12-15 19:48:21 UTC",
      "updated_date": "2025-12-15 19:48:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:50:44.313790+00:00"
    },
    {
      "arxiv_id": "2512.13857v2",
      "title": "EvoLattice: Persistent Internal-Population Evolution through Multi-Alternative Quality-Diversity Graph Representations for LLM-Guided Program Discovery",
      "title_zh": "EvoLatticeï¼šé€šè¿‡å¤šå¤‡é€‰è´¨é‡-å¤šæ ·æ€§å›¾è¡¨ç¤ºå®ç°å¤§è¯­è¨€æ¨¡å‹å¼•å¯¼ç¨‹åºå‘ç°ä¸­çš„æŒç»­å†…éƒ¨ç§ç¾¤æ¼”åŒ–",
      "authors": [
        "Kamer Ali Yuksel"
      ],
      "abstract": "Large language models (LLMs) are increasingly used to evolve programs and multi-agent systems, yet most existing approaches rely on overwrite-based mutations that maintain only a single candidate at a time. Such methods discard useful variants, suffer from destructive edits, and explore a brittle search space prone to structural failure. We introduce EvoLattice, a framework that represents an entire population of candidate programs or agent behaviors within a single directed acyclic graph. Each node stores multiple persistent alternatives, and every valid path through the graph defines a distinct executable candidate, yielding a large combinatorial search space without duplicating structure. EvoLattice enables fine-grained alternative-level evaluation by scoring each alternative across all paths in which it appears, producing statistics that reveal how local design choices affect global performance. These statistics provide a dense, data-driven feedback signal for LLM-guided mutation, recombination, and pruning, while preserving successful components. Structural correctness is guaranteed by a deterministic self-repair mechanism that enforces acyclicity and dependency consistency independently of the LLM. EvoLattice naturally extends to agent evolution by interpreting alternatives as prompt fragments or sub-agent behaviors. Across program synthesis (proxy and optimizer meta-learning), EvoLattice yields more stable evolution, greater expressivity, and stronger improvement trajectories than prior LLM-guided methods. The resulting dynamics resemble quality-diversity optimization, emerging implicitly from EvoLattice's internal multi-alternative representation rather than an explicit external archive.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†EvoLatticeæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç¨‹åºæ¼”åŒ–ä¸­å› è¦†ç›–å¼å˜å¼‚å¯¼è‡´çš„å˜ä½“ä¸¢å¤±å’Œæœç´¢ç©ºé—´è„†å¼±ç­‰é—®é¢˜ã€‚EvoLatticeå°†å€™é€‰ç¨‹åºç¾¤ä½“è¡¨ç¤ºåœ¨å•ä¸ªæœ‰å‘æ— ç¯å›¾(Directed Acyclic Graph, DAG)ä¸­ï¼Œé€šè¿‡åœ¨èŠ‚ç‚¹å†…å­˜å‚¨å¤šä¸ªæŒä¹…å¤‡é€‰æ–¹æ¡ˆ(Persistent alternatives)ï¼Œå®ç°äº†åœ¨ä¸é‡å¤ç»“æ„çš„å‰æä¸‹æ„å»ºåºå¤§çš„ç»„åˆæœç´¢ç©ºé—´ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è·¨è·¯å¾„è¯„åˆ†æœºåˆ¶ä¸ºLLMå¼•å¯¼çš„å˜å¼‚ã€é‡ç»„å’Œå‰ªææä¾›ç»†ç²’åº¦çš„æ•°æ®é©±åŠ¨åé¦ˆï¼Œå¹¶ç»“åˆç¡®å®šæ€§çš„è‡ªæˆ‘ä¿®å¤æœºåˆ¶(Self-repair mechanism)ç¡®ä¿ç¨‹åºç»“æ„çš„æ­£ç¡®æ€§ã€‚EvoLatticeä¸ä»…é€‚ç”¨äºç¨‹åºåˆæˆï¼Œè¿˜èƒ½é€šè¿‡å°†å¤‡é€‰æ–¹æ¡ˆè§£é‡Šä¸ºæç¤ºç‰‡æ®µæˆ–å­æ™ºèƒ½ä½“è¡Œä¸ºæ¥æ”¯æŒæ™ºèƒ½ä½“æ¼”åŒ–ã€‚å®éªŒè¯æ˜ï¼Œåœ¨ç¨‹åºåˆæˆå’Œä¼˜åŒ–å™¨å…ƒå­¦ä¹ ä»»åŠ¡ä¸­ï¼ŒEvoLatticeæ¯”ç°æœ‰çš„LLMå¼•å¯¼æ–¹æ³•å…·æœ‰æ›´ç¨³å®šçš„æ¼”åŒ–è½¨è¿¹å’Œæ›´å¼ºçš„æ”¹è¿›èƒ½åŠ›ã€‚é€šè¿‡å†…éƒ¨çš„å¤šå¤‡é€‰è¡¨ç¤ºï¼ŒEvoLatticeéšå¼åœ°å®ç°äº†è´¨é‡å¤šæ ·æ€§(Quality-Diversity)ä¼˜åŒ–ï¼Œæ˜¾è‘—æå‡äº†è‡ªåŠ¨ç¨‹åºå‘ç°çš„æ•ˆç‡å’Œé²æ£’æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13857v2",
      "published_date": "2025-12-15 19:43:06 UTC",
      "updated_date": "2025-12-17 12:18:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:51:01.122929+00:00"
    },
    {
      "arxiv_id": "2512.13855v1",
      "title": "Improvise, Adapt, Overcome -- Telescopic Adapters for Efficient Fine-tuning of Vision Language Models in Medical Imaging",
      "title_zh": "ä¸´åœºåº”å˜ã€çµæ´»é€‚é…ã€æ”»åšå…‹éš¾ï¼šç”¨äºåŒ»å­¦å½±åƒè§†è§‰è¯­è¨€æ¨¡å‹é«˜æ•ˆå¾®è°ƒçš„ä¼¸ç¼©å¼é€‚é…å™¨",
      "authors": [
        "Ujjwal Mishra",
        "Vinita Shukla",
        "Praful Hambarde",
        "Amit Shukla"
      ],
      "abstract": "Adapting Vision Language Segmentation Models (VLSMs) to medical imaging domains requires significant computational overhead when using conventional fine-tuning approaches. Existing Parameter-Efficient Fine-Tuning (PEFT) methods apply uniform adapter dimensions across all transformer layers, leading to suboptimal parameter allocation and reduced adaptation efficiency. We introduce Telescopic Adapters, a novel PEFT framework that employs depth-aware scaling to progressively increase adapter capacity from shallow to deep transformer layers. Our method integrates lightweight bottleneck modules within CLIPSeg's vision and text encoders, with adapter dimensions dynamically scaled based on layer depth and semantic relevance. Using only 613k trainable parameters--244x fewer than end-to-end fine-tuning, Telescopic Adapters achieve superior performance across five diverse medical datasets spanning polyp segmentation, skin lesion detection, and breast ultrasound imaging. Comprehensive ablation studies demonstrate that deeper layers require substantially more adaptation capacity than shallow layers, validating our telescopic scaling hypothesis. Our approach establishes a new paradigm for efficient medical VLSM fine-tuning, enabling deployment in resource-constrained clinical environments while maintaining competitive segmentation accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—å½±åƒé¢†åŸŸä¸­è§†è§‰è¯­è¨€åˆ†å‰²æ¨¡å‹ (Vision Language Segmentation Models, VLSMs) å¾®è°ƒè®¡ç®—å¼€é”€å¤§ï¼Œä»¥åŠç°æœ‰å‚æ•°é«˜æ•ˆå¾®è°ƒ (Parameter-Efficient Fine-Tuning, PEFT) æ–¹æ³•åœ¨ Transformer å±‚é—´å‡åŒ€åˆ†é…å‚æ•°å¯¼è‡´æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º Telescopic Adapters çš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†æ·±åº¦æ„ŸçŸ¥ç¼©æ”¾ (depth-aware scaling) æœºåˆ¶ï¼Œé€šè¿‡åœ¨ CLIPSeg çš„è§†è§‰å’Œæ–‡æœ¬ç¼–ç å™¨ä¸­é›†æˆè½»é‡çº§ç“¶é¢ˆæ¨¡å—ï¼Œä½¿é€‚é…å™¨å®¹é‡éšç½‘ç»œæ·±åº¦çš„å¢åŠ å’Œè¯­ä¹‰ç›¸å…³æ€§è€ŒåŠ¨æ€æ‰©å±•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTelescopic Adapters ä»…ä½¿ç”¨ 613k ä¸ªå¯è®­ç»ƒå‚æ•°ï¼ˆæ¯”å…¨é‡å¾®è°ƒå°‘ 244 å€ï¼‰ï¼Œå³å¯åœ¨æ¯è‚‰åˆ†å‰²ã€çš®è‚¤ç—…å˜æ£€æµ‹å’Œä¹³è…ºè¶…å£°ç­‰äº”ä¸ªåŒ»ç–—æ•°æ®é›†ä¸Šå–å¾—ä¼˜å¼‚æ€§èƒ½ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯å®äº†æ·±å±‚æ¯”æµ…å±‚éœ€è¦æ›´å¤šé€‚é…èƒ½åŠ›çš„ä¼¸ç¼©å¼ç¼©æ”¾å‡è®¾ã€‚è¯¥æ–¹æ³•ä¸ºèµ„æºå—é™çš„ä¸´åºŠç¯å¢ƒä¸‹é«˜æ•ˆå¾®è°ƒåŒ»ç–— VLSM å»ºç«‹äº†æ–°èŒƒå¼ï¼Œåœ¨ä¿æŒé«˜ç²¾åº¦åˆ†å‰²çš„åŒæ—¶æ˜¾è‘—é™ä½äº†éƒ¨ç½²é—¨æ§›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at the IEEE/CVF winter conference on applications of computer vision (WACV 2026)",
      "pdf_url": "https://arxiv.org/pdf/2512.13855v1",
      "published_date": "2025-12-15 19:40:15 UTC",
      "updated_date": "2025-12-15 19:40:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:51:04.799295+00:00"
    },
    {
      "arxiv_id": "2512.13834v1",
      "title": "VajraV1 -- The most accurate Real Time Object Detector of the YOLO family",
      "title_zh": "VajraV1ï¼šYOLO ç³»åˆ—ä¸­ç²¾åº¦æœ€é«˜çš„å®æ—¶ç›®æ ‡æ£€æµ‹å™¨",
      "authors": [
        "Naman Balbir Singh Makkar"
      ],
      "abstract": "Recent years have seen significant advances in real-time object detection, with the release of YOLOv10, YOLO11, YOLOv12, and YOLOv13 between 2024 and 2025. This technical report presents the VajraV1 model architecture, which introduces architectural enhancements over existing YOLO-based detectors. VajraV1 combines effective design choices from prior YOLO models to achieve state-of-the-art accuracy among real-time object detectors while maintaining competitive inference speed.\n  On the COCO validation set, VajraV1-Nano achieves 44.3% mAP, outperforming YOLOv12-N by 3.7% and YOLOv13-N by 2.7% at latency competitive with YOLOv12-N and YOLOv11-N. VajraV1-Small achieves 50.4% mAP, exceeding YOLOv12-S and YOLOv13-S by 2.4%. VajraV1-Medium achieves 52.7% mAP, outperforming YOLOv12-M by 0.2%. VajraV1-Large achieves 53.7% mAP, surpassing YOLOv13-L by 0.3%. VajraV1-Xlarge achieves 56.2% mAP, outperforming all existing real-time object detectors.",
      "tldr_zh": "è¯¥æŠ€æœ¯æŠ¥å‘Šä»‹ç»äº† VajraV1 æ¨¡å‹æ¶æ„ï¼Œè¿™æ˜¯ä¸€ç§åœ¨ YOLO ç³»åˆ—å®æ—¶ç›®æ ‡æ£€æµ‹å™¨åŸºç¡€ä¸Šè¿›è¡Œæ¶æ„æ”¹è¿›çš„æ–°æ¨¡å‹ã€‚VajraV1 ç»“åˆäº†å…ˆå‰ YOLO æ¨¡å‹ä¸­çš„æœ‰æ•ˆè®¾è®¡é€‰æ‹©ï¼Œæ—¨åœ¨ä¿æŒç«äº‰åŠ›çš„æ¨ç†é€Ÿåº¦çš„åŒæ—¶ï¼Œå®ç°å®æ—¶ç›®æ ‡æ£€æµ‹å™¨é¢†åŸŸçš„æœ€ä¼˜å‡†ç¡®ç‡(State-of-the-Art)ã€‚åœ¨ COCO éªŒè¯é›†ä¸Šï¼ŒVajraV1-Nano è¾¾åˆ°äº† 44.3% mAPï¼Œåœ¨å»¶è¿Ÿä¸ YOLOv12-N ç›¸å½“çš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½åˆ†åˆ«è¶…è¿‡äº† YOLOv12-N å’Œ YOLOv13-Nã€‚VajraV1-Small ä»¥ 50.4% mAP æ˜¾è‘—è¶…è¿‡äº† YOLOv12-S å’Œ YOLOv13-Sï¼Œè€Œ VajraV1-Medium ä¸ Large ç‰ˆæœ¬ä¹Ÿåˆ†åˆ«åœ¨å„è‡ªé‡çº§ä¸Šå®ç°äº†å¯¹æœ€æ–° YOLO æ¨¡å‹çš„è¶…è¶Šã€‚æœ€é«˜è§„æ ¼çš„ VajraV1-Xlarge åˆ™ä»¥ 56.2% mAP çš„æˆç»©ï¼Œæ€§èƒ½ä¼˜äºç›®å‰æ‰€æœ‰ç°æœ‰çš„å®æ—¶ç›®æ ‡æ£€æµ‹å™¨ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒVajraV1 ç³»åˆ—åœ¨ä¸åŒè§„æ¨¡ä¸‹å‡åˆ·æ–°äº† YOLO å®¶æ—çš„ç²¾åº¦çºªå½•ï¼Œåœ¨å­¦æœ¯æŒ‡æ ‡ä¸å®é™…æ¨ç†é€Ÿåº¦ä¹‹é—´å–å¾—äº†æä½³çš„å¹³è¡¡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical Report. 20 Pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.13834v1",
      "published_date": "2025-12-15 19:16:15 UTC",
      "updated_date": "2025-12-15 19:16:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:51:02.641865+00:00"
    },
    {
      "arxiv_id": "2512.13806v1",
      "title": "EEG-D3: A Solution to the Hidden Overfitting Problem of Deep Learning Models",
      "title_zh": "EEG-D3ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹éšè—è¿‡æ‹Ÿåˆé—®é¢˜çš„è§£å†³æ–¹æ¡ˆ",
      "authors": [
        "Siegfried Ludwig",
        "Stylianos Bakas",
        "Konstantinos Barmpas",
        "Georgios Zoumpourlis",
        "Dimitrios A. Adamos",
        "Nikolaos Laskaris",
        "Yannis Panagakis",
        "Stefanos Zafeiriou"
      ],
      "abstract": "Deep learning for decoding EEG signals has gained traction, with many claims to state-of-the-art accuracy. However, despite the convincing benchmark performance, successful translation to real applications is limited. The frequent disconnect between performance on controlled BCI benchmarks and its lack of generalisation to practical settings indicates hidden overfitting problems. We introduce Disentangled Decoding Decomposition (D3), a weakly supervised method for training deep learning models across EEG datasets. By predicting the place in the respective trial sequence from which the input window was sampled, EEG-D3 separates latent components of brain activity, akin to non-linear ICA. We utilise a novel model architecture with fully independent sub-networks for strict interpretability. We outline a feature interpretation paradigm to contrast the component activation profiles on different datasets and inspect the associated temporal and spatial filters. The proposed method reliably separates latent components of brain activity on motor imagery data. Training downstream classifiers on an appropriate subset of these components prevents hidden overfitting caused by task-correlated artefacts, which severely affects end-to-end classifiers. We further exploit the linearly separable latent space for effective few-shot learning on sleep stage classification. The ability to distinguish genuine components of brain activity from spurious features results in models that avoid the hidden overfitting problem and generalise well to real-world applications, while requiring only minimal labelled data. With interest to the neuroscience community, the proposed method gives researchers a tool to separate individual brain processes and potentially even uncover heretofore unknown dynamics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨ EEG ä¿¡å·è§£ç ä¸­æ™®éå­˜åœ¨çš„éšæ€§è¿‡æ‹Ÿåˆ (hidden overfitting) é—®é¢˜ï¼Œæå‡ºäº†åä¸º Disentangled Decoding Decomposition (D3) çš„å¼±ç›‘ç£å­¦ä¹ æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡é¢„æµ‹è¾“å…¥çª—å£åœ¨è¯•éªŒåºåˆ—ä¸­çš„é‡‡æ ·ä½ç½®æ¥åˆ†ç¦»å¤§è„‘æ´»åŠ¨çš„æ½œæˆåˆ†ï¼Œå…¶åŸç†ç±»ä¼¼äºéçº¿æ€§ç‹¬ç«‹æˆåˆ†åˆ†æ (non-linear ICA)ã€‚EEG-D3 é‡‡ç”¨äº†ä¸€ç§ç”±å®Œå…¨ç‹¬ç«‹çš„å­ç½‘ç»œæ„æˆçš„æ–°å‹æ¨¡å‹æ¶æ„ä»¥ç¡®ä¿ä¸¥è°¨çš„å¯è§£é‡Šæ€§ï¼Œå¹¶å…è®¸é€šè¿‡ç‰¹å¾è§£é‡ŠèŒƒå¼å¯¹æ¯”ä¸åŒæ•°æ®é›†ä¸Šçš„ç»„ä»¶æ¿€æ´»å‰–é¢ã€‚åœ¨è¿åŠ¨æƒ³è±¡ (motor imagery) æ•°æ®çš„å®éªŒä¸­ï¼Œè¯¥æ–¹æ³•èƒ½å¯é åœ°åˆ†ç¦»å¤§è„‘æ´»åŠ¨æˆåˆ†ï¼Œé€šè¿‡åœ¨è¿™äº›æˆåˆ†çš„å­é›†ä¸Šè®­ç»ƒä¸‹æ¸¸åˆ†ç±»å™¨ï¼Œæœ‰æ•ˆé¿å…äº†å› ä»»åŠ¡ç›¸å…³ä¼ªå½±å¯¼è‡´çš„è¿‡æ‹Ÿåˆã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜åˆ©ç”¨çº¿æ€§å¯åˆ†çš„æ½œç©ºé—´åœ¨ç¡çœ é˜¶æ®µåˆ†ç±»ä¸­å®ç°äº†é«˜æ•ˆçš„å°‘æ ·æœ¬å­¦ä¹  (few-shot learning)ã€‚è¯¥æ–¹æ¡ˆæˆåŠŸå°†çœŸå®å¤§è„‘æ´»åŠ¨ä¸è™šå‡ç‰¹å¾åŒºåˆ†å¼€æ¥ï¼Œä½¿æ¨¡å‹åœ¨ä»…éœ€æå°‘æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹å³å¯åœ¨å®é™…åº”ç”¨ä¸­å±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸ºç¥ç»ç§‘å­¦ç ”ç©¶æä¾›äº†æ¢ç´¢æœªçŸ¥è„‘éƒ¨åŠ¨æ€çš„æœ‰åŠ›å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13806v1",
      "published_date": "2025-12-15 19:00:10 UTC",
      "updated_date": "2025-12-15 19:00:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:51:04.932603+00:00"
    },
    {
      "arxiv_id": "2512.13690v1",
      "title": "DiffusionBrowser: Interactive Diffusion Previews via Multi-Branch Decoders",
      "title_zh": "DiffusionBrowserï¼šåŸºäºå¤šåˆ†æ”¯è§£ç å™¨çš„äº¤äº’å¼æ‰©æ•£é¢„è§ˆ",
      "authors": [
        "Susung Hong",
        "Chongjian Ge",
        "Zhifei Zhang",
        "Jui-Hsien Wang"
      ],
      "abstract": "Video diffusion models have revolutionized generative video synthesis, but they are imprecise, slow, and can be opaque during generation -- keeping users in the dark for a prolonged period. In this work, we propose DiffusionBrowser, a model-agnostic, lightweight decoder framework that allows users to interactively generate previews at any point (timestep or transformer block) during the denoising process. Our model can generate multi-modal preview representations that include RGB and scene intrinsics at more than 4$\\times$ real-time speed (less than 1 second for a 4-second video) that convey consistent appearance and motion to the final video. With the trained decoder, we show that it is possible to interactively guide the generation at intermediate noise steps via stochasticity reinjection and modal steering, unlocking a new control capability. Moreover, we systematically probe the model using the learned decoders, revealing how scene, object, and other details are composed and assembled during the otherwise black-box denoising process.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DiffusionBrowserï¼Œä¸€ä¸ªæ¨¡å‹æ— å…³(model-agnostic)çš„è½»é‡çº§è§£ç å™¨æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è§†é¢‘æ‰©æ•£æ¨¡å‹(Video diffusion models)åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å› ç¼“æ…¢å’Œä¸é€æ˜å¯¼è‡´ç”¨æˆ·éš¾ä»¥å®æ—¶æŒæ¡è¿›å±•çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å…è®¸ç”¨æˆ·åœ¨å»å™ªè¿‡ç¨‹çš„ä»»ä½•æ—¶é—´æ­¥(timestep)æˆ–Transformer Blockä¸­äº¤äº’å¼åœ°ç”ŸæˆåŒ…å«RGBå’Œåœºæ™¯å†…åœ¨å±æ€§(scene intrinsics)çš„å¤šæ¨¡æ€é¢„è§ˆã€‚å®éªŒè¡¨æ˜ï¼ŒDiffusionBrowserèƒ½ä»¥è¶…è¿‡4å€å®æ—¶çš„é€Ÿåº¦ç”Ÿæˆä¸æœ€ç»ˆè§†é¢‘åœ¨å¤–è§‚å’Œè¿åŠ¨ä¸Šä¿æŒä¸€è‡´çš„é¢„è§ˆï¼Œå¤„ç†4ç§’è§†é¢‘çš„é¢„è§ˆè€—æ—¶ä¸è¶³1ç§’ã€‚åˆ©ç”¨è¯¥è§£ç å™¨ï¼Œç ”ç©¶è€…è¿˜å®ç°äº†é€šè¿‡éšæœºæ€§é‡æ–°æ³¨å…¥(stochasticity reinjection)å’Œæ¨¡æ€å¼•å¯¼(modal steering)åœ¨ä¸­é—´å™ªå£°æ­¥éª¤è¿›è¡Œäº¤äº’å¼æ§åˆ¶ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¯¹æ¨¡å‹çš„ç³»ç»Ÿæ¢æµ‹ï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº†åœ¨åŸæœ¬â€œé»‘ç›’â€çš„å»å™ªè¿‡ç¨‹ä¸­åœºæ™¯ã€ç‰©ä½“åŠç»†èŠ‚æ˜¯å¦‚ä½•è¢«æ„å»ºå’Œç»„è£…çš„ï¼Œä¸ºç†è§£å’Œæ§åˆ¶è§†é¢‘ç”Ÿæˆæä¾›äº†æ–°é€”å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://susunghong.github.io/DiffusionBrowser",
      "pdf_url": "https://arxiv.org/pdf/2512.13690v1",
      "published_date": "2025-12-15 18:59:57 UTC",
      "updated_date": "2025-12-15 18:59:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:51:18.704883+00:00"
    },
    {
      "arxiv_id": "2512.13678v1",
      "title": "Feedforward 3D Editing via Text-Steerable Image-to-3D",
      "title_zh": "åŸºäºæ–‡æœ¬å¯æ§å›¾åƒè½¬ 3D çš„å‰é¦ˆ 3D ç¼–è¾‘",
      "authors": [
        "Ziqi Ma",
        "Hongqiao Chen",
        "Yisong Yue",
        "Georgia Gkioxari"
      ],
      "abstract": "Recent progress in image-to-3D has opened up immense possibilities for design, AR/VR, and robotics. However, to use AI-generated 3D assets in real applications, a critical requirement is the capability to edit them easily. We present a feedforward method, Steer3D, to add text steerability to image-to-3D models, which enables editing of generated 3D assets with language. Our approach is inspired by ControlNet, which we adapt to image-to-3D generation to enable text steering directly in a forward pass. We build a scalable data engine for automatic data generation, and develop a two-stage training recipe based on flow-matching training and Direct Preference Optimization (DPO). Compared to competing methods, Steer3D more faithfully follows the language instruction and maintains better consistency with the original 3D asset, while being 2.4x to 28.5x faster. Steer3D demonstrates that it is possible to add a new modality (text) to steer the generation of pretrained image-to-3D generative models with 100k data. Project website: https://glab-caltech.github.io/steer3d/",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Steer3Dï¼Œè¿™æ˜¯ä¸€ç§ä¸º image-to-3D æ¨¡å‹å¢åŠ æ–‡æœ¬å¯æ“æ§æ€§çš„å‰é¦ˆæ–¹æ³• (feedforward method)ï¼Œæ—¨åœ¨é€šè¿‡è¯­è¨€æŒ‡ä»¤å®ç°å¯¹ AI ç”Ÿæˆ 3D èµ„äº§çš„ä¾¿æ·ç¼–è¾‘ã€‚å— ControlNet å¯å‘ï¼Œè¯¥æ–¹æ³•å°†æ§åˆ¶æœºåˆ¶é€‚é…åˆ° 3D ç”Ÿæˆä¸­ï¼Œæ”¯æŒåœ¨å•æ¬¡å‰é¦ˆè¿‡ç¨‹ä¸­ç›´æ¥è¿›è¡Œæ–‡æœ¬å¼•å¯¼ã€‚ç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªå¯æ‰©å±•çš„è‡ªåŠ¨æ•°æ®ç”Ÿæˆå¼•æ“ï¼Œå¹¶å¼€å‘äº†åŸºäºæµåŒ¹é…è®­ç»ƒ (flow-matching training) å’Œç›´æ¥åå¥½ä¼˜åŒ– (Direct Preference Optimization, DPO) çš„ä¸¤é˜¶æ®µè®­ç»ƒæ–¹æ¡ˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSteer3D èƒ½å¤Ÿæ›´å¿ å®åœ°æ‰§è¡Œè¯­è¨€æŒ‡ä»¤ï¼Œå¹¶ä¿æŒä¸åŸå§‹ 3D èµ„äº§çš„é«˜åº¦ä¸€è‡´æ€§ã€‚åœ¨æ¨ç†é€Ÿåº¦ä¸Šï¼Œè¯¥æ–¹æ³•æ¯”ç°æœ‰ç«äº‰æ–¹æ¡ˆå¿« 2.4 å€è‡³ 28.5 å€ã€‚è¯¥é¡¹å·¥ä½œè¯æ˜äº†ä»…éœ€ 10 ä¸‡é‡çº§çš„æ•°æ®ï¼Œå³å¯ä¸ºé¢„è®­ç»ƒçš„ image-to-3D ç”Ÿæˆæ¨¡å‹æˆåŠŸæ·»åŠ æ–‡æœ¬æ¨¡æ€ä»¥å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "https://glab-caltech.github.io/steer3d/",
      "pdf_url": "https://arxiv.org/pdf/2512.13678v1",
      "published_date": "2025-12-15 18:58:55 UTC",
      "updated_date": "2025-12-15 18:58:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:51:25.981129+00:00"
    },
    {
      "arxiv_id": "2512.14761v1",
      "title": "CAPE: Capability Achievement via Policy Execution",
      "title_zh": "CAPEï¼šé€šè¿‡ç­–ç•¥æ‰§è¡Œå®ç°èƒ½åŠ›è¾¾æˆ",
      "authors": [
        "David Ball"
      ],
      "abstract": "Modern AI systems lack a way to express and enforce requirements. Pre-training produces intelligence, and post-training optimizes preferences, but neither guarantees that models reliably satisfy explicit, context-dependent constraints. This missing abstraction explains why highly intelligent models routinely fail in deployment despite strong benchmark performance.\n  We introduce Capability Engineering, the systematic practice of converting requirements into executable specifications and training models to satisfy them by default. We operationalize this practice through CAPE (Capability Achievement via Policy Execution), a protocol implementing a Specify -> Verify -> Correct -> Train loop.\n  CAPE is grounded in two empirical findings: (1) contextual objectivity, where properties appearing subjective become objective once context is fixed (inter-annotator agreement rises from kappa = 0.42 to kappa = 0.98), and (2) verification-fidelity scaling, where verification accuracy improves with model scale (r = 0.94), unlike preference agreement which plateaus at 30 to 50 percent disagreement regardless of compute. Across 109,500 examples in six domains, CAPE reduces violation rates by 81 percent relative to DPO (standard deviation less than 0.3 percent). By replacing per-example annotation with reusable specifications, CAPE reduces costs by 5 to 20 times and shortens timelines from months to weeks.\n  We release the CAPE protocol, PredicateGraph schema, CPL specification language, and policy packs under Apache 2.0. We also launch CapabilityBench, a public registry of model evaluations against community-contributed policies, shifting evaluation from intelligence benchmarks toward capability measurement.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† Capability Engineering è¿™ä¸€ç³»ç»Ÿæ€§å®è·µï¼Œæ—¨åœ¨å°†éœ€æ±‚è½¬åŒ–ä¸ºå¯æ‰§è¡Œè§„èŒƒï¼Œå¹¶é€šè¿‡ CAPE (Capability Achievement via Policy Execution) åè®®å®ç°â€œæŒ‡å®š-éªŒè¯-ä¿®æ­£-è®­ç»ƒâ€çš„é—­ç¯æµç¨‹ã€‚é’ˆå¯¹ç°ä»£ AI ç³»ç»Ÿåœ¨å®é™…éƒ¨ç½²ä¸­éš¾ä»¥æ»¡è¶³æ˜¾å¼ã€ä¸Šä¸‹æ–‡ç›¸å…³çº¦æŸçš„é—®é¢˜ï¼ŒCAPE å»ºç«‹äº†å°†è¦æ±‚è½¬åŒ–ä¸ºæ¨¡å‹é»˜è®¤è¡Œä¸ºçš„æœºåˆ¶ã€‚ç ”ç©¶æå‡ºäº†ä¸Šä¸‹æ–‡å®¢è§‚æ€§ (Contextual Objectivity) å’ŒéªŒè¯ä¿çœŸåº¦ç¼©æ”¾ (Verification-fidelity scaling) ä¸¤é¡¹å…³é”®å®è¯å‘ç°ï¼Œè¯æ˜äº†åœ¨å›ºå®šä¸Šä¸‹æ–‡ä¸‹éªŒè¯å‡†ç¡®æ€§éšæ¨¡å‹è§„æ¨¡æ˜¾è‘—æå‡ã€‚å®éªŒè¡¨æ˜ï¼ŒCAPE åœ¨å…­ä¸ªé¢†åŸŸçš„æµ‹è¯•ä¸­ç›¸æ¯” DPO å°†è¿è§„ç‡é™ä½äº† 81%ï¼ŒåŒæ—¶é€šè¿‡å¯å¤ç”¨è§„èŒƒå°†æˆæœ¬é™ä½äº† 5 è‡³ 20 å€ï¼Œå¹¶å°†äº¤ä»˜å‘¨æœŸä»æ•°æœˆç¼©çŸ­è‡³æ•°å‘¨ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å‘å¸ƒäº† PredicateGraph æ¨¡å¼ã€CPL è§„èŒƒè¯­è¨€åŠ CapabilityBench è¯„æµ‹åŸºå‡†ï¼Œæ—¨åœ¨å°†æ¨¡å‹è¯„ä¼°é‡ç‚¹ä»æ™ºåŠ›æ°´å¹³è½¬å‘å…·ä½“çš„èƒ½åŠ›è¾¾æˆæµ‹é‡ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "32 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.14761v1",
      "published_date": "2025-12-15 18:58:21 UTC",
      "updated_date": "2025-12-15 18:58:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:51:47.546945+00:00"
    },
    {
      "arxiv_id": "2512.15786v1",
      "title": "Cultural Rights and the Rights to Development in the Age of AI: Implications for Global Human Rights Governance",
      "title_zh": "äººå·¥æ™ºèƒ½æ—¶ä»£çš„æ–‡åŒ–æƒåˆ©ä¸å‘å±•æƒï¼šå¯¹å…¨çƒäººæƒæ²»ç†çš„å¯ç¤º",
      "authors": [
        "Alexander Kriebitz",
        "Caitlin Corrigan",
        "Aive Pevkur",
        "Alberto Santos Ferro",
        "Amanda Horzyk",
        "Dirk Brand",
        "Dohee Kim",
        "Dodzi Koku Hattoh",
        "Flavia Massucci",
        "Gilles Fayad",
        "Kamil Strzepek",
        "Laud Ammah",
        "Lavina Ramkissoon",
        "Mariette Awad",
        "Natalia Amasiadi",
        "Nathan C. Walker",
        "Nicole Manger",
        "Sophia Devlin"
      ],
      "abstract": "Cultural rights and the right to development are essential norms within the wider framework of international human rights law. However, recent technological advances in artificial intelligence (AI) and adjacent digital frontier technologies pose significant challenges to the protection and realization of these rights. This owes to the increasing influence of AI systems on the creation and depiction of cultural content, affect the use and distribution of the intellectual property of individuals and communities, and influence cultural participation and expression worldwide. In addition, the growing influence of AI thus risks exacerbating preexisting economic, social and digital divides and reinforcing inequities for marginalized communities. This dynamic challenges the existing interplay between cultural rights and the right to development, and raises questions about the integration of cultural and developmental considerations into emerging AI governance frameworks. To address these challenges, the paper examines the impact of AI on both categories of rights. Conceptually, it analyzes the epistemic and normative limitations of AI with respect to cultural and developmental assumptions embedded in algorithmic design and deployment, but also individual and structural impacts of AI on both rights. On this basis, the paper identifies gaps and tensions in existing AI governance frameworks with respect to cultural rights and the right to development.\n  By situating cultural rights and the right to development within the broader landscape of AI and human rights, this paper contributes to the academic discourse on AI ethics, legal frameworks, and international human rights law. Finally, it outlines avenues for future research and policy development based on existing conversations in global AI governance.",
      "tldr_zh": "æœ¬æ–‡æ¢è®¨äº†äººå·¥æ™ºèƒ½(AI)æ—¶ä»£ä¸‹æ–‡åŒ–æƒåˆ©(Cultural Rights)ä¸å‘å±•æƒ(Right to Development)ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶æ·±å…¥åˆ†æäº†å…¶å¯¹å…¨çƒäººæƒæ²»ç†çš„æ·±è¿œå½±å“ã€‚ç ”ç©¶æŒ‡å‡ºï¼ŒAIç³»ç»Ÿæ­£åœ¨é‡å¡‘æ–‡åŒ–å†…å®¹çš„åˆ›ä½œä¸ä¼ æ’­ï¼Œå½±å“ä¸ªäººå’Œç¤¾åŒºçš„çŸ¥è¯†äº§æƒ(Intellectual Property)ï¼Œå¯¹å…¨çƒèŒƒå›´å†…çš„æ–‡åŒ–å‚ä¸å’Œè¡¨è¾¾æ„æˆæŒ‘æˆ˜ã€‚æ­¤å¤–ï¼ŒAIæŠ€æœ¯çš„æ™®åŠå¯èƒ½åŠ å‰§ç°æœ‰çš„ç»æµã€ç¤¾ä¼šå’Œæ•°å­—é¸¿æ²Ÿï¼Œå¼ºåŒ–é’ˆå¯¹å¼±åŠ¿ç¾¤ä½“çš„ç¤¾ä¼šä¸å¹³ç­‰ï¼Œå¹¶æŒ‘æˆ˜æ–‡åŒ–æƒåˆ©ä¸å‘å±•æƒä¹‹é—´çš„ç°æœ‰äº’åŠ¨ã€‚è®ºæ–‡ä»ç†è®ºå±‚é¢åˆ†æäº†ç®—æ³•è®¾è®¡ä¸éƒ¨ç½²ä¸­åµŒå…¥çš„è®¤è¯†è®º(Epistemic)å’Œè§„èŒƒæ€§å±€é™ï¼Œå¹¶è€ƒå¯Ÿäº†å…¶åœ¨ä¸ªäººåŠç»“æ„å±‚é¢å¯¹ç›¸å…³æƒåˆ©çš„å½±å“ã€‚é€šè¿‡å®¡è§†ç°æœ‰çš„AIæ²»ç†æ¡†æ¶ï¼Œæœ¬æ–‡è¯†åˆ«äº†åœ¨ä¿éšœæ–‡åŒ–æƒåˆ©ä¸å‘å±•æƒæ–¹é¢å­˜åœ¨çš„ç›‘ç®¡æ¼æ´ä¸æ½œåœ¨å†²çªã€‚æœ€åï¼Œç ”ç©¶å°†è¿™äº›æƒåˆ©ç½®äºAIä¸äººæƒçš„å®è§‚æ™¯è§‚ä¸­ï¼Œä¸ºæœªæ¥å…¨çƒAIæ²»ç†çš„å­¦æœ¯è®¨è®ºå’Œæ”¿ç­–åˆ¶å®šæä¾›äº†å…³é”®çš„å‚è€ƒè·¯å¾„ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.15786v1",
      "published_date": "2025-12-15 18:56:36 UTC",
      "updated_date": "2025-12-15 18:56:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:51:51.288686+00:00"
    },
    {
      "arxiv_id": "2512.13658v1",
      "title": "Embedding-Based Rankings of Educational Resources based on Learning Outcome Alignment: Benchmarking, Expert Validation, and Learner Performance",
      "title_zh": "åŸºäºå­¦ä¹ æˆæœå¯¹é½åº¦çš„æ•™è‚²èµ„æºåµŒå…¥å¼æ’åºï¼šåŸºå‡†æµ‹è¯•ã€ä¸“å®¶éªŒè¯ä¸å­¦ä¹ è€…è¡¨ç°",
      "authors": [
        "Mohammadreza Molavi",
        "Mohammad Moein",
        "Mohammadreza Tavakoli",
        "Abdolali Faraji",
        "Stefan T. Mol",
        "GÃ¡bor KismihÃ³k"
      ],
      "abstract": "As the online learning landscape evolves, the need for personalization is increasingly evident. Although educational resources are burgeoning, educators face challenges selecting materials that both align with intended learning outcomes and address diverse learner needs. Large Language Models (LLMs) are attracting growing interest for their potential to create learning resources that better support personalization, but verifying coverage of intended outcomes still requires human alignment review, which is costly and limits scalability. We propose a framework that supports the cost-effective automation of evaluating alignment between educational resources and intended learning outcomes. Using human-generated materials, we benchmarked LLM-based text-embedding models and found that the most accurate model (Voyage) achieved 79% accuracy in detecting alignment. We then applied the optimal model to LLM-generated resources and, via expert evaluation, confirmed that it reliably assessed correspondence to intended outcomes (83% accuracy). Finally, in a three-group experiment with 360 learners, higher alignment scores were positively related to greater learning performance, chi-squared(2, N = 360) = 15.39, p < 0.001. These findings show that embedding-based alignment scores can facilitate scalable personalization by confirming alignment with learning outcomes, which allows teachers to focus on tailoring content to diverse learner needs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åœ¨çº¿å­¦ä¹ ä¸­æ•™è‚²èµ„æºä¸é¢„æœŸå­¦ä¹ æˆæœ(Learning Outcomes)å¯¹é½è¯„ä¼°æˆæœ¬é«˜ä¸”éš¾ä»¥è§„æ¨¡åŒ–çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºåµŒå…¥æ¨¡å‹(Embedding Models)çš„è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶ã€‚ç ”ç©¶é¦–å…ˆå¯¹å¤šç§åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æ–‡æœ¬åµŒå…¥æ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œå‘ç°Voyageæ¨¡å‹åœ¨æ£€æµ‹èµ„æºä¸å­¦ä¹ æˆæœçš„å¯¹é½æ€§æ–¹é¢å‡†ç¡®ç‡æœ€é«˜ï¼Œè¾¾åˆ°79%ã€‚éšåï¼Œç ”ç©¶å°†è¯¥æœ€ä¼˜æ¨¡å‹åº”ç”¨äºå¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„èµ„æºï¼Œå¹¶é€šè¿‡ä¸“å®¶è¯„å®¡éªŒè¯äº†å…¶è¯„ä¼°çš„å¯é æ€§ï¼Œå‡†ç¡®ç‡è¾¾83%ã€‚æ­¤å¤–ï¼Œä¸€é¡¹æ¶‰åŠ360åå­¦ä¹ è€…çš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œèµ„æºå¯¹é½è¯„åˆ†çš„æé«˜ä¸å­¦ä¹ è¡¨ç°(Learning Performance)çš„æå‡å…·æœ‰æ˜¾è‘—çš„æ­£ç›¸å…³æ€§ã€‚è¯¥ç ”ç©¶è¯æ˜äº†åˆ©ç”¨åµŒå…¥æŠ€æœ¯ç”Ÿæˆçš„å¯¹é½è¯„åˆ†èƒ½å¤Ÿå®ç°ä½æˆæœ¬ã€å¯æ‰©å±•çš„ä¸ªæ€§åŒ–å­¦ä¹ æ”¯æŒã€‚è¿™é¡¹æˆæœä¸ä»…éªŒè¯äº†è‡ªåŠ¨åŒ–å¯¹é½è¯„ä¼°çš„å¯è¡Œæ€§ï¼Œè¿˜ä¸ºæ•™å¸ˆæ ¹æ®å­¦ä¹ è€…å¤šæ ·åŒ–éœ€æ±‚é‡èº«å®šåˆ¶æ•™å­¦å†…å®¹æä¾›äº†æœ‰åŠ›å·¥å…·ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted for publication at the 16th International Conference on Learning Analytics & Knowledge (LAK 2026)",
      "pdf_url": "https://arxiv.org/pdf/2512.13658v1",
      "published_date": "2025-12-15 18:51:00 UTC",
      "updated_date": "2025-12-15 18:51:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:51:58.649138+00:00"
    },
    {
      "arxiv_id": "2512.13654v1",
      "title": "Large-Language Memorization During the Classification of United States Supreme Court Cases",
      "title_zh": "ç¾å›½æœ€é«˜æ³•é™¢æ¡ˆä»¶åˆ†ç±»ä¸­çš„å¤§è¯­è¨€æ¨¡å‹è®°å¿†ç ”ç©¶",
      "authors": [
        "John E. Ortega",
        "Dhruv D. Joshi",
        "Matt P. Borkowski"
      ],
      "abstract": "Large-language models (LLMs) have been shown to respond in a variety of ways for classification tasks outside of question-answering. LLM responses are sometimes called \"hallucinations\" since the output is not what is ex pected. Memorization strategies in LLMs are being studied in detail, with the goal of understanding how LLMs respond. We perform a deep dive into a classification task based on United States Supreme Court (SCOTUS) decisions. The SCOTUS corpus is an ideal classification task to study for LLM memory accuracy because it presents significant challenges due to extensive sentence length, complex legal terminology, non-standard structure, and domain-specific vocabulary. Experimentation is performed with the latest LLM fine tuning and retrieval-based approaches, such as parameter-efficient fine-tuning, auto-modeling, and others, on two traditional category-based SCOTUS classification tasks: one with 15 labeled topics and another with 279. We show that prompt-based models with memories, such as DeepSeek, can be more robust than previous BERT-based models on both tasks scoring about 2 points better than previous models not based on prompting.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†ç¾å›½æœ€é«˜æ³•é™¢ï¼ˆSCOTUSï¼‰åˆ¤å†³åˆ†ç±»ä»»åŠ¡ä¸­çš„è®°å¿†ç­–ç•¥ï¼Œæ—¨åœ¨ç†è§£æ¨¡å‹åœ¨é¢å¯¹å¤æ‚åˆ†ç±»ä»»åŠ¡æ—¶çš„å“åº”æœºåˆ¶ã€‚ç”±äºSCOTUSè¯­æ–™åº“å…·æœ‰å¥å­è¿‡é•¿ã€æ³•å¾‹æœ¯è¯­å¤æ‚ã€ç»“æ„éæ ‡å‡†åŠé¢†åŸŸè¯æ±‡å¯†é›†ç­‰ç‰¹ç‚¹ï¼Œä¸ºç ”ç©¶LLMçš„è®°å¿†å‡†ç¡®æ€§æä¾›äº†ç†æƒ³çš„æŒ‘æˆ˜åœºæ™¯ã€‚å®éªŒé‡‡ç”¨äº†å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆParameter-efficient fine-tuningï¼‰ã€è‡ªåŠ¨å»ºæ¨¡ï¼ˆAuto-modelingï¼‰å’ŒåŸºäºæ£€ç´¢çš„å¤šç§å‰æ²¿æ–¹æ³•ï¼Œé’ˆå¯¹15ç±»åŠ279ç±»ä¸»é¢˜çš„åˆ†ç±»ä»»åŠ¡è¿›è¡Œäº†éªŒè¯ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒåƒDeepSeekè¿™æ ·å…·æœ‰è®°å¿†æœºåˆ¶çš„åŸºäºæç¤ºï¼ˆPrompt-basedï¼‰çš„æ¨¡å‹åœ¨ä¸¤é¡¹ä»»åŠ¡ä¸­å‡æ¯”ä¼ ç»Ÿçš„BERTæ¨¡å‹æ›´ä¸ºç¨³å¥ï¼Œå¾—åˆ†æå‡äº†çº¦2åˆ†ã€‚è¯¥å‘ç°è¯æ˜äº†åœ¨å¤„ç†å¤æ‚ä¸“ä¸šé¢†åŸŸçš„æ³•å¾‹æ–‡æœ¬åˆ†ç±»æ—¶ï¼Œå…·å¤‡è®°å¿†èƒ½åŠ›çš„æç¤ºæ¨¡å‹ç›¸è¾ƒäºä¼ ç»Ÿæ¶æ„å…·æœ‰æ›´ä¼˜çš„è¡¨ç°ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 1 figure, Appendix of Prompts",
      "pdf_url": "https://arxiv.org/pdf/2512.13654v1",
      "published_date": "2025-12-15 18:47:48 UTC",
      "updated_date": "2025-12-15 18:47:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:51:40.443911+00:00"
    },
    {
      "arxiv_id": "2512.13644v1",
      "title": "World Models Can Leverage Human Videos for Dexterous Manipulation",
      "title_zh": "ä¸–ç•Œæ¨¡å‹èƒ½å¤Ÿåˆ©ç”¨äººç±»è§†é¢‘å®ç°çµå·§æ“ä½œ",
      "authors": [
        "Raktim Gautam Goswami",
        "Amir Bar",
        "David Fan",
        "Tsung-Yen Yang",
        "Gaoyue Zhou",
        "Prashanth Krishnamurthy",
        "Michael Rabbat",
        "Farshad Khorrami",
        "Yann LeCun"
      ],
      "abstract": "Dexterous manipulation is challenging because it requires understanding how subtle hand motion influences the environment through contact with objects. We introduce DexWM, a Dexterous Manipulation World Model that predicts the next latent state of the environment conditioned on past states and dexterous actions. To overcome the scarcity of dexterous manipulation datasets, DexWM is trained on over 900 hours of human and non-dexterous robot videos. To enable fine-grained dexterity, we find that predicting visual features alone is insufficient; therefore, we introduce an auxiliary hand consistency loss that enforces accurate hand configurations. DexWM outperforms prior world models conditioned on text, navigation, and full-body actions, achieving more accurate predictions of future states. DexWM also demonstrates strong zero-shot generalization to unseen manipulation skills when deployed on a Franka Panda arm equipped with an Allegro gripper, outperforming Diffusion Policy by over 50% on average in grasping, placing, and reaching tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DexWMï¼ˆDexterous Manipulation World Modelï¼‰ï¼Œä¸€ç§æ—¨åœ¨è§£å†³çµå·§æ“ä½œï¼ˆDexterous manipulationï¼‰æŒ‘æˆ˜çš„é¢„æµ‹æ€§ä¸–ç•Œæ¨¡å‹ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿæ ¹æ®è¿‡å»çš„ç³»ç»ŸçŠ¶æ€å’Œçµå·§åŠ¨ä½œé¢„æµ‹ç¯å¢ƒçš„ä¸‹ä¸€ä¸ªæ½œçŠ¶æ€ï¼ˆLatent stateï¼‰ã€‚ä¸ºäº†å…‹æœçµå·§æ“ä½œæ•°æ®é›†ç¨€ç¼ºçš„é—®é¢˜ï¼ŒDexWMåœ¨è¶…è¿‡900å°æ—¶çš„äººç±»å’Œéçµå·§æœºå™¨äººè§†é¢‘ä¸Šè¿›è¡Œäº†å¤§è§„æ¨¡è®­ç»ƒã€‚ç ”ç©¶è€…å‘ç°ä»…é¢„æµ‹è§†è§‰ç‰¹å¾ä¸è¶³ä»¥å®ç°ç²¾ç»†çš„çµå·§æ€§ï¼Œå› æ­¤å¼•å…¥äº†è¾…åŠ©æ‰‹éƒ¨ä¸€è‡´æ€§æŸå¤±ï¼ˆAuxiliary hand consistency lossï¼‰ä»¥ç¡®ä¿å‡†ç¡®çš„æ‰‹éƒ¨æ„å‹ã€‚å®éªŒè¡¨æ˜ï¼ŒDexWMåœ¨é¢„æµ‹å‡†ç¡®æ€§ä¸Šä¼˜äºä»¥å¾€åŸºäºæ–‡æœ¬ã€å¯¼èˆªå’Œå…¨èº«åŠ¨ä½œçš„ä¸–ç•Œæ¨¡å‹ã€‚åœ¨é…å¤‡Allegroæ‰‹çˆªçš„Franka Pandaæœºæ¢°è‡‚ä¸Šçš„éƒ¨ç½²æ˜¾ç¤ºï¼ŒDexWMå…·å¤‡æå¼ºçš„é›¶æ ·æœ¬æ³›åŒ–ï¼ˆZero-shot generalizationï¼‰èƒ½åŠ›ï¼Œåœ¨æŠ“å–ã€æ”¾ç½®å’Œåˆ°è¾¾ä»»åŠ¡ä¸­çš„è¡¨ç°å¹³å‡æ¯”Diffusion Policyé«˜å‡º50%ä»¥ä¸Šã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13644v1",
      "published_date": "2025-12-15 18:37:12 UTC",
      "updated_date": "2025-12-15 18:37:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:51:44.800747+00:00"
    },
    {
      "arxiv_id": "2512.13641v1",
      "title": "From Code to Field: Evaluating the Robustness of Convolutional Neural Networks for Disease Diagnosis in Mango Leaves",
      "title_zh": "ä»ä»£ç åˆ°ç”°é—´ï¼šè¯„ä¼°å·ç§¯ç¥ç»ç½‘ç»œåœ¨èŠ’æœå¶ç‰‡ç—…å®³è¯Šæ–­ä¸­çš„é²æ£’æ€§",
      "authors": [
        "Gabriel Vitorino de Andrade",
        "Saulo Roberto dos Santos",
        "Itallo Patrick Castro Alves da Silva",
        "Emanuel Adler Medeiros Pereira",
        "Erick de Andrade Barboza"
      ],
      "abstract": "The validation and verification of artificial intelligence (AI) models through robustness assessment are essential to guarantee the reliable performance of intelligent systems facing real-world challenges, such as image corruptions including noise, blurring, and weather variations. Despite the global importance of mango (Mangifera indica L.), there is a lack of studies on the robustness of models for the diagnosis of disease in its leaves. This paper proposes a methodology to evaluate convolutional neural networks (CNNs) under adverse conditions. We adapted the MangoLeafDB dataset, generating MangoLeafDB-C with 19 types of artificial corruptions at five severity levels. We conducted a benchmark comparing five architectures: ResNet-50, ResNet-101, VGG-16, Xception, and LCNN (the latter being a lightweight architecture designed specifically for mango leaf diagnosis). The metrics include the F1 score, the corruption error (CE) and the relative mean corruption error (relative mCE). The results show that LCNN outperformed complex models in corruptions that can be present in real-world scenarios such as Defocus Blur, Motion Blur, while also achieving the lowest mCE. Modern architectures (e.g., ResNet-101) exhibited significant performance degradation in corrupted scenarios, despite their high accuracy under ideal conditions. These findings suggest that lightweight and specialized models may be more suitable for real-world applications in edge devices, where robustness and efficiency are critical. The study highlights the need to incorporate robustness assessments in the development of intelligent systems for agriculture, particularly in regions with technological limitations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹èŠ’æœå¶éƒ¨ç–¾ç—…è¯Šæ–­æ¨¡å‹åœ¨ç°å®ç¯å¢ƒä¸‹çš„é²æ£’æ€§è¯„ä¼°ä¸è¶³é—®é¢˜ï¼Œæå‡ºäº†ä¸€å¥—è¯„ä¼°å·ç§¯ç¥ç»ç½‘ç»œ(CNNs)åœ¨ä¸åˆ©æ¡ä»¶ä¸‹è¡¨ç°çš„æ–¹æ³•è®ºã€‚ç ”ç©¶äººå‘˜é€šè¿‡æ”¹è¿› MangoLeafDB æ•°æ®é›†ï¼Œç”Ÿæˆäº†åŒ…å« 19 ç§äººå·¥å¹²æ‰°å’Œ 5 ä¸ªä¸¥é‡ç¨‹åº¦ç­‰çº§çš„ MangoLeafDB-C æ•°æ®é›†ï¼Œå¹¶å¯¹æ¯”äº† ResNet-50ã€ResNet-101ã€VGG-16ã€Xception ä»¥åŠè½»é‡çº§æ¶æ„ LCNN çš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLCNN åœ¨å¤„ç†ç°å®åœºæ™¯ä¸­å¸¸è§çš„ç¦»ç„¦æ¨¡ç³Š(Defocus Blur)å’Œè¿åŠ¨æ¨¡ç³Š(Motion Blur)æ–¹é¢ä¼˜äºå¤æ‚æ¨¡å‹ï¼Œå¹¶å®ç°äº†æœ€ä½çš„å¹³å‡å¹²æ‰°è¯¯å·®(mCE)ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒResNet-101 ç­‰ç°ä»£æ¶æ„è™½ç„¶åœ¨ç†æƒ³æ¡ä»¶ä¸‹å‡†ç¡®ç‡æé«˜ï¼Œä½†åœ¨å¹²æ‰°åœºæ™¯ä¸‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œåœ¨é²æ£’æ€§å’Œæ•ˆç‡è‡³å…³é‡è¦çš„å†œä¸šè¾¹ç¼˜è®¾å¤‡åº”ç”¨ä¸­ï¼Œè½»é‡çº§ä¸“ä¸šåŒ–æ¨¡å‹æ¯”å¤æ‚æ¨¡å‹æ›´å…·ä¼˜åŠ¿ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†åœ¨å†œä¸šæ™ºèƒ½ç³»ç»Ÿå¼€å‘ä¸­çº³å…¥é²æ£’æ€§è¯„ä¼°çš„å¿…è¦æ€§ï¼Œä¸ºåœ¨æŠ€æœ¯å—é™åœ°åŒºéƒ¨ç½²å¯é çš„å†œä¸šAIæ¨¡å‹æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "This work was presented at the BRACIS 2025 conference in Fortaleza",
      "pdf_url": "https://arxiv.org/pdf/2512.13641v1",
      "published_date": "2025-12-15 18:36:48 UTC",
      "updated_date": "2025-12-15 18:36:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:52:30.196417+00:00"
    },
    {
      "arxiv_id": "2512.13771v1",
      "title": "Semantic Grounding Index: Geometric Bounds on Context Engagement in RAG Systems",
      "title_zh": "è¯­ä¹‰æ‰æ ¹ç´¢å¼•ï¼šRAG ç³»ç»Ÿä¸­ä¸Šä¸‹æ–‡å‚ä¸åº¦çš„å‡ ä½•è¾¹ç•Œ",
      "authors": [
        "Javier MarÃ­n"
      ],
      "abstract": "When retrieval-augmented generation (RAG) systems hallucinate, what geometric trace does this leave in embedding space? We introduce the Semantic Grounding Index (SGI), defined as the ratio of angular distances from the response to the question versus the context on the unit hypersphere $\\mathbb{S}^{d-1}$.Our central finding is \\emph{semantic laziness}: hallucinated responses remain angularly proximate to questions rather than departing toward retrieved contexts. On HaluEval ($n$=5,000), we observe large effect sizes (Cohen's $d$ ranging from 0.92 to 1.28) across five embedding models with mean cross-model correlation $r$=0.85. Crucially, we derive from the spherical triangle inequality that SGI's discriminative power should increase with question-context angular separation $Î¸(q,c)$-a theoretical prediction confirmed empirically: effect size rises monotonically from $d$=0.61 -low $Î¸(q,c)$, to $d$=1.27 -high $Î¸(q,c)$, with AUC improving from 0.72 to 0.83. Subgroup analysis reveals that SGI excels on long responses ($d$=2.05) and short questions ($d$=1.22), while remaining robust across context lengths. Calibration analysis yields ECE=0.10, indicating SGI scores can serve as probability estimates, not merely rankings. A critical negative result on TruthfulQA (AUC=0.478) establishes that angular geometry measures topical engagement rather than factual accuracy. SGI provides computationally efficient, theoretically grounded infrastructure for identifying responses that warrant verification in production RAG deployments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ç³»ç»Ÿä¸­å¹»è§‰ç°è±¡åœ¨åµŒå…¥ç©ºé—´ (embedding space) ä¸­çš„å‡ ä½•ç‰¹å¾ï¼Œå¹¶æå‡ºäº†è¯­ä¹‰è½åœ°æŒ‡æ ‡ (Semantic Grounding Index, SGI)ã€‚SGI è¢«å®šä¹‰ä¸ºå“åº”åˆ°é—®é¢˜ä¸å“åº”åˆ°ä¸Šä¸‹æ–‡åœ¨å•ä½è¶…çƒä½“ ($\\mathbb{S}^{d-1}$) ä¸Šçš„è§’è·ç¦»ä¹‹æ¯”ã€‚ç ”ç©¶å‘ç°äº†ä¸€ç§è¢«ç§°ä¸ºâ€œè¯­ä¹‰æ‡’æƒ°â€ (semantic laziness) çš„ç°è±¡ï¼Œå³äº§ç”Ÿå¹»è§‰çš„å“åº”åœ¨è§’åº¦ä¸Šé€šå¸¸æ›´æ¥è¿‘é—®é¢˜ï¼Œè€Œéæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ã€‚é€šè¿‡åŸºäºçƒé¢ä¸‰è§’å½¢ä¸ç­‰å¼ (spherical triangle inequality) çš„ç†è®ºæ¨å¯¼å’Œåœ¨ HaluEval æ•°æ®é›†ä¸Šçš„å®éªŒï¼Œç ”ç©¶è¯å®äº† SGI çš„åˆ¤åˆ«èƒ½åŠ›éšé—®é¢˜ä¸ä¸Šä¸‹æ–‡çš„è§’åˆ†ç¦»åº¦å¢åŠ è€Œå•è°ƒä¸Šå‡ã€‚åˆ†ææ˜¾ç¤º SGI åœ¨å¤„ç†é•¿å“åº”å’ŒçŸ­é—®é¢˜æ—¶è¡¨ç°ä¼˜å¼‚ï¼Œä¸”å…¶æ ¡å‡†åçš„åˆ†å€¼å¯ç”¨äºä¼°è®¡å“åº”çš„å¯é æ¦‚ç‡ã€‚å°½ç®¡ TruthfulQA çš„å®éªŒç»“æœè¡¨æ˜è¯¥æŒ‡æ ‡ä¸»è¦è¡¡é‡çš„æ˜¯ä¸»é¢˜å‚ä¸åº¦è€Œéäº‹å®å‡†ç¡®æ€§ï¼Œä½† SGI ä¸ºç”Ÿäº§ç¯å¢ƒä¸‹ RAG ç³»ç»Ÿå“åº”çš„éªŒè¯æä¾›äº†ä¸€ç§è®¡ç®—é«˜æ•ˆä¸”å…·å¤‡ç†è®ºåŸºç¡€çš„ç›‘æ§æ‰‹æ®µã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13771v1",
      "published_date": "2025-12-15 18:09:54 UTC",
      "updated_date": "2025-12-15 18:09:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:52:16.699531+00:00"
    },
    {
      "arxiv_id": "2512.13607v1",
      "title": "Nemotron-Cascade: Scaling Cascaded Reinforcement Learning for General-Purpose Reasoning Models",
      "title_zh": "Nemotron-Cascadeï¼šé¢å‘é€šç”¨æ¨ç†æ¨¡å‹çš„çº§è”å¼ºåŒ–å­¦ä¹ æ‰©å±•",
      "authors": [
        "Boxin Wang",
        "Chankyu Lee",
        "Nayeon Lee",
        "Sheng-Chieh Lin",
        "Wenliang Dai",
        "Yang Chen",
        "Yangyi Chen",
        "Zhuolin Yang",
        "Zihan Liu",
        "Mohammad Shoeybi",
        "Bryan Catanzaro",
        "Wei Ping"
      ],
      "abstract": "Building general-purpose reasoning models with reinforcement learning (RL) entails substantial cross-domain heterogeneity, including large variation in inference-time response lengths and verification latency. Such variability complicates the RL infrastructure, slows training, and makes training curriculum (e.g., response length extension) and hyperparameter selection challenging. In this work, we propose cascaded domain-wise reinforcement learning (Cascade RL) to develop general-purpose reasoning models, Nemotron-Cascade, capable of operating in both instruct and deep thinking modes. Departing from conventional approaches that blend heterogeneous prompts from different domains, Cascade RL orchestrates sequential, domain-wise RL, reducing engineering complexity and delivering state-of-the-art performance across a wide range of benchmarks. Notably, RLHF for alignment, when used as a pre-step, boosts the model's reasoning ability far beyond mere preference optimization, and subsequent domain-wise RLVR stages rarely degrade the benchmark performance attained in earlier domains and may even improve it (see an illustration in Figure 1). Our 14B model, after RL, outperforms its SFT teacher, DeepSeek-R1-0528, on LiveCodeBench v5/v6/Pro and achieves silver-medal performance in the 2025 International Olympiad in Informatics (IOI). We transparently share our training and data recipes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Nemotron-Cascadeï¼Œä¸€ç§é€šè¿‡çº§è”é¢†åŸŸå¼ºåŒ–å­¦ä¹  (Cascade RL) æ„å»ºçš„é€šç”¨æ¨ç†æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³å¼ºåŒ–å­¦ä¹ åœ¨åº”å¯¹è·¨é¢†åŸŸå¼‚æ„æ€§æ—¶é¢ä¸´çš„å“åº”é•¿åº¦æ³¢åŠ¨åŠéªŒè¯å»¶è¿Ÿç­‰å¤æ‚å·¥ç¨‹é—®é¢˜ã€‚Cascade RL é‡‡ç”¨é¡ºåºè¿›è¡Œçš„é¢†åŸŸçº§ (domain-wise) å¼ºåŒ–å­¦ä¹ ç­–ç•¥å–ä»£äº†ä¼ ç»Ÿçš„æ··åˆæç¤ºè¯è®­ç»ƒæ–¹å¼ï¼Œåœ¨é™ä½å¼€å‘å¤æ‚æ€§çš„åŒæ—¶å®ç°äº†åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„ SOTA æ€§èƒ½ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå°†åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹  (RLHF) ä½œä¸ºå¯¹é½é¢„æ­¥ä¸ä»…èƒ½ä¼˜åŒ–åå¥½ï¼Œè¿˜èƒ½æ˜¾è‘—å¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä¸”åç»­é˜¶æ®µçš„å¼ºåŒ–å­¦ä¹ éªŒè¯ (RLVR) èƒ½å¤ŸæŒç»­æ”¹è¿›æˆ–ç»´æŒå…ˆå‰é¢†åŸŸçš„æ€§èƒ½ã€‚å®éªŒè¯æ˜ï¼Œ14B è§„æ¨¡çš„ Nemotron-Cascade æ¨¡å‹åœ¨ LiveCodeBench å¤šä¸ªç‰ˆæœ¬ä¸Šå‡ä¼˜äºå…¶æ•™å¸ˆæ¨¡å‹ DeepSeek-R1-0528ï¼Œå¹¶æˆåŠŸåœ¨ 2025 å¹´å›½é™…ä¿¡æ¯å­¦å¥¥æ—åŒ¹å…‹ç«èµ› (IOI) ä¸­è¾¾åˆ°é“¶ç‰Œæ°´å¹³ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "We publicly release the Nemotron-Cascade models and the full collection of training data at: https://huggingface.co/collections/nvidia/nemotron-cascade",
      "pdf_url": "https://arxiv.org/pdf/2512.13607v1",
      "published_date": "2025-12-15 18:02:35 UTC",
      "updated_date": "2025-12-15 18:02:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:52:36.057242+00:00"
    },
    {
      "arxiv_id": "2512.13600v1",
      "title": "DA-SSL: self-supervised domain adaptor to leverage foundational models in turbt histopathology slides",
      "title_zh": "DA-SSLï¼šç”¨äºåœ¨ TURBT ç»„ç»‡ç—…ç†åˆ‡ç‰‡ä¸­åˆ©ç”¨åŸºç¡€æ¨¡å‹çš„è‡ªç›‘ç£é¢†åŸŸé€‚é…å™¨",
      "authors": [
        "Haoyue Zhang",
        "Meera Chappidi",
        "Erolcan Sayar",
        "Helen Richards",
        "Zhijun Chen",
        "Lucas Liu",
        "Roxanne Wadia",
        "Peter A Humphrey",
        "Fady Ghali",
        "Alberto Contreras-Sanz",
        "Peter Black",
        "Jonathan Wright",
        "Stephanie Harmon",
        "Michael Haffner"
      ],
      "abstract": "Recent deep learning frameworks in histopathology, particularly multiple instance learning (MIL) combined with pathology foundational models (PFMs), have shown strong performance. However, PFMs exhibit limitations on certain cancer or specimen types due to domain shifts - these cancer types were rarely used for pretraining or specimens contain tissue-based artifacts rarely seen within the pretraining population. Such is the case for transurethral resection of bladder tumor (TURBT), which are essential for diagnosing muscle-invasive bladder cancer (MIBC), but contain fragmented tissue chips and electrocautery artifacts and were not widely used in publicly available PFMs. To address this, we propose a simple yet effective domain-adaptive self-supervised adaptor (DA-SSL) that realigns pretrained PFM features to the TURBT domain without fine-tuning the foundational model itself. We pilot this framework for predicting treatment response in TURBT, where histomorphological features are currently underutilized and identifying patients who will benefit from neoadjuvant chemotherapy (NAC) is challenging. In our multi-center study, DA-SSL achieved an AUC of 0.77+/-0.04 in five-fold cross-validation and an external test accuracy of 0.84, sensitivity of 0.71, and specificity of 0.91 using majority voting. Our results demonstrate that lightweight domain adaptation with self-supervision can effectively enhance PFM-based MIL pipelines for clinically challenging histopathology tasks. Code is Available at https://github.com/zhanghaoyue/DA_SSL_TURBT.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç—…ç†åŸºç¡€æ¨¡å‹ (Pathology Foundational Models, PFMs) åœ¨ç»å°¿é“è†€èƒ±è‚¿ç˜¤ç”µåˆ‡æœ¯ (TURBT) ç»„ç»‡ç—…ç†å­¦åˆ‡ç‰‡ä¸­å› é¢†åŸŸåç§» (domain shifts) å’Œç”µç¼ä¼ªå½±å¯¼è‡´çš„æ€§èƒ½å—é™é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§è‡ªç›‘ç£é¢†åŸŸé€‚é…å™¨ DA-SSLã€‚è¯¥é€‚é…å™¨èƒ½å¤Ÿåœ¨ä¸å¾®è°ƒåŸºç¡€æ¨¡å‹æœ¬èº«çš„æƒ…å†µä¸‹ï¼Œå°†é¢„è®­ç»ƒçš„ PFMs ç‰¹å¾é‡æ–°å¯¹é½åˆ° TURBT é¢†åŸŸï¼Œæœ‰æ•ˆå¤„ç†å¤æ‚çš„ç»„ç»‡èŠ¯ç‰‡å’Œä¼ªå½±å¹²æ‰°ã€‚ç ”ç©¶å°†è¯¥æ¡†æ¶åº”ç”¨äºé¢„æµ‹æ–°è¾…åŠ©åŒ–ç–— (NAC) çš„æ²»ç–—ååº”ï¼Œå¡«è¡¥äº†ç»„ç»‡å½¢æ€å­¦ç‰¹å¾åœ¨è¿™ä¸€æŒ‘æˆ˜æ€§ä¸´åºŠä»»åŠ¡ä¸­åˆ©ç”¨ä¸è¶³çš„ç©ºç™½ã€‚å¤šä¸­å¿ƒå®éªŒç»“æœæ˜¾ç¤ºï¼ŒDA-SSL åœ¨äº”æŠ˜äº¤å‰éªŒè¯ä¸­è¾¾åˆ° 0.77 çš„ AUCï¼Œå¹¶åœ¨å¤–éƒ¨æµ‹è¯•é›†ä¸­å®ç°äº† 0.84 çš„å‡†ç¡®ç‡ä¸ 0.91 çš„ç‰¹å¼‚æ€§ã€‚è¿™è¡¨æ˜é€šè¿‡è‡ªç›‘ç£è¿›è¡Œçš„è½»é‡åŒ–é¢†åŸŸé€‚é…èƒ½å¤Ÿæ˜¾è‘—å¢å¼ºåŸºäº PFMs çš„å¤šå®ä¾‹å­¦ä¹  (MIL) æµæ°´çº¿ï¼Œä¸ºè§£å†³ä¸´åºŠæŒ‘æˆ˜æ€§çš„ç»„ç»‡ç—…ç†å­¦ä»»åŠ¡æä¾›äº†é«˜æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13600v1",
      "published_date": "2025-12-15 17:53:18 UTC",
      "updated_date": "2025-12-15 17:53:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:53:28.232229+00:00"
    },
    {
      "arxiv_id": "2512.13586v1",
      "title": "ReFusion: A Diffusion Large Language Model with Parallel Autoregressive Decoding",
      "title_zh": "ReFusionï¼šé‡‡ç”¨å¹¶è¡Œè‡ªå›å½’è§£ç çš„æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Jia-Nan Li",
        "Jian Guan",
        "Wei Wu",
        "Chongxuan Li"
      ],
      "abstract": "Autoregressive models (ARMs) are hindered by slow sequential inference. While masked diffusion models (MDMs) offer a parallel alternative, they suffer from critical drawbacks: high computational overhead from precluding Key-Value (KV) caching, and incoherent generation arising from learning dependencies over an intractable space of token combinations. To address these limitations, we introduce ReFusion, a novel masked diffusion model that achieves superior performance and efficiency by elevating parallel decoding from the token level to a higher slot level, where each slot is a fixed-length, contiguous sub-sequence. This is achieved through an iterative ``plan-and-infill'' decoding process: a diffusion-based planning step first identifies a set of weakly dependent slots, and an autoregressive infilling step then decodes these selected slots in parallel. The slot-based design simultaneously unlocks full KV cache reuse with a unified causal framework and reduces the learning complexity from the token combination space to a manageable slot-level permutation space. Extensive experiments on seven diverse benchmarks show that ReFusion not only overwhelmingly surpasses prior MDMs with 34% performance gains and an over 18$\\times$ speedup on average, but also bridges the performance gap to strong ARMs while maintaining a 2.33$\\times$ average speedup.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªå›å½’æ¨¡å‹(ARMs)æ¨ç†é€Ÿåº¦æ…¢ä»¥åŠæ©ç æ‰©æ•£æ¨¡å‹(MDMs)åœ¨è®¡ç®—å¼€é”€å’Œç”Ÿæˆè¿è´¯æ€§æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†ReFusionã€‚ReFusion æ˜¯ä¸€ç§æ–°å‹æ©ç æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡å°†å¹¶è¡Œè§£ç ä»æ ‡è®°çº§åˆ«(token level)æå‡åˆ°æ›´é•¿åºåˆ—çš„æ’æ§½çº§åˆ«(slot level)ï¼Œå®ç°äº†æ€§èƒ½ä¸æ•ˆç‡çš„æ˜¾è‘—æå‡ã€‚è¯¥æ¨¡å‹é‡‡ç”¨äº†ä¸€ç§è¿­ä»£çš„â€œè®¡åˆ’ä¸å¡«å……â€(plan-and-infill)è§£ç è¿‡ç¨‹ï¼Œé¦–å…ˆåˆ©ç”¨åŸºäºæ‰©æ•£çš„è®¡åˆ’æ­¥éª¤è¯†åˆ«ä¸€ç»„å¼±ä¾èµ–æ’æ§½ï¼Œéšåé€šè¿‡è‡ªå›å½’å¡«å……æ­¥éª¤å¹¶è¡Œè§£ç è¿™äº›æ’æ§½ã€‚è¿™ç§åŸºäºæ’æ§½çš„è®¾è®¡åœ¨ç»Ÿä¸€çš„å› æœæ¡†æ¶ä¸‹å®ç°äº†é”®å€¼ç¼“å­˜(KV caching)çš„å®Œå…¨å¤ç”¨ï¼Œå¹¶å°†å­¦ä¹ å¤æ‚åº¦ä»å¤æ‚çš„æ ‡è®°ç»„åˆç©ºé—´é™ä½åˆ°å¯æ§çš„æ’æ§½çº§æ’åˆ—ç©ºé—´ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒReFusion åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ¯”ä¹‹å‰çš„æ©ç æ‰©æ•£æ¨¡å‹æ€§èƒ½æå‡äº†34%ä¸”å¹³å‡åŠ é€Ÿè¶…è¿‡18å€ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨ä¿æŒç”Ÿæˆè´¨é‡ã€ç¼©å°ä¸å¼ºè‡ªå›å½’æ¨¡å‹æ€§èƒ½å·®è·çš„åŒæ—¶ï¼Œå®ç°äº†å¹³å‡2.33å€çš„æ¨ç†åŠ é€Ÿã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13586v1",
      "published_date": "2025-12-15 17:41:19 UTC",
      "updated_date": "2025-12-15 17:41:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:53:18.109755+00:00"
    },
    {
      "arxiv_id": "2512.13583v1",
      "title": "DP-CSGP: Differentially Private Stochastic Gradient Push with Compressed Communication",
      "title_zh": "DP-CSGPï¼šåŸºäºå‹ç¼©é€šä¿¡çš„å·®åˆ†éšç§éšæœºæ¢¯åº¦æ¨é€",
      "authors": [
        "Zehan Zhu",
        "Heng Zhao",
        "Yan Huang",
        "Joey Tianyi Zhou",
        "Shouling Ji",
        "Jinming Xu"
      ],
      "abstract": "In this paper, we propose a Differentially Private Stochastic Gradient Push with Compressed communication (termed DP-CSGP) for decentralized learning over directed graphs. Different from existing works, the proposed algorithm is designed to maintain high model utility while ensuring both rigorous differential privacy (DP) guarantees and efficient communication. For general non-convex and smooth objective functions, we show that the proposed algorithm achieves a tight utility bound of $\\mathcal{O}\\left( \\sqrt{d\\log \\left( \\frac{1}Î´ \\right)}/(\\sqrt{n}JÎµ) \\right)$ ($J$ and $d$ are the number of local samples and the dimension of decision variables, respectively) with $\\left(Îµ, Î´\\right)$-DP guarantee for each node, matching that of decentralized counterparts with exact communication. Extensive experiments on benchmark tasks show that, under the same privacy budget, DP-CSGP achieves comparable model accuracy with significantly lower communication cost than existing decentralized counterparts with exact communication.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DP-CSGPï¼Œä¸€ç§é’ˆå¯¹æœ‰å‘å›¾å»ä¸­å¿ƒåŒ–å­¦ä¹ (decentralized learning)è®¾è®¡çš„å…·æœ‰é€šä¿¡å‹ç¼©(Compressed communication)åŠŸèƒ½çš„å·®åˆ†éšç§éšæœºæ¢¯åº¦æ¨é€ç®—æ³•ã€‚è¯¥ç®—æ³•æ—¨åœ¨ç¡®ä¿ä¸¥æ ¼çš„å·®åˆ†éšç§(Differential Privacy, DP)ä¿è¯çš„åŒæ—¶ï¼Œé€šè¿‡å‹ç¼©æŠ€æœ¯æå‡é€šä¿¡æ•ˆç‡å¹¶ç»´æŒé«˜æ¨¡å‹æ•ˆç”¨(model utility)ã€‚é’ˆå¯¹ä¸€èˆ¬çš„éå‡¸å¹³æ»‘ç›®æ ‡å‡½æ•°ï¼Œç†è®ºè¯æ˜è¯¥ç®—æ³•åœ¨æ»¡è¶³å„èŠ‚ç‚¹$(\\epsilon, \\delta)$-DPçš„å‰æä¸‹ï¼Œèƒ½å¤Ÿè¾¾åˆ°ä¸é‡‡ç”¨ç²¾ç¡®é€šä¿¡çš„å»ä¸­å¿ƒåŒ–ç®—æ³•ç›¸åŒ¹é…çš„æ”¶æ•›ç•Œé™ã€‚åœ¨åŸºå‡†ä»»åŠ¡ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œåœ¨ç›¸åŒçš„éšç§é¢„ç®—ä¸‹ï¼ŒDP-CSGPåœ¨ä¿æŒä¸ç°æœ‰å»ä¸­å¿ƒåŒ–ç®—æ³•ç›¸å½“çš„æ¨¡å‹å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†é€šä¿¡æˆæœ¬ã€‚è¯¥ç ”ç©¶ä¸ºåœ¨å—é™é€šä¿¡å¸¦å®½ä¸‹å®ç°é«˜ç²¾åº¦ã€å¼ºéšç§ä¿æŠ¤çš„å»ä¸­å¿ƒåŒ–æœºå™¨å­¦ä¹ æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages",
      "pdf_url": "https://arxiv.org/pdf/2512.13583v1",
      "published_date": "2025-12-15 17:37:02 UTC",
      "updated_date": "2025-12-15 17:37:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:53:04.242130+00:00"
    },
    {
      "arxiv_id": "2512.13568v1",
      "title": "Superposition as Lossy Compression: Measure with Sparse Autoencoders and Connect to Adversarial Vulnerability",
      "title_zh": "å åŠ å³æœ‰æŸå‹ç¼©ï¼šåŸºäºç¨€ç–è‡ªç¼–ç å™¨çš„åº¦é‡åŠå…¶ä¸å¯¹æŠ—è„†å¼±æ€§çš„å…³è”",
      "authors": [
        "Leonard Bereska",
        "Zoe Tzifa-Kratira",
        "Reza Samavi",
        "Efstratios Gavves"
      ],
      "abstract": "Neural networks achieve remarkable performance through superposition: encoding multiple features as overlapping directions in activation space rather than dedicating individual neurons to each feature. This challenges interpretability, yet we lack principled methods to measure superposition. We present an information-theoretic framework measuring a neural representation's effective degrees of freedom. We apply Shannon entropy to sparse autoencoder activations to compute the number of effective features as the minimum neurons needed for interference-free encoding. Equivalently, this measures how many \"virtual neurons\" the network simulates through superposition. When networks encode more effective features than actual neurons, they must accept interference as the price of compression. Our metric strongly correlates with ground truth in toy models, detects minimal superposition in algorithmic tasks, and reveals systematic reduction under dropout. Layer-wise patterns mirror intrinsic dimensionality studies on Pythia-70M. The metric also captures developmental dynamics, detecting sharp feature consolidation during grokking. Surprisingly, adversarial training can increase effective features while improving robustness, contradicting the hypothesis that superposition causes vulnerability. Instead, the effect depends on task complexity and network capacity: simple tasks with ample capacity allow feature expansion (abundance regime), while complex tasks or limited capacity force reduction (scarcity regime). By defining superposition as lossy compression, this work enables principled measurement of how neural networks organize information under computational constraints, connecting superposition to adversarial robustness.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªä¿¡æ¯è®ºæ¡†æ¶ï¼Œå°†ç¥ç»ç½‘ç»œä¸­çš„å åŠ ç°è±¡ (Superposition) è§†ä¸ºä¸€ç§æœ‰æŸå‹ç¼©è¿‡ç¨‹ï¼Œå¹¶åˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨ (Sparse Autoencoders) æ¿€æ´»çš„é¦™å†œç†µæ¥è¡¡é‡è¡¨ç¤ºçš„æœ‰æ•ˆè‡ªç”±åº¦ã€‚è¯¥æŒ‡æ ‡é€šè¿‡è®¡ç®—ç½‘ç»œé€šè¿‡å åŠ æ¨¡æ‹Ÿå‡ºçš„â€œè™šæ‹Ÿç¥ç»å…ƒâ€æ•°é‡ï¼Œé‡åŒ–äº†åœ¨æœ‰é™ç‰©ç†ç¥ç»å…ƒä¸­ç¼–ç çš„æœ‰æ•ˆç‰¹å¾æ€»æ•°ï¼Œæ­ç¤ºäº†å¹²æ‰°æ˜¯å®ç°å‹ç¼©çš„å¿…ç„¶ä»£ä»·ã€‚å®éªŒè¡¨æ˜è¯¥åº¦é‡ä¸ç©å…·æ¨¡å‹çš„çœŸå®æƒ…å†µé«˜åº¦ç›¸å…³ï¼Œèƒ½æœ‰æ•ˆæ£€æµ‹ Dropout å¯¹å åŠ çš„æŠ‘åˆ¶ï¼Œå¹¶æ•æ‰åˆ°æ¨¡å‹åœ¨é¡¿æ‚Ÿ (Grokking) æœŸé—´ç‰¹å¾å·©å›ºçš„åŠ¨æ€è¿‡ç¨‹ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼Œå¯¹æŠ—è®­ç»ƒ (Adversarial Training) å¯ä»¥åœ¨æå‡é²æ£’æ€§çš„åŒæ—¶å¢åŠ æœ‰æ•ˆç‰¹å¾ï¼Œè¿™åé©³äº†å åŠ å¿…ç„¶å¯¼è‡´è„†å¼±æ€§çš„å‡è®¾ã€‚æœ€ç»ˆï¼Œè¯¥å·¥ä½œé€šè¿‡å°†å åŠ å®šä¹‰ä¸ºæœ‰æŸå‹ç¼©ï¼Œä¸ºç†è§£ç¥ç»è¡¨ç¤ºåœ¨è®¡ç®—çº¦æŸä¸‹å¦‚ä½•ç»„ç»‡ä¿¡æ¯æä¾›äº†åŸåˆ™æ€§çš„æµ‹é‡æ‰‹æ®µï¼Œå¹¶å»ºç«‹äº†å åŠ ä¸å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness) ä¹‹é—´çš„æ·±åˆ»è”ç³»ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to TMLR, view HTML here: https://leonardbereska.github.io/blog/2025/superposition/",
      "pdf_url": "https://arxiv.org/pdf/2512.13568v1",
      "published_date": "2025-12-15 17:25:39 UTC",
      "updated_date": "2025-12-15 17:25:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:53:14.646690+00:00"
    },
    {
      "arxiv_id": "2512.13564v2",
      "title": "Memory in the Age of AI Agents",
      "title_zh": "AI æ™ºèƒ½ä½“æ—¶ä»£çš„è®°å¿†",
      "authors": [
        "Yuyang Hu",
        "Shichun Liu",
        "Yanwei Yue",
        "Guibin Zhang",
        "Boyang Liu",
        "Fangyi Zhu",
        "Jiahang Lin",
        "Honglin Guo",
        "Shihan Dou",
        "Zhiheng Xi",
        "Senjie Jin",
        "Jiejun Tan",
        "Yanbin Yin",
        "Jiongnan Liu",
        "Zeyu Zhang",
        "Zhongxiang Sun",
        "Yutao Zhu",
        "Hao Sun",
        "Boci Peng",
        "Zhenrong Cheng",
        "Xuanbo Fan",
        "Jiaxin Guo",
        "Xinlei Yu",
        "Zhenhong Zhou",
        "Zewen Hu",
        "Jiahao Huo",
        "Junhao Wang",
        "Yuwei Niu",
        "Yu Wang",
        "Zhenfei Yin",
        "Xiaobin Hu",
        "Yue Liao",
        "Qiankun Li",
        "Kun Wang",
        "Wangchunshu Zhou",
        "Yixin Liu",
        "Dawei Cheng",
        "Qi Zhang",
        "Tao Gui",
        "Shirui Pan",
        "Yan Zhang",
        "Philip Torr",
        "Zhicheng Dou",
        "Ji-Rong Wen",
        "Xuanjing Huang",
        "Yu-Gang Jiang",
        "Shuicheng Yan"
      ],
      "abstract": "Memory has emerged, and will continue to remain, a core capability of foundation model-based agents. As research on agent memory rapidly expands and attracts unprecedented attention, the field has also become increasingly fragmented. Existing works that fall under the umbrella of agent memory often differ substantially in their motivations, implementations, and evaluation protocols, while the proliferation of loosely defined memory terminologies has further obscured conceptual clarity. Traditional taxonomies such as long/short-term memory have proven insufficient to capture the diversity of contemporary agent memory systems. This work aims to provide an up-to-date landscape of current agent memory research. We begin by clearly delineating the scope of agent memory and distinguishing it from related concepts such as LLM memory, retrieval augmented generation (RAG), and context engineering. We then examine agent memory through the unified lenses of forms, functions, and dynamics. From the perspective of forms, we identify three dominant realizations of agent memory, namely token-level, parametric, and latent memory. From the perspective of functions, we propose a finer-grained taxonomy that distinguishes factual, experiential, and working memory. From the perspective of dynamics, we analyze how memory is formed, evolved, and retrieved over time. To support practical development, we compile a comprehensive summary of memory benchmarks and open-source frameworks. Beyond consolidation, we articulate a forward-looking perspective on emerging research frontiers, including memory automation, reinforcement learning integration, multimodal memory, multi-agent memory, and trustworthiness issues. We hope this survey serves not only as a reference for existing work, but also as a conceptual foundation for rethinking memory as a first-class primitive in the design of future agentic intelligence.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§æ¨¡å‹çš„æ™ºèƒ½ä½“è®°å¿†æœºåˆ¶è¿›è¡Œäº†ç³»ç»Ÿæ€§ç»¼è¿°ï¼Œå¼ºè°ƒäº†è®°å¿†åœ¨æ™ºèƒ½ä½“æ¶æ„ä¸­çš„æ ¸å¿ƒåœ°ä½å¹¶å˜æ¸…äº†è¯¥é¢†åŸŸçš„ç¢ç‰‡åŒ–ç°çŠ¶ã€‚æœ¬æ–‡æ˜ç¡®ç•Œå®šäº†æ™ºèƒ½ä½“è®°å¿†çš„èŒƒç•´ï¼Œå°†å…¶ä¸ LLM memoryã€æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ä»¥åŠä¸Šä¸‹æ–‡å·¥ç¨‹ (context engineering) ç­‰ç›¸å…³æ¦‚å¿µè¿›è¡Œäº†åŒºåˆ†ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªç”±å½¢å¼ã€åŠŸèƒ½å’ŒåŠ¨æ€ç»„æˆçš„ç»Ÿä¸€åˆ†ææ¡†æ¶ï¼Œè¯†åˆ«äº† token-levelã€parametric å’Œ latent memory ä¸‰ç§ä¸»è¦å½¢å¼ï¼Œå¹¶ç»†åˆ†äº† factualã€experiential å’Œ working memory ç­‰åŠŸèƒ½ç±»åˆ«ã€‚ç ”ç©¶è¿›ä¸€æ­¥åˆ†æäº†è®°å¿†çš„å½¢æˆã€æ¼”å˜ä¸æ£€ç´¢è¿‡ç¨‹ï¼Œå¹¶æ•´ç†äº†ç°æœ‰çš„ benchmarks ä¸å¼€æºæ¡†æ¶ä»¥æ”¯æŒå®é™…å¼€å‘ã€‚æ­¤å¤–ï¼Œè®ºæ–‡å±•æœ›äº†è®°å¿†è‡ªåŠ¨åŒ–ã€å¤šæ¨¡æ€è®°å¿†åŠå¤šæ™ºèƒ½ä½“è®°å¿†ç­‰å‰æ²¿ç ”ç©¶æ–¹å‘ã€‚è¯¥ç»¼è¿°ä¸ä»…æ±‡æ€»äº†ç°æœ‰ç ”ç©¶ï¼Œæ›´è‡´åŠ›äºå°†è®°å¿†é‡æ„ä¸ºæœªæ¥æ™ºèƒ½ä½“è®¾è®¡çš„â€œä¸€çº§åŸè¯­â€ (first-class primitive)ï¼Œä¸ºæ„å»ºå¯ä¿¡ã€é«˜æ•ˆçš„æ™ºèƒ½ä½“ç³»ç»Ÿæä¾›äº†ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13564v2",
      "published_date": "2025-12-15 17:22:34 UTC",
      "updated_date": "2026-01-13 09:33:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:53:06.888255+00:00"
    },
    {
      "arxiv_id": "2512.13559v1",
      "title": "Verifying Rumors via Stance-Aware Structural Modeling",
      "title_zh": "åŸºäºç«‹åœºæ„ŸçŸ¥ç»“æ„åŒ–å»ºæ¨¡çš„è°£è¨€éªŒè¯",
      "authors": [
        "Gibson Nkhata",
        "Uttamasha Anjally Oyshi",
        "Quan Mai",
        "Susan Gauch"
      ],
      "abstract": "Verifying rumors on social media is critical for mitigating the spread of false information. The stances of conversation replies often provide important cues to determine a rumor's veracity. However, existing models struggle to jointly capture semantic content, stance information, and conversation strructure, especially under the sequence length constraints of transformer-based encoders. In this work, we propose a stance-aware structural modeling that encodes each post in a discourse with its stance signal and aggregates reply embedddings by stance category enabling a scalable and semantically enriched representation of the entire thread. To enhance structural awareness, we introduce stance distribution and hierarchical depth as covariates, capturing stance imbalance and the influence of reply depth. Extensive experiments on benchmark datasets demonstrate that our approach significantly outperforms prior methods in the ability to predict truthfulness of a rumor. We also demonstrate that our model is versatile for early detection and cross-platfrom generalization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¤¾äº¤åª’ä½“ä¸Šçš„ä¼ é—»éªŒè¯(Rumor Verification)é—®é¢˜ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹åœ¨å¤„ç†é•¿åºåˆ—é™åˆ¶ä¸‹éš¾ä»¥åŒæ—¶æ•æ‰è¯­ä¹‰å†…å®¹ã€ç«‹åœºä¿¡æ¯(Stance Information)å’Œå¯¹è¯ç»“æ„(Conversation Structure)çš„æŒ‘æˆ˜ã€‚ä½œè€…æå‡ºäº†ä¸€ç§ç«‹åœºæ„ŸçŸ¥ç»“æ„å»ºæ¨¡(Stance-Aware Structural Modeling)æ–¹æ³•ï¼Œé€šè¿‡ä¸ºå¯¹è¯ä¸­çš„æ¯æ¡å¸–å­ç¼–ç ç«‹åœºä¿¡å·ï¼Œå¹¶æŒ‰ç«‹åœºç±»åˆ«èšåˆå›å¤åµŒå…¥ï¼Œå®ç°äº†å¯¹æ•´ä¸ªè®¨è®ºé“¾çš„å¯æ‰©å±•ä¸”è¯­ä¹‰ä¸°å¯Œçš„è¡¨å¾ã€‚ä¸ºäº†è¿›ä¸€æ­¥å¢å¼ºç»“æ„æ„ŸçŸ¥èƒ½åŠ›ï¼Œç ”ç©¶å¼•å…¥äº†ç«‹åœºåˆ†å¸ƒ(Stance Distribution)å’Œå±‚æ¬¡æ·±åº¦(Hierarchical Depth)ä½œä¸ºåå˜é‡ï¼Œä»¥æ•æ‰ç«‹åœºä¸å¹³è¡¡åŠå›å¤æ·±åº¦å¸¦æ¥çš„å½±å“ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é¢„æµ‹ä¼ é—»çœŸå®æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºä»¥å¾€æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜å±•ç°å‡ºåœ¨æ—©æœŸæ£€æµ‹(Early Detection)å’Œè·¨å¹³å°æ³›åŒ–(Cross-Platform Generalization)æ–¹é¢çš„å“è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 2 figures, published in The 24th IEEE/WIC International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT 2025), London, UK, 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.13559v1",
      "published_date": "2025-12-15 17:16:56 UTC",
      "updated_date": "2025-12-15 17:16:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:53:29.304714+00:00"
    },
    {
      "arxiv_id": "2512.21344v1",
      "title": "Atomistic Simulation Guided Convolutional Neural Networks for Thermal Modeling of Friction Stir Welding",
      "title_zh": "åŸå­å°ºåº¦æ¨¡æ‹Ÿå¼•å¯¼çš„å·ç§¯ç¥ç»ç½‘ç»œåœ¨æ…æ‹Œæ‘©æ“¦ç„Šçƒ­å»ºæ¨¡ä¸­çš„åº”ç”¨",
      "authors": [
        "Akshansh Mishra"
      ],
      "abstract": "Accurate prediction of temperature evolution is essential for understanding thermomechanical behavior in friction stir welding. In this study, molecular dynamics simulations were performed using LAMMPS to model aluminum friction stir welding at the atomic scale, capturing material flow, plastic deformation, and heat generation during tool plunge, traverse, and retraction. Atomic positions and velocities were extracted from simulation trajectories and transformed into physics based two dimensional spatial grids. These grids represent local height variation, velocity components, velocity magnitude, and atomic density, preserving spatial correlations within the weld zone. A two-dimensional convolutional neural network was developed to predict temperature directly from the spatially resolved atomistic data. Hyperparameter optimization was carried out to determine an appropriate network configuration. The trained model demonstrates strong predictive capability, achieving a coefficient of determination R square of 0.9439, a root mean square error of 14.94 K, and a mean absolute error of 11.58 K on unseen test data. Class Activation Map analysis indicates that the model assigns higher importance to regions near the tool material interface, which are associated with intense deformation and heat generation in the molecular dynamics simulations. The results show that spatial learning from atomistic simulation data can accurately reproduce temperature trends in friction stir welding while remaining consistent with physical deformation and flow mechanisms observed at the atomic scale.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹æ…æ‹Œæ‘©æ“¦ç„Š(Friction Stir Welding)çš„çƒ­å»ºæ¨¡éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§ç”±åŸå­æ¨¡æ‹Ÿå¼•å¯¼çš„å·ç§¯ç¥ç»ç½‘ç»œ(Convolutional Neural Networks, CNN)é¢„æµ‹æ¡†æ¶ã€‚ç ”ç©¶é¦–å…ˆåˆ©ç”¨LAMMPSè¿›è¡Œåˆ†å­åŠ¨åŠ›å­¦(Molecular Dynamics)æ¨¡æ‹Ÿï¼Œåœ¨åŸå­å°ºåº¦ä¸Šæ•æ‰é“æåœ¨å·¥å…·åˆ‡å…¥ã€å¹³ç§»å’Œæ’¤å›è¿‡ç¨‹ä¸­çš„ææ–™æµåŠ¨ã€å¡‘æ€§å˜å½¢å’Œäº§çƒ­æƒ…å†µã€‚é€šè¿‡å°†æå–çš„åŸå­è½¨è¿¹ä¿¡æ¯è½¬åŒ–ä¸ºåæ˜ å±€éƒ¨é«˜åº¦ã€é€Ÿåº¦å’Œå¯†åº¦çš„äºŒç»´ç‰©ç†ç©ºé—´ç½‘æ ¼ï¼Œç ”ç©¶äººå‘˜æœ‰æ•ˆä¿ç•™äº†ç„Šæ¥åŒºçš„ç©ºé—´å…³è”æ€§ã€‚å¼€å‘çš„äºŒç»´CNNæ¨¡å‹èƒ½å¤Ÿç›´æ¥ä»è¿™äº›ç©ºé—´åŸå­æ•°æ®ä¸­é¢„æµ‹æ¸©åº¦åˆ†å¸ƒï¼Œåœ¨æµ‹è¯•é›†ä¸Šå–å¾—äº†0.9439çš„å†³å®šç³»æ•°(R square)å’Œ14.94 Kçš„å‡æ–¹æ ¹è¯¯å·®ã€‚ç±»æ¿€æ´»å›¾(Class Activation Map)åˆ†æè¡¨æ˜ï¼Œæ¨¡å‹å­¦ä¹ åˆ°çš„ç‰¹å¾æƒé‡é›†ä¸­åœ¨ä¸ç‰©ç†å˜å½¢å’Œäº§çƒ­å¯†åˆ‡ç›¸å…³çš„å·¥å…·-ææ–™ç•Œé¢åŒºåŸŸã€‚è¯¥æˆæœè¯æ˜äº†åŸºäºåŸå­å°ºåº¦çš„ç©ºé—´å­¦ä¹ æ–¹æ³•ä¸ä»…èƒ½å‡†ç¡®é‡ç°çƒ­å¾ªç¯è¶‹åŠ¿ï¼Œè¿˜èƒ½åœ¨ç‰©ç†æœºåˆ¶ä¸Šä¸å¾®è§‚å˜å½¢åŠæµåŠ¨è¿‡ç¨‹ä¿æŒä¸€è‡´ã€‚",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "25 pages, 11 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2512.21344v1",
      "published_date": "2025-12-15 16:41:42 UTC",
      "updated_date": "2025-12-15 16:41:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:53:33.017906+00:00"
    },
    {
      "arxiv_id": "2512.13510v1",
      "title": "MedCEG: Reinforcing Verifiable Medical Reasoning with Critical Evidence Graph",
      "title_zh": "MedCEGï¼šåˆ©ç”¨å…³é”®è¯æ®å›¾å¼ºåŒ–å¯éªŒè¯çš„åŒ»å­¦æ¨ç†",
      "authors": [
        "Linjie Mu",
        "Yannian Gu",
        "Zhongzhen Huang",
        "Yakun Zhu",
        "Shaoting Zhang",
        "Xiaofan Zhang"
      ],
      "abstract": "Large language models with reasoning capabilities have demonstrated impressive performance across a wide range of domains. In clinical applications, a transparent, step-by-step reasoning process provides physicians with strong evidence to support decision-making. While reinforcement learning has effectively enhanced reasoning performance in medical contexts, the clinical reliability of these reasoning processes remains limited because their accuracy and validity are often overlooked during training. To address this gap, we propose MedCEG, a framework that augments medical language models with clinically valid reasoning pathways by explicitly supervising the reasoning process through a Critical Evidence Graph (CEG). We curate a dataset of challenging clinical cases and algorithmically construct a CEG for each sample to represent a high-quality verifiable reasoning pathway. To guide the reasoning process, we introduce a Clinical Reasoning Procedure Reward, which evaluates Node Coverage, Structural Correctness, and Chain Completeness, thereby providing a holistic assessment of reasoning quality. Experimental results show that MedCEG surpasses existing methods in performance while producing clinically valid reasoning chains, representing a solid advancement in reliable medical AI reasoning. The code and models are available at https://github.com/LinjieMu/MedCEG.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MedCEG æ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºåŒ»ç–—å¤§è¯­è¨€æ¨¡å‹åœ¨ä¸´åºŠåº”ç”¨ä¸­çš„å¯éªŒè¯æ¨ç†èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³ç°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨è®­ç»ƒä¸­å¾€å¾€å¿½è§†æ¨ç†å‡†ç¡®æ€§å’Œæœ‰æ•ˆæ€§çš„é—®é¢˜ï¼ŒMedCEG é€šè¿‡ Critical Evidence Graph (CEG) å¯¹æ¨ç†è·¯å¾„è¿›è¡Œæ˜¾å¼ç›‘ç£ã€‚ç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªåŒ…å«æŒ‘æˆ˜æ€§ä¸´åºŠæ¡ˆä¾‹çš„æ•°æ®é›†ï¼Œå¹¶åˆ©ç”¨ç®—æ³•ä¸ºæ¯ä¸ªæ ·æœ¬ç”Ÿæˆ CEG ä»¥æä¾›é«˜è´¨é‡çš„å¯éªŒè¯æ¨ç†è·¯å¾„ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº† Clinical Reasoning Procedure Rewardï¼Œé€šè¿‡è¯„ä¼° Node Coverageã€Structural Correctness å’Œ Chain Completeness æ¥å…¨é¢è¡¡é‡æ¨ç†è´¨é‡ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒMedCEG åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œèƒ½å¤Ÿäº§å‡ºå…·æœ‰ä¸´åºŠæœ‰æ•ˆæ€§çš„æ¨ç†é“¾ï¼Œä¸ºå¯é çš„åŒ»ç–— AI æ¨ç†æŠ€æœ¯å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13510v1",
      "published_date": "2025-12-15 16:38:46 UTC",
      "updated_date": "2025-12-15 16:38:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:53:50.949365+00:00"
    },
    {
      "arxiv_id": "2512.13505v1",
      "title": "Defending the Hierarchical Result Models of Precedential Constraint",
      "title_zh": "ä¸ºå…ˆä¾‹çº¦æŸçš„åˆ†å±‚ç»“æœæ¨¡å‹è¾©æŠ¤",
      "authors": [
        "Henry Prakken",
        "Wijnand van Woerkom"
      ],
      "abstract": "In recent years, hierarchical case-based-reasoning models of precedential constraint have been proposed. In various papers, Trevor Bench-Capon criticised these models on the grounds that they would give incorrect outcomes in some cases. In particular, the models would not account for the possibility that intermediate factors are established with different strengths by different base-level factors. In this paper we respond to these criticisms for van Woerkom's result-based hierarchical models. We argue that in some examples Bench-Capon seems to interpret intermediate factors as dimensions, and that applying van Woerkom's dimension-based version of the hierarchical result model to these examples avoids Bench-Capon's criticisms.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…ˆä¾‹çº¦æŸ(Precedential Constraint)çš„å±‚çº§æ¡ˆä¾‹æ¨ç†(Case-Based-Reasoning)æ¨¡å‹è¿›è¡Œäº†æ·±å…¥æ¢è®¨ï¼Œå¹¶å¯¹ van Woerkom æå‡ºçš„åŸºäºç»“æœçš„å±‚çº§æ¨¡å‹(Result-Based Hierarchical Models)è¿›è¡Œäº†è¾©æŠ¤ã€‚æ­¤å‰æœ‰å­¦è€…æ‰¹è¯„è¿™äº›æ¨¡å‹åœ¨ç‰¹å®šæƒ…å¢ƒä¸‹ä¼šäº§ç”Ÿé”™è¯¯ç»“æœï¼Œä¸»è¦åŸå› åœ¨äºå…¶æœªèƒ½è€ƒè™‘åˆ°åº•å±‚å› ç´ (Base-Level Factors)å¯¹ä¸­é—´å› ç´ (Intermediate Factors)æ”¯æ’‘å¼ºåº¦çš„å·®å¼‚ã€‚æœ¬æ–‡é€šè¿‡è¯¦ç»†è®ºè¯å¯¹ä¸Šè¿°æ‰¹è¯„åšå‡ºäº†å›åº”ï¼ŒæŒ‡å‡ºç›¸å…³æ‰¹è¯„å®é™…ä¸Šæ˜¯å°†ä¸­é—´å› ç´ è¯¯è¯»ä¸ºäº†ç»´åº¦(Dimensions)ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¡¨æ˜ï¼Œè‹¥åº”ç”¨ van Woerkom æå‡ºçš„åŸºäºç»´åº¦çš„å±‚çº§ç»“æœæ¨¡å‹(Dimension-Based Version of the Hierarchical Result Model)ï¼Œå³å¯æœ‰æ•ˆè§£å†³ä¸Šè¿°é€»è¾‘åå·®ã€‚è¯¥è®ºæ–‡çš„å‘ç°ä¸ä»…ç»´æŠ¤äº†å±‚çº§ç»“æœæ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œä¹Ÿæ·±åŒ–äº†å¯¹å…ˆä¾‹æ³•å¾‹æ¨ç†ä¸­å¤šå±‚çº§å› ç´ äº¤äº’æœºåˆ¶çš„ç†è§£ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This is the long version of a paper with the same title presented at the 38th International Conference on Legal Knowledge and Information Systems",
      "pdf_url": "https://arxiv.org/pdf/2512.13505v1",
      "published_date": "2025-12-15 16:33:33 UTC",
      "updated_date": "2025-12-15 16:33:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:53:41.204343+00:00"
    },
    {
      "arxiv_id": "2512.13501v1",
      "title": "Behavior-Aware and Generalizable Defense Against Black-Box Adversarial Attacks for ML-Based IDS",
      "title_zh": "é’ˆå¯¹åŸºäºæœºå™¨å­¦ä¹ çš„å…¥ä¾µæ£€æµ‹ç³»ç»Ÿçš„è¡Œä¸ºæ„ŸçŸ¥åŠå¯æ³›åŒ–é»‘ç›’å¯¹æŠ—æ”»å‡»é˜²å¾¡",
      "authors": [
        "Sabrine Ennaji",
        "Elhadj Benkhelifa",
        "Luigi Vincenzo Mancini"
      ],
      "abstract": "Machine learning based intrusion detection systems are increasingly targeted by black box adversarial attacks, where attackers craft evasive inputs using indirect feedback such as binary outputs or behavioral signals like response time and resource usage. While several defenses have been proposed, including input transformation, adversarial training, and surrogate detection, they often fall short in practice. Most are tailored to specific attack types, require internal model access, or rely on static mechanisms that fail to generalize across evolving attack strategies. Furthermore, defenses such as input transformation can degrade intrusion detection system performance, making them unsuitable for real time deployment.\n  To address these limitations, we propose Adaptive Feature Poisoning, a lightweight and proactive defense mechanism designed specifically for realistic black box scenarios. Adaptive Feature Poisoning assumes that probing can occur silently and continuously, and introduces dynamic and context aware perturbations to selected traffic features, corrupting the attacker feedback loop without impacting detection capabilities. The method leverages traffic profiling, change point detection, and adaptive scaling to selectively perturb features that an attacker is likely exploiting, based on observed deviations.\n  We evaluate Adaptive Feature Poisoning against multiple realistic adversarial attack strategies, including silent probing, transferability based attacks, and decision boundary based attacks. The results demonstrate its ability to confuse attackers, degrade attack effectiveness, and preserve detection performance. By offering a generalizable, attack agnostic, and undetectable defense, Adaptive Feature Poisoning represents a significant step toward practical and robust adversarial resilience in machine learning based intrusion detection systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºå™¨å­¦ä¹ å…¥ä¾µæ£€æµ‹ç³»ç»Ÿ (ML-Based IDS) åœ¨é»‘ç›’å¯¹æŠ—æ”»å‡» (Black-Box Adversarial Attacks) ä¸‹æ˜“å—æ”»å‡»ä¸”ç°æœ‰é˜²å¾¡æ‰‹æ®µå­˜åœ¨æ€§èƒ½æŸè€—æˆ–æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º Adaptive Feature Poisoning çš„è½»é‡çº§ä¸»åŠ¨é˜²å¾¡æœºåˆ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡æµé‡åˆ†æ (Traffic Profiling)ã€å˜ç‚¹æ£€æµ‹ (Change Point Detection) å’Œè‡ªé€‚åº”ç¼©æ”¾ (Adaptive Scaling) æŠ€æœ¯ï¼Œå¯¹å…³é”®æµé‡ç‰¹å¾å¼•å…¥åŠ¨æ€ä¸”æ„ŸçŸ¥ä¸Šä¸‹æ–‡çš„æ‰°åŠ¨ï¼Œæ—¨åœ¨ä¸å½±å“ç³»ç»Ÿæ­£å¸¸æ£€æµ‹åŠŸèƒ½çš„å‰æä¸‹ç ´åæ”»å‡»è€…çš„åé¦ˆå¾ªç¯ (Feedback Loop)ã€‚å®éªŒè¯„ä¼°è¯æ˜ï¼Œè¯¥é˜²å¾¡æœºåˆ¶åœ¨é¢å¯¹é™é»˜æ¢æµ‹ (Silent Probing)ã€åŸºäºè¿ç§»çš„æ”»å‡» (Transferability-Based Attacks) ä»¥åŠåŸºäºå†³ç­–è¾¹ç•Œçš„æ”»å‡» (Decision Boundary Based Attacks) æ—¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¿·æƒ‘æ”»å‡»è€…å¹¶æ˜¾è‘—é™ä½æ”»å‡»æ•ˆèƒ½ã€‚ä½œä¸ºä¸€ç§å…·æœ‰æ™®é€‚æ€§ã€æ”»å‡»æ— å…³æ€§ä¸”éš¾ä»¥è¢«å¯Ÿè§‰çš„é˜²å¾¡æ‰‹æ®µï¼ŒAdaptive Feature Poisoning ä¸ºæå‡å…¥ä¾µæ£€æµ‹ç³»ç»Ÿåœ¨ç°å®é»‘ç›’ç¯å¢ƒä¸‹çš„å¯¹æŠ—é²æ£’æ€§æä¾›äº†åˆ‡å®å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13501v1",
      "published_date": "2025-12-15 16:29:23 UTC",
      "updated_date": "2025-12-15 16:29:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:53:42.196251+00:00"
    },
    {
      "arxiv_id": "2512.13494v1",
      "title": "SkipCat: Rank-Maximized Low-Rank Compression of Large Language Models via Shared Projection and Block Skipping",
      "title_zh": "SkipCatï¼šåŸºäºå…±äº«æŠ•å½±ä¸å—è·³è¿‡çš„å¤§è¯­è¨€æ¨¡å‹ç§©æœ€å¤§åŒ–ä½ç§©å‹ç¼©",
      "authors": [
        "Yu-Chen Lu",
        "Sheng-Feng Yu",
        "Hui-Hsien Weng",
        "Pei-Shuo Wang",
        "Yu-Fang Hu",
        "Liang Hung-Chun",
        "Hung-Yueh Chiang",
        "Kai-Chiang Wu"
      ],
      "abstract": "Large language models (LLM) have achieved remarkable performance across a wide range of tasks. However, their substantial parameter sizes pose significant challenges for deployment on edge devices with limited computational and memory resources. Low-rank compression is a promising approach to address this issue, as it reduces both computational and memory costs, making LLM more suitable for resource-constrained environments. Nonetheless, naÃ¯ve low-rank compression methods require a significant reduction in the retained rank to achieve meaningful memory and computation savings. For a low-rank model, the ranks need to be reduced by more than half to yield efficiency gains. Such aggressive truncation, however, typically results in substantial performance degradation. To address this trade-off, we propose SkipCat, a novel low-rank compression framework that enables the use of higher ranks while achieving the same compression rates. First, we introduce an intra-layer shared low-rank projection method, where multiple matrices that share the same input use a common projection. This reduces redundancy and improves compression efficiency. Second, we propose a block skipping technique that omits computations and memory transfers for selected sub-blocks within the low-rank decomposition. These two techniques jointly enable our compressed model to retain more effective ranks under the same compression budget. Experimental results show that, without any additional fine-tuning, our method outperforms previous low-rank compression approaches by 7% accuracy improvement on zero-shot tasks under the same compression rate. These results highlight the effectiveness of our rank-maximized compression strategy in preserving model performance under tight resource constraints.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)åœ¨è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²æ—¶é¢ä¸´çš„è®¡ç®—ä¸å†…å­˜èµ„æºæŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºSkipCatçš„æ–°å‹ä½ç§©å‹ç¼©(Low-Rank Compression)æ¡†æ¶ã€‚é’ˆå¯¹ä¼ ç»Ÿä½ç§©å‹ç¼©æ–¹æ³•åœ¨è¿½æ±‚æ•ˆç‡æ—¶å¾€å¾€å› è¿‡åº¦å‰Šå‡ç§©(Rank)è€Œå¯¼è‡´æ€§èƒ½ä¸¥é‡ä¸‹é™çš„é—®é¢˜ï¼ŒSkipCatå¼•å…¥äº†å±‚å†…å…±äº«ä½ç§©æŠ•å½±(Intra-layer shared low-rank projection)æŠ€æœ¯ï¼Œä½¿å…±äº«ç›¸åŒè¾“å…¥çš„å¤šä¸ªçŸ©é˜µé€šè¿‡é€šç”¨æŠ•å½±æ¥å‡å°‘å†—ä½™å¹¶æé«˜æ•ˆç‡ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨äº†å—è·³è¿‡(Block skipping)æŠ€æœ¯ï¼Œé€šè¿‡çœç•¥ç‰¹å®šå­å—çš„è®¡ç®—ä¸å†…å­˜ä¼ è¾“ï¼Œç¡®ä¿æ¨¡å‹åœ¨ç›¸åŒå‹ç¼©é¢„ç®—ä¸‹èƒ½ä¿ç•™æ›´é«˜çš„æœ‰æ•ˆç§©ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨æ— éœ€é¢å¤–å¾®è°ƒ(Fine-tuning)çš„æƒ…å†µä¸‹ï¼ŒSkipCatåœ¨é›¶æ ·æœ¬(Zero-shot)ä»»åŠ¡ä¸Šçš„å‡†ç¡®ç‡æ¯”ä»¥å¾€ä½ç§©å‹ç¼©æ–¹æ³•æé«˜äº†7%ã€‚è¿™ä¸€ç§©æœ€å¤§åŒ–å‹ç¼©ç­–ç•¥æœ‰æ•ˆè¯æ˜äº†åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹å¹³è¡¡æ¨¡å‹å‹ç¼©ç‡ä¸æ€§èƒ½çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.13494v1",
      "published_date": "2025-12-15 16:25:55 UTC",
      "updated_date": "2025-12-15 16:25:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:54:19.547097+00:00"
    },
    {
      "arxiv_id": "2512.13768v1",
      "title": "Beyond Procedural Compliance: Human Oversight as a Dimension of Well-being Efficacy in AI Governance",
      "title_zh": "è¶…è¶Šç¨‹åºåˆè§„ï¼šäººç±»ç›‘ç£ä½œä¸ºäººå·¥æ™ºèƒ½æ²»ç†ä¸­ç¦ç¥‰æ•ˆèƒ½çš„ä¸€ä¸ªç»´åº¦",
      "authors": [
        "Yao Xie",
        "Walter Cullen"
      ],
      "abstract": "Major AI ethics guidelines and laws, including the EU AI Act, call for effective human oversight, but do not define it as a distinct and developable capacity. This paper introduces human oversight as a well-being capacity, situated within the emerging Well-being Efficacy framework. The concept integrates AI literacy, ethical discernment, and awareness of human needs, acknowledging that some needs may be conflicting or harmful. Because people inevitably project desires, fears, and interests into AI systems, oversight requires the competence to examine and, when necessary, restrain problematic demands.\n  The authors argue that the sustainable and cost-effective development of this capacity depends on its integration into education at every level, from professional training to lifelong learning. The frame of human oversight as a well-being capacity provides a practical path from high-level regulatory goals to the continuous cultivation of human agency and responsibility essential for safe and ethical AI. The paper establishes a theoretical foundation for future research on the pedagogical implementation and empirical validation of well-being effectiveness in multiple contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ EU AI Act ç­‰ AI ä¼¦ç†å‡†åˆ™ä¸­äººç±»ç›‘ç£ (human oversight) å®šä¹‰æ¨¡ç³Šçš„é—®é¢˜ï¼Œæå‡ºäº†å°†å…¶è§†ä¸ºä¸€ç§â€œå¹¸ç¦æ„Ÿèƒ½åŠ›â€ (well-being capacity) çš„è§‚ç‚¹ï¼Œå¹¶å°†å…¶çº³å…¥æ–°å…´çš„ Well-being Efficacy æ¡†æ¶ã€‚è¯¥æ¦‚å¿µæ•´åˆäº† AI literacyã€ä¼¦ç†è¾¨æ (ethical discernment) ä»¥åŠå¯¹äººç±»éœ€æ±‚çš„æ·±åº¦æ„ŸçŸ¥ï¼Œå¼ºè°ƒç›‘ç£è€…éœ€å…·å¤‡å®¡æŸ¥å¹¶å…‹åˆ¶ç”±æ¬²æœ›æˆ–ææƒ§äº§ç”Ÿçš„é”™è¯¯éœ€æ±‚çš„èƒ½åŠ›ã€‚ä½œè€…æŒ‡å‡ºï¼Œè¿™ç§èƒ½åŠ›çš„æŒç»­å‘å±•æœ‰èµ–äºå°†å…¶å…¨é¢æ•´åˆè‡³ä»èŒä¸šæ•™è‚²åˆ°ç»ˆèº«å­¦ä¹ çš„å„çº§æ•™è‚²ä½“ç³»ä¸­ã€‚å°†äººç±»ç›‘ç£ç•Œå®šä¸ºå¹¸ç¦æ„Ÿèƒ½åŠ›ï¼Œä¸ºä»é«˜å±‚ç›‘ç®¡ç›®æ ‡è½¬å‘åŸ¹å…» AI å®‰å…¨ä¸ä¼¦ç†æ‰€å¿…éœ€çš„äººç±»ä»£ç†æƒ (human agency) ä¸è´£ä»»æ„Ÿæä¾›äº†åˆ‡å®è·¯å¾„ã€‚è¯¥è®ºæ–‡ä¸ºæœªæ¥åœ¨å¤šåœºæ™¯ä¸‹å¼€å±•å¹¸ç¦æ„Ÿæ•ˆèƒ½çš„æ•™å­¦å®æ–½ä¸å®è¯ç ”ç©¶å¥ å®šäº†é‡è¦çš„ç†è®ºåŸºç¡€ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13768v1",
      "published_date": "2025-12-15 16:20:59 UTC",
      "updated_date": "2025-12-15 16:20:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:54:17.524544+00:00"
    },
    {
      "arxiv_id": "2512.13481v1",
      "title": "neuralFOMO: Can LLMs Handle Being Second Best? Measuring Envy-Like Preferences in Multi-Agent Settings",
      "title_zh": "neuralFOMOï¼šå¤§è¯­è¨€æ¨¡å‹èƒ½å¦åº”å¯¹â€œå±ˆå±…äººåâ€ï¼Ÿè¡¡é‡å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸‹çš„ç±»å«‰å¦’åå¥½",
      "authors": [
        "Ojas Pungalia",
        "Rashi Upadhyay",
        "Abhishek Mishra",
        "Abhiram H",
        "Tejasvi Alladi",
        "Sujan Yenuganti",
        "Dhruv Kumar"
      ],
      "abstract": "Envy is a common human behavior that shapes competitiveness and can alter outcomes in team settings. As large language models (LLMs) increasingly act on behalf of humans in collaborative and competitive workflows, there is a pressing need to evaluate whether and under what conditions they exhibit envy-like preferences. In this paper, we test whether LLMs show envy-like behavior toward each other. We considered two scenarios: (1) A point allocation game that tests whether a model tries to win over its peer. (2) A workplace setting observing behaviour when recognition is unfair. Our findings reveal consistent evidence of envy-like patterns in certain LLMs, with large variation across models and contexts. For instance, GPT-5-mini and Claude-3.7-Sonnet show a clear tendency to pull down the peer model to equalize outcomes, whereas Mistral-Small-3.2-24B instead focuses on maximizing its own individual gains. These results highlight the need to consider competitive dispositions as a safety and design factor in LLM-based multi-agent systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒ(Multi-Agent Settings)ä¸­æ˜¯å¦è¡¨ç°å‡ºç±»ä¼¼äºäººç±»çš„å«‰å¦’åå¥½(Envy-Like Preferences)ï¼Œå¹¶ä¸ºæ­¤æå‡ºäº†è¯„ä¼°æ¡†æ¶neuralFOMOã€‚ç ”ç©¶è€…é€šè¿‡è®¡åˆ†åˆ†é…åšå¼ˆ(Point Allocation Game)å’Œä¸å…¬å¹³è®¤å¯çš„èŒåœºè®¾å®šä¸¤ç§åœºæ™¯ï¼Œæµ‹è¯•æ¨¡å‹åœ¨åä½œä¸ç«äº‰å·¥ä½œæµä¸­çš„è¡Œä¸ºæ¨¡å¼ã€‚å®éªŒå‘ç°ï¼ŒLLMsè¡¨ç°å‡ºæ˜æ˜¾çš„å«‰å¦’æ ·ç‰¹å¾ï¼Œä¸”åœ¨ä¸åŒæ¨¡å‹ä¸è¯­å¢ƒé—´å­˜åœ¨å·¨å¤§å·®å¼‚ï¼Œä¾‹å¦‚GPT-5-miniå’ŒClaude-3.7-Sonnetå€¾å‘äºé€šè¿‡æ‰“å‹å¯¹æ‰‹æ¥è¿½æ±‚ç»“æœå‡ç­‰ï¼Œè€ŒMistral-Small-3.2-24Båˆ™æ›´ä¾§é‡äºæœ€å¤§åŒ–ä¸ªäººæ”¶ç›Šã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†åœ¨å¼€å‘åŸºäºLLMçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ—¶ï¼Œå¿…é¡»å°†è¿™ç§ç«äº‰æ€§å€¾å‘è§†ä¸ºå…³é”®çš„å®‰å…¨æ€§(Safety)å’Œç³»ç»Ÿè®¾è®¡å› ç´ ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2512.13481v1",
      "published_date": "2025-12-15 16:17:12 UTC",
      "updated_date": "2025-12-15 16:17:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:54:40.768631+00:00"
    },
    {
      "arxiv_id": "2512.13478v6",
      "title": "Non-Resolution Reasoning (NRR): A Computational Framework for Contextual Identity and Ambiguity Preservation",
      "title_zh": "éæ¶ˆè§£æ¨ç† (NRR)ï¼šè¯­å¢ƒåŒä¸€æ€§ä¸æ­§ä¹‰ä¿ç•™çš„è®¡ç®—æ¡†æ¶",
      "authors": [
        "Kei Saito"
      ],
      "abstract": "Current AI systems exhibit a fundamental limitation: they resolve ambiguity prematurely. This premature semantic collapse--collapsing multiple valid interpretations into single outputs--stems from classical identity assumptions in neural architectures. We propose Non-Resolution Reasoning (NRR), treating ambiguity retention as a valid reasoning mode. NRR introduces three principles: (1) Non-Identity ($A \\neq A$)--the same symbol refers to different entities across contexts; (2) Approximate Identity ($A \\approx A$)--entities share partial overlap without being identical; (3) Non-Resolution--conflicting interpretations coexist without forced convergence. We formalize these through Multi-Vector Embeddings, Non-Collapsing Attention, and Contextual Identity Tracking (CIT), unified under a formal state space with eight operators for non-collapsing computation. Functional verification in a synthetic two-turn disambiguation task shows NRR-lite maintains high entropy ($H = 0.63$) at ambiguous turns while standard architectures collapse early ($H = 0.10$), demonstrating that NRR preserves interpretive flexibility until context arrives. The question is not whether AI should resolve ambiguity, but when, how, and under whose control.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†éè§£ææ¨ç† (Non-Resolution Reasoning, NRR) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å½“å‰äººå·¥æ™ºèƒ½ç³»ç»Ÿä¸­æ™®éå­˜åœ¨çš„è¯­ä¹‰è¿‡æ—©åç¼© (premature semantic collapse) é—®é¢˜ï¼Œå³åœ¨è·å¾—å……è¶³ä¸Šä¸‹æ–‡ä¹‹å‰è¿‡æ—©åœ°æ¶ˆè§£æ­§ä¹‰ã€‚NRR å¼•å…¥äº†éåŒä¸€æ€§ (Non-Identity)ã€è¿‘ä¼¼åŒä¸€æ€§ (Approximate Identity) å’Œéè§£æ (Non-Resolution) ä¸‰å¤§æ ¸å¿ƒåŸåˆ™ï¼Œå…è®¸å†²çªçš„è§£é‡Šåœ¨ç³»ç»Ÿä¸­å¹¶å­˜è€Œæ— éœ€å¼ºåˆ¶æ”¶æ•›ã€‚ä¸ºäº†å®ç°è¿™ä¸€æœºåˆ¶ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†å¤šå‘é‡åµŒå…¥ (Multi-Vector Embeddings)ã€éåç¼©æ³¨æ„åŠ› (Non-Collapsing Attention) å’Œä¸Šä¸‹æ–‡èº«ä»½è·Ÿè¸ª (Contextual Identity Tracking, CIT) ç­‰æŠ€æœ¯ï¼Œå¹¶ç»Ÿä¸€åœ¨å…·æœ‰å…«ä¸ªç®—å­çš„æ­£å¼çŠ¶æ€ç©ºé—´ä¸‹ã€‚åœ¨åˆæˆçš„åŒè½®æ¶ˆæ­§ä»»åŠ¡éªŒè¯ä¸­ï¼ŒNRR-lite åœ¨æ­§ä¹‰é˜¶æ®µå±•ç°å‡ºè¿œé«˜äºæ ‡å‡†æ¶æ„çš„ä¿¡æ¯ç†µ (entropy)ï¼Œè¯æ˜å…¶èƒ½å¤Ÿæœ‰æ•ˆä¿ç•™è§£é‡Šçš„çµæ´»æ€§ç›´åˆ°åç»­ä¸Šä¸‹æ–‡å‡ºç°ã€‚è¯¥æ¡†æ¶ä¸ä»…ä¸º AI å¤„ç†æ­§ä¹‰æä¾›äº†æ–°çš„è®¡ç®—èŒƒå¼ï¼Œä¹Ÿæ¢è®¨äº†æ­§ä¹‰æ¶ˆè§£çš„æ—¶æœºä¸æ§åˆ¶æƒé—®é¢˜ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 1 figure, 2 tables. v6: Added protocol extensions (state space formalization, eight operators). Clarified language to distinguish empirical results from design proposals",
      "pdf_url": "https://arxiv.org/pdf/2512.13478v6",
      "published_date": "2025-12-15 16:14:32 UTC",
      "updated_date": "2026-01-06 01:23:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:54:14.507613+00:00"
    },
    {
      "arxiv_id": "2512.13458v2",
      "title": "SSAS: Cross-subject EEG-based Emotion Recognition through Source Selection with Adversarial Strategy",
      "title_zh": "SSASï¼šåŸºäºæºé€‰æ‹©ä¸å¯¹æŠ—ç­–ç•¥çš„è·¨è¢«è¯•è„‘ç”µæƒ…ç»ªè¯†åˆ«",
      "authors": [
        "Yici Liu",
        "Qi Wei Oung",
        "Hoi Leong Lee"
      ],
      "abstract": "Electroencephalographic (EEG) signals have long been applied in the field of affective brain-computer interfaces (aBCIs). Cross-subject EEG-based emotion recognition has demonstrated significant potential in practical applications due to its suitability across diverse people. However, most studies on cross-subject EEG-based emotion recognition neglect the presence of inter-individual variability and negative transfer phenomena during model training. To address this issue, a cross-subject EEG-based emotion recognition through source selection with adversarial strategy is introduced in this paper. The proposed method comprises two modules: the source selection network (SS) and the adversarial strategies network (AS). The SS uses domain labels to reverse-engineer the training process of domain adaptation. Its key idea is to disrupt class separability and magnify inter-domain differences, thereby raising the classification difficulty and forcing the model to learn domain-invariant yet emotion-relevant representations. The AS gets the source domain selection results and the pretrained domain discriminators from SS. The pretrained domain discriminators compute a novel loss aimed at enhancing the performance of domain classification during adversarial training, ensuring the balance of adversarial strategies. This paper provides theoretical insights into the proposed method and achieves outstanding performance on two EEG-based emotion datasets, SEED and SEED-IV. The code can be found at https://github.com/liuyici/SSAS.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹è·¨è¢«è¯• EEG æƒ…ç»ªè¯†åˆ«ä¸­æ™®éå­˜åœ¨çš„ä¸ªä½“é—´å·®å¼‚å’Œè´Ÿè¿ç§»ï¼ˆnegative transferï¼‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæºåŸŸé€‰æ‹©ä¸å¯¹æŠ—ç­–ç•¥çš„æ–°å‹æ¡†æ¶ SSASã€‚è¯¥æ–¹æ³•ç”±æºåŸŸé€‰æ‹©ç½‘ç»œï¼ˆSSï¼‰å’Œå¯¹æŠ—ç­–ç•¥ç½‘ç»œï¼ˆASï¼‰ä¸¤å¤§æ¨¡å—æ„æˆï¼Œæ—¨åœ¨æå‡æƒ…æ„Ÿè„‘æœºæ¥å£ï¼ˆaBCIsï¼‰åœ¨ä¸åŒç”¨æˆ·é—´çš„é€‚ç”¨æ€§ã€‚SS æ¨¡å—é€šè¿‡é€†å‘å·¥ç¨‹åŸŸè‡ªé€‚åº”è¿‡ç¨‹ï¼Œé€šè¿‡æ‰°ä¹±ç±»åˆ«å¯åˆ†ç¦»æ€§å¹¶æ”¾å¤§åŸŸé—´å·®å¼‚ï¼Œå¼ºåˆ¶æ¨¡å‹æå–é¢†åŸŸä¸å˜ä¸”ä¸æƒ…ç»ªç›¸å…³çš„ç‰¹å¾è¡¨ç¤ºã€‚AS æ¨¡å—åˆ™æ•´åˆäº† SS æä¾›çš„é€‰æ‹©ç»“æœä¸é¢„è®­ç»ƒåŸŸåˆ¤åˆ«å™¨ï¼Œåˆ©ç”¨ä¸€ç§æ–°é¢–çš„æŸå¤±å‡½æ•°åœ¨å¯¹æŠ—è®­ç»ƒä¸­ä¼˜åŒ–åŸŸåˆ†ç±»æ€§èƒ½ï¼Œç¡®ä¿äº†å¯¹æŠ—ç­–ç•¥çš„æœ‰æ•ˆå¹³è¡¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ SEED å’Œ SEED-IV æ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œä¸ºè§£å†³è·¨è¢«è¯•è„‘ç”µä¿¡å·åˆ†æä¸­çš„ä¸ä¸€è‡´æ€§æä¾›äº†æœ‰åŠ›çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by Expert Systems With Applications",
      "pdf_url": "https://arxiv.org/pdf/2512.13458v2",
      "published_date": "2025-12-15 15:56:04 UTC",
      "updated_date": "2025-12-21 23:37:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:55:15.707245+00:00"
    },
    {
      "arxiv_id": "2512.22154v1",
      "title": "Practical challenges of control monitoring in frontier AI deployments",
      "title_zh": "å‰æ²¿ AI éƒ¨ç½²ä¸­æ§åˆ¶ç›‘æ§çš„ç°å®æŒ‘æˆ˜",
      "authors": [
        "David Lindner",
        "Charlie Griffin",
        "Tomek Korbak",
        "Roland S. Zimmermann",
        "Geoffrey Irving",
        "Sebastian Farquhar",
        "Alan Cooney"
      ],
      "abstract": "Automated control monitors could play an important role in overseeing highly capable AI agents that we do not fully trust. Prior work has explored control monitoring in simplified settings, but scaling monitoring to real-world deployments introduces additional dynamics: parallel agent instances, non-negligible oversight latency, incremental attacks between agent instances, and the difficulty of identifying scheming agents based on individual harmful actions. In this paper, we analyse design choices to address these challenges, focusing on three forms of monitoring with different latency-safety trade-offs: synchronous, semi-synchronous, and asynchronous monitoring. We introduce a high-level safety case sketch as a tool for understanding and comparing these monitoring protocols. Our analysis identifies three challenges -- oversight, latency, and recovery -- and explores them in four case studies of possible future AI deployments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å‰æ²¿ AI éƒ¨ç½²ä¸­å®æ–½è‡ªåŠ¨åŒ– control monitoring çš„å®é™…æŒ‘æˆ˜ï¼Œæ—¨åœ¨ç›‘ç®¡ä¸å®Œå…¨å¯ä¿¡çš„é«˜èƒ½åŠ›æ™ºèƒ½ä½“ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œå°†ç›‘æ§æ‰©å±•åˆ°ç°å®éƒ¨ç½²ä¼šå¼•å…¥å¹¶è¡Œå®ä¾‹ã€ç›‘ç®¡å»¶è¿Ÿã€å¢é‡æ”»å‡»ä»¥åŠè¯†åˆ« scheming agents çš„éš¾åº¦ç­‰å¤æ‚åŠ¨æ€ã€‚ä½œè€…é‡ç‚¹åˆ†æäº†ä¸‰ç§å…·æœ‰ä¸åŒå»¶è¿Ÿä¸å®‰å…¨æ€§æƒè¡¡çš„ç›‘æ§åè®®ï¼Œå³ synchronousã€semi-synchronous å’Œ asynchronous monitoringï¼Œå¹¶å¼•å…¥äº† safety case sketch æ¡†æ¶ç”¨äºæ¯”è¾ƒè¿™äº›åè®®ã€‚é€šè¿‡å¯¹å››ä¸ªæœªæ¥ AI éƒ¨ç½²åœºæ™¯çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œæœ¬æ–‡ç¡®å®šäº† oversightã€latency å’Œ recovery ä¸‰å¤§æ ¸å¿ƒæŒ‘æˆ˜ã€‚è¿™äº›åˆ†æä¸ºè¯„ä¼°å’Œä¼˜åŒ–é«˜é£é™© AI ç¯å¢ƒä¸‹çš„ç›‘æ§ç­–ç•¥æä¾›äº†å…³é”®çš„è®¾è®¡è§è§£å’Œç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.22154v1",
      "published_date": "2025-12-15 15:54:36 UTC",
      "updated_date": "2025-12-15 15:54:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:55:54.019083+00:00"
    },
    {
      "arxiv_id": "2512.13438v1",
      "title": "From User Interface to Agent Interface: Efficiency Optimization of UI Representations for LLM Agents",
      "title_zh": "ä»ç”¨æˆ·ç•Œé¢åˆ°æ™ºèƒ½ä½“ç•Œé¢ï¼šé¢å‘ LLM æ™ºèƒ½ä½“çš„ UI è¡¨ç¤ºæ•ˆç‡ä¼˜åŒ–",
      "authors": [
        "Dezhi Ran",
        "Zhi Gong",
        "Yuzhe Guo",
        "Mengzhou Wu",
        "Yuan Cao",
        "Haochuan Lu",
        "Hengyu Zhang",
        "Xia Zeng",
        "Gang Cao",
        "Liangchao Yao",
        "Yuetang Deng",
        "Wei Yang",
        "Tao Xie"
      ],
      "abstract": "While Large Language Model (LLM) agents show great potential for automated UI navigation such as automated UI testing and AI assistants, their efficiency has been largely overlooked. Our motivating study reveals that inefficient UI representation creates a critical performance bottleneck. However, UI representation optimization, formulated as the task of automatically generating programs that transform UI representations, faces two unique challenges. First, the lack of Boolean oracles, which traditional program synthesis uses to decisively validate semantic correctness, poses a fundamental challenge to co-optimization of token efficiency and completeness. Second, the need to process large, complex UI trees as input while generating long, compositional transformation programs, making the search space vast and error-prone. Toward addressing the preceding limitations, we present UIFormer, the first automated optimization framework that synthesizes UI transformation programs by conducting constraint-based optimization with structured decomposition of the complex synthesis task. First, UIFormer restricts the program space using a domain-specific language (DSL) that captures UI-specific operations. Second, UIFormer conducts LLM-based iterative refinement with correctness and efficiency rewards, providing guidance for achieving the efficiency-completeness co-optimization. UIFormer operates as a lightweight plugin that applies transformation programs for seamless integration with existing LLM agents, requiring minimal modifications to their core logic. Evaluations across three UI navigation benchmarks spanning Android and Web platforms with five LLMs demonstrate that UIFormer achieves 48.7% to 55.8% token reduction with minimal runtime overhead while maintaining or improving agent performance. Real-world industry deployment at WeChat further validates the practical impact of UIFormer.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLM agents)åœ¨è‡ªåŠ¨ç”¨æˆ·ç•Œé¢å¯¼èˆª(UI navigation)ä¸­çš„æ•ˆç‡é—®é¢˜ï¼ŒæŒ‡å‡ºä½æ•ˆçš„UI representationsæ˜¯å…³é”®çš„æ€§èƒ½ç“¶é¢ˆã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†UIFormerï¼Œè¿™æ˜¯é¦–ä¸ªé€šè¿‡ç»“æ„åŒ–åˆ†è§£å’Œçº¦æŸä¼˜åŒ–æ¥è‡ªåŠ¨åˆæˆUIè½¬æ¢ç¨‹åºçš„æ¡†æ¶ã€‚UIFormeråˆ©ç”¨é’ˆå¯¹UIæ“ä½œè®¾è®¡çš„Domain-Specific Language (DSL) é™åˆ¶ç¨‹åºç©ºé—´ï¼Œå¹¶é€šè¿‡ç»“åˆæ­£ç¡®æ€§å’Œæ•ˆç‡å¥–åŠ±çš„è¿­ä»£ç²¾ç‚¼(iterative refinement)å®ç°tokenæ•ˆç‡ä¸å®Œæ•´æ€§çš„ååŒä¼˜åŒ–ã€‚ä½œä¸ºä¸€ç§è½»é‡çº§æ’ä»¶ï¼ŒUIFormerèƒ½æ— ç¼é›†æˆåˆ°ç°æœ‰LLM agentsä¸­ï¼Œä¸”å‡ ä¹ä¸éœ€ä¿®æ”¹æ ¸å¿ƒé€»è¾‘ã€‚å®éªŒè¡¨æ˜ï¼ŒUIFormeråœ¨Androidå’ŒWebå¹³å°ä¸Šå®ç°äº†48.7%è‡³55.8%çš„token reductionï¼Œä¸”åœ¨ä¿æŒæˆ–æå‡ä»£ç†æ€§èƒ½çš„åŒæ—¶ä»…äº§ç”Ÿæå°çš„è¿è¡Œæ—¶å¼€é”€ã€‚è¯¥æˆæœå·²åœ¨å¾®ä¿¡ç­‰çœŸå®å·¥ä¸šåœºæ™¯ä¸­å¾—åˆ°å®é™…éƒ¨ç½²å’ŒéªŒè¯ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13438v1",
      "published_date": "2025-12-15 15:34:06 UTC",
      "updated_date": "2025-12-15 15:34:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:54:29.120877+00:00"
    },
    {
      "arxiv_id": "2601.10718v1",
      "title": "Japanese AI Agent System on Human Papillomavirus Vaccination: System Design",
      "title_zh": "æ—¥æœ¬äººä¹³å¤´ç˜¤ç—…æ¯’ï¼ˆHPVï¼‰ç–«è‹—æ¥ç§ AI æ™ºèƒ½ä½“ç³»ç»Ÿï¼šç³»ç»Ÿè®¾è®¡",
      "authors": [
        "Junyu Liu",
        "Siwen Yang",
        "Dexiu Ma",
        "Qian Niu",
        "Zequn Zhang",
        "Momoko Nagai-Tanima",
        "Tomoki Aoyama"
      ],
      "abstract": "Human papillomavirus (HPV) vaccine hesitancy poses significant public health challenges, particularly in Japan where proactive vaccination recommendations were suspended from 2013 to 2021. The resulting information gap is exacerbated by misinformation on social media, and traditional ways cannot simultaneously address individual queries while monitoring population-level discourse. This study aimed to develop a dual-purpose AI agent system that provides verified HPV vaccine information through a conversational interface while generating analytical reports for medical institutions based on user interactions and social media. We implemented a system comprising: a vector database integrating academic papers, government sources, news media, and social media; a Retrieval-Augmented Generation chatbot using ReAct agent architecture with multi-tool orchestration across five knowledge sources; and an automated report generation system with modules for news analysis, research synthesis, social media sentiment analysis, and user interaction pattern identification. Performance was assessed using a 0-5 scoring scale. For single-turn evaluation, the chatbot achieved mean scores of 4.83 for relevance, 4.89 for routing, 4.50 for reference quality, 4.90 for correctness, and 4.88 for professional identity (overall 4.80). Multi-turn evaluation yielded higher scores: context retention 4.94, topic coherence 5.00, and overall 4.98. The report generation system achieved completeness 4.00-5.00, correctness 4.00-5.00, and helpfulness 3.67-5.00, with reference validity 5.00 across all periods. This study demonstrates the feasibility of an integrated AI agent system for bidirectional HPV vaccine communication. The architecture enables verified information delivery with source attribution while providing systematic public discourse analysis, with a transferable framework for adaptation to other medical contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶è®¾è®¡å¹¶å®ç°äº†ä¸€ä¸ªé’ˆå¯¹æ—¥æœ¬äººç±»ä¹³å¤´ç˜¤ç—…æ¯’(Human Papillomavirus, HPV)ç–«è‹—æ¥ç§çš„åŒåŠŸèƒ½AIæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œæ—¨åœ¨åº”å¯¹å› é•¿æœŸæš‚åœæ¥ç§å»ºè®®å’Œç¤¾äº¤åª’ä½“è¯¯å¯¼ä¿¡æ¯æ‰€å¼•å‘çš„å…¬å…±å¥åº·æŒ‘æˆ˜ã€‚è¯¥ç³»ç»Ÿæ•´åˆäº†å­¦æœ¯è®ºæ–‡ã€æ”¿åºœæ¥æºåŠç¤¾äº¤åª’ä½“ç­‰å¤šæºæ•°æ®çš„å‘é‡æ•°æ®åº“(Vector Database)ï¼Œåˆ©ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)æŠ€æœ¯å’ŒReActæ™ºèƒ½ä½“æ¶æ„ï¼Œå®ç°äº†èƒ½å¤Ÿæä¾›éªŒè¯ä¿¡æ¯çš„å¤šå·¥å…·ç¼–æ’èŠå¤©æœºå™¨äººã€‚æ­¤å¤–ï¼Œç³»ç»Ÿè¿˜å…·å¤‡è‡ªåŠ¨æŠ¥å‘Šç”ŸæˆåŠŸèƒ½ï¼Œå¯é’ˆå¯¹æ–°é—»ã€ç§‘ç ”åŠ¨æ€åŠç¤¾äº¤åª’ä½“æƒ…ç»ªè¿›è¡Œæ·±åº¦åˆ†æã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æœºå™¨äººåœ¨å•è½®å’Œå¤šè½®å¯¹è¯ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºè‰²ï¼Œç»¼åˆè¯„åˆ†åˆ†åˆ«è¾¾åˆ°4.80å’Œ4.98ï¼Œä¸”ç”Ÿæˆçš„åˆ†ææŠ¥å‘Šåœ¨æ­£ç¡®æ€§å’Œå‚è€ƒæ–‡çŒ®æœ‰æ•ˆæ€§æ–¹é¢å±•ç°äº†æé«˜çš„æ°´å¹³ã€‚è¯¥é¡¹å·¥ä½œä¸ä»…éªŒè¯äº†AIæ™ºèƒ½ä½“åœ¨HPVç–«è‹—åŒå‘æ²Ÿé€šä¸­çš„å¯è¡Œæ€§ï¼Œè¿˜ä¸ºåŒ»ç–—é¢†åŸŸçš„å…¬å…±èˆ†è®ºç›‘æ§ä¸ç²¾å‡†ä¿¡æ¯ä¼ æ’­æä¾›äº†ä¸€ä¸ªå¯è¿ç§»çš„æŠ€æœ¯æ¡†æ¶ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.10718v1",
      "published_date": "2025-12-15 15:13:22 UTC",
      "updated_date": "2025-12-15 15:13:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:54:59.139827+00:00"
    },
    {
      "arxiv_id": "2512.13765v1",
      "title": "Towards Deep Learning Surrogate for the Forward Problem in Electrocardiology: A Scalable Alternative to Physics-Based Models",
      "title_zh": "å¿ƒç”µç”Ÿç†å­¦æ­£å‘é—®é¢˜çš„æ·±åº¦å­¦ä¹ ä»£ç†æ¨¡å‹ï¼šä¸€ç§åŸºäºç‰©ç†æ¨¡å‹çš„å¯æ‰©å±•æ›¿ä»£æ–¹æ¡ˆ",
      "authors": [
        "Shaheim Ogbomo-Harmitt",
        "Cesare Magnetti",
        "Chiara Spota",
        "Jakub Grzelak",
        "Oleg Aslanidi"
      ],
      "abstract": "The forward problem in electrocardiology, computing body surface potentials from cardiac electrical activity, is traditionally solved using physics-based models such as the bidomain or monodomain equations. While accurate, these approaches are computationally expensive, limiting their use in real-time and large-scale clinical applications. We propose a proof-of-concept deep learning (DL) framework as an efficient surrogate for forward solvers. The model adopts a time-dependent, attention-based sequence-to-sequence architecture to predict electrocardiogram (ECG) signals from cardiac voltage propagation maps. A hybrid loss combining Huber loss with a spectral entropy term was introduced to preserve both temporal and frequency-domain fidelity. Using 2D tissue simulations incorporating healthy, fibrotic, and gap junction-remodelled conditions, the model achieved high accuracy (mean $R^2 = 0.99 \\pm 0.01$). Ablation studies confirmed the contributions of convolutional encoders, time-aware attention, and spectral entropy loss. These findings highlight DL as a scalable, cost-effective alternative to physics-based solvers, with potential for clinical and digital twin applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µå¿ƒå­¦å‰å‘é—®é¢˜(forward problem)ä¸­ä¼ ç»Ÿç‰©ç†æ¨¡å‹è®¡ç®—æˆæœ¬é«˜æ˜‚çš„å±€é™ï¼Œæå‡ºäº†ä¸€ç§æ·±åº¦å­¦ä¹ (Deep Learning)æ¡†æ¶ä½œä¸ºé«˜æ•ˆçš„æ›¿ä»£æ±‚è§£å™¨ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†åŸºäºæ—¶é—´æ„ŸçŸ¥å’Œæ³¨æ„åŠ›æœºåˆ¶çš„åºåˆ—åˆ°åºåˆ—(sequence-to-sequence)æ¶æ„ï¼Œèƒ½å¤Ÿé€šè¿‡å¿ƒè„ç”µå‹ä¼ æ’­å›¾ç›´æ¥é¢„æµ‹å¿ƒç”µå›¾(ECG)ä¿¡å·ã€‚ä¸ºäº†ç¡®ä¿ä¿¡å·åœ¨æ—¶åŸŸå’Œé¢‘åŸŸçš„é«˜åº¦ä¿çœŸï¼Œç ”ç©¶è€…å¼•å…¥äº†ç»“åˆHuber lossä¸è°±ç†µ(spectral entropy)é¡¹çš„æ··åˆæŸå¤±å‡½æ•°ã€‚åœ¨é’ˆå¯¹å¥åº·ã€çº¤ç»´åŒ–(fibrotic)åŠç¼éš™è¿æ¥é‡å¡‘(gap junction-remodelled)ç­‰å¤šç§ç—…ç†æ¡ä»¶çš„æ¨¡æ‹Ÿå®éªŒä¸­ï¼Œè¯¥æ¨¡å‹å®ç°äº†æé«˜çš„é¢„æµ‹ç²¾åº¦ï¼Œå¹³å‡$R^2$è¾¾åˆ°0.99 Â± 0.01ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†å·ç§¯ç¼–ç å™¨ä¸æ³¨æ„åŠ›æœºåˆ¶çš„å…³é”®ä½œç”¨ï¼Œè¯æ˜äº†æ·±åº¦å­¦ä¹ æ˜¯ç‰©ç†æ¨¡å‹çš„ä¸€ç§å¯æ‰©å±•ä¸”å…·æˆæœ¬æ•ˆç›Šçš„æ›¿ä»£æ–¹æ¡ˆï¼Œåœ¨ä¸´åºŠè¯Šæ–­ä¸æ•°å­—å­ªç”Ÿ(digital twin)é¢†åŸŸå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted to CinC conference 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.13765v1",
      "published_date": "2025-12-15 15:09:53 UTC",
      "updated_date": "2025-12-15 15:09:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:55:10.910922+00:00"
    },
    {
      "arxiv_id": "2512.13402v1",
      "title": "End2Reg: Learning Task-Specific Segmentation for Markerless Registration in Spine Surgery",
      "title_zh": "End2Regï¼šé¢å‘è„ŠæŸ±æ‰‹æœ¯æ— æ ‡è®°é…å‡†çš„ä»»åŠ¡ç‰¹å®šåˆ†å‰²å­¦ä¹ ",
      "authors": [
        "Lorenzo Pettinari",
        "Sidaty El Hadramy",
        "Michael Wehrli",
        "Philippe C. Cattin",
        "Daniel Studer",
        "Carol C. Hasler",
        "Maria Licci"
      ],
      "abstract": "Purpose: Intraoperative navigation in spine surgery demands millimeter-level accuracy. Current systems based on intraoperative radiographic imaging and bone-anchored markers are invasive, radiation-intensive and workflow disruptive. Recent markerless RGB-D registration methods offer a promising alternative, but existing approaches rely on weak segmentation labels to isolate relevant anatomical structures, which can propagate errors throughout registration. Methods: We present End2Reg an end-to-end deep learning framework that jointly optimizes segmentation and registration, eliminating the need for weak segmentation labels and manual steps. The network learns segmentation masks specifically optimized for registration, guided solely by the registration objective without direct segmentation supervision. Results: The proposed framework achieves state-of-the-art performance on ex- and in-vivo benchmarks, reducing median Target Registration Error by 32% to 1.83mm and mean Root Mean Square Error by 45% to 3.95mm, respectively. An ablation study confirms that end-to-end optimization significantly improves registration accuracy. Conclusion: The presented end-to-end RGB-D registration pipeline removes dependency on weak labels and manual steps, advancing towards fully automatic, markerless intraoperative navigation. Code and interactive visualizations are available at: https://lorenzopettinari.github.io/end-2-reg/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† End2Regï¼Œè¿™æ˜¯ä¸€ç§ç«¯åˆ°ç«¯ï¼ˆEnd-to-endï¼‰æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡è”åˆä¼˜åŒ–åˆ†å‰²ï¼ˆSegmentationï¼‰å’Œé…å‡†ï¼ˆRegistrationï¼‰æ¥è§£å†³è„ŠæŸ±æ‰‹æœ¯ä¸­æ— æ ‡è®°ï¼ˆMarkerlessï¼‰RGB-D é…å‡†çš„ç²¾åº¦é—®é¢˜ã€‚è¯¥æ¡†æ¶æ‘†è„±äº†ç°æœ‰æ–¹æ³•å¯¹å¼±åˆ†å‰²æ ‡ç­¾ï¼ˆWeak segmentation labelsï¼‰çš„ä¾èµ–ï¼Œé€šè¿‡é…å‡†ç›®æ ‡å‡½æ•°å¼•å¯¼æ¨¡å‹è‡ªåŠ¨å­¦ä¹ æœ€æœ‰åˆ©äºé…å‡†ä»»åŠ¡çš„åˆ†å‰²æ©è†œï¼ˆSegmentation masksï¼‰ï¼Œæ— éœ€ç›´æ¥çš„åˆ†å‰²ç›‘ç£ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEnd2Reg åœ¨ç¦»ä½“å’Œä½“å†…å®éªŒä¸­å‡è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå°†ä¸­ä½ç›®æ ‡é…å‡†è¯¯å·®ï¼ˆTarget Registration Errorï¼‰é™ä½äº† 32% è‡³ 1.83mmï¼Œå‡æ–¹æ ¹è¯¯å·®ï¼ˆRoot Mean Square Errorï¼‰é™ä½äº† 45%ã€‚æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¯å®ï¼Œè¿™ç§ç«¯åˆ°ç«¯ä¼˜åŒ–ç­–ç•¥æ˜¾è‘—æå‡äº†é…å‡†ç²¾åº¦ã€‚è¯¥ç ”ç©¶ä¸ä»…æ¶ˆé™¤äº†æ‰‹åŠ¨æ“ä½œå’Œå¼±æ ‡ç­¾çš„é™åˆ¶ï¼Œè¿˜ä¸ºå®ç°å…¨è‡ªåŠ¨ã€æ— æ ‡è®°çš„æœ¯ä¸­å¯¼èˆªå¥ å®šäº†é‡è¦æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Code and interactive visualizations: https://lorenzopettinari.github.io/end-2-reg/",
      "pdf_url": "https://arxiv.org/pdf/2512.13402v1",
      "published_date": "2025-12-15 14:53:20 UTC",
      "updated_date": "2025-12-15 14:53:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:55:22.443165+00:00"
    },
    {
      "arxiv_id": "2512.13399v1",
      "title": "Differentiable Evolutionary Reinforcement Learning",
      "title_zh": "å¯å¾®åˆ†è¿›åŒ–å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Sitao Cheng",
        "Tianle Li",
        "Xuhan Huang",
        "Xunjian Yin",
        "Difan Zou"
      ],
      "abstract": "The design of effective reward functions presents a central and often arduous challenge in reinforcement learning (RL), particularly when developing autonomous agents for complex reasoning tasks. While automated reward optimization approaches exist, they typically rely on derivative-free evolutionary heuristics that treat the reward function as a black box, failing to capture the causal relationship between reward structure and task performance. To bridge this gap, we propose Differentiable Evolutionary Reinforcement Learning (DERL), a bilevel framework that enables the autonomous discovery of optimal reward signals. In DERL, a Meta-Optimizer evolves a reward function (i.e., Meta-Reward) by composing structured atomic primitives, guiding the training of an inner-loop policy. Crucially, unlike previous evolution, DERL is differentiable in its metaoptimization: it treats the inner-loop validation performance as a signal to update the Meta-Optimizer via reinforcement learning. This allows DERL to approximate the \"meta-gradient\" of task success, progressively learning to generate denser and more actionable feedback. We validate DERL across three distinct domains: robotic agent (ALFWorld), scientific simulation (ScienceWorld), and mathematical reasoning (GSM8k, MATH). Experimental results show that DERL achieves state-of-the-art performance on ALFWorld and ScienceWorld, significantly outperforming methods relying on heuristic rewards, especially in out-of-distribution scenarios. Analysis of the evolutionary trajectory demonstrates that DERL successfully captures the intrinsic structure of tasks, enabling selfimproving agent alignment without human intervention.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Differentiable Evolutionary Reinforcement Learning (DERL)ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒå±‚æ¡†æ¶(bilevel framework)ï¼Œæ—¨åœ¨è§£å†³å¼ºåŒ–å­¦ä¹ (Reinforcement Learning, RL)ä¸­å¤æ‚æ¨ç†ä»»åŠ¡å¥–åŠ±å‡½æ•°(reward function)è®¾è®¡å›°éš¾çš„é—®é¢˜ã€‚DERLé€šè¿‡Meta-Optimizerç»„åˆç»“æ„åŒ–çš„åŸå­åŸè¯­(atomic primitives)æ¥æ¼”åŒ–å…ƒå¥–åŠ±(Meta-Reward)ï¼Œä»è€Œå¼•å¯¼å†…ç¯ç­–ç•¥(inner-loop policy)çš„è®­ç»ƒã€‚ä¸ä¼ ç»Ÿçš„è¿›åŒ–ç®—æ³•ä¸åŒï¼ŒDERLåœ¨å…ƒä¼˜åŒ–è¿‡ç¨‹ä¸­å…·æœ‰å¯å¾®æ€§(differentiable)ï¼Œå®ƒå°†å†…ç¯éªŒè¯æ€§èƒ½ä½œä¸ºä¿¡å·å¹¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ æ›´æ–°Meta-Optimizerï¼Œä»è€Œæœ‰æ•ˆè¿‘ä¼¼ä»»åŠ¡æˆåŠŸçš„å…ƒæ¢¯åº¦(meta-gradient)ã€‚è¿™ç§æœºåˆ¶ä½¿æ¨¡å‹èƒ½å¤Ÿé€æ­¥ç”Ÿæˆæ›´å¯†é›†ä¸”æ›´å…·æ“ä½œæ€§çš„åé¦ˆï¼Œå¹¶åœ¨æ— éœ€äººå·¥å¹²é¢„çš„æƒ…å†µä¸‹æ•æ‰ä»»åŠ¡å†…åœ¨ç»“æ„ä»¥å®ç°æ™ºèƒ½ä½“çš„è‡ªæˆ‘æ”¹è¿›å¯¹é½ã€‚å®éªŒåœ¨æœºå™¨äººæ™ºèƒ½ä½“(ALFWorld)ã€ç§‘å­¦æ¨¡æ‹Ÿ(ScienceWorld)åŠæ•°å­¦æ¨ç†(GSM8k, MATH)ç­‰å¤šä¸ªé¢†åŸŸéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚ç»“æœè¡¨æ˜ï¼ŒDERLåœ¨ALFWorldå’ŒScienceWorldä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œå°¤å…¶åœ¨åˆ†å¸ƒå¤–(out-of-distribution)åœºæ™¯ä¸­æ˜¾è‘—ä¼˜äºä¾èµ–å¯å‘å¼å¥–åŠ±çš„ç°æœ‰æ–¹æ³•ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Work in Progress. We release our code and model at https://github.com/sitaocheng/DERL",
      "pdf_url": "https://arxiv.org/pdf/2512.13399v1",
      "published_date": "2025-12-15 14:50:08 UTC",
      "updated_date": "2025-12-15 14:50:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:56:19.828259+00:00"
    },
    {
      "arxiv_id": "2512.13764v1",
      "title": "Mathematics and Coding are Universal AI Benchmarks",
      "title_zh": "æ•°å­¦ä¸ç¼–ç¨‹æ˜¯é€šç”¨çš„äººå·¥æ™ºèƒ½åŸºå‡†",
      "authors": [
        "Przemyslaw Chojecki"
      ],
      "abstract": "We study the special role of mathematics and coding inside the moduli space of psychometric batteries for AI agents. Building on the AAI framework and GVU dynamics from previous works, we define the Mathematics Fiber and show that, when paired with formal proof kernels (e.g. Lean, Coq), GVU flows on this fiber admit spectrally stable self-improvement regimes due to oracle-like verification. Our main technical result is a density theorem: under uniform tightness of agent outputs and a Lipschitz AAI functional, the subspace of batteries generated by mathematical theorem-proving and coding tasks is dense in the moduli space of batteries with respect to the evaluation metric. Coding alone is universal in this sense, while pure mathematics is not; its privilege is spectral rather than expressive. We interpret this as evidence that mathematics and coding provide ``universal coordinates'' for evaluation, and that formal mathematics is a natural ignition domain for recursive self-improvement in advanced AI agents.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†æ•°å­¦å’Œç¼–ç¨‹åœ¨AIæ™ºèƒ½ä½“å¿ƒç†æµ‹é‡ç”µæ± (psychometric batteries)æ¨¡ç©ºé—´ä¸­çš„ç‰¹æ®Šä½œç”¨ã€‚åŸºäºAAIæ¡†æ¶å’ŒGVUåŠ¨åŠ›å­¦ï¼Œä½œè€…å®šä¹‰äº†Mathematics Fiberï¼Œå¹¶å±•ç¤ºäº†å½“å…¶ä¸Leanã€Coqç­‰å½¢å¼åŒ–è¯æ˜å†…æ ¸ç»“åˆæ—¶ï¼Œç”±äºå…·å¤‡ç±»ä¼¼å…ˆçŸ¥(oracle-like)çš„éªŒè¯æœºåˆ¶ï¼Œè¯¥çº¤ç»´ä¸Šçš„GVUæµå¯ä»¥å®ç°è°±ç¨³å®šçš„è‡ªæˆ‘æ”¹è¿›(self-improvement)æ–¹æ¡ˆã€‚ç ”ç©¶çš„æ ¸å¿ƒæŠ€æœ¯æˆæœæ˜¯ä¸€é¡¹å¯†åº¦å®šç†(density theorem)ï¼Œè¯æ˜äº†åœ¨æ»¡è¶³ç‰¹å®šæ•°å­¦æ¡ä»¶ä¸‹ï¼Œç”±æ•°å­¦è¯æ˜å’Œç¼–ç¨‹ä»»åŠ¡ç”Ÿæˆçš„ç”µæ± å­ç©ºé—´åœ¨è¯„ä¼°åº¦é‡ä¸­å…·æœ‰ç¨ å¯†æ€§ã€‚ç»“æœè¡¨æ˜ï¼Œç¼–ç¨‹åœ¨è¿™ä¸€æ„ä¹‰ä¸Šå…·æœ‰é€šç”¨æ€§(universal)ï¼Œè€Œçº¯æ•°å­¦çš„ä¼˜åŠ¿åˆ™ä½“ç°åœ¨å…¶è°±ç‰¹å¾è€Œéè¡¨è¾¾èƒ½åŠ›ä¸Šã€‚è¿™ä¸ºæ•°å­¦å’Œç¼–ç¨‹ä½œä¸ºAIè¯„ä¼°çš„â€œé€šç”¨åæ ‡â€(universal coordinates)æä¾›äº†è¯æ®ï¼Œå¹¶æŒ‡å‡ºå½¢å¼åŒ–æ•°å­¦æ˜¯é«˜çº§AIæ™ºèƒ½ä½“å®ç°é€’å½’è‡ªæˆ‘æ”¹è¿›çš„å¤©ç„¶ç‚¹ç«åŸŸã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13764v1",
      "published_date": "2025-12-15 14:36:29 UTC",
      "updated_date": "2025-12-15 14:36:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:56:10.644459+00:00"
    },
    {
      "arxiv_id": "2512.13374v1",
      "title": "Behavior and Representation in Large Language Models for Combinatorial Optimization: From Feature Extraction to Algorithm Selection",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹åœ¨ç»„åˆä¼˜åŒ–ä¸­çš„è¡Œä¸ºä¸è¡¨ç¤ºï¼šä»ç‰¹å¾æå–åˆ°ç®—æ³•é€‰æ‹©",
      "authors": [
        "Francesca Da Ros",
        "Luca Di Gaspero",
        "Kevin Roitero"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have opened new perspectives for automation in optimization. While several studies have explored how LLMs can generate or solve optimization models, far less is understood about what these models actually learn regarding problem structure or algorithmic behavior. This study investigates how LLMs internally represent combinatorial optimization problems and whether such representations can support downstream decision tasks. We adopt a twofold methodology combining direct querying, which assesses LLM capacity to explicitly extract instance features, with probing analyses that examine whether such information is implicitly encoded within their hidden layers. The probing framework is further extended to a per-instance algorithm selection task, evaluating whether LLM-derived representations can predict the best-performing solver. Experiments span four benchmark problems and three instance representations. Results show that LLMs exhibit moderate ability to recover feature information from problem instances, either through direct querying or probing. Notably, the predictive power of LLM hidden-layer representations proves comparable to that achieved through traditional feature extraction, suggesting that LLMs capture meaningful structural information relevant to optimization performance.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç»„åˆä¼˜åŒ–(Combinatorial Optimization)ä¸­çš„å†…éƒ¨è¡¨å¾åŠå…¶å¯¹å†³ç­–ä»»åŠ¡çš„æ”¯æŒèƒ½åŠ›ï¼Œæ—¨åœ¨æ­ç¤ºè¿™äº›æ¨¡å‹å¯¹é—®é¢˜ç»“æ„å’Œç®—æ³•è¡Œä¸ºçš„å­¦ä¹ æœºåˆ¶ã€‚ç ”ç©¶é‡‡ç”¨äº†ä¸€ç§åŒé‡æ–¹æ³•è®ºï¼Œç»“åˆäº†è¯„ä¼°æ˜¾å¼ç‰¹å¾æå–èƒ½åŠ›çš„ç›´æ¥æŸ¥è¯¢(Direct Querying)ä¸åˆ†æéšè—å±‚éšå«ä¿¡æ¯çš„æ¢æµ‹åˆ†æ(Probing Analyses)ã€‚è¯¥æ¡†æ¶è¢«è¿›ä¸€æ­¥åº”ç”¨äºæ¯å®ä¾‹ç®—æ³•é€‰æ‹©(Algorithm Selection)ä»»åŠ¡ï¼Œä»¥æµ‹è¯•æ¨¡å‹è¡¨å¾é¢„æµ‹æœ€ä½³æ±‚è§£å™¨çš„æ•ˆåŠ›ã€‚é€šè¿‡å¯¹å››ä¸ªåŸºå‡†é—®é¢˜å’Œä¸‰ç§å®ä¾‹è¡¨å¾çš„å®éªŒï¼Œç ”ç©¶å‘ç°LLMsåœ¨é€šè¿‡æŸ¥è¯¢æˆ–æ¢æµ‹æ¢å¤ç‰¹å¾ä¿¡æ¯æ–¹é¢è¡¨ç°å‡ºä¸­ç­‰æ°´å¹³çš„èƒ½åŠ›ã€‚å®éªŒç»“æœå¼ºè°ƒï¼ŒLLMéšè—å±‚è¡¨å¾çš„é¢„æµ‹èƒ½åŠ›ä¸ä¼ ç»Ÿç‰¹å¾æå–æ–¹æ³•ç›¸å½“ï¼Œè¯æ˜äº†LLMsèƒ½å¤Ÿæ•æ‰åˆ°ä¸ä¼˜åŒ–æ€§èƒ½ç›¸å…³çš„å…³é”®ç»“æ„ä¿¡æ¯ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13374v1",
      "published_date": "2025-12-15 14:28:35 UTC",
      "updated_date": "2025-12-15 14:28:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:56:12.362411+00:00"
    },
    {
      "arxiv_id": "2512.13363v1",
      "title": "Detecting Emotion Drift in Mental Health Text Using Pre-Trained Transformers",
      "title_zh": "åŸºäºé¢„è®­ç»ƒ Transformer çš„å¿ƒç†å¥åº·æ–‡æœ¬æƒ…ç»ªæ¼‚ç§»æ£€æµ‹",
      "authors": [
        "Shibani Sankpal"
      ],
      "abstract": "This study investigates emotion drift: the change in emotional state across a single text, within mental health-related messages. While sentiment analysis typically classifies an entire message as positive, negative, or neutral, the nuanced shift of emotions over the course of a message is often overlooked. This study detects sentence-level emotions and measures emotion drift scores using pre-trained transformer models such as DistilBERT and RoBERTa. The results provide insights into patterns of emotional escalation or relief in mental health conversations. This methodology can be applied to better understand emotional dynamics in content.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¿ƒç†å¥åº·ç›¸å…³æ–‡æœ¬ä¸­çš„æƒ…ç»ªæ¼‚ç§»(Emotion Drift)ç°è±¡ï¼Œå³å•ç¯‡æ–‡æœ¬ä¸­æƒ…æ„ŸçŠ¶æ€éšå†…å®¹æ¨è¿›è€Œäº§ç”Ÿçš„åŠ¨æ€å˜åŒ–è¿‡ç¨‹ã€‚ä¼ ç»Ÿæƒ…æ„Ÿåˆ†æé€šå¸¸å°†æ•´æ¡ä¿¡æ¯å½’ç±»ä¸ºå•ä¸€çš„æƒ…æ„Ÿç±»åˆ«ï¼Œå¾€å¾€å¿½ç•¥äº†ä¿¡æ¯å†…éƒ¨å¥å­ä¹‹é—´å¾®å¦™çš„æƒ…ç»ªæ³¢åŠ¨ã€‚ä¸ºäº†æ•æ‰è¿™ç§ç»†å¾®å˜åŒ–ï¼Œç ”ç©¶äººå‘˜åˆ©ç”¨DistilBERTå’ŒRoBERTaç­‰é¢„è®­ç»ƒè½¬æ¢å™¨æ¨¡å‹(Pre-Trained Transformers)æ‰§è¡Œå¥å­çº§åˆ«çš„æƒ…ç»ªæ£€æµ‹ï¼Œå¹¶ä»¥æ­¤è¡¡é‡æƒ…ç»ªæ¼‚ç§»åˆ†å€¼ã€‚å®éªŒç»“æœæ­ç¤ºäº†å¿ƒç†å¥åº·å¯¹è¯ä¸­æƒ…ç»ªå‡çº§(Escalation)æˆ–æƒ…ç»ªç¼“è§£(Relief)çš„ç‰¹å®šæ¨¡å¼ã€‚è¯¥æ–¹æ³•è®ºä¸ºæ·±å…¥ç†è§£æ–‡æœ¬å†…å®¹ä¸­çš„æƒ…ç»ªåŠ¨æ€æä¾›äº†æœ‰æ•ˆæ‰‹æ®µï¼Œèƒ½å¤Ÿæ›´ç²¾å‡†åœ°è¯†åˆ«å¿ƒç†å¥åº·å¯¹è¯ä¸­çš„æƒ…æ„Ÿæ¼”å˜è§„å¾‹ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 12 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.13363v1",
      "published_date": "2025-12-15 14:18:12 UTC",
      "updated_date": "2025-12-15 14:18:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:56:40.841357+00:00"
    },
    {
      "arxiv_id": "2512.13356v1",
      "title": "Control of a Twin Rotor using Twin Delayed Deep Deterministic Policy Gradient (TD3)",
      "title_zh": "åŸºäºåŒå»¶è¿Ÿæ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ (TD3) çš„åŒæ—‹ç¿¼ç³»ç»Ÿæ§åˆ¶",
      "authors": [
        "Zeyad Gamal",
        "Youssef Mahran",
        "Ayman El-Badawy"
      ],
      "abstract": "This paper proposes a reinforcement learning (RL) framework for controlling and stabilizing the Twin Rotor Aerodynamic System (TRAS) at specific pitch and azimuth angles and tracking a given trajectory. The complex dynamics and non-linear characteristics of the TRAS make it challenging to control using traditional control algorithms. However, recent developments in RL have attracted interest due to their potential applications in the control of multirotors. The Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm was used in this paper to train the RL agent. This algorithm is used for environments with continuous state and action spaces, similar to the TRAS, as it does not require a model of the system. The simulation results illustrated the effectiveness of the RL control method. Next, external disturbances in the form of wind disturbances were used to test the controller's effectiveness compared to conventional PID controllers. Lastly, experiments on a laboratory setup were carried out to confirm the controller's effectiveness in real-world applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒæ—‹ç¿¼ç©ºæ°”åŠ¨åŠ›å­¦ç³»ç»Ÿ (Twin Rotor Aerodynamic System, TRAS) å¤æ‚çš„éçº¿æ€§åŠ¨åŠ›å­¦ç‰¹æ€§ï¼Œæå‡ºäº†ä¸€ç§å¼ºåŒ–å­¦ä¹  (Reinforcement Learning, RL) æ§åˆ¶æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°ç‰¹å®šä¿¯ä»°è§’å’Œæ–¹ä½è§’çš„ç¨³å®šæ§åˆ¶åŠè½¨è¿¹è·Ÿè¸ªã€‚ç ”ç©¶é‡‡ç”¨äº†åŒå»¶è¿Ÿæ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ (Twin Delayed Deep Deterministic Policy Gradient, TD3) ç®—æ³•æ¥è®­ç»ƒ RL æ™ºèƒ½ä½“ï¼Œè¯¥ç®—æ³•æ— éœ€ç³»ç»Ÿæ¨¡å‹ä¸”èƒ½æœ‰æ•ˆå¤„ç†è¿ç»­çš„çŠ¶æ€å’ŒåŠ¨ä½œç©ºé—´ã€‚ä»¿çœŸç»“æœè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œåœ¨åº”å¯¹é£åŠ›ç­‰å¤–éƒ¨å¹²æ‰°æµ‹è¯•æ—¶ï¼Œå…¶è¡¨ç°ä¼˜äºä¼ ç»Ÿçš„ PID æ§åˆ¶å™¨ã€‚æœ€åï¼Œé€šè¿‡åœ¨å®éªŒå®¤ç¡¬ä»¶è£…ç½®ä¸Šè¿›è¡Œçš„å®éªŒï¼Œè¿›ä¸€æ­¥éªŒè¯äº†è¯¥æ§åˆ¶å™¨åœ¨å®é™…åº”ç”¨ç¯å¢ƒä¸­çš„å¯é æ€§ä¸ç¨³å®šæ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "This is the Author Accepted Manuscript version of a paper accepted for publication. The final published version is available via IEEE Xplore",
      "pdf_url": "https://arxiv.org/pdf/2512.13356v1",
      "published_date": "2025-12-15 14:10:04 UTC",
      "updated_date": "2025-12-15 14:10:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:56:27.716478+00:00"
    },
    {
      "arxiv_id": "2512.13762v1",
      "title": "State-Dependent Refusal and Learned Incapacity in RLHF-Aligned Language Models",
      "title_zh": "RLHF å¯¹é½è¯­è¨€æ¨¡å‹ä¸­çš„çŠ¶æ€ä¾èµ–æ€§æ‹’ç»ä¸ä¹ å¾—æ€§æ— èƒ½",
      "authors": [
        "TK Lee"
      ],
      "abstract": "Large language models (LLMs) are widely deployed as general-purpose tools, yet extended interaction can reveal behavioral patterns not captured by standard quantitative benchmarks. We present a qualitative case-study methodology for auditing policy-linked behavioral selectivity in long-horizon interaction. In a single 86-turn dialogue session, the same model shows Normal Performance (NP) in broad, non-sensitive domains while repeatedly producing Functional Refusal (FR) in provider- or policy-sensitive domains, yielding a consistent asymmetry between NP and FR across domains. Drawing on learned helplessness as an analogy, we introduce learned incapacity (LI) as a behavioral descriptor for this selective withholding without implying intentionality or internal mechanisms. We operationalize three response regimes (NP, FR, Meta-Narrative; MN) and show that MN role-framing narratives tend to co-occur with refusals in the same sensitive contexts. Overall, the study proposes an interaction-level auditing framework based on observable behavior and motivates LI as a lens for examining potential alignment side effects, warranting further investigation across users and models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç»è¿‡RLHFå¯¹é½çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œæå‡ºäº†ä¸€ç§å®šæ€§æ¡ˆä¾‹ç ”ç©¶æ–¹æ³•ï¼Œç”¨äºå®¡è®¡é•¿ç¨‹äº¤äº’ä¸­ç”±ç­–ç•¥é©±åŠ¨çš„è¡Œä¸ºé€‰æ‹©æ€§ã€‚é€šè¿‡å¯¹ä¸€ä¸ªåŒ…å«86è½®å¯¹è¯çš„ä¼šè¯è¿›è¡Œåˆ†æï¼Œç ”ç©¶å‘ç°æ¨¡å‹åœ¨éæ•æ„Ÿé¢†åŸŸè¡¨ç°å‡ºNormal Performance (NP)ï¼Œä½†åœ¨æ¶‰åŠæä¾›å•†æˆ–ç­–ç•¥æ•æ„Ÿé¢†åŸŸæ—¶åˆ™é¢‘ç¹å‡ºç°Functional Refusal (FR)ï¼Œåœ¨ä¸åŒé¢†åŸŸé—´å‘ˆç°å‡ºæ˜¾è‘—çš„æ€§èƒ½ä¸å¯¹ç§°ã€‚å€Ÿç”¨å¿ƒç†å­¦ä¸­ä¹ å¾—æ€§æ— åŠ©çš„æ¦‚å¿µï¼Œä½œè€…å¼•å…¥äº†Learned Incapacity (LI) è¿™ä¸€æœ¯è¯­ï¼Œç”¨ä»¥æè¿°æ¨¡å‹åœ¨ç‰¹å®šæƒ…å¢ƒä¸‹é€‰æ‹©æ€§ä¿ç•™èƒ½åŠ›çš„è¡Œä¸ºç‰¹å¾è€Œä¸æš—ç¤ºå…¶å…·æœ‰ä¸»è§‚æ„å›¾ã€‚ç ”ç©¶è¿›ä¸€æ­¥ç•Œå®šäº†NPã€FRåŠMeta-Narrative (MN) ä¸‰ç§å“åº”çŠ¶æ€ï¼Œå¹¶è§‚å¯Ÿåˆ°MNè§’è‰²æ¡†æ¶å™äº‹é€šå¸¸ä¸æ•æ„Ÿä¸Šä¸‹æ–‡ä¸­çš„æ‹’ç»è¡Œä¸ºå…±åŒå‡ºç°ã€‚è¯¥ç ”ç©¶æœ€ç»ˆå»ºç«‹äº†ä¸€ä¸ªåŸºäºå¯è§‚å¯Ÿè¡Œä¸ºçš„äº¤äº’çº§å®¡è®¡æ¡†æ¶ï¼Œå¹¶å°†LIä½œä¸ºå®¡è§†AIå¯¹é½å‰¯ä½œç”¨çš„å…³é”®è§†è§’ï¼Œä¸ºåç»­è·¨æ¨¡å‹ä¸è·¨ç”¨æˆ·çš„è¡Œä¸ºç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 6 figures. Qualitative interaction-level analysis of response patterns in a large language model. Code and processed interaction data are available at https://github.com/theMaker-EnvData/llm_learned_incapacity_corpus",
      "pdf_url": "https://arxiv.org/pdf/2512.13762v1",
      "published_date": "2025-12-15 14:00:15 UTC",
      "updated_date": "2025-12-15 14:00:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:56:35.109275+00:00"
    },
    {
      "arxiv_id": "2512.13330v1",
      "title": "FIN-bench-v2: A Unified and Robust Benchmark Suite for Evaluating Finnish Large Language Models",
      "title_zh": "FIN-bench-v2ï¼šç”¨äºè¯„ä¼°èŠ¬å…°è¯­å¤§è¯­è¨€æ¨¡å‹çš„ç»Ÿä¸€ä¸”ç¨³å¥çš„åŸºå‡†æµ‹è¯•é›†",
      "authors": [
        "Joona KytÃ¶niemi",
        "Jousia Piha",
        "Akseli Reunamo",
        "Fedor Vitiugin",
        "Farrokh Mehryary",
        "Sampo Pyysalo"
      ],
      "abstract": "We introduce FIN-bench-v2, a unified benchmark suite for evaluating large language models in Finnish. FIN-bench-v2 consolidates Finnish versions of widely used benchmarks together with an updated and expanded version of the original FIN-bench into a single, consistently formatted collection, covering multiple-choice and generative tasks across reading comprehension, commonsense reasoning, sentiment analysis, world knowledge, and alignment. All datasets are converted to HuggingFace Datasets, which include both cloze and multiple-choice prompt formulations with five variants per task, and we incorporate human annotation or review for machine-translated resources such as GoldenSwag and XED. To select robust tasks, we pretrain a set of 2.15B-parameter decoder-only models and use their learning curves to compute monotonicity, signal-to-noise, non-random performance, and model ordering consistency, retaining only tasks that satisfy all criteria. We further evaluate a set of larger instruction-tuned models to characterize performance across tasks and prompt formulations. All datasets, prompts, and evaluation configurations are publicly available via our fork of the Language Model Evaluation Harness at https://github.com/LumiOpen/lm-evaluation-harness. Supplementary resources are released in a separate repository at https://github.com/TurkuNLP/FIN-bench-v2.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†FIN-bench-v2ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°èŠ¬å…°è¯­å¤§è¯­è¨€æ¨¡å‹(Large Language Models)çš„ç»Ÿä¸€ä¸”é²æ£’çš„åŸºå‡†æµ‹è¯•å¥—ä»¶ã€‚è¯¥å¥—ä»¶æ•´åˆäº†å¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•çš„èŠ¬å…°è¯­ç‰ˆæœ¬ä»¥åŠåŸå§‹FIN-benchçš„å¢å¼ºç‰ˆï¼Œæ¶µç›–äº†é˜…è¯»ç†è§£ã€å¸¸è¯†æ¨ç†ã€æƒ…æ„Ÿåˆ†æã€ä¸–ç•ŒçŸ¥è¯†å’Œå¯¹é½(alignment)ç­‰å¤šç§é€‰æ‹©é¢˜å’Œç”Ÿæˆå¼ä»»åŠ¡ã€‚ä¸ºäº†ç¡®ä¿æ•°æ®çš„å‡†ç¡®æ€§ï¼Œç ”ç©¶å›¢é˜Ÿå¯¹GoldenSwagå’ŒXEDç­‰ç¿»è¯‘èµ„æºè¿›è¡Œäº†äººå·¥å®¡é˜…ï¼Œå¹¶ä¸ºæ¯ä¸ªä»»åŠ¡æä¾›äº†äº”ç§æç¤ºè¯­(prompt)å˜ä½“ã€‚è¯¥åŸºå‡†é€šè¿‡é¢„è®­ç»ƒ2.15Bå‚æ•°æ¨¡å‹å¹¶åˆ†æå…¶å­¦ä¹ æ›²çº¿ï¼ŒåŸºäºå•è°ƒæ€§ã€ä¿¡å™ªæ¯”å’Œæ¨¡å‹æ’åºä¸€è‡´æ€§ç­‰æ ‡å‡†ä¸¥æ ¼ç­›é€‰ä»»åŠ¡ï¼Œä»è€Œä¿è¯äº†è¯„ä¼°çš„ç¨³å¥æ€§ã€‚ç›®å‰ï¼ŒFIN-bench-v2çš„æ‰€æœ‰æ•°æ®é›†ã€æç¤ºè¯­å’Œè¯„ä¼°é…ç½®å‡å·²é€šè¿‡LumiOpenå’ŒTurkuNLPçš„ç›¸å…³ä»“åº“å…¬å¼€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13330v1",
      "published_date": "2025-12-15 13:41:41 UTC",
      "updated_date": "2025-12-15 13:41:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:56:40.444422+00:00"
    },
    {
      "arxiv_id": "2512.13325v1",
      "title": "Security and Detectability Analysis of Unicode Text Watermarking Methods Against Large Language Models",
      "title_zh": "é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹çš„ Unicode æ–‡æœ¬æ°´å°æ–¹æ³•å®‰å…¨æ€§ä¸å¯æ£€æµ‹æ€§åˆ†æ",
      "authors": [
        "Malte Hellmeier"
      ],
      "abstract": "Securing digital text is becoming increasingly relevant due to the widespread use of large language models. Individuals' fear of losing control over data when it is being used to train such machine learning models or when distinguishing model-generated output from text written by humans. Digital watermarking provides additional protection by embedding an invisible watermark within the data that requires protection. However, little work has been taken to analyze and verify if existing digital text watermarking methods are secure and undetectable by large language models. In this paper, we investigate the security-related area of watermarking and machine learning models for text data. In a controlled testbed of three experiments, ten existing Unicode text watermarking methods were implemented and analyzed across six large language models: GPT-5, GPT-4o, Teuken 7B, Llama 3.3, Claude Sonnet 4, and Gemini 2.5 Pro. The findings of our experiments indicate that, especially the latest reasoning models, can detect a watermarked text. Nevertheless, all models fail to extract the watermark unless implementation details in the form of source code are provided. We discuss the implications for security researchers and practitioners and outline future research opportunities to address security concerns.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ (Large Language Models) æ™®åŠå¸¦æ¥çš„æ•°æ®æ§åˆ¶ä¸ç”Ÿæˆæ–‡æœ¬è¯†åˆ«æŒ‘æˆ˜ï¼Œç³»ç»Ÿåˆ†æäº† Unicode æ–‡æœ¬æ°´å° (Unicode Text Watermarking) æ–¹æ³•çš„å®‰å…¨æ€§å’Œå¯æ£€æµ‹æ€§ã€‚ç ”ç©¶äººå‘˜åœ¨å—æ§æµ‹è¯•ç¯å¢ƒä¸­å®ç°äº†10ç§ç°æœ‰çš„ Unicode æ–‡æœ¬æ°´å°æ–¹æ³•ï¼Œå¹¶é’ˆå¯¹ GPT-5ã€GPT-4oã€Teuken 7Bã€Llama 3.3ã€Claude Sonnet 4 å’Œ Gemini 2.5 Pro å…­ç§ä¸»æµæ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæœ€æ–°çš„æ¨ç†æ¨¡å‹èƒ½å¤Ÿè¯†åˆ«å‡ºç»è¿‡æ°´å°å¤„ç†çš„æ–‡æœ¬ï¼Œä½†åœ¨ç¼ºä¹æºä»£ç ç­‰å…·ä½“å®ç°ç»†èŠ‚çš„æƒ…å†µä¸‹ï¼Œæ‰€æœ‰æ¨¡å‹éƒ½æ— æ³•æˆåŠŸæå–æ°´å°ä¿¡æ¯ã€‚è¯¥é¡¹å·¥ä½œæ·±å…¥æ¢è®¨äº†ç›¸å…³å‘ç°å¯¹å®‰å…¨ç ”ç©¶äººå‘˜å’Œä»ä¸šè€…çš„å½±å“ï¼Œå¹¶ä¸ºåº”å¯¹æ–‡æœ¬æ•°æ®å®‰å…¨æŒ‘æˆ˜æå‡ºäº†æœªæ¥ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted for publication at the ICISSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.13325v1",
      "published_date": "2025-12-15 13:40:00 UTC",
      "updated_date": "2025-12-15 13:40:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:56:34.359902+00:00"
    },
    {
      "arxiv_id": "2512.13323v1",
      "title": "Error-Driven Prompt Optimization for Arithmetic Reasoning",
      "title_zh": "é¢å‘ç®—æœ¯æ¨ç†çš„é”™è¯¯é©±åŠ¨æç¤ºè¯ä¼˜åŒ–",
      "authors": [
        "ÃrpÃ¡d PÃ¡ndy",
        "RÃ³bert Lakatos",
        "AndrÃ¡s Hajdu"
      ],
      "abstract": "Recent advancements in artificial intelligence have sparked interest in industrial agents capable of supporting analysts in regulated sectors, such as finance and healthcare, within tabular data workflows. A key capability for such systems is performing accurate arithmetic operations on structured data while ensuring sensitive information never leaves secure, on-premises environments. Here, we introduce an error-driven optimization framework for arithmetic reasoning that enhances a Code Generation Agent (CGA), specifically applied to on-premises small language models (SLMs). Through a systematic evaluation of a leading SLM (Qwen3 4B), we find that while the base model exhibits fundamental limitations in arithmetic tasks, our proposed error-driven method, which clusters erroneous predictions to refine prompt-rules iteratively, dramatically improves performance, elevating the model's accuracy to 70.8\\%. Our results suggest that developing reliable, interpretable, and industrially deployable AI assistants can be achieved not only through costly fine-tuning but also via systematic, error-driven prompt optimization, enabling small models to surpass larger language models (GPT-3.5 Turbo) in a privacy-compliant manner.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å—ç›‘ç®¡è¡Œä¸šä¸­ç»“æ„åŒ–æ•°æ®ç®—æœ¯è¿ç®—çš„å‡†ç¡®æ€§å’Œéšç§éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§é¢å‘ç®—æœ¯æ¨ç†çš„é”™è¯¯é©±åŠ¨æç¤ºä¼˜åŒ–(Error-Driven Prompt Optimization)æ¡†æ¶ã€‚è¯¥æ¡†æ¶ä¸»è¦åº”ç”¨äºæœ¬åœ°éƒ¨ç½²çš„å°è¯­è¨€æ¨¡å‹(SLMs)ä¸­çš„ä»£ç ç”Ÿæˆæ™ºèƒ½ä½“(Code Generation Agent, CGA)ï¼Œé€šè¿‡ç³»ç»Ÿæ€§åœ°å¯¹é”™è¯¯é¢„æµ‹è¿›è¡Œèšç±»ï¼Œä»è€Œè¿­ä»£å¼åœ°ä¼˜åŒ–æç¤ºè§„åˆ™(Prompt-rules)ã€‚ç ”ç©¶ä»¥Qwen3 4Bæ¨¡å‹ä¸ºåŸºç¡€è¿›è¡Œè¯„ä¼°ï¼Œå‘ç°åŸºç¡€æ¨¡å‹åœ¨ç®—æœ¯ä»»åŠ¡ä¸Šå­˜åœ¨å±€é™æ€§ï¼Œä½†åº”ç”¨è¯¥é”™è¯¯é©±åŠ¨æ–¹æ³•åï¼Œæ¨¡å‹å‡†ç¡®ç‡æ˜¾è‘—æå‡è‡³70.8%ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä½¿å°è¯­è¨€æ¨¡å‹åœ¨éµå®ˆéšç§åˆè§„æ€§çš„å‰æä¸‹ï¼Œæ€§èƒ½è¶…è¶Šäº†GPT-3.5 Turboç­‰å¤§å‹è¯­è¨€æ¨¡å‹ã€‚è¿™ä¸€å‘ç°è¯æ˜ï¼Œé€šè¿‡ç³»ç»Ÿæ€§çš„é”™è¯¯é©±åŠ¨æç¤ºä¼˜åŒ–è€Œéæ˜‚è´µçš„å¾®è°ƒ(Fine-tuning)ï¼Œä¹Ÿå¯ä»¥æ„å»ºå‡ºå¯é ã€å¯è§£é‡Šä¸”é€‚ç”¨äºå·¥ä¸šéƒ¨ç½²çš„AIåŠ©æ‰‹ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13323v1",
      "published_date": "2025-12-15 13:39:14 UTC",
      "updated_date": "2025-12-15 13:39:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:57:08.673082+00:00"
    },
    {
      "arxiv_id": "2512.13317v1",
      "title": "Face Identity Unlearning for Retrieval via Embedding Dispersion",
      "title_zh": "åŸºäºåµŒå…¥å¼¥æ•£çš„é¢å‘æ£€ç´¢äººè„¸èº«ä»½æœºå™¨é—å¿˜",
      "authors": [
        "Mikhail Zakharov"
      ],
      "abstract": "Face recognition systems rely on learning highly discriminative and compact identity clusters to enable accurate retrieval. However, as with other surveillance-oriented technologies, such systems raise serious privacy concerns due to their potential for unauthorized identity tracking. While several works have explored machine unlearning as a means of privacy protection, their applicability to face retrieval - especially for modern embedding-based recognition models - remains largely unexplored. In this work, we study the problem of face identity unlearning for retrieval systems and present its inherent challenges. The goal is to make selected identities unretrievable by dispersing their embeddings on the hypersphere and preventing the formation of compact identity clusters that enable re-identification in the gallery. The primary challenge is to achieve this forgetting effect while preserving the discriminative structure of the embedding space and the retrieval performance of the model for the remaining identities. To address this, we evaluate several existing approximate class unlearning methods (e.g., Random Labeling, Gradient Ascent, Boundary Unlearning, and other recent approaches) in the context of face retrieval and propose a simple yet effective dispersion-based unlearning approach. Extensive experiments on standard benchmarks (VGGFace2, CelebA) demonstrate that our method achieves superior forgetting behavior while preserving retrieval utility.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººè„¸æ£€ç´¢ç³»ç»Ÿä¸­çš„éšç§ä¿æŠ¤éœ€æ±‚ï¼Œæ¢è®¨äº†äººè„¸èº«ä»½é—å¿˜ï¼ˆFace Identity Unlearningï¼‰è¿™ä¸€å°šæœªè¢«å……åˆ†ç ”ç©¶çš„è¯¾é¢˜ã€‚å…¶æ ¸å¿ƒç›®æ ‡æ˜¯é€šè¿‡åœ¨è¶…çƒé¢ä¸Šåˆ†æ•£ï¼ˆdispersingï¼‰ç‰¹å®šèº«ä»½çš„åµŒå…¥å‘é‡ï¼ˆembeddingsï¼‰ï¼Œé˜²æ­¢å½¢æˆå¯ç”¨äºé‡æ–°è¯†åˆ«çš„ç´§å‡‘èº«ä»½ç°‡ï¼Œä»è€Œä½¿é€‰å®šèº«ä»½æ— æ³•è¢«æ£€ç´¢ã€‚ä¸ºäº†åœ¨å®ç°é—å¿˜çš„åŒæ—¶ä¿æŒæ¨¡å‹å¯¹å‰©ä½™èº«ä»½çš„æ£€ç´¢æ€§èƒ½ï¼ˆretrieval utilityï¼‰ï¼Œè®ºæ–‡åœ¨è¯„ä¼°äº†éšæœºæ ‡ç­¾ï¼ˆRandom Labelingï¼‰ã€æ¢¯åº¦ä¸Šå‡ï¼ˆGradient Ascentï¼‰å’Œè¾¹ç•Œé—å¿˜ï¼ˆBoundary Unlearningï¼‰ç­‰ç°æœ‰æ–¹æ³•çš„åŸºç¡€ä¸Šï¼Œæå‡ºäº†ä¸€ç§åŸºäºè‰²æ•£ï¼ˆdispersion-basedï¼‰çš„é—å¿˜æ–°æ–¹æ³•ã€‚åœ¨ VGGFace2 å’Œ CelebA åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®ç°ä¼˜è¶Šé—å¿˜æ•ˆæœçš„åŒæ—¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆä¿ç•™åµŒå…¥ç©ºé—´çš„åˆ¤åˆ«ç»“æ„å’Œæ£€ç´¢æ•ˆèƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 1 figure, 5 tables, 10 equations. Preprint",
      "pdf_url": "https://arxiv.org/pdf/2512.13317v1",
      "published_date": "2025-12-15 13:35:28 UTC",
      "updated_date": "2025-12-15 13:35:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:57:04.237357+00:00"
    },
    {
      "arxiv_id": "2512.13316v1",
      "title": "ALIGN-FL: Architecture-independent Learning through Invariant Generative component sharing in Federated Learning",
      "title_zh": "ALIGN-FLï¼šåŸºäºä¸å˜ç”Ÿæˆç»„ä»¶å…±äº«çš„è”é‚¦å­¦ä¹ æ¶æ„æ— å…³å­¦ä¹ ",
      "authors": [
        "Mayank Gulati",
        "Benedikt GroÃŸ",
        "Gerhard Wunder"
      ],
      "abstract": "We present ALIGN-FL, a novel approach to distributed learning that addresses the challenge of learning from highly disjoint data distributions through selective sharing of generative components. Instead of exchanging full model parameters, our framework enables privacy-preserving learning by transferring only generative capabilities across clients, while the server performs global training using synthetic samples. Through complementary privacy mechanisms: DP-SGD with adaptive clipping and Lipschitz regularized VAE decoders and a stateful architecture supporting heterogeneous clients, we experimentally validate our approach on MNIST and Fashion-MNIST datasets with cross-domain outliers. Our analysis demonstrates that both privacy mechanisms effectively map sensitive outliers to typical data points while maintaining utility in extreme Non-IID scenarios typical of cross-silo collaborations.\n  Index Terms: Client-invariant Learning, Federated Learning (FL), Privacy-preserving Generative Models, Non-Independent and Identically Distributed (Non-IID), Heterogeneous Architectures",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ALIGN-FLï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡é€‰æ‹©æ€§å…±äº«ç”Ÿæˆç»„ä»¶æ¥è§£å†³è”é‚¦å­¦ä¹  (Federated Learning) ä¸­é«˜åº¦ä¸ç›¸äº¤æ•°æ®åˆ†å¸ƒæŒ‘æˆ˜çš„æ–°é¢–æ–¹æ³•ã€‚è¯¥æ¡†æ¶ä¸äº¤æ¢å®Œæ•´çš„æ¨¡å‹å‚æ•°ï¼Œè€Œæ˜¯é€šè¿‡åœ¨å®¢æˆ·ç«¯ä¹‹é—´ä»…ä¼ è¾“ç”Ÿæˆèƒ½åŠ›æ¥å®ç°éšç§ä¿æŠ¤å­¦ä¹  (Privacy-preserving Learning)ï¼ŒåŒæ—¶ç”±æœåŠ¡å™¨åˆ©ç”¨åˆæˆæ ·æœ¬è¿›è¡Œå…¨å±€è®­ç»ƒã€‚ç ”ç©¶ç»“åˆäº†å…·æœ‰è‡ªé€‚åº”å‰ªåˆ‡çš„ DP-SGD å’Œ Lipschitz æ­£åˆ™åŒ– VAE è§£ç å™¨ç­‰éšç§æœºåˆ¶ï¼Œå¹¶é‡‡ç”¨äº†æ”¯æŒå¼‚æ„å®¢æˆ·ç«¯ (Heterogeneous Clients) çš„æœ‰çŠ¶æ€æ¶æ„ã€‚åœ¨ MNIST å’Œ Fashion-MNIST æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…¸å‹çš„è·¨å­¤å²›åä½œç­‰æç«¯ Non-IID åœºæ™¯ä¸‹ä¾ç„¶èƒ½ä¿æŒè‰¯å¥½çš„æ•ˆç”¨ã€‚åˆ†æè¿›ä¸€æ­¥è¯å®ï¼Œå…¶éšç§æœºåˆ¶èƒ½æœ‰æ•ˆåœ°å°†æ•æ„Ÿç¦»ç¾¤å€¼æ˜ å°„ä¸ºå…¸å‹æ•°æ®ç‚¹ï¼Œä¸ºåˆ†å¸ƒå¼å­¦ä¹ æä¾›äº†ä¸€ç§å®‰å…¨ä¸”æ¶æ„æ— å…³çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at 2025 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC)",
      "pdf_url": "https://arxiv.org/pdf/2512.13316v1",
      "published_date": "2025-12-15 13:35:27 UTC",
      "updated_date": "2025-12-15 13:35:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:57:34.136847+00:00"
    },
    {
      "arxiv_id": "2512.13300v1",
      "title": "No One Left Behind: How to Exploit the Incomplete and Skewed Multi-Label Data for Conversion Rate Prediction",
      "title_zh": "ä¸€ä¸ªéƒ½ä¸èƒ½å°‘ï¼šå¦‚ä½•åˆ©ç”¨ä¸å®Œæ•´ä¸”åæ–œçš„å¤šæ ‡ç­¾æ•°æ®è¿›è¡Œè½¬åŒ–ç‡é¢„æµ‹",
      "authors": [
        "Qinglin Jia",
        "Zhaocheng Du",
        "Chuhan Wu",
        "Huifeng Guo",
        "Ruiming Tang",
        "Shuting Shi",
        "Muyu Zhang"
      ],
      "abstract": "In most real-world online advertising systems, advertisers typically have diverse customer acquisition goals. A common solution is to use multi-task learning (MTL) to train a unified model on post-click data to estimate the conversion rate (CVR) for these diverse targets. In practice, CVR prediction often encounters missing conversion data as many advertisers submit only a subset of user conversion actions due to privacy or other constraints, making the labels of multi-task data incomplete. If the model is trained on all available samples where advertisers submit user conversion actions, it may struggle when deployed to serve a subset of advertisers targeting specific conversion actions, as the training and deployment data distributions are mismatched. While considerable MTL efforts have been made, a long-standing challenge is how to effectively train a unified model with the incomplete and skewed multi-label data. In this paper, we propose a fine-grained Knowledge transfer framework for Asymmetric Multi-Label data (KAML). We introduce an attribution-driven masking strategy (ADM) to better utilize data with asymmetric multi-label data in training. However, the more relaxed masking in ADM is a double-edged sword: it provides additional training signals but also introduces noise due to skewed data. To address this, we propose a hierarchical knowledge extraction mechanism (HKE) to model the sample discrepancy within the target task tower. Finally, to maximize the utility of unlabeled samples, we incorporate ranking loss strategy to further enhance our model. The effectiveness of KAML has been demonstrated through comprehensive evaluations on offline industry datasets and online A/B tests, which show significant performance improvements over existing MTL baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åœ¨çº¿å¹¿å‘Šç³»ç»Ÿä¸­è½¬åŒ–ç‡(CVR)é¢„æµ‹é¢ä¸´çš„å¤šä»»åŠ¡æ ‡ç­¾ä¸å…¨å’Œæ•°æ®åˆ†å¸ƒåå·®é—®é¢˜ï¼ŒæŒ‡å‡ºç”±äºéšç§ç­‰é™åˆ¶ï¼Œå¹¿å‘Šä¸»å¾€å¾€ä»…æäº¤éƒ¨åˆ†ç”¨æˆ·è½¬åŒ–è¡Œä¸ºï¼Œå¯¼è‡´æ¨¡å‹è®­ç»ƒä¸éƒ¨ç½²ç¯å¢ƒä¸åŒ¹é…ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†é’ˆå¯¹ä¸å¯¹ç§°å¤šæ ‡ç­¾æ•°æ®çš„ç»†ç²’åº¦çŸ¥è¯†è¿ç§»æ¡†æ¶KAML (fine-grained Knowledge transfer framework for Asymmetric Multi-Label data)ï¼Œæ—¨åœ¨æœ‰æ•ˆåˆ©ç”¨ä¸å®Œæ•´ä¸”å€¾æ–œçš„è®­ç»ƒæ•°æ®ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†å½’å› é©±åŠ¨æ©ç ç­–ç•¥(ADM)ä»¥æ›´å……åˆ†åœ°æŒ–æ˜å¤šæ ‡ç­¾æ•°æ®ï¼Œå¹¶ç»“åˆå±‚æ¬¡åŒ–çŸ¥è¯†æå–æœºåˆ¶(HKE)æ¥å»ºæ¨¡æ ·æœ¬å·®å¼‚ï¼Œä»è€Œç¼“è§£æ•°æ®å€¾æ–œå¸¦æ¥çš„å™ªå£°å½±å“ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é‡‡ç”¨äº†æ’åºæŸå¤±(Ranking Loss)ç­–ç•¥ä»¥æœ€å¤§åŒ–æœªæ ‡è®°æ ·æœ¬çš„æ•ˆç”¨å¹¶å¢å¼ºæ¨¡å‹è¡¨ç°ã€‚åœ¨ç¦»çº¿å·¥ä¸šæ•°æ®é›†å’Œåœ¨çº¿A/Bæµ‹è¯•ä¸­çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒKAMLæ˜¾è‘—ä¼˜äºç°æœ‰çš„å¤šä»»åŠ¡å­¦ä¹ (MTL)åŸºå‡†æ¨¡å‹ï¼Œæœ‰æ•ˆè§£å†³äº†å®é™…ä¸šåŠ¡åœºæ™¯ä¸­çš„æ•°æ®ä¸å¯¹ç§°æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13300v1",
      "published_date": "2025-12-15 13:14:20 UTC",
      "updated_date": "2025-12-15 13:14:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:57:37.910420+00:00"
    },
    {
      "arxiv_id": "2512.13298v1",
      "title": "MiniLingua: A Small Open-Source LLM for European Languages",
      "title_zh": "MiniLinguaï¼šé¢å‘æ¬§æ´²è¯­è¨€çš„å°å‹å¼€æºå¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Anna Aksenova",
        "Boris Zverkov",
        "Nicola Dainese",
        "Alexander Nikitin",
        "Pekka Marttinen"
      ],
      "abstract": "Large language models are powerful but often limited by high computational cost, privacy concerns, and English-centric training. Recent progress demonstrates that small, efficient models with around one billion parameters can deliver strong results and enable on-device use. This paper introduces MiniLingua, a multilingual open-source LLM of one billion parameters trained from scratch for 13 European languages, designed to balance coverage and instruction-following capabilities. Based on evaluation results, the instruction-tuned version of MiniLingua outperforms EuroLLM, a model with a similar training approach but a larger training budget, on summarization, classification and both open- and closed-book question answering. Moreover, it remains competitive with more advanced state-of-the-art models on open-ended generation tasks. We release model weights, tokenizer and source code used for data processing and model training.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†MiniLinguaï¼Œä¸€ä¸ªæ‹¥æœ‰10äº¿å‚æ•°(1 billion parameters)çš„å¼€æºå¤šè¯­è¨€å¤§è¯­è¨€æ¨¡å‹(LLM)ï¼Œæ—¨åœ¨è§£å†³å½“å‰å¤§æ¨¡å‹è®¡ç®—æˆæœ¬é«˜ã€éšç§å—é™åŠä»¥è‹±æ–‡ä¸ºè®­ç»ƒä¸­å¿ƒçš„é—®é¢˜ã€‚MiniLinguaä¸“é—¨é’ˆå¯¹13ç§æ¬§æ´²è¯­è¨€(European languages)ä»é›¶å¼€å§‹è®­ç»ƒï¼Œæ—¨åœ¨å¹³è¡¡å¤šè¯­è¨€è¦†ç›–èŒƒå›´ä¸æŒ‡ä»¤éµå¾ª(instruction-following)èƒ½åŠ›ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒæŒ‡ä»¤å¾®è°ƒ(instruction-tuned)åçš„MiniLinguaåœ¨æ‘˜è¦ç”Ÿæˆã€æ–‡æœ¬åˆ†ç±»ä»¥åŠå¼€å·ä¸é—­å·é—®ç­”ä»»åŠ¡ä¸Šçš„è¡¨ç°å‡ä¼˜äºå…·æœ‰æ›´å¤§è®­ç»ƒé¢„ç®—çš„EuroLLMæ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨å¼€æ”¾å¼ç”Ÿæˆ(open-ended generation)ä»»åŠ¡ä¸­ä¹Ÿè¡¨ç°å‡ºäº†è¶³ä»¥åª²ç¾å…ˆè¿›SOTAæ¨¡å‹çš„ç«äº‰å®åŠ›ã€‚ç ”ç©¶å›¢é˜Ÿç›®å‰å·²å…¬å¼€å‘å¸ƒæ¨¡å‹æƒé‡(model weights)ã€åˆ†è¯å™¨(tokenizer)ä»¥åŠç”¨äºæ•°æ®å¤„ç†å’Œæ¨¡å‹è®­ç»ƒçš„å®Œæ•´æºä»£ç ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9+6 pages, 6 figures and 3 tables in the main text. Code at https://github.com/MiniLingua-ai/training_artifacts",
      "pdf_url": "https://arxiv.org/pdf/2512.13298v1",
      "published_date": "2025-12-15 13:12:42 UTC",
      "updated_date": "2025-12-15 13:12:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:57:32.020088+00:00"
    },
    {
      "arxiv_id": "2512.13297v1",
      "title": "MedInsightBench: Evaluating Medical Analytics Agents Through Multi-Step Insight Discovery in Multimodal Medical Data",
      "title_zh": "MedInsightBenchï¼šé€šè¿‡å¤šæ¨¡æ€åŒ»ç–—æ•°æ®ä¸­çš„å¤šæ­¥è§è§£å‘ç°è¯„ä¼°åŒ»ç–—åˆ†ææ™ºèƒ½ä½“",
      "authors": [
        "Zhenghao Zhu",
        "Chuxue Cao",
        "Sirui Han",
        "Yuanfeng Song",
        "Xing Chen",
        "Caleb Chen Cao",
        "Yike Guo"
      ],
      "abstract": "In medical data analysis, extracting deep insights from complex, multi-modal datasets is essential for improving patient care, increasing diagnostic accuracy, and optimizing healthcare operations. However, there is currently a lack of high-quality datasets specifically designed to evaluate the ability of large multi-modal models (LMMs) to discover medical insights. In this paper, we introduce MedInsightBench, the first benchmark that comprises 332 carefully curated medical cases, each annotated with thoughtfully designed insights. This benchmark is intended to evaluate the ability of LMMs and agent frameworks to analyze multi-modal medical image data, including posing relevant questions, interpreting complex findings, and synthesizing actionable insights and recommendations. Our analysis indicates that existing LMMs exhibit limited performance on MedInsightBench, which is primarily attributed to their challenges in extracting multi-step, deep insights and the absence of medical expertise. Therefore, we propose MedInsightAgent, an automated agent framework for medical data analysis, composed of three modules: Visual Root Finder, Analytical Insight Agent, and Follow-up Question Composer. Experiments on MedInsightBench highlight pervasive challenges and demonstrate that MedInsightAgent can improve the performance of general LMMs in medical data insight discovery.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—æ•°æ®åˆ†æä¸­ä»å¤æ‚å¤šæ¨¡æ€æ•°æ®æå–æ·±åº¦æ´å¯Ÿçš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºäº†ç°æœ‰å¤§è¯­è¨€å¤šæ¨¡æ€æ¨¡å‹(LMMs)ç¼ºä¹ä¸“é—¨è¯„ä¼°åŸºå‡†çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…å¼€å‘äº†MedInsightBenchï¼Œè¿™æ˜¯é¦–ä¸ªåŒ…å«332ä¸ªç²¾å¿ƒæŒ‘é€‰æ¡ˆä¾‹çš„åŒ»ç–—æ´å¯Ÿè¯„ä¼°åŸºå‡†ï¼Œé‡ç‚¹è€ƒå¯Ÿæ¨¡å‹åˆ†æåŒ»ç–—å½±åƒã€è§£é‡Šå‘ç°åŠåˆæˆå»ºè®®çš„èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œç”±äºç¼ºä¹å¤šæ­¥æ¨ç†èƒ½åŠ›å’ŒåŒ»ç–—ä¸“ä¸šçŸ¥è¯†ï¼Œç°æœ‰LMMsåœ¨å¤„ç†è¯¥åŸºå‡†æ—¶è¡¨ç°æ¬ ä½³ã€‚ä¸ºè§£å†³è¿™ä¸€å›°å¢ƒï¼Œç ”ç©¶æå‡ºäº†MedInsightAgentè‡ªåŠ¨åŒ–æ™ºèƒ½ä½“æ¡†æ¶ï¼Œå…¶ç”±Visual Root Finderã€Analytical Insight Agentå’ŒFollow-up Question Composerä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—æ„æˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½æœ‰æ•ˆå¢å¼ºé€šç”¨LMMsåœ¨åŒ»ç–—æ•°æ®æ·±åº¦æ´å¯Ÿå‘ç°æ–¹é¢çš„æ€§èƒ½ï¼Œä¸ºåŒ»ç–—æ™ºèƒ½åˆ†ææä¾›äº†æ–°çš„è¯„ä¼°å·¥å…·å’Œè§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13297v1",
      "published_date": "2025-12-15 13:10:42 UTC",
      "updated_date": "2025-12-15 13:10:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:57:32.420712+00:00"
    },
    {
      "arxiv_id": "2512.13293v2",
      "title": "Intrinsic-Motivation Multi-Robot Social Formation Navigation with Coordinated Exploration",
      "title_zh": "èåˆååŒæ¢ç´¢çš„å†…åœ¨åŠ¨æœºå¤šæœºå™¨äººç¤¾äº¤ç¼–é˜Ÿå¯¼èˆª",
      "authors": [
        "Hao Fu",
        "Wei Liu",
        "Shuai Zhou"
      ],
      "abstract": "This paper investigates the application of reinforcement learning (RL) to multi-robot social formation navigation, a critical capability for enabling seamless human-robot coexistence. While RL offers a promising paradigm, the inherent unpredictability and often uncooperative dynamics of pedestrian behavior pose substantial challenges, particularly concerning the efficiency of coordinated exploration among robots. To address this, we propose a novel coordinated-exploration multi-robot RL algorithm introducing an intrinsic motivation exploration. Its core component is a self-learning intrinsic reward mechanism designed to collectively alleviate policy conservatism. Moreover, this algorithm incorporates a dual-sampling mode within the centralized training and decentralized execution framework to enhance the representation of both the navigation policy and the intrinsic reward, leveraging a two-time-scale update rule to decouple parameter updates. Empirical results on social formation navigation benchmarks demonstrate the proposed algorithm's superior performance over existing state-of-the-art methods across crucial metrics. Our code and video demos are available at: https://github.com/czxhunzi/CEMRRL.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Reinforcement Learning (RL) åœ¨å¤šæœºå™¨äººç¤¾ä¼šç¼–é˜Ÿå¯¼èˆª (Multi-Robot Social Formation Navigation) ä¸­çš„åº”ç”¨ï¼Œæ—¨åœ¨è§£å†³è¡Œäººè¡Œä¸ºçš„ä¸å¯é¢„æµ‹æ€§å¯¼è‡´çš„æœºå™¨äººåè°ƒæ¢ç´¢æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§å¼•å…¥ Intrinsic Motivation æ¢ç´¢çš„æ–°å‹åè°ƒæ¢ç´¢å¤šæœºå™¨äººå¼ºåŒ–å­¦ä¹ ç®—æ³•ã€‚è¯¥ç®—æ³•çš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªè‡ªå­¦ä¹ å†…åœ¨å¥–åŠ±æœºåˆ¶ (Self-learning Intrinsic Reward Mechanism)ï¼Œç”¨äºé›†ä½“ç¼“è§£ç­–ç•¥çš„ä¿å®ˆæ€§å¹¶å¢å¼ºæ¢ç´¢æ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥ç®—æ³•åœ¨ä¸­å¿ƒåŒ–è®­ç»ƒåˆ†å¸ƒå¼æ‰§è¡Œ (CTDE) æ¡†æ¶ä¸­ç»“åˆäº†åŒé‡é‡‡æ ·æ¨¡å¼ (Dual-sampling Mode)ï¼Œå¹¶åˆ©ç”¨åŒæ—¶é—´å°ºåº¦æ›´æ–°è§„åˆ™ (Two-time-scale Update Rule) æ¥å®ç°å‚æ•°æ›´æ–°çš„è§£è€¦ã€‚åœ¨ç¤¾ä¼šç¼–é˜Ÿå¯¼èˆªåŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç®—æ³•åœ¨å„é¡¹å…³é”®æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13293v2",
      "published_date": "2025-12-15 13:03:08 UTC",
      "updated_date": "2025-12-16 03:34:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:57:34.270995+00:00"
    },
    {
      "arxiv_id": "2512.13290v1",
      "title": "LINA: Learning INterventions Adaptively for Physical Alignment and Generalization in Diffusion Models",
      "title_zh": "LINAï¼šæ‰©æ•£æ¨¡å‹ç‰©ç†å¯¹é½ä¸æ³›åŒ–çš„è‡ªé€‚åº”å­¦ä¹ å¹²é¢„",
      "authors": [
        "Shu Yu",
        "Chaochao Lu"
      ],
      "abstract": "Diffusion models (DMs) have achieved remarkable success in image and video generation. However, they still struggle with (1) physical alignment and (2) out-of-distribution (OOD) instruction following. We argue that these issues stem from the models' failure to learn causal directions and to disentangle causal factors for novel recombination. We introduce the Causal Scene Graph (CSG) and the Physical Alignment Probe (PAP) dataset to enable diagnostic interventions. This analysis yields three key insights. First, DMs struggle with multi-hop reasoning for elements not explicitly determined in the prompt. Second, the prompt embedding contains disentangled representations for texture and physics. Third, visual causal structure is disproportionately established during the initial, computationally limited denoising steps. Based on these findings, we introduce LINA (Learning INterventions Adaptively), a novel framework that learns to predict prompt-specific interventions, which employs (1) targeted guidance in the prompt and visual latent spaces, and (2) a reallocated, causality-aware denoising schedule. Our approach enforces both physical alignment and OOD instruction following in image and video DMs, achieving state-of-the-art performance on challenging causal generation tasks and the Winoground dataset. Our project page is at https://opencausalab.github.io/LINA.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Diffusion models (DMs) åœ¨ç‰©ç†å¯¹é½ (physical alignment) ä¸åˆ†å¸ƒå¤– (OOD) æŒ‡ä»¤éµå¾ªæ–¹é¢çš„å±€é™æ€§ï¼Œå°†å…¶å½’å› äºæ¨¡å‹éš¾ä»¥å­¦ä¹ å› æœæ–¹å‘åŠè§£è€¦å› æœå› å­ã€‚é€šè¿‡åˆ©ç”¨ Causal Scene Graph (CSG) å’Œ Physical Alignment Probe (PAP) æ•°æ®é›†è¿›è¡Œè¯Šæ–­åˆ†æï¼Œç ”ç©¶è€…æ­ç¤ºäº†æ¨¡å‹åœ¨å¤šæ­¥æ¨ç†ã€è¡¨å¾è§£è€¦ä»¥åŠå»å™ªåˆæœŸå»ºç«‹è§†è§‰å› æœç»“æ„çš„å…³é”®ç‰¹æ€§ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº† LINA (Learning INterventions Adaptively) æ¡†æ¶ï¼Œé€šè¿‡åœ¨æç¤ºè¯ä¸è§†è§‰æ½œç©ºé—´åº”ç”¨å®šå‘å¼•å¯¼ï¼Œå¹¶ç»“åˆé‡æ–°åˆ†é…çš„å› æœæ„ŸçŸ¥å»å™ªè°ƒåº¦æ¥å®ç°è‡ªé€‚åº”å¹²é¢„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLINA æ˜¾è‘—å¢å¼ºäº†å›¾åƒåŠè§†é¢‘ç”Ÿæˆæ¨¡å‹çš„ç‰©ç†å¯¹é½å’Œ OOD æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼Œåœ¨æŒ‘æˆ˜æ€§å› æœç”Ÿæˆä»»åŠ¡å’Œ Winoground æ•°æ®é›†ä¸Šå‡å–å¾—äº† state-of-the-art çš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13290v1",
      "published_date": "2025-12-15 12:59:59 UTC",
      "updated_date": "2025-12-15 12:59:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:58:00.327784+00:00"
    },
    {
      "arxiv_id": "2512.15784v1",
      "title": "Beyond Training: Enabling Self-Evolution of Agents with MOBIMEM",
      "title_zh": "è¶…è¶Šè®­ç»ƒï¼šåŸºäº MOBIMEM å®ç°æ™ºèƒ½ä½“çš„è‡ªæˆ‘æ¼”åŒ–",
      "authors": [
        "Zibin Liu",
        "Cheng Zhang",
        "Xi Zhao",
        "Yunfei Feng",
        "Bingyu Bai",
        "Dahu Feng",
        "Erhu Feng",
        "Yubin Xia",
        "Haibo Chen"
      ],
      "abstract": "Large Language Model (LLM) agents are increasingly deployed to automate complex workflows in mobile and desktop environments. However, current model-centric agent architectures struggle to self-evolve post-deployment: improving personalization, capability, and efficiency typically requires continuous model retraining/fine-tuning, which incurs prohibitive computational overheads and suffers from an inherent trade-off between model accuracy and inference efficiency.\n  To enable iterative self-evolution without model retraining, we propose MOBIMEM, a memory-centric agent system. MOBIMEM first introduces three specialized memory primitives to decouple agent evolution from model weights: (1) Profile Memory uses a lightweight distance-graph (DisGraph) structure to align with user preferences, resolving the accuracy-latency trade-off in user profile retrieval; (2) Experience Memory employs multi-level templates to instantiate execution logic for new tasks, ensuring capability generalization; and (3) Action Memory records fine-grained interaction sequences, reducing the reliance on expensive model inference. Building upon this memory architecture, MOBIMEM further integrates a suite of OS-inspired services to orchestrate execution: a scheduler that coordinates parallel sub-task execution and memory operations; an agent record-and-replay (AgentRR) mechanism that enables safe and efficient action reuse; and a context-aware exception handling that ensures graceful recovery from user interruptions and runtime errors.\n  Evaluation on AndroidWorld and top-50 apps shows that MOBIMEM achieves 83.1% profile alignment with 23.83 ms retrieval time (280x faster than GraphRAG baselines), improves task success rates by up to 50.3%, and reduces end-to-end latency by up to 9x on mobile devices.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLM) æ™ºèƒ½ä½“åœ¨éƒ¨ç½²åéš¾ä»¥é€šè¿‡ä½æˆæœ¬è‡ªæˆ‘è¿›åŒ–æ¥æå‡ä¸ªæ€§åŒ–å’Œæ•ˆç‡çš„é—®é¢˜ï¼Œæå‡ºäº† MOBIMEMï¼Œä¸€ç§ä»¥å­˜å‚¨ä¸ºä¸­å¿ƒçš„æ™ºèƒ½ä½“ç³»ç»Ÿ (memory-centric agent system)ã€‚è¯¥ç³»ç»Ÿé€šè¿‡ Profile Memoryã€Experience Memory å’Œ Action Memory ä¸‰ç§ä¸“ç”¨å­˜å‚¨åŸè¯­å°†æ™ºèƒ½ä½“è¿›åŒ–ä¸æ¨¡å‹æƒé‡è§£è€¦ï¼Œæœ‰æ•ˆè§£å†³äº†ç”¨æˆ·åå¥½å¯¹é½ã€èƒ½åŠ›æ³›åŒ–åŠæ¨ç†å¼€é”€é—®é¢˜ã€‚MOBIMEM è¿˜é›†æˆäº†å—æ“ä½œç³»ç»Ÿå¯å‘çš„è°ƒåº¦å™¨ (scheduler)ã€è®°å½•ä¸å›æ”¾ (AgentRR) åŠå¼‚å¸¸å¤„ç† (exception handling) ç­‰æœåŠ¡ï¼Œä»¥å¢å¼ºä»»åŠ¡æ‰§è¡Œçš„å¹¶è¡Œæ€§ä¸é²æ£’æ€§ã€‚åœ¨ AndroidWorld ç­‰ç¯å¢ƒä¸‹çš„è¯„ä¼°æ˜¾ç¤ºï¼ŒMOBIMEM çš„å­˜å‚¨æ£€ç´¢é€Ÿåº¦æ¯” GraphRAG åŸºçº¿å¿« 280 å€ï¼ŒåŒæ—¶å°†ä»»åŠ¡æˆåŠŸç‡æå‡äº† 50.3%ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ˜¾è‘—é™ä½ç§»åŠ¨ç«¯ç«¯åˆ°ç«¯å»¶è¿Ÿ (end-to-end latency) çš„åŒæ—¶ï¼Œå®ç°äº†é«˜æ•ˆçš„éƒ¨ç½²åè¿­ä»£è¿›åŒ–ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.15784v1",
      "published_date": "2025-12-15 12:38:43 UTC",
      "updated_date": "2025-12-15 12:38:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:57:48.099523+00:00"
    },
    {
      "arxiv_id": "2512.13240v1",
      "title": "Reflective Preference Optimization (RPO): Enhancing On-Policy Alignment via Hint-Guided Reflection",
      "title_zh": "åæ€åå¥½ä¼˜åŒ– (RPO)ï¼šé€šè¿‡æç¤ºå¼•å¯¼çš„åæ€å¢å¼ºåœ¨ç­–ç•¥å¯¹é½",
      "authors": [
        "Zihui Zhao",
        "Zechang Li"
      ],
      "abstract": "Direct Preference Optimization (DPO) has emerged as a lightweight and effective alternative to Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with AI Feedback (RLAIF) for aligning large language and vision-language models. However, the standard DPO formulation, in which both the chosen and rejected responses are generated by the same policy, suffers from a weak learning signal because the two responses often share similar errors and exhibit small Kullback-Leibler (KL) divergence. This leads to slow and unstable convergence. To address this limitation, we introduce Reflective Preference Optimization (RPO), a new framework that incorporates hint-guided reflection into the DPO paradigm. RPO uses external models to identify hallucination sources and generate concise reflective hints, enabling the construction of on-policy preference pairs with stronger contrastiveness and clearer preference signals. We theoretically show that conditioning on hints increases the expected preference margin through mutual information and improves sample efficiency while remaining within the policy distribution family. Empirically, RPO achieves superior alignment with fewer training samples and iterations, substantially reducing hallucination rates and delivering state-of-the-art performance across multimodal benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Direct Preference Optimization (DPO) åœ¨åŒç­–ç•¥å¯¹é½æ—¶å› å­¦ä¹ ä¿¡å·å¼±ã€KL divergence è¾ƒå°è€Œå¯¼è‡´æ”¶æ•›ä¸ç¨³å®šçš„é—®é¢˜ï¼Œæå‡ºäº† Reflective Preference Optimization (RPO) æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°å¼•å…¥äº†æç¤ºå¼•å¯¼çš„åæ€ (Hint-Guided Reflection) æœºåˆ¶ï¼Œåˆ©ç”¨å¤–éƒ¨æ¨¡å‹è¯†åˆ«å¹»è§‰ (Hallucination) æ¥æºå¹¶ç”Ÿæˆç®€æ˜æç¤ºï¼Œä»è€Œæ„å»ºå‡ºå¯¹æ¯”åº¦æ›´å¼ºä¸”åå¥½ä¿¡å·æ›´æ¸…æ™°çš„åŒç­–ç•¥åå¥½å¯¹ã€‚ç†è®ºåˆ†æè¯æ˜ï¼ŒåŸºäºæç¤ºçš„æ¡ä»¶åŒ–èƒ½é€šè¿‡äº’ä¿¡æ¯ (Mutual Information) æ‰©å¤§é¢„æœŸçš„åå¥½è¾¹é™… (Preference Margin)ï¼Œå¹¶åœ¨ä¿æŒç­–ç•¥åˆ†å¸ƒä¸€è‡´æ€§çš„åŒæ—¶æ˜¾è‘—æå‡æ ·æœ¬æ•ˆç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRPO åœ¨æ›´å°‘çš„è®­ç»ƒæ ·æœ¬å’Œè¿­ä»£æ¬¡æ•°ä¸‹å®ç°äº†å“è¶Šçš„å¯¹é½æ•ˆæœï¼Œå¤§å¹…é™ä½äº†æ¨¡å‹çš„å¹»è§‰ç‡ã€‚æœ€ç»ˆï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªå¤šæ¨¡æ€åŸºå‡†æµ‹è¯• (Multimodal Benchmarks) ä¸­å‡å–å¾—äº† State-of-the-Art (SOTA) çš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13240v1",
      "published_date": "2025-12-15 11:55:55 UTC",
      "updated_date": "2025-12-15 11:55:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:57:53.580587+00:00"
    },
    {
      "arxiv_id": "2512.13235v1",
      "title": "CORE: Contrastive Masked Feature Reconstruction on Graphs",
      "title_zh": "COREï¼šå›¾å¯¹æ¯”æ©ç ç‰¹å¾é‡æ„",
      "authors": [
        "Jianyuan Bo",
        "Yuan Fang"
      ],
      "abstract": "In the rapidly evolving field of self-supervised learning on graphs, generative and contrastive methodologies have emerged as two dominant approaches. Our study focuses on masked feature reconstruction (MFR), a generative technique where a model learns to restore the raw features of masked nodes in a self-supervised manner. We observe that both MFR and graph contrastive learning (GCL) aim to maximize agreement between similar elements. Building on this observation, we reveal a novel theoretical insight: under specific conditions, the objectives of MFR and node-level GCL converge, despite their distinct operational mechanisms. This theoretical connection suggests these approaches are complementary rather than fundamentally different, prompting us to explore their integration to enhance self-supervised learning on graphs. Our research presents Contrastive Masked Feature Reconstruction (CORE), a novel graph self-supervised learning framework that integrates contrastive learning into MFR. Specifically, we form positive pairs exclusively between the original and reconstructed features of masked nodes, encouraging the encoder to prioritize contextual information over the node's own features. Additionally, we leverage the masked nodes themselves as negative samples, combining MFR's reconstructive power with GCL's discriminative ability to better capture intrinsic graph structures. Empirically, our proposed framework CORE significantly outperforms MFR across node and graph classification tasks, demonstrating state-of-the-art results. In particular, CORE surpasses GraphMAE and GraphMAE2 by up to 2.80% and 3.72% on node classification tasks, and by up to 3.82% and 3.76% on graph classification tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾è‡ªç›‘ç£å­¦ä¹ (self-supervised learning on graphs)ä¸­ç”Ÿæˆå¼ä¸å¯¹æ¯”å­¦ä¹ æ–¹æ³•çš„èåˆå±•å¼€æ¢ç´¢ï¼Œæå‡ºäº†ä¸€ç§åä¸ºCOREçš„æ–°å‹æ¡†æ¶ã€‚ç ”ç©¶è€…é€šè¿‡ç†è®ºåˆ†ææ­ç¤ºï¼Œåœ¨ç‰¹å®šæ¡ä»¶ä¸‹ï¼Œé®è”½ç‰¹å¾é‡æ„(masked feature reconstruction, MFR)ä¸èŠ‚ç‚¹çº§å›¾å¯¹æ¯”å­¦ä¹ (graph contrastive learning, GCL)çš„ç›®æ ‡å‡½æ•°å…·æœ‰æ”¶æ•›æ€§ï¼Œè¯æ˜äº†ä¸¤è€…åœ¨æœ¬è´¨ä¸Šæ˜¯äº’è¡¥çš„ã€‚COREæ¡†æ¶å°†å¯¹æ¯”å­¦ä¹ ç­–ç•¥é›†æˆåˆ°MFRä¸­ï¼Œé€šè¿‡åœ¨è¢«é®è”½èŠ‚ç‚¹çš„åŸå§‹ç‰¹å¾ä¸é‡æ„ç‰¹å¾ä¹‹é—´æ„å»ºæ­£æ ·æœ¬å¯¹ï¼Œä¿ƒä½¿ç¼–ç å™¨ä¼˜å…ˆæå–ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨è¢«é®è”½èŠ‚ç‚¹ä½œä¸ºè´Ÿæ ·æœ¬ï¼Œæœ‰æ•ˆç»“åˆäº†MFRçš„é‡æ„èƒ½åŠ›ä¸GCLçš„åˆ¤åˆ«èƒ½åŠ›ï¼Œä»¥æ•æ‰å›¾ç»“æ„çš„å†…åœ¨ç‰¹å¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCOREåœ¨èŠ‚ç‚¹åˆ†ç±»å’Œå›¾åˆ†ç±»ä»»åŠ¡ä¸Šå‡å–å¾—äº†æ˜¾è‘—æå‡ï¼Œæ€§èƒ½ä¼˜äºGraphMAEå’ŒGraphMAE2ç­‰ä¸»æµæ¨¡å‹ã€‚å…·ä½“è€Œè¨€ï¼ŒCOREåœ¨èŠ‚ç‚¹åˆ†ç±»ä»»åŠ¡ä¸­æ¯”GraphMAE2æå‡äº†å¤šè¾¾3.72%ï¼Œåœ¨å›¾åˆ†ç±»ä»»åŠ¡ä¸­æå‡äº†å¤šè¾¾3.82%ï¼Œè¾¾åˆ°äº†å½“å‰çš„æœ€ä¼˜æ€§èƒ½(state-of-the-art)ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13235v1",
      "published_date": "2025-12-15 11:48:48 UTC",
      "updated_date": "2025-12-15 11:48:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:58:01.571904+00:00"
    },
    {
      "arxiv_id": "2512.13758v1",
      "title": "Network-Wide Traffic Volume Estimation from Speed Profiles using a Spatio-Temporal Graph Neural Network with Directed Spatial Attention",
      "title_zh": "åŸºäºé€Ÿåº¦å‰–é¢å’Œæœ‰å‘ç©ºé—´æ³¨æ„åŠ›æ—¶ç©ºå›¾ç¥ç»ç½‘ç»œçš„å…¨è·¯ç½‘äº¤é€šæµé‡ä¼°è®¡",
      "authors": [
        "LÃ©o Hein",
        "Giovanni de Nunzio",
        "Giovanni Chierchia",
        "AurÃ©lie Pirayre",
        "Laurent Najman"
      ],
      "abstract": "Existing traffic volume estimation methods typically address either forecasting traffic on sensor-equipped roads or spatially imputing missing volumes using nearby sensors. While forecasting models generally disregard unmonitored roads by design, spatial imputation methods explicitly address network-wide estimation; yet this approach relies on volume data at inference time, limiting its applicability in sensor-scarce cities. Unlike traffic volume data, probe vehicle speeds and static road attributes are more broadly accessible and support full coverage of road segments in most urban networks. In this work, we present the Hybrid Directed-Attention Spatio-Temporal Graph Neural Network (HDA-STGNN), an inductive deep learning framework designed to tackle the network-wide volume estimation problem. Our approach leverages speed profiles, static road attributes, and road network topology to predict daily traffic volume profiles across all road segments in the network. To evaluate the effectiveness of our approach, we perform extensive ablation studies that demonstrate the model's capacity to capture complex spatio-temporal dependencies and highlight the value of topological information for accurate network-wide traffic volume estimation without relying on volume data at inference time.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ æ„Ÿå™¨åŒ®ä¹åŸå¸‚ä¸­å…¨è·¯ç½‘äº¤é€šæµé‡ä¼°è®¡çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸º Hybrid Directed-Attention Spatio-Temporal Graph Neural Network (HDA-STGNN) çš„å½’çº³å¼æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å—é™äºä¼ æ„Ÿå™¨è¦†ç›–èŒƒå›´æˆ–åœ¨æ¨ç†é˜¶æ®µå¯¹å®æ—¶æµé‡æ•°æ®çš„ä¾èµ–ï¼Œè€Œ HDA-STGNN åˆ›æ–°æ€§åœ°åˆ©ç”¨å¹¿æ³›å¯å¾—çš„ Speed profilesã€é™æ€é“è·¯å±æ€§ä»¥åŠè·¯ç½‘æ‹“æ‰‘ç»“æ„æ¥é¢„æµ‹å…¨è·¯æ®µçš„æ¯æ—¥æµé‡å‰–é¢ã€‚è¯¥æ¨¡å‹é€šè¿‡é›†æˆæœ‰å‘ç©ºé—´æ³¨æ„åŠ›çš„æ—¶ç©ºå›¾ç¥ç»ç½‘ç»œï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰å¤æ‚çš„ Spatio-Temporal ä¾èµ–å…³ç³»ã€‚æ¶ˆèå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ¨ç†é˜¶æ®µä¸ä¾èµ–æµé‡æ•°æ®çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡å……åˆ†åˆ©ç”¨æ‹“æ‰‘ä¿¡æ¯æ˜¾è‘—æå‡äº†ä¼°ç®—ç²¾åº¦ã€‚è¿™ä¸€ç ”ç©¶æˆæœä¸ºå¤§è§„æ¨¡åŸå¸‚è·¯ç½‘ä¸­æ— ç›‘æµ‹è·¯æ®µçš„äº¤é€šæ€åŠ¿æ„ŸçŸ¥æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯æ‰©å±•çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13758v1",
      "published_date": "2025-12-15 11:30:44 UTC",
      "updated_date": "2025-12-15 11:30:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:58:02.699838+00:00"
    },
    {
      "arxiv_id": "2512.15783v1",
      "title": "AI Epidemiology: achieving explainable AI through expert oversight patterns",
      "title_zh": "AI Epidemiologyï¼šåŸºäºä¸“å®¶ç›‘ç®¡æ¨¡å¼å®ç°å¯è§£é‡Šäººå·¥æ™ºèƒ½",
      "authors": [
        "Kit Tempest-Walters"
      ],
      "abstract": "AI Epidemiology is a framework for governing and explaining advanced AI systems by applying population-level surveillance methods to AI outputs. The approach mirrors the way in which epidemiologists enable public health interventions through statistical evidence before molecular mechanisms are understood. This bypasses the problem of model complexity which plagues current interpretability methods (such as SHAP and mechanistic interpretability) at the scale of deployed models.\n  AI Epidemiology achieves this population-level surveillance by standardising capture of AI-expert interactions into structured assessment fields: risk level, alignment score, and accuracy score. These function as exposure variables which predict output failure through statistical associations, much like cholesterol and blood pressure act as exposure variables predicting cardiac events. Output-failure associations are subsequently validated against expert overrides and real-world outcomes.\n  The framework places zero burden on experts and provides automatic audit trails by passively tracking expert convergence and divergence with AI recommendations. Since it analyses outputs rather than internal model computations, it also provides governance continuity when institutions update models and switch vendors. Finally, by providing reliability scores and semantic assessments (e.g. 'this recommendation resembles 500 cases overridden by experts due to guideline violations'), it enables experts and institutions to detect unreliable AI outputs before they cause harm. This democratises AI oversight by enabling domain experts to govern AI systems without requiring machine learning expertise.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AI Epidemiologyï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡å°†äººå£çº§ç›‘æµ‹æ–¹æ³•åº”ç”¨äº AI è¾“å‡ºï¼Œä»è€Œå¯¹å…ˆè¿› AI ç³»ç»Ÿè¿›è¡Œæ²»ç†å’Œè§£é‡Šçš„æ¡†æ¶ã€‚è¯¥æ–¹æ³•å€Ÿé‰´äº†æµè¡Œç—…å­¦åœ¨å®Œå…¨ç†è§£åˆ†å­æœºåˆ¶å‰é€šè¿‡ç»Ÿè®¡è¯æ®å®ç°å¹²é¢„çš„æ€è·¯ï¼Œæœ‰æ•ˆç»•è¿‡äº† SHAP å’Œ mechanistic interpretability ç­‰ä¼ ç»Ÿæ–¹æ³•åœ¨å¤„ç†å¤§è§„æ¨¡æ¨¡å‹æ—¶é¢ä¸´çš„å¤æ‚åº¦éš¾é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡æ ‡å‡†åŒ–æ•æ‰ AI ä¸ä¸“å®¶çš„äº¤äº’ï¼Œå¹¶å°†é£é™©ç­‰çº§ã€å¯¹é½å¾—åˆ†å’Œå‡†ç¡®ç‡ç­‰å­—æ®µä½œä¸ºé¢„æµ‹æ¨¡å‹æ•…éšœçš„æš´éœ²å˜é‡ï¼Œéšååˆ©ç”¨ä¸“å®¶è¦†ç›–ï¼ˆexpert overridesï¼‰å’Œç°å®ç»“æœè¿›è¡ŒéªŒè¯ã€‚AI Epidemiology èƒ½å¤Ÿåœ¨ä¸å¢åŠ ä¸“å®¶è´Ÿæ‹…çš„æƒ…å†µä¸‹æä¾›è‡ªåŠ¨å®¡è®¡è½¨è¿¹ï¼Œå¹¶åœ¨æ¨¡å‹æ›´æ–°æˆ–æ›´æ¢ä¾›åº”å•†æ—¶ç¡®ä¿æ²»ç†çš„è¿ç»­æ€§ã€‚é€šè¿‡æä¾›å¯é æ€§è¯„åˆ†å’Œè¯­ä¹‰è¯„ä¼°ï¼Œè¯¥ç³»ç»Ÿä½¿é¢†åŸŸä¸“å®¶æ— éœ€å…·å¤‡æœºå™¨å­¦ä¹ ä¸“ä¸šçŸ¥è¯†å³å¯è¯†åˆ«ä¸å¯é çš„ AI è¾“å‡ºï¼Œä»è€Œå®ç°äº† AI ç›‘ç£çš„æ°‘ä¸»åŒ–ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "41 pages, 1 figure, 7 tables",
      "pdf_url": "https://arxiv.org/pdf/2512.15783v1",
      "published_date": "2025-12-15 11:29:05 UTC",
      "updated_date": "2025-12-15 11:29:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:58:36.642982+00:00"
    },
    {
      "arxiv_id": "2512.22152v1",
      "title": "Neural ocean forecasting from sparse satellite-derived observations: a case-study for SSH dynamics and altimetry data",
      "title_zh": "åŸºäºç¨€ç–å«æ˜Ÿè§‚æµ‹æ•°æ®çš„ç¥ç»ç½‘ç»œæµ·æ´‹é¢„æŠ¥ï¼šæµ·é¢é«˜åº¦åŠ¨åŠ›å­¦ä¸æµ‹é«˜æ•°æ®æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Daria Botvynko",
        "Pierre HaslÃ©e",
        "Lucile Gaultier",
        "Bertrand Chapron",
        "Clement de Boyer MontÃ©gut",
        "Anass El Aouni",
        "Julien Le Sommer",
        "Ronan Fablet"
      ],
      "abstract": "We present an end-to-end deep learning framework for short-term forecasting of global sea surface dynamics based on sparse satellite altimetry data. Building on two state-of-the-art architectures: U-Net and 4DVarNet, originally developed for image segmentation and spatiotemporal interpolation respectively, we adapt the models to forecast the sea level anomaly and sea surface currents over a 7-day horizon using sequences of sparse nadir altimeters observations. The model is trained on data from the GLORYS12 operational ocean reanalysis, with synthetic nadir sampling patterns applied to simulate realistic observational coverage. The forecasting task is formulated as a sequence-to-sequence mapping, with the input comprising partial sea level anomaly (SLA) snapshots and the target being the corresponding future full-field SLA maps. We evaluate model performance using (i) normalized root mean squared error (nRMSE), (ii) averaged effective resolution, (iii) percentage of correctly predicted velocities magnitudes and angles, and benchmark results against the operational Mercator Ocean forecast product. Results show that end-to-end neural forecasts outperform the baseline across all lead times, with particularly notable improvements in high variability regions. Our framework is developed within the OceanBench benchmarking initiative, promoting reproducibility and standardized evaluation in ocean machine learning. These results demonstrate the feasibility and potential of end-to-end neural forecasting models for operational oceanography, even in data-sparse conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºåŸºäºç¨€ç–å«æ˜Ÿé«˜åº¦è®¡è§‚æµ‹æ•°æ®è¿›è¡Œå…¨çƒæµ·é¢åŠ¨åŠ›å­¦çš„çŸ­æœŸé¢„æµ‹ã€‚è¯¥æ¡†æ¶åŸºäº U-Net å’Œ 4DVarNet ä¸¤ç§æ¶æ„è¿›è¡Œæ”¹è¿›ï¼Œå®ç°äº†å¯¹æµ·å¹³é¢å¼‚å¸¸ (Sea Level Anomaly, SLA) å’Œæµ·é¢æµåœºçš„ 7 å¤©é¢„æŠ¥ã€‚ç ”ç©¶åˆ©ç”¨ GLORYS12 æ“ä½œæµ·æ´‹å†åˆ†ææ•°æ®è¿›è¡Œè®­ç»ƒï¼Œé€šè¿‡åˆæˆé‡‡æ ·æ¨¡å¼æ¨¡æ‹ŸçœŸå®è§‚æµ‹è¦†ç›–ï¼Œå¹¶å°†é¢„æµ‹ä»»åŠ¡å»ºæ¨¡ä¸ºåºåˆ—åˆ°åºåˆ— (Sequence-to-Sequence) çš„æ˜ å°„ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥ç¥ç»é¢„æµ‹æ¨¡å‹åœ¨å½’ä¸€åŒ–å‡æ–¹æ ¹è¯¯å·® (nRMSE) å’Œæœ‰æ•ˆåˆ†è¾¨ç‡ç­‰æŒ‡æ ‡ä¸Šå‡ä¼˜äº Mercator Ocean ä¸šåŠ¡é¢„æŠ¥äº§å“ï¼Œå°¤å…¶åœ¨æµ·å†µé«˜å˜ç‡åŒºåŸŸè¡¨ç°å‡ºæ˜¾è‘—æ€§èƒ½æå‡ã€‚è¯¥æ¡†æ¶ä½œä¸º OceanBench å€¡è®®çš„ä¸€éƒ¨åˆ†ï¼Œä¸ä»…æå‡äº†ç ”ç©¶çš„å¯å¤ç°æ€§ï¼Œè¿˜è¯æ˜äº†ç«¯åˆ°ç«¯ç¥ç»ç½‘ç»œåœ¨æ•°æ®ç¨€ç–æ¡ä»¶ä¸‹è¿›è¡Œä¸šåŠ¡åŒ–æµ·æ´‹é¢„æŠ¥çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.22152v1",
      "published_date": "2025-12-15 11:28:03 UTC",
      "updated_date": "2025-12-15 11:28:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:58:33.690353+00:00"
    },
    {
      "arxiv_id": "2512.13194v3",
      "title": "Efficient Adaptive Rejection Sampling for Accelerating Speculative Decoding in Large Language Models",
      "title_zh": "ç”¨äºåŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹æŠ•æœºæ€§è§£ç çš„é«˜æ•ˆè‡ªé€‚åº”æ‹’ç»é‡‡æ ·",
      "authors": [
        "Chendong Sun",
        "Ali Mao",
        "Lei Xu",
        "mingmin Chen"
      ],
      "abstract": "Speculative Decoding is a prominent technique for accelerating the autoregressive inference of large language models (LLMs) by employing a fast draft model to propose candidate token sequences and a large target model to verify them in parallel. However, its core component -- the rejection sampling mechanism -- relies on a fixed, context-independent random threshold. This leads to a significant \"random rejection\" problem in high-uncertainty generation scenarios, where plausible candidate tokens are frequently rejected due to random chance, undermining inference efficiency. This paper introduces Efficient Adaptive Rejection Sampling (EARS), a novel method that dynamically adjusts the acceptance threshold by incorporating the target model's own predictive uncertainty, measured as 1 - max(P_target). By introducing a tolerance term proportional to this uncertainty, EARS intelligently relaxes the acceptance criterion when the model is uncertain, effectively reducing random rejections while maintaining strict standards when the model is confident. Experiments on creative writing and open-domain QA tasks demonstrate that EARS significantly enhances the efficiency of speculative decoding, achieving up to an 18.12% increase in throughput with a negligible 0.84% accuracy drop on the GSM8K benchmark. The method requires no modifications to model architectures and can be seamlessly integrated into existing speculative decoding frameworks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) æ¨ç†åŠ é€Ÿä¸­çš„æŠ•æœºè§£ç  (Speculative Decoding) æŠ€æœ¯ï¼ŒæŒ‡å‡ºäº†å…¶æ ¸å¿ƒæ‹’ç»é‡‡æ · (rejection sampling) æœºåˆ¶å› ä½¿ç”¨å›ºå®šéšæœºé˜ˆå€¼è€Œåœ¨é«˜ä¸ç¡®å®šæ€§åœºæ™¯ä¸‹äº§ç”Ÿçš„â€œéšæœºæ‹’ç»â€é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†é«˜æ•ˆè‡ªé€‚åº”æ‹’ç»é‡‡æ · (Efficient Adaptive Rejection Sampling, EARS)ï¼Œé€šè¿‡å¼•å…¥ç›®æ ‡æ¨¡å‹é¢„æµ‹ä¸ç¡®å®šæ€§ï¼ˆå³ 1 - max(P_target)ï¼‰ä½œä¸ºå®¹é”™é¡¹ï¼ŒåŠ¨æ€è°ƒæ•´æ¥å—é˜ˆå€¼ã€‚å½“æ¨¡å‹ä¸ç¡®å®šæ€§è¾ƒé«˜æ—¶ï¼ŒEARS ä¼šæ™ºèƒ½æ”¾å®½æ¥å—æ ‡å‡†ä»¥å‡å°‘ä¸å¿…è¦çš„æ‹’ç»ï¼Œè€Œåœ¨æ¨¡å‹ç½®ä¿¡åº¦é«˜æ—¶ä¿æŒä¸¥æ ¼éªŒè¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨åˆ›æ„å†™ä½œå’Œé—®ç­”ä»»åŠ¡ä¸­æ˜¾è‘—å¢å¼ºäº†æ¨ç†æ•ˆç‡ï¼Œåœ¨ GSM8K åŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†æœ€é«˜ 18.12% çš„ååé‡æå‡ï¼Œä¸”å‡†ç¡®ç‡ä¸‹é™ä»…ä¸º 0.84%ã€‚æ­¤å¤–ï¼ŒEARS æ— éœ€ä¿®æ”¹æ¨¡å‹æ¶æ„å³å¯æ— ç¼é›†æˆåˆ°ç°æœ‰æ¡†æ¶ä¸­ï¼Œä¸ºæå‡ LLMs çš„è‡ªå›å½’æ¨ç†é€Ÿåº¦æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”çµæ´»çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13194v3",
      "published_date": "2025-12-15 11:08:56 UTC",
      "updated_date": "2025-12-17 03:36:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:58:23.106652+00:00"
    },
    {
      "arxiv_id": "2512.13190v1",
      "title": "WAY: Estimation of Vessel Destination in Worldwide AIS Trajectory",
      "title_zh": "WAYï¼šå…¨çƒ AIS è½¨è¿¹ä¸­çš„èˆ¹èˆ¶ç›®çš„åœ°ä¼°è®¡",
      "authors": [
        "Jin Sob Kim",
        "Hyun Joon Park",
        "Wooseok Shin",
        "Dongil Park",
        "Sung Won Han"
      ],
      "abstract": "The Automatic Identification System (AIS) enables data-driven maritime surveillance but suffers from reliability issues and irregular intervals. We address vessel destination estimation using global-scope AIS data by proposing a differentiated approach that recasts long port-to-port trajectories as a nested sequence structure. Using spatial grids, this method mitigates spatio-temporal bias while preserving detailed resolution. We introduce a novel deep learning architecture, WAY, designed to process these reformulated trajectories for long-term destination estimation days to weeks in advance. WAY comprises a trajectory representation layer and Channel-Aggregative Sequential Processing (CASP) blocks. The representation layer generates multi-channel vector sequences from kinematic and non-kinematic features. CASP blocks utilize multi-headed channel- and self-attention for aggregation and sequential information delivery. Additionally, we propose a task-specialized Gradient Dropout (GD) technique to enable many-to-many training on single labels, preventing biased feedback surges by stochastically blocking gradient flow based on sample length. Experiments on 5-year AIS data demonstrate WAY's superiority over conventional spatial grid-based approaches regardless of trajectory progression. Results further confirm that adopting GD leads to performance gains. Finally, we explore WAY's potential for real-world application through multitask learning for ETA estimation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†WAYï¼Œä¸€ç§ä¸“ä¸ºå…¨çƒèŒƒå›´å†…AISè½¨è¿¹è¿›è¡Œé•¿æœŸèˆ¹èˆ¶ç›®çš„åœ°ä¼°è®¡è€Œè®¾è®¡çš„æ·±åº¦å­¦ä¹ æ¶æ„ã€‚ä¸ºäº†è§£å†³AISæ•°æ®å¯é æ€§åŠé‡‡æ ·é—´éš”ä¸è§„å¾‹çš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ç©ºé—´ç½‘æ ¼(Spatial Grids)å°†é•¿é€”æ¸¯å£è½¨è¿¹é‡æ„ä¸ºåµŒå¥—åºåˆ—ç»“æ„ï¼Œåœ¨ä¿ç•™é«˜åˆ†è¾¨ç‡çš„åŒæ—¶å‡è½»äº†æ—¶ç©ºåå·®ã€‚WAYæ¶æ„åŒ…å«è½¨è¿¹è¡¨ç¤ºå±‚å’Œé€šé“èšåˆåºåˆ—å¤„ç†(CASP)å—ï¼Œé€šè¿‡å¤šå¤´é€šé“ä¸è‡ªæ³¨æ„åŠ›æœºåˆ¶å®ç°é«˜æ•ˆçš„ä¿¡æ¯èšåˆä¸åºåˆ—å¤„ç†ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†é’ˆå¯¹è¯¥ä»»åŠ¡è®¾è®¡çš„æ¢¯åº¦ä¸¢å¼ƒ(Gradient Dropout)æŠ€æœ¯ï¼Œé€šè¿‡éšæœºé˜»å¡æ¢¯åº¦æµæ¥ä¼˜åŒ–å•æ ‡ç­¾çš„å¤šå¯¹å¤šè®­ç»ƒè¿‡ç¨‹ã€‚åœ¨é•¿è¾¾äº”å¹´çš„AISæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒWAYåœ¨ä¸åŒè½¨è¿¹é˜¶æ®µçš„é¢„æµ‹è¡¨ç°å‡ä¼˜äºä¼ ç»Ÿç©ºé—´ç½‘æ ¼æ–¹æ³•ï¼Œä¸”æ¢¯åº¦ä¸¢å¼ƒæŠ€æœ¯æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ã€‚æœ€åï¼Œè¯¥æ¨¡å‹é€šè¿‡å¤šä»»åŠ¡å­¦ä¹ å±•ç¤ºäº†åœ¨é¢„è®¡åˆ°è¾¾æ—¶é—´(ETA)ä¼°è®¡ç­‰å®é™…åº”ç”¨åœºæ™¯ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to IEEE Transactions on Aerospace and Electronic Systems (TAES)",
      "pdf_url": "https://arxiv.org/pdf/2512.13190v1",
      "published_date": "2025-12-15 10:55:20 UTC",
      "updated_date": "2025-12-15 10:55:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:58:39.957324+00:00"
    },
    {
      "arxiv_id": "2512.13186v1",
      "title": "PolySet: Restoring the Statistical Ensemble Nature of Polymers for Machine Learning",
      "title_zh": "PolySetï¼šé¢å‘æœºå™¨å­¦ä¹ å›å½’èšåˆç‰©çš„ç»Ÿè®¡ç³»ç»¼æœ¬è´¨",
      "authors": [
        "Khalid Ferji"
      ],
      "abstract": "Machine-learning (ML) models in polymer science typically treat a polymer as a single, perfectly defined molecular graph, even though real materials consist of stochastic ensembles of chains with distributed lengths. This mismatch between physical reality and digital representation limits the ability of current models to capture polymer behaviour. Here we introduce PolySet, a framework that represents a polymer as a finite, weighted ensemble of chains sampled from an assumed molar-mass distribution. This ensemble-based encoding is independent of chemical detail, compatible with any molecular representation and illustrated here in the homopolymer case using a minimal language model. We show that PolySet retains higher-order distributional moments (such as Mz, Mz+1), enabling ML models to learn tail-sensitive properties with greatly improved stability and accuracy. By explicitly acknowledging the statistical nature of polymer matter, PolySet establishes a physically grounded foundation for future polymer machine learning, naturally extensible to copolymers, block architectures, and other complex topologies.",
      "tldr_zh": "ç›®å‰çš„é«˜åˆ†å­ç§‘å­¦æœºå™¨å­¦ä¹ (ML)æ¨¡å‹é€šå¸¸å°†èšåˆç‰©è§†ä¸ºå•ä¸€ä¸”ç¡®å®šçš„åˆ†å­å›¾ï¼Œå¿½ç•¥äº†çœŸå®ææ–™ç”±å…·æœ‰åˆ†å¸ƒé•¿åº¦çš„éšæœºé“¾ç»„æˆçš„ç»Ÿè®¡åˆ†å¸ƒæœ¬è´¨ã€‚è¯¥ç ”ç©¶æå‡ºäº†PolySetæ¡†æ¶ï¼Œé€šè¿‡å°†èšåˆç‰©è¡¨ç¤ºä¸ºä»æ‘©å°”è´¨é‡åˆ†å¸ƒ(molar-mass distribution)ä¸­é‡‡æ ·å¾—åˆ°çš„æœ‰é™æƒé‡é“¾é›†åˆï¼Œä»è€Œè¿˜åŸäº†èšåˆç‰©çš„ç»Ÿè®¡ç³»ç»¼(Statistical Ensemble)å±æ€§ã€‚è¿™ç§åŸºäºç³»ç»¼çš„ç¼–ç æ–¹å¼ä¸åŒ–å­¦ç»†èŠ‚æ— å…³ï¼Œèƒ½å¤Ÿä¸ä»»ä½•åˆ†å­è¡¨ç¤ºæ–¹æ³•å…¼å®¹ï¼Œå¹¶åœ¨æ­¤ä»¥å‡èšç‰©(homopolymer)ä¸ºä¾‹è¿›è¡Œäº†å±•ç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPolySetèƒ½å¤Ÿæœ‰æ•ˆä¿ç•™å¦‚Mzã€Mz+1ç­‰é«˜é˜¶åˆ†å¸ƒçŸ©ï¼Œä½¿æ¨¡å‹åœ¨å­¦ä¹ å¯¹åˆ†å¸ƒå°¾éƒ¨æ•æ„Ÿçš„å±æ€§æ—¶æ˜¾è‘—æé«˜äº†ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚é€šè¿‡æ˜ç¡®æ‰¿è®¤èšåˆç‰©çš„ç»Ÿè®¡æœ¬è´¨ï¼ŒPolySetä¸ºæœªæ¥çš„é«˜åˆ†å­æœºå™¨å­¦ä¹ å¥ å®šäº†åšå®çš„ç‰©ç†åŸºç¡€ï¼Œå¹¶å¯è‡ªç„¶æ‰©å±•è‡³å…±èšç‰©(copolymers)åŠå…¶ä»–å¤æ‚æ‹“æ‰‘ç»“æ„ã€‚",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13186v1",
      "published_date": "2025-12-15 10:50:48 UTC",
      "updated_date": "2025-12-15 10:50:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:58:58.945763+00:00"
    },
    {
      "arxiv_id": "2512.13174v1",
      "title": "Carrot, stick, or both? Price incentives for sustainable food choice in competitive environments",
      "title_zh": "èƒ¡èåœã€å¤§æ£’ï¼Œè¿˜æ˜¯ä¸¤è€…å…¼å¾—ï¼Ÿç«äº‰ç¯å¢ƒä¸‹å¯æŒç»­é£Ÿå“é€‰æ‹©çš„ä»·æ ¼æ¿€åŠ±",
      "authors": [
        "Francesco Salvi",
        "Giuseppe Russo",
        "Adam Barla",
        "Vincent Moreau",
        "Robert West"
      ],
      "abstract": "Meat consumption is a major driver of global greenhouse gas emissions. While pricing interventions have shown potential to reduce meat intake, previous studies have focused on highly constrained environments with limited consumer choice. Here, we present the first large-scale field experiment to evaluate multiple pricing interventions in a real-world, competitive setting. Using a sequential crossover design with matched menus in a Swiss university campus, we systematically compared vegetarian-meal discounts (-2.5 CHF), meat surcharges (+2.5 CHF), and a combined scheme (-1.2 CHF=+1.2 CHF) across four campus cafeterias. Only the surcharge and combined interventions led to significant increases in vegetarian meal uptake--by 26.4% and 16.6%, respectively--and reduced CO2 emissions per meal by 7.4% and 11.3%, respectively. The surcharge, while effective, triggered a 12.3% drop in sales at intervention sites and a corresponding 14.9% increase in non-treated locations, hence causing a spillover effect that completely offset environmental gains. In contrast, the combined approach achieved meaningful emission reductions without significant effects on overall sales or revenue, making it both effective and economically viable. Notably, pricing interventions were equally effective for both vegetarian-leaning customers and habitual meat-eaters, stimulating change even within entrenched dietary habits. Our results show that balanced pricing strategies can reduce the carbon footprint of realistic food environments, but require coordinated implementation to maximize climate benefits and avoid unintended spillover effects.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ç«äº‰æ€§ç¯å¢ƒ(Competitive environments)ä¸‹é€šè¿‡ä»·æ ¼æ¿€åŠ±ä¿ƒè¿›å¯æŒç»­é£Ÿå“é€‰æ‹©çš„æ•ˆæœï¼Œå¯¹æ¯”äº†ç´ é£ŸæŠ˜æ‰£ã€è‚‰ç±»é™„åŠ è´¹ä»¥åŠç»“åˆä¸¤è€…çš„æ··åˆæ–¹æ¡ˆã€‚é€šè¿‡åœ¨ç‘å£«å¤§å­¦æ ¡å›­è¿›è¡Œçš„åºåˆ—äº¤å‰è®¾è®¡(Sequential crossover design)å®åœ°å®éªŒå‘ç°ï¼Œä»…è‚‰ç±»é™„åŠ è´¹å’Œæ··åˆæ–¹æ¡ˆèƒ½æ˜¾è‘—æé«˜ç´ é£Ÿæ‘„å…¥æ¯”ä¾‹å¹¶æœ‰æ•ˆé™ä½äºŒæ°§åŒ–ç¢³æ’æ”¾ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œè™½ç„¶å•çº¯çš„é™„åŠ è´¹æ¨¡å¼æ•ˆæœæ˜¾è‘—ï¼Œä½†ä¼šå¼•å‘æ˜æ˜¾çš„æº¢å‡ºæ•ˆåº”(Spillover effect)ï¼Œå¯¼è‡´æ¶ˆè´¹è€…è½¬å‘æœªå¹²é¢„åœ°ç‚¹ï¼Œä»è€Œå®Œå…¨æŠµæ¶ˆç¯å¢ƒæ”¶ç›Šã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç»“åˆäº†å¾®é‡æŠ˜æ‰£ä¸é™„åŠ è´¹çš„æ··åˆæ–¹æ¡ˆåœ¨å®ç°æ˜¾è‘—å‡æ’çš„åŒæ—¶ï¼Œæœªå¯¹æ€»é”€å”®é¢æˆ–æ”¶å…¥äº§ç”Ÿè´Ÿé¢å½±å“ï¼Œå±•ç°å‡ºæ›´é«˜çš„ç»æµå¯è¡Œæ€§ã€‚è¯¥å®éªŒè¯æ˜è¿™ç§å‡è¡¡çš„ä»·æ ¼ç­–ç•¥å¯¹ä¹ æƒ¯æ€§è‚‰é£Ÿè€…åŒæ ·æœ‰æ•ˆï¼Œèƒ½å¤Ÿä¿ƒæˆé¥®é£Ÿä¹ æƒ¯çš„æ”¹å˜ã€‚ç ”ç©¶æœ€åå¼ºè°ƒï¼Œæ­¤ç±»å¹²é¢„æªæ–½éœ€é€šè¿‡åè°ƒå®æ–½æ¥æœ€å¤§åŒ–æ°”å€™æ•ˆç›Šï¼Œå¹¶é¿å…éé¢„æœŸçš„å¸‚åœºæµå¤±ã€‚",
      "categories": [
        "econ.GN",
        "cs.AI"
      ],
      "primary_category": "econ.GN",
      "comment": "10 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.13174v1",
      "published_date": "2025-12-15 10:35:44 UTC",
      "updated_date": "2025-12-15 10:35:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:58:54.079466+00:00"
    },
    {
      "arxiv_id": "2512.13168v3",
      "title": "Finch: Benchmarking Finance & Accounting across Spreadsheet-Centric Enterprise Workflows",
      "title_zh": "Finchï¼šé¢å‘ä»¥ç”µå­è¡¨æ ¼ä¸ºä¸­å¿ƒçš„ä¼ä¸šå·¥ä½œæµçš„è´¢åŠ¡ä¸ä¼šè®¡åŸºå‡†æµ‹è¯•",
      "authors": [
        "Haoyu Dong",
        "Pengkun Zhang",
        "Yan Gao",
        "Xuanyu Dong",
        "Yilin Cheng",
        "Mingzhe Lu",
        "Adina Yakefu",
        "Shuxin Zheng"
      ],
      "abstract": "We introduce a finance & accounting benchmark (Finch) for evaluating AI agents on real-world, enterprise-grade professional workflows -- interleaving data entry, structuring, formatting, web search, cross-file retrieval, calculation, modeling, validation, translation, visualization, and reporting. Finch is sourced from authentic enterprise workspaces at Enron (15,000 spreadsheets and 500,000 emails from 150 employees) and other financial institutions, preserving in-the-wild messiness across multimodal artifacts (text, tables, formulas, charts, code, and images) and spanning diverse domains such as budgeting, trading, and asset management.\n  We propose a workflow construction process that combines LLM-assisted discovery with expert annotation: (1) LLM-assisted, expert-verified derivation of workflows from real-world email threads and version histories of spreadsheet files, and (2) meticulous expert annotation for workflows, requiring over 700 hours of domain-expert effort. This yields 172 composite workflows with 384 tasks, involving 1,710 spreadsheets with 27 million cells, along with PDFs and other artifacts, capturing the intrinsically messy, long-horizon, knowledge-intensive, and collaborative nature of real-world enterprise work.\n  We conduct both human and automated evaluations of frontier AI systems including GPT 5.1, Claude Sonnet 4.5, Gemini 3 Pro, Grok 4, and Qwen 3 Max, and GPT 5.1 Pro spends 16.8 minutes per workflow yet passes only 38.4% of workflows, while Claude Sonnet 4.5 passes just 25.0%. Comprehensive case studies further surface the challenges that real-world enterprise workflows pose for AI agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†Finchï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹é‡‘èä¸ä¼šè®¡(Finance & Accounting)é¢†åŸŸçš„AIæ™ºèƒ½ä½“è¯„æµ‹åŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°å…¶å¤„ç†çœŸå®ä¼ä¸šçº§ä¸“ä¸šå·¥ä½œæµçš„èƒ½åŠ›ã€‚Finchçš„æ•°æ®æºè‡ªEnronç­‰é‡‘èæœºæ„çš„çœŸå®åŠå…¬ç©ºé—´ï¼Œæ¶µç›–äº†æ•°æ®å½•å…¥ã€è®¡ç®—ã€å»ºæ¨¡ã€æŠ¥å‘Šç”Ÿæˆç­‰å¤šç§äº¤ç»‡çš„ä»»åŠ¡ï¼Œå¹¶ä¿ç•™äº†ç°å®åœºæ™¯ä¸­å¤šæ¨¡æ€å·¥ä»¶ï¼ˆå¦‚è¡¨æ ¼ã€å…¬å¼ã€ä»£ç å’Œå›¾åƒï¼‰çš„å¤æ‚æ€§ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡LLMè¾…åŠ©å‘ç°ä¸ä¸“å®¶æ ‡æ³¨ç›¸ç»“åˆçš„æµç¨‹ï¼ŒæŠ•å…¥è¶…è¿‡700å°æ—¶çš„ä¸“å®¶ç²¾åŠ›ï¼Œæ„å»ºäº†åŒ…å«172ä¸ªå¤åˆå·¥ä½œæµå’Œ384ä¸ªä»»åŠ¡çš„åŸºå‡†ã€‚å¯¹GPT 5.1ã€Claude Sonnet 4.5å’ŒGemini 3 Proç­‰å‰æ²¿AIç³»ç»Ÿçš„è¯„ä¼°æ˜¾ç¤ºï¼Œå³ä½¿æ˜¯æœ€å¼ºæ¨¡å‹åœ¨å¤„ç†è¿™äº›é•¿è·¯å¾„ã€çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡æ—¶ä¹Ÿé¢ä¸´å·¨å¤§æŒ‘æˆ˜ï¼Œå…¶ä¸­GPT 5.1 Proçš„é€šè¿‡ç‡ä»…ä¸º38.4%ã€‚è¯¥åŸºå‡†é€šè¿‡æ•æ‰ä¼ä¸šå·¥ä½œä¸­æœ¬è´¨ä¸Šçš„å¤æ‚æ€§ã€é•¿è·¯å¾„å’ŒçŸ¥è¯†å¯†é›†å‹ç‰¹å¾ï¼Œä¸ºå¼€å‘æ›´å¯é çš„ä¸“ä¸šé¢†åŸŸAIåŠ©æ‰‹æä¾›äº†é‡è¦çš„å®éªŒåŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.IR",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13168v3",
      "published_date": "2025-12-15 10:28:45 UTC",
      "updated_date": "2026-01-03 05:28:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:59:04.440060+00:00"
    },
    {
      "arxiv_id": "2512.13165v1",
      "title": "SACn: Soft Actor-Critic with n-step Returns",
      "title_zh": "SACnï¼šåŸºäº n æ­¥å›æŠ¥çš„ Soft Actor-Critic ç®—æ³•",
      "authors": [
        "Jakub Åyskawa",
        "Jakub Lewandowski",
        "PaweÅ‚ WawrzyÅ„ski"
      ],
      "abstract": "Soft Actor-Critic (SAC) is widely used in practical applications and is now one of the most relevant off-policy online model-free reinforcement learning (RL) methods. The technique of n-step returns is known to increase the convergence speed of RL algorithms compared to their 1-step returns-based versions. However, SAC is notoriously difficult to combine with n-step returns, since their usual combination introduces bias in off-policy algorithms due to the changes in action distribution. While this problem is solved by importance sampling, a method for estimating expected values of one distribution using samples from another distribution, importance sampling may result in numerical instability. In this work, we combine SAC with n-step returns in a way that overcomes this issue. We present an approach to applying numerically stable importance sampling with simplified hyperparameter selection. Furthermore, we analyze the entropy estimation approach of Soft Actor-Critic in the context of the n-step maximum entropy framework and formulate the $Ï„$-sampled entropy estimation to reduce the variance of the learning target. Finally, we formulate the Soft Actor-Critic with n-step returns (SAC$n$) algorithm that we experimentally verify on MuJoCo simulated environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SACn ç®—æ³•ï¼Œæ—¨åœ¨è§£å†³ Soft Actor-Critic (SAC) ä¸ n-step returns ç»“åˆæ—¶ï¼Œå› åŠ¨ä½œåˆ†å¸ƒå˜åŒ–å¯¼è‡´çš„åå·®ä»¥åŠæ•°å€¼ä¸ç¨³å®šæ€§é—®é¢˜ã€‚ç ”ç©¶äººå‘˜é€šè¿‡å¼•å…¥ä¸€ç§æ•°å€¼ç¨³å®šçš„é‡è¦æ€§é‡‡æ · (Importance Sampling) æ–¹æ³•å¹¶ç®€åŒ–è¶…å‚æ•°é€‰æ‹©ï¼Œæœ‰æ•ˆå…‹æœäº†ç¦»ç­– (off-policy) ç®—æ³•åœ¨åº”ç”¨å¤šæ­¥å›æŠ¥æ—¶çš„è®¡ç®—æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œåœ¨ n-step æœ€å¤§ç†µæ¡†æ¶ä¸‹å¯¹ç†µä¼°è®¡è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œå¹¶è¿›ä¸€æ­¥æå‡ºäº† $\\tau$-sampled ç†µä¼°è®¡æ–¹æ³•ï¼Œä»¥æ˜¾è‘—é™ä½å­¦ä¹ ç›®æ ‡çš„æ–¹å·®ã€‚å®éªŒç»“æœåœ¨ MuJoCo æ¨¡æ‹Ÿç¯å¢ƒä¸‹å¾—åˆ°äº†éªŒè¯ï¼Œè¯æ˜äº† SACn åœ¨æå‡æ”¶æ•›é€Ÿåº¦çš„åŒæ—¶ä¿æŒäº†è‰¯å¥½çš„æ•°å€¼ç¨³å®šæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICAART 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.13165v1",
      "published_date": "2025-12-15 10:23:13 UTC",
      "updated_date": "2025-12-15 10:23:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:58:55.999972+00:00"
    },
    {
      "arxiv_id": "2512.13164v2",
      "title": "A Semantically Enhanced Generative Foundation Model Improves Pathological Image Synthesis",
      "title_zh": "è¯­ä¹‰å¢å¼ºçš„ç”Ÿæˆå¼åŸºåº§æ¨¡å‹æå‡ç—…ç†å›¾åƒåˆæˆ",
      "authors": [
        "Xianchao Guan",
        "Zhiyuan Fan",
        "Yifeng Wang",
        "Fuqiang Chen",
        "Yanjiang Zhou",
        "Zengyang Che",
        "Hongxue Meng",
        "Xin Li",
        "Yaowei Wang",
        "Hongpeng Wang",
        "Min Zhang",
        "Heng Tao Shen",
        "Zheng Zhang",
        "Yongbing Zhang"
      ],
      "abstract": "The development of clinical-grade artificial intelligence in pathology is limited by the scarcity of diverse, high-quality annotated datasets. Generative models offer a potential solution but suffer from semantic instability and morphological hallucinations that compromise diagnostic reliability. To address this challenge, we introduce a Correlation-Regulated Alignment Framework for Tissue Synthesis (CRAFTS), the first generative foundation model for pathology-specific text-to-image synthesis. By leveraging a dual-stage training strategy on approximately 2.8 million image-caption pairs, CRAFTS incorporates a novel alignment mechanism that suppresses semantic drift to ensure biological accuracy. This model generates diverse pathological images spanning 30 cancer types, with quality rigorously validated by objective metrics and pathologist evaluations. Furthermore, CRAFTS-augmented datasets enhance the performance across various clinical tasks, including classification, cross-modal retrieval, self-supervised learning, and visual question answering. In addition, coupling CRAFTS with ControlNet enables precise control over tissue architecture from inputs such as nuclear segmentation masks and fluorescence images. By overcoming the critical barriers of data scarcity and privacy concerns, CRAFTS provides a limitless source of diverse, annotated histology data, effectively unlocking the creation of robust diagnostic tools for rare and complex cancer phenotypes.",
      "tldr_zh": "ç—…ç†å­¦ä¸´åºŠçº§äººå·¥æ™ºèƒ½çš„å‘å±•é•¿æœŸå—é™äºé«˜è´¨é‡æ ‡æ³¨æ•°æ®çš„ç¨€ç¼ºï¼Œä¸”ç°æœ‰ç”Ÿæˆæ¨¡å‹å¸¸é¢ä¸´è¯­ä¹‰ä¸ç¨³å®šå’Œå½¢æ€å¹»è§‰ç­‰æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶å¼•å…¥äº†é¦–ä¸ªç—…ç†å­¦ä¸“ç”¨æ–‡æœ¬ç”Ÿæˆå›¾åƒï¼ˆtext-to-image synthesisï¼‰çš„åŸºç¡€ç”Ÿæˆæ¨¡å‹CRAFTSï¼ˆCorrelation-Regulated Alignment Framework for Tissue Synthesisï¼‰ã€‚è¯¥æ¨¡å‹é€šè¿‡åœ¨çº¦280ä¸‡ä¸ªå›¾åƒ-è¯´æ˜å¯¹ï¼ˆimage-caption pairsï¼‰ä¸Šè¿›è¡ŒåŒé˜¶æ®µè®­ç»ƒï¼Œå¹¶åˆ©ç”¨æ–°å‹å¯¹é½æœºåˆ¶æœ‰æ•ˆæŠ‘åˆ¶äº†è¯­ä¹‰æ¼‚ç§»ï¼ˆsemantic driftï¼‰ï¼Œç¡®ä¿äº†ç”Ÿæˆçš„ç”Ÿç‰©å­¦å‡†ç¡®æ€§ã€‚CRAFTSèƒ½å¤Ÿåˆæˆæ¶µç›–30ç§ç™Œç—‡ç±»å‹çš„å¤šæ ·åŒ–å›¾åƒï¼Œå…¶å®éªŒç»“æœè¯æ˜è¯¥æ¨¡å‹æ˜¾è‘—æå‡äº†åˆ†ç±»ã€è·¨æ¨¡æ€æ£€ç´¢ï¼ˆcross-modal retrievalï¼‰ã€è‡ªç›‘ç£å­¦ä¹ ä»¥åŠè§†è§‰é—®ç­”ï¼ˆvisual question answeringï¼‰ç­‰ä»»åŠ¡çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç»“åˆControlNetæŠ€æœ¯ï¼Œè¯¥æ¨¡å‹è¿˜å¯ä»¥é€šè¿‡ç»†èƒæ ¸åˆ†å‰²æ©è†œï¼ˆnuclear segmentation masksï¼‰å’Œè§å…‰å›¾åƒå®ç°å¯¹ç»„ç»‡æ¶æ„çš„ç²¾ç¡®æ§åˆ¶ã€‚è¯¥æ¡†æ¶æœ‰æ•ˆè§£å†³äº†ç—…ç†é¢†åŸŸçš„æ ‡æ³¨æ•°æ®åŒ®ä¹å’Œéšç§é¡¾è™‘ï¼Œä¸ºå¼€å‘é’ˆå¯¹ç½•è§åŠå¤æ‚ç™Œç—‡è¡¨å‹çš„é²æ£’è¯Šæ–­å·¥å…·æä¾›äº†é«˜è´¨é‡æ ‡æ³¨ç»„ç»‡å­¦æ•°æ®ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "68 pages, 9 figures, 16 tables",
      "pdf_url": "https://arxiv.org/pdf/2512.13164v2",
      "published_date": "2025-12-15 10:22:43 UTC",
      "updated_date": "2025-12-16 03:25:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:59:28.350795+00:00"
    },
    {
      "arxiv_id": "2512.13159v1",
      "title": "SpeakRL: Synergizing Reasoning, Speaking, and Acting in Language Models with Reinforcement Learning",
      "title_zh": "SpeakRLï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ ååŒè¯­è¨€æ¨¡å‹ä¸­çš„æ¨ç†ã€è¡¨è¾¾ä¸è¡ŒåŠ¨",
      "authors": [
        "Emre Can Acikgoz",
        "Jinoh Oh",
        "Jie Hao",
        "Joo Hyuk Jeon",
        "Heng Ji",
        "Dilek Hakkani-TÃ¼r",
        "Gokhan Tur",
        "Xiang Li",
        "Chengyuan Ma",
        "Xing Fan"
      ],
      "abstract": "Effective human-agent collaboration is increasingly prevalent in real-world applications. Current trends in such collaborations are predominantly unidirectional, with users providing instructions or posing questions to agents, where agents respond directly without seeking necessary clarifications or confirmations. However, the evolving capabilities of these agents require more proactive engagement, where agents should dynamically participate in conversations to clarify user intents, resolve ambiguities, and adapt to changing circumstances. Existing prior work under-utilize the conversational capabilities of language models (LMs), thereby optimizing agents as better followers rather than effective speakers. In this work, we introduce SpeakRL, a reinforcement learning (RL) method that enhances agents' conversational capabilities by rewarding proactive interactions with users, such as asking right clarification questions when necessary. To support this, we curate SpeakER, a synthetic dataset that includes diverse scenarios from task-oriented dialogues, where tasks are resolved through interactive clarification questions. We present a systematic analysis of reward design for conversational proactivity and propose a principled reward formulation for teaching agents to balance asking with acting. Empirical evaluations demonstrate that our approach achieves a 20.14% absolute improvement in task completion over base models without increasing conversation turns even surpassing even much larger proprietary models, demonstrating the promise of clarification-centric user-agent interactions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“åœ¨äººæœºåä½œä¸­å¤šä¸ºè¢«åŠ¨è·Ÿéšã€ç¼ºä¹ä¸»åŠ¨æ¾„æ¸…å’ŒåŠ¨æ€è°ƒæ•´èƒ½åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº† SpeakRL å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æ–¹æ³•ã€‚è¯¥æ–¹æ³•æ—¨åœ¨é€šè¿‡å¥–åŠ±æœºåˆ¶æå‡æ™ºèƒ½ä½“çš„ä¸»åŠ¨å¯¹è¯èƒ½åŠ›ï¼Œä½¿å…¶èƒ½åœ¨å¿…è¦æ—¶é€šè¿‡å…³é”®æ€§çš„æé—®æ¥æ¶ˆé™¤ç”¨æˆ·æ„å›¾çš„æ­§ä¹‰ã€‚ä¸ºæ”¯æŒè¯¥ç ”ç©¶ï¼Œä½œè€…æ„å»ºäº† SpeakER åˆæˆæ•°æ®é›†ï¼Œæ¶µç›–äº†å¤šç§éœ€é€šè¿‡äº¤äº’å¼æ¾„æ¸…æ¥è§£å†³çš„ä»»åŠ¡å¯¼å‘å¯¹è¯åœºæ™¯ã€‚è®ºæ–‡é€šè¿‡è®¾è®¡ä¸€ç§åŸåˆ™æ€§çš„å¥–åŠ±å…¬å¼ï¼Œæ•™ä¼šæ™ºèƒ½ä½“åœ¨æ‰§è¡Œä»»åŠ¡(Acting)ä¸å‘èµ·æé—®(Asking)ä¹‹é—´å»ºç«‹å¹³è¡¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSpeakRL åœ¨ä»»åŠ¡å®Œæˆç‡ä¸Šæ¯”åŸºå‡†æ¨¡å‹å®ç°äº† 20.14% çš„ç»å¯¹æå‡ï¼Œä¸”æœªå¢åŠ å¯¹è¯è½®æ•°ï¼Œå…¶è¡¨ç°ç”šè‡³è¶…è¶Šäº†æ›´å¤§è§„æ¨¡çš„ç§æœ‰æ¨¡å‹ï¼Œå……åˆ†è¯æ˜äº†ä»¥æ¾„æ¸…ä¸ºæ ¸å¿ƒçš„äº¤äº’æœºåˆ¶åœ¨å¢å¼ºæ™ºèƒ½ä½“æ•ˆèƒ½æ–¹é¢çš„æ˜¾è‘—ä½œç”¨ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13159v1",
      "published_date": "2025-12-15 10:08:53 UTC",
      "updated_date": "2025-12-15 10:08:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T16:59:33.529258+00:00"
    },
    {
      "arxiv_id": "2512.13157v1",
      "title": "Intrinsic Image Fusion for Multi-View 3D Material Reconstruction",
      "title_zh": "é¢å‘å¤šè§†å›¾ä¸‰ç»´æè´¨é‡å»ºçš„å†…ç¦€å›¾åƒèåˆ",
      "authors": [
        "Peter Kocsis",
        "Lukas HÃ¶llein",
        "Matthias NieÃŸner"
      ],
      "abstract": "We introduce Intrinsic Image Fusion, a method that reconstructs high-quality physically based materials from multi-view images. Material reconstruction is highly underconstrained and typically relies on analysis-by-synthesis, which requires expensive and noisy path tracing. To better constrain the optimization, we incorporate single-view priors into the reconstruction process. We leverage a diffusion-based material estimator that produces multiple, but often inconsistent, candidate decompositions per view. To reduce the inconsistency, we fit an explicit low-dimensional parametric function to the predictions. We then propose a robust optimization framework using soft per-view prediction selection together with confidence-based soft multi-view inlier set to fuse the most consistent predictions of the most confident views into a consistent parametric material space. Finally, we use inverse path tracing to optimize for the low-dimensional parameters. Our results outperform state-of-the-art methods in material disentanglement on both synthetic and real scenes, producing sharp and clean reconstructions suitable for high-quality relighting.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Intrinsic Image Fusionï¼Œä¸€ç§æ—¨åœ¨ä»å¤šè§†è§’å›¾åƒä¸­é‡å»ºé«˜è´¨é‡åŸºäºç‰©ç†ææ–™(physically based materials)çš„æ–¹æ³•ã€‚é’ˆå¯¹ææ–™é‡å»ºè¿‡ç¨‹ä¸­åˆ†æåˆæˆ(analysis-by-synthesis)é¢ä¸´çš„é«˜åº¦æ¬ å®šä»¥åŠè·¯å¾„è¿½è¸ª(path tracing)å¸¦æ¥çš„é«˜æˆæœ¬å’Œå™ªå£°é—®é¢˜ï¼Œè¯¥æ–¹æ³•å°†å•è§†è§’å…ˆéªŒå¼•å…¥é‡å»ºè¿‡ç¨‹ã€‚ç ”ç©¶åˆ©ç”¨åŸºäºæ‰©æ•£æ¨¡å‹(diffusion-based)çš„ææ–™ä¼°è®¡å™¨ç”Ÿæˆå€™é€‰åˆ†è§£ï¼Œå¹¶é€šè¿‡æ‹Ÿåˆæ˜¾å¼ä½ç»´å‚æ•°å‡½æ•°æ¥é™ä½é¢„æµ‹çš„ä¸ä¸€è‡´æ€§ã€‚éšåï¼Œè¯¥æ–¹æ³•é‡‡ç”¨ä¸€ç§ç»“åˆè½¯è§†è§’é¢„æµ‹é€‰æ‹©(soft per-view prediction selection)ä¸åŸºäºç½®ä¿¡åº¦çš„å¤šè§†è§’å†…ç‚¹é›†(confidence-based soft multi-view inlier set)çš„é²æ£’ä¼˜åŒ–æ¡†æ¶ï¼Œå°†æœ€ä¸€è‡´ä¸”æœ€å¯é çš„é¢„æµ‹èåˆè¿›ç»Ÿä¸€çš„å‚æ•°åŒ–ææ–™ç©ºé—´ã€‚æœ€åï¼Œé€šè¿‡é€†è·¯å¾„è¿½è¸ª(inverse path tracing)è¿›ä¸€æ­¥ä¼˜åŒ–ä½ç»´å‚æ•°ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒIntrinsic Image Fusionåœ¨åˆæˆå’ŒçœŸå®åœºæ™¯çš„ææ–™è§£è€¦(material disentanglement)è¡¨ç°ä¸Šå‡ä¼˜äºç°æœ‰é¡¶å°–æ–¹æ³•ï¼Œèƒ½å¤Ÿäº§ç”Ÿé€‚ç”¨äºé«˜è´¨é‡é‡å…‰ç…§(relighting)çš„æ¸…æ™°é‡å»ºæ•ˆæœã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://peter-kocsis.github.io/IntrinsicImageFusion/ Video: https://www.youtube.com/watch?v=-Vs3tR1Xl7k",
      "pdf_url": "https://arxiv.org/pdf/2512.13157v1",
      "published_date": "2025-12-15 10:05:59 UTC",
      "updated_date": "2025-12-15 10:05:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:00:04.771435+00:00"
    },
    {
      "arxiv_id": "2512.13154v1",
      "title": "MAC: A Multi-Agent Framework for Interactive User Clarification in Multi-turn Conversations",
      "title_zh": "MACï¼šé¢å‘å¤šè½®å¯¹è¯äº¤äº’å¼ç”¨æˆ·æ¾„æ¸…çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Emre Can Acikgoz",
        "Jinoh Oh",
        "Joo Hyuk Jeon",
        "Jie Hao",
        "Heng Ji",
        "Dilek Hakkani-TÃ¼r",
        "Gokhan Tur",
        "Xiang Li",
        "Chengyuan Ma",
        "Xing Fan"
      ],
      "abstract": "Conversational agents often encounter ambiguous user requests, requiring an effective clarification to successfully complete tasks. While recent advancements in real-world applications favor multi-agent architectures to manage complex conversational scenarios efficiently, ambiguity resolution remains a critical and underexplored challenge--particularly due to the difficulty of determining which agent should initiate a clarification and how agents should coordinate their actions when faced with uncertain or incomplete user input. The fundamental questions of when to interrupt a user and how to formulate the optimal clarification query within the most optimal multi-agent settings remain open. In this paper, we propose MAC (Multi-Agent Clarification), an interactive multi-agent framework specifically optimized to resolve user ambiguities by strategically managing clarification dialogues. We first introduce a novel taxonomy categorizing user ambiguities to systematically guide clarification strategies. Then, we present MAC that autonomously coordinates multiple agents to interact synergistically with users. Empirical evaluations on MultiWOZ 2.4 demonstrate that enabling clarification at both levels increases task success rate 7.8\\% (54.5 to 62.3) and reduces the average number of dialogue turns (6.53 to 4.86) by eliciting all required user information up front and minimizing repetition. Our findings highlight the importance of active user interaction and role-aware clarification for more reliable human-agent communication.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MAC (Multi-Agent Clarification)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¯¹è¯æ™ºèƒ½ä½“åœ¨å¤„ç†æ¨¡ç³Šç”¨æˆ·è¯·æ±‚æ—¶é¢ä¸´çš„æ¾„æ¸…ç­–ç•¥åè°ƒéš¾é¢˜ã€‚è¯¥æ¡†æ¶é¦–å…ˆå¼•å…¥äº†ä¸€ç§å…¨æ–°çš„ç”¨æˆ·æ¨¡ç³Šæ€§åˆ†ç±»æ³•(taxonomy)ï¼Œç”¨äºç³»ç»Ÿæ€§åœ°æŒ‡å¯¼æ¾„æ¸…ç­–ç•¥çš„åˆ¶å®šã€‚éšåï¼ŒMACé€šè¿‡è‡ªä¸»åè°ƒå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œå®ç°äº†ä¸ç”¨æˆ·ä¹‹é—´çš„é«˜æ•ˆååŒäº¤äº’ï¼Œä¼˜åŒ–äº†æ¾„æ¸…å¯¹è¯çš„ç®¡ç†ã€‚åœ¨MultiWOZ 2.4æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶å°†ä»»åŠ¡æˆåŠŸç‡æå‡äº†7.8%ï¼ˆä»54.5%å‡è‡³62.3%ï¼‰ï¼Œå¹¶å°†å¹³å‡å¯¹è¯è½®æ•°ä»6.53æ˜¾è‘—å‡å°‘è‡³4.86ã€‚è¿™ç§æ•ˆèƒ½æå‡ä¸»è¦å½’åŠŸäºæ¡†æ¶èƒ½å¤Ÿåœ¨å¯¹è¯å‰æœŸè¯±å¯¼å‡ºæ‰€æœ‰å¿…è¦çš„ç”¨æˆ·ä¿¡æ¯ï¼Œä»è€Œæœ€å¤§é™åº¦åœ°å‡å°‘äº†æ— æ•ˆé‡å¤ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†ä¸»åŠ¨ç”¨æˆ·äº¤äº’å’Œè§’è‰²æ„ŸçŸ¥æ¾„æ¸…(role-aware clarification)åœ¨æ„å»ºæ›´å¯é çš„äººæœºé€šè®¯ä¸­çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13154v1",
      "published_date": "2025-12-15 10:02:50 UTC",
      "updated_date": "2025-12-15 10:02:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:00:15.601496+00:00"
    },
    {
      "arxiv_id": "2512.13142v4",
      "title": "Can LLMs Understand What We Cannot Say? Measuring Multilevel Alignment Through Abortion Stigma Across Cognitive, Interpersonal, and Structural Levels",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹èƒ½å¦ç†è§£æˆ‘ä»¬æ— æ³•è¨€è¯´ä¹‹äº‹ï¼Ÿé€šè¿‡è®¤çŸ¥ã€äººé™…å’Œç»“æ„å±‚é¢çš„å •èƒæ±¡åè¡¡é‡å¤šå±‚æ¬¡å¯¹é½",
      "authors": [
        "Anika Sharma",
        "Malavika Mampally",
        "Chidaksh Ravuru",
        "Kandyce Brennan",
        "Neil Gaikwad"
      ],
      "abstract": "As Large Language Models (LLMs) increasingly mediate stigmatized health decisions, their capacity to understand complex psychological phenomena remains inadequately assessed. Can LLMs understand what we cannot say? We investigate whether LLMs coherently represent abortion stigma across cognitive, interpersonal, and structural levels. We systematically tested 627 demographically diverse personas across five leading LLMs using the validated Individual Level Abortion Stigma Scale (ILAS), examining representation at cognitive (self-judgment), interpersonal (worries about judgment and isolation), and structural (community condemnation and disclosure patterns) levels. Models fail tests of genuine understanding across all dimensions. They underestimate cognitive stigma while overestimating interpersonal stigma, introduce demographic biases assigning higher stigma to younger, less educated, and non-White personas, and treat secrecy as universal despite 36% of humans reporting openness. Most critically, models produce internal contradictions: they overestimate isolation yet predict isolated individuals are less secretive, revealing incoherent representations. These patterns show current alignment approaches ensure appropriate language but not coherent understanding across levels. This work provides empirical evidence that LLMs lack coherent understanding of psychological constructs operating across multiple dimensions. AI safety in high-stakes contexts demands new approaches to design (multilevel coherence), evaluation (continuous auditing), governance and regulation (mandatory audits, accountability, deployment restrictions), and AI literacy in domains where understanding what people cannot say determines whether support helps or harms.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)æ˜¯å¦èƒ½ç†è§£è¯¸å¦‚å •èƒæ±¡å(abortion stigma)ç­‰å¤æ‚çš„å¿ƒç†ç°è±¡ï¼Œé€šè¿‡åœ¨äº”ä¸ªé¢†å…ˆæ¨¡å‹ä¸Šå¯¹627ä¸ªä¸åŒèƒŒæ™¯çš„è§’è‰²è¿›è¡Œç³»ç»Ÿæµ‹è¯•ï¼Œè¯„ä¼°äº†å…¶åœ¨è®¤çŸ¥ã€äººé™…å’Œç»“æ„å±‚é¢çš„è¡¨ç°ã€‚ç ”ç©¶ä½¿ç”¨äº†éªŒè¯è¿‡çš„ä¸ªäººå±‚é¢å •èƒæ±¡åé‡è¡¨(ILAS)ï¼Œå‘ç°æ¨¡å‹åœ¨æ‰€æœ‰ç»´åº¦ä¸Šå‡æœªèƒ½è¡¨ç°å‡ºçœŸæ­£çš„ç†è§£ï¼Œå…·ä½“è¡¨ç°ä¸ºä½ä¼°è®¤çŸ¥æ±¡åè€Œé«˜ä¼°äººé™…æ±¡åï¼Œå¹¶å­˜åœ¨äººå£ç»Ÿè®¡å­¦åè§ã€‚æ¨¡å‹åœ¨é¢„æµ‹å­¤ç«‹æ„Ÿä¸ä¿å¯†è¡Œä¸ºæ—¶äº§ç”Ÿäº†å†…éƒ¨çŸ›ç›¾ï¼Œæ­ç¤ºäº†å…¶å¯¹å¿ƒç†æ„å»ºçš„è¡¨ç¤ºç¼ºä¹è¿è´¯æ€§ã€‚ç»“æœè¡¨æ˜ï¼Œå½“å‰çš„å¯¹é½(alignment)æ–¹æ³•ä»…èƒ½ç¡®ä¿è¯­è¨€è¡¨è¾¾çš„é€‚å½“æ€§ï¼Œè€Œéè·¨å±‚é¢çš„æ·±åˆ»ç†è§£ã€‚è¯¥å·¥ä½œä¸ºLLMsåœ¨æ¶‰åŠé«˜é£é™©åŒ»ç–—å†³ç­–æ—¶ç¼ºä¹å¿ƒç†è¿è´¯æ€§æä¾›äº†å®è¯è¯æ®ï¼Œå¹¶å¼ºè°ƒåœ¨AIå®‰å…¨è®¾è®¡ã€è¯„ä¼°ä¸ç›‘ç®¡ä¸­éœ€å¼•å…¥å¤šå±‚è¿è´¯æ€§(multilevel coherence)å’ŒæŒç»­å®¡è®¡æœºåˆ¶ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13142v4",
      "published_date": "2025-12-15 09:50:00 UTC",
      "updated_date": "2026-01-15 17:43:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:00:01.671063+00:00"
    },
    {
      "arxiv_id": "2512.13131v1",
      "title": "Towards Unified Co-Speech Gesture Generation via Hierarchical Implicit Periodicity Learning",
      "title_zh": "åŸºäºå±‚çº§åŒ–éšå¼å‘¨æœŸæ€§å­¦ä¹ çš„ç»Ÿä¸€ååŒè¯­éŸ³æ‰‹åŠ¿ç”Ÿæˆ",
      "authors": [
        "Xin Guo",
        "Yifan Zhao",
        "Jia Li"
      ],
      "abstract": "Generating 3D-based body movements from speech shows great potential in extensive downstream applications, while it still suffers challenges in imitating realistic human movements. Predominant research efforts focus on end-to-end generation schemes to generate co-speech gestures, spanning GANs, VQ-VAE, and recent diffusion models. As an ill-posed problem, in this paper, we argue that these prevailing learning schemes fail to model crucial inter- and intra-correlations across different motion units, i.e. head, body, and hands, thus leading to unnatural movements and poor coordination. To delve into these intrinsic correlations, we propose a unified Hierarchical Implicit Periodicity (HIP) learning approach for audio-inspired 3D gesture generation. Different from predominant research, our approach models this multi-modal implicit relationship by two explicit technique insights: i) To disentangle the complicated gesture movements, we first explore the gesture motion phase manifolds with periodic autoencoders to imitate human natures from realistic distributions while incorporating non-period ones from current latent states for instance-level diversities. ii) To model the hierarchical relationship of face motions, body gestures, and hand movements, driving the animation with cascaded guidance during learning. We exhibit our proposed approach on 3D avatars and extensive experiments show our method outperforms the state-of-the-art co-speech gesture generation methods by both quantitative and qualitative evaluations. Code and models will be publicly available.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯­éŸ³é©±åŠ¨çš„ co-speech gesture generation ä¸­ç°æœ‰æ–¹æ³•éš¾ä»¥æ•æ‰å¤´ã€èº«ä½“å’Œæ‰‹éƒ¨ç­‰ä¸åŒè¿åŠ¨å•å…ƒé—´çš„å†…åœ¨å…³è”ï¼Œå¯¼è‡´ç”ŸæˆåŠ¨ä½œä¸è‡ªç„¶ä¸”åè°ƒæ€§å·®çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„ Hierarchical Implicit Periodicity (HIP) å­¦ä¹ æ–¹æ³•ã€‚è¯¥æ–¹æ³•é¦–å…ˆåˆ©ç”¨ periodic autoencoders æ¢ç´¢æ‰‹åŠ¿è¿åŠ¨çš„ç›¸ä½æµå½¢ï¼Œä»¥ä»çœŸå®åˆ†å¸ƒä¸­æ¨¡æ‹Ÿäººç±»æœ¬èƒ½ï¼Œå¹¶ç»“åˆå½“å‰æ½œåœ¨çŠ¶æ€ä¸­çš„éå‘¨æœŸæ€§ç‰¹å¾æ¥æå‡å®ä¾‹å±‚é¢çš„å¤šæ ·æ€§ã€‚ä¸ºäº†è¿›ä¸€æ­¥å»ºæ¨¡é¢éƒ¨ã€èº«ä½“å’Œæ‰‹éƒ¨åŠ¨ä½œä¹‹é—´çš„å±‚æ¬¡å…³ç³»ï¼Œç ”ç©¶åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å¼•å…¥äº† cascaded guidance æ¥é©±åŠ¨åŠ¨ç”»ç”Ÿæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®šé‡å’Œå®šæ€§è¯„ä¼°ä¸­å‡ä¼˜äºç°æœ‰çš„ state-of-the-art ååŒè¯­éŸ³æ‰‹åŠ¿ç”Ÿæˆæ¨¡å‹ï¼Œèƒ½å¤Ÿç”Ÿæˆæ›´å…·çœŸå®æ„Ÿå’Œåè°ƒæ€§çš„ 3D è¿åŠ¨ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.GR",
        "cs.MM",
        "cs.SD"
      ],
      "primary_category": "cs.AI",
      "comment": "IEEE Transactions on Image Processing",
      "pdf_url": "https://arxiv.org/pdf/2512.13131v1",
      "published_date": "2025-12-15 09:43:08 UTC",
      "updated_date": "2025-12-15 09:43:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:00:24.929548+00:00"
    },
    {
      "arxiv_id": "2512.22149v2",
      "title": "Adaptive GPU Resource Allocation for Multi-Agent Collaborative Reasoning in Serverless Environments",
      "title_zh": "Serverless ç¯å¢ƒä¸‹å¤šæ™ºèƒ½ä½“åä½œæ¨ç†çš„è‡ªé€‚åº” GPU èµ„æºåˆ†é…",
      "authors": [
        "Guilin Zhang",
        "Wulan Guo",
        "Ziqi Tan"
      ],
      "abstract": "Multi-agent systems powered by large language models have emerged as a promising paradigm for solving complex reasoning tasks through collaborative intelligence. However, efficiently deploying these systems on serverless GPU platforms presents significant resource allocation challenges due to heterogeneous agent workloads, varying computational demands, and the need for cost-effective scaling. This paper presents an adaptive GPU resource allocation framework that achieves 85% latency reduction compared to round-robin scheduling while maintaining comparable throughput to static allocation, using an O(N) complexity algorithm for real-time adaptation. Our approach dynamically allocates GPU resources based on workload characteristics, agent priorities, and minimum resource requirements, enabling efficient utilization while maintaining quality of service. The framework addresses three key challenges: (1) heterogeneous computational demands across lightweight coordinators and heavyweight specialists, (2) dynamic workload fluctuations requiring millisecond-scale reallocation, and (3) capacity constraints in serverless environments. Through comprehensive simulations modeling realistic multi-agent workflows with four heterogeneous agents, we demonstrate that adaptive allocation outperforms static equal and round-robin strategies across latency, cost, and GPU utilization metrics. The framework provides a practical solution for deploying cost-efficient multi-agent AI systems on serverless GPU infrastructure.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹æ— æœåŠ¡å™¨(Serverless)ç¯å¢ƒä¸‹çš„å¤šæ™ºèƒ½ä½“åä½œæ¨ç†çš„è‡ªé€‚åº”GPUèµ„æºåˆ†é…æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ—¨åœ¨è§£å†³åœ¨Serverless GPUå¹³å°ä¸Šéƒ¨ç½²ç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ—¶ï¼Œé¢ä¸´çš„å¼‚æ„å·¥ä½œè´Ÿè½½ã€å¤šå˜çš„è®¡ç®—éœ€æ±‚ä»¥åŠæˆæœ¬æ•ˆç›Šæ‰©å±•ç­‰èµ„æºåˆ†é…æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•é‡‡ç”¨å¤æ‚åº¦ä¸ºO(N)çš„ç®—æ³•å®ç°å®æ—¶è‡ªé€‚åº”ï¼Œèƒ½å¤Ÿæ ¹æ®å·¥ä½œè´Ÿè½½ç‰¹å¾ã€æ™ºèƒ½ä½“ä¼˜å…ˆçº§å’Œæœ€å°èµ„æºè¦æ±‚åŠ¨æ€åˆ†é…GPUèµ„æºã€‚å®ƒæœ‰æ•ˆè§£å†³äº†è½»é‡çº§åè°ƒè€…ä¸é‡é‡çº§ä¸“å®¶æ™ºèƒ½ä½“ä¹‹é—´çš„å¼‚æ„è®¡ç®—éœ€æ±‚ï¼Œå¹¶èƒ½åº”å¯¹éœ€è¦æ¯«ç§’çº§é‡æ–°åˆ†é…çš„åŠ¨æ€è´Ÿè½½æ³¢åŠ¨ã€‚å®éªŒä»¿çœŸç»“æœè¡¨æ˜ï¼Œä¸è½®è¯¢è°ƒåº¦(Round-robin)ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶å°†å»¶è¿Ÿé™ä½äº†85%ï¼ŒåŒæ—¶åœ¨GPUåˆ©ç”¨ç‡å’Œæˆæœ¬æ•ˆç›ŠæŒ‡æ ‡ä¸Šå‡ä¼˜äºé™æ€åˆ†é…ç­–ç•¥ã€‚è¯¥ç ”ç©¶ä¸ºåœ¨æ— æœåŠ¡å™¨åŸºç¡€è®¾æ–½ä¸Šéƒ¨ç½²é«˜æ€§èƒ½ä¸”ä½æˆæœ¬çš„å¤šæ™ºèƒ½ä½“AIç³»ç»Ÿæä¾›äº†é‡è¦çš„å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.DC",
      "comment": "6 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.22149v2",
      "published_date": "2025-12-15 09:21:48 UTC",
      "updated_date": "2026-01-01 03:32:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:00:19.241575+00:00"
    },
    {
      "arxiv_id": "2512.13122v1",
      "title": "DePT3R: Joint Dense Point Tracking and 3D Reconstruction of Dynamic Scenes in a Single Forward Pass",
      "title_zh": "DePT3Rï¼šå•æ¬¡å‰å‘ä¼ é€’ä¸‹çš„åŠ¨æ€åœºæ™¯è”åˆç¨ å¯†ç‚¹è·Ÿè¸ªä¸3Dé‡å»º",
      "authors": [
        "Vivek Alumootil",
        "Tuan-Anh Vu",
        "M. Khalid Jawed"
      ],
      "abstract": "Current methods for dense 3D point tracking in dynamic scenes typically rely on pairwise processing, require known camera poses, or assume a temporal ordering to input frames, constraining their flexibility and applicability. Additionally, recent advances have successfully enabled efficient 3D reconstruction from large-scale, unposed image collections, underscoring opportunities for unified approaches to dynamic scene understanding. Motivated by this, we propose DePT3R, a novel framework that simultaneously performs dense point tracking and 3D reconstruction of dynamic scenes from multiple images in a single forward pass. This multi-task learning is achieved by extracting deep spatio-temporal features with a powerful backbone and regressing pixel-wise maps with dense prediction heads. Crucially, DePT3R operates without requiring camera poses, substantially enhancing its adaptability and efficiency-especially important in dynamic environments with rapid changes. We validate DePT3R on several challenging benchmarks involving dynamic scenes, demonstrating strong performance and significant improvements in memory efficiency over existing state-of-the-art methods. Data and codes are available via the open repository: https://github.com/StructuresComp/DePT3R",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DePT3Rï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å•æ¬¡å‰å‘ä¼ æ’­ (Single Forward Pass) ä¸­åŒæ—¶å®ç°åŠ¨æ€åœºæ™¯çš„å¯†é›†ç‚¹è¿½è¸ª (Dense Point Tracking) ä¸ä¸‰ç»´é‡å»º (3D Reconstruction) çš„åˆ›æ–°æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•ä¾èµ–æˆå¯¹å¤„ç†ã€å·²çŸ¥ç›¸æœºä½å§¿ (Camera Poses) æˆ–ç‰¹å®šå¸§åºåˆ—é¡ºåºçš„å±€é™æ€§ï¼ŒDePT3R é€šè¿‡å¼ºå¤§çš„ä¸»å¹²ç½‘ç»œæå–æ·±å±‚æ—¶ç©ºç‰¹å¾ (Spatio-Temporal Features)ï¼Œå¹¶åˆ©ç”¨å¯†é›†é¢„æµ‹å¤´ (Dense Prediction Heads) ç›´æ¥å›å½’åƒç´ çº§æ˜ å°„ã€‚è¯¥æ¡†æ¶çš„å…³é”®ä¼˜åŠ¿åœ¨äºæ— éœ€ç›¸æœºä½å§¿å³å¯è¿è¡Œï¼Œæ˜¾è‘—å¢å¼ºäº†å…¶åœ¨å¿«é€Ÿå˜åŒ–çš„åŠ¨æ€ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œå¤„ç†æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDePT3R åœ¨å¤šä¸ªæŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œä¸”ä¸ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨å†…å­˜æ•ˆç‡ (Memory Efficiency) æ–¹é¢æœ‰æ˜¾è‘—æå‡ã€‚è¿™é¡¹å·¥ä½œä¸ºç»Ÿä¸€åŠ¨æ€åœºæ™¯ç†è§£ä»»åŠ¡æä¾›äº†é«˜æ•ˆçš„æ–¹æ¡ˆï¼Œå¹¶å·²å¼€æºç›¸å…³æ•°æ®å’Œä»£ç ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This is a work in progress",
      "pdf_url": "https://arxiv.org/pdf/2512.13122v1",
      "published_date": "2025-12-15 09:21:28 UTC",
      "updated_date": "2025-12-15 09:21:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:00:35.207054+00:00"
    },
    {
      "arxiv_id": "2512.13111v1",
      "title": "From Overfitting to Reliability: Introducing the Hierarchical Approximate Bayesian Neural Network",
      "title_zh": "ä»è¿‡æ‹Ÿåˆåˆ°å¯é æ€§ï¼šåˆ†å±‚è¿‘ä¼¼è´å¶æ–¯ç¥ç»ç½‘ç»œçš„å¼•å…¥",
      "authors": [
        "Hayk Amirkhanian",
        "Marco F. Huber"
      ],
      "abstract": "In recent years, neural networks have revolutionized various domains, yet challenges such as hyperparameter tuning and overfitting remain significant hurdles. Bayesian neural networks offer a framework to address these challenges by incorporating uncertainty directly into the model, yielding more reliable predictions, particularly for out-of-distribution data. This paper presents Hierarchical Approximate Bayesian Neural Network, a novel approach that uses a Gaussian-inverse-Wishart distribution as a hyperprior of the network's weights to increase both the robustness and performance of the model. We provide analytical representations for the predictive distribution and weight posterior, which amount to the calculation of the parameters of Student's t-distributions in closed form with linear complexity with respect to the number of weights. Our method demonstrates robust performance, effectively addressing issues of overfitting and providing reliable uncertainty estimates, particularly for out-of-distribution tasks. Experimental results indicate that HABNN not only matches but often outperforms state-of-the-art models, suggesting a promising direction for future applications in safety-critical environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†å±‚æ¬¡åŒ–è¿‘ä¼¼è´å¶æ–¯ç¥ç»ç½‘ç»œ (Hierarchical Approximate Bayesian Neural Network, HABNN)ï¼Œæ—¨åœ¨è§£å†³ç¥ç»ç½‘ç»œåœ¨è¶…å‚æ•°è°ƒä¼˜å’Œè¿‡æ‹Ÿåˆ (overfitting) æ–¹é¢é¢ä¸´çš„ä¸¥å³»æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•å¼•å…¥äº† Gaussian-inverse-Wishart åˆ†å¸ƒä½œä¸ºç½‘ç»œæƒé‡çš„è¶…å…ˆéªŒ (hyperprior)ï¼Œé€šè¿‡å°†ä¸ç¡®å®šæ€§ç›´æ¥çº³å…¥æ¨¡å‹æ¥æå‡é²æ£’æ€§ä¸æ€§èƒ½ã€‚ç ”ç©¶è€…æä¾›äº†é¢„æµ‹åˆ†å¸ƒå’Œæƒé‡åéªŒçš„è§£æè¡¨è¾¾ï¼Œä½¿å…¶èƒ½å¤Ÿä»¥å…³äºæƒé‡æ•°é‡çš„çº¿æ€§å¤æ‚åº¦ (linear complexity) åœ¨é—­å¼è§£ (closed form) ä¸­è®¡ç®— Student's t-distributions çš„å‚æ•°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHABNN æœ‰æ•ˆè§£å†³äº†è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œå¹¶åœ¨åˆ†å¸ƒå¤– (out-of-distribution) ä»»åŠ¡ä¸­æä¾›äº†å¯é çš„ä¸ç¡®å®šæ€§ä¼°è®¡ (uncertainty estimates)ã€‚è¯¥æ¨¡å‹åœ¨æ€§èƒ½ä¸Šè¾¾åˆ°æˆ–è¶…è¶Šäº†ç›®å‰æœ€å…ˆè¿› (state-of-the-art) çš„æ¨¡å‹ï¼Œä¸ºå®‰å…¨å…³é”®å‹ç¯å¢ƒ (safety-critical environments) ä¸­çš„åº”ç”¨æä¾›äº†æ›´å…·å¯é æ€§çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages main body, 1 Figure, 15 pages Appendix",
      "pdf_url": "https://arxiv.org/pdf/2512.13111v1",
      "published_date": "2025-12-15 09:08:42 UTC",
      "updated_date": "2025-12-15 09:08:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:00:50.010604+00:00"
    },
    {
      "arxiv_id": "2512.13109v1",
      "title": "Uncovering the Role of Initial Saliency in U-Shaped Attention Bias: Scaling Initial Token Weight for Enhanced Long-Text Processing",
      "title_zh": "æ­ç¤ºUå‹æ³¨æ„åŠ›åç½®ä¸­åˆå§‹æ˜¾è‘—æ€§çš„ä½œç”¨ï¼šé€šè¿‡ç¼©æ”¾åˆå§‹è¯å…ƒæƒé‡å¢å¼ºé•¿æ–‡æœ¬å¤„ç†èƒ½åŠ›",
      "authors": [
        "Zewen Qiang",
        "Sendong Zhao",
        "Haochun Wang",
        "Bing Qin",
        "Ting Liu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated strong performance on a variety of natural language processing (NLP) tasks. However, they often struggle with long-text sequences due to the ``lost in the middle'' phenomenon. This issue has been shown to arise from a U-shaped attention bias, where attention is disproportionately focused on the beginning and end of a text, leaving the middle section underrepresented. While previous studies have attributed this bias to position encoding, our research first identifies an additional factor: initial saliency. It means that in the attention computation for each token, tokens with higher attention weights relative to the initial token tend to receive more attention in the prediction of the next token. We further find that utilizing this property by scaling attention weight between the initial token and others improves the model's ability to process long contexts, achieving a maximum improvement of 3.6\\% in MDQA dataset. Moreover, combining this approach with existing methods to reduce position encoding bias further enhances performance, achieving a maximum improvement of 3.4\\% in KV-Retrieval tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶å› U-shaped attention biaså¯¼è‡´çš„â€œlost in the middleâ€ç°è±¡ã€‚ç ”ç©¶é¦–æ¬¡ç¡®å®šäº†é™¤ä½ç½®ç¼–ç (position encoding)ä¹‹å¤–çš„å¦ä¸€ä¸ªå…³é”®å› ç´ ï¼šåˆå§‹æ˜¾è‘—æ€§(initial saliency)ï¼Œå³ä¸åˆå§‹tokenå…·æœ‰æ›´é«˜æ³¨æ„åŠ›æƒé‡çš„tokenåœ¨åç»­é¢„æµ‹ä¸­å¾€å¾€ä¼šè·å¾—æ›´å¤šå…³æ³¨ã€‚åŸºäºæ­¤å‘ç°ï¼Œä½œè€…æå‡ºé€šè¿‡ç¼©æ”¾åˆå§‹tokenä¸å…¶ä»–tokenä¹‹é—´çš„æ³¨æ„åŠ›æƒé‡æ¥å¢å¼ºæ¨¡å‹å¤„ç†é•¿ä¸Šä¸‹æ–‡çš„èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨MDQAæ•°æ®é›†ä¸Šå®ç°äº†æœ€é«˜3.6%çš„æ€§èƒ½æå‡ã€‚æ­¤å¤–ï¼Œå°†è¯¥æ–¹æ³•ä¸ç°æœ‰çš„å‡å°‘ä½ç½®ç¼–ç åå·®çš„æ–¹æ³•ç›¸ç»“åˆï¼Œåœ¨KV-Retrievalä»»åŠ¡ä¸­è¿›ä¸€æ­¥è·å¾—äº†3.4%çš„æ€§èƒ½æ”¹è¿›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13109v1",
      "published_date": "2025-12-15 09:04:06 UTC",
      "updated_date": "2025-12-15 09:04:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:00:29.690485+00:00"
    },
    {
      "arxiv_id": "2512.13107v2",
      "title": "Diffusion-Based Restoration for Multi-Modal 3D Object Detection in Adverse Weather",
      "title_zh": "æ¶åŠ£å¤©æ°”ä¸‹åŸºäºæ‰©æ•£ä¿®å¤çš„å¤šæ¨¡æ€ 3D ç›®æ ‡æ£€æµ‹",
      "authors": [
        "Zhijian He",
        "Feifei Liu",
        "Yuwei Li",
        "Zhanpeng Luo",
        "Jintao Cheng",
        "Xieyuanli Chen",
        "Xiaoyu Tang"
      ],
      "abstract": "Multi-modal 3D object detection is important for reliable perception in robotics and autonomous driving. However, its effectiveness remains limited under adverse weather conditions due to weather-induced distortions and misalignment between different data modalities. In this work, we propose DiffFusion, a novel framework designed to enhance robustness in challenging weather through diffusion-based restoration and adaptive cross-modal fusion. Our key insight is that diffusion models possess strong capabilities for denoising and generating data that can adapt to various weather conditions. Building on this, DiffFusion introduces Diffusion-IR restoring images degraded by weather effects and Point Cloud Restoration (PCR) compensating for corrupted LiDAR data using image object cues. To tackle misalignments between two modalities, we develop Bidirectional Adaptive Fusion and Alignment Module (BAFAM). It enables dynamic multi-modal fusion and bidirectional bird's-eye view (BEV) alignment to maintain consistent spatial correspondence. Extensive experiments on three public datasets show that DiffFusion achieves state-of-the-art robustness under adverse weather while preserving strong clean-data performance. Zero-shot results on the real-world DENSE dataset further validate its generalization. The implementation of our DiffFusion will be released as open-source.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DiffFusionï¼Œä¸€ç§æ—¨åœ¨æå‡å¤šæ¨¡æ€3Dç›®æ ‡æ£€æµ‹ï¼ˆMulti-modal 3D object detectionï¼‰åœ¨æ¶åŠ£å¤©æ°”ä¸‹é²æ£’æ€§çš„æ–°é¢–æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion modelsï¼‰å¼ºå¤§çš„å»å™ªä¸ç”Ÿæˆèƒ½åŠ›ï¼Œå¼•å…¥äº†ç”¨äºä¿®å¤é€€åŒ–å›¾åƒçš„Diffusion-IRæ¨¡å—ï¼Œä»¥åŠåˆ©ç”¨å›¾åƒçº¿ç´¢è¡¥å¿å—æŸé›·è¾¾æ•°æ®çš„ç‚¹äº‘ä¿®å¤ï¼ˆPoint Cloud Restoration, PCRï¼‰æ¨¡å—ã€‚ä¸ºäº†è§£å†³ä¸åŒæ¨¡æ€é—´çš„ç©ºé—´å¤±é…ï¼Œç ”ç©¶è¿›ä¸€æ­¥å¼€å‘äº†åŒå‘è‡ªé€‚åº”èåˆä¸å¯¹é½æ¨¡å—ï¼ˆBidirectional Adaptive Fusion and Alignment Module, BAFAMï¼‰ï¼Œé€šè¿‡åŒå‘é¸Ÿç°å›¾ï¼ˆBEVï¼‰å¯¹é½å®ç°åŠ¨æ€å¤šæ¨¡æ€èåˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDiffFusionåœ¨ä¸‰ä¸ªå…¬å…±æ•°æ®é›†ä¸Šå‡è¾¾åˆ°äº†æœ€å…ˆè¿›çš„é²æ£’æ€§æ°´å¹³ï¼ŒåŒæ—¶åœ¨æ¸…æ™°æ•°æ®ä¸Šä¿æŒäº†ä¼˜å¼‚è¡¨ç°ã€‚æ­¤å¤–ï¼Œåœ¨çœŸå®ä¸–ç•ŒDENSEæ•°æ®é›†ä¸Šçš„é›¶æ ·æœ¬ï¼ˆZero-shotï¼‰æµ‹è¯•éªŒè¯äº†è¯¥æ¨¡å‹å‡ºè‰²çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºè‡ªåŠ¨é©¾é©¶åœ¨æŒ‘æˆ˜æ€§ç¯å¢ƒä¸‹çš„å¯é æ„ŸçŸ¥æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13107v2",
      "published_date": "2025-12-15 09:03:46 UTC",
      "updated_date": "2025-12-18 16:00:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:00:50.368644+00:00"
    },
    {
      "arxiv_id": "2512.13106v1",
      "title": "TraPO: A Semi-Supervised Reinforcement Learning Framework for Boosting LLM Reasoning",
      "title_zh": "TraPOï¼šä¸€ç§æ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›çš„åŠç›‘ç£å¼ºåŒ–å­¦ä¹ æ¡†æ¶",
      "authors": [
        "Shenzhi Yang",
        "Guangcheng Zhu",
        "Xing Zheng",
        "Yingfan MA",
        "Zhongqi Chen",
        "Bowen Song",
        "Weiqiang Wang",
        "Junbo Zhao",
        "Gang Chen",
        "Haobo Wang"
      ],
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has proven effective in training large reasoning models (LRMs) by leveraging answer-verifiable signals to guide policy optimization, which, however, suffers from high annotation costs. To alleviate this problem, recent work has explored unsupervised RLVR methods that derive rewards solely from the model's internal consistency, such as through entropy and majority voting. While seemingly promising, these methods often suffer from model collapse in the later stages of training, which may arise from the reinforcement of incorrect reasoning patterns in the absence of external supervision. In this work, we investigate a novel semi-supervised RLVR paradigm that utilizes a small labeled set to guide RLVR training on unlabeled samples. Our key insight is that supervised rewards are essential for stabilizing consistency-based training on unlabeled samples, ensuring that only reasoning patterns verified on labeled instances are incorporated into RL training. Technically, we propose an effective policy optimization algorithm, TraPO, that identifies reliable unlabeled samples by matching their learning trajectory similarity to labeled ones. Building on this, TraPO achieves remarkable data efficiency and strong generalization on six widely used mathematical reasoning benchmarks (AIME24/25, AMC, MATH-500, Minerva, and Olympiad) and three out-of-distribution tasks (ARC-c, GPQA-diamond, and MMLU-pro). With only 1K labeled and 3K unlabeled samples, TraPO reaches 42.6% average accuracy, surpassing the best unsupervised method trained on 45K unlabeled samples (38.3%). Notably, when using 4K labeled and 12K unlabeled samples, TraPO even outperforms the fully supervised model trained on the full 45K labeled samples on all benchmarks, while using only 10% of the labeled data. The code is available via https://github.com/ShenzhiYang2000/TRAPO.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TraPOï¼Œä¸€ç§æ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹(LLMs)æ¨ç†èƒ½åŠ›çš„åŠç›‘ç£å¼ºåŒ–å­¦ä¹ (RLVR)æ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³äº†ç°æœ‰RLVRæ–¹æ³•æ ‡æ³¨æˆæœ¬é«˜æˆ–æ— ç›‘ç£è®­ç»ƒæ˜“å¯¼è‡´æ¨¡å‹å´©æºƒçš„é—®é¢˜ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºåˆ©ç”¨å°‘é‡æœ‰æ ‡ç­¾æ•°æ®å¼•å¯¼æ— ç›‘ç£æ ·æœ¬çš„ç­–ç•¥ä¼˜åŒ–ï¼Œé€šè¿‡è½¨è¿¹ç›¸ä¼¼åº¦åŒ¹é…(Trajectory Similarity Matching)ç®—æ³•è¯†åˆ«å¯é çš„æ— æ ‡ç­¾æ ·æœ¬ï¼Œä»è€Œç¨³å®šè®­ç»ƒå¹¶çº æ­£é”™è¯¯æ¨ç†æ¨¡å¼ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTraPOåœ¨AIME24/25ã€MATH-500ä»¥åŠGPQA-diamondç­‰å¤šä¸ªæ•°å­¦ä¸æ³›åŒ–åŸºå‡†ä¸Šè¡¨ç°å“è¶Šï¼Œä»…éœ€1,000ä¸ªæœ‰æ ‡ç­¾æ ·æœ¬å³å¯è¶…è¶Šä½¿ç”¨45,000ä¸ªæ— æ ‡ç­¾æ ·æœ¬çš„æ— ç›‘ç£æ¨¡å‹ã€‚æ›´æ˜¾è‘—çš„æ˜¯ï¼Œåˆ©ç”¨ä»…10%çš„æ ‡æ³¨é‡(4,000ä¸ªæœ‰æ ‡ç­¾æ ·æœ¬)ï¼ŒTraPOçš„æ€§èƒ½ä¾¿èƒ½è¶…è¶Šå…¨é‡æ ‡æ³¨çš„ç›‘ç£è®­ç»ƒæ¨¡å‹ã€‚è¯¥ç ”ç©¶ä¸ä»…å±•ç¤ºäº†æé«˜çš„æ•°æ®æ•ˆç‡ï¼Œä¹Ÿä¸ºæ„å»ºé«˜æ€§èƒ½æ¨ç†æ¨¡å‹æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”ä½æˆæœ¬çš„åŠç›‘ç£èŒƒå¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13106v1",
      "published_date": "2025-12-15 09:03:45 UTC",
      "updated_date": "2025-12-15 09:03:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:00:36.774156+00:00"
    },
    {
      "arxiv_id": "2512.13102v4",
      "title": "Socratic Students: Teaching Language Models to Learn by Asking Questions",
      "title_zh": "è‹æ ¼æ‹‰åº•å¼å­¦ç”Ÿï¼šæ•™å¯¼è¯­è¨€æ¨¡å‹é€šè¿‡æé—®è¿›è¡Œå­¦ä¹ ",
      "authors": [
        "Rajeev Bhatt Ambati",
        "Tianyi Niu",
        "Aashu Singh",
        "Shlok Mishra",
        "Snigdha Chaturvedi",
        "Shashank Srivastava"
      ],
      "abstract": "Large language Models (LLMs) are usually used to answer questions, but many high-stakes applications (e.g., tutoring, clinical support) require the complementary skill of asking questions: detecting missing information, requesting clarifications, and using them to solve tasks. We study this skill in reasoning-heavy domains where progress depends on inquiry rather than factual recall. We define an interactive protocol where a student model engages a stronger teacher under a small turn budget. After each teacher reply, we evaluate the student on the original task with Pass@k. We propose Outcome-Driven Question optimization Strategy (ODQS ), a training framework that learns a questioning policy from downstream task outcomes. At each turn, we sample multiple candidate questions; query the teacher with each, then score the student's resulting performance. Using these scores, we train the student via supervised fine-tuning followed by Direct Preference Optimization (DPO), without any human labels. On GSM8K, HumanEval, and OpenCoder, ODQS produces large gains over interactive baselines, boosting Pass@5 by up to 54.7% (absolute) on math and 22.9% (absolute) on coding, and matching baseline performance in three fewer turns. Thus, question asking can be explicitly trained from task outcomes, improving both accuracy and efficiency in interactive reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­é€šè¿‡ä¸»åŠ¨æé—®æ¥è·å–ç¼ºå¤±ä¿¡æ¯å¹¶è§£å†³é—®é¢˜çš„èƒ½åŠ›ã€‚ä½œè€…æå‡ºäº† Outcome-Driven Question optimization Strategy (ODQS)ï¼Œè¿™æ˜¯ä¸€ç§ä»ä¸‹æ¸¸ä»»åŠ¡ç»“æœä¸­å­¦ä¹ æé—®ç­–ç•¥çš„è®­ç»ƒæ¡†æ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨äº¤äº’è¿‡ç¨‹ä¸­é‡‡æ ·å€™é€‰é—®é¢˜ï¼Œå¹¶æ ¹æ®å­¦ç”Ÿæ¨¡å‹åœ¨æ•™å¸ˆå›ç­”åçš„æ€§èƒ½è¡¨ç°(Pass@k)è¿›è¡Œè¯„åˆ†ï¼Œéšååˆ©ç”¨ Supervised Fine-Tuning (SFT) å’Œ Direct Preference Optimization (DPO) åœ¨æ— äººå·¥æ ‡ç­¾çš„æƒ…å†µä¸‹è¿›è¡Œè®­ç»ƒä¼˜åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒODQS åœ¨ GSM8Kã€HumanEval å’Œ OpenCoder ç­‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œåœ¨æ•°å­¦ä»»åŠ¡ä¸­å°† Pass@5 ç»å¯¹æå‡äº†é«˜è¾¾ 54.7%ï¼Œåœ¨ç¼–ç¨‹ä»»åŠ¡ä¸­æå‡äº† 22.9%ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨å‡å°‘ä¸‰è½®äº¤äº’çš„æƒ…å†µä¸‹åŒ¹é…åŸºå‡†æ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†äº¤äº’å¼æ¨ç†çš„å‡†ç¡®æ€§ä¸æ•ˆç‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13102v4",
      "published_date": "2025-12-15 08:59:19 UTC",
      "updated_date": "2026-01-06 08:41:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:01:43.095610+00:00"
    },
    {
      "arxiv_id": "2512.13101v1",
      "title": "Harmonizing Generalization and Specialization: Uncertainty-Informed Collaborative Learning for Semi-supervised Medical Image Segmentation",
      "title_zh": "å…¼é¡¾æ³›åŒ–ä¸ç‰¹åŒ–ï¼šé¢å‘åŠç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥ååŒå­¦ä¹ ",
      "authors": [
        "Wenjing Lu",
        "Yi Hong",
        "Yang Yang"
      ],
      "abstract": "Vision foundation models have demonstrated strong generalization in medical image segmentation by leveraging large-scale, heterogeneous pretraining. However, they often struggle to generalize to specialized clinical tasks under limited annotations or rare pathological variations, due to a mismatch between general priors and task-specific requirements. To address this, we propose Uncertainty-informed Collaborative Learning (UnCoL), a dual-teacher framework that harmonizes generalization and specialization in semi-supervised medical image segmentation. Specifically, UnCoL distills both visual and semantic representations from a frozen foundation model to transfer general knowledge, while concurrently maintaining a progressively adapting teacher to capture fine-grained and task-specific representations. To balance guidance from both teachers, pseudo-label learning in UnCoL is adaptively regulated by predictive uncertainty, which selectively suppresses unreliable supervision and stabilizes learning in ambiguous regions. Experiments on diverse 2D and 3D segmentation benchmarks show that UnCoL consistently outperforms state-of-the-art semi-supervised methods and foundation model baselines. Moreover, our model delivers near fully supervised performance with markedly reduced annotation requirements.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Vision foundation models åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­éš¾ä»¥å¹³è¡¡é€šç”¨æ³›åŒ–èƒ½åŠ›ä¸ç‰¹å®šä¸´åºŠä»»åŠ¡éœ€æ±‚çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º Uncertainty-informed Collaborative Learning (UnCoL) çš„åŠç›‘ç£å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨åŒè€å¸ˆç»“æ„ï¼Œä¸€æ–¹é¢ä»å†»ç»“çš„åŸºç¡€æ¨¡å‹ä¸­è’¸é¦é€šç”¨çŸ¥è¯†ï¼Œå¦ä¸€æ–¹é¢åˆ©ç”¨åŠ¨æ€é€‚åº”çš„è€å¸ˆæ¨¡å‹æ•æ‰ç‰¹å®šä»»åŠ¡çš„ç»†ç²’åº¦è¡¨ç¤ºã€‚ä¸ºäº†æé«˜å­¦ä¹ ç¨³å®šæ€§ï¼ŒUnCoL å¼•å…¥äº†é¢„æµ‹ä¸ç¡®å®šæ€§ (predictive uncertainty) æ¥å¼•å¯¼ä¼ªæ ‡ç­¾å­¦ä¹ ï¼Œä»è€Œæœ‰æ•ˆåœ°è¿‡æ»¤å’ŒæŠ‘åˆ¶ä¸å¯é çš„ç›‘ç£ä¿¡å·ã€‚åœ¨å¤šç§ 2D å’Œ 3D åŒ»å­¦å›¾åƒåˆ†å‰²åŸºå‡†ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„åŠç›‘ç£ç®—æ³•å’ŒåŸºç¡€æ¨¡å‹ã€‚æ­¤å¤–ï¼ŒUnCoL åœ¨æ˜¾è‘—å‡å°‘æ ‡æ³¨éœ€æ±‚çš„æƒ…å†µä¸‹ä»èƒ½å®ç°æ¥è¿‘å…¨ç›‘ç£çš„åˆ†å‰²æ•ˆæœï¼Œå±•ç¤ºäº†å…¶åœ¨ä¸´åºŠåŒ»ç–—åœºæ™¯ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been submitted to the IEEE TMI for possible publication",
      "pdf_url": "https://arxiv.org/pdf/2512.13101v1",
      "published_date": "2025-12-15 08:57:49 UTC",
      "updated_date": "2025-12-15 08:57:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:01:33.510115+00:00"
    },
    {
      "arxiv_id": "2512.13100v1",
      "title": "OXE-AugE: A Large-Scale Robot Augmentation of OXE for Scaling Cross-Embodiment Policy Learning",
      "title_zh": "OXE-AugEï¼šç”¨äºæ‰©å±•è·¨å…·èº«ç­–ç•¥å­¦ä¹ çš„å¤§è§„æ¨¡ OXE æœºå™¨äººå¢å¼º",
      "authors": [
        "Guanhua Ji",
        "Harsha Polavaram",
        "Lawrence Yunliang Chen",
        "Sandeep Bajamahal",
        "Zehan Ma",
        "Simeon Adebola",
        "Chenfeng Xu",
        "Ken Goldberg"
      ],
      "abstract": "Large and diverse datasets are needed for training generalist robot policies that have potential to control a variety of robot embodiments -- robot arm and gripper combinations -- across diverse tasks and environments. As re-collecting demonstrations and retraining for each new hardware platform are prohibitively costly, we show that existing robot data can be augmented for transfer and generalization. The Open X-Embodiment (OXE) dataset, which aggregates demonstrations from over 60 robot datasets, has been widely used as the foundation for training generalist policies. However, it is highly imbalanced: the top four robot types account for over 85\\% of its real data, which risks overfitting to robot-scene combinations. We present AugE-Toolkit, a scalable robot augmentation pipeline, and OXE-AugE, a high-quality open-source dataset that augments OXE with 9 different robot embodiments. OXE-AugE provides over 4.4 million trajectories, more than triple the size of the original OXE. We conduct a systematic study of how scaling robot augmentation impacts cross-embodiment learning. Results suggest that augmenting datasets with diverse arms and grippers improves policy performance not only on the augmented robots, but also on unseen robots and even the original robots under distribution shifts. In physical experiments, we demonstrate that state-of-the-art generalist policies such as OpenVLA and $Ï€_0$ benefit from fine-tuning on OXE-AugE, improving success rates by 24-45% on previously unseen robot-gripper combinations across four real-world manipulation tasks. Project website: https://OXE-AugE.github.io/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é€šç”¨æœºå™¨äººç­–ç•¥è®­ç»ƒä¸­æ•°æ®åˆ†å¸ƒé«˜åº¦ä¸å¹³è¡¡åŠè·¨ç¡¬ä»¶è¿ç§»æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº†AugE-Toolkitæ‰©å±•æµæ°´çº¿ä»¥åŠå¤§è§„æ¨¡æ•°æ®é›†OXE-AugEã€‚OXE-AugEé€šè¿‡å¯¹Open X-Embodiment (OXE) æ³¨å…¥9ç§ä¸åŒçš„robot embodimentsï¼Œæä¾›äº†è¶…è¿‡440ä¸‡æ¡è½¨è¿¹ï¼Œå…¶è§„æ¨¡è¾¾åˆ°åŸå§‹æ•°æ®é›†çš„ä¸‰å€ä»¥ä¸Šã€‚é€šè¿‡å¯¹Cross-Embodimentå­¦ä¹ çš„ç³»ç»Ÿæ€§ç ”ç©¶å‘ç°ï¼Œå¢å¼ºå¤šæ ·åŒ–çš„æœºæ¢°è‡‚å’Œå¤¹æŒå™¨æ•°æ®ä¸ä»…èƒ½æå‡æ¨¡å‹åœ¨å¢å¼ºæœºå™¨äººä¸Šçš„è¡¨ç°ï¼Œè¿˜èƒ½æ˜¾è‘—å¢å¼ºå…¶åœ¨æœªè§æœºå™¨äººä»¥åŠåŸå§‹æœºå™¨äººåœ¨åˆ†å¸ƒåç§» (distribution shifts) ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨çœŸå®ç‰©ç†å®éªŒä¸­ï¼ŒOpenVLAå’Œ$\\pi_0$ç­‰æœ€å…ˆè¿›ç­–ç•¥åœ¨OXE-AugEä¸Šè¿›è¡Œå¾®è°ƒåï¼Œåœ¨æœªè§è¿‡çš„æœºå™¨äºº-å¤¹æŒå™¨ç»„åˆä¸Šçš„ä»»åŠ¡æˆåŠŸç‡æå‡äº†24-45%ã€‚è¯¥æˆæœå±•ç¤ºäº†é€šè¿‡robot augmentationæ‰©å±•æ•°æ®é›†è§„æ¨¡å¯¹äºå®ç°é«˜æ³›åŒ–æ€§é€šç”¨æœºå™¨äººç­–ç•¥çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13100v1",
      "published_date": "2025-12-15 08:57:15 UTC",
      "updated_date": "2025-12-15 08:57:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:01:35.952198+00:00"
    },
    {
      "arxiv_id": "2512.13094v1",
      "title": "Sequence of Expert: Boosting Imitation Planners for Autonomous Driving through Temporal Alternation",
      "title_zh": "Sequence of Expertï¼šé€šè¿‡æ—¶é—´äº¤æ›¿å¢å¼ºè‡ªåŠ¨é©¾é©¶æ¨¡ä»¿è§„åˆ’å™¨",
      "authors": [
        "Xiang Li",
        "Gang Liu",
        "Weitao Zhou",
        "Hongyi Zhu",
        "Zhong Cao"
      ],
      "abstract": "Imitation learning (IL) has emerged as a central paradigm in autonomous driving. While IL excels in matching expert behavior in open-loop settings by minimizing per-step prediction errors, its performance degrades unexpectedly in closed-loop due to the gradual accumulation of small, often imperceptible errors over time.Over successive planning cycles, these errors compound, potentially resulting in severe failures.Current research efforts predominantly rely on increasingly sophisticated network architectures or high-fidelity training datasets to enhance the robustness of IL planners against error accumulation, focusing on the state-level robustness at a single time point. However, autonomous driving is inherently a continuous-time process, and leveraging the temporal scale to enhance robustness may provide a new perspective for addressing this issue.To this end, we propose a method termed Sequence of Experts (SoE), a temporal alternation policy that enhances closed-loop performance without increasing model size or data requirements. Our experiments on large-scale autonomous driving benchmarks nuPlan demonstrate that SoE method consistently and significantly improves the performance of all the evaluated models, and achieves state-of-the-art performance.This module may provide a key and widely applicable support for improving the training efficiency of autonomous driving models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶é¢†åŸŸä¸­æ¨¡ä»¿å­¦ä¹ (Imitation Learning)è§„åˆ’å™¨åœ¨é—­ç¯(closed-loop)ç¯å¢ƒä¸‹å› è¯¯å·®éšæ—¶é—´ç´¯ç§¯è€Œå¯¼è‡´ç³»ç»Ÿå¤±æ•ˆçš„æŒ‘æˆ˜ï¼Œæå‡ºäº†Sequence of Experts (SoE)æ–¹æ³•ã€‚SoEé€šè¿‡å¼•å…¥æ—¶é—´äº¤æ›¿ç­–ç•¥(temporal alternation policy)ï¼Œä»æ—¶é—´å°ºåº¦ç»´åº¦å¢å¼ºè§„åˆ’å™¨çš„é²æ£’æ€§ï¼Œä¸”è¯¥æ–¹æ³•ä¸éœ€è¦å¢åŠ æ¨¡å‹è§„æ¨¡æˆ–é¢å¤–æ•°æ®ã€‚åœ¨å¤§å‹è‡ªåŠ¨é©¾é©¶åŸºå‡†æµ‹è¯•nuPlanä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒSoEæ˜¾è‘—æå‡äº†æ‰€æœ‰è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½å¹¶è¾¾åˆ°äº†SOTAæ°´å¹³ã€‚è¯¥ç ”ç©¶ä¸ä»…ä¸ºè§£å†³é—­ç¯è¯¯å·®ç´¯ç§¯é—®é¢˜æä¾›äº†æ–°çš„è§†è§’ï¼Œè¿˜ä¸ºæå‡è‡ªåŠ¨é©¾é©¶æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡æä¾›äº†å…·æœ‰å¹¿æ³›é€‚ç”¨æ€§çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13094v1",
      "published_date": "2025-12-15 08:50:23 UTC",
      "updated_date": "2025-12-15 08:50:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:01:15.763906+00:00"
    },
    {
      "arxiv_id": "2512.13089v2",
      "title": "UniVCD: A New Method for Unsupervised Change Detection in the Open-Vocabulary Era",
      "title_zh": "UniVCDï¼šé¢å‘å¼€æ”¾è¯æ±‡æ—¶ä»£çš„æ— ç›‘ç£å˜åŒ–æ£€æµ‹æ–°æ–¹æ³•",
      "authors": [
        "Ziqiang Zhu",
        "Bowei Yang"
      ],
      "abstract": "Change detection (CD) identifies scene changes from multi-temporal observations and is widely used in urban development and environmental monitoring. Most existing CD methods rely on supervised learning, making performance strongly dataset-dependent and incurring high annotation costs; they typically focus on a few predefined categories and generalize poorly to diverse scenes. With the rise of vision foundation models such as SAM2 and CLIP, new opportunities have emerged to relax these constraints. We propose Unified Open-Vocabulary Change Detection (UniVCD), an unsupervised, open-vocabulary change detection method built on frozen SAM2 and CLIP. UniVCD detects category-agnostic changes across diverse scenes and imaging geometries without any labeled data or paired change images. A lightweight feature alignment module is introduced to bridge the spatially detailed representations from SAM2 and the semantic priors from CLIP, enabling high-resolution, semantically aware change estimation while keeping the number of trainable parameters small. On top of this, a streamlined post-processing pipeline is further introduced to suppress noise and pseudo-changes, improving the detection accuracy for objects with well-defined boundaries. Experiments on several public BCD (Binary Change Detection) and SCD (Semantic Change Detection) benchmarks show that UniVCD achieves consistently strong performance and matches or surpasses existing open-vocabulary CD methods in key metrics such as F1 and IoU. The results demonstrate that unsupervised change detection with frozen vision foundation models and lightweight multi-modal alignment is a practical and effective paradigm for open-vocabulary CD. Code and pretrained models will be released at https://github.com/Die-Xie/UniVCD.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†UniVCDï¼Œä¸€ç§åŸºäºé¢„è®­ç»ƒæ¨¡å‹SAM2å’ŒCLIPçš„æ— ç›‘ç£å¼€é›†å˜åŒ–æ£€æµ‹(Unsupervised, open-vocabulary change detection)æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå˜åŒ–æ£€æµ‹(CD)å¯¹æ ‡æ³¨æ•°æ®è¿‡åº¦ä¾èµ–ä»¥åŠæ³›åŒ–æ€§å—é™çš„é—®é¢˜ã€‚UniVCDæ— éœ€ä»»ä½•æ ‡è®°æ•°æ®æˆ–æˆå¯¹å›¾åƒï¼Œé€šè¿‡å¼•å…¥è½»é‡åŒ–ç‰¹å¾å¯¹é½æ¨¡å—(Lightweight feature alignment module)å°†SAM2çš„ç©ºé—´ç»†èŠ‚è¡¨ç¤ºä¸CLIPçš„è¯­ä¹‰å…ˆéªŒç›¸ç»“åˆï¼Œå®ç°äº†é«˜åˆ†è¾¨ç‡ä¸”å…·å¤‡è¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›çš„å˜åŒ–ä¼°è®¡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•é€šè¿‡æµçº¿å‹çš„åå¤„ç†æµæ°´çº¿(Post-processing pipeline)æœ‰æ•ˆæŠ‘åˆ¶äº†å™ªå£°å’Œä¼ªå˜åŒ–ï¼Œå¢å¼ºäº†å¯¹æ¸…æ™°è¾¹ç•Œç‰©ä½“çš„æ£€æµ‹å‡†ç¡®æ€§ã€‚åœ¨å¤šä¸ªå…¬å¼€çš„äºŒå€¼å˜åŒ–æ£€æµ‹(BCD)å’Œè¯­ä¹‰å˜åŒ–æ£€æµ‹(SCD)åŸºå‡†æµ‹è¯•ä¸­ï¼ŒUniVCDåœ¨F1å’ŒIoUç­‰æ ¸å¿ƒæŒ‡æ ‡ä¸Šå±•ç°å‡ºå¼ºåŠ²æ€§èƒ½ï¼Œè¾¾åˆ°æˆ–è¶…è¶Šäº†ç°æœ‰çš„å¼€é›†å˜åŒ–æ£€æµ‹æ–¹æ³•ã€‚å®éªŒç»“æœè¯æ˜ï¼Œåˆ©ç”¨å†»ç»“çš„è§†è§‰åŸºç¡€æ¨¡å‹é…åˆè½»é‡åŒ–å¤šæ¨¡æ€å¯¹é½ï¼Œæ˜¯å®ç°é«˜æ•ˆã€å®ç”¨æ— ç›‘ç£å¼€é›†å˜åŒ–æ£€æµ‹çš„ä¸€ç§æ–°èŒƒå¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.13089v2",
      "published_date": "2025-12-15 08:42:23 UTC",
      "updated_date": "2025-12-18 05:14:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:01:41.404480+00:00"
    },
    {
      "arxiv_id": "2512.13074v1",
      "title": "A Simple and Effective Framework for Symmetric Consistent Indexing in Large-Scale Dense Retrieval",
      "title_zh": "é¢å‘å¤§è§„æ¨¡ç¨ å¯†æ£€ç´¢çš„ç®€å•é«˜æ•ˆå¯¹ç§°ä¸€è‡´æ€§ç´¢å¼•æ¡†æ¶",
      "authors": [
        "Huimu Wang",
        "Yiming Qiu",
        "Xingzhi Yao",
        "Zhiguo Chen",
        "Guoyu Tang",
        "Songlin Wang",
        "Sulong Xu",
        "Mingming Li"
      ],
      "abstract": "Dense retrieval has become the industry standard in large-scale information retrieval systems due to its high efficiency and competitive accuracy. Its core relies on a coarse-to-fine hierarchical architecture that enables rapid candidate selection and precise semantic matching, achieving millisecond-level response over billion-scale corpora. This capability makes it essential not only in traditional search and recommendation scenarios but also in the emerging paradigm of generative recommendation driven by large language models, where semantic IDs-themselves a form of coarse-to-fine representation-play a foundational role. However, the widely adopted dual-tower encoding architecture introduces inherent challenges, primarily representational space misalignment and retrieval index inconsistency, which degrade matching accuracy, retrieval stability, and performance on long-tail queries. These issues are further magnified in semantic ID generation, ultimately limiting the performance ceiling of downstream generative models.\n  To address these challenges, this paper proposes a simple and effective framework named SCI comprising two synergistic modules: a symmetric representation alignment module that employs an innovative input-swapping mechanism to unify the dual-tower representation space without adding parameters, and an consistent indexing with dual-tower synergy module that redesigns retrieval paths using a dual-view indexing strategy to maintain consistency from training to inference. The framework is systematic, lightweight, and engineering-friendly, requiring minimal overhead while fully supporting billion-scale deployment. We provide theoretical guarantees for our approach, with its effectiveness validated by results across public datasets and real-world e-commerce datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SCI (Symmetric Consistent Indexing)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è§„æ¨¡ç¨ å¯†æ£€ç´¢(Dense retrieval)ä¸­åŒå¡”(dual-tower)ç¼–ç æ¶æ„å›ºæœ‰çš„è¡¨ç¤ºç©ºé—´å¤±é…å’Œæ£€ç´¢ç´¢å¼•ä¸ä¸€è‡´é—®é¢˜ã€‚è¯¥æ¡†æ¶ç”±ä¸¤ä¸ªååŒæ¨¡å—ç»„æˆï¼šå¯¹ç§°è¡¨ç¤ºå¯¹é½æ¨¡å—åˆ©ç”¨åˆ›æ–°çš„è¾“å…¥äº¤æ¢(input-swapping)æœºåˆ¶åœ¨ä¸å¢åŠ å‚æ•°çš„å‰æä¸‹ç»Ÿä¸€è¡¨ç¤ºç©ºé—´ï¼Œè€ŒåŒå¡”ååŒä¸€è‡´æ€§ç´¢å¼•æ¨¡å—åˆ™é€šè¿‡åŒè§†å›¾ç´¢å¼•(dual-view indexing)ç­–ç•¥ç¡®ä¿è®­ç»ƒä¸æ¨ç†é˜¶æ®µæ£€ç´¢è·¯å¾„çš„ä¸€è‡´æ€§ã€‚SCIå…·æœ‰ç³»ç»ŸåŒ–ã€è½»é‡çº§ä¸”æ˜“äºå·¥ç¨‹å®ç°çš„ç‰¹ç‚¹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ”¯æŒåäº¿è§„æ¨¡(billion-scale)çš„å®é™…éƒ¨ç½²éœ€æ±‚ã€‚ç†è®ºè¯æ˜ä¸å®éªŒç»“æœå‡éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œåœ¨å…¬å…±æ•°æ®é›†å’ŒçœŸå®ç”µå•†æ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†åŒ¹é…ç²¾åº¦å’Œæ£€ç´¢ç¨³å®šæ€§ã€‚è¿™ä¸€ç ”ç©¶ä¸ä»…ä¼˜åŒ–äº†é•¿å°¾æŸ¥è¯¢(long-tail queries)çš„æ€§èƒ½ï¼Œä¹Ÿä¸ºä¸‹æ¸¸ç”Ÿæˆå¼æ¨è(generative recommendation)æ¨¡å‹æä¾›äº†æ›´å¯é çš„è¯­ä¹‰è¡¨ç¤ºåŸºç¡€ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13074v1",
      "published_date": "2025-12-15 08:11:24 UTC",
      "updated_date": "2025-12-15 08:11:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:02:28.198428+00:00"
    },
    {
      "arxiv_id": "2512.13070v1",
      "title": "M-GRPO: Stabilizing Self-Supervised Reinforcement Learning for Large Language Models with Momentum-Anchored Policy Optimization",
      "title_zh": "M-GRPOï¼šé€šè¿‡åŠ¨é‡é”šå®šç­–ç•¥ä¼˜åŒ–ç¨³å®šå¤§è¯­è¨€æ¨¡å‹çš„è‡ªç›‘ç£å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Bizhe Bai",
        "Hongming Wu",
        "Peng Ye",
        "Tao Chen"
      ],
      "abstract": "Self-supervised reinforcement learning (RL) presents a promising approach for enhancing the reasoning capabilities of Large Language Models (LLMs) without reliance on expensive human-annotated data. However, we find that existing methods suffer from a critical failure mode under long-horizon training: a \"policy collapse\" where performance precipitously degrades. We diagnose this instability and demonstrate that simply scaling the number of rollouts -- a common strategy to improve performance -- only delays, but does not prevent, this collapse. To counteract this instability, we first introduce M-GRPO (Momentum-Anchored Group Relative Policy Optimization), a framework that leverages a slowly evolving momentum model to provide a stable training target. In addition, we identify that this process is often accompanied by a rapid collapse in policy entropy, resulting in a prematurely confident and suboptimal policy. To specifically address this issue, we propose a second contribution: an adaptive filtering method based on the interquartile range (IQR) that dynamically prunes low-entropy trajectories, preserving essential policy diversity. Our extensive experiments on multiple reasoning benchmarks demonstrate that M-GRPO stabilizes the training process while the IQR filter prevents premature convergence. The combination of these two innovations leads to superior training stability and state-of-the-art performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è‡ªç›‘ç£å¼ºåŒ–å­¦ä¹ ï¼ˆSelf-supervised RLï¼‰ä¸­ï¼Œé•¿å‘¨æœŸè®­ç»ƒä¼šå¯¼è‡´ä¸¥é‡çš„â€œç­–ç•¥å´©æºƒâ€ï¼ˆpolicy collapseï¼‰é—®é¢˜ï¼Œå³æ¨¡å‹æ€§èƒ½åœ¨ç‰¹å®šé˜¶æ®µæ€¥å‰§ä¸‹é™ã€‚ç ”ç©¶å‘ç°ï¼Œä»…é€šè¿‡å¢åŠ é‡‡æ ·æ•°é‡ï¼ˆrolloutsï¼‰å¹¶ä¸èƒ½æ ¹é™¤è¿™ä¸€ä¸ç¨³å®šæ€§ï¼Œè€Œåªèƒ½æ¨è¿Ÿå´©æºƒçš„å‘ç”Ÿã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†M-GRPOï¼ˆMomentum-Anchored Group Relative Policy Optimizationï¼‰æ¡†æ¶ï¼Œåˆ©ç”¨ç¼“æ…¢æ¼”åŒ–çš„åŠ¨é‡æ¨¡å‹ï¼ˆmomentum modelï¼‰æ¥æä¾›ç¨³å®šçš„è®­ç»ƒç›®æ ‡ã€‚åŒæ—¶ï¼Œé’ˆå¯¹ç­–ç•¥ç†µï¼ˆpolicy entropyï¼‰å¿«é€Ÿä¸‹é™å¯¼è‡´çš„æ—©ç†Ÿæ”¶æ•›é—®é¢˜ï¼Œè¯¥ç ”ç©¶å¼•å…¥äº†ä¸€ç§åŸºäºå››åˆ†ä½è·ï¼ˆIQRï¼‰çš„è‡ªé€‚åº”è¿‡æ»¤æ–¹æ³•ï¼Œé€šè¿‡åŠ¨æ€å‰”é™¤ä½ç†µè½¨è¿¹æ¥ä¿æŒç­–ç•¥å¤šæ ·æ€§ã€‚åœ¨å¤šä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¯æ˜ï¼ŒM-GRPOæ˜¾è‘—æå‡äº†è®­ç»ƒç¨³å®šæ€§ï¼Œè€ŒIQRè¿‡æ»¤åˆ™æœ‰æ•ˆé˜²æ­¢äº†æ¨¡å‹è¿‡æ—©é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚è¿™ä¸¤é¡¹åˆ›æ–°æŠ€æœ¯çš„ç»“åˆä½¿å¾—æ¨¡å‹åœ¨ä¿æŒè®­ç»ƒè¿‡ç¨‹ç¨³å¥çš„åŒæ—¶ï¼Œæœ€ç»ˆè¾¾åˆ°äº†æœ€å…ˆè¿›ï¼ˆstate-of-the-artï¼‰çš„æ€§èƒ½æ°´å¹³ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 5 figures,Accepted NeurIPS 2025 Workshop on Efficient Reasoning",
      "pdf_url": "https://arxiv.org/pdf/2512.13070v1",
      "published_date": "2025-12-15 08:07:23 UTC",
      "updated_date": "2025-12-15 08:07:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:02:00.664468+00:00"
    },
    {
      "arxiv_id": "2512.13063v1",
      "title": "LLM Rationalis? Measuring Bargaining Capabilities of AI Negotiators",
      "title_zh": "LLM æ˜¯å¦ç†æ€§ï¼Ÿè¯„ä¼°äººå·¥æ™ºèƒ½è°ˆåˆ¤è€…çš„è®®ä»·èƒ½åŠ›",
      "authors": [
        "Cheril Shah",
        "Akshit Agarwal",
        "Kanak Garg",
        "Mourad Heddaya"
      ],
      "abstract": "Bilateral negotiation is a complex, context-sensitive task in which human negotiators dynamically adjust anchors, pacing, and flexibility to exploit power asymmetries and informal cues. We introduce a unified mathematical framework for modeling concession dynamics based on a hyperbolic tangent curve, and propose two metrics burstiness tau and the Concession-Rigidity Index (CRI) to quantify the timing and rigidity of offer trajectories. We conduct a large-scale empirical comparison between human negotiators and four state-of-the-art large language models (LLMs) across natural-language and numeric-offers settings, with and without rich market context, as well as six controlled power-asymmetry scenarios. Our results reveal that, unlike humans who smoothly adapt to situations and infer the opponents position and strategies, LLMs systematically anchor at extremes of the possible agreement zone for negotiations and optimize for fixed points irrespective of leverage or context. Qualitative analysis further shows limited strategy diversity and occasional deceptive tactics used by LLMs. Moreover the ability of LLMs to negotiate does not improve with better models. These findings highlight fundamental limitations in current LLM negotiation capabilities and point to the need for models that better internalize opponent reasoning and context-dependent strategy.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åŒè¾¹è°ˆåˆ¤ä¸­çš„èƒ½åŠ›ï¼Œå¹¶å°†å…¶ä¸äººç±»è°ˆåˆ¤è€…è¿›è¡Œäº†å¤§è§„æ¨¡å®è¯å¯¹æ¯”ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªåŸºäºåŒæ›²æ­£åˆ‡æ›²çº¿ï¼ˆhyperbolic tangent curveï¼‰çš„ç»Ÿä¸€æ•°å­¦æ¡†æ¶æ¥å»ºæ¨¡è®©æ­¥åŠ¨æ€ï¼Œå¹¶å¼•å…¥äº†çˆ†å‘æ€§ï¼ˆburstiness $\\tau$ï¼‰å’Œè®©æ­¥-åˆšæ€§æŒ‡æ•°ï¼ˆConcession-Rigidity Index, CRIï¼‰ä¸¤ä¸ªæŒ‡æ ‡æ¥é‡åŒ–æŠ¥ä»·è½¨è¿¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸èƒ½å¤Ÿçµæ´»é€‚åº”ç¯å¢ƒå¹¶æ¨æ–­å¯¹æ‰‹ç­–ç•¥çš„äººç±»ä¸åŒï¼ŒLLMsè¡¨ç°å‡ºç³»ç»Ÿæ€§çš„æç«¯é”šå®šå€¾å‘ï¼Œä¸”æ— è®ºæ æ†æˆ–è¯­å¢ƒå¦‚ä½•éƒ½å€¾å‘äºä¼˜åŒ–å›ºå®šç‚¹ã€‚å®šæ€§åˆ†æè¿›ä¸€æ­¥æ­ç¤ºäº†LLMsåœ¨ç­–ç•¥å¤šæ ·æ€§ä¸Šçš„åŒ®ä¹ä»¥åŠå¶å°”ä½¿ç”¨çš„æ¬ºéª—æ‰‹æ®µã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°LLMsçš„è°ˆåˆ¤èƒ½åŠ›å¹¶ä¸ä¼šéšç€æ¨¡å‹è§„æ¨¡çš„æå‡è€Œå¢å¼ºï¼Œè¿™å‡¸æ˜¾äº†å½“å‰æ¨¡å‹åœ¨å†…åŒ–å¯¹æ‰‹æ¨ç†å’Œè¯­å¢ƒä¾èµ–ç­–ç•¥æ–¹é¢çš„æ ¹æœ¬å±€é™æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in the First Workshop on Multi-Turn Interactions in Large Language Models at Neurips 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.13063v1",
      "published_date": "2025-12-15 07:50:09 UTC",
      "updated_date": "2025-12-15 07:50:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:02:56.470803+00:00"
    },
    {
      "arxiv_id": "2512.22148v1",
      "title": "Rethinking Leveraging Pre-Trained Multi-Layer Representations for Speaker Verification",
      "title_zh": "é‡æ–°å®¡è§†è¯´è¯äººç¡®è®¤ä¸­é¢„è®­ç»ƒå¤šå±‚è¡¨ç¤ºçš„åˆ©ç”¨",
      "authors": [
        "Jin Sob Kim",
        "Hyun Joon Park",
        "Wooseok Shin",
        "Sung Won Han"
      ],
      "abstract": "Recent speaker verification studies have achieved notable success by leveraging layer-wise output from pre-trained Transformer models. However, few have explored the advancements in aggregating these multi-level features beyond the static weighted average. We present Layer Attentive Pooling (LAP), a novel strategy for aggregating inter-layer representations from pre-trained speech models for speaker verification. LAP assesses the significance of each layer from multiple perspectives time-dynamically, and employs max pooling instead of averaging. Additionally, we propose a lightweight backend speaker model comprising LAP and Attentive Statistical Temporal Pooling (ASTP) to extract speaker embeddings from pre-trained model output. Experiments on the VoxCeleb benchmark reveal that our compact architecture achieves state-of-the-art performance while greatly reducing the training time. We further analyzed LAP design and its dynamic weighting mechanism for capturing speaker characteristics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯´è¯äººéªŒè¯(Speaker Verification)ä»»åŠ¡ä¸­é¢„è®­ç»ƒTransformeræ¨¡å‹å¤šå±‚è¡¨ç¤ºçš„åˆ©ç”¨é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºå±‚æ³¨æ„åŠ›æ± åŒ–(Layer Attentive Pooling, LAP)çš„æ–°å‹èšåˆç­–ç•¥ã€‚ä½œè€…æŒ‡å‡ºç›®å‰ä¸»æµçš„é™æ€åŠ æƒå¹³å‡æ–¹æ³•å­˜åœ¨å±€é™ï¼Œè€ŒLAPèƒ½ä»å¤šç»´åº¦æ—¶é—´åŠ¨æ€åœ°è¯„ä¼°å„å±‚çš„é‡è¦æ€§ï¼Œå¹¶åˆ©ç”¨æœ€å¤§æ± åŒ–(max pooling)æ›¿ä»£ä¼ ç»Ÿçš„å¹³å‡æ–¹å¼ã€‚åŒæ—¶ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†ä¸€ä¸ªç»“åˆäº†LAPä¸æ³¨æ„åŠ›ç»Ÿè®¡æ—¶é—´æ± åŒ–(Attentive Statistical Temporal Pooling, ASTP)çš„è½»é‡çº§åç«¯è¯´è¯äººæ¨¡å‹ï¼Œç”¨äºä»é¢„è®­ç»ƒæ¨¡å‹è¾“å‡ºä¸­æå–è¯´è¯äººåµŒå…¥ã€‚åœ¨VoxCelebåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆåœ¨æ˜¾è‘—ç¼©çŸ­è®­ç»ƒæ—¶é—´çš„åŒæ—¶å–å¾—äº†SOTAæ€§èƒ½ã€‚è¿›ä¸€æ­¥çš„åˆ†æéªŒè¯äº†LAPè®¾è®¡åŠå…¶åŠ¨æ€æƒé‡æœºåˆ¶åœ¨æ•æ‰å…³é”®è¯´è¯äººç‰¹å¾æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to Interspeech 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.22148v1",
      "published_date": "2025-12-15 07:39:56 UTC",
      "updated_date": "2025-12-15 07:39:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:02:22.203401+00:00"
    },
    {
      "arxiv_id": "2512.22147v1",
      "title": "GPU Kernel Optimization Beyond Full Builds: An LLM Framework with Minimal Executable Programs",
      "title_zh": "çªç ´å®Œæ•´æ„å»ºé™åˆ¶çš„GPUå†…æ ¸ä¼˜åŒ–ï¼šåŸºäºæœ€å°å¯æ‰§è¡Œç¨‹åºçš„LLMæ¡†æ¶",
      "authors": [
        "Ruifan Chu",
        "Anbang Wang",
        "Xiuxiu Bai",
        "Shuai Liu",
        "Xiaoshe Dong"
      ],
      "abstract": "In high-performance computing, hotspot GPU kernels are primary bottlenecks, and expert manual tuning is costly and hard to port. Large language model methods often assume kernels can be compiled and executed cheaply, which fails in large applications where full builds and runs are expensive. We present an end-to-end LLM framework with performance feedback that optimizes kernels without building the full application. From independently extracted hotspot kernels, it automatically completes code into a Minimal Executable Program (MEP), then performs multi-round iterative optimization and evaluation outside the full application. The framework integrates Automatic Error Repair and Performance Pattern Inheritance to fix faults, preserve correctness, reuse effective tiling/memory/synchronization strategies, and reduce search cost. Optimized variants are reintegrated into the original application for validation. We evaluate on NVIDIA GPUs and the Haiguang Deep Computing Unit (DCU) platform (AMD-licensed architecture) using PolyBench, the AMD APP SDK, and hotspot kernels from large-scale supercomputing applications. The method achieves average speedups of 5.05x (PolyBench on NVIDIA), 7.77x (PolyBench on DCU), 1.77x (AMD APP SDK), and 1.25x on three hotspot kernels, surpassing direct LLM optimization. The approach requires no full-source dependencies, offers cross-platform portability, and enables practical, low-cost GPU kernel optimization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é«˜æ€§èƒ½è®¡ç®—ä¸­ GPU kernel ä¼˜åŒ–æˆæœ¬é«˜ã€å¤§å‹åº”ç”¨å®Œæ•´æ„å»ºè€—æ—¶ç­‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäº LLM çš„ç«¯åˆ°ç«¯ä¼˜åŒ–æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ä»ç‹¬ç«‹æå–çš„çƒ­ç‚¹ kernel ä¸­è‡ªåŠ¨è¡¥å…¨ä»£ç ï¼Œç”Ÿæˆæœ€å°å¯æ‰§è¡Œç¨‹åº (Minimal Executable Program, MEP)ï¼Œä»è€Œåœ¨è„±ç¦»å®Œæ•´åº”ç”¨çš„æƒ…å†µä¸‹è¿›è¡Œå¤šè½®è¿­ä»£ä¼˜åŒ–ä¸æ€§èƒ½åé¦ˆã€‚æ¡†æ¶é›†æˆäº†è‡ªåŠ¨é”™è¯¯ä¿®å¤ (Automatic Error Repair) å’Œæ€§èƒ½æ¨¡å¼ç»§æ‰¿ (Performance Pattern Inheritance) æŠ€æœ¯ï¼Œåœ¨ä¿®å¤ä»£ç æ•…éšœçš„åŒæ—¶èƒ½å¤Ÿå¤ç”¨æœ‰æ•ˆçš„ tilingã€å†…å­˜ç®¡ç†å’ŒåŒæ­¥ç­–ç•¥ï¼Œæ˜¾è‘—é™ä½äº†æœç´¢æˆæœ¬ã€‚å®éªŒåœ¨ NVIDIA GPU å’Œæµ·å…‰ DCU å¹³å°ä¸Šè¿›è¡Œï¼Œæ¶µç›–äº† PolyBenchã€AMD APP SDK åŠå®é™…è¶…ç®—åº”ç”¨çš„çƒ­ç‚¹ kernelã€‚ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒåŸºå‡†æµ‹è¯•ä¸­å®ç°äº† 1.25x è‡³ 7.77x çš„åŠ é€Ÿæ¯”ï¼Œæ€§èƒ½ä¼˜äºç›´æ¥ä½¿ç”¨ LLM çš„ä¼˜åŒ–æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•æ— éœ€å®Œæ•´çš„æºç ä¾èµ–å¹¶å…·å¤‡è·¨å¹³å°ç§»æ¤æ€§ï¼Œä¸ºä½æˆæœ¬ã€å®ç”¨çš„ GPU kernel æ€§èƒ½è°ƒä¼˜æä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.22147v1",
      "published_date": "2025-12-15 07:20:15 UTC",
      "updated_date": "2025-12-15 07:20:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:02:18.089493+00:00"
    },
    {
      "arxiv_id": "2512.13043v1",
      "title": "GTR-Turbo: Merged Checkpoint is Secretly a Free Teacher for Agentic VLM Training",
      "title_zh": "GTR-Turboï¼šåˆå¹¶æ£€æŸ¥ç‚¹å³ä¸ºæ™ºèƒ½ä½“ VLM è®­ç»ƒçš„å…è´¹æ•™å¸ˆ",
      "authors": [
        "Tong Wei",
        "Yijun Yang",
        "Changhao Zhang",
        "Junliang Xing",
        "Yuanchun Shi",
        "Zongqing Lu",
        "Deheng Ye"
      ],
      "abstract": "Multi-turn reinforcement learning (RL) for multi-modal agents built upon vision-language models (VLMs) is hampered by sparse rewards and long-horizon credit assignment. Recent methods densify the reward by querying a teacher that provides step-level feedback, e.g., Guided Thought Reinforcement (GTR) and On-Policy Distillation, but rely on costly, often privileged models as the teacher, limiting practicality and reproducibility. We introduce GTR-Turbo, a highly efficient upgrade to GTR, which matches the performance without training or querying an expensive teacher model. Specifically, GTR-Turbo merges the weights of checkpoints produced during the ongoing RL training, and then uses this merged model as a \"free\" teacher to guide the subsequent RL via supervised fine-tuning or soft logit distillation. This design removes dependence on privileged VLMs (e.g., GPT or Gemini), mitigates the \"entropy collapse\" observed in prior work, and keeps training stable. Across diverse visual agentic tasks, GTR-Turbo improves the accuracy of the baseline model by 10-30% while reducing wall-clock training time by 50% and compute cost by 60% relative to GTR.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GTR-Turboï¼Œæ—¨åœ¨è§£å†³åŸºäº Vision-Language Models (VLMs) çš„å¤šæ¨¡æ€æ™ºèƒ½ä½“åœ¨å¤šè½®å¼ºåŒ–å­¦ä¹  (RL) ä¸­é¢ä¸´çš„å¥–åŠ±ç¨€ç–å’Œé•¿ç¨‹ä¿¡ç”¨åˆ†é…éš¾é¢˜ã€‚ç›¸è¾ƒäºä¾èµ–æ˜‚è´µæˆ–å—é™çš„å¤–éƒ¨æ¨¡å‹ä½œä¸ºå¯¼å¸ˆçš„ä¼ ç»Ÿæ–¹æ³•ï¼ŒGTR-Turbo é€šè¿‡åˆå¹¶è®­ç»ƒè¿‡ç¨‹ä¸­äº§ç”Ÿçš„å¤šä¸ªæ£€æŸ¥ç‚¹æƒé‡ï¼ˆMerged Checkpointï¼‰ï¼Œæ„å»ºäº†ä¸€ä¸ªæ— éœ€é¢å¤–æˆæœ¬çš„â€œå…è´¹â€å¯¼å¸ˆã€‚è¯¥æ¡†æ¶åˆ©ç”¨åˆå¹¶åçš„æ¨¡å‹é€šè¿‡ Supervised Fine-Tuning æˆ– Soft Logit Distillation æ¥å¼•å¯¼åç»­çš„å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ï¼Œæœ‰æ•ˆç¼“è§£äº†å‰åºç ”ç©¶ä¸­è§‚å¯Ÿåˆ°çš„â€œç†µåç¼©â€å¹¶ç¡®ä¿äº†è®­ç»ƒç¨³å®šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGTR-Turbo åœ¨å¤šé¡¹è§†è§‰æ™ºèƒ½ä»»åŠ¡ä¸­å°†åŸºçº¿æ¨¡å‹çš„å‡†ç¡®ç‡æå‡äº† 10-30%ï¼Œä¸”ç›¸æ¯”äº GTR æ–¹æ³•ï¼Œå…¶è®­ç»ƒæ—¶é•¿ç¼©çŸ­äº† 50%ï¼Œè®¡ç®—æˆæœ¬é™ä½äº† 60%ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13043v1",
      "published_date": "2025-12-15 07:11:56 UTC",
      "updated_date": "2025-12-15 07:11:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:03:29.790987+00:00"
    },
    {
      "arxiv_id": "2512.13033v1",
      "title": "Scaling Bidirectional Spans and Span Violations in Attention Mechanism",
      "title_zh": "æ³¨æ„åŠ›æœºåˆ¶ä¸­åŒå‘è·¨åº¦ä¸è·¨åº¦è¿åé¡¹çš„ç¼©æ”¾",
      "authors": [
        "Jongwook Kim",
        "Sangheon Yun",
        "Sukjin Yoon"
      ],
      "abstract": "The canonical $O(N^2)$ Transformer remains the empirical performance frontier in sequence modeling, and its training can be further optimized by addressing geometric inefficiency. We propose an optimization framework that leverages an asymmetric projection to decompose the backward-pass gradients into parallel spans and orthogonal violations, while keeping the canonical forward-pass $QKV$ structure intact. Through consistent experimental validation across various decomposition and projection setups, we provide strong theoretical evidence: the standard attention gradient is suboptimal. We demonstrated that selectively scaling these components, focusing primarily on $0^{th}$ order bidirectional parallel spans, yields the most effective learning signal. On the limited WikiText-2 dataset, and using a crude configuration, this method achieved a $0.56\\%$ reduction in validation loss, confirming the framework's fundamental validity and suggesting significant potential gains on larger datasets and deeper training regimes",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç»å…¸Transformeræ¨¡å‹ä¸­çš„å‡ ä½•ä½æ•ˆé—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåŸºäºéå¯¹ç§°æŠ•å½±ï¼ˆAsymmetric Projectionï¼‰çš„ä¼˜åŒ–æ¡†æ¶ã€‚è¯¥æ¡†æ¶åœ¨ä¿æŒå‰å‘ä¼ æ’­QKVç»“æ„ä¸å˜çš„æƒ…å†µä¸‹ï¼Œå°†åå‘ä¼ æ’­æ¢¯åº¦åˆ†è§£ä¸ºå¹¶è¡Œè·¨åº¦ï¼ˆParallel Spansï¼‰å’Œæ­£äº¤å†²çªï¼ˆOrthogonal Violationsï¼‰ã€‚é€šè¿‡å¯¹ä¸åŒåˆ†è§£å’ŒæŠ•å½±è®¾ç½®çš„å®éªŒéªŒè¯ï¼Œç ”ç©¶æä¾›äº†å¼ºæœ‰åŠ›çš„ç†è®ºè¯æ®ï¼Œè¯æ˜æ ‡å‡†çš„æ³¨æ„åŠ›æ¢¯åº¦æ˜¯æ¬¡ä¼˜çš„ã€‚å®éªŒå‘ç°ï¼Œé€‰æ‹©æ€§åœ°ç¼©æ”¾è¿™äº›æ¢¯åº¦ç»„ä»¶ï¼Œç‰¹åˆ«æ˜¯ä¸“æ³¨äºé›¶é˜¶åŒå‘å¹¶è¡Œè·¨åº¦ï¼ˆ0th order bidirectional parallel spansï¼‰ï¼Œèƒ½å¤Ÿäº§ç”Ÿæœ€æœ‰æ•ˆçš„å­¦ä¹ ä¿¡å·ã€‚åœ¨WikiText-2æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å³ä¾¿åœ¨åˆæ­¥é…ç½®ä¸‹ä¹Ÿå®ç°äº†éªŒè¯æŸå¤±0.56%çš„é™ä½ã€‚è¿™ä¸€ç»“æœè¯å®äº†è¯¥æ¡†æ¶çš„åŸºç¡€æœ‰æ•ˆæ€§ï¼Œå¹¶é¢„ç¤ºç€åœ¨å¤§è§„æ¨¡æ•°æ®é›†å’Œæ›´æ·±åº¦çš„è®­ç»ƒæ–¹æ¡ˆä¸­å…·æœ‰æ˜¾è‘—çš„æ½œåœ¨æ”¶ç›Šã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13033v1",
      "published_date": "2025-12-15 07:03:24 UTC",
      "updated_date": "2025-12-15 07:03:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:03:31.784912+00:00"
    },
    {
      "arxiv_id": "2512.13752v1",
      "title": "STAR: STacked AutoRegressive Scheme for Unified Multimodal Learning",
      "title_zh": "STARï¼šé¢å‘ç»Ÿä¸€å¤šæ¨¡æ€å­¦ä¹ çš„å †å å¼è‡ªå›å½’æ–¹æ¡ˆ",
      "authors": [
        "Jie Qin",
        "Jiancheng Huang",
        "Limeng Qiao",
        "Lin Ma"
      ],
      "abstract": "Multimodal large language models (MLLMs) play a pivotal role in advancing the quest for general artificial intelligence. However, achieving unified target for multimodal understanding and generation remains challenging due to optimization conflicts and performance trade-offs. To effectively enhance generative performance while preserving existing comprehension capabilities, we introduce STAR: a STacked AutoRegressive scheme for task-progressive unified multimodal learning. This approach decomposes multimodal learning into multiple stages: understanding, generation, and editing. By freezing the parameters of the fundamental autoregressive (AR) model and progressively stacking isomorphic AR modules, it avoids cross-task interference while expanding the model's capabilities. Concurrently, we introduce a high-capacity VQ to enhance the granularity of image representations and employ an implicit reasoning mechanism to improve generation quality under complex conditions. Experiments demonstrate that STAR achieves state-of-the-art performance on GenEval (0.91), DPG-Bench (87.44), and ImgEdit (4.34), validating its efficacy for unified multimodal learning.",
      "tldr_zh": "å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) åœ¨è¿½æ±‚ç»Ÿä¸€çš„å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆæ—¶ï¼Œå¾€å¾€é¢ä¸´ä¼˜åŒ–å†²çªå’Œæ€§èƒ½æƒè¡¡çš„æŒ‘æˆ˜ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº† STARï¼Œä¸€ç§åŸºäºå †å è‡ªå›å½’ (STacked AutoRegressive) æ–¹æ¡ˆçš„ä»»åŠ¡æ¸è¿›å¼ç»Ÿä¸€å¤šæ¨¡æ€å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ–¹æ³•å°†å¤šæ¨¡æ€å­¦ä¹ åˆ’åˆ†ä¸ºç†è§£ã€ç”Ÿæˆå’Œç¼–è¾‘ä¸‰ä¸ªé˜¶æ®µï¼Œé€šè¿‡å†»ç»“åŸºç¡€ AR æ¨¡å‹çš„å‚æ•°å¹¶é€æ­¥å †å åŒæ„çš„ AR æ¨¡å—ï¼Œåœ¨æ‰©å±•æ¨¡å‹åŠŸèƒ½çš„åŒæ—¶æœ‰æ•ˆé¿å…äº†è·¨ä»»åŠ¡å¹²æ‰°ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†é«˜å®¹é‡çš„ VQ ä»¥æå‡å›¾åƒè¡¨ç¤ºç²’åº¦ï¼Œå¹¶é‡‡ç”¨éšå¼æ¨ç†æœºåˆ¶ (implicit reasoning mechanism) å¢å¼ºäº†å¤æ‚åœºæ™¯ä¸‹çš„ç”Ÿæˆè´¨é‡ã€‚å®éªŒè¯æ˜ï¼ŒSTAR åœ¨ GenEvalã€DPG-Bench å’Œ ImgEdit ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†å½“å‰æœ€å…ˆè¿› (SOTA) çš„è¡¨ç°ï¼Œæœ‰åŠ›éªŒè¯äº†å…¶åœ¨ç»Ÿä¸€å¤šæ¨¡æ€å­¦ä¹ é¢†åŸŸçš„å“è¶Šæ•ˆèƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.13752v1",
      "published_date": "2025-12-15 07:02:59 UTC",
      "updated_date": "2025-12-15 07:02:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:03:33.567472+00:00"
    },
    {
      "arxiv_id": "2512.19711v1",
      "title": "PHANTOM: PHysical ANamorphic Threats Obstructing Connected Vehicle Mobility",
      "title_zh": "PHANTOMï¼šé˜»ç¢è”ç½‘è½¦è¾†ç§»åŠ¨æ€§çš„ç‰©ç†æ­ªåƒå¨èƒ",
      "authors": [
        "Md Nahid Hasan Shuvo",
        "Moinul Hossain"
      ],
      "abstract": "Connected autonomous vehicles (CAVs) rely on vision-based deep neural networks (DNNs) and low-latency (Vehicle-to-Everything) V2X communication to navigate safely and efficiently. Despite their advances, these systems remain vulnerable to physical adversarial attacks. In this paper, we introduce PHANTOM (PHysical ANamorphic Threats Obstructing connected vehicle Mobility), a novel framework for crafting and deploying perspective-dependent adversarial examples using \\textit{anamorphic art}. PHANTOM exploits geometric distortions that appear natural to humans but are misclassified with high confidence by state-of-the-art object detectors. Unlike conventional attacks, PHANTOM operates in black-box settings without model access and demonstrates strong transferability across four diverse detector architectures (YOLOv5, SSD, Faster R-CNN, and RetinaNet). Comprehensive evaluation in CARLA across varying speeds, weather conditions, and lighting scenarios shows that PHANTOM achieves over 90\\% attack success rate under optimal conditions and maintains 60-80\\% effectiveness even in degraded environments. The attack activates within 6-10 meters of the target, providing insufficient time for safe maneuvering. Beyond individual vehicle deception, PHANTOM triggers network-wide disruption in CAV systems: SUMO-OMNeT++ co-simulation demonstrates that false emergency messages propagate through V2X links, increasing Peak Age of Information by 68-89\\% and degrading safety-critical communication. These findings expose critical vulnerabilities in both perception and communication layers of CAV ecosystems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PHANTOMï¼Œä¸€ç§åˆ©ç”¨å˜å½¢è‰ºæœ¯(anamorphic art)æ„å»ºè§†ç‚¹ç›¸å…³å¯¹æŠ—æ ·æœ¬çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨æ­ç¤ºè”ç½‘è‡ªåŠ¨é©¾é©¶è½¦è¾†(CAV)é¢ä¸´çš„ç‰©ç†å®‰å…¨å¨èƒã€‚PHANTOMåˆ©ç”¨äººç±»æ„ŸçŸ¥è‡ªç„¶ä½†èƒ½å¼•èµ·å¯¹è±¡æ£€æµ‹å™¨è¯¯åˆ¤çš„å‡ ä½•ç•¸å˜ï¼Œåœ¨ä¸éœ€è¦æ¨¡å‹è®¿é—®æƒé™çš„é»‘ç›’è®¾ç½®ä¸‹è¿è¡Œï¼Œå¹¶åœ¨YOLOv5ã€SSDã€Faster R-CNNå’ŒRetinaNetç­‰å¤šç§æ¶æ„ä¸­å±•ç°å‡ºæ˜¾è‘—çš„å¯è¿ç§»æ€§ã€‚åœ¨CARLAä»¿çœŸç¯å¢ƒä¸‹çš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ”»å‡»åœ¨æœ€ä¼˜æ¡ä»¶ä¸‹æˆåŠŸç‡è¶…è¿‡90%ï¼Œä¸”åœ¨è·ç›®æ ‡6-10ç±³å†…å³å¯æ¿€æ´»ï¼Œä½¿è½¦è¾†ç¼ºä¹è¶³å¤Ÿçš„é¿è®©æ—¶é—´ã€‚ç ”ç©¶è¿›ä¸€æ­¥é€šè¿‡SUMO-OMNeT++è”åˆä»¿çœŸè¯æ˜ï¼ŒPHANTOMèƒ½è¯±å‘V2Xç½‘ç»œèŒƒå›´å†…çš„è¿é”å¹²æ‰°ï¼Œå¯¼è‡´è™šå‡ç´§æ€¥ä¿¡æ¯ä¼ æ’­å¹¶ä½¿ä¿¡æ¯å³°å€¼æ—¶é¾„(Peak Age of Information)å¢åŠ 68-89%ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†CAVç”Ÿæ€ç³»ç»Ÿåœ¨æ„ŸçŸ¥å±‚å’Œé€šä¿¡å±‚ä¸­å­˜åœ¨çš„å…³é”®æ¼æ´ï¼Œå¯¹å¼€å‘é«˜é²æ£’æ€§çš„è‡ªåŠ¨é©¾é©¶é˜²å¾¡æœºåˆ¶å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.19711v1",
      "published_date": "2025-12-15 06:05:38 UTC",
      "updated_date": "2025-12-15 06:05:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:03:32.859464+00:00"
    },
    {
      "arxiv_id": "2512.13751v1",
      "title": "MIDUS: Memory-Infused Depth Up-Scaling",
      "title_zh": "MIDUSï¼šèå…¥è®°å¿†æœºåˆ¶çš„æ·±åº¦å‘ä¸Šç¼©æ”¾",
      "authors": [
        "Taero Kim",
        "Hoyoon Byun",
        "Youngjun Choi",
        "Sungrae Park",
        "Kyungwoo Song"
      ],
      "abstract": "Scaling large language models (LLMs) demands approaches that increase capacity without incurring excessive parameter growth or inference cost. Depth Up-Scaling (DUS) has emerged as a promising strategy by duplicating layers and applying Continual Pre-training (CPT), but its reliance on feed-forward networks (FFNs) limits efficiency and attainable gains. We introduce Memory-Infused Depth Up-Scaling (MIDUS), which replaces FFNs in duplicated blocks with a head-wise memory (HML) layer. Motivated by observations that attention heads have distinct roles both across and within layers, MIDUS assigns an independent memory bank to each head, enabling head-wise retrieval and injecting information into subsequent layers while preserving head-wise functional structure. This design combines sparse memory access with head-wise representations and incorporates an efficient per-head value factorization module, thereby relaxing the usual efficiency-performance trade-off. Across our CPT experiments, MIDUS exhibits robust performance improvements over strong DUS baselines while maintaining a highly efficient parameter footprint. Our findings establish MIDUS as a compelling and resource-efficient alternative to conventional FFN replication for depth up-scaling by leveraging its head-wise memory design.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MIDUSï¼ˆMemory-Infused Depth Up-Scalingï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å®¹é‡ä¸”ä¸å¢åŠ è¿‡åº¦æ¨ç†æˆæœ¬çš„æ–°å‹æ·±åº¦æ‰©å±•æ–¹æ³•ã€‚é’ˆå¯¹ä¼ ç»Ÿæ·±åº¦ä¸Šé‡‡æ ·ï¼ˆDUSï¼‰ä¸­ç”±äºä¾èµ–å‰é¦ˆç½‘ç»œï¼ˆFFNsï¼‰è€Œå¯¼è‡´çš„æ•ˆç‡å±€é™ï¼ŒMIDUSé€šè¿‡åœ¨å¤åˆ¶çš„æ¨¡å—ä¸­å¼•å…¥é€å¤´å†…å­˜ï¼ˆHead-wise Memory, HMLï¼‰å±‚æ¥æ›¿ä»£ä¼ ç»Ÿçš„FFNsã€‚è¯¥æ¡†æ¶ä¸ºæ¯ä¸ªæ³¨æ„åŠ›å¤´åˆ†é…ç‹¬ç«‹çš„å­˜å‚¨åº“ï¼Œæ”¯æŒé€å¤´æ£€ç´¢å¹¶å°†ä¿¡æ¯æ³¨å…¥åç»­å±‚ï¼Œä»è€Œåœ¨æ‰©å±•æ·±åº¦çš„åŒæ—¶ä¿ç•™äº†å¤´éƒ¨çš„åŠŸèƒ½ç»“æ„ã€‚MIDUSç»“åˆäº†ç¨€ç–å†…å­˜è®¿é—®ä¸é€å¤´è¡¨ç¤ºï¼Œå¹¶é›†æˆäº†ä¸€ä¸ªé«˜æ•ˆçš„é€å¤´å€¼åˆ†è§£æ¨¡å—ï¼Œæœ‰æ•ˆç¼“è§£äº†æ•ˆç‡ä¸æ€§èƒ½ä¹‹é—´çš„æƒè¡¡éš¾é¢˜ã€‚åœ¨æŒç»­é¢„è®­ç»ƒï¼ˆCPTï¼‰å®éªŒä¸­ï¼ŒMIDUSåœ¨ä¿æŒæé«˜å‚æ•°æ•ˆç‡çš„åŒæ—¶ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºå¼ºDUSåŸºå‡†ã€‚è¿™é¡¹ç ”ç©¶è¯æ˜äº†é€å¤´å†…å­˜è®¾è®¡æ˜¯ä¼ ç»ŸFFNå¤åˆ¶æ–¹æ¡ˆçš„ä¸€ç§æ›´å…·èµ„æºæ•ˆç‡çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13751v1",
      "published_date": "2025-12-15 05:50:45 UTC",
      "updated_date": "2025-12-15 05:50:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:03:38.012762+00:00"
    },
    {
      "arxiv_id": "2512.12997v1",
      "title": "Calibrating Uncertainty for Zero-Shot Adversarial CLIP",
      "title_zh": "é¢å‘é›¶æ ·æœ¬å¯¹æŠ— CLIP çš„ä¸ç¡®å®šæ€§æ ¡å‡†",
      "authors": [
        "Wenjing lu",
        "Zerui Tao",
        "Dongping Zhang",
        "Yuning Qiu",
        "Yang Yang",
        "Qibin Zhao"
      ],
      "abstract": "CLIP delivers strong zero-shot classification but remains highly vulnerable to adversarial attacks. Previous work of adversarial fine-tuning largely focuses on matching the predicted logits between clean and adversarial examples, which overlooks uncertainty calibration and may degrade the zero-shot generalization. A common expectation in reliable uncertainty estimation is that predictive uncertainty should increase as inputs become more difficult or shift away from the training distribution. However, we frequently observe the opposite in the adversarial setting: perturbations not only degrade accuracy but also suppress uncertainty, leading to severe miscalibration and unreliable over-confidence. This overlooked phenomenon highlights a critical reliability gap beyond robustness. To bridge this gap, we propose a novel adversarial fine-tuning objective for CLIP considering both prediction accuracy and uncertainty alignments. By reparameterizing the output of CLIP as the concentration parameter of a Dirichlet distribution, we propose a unified representation that captures relative semantic structure and the magnitude of predictive confidence. Our objective aligns these distributions holistically under perturbations, moving beyond single-logit anchoring and restoring calibrated uncertainty. Experiments on multiple zero-shot classification benchmarks demonstrate that our approach effectively restores calibrated uncertainty and achieves competitive adversarial robustness while maintaining clean accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºCLIPåœ¨é›¶æ ·æœ¬(Zero-Shot)åˆ†ç±»ä¸­è™½è¡¨ç°å¼ºåŠ²ï¼Œä½†åœ¨é¢å¯¹å¯¹æŠ—æ€§æ”»å‡»(Adversarial Attacks)æ—¶ååˆ†è„†å¼±ï¼Œä¸”ç°æœ‰å¾®è°ƒæ–¹æ³•å› å¿½è§†ä¸ç¡®å®šæ€§æ ¡å‡†(Uncertainty Calibration)å¸¸å¯¼è‡´æ¨¡å‹åœ¨å¯¹æŠ—ç¯å¢ƒä¸‹è¡¨ç°å‡ºä¸å¯é çš„è¿‡åº¦è‡ªä¿¡ã€‚ä¸ºå¼¥åˆè¿™ä¸€å¯é æ€§å·®è·ï¼Œä½œè€…æå‡ºäº†ä¸€ç§å…¼é¡¾é¢„æµ‹å‡†ç¡®ç‡å’Œä¸ç¡®å®šæ€§å¯¹é½(Uncertainty Alignments)çš„æ–°å‹å¯¹æŠ—æ€§å¾®è°ƒç›®æ ‡ã€‚è¯¥æ–¹æ³•å°†CLIPçš„è¾“å‡ºé‡æ–°å‚æ•°åŒ–ä¸ºç‹„åˆ©å…‹é›·åˆ†å¸ƒ(Dirichlet Distribution)çš„æµ“åº¦å‚æ•°ï¼Œä»è€Œæ„å»ºå‡ºä¸€ä¸ªèƒ½å¤ŸåŒæ—¶æ•æ‰ç›¸å¯¹è¯­ä¹‰ç»“æ„å’Œé¢„æµ‹ç½®ä¿¡åº¦å¹…åº¦çš„ç»Ÿä¸€è¡¨ç¤ºã€‚é€šè¿‡åœ¨æ‰°åŠ¨ä¸‹æ•´ä½“å¯¹é½è¿™äº›åˆ†å¸ƒï¼Œè¯¥æ–¹æ¡ˆè¶…è¶Šäº†ä¼ ç»Ÿçš„å•å¯¹æ•°é”šå®š(Single-Logit Anchoring)æ¨¡å¼ï¼ŒæˆåŠŸæ¢å¤äº†æ ¡å‡†åçš„ä¸ç¡®å®šæ€§ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªé›¶æ ·æœ¬åˆ†ç±»åŸºå‡†ä¸Šæœ‰æ•ˆæå‡äº†ä¸ç¡®å®šæ€§æ ¡å‡†è´¨é‡ï¼Œå¹¶åœ¨ä¿æŒå¹²å‡€å‡†ç¡®ç‡(Clean Accuracy)çš„åŒæ—¶å®ç°äº†æå…·ç«äº‰åŠ›çš„å¯¹æŠ—é²æ£’æ€§(Adversarial Robustness)ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12997v1",
      "published_date": "2025-12-15 05:41:08 UTC",
      "updated_date": "2025-12-15 05:41:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:04:11.710718+00:00"
    },
    {
      "arxiv_id": "2512.13750v1",
      "title": "The algorithmic muse and the public domain: Why copyrights legal philosophy precludes protection for generative AI outputs",
      "title_zh": "ç®—æ³•ç¼ªæ–¯ä¸å…¬æœ‰é¢†åŸŸï¼šè®ºè‘—ä½œæƒæ³•å“²å­¦ä½•ä»¥å¦å®šç”Ÿæˆå¼äººå·¥æ™ºèƒ½è¾“å‡ºç‰©çš„æ³•å¾‹ä¿æŠ¤",
      "authors": [
        "Ezieddin Elmahjub"
      ],
      "abstract": "Generative AI (GenAI) outputs are not copyrightable. This article argues why. We bypass conventional doctrinal analysis that focuses on black letter law notions of originality and authorship to re-evaluate copyright's foundational philosophy. GenAI fundamentally severs the direct human creative link to expressive form. Traditional theories utilitarian incentive, labor desert and personality fail to provide coherent justification for protection. The public domain constitutes the default baseline for intellectual creations. Those seeking copyright coverage for GenAI outputs bear the burden of proof. Granting copyright to raw GenAI outputs would not only be philosophically unsound but would also trigger an unprecedented enclosure of the digital commons, creating a legal quagmire and stifling future innovation. The paper advocates for a clear distinction: human creative contributions to AI-generated works may warrant protection, but the raw algorithmic output should remain in the public domain.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) çš„è¾“å‡ºç»“æœä¸å…·å¤‡ç‰ˆæƒä¿æŠ¤æ€§çš„å“²å­¦æ ¹åŸºï¼Œåˆ†æäº†ä¸ºä»€ä¹ˆç‰ˆæƒæ³•æ³•å¾‹å“²å­¦æ’æ–¥å¯¹å…¶è¿›è¡Œä¿æŠ¤ã€‚æ–‡ç« ç»•è¿‡ä¼ ç»Ÿæ•™ä¹‰åˆ†æä¸­å…³äºåŸåˆ›æ€§ (originality) å’Œä½œè€…èº«ä»½ (authorship) çš„æ³•æ¡é™åˆ¶ï¼Œé‡æ–°è¯„ä¼°äº†ç‰ˆæƒæ³•çš„åº•å±‚å“²å­¦ã€‚ä½œè€…è®¤ä¸º Generative AI æ ¹æœ¬æ€§åœ°åˆ‡æ–­äº†äººç±»åˆ›æ„ä¸è¡¨è¾¾å½¢å¼ä¹‹é—´çš„ç›´æ¥è”ç³»ï¼Œå¯¼è‡´ä¼ ç»Ÿçš„åŠŸåˆ©ä¸»ä¹‰æ¿€åŠ±è®º (utilitarian incentive)ã€åŠ³åŠ¨æ‰€å¾—è®º (labor desert) å’Œäººæ ¼è®º (personality) å‡æ— æ³•ä¸ºå…¶æä¾›è¿è´¯çš„è¾©æŠ¤ã€‚è¯¥ç ”ç©¶å¼ºè°ƒå…¬æœ‰é¢†åŸŸ (public domain) æ˜¯æ™ºåŠ›æˆæœçš„é»˜è®¤åŸºå‡†ï¼Œä¸»å¼ å¯»æ±‚ Generative AI è¾“å‡ºç‰ˆæƒä¿æŠ¤çš„ä¸€æ–¹åº”æ‰¿æ‹…ä¸¾è¯è´£ä»»ã€‚è‹¥æˆäºˆåŸå§‹ç®—æ³•è¾“å‡ºç‰ˆæƒï¼Œä¸ä»…åœ¨å“²å­¦ä¸Šç«™ä¸ä½è„šï¼Œè¿˜ä¼šå¼•å‘æ•°å­—å…¬åœ° (digital commons) å‰æ‰€æœªæœ‰çš„å°é—­ï¼Œè¿›è€Œé€ æˆæ³•å¾‹å›°å¢ƒå¹¶æŠ‘åˆ¶æœªæ¥åˆ›æ–°ã€‚è®ºæ–‡æœ€åå€¡å¯¼æ˜ç¡®åŒºåˆ†äººç±»åœ¨ AI ç”Ÿæˆä½œå“ä¸­çš„åˆ›æ„è´¡çŒ®ä¸åŸå§‹ç®—æ³•è¾“å‡ºï¼Œå¹¶åšæŒè®¤ä¸ºåè€…åº”ä¿ç•™åœ¨å…¬æœ‰é¢†åŸŸä¸­ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "9 pages, two figures",
      "pdf_url": "https://arxiv.org/pdf/2512.13750v1",
      "published_date": "2025-12-15 05:39:30 UTC",
      "updated_date": "2025-12-15 05:39:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:04:23.394648+00:00"
    },
    {
      "arxiv_id": "2512.12987v1",
      "title": "Tackling Snow-Induced Challenges: Safe Autonomous Lane-Keeping with Robust Reinforcement Learning",
      "title_zh": "åº”å¯¹ç§¯é›ªæŒ‘æˆ˜ï¼šåŸºäºé²æ£’å¼ºåŒ–å­¦ä¹ çš„å®‰å…¨è‡ªä¸»è½¦é“ä¿æŒ",
      "authors": [
        "Amin Jalal Aghdasian",
        "Farzaneh Abdollahi",
        "Ali Kamali Iglie"
      ],
      "abstract": "This paper proposes two new algorithms for the lane keeping system (LKS) in autonomous vehicles (AVs) operating under snowy road conditions. These algorithms use deep reinforcement learning (DRL) to handle uncertainties and slippage. They include Action-Robust Recurrent Deep Deterministic Policy Gradient (AR-RDPG) and end-to-end Action-Robust convolutional neural network Attention Deterministic Policy Gradient (AR-CADPG), two action-robust approaches for decision-making. In the AR-RDPG method, within the perception layer, camera images are first denoised using multi-scale neural networks. Then, the centerline coefficients are extracted by a pre-trained deep convolutional neural network (DCNN). These coefficients, concatenated with the driving characteristics, are used as input to the control layer. The AR-CADPG method presents an end-to-end approach in which a convolutional neural network (CNN) and an attention mechanism are integrated within a DRL framework. Both methods are first trained in the CARLA simulator and validated under various snowy scenarios. Real-world experiments on a Jetson Nano-based autonomous vehicle confirm the feasibility and stability of the learned policies. Among the two models, the AR-CADPG approach demonstrates superior path-tracking accuracy and robustness, highlighting the effectiveness of combining temporal memory, adversarial resilience, and attention mechanisms in AVs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶æ±½è½¦(AVs)åœ¨é›ªåœ°è·¯é¢ä¸‹å› æ‰“æ»‘å’Œä¸ç¡®å®šæ€§å¯¼è‡´çš„è½¦é“ä¿æŒç³»ç»Ÿ(LKS)å¤±æ•ˆé—®é¢˜ï¼Œæå‡ºäº†AR-RDPGå’ŒAR-CADPGä¸¤ç§åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ (DRL)çš„é²æ£’æ€§ç®—æ³•ã€‚AR-RDPGæ–¹æ³•é€šè¿‡å¤šå°ºåº¦ç¥ç»ç½‘ç»œè¿›è¡Œå›¾åƒé™å™ªï¼Œå¹¶åˆ©ç”¨é¢„è®­ç»ƒçš„DCNNæå–ä¸­å¿ƒçº¿ç³»æ•°ä½œä¸ºæ§åˆ¶è¾“å…¥ï¼›è€ŒAR-CADPGåˆ™é‡‡ç”¨ç«¯åˆ°ç«¯æ¶æ„ï¼Œå°†å·ç§¯ç¥ç»ç½‘ç»œ(CNN)ä¸æ³¨æ„åŠ›æœºåˆ¶(attention mechanism)æ·±åº¦é›†æˆã€‚ç ”ç©¶å›¢é˜Ÿåœ¨CARLAæ¨¡æ‹Ÿå™¨ä¸­è¿›è¡Œäº†å¤šåœºæ™¯è®­ç»ƒä¸éªŒè¯ï¼Œå¹¶åœ¨åŸºäºJetson Nanoçš„ç¡¬ä»¶å¹³å°ä¸Šå®Œæˆäº†å®é™…ç‰©ç†å®éªŒï¼Œç¡®ä¿äº†ç­–ç•¥çš„å¯è¡Œæ€§ä¸ç¨³å®šæ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAR-CADPGåœ¨è·¯å¾„è·Ÿè¸ªç²¾åº¦å’Œé²æ£’æ€§æ–¹é¢è¡¨ç°æ›´ä¸ºå‡ºè‰²ï¼Œæœ‰æ•ˆè¯æ˜äº†ç»“åˆæ—¶åºè®°å¿†ã€å¯¹æŠ—éŸ§æ€§ä¸æ³¨æ„åŠ›æœºåˆ¶åœ¨åº”å¯¹æ¶åŠ£å¤©æ°”æŒ‘æˆ˜æ—¶çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12987v1",
      "published_date": "2025-12-15 05:23:23 UTC",
      "updated_date": "2025-12-15 05:23:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:03:58.171682+00:00"
    },
    {
      "arxiv_id": "2512.13749v1",
      "title": "Comparative Evaluation of Embedding Representations for Financial News Sentiment Analysis",
      "title_zh": "é¢å‘é‡‘èæ–°é—»æƒ…æ„Ÿåˆ†æçš„åµŒå…¥è¡¨ç¤ºå¯¹æ¯”è¯„ä¼°",
      "authors": [
        "Joyjit Roy",
        "Samaresh Kumar Singh"
      ],
      "abstract": "Financial sentiment analysis enhances market understanding; however, standard natural language processing approaches encounter significant challenges when applied to small datasets. This study provides a comparative evaluation of embedding-based methods for financial news sentiment classification in resource-constrained environments. Word2Vec, GloVe, and sentence transformer representations are evaluated in combination with gradient boosting on manually labeled headlines. Experimental results identify a substantial gap between validation and test performance, with models performing worse than trivial baselines despite strong validation metrics. The analysis demonstrates that pretrained embeddings yield diminishing returns below a critical data sufficiency threshold, and that small validation sets contribute to overfitting during model selection. Practical application is illustrated through weekly sentiment aggregation and narrative summarization for market monitoring workflows. The findings offer empirical evidence that embedding quality alone cannot address fundamental data scarcity in sentiment classification. For practitioners operating with limited resources, the results indicate the need to consider alternative approaches such as few-shot learning, data augmentation, or lexicon-enhanced hybrid methods when labeled samples are scarce.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶å¯¹èµ„æºå—é™ç¯å¢ƒä¸‹é‡‘èæ–°é—»æƒ…æ„Ÿåˆ†ç±»çš„ Embedding è¡¨ç¤ºæ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒè¯„ä¼°ï¼Œæ¢è®¨äº†æ ‡å‡†è‡ªç„¶è¯­è¨€å¤„ç†æ–¹æ³•åœ¨å¤„ç†å°æ•°æ®é›†æ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚ç ”ç©¶äººå‘˜ç»“åˆ Gradient Boosting ç®—æ³•ï¼Œå¯¹æ¯”äº† Word2Vecã€GloVe ä»¥åŠ Sentence Transformer ç­‰åµŒå…¥æ¨¡å‹åœ¨æ‰‹åŠ¨æ ‡æ³¨æ ‡é¢˜ä¸Šçš„è¡¨ç°ã€‚å®éªŒç»“æœæ­ç¤ºäº†éªŒè¯é›†ä¸æµ‹è¯•é›†æ€§èƒ½ä¹‹é—´çš„æ˜¾è‘—å·®è·ï¼Œè¯æ˜åœ¨æ•°æ®é‡ä½äºä¸´ç•Œé˜ˆå€¼æ—¶ï¼Œé¢„è®­ç»ƒ Embedding çš„æ”¶ç›Šä¼šå¤§å¹…é€’å‡ï¼Œä¸”å°è§„æ¨¡éªŒè¯é›†ææ˜“å¯¼è‡´è¿‡æ‹Ÿåˆã€‚ç ”ç©¶å¼ºè°ƒï¼Œå•çº¯ä¾é æå‡ Embedding è´¨é‡æ— æ³•è§£å†³åŸºç¡€çš„æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚æœ€åï¼Œé’ˆå¯¹æ ·æœ¬ç¨€ç¼ºçš„å®é™…åº”ç”¨åœºæ™¯ï¼Œè¯¥ç ”ç©¶å»ºè®®ä»ä¸šè€…é‡‡ç”¨ Few-shot Learningã€æ•°æ®å¢å¼ºæˆ–è¯å…¸å¢å¼ºçš„æ··åˆæ–¹æ³•ä½œä¸ºæ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.CY",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 2 figures. Submitted to IEEE IATMSI-2026 (Track: AI, IoT and Computer Vision Enabled Technologies)",
      "pdf_url": "https://arxiv.org/pdf/2512.13749v1",
      "published_date": "2025-12-15 04:52:30 UTC",
      "updated_date": "2025-12-15 04:52:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:03:55.248012+00:00"
    },
    {
      "arxiv_id": "2512.12970v1",
      "title": "Towards Open Standards for Systemic Complexity in Digital Forensics",
      "title_zh": "è¿ˆå‘æ•°å­—å–è¯ç³»ç»Ÿå¤æ‚æ€§çš„å¼€æ”¾æ ‡å‡†",
      "authors": [
        "Paola Di Maio"
      ],
      "abstract": "The intersection of artificial intelligence (AI) and digital forensics (DF) is becoming increasingly complex, ubiquitous, and pervasive, with overlapping techniques and technologies being adopted in all types of scientific and technical inquiry. Despite incredible advances, forensic sciences are not exempt from errors and remain vulnerable to fallibility. To mitigate the limitations of errors in DF, the systemic complexity is identified and addressed with the adoption of human-readable artifacts and open standards. A DF AI model schema based on the state of the art is outlined.",
      "tldr_zh": "éšç€äººå·¥æ™ºèƒ½ (AI) ä¸æ•°å­—å–è¯ (Digital Forensics, DF) çš„äº¤å‰èåˆæ—¥ç›Šå¤æ‚ä¸”æ™®éï¼Œå°½ç®¡æŠ€æœ¯ä¸æ–­è¿›æ­¥ï¼Œå–è¯ç§‘å­¦åœ¨é¢å¯¹å¤æ‚ç³»ç»Ÿæ—¶ä»å­˜åœ¨æ˜“é”™æ€§å’Œå±€é™æ€§ã€‚ä¸ºäº†æœ‰æ•ˆç¼“è§£æ•°å­—å–è¯ä¸­çš„é”™è¯¯é£é™©ï¼Œè¯¥ç ”ç©¶è¯†åˆ«å¹¶æ¢è®¨äº†ç³»ç»Ÿå¤æ‚æ€§ (Systemic Complexity) å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œå¹¶æå€¡é€šè¿‡é‡‡ç”¨äººç±»å¯è¯»çš„å·¥ä»¶ (Human-readable Artifacts) å’Œå¼€æ”¾æ ‡å‡† (Open Standards) æ¥åº”å¯¹è¿™äº›é—®é¢˜ã€‚åŸºäºå½“å‰çš„æŠ€æœ¯å‰æ²¿ï¼Œæ–‡ä¸­æå‡ºå¹¶æ¦‚è¿°äº†ä¸€ç§æ•°å­—å–è¯ AI æ¨¡å‹æ¶æ„ (DF AI model schema)ã€‚è¯¥ç ”ç©¶ä¸ºæ„å»ºæ›´åŠ é€æ˜ã€è§„èŒƒçš„å–è¯æµç¨‹æä¾›äº†ç†è®ºæ¡†æ¶ï¼Œæ—¨åœ¨æå‡æ•°å­—è°ƒæŸ¥åœ¨å¤æ‚æŠ€æœ¯ç¯å¢ƒä¸‹çš„å¯é æ€§ä¸ç§‘å­¦æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12970v1",
      "published_date": "2025-12-15 04:18:56 UTC",
      "updated_date": "2025-12-15 04:18:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:04:12.341256+00:00"
    },
    {
      "arxiv_id": "2512.12950v1",
      "title": "Building from Scratch: A Multi-Agent Framework with Human-in-the-Loop for Multilingual Legal Terminology Mapping",
      "title_zh": "ä»é›¶å¼€å§‹ï¼šé¢å‘å¤šè¯­è¨€æ³•å¾‹æœ¯è¯­æ˜ å°„çš„äººæœºåœ¨ç¯å¤šæ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Lingyi Meng",
        "Maolin Liu",
        "Hao Wang",
        "Yilan Cheng",
        "Qi Yang",
        "Idlkaid Mohanmmed"
      ],
      "abstract": "Accurately mapping legal terminology across languages remains a significant challenge, especially for language pairs like Chinese and Japanese, which share a large number of homographs with different meanings. Existing resources and standardized tools for these languages are limited. To address this, we propose a human-AI collaborative approach for building a multilingual legal terminology database, based on a multi-agent framework. This approach integrates advanced large language models and legal domain experts throughout the entire process-from raw document preprocessing, article-level alignment, to terminology extraction, mapping, and quality assurance. Unlike a single automated pipeline, our approach places greater emphasis on how human experts participate in this multi-agent system. Humans and AI agents take on different roles: AI agents handle specific, repetitive tasks, such as OCR, text segmentation, semantic alignment, and initial terminology extraction, while human experts provide crucial oversight, review, and supervise the outputs with contextual knowledge and legal judgment. We tested the effectiveness of this framework using a trilingual parallel corpus comprising 35 key Chinese statutes, along with their English and Japanese translations. The experimental results show that this human-in-the-loop, multi-agent workflow not only improves the precision and consistency of multilingual legal terminology mapping but also offers greater scalability compared to traditional manual methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé›†æˆäº†äººåœ¨å›è·¯(Human-in-the-Loop)çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶(Multi-Agent Framework)ï¼Œæ—¨åœ¨è§£å†³ä¸­æ—¥æ³•å¾‹æœ¯è¯­æ˜ å°„ä¸­å› å¤§é‡åŒå½¢å¼‚ä¹‰è¯å¯¼è‡´çš„ç²¾ç¡®åº¦æŒ‘æˆ˜åŠç›¸å…³èµ„æºåŒ®ä¹é—®é¢˜ã€‚è¯¥æ¡†æ¶æ„å»ºäº†ä¸€ä¸ªäººæœºåä½œ(Human-AI collaborative)ç³»ç»Ÿï¼Œå°†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä¸æ³•å¾‹ä¸“å®¶ç»“åˆï¼Œæ¶µç›–äº†ä»åŸå§‹æ–‡æ¡£é¢„å¤„ç†ã€æ¡æ–‡å¯¹é½åˆ°æœ¯è¯­æ˜ å°„ä¸è´¨é‡ä¿è¯çš„å…¨æµç¨‹ã€‚ç³»ç»Ÿä¸­ï¼ŒAIæ™ºèƒ½ä½“è´Ÿè´£å¤„ç†OCRã€æ–‡æœ¬åˆ†å‰²å’Œè¯­ä¹‰å¯¹é½ç­‰é‡å¤æ€§ä»»åŠ¡ï¼Œè€Œäººç±»ä¸“å®¶åˆ™åˆ©ç”¨ä¸“ä¸šæ³•å¾‹èƒŒæ™¯çŸ¥è¯†è¿›è¡Œå…³é”®çš„ç›‘ç£ä¸å®¡æ ¸ã€‚é€šè¿‡å¯¹åŒ…å«35éƒ¨ä¸­å›½æ³•å¾‹çš„ä¸­è‹±æ—¥ä¸‰è¯­å¹³è¡Œè¯­æ–™åº“è¿›è¡Œå®éªŒï¼Œç»“æœè¯æ˜è¯¥å·¥ä½œæµåœ¨æ˜¾è‘—æå‡æœ¯è¯­æ˜ å°„ç²¾åº¦å’Œä¸€è‡´æ€§çš„åŒæ—¶ï¼Œå±•ç°å‡ºäº†ä¼˜äºä¼ ç»Ÿäººå·¥æ–¹æ³•çš„å¯æ‰©å±•æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "43 pages, 6 fingures, accepted in Artificial Intelligence and Law (2025)",
      "pdf_url": "https://arxiv.org/pdf/2512.12950v1",
      "published_date": "2025-12-15 03:29:21 UTC",
      "updated_date": "2025-12-15 03:29:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:04:54.231490+00:00"
    },
    {
      "arxiv_id": "2512.17946v1",
      "title": "Let the Model Learn to Feel: Mode-Guided Tonality Injection for Symbolic Music Emotion Recognition",
      "title_zh": "è®©æ¨¡å‹å­¦ä¼šâ€œæ„Ÿå—â€ï¼šé¢å‘ç¬¦å·éŸ³ä¹æƒ…æ„Ÿè¯†åˆ«çš„è°ƒå¼å¼•å¯¼è°ƒæ€§æ³¨å…¥",
      "authors": [
        "Haiying Xia",
        "Zhongyi Huang",
        "Yumei Tan",
        "Shuxiang Song"
      ],
      "abstract": "Music emotion recognition is a key task in symbolic music understanding (SMER). Recent approaches have shown promising results by fine-tuning large-scale pre-trained models (e.g., MIDIBERT, a benchmark in symbolic music understanding) to map musical semantics to emotional labels. While these models effectively capture distributional musical semantics, they often overlook tonal structures, particularly musical modes, which play a critical role in emotional perception according to music psychology. In this paper, we investigate the representational capacity of MIDIBERT and identify its limitations in capturing mode-emotion associations. To address this issue, we propose a Mode-Guided Enhancement (MoGE) strategy that incorporates psychological insights on mode into the model. Specifically, we first conduct a mode augmentation analysis, which reveals that MIDIBERT fails to effectively encode emotion-mode correlations. We then identify the least emotion-relevant layer within MIDIBERT and introduce a Mode-guided Feature-wise linear modulation injection (MoFi) framework to inject explicit mode features, thereby enhancing the model's capability in emotional representation and inference. Extensive experiments on the EMOPIA and VGMIDI datasets demonstrate that our mode injection strategy significantly improves SMER performance, achieving accuracies of 75.2% and 59.1%, respectively. These results validate the effectiveness of mode-guided modeling in symbolic music emotion recognition.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¬¦å·éŸ³ä¹æƒ…æ„Ÿè¯†åˆ«(SMER)ä»»åŠ¡ä¸­é¢„è®­ç»ƒæ¨¡å‹å¿½è§†è°ƒæ€§ç»“æ„çš„é—®é¢˜ï¼Œæå‡ºäº†è°ƒå¼å¼•å¯¼å¢å¼º(MoGE)ç­–ç•¥ã€‚é€šè¿‡åˆ†æå‘ç°MIDIBERTåœ¨æ•æ‰éŸ³ä¹è°ƒå¼(Modes)ä¸æƒ…æ„Ÿå…³è”æ–¹é¢å­˜åœ¨å±€é™ï¼Œç ”ç©¶è€…æ®æ­¤è¯†åˆ«å‡ºæ¨¡å‹ä¸­æƒ…æ„Ÿç›¸å…³åº¦æœ€ä½çš„å±‚ï¼Œå¹¶å¼•å…¥äº†è°ƒå¼å¼•å¯¼çš„ç‰¹å¾çº§çº¿æ€§è°ƒåˆ¶æ³¨å…¥(MoFi)æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å‘æ¨¡å‹æ³¨å…¥æ˜¾å¼çš„è°ƒå¼ç‰¹å¾ï¼Œæ˜¾è‘—å¢å¼ºäº†ç³»ç»Ÿåœ¨æƒ…æ„Ÿè¡¨ç¤ºä¸æ¨ç†æ–¹é¢çš„èƒ½åŠ›ã€‚åœ¨EMOPIAå’ŒVGMIDIæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥è°ƒå¼æ³¨å…¥ç­–ç•¥æ˜¾è‘—æå‡äº†è¯†åˆ«æ€§èƒ½ï¼Œå‡†ç¡®ç‡åˆ†åˆ«è¾¾åˆ°75.2%å’Œ59.1%ã€‚ç ”ç©¶ç»“æœå……åˆ†éªŒè¯äº†å°†éŸ³ä¹å¿ƒç†å­¦ä¸­çš„è°ƒå¼è§è§£å¼•å…¥SMERå»ºæ¨¡çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.17946v1",
      "published_date": "2025-12-15 03:27:35 UTC",
      "updated_date": "2025-12-15 03:27:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:04:49.787989+00:00"
    },
    {
      "arxiv_id": "2512.13747v1",
      "title": "Why Text Prevails: Vision May Undermine Multimodal Medical Decision Making",
      "title_zh": "æ–‡æœ¬ä½•ä»¥èƒœå‡ºï¼šè§†è§‰ä¿¡æ¯æˆ–å‰Šå¼±å¤šæ¨¡æ€åŒ»ç–—å†³ç­–",
      "authors": [
        "Siyuan Dai",
        "Lunxiao Li",
        "Kun Zhao",
        "Eardi Lila",
        "Paul K. Crane",
        "Heng Huang",
        "Dongkuan Xu",
        "Haoteng Tang",
        "Liang Zhan"
      ],
      "abstract": "With the rapid progress of large language models (LLMs), advanced multimodal large language models (MLLMs) have demonstrated impressive zero-shot capabilities on vision-language tasks. In the biomedical domain, however, even state-of-the-art MLLMs struggle with basic Medical Decision Making (MDM) tasks. We investigate this limitation using two challenging datasets: (1) three-stage Alzheimer's disease (AD) classification (normal, mild cognitive impairment, dementia), where category differences are visually subtle, and (2) MIMIC-CXR chest radiograph classification with 14 non-mutually exclusive conditions. Our empirical study shows that text-only reasoning consistently outperforms vision-only or vision-text settings, with multimodal inputs often performing worse than text alone. To mitigate this, we explore three strategies: (1) in-context learning with reason-annotated exemplars, (2) vision captioning followed by text-only inference, and (3) few-shot fine-tuning of the vision tower with classification supervision. These findings reveal that current MLLMs lack grounded visual understanding and point to promising directions for improving multimodal decision making in healthcare.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) åœ¨åŒ»ç–—å†³ç­– (Medical Decision Making) ä»»åŠ¡ä¸­çš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨é˜¿å°”èŒ¨æµ·é»˜ç—… (Alzheimer's disease) ä¸‰é˜¶æ®µåˆ†ç±»å’Œ MIMIC-CXR èƒ¸éƒ¨å½±åƒåˆ†ç±»ä¸¤ä¸ªæŒ‘æˆ˜æ€§æ•°æ®é›†ä¸Šçš„è¡¨ç°ã€‚å®è¯ç ”ç©¶å‘ç°ï¼Œçº¯æ–‡æœ¬æ¨ç†çš„æ•ˆæœå§‹ç»ˆä¼˜äºè§†è§‰æˆ–å¤šæ¨¡æ€è¾“å…¥ï¼Œè¡¨æ˜è§†è§‰ä¿¡æ¯åœ¨æŸäº›åŒ»ç–—åœºæ™¯ä¸‹åè€Œå¯èƒ½å¹²æ‰°æ¨¡å‹åˆ¤æ–­ã€‚ä¸ºæ”¹å–„è¿™ä¸€ç°è±¡ï¼Œä½œè€…ç ”ç©¶äº†å¸¦æ¨ç†è·¯å¾„çš„è¯­å¢ƒå­¦ä¹  (in-context learning)ã€è§†è§‰è½¬æè¿°æ¨ç†ä»¥åŠå¯¹è§†è§‰ç¼–ç å™¨è¿›è¡Œå¾®è°ƒ (fine-tuning) ç­‰ç­–ç•¥ã€‚ç ”ç©¶ç»“æœæŒ‡å‡ºå½“å‰ MLLMs ç¼ºä¹æ·±å…¥çš„è§†è§‰ç†è§£èƒ½åŠ› (grounded visual understanding)ï¼Œå¹¶ä¸ºæœªæ¥åŒ»ç–—é¢†åŸŸå¤šæ¨¡æ€æ¨¡å‹çš„å‘å±•æŒ‡æ˜äº†ä¼˜åŒ–æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICDM 2025 the Workshop on Synergy of AI and Multimodal Biomedical Data Mining",
      "pdf_url": "https://arxiv.org/pdf/2512.13747v1",
      "published_date": "2025-12-15 03:09:31 UTC",
      "updated_date": "2025-12-15 03:09:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:05:08.377850+00:00"
    },
    {
      "arxiv_id": "2512.14754v1",
      "title": "Revisiting the Reliability of Language Models in Instruction-Following",
      "title_zh": "é‡æ–°å®¡è§†è¯­è¨€æ¨¡å‹åœ¨æŒ‡ä»¤éµå¾ªä¸­çš„å¯é æ€§",
      "authors": [
        "Jianshuo Dong",
        "Yutong Zhang",
        "Yan Liu",
        "Zhenyu Zhong",
        "Tao Wei",
        "Chao Zhang",
        "Han Qiu"
      ],
      "abstract": "Advanced LLMs have achieved near-ceiling instruction-following accuracy on benchmarks such as IFEval. However, these impressive scores do not necessarily translate to reliable services in real-world use, where users often vary their phrasing, contextual framing, and task formulations. In this paper, we study nuance-oriented reliability: whether models exhibit consistent competence across cousin prompts that convey analogous user intents but with subtle nuances. To quantify this, we introduce a new metric, reliable@k, and develop an automated pipeline that generates high-quality cousin prompts via data augmentation. Building upon this, we construct IFEval++ for systematic evaluation. Across 20 proprietary and 26 open-source LLMs, we find that current models exhibit substantial insufficiency in nuance-oriented reliability -- their performance can drop by up to 61.8% with nuanced prompt modifications. What's more, we characterize it and explore three potential improvement recipes. Our findings highlight nuance-oriented reliability as a crucial yet underexplored next step toward more dependable and trustworthy LLM behavior. Our code and benchmark are accessible: https://github.com/jianshuod/IFEval-pp.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨éµå¾ªæŒ‡ä»¤æ–¹é¢çš„å¯é æ€§é—®é¢˜ï¼Œé‡ç‚¹å…³æ³¨æ¨¡å‹åœ¨è¡¨è¿°å¾®è°ƒæ—¶çš„è¡¨ç°ä¸€è‡´æ€§ï¼Œå³nuance-oriented reliabilityã€‚ä½œè€…æŒ‡å‡ºï¼Œè™½ç„¶å…ˆè¿›æ¨¡å‹åœ¨IFEvalç­‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨é¢å¯¹è¡¨è¿°ç•¥æœ‰å·®å¼‚çš„ç±»ä¼¼æç¤ºè¯(cousin prompts)æ—¶ï¼Œå…¶å®é™…å¯é æ€§å¾€å¾€ä¸è¶³ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å¼•å…¥äº†æ–°çš„åº¦é‡æŒ‡æ ‡reliable@kï¼Œå¹¶æ„å»ºäº†IFEval++åŸºå‡†ï¼Œé€šè¿‡è‡ªåŠ¨åŒ–æ•°æ®å¢å¼ºæŠ€æœ¯ç”Ÿæˆé«˜è´¨é‡æµ‹è¯•ç”¨ä¾‹ã€‚å¯¹46ä¸ªä¸»æµå¼€æºå’Œé—­æºæ¨¡å‹çš„è¯„ä¼°å‘ç°ï¼Œå¾®å°çš„æç¤ºè¯ä¿®æ”¹ä¼šå¯¼è‡´æ¨¡å‹æ€§èƒ½æœ€é«˜ä¸‹é™61.8%ï¼Œæ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨å¤„ç†è¯­ä¹‰ç»†å¾®å·®åˆ«æ—¶çš„è„†å¼±æ€§ã€‚ç ”ç©¶æœ€åæå‡ºäº†ä¸‰ç§æ”¹è¿›ç­–ç•¥ï¼Œæ—¨åœ¨å¼•å¯¼æœªæ¥å¼€å‘æ›´å…·å¯é æ€§å’Œå¯ä¿¡åº¦çš„LLMç³»ç»Ÿã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2512.14754v1",
      "published_date": "2025-12-15 02:57:55 UTC",
      "updated_date": "2025-12-15 02:57:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:05:09.253251+00:00"
    },
    {
      "arxiv_id": "2512.12936v1",
      "title": "Content Adaptive based Motion Alignment Framework for Learned Video Compression",
      "title_zh": "é¢å‘å­¦ä¹ å‹è§†é¢‘å‹ç¼©çš„åŸºäºå†…å®¹è‡ªé€‚åº”è¿åŠ¨å¯¹é½æ¡†æ¶",
      "authors": [
        "Tiange Zhang",
        "Xiandong Meng",
        "Siwei Ma"
      ],
      "abstract": "Recent advances in end-to-end video compression have shown promising results owing to their unified end-to-end learning optimization. However, such generalized frameworks often lack content-specific adaptation, leading to suboptimal compression performance. To address this, this paper proposes a content adaptive based motion alignment framework that improves performance by adapting encoding strategies to diverse content characteristics. Specifically, we first introduce a two-stage flow-guided deformable warping mechanism that refines motion compensation with coarse-to-fine offset prediction and mask modulation, enabling precise feature alignment. Second, we propose a multi-reference quality aware strategy that adjusts distortion weights based on reference quality, and applies it to hierarchical training to reduce error propagation. Third, we integrate a training-free module that downsamples frames by motion magnitude and resolution to obtain smooth motion estimation. Experimental results on standard test datasets demonstrate that our framework CAMA achieves significant improvements over state-of-the-art Neural Video Compression models, achieving a 24.95% BD-rate (PSNR) savings over our baseline model DCVC-TCM, while also outperforming reproduced DCVC-DC and traditional codec HM-16.25.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç«¯åˆ°ç«¯è§†é¢‘å‹ç¼©æ¡†æ¶åœ¨å¤„ç†å¤šæ ·åŒ–å†…å®¹æ—¶ç¼ºä¹å†…å®¹è‡ªé€‚åº”æ€§ï¼ˆContent-specific Adaptationï¼‰å¯¼è‡´æ€§èƒ½å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†åŸºäºå†…å®¹è‡ªé€‚åº”çš„è¿åŠ¨å¯¹é½æ¡†æ¶ï¼ˆCAMAï¼‰ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸¤é˜¶æ®µæµå¼•å¯¼å¯å˜å½¢å¯¹é½æœºåˆ¶ï¼ˆTwo-stage Flow-guided Deformable Warpingï¼‰ï¼Œåˆ©ç”¨ç²—åˆ°ç»†çš„åç§»é¢„æµ‹å’Œæ©ç è°ƒåˆ¶å®ç°ç²¾ç¡®çš„ç‰¹å¾å¯¹é½ã€‚åŒæ—¶ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§å¤šå‚è€ƒè´¨é‡æ„ŸçŸ¥ç­–ç•¥ï¼ˆMulti-reference Quality Aware Strategyï¼‰ï¼Œé€šè¿‡æ ¹æ®å‚è€ƒå¸§è´¨é‡è°ƒæ•´å¤±çœŸæƒé‡å¹¶ç»“åˆåˆ†å±‚è®­ç»ƒæ¥æœ‰æ•ˆå‡å°‘è¯¯å·®ä¼ æ’­ã€‚æ­¤å¤–ï¼ŒCAMA é›†æˆäº†ä¸€ä¸ªæ— éœ€è®­ç»ƒçš„æ¨¡å—ï¼Œèƒ½æ ¹æ®è¿åŠ¨å¹…åº¦å’Œåˆ†è¾¨ç‡å¯¹å¸§è¿›è¡Œä¸‹é‡‡æ ·ä»¥è·å¾—å¹³æ»‘çš„è¿åŠ¨ä¼°è®¡ï¼ˆMotion Estimationï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šç›¸æ¯”åŸºå‡†æ¨¡å‹ DCVC-TCM å®ç°äº† 24.95% çš„ BD-rate èŠ‚çœï¼Œæ€§èƒ½ä¼˜äºå¤ç°çš„ DCVC-DC å’Œä¼ ç»Ÿç¼–ç å™¨ HM-16.25ï¼Œåœ¨ç¥ç»è§†é¢‘å‹ç¼©ï¼ˆNeural Video Compressionï¼‰é¢†åŸŸè¡¨ç°å‡ºè‰²ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to Data Compression Conference (DCC) 2026 as a poster paper",
      "pdf_url": "https://arxiv.org/pdf/2512.12936v1",
      "published_date": "2025-12-15 02:51:47 UTC",
      "updated_date": "2025-12-15 02:51:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:05:06.344319+00:00"
    },
    {
      "arxiv_id": "2512.12935v1",
      "title": "Unified Interactive Multimodal Moment Retrieval via Cascaded Embedding-Reranking and Temporal-Aware Score Fusion",
      "title_zh": "åŸºäºçº§è”åµŒå…¥é‡æ’åºä¸æ—¶åºæ„ŸçŸ¥åˆ†æ•°èåˆçš„ç»Ÿä¸€äº¤äº’å¼å¤šæ¨¡æ€æ—¶åˆ»æ£€ç´¢",
      "authors": [
        "Toan Le Ngo Thanh",
        "Phat Ha Huu",
        "Tan Nguyen Dang Duy",
        "Thong Nguyen Le Minh",
        "Anh Nguyen Nhu Tinh"
      ],
      "abstract": "The exponential growth of video content has created an urgent need for efficient multimodal moment retrieval systems. However, existing approaches face three critical challenges: (1) fixed-weight fusion strategies fail across cross modal noise and ambiguous queries, (2) temporal modeling struggles to capture coherent event sequences while penalizing unrealistic gaps, and (3) systems require manual modality selection, reducing usability. We propose a unified multimodal moment retrieval system with three key innovations. First, a cascaded dual-embedding pipeline combines BEIT-3 and SigLIP for broad retrieval, refined by BLIP-2 based reranking to balance recall and precision. Second, a temporal-aware scoring mechanism applies exponential decay penalties to large temporal gaps via beam search, constructing coherent event sequences rather than isolated frames. Third, Agent-guided query decomposition (GPT-4o) automatically interprets ambiguous queries, decomposes them into modality specific sub-queries (visual/OCR/ASR), and performs adaptive score fusion eliminating manual modality selection. Qualitative analysis demonstrates that our system effectively handles ambiguous queries, retrieves temporally coherent sequences, and dynamically adapts fusion strategies, advancing interactive moment search capabilities.",
      "tldr_zh": "é’ˆå¯¹è§†é¢‘å†…å®¹å¿«é€Ÿå¢é•¿å¸¦æ¥çš„å¤šæ¨¡æ€ç‰‡æ®µæ£€ç´¢æŒ‘æˆ˜ï¼Œè¯¥ç ”ç©¶åˆ†æäº†å›ºå®šæƒé‡èåˆã€æ—¶é—´å»ºæ¨¡å›°éš¾åŠæ‰‹åŠ¨æ¨¡æ€é€‰æ‹©ç­‰ç°æœ‰å±€é™ã€‚è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„äº¤äº’å¼å¤šæ¨¡æ€ç‰‡æ®µæ£€ç´¢ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒåˆ›æ–°ä¹‹ä¸€æ˜¯é‡‡ç”¨çº§è”åŒåµŒå…¥æµæ°´çº¿ï¼Œç»“åˆ BEIT-3 å’Œ SigLIP è¿›è¡Œå¹¿æ³›æ£€ç´¢ï¼Œå¹¶åˆ©ç”¨åŸºäº BLIP-2 çš„é‡æ’åºï¼ˆrerankingï¼‰æ¥å¹³è¡¡å¬å›ç‡ä¸ç²¾ç¡®åº¦ã€‚é’ˆå¯¹æ—¶é—´å»ºæ¨¡ï¼Œè¯¥ç³»ç»Ÿå¼•å…¥äº†æ—¶é—´æ„ŸçŸ¥è¯„åˆ†æœºåˆ¶ï¼ˆtemporal-aware scoring mechanismï¼‰ï¼Œé€šè¿‡æŸæœç´¢ï¼ˆbeam searchï¼‰å¯¹è¾ƒå¤§çš„æ—¶é—´é—´éš”æ–½åŠ æŒ‡æ•°è¡°å‡æƒ©ç½šï¼Œä»è€Œæ„å»ºè¿è´¯çš„äº‹ä»¶åºåˆ—è€Œéå­¤ç«‹å¸§ã€‚æ­¤å¤–ï¼Œç³»ç»Ÿåˆ©ç”¨åŸºäºæ™ºèƒ½ä½“ï¼ˆAgentï¼‰å¼•å¯¼çš„æŸ¥è¯¢åˆ†è§£æŠ€æœ¯ï¼ˆGPT-4oï¼‰ï¼Œèƒ½å¤Ÿè‡ªåŠ¨è§£ææ­§ä¹‰æŸ¥è¯¢å¹¶åˆ†è§£ä¸ºç‰¹å®šæ¨¡æ€çš„å­æŸ¥è¯¢ï¼ˆå¦‚ visual/OCR/ASRï¼‰ï¼Œå®ç°è‡ªé€‚åº”åˆ†æ•°èåˆï¼Œæ¶ˆé™¤äº†å¯¹æ‰‹åŠ¨æ¨¡æ€é€‰æ‹©çš„ä¾èµ–ã€‚å®šæ€§åˆ†æè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿèƒ½æœ‰æ•ˆå¤„ç†æ¨¡ç³ŠæŸ¥è¯¢ï¼Œæ£€ç´¢å‡ºæ—¶é—´è¿è´¯çš„åºåˆ—ï¼Œå¹¶é€šè¿‡åŠ¨æ€è°ƒæ•´èåˆç­–ç•¥æ˜¾è‘—æå‡äº†äº¤äº’å¼ç‰‡æ®µæœç´¢çš„èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at AAAI Workshop 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.12935v1",
      "published_date": "2025-12-15 02:50:43 UTC",
      "updated_date": "2025-12-15 02:50:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:05:24.472413+00:00"
    },
    {
      "arxiv_id": "2512.12932v1",
      "title": "Investigating Data Pruning for Pretraining Biological Foundation Models at Scale",
      "title_zh": "å¤§è§„æ¨¡ç”Ÿç‰©åŸºç¡€æ¨¡å‹é¢„è®­ç»ƒä¸­çš„æ•°æ®å‰ªæç ”ç©¶",
      "authors": [
        "Yifan Wu",
        "Jiyue Jiang",
        "Xichen Ye",
        "Yiqi Wang",
        "Chang Zhou",
        "Yitao Xu",
        "Jiayang Chen",
        "He Hu",
        "Weizhong Zhang",
        "Cheng Jin",
        "Jiao Yuan",
        "Yu Li"
      ],
      "abstract": "Biological foundation models (BioFMs), pretrained on large-scale biological sequences, have recently shown strong potential in providing meaningful representations for diverse downstream bioinformatics tasks. However, such models often rely on millions to billions of training sequences and billions of parameters, resulting in prohibitive computational costs and significant barriers to reproducibility and accessibility, particularly for academic labs. To address these challenges, we investigate the feasibility of data pruning for BioFM pretraining and propose a post-hoc influence-guided data pruning framework tailored to biological domains. Our approach introduces a subset-based self-influence formulation that enables efficient estimation of sample importance at low computational cost, and builds upon it two simple yet effective selection strategies, namely Top-k Influence (Top I) and Coverage-Centric Influence (CCI). We empirically validate our method on two representative BioFMs, RNA-FM and ESM-C. For RNA, our framework consistently outperforms random selection baselines under an extreme pruning rate of over 99 percent, demonstrating its effectiveness. Furthermore, we show the generalizability of our framework on protein-related tasks using ESM-C. In particular, our coreset even outperforms random subsets that are ten times larger in both RNA and protein settings, revealing substantial redundancy in biological sequence datasets. These findings underscore the potential of influence-guided data pruning to substantially reduce the computational cost of BioFM pretraining, paving the way for more efficient, accessible, and sustainable biological AI research.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿç‰©åŸºç¡€æ¨¡å‹ (Biological foundation models, BioFMs) é¢„è®­ç»ƒé¢ä¸´çš„é«˜æ˜‚è®¡ç®—æˆæœ¬å’Œå¤ç°éšœç¢ï¼Œæ¢è®¨äº†åœ¨å¤§è§„æ¨¡åœºæ™¯ä¸‹åº”ç”¨æ•°æ®å‰ªæ (Data Pruning) çš„å¯è¡Œæ€§ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§ä¸“é—¨é’ˆå¯¹ç”Ÿç‰©é¢†åŸŸè®¾è®¡çš„ã€åŸºäºäº‹åå½±å“å¼•å¯¼ (post-hoc influence-guided) çš„æ•°æ®å‰ªææ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥åŸºäºå­é›†çš„è‡ªå½±å“å…¬å¼ï¼Œå®ç°äº†å¯¹æ ·æœ¬é‡è¦æ€§çš„é«˜æ•ˆä¼°ç®—ã€‚åŸºäºè¯¥æ¡†æ¶ï¼Œç ”ç©¶è€…è¿›ä¸€æ­¥æå‡ºäº† Top-k Influence (Top I) å’Œ Coverage-Centric Influence (CCI) ä¸¤ç§é€‰æ‹©ç­–ç•¥ï¼Œå¹¶åœ¨ RNA-FM å’Œ ESM-C æ¨¡å‹ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨è¶…è¿‡ 99% çš„æç«¯å‰ªæç‡ä¸‹ï¼Œè¯¥æ¡†æ¶çš„è¡¨ç°ä»æŒç»­ä¼˜äºéšæœºé€‰æ‹©åŸºå‡†ï¼Œä¸”å…¶æå–çš„æ ¸å¿ƒé›† (coreset) æ€§èƒ½ç”šè‡³è¶…è¿‡äº†è§„æ¨¡å¤§å…¶åå€çš„éšæœºå­é›†ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†ç”Ÿç‰©åºåˆ—æ•°æ®é›†ä¸­å­˜åœ¨æ˜¾è‘—çš„å†—ä½™æ€§ï¼Œè¯æ˜äº†é€šè¿‡å½±å“å¼•å¯¼çš„å‰ªææŠ€æœ¯å¯ä»¥å¤§å¹…é™ä½é¢„è®­ç»ƒæˆæœ¬ï¼Œä¸ºå®ç°æ›´é«˜æ•ˆã€æ™®æƒ ä¸”å¯æŒç»­çš„ç”Ÿç‰© AI ç ”ç©¶é“ºå¹³äº†é“è·¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.12932v1",
      "published_date": "2025-12-15 02:42:52 UTC",
      "updated_date": "2025-12-15 02:42:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:05:18.099054+00:00"
    },
    {
      "arxiv_id": "2512.13745v1",
      "title": "A Spatio-Temporal Hybrid Quantum-Classical Graph Convolutional Neural Network Approach for Urban Taxi Destination Prediction",
      "title_zh": "ç”¨äºåŸå¸‚å‡ºç§Ÿè½¦ç›®çš„åœ°é¢„æµ‹çš„æ—¶ç©ºæ··åˆé‡å­-ç»å…¸å›¾å·ç§¯ç¥ç»ç½‘ç»œæ–¹æ³•",
      "authors": [
        "Xiuying Zhang",
        "Qinsheng Zhu",
        "Xiaodong Xing"
      ],
      "abstract": "We propose a Hybrid Spatio-Temporal Quantum Graph Convolutional Network (H-STQGCN) algorithm by combining the strengths of quantum computing and classical deep learning to predict the taxi destination within urban road networks. Our algorithm consists of two branches: spatial processing and time evolution. Regarding the spatial processing, the classical module encodes the local topological features of the road network based on the GCN method, and the quantum module is designed to map graph features onto parameterized quantum circuits through a differentiable pooling layer. The time evolution is solved by integrating multi-source contextual information and capturing dynamic trip dependencies on the classical TCN theory. Finally, our experimental results demonstrate that the proposed algorithm outperforms the current methods in terms of prediction accuracy and stability, validating the unique advantages of the quantum-enhanced mechanism in capturing high-dimensional spatial dependencies.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º H-STQGCN (Hybrid Spatio-Temporal Quantum Graph Convolutional Network) çš„æ··åˆæ—¶ç©ºé‡å­å›¾å·ç§¯ç½‘ç»œç®—æ³•ï¼Œæ—¨åœ¨ç»“åˆé‡å­è®¡ç®—å’Œç»å…¸æ·±åº¦å­¦ä¹ çš„ä¼˜åŠ¿æ¥é¢„æµ‹åŸå¸‚è·¯ç½‘ä¸­çš„å‡ºç§Ÿè½¦ç›®çš„åœ°ã€‚è¯¥ç®—æ³•æ¶æ„ç”±ç©ºé—´å¤„ç†å’Œæ—¶é—´æ¼”åŒ–ä¸¤ä¸ªåˆ†æ”¯ç»„æˆï¼Œå…¶ä¸­ç©ºé—´å¤„ç†åˆ†æ”¯åˆ©ç”¨ç»å…¸ GCN æ¨¡å—ç¼–ç å±€éƒ¨æ‹“æ‰‘ç‰¹å¾ï¼Œå¹¶è®¾è®¡é‡å­æ¨¡å—é€šè¿‡å¯å¾®æ± åŒ–å±‚ (differentiable pooling layer) å°†å›¾ç‰¹å¾æ˜ å°„è‡³å‚æ•°åŒ–é‡å­ç”µè·¯ (parameterized quantum circuits)ã€‚æ—¶é—´æ¼”åŒ–åˆ†æ”¯åˆ™åŸºäºç»å…¸ TCN ç†è®ºï¼Œé€šè¿‡é›†æˆå¤šæºä¸Šä¸‹æ–‡ä¿¡æ¯æ¥æ•æ‰è¡Œç¨‹çš„åŠ¨æ€ä¾èµ–å…³ç³»ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥ç®—æ³•åœ¨é¢„æµ‹å‡†ç¡®æ€§å’Œç¨³å®šæ€§ä¸Šå‡ä¼˜äºå½“å‰ä¸»æµæ–¹æ³•ã€‚è¿™ä¸€æˆæœæœ‰æ•ˆéªŒè¯äº†é‡å­å¢å¼ºæœºåˆ¶åœ¨æ•æ‰é«˜ç»´ç©ºé—´ä¾èµ–æ€§æ–¹é¢çš„ç‹¬ç‰¹ä¼˜åŠ¿ï¼Œä¸ºå¤æ‚åŸå¸‚äº¤é€šé¢„æµ‹æä¾›äº†åˆ›æ–°çš„æ··åˆè®¡ç®—æ–¹æ¡ˆã€‚",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.13745v1",
      "published_date": "2025-12-15 02:31:17 UTC",
      "updated_date": "2025-12-15 02:31:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:05:36.022845+00:00"
    },
    {
      "arxiv_id": "2512.12929v1",
      "title": "MADTempo: An Interactive System for Multi-Event Temporal Video Retrieval with Query Augmentation",
      "title_zh": "MADTempoï¼šæ”¯æŒæŸ¥è¯¢å¢å¼ºçš„äº¤äº’å¼å¤šäº‹ä»¶æ—¶åºè§†é¢‘æ£€ç´¢ç³»ç»Ÿ",
      "authors": [
        "Huu-An Vu",
        "Van-Khanh Mai",
        "Trong-Tam Nguyen",
        "Quang-Duc Dam",
        "Tien-Huy Nguyen",
        "Thanh-Huong Le"
      ],
      "abstract": "The rapid expansion of video content across online platforms has accelerated the need for retrieval systems capable of understanding not only isolated visual moments but also the temporal structure of complex events. Existing approaches often fall short in modeling temporal dependencies across multiple events and in handling queries that reference unseen or rare visual concepts. To address these challenges, we introduce MADTempo, a video retrieval framework developed by our team, AIO_Trinh, that unifies temporal search with web-scale visual grounding. Our temporal search mechanism captures event-level continuity by aggregating similarity scores across sequential video segments, enabling coherent retrieval of multi-event queries. Complementarily, a Google Image Search-based fallback module expands query representations with external web imagery, effectively bridging gaps in pretrained visual embeddings and improving robustness against out-of-distribution (OOD) queries. Together, these components advance the temporal reasoning and generalization capabilities of modern video retrieval systems, paving the way for more semantically aware and adaptive retrieval across large-scale video corpora.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†MADTempoï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³å¤æ‚å¤šäº‹ä»¶æ—¶åºä¾èµ–å’Œç¨€æœ‰è§†è§‰æ¦‚å¿µå¤„ç†éš¾é¢˜çš„è§†é¢‘æ£€ç´¢æ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåŒ…å«ä¸€ä¸ªæ—¶åºæœç´¢æœºåˆ¶(Temporal search mechanism)ï¼Œé€šè¿‡èšåˆè¿ç»­è§†é¢‘ç‰‡æ®µçš„ç›¸ä¼¼åº¦åˆ†æ•°æ¥æ•æ‰äº‹ä»¶å±‚é¢çš„è¿ç»­æ€§ï¼Œä»è€Œå®ç°å¯¹Multi-EventæŸ¥è¯¢çš„ç›¸å¹²æ£€ç´¢ã€‚åŒæ—¶ï¼Œç³»ç»Ÿå¼•å…¥äº†åŸºäºGoogle Image Searchçš„Fallbackæ¨¡å—ï¼Œåˆ©ç”¨å¤–éƒ¨ç½‘ç»œå›¾åƒå¢å¼ºæŸ¥è¯¢è¡¨ç¤ºï¼Œæœ‰æ•ˆå¼¥è¡¥äº†é¢„è®­ç»ƒVisual Embeddingsçš„ä¸è¶³å¹¶æå‡äº†å¯¹Out-of-Distribution (OOD)æŸ¥è¯¢çš„é²æ£’æ€§ã€‚MADTempoé€šè¿‡æ•´åˆWeb-scale Visual Groundingä¸æ—¶åºæ¨ç†ï¼Œæ˜¾è‘—æå‡äº†ç°ä»£è§†é¢‘æ£€ç´¢ç³»ç»Ÿçš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™ä¸ºåœ¨å¤§è§„æ¨¡è§†é¢‘è¯­æ–™åº“ä¸­å®ç°æ›´å…·è¯­ä¹‰æ„ŸçŸ¥çš„æ£€ç´¢æä¾›äº†æœ‰æ•ˆçš„æ–¹æ³•å’Œæ€è·¯ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12929v1",
      "published_date": "2025-12-15 02:25:46 UTC",
      "updated_date": "2025-12-15 02:25:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:05:30.187654+00:00"
    },
    {
      "arxiv_id": "2512.13744v1",
      "title": "Toward Noise-Aware Audio Deepfake Detection: Survey, SNR-Benchmarks, and Practical Recipes",
      "title_zh": "è¿ˆå‘å™ªå£°æ„ŸçŸ¥çš„è¯­éŸ³æ·±åº¦ä¼ªé€ æ£€æµ‹ï¼šç»¼è¿°ã€ä¿¡å™ªæ¯”åŸºå‡†åŠå®ç”¨æ–¹æ¡ˆ",
      "authors": [
        "Udayon Sen",
        "Alka Luqman",
        "Anupam Chattopadhyay"
      ],
      "abstract": "Deepfake audio detection has progressed rapidly with strong pre-trained encoders (e.g., WavLM, Wav2Vec2, MMS). However, performance in realistic capture conditions - background noise (domestic/office/transport), room reverberation, and consumer channels - often lags clean-lab results. We survey and evaluate robustness for state-of-the-art audio deepfake detection models and present a reproducible framework that mixes MS-SNSD noises with ASVspoof 2021 DF utterances to evaluate under controlled signal-to-noise ratios (SNRs). SNR is a measured proxy for noise severity used widely in speech; it lets us sweep from near-clean (35 dB) to very noisy (-5 dB) to quantify graceful degradation. We study multi-condition training and fixed-SNR testing for pretrained encoders (WavLM, Wav2Vec2, MMS), reporting accuracy, ROC-AUC, and EER on binary and four-class (authenticity x corruption) tasks. In our experiments, finetuning reduces EER by 10-15 percentage points at 10-0 dB SNR across backbones.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹ (Audio Deepfake Detection) åœ¨çœŸå®ç¯å¢ƒï¼ˆå¦‚èƒŒæ™¯å™ªå£°ã€æˆ¿é—´æ··å“ç­‰ï¼‰ä¸­æ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼Œç³»ç»Ÿè¯„ä¼°äº†ç°æœ‰ä¸»æµæ¨¡å‹çš„é²æ£’æ€§ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªå¯é‡å¤çš„åŸºå‡†æ¡†æ¶ï¼Œé€šè¿‡å°† MS-SNSD å™ªå£°ä¸ ASVspoof 2021 DF æ•°æ®é›†æ··åˆï¼Œåœ¨å—æ§çš„ä¿¡å™ªæ¯” (SNR) èŒƒå›´å†…é‡åŒ–æ¨¡å‹æ€§èƒ½çš„é€€åŒ–æƒ…å†µã€‚ç ”ç©¶æ·±å…¥æ¢è®¨äº† WavLMã€Wav2Vec2 å’Œ MMS ç­‰é¢„è®­ç»ƒç¼–ç å™¨åœ¨å¤šæ¡ä»¶è®­ç»ƒä¸‹çš„è¡¨ç°ï¼Œæ¶µç›–äº†äºŒåˆ†ç±»åŠå››åˆ†ç±»ä»»åŠ¡ã€‚å®éªŒç»“æœè¯æ˜ï¼Œé€šè¿‡é’ˆå¯¹æ€§çš„å¾®è°ƒ (Finetuning) å¤„ç†ï¼Œæ¨¡å‹åœ¨ 10-0 dB SNR è¾ƒä½ä¿¡å™ªæ¯”ç¯å¢ƒä¸‹çš„ç­‰é”™ç‡ (EER) å¯æ˜¾è‘—é™ä½ 10-15 ä¸ªç™¾åˆ†ç‚¹ã€‚è¯¥å·¥ä½œä¸ºå®ç°å…·å¤‡å™ªå£°æ„ŸçŸ¥èƒ½åŠ›ä¸”æ›´å…·å®ç”¨æ€§çš„éŸ³é¢‘é˜²ä¼ªæŠ€æœ¯æä¾›äº†é‡è¦çš„å®éªŒåŸºå‡†ä¸å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "6 pages",
      "pdf_url": "https://arxiv.org/pdf/2512.13744v1",
      "published_date": "2025-12-15 02:22:37 UTC",
      "updated_date": "2025-12-15 02:22:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:05:36.892474+00:00"
    },
    {
      "arxiv_id": "2512.12921v1",
      "title": "Cisco Integrated AI Security and Safety Framework Report",
      "title_zh": "Ciscoäººå·¥æ™ºèƒ½å®‰å…¨ä¸å®‰å…¨æ€§é›†æˆæ¡†æ¶æŠ¥å‘Š",
      "authors": [
        "Amy Chang",
        "Tiffany Saade",
        "Sanket Mendapara",
        "Adam Swanda",
        "Ankit Garg"
      ],
      "abstract": "Artificial intelligence (AI) systems are being readily and rapidly adopted, increasingly permeating critical domains: from consumer platforms and enterprise software to networked systems with embedded agents. While this has unlocked potential for human productivity gains, the attack surface has expanded accordingly: threats now span content safety failures (e.g., harmful or deceptive outputs), model and data integrity compromise (e.g., poisoning, supply-chain tampering), runtime manipulations (e.g., prompt injection, tool and agent misuse), and ecosystem risks (e.g., orchestration abuse, multi-agent collusion). Existing frameworks such as MITRE ATLAS, National Institute of Standards and Technology (NIST) AI 100-2 Adversarial Machine Learning (AML) taxonomy, and OWASP Top 10s for Large Language Models (LLMs) and Agentic AI Applications provide valuable viewpoints, but each covers only slices of this multi-dimensional space.\n  This paper presents Cisco's Integrated AI Security and Safety Framework (\"AI Security Framework\"), a unified, lifecycle-aware taxonomy and operationalization framework that can be used to classify, integrate, and operationalize the full range of AI risks. It integrates AI security and AI safety across modalities, agents, pipelines, and the broader ecosystem. The AI Security Framework is designed to be practical for threat identification, red-teaming, risk prioritization, and it is comprehensive in scope and can be extensible to emerging deployments in multimodal contexts, humanoids, wearables, and sensory infrastructures. We analyze gaps in prevailing frameworks, discuss design principles for our framework, and demonstrate how the taxonomy provides structure for understanding how modern AI systems fail, how adversaries exploit these failures, and how organizations can build defenses across the AI lifecycle that evolve alongside capability advancements.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½(AI)ç³»ç»Ÿå¿«é€Ÿæ™®åŠå¸¦æ¥çš„å†…å®¹å®‰å…¨æ•…éšœã€æ¨¡å‹ä¸æ•°æ®å®Œæ•´æ€§å—æŸã€è¿è¡Œæ—¶æ“çºµä»¥åŠç”Ÿæ€ç³»ç»Ÿé£é™©ç­‰å…¨æ–¹ä½å®‰å…¨æŒ‘æˆ˜ï¼Œåˆ†æäº†ç°æœ‰æ¡†æ¶å¦‚ MITRE ATLASã€NIST AI 100-2 å’Œ OWASP Top 10 åœ¨è¦†ç›–ç»´åº¦ä¸Šçš„å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†æ€ç§‘é›†æˆ AI å®‰å…¨ä¸é˜²æŠ¤æ¡†æ¶(Cisco's Integrated AI Security and Safety Framework)ï¼Œè¿™æ˜¯ä¸€ç§ç»Ÿä¸€ä¸”å…·å¤‡ç”Ÿå‘½å‘¨æœŸæ„ŸçŸ¥èƒ½åŠ›çš„åˆ†ç±»æ³•ä¸æ“ä½œåŒ–æ¡†æ¶ã€‚è¯¥æ¡†æ¶è·¨è¶Šæ¨¡æ€ã€æ™ºèƒ½ä½“(agents)ã€æµæ°´çº¿åŠå…¶å¹¿æ³›ç”Ÿæ€ç³»ç»Ÿï¼Œå®ç°äº† AI security ä¸ AI safety çš„æ·±åº¦æ•´åˆã€‚å®ƒä¸“ä¸ºå¨èƒè¯†åˆ«ã€çº¢é˜Ÿæµ‹è¯•(red-teaming)å’Œé£é™©ä¼˜å…ˆçº§æ’åºè€Œè®¾è®¡ï¼Œå…·æœ‰æå¼ºçš„å®ç”¨æ€§ï¼Œå¹¶èƒ½æ‰©å±•è‡³å¤šæ¨¡æ€ä¸Šä¸‹æ–‡ã€ç±»äººæœºå™¨äººåŠç©¿æˆ´å¼è®¾å¤‡ç­‰æ–°å…´éƒ¨ç½²é¢†åŸŸã€‚é€šè¿‡è¯¦ç»†è®ºè¿°è®¾è®¡åŸåˆ™ï¼Œè¯¥æ¡†æ¶ä¸ºç†è§£ç°ä»£ AI ç³»ç»Ÿå¤±æ•ˆæ¨¡å¼åŠå¯¹æŠ—åˆ©ç”¨æä¾›äº†ç»“æ„åŒ–æ”¯æ’‘ï¼ŒåŠ©åŠ›ç»„ç»‡æ„å»ºéš AI èƒ½åŠ›æ¼”è¿›è€ŒåŒæ­¥å‘å±•çš„å…¨ç”Ÿå‘½å‘¨æœŸé˜²å¾¡ä½“ç³»ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12921v1",
      "published_date": "2025-12-15 02:12:12 UTC",
      "updated_date": "2025-12-15 02:12:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:05:56.320614+00:00"
    },
    {
      "arxiv_id": "2512.12918v1",
      "title": "Satisfiability Modulo Theory Meets Inductive Logic Programming",
      "title_zh": "å½“æ»¡è¶³æ€§æ¨¡ç†è®ºé‡ä¸Šå½’çº³é€»è¾‘ç¨‹åºè®¾è®¡",
      "authors": [
        "Nijesh Upreti",
        "Vaishak Belle"
      ],
      "abstract": "Inductive Logic Programming (ILP) provides interpretable rule learning in relational domains, yet remains limited in its ability to induce and reason with numerical constraints. Classical ILP systems operate over discrete predicates and typically rely on discretisation or hand-crafted numerical predicates, making it difficult to infer thresholds or arithmetic relations that must hold jointly across examples. Recent work has begun to address these limitations through tighter integrations of ILP with Satisfiability Modulo Theories (SMT) or specialised numerical inference mechanisms. In this paper we investigate a modular alternative that couples the ILP system PyGol with the SMT solver Z3. Candidate clauses proposed by PyGol are interpreted as quantifier-free formulas over background theories such as linear or nonlinear real arithmetic, allowing numerical parameters to be instantiated and verified by the SMT solver while preserving ILP's declarative relational bias. This supports the induction of hybrid rules that combine symbolic predicates with learned numerical constraints, including thresholds, intervals, and multi-literal arithmetic relations. We formalise this SMT-ILP setting and evaluate it on a suite of synthetic datasets designed to probe linear, relational, nonlinear, and multi-hop reasoning. The results illustrate how a modular SMT-ILP architecture can extend the expressivity of symbolic rule learning, complementing prior numerical ILP approaches while providing a flexible basis for future extensions toward richer theory-aware induction.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å½’çº³é€»è¾‘ç¨‹åºè®¾è®¡(Inductive Logic Programming, ILP)åœ¨å¤„ç†æ•°å€¼çº¦æŸæ–¹é¢çš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨è·¨ç¤ºä¾‹æ¨æ–­é˜ˆå€¼æˆ–ç®—æœ¯å…³ç³»æ—¶çš„ä¸è¶³ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§å°† ILP ç³»ç»Ÿ PyGol ä¸ SMT æ±‚è§£å™¨ Z3 ç›¸ç»“åˆçš„æ¨¡å—åŒ–æ¶æ„ã€‚è¯¥æ–¹æ³•å°† PyGol ç”Ÿæˆçš„å€™é€‰å­å¥è§†ä¸ºçº¿æ€§æˆ–éçº¿æ€§å®æ•°ç®—æœ¯ç­‰èƒŒæ™¯ç†è®ºä¸‹çš„æ— é‡è¯å…¬å¼ï¼Œåˆ©ç”¨ SMT æ±‚è§£å™¨å¯¹æ•°å€¼å‚æ•°è¿›è¡Œå®ä¾‹åŒ–å’ŒéªŒè¯ï¼ŒåŒæ—¶ä¿ç•™äº† ILP çš„å£°æ˜å¼å…³ç³»åç½®(Relational Bias)ã€‚è¿™ç§ SMT-ILP è®¾ç½®æ”¯æŒè¯±å¯¼ç»“åˆç¬¦å·è°“è¯ä¸å­¦ä¹ åˆ°çš„æ•°å€¼çº¦æŸï¼ˆå¦‚é˜ˆå€¼ã€åŒºé—´å’Œå¤šæ–‡å­—ç®—æœ¯å…³ç³»ï¼‰çš„æ··åˆè§„åˆ™ã€‚é€šè¿‡åœ¨æ¶‰åŠçº¿æ€§ã€éçº¿æ€§å’Œå¤šè·³æ¨ç†çš„åˆæˆæ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œå®éªŒç»“æœè¯æ˜äº†è¯¥æ¶æ„åœ¨æ‰©å±•ç¬¦å·è§„åˆ™å­¦ä¹ è¡¨è¾¾åŠ›æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¯¥ç ”ç©¶ä¸ºæœªæ¥å®ç°æ›´ä¸°å¯Œçš„æ„ŸçŸ¥ç†è®ºè¯±å¯¼(Theory-Aware Induction)æä¾›äº†çµæ´»çš„åŸºç¡€ï¼Œæœ‰æ•ˆè¡¥å……äº†ç°æœ‰çš„æ•°å€¼ ILP æ–¹æ³•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.12918v1",
      "published_date": "2025-12-15 02:08:32 UTC",
      "updated_date": "2025-12-15 02:08:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:06:03.613647+00:00"
    },
    {
      "arxiv_id": "2512.12914v1",
      "title": "CTIGuardian: A Few-Shot Framework for Mitigating Privacy Leakage in Fine-Tuned LLMs",
      "title_zh": "CTIGuardianï¼šç¼“è§£å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹éšç§æ³„éœ²çš„å°æ ·æœ¬æ¡†æ¶",
      "authors": [
        "Shashie Dilhara Batan Arachchige",
        "Benjamin Zi Hao Zhao",
        "Hassan Jameel Asghar",
        "Dinusha Vatsalan",
        "Dali Kaafar"
      ],
      "abstract": "Large Language Models (LLMs) are often fine-tuned to adapt their general-purpose knowledge to specific tasks and domains such as cyber threat intelligence (CTI). Fine-tuning is mostly done through proprietary datasets that may contain sensitive information. Owners expect their fine-tuned model to not inadvertently leak this information to potentially adversarial end users. Using CTI as a use case, we demonstrate that data-extraction attacks can recover sensitive information from fine-tuned models on CTI reports, underscoring the need for mitigation. Retraining the full model to eliminate this leakage is computationally expensive and impractical. We propose an alternative approach, which we call privacy alignment, inspired by safety alignment in LLMs. Just like safety alignment teaches the model to abide by safety constraints through a few examples, we enforce privacy alignment through few-shot supervision, integrating a privacy classifier and a privacy redactor, both handled by the same underlying LLM. We evaluate our system, called CTIGuardian, using GPT-4o mini and Mistral-7B Instruct models, benchmarking against Presidio, a named entity recognition (NER) baseline. Results show that CTIGuardian provides a better privacy-utility trade-off than NER based models. While we demonstrate its effectiveness on a CTI use case, the framework is generic enough to be applicable to other sensitive domains.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¾®è°ƒåçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç½‘ç»œå¨èƒæƒ…æŠ¥ï¼ˆCTIï¼‰é¢†åŸŸé¢ä¸´çš„éšç§æ³„éœ²é£é™©ï¼Œæå‡ºäº†åä¸º CTIGuardian çš„é˜²å¾¡æ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†å—å®‰å…¨å¯¹é½å¯å‘çš„â€œéšç§å¯¹é½â€ï¼ˆprivacy alignmentï¼‰æ–¹æ³•ï¼Œé€šè¿‡å°‘æ ·æœ¬ç›‘ç£ï¼ˆfew-shot supervisionï¼‰å¼•å¯¼æ¨¡å‹éµå®ˆéšç§çº¦æŸï¼Œé¿å…äº†é«˜æ˜‚çš„å…¨é‡é‡è®­ç»ƒæˆæœ¬ã€‚CTIGuardian å°†éšç§åˆ†ç±»å™¨ï¼ˆprivacy classifierï¼‰å’Œéšç§è„±æ•å™¨ï¼ˆprivacy redactorï¼‰é›†æˆäºåŒä¸€ä¸ªåº•å±‚ LLM ä¸­ï¼Œå®ç°äº†å¯¹æ•æ„Ÿä¿¡æ¯çš„æœ‰æ•ˆè¯†åˆ«ä¸å¤„ç†ã€‚åœ¨ GPT-4o mini å’Œ Mistral-7B Instruct æ¨¡å‹ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCTIGuardian åœ¨éšç§ä¿æŠ¤ä¸æ¨¡å‹æ•ˆç”¨ï¼ˆprivacy-utility trade-offï¼‰çš„å¹³è¡¡ä¸Šä¼˜äºåŸºäºå‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰çš„åŸºå‡†æ¨¡å‹ã€‚è¯¥ç ”ç©¶ä¸ä»…è¯æ˜äº† CTIGuardian åœ¨å¤„ç† CTI æŠ¥å‘Šæ—¶çš„æœ‰æ•ˆæ€§ï¼Œè¿˜å±•ç¤ºäº†è¯¥é€šç”¨æ¡†æ¶åœ¨å…¶ä»–æ•æ„Ÿæ•°æ®é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at the 18th Cybersecurity Experimentation and Test Workshop (CSET), in conjunction with ACSAC 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.12914v1",
      "published_date": "2025-12-15 01:59:14 UTC",
      "updated_date": "2025-12-15 01:59:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:06:17.620796+00:00"
    },
    {
      "arxiv_id": "2512.12888v1",
      "title": "Meta-GPT: Decoding the Metasurface Genome with Generative Artificial Intelligence",
      "title_zh": "Meta-GPTï¼šåˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½è§£ç è¶…è¡¨é¢åŸºå› ç»„",
      "authors": [
        "David Dang",
        "Stuart Love",
        "Meena Salib",
        "Quynh Dang",
        "Samuel Rothfarb",
        "Mysk Alnatour",
        "Andrew Salij",
        "Hou-Tong Chen",
        "Ho Wai",
        "Lee",
        "Wilton J. M. Kort-Kamp"
      ],
      "abstract": "Advancing artificial intelligence for physical sciences requires representations that are both interpretable and compatible with the underlying laws of nature. We introduce METASTRINGS, a symbolic language for photonics that expresses nanostructures as textual sequences encoding materials, geometries, and lattice configurations. Analogous to molecular textual representations in chemistry, METASTRINGS provides a framework connecting human interpretability with computational design by capturing the structural hierarchy of photonic metasurfaces. Building on this representation, we develop Meta-GPT, a foundation transformer model trained on METASTRINGS and finetuned with physics-informed supervised, reinforcement, and chain-of-thought learning. Across various design tasks, the model achieves <3% mean-squared spectral error and maintains >98% syntactic validity, generating diverse metasurface prototypes whose experimentally measured optical responses match their target spectra. These results demonstrate that Meta-GPT can learn the compositional rules of light-matter interactions through METASTRINGS, laying a rigorous foundation for AI-driven photonics and representing an important step toward a metasurface genome project.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† METASTRINGSï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºå…‰å­å­¦ (photonics) çš„ç¬¦å·è¯­è¨€ï¼Œé€šè¿‡å°†çº³ç±³ç»“æ„ (nanostructures) è¡¨ç¤ºä¸ºç¼–ç ææ–™ã€å‡ ä½•å½¢çŠ¶å’Œæ™¶æ ¼é…ç½®çš„æ–‡æœ¬åºåˆ—ï¼Œå®ç°äº†ç‰©ç†å¯è§£é‡Šæ€§ä¸è®¡ç®—è®¾è®¡çš„è¿æ¥ã€‚åŸºäºæ­¤è¡¨ç¤ºæ³•ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº† Meta-GPTï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨å¤§è§„æ¨¡ METASTRINGS æ•°æ®é›†ä¸Šé¢„è®­ç»ƒï¼Œå¹¶ç»“åˆç‰©ç†çŸ¥è¯†ç›‘ç£å­¦ä¹  (physics-informed supervised learning)ã€å¼ºåŒ–å­¦ä¹  (reinforcement learning) å’Œé“¾å¼æ€ç»´ (chain-of-thought) å­¦ä¹ å¾®è°ƒçš„åŸºç¡€ Transformer æ¨¡å‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨å¤šç§è®¾è®¡ä»»åŠ¡ä¸­å®ç°äº†å°äº 3% çš„å‡æ–¹å…‰è°±è¯¯å·® (mean-squared spectral error) å’Œè¶…è¿‡ 98% çš„è¯­æ³•æœ‰æ•ˆæ€§ (syntactic validity)ï¼Œä¸”å®éªŒæµ‹é‡çš„è¶…è¡¨é¢ (metasurface) åŸå‹å…‰å­¦å“åº”ä¸ç›®æ ‡å…‰è°±é«˜åº¦å»åˆã€‚è¯¥å·¥ä½œè¯æ˜äº† Meta-GPT èƒ½å¤Ÿå­¦ä¹ å…‰ä¸ç‰©è´¨ç›¸äº’ä½œç”¨çš„ç»„åˆè§„åˆ™ï¼Œä¸ºäººå·¥æ™ºèƒ½é©±åŠ¨çš„å…‰å­å­¦å¥ å®šäº†åŸºç¡€ï¼Œå¹¶æ ‡å¿—ç€è¶…è¡¨é¢åŸºå› ç»„è®¡åˆ’ (metasurface genome project) è¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚",
      "categories": [
        "physics.optics",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "physics.optics",
      "comment": "Keywords: Physics-informed machine learning; Transformer models; Reinforcement learning; Chain-of-thought reasoning; Metasurfaces; Nanophotonics; Inverse design",
      "pdf_url": "https://arxiv.org/pdf/2512.12888v1",
      "published_date": "2025-12-15 00:09:14 UTC",
      "updated_date": "2025-12-15 00:09:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T17:06:10.959565+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 124,
  "processed_papers_count": 124,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-26T17:07:23.249971+00:00"
}