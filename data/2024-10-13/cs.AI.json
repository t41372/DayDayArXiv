{
  "date": "2024-10-13",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-13 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 模型的安全性、医疗应用、强化学习和图像处理等领域，亮点包括 LLM 的幻觉检测和农村医疗 AI 系统，以及知名学者如 Yixuan Li 和 Nihar B. Shah 的贡献，这些工作展示了 AI 在实际场景中的潜力，并推动了模型鲁棒性和高效性的进步。\n\n下面，我们挑选并讨论部分重要、具有话题度和影响力的论文，先从 AI 和 LLM 相关主题入手，再聊医疗和机器人领域。其他论文如数学基准测试或一般图像处理，我们快速掠过，以控制篇幅。\n\n### AI 和 LLM 相关论文\n- **Safety-Aware Fine-Tuning of Large Language Models（LLM 安全微调）**  \n  作者包括知名学者 Yixuan Li。该论文提出 SAFT 框架，通过评分函数自动检测并移除有害数据样本，实现 LLM 微调的安全性提升，实验显示可降低有害输出率达 27.8%，这对 LLM 在敏感领域的应用（如医疗决策）有重要启示。\n\n- **BlackDAN: A Black-Box Multi-Objective Approach for Effective and Contextual Jailbreaking of Large Language Models（黑盒多目标方法用于 LLM 越狱攻击）**  \n  这篇论文引入 BlackDAN 框架，使用多目标优化算法（如 NSGA-II）生成高质量的越狱提示，平衡攻击成功率、隐蔽性和语义相关性。贡献在于提升了 LLM 安全评估的全面性，实验显示其在多种 LLM 上表现优于单目标方法，突显 AI 系统的潜在漏洞。\n\n- **A Step Towards Mixture of Grader: Statistical Analysis of Existing Automatic Evaluation Metrics（迈向评估器混合：现有自动评估指标的统计分析）**  \n  作者 Yun Joon Soh 和 Jishen Zhao 分析了 QA 任务的评估指标，发现指标间相关性高但无单一指标能完美模拟人工评分。论文建议使用“混合评估器”改进自动评估，这为 LLM 输出质量评估提供了新思路。\n\n- **Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning（零样本学习：基于检索的参数集成而非微调）**  \n  该工作提出 RPE 方法，通过检索 LoRA 参数数据库实现零样本学习，避免了传统微调的计算开销。发现它在医疗报告生成和图像分割任务中超越监督微调，强调了高效和隐私保护的实际价值。\n\n- **Agentic Information Retrieval（代理式信息检索）**  \n  作者 Weinan Zhang 等扩展了信息检索定义，提出代理式框架，利用 LLM 和 AI 代理处理动态信息状态。贡献在于从静态检索转向动态决策，这可能革新搜索系统，尤其在实时应用中。\n\n- **Prompt Tuning for Audio Deepfake Detection: Computationally Efficient Test-time Domain Adaptation with Limited Target Dataset（音频深度伪造检测的提示微调：高效测试时域适应）**  \n  论文开发了一种提示微调方法，提升音频深度伪造检测的鲁棒性，即使在数据有限的情况下。核心发现是它能与现有模型无缝集成，提高准确率，同时减少计算负担。\n\n### 医疗和机器人相关论文\n- **IMAS: A Comprehensive Agentic Approach to Rural Healthcare Delivery（农村医疗交付的全面代理方法）**  \n  作者 Agasthya Gangavarapu 等提出 IMAS 系统，利用 LLM 和代理技术为农村医疗工作者提供支持，包括翻译和诊断。贡献在于处理文化和识字差异，实验在 MedQA 等数据集上显著提升医疗可达性，这对全球医疗不平等有实际影响。\n\n- **WormKAN: Are KAN Effective for Identifying and Tracking Concept Drift in Time Series?（WormKAN：Kolmogorov-Arnold 网络在时间序列概念漂移识别中的有效性）**  \n  论文引入 WormKAN 模型，使用 KAN 网络检测时间序列中的概念漂移，结合标准化和动态模块。发现它在金融和医疗数据上提升了漂移跟踪准确性，这为实时监控系统提供了新工具。\n\n- **SlimSeiz: Efficient Channel-Adaptive Seizure Prediction Using a Mamba-Enhanced Network（SlimSeiz：基于 Mamba 增强网络的通道自适应癫痫预测）**  \n  该工作提出 SlimSeiz 框架，通过自适应通道选择和轻量网络预测癫痫发作，减少通道数量同时保持 94.8% 准确率。贡献在于提升了移动设备的可用性，适用于临床实时监测。\n\n- **Towards Homogeneous Lexical Tone Decoding from Heterogeneous Intracranial Recordings（从异质颅内记录向同质词汇音调解码）**  \n  作者 Mohamad Sawan 等开发 H2DiLR 框架，处理脑机接口中的数据异质性，提升音调解码准确性。实验显示它在多主体数据上优于传统方法，这对语言障碍康复有重要启示。\n\n- **Surgical-LLaVA: Toward Surgical Scenario Understanding via Large Language and Vision Models（手术场景理解：基于大型语言和视觉模型）**  \n  论文构建 Surgical-LLaVA 系统，融合图像和视频表示用于手术场景分析。发现它在手术问答任务中超越基线，提升了 AI 在手术辅助中的潜力。\n\n### 其他快速掠过\n其他论文如 **Large-scale Multi-objective Feature Selection（大规模多目标特征选择）** 和 **Online Multi-modal Root Cause Analysis（在线多模态根因分析）** 等，分别提出了高效特征选择算法和根因定位方法，但这些相对常规，我们仅提及它们在机器学习优化中的贡献，而不深入讨论。同样，强化学习论文如 **VQ-CNMP: Neuro-Symbolic Skill Learning for Bi-Level Planning（神经符号技能学习用于双层规划）** 展示了机器人规划的进展，但篇幅有限，这里就简略带过。\n\n总之，今天的论文突显 AI 向实际应用（如医疗和安全）的扩展，值得关注领域从业者跟进。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2410.10045v1",
      "title": "VQ-CNMP: Neuro-Symbolic Skill Learning for Bi-Level Planning",
      "title_zh": "VQ-CNMP：神经符号技能学习用于双层规划",
      "authors": [
        "Hakan Aktas",
        "Emre Ugur"
      ],
      "abstract": "This paper proposes a novel neural network model capable of discovering\nhigh-level skill representations from unlabeled demonstration data. We also\npropose a bi-level planning pipeline that utilizes our model using a\ngradient-based planning approach. While extracting high-level representations,\nour model also preserves the low-level information, which can be used for\nlow-level action planning. In the experiments, we tested the skill discovery\nperformance of our model under different conditions, tested whether Multi-Modal\nLLMs can be utilized to label the learned high-level skill representations, and\nfinally tested the high-level and low-level planning performance of our\npipeline.",
      "tldr_zh": "本论文提出了一种新型神经网络模型 VQ-CNMP，用于从无标签演示数据中自动发现高级技能表示，同时保留低级信息以支持低级动作规划。作者还设计了双层规划（Bi-Level Planning）管道，采用梯度-based方法整合该模型，实现高效的高级和低级任务规划。实验结果显示，该模型在不同条件下的技能发现性能良好，并验证了 Multi-Modal LLMs 可用于标记高级技能表示，从而提升整体规划效能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "12 pages, 6 figures, Submitted to Conference on Robot Learning LEAP\n  Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.10045v1",
      "published_date": "2024-10-13 23:29:46 UTC",
      "updated_date": "2024-10-13 23:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:51:16.709234"
    },
    {
      "arxiv_id": "2410.12868v1",
      "title": "IMAS: A Comprehensive Agentic Approach to Rural Healthcare Delivery",
      "title_zh": "IMAS: 一种全面的智能体方法，用于农村医疗保健服务提供",
      "authors": [
        "Agasthya Gangavarapu",
        "Ananya Gangavarapu"
      ],
      "abstract": "Since the onset of COVID-19, rural communities worldwide have faced\nsignificant challenges in accessing healthcare due to the migration of\nexperienced medical professionals to urban centers. Semi-trained caregivers,\nsuch as Community Health Workers (CHWs) and Registered Medical Practitioners\n(RMPs), have stepped in to fill this gap, but often lack formal training. This\npaper proposes an advanced agentic medical assistant system designed to improve\nhealthcare delivery in rural areas by utilizing Large Language Models (LLMs)\nand agentic approaches. The system is composed of five crucial components:\ntranslation, medical complexity assessment, expert network integration, final\nmedical advice generation, and response simplification. Our innovative\nframework ensures context-sensitive, adaptive, and reliable medical assistance,\ncapable of clinical triaging, diagnostics, and identifying cases requiring\nspecialist intervention. The system is designed to handle cultural nuances and\nvarying literacy levels, providing clear and actionable medical advice in local\nlanguages. Evaluation results using the MedQA, PubMedQA, and JAMA datasets\ndemonstrate that this integrated approach significantly enhances the\neffectiveness of rural healthcare workers, making healthcare more accessible\nand understandable for underserved populations. All code and supplemental\nmaterials associated with the paper and IMAS are available at\nhttps://github.com/uheal/imas.",
      "tldr_zh": "该论文针对COVID-19后农村地区医疗访问挑战（如医疗专业人员迁移和半训练护理人员如CHWs和RMPs的不足），提出IMAS系统，这是一种基于Large Language Models (LLMs)和代理方法的综合框架。IMAS包括五个关键组件：翻译、医疗复杂性评估、专家网络整合、最终医疗建议生成和响应简化，以提供上下文敏感、适应性的医疗援助，包括临床分流、诊断和识别需要专家干预的病例，同时处理文化细微差别和不同识字水平。评估结果显示，该系统在MedQA、PubMedQA和JAMA数据集上显著提升了农村医疗工作者的有效性，使医疗服务更易访问和易懂。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12868v1",
      "published_date": "2024-10-13 23:07:11 UTC",
      "updated_date": "2024-10-13 23:07:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:51:27.551813"
    },
    {
      "arxiv_id": "2410.21293v1",
      "title": "Large-scale Multi-objective Feature Selection: A Multi-phase Search Space Shrinking Approach",
      "title_zh": "大规模多目标特征选择：一种多阶段搜索空间收缩方法",
      "authors": [
        "Azam Asilian Bidgoli",
        "Shahryar Rahnamayan"
      ],
      "abstract": "Feature selection is a crucial step in machine learning, especially for\nhigh-dimensional datasets, where irrelevant and redundant features can degrade\nmodel performance and increase computational costs. This paper proposes a novel\nlarge-scale multi-objective evolutionary algorithm based on the search space\nshrinking, termed LMSSS, to tackle the challenges of feature selection\nparticularly as a sparse optimization problem. The method includes a shrinking\nscheme to reduce dimensionality of the search space by eliminating irrelevant\nfeatures before the main evolutionary process. This is achieved through a\nranking-based filtering method that evaluates features based on their\ncorrelation with class labels and frequency in an initial, cost-effective\nevolutionary process. Additionally, a smart crossover scheme based on voting\nbetween parent solutions is introduced, giving higher weight to the parent with\nbetter classification accuracy. An intelligent mutation process is also\ndesigned to target features prematurely excluded from the population, ensuring\nthey are evaluated in combination with other features. These integrated\ntechniques allow the evolutionary process to explore the search space more\nefficiently and effectively, addressing the sparse and high-dimensional nature\nof large-scale feature selection problems. The effectiveness of the proposed\nalgorithm is demonstrated through comprehensive experiments on 15 large-scale\ndatasets, showcasing its potential to identify more accurate feature subsets\ncompared to state-of-the-art large-scale feature selection algorithms. These\nresults highlight LMSSS's capability to improve model performance and\ncomputational efficiency, setting a new benchmark in the field.",
      "tldr_zh": "这篇论文提出了一种名为 LMSSS 的多目标进化算法，用于处理大规模特征选择问题，通过多阶段搜索空间收缩来减少维度并优化稀疏问题。方法包括基于排名的过滤机制（评估特征与类标签的相关性和频率）、智能交叉方案（通过投票赋予分类准确率更高的父解决方案更高权重），以及智能变异过程（针对过早排除的特征进行重新评估），从而提升搜索效率。实验在15个大规模数据集上验证了 LMSSS 的有效性，其识别的特征子集比现有算法更准确，提高了模型性能和计算效率。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21293v1",
      "published_date": "2024-10-13 23:06:10 UTC",
      "updated_date": "2024-10-13 23:06:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:51:39.440817"
    },
    {
      "arxiv_id": "2410.10041v2",
      "title": "WormKAN: Are KAN Effective for Identifying and Tracking Concept Drift in Time Series?",
      "title_zh": "翻译失败",
      "authors": [
        "Kunpeng Xu",
        "Lifei Chen",
        "Shengrui Wang"
      ],
      "abstract": "Dynamic concepts in time series are crucial for understanding complex systems\nsuch as financial markets, healthcare, and online activity logs. These concepts\nhelp reveal structures and behaviors in sequential data for better\ndecision-making and forecasting. However, existing models often struggle to\ndetect and track concept drift due to limitations in interpretability and\nadaptability. To address this challenge, inspired by the flexibility of the\nrecent Kolmogorov-Arnold Network (KAN), we propose WormKAN, a concept-aware\nKAN-based model to address concept drift in co-evolving time series. WormKAN\nconsists of three key components: Patch Normalization, Temporal Representation\nModule, and Concept Dynamics. Patch normalization processes co-evolving time\nseries into patches, treating them as fundamental modeling units to capture\nlocal dependencies while ensuring consistent scaling. The temporal\nrepresentation module learns robust latent representations by leveraging a\nKAN-based autoencoder, complemented by a smoothness constraint, to uncover\ninter-patch correlations. Concept dynamics identifies and tracks dynamic\ntransitions, revealing structural shifts in the time series through concept\nidentification and drift detection. These transitions, akin to passing through\na \\textit{wormhole}, are identified by abrupt changes in the latent space.\nExperiments show that KAN and KAN-based models (WormKAN) effectively segment\ntime series into meaningful concepts, enhancing the identification and tracking\nof concept drift.",
      "tldr_zh": "本研究探讨了Kolmogorov-Arnold Network (KAN) 在时间序列中识别和跟踪概念漂移的有效性，针对现有模型的可解释性和适应性不足问题，提出WormKAN模型，用于处理共进化时间序列中的动态概念。WormKAN 包括三个关键组件：Patch Normalization 处理时间序列为 patches 以捕获局部依赖并确保缩放一致；Temporal Representation Module 通过 KAN-based autoencoder 和平滑约束学习稳健的潜在表示，揭示 patches 间的相关性；Concept Dynamics 模块识别和跟踪动态转换（如潜在空间的突然变化，类似于通过 wormhole），从而检测结构移位。实验结果显示，WormKAN 能有效将时间序列分割成有意义的概念，提升概念漂移的识别和跟踪性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10041v2",
      "published_date": "2024-10-13 23:05:37 UTC",
      "updated_date": "2024-12-13 00:23:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:51:52.520684"
    },
    {
      "arxiv_id": "2410.10030v1",
      "title": "A Step Towards Mixture of Grader: Statistical Analysis of Existing Automatic Evaluation Metrics",
      "title_zh": "翻译失败",
      "authors": [
        "Yun Joon Soh",
        "Jishen Zhao"
      ],
      "abstract": "The explosion of open-sourced models and Question-Answering (QA) datasets\nemphasizes the importance of automated QA evaluation. We studied the statistics\nof the existing evaluation metrics for a better understanding of their\nlimitations. By measuring the correlation coefficients of each evaluation\nmetric concerning human-like evaluation score, we observed the following: (1)\nexisting metrics have a high correlation among them concerning the question\ntype (e.g., single word, single phrase, etc.), (2) no single metric can\nadequately estimate the human-like evaluation. As a potential solution, we\ndiscuss how a Mixture Of Grader could potentially improve the auto QA evaluator\nquality.",
      "tldr_zh": "本研究对现有自动评估指标进行了统计分析，旨在更好地理解其在Question-Answering (QA)系统中的局限性。通过测量各指标与人类评估分数的correlation coefficients，发现这些指标在问题类型（如单字或单短语）上彼此高度相关，但没有单一指标能充分模拟人类评估。研究结果强调了现有方法的不足，并提出Mixture of Grader作为潜在解决方案，以提升自动QA评估器的质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10030v1",
      "published_date": "2024-10-13 22:10:42 UTC",
      "updated_date": "2024-10-13 22:10:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:52:03.553098"
    },
    {
      "arxiv_id": "2410.10021v1",
      "title": "Online Multi-modal Root Cause Analysis",
      "title_zh": "在线多模态根因分析",
      "authors": [
        "Lecheng Zheng",
        "Zhengzhang Chen",
        "Haifeng Chen",
        "Jingrui He"
      ],
      "abstract": "Root Cause Analysis (RCA) is essential for pinpointing the root causes of\nfailures in microservice systems. Traditional data-driven RCA methods are\ntypically limited to offline applications due to high computational demands,\nand existing online RCA methods handle only single-modal data, overlooking\ncomplex interactions in multi-modal systems. In this paper, we introduce OCEAN,\na novel online multi-modal causal structure learning method for root cause\nlocalization. OCEAN employs a dilated convolutional neural network to capture\nlong-term temporal dependencies and graph neural networks to learn causal\nrelationships among system entities and key performance indicators. We further\ndesign a multi-factor attention mechanism to analyze and reassess the\nrelationships among different metrics and log indicators/attributes for\nenhanced online causal graph learning. Additionally, a contrastive mutual\ninformation maximization-based graph fusion module is developed to effectively\nmodel the relationships across various modalities. Extensive experiments on\nthree real-world datasets demonstrate the effectiveness and efficiency of our\nproposed method.",
      "tldr_zh": "这篇论文针对微服务系统的根因分析（RCA）问题，提出了一种新型在线多模态因果结构学习方法OCEAN，以解决传统方法仅限于离线应用和单模态数据的局限性。OCEAN利用扩张卷积神经网络（dilated convolutional neural network）捕获长期时间依赖、图神经网络（graph neural networks）学习系统实体与关键性能指标（key performance indicators）间的因果关系，并通过多因素注意力机制（multi-factor attention mechanism）和基于对比互信息最大化的图融合模块（contrastive mutual information maximization-based graph fusion module）来处理多模态数据的交互。实验在三个真实世界数据集上验证了OCEAN的有效性和效率，显著提升了根因定位的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10021v1",
      "published_date": "2024-10-13 21:47:36 UTC",
      "updated_date": "2024-10-13 21:47:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:52:16.179964"
    },
    {
      "arxiv_id": "2410.10020v1",
      "title": "Adaptive Reasoning and Acting in Medical Language Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Dutta",
        "Yen-Che Hsiao"
      ],
      "abstract": "This paper presents an innovative large language model (LLM) agent framework\nfor enhancing diagnostic accuracy in simulated clinical environments using the\nAgentClinic benchmark. The proposed automatic correction enables doctor agents\nto iteratively refine their reasoning and actions following incorrect\ndiagnoses, fostering improved decision-making over time. Experiments show that\nthe implementation of the adaptive LLM-based doctor agents achieve correct\ndiagnoses through dynamic interactions with simulated patients. The evaluations\nhighlight the capacity of autonomous agents to adapt and improve in complex\nmedical scenarios. Future enhancements will focus on refining the algorithm and\nexpanding its applicability across a wider range of tasks and different large\nlanguage models.",
      "tldr_zh": "本研究提出了一种基于大型语言模型(LLM)的代理框架，用于提升模拟临床环境中的诊断准确性，特别是在AgentClinic基准上的应用。该框架引入自动修正机制，使医生代理能够在诊断错误后迭代优化推理和行动，通过与模拟患者的动态交互实现决策改进。实验结果显示，该适应性LLM代理能够成功实现正确诊断，并在复杂医疗场景中展现出自主适应和提升的能力。未来工作将聚焦于算法优化，并扩展其适用范围至更多任务和不同LLM模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10020v1",
      "published_date": "2024-10-13 21:45:16 UTC",
      "updated_date": "2024-10-13 21:45:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:52:26.528413"
    },
    {
      "arxiv_id": "2410.10018v1",
      "title": "Improving accuracy and convergence of federated learning edge computing methods for generalized DER forecasting applications in power grid",
      "title_zh": "翻译失败",
      "authors": [
        "Vineet Jagadeesan Nair",
        "Lucas Pereira"
      ],
      "abstract": "This proposal aims to develop more accurate federated learning (FL) methods\nwith faster convergence properties and lower communication requirements,\nspecifically for forecasting distributed energy resources (DER) such as\nrenewables, energy storage, and loads in modern, low-carbon power grids. This\nwill be achieved by (i) leveraging recently developed extensions of FL such as\nhierarchical and iterative clustering to improve performance with non-IID data,\n(ii) experimenting with different types of FL global models well-suited to\ntime-series data, and (iii) incorporating domain-specific knowledge from power\nsystems to build more general FL frameworks and architectures that can be\napplied to diverse types of DERs beyond just load forecasting, and with\nheterogeneous clients.",
      "tldr_zh": "该研究旨在改进联邦学习（FL）方法，以提升分布式能源资源（DER）预测的准确性、收敛速度和通信效率，适用于现代低碳电力网格。该方法通过利用分层和迭代聚类等 FL 扩展来处理非独立同分布（non-IID）数据，实验不同类型的 FL 全局模型以适应时间序列数据，并整合电力系统的领域知识构建通用框架。该框架支持多种 DER 类型和异构客户端的应用，有望扩展 FL 在 DER 预测中的实际部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at the NeurIPS 2022 Tackling Climate Change with Machine\n  Learning workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.10018v1",
      "published_date": "2024-10-13 21:34:00 UTC",
      "updated_date": "2024-10-13 21:34:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:52:39.174235"
    },
    {
      "arxiv_id": "2410.10014v1",
      "title": "Safety-Aware Fine-Tuning of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hyeong Kyu Choi",
        "Xuefeng Du",
        "Yixuan Li"
      ],
      "abstract": "Fine-tuning Large Language Models (LLMs) has emerged as a common practice for\ntailoring models to individual needs and preferences. The choice of datasets\nfor fine-tuning can be diverse, introducing safety concerns regarding the\npotential inclusion of harmful data samples. Manually filtering or avoiding\nsuch samples, however, can be labor-intensive and subjective. To address these\ndifficulties, we propose a novel Safety-Aware Fine-Tuning (SAFT) framework\ndesigned to automatically detect and remove potentially harmful data, by\nleveraging a scoring function that exploits the subspace information of harmful\nand benign samples. Experimental results demonstrate the efficacy of SAFT\nacross different LLMs and varying contamination rates, achieving reductions in\nharmfulness of up to 27.8%. Going beyond, we delve into the mechanism of our\napproach and validate its versatility in addressing practical challenges in\nreal-world scenarios.",
      "tldr_zh": "该论文提出 Safety-Aware Fine-Tuning (SAFT) 框架，用于微调 Large Language Models (LLMs) 时自动检测并移除潜在有害数据样本，以解决数据集多样性带来的安全风险。SAFT 通过一个基于有害和良性样本子空间信息的评分函数，实现高效的自动过滤，而无需主观手动干预。实验结果显示，该框架在不同 LLMs 和污染率下有效，减少有害性高达 27.8%，并验证了其在实际场景中的机制和实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024 Workshop on Safe Generative AI",
      "pdf_url": "http://arxiv.org/pdf/2410.10014v1",
      "published_date": "2024-10-13 21:24:25 UTC",
      "updated_date": "2024-10-13 21:24:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:52:51.111798"
    },
    {
      "arxiv_id": "2410.10011v1",
      "title": "Learning Interpretable Classifiers for PDDL Planning",
      "title_zh": "学习 PDDL 规划的可解释分类器",
      "authors": [
        "Arnaud Lequen"
      ],
      "abstract": "We consider the problem of synthesizing interpretable models that recognize\nthe behaviour of an agent compared to other agents, on a whole set of similar\nplanning tasks expressed in PDDL. Our approach consists in learning logical\nformulas, from a small set of examples that show how an agent solved small\nplanning instances. These formulas are expressed in a version of First-Order\nTemporal Logic (FTL) tailored to our planning formalism. Such formulas are\nhuman-readable, serve as (partial) descriptions of an agent's policy, and\ngeneralize to unseen instances. We show that learning such formulas is\ncomputationally intractable, as it is an NP-hard problem. As such, we propose\nto learn these behaviour classifiers through a topology-guided compilation to\nMaxSAT, which allows us to generate a wide range of different formulas.\nExperiments show that interesting and accurate formulas can be learned in\nreasonable time.",
      "tldr_zh": "这篇论文提出了一种方法，用于学习可解释的分类器，以识别代理在 PDDL 规划任务中的行为，基于少量示例学习 First-Order Temporal Logic (FTL) 逻辑公式作为代理策略的描述。公式采用定制的 FTL 表达形式，确保可读性和泛化能力，能够应用于未见实例。尽管学习此类公式是 NP-hard 问题，作者通过 topology-guided 编译到 MaxSAT 的方式生成多种公式。实验结果表明，该方法能在合理时间内学习到准确且有意义的公式。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10011v1",
      "published_date": "2024-10-13 21:12:45 UTC",
      "updated_date": "2024-10-13 21:12:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:53:04.514617"
    },
    {
      "arxiv_id": "2410.10009v2",
      "title": "Enhancing Peer Review in Astronomy: A Machine Learning and Optimization Approach to Reviewer Assignments for ALMA",
      "title_zh": "翻译失败",
      "authors": [
        "John M. Carpenter",
        "Andrea Corvillón",
        "Nihar B. Shah"
      ],
      "abstract": "The increasing volume of papers and proposals that undergo peer review\nemphasizes the pressing need for greater automation to effectively manage the\ngrowing scale. In this study, we present the deployment and evaluation of\nmachine learning and optimization techniques to assign proposals to reviewers\nthat were developed for the Atacama Large Millimeter/submillimeter Array (ALMA)\nduring the Cycle 10 Call for Proposals issued in 2023. Using topic modeling\nalgorithms, we identify the proposal topics and assess reviewers' expertise\nbased on their previous ALMA proposal submissions. We then apply an adapted\nversion of the assignment optimization algorithm from PeerReview4All (Stelmakh\net al. 2021) to maximize the alignment between proposal topics and reviewer\nexpertise. Our evaluation shows a significant improvement in matching reviewer\nexpertise: the median similarity score between the proposal topic and reviewer\nexpertise increased by 51 percentage points compared to the previous cycle, and\nthe percentage of reviewers reporting expertise in their assigned proposals\nrose by 20 percentage points. Furthermore, the assignment process proved highly\neffective in that no proposals required reassignment due to significant\nmismatches, resulting in a savings of 3 to 5 days of manual effort.",
      "tldr_zh": "本研究针对天文学领域 ALMA 的提案评审过程，引入 machine learning 和 optimization 技术，以自动化审稿人分配并提升匹配效率。通过 topic modeling 算法识别提案主题，并基于审稿人以往 ALMA 提交评估其专业知识，然后应用从 PeerReview4All 适配的优化算法最大化主题与专业知识的匹配。结果表明，提案与审稿人专业知识的相似度中位数提高了 51 个百分点，审稿人报告的专业覆盖率增加了 20 个百分点，且无需重新分配，节省了 3 到 5 天的手动工作。该方法显著提高了评审过程的准确性和效率，为大规模同行评审提供了可扩展的解决方案。",
      "categories": [
        "astro-ph.IM",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "16 pages, 5 figures, revised version accepted by PASP",
      "pdf_url": "http://arxiv.org/pdf/2410.10009v2",
      "published_date": "2024-10-13 21:06:00 UTC",
      "updated_date": "2025-02-18 23:11:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:53:15.769643"
    },
    {
      "arxiv_id": "2410.12867v1",
      "title": "Empowering Dysarthric Speech: Leveraging Advanced LLMs for Accurate Speech Correction and Multimodal Emotion Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Kaushal Attaluri",
        "Anirudh CHVS",
        "Sireesha Chittepu"
      ],
      "abstract": "Dysarthria is a motor speech disorder caused by neurological damage that\naffects the muscles used for speech production, leading to slurred, slow, or\ndifficult-to-understand speech. It affects millions of individuals worldwide,\nincluding those with conditions such as stroke, traumatic brain injury,\ncerebral palsy, Parkinsons disease, and multiple sclerosis. Dysarthria presents\na major communication barrier, impacting quality of life and social\ninteraction. This paper introduces a novel approach to recognizing and\ntranslating dysarthric speech, empowering individuals with this condition to\ncommunicate more effectively. We leverage advanced large language models for\naccurate speech correction and multimodal emotion analysis. Dysarthric speech\nis first converted to text using OpenAI Whisper model, followed by sentence\nprediction using fine-tuned open-source models and benchmark models like\nGPT-4.o, LLaMA 3.1 70B and Mistral 8x7B on Groq AI accelerators. The dataset\nused combines the TORGO dataset with Google speech data, manually labeled for\nemotional context. Our framework identifies emotions such as happiness,\nsadness, neutrality, surprise, anger, and fear, while reconstructing intended\nsentences from distorted speech with high accuracy. This approach demonstrates\nsignificant advancements in the recognition and interpretation of dysarthric\nspeech.",
      "tldr_zh": "本文针对构音障碍（Dysarthria）患者面临的语音障碍问题，提出了一种利用高级大型语言模型（LLMs）进行准确语音校正和多模态情感分析的框架，以提升他们的沟通能力。方法包括先使用OpenAI Whisper模型将dysarthric speech转换为文本，然后通过fine-tuned开源模型和基准模型如GPT-4.o、LLaMA 3.1 70B以及Mistral 8x7B在Groq AI加速器上进行句子预测和情感识别。数据集结合了TORGO数据集与Google语音数据，并手动标注情感，如happiness、sadness、neutrality、surprise、anger和fear。该框架实现了高准确率的意图句子重建，并在dysarthric speech的识别和解释方面取得了显著进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 6 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.12867v1",
      "published_date": "2024-10-13 20:54:44 UTC",
      "updated_date": "2024-10-13 20:54:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:53:29.584917"
    },
    {
      "arxiv_id": "2410.09999v1",
      "title": "Leveraging Customer Feedback for Multi-modal Insight Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Sandeep Sricharan Mukku",
        "Abinesh Kanagarajan",
        "Pushpendu Ghosh",
        "Chetan Aggarwal"
      ],
      "abstract": "Businesses can benefit from customer feedback in different modalities, such\nas text and images, to enhance their products and services. However, it is\ndifficult to extract actionable and relevant pairs of text segments and images\nfrom customer feedback in a single pass. In this paper, we propose a novel\nmulti-modal method that fuses image and text information in a latent space and\ndecodes it to extract the relevant feedback segments using an image-text\ngrounded text decoder. We also introduce a weakly-supervised data generation\ntechnique that produces training data for this task. We evaluate our model on\nunseen data and demonstrate that it can effectively mine actionable insights\nfrom multi-modal customer feedback, outperforming the existing baselines by\n$14$ points in F1 score.",
      "tldr_zh": "该研究针对企业从多模态客户反馈（如文本和图像）中提取可行动洞见的挑战，提出了一种新颖的多模态方法。该方法在latent space中融合图像和文本信息，并使用image-text grounded text decoder来提取相关反馈段，同时引入weakly-supervised数据生成技术以产生训练数据。在未见过的数据上评估，该模型的表现比现有基线高14点F1 score，展示了其在挖掘多模态反馈中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.09999v1",
      "published_date": "2024-10-13 20:45:00 UTC",
      "updated_date": "2024-10-13 20:45:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:53:38.772880"
    },
    {
      "arxiv_id": "2410.09998v1",
      "title": "SlimSeiz: Efficient Channel-Adaptive Seizure Prediction Using a Mamba-Enhanced Network",
      "title_zh": "翻译失败",
      "authors": [
        "Guorui Lu",
        "Jing Peng",
        "Bingyuan Huang",
        "Chang Gao",
        "Todor Stefanov",
        "Yong Hao",
        "Qinyu Chen"
      ],
      "abstract": "Epileptic seizures cause abnormal brain activity, and their unpredictability\ncan lead to accidents, underscoring the need for long-term seizure prediction.\nAlthough seizures can be predicted by analyzing electroencephalogram (EEG)\nsignals, existing methods often require too many electrode channels or larger\nmodels, limiting mobile usability. This paper introduces a SlimSeiz framework\nthat utilizes adaptive channel selection with a lightweight neural network\nmodel. SlimSeiz operates in two states: the first stage selects the optimal\nchannel set for seizure prediction using machine learning algorithms, and the\nsecond stage employs a lightweight neural network based on convolution and\nMamba for prediction. On the Children's Hospital Boston-MIT (CHB-MIT) EEG\ndataset, SlimSeiz can reduce channels from 22 to 8 while achieving a\nsatisfactory result of 94.8% accuracy, 95.5% sensitivity, and 94.0% specificity\nwith only 21.2K model parameters, matching or outperforming larger models'\nperformance. We also validate SlimSeiz on a new EEG dataset, SRH-LEI, collected\nfrom Shanghai Renji Hospital, demonstrating its effectiveness across different\npatients. The code and SRH-LEI dataset are available at\nhttps://github.com/guoruilu/SlimSeiz.",
      "tldr_zh": "本研究提出 SlimSeiz 框架，用于高效的自适应通道选择癫痫发作预测，解决现有 EEG 分析方法依赖过多电极通道或大型模型的问题。框架分为两阶段：第一阶段使用机器学习算法选择最优通道集，第二阶段采用基于卷积和 Mamba 的轻量级神经网络进行预测。在 CHB-MIT EEG 数据集上，SlimSeiz 将通道从 22 减至 8，同时实现 94.8% 准确率、95.5% 敏感性和 94.0% 特异性，仅需 21.2K 参数，与大型模型相当或更优。此外，在新的 SRH-LEI 数据集上验证了其有效性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.09998v1",
      "published_date": "2024-10-13 20:43:01 UTC",
      "updated_date": "2024-10-13 20:43:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:53:51.129611"
    },
    {
      "arxiv_id": "2410.09997v1",
      "title": "Collu-Bench: A Benchmark for Predicting Language Model Hallucinations in Code",
      "title_zh": "Collu-Bench：用于预测代码中语言模型幻觉的基准测试",
      "authors": [
        "Nan Jiang",
        "Qi Li",
        "Lin Tan",
        "Tianyi Zhang"
      ],
      "abstract": "Despite their success, large language models (LLMs) face the critical\nchallenge of hallucinations, generating plausible but incorrect content. While\nmuch research has focused on hallucinations in multiple modalities including\nimages and natural language text, less attention has been given to\nhallucinations in source code, which leads to incorrect and vulnerable code\nthat causes significant financial loss. To pave the way for research in LLMs'\nhallucinations in code, we introduce Collu-Bench, a benchmark for predicting\ncode hallucinations of LLMs across code generation (CG) and automated program\nrepair (APR) tasks. Collu-Bench includes 13,234 code hallucination instances\ncollected from five datasets and 11 diverse LLMs, ranging from open-source\nmodels to commercial ones. To better understand and predict code\nhallucinations, Collu-Bench provides detailed features such as the per-step log\nprobabilities of LLMs' output, token types, and the execution feedback of LLMs'\ngenerated code for in-depth analysis. In addition, we conduct experiments to\npredict hallucination on Collu-Bench, using both traditional machine learning\ntechniques and neural networks, which achieves 22.03 -- 33.15% accuracy. Our\nexperiments draw insightful findings of code hallucination patterns, reveal the\nchallenge of accurately localizing LLMs' hallucinations, and highlight the need\nfor more sophisticated techniques.",
      "tldr_zh": "本论文引入 Collu-Bench，一个基准数据集，用于预测大型语言模型(LLMs)在代码生成(CG)和自动程序修复(APR)任务中的幻觉问题。Collu-Bench 包含 13,234 个代码幻觉实例，从五个数据集和 11 个多样化 LLMs（如开源和商业模型）中收集，并提供详细特征，包括每步 log probabilities、token 类型和代码执行反馈，以支持深入分析。实验结果显示，使用传统机器学习和神经网络的预测准确率达到 22.03% 到 33.15%，揭示了代码幻觉的模式、定位挑战，并强调了开发更先进技术的必要性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09997v1",
      "published_date": "2024-10-13 20:41:47 UTC",
      "updated_date": "2024-10-13 20:41:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:54:03.109823"
    },
    {
      "arxiv_id": "2410.09988v2",
      "title": "HARDMath: A Benchmark Dataset for Challenging Problems in Applied Mathematics",
      "title_zh": "HARDMath：应用数学挑战性问题的基准数据集",
      "authors": [
        "Jingxuan Fan",
        "Sarah Martinson",
        "Erik Y. Wang",
        "Kaylie Hausknecht",
        "Jonah Brenner",
        "Danxian Liu",
        "Nianli Peng",
        "Corey Wang",
        "Michael P. Brenner"
      ],
      "abstract": "Advanced applied mathematics problems are underrepresented in existing Large\nLanguage Model (LLM) benchmark datasets. To address this, we introduce\nHARDMath, a dataset inspired by a graduate course on asymptotic methods,\nfeaturing challenging applied mathematics problems that require analytical\napproximation techniques. These problems demand a combination of mathematical\nreasoning, computational tools, and subjective judgment, making them difficult\nfor LLMs. Our framework auto-generates a large number of problems with\nsolutions validated against numerical ground truths. We evaluate both open- and\nclosed-source LLMs on HARDMath-mini, a sub-sampled test set of 366 problems, as\nwell as on 40 word problems formulated in applied science contexts. Even\nleading closed-source models like GPT-4 achieve only 43.8% overall accuracy\nwith few-shot Chain-of-Thought prompting, and all models demonstrate\nsignificantly lower performance compared to results on existing mathematics\nbenchmark datasets. We additionally conduct a detailed error analysis to gain\ninsights into the failure cases of LLMs. These results demonstrate limitations\nof current LLM performance on advanced graduate-level applied math problems and\nunderscore the importance of datasets like HARDMath to advance mathematical\nabilities of LLMs.",
      "tldr_zh": "本文提出 HARDMath 数据集，这是一个针对高级应用数学问题的基准集，灵感来源于渐近方法研究生课程，包含需要数学推理、计算工具和主观判断的挑战性问题。数据集通过自动生成框架创建大量问题，并使用数值真实值验证解决方案；在评估中，领先的 LLM 如 GPT-4 在 HARDMath-mini（366 个问题子集）和应用科学语境的 40 个文字问题上，仅达到 43.8% 的整体准确率，且远低于现有数学基准数据集的性能。研究通过详细错误分析揭示了 LLM 在研究生级应用数学上的局限性，并强调此类数据集对提升 LLM 数学能力的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code and the HARDMath dataset is available at\n  https://github.com/sarahmart/HARDMath",
      "pdf_url": "http://arxiv.org/pdf/2410.09988v2",
      "published_date": "2024-10-13 20:09:41 UTC",
      "updated_date": "2024-12-13 22:03:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:54:16.056832"
    },
    {
      "arxiv_id": "2410.09979v1",
      "title": "Facial Width-to-Height Ratio Does Not Predict Self-Reported Behavioral Tendencies",
      "title_zh": "翻译失败",
      "authors": [
        "Michal Kosinski"
      ],
      "abstract": "A growing number of studies have linked facial width-to-height ratio (fWHR)\nwith various antisocial or violent behavioral tendencies. However, those\nstudies have predominantly been laboratory based and low powered. This work\nreexamined the links between fWHR and behavioral tendencies in a large sample\nof 137,163 participants. Behavioral tendencies were measured using 55\nwell-established psychometric scales, including self-report scales measuring\nintelligence, domains and facets of the five-factor model of personality,\nimpulsiveness, sense of fairness, sensational interests, self-monitoring,\nimpression management, and satisfaction with life. The findings revealed that\nfWHR is not substantially linked with any of these self-reported measures of\nbehavioral tendencies, calling into question whether the links between fWHR and\nbehavior generalize beyond the small samples and specific experimental settings\nthat have been used in past fWHR research.",
      "tldr_zh": "这篇论文调查了面部宽度高度比 (fWHR) 是否能预测自报行为倾向，基于先前研究中发现的潜在关联。研究使用 137,163 名参与者的庞大数据集和 55 个心理测量量表，包括五因素人格模型 (five-factor model)、冲动性 (impulsiveness)、公平感 (sense of fairness) 等，对行为倾向进行评估。结果显示，fWHR 与这些自报行为倾向无显著关联，表明此类关联可能仅限于过去的小样本实验环境，并质疑其普遍性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "Psychological Science (2017)",
      "pdf_url": "http://arxiv.org/pdf/2410.09979v1",
      "published_date": "2024-10-13 19:48:53 UTC",
      "updated_date": "2024-10-13 19:48:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:54:28.126890"
    },
    {
      "arxiv_id": "2410.09972v1",
      "title": "Make the Pertinent Salient: Task-Relevant Reconstruction for Visual Control with Distractions",
      "title_zh": "翻译失败",
      "authors": [
        "Kyungmin Kim",
        "JB Lanier",
        "Pierre Baldi",
        "Charless Fowlkes",
        "Roy Fox"
      ],
      "abstract": "Recent advancements in Model-Based Reinforcement Learning (MBRL) have made it\na powerful tool for visual control tasks. Despite improved data efficiency, it\nremains challenging to train MBRL agents with generalizable perception.\nTraining in the presence of visual distractions is particularly difficult due\nto the high variation they introduce to representation learning. Building on\nDREAMER, a popular MBRL method, we propose a simple yet effective auxiliary\ntask to facilitate representation learning in distracting environments. Under\nthe assumption that task-relevant components of image observations are\nstraightforward to identify with prior knowledge in a given task, we use a\nsegmentation mask on image observations to only reconstruct task-relevant\ncomponents. In doing so, we greatly reduce the complexity of representation\nlearning by removing the need to encode task-irrelevant objects in the latent\nrepresentation. Our method, Segmentation Dreamer (SD), can be used either with\nground-truth masks easily accessible in simulation or by leveraging potentially\nimperfect segmentation foundation models. The latter is further improved by\nselectively applying the reconstruction loss to avoid providing misleading\nlearning signals due to mask prediction errors. In modified DeepMind Control\nsuite (DMC) and Meta-World tasks with added visual distractions, SD achieves\nsignificantly better sample efficiency and greater final performance than prior\nwork. We find that SD is especially helpful in sparse reward tasks otherwise\nunsolvable by prior work, enabling the training of visually robust agents\nwithout the need for extensive reward engineering.",
      "tldr_zh": "本研究针对Model-Based Reinforcement Learning (MBRL)在视觉控制任务中处理视觉干扰的挑战，提出了一种名为Segmentation Dreamer (SD)的改进方法。\nSD通过使用分割掩码仅重建图像观察中的任务相关组件，简化表示学习过程，避免编码无关对象，从而提升了在干扰环境下的鲁棒性。\n实验结果显示，在修改后的DeepMind Control suite和Meta-World任务中，SD显著提高了样本效率和最终性能，尤其在稀疏奖励任务中，帮助训练出视觉鲁棒代理，而无需额外奖励工程。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09972v1",
      "published_date": "2024-10-13 19:24:07 UTC",
      "updated_date": "2024-10-13 19:24:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:54:39.576499"
    },
    {
      "arxiv_id": "2410.09967v1",
      "title": "Improving 3D Few-Shot Segmentation with Inference-Time Pseudo-Labeling",
      "title_zh": "通过推理时伪标签改善3D少样本分割",
      "authors": [
        "Mohammad Mozafari",
        "Hosein Hasani",
        "Reza Vahidimajd",
        "Mohamadreza Fereydooni",
        "Mahdieh Soleymani Baghshah"
      ],
      "abstract": "In recent years, few-shot segmentation (FSS) models have emerged as a\npromising approach in medical imaging analysis, offering remarkable\nadaptability to segment novel classes with limited annotated data. Existing\napproaches to few-shot segmentation have often overlooked the potential of the\nquery itself, failing to fully utilize the valuable information it contains.\nHowever, treating the query as unlabeled data provides an opportunity to\nenhance prediction accuracy. Specifically in the domain of medical imaging, the\nvolumetric structure of queries offers a considerable source of valuable\ninformation that can be used to improve the target slice segmentation. In this\nwork, we present a novel strategy to efficiently leverage the intrinsic\ninformation of the query sample for final segmentation during inference. First,\nwe use the support slices from a reference volume to generate an initial\nsegmentation score for the query slices through a prototypical approach.\nSubsequently, we apply a confidence-aware pseudo-labeling procedure to transfer\nthe most informative parts of query slices to the support set. The final\nprediction is performed based on the new expanded support set, enabling the\nprediction of a more accurate segmentation mask for the query volume. Extensive\nexperiments show that the proposed method can effectively boost performance\nacross diverse settings and datasets.",
      "tldr_zh": "本文提出了一种改进 3D Few-Shot Segmentation 的新策略，通过 Inference-Time Pseudo-Labeling 在推理阶段利用查询样本的内在信息来提升分割准确性。具体方法包括：首先使用支持切片（support slices）通过原型方法生成查询切片的初始分割分数，然后应用置信度aware的伪标签过程，将查询切片中最具信息性的部分转移到扩展的支持集，最后基于新支持集进行更精确的预测。实验结果表明，该方法在医疗图像分析的多种设置和数据集上有效提升了性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09967v1",
      "published_date": "2024-10-13 19:07:07 UTC",
      "updated_date": "2024-10-13 19:07:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:54:51.341527"
    },
    {
      "arxiv_id": "2410.09964v1",
      "title": "Lower-dimensional projections of cellular expression improves cell type classification from single-cell RNA sequencing",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Umar",
        "Muhammad Asif",
        "Arif Mahmood"
      ],
      "abstract": "Single-cell RNA sequencing (scRNA-seq) enables the study of cellular\ndiversity at single cell level. It provides a global view of cell-type\nspecification during the onset of biological mechanisms such as developmental\nprocesses and human organogenesis. Various statistical, machine and deep\nlearning-based methods have been proposed for cell-type classification. Most of\nthe methods utilizes unsupervised lower dimensional projections obtained from\nfor a large reference data. In this work, we proposed a reference-based method\nfor cell type classification, called EnProCell. The EnProCell, first, computes\nlower dimensional projections that capture both the high variance and class\nseparability through an ensemble of principle component analysis and multiple\ndiscriminant analysis. In the second phase, EnProCell trains a deep neural\nnetwork on the lower dimensional representation of data to classify cell types.\nThe proposed method outperformed the existing state-of-the-art methods when\ntested on four different data sets produced from different single-cell\nsequencing technologies. The EnProCell showed higher accuracy (98.91) and F1\nscore (98.64) than other methods for predicting reference from reference\ndatasets. Similarly, EnProCell also showed better performance than existing\nmethods in predicting cell types for data with unknown cell types (query) from\nreference datasets (accuracy:99.52; F1 score: 99.07). In addition to improved\nperformance, the proposed methodology is simple and does not require more\ncomputational resources and time. the EnProCell is available at\nhttps://github.com/umar1196/EnProCell.",
      "tldr_zh": "本研究提出了一种名为 EnProCell 的参考-based 方法，用于提升 single-cell RNA sequencing (scRNA-seq) 数据中细胞类型分类的准确性。EnProCell 通过集成 principal component analysis (PCA) 和 multiple discriminant analysis (MDA) 计算低维投影，以捕捉高方差和类可分性，然后在这些投影上训练 deep neural network 进行分类。该方法在四个不同数据集上测试时，优于现有 state-of-the-art 方法，实现了高达98.91%的准确率和98.64%的 F1 分数，尤其在预测未知细胞类型时表现突出（准确率99.52%、F1 分数99.07%）。此外，EnProCell 设计简单，不需额外计算资源和时间，便于实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09964v1",
      "published_date": "2024-10-13 19:01:38 UTC",
      "updated_date": "2024-10-13 19:01:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:55:04.073108"
    },
    {
      "arxiv_id": "2410.09954v1",
      "title": "EITNet: An IoT-Enhanced Framework for Real-Time Basketball Action Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyu Liu",
        "Xinyu Liu",
        "Mingzhe Qu",
        "Tianyi Lyu"
      ],
      "abstract": "Integrating IoT technology into basketball action recognition enhances sports\nanalytics, providing crucial insights into player performance and game\nstrategy. However, existing methods often fall short in terms of accuracy and\nefficiency, particularly in complex, real-time environments where player\nmovements are frequently occluded or involve intricate interactions. To\novercome these challenges, we propose the EITNet model, a deep learning\nframework that combines EfficientDet for object detection, I3D for\nspatiotemporal feature extraction, and TimeSformer for temporal analysis, all\nintegrated with IoT technology for seamless real-time data collection and\nprocessing. Our contributions include developing a robust architecture that\nimproves recognition accuracy to 92\\%, surpassing the baseline EfficientDet\nmodel's 87\\%, and reducing loss to below 5.0 compared to EfficientDet's 9.0\nover 50 epochs. Furthermore, the integration of IoT technology enhances\nreal-time data processing, providing adaptive insights into player performance\nand strategy. The paper details the design and implementation of EITNet,\nexperimental validation, and a comprehensive evaluation against existing\nmodels. The results demonstrate EITNet's potential to significantly advance\nautomated sports analysis and optimize data utilization for player performance\nand strategy improvement.",
      "tldr_zh": "本研究提出 EITNet 框架，通过整合 IoT 技术，实现篮球动作的实时识别，解决现有方法在复杂环境（如动作遮挡和互动）中的准确性和效率问题。EITNet 结合 EfficientDet 用于对象检测、I3D 用于时空特征提取，以及 TimeSformer 用于时间分析，实现无缝的实时数据收集和处理。实验结果显示，该框架将识别准确率提升至 92%，比基线 EfficientDet 的 87% 高，且将损失降低至低于 5.0，与 EfficientDet 的 9.0 相比显著改善。总体上，EITNet 能推进自动化体育分析，并优化球员表现和策略的实时洞见。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "pages",
      "pdf_url": "http://arxiv.org/pdf/2410.09954v1",
      "published_date": "2024-10-13 18:21:15 UTC",
      "updated_date": "2024-10-13 18:21:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:55:14.948570"
    },
    {
      "arxiv_id": "2410.19769v1",
      "title": "Real-time Monitoring of Lower Limb Movement Resistance Based on Deep Learning",
      "title_zh": "基于深度学习的下肢运动阻力实时监测",
      "authors": [
        "Buren Batu",
        "Yuanmeng Liu",
        "Tianyi Lyu"
      ],
      "abstract": "Real-time lower limb movement resistance monitoring is critical for various\napplications in clinical and sports settings, such as rehabilitation and\nathletic training. Current methods often face limitations in accuracy,\ncomputational efficiency, and generalizability, which hinder their practical\nimplementation. To address these challenges, we propose a novel Mobile\nMulti-Task Learning Network (MMTL-Net) that integrates MobileNetV3 for\nefficient feature extraction and employs multi-task learning to simultaneously\npredict resistance levels and recognize activities. The advantages of MMTL-Net\ninclude enhanced accuracy, reduced latency, and improved computational\nefficiency, making it highly suitable for real-time applications. Experimental\nresults demonstrate that MMTL-Net significantly outperforms existing models on\nthe UCI Human Activity Recognition and Wireless Sensor Data Mining Activity\nPrediction datasets, achieving a lower Force Error Rate (FER) of 6.8% and a\nhigher Resistance Prediction Accuracy (RPA) of 91.2%. Additionally, the model\nshows a Real-time Responsiveness (RTR) of 12 milliseconds and a Throughput (TP)\nof 33 frames per second. These findings underscore the model's robustness and\neffectiveness in diverse real-world scenarios. The proposed framework not only\nadvances the state-of-the-art in resistance monitoring but also paves the way\nfor more efficient and accurate systems in clinical and sports applications. In\nreal-world settings, the practical implications of MMTL-Net include its\npotential to enhance patient outcomes in rehabilitation and improve athletic\nperformance through precise, real-time monitoring and feedback.",
      "tldr_zh": "该研究针对下肢运动阻力的实时监控问题，提出了一种新型 Mobile Multi-Task Learning Network (MMTL-Net)，它整合 MobileNetV3 用于高效特征提取，并采用多任务学习同时预测阻力水平和识别活动，从而解决现有方法的准确性、计算效率和泛化性不足。实验结果显示，MMTL-Net 在 UCI Human Activity Recognition 和 Wireless Sensor Data Mining Activity Prediction 数据集上优于基线模型，实现了 Force Error Rate (FER) 仅 6.8%、Resistance Prediction Accuracy (RPA) 达 91.2%、Real-time Responsiveness (RTR) 12 毫秒和 Throughput (TP) 33 帧/秒。该框架的鲁棒性为临床康复和体育训练提供更精确的实时监控和反馈，推动相关领域的应用创新。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "17 pages paper",
      "pdf_url": "http://arxiv.org/pdf/2410.19769v1",
      "published_date": "2024-10-13 18:19:48 UTC",
      "updated_date": "2024-10-13 18:19:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:55:28.460018"
    },
    {
      "arxiv_id": "2410.12866v2",
      "title": "Towards Homogeneous Lexical Tone Decoding from Heterogeneous Intracranial Recordings",
      "title_zh": "翻译失败",
      "authors": [
        "Di Wu",
        "Siyuan Li",
        "Chen Feng",
        "Lu Cao",
        "Yue Zhang",
        "Jie Yang",
        "Mohamad Sawan"
      ],
      "abstract": "Recent advancements in brain-computer interfaces (BCIs) have enabled the\ndecoding of lexical tones from intracranial recordings, offering the potential\nto restore the communication abilities of speech-impaired tonal language\nspeakers. However, data heterogeneity induced by both physiological and\ninstrumental factors poses a significant challenge for unified invasive brain\ntone decoding. Traditional subject-specific models, which operate under a\nheterogeneous decoding paradigm, fail to capture generalized neural\nrepresentations and cannot effectively leverage data across subjects. To\naddress these limitations, we introduce Homogeneity-Heterogeneity Disentangled\nLearning for neural Representations (H2DiLR), a novel framework that\ndisentangles and learns both the homogeneity and heterogeneity from\nintracranial recordings across multiple subjects. To evaluate H2DiLR, we\ncollected stereoelectroencephalography (sEEG) data from multiple participants\nreading Mandarin materials comprising 407 syllables, representing nearly all\nMandarin characters. Extensive experiments demonstrate that H2DiLR, as a\nunified decoding paradigm, significantly outperforms the conventional\nheterogeneous decoding approach. Furthermore, we empirically confirm that\nH2DiLR effectively captures both homogeneity and heterogeneity during neural\nrepresentation learning.",
      "tldr_zh": "该研究针对脑机接口(BCIs)中从异质颅内记录解码词汇语调的挑战，提出H2DiLR框架，以分离并学习跨多个主体的同质性和异质性神经表示，从而实现统一的脑部语调解码。H2DiLR通过收集多参与者阅读普通话材料的立体脑电图(sEEG)数据（包括407个音节），解决了传统主体特定模型的局限性。实验结果显示，H2DiLR显著优于传统异质解码方法，并证实其在神经表示学习中有效捕捉同质性和异质性，为恢复声调语言使用者沟通能力提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS",
        "q-bio.NC"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR2025 Poster (Preprint V2)",
      "pdf_url": "http://arxiv.org/pdf/2410.12866v2",
      "published_date": "2024-10-13 18:09:12 UTC",
      "updated_date": "2025-02-18 12:28:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:55:39.878510"
    },
    {
      "arxiv_id": "2410.09948v1",
      "title": "State of NLP in Kenya: A Survey",
      "title_zh": "肯尼亚的 NLP 现状：一个调查",
      "authors": [
        "Cynthia Jayne Amol",
        "Everlyn Asiko Chimoto",
        "Rose Delilah Gesicho",
        "Antony M. Gitau",
        "Naome A. Etori",
        "Caringtone Kinyanjui",
        "Steven Ndung'u",
        "Lawrence Moruye",
        "Samson Otieno Ooko",
        "Kavengi Kitonga",
        "Brian Muhia",
        "Catherine Gitau",
        "Antony Ndolo",
        "Lilian D. A. Wanzare",
        "Albert Njoroge Kahira",
        "Ronald Tombe"
      ],
      "abstract": "Kenya, known for its linguistic diversity, faces unique challenges and\npromising opportunities in advancing Natural Language Processing (NLP)\ntechnologies, particularly for its underrepresented indigenous languages. This\nsurvey provides a detailed assessment of the current state of NLP in Kenya,\nemphasizing ongoing efforts in dataset creation, machine translation, sentiment\nanalysis, and speech recognition for local dialects such as Kiswahili, Dholuo,\nKikuyu, and Luhya. Despite these advancements, the development of NLP in Kenya\nremains constrained by limited resources and tools, resulting in the\nunderrepresentation of most indigenous languages in digital spaces. This paper\nuncovers significant gaps by critically evaluating the available datasets and\nexisting NLP models, most notably the need for large-scale language models and\nthe insufficient digital representation of Indigenous languages. We also\nanalyze key NLP applications: machine translation, information retrieval, and\nsentiment analysis-examining how they are tailored to address local linguistic\nneeds. Furthermore, the paper explores the governance, policies, and\nregulations shaping the future of AI and NLP in Kenya and proposes a strategic\nroadmap to guide future research and development efforts. Our goal is to\nprovide a foundation for accelerating the growth of NLP technologies that meet\nKenya's diverse linguistic demands.",
      "tldr_zh": "这项调查评估了肯尼亚在Natural Language Processing (NLP)领域的现状，强调其语言多样性带来的挑战和机遇，特别是针对Kiswahili、Dholuo、Kikuyu和Luhya等本土语言的进展，包括数据集创建、machine translation、sentiment analysis和speech recognition。研究发现，资源和工具的有限导致这些语言在数字空间中代表不足，并突出了现有数据集和NLP模型的不足，如缺乏大规模语言模型。论文分析了关键NLP应用如何适应本地需求，并探讨了治理、政策和法规的影响。最终，它提出一个战略路线图，以加速NLP技术的发展，满足肯尼亚的多样化语言需求。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.09948v1",
      "published_date": "2024-10-13 18:08:24 UTC",
      "updated_date": "2024-10-13 18:08:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:55:52.241224"
    },
    {
      "arxiv_id": "2410.09940v2",
      "title": "Generalized Group Data Attribution",
      "title_zh": "翻译失败",
      "authors": [
        "Dan Ley",
        "Suraj Srinivas",
        "Shichang Zhang",
        "Gili Rusak",
        "Himabindu Lakkaraju"
      ],
      "abstract": "Data Attribution (DA) methods quantify the influence of individual training\ndata points on model outputs and have broad applications such as\nexplainability, data selection, and noisy label identification. However,\nexisting DA methods are often computationally intensive, limiting their\napplicability to large-scale machine learning models. To address this\nchallenge, we introduce the Generalized Group Data Attribution (GGDA)\nframework, which computationally simplifies DA by attributing to groups of\ntraining points instead of individual ones. GGDA is a general framework that\nsubsumes existing attribution methods and can be applied to new DA techniques\nas they emerge. It allows users to optimize the trade-off between efficiency\nand fidelity based on their needs. Our empirical results demonstrate that GGDA\napplied to popular DA methods such as Influence Functions, TracIn, and TRAK\nresults in upto 10x-50x speedups over standard DA methods while gracefully\ntrading off attribution fidelity. For downstream applications such as dataset\npruning and noisy label identification, we demonstrate that GGDA significantly\nimproves computational efficiency and maintains effectiveness, enabling\npractical applications in large-scale machine learning scenarios that were\npreviously infeasible.",
      "tldr_zh": "这篇论文提出了 Generalized Group Data Attribution (GGDA) 框架，以简化 Data Attribution (DA) 方法的计算开销，将归因对象从单个训练数据点扩展到数据组，从而提升效率。GGDA 作为通用框架，兼容现有方法如 Influence Functions、TracIn 和 TRAK，并允许用户根据需求优化效率与归因保真度的权衡。实验结果显示，GGDA 使这些方法的速度提升 10x-50x，同时在下游应用如数据集修剪和噪声标签识别中保持了有效性，使其适用于大规模机器学习场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09940v2",
      "published_date": "2024-10-13 17:51:21 UTC",
      "updated_date": "2024-10-21 14:36:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:56:03.691908"
    },
    {
      "arxiv_id": "2410.09928v1",
      "title": "M2M-Gen: A Multimodal Framework for Automated Background Music Generation in Japanese Manga Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Megha Sharma",
        "Muhammad Taimoor Haseeb",
        "Gus Xia",
        "Yoshimasa Tsuruoka"
      ],
      "abstract": "This paper introduces M2M Gen, a multi modal framework for generating\nbackground music tailored to Japanese manga. The key challenges in this task\nare the lack of an available dataset or a baseline. To address these\nchallenges, we propose an automated music generation pipeline that produces\nbackground music for an input manga book. Initially, we use the dialogues in a\nmanga to detect scene boundaries and perform emotion classification using the\ncharacters faces within a scene. Then, we use GPT4o to translate this low level\nscene information into a high level music directive. Conditioned on the scene\ninformation and the music directive, another instance of GPT 4o generates page\nlevel music captions to guide a text to music model. This produces music that\nis aligned with the mangas evolving narrative. The effectiveness of M2M Gen is\nconfirmed through extensive subjective evaluations, showcasing its capability\nto generate higher quality, more relevant and consistent music that complements\nspecific scenes when compared to our baselines.",
      "tldr_zh": "这篇论文介绍了 M2M-Gen，一个多模态框架，利用大型语言模型（如 GPT-4o）来实现日本漫画的自动背景音乐生成。框架首先通过分析漫画对话检测场景边界并进行情感分类（基于人物面部），然后将低级场景信息转化为高级音乐指令，并生成页面级音乐标题来指导文本到音乐模型。最终，生成的音乐与漫画叙事高度对齐，主观评估显示 M2M-Gen 比基线模型在音乐质量、相关性和一致性方面表现出色，从而解决了缺乏数据集和基准的挑战。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09928v1",
      "published_date": "2024-10-13 17:15:59 UTC",
      "updated_date": "2024-10-13 17:15:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:57:09.692523"
    },
    {
      "arxiv_id": "2410.09923v1",
      "title": "Analysis and Design of a Personalized Recommendation System Based on a Dynamic User Interest Model",
      "title_zh": "基于动态用户兴趣模型的个性化推荐系统的分析与设计",
      "authors": [
        "Chunyan Mao",
        "Shuaishuai Huang",
        "Mingxiu Sui",
        "Haowei Yang",
        "Xueshe Wang"
      ],
      "abstract": "With the rapid development of the internet and the explosion of information,\nproviding users with accurate personalized recommendations has become an\nimportant research topic. This paper designs and analyzes a personalized\nrecommendation system based on a dynamic user interest model. The system\ncaptures user behavior data, constructs a dynamic user interest model, and\ncombines multiple recommendation algorithms to provide personalized content to\nusers. The research results show that this system significantly improves\nrecommendation accuracy and user satisfaction. This paper discusses the\nsystem's architecture design, algorithm implementation, and experimental\nresults in detail and explores future research directions.",
      "tldr_zh": "这篇论文分析并设计了一个基于动态用户兴趣模型的个性化推荐系统，以应对互联网信息爆炸带来的挑战。\n系统通过捕获用户行为数据，构建动态用户兴趣模型，并整合多种推荐算法，为用户提供准确的个性化内容。\n研究结果表明，该系统显著提升了推荐准确性和用户满意度，并详细讨论了系统架构设计、算法实现、实验结果以及未来研究方向。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09923v1",
      "published_date": "2024-10-13 17:08:16 UTC",
      "updated_date": "2024-10-13 17:08:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:56:27.279815"
    },
    {
      "arxiv_id": "2410.09918v2",
      "title": "Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces",
      "title_zh": "Dualformer：通过随机推理轨迹学习实现的可控快速与缓慢思考",
      "authors": [
        "DiJia Su",
        "Sainbayar Sukhbaatar",
        "Michael Rabbat",
        "Yuandong Tian",
        "Qinqing Zheng"
      ],
      "abstract": "In human cognition theory, human thinking is governed by two systems: the\nfast and intuitive System 1 and the slower but more deliberative System 2.\nRecent studies have shown that incorporating System 2 process into Transformers\nincluding large language models (LLMs), significantly enhances their reasoning\ncapabilities. Nevertheless, models that purely resemble System 2 thinking\nrequire substantially higher computational costs and are much slower to\nrespond. To address this challenge, we present Dualformer, a single Transformer\nmodel that seamlessly integrates both the fast and slow reasoning modes.\nDualformer is obtained by training on data with randomized reasoning traces,\nwhere different parts of the traces are dropped during training. The dropping\nstrategies are specifically tailored according to the trace structure,\nanalogous to analyzing our thinking process and creating shortcuts with\npatterns. At inference time, our model can be configured to output only the\nsolutions (fast mode) or both the reasoning chain and the final solution (slow\nmode), or automatically decide which mode to engage (auto mode). In all cases,\nDualformer outperforms the corresponding baseline models in both performance\nand computational efficiency: (1) in slow mode, Dualformer optimally solves\nunseen 30 x 30 maze navigation tasks 97.6% of the time, surpassing the\nSearchformer (trained on data with complete reasoning traces) baseline\nperformance of 93.3%, while only using 45.5% fewer reasoning steps; (2) in fast\nmode, Dualformer completes those tasks with an 80% optimal rate, significantly\noutperforming the Solution-Only model (trained on solution-only data), which\nhas an optimal rate of only 30%. For math problems, our techniques have also\nachieved improved performance with LLM fine-tuning, showing its generalization\nbeyond task-specific models.",
      "tldr_zh": "本研究提出Dualformer，一种单Transformer模型，融合人类认知中的System 1（快速直观思考）和System 2（缓慢深思推理），通过在训练中使用随机化推理痕迹（Randomized Reasoning Traces）来实现可控的快速和缓慢模式。训练策略针对痕迹结构设计丢弃机制，模拟思维 shortcuts，提升计算效率。在推理时，Dualformer可切换为快速模式（仅输出解决方案）、缓慢模式（输出推理链和解决方案）或自动模式。实验结果显示，在30x30迷宫导航任务中，缓慢模式下的最优成功率达97.6%，比基线Searchformer高4.3%且减少45.5%推理步骤，而快速模式下的成功率达80%，远超Solution-Only模型的30%；此外，该方法在数学问题上通过LLM微调也显示出良好的泛化性能。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09918v2",
      "published_date": "2024-10-13 16:53:02 UTC",
      "updated_date": "2025-04-10 18:46:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:56:41.030453"
    },
    {
      "arxiv_id": "2410.09908v1",
      "title": "Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Pengfei Jin",
        "Peng Shu",
        "Sekeun Kim",
        "Qing Xiao",
        "Sifan Song",
        "Cheng Chen",
        "Tianming Liu",
        "Xiang Li",
        "Quanzheng Li"
      ],
      "abstract": "Foundation models have become a cornerstone in deep learning, with techniques\nlike Low-Rank Adaptation (LoRA) offering efficient fine-tuning of large models.\nSimilarly, methods such as Retrieval-Augmented Generation (RAG), which leverage\nvectorized databases, have further improved model performance by grounding\noutputs in external information. While these approaches have demonstrated\nnotable success, they often require extensive training or labeled data, which\ncan limit their adaptability in resource-constrained environments. To address\nthese challenges, we introduce Retrieval-based Parameter Ensemble (RPE), a new\nmethod that creates a vectorized database of LoRAs, enabling efficient\nretrieval and application of model adaptations to new tasks. RPE minimizes the\nneed for extensive training and eliminates the requirement for labeled data,\nmaking it particularly effective for zero-shot learning. Additionally, RPE is\nwell-suited for privacy-sensitive domains like healthcare, as it modifies model\nparameters without accessing raw data. When applied to tasks such as medical\nreport generation and image segmentation, RPE not only proved effective but\nalso surpassed supervised fine-tuning methods in certain cases, highlighting\nits potential to enhance both computational efficiency and privacy in deep\nlearning applications.",
      "tldr_zh": "该论文提出了一种名为 Retrieval-based Parameter Ensemble (RPE) 的新方法，作为传统微调的替代方案，用于零样本学习 (zero-shot learning)。RPE 通过构建一个 Low-Rank Adaptation (LoRA) 的向量化数据库，实现模型参数的高效检索和应用，从而减少了对广泛训练和标注数据的依赖，特别适合隐私敏感领域如医疗。实验结果显示，在医疗报告生成和图像分割等任务上，RPE 超过了监督微调方法，不仅提升了计算效率，还加强了隐私保护。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09908v1",
      "published_date": "2024-10-13 16:28:38 UTC",
      "updated_date": "2024-10-13 16:28:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:56:50.549289"
    },
    {
      "arxiv_id": "2410.09904v1",
      "title": "Equitable Access to Justice: Logical LLMs Show Promise",
      "title_zh": "翻译失败",
      "authors": [
        "Manuj Kant",
        "Manav Kant",
        "Marzieh Nabi",
        "Preston Carlson",
        "Megan Ma"
      ],
      "abstract": "The costs and complexity of the American judicial system limit access to\nlegal solutions for many Americans. Large language models (LLMs) hold great\npotential to improve access to justice. However, a major challenge in applying\nAI and LLMs in legal contexts, where consistency and reliability are crucial,\nis the need for System 2 reasoning. In this paper, we explore the integration\nof LLMs with logic programming to enhance their ability to reason, bringing\ntheir strategic capabilities closer to that of a skilled lawyer. Our objective\nis to translate laws and contracts into logic programs that can be applied to\nspecific legal cases, with a focus on insurance contracts. We demonstrate that\nwhile GPT-4o fails to encode a simple health insurance contract into logical\ncode, the recently released OpenAI o1-preview model succeeds, exemplifying how\nLLMs with advanced System 2 reasoning capabilities can expand access to\njustice.",
      "tldr_zh": "该论文探讨了美国司法系统的成本和复杂性如何限制公众对法律解决方案的获取，并强调大语言模型(LLMs) 的潜力来改善司法公平性。作者提出将 LLMs 与逻辑编程整合，以增强其 System 2 reasoning 能力，使其推理水平接近熟练律师，特别是通过将法律和合同（如保险合同）翻译成可应用的逻辑程序。实验结果显示，GPT-4o 无法成功编码一个简单的健康保险合同，而 OpenAI o1-preview 模型则能实现这一任务，证明了具备高级 System 2 reasoning 的 LLMs 如何扩展司法访问并提升可靠性。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09904v1",
      "published_date": "2024-10-13 16:26:07 UTC",
      "updated_date": "2024-10-13 16:26:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:57:03.046176"
    },
    {
      "arxiv_id": "2410.09890v1",
      "title": "Large-Scale 3D Medical Image Pre-training with Geometric Context Priors",
      "title_zh": "大规模 3D 医疗图像预训练，基于几何上下文先验",
      "authors": [
        "Linshan Wu",
        "Jiaxin Zhuang",
        "Hao Chen"
      ],
      "abstract": "The scarcity of annotations poses a significant challenge in medical image\nanalysis. Large-scale pre-training has emerged as a promising label-efficient\nsolution, owing to the utilization of large-scale data, large models, and\nadvanced pre-training techniques. However, its development in medical images\nremains underexplored. The primary challenge lies in harnessing large-scale\nunlabeled data and learning high-level semantics without annotations. We\nobserve that 3D medical images exhibit consistent geometric context, i.e.,\nconsistent geometric relations between different organs, which leads to a\npromising way for learning consistent representations. Motivated by this, we\nintroduce a simple-yet-effective Volume Contrast (VoCo) framework to leverage\ngeometric context priors for self-supervision. Given an input volume, we\nextract base crops from different regions to construct positive and negative\npairs for contrastive learning. Then we predict the contextual position of a\nrandom crop by contrasting its similarity to the base crops. In this way, VoCo\nencodes the inherent geometric context into model representations, facilitating\nhigh-level semantic learning without annotations. Specifically, we (1)\nintroduce the largest medical pre-training dataset PreCT-160K; (2) investigate\nscaling laws and propose guidelines for tailoring different model sizes to\nvarious medical tasks; (3) build a benchmark encompassing 48 medical tasks.\nExtensive experiments highlight the superiority of VoCo. Codes at\nhttps://github.com/Luffy03/Large-Scale-Medical.",
      "tldr_zh": "该研究针对医疗图像分析中标注稀缺的挑战，提出了一种基于几何上下文先验的Volume Contrast (VoCo)框架，用于大规模3D医疗图像的自监督预训练。VoCo通过提取base crops构建正负对进行contrastive learning，并预测随机crop的上下文位置，从而在无标注情况下学习高层次语义。该框架引入了最大的医疗预训练数据集PreCT-160K，研究了scaling laws并提供模型大小适配不同任务的指导原则，同时构建了涵盖48个医疗任务的基准；实验结果证明VoCo在各种任务上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024 Extension",
      "pdf_url": "http://arxiv.org/pdf/2410.09890v1",
      "published_date": "2024-10-13 15:59:26 UTC",
      "updated_date": "2024-10-13 15:59:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:57:21.132682"
    },
    {
      "arxiv_id": "2410.09870v3",
      "title": "ChroKnowledge: Unveiling Chronological Knowledge of Language Models in Multiple Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Yein Park",
        "Chanwoong Yoon",
        "Jungwoo Park",
        "Donghyeon Lee",
        "Minbyul Jeong",
        "Jaewoo Kang"
      ],
      "abstract": "Large language models (LLMs) have brought significant changes to many aspects\nof our lives. However, assessing and ensuring their chronological knowledge\nremains challenging. Existing approaches fall short in addressing the temporal\nadaptability of knowledge, often relying on a fixed time-point view. To\novercome this, we introduce ChroKnowBench, a benchmark dataset designed to\nevaluate chronologically accumulated knowledge across three key aspects:\nmultiple domains, time dependency, temporal state. Our benchmark distinguishes\nbetween knowledge that evolves (e.g., personal history, scientific discoveries,\namended laws) and knowledge that remain constant (e.g., mathematical truths,\ncommonsense facts). Building on this benchmark, we present ChroKnowledge\n(Chronological Categorization of Knowledge), a novel sampling-based framework\nfor evaluating LLMs' non-parametric chronological knowledge. Our evaluation led\nto the following observations: (1) The ability of eliciting temporal knowledge\nvaries depending on the data format that model was trained on. (2) LLMs\npartially recall knowledge or show a cut-off at temporal boundaries rather than\nrecalling all aspects of knowledge correctly. Thus, we apply our\nChroKnowPrompt, an in-depth prompting to elicit chronological knowledge by\ntraversing step-by-step through the surrounding time spans. We observe that it\nsuccessfully recalls objects across both open-source and proprietary LLMs,\ndemonstrating versatility, though it faces challenges with dynamic datasets and\nunstructured formats.",
      "tldr_zh": "这篇论文引入了 ChroKnowBench，一个基准数据集，用于评估大型语言模型（LLMs）在多个领域的 chronological knowledge，包括时间依赖性和时间状态。该数据集区分了演变的知识（如科学发现）和恒定知识（如数学事实），并提出 ChroKnowledge 框架，一个基于采样的方法来评估 LLMs 的非参数时间知识。实验发现，LLMs 的知识提取能力依赖于训练数据格式，且可能出现部分回忆或时间边界截断；为此，作者开发了 ChroKnowPrompt，一种逐步遍历时间跨度的提示技术，能有效在开源和专有模型中回忆知识，但对动态数据集和非结构化格式仍有挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025, 40 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.09870v3",
      "published_date": "2024-10-13 15:08:49 UTC",
      "updated_date": "2025-02-28 08:02:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:57:33.683305"
    },
    {
      "arxiv_id": "2410.09869v1",
      "title": "Prompt Tuning for Audio Deepfake Detection: Computationally Efficient Test-time Domain Adaptation with Limited Target Dataset",
      "title_zh": "音频深度伪造检测的提示调优：计算高效的测试时域适应，使用有限的目标数据集",
      "authors": [
        "Hideyuki Oiso",
        "Yuto Matsunaga",
        "Kazuya Kakizaki",
        "Taiki Miyagawa"
      ],
      "abstract": "We study test-time domain adaptation for audio deepfake detection (ADD),\naddressing three challenges: (i) source-target domain gaps, (ii) limited target\ndataset size, and (iii) high computational costs. We propose an ADD method\nusing prompt tuning in a plug-in style. It bridges domain gaps by integrating\nit seamlessly with state-of-the-art transformer models and/or with other\nfine-tuning methods, boosting their performance on target data (challenge (i)).\nIn addition, our method can fit small target datasets because it does not\nrequire a large number of extra parameters (challenge (ii)). This feature also\ncontributes to computational efficiency, countering the high computational\ncosts typically associated with large-scale pre-trained models in ADD\n(challenge (iii)). We conclude that prompt tuning for ADD under domain gaps\npresents a promising avenue for enhancing accuracy with minimal target data and\nnegligible extra computational burden.",
      "tldr_zh": "这篇论文针对音频深度伪造检测（ADD）中的测试时域适应问题，提出了一种基于提示调优（prompt tuning）的插件式方法，以应对源目标域差距、有限目标数据集和高计算成本的挑战。该方法可无缝集成到状态-of-the-art Transformer模型或其他微调方法中，提升目标数据上的检测性能，同时不需要额外大量参数，从而适应小规模数据集并提高计算效率。实验结果显示，这种方法在域差距环境下显著提升了ADD的准确性，仅需最少的额外计算负担，为高效的ADD应用提供了有前景的解决方案。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at Interspeech 2024. Hideyuki Oiso and Yuto Matsunaga\n  contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2410.09869v1",
      "published_date": "2024-10-13 15:07:35 UTC",
      "updated_date": "2024-10-13 15:07:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:57:45.454014"
    },
    {
      "arxiv_id": "2410.12865v1",
      "title": "ELF-Gym: Evaluating Large Language Models Generated Features for Tabular Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yanlin Zhang",
        "Ning Li",
        "Quan Gan",
        "Weinan Zhang",
        "David Wipf",
        "Minjie Wang"
      ],
      "abstract": "Crafting effective features is a crucial yet labor-intensive and\ndomain-specific task within machine learning pipelines. Fortunately, recent\nadvancements in Large Language Models (LLMs) have shown promise in automating\nvarious data science tasks, including feature engineering. But despite this\npotential, evaluations thus far are primarily based on the end performance of a\ncomplete ML pipeline, providing limited insight into precisely how LLMs behave\nrelative to human experts in feature engineering. To address this gap, we\npropose ELF-Gym, a framework for Evaluating LLM-generated Features. We curated\na new dataset from historical Kaggle competitions, including 251 \"golden\"\nfeatures used by top-performing teams. ELF-Gym then quantitatively evaluates\nLLM-generated features by measuring their impact on downstream model\nperformance as well as their alignment with expert-crafted features through\nsemantic and functional similarity assessments. This approach provides a more\ncomprehensive evaluation of disparities between LLMs and human experts, while\noffering valuable insights into specific areas where LLMs may have room for\nimprovement. For example, using ELF-Gym we empirically demonstrate that, in the\nbest-case scenario, LLMs can semantically capture approximately 56% of the\ngolden features, but at the more demanding implementation level this overlap\ndrops to 13%. Moreover, in other cases LLMs may fail completely, particularly\non datasets that require complex features, indicating broad potential pathways\nfor improvement.",
      "tldr_zh": "该论文提出 ELF-Gym 框架，用于评估 Large Language Models (LLMs) 生成的特征在表格预测中的效果，旨在解决现有评估方法忽略 LLMs 与人类专家在特征工程方面的直接比较问题。ELF-Gym 利用从 Kaggle 比赛中收集的 251 个“黄金”特征数据集，通过测量 LLMs 生成特征对下游模型性能的影响以及与专家特征的语义和功能相似度，进行量化评估。结果显示，LLMs 能语义捕获约 56% 的黄金特征，但实现层面仅 13%，特别是在复杂数据集上可能完全失败，这为 LLMs 在特征工程方面的改进提供了关键洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12865v1",
      "published_date": "2024-10-13 13:59:33 UTC",
      "updated_date": "2024-10-13 13:59:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:57:57.293776"
    },
    {
      "arxiv_id": "2410.09838v2",
      "title": "Uncovering, Explaining, and Mitigating the Superficial Safety of Backdoor Defense",
      "title_zh": "揭示、解释和缓解后门防御的表面",
      "authors": [
        "Rui Min",
        "Zeyu Qin",
        "Nevin L. Zhang",
        "Li Shen",
        "Minhao Cheng"
      ],
      "abstract": "Backdoor attacks pose a significant threat to Deep Neural Networks (DNNs) as\nthey allow attackers to manipulate model predictions with backdoor triggers. To\naddress these security vulnerabilities, various backdoor purification methods\nhave been proposed to purify compromised models. Typically, these purified\nmodels exhibit low Attack Success Rates (ASR), rendering them resistant to\nbackdoored inputs. However, Does achieving a low ASR through current safety\npurification methods truly eliminate learned backdoor features from the\npretraining phase? In this paper, we provide an affirmative answer to this\nquestion by thoroughly investigating the Post-Purification Robustness of\ncurrent backdoor purification methods. We find that current safety purification\nmethods are vulnerable to the rapid re-learning of backdoor behavior, even when\nfurther fine-tuning of purified models is performed using a very small number\nof poisoned samples. Based on this, we further propose the practical\nQuery-based Reactivation Attack (QRA) which could effectively reactivate the\nbackdoor by merely querying purified models. We find the failure to achieve\nsatisfactory post-purification robustness stems from the insufficient deviation\nof purified models from the backdoored model along the backdoor-connected path.\nTo improve the post-purification robustness, we propose a straightforward\ntuning defense, Path-Aware Minimization (PAM), which promotes deviation along\nbackdoor-connected paths with extra model updates. Extensive experiments\ndemonstrate that PAM significantly improves post-purification robustness while\nmaintaining a good clean accuracy and low ASR. Our work provides a new\nperspective on understanding the effectiveness of backdoor safety tuning and\nhighlights the importance of faithfully assessing the model's safety.",
      "tldr_zh": "本文揭示了现有后门防御方法虽能降低攻击成功率（ASR），但未能真正消除后门特征，导致净化后的深度神经网络（DNNs）易于快速重新学习后门行为。作者通过实验发现，这种脆弱性源于净化模型与后门模型在后门连接路径上的偏差不足，并提出了 Query-based Reactivation Attack (QRA)，仅通过简单查询即可重新激活后门。针对此问题，作者引入 Path-Aware Minimization (PAM) 防御方法，通过额外模型更新增强路径偏差，从而显著提高后净化鲁棒性，同时保持良好干净准确率和低 ASR。本研究为评估后门防御的有效性提供了新视角，强调了模型安全评估的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 Spotlight paper. The first two authors contributed\n  equally",
      "pdf_url": "http://arxiv.org/pdf/2410.09838v2",
      "published_date": "2024-10-13 13:37:36 UTC",
      "updated_date": "2024-10-16 15:59:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:58:09.560459"
    },
    {
      "arxiv_id": "2410.09831v1",
      "title": "LoLI-Street: Benchmarking Low-Light Image Enhancement and Beyond",
      "title_zh": "LoLI-Street：低光照图像增强的基准测试与超越",
      "authors": [
        "Md Tanvir Islam",
        "Inzamamul Alam",
        "Simon S. Woo",
        "Saeed Anwar",
        "IK Hyun Lee",
        "Khan Muhammad"
      ],
      "abstract": "Low-light image enhancement (LLIE) is essential for numerous computer vision\ntasks, including object detection, tracking, segmentation, and scene\nunderstanding. Despite substantial research on improving low-quality images\ncaptured in underexposed conditions, clear vision remains critical for\nautonomous vehicles, which often struggle with low-light scenarios, signifying\nthe need for continuous research. However, paired datasets for LLIE are scarce,\nparticularly for street scenes, limiting the development of robust LLIE\nmethods. Despite using advanced transformers and/or diffusion-based models,\ncurrent LLIE methods struggle in real-world low-light conditions and lack\ntraining on street-scene datasets, limiting their effectiveness for autonomous\nvehicles. To bridge these gaps, we introduce a new dataset LoLI-Street\n(Low-Light Images of Streets) with 33k paired low-light and well-exposed images\nfrom street scenes in developed cities, covering 19k object classes for object\ndetection. LoLI-Street dataset also features 1,000 real low-light test images\nfor testing LLIE models under real-life conditions. Furthermore, we propose a\ntransformer and diffusion-based LLIE model named \"TriFuse\". Leveraging the\nLoLI-Street dataset, we train and evaluate our TriFuse and SOTA models to\nbenchmark on our dataset. Comparing various models, our dataset's\ngeneralization feasibility is evident in testing across different mainstream\ndatasets by significantly enhancing images and object detection for practical\napplications in autonomous driving and surveillance systems. The complete code\nand dataset is available on https://github.com/tanvirnwu/TriFuse.",
      "tldr_zh": "本文针对低光图像增强 (LLIE) 的数据集稀缺问题，引入了新基准数据集 LoLI-Street，包含 33k 对街景图像（覆盖 19k 对象类别）和 1,000 张真实低光测试图像，以支持更真实的训练和评估。作者提出了一种基于 transformer 和 diffusion 的模型 TriFuse，用于提升 LLIE 性能，并在 LoLI-Street 上训练并与 SOTA 模型进行基准测试。实验结果显示，TriFuse 显著提高了图像质量和物体检测准确率，并展示了良好的泛化能力，适用于自动驾驶和监控系统的实际场景。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by the Asian Conference on Computer Vision (ACCV 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.09831v1",
      "published_date": "2024-10-13 13:11:56 UTC",
      "updated_date": "2024-10-13 13:11:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:58:32.760029"
    },
    {
      "arxiv_id": "2410.09807v2",
      "title": "Single Ground Truth Is Not Enough: Adding Flexibility to Aspect-Based Sentiment Analysis Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Soyoung Yang",
        "Hojun Cho",
        "Jiyoung Lee",
        "Sohee Yoon",
        "Edward Choi",
        "Jaegul Choo",
        "Won Ik Cho"
      ],
      "abstract": "Aspect-based sentiment analysis (ABSA) is a challenging task of extracting\nsentiments along with their corresponding aspects and opinion terms from the\ntext. The inherent subjectivity of span annotation makes variability in the\nsurface forms of extracted terms, complicating the evaluation process.\nTraditional evaluation methods often constrain ground truths (GT) to a single\nterm, potentially misrepresenting the accuracy of semantically valid\npredictions that differ in surface form. To address this limitation, we propose\na novel and fully automated pipeline that expands existing evaluation sets by\nadding alternative valid terms for aspect and opinion. Our approach facilitates\nan equitable assessment of language models by accommodating multiple-answer\ncandidates, resulting in enhanced human agreement compared to single-answer\ntest sets (achieving up to a 10\\%p improvement in Kendall's Tau score).\nExperimental results demonstrate that our expanded evaluation set helps uncover\nthe capabilities of large language models (LLMs) in ABSA tasks, which is\nconcealed by the single-answer GT sets. Consequently, our work contributes to\nthe development of a flexible evaluation framework for ABSA by embracing\ndiverse surface forms to span extraction tasks in a cost-effective and\nreproducible manner. Our code and dataset is open at\nhttps://github.com/dudrrm/zoom-in-n-out-absa.",
      "tldr_zh": "该论文指出，Aspect-Based Sentiment Analysis (ABSA) 任务在提取文本中的方面、情感和意见术语时，由于标注的主观性，传统评估方法仅使用单一 ground truth (GT) 可能导致对表面形式不同的正确预测评估不公。作者提出一个全新、全自动化的管道，用于扩展现有评估集，通过添加替代的合法术语（alternative valid terms）来支持多答案候选评估，从而提升评估的公平性。实验结果显示，这种方法显著提高了人类一致性（human agreement），Kendall's Tau 分数提升了10%，并揭示了 large language models (LLMs) 在 ABSA 任务中的隐藏能力。总之，该工作为 ABSA 提供了一个灵活、成本有效且可重复的评估框架，并开源了代码和数据集。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 camera-ready",
      "pdf_url": "http://arxiv.org/pdf/2410.09807v2",
      "published_date": "2024-10-13 11:48:09 UTC",
      "updated_date": "2025-02-12 04:24:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:58:34.076694"
    },
    {
      "arxiv_id": "2410.13891v2",
      "title": "S$^4$ST: A Strong, Self-transferable, faSt, and Simple Scale Transformation for Transferable Targeted Attack",
      "title_zh": "翻译失败",
      "authors": [
        "Yongxiang Liu",
        "Bowen Peng",
        "Li Liu",
        "Xiang Li"
      ],
      "abstract": "Transferable Targeted Attacks (TTAs), which aim to deceive black-box models\ninto predicting specific erroneous labels, face significant challenges due to\nsevere overfitting to surrogate models. Although modifying image features to\ngenerate robust semantic patterns of the target class is a promising approach,\nexisting methods heavily rely on large-scale additional data. This dependence\nundermines the fair evaluation of TTA threats, potentially leading to a false\nsense of security or unnecessary overreactions. In this paper, we introduce two\nblind measures, surrogate self-alignment and self-transferability, to analyze\nthe effectiveness and correlations of basic transformations, to enhance\ndata-free attacks under strict black-box constraints. Our findings challenge\nconventional assumptions: (1) Attacking simple scaling transformations uniquely\nenhances targeted transferability, outperforming other basic transformations\nand rivaling leading complex methods; (2) Geometric and color transformations\nexhibit high internal redundancy despite weak inter-category correlations.\nThese insights drive the design and tuning of S4ST (Strong, Self-transferable,\nfaSt, Simple Scale Transformation), which integrates dimensionally consistent\nscaling, complementary low-redundancy transformations, and block-wise\noperations. Extensive experiments on the ImageNet-Compatible dataset\ndemonstrate that S4ST achieves a 77.7% average targeted success rate (tSuc),\nsurpassing existing transformations (+17.2% over H-Aug with only 26%\ncomputational time) and SOTA TTA solutions (+6.2% over SASD-WS with 1.2M\nsamples for post-training). Notably, it attains 69.6% and 55.3% average tSuc\nagainst three commercial APIs and vision-language models, respectively. This\nwork establishes a new SOTA for TTAs, highlights their potential threats, and\ncalls for a reevaluation of the data dependency in achieving targeted\ntransferability.",
      "tldr_zh": "该论文针对可转移目标攻击（Transferable Targeted Attacks, TTAs）的问题，提出了一种强大、自转移、快速且简单的缩放变换方法 S$^4$ST，以减少对额外数据的依赖并提升攻击转移性。研究通过引入 surrogate self-alignment 和 self-transferability 两个盲测指标，分析了基本变换的有效性和相关性，发现缩放变换能显著提升目标转移性，而几何和颜色变换存在内部冗余。实验在 ImageNet-Compatible 数据集上显示，S$^4$ST 实现了 77.7% 的平均 targeted success rate (tSuc)，超过了现有方法（如 H-Aug 和 SASD-WS），并在商业 API 和视觉语言模型上表现出色，从而重新评估了 TTAs 的潜在威胁和数据依赖性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "16 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.13891v2",
      "published_date": "2024-10-13 11:39:13 UTC",
      "updated_date": "2025-02-25 10:11:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:58:46.985846"
    },
    {
      "arxiv_id": "2410.09804v3",
      "title": "BlackDAN: A Black-Box Multi-Objective Approach for Effective and Contextual Jailbreaking of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyuan Wang",
        "Victor Shea-Jay Huang",
        "Renmiao Chen",
        "Hao Wang",
        "Chengwei Pan",
        "Lei Sha",
        "Minlie Huang"
      ],
      "abstract": "While large language models (LLMs) exhibit remarkable capabilities across\nvarious tasks, they encounter potential security risks such as jailbreak\nattacks, which exploit vulnerabilities to bypass security measures and generate\nharmful outputs. Existing jailbreak strategies mainly focus on maximizing\nattack success rate (ASR), frequently neglecting other critical factors,\nincluding the relevance of the jailbreak response to the query and the level of\nstealthiness. This narrow focus on single objectives can result in ineffective\nattacks that either lack contextual relevance or are easily recognizable. In\nthis work, we introduce BlackDAN, an innovative black-box attack framework with\nmulti-objective optimization, aiming to generate high-quality prompts that\neffectively facilitate jailbreaking while maintaining contextual relevance and\nminimizing detectability. BlackDAN leverages Multiobjective Evolutionary\nAlgorithms (MOEAs), specifically the NSGA-II algorithm, to optimize jailbreaks\nacross multiple objectives including ASR, stealthiness, and semantic relevance.\nBy integrating mechanisms like mutation, crossover, and Pareto-dominance,\nBlackDAN provides a transparent and interpretable process for generating\njailbreaks. Furthermore, the framework allows customization based on user\npreferences, enabling the selection of prompts that balance harmfulness,\nrelevance, and other factors. Experimental results demonstrate that BlackDAN\noutperforms traditional single-objective methods, yielding higher success rates\nand improved robustness across various LLMs and multimodal LLMs, while ensuring\njailbreak responses are both relevant and less detectable.",
      "tldr_zh": "这篇论文介绍了 BlackDAN，一种黑盒多目标优化框架，用于对 Large Language Models (LLMs) 进行有效且上下文相关的 jailbreaking 攻击，旨在同时优化攻击成功率 (ASR)、隐蔽性和语义相关性。BlackDAN 采用 Multiobjective Evolutionary Algorithms (MOEAs)，特别是 NSGA-II 算法，通过 mutation、crossover 和 Pareto-dominance 机制生成高质量提示，并允许用户自定义以平衡有害性、相关性和其他因素。该框架解决了传统单目标方法的局限性，实验显示 BlackDAN 在各种 LLMs 和多模态 LLMs 上实现了更高的成功率和鲁棒性，同时使攻击响应更相关且不易检测。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09804v3",
      "published_date": "2024-10-13 11:15:38 UTC",
      "updated_date": "2024-11-27 02:41:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:58:58.903963"
    },
    {
      "arxiv_id": "2410.09802v1",
      "title": "EBDM: Exemplar-guided Image Translation with Brownian-bridge Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Eungbean Lee",
        "Somi Jeong",
        "Kwanghoon Sohn"
      ],
      "abstract": "Exemplar-guided image translation, synthesizing photo-realistic images that\nconform to both structural control and style exemplars, is attracting attention\ndue to its ability to enhance user control over style manipulation. Previous\nmethodologies have predominantly depended on establishing dense correspondences\nacross cross-domain inputs. Despite these efforts, they incur quadratic memory\nand computational costs for establishing dense correspondence, resulting in\nlimited versatility and performance degradation. In this paper, we propose a\nnovel approach termed Exemplar-guided Image Translation with Brownian-Bridge\nDiffusion Models (EBDM). Our method formulates the task as a stochastic\nBrownian bridge process, a diffusion process with a fixed initial point as\nstructure control and translates into the corresponding photo-realistic image\nwhile being conditioned solely on the given exemplar image. To efficiently\nguide the diffusion process toward the style of exemplar, we delineate three\npivotal components: the Global Encoder, the Exemplar Network, and the Exemplar\nAttention Module to incorporate global and detailed texture information from\nexemplar images. Leveraging Bridge diffusion, the network can translate images\nfrom structure control while exclusively conditioned on the exemplar style,\nleading to more robust training and inference processes. We illustrate the\nsuperiority of our method over competing approaches through comprehensive\nbenchmark evaluations and visual results.",
      "tldr_zh": "本研究提出了一种名为EBDM的Exemplar-guided Image Translation方法，利用Brownian-bridge Diffusion Models来合成符合结构控制和风格示例的真实图像，从而提升用户对风格操控的控制力。EBDM将图像翻译任务表述为一个随机Brownian桥过程，仅基于给定示例图像进行条件引导，并引入Global Encoder、Exemplar Network和Exemplar Attention Module来整合示例的全局和详细纹理信息，避免了传统方法的密集对应计算开销。实验结果显示，该方法在基准评估和视觉效果上优于现有竞争方法，提供更高效、鲁棒的图像翻译过程。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.09802v1",
      "published_date": "2024-10-13 11:10:34 UTC",
      "updated_date": "2024-10-13 11:10:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:59:09.101969"
    },
    {
      "arxiv_id": "2410.09795v4",
      "title": "WGFormer: An SE(3)-Transformer Driven by Wasserstein Gradient Flows for Molecular Ground-State Conformation Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Fanmeng Wang",
        "Minjie Cheng",
        "Hongteng Xu"
      ],
      "abstract": "Predicting molecular ground-state conformation (i.e., energy-minimized\nconformation) is crucial for many chemical applications such as molecular\ndocking and property prediction. Classic energy-based simulation is\ntime-consuming when solving this problem while existing learning-based methods\nhave advantages in computational efficiency but sacrifice accuracy and\ninterpretability. In this work, we propose a novel and effective method to\nbridge the energy-based simulation and the learning-based strategy, which\ndesigns and learns a Wasserstein gradient flow-driven SE(3)-Transformer, called\nWGFormer, for molecular ground-state conformation prediction. Specifically, our\nmethod tackles this task within an auto-encoding framework, which encodes\nlow-quality conformations by the proposed WGFormer and decodes corresponding\nground-state conformations by an MLP. The architecture of WGFormer corresponds\nto Wasserstein gradient flows -- it optimizes molecular conformations by\nminimizing an energy function defined on the latent mixture models of atoms,\nthereby significantly improving performance and interpretability. Extensive\nexperiments show that our method consistently outperforms state-of-the-art\ncompetitors, providing a new and insightful paradigm to predict molecular\nground-state conformation.",
      "tldr_zh": "本研究提出了一种名为 WGFormer 的新方法，用于预测分子基态构象（molecular ground-state conformation），旨在解决传统能量模拟耗时长和现有学习方法准确性不足的问题。WGFormer 是一个由 Wasserstein gradient flows 驱动的 SE(3)-Transformer，通过自编码框架（auto-encoding framework）编码低质量构象并使用 MLP 解码，从而最小化原子潜在混合模型上的能量函数，提高了预测的性能和可解释性。该方法在广泛实验中 consistently outperforms 现有最先进竞争者，提供了一个结合能量模拟和学习策略的新范式。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG",
        "physics.chem-ph"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09795v4",
      "published_date": "2024-10-13 10:48:22 UTC",
      "updated_date": "2025-02-13 12:35:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:59:21.827703"
    },
    {
      "arxiv_id": "2410.18123v1",
      "title": "Movement Control of Smart Mosque's Domes using CSRNet and Fuzzy Logic Techniques",
      "title_zh": "利用 CSRNet 和模糊逻辑技术的智能清真寺圆顶运动控制",
      "authors": [
        "Anas H. Blasi",
        "Mohammad Awis Al Lababede",
        "Mohammed A. Alsuwaiket"
      ],
      "abstract": "Mosques are worship places of Allah and must be preserved clean, immaculate,\nprovide all the comforts of the worshippers in them. The prophet's mosque in\nMedina/ Saudi Arabia is one of the most important mosques for Muslims. It\noccupies second place after the sacred mosque in Mecca/ Saudi Arabia, which is\nin constant overcrowding by all Muslims to visit the prophet Mohammad's tomb.\nThis paper aims to propose a smart dome model to preserve the fresh air and\nallow the sunlight to enter the mosque using artificial intelligence\ntechniques. The proposed model controls domes movements based on the weather\nconditions and the overcrowding rates in the mosque. The data have been\ncollected from two different resources, the first one from the database of\nSaudi Arabia weather's history, and the other from Shanghai Technology\nDatabase. Congested Scene Recognition Network (CSRNet) and Fuzzy techniques\nhave applied using Python programming language to control the domes to be\nopened and closed for a specific time to renew the air inside the mosque. Also,\nthis model consists of several parts that are connected for controlling the\nmechanism of opening/closing domes according to weather data and the situation\nof crowding in the mosque. Finally, the main goal of this paper has been\nachieved, and the proposed model has worked efficiently and specifies the exact\nduration time to keep the domes open automatically for a few minutes for each\nhour head.",
      "tldr_zh": "本论文提出了一种智能清真寺穹顶控制模型，旨在根据天气条件和清真寺拥挤程度自动调节穹顶开合，以保持新鲜空气和阳光进入。模型利用 Congested Scene Recognition Network (CSRNet) 检测拥挤情况，并结合 Fuzzy Logic 技术处理天气数据，实现精确的开闭机制。数据来源于沙特阿拉伯天气历史数据库和上海技术数据库，通过 Python 编程语言构建系统，最终实验证明该模型高效运行，能自动指定穹顶每小时打开的精确时长。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18123v1",
      "published_date": "2024-10-13 09:39:44 UTC",
      "updated_date": "2024-10-13 09:39:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:59:32.914256"
    },
    {
      "arxiv_id": "2410.09780v1",
      "title": "Expanding Search Space with Diverse Prompting Agents: An Efficient Sampling Approach for LLM Mathematical Reasoning",
      "title_zh": "通过多样化提示代理扩展搜索空间：一种用于大型语言模型数学推理的高效采样方法",
      "authors": [
        "Gisang Lee",
        "Sangwoo Park",
        "Junyoung Park",
        "Andrew Chung",
        "Sieun Park",
        "Yoonah Park",
        "Byungju Kim",
        "Min-gyu Cho"
      ],
      "abstract": "Large Language Models (LLMs) have exhibited remarkable capabilities in many\ncomplex tasks including mathematical reasoning. However, traditional approaches\nheavily rely on ensuring self-consistency within single prompting method, which\nlimits the exploration of diverse problem-solving strategies. This study\naddresses these limitations by performing an experimental analysis of distinct\nprompting methods within the domain of mathematical reasoning. Our findings\ndemonstrate that each method explores a distinct search space, and this\ndifferentiation becomes more evident with increasing problem complexity. To\nleverage this phenomenon, we applied efficient sampling process that uniformly\ncombines samples from these diverse methods, which not only expands the maximum\nsearch space but achieves higher performance with fewer runs compared to single\nmethods. Especially, within the subset of difficult questions of MATH dataset\nnamed MATH-hard, The maximum search space was achieved while utilizing\napproximately 43% fewer runs than single methods on average. These findings\nhighlight the importance of integrating diverse problem-solving strategies to\nenhance the reasoning abilities of LLMs.",
      "tldr_zh": "本研究发现，大型语言模型(LLMs)在数学推理任务中，传统单一提示方法会限制问题解决策略的多样性，导致搜索空间狭窄。通过实验分析不同提示方法，该研究证明每个方法探索的搜索空间独特，尤其在复杂问题中差异更明显。作者提出了一种高效采样方法，将多样提示代理的样本均匀结合，扩大搜索空间并在更少运行次数下提升性能，例如在MATH-hard数据集上，仅需约43%更少的运行就达到最大搜索空间。这些发现强调了整合多样化策略的重要性，以增强LLMs的数学推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.09780v1",
      "published_date": "2024-10-13 08:49:22 UTC",
      "updated_date": "2024-10-13 08:49:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:59:45.600990"
    },
    {
      "arxiv_id": "2410.09775v1",
      "title": "EasyJudge: an Easy-to-use Tool for Comprehensive Response Evaluation of LLMs",
      "title_zh": "EasyJudge：一个易于使用的工具，用于大语言模型的全面响应评估",
      "authors": [
        "Yijie Li",
        "Yuan Sun"
      ],
      "abstract": "Recently, there has been a growing trend of employing large language models\n(LLMs) to judge the quality of other LLMs. Many studies have adopted\nclosed-source models, mainly using GPT-4 as the evaluator. However, due to the\nclosed-source nature of the GPT-4 model, employing it as an evaluator has\nresulted in issues including transparency, controllability, and\ncost-effectiveness. Some researchers have turned to using fine-tuned\nopen-source LLMs as evaluators. However, existing open-source evaluation LLMs\ngenerally lack a user-friendly visualization tool, and they have not been\noptimized for accelerated model inference, which causes inconvenience for\nresearchers with limited resources and those working across different fields.\nThis paper presents EasyJudge, a model developed to evaluate significant\nlanguage model responses. It is lightweight, precise, efficient, and\nuser-friendly, featuring an intuitive visualization interface for ease of\ndeployment and use. EasyJudge uses detailed datasets and refined prompts for\nmodel optimization, achieving strong consistency with human and proprietary\nmodel evaluations. The model optimized with quantitative methods enables\nEasyJudge to run efficiently on consumer-grade GPUs or even CPUs. We also\nprovide detailed analysis and case studies to further reveal the potential of\nour method.",
      "tldr_zh": "该论文介绍了 EasyJudge，一种轻量级、精确且用户友好的工具，用于全面评估大型语言模型(LLMs)的响应，解决了使用闭源模型如 GPT-4 时的透明度、可控性和成本问题。EasyJudge 通过利用详细数据集和精炼提示对开源 LLMs 进行优化，实现高效推理，并在消费级 GPU 或 CPU 上运行，同时提供直观的可视化界面。实验结果显示，EasyJudge 与人类和专有模型评估高度一致，并通过详细分析和案例研究证明了其潜力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09775v1",
      "published_date": "2024-10-13 08:24:12 UTC",
      "updated_date": "2024-10-13 08:24:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:59:57.389020"
    },
    {
      "arxiv_id": "2410.09772v1",
      "title": "HypomimiaCoach: An AU-based Digital Therapy System for Hypomimia Detection & Rehabilitation with Parkinson's Disease",
      "title_zh": "翻译失败",
      "authors": [
        "Yingjing Xu",
        "Xueyan Cai",
        "Zihong Zhou",
        "Mengru Xue",
        "Bo Wang",
        "Haotian Wang",
        "Zhengke Li",
        "Chentian Weng",
        "Wei Luo",
        "Cheng Yao",
        "Bo Lin",
        "Jianwei Yin"
      ],
      "abstract": "Hypomimia is a non-motor symptom of Parkinson's disease that manifests as\ndelayed facial movements and expressions, along with challenges in articulation\nand emotion. Currently, subjective evaluation by neurologists is the primary\nmethod for hypomimia detection, and conventional rehabilitation approaches\nheavily rely on verbal prompts from rehabilitation physicians. There remains a\ndeficiency in accessible, user-friendly and scientifically rigorous assistive\ntools for hypomimia treatments. To investigate this, we developed\nHypomimaCoach, an Action Unit (AU)-based digital therapy system for hypomimia\ndetection and rehabilitation in Parkinson's disease. The HypomimaCoach system\nwas designed to facilitate engagement through the incorporation of both relaxed\nand controlled rehabilitation exercises, while also stimulating initiative\nthrough the integration of digital therapies that incorporated traditional face\ntraining methods. We extract action unit(AU) features and their relationship\nfor hypomimia detection. In order to facilitate rehabilitation, a series of\ntraining programmes have been devised based on the Action Units (AUs) and\npatients are provided with real-time feedback through an additional AU\nrecognition model, which guides them through their training routines. A pilot\nstudy was conducted with seven participants in China, all of whom exhibited\nsymptoms of Parkinson's disease hypomimia. The results of the pilot study\ndemonstrated a positive impact on participants' self-efficacy, with favourable\nfeedback received. Furthermore, physician evaluations validated the system's\napplicability in a therapeutic setting for patients with Parkinson's disease,\nas well as its potential value in clinical applications.",
      "tldr_zh": "本文开发了HypomimiaCoach，一个基于Action Unit (AU)的数字治疗系统，用于检测和康复帕金森病患者的Hypomimia症状，该症状包括面部运动延迟和表情障碍。系统通过提取AU特征及其关系进行检测，并设计了一系列基于AU的训练程序，提供实时反馈以提升患者参与度和主动性。试点研究涉及7名中国患者，结果显示系统提高了患者的自我效能，获得了积极反馈，并经医生评估确认其在临床治疗中的潜在价值。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09772v1",
      "published_date": "2024-10-13 08:09:42 UTC",
      "updated_date": "2024-10-13 08:09:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:00:09.455773"
    },
    {
      "arxiv_id": "2410.09770v1",
      "title": "'Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated peer-reviews",
      "title_zh": "翻译失败",
      "authors": [
        "Sandeep Kumar",
        "Mohit Sahu",
        "Vardhan Gacche",
        "Tirthankar Ghosal",
        "Asif Ekbal"
      ],
      "abstract": "The integrity of the peer-review process is vital for maintaining scientific\nrigor and trust within the academic community. With the steady increase in the\nusage of large language models (LLMs) like ChatGPT in academic writing, there\nis a growing concern that AI-generated texts could compromise scientific\npublishing, including peer-reviews. Previous works have focused on generic\nAI-generated text detection or have presented an approach for estimating the\nfraction of peer-reviews that can be AI-generated. Our focus here is to solve a\nreal-world problem by assisting the editor or chair in determining whether a\nreview is written by ChatGPT or not. To address this, we introduce the Term\nFrequency (TF) model, which posits that AI often repeats tokens, and the Review\nRegeneration (RR) model, which is based on the idea that ChatGPT generates\nsimilar outputs upon re-prompting. We stress test these detectors against token\nattack and paraphrasing. Finally, we propose an effective defensive strategy to\nreduce the effect of paraphrasing on our models. Our findings suggest both our\nproposed methods perform better than the other AI text detectors. Our RR model\nis more robust, although our TF model performs better than the RR model without\nany attacks. We make our code, dataset, and model public.",
      "tldr_zh": "本研究探讨了检测 AI 生成的同行评审问题，以维护学术出版的诚信，因为 large language models (LLMs) 如 ChatGPT 的使用可能导致文本伪造。论文引入了 Term Frequency (TF) 模型（基于 AI 重复 tokens 的假设）和 Review Regeneration (RR) 模型（利用 ChatGPT 在重新提示时生成相似输出的特性），并对这些模型进行了 token attack 和 paraphrasing 的压力测试，同时提出防御策略来减轻 paraphrasing 的影响。结果显示，TF 和 RR 模型比其他 AI 文本检测器表现更优，其中 RR 模型更具鲁棒性，而 TF 模型在无攻击场景下更出色；研究还公开了代码、数据集和模型以促进进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP Main, 17 pages, 5 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.09770v1",
      "published_date": "2024-10-13 08:06:08 UTC",
      "updated_date": "2024-10-13 08:06:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:00:22.829725"
    },
    {
      "arxiv_id": "2410.09767v2",
      "title": "LibEER: A Comprehensive Benchmark and Algorithm Library for EEG-based Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Huan Liu",
        "Shusen Yang",
        "Yuzhe Zhang",
        "Mengze Wang",
        "Fanyu Gong",
        "Chengxi Xie",
        "Guanjian Liu",
        "Zejun Liu",
        "Yong-Jin Liu",
        "Bao-Liang Lu",
        "Dalin Zhang"
      ],
      "abstract": "EEG-based emotion recognition (EER) has gained significant attention due to\nits potential for understanding and analyzing human emotions. While recent\nadvancements in deep learning techniques have substantially improved EER, the\nfield lacks a convincing benchmark and comprehensive open-source libraries.\nThis absence complicates fair comparisons between models and creates\nreproducibility challenges for practitioners, which collectively hinder\nprogress. To address these issues, we introduce LibEER, a comprehensive\nbenchmark and algorithm library designed to facilitate fair comparisons in EER.\nLibEER carefully selects popular and powerful baselines, harmonizes key\nimplementation details across methods, and provides a standardized codebase in\nPyTorch. By offering a consistent evaluation framework with standardized\nexperimental settings, LibEER enables unbiased assessments of over ten\nrepresentative deep learning models for EER across the four most widely used\ndatasets. Additionally, we conduct a thorough, reproducible comparison of model\nperformance and efficiency, providing valuable insights to guide researchers in\nthe selection and design of EER models. Moreover, we make observations and\nin-depth analysis on the experiment results and identify current challenges in\nthis community. We hope that our work will not only lower entry barriers for\nnewcomers to EEG-based emotion recognition but also contribute to the\nstandardization of research in this domain, fostering steady development. The\nlibrary and source code are publicly available at\nhttps://github.com/XJTU-EEG/LibEER.",
      "tldr_zh": "本论文针对 EEG-based Emotion Recognition (EER) 领域缺乏可靠基准和开源库的问题，引入了 LibEER，这是一个全面的基准和算法库，使用 PyTorch 提供标准化代码和统一实验设置。LibEER 选取了十余个代表性 deep learning 模型，在四个最广泛使用的数据集上进行公平比较，并分析了模型性能和效率，提供宝贵见解。研究还观察实验结果，识别当前挑战，并通过开源代码（https://github.com/XJTU-EEG/LibEER）降低新手进入门槛，促进 EER 领域的标准化发展。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09767v2",
      "published_date": "2024-10-13 07:51:39 UTC",
      "updated_date": "2024-11-12 12:09:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:00:33.816596"
    },
    {
      "arxiv_id": "2410.09763v3",
      "title": "EEG-based AI-BCI Wheelchair Advancement: A Brain-Computer Interfacing Wheelchair System Using Deep Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Biplov Paneru",
        "Bishwash Paneru",
        "Bipul Thapa",
        "Khem Narayan Poudyal"
      ],
      "abstract": "This study offers a revolutionary strategy to developing wheelchairs based on\nthe Brain-Computer Interface (BCI) that incorporates Artificial Intelligence\n(AI) using a The device uses electroencephalogram (EEG) data to mimic\nwheelchair navigation. Five different models were trained on a pre-filtered\ndataset that was divided into fixed-length windows using a sliding window\ntechnique. Each window contained statistical measurements, FFT coefficients for\ndifferent frequency bands, and a label identifying the activity carried out\nduring that window that was taken from an open-source Kaggle repository. The\nXGBoost model outperformed the other models, CatBoost, GRU, SVC, and XGBoost,\nwith an accuracy of 60%. The CatBoost model with a major difference between\ntraining and testing accuracy shows overfitting, and similarly, the\nbest-performing model, with SVC, was implemented in a tkinter GUI. The\nwheelchair movement could be simulated in various directions, and a Raspberry\nPi-powered wheelchair system for brain-computer interface is proposed here.",
      "tldr_zh": "这篇论文提出了一种基于 EEG（脑电图）的 AI-BCI（脑机接口）轮椅系统，使用深度学习方法来模拟轮椅导航。研究团队训练了五个模型，包括 XGBoost、CatBoost、GRU 和 SVC，在开源 Kaggle 数据集上进行处理，该数据集通过滑动窗口技术提取统计测量、FFT（快速傅里叶变换）系数和活动标签。XGBoost 模型表现出色，准确率达到 60%，而 CatBoost 模型显示出过拟合问题。最终，他们使用 SVC 模型实现了一个 Tkinter GUI 接口，并提出基于 Raspberry Pi 的轮椅系统，以推进自主脑机接口应用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09763v3",
      "published_date": "2024-10-13 07:41:37 UTC",
      "updated_date": "2025-01-12 15:56:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:00:45.728464"
    },
    {
      "arxiv_id": "2410.09761v1",
      "title": "ChartKG: A Knowledge-Graph-Based Representation for Chart Images",
      "title_zh": "ChartKG：基于知识图谱的图表图像表示",
      "authors": [
        "Zhiguang Zhou",
        "Haoxuan Wang",
        "Zhengqing Zhao",
        "Fengling Zheng",
        "Yongheng Wang",
        "Wei Chen",
        "Yong Wang"
      ],
      "abstract": "Chart images, such as bar charts, pie charts, and line charts, are\nexplosively produced due to the wide usage of data visualizations. Accordingly,\nknowledge mining from chart images is becoming increasingly important, which\ncan benefit downstream tasks like chart retrieval and knowledge graph\ncompletion. However, existing methods for chart knowledge mining mainly focus\non converting chart images into raw data and often ignore their visual\nencodings and semantic meanings, which can result in information loss for many\ndownstream tasks. In this paper, we propose ChartKG, a novel knowledge graph\n(KG) based representation for chart images, which can model the visual elements\nin a chart image and semantic relations among them including visual encodings\nand visual insights in a unified manner. Further, we develop a general\nframework to convert chart images to the proposed KG-based representation. It\nintegrates a series of image processing techniques to identify visual elements\nand relations, e.g., CNNs to classify charts, yolov5 and optical character\nrecognition to parse charts, and rule-based methods to construct graphs. We\npresent four cases to illustrate how our knowledge-graph-based representation\ncan model the detailed visual elements and semantic relations in charts, and\nfurther demonstrate how our approach can benefit downstream applications such\nas semantic-aware chart retrieval and chart question answering. We also conduct\nquantitative evaluations to assess the two fundamental building blocks of our\nchart-to-KG framework, i.e., object recognition and optical character\nrecognition. The results provide support for the usefulness and effectiveness\nof ChartKG.",
      "tldr_zh": "该论文提出ChartKG，一种基于Knowledge Graph (KG)的表示方法，用于建模图表图像（如条形图、饼图和折线图）的视觉元素和语义关系，包括视觉编码和洞见，以解决现有方法忽略这些方面导致的信息损失问题。研究开发了一个通用框架，将图表图像转换为KG表示，整合了CNNs分类、YOLOv5对象识别、OCR字符识别以及基于规则的方法来识别元素和关系。论文通过四个案例展示了ChartKG在语义感知图表检索和图表问答等下游任务中的应用益处，并通过定量评估验证了框架的核心组件（如对象识别和OCR）的有效性，结果支持了ChartKG的实用性和准确性。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09761v1",
      "published_date": "2024-10-13 07:38:44 UTC",
      "updated_date": "2024-10-13 07:38:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:00:59.027072"
    },
    {
      "arxiv_id": "2410.09754v1",
      "title": "SimBa: Simplicity Bias for Scaling Up Parameters in Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hojoon Lee",
        "Dongyoon Hwang",
        "Donghu Kim",
        "Hyunseung Kim",
        "Jun Jet Tai",
        "Kaushik Subramanian",
        "Peter R. Wurman",
        "Jaegul Choo",
        "Peter Stone",
        "Takuma Seno"
      ],
      "abstract": "Recent advances in CV and NLP have been largely driven by scaling up the\nnumber of network parameters, despite traditional theories suggesting that\nlarger networks are prone to overfitting. These large networks avoid\noverfitting by integrating components that induce a simplicity bias, guiding\nmodels toward simple and generalizable solutions. However, in deep RL,\ndesigning and scaling up networks have been less explored. Motivated by this\nopportunity, we present SimBa, an architecture designed to scale up parameters\nin deep RL by injecting a simplicity bias. SimBa consists of three components:\n(i) an observation normalization layer that standardizes inputs with running\nstatistics, (ii) a residual feedforward block to provide a linear pathway from\nthe input to output, and (iii) a layer normalization to control feature\nmagnitudes. By scaling up parameters with SimBa, the sample efficiency of\nvarious deep RL algorithms-including off-policy, on-policy, and unsupervised\nmethods-is consistently improved. Moreover, solely by integrating SimBa\narchitecture into SAC, it matches or surpasses state-of-the-art deep RL methods\nwith high computational efficiency across DMC, MyoSuite, and HumanoidBench.\nThese results demonstrate SimBa's broad applicability and effectiveness across\ndiverse RL algorithms and environments.",
      "tldr_zh": "本论文提出 SimBa 架构，通过注入 simplicity bias 来扩展 deep RL 中的网络参数，避免过拟合问题。SimBa 包括三个组件：observation normalization layer 用于标准化输入、residual feedforward block 提供线性路径，以及 layer normalization 控制特征幅度。该架构显著提高了各种 deep RL 算法（如 off-policy、on-policy 和无监督方法）的样本效率，并在 DMC、MyoSuite 和 HumanoidBench 等环境中，仅通过集成到 SAC 中就匹配或超越了最先进方法，同时保持高计算效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2410.09754v1",
      "published_date": "2024-10-13 07:20:53 UTC",
      "updated_date": "2024-10-13 07:20:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:01:11.267759"
    },
    {
      "arxiv_id": "2410.11578v1",
      "title": "STA-Unet: Rethink the semantic redundant for Medical Imaging Segmentation",
      "title_zh": "STA-Unet",
      "authors": [
        "Vamsi Krishna Vasa",
        "Wenhui Zhu",
        "Xiwen Chen",
        "Peijie Qiu",
        "Xuanzhao Dong",
        "Yalin Wang"
      ],
      "abstract": "In recent years, significant progress has been made in the medical image\nanalysis domain using convolutional neural networks (CNNs). In particular, deep\nneural networks based on a U-shaped architecture (UNet) with skip connections\nhave been adopted for several medical imaging tasks, including organ\nsegmentation. Despite their great success, CNNs are not good at learning global\nor semantic features. Especially ones that require human-like reasoning to\nunderstand the context. Many UNet architectures attempted to adjust with the\nintroduction of Transformer-based self-attention mechanisms, and notable gains\nin performance have been noted. However, the transformers are inherently flawed\nwith redundancy to learn at shallow layers, which often leads to an increase in\nthe computation of attention from the nearby pixels offering limited\ninformation. The recently introduced Super Token Attention (STA) mechanism\nadapts the concept of superpixels from pixel space to token space, using super\ntokens as compact visual representations. This approach tackles the redundancy\nby learning efficient global representations in vision transformers, especially\nfor the shallow layers. In this work, we introduce the STA module in the UNet\narchitecture (STA-UNet), to limit redundancy without losing rich information.\nExperimental results on four publicly available datasets demonstrate the\nsuperiority of STA-UNet over existing state-of-the-art architectures in terms\nof Dice score and IOU for organ segmentation tasks. The code is available at\n\\url{https://github.com/Retinal-Research/STA-UNet}.",
      "tldr_zh": "该论文针对卷积神经网络(CNNs) 在医疗图像分割中学习全局语义特征的不足，提出了一种改进的 UNet 架构，即 STA-UNet，以减少浅层 Transformer 的冗余问题。Super Token Attention (STA) 机制将 superpixels 的概念应用于 token 空间，创建紧凑的视觉表示，从而提升全局特征学习效率，同时保留丰富信息。在四个公开数据集上的实验显示，STA-UNet 在器官分割任务中显著优于现有最先进模型，在 Dice score 和 IOU 指标上表现出色。代码已开源，可从指定链接获取。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11578v1",
      "published_date": "2024-10-13 07:19:46 UTC",
      "updated_date": "2024-10-13 07:19:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:01:21.641571"
    },
    {
      "arxiv_id": "2410.09750v1",
      "title": "Surgical-LLaVA: Toward Surgical Scenario Understanding via Large Language and Vision Models",
      "title_zh": "翻译失败",
      "authors": [
        "Juseong Jin",
        "Chang Wook Jeong"
      ],
      "abstract": "Conversation agents powered by large language models are revolutionizing the\nway we interact with visual data. Recently, large vision-language models\n(LVLMs) have been extensively studied for both images and videos. However,\nthese studies typically focus on common scenarios. In this work, we introduce\nan LVLM specifically designed for surgical scenarios. We integrate visual\nrepresentations of surgical images and videos into the language feature space.\nConsequently, we establish a LVLM model, Surgical-LLaVA, fine-tuned on\ninstruction following data of surgical scenarios. Our experiments demonstrate\nthat Surgical-LLaVA exhibits impressive multi-modal chat abilities in surgical\ncontexts, occasionally displaying multi-modal behaviors on unseen instructions.\nWe conduct a quantitative evaluation of visual question-answering datasets for\nsurgical scenarios. The results show superior performance compared to previous\nworks, indicating the potential of our model to tackle more complex surgery\nscenarios.",
      "tldr_zh": "本研究开发了Surgical-LLaVA，一种专为手术场景设计的大型视觉语言模型(LVLM)，旨在通过整合手术图像和视频的视觉表示到语言特征空间，实现更精确的情境理解。\n该模型通过在指令跟随数据上进行微调，展现出强大的多模态聊天能力，甚至能在未见指令下表现出灵活行为。\n实验评估显示，Surgical-LLaVA在手术视觉问答数据集上优于先前工作，证明其潜力在处理复杂手术场景中发挥关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024 AIM-FM Workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.09750v1",
      "published_date": "2024-10-13 07:12:35 UTC",
      "updated_date": "2024-10-13 07:12:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:01:33.735437"
    },
    {
      "arxiv_id": "2410.09747v3",
      "title": "t-READi: Transformer-Powered Robust and Efficient Multimodal Inference for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Pengfei Hu",
        "Yuhang Qian",
        "Tianyue Zheng",
        "Ang Li",
        "Zhe Chen",
        "Yue Gao",
        "Xiuzhen Cheng",
        "Jun Luo"
      ],
      "abstract": "Given the wide adoption of multimodal sensors (e.g., camera, lidar, radar) by\nautonomous vehicles (AVs), deep analytics to fuse their outputs for a robust\nperception become imperative. However, existing fusion methods often make two\nassumptions rarely holding in practice: i) similar data distributions for all\ninputs and ii) constant availability for all sensors. Because, for example,\nlidars have various resolutions and failures of radars may occur, such\nvariability often results in significant performance degradation in fusion. To\nthis end, we present tREADi, an adaptive inference system that accommodates the\nvariability of multimodal sensory data and thus enables robust and efficient\nperception. t-READi identifies variation-sensitive yet structure-specific model\nparameters; it then adapts only these parameters while keeping the rest intact.\nt-READi also leverages a cross-modality contrastive learning method to\ncompensate for the loss from missing modalities. Both functions are implemented\nto maintain compatibility with existing multimodal deep fusion methods. The\nextensive experiments evidently demonstrate that compared with the status quo\napproaches, t-READi not only improves the average inference accuracy by more\nthan 6% but also reduces the inference latency by almost 15x with the cost of\nonly 5% extra memory overhead in the worst case under realistic data and modal\nvariations.",
      "tldr_zh": "该论文提出 t-READi，一种基于 Transformer 的鲁棒高效多模态推理系统，用于自动驾驶中融合摄像头、lidar 和 radar 等传感器的数据，以应对数据分布差异和传感器缺失问题。t-READi 通过识别并适应变异敏感的模型参数，同时利用跨模态对比学习来补偿缺失模态，确保与现有多模态深度融合方法兼容。实验结果显示，t-READi 比现有方法提高了超过6%的平均推理准确率，并将推理延迟减少近15倍，仅增加5%的内存开销。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.DC",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.09747v3",
      "published_date": "2024-10-13 06:53:58 UTC",
      "updated_date": "2024-11-21 06:46:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:01:46.691044"
    },
    {
      "arxiv_id": "2410.09734v1",
      "title": "Gradient-Free Neural Network Training on the Edge",
      "title_zh": "翻译失败",
      "authors": [
        "Dotan Di Castro",
        "Omkar Joglekar",
        "Shir Kozlovsky",
        "Vladimir Tchuiev",
        "Michal Moshkovitz"
      ],
      "abstract": "Training neural networks is computationally heavy and energy-intensive. Many\nmethodologies were developed to save computational requirements and energy by\nreducing the precision of network weights at inference time and introducing\ntechniques such as rounding, stochastic rounding, and quantization. However,\nmost of these techniques still require full gradient precision at training\ntime, which makes training such models prohibitive on edge devices. This work\npresents a novel technique for training neural networks without needing\ngradients. This enables a training process where all the weights are one or two\nbits, without any hidden full precision computations. We show that it is\npossible to train models without gradient-based optimization techniques by\nidentifying erroneous contributions of each neuron towards the expected\nclassification and flipping the relevant bits using logical operations. We\ntested our method on several standard datasets and achieved performance\ncomparable to corresponding gradient-based baselines with a fraction of the\ncompute power.",
      "tldr_zh": "本文提出了一种无需梯度的神经网络训练方法，旨在解决传统训练过程的计算密集和高能耗问题，尤其适用于边缘设备。该方法通过识别每个神经元的错误贡献，并使用逻辑操作翻转相关位，使所有权重仅需 1 或 2 位，而无需隐藏的全精度计算。在标准数据集上测试，该技术实现了与基于 gradients 的基线模型相当的性能，但计算功率大幅降低，为高效的边缘计算提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09734v1",
      "published_date": "2024-10-13 05:38:39 UTC",
      "updated_date": "2024-10-13 05:38:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:02:01.563281"
    },
    {
      "arxiv_id": "2410.09729v2",
      "title": "MIRAGE: Multimodal Identification and Recognition of Annotations in Indian General Prescriptions",
      "title_zh": "翻译失败",
      "authors": [
        "Tavish Mankash",
        "V. S. Chaithanya Kota",
        "Anish De",
        "Praveen Prakash",
        "Kshitij Jadhav"
      ],
      "abstract": "Hospitals in India still rely on handwritten medical records despite the\navailability of Electronic Medical Records (EMR), complicating statistical\nanalysis and record retrieval. Handwritten records pose a unique challenge,\nrequiring specialized data for training models to recognize medications and\ntheir recommendation patterns. While traditional handwriting recognition\napproaches employ 2-D LSTMs, recent studies have explored using Multimodal\nLarge Language Models (MLLMs) for OCR tasks. Building on this approach, we\nfocus on extracting medication names and dosages from simulated medical\nrecords. Our methodology MIRAGE (Multimodal Identification and Recognition of\nAnnotations in indian GEneral prescriptions) involves fine-tuning the QWEN VL,\nLLaVA 1.6 and Idefics2 models on 743,118 high resolution simulated medical\nrecord images-fully annotated from 1,133 doctors across India. Our approach\nachieves 82% accuracy in extracting medication names and dosages.",
      "tldr_zh": "该研究针对印度医院依赖手写医疗记录的问题，提出MIRAGE框架，用于从模拟医疗记录中提取药物名称和剂量，以解决统计分析和记录检索的挑战。MIRAGE方法通过微调Multimodal Large Language Models（MLLMs）如QWEN VL、LLaVA 1.6和Idefics2模型，利用743,118张高分辨率图像（由印度1,133名医生标注），超越传统2-D LSTMs方法。实验结果显示，该框架在提取药物名称和剂量方面的准确率达到82%，为手写医疗记录处理提供有效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 9 figures, 3 tables, submitted to ISBI 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.09729v2",
      "published_date": "2024-10-13 05:19:09 UTC",
      "updated_date": "2024-11-12 04:19:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:02:09.905584"
    },
    {
      "arxiv_id": "2410.09718v2",
      "title": "A Tidal Current Speed Forecasting Model based on Multi-Periodicity Learning",
      "title_zh": "一种基于多周期性学习的潮汐流速预测模型",
      "authors": [
        "Tengfei Cheng",
        "Yangdi Huang",
        "Yunxuan Dong"
      ],
      "abstract": "Tidal energy is one of the key components in increasing the penetration rate\nof renewable energy. The penetration of tidal energy in the electrical grid\ndepends on the accuracy of tidal current speed forecasting. Modeling\ninaccuracies hinder forecast accuracy. Previous research has primarily used\nphysical models to forecast tidal current speed. However, tidal current\nvariations influenced by the orbital periods of celestial bodies make accurate\nphysical modeling challenging. Researching the multi-periodicity of tides is\ncrucial for accurately forecasting tidal current speed. In this article, we\npropose the Wavelet-Enhanced Convolutional Network (WCN) to learn\nmulti-periodicity. The framework embeds intra-period and inter-period\nvariations of one-dimensional tidal current data into the rows and columns of a\ntwo-dimensional tensor. Then, the two-dimensional variations of the sequence\ncan be processed by convolutional kernels. We integrate a time-frequency\nanalysis method into the framework to further address local periodic features.\nAdditionally, to enhance the framework's stability, we optimize the framework's\nhyperparameters with the Tree-structured Parzen Estimator algorithm. The\nproposed framework avoids the lack of learning multi-periodicity. Compared with\nbenchmarks, the proposed framework reduces the mean absolute error and mean\nsquare error in 10-step forecasting by, at most, 90.36% and 97.56%,\nrespectively.",
      "tldr_zh": "本论文针对潮汐流速预测的准确性问题，提出 Wavelet-Enhanced Convolutional Network (WCN) 模型，通过学习潮汐的多周期性来克服物理模型的局限性。WCN 将一维潮汐数据嵌入二维张量中，处理内部和内部周期变化，并整合时频分析方法来捕捉局部周期特征，同时使用 Tree-structured Parzen Estimator 算法优化超参数以提升稳定性。与基准模型相比，该框架在 10 步预测中将平均绝对误差和均方误差分别降低了最多 90.36% 和 97.56%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09718v2",
      "published_date": "2024-10-13 04:15:05 UTC",
      "updated_date": "2025-02-04 13:44:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:02:23.548235"
    },
    {
      "arxiv_id": "2410.09713v4",
      "title": "Agentic Information Retrieval",
      "title_zh": "代理式信息检索",
      "authors": [
        "Weinan Zhang",
        "Junwei Liao",
        "Ning Li",
        "Kounianhua Du",
        "Jianghao Lin"
      ],
      "abstract": "Since the 1970s, information retrieval (IR) has long been defined as the\nprocess of acquiring relevant information items from a pre-defined corpus to\nsatisfy user information needs. Traditional IR systems, while effective in\ndomains like web search, are constrained by their reliance on static,\npre-defined information items. To this end, this paper introduces agentic\ninformation retrieval (Agentic IR), a transformative next-generation paradigm\nfor IR driven by large language models (LLMs) and AI agents. The central shift\nin agentic IR is the evolving definition of ``information'' from static,\npre-defined information items to dynamic, context-dependent information states.\nInformation state refers to a particular information context that the user is\nright in within a dynamic environment, encompassing not only the acquired\ninformation items but also real-time user preferences, contextual factors, and\ndecision-making processes. In such a way, traditional information retrieval,\nfocused on acquiring relevant information items based on user queries, can be\nnaturally extended to achieving the target information state given the user\ninstruction, which thereby defines the agentic information retrieval. We\nsystematically discuss agentic IR from various aspects, i.e., task formulation,\narchitecture, evaluation, case studies, as well as challenges and future\nprospects. We believe that the concept of agentic IR introduced in this paper\nnot only broadens the scope of information retrieval research but also lays the\nfoundation for a more adaptive, interactive, and intelligent next-generation IR\nparadigm.",
      "tldr_zh": "这篇论文引入了Agentic Information Retrieval（Agentic IR）作为信息检索（IR）领域的下一代范式，由大型语言模型（LLMs）和AI代理驱动，将“信息”从静态预定义项扩展到动态的“信息状态”。Agentic IR 强调信息状态包括实时用户偏好、上下文因素和决策过程，从而从传统基于查询获取信息项的模式，转向基于用户指令实现目标信息状态。论文系统讨论了Agentic IR的任务制定、架构、评估、案例研究，以及面临的挑战和未来前景。该范式拓宽了IR研究范围，为构建更适应性、交互性和智能的IR系统奠定了基础。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "11 pages, perspective paper",
      "pdf_url": "http://arxiv.org/pdf/2410.09713v4",
      "published_date": "2024-10-13 03:45:24 UTC",
      "updated_date": "2025-02-23 03:23:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:02:34.039839"
    },
    {
      "arxiv_id": "2410.12864v1",
      "title": "Investigating Implicit Bias in Large Language Models: A Large-Scale Study of Over 50 LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Divyanshu Kumar",
        "Umang Jain",
        "Sahil Agarwal",
        "Prashanth Harshangi"
      ],
      "abstract": "Large Language Models (LLMs) are being adopted across a wide range of tasks,\nincluding decision-making processes in industries where bias in AI systems is a\nsignificant concern. Recent research indicates that LLMs can harbor implicit\nbiases even when they pass explicit bias evaluations. Building upon the\nframeworks of the LLM Implicit Association Test (IAT) Bias and LLM Decision\nBias, this study highlights that newer or larger language models do not\nautomatically exhibit reduced bias; in some cases, they displayed higher bias\nscores than their predecessors, such as in Meta's Llama series and OpenAI's GPT\nmodels. This suggests that increasing model complexity without deliberate bias\nmitigation strategies can unintentionally amplify existing biases. The\nvariability in bias scores within and across providers underscores the need for\nstandardized evaluation metrics and benchmarks for bias assessment. The lack of\nconsistency indicates that bias mitigation is not yet a universally prioritized\ngoal in model development, which can lead to unfair or discriminatory outcomes.\nBy broadening the detection of implicit bias, this research provides a more\ncomprehensive understanding of the biases present in advanced models and\nunderscores the critical importance of addressing these issues to ensure the\ndevelopment of fair and responsible AI systems.",
      "tldr_zh": "本研究通过对超过50个大型语言模型 (LLMs) 进行大规模调查，评估了这些模型中的隐性偏见 (Implicit Bias)，基于 LLM Implicit Association Test (IAT) Bias 和 LLM Decision Bias 框架。结果显示，更大或更新的模型（如 Meta 的 Llama 系列和 OpenAI 的 GPT 模型）并不一定减少偏见，反而在某些情况下表现出更高的偏见分数，这可能是由于增加模型复杂度而缺乏 deliberate bias mitigation strategies 所致。研究强调，偏见分数在模型间和提供者间的变异性突显了标准化评估指标的必要性，并呼吁在模型开发中优先考虑偏见缓解，以避免不公平或歧视性结果并推动公平、负责任的 AI 系统发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12864v1",
      "published_date": "2024-10-13 03:43:18 UTC",
      "updated_date": "2024-10-13 03:43:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:02:47.471179"
    },
    {
      "arxiv_id": "2410.09703v1",
      "title": "Universal scaling laws in quantum-probabilistic machine learning by tensor network towards interpreting representation and generalization powers",
      "title_zh": "翻译失败",
      "authors": [
        "Sheng-Chen Bai",
        "Shi-Ju Ran"
      ],
      "abstract": "Interpreting the representation and generalization powers has been a\nlong-standing issue in the field of machine learning (ML) and artificial\nintelligence. This work contributes to uncovering the emergence of universal\nscaling laws in quantum-probabilistic ML. We take the generative tensor network\n(GTN) in the form of a matrix product state as an example and show that with an\nuntrained GTN (such as a random TN state), the negative logarithmic likelihood\n(NLL) $L$ generally increases linearly with the number of features $M$, i.e.,\n$L \\simeq k M + const$. This is a consequence of the so-called ``catastrophe of\northogonality,'' which states that quantum many-body states tend to become\nexponentially orthogonal to each other as $M$ increases. We reveal that while\ngaining information through training, the linear scaling law is suppressed by a\nnegative quadratic correction, leading to $L \\simeq \\beta M - \\alpha M^2 +\nconst$. The scaling coefficients exhibit logarithmic relationships with the\nnumber of training samples and the number of quantum channels $\\chi$. The\nemergence of the quadratic correction term in NLL for the testing (training)\nset can be regarded as evidence of the generalization (representation) power of\nGTN. Over-parameterization can be identified by the deviation in the values of\n$\\alpha$ between training and testing sets while increasing $\\chi$. We further\ninvestigate how orthogonality in the quantum feature map relates to the\nsatisfaction of quantum probabilistic interpretation, as well as to the\nrepresentation and generalization powers of GTN. The unveiling of universal\nscaling laws in quantum-probabilistic ML would be a valuable step toward\nestablishing a white-box ML scheme interpreted within the quantum probabilistic\nframework.",
      "tldr_zh": "本文揭示了量子-概率机器学习中的通用缩放定律，通过生成性张量网络（GTN），如矩阵乘积状态（MPS），分析了负对数似然（NLL）的行为：未训练模型下，NLL 与特征数 M 线性增加（L ≈ k M + const），而训练后出现负二次修正（L ≈ β M - α M^2 + const），这与训练样本数和量子通道数 χ 的对数关系相关。二次修正项体现了 GTN 的表示（训练集）和泛化（测试集）能力，并可通过 α 的偏差识别过参数化问题。该研究还探讨了量子特征映射中的正交性与量子概率解释的关联，为建立白盒机器学习方案提供了重要基础。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "quant-ph",
      "comment": "5 pages (main text) + 3 pages (appendices), 5 figures (main text) + 4\n  figures (appendices)",
      "pdf_url": "http://arxiv.org/pdf/2410.09703v1",
      "published_date": "2024-10-13 02:48:08 UTC",
      "updated_date": "2024-10-13 02:48:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:02:59.378044"
    },
    {
      "arxiv_id": "2410.09699v1",
      "title": "Honest AI: Fine-Tuning \"Small\" Language Models to Say \"I Don't Know\", and Reducing Hallucination in RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Xinxi Chen",
        "Li Wang",
        "Wei Wu",
        "Qi Tang",
        "Yiyao Liu"
      ],
      "abstract": "Hallucination is a key roadblock for applications of Large Language Models\n(LLMs), particularly for enterprise applications that are sensitive to\ninformation accuracy. To address this issue, two general approaches have been\nexplored: Retrieval-Augmented Generation (RAG) to supply LLMs with updated\ninformation as context, and fine-tuning the LLMs with new information and\ndesired output styles. In this paper, we propose Honest AI: a novel strategy to\nfine-tune \"small\" language models to say \"I don't know\" to reduce\nhallucination, along with several alternative RAG approaches. The solution\nranked 1st in Task 2 for the false premise question. The alternative approaches\ninclude using RAG with search engine and knowledge graph results, fine-tuning\nbase LLMs with new information and combinations of both approaches. Although\nall approaches improve the performance of the LLMs, RAG alone does not\nsignificantly improve the performance and fine-tuning is needed for better\nresults. Finally, the hybrid approach achieved the highest score in the CRAG\nbenchmark. In addition, our approach emphasizes the use of relatively small\nmodels with fewer than 10 billion parameters, promoting resource efficiency.",
      "tldr_zh": "这篇论文提出 Honest AI 策略，通过 fine-tuning \"small\" language models 来训练模型学会说 \"I don't know\"，从而减少 Large Language Models (LLMs) 中的 hallucination 问题。研究者探索了多种方法，包括使用 Retrieval-Augmented Generation (RAG) 与搜索引擎和知识图谱结合、直接 fine-tuning 基模型，以及二者的混合方式。实验结果显示，RAG 单独使用效果不显著，而混合方法在 CRAG 基准中取得了最高分数，并在特定任务中排名第一；此外，该方法强调使用少于 10 亿参数的小模型，以提升资源效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09699v1",
      "published_date": "2024-10-13 02:34:47 UTC",
      "updated_date": "2024-10-13 02:34:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:03:11.176923"
    },
    {
      "arxiv_id": "2410.10901v1",
      "title": "3DS: Decomposed Difficulty Data Selection's Case Study on LLM Medical Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Hongxin Ding",
        "Yue Fang",
        "Runchuan Zhu",
        "Xinke Jiang",
        "Jinyang Zhang",
        "Yongxin Xu",
        "Xu Chu",
        "Junfeng Zhao",
        "Yasha Wang"
      ],
      "abstract": "Large Language Models(LLMs) excel in general tasks but struggle in\nspecialized domains like healthcare due to limited domain-specific\nknowledge.Supervised Fine-Tuning(SFT) data construction for domain adaptation\noften relies on heuristic methods, such as GPT-4 annotation or manual data\nselection, with a data-centric focus on presumed diverse, high-quality\ndatasets. However, these methods overlook the model's inherent knowledge\ndistribution, introducing noise, redundancy, and irrelevant data, leading to a\nmismatch between the selected data and the model's learning task, resulting in\nsuboptimal performance. To address this, we propose a two-stage model-centric\ndata selection framework, Decomposed Difficulty Data Selection (3DS), which\naligns data with the model's knowledge distribution for optimized adaptation.\nIn Stage1, we apply Prompt-Driven Data Selection via Explicit Alignment, where\nthe the model filters irrelevant or redundant data based on its internal\nknowledge. In Stage2, we perform Decomposed Difficulty Data Selection, where\ndata selection is guided by our defined difficulty decomposition, using three\nmetrics: Instruction Understanding, Response Confidence, and Response\nCorrectness. Additionally, an attention-based importance weighting mechanism\ncaptures token importance for more accurate difficulty calibration. This\ntwo-stage approach ensures the selected data is not only aligned with the\nmodel's knowledge and preferences but also appropriately challenging for the\nmodel to learn, leading to more effective and targeted domain adaptation. In\nthe case study of the medical domain, our extensive experiments on real-world\nhealthcare datasets demonstrate the superiority of 3DS over exisiting methods\nin accuracy by over 5.29%. Our dataset and code will be open-sourced at\nhttps://anonymous.4open.science/r/3DS-E67F.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 在医疗领域的适应性问题，提出了一种两阶段模型导向数据选择框架——Decomposed Difficulty Data Selection (3DS)，以解决传统 Supervised Fine-Tuning (SFT) 方法中数据噪声和冗余问题。框架的第一阶段通过 Prompt-Driven Data Selection via Explicit Alignment，利用模型内部知识过滤无关数据；第二阶段则基于 Instruction Understanding、Response Confidence 和 Response Correctness 等指标进行难度分解，并采用 attention-based importance weighting 机制来优化数据难度校准，从而提升模型的学习效率。在医疗数据集的案例研究中，3DS 比现有方法提高了超过 5.29% 的准确率，为 LLMs 的领域适应提供了更有效的策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10901v1",
      "published_date": "2024-10-13 02:29:00 UTC",
      "updated_date": "2024-10-13 02:29:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:03:24.387569"
    },
    {
      "arxiv_id": "2410.09695v3",
      "title": "Can In-context Learning Really Generalize to Out-of-distribution Tasks?",
      "title_zh": "上下文学习是否真正能泛化到分布外任务？",
      "authors": [
        "Qixun Wang",
        "Yifei Wang",
        "Yisen Wang",
        "Xianghua Ying"
      ],
      "abstract": "In this work, we explore the mechanism of in-context learning (ICL) on\nout-of-distribution (OOD) tasks that were not encountered during training. To\nachieve this, we conduct synthetic experiments where the objective is to learn\nOOD mathematical functions through ICL using a GPT-2 model. We reveal that\nTransformers may struggle to learn OOD task functions through ICL.\nSpecifically, ICL performance resembles implementing a function within the\npretraining hypothesis space and optimizing it with gradient descent based on\nthe in-context examples. Additionally, we investigate ICL's well-documented\nability to learn unseen abstract labels in context. We demonstrate that such\nability only manifests in the scenarios without distributional shifts and,\ntherefore, may not serve as evidence of new-task-learning ability. Furthermore,\nwe assess ICL's performance on OOD tasks when the model is pretrained on\nmultiple tasks. Both empirical and theoretical analyses demonstrate the\nexistence of the \\textbf{low-test-error preference} of ICL, where it tends to\nimplement the pretraining function that yields low test error in the testing\ncontext. We validate this through numerical experiments. This new theoretical\nresult, combined with our empirical findings, elucidates the mechanism of ICL\nin addressing OOD tasks.",
      "tldr_zh": "本研究探讨了 In-context Learning (ICL) 是否能真正泛化到 Out-of-distribution (OOD) 任务，通过使用 GPT-2 模型进行合成实验来学习 OOD 数学函数。结果显示，Transformers 在通过 ICL 学习 OOD 任务时可能表现不佳，类似于在预训练假设空间内基于上下文示例优化函数。研究进一步发现，ICL 仅在无分布偏移的场景中能有效学习未见抽象标签，且当模型在多任务上预训练时，会表现出 low-test-error preference，即优先实现预训练函数以降低测试错误。总体而言，这些经验和理论分析阐明了 ICL 处理 OOD 任务的机制及其局限性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint, under review",
      "pdf_url": "http://arxiv.org/pdf/2410.09695v3",
      "published_date": "2024-10-13 02:10:26 UTC",
      "updated_date": "2024-12-04 15:35:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:03:33.900217"
    },
    {
      "arxiv_id": "2410.09693v1",
      "title": "Neural Solver Selection for Combinatorial Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Chengrui Gao",
        "Haopu Shang",
        "Ke Xue",
        "Chao Qian"
      ],
      "abstract": "Machine learning has increasingly been employed to solve NP-hard\ncombinatorial optimization problems, resulting in the emergence of neural\nsolvers that demonstrate remarkable performance, even with minimal\ndomain-specific knowledge. To date, the community has created numerous\nopen-source neural solvers with distinct motivations and inductive biases.\nWhile considerable efforts are devoted to designing powerful single solvers,\nour findings reveal that existing solvers typically demonstrate complementary\nperformance across different problem instances. This suggests that significant\nimprovements could be achieved through effective coordination of neural solvers\nat the instance level. In this work, we propose the first general framework to\ncoordinate the neural solvers, which involves feature extraction, selection\nmodel, and selection strategy, aiming to allocate each instance to the most\nsuitable solvers. To instantiate, we collect several typical neural solvers\nwith state-of-the-art performance as alternatives, and explore various methods\nfor each component of the framework. We evaluated our framework on two\nextensively studied combinatorial optimization problems, Traveling Salesman\nProblem (TSP) and Capacitated Vehicle Routing Problem (CVRP). Experimental\nresults show that the proposed framework can effectively distribute instances\nand the resulting composite solver can achieve significantly better performance\n(e.g., reduce the optimality gap by 0.88\\% on TSPLIB and 0.71\\% on CVRPLIB)\nthan the best individual neural solver with little extra time cost.",
      "tldr_zh": "本研究发现，现有的神经求解器（neural solvers）在解决 NP-hard 组合优化问题时表现出互补性能，因此提出一个通用框架，用于在实例级别协调这些求解器。该框架包括特征提取、选择模型和选择策略，旨在为每个问题实例分配最合适的求解器。实验结果显示，在 Traveling Salesman Problem (TSP) 和 Capacitated Vehicle Routing Problem (CVRP) 上，该框架能有效分配实例，并使组合求解器比最佳单个求解器显著提升性能（如在 TSPLIB 上减少 0.88% 的最优性差距，在 CVRPLIB 上减少 0.71%），且额外时间成本很小。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09693v1",
      "published_date": "2024-10-13 02:05:41 UTC",
      "updated_date": "2024-10-13 02:05:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:03:46.183786"
    },
    {
      "arxiv_id": "2410.09692v1",
      "title": "ALLoRA: Adaptive Learning Rate Mitigates LoRA Fatal Flaws",
      "title_zh": "ALLoRA：自适应学习率缓解 LoRA 的致命缺陷",
      "authors": [
        "Hai Huang",
        "Randall Balestriero"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) is the bread and butter of Large Language Model\n(LLM) finetuning. LoRA learns an additive low-rank perturbation, $AB$, of a\npretrained matrix parameter $W$ to align the model to a new task or dataset\nwith $W+AB$. We identify three core limitations to LoRA for finetuning--a\nsetting that employs limited amount of data and training steps. First, LoRA\nemploys Dropout to prevent overfitting. We prove that Dropout is only suitable\nfor long training episodes but fails to converge to a reliable regularizer for\nshort training episodes. Second, LoRA's initialization of $B$ at $0$ creates a\nslow training dynamic between $A$ and $B$. That dynamic is also exacerbated by\nDropout that further slows the escape from $0$ for $B$ which is particularly\nharmful for short training episodes. Third, the scaling factor multiplying each\nLoRA additive perturbation creates ``short-sighted'' interactions between the\nLoRA modules of different layers. Motivated by principled analysis of those\nlimitations, we find an elegant solution: a Dropout-free, scaling-free, LoRA\nwith Adaptive Learning rate--coined ALLoRA. By scaling the per sample and per\nparameter gradients with a coefficient inversely proportional to parameters'\n$\\ell_2$ norm, ALLoRA alleviates those three limitations. As a by-product,\nALLoRA removes two hyper-parameters from LoRA: the scaling factor and the\ndropout rate. Empirical results show that ALLoRA admits better accuracy than\nLoRA on various settings, including against recent LoRA variants such as\nWeight-Decomposed Low-Rank Adaptation (DoRA). Ablation studies show our\nsolution is the optimal in a family of weight-dependent / output-dependent\napproaches on various LLMs including the latest Llama3.",
      "tldr_zh": "该论文识别出Low-Rank Adaptation (LoRA) 在大语言模型 (LLM) 微调中的三个核心缺陷：Dropout 无法在短训练周期中有效防止过拟合、B 的零初始化导致训练动态缓慢，以及缩放因子引起层间交互的“短视”问题。作者提出ALLoRA，一种无Dropout和无缩放因子的改进方法，通过按参数的$\\ell_2$范数反比缩放梯度来实现自适应学习率，从而缓解这些限制，并简化了模型设计（移除缩放因子和Dropout率超参数）。实验结果显示，ALLoRA 在各种LLM设置下比LoRA及其变体（如DoRA）表现出更高的准确率，并在消融研究中证明其在Llama3等模型上的优越性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09692v1",
      "published_date": "2024-10-13 01:57:38 UTC",
      "updated_date": "2024-10-13 01:57:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:03:58.310748"
    },
    {
      "arxiv_id": "2410.09691v2",
      "title": "Robust 3D Point Clouds Classification based on Declarative Defenders",
      "title_zh": "翻译失败",
      "authors": [
        "Kaidong Li",
        "Tianxiao Zhang",
        "Cuncong Zhong",
        "Ziming Zhang",
        "Guanghui Wang"
      ],
      "abstract": "3D point cloud classification requires distinct models from 2D image\nclassification due to the divergent characteristics of the respective input\ndata. While 3D point clouds are unstructured and sparse, 2D images are\nstructured and dense. Bridging the domain gap between these two data types is a\nnon-trivial challenge to enable model interchangeability. Recent research using\nLattice Point Classifier (LPC) highlights the feasibility of cross-domain\napplicability. However, the lattice projection operation in LPC generates 2D\nimages with disconnected projected pixels. In this paper, we explore three\ndistinct algorithms for mapping 3D point clouds into 2D images. Through\nextensive experiments, we thoroughly examine and analyze their performance and\ndefense mechanisms. Leveraging current large foundation models, we scrutinize\nthe feature disparities between regular 2D images and projected 2D images. The\nproposed approaches demonstrate superior accuracy and robustness against\nadversarial attacks. The generative model-based mapping algorithms yield\nregular 2D images, further minimizing the domain gap from regular 2D\nclassification tasks. The source code is available at\nhttps://github.com/KaidongLi/pytorch-LatticePointClassifier.git.",
      "tldr_zh": "本论文探讨了将3D point clouds映射到2D images的挑战，以桥接两者在结构和密度的领域差距，并提出三种不同的映射算法作为declarative defenders。研究通过广泛实验分析这些算法的性能、防御机制，并利用大型基础模型检查投影图像的特征差异。结果表明，所提方法显著提高了3D point clouds分类的准确性和对adversarial attacks的鲁棒性，其中基于生成模型的算法能生成常规2D images，进一步缩小了与传统2D分类任务的领域差距。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09691v2",
      "published_date": "2024-10-13 01:32:38 UTC",
      "updated_date": "2024-10-19 01:52:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:04:10.887746"
    },
    {
      "arxiv_id": "2410.09687v1",
      "title": "MoIN: Mixture of Introvert Experts to Upcycle an LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Ajinkya Tejankar",
        "KL Navaneet",
        "Ujjawal Panchal",
        "Kossar Pourahmadi",
        "Hamed Pirsiavash"
      ],
      "abstract": "The goal of this paper is to improve (upcycle) an existing large language\nmodel without the prohibitive requirements of continued pre-training of the\nfull-model. The idea is to split the pre-training data into semantically\nrelevant groups and train an expert on each subset. An expert takes the form of\na lightweight adapter added on the top of a frozen base model. During\ninference, an incoming query is first routed to the most relevant expert which\nis then loaded onto the base model for the forward pass. Unlike typical Mixture\nof Experts (MoE) models, the experts in our method do not work with other\nexperts for a single query. Hence, we dub them \"introvert\" experts. Freezing\nthe base model and keeping the experts as lightweight adapters allows extreme\nparallelism during training and inference. Training of all experts can be done\nin parallel without any communication channels between them. Similarly, the\ninference can also be heavily parallelized by distributing experts on different\nGPUs and routing each request to the GPU containing its relevant expert. We\nimplement a proof-of-concept version of this method and show the validity of\nour approach.",
      "tldr_zh": "这篇论文提出了MoIN框架，即Mixture of Introvert Experts，用于提升现有的大型语言模型(LLM)，而无需进行完整的继续预训练。方法包括将预训练数据分成语义相关的子集，每个子集训练一个轻量级适配器作为“introvert” experts，这些experts不与其他experts协作，而是独立添加到冻结的基模型上。推理过程中，通过路由机制将查询定向到最相关experts，实现训练和推理的极高并行性，如在不同GPU上分布experts。实验证明了该方法的有效性，通过概念验证展示了其在提升LLM性能方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09687v1",
      "published_date": "2024-10-13 01:11:04 UTC",
      "updated_date": "2024-10-13 01:11:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:04:22.122066"
    },
    {
      "arxiv_id": "2410.09686v2",
      "title": "Generalization of Compositional Tasks with Logical Specification via Implicit Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Duo Xu",
        "Faramarz Fekri"
      ],
      "abstract": "In this study, we address the challenge of learning generalizable policies\nfor compositional tasks defined by logical specifications. These tasks consist\nof multiple temporally extended sub-tasks. Due to the sub-task\ninter-dependencies and sparse reward issue in long-horizon tasks, existing\nreinforcement learning (RL) approaches, such as task-conditioned and\ngoal-conditioned policies, continue to struggle with slow convergence and\nsub-optimal performance in generalizing to compositional tasks. To overcome\nthese limitations, we introduce a new hierarchical RL framework that enhances\nthe efficiency and optimality of task generalization. At the high level, we\npresent an implicit planner specifically designed for generalizing\ncompositional tasks. This planner selects the next sub-task and estimates the\nmulti-step return for completing the remaining task to complete from the\ncurrent state. It learns a latent transition model and performs planning in the\nlatent space by using a graph neural network (GNN). Subsequently, the\nhigh-level planner's selected sub-task guides the low-level agent to\neffectively handle long-horizon tasks, while the multi-step return encourages\nthe low-level policy to account for future sub-task dependencies, enhancing its\noptimality. We conduct comprehensive experiments to demonstrate the framework's\nadvantages over previous methods in terms of both efficiency and optimality.",
      "tldr_zh": "本研究针对由逻辑规范定义的组合任务（compositional tasks）学习可泛化的策略，这些任务涉及多个时间延展子任务（temporally extended sub-tasks），但现有强化学习（RL）方法因子任务依赖和稀疏奖励而面临收敛慢和性能不佳的问题。论文提出一个分层RL框架，包括一个隐式规划器（implicit planner），该规划器在潜在空间使用图神经网络（GNN）来选择下一个子任务并估计多步回报，从而指导低层代理处理长horizon任务并提升策略的优化性。该框架通过高层次规划增强任务泛化效率，同时考虑未来子任务依赖。该方法在全面实验中显示出比现有方法更高的效率和优化性能。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09686v2",
      "published_date": "2024-10-13 00:57:10 UTC",
      "updated_date": "2024-11-02 17:17:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:04:34.924759"
    },
    {
      "arxiv_id": "2410.09681v3",
      "title": "LoRD: Adapting Differentiable Driving Policies to Distribution Shifts",
      "title_zh": "翻译失败",
      "authors": [
        "Christopher Diehl",
        "Peter Karkus",
        "Sushant Veer",
        "Marco Pavone",
        "Torsten Bertram"
      ],
      "abstract": "Distribution shifts between operational domains can severely affect the\nperformance of learned models in self-driving vehicles (SDVs). While this is a\nwell-established problem, prior work has mostly explored naive solutions such\nas fine-tuning, focusing on the motion prediction task. In this work, we\nexplore novel adaptation strategies for differentiable autonomy stacks\nconsisting of prediction, planning, and control, perform evaluation in\nclosed-loop, and investigate the often-overlooked issue of catastrophic\nforgetting. Specifically, we introduce two simple yet effective techniques: a\nlow-rank residual decoder (LoRD) and multi-task fine-tuning. Through\nexperiments across three models conducted on two real-world autonomous driving\ndatasets (nuPlan, exiD), we demonstrate the effectiveness of our methods and\nhighlight a significant performance gap between open-loop and closed-loop\nevaluation in prior approaches. Our approach improves forgetting by up to\n23.33% and the closed-loop OOD driving score by 9.93% in comparison to standard\nfine-tuning.",
      "tldr_zh": "该论文探讨了自驾车辆（SDVs）中分布偏移（Distribution Shifts）对可微分驾驶策略（Differentiable Driving Policies）性能的影响，提出两种简单有效的适应技术：低秩残差解码器（LoRD）和多任务微调，以优化自治栈中的预测、规划和控制模块。实验在nuPlan和exiD两个真实世界自动驾驶数据集上进行，展示了这些方法在闭环评估中显著减少灾难性遗忘（up to 23.33%）并提高OOD驾驶分数（9.93%），同时突出了开放循环和闭环评估之间的性能差距。总的来说，该方法为更鲁棒的自驾系统提供了实用改进。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "IEEE International Conference on Robotics & Automation, ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.09681v3",
      "published_date": "2024-10-13 00:36:11 UTC",
      "updated_date": "2025-03-28 14:35:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:04:46.711807"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 68,
  "processed_papers_count": 68,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T11:05:04.511629"
}