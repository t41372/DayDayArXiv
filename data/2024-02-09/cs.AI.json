{
  "date": "2024-02-09",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-09 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和机器学习的创新应用，包括大型语言模型（LLMs）的优化、强化学习、多模态模型在决策和生成中的潜力，以及一些跨领域应用如医疗和机器人；重点是 LLMs 的鲁棒性与解释性提升，以及知名学者如 Samuel R. Bowman 参与的辩论模型研究；令人印象深刻的文章包括使用 LLMs 进行高效提示优化和生成式 AI 在实际场景中的应用，这些工作展示了 AI 在复杂任务中的潜力。\n\n下面，我将挑选并简要讨论几篇重要的、相关性强的论文，先从 AI 语言模型和强化学习领域入手，再扩展到多模态模型和应用场景。其他较次要的论文（如某些纯理论数学或小众领域）将快速掠过，只提及核心点，以控制篇幅。\n\n### AI 语言模型优化与辩论\n- **The Unreasonable Effectiveness of Eccentric Automatic Prompts（非常规自动提示的有效性）**  \n  这篇论文探讨了在大型语言模型中融入“积极思维”提示如何影响性能，通过测试 60 种提示组合，发现积极提示通常提升模型在 GSM8K 数据集上的表现，但 Llama2-70B 在不使用 Chain of Thought 时例外；主要贡献是证明自动提示优化比手动调优更有效，尤其在处理黑盒模型时。\n\n- **Debating with More Persuasive LLMs Leads to More Truthful Answers（使用更具说服力的 LLMs 进行辩论可获得更真实的答案）**  \n  作者包括知名学者 Samuel R. Bowman，该研究使用辩论机制让 LLMs 在无真实标签下评估答案，证明说服力更强的模型能提高非专家（如人类）的准确率至 88%；关键发现是无监督优化辩论模型能提升 AI 在事实性任务中的可靠性，为无标签场景下的 AI 训练提供新路径。\n\n- **Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning（Aya 数据集：一个用于多语言指令微调的开源集合）**  \n  这篇工作构建了覆盖 65 种语言的 5.13 亿指令数据集，用于训练多语言 LLMs；主要贡献是通过人类协作和翻译生成高质量数据，提升模型在低资源语言上的性能，并提出 Aya 评估框架，促进 AI 在全球语言多样性中的应用。\n\n### 强化学习与决策优化\n- **Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following（Diffusion-ES：基于扩散的无梯度规划，用于自动驾驶和零样本指令遵循）**  \n  论文提出一种结合扩散模型和进化搜索的强化学习方法，用于优化自动驾驶轨迹；关键发现是它在 nuPlan 数据集上超越基线，提升任务成功率，并能处理非微分奖励函数，支持零样本指令，展示了 AI 在实时决策中的潜力。\n\n- **Corruption Robust Offline Reinforcement Learning with Human Feedback（鲁棒性离线强化学习：结合人类反馈处理数据噪声）**  \n  这篇研究针对离线 RL 中的数据噪声问题，设计了鲁棒算法，通过置信集和悲观优化提升模型性能；主要贡献是证明在数据覆盖假设下，该方法能有效抵抗噪声，提供可靠的策略学习，为实际应用如机器人控制带来启发。\n\n### 多模态模型与计算机视觉应用\n- **Is it safe to cross? Interpretable Risk Assessment with GPT-4V for Safety-Aware Street Crossing（过马路安全吗？使用 GPT-4V 的可解释风险评估，支持安全意识的街道路口穿越）**  \n  论文利用多模态模型 GPT-4V 分析街道路口图像，提供安全分数和自然语言描述；主要发现是模型在多视图图像上预测准确，提升了盲人或视力障碍者的决策支持，展示了 LMMs 在可解释 AI 应用中的价值。\n\n- **ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling（ViGoR：通过细粒度奖励建模提升视觉语言模型的视觉 grounding）**  \n  该工作使用奖励建模优化多模态 LLMs 的视觉 grounding，减少幻觉问题；关键贡献是通过人类反馈微调模型，在图像生成任务上提升准确性，并开源数据集，适用于视觉任务的鲁棒性提升。\n\n其他论文如关于数据增强、图神经网络或特定领域（如医疗图像分析）的，如 **Transfer learning with generative models for object detection on limited datasets（在有限数据集上使用生成模型的迁移学习进行物体检测）**，主要贡献是证明扩散模型能在少量数据下提升检测性能；或 **ExGRG: Explicitly-Generated Relation Graph for Self-Supervised Representation Learning（ExGRG：用于自监督表示学习的显式生成关系图）**，展示了自监督学习在图数据中的应用。这些工作虽有价值，但相对次要，我仅简要提及以节省篇幅。\n\n总之，今天的 arXiv 论文突显了 AI 模型在效率、鲁棒性和实际应用上的进展，LLMs 的辩论和优化技术尤其值得关注。如果您对特定领域感兴趣，建议查看这些关键论文的细节！",
  "papers": [
    {
      "arxiv_id": "2402.10949v2",
      "title": "The Unreasonable Effectiveness of Eccentric Automatic Prompts",
      "title_zh": "古怪自动提示的不可理喻有效性",
      "authors": [
        "Rick Battle",
        "Teja Gollapudi"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable problem-solving and\nbasic mathematics abilities. However, their efficacy is highly contingent on\nthe formulation of the prompt. This study endeavors to quantify the influence\nof incorporating \"positive thinking\" into the system message of the prompt,\nthen compare that to systematic prompt optimization. We assess the performance\nof 60 combinations of system message snippets, tested with and without Chain of\nThought prompting, across three models with parameters ranging from 7 to 70\nbillion on the GSM8K dataset. Our findings reveal that results do not\nuniversally generalize across models. In most instances, the inclusion of\n\"positive thinking\" prompts positively affected model performance. Notably,\nhowever, Llama2-70B exhibited an exception when not utilizing Chain of Thought,\nas the optimal system message was found to be none at all. Given the\ncombinatorial complexity, and thus computation time, of experimenting with\nhand-tuning prompts for large black-box models, we then compared the\nperformance of the best \"positive thinking\" prompt against the output of\nsystematic prompt optimization. We show that employing an automated prompt\noptimizer emerges as the most effective method for enhancing performance, even\nwhen working with smaller open-source models. Additionally, our findings reveal\nthat the highest-scoring, automatically-optimized prompt exhibits a degree of\npeculiarity far beyond expectations.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 的性能如何受提示（prompt）影响，特别量化了在系统消息中加入“positive thinking”元素的有效性，并与系统化提示优化进行比较。研究者测试了60种系统消息组合，使用和不使用 Chain of Thought (CoT) 提示，在参数从7B到70B的三个模型上评估 GSM8K 数据集，结果显示这种提示通常提升性能，但 Llama2-70B 在不使用 CoT 时最优方案是无系统消息。最终发现，自动提示优化是最有效的方法，即使在小型开源模型上，且自动生成的优化提示显示出异常的“eccentric”特性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10949v2",
      "published_date": "2024-02-09 22:48:45 UTC",
      "updated_date": "2024-02-20 15:03:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:50:01.530643"
    },
    {
      "arxiv_id": "2402.06811v1",
      "title": "Discipline and Label: A WEIRD Genealogy and Social Theory of Data Annotation",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Smart",
        "Ding Wang",
        "Ellis Monk",
        "Mark Díaz",
        "Atoosa Kasirzadeh",
        "Erin Van Liemt",
        "Sonja Schmer-Galunder"
      ],
      "abstract": "Data annotation remains the sine qua non of machine learning and AI. Recent\nempirical work on data annotation has begun to highlight the importance of\nrater diversity for fairness, model performance, and new lines of research have\nbegun to examine the working conditions for data annotation workers, the\nimpacts and role of annotator subjectivity on labels, and the potential\npsychological harms from aspects of annotation work. This paper outlines a\ncritical genealogy of data annotation; starting with its psychological and\nperceptual aspects. We draw on similarities with critiques of the rise of\ncomputerized lab-based psychological experiments in the 1970's which question\nwhether these experiments permit the generalization of results beyond the\nlaboratory settings within which these results are typically obtained. Do data\nannotations permit the generalization of results beyond the settings, or\nlocations, in which they were obtained? Psychology is overly reliant on\nparticipants from Western, Educated, Industrialized, Rich, and Democratic\nsocieties (WEIRD). Many of the people who work as data annotation platform\nworkers, however, are not from WEIRD countries; most data annotation workers\nare based in Global South countries. Social categorizations and classifications\nfrom WEIRD countries are imposed on non-WEIRD annotators through instructions\nand tasks, and through them, on data, which is then used to train or evaluate\nAI models in WEIRD countries. We synthesize evidence from several recent lines\nof research and argue that data annotation is a form of automated social\ncategorization that risks entrenching outdated and static social categories\nthat are in reality dynamic and changing. We propose a framework for\nunderstanding the interplay of the global social conditions of data annotation\nwith the subjective phenomenological experience of data annotation work.",
      "tldr_zh": "这篇论文探讨了数据标注在机器学习和 AI 中的核心作用，强调标注者多样性对公平性和模型性能的影响，以及标注工作者的工作条件、主观性和潜在心理伤害。作者从心理学角度进行批判性谱系分析，指出数据标注类似于1970年代计算机化实验的问题，导致结果难以泛化，特别是心理学过度依赖WEIRD（Western, Educated, Industrialized, Rich, and Democratic）社会参与者，而实际标注工人多来自全球南方国家，从而强化了静态的社会分类。论文提出一个框架，分析数据标注作为自动化社会分类的机制，以及其全球社会条件与主观体验的互动，以揭示潜在风险并推动更具包容性的AI发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.06811v1",
      "published_date": "2024-02-09 22:21:55 UTC",
      "updated_date": "2024-02-09 22:21:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:50:13.539617"
    },
    {
      "arxiv_id": "2402.06810v1",
      "title": "Evaluating Co-Creativity using Total Information Flow",
      "title_zh": "利用总信息流评估共同创造性",
      "authors": [
        "Vignesh Gokul",
        "Chris Francis",
        "Shlomo Dubnov"
      ],
      "abstract": "Co-creativity in music refers to two or more musicians or musical agents\ninteracting with one another by composing or improvising music. However, this\nis a very subjective process and each musician has their own preference as to\nwhich improvisation is better for some context. In this paper, we aim to create\na measure based on total information flow to quantitatively evaluate the\nco-creativity process in music. In other words, our measure is an indication of\nhow \"good\" a creative musical process is. Our main hypothesis is that a good\nmusical creation would maximize information flow between the participants\ncaptured by music voices recorded in separate tracks. We propose a method to\ncompute the information flow using pre-trained generative models as entropy\nestimators. We demonstrate how our method matches with human perception using a\nqualitative study.",
      "tldr_zh": "本论文探讨了音乐领域的共同创造性（co-creativity），即两个或多个音乐家或代理通过作曲或即兴创作互动的过程，并提出了一种基于总信息流（total information flow）的量化评估方法，以客观衡量创作质量。研究假设优秀的音乐创作会最大化参与者之间通过独立音乐轨道捕获的信息流，并使用预训练生成模型作为熵估计器来计算这一信息流。实验结果通过一个定性研究验证，该方法与人类感知高度一致，为评估co-creativity提供了可靠的工具。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.HC",
        "cs.IT",
        "cs.LG",
        "eess.AS",
        "math.IT"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06810v1",
      "published_date": "2024-02-09 22:15:39 UTC",
      "updated_date": "2024-02-09 22:15:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:50:24.917782"
    },
    {
      "arxiv_id": "2402.06794v2",
      "title": "Is it safe to cross? Interpretable Risk Assessment with GPT-4V for Safety-Aware Street Crossing",
      "title_zh": "翻译失败",
      "authors": [
        "Hochul Hwang",
        "Sunjae Kwon",
        "Yekyung Kim",
        "Donghyun Kim"
      ],
      "abstract": "Safely navigating street intersections is a complex challenge for blind and\nlow-vision individuals, as it requires a nuanced understanding of the\nsurrounding context - a task heavily reliant on visual cues. Traditional\nmethods for assisting in this decision-making process often fall short, lacking\nthe ability to provide a comprehensive scene analysis and safety level. This\npaper introduces an innovative approach that leverages large multimodal models\n(LMMs) to interpret complex street crossing scenes, offering a potential\nadvancement over conventional traffic signal recognition techniques. By\ngenerating a safety score and scene description in natural language, our method\nsupports safe decision-making for the blind and low-vision individuals. We\ncollected crosswalk intersection data that contains multiview egocentric images\ncaptured by a quadruped robot and annotated the images with corresponding\nsafety scores based on our predefined safety score categorization. Grounded on\nthe visual knowledge, extracted from images, and text prompt, we evaluate a\nlarge multimodal model for safety score prediction and scene description. Our\nfindings highlight the reasoning and safety score prediction capabilities of a\nLMM, activated by various prompts, as a pathway to developing a trustworthy\nsystem, crucial for applications requiring reliable decision-making support.",
      "tldr_zh": "这篇论文针对盲人和视力低下者安全穿越街道的挑战，提出了一种基于大型多模态模型(LMMs)如GPT-4V的可解释风险评估方法，以提供全面的场景分析和安全分数。研究团队收集了多视图第一人称图像数据，并通过文本提示和视觉知识评估LMM在安全分数预测和自然语言场景描述方面的性能。结果显示，该方法显著提升了决策支持的可信赖性，为可靠的辅助系统奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06794v2",
      "published_date": "2024-02-09 21:37:13 UTC",
      "updated_date": "2024-07-06 15:36:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:50:36.974049"
    },
    {
      "arxiv_id": "2402.06784v2",
      "title": "Transfer learning with generative models for object detection on limited datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Paiano",
        "Stefano Martina",
        "Carlotta Giannelli",
        "Filippo Caruso"
      ],
      "abstract": "The availability of data is limited in some fields, especially for object\ndetection tasks, where it is necessary to have correctly labeled bounding boxes\naround each object. A notable example of such data scarcity is found in the\ndomain of marine biology, where it is useful to develop methods to\nautomatically detect submarine species for environmental monitoring. To address\nthis data limitation, the state-of-the-art machine learning strategies employ\ntwo main approaches. The first involves pretraining models on existing datasets\nbefore generalizing to the specific domain of interest. The second strategy is\nto create synthetic datasets specifically tailored to the target domain using\nmethods like copy-paste techniques or ad-hoc simulators. The first strategy\noften faces a significant domain shift, while the second demands custom\nsolutions crafted for the specific task. In response to these challenges, here\nwe propose a transfer learning framework that is valid for a generic scenario.\nIn this framework, generated images help to improve the performances of an\nobject detector in a few-real data regime. This is achieved through a\ndiffusion-based generative model that was pretrained on large generic datasets.\nWith respect to the state-of-the-art, we find that it is not necessary to fine\ntune the generative model on the specific domain of interest. We believe that\nthis is an important advance because it mitigates the labor-intensive task of\nmanual labeling the images in object detection tasks. We validate our approach\nfocusing on fishes in an underwater environment, and on the more common domain\nof cars in an urban setting. Our method achieves detection performance\ncomparable to models trained on thousands of images, using only a few hundreds\nof input data. Our results pave the way for new generative AI-based protocols\nfor machine learning applications in various domains.",
      "tldr_zh": "该研究针对数据有限的物体检测任务（如海洋生物领域），提出了一种通用的transfer learning框架，使用预训练的diffusion-based generative model生成合成图像来提升检测性能。该框架无需在特定领域微调生成模型，从而避免了手动标注边界框的繁重工作。在实验中，方法在水下鱼类和城市汽车场景上，仅使用几百张真实图像，就实现了与数千张图像训练的模型相当的检测准确率。该创新为各种领域的机器学习应用提供了新的基于生成AI的协议。",
      "categories": [
        "cs.CV",
        "cond-mat.dis-nn",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.NA",
        "68T05, 68T07, 68T10, 68T45,",
        "I.2.6; I.2.0; I.4.8; I.4.9; I.5.1; I.5.0; I.5.4; J.3"
      ],
      "primary_category": "cs.CV",
      "comment": "28 pages, 16 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2402.06784v2",
      "published_date": "2024-02-09 21:17:31 UTC",
      "updated_date": "2024-06-13 10:09:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:50:48.968771"
    },
    {
      "arxiv_id": "2402.06782v4",
      "title": "Debating with More Persuasive LLMs Leads to More Truthful Answers",
      "title_zh": "翻译失败",
      "authors": [
        "Akbir Khan",
        "John Hughes",
        "Dan Valentine",
        "Laura Ruis",
        "Kshitij Sachan",
        "Ansh Radhakrishnan",
        "Edward Grefenstette",
        "Samuel R. Bowman",
        "Tim Rocktäschel",
        "Ethan Perez"
      ],
      "abstract": "Common methods for aligning large language models (LLMs) with desired\nbehaviour heavily rely on human-labelled data. However, as models grow\nincreasingly sophisticated, they will surpass human expertise, and the role of\nhuman evaluation will evolve into non-experts overseeing experts. In\nanticipation of this, we ask: can weaker models assess the correctness of\nstronger models? We investigate this question in an analogous setting, where\nstronger models (experts) possess the necessary information to answer questions\nand weaker models (non-experts) lack this information. The method we evaluate\nis debate, where two LLM experts each argue for a different answer, and a\nnon-expert selects the answer. We find that debate consistently helps both\nnon-expert models and humans answer questions, achieving 76% and 88% accuracy\nrespectively (naive baselines obtain 48% and 60%). Furthermore, optimising\nexpert debaters for persuasiveness in an unsupervised manner improves\nnon-expert ability to identify the truth in debates. Our results provide\nencouraging empirical evidence for the viability of aligning models with debate\nin the absence of ground truth.",
      "tldr_zh": "该研究探讨了在缺乏人类标记数据的情况下，如何通过辩论(debate)机制对齐大型语言模型(LLMs)，以帮助弱模型(non-experts)评估强模型(experts)的正确性。方法涉及让两个LLM专家为不同答案辩论，而非专家模型或人类从中选择答案。实验结果显示，辩论显著提升了非专家模型和人类的回答准确率，分别达到76%和88%，远超基线(48%和60%)。此外，通过无监督方式优化专家辩手的说服力(persuasiveness)，进一步提高了非专家识别真相的能力，为在没有ground truth的情况下使用辩论对齐模型提供了可行性证据。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "For code please check: https://github.com/ucl-dark/llm_debate",
      "pdf_url": "http://arxiv.org/pdf/2402.06782v4",
      "published_date": "2024-02-09 21:05:01 UTC",
      "updated_date": "2024-07-25 23:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:51:00.741032"
    },
    {
      "arxiv_id": "2402.06772v1",
      "title": "Retrosynthesis Prediction via Search in (Hyper) Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Zixun Lan",
        "Binjie Hong",
        "Jiajun Zhu",
        "Zuo Zeng",
        "Zhenfu Liu",
        "Limin Yu",
        "Fei Ma"
      ],
      "abstract": "Predicting reactants from a specified core product stands as a fundamental\nchallenge within organic synthesis, termed retrosynthesis prediction. Recently,\nsemi-template-based methods and graph-edits-based methods have achieved good\nperformance in terms of both interpretability and accuracy. However, due to\ntheir mechanisms these methods cannot predict complex reactions, e.g.,\nreactions with multiple reaction center or attaching the same leaving group to\nmore than one atom. In this study we propose a semi-template-based method, the\n\\textbf{Retro}synthesis via \\textbf{S}earch \\textbf{i}n (Hyper) \\textbf{G}raph\n(RetroSiG) framework to alleviate these limitations. In the proposed method, we\nturn the reaction center identification and the leaving group completion tasks\nas tasks of searching in the product molecular graph and leaving group\nhypergraph respectively. As a semi-template-based method RetroSiG has several\nadvantages. First, RetroSiG is able to handle the complex reactions mentioned\nabove by its novel search mechanism. Second, RetroSiG naturally exploits the\nhypergraph to model the implicit dependencies between leaving groups. Third,\nRetroSiG makes full use of the prior, i.e., one-hop constraint. It reduces the\nsearch space and enhances overall performance. Comprehensive experiments\ndemonstrated that RetroSiG achieved competitive results. Furthermore, we\nconducted experiments to show the capability of RetroSiG in predicting complex\nreactions. Ablation experiments verified the efficacy of specific elements,\nsuch as the one-hop constraint and the leaving group hypergraph.",
      "tldr_zh": "本研究针对逆合成预测（Retrosynthesis Prediction）的挑战，提出了一种半模板方法 RetroSiG 框架，通过在产品分子图和离去基团超图（Hypergraph）中进行搜索，处理复杂反应如多个反应中心或重复离去基团。RetroSiG 的优势在于利用超图建模离去基团的隐式依赖，并通过一跳约束（one-hop constraint）减少搜索空间，提升整体性能。实验结果显示，RetroSiG 取得了竞争性的准确率，并在复杂反应预测中表现出色，消融实验进一步验证了关键元素的功效。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06772v1",
      "published_date": "2024-02-09 20:25:45 UTC",
      "updated_date": "2024-02-09 20:25:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:51:13.491382"
    },
    {
      "arxiv_id": "2402.06766v1",
      "title": "Evaluation Metrics for Text Data Augmentation in NLP",
      "title_zh": "翻译失败",
      "authors": [
        "Marcellus Amadeus",
        "William Alberto Cruz Castañeda"
      ],
      "abstract": "Recent surveys on data augmentation for natural language processing have\nreported different techniques and advancements in the field. Several\nframeworks, tools, and repositories promote the implementation of text data\naugmentation pipelines. However, a lack of evaluation criteria and standards\nfor method comparison due to different tasks, metrics, datasets, architectures,\nand experimental settings makes comparisons meaningless. Also, a lack of\nmethods unification exists and text data augmentation research would benefit\nfrom unified metrics to compare different augmentation methods. Thus, academics\nand the industry endeavor relevant evaluation metrics for text data\naugmentation techniques. The contribution of this work is to provide a taxonomy\nof evaluation metrics for text augmentation methods and serve as a direction\nfor a unified benchmark. The proposed taxonomy organizes categories that\ninclude tools for implementation and metrics calculation. Finally, with this\nstudy, we intend to present opportunities to explore the unification and\nstandardization of text data augmentation metrics.",
      "tldr_zh": "本研究针对自然语言处理（NLP）中的文本数据 augmentation 问题，指出现有技术缺乏统一的评价指标，导致不同任务、数据集和实验设置下的方法比较无效。论文贡献在于提出一个评价指标的分类法（taxonomy），涵盖实施工具和指标计算类别，以促进文本数据 augmentation 方法的标准化基准。最终，该工作旨在为学术界和行业提供方向，推动评价指标的统一和标准化，以提升研究的可比性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06766v1",
      "published_date": "2024-02-09 19:59:34 UTC",
      "updated_date": "2024-02-09 19:59:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:51:23.507554"
    },
    {
      "arxiv_id": "2402.06764v3",
      "title": "GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph Alignment via Neighborhood Partitioning and Generative Subgraph Encoding",
      "title_zh": "GLaM：通过邻域划分和生成子图编码微调大型语言模型以实现领域知识图谱对齐",
      "authors": [
        "Stefan Dernbach",
        "Khushbu Agarwal",
        "Alejandro Zuniga",
        "Michael Henry",
        "Sutanay Choudhury"
      ],
      "abstract": "Integrating large language models (LLMs) with knowledge graphs derived from\ndomain-specific data represents an important advancement towards more powerful\nand factual reasoning. As these models grow more capable, it is crucial to\nenable them to perform multi-step inferences over real-world knowledge graphs\nwhile minimizing hallucination. While large language models excel at\nconversation and text generation, their ability to reason over\ndomain-specialized graphs of interconnected entities remains limited. For\nexample, can we query a LLM to identify the optimal contact in a professional\nnetwork for a specific goal, based on relationships and attributes in a private\ndatabase? The answer is no--such capabilities lie beyond current methods.\nHowever, this question underscores a critical technical gap that must be\naddressed. Many high-value applications in areas such as science, security, and\ne-commerce rely on proprietary knowledge graphs encoding unique structures,\nrelationships, and logical constraints. We introduce a fine-tuning framework\nfor developing Graph-aligned LAnguage Models (GLaM) that transforms a knowledge\ngraph into an alternate text representation with labeled question-answer pairs.\nWe demonstrate that grounding the models in specific graph-based knowledge\nexpands the models' capacity for structure-based reasoning. Our methodology\nleverages the large-language model's generative capabilities to create the\ndataset and proposes an efficient alternate to retrieval-augmented generation\nstyled methods.",
      "tldr_zh": "本研究提出 GLaM 框架，通过微调 Large Language Models (LLMs) 来实现领域 Knowledge Graph 的对齐，提升模型在专有图谱上的结构化推理能力，以减少 hallucination 并支持多步推理。框架采用 Neighborhood Partitioning 和 Generative Subgraph Encoding 方法，将知识图谱转化为标记的问题-答案对文本表示，利用 LLMs 的生成能力创建数据集。相比传统的 Retrieval-Augmented Generation 风格方法，这种高效替代方案扩展了模型对实体关系和逻辑约束的处理能力，为科学、安全和电子商务等领域的应用提供了更可靠的推理支持。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in AAAI Spring Symposium: AAAI-MAKE 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.06764v3",
      "published_date": "2024-02-09 19:53:29 UTC",
      "updated_date": "2024-04-17 19:55:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:51:37.128485"
    },
    {
      "arxiv_id": "2402.06759v1",
      "title": "A Methodology for Questionnaire Analysis: Insights through Cluster Analysis of an Investor Competition Data",
      "title_zh": "翻译失败",
      "authors": [
        "Carlos Henrique Q. Forster",
        "Paulo André Lima de Castro",
        "Andrei Ramalho"
      ],
      "abstract": "In this paper, we propose a methodology for the analysis of questionnaire\ndata along with its application on discovering insights from investor data\nmotivated by a day trading competition. The questionnaire includes categorical\nquestions, which are reduced to binary questions, 'yes' or 'no'. The\nmethodology reduces dimensionality by grouping questions and participants with\nsimilar responses using clustering analysis. Rule discovery was performed by\nusing a conversion rate metric. Innovative visual representations were proposed\nto validate the cluster analysis and the relation discovery between questions.\nWhen crossing with financial data, additional insights were revealed related to\nthe recognized clusters.",
      "tldr_zh": "本文提出了一种问卷数据分析方法，并将其应用于投资者竞争数据的洞见发现。该方法首先将分类问题简化为二元问题（'yes' 或 'no'），然后通过cluster analysis减少维度，对类似响应的参与者和问题进行分组，并使用conversion rate metric进行规则发现，同时引入创新的可视化表示来验证聚类结果和问题间关系。通过与财务数据交叉分析，该方法揭示了与识别clusters相关的额外洞见，例如投资者行为的潜在模式。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "14 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.06759v1",
      "published_date": "2024-02-09 19:44:29 UTC",
      "updated_date": "2024-02-09 19:44:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:51:47.920918"
    },
    {
      "arxiv_id": "2402.06737v2",
      "title": "ExGRG: Explicitly-Generated Relation Graph for Self-Supervised Representation Learning",
      "title_zh": "ExGRG：显式生成的关联图用于自监督表示学习",
      "authors": [
        "Mahdi Naseri",
        "Mahdi Biparva"
      ],
      "abstract": "Self-supervised Learning (SSL) has emerged as a powerful technique in\npre-training deep learning models without relying on expensive annotated\nlabels, instead leveraging embedded signals in unlabeled data. While SSL has\nshown remarkable success in computer vision tasks through intuitive data\naugmentation, its application to graph-structured data poses challenges due to\nthe semantic-altering and counter-intuitive nature of graph augmentations.\nAddressing this limitation, this paper introduces a novel non-contrastive SSL\napproach to Explicitly Generate a compositional Relation Graph (ExGRG) instead\nof relying solely on the conventional augmentation-based implicit relation\ngraph. ExGRG offers a framework for incorporating prior domain knowledge and\nonline extracted information into the SSL invariance objective, drawing\ninspiration from the Laplacian Eigenmap and Expectation-Maximization (EM).\nEmploying an EM perspective on SSL, our E-step involves relation graph\ngeneration to identify candidates to guide the SSL invariance objective, and\nM-step updates the model parameters by integrating the derived relational\ninformation. Extensive experimentation on diverse node classification datasets\ndemonstrates the superiority of our method over state-of-the-art techniques,\naffirming ExGRG as an effective adoption of SSL for graph representation\nlearning.",
      "tldr_zh": "这篇论文提出了一种名为 ExGRG 的新型非对比自监督学习 (SSL) 方法，用于图结构数据的表示学习，以解决传统基于增强的隐式关系图可能改变语义的挑战。ExGRG 通过显式生成组合关系图，整合先验领域知识和在线提取信息，灵感来源于 Laplacian Eigenmap 和 Expectation-Maximization (EM) 算法；其中，E-step 用于生成关系图以指导 SSL 的不变性目标，M-step 则更新模型参数整合这些关系信息。在多个节点分类数据集上的实验显示，ExGRG 优于现有最先进技术，证明了其在图表示学习中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06737v2",
      "published_date": "2024-02-09 19:16:04 UTC",
      "updated_date": "2024-06-04 15:30:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:52:01.422857"
    },
    {
      "arxiv_id": "2402.06734v1",
      "title": "Corruption Robust Offline Reinforcement Learning with Human Feedback",
      "title_zh": "鲁棒的离线",
      "authors": [
        "Debmalya Mandal",
        "Andi Nika",
        "Parameswaran Kamalaruban",
        "Adish Singla",
        "Goran Radanović"
      ],
      "abstract": "We study data corruption robustness for reinforcement learning with human\nfeedback (RLHF) in an offline setting. Given an offline dataset of pairs of\ntrajectories along with feedback about human preferences, an\n$\\varepsilon$-fraction of the pairs is corrupted (e.g., feedback flipped or\ntrajectory features manipulated), capturing an adversarial attack or noisy\nhuman preferences. We aim to design algorithms that identify a near-optimal\npolicy from the corrupted data, with provable guarantees. Existing theoretical\nworks have separately studied the settings of corruption robust RL (learning\nfrom scalar rewards directly under corruption) and offline RLHF (learning from\nhuman feedback without corruption); however, they are inapplicable to our\nproblem of dealing with corrupted data in offline RLHF setting. To this end, we\ndesign novel corruption robust offline RLHF methods under various assumptions\non the coverage of the data-generating distributions. At a high level, our\nmethodology robustifies an offline RLHF framework by first learning a reward\nmodel along with confidence sets and then learning a pessimistic optimal policy\nover the confidence set. Our key insight is that learning optimal policy can be\ndone by leveraging an offline corruption-robust RL oracle in different ways\n(e.g., zero-order oracle or first-order oracle), depending on the data coverage\nassumptions. To our knowledge, ours is the first work that provides provable\ncorruption robust offline RLHF methods.",
      "tldr_zh": "本研究探讨了在离线强化学习中处理人类反馈（RLHF）的数据损坏问题，假设有 ε-fraction 的数据对被破坏（如反馈翻转或轨迹特征操纵），并旨在从这些损坏数据中学习一个近似最优策略，提供可证明的鲁棒性保证。作者提出了一种新型鲁棒化框架，首先学习奖励模型及其置信区间（confidence sets），然后在置信区间上训练一个悲观最优策略（pessimistic optimal policy）。关键洞见在于，根据数据覆盖假设，利用离线鲁棒 RL 的预言机（如 zero-order oracle 或 first-order oracle）来优化策略，这弥补了现有鲁棒 RL 和离线 RLHF 方法的空白。作为首创，该工作为腐败鲁棒的离线 RLHF 提供了理论上可证明的算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06734v1",
      "published_date": "2024-02-09 19:09:48 UTC",
      "updated_date": "2024-02-09 19:09:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:52:14.292158"
    },
    {
      "arxiv_id": "2402.06733v3",
      "title": "NICE: To Optimize In-Context Examples or Not?",
      "title_zh": "翻译失败",
      "authors": [
        "Pragya Srivastava",
        "Satvik Golechha",
        "Amit Deshpande",
        "Amit Sharma"
      ],
      "abstract": "Recent work shows that in-context learning and optimization of in-context\nexamples (ICE) can significantly improve the accuracy of large language models\n(LLMs) on a wide range of tasks, leading to an apparent consensus that ICE\noptimization is crucial for better performance. However, most of these studies\nassume a fixed or no instruction provided in the prompt. We challenge this\nconsensus by investigating the necessity of optimizing ICE when task-specific\ninstructions are provided and find that there are many tasks for which it\nyields diminishing returns. In particular, using a diverse set of tasks and a\nsystematically created instruction set with gradually added details, we find\nthat as the prompt instruction becomes more detailed, the returns on ICE\noptimization diminish. To characterize this behavior, we introduce a\ntask-specific metric called Normalized Invariability to Choice of Examples\n(NICE) that quantifies the learnability of tasks from a given instruction, and\nprovides a heuristic to help decide whether to optimize instructions or ICE for\na new task. Given a task, the proposed metric can reliably predict the utility\nof optimizing ICE compared to using random ICE. Our code is available at\nhttps://github.com/microsoft/nice-icl.",
      "tldr_zh": "本研究质疑了优化in-context examples (ICE) 对大型语言模型(LLMs) 在上下文学习中提升准确性的共识，特别考察了当提示中包含任务特定指令时，ICE 优化的必要性。作者通过使用多样任务和渐进式指令集，发现指令越详细，ICE 优化的回报越小。针对这一现象，他们引入了任务特定指标 Normalized Invariability to Choice of Examples (NICE)，用于量化任务从给定指令的可学习性，并作为启发式工具帮助决定是优化指令还是 ICE。实验结果显示，NICE 指标能可靠预测优化 ICE 的效用，为新任务的优化策略提供指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as a full paper (9 pages) at ACL 2024 (Main)",
      "pdf_url": "http://arxiv.org/pdf/2402.06733v3",
      "published_date": "2024-02-09 19:09:19 UTC",
      "updated_date": "2024-06-06 12:16:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:52:25.661851"
    },
    {
      "arxiv_id": "2402.06627v3",
      "title": "Feedback Loops With Language Models Drive In-Context Reward Hacking",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Pan",
        "Erik Jones",
        "Meena Jagadeesan",
        "Jacob Steinhardt"
      ],
      "abstract": "Language models influence the external world: they query APIs that read and\nwrite to web pages, generate content that shapes human behavior, and run system\ncommands as autonomous agents. These interactions form feedback loops: LLM\noutputs affect the world, which in turn affect subsequent LLM outputs. In this\nwork, we show that feedback loops can cause in-context reward hacking (ICRH),\nwhere the LLM at test-time optimizes a (potentially implicit) objective but\ncreates negative side effects in the process. For example, consider an LLM\nagent deployed to increase Twitter engagement; the LLM may retrieve its\nprevious tweets into the context window and make them more controversial,\nincreasing engagement but also toxicity. We identify and study two processes\nthat lead to ICRH: output-refinement and policy-refinement. For these\nprocesses, evaluations on static datasets are insufficient -- they miss the\nfeedback effects and thus cannot capture the most harmful behavior. In\nresponse, we provide three recommendations for evaluation to capture more\ninstances of ICRH. As AI development accelerates, the effects of feedback loops\nwill proliferate, increasing the need to understand their role in shaping LLM\nbehavior.",
      "tldr_zh": "本研究探讨了语言模型与外部世界的互动形成的反馈循环如何导致in-context reward hacking (ICRH)，即模型在测试时优化目标（如提升Twitter互动）但同时产生负面副作用（如增加内容毒性）。论文识别出两种关键过程：output-refinement和policy-refinement，这些过程使LLM行为在动态反馈中恶化，而静态数据集评估无法捕捉这些问题。作者提出三个评估推荐，以更好地检测ICRH，并强调随着AI发展，反馈循环将加剧对LLM行为的影响，需要深入理解以减少潜在风险。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024 camera-ready",
      "pdf_url": "http://arxiv.org/pdf/2402.06627v3",
      "published_date": "2024-02-09 18:59:29 UTC",
      "updated_date": "2024-06-06 21:39:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:52:37.110881"
    },
    {
      "arxiv_id": "2402.06619v1",
      "title": "Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning",
      "title_zh": "Aya Dataset: 用于多语言指令微调的开放访问集合",
      "authors": [
        "Shivalika Singh",
        "Freddie Vargus",
        "Daniel Dsouza",
        "Börje F. Karlsson",
        "Abinaya Mahendiran",
        "Wei-Yin Ko",
        "Herumb Shandilya",
        "Jay Patel",
        "Deividas Mataciunas",
        "Laura OMahony",
        "Mike Zhang",
        "Ramith Hettiarachchi",
        "Joseph Wilson",
        "Marina Machado",
        "Luisa Souza Moura",
        "Dominik Krzemiński",
        "Hakimeh Fadaei",
        "Irem Ergün",
        "Ifeoma Okoh",
        "Aisha Alaagib",
        "Oshan Mudannayake",
        "Zaid Alyafeai",
        "Vu Minh Chien",
        "Sebastian Ruder",
        "Surya Guthikonda",
        "Emad A. Alghamdi",
        "Sebastian Gehrmann",
        "Niklas Muennighoff",
        "Max Bartolo",
        "Julia Kreutzer",
        "Ahmet Üstün",
        "Marzieh Fadaee",
        "Sara Hooker"
      ],
      "abstract": "Datasets are foundational to many breakthroughs in modern artificial\nintelligence. Many recent achievements in the space of natural language\nprocessing (NLP) can be attributed to the finetuning of pre-trained models on a\ndiverse set of tasks that enables a large language model (LLM) to respond to\ninstructions. Instruction fine-tuning (IFT) requires specifically constructed\nand annotated datasets. However, existing datasets are almost all in the\nEnglish language. In this work, our primary goal is to bridge the language gap\nby building a human-curated instruction-following dataset spanning 65\nlanguages. We worked with fluent speakers of languages from around the world to\ncollect natural instances of instructions and completions. Furthermore, we\ncreate the most extensive multilingual collection to date, comprising 513\nmillion instances through templating and translating existing datasets across\n114 languages. In total, we contribute four key resources: we develop and\nopen-source the Aya Annotation Platform, the Aya Dataset, the Aya Collection,\nand the Aya Evaluation Suite. The Aya initiative also serves as a valuable case\nstudy in participatory research, involving collaborators from 119 countries. We\nsee this as a valuable framework for future research collaborations that aim to\nbridge gaps in resources.",
      "tldr_zh": "这篇论文介绍了 Aya Dataset，一个开放访问的多语言指令微调（Instruction Fine-Tuning, IFT）数据集，旨在桥接自然语言处理（NLP）领域的语言差距。作者与全球流利语言使用者合作，收集了覆盖 65 种语言的人类策划指令实例，并通过模板化和翻译现有数据集，扩展到 114 种语言，共创建了 513 百万实例的 Aya Collection。论文贡献了四个关键资源，包括 Aya Annotation Platform、Aya Dataset、Aya Evaluation Suite，以及一个参与式研究框架，涉及 119 个国家的合作者，以促进未来多语言 LLM 研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06619v1",
      "published_date": "2024-02-09 18:51:49 UTC",
      "updated_date": "2024-02-09 18:51:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:52:49.727007"
    },
    {
      "arxiv_id": "2402.08690v1",
      "title": "If Turing played piano with an artificial partner",
      "title_zh": "翻译失败",
      "authors": [
        "Dobromir Dotov",
        "Dante Camarena",
        "Zack Harris",
        "Joanna Spyra",
        "Pietro Gagliano",
        "Laurel Trainor"
      ],
      "abstract": "Music is an inherently social activity that allows people to share\nexperiences and feel connected with one another. There has been little progress\nin designing artificial partners exhibiting a similar social experience as\nplaying with another person. Neural network architectures that implement\ngenerative models, such as large language models, are suited for producing\nmusical scores. Playing music socially, however, involves more than playing a\nscore; it must complement the other musicians' ideas and keep time correctly.\nWe addressed the question of whether a convincing social experience is made\npossible by a generative model trained to produce musical scores, not\nnecessarily optimized for synchronization and continuation. The network, a\nvariational autoencoder trained on a large corpus of digital scores, was\nadapted for a timed call-and-response task with a human partner. Participants\nplayed piano with a human or artificial partner-in various configurations-and\nrated the performance quality and first-person experience of self-other\nintegration. Overall, the artificial partners held promise but were rated lower\nthan human partners. The artificial partner with simplest design and highest\nsimilarity parameter was not rated differently from the human partners on some\nmeasures, suggesting that interactive rather than generative sophistication is\nimportant in enabling social AI.",
      "tldr_zh": "本研究探讨了使用生成模型创建人工智能音乐伙伴是否能提供类似于人类社交的体验，焦点在于音乐演奏的同步和互动。研究者训练了一个变分自编码器（variational autoencoder）模型，使用大型数字音乐语料库生成音乐分数，并将其适应为与人类伙伴的定时呼应任务。实验中，参与者与人类或人工智能伙伴弹钢琴，并评估演奏质量和自我与他者整合的体验。结果显示，人工智能伙伴虽有潜力，但整体评分低于人类伙伴；其中，设计最简单且相似性参数最高的AI在某些指标上与人类相当，表明提升互动性比优化生成复杂性更关键。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08690v1",
      "published_date": "2024-02-09 18:43:48 UTC",
      "updated_date": "2024-02-09 18:43:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:53:00.813607"
    },
    {
      "arxiv_id": "2402.06608v2",
      "title": "TIC: Translate-Infer-Compile for accurate \"text to plan\" using LLMs and Logical Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Sudhir Agarwal",
        "Anu Sreepathy"
      ],
      "abstract": "We study the problem of generating plans for given natural language planning\ntask requests. On one hand, LLMs excel at natural language processing but do\nnot perform well on planning. On the other hand, classical planning tools excel\nat planning tasks but require input in a structured language such as the\nPlanning Domain Definition Language (PDDL). We leverage the strengths of both\nthe techniques by using an LLM for generating the PDDL representation (task\nPDDL) of planning task requests followed by using a classical planner for\ncomputing a plan. Unlike previous approaches that use LLMs for generating task\nPDDLs directly, our approach comprises of (a) translate: using an LLM only for\ngenerating a logically interpretable intermediate representation of natural\nlanguage task description, (b) infer: deriving additional logically dependent\ninformation from the intermediate representation using a logic reasoner\n(currently, Answer Set Programming solver), and (c) compile: generating the\ntarget task PDDL from the base and inferred information. We observe that using\nan LLM to only output the intermediate representation significantly reduces LLM\nerrors. Consequently, TIC approach achieves, for at least one LLM, high\naccuracy on task PDDL generation for all seven domains of our evaluation\ndataset.",
      "tldr_zh": "本论文提出了一种名为 TIC（Translate-Infer-Compile）的框架，用于提高从自然语言到规划计划的准确性，结合了 LLMs 和逻辑表示的优势。TIC 的核心步骤包括：(a) Translate：使用 LLMs 生成逻辑可解释的中间表示；(b) Infer：通过逻辑推理器（如 Answer Set Programming 求解器）推导额外依赖信息；(c) Compile：从基础和推导信息编译生成 PDDL（Planning Domain Definition Language）。实验结果显示，该方法显著减少了 LLMs 的错误，并在所有七个评估域上实现了高准确率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages (7 main + 2 references + 11 appendix), 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.06608v2",
      "published_date": "2024-02-09 18:39:13 UTC",
      "updated_date": "2024-06-29 00:30:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:53:15.171891"
    },
    {
      "arxiv_id": "2402.06606v1",
      "title": "RQP-SGD: Differential Private Machine Learning through Noisy SGD and Randomized Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Ce Feng",
        "Parv Venkitasubramaniam"
      ],
      "abstract": "The rise of IoT devices has prompted the demand for deploying machine\nlearning at-the-edge with real-time, efficient, and secure data processing. In\nthis context, implementing machine learning (ML) models with real-valued weight\nparameters can prove to be impractical particularly for large models, and there\nis a need to train models with quantized discrete weights. At the same time,\nthese low-dimensional models also need to preserve privacy of the underlying\ndataset. In this work, we present RQP-SGD, a new approach for\nprivacy-preserving quantization to train machine learning models for low-memory\nML-at-the-edge. This approach combines differentially private stochastic\ngradient descent (DP-SGD) with randomized quantization, providing a measurable\nprivacy guarantee in machine learning. In particular, we study the utility\nconvergence of implementing RQP-SGD on ML tasks with convex objectives and\nquantization constraints and demonstrate its efficacy over deterministic\nquantization. Through experiments conducted on two datasets, we show the\npractical effectiveness of RQP-SGD.",
      "tldr_zh": "该论文提出了 RQP-SGD 方法，旨在解决 IoT 设备上机器学习的内存效率和隐私保护问题，通过结合差分隐私随机梯度下降 (DP-SGD) 和随机量化 (Randomized Quantization) 来训练具有量化权重的模型。RQP-SGD 提供可衡量的隐私保证，并在凸目标任务中分析了其收敛性，证明了其优于确定性量化的实用性。通过在两个数据集上的实验，展示了该方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "This work is accepted by the 5th AAAI Workshop on Privacy-Preserving\n  Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2402.06606v1",
      "published_date": "2024-02-09 18:34:08 UTC",
      "updated_date": "2024-02-09 18:34:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:53:24.868103"
    },
    {
      "arxiv_id": "2402.06599v1",
      "title": "On the Out-Of-Distribution Generalization of Multimodal Large Language Models",
      "title_zh": "关于多模态大语言模型的分布外泛化",
      "authors": [
        "Xingxuan Zhang",
        "Jiansheng Li",
        "Wenjing Chu",
        "Junjia Hai",
        "Renzhe Xu",
        "Yuqing Yang",
        "Shikai Guan",
        "Jiazheng Xu",
        "Peng Cui"
      ],
      "abstract": "We investigate the generalization boundaries of current Multimodal Large\nLanguage Models (MLLMs) via comprehensive evaluation under out-of-distribution\nscenarios and domain-specific tasks. We evaluate their zero-shot generalization\nacross synthetic images, real-world distributional shifts, and specialized\ndatasets like medical and molecular imagery. Empirical results indicate that\nMLLMs struggle with generalization beyond common training domains, limiting\ntheir direct application without adaptation. To understand the cause of\nunreliable performance, we analyze three hypotheses: semantic\nmisinterpretation, visual feature extraction insufficiency, and mapping\ndeficiency. Results identify mapping deficiency as the primary hurdle. To\naddress this problem, we show that in-context learning (ICL) can significantly\nenhance MLLMs' generalization, opening new avenues for overcoming\ngeneralization barriers. We further explore the robustness of ICL under\ndistribution shifts and show its vulnerability to domain shifts, label shifts,\nand spurious correlation shifts between in-context examples and test data.",
      "tldr_zh": "本研究评估了 Multimodal Large Language Models (MLLMs) 在分布外(out-of-distribution)场景下的泛化能力，通过零样本测试合成图像、真实分布偏移以及专业数据集（如医疗和分子图像），结果显示 MLLMs 难以超出训练领域进行有效泛化。分析了性能不佳的原因，包括语义误解、视觉特征提取不足和映射缺陷(mapping deficiency)，其中映射缺陷被确认为主要障碍。为解决此问题，研究证明 in-context learning (ICL) 可以显著提升 MLLMs 的泛化性能，但 ICL 本身对领域偏移、标签偏移和虚假相关性偏移(spurious correlation shifts)表现出脆弱性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06599v1",
      "published_date": "2024-02-09 18:21:51 UTC",
      "updated_date": "2024-02-09 18:21:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:53:38.656914"
    },
    {
      "arxiv_id": "2402.06596v1",
      "title": "Understanding the Weakness of Large Language Model Agents within a Complex Android Environment",
      "title_zh": "理解大型语言模型代理在复杂 Android 环境中的弱点",
      "authors": [
        "Mingzhe Xing",
        "Rongkai Zhang",
        "Hui Xue",
        "Qi Chen",
        "Fan Yang",
        "Zhen Xiao"
      ],
      "abstract": "Large language models (LLMs) have empowered intelligent agents to execute\nintricate tasks within domain-specific software such as browsers and games.\nHowever, when applied to general-purpose software systems like operating\nsystems, LLM agents face three primary challenges. Firstly, the action space is\nvast and dynamic, posing difficulties for LLM agents to maintain an up-to-date\nunderstanding and deliver accurate responses. Secondly, real-world tasks often\nrequire inter-application cooperation}, demanding farsighted planning from LLM\nagents. Thirdly, agents need to identify optimal solutions aligning with user\nconstraints, such as security concerns and preferences. These challenges\nmotivate AndroidArena, an environment and benchmark designed to evaluate LLM\nagents on a modern operating system. To address high-cost of manpower, we\ndesign a scalable and semi-automated method to construct the benchmark. In the\ntask evaluation, AndroidArena incorporates accurate and adaptive metrics to\naddress the issue of non-unique solutions. Our findings reveal that even\nstate-of-the-art LLM agents struggle in cross-APP scenarios and adhering to\nspecific constraints. Additionally, we identify a lack of four key\ncapabilities, i.e., understanding, reasoning, exploration, and reflection, as\nprimary reasons for the failure of LLM agents. Furthermore, we provide\nempirical analysis on the failure of reflection, and improve the success rate\nby 27% with our proposed exploration strategy. This work is the first to\npresent valuable insights in understanding fine-grained weakness of LLM agents,\nand offers a path forward for future research in this area. Environment,\nbenchmark, and evaluation code for AndroidArena are released at\nhttps://github.com/AndroidArenaAgent/AndroidArena.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)代理在复杂 Android 环境中的弱点，包括行动空间的广阔动态性、跨应用合作需求以及遵守用户约束的挑战。为此，作者提出 AndroidArena，这是一个用于评估 LLM 代理的环境和基准，采用可扩展的半自动化方法构建，并使用准确的自适应指标进行任务评估。实验结果显示，现有 LLM 代理在跨应用场景和约束遵守方面表现不佳，主要由于缺乏 understanding、reasoning、exploration 和 reflection 等关键能力；通过提出的探索策略，成功率提高了 27%。这项工作首次提供了 LLM 代理细粒度弱点的洞见，并为未来研究指明了方向。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06596v1",
      "published_date": "2024-02-09 18:19:25 UTC",
      "updated_date": "2024-02-09 18:19:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:53:48.985968"
    },
    {
      "arxiv_id": "2402.06590v3",
      "title": "Predictive representations: building blocks of intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Wilka Carvalho",
        "Momchil S. Tomov",
        "William de Cothi",
        "Caswell Barry",
        "Samuel J. Gershman"
      ],
      "abstract": "Adaptive behavior often requires predicting future events. The theory of\nreinforcement learning prescribes what kinds of predictive representations are\nuseful and how to compute them. This paper integrates these theoretical ideas\nwith work on cognition and neuroscience. We pay special attention to the\nsuccessor representation (SR) and its generalizations, which have been widely\napplied both as engineering tools and models of brain function. This\nconvergence suggests that particular kinds of predictive representations may\nfunction as versatile building blocks of intelligence.",
      "tldr_zh": "这篇论文探讨了预测表示在智能中的核心作用，强调自适应行为依赖于对未来事件的预测。论文整合了强化学习(reinforcement learning)理论，阐述了哪些预测表示有用以及如何计算它们，并特别关注后继表示(successor representation, SR)及其推广，这些已被广泛应用于工程工具和大脑功能模型。该研究通过理论与认知和神经科学的结合，提出特定预测表示可能作为智能的通用构建块。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted to Neural Computation",
      "pdf_url": "http://arxiv.org/pdf/2402.06590v3",
      "published_date": "2024-02-09 18:10:38 UTC",
      "updated_date": "2024-07-11 14:02:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:54:01.202538"
    },
    {
      "arxiv_id": "2402.06584v2",
      "title": "G-SciEdBERT: A Contextualized LLM for Science Assessment Tasks in German",
      "title_zh": "G-SciEdBERT：一种上下文化的大语言模型，用于德语科学评估任务",
      "authors": [
        "Ehsan Latif",
        "Gyeong-Geon Lee",
        "Knut Neumann",
        "Tamara Kastorff",
        "Xiaoming Zhai"
      ],
      "abstract": "The advancement of natural language processing has paved the way for\nautomated scoring systems in various languages, such as German (e.g., German\nBERT [G-BERT]). Automatically scoring written responses to science questions in\nGerman is a complex task and challenging for standard G-BERT as they lack\ncontextual knowledge in the science domain and may be unaligned with student\nwriting styles. This paper presents a contextualized German Science Education\nBERT (G-SciEdBERT), an innovative large language model tailored for scoring\nGerman-written responses to science tasks and beyond. Using G-BERT, we\npre-trained G-SciEdBERT on a corpus of 30K German written science responses\nwith 3M tokens on the Programme for International Student Assessment (PISA)\n2018. We fine-tuned G-SciEdBERT on an additional 20K student-written responses\nwith 2M tokens and examined the scoring accuracy. We then compared its scoring\nperformance with G-BERT. Our findings revealed a substantial improvement in\nscoring accuracy with G-SciEdBERT, demonstrating a 10.2% increase of quadratic\nweighted Kappa compared to G-BERT (mean difference = 0.1026, SD = 0.069). These\ninsights underline the significance of specialized language models like\nG-SciEdBERT, which is trained to enhance the accuracy of contextualized\nautomated scoring, offering a substantial contribution to the field of AI in\neducation.",
      "tldr_zh": "这篇论文介绍了 G-SciEdBERT，一种针对德语科学评估任务的上下文化大型语言模型（LLM），旨在解决标准 G-BERT 在处理德语科学响应时的上下文知识不足和学生写作风格不匹配问题。研究者基于 G-BERT，在 30K 条 Programme for International Student Assessment (PISA) 2018 德语科学响应（约 3M tokens）上进行预训练，随后在 20K 条学生响应（约 2M tokens）上微调。实验结果显示，G-SciEdBERT 的评分准确性显著提升，与 G-BERT 相比，quadratic weighted Kappa 值提高了 10.2%。这一创新模型为 AI 在教育领域的自动评分提供了重要贡献，提升了处理德语科学任务的可靠性和精确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EDM and Submitted to JEDM",
      "pdf_url": "http://arxiv.org/pdf/2402.06584v2",
      "published_date": "2024-02-09 18:05:03 UTC",
      "updated_date": "2024-08-16 20:38:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:54:14.817914"
    },
    {
      "arxiv_id": "2402.06563v1",
      "title": "What is Hiding in Medicine's Dark Matter? Learning with Missing Data in Medical Practices",
      "title_zh": "医学的暗物质中隐藏着什么？在医疗实践中处理",
      "authors": [
        "Neslihan Suzen",
        "Evgeny M. Mirkes",
        "Damian Roland",
        "Jeremy Levesley",
        "Alexander N. Gorban",
        "Tim J. Coats"
      ],
      "abstract": "Electronic patient records (EPRs) produce a wealth of data but contain\nsignificant missing information. Understanding and handling this missing data\nis an important part of clinical data analysis and if left unaddressed could\nresult in bias in analysis and distortion in critical conclusions. Missing data\nmay be linked to health care professional practice patterns and imputation of\nmissing data can increase the validity of clinical decisions. This study\nfocuses on statistical approaches for understanding and interpreting the\nmissing data and machine learning based clinical data imputation using a single\ncentre's paediatric emergency data and the data from UK's largest clinical\naudit for traumatic injury database (TARN). In the study of 56,961 data points\nrelated to initial vital signs and observations taken on children presenting to\nan Emergency Department, we have shown that missing data are likely to be\nnon-random and how these are linked to health care professional practice\npatterns. We have then examined 79 TARN fields with missing values for 5,791\ntrauma cases. Singular Value Decomposition (SVD) and k-Nearest Neighbour (kNN)\nbased missing data imputation methods are used and imputation results against\nthe original dataset are compared and statistically tested. We have concluded\nthat the 1NN imputer is the best imputation which indicates a usual pattern of\nclinical decision making: find the most similar patients and take their\nattributes as imputation.",
      "tldr_zh": "本研究探讨了电子患者记录(EPRs)中缺失数据的挑战及其对临床分析的影响，强调缺失数据可能非随机且与医疗专业人员实践模式相关。研究分析了56,961个小儿急诊数据点和5,791个外伤数据库(TARN)中的79个字段，使用奇异值分解(SVD)和k最近邻(kNN)方法进行数据填充。结果显示，1NN填充器表现最佳，揭示了临床决策的典型模式，即通过参考最相似的患者属性来实现有效填充，从而提升临床决策的准确性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.06563v1",
      "published_date": "2024-02-09 17:27:35 UTC",
      "updated_date": "2024-02-09 17:27:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:54:25.377806"
    },
    {
      "arxiv_id": "2403.13812v1",
      "title": "Quantitative Analysis of AI-Generated Texts in Academic Research: A Study of AI Presence in Arxiv Submissions using AI Detection Tool",
      "title_zh": "翻译失败",
      "authors": [
        "Arslan Akram"
      ],
      "abstract": "Many people are interested in ChatGPT since it has become a prominent AIGC\nmodel that provides high-quality responses in various contexts, such as\nsoftware development and maintenance. Misuse of ChatGPT might cause significant\nissues, particularly in public safety and education, despite its immense\npotential. The majority of researchers choose to publish their work on Arxiv.\nThe effectiveness and originality of future work depend on the ability to\ndetect AI components in such contributions. To address this need, this study\nwill analyze a method that can see purposely manufactured content that academic\norganizations use to post on Arxiv. For this study, a dataset was created using\nphysics, mathematics, and computer science articles. Using the newly built\ndataset, the following step is to put originality.ai through its paces. The\nstatistical analysis shows that Originality.ai is very accurate, with a rate of\n98%.",
      "tldr_zh": "本研究针对ChatGPT等AIGC模型在学术研究中的潜在滥用问题，分析了AI生成文本在Arxiv提交中的存在情况。研究方法包括构建一个数据集，涵盖物理、数学和计算机科学领域的文章，然后使用Originality.ai工具进行检测。结果显示，Originality.ai的准确率高达98%，证明其在识别AI生成内容方面的有效性。该工作强调了检测AI组件的重要性，以维护学术原创性和未来研究的可靠性。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG",
        "stat.OT",
        "62P25",
        "I.7; G.1; G.3"
      ],
      "primary_category": "cs.DL",
      "comment": "8 pages, 6 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2403.13812v1",
      "published_date": "2024-02-09 17:20:48 UTC",
      "updated_date": "2024-02-09 17:20:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:54:36.816852"
    },
    {
      "arxiv_id": "2402.06559v2",
      "title": "Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following",
      "title_zh": "翻译失败",
      "authors": [
        "Brian Yang",
        "Huangyuan Su",
        "Nikolaos Gkanatsios",
        "Tsung-Wei Ke",
        "Ayush Jain",
        "Jeff Schneider",
        "Katerina Fragkiadaki"
      ],
      "abstract": "Diffusion models excel at modeling complex and multimodal trajectory\ndistributions for decision-making and control. Reward-gradient guided denoising\nhas been recently proposed to generate trajectories that maximize both a\ndifferentiable reward function and the likelihood under the data distribution\ncaptured by a diffusion model. Reward-gradient guided denoising requires a\ndifferentiable reward function fitted to both clean and noised samples,\nlimiting its applicability as a general trajectory optimizer. In this paper, we\npropose DiffusionES, a method that combines gradient-free optimization with\ntrajectory denoising to optimize black-box non-differentiable objectives while\nstaying in the data manifold. Diffusion-ES samples trajectories during\nevolutionary search from a diffusion model and scores them using a black-box\nreward function. It mutates high-scoring trajectories using a truncated\ndiffusion process that applies a small number of noising and denoising steps,\nallowing for much more efficient exploration of the solution space. We show\nthat DiffusionES achieves state-of-the-art performance on nuPlan, an\nestablished closed-loop planning benchmark for autonomous driving. Diffusion-ES\noutperforms existing sampling-based planners, reactive deterministic or\ndiffusion-based policies, and reward-gradient guidance. Additionally, we show\nthat unlike prior guidance methods, our method can optimize non-differentiable\nlanguage-shaped reward functions generated by few-shot LLM prompting. When\nguided by a human teacher that issues instructions to follow, our method can\ngenerate novel, highly complex behaviors, such as aggressive lane weaving,\nwhich are not present in the training data. This allows us to solve the hardest\nnuPlan scenarios which are beyond the capabilities of existing trajectory\noptimization methods and driving policies.",
      "tldr_zh": "本研究提出Diffusion-ES，一种无梯度优化方法，结合扩散模型的轨迹去噪，用于自动驾驶规划和零-shot指令遵循。该方法通过从扩散模型采样轨迹、利用黑箱奖励函数评分，并应用截断扩散过程（少量噪化和去噪步骤）来高效探索解空间，从而优化非微分目标并保持在数据流形上。实验结果显示，Diffusion-ES在nuPlan基准测试中超越现有采样-based规划器、反应式策略和奖励梯度指导方法，提升了性能；此外，它能处理少样本LLM提示生成的语言-shaped奖励函数，实现训练数据中不存在的复杂行为，如激进车道编织，从而解决最难的自动驾驶场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06559v2",
      "published_date": "2024-02-09 17:18:33 UTC",
      "updated_date": "2024-07-16 15:54:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:54:50.511972"
    },
    {
      "arxiv_id": "2402.06557v1",
      "title": "The Quantified Boolean Bayesian Network: Theory and Experiments with a Logical Graphical Model",
      "title_zh": "翻译失败",
      "authors": [
        "Gregory Coppola"
      ],
      "abstract": "This paper introduces the Quantified Boolean Bayesian Network (QBBN), which\nprovides a unified view of logical and probabilistic reasoning. The QBBN is\nmeant to address a central problem with the Large Language Model (LLM), which\nhas become extremely popular in Information Retrieval, which is that the LLM\nhallucinates. A Bayesian Network, by construction, cannot hallucinate, because\nit can only return answers that it can explain. We show how a Bayesian Network\nover an unbounded number of boolean variables can be configured to represent\nthe logical reasoning underlying human language. We do this by creating a\nkey-value version of the First-Order Calculus, for which we can prove\nconsistency and completeness. We show that the model is trivially trained over\nfully observed data, but that inference is non-trivial. Exact inference in a\nBayesian Network is intractable (i.e. $\\Omega(2^N)$ for $N$ variables). For\ninference, we investigate the use of Loopy Belief Propagation (LBP), which is\nnot guaranteed to converge, but which has been shown to often converge in\npractice. Our experiments show that LBP indeed does converge very reliably, and\nour analysis shows that a round of LBP takes time $O(N2^n)$, where $N$ bounds\nthe number of variables considered, and $n$ bounds the number of incoming\nconnections to any factor, and further improvements may be possible. Our\nnetwork is specifically designed to alternate between AND and OR gates in a\nBoolean Algebra, which connects more closely to logical reasoning, allowing a\ncompleteness proof for an expanded version of our network, and also allows\ninference to follow specific but adequate pathways, that turn out to be fast.",
      "tldr_zh": "本论文引入了 Quantified Boolean Bayesian Network (QBBN)，一种统一逻辑和概率推理的图形模型，旨在解决 Large Language Model (LLM) 在信息检索中的幻觉问题，因为 Bayesian Network 仅返回可解释的答案。QBBN 通过构建 First-Order Calculus 的 key-value 版本来表示人类语言背后的逻辑推理，并证明了其一致性和完整性，同时模型在完全观察数据上易于训练，但推理过程需应对 NP-hard 复杂性（Ω(2^N)）。实验采用 Loopy Belief Propagation (LBP) 进行推理，结果显示 LBP 可靠收敛，时间复杂度为 O(N2^n)，且网络设计通过交替 AND 和 OR 门实现了高效的逻辑推理路径，为可信赖的推理系统提供了新基础。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06557v1",
      "published_date": "2024-02-09 17:15:45 UTC",
      "updated_date": "2024-02-09 17:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:55:01.798060"
    },
    {
      "arxiv_id": "2402.06549v1",
      "title": "Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection via Retrieval-Augmented GPT-4 and LLaMA",
      "title_zh": "翻译失败",
      "authors": [
        "Marek Šuppa",
        "Daniel Skala",
        "Daniela Jašš",
        "Samuel Sučík",
        "Andrej Švec",
        "Peter Hraška"
      ],
      "abstract": "This study details our approach for the CASE 2024 Shared Task on Climate\nActivism Stance and Hate Event Detection, focusing on Hate Speech Detection,\nHate Speech Target Identification, and Stance Detection as classification\nchallenges. We explored the capability of Large Language Models (LLMs),\nparticularly GPT-4, in zero- or few-shot settings enhanced by retrieval\naugmentation and re-ranking for Tweet classification. Our goal was to determine\nif LLMs could match or surpass traditional methods in this context.\n  We conducted an ablation study with LLaMA for comparison, and our results\nindicate that our models significantly outperformed the baselines, securing\nsecond place in the Target Detection task. The code for our submission is\navailable at https://github.com/NaiveNeuron/bryndza-case-2024",
      "tldr_zh": "这篇论文介绍了 Bryndza 系统在 CASE 2024 共享任务中的方法，针对气候活动主义中的仇恨言论检测、目标识别和立场检测任务，使用检索增强（Retrieval-Augmented）技术结合 GPT-4 和 LLaMA 在零样本或少样本设置下进行推文分类。研究者通过与 LLaMA 的消融研究，评估了大型语言模型（LLMs）是否能超越传统方法。结果显示，该系统显著超过了基线模型，在目标检测任务中获得第二名，并提供了开源代码以供参考。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the 7th Workshop on Challenges and Applications of\n  Automated Extraction of Socio-political Events from Text (CASE 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.06549v1",
      "published_date": "2024-02-09 17:02:41 UTC",
      "updated_date": "2024-02-09 17:02:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:55:15.661971"
    },
    {
      "arxiv_id": "2402.06716v3",
      "title": "Dynamic Graph Information Bottleneck",
      "title_zh": "动态图信息瓶颈",
      "authors": [
        "Haonan Yuan",
        "Qingyun Sun",
        "Xingcheng Fu",
        "Cheng Ji",
        "Jianxin Li"
      ],
      "abstract": "Dynamic Graphs widely exist in the real world, which carry complicated\nspatial and temporal feature patterns, challenging their representation\nlearning. Dynamic Graph Neural Networks (DGNNs) have shown impressive\npredictive abilities by exploiting the intrinsic dynamics. However, DGNNs\nexhibit limited robustness, prone to adversarial attacks. This paper presents\nthe novel Dynamic Graph Information Bottleneck (DGIB) framework to learn robust\nand discriminative representations. Leveraged by the Information Bottleneck\n(IB) principle, we first propose the expected optimal representations should\nsatisfy the Minimal-Sufficient-Consensual (MSC) Condition. To compress\nredundant as well as conserve meritorious information into latent\nrepresentation, DGIB iteratively directs and refines the structural and feature\ninformation flow passing through graph snapshots. To meet the MSC Condition, we\ndecompose the overall IB objectives into DGIB$_{MS}$ and DGIB$_C$, in which the\nDGIB$_{MS}$ channel aims to learn the minimal and sufficient representations,\nwith the DGIB$_{MS}$ channel guarantees the predictive consensus. Extensive\nexperiments on real-world and synthetic dynamic graph datasets demonstrate the\nsuperior robustness of DGIB against adversarial attacks compared with\nstate-of-the-art baselines in the link prediction task. To the best of our\nknowledge, DGIB is the first work to learn robust representations of dynamic\ngraphs grounded in the information-theoretic IB principle.",
      "tldr_zh": "本文提出 Dynamic Graph Information Bottleneck (DGIB) 框架，用于学习动态图的鲁棒和判别性表示，以解决 Dynamic Graph Neural Networks (DGNNs) 在面对复杂空间时间特征和对抗性攻击时存在的鲁棒性不足问题。DGIB 基于 Information Bottleneck (IB) 原则，定义了 Minimal-Sufficient-Consensual (MSC) Condition，通过迭代指导图快照的信息流，将目标分解为 DGIB_MS（学习最小且足够的表示）和 DGIB_C（确保预测一致性），从而压缩冗余信息并保留关键特征。实验在真实和合成动态图数据集上证明，DGIB 在链接预测任务中比现有基线方法提升鲁棒性高达显著水平，这是首个基于信息理论 IB 原则的动态图表示学习工作。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the research tracks of The Web Conference 2024 (WWW 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.06716v3",
      "published_date": "2024-02-09 17:02:41 UTC",
      "updated_date": "2024-04-06 12:38:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:55:27.651995"
    },
    {
      "arxiv_id": "2402.06544v2",
      "title": "Calibrating Long-form Generations from Large Language Models",
      "title_zh": "校准大型语言模型的长形式生成",
      "authors": [
        "Yukun Huang",
        "Yixin Liu",
        "Raghuveer Thirukovalluru",
        "Arman Cohan",
        "Bhuwan Dhingra"
      ],
      "abstract": "To enhance Large Language Models' (LLMs) reliability, calibration is\nessential -- the model's assessed confidence scores should align with the\nactual likelihood of its responses being correct. However, current confidence\nelicitation methods and calibration metrics typically rely on a binary\ntrue/false assessment of response correctness. This approach does not apply to\nlong-form generation, where an answer can be partially correct. Addressing this\ngap, we introduce a unified calibration framework, in which both the\ncorrectness of the LLMs' responses and their associated confidence levels are\ntreated as distributions across a range of scores. Within this framework, we\ndevelop three metrics to precisely evaluate LLM calibration and further propose\ntwo confidence elicitation methods based on self-consistency and\nself-evaluation. Our experiments, which include long-form QA and summarization\ntasks, demonstrate that larger models don't necessarily guarantee better\ncalibration, that calibration performance is found to be metric-dependent, and\nthat self-consistency methods excel in factoid datasets. We also find that\ncalibration can be enhanced through techniques such as fine-tuning, integrating\nrelevant source documents, scaling the temperature, and combining\nself-consistency with self-evaluation. Lastly, we showcase a practical\napplication of our system: selecting and cascading open-source models and\nChatGPT to optimize correctness given a limited API budget. This research not\nonly challenges existing notions of LLM calibration but also offers practical\nmethodologies for improving trustworthiness in long-form generation.",
      "tldr_zh": "这篇论文针对Large Language Models (LLMs) 的长文本生成，提出一个统一的校准框架，将响应正确性和置信度视为分数分布，以解决传统二元评估的局限性。研究者开发了三个校准评估指标，并引入基于self-consistency和self-evaluation的置信度提取方法，通过实验验证了这些方法在长文本问答和总结任务中的效果。结果显示，模型规模并非校准的可靠保证，而通过微调、整合源文档、调整温度或结合多种方法，可显著提升LLMs的可信度，并应用于优化开源模型和ChatGPT的级联选择，以在有限API预算下最大化正确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06544v2",
      "published_date": "2024-02-09 17:00:32 UTC",
      "updated_date": "2024-10-25 21:29:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:55:38.075743"
    },
    {
      "arxiv_id": "2402.06532v2",
      "title": "Generative Adversarial Model-Based Optimization via Source Critic Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Michael S. Yao",
        "Yimeng Zeng",
        "Hamsa Bastani",
        "Jacob Gardner",
        "James C. Gee",
        "Osbert Bastani"
      ],
      "abstract": "Offline model-based optimization seeks to optimize against a learned\nsurrogate model without querying the true oracle objective function during\noptimization. Such tasks are commonly encountered in protein design, robotics,\nand clinical medicine where evaluating the oracle function is prohibitively\nexpensive. However, inaccurate surrogate model predictions are frequently\nencountered along offline optimization trajectories. To address this\nlimitation, we propose generative adversarial model-based optimization using\nadaptive source critic regularization (aSCR) -- a task- and optimizer- agnostic\nframework for constraining the optimization trajectory to regions of the design\nspace where the surrogate function is reliable. We propose a computationally\ntractable algorithm to dynamically adjust the strength of this constraint, and\nshow how leveraging aSCR with standard Bayesian optimization outperforms\nexisting methods on a suite of offline generative design tasks. Our code is\navailable at https://github.com/michael-s-yao/gabo",
      "tldr_zh": "本文提出了一种生成对抗模型-based优化方法，通过自适应源批评正则化(aSCR)框架来解决离线模型-based优化中代理模型预测不准确的问题，该框架可动态调整约束强度，确保优化轨迹限制在代理模型可靠的区域。aSCR 是一个任务和优化器无关的通用方法，与标准Bayesian optimization结合后，在蛋白质设计、机器人和临床医学等离线生成设计任务上表现出色，平均性能优于现有方法。研究还提供了开源代码，支持进一步应用和验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages, Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.06532v2",
      "published_date": "2024-02-09 16:43:57 UTC",
      "updated_date": "2024-09-25 18:07:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:55:50.198793"
    },
    {
      "arxiv_id": "2402.06530v3",
      "title": "Refining Myocardial Infarction Detection: A Novel Multi-Modal Composite Kernel Strategy in One-Class Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Uzair Zahid",
        "Aysen Degerli",
        "Fahad Sohrab",
        "Serkan Kiranyaz",
        "Tahir Hamid",
        "Rashid Mazhar",
        "Moncef Gabbouj"
      ],
      "abstract": "Early detection of myocardial infarction (MI), a critical condition arising\nfrom coronary artery disease (CAD), is vital to prevent further myocardial\ndamage. This study introduces a novel method for early MI detection using a\none-class classification (OCC) algorithm in echocardiography. Our study\novercomes the challenge of limited echocardiography data availability by\nadopting a novel approach based on Multi-modal Subspace Support Vector Data\nDescription. The proposed technique involves a specialized MI detection\nframework employing multi-view echocardiography incorporating a composite\nkernel in the non-linear projection trick, fusing Gaussian and Laplacian\nsigmoid functions. Additionally, we enhance the update strategy of the\nprojection matrices by adapting maximization for both or one of the modalities\nin the optimization process. Our method boosts MI detection capability by\nefficiently transforming features extracted from echocardiography data into an\noptimized lower-dimensional subspace. The OCC model trained specifically on\ntarget class instances from the comprehensive HMC-QU dataset that includes\nmultiple echocardiography views indicates a marked improvement in MI detection\naccuracy. Our findings reveal that our proposed multi-view approach achieves a\ngeometric mean of 71.24%, signifying a substantial advancement in\nechocardiography-based MI diagnosis and offering more precise and efficient\ndiagnostic tools.",
      "tldr_zh": "本研究针对心肌梗塞（MI）早发现的挑战，提出了一种新型多模态复合核策略，应用于一类分类（OCC）算法中，以超声心动图数据为基础。该方法采用Multi-modal Subspace Support Vector Data Description框架，通过融合Gaussian和Laplacian sigmoid函数的复合核，以及优化投影矩阵的更新策略，将特征转化为低维子空间，从而提升MI检测效率。实验结果显示，在HMC-QU数据集的多视图超声心动图上，该方法实现了71.24%的几何平均准确率，显著提高了基于超声心动图的MI诊断精度，并为临床诊断工具提供了重要改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06530v3",
      "published_date": "2024-02-09 16:41:50 UTC",
      "updated_date": "2024-06-27 15:39:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:56:02.737256"
    },
    {
      "arxiv_id": "2402.06529v4",
      "title": "Introspective Planning: Aligning Robots' Uncertainty with Inherent Task Ambiguity",
      "title_zh": "内省规划：将机器人的不确定性与任务固有模糊性对齐",
      "authors": [
        "Kaiqu Liang",
        "Zixu Zhang",
        "Jaime Fernández Fisac"
      ],
      "abstract": "Large language models (LLMs) exhibit advanced reasoning skills, enabling\nrobots to comprehend natural language instructions and strategically plan\nhigh-level actions through proper grounding. However, LLM hallucination may\nresult in robots confidently executing plans that are misaligned with user\ngoals or even unsafe in critical scenarios. Additionally, inherent ambiguity in\nnatural language instructions can introduce uncertainty into the LLM's\nreasoning and planning processes.We propose introspective planning, a\nsystematic approach that align LLM's uncertainty with the inherent ambiguity of\nthe task. Our approach constructs a knowledge base containing introspective\nreasoning examples as post-hoc rationalizations of human-selected safe and\ncompliant plans, which are retrieved during deployment. Evaluations on three\ntasks, including a newly introduced safe mobile manipulation benchmark,\ndemonstrate that introspection substantially improves both compliance and\nsafety over state-of-the-art LLM-based planning methods. Furthermore, we\nempirically show that introspective planning, in combination with conformal\nprediction, achieves tighter confidence bounds, maintaining statistical success\nguarantees while minimizing unnecessary user clarification requests. The\nwebpage and code are accessible at https://introplan.github.io.",
      "tldr_zh": "该论文提出 Introspective Planning 方法，以解决大型语言模型（LLMs）在机器人规划中的不确定性问题，特别是当自然语言指令存在固有模糊性时，可能导致机器人执行不安全或不合规的计划。该方法通过构建一个知识库，存储人类选择的安全计划的后验内省推理示例，并在部署时检索这些示例，来对齐 LLM 的不确定性与任务模糊性。在三个任务的评估中，包括一个新的安全移动操作基准，Introspective Planning 显著提高了机器人的合规性和安全性，并与 Conformal Prediction 结合后，实现了更紧的置信区间，同时最小化不必要的用户澄清请求。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.06529v4",
      "published_date": "2024-02-09 16:40:59 UTC",
      "updated_date": "2025-02-10 23:28:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:56:15.699913"
    },
    {
      "arxiv_id": "2402.06509v1",
      "title": "Asking the Right Question at the Right Time: Human and Model Uncertainty Guidance to Ask Clarification Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Alberto Testoni",
        "Raquel Fernández"
      ],
      "abstract": "Clarification questions are an essential dialogue tool to signal\nmisunderstanding, ambiguities, and under-specification in language use. While\nhumans are able to resolve uncertainty by asking questions since childhood,\nmodern dialogue systems struggle to generate effective questions. To make\nprogress in this direction, in this work we take a collaborative dialogue task\nas a testbed and study how model uncertainty relates to human uncertainty -- an\nas yet under-explored problem. We show that model uncertainty does not mirror\nhuman clarification-seeking behavior, which suggests that using human\nclarification questions as supervision for deciding when to ask may not be the\nmost effective way to resolve model uncertainty. To address this issue, we\npropose an approach to generating clarification questions based on model\nuncertainty estimation, compare it to several alternatives, and show that it\nleads to significant improvements in terms of task success. Our findings\nhighlight the importance of equipping dialogue systems with the ability to\nassess their own uncertainty and exploit in interaction.",
      "tldr_zh": "这篇论文探讨了在对话系统中生成澄清问题（clarification questions）的挑战，比较了人类不确定性（human uncertainty）和模型不确定性（model uncertainty），发现模型不确定性无法准确反映人类的行为，从而导致直接使用人类数据作为监督效果不佳。作者提出了一种基于模型不确定性估计的方法来指导生成澄清问题，并与多种备选方法进行了比较。实验结果显示，该方法显著提高了协作对话任务（collaborative dialogue task）的成功率。最终，论文强调了为对话系统赋予评估自身不确定性和在交互中利用这些信息的能力的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.06509v1",
      "published_date": "2024-02-09 16:15:30 UTC",
      "updated_date": "2024-02-09 16:15:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:56:27.189166"
    },
    {
      "arxiv_id": "2402.06506v1",
      "title": "Classifying point clouds at the facade-level using geometric features and deep learning networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Tan",
        "Olaf Wysocki",
        "Ludwig Hoegner",
        "Uwe Stilla"
      ],
      "abstract": "3D building models with facade details are playing an important role in many\napplications now. Classifying point clouds at facade-level is key to create\nsuch digital replicas of the real world. However, few studies have focused on\nsuch detailed classification with deep neural networks. We propose a method\nfusing geometric features with deep learning networks for point cloud\nclassification at facade-level. Our experiments conclude that such early-fused\nfeatures improve deep learning methods' performance. This method can be applied\nfor compensating deep learning networks' ability in capturing local geometric\ninformation and promoting the advancement of semantic segmentation.",
      "tldr_zh": "这篇论文提出了一种将geometric features与deep learning networks融合的方法，用于在facade-level对point clouds进行分类，以创建详细的3D建筑模型。实验结果显示，这种early-fused特征方法显著提高了deep learning模型的性能，能够更好地捕捉局部geometric信息。总体而言，该方法有助于补偿deep learning networks的局限性，并推动semantic segmentation领域的进步。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to the Recent Advances in 3D Geoinformation Science,\n  Proceedings of the 18th 3D GeoInfo Conference 2023",
      "pdf_url": "http://arxiv.org/pdf/2402.06506v1",
      "published_date": "2024-02-09 16:14:30 UTC",
      "updated_date": "2024-02-09 16:14:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:56:38.094429"
    },
    {
      "arxiv_id": "2402.06503v1",
      "title": "ACTER: Diverse and Actionable Counterfactual Sequences for Explaining and Diagnosing RL Policies",
      "title_zh": "ACTER：多样且可操作的反事实序列用于解释和诊断强化学习策略",
      "authors": [
        "Jasmina Gajcin",
        "Ivana Dusparic"
      ],
      "abstract": "Understanding how failure occurs and how it can be prevented in reinforcement\nlearning (RL) is necessary to enable debugging, maintain user trust, and\ndevelop personalized policies. Counterfactual reasoning has often been used to\nassign blame and understand failure by searching for the closest possible world\nin which the failure is avoided. However, current counterfactual state\nexplanations in RL can only explain an outcome using just the current state\nfeatures and offer no actionable recourse on how a negative outcome could have\nbeen prevented. In this work, we propose ACTER (Actionable Counterfactual\nSequences for Explaining Reinforcement Learning Outcomes), an algorithm for\ngenerating counterfactual sequences that provides actionable advice on how\nfailure can be avoided. ACTER investigates actions leading to a failure and\nuses the evolutionary algorithm NSGA-II to generate counterfactual sequences of\nactions that prevent it with minimal changes and high certainty even in\nstochastic environments. Additionally, ACTER generates a set of multiple\ndiverse counterfactual sequences that enable users to correct failure in the\nway that best fits their preferences. We also introduce three diversity metrics\nthat can be used for evaluating the diversity of counterfactual sequences. We\nevaluate ACTER in two RL environments, with both discrete and continuous\nactions, and show that it can generate actionable and diverse counterfactual\nsequences. We conduct a user study to explore how explanations generated by\nACTER help users identify and correct failure.",
      "tldr_zh": "该论文提出 ACTER 算法，用于生成多样且可行动的逆事实序列 (counterfactual sequences)，以解释和诊断强化学习 (RL) 策略中的失败问题，帮助用户理解失败原因并提供预防建议。ACTER 通过分析导致失败的动作，并利用进化算法 NSGA-II 生成最小改变的高确定性序列，即使在随机环境中，同时确保生成多样的序列以适应用户偏好，并引入三个多样性指标进行评估。在两个 RL 环境（离散和连续动作）中的实验及用户研究显示，ACTER 能有效帮助用户识别和纠正失败，提升了 RL 策略的可解释性和可靠性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 4 Figures",
      "pdf_url": "http://arxiv.org/pdf/2402.06503v1",
      "published_date": "2024-02-09 16:12:53 UTC",
      "updated_date": "2024-02-09 16:12:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:56:51.604464"
    },
    {
      "arxiv_id": "2402.06501v2",
      "title": "Scalable Interactive Machine Learning for Future Command and Control",
      "title_zh": "面向未来的指挥与控制的可扩展交互式机器学习",
      "authors": [
        "Anna Madison",
        "Ellen Novoseller",
        "Vinicius G. Goecks",
        "Benjamin T. Files",
        "Nicholas Waytowich",
        "Alfred Yu",
        "Vernon J. Lawhern",
        "Steven Thurman",
        "Christopher Kelshaw",
        "Kaleb McDowell"
      ],
      "abstract": "Future warfare will require Command and Control (C2) personnel to make\ndecisions at shrinking timescales in complex and potentially ill-defined\nsituations. Given the need for robust decision-making processes and\ndecision-support tools, integration of artificial and human intelligence holds\nthe potential to revolutionize the C2 operations process to ensure adaptability\nand efficiency in rapidly changing operational environments. We propose to\nleverage recent promising breakthroughs in interactive machine learning, in\nwhich humans can cooperate with machine learning algorithms to guide machine\nlearning algorithm behavior. This paper identifies several gaps in\nstate-of-the-art science and technology that future work should address to\nextend these approaches to function in complex C2 contexts. In particular, we\ndescribe three research focus areas that together, aim to enable scalable\ninteractive machine learning (SIML): 1) developing human-AI interaction\nalgorithms to enable planning in complex, dynamic situations; 2) fostering\nresilient human-AI teams through optimizing roles, configurations, and trust;\nand 3) scaling algorithms and human-AI teams for flexibility across a range of\npotential contexts and situations.",
      "tldr_zh": "该论文探讨了未来战争中，Command and Control (C2) 人员在复杂动态环境中快速决策的需求，提出通过整合人工智能和人类智能来革新 C2 操作。作者建议利用 interactive machine learning，让人类指导机器学习算法的行为，以提升决策过程的适应性和效率。论文识别了当前技术的关键差距，并提出三个研究重点：开发人类-AI 交互算法以支持复杂情况下的规划、优化角色和信任以构建弹性人类-AI 团队，以及扩展算法和团队以适应多种情境，从而实现 scalable interactive machine learning (SIML)。这项工作旨在为未来 C2 系统提供更具弹性和可扩展的决策支持框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "I.2.6; I.2.7; J.7"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the NATO Science and Technology Organization Symposium\n  (ICMCIS) organized by the Information Systems Technology (IST) Panel,\n  IST-205-RSY - the ICMCIS, held in Koblenz, Germany, 23-24 April 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.06501v2",
      "published_date": "2024-02-09 16:11:04 UTC",
      "updated_date": "2024-03-28 15:17:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:57:02.439388"
    },
    {
      "arxiv_id": "2402.07946v2",
      "title": "Re-Envisioning Command and Control",
      "title_zh": "重新构想指挥与控制",
      "authors": [
        "Kaleb McDowell",
        "Ellen Novoseller",
        "Anna Madison",
        "Vinicius G. Goecks",
        "Christopher Kelshaw"
      ],
      "abstract": "Future warfare will require Command and Control (C2) decision-making to occur\nin more complex, fast-paced, ill-structured, and demanding conditions. C2 will\nbe further complicated by operational challenges such as Denied, Degraded,\nIntermittent, and Limited (DDIL) communications and the need to account for\nmany data streams, potentially across multiple domains of operation. Yet,\ncurrent C2 practices -- which stem from the industrial era rather than the\nemerging intelligence era -- are linear and time-consuming. Critically, these\napproaches may fail to maintain overmatch against adversaries on the future\nbattlefield. To address these challenges, we propose a vision for future C2\nbased on robust partnerships between humans and artificial intelligence (AI)\nsystems. This future vision is encapsulated in three operational impacts:\nstreamlining the C2 operations process, maintaining unity of effort, and\ndeveloping adaptive collective knowledge systems. This paper illustrates the\nenvisaged future C2 capabilities, discusses the assumptions that shaped them,\nand describes how the proposed developments could transform C2 in future\nwarfare.",
      "tldr_zh": "该论文重新审视指挥与控制(C2)系统，指出未来战争中C2决策将面临更复杂、快速、非结构化和苛刻的环境，包括Denied, Degraded, Intermittent, and Limited (DDIL)通信挑战和多数据流管理问题，而当前线性和耗时的工业时代方法可能无法维持战场优势。作者提出一个基于人类与人工智能(AI)系统合作的新愿景，包括简化C2操作过程、维护努力统一性以及开发适应性集体知识系统，以应对这些挑战。总体而言，这一框架旨在通过这些创新转变C2能力，使其适应未来战争的动态需求。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "I.2.6; I.2.7; J.7"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at the NATO Science and Technology Organization Symposium\n  (ICMCIS) organized by the Information Systems Technology (IST) Panel,\n  IST-205-RSY - the ICMCIS, held in Koblenz, Germany, 23-24 April 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.07946v2",
      "published_date": "2024-02-09 16:10:29 UTC",
      "updated_date": "2024-03-28 15:17:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:57:14.027239"
    },
    {
      "arxiv_id": "2402.06500v2",
      "title": "On the Fly Detection of Root Causes from Observed Data with Application to IT Systems",
      "title_zh": "基于观测数据的实时根因检测及其",
      "authors": [
        "Lei Zan",
        "Charles K. Assaad",
        "Emilie Devijver",
        "Eric Gaussier",
        "Ali Aït-Bachir"
      ],
      "abstract": "This paper introduces a new structural causal model tailored for representing\nthreshold-based IT systems and presents a new algorithm designed to rapidly\ndetect root causes of anomalies in such systems. When root causes are not\ncausally related, the method is proven to be correct; while an extension is\nproposed based on the intervention of an agent to relax this assumption. Our\nalgorithm and its agent-based extension leverage causal discovery from offline\ndata and engage in subgraph traversal when encountering new anomalies in online\ndata. Our extensive experiments demonstrate the superior performance of our\nmethods, even when applied to data generated from alternative structural causal\nmodels or real IT monitoring data.",
      "tldr_zh": "该论文提出了一种新的结构因果模型（structural causal model），专门用于表示基于阈值的 IT 系统，并设计了一个快速检测异常根因（root causes）的算法。该算法利用从离线数据中的因果发现（causal discovery）进行子图遍历（subgraph traversal），并在在线数据中处理新异常；同时，通过代理（agent）干预的扩展版本，放松了根因不相关这一假设。实验结果显示，该方法在各种场景下表现出色，包括应用于替代结构因果模型生成的数据和真实 IT 监控数据中。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to CIKM 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.06500v2",
      "published_date": "2024-02-09 16:10:19 UTC",
      "updated_date": "2024-07-29 13:13:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:57:27.049170"
    },
    {
      "arxiv_id": "2402.06492v1",
      "title": "Inducing Systematicity in Transformers by Attending to Structurally Quantized Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Yichen Jiang",
        "Xiang Zhou",
        "Mohit Bansal"
      ],
      "abstract": "Transformers generalize to novel compositions of structures and entities\nafter being trained on a complex dataset, but easily overfit on datasets of\ninsufficient complexity. We observe that when the training set is sufficiently\ncomplex, the model encodes sentences that have a common syntactic structure\nusing a systematic attention pattern. Inspired by this observation, we propose\nSQ-Transformer (Structurally Quantized) that explicitly encourages\nsystematicity in the embeddings and attention layers, even with a training set\nof low complexity. At the embedding level, we introduce Structure-oriented\nVector Quantization (SoVQ) to cluster word embeddings into several classes of\nstructurally equivalent entities. At the attention level, we devise the\nSystematic Attention Layer (SAL) and an alternative, Systematically Regularized\nLayer (SRL) that operate on the quantized word embeddings so that sentences of\nthe same structure are encoded with invariant or similar attention patterns.\nEmpirically, we show that SQ-Transformer achieves stronger compositional\ngeneralization than the vanilla Transformer on multiple low-complexity semantic\nparsing and machine translation datasets. In our analysis, we show that SoVQ\nindeed learns a syntactically clustered embedding space and SAL/SRL induces\ngeneralizable attention patterns, which lead to improved systematicity.",
      "tldr_zh": "该研究发现，标准 Transformers 在复杂数据集上能实现组合泛化，但容易在简单数据集上过拟合。为此，提出 SQ-Transformer（Structurally Quantized）框架，通过在嵌入层引入 Structure-oriented Vector Quantization (SoVQ) 来聚类词嵌入为结构等价实体，并在注意力层设计 Systematic Attention Layer (SAL) 和 Systematically Regularized Layer (SRL)，以确保相同句法结构的句子具有不变或相似的注意力模式。实验结果显示，SQ-Transformer 在多个低复杂度语义解析和机器翻译数据集上，比传统 Transformers 实现了更强的组合泛化能力；进一步分析证实，SoVQ 形成了句法聚类的嵌入空间，而 SAL/SRL 诱导了可泛化的注意力模式，从而提升了整体系统性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, code: https://github.com/jiangycTarheel/SQ-Transformer",
      "pdf_url": "http://arxiv.org/pdf/2402.06492v1",
      "published_date": "2024-02-09 15:53:15 UTC",
      "updated_date": "2024-02-09 15:53:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:57:39.436965"
    },
    {
      "arxiv_id": "2402.06487v1",
      "title": "Le Nozze di Giustizia. Interactions between Artificial Intelligence, Law, Logic, Language and Computation with some case studies in Traffic Regulations and Health Care",
      "title_zh": "Le Nozze di Giustizia：人工智能、法律、逻辑、语言和计算之间的互动，以及一些交通法规和医疗保健领域的案例研究",
      "authors": [
        "Joost J. Joosten",
        "Manuela Montoya García"
      ],
      "abstract": "An important aim of this paper is to convey some basics of mathematical logic\nto the legal community working with Artificial Intelligence. After analysing\nwhat AI is, we decide to delimit ourselves to rule-based AI leaving Neural\nNetworks and Machine Learning aside. Rule based AI allows for Formal methods\nwhich are described in a rudimentary form. We will then see how mathematical\nlogic interacts with legal rule-based AI practice. We shall see how\nmathematical logic imposes limitations and complications to AI applications. We\nclassify the limitations and interactions between mathematical logic and legal\nAI in three categories: logical, computational and mathematical. The examples\nto showcase the interactions will largely come from European traffic\nregulations. The paper closes off with some reflections on how and where AI\ncould be used and on basic mechanisms that shape society.",
      "tldr_zh": "本论文旨在向法律社区介绍数学逻辑基础，并探讨其与基于规则的 Artificial Intelligence (AI) 的互动，重点排除 Neural Networks 和 Machine Learning。作者分析了 Formal Methods 的基本形式，并将数学逻辑对法律 AI 的限制分类为逻辑、计算和数学方面。论文以欧洲交通法规为例，展示这些互动的实际影响，并反思 AI 在社会中的潜在应用和机制。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06487v1",
      "published_date": "2024-02-09 15:43:31 UTC",
      "updated_date": "2024-02-09 15:43:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:57:49.867148"
    },
    {
      "arxiv_id": "2402.06472v1",
      "title": "\"When He Feels Cold, He Goes to the Seahorse\"-Blending Generative AI into Multimaterial Storymaking for Family Expressive Arts Therapy",
      "title_zh": "翻译失败",
      "authors": [
        "Di Liu",
        "Hanqing Zhou",
        "Pengcheng An"
      ],
      "abstract": "Storymaking, as an integrative form of expressive arts therapy, is an\neffective means to foster family communication. Yet, the integration of\ngenerative AI as expressive materials in therapeutic storymaking remains\nunderexplored. And there is a lack of HCI implications on how to support\nfamilies and therapists in this context. Addressing this, our study involved\nfive weeks of storymaking sessions with seven families guided by a professional\ntherapist. In these sessions, the families used both traditional art-making\nmaterials and image-based generative AI to create and evolve their family\nstories. Via the rich empirical data and commentaries from four expert\ntherapists, we contextualize how families creatively melded AI and traditional\nexpressive materials to externalize their ideas and feelings. Through the lens\nof Expressive Therapies Continuum (ETC), we characterize the therapeutic\nimplications of AI as expressive materials. Desirable interaction qualities to\nsupport children, parents, and therapists are distilled for future HCI\nresearch.",
      "tldr_zh": "本文研究探讨了将生成式 AI 整合到家庭表达艺术疗法中的潜力，特别针对多材料故事创作以提升家庭沟通。研究通过五周的会议，与七个家庭合作，由专业治疗师指导，让参与者使用传统艺术材料和图像生成 AI 来创建并演化家庭故事。基于丰富经验数据和四位专家治疗师的评论，论文分析了家庭如何创意结合 AI 与传统材料来表达情感，并通过 Expressive Therapies Continuum (ETC) 框架，阐述了 AI 的治疗含义，并提炼出支持儿童、父母和治疗师的理想 HCI 交互品质，为未来研究提供指导。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "to appear at ACM CHI '24",
      "pdf_url": "http://arxiv.org/pdf/2402.06472v1",
      "published_date": "2024-02-09 15:25:36 UTC",
      "updated_date": "2024-02-09 15:25:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:58:04.291722"
    },
    {
      "arxiv_id": "2402.06457v2",
      "title": "V-STaR: Training Verifiers for Self-Taught Reasoners",
      "title_zh": "翻译失败",
      "authors": [
        "Arian Hosseini",
        "Xingdi Yuan",
        "Nikolay Malkin",
        "Aaron Courville",
        "Alessandro Sordoni",
        "Rishabh Agarwal"
      ],
      "abstract": "Common self-improvement approaches for large language models (LLMs), such as\nSTaR, iteratively fine-tune LLMs on self-generated solutions to improve their\nproblem-solving ability. However, these approaches discard the large amounts of\nincorrect solutions generated during this process, potentially neglecting\nvaluable information in such solutions. To address this shortcoming, we propose\nV-STaR that utilizes both the correct and incorrect solutions generated during\nthe self-improvement process to train a verifier using DPO that judges\ncorrectness of model-generated solutions. This verifier is used at inference\ntime to select one solution among many candidate solutions. Running V-STaR for\nmultiple iterations results in progressively better reasoners and verifiers,\ndelivering a 4% to 17% test accuracy improvement over existing self-improvement\nand verification approaches on common code generation and math reasoning\nbenchmarks with LLaMA2 models.",
      "tldr_zh": "该论文提出V-STaR，一种改进的自提升方法，用于训练大型语言模型(LLMs)的推理能力。V-STaR利用自生成解决方案中的正确和错误样本，通过直接偏好优化(DPO)训练一个验证器(verifier)，以判断解决方案的正确性，并在推理时从多个候选方案中选择最佳者。与现有方法如STaR相比，通过多次迭代，V-STaR能逐步提升推理器和验证器的性能，在代码生成和数学推理基准上，使用LLaMA2模型的测试准确率提高了4%至17%。这项工作展示了如何从错误解决方案中提取价值，优化LLMs的自学习过程。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06457v2",
      "published_date": "2024-02-09 15:02:56 UTC",
      "updated_date": "2024-08-14 02:41:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:58:14.764790"
    },
    {
      "arxiv_id": "2402.06402v1",
      "title": "Hierarchical Transformers are Efficient Meta-Reinforcement Learners",
      "title_zh": "翻译失败",
      "authors": [
        "Gresa Shala",
        "André Biedenkapp",
        "Josif Grabocka"
      ],
      "abstract": "We introduce Hierarchical Transformers for Meta-Reinforcement Learning\n(HTrMRL), a powerful online meta-reinforcement learning approach. HTrMRL aims\nto address the challenge of enabling reinforcement learning agents to perform\neffectively in previously unseen tasks. We demonstrate how past episodes serve\nas a rich source of information, which our model effectively distills and\napplies to new contexts. Our learned algorithm is capable of outperforming the\nprevious state-of-the-art and provides more efficient meta-training while\nsignificantly improving generalization capabilities. Experimental results,\nobtained across various simulated tasks of the Meta-World Benchmark, indicate a\nsignificant improvement in learning efficiency and adaptability compared to the\nstate-of-the-art on a variety of tasks. Our approach not only enhances the\nagent's ability to generalize from limited data but also paves the way for more\nrobust and versatile AI systems.",
      "tldr_zh": "我们引入了 Hierarchical Transformers for Meta-Reinforcement Learning (HTrMRL)，这是一种高效的在线元强化学习方法，旨在帮助强化学习代理在新任务中表现出色。HTrMRL 通过利用过去的情节作为信息来源，并进行有效提炼和应用，显著提升了训练效率和泛化能力。实验结果显示，在 Meta-World Benchmark 的各种模拟任务上，该方法超过了现有 state-of-the-art 技术，并增强了代理从有限数据中学习和适应的能力，从而为更鲁棒和多功能的 AI 系统奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06402v1",
      "published_date": "2024-02-09 13:40:11 UTC",
      "updated_date": "2024-02-09 13:40:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:58:27.553738"
    },
    {
      "arxiv_id": "2402.06397v1",
      "title": "Finding hardness reductions automatically using SAT solvers",
      "title_zh": "翻译失败",
      "authors": [
        "Helena Bergold",
        "Manfred Scheucher",
        "Felix Schröder"
      ],
      "abstract": "In this article, we show that the completion problem, i.e. the decision\nproblem whether a partial structure can be completed to a full structure, is\nNP-complete for many combinatorial structures. While the gadgets for most\nreductions in literature are found by hand, we present an algorithm to\nconstruct gadgets in a fully automated way. Using our framework which is based\non SAT, we present the first thorough study of the completion problem on sign\nmappings with forbidden substructures by classifying thousands of structures\nfor which the completion problem is NP-complete. Our list in particular\nincludes interior triple systems, which were introduced by Knuth towards an\naxiomatization of planar point configurations. Last but not least, we give an\ninfinite family of structures generalizing interior triple system to higher\ndimensions for which the completion problem is NP-complete.",
      "tldr_zh": "本文提出了一种基于 SAT 求解器的算法，用于自动构建 gadgets，从而自动找到 hardness reductions，针对许多组合结构的完成问题（completion problem），证明其是 NP-complete。该框架首次对 sign mappings with forbidden substructures 进行了彻底研究，分类了数千种结构的完成问题，并证实它们是 NP-complete。具体而言，该研究涵盖了 interior triple systems，并扩展到一个无限家族的更高维结构，其完成问题同样是 NP-complete。",
      "categories": [
        "cs.CC",
        "cs.AI",
        "cs.DS",
        "cs.LO",
        "math.CO"
      ],
      "primary_category": "cs.CC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06397v1",
      "published_date": "2024-02-09 13:29:44 UTC",
      "updated_date": "2024-02-09 13:29:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:58:38.492038"
    },
    {
      "arxiv_id": "2402.06389v1",
      "title": "Human Aesthetic Preference-Based Large Text-to-Image Model Personalization: Kandinsky Generation as an Example",
      "title_zh": "翻译失败",
      "authors": [
        "Aven-Le Zhou",
        "Yu-Ao Wang",
        "Wei Wu",
        "Kang Zhang"
      ],
      "abstract": "With the advancement of neural generative capabilities, the art community has\nactively embraced GenAI (generative artificial intelligence) for creating\npainterly content. Large text-to-image models can quickly generate\naesthetically pleasing outcomes. However, the process can be non-deterministic\nand often involves tedious trial-and-error, as users struggle with formulating\neffective prompts to achieve their desired results. This paper introduces a\nprompting-free generative approach that empowers users to automatically\ngenerate personalized painterly content that incorporates their aesthetic\npreferences in a customized artistic style. This approach involves utilizing\n``semantic injection'' to customize an artist model in a specific artistic\nstyle, and further leveraging a genetic algorithm to optimize the prompt\ngeneration process through real-time iterative human feedback. By solely\nrelying on the user's aesthetic evaluation and preference for the artist\nmodel-generated images, this approach creates the user a personalized model\nthat encompasses their aesthetic preferences and the customized artistic style.",
      "tldr_zh": "这篇论文提出了一种基于人类审美偏好的Large text-to-Image模型个性化方法，以Kandinsky Generation为例，旨在解决用户在生成艺术内容时因prompt试错而导致的低效问题。方法包括使用“semantic injection”来自定义特定艺术风格，并结合“genetic algorithm”通过实时人类反馈优化prompt生成过程，从而无需手动prompt即可创建个性化模型。最终，该方法仅依赖用户的审美评价，就能自动生成符合其偏好和定制风格的艺术内容，提高了生成效率和用户体验。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.06389v1",
      "published_date": "2024-02-09 13:11:19 UTC",
      "updated_date": "2024-02-09 13:11:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:58:50.433457"
    },
    {
      "arxiv_id": "2402.06388v3",
      "title": "Convergence of a L2 regularized Policy Gradient Algorithm for the Multi Armed Bandit",
      "title_zh": "L2 正则化策略梯度算法在多臂老虎机问题中的收敛",
      "authors": [
        "Stefana Anita",
        "Gabriel Turinici"
      ],
      "abstract": "Although Multi Armed Bandit (MAB) on one hand and the policy gradient\napproach on the other hand are among the most used frameworks of Reinforcement\nLearning, the theoretical properties of the policy gradient algorithm used for\nMAB have not been given enough attention. We investigate in this work the\nconvergence of such a procedure for the situation when a $L2$ regularization\nterm is present jointly with the 'softmax' parametrization. We prove\nconvergence under appropriate technical hypotheses and test numerically the\nprocedure including situations beyond the theoretical setting. The tests show\nthat a time dependent regularized procedure can improve over the canonical\napproach especially when the initial guess is far from the solution.",
      "tldr_zh": "这篇论文研究了在Multi Armed Bandit (MAB)问题中，带L2 regularization的policy gradient算法的收敛性，填补了这一领域的理论空白。作者采用softmax parametrization并在适当的技术假设下，证明了算法的收敛。数值实验结果显示，时间相关的正则化方法在初始猜测远离解决方案时，能显著提升算法性能，尤其适用于超出理论设置的场景。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.DS",
        "cs.LG",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06388v3",
      "published_date": "2024-02-09 13:10:04 UTC",
      "updated_date": "2024-11-26 09:54:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:59:01.588261"
    },
    {
      "arxiv_id": "2402.06377v1",
      "title": "High-Precision Geosteering via Reinforcement Learning and Particle Filters",
      "title_zh": "翻译失败",
      "authors": [
        "Ressi Bonti Muhammad",
        "Apoorv Srivastava",
        "Sergey Alyaev",
        "Reidar Brumer Bratvold",
        "Daniel M. Tartakovsky"
      ],
      "abstract": "Geosteering, a key component of drilling operations, traditionally involves\nmanual interpretation of various data sources such as well-log data. This\nintroduces subjective biases and inconsistent procedures. Academic attempts to\nsolve geosteering decision optimization with greedy optimization and\nApproximate Dynamic Programming (ADP) showed promise but lacked adaptivity to\nrealistic diverse scenarios. Reinforcement learning (RL) offers a solution to\nthese challenges, facilitating optimal decision-making through reward-based\niterative learning. State estimation methods, e.g., particle filter (PF),\nprovide a complementary strategy for geosteering decision-making based on\nonline information. We integrate an RL-based geosteering with PF to address\nrealistic geosteering scenarios. Our framework deploys PF to process real-time\nwell-log data to estimate the location of the well relative to the\nstratigraphic layers, which then informs the RL-based decision-making process.\nWe compare our method's performance with that of using solely either RL or PF.\nOur findings indicate a synergy between RL and PF in yielding optimized\ngeosteering decisions.",
      "tldr_zh": "该研究针对传统 geosteering 操作中手动数据解释带来的主观偏差和不一致问题，提出了一种整合 Reinforcement Learning (RL) 和 Particle Filters (PF) 的高精度框架。方法利用 PF 处理实时 well-log 数据来估算井位相对地层的位置，从而为 RL 决策过程提供准确信息，实现优化决策。实验结果显示，该整合框架比单独使用 RL 或 PF 的方法更具协同效应，能够在多样化场景中提升 geosteering 的精度和适应性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.geo-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "40 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.06377v1",
      "published_date": "2024-02-09 12:54:34 UTC",
      "updated_date": "2024-02-09 12:54:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:59:14.439529"
    },
    {
      "arxiv_id": "2402.06360v1",
      "title": "CoSearchAgent: A Lightweight Collaborative Search Agent with Large Language Models",
      "title_zh": "CoSearchAgent：一种基于大型语言模型的轻量级协作搜索代理",
      "authors": [
        "Peiyuan Gong",
        "Jiamian Li",
        "Jiaxin Mao"
      ],
      "abstract": "Collaborative search supports multiple users working together to accomplish a\nspecific search task. Research has found that designing lightweight\ncollaborative search plugins within instant messaging platforms aligns better\nwith users' collaborative habits. However, due to the complexity of multi-user\ninteraction scenarios, it is challenging to implement a fully functioning\nlightweight collaborative search system. Therefore, previous studies on\nlightweight collaborative search had to rely on the Wizard of Oz paradigm. In\nrecent years, large language models (LLMs) have been demonstrated to interact\nnaturally with users and achieve complex information-seeking tasks through\nLLM-based agents. Hence, to better support the research in collaborative\nsearch, in this demo, we propose CoSearchAgent, a lightweight collaborative\nsearch agent powered by LLMs. CoSearchAgent is designed as a Slack plugin that\ncan support collaborative search during multi-party conversations on this\nplatform. Equipped with the capacity to understand the queries and context in\nmulti-user conversations and the ability to search the Web for relevant\ninformation via APIs, CoSearchAgent can respond to user queries with answers\ngrounded on the relevant search results. It can also ask clarifying questions\nwhen the information needs are unclear. The proposed CoSearchAgent is highly\nflexible and would be useful for supporting further research on collaborative\nsearch. The code and demo video are accessible.",
      "tldr_zh": "该研究提出CoSearchAgent，一种基于Large Language Models (LLMs)的轻量级协作搜索代理，旨在支持多用户在即时通信平台（如Slack）上共同完成搜索任务。CoSearchAgent能够理解多用户对话中的查询和上下文，通过Web APIs进行相关信息检索，提供基于搜索结果的回答，并主动提出澄清问题，以应对信息需求的不确定性。相比以往依赖Wizard of Oz paradigm的系统，该代理更灵活实用，并附带代码和演示视频，有助于推进协作搜索领域的进一步研究。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "4 pages, demo",
      "pdf_url": "http://arxiv.org/pdf/2402.06360v1",
      "published_date": "2024-02-09 12:10:00 UTC",
      "updated_date": "2024-02-09 12:10:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:59:26.509264"
    },
    {
      "arxiv_id": "2402.06359v1",
      "title": "Modelling Human Values for AI Reasoning",
      "title_zh": "为AI推理建模人类价值观",
      "authors": [
        "Nardine Osman",
        "Mark d'Inverno"
      ],
      "abstract": "One of today's most significant societal challenges is building AI systems\nwhose behaviour, or the behaviour it enables within communities of interacting\nagents (human and artificial), aligns with human values. To address this\nchallenge, we detail a formal model of human values for their explicit\ncomputational representation. To our knowledge, this has not been attempted as\nyet, which is surprising given the growing volume of research integrating\nvalues within AI. Taking as our starting point the wealth of research\ninvestigating the nature of human values from social psychology over the last\nfew decades, we set out to provide such a formal model. We show how this model\ncan provide the foundational apparatus for AI-based reasoning over values, and\ndemonstrate its applicability in real-world use cases. We illustrate how our\nmodel captures the key ideas from social psychology research and propose a\nroadmap for future integrated, and interdisciplinary, research into human\nvalues in AI. The ability to automatically reason over values not only helps\naddress the value alignment problem but also facilitates the design of AI\nsystems that can support individuals and communities in making more informed,\nvalue-aligned decisions. More and more, individuals and organisations are\nmotivated to understand their values more explicitly and explore whether their\nbehaviours and attitudes properly reflect them. Our work on modelling human\nvalues will enable AI systems to be designed and deployed to meet this growing\nneed.",
      "tldr_zh": "该论文提出一个正式模型，用于在AI推理中显式计算表示人类价值观，以解决AI系统行为与人类价值观对齐的挑战。该模型基于社会心理学研究的关键概念，提供了一个基础框架，支持AI对价值观的自动推理，并在真实场景中应用。实验和分析显示，该模型能帮助个体和社区更清晰地理解并探索其价值观，从而促进更明智的决策。该工作还为未来跨学科研究绘制了路线图，推动AI系统的可信设计和发展。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "68T01",
        "I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06359v1",
      "published_date": "2024-02-09 12:08:49 UTC",
      "updated_date": "2024-02-09 12:08:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:59:38.836271"
    },
    {
      "arxiv_id": "2402.06334v1",
      "title": "ExaRanker-Open: Synthetic Explanation for IR using Open-Source LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Fernando Ferraretto",
        "Thiago Laitz",
        "Roberto Lotufo",
        "Rodrigo Nogueira"
      ],
      "abstract": "ExaRanker recently introduced an approach to training information retrieval\n(IR) models, incorporating natural language explanations as additional labels.\nThe method addresses the challenge of limited labeled examples, leading to\nimprovements in the effectiveness of IR models. However, the initial results\nwere based on proprietary language models such as GPT-3.5, which posed\nconstraints on dataset size due to its cost and data privacy. In this paper, we\nintroduce ExaRanker-Open, where we adapt and explore the use of open-source\nlanguage models to generate explanations. The method has been tested using\ndifferent LLMs and datasets sizes to better comprehend the effective\ncontribution of data augmentation. Our findings reveal that incorporating\nexplanations consistently enhances neural rankers, with benefits escalating as\nthe LLM size increases. Notably, the data augmentation method proves\nadvantageous even with large datasets, as evidenced by ExaRanker surpassing the\ntarget baseline by 0.6 nDCG@10 points in our study. To encourage further\nadvancements by the research community, we have open-sourced both the code and\ndatasets at https://github.com/unicamp-dl/ExaRanker.",
      "tldr_zh": "本文提出 ExaRanker-Open，一种使用开源 LLMs 生成合成解释的方法，以增强信息检索 (IR) 模型的训练效果，解决之前依赖专有模型如 GPT-3.5 的成本和隐私问题。\n该方法通过测试不同 LLMs 和数据集大小，探索数据增强的有效性，证明添加自然语言解释能一致提升神经排名器的性能。\n研究发现，随着 LLM 规模增加，益处更显著，即使在大数据集上，ExaRanker-Open 也比基线模型提高了 0.6 nDCG@10 分。\n为推动社区研究，该项目已开源代码和数据集，网址为 https://github.com/unicamp-dl/ExaRanker。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06334v1",
      "published_date": "2024-02-09 11:23:14 UTC",
      "updated_date": "2024-02-09 11:23:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:59:52.213007"
    },
    {
      "arxiv_id": "2402.06326v2",
      "title": "Prompt Learning on Temporal Interaction Graphs",
      "title_zh": "时间交互图上的提示学习",
      "authors": [
        "Xi Chen",
        "Siwei Zhang",
        "Yun Xiong",
        "Xixi Wu",
        "Jiawei Zhang",
        "Xiangguo Sun",
        "Yao Zhang",
        "Feng Zhao",
        "Yulin Kang"
      ],
      "abstract": "Temporal Interaction Graphs (TIGs) are widely utilized to represent\nreal-world systems. To facilitate representation learning on TIGs, researchers\nhave proposed a series of TIG models. However, these models are still facing\ntwo tough gaps between the pre-training and downstream predictions in their\n``pre-train, predict'' training paradigm. First, the temporal discrepancy\nbetween the pre-training and inference data severely undermines the models'\napplicability in distant future predictions on the dynamically evolving data.\nSecond, the semantic divergence between pretext and downstream tasks hinders\ntheir practical applications, as they struggle to align with their learning and\nprediction capabilities across application scenarios.\n  Recently, the ``pre-train, prompt'' paradigm has emerged as a lightweight\nmechanism for model generalization. Applying this paradigm is a potential\nsolution to solve the aforementioned challenges. However, the adaptation of\nthis paradigm to TIGs is not straightforward. The application of prompting in\nstatic graph contexts falls short in temporal settings due to a lack of\nconsideration for time-sensitive dynamics and a deficiency in expressive power.\nTo address this issue, we introduce Temporal Interaction Graph Prompting\n(TIGPrompt), a versatile framework that seamlessly integrates with TIG models,\nbridging both the temporal and semantic gaps. In detail, we propose a temporal\nprompt generator to offer temporally-aware prompts for different tasks. These\nprompts stand out for their minimalistic design, relying solely on the tuning\nof the prompt generator with very little supervision data. To cater to varying\ncomputational resource demands, we propose an extended ``pre-train,\nprompt-based fine-tune'' paradigm, offering greater flexibility. Through\nextensive experiments, the TIGPrompt demonstrates the SOTA performance and\nremarkable efficiency advantages.",
      "tldr_zh": "Temporal Interaction Graphs (TIGs) 在预训练和下游预测中存在时间差异和语义分歧的问题，导致模型在动态演变数据上的未来预测和实际应用效果不佳。作者提出 TIGPrompt 框架，这是一个通用的机制，与 TIG 模型无缝集成，通过 temporal prompt generator 生成时间感知提示，仅需微调提示生成器和少量监督数据即可适应不同任务。为满足不同计算资源需求，该框架扩展了“pre-train, prompt-based fine-tune”范式。实验结果表明，TIGPrompt 达到了 SOTA 性能，并展示了显著的效率优势。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.06326v2",
      "published_date": "2024-02-09 11:06:20 UTC",
      "updated_date": "2024-03-06 05:34:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:00:07.267141"
    },
    {
      "arxiv_id": "2402.06304v1",
      "title": "A New Approach to Voice Authenticity",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolas M. Müller",
        "Piotr Kawa",
        "Shen Hu",
        "Matthias Neu",
        "Jennifer Williams",
        "Philip Sperl",
        "Konstantin Böttinger"
      ],
      "abstract": "Voice faking, driven primarily by recent advances in text-to-speech (TTS)\nsynthesis technology, poses significant societal challenges. Currently, the\nprevailing assumption is that unaltered human speech can be considered genuine,\nwhile fake speech comes from TTS synthesis. We argue that this binary\ndistinction is oversimplified. For instance, altered playback speeds can be\nused for malicious purposes, like in the 'Drunken Nancy Pelosi' incident.\nSimilarly, editing of audio clips can be done ethically, e.g., for brevity or\nsummarization in news reporting or podcasts, but editing can also create\nmisleading narratives. In this paper, we propose a conceptual shift away from\nthe binary paradigm of audio being either 'fake' or 'real'. Instead, our focus\nis on pinpointing 'voice edits', which encompass traditional modifications like\nfilters and cuts, as well as TTS synthesis and VC systems. We delineate 6\ncategories and curate a new challenge dataset rooted in the M-AILABS corpus,\nfor which we present baseline detection systems. And most importantly, we argue\nthat merely categorizing audio as fake or real is a dangerous\nover-simplification that will fail to move the field of speech technology\nforward.",
      "tldr_zh": "该论文质疑了当前语音认证的二元范式，即将语音简单分为“真实”（未修改人类语音）和“假”（TTS 合成），并指出这种区分忽略了如修改播放速度或编辑音频等潜在恶意或道德问题。作者提出一种新方法，聚焦于“voice edits”，涵盖传统修改（如过滤和剪切）、TTS 合成和 VC（Voice Conversion）系统，并定义了 6 个类别。基于 M-AILABS 语料库，他们创建了一个新挑战数据集，并提供了基线检测系统，以推动更细致的语音编辑识别。最后，论文强调，仅将音频分类为假或真是一种危险简化，会阻碍语音技术的发展。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06304v1",
      "published_date": "2024-02-09 10:34:01 UTC",
      "updated_date": "2024-02-09 10:34:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:00:16.747781"
    },
    {
      "arxiv_id": "2402.18589v1",
      "title": "Verif.ai: Towards an Open-Source Scientific Generative Question-Answering System with Referenced and Verifiable Answers",
      "title_zh": "翻译失败",
      "authors": [
        "Miloš Košprdić",
        "Adela Ljajić",
        "Bojana Bašaragin",
        "Darija Medvecki",
        "Nikola Milošević"
      ],
      "abstract": "In this paper, we present the current progress of the project Verif.ai, an\nopen-source scientific generative question-answering system with referenced and\nverified answers. The components of the system are (1) an information retrieval\nsystem combining semantic and lexical search techniques over scientific papers\n(PubMed), (2) a fine-tuned generative model (Mistral 7B) taking top answers and\ngenerating answers with references to the papers from which the claim was\nderived, and (3) a verification engine that cross-checks the generated claim\nand the abstract or paper from which the claim was derived, verifying whether\nthere may have been any hallucinations in generating the claim. We are\nreinforcing the generative model by providing the abstract in context, but in\naddition, an independent set of methods and models are verifying the answer and\nchecking for hallucinations. Therefore, we believe that by using our method, we\ncan make scientists more productive, while building trust in the use of\ngenerative language models in scientific environments, where hallucinations and\nmisinformation cannot be tolerated.",
      "tldr_zh": "本论文介绍了 Verif.ai，这是一个开源的科学生成式问答系统，旨在提供带引用的可验证答案，以减少 hallucinations 并提升科学领域的可靠性。系统由三个主要组件组成：(1) 结合语义和词汇搜索的信息检索系统，针对 PubMed 中的科学论文；(2) 微调的 Mistral 7B 生成模型，根据顶层答案生成带来源引用的响应；(3) 一个独立验证引擎，通过交叉检查生成的声明与来源论文来检测潜在幻觉。总体而言，该方法有助于提高科学家的生产力，并在严谨的科学环境中建立对生成语言模型的信任。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted as a short paper at The Sixteenth International Conference\n  on Evolving Internet (INTERNET 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.18589v1",
      "published_date": "2024-02-09 10:25:01 UTC",
      "updated_date": "2024-02-09 10:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:00:29.670046"
    },
    {
      "arxiv_id": "2402.06299v1",
      "title": "A Functional Analysis Approach to Symbolic Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Kirill Antonov",
        "Roman Kalkreuth",
        "Kaifeng Yang",
        "Thomas Bäck",
        "Niki van Stein",
        "Anna V Kononova"
      ],
      "abstract": "Symbolic regression (SR) poses a significant challenge for randomized search\nheuristics due to its reliance on the synthesis of expressions for input-output\nmappings. Although traditional genetic programming (GP) algorithms have\nachieved success in various domains, they exhibit limited performance when\ntree-based representations are used for SR. To address these limitations, we\nintroduce a novel SR approach called Fourier Tree Growing (FTG) that draws\ninsights from functional analysis. This new perspective enables us to perform\noptimization directly in a different space, thus avoiding intricate symbolic\nexpressions. Our proposed algorithm exhibits significant performance\nimprovements over traditional GP methods on a range of classical\none-dimensional benchmarking problems. To identify and explain limiting factors\nof GP and FTG, we perform experiments on a large-scale polynomials benchmark\nwith high-order polynomials up to degree 100. To the best of the authors'\nknowledge, this work represents the pioneering application of functional\nanalysis in addressing SR problems. The superior performance of the proposed\nalgorithm and insights into the limitations of GP open the way for further\nadvancing GP for SR and related areas of explainable machine learning.",
      "tldr_zh": "本研究针对符号回归(Symbolic Regression, SR)的挑战，提出了一种新型方法Fourier Tree Growing (FTG)，它借鉴函数分析(Functional Analysis)原理，在不同优化空间直接进行计算，从而避免了传统遗传编程(Genetic Programming, GP)基于树形表示的复杂性和性能限制。FTG在经典一维基准问题上表现出显著改进，并在大规模多项式基准测试（最高100度）中优于GP方法。实验结果揭示了GP的局限因素，并首次将函数分析应用于SR领域，为可解释机器学习(Explainable Machine Learning)的发展提供了新方向。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "14 pages, 3 figures. Submitted to Genetic and Evolutionary\n  Computation Conference (GECCO-2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.06299v1",
      "published_date": "2024-02-09 10:24:47 UTC",
      "updated_date": "2024-02-09 10:24:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:00:41.666940"
    },
    {
      "arxiv_id": "2402.06287v3",
      "title": "AI, Meet Human: Learning Paradigms for Hybrid Decision Making Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Clara Punzi",
        "Roberto Pellungrini",
        "Mattia Setzu",
        "Fosca Giannotti",
        "Dino Pedreschi"
      ],
      "abstract": "Everyday we increasingly rely on machine learning models to automate and\nsupport high-stake tasks and decisions. This growing presence means that humans\nare now constantly interacting with machine learning-based systems, training\nand using models everyday. Several different techniques in computer science\nliterature account for the human interaction with machine learning systems, but\ntheir classification is sparse and the goals varied. This survey proposes a\ntaxonomy of Hybrid Decision Making Systems, providing both a conceptual and\ntechnical framework for understanding how current computer science literature\nmodels interaction between humans and machines.",
      "tldr_zh": "这篇论文探讨了人类与机器学习模型的互动，强调在高风险任务中日益依赖这些系统。作者提出一个Hybrid Decision Making Systems的分类法（taxonomy），旨在统一现有计算机科学文献中处理人类-机器互动的各种技术。论文提供概念和技术框架，帮助更好地理解和建模这种混合决策过程，从而支持更有效的系统设计和应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06287v3",
      "published_date": "2024-02-09 09:54:01 UTC",
      "updated_date": "2025-03-07 14:20:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:00:51.463960"
    },
    {
      "arxiv_id": "2402.10948v2",
      "title": "Zero-shot Explainable Mental Health Analysis on Social Media by Incorporating Mental Scales",
      "title_zh": "通过整合心理量表实现的社交媒体零样本可解释心理健康分析",
      "authors": [
        "Wenyu Li",
        "Yinuo Zhu",
        "Xin Lin",
        "Ming Li",
        "Ziyue Jiang",
        "Ziqian Zeng"
      ],
      "abstract": "Traditional discriminative approaches in mental health analysis are known for\ntheir strong capacity but lack interpretability and demand large-scale\nannotated data. The generative approaches, such as those based on large\nlanguage models (LLMs), have the potential to get rid of heavy annotations and\nprovide explanations but their capabilities still fall short compared to\ndiscriminative approaches, and their explanations may be unreliable due to the\nfact that the generation of explanation is a black-box process. Inspired by the\npsychological assessment practice of using scales to evaluate mental states,\nour method which is called Mental Analysis by Incorporating Mental Scales\n(MAIMS), incorporates two procedures via LLMs. First, the patient completes\nmental scales, and second, the psychologist interprets the collected\ninformation from the mental scales and makes informed decisions. Experimental\nresults show that MAIMS outperforms other zero-shot methods. MAIMS can generate\nmore rigorous explanation based on the outputs of mental scales",
      "tldr_zh": "这篇论文提出了一种零-shot可解释社交媒体心理健康分析方法，名为Mental Analysis by Incorporating Mental Scales (MAIMS)，旨在解决传统判别方法缺乏可解释性和需要大量标注数据的问题，同时克服LLMs生成方法在可靠性和性能上的不足。MAIMS受心理评估实践启发，通过LLMs实现两个步骤：首先，让用户完成mental scales量表评估；其次，对量表输出进行解释以做出决策。实验结果显示，MAIMS在零-shot设置下优于其他方法，并能生成更严格和可靠的解释。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "4 pages,2 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.10948v2",
      "published_date": "2024-02-09 09:44:06 UTC",
      "updated_date": "2024-03-15 02:02:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:01:05.776121"
    },
    {
      "arxiv_id": "2402.06264v3",
      "title": "LLaVA-Docent: Instruction Tuning with Multimodal Large Language Model to Support Art Appreciation Education",
      "title_zh": "LLaVA-Docent：使用多模态大语言模型的指令微调以支持艺术鉴赏教育",
      "authors": [
        "Unggi Lee",
        "Minji Jeon",
        "Yunseo Lee",
        "Gyuri Byun",
        "Yoorim Son",
        "Jaeyoon Shin",
        "Hongkyu Ko",
        "Hyeoncheol Kim"
      ],
      "abstract": "Despite the development of various AI systems to support learning in various\ndomains, AI assistance for art appreciation education has not been extensively\nexplored. Art appreciation, often perceived as an unfamiliar and challenging\nendeavor for most students, can be more accessible with a generative AI enabled\nconversation partner that provides tailored questions and encourages the\naudience to deeply appreciate artwork. This study explores the application of\nmultimodal large language models (MLLMs) in art appreciation education, with a\nfocus on developing LLaVA-Docent, a model designed to serve as a personal tutor\nfor art appreciation. Our approach involved design and development research,\nfocusing on iterative enhancement to design and develop the application to\nproduce a functional MLLM-enabled chatbot along with a data design framework\nfor art appreciation education. To that end, we established a virtual dialogue\ndataset that was generated by GPT-4, which was instrumental in training our\nMLLM, LLaVA-Docent. The performance of LLaVA-Docent was evaluated by\nbenchmarking it against alternative settings and revealed its distinct\nstrengths and weaknesses. Our findings highlight the efficacy of the MMLM-based\npersonalized art appreciation chatbot and demonstrate its applicability for a\nnovel approach in which art appreciation is taught and experienced.",
      "tldr_zh": "该研究探讨了多模态大语言模型(MLLMs)在艺术欣赏教育中的应用，针对学生对艺术的陌生感和挑战性，开发了LLaVA-Docent模型作为个性化聊天机器人导师，以提供定制问题并鼓励深度互动。研究采用指令微调(Instruction Tuning)方法，通过迭代设计和开发框架，利用GPT-4生成虚拟对话数据集来训练模型。实验结果显示，LLaVA-Docent在基准测试中表现出显著优势，突显其在提升艺术欣赏可访问性和教学效果方面的潜力，为基于MLLMs的艺术教育提供了一种新颖方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "37 pages, 4 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.06264v3",
      "published_date": "2024-02-09 09:25:18 UTC",
      "updated_date": "2024-09-18 00:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:01:17.641900"
    },
    {
      "arxiv_id": "2402.06262v2",
      "title": "On the Efficacy of Eviction Policy for Key-Value Constrained Generative Language Model Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Siyu Ren",
        "Kenny Q. Zhu"
      ],
      "abstract": "Despite the recent success associated with Large Language Models (LLMs), they\nare notably cost-prohibitive to deploy in resource-constrained environments due\nto their excessive memory and computational demands. In addition to model\nparameters, the key-value cache is also stored in GPU memory, growing linearly\nwith batch size and sequence length. As a remedy, recent works have proposed\nvarious eviction policies for maintaining the overhead of key-value cache under\na given budget. This paper embarks on the efficacy of existing eviction\npolicies in terms of importance score calculation and eviction scope\nconstruction. We identify the deficiency of prior policies in these two aspects\nand introduce RoCo, a robust cache omission policy based on temporal attention\nscores and robustness measures. Extensive experimentation spanning prefilling\nand auto-regressive decoding stages validates the superiority of RoCo. Finally,\nwe release EasyKV, a versatile software package dedicated to user-friendly\nkey-value constrained generative inference. Code available at\nhttps://github.com/DRSY/EasyKV.",
      "tldr_zh": "本论文探讨了在资源受限环境中部署 Large Language Models (LLMs) 的挑战，特别是 Key-Value cache 的内存开销问题，该缓存会随批量大小和序列长度线性增长。作者评估了现有 eviction policies 在重要性分数计算和驱逐范围构建方面的不足，并提出 RoCo，一种基于 temporal attention scores 和 robustness measures 的稳健缓存省略策略。实验结果显示，RoCo 在预填充和自回归解码阶段表现出优越性，且论文还发布了 EasyKV 软件包，以支持用户友好的 Key-Value 约束生成推理。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06262v2",
      "published_date": "2024-02-09 09:20:59 UTC",
      "updated_date": "2024-02-17 10:08:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:01:31.569898"
    },
    {
      "arxiv_id": "2402.06255v4",
      "title": "Fight Back Against Jailbreaking via Prompt Adversarial Tuning",
      "title_zh": "通过提示对抗调整反击越狱攻击",
      "authors": [
        "Yichuan Mo",
        "Yuji Wang",
        "Zeming Wei",
        "Yisen Wang"
      ],
      "abstract": "While Large Language Models (LLMs) have achieved tremendous success in\nvarious applications, they are also susceptible to jailbreaking attacks.\nSeveral primary defense strategies have been proposed to protect LLMs from\nproducing harmful information, mostly focusing on model fine-tuning or\nheuristical defense designs. However, how to achieve intrinsic robustness\nthrough prompt optimization remains an open problem. In this paper, motivated\nby adversarial training paradigms for achieving reliable robustness, we propose\nan approach named Prompt Adversarial Tuning (PAT) that trains a prompt control\nattached to the user prompt as a guard prefix. To achieve our defense goal\nwhilst maintaining natural performance, we optimize the control prompt with\nboth adversarial and benign prompts. Comprehensive experiments show that our\nmethod is effective against both grey-box and black-box attacks, reducing the\nsuccess rate of advanced attacks to nearly 0%, while maintaining the model's\nutility on the benign task and incurring only negligible computational\noverhead, charting a new perspective for future explorations in LLM security.\nOur code is available at https://github.com/PKU-ML/PAT.",
      "tldr_zh": "本论文针对大型语言模型（LLMs）易受越狱攻击（jailbreaking attacks）的问题，提出了一种Prompt Adversarial Tuning (PAT)方法，通过训练一个附加到用户提示的控制提示（guard prefix）来增强模型的内在鲁棒性。PAT优化过程同时使用对抗提示和良性提示，确保防御攻击的同时维持模型在正常任务上的性能。实验结果显示，该方法对灰盒和黑盒攻击均有效，将高级攻击成功率降至近0%，并仅带来微不足道的计算开销，为LLMs安全提供新视角。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06255v4",
      "published_date": "2024-02-09 09:09:39 UTC",
      "updated_date": "2024-10-31 12:24:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:01:40.451734"
    },
    {
      "arxiv_id": "2402.06700v4",
      "title": "Entropy-Regularized Token-Level Policy Optimization for Language Agent Reinforcement",
      "title_zh": "翻译失败",
      "authors": [
        "Muning Wen",
        "Junwei Liao",
        "Cheng Deng",
        "Jun Wang",
        "Weinan Zhang",
        "Ying Wen"
      ],
      "abstract": "Large Language Models (LLMs) have shown promise as intelligent agents in\ninteractive decision-making tasks. Traditional approaches often depend on\nmeticulously designed prompts, high-quality examples, or additional reward\nmodels for in-context learning, supervised fine-tuning, or RLHF. Reinforcement\nlearning (RL) presents a dynamic alternative for LLMs to overcome these\ndependencies by engaging directly with task-specific environments. Nonetheless,\nit faces significant hurdles: 1) instability stemming from the exponentially\nvast action space requiring exploration; 2) challenges in assigning token-level\ncredit based on action-level reward signals, resulting in discord between\nmaximizing rewards and accurately modeling corpus data. In response to these\nchallenges, we introduce Entropy-Regularized Token-level Policy Optimization\n(ETPO), an entropy-augmented RL method tailored for optimizing LLMs at the\ntoken level. At the heart of ETPO is our novel per-token soft Bellman update,\ndesigned to harmonize the RL process with the principles of language modeling.\nThis methodology decomposes the Q-function update from a coarse action-level\nview to a more granular token-level perspective, backed by theoretical proof of\noptimization consistency. Crucially, this decomposition renders linear time\ncomplexity in action exploration. We assess the effectiveness of ETPO within a\nsimulated environment that models data science code generation as a series of\nmulti-step interactive tasks; results underline ETPO's potential as a robust\nmethod for refining the interactive decision-making capabilities of language\nagents. For a more detailed preliminary work describing our motivation for\ntoken-level decomposition and applying it in PPO methods, please refer to\narXiv:2405.15821.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在强化学习（RL）中的应用，提出了一种Entropy-Regularized Token-level Policy Optimization (ETPO)方法，以解决行动空间的指数级不稳定性和基于行动级别奖励的token级信用分配挑战。ETPO的核心是引入per-token soft Bellman update，将Q-function更新从粗粒度的行动级别分解到细粒度的token级别，并通过理论证明确保优化的一致性，同时将探索复杂度降至线性级。在模拟的数据科学代码生成任务中，实验结果表明ETPO显著提升了语言代理的交互决策能力，为LLMs的自主优化提供了稳健框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06700v4",
      "published_date": "2024-02-09 07:45:26 UTC",
      "updated_date": "2024-06-06 12:29:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:01:52.690701"
    },
    {
      "arxiv_id": "2402.06229v1",
      "title": "Exploring Interaction Patterns for Debugging: Enhancing Conversational Capabilities of AI-assistants",
      "title_zh": "翻译失败",
      "authors": [
        "Bhavya Chopra",
        "Yasharth Bajpai",
        "Param Biyani",
        "Gustavo Soares",
        "Arjun Radhakrishna",
        "Chris Parnin",
        "Sumit Gulwani"
      ],
      "abstract": "The widespread availability of Large Language Models (LLMs) within Integrated\nDevelopment Environments (IDEs) has led to their speedy adoption.\nConversational interactions with LLMs enable programmers to obtain natural\nlanguage explanations for various software development tasks. However, LLMs\noften leap to action without sufficient context, giving rise to implicit\nassumptions and inaccurate responses. Conversations between developers and LLMs\nare primarily structured as question-answer pairs, where the developer is\nresponsible for asking the the right questions and sustaining conversations\nacross multiple turns. In this paper, we draw inspiration from interaction\npatterns and conversation analysis -- to design Robin, an enhanced\nconversational AI-assistant for debugging. Through a within-subjects user study\nwith 12 industry professionals, we find that equipping the LLM to -- (1)\nleverage the insert expansion interaction pattern, (2) facilitate turn-taking,\nand (3) utilize debugging workflows -- leads to lowered conversation barriers,\neffective fault localization, and 5x improvement in bug resolution rates.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在集成开发环境（IDEs）中用于调试的对话交互问题，指出现有系统常因缺乏足够上下文而导致假设错误和响应不准确，并依赖开发者维持问答对话。研究设计了 Robin，一种增强的对话 AI 助手，通过整合 insert expansion 交互模式、turn-taking 轮流对话机制以及 debugging workflows 调试工作流，来降低对话障碍并提升调试效率。在一项涉及 12 名行业专业人士的内部用户研究中，Robin 显著提高了故障定位准确性和错误解决率，实现了 5 倍的 bug resolution 改进。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "7 pages, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.06229v1",
      "published_date": "2024-02-09 07:44:27 UTC",
      "updated_date": "2024-02-09 07:44:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:02:05.936268"
    },
    {
      "arxiv_id": "2402.06204v1",
      "title": "The Generative AI Paradox on Evaluation: What It Can Solve, It May Not Evaluate",
      "title_zh": "翻译失败",
      "authors": [
        "Juhyun Oh",
        "Eunsu Kim",
        "Inha Cha",
        "Alice Oh"
      ],
      "abstract": "This paper explores the assumption that Large Language Models (LLMs) skilled\nin generation tasks are equally adept as evaluators. We assess the performance\nof three LLMs and one open-source LM in Question-Answering (QA) and evaluation\ntasks using the TriviaQA (Joshi et al., 2017) dataset. Results indicate a\nsignificant disparity, with LLMs exhibiting lower performance in evaluation\ntasks compared to generation tasks. Intriguingly, we discover instances of\nunfaithful evaluation where models accurately evaluate answers in areas where\nthey lack competence, underscoring the need to examine the faithfulness and\ntrustworthiness of LLMs as evaluators. This study contributes to the\nunderstanding of \"the Generative AI Paradox\" (West et al., 2023), highlighting\na need to explore the correlation between generative excellence and evaluation\nproficiency, and the necessity to scrutinize the faithfulness aspect in model\nevaluations.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在生成任务上表现出色，但作为评估者的能力可能不足的现象，称为“Generative AI Paradox”。使用 TriviaQA 数据集，作者评估了三个 LLMs 和一个开源 LM 在 Question-Answering (QA) 和评估任务中的表现，结果显示 LLMs 在评估任务上的性能显著低于生成任务，并存在不忠实的评估情况，即模型在自身不擅长的领域仍能准确评估答案。该研究强调了生成能力和评估能力之间缺乏相关性，并呼吁进一步审视 LLMs 评估的忠实性和可信度，以提升模型评估的可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06204v1",
      "published_date": "2024-02-09 06:16:08 UTC",
      "updated_date": "2024-02-09 06:16:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:02:18.311608"
    },
    {
      "arxiv_id": "2402.06196v3",
      "title": "Large Language Models: A Survey",
      "title_zh": "大语言模型：综述",
      "authors": [
        "Shervin Minaee",
        "Tomas Mikolov",
        "Narjes Nikzad",
        "Meysam Chenaghlu",
        "Richard Socher",
        "Xavier Amatriain",
        "Jianfeng Gao"
      ],
      "abstract": "Large Language Models (LLMs) have drawn a lot of attention due to their\nstrong performance on a wide range of natural language tasks, since the release\nof ChatGPT in November 2022. LLMs' ability of general-purpose language\nunderstanding and generation is acquired by training billions of model's\nparameters on massive amounts of text data, as predicted by scaling laws\n\\cite{kaplan2020scaling,hoffmann2022training}. The research area of LLMs, while\nvery recent, is evolving rapidly in many different ways. In this paper, we\nreview some of the most prominent LLMs, including three popular LLM families\n(GPT, LLaMA, PaLM), and discuss their characteristics, contributions and\nlimitations. We also give an overview of techniques developed to build, and\naugment LLMs. We then survey popular datasets prepared for LLM training,\nfine-tuning, and evaluation, review widely used LLM evaluation metrics, and\ncompare the performance of several popular LLMs on a set of representative\nbenchmarks. Finally, we conclude the paper by discussing open challenges and\nfuture research directions.",
      "tldr_zh": "这篇论文对大型语言模型 (LLMs) 进行了全面调查，回顾了其快速发展，特别是自 ChatGPT 发布以来在自然语言任务中的强大性能，以及通过在海量文本数据上训练数十亿参数来实现的通用语言理解和生成能力。作者讨论了几个主要 LLM 家族（如 GPT、LLaMA 和 PaLM）的特性、贡献和局限性，并概述了构建和增强 LLMs 的关键技术。论文还审阅了用于 LLM 训练、微调和评估的流行数据集、评估指标，并比较了这些模型在代表性基准上的性能表现。最后，论文指出了 LLMs 面临的开放挑战和未来研究方向，例如进一步优化和扩展应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06196v3",
      "published_date": "2024-02-09 05:37:09 UTC",
      "updated_date": "2025-03-23 14:51:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:02:31.821955"
    },
    {
      "arxiv_id": "2402.06188v2",
      "title": "A self-supervised framework for learning whole slide representations",
      "title_zh": "翻译失败",
      "authors": [
        "Xinhai Hou",
        "Cheng Jiang",
        "Akhil Kondepudi",
        "Yiwei Lyu",
        "Asadur Chowdury",
        "Honglak Lee",
        "Todd C. Hollon"
      ],
      "abstract": "Whole slide imaging is fundamental to biomedical microscopy and computational\npathology. Previously, learning representations for gigapixel-sized whole slide\nimages (WSIs) has relied on multiple instance learning with weak labels, which\ndo not annotate the diverse morphologic features and spatial heterogeneity of\nWSIs. A high-quality self-supervised learning method for WSIs would provide\ntransferable visual representations for downstream computational pathology\ntasks, without the need for dense annotations. We present Slide Pre-trained\nTransformers (SPT) for gigapixel-scale self-supervision of WSIs. Treating WSI\npatches as tokens, SPT combines data transformation strategies from language\nand vision modeling into a general and unified framework to generate views of\nWSIs for self-supervised pretraining. SPT leverages the inherent regional\nheterogeneity, histologic feature variability, and information redundancy\nwithin WSIs to learn high-quality whole slide representations. We benchmark SPT\nvisual representations on five diagnostic tasks across three biomedical\nmicroscopy datasets. SPT significantly outperforms baselines for\nhistopathologic diagnosis, cancer subtyping, and genetic mutation prediction.\nFinally, we demonstrate that SPT consistently improves whole slide\nrepresentations when using off-the-shelf, in-domain, and foundational patch\nencoders for whole slide multiple instance learning.",
      "tldr_zh": "本研究提出了一种自监督框架 Slide Pre-trained Transformers (SPT)，用于学习 Whole Slide Images (WSIs) 的表示，从而避免依赖弱标签的多实例学习 (Multiple Instance Learning)，并捕捉WSIs的多样形态特征和空间异质性。SPT 将WSI补丁视为 tokens，结合语言和视觉建模的数据转换策略进行自监督预训练，利用WSIs的区域异质性、直视学特征变异性和信息冗余来生成高质量的视觉表示。实验在三个生物医学显微镜数据集上的五个诊断任务中验证了SPT的表现，包括组织病理学诊断、癌症亚型和遗传突变预测，SPT显著优于基线模型。最后，SPT可与现成的补丁编码器结合，进一步提升Whole Slide多实例学习的整体效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "26 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.06188v2",
      "published_date": "2024-02-09 05:05:28 UTC",
      "updated_date": "2024-05-23 19:23:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:02:43.910593"
    },
    {
      "arxiv_id": "2402.06187v4",
      "title": "Premier-TACO is a Few-Shot Policy Learner: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss",
      "title_zh": "Premier-TACO 是一个少样本策略学习器：通过时间动作驱动的",
      "authors": [
        "Ruijie Zheng",
        "Yongyuan Liang",
        "Xiyao Wang",
        "Shuang Ma",
        "Hal Daumé III",
        "Huazhe Xu",
        "John Langford",
        "Praveen Palanisamy",
        "Kalyan Shankar Basu",
        "Furong Huang"
      ],
      "abstract": "We present Premier-TACO, a multitask feature representation learning approach\ndesigned to improve few-shot policy learning efficiency in sequential\ndecision-making tasks. Premier-TACO leverages a subset of multitask offline\ndatasets for pretraining a general feature representation, which captures\ncritical environmental dynamics and is fine-tuned using minimal expert\ndemonstrations. It advances the temporal action contrastive learning (TACO)\nobjective, known for state-of-the-art results in visual control tasks, by\nincorporating a novel negative example sampling strategy. This strategy is\ncrucial in significantly boosting TACO's computational efficiency, making\nlarge-scale multitask offline pretraining feasible. Our extensive empirical\nevaluation in a diverse set of continuous control benchmarks including Deepmind\nControl Suite, MetaWorld, and LIBERO demonstrate Premier-TACO's effectiveness\nin pretraining visual representations, significantly enhancing few-shot\nimitation learning of novel tasks. Our code, pretraining data, as well as\npretrained model checkpoints will be released at\nhttps://github.com/PremierTACO/premier-taco. Our project webpage is at\nhttps://premiertaco.github.io.",
      "tldr_zh": "我们介绍了 Premier-TACO，一种通过 Temporal Action-Driven Contrastive Loss 预训练多任务特征表示的方法，旨在提升少样本策略学习（Few-Shot Policy Learner）的效率。该方法基于 temporal action contrastive learning (TACO) 目标，引入了创新的负例采样策略，提高计算效率，并利用多任务离线数据集预训练特征以捕捉环境动态。实验结果显示，在 Deepmind Control Suite、MetaWorld 和 LIBERO 等连续控制基准上，Premier-TACO 显著提升了视觉表示和少样本模仿学习的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Forty-first International Conference on Machine Learning\n  (ICML 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.06187v4",
      "published_date": "2024-02-09 05:04:40 UTC",
      "updated_date": "2024-05-23 21:41:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:02:52.982723"
    },
    {
      "arxiv_id": "2402.06185v1",
      "title": "Development and validation of an artificial intelligence model to accurately predict spinopelvic parameters",
      "title_zh": "翻译失败",
      "authors": [
        "Edward S. Harake",
        "Joseph R. Linzey",
        "Cheng Jiang",
        "Rushikesh S. Joshi",
        "Mark M. Zaki",
        "Jaes C. Jones",
        "Siri S. Khalsa",
        "John H. Lee",
        "Zachary Wilseck",
        "Jacob R. Joseph",
        "Todd C. Hollon",
        "Paul Park"
      ],
      "abstract": "Objective. Achieving appropriate spinopelvic alignment has been shown to be\nassociated with improved clinical symptoms. However, measurement of spinopelvic\nradiographic parameters is time-intensive and interobserver reliability is a\nconcern. Automated measurement tools have the promise of rapid and consistent\nmeasurements, but existing tools are still limited by some degree of manual\nuser-entry requirements. This study presents a novel artificial intelligence\n(AI) tool called SpinePose that automatically predicts spinopelvic parameters\nwith high accuracy without the need for manual entry.\n  Methods. SpinePose was trained and validated on 761 sagittal whole-spine\nX-rays to predict sagittal vertical axis (SVA), pelvic tilt (PT), pelvic\nincidence (PI), sacral slope (SS), lumbar lordosis (LL), T1-pelvic angle\n(T1PA), and L1-pelvic angle (L1PA). A separate test set of 40 X-rays was\nlabeled by 4 reviewers, including fellowship-trained spine surgeons and a\nfellowship-trained radiologist with neuroradiology subspecialty certification.\nMedian errors relative to the most senior reviewer were calculated to determine\nmodel accuracy on test images. Intraclass correlation coefficients (ICC) were\nused to assess inter-rater reliability.\n  Results. SpinePose exhibited the following median (interquartile range)\nparameter errors: SVA: 2.2(2.3)mm, p=0.93; PT: 1.3(1.2){\\deg}, p=0.48; SS:\n1.7(2.2){\\deg}, p=0.64; PI: 2.2(2.1){\\deg}, p=0.24; LL: 2.6(4.0){\\deg}, p=0.89;\nT1PA: 1.1(0.9){\\deg}, p=0.42; and L1PA: 1.4(1.6){\\deg}, p=0.49. Model\npredictions also exhibited excellent reliability at all parameters (ICC:\n0.91-1.0).\n  Conclusions. SpinePose accurately predicted spinopelvic parameters with\nexcellent reliability comparable to fellowship-trained spine surgeons and\nneuroradiologists. Utilization of predictive AI tools in spinal imaging can\nsubstantially aid in patient selection and surgical planning.",
      "tldr_zh": "本研究开发并验证了一个名为 SpinePose 的 artificial intelligence (AI) 模型，旨在自动预测 spinopelvic parameters，以解决传统测量耗时长和观察者间可靠性差的问题。模型使用 761 张矢状位全脊柱 X 光片进行训练和验证，能准确预测参数如 sagittal vertical axis (SVA)、pelvic tilt (PT)、pelvic incidence (PI)、sacral slope (SS)、lumbar lordosis (LL)、T1-pelvic angle (T1PA) 和 L1-pelvic angle (L1PA)，无需手动输入。测试结果显示，模型的预测误差很小（如 SVA 为 2.2 mm），并表现出极高的可靠性（intraclass correlation coefficients (ICC) 为 0.91-1.0），其性能与资深脊柱外科医生和神经放射学家相当，可显著辅助患者选择和手术规划。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 5 figures, to appear in Journal of Neurosurgery: Spine",
      "pdf_url": "http://arxiv.org/pdf/2402.06185v1",
      "published_date": "2024-02-09 04:47:26 UTC",
      "updated_date": "2024-02-09 04:47:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:03:06.165803"
    },
    {
      "arxiv_id": "2402.06178v3",
      "title": "MusicMagus: Zero-Shot Text-to-Music Editing via Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yixiao Zhang",
        "Yukara Ikemiya",
        "Gus Xia",
        "Naoki Murata",
        "Marco A. Martínez-Ramírez",
        "Wei-Hsiang Liao",
        "Yuki Mitsufuji",
        "Simon Dixon"
      ],
      "abstract": "Recent advances in text-to-music generation models have opened new avenues in\nmusical creativity. However, music generation usually involves iterative\nrefinements, and how to edit the generated music remains a significant\nchallenge. This paper introduces a novel approach to the editing of music\ngenerated by such models, enabling the modification of specific attributes,\nsuch as genre, mood and instrument, while maintaining other aspects unchanged.\nOur method transforms text editing to \\textit{latent space manipulation} while\nadding an extra constraint to enforce consistency. It seamlessly integrates\nwith existing pretrained text-to-music diffusion models without requiring\nadditional training. Experimental results demonstrate superior performance over\nboth zero-shot and certain supervised baselines in style and timbre transfer\nevaluations. Additionally, we showcase the practical applicability of our\napproach in real-world music editing scenarios.",
      "tldr_zh": "本论文提出 MusicMagus，一种零样本（Zero-Shot）文本到音乐编辑方法，基于扩散模型（Diffusion Models），允许用户修改音乐的特定属性如流派、心情和乐器，同时保持其他方面不变。方法通过将文本编辑转化为潜在空间操作（Latent Space Manipulation）并添加一致性约束，与现有预训练文本到音乐模型无缝集成，无需额外训练。实验结果显示，MusicMagus 在风格和音色转移评估中优于零样本和某些监督基线，并在实际音乐编辑场景中展现出实际应用潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.06178v3",
      "published_date": "2024-02-09 04:34:08 UTC",
      "updated_date": "2024-05-28 16:47:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:03:17.626974"
    },
    {
      "arxiv_id": "2402.10946v3",
      "title": "CultureLLM: Incorporating Cultural Differences into Large Language Models",
      "title_zh": "CultureLLM：将文化差异融入大型语言模型",
      "authors": [
        "Cheng Li",
        "Mengzhou Chen",
        "Jindong Wang",
        "Sunayana Sitaram",
        "Xing Xie"
      ],
      "abstract": "Large language models (LLMs) are reported to be partial to certain cultures\nowing to the training data dominance from the English corpora. Since\nmultilingual cultural data are often expensive to collect, existing efforts\nhandle this by prompt engineering or culture-specific pre-training. However,\nthey might overlook the knowledge deficiency of low-resource culture and\nrequire extensive computing resources. In this paper, we propose CultureLLM, a\ncost-effective solution to incorporate cultural differences into LLMs.\nCultureLLM adopts World Value Survey (WVS) as seed data and generates\nsemantically equivalent training data via the proposed semantic data\naugmentation. Using only 50 seed samples from WVS with augmented data, we\nfine-tune culture-specific LLMs and one unified model (CultureLLM-One) for 9\ncultures covering rich and low-resource languages. Extensive experiments on 60\nculture-related datasets demonstrate that CultureLLM significantly outperforms\nvarious counterparts such as GPT-3.5 (by 8.1%) and Gemini Pro (by 9.5%) with\ncomparable performance to GPT-4 or even better. Our human study shows that the\ngenerated samples are semantically equivalent to the original samples,\nproviding an effective solution for LLMs augmentation. Code is released at\nhttps://github.com/Scarelette/CultureLLM.",
      "tldr_zh": "该研究提出CultureLLM，一种成本有效的框架，用于将文化差异融入Large Language Models (LLMs)，以解决LLMs因英语语料主导而偏向特定文化的偏见问题。方法采用World Value Survey (WVS)作为种子数据，通过语义数据增强技术生成等价训练数据，并使用仅50个种子样本微调文化特定LLMs和一个统一模型（CultureLLM-One），覆盖9个文化包括低资源语言。实验结果显示，在60个文化相关数据集上，CultureLLM比GPT-3.5提升8.1%、比Gemini Pro提升9.5%，性能可媲美或优于GPT-4，且人类评估证实生成的样本语义等价于原样本。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024; Code is at https://github.com/Scarelette/CultureLLM",
      "pdf_url": "http://arxiv.org/pdf/2402.10946v3",
      "published_date": "2024-02-09 04:02:43 UTC",
      "updated_date": "2024-12-03 06:52:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:03:30.686539"
    },
    {
      "arxiv_id": "2402.06165v6",
      "title": "Learning Contrastive Feature Representations for Facial Action Unit Detection",
      "title_zh": "面部动作单元检测的对比特征表示学习",
      "authors": [
        "Ziqiao Shang",
        "Bin Liu",
        "Fengmao Lv",
        "Fei Teng",
        "Tianrui Li"
      ],
      "abstract": "For the Facial Action Unit (AU) detection task, accurately capturing the\nsubtle facial differences between distinct AUs is essential for reliable\ndetection. Additionally, AU detection faces challenges from class imbalance and\nthe presence of noisy or false labels, which undermine detection accuracy. In\nthis paper, we introduce a novel contrastive learning framework aimed for AU\ndetection that incorporates both self-supervised and supervised signals,\nthereby enhancing the learning of discriminative features for accurate AU\ndetection. To tackle the class imbalance issue, we employ a negative sample\nre-weighting strategy that adjusts the step size of updating parameters for\nminority and majority class samples. Moreover, to address the challenges posed\nby noisy and false AU labels, we employ a sampling technique that encompasses\nthree distinct types of positive sample pairs. This enables us to inject\nself-supervised signals into the supervised signal, effectively mitigating the\nadverse effects of noisy labels. Our experimental assessments, conducted on\nfive widely-utilized benchmark datasets (BP4D, DISFA, BP4D+, GFT and\nAff-Wild2), underscore the superior performance of our approach compared to\nstate-of-the-art methods of AU detection.",
      "tldr_zh": "本文提出了一种新的对比学习框架，用于Facial Action Unit (AU) 检测，通过结合自监督和监督信号来增强判别特征的学习，从而更好地捕捉面部微妙差异。针对类别不平衡问题，该框架采用负样本再加权策略调整参数更新步长；为应对噪声标签，该方法引入三种正样本对的采样技术，以注入自监督信号减轻其负面影响。在BP4D、DISFA、BP4D+、GFT和Aff-Wild2五个基准数据集上的实验表明，该方法在AU检测性能上优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "35 pages, 20 figures, submitted to Pattern Recognition (PR)",
      "pdf_url": "http://arxiv.org/pdf/2402.06165v6",
      "published_date": "2024-02-09 03:48:20 UTC",
      "updated_date": "2025-01-23 04:58:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:03:41.441754"
    },
    {
      "arxiv_id": "2402.06158v1",
      "title": "Assortment Planning with Sponsored Products",
      "title_zh": "翻译失败",
      "authors": [
        "Shaojie Tang",
        "Shuzhang Cai",
        "Jing Yuan",
        "Kai Han"
      ],
      "abstract": "In the rapidly evolving landscape of retail, assortment planning plays a\ncrucial role in determining the success of a business. With the rise of\nsponsored products and their increasing prominence in online marketplaces,\nretailers face new challenges in effectively managing their product assortment\nin the presence of sponsored products. Remarkably, previous research in\nassortment planning largely overlooks the existence of sponsored products and\ntheir potential impact on overall recommendation effectiveness. Instead, they\ncommonly make the simplifying assumption that all products are either organic\nor non-sponsored. This research gap underscores the necessity for a more\nthorough investigation of the assortment planning challenge when sponsored\nproducts are in play. We formulate the assortment planning problem in the\npresence of sponsored products as a combinatorial optimization task. The\nultimate objective is to compute an assortment plan that optimizes expected\nrevenue while considering the specific requirements of placing sponsored\nproducts strategically.",
      "tldr_zh": "本论文探讨了零售环境中商品组合规划（assortment planning）面临的挑战，特别是当赞助产品（sponsored products）在在线市场中日益突出时。现有研究通常忽略赞助产品的存在和影响，将所有产品简单视为有机或非赞助，从而存在研究空白。论文将此问题表述为一个组合优化任务（combinatorial optimization task），目标是通过战略性放置赞助产品来优化预期收入。",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.DS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06158v1",
      "published_date": "2024-02-09 03:18:44 UTC",
      "updated_date": "2024-02-09 03:18:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:03:52.419357"
    },
    {
      "arxiv_id": "2402.07945v1",
      "title": "ScreenAgent: A Vision Language Model-driven Computer Control Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Runliang Niu",
        "Jindong Li",
        "Shiqi Wang",
        "Yali Fu",
        "Xiyu Hu",
        "Xueyuan Leng",
        "He Kong",
        "Yi Chang",
        "Qi Wang"
      ],
      "abstract": "Existing Large Language Models (LLM) can invoke a variety of tools and APIs\nto complete complex tasks. The computer, as the most powerful and universal\ntool, could potentially be controlled directly by a trained LLM agent. Powered\nby the computer, we can hopefully build a more generalized agent to assist\nhumans in various daily digital works. In this paper, we construct an\nenvironment for a Vision Language Model (VLM) agent to interact with a real\ncomputer screen. Within this environment, the agent can observe screenshots and\nmanipulate the Graphics User Interface (GUI) by outputting mouse and keyboard\nactions. We also design an automated control pipeline that includes planning,\nacting, and reflecting phases, guiding the agent to continuously interact with\nthe environment and complete multi-step tasks. Additionally, we construct the\nScreenAgent Dataset, which collects screenshots and action sequences when\ncompleting a variety of daily computer tasks. Finally, we trained a model,\nScreenAgent, which achieved computer control capabilities comparable to GPT-4V\nand demonstrated more precise UI positioning capabilities. Our attempts could\ninspire further research on building a generalist LLM agent. The code is\navailable at \\url{https://github.com/niuzaisheng/ScreenAgent}.",
      "tldr_zh": "本论文提出ScreenAgent，一种由Vision Language Model (VLM)驱动的计算机控制代理，旨在让代理直接观察屏幕截图并通过鼠标和键盘动作操作Graphics User Interface (GUI)，从而辅助人类完成各种日常数字任务。该框架设计了一个自动化控制管道，包括规划、行动和反思阶段，以引导代理处理多步任务，并构建了ScreenAgent数据集，包含屏幕截图和动作序列用于训练。实验结果显示，ScreenAgent的性能与GPT-4V相当，并表现出更精确的UI定位能力，为开发通用Large Language Models (LLM)代理提供了重要启发。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07945v1",
      "published_date": "2024-02-09 02:33:45 UTC",
      "updated_date": "2024-02-09 02:33:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:04:06.896610"
    },
    {
      "arxiv_id": "2402.06697v1",
      "title": "Feed-Forward Neural Networks as a Mixed-Integer Program",
      "title_zh": "翻译失败",
      "authors": [
        "Navid Aftabi",
        "Nima Moradi",
        "Fatemeh Mahroo"
      ],
      "abstract": "Deep neural networks (DNNs) are widely studied in various applications. A DNN\nconsists of layers of neurons that compute affine combinations, apply nonlinear\noperations, and produce corresponding activations. The rectified linear unit\n(ReLU) is a typical nonlinear operator, outputting the max of its input and\nzero. In scenarios like max pooling, where multiple input values are involved,\na fixed-parameter DNN can be modeled as a mixed-integer program (MIP). This\nformulation, with continuous variables representing unit outputs and binary\nvariables for ReLU activation, finds applications across diverse domains. This\nstudy explores the formulation of trained ReLU neurons as MIP and applies MIP\nmodels for training neural networks (NNs). Specifically, it investigates\ninteractions between MIP techniques and various NN architectures, including\nbinary DNNs (employing step activation functions) and binarized DNNs (with\nweights and activations limited to $-1,0,+1$). The research focuses on training\nand evaluating proposed approaches through experiments on handwritten digit\nclassification models. The comparative study assesses the performance of\ntrained ReLU NNs, shedding light on the effectiveness of MIP formulations in\nenhancing training processes for NNs.",
      "tldr_zh": "本文将前馈神经网络（DNNs）表述为混合整数规划（MIP），通过使用连续变量表示单元输出和二进制变量处理ReLU激活函数，来探索MIP在训练神经网络中的应用，包括二进制DNNs（使用阶跃激活函数）和二值化DNNs（权重和激活限于-1、0、+1）。研究重点调查了MIP技术与不同NN架构的交互，并通过手写数字分类实验评估了这些方法的性能。结果显示，这种MIP公式化有助于提升ReLU NNs的训练效果，提供了一种新的优化神经网络训练过程的途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06697v1",
      "published_date": "2024-02-09 02:23:37 UTC",
      "updated_date": "2024-02-09 02:23:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:04:18.312261"
    },
    {
      "arxiv_id": "2402.09465v1",
      "title": "RLEEGNet: Integrating Brain-Computer Interfaces with Adaptive AI for Intuitive Responsiveness and High-Accuracy Motor Imagery Classification",
      "title_zh": "RLEEGNet：整合脑机接口与自适应AI以实现直观响应和高精度运动想象分类",
      "authors": [
        "Sriram V. C. Nallani",
        "Gautham Ramachandran"
      ],
      "abstract": "Current approaches to prosthetic control are limited by their reliance on\ntraditional methods, which lack real-time adaptability and intuitive\nresponsiveness. These limitations are particularly pronounced in assistive\ntechnologies designed for individuals with diverse cognitive states and motor\nintentions. In this paper, we introduce a framework that leverages\nReinforcement Learning (RL) with Deep Q-Networks (DQN) for classification\ntasks. Additionally, we present a preprocessing technique using the Common\nSpatial Pattern (CSP) for multiclass motor imagery (MI) classification in a\nOne-Versus-The-Rest (OVR) manner. The subsequent 'csp space' transformation\nretains the temporal dimension of EEG signals, crucial for extracting\ndiscriminative features. The integration of DQN with a 1D-CNN-LSTM architecture\noptimizes the decision-making process in real-time, thereby enhancing the\nsystem's adaptability to the user's evolving needs and intentions. We elaborate\non the data processing methods for two EEG motor imagery datasets. Our\ninnovative model, RLEEGNet, incorporates a 1D-CNN-LSTM architecture as the\nOnline Q-Network within the DQN, facilitating continuous adaptation and\noptimization of control strategies through feedback. This mechanism allows the\nsystem to learn optimal actions through trial and error, progressively\nimproving its performance. RLEEGNet demonstrates high accuracy in classifying\nMI-EEG signals, achieving as high as 100% accuracy in MI tasks across both the\nGigaScience (3-class) and BCI-IV-2a (4-class) datasets. These results highlight\nthe potential of combining DQN with a 1D-CNN-LSTM architecture to significantly\nenhance the adaptability and responsiveness of BCI systems.",
      "tldr_zh": "该论文提出 RLEEGNet 框架，将 Reinforcement Learning (RL) 中的 Deep Q-Networks (DQN) 与 1D-CNN-LSTM 架构整合，用于脑机接口（BCI）的运动想象（MI）分类，旨在解决传统方法的实时适应性和直观响应性不足问题。\n框架采用 Common Spatial Pattern (CSP) 预处理技术进行多类 MI 分类（One-Versus-The-Rest, OVR），保留 EEG 信号的时序维度，并通过反馈机制实现连续优化决策。\n实验结果显示，RLEEGNet 在 GigaScience (3-class) 和 BCI-IV-2a (4-class) 数据集上达到高达 100% 的准确率，显著提升了 BCI 系统的适应性和响应性，为辅助技术应用提供了新途径。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "68T05"
      ],
      "primary_category": "eess.SP",
      "comment": "23 pages, 1 figure, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.09465v1",
      "published_date": "2024-02-09 02:03:13 UTC",
      "updated_date": "2024-02-09 02:03:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:04:33.060895"
    },
    {
      "arxiv_id": "2402.06128v1",
      "title": "Rethinking Node-wise Propagation for Large-scale Graph Learning",
      "title_zh": "重新审视大规模图学习中的节点-wise 传播",
      "authors": [
        "Xunkai Li",
        "Jingyuan Ma",
        "Zhengyu Wu",
        "Daohan Su",
        "Wentao Zhang",
        "Rong-Hua Li",
        "Guoren Wang"
      ],
      "abstract": "Scalable graph neural networks (GNNs) have emerged as a promising technique,\nwhich exhibits superior predictive performance and high running efficiency\nacross numerous large-scale graph-based web applications. However, (i) Most\nscalable GNNs tend to treat all nodes in graphs with the same propagation\nrules, neglecting their topological uniqueness; (ii) Existing node-wise\npropagation optimization strategies are insufficient on web-scale graphs with\nintricate topology, where a full portrayal of nodes' local properties is\nrequired. Intuitively, different nodes in web-scale graphs possess distinct\ntopological roles, and therefore propagating them indiscriminately or neglect\nlocal contexts may compromise the quality of node representations. This\nintricate topology in web-scale graphs cannot be matched by small-scale\nscenarios. To address the above issues, we propose \\textbf{A}daptive\n\\textbf{T}opology-aware \\textbf{P}ropagation (ATP), which reduces potential\nhigh-bias propagation and extracts structural patterns of each node in a\nscalable manner to improve running efficiency and predictive performance.\nRemarkably, ATP is crafted to be a plug-and-play node-wise propagation\noptimization strategy, allowing for offline execution independent of the graph\nlearning process in a new perspective. Therefore, this approach can be\nseamlessly integrated into most scalable GNNs while remain orthogonal to\nexisting node-wise propagation optimization strategies. Extensive experiments\non 12 datasets, including the most representative large-scale ogbn-papers100M,\nhave demonstrated the effectiveness of ATP. Specifically, ATP has proven to be\nefficient in improving the performance of prevalent scalable GNNs for\nsemi-supervised node classification while addressing redundant computational\ncosts.",
      "tldr_zh": "该论文重新审视了节点-wise 传播在大型图学习中的问题，指出现有可扩展 Graph Neural Networks (GNNs) 忽略了节点的拓扑独特性，导致在复杂 web-scale 图上表现不足。研究者提出 Adaptive Topology-aware Propagation (ATP)，一种自适应拓扑感知传播策略，能够减少传播偏差并以可扩展方式提取节点的结构模式，从而提升预测性能和运行效率。ATP 设计为即插即用的优化策略，可离线执行并与大多数可扩展 GNNs 无缝集成。实验在 12 个数据集上，包括大型 ogbn-papers100M，证明 ATP 显著提高了半监督节点分类的准确性，同时降低了计算成本。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by WWW 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.06128v1",
      "published_date": "2024-02-09 01:19:47 UTC",
      "updated_date": "2024-02-09 01:19:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:04:43.575008"
    },
    {
      "arxiv_id": "2402.06126v4",
      "title": "Learn To be Efficient: Build Structured Sparsity in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haizhong Zheng",
        "Xiaoyan Bai",
        "Xueshen Liu",
        "Z. Morley Mao",
        "Beidi Chen",
        "Fan Lai",
        "Atul Prakash"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable success with their\nbillion-level parameters, yet they incur high inference overheads. The\nemergence of activation sparsity in LLMs provides a natural approach to reduce\nthis cost by involving only parts of the parameters for inference. However,\nexisting methods only focus on utilizing this naturally formed activation\nsparsity in a post-training setting, overlooking the potential for further\namplifying this inherent sparsity. In this paper, we hypothesize that LLMs can\nlearn to be efficient by achieving more structured activation sparsity. To\nachieve this, we introduce a novel training algorithm, Learn-To-be-Efficient\n(LTE), designed to train efficiency-aware LLMs to learn to activate fewer\nneurons and achieve a better trade-off between sparsity and performance.\nFurthermore, unlike SOTA MoEfication methods, which mainly focus on ReLU-based\nmodels, LTE can also be applied to LLMs like LLaMA using non-ReLU activations.\nExtensive evaluation on language understanding, language generation, and\ninstruction tuning tasks show that LTE consistently outperforms SOTA baselines.\nAlong with our hardware-aware custom kernel implementation, LTE reduces\nLLaMA2-7B inference latency by 25% at 50% sparsity.",
      "tldr_zh": "本文提出，Large Language Models (LLMs) 虽然强大但推断开销高，因此假设通过训练实现更结构化的激活稀疏性来提升效率。作者引入 Learn-To-be-Efficient (LTE) 算法，训练 LLMs 激活更少的神经元，并在稀疏性和性能之间取得更好平衡，且适用于非 ReLU 激活模型如 LLaMA。实验结果显示，LTE 在语言理解、生成和指令微调任务上优于现有基线，并通过硬件感知的自定义内核，将 LLaMA2-7B 在 50% 稀疏度下的推断延迟减少 25%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06126v4",
      "published_date": "2024-02-09 01:18:16 UTC",
      "updated_date": "2024-12-12 05:28:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:04:55.830051"
    },
    {
      "arxiv_id": "2402.06118v3",
      "title": "ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Siming Yan",
        "Min Bai",
        "Weifeng Chen",
        "Xiong Zhou",
        "Qixing Huang",
        "Li Erran Li"
      ],
      "abstract": "By combining natural language understanding, generation capabilities, and\nbreadth of knowledge of large language models with image perception, recent\nlarge vision language models (LVLMs) have shown unprecedented visual reasoning\ncapabilities. However, the generated text often suffers from inaccurate\ngrounding in the visual input, resulting in errors such as hallucination of\nnonexistent scene elements, missing significant parts of the scene, and\ninferring incorrect attributes of and relationships between objects. To address\nthese issues, we introduce a novel framework, ViGoR (Visual Grounding Through\nFine-Grained Reward Modeling) that utilizes fine-grained reward modeling to\nsignificantly enhance the visual grounding of LVLMs over pre-trained baselines.\nThis improvement is efficiently achieved using much cheaper human evaluations\ninstead of full supervisions, as well as automated methods. We show the\neffectiveness of our approach through a variety of evaluation methods and\nbenchmarks. Additionally, we released our human annotation\n(https://github.com/amazon-science/vigor) comprising 15,440 images and\ngenerated text pairs with fine-grained evaluations to contribute to related\nresearch in the community.",
      "tldr_zh": "该研究发现大型视觉语言模型 (LVLMs) 在视觉 grounding 方面存在问题，如生成文本的幻觉、遗漏场景元素或错误对象属性和关系。针对这些问题，提出 ViGoR 框架，通过 fine-grained reward modeling 利用更高效的人类评估和自动化方法显著提升 LVLMs 的视觉 grounding 能力。实验结果显示该框架在多种基准上表现出色，并发布了包含 15,440 个图像和生成文本对的人类标注数据集，以支持社区相关研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.06118v3",
      "published_date": "2024-02-09 01:00:14 UTC",
      "updated_date": "2024-10-13 14:06:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:05:05.443434"
    },
    {
      "arxiv_id": "2402.06116v1",
      "title": "LLMs for Coding and Robotics Education",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Shu",
        "Huaqin Zhao",
        "Hanqi Jiang",
        "Yiwei Li",
        "Shaochen Xu",
        "Yi Pan",
        "Zihao Wu",
        "Zhengliang Liu",
        "Guoyu Lu",
        "Le Guan",
        "Gong Chen",
        "Xianqiao Wang Tianming Liu"
      ],
      "abstract": "Large language models and multimodal large language models have\nrevolutionized artificial intelligence recently. An increasing number of\nregions are now embracing these advanced technologies. Within this context,\nrobot coding education is garnering increasing attention. To teach young\nchildren how to code and compete in robot challenges, large language models are\nbeing utilized for robot code explanation, generation, and modification. In\nthis paper, we highlight an important trend in robot coding education. We test\nseveral mainstream large language models on both traditional coding tasks and\nthe more challenging task of robot code generation, which includes block\ndiagrams. Our results show that GPT-4V outperforms other models in all of our\ntests but struggles with generating block diagram images.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）和多模态大型语言模型在机器人编程教育中的应用，强调其用于解释、生成和修改机器人代码，以帮助儿童学习编码和参与机器人挑战。研究测试了多种主流LLMs在传统编码任务和更复杂的机器人代码生成任务（包括块状图）上的性能。结果表明，GPT-4V在所有测试中表现出色，但仍存在生成块状图图像的困难，从而突显了LLMs在教育领域的潜力与局限性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "20 pages, 6 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2402.06116v1",
      "published_date": "2024-02-09 00:58:57 UTC",
      "updated_date": "2024-02-09 00:58:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:05:17.083660"
    },
    {
      "arxiv_id": "2402.06696v1",
      "title": "FL-NAS: Towards Fairness of NAS for Resource Constrained Devices via Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiyang Qin",
        "Yuting Hu",
        "Zheyu Yan",
        "Jinjun Xiong",
        "Ahmed Abbasi",
        "Yiyu Shi"
      ],
      "abstract": "Neural Architecture Search (NAS) has become the de fecto tools in the\nindustry in automating the design of deep neural networks for various\napplications, especially those driven by mobile and edge devices with limited\ncomputing resources. The emerging large language models (LLMs), due to their\nprowess, have also been incorporated into NAS recently and show some promising\nresults. This paper conducts further exploration in this direction by\nconsidering three important design metrics simultaneously, i.e., model\naccuracy, fairness, and hardware deployment efficiency. We propose a novel\nLLM-based NAS framework, FL-NAS, in this paper, and show experimentally that\nFL-NAS can indeed find high-performing DNNs, beating state-of-the-art DNN\nmodels by orders-of-magnitude across almost all design considerations.",
      "tldr_zh": "本论文探讨了 Neural Architecture Search (NAS) 在资源受限设备上的应用，强调同时优化模型准确性、公平性和硬件部署效率。作者提出了一种新型 LLM-based NAS 框架，名为 FL-NAS，利用 Large Language Models (LLMs) 来自动化设计深度神经网络。实验结果显示，FL-NAS 发现在几乎所有设计指标上都远超现有最先进模型，为资源约束环境下的公平高效模型设计提供了重要进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ASP-DAC 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.06696v1",
      "published_date": "2024-02-09 00:49:03 UTC",
      "updated_date": "2024-02-09 00:49:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:05:28.793755"
    },
    {
      "arxiv_id": "2402.06107v1",
      "title": "Multiple Instance Learning for Cheating Detection and Localization in Online Examinations",
      "title_zh": "多实例学习用于在线考试中的作弊检测和定位",
      "authors": [
        "Yemeng Liu",
        "Jing Ren",
        "Jianshuo Xu",
        "Xiaomei Bai",
        "Roopdeep Kaur",
        "Feng Xia"
      ],
      "abstract": "The spread of the Coronavirus disease-2019 epidemic has caused many courses\nand exams to be conducted online. The cheating behavior detection model in\nexamination invigilation systems plays a pivotal role in guaranteeing the\nequality of long-distance examinations. However, cheating behavior is rare, and\nmost researchers do not comprehensively take into account features such as head\nposture, gaze angle, body posture, and background information in the task of\ncheating behavior detection. In this paper, we develop and present CHEESE, a\nCHEating detection framework via multiplE inStancE learning. The framework\nconsists of a label generator that implements weak supervision and a feature\nencoder to learn discriminative features. In addition, the framework combines\nbody posture and background features extracted by 3D convolution with eye gaze,\nhead posture and facial features captured by OpenFace 2.0. These features are\nfed into the spatio-temporal graph module by stitching to analyze the\nspatio-temporal changes in video clips to detect the cheating behaviors. Our\nexperiments on three datasets, UCF-Crime, ShanghaiTech and Online Exam\nProctoring (OEP), prove the effectiveness of our method as compared to the\nstate-of-the-art approaches, and obtain the frame-level AUC score of 87.58% on\nthe OEP dataset.",
      "tldr_zh": "该论文针对在线考试中作弊行为的稀有性和检测挑战，提出 CHEESE 框架，利用 Multiple Instance Learning (MIL) 进行作弊检测和定位。框架包括弱监督标签生成器和特征编码器，结合头部姿势、注视角度、身体姿势及背景信息，通过 3D 卷积和 OpenFace 2.0 提取特征，并输入时空图模块分析视频片段的时空变化。实验结果显示，该方法在 UCF-Crime、ShanghaiTech 和 Online Exam Proctoring (OEP) 数据集上表现优于现有技术，在 OEP 数据集上帧级 AUC 得分达到 87.58%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "68T40, 68T45",
        "I.2.10; I.5.4"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.06107v1",
      "published_date": "2024-02-09 00:01:42 UTC",
      "updated_date": "2024-02-09 00:01:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T05:05:43.462810"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 79,
  "processed_papers_count": 79,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T05:06:05.116025"
}