[
  {
    "arxiv_id": "2404.04452v2",
    "title": "Vision transformers in domain adaptation and domain generalization: a study of robustness",
    "authors": [
      "Shadi Alijani",
      "Jamil Fayyad",
      "Homayoun Najjaran"
    ],
    "abstract": "Deep learning models are often evaluated in scenarios where the data\ndistribution is different from those used in the training and validation\nphases. The discrepancy presents a challenge for accurately predicting the\nperformance of models once deployed on the target distribution. Domain\nadaptation and generalization are widely recognized as effective strategies for\naddressing such shifts, thereby ensuring reliable performance. The recent\npromising results in applying vision transformers in computer vision tasks,\ncoupled with advancements in self-attention mechanisms, have demonstrated their\nsignificant potential for robustness and generalization in handling\ndistribution shifts. Motivated by the increased interest from the research\ncommunity, our paper investigates the deployment of vision transformers in\ndomain adaptation and domain generalization scenarios. For domain adaptation\nmethods, we categorize research into feature-level, instance-level, model-level\nadaptations, and hybrid approaches, along with other categorizations with\nrespect to diverse strategies for enhancing domain adaptation. Similarly, for\ndomain generalization, we categorize research into multi-domain learning,\nmeta-learning, regularization techniques, and data augmentation strategies. We\nfurther classify diverse strategies in research, underscoring the various\napproaches researchers have taken to address distribution shifts by integrating\nvision transformers. The inclusion of comprehensive tables summarizing these\ncategories is a distinct feature of our work, offering valuable insights for\nresearchers. These findings highlight the versatility of vision transformers in\nmanaging distribution shifts, crucial for real-world applications, especially\nin critical safety and decision-making scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.10; I.4.9; I.4.7; I.5.1"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04452v2",
    "published_date": "2024-04-05 23:38:57 UTC",
    "updated_date": "2024-10-15 19:49:31 UTC"
  },
  {
    "arxiv_id": "2404.04446v2",
    "title": "Bounding Causal Effects with Leaky Instruments",
    "authors": [
      "David S. Watson",
      "Jordan Penn",
      "Lee M. Gunderson",
      "Gecia Bravo-Hermsdorff",
      "Afsaneh Mastouri",
      "Ricardo Silva"
    ],
    "abstract": "Instrumental variables (IVs) are a popular and powerful tool for estimating\ncausal effects in the presence of unobserved confounding. However, classical\napproaches rely on strong assumptions such as the $\\textit{exclusion\ncriterion}$, which states that instrumental effects must be entirely mediated\nby treatments. This assumption often fails in practice. When IV methods are\nimproperly applied to data that do not meet the exclusion criterion, estimated\ncausal effects may be badly biased. In this work, we propose a novel solution\nthat provides $\\textit{partial}$ identification in linear systems given a set\nof $\\textit{leaky instruments}$, which are allowed to violate the exclusion\ncriterion to some limited degree. We derive a convex optimization objective\nthat provides provably sharp bounds on the average treatment effect under some\ncommon forms of information leakage, and implement inference procedures to\nquantify the uncertainty of resulting estimates. We demonstrate our method in a\nset of experiments with simulated data, where it performs favorably against the\nstate of the art. An accompanying $\\texttt{R}$ package, $\\texttt{leakyIV}$, is\navailable from $\\texttt{CRAN}$.",
    "categories": [
      "stat.ME",
      "cs.AI"
    ],
    "primary_category": "stat.ME",
    "comment": "Camera ready version (UAI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.04446v2",
    "published_date": "2024-04-05 23:17:25 UTC",
    "updated_date": "2024-05-08 09:59:09 UTC"
  },
  {
    "arxiv_id": "2404.04442v1",
    "title": "Exploring Autonomous Agents through the Lens of Large Language Models: A Review",
    "authors": [
      "Saikat Barua"
    ],
    "abstract": "Large Language Models (LLMs) are transforming artificial intelligence,\nenabling autonomous agents to perform diverse tasks across various domains.\nThese agents, proficient in human-like text comprehension and generation, have\nthe potential to revolutionize sectors from customer service to healthcare.\nHowever, they face challenges such as multimodality, human value alignment,\nhallucinations, and evaluation. Techniques like prompting, reasoning, tool\nutilization, and in-context learning are being explored to enhance their\ncapabilities. Evaluation platforms like AgentBench, WebArena, and ToolLLM\nprovide robust methods for assessing these agents in complex scenarios. These\nadvancements are leading to the development of more resilient and capable\nautonomous agents, anticipated to become integral in our digital lives,\nassisting in tasks from email responses to disease diagnosis. The future of AI,\nwith LLMs at the forefront, is promising.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "47 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.04442v1",
    "published_date": "2024-04-05 22:59:02 UTC",
    "updated_date": "2024-04-05 22:59:02 UTC"
  },
  {
    "arxiv_id": "2404.04436v1",
    "title": "AI Knowledge and Reasoning: Emulating Expert Creativity in Scientific Research",
    "authors": [
      "Anirban Mukherjee",
      "Hannah Hanwen Chang"
    ],
    "abstract": "We investigate whether modern AI can emulate expert creativity in complex\nscientific endeavors. We introduce novel methodology that utilizes original\nresearch articles published after the AI's training cutoff, ensuring no prior\nexposure, mitigating concerns of rote memorization and prior training. The AI\nare tasked with redacting findings, predicting outcomes from redacted research,\nand assessing prediction accuracy against reported results. Analysis on 589\npublished studies in four leading psychology journals over a 28-month period,\nshowcase the AI's proficiency in understanding specialized research, deductive\nreasoning, and evaluating evidentiary alignment--cognitive hallmarks of human\nsubject matter expertise and creativity. These findings suggest the potential\nof general-purpose AI to transform academia, with roles requiring\nknowledge-based creativity become increasingly susceptible to technological\nsubstitution.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04436v1",
    "published_date": "2024-04-05 22:30:47 UTC",
    "updated_date": "2024-04-05 22:30:47 UTC"
  },
  {
    "arxiv_id": "2404.06519v1",
    "title": "Best Response Shaping",
    "authors": [
      "Milad Aghajohari",
      "Tim Cooijmans",
      "Juan Agustin Duque",
      "Shunichi Akatsuka",
      "Aaron Courville"
    ],
    "abstract": "We investigate the challenge of multi-agent deep reinforcement learning in\npartially competitive environments, where traditional methods struggle to\nfoster reciprocity-based cooperation. LOLA and POLA agents learn\nreciprocity-based cooperative policies by differentiation through a few\nlook-ahead optimization steps of their opponent. However, there is a key\nlimitation in these techniques. Because they consider a few optimization steps,\na learning opponent that takes many steps to optimize its return may exploit\nthem. In response, we introduce a novel approach, Best Response Shaping (BRS),\nwhich differentiates through an opponent approximating the best response,\ntermed the \"detective.\" To condition the detective on the agent's policy for\ncomplex games we propose a state-aware differentiable conditioning mechanism,\nfacilitated by a question answering (QA) method that extracts a representation\nof the agent based on its behaviour on specific environment states. To\nempirically validate our method, we showcase its enhanced performance against a\nMonte Carlo Tree Search (MCTS) opponent, which serves as an approximation to\nthe best response in the Coin Game. This work expands the applicability of\nmulti-agent RL in partially competitive environments and provides a new pathway\ntowards achieving improved social welfare in general sum games.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06519v1",
    "published_date": "2024-04-05 22:03:35 UTC",
    "updated_date": "2024-04-05 22:03:35 UTC"
  },
  {
    "arxiv_id": "2404.04420v1",
    "title": "The NES Video-Music Database: A Dataset of Symbolic Video Game Music Paired with Gameplay Videos",
    "authors": [
      "Igor Cardoso",
      "Rubens O. Moraes",
      "Lucas N. Ferreira"
    ],
    "abstract": "Neural models are one of the most popular approaches for music generation,\nyet there aren't standard large datasets tailored for learning music directly\nfrom game data. To address this research gap, we introduce a novel dataset\nnamed NES-VMDB, containing 98,940 gameplay videos from 389 NES games, each\npaired with its original soundtrack in symbolic format (MIDI). NES-VMDB is\nbuilt upon the Nintendo Entertainment System Music Database (NES-MDB),\nencompassing 5,278 music pieces from 397 NES games. Our approach involves\ncollecting long-play videos for 389 games of the original dataset, slicing them\ninto 15-second-long clips, and extracting the audio from each clip.\nSubsequently, we apply an audio fingerprinting algorithm (similar to Shazam) to\nautomatically identify the corresponding piece in the NES-MDB dataset.\nAdditionally, we introduce a baseline method based on the Controllable Music\nTransformer to generate NES music conditioned on gameplay clips. We evaluated\nthis approach with objective metrics, and the results showed that the\nconditional CMT improves musical structural quality when compared to its\nunconditional counterpart. Moreover, we used a neural classifier to predict the\ngame genre of the generated pieces. Results showed that the CMT generator can\nlearn correlations between gameplay videos and game genres, but further\nresearch has to be conducted to achieve human-level performance.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted for publication at the 19th International Conference on the\n  Foundations of Digital Games",
    "pdf_url": "http://arxiv.org/pdf/2404.04420v1",
    "published_date": "2024-04-05 21:41:20 UTC",
    "updated_date": "2024-04-05 21:41:20 UTC"
  },
  {
    "arxiv_id": "2404.05758v1",
    "title": "Implicit Assimilation of Sparse In Situ Data for Dense & Global Storm Surge Forecasting",
    "authors": [
      "Patrick Ebel",
      "Brandon Victor",
      "Peter Naylor",
      "Gabriele Meoni",
      "Federico Serva",
      "Rochelle Schneider"
    ],
    "abstract": "Hurricanes and coastal floods are among the most disastrous natural hazards.\nBoth are intimately related to storm surges, as their causes and effects,\nrespectively. However, the short-term forecasting of storm surges has proven\nchallenging, especially when targeting previously unseen locations or sites\nwithout tidal gauges. Furthermore, recent work improved short and medium-term\nweather forecasting but the handling of raw unassimilated data remains\nnon-trivial. In this paper, we tackle both challenges and demonstrate that\nneural networks can implicitly assimilate sparse in situ tide gauge data with\ncoarse ocean state reanalysis in order to forecast storm surges. We curate a\nglobal dataset to learn and validate the dense prediction of storm surges,\nbuilding on preceding efforts. Other than prior work limited to known gauges,\nour approach extends to ungauged sites, paving the way for global storm surge\nforecasting.",
    "categories": [
      "physics.data-an",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "physics.ao-ph",
      "stat.AP"
    ],
    "primary_category": "physics.data-an",
    "comment": "Accepted at CVPR EarthVision 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.05758v1",
    "published_date": "2024-04-05 21:28:56 UTC",
    "updated_date": "2024-04-05 21:28:56 UTC"
  },
  {
    "arxiv_id": "2404.04403v1",
    "title": "Low-Rank Robust Subspace Tensor Clustering for Metro Passenger Flow Modeling",
    "authors": [
      "Jiuyun Hu",
      "Ziyue Li",
      "Chen Zhang",
      "Fugee Tsung",
      "Hao Yan"
    ],
    "abstract": "Tensor clustering has become an important topic, specifically in\nspatio-temporal modeling, due to its ability to cluster spatial modes (e.g.,\nstations or road segments) and temporal modes (e.g., time of the day or day of\nthe week). Our motivating example is from subway passenger flow modeling, where\nsimilarities between stations are commonly found. However, the challenges lie\nin the innate high-dimensionality of tensors and also the potential existence\nof anomalies. This is because the three tasks, i.e., dimension reduction,\nclustering, and anomaly decomposition, are inter-correlated to each other, and\ntreating them in a separate manner will render a suboptimal performance. Thus,\nin this work, we design a tensor-based subspace clustering and anomaly\ndecomposition technique for simultaneously outlier-robust dimension reduction\nand clustering for high-dimensional tensors. To achieve this, a novel low-rank\nrobust subspace clustering decomposition model is proposed by combining Tucker\ndecomposition, sparse anomaly decomposition, and subspace clustering. An\neffective algorithm based on Block Coordinate Descent is proposed to update the\nparameters. Prudent experiments prove the effectiveness of the proposed\nframework via the simulation study, with a gain of +25% clustering accuracy\nthan benchmark methods in a hard case. The interrelations of the three tasks\nare also analyzed via ablation studies, validating the interrelation\nassumption. Moreover, a case study in the station clustering based on real\npassenger flow data is conducted, with quite valuable insights discovered.",
    "categories": [
      "stat.ME",
      "cs.AI"
    ],
    "primary_category": "stat.ME",
    "comment": "Conditionally Accepted in INFORMS Journal of Data Science",
    "pdf_url": "http://arxiv.org/pdf/2404.04403v1",
    "published_date": "2024-04-05 21:00:43 UTC",
    "updated_date": "2024-04-05 21:00:43 UTC"
  },
  {
    "arxiv_id": "2404.04399v1",
    "title": "Longitudinal Targeted Minimum Loss-based Estimation with Temporal-Difference Heterogeneous Transformer",
    "authors": [
      "Toru Shirakawa",
      "Yi Li",
      "Yulun Wu",
      "Sky Qiu",
      "Yuxuan Li",
      "Mingduo Zhao",
      "Hiroyasu Iso",
      "Mark van der Laan"
    ],
    "abstract": "We propose Deep Longitudinal Targeted Minimum Loss-based Estimation (Deep\nLTMLE), a novel approach to estimate the counterfactual mean of outcome under\ndynamic treatment policies in longitudinal problem settings. Our approach\nutilizes a transformer architecture with heterogeneous type embedding trained\nusing temporal-difference learning. After obtaining an initial estimate using\nthe transformer, following the targeted minimum loss-based likelihood\nestimation (TMLE) framework, we statistically corrected for the bias commonly\nassociated with machine learning algorithms. Furthermore, our method also\nfacilitates statistical inference by enabling the provision of 95% confidence\nintervals grounded in asymptotic statistical theory. Simulation results\ndemonstrate our method's superior performance over existing approaches,\nparticularly in complex, long time-horizon scenarios. It remains effective in\nsmall-sample, short-duration contexts, matching the performance of\nasymptotically efficient estimators. To demonstrate our method in practice, we\napplied our method to estimate counterfactual mean outcomes for standard versus\nintensive blood pressure management strategies in a real-world cardiovascular\nepidemiology cohort study.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "stat.AP",
      "stat.ME"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04399v1",
    "published_date": "2024-04-05 20:56:15 UTC",
    "updated_date": "2024-04-05 20:56:15 UTC"
  },
  {
    "arxiv_id": "2404.04392v3",
    "title": "Fine-Tuning, Quantization, and LLMs: Navigating Unintended Outcomes",
    "authors": [
      "Divyanshu Kumar",
      "Anurakt Kumar",
      "Sahil Agarwal",
      "Prashanth Harshangi"
    ],
    "abstract": "Large Language Models (LLMs) have gained widespread adoption across various\ndomains, including chatbots and auto-task completion agents. However, these\nmodels are susceptible to safety vulnerabilities such as jailbreaking, prompt\ninjection, and privacy leakage attacks. These vulnerabilities can lead to the\ngeneration of malicious content, unauthorized actions, or the disclosure of\nconfidential information. While foundational LLMs undergo alignment training\nand incorporate safety measures, they are often subject to fine-tuning, or\ndoing quantization resource-constrained environments. This study investigates\nthe impact of these modifications on LLM safety, a critical consideration for\nbuilding reliable and secure AI systems. We evaluate foundational models\nincluding Mistral, Llama series, Qwen, and MosaicML, along with their\nfine-tuned variants. Our comprehensive analysis reveals that fine-tuning\ngenerally increases the success rates of jailbreak attacks, while quantization\nhas variable effects on attack success rates. Importantly, we find that\nproperly implemented guardrails significantly enhance resistance to jailbreak\nattempts. These findings contribute to our understanding of LLM vulnerabilities\nand provide insights for developing more robust safety strategies in the\ndeployment of language models.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04392v3",
    "published_date": "2024-04-05 20:31:45 UTC",
    "updated_date": "2024-09-09 06:25:33 UTC"
  },
  {
    "arxiv_id": "2404.04376v1",
    "title": "ClickDiffusion: Harnessing LLMs for Interactive Precise Image Editing",
    "authors": [
      "Alec Helbling",
      "Seongmin Lee",
      "Polo Chau"
    ],
    "abstract": "Recently, researchers have proposed powerful systems for generating and\nmanipulating images using natural language instructions. However, it is\ndifficult to precisely specify many common classes of image transformations\nwith text alone. For example, a user may wish to change the location and breed\nof a particular dog in an image with several similar dogs. This task is quite\ndifficult with natural language alone, and would require a user to write a\nlaboriously complex prompt that both disambiguates the target dog and describes\nthe destination. We propose ClickDiffusion, a system for precise image\nmanipulation and generation that combines natural language instructions with\nvisual feedback provided by the user through a direct manipulation interface.\nWe demonstrate that by serializing both an image and a multi-modal instruction\ninto a textual representation it is possible to leverage LLMs to perform\nprecise transformations of the layout and appearance of an image. Code\navailable at https://github.com/poloclub/ClickDiffusion.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2402.07925",
    "pdf_url": "http://arxiv.org/pdf/2404.04376v1",
    "published_date": "2024-04-05 19:38:18 UTC",
    "updated_date": "2024-04-05 19:38:18 UTC"
  },
  {
    "arxiv_id": "2404.08674v1",
    "title": "Effects of Different Prompts on the Quality of GPT-4 Responses to Dementia Care Questions",
    "authors": [
      "Zhuochun Li",
      "Bo Xie",
      "Robin Hilsabeck",
      "Alyssa Aguirre",
      "Ning Zou",
      "Zhimeng Luo",
      "Daqing He"
    ],
    "abstract": "Evidence suggests that different prompts lead large language models (LLMs) to\ngenerate responses with varying quality. Yet, little is known about prompts'\neffects on response quality in healthcare domains. In this exploratory study,\nwe address this gap, focusing on a specific healthcare domain: dementia\ncaregiving. We first developed an innovative prompt template with three\ncomponents: (1) system prompts (SPs) featuring 4 different roles; (2) an\ninitialization prompt; and (3) task prompts (TPs) specifying different levels\nof details, totaling 12 prompt combinations. Next, we selected 3 social media\nposts containing complicated, real-world questions about dementia caregivers'\nchallenges in 3 areas: memory loss and confusion, aggression, and driving. We\nthen entered these posts into GPT-4, with our 12 prompts, to generate 12\nresponses per post, totaling 36 responses. We compared the word count of the 36\nresponses to explore potential differences in response length. Two experienced\ndementia care clinicians on our team assessed the response quality using a\nrating scale with 5 quality indicators: factual, interpretation, application,\nsynthesis, and comprehensiveness (scoring range: 0-5; higher scores indicate\nhigher quality).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08674v1",
    "published_date": "2024-04-05 19:24:57 UTC",
    "updated_date": "2024-04-05 19:24:57 UTC"
  },
  {
    "arxiv_id": "2404.04351v2",
    "title": "Assisting humans in complex comparisons: automated information comparison at scale",
    "authors": [
      "Truman Yuen",
      "Graham A. Watt",
      "Yuri Lawryshyn"
    ],
    "abstract": "Generative Large Language Models enable efficient analytics across knowledge\ndomains, rivalling human experts in information comparisons. However, the\napplications of LLMs for information comparisons face scalability challenges\ndue to the difficulties in maintaining information across large contexts and\novercoming model token limitations. To address these challenges, we developed\nthe novel Abstractive Summarization & Criteria-driven Comparison Endpoint\n(ASC$^2$End) system to automate information comparison at scale. Our system\nemploys Semantic Text Similarity comparisons for generating evidence-supported\nanalyses. We utilize proven data-handling strategies such as abstractive\nsummarization and retrieval augmented generation to overcome token limitations\nand retain relevant information during model inference. Prompts were designed\nusing zero-shot strategies to contextualize information for improved model\nreasoning. We evaluated abstractive summarization using ROUGE scoring and\nassessed the generated comparison quality using survey responses. Models\nevaluated on the ASC$^2$End system show desirable results providing insights on\nthe expected performance of the system. ASC$^2$End is a novel system and tool\nthat enables accurate, automated information comparison at scale across\nknowledge domains, overcoming limitations in context length and retrieval.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7; I.2.8"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 7 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.04351v2",
    "published_date": "2024-04-05 18:44:54 UTC",
    "updated_date": "2024-09-19 00:18:08 UTC"
  },
  {
    "arxiv_id": "2404.04344v1",
    "title": "A Repository for Formal Contexts",
    "authors": [
      "Tom Hanika",
      "Robert Jäschke"
    ],
    "abstract": "Data is always at the center of the theoretical development and investigation\nof the applicability of formal concept analysis. It is therefore not surprising\nthat a large number of data sets are repeatedly used in scholarly articles and\nsoftware tools, acting as de facto standard data sets. However, the\ndistribution of the data sets poses a problem for the sustainable development\nof the research field. There is a lack of a central location that provides and\ndescribes FCA data sets and links them to already known analysis results. This\narticle analyses the current state of the dissemination of FCA data sets,\npresents the requirements for a central FCA repository, and highlights the\nchallenges for this.",
    "categories": [
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.04344v1",
    "published_date": "2024-04-05 18:27:04 UTC",
    "updated_date": "2024-04-05 18:27:04 UTC"
  },
  {
    "arxiv_id": "2404.04332v1",
    "title": "Scope Ambiguities in Large Language Models",
    "authors": [
      "Gaurav Kamath",
      "Sebastian Schuster",
      "Sowmya Vajjala",
      "Siva Reddy"
    ],
    "abstract": "Sentences containing multiple semantic operators with overlapping scope often\ncreate ambiguities in interpretation, known as scope ambiguities. These\nambiguities offer rich insights into the interaction between semantic structure\nand world knowledge in language processing. Despite this, there has been little\nresearch into how modern large language models treat them. In this paper, we\ninvestigate how different versions of certain autoregressive language models --\nGPT-2, GPT-3/3.5, Llama 2 and GPT-4 -- treat scope ambiguous sentences, and\ncompare this with human judgments. We introduce novel datasets that contain a\njoint total of almost 1,000 unique scope-ambiguous sentences, containing\ninteractions between a range of semantic operators, and annotated for human\njudgments. Using these datasets, we find evidence that several models (i) are\nsensitive to the meaning ambiguity in these sentences, in a way that patterns\nwell with human judgments, and (ii) can successfully identify human-preferred\nreadings at a high level of accuracy (over 90% in some cases).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To be published in Transactions of the Association for Computational\n  Linguistics",
    "pdf_url": "http://arxiv.org/pdf/2404.04332v1",
    "published_date": "2024-04-05 18:01:02 UTC",
    "updated_date": "2024-04-05 18:01:02 UTC"
  },
  {
    "arxiv_id": "2404.04326v3",
    "title": "Hypothesis Generation with Large Language Models",
    "authors": [
      "Yangqiaoyu Zhou",
      "Haokun Liu",
      "Tejes Srivastava",
      "Hongyuan Mei",
      "Chenhao Tan"
    ],
    "abstract": "Effective generation of novel hypotheses is instrumental to scientific\nprogress. So far, researchers have been the main powerhouse behind hypothesis\ngeneration by painstaking data analysis and thinking (also known as the Eureka\nmoment). In this paper, we examine the potential of large language models\n(LLMs) to generate hypotheses. We focus on hypothesis generation based on data\n(i.e., labeled examples). To enable LLMs to handle arbitrarily long contexts,\nwe generate initial hypotheses from a small number of examples and then update\nthem iteratively to improve the quality of hypotheses. Inspired by multi-armed\nbandits, we design a reward function to inform the exploitation-exploration\ntradeoff in the update process. Our algorithm is able to generate hypotheses\nthat enable much better predictive performance than few-shot prompting in\nclassification tasks, improving accuracy by 31.7% on a synthetic dataset and by\n13.9%, 3.3% and, 24.9% on three real-world datasets. We also outperform\nsupervised learning by 12.8% and 11.2% on two challenging real-world datasets.\nFurthermore, we find that the generated hypotheses not only corroborate\nhuman-verified theories but also uncover new insights for the tasks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages, 6 figures, code link:\n  https://github.com/ChicagoHAI/hypothesis_generation. Accepted by the 1st\n  Workshop on NLP for Science (NLP4Science) at EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04326v3",
    "published_date": "2024-04-05 18:00:07 UTC",
    "updated_date": "2024-12-18 19:00:00 UTC"
  },
  {
    "arxiv_id": "2404.04254v3",
    "title": "Watermark-based Attribution of AI-Generated Content",
    "authors": [
      "Zhengyuan Jiang",
      "Moyang Guo",
      "Yuepeng Hu",
      "Neil Zhenqiang Gong"
    ],
    "abstract": "Several companies have deployed watermark-based detection to identify\nAI-generated content. However, attribution--the ability to trace back to the\nuser of a generative AI (GenAI) service who created a given piece of\nAI-generated content--remains largely unexplored despite its growing\nimportance. In this work, we aim to bridge this gap by conducting the first\nsystematic study on watermark-based, user-level attribution of AI-generated\ncontent. Our key idea is to assign a unique watermark to each user of the GenAI\nservice and embed this watermark into the AI-generated content created by that\nuser. Attribution is then performed by identifying the user whose watermark\nbest matches the one extracted from the given content. This approach, however,\nfaces a key challenge: How should watermarks be selected for users to maximize\nattribution performance? To address the challenge, we first theoretically\nderive lower bounds on detection and attribution performance through rigorous\nprobabilistic analysis for any given set of user watermarks. Then, we select\nwatermarks for users to maximize these lower bounds, thereby optimizing\ndetection and attribution performance. Our theoretical and empirical results\nshow that watermark-based attribution inherits both the accuracy and\n(non-)robustness properties of the underlying watermark. Specifically,\nattribution remains highly accurate when the watermarked AI-generated content\nis either not post-processed or subjected to common post-processing such as\nJPEG compression, as well as black-box adversarial post-processing with limited\nquery budgets.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04254v3",
    "published_date": "2024-04-05 17:58:52 UTC",
    "updated_date": "2024-11-20 19:17:53 UTC"
  },
  {
    "arxiv_id": "2404.04253v1",
    "title": "Growing Q-Networks: Solving Continuous Control Tasks with Adaptive Control Resolution",
    "authors": [
      "Tim Seyde",
      "Peter Werner",
      "Wilko Schwarting",
      "Markus Wulfmeier",
      "Daniela Rus"
    ],
    "abstract": "Recent reinforcement learning approaches have shown surprisingly strong\ncapabilities of bang-bang policies for solving continuous control benchmarks.\nThe underlying coarse action space discretizations often yield favourable\nexploration characteristics while final performance does not visibly suffer in\nthe absence of action penalization in line with optimal control theory. In\nrobotics applications, smooth control signals are commonly preferred to reduce\nsystem wear and energy efficiency, but action costs can be detrimental to\nexploration during early training. In this work, we aim to bridge this\nperformance gap by growing discrete action spaces from coarse to fine control\nresolution, taking advantage of recent results in decoupled Q-learning to scale\nour approach to high-dimensional action spaces up to dim(A) = 38. Our work\nindicates that an adaptive control resolution in combination with value\ndecomposition yields simple critic-only algorithms that yield surprisingly\nstrong performance on continuous control tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04253v1",
    "published_date": "2024-04-05 17:58:37 UTC",
    "updated_date": "2024-04-05 17:58:37 UTC"
  },
  {
    "arxiv_id": "2404.04251v3",
    "title": "Who Evaluates the Evaluations? Objectively Scoring Text-to-Image Prompt Coherence Metrics with T2IScoreScore (TS2)",
    "authors": [
      "Michael Saxon",
      "Fatima Jahara",
      "Mahsa Khoshnoodi",
      "Yujie Lu",
      "Aditya Sharma",
      "William Yang Wang"
    ],
    "abstract": "With advances in the quality of text-to-image (T2I) models has come interest\nin benchmarking their prompt faithfulness -- the semantic coherence of\ngenerated images to the prompts they were conditioned on. A variety of T2I\nfaithfulness metrics have been proposed, leveraging advances in cross-modal\nembeddings and vision-language models (VLMs). However, these metrics are not\nrigorously compared and benchmarked, instead presented with correlation to\nhuman Likert scores over a set of easy-to-discriminate images against seemingly\nweak baselines.\n  We introduce T2IScoreScore, a curated set of semantic error graphs containing\na prompt and a set of increasingly erroneous images. These allow us to\nrigorously judge whether a given prompt faithfulness metric can correctly order\nimages with respect to their objective error count and significantly\ndiscriminate between different error nodes, using meta-metric scores derived\nfrom established statistical tests. Surprisingly, we find that the\nstate-of-the-art VLM-based metrics (e.g., TIFA, DSG, LLMScore, VIEScore) we\ntested fail to significantly outperform simple (and supposedly worse)\nfeature-based metrics like CLIPScore, particularly on a hard subset of\nnaturally-occurring T2I model errors. TS2 will enable the development of better\nT2I prompt faithfulness metrics through more rigorous comparison of their\nconformity to expected orderings and separations under objective criteria.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024 Spotlight",
    "pdf_url": "http://arxiv.org/pdf/2404.04251v3",
    "published_date": "2024-04-05 17:57:16 UTC",
    "updated_date": "2024-10-31 01:39:48 UTC"
  },
  {
    "arxiv_id": "2404.04318v1",
    "title": "Robust Depth Enhancement via Polarization Prompt Fusion Tuning",
    "authors": [
      "Kei Ikemura",
      "Yiming Huang",
      "Felix Heide",
      "Zhaoxiang Zhang",
      "Qifeng Chen",
      "Chenyang Lei"
    ],
    "abstract": "Existing depth sensors are imperfect and may provide inaccurate depth values\nin challenging scenarios, such as in the presence of transparent or reflective\nobjects. In this work, we present a general framework that leverages\npolarization imaging to improve inaccurate depth measurements from various\ndepth sensors. Previous polarization-based depth enhancement methods focus on\nutilizing pure physics-based formulas for a single sensor. In contrast, our\nmethod first adopts a learning-based strategy where a neural network is trained\nto estimate a dense and complete depth map from polarization data and a sensor\ndepth map from different sensors. To further improve the performance, we\npropose a Polarization Prompt Fusion Tuning (PPFT) strategy to effectively\nutilize RGB-based models pre-trained on large-scale datasets, as the size of\nthe polarization dataset is limited to train a strong model from scratch. We\nconducted extensive experiments on a public dataset, and the results\ndemonstrate that the proposed method performs favorably compared to existing\ndepth enhancement baselines. Code and demos are available at\nhttps://lastbasket.github.io/PPFT/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024. Project page: https://lastbasket.github.io/PPFT/. The\n  first two authors contribute equally",
    "pdf_url": "http://arxiv.org/pdf/2404.04318v1",
    "published_date": "2024-04-05 17:55:33 UTC",
    "updated_date": "2024-04-05 17:55:33 UTC"
  },
  {
    "arxiv_id": "2404.04243v3",
    "title": "Identity Decoupling for Multi-Subject Personalization of Text-to-Image Models",
    "authors": [
      "Sangwon Jang",
      "Jaehyeong Jo",
      "Kimin Lee",
      "Sung Ju Hwang"
    ],
    "abstract": "Text-to-image diffusion models have shown remarkable success in generating\npersonalized subjects based on a few reference images. However, current methods\noften fail when generating multiple subjects simultaneously, resulting in mixed\nidentities with combined attributes from different subjects. In this work, we\npresent MuDI, a novel framework that enables multi-subject personalization by\neffectively decoupling identities from multiple subjects. Our main idea is to\nutilize segmented subjects generated by a foundation model for segmentation\n(Segment Anything) for both training and inference, as a form of data\naugmentation for training and initialization for the generation process.\nMoreover, we further introduce a new metric to better evaluate the performance\nof our method on multi-subject personalization. Experimental results show that\nour MuDI can produce high-quality personalized images without identity mixing,\neven for highly similar subjects as shown in Figure 1. Specifically, in human\nevaluation, MuDI obtains twice the success rate for personalizing multiple\nsubjects without identity mixing over existing baselines and is preferred over\n70% against the strongest baseline.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024. Project page: https://mudi-t2i.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2404.04243v3",
    "published_date": "2024-04-05 17:45:22 UTC",
    "updated_date": "2024-10-28 08:22:36 UTC"
  },
  {
    "arxiv_id": "2404.04242v1",
    "title": "Physical Property Understanding from Language-Embedded Feature Fields",
    "authors": [
      "Albert J. Zhai",
      "Yuan Shen",
      "Emily Y. Chen",
      "Gloria X. Wang",
      "Xinlei Wang",
      "Sheng Wang",
      "Kaiyu Guan",
      "Shenlong Wang"
    ],
    "abstract": "Can computers perceive the physical properties of objects solely through\nvision? Research in cognitive science and vision science has shown that humans\nexcel at identifying materials and estimating their physical properties based\npurely on visual appearance. In this paper, we present a novel approach for\ndense prediction of the physical properties of objects using a collection of\nimages. Inspired by how humans reason about physics through vision, we leverage\nlarge language models to propose candidate materials for each object. We then\nconstruct a language-embedded point cloud and estimate the physical properties\nof each 3D point using a zero-shot kernel regression approach. Our method is\naccurate, annotation-free, and applicable to any object in the open world.\nExperiments demonstrate the effectiveness of the proposed approach in various\nphysical property reasoning tasks, such as estimating the mass of common\nobjects, as well as other properties like friction and hardness.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024. Project page (with code):\n  https://ajzhai.github.io/NeRF2Physics/",
    "pdf_url": "http://arxiv.org/pdf/2404.04242v1",
    "published_date": "2024-04-05 17:45:07 UTC",
    "updated_date": "2024-04-05 17:45:07 UTC"
  },
  {
    "arxiv_id": "2404.04234v3",
    "title": "player2vec: A Language Modeling Approach to Understand Player Behavior in Games",
    "authors": [
      "Tianze Wang",
      "Maryam Honari-Jahromi",
      "Styliani Katsarou",
      "Olga Mikheeva",
      "Theodoros Panagiotakopoulos",
      "Sahar Asadi",
      "Oleg Smirnov"
    ],
    "abstract": "Methods for learning latent user representations from historical behavior\nlogs have gained traction for recommendation tasks in e-commerce, content\nstreaming, and other settings. However, this area still remains relatively\nunderexplored in video and mobile gaming contexts. In this work, we present a\nnovel method for overcoming this limitation by extending a long-range\nTransformer model from the natural language processing domain to player\nbehavior data. We discuss specifics of behavior tracking in games and propose\npreprocessing and tokenization approaches by viewing in-game events in an\nanalogous way to words in sentences, thus enabling learning player\nrepresentations in a self-supervised manner in the absence of ground-truth\nannotations. We experimentally demonstrate the efficacy of the proposed\napproach in fitting the distribution of behavior events by evaluating intrinsic\nlanguage modeling metrics. Furthermore, we qualitatively analyze the emerging\nstructure of the learned embedding space and show its value for generating\ninsights into behavior patterns to inform downstream applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04234v3",
    "published_date": "2024-04-05 17:29:47 UTC",
    "updated_date": "2024-06-07 22:01:05 UTC"
  },
  {
    "arxiv_id": "2405.12222v1",
    "title": "Influence based explainability of brain tumors segmentation in multimodal Magnetic Resonance Imaging",
    "authors": [
      "Tommaso Torda",
      "Andrea Ciardiello",
      "Simona Gargiulo",
      "Greta Grillo",
      "Simone Scardapane",
      "Cecilia Voena",
      "Stefano Giagu"
    ],
    "abstract": "In recent years Artificial Intelligence has emerged as a fundamental tool in\nmedical applications. Despite this rapid development, deep neural networks\nremain black boxes that are difficult to explain, and this represents a major\nlimitation for their use in clinical practice. We focus on the segmentation of\nmedical images task, where most explainability methods proposed so far provide\na visual explanation in terms of an input saliency map. The aim of this work is\nto extend, implement and test instead an influence-based explainability\nalgorithm, TracIn, proposed originally for classification tasks, in a\nchallenging clinical problem, i.e., multiclass segmentation of tumor brains in\nmultimodal Magnetic Resonance Imaging. We verify the faithfulness of the\nproposed algorithm linking the similarities of the latent representation of the\nnetwork to the TracIn output. We further test the capacity of the algorithm to\nprovide local and global explanations, and we suggest that it can be adopted as\na tool to select the most relevant features used in the decision process. The\nmethod is generalizable for all semantic segmentation tasks where classes are\nmutually exclusive, which is the standard framework in these cases.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "15 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.12222v1",
    "published_date": "2024-04-05 17:07:21 UTC",
    "updated_date": "2024-04-05 17:07:21 UTC"
  },
  {
    "arxiv_id": "2404.04220v1",
    "title": "Multi-modal perception for soft robotic interactions using generative models",
    "authors": [
      "Enrico Donato",
      "Egidio Falotico",
      "Thomas George Thuruthel"
    ],
    "abstract": "Perception is essential for the active interaction of physical agents with\nthe external environment. The integration of multiple sensory modalities, such\nas touch and vision, enhances this perceptual process, creating a more\ncomprehensive and robust understanding of the world. Such fusion is\nparticularly useful for highly deformable bodies such as soft robots.\nDeveloping a compact, yet comprehensive state representation from multi-sensory\ninputs can pave the way for the development of complex control strategies. This\npaper introduces a perception model that harmonizes data from diverse\nmodalities to build a holistic state representation and assimilate essential\ninformation. The model relies on the causality between sensory input and\nrobotic actions, employing a generative model to efficiently compress fused\ninformation and predict the next observation. We present, for the first time, a\nstudy on how touch can be predicted from vision and proprioception on soft\nrobots, the importance of the cross-modal generation and why this is essential\nfor soft robotic interactions in unstructured environments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted for presentation at IEEE RoboSoft 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04220v1",
    "published_date": "2024-04-05 17:06:03 UTC",
    "updated_date": "2024-04-05 17:06:03 UTC"
  },
  {
    "arxiv_id": "2404.04219v1",
    "title": "Continual Policy Distillation of Reinforcement Learning-based Controllers for Soft Robotic In-Hand Manipulation",
    "authors": [
      "Lanpei Li",
      "Enrico Donato",
      "Vincenzo Lomonaco",
      "Egidio Falotico"
    ],
    "abstract": "Dexterous manipulation, often facilitated by multi-fingered robotic hands,\nholds solid impact for real-world applications. Soft robotic hands, due to\ntheir compliant nature, offer flexibility and adaptability during object\ngrasping and manipulation. Yet, benefits come with challenges, particularly in\nthe control development for finger coordination. Reinforcement Learning (RL)\ncan be employed to train object-specific in-hand manipulation policies, but\nlimiting adaptability and generalizability. We introduce a Continual Policy\nDistillation (CPD) framework to acquire a versatile controller for in-hand\nmanipulation, to rotate different objects in shape and size within a\nfour-fingered soft gripper. The framework leverages Policy Distillation (PD) to\ntransfer knowledge from expert policies to a continually evolving student\npolicy network. Exemplar-based rehearsal methods are then integrated to\nmitigate catastrophic forgetting and enhance generalization. The performance of\nthe CPD framework over various replay strategies demonstrates its effectiveness\nin consolidating knowledge from multiple experts and achieving versatile and\nadaptive behaviours for in-hand manipulation tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted for presentation at IEEE RoboSoft 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04219v1",
    "published_date": "2024-04-05 17:05:45 UTC",
    "updated_date": "2024-04-05 17:05:45 UTC"
  },
  {
    "arxiv_id": "2404.04205v1",
    "title": "Enhancing IoT Intelligence: A Transformer-based Reinforcement Learning Methodology",
    "authors": [
      "Gaith Rjoub",
      "Saidul Islam",
      "Jamal Bentahar",
      "Mohammed Amin Almaiah",
      "Rana Alrawashdeh"
    ],
    "abstract": "The proliferation of the Internet of Things (IoT) has led to an explosion of\ndata generated by interconnected devices, presenting both opportunities and\nchallenges for intelligent decision-making in complex environments. Traditional\nReinforcement Learning (RL) approaches often struggle to fully harness this\ndata due to their limited ability to process and interpret the intricate\npatterns and dependencies inherent in IoT applications. This paper introduces a\nnovel framework that integrates transformer architectures with Proximal Policy\nOptimization (PPO) to address these challenges. By leveraging the\nself-attention mechanism of transformers, our approach enhances RL agents'\ncapacity for understanding and acting within dynamic IoT environments, leading\nto improved decision-making processes. We demonstrate the effectiveness of our\nmethod across various IoT scenarios, from smart home automation to industrial\ncontrol systems, showing marked improvements in decision-making efficiency and\nadaptability. Our contributions include a detailed exploration of the\ntransformer's role in processing heterogeneous IoT data, a comprehensive\nevaluation of the framework's performance in diverse environments, and a\nbenchmark against traditional RL methods. The results indicate significant\nadvancements in enabling RL agents to navigate the complexities of IoT\necosystems, highlighting the potential of our approach to revolutionize\nintelligent automation and decision-making in the IoT landscape.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04205v1",
    "published_date": "2024-04-05 16:30:45 UTC",
    "updated_date": "2024-04-05 16:30:45 UTC"
  },
  {
    "arxiv_id": "2404.08673v1",
    "title": "Sentiment analysis and random forest to classify LLM versus human source applied to Scientific Texts",
    "authors": [
      "Javier J. Sanchez-Medina"
    ],
    "abstract": "After the launch of ChatGPT v.4 there has been a global vivid discussion on\nthe ability of this artificial intelligence powered platform and some other\nsimilar ones for the automatic production of all kinds of texts, including\nscientific and technical texts. This has triggered a reflection in many\ninstitutions on whether education and academic procedures should be adapted to\nthe fact that in future many texts we read will not be written by humans\n(students, scholars, etc.), at least, not entirely. In this work it is proposed\na new methodology to classify texts coming from an automatic text production\nengine or a human, based on Sentiment Analysis as a source for feature\nengineering independent variables and then train with them a Random Forest\nclassification algorithm. Using four different sentiment lexicons, a number of\nnew features where produced, and then fed to a machine learning random forest\nmethodology, to train such a model. Results seem very convincing that this may\nbe a promising research line to detect fraud, in such environments where human\nare supposed to be the source of texts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "68"
    ],
    "primary_category": "cs.CL",
    "comment": "12 Pages, 3 tables, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.08673v1",
    "published_date": "2024-04-05 16:14:36 UTC",
    "updated_date": "2024-04-05 16:14:36 UTC"
  },
  {
    "arxiv_id": "2404.15324v1",
    "title": "Advanced simulation-based predictive modelling for solar irradiance sensor farms",
    "authors": [
      "José L. Risco-Martín",
      "Ignacio-Iker Prado-Rujas",
      "Javier Campoy",
      "María S. Pérez",
      "Katzalin Olcoz"
    ],
    "abstract": "As solar power continues to grow and replace traditional energy sources, the\nneed for reliable forecasting models becomes increasingly important to ensure\nthe stability and efficiency of the grid. However, the management of these\nmodels still needs to be improved, and new tools and technologies are required\nto handle the deployment and control of solar facilities. This work introduces\na novel framework named Cloud-based Analysis and Integration for Data\nEfficiency (CAIDE), designed for real-time monitoring, management, and\nforecasting of solar irradiance sensor farms. CAIDE is designed to manage\nmultiple sensor farms simultaneously while improving predictive models in\nreal-time using well-grounded Modeling and Simulation (M&S) methodologies. The\nframework leverages Model Based Systems Engineering (MBSE) and an Internet of\nThings (IoT) infrastructure to support the deployment and analysis of solar\nplants in dynamic environments. The system can adapt and re-train the model\nwhen given incorrect results, ensuring that forecasts remain accurate and\nup-to-date. Furthermore, CAIDE can be executed in sequential, parallel, and\ndistributed architectures, assuring scalability. The effectiveness of CAIDE is\ndemonstrated in a complex scenario composed of several solar irradiance sensor\nfarms connected to a centralized management system. Our results show that CAIDE\nis scalable and effective in managing and forecasting solar power production\nwhile improving the accuracy of predictive models in real time. The framework\nhas important implications for the deployment of solar plants and the future of\nrenewable energy sources.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15324v1",
    "published_date": "2024-04-05 15:44:51 UTC",
    "updated_date": "2024-04-05 15:44:51 UTC"
  },
  {
    "arxiv_id": "2406.11857v1",
    "title": "AI Royalties -- an IP Framework to Compensate Artists & IP Holders for AI-Generated Content",
    "authors": [
      "Pablo Ducru",
      "Jonathan Raiman",
      "Ronaldo Lemos",
      "Clay Garner",
      "George He",
      "Hanna Balcha",
      "Gabriel Souto",
      "Sergio Branco",
      "Celina Bottino"
    ],
    "abstract": "This article investigates how AI-generated content can disrupt central\nrevenue streams of the creative industries, in particular the collection of\ndividends from intellectual property (IP) rights. It reviews the IP and\ncopyright questions related to the input and output of generative AI systems. A\nsystematic method is proposed to assess whether AI-generated outputs,\nespecially images, infringe previous copyrights, using a similarity metric\n(CLIP) between images against historical copyright rulings. An examination\n(economic and technical feasibility) of previously proposed compensation\nframeworks reveals their financial implications for creatives and IP holders.\nLastly, we propose a novel IP framework for compensation of artists and IP\nholders based on their published \"licensed AIs\" as a new medium and asset from\nwhich to collect AI royalties.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "7 pages, 2 figures, submitted to AAAI",
    "pdf_url": "http://arxiv.org/pdf/2406.11857v1",
    "published_date": "2024-04-05 15:35:08 UTC",
    "updated_date": "2024-04-05 15:35:08 UTC"
  },
  {
    "arxiv_id": "2404.04316v2",
    "title": "Parameter Efficient Quasi-Orthogonal Fine-Tuning via Givens Rotation",
    "authors": [
      "Xinyu Ma",
      "Xu Chu",
      "Zhibang Yang",
      "Yang Lin",
      "Xin Gao",
      "Junfeng Zhao"
    ],
    "abstract": "With the increasingly powerful performances and enormous scales of pretrained\nmodels, promoting parameter efficiency in fine-tuning has become a crucial need\nfor effective and efficient adaptation to various downstream tasks. One\nrepresentative line of fine-tuning methods is Orthogonal Fine-tuning (OFT),\nwhich rigorously preserves the angular distances within the parameter space to\npreserve the pretrained knowledge. Despite the empirical effectiveness, OFT\nstill suffers low parameter efficiency at $\\mathcal{O}(d^2)$ and limited\ncapability of downstream adaptation. Inspired by Givens rotation, in this\npaper, we proposed quasi-Givens Orthogonal Fine-Tuning (qGOFT) to address the\nproblems. We first use $\\mathcal{O}(d)$ Givens rotations to accomplish\narbitrary orthogonal transformation in $SO(d)$ with provable equivalence,\nreducing parameter complexity from $\\mathcal{O}(d^2)$ to $\\mathcal{O}(d)$. Then\nwe introduce flexible norm and relative angular adjustments under soft\northogonality regularization to enhance the adaptation capability of downstream\nsemantic deviations. Extensive experiments on various tasks and pretrained\nmodels validate the effectiveness of our methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Appeared at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04316v2",
    "published_date": "2024-04-05 15:28:44 UTC",
    "updated_date": "2024-06-07 03:54:01 UTC"
  },
  {
    "arxiv_id": "2404.04167v5",
    "title": "Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model",
    "authors": [
      "Xinrun Du",
      "Zhouliang Yu",
      "Songyang Gao",
      "Ding Pan",
      "Yuyang Cheng",
      "Ziyang Ma",
      "Ruibin Yuan",
      "Xingwei Qu",
      "Jiaheng Liu",
      "Tianyu Zheng",
      "Xinchen Luo",
      "Guorui Zhou",
      "Wenhu Chen",
      "Ge Zhang"
    ],
    "abstract": "In this study, we introduce CT-LLM, a 2B large language model (LLM) that\nillustrates a pivotal shift towards prioritizing the Chinese language in\ndeveloping LLMs. Uniquely initiated from scratch, CT-LLM diverges from the\nconventional methodology by primarily incorporating Chinese textual data,\nutilizing an extensive corpus of 1,200 billion tokens, including 800 billion\nChinese tokens, 300 billion English tokens, and 100 billion code tokens. This\nstrategic composition facilitates the model's exceptional proficiency in\nunderstanding and processing Chinese, a capability further enhanced through\nalignment techniques. Demonstrating remarkable performance on the CHC-Bench,\nCT-LLM excels in Chinese language tasks, and showcases its adeptness in English\nthrough SFT. This research challenges the prevailing paradigm of training LLMs\npredominantly on English corpora and then adapting them to other languages,\nbroadening the horizons for LLM training methodologies. By open-sourcing the\nfull process of training a Chinese LLM, including a detailed data processing\nprocedure with the obtained Massive Appropriate Pretraining Chinese Corpus\n(MAP-CC), a well-chosen multidisciplinary Chinese Hard Case Benchmark\n(CHC-Bench), and the 2B-size Chinese Tiny LLM (CT-LLM), we aim to foster\nfurther exploration and innovation in both academia and industry, paving the\nway for more inclusive and versatile language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04167v5",
    "published_date": "2024-04-05 15:20:02 UTC",
    "updated_date": "2024-09-13 09:47:29 UTC"
  },
  {
    "arxiv_id": "2404.04159v1",
    "title": "Noisy Label Processing for Classification: A Survey",
    "authors": [
      "Mengting Li",
      "Chuang Zhu"
    ],
    "abstract": "In recent years, deep neural networks (DNNs) have gained remarkable\nachievement in computer vision tasks, and the success of DNNs often depends\ngreatly on the richness of data. However, the acquisition process of data and\nhigh-quality ground truth requires a lot of manpower and money. In the long,\ntedious process of data annotation, annotators are prone to make mistakes,\nresulting in incorrect labels of images, i.e., noisy labels. The emergence of\nnoisy labels is inevitable. Moreover, since research shows that DNNs can easily\nfit noisy labels, the existence of noisy labels will cause significant damage\nto the model training process. Therefore, it is crucial to combat noisy labels\nfor computer vision tasks, especially for classification tasks. In this survey,\nwe first comprehensively review the evolution of different deep learning\napproaches for noisy label combating in the image classification task. In\naddition, we also review different noise patterns that have been proposed to\ndesign robust algorithms. Furthermore, we explore the inner pattern of\nreal-world label noise and propose an algorithm to generate a synthetic label\nnoise pattern guided by real-world data. We test the algorithm on the\nwell-known real-world dataset CIFAR-10N to form a new real-world data-guided\nsynthetic benchmark and evaluate some typical noise-robust methods on the\nbenchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04159v1",
    "published_date": "2024-04-05 15:11:09 UTC",
    "updated_date": "2024-04-05 15:11:09 UTC"
  },
  {
    "arxiv_id": "2404.04139v1",
    "title": "Precision Guided Approach to Mitigate Data Poisoning Attacks in Federated Learning",
    "authors": [
      "K Naveen Kumar",
      "C Krishna Mohan",
      "Aravind Machiry"
    ],
    "abstract": "Federated Learning (FL) is a collaborative learning paradigm enabling\nparticipants to collectively train a shared machine learning model while\npreserving the privacy of their sensitive data. Nevertheless, the inherent\ndecentralized and data-opaque characteristics of FL render its susceptibility\nto data poisoning attacks. These attacks introduce malformed or malicious\ninputs during local model training, subsequently influencing the global model\nand resulting in erroneous predictions. Current FL defense strategies against\ndata poisoning attacks either involve a trade-off between accuracy and\nrobustness or necessitate the presence of a uniformly distributed root dataset\nat the server. To overcome these limitations, we present FedZZ, which harnesses\na zone-based deviating update (ZBDU) mechanism to effectively counter data\npoisoning attacks in FL. Further, we introduce a precision-guided methodology\nthat actively characterizes these client clusters (zones), which in turn aids\nin recognizing and discarding malicious updates at the server. Our evaluation\nof FedZZ across two widely recognized datasets: CIFAR10 and EMNIST, demonstrate\nits efficacy in mitigating data poisoning attacks, surpassing the performance\nof prevailing state-of-the-art methodologies in both single and multi-client\nattack scenarios and varying attack volumes. Notably, FedZZ also functions as a\nrobust client selection strategy, even in highly non-IID and attack-free\nscenarios. Moreover, in the face of escalating poisoning rates, the model\naccuracy attained by FedZZ displays superior resilience compared to existing\ntechniques. For instance, when confronted with a 50% presence of malicious\nclients, FedZZ sustains an accuracy of 67.43%, while the accuracy of the\nsecond-best solution, FL-Defender, diminishes to 43.36%.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "14 pages, 11 figures, 5 tables, Accepted in ACM CODASPY 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04139v1",
    "published_date": "2024-04-05 14:37:49 UTC",
    "updated_date": "2024-04-05 14:37:49 UTC"
  },
  {
    "arxiv_id": "2404.04108v2",
    "title": "Large language models as oracles for instantiating ontologies with domain-specific knowledge",
    "authors": [
      "Giovanni Ciatto",
      "Andrea Agiollo",
      "Matteo Magnini",
      "Andrea Omicini"
    ],
    "abstract": "Background. Endowing intelligent systems with semantic data commonly requires\ndesigning and instantiating ontologies with domain-specific knowledge.\nEspecially in the early phases, those activities are typically performed\nmanually by human experts possibly leveraging on their own experience. The\nresulting process is therefore time-consuming, error-prone, and often biased by\nthe personal background of the ontology designer. Objective. To mitigate that\nissue, we propose a novel domain-independent approach to automatically\ninstantiate ontologies with domain-specific knowledge, by leveraging on large\nlanguage models (LLMs) as oracles. Method. Starting from (i) an initial schema\ncomposed by inter-related classes and properties and (ii) a set of query\ntemplates, our method queries the LLM multiple times, and generates instances\nfor both classes and properties from its replies. Thus, the ontology is\nautomatically filled with domain-specific knowledge, compliant to the initial\nschema. As a result, the ontology is quickly and automatically enriched with\nmanifold instances, which experts may consider to keep, adjust, discard, or\ncomplement according to their own needs and expertise. Contribution. We\nformalise our method in general way and instantiate it over various LLMs, as\nwell as on a concrete case study. We report experiments rooted in the\nnutritional domain where an ontology of food meals and their ingredients is\nautomatically instantiated from scratch, starting from a categorisation of\nmeals and their relationships. There, we analyse the quality of the generated\nontologies and compare ontologies attained by exploiting different LLMs.\nExperimentally, our approach achieves a quality metric that is up to five times\nhigher than the state-of-the-art, while reducing erroneous entities and\nrelations by up to ten times. Finally, we provide a SWOT analysis of the\nproposed method.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04108v2",
    "published_date": "2024-04-05 14:04:07 UTC",
    "updated_date": "2024-12-12 10:56:35 UTC"
  },
  {
    "arxiv_id": "2404.04106v1",
    "title": "Intervention-Assisted Policy Gradient Methods for Online Stochastic Queuing Network Optimization: Technical Report",
    "authors": [
      "Jerrod Wigmore",
      "Brooke Shrader",
      "Eytan Modiano"
    ],
    "abstract": "Deep Reinforcement Learning (DRL) offers a powerful approach to training\nneural network control policies for stochastic queuing networks (SQN). However,\ntraditional DRL methods rely on offline simulations or static datasets,\nlimiting their real-world application in SQN control. This work proposes Online\nDeep Reinforcement Learning-based Controls (ODRLC) as an alternative, where an\nintelligent agent interacts directly with a real environment and learns an\noptimal control policy from these online interactions. SQNs present a challenge\nfor ODRLC due to the unbounded nature of the queues within the network\nresulting in an unbounded state-space. An unbounded state-space is particularly\nchallenging for neural network policies as neural networks are notoriously poor\nat extrapolating to unseen states. To address this challenge, we propose an\nintervention-assisted framework that leverages strategic interventions from\nknown stable policies to ensure the queue sizes remain bounded. This framework\ncombines the learning power of neural networks with the guaranteed stability of\nclassical control policies for SQNs. We introduce a method to design these\nintervention-assisted policies to ensure strong stability of the network.\nFurthermore, we extend foundational DRL theorems for intervention-assisted\npolicies and develop two practical algorithms specifically for ODRLC of SQNs.\nFinally, we demonstrate through experiments that our proposed algorithms\noutperform both classical control approaches and prior ODRLC algorithms.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "F.2.2; I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 6 Figures",
    "pdf_url": "http://arxiv.org/pdf/2404.04106v1",
    "published_date": "2024-04-05 14:02:04 UTC",
    "updated_date": "2024-04-05 14:02:04 UTC"
  },
  {
    "arxiv_id": "2404.04102v2",
    "title": "ROPO: Robust Preference Optimization for Large Language Models",
    "authors": [
      "Xize Liang",
      "Chao Chen",
      "Shuang Qiu",
      "Jie Wang",
      "Yue Wu",
      "Zhihang Fu",
      "Zhihao Shi",
      "Feng Wu",
      "Jieping Ye"
    ],
    "abstract": "Preference alignment is pivotal for empowering large language models (LLMs)\nto generate helpful and harmless responses. However, the performance of\npreference alignment is highly sensitive to the prevalent noise in the\npreference data. Recent efforts for this problem either marginally alleviate\nthe impact of noise without the ability to actually reduce its presence, or\nrely on costly teacher LLMs prone to reward misgeneralization. To address these\nchallenges, we propose the RObust Preference Optimization (ROPO) framework, an\niterative alignment approach that integrates noise-tolerance and filtering of\nnoisy samples without the aid of external models. Specifically, ROPO\niteratively solves a constrained optimization problem, where we dynamically\nassign a quality-aware weight for each sample and constrain the sum of the\nweights to the number of samples we intend to retain. For noise-tolerant\ntraining and effective noise identification, we derive a robust loss by\nsuppressing the gradients of samples with high uncertainty. We demonstrate both\nempirically and theoretically that the derived loss is critical for\ndistinguishing noisy samples from clean ones. Furthermore, inspired by our\nderived loss, we propose a robustness-guided rejection sampling technique to\ncompensate for the potential important information in discarded queries.\nExperiments on three widely-used datasets with Mistral-7B and Llama-2-7B\ndemonstrate that ROPO significantly outperforms existing preference alignment\nmethods, with its superiority growing as the noise rate increases.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04102v2",
    "published_date": "2024-04-05 13:58:51 UTC",
    "updated_date": "2024-05-28 17:11:53 UTC"
  },
  {
    "arxiv_id": "2405.10957v1",
    "title": "Statistical Mechanics and Artificial Neural Networks: Principles, Models, and Applications",
    "authors": [
      "Lucas Böttcher",
      "Gregory Wheeler"
    ],
    "abstract": "The field of neuroscience and the development of artificial neural networks\n(ANNs) have mutually influenced each other, drawing from and contributing to\nmany concepts initially developed in statistical mechanics. Notably, Hopfield\nnetworks and Boltzmann machines are versions of the Ising model, a model\nextensively studied in statistical mechanics for over a century. In the first\npart of this chapter, we provide an overview of the principles, models, and\napplications of ANNs, highlighting their connections to statistical mechanics\nand statistical learning theory.\n  Artificial neural networks can be seen as high-dimensional mathematical\nfunctions, and understanding the geometric properties of their loss landscapes\n(i.e., the high-dimensional space on which one wishes to find extrema or\nsaddles) can provide valuable insights into their optimization behavior,\ngeneralization abilities, and overall performance. Visualizing these functions\ncan help us design better optimization methods and improve their generalization\nabilities. Thus, the second part of this chapter focuses on quantifying\ngeometric properties and visualizing loss functions associated with deep ANNs.",
    "categories": [
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cond-mat.dis-nn",
    "comment": "45 pages, 12 figures. arXiv admin note: text overlap with\n  arXiv:2208.13219",
    "pdf_url": "http://arxiv.org/pdf/2405.10957v1",
    "published_date": "2024-04-05 13:54:58 UTC",
    "updated_date": "2024-04-05 13:54:58 UTC"
  },
  {
    "arxiv_id": "2404.04095v1",
    "title": "Dynamic Prompt Optimizing for Text-to-Image Generation",
    "authors": [
      "Wenyi Mo",
      "Tianyu Zhang",
      "Yalong Bai",
      "Bing Su",
      "Ji-Rong Wen",
      "Qing Yang"
    ],
    "abstract": "Text-to-image generative models, specifically those based on diffusion models\nlike Imagen and Stable Diffusion, have made substantial advancements. Recently,\nthere has been a surge of interest in the delicate refinement of text prompts.\nUsers assign weights or alter the injection time steps of certain words in the\ntext prompts to improve the quality of generated images. However, the success\nof fine-control prompts depends on the accuracy of the text prompts and the\ncareful selection of weights and time steps, which requires significant manual\nintervention. To address this, we introduce the \\textbf{P}rompt\n\\textbf{A}uto-\\textbf{E}diting (PAE) method. Besides refining the original\nprompts for image generation, we further employ an online reinforcement\nlearning strategy to explore the weights and injection time steps of each word,\nleading to the dynamic fine-control prompts. The reward function during\ntraining encourages the model to consider aesthetic score, semantic\nconsistency, and user preferences. Experimental results demonstrate that our\nproposed method effectively improves the original prompts, generating visually\nmore appealing images while maintaining semantic alignment. Code is available\nat https://github.com/Mowenyii/PAE.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04095v1",
    "published_date": "2024-04-05 13:44:39 UTC",
    "updated_date": "2024-04-05 13:44:39 UTC"
  },
  {
    "arxiv_id": "2404.04067v4",
    "title": "Does Biomedical Training Lead to Better Medical Performance?",
    "authors": [
      "Amin Dada",
      "Marie Bauer",
      "Amanda Butler Contreras",
      "Osman Alperen Koraş",
      "Constantin Marc Seibold",
      "Kaleb E Smith",
      "Jens Kleesiek"
    ],
    "abstract": "Large Language Models (LLMs) are expected to significantly contribute to\npatient care, diagnostics, and administrative processes. Emerging biomedical\nLLMs aim to address healthcare-specific challenges, including privacy demands\nand computational constraints. Assessing the models' suitability for this\nsensitive application area is of the utmost importance. However, biomedical\ntraining has not been systematically evaluated on medical tasks. This study\ninvestigates the effect of biomedical training in the context of six practical\nmedical tasks evaluating $25$ models. In contrast to previous evaluations, our\nresults reveal a performance decline in nine out of twelve biomedical models\nafter fine-tuning, particularly on tasks involving hallucinations, ICD10\ncoding, and instruction adherence. General-domain models like\nMeta-Llama-3.1-70B-Instruct outperformed their biomedical counterparts,\nindicating a trade-off between domain-specific fine-tuning and general medical\ntask performance. We open-source all evaluation scripts and datasets at\nhttps://github.com/TIO-IKIM/CLUE to support further research in this critical\narea.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04067v4",
    "published_date": "2024-04-05 12:51:37 UTC",
    "updated_date": "2024-09-17 08:19:59 UTC"
  },
  {
    "arxiv_id": "2404.04057v3",
    "title": "Score identity Distillation: Exponentially Fast Distillation of Pretrained Diffusion Models for One-Step Generation",
    "authors": [
      "Mingyuan Zhou",
      "Huangjie Zheng",
      "Zhendong Wang",
      "Mingzhang Yin",
      "Hai Huang"
    ],
    "abstract": "We introduce Score identity Distillation (SiD), an innovative data-free\nmethod that distills the generative capabilities of pretrained diffusion models\ninto a single-step generator. SiD not only facilitates an exponentially fast\nreduction in Fr\\'echet inception distance (FID) during distillation but also\napproaches or even exceeds the FID performance of the original teacher\ndiffusion models. By reformulating forward diffusion processes as semi-implicit\ndistributions, we leverage three score-related identities to create an\ninnovative loss mechanism. This mechanism achieves rapid FID reduction by\ntraining the generator using its own synthesized images, eliminating the need\nfor real data or reverse-diffusion-based generation, all accomplished within\nsignificantly shortened generation time. Upon evaluation across four benchmark\ndatasets, the SiD algorithm demonstrates high iteration efficiency during\ndistillation and surpasses competing distillation approaches, whether they are\none-step or few-step, data-free, or dependent on training data, in terms of\ngeneration quality. This achievement not only redefines the benchmarks for\nefficiency and effectiveness in diffusion distillation but also in the broader\nfield of diffusion-based generation. The PyTorch implementation is available at\nhttps://github.com/mingyuanzhou/SiD",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024, PyTorch implementation:\n  https://github.com/mingyuanzhou/SiD",
    "pdf_url": "http://arxiv.org/pdf/2404.04057v3",
    "published_date": "2024-04-05 12:30:19 UTC",
    "updated_date": "2024-05-24 17:20:46 UTC"
  },
  {
    "arxiv_id": "2404.04313v1",
    "title": "JobFormer: Skill-Aware Job Recommendation with Semantic-Enhanced Transformer",
    "authors": [
      "Zhihao Guan",
      "Jia-Qi Yang",
      "Yang Yang",
      "Hengshu Zhu",
      "Wenjie Li",
      "Hui Xiong"
    ],
    "abstract": "Job recommendation aims to provide potential talents with suitable job\ndescriptions (JDs) consistent with their career trajectory, which plays an\nessential role in proactive talent recruitment. In real-world management\nscenarios, the available JD-user records always consist of JDs, user profiles,\nand click data, in which the user profiles are typically summarized as the\nuser's skill distribution for privacy reasons. Although existing sophisticated\nrecommendation methods can be directly employed, effective recommendation still\nhas challenges considering the information deficit of JD itself and the natural\nheterogeneous gap between JD and user profile. To address these challenges, we\nproposed a novel skill-aware recommendation model based on the designed\nsemantic-enhanced transformer to parse JDs and complete personalized job\nrecommendation. Specifically, we first model the relative items of each JD and\nthen adopt an encoder with the local-global attention mechanism to better mine\nthe intra-job and inter-job dependencies from JD tuples. Moreover, we adopt a\ntwo-stage learning strategy for skill-aware recommendation, in which we utilize\nthe skill distribution to guide JD representation learning in the recall stage,\nand then combine the user profiles for final prediction in the ranking stage.\nConsequently, we can embed rich contextual semantic representations for\nlearning JDs, while skill-aware recommendation provides effective JD-user joint\nrepresentation for click-through rate (CTR) prediction. To validate the\nsuperior performance of our method for job recommendation, we present a\nthorough empirical analysis of large-scale real-world and public datasets to\ndemonstrate its effectiveness and interpretability.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04313v1",
    "published_date": "2024-04-05 12:25:00 UTC",
    "updated_date": "2024-04-05 12:25:00 UTC"
  },
  {
    "arxiv_id": "2404.04312v1",
    "title": "Half-Space Feature Learning in Neural Networks",
    "authors": [
      "Mahesh Lorik Yadav",
      "Harish Guruprasad Ramaswamy",
      "Chandrashekar Lakshminarayanan"
    ],
    "abstract": "There currently exist two extreme viewpoints for neural network feature\nlearning -- (i) Neural networks simply implement a kernel method (a la NTK) and\nhence no features are learned (ii) Neural networks can represent (and hence\nlearn) intricate hierarchical features suitable for the data. We argue in this\npaper neither interpretation is likely to be correct based on a novel\nviewpoint. Neural networks can be viewed as a mixture of experts, where each\nexpert corresponds to a (number of layers length) path through a sequence of\nhidden units. We use this alternate interpretation to motivate a model, called\nthe Deep Linearly Gated Network (DLGN), which sits midway between deep linear\nnetworks and ReLU networks. Unlike deep linear networks, the DLGN is capable of\nlearning non-linear features (which are then linearly combined), and unlike\nReLU networks these features are ultimately simple -- each feature is\neffectively an indicator function for a region compactly described as an\nintersection of (number of layers) half-spaces in the input space. This\nviewpoint allows for a comprehensive global visualization of features, unlike\nthe local visualizations for neurons based on saliency/activation/gradient\nmaps. Feature learning in DLGNs is shown to happen and the mechanism with which\nthis happens is through learning half-spaces in the input space that contain\nsmooth regions of the target function. Due to the structure of DLGNs, the\nneurons in later layers are fundamentally the same as those in earlier layers\n-- they all represent a half-space -- however, the dynamics of gradient descent\nimpart a distinct clustering to the later layer neurons. We hypothesize that\nReLU networks also have similar feature learning behaviour.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04312v1",
    "published_date": "2024-04-05 12:03:19 UTC",
    "updated_date": "2024-04-05 12:03:19 UTC"
  },
  {
    "arxiv_id": "2404.04311v1",
    "title": "A Real-time Anomaly Detection Using Convolutional Autoencoder with Dynamic Threshold",
    "authors": [
      "Sarit Maitra",
      "Sukanya Kundu",
      "Aishwarya Shankar"
    ],
    "abstract": "The majority of modern consumer-level energy is generated by real-time smart\nmetering systems. These frequently contain anomalies, which prevent reliable\nestimates of the series' evolution. This work introduces a hybrid modeling\napproach combining statistics and a Convolutional Autoencoder with a dynamic\nthreshold. The threshold is determined based on Mahalanobis distance and moving\naverages. It has been tested using real-life energy consumption data collected\nfrom smart metering systems. The solution includes a real-time, meter-level\nanomaly detection system that connects to an advanced monitoring system. This\nmakes a substantial contribution by detecting unusual data movements and\ndelivering an early warning. Early detection and subsequent troubleshooting can\nfinancially benefit organizations and consumers and prevent disasters from\noccurring.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04311v1",
    "published_date": "2024-04-05 11:03:36 UTC",
    "updated_date": "2024-04-05 11:03:36 UTC"
  },
  {
    "arxiv_id": "2404.14416v1",
    "title": "Conditional diffusion models for downscaling & bias correction of Earth system model precipitation",
    "authors": [
      "Michael Aich",
      "Philipp Hess",
      "Baoxiang Pan",
      "Sebastian Bathiany",
      "Yu Huang",
      "Niklas Boers"
    ],
    "abstract": "Climate change exacerbates extreme weather events like heavy rainfall and\nflooding. As these events cause severe losses of property and lives, accurate\nhigh-resolution simulation of precipitation is imperative. However, existing\nEarth System Models (ESMs) struggle with resolving small-scale dynamics and\nsuffer from biases, especially for extreme events. Traditional statistical bias\ncorrection and downscaling methods fall short in improving spatial structure,\nwhile recent deep learning methods lack controllability over the output and\nsuffer from unstable training. Here, we propose a novel machine learning\nframework for simultaneous bias correction and downscaling. We train a\ngenerative diffusion model in a supervised way purely on observational data. We\nmap observational and ESM data to a shared embedding space, where both are\nunbiased towards each other and train a conditional diffusion model to reverse\nthe mapping. Our method can be used to correct any ESM field, as the training\nis independent of the ESM. Our approach ensures statistical fidelity, preserves\nlarge-scale spatial patterns and outperforms existing methods especially\nregarding extreme events and small-scale spatial features that are crucial for\nimpact assessments.",
    "categories": [
      "physics.geo-ph",
      "cs.AI",
      "cs.LG",
      "physics.ao-ph"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14416v1",
    "published_date": "2024-04-05 11:01:50 UTC",
    "updated_date": "2024-04-05 11:01:50 UTC"
  },
  {
    "arxiv_id": "2404.04310v1",
    "title": "Suppressing Modulation Instability with Reinforcement Learning",
    "authors": [
      "Nikolay Kalmykov",
      "Rishat Zagidullin",
      "Oleg Rogov",
      "Sergey Rykovanov",
      "Dmitry V. Dylov"
    ],
    "abstract": "Modulation instability is a phenomenon of spontaneous pattern formation in\nnonlinear media, oftentimes leading to an unpredictable behaviour and a\ndegradation of a signal of interest. We propose an approach based on\nreinforcement learning to suppress the unstable modes by optimizing the\nparameters for the time modulation of the potential in the nonlinear system. We\ntest our approach in 1D and 2D cases and propose a new class of\nphysically-meaningful reward functions to guarantee tamed instability.",
    "categories": [
      "nlin.PS",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "physics.app-ph"
    ],
    "primary_category": "nlin.PS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04310v1",
    "published_date": "2024-04-05 10:29:18 UTC",
    "updated_date": "2024-04-05 10:29:18 UTC"
  },
  {
    "arxiv_id": "2404.04001v1",
    "title": "Approximate UMAP allows for high-rate online visualization of high-dimensional data streams",
    "authors": [
      "Peter Wassenaar",
      "Pierre Guetschel",
      "Michael Tangermann"
    ],
    "abstract": "In the BCI field, introspection and interpretation of brain signals are\ndesired for providing feedback or to guide rapid paradigm prototyping but are\nchallenging due to the high noise level and dimensionality of the signals. Deep\nneural networks are often introspected by transforming their learned feature\nrepresentations into 2- or 3-dimensional subspace visualizations using\nprojection algorithms like Uniform Manifold Approximation and Projection\n(UMAP). Unfortunately, these methods are computationally expensive, making the\nprojection of data streams in real-time a non-trivial task. In this study, we\nintroduce a novel variant of UMAP, called approximate UMAP (aUMAP). It aims at\ngenerating rapid projections for real-time introspection. To study its\nsuitability for real-time projecting, we benchmark the methods against standard\nUMAP and its neural network counterpart parametric UMAP. Our results show that\napproximate UMAP delivers projections that replicate the projection space of\nstandard UMAP while decreasing projection speed by an order of magnitude and\nmaintaining the same training time.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "eess.SP",
      "I.5.3; I.5.3; J.4"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 3 figures, submitted to the Graz BCI conference 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04001v1",
    "published_date": "2024-04-05 10:25:26 UTC",
    "updated_date": "2024-04-05 10:25:26 UTC"
  },
  {
    "arxiv_id": "2404.03997v1",
    "title": "Demonstration Guided Multi-Objective Reinforcement Learning",
    "authors": [
      "Junlin Lu",
      "Patrick Mannion",
      "Karl Mason"
    ],
    "abstract": "Multi-objective reinforcement learning (MORL) is increasingly relevant due to\nits resemblance to real-world scenarios requiring trade-offs between multiple\nobjectives. Catering to diverse user preferences, traditional reinforcement\nlearning faces amplified challenges in MORL. To address the difficulty of\ntraining policies from scratch in MORL, we introduce demonstration-guided\nmulti-objective reinforcement learning (DG-MORL). This novel approach utilizes\nprior demonstrations, aligns them with user preferences via corner weight\nsupport, and incorporates a self-evolving mechanism to refine suboptimal\ndemonstrations. Our empirical studies demonstrate DG-MORL's superiority over\nexisting MORL algorithms, establishing its robustness and efficacy,\nparticularly under challenging conditions. We also provide an upper bound of\nthe algorithm's sample complexity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03997v1",
    "published_date": "2024-04-05 10:19:04 UTC",
    "updated_date": "2024-04-05 10:19:04 UTC"
  },
  {
    "arxiv_id": "2404.03996v1",
    "title": "Fast Genetic Algorithm for feature selection -- A qualitative approximation approach",
    "authors": [
      "Mohammed Ghaith Altarabichi",
      "Sławomir Nowaczyk",
      "Sepideh Pashami",
      "Peyman Sheikholharam Mashhadi"
    ],
    "abstract": "Evolutionary Algorithms (EAs) are often challenging to apply in real-world\nsettings since evolutionary computations involve a large number of evaluations\nof a typically expensive fitness function. For example, an evaluation could\ninvolve training a new machine learning model. An approximation (also known as\nmeta-model or a surrogate) of the true function can be used in such\napplications to alleviate the computation cost. In this paper, we propose a\ntwo-stage surrogate-assisted evolutionary approach to address the computational\nissues arising from using Genetic Algorithm (GA) for feature selection in a\nwrapper setting for large datasets. We define 'Approximation Usefulness' to\ncapture the necessary conditions to ensure correctness of the EA computations\nwhen an approximation is used. Based on this definition, we propose a procedure\nto construct a lightweight qualitative meta-model by the active selection of\ndata instances. We then use a meta-model to carry out the feature selection\ntask. We apply this procedure to the GA-based algorithm CHC (Cross generational\nelitist selection, Heterogeneous recombination and Cataclysmic mutation) to\ncreate a Qualitative approXimations variant, CHCQX. We show that CHCQX\nconverges faster to feature subset solutions of significantly higher accuracy\n(as compared to CHC), particularly for large datasets with over 100K instances.\nWe also demonstrate the applicability of the thinking behind our approach more\nbroadly to Swarm Intelligence (SI), another branch of the Evolutionary\nComputation (EC) paradigm with results of PSOQX, a qualitative approximation\nadaptation of the Particle Swarm Optimization (PSO) method. A GitHub repository\nwith the complete implementation is available.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03996v1",
    "published_date": "2024-04-05 10:15:24 UTC",
    "updated_date": "2024-04-05 10:15:24 UTC"
  },
  {
    "arxiv_id": "2404.03995v1",
    "title": "Balancing Progress and Responsibility: A Synthesis of Sustainability Trade-Offs of AI-Based Systems",
    "authors": [
      "Apoorva Nalini Pradeep Kumar",
      "Justus Bogner",
      "Markus Funke",
      "Patricia Lago"
    ],
    "abstract": "Recent advances in artificial intelligence (AI) capabilities have increased\nthe eagerness of companies to integrate AI into software systems. While AI can\nbe used to have a positive impact on several dimensions of sustainability, this\nis often overshadowed by its potential negative influence. While many studies\nhave explored sustainability factors in isolation, there is insufficient\nholistic coverage of potential sustainability benefits or costs that\npractitioners need to consider during decision-making for AI adoption. We\ntherefore aim to synthesize trade-offs related to sustainability in the context\nof integrating AI into software systems. We want to make the sustainability\nbenefits and costs of integrating AI more transparent and accessible for\npractitioners.\n  The study was conducted in collaboration with a Dutch financial organization.\nWe first performed a rapid review that led to the inclusion of 151 research\npapers. Afterward, we conducted six semi-structured interviews to enrich the\ndata with industry perspectives. The combined results showcase the potential\nsustainability benefits and costs of integrating AI. The labels synthesized\nfrom the review regarding potential sustainability benefits were clustered into\n16 themes, with \"energy management\" being the most frequently mentioned one. 11\nthemes were identified in the interviews, with the top mentioned theme being\n\"employee wellbeing\". Regarding sustainability costs, the review discovered\nseven themes, with \"deployment issues\" being the most popular one, followed by\n\"ethics & society\". \"Environmental issues\" was the top theme from the\ninterviews. Our results provide valuable insights to organizations and\npractitioners for understanding the potential sustainability implications of\nadopting AI.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for publication at the 8th International Workshop on Green\n  and Sustainable Software (GREENS'24), collocated with ICSA'24",
    "pdf_url": "http://arxiv.org/pdf/2404.03995v1",
    "published_date": "2024-04-05 10:11:08 UTC",
    "updated_date": "2024-04-05 10:11:08 UTC"
  },
  {
    "arxiv_id": "2404.03992v1",
    "title": "Rolling the dice for better deep learning performance: A study of randomness techniques in deep neural networks",
    "authors": [
      "Mohammed Ghaith Altarabichi",
      "Sławomir Nowaczyk",
      "Sepideh Pashami",
      "Peyman Sheikholharam Mashhadi",
      "Julia Handl"
    ],
    "abstract": "This paper investigates how various randomization techniques impact Deep\nNeural Networks (DNNs). Randomization, like weight noise and dropout, aids in\nreducing overfitting and enhancing generalization, but their interactions are\npoorly understood. The study categorizes randomness techniques into four types\nand proposes new methods: adding noise to the loss function and random masking\nof gradient updates. Using Particle Swarm Optimizer (PSO) for hyperparameter\noptimization, it explores optimal configurations across MNIST, FASHION-MNIST,\nCIFAR10, and CIFAR100 datasets. Over 30,000 configurations are evaluated,\nrevealing data augmentation and weight initialization randomness as main\nperformance contributors. Correlation analysis shows different optimizers\nprefer distinct randomization types. The complete implementation and dataset\nare available on GitHub.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03992v1",
    "published_date": "2024-04-05 10:02:32 UTC",
    "updated_date": "2024-04-05 10:02:32 UTC"
  },
  {
    "arxiv_id": "2404.03978v2",
    "title": "Random Walk in Random Permutation Set Theory",
    "authors": [
      "Jiefeng Zhou",
      "Zhen Li",
      "Yong Deng"
    ],
    "abstract": "Random walk is an explainable approach for modeling natural processes at the\nmolecular level. The Random Permutation Set Theory (RPST) serves as a framework\nfor uncertainty reasoning, extending the applicability of Dempster-Shafer\nTheory. Recent explorations indicate a promising link between RPST and random\nwalk. In this study, we conduct an analysis and construct a random walk model\nbased on the properties of RPST, with Monte Carlo simulations of such random\nwalk. Our findings reveal that the random walk generated through RPST exhibits\ncharacteristics similar to those of a Gaussian random walk and can be\ntransformed into a Wiener process through a specific limiting scaling\nprocedure. This investigation establishes a novel connection between RPST and\nrandom walk theory, thereby not only expanding the applicability of RPST, but\nalso demonstrating the potential for combining the strengths of both approaches\nto improve problem-solving abilities.",
    "categories": [
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.AI",
    "comment": "27 pages, 8 figures; references added",
    "pdf_url": "http://arxiv.org/pdf/2404.03978v2",
    "published_date": "2024-04-05 09:19:55 UTC",
    "updated_date": "2024-04-22 15:18:14 UTC"
  },
  {
    "arxiv_id": "2404.04308v1",
    "title": "Visual Knowledge in the Big Model Era: Retrospect and Prospect",
    "authors": [
      "Wenguan Wang",
      "Yi Yang",
      "Yunhe Pan"
    ],
    "abstract": "Visual knowledge is a new form of knowledge representation that can\nencapsulate visual concepts and their relations in a succinct, comprehensive,\nand interpretable manner, with a deep root in cognitive psychology. As the\nknowledge about the visual world has been identified as an indispensable\ncomponent of human cognition and intelligence, visual knowledge is poised to\nhave a pivotal role in establishing machine intelligence. With the recent\nadvance of Artificial Intelligence (AI) techniques, large AI models (or\nfoundation models) have emerged as a potent tool capable of extracting\nversatile patterns from broad data as implicit knowledge, and abstracting them\ninto an outrageous amount of numeric parameters. To pave the way for creating\nvisual knowledge empowered AI machines in this coming wave, we present a timely\nreview that investigates the origins and development of visual knowledge in the\npre-big model era, and accentuates the opportunities and unique role of visual\nknowledge in the big model era.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04308v1",
    "published_date": "2024-04-05 07:31:24 UTC",
    "updated_date": "2024-04-05 07:31:24 UTC"
  },
  {
    "arxiv_id": "2404.04306v1",
    "title": "AuditGPT: Auditing Smart Contracts with ChatGPT",
    "authors": [
      "Shihao Xia",
      "Shuai Shao",
      "Mengting He",
      "Tingting Yu",
      "Linhai Song",
      "Yiying Zhang"
    ],
    "abstract": "To govern smart contracts running on Ethereum, multiple Ethereum Request for\nComment (ERC) standards have been developed, each containing a set of rules to\nguide the behaviors of smart contracts. Violating the ERC rules could cause\nserious security issues and financial loss, signifying the importance of\nverifying smart contracts follow ERCs. Today's practices of such verification\nare to either manually audit each single contract or use expert-developed,\nlimited-scope program-analysis tools, both of which are far from being\neffective in identifying ERC rule violations. This paper presents a tool named\nAuditGPT that leverages large language models (LLMs) to automatically and\ncomprehensively verify ERC rules against smart contracts. To build AuditGPT, we\nfirst conduct an empirical study on 222 ERC rules specified in four popular\nERCs to understand their content, their security impacts, their specification\nin natural language, and their implementation in Solidity. Guided by the study,\nwe construct AuditGPT by separating the large, complex auditing process into\nsmall, manageable tasks and design prompts specialized for each ERC rule type\nto enhance LLMs' auditing performance. In the evaluation, AuditGPT successfully\npinpoints 418 ERC rule violations and only reports 18 false positives,\nshowcasing its effectiveness and accuracy. Moreover, AuditGPT beats an auditing\nservice provided by security experts in effectiveness, accuracy, and cost,\ndemonstrating its advancement over state-of-the-art smart-contract auditing\npractices.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04306v1",
    "published_date": "2024-04-05 07:19:13 UTC",
    "updated_date": "2024-04-05 07:19:13 UTC"
  },
  {
    "arxiv_id": "2404.03913v1",
    "title": "Concept Weaver: Enabling Multi-Concept Fusion in Text-to-Image Models",
    "authors": [
      "Gihyun Kwon",
      "Simon Jenni",
      "Dingzeyu Li",
      "Joon-Young Lee",
      "Jong Chul Ye",
      "Fabian Caba Heilbron"
    ],
    "abstract": "While there has been significant progress in customizing text-to-image\ngeneration models, generating images that combine multiple personalized\nconcepts remains challenging. In this work, we introduce Concept Weaver, a\nmethod for composing customized text-to-image diffusion models at inference\ntime. Specifically, the method breaks the process into two steps: creating a\ntemplate image aligned with the semantics of input prompts, and then\npersonalizing the template using a concept fusion strategy. The fusion strategy\nincorporates the appearance of the target concepts into the template image\nwhile retaining its structural details. The results indicate that our method\ncan generate multiple custom concepts with higher identity fidelity compared to\nalternative approaches. Furthermore, the method is shown to seamlessly handle\nmore than two concepts and closely follow the semantic meaning of the input\nprompt without blending appearances across different subjects.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.03913v1",
    "published_date": "2024-04-05 06:41:27 UTC",
    "updated_date": "2024-04-05 06:41:27 UTC"
  },
  {
    "arxiv_id": "2404.03912v1",
    "title": "Forget NLI, Use a Dictionary: Zero-Shot Topic Classification for Low-Resource Languages with Application to Luxembourgish",
    "authors": [
      "Fred Philippy",
      "Shohreh Haddadan",
      "Siwen Guo"
    ],
    "abstract": "In NLP, zero-shot classification (ZSC) is the task of assigning labels to\ntextual data without any labeled examples for the target classes. A common\nmethod for ZSC is to fine-tune a language model on a Natural Language Inference\n(NLI) dataset and then use it to infer the entailment between the input\ndocument and the target labels. However, this approach faces certain\nchallenges, particularly for languages with limited resources. In this paper,\nwe propose an alternative solution that leverages dictionaries as a source of\ndata for ZSC. We focus on Luxembourgish, a low-resource language spoken in\nLuxembourg, and construct two new topic relevance classification datasets based\non a dictionary that provides various synonyms, word translations and example\nsentences. We evaluate the usability of our dataset and compare it with the\nNLI-based approach on two topic classification tasks in a zero-shot manner. Our\nresults show that by using the dictionary-based dataset, the trained models\noutperform the ones following the NLI-based approach for ZSC. While we focus on\na single low-resource language in this study, we believe that the efficacy of\nour approach can also transfer to other languages where such a dictionary is\navailable.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "3rd Annual Meeting of the ELRA/ISCA Special Interest Group on\n  Under-resourced Languages (SIGUL 2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.03912v1",
    "published_date": "2024-04-05 06:35:31 UTC",
    "updated_date": "2024-04-05 06:35:31 UTC"
  },
  {
    "arxiv_id": "2404.03908v1",
    "title": "Multi-Task Learning for Lung sound & Lung disease classification",
    "authors": [
      "Suma K V",
      "Deepali Koppad",
      "Preethi Kumar",
      "Neha A Kantikar",
      "Surabhi Ramesh"
    ],
    "abstract": "In recent years, advancements in deep learning techniques have considerably\nenhanced the efficiency and accuracy of medical diagnostics. In this work, a\nnovel approach using multi-task learning (MTL) for the simultaneous\nclassification of lung sounds and lung diseases is proposed. Our proposed model\nleverages MTL with four different deep learning models such as 2D CNN,\nResNet50, MobileNet and Densenet to extract relevant features from the lung\nsound recordings. The ICBHI 2017 Respiratory Sound Database was employed in the\ncurrent study. The MTL for MobileNet model performed better than the other\nmodels considered, with an accuracy of74\\% for lung sound analysis and 91\\% for\nlung diseases classification. Results of the experimentation demonstrate the\nefficacy of our approach in classifying both lung sounds and lung diseases\nconcurrently.\n  In this study,using the demographic data of the patients from the database,\nrisk level computation for Chronic Obstructive Pulmonary Disease is also\ncarried out. For this computation, three machine learning algorithms namely\nLogistic Regression, SVM and Random Forest classifierswere employed. Among\nthese ML algorithms, the Random Forest classifier had the highest accuracy of\n92\\%.This work helps in considerably reducing the physician's burden of not\njust diagnosing the pathology but also effectively communicating to the patient\nabout the possible causes or outcomes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03908v1",
    "published_date": "2024-04-05 06:15:58 UTC",
    "updated_date": "2024-04-05 06:15:58 UTC"
  },
  {
    "arxiv_id": "2404.03900v1",
    "title": "Nonparametric Modern Hopfield Models",
    "authors": [
      "Jerry Yao-Chieh Hu",
      "Bo-Yu Chen",
      "Dennis Wu",
      "Feng Ruan",
      "Han Liu"
    ],
    "abstract": "We present a nonparametric construction for deep learning compatible modern\nHopfield models and utilize this framework to debut an efficient variant. Our\nkey contribution stems from interpreting the memory storage and retrieval\nprocesses in modern Hopfield models as a nonparametric regression problem\nsubject to a set of query-memory pairs. Crucially, our framework not only\nrecovers the known results from the original dense modern Hopfield model but\nalso fills the void in the literature regarding efficient modern Hopfield\nmodels, by introducing \\textit{sparse-structured} modern Hopfield models with\nsub-quadratic complexity. We establish that this sparse model inherits the\nappealing theoretical properties of its dense analogue -- connection with\ntransformer attention, fixed point convergence and exponential memory capacity\n-- even without knowing details of the Hopfield energy function. Additionally,\nwe showcase the versatility of our framework by constructing a family of modern\nHopfield models as extensions, including linear, random masked, top-$K$ and\npositive random feature modern Hopfield models. Empirically, we validate the\nefficacy of our framework in both synthetic and realistic settings.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "stat.ML",
    "comment": "59 pages; Code available at\n  https://github.com/MAGICS-LAB/NonparametricHopfield",
    "pdf_url": "http://arxiv.org/pdf/2404.03900v1",
    "published_date": "2024-04-05 05:46:20 UTC",
    "updated_date": "2024-04-05 05:46:20 UTC"
  },
  {
    "arxiv_id": "2404.08672v3",
    "title": "Taxonomy and Analysis of Sensitive User Queries in Generative AI Search",
    "authors": [
      "Hwiyeol Jo",
      "Taiwoo Park",
      "Hyunwoo Lee",
      "Nayoung Choi",
      "Changbong Kim",
      "Ohjoon Kwon",
      "Donghyeon Jeon",
      "Eui-Hyeon Lee",
      "Kyoungho Shin",
      "Sun Suk Lim",
      "Kyungmi Kim",
      "Jihye Lee",
      "Sun Kim"
    ],
    "abstract": "Although there has been a growing interest among industries in integrating\ngenerative LLMs into their services, limited experience and scarcity of\nresources act as a barrier in launching and servicing large-scale LLM-based\nservices. In this paper, we share our experiences in developing and operating\ngenerative AI models within a national-scale search engine, with a specific\nfocus on the sensitiveness of user queries. We propose a taxonomy for sensitive\nsearch queries, outline our approaches, and present a comprehensive analysis\nreport on sensitive queries from actual users. We believe that our experiences\nin launching generative AI search systems can contribute to reducing the\nbarrier in building generative LLM-based services.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "NAACL2025(Findings), corrected typo in co-corresponding authors",
    "pdf_url": "http://arxiv.org/pdf/2404.08672v3",
    "published_date": "2024-04-05 05:14:46 UTC",
    "updated_date": "2025-04-16 18:59:52 UTC"
  },
  {
    "arxiv_id": "2404.03894v1",
    "title": "Holon: a cybernetic interface for bio-semiotics",
    "authors": [
      "Jon McCormack",
      "Elliott Wilson"
    ],
    "abstract": "This paper presents an interactive artwork, \"Holon\", a collection of 130\nautonomous, cybernetic organisms that listen and make sound in collaboration\nwith the natural environment. The work was developed for installation on water\nat a heritage-listed dock in Melbourne, Australia. Conceptual issues informing\nthe work are presented, along with a detailed technical overview of the\nimplementation. Individual holons are of three types, inspired by biological\nmodels of animal communication: composer/generators, collector/critics and\ndisruptors. Collectively, Holon integrates and occupies elements of the\nacoustic spectrum in collaboration with human and non-human agents.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MA",
      "eess.AS",
      "I.2.11; J.5"
    ],
    "primary_category": "cs.SD",
    "comment": "Paper accepted at ISEA 24, The 29th International Symposium on\n  Electronic Art, Brisbane, Australia, 21-29 June 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.03894v1",
    "published_date": "2024-04-05 05:03:39 UTC",
    "updated_date": "2024-04-05 05:03:39 UTC"
  },
  {
    "arxiv_id": "2404.03893v1",
    "title": "KGExplainer: Towards Exploring Connected Subgraph Explanations for Knowledge Graph Completion",
    "authors": [
      "Tengfei Ma",
      "Xiang song",
      "Wen Tao",
      "Mufei Li",
      "Jiani Zhang",
      "Xiaoqin Pan",
      "Jianxin Lin",
      "Bosheng Song",
      "xiangxiang Zeng"
    ],
    "abstract": "Knowledge graph completion (KGC) aims to alleviate the inherent\nincompleteness of knowledge graphs (KGs), which is a critical task for various\napplications, such as recommendations on the web. Although knowledge graph\nembedding (KGE) models have demonstrated superior predictive performance on KGC\ntasks, these models infer missing links in a black-box manner that lacks\ntransparency and accountability, preventing researchers from developing\naccountable models. Existing KGE-based explanation methods focus on exploring\nkey paths or isolated edges as explanations, which is information-less to\nreason target prediction. Additionally, the missing ground truth leads to these\nexplanation methods being ineffective in quantitatively evaluating explored\nexplanations. To overcome these limitations, we propose KGExplainer, a\nmodel-agnostic method that identifies connected subgraph explanations and\ndistills an evaluator to assess them quantitatively. KGExplainer employs a\nperturbation-based greedy search algorithm to find key connected subgraphs as\nexplanations within the local structure of target predictions. To evaluate the\nquality of the explored explanations, KGExplainer distills an evaluator from\nthe target KGE model. By forwarding the explanations to the evaluator, our\nmethod can examine the fidelity of them. Extensive experiments on benchmark\ndatasets demonstrate that KGExplainer yields promising improvement and achieves\nan optimal ratio of 83.3% in human evaluation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 7 figures, 11 tables. Under Review",
    "pdf_url": "http://arxiv.org/pdf/2404.03893v1",
    "published_date": "2024-04-05 05:02:12 UTC",
    "updated_date": "2024-04-05 05:02:12 UTC"
  },
  {
    "arxiv_id": "2404.03892v3",
    "title": "Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI",
    "authors": [
      "Maryam Ahmed",
      "Tooba Bibi",
      "Rizwan Ahmed Khan",
      "Sidra Nasir"
    ],
    "abstract": "The Deep learning (DL) models for diagnosing breast cancer from mammographic\nimages often operate as \"black boxes\", making it difficult for healthcare\nprofessionals to trust and understand their decision-making processes. The\nstudy presents an integrated framework combining Convolutional Neural Networks\n(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis\nof breast cancer using the CBIS-DDSM dataset. The methodology encompasses an\nelaborate data preprocessing pipeline and advanced data augmentation techniques\nto counteract dataset limitations and transfer learning using pre-trained\nnetworks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of\nour study is the evaluation of XAI's effectiveness in interpreting model\npredictions, highlighted by utilizing the Hausdorff measure to assess the\nalignment between AI-generated explanations and expert annotations\nquantitatively. This approach is critical for XAI in promoting trustworthiness\nand ethical fairness in AI-assisted diagnostics. The findings from our research\nillustrate the effective collaboration between CNNs and XAI in advancing\ndiagnostic methods for breast cancer, thereby facilitating a more seamless\nintegration of advanced AI technologies within clinical settings. By enhancing\nthe interpretability of AI driven decisions, this work lays the groundwork for\nimproved collaboration between AI systems and medical practitioners, ultimately\nenriching patient care. Furthermore, the implications of our research extended\nwell beyond the current methodologies. It encourages further research into how\nto combine multimodal data and improve AI explanations to meet the needs of\nclinical practice.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03892v3",
    "published_date": "2024-04-05 05:00:21 UTC",
    "updated_date": "2024-04-27 08:24:37 UTC"
  },
  {
    "arxiv_id": "2404.03891v1",
    "title": "Can only LLMs do Reasoning?: Potential of Small Language Models in Task Planning",
    "authors": [
      "Gawon Choi",
      "Hyemin Ahn"
    ],
    "abstract": "In robotics, the use of Large Language Models (LLMs) is becoming prevalent,\nespecially for understanding human commands. In particular, LLMs are utilized\nas domain-agnostic task planners for high-level human commands. LLMs are\ncapable of Chain-of-Thought (CoT) reasoning, and this allows LLMs to be task\nplanners. However, we need to consider that modern robots still struggle to\nperform complex actions, and the domains where robots can be deployed are\nlimited in practice. This leads us to pose a question: If small LMs can be\ntrained to reason in chains within a single domain, would even small LMs be\ngood task planners for the robots? To train smaller LMs to reason in chains, we\nbuild `COmmand-STeps datasets' (COST) consisting of high-level commands along\nwith corresponding actionable low-level steps, via LLMs. We release not only\nour datasets but also the prompt templates used to generate them, to allow\nanyone to build datasets for their domain. We compare GPT3.5 and GPT4 with the\nfinetuned GPT2 for task domains, in tabletop and kitchen environments, and the\nresult shows that GPT2-medium is comparable to GPT3.5 for task planning in a\nspecific domain. Our dataset, code, and more output samples can be found in\nhttps://github.com/Gawon-Choi/small-LMs-Task-Planning",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.03891v1",
    "published_date": "2024-04-05 04:58:34 UTC",
    "updated_date": "2024-04-05 04:58:34 UTC"
  },
  {
    "arxiv_id": "2404.03888v2",
    "title": "A proximal policy optimization based intelligent home solar management",
    "authors": [
      "Kode Creer",
      "Imitiaz Parvez"
    ],
    "abstract": "In the smart grid, the prosumers can sell unused electricity back to the\npower grid, assuming the prosumers own renewable energy sources and storage\nunits. The maximizing of their profits under a dynamic electricity market is a\nproblem that requires intelligent planning. To address this, we propose a\nframework based on Proximal Policy Optimization (PPO) using recurrent rewards.\nBy using the information about the rewards modeled effectively with PPO to\nmaximize our objective, we were able to get over 30\\% improvement over the\nother naive algorithms in accumulating total profits. This shows promise in\ngetting reinforcement learning algorithms to perform tasks required to plan\ntheir actions in complex domains like financial markets. We also introduce a\nnovel method for embedding longs based on soliton waves that outperformed\nnormal embedding in our use case with random floating point data augmentation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This manuscript has been accepted for IEEE EIT Conference",
    "pdf_url": "http://arxiv.org/pdf/2404.03888v2",
    "published_date": "2024-04-05 04:34:43 UTC",
    "updated_date": "2024-05-09 03:51:01 UTC"
  },
  {
    "arxiv_id": "2404.03887v4",
    "title": "SAAS: Solving Ability Amplification Strategy for Enhanced Mathematical Reasoning in Large Language Models",
    "authors": [
      "Hyeonwoo Kim",
      "Gyoungjin Gim",
      "Yungi Kim",
      "Jihoo Kim",
      "Byungju Kim",
      "Wonseok Lee",
      "Chanjun Park"
    ],
    "abstract": "This study presents a novel learning approach designed to enhance both\nmathematical reasoning and problem-solving abilities of Large Language Models\n(LLMs). We focus on integrating the Chain-of-Thought (CoT) and the\nProgram-of-Thought (PoT) learning, hypothesizing that prioritizing the learning\nof mathematical reasoning ability is helpful for the amplification of\nproblem-solving ability. Thus, the initial learning with CoT is essential for\nsolving challenging mathematical problems. To this end, we propose a sequential\nlearning approach, named SAAS (Solving Ability Amplification Strategy), which\nstrategically transitions from CoT learning to PoT learning. Our empirical\nstudy, involving an extensive performance comparison using several benchmarks,\ndemonstrates that our SAAS achieves state-of-the-art (SOTA) performance. The\nresults underscore the effectiveness of our sequential learning approach,\nmarking a significant advancement in the field of mathematical reasoning in\nLLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 Industry Track",
    "pdf_url": "http://arxiv.org/pdf/2404.03887v4",
    "published_date": "2024-04-05 04:25:47 UTC",
    "updated_date": "2024-10-02 11:56:35 UTC"
  },
  {
    "arxiv_id": "2404.03869v2",
    "title": "Heterogeneous Multi-Agent Reinforcement Learning for Zero-Shot Scalable Collaboration",
    "authors": [
      "Xudong Guo",
      "Daming Shi",
      "Junjie Yu",
      "Wenhui Fan"
    ],
    "abstract": "The emergence of multi-agent reinforcement learning (MARL) is significantly\ntransforming various fields like autonomous vehicle networks. However,\nreal-world multi-agent systems typically contain multiple roles, and the scale\nof these systems dynamically fluctuates. Consequently, in order to achieve\nzero-shot scalable collaboration, it is essential that strategies for different\nroles can be updated flexibly according to the scales, which is still a\nchallenge for current MARL frameworks. To address this, we propose a novel MARL\nframework named Scalable and Heterogeneous Proximal Policy Optimization\n(SHPPO), integrating heterogeneity into parameter-shared PPO-based MARL\nnetworks. We first leverage a latent network to learn strategy patterns for\neach agent adaptively. Second, we introduce a heterogeneous layer to be\ninserted into decision-making networks, whose parameters are specifically\ngenerated by the learned latent variables. Our approach is scalable as all the\nparameters are shared except for the heterogeneous layer, and gains both\ninter-individual and temporal heterogeneity, allowing SHPPO to adapt\neffectively to varying scales. SHPPO exhibits superior performance in classic\nMARL environments like Starcraft Multi-Agent Challenge (SMAC) and Google\nResearch Football (GRF), showcasing enhanced zero-shot scalability, and\noffering insights into the learned latent variables' impact on team performance\nby visualization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03869v2",
    "published_date": "2024-04-05 03:02:57 UTC",
    "updated_date": "2024-10-02 14:52:13 UTC"
  },
  {
    "arxiv_id": "2404.03868v2",
    "title": "Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction",
    "authors": [
      "Bowen Zhang",
      "Harold Soh"
    ],
    "abstract": "In this work, we are interested in automated methods for knowledge graph\ncreation (KGC) from input text. Progress on large language models (LLMs) has\nprompted a series of recent works applying them to KGC, e.g., via zero/few-shot\nprompting. Despite successes on small domain-specific datasets, these models\nface difficulties scaling up to text common in many real-world applications. A\nprincipal issue is that, in prior methods, the KG schema has to be included in\nthe LLM prompt to generate valid triplets; larger and more complex schemas\neasily exceed the LLMs' context window length. Furthermore, there are scenarios\nwhere a fixed pre-defined schema is not available and we would like the method\nto construct a high-quality KG with a succinct self-generated schema. To\naddress these problems, we propose a three-phase framework named\nExtract-Define-Canonicalize (EDC): open information extraction followed by\nschema definition and post-hoc canonicalization. EDC is flexible in that it can\nbe applied to settings where a pre-defined target schema is available and when\nit is not; in the latter case, it constructs a schema automatically and applies\nself-canonicalization. To further improve performance, we introduce a trained\ncomponent that retrieves schema elements relevant to the input text; this\nimproves the LLMs' extraction performance in a retrieval-augmented\ngeneration-like manner. We demonstrate on three KGC benchmarks that EDC is able\nto extract high-quality triplets without any parameter tuning and with\nsignificantly larger schemas compared to prior works. Code for EDC is available\nat https://github.com/clear-nus/edc.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 3 figures, Proceedings of the 2024 Conference on Empirical\n  Methods in Natural Language Processing",
    "pdf_url": "http://arxiv.org/pdf/2404.03868v2",
    "published_date": "2024-04-05 02:53:51 UTC",
    "updated_date": "2024-10-02 05:51:53 UTC"
  }
]