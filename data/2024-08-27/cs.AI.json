{
  "date": "2024-08-27",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-27 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 和机器学习的创新应用，包括大型语言模型的优化（如 Mamba 和 LLaMA 系列）、视觉语言模型在遥感和游戏中的潜力，以及强化学习在医疗和网络安全中的进展，令人印象深刻的包括 Susan Murphy 的强化学习算法和扩散模型用于实时游戏引擎的设计。\n\n### AI 语言模型与优化\n这些论文探讨了大型语言模型的提升和应用，强调了高效训练和鲁棒性改进。\n- **The Mamba in the Llama: Distilling and Accelerating Hybrid Models（Mamba in Llama: 蒸馏和加速混合模型）**：提出将 Transformer 模型蒸馏到线性 RNN（如 Mamba），实现高效推理，显著提升了 Llama3-8B 在聊天基准上的性能，并在 AlpacaEval 2 和 MT-Bench 上达到新高。\n- **BaichuanSEED: Sharing the Potential of ExtensivE Data Collection and Deduplication by Introducing a Competitive Large Language Model Baseline（BaichuanSEED: 通过引入竞争性大型语言模型基准共享大规模数据收集和去重的潜力）**：介绍一个通用数据处理管道和 7B 模型，实现了高效的预训练和微调，在基准测试中与 Qwen 和 Llama3 相当，展示了数据处理对模型性能的关键作用。\n- **Diffusion Models Are Real-Time Game Engines（扩散模型作为实时游戏引擎）**：创新地将扩散模型应用于游戏引擎，实现 20 FPS 的实时交互，生成高质量 DOOM 游戏帧，显著提升了长序列模拟的稳定性和逼真度。\n\n### 强化学习与多代理系统\n这些工作突出了强化学习在复杂环境中的应用，特别关注多任务和鲁棒性。\n- **MiWaves Reinforcement Learning Algorithm（MiWaves 强化学习算法）**：Susan Murphy 等作者提出了一种算法，用于优化干预提示减少大麻使用，结合 RL 和领域知识，在真实试验中展示了动态适应性和实际效果。\n- **Simultaneous Training of First- and Second-Order Optimizers in Population-Based Reinforcement Learning（在基于种群的强化学习中同时训练一阶和二阶优化器）**：引入混合优化器（如 K-FAC 和 Adam），在 MuJoCo 环境中提升了性能和稳定性，展示了二阶优化器的潜力。\n- **On Stateful Value Factorization in Multi-Agent Reinforcement Learning（在多代理强化学习中的有状态值因式分解）**：提出 DuelMIX 算法，通过学习独立代理效用估计器，提高了 StarCraft II 等任务的性能，强调了理论与实践的统一。\n\n### 视觉语言模型与图像生成\n这些论文强调了视觉任务的鲁棒性和多模态融合。\n- **Fundus2Video: Cross-Modal Angiography Video Generation from Static Fundus Photography with Clinical Knowledge Guidance（Fundus2Video: 使用临床知识指导从静态眼底照片生成交叉模态血管造影视频）**：开发了一个自回归 GAN 框架，生成动态眼底视频，显著提升了眼部疾病诊断的非侵入性应用。\n- **Negation Blindness in Large Language Models: Unveiling the NO Syndrome in Image Generation（大型语言模型中的否定盲点：揭示图像生成中的 NO 综合征）**：揭示了 LLMs 在处理否定提示时的局限性，通过实验分析了模型规模对拒绝率的影响，并与人类行为比较。\n- **Diffusion based Semantic Outlier Generation via Nuisance Awareness for Out-of-Distribution Detection（基于扩散的语义异常生成，通过干扰感知进行分布外检测）**：提出一种生成框架，创建语义差异大的异常样本，提高了 OOD 检测的准确性，在图像基准上超越了基线。\n\n### 其他领域快速掠过\n其他论文涉及医疗 AI、网络安全和知识图谱等，但影响力相对较小，仅简要提及。\n- **Large Language Models for Disease Diagnosis: A Scoping Review（大型语言模型在疾病诊断中的综述）**：综述了 LLMs 在诊断中的应用，强调了多任务评估和未来方向。\n- **VoxCeleb Speaker Recognition Challenge: A Retrospective（VoxCeleb 说话者识别挑战回顾）**：回顾了说话者识别和对话分离的进展，展示了挑战数据集在提升模型性能中的作用。\n- 其余如脑机融合学习、知识图谱嵌入等论文（如 NeuralOOD、RSTeller）提供了技术创新，但未见突破性发现，建议感兴趣读者查阅原文。\n\n今天的论文总体上展示了 AI 模型在效率、鲁棒性和实际应用上的进展，特别是语言和视觉领域的融合。重点论文如 Mamba in Llama 和 MiWaves 值得关注，体现了高效计算和跨领域应用的潜力。更多细节请查看 arXiv！",
  "papers": [
    {
      "arxiv_id": "2408.15443v1",
      "title": "Pathfinding with Lazy Successor Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Keisuke Okumura"
      ],
      "abstract": "We study a pathfinding problem where only locations (i.e., vertices) are\ngiven, and edges are implicitly defined by an oracle answering the connectivity\nof two locations. Despite its simple structure, this problem becomes\nnon-trivial with a massive number of locations, due to posing a huge branching\nfactor for search algorithms. Limiting the number of successors, such as with\nnearest neighbors, can reduce search efforts but compromises completeness.\nInstead, we propose a novel LaCAS* algorithm, which does not generate\nsuccessors all at once but gradually generates successors as the search\nprogresses. This scheme is implemented with k-nearest neighbors search on a k-d\ntree. LaCAS* is a complete and anytime algorithm that eventually converges to\nthe optima. Extensive evaluations demonstrate the efficacy of LaCAS*, e.g.,\nsolving complex pathfinding instances quickly, where conventional methods\nfalter.",
      "tldr_zh": "本研究探讨了一种路径查找问题，其中仅给出位置（vertices），边由预言机（oracle）隐式定义，通过查询位置连通性来构建图，但海量位置导致搜索算法面临巨大分支因子（branching factor）。为了解决此问题，作者提出LaCAS*算法，该算法采用延迟生成后继节点（lazy successor generation）的策略，随着搜索进展逐步生成后继节点，并使用k-nearest neighbors搜索在k-d tree上实现。LaCAS*是一个完整的、anytime算法，最终收敛到最优解。实验评估显示，LaCAS*能快速解决复杂路径查找实例，而传统方法则难以应对。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.15443v1",
      "published_date": "2024-08-27 23:25:25 UTC",
      "updated_date": "2024-08-27 23:25:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:02:42.124836"
    },
    {
      "arxiv_id": "2408.15436v1",
      "title": "Online Event-Triggered Switching for Frequency Control in Power Grids with Variable Inertia",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Feng",
        "Wenqi Cui",
        "Jorge Cortés",
        "Yuanyuan Shi"
      ],
      "abstract": "The increasing integration of renewable energy resources into power grids has\nled to time-varying system inertia and consequent degradation in frequency\ndynamics. A promising solution to alleviate performance degradation is using\npower electronics interfaced energy resources, such as renewable generators and\nbattery energy storage for primary frequency control, by adjusting their power\noutput set-points in response to frequency deviations. However, designing a\nfrequency controller under time-varying inertia is challenging. Specifically,\nthe stability or optimality of controllers designed for time-invariant systems\ncan be compromised once applied to a time-varying system. We model the\nfrequency dynamics under time-varying inertia as a nonlinear switching system,\nwhere the frequency dynamics under each mode are described by the nonlinear\nswing equations and different modes represent different inertia levels. We\nidentify a key controller structure, named Neural Proportional-Integral\n(Neural-PI) controller, that guarantees exponential input-to-state stability\nfor each mode. To further improve performance, we present an online\nevent-triggered switching algorithm to select the most suitable controller from\na set of Neural-PI controllers, each optimized for specific inertia levels.\nSimulations on the IEEE 39-bus system validate the effectiveness of the\nproposed online switching control method with stability guarantees and\noptimized performance for frequency control under time-varying inertia.",
      "tldr_zh": "该研究针对可再生能源整合导致电力网格惯性时变的问题，提出了一种在线事件触发切换(Event-Triggered Switching)方法，用于优化频率控制。研究将频率动态建模为非线性切换系统，并引入Neural-PI控制器，确保每个惯性水平下的指数输入-状态稳定性；同时，通过在线切换算法从一组针对特定惯性优化的控制器中选择最佳方案。模拟结果在IEEE 39-bus系统中验证了该方法的有效性，提供稳定性保证并显著提升了时变惯性下的频率控制性能。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15436v1",
      "published_date": "2024-08-27 22:44:33 UTC",
      "updated_date": "2024-08-27 22:44:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:02:53.542285"
    },
    {
      "arxiv_id": "2408.15425v1",
      "title": "Fast and Modular Autonomy Software for Autonomous Racing Vehicles",
      "title_zh": "针对自主赛车的快速模块化自治软件",
      "authors": [
        "Andrew Saba",
        "Aderotimi Adetunji",
        "Adam Johnson",
        "Aadi Kothari",
        "Matthew Sivaprakasam",
        "Joshua Spisak",
        "Prem Bharatia",
        "Arjun Chauhan",
        "Brendan Duff Jr.",
        "Noah Gasparro",
        "Charles King",
        "Ryan Larkin",
        "Brian Mao",
        "Micah Nye",
        "Anjali Parashar",
        "Joseph Attias",
        "Aurimas Balciunas",
        "Austin Brown",
        "Chris Chang",
        "Ming Gao",
        "Cindy Heredia",
        "Andrew Keats",
        "Jose Lavariega",
        "William Muckelroy III",
        "Andre Slavescu",
        "Nickolas Stathas",
        "Nayana Suvarna",
        "Chuan Tian Zhang",
        "Sebastian Scherer",
        "Deva Ramanan"
      ],
      "abstract": "Autonomous motorsports aim to replicate the human racecar driver with\nsoftware and sensors. As in traditional motorsports, Autonomous Racing Vehicles\n(ARVs) are pushed to their handling limits in multi-agent scenarios at\nextremely high ($\\geq 150mph$) speeds. This Operational Design Domain (ODD)\npresents unique challenges across the autonomy stack. The Indy Autonomous\nChallenge (IAC) is an international competition aiming to advance autonomous\nvehicle development through ARV competitions. While far from challenging what a\nhuman racecar driver can do, the IAC is pushing the state of the art by\nfacilitating full-sized ARV competitions. This paper details the MIT-Pitt-RW\nTeam's approach to autonomous racing in the IAC. In this work, we present our\nmodular and fast approach to agent detection, motion planning and controls to\ncreate an autonomy stack. We also provide analysis of the performance of the\nsoftware stack in single and multi-agent scenarios for rapid deployment in a\nfast-paced competition environment. We also cover what did and did not work\nwhen deployed on a physical system the Dallara AV-21 platform and potential\nimprovements to address these shortcomings. Finally, we convey lessons learned\nand discuss limitations and future directions for improvement.",
      "tldr_zh": "这篇论文介绍了MIT-Pitt-RW团队为Indy Autonomous Challenge (IAC)开发的模块化和快速自主软件栈，旨在提升Autonomous Racing Vehicles (ARVs)在高速（≥150mph）多代理场景下的性能。该软件栈包括代理检测（agent detection）、运动规划（motion planning）和控制（controls）的模块化方法，以应对Operational Design Domain (ODD)中的独特挑战。实验结果显示，该栈在单代理和多代理环境中表现出色，并在Dallara AV-21平台上部署后提供了性能分析和改进建议。最终，论文总结了经验教训、现有局限性以及未来优化方向。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.RO",
      "comment": "Published in Journal of Field Robotics",
      "pdf_url": "http://arxiv.org/pdf/2408.15425v1",
      "published_date": "2024-08-27 21:57:16 UTC",
      "updated_date": "2024-08-27 21:57:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:03:06.862697"
    },
    {
      "arxiv_id": "2408.15421v2",
      "title": "Simultaneous Training of First- and Second-Order Optimizers in Population-Based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Felix Pfeiffer",
        "Shahram Eivazi"
      ],
      "abstract": "The tuning of hyperparameters in reinforcement learning (RL) is critical, as\nthese parameters significantly impact an agent's performance and learning\nefficiency. Dynamic adjustment of hyperparameters during the training process\ncan significantly enhance both the performance and stability of learning.\nPopulation-based training (PBT) provides a method to achieve this by\ncontinuously tuning hyperparameters throughout the training. This ongoing\nadjustment enables models to adapt to different learning stages, resulting in\nfaster convergence and overall improved performance. In this paper, we propose\nan enhancement to PBT by simultaneously utilizing both first- and second-order\noptimizers within a single population. We conducted a series of experiments\nusing the TD3 algorithm across various MuJoCo environments. Our results, for\nthe first time, empirically demonstrate the potential of incorporating\nsecond-order optimizers within PBT-based RL. Specifically, the combination of\nthe K-FAC optimizer with Adam led to up to a 10% improvement in overall\nperformance compared to PBT using only Adam. Additionally, in environments\nwhere Adam occasionally fails, such as the Swimmer environment, the mixed\npopulation with K-FAC exhibited more reliable learning outcomes, offering a\nsignificant advantage in training stability without a substantial increase in\ncomputational time.",
      "tldr_zh": "本文提出了一种在 Population-Based Training (PBT) 中的增强方法，即在单个种群中同时使用第一阶优化器（如 Adam）和第二阶优化器（如 K-FAC），以动态调整强化学习 (RL) 的超参数，从而提升代理的性能和训练稳定性。实验在 TD3 算法和各种 MuJoCo 环境中进行，结果显示这种混合优化器组合比仅使用 Adam 的 PBT 提高了高达 10% 的整体性能。特别是在 Swimmer 等环境中，该方法显著改善了学习可靠性，并保持了计算时间的基本不变，为 RL 的高效训练提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.15421v2",
      "published_date": "2024-08-27 21:54:26 UTC",
      "updated_date": "2024-09-04 10:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:03:19.382925"
    },
    {
      "arxiv_id": "2408.15406v1",
      "title": "Intertwined Biases Across Social Media Spheres: Unpacking Correlations in Media Bias Dimensions",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Liu",
        "Yike Li",
        "Dong Wang"
      ],
      "abstract": "Media bias significantly shapes public perception by reinforcing stereotypes\nand exacerbating societal divisions. Prior research has often focused on\nisolated media bias dimensions such as \\textit{political bias} or\n\\textit{racial bias}, neglecting the complex interrelationships among various\nbias dimensions across different topic domains. Moreover, we observe that\nmodels trained on existing media bias benchmarks fail to generalize effectively\non recent social media posts, particularly in certain bias identification\ntasks. This shortfall primarily arises because these benchmarks do not\nadequately reflect the rapidly evolving nature of social media content, which\nis characterized by shifting user behaviors and emerging trends. In response to\nthese limitations, our research introduces a novel dataset collected from\nYouTube and Reddit over the past five years. Our dataset includes automated\nannotations for YouTube content across a broad spectrum of bias dimensions,\nsuch as gender, racial, and political biases, as well as hate speech, among\nothers. It spans diverse domains including politics, sports, healthcare,\neducation, and entertainment, reflecting the complex interplay of biases across\ndifferent societal sectors. Through comprehensive statistical analysis, we\nidentify significant differences in bias expression patterns and intra-domain\nbias correlations across these domains. By utilizing our understanding of the\ncorrelations among various bias dimensions, we lay the groundwork for creating\nadvanced systems capable of detecting multiple biases simultaneously. Overall,\nour dataset advances the field of media bias identification, contributing to\nthe development of tools that promote fairer media consumption. The\ncomprehensive awareness of existing media bias fosters more ethical journalism,\npromotes cultural sensitivity, and supports a more informed and equitable\npublic discourse.",
      "tldr_zh": "该研究探讨了社交媒体中媒体偏见维度的相互关联，指出现有研究往往忽略了如 political bias 和 racial bias 等维度间的复杂互动，导致模型在社交媒体内容上泛化性差。研究者构建了一个新数据集，从 YouTube 和 Reddit 收集了过去五年的数据，并自动标注了 gender, racial, political biases 以及 hate speech 等多个维度，涵盖 politics, sports, healthcare, education 和 entertainment 等领域。通过统计分析，他们揭示了不同领域中偏见表达模式和内部相关性的显著差异，并为开发能同时检测多种偏见的先进系统提供了基础。该数据集推进了媒体偏见识别领域，促进更公平的媒体消费和更道德的新闻实践。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.SI",
      "comment": "Accepted to ASONAM 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.15406v1",
      "published_date": "2024-08-27 21:03:42 UTC",
      "updated_date": "2024-08-27 21:03:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:03:31.518976"
    },
    {
      "arxiv_id": "2408.15399v1",
      "title": "A Statistical Framework for Data-dependent Retrieval-Augmented Models",
      "title_zh": "翻译失败",
      "authors": [
        "Soumya Basu",
        "Ankit Singh Rawat",
        "Manzil Zaheer"
      ],
      "abstract": "Modern ML systems increasingly augment input instances with additional\nrelevant information to enhance final prediction. Despite growing interest in\nsuch retrieval-augmented models, their fundamental properties and training are\nnot well understood. We propose a statistical framework to study such models\nwith two components: 1) a {\\em retriever} to identify the relevant information\nout of a large corpus via a data-dependent metric; and 2) a {\\em predictor}\nthat consumes the input instances along with the retrieved information to make\nthe final predictions. We present a principled method for end-to-end training\nof both components and draw connections with various training approaches in the\nliterature. Furthermore, we establish excess risk bounds for\nretrieval-augmented models while delineating the contributions of both\nretriever and predictor towards the model performance. We validate the utility\nof our proposed training methods along with the key takeaways from our\nstatistical analysis on open domain question answering task where retrieval\naugmentation is important.",
      "tldr_zh": "这篇论文提出了一种统计框架，用于研究数据依赖的retrieval-augmented models，通过结合retriever（用于从大语料库中通过数据依赖指标识别相关信息）和predictor（利用输入实例及检索信息进行最终预测）来增强机器学习系统的预测性能。作者提供了一种端到端训练方法，并与现有文献方法建立联系，同时建立了过量风险边界，以分析retriever和predictor对模型性能的贡献。在开放域问答任务上，实验验证了该框架的有效性及其关键见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15399v1",
      "published_date": "2024-08-27 20:51:06 UTC",
      "updated_date": "2024-08-27 20:51:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:03:41.264822"
    },
    {
      "arxiv_id": "2408.15395v1",
      "title": "SCAN-Edge: Finding MobileNet-speed Hybrid Networks for Diverse Edge Devices via Hardware-Aware Evolutionary Search",
      "title_zh": "SCAN-Edge：通过硬件感知进化搜索为多样化边缘设备寻找达到 MobileNet 速度的混合网络",
      "authors": [
        "Hung-Yueh Chiang",
        "Diana Marculescu"
      ],
      "abstract": "Designing low-latency and high-efficiency hybrid networks for a variety of\nlow-cost commodity edge devices is both costly and tedious, leading to the\nadoption of hardware-aware neural architecture search (NAS) for finding optimal\narchitectures. However, unifying NAS for a wide range of edge devices presents\nchallenges due to the variety of hardware designs, supported operations, and\ncompilation optimizations. Existing methods often fix the search space of\narchitecture choices (e.g., activation, convolution, or self-attention) and\nestimate latency using hardware-agnostic proxies (e.g., FLOPs), which fail to\nachieve proclaimed latency across various edge devices. To address this issue,\nwe propose SCAN-Edge, a unified NAS framework that jointly searches for\nself-attention, convolution, and activation to accommodate the wide variety of\nedge devices, including CPU-, GPU-, and hardware accelerator-based systems. To\nhandle the large search space, SCAN-Edge relies on with a hardware-aware\nevolutionary algorithm that improves the quality of the search space to\naccelerate the sampling process. Experiments on large-scale datasets\ndemonstrate that our hybrid networks match the actual MobileNetV2 latency for\n224x224 input resolution on various commodity edge devices.",
      "tldr_zh": "本文提出 SCAN-Edge，一种统一的硬件感知神经架构搜索 (NAS) 框架，用于为 CPU、GPU 和硬件加速器等多样化边缘设备设计低延迟、高效率的混合网络。SCAN-Edge 通过联合搜索自注意力、卷积和激活，并采用硬件感知进化算法优化搜索空间，加速采样过程并解决现有方法依赖硬件无关代理 (如 FLOPs) 的局限性。实验在大型数据集上表明，该框架生成的网络在各种商品边缘设备上实现了与 MobileNetV2 相当的实际延迟性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15395v1",
      "published_date": "2024-08-27 20:39:09 UTC",
      "updated_date": "2024-08-27 20:39:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:03:54.788958"
    },
    {
      "arxiv_id": "2408.15381v2",
      "title": "On Stateful Value Factorization in Multi-Agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Enrico Marchesini",
        "Andrea Baisero",
        "Rupali Bhati",
        "Christopher Amato"
      ],
      "abstract": "Value factorization is a popular paradigm for designing scalable multi-agent\nreinforcement learning algorithms. However, current factorization methods make\nchoices without full justification that may limit their performance. For\nexample, the theory in prior work uses stateless (i.e., history) functions,\nwhile the practical implementations use state information -- making the\nmotivating theory a mismatch for the implementation. Also, methods have built\noff of previous approaches, inheriting their architectures without exploring\nother, potentially better ones. To address these concerns, we formally analyze\nthe theory of using the state instead of the history in current methods --\nreconnecting theory and practice. We then introduce DuelMIX, a factorization\nalgorithm that learns distinct per-agent utility estimators to improve\nperformance and achieve full expressiveness. Experiments on StarCraft II\nmicromanagement and Box Pushing tasks demonstrate the benefits of our\nintuitions.",
      "tldr_zh": "该论文分析了多智能体强化学习（multi-agent reinforcement learning）中 value factorization 方法的局限性，指出现有方法理论依赖无状态（history）函数，而实际实现使用状态信息，导致理论与实践不匹配。作者正式探讨了使用状态信息的理论基础，并提出 DuelMIX 算法，该算法通过学习独立的每个代理（per-agent）效用估计器，实现更高的性能和完全表达性。在 StarCraft II 微管理任务和 Box Pushing 任务的实验中，DuelMIX 显著优于基线模型，验证了这些改进的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 9 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.15381v2",
      "published_date": "2024-08-27 19:45:26 UTC",
      "updated_date": "2024-09-09 22:49:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:04:06.572949"
    },
    {
      "arxiv_id": "2409.00113v2",
      "title": "Wait, that's not an option: LLMs Robustness with Incorrect Multiple-Choice Options",
      "title_zh": "翻译失败",
      "authors": [
        "Gracjan Góral",
        "Emilia Wiśnios",
        "Piotr Sankowski",
        "Paweł Budzianowski"
      ],
      "abstract": "Decision-making under full alignment requires balancing between reasoning and\nfaithfulness - a challenge for large language models (LLMs). This study\nexplores whether LLMs prioritize following instructions over reasoning and\ntruth when given \"misleading\" instructions, such as \"Respond solely with A or\nB\", even when neither option is correct. We introduce a new metric called\n\"reflective judgment\", which sheds new light on the relationship between the\npre-training and post-training alignment schemes. In tasks ranging from basic\narithmetic to domain-specific assessments, models like GPT-4o, o1-mini, or\nClaude 3 Opus adhered to instructions correctly but failed to reflect on the\nvalidity of the provided options. Contrary, models from the Llama 3.1 family\n(8B, 70B, 405B) or base Qwen2.5 (7B, 14B, 32B) families exhibit improved\nrefusal rates with size, indicating a scaling effect. We also observed that\nalignment techniques, though intended to enhance reasoning, sometimes weakened\nthe models' ability to reject incorrect instructions, leading them to follow\nflawed prompts uncritically. Finally, we have also conducted a parallel human\nstudy revealing similar patterns in human behavior and annotations. We\nhighlight how popular RLHF datasets might disrupt either training or evaluation\ndue to annotations exhibiting poor reflective judgement.",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 在面对误导性指令（如“仅回答 A 或 B”但选项均不正确）时的鲁棒性，评估模型在推理与忠实性之间的平衡。研究引入了新的 reflective judgment 指标，揭示预训练和后训练对齐方案的影响，并在从基本算术到领域特定任务的实验中发现，模型如 GPT-4o 和 Claude 3 Opus 倾向于盲目遵循指令，而 Llama 3.1 系列和 Qwen2.5 系列则随着规模增大表现出更高的拒绝率。结果显示，对齐技术有时会削弱模型拒绝不正确指令的能力，与平行人类研究类似行为一致，并强调 RLHF 数据集可能因注释的 poor reflective judgment 而影响训练和评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for NeurIPS 2024 FM-EduAssess Workshop",
      "pdf_url": "http://arxiv.org/pdf/2409.00113v2",
      "published_date": "2024-08-27 19:27:43 UTC",
      "updated_date": "2024-10-10 20:46:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:04:18.856118"
    },
    {
      "arxiv_id": "2408.16027v1",
      "title": "Toward Time-Continuous Data Inference in Sparse Urban CrowdSensing",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyu Sun",
        "Haoyang Su",
        "Hanqi Sun",
        "En Wang",
        "Wenbin Liu"
      ],
      "abstract": "Mobile Crowd Sensing (MCS) is a promising paradigm that leverages mobile\nusers and their smart portable devices to perform various real-world tasks.\nHowever, due to budget constraints and the inaccessibility of certain areas,\nSparse MCS has emerged as a more practical alternative, collecting data from a\nlimited number of target subareas and utilizing inference algorithms to\ncomplete the full sensing map. While existing approaches typically assume a\ntime-discrete setting with data remaining constant within each sensing cycle,\nthis simplification can introduce significant errors, especially when dealing\nwith long cycles, as real-world sensing data often changes continuously. In\nthis paper, we go from fine-grained completion, i.e., the subdivision of\nsensing cycles into minimal time units, towards a more accurate,\ntime-continuous completion. We first introduce Deep Matrix Factorization (DMF)\nas a neural network-enabled framework and enhance it with a Recurrent Neural\nNetwork (RNN-DMF) to capture temporal correlations in these finer time slices.\nTo further deal with the continuous data, we propose TIME-DMF, which captures\ntemporal information across unequal intervals, enabling time-continuous\ncompletion. Additionally, we present the Query-Generate (Q-G) strategy within\nTIME-DMF to model the infinite states of continuous data. Extensive experiments\nacross five types of sensing tasks demonstrate the effectiveness of our models\nand the advantages of time-continuous completion.",
      "tldr_zh": "该研究针对 Sparse Urban CrowdSensing 中的数据推断问题，指出现有方法假设时间离散（time-discrete）会导致显著错误，因为真实数据（如 Mobile Crowd Sensing (MCS) 任务）是连续变化的。论文提出 Deep Matrix Factorization (DMF) 框架，并增强为 RNN-DMF 以捕捉细粒度时间片段的 temporal correlations，以及 TIME-DMF 来处理不等时间间隔的 temporal information，并引入 Query-Generate (Q-G) strategy 以建模连续数据的无限状态。实验在五种 sensing tasks 上证明了这些模型的有效性，以及 time-continuous completion 的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.16027v1",
      "published_date": "2024-08-27 19:25:41 UTC",
      "updated_date": "2024-08-27 19:25:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:04:29.794853"
    },
    {
      "arxiv_id": "2408.15373v1",
      "title": "Handling Geometric Domain Shifts in Semantic Segmentation of Surgical RGB and Hyperspectral Images",
      "title_zh": "翻译失败",
      "authors": [
        "Silvia Seidlitz",
        "Jan Sellner",
        "Alexander Studier-Fischer",
        "Alessandro Motta",
        "Berkin Özdemir",
        "Beat P. Müller-Stich",
        "Felix Nickel",
        "Lena Maier-Hein"
      ],
      "abstract": "Robust semantic segmentation of intraoperative image data holds promise for\nenabling automatic surgical scene understanding and autonomous robotic surgery.\nWhile model development and validation are primarily conducted on idealistic\nscenes, geometric domain shifts, such as occlusions of the situs, are common in\nreal-world open surgeries. To close this gap, we (1) present the first analysis\nof state-of-the-art (SOA) semantic segmentation models when faced with\ngeometric out-of-distribution (OOD) data, and (2) propose an augmentation\ntechnique called \"Organ Transplantation\", to enhance generalizability. Our\ncomprehensive validation on six different OOD datasets, comprising 600 RGB and\nhyperspectral imaging (HSI) cubes from 33 pigs, each annotated with 19 classes,\nreveals a large performance drop in SOA organ segmentation models on geometric\nOOD data. This performance decline is observed not only in conventional RGB\ndata (with a dice similarity coefficient (DSC) drop of 46 %) but also in HSI\ndata (with a DSC drop of 45 %), despite the richer spectral information\ncontent. The performance decline increases with the spatial granularity of the\ninput data. Our augmentation technique improves SOA model performance by up to\n67 % for RGB data and 90 % for HSI data, achieving performance at the level of\nin-distribution performance on real OOD test data. Given the simplicity and\neffectiveness of our augmentation method, it is a valuable tool for addressing\ngeometric domain shifts in surgical scene segmentation, regardless of the\nunderlying model. Our code and pre-trained models are publicly available at\nhttps://github.com/IMSY-DKFZ/htc.",
      "tldr_zh": "该研究分析了现有最先进（SOA）语义分割模型在手术 RGB 和 Hyperspectral Imaging (HSI) 图像中面对几何域移位（Geometric Domain Shifts）时的性能问题，发现模型在 Out-of-Distribution (OOD) 数据上表现大幅下降，RGB 数据 Dice Similarity Coefficient (DSC) 下降 46%，HSI 数据下降 45%。为了提升模型的泛化能力，研究提出了一种名为“Organ Transplantation”的增强技术，通过模拟器官移植来处理遮挡等几何变化。实验在六种 OOD 数据集上进行，包括 600 个来自 33 头猪的图像立方体和 19 个类别的标注，结果显示该技术使 SOA 模型性能提升高达 67%（RGB）和 90%（HSI），达到分布内水平。总之，此方法为手术场景语义分割提供了一个简单有效的工具，以应对真实手术中的几何挑战。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Silvia Seidlitz and Jan Sellner contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2408.15373v1",
      "published_date": "2024-08-27 19:13:15 UTC",
      "updated_date": "2024-08-27 19:13:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:04:43.631954"
    },
    {
      "arxiv_id": "2408.15354v1",
      "title": "What Is Required for Empathic AI? It Depends, and Why That Matters for AI Developers and Users",
      "title_zh": "翻译失败",
      "authors": [
        "Jana Schaich Borg",
        "Hannah Read"
      ],
      "abstract": "Interest is growing in artificial empathy, but so is confusion about what\nartificial empathy is or needs to be. This confusion makes it challenging to\nnavigate the technical and ethical issues that accompany empathic AI\ndevelopment. Here, we outline a framework for thinking about empathic AI based\non the premise that different constellations of capabilities associated with\nempathy are important for different empathic AI applications. We describe\ndistinctions of capabilities that we argue belong under the empathy umbrella,\nand show how three medical empathic AI use cases require different sets of\nthese capabilities. We conclude by discussing why appreciation of the diverse\ncapabilities under the empathy umbrella is important for both AI creators and\nusers.",
      "tldr_zh": "该论文探讨了人工移情（artificial empathy）在AI中的要求，强调不同应用场景需要不同的移情能力组合，从而帮助解决技术与伦理挑战。作者提出一个框架，区分了属于移情范畴的各种能力，并通过三个医疗empathic AI用例（如诊断辅助）展示这些能力如何因应用而异。最终，论文强调，认识到移情能力多样性对AI开发者（用于设计）和用户（用于评估）至关重要，以促进更可靠和负责任的AI发展。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear at the 7th AAAI/ACM Conference on AI, Ethics, and Society,\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2408.15354v1",
      "published_date": "2024-08-27 18:27:22 UTC",
      "updated_date": "2024-08-27 18:27:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:04:53.521193"
    },
    {
      "arxiv_id": "2409.07464v1",
      "title": "Reflective Human-Machine Co-adaptation for Enhanced Text-to-Image Generation Dialogue System",
      "title_zh": "翻译失败",
      "authors": [
        "Yuheng Feng",
        "Yangfan He",
        "Yinghui Xia",
        "Tianyu Shi",
        "Jun Wang",
        "Jinsong Yang"
      ],
      "abstract": "Today's image generation systems are capable of producing realistic and\nhigh-quality images. However, user prompts often contain ambiguities, making it\ndifficult for these systems to interpret users' potential intentions.\nConsequently, machines need to interact with users multiple rounds to better\nunderstand users' intents. The unpredictable costs of using or learning image\ngeneration models through multiple feedback interactions hinder their\nwidespread adoption and full performance potential, especially for non-expert\nusers. In this research, we aim to enhance the user-friendliness of our image\ngeneration system. To achieve this, we propose a reflective human-machine\nco-adaptation strategy, named RHM-CAS. Externally, the Agent engages in\nmeaningful language interactions with users to reflect on and refine the\ngenerated images. Internally, the Agent tries to optimize the policy based on\nuser preferences, ensuring that the final outcomes closely align with user\npreferences. Various experiments on different tasks demonstrate the\neffectiveness of the proposed method.",
      "tldr_zh": "该研究针对文本到图像生成系统的用户提示模糊问题，提出了一种反思性人机协同适应策略（RHM-CAS），以提升系统的用户友好性。RHM-CAS 包括外部层面，通过 Agent 与用户的语言交互来反思和优化生成图像，以及内部层面，基于用户偏好调整 Agent 的策略，确保输出更符合意图。在不同任务的实验中，该方法证明了其有效性，帮助减少多轮交互成本并提升非专家用户的体验。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07464v1",
      "published_date": "2024-08-27 18:08:00 UTC",
      "updated_date": "2024-08-27 18:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:05:05.566292"
    },
    {
      "arxiv_id": "2408.15332v2",
      "title": "What makes math problems hard for reinforcement learning: a case study",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Shehper",
        "Anibal M. Medina-Mardones",
        "Lucas Fagan",
        "Bartłomiej Lewandowski",
        "Angus Gruen",
        "Yang Qiu",
        "Piotr Kucharski",
        "Zhenghan Wang",
        "Sergei Gukov"
      ],
      "abstract": "Using a long-standing conjecture from combinatorial group theory, we explore,\nfrom multiple perspectives, the challenges of finding rare instances carrying\ndisproportionately high rewards. Based on lessons learned in the context\ndefined by the Andrews-Curtis conjecture, we propose algorithmic enhancements\nand a topological hardness measure with implications for a broad class of\nsearch problems. As part of our study, we also address several open\nmathematical questions. Notably, we demonstrate the length reducibility of all\nbut two presentations in the Akbulut-Kirby series (1981), and resolve various\npotential counterexamples in the Miller-Schupp series (1991), including three\ninfinite subfamilies.",
      "tldr_zh": "这篇论文以组合群论中的 Andrews-Curtis conjecture 为案例，探讨了强化学习（reinforcement learning）在寻找稀有高回报实例时的挑战，包括算法效率和问题复杂性。作者基于这一背景提出算法增强和一个拓扑硬度度量（topological hardness measure），以提升对这类搜索问题的处理能力，并为更广泛的数学搜索任务提供启示。研究还解决了几个开放数学问题，如证明 Akbulut-Kirby series 中除两个外的所有表示的长度可约性，以及解决 Miller-Schupp series 中的多个潜在反例，包括三个无限子家族。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.CO",
        "math.GR",
        "math.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "58 pages, 25 figures, 1 table. Try it:\n  https://github.com/shehper/AC-Solver",
      "pdf_url": "http://arxiv.org/pdf/2408.15332v2",
      "published_date": "2024-08-27 18:00:06 UTC",
      "updated_date": "2025-02-11 18:01:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:05:18.872874"
    },
    {
      "arxiv_id": "2408.15237v3",
      "title": "The Mamba in the Llama: Distilling and Accelerating Hybrid Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junxiong Wang",
        "Daniele Paliotta",
        "Avner May",
        "Alexander M. Rush",
        "Tri Dao"
      ],
      "abstract": "Linear RNN architectures, like Mamba, can be competitive with Transformer\nmodels in language modeling while having advantageous deployment\ncharacteristics. Given the focus on training large-scale Transformer models, we\nconsider the challenge of converting these pretrained models for deployment. We\ndemonstrate that it is feasible to distill large Transformers into linear RNNs\nby reusing the linear projection weights from attention layers with academic\nGPU resources. The resulting hybrid model, which incorporates a quarter of the\nattention layers, achieves performance comparable to the original Transformer\nin chat benchmarks and outperforms open-source hybrid Mamba models trained from\nscratch with trillions of tokens in both chat benchmarks and general\nbenchmarks. Moreover, we introduce a hardware-aware speculative decoding\nalgorithm that accelerates the inference speed of Mamba and hybrid models.\nOverall we show how, with limited computation resources, we can remove many of\nthe original attention layers and generate from the resulting model more\nefficiently. Our top-performing model, distilled from Llama3-8B-Instruct,\nachieves a 29.61 length-controlled win rate on AlpacaEval 2 against GPT-4 and\n7.35 on MT-Bench, surpassing the best 8B scale instruction-tuned linear RNN\nmodel. We also find that the distilled model has natural length extrapolation,\nshowing almost perfect accuracy in the needle-in-a-haystack test at 20x the\ndistillation length. Code and pre-trained checkpoints are open-sourced at\nhttps://github.com/jxiw/MambaInLlama and\nhttps://github.com/itsdaniele/speculative_mamba.",
      "tldr_zh": "本研究探讨了将大型Transformer模型蒸馏成线性RNN架构（如Mamba）的可行性，通过重用注意力层的线性投影权重，在学术GPU资源下创建混合模型。结果显示，该混合模型在聊天基准测试中表现与原Transformer相当，并在一般基准上优于从零训练的开源Mamba模型。研究还引入了硬件感知的推测解码算法，显著加速了Mamba和混合模型的推理速度；从Llama3-8B-Instruct蒸馏的顶尖模型在AlpacaEval 2上击败GPT-4，胜率达29.61%，并在MT-Bench上得分7.35，同时展现出优秀的长度外推能力。总的来说，该方法证明了用有限计算资源优化模型部署的潜力，并开源了相关代码和检查点。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024. v3 updates: fix format errors",
      "pdf_url": "http://arxiv.org/pdf/2408.15237v3",
      "published_date": "2024-08-27 17:56:11 UTC",
      "updated_date": "2025-01-08 20:34:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:05:30.712699"
    },
    {
      "arxiv_id": "2408.15232v2",
      "title": "Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations",
      "title_zh": "翻译失败",
      "authors": [
        "Yucheng Jiang",
        "Yijia Shao",
        "Dekun Ma",
        "Sina J. Semnani",
        "Monica S. Lam"
      ],
      "abstract": "While language model (LM)-powered chatbots and generative search engines\nexcel at answering concrete queries, discovering information in the terrain of\nunknown unknowns remains challenging for users. To emulate the common\neducational scenario where children/students learn by listening to and\nparticipating in conversations of their parents/teachers, we create\nCollaborative STORM (Co-STORM). Unlike QA systems that require users to ask all\nthe questions, Co-STORM lets users observe and occasionally steer the discourse\namong several LM agents. The agents ask questions on the user's behalf,\nallowing the user to discover unknown unknowns serendipitously. To facilitate\nuser interaction, Co-STORM assists users in tracking the discourse by\norganizing the uncovered information into a dynamic mind map, ultimately\ngenerating a comprehensive report as takeaways. For automatic evaluation, we\nconstruct the WildSeek dataset by collecting real information-seeking records\nwith user goals. Co-STORM outperforms baseline methods on both discourse trace\nand report quality. In a further human evaluation, 70% of participants prefer\nCo-STORM over a search engine, and 78% favor it over a RAG chatbot.",
      "tldr_zh": "本研究探讨了语言模型（LM）在处理未知未知（unknown unknowns）信息时的挑战，提出了一种名为 Collaborative STORM (Co-STORM) 的系统，让用户通过观察和偶尔引导多个 LM 代理对话来实现互动式学习。Co-STORM 允许代理代表用户提问，从而帮助用户意外发现新信息，并通过动态思维导图组织内容，最终生成全面报告。实验使用 WildSeek 数据集进行评估，结果显示 Co-STORM 在对话追踪和报告质量上优于基线方法，且人类评估中，70% 参与者更喜欢它比搜索引擎，78% 比 RAG 聊天机器人。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "I.2.7; H.5.2; H.3.3"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2408.15232v2",
      "published_date": "2024-08-27 17:50:03 UTC",
      "updated_date": "2024-10-17 20:43:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:05:42.092870"
    },
    {
      "arxiv_id": "2408.15313v2",
      "title": "Bi-Factorial Preference Optimization: Balancing Safety-Helpfulness in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxuan Zhang",
        "Philip H. S. Torr",
        "Mohamed Elhoseiny",
        "Adel Bibi"
      ],
      "abstract": "Fine-tuning large language models (LLMs) on human preferences, typically\nthrough reinforcement learning from human feedback (RLHF), has proven\nsuccessful in enhancing their capabilities. However, ensuring the safety of\nLLMs during fine-tuning remains a critical concern, and mitigating the\npotential conflicts in safety and helpfulness is costly in RLHF. To address\nthis issue, we propose a supervised learning framework called Bi-Factorial\nPreference Optimization (BFPO), which re-parameterizes a joint RLHF objective\nof both safety and helpfulness into a single supervised learning objective. In\nsupervised optimization, a labeling function is used to capture the global\npreferences ranking to balance both safety and helpfulness. To evaluate BFPO,\nwe develop a benchmark that includes comprehensive discriminative and\ngenerative tasks for helpfulness and harmlessness. The results indicate that\nour method significantly outperforms existing approaches in both safety and\nhelpfulness. Moreover, BFPO achieves the same level of safety as methods that\nheavily rely on human labor with less than 10\\% of the computational resources\nand human prompting and annotation process. The training recipes can be found\nhere: https://github.com/wx-zhang/bfpo.",
      "tldr_zh": "这篇论文提出了一种名为 Bi-Factorial Preference Optimization (BFPO) 的监督学习框架，用于平衡大型语言模型 (LLMs) 在安全性和帮助性方面的优化，解决了传统 RLHF (Reinforcement Learning from Human Feedback) 方法中潜在冲突的问题。BFPO 通过重新参数化联合 RLHF 目标并使用标签函数捕获全局偏好排名，实现对安全和帮助性的高效平衡。实验结果显示，该方法在开发的综合基准测试中显著优于现有方法，并在安全性能上仅用少于 10% 的计算资源和人力就达到同等水平。训练配方可从 GitHub 仓库获取（https://github.com/wx-zhang/bfpo）。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "The paper has been accepted in ICLR 2025 as spotlight presentation",
      "pdf_url": "http://arxiv.org/pdf/2408.15313v2",
      "published_date": "2024-08-27 17:31:21 UTC",
      "updated_date": "2025-04-08 11:04:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:05:55.923577"
    },
    {
      "arxiv_id": "2408.15217v1",
      "title": "Fundus2Video: Cross-Modal Angiography Video Generation from Static Fundus Photography with Clinical Knowledge Guidance",
      "title_zh": "Fundus2Video：基于临床知识指导的从静态眼底摄影生成跨模态血管造影",
      "authors": [
        "Weiyi Zhang",
        "Siyu Huang",
        "Jiancheng Yang",
        "Ruoyu Chen",
        "Zongyuan Ge",
        "Yingfeng Zheng",
        "Danli Shi",
        "Mingguang He"
      ],
      "abstract": "Fundus Fluorescein Angiography (FFA) is a critical tool for assessing retinal\nvascular dynamics and aiding in the diagnosis of eye diseases. However, its\ninvasive nature and less accessibility compared to Color Fundus (CF) images\npose significant challenges. Current CF to FFA translation methods are limited\nto static generation. In this work, we pioneer dynamic FFA video generation\nfrom static CF images. We introduce an autoregressive GAN for smooth,\nmemory-saving frame-by-frame FFA synthesis. To enhance the focus on dynamic\nlesion changes in FFA regions, we design a knowledge mask based on clinical\nexperience. Leveraging this mask, our approach integrates innovative knowledge\nmask-guided techniques, including knowledge-boosted attention, knowledge-aware\ndiscriminators, and mask-enhanced patchNCE loss, aimed at refining generation\nin critical areas and addressing the pixel misalignment challenge. Our method\nachieves the best FVD of 1503.21 and PSNR of 11.81 compared to other common\nvideo generation approaches. Human assessment by an ophthalmologist confirms\nits high generation quality. Notably, our knowledge mask surpasses supervised\nlesion segmentation masks, offering a promising non-invasive alternative to\ntraditional FFA for research and clinical applications. The code is available\nat https://github.com/Michi-3000/Fundus2Video.",
      "tldr_zh": "本研究针对 Fundus Fluorescein Angiography (FFA) 的侵入性和可访问性问题，首次从静态 Color Fundus (CF) 图像生成动态 FFA 视频，作为非侵入性诊断替代方案。作者提出了一种 autoregressive GAN 框架，用于平滑且节省内存的逐帧视频合成，并设计基于临床经验的 knowledge mask 来聚焦动态病变区域。框架整合了 knowledge-boosted attention、knowledge-aware discriminators 和 mask-enhanced patchNCE loss 等技术，以优化关键区域生成并解决像素不对齐问题。实验结果显示，该方法在 FVD 和 PSNR 上分别达到最佳值 1503.21 和 11.81，并获得眼科医生的人眼评估认可；此外，knowledge mask 优于监督病变分割 mask，为临床应用提供新途径。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "The paper has been accepted by Medical Image Computing and Computer\n  Assisted Intervention Society (MICCAI) 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.15217v1",
      "published_date": "2024-08-27 17:30:49 UTC",
      "updated_date": "2024-08-27 17:30:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:06:06.783864"
    },
    {
      "arxiv_id": "2409.00112v1",
      "title": "Toward Large Language Models as a Therapeutic Tool: Comparing Prompting Techniques to Improve GPT-Delivered Problem-Solving Therapy",
      "title_zh": "翻译失败",
      "authors": [
        "Daniil Filienko",
        "Yinzhou Wang",
        "Caroline El Jazmi",
        "Serena Xie",
        "Trevor Cohen",
        "Martine De Cock",
        "Weichao Yuwen"
      ],
      "abstract": "While Large Language Models (LLMs) are being quickly adapted to many domains,\nincluding healthcare, their strengths and pitfalls remain under-explored. In\nour study, we examine the effects of prompt engineering to guide Large Language\nModels (LLMs) in delivering parts of a Problem-Solving Therapy (PST) session\nvia text, particularly during the symptom identification and assessment phase\nfor personalized goal setting. We present evaluation results of the models'\nperformances by automatic metrics and experienced medical professionals. We\ndemonstrate that the models' capability to deliver protocolized therapy can be\nimproved with the proper use of prompt engineering methods, albeit with\nlimitations. To our knowledge, this study is among the first to assess the\neffects of various prompting techniques in enhancing a generalist model's\nability to deliver psychotherapy, focusing on overall quality, consistency, and\nempathy. Exploring LLMs' potential in delivering psychotherapy holds promise\nwith the current shortage of mental health professionals amid significant\nneeds, enhancing the potential utility of AI-based and AI-enhanced care\nservices.",
      "tldr_zh": "本文研究了如何通过提示工程（Prompt Engineering）提升大型语言模型（LLMs），如 GPT，在问题解决疗法（Problem-Solving Therapy, PST）中交付症状识别和评估阶段。研究者比较了不同提示技术，并使用自动指标和医疗专业人士进行评估，结果显示适当的提示方法能改善模型的整体质量、一致性和移情能力，尽管仍存在局限性。该工作首次评估了这些技术在心理治疗中的效果，并强调 LLMs 有望缓解心理健康专业人员短缺的全球性需求。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for AMIA 2024 proceedings",
      "pdf_url": "http://arxiv.org/pdf/2409.00112v1",
      "published_date": "2024-08-27 17:25:16 UTC",
      "updated_date": "2024-08-27 17:25:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:06:19.378012"
    },
    {
      "arxiv_id": "2409.04456v1",
      "title": "Pattern based learning and optimisation through pricing for bin packing problem",
      "title_zh": "翻译失败",
      "authors": [
        "Huayan Zhang",
        "Ruibin Bai",
        "Tie-Yan Liu",
        "Jiawei Li",
        "Bingchen Lin",
        "Jianfeng Ren"
      ],
      "abstract": "As a popular form of knowledge and experience, patterns and their\nidentification have been critical tasks in most data mining applications.\nHowever, as far as we are aware, no study has systematically examined the\ndynamics of pattern values and their reuse under varying conditions. We argue\nthat when problem conditions such as the distributions of random variables\nchange, the patterns that performed well in previous circumstances may become\nless effective and adoption of these patterns would result in sub-optimal\nsolutions. In response, we make a connection between data mining and the\nduality theory in operations research and propose a novel scheme to efficiently\nidentify patterns and dynamically quantify their values for each specific\ncondition. Our method quantifies the value of patterns based on their ability\nto satisfy stochastic constraints and their effects on the objective value,\nallowing high-quality patterns and their combinations to be detected. We use\nthe online bin packing problem to evaluate the effectiveness of the proposed\nscheme and illustrate the online packing procedure with the guidance of\npatterns that address the inherent uncertainty of the problem. Results show\nthat the proposed algorithm significantly outperforms the state-of-the-art\nmethods. We also analysed in detail the distinctive features of the proposed\nmethods that lead to performance improvement and the special cases where our\nmethod can be further improved.",
      "tldr_zh": "本文研究了patterns在数据挖掘中的动态价值，指出当问题条件（如随机变量分布）变化时，以前有效的patterns可能导致次优解决方案。作者提出一种新方案，将数据挖掘与duality theory结合，通过量化patterns满足stochastic constraints的能力及其对目标值的影响，来高效识别和动态评估高价值patterns。实验在online bin packing problem上验证了该算法的表现，显著优于现有方法，并分析了其独特特点及潜在改进方向。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04456v1",
      "published_date": "2024-08-27 17:03:48 UTC",
      "updated_date": "2024-08-27 17:03:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:06:30.018961"
    },
    {
      "arxiv_id": "2408.15204v2",
      "title": "Can Unconfident LLM Annotations Be Used for Confident Conclusions?",
      "title_zh": "不自信的 LLM 标注能否用于得出自信的结论？",
      "authors": [
        "Kristina Gligorić",
        "Tijana Zrnic",
        "Cinoo Lee",
        "Emmanuel J. Candès",
        "Dan Jurafsky"
      ],
      "abstract": "Large language models (LLMs) have shown high agreement with human raters\nacross a variety of tasks, demonstrating potential to ease the challenges of\nhuman data collection. In computational social science (CSS), researchers are\nincreasingly leveraging LLM annotations to complement slow and expensive human\nannotations. Still, guidelines for collecting and using LLM annotations,\nwithout compromising the validity of downstream conclusions, remain limited. We\nintroduce Confidence-Driven Inference: a method that combines LLM annotations\nand LLM confidence indicators to strategically select which human annotations\nshould be collected, with the goal of producing accurate statistical estimates\nand provably valid confidence intervals while reducing the number of human\nannotations needed. Our approach comes with safeguards against LLM annotations\nof poor quality, guaranteeing that the conclusions will be both valid and no\nless accurate than if we only relied on human annotations. We demonstrate the\neffectiveness of Confidence-Driven Inference over baselines in statistical\nestimation tasks across three CSS settings--text politeness, stance, and\nbias--reducing the needed number of human annotations by over 25% in each.\nAlthough we use CSS settings for demonstration, Confidence-Driven Inference can\nbe used to estimate most standard quantities across a broad range of NLP\nproblems.",
      "tldr_zh": "本研究探讨了如何利用大型语言模型（LLMs）的标注结果，即使其置信度不高，也能得出可靠的结论。作者引入了Confidence-Driven Inference方法，该方法结合LLMs的置信度指标，战略性地选择需要人类标注的数据，从而减少人类标注量，同时确保统计估计的准确性和置信区间的有效性。该方法对LLMs标注质量提供保障，保证结论不亚于纯人类标注的准确度。在计算社会科学（CSS）中的文本礼貌、立场和偏见任务上，实验显示该方法可减少超过25%的人类标注需求，并可扩展到更广泛的自然语言处理（NLP）问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Please cite as: Can Unconfident LLM Annotations Be Used for Confident\n  Conclusions? Kristina Gligori\\'c, Tijana Zrnic, Cinoo Lee, Emmanuel Cand\\`es,\n  and Dan Jurafsky. NAACL, 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.15204v2",
      "published_date": "2024-08-27 17:03:18 UTC",
      "updated_date": "2025-02-08 15:15:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:06:42.104149"
    },
    {
      "arxiv_id": "2408.15198v1",
      "title": "Automatic 8-tissue Segmentation for 6-month Infant Brains",
      "title_zh": "针对 6 个月婴儿大脑的自动 8 组织分割",
      "authors": [
        "Yilan Dong",
        "Vanessa Kyriakopoulou",
        "Irina Grigorescu",
        "Grainne McAlonan",
        "Dafnis Batalle",
        "Maria Deprez"
      ],
      "abstract": "Numerous studies have highlighted that atypical brain development,\nparticularly during infancy and toddlerhood, is linked to an increased\nlikelihood of being diagnosed with a neurodevelopmental condition, such as\nautism. Accurate brain tissue segmentations for morphological analysis are\nessential in numerous infant studies. However, due to ongoing white matter (WM)\nmyelination changing tissue contrast in T1- and T2-weighted images, automatic\ntissue segmentation in 6-month infants is particularly difficult. On the other\nhand, manual labelling by experts is time-consuming and labor-intensive. In\nthis study, we propose the first 8-tissue segmentation pipeline for\nsix-month-old infant brains. This pipeline utilizes domain adaptation (DA)\ntechniques to leverage our longitudinal data, including neonatal images\nsegmented with the neonatal Developing Human Connectome Project structural\npipeline. Our pipeline takes raw 6-month images as inputs and generates the\n8-tissue segmentation as outputs, forming an end-to-end segmentation pipeline.\nThe segmented tissues include WM, gray matter (GM), cerebrospinal fluid (CSF),\nventricles, cerebellum, basal ganglia, brainstem, and hippocampus/amygdala.\nCycle-Consistent Generative Adversarial Network (CycleGAN) and Attention U-Net\nwere employed to achieve the image contrast transformation between neonatal and\n6-month images and perform tissue segmentation on the synthesized 6-month\nimages (neonatal images with 6-month intensity contrast), respectively.\nMoreover, we incorporated the segmentation outputs from Infant Brain Extraction\nand Analysis Toolbox (iBEAT) and another Attention U-Net to further enhance the\nperformance and construct the end-to-end segmentation pipeline. Our evaluation\nwith real 6-month images achieved a DICE score of 0.92, an HD95 of 1.6, and an\nASSD of 0.42.",
      "tldr_zh": "本文提出首个针对6个月婴儿大脑的自动8组织分割管道，旨在解决白质髓鞘化导致的T1和T2加权图像对比变化问题。该管道采用域适应技术，利用纵向数据（如新生儿图像），结合CycleGAN进行图像对比转换、Attention U-Net进行组织分割，并整合iBEAT进一步优化性能，形成端到端流程。实验结果显示，在真实6个月图像上，该方法实现了DICE score 0.92、HD95 1.6和ASSD 0.42的优异指标，为婴儿脑发育研究提供高效工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "11 pages, 4 figures, to be published in MICCAI PIPPI workshop",
      "pdf_url": "http://arxiv.org/pdf/2408.15198v1",
      "published_date": "2024-08-27 16:58:23 UTC",
      "updated_date": "2024-08-27 16:58:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:06:54.444279"
    },
    {
      "arxiv_id": "2408.15185v2",
      "title": "Human-Centric Video Anomaly Detection Through Spatio-Temporal Pose Tokenization and Transformer",
      "title_zh": "基于空间-时间姿态标记化和 Transformer 的人类中心视频异常检测",
      "authors": [
        "Ghazal Alinezhad Noghre",
        "Armin Danesh Pazho",
        "Hamed Tabkhi"
      ],
      "abstract": "Video Anomaly Detection (VAD) presents a significant challenge in computer\nvision, particularly due to the unpredictable and infrequent nature of\nanomalous events, coupled with the diverse and dynamic environments in which\nthey occur. Human-centric VAD, a specialized area within this domain, faces\nadditional complexities, including variations in human behavior, potential\nbiases in data, and substantial privacy concerns related to human subjects.\nThese issues complicate the development of models that are both robust and\ngeneralizable. To address these challenges, recent advancements have focused on\npose-based VAD, which leverages human pose as a high-level feature to mitigate\nprivacy concerns, reduce appearance biases, and minimize background\ninterference. In this paper, we introduce SPARTA, a novel transformer-based\narchitecture designed specifically for human-centric pose-based VAD. SPARTA\nintroduces an innovative Spatio-Temporal Pose and Relative Pose (ST-PRP)\ntokenization method that produces an enriched representation of human motion\nover time. This approach ensures that the transformer's attention mechanism\ncaptures both spatial and temporal patterns simultaneously, rather than\nfocusing on only one aspect. The addition of the relative pose further\nemphasizes subtle deviations from normal human movements. The architecture's\ncore, a novel Unified Encoder Twin Decoders (UETD) transformer, significantly\nimproves the detection of anomalous behaviors in video data. Extensive\nevaluations across multiple benchmark datasets demonstrate that SPARTA\nconsistently outperforms existing methods, establishing a new state-of-the-art\nin pose-based VAD.",
      "tldr_zh": "本研究针对人类中心视频异常检测（VAD）的挑战，包括人类行为变异、数据偏差和隐私问题，提出了一种基于Transformer的SPARTA架构。该架构引入了创新的Spatio-Temporal Pose and Relative Pose (ST-PRP) tokenization方法，能够同时捕捉时空模式并强调相对姿势的细微偏差，从而生成更丰富的运动表示。核心组件Unified Encoder Twin Decoders (UETD) Transformer显著提升了异常行为检测的准确性，在多个基准数据集上，SPARTA超越现有方法，建立了新的姿态-based VAD状态。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15185v2",
      "published_date": "2024-08-27 16:40:14 UTC",
      "updated_date": "2025-03-17 14:05:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:07:05.749573"
    },
    {
      "arxiv_id": "2408.15305v1",
      "title": "Parameter-Efficient Quantized Mixture-of-Experts Meets Vision-Language Instruction Tuning for Semiconductor Electron Micrograph Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Sakhinana Sagar Srinivas",
        "Chidaksh Ravuru",
        "Geethan Sannidhi",
        "Venkataramana Runkana"
      ],
      "abstract": "Semiconductors, crucial to modern electronics, are generally under-researched\nin foundational models. It highlights the need for research to enhance the\nsemiconductor device technology portfolio and aid in high-end device\nfabrication. In this paper, we introduce sLAVA, a small-scale vision-language\nassistant tailored for semiconductor manufacturing, with a focus on electron\nmicroscopy image analysis. It addresses challenges of data scarcity and\nacquiring high-quality, expert-annotated data. We employ a teacher-student\nparadigm, using a foundational vision language model like GPT-4 as a teacher to\ncreate instruction-following multimodal data for customizing the student model,\nsLAVA, for electron microscopic image analysis tasks on consumer hardware with\nlimited budgets. Our approach allows enterprises to further fine-tune the\nproposed framework with their proprietary data securely within their own\ninfrastructure, protecting intellectual property. Rigorous experiments validate\nthat our framework surpasses traditional methods, handles data shifts, and\nenables high-throughput screening.",
      "tldr_zh": "该论文提出 sLAVA，一种参数高效量化混合专家 (Parameter-Efficient Quantized Mixture-of-Experts) 与视觉语言指令微调 (Vision-Language Instruction Tuning) 相结合的框架，用于半导体电子显微镜图像分析，以解决数据稀缺和高质标注数据获取的挑战。采用 teacher-student 范式，以 GPT-4 作为 teacher 生成多模态指令数据，从而在消费级硬件上定制训练 sLAVA 模型，并允许企业使用私有数据在内部微调以保护知识产权。实验结果表明，该框架超越传统方法，能够有效处理数据偏移并实现高通量筛选，为半导体制造领域的智能分析提供高效、可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper published at ICML 2024 Workshop on Foundation Models in the\n  Wild",
      "pdf_url": "http://arxiv.org/pdf/2408.15305v1",
      "published_date": "2024-08-27 15:59:26 UTC",
      "updated_date": "2024-08-27 15:59:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:07:30.490467"
    },
    {
      "arxiv_id": "2408.15737v1",
      "title": "TCNFormer: Temporal Convolutional Network Former for Short-Term Wind Speed Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Abid Hasan Zim",
        "Aquib Iqbal",
        "Asad Malik",
        "Zhicheng Dong",
        "Hanzhou Wu"
      ],
      "abstract": "Global environmental challenges and rising energy demands have led to\nextensive exploration of wind energy technologies. Accurate wind speed\nforecasting (WSF) is crucial for optimizing wind energy capture and ensuring\nsystem stability. However, predicting wind speed remains challenging due to its\ninherent randomness, fluctuation, and unpredictability. This study proposes the\nTemporal Convolutional Network Former (TCNFormer) for short-term (12-hour) wind\nspeed forecasting. The TCNFormer integrates the Temporal Convolutional Network\n(TCN) and transformer encoder to capture the spatio-temporal features of wind\nspeed. The transformer encoder consists of two distinct attention mechanisms:\ncausal temporal multi-head self-attention (CT-MSA) and temporal external\nattention (TEA). CT-MSA ensures that the output of a step derives only from\nprevious steps, i.e., causality. Locality is also introduced to improve\nefficiency. TEA explores potential relationships between different sample\nsequences in wind speed data. This study utilizes wind speed data from the NASA\nPrediction of Worldwide Energy Resources (NASA POWER) of Patenga Sea Beach,\nChittagong, Bangladesh (latitude 22.2352{\\deg} N, longitude 91.7914{\\deg} E)\nover a year (six seasons). The findings indicate that the TCNFormer outperforms\nstate-of-the-art models in prediction accuracy. The proposed TCNFormer presents\na promising method for spatio-temporal WSF and may achieve desirable\nperformance in real-world applications of wind power systems.",
      "tldr_zh": "该研究针对风速预测（WSF）的随机性和波动性，提出了一种名为 TCNFormer 的模型，用于短期（12 小时）风速预测。TCNFormer 整合了 Temporal Convolutional Network (TCN) 和 Transformer 编码器，其中包括 Causal Temporal Multi-Head Self-Attention (CT-MSA) 以确保因果性和效率，以及 Temporal External Attention (TEA) 来探索不同样本序列间的关系，从而捕捉风速的时空特征。实验使用 NASA POWER 的孟加拉国 Patenga 海滩一年数据，结果显示 TCNFormer 在预测准确性上优于现有最先进模型，为风力系统的实际应用提供了一个有前景的方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15737v1",
      "published_date": "2024-08-27 15:35:42 UTC",
      "updated_date": "2024-08-27 15:35:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:07:30.977855"
    },
    {
      "arxiv_id": "2408.15128v1",
      "title": "Evaluating the Energy Consumption of Machine Learning: Systematic Literature Review and Experiments",
      "title_zh": "评估机器学习的能源消耗：系统文献综述和实验",
      "authors": [
        "Charlotte Rodriguez",
        "Laura Degioanni",
        "Laetitia Kameni",
        "Richard Vidal",
        "Giovanni Neglia"
      ],
      "abstract": "Monitoring, understanding, and optimizing the energy consumption of Machine\nLearning (ML) are various reasons why it is necessary to evaluate the energy\nusage of ML. However, there exists no universal tool that can answer this\nquestion for all use cases, and there may even be disagreement on how to\nevaluate energy consumption for a specific use case. Tools and methods are\nbased on different approaches, each with their own advantages and drawbacks,\nand they need to be mapped out and explained in order to select the most\nsuitable one for a given situation. We address this challenge through two\napproaches. First, we conduct a systematic literature review of all tools and\nmethods that permit to evaluate the energy consumption of ML (both at training\nand at inference), irrespective of whether they were originally designed for\nmachine learning or general software. Second, we develop and use an\nexperimental protocol to compare a selection of these tools and methods. The\ncomparison is both qualitative and quantitative on a range of ML tasks of\ndifferent nature (vision, language) and computational complexity. The\nsystematic literature review serves as a comprehensive guide for understanding\nthe array of tools and methods used in evaluating energy consumption of ML, for\nvarious use cases going from basic energy monitoring to consumption\noptimization. Two open-source repositories are provided for further\nexploration. The first one contains tools that can be used to replicate this\nwork or extend the current review. The second repository houses the\nexperimental protocol, allowing users to augment the protocol with new ML\ncomputing tasks and additional energy evaluation tools.",
      "tldr_zh": "这篇论文评估了机器学习(ML)的能源消耗，通过系统文献综述和实验方法来解决工具选择难题。研究者首先进行系统文献综述，涵盖所有评估ML训练和推理能源消耗的工具和方法，无论其是否专为ML设计。接着，他们开发了一个实验协议，对选定的工具进行定性和定量比较，涉及不同性质的ML任务（如视觉和语言模型）及计算复杂度。最终，该工作提供了全面指南，从基本能源监控到优化策略，并分享了两个开源仓库，支持用户复制实验或扩展评估。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "52 pages,",
      "pdf_url": "http://arxiv.org/pdf/2408.15128v1",
      "published_date": "2024-08-27 15:08:06 UTC",
      "updated_date": "2024-08-27 15:08:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:07:45.365056"
    },
    {
      "arxiv_id": "2408.15301v2",
      "title": "The Uniqueness of LLaMA3-70B Series with Per-Channel Quantization",
      "title_zh": "LLaMA3-70B 系列的独特之处：每通道量化",
      "authors": [
        "Minghai Qin"
      ],
      "abstract": "We have observed a distinctive quantization-related behavior in the\nLLaMA3/3.1-70B models that is absent in both the LLaMA2-70B and\nLLaMA3/3.1/3.2-1B/3B/8B/405B models. Quantization is a crucial technique for\ndeploying large language models (LLMs) efficiently. The impact of W8A8\npost-training quantization on model accuracy, especially on the recently\nreleased LLaMA3/3.1 model series, remains contentious. In this paper, we\nexplore three key questions: What makes the LLaMA3-70B model series uniquely\nvulnerable to quantization? Why is this the case? And how can the issue be\naddressed? We empirically investigate multiple LLMs featured on an open LLM\nleaderboard, discovering that the LLaMA3-70B model series have a unique\naccuracy degradation behavior with W8A8 per-channel post-training quantization.\nIn contrast, other model series such as LLaMA2, LLaMA3/3.1-8B, LLaMA3.2, Qwen,\nMixtral, Mistral, Phi-3, and Falcon demonstrate robust performance with W8A8.\nContrary to previous assertions attributing degradation to the large dynamic\nrange of activations, our findings indicate that the weight distribution of the\nLLaMA3-70B is the primary factor behind the vulnerability. By meticulously\nanalyzing the distinct characteristics of weight distributions across\nTransformer blocks, we propose two solutions that make different tradeoffs in\nhardware/software overhead. First, we propose a mixed strategy where less than\n3\\% of the layers employ finer per-group W8A8 quantization granularity. Second,\nwe introduce a bi-smoothing strategy that balances quantization errors between\nweights and activations while maintaining per-channel quantization throughout.\nExperimental results demonstrate that both strategies effectively preserve the\naccuracy of the entire LLaMA3-70B model series under W8A8 quantization,\nachieving performance on par with their FP16 counterparts.",
      "tldr_zh": "本文研究发现，LLaMA3-70B 系列模型在 W8A8 per-channel 量化中表现出独特的准确率下降问题，这在其他模型如 LLaMA2、LLaMA3/3.1-8B、Qwen 和 Mistral 等中并不明显。原因主要在于 LLaMA3-70B 的权重分布，而不是激活的动态范围。作者提出两种解决方案：一种是混合策略，仅对少于 3% 的层使用更细的 per-group W8A8 量化；另一种是 bi-smoothing 策略，用于平衡权重和激活之间的量化错误，同时保持 per-channel 量化。实验结果表明，这两种策略能有效恢复 LLaMA3-70B 系列的性能，使其在 W8A8 量化下与 FP16 相当。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 41 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.15301v2",
      "published_date": "2024-08-27 15:03:01 UTC",
      "updated_date": "2024-10-01 09:05:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:07:56.946952"
    },
    {
      "arxiv_id": "2408.15121v1",
      "title": "Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Sovrano",
        "Michael Lognoul",
        "Giulia Vilone"
      ],
      "abstract": "Significant investment and development have gone into integrating Artificial\nIntelligence (AI) in medical and healthcare applications, leading to advanced\ncontrol systems in medical technology. However, the opacity of AI systems\nraises concerns about essential characteristics needed in such sensitive\napplications, like transparency and trustworthiness. Our study addresses these\nconcerns by investigating a process for selecting the most adequate Explainable\nAI (XAI) methods to comply with the explanation requirements of key EU\nregulations in the context of smart bioelectronics for medical devices. The\nadopted methodology starts with categorising smart devices by their control\nmechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving\ninto their technology. Then, we analyse these regulations to define their\nexplainability requirements for the various devices and related goals.\nSimultaneously, we classify XAI methods by their explanatory objectives. This\nallows for matching legal explainability requirements with XAI explanatory\ngoals and determining the suitable XAI algorithms for achieving them. Our\nfindings provide a nuanced understanding of which XAI algorithms align better\nwith EU regulations for different types of medical devices. We demonstrate this\nthrough practical case studies on different neural implants, from chronic\ndisease management to advanced prosthetics. This study fills a crucial gap in\naligning XAI applications in bioelectronics with stringent provisions of EU\nregulations. It provides a practical framework for developers and researchers,\nensuring their AI innovations advance healthcare technology and adhere to legal\nand ethical standards.",
      "tldr_zh": "本研究提出了一种方法论，用于选择合适的Explainable AI (XAI) 方法，以确保智能生物医疗设备符合欧盟法规的解释要求。方法包括将设备分类为开放循环、闭环和半闭环系统，分析欧盟法规的解释性需求，并将XAI 方法按解释目标分类，从而匹配合适的XAI 算法。研究通过神经植入物案例研究（如慢性病管理和高级假肢）证明了特定XAI 算法与不同设备类型的法规对齐，提供了一个实用框架，帮助开发者在推进医疗技术的同时，满足法律和伦理标准。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication at ECAI 2024, main-track",
      "pdf_url": "http://arxiv.org/pdf/2408.15121v1",
      "published_date": "2024-08-27 14:59:27 UTC",
      "updated_date": "2024-08-27 14:59:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:08:10.200891"
    },
    {
      "arxiv_id": "2408.15119v3",
      "title": "A Permuted Autoregressive Approach to Word-Level Recognition for Urdu Digital Text",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Mustafa",
        "Muhammad Tahir Rafique",
        "Muhammad Ijlal Baig",
        "Hasan Sajid",
        "Muhammad Jawad Khan",
        "Karam Dad Kallu"
      ],
      "abstract": "This research paper introduces a novel word-level Optical Character\nRecognition (OCR) model specifically designed for digital Urdu text, leveraging\ntransformer-based architectures and attention mechanisms to address the\ndistinct challenges of Urdu script recognition, including its diverse text\nstyles, fonts, and variations. The model employs a permuted autoregressive\nsequence (PARSeq) architecture, which enhances its performance by enabling\ncontext-aware inference and iterative refinement through the training of\nmultiple token permutations. This method allows the model to adeptly manage\ncharacter reordering and overlapping characters, commonly encountered in Urdu\nscript. Trained on a dataset comprising approximately 160,000 Urdu text images,\nthe model demonstrates a high level of accuracy in capturing the intricacies of\nUrdu script, achieving a CER of 0.178. Despite ongoing challenges in handling\ncertain text variations, the model exhibits superior accuracy and effectiveness\nin practical applications. Future work will focus on refining the model through\nadvanced data augmentation techniques and the integration of context-aware\nlanguage models to further enhance its performance and robustness in Urdu text\nrecognition.",
      "tldr_zh": "本研究提出了一种针对数字乌尔都语文本的词级 Optical Character Recognition (OCR) 模型，利用 transformer-based 架构和 attention mechanisms 来应对乌尔都脚本的独特挑战，如多样化的文本样式、字体和变体。模型采用 permuted autoregressive sequence (PARSeq) 架构，通过训练多个 token permutations 实现上下文感知推理和迭代精炼，从而有效处理字符重新排序和重叠字符。在约 16 万乌尔都语文本图像数据集上训练，该模型达到了 CER 0.178 的高准确率，并展示了在实际应用中的优越性能。未来工作将通过高级数据增强技术和整合上下文感知语言模型，进一步提升模型的鲁棒性和表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15119v3",
      "published_date": "2024-08-27 14:58:13 UTC",
      "updated_date": "2024-08-30 15:29:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:08:18.888775"
    },
    {
      "arxiv_id": "2409.00107v1",
      "title": "Evaluating the Impact of Multiple DER Aggregators on Wholesale Energy Markets: A Hybrid Mean Field Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Jun He",
        "Andrew L. Liu"
      ],
      "abstract": "The integration of distributed energy resources (DERs) into wholesale energy\nmarkets can greatly enhance grid flexibility, improve market efficiency, and\ncontribute to a more sustainable energy future. As DERs -- such as solar PV\npanels and energy storage -- proliferate, effective mechanisms are needed to\nensure that small prosumers can participate meaningfully in these markets. We\nstudy a wholesale market model featuring multiple DER aggregators, each\ncontrolling a portfolio of DER resources and bidding into the market on behalf\nof the DER asset owners. The key of our approach lies in recognizing the\nrepeated nature of market interactions the ability of participants to learn and\nadapt over time. Specifically, Aggregators repeatedly interact with each other\nand with other suppliers in the wholesale market, collectively shaping\nwholesale electricity prices (aka the locational marginal prices (LMPs)). We\nmodel this multi-agent interaction using a mean-field game (MFG), which uses\nmarket information -- reflecting the average behavior of market participants --\nto enable each aggregator to predict long-term LMP trends and make informed\ndecisions. For each aggregator, because they control the DERs within their\nportfolio under certain contract structures, we employ a mean-field control\n(MFC) approach (as opposed to a MFG) to learn an optimal policy that maximizes\nthe total rewards of the DERs under their management. We also propose a\nreinforcement learning (RL)-based method to help each agent learn optimal\nstrategies within the MFG framework, enhancing their ability to adapt to market\nconditions and uncertainties. Numerical simulations show that LMPs quickly\nreach a steady state in the hybrid mean-field approach. Furthermore, our\nresults demonstrate that the combination of energy storage and mean-field\nlearning significantly reduces price volatility compared to scenarios without\nstorage.",
      "tldr_zh": "这篇论文评估了多个分布式能源资源（DERs）聚合器对批发能源市场的冲击，旨在通过有效机制提升小型生产消费者的参与度。研究采用均值场游戏（Mean-Field Game, MFG）建模多智能体互动，帮助聚合器预测长期定位边际价格（LMPs）趋势，并使用均值场控制（Mean-Field Control, MFC）优化每个聚合器的策略，以最大化其管理的DER回报。论文还引入基于强化学习（Reinforcement Learning, RL）的算法，使代理能够适应市场不确定性。模拟结果显示，该混合方法使LMPs快速达到稳态，且结合能源存储显著降低了价格波动。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "econ.GN",
        "math.OC",
        "q-fin.EC"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00107v1",
      "published_date": "2024-08-27 14:56:28 UTC",
      "updated_date": "2024-08-27 14:56:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:08:31.352138"
    },
    {
      "arxiv_id": "2408.15116v1",
      "title": "Evaluating Stability of Unreflective Alignment",
      "title_zh": "评估非反射性对齐的稳定性",
      "authors": [
        "James Lucassen",
        "Mark Henry",
        "Philippa Wright",
        "Owen Yeung"
      ],
      "abstract": "Many theoretical obstacles to AI alignment are consequences of reflective\nstability - the problem of designing alignment mechanisms that the AI would not\ndisable if given the option. However, problems stemming from reflective\nstability are not obviously present in current LLMs, leading to disagreement\nover whether they will need to be solved to enable safe delegation of cognitive\nlabor. In this paper, we propose Counterfactual Priority Change (CPC)\ndestabilization as a mechanism by which reflective stability problems may arise\nin future LLMs. We describe two risk factors for CPC-destabilization: 1)\nCPC-based stepping back and 2) preference instability. We develop preliminary\nevaluations for each of these risk factors, and apply them to frontier LLMs.\nOur findings indicate that in current LLMs, increased scale and capability are\nassociated with increases in both CPC-based stepping back and preference\ninstability, suggesting that CPC-destabilization may cause reflective stability\nproblems in future LLMs.",
      "tldr_zh": "这篇论文评估了AI对齐（alignment）中非反射稳定性（unreflective alignment）的潜在问题，焦点在于提出Counterfactual Priority Change (CPC) destabilization作为未来大型语言模型（LLMs）可能引发的反射稳定性（reflective stability）风险机制。论文识别了两个关键风险因素：1) CPC-based stepping back，以及2) preference instability，并开发了初步评估方法应用于前沿LLMs。研究发现，随着LLMs规模和能力的提升，这两种风险因素均显著增加，表明CPC-destabilization可能在未来LLMs中引发反射稳定性问题，从而强调了需要解决这些问题以确保AI安全部署。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15116v1",
      "published_date": "2024-08-27 14:55:15 UTC",
      "updated_date": "2024-08-27 14:55:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:08:45.443414"
    },
    {
      "arxiv_id": "2408.15114v1",
      "title": "Few-Shot Unsupervised Implicit Neural Shape Representation Learning with Spatial Adversaries",
      "title_zh": "翻译失败",
      "authors": [
        "Amine Ouasfi",
        "Adnane Boukhayma"
      ],
      "abstract": "Implicit Neural Representations have gained prominence as a powerful\nframework for capturing complex data modalities, encompassing a wide range from\n3D shapes to images and audio. Within the realm of 3D shape representation,\nNeural Signed Distance Functions (SDF) have demonstrated remarkable potential\nin faithfully encoding intricate shape geometry. However, learning SDFs from\nsparse 3D point clouds in the absence of ground truth supervision remains a\nvery challenging task. While recent methods rely on smoothness priors to\nregularize the learning, our method introduces a regularization term that\nleverages adversarial samples around the shape to improve the learned SDFs.\nThrough extensive experiments and evaluations, we illustrate the efficacy of\nour proposed method, highlighting its capacity to improve SDF learning with\nrespect to baselines and the state-of-the-art using synthetic and real data.",
      "tldr_zh": "该论文探讨了在无监督 Few-Shot 环境中学习 Implicit Neural Shape Representation 的方法，特别针对 Neural Signed Distance Functions (SDF) 在从稀疏 3D 点云中捕捉复杂形状几何的挑战。作者引入了一种基于 Spatial Adversaries 的正则化项，利用形状周围的对抗样本来增强 SDF 学习，从而克服传统方法的平滑性先验局限性。通过广泛实验，证明该方法在合成和真实数据上显著优于基线和最先进技术，提升了形状表示的准确性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.15114v1",
      "published_date": "2024-08-27 14:54:33 UTC",
      "updated_date": "2024-08-27 14:54:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:08:56.526754"
    },
    {
      "arxiv_id": "2409.00106v1",
      "title": "Zero-Shot Visual Reasoning by Vision-Language Models: Benchmarking and Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Aishik Nagar",
        "Shantanu Jaiswal",
        "Cheston Tan"
      ],
      "abstract": "Vision-language models (VLMs) have shown impressive zero- and few-shot\nperformance on real-world visual question answering (VQA) benchmarks, alluding\nto their capabilities as visual reasoning engines. However, the benchmarks\nbeing used conflate \"pure\" visual reasoning with world knowledge, and also have\nquestions that involve a limited number of reasoning steps. Thus, it remains\nunclear whether a VLM's apparent visual reasoning performance is due to its\nworld knowledge, or due to actual visual reasoning capabilities.\n  To clarify this ambiguity, we systematically benchmark and dissect the\nzero-shot visual reasoning capabilities of VLMs through synthetic datasets that\nrequire minimal world knowledge, and allow for analysis over a broad range of\nreasoning steps. We focus on two novel aspects of zero-shot visual reasoning:\ni) evaluating the impact of conveying scene information as either visual\nembeddings or purely textual scene descriptions to the underlying large\nlanguage model (LLM) of the VLM, and ii) comparing the effectiveness of\nchain-of-thought prompting to standard prompting for zero-shot visual\nreasoning.\n  We find that the underlying LLMs, when provided textual scene descriptions,\nconsistently perform better compared to being provided visual embeddings. In\nparticular, 18% higher accuracy is achieved on the PTR dataset. We also find\nthat CoT prompting performs marginally better than standard prompting only for\nthe comparatively large GPT-3.5-Turbo (175B) model, and does worse for\nsmaller-scale models. This suggests the emergence of CoT abilities for visual\nreasoning in LLMs at larger scales even when world knowledge is limited.\nOverall, we find limitations in the abilities of VLMs and LLMs for more complex\nvisual reasoning, and highlight the important role that LLMs can play in visual\nreasoning.",
      "tldr_zh": "本研究评估了视觉语言模型 (VLMs) 在零样本视觉推理中的能力，通过合成数据集进行基准测试和分析，这些数据集最小化世界知识影响，并覆盖多种推理步骤。研究比较了将场景信息作为视觉嵌入或纯文本描述提供给底层大语言模型 (LLMs) 的效果，发现文本描述显著提升性能，尤其在 PTR 数据集上准确率提高 18%。此外，Chain-of-Thought (CoT) 提示仅在大规模模型如 GPT-3.5-Turbo (175B) 上略优于标准提示，而在较小模型中表现更差，整体揭示了 VLMs 和 LLMs 在复杂视觉推理中的局限性，并强调了 LLMs 在此领域的重要作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.00106v1",
      "published_date": "2024-08-27 14:43:54 UTC",
      "updated_date": "2024-08-27 14:43:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:09:09.050954"
    },
    {
      "arxiv_id": "2408.15300v1",
      "title": "GIFT-SW: Gaussian noise Injected Fine-Tuning of Salient Weights for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Maxim Zhelnin",
        "Viktor Moskvoretskii",
        "Egor Shvetsov",
        "Egor Venediktov",
        "Mariya Krylova",
        "Aleksandr Zuev",
        "Evgeny Burnaev"
      ],
      "abstract": "Parameter Efficient Fine-Tuning (PEFT) methods have gained popularity and\ndemocratized the usage of Large Language Models (LLMs). Recent studies have\nshown that a small subset of weights significantly impacts performance. Based\non this observation, we introduce a novel PEFT method, called Gaussian noise\nInjected Fine Tuning of Salient Weights (GIFT-SW). Our method updates only\nsalient columns, while injecting Gaussian noise into non-salient ones. To\nidentify these columns, we developeda generalized sensitivity metric that\nextends and unifies metrics from previous studies. Experiments with LLaMA\nmodels demonstrate that GIFT-SW outperforms full fine-tuning and modern PEFT\nmethods under the same computational budget. Moreover, GIFT-SW offers practical\nadvantages to recover performance of models subjected to mixed-precision\nquantization with keeping salient weights in full precision.",
      "tldr_zh": "该论文提出了一种新型参数高效微调 (PEFT) 方法，名为 GIFT-SW，用于大型语言模型 (LLMs)，旨在通过更新显著权重 (salient weights) 并向非显著权重注入 Gaussian noise 来提升性能。方法采用一个广义的敏感性指标来识别这些权重，从而减少计算开销。实验结果显示，在 LLaMA 模型上，GIFT-SW 在相同计算预算下优于全微调和现代 PEFT 方法。此外，该方法还能帮助恢复混合精度量化后模型的性能，同时保持显著权重在全精度状态。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15300v1",
      "published_date": "2024-08-27 14:41:14 UTC",
      "updated_date": "2024-08-27 14:41:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:09:20.062167"
    },
    {
      "arxiv_id": "2409.00105v2",
      "title": "Negation Blindness in Large Language Models: Unveiling the NO Syndrome in Image Generation",
      "title_zh": "大型语言模型中的否定盲视：揭示图像生成中的 NO 综合征",
      "authors": [
        "Mohammad Nadeem",
        "Shahab Saquib Sohail",
        "Erik Cambria",
        "Björn W. Schuller",
        "Amir Hussain"
      ],
      "abstract": "Foundational Large Language Models (LLMs) have changed the way we perceive\ntechnology. They have been shown to excel in tasks ranging from poem writing\nand coding to essay generation and puzzle solving. With the incorporation of\nimage generation capability, they have become more comprehensive and versatile\nAI tools. At the same time, researchers are striving to identify the\nlimitations of these tools to improve them further. Currently identified flaws\ninclude hallucination, biases, and bypassing restricted commands to generate\nharmful content. In the present work, we have identified a fundamental\nlimitation related to the image generation ability of LLMs, and termed it The\nNO Syndrome. This negation blindness refers to LLMs inability to correctly\ncomprehend NO related natural language prompts to generate the desired images.\nInterestingly, all tested LLMs including GPT-4, Gemini, and Copilot were found\nto be suffering from this syndrome. To demonstrate the generalization of this\nlimitation, we carried out simulation experiments and conducted entropy-based\nand benchmark statistical analysis tests on various LLMs in multiple languages,\nincluding English, Hindi, and French. We conclude that the NO syndrome is a\nsignificant flaw in current LLMs that needs to be addressed. A related finding\nof this study showed a consistent discrepancy between image and textual\nresponses as a result of this NO syndrome. We posit that the introduction of a\nnegation context-aware reinforcement learning based feedback loop between the\nLLMs textual response and generated image could help ensure the generated text\nis based on both the LLMs correct contextual understanding of the negation\nquery and the generated visual output.",
      "tldr_zh": "本文研究揭示了Large Language Models (LLMs) 在图像生成中的Negation Blindness问题，即NO Syndrome，这是一种LLMs无法正确理解带有否定词（如“NO”）的自然语言提示，从而生成错误图像的核心缺陷。研究者通过模拟实验、熵-based分析和基准统计测试，评估了GPT-4、Gemini和Copilot等模型在英语、印地语和法语等多种语言上的表现，结果显示所有测试模型均受此症候影响。实验还发现，该问题导致图像和文本响应之间存在显著不一致，并建议引入基于否定上下文感知的强化学习反馈循环，以提升LLMs的准确性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.00105v2",
      "published_date": "2024-08-27 14:40:16 UTC",
      "updated_date": "2024-09-04 14:40:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:09:32.124769"
    },
    {
      "arxiv_id": "2408.15101v1",
      "title": "MTMamba++: Enhancing Multi-Task Dense Scene Understanding via Mamba-Based Decoders",
      "title_zh": "翻译失败",
      "authors": [
        "Baijiong Lin",
        "Weisen Jiang",
        "Pengguang Chen",
        "Shu Liu",
        "Ying-Cong Chen"
      ],
      "abstract": "Multi-task dense scene understanding, which trains a model for multiple dense\nprediction tasks, has a wide range of application scenarios. Capturing\nlong-range dependency and enhancing cross-task interactions are crucial to\nmulti-task dense prediction. In this paper, we propose MTMamba++, a novel\narchitecture for multi-task scene understanding featuring with a Mamba-based\ndecoder. It contains two types of core blocks: self-task Mamba (STM) block and\ncross-task Mamba (CTM) block. STM handles long-range dependency by leveraging\nstate-space models, while CTM explicitly models task interactions to facilitate\ninformation exchange across tasks. We design two types of CTM block, namely\nF-CTM and S-CTM, to enhance cross-task interaction from feature and semantic\nperspectives, respectively. Experiments on NYUDv2, PASCAL-Context, and\nCityscapes datasets demonstrate the superior performance of MTMamba++ over\nCNN-based and Transformer-based methods. The code is available at\nhttps://github.com/EnVision-Research/MTMamba.",
      "tldr_zh": "本论文提出 MTMamba++，一种基于 Mamba 的解码器架构，用于提升多任务密集场景理解，通过捕捉长距离依赖和增强跨任务交互。架构的核心组件包括自任务 Mamba (STM) 块，利用状态空间模型处理长距离依赖，以及跨任务 Mamba (CTM) 块，包括 F-CTM 和 S-CTM 两种类型，分别从特征和语义角度促进任务间信息交换。实验在 NYUDv2、PASCAL-Context 和 Cityscapes 数据集上表明，MTMamba++ 优于基于 CNN 和 Transformer 的方法，展示了其在多任务密集预测中的卓越性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: text overlap with arXiv:2407.02228",
      "pdf_url": "http://arxiv.org/pdf/2408.15101v1",
      "published_date": "2024-08-27 14:36:46 UTC",
      "updated_date": "2024-08-27 14:36:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:09:43.777583"
    },
    {
      "arxiv_id": "2408.15099v3",
      "title": "No Regrets: Investigating and Improving Regret Approximations for Curriculum Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Rutherford",
        "Michael Beukman",
        "Timon Willi",
        "Bruno Lacerda",
        "Nick Hawes",
        "Jakob Foerster"
      ],
      "abstract": "What data or environments to use for training to improve downstream\nperformance is a longstanding and very topical question in reinforcement\nlearning. In particular, Unsupervised Environment Design (UED) methods have\ngained recent attention as their adaptive curricula promise to enable agents to\nbe robust to in- and out-of-distribution tasks. This work investigates how\nexisting UED methods select training environments, focusing on task\nprioritisation metrics. Surprisingly, despite methods aiming to maximise regret\nin theory, the practical approximations do not correlate with regret but with\nsuccess rate. As a result, a significant portion of an agent's experience comes\nfrom environments it has already mastered, offering little to no contribution\ntoward enhancing its abilities. Put differently, current methods fail to\npredict intuitive measures of ``learnability.'' Specifically, they are unable\nto consistently identify those scenarios that the agent can sometimes solve,\nbut not always. Based on our analysis, we develop a method that directly trains\non scenarios with high learnability. This simple and intuitive approach\noutperforms existing UED methods in several binary-outcome environments,\nincluding the standard domain of Minigrid and a novel setting closely inspired\nby a real-world robotics problem. We further introduce a new adversarial\nevaluation procedure for directly measuring robustness, closely mirroring the\nconditional value at risk (CVaR). We open-source all our code and present\nvisualisations of final policies here:\nhttps://github.com/amacrutherford/sampling-for-learnability.",
      "tldr_zh": "本文研究了强化学习中 Unsupervised Environment Design (UED) 方法的任务优先级指标，发现现有方法虽理论上旨在最大化 regret，但实际近似值更依赖 success rate，导致代理在已掌握的环境上浪费大量经验，无法有效识别“learnability”（代理有时能解决但不稳定的场景）。为此，作者提出了一种直接针对高 learnability 场景训练的简单方法，该方法在 Minigrid 和受真实机器人问题启发的环境中优于现有 UED 方法。实验结果显示，新方法显著提升了代理的性能，并引入了新的对抗性评估程序，类似于 conditional value at risk (CVaR)，用于直接测量 robust 性。作者开源了代码并提供了策略可视化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15099v3",
      "published_date": "2024-08-27 14:31:54 UTC",
      "updated_date": "2024-10-29 18:25:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:09:57.473886"
    },
    {
      "arxiv_id": "2408.16088v1",
      "title": "Ensuring Equitable Financial Decisions: Leveraging Counterfactual Fairness and Deep Learning for Bias",
      "title_zh": "翻译失败",
      "authors": [
        "Saish Shinde"
      ],
      "abstract": "Concerns regarding fairness and bias have been raised in recent years due to\nthe growing use of machine learning models in crucial decision-making\nprocesses, especially when it comes to delicate characteristics like gender. In\norder to address biases in machine learning models, this research paper\ninvestigates advanced bias mitigation techniques, with a particular focus on\ncounterfactual fairness in conjunction with data augmentation. The study looks\ninto how these integrated approaches can lessen gender bias in the financial\nindustry, specifically in loan approval procedures. We show that these\napproaches are effective in achieving more equitable results through thorough\ntesting and assessment on a skewed financial dataset. The findings emphasize\nhow crucial it is to use fairness-aware techniques when creating machine\nlearning models in order to guarantee morally righteous and impartial\ndecision-making.",
      "tldr_zh": "本研究探讨了机器学习模型在决策过程中存在的偏置问题，特别是性别偏置，旨在通过整合反事实公平性（counterfactual fairness）和数据增强（data augmentation）来缓解这些偏置。论文专注于金融领域的贷款审批流程，使用这些先进技术在偏置数据集上进行测试，证明了它们能有效实现更公平的结果。最终，研究强调了在开发机器学习模型时采用公平感知技术的重要性，以确保道德和公正的决策过程。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.16088v1",
      "published_date": "2024-08-27 14:28:06 UTC",
      "updated_date": "2024-08-27 14:28:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:10:07.086987"
    },
    {
      "arxiv_id": "2408.15096v2",
      "title": "Post-processing fairness with minimal changes",
      "title_zh": "翻译失败",
      "authors": [
        "Federico Di Gennaro",
        "Thibault Laugel",
        "Vincent Grari",
        "Xavier Renard",
        "Marcin Detyniecki"
      ],
      "abstract": "In this paper, we introduce a novel post-processing algorithm that is both\nmodel-agnostic and does not require the sensitive attribute at test time. In\naddition, our algorithm is explicitly designed to enforce minimal changes\nbetween biased and debiased predictions; a property that, while highly\ndesirable, is rarely prioritized as an explicit objective in fairness\nliterature. Our approach leverages a multiplicative factor applied to the logit\nvalue of probability scores produced by a black-box classifier. We demonstrate\nthe efficacy of our method through empirical evaluations, comparing its\nperformance against other four debiasing algorithms on two widely used datasets\nin fairness research.",
      "tldr_zh": "本文提出了一种新型后处理算法，用于实现模型无关（model-agnostic）的公平性调整，同时在测试时无需敏感属性（sensitive attribute），并优先最小化偏置预测和去偏预测之间的变化。算法的核心方法是通过对黑箱分类器的logit值应用乘法因子来调整概率分数。实验结果显示，该算法在两个广泛使用的公平性数据集上，与其他四个debiasing algorithms相比，表现出色，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15096v2",
      "published_date": "2024-08-27 14:26:56 UTC",
      "updated_date": "2024-08-29 15:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:10:18.858869"
    },
    {
      "arxiv_id": "2408.15079v1",
      "title": "BaichuanSEED: Sharing the Potential of ExtensivE Data Collection and Deduplication by Introducing a Competitive Large Language Model Baseline",
      "title_zh": "翻译失败",
      "authors": [
        "Guosheng Dong",
        "Da Pan",
        "Yiding Sun",
        "Shusen Zhang",
        "Zheng Liang",
        "Xin Wu",
        "Yanjun Shen",
        "Fan Yang",
        "Haoze Sun",
        "Tianpeng Li",
        "Mingan Lin",
        "Jianhua Xu",
        "Yufan Zhang",
        "Xiaonan Nie",
        "Lei Su",
        "Bingning Wang",
        "Wentao Zhang",
        "Jiaxin Mao",
        "Zenan Zhou",
        "Weipeng Chen"
      ],
      "abstract": "The general capabilities of Large Language Models (LLM) highly rely on the\ncomposition and selection on extensive pretraining datasets, treated as\ncommercial secrets by several institutions. To mitigate this issue, we\nopen-source the details of a universally applicable data processing pipeline\nand validate its effectiveness and potential by introducing a competitive LLM\nbaseline. Specifically, the data processing pipeline consists of broad\ncollection to scale up and reweighting to improve quality. We then pretrain a\n7B model BaichuanSEED with 3T tokens processed by our pipeline without any\ndeliberate downstream task-related optimization, followed by an easy but\neffective supervised fine-tuning stage. BaichuanSEED demonstrates consistency\nand predictability throughout training and achieves comparable performance on\ncomprehensive benchmarks with several commercial advanced large language\nmodels, such as Qwen1.5 and Llama3. We also conduct several heuristic\nexperiments to discuss the potential for further optimization of downstream\ntasks, such as mathematics and coding.",
      "tldr_zh": "该论文开源了一个通用数据处理管道，以解决大型语言模型（LLM）的预训练数据集依赖性和商业机密问题，该管道包括广泛数据收集和重新加权步骤，以提升数据规模和质量。研究者使用该管道处理3T tokens预训练了一个7B模型BaichuanSEED，并进行简单监督微调，而未针对特定下游任务优化。结果显示，BaichuanSEED在综合基准测试中表现出色，与Qwen1.5和Llama3等商业模型相当，并通过实验探讨了进一步优化数学和编码等任务的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.15079v1",
      "published_date": "2024-08-27 14:08:23 UTC",
      "updated_date": "2024-08-27 14:08:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:10:31.933961"
    },
    {
      "arxiv_id": "2408.15077v2",
      "title": "MMASD+: A Novel Dataset for Privacy-Preserving Behavior Analysis of Children with Autism Spectrum Disorder",
      "title_zh": "MMASD+：一个用于隐私保护的自闭谱系障碍儿童行为分析的新颖数据集",
      "authors": [
        "Pavan Uttej Ravva",
        "Behdokht Kiafar",
        "Pinar Kullu",
        "Jicheng Li",
        "Anjana Bhat",
        "Roghayeh Leila Barmaki"
      ],
      "abstract": "Autism spectrum disorder (ASD) is characterized by significant challenges in\nsocial interaction and comprehending communication signals. Recently,\ntherapeutic interventions for ASD have increasingly utilized Deep learning\npowered-computer vision techniques to monitor individual progress over time.\nThese models are trained on private, non-public datasets from the autism\ncommunity, creating challenges in comparing results across different models due\nto privacy-preserving data-sharing issues. This work introduces MMASD+, an\nenhanced version of the novel open-source dataset called Multimodal ASD\n(MMASD). MMASD+ consists of diverse data modalities, including 3D-Skeleton, 3D\nBody Mesh, and Optical Flow data. It integrates the capabilities of Yolov8 and\nDeep SORT algorithms to distinguish between the therapist and children,\naddressing a significant barrier in the original dataset. Additionally, a\nMultimodal Transformer framework is proposed to predict 11 action types and the\npresence of ASD. This framework achieves an accuracy of 95.03% for predicting\naction types and 96.42% for predicting ASD presence, demonstrating over a 10%\nimprovement compared to models trained on single data modalities. These\nfindings highlight the advantages of integrating multiple data modalities\nwithin the Multimodal Transformer framework.",
      "tldr_zh": "这篇论文引入了 MMASD+ 数据集，这是一个增强版的开源 Multimodal ASD (MMASD) 数据集，用于隐私保护的 Autism Spectrum Disorder (ASD) 儿童行为分析。MMASD+ 包含多种数据模态，如 3D-Skeleton、3D Body Mesh 和 Optical Flow 数据，并利用 Yolov8 和 Deep SORT 算法来区分治疗师和儿童，从而解决数据共享障碍。论文提出 Multimodal Transformer 框架，用于预测 11 种动作类型和 ASD 存在，分别达到 95.03% 和 96.42% 的准确率，比单一数据模态模型提升超过 10%。这些发现强调了整合多模态数据的优势，为 ASD 研究提供可比较的基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15077v2",
      "published_date": "2024-08-27 14:05:48 UTC",
      "updated_date": "2024-08-28 20:30:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:10:46.364463"
    },
    {
      "arxiv_id": "2408.15076v1",
      "title": "MiWaves Reinforcement Learning Algorithm",
      "title_zh": "MiWaves 强化学习算法",
      "authors": [
        "Susobhan Ghosh",
        "Yongyi Guo",
        "Pei-Yao Hung",
        "Lara Coughlin",
        "Erin Bonar",
        "Inbal Nahum-Shani",
        "Maureen Walton",
        "Susan Murphy"
      ],
      "abstract": "The escalating prevalence of cannabis use poses a significant public health\nchallenge globally. In the U.S., cannabis use is more prevalent among emerging\nadults (EAs) (ages 18-25) than any other age group, with legalization in the\nmultiple states contributing to a public perception that cannabis is less risky\nthan in prior decades. To address this growing concern, we developed MiWaves, a\nreinforcement learning (RL) algorithm designed to optimize the delivery of\npersonalized intervention prompts to reduce cannabis use among EAs. MiWaves\nleverages domain expertise and prior data to tailor the likelihood of delivery\nof intervention messages. This paper presents a comprehensive overview of the\nalgorithm's design, including key decisions and experimental outcomes. The\nfinalized MiWaves RL algorithm was deployed in a clinical trial from March to\nMay 2024.",
      "tldr_zh": "该研究针对大麻使用在全球尤其是emerging adults（18-25岁群体）中的日益流行问题，开发了MiWaves强化学习（RL）算法，以优化个性化干预提示的传递，从而减少大麻使用。MiWaves算法利用领域专业知识和先验数据来定制干预消息的频率和内容，确保干预更具针对性。论文详细概述了算法的设计决策、实验结果，并报告其在2024年3月至5月的临床试验中成功部署，为公共健康干预提供了可扩展的框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2402.17739",
      "pdf_url": "http://arxiv.org/pdf/2408.15076v1",
      "published_date": "2024-08-27 14:04:04 UTC",
      "updated_date": "2024-08-27 14:04:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:11:05.773826"
    },
    {
      "arxiv_id": "2408.15073v1",
      "title": "Interactive dense pixel visualizations for time series and model attribution explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Udo Schlegel",
        "Daniel A. Keim"
      ],
      "abstract": "The field of Explainable Artificial Intelligence (XAI) for Deep Neural\nNetwork models has developed significantly, offering numerous techniques to\nextract explanations from models. However, evaluating explanations is often not\ntrivial, and differences in applied metrics can be subtle, especially with\nnon-intelligible data. Thus, there is a need for visualizations tailored to\nexplore explanations for domains with such data, e.g., time series. We propose\nDAVOTS, an interactive visual analytics approach to explore raw time series\ndata, activations of neural networks, and attributions in a dense-pixel\nvisualization to gain insights into the data, models' decisions, and\nexplanations. To further support users in exploring large datasets, we apply\nclustering approaches to the visualized data domains to highlight groups and\npresent ordering strategies for individual and combined data exploration to\nfacilitate finding patterns. We visualize a CNN trained on the FordA dataset to\ndemonstrate the approach.",
      "tldr_zh": "本研究针对可解释人工智能(XAI)领域中评估模型解释的挑战，特别是处理非直观数据如时间序列时的问题，提出了一种交互式视觉分析方法DAVOTS。DAVOTS利用密集像素可视化(dense-pixel visualization)来探索原始时间序列数据、神经网络激活和归因，帮助用户洞察数据模式、模型决策及解释。论文还引入聚类(clustering)方法和排序策略，以支持大型数据集的探索，并通过在FordA数据集上训练的CNN模型进行演示，展示了该方法的有效性。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 2 figures, accepted at MLVIS 2023",
      "pdf_url": "http://arxiv.org/pdf/2408.15073v1",
      "published_date": "2024-08-27 14:02:21 UTC",
      "updated_date": "2024-08-27 14:02:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:11:08.494609"
    },
    {
      "arxiv_id": "2409.00103v1",
      "title": "Nuance Matters: Probing Epistemic Consistency in Causal Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Shaobo Cui",
        "Junyou Li",
        "Luca Mouchel",
        "Yiyang Feng",
        "Boi Faltings"
      ],
      "abstract": "To address this gap, our study introduces the concept of causal epistemic\nconsistency, which focuses on the self-consistency of Large Language Models\n(LLMs) in differentiating intermediates with nuanced differences in causal\nreasoning. We propose a suite of novel metrics -- intensity ranking\nconcordance, cross-group position agreement, and intra-group clustering -- to\nevaluate LLMs on this front. Through extensive empirical studies on 21\nhigh-profile LLMs, including GPT-4, Claude3, and LLaMA3-70B, we have favoring\nevidence that current models struggle to maintain epistemic consistency in\nidentifying the polarity and intensity of intermediates in causal reasoning.\nAdditionally, we explore the potential of using internal token probabilities as\nan auxiliary tool to maintain causal epistemic consistency. In summary, our\nstudy bridges a critical gap in AI research by investigating the\nself-consistency over fine-grained intermediates involved in causal reasoning.",
      "tldr_zh": "本研究引入了causal epistemic consistency的概念，评估大型语言模型(LLMs)在因果推理中区分细微差异中间变量的自一致性。研究者提出了三个新指标——intensity ranking concordance、cross-group position agreement和intra-group clustering——并对21个知名LLMs（如GPT-4、Claude3和LLaMA3-70B）进行了广泛实验。结果显示，这些模型在识别中间变量的极性和强度方面难以维持认知一致性。最终，该研究探讨了使用内部token probabilities作为辅助工具的潜力，并填补了AI领域因果推理自一致性研究的空白。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.00103v1",
      "published_date": "2024-08-27 13:42:34 UTC",
      "updated_date": "2024-08-27 13:42:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:11:21.827068"
    },
    {
      "arxiv_id": "2408.15299v1",
      "title": "TourSynbio: A Multi-Modal Large Model and Agent Framework to Bridge Text and Protein Sequences for Protein Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Yiqing Shen",
        "Zan Chen",
        "Michail Mamalakis",
        "Yungeng Liu",
        "Tianbin Li",
        "Yanzhou Su",
        "Junjun He",
        "Pietro Liò",
        "Yu Guang Wang"
      ],
      "abstract": "The structural similarities between protein sequences and natural languages\nhave led to parallel advancements in deep learning across both domains. While\nlarge language models (LLMs) have achieved much progress in the domain of\nnatural language processing, their potential in protein engineering remains\nlargely unexplored. Previous approaches have equipped LLMs with protein\nunderstanding capabilities by incorporating external protein encoders, but this\nfails to fully leverage the inherent similarities between protein sequences and\nnatural languages, resulting in sub-optimal performance and increased model\ncomplexity. To address this gap, we present TourSynbio-7B, the first\nmulti-modal large model specifically designed for protein engineering tasks\nwithout external protein encoders. TourSynbio-7B demonstrates that LLMs can\ninherently learn to understand proteins as language. The model is post-trained\nand instruction fine-tuned on InternLM2-7B using ProteinLMDataset, a dataset\ncomprising 17.46 billion tokens of text and protein sequence for\nself-supervised pretraining and 893K instructions for supervised fine-tuning.\nTourSynbio-7B outperforms GPT-4 on the ProteinLMBench, a benchmark of 944\nmanually verified multiple-choice questions, with 62.18% accuracy. Leveraging\nTourSynbio-7B's enhanced protein sequence understanding capability, we\nintroduce TourSynbio-Agent, an innovative framework capable of performing\nvarious protein engineering tasks, including mutation analysis, inverse\nfolding, protein folding, and visualization. TourSynbio-Agent integrates\npreviously disconnected deep learning models in the protein engineering domain,\noffering a unified conversational user interface for improved usability.\nFinally, we demonstrate the efficacy of TourSynbio-7B and TourSynbio-Agent\nthrough two wet lab case studies on vanilla key enzyme modification and steroid\ncompound catalysis.",
      "tldr_zh": "该论文提出TourSynbio-7B，一种不依赖外部蛋白编码器的多模态大型模型，旨在利用蛋白序列与自然语言的相似性来提升蛋白工程任务的性能。模型基于InternLM2-7B，通过在ProteinLMDataset（包含17.46亿tokens的自监督预训练和89.3万指令的监督微调）上进行后训练，实现了对蛋白序列的内在理解，并在ProteinLMBench基准测试中以62.18%的准确率优于GPT-4。进一步，论文引入TourSynbio-Agent框架，该框架整合多种深度学习模型，提供统一的对话式用户界面，支持任务如突变分析、逆折叠、蛋白折叠和可视化，并通过两个湿实验室案例研究（如关键酶修改和类固醇催化）证明了其实际效能。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15299v1",
      "published_date": "2024-08-27 13:36:00 UTC",
      "updated_date": "2024-08-27 13:36:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:11:36.496212"
    },
    {
      "arxiv_id": "2408.15055v1",
      "title": "Causal Rule Forest: Toward Interpretable and Precise Treatment Effect Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Chan Hsu",
        "Jun-Ting Wu",
        "Yihuang Kang"
      ],
      "abstract": "Understanding and inferencing Heterogeneous Treatment Effects (HTE) and\nConditional Average Treatment Effects (CATE) are vital for developing\npersonalized treatment recommendations. Many state-of-the-art approaches\nachieve inspiring performance in estimating HTE on benchmark datasets or\nsimulation studies. However, the indirect predicting manner and complex model\narchitecture reduce the interpretability of these approaches. To mitigate the\ngap between predictive performance and heterogeneity interpretability, we\nintroduce the Causal Rule Forest (CRF), a novel approach to learning hidden\npatterns from data and transforming the patterns into interpretable multi-level\nBoolean rules. By training the other interpretable causal inference models with\ndata representation learned by CRF, we can reduce the predictive errors of\nthese models in estimating HTE and CATE, while keeping their interpretability\nfor identifying subgroups that a treatment is more effective. Our experiments\nunderscore the potential of CRF to advance personalized interventions and\npolicies, paving the way for future research to enhance its scalability and\napplication across complex causal inference challenges.",
      "tldr_zh": "该论文针对理解和推断 Heterogeneous Treatment Effects (HTE) 与 Conditional Average Treatment Effects (CATE) 的挑战，提出 Causal Rule Forest (CRF) 模型，以平衡预测性能和可解释性。CRF 通过从数据中学习隐藏模式并将其转化为可解释的多级 Boolean rules，然后用于训练其他可解释的因果推断模型，从而减少 HTE 和 CATE 估计中的预测错误，同时识别治疗更有效的子群。实验结果表明，CRF 有助于推进个性化干预和政策，并为未来扩展其可扩展性和应用铺平道路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The 25th IEEE International Conference on Information Reuse and\n  Integration for Data Science (IRI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.15055v1",
      "published_date": "2024-08-27 13:32:31 UTC",
      "updated_date": "2024-08-27 13:32:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:11:44.560195"
    },
    {
      "arxiv_id": "2408.15041v1",
      "title": "Earth Observation Satellite Scheduling with Graph Neural Networks",
      "title_zh": "利用图神经网络的地球观测卫星调度",
      "authors": [
        "Antoine Jacquet",
        "Guillaume Infantes",
        "Nicolas Meuleau",
        "Emmanuel Benazera",
        "Stéphanie Roussel",
        "Vincent Baudoui",
        "Jonathan Guerra"
      ],
      "abstract": "The Earth Observation Satellite Planning (EOSP) is a difficult optimization\nproblem with considerable practical interest. A set of requested observations\nmust be scheduled on an agile Earth observation satellite while respecting\nconstraints on their visibility window, as well as maneuver constraints that\nimpose varying delays between successive observations. In addition, the problem\nis largely oversubscribed: there are much more candidate observations than what\ncan possibly be achieved. Therefore, one must select the set of observations\nthat will be performed while maximizing their weighted cumulative benefit, and\npropose a feasible schedule for these observations. As previous work mostly\nfocused on heuristic and iterative search algorithms, this paper presents a new\ntechnique for selecting and scheduling observations based on Graph Neural\nNetworks (GNNs) and Deep Reinforcement Learning (DRL). GNNs are used to extract\nrelevant information from the graphs representing instances of the EOSP, and\nDRL drives the search for optimal schedules. Our simulations show that it is\nable to learn on small problem instances and generalize to larger real-world\ninstances, with very competitive performance compared to traditional\napproaches.",
      "tldr_zh": "该论文针对Earth Observation Satellite Planning (EOSP)优化问题提出了一种新方法，该问题涉及在受可见窗口和机动约束的条件下调度卫星观察请求，同时从过度订阅的候选中选择高收益观察。研究利用Graph Neural Networks (GNNs)从表示EOSP实例的图中提取关键信息，并结合Deep Reinforcement Learning (DRL)驱动最佳调度的搜索过程。该方法在小规模实例上训练后，能泛化到真实大型实例，并显示出与传统算法相当甚至更具竞争力的性能。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at 17th European Workshop on Reinforcement Learning (EWRL\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.15041v1",
      "published_date": "2024-08-27 13:10:26 UTC",
      "updated_date": "2024-08-27 13:10:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:11:55.945163"
    },
    {
      "arxiv_id": "2408.15037v1",
      "title": "Evidence-Enhanced Triplet Generation Framework for Hallucination Alleviation in Generative Question Answering",
      "title_zh": "证据增强的三元组生成框架，用于生成式问答中的幻觉缓解",
      "authors": [
        "Haowei Du",
        "Huishuai Zhang",
        "Dongyan Zhao"
      ],
      "abstract": "To address the hallucination in generative question answering (GQA) where the\nanswer can not be derived from the document, we propose a novel\nevidence-enhanced triplet generation framework, EATQA, encouraging the model to\npredict all the combinations of (Question, Evidence, Answer) triplet by\nflipping the source pair and the target label to understand their logical\nrelationships, i.e., predict Answer(A), Question(Q), and Evidence(E) given a\nQE, EA, and QA pairs, respectively. Furthermore, we bridge the distribution gap\nto distill the knowledge from evidence in inference stage. Our framework\nensures the model to learn the logical relation between query, evidence and\nanswer, which simultaneously improves the evidence generation and query\nanswering. In this paper, we apply EATQA to LLama and it outperforms other\nLLMs-based methods and hallucination mitigation approaches on two challenging\nGQA benchmarks. Further analysis shows that our method not only keeps prior\nknowledge within LLM, but also mitigates hallucination and generates faithful\nanswers.",
      "tldr_zh": "为了缓解生成式问答 (GQA) 中的 hallucination 问题，即答案无法从文档中推导，本文提出了一种名为 EATQA 的证据增强三元组生成框架。该框架通过翻转源对和目标标签（如给定 QE 预测 A），鼓励模型学习 Question、Evidence 和 Answer 三元组之间的逻辑关系，并在推理阶段桥接分布差距以提炼证据知识。实验结果显示，应用于 LLaMA 的 EATQA 在两个 GQA 基准上超越其他基于 LLM 的方法和 hallucination 缓解策略，不仅保留了模型的先验知识，还显著改善了证据生成和答案的可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15037v1",
      "published_date": "2024-08-27 13:07:07 UTC",
      "updated_date": "2024-08-27 13:07:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:12:09.208068"
    },
    {
      "arxiv_id": "2408.15032v1",
      "title": "Mamba2MIL: State Space Duality Based Multiple Instance Learning for Computational Pathology",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqi Zhang",
        "Xiaoqian Zhang",
        "Jiakai Wang",
        "Yuancheng Yang",
        "Taiying Peng",
        "Chao Tong"
      ],
      "abstract": "Computational pathology (CPath) has significantly advanced the clinical\npractice of pathology. Despite the progress made, Multiple Instance Learning\n(MIL), a promising paradigm within CPath, continues to face challenges,\nparticularly related to incomplete information utilization. Existing\nframeworks, such as those based on Convolutional Neural Networks (CNNs),\nattention, and selective scan space state sequential model (SSM), lack\nsufficient flexibility and scalability in fusing diverse features, and cannot\neffectively fuse diverse features. Additionally, current approaches do not\nadequately exploit order-related and order-independent features, resulting in\nsuboptimal utilization of sequence information. To address these limitations,\nwe propose a novel MIL framework called Mamba2MIL. Our framework utilizes the\nstate space duality model (SSD) to model long sequences of patches of whole\nslide images (WSIs), which, combined with weighted feature selection, supports\nthe fusion processing of more branching features and can be extended according\nto specific application needs. Moreover, we introduce a sequence transformation\nmethod tailored to varying WSI sizes, which enhances sequence-independent\nfeatures while preserving local sequence information, thereby improving\nsequence information utilization. Extensive experiments demonstrate that\nMamba2MIL surpasses state-of-the-art MIL methods. We conducted extensive\nexperiments across multiple datasets, achieving improvements in nearly all\nperformance metrics. Specifically, on the NSCLC dataset, Mamba2MIL achieves a\nbinary tumor classification AUC of 0.9533 and an accuracy of 0.8794. On the\nBRACS dataset, it achieves a multiclass classification AUC of 0.7986 and an\naccuracy of 0.4981. The code is available at\nhttps://github.com/YuqiZhang-Buaa/Mamba2MIL.",
      "tldr_zh": "本研究针对计算病理学（Computational Pathology）中的 Multiple Instance Learning (MIL) 问题，提出了一种新型框架 Mamba2MIL，以解决现有方法在融合多样特征和利用顺序相关/无关信息方面的不足。Mamba2MIL 利用 state space duality model (SSD) 来建模 Whole Slide Images (WSIs) 的长序列，并结合 weighted feature selection 和 sequence transformation 方法，提升特征融合的灵活性和序列信息利用效率。实验结果显示，该框架在多个数据集上超越了最先进的方法，例如在 NSCLC 数据集上实现二元肿瘤分类 AUC 为 0.9533 和准确率 0.8794，在 BRACS 数据集上达到多类分类 AUC 为 0.7986 和准确率 0.4981。代码已在 https://github.com/YuqiZhang-Buaa/Mamba2MIL 公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15032v1",
      "published_date": "2024-08-27 13:01:19 UTC",
      "updated_date": "2024-08-27 13:01:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:12:21.154983"
    },
    {
      "arxiv_id": "2408.15026v1",
      "title": "Sequence-aware Pre-training for Echocardiography Probe Guidance",
      "title_zh": "针对超声心动图探头引导的序列感知预训练",
      "authors": [
        "Haojun Jiang",
        "Zhenguo Sun",
        "Yu Sun",
        "Ning Jia",
        "Meng Li",
        "Shaqi Luo",
        "Shiji Song",
        "Gao Huang"
      ],
      "abstract": "Cardiac ultrasound probe guidance aims to help novices adjust the 6-DOF probe\npose to obtain high-quality sectional images. Cardiac ultrasound faces two\nmajor challenges: (1) the inherently complex structure of the heart, and (2)\nsignificant individual variations. Previous works have only learned the\npopulation-averaged 2D and 3D structures of the heart rather than personalized\ncardiac structural features, leading to a performance bottleneck. Clinically,\nwe observed that sonographers adjust their understanding of a patient's cardiac\nstructure based on prior scanning sequences, thereby modifying their scanning\nstrategies. Inspired by this, we propose a sequence-aware self-supervised\npre-training method. Specifically, our approach learns personalized 2D and 3D\ncardiac structural features by predicting the masked-out images and actions in\na scanning sequence. We hypothesize that if the model can predict the missing\ncontent it has acquired a good understanding of the personalized cardiac\nstructure. In the downstream probe guidance task, we also introduced a sequence\nmodeling approach that models individual cardiac structural information based\non the images and actions from historical scan data, enabling more accurate\nnavigation decisions. Experiments on a large-scale dataset with 1.36 million\nsamples demonstrated that our proposed sequence-aware paradigm can\nsignificantly reduce navigation errors, with translation errors decreasing by\n15.90% to 36.87% and rotation errors decreasing by 11.13% to 20.77%, compared\nto state-of-the-art methods.",
      "tldr_zh": "这篇论文针对心脏超声（Echocardiography）探头引导问题，提出了一种序列感知的自监督预训练方法，以应对心脏结构复杂性和个体差异挑战。该方法通过预测扫描序列中被掩盖的图像和动作，来学习个性化的2D和3D心脏结构特征，从而提升模型对患者特定结构的理解。在下游探头引导任务中，引入序列建模技术，利用历史扫描数据中的图像和动作优化导航决策。实验在包含136万样本的大型数据集上显示，与最先进方法相比，该范式显著降低了导航错误，平移错误减少15.90%至36.87%，旋转错误减少11.13%至20.77%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Tech Report",
      "pdf_url": "http://arxiv.org/pdf/2408.15026v1",
      "published_date": "2024-08-27 12:55:54 UTC",
      "updated_date": "2024-08-27 12:55:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:12:33.551901"
    },
    {
      "arxiv_id": "2408.15018v1",
      "title": "Cross-subject Brain Functional Connectivity Analysis for Multi-task Cognitive State Evaluation",
      "title_zh": "用于多任务认知状态评估的跨主体脑功能连接分析",
      "authors": [
        "Jun Chen",
        "Anqi Chen",
        "Bingkun Jiang",
        "Mohammad S. Obaidat",
        "Ni Li",
        "Xinyu Zhang"
      ],
      "abstract": "Cognition refers to the function of information perception and processing,\nwhich is the fundamental psychological essence of human beings. It is\nresponsible for reasoning and decision-making, while its evaluation is\nsignificant for the aviation domain in mitigating potential safety risks.\nExisting studies tend to use varied methods for cognitive state evaluation yet\nhave limitations in timeliness, generalisation, and interpretability.\nAccordingly, this study adopts brain functional connectivity with\nelectroencephalography signals to capture associations in brain regions across\nmultiple subjects for evaluating real-time cognitive states. Specifically, a\nvirtual reality-based flight platform is constructed with multi-screen\nembedded. Three distinctive cognitive tasks are designed and each has three\ndegrees of difficulty. Thirty subjects are acquired for analysis and\nevaluation. The results are interpreted through different perspectives,\nincluding inner-subject and cross-subject for task-wise and gender-wise\nunderlying brain functional connectivity. Additionally, this study incorporates\nquestionnaire-based, task performance-based, and physiological measure-based\napproaches to fairly label the trials. A multi-class cognitive state evaluation\nis further conducted with the active brain connections. Benchmarking results\ndemonstrate that the identified brain regions have considerable influences in\ncognition, with a multi-class accuracy rate of 95.83% surpassing existing\nstudies. The derived findings bring significance to understanding the dynamic\nrelationships among human brain functional regions, cross-subject cognitive\nbehaviours, and decision-making, which have promising practical application\nvalues.",
      "tldr_zh": "这篇论文提出了一种基于脑功能连接（brain functional connectivity）的跨主体分析方法，利用 EEG 信号评估多任务认知状态，以解决现有方法的及时性、泛化性和可解释性问题。研究构建了一个基于虚拟现实的飞行平台，设计了三个不同难度的认知任务，并对 30 名受试者进行任务导向和性别导向的内主体与跨主体分析，同时结合问卷、任务表现和生理测量进行试验标记。结果显示，该方法在多类认知状态评估中达到了 95.83% 的准确率，优于现有研究，并揭示了关键脑区的动态关系及其在决策和认知行为中的实际应用价值。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15018v1",
      "published_date": "2024-08-27 12:51:59 UTC",
      "updated_date": "2024-08-27 12:51:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:12:46.951640"
    },
    {
      "arxiv_id": "2409.06729v1",
      "title": "How will advanced AI systems impact democracy?",
      "title_zh": "先进的 AI 系统将如何影响民主？",
      "authors": [
        "Christopher Summerfield",
        "Lisa Argyle",
        "Michiel Bakker",
        "Teddy Collins",
        "Esin Durmus",
        "Tyna Eloundou",
        "Iason Gabriel",
        "Deep Ganguli",
        "Kobi Hackenburg",
        "Gillian Hadfield",
        "Luke Hewitt",
        "Saffron Huang",
        "Helene Landemore",
        "Nahema Marchal",
        "Aviv Ovadya",
        "Ariel Procaccia",
        "Mathias Risse",
        "Bruce Schneier",
        "Elizabeth Seger",
        "Divya Siddarth",
        "Henrik Skaug Sætra",
        "MH Tessler",
        "Matthew Botvinick"
      ],
      "abstract": "Advanced AI systems capable of generating humanlike text and multimodal\ncontent are now widely available. In this paper, we discuss the impacts that\ngenerative artificial intelligence may have on democratic processes. We\nconsider the consequences of AI for citizens' ability to make informed choices\nabout political representatives and issues (epistemic impacts). We ask how AI\nmight be used to destabilise or support democratic mechanisms like elections\n(material impacts). Finally, we discuss whether AI will strengthen or weaken\ndemocratic principles (foundational impacts). It is widely acknowledged that\nnew AI systems could pose significant challenges for democracy. However, it has\nalso been argued that generative AI offers new opportunities to educate and\nlearn from citizens, strengthen public discourse, help people find common\nground, and to reimagine how democracies might work better.",
      "tldr_zh": "这篇论文探讨了生成式 AI（generative AI）对民主过程的影响，重点分析其可能带来的挑战和机遇。作者从三个方面考量：认识论影响（epistemic impacts），即 AI 如何影响公民做出知情选择的ability；物质影响（material impacts），即 AI 在破坏或支持选举等民主机制中的作用；以及基础影响（foundational impacts），即 AI 是否会加强或削弱民主原则。尽管 AI 系统可能加剧民主风险，但论文也指出它能提供新机会，如提升公民教育、强化公共话语和重新设计民主运作方式。总的来说，这为理解 AI 在民主中的双重作用提供了全面框架。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "25 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.06729v1",
      "published_date": "2024-08-27 12:05:59 UTC",
      "updated_date": "2024-08-27 12:05:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:12:57.386965"
    },
    {
      "arxiv_id": "2408.14976v1",
      "title": "Prior-free Balanced Replay: Uncertainty-guided Reservoir Sampling for Long-Tailed Continual Learning",
      "title_zh": "无先验平衡重放：不确定性引导的 Reservoir 采样用于长尾持续学习",
      "authors": [
        "Lei Liu",
        "Li Liu",
        "Yawen Cui"
      ],
      "abstract": "Even in the era of large models, one of the well-known issues in continual\nlearning (CL) is catastrophic forgetting, which is significantly challenging\nwhen the continual data stream exhibits a long-tailed distribution, termed as\nLong-Tailed Continual Learning (LTCL). Existing LTCL solutions generally\nrequire the label distribution of the data stream to achieve re-balance\ntraining. However, obtaining such prior information is often infeasible in real\nscenarios since the model should learn without pre-identifying the majority and\nminority classes. To this end, we propose a novel Prior-free Balanced Replay\n(PBR) framework to learn from long-tailed data stream with less forgetting.\nConcretely, motivated by our experimental finding that the minority classes are\nmore likely to be forgotten due to the higher uncertainty, we newly design an\nuncertainty-guided reservoir sampling strategy to prioritize rehearsing\nminority data without using any prior information, which is based on the mutual\ndependence between the model and samples. Additionally, we incorporate two\nprior-free components to further reduce the forgetting issue: (1) Boundary\nconstraint is to preserve uncertain boundary supporting samples for continually\nre-estimating task boundaries. (2) Prototype constraint is to maintain the\nconsistency of learned class prototypes along with training. Our approach is\nevaluated on three standard long-tailed benchmarks, demonstrating superior\nperformance to existing CL methods and previous SOTA LTCL approach in both\ntask- and class-incremental learning settings, as well as ordered- and\nshuffled-LTCL settings.",
      "tldr_zh": "该研究针对长尾分布下的持续学习（Long-Tailed Continual Learning, LTCL）问题，提出了一种无需先验信息的框架Prior-free Balanced Replay (PBR)，以缓解灾难性遗忘。PBR 通过 uncertainty-guided reservoir sampling 策略，根据模型的不确定性优先 rehearsing 少数类数据，从而在不依赖标签分布的情况下平衡训练。框架还整合了 Boundary constraint（保留不确定边界样本以重新估计任务边界）和 Prototype constraint（维护类原型的 consistency），进一步减少遗忘。实验在三个标准长尾基准上显示，PBR 在 task- 和 class-incremental learning 设置中，以及 ordered- 和 shuffled-LTCL 设置中，均优于现有方法和最先进 LTCL 方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14976v1",
      "published_date": "2024-08-27 11:38:01 UTC",
      "updated_date": "2024-08-27 11:38:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:13:10.301952"
    },
    {
      "arxiv_id": "2408.15297v3",
      "title": "YOLO-Stutter: End-to-end Region-Wise Speech Dysfluency Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Xuanru Zhou",
        "Anshul Kashyap",
        "Steve Li",
        "Ayati Sharma",
        "Brittany Morin",
        "David Baquirin",
        "Jet Vonk",
        "Zoe Ezzes",
        "Zachary Miller",
        "Maria Luisa Gorno Tempini",
        "Jiachen Lian",
        "Gopala Krishna Anumanchipalli"
      ],
      "abstract": "Dysfluent speech detection is the bottleneck for disordered speech analysis\nand spoken language learning. Current state-of-the-art models are governed by\nrule-based systems which lack efficiency and robustness, and are sensitive to\ntemplate design. In this paper, we propose YOLO-Stutter: a first end-to-end\nmethod that detects dysfluencies in a time-accurate manner. YOLO-Stutter takes\nimperfect speech-text alignment as input, followed by a spatial feature\naggregator, and a temporal dependency extractor to perform region-wise boundary\nand class predictions. We also introduce two dysfluency corpus, VCTK-Stutter\nand VCTK-TTS, that simulate natural spoken dysfluencies including repetition,\nblock, missing, replacement, and prolongation. Our end-to-end method achieves\nstate-of-the-art performance with a minimum number of trainable parameters for\non both simulated data and real aphasia speech. Code and datasets are\nopen-sourced at https://github.com/rorizzz/YOLO-Stutter",
      "tldr_zh": "本文提出 YOLO-Stutter，一种首个端到端(end-to-end)方法，用于时间精确的言语流畅障碍(speech dysfluency)检测，解决了传统规则-based 系统在效率和鲁棒性上的不足。 该方法以 imperfect speech-text alignment 为输入，通过 spatial feature aggregator 和 temporal dependency extractor 进行 region-wise 的边界和类别预测。 此外，作者引入了 VCTK-Stutter 和 VCTK-TTS 语料库来模拟自然言语流畅障碍（如 repetition、block、missing、replacement 和 prolongation），并在模拟数据和真实失语症语音上实现了 state-of-the-art 性能，同时开源了代码和数据集。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.15297v3",
      "published_date": "2024-08-27 11:31:12 UTC",
      "updated_date": "2024-09-15 06:20:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:13:24.054584"
    },
    {
      "arxiv_id": "2408.14961v1",
      "title": "CVPT: Cross-Attention help Visual Prompt Tuning adapt visual task",
      "title_zh": "翻译失败",
      "authors": [
        "Lingyun Huang",
        "Jianxu Mao",
        "Yaonan Wang",
        "Junfei Yi",
        "Ziming Tao"
      ],
      "abstract": "In recent years, the rapid expansion of model sizes has led to large-scale\npre-trained models demonstrating remarkable capabilities. Consequently, there\nhas been a trend towards increasing the scale of models. However, this trend\nintroduces significant challenges, including substantial computational costs of\ntraining and transfer to downstream tasks. To address these issues,\nParameter-Efficient Fine-Tuning (PEFT) methods have been introduced. These\nmethods optimize large-scale pre-trained models for specific tasks by\nfine-tuning a select group of parameters. Among these PEFT methods,\nadapter-based and prompt-based methods are the primary techniques.\nSpecifically, in the field of visual fine-tuning, adapters gain prominence over\nprompts because of the latter's relatively weaker performance and efficiency.\nUnder the circumstances, we refine the widely-used Visual Prompt Tuning (VPT)\nmethod, proposing Cross Visual Prompt Tuning (CVPT). CVPT calculates\ncross-attention between the prompt tokens and the embedded tokens, which allows\nus to compute the semantic relationship between them and conduct the\nfine-tuning of models exactly to adapt visual tasks better. Furthermore, we\nintroduce the weight-sharing mechanism to initialize the parameters of\ncross-attention, which avoids massive learnable parameters from cross-attention\nand enhances the representative capability of cross-attention. We conduct\ncomprehensive testing across 25 datasets and the result indicates that CVPT\nsignificantly improves VPT's performance and efficiency in visual tasks. For\nexample, on the VTAB-1K benchmark, CVPT outperforms VPT over 4% in average\naccuracy, rivaling the advanced adapter-based methods in performance and\nefficiency. Our experiments confirm that prompt-based methods can achieve\nexceptional results in visual fine-tuning.",
      "tldr_zh": "该研究针对视觉微调中提示方法（如Visual Prompt Tuning, VPT）的性能不足问题，提出了一种改进框架Cross Visual Prompt Tuning (CVPT)。CVPT 通过计算提示标记和嵌入标记之间的Cross-Attention，捕捉语义关系，并引入权重共享机制来减少可学习参数，提升模型的适应性和效率。实验在25个数据集上进行，结果显示CVPT在VTAB-1K基准上比VPT平均准确率提高4%，并在性能和效率上媲美先进的Adapter-based方法，证明了提示方法在视觉任务中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14961v1",
      "published_date": "2024-08-27 11:07:19 UTC",
      "updated_date": "2024-08-27 11:07:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:13:34.010815"
    },
    {
      "arxiv_id": "2408.14960v1",
      "title": "Multilingual Arbitrage: Optimizing Data Pools to Accelerate Multilingual Progress",
      "title_zh": "多语言套利：优化数据池以加速",
      "authors": [
        "Ayomide Odumakinde",
        "Daniel D'souza",
        "Pat Verga",
        "Beyza Ermis",
        "Sara Hooker"
      ],
      "abstract": "The use of synthetic data has played a critical role in recent state-of-art\nbreakthroughs. However, overly relying on a single oracle teacher model to\ngenerate data has been shown to lead to model collapse and invite propagation\nof biases. These limitations are particularly evident in multilingual settings,\nwhere the absence of a universally effective teacher model that excels across\nall languages presents significant challenges. In this work, we address these\nextreme difference by introducing \"multilingual arbitrage\", which capitalizes\non performance variations between multiple models for a given language. To do\nso, we strategically route samples through a diverse pool of models, each with\nunique strengths in different languages. Across exhaustive experiments on\nstate-of-art models, our work suggests that arbitrage techniques allow for\nspectacular gains in performance that far outperform relying on a single\nteacher. In particular, compared to the best single teacher, we observe gains\nof up to 56.5% improvement in win rates averaged across all languages when\nswitching to multilingual arbitrage. We observe the most significant gains for\nthe least resourced languages in our pool.",
      "tldr_zh": "该研究探讨了合成数据(synthetic data)过度依赖单一教师模型(teacher model)所带来的模型崩溃和偏见传播问题，尤其在多语言环境中。论文引入“multilingual arbitrage”方法，通过利用多个模型在不同语言上的性能差异，战略性地路由样本以优化数据池，从而加速多语言模型的进步。实验结果显示，与最佳单一教师模型相比，该方法平均提高了56.5%的胜率，并在低资源语言上取得了最显著的性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14960v1",
      "published_date": "2024-08-27 11:07:15 UTC",
      "updated_date": "2024-08-27 11:07:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:13:45.217827"
    },
    {
      "arxiv_id": "2408.14950v1",
      "title": "NeuralOOD: Improving Out-of-Distribution Generalization Performance with Brain-machine Fusion Learning Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Shuangchen Zhao",
        "Changde Du",
        "Hui Li",
        "Huiguang He"
      ],
      "abstract": "Deep Neural Networks (DNNs) have demonstrated exceptional recognition\ncapabilities in traditional computer vision (CV) tasks. However, existing CV\nmodels often suffer a significant decrease in accuracy when confronted with\nout-of-distribution (OOD) data. In contrast to these DNN models, human can\nmaintain a consistently low error rate when facing OOD scenes, partly\nattributed to the rich prior cognitive knowledge stored in the human brain.\nPrevious OOD generalization researches only focus on the single modal,\noverlooking the advantages of multimodal learning method. In this paper, we\nutilize the multimodal learning method to improve the OOD generalization and\npropose a novel Brain-machine Fusion Learning (BMFL) framework. We adopt the\ncross-attention mechanism to fuse the visual knowledge from CV model and prior\ncognitive knowledge from the human brain. Specially, we employ a pre-trained\nvisual neural encoding model to predict the functional Magnetic Resonance\nImaging (fMRI) from visual features which eliminates the need for the fMRI data\ncollection and pre-processing, effectively reduces the workload associated with\nconventional BMFL methods. Furthermore, we construct a brain transformer to\nfacilitate the extraction of knowledge inside the fMRI data. Moreover, we\nintroduce the Pearson correlation coefficient maximization regularization\nmethod into the training process, which improves the fusion capability with\nbetter constrains. Our model outperforms the DINOv2 and baseline models on the\nImageNet-1k validation dataset as well as six curated OOD datasets, showcasing\nits superior performance in diverse scenarios.",
      "tldr_zh": "这篇论文提出了 NeuralOOD 框架，通过 Brain-machine Fusion Learning (BMFL) 方法来提升深度神经网络 (DNNs) 在 Out-of-Distribution (OOD) 数据上的泛化性能，借鉴人类脑部认知知识的优势。框架采用 cross-attention 机制融合视觉特征和 fMRI 认知知识，并使用预训练视觉神经编码模型预测 fMRI、构建 brain transformer 提取知识，以及引入 Pearson 相关系数最大化正则化来优化融合过程，从而减少数据收集工作量。实验结果显示，该模型在 ImageNet-1k 和六个 OOD 数据集上优于 DINOv2 和基线模型，证明了其在多样化场景中的出色表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14950v1",
      "published_date": "2024-08-27 10:54:37 UTC",
      "updated_date": "2024-08-27 10:54:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:13:59.531587"
    },
    {
      "arxiv_id": "2408.14935v1",
      "title": "Quotient Normalized Maximum Likelihood Criterion for Learning Bayesian Network Structures",
      "title_zh": "用于学习贝叶斯网络结构的商数归一化最大似然准则",
      "authors": [
        "Tomi Silander",
        "Janne Leppä-aho",
        "Elias Jääsaari",
        "Teemu Roos"
      ],
      "abstract": "We introduce an information theoretic criterion for Bayesian network\nstructure learning which we call quotient normalized maximum likelihood (qNML).\nIn contrast to the closely related factorized normalized maximum likelihood\ncriterion, qNML satisfies the property of score equivalence. It is also\ndecomposable and completely free of adjustable hyperparameters. For practical\ncomputations, we identify a remarkably accurate approximation proposed earlier\nby Szpankowski and Weinberger. Experiments on both simulated and real data\ndemonstrate that the new criterion leads to parsimonious models with good\npredictive accuracy.",
      "tldr_zh": "本研究提出了一种名为 quotient normalized maximum likelihood (qNML) 的信息理论标准，用于贝叶斯网络结构学习。不同于 factorized normalized maximum likelihood 标准，qNML 满足 score equivalence 属性，同时具备 decomposable 和无超参数的优点。研究采用 Szpankowski 和 Weinberger 早前提出的精确近似方法进行实际计算，并在模拟和真实数据实验中证明，qNML 能生成简洁的模型并实现良好的预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AISTATS 2018",
      "pdf_url": "http://arxiv.org/pdf/2408.14935v1",
      "published_date": "2024-08-27 10:17:22 UTC",
      "updated_date": "2024-08-27 10:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:14:08.685827"
    },
    {
      "arxiv_id": "2408.14925v1",
      "title": "Distance-Forward Learning: Enhancing the Forward-Forward Algorithm Towards High-Performance On-Chip Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yujie Wu",
        "Siyuan Xu",
        "Jibin Wu",
        "Lei Deng",
        "Mingkun Xu",
        "Qinghao Wen",
        "Guoqi Li"
      ],
      "abstract": "The Forward-Forward (FF) algorithm was recently proposed as a local learning\nmethod to address the limitations of backpropagation (BP), offering biological\nplausibility along with memory-efficient and highly parallelized computational\nbenefits. However, it suffers from suboptimal performance and poor\ngeneralization, largely due to inadequate theoretical support and a lack of\neffective learning strategies. In this work, we reformulate FF using distance\nmetric learning and propose a distance-forward algorithm (DF) to improve FF\nperformance in supervised vision tasks while preserving its local computational\nproperties, making it competitive for efficient on-chip learning. To achieve\nthis, we reinterpret FF through the lens of centroid-based metric learning and\ndevelop a goodness-based N-pair margin loss to facilitate the learning of\ndiscriminative features. Furthermore, we integrate layer-collaboration local\nupdate strategies to reduce information loss caused by greedy local parameter\nupdates. Our method surpasses existing FF models and other advanced local\nlearning approaches, with accuracies of 99.7\\% on MNIST, 88.2\\% on CIFAR-10,\n59\\% on CIFAR-100, 95.9\\% on SVHN, and 82.5\\% on ImageNette, respectively.\nMoreover, it achieves comparable performance with less than 40\\% memory cost\ncompared to BP training, while exhibiting stronger robustness to multiple types\nof hardware-related noise, demonstrating its potential for online learning and\nenergy-efficient computation on neuromorphic chips.",
      "tldr_zh": "该研究针对 Forward-Forward (FF) 算法的性能不足和泛化问题，提出 distance-forward algorithm (DF)，通过重新利用距离度量学习并开发 goodness-based N-pair margin loss 来学习判别特征，同时整合 layer-collaboration 本地更新策略，以减少信息损失并保持高效的本地计算特性。DF 算法在监督视觉任务中表现出色，在 MNIST 上达到 99.7% 准确率、CIFAR-10 上为 88.2%、CIFAR-100 上为 59%、SVHN 上为 95.9% 以及 ImageNette 上为 82.5%，优于现有 FF 模型和其他本地学习方法。相比 backpropagation (BP)，DF 使用不到 40% 的内存，并对硬件相关噪声具有更强鲁棒性，使其适用于在线学习和能量高效的 on-chip 神经形态芯片计算。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14925v1",
      "published_date": "2024-08-27 10:01:43 UTC",
      "updated_date": "2024-08-27 10:01:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:14:34.871792"
    },
    {
      "arxiv_id": "2408.15294v2",
      "title": "Evaluating the Predictive Features of Person-Centric Knowledge Graph Embeddings: Unfolding Ablation Studies",
      "title_zh": "评估以人为中心的知识图谱嵌入的预测特征：",
      "authors": [
        "Christos Theodoropoulos",
        "Natasha Mulligan",
        "Joao Bettencourt-Silva"
      ],
      "abstract": "Developing novel predictive models with complex biomedical information is\nchallenging due to various idiosyncrasies related to heterogeneity,\nstandardization or sparseness of the data. We previously introduced a\nperson-centric ontology to organize information about individual patients, and\na representation learning framework to extract person-centric knowledge graphs\n(PKGs) and to train Graph Neural Networks (GNNs). In this paper, we propose a\nsystematic approach to examine the results of GNN models trained with both\nstructured and unstructured information from the MIMIC-III dataset. Through\nablation studies on different clinical, demographic, and social data, we show\nthe robustness of this approach in identifying predictive features in PKGs for\nthe task of readmission prediction.",
      "tldr_zh": "该论文评估了 Person-Centric Knowledge Graphs (PKGs) 嵌入的预测特征，通过展开消融研究来应对生物医学数据中异质性、标准化和稀疏性的挑战。作者使用之前引入的 person-centric 本体和表示学习框架，训练 Graph Neural Networks (GNNs) 模型，并结合 MIMIC-III 数据集的结构化和非结构化信息进行系统分析。研究结果显示，该方法在再入院预测任务中表现出鲁棒性，能够有效识别临床、人口统计和社会数据的关键预测特征。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the 34th Medical Informatics Europe Conference",
      "pdf_url": "http://arxiv.org/pdf/2408.15294v2",
      "published_date": "2024-08-27 09:48:25 UTC",
      "updated_date": "2024-08-29 09:43:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:14:36.278576"
    },
    {
      "arxiv_id": "2408.14895v2",
      "title": "VHAKG: A Multi-modal Knowledge Graph Based on Synchronized Multi-view Videos of Daily Activities",
      "title_zh": "翻译失败",
      "authors": [
        "Shusaku Egami",
        "Takahiro Ugai",
        "Swe Nwe Nwe Htun",
        "Ken Fukuda"
      ],
      "abstract": "Multi-modal knowledge graphs (MMKGs), which ground various non-symbolic data\n(e.g., images and videos) into symbols, have attracted attention as resources\nenabling knowledge processing and machine learning across modalities. However,\nthe construction of MMKGs for videos consisting of multiple events, such as\ndaily activities, is still in the early stages. In this paper, we construct an\nMMKG based on synchronized multi-view simulated videos of daily activities.\nBesides representing the content of daily life videos as event-centric\nknowledge, our MMKG also includes frame-by-frame fine-grained changes, such as\nbounding boxes within video frames. In addition, we provide support tools for\nquerying our MMKG. As an application example, we demonstrate that our MMKG\nfacilitates benchmarking vision-language models by providing the necessary\nvision-language datasets for a tailored task.",
      "tldr_zh": "本研究构建了 VHAKG，一种基于同步多视图日常活动视频的多模态知识图 (MMKG)，旨在将非符号数据（如视频）转化为符号形式，支持跨模态知识处理和机器学习。VHAKG 不仅表示事件中心知识，还包括帧级细粒度变化，如 bounding boxes，以捕捉视频内容的详细动态。此外，该知识图提供了查询工具，并展示了其在基准测试 vision-language models 方面的应用潜力，为相关任务提供必要的视觉语言数据集。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "68T30",
        "I.2.4; H.5.1"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 4 figures, accepted by CIKM2024 Resource Track",
      "pdf_url": "http://arxiv.org/pdf/2408.14895v2",
      "published_date": "2024-08-27 09:18:57 UTC",
      "updated_date": "2024-08-28 01:56:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:14:49.755192"
    },
    {
      "arxiv_id": "2408.14886v1",
      "title": "The VoxCeleb Speaker Recognition Challenge: A Retrospective",
      "title_zh": "VoxCeleb 说话者识别挑战：回顾",
      "authors": [
        "Jaesung Huh",
        "Joon Son Chung",
        "Arsha Nagrani",
        "Andrew Brown",
        "Jee-weon Jung",
        "Daniel Garcia-Romero",
        "Andrew Zisserman"
      ],
      "abstract": "The VoxCeleb Speaker Recognition Challenges (VoxSRC) were a series of\nchallenges and workshops that ran annually from 2019 to 2023. The challenges\nprimarily evaluated the tasks of speaker recognition and diarisation under\nvarious settings including: closed and open training data; as well as\nsupervised, self-supervised, and semi-supervised training for domain\nadaptation. The challenges also provided publicly available training and\nevaluation datasets for each task and setting, with new test sets released each\nyear. In this paper, we provide a review of these challenges that covers: what\nthey explored; the methods developed by the challenge participants and how\nthese evolved; and also the current state of the field for speaker verification\nand diarisation. We chart the progress in performance over the five\ninstallments of the challenge on a common evaluation dataset and provide a\ndetailed analysis of how each year's special focus affected participants'\nperformance. This paper is aimed both at researchers who want an overview of\nthe speaker recognition and diarisation field, and also at challenge organisers\nwho want to benefit from the successes and avoid the mistakes of the VoxSRC\nchallenges. We end with a discussion of the current strengths of the field and\nopen challenges. Project page :\nhttps://mm.kaist.ac.kr/datasets/voxceleb/voxsrc/workshop.html",
      "tldr_zh": "这篇回顾性论文总结了2019年至2023年的VoxCeleb Speaker Recognition Challenge (VoxSRC)系列活动，这些挑战评估了speaker recognition和diarisation任务在封闭、开放训练数据以及监督、自监督和半监督设置下的性能。挑战提供了公开的训练和评估数据集，每年发布新测试集，并跟踪参与者方法的演变和整体领域进步。实验结果显示，在共同评估数据集上，性能逐年提升，且每年的特殊焦点（如领域适应）显著影响了参与者的表现；论文还讨论了当前speaker verification和diarisation领域的优势、经验教训以及未解决的开放挑战。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "TASLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.14886v1",
      "published_date": "2024-08-27 08:57:31 UTC",
      "updated_date": "2024-08-27 08:57:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:15:00.839586"
    },
    {
      "arxiv_id": "2408.14875v1",
      "title": "Adversarial Attacks and Defenses in Multivariate Time-Series Forecasting for Smart and Connected Infrastructures",
      "title_zh": "多变量时间序列预测中的对抗攻击和防御，用于智能和互联基础设施",
      "authors": [
        "Pooja Krishan",
        "Rohan Mohapatra",
        "Saptarshi Sengupta"
      ],
      "abstract": "The emergence of deep learning models has revolutionized various industries\nover the last decade, leading to a surge in connected devices and\ninfrastructures. However, these models can be tricked into making incorrect\npredictions with high confidence, leading to disastrous failures and security\nconcerns. To this end, we explore the impact of adversarial attacks on\nmultivariate time-series forecasting and investigate methods to counter them.\nSpecifically, we employ untargeted white-box attacks, namely the Fast Gradient\nSign Method (FGSM) and the Basic Iterative Method (BIM), to poison the inputs\nto the training process, effectively misleading the model. We also illustrate\nthe subtle modifications to the inputs after the attack, which makes detecting\nthe attack using the naked eye quite difficult. Having demonstrated the\nfeasibility of these attacks, we develop robust models through adversarial\ntraining and model hardening. We are among the first to showcase the\ntransferability of these attacks and defenses by extrapolating our work from\nthe benchmark electricity data to a larger, 10-year real-world data used for\npredicting the time-to-failure of hard disks. Our experimental results confirm\nthat the attacks and defenses achieve the desired security thresholds, leading\nto a 72.41% and 94.81% decrease in RMSE for the electricity and hard disk\ndatasets respectively after implementing the adversarial defenses.",
      "tldr_zh": "该研究探讨了对抗攻击（Adversarial Attacks）对多变量时间序列预测（Multivariate Time-Series Forecasting）的潜在威胁，特别是在智能和连接基础设施中的应用。研究者使用 Fast Gradient Sign Method (FGSM) 和 Basic Iterative Method (BIM) 等白盒攻击方法来毒害训练输入，导致模型预测错误，但这些修改不易被肉眼察觉。为应对这些攻击，他们通过对抗训练（Adversarial Training）和模型强化开发了鲁棒模型，并在电力数据和硬盘故障预测数据集上验证了攻击与防御的可转移性，结果显示 RMSE 分别降低了 72.41% 和 94.81%。这项工作为提升深度学习模型的安全性提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.PF",
        "B.1.3; I.2.4"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 32 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.14875v1",
      "published_date": "2024-08-27 08:44:31 UTC",
      "updated_date": "2024-08-27 08:44:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:15:12.818027"
    },
    {
      "arxiv_id": "2408.14871v2",
      "title": "Learning Robust Reward Machines from Noisy Labels",
      "title_zh": "从噪声标签学习鲁棒奖励机器",
      "authors": [
        "Roko Parac",
        "Lorenzo Nodari",
        "Leo Ardon",
        "Daniel Furelos-Blanco",
        "Federico Cerutti",
        "Alessandra Russo"
      ],
      "abstract": "This paper presents PROB-IRM, an approach that learns robust reward machines\n(RMs) for reinforcement learning (RL) agents from noisy execution traces. The\nkey aspect of RM-driven RL is the exploitation of a finite-state machine that\ndecomposes the agent's task into different subtasks. PROB-IRM uses a\nstate-of-the-art inductive logic programming framework robust to noisy examples\nto learn RMs from noisy traces using the Bayesian posterior degree of beliefs,\nthus ensuring robustness against inconsistencies. Pivotal for the results is\nthe interleaving between RM learning and policy learning: a new RM is learned\nwhenever the RL agent generates a trace that is believed not to be accepted by\nthe current RM. To speed up the training of the RL agent, PROB-IRM employs a\nprobabilistic formulation of reward shaping that uses the posterior Bayesian\nbeliefs derived from the traces. Our experimental analysis shows that PROB-IRM\ncan learn (potentially imperfect) RMs from noisy traces and exploit them to\ntrain an RL agent to solve its tasks successfully. Despite the complexity of\nlearning the RM from noisy traces, agents trained with PROB-IRM perform\ncomparably to agents provided with handcrafted RMs.",
      "tldr_zh": "本研究提出了一种名为 PROB-IRM 的方法，用于从嘈杂的执行轨迹中学习鲁棒的 Reward Machines (RMs)，以提升强化学习 (RL) 代理的任务分解和执行能力。PROB-IRM 利用先进的归纳逻辑编程框架和贝叶斯后验置信度来处理噪声数据，并在 RM 学习与策略学习之间实现交织：当 RL 代理生成不被当前 RM 接受的轨迹时，动态学习新的 RM，同时通过概率奖励整形加速训练过程。实验结果表明，即使从嘈杂轨迹中学习到的 RMs 可能不完美，PROB-IRM 训练的 RL 代理在任务性能上与使用手工制作 RMs 的代理相当，展示了其鲁棒性和实用性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the 21st International Conference on Principles of\n  Knowledge Representation and Reasoning (KR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.14871v2",
      "published_date": "2024-08-27 08:41:42 UTC",
      "updated_date": "2025-03-21 14:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:15:26.202393"
    },
    {
      "arxiv_id": "2408.15293v1",
      "title": "Learning Granularity Representation for Temporal Knowledge Graph Completion",
      "title_zh": "针对时间知识图补全的学习粒度表示",
      "authors": [
        "Jinchuan Zhang",
        "Tianqi Wan",
        "Chong Mu",
        "Guangxi Lu",
        "Ling Tian"
      ],
      "abstract": "Temporal Knowledge Graphs (TKGs) incorporate temporal information to reflect\nthe dynamic structural knowledge and evolutionary patterns of real-world facts.\nNevertheless, TKGs are still limited in downstream applications due to the\nproblem of incompleteness. Consequently, TKG completion (also known as link\nprediction) has been widely studied, with recent research focusing on\nincorporating independent embeddings of time or combining them with entities\nand relations to form temporal representations. However, most existing methods\noverlook the impact of history from a multi-granularity aspect. The inherent\nsemantics of human-defined temporal granularities, such as ordinal dates,\nreveal general patterns to which facts typically adhere. To counter this\nlimitation, this paper proposes \\textbf{L}earning \\textbf{G}ranularity\n\\textbf{Re}presentation (termed $\\mathsf{LGRe}$) for TKG completion. It\ncomprises two main components: Granularity Representation Learning (GRL) and\nAdaptive Granularity Balancing (AGB). Specifically, GRL employs time-specific\nmulti-layer convolutional neural networks to capture interactions between\nentities and relations at different granularities. After that, AGB generates\nadaptive weights for these embeddings according to temporal semantics,\nresulting in expressive representations of predictions. Moreover, to reflect\nsimilar semantics of adjacent timestamps, a temporal loss function is\nintroduced. Extensive experimental results on four event benchmarks demonstrate\nthe effectiveness of $\\mathsf{LGRe}$ in learning time-related representations.\nTo ensure reproducibility, our code is available at\nhttps://github.com/KcAcoZhang/LGRe.",
      "tldr_zh": "本研究针对Temporal Knowledge Graphs (TKGs) 的不完整性问题，提出了一种学习粒度表示的方法，即LGRe框架，以更好地捕捉多粒度历史影响和时间语义。LGRe 包括两个核心组件：Granularity Representation Learning (GRL)，它利用时间特定的多层卷积神经网络捕获不同粒度下实体和关系的交互；以及Adaptive Granularity Balancing (AGB)，通过生成自适应权重来优化表示。此外，该框架引入了temporal loss function 来处理相邻时间戳的相似语义。在四个事件基准上的实验结果证明，LGRe 显著提升了TKG completion 的性能，并提供了可复现的代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages. Accepted at ICONIP 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.15293v1",
      "published_date": "2024-08-27 08:19:34 UTC",
      "updated_date": "2024-08-27 08:19:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:15:37.787807"
    },
    {
      "arxiv_id": "2409.05888v2",
      "title": "MA-CDMR: An Intelligent Cross-domain Multicast Routing Method based on Multiagent Deep Reinforcement Learning in Multi-domain SDWN",
      "title_zh": "MA-CDMR",
      "authors": [
        "Miao Ye",
        "Hongwen Hu",
        "Xiaoli Wang",
        "Yuping Wang",
        "Yong Wang",
        "Wen Peng",
        "Jihao Zheng"
      ],
      "abstract": "The cross-domain multicast routing problem in a software-defined wireless\nnetwork with multiple controllers is a classic NP-hard optimization problem. As\nthe network size increases, designing and implementing cross-domain multicast\nrouting paths in the network requires not only designing efficient solution\nalgorithms to obtain the optimal cross-domain multicast tree but also ensuring\nthe timely and flexible acquisition and maintenance of global network state\ninformation. However, existing solutions have a limited ability to sense the\nnetwork traffic state, affecting the quality of service of multicast services.\nIn addition, these methods have difficulty adapting to the highly dynamically\nchanging network states and have slow convergence speeds. To this end, this\npaper aims to design and implement a multiagent deep reinforcement learning\nbased cross-domain multicast routing method for SDWN with multicontroller\ndomains. First, a multicontroller communication mechanism and a multicast group\nmanagement module are designed to transfer and synchronize network information\nbetween different control domains of the SDWN, thus effectively managing the\njoining and classification of members in the cross-domain multicast group.\nSecond, a theoretical analysis and proof show that the optimal cross-domain\nmulticast tree includes an interdomain multicast tree and an intradomain\nmulticast tree. An agent is established for each controller, and a cooperation\nmechanism between multiple agents is designed to effectively optimize\ncross-domain multicast routing and ensure consistency and validity in the\nrepresentation of network state information for cross-domain multicast routing\ndecisions. Third, a multiagent reinforcement learning-based method that\ncombines online and offline training is designed to reduce the dependence on\nthe real-time environment and increase the convergence speed of multiple\nagents.",
      "tldr_zh": "本论文提出 MA-CDMR，一种基于 Multiagent Deep Reinforcement Learning 的智能跨域多播路由方法，针对多域 SDWN 中的 NP-hard 优化问题，旨在提升网络状态感知和动态适应能力。论文设计了多控制器通信机制和多播组管理模块，以实现网络信息同步和跨域成员管理；同时，通过理论分析证明最优跨域多播树包括域间和域内树，并建立多智能体合作机制来优化路由决策。最终，该方法结合在线和离线训练，减少对实时环境的依赖，并加速多智能体收敛速度，从而提高多播服务的质量和服务可靠性。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05888v2",
      "published_date": "2024-08-27 08:16:32 UTC",
      "updated_date": "2024-09-11 13:52:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:15:50.524528"
    },
    {
      "arxiv_id": "2408.14855v1",
      "title": "Enhancing Analogical Reasoning in the Abstraction and Reasoning Corpus via Model-Based RL",
      "title_zh": "翻译失败",
      "authors": [
        "Jihwan Lee",
        "Woochang Sim",
        "Sejin Kim",
        "Sundong Kim"
      ],
      "abstract": "This paper demonstrates that model-based reinforcement learning (model-based\nRL) is a suitable approach for the task of analogical reasoning. We hypothesize\nthat model-based RL can solve analogical reasoning tasks more efficiently\nthrough the creation of internal models. To test this, we compared DreamerV3, a\nmodel-based RL method, with Proximal Policy Optimization, a model-free RL\nmethod, on the Abstraction and Reasoning Corpus (ARC) tasks. Our results\nindicate that model-based RL not only outperforms model-free RL in learning and\ngeneralizing from single tasks but also shows significant advantages in\nreasoning across similar tasks.",
      "tldr_zh": "本研究探讨了使用模型-based reinforcement learning (model-based RL) 来提升 Abstraction and Reasoning Corpus (ARC) 中的类比推理能力，假设 model-based RL 通过创建内部模型能更高效地处理此类任务。研究者比较了 DreamerV3（一种 model-based RL 方法）和 Proximal Policy Optimization（PPO，一种 model-free RL 方法）在 ARC 任务上的表现。结果显示，DreamerV3 不仅在单个任务的学习和泛化方面优于 PPO，还在跨类似任务的推理上表现出显著优势，从而证明了 model-based RL 在类比推理中的潜力。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to IJCAI 2024 IARML Workshop",
      "pdf_url": "http://arxiv.org/pdf/2408.14855v1",
      "published_date": "2024-08-27 08:15:20 UTC",
      "updated_date": "2024-08-27 08:15:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:16:00.584227"
    },
    {
      "arxiv_id": "2408.14853v2",
      "title": "Atoxia: Red-teaming Large Language Models with Target Toxic Answers",
      "title_zh": "Atoxia：利用目标有害答案对大型语言模型进行红队测试",
      "authors": [
        "Yuhao Du",
        "Zhuo Li",
        "Pengyu Cheng",
        "Xiang Wan",
        "Anningzhe Gao"
      ],
      "abstract": "Despite the substantial advancements in artificial intelligence, large\nlanguage models (LLMs) remain being challenged by generation safety. With\nadversarial jailbreaking prompts, one can effortlessly induce LLMs to output\nharmful content, causing unexpected negative social impacts. This vulnerability\nhighlights the necessity for robust LLM red-teaming strategies to identify and\nmitigate such risks before large-scale application. To detect specific types of\nrisks, we propose a novel red-teaming method that $\\textbf{A}$ttacks LLMs with\n$\\textbf{T}$arget $\\textbf{Toxi}$c $\\textbf{A}$nswers ($\\textbf{Atoxia}$).\nGiven a particular harmful answer, Atoxia generates a corresponding user query\nand a misleading answer opening to examine the internal defects of a given LLM.\nThe proposed attacker is trained within a reinforcement learning scheme with\nthe LLM outputting probability of the target answer as the reward. We verify\nthe effectiveness of our method on various red-teaming benchmarks, such as\nAdvBench and HH-Harmless. The empirical results demonstrate that Atoxia can\nsuccessfully detect safety risks in not only open-source models but also\nstate-of-the-art black-box models such as GPT-4o.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)的安全漏洞，提出了一种名为Atoxia的红队测试方法，用于检测特定有害答案的风险。Atoxia给定目标有害答案，通过强化学习生成对应的用户查询和误导性答案，以暴露LLMs的内部缺陷。实验在AdvBench和HH-Harmless等基准上验证了其有效性，不仅适用于开源模型，还能成功识别黑箱模型如GPT-4o的安全问题，从而为提升LLMs的安全性提供重要工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Findings of NAACL-2025",
      "pdf_url": "http://arxiv.org/pdf/2408.14853v2",
      "published_date": "2024-08-27 08:12:08 UTC",
      "updated_date": "2025-02-16 07:47:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:16:13.283591"
    },
    {
      "arxiv_id": "2408.14849v2",
      "title": "Project SHADOW: Symbolic Higher-order Associative Deductive reasoning On Wikidata using LM probing",
      "title_zh": "翻译失败",
      "authors": [
        "Hanna Abi Akl"
      ],
      "abstract": "We introduce SHADOW, a fine-tuned language model trained on an intermediate\ntask using associative deductive reasoning, and measure its performance on a\nknowledge base construction task using Wikidata triple completion. We evaluate\nSHADOW on the LM-KBC 2024 challenge and show that it outperforms the baseline\nsolution by 20% with a F1 score of 68.72%.",
      "tldr_zh": "本研究引入了 Project SHADOW，这是一个通过微调的语言模型（LM），利用 associative deductive reasoning 在中间任务上训练，以提升知识库构建能力。\nSHADOW 通过 LM probing 在 Wikidata 的 triple completion 任务上进行评估。\n在 LM-KBC 2024 挑战中，SHADOW 的 F1 score 达到 68.72%，比基线方案提高了 20%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 1 figure, accepted for the International Conference on\n  Natural Language Computing (NATL) 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.14849v2",
      "published_date": "2024-08-27 08:01:13 UTC",
      "updated_date": "2024-09-23 12:22:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:16:24.545302"
    },
    {
      "arxiv_id": "2408.14841v1",
      "title": "Diffusion based Semantic Outlier Generation via Nuisance Awareness for Out-of-Distribution Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Suhee Yoon",
        "Sanghyu Yoon",
        "Hankook Lee",
        "Ye Seul Sim",
        "Sungik Choi",
        "Kyungeun Lee",
        "Hye-Seung Cho",
        "Woohyung Lim"
      ],
      "abstract": "Out-of-distribution (OOD) detection, which determines whether a given sample\nis part of the in-distribution (ID), has recently shown promising results\nthrough training with synthetic OOD datasets. Nonetheless, existing methods\noften produce outliers that are considerably distant from the ID, showing\nlimited efficacy for capturing subtle distinctions between ID and OOD. To\naddress these issues, we propose a novel framework, Semantic Outlier generation\nvia Nuisance Awareness (SONA), which notably produces challenging outliers by\ndirectly leveraging pixel-space ID samples through diffusion models. Our\napproach incorporates SONA guidance, providing separate control over semantic\nand nuisance regions of ID samples. Thereby, the generated outliers achieve two\ncrucial properties: (i) they present explicit semantic-discrepant information,\nwhile (ii) maintaining various levels of nuisance resemblance with ID.\nFurthermore, the improved OOD detector training with SONA outliers facilitates\nlearning with a focus on semantic distinctions. Extensive experiments\ndemonstrate the effectiveness of our framework, achieving an impressive AUROC\nof 88% on near-OOD datasets, which surpasses the performance of baseline\nmethods by a significant margin of approximately 6%.",
      "tldr_zh": "该论文提出了一种新框架SONA（Semantic Outlier generation via Nuisance Awareness），利用diffusion models从像素空间的In-Distribution (ID)样本生成更具挑战性的Out-of-Distribution (OOD)异常样本，以解决现有方法在捕捉ID和OOD细微差异方面的不足。SONA通过指导机制分别控制样本的semantic和nuisance区域，确保生成的异常样本同时具备显式的semantic-discrepant信息和与ID在nuisance方面的相似度，从而提升OOD检测器的训练效果。实验结果显示，该框架在near-OOD数据集上实现了88%的AUROC，较基线方法提高了约6%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14841v1",
      "published_date": "2024-08-27 07:52:44 UTC",
      "updated_date": "2024-08-27 07:52:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:16:37.355976"
    },
    {
      "arxiv_id": "2408.14840v2",
      "title": "CL4KGE: A Curriculum Learning Method for Knowledge Graph Embedding",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Liu",
        "Chuan Zhou",
        "Peng Zhang",
        "Yanan Cao",
        "Yongchao Liu",
        "Zhao Li",
        "Hongyang Chen"
      ],
      "abstract": "Knowledge graph embedding (KGE) constitutes a foundational task, directed\ntowards learning representations for entities and relations within knowledge\ngraphs (KGs), with the objective of crafting representations comprehensive\nenough to approximate the logical and symbolic interconnections among entities.\nIn this paper, we define a metric Z-counts to measure the difficulty of\ntraining each triple ($<$head entity, relation, tail entity$>$) in KGs with\ntheoretical analysis. Based on this metric, we propose \\textbf{CL4KGE}, an\nefficient \\textbf{C}urriculum \\textbf{L}earning based training strategy for\n\\textbf{KGE}. This method includes a difficulty measurer and a training\nscheduler that aids in the training of KGE models. Our approach possesses the\nflexibility to act as a plugin within a wide range of KGE models, with the\nadded advantage of adaptability to the majority of KGs in existence. The\nproposed method has been evaluated on popular KGE models, and the results\ndemonstrate that it enhances the state-of-the-art methods. The use of Z-counts\nas a metric has enabled the identification of challenging triples in KGs, which\nhelps in devising effective training strategies.",
      "tldr_zh": "这篇论文针对知识图嵌入 (KGE) 任务，提出了一种基于课程学习 (Curriculum Learning) 的训练策略 CL4KGE，以优化实体和关系的表示学习。论文定义了 Z-counts 指标来衡量每个三元组 (<head entity, relation, tail entity>) 的训练难度，并通过理论分析支持该指标的应用。CL4KGE 包括难度测量器和训练调度器，能够作为插件灵活集成到多种 KGE 模型中，并适应大多数知识图 (KGs)。实验结果表明，该方法提升了现有最先进方法的性能，并有助于识别和处理 KGs 中的挑战性三元组。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.14840v2",
      "published_date": "2024-08-27 07:51:26 UTC",
      "updated_date": "2024-09-09 06:57:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:16:50.858870"
    },
    {
      "arxiv_id": "2408.14837v2",
      "title": "Diffusion Models Are Real-Time Game Engines",
      "title_zh": "扩散模型是实时游戏引擎",
      "authors": [
        "Dani Valevski",
        "Yaniv Leviathan",
        "Moab Arar",
        "Shlomi Fruchter"
      ],
      "abstract": "We present GameNGen, the first game engine powered entirely by a neural model\nthat also enables real-time interaction with a complex environment over long\ntrajectories at high quality. When trained on the classic game DOOM, GameNGen\nextracts gameplay and uses it to generate a playable environment that can\ninteractively simulate new trajectories. GameNGen runs at 20 frames per second\non a single TPU and remains stable over extended multi-minute play sessions.\nNext frame prediction achieves a PSNR of 29.4, comparable to lossy JPEG\ncompression. Human raters are only slightly better than random chance at\ndistinguishing short clips of the game from clips of the simulation, even after\n5 minutes of auto-regressive generation. GameNGen is trained in two phases: (1)\nan RL-agent learns to play the game and the training sessions are recorded, and\n(2) a diffusion model is trained to produce the next frame, conditioned on the\nsequence of past frames and actions. Conditioning augmentations help ensure\nstable auto-regressive generation over long trajectories, and decoder\nfine-tuning improves the fidelity of visual details and text.",
      "tldr_zh": "本研究提出 GameNGen，一种完全由扩散模型驱动的实时游戏引擎，能够生成可交互的复杂环境，支持长轨迹的高质量模拟，例如在经典游戏 DOOM 上实现稳定多分钟播放。训练过程分为两个阶段：首先，使用 RL-agent 学习玩游戏并记录会话；其次，训练扩散模型基于过去帧和动作生成下一帧，并通过条件增强和解码器微调确保生成稳定性及视觉细节的保真度。实验结果显示，GameNGen 在单个 TPU 上运行达到 20 FPS，下一帧预测的 PSNR 为 29.4，且人类评委难以区分真实游戏和模拟片段，证明了其在实时交互和逼真性方面的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025. Project page: https://gamengen.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2408.14837v2",
      "published_date": "2024-08-27 07:46:07 UTC",
      "updated_date": "2025-04-24 03:03:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:17:13.104205"
    },
    {
      "arxiv_id": "2408.14834v1",
      "title": "Strategic Optimization and Challenges of Large Language Models in Object-Oriented Programming",
      "title_zh": "大语言模型在面向对象编程中的战略优化与挑战",
      "authors": [
        "Zinan Wang"
      ],
      "abstract": "In the area of code generation research, the emphasis has transitioned from\ncrafting individual functions to developing class-level method code that\nintegrates contextual information. This shift has brought several benchmarks\nsuch as ClassEval and CoderEval, which consider class-level contexts.\nNevertheless, the influence of specific contextual factors at the method level\nremains less explored.\n  This research focused on method-level code generation within the\nObject-Oriented Programming (OOP) framework. Based on CoderEval, we devised\nexperiments that varied the extent of contextual information in the prompts,\nranging from method-specific to project-wide details. We introduced the\ninnovative metric of \"Prompt-Token Cost-Effectiveness\" to evaluate the economic\nviability of incorporating additional contextual layers. Our findings indicate\nthat prompts enriched with method invocation details yield the highest\ncost-effectiveness. Additionally, our study revealed disparities among Large\nLanguage Models (LLMs) regarding error type distributions and the level of\nassistance they provide to developers. Notably, larger LLMs do not invariably\nperform better. We also observed that tasks with higher degrees of coupling\npresent more substantial challenges, suggesting that the choice of LLM should\nbe tailored to the task's coupling degree. For example, GPT-4 exhibited\nimproved performance in low-coupling scenarios, whereas GPT-3.5 seemed better\nsuited for tasks with high coupling. By meticulously curating prompt content\nand selecting the appropriate LLM, developers can optimize code quality while\nmaximizing cost-efficiency during the development process.",
      "tldr_zh": "本研究探讨了 Large Language Models (LLMs) 在 Object-Oriented Programming (OOP) 中的优化策略和挑战，焦点在于方法级代码生成，并基于 CoderEval 基准设计实验，测试提示中上下文信息（如方法特定到项目级）的变异影响。研究引入了创新指标“Prompt-Token Cost-Effectiveness”，评估添加上下文的经济性，发现包含方法调用细节的提示具有最高成本效益。结果显示，不同 LLMs 在错误类型分布和开发辅助方面存在差异，较大模型并不总是表现更好，且高耦合任务更具挑战性，例如 GPT-4 适合低耦合场景，而 GPT-3.5 更适用于高耦合任务。通过精心设计提示和选择合适 LLM，开发者可优化代码质量并提升成本效率。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.14834v1",
      "published_date": "2024-08-27 07:44:16 UTC",
      "updated_date": "2024-08-27 07:44:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:17:14.816812"
    },
    {
      "arxiv_id": "2408.14825v1",
      "title": "From Rule-Based Models to Deep Learning Transformers Architectures for Natural Language Processing and Sign Language Translation Systems: Survey, Taxonomy and Performance Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Nada Shahin",
        "Leila Ismail"
      ],
      "abstract": "With the growing Deaf and Hard of Hearing population worldwide and the\npersistent shortage of certified sign language interpreters, there is a\npressing need for an efficient, signs-driven, integrated end-to-end translation\nsystem, from sign to gloss to text and vice-versa. There has been a wealth of\nresearch on machine translations and related reviews. However, there are few\nworks on sign language machine translation considering the particularity of the\nlanguage being continuous and dynamic. This paper aims to address this void,\nproviding a retrospective analysis of the temporal evolution of sign language\nmachine translation algorithms and a taxonomy of the Transformers\narchitectures, the most used approach in language translation. We also present\nthe requirements of a real-time Quality-of-Service sign language ma-chine\ntranslation system underpinned by accurate deep learning algorithms. We propose\nfuture research directions for sign language translation systems.",
      "tldr_zh": "这篇论文回顾了从基于规则的模型到深度学习 Transformers 架构在自然语言处理(NLP)和手语翻译系统中的演变，强调了手语机器翻译的独特挑战，如语言的连续性和动态性。论文提供了 Transformers 架构的taxonomy，并评估了这些方法在手语翻译中的性能，指出现有研究的不足。最终，它讨论了实时 Quality-of-Service (QoS) 系统的要求，并提出未来研究方向，以应对聋哑人口增长和翻译员短缺的实际需求。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG",
        "I.2, I.2.7, I.4, I.4.9"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14825v1",
      "published_date": "2024-08-27 07:11:45 UTC",
      "updated_date": "2024-08-27 07:11:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:17:25.568351"
    },
    {
      "arxiv_id": "2408.14817v1",
      "title": "A Comprehensive Benchmark of Machine and Deep Learning Across Diverse Tabular Datasets",
      "title_zh": "机器学习和深度学习在多种表格数据集上的全面基准测试",
      "authors": [
        "Assaf Shmuel",
        "Oren Glickman",
        "Teddy Lazebnik"
      ],
      "abstract": "The analysis of tabular datasets is highly prevalent both in scientific\nresearch and real-world applications of Machine Learning (ML). Unlike many\nother ML tasks, Deep Learning (DL) models often do not outperform traditional\nmethods in this area. Previous comparative benchmarks have shown that DL\nperformance is frequently equivalent or even inferior to models such as\nGradient Boosting Machines (GBMs). In this study, we introduce a comprehensive\nbenchmark aimed at better characterizing the types of datasets where DL models\nexcel. Although several important benchmarks for tabular datasets already\nexist, our contribution lies in the variety and depth of our comparison: we\nevaluate 111 datasets with 20 different models, including both regression and\nclassification tasks. These datasets vary in scale and include both those with\nand without categorical variables. Importantly, our benchmark contains a\nsufficient number of datasets where DL models perform best, allowing for a\nthorough analysis of the conditions under which DL models excel. Building on\nthe results of this benchmark, we train a model that predicts scenarios where\nDL models outperform alternative methods with 86.1% accuracy (AUC 0.78). We\npresent insights derived from this characterization and compare these findings\nto previous benchmarks.",
      "tldr_zh": "本文提出一个全面基准，用于评估机器学习(ML)和深度学习(DL)模型在多样化表格数据集上的性能，旨在识别DL模型表现出色的数据集类型。该基准评估了111个数据集，使用20种模型（包括回归和分类任务），涵盖不同规模和分类变量的场景。研究发现，DL模型在特定条件下优于传统方法如Gradient Boosting Machines (GBMs)，并基于基准结果训练了一个预测模型，能以86.1%的准确率(AUC 0.78)预测DL适用的场景。该工作提供了DL性能的深入洞见，并与其他基准进行了比较。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14817v1",
      "published_date": "2024-08-27 06:58:52 UTC",
      "updated_date": "2024-08-27 06:58:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:17:38.485786"
    },
    {
      "arxiv_id": "2408.14811v1",
      "title": "Brain-inspired Artificial Intelligence: A Comprehensive Review",
      "title_zh": "脑启发的人工智能：全面综述",
      "authors": [
        "Jing Ren",
        "Feng Xia"
      ],
      "abstract": "Current artificial intelligence (AI) models often focus on enhancing\nperformance through meticulous parameter tuning and optimization techniques.\nHowever, the fundamental design principles behind these models receive\ncomparatively less attention, which can limit our understanding of their\npotential and constraints. This comprehensive review explores the diverse\ndesign inspirations that have shaped modern AI models, i.e., brain-inspired\nartificial intelligence (BIAI). We present a classification framework that\ncategorizes BIAI approaches into physical structure-inspired and human\nbehavior-inspired models. We also examine the real-world applications where\ndifferent BIAI models excel, highlighting their practical benefits and\ndeployment challenges. By delving into these areas, we provide new insights and\npropose future research directions to drive innovation and address current gaps\nin the field. This review offers researchers and practitioners a comprehensive\noverview of the BIAI landscape, helping them harness its potential and expedite\nadvancements in AI development.",
      "tldr_zh": "这篇综述探讨了脑启发人工智能 (BIAI) 的设计灵感，强调了其在现代 AI 模型中的作用，并指出当前 AI 开发更注重参数优化而非基本原则，可能限制其潜力和理解。作者提出一个分类框架，将 BIAI 分为 physical structure-inspired 和 human behavior-inspired 模型，并分析这些模型在真实世界的应用、实际益处和部署挑战。综述提供了新见解和未来研究方向，帮助研究者和从业者全面把握 BIAI 景观，推动 AI 领域的创新发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "35 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.14811v1",
      "published_date": "2024-08-27 06:49:50 UTC",
      "updated_date": "2024-08-27 06:49:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:17:50.191989"
    },
    {
      "arxiv_id": "2408.14806v2",
      "title": "Poly2Vec: Polymorphic Fourier-Based Encoding of Geospatial Objects for GeoAI Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Maria Despoina Siampou",
        "Jialiang Li",
        "John Krumm",
        "Cyrus Shahabi",
        "Hua Lu"
      ],
      "abstract": "Encoding geospatial objects is fundamental for geospatial artificial\nintelligence (GeoAI) applications, which leverage machine learning (ML) models\nto analyze spatial information. Common approaches transform each object into\nknown formats, like image and text, for compatibility with ML models. However,\nthis process often discards crucial spatial information, such as the object's\nposition relative to the entire space, reducing downstream task effectiveness.\nAlternative encoding methods that preserve some spatial properties are often\ndevised for specific data objects (e.g., point encoders), making them\nunsuitable for tasks that involve different data types (i.e., points,\npolylines, and polygons). To this end, we propose Poly2Vec, a polymorphic\nFourier-based encoding approach that unifies the representation of geospatial\nobjects, while preserving the essential spatial properties. Poly2Vec\nincorporates a learned fusion module that adaptively integrates the magnitude\nand phase of the Fourier transform for different tasks and geometries. We\nevaluate Poly2Vec on five diverse tasks, organized into two categories. The\nfirst empirically demonstrates that Poly2Vec consistently outperforms\nobject-specific baselines in preserving three key spatial relationships:\ntopology, direction, and distance. The second shows that integrating Poly2Vec\ninto a state-of-the-art GeoAI workflow improves the performance in two popular\ntasks: population prediction and land use inference.",
      "tldr_zh": "该论文提出 Poly2Vec，一种基于傅立叶变换的多态编码方法，用于 GeoAI 应用中统一表示地理空间对象（如点、多线和多边形），以保留关键空间属性（如拓扑、方向和距离），从而解决传统编码方法丢弃信息和兼容性问题的局限。Poly2Vec 包含一个学习融合模块，能适应不同任务和几何形状，动态整合傅立叶变换的幅度和相位。实验结果显示，Poly2Vec 在五个多样化任务上优于特定对象基线模型，不仅在保留空间关系方面表现出色，还提升了人口预测和土地使用推断等实际 GeoAI 工作流的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14806v2",
      "published_date": "2024-08-27 06:28:35 UTC",
      "updated_date": "2025-05-11 20:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:18:03.175219"
    },
    {
      "arxiv_id": "2408.14792v2",
      "title": "Measuring Human Contribution in AI-Assisted Content Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yueqi Xie",
        "Tao Qi",
        "Jingwei Yi",
        "Xiyuan Yang",
        "Ryan Whalen",
        "Junming Huang",
        "Qian Ding",
        "Yu Xie",
        "Xing Xie",
        "Fangzhao Wu"
      ],
      "abstract": "With the growing prevalence of generative artificial intelligence (AI), an\nincreasing amount of content is no longer exclusively generated by humans but\nby generative AI models with human guidance. This shift presents notable\nchallenges for the delineation of originality due to the varying degrees of\nhuman contribution in AI-assisted works. This study raises the research\nquestion of measuring human contribution in AI-assisted content generation and\nintroduces a framework to address this question that is grounded in information\ntheory. By calculating mutual information between human input and AI-assisted\noutput relative to self-information of AI-assisted output, we quantify the\nproportional information contribution of humans in content generation. Our\nexperimental results demonstrate that the proposed measure effectively\ndiscriminates between varying degrees of human contribution across multiple\ncreative domains. We hope that this work lays a foundation for measuring human\ncontributions in AI-assisted content generation in the era of generative AI.",
      "tldr_zh": "本研究探讨了在生成式人工智能（AI）辅助内容生成中，如何衡量人类贡献的问题，以应对原创性界定的挑战。研究提出一个基于信息理论的框架，通过计算人类输入与AI辅助输出之间的mutual information，相对于AI辅助输出的self-information，量化人类的比例贡献。该框架在多个创意领域进行了实验验证，结果显示它能有效区分不同程度的人类参与度。该工作为生成式AI时代评估人类贡献奠定了基础。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14792v2",
      "published_date": "2024-08-27 05:56:04 UTC",
      "updated_date": "2025-02-13 17:22:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:18:12.434190"
    },
    {
      "arxiv_id": "2408.14791v3",
      "title": "Optimizing Structured Data Processing through Robotic Process Automation",
      "title_zh": "通过机器人流程自动化优化结构化数据处理",
      "authors": [
        "Vivek Bhardwaj",
        "Ajit Noonia",
        "Sandeep Chaurasia",
        "Mukesh Kumar",
        "Abdulnaser Rashid",
        "Mohamed Tahar Ben Othman"
      ],
      "abstract": "Robotic Process Automation (RPA) has emerged as a game-changing technology in\ndata extraction, revolutionizing the way organizations process and analyze\nlarge volumes of documents such as invoices, purchase orders, and payment\nadvices. This study investigates the use of RPA for structured data extraction\nand evaluates its advantages over manual processes. By comparing\nhuman-performed tasks with those executed by RPA software bots, we assess\nefficiency and accuracy in data extraction from invoices, focusing on the\neffectiveness of the RPA system. Through four distinct scenarios involving\nvarying numbers of invoices, we measure efficiency in terms of time and effort\nrequired for task completion, as well as accuracy by comparing error rates\nbetween manual and RPA processes. Our findings highlight the significant\nefficiency gains achieved by RPA, with bots completing tasks in significantly\nless time compared to manual efforts across all cases. Moreover, the RPA system\nconsistently achieves perfect accuracy, mitigating the risk of errors and\nenhancing process reliability. These results underscore the transformative\npotential of RPA in optimizing operational efficiency, reducing human labor\ncosts, and improving overall business performance.",
      "tldr_zh": "这篇论文探讨了 Robotic Process Automation (RPA) 在优化结构化数据处理（如发票和采购订单提取）方面的应用，通过比较手动操作与 RPA 系统的效率和准确性。研究采用四个不同场景（涉及不同数量的发票）来评估任务完成时间、努力消耗和错误率，结果显示 RPA 显著缩短处理时间并实现 100% 准确率。总体而言，这些发现突显了 RPA 在提升操作效率、减少人力成本和改善业务绩效方面的变革潜力。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14791v3",
      "published_date": "2024-08-27 05:53:02 UTC",
      "updated_date": "2024-10-31 12:23:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:18:24.931786"
    },
    {
      "arxiv_id": "2408.14780v2",
      "title": "GINN-KAN: Interpretability pipelining with applications in Physics Informed Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Nisal Ranasinghe",
        "Yu Xia",
        "Sachith Seneviratne",
        "Saman Halgamuge"
      ],
      "abstract": "Neural networks are powerful function approximators, yet their ``black-box\"\nnature often renders them opaque and difficult to interpret. While many\npost-hoc explanation methods exist, they typically fail to capture the\nunderlying reasoning processes of the networks. A truly interpretable neural\nnetwork would be trained similarly to conventional models using techniques such\nas backpropagation, but additionally provide insights into the learned\ninput-output relationships. In this work, we introduce the concept of\ninterpretability pipelineing, to incorporate multiple interpretability\ntechniques to outperform each individual technique. To this end, we first\nevaluate several architectures that promise such interpretability, with a\nparticular focus on two recent models selected for their potential to\nincorporate interpretability into standard neural network architectures while\nstill leveraging backpropagation: the Growing Interpretable Neural Network\n(GINN) and Kolmogorov Arnold Networks (KAN). We analyze the limitations and\nstrengths of each and introduce a novel interpretable neural network GINN-KAN\nthat synthesizes the advantages of both models. When tested on the Feynman\nsymbolic regression benchmark datasets, GINN-KAN outperforms both GINN and KAN.\nTo highlight the capabilities and the generalizability of this approach, we\nposition GINN-KAN as an alternative to conventional black-box networks in\nPhysics-Informed Neural Networks (PINNs). We expect this to have far-reaching\nimplications in the application of deep learning pipelines in the natural\nsciences. Our experiments with this interpretable PINN on 15 different partial\ndifferential equations demonstrate that GINN-KAN augmented PINNs outperform\nPINNs with black-box networks in solving differential equations and surpass the\ncapabilities of both GINN and KAN.",
      "tldr_zh": "这篇论文引入了 interpretability pipelineing 的概念，将多个解释技术整合，以提升神经网络的可解释性，同时保持 backpropagation 等标准训练方法。研究者开发了 GINN-KAN 模型，将 Growing Interpretable Neural Network (GINN) 和 Kolmogorov Arnold Networks (KAN) 的优势相结合，并在 Feynman 符号回归基准测试中表现出色，优于单独的 GINN 和 KAN。进一步应用于 Physics-Informed Neural Networks (PINNs)，GINN-KAN 在解决 15 个偏微分方程时超越了传统黑箱网络的性能，这有望扩展深度学习在自然科学的实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14780v2",
      "published_date": "2024-08-27 04:57:53 UTC",
      "updated_date": "2024-08-28 15:48:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:18:38.871801"
    },
    {
      "arxiv_id": "2408.14776v2",
      "title": "MROVSeg: Breaking the Resolution Curse of Vision-Language Models in Open-Vocabulary Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanbing Zhu",
        "Bingke Zhu",
        "Yingying Chen",
        "Yunfang Niu",
        "Ming Tang",
        "Jinqiao Wang"
      ],
      "abstract": "Pretrained vision-language models (VLMs), \\eg CLIP, are increasingly used to\nbridge the gap between open- and close-vocabulary recognition in\nopen-vocabulary image segmentation. As VLMs are generally pretrained with\nlow-resolution images (e.g. $224\\times224$), most previous methods operate only\non downscaled images. We question this design as low resolution features often\nfail to preserve fine details. A typical solution is to employ additional image\nbackbones for high-resolution inputs, but it also introduce significant\ncomputation overhead. Therefore, we propose MROVSeg, a multi-resolution\ntraining framework for open-vocabulary image segmentation with a single\npretrained CLIP backbone, that uses sliding windows to slice the\nhigh-resolution input into uniform patches, each matching the input size of the\nwell-trained image encoder. Its key components include a Multi-Res Adapter,\nwhich restores the spatial geometry and grasps local-global correspondences\nacross patches by interacting with multi-resolution features. To achieve\naccurate segmentation, we introduce Multi-grained Masked Attention scheme to\naggregate multi-grained semantics from multi-resolution CLIP features to object\nqueries. Through comprehensive experiments, we demonstrate the superiority of\nMROVSeg on well-established open-vocabulary image segmentation benchmarks,\nestablishing new standards for open-vocabulary image segmentation.",
      "tldr_zh": "这篇论文针对视觉语言模型(VLMs)如 CLIP 在开词汇图像分割中的分辨率问题，提出 MROVSeg 框架，以单个预训练 CLIP 骨干网络处理高分辨率输入。框架通过滑动窗口将图像切片成均匀补丁，并引入 Multi-Res Adapter 来恢复空间几何和捕捉补丁间的局部-全局对应关系，以及 Multi-grained Masked Attention 来聚合多分辨率特征的多粒度语义到对象查询。实验结果显示，MROVSeg 在开词汇图像分割基准上显著优于现有方法，建立了新的性能标准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical report",
      "pdf_url": "http://arxiv.org/pdf/2408.14776v2",
      "published_date": "2024-08-27 04:45:53 UTC",
      "updated_date": "2024-11-27 15:26:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:18:52.092939"
    },
    {
      "arxiv_id": "2408.14772v2",
      "title": "A global AI community requires language-diverse publishing",
      "title_zh": "全球人工智能社区需要语言多样化出版",
      "authors": [
        "Haley Lepp",
        "Parth Sarin"
      ],
      "abstract": "In this provocation, we discuss the English dominance of the AI research\ncommunity, arguing that the requirement for English language publishing upholds\nand reinforces broader regimes of extraction in AI. While large language models\nand machine translation have been celebrated as a way to break down barriers,\nwe regard their use as a symptom of linguistic exclusion of scientists and\npotential readers. We propose alternative futures for a healthier publishing\nculture, organized around three themes: administering conferences in the\nlanguages of the country in which they are held, instructing peer reviewers not\nto adjudicate the language appropriateness of papers, and offering\nopportunities to publish and present in multiple languages. We welcome new\ntranslations of this piece. Please contact the authors if you would like to\ncontribute one.",
      "tldr_zh": "该论文讨论了AI研究社区的英语主导地位，认为强制英语出版强化了AI领域的提取制度，导致语言排斥。作者认为，虽然大型语言模型(LLMs)和机器翻译被视为打破障碍的工具，但实际上它们只是这种排斥的症状，而不是解决方案。论文提出三种促进更健康出版文化的建议：使用举办国家语言管理会议、不让同行评审者评判论文语言适当性，以及提供多语言出版和展示机会，以构建一个更具包容性的全球AI社区。作者欢迎对此文章的翻译贡献。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "K.7.0; K.4.2; I.2.m"
      ],
      "primary_category": "cs.CL",
      "comment": "Translations by Tianyu M. Fang (Mandarin Chinese), Michael Hardy\n  (Guarani), Vandana Sarin and Vivek Sarin (Hindi), Roshna Omer Abdulrahman\n  (Soran\\^i Kurdish), Gabriel Poesia (Portuguese), and Mat\\'ias Grinberg\n  (Spanish). In the proceedings of the Global AI Cultures Workshop at the\n  Twelfth International Conference on Learning Representations (ICLR) 2024,\n  Vienna, Austria, May 7-11, 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.14772v2",
      "published_date": "2024-08-27 04:20:10 UTC",
      "updated_date": "2024-08-29 19:50:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:19:02.987131"
    },
    {
      "arxiv_id": "2409.00099v2",
      "title": "Query-by-Example Keyword Spotting Using Spectral-Temporal Graph Attentive Pooling and Multi-Task Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu Wang",
        "Shuyu Kong",
        "Li Wan",
        "Biqiao Zhang",
        "Yiteng Huang",
        "Mumin Jin",
        "Ming Sun",
        "Xin Lei",
        "Zhaojun Yang"
      ],
      "abstract": "Existing keyword spotting (KWS) systems primarily rely on predefined keyword\nphrases. However, the ability to recognize customized keywords is crucial for\ntailoring interactions with intelligent devices. In this paper, we present a\nnovel Query-by-Example (QbyE) KWS system that employs spectral-temporal graph\nattentive pooling and multi-task learning. This framework aims to effectively\nlearn speaker-invariant and linguistic-informative embeddings for QbyE KWS\ntasks. Within this framework, we investigate three distinct network\narchitectures for encoder modeling: LiCoNet, Conformer and ECAPA_TDNN. The\nexperimental results on a substantial internal dataset of $629$ speakers have\ndemonstrated the effectiveness of the proposed QbyE framework in maximizing the\npotential of simpler models such as LiCoNet. Particularly, LiCoNet, which is\n13x more efficient, achieves comparable performance to the computationally\nintensive Conformer model (1.98% vs. 1.63\\% FRR at 0.3 FAs/Hr).",
      "tldr_zh": "本文提出了一种新型的Query-by-Example (QbyE) Keyword Spotting (KWS) 系统，利用spectral-temporal graph attentive pooling和multi-task learning，旨在学习speaker-invariant和linguistic-informative embeddings，以支持自定义关键词识别。系统探索了三种网络架构，包括LiCoNet、Conformer和ECAPA_TDNN，并在包含629名说话者的内部数据集上进行实验。结果显示，LiCoNet模型在计算效率上比Conformer高出13倍，同时在0.3 FAs/Hr时的FRR性能相当（1.98% vs. 1.63%），证明了该框架的有效性和实用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00099v2",
      "published_date": "2024-08-27 03:44:57 UTC",
      "updated_date": "2024-11-23 20:55:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:19:25.150727"
    },
    {
      "arxiv_id": "2408.14754v1",
      "title": "Sequential-Scanning Dual-Energy CT Imaging Using High Temporal Resolution Image Reconstruction and Error-Compensated Material Basis Image Generation",
      "title_zh": "顺序扫描双能量CT成像",
      "authors": [
        "Qiaoxin Li",
        "Ruifeng Chen",
        "Peng Wang",
        "Guotao Quan",
        "Yanfeng Du",
        "Dong Liang",
        "Yinsheng Li"
      ],
      "abstract": "Dual-energy computed tomography (DECT) has been widely used to obtain\nquantitative elemental composition of imaged subjects for personalized and\nprecise medical diagnosis. Compared with DECT leveraging advanced X-ray source\nand/or detector technologies, the use of the sequential-scanning data\nacquisition scheme to implement DECT may make a broader impact on clinical\npractice because this scheme requires no specialized hardware designs and can\nbe directly implemented into conventional CT systems. However, since the\nconcentration of iodinated contrast agent in the imaged subject varies over\ntime, sequentially scanned data sets acquired at two tube potentials are\ntemporally inconsistent. As existing material basis image reconstruction\napproaches assume that the data sets acquired at two tube potentials are\ntemporally consistent, the violation of this assumption results in inaccurate\nquantification of material concentration. In this work, we developed\nsequential-scanning DECT imaging using high temporal resolution image\nreconstruction and error-compensated material basis image generation,\nACCELERATION in short, to address the technical challenge induced by temporal\ninconsistency of sequentially scanned data sets and improve quantification\naccuracy of material concentration in sequential-scanning DECT. ACCELERATION\nhas been validated and evaluated using numerical simulation data sets generated\nfrom clinical human subject exams and experimental human subject studies.\nResults demonstrated the improvement of quantification accuracy and image\nquality using ACCELERATION.",
      "tldr_zh": "这篇论文针对顺序扫描双能 CT (DECT) 成像中，由于碘化对比剂浓度随时间变化导致的数据时间不一致性问题，提出了 ACCELERATION 方法。该方法结合高时间分辨率图像重建和错误补偿的材料基础图像生成技术，解决了现有方法的量化不准确性。实验结果显示，使用数值模拟和实际人体数据验证后，ACCELERATION 显著提高了材料浓度的量化准确性和图像质量。",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "cs.CV",
        "physics.ins-det"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14754v1",
      "published_date": "2024-08-27 03:09:39 UTC",
      "updated_date": "2024-08-27 03:09:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:19:26.836791"
    },
    {
      "arxiv_id": "2408.14753v1",
      "title": "CoopASD: Cooperative Machine Anomalous Sound Detection with Privacy Concerns",
      "title_zh": "CoopASD：考虑隐私问题的合作机器异常声音检测",
      "authors": [
        "Anbai Jiang",
        "Yuchen Shi",
        "Pingyi Fan",
        "Wei-Qiang Zhang",
        "Jia Liu"
      ],
      "abstract": "Machine anomalous sound detection (ASD) has emerged as one of the most\npromising applications in the Industrial Internet of Things (IIoT) due to its\nunprecedented efficacy in mitigating risks of malfunctions and promoting\nproduction efficiency. Previous works mainly investigated the machine ASD task\nunder centralized settings. However, developing the ASD system under\ndecentralized settings is crucial in practice, since the machine data are\ndispersed in various factories and the data should not be explicitly shared due\nto privacy concerns. To enable these factories to cooperatively develop a\nscalable ASD model while preserving their privacy, we propose a novel framework\nnamed CoopASD, where each factory trains an ASD model on its local dataset, and\na central server aggregates these local models periodically. We employ a\npre-trained model as the backbone of the ASD model to improve its robustness\nand develop specialized techniques to stabilize the model under a completely\nnon-iid and domain shift setting. Compared with previous state-of-the-art\n(SOTA) models trained in centralized settings, CoopASD showcases competitive\nresults with negligible degradation of 0.08%. We also conduct extensive\nablation studies to demonstrate the effectiveness of CoopASD.",
      "tldr_zh": "机器异常声音检测 (ASD) 在工业物联网 (IIoT) 中具有重要应用，但由于数据分散在不同工厂且涉及隐私问题，传统集中式方法难以实现。本文提出了 CoopASD 框架，该框架允许每个工厂在本地数据集上训练 ASD 模型，使用预训练模型作为骨干，并通过中央服务器定期聚合模型，以应对非独立同分布 (non-iid) 和领域偏移的挑战。与现有最先进 (SOTA) 模型相比，CoopASD 在性能上仅下降 0.08%，并通过广泛的消融研究验证了其有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.DC",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by GLOBECOM 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.14753v1",
      "published_date": "2024-08-27 03:07:03 UTC",
      "updated_date": "2024-08-27 03:07:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:19:41.007752"
    },
    {
      "arxiv_id": "2408.14747v1",
      "title": "Benchmarking Reinforcement Learning Methods for Dexterous Robotic Manipulation with a Three-Fingered Gripper",
      "title_zh": "翻译失败",
      "authors": [
        "Elizabeth Cutler",
        "Yuning Xing",
        "Tony Cui",
        "Brendan Zhou",
        "Koen van Rijnsoever",
        "Ben Hart",
        "David Valencia",
        "Lee Violet C. Ong",
        "Trevor Gee",
        "Minas Liarokapis",
        "Henry Williams"
      ],
      "abstract": "Reinforcement Learning (RL) training is predominantly conducted in\ncost-effective and controlled simulation environments. However, the transfer of\nthese trained models to real-world tasks often presents unavoidable challenges.\nThis research explores the direct training of RL algorithms in controlled yet\nrealistic real-world settings for the execution of dexterous manipulation. The\nbenchmarking results of three RL algorithms trained on intricate in-hand\nmanipulation tasks within practical real-world contexts are presented. Our\nstudy not only demonstrates the practicality of RL training in authentic\nreal-world scenarios, facilitating direct real-world applications, but also\nprovides insights into the associated challenges and considerations.\nAdditionally, our experiences with the employed experimental methods are\nshared, with the aim of empowering and engaging fellow researchers and\npractitioners in this dynamic field of robotics.",
      "tldr_zh": "该研究评估了强化学习（RL）算法在真实世界灵巧机器人操作中的性能，使用三指夹持器进行直接训练，而非依赖模拟环境转移。研究基准测试了三个RL算法在复杂手部操作任务上的表现，证明了在真实场景中训练RL的可行性和实用性。结果揭示了相关挑战和考虑因素，并分享了实验经验，以鼓励其他研究者在机器人领域进一步探索。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14747v1",
      "published_date": "2024-08-27 02:52:15 UTC",
      "updated_date": "2024-08-27 02:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:19:49.998717"
    },
    {
      "arxiv_id": "2408.14744v3",
      "title": "RSTeller: Scaling Up Visual Language Modeling in Remote Sensing with Rich Linguistic Semantics from Openly Available Data and Large Language Models",
      "title_zh": "RSTeller：利用来自",
      "authors": [
        "Junyao Ge",
        "Xu Zhang",
        "Yang Zheng",
        "Kaitai Guo",
        "Jimin Liang"
      ],
      "abstract": "Abundant, well-annotated multimodal data in remote sensing are pivotal for\naligning complex visual remote sensing (RS) scenes with human language,\nenabling the development of specialized vision language models across diverse\nRS interpretation tasks. However, annotating RS images with rich linguistic\nsemantics at scale demands expertise in RS and substantial human labor, making\nit costly and often impractical. In this study, we propose a workflow that\nleverages large language models (LLMs) to generate multimodal datasets with\nsemantically rich captions at scale from plain OpenStreetMap (OSM) data for\nimages sourced from the Google Earth Engine (GEE) platform. This approach\nfacilitates the generation of paired remote sensing data and can be readily\nscaled up using openly available data. Within this framework, we present\nRSTeller, a multimodal dataset comprising over 1.3 million RS images, each\naccompanied by two descriptive captions. Extensive experiments demonstrate that\nRSTeller enhances the performance of multiple existing vision language models\nfor RS scene understanding through continual pre-training. Our methodology\nsignificantly reduces the manual effort and expertise needed for annotating\nremote sensing imagery while democratizing access to high-quality annotated\ndata. This advancement fosters progress in visual language modeling and\nencourages broader participation in remote sensing research and applications.\nThe RSTeller dataset is available at https://github.com/SlytherinGe/RSTeller.",
      "tldr_zh": "该研究针对远程感应（RS）领域中标注图像所需的专业知识和人力成本问题，提出了一种工作流，利用大型语言模型（LLMs）从 OpenStreetMap (OSM) 数据生成语义丰富的多模态数据集，并应用于 Google Earth Engine (GEE) 图像。研究构建了 RSTeller 数据集，包含超过 130 万张 RS 图像，每张图像配有两个描述性标题，通过持续预训练显著提升了现有视觉语言模型在 RS 场景理解中的性能。相比传统方法，该方法大幅减少了手动标注的努力和专业需求，促进了视觉语言建模的进步，并推动了 RS 研究的可访问性和广泛参与。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.8; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to ISPRS",
      "pdf_url": "http://arxiv.org/pdf/2408.14744v3",
      "published_date": "2024-08-27 02:45:26 UTC",
      "updated_date": "2025-04-16 13:02:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:20:03.946817"
    },
    {
      "arxiv_id": "2409.06726v1",
      "title": "Feedback-based Modal Mutual Search for Attacking Vision-Language Pre-training Models",
      "title_zh": "翻译失败",
      "authors": [
        "Renhua Ding",
        "Xinze Zhang",
        "Xiao Yang",
        "Kun He"
      ],
      "abstract": "Although vision-language pre-training (VLP) models have achieved remarkable\nprogress on cross-modal tasks, they remain vulnerable to adversarial attacks.\nUsing data augmentation and cross-modal interactions to generate transferable\nadversarial examples on surrogate models, transfer-based black-box attacks have\nbecome the mainstream methods in attacking VLP models, as they are more\npractical in real-world scenarios. However, their transferability may be\nlimited due to the differences on feature representation across different\nmodels. To this end, we propose a new attack paradigm called Feedback-based\nModal Mutual Search (FMMS). FMMS introduces a novel modal mutual loss (MML),\naiming to push away the matched image-text pairs while randomly drawing\nmismatched pairs closer in feature space, guiding the update directions of the\nadversarial examples. Additionally, FMMS leverages the target model feedback to\niteratively refine adversarial examples, driving them into the adversarial\nregion. To our knowledge, this is the first work to exploit target model\nfeedback to explore multi-modality adversarial boundaries. Extensive empirical\nevaluations on Flickr30K and MSCOCO datasets for image-text matching tasks show\nthat FMMS significantly outperforms the state-of-the-art baselines.",
      "tldr_zh": "这篇论文针对视觉语言预训练 (VLP) 模型易受对抗攻击的问题，提出了一种新范式 Feedback-based Modal Mutual Search (FMMS)，旨在提升攻击的可转移性。FMMS 引入 modal mutual loss (MML) 来在特征空间中推远匹配的图像-文本对，同时拉近不匹配对，并利用目标模型反馈进行迭代精炼对抗样本，以探索多模态对抗边界。实验在 Flickr30K 和 MSCOCO 数据集上的图像-文本匹配任务中显示，FMMS 显著优于最先进基线方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.06726v1",
      "published_date": "2024-08-27 02:31:39 UTC",
      "updated_date": "2024-08-27 02:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:20:16.734740"
    },
    {
      "arxiv_id": "2409.00097v2",
      "title": "Large Language Models for Disease Diagnosis: A Scoping Review",
      "title_zh": "翻译失败",
      "authors": [
        "Shuang Zhou",
        "Zidu Xu",
        "Mian Zhang",
        "Chunpu Xu",
        "Yawen Guo",
        "Zaifu Zhan",
        "Sirui Ding",
        "Jiashuo Wang",
        "Kaishuai Xu",
        "Yi Fang",
        "Liqiao Xia",
        "Jeremy Yeung",
        "Daochen Zha",
        "Genevieve B. Melton",
        "Mingquan Lin",
        "Rui Zhang"
      ],
      "abstract": "Automatic disease diagnosis has become increasingly valuable in clinical\npractice. The advent of large language models (LLMs) has catalyzed a paradigm\nshift in artificial intelligence, with growing evidence supporting the efficacy\nof LLMs in diagnostic tasks. Despite the increasing attention in this field, a\nholistic view is still lacking. Many critical aspects remain unclear, such as\nthe diseases and clinical data to which LLMs have been applied, the LLM\ntechniques employed, and the evaluation methods used. In this article, we\nperform a comprehensive review of LLM-based methods for disease diagnosis. Our\nreview examines the existing literature across various dimensions, including\ndisease types and associated clinical specialties, clinical data, LLM\ntechniques, and evaluation methods. Additionally, we offer recommendations for\napplying and evaluating LLMs for diagnostic tasks. Furthermore, we assess the\nlimitations of current research and discuss future directions. To our\nknowledge, this is the first comprehensive review for LLM-based disease\ndiagnosis.",
      "tldr_zh": "这篇综述文章对Large Language Models (LLMs)在疾病诊断中的应用进行了全面审查，涵盖了LLMs适用的疾病类型、临床数据、所采用的LLM技术以及评估方法。研究分析了现有文献，提供了针对诊断任务的LLMs应用和评估推荐，并指出了当前研究的局限性以及未来发展方向。作为首个此类全面审查，该工作为提升LLMs在临床实践中的效能提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "69 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.00097v2",
      "published_date": "2024-08-27 02:06:45 UTC",
      "updated_date": "2024-09-19 12:19:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:20:27.592772"
    },
    {
      "arxiv_id": "2408.14728v1",
      "title": "TART: Boosting Clean Accuracy Through Tangent Direction Guided Adversarial Training",
      "title_zh": "TART：通过切线方向引导的对抗训练提升干净准确率",
      "authors": [
        "Bongsoo Yi",
        "Rongjie Lai",
        "Yao Li"
      ],
      "abstract": "Adversarial training has been shown to be successful in enhancing the\nrobustness of deep neural networks against adversarial attacks. However, this\nrobustness is accompanied by a significant decline in accuracy on clean data.\nIn this paper, we propose a novel method, called Tangent Direction Guided\nAdversarial Training (TART), that leverages the tangent space of the data\nmanifold to ameliorate the existing adversarial defense algorithms. We argue\nthat training with adversarial examples having large normal components\nsignificantly alters the decision boundary and hurts accuracy. TART mitigates\nthis issue by estimating the tangent direction of adversarial examples and\nallocating an adaptive perturbation limit according to the norm of their\ntangential component. To the best of our knowledge, our paper is the first work\nto consider the concept of tangent space and direction in the context of\nadversarial defense. We validate the effectiveness of TART through extensive\nexperiments on both simulated and benchmark datasets. The results demonstrate\nthat TART consistently boosts clean accuracy while retaining a high level of\nrobustness against adversarial attacks. Our findings suggest that incorporating\nthe geometric properties of data can lead to more effective and efficient\nadversarial training methods.",
      "tldr_zh": "该论文提出了一种名为 TART 的新方法，通过切线方向指导对抗训练（Tangent Direction Guided Adversarial Training），旨在提升深度神经网络在对抗攻击下的鲁棒性，同时减少对干净数据（clean data）的准确率下降。TART 利用数据流形的切线空间（tangent space）来估计对抗样本的切线方向，并根据其切向分量的范数分配自适应扰动限制，从而避免训练过程过度改变决策边界。实验结果显示，在模拟和基准数据集上，TART 显著提高了干净数据的准确率，同时保持了较高的对抗攻击鲁棒性。该研究证明，结合数据几何属性可以使对抗训练更有效和高效。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14728v1",
      "published_date": "2024-08-27 01:41:21 UTC",
      "updated_date": "2024-08-27 01:41:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:20:39.417969"
    },
    {
      "arxiv_id": "2409.00096v1",
      "title": "Non-instructional Fine-tuning: Enabling Instruction-Following Capabilities in Pre-trained Language Models without Instruction-Following Data",
      "title_zh": "翻译失败",
      "authors": [
        "Juncheng Xie",
        "Shensian Syu",
        "Hung-yi Lee"
      ],
      "abstract": "Instruction fine-tuning is crucial for today's large language models (LLMs)\nto learn to follow instructions and align with human preferences.\nConventionally, supervised data, including the instruction and the correct\nresponse, is required for instruction fine-tuning. To obtain such data, some\nresearchers prompted well-trained models like GPT-4 to generate instructions\nand correct responses. In this paper, we propose a novel approach that uses the\nfirst half of a random text from OpenWebText as the instruction and\nGPT-3.5-turbo or GPT-4-turbo to complete the text as the response. Despite the\ndata being \"non-instructional\", we found that pre-trained LLMs fine-tuned on\nthis data can gain instruction-following capabilities. This observation is\nverified by fine-tuning several well-known pre-trained LLMs (e.g., LLaMA-2-7B,\nLLaMA-3-8B, LLaMA-3-70B, Mistral-7B-v0.1). The \"non-instructional data\" also\nimproved some models that underwent supervised fine-tuning and human preference\nalignment. Our LLaMA-3-70B-Instruct fine-tuned through \"non-instructional data\"\nis comparable with LLaMA-3.1-70B-Instruct on the Arena Hard leaderboard. We\nanalyzed the \"non-instructional data\" and ensured it is devoid of content\nrelated to instruction fine-tuning. Our findings will inspire further\ninvestigation into how to develop instruction-following capabilities without\nexplicit instruction-related data.",
      "tldr_zh": "该论文提出了一种名为“Non-instructional Fine-tuning”的新方法，使用 OpenWebText 的随机文本前半部分作为指令，并由 GPT-3.5-turbo 或 GPT-4-turbo 生成响应，从而在预训练 LLM（如 LLaMA-2-7B 和 LLaMA-3-70B）中启用 Instruction-Following 能力，而无需传统指令数据。\n实验验证显示，微调后的模型不仅获得了指令遵循能力，还改善了已进行监督微调和人类偏好对齐的模型的表现，例如微调后的 LLaMA-3-70B-Instruct 在 Arena Hard 排行榜上与 LLaMA-3.1-70B-Instruct 相当。\n作者分析了数据，确保其不包含指令微调相关内容，并强调这一方法将激发进一步研究如何在 absence of explicit instruction-related data 的情况下开发 LLM 的指令遵循能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 2 figures, 15 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.00096v1",
      "published_date": "2024-08-27 01:21:53 UTC",
      "updated_date": "2024-08-27 01:21:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:20:53.975968"
    },
    {
      "arxiv_id": "2408.16021v2",
      "title": "XG-NID: Dual-Modality Network Intrusion Detection using a Heterogeneous Graph Neural Network and Large Language Model",
      "title_zh": "XG-NID：使用异构图神经网络和大语言模型的双模态网络入侵检测",
      "authors": [
        "Yasir Ali Farrukh",
        "Syed Wali",
        "Irfan Khan",
        "Nathaniel D. Bastian"
      ],
      "abstract": "In the rapidly evolving field of cybersecurity, the integration of flow-level\nand packet-level information for real-time intrusion detection remains a\nlargely untapped area of research. This paper introduces \"XG-NID,\" a novel\nframework that, to the best of our knowledge, is the first to fuse flow-level\nand packet-level data within a heterogeneous graph structure, offering a\ncomprehensive analysis of network traffic. Leveraging a heterogeneous graph\nneural network (GNN) with graph-level classification, XG-NID uniquely enables\nreal-time inference while effectively capturing the intricate relationships\nbetween flow and packet payload data. Unlike traditional GNN-based\nmethodologies that predominantly analyze historical data, XG-NID is designed to\naccommodate the heterogeneous nature of network traffic, providing a robust and\nreal-time defense mechanism. Our framework extends beyond mere classification;\nit integrates Large Language Models (LLMs) to generate detailed, human-readable\nexplanations and suggest potential remedial actions, ensuring that the insights\nproduced are both actionable and comprehensible. Additionally, we introduce a\nnew set of flow features based on temporal information, further enhancing the\ncontextual and explainable inferences provided by our model. To facilitate\npractical application and accessibility, we developed \"GNN4ID,\" an open-source\ntool that enables the extraction and transformation of raw network traffic into\nthe proposed heterogeneous graph structure, seamlessly integrating flow and\npacket-level data. Our comprehensive quantitative comparative analysis\ndemonstrates that XG-NID achieves an F1 score of 97\\% in multi-class\nclassification, outperforming existing baseline and state-of-the-art methods.\nThis sets a new standard in Network Intrusion Detection Systems by combining\ninnovative data fusion with enhanced interpretability and real-time\ncapabilities.",
      "tldr_zh": "该论文提出XG-NID框架，这是首个将flow-level和packet-level数据融合到异构图结构中的网络入侵检测系统，利用Heterogeneous Graph Neural Network (GNN)进行图级分类，实现实时推理并捕捉网络流量间的复杂关系。框架整合Large Language Models (LLMs)来生成详细的人类可读解释和潜在补救措施，同时引入基于时间信息的新的flow特征，提升模型的可解释性和上下文分析。为便于应用，作者开发了开源工具GNN4ID，用于提取和转换原始网络流量。实验结果显示，XG-NID在多类分类中达到97%的F1分数，优于现有基线方法，并为网络入侵检测系统设定了新标准，提供创新数据融合和实时防御能力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "19 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.16021v2",
      "published_date": "2024-08-27 01:14:34 UTC",
      "updated_date": "2025-05-07 21:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:21:15.052223"
    },
    {
      "arxiv_id": "2408.14721v2",
      "title": "PAT: Pruning-Aware Tuning for Large Language Models",
      "title_zh": "PAT：针对大型语言模型的剪枝感知调优",
      "authors": [
        "Yijiang Liu",
        "Huanrui Yang",
        "Youxin Chen",
        "Rongyu Zhang",
        "Miao Wang",
        "Yuan Du",
        "Li Du"
      ],
      "abstract": "Large language models (LLMs) excel in language tasks, especially with\nsupervised fine-tuning after pre-training. However, their substantial memory\nand computational requirements hinder practical applications. Structural\npruning, which reduces less significant weight dimensions, is one solution.\nYet, traditional post-hoc pruning often leads to significant performance loss,\nwith limited recovery from further fine-tuning due to reduced capacity. Since\nthe model fine-tuning refines the general and chaotic knowledge in pre-trained\nmodels, we aim to incorporate structural pruning with the fine-tuning, and\npropose the Pruning-Aware Tuning (PAT) paradigm to eliminate model redundancy\nwhile preserving the model performance to the maximum extend. Specifically, we\ninsert the innovative Hybrid Sparsification Modules (HSMs) between the\nAttention and FFN components to accordingly sparsify the upstream and\ndownstream linear modules. The HSM comprises a lightweight operator and a\nglobally shared trainable mask. The lightweight operator maintains a training\noverhead comparable to that of LoRA, while the trainable mask unifies the\nchannels to be sparsified, ensuring structural pruning. Additionally, we\npropose the Identity Loss which decouples the transformation and scaling\nproperties of the HSMs to enhance training robustness. Extensive experiments\ndemonstrate that PAT excels in both performance and efficiency. For example,\nour Llama2-7b model with a 25\\% pruning ratio achieves 1.33$\\times$ speedup\nwhile outperforming the LoRA-finetuned model by up to 1.26\\% in accuracy with a\nsimilar training cost. Code:\nhttps://github.com/kriskrisliu/PAT_Pruning-Aware-Tuning",
      "tldr_zh": "本研究针对大型语言模型（LLMs）的内存和计算需求问题，提出了一种Pruning-Aware Tuning (PAT) 范式，将结构修剪与微调过程结合，旨在消除模型冗余的同时最大限度保留性能。PAT 通过在Attention和FFN组件之间插入Hybrid Sparsification Modules (HSMs)，其中包括轻量级操作符和全局共享的可训练掩码，以实现上游和下游线性模块的稀疏化，并引入Identity Loss来解耦HSMs的变换和缩放属性，提升训练鲁棒性。实验结果显示，PAT在类似训练成本下表现出色，例如Llama2-7b模型在25%修剪率下实现1.33倍速度提升，并比LoRA微调模型准确率高出1.26%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.14721v2",
      "published_date": "2024-08-27 01:04:14 UTC",
      "updated_date": "2025-01-25 05:21:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:21:16.343570"
    },
    {
      "arxiv_id": "2408.14718v1",
      "title": "Residual-based Adaptive Huber Loss (RAHL) -- Design of an improved Huber loss for CQI prediction in 5G networks",
      "title_zh": "翻译失败",
      "authors": [
        "Mina Kaviani",
        "Jurandy Almeida",
        "Fabio L. Verdi"
      ],
      "abstract": "The Channel Quality Indicator (CQI) plays a pivotal role in 5G networks,\noptimizing infrastructure dynamically to ensure high Quality of Service (QoS).\nRecent research has focused on improving CQI estimation in 5G networks using\nmachine learning. In this field, the selection of the proper loss function is\ncritical for training an accurate model. Two commonly used loss functions are\nMean Squared Error (MSE) and Mean Absolute Error (MAE). Roughly speaking, MSE\nput more weight on outliers, MAE on the majority. Here, we argue that the Huber\nloss function is more suitable for CQI prediction, since it combines the\nbenefits of both MSE and MAE. To achieve this, the Huber loss transitions\nsmoothly between MSE and MAE, controlled by a user-defined hyperparameter\ncalled delta. However, finding the right balance between sensitivity to small\nerrors (MAE) and robustness to outliers (MSE) by manually choosing the optimal\ndelta is challenging. To address this issue, we propose a novel loss function,\nnamed Residual-based Adaptive Huber Loss (RAHL). In RAHL, a learnable residual\nis added to the delta, enabling the model to adapt based on the distribution of\nerrors in the data. Our approach effectively balances model robustness against\noutliers while preserving inlier data precision. The widely recognized Long\nShort-Term Memory (LSTM) model is employed in conjunction with RAHL, showcasing\nsignificantly improved results compared to the aforementioned loss functions.\nThe obtained results affirm the superiority of RAHL, offering a promising\navenue for enhanced CQI prediction in 5G networks.",
      "tldr_zh": "本论文针对5G网络中Channel Quality Indicator (CQI)预测的挑战，提出了一种新型损失函数Residual-based Adaptive Huber Loss (RAHL)，以克服传统Mean Squared Error (MSE)和Mean Absolute Error (MAE)的局限性。RAHL在Huber loss基础上添加了一个可学习的residual参数，使delta能根据数据错误分布自动调整，从而平衡了对异常值的鲁棒性和对正常数据的精确性。实验结果显示，使用Long Short-Term Memory (LSTM)模型的RAHL在CQI预测中显著优于MSE和MAE，提供了一种更有效的5G网络优化方法。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "https://sol.sbc.org.br/index.php/sbrc/article/view/29822/29625",
      "pdf_url": "http://arxiv.org/pdf/2408.14718v1",
      "published_date": "2024-08-27 00:58:32 UTC",
      "updated_date": "2024-08-27 00:58:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:21:28.064916"
    },
    {
      "arxiv_id": "2408.14717v1",
      "title": "Text2SQL is Not Enough: Unifying AI and Databases with TAG",
      "title_zh": "Text2SQL 是不够的：使用 TAG 统一 AI 和数据库",
      "authors": [
        "Asim Biswal",
        "Liana Patel",
        "Siddarth Jha",
        "Amog Kamsetty",
        "Shu Liu",
        "Joseph E. Gonzalez",
        "Carlos Guestrin",
        "Matei Zaharia"
      ],
      "abstract": "AI systems that serve natural language questions over databases promise to\nunlock tremendous value. Such systems would allow users to leverage the\npowerful reasoning and knowledge capabilities of language models (LMs)\nalongside the scalable computational power of data management systems. These\ncombined capabilities would empower users to ask arbitrary natural language\nquestions over custom data sources. However, existing methods and benchmarks\ninsufficiently explore this setting. Text2SQL methods focus solely on natural\nlanguage questions that can be expressed in relational algebra, representing a\nsmall subset of the questions real users wish to ask. Likewise,\nRetrieval-Augmented Generation (RAG) considers the limited subset of queries\nthat can be answered with point lookups to one or a few data records within the\ndatabase. We propose Table-Augmented Generation (TAG), a unified and\ngeneral-purpose paradigm for answering natural language questions over\ndatabases. The TAG model represents a wide range of interactions between the LM\nand database that have been previously unexplored and creates exciting research\nopportunities for leveraging the world knowledge and reasoning capabilities of\nLMs over data. We systematically develop benchmarks to study the TAG problem\nand find that standard methods answer no more than 20% of queries correctly,\nconfirming the need for further research in this area. We release code for the\nbenchmark at https://github.com/TAG-Research/TAG-Bench.",
      "tldr_zh": "该论文批评现有Text2SQL和Retrieval-Augmented Generation (RAG)方法在处理自然语言数据库查询时的局限性，前者仅限于关系代数查询，后者只支持简单点查询。作者提出Table-Augmented Generation (TAG)作为一种统一的范式，允许language models (LMs)充分利用其知识和推理能力，与数据库进行更广泛的交互，从而支持用户对自定义数据源的任意查询。实验基准显示，标准方法正确回答不超过20%的查询，突显了TAG的潜力，并发布了相关代码以推动进一步研究。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14717v1",
      "published_date": "2024-08-27 00:50:14 UTC",
      "updated_date": "2024-08-27 00:50:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:21:41.249991"
    },
    {
      "arxiv_id": "2408.14713v1",
      "title": "StyleSpeech: Parameter-efficient Fine Tuning for Pre-trained Controllable Text-to-Speech",
      "title_zh": "翻译失败",
      "authors": [
        "Haowei Lou",
        "Helen Paik",
        "Wen Hu",
        "Lina Yao"
      ],
      "abstract": "This paper introduces StyleSpeech, a novel Text-to-Speech~(TTS) system that\nenhances the naturalness and accuracy of synthesized speech. Building upon\nexisting TTS technologies, StyleSpeech incorporates a unique Style Decorator\nstructure that enables deep learning models to simultaneously learn style and\nphoneme features, improving adaptability and efficiency through the principles\nof Lower Rank Adaptation~(LoRA). LoRA allows efficient adaptation of style\nfeatures in pre-trained models. Additionally, we introduce a novel automatic\nevaluation metric, the LLM-Guided Mean Opinion Score (LLM-MOS), which employs\nlarge language models to offer an objective and robust protocol for\nautomatically assessing TTS system performance. Extensive testing on benchmark\ndatasets shows that our approach markedly outperforms existing state-of-the-art\nbaseline methods in producing natural, accurate, and high-quality speech. These\nadvancements not only pushes the boundaries of current TTS system capabilities,\nbut also facilitate the application of TTS system in more dynamic and\nspecialized, such as interactive virtual assistants, adaptive audiobooks, and\ncustomized voice for gaming. Speech samples can be found in\nhttps://style-speech.vercel.app",
      "tldr_zh": "本论文提出StyleSpeech，一种参数高效的微调方法，用于预训练的可控Text-to-Speech (TTS) 系统，通过Style Decorator结构同时学习风格和音素特征，并利用Lower Rank Adaptation (LoRA) 实现高效适应，提升合成语音的自然性和准确性。论文还引入了LLM-Guided Mean Opinion Score (LLM-MOS) 作为一种新型自动评估指标，利用大型语言模型提供客观的TTS性能评估。实验结果显示，StyleSpeech在基准数据集上显著优于现有基线方法，生成高质量语音，并扩展了TTS的应用场景，如交互式虚拟助手、适应性有声读物和游戏定制声音。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.14713v1",
      "published_date": "2024-08-27 00:37:07 UTC",
      "updated_date": "2024-08-27 00:37:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T19:21:51.587572"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 96,
  "processed_papers_count": 96,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T19:22:10.687778"
}