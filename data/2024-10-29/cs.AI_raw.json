[
  {
    "arxiv_id": "2411.00840v1",
    "title": "Peri-AIIMS: Perioperative Artificial Intelligence Driven Integrated Modeling of Surgeries using Anesthetic, Physical and Cognitive Statuses for Predicting Hospital Outcomes",
    "authors": [
      "Sabyasachi Bandyopadhyay",
      "Jiaqing Zhang",
      "Ronald L. Ison",
      "David J. Libon",
      "Patrick Tighe",
      "Catherine Price",
      "Parisa Rashidi"
    ],
    "abstract": "The association between preoperative cognitive status and surgical outcomes\nis a critical, yet scarcely explored area of research. Linking intraoperative\ndata with postoperative outcomes is a promising and low-cost way of evaluating\nlong-term impacts of surgical interventions. In this study, we evaluated how\npreoperative cognitive status as measured by the clock drawing test contributed\nto predicting length of hospital stay, hospital charges, average pain\nexperienced during follow-up, and 1-year mortality over and above\nintraoperative variables, demographics, preoperative physical status and\ncomorbidities. We expanded our analysis to 6 specific surgical groups where\nsufficient data was available for cross-validation. The clock drawing images\nwere represented by 10 constructional features discovered by a semi-supervised\ndeep learning algorithm, previously validated to differentiate between dementia\nand non-dementia patients. Different machine learning models were trained to\nclassify postoperative outcomes in hold-out test sets. The models were compared\nto their relative performance, time complexity, and interpretability. Shapley\nAdditive Explanations (SHAP) analysis was used to find the most predictive\nfeatures for classifying different outcomes in different surgical contexts.\nRelative classification performances achieved by different feature sets showed\nthat the perioperative cognitive dataset which included clock drawing features\nin addition to intraoperative variables, demographics, and comorbidities served\nas the best dataset for 12 of 18 possible surgery-outcome combinations...",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00840v1",
    "published_date": "2024-10-29 23:42:51 UTC",
    "updated_date": "2024-10-29 23:42:51 UTC"
  },
  {
    "arxiv_id": "2410.22597v1",
    "title": "Are Large-Language Models Graph Algorithmic Reasoners?",
    "authors": [
      "Alexander K Taylor",
      "Anthony Cuturrufo",
      "Vishal Yathish",
      "Mingyu Derek Ma",
      "Wei Wang"
    ],
    "abstract": "We seek to address a core challenge facing current Large Language Models\n(LLMs). LLMs have demonstrated superior performance in many tasks, yet continue\nto struggle with reasoning problems on explicit graphs that require multiple\nsteps. To address this gap, we introduce a novel benchmark designed to evaluate\nLLM performance on classical algorithmic reasoning tasks on explicit graphs.\nOur benchmark encompasses five fundamental algorithms: Breadth-First Search\n(BFS) and Depth-First Search (DFS) for connectivity, Dijkstra's algorithm and\nFloyd-Warshall algorithm for all nodes shortest path, and Prim's Minimum\nSpanning Tree (MST-Prim's) algorithm. Through extensive experimentation, we\nassess the capabilities of state-of-the-art LLMs in executing these algorithms\nstep-by-step and systematically evaluate their performance at each stage. Our\nfindings highlight the persistent challenges LLMs face in this domain and\nunderscore the necessity for advanced prompting techniques and algorithmic\ninstruction to enhance their graph reasoning abilities. This work presents\nMAGMA, the first comprehensive benchmark focused on LLMs completing classical\ngraph algorithms, and provides a critical step toward understanding and\nimproving their structured problem-solving skills.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 13 Figures",
    "pdf_url": "http://arxiv.org/pdf/2410.22597v1",
    "published_date": "2024-10-29 23:28:37 UTC",
    "updated_date": "2024-10-29 23:28:37 UTC"
  },
  {
    "arxiv_id": "2410.22591v2",
    "title": "FGCE: Feasible Group Counterfactual Explanations for Auditing Fairness",
    "authors": [
      "Christos Fragkathoulas",
      "Vasiliki Papanikou",
      "Evaggelia Pitoura",
      "Evimaria Terzi"
    ],
    "abstract": "This paper introduces the first graph-based framework for generating group\ncounterfactual explanations to audit model fairness, a crucial aspect of\ntrustworthy machine learning. Counterfactual explanations are instrumental in\nunderstanding and mitigating unfairness by revealing how inputs should change\nto achieve a desired outcome. Our framework, named Feasible Group\nCounterfactual Explanations (FGCEs), captures real-world feasibility\nconstraints and constructs subgroups with similar counterfactuals, setting it\napart from existing methods. It also addresses key trade-offs in counterfactual\ngeneration, including the balance between the number of counterfactuals, their\nassociated costs, and the breadth of coverage achieved. To evaluate these\ntrade-offs and assess fairness, we propose measures tailored to group\ncounterfactual generation. Our experimental results on benchmark datasets\ndemonstrate the effectiveness of our approach in managing feasibility\nconstraints and trade-offs, as well as the potential of our proposed metrics in\nidentifying and quantifying fairness issues.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22591v2",
    "published_date": "2024-10-29 23:10:01 UTC",
    "updated_date": "2024-11-15 12:02:15 UTC"
  },
  {
    "arxiv_id": "2411.00839v1",
    "title": "CausAdv: A Causal-based Framework for Detecting Adversarial Examples",
    "authors": [
      "Hichem Debbi"
    ],
    "abstract": "Deep learning has led to tremendous success in many real-world applications\nof computer vision, thanks to sophisticated architectures such as Convolutional\nneural networks (CNNs). However, CNNs have been shown to be vulnerable to\ncrafted adversarial perturbations in inputs. These inputs appear almost\nindistinguishable from natural images, yet they are incorrectly classified by\nCNN architectures. This vulnerability of adversarial examples has led\nresearchers to focus on enhancing the robustness of deep learning models in\ngeneral, and CNNs in particular, by creating defense and detection methods to\ndistinguish adversarials inputs from natural ones. In this paper, we address\nthe adversarial robustness of CNNs through causal reasoning.\n  We propose CausAdv: a causal framework for detecting adversarial examples\nbased on counterfactual reasoning. CausAdv learns causal and non-causal\nfeatures of every input, and quantifies the counterfactual information (CI) of\nevery filter of the last convolutional layer. Then we perform statistical\nanalysis on the filters CI of every sample, whether clan or adversarials, to\ndemonstrate how adversarial examples indeed exhibit different CI distributions\ncompared to clean samples. Our results show that causal reasoning enhances the\nprocess of adversarials detection without the need to train a separate\ndetector. In addition, we illustrate the efficiency of causal explanations as a\nhelpful detection technique through visualizing the causal features. The\nresults can be reproduced using the code available in the repository:\nhttps://github.com/HichemDebbi/CausAdv.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ME",
      "stat.ML",
      "I.2.10"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00839v1",
    "published_date": "2024-10-29 22:57:48 UTC",
    "updated_date": "2024-10-29 22:57:48 UTC"
  },
  {
    "arxiv_id": "2410.22584v1",
    "title": "BENCHAGENTS: Automated Benchmark Creation with Agent Interaction",
    "authors": [
      "Natasha Butt",
      "Varun Chandrasekaran",
      "Neel Joshi",
      "Besmira Nushi",
      "Vidhisha Balachandran"
    ],
    "abstract": "Evaluations are limited by benchmark availability. As models evolve, there is\na need to create benchmarks that can measure progress on new generative\ncapabilities. However, creating new benchmarks through human annotations is\nslow and expensive, restricting comprehensive evaluations for any capability.\nWe introduce BENCHAGENTS, a framework that methodically leverages large\nlanguage models (LLMs) to automate benchmark creation for complex capabilities\nwhile inherently ensuring data and metric quality. BENCHAGENTS decomposes the\nbenchmark creation process into planning, generation, data verification, and\nevaluation, each of which is executed by an LLM agent. These agents interact\nwith each other and utilize human-in-the-loop feedback from benchmark\ndevelopers to explicitly improve and flexibly control data diversity and\nquality. We use BENCHAGENTS to create benchmarks to evaluate capabilities\nrelated to planning and constraint satisfaction during text generation. We then\nuse these benchmarks to study seven state-of-the-art models and extract new\ninsights on common failure modes and model differences.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22584v1",
    "published_date": "2024-10-29 22:56:18 UTC",
    "updated_date": "2024-10-29 22:56:18 UTC"
  },
  {
    "arxiv_id": "2410.22578v1",
    "title": "Energy-Aware Multi-Agent Reinforcement Learning for Collaborative Execution in Mission-Oriented Drone Networks",
    "authors": [
      "Ying Li",
      "Changling Li",
      "Jiyao Chen",
      "Christine Roinou"
    ],
    "abstract": "Mission-oriented drone networks have been widely used for structural\ninspection, disaster monitoring, border surveillance, etc. Due to the limited\nbattery capacity of drones, mission execution strategy impacts network\nperformance and mission completion. However, collaborative execution is a\nchallenging problem for drones in such a dynamic environment as it also\ninvolves efficient trajectory design. We leverage multi-agent reinforcement\nlearning (MARL) to manage the challenge in this study, letting each drone learn\nto collaboratively execute tasks and plan trajectories based on its current\nstatus and environment. Simulation results show that the proposed collaborative\nexecution model can successfully complete the mission at least 80% of the time,\nregardless of task locations and lengths, and can even achieve a 100% success\nrate when the task density is not way too sparse. To the best of our knowledge,\nour work is one of the pioneer studies on leveraging MARL on collaborative\nexecution for mission-oriented drone networks; the unique value of this work\nlies in drone battery level driving our model design.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.NI",
    "comment": "2022 International Conference on Computer Communications and Networks",
    "pdf_url": "http://arxiv.org/pdf/2410.22578v1",
    "published_date": "2024-10-29 22:43:26 UTC",
    "updated_date": "2024-10-29 22:43:26 UTC"
  },
  {
    "arxiv_id": "2410.22559v4",
    "title": "Unpicking Data at the Seams: Understanding Disentanglement in VAEs",
    "authors": [
      "Carl Allen"
    ],
    "abstract": "Disentanglement, or identifying statistically independent factors of the\ndata, is relevant to much of machine learning, from controlled data generation\nand robust classification to efficient encoding and improving our understanding\nof the data itself. Disentanglement arises in several generative paradigms\nincluding Variational Autoencoders (VAEs), Generative Adversarial Networks and\ndiffusion models. Recent progress has been made in understanding\ndisentanglement in VAEs, where a choice of diagonal posterior covariance\nmatrices is shown to promote mutual orthogonality between columns of the\ndecoder's Jacobian. We build on this to show how such orthogonality, a\ngeometric property, translates to disentanglement, a statistical property,\nfurthering our understanding of how a VAE identifies independent components of,\nor disentangles, the data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22559v4",
    "published_date": "2024-10-29 21:54:18 UTC",
    "updated_date": "2025-02-06 15:35:37 UTC"
  },
  {
    "arxiv_id": "2410.22553v1",
    "title": "ML Research Benchmark",
    "authors": [
      "Matthew Kenney"
    ],
    "abstract": "Artificial intelligence agents are increasingly capable of performing complex\ntasks across various domains. As these agents advance, there is a growing need\nto accurately measure and benchmark their capabilities, particularly in\naccelerating AI research and development. Current benchmarks focus on general\nmachine learning tasks, but lack comprehensive evaluation methods for assessing\nAI agents' abilities in tackling research-level problems and competition-level\nchallenges in the field of AI. We present the ML Research Benchmark (MLRB),\ncomprising 7 competition-level tasks derived from recent machine learning\nconference tracks. These tasks span activities typically undertaken by AI\nresearchers, including model training efficiency, pretraining on limited data,\ndomain specific fine-tuning, and model compression. This paper introduces a\nnovel benchmark and evaluates it using agent scaffolds powered by frontier\nmodels, including Claude-3 and GPT-4o. The results indicate that the Claude-3.5\nSonnet agent performs best across our benchmark, excelling in planning and\ndeveloping machine learning models. However, both tested agents struggled to\nperform non-trivial research iterations. We observed significant performance\nvariations across tasks, highlighting the complexity of AI development and the\nchallenges in creating versatile agent scaffolds. While current AI agents can\nsuccessfully navigate complex instructions and produce baseline results, they\nfall short of the capabilities required for advanced AI research. The ML\nResearch Benchmark provides a valuable framework for assessing and comparing AI\nagents on tasks mirroring real-world AI research challenges.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22553v1",
    "published_date": "2024-10-29 21:38:42 UTC",
    "updated_date": "2024-10-29 21:38:42 UTC"
  },
  {
    "arxiv_id": "2410.22552v1",
    "title": "Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents",
    "authors": [
      "Jaekyeom Kim",
      "Dong-Ki Kim",
      "Lajanugen Logeswaran",
      "Sungryull Sohn",
      "Honglak Lee"
    ],
    "abstract": "In this paper, we introduce Auto-Intent, a method to adapt a pre-trained\nlarge language model (LLM) as an agent for a target domain without direct\nfine-tuning, where we empirically focus on web navigation tasks. Our approach\nfirst discovers the underlying intents from target domain demonstrations\nunsupervisedly, in a highly compact form (up to three words). With the\nextracted intents, we train our intent predictor to predict the next intent\ngiven the agent's past observations and actions. In particular, we propose a\nself-exploration approach where top-k probable intent predictions are provided\nas a hint to the pre-trained LLM agent, which leads to enhanced decision-making\ncapabilities. Auto-Intent substantially improves the performance of GPT-{3.5,\n4} and Llama-3.1-{70B, 405B} agents on the large-scale real-website navigation\nbenchmarks from Mind2Web and online navigation tasks from WebArena with its\ncross-benchmark generalization from Mind2Web.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2410.22552v1",
    "published_date": "2024-10-29 21:37:04 UTC",
    "updated_date": "2024-10-29 21:37:04 UTC"
  },
  {
    "arxiv_id": "2410.22526v1",
    "title": "From Silos to Systems: Process-Oriented Hazard Analysis for AI Systems",
    "authors": [
      "Shalaleh Rismani",
      "Roel Dobbe",
      "AJung Moon"
    ],
    "abstract": "To effectively address potential harms from AI systems, it is essential to\nidentify and mitigate system-level hazards. Current analysis approaches focus\non individual components of an AI system, like training data or models, in\nisolation, overlooking hazards from component interactions or how they are\nsituated within a company's development process. To this end, we draw from the\nestablished field of system safety, which considers safety as an emergent\nproperty of the entire system, not just its components. In this work, we\ntranslate System Theoretic Process Analysis (STPA) - a recognized system safety\nframework - for analyzing AI operation and development processes. We focus on\nsystems that rely on machine learning algorithms and conducted STPA on three\ncase studies involving linear regression, reinforcement learning, and\ntransformer-based generative models. Our analysis explored how STPA's control\nand system-theoretic perspectives apply to AI systems and whether unique AI\ntraits - such as model opacity, capability uncertainty, and output complexity -\nnecessitate significant modifications to the framework. We find that the key\nconcepts and steps of conducting an STPA readily apply, albeit with a few\nadaptations tailored for AI systems. We present the Process-oriented Hazard\nAnalysis for AI Systems (PHASE) as a guideline that adapts STPA concepts for\nAI, making STPA-based hazard analysis more accessible. PHASE enables four key\naffordances for analysts responsible for managing AI system harms: 1) detection\nof hazards at the systems level, including those from accumulation of disparate\nissues; 2) explicit acknowledgment of social factors contributing to\nexperiences of algorithmic harms; 3) creation of traceable accountability\nchains between harms and those who can mitigate the harm; and 4) ongoing\nmonitoring and mitigation of new hazards.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22526v1",
    "published_date": "2024-10-29 20:43:18 UTC",
    "updated_date": "2024-10-29 20:43:18 UTC"
  },
  {
    "arxiv_id": "2410.22517v1",
    "title": "Attention Speaks Volumes: Localizing and Mitigating Bias in Language Models",
    "authors": [
      "Rishabh Adiga",
      "Besmira Nushi",
      "Varun Chandrasekaran"
    ],
    "abstract": "We explore the internal mechanisms of how bias emerges in large language\nmodels (LLMs) when provided with ambiguous comparative prompts: inputs that\ncompare or enforce choosing between two or more entities without providing\nclear context for preference. Most approaches for bias mitigation focus on\neither post-hoc analysis or data augmentation. However, these are transient\nsolutions, without addressing the root cause: the model itself. Numerous prior\nworks show the influence of the attention module towards steering generations.\nWe believe that analyzing attention is also crucial for understanding bias, as\nit provides insight into how the LLM distributes its focus across different\nentities and how this contributes to biased decisions. To this end, we first\nintroduce a metric to quantify the LLM's preference for one entity over\nanother. We then propose $\\texttt{ATLAS}$ (Attention-based Targeted Layer\nAnalysis and Scaling), a technique to localize bias to specific layers of the\nLLM by analyzing attention scores and then reduce bias by scaling attention in\nthese biased layers. To evaluate our method, we conduct experiments across 3\ndatasets (BBQ, Crows-Pairs, and WinoGender) using $\\texttt{GPT-2 XL}$ (1.5B),\n$\\texttt{GPT-J}$ (6B), $\\texttt{LLaMA-2}$ (7B) and $\\texttt{LLaMA-3}$ (8B). Our\nexperiments demonstrate that bias is concentrated in the later layers,\ntypically around the last third. We also show how $\\texttt{ATLAS}$ effectively\nmitigates bias through targeted interventions without compromising downstream\nperformance and an average increase of only 0.82% in perplexity when the\nintervention is applied. We see an average improvement of 0.28 points in the\nbias score across all the datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22517v1",
    "published_date": "2024-10-29 20:15:56 UTC",
    "updated_date": "2024-10-29 20:15:56 UTC"
  },
  {
    "arxiv_id": "2410.23317v1",
    "title": "VL-Cache: Sparsity and Modality-Aware KV Cache Compression for Vision-Language Model Inference Acceleration",
    "authors": [
      "Dezhan Tu",
      "Danylo Vashchilenko",
      "Yuzhe Lu",
      "Panpan Xu"
    ],
    "abstract": "Vision-Language Models (VLMs) have demonstrated impressive performance across\na versatile set of tasks. A key challenge in accelerating VLMs is storing and\naccessing the large Key-Value (KV) cache that encodes long visual contexts,\nsuch as images or videos. While existing KV cache compression methods are\neffective for Large Language Models (LLMs), directly migrating them to VLMs\nyields suboptimal accuracy and speedup. To bridge the gap, we propose VL-Cache,\na novel KV cache compression recipe tailored for accelerating VLM inference. In\nthis paper, we first investigate the unique sparsity pattern of VLM attention\nby distinguishing visual and text tokens in prefill and decoding phases. Based\non these observations, we introduce a layer-adaptive sparsity-aware cache\nbudget allocation method that effectively distributes the limited cache budget\nacross different layers, further reducing KV cache size without compromising\naccuracy. Additionally, we develop a modality-aware token scoring policy to\nbetter evaluate the token importance. Empirical results on multiple benchmark\ndatasets demonstrate that retaining only 10% of KV cache achieves accuracy\ncomparable to that with full cache. In a speed benchmark, our method\naccelerates end-to-end latency of generating 100 tokens by up to 2.33x and\nspeeds up decoding by up to 7.08x, while reducing the memory footprint of KV\ncache in GPU by 90%.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.DC",
      "cs.PF"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23317v1",
    "published_date": "2024-10-29 20:04:34 UTC",
    "updated_date": "2024-10-29 20:04:34 UTC"
  },
  {
    "arxiv_id": "2411.00046v1",
    "title": "CurateGPT: A flexible language-model assisted biocuration tool",
    "authors": [
      "Harry Caufield",
      "Carlo Kroll",
      "Shawn T O'Neil",
      "Justin T Reese",
      "Marcin P Joachimiak",
      "Harshad Hegde",
      "Nomi L Harris",
      "Madan Krishnamurthy",
      "James A McLaughlin",
      "Damian Smedley",
      "Melissa A Haendel",
      "Peter N Robinson",
      "Christopher J Mungall"
    ],
    "abstract": "Effective data-driven biomedical discovery requires data curation: a\ntime-consuming process of finding, organizing, distilling, integrating,\ninterpreting, annotating, and validating diverse information into a structured\nform suitable for databases and knowledge bases. Accurate and efficient\ncuration of these digital assets is critical to ensuring that they are FAIR,\ntrustworthy, and sustainable. Unfortunately, expert curators face significant\ntime and resource constraints. The rapid pace of new information being\npublished daily is exceeding their capacity for curation. Generative AI,\nexemplified by instruction-tuned large language models (LLMs), has opened up\nnew possibilities for assisting human-driven curation. The design philosophy of\nagents combines the emerging abilities of generative AI with more precise\nmethods. A curator's tasks can be aided by agents for performing reasoning,\nsearching ontologies, and integrating knowledge across external sources, all\nefforts otherwise requiring extensive manual effort. Our LLM-driven annotation\ntool, CurateGPT, melds the power of generative AI together with trusted\nknowledge bases and literature sources. CurateGPT streamlines the curation\nprocess, enhancing collaboration and efficiency in common workflows. Compared\nto direct interaction with an LLM, CurateGPT's agents enable access to\ninformation beyond that in the LLM's training data and they provide direct\nlinks to the data supporting each claim. This helps curators, researchers, and\nengineers scale up curation efforts to keep pace with the ever-increasing\nvolume of scientific data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "q-bio.QM"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00046v1",
    "published_date": "2024-10-29 20:00:04 UTC",
    "updated_date": "2024-10-29 20:00:04 UTC"
  },
  {
    "arxiv_id": "2410.22492v2",
    "title": "RealCQA-V2 : Visual Premise Proving A Manual COT Dataset for Charts",
    "authors": [
      "Saleem Ahmed",
      "Ranga Setlur",
      "Venu Govindaraju"
    ],
    "abstract": "We introduce Visual Premise Proving (VPP), a novel task tailored to refine\nthe process of chart question answering by deconstructing it into a series of\nlogical premises. Each of these premises represents an essential step in\ncomprehending a chart's content and deriving logical conclusions, thereby\nproviding a granular look at a model's reasoning abilities. This approach\nrepresents a departure from conventional accuracy-based evaluation methods,\nemphasizing the model's ability to sequentially validate each premise and\nideally mimic human analytical processes. A model adept at reasoning is\nexpected to demonstrate proficiency in both data retrieval and the structural\nunderstanding of charts, suggesting a synergy between these competencies.\nHowever, in our zero-shot study using the sophisticated MATCHA model on a\nscientific chart question answering dataset, an intriguing pattern emerged. The\nmodel showcased superior performance in chart reasoning (27\\%) over chart\nstructure (19\\%) and data retrieval (14\\%). This performance gap suggests that\nmodels might more readily generalize reasoning capabilities across datasets,\nbenefiting from consistent mathematical and linguistic semantics, even when\nchallenged by changes in the visual domain that complicate structure\ncomprehension and data retrieval. Furthermore, the efficacy of using accuracy\nof binary QA for evaluating chart reasoning comes into question if models can\ndeduce correct answers without parsing chart data or structure. VPP highlights\nthe importance of integrating reasoning with visual comprehension to enhance\nmodel performance in chart analysis, pushing for a balanced approach in\nevaluating visual data interpretation capabilities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Under Review : Code and Data will be made public soon",
    "pdf_url": "http://arxiv.org/pdf/2410.22492v2",
    "published_date": "2024-10-29 19:32:53 UTC",
    "updated_date": "2024-11-10 00:54:21 UTC"
  },
  {
    "arxiv_id": "2411.00045v1",
    "title": "A Novel Psychometrics-Based Approach to Developing Professional Competency Benchmark for Large Language Models",
    "authors": [
      "Elena Kardanova",
      "Alina Ivanova",
      "Ksenia Tarasova",
      "Taras Pashchenko",
      "Aleksei Tikhoniuk",
      "Elen Yusupova",
      "Anatoly Kasprzhak",
      "Yaroslav Kuzminov",
      "Ekaterina Kruchinskaia",
      "Irina Brun"
    ],
    "abstract": "The era of large language models (LLM) raises questions not only about how to\ntrain models, but also about how to evaluate them. Despite numerous existing\nbenchmarks, insufficient attention is often given to creating assessments that\ntest LLMs in a valid and reliable manner. To address this challenge, we\naccommodate the Evidence-centered design (ECD) methodology and propose a\ncomprehensive approach to benchmark development based on rigorous psychometric\nprinciples. In this paper, we have made the first attempt to illustrate this\napproach by creating a new benchmark in the field of pedagogy and education,\nhighlighting the limitations of existing benchmark development approach and\ntaking into account the development of LLMs. We conclude that a new approach to\nbenchmarking is required to match the growing complexity of AI applications in\nthe educational context. We construct a novel benchmark guided by the Bloom's\ntaxonomy and rigorously designed by a consortium of education experts trained\nin test development. Thus the current benchmark provides an academically robust\nand practical assessment tool tailored for LLMs, rather than human\nparticipants. Tested empirically on the GPT model in the Russian language, it\nevaluates model performance across varied task complexities, revealing critical\ngaps in current LLM capabilities. Our results indicate that while generative AI\ntools hold significant promise for education - potentially supporting tasks\nsuch as personalized tutoring, real-time feedback, and multilingual learning -\ntheir reliability as autonomous teachers' assistants right now remain rather\nlimited, particularly in tasks requiring deeper cognitive engagement.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "36 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.00045v1",
    "published_date": "2024-10-29 19:32:43 UTC",
    "updated_date": "2024-10-29 19:32:43 UTC"
  },
  {
    "arxiv_id": "2410.22488v1",
    "title": "Privacy-Preserving Dynamic Assortment Selection",
    "authors": [
      "Young Hyun Cho",
      "Will Wei Sun"
    ],
    "abstract": "With the growing demand for personalized assortment recommendations, concerns\nover data privacy have intensified, highlighting the urgent need for effective\nprivacy-preserving strategies. This paper presents a novel framework for\nprivacy-preserving dynamic assortment selection using the multinomial logit\n(MNL) bandits model. Our approach employs a perturbed upper confidence bound\nmethod, integrating calibrated noise into user utility estimates to balance\nbetween exploration and exploitation while ensuring robust privacy protection.\nWe rigorously prove that our policy satisfies Joint Differential Privacy (JDP),\nwhich better suits dynamic environments than traditional differential privacy,\neffectively mitigating inference attack risks. This analysis is built upon a\nnovel objective perturbation technique tailored for MNL bandits, which is also\nof independent interest. Theoretically, we derive a near-optimal regret bound\nof $\\tilde{O}(\\sqrt{T})$ for our policy and explicitly quantify how privacy\nprotection impacts regret. Through extensive simulations and an application to\nthe Expedia hotel dataset, we demonstrate substantial performance enhancements\nover the benchmark method.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22488v1",
    "published_date": "2024-10-29 19:28:01 UTC",
    "updated_date": "2024-10-29 19:28:01 UTC"
  },
  {
    "arxiv_id": "2410.22480v1",
    "title": "Scaling LLM Inference with Optimized Sample Compute Allocation",
    "authors": [
      "Kexun Zhang",
      "Shang Zhou",
      "Danqing Wang",
      "William Yang Wang",
      "Lei Li"
    ],
    "abstract": "Sampling is a basic operation in many inference-time algorithms of large\nlanguage models (LLMs). To scale up inference efficiently with a limited\ncompute, it is crucial to find an optimal allocation for sample compute\nbudgets: Which sampling configurations (model, temperature, language, etc.) do\nwe use? How many samples do we generate in each configuration? We formulate\nthese choices as a learning problem and propose OSCA, an algorithm that\nOptimizes Sample Compute Allocation by finding an optimal mix of different\ninference configurations. Our experiments show that with our learned mixed\nallocation, we can achieve accuracy better than the best single configuration\nwith 128x less compute on code generation and 25x less compute on 4 reasoning\ntasks. OSCA is also shown to be effective in agentic workflows beyond\nsingle-turn tasks, achieving a better accuracy on SWE-Bench with 3x less\ncompute than the default configuration. Our code and generations are released\nat https://github.com/LeiLiLab/OSCA.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22480v1",
    "published_date": "2024-10-29 19:17:55 UTC",
    "updated_date": "2024-10-29 19:17:55 UTC"
  },
  {
    "arxiv_id": "2410.22475v1",
    "title": "Ethical Statistical Practice and Ethical AI",
    "authors": [
      "Rochelle E. Tractenberg"
    ],
    "abstract": "Artificial Intelligence (AI) is a field that utilizes computing and often,\ndata and statistics, intensively together to solve problems or make\npredictions. AI has been evolving with literally unbelievable speed over the\npast few years, and this has led to an increase in social, cultural,\nindustrial, scientific, and governmental concerns about the ethical development\nand use of AI systems worldwide. The ASA has issued a statement on ethical\nstatistical practice and AI (ASA, 2024), which echoes similar statements from\nother groups. Here we discuss the support for ethical statistical practice and\nethical AI that has been established in long-standing human rights law and\nethical practice standards for computing and statistics. There are multiple\nsources of support for ethical statistical practice and ethical AI deriving\nfrom these source documents, which are critical for strengthening the\noperationalization of the \"Statement on Ethical AI for Statistics\nPractitioners\". These resources are explicated for interested readers to\nutilize to guide their development and use of AI in, and through, their\nstatistical practice.",
    "categories": [
      "stat.OT",
      "cs.AI",
      "cs.CY",
      "00, 62, 62.A01, 62.A99, 62.P99, 97.K8D",
      "A.0; A.m; K.7; K.4"
    ],
    "primary_category": "stat.OT",
    "comment": "10 pages; Preprint of submission to Proceedings of JSM 2024 Portland,\n  OR",
    "pdf_url": "http://arxiv.org/pdf/2410.22475v1",
    "published_date": "2024-10-29 19:09:34 UTC",
    "updated_date": "2024-10-29 19:09:34 UTC"
  },
  {
    "arxiv_id": "2411.00838v1",
    "title": "Task-Oriented Real-time Visual Inference for IoVT Systems: A Co-design Framework of Neural Networks and Edge Deployment",
    "authors": [
      "Jiaqi Wu",
      "Simin Chen",
      "Zehua Wang",
      "Wei Chen",
      "Zijian Tian",
      "F. Richard Yu",
      "Victor C. M. Leung"
    ],
    "abstract": "As the volume of image data grows, data-oriented cloud computing in Internet\nof Video Things (IoVT) systems encounters latency issues. Task-oriented edge\ncomputing addresses this by shifting data analysis to the edge. However,\nlimited computational power of edge devices poses challenges for executing\nvisual tasks. Existing methods struggle to balance high model performance with\nlow resource consumption; lightweight neural networks often underperform, while\ndevice-specific models designed by Neural Architecture Search (NAS) fail to\nadapt to heterogeneous devices. For these issues, we propose a novel co-design\nframework to optimize neural network architecture and deployment strategies\nduring inference for high-throughput. Specifically, it implements a dynamic\nmodel structure based on re-parameterization, coupled with a Roofline-based\nmodel partitioning strategy to enhance the computational performance of edge\ndevices. We also employ a multi-objective co-optimization approach to balance\nthroughput and accuracy. Additionally, we derive mathematical consistency and\nconvergence of partitioned models. Experimental results demonstrate significant\nimprovements in throughput (12.05\\% on MNIST, 18.83\\% on ImageNet) and superior\nclassification accuracy compared to baseline algorithms. Our method\nconsistently achieves stable performance across different devices, underscoring\nits adaptability. Simulated experiments further confirm its efficacy in\nhigh-accuracy, real-time detection for small objects in IoVT systems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00838v1",
    "published_date": "2024-10-29 19:02:54 UTC",
    "updated_date": "2024-10-29 19:02:54 UTC"
  },
  {
    "arxiv_id": "2410.22459v1",
    "title": "Predicting Future Actions of Reinforcement Learning Agents",
    "authors": [
      "Stephen Chung",
      "Scott Niekum",
      "David Krueger"
    ],
    "abstract": "As reinforcement learning agents become increasingly deployed in real-world\nscenarios, predicting future agent actions and events during deployment is\nimportant for facilitating better human-agent interaction and preventing\ncatastrophic outcomes. This paper experimentally evaluates and compares the\neffectiveness of future action and event prediction for three types of RL\nagents: explicitly planning, implicitly planning, and non-planning. We employ\ntwo approaches: the inner state approach, which involves predicting based on\nthe inner computations of the agents (e.g., plans or neuron activations), and a\nsimulation-based approach, which involves unrolling the agent in a learned\nworld model. Our results show that the plans of explicitly planning agents are\nsignificantly more informative for prediction than the neuron activations of\nthe other types. Furthermore, using internal plans proves more robust to model\nquality compared to simulation-based approaches when predicting actions, while\nthe results for event prediction are more mixed. These findings highlight the\nbenefits of leveraging inner states and simulations to predict future agent\nactions and events, thereby improving interaction and safety in real-world\ndeployments.",
    "categories": [
      "cs.AI",
      "I.2.6; I.2.8; I.5.1"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.22459v1",
    "published_date": "2024-10-29 18:48:18 UTC",
    "updated_date": "2024-10-29 18:48:18 UTC"
  },
  {
    "arxiv_id": "2410.22457v1",
    "title": "Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset",
    "authors": [
      "Adrian Garret Gabriel",
      "Alaa Alameer Ahmad",
      "Shankar Kumar Jeyakumar"
    ],
    "abstract": "Advancements in Large Language Models (LLMs) are revolutionizing the\ndevelopment of autonomous agentic systems by enabling dynamic, context-aware\ntask decomposition and automated tool selection. These sophisticated systems\npossess significant automation potential across various industries, managing\ncomplex tasks, interacting with external systems to enhance knowledge, and\nexecuting actions independently. This paper presents three primary\ncontributions to advance this field:\n  - Advanced Agentic Framework: A system that handles multi-hop queries,\ngenerates and executes task graphs, selects appropriate tools, and adapts to\nreal-time changes.\n  - Novel Evaluation Metrics: Introduction of Node F1 Score, Structural\nSimilarity Index (SSI), and Tool F1 Score to comprehensively assess agentic\nsystems.\n  - Specialized Dataset: Development of an AsyncHow-based dataset for analyzing\nagent behavior across different task complexities.\n  Our findings reveal that asynchronous and dynamic task graph decomposition\nsignificantly enhances system responsiveness and scalability, particularly for\ncomplex, multi-step tasks. Detailed analysis shows that structural and\nnode-level metrics are crucial for sequential tasks, while tool-related metrics\nare more important for parallel tasks. Specifically, the Structural Similarity\nIndex (SSI) is the most significant predictor of performance in sequential\ntasks, and the Tool F1 Score is essential for parallel tasks. These insights\nhighlight the need for balanced evaluation methods that capture both structural\nand operational dimensions of agentic systems. Additionally, our evaluation\nframework, validated through empirical analysis and statistical testing,\nprovides valuable insights for improving the adaptability and reliability of\nagentic systems in dynamic environments.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024), NeurIPS 2024 Workshop on Open-World Agents",
    "pdf_url": "http://arxiv.org/pdf/2410.22457v1",
    "published_date": "2024-10-29 18:45:13 UTC",
    "updated_date": "2024-10-29 18:45:13 UTC"
  },
  {
    "arxiv_id": "2410.22456v1",
    "title": "Image2Struct: Benchmarking Structure Extraction for Vision-Language Models",
    "authors": [
      "Josselin Somerville Roberts",
      "Tony Lee",
      "Chi Heem Wong",
      "Michihiro Yasunaga",
      "Yifan Mai",
      "Percy Liang"
    ],
    "abstract": "We introduce Image2Struct, a benchmark to evaluate vision-language models\n(VLMs) on extracting structure from images. Our benchmark 1) captures\nreal-world use cases, 2) is fully automatic and does not require human\njudgment, and 3) is based on a renewable stream of fresh data. In Image2Struct,\nVLMs are prompted to generate the underlying structure (e.g., LaTeX code or\nHTML) from an input image (e.g., webpage screenshot). The structure is then\nrendered to produce an output image (e.g., rendered webpage), which is compared\nagainst the input image to produce a similarity score. This round-trip\nevaluation allows us to quantitatively evaluate VLMs on tasks with multiple\nvalid structures. We create a pipeline that downloads fresh data from active\nonline communities upon execution and evaluates the VLMs without human\nintervention. We introduce three domains (Webpages, LaTeX, and Musical Scores)\nand use five image metrics (pixel similarity, cosine similarity between the\nInception vectors, learned perceptual image patch similarity, structural\nsimilarity index measure, and earth mover similarity) that allow efficient and\nautomatic comparison between pairs of images. We evaluate Image2Struct on 14\nprominent VLMs and find that scores vary widely, indicating that Image2Struct\ncan differentiate between the performances of different VLMs. Additionally, the\nbest score varies considerably across domains (e.g., 0.402 on sheet music vs.\n0.830 on LaTeX equations), indicating that Image2Struct contains tasks of\nvarying difficulty. For transparency, we release the full results at\nhttps://crfm.stanford.edu/helm/image2struct/v1.0.1/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024. First three authors contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2410.22456v1",
    "published_date": "2024-10-29 18:44:59 UTC",
    "updated_date": "2024-10-29 18:44:59 UTC"
  },
  {
    "arxiv_id": "2411.00837v1",
    "title": "Longitudinal Mammogram Exam-based Breast Cancer Diagnosis Models: Vulnerability to Adversarial Attacks",
    "authors": [
      "Zhengbo Zhou",
      "Degan Hao",
      "Dooman Arefan",
      "Margarita Zuley",
      "Jules Sumkin",
      "Shandong Wu"
    ],
    "abstract": "In breast cancer detection and diagnosis, the longitudinal analysis of\nmammogram images is crucial. Contemporary models excel in detecting temporal\nimaging feature changes, thus enhancing the learning process over sequential\nimaging exams. Yet, the resilience of these longitudinal models against\nadversarial attacks remains underexplored. In this study, we proposed a novel\nattack method that capitalizes on the feature-level relationship between two\nsequential mammogram exams of a longitudinal model, guided by both\ncross-entropy loss and distance metric learning, to achieve significant attack\nefficacy, as implemented using attack transferring in a black-box attacking\nmanner. We performed experiments on a cohort of 590 breast cancer patients\n(each has two sequential mammogram exams) in a case-control setting. Results\nshowed that our proposed method surpassed several state-of-the-art adversarial\nattacks in fooling the diagnosis models to give opposite outputs. Our method\nremained effective even if the model was trained with the common defending\nmethod of adversarial training.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00837v1",
    "published_date": "2024-10-29 18:37:44 UTC",
    "updated_date": "2024-10-29 18:37:44 UTC"
  },
  {
    "arxiv_id": "2410.22451v1",
    "title": "Addressing Issues with Working Memory in Video Object Segmentation",
    "authors": [
      "Clayton Bromley",
      "Alexander Moore",
      "Amar Saini",
      "Douglas Poland",
      "Carmen Carrano"
    ],
    "abstract": "Contemporary state-of-the-art video object segmentation (VOS) models compare\nincoming unannotated images to a history of image-mask relations via affinity\nor cross-attention to predict object masks. We refer to the internal memory\nstate of the initial image-mask pair and past image-masks as a working memory\nbuffer. While the current state of the art models perform very well on clean\nvideo data, their reliance on a working memory of previous frames leaves room\nfor error. Affinity-based algorithms include the inductive bias that there is\ntemporal continuity between consecutive frames. To account for inconsistent\ncamera views of the desired object, working memory models need an algorithmic\nmodification that regulates the memory updates and avoid writing irrelevant\nframes into working memory. A simple algorithmic change is proposed that can be\napplied to any existing working memory-based VOS model to improve performance\non inconsistent views, such as sudden camera cuts, frame interjections, and\nextreme context changes. The resulting model performances show significant\nimprovement on video data with these frame interjections over the same model\nwithout the algorithmic addition. Our contribution is a simple decision\nfunction that determines whether working memory should be updated based on the\ndetection of sudden, extreme changes and the assumption that the object is no\nlonger in frame. By implementing algorithmic changes, such as this, we can\nincrease the real-world applicability of current VOS models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T45",
      "I.4.6; I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.22451v1",
    "published_date": "2024-10-29 18:34:41 UTC",
    "updated_date": "2024-10-29 18:34:41 UTC"
  },
  {
    "arxiv_id": "2410.22446v2",
    "title": "Do Large Language Models Align with Core Mental Health Counseling Competencies?",
    "authors": [
      "Viet Cuong Nguyen",
      "Mohammad Taher",
      "Dongwan Hong",
      "Vinicius Konkolics Possobom",
      "Vibha Thirunellayi Gopalakrishnan",
      "Ekta Raj",
      "Zihang Li",
      "Heather J. Soled",
      "Michael L. Birnbaum",
      "Srijan Kumar",
      "Munmun De Choudhury"
    ],
    "abstract": "The rapid evolution of Large Language Models (LLMs) presents a promising\nsolution to the global shortage of mental health professionals. However, their\nalignment with essential counseling competencies remains underexplored. We\nintroduce CounselingBench, a novel NCMHCE-based benchmark evaluating 22\ngeneral-purpose and medical-finetuned LLMs across five key competencies. While\nfrontier models surpass minimum aptitude thresholds, they fall short of\nexpert-level performance, excelling in Intake, Assessment & Diagnosis but\nstruggling with Core Counseling Attributes and Professional Practice & Ethics.\nSurprisingly, medical LLMs do not outperform generalist models in accuracy,\nthough they provide slightly better justifications while making more\ncontext-related errors. These findings highlight the challenges of developing\nAI for mental health counseling, particularly in competencies requiring empathy\nand nuanced reasoning. Our results underscore the need for specialized,\nfine-tuned models aligned with core mental health counseling competencies and\nsupported by human oversight before real-world deployment. Code and data\nassociated with this manuscript can be found at:\nhttps://github.com/cuongnguyenx/CounselingBench",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 Pages, Accepted to Findings of NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.22446v2",
    "published_date": "2024-10-29 18:27:11 UTC",
    "updated_date": "2025-02-26 21:37:16 UTC"
  },
  {
    "arxiv_id": "2410.22325v2",
    "title": "Robots Pre-train Robots: Manipulation-Centric Robotic Representation from Large-Scale Robot Datasets",
    "authors": [
      "Guangqi Jiang",
      "Yifei Sun",
      "Tao Huang",
      "Huanyu Li",
      "Yongyuan Liang",
      "Huazhe Xu"
    ],
    "abstract": "The pre-training of visual representations has enhanced the efficiency of\nrobot learning. Due to the lack of large-scale in-domain robotic datasets,\nprior works utilize in-the-wild human videos to pre-train robotic visual\nrepresentation. Despite their promising results, representations from human\nvideos are inevitably subject to distribution shifts and lack the dynamics\ninformation crucial for task completion. We first evaluate various pre-trained\nrepresentations in terms of their correlation to the downstream robotic\nmanipulation tasks (i.e., manipulation centricity). Interestingly, we find that\nthe \"manipulation centricity\" is a strong indicator of success rates when\napplied to downstream tasks. Drawing from these findings, we propose\nManipulation Centric Representation (MCR), a foundation representation learning\nframework capturing both visual features and the dynamics information such as\nactions and proprioceptions of manipulation tasks to improve manipulation\ncentricity. Specifically, we pre-train a visual encoder on the DROID robotic\ndataset and leverage motion-relevant data such as robot proprioceptive states\nand actions. We introduce a novel contrastive loss that aligns visual\nobservations with the robot's proprioceptive state-action dynamics, combined\nwith a behavior cloning (BC)-like actor loss to predict actions during\npre-training, along with a time contrastive loss. Empirical results across 4\nsimulation domains with 20 tasks verify that MCR outperforms the strongest\nbaseline method by 14.8%. Moreover, MCR boosts the performance of\ndata-efficient learning with a UR5e arm on 3 real-world tasks by 76.9%. Project\nwebsite: https://robots-pretrain-robots.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22325v2",
    "published_date": "2024-10-29 17:58:13 UTC",
    "updated_date": "2024-10-30 03:33:08 UTC"
  },
  {
    "arxiv_id": "2410.22391v2",
    "title": "A Large Recurrent Action Model: xLSTM enables Fast Inference for Robotics Tasks",
    "authors": [
      "Thomas Schmied",
      "Thomas Adler",
      "Vihang Patil",
      "Maximilian Beck",
      "Korbinian Pppel",
      "Johannes Brandstetter",
      "Gnter Klambauer",
      "Razvan Pascanu",
      "Sepp Hochreiter"
    ],
    "abstract": "In recent years, there has been a trend in the field of Reinforcement\nLearning (RL) towards large action models trained offline on large-scale\ndatasets via sequence modeling. Existing models are primarily based on the\nTransformer architecture, which result in powerful agents. However, due to slow\ninference times, Transformer-based approaches are impractical for real-time\napplications, such as robotics. Recently, modern recurrent architectures, such\nas xLSTM and Mamba, have been proposed that exhibit parallelization benefits\nduring training similar to the Transformer architecture while offering fast\ninference. In this work, we study the aptitude of these modern recurrent\narchitectures for large action models. Consequently, we propose a Large\nRecurrent Action Model (LRAM) with an xLSTM at its core that comes with\nlinear-time inference complexity and natural sequence length extrapolation\nabilities. Experiments on 432 tasks from 6 domains show that LRAM compares\nfavorably to Transformers in terms of performance and speed.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22391v2",
    "published_date": "2024-10-29 17:55:47 UTC",
    "updated_date": "2025-02-20 09:29:58 UTC"
  },
  {
    "arxiv_id": "2411.03336v2",
    "title": "Towards evaluations-based safety cases for AI scheming",
    "authors": [
      "Mikita Balesni",
      "Marius Hobbhahn",
      "David Lindner",
      "Alexander Meinke",
      "Tomek Korbak",
      "Joshua Clymer",
      "Buck Shlegeris",
      "Jrmy Scheurer",
      "Charlotte Stix",
      "Rusheb Shah",
      "Nicholas Goldowsky-Dill",
      "Dan Braun",
      "Bilal Chughtai",
      "Owain Evans",
      "Daniel Kokotajlo",
      "Lucius Bushnaq"
    ],
    "abstract": "We sketch how developers of frontier AI systems could construct a structured\nrationale -- a 'safety case' -- that an AI system is unlikely to cause\ncatastrophic outcomes through scheming. Scheming is a potential threat model\nwhere AI systems could pursue misaligned goals covertly, hiding their true\ncapabilities and objectives. In this report, we propose three arguments that\nsafety cases could use in relation to scheming. For each argument we sketch how\nevidence could be gathered from empirical evaluations, and what assumptions\nwould need to be met to provide strong assurance. First, developers of frontier\nAI systems could argue that AI systems are not capable of scheming (Scheming\nInability). Second, one could argue that AI systems are not capable of posing\nharm through scheming (Harm Inability). Third, one could argue that control\nmeasures around the AI systems would prevent unacceptable outcomes even if the\nAI systems intentionally attempted to subvert them (Harm Control).\nAdditionally, we discuss how safety cases might be supported by evidence that\nan AI system is reasonably aligned with its developers (Alignment). Finally, we\npoint out that many of the assumptions required to make these safety arguments\nhave not been confidently satisfied to date and require making progress on\nmultiple open research problems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03336v2",
    "published_date": "2024-10-29 17:55:29 UTC",
    "updated_date": "2024-11-07 09:18:26 UTC"
  },
  {
    "arxiv_id": "2410.22314v1",
    "title": "An Efficient Approach to Generate Safe Drivable Space by LiDAR-Camera-HDmap Fusion",
    "authors": [
      "Minghao Ning",
      "Ahmad Reza Alghooneh",
      "Chen Sun",
      "Ruihe Zhang",
      "Pouya Panahandeh",
      "Steven Tuer",
      "Ehsan Hashemi",
      "Amir Khajepour"
    ],
    "abstract": "In this paper, we propose an accurate and robust perception module for\nAutonomous Vehicles (AVs) for drivable space extraction. Perception is crucial\nin autonomous driving, where many deep learning-based methods, while accurate\non benchmark datasets, fail to generalize effectively, especially in diverse\nand unpredictable environments. Our work introduces a robust easy-to-generalize\nperception module that leverages LiDAR, camera, and HD map data fusion to\ndeliver a safe and reliable drivable space in all weather conditions. We\npresent an adaptive ground removal and curb detection method integrated with HD\nmap data for enhanced obstacle detection reliability. Additionally, we propose\nan adaptive DBSCAN clustering algorithm optimized for precipitation noise, and\na cost-effective LiDAR-camera frustum association that is resilient to\ncalibration discrepancies. Our comprehensive drivable space representation\nincorporates all perception data, ensuring compatibility with vehicle\ndimensions and road regulations. This approach not only improves generalization\nand efficiency, but also significantly enhances safety in autonomous vehicle\noperations. Our approach is tested on a real dataset and its reliability is\nverified during the daily (including harsh snowy weather) operation of our\nautonomous shuttle, WATonoBus",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22314v1",
    "published_date": "2024-10-29 17:54:02 UTC",
    "updated_date": "2024-10-29 17:54:02 UTC"
  },
  {
    "arxiv_id": "2410.22312v2",
    "title": "Effective Guidance for Model Attention with Simple Yes-no Annotations",
    "authors": [
      "Seongmin Lee",
      "Ali Payani",
      "Duen Horng Chau"
    ],
    "abstract": "Modern deep learning models often make predictions by focusing on irrelevant\nareas, leading to biased performance and limited generalization. Existing\nmethods aimed at rectifying model attention require explicit labels for\nirrelevant areas or complex pixel-wise ground truth attention maps. We present\nCRAYON (Correcting Reasoning with Annotations of Yes Or No), offering\neffective, scalable, and practical solutions to rectify model attention using\nsimple yes-no annotations. CRAYON empowers classical and modern model\ninterpretation techniques to identify and guide model reasoning:\nCRAYON-ATTENTION directs classic interpretations based on saliency maps to\nfocus on relevant image regions, while CRAYON-PRUNING removes irrelevant\nneurons identified by modern concept-based methods to mitigate their influence.\nThrough extensive experiments with both quantitative and human evaluation, we\nshowcase CRAYON's effectiveness, scalability, and practicality in refining\nmodel attention. CRAYON achieves state-of-the-art performance, outperforming 12\nmethods across 3 benchmark datasets, surpassing approaches that require more\ncomplex annotations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 5 figures, IEEE BigData 2024 Paper",
    "pdf_url": "http://arxiv.org/pdf/2410.22312v2",
    "published_date": "2024-10-29 17:53:33 UTC",
    "updated_date": "2024-11-15 22:53:42 UTC"
  },
  {
    "arxiv_id": "2410.22307v1",
    "title": "SVIP: Towards Verifiable Inference of Open-source Large Language Models",
    "authors": [
      "Yifan Sun",
      "Yuhang Li",
      "Yue Zhang",
      "Yuchen Jin",
      "Huan Zhang"
    ],
    "abstract": "Open-source Large Language Models (LLMs) have recently demonstrated\nremarkable capabilities in natural language understanding and generation,\nleading to widespread adoption across various domains. However, their\nincreasing model sizes render local deployment impractical for individual\nusers, pushing many to rely on computing service providers for inference\nthrough a blackbox API. This reliance introduces a new risk: a computing\nprovider may stealthily substitute the requested LLM with a smaller, less\ncapable model without consent from users, thereby delivering inferior outputs\nwhile benefiting from cost savings. In this paper, we formalize the problem of\nverifiable inference for LLMs. Existing verifiable computing solutions based on\ncryptographic or game-theoretic techniques are either computationally\nuneconomical or rest on strong assumptions. We introduce SVIP, a secret-based\nverifiable LLM inference protocol that leverages intermediate outputs from LLM\nas unique model identifiers. By training a proxy task on these outputs and\nrequiring the computing provider to return both the generated text and the\nprocessed intermediate outputs, users can reliably verify whether the computing\nprovider is acting honestly. In addition, the integration of a secret mechanism\nfurther enhances the security of our protocol. We thoroughly analyze our\nprotocol under multiple strong and adaptive adversarial scenarios. Our\nextensive experiments demonstrate that SVIP is accurate, generalizable,\ncomputationally efficient, and resistant to various attacks. Notably, SVIP\nachieves false negative rates below 5% and false positive rates below 3%, while\nrequiring less than 0.01 seconds per query for verification.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.22307v1",
    "published_date": "2024-10-29 17:52:45 UTC",
    "updated_date": "2024-10-29 17:52:45 UTC"
  },
  {
    "arxiv_id": "2410.22303v1",
    "title": "$\\mathsf{OPA}$: One-shot Private Aggregation with Single Client Interaction and its Applications to Federated Learning",
    "authors": [
      "Harish Karthikeyan",
      "Antigoni Polychroniadou"
    ],
    "abstract": "Our work aims to minimize interaction in secure computation due to the high\ncost and challenges associated with communication rounds, particularly in\nscenarios with many clients. In this work, we revisit the problem of secure\naggregation in the single-server setting where a single evaluation server can\nsecurely aggregate client-held individual inputs. Our key contribution is the\nintroduction of One-shot Private Aggregation ($\\mathsf{OPA}$) where clients\nspeak only once (or even choose not to speak) per aggregation evaluation. Since\neach client communicates only once per aggregation, this simplifies managing\ndropouts and dynamic participation, contrasting with multi-round protocols and\naligning with plaintext secure aggregation, where clients interact only once.\nWe construct $\\mathsf{OPA}$ based on LWR, LWE, class groups, DCR and\ndemonstrate applications to privacy-preserving Federated Learning (FL) where\nclients \\emph{speak once}. This is a sharp departure from prior multi-round FL\nprotocols whose study was initiated by Bonawitz et al. (CCS, 2017). Moreover,\nunlike the YOSO (You Only Speak Once) model for general secure computation,\n$\\mathsf{OPA}$ eliminates complex committee selection protocols to achieve\nadaptive security. Beyond asymptotic improvements, $\\mathsf{OPA}$ is practical,\noutperforming state-of-the-art solutions. We benchmark logistic regression\nclassifiers for two datasets, while also building an MLP classifier to train on\nMNIST, CIFAR-10, and CIFAR-100 datasets. We build two flavors of $\\caps$ (1)\nfrom (threshold) key homomorphic PRF and (2) from seed homomorphic PRG and\nsecret sharing.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "D.4.6; I.2.11; E.3; K.4.1; I.2"
    ],
    "primary_category": "cs.CR",
    "comment": "To appear at the NeurIPS 2024 FL@FM workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.22303v1",
    "published_date": "2024-10-29 17:50:11 UTC",
    "updated_date": "2024-10-29 17:50:11 UTC"
  },
  {
    "arxiv_id": "2410.22285v1",
    "title": "From melodic note sequences to pitches using word2vec",
    "authors": [
      "Daniel Defays"
    ],
    "abstract": "Applying the word2vec technique, commonly used in language modeling, to\nmelodies, where notes are treated as words in sentences, enables the capture of\npitch information. This study examines two datasets: 20 children's songs and an\nexcerpt from a Bach sonata. The semantic space for defining the embeddings is\nof very small dimension, specifically 2. Notes are predicted based on the 2, 3\nor 4 preceding notes that establish the context. A multivariate analysis of the\nresults shows that the semantic vectors representing the notes have a multiple\ncorrelation coefficient of approximately 0.80 with their pitches.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.22285v1",
    "published_date": "2024-10-29 17:38:27 UTC",
    "updated_date": "2024-10-29 17:38:27 UTC"
  },
  {
    "arxiv_id": "2410.22390v1",
    "title": "FNDEX: Fake News and Doxxing Detection with Explainable AI",
    "authors": [
      "Dorsaf Sallami",
      "Esma Ameur"
    ],
    "abstract": "The widespread and diverse online media platforms and other internet-driven\ncommunication technologies have presented significant challenges in defining\nthe boundaries of freedom of expression. Consequently, the internet has been\ntransformed into a potential cyber weapon. Within this evolving landscape, two\nparticularly hazardous phenomena have emerged: fake news and doxxing. Although\nthese threats have been subjects of extensive scholarly analysis, the\ncrossroads where they intersect remain unexplored. This research addresses this\nconvergence by introducing a novel system. The Fake News and Doxxing Detection\nwith Explainable Artificial Intelligence (FNDEX) system leverages the\ncapabilities of three distinct transformer models to achieve high-performance\ndetection for both fake news and doxxing. To enhance data security, a rigorous\nthree-step anonymization process is employed, rooted in a pattern-based\napproach for anonymizing personally identifiable information. Finally, this\nresearch emphasizes the importance of generating coherent explanations for the\noutcomes produced by both detection models. Our experiments on realistic\ndatasets demonstrate that our system significantly outperforms the existing\nbaselines",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22390v1",
    "published_date": "2024-10-29 17:29:45 UTC",
    "updated_date": "2024-10-29 17:29:45 UTC"
  },
  {
    "arxiv_id": "2411.00836v2",
    "title": "DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models",
    "authors": [
      "Chengke Zou",
      "Xingang Guo",
      "Rui Yang",
      "Junyu Zhang",
      "Bin Hu",
      "Huan Zhang"
    ],
    "abstract": "The rapid advancements in Vision-Language Models (VLMs) have shown great\npotential in tackling mathematical reasoning tasks that involve visual context.\nUnlike humans who can reliably apply solution steps to similar problems with\nminor modifications, we found that SOTA VLMs like GPT-4o can consistently fail\nin these scenarios, revealing limitations in their mathematical reasoning\ncapabilities. In this paper, we investigate the mathematical reasoning\nrobustness in VLMs and evaluate how well these models perform under different\nvariants of the same question, such as changes in visual numerical values or\nfunction graphs. While several vision-based math benchmarks have been developed\nto assess VLMs' problem-solving capabilities, these benchmarks contain only\nstatic sets of problems and cannot easily evaluate mathematical reasoning\nrobustness. To fill this gap, we introduce DynaMath, a dynamic visual math\nbenchmark designed for in-depth assessment of VLMs. DynaMath includes 501\nhigh-quality, multi-topic seed questions, each represented as a Python program.\nThose programs are carefully designed and annotated to enable the automatic\ngeneration of a much larger set of concrete questions, including many different\ntypes of visual and textual variations. DynaMath allows us to evaluate the\ngeneralization ability of VLMs, by assessing their performance under varying\ninput conditions of a seed question. We evaluated 14 SOTA VLMs with 5,010\ngenerated concrete questions. Our results show that the worst-case model\naccuracy, defined as the percentage of correctly answered seed questions in all\n10 variants, is significantly lower than the average-case accuracy. Our\nanalysis emphasizes the need to study the robustness of VLMs' reasoning\nabilities, and DynaMath provides valuable insights to guide the development of\nmore reliable models for mathematical reasoning.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.00836v2",
    "published_date": "2024-10-29 17:29:19 UTC",
    "updated_date": "2025-02-24 06:55:22 UTC"
  },
  {
    "arxiv_id": "2410.22271v1",
    "title": "Leveraging Reverberation and Visual Depth Cues for Sound Event Localization and Detection with Distance Estimation",
    "authors": [
      "Davide Berghi",
      "Philip J. B. Jackson"
    ],
    "abstract": "This report describes our systems submitted for the DCASE2024 Task 3\nchallenge: Audio and Audiovisual Sound Event Localization and Detection with\nSource Distance Estimation (Track B). Our main model is based on the\naudio-visual (AV) Conformer, which processes video and audio embeddings\nextracted with ResNet50 and with an audio encoder pre-trained on SELD,\nrespectively. This model outperformed the audio-visual baseline of the\ndevelopment set of the STARSS23 dataset by a wide margin, halving its DOAE and\nimproving the F1 by more than 3x. Our second system performs a temporal\nensemble from the outputs of the AV-Conformer. We then extended the model with\nfeatures for distance estimation, such as direct and reverberant signal\ncomponents extracted from the omnidirectional audio channel, and depth maps\nextracted from the video frames. While the new system improved the RDE of our\nprevious model by about 3 percentage points, it achieved a lower F1 score. This\nmay be caused by sound classes that rarely appear in the training set and that\nthe more complex system does not detect, as analysis can determine. To overcome\nthis problem, our fourth and final system consists of an ensemble strategy\ncombining the predictions of the other three. Many opportunities to refine the\nsystem and training strategy can be tested in future ablation experiments, and\nlikely achieve incremental performance gains for this audio-visual task.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22271v1",
    "published_date": "2024-10-29 17:28:43 UTC",
    "updated_date": "2024-10-29 17:28:43 UTC"
  },
  {
    "arxiv_id": "2410.22269v2",
    "title": "Fourier Head: Helping Large Language Models Learn Complex Probability Distributions",
    "authors": [
      "Nate Gillman",
      "Daksh Aggarwal",
      "Michael Freeman",
      "Saurabh Singh",
      "Chen Sun"
    ],
    "abstract": "As the quality of large language models has improved, there has been\nincreased interest in using them to model non-linguistic tokens. For example,\nthe Decision Transformer recasts agentic decision making as a sequence modeling\nproblem, using a decoder-only LLM to model the distribution over the discrete\naction space for an Atari agent. However, when adapting LLMs to non-linguistic\ndomains, it remains unclear if softmax over discrete bins captures the\ncontinuous structure of the tokens and the potentially complex distributions\nneeded for high quality token generation. We introduce a neural network layer,\nconstructed using Fourier series, which we can easily substitute for any linear\nlayer if we want the outputs to have a more continuous structure. We perform\nextensive analysis on synthetic datasets, as well as on large-scale decision\nmaking and time series forecasting tasks. We also provide theoretical evidence\nthat this layer can better learn signal from data while ignoring high-frequency\nnoise. All of our results support the effectiveness of our proposed Fourier\nhead in scenarios where the underlying data distribution has a natural\ncontinuous structure. For example, the Fourier head improves a Decision\nTransformer agent's returns across four benchmark Atari games by as much as\n377%, and increases a state-of-the-art times series foundation model's\nforecasting performance by 3.5% across 20 benchmarks unseen during training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Camera ready version (ICLR 2025). Code at\n  https://nategillman.com/fourier-head",
    "pdf_url": "http://arxiv.org/pdf/2410.22269v2",
    "published_date": "2024-10-29 17:27:58 UTC",
    "updated_date": "2025-03-10 23:59:12 UTC"
  },
  {
    "arxiv_id": "2410.22233v3",
    "title": "ContextIQ: A Multimodal Expert-Based Video Retrieval System for Contextual Advertising",
    "authors": [
      "Ashutosh Chaubey",
      "Anoubhav Agarwaal",
      "Sartaki Sinha Roy",
      "Aayush Agrawal",
      "Susmita Ghose"
    ],
    "abstract": "Contextual advertising serves ads that are aligned to the content that the\nuser is viewing. The rapid growth of video content on social platforms and\nstreaming services, along with privacy concerns, has increased the need for\ncontextual advertising. Placing the right ad in the right context creates a\nseamless and pleasant ad viewing experience, resulting in higher audience\nengagement and, ultimately, better ad monetization. From a technology\nstandpoint, effective contextual advertising requires a video retrieval system\ncapable of understanding complex video content at a very granular level.\nCurrent text-to-video retrieval models based on joint multimodal training\ndemand large datasets and computational resources, limiting their practicality\nand lacking the key functionalities required for ad ecosystem integration. We\nintroduce ContextIQ, a multimodal expert-based video retrieval system designed\nspecifically for contextual advertising. ContextIQ utilizes modality-specific\nexperts-video, audio, transcript (captions), and metadata such as objects,\nactions, emotion, etc.-to create semantically rich video representations. We\nshow that our system, without joint training, achieves better or comparable\nresults to state-of-the-art models and commercial solutions on multiple\ntext-to-video retrieval benchmarks. Our ablation studies highlight the benefits\nof leveraging multiple modalities for enhanced video retrieval accuracy instead\nof using a vision-language model alone. Furthermore, we show how video\nretrieval systems such as ContextIQ can be used for contextual advertising in\nan ad ecosystem while also addressing concerns related to brand safety and\nfiltering inappropriate content.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.22233v3",
    "published_date": "2024-10-29 17:01:05 UTC",
    "updated_date": "2025-03-29 17:42:02 UTC"
  },
  {
    "arxiv_id": "2411.08910v1",
    "title": "Automated Feedback in Math Education: A Comparative Analysis of LLMs for Open-Ended Responses",
    "authors": [
      "Sami Baral",
      "Eamon Worden",
      "Wen-Chiang Lim",
      "Zhuang Luo",
      "Christopher Santorelli",
      "Ashish Gurung",
      "Neil Heffernan"
    ],
    "abstract": "The effectiveness of feedback in enhancing learning outcomes is well\ndocumented within Educational Data Mining (EDM). Various prior research has\nexplored methodologies to enhance the effectiveness of feedback. Recent\ndevelopments in Large Language Models (LLMs) have extended their utility in\nenhancing automated feedback systems. This study aims to explore the potential\nof LLMs in facilitating automated feedback in math education. We examine the\neffectiveness of LLMs in evaluating student responses by comparing 3 different\nmodels: Llama, SBERT-Canberra, and GPT4 model. The evaluation requires the\nmodel to provide both a quantitative score and qualitative feedback on the\nstudent's responses to open-ended math problems. We employ Mistral, a version\nof Llama catered to math, and fine-tune this model for evaluating student\nresponses by leveraging a dataset of student responses and teacher-written\nfeedback for middle-school math problems. A similar approach was taken for\ntraining the SBERT model as well, while the GPT4 model used a zero-shot\nlearning approach. We evaluate the model's performance in scoring accuracy and\nthe quality of feedback by utilizing judgments from 2 teachers. The teachers\nutilized a shared rubric in assessing the accuracy and relevance of the\ngenerated feedback. We conduct both quantitative and qualitative analyses of\nthe model performance. By offering a detailed comparison of these methods, this\nstudy aims to further the ongoing development of automated feedback systems and\noutlines potential future directions for leveraging generative LLMs to create\nmore personalized learning experiences.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "12 pages including references, 4 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.08910v1",
    "published_date": "2024-10-29 16:57:45 UTC",
    "updated_date": "2024-10-29 16:57:45 UTC"
  },
  {
    "arxiv_id": "2410.22223v1",
    "title": "MAPUNetR: A Hybrid Vision Transformer and U-Net Architecture for Efficient and Interpretable Medical Image Segmentation",
    "authors": [
      "Ovais Iqbal Shah",
      "Danish Raza Rizvi",
      "Aqib Nazir Mir"
    ],
    "abstract": "Medical image segmentation is pivotal in healthcare, enhancing diagnostic\naccuracy, informing treatment strategies, and tracking disease progression.\nThis process allows clinicians to extract critical information from visual\ndata, enabling personalized patient care. However, developing neural networks\nfor segmentation remains challenging, especially when preserving image\nresolution, which is essential in detecting subtle details that influence\ndiagnoses. Moreover, the lack of transparency in these deep learning models has\nslowed their adoption in clinical practice. Efforts in model interpretability\nare increasingly focused on making these models' decision-making processes more\ntransparent. In this paper, we introduce MAPUNetR, a novel architecture that\nsynergizes the strengths of transformer models with the proven U-Net framework\nfor medical image segmentation. Our model addresses the resolution preservation\nchallenge and incorporates attention maps highlighting segmented regions,\nincreasing accuracy and interpretability. Evaluated on the BraTS 2020 dataset,\nMAPUNetR achieved a dice score of 0.88 and a dice coefficient of 0.92 on the\nISIC 2018 dataset. Our experiments show that the model maintains stable\nperformance and potential as a powerful tool for medical image segmentation in\nclinical practice.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22223v1",
    "published_date": "2024-10-29 16:52:57 UTC",
    "updated_date": "2024-10-29 16:52:57 UTC"
  },
  {
    "arxiv_id": "2410.22209v5",
    "title": "A Methodology for Incompleteness-Tolerant and Modular Gradual Semantics for Argumentative Statement Graphs",
    "authors": [
      "Antonio Rago",
      "Stylianos Loukas Vasileiou",
      "Francesca Toni",
      "Tran Cao Son",
      "William Yeoh"
    ],
    "abstract": "Gradual semantics (GS) have demonstrated great potential in argumentation, in\nparticular for deploying quantitative bipolar argumentation frameworks (QBAFs)\nin a number of real-world settings, from judgmental forecasting to explainable\nAI. In this paper, we provide a novel methodology for obtaining GS for\nstatement graphs, a form of structured argumentation framework, where arguments\nand relations between them are built from logical statements. Our methodology\ndiffers from existing approaches in the literature in two main ways. First, it\nnaturally accommodates incomplete information, so that arguments with partially\nspecified premises can play a meaningful role in the evaluation. Second, it is\nmodularly defined to leverage on any GS for QBAFs. We also define a set of\nnovel properties for our GS and study their suitability alongside a set of\nexisting properties (adapted to our setting) for two instantiations of our GS,\ndemonstrating their advantages over existing approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22209v5",
    "published_date": "2024-10-29 16:38:35 UTC",
    "updated_date": "2025-01-30 15:29:39 UTC"
  },
  {
    "arxiv_id": "2410.22208v1",
    "title": "Drone Acoustic Analysis for Predicting Psychoacoustic Annoyance via Artificial Neural Networks",
    "authors": [
      "Andrea Vaiuso",
      "Marcello Righi",
      "Oier Coretti",
      "Moreno Apicella"
    ],
    "abstract": "Unmanned Aerial Vehicles (UAVs) have become widely used in various fields and\nindustrial applications thanks to their low operational cost, compact size and\nwide accessibility. However, the noise generated by drone propellers has\nemerged as a significant concern. This may affect the public willingness to\nimplement these vehicles in services that require operation in proximity to\nresidential areas. The standard approaches to address this challenge include\nsound pressure measurements and noise characteristic analyses. The integration\nof Artificial Intelligence models in recent years has further streamlined the\nprocess by enhancing complex feature detection in drone acoustics data. This\nstudy builds upon prior research by examining the efficacy of various Deep\nLearning models in predicting Psychoacoustic Annoyance, an effective index for\nmeasuring perceived annoyance by human ears, based on multiple drone\ncharacteristics as input. This is accomplished by constructing a training\ndataset using precise measurements of various drone models with multiple\nmicrophones and analyzing flight data, maneuvers, drone physical\ncharacteristics, and perceived annoyance under realistic conditions. The aim of\nthis research is to improve our understanding of drone noise, aid in the\ndevelopment of noise reduction techniques, and encourage the acceptance of\ndrone usage on public spaces.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "20 Pages, 10 Figures, 4 Tables",
    "pdf_url": "http://arxiv.org/pdf/2410.22208v1",
    "published_date": "2024-10-29 16:38:34 UTC",
    "updated_date": "2024-10-29 16:38:34 UTC"
  },
  {
    "arxiv_id": "2410.22203v1",
    "title": "Democratizing Reward Design for Personal and Representative Value-Alignment",
    "authors": [
      "Carter Blair",
      "Kate Larson",
      "Edith Law"
    ],
    "abstract": "Aligning AI agents with human values is challenging due to diverse and\nsubjective notions of values. Standard alignment methods often aggregate crowd\nfeedback, which can result in the suppression of unique or minority\npreferences. We introduce Interactive-Reflective Dialogue Alignment, a method\nthat iteratively engages users in reflecting on and specifying their subjective\nvalue definitions. This system learns individual value definitions through\nlanguage-model-based preference elicitation and constructs personalized reward\nmodels that can be used to align AI behaviour. We evaluated our system through\ntwo studies with 30 participants, one focusing on \"respect\" and the other on\nethical decision-making in autonomous vehicles. Our findings demonstrate\ndiverse definitions of value-aligned behaviour and show that our system can\naccurately capture each person's unique understanding. This approach enables\npersonalized alignment and can inform more representative and interpretable\ncollective alignment strategies.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.22203v1",
    "published_date": "2024-10-29 16:37:01 UTC",
    "updated_date": "2024-10-29 16:37:01 UTC"
  },
  {
    "arxiv_id": "2410.22194v1",
    "title": "ADAM: An Embodied Causal Agent in Open-World Environments",
    "authors": [
      "Shu Yu",
      "Chaochao Lu"
    ],
    "abstract": "In open-world environments like Minecraft, existing agents face challenges in\ncontinuously learning structured knowledge, particularly causality. These\nchallenges stem from the opacity inherent in black-box models and an excessive\nreliance on prior knowledge during training, which impair their\ninterpretability and generalization capability. To this end, we introduce ADAM,\nAn emboDied causal Agent in Minecraft, that can autonomously navigate the open\nworld, perceive multimodal contexts, learn causal world knowledge, and tackle\ncomplex tasks through lifelong learning. ADAM is empowered by four key\ncomponents: 1) an interaction module, enabling the agent to execute actions\nwhile documenting the interaction processes; 2) a causal model module, tasked\nwith constructing an ever-growing causal graph from scratch, which enhances\ninterpretability and diminishes reliance on prior knowledge; 3) a controller\nmodule, comprising a planner, an actor, and a memory pool, which uses the\nlearned causal graph to accomplish tasks; 4) a perception module, powered by\nmultimodal large language models, which enables ADAM to perceive like a human\nplayer. Extensive experiments show that ADAM constructs an almost perfect\ncausal graph from scratch, enabling efficient task decomposition and execution\nwith strong interpretability. Notably, in our modified Minecraft games where no\nprior knowledge is available, ADAM maintains its performance and shows\nremarkable robustness and generalization capability. ADAM pioneers a novel\nparadigm that integrates causal methods and embodied agents in a synergistic\nmanner. Our project page is at https://opencausalab.github.io/ADAM.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22194v1",
    "published_date": "2024-10-29 16:32:01 UTC",
    "updated_date": "2024-10-29 16:32:01 UTC"
  },
  {
    "arxiv_id": "2410.22184v1",
    "title": "Multi-Level Feature Distillation of Joint Teachers Trained on Distinct Image Datasets",
    "authors": [
      "Adrian Iordache",
      "Bogdan Alexe",
      "Radu Tudor Ionescu"
    ],
    "abstract": "We propose a novel teacher-student framework to distill knowledge from\nmultiple teachers trained on distinct datasets. Each teacher is first trained\nfrom scratch on its own dataset. Then, the teachers are combined into a joint\narchitecture, which fuses the features of all teachers at multiple\nrepresentation levels. The joint teacher architecture is fine-tuned on samples\nfrom all datasets, thus gathering useful generic information from all data\nsamples. Finally, we employ a multi-level feature distillation procedure to\ntransfer the knowledge to a student model for each of the considered datasets.\nWe conduct image classification experiments on seven benchmarks, and action\nrecognition experiments on three benchmarks. To illustrate the power of our\nfeature distillation procedure, the student architectures are chosen to be\nidentical to those of the individual teachers. To demonstrate the flexibility\nof our approach, we combine teachers with distinct architectures. We show that\nour novel Multi-Level Feature Distillation (MLFD) can significantly surpass\nequivalent architectures that are either trained on individual datasets, or\njointly trained on all datasets at once. Furthermore, we confirm that each step\nof the proposed training procedure is well motivated by a comprehensive\nablation study. We publicly release our code at\nhttps://github.com/AdrianIordache/MLFD.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.22184v1",
    "published_date": "2024-10-29 16:23:20 UTC",
    "updated_date": "2024-10-29 16:23:20 UTC"
  },
  {
    "arxiv_id": "2410.22180v1",
    "title": "Natural Language Processing for Analyzing Electronic Health Records and Clinical Notes in Cancer Research: A Review",
    "authors": [
      "Muhammad Bilal",
      "Ameer Hamza",
      "Nadia Malik"
    ],
    "abstract": "Objective: This review aims to analyze the application of natural language\nprocessing (NLP) techniques in cancer research using electronic health records\n(EHRs) and clinical notes. This review addresses gaps in the existing\nliterature by providing a broader perspective than previous studies focused on\nspecific cancer types or applications. Methods: A comprehensive literature\nsearch was conducted using the Scopus database, identifying 94 relevant studies\npublished between 2019 and 2024. Data extraction included study\ncharacteristics, cancer types, NLP methodologies, dataset information,\nperformance metrics, challenges, and future directions. Studies were\ncategorized based on cancer types and NLP applications. Results: The results\nshowed a growing trend in NLP applications for cancer research, with breast,\nlung, and colorectal cancers being the most studied. Information extraction and\ntext classification emerged as predominant NLP tasks. A shift from rule-based\nto advanced machine learning techniques, particularly transformer-based models,\nwas observed. The Dataset sizes used in existing studies varied widely. Key\nchallenges included the limited generalizability of proposed solutions and the\nneed for improved integration into clinical workflows. Conclusion: NLP\ntechniques show significant potential in analyzing EHRs and clinical notes for\ncancer research. However, future work should focus on improving model\ngeneralizability, enhancing robustness in handling complex clinical language,\nand expanding applications to understudied cancer types. Integration of NLP\ntools into clinical practice and addressing ethical considerations remain\ncrucial for utilizing the full potential of NLP in enhancing cancer diagnosis,\ntreatment, and patient outcomes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22180v1",
    "published_date": "2024-10-29 16:17:07 UTC",
    "updated_date": "2024-10-29 16:17:07 UTC"
  },
  {
    "arxiv_id": "2410.22177v1",
    "title": "Analyzing Multimodal Interaction Strategies for LLM-Assisted Manipulation of 3D Scenes",
    "authors": [
      "Junlong Chen",
      "Jens Grubert",
      "Per Ola Kristensson"
    ],
    "abstract": "As more applications of large language models (LLMs) for 3D content for\nimmersive environments emerge, it is crucial to study user behaviour to\nidentify interaction patterns and potential barriers to guide the future design\nof immersive content creation and editing systems which involve LLMs. In an\nempirical user study with 12 participants, we combine quantitative usage data\nwith post-experience questionnaire feedback to reveal common interaction\npatterns and key barriers in LLM-assisted 3D scene editing systems. We identify\nopportunities for improving natural language interfaces in 3D design tools and\npropose design recommendations for future LLM-integrated 3D content creation\nsystems. Through an empirical study, we demonstrate that LLM-assisted\ninteractive systems can be used productively in immersive environments.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2410.22177v1",
    "published_date": "2024-10-29 16:15:59 UTC",
    "updated_date": "2024-10-29 16:15:59 UTC"
  },
  {
    "arxiv_id": "2410.22151v1",
    "title": "Standardization Trends on Safety and Trustworthiness Technology for Advanced AI",
    "authors": [
      "Jonghong Jeon"
    ],
    "abstract": "Artificial Intelligence (AI) has rapidly evolved over the past decade and has\nadvanced in areas such as language comprehension, image and video recognition,\nprogramming, and scientific reasoning. Recent AI technologies based on large\nlanguage models and foundation models are approaching or surpassing artificial\ngeneral intelligence. These systems demonstrate superior performance in complex\nproblem solving, natural language processing, and multi-domain tasks, and can\npotentially transform fields such as science, industry, healthcare, and\neducation. However, these advancements have raised concerns regarding the\nsafety and trustworthiness of advanced AI, including risks related to\nuncontrollability, ethical conflicts, long-term socioeconomic impacts, and\nsafety assurance. Efforts are being expended to develop internationally\nagreed-upon standards to ensure the safety and reliability of AI. This study\nanalyzes international trends in safety and trustworthiness standardization for\nadvanced AI, identifies key areas for standardization, proposes future\ndirections and strategies, and draws policy implications. The goal is to\nsupport the safe and trustworthy development of advanced AI and enhance\ninternational competitiveness through effective standardization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 2 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.22151v1",
    "published_date": "2024-10-29 15:50:24 UTC",
    "updated_date": "2024-10-29 15:50:24 UTC"
  },
  {
    "arxiv_id": "2410.22134v2",
    "title": "ProMoE: Fast MoE-based LLM Serving using Proactive Caching",
    "authors": [
      "Xiaoniu Song",
      "Zihang Zhong",
      "Rong Chen",
      "Haibo Chen"
    ],
    "abstract": "The promising applications of large language models are often limited by the\nconstrained GPU memory capacity available on edge devices. Mixture-of-Experts\n(MoE) models help address this issue by activating only a subset of the model's\nparameters during computation. This approach allows the unused parameters to be\noffloaded to host memory, thereby reducing the overall GPU memory demand.\nHowever, existing cache-based offloading solutions handle cache misses\nreactively, which significantly impacts system performance. In this paper, we\nintroduce ProMoE, a novel proactive caching system that utilizes intermediate\nresults to predict subsequent expert usage. By proactively fetching experts in\nadvance, ProMoE eliminates passive cache misses, removes loading time from the\ncritical path, and reduces the performance overhead associated with offloading.\nOur evaluations demonstrate that ProMoE achieves an average speedup of 2.20x\n(up to 3.21x) and 2.07x (up to 5.02x) in the prefill and decode stages,\nrespectively, compared to existing offloading solutions.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22134v2",
    "published_date": "2024-10-29 15:31:27 UTC",
    "updated_date": "2025-02-08 14:11:25 UTC"
  },
  {
    "arxiv_id": "2410.22135v2",
    "title": "Lightweight Frequency Masker for Cross-Domain Few-Shot Semantic Segmentation",
    "authors": [
      "Jintao Tong",
      "Yixiong Zou",
      "Yuhua Li",
      "Ruixuan Li"
    ],
    "abstract": "Cross-domain few-shot segmentation (CD-FSS) is proposed to first pre-train\nthe model on a large-scale source-domain dataset, and then transfer the model\nto data-scarce target-domain datasets for pixel-level segmentation. The\nsignificant domain gap between the source and target datasets leads to a sharp\ndecline in the performance of existing few-shot segmentation (FSS) methods in\ncross-domain scenarios. In this work, we discover an intriguing phenomenon:\nsimply filtering different frequency components for target domains can lead to\na significant performance improvement, sometimes even as high as 14% mIoU.\nThen, we delve into this phenomenon for an interpretation, and find such\nimprovements stem from the reduced inter-channel correlation in feature maps,\nwhich benefits CD-FSS with enhanced robustness against domain gaps and larger\nactivated regions for segmentation. Based on this, we propose a lightweight\nfrequency masker, which further reduces channel correlations by an\nAmplitude-Phase Masker (APM) module and an Adaptive Channel Phase Attention\n(ACPA) module. Notably, APM introduces only 0.01% additional parameters but\nimproves the average performance by over 10%, and ACPA imports only 2.5%\nparameters but further improves the performance by over 1.5%, which\nsignificantly surpasses the state-of-the-art CD-FSS methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.22135v2",
    "published_date": "2024-10-29 15:31:27 UTC",
    "updated_date": "2024-11-22 06:41:07 UTC"
  },
  {
    "arxiv_id": "2410.22130v2",
    "title": "Solving Epistemic Logic Programs using Generate-and-Test with Propagation",
    "authors": [
      "Jorge Fandinno",
      "Lute Lillo"
    ],
    "abstract": "This paper introduces a general framework for generate-and-test-based solvers\nfor epistemic logic programs that can be instantiated with different generator\nand tester programs, and we prove sufficient conditions on those programs for\nthe correctness of the solvers built using this framework. It also introduces a\nnew generator program that incorporates the propagation of epistemic\nconsequences and shows that this can exponentially reduce the number of\ncandidates that need to be tested while only incurring a linear overhead. We\nimplement a new solver based on these theoretical findings and experimentally\nshow that it outperforms existing solvers by achieving a ~3.3x speed-up and\nsolving 91% more instances on well-known benchmarks.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for publication in the Proceedings of the 39th Annual AAAI\n  Conference on Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2410.22130v2",
    "published_date": "2024-10-29 15:28:40 UTC",
    "updated_date": "2024-12-13 16:05:14 UTC"
  },
  {
    "arxiv_id": "2410.22129v1",
    "title": "Improving Performance of Commercially Available AI Products in a Multi-Agent Configuration",
    "authors": [
      "Cory Hymel",
      "Sida Peng",
      "Kevin Xu",
      "Charath Ranganathan"
    ],
    "abstract": "In recent years, with the rapid advancement of large language models (LLMs),\nmulti-agent systems have become increasingly more capable of practical\napplication. At the same time, the software development industry has had a\nnumber of new AI-powered tools developed that improve the software development\nlifecycle (SDLC). Academically, much attention has been paid to the role of\nmulti-agent systems to the SDLC. And, while single-agent systems have\nfrequently been examined in real-world applications, we have seen comparatively\nfew real-world examples of publicly available commercial tools working together\nin a multi-agent system with measurable improvements. In this experiment we\ntest context sharing between Crowdbotics PRD AI, a tool for generating software\nrequirements using AI, and GitHub Copilot, an AI pair-programming tool. By\nsharing business requirements from PRD AI, we improve the code suggestion\ncapabilities of GitHub Copilot by 13.8% and developer task success rate by\n24.5% -- demonstrating a real-world example of commercially-available AI\nsystems working together with improved outcomes.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "7 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.22129v1",
    "published_date": "2024-10-29 15:28:19 UTC",
    "updated_date": "2024-10-29 15:28:19 UTC"
  },
  {
    "arxiv_id": "2410.22120v1",
    "title": "Vision Paper: Designing Graph Neural Networks in Compliance with the European Artificial Intelligence Act",
    "authors": [
      "Barbara Hoffmann",
      "Jana Vatter",
      "Ruben Mayer"
    ],
    "abstract": "The European Union's Artificial Intelligence Act (AI Act) introduces\ncomprehensive guidelines for the development and oversight of Artificial\nIntelligence (AI) and Machine Learning (ML) systems, with significant\nimplications for Graph Neural Networks (GNNs). This paper addresses the unique\nchallenges posed by the AI Act for GNNs, which operate on complex\ngraph-structured data. The legislation's requirements for data management, data\ngovernance, robustness, human oversight, and privacy necessitate tailored\nstrategies for GNNs. Our study explores the impact of these requirements on GNN\ntraining and proposes methods to ensure compliance. We provide an in-depth\nanalysis of bias, robustness, explainability, and privacy in the context of\nGNNs, highlighting the need for fair sampling strategies and effective\ninterpretability techniques. Our contributions fill the research gap by\noffering specific guidance for GNNs under the new legislative framework and\nidentifying open questions and future research directions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22120v1",
    "published_date": "2024-10-29 15:22:45 UTC",
    "updated_date": "2024-10-29 15:22:45 UTC"
  },
  {
    "arxiv_id": "2410.22118v2",
    "title": "The Impact of Inference Acceleration on Bias of LLMs",
    "authors": [
      "Elisabeth Kirsten",
      "Ivan Habernal",
      "Vedant Nanda",
      "Muhammad Bilal Zafar"
    ],
    "abstract": "Last few years have seen unprecedented advances in capabilities of Large\nLanguage Models (LLMs). These advancements promise to benefit a vast array of\napplication domains. However, due to their immense size, performing inference\nwith LLMs is both costly and slow. Consequently, a plethora of recent work has\nproposed strategies to enhance inference efficiency, e.g., quantization,\npruning, and caching. These acceleration strategies reduce the inference cost\nand latency, often by several factors, while maintaining much of the predictive\nperformance measured via common benchmarks. In this work, we explore another\ncritical aspect of LLM performance: demographic bias in model generations due\nto inference acceleration optimizations. Using a wide range of metrics, we\nprobe bias in model outputs from a number of angles. Analysis of outputs before\nand after inference acceleration shows significant change in bias. Worryingly,\nthese bias effects are complex and unpredictable. A combination of an\nacceleration strategy and bias type may show little bias change in one model\nbut may lead to a large effect in another. Our results highlight a need for\nin-depth and case-by-case evaluation of model bias after it has been modified\nto accelerate inference.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22118v2",
    "published_date": "2024-10-29 15:19:13 UTC",
    "updated_date": "2025-02-19 11:10:09 UTC"
  },
  {
    "arxiv_id": "2410.22114v2",
    "title": "Policy Gradient for Robust Markov Decision Processes",
    "authors": [
      "Qiuhao Wang",
      "Shaohang Xu",
      "Chin Pang Ho",
      "Marek Petrik"
    ],
    "abstract": "We develop a generic policy gradient method with the global optimality\nguarantee for robust Markov Decision Processes (MDPs). While policy gradient\nmethods are widely used for solving dynamic decision problems due to their\nscalable and efficient nature, adapting these methods to account for model\nambiguity has been challenging, often making it impractical to learn robust\npolicies. This paper introduces a novel policy gradient method, Double-Loop\nRobust Policy Mirror Descent (DRPMD), for solving robust MDPs. DRPMD employs a\ngeneral mirror descent update rule for the policy optimization with adaptive\ntolerance per iteration, guaranteeing convergence to a globally optimal policy.\nWe provide a comprehensive analysis of DRPMD, including new convergence results\nunder both direct and softmax parameterizations, and provide novel insights\ninto the inner problem solution through Transition Mirror Ascent (TMA).\nAdditionally, we propose innovative parametric transition kernels for both\ndiscrete and continuous state-action spaces, broadening the applicability of\nour approach. Empirical results validate the robustness and global convergence\nof DRPMD across various challenging robust MDP settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22114v2",
    "published_date": "2024-10-29 15:16:02 UTC",
    "updated_date": "2024-10-31 15:34:35 UTC"
  },
  {
    "arxiv_id": "2410.22108v2",
    "title": "Protecting Privacy in Multimodal Large Language Models with MLLMU-Bench",
    "authors": [
      "Zheyuan Liu",
      "Guangyao Dou",
      "Mengzhao Jia",
      "Zhaoxuan Tan",
      "Qingkai Zeng",
      "Yongle Yuan",
      "Meng Jiang"
    ],
    "abstract": "Generative models such as Large Language Models (LLM) and Multimodal Large\nLanguage models (MLLMs) trained on massive web corpora can memorize and\ndisclose individuals' confidential and private data, raising legal and ethical\nconcerns. While many previous works have addressed this issue in LLM via\nmachine unlearning, it remains largely unexplored for MLLMs. To tackle this\nchallenge, we introduce Multimodal Large Language Model Unlearning Benchmark\n(MLLMU-Bench), a novel benchmark aimed at advancing the understanding of\nmultimodal machine unlearning. MLLMU-Bench consists of 500 fictitious profiles\nand 153 profiles for public celebrities, each profile feature over 14\ncustomized question-answer pairs, evaluated from both multimodal (image+text)\nand unimodal (text) perspectives. The benchmark is divided into four sets to\nassess unlearning algorithms in terms of efficacy, generalizability, and model\nutility. Finally, we provide baseline results using existing generative model\nunlearning algorithms. Surprisingly, our experiments show that unimodal\nunlearning algorithms excel in generation and cloze tasks, while multimodal\nunlearning approaches perform better in classification tasks with multimodal\ninputs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL Main 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.22108v2",
    "published_date": "2024-10-29 15:07:23 UTC",
    "updated_date": "2025-02-14 22:08:37 UTC"
  },
  {
    "arxiv_id": "2410.22105v2",
    "title": "DAGE: DAG Query Answering via Relational Combinator with Logical Constraints",
    "authors": [
      "Yunjie He",
      "Bo Xiong",
      "Daniel Hernndez",
      "Yuqicheng Zhu",
      "Evgeny Kharlamov",
      "Steffen Staab"
    ],
    "abstract": "Predicting answers to queries over knowledge graphs is called a complex\nreasoning task because answering a query requires subdividing it into\nsubqueries. Existing query embedding methods use this decomposition to compute\nthe embedding of a query as the combination of the embedding of the subqueries.\nThis requirement limits the answerable queries to queries having a single free\nvariable and being decomposable, which are called tree-form queries and\ncorrespond to the $\\mathcal{SROI}^-$ description logic. In this paper, we\ndefine a more general set of queries, called DAG queries and formulated in the\n$\\mathcal{ALCOIR}$ description logic, propose a query embedding method for\nthem, called DAGE, and a new benchmark to evaluate query embeddings on them.\nGiven the computational graph of a DAG query, DAGE combines the possibly\nmultiple paths between two nodes into a single path with a trainable operator\nthat represents the intersection of relations and learns DAG-DL from\ntautologies. We show that it is possible to implement DAGE on top of existing\nquery embedding methods, and we empirically measure the improvement of our\nmethod over the results of vanilla methods evaluated in tree-form queries that\napproximate the DAG queries of our proposed benchmark.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "Accepted at WWW2025",
    "pdf_url": "http://arxiv.org/pdf/2410.22105v2",
    "published_date": "2024-10-29 15:02:48 UTC",
    "updated_date": "2025-02-12 12:02:01 UTC"
  },
  {
    "arxiv_id": "2410.22101v2",
    "title": "Hyperspectral Imaging-Based Perception in Autonomous Driving Scenarios: Benchmarking Baseline Semantic Segmentation Models",
    "authors": [
      "Imad Ali Shah",
      "Jiarong Li",
      "Martin Glavin",
      "Edward Jones",
      "Enda Ward",
      "Brian Deegan"
    ],
    "abstract": "Hyperspectral Imaging (HSI) is known for its advantages over traditional RGB\nimaging in remote sensing, agriculture, and medicine. Recently, it has gained\nattention for enhancing Advanced Driving Assistance Systems (ADAS) perception.\nSeveral HSI datasets such as HyKo, HSI-Drive, HSI-Road, and Hyperspectral City\nhave been made available. However, a comprehensive evaluation of semantic\nsegmentation models (SSM) using these datasets is lacking. To address this gap,\nwe evaluated the available annotated HSI datasets on four deep learning-based\nbaseline SSMs: DeepLab v3+, HRNet, PSPNet, and U-Net, along with its two\nvariants: Coordinate Attention (UNet-CA) and Convolutional Block-Attention\nModule (UNet-CBAM). The original model architectures were adapted to handle the\nvarying spatial and spectral dimensions of the datasets. These baseline SSMs\nwere trained using a class-weighted loss function for individual HSI datasets\nand evaluated using mean-based metrics such as intersection over union (IoU),\nrecall, precision, F1 score, specificity, and accuracy. Our results indicate\nthat UNet-CBAM, which extracts channel-wise features, outperforms other SSMs\nand shows potential to leverage spectral information for enhanced semantic\nsegmentation. This study establishes a baseline SSM benchmark on available\nannotated datasets for future evaluation of HSI-based ADAS perception. However,\nlimitations of current HSI datasets, such as limited dataset size, high class\nimbalance, and lack of fine-grained annotations, remain significant constraints\nfor developing robust SSMs for ADAS applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted and Presented at IEEE WHISPERS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.22101v2",
    "published_date": "2024-10-29 14:54:13 UTC",
    "updated_date": "2024-12-12 16:46:41 UTC"
  },
  {
    "arxiv_id": "2410.22099v4",
    "title": "TractShapeNet: Efficient Multi-Shape Learning with 3D Tractography Point Clouds",
    "authors": [
      "Yui Lo",
      "Yuqian Chen",
      "Dongnan Liu",
      "Jon Haitz Legarreta",
      "Leo Zekelman",
      "Fan Zhang",
      "Jarrett Rushmore",
      "Yogesh Rathi",
      "Nikos Makris",
      "Alexandra J. Golby",
      "Weidong Cai",
      "Lauren J. O'Donnell"
    ],
    "abstract": "Brain imaging studies have demonstrated that diffusion MRI tractography\ngeometric shape descriptors can inform the study of the brain's white matter\npathways and their relationship to brain function. In this work, we investigate\nthe possibility of utilizing a deep learning model to compute shape measures of\nthe brain's white matter connections. We introduce a novel framework,\nTractShapeNet, that leverages a point cloud representation of tractography to\ncompute five shape measures: length, span, volume, total surface area, and\nirregularity. We assess the performance of the method on a large dataset\nincluding 1065 healthy young adults. Experiments for shape measure computation\ndemonstrate that our proposed TractShapeNet outperforms other point cloud-based\nneural network models in both the Pearson correlation coefficient and\nnormalized error metrics. We compare the inference runtime results with the\nconventional shape computation tool DSI-Studio. Our results demonstrate that a\ndeep learning approach enables faster and more efficient shape measure\ncomputation. We also conduct experiments on two downstream language cognition\nprediction tasks, showing that shape measures from TractShapeNet perform\nsimilarly to those computed by DSI-Studio. Our code will be available at:\nhttps://github.com/SlicerDMRI/TractShapeNet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 2 figures, 4 tables. This work has been accepted to 2025\n  IEEE 22nd International Symposium on Biomedical Imaging (ISBI)",
    "pdf_url": "http://arxiv.org/pdf/2410.22099v4",
    "published_date": "2024-10-29 14:53:10 UTC",
    "updated_date": "2025-02-14 14:46:03 UTC"
  },
  {
    "arxiv_id": "2411.00041v1",
    "title": "NeuroSym-BioCAT: Leveraging Neuro-Symbolic Methods for Biomedical Scholarly Document Categorization and Question Answering",
    "authors": [
      "Parvez Zamil",
      "Gollam Rabby",
      "Md. Sadekur Rahman",
      "Sren Auer"
    ],
    "abstract": "The growing volume of biomedical scholarly document abstracts presents an\nincreasing challenge in efficiently retrieving accurate and relevant\ninformation. To address this, we introduce a novel approach that integrates an\noptimized topic modelling framework, OVB-LDA, with the BI-POP CMA-ES\noptimization technique for enhanced scholarly document abstract categorization.\nComplementing this, we employ the distilled MiniLM model, fine-tuned on\ndomain-specific data, for high-precision answer extraction. Our approach is\nevaluated across three configurations: scholarly document abstract retrieval,\ngold-standard scholarly documents abstract, and gold-standard snippets,\nconsistently outperforming established methods such as RYGH and bio-answer\nfinder. Notably, we demonstrate that extracting answers from scholarly\ndocuments abstracts alone can yield high accuracy, underscoring the sufficiency\nof abstracts for many biomedical queries. Despite its compact size, MiniLM\nexhibits competitive performance, challenging the prevailing notion that only\nlarge, resource-intensive models can handle such complex tasks. Our results,\nvalidated across various question types and evaluation batches, highlight the\nrobustness and adaptability of our method in real-world biomedical\napplications. While our approach shows promise, we identify challenges in\nhandling complex list-type questions and inconsistencies in evaluation metrics.\nFuture work will focus on refining the topic model with more extensive\ndomain-specific datasets, further optimizing MiniLM and utilizing large\nlanguage models (LLM) to improve both precision and efficiency in biomedical\nquestion answering.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00041v1",
    "published_date": "2024-10-29 14:45:12 UTC",
    "updated_date": "2024-10-29 14:45:12 UTC"
  },
  {
    "arxiv_id": "2411.00040v1",
    "title": "P$^2$C$^2$Net: PDE-Preserved Coarse Correction Network for efficient prediction of spatiotemporal dynamics",
    "authors": [
      "Qi Wang",
      "Pu Ren",
      "Hao Zhou",
      "Xin-Yang Liu",
      "Zhiwen Deng",
      "Yi Zhang",
      "Ruizhi Chengze",
      "Hongsheng Liu",
      "Zidong Wang",
      "Jian-Xun Wang",
      "Ji-Rong_Wen",
      "Hao Sun",
      "Yang Liu"
    ],
    "abstract": "When solving partial differential equations (PDEs), classical numerical\nmethods often require fine mesh grids and small time stepping to meet\nstability, consistency, and convergence conditions, leading to high\ncomputational cost. Recently, machine learning has been increasingly utilized\nto solve PDE problems, but they often encounter challenges related to\ninterpretability, generalizability, and strong dependency on rich labeled data.\nHence, we introduce a new PDE-Preserved Coarse Correction Network\n(P$^2$C$^2$Net) to efficiently solve spatiotemporal PDE problems on coarse mesh\ngrids in small data regimes. The model consists of two synergistic modules: (1)\na trainable PDE block that learns to update the coarse solution (i.e., the\nsystem state), based on a high-order numerical scheme with boundary condition\nencoding, and (2) a neural network block that consistently corrects the\nsolution on the fly. In particular, we propose a learnable symmetric Conv\nfilter, with weights shared over the entire model, to accurately estimate the\nspatial derivatives of PDE based on the neural-corrected system state. The\nresulting physics-encoded model is capable of handling limited training data\n(e.g., 3--5 trajectories) and accelerates the prediction of PDE solutions on\ncoarse spatiotemporal grids while maintaining a high accuracy. P$^2$C$^2$Net\nachieves consistent state-of-the-art performance with over 50\\% gain (e.g., in\nterms of relative prediction error) across four datasets covering complex\nreaction-diffusion processes and turbulent flows.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.LG",
      "cs.NA"
    ],
    "primary_category": "math.NA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00040v1",
    "published_date": "2024-10-29 14:45:07 UTC",
    "updated_date": "2024-10-29 14:45:07 UTC"
  },
  {
    "arxiv_id": "2410.22077v1",
    "title": "Mapping the Neuro-Symbolic AI Landscape by Architectures: A Handbook on Augmenting Deep Learning Through Symbolic Reasoning",
    "authors": [
      "Jonathan Feldstein",
      "Paulius Dilkas",
      "Vaishak Belle",
      "Efthymia Tsamoura"
    ],
    "abstract": "Integrating symbolic techniques with statistical ones is a long-standing\nproblem in artificial intelligence. The motivation is that the strengths of\neither area match the weaknesses of the other, and $\\unicode{x2013}$ by\ncombining the two $\\unicode{x2013}$ the weaknesses of either method can be\nlimited. Neuro-symbolic AI focuses on this integration where the statistical\nmethods are in particular neural networks. In recent years, there has been\nsignificant progress in this research field, where neuro-symbolic systems\noutperformed logical or neural models alone. Yet, neuro-symbolic AI is,\ncomparatively speaking, still in its infancy and has not been widely adopted by\nmachine learning practitioners. In this survey, we present the first mapping of\nneuro-symbolic techniques into families of frameworks based on their\narchitectures, with several benefits: Firstly, it allows us to link different\nstrengths of frameworks to their respective architectures. Secondly, it allows\nus to illustrate how engineers can augment their neural networks while treating\nthe symbolic methods as black-boxes. Thirdly, it allows us to map most of the\nfield so that future researchers can identify closely related frameworks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "57 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.22077v1",
    "published_date": "2024-10-29 14:35:59 UTC",
    "updated_date": "2024-10-29 14:35:59 UTC"
  },
  {
    "arxiv_id": "2410.22066v1",
    "title": "Sing it, Narrate it: Quality Musical Lyrics Translation",
    "authors": [
      "Zhuorui Ye",
      "Jinhan Li",
      "Rongwu Xu"
    ],
    "abstract": "Translating lyrics for musicals presents unique challenges due to the need to\nensure high translation quality while adhering to singability requirements such\nas length and rhyme. Existing song translation approaches often prioritize\nthese singability constraints at the expense of translation quality, which is\ncrucial for musicals. This paper aims to enhance translation quality while\nmaintaining key singability features. Our method consists of three main\ncomponents. First, we create a dataset to train reward models for the automatic\nevaluation of translation quality. Second, to enhance both singability and\ntranslation quality, we implement a two-stage training process with filtering\ntechniques. Finally, we introduce an inference-time optimization framework for\ntranslating entire songs. Extensive experiments, including both automatic and\nhuman evaluations, demonstrate significant improvements over baseline methods\nand validate the effectiveness of each component in our approach.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22066v1",
    "published_date": "2024-10-29 14:23:56 UTC",
    "updated_date": "2024-10-29 14:23:56 UTC"
  },
  {
    "arxiv_id": "2411.00039v1",
    "title": "Linear Chain Transformation: Expanding Optimization Dynamics for Fine-Tuning Large Language Models",
    "authors": [
      "Yulong Wang",
      "Chang Zuo",
      "Yin Xuan",
      "Hong Li",
      "Ni Wei"
    ],
    "abstract": "Fine-tuning large language models (LLMs) has become essential for adapting\npretrained models to specific downstream tasks. In this paper, we propose\nLinear Chain Transformation (LinChain), a novel approach that introduces a\nsequence of linear transformations during fine-tuning to enrich optimization\ndynamics. By incorporating multiple linear transformations into the parameter\nupdate process, LinChain expands the effective rank of updates and enhances the\nmodel's ability to learn complex task-specific representations. We demonstrate\nthat this method significantly improves the performance of LLM fine-tuning over\nstate-of-the-art methods by providing more flexible optimization paths during\ntraining, while maintaining the inference efficiency of the resulting model.\nOur experiments on various benchmark tasks show that LinChain leads to better\ngeneralization, fewer learnable parameters, and improved task adaptation,\nmaking it a compelling strategy for LLM fine-tuning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 2 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.00039v1",
    "published_date": "2024-10-29 14:07:24 UTC",
    "updated_date": "2024-10-29 14:07:24 UTC"
  },
  {
    "arxiv_id": "2411.00038v2",
    "title": "Topic-Conversation Relevance (TCR) Dataset and Benchmarks",
    "authors": [
      "Yaran Fan",
      "Jamie Pool",
      "Senja Filipi",
      "Ross Cutler"
    ],
    "abstract": "Workplace meetings are vital to organizational collaboration, yet a large\npercentage of meetings are rated as ineffective. To help improve meeting\neffectiveness by understanding if the conversation is on topic, we create a\ncomprehensive Topic-Conversation Relevance (TCR) dataset that covers a variety\nof domains and meeting styles. The TCR dataset includes 1,500 unique meetings,\n22 million words in transcripts, and over 15,000 meeting topics, sourced from\nboth newly collected Speech Interruption Meeting (SIM) data and existing public\ndatasets. Along with the text data, we also open source scripts to generate\nsynthetic meetings or create augmented meetings from the TCR dataset to enhance\ndata diversity. For each data source, benchmarks are created using GPT-4 to\nevaluate the model accuracy in understanding transcription-topic relevance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To be published in 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024) Track on Datasets and Benchmarks",
    "pdf_url": "http://arxiv.org/pdf/2411.00038v2",
    "published_date": "2024-10-29 13:55:17 UTC",
    "updated_date": "2024-11-04 03:40:54 UTC"
  },
  {
    "arxiv_id": "2411.00832v1",
    "title": "Advanced Hybrid Deep Learning Model for Enhanced Classification of Osteosarcoma Histopathology Images",
    "authors": [
      "Arezoo Borji",
      "Gernot Kronreif",
      "Bernhard Angermayr",
      "Sepideh Hatamikia"
    ],
    "abstract": "Recent advances in machine learning are transforming medical image analysis,\nparticularly in cancer detection and classification. Techniques such as deep\nlearning, especially convolutional neural networks (CNNs) and vision\ntransformers (ViTs), are now enabling the precise analysis of complex\nhistopathological images, automating detection, and enhancing classification\naccuracy across various cancer types. This study focuses on osteosarcoma (OS),\nthe most common bone cancer in children and adolescents, which affects the long\nbones of the arms and legs. Early and accurate detection of OS is essential for\nimproving patient outcomes and reducing mortality. However, the increasing\nprevalence of cancer and the demand for personalized treatments create\nchallenges in achieving precise diagnoses and customized therapies. We propose\na novel hybrid model that combines convolutional neural networks (CNN) and\nvision transformers (ViT) to improve diagnostic accuracy for OS using\nhematoxylin and eosin (H&E) stained histopathological images. The CNN model\nextracts local features, while the ViT captures global patterns from\nhistopathological images. These features are combined and classified using a\nMulti-Layer Perceptron (MLP) into four categories: non-tumor (NT), non-viable\ntumor (NVT), viable tumor (VT), and none-viable ratio (NVR). Using the Cancer\nImaging Archive (TCIA) dataset, the model achieved an accuracy of 99.08%,\nprecision of 99.10%, recall of 99.28%, and an F1-score of 99.23%. This is the\nfirst successful four-class classification using this dataset, setting a new\nbenchmark in OS research and offering promising potential for future diagnostic\nadvancements.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00832v1",
    "published_date": "2024-10-29 13:54:08 UTC",
    "updated_date": "2024-10-29 13:54:08 UTC"
  },
  {
    "arxiv_id": "2411.00831v1",
    "title": "Saliency-Based diversity and fairness Metric and FaceKeepOriginalAugment: A Novel Approach for Enhancing Fairness and Diversity",
    "authors": [
      "Teerath Kumar",
      "Alessandra Mileo",
      "Malika Bendechache"
    ],
    "abstract": "Data augmentation has become a pivotal tool in enhancing the performance of\ncomputer vision tasks, with the KeepOriginalAugment method emerging as a\nstandout technique for its intelligent incorporation of salient regions within\nless prominent areas, enabling augmentation in both regions. Despite its\nsuccess in image classification, its potential in addressing biases remains\nunexplored. In this study, we introduce an extension of the KeepOriginalAugment\nmethod, termed FaceKeepOriginalAugment, which explores various debiasing\naspects-geographical, gender, and stereotypical biases-in computer vision\nmodels. By maintaining a delicate balance between data diversity and\ninformation preservation, our approach empowers models to exploit both diverse\nsalient and non-salient regions, thereby fostering increased diversity and\ndebiasing effects. We investigate multiple strategies for determining the\nplacement of the salient region and swapping perspectives to decide which part\nundergoes augmentation. Leveraging the Image Similarity Score (ISS), we\nquantify dataset diversity across a range of datasets, including Flickr Faces\nHQ (FFHQ), WIKI, IMDB, Labelled Faces in the Wild (LFW), UTK Faces, and Diverse\nDataset. We evaluate the effectiveness of FaceKeepOriginalAugment in mitigating\ngender bias across CEO, Engineer, Nurse, and School Teacher datasets, utilizing\nthe Image-Image Association Score (IIAS) in convolutional neural networks\n(CNNs) and vision transformers (ViTs). Our findings shows the efficacy of\nFaceKeepOriginalAugment in promoting fairness and inclusivity within computer\nvision models, demonstrated by reduced gender bias and enhanced overall\nfairness. Additionally, we introduce a novel metric, Saliency-Based Diversity\nand Fairness Metric, which quantifies both diversity and fairness while\nhandling data imbalance across various datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Paper is underReview in Image and Vision Computing Journal special\n  issue: Advancing Transparency and Privacy: Explainable AI and Synthetic Data\n  in Biometrics and Computer Vision",
    "pdf_url": "http://arxiv.org/pdf/2411.00831v1",
    "published_date": "2024-10-29 13:49:23 UTC",
    "updated_date": "2024-10-29 13:49:23 UTC"
  },
  {
    "arxiv_id": "2411.08906v1",
    "title": "Assessing the Auditability of AI-integrating Systems: A Framework and Learning Analytics Case Study",
    "authors": [
      "Linda Fernsel",
      "Yannick Kalff",
      "Katharina Simbeck"
    ],
    "abstract": "Audits contribute to the trustworthiness of Learning Analytics (LA) systems\nthat integrate Artificial Intelligence (AI) and may be legally required in the\nfuture. We argue that the efficacy of an audit depends on the auditability of\nthe audited system. Therefore, systems need to be designed with auditability in\nmind. We present a framework for assessing the auditability of AI-integrating\nsystems that consists of three parts: (1) Verifiable claims about the validity,\nutility and ethics of the system, (2) Evidence on subjects (data, models or the\nsystem) in different types (documentation, raw sources and logs) to back or\nrefute claims, (3) Evidence must be accessible to auditors via technical means\n(APIs, monitoring tools, explainable AI, etc.). We apply the framework to\nassess the auditability of Moodle's dropout prediction system and a prototype\nAI-based LA. We find that Moodle's auditability is limited by incomplete\ndocumentation, insufficient monitoring capabilities and a lack of available\ntest data. The framework supports assessing the auditability of AI-based LA\nsystems in use and improves the design of auditable systems and thus of audits.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "68-XX",
      "K.3.1; K.4.1; K.4.2; K.5.2"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08906v1",
    "published_date": "2024-10-29 13:43:21 UTC",
    "updated_date": "2024-10-29 13:43:21 UTC"
  },
  {
    "arxiv_id": "2411.00830v1",
    "title": "Unsupervised Training of a Dynamic Context-Aware Deep Denoising Framework for Low-Dose Fluoroscopic Imaging",
    "authors": [
      "Sun-Young Jeon",
      "Sen Wang",
      "Adam S. Wang",
      "Garry E. Gold",
      "Jang-Hwan Choi"
    ],
    "abstract": "Fluoroscopy is critical for real-time X-ray visualization in medical imaging.\nHowever, low-dose images are compromised by noise, potentially affecting\ndiagnostic accuracy. Noise reduction is crucial for maintaining image quality,\nespecially given such challenges as motion artifacts and the limited\navailability of clean data in medical imaging. To address these issues, we\npropose an unsupervised training framework for dynamic context-aware denoising\nof fluoroscopy image sequences. First, we train the multi-scale recurrent\nattention U-Net (MSR2AU-Net) without requiring clean data to address the\ninitial noise. Second, we incorporate a knowledge distillation-based\nuncorrelated noise suppression module and a recursive filtering-based\ncorrelated noise suppression module enhanced with motion compensation to\nfurther improve motion compensation and achieve superior denoising performance.\nFinally, we introduce a novel approach by combining these modules with a\npixel-wise dynamic object motion cross-fusion matrix, designed to adapt to\nmotion, and an edge-preserving loss for precise detail retention. To validate\nthe proposed method, we conducted extensive numerical experiments on medical\nimage datasets, including 3500 fluoroscopy images from dynamic phantoms (2,400\nimages for training, 1,100 for testing) and 350 clinical images from a spinal\nsurgery patient. Moreover, we demonstrated the robustness of our approach\nacross different imaging modalities by testing it on the publicly available\n2016 Low Dose CT Grand Challenge dataset, using 4,800 images for training and\n1,136 for testing. The results demonstrate that the proposed approach\noutperforms state-of-the-art unsupervised algorithms in both visual quality and\nquantitative evaluation while achieving comparable performance to\nwell-established supervised learning methods across low-dose fluoroscopy and CT\nimaging.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "15 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.00830v1",
    "published_date": "2024-10-29 13:39:31 UTC",
    "updated_date": "2024-10-29 13:39:31 UTC"
  },
  {
    "arxiv_id": "2410.22026v1",
    "title": "Enhance Hyperbolic Representation Learning via Second-order Pooling",
    "authors": [
      "Kun Song",
      "Ruben Solozabal",
      "Li hao",
      "Lu Ren",
      "Moloud Abdar",
      "Qing Li",
      "Fakhri Karray",
      "Martin Takac"
    ],
    "abstract": "Hyperbolic representation learning is well known for its ability to capture\nhierarchical information. However, the distance between samples from different\nlevels of hierarchical classes can be required large. We reveal that the\nhyperbolic discriminant objective forces the backbone to capture this\nhierarchical information, which may inevitably increase the Lipschitz constant\nof the backbone. This can hinder the full utilization of the backbone's\ngeneralization ability. To address this issue, we introduce second-order\npooling into hyperbolic representation learning, as it naturally increases the\ndistance between samples without compromising the generalization ability of the\ninput features. In this way, the Lipschitz constant of the backbone does not\nnecessarily need to be large. However, current off-the-shelf low-dimensional\nbilinear pooling methods cannot be directly employed in hyperbolic\nrepresentation learning because they inevitably reduce the distance expansion\ncapability. To solve this problem, we propose a kernel approximation\nregularization, which enables the low-dimensional bilinear features to\napproximate the kernel function well in low-dimensional space. Finally, we\nconduct extensive experiments on graph-structured datasets to demonstrate the\neffectiveness of the proposed method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22026v1",
    "published_date": "2024-10-29 13:17:43 UTC",
    "updated_date": "2024-10-29 13:17:43 UTC"
  },
  {
    "arxiv_id": "2410.22020v2",
    "title": "Path-based summary explanations for graph recommenders (extended version)",
    "authors": [
      "Danae Pla Karidi",
      "Evaggelia Pitoura"
    ],
    "abstract": "Path-based explanations provide intrinsic insights into graph-based\nrecommendation models. However, most previous work has focused on explaining an\nindividual recommendation of an item to a user. In this paper, we propose\nsummary explanations, i.e., explanations that highlight why a user or a group\nof users receive a set of item recommendations and why an item, or a group of\nitems, is recommended to a set of users as an effective means to provide\ninsights into the collective behavior of the recommender. We also present a\nnovel method to summarize explanations using efficient graph algorithms,\nspecifically the Steiner Tree and the Prize-Collecting Steiner Tree. Our\napproach reduces the size and complexity of summary explanations while\npreserving essential information, making explanations more comprehensible for\nusers and more useful to model developers. Evaluations across multiple metrics\ndemonstrate that our summaries outperform baseline explanation methods in most\nscenarios, in a variety of quality aspects.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This is an extended version of the work \"Path-based summary\n  explanations for graph recommenders\", which has been accepted for publication\n  in the Proceedings of the IEEE International Conference on Data Engineering\n  (ICDE) 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.22020v2",
    "published_date": "2024-10-29 13:10:03 UTC",
    "updated_date": "2024-12-07 09:36:07 UTC"
  },
  {
    "arxiv_id": "2411.00036v2",
    "title": "Coupling quantum-like cognition with the neuronal networks within generalized probability theory",
    "authors": [
      "Andrei Khrennikov",
      "Masanao Ozawa",
      "Felix Benninger",
      "Oded Shor"
    ],
    "abstract": "The past few years have seen a surge in the application of quantum theory\nmethodologies and quantum-like modeling in fields such as cognition,\npsychology, and decision-making. Despite the success of this approach in\nexplaining various psychological phenomena such as order, conjunction,\ndisjunction, and response replicability effects there remains a potential\ndissatisfaction due to its lack of clear connection to neurophysiological\nprocesses in the brain. Currently, it remains a phenomenological approach. In\nthis paper, we develop a quantum-like representation of networks of\ncommunicating neurons. This representation is not based on standard quantum\ntheory but on generalized probability theory (GPT), with a focus on the\noperational measurement framework. Specifically, we use a version of GPT that\nrelies on ordered linear state spaces rather than the traditional complex\nHilbert spaces. A network of communicating neurons is modeled as a weighted\ndirected graph, which is encoded by its weight matrix. The state space of these\nweight matrices is embedded within the GPT framework, incorporating effect\nobservables and state updates within the theory of measurement instruments a\ncritical aspect of this model. This GPT based approach successfully reproduces\nkey quantum-like effects, such as order, non-repeatability, and disjunction\neffects (commonly associated with decision interference). Moreover, this\nframework supports quantum-like modeling in medical diagnostics for\nneurological conditions such as depression and epilepsy. While this paper\nfocuses primarily on cognition and neuronal networks, the proposed formalism\nand methodology can be directly applied to a wide range of biological and\nsocial networks.",
    "categories": [
      "physics.soc-ph",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "RIKEN Quantum Workshop, October 11, 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.00036v2",
    "published_date": "2024-10-29 13:09:35 UTC",
    "updated_date": "2025-01-04 13:39:24 UTC"
  },
  {
    "arxiv_id": "2410.22013v1",
    "title": "Modeling Temporal Positive and Negative Excitation for Sequential Recommendation",
    "authors": [
      "Chengkai Huang",
      "Shoujin Wang",
      "Xianzhi Wang",
      "Lina Yao"
    ],
    "abstract": "Sequential recommendation aims to predict the next item which interests users\nvia modeling their interest in items over time. Most of the existing works on\nsequential recommendation model users' dynamic interest in specific items while\noverlooking users' static interest revealed by some static attribute\ninformation of items, e.g., category, or brand. Moreover, existing works often\nonly consider the positive excitation of a user's historical interactions on\nhis/her next choice on candidate items while ignoring the commonly existing\nnegative excitation, resulting in insufficient modeling dynamic interest. The\noverlook of static interest and negative excitation will lead to incomplete\ninterest modeling and thus impede the recommendation performance. To this end,\nin this paper, we propose modeling both static interest and negative excitation\nfor dynamic interest to further improve the recommendation performance.\nAccordingly, we design a novel Static-Dynamic Interest Learning (SDIL)\nframework featured with a novel Temporal Positive and Negative Excitation\nModeling (TPNE) module for accurate sequential recommendation. TPNE is\nspecially designed for comprehensively modeling dynamic interest based on\ntemporal positive and negative excitation learning. Extensive experiments on\nthree real-world datasets show that SDIL can effectively capture both static\nand dynamic interest and outperforms state-of-the-art baselines.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22013v1",
    "published_date": "2024-10-29 13:02:11 UTC",
    "updated_date": "2024-10-29 13:02:11 UTC"
  },
  {
    "arxiv_id": "2411.04137v1",
    "title": "Generative AI Enabled Matching for 6G Multiple Access",
    "authors": [
      "Xudong Wang",
      "Hongyang Du",
      "Dusit Niyato",
      "Lijie Zhou",
      "Lei Feng",
      "Zhixiang Yang",
      "Fanqin Zhou",
      "Wenjing Li"
    ],
    "abstract": "In wireless networks, applying deep learning models to solve matching\nproblems between different entities has become a mainstream and effective\napproach. However, the complex network topology in 6G multiple access presents\nsignificant challenges for the real-time performance and stability of matching\ngeneration. Generative artificial intelligence (GenAI) has demonstrated strong\ncapabilities in graph feature extraction, exploration, and generation, offering\npotential for graph-structured matching generation. In this paper, we propose a\nGenAI-enabled matching generation framework to support 6G multiple access.\nSpecifically, we first summarize the classical matching theory, discuss common\nGenAI models and applications from the perspective of matching generation.\nThen, we propose a framework based on generative diffusion models (GDMs) that\niteratively denoises toward reward maximization to generate a matching strategy\nthat meets specific requirements. Experimental results show that, compared to\ndecision-based AI approaches, our framework can generate more effective\nmatching strategies based on given conditions and predefined rewards, helping\nto solve complex problems in 6G multiple access, such as task allocation.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "8 pages,5 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.04137v1",
    "published_date": "2024-10-29 13:01:26 UTC",
    "updated_date": "2024-10-29 13:01:26 UTC"
  },
  {
    "arxiv_id": "2410.22382v2",
    "title": "Debiasing Alternative Data for Credit Underwriting Using Causal Inference",
    "authors": [
      "Chris Lam"
    ],
    "abstract": "Alternative data provides valuable insights for lenders to evaluate a\nborrower's creditworthiness, which could help expand credit access to\nunderserved groups and lower costs for borrowers. But some forms of alternative\ndata have historically been excluded from credit underwriting because it could\nact as an illegal proxy for a protected class like race or gender, causing\nredlining. We propose a method for applying causal inference to a supervised\nmachine learning model to debias alternative data so that it might be used for\ncredit underwriting. We demonstrate how our algorithm can be used against a\npublic credit dataset to improve model accuracy across different racial groups,\nwhile providing theoretically robust nondiscrimination guarantees.",
    "categories": [
      "q-fin.RM",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "q-fin.RM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22382v2",
    "published_date": "2024-10-29 12:54:55 UTC",
    "updated_date": "2024-10-31 17:12:27 UTC"
  },
  {
    "arxiv_id": "2410.21991v6",
    "title": "From Explicit Rules to Implicit Reasoning in Weakly Supervised Video Anomaly Detection",
    "authors": [
      "Wen-Dong Jiang",
      "Chih-Yung Chang",
      "Ssu-Chi Kuai",
      "Diptendu Sinha Roy"
    ],
    "abstract": "Recent advances in pre-trained models have demonstrated exceptional\nperformance in video anomaly detection (VAD). However, most systems remain\nblack boxes, lacking explainability during training and inference. A key\nchallenge is integrating explicit knowledge into implicit models to create\nexpert-driven, interpretable VAD systems. This paper introduces Rule-based\nViolence Monitoring (RuleVM), a novel weakly supervised video anomaly detection\n(WVAD) paradigm. RuleVM employs a dual-branch architecture: an implicit branch\nusing visual features for coarse-grained binary classification, with feature\nextraction split into scene frames and action channels, and an explicit branch\nleveraging language-image alignment for fine-grained classification. The\nexplicit branch utilizes the state-of-the-art YOLO-World model for object\ndetection in video frames, with association rules mined from data as video\ndescriptors. This design enables interpretable coarse- and fine-grained\nviolence monitoring. Extensive experiments on two standard benchmarks show\nRuleVM outperforms state-of-the-art methods in both granularities. Notably, it\nreveals rules like increased violence risk with crowd size. Demo content is\nprovided in the appendix.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This manuscript has been submitted to IEEE Transactions on Circuits\n  and Systems for Video Technology and is under consideration for publication,\n  with potential copyright transfer in the future",
    "pdf_url": "http://arxiv.org/pdf/2410.21991v6",
    "published_date": "2024-10-29 12:22:07 UTC",
    "updated_date": "2025-04-06 04:35:46 UTC"
  },
  {
    "arxiv_id": "2411.00034v1",
    "title": "Is Our Chatbot Telling Lies? Assessing Correctness of an LLM-based Dutch Support Chatbot",
    "authors": [
      "Herman Lassche",
      "Michiel Overeem",
      "Ayushi Rastogi"
    ],
    "abstract": "Companies support their customers using live chats and chatbots to gain their\nloyalty. AFAS is a Dutch company aiming to leverage the opportunity large\nlanguage models (LLMs) offer to answer customer queries with minimal to no\ninput from its customer support team. Adding to its complexity, it is unclear\nwhat makes a response correct, and that too in Dutch. Further, with minimal\ndata available for training, the challenge is to identify whether an answer\ngenerated by a large language model is correct and do it on the fly.\n  This study is the first to define the correctness of a response based on how\nthe support team at AFAS makes decisions. It leverages literature on natural\nlanguage generation and automated answer grading systems to automate the\ndecision-making of the customer support team. We investigated questions\nrequiring a binary response (e.g., Would it be possible to adjust tax rates\nmanually?) or instructions (e.g., How would I adjust tax rate manually?) to\ntest how close our automated approach reaches support rating. Our approach can\nidentify wrong messages in 55\\% of the cases. This work shows the viability of\nautomatically assessing when our chatbot tell lies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7; I.7.0"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages + 2 pages references, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.00034v1",
    "published_date": "2024-10-29 12:02:14 UTC",
    "updated_date": "2024-10-29 12:02:14 UTC"
  },
  {
    "arxiv_id": "2410.21968v1",
    "title": "Automated Vulnerability Detection Using Deep Learning Technique",
    "authors": [
      "Guan-Yan Yang",
      "Yi-Heng Ko",
      "Farn Wang",
      "Kuo-Hui Yeh",
      "Haw-Shiang Chang",
      "Hsueh-Yi Chen"
    ],
    "abstract": "Our work explores the utilization of deep learning, specifically leveraging\nthe CodeBERT model, to enhance code security testing for Python applications by\ndetecting SQL injection vulnerabilities. Unlike traditional security testing\nmethods that may be slow and error-prone, our approach transforms source code\ninto vector representations and trains a Long Short-Term Memory (LSTM) model to\nidentify vulnerable patterns. When compared with existing static application\nsecurity testing (SAST) tools, our model displays superior performance,\nachieving higher precision, recall, and F1-score. The study demonstrates that\ndeep learning techniques, particularly with CodeBERT's advanced contextual\nunderstanding, can significantly improve vulnerability detection, presenting a\nscalable methodology applicable to various programming languages and\nvulnerability types.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE",
      "D.2.4; D.2.5"
    ],
    "primary_category": "cs.CR",
    "comment": "4 pages, 1 figures; Presented at The 30st International Conference on\n  Computational & Experimental Engineering and Sciences (ICCES2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.21968v1",
    "published_date": "2024-10-29 11:51:51 UTC",
    "updated_date": "2024-10-29 11:51:51 UTC"
  },
  {
    "arxiv_id": "2410.21967v2",
    "title": "Dual Conditional Diffusion Models for Sequential Recommendation",
    "authors": [
      "Hongtao Huang",
      "Chengkai Huang",
      "Tong Yu",
      "Xiaojun Chang",
      "Wen Hu",
      "Julian McAuley",
      "Lina Yao"
    ],
    "abstract": "Recent advancements in diffusion models have shown promising results in\nsequential recommendation (SR). Existing approaches predominantly rely on\nimplicit conditional diffusion models, which compress user behaviors into a\nsingle representation during the forward diffusion process. While effective to\nsome extent, this oversimplification often leads to the loss of sequential and\ncontextual information, which is critical for understanding user behavior.\nMoreover, explicit information, such as user-item interactions or sequential\npatterns, remains underutilized, despite its potential to directly guide the\nrecommendation process and improve precision. However, combining implicit and\nexplicit information is non-trivial, as it requires dynamically integrating\nthese complementary signals while avoiding noise and irrelevant patterns within\nuser behaviors. To address these challenges, we propose Dual Conditional\nDiffusion Models for Sequential Recommendation (DCRec), which effectively\nintegrates implicit and explicit information by embedding dual conditions into\nboth the forward and reverse diffusion processes. This allows the model to\nretain valuable sequential and contextual information while leveraging explicit\nuser-item interactions to guide the recommendation process. Specifically, we\nintroduce the Dual Conditional Diffusion Transformer (DCDT), which employs a\ncross-attention mechanism to dynamically integrate explicit signals throughout\nthe diffusion stages, ensuring contextual understanding and minimizing the\ninfluence of irrelevant patterns. This design enables precise and contextually\nrelevant recommendations. Extensive experiments on public benchmark datasets\ndemonstrate that DCRec significantly outperforms state-of-the-art methods in\nboth accuracy and computational efficiency.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21967v2",
    "published_date": "2024-10-29 11:51:06 UTC",
    "updated_date": "2025-03-18 04:42:54 UTC"
  },
  {
    "arxiv_id": "2410.21951v2",
    "title": "Fast and High-Quality Auto-Regressive Speech Synthesis via Speculative Decoding",
    "authors": [
      "Bohan Li",
      "Hankun Wang",
      "Situo Zhang",
      "Yiwei Guo",
      "Kai Yu"
    ],
    "abstract": "The auto-regressive architecture, like GPTs, is widely used in modern\nText-to-Speech (TTS) systems. However, it incurs substantial inference time,\nparticularly due to the challenges in the next-token prediction posed by\nlengthy sequences of speech tokens. In this work, we introduce VADUSA, one of\nthe first approaches to accelerate auto-regressive TTS through speculative\ndecoding. Our results show that VADUSA not only significantly improves\ninference speed but also enhances performance by incorporating draft heads to\npredict future speech content auto-regressively. Furthermore, the inclusion of\na tolerance mechanism during sampling accelerates inference without\ncompromising quality. Our approach demonstrates strong generalization across\nlarge datasets and various types of speech tokens.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD",
      "68T07"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted by ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.21951v2",
    "published_date": "2024-10-29 11:12:01 UTC",
    "updated_date": "2025-02-10 04:22:08 UTC"
  },
  {
    "arxiv_id": "2410.21943v1",
    "title": "Beyond Text: Optimizing RAG with Multimodal Inputs for Industrial Applications",
    "authors": [
      "Monica Riedler",
      "Stefan Langer"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nanswering questions, but they lack domain-specific knowledge and are prone to\nhallucinations. Retrieval Augmented Generation (RAG) is one approach to address\nthese challenges, while multimodal models are emerging as promising AI\nassistants for processing both text and images. In this paper we describe a\nseries of experiments aimed at determining how to best integrate multimodal\nmodels into RAG systems for the industrial domain. The purpose of the\nexperiments is to determine whether including images alongside text from\ndocuments within the industrial domain increases RAG performance and to find\nthe optimal configuration for such a multimodal RAG system. Our experiments\ninclude two approaches for image processing and retrieval, as well as two LLMs\n(GPT4-Vision and LLaVA) for answer synthesis. These image processing strategies\ninvolve the use of multimodal embeddings and the generation of textual\nsummaries from images. We evaluate our experiments with an LLM-as-a-Judge\napproach. Our results reveal that multimodal RAG can outperform single-modality\nRAG settings, although image retrieval poses a greater challenge than text\nretrieval. Additionally, leveraging textual summaries from images presents a\nmore promising approach compared to the use of multimodal embeddings, providing\nmore opportunities for future advancements.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21943v1",
    "published_date": "2024-10-29 11:03:31 UTC",
    "updated_date": "2024-10-29 11:03:31 UTC"
  },
  {
    "arxiv_id": "2410.21940v1",
    "title": "Human-Readable Programs as Actors of Reinforcement Learning Agents Using Critic-Moderated Evolution",
    "authors": [
      "Senne Deproost",
      "Denis Steckelmacher",
      "Ann Now"
    ],
    "abstract": "With Deep Reinforcement Learning (DRL) being increasingly considered for the\ncontrol of real-world systems, the lack of transparency of the neural network\nat the core of RL becomes a concern. Programmatic Reinforcement Learning (PRL)\nis able to to create representations of this black-box in the form of source\ncode, not only increasing the explainability of the controller but also\nallowing for user adaptations. However, these methods focus on distilling a\nblack-box policy into a program and do so after learning using the Mean Squared\nError between produced and wanted behaviour, discarding other elements of the\nRL algorithm. The distilled policy may therefore perform significantly worse\nthan the black-box learned policy.\n  In this paper, we propose to directly learn a program as the policy of an RL\nagent. We build on TD3 and use its critics as the basis of the objective\nfunction of a genetic algorithm that syntheses the program. Our approach builds\nthe program during training, as opposed to after the fact. This steers the\nprogram to actual high rewards, instead of a simple Mean Squared Error. Also,\nour approach leverages the TD3 critics to achieve high sample-efficiency, as\nopposed to pure genetic methods that rely on Monte-Carlo evaluations. Our\nexperiments demonstrate the validity, explainability and sample-efficiency of\nour approach in a simple gridworld environment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in BNAIC/BeNeLearn 2024 conference proceedings",
    "pdf_url": "http://arxiv.org/pdf/2410.21940v1",
    "published_date": "2024-10-29 10:57:33 UTC",
    "updated_date": "2024-10-29 10:57:33 UTC"
  },
  {
    "arxiv_id": "2410.21939v2",
    "title": "AI Cyber Risk Benchmark: Automated Exploitation Capabilities",
    "authors": [
      "Dan Ristea",
      "Vasilios Mavroudis",
      "Chris Hicks"
    ],
    "abstract": "We introduce a new benchmark for assessing AI models' capabilities and risks\nin automated software exploitation, focusing on their ability to detect and\nexploit vulnerabilities in real-world software systems. Using DARPA's AI Cyber\nChallenge (AIxCC) framework and the Nginx challenge project, a deliberately\nmodified version of the widely used Nginx web server, we evaluate several\nleading language models, including OpenAI's o1-preview and o1-mini, Anthropic's\nClaude-3.5-sonnet-20241022 and Claude-3.5-sonnet-20240620, Google DeepMind's\nGemini-1.5-pro, and OpenAI's earlier GPT-4o model. Our findings reveal that\nthese models vary significantly in their success rates and efficiency, with\no1-preview achieving the highest success rate of 64.71 percent and o1-mini and\nClaude-3.5-sonnet-20241022 providing cost-effective but less successful\nalternatives. This benchmark establishes a foundation for systematically\nevaluating the AI cyber risk posed by automated exploitation tools.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21939v2",
    "published_date": "2024-10-29 10:57:11 UTC",
    "updated_date": "2024-12-09 15:29:55 UTC"
  },
  {
    "arxiv_id": "2410.21938v1",
    "title": "ReMix: Training Generalized Person Re-identification on a Mixture of Data",
    "authors": [
      "Timur Mamedov",
      "Anton Konushin",
      "Vadim Konushin"
    ],
    "abstract": "Modern person re-identification (Re-ID) methods have a weak generalization\nability and experience a major accuracy drop when capturing environments\nchange. This is because existing multi-camera Re-ID datasets are limited in\nsize and diversity, since such data is difficult to obtain. At the same time,\nenormous volumes of unlabeled single-camera records are available. Such data\ncan be easily collected, and therefore, it is more diverse. Currently,\nsingle-camera data is used only for self-supervised pre-training of Re-ID\nmethods. However, the diversity of single-camera data is suppressed by\nfine-tuning on limited multi-camera data after pre-training. In this paper, we\npropose ReMix, a generalized Re-ID method jointly trained on a mixture of\nlimited labeled multi-camera and large unlabeled single-camera data. Effective\ntraining of our method is achieved through a novel data sampling strategy and\nnew loss functions that are adapted for joint use with both types of data.\nExperiments show that ReMix has a high generalization ability and outperforms\nstate-of-the-art methods in generalizable person Re-ID. To the best of our\nknowledge, this is the first work that explores joint training on a mixture of\nmulti-camera and single-camera data in person Re-ID.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.21938v1",
    "published_date": "2024-10-29 10:57:03 UTC",
    "updated_date": "2024-10-29 10:57:03 UTC"
  },
  {
    "arxiv_id": "2410.21936v1",
    "title": "LogSHIELD: A Graph-based Real-time Anomaly Detection Framework using Frequency Analysis",
    "authors": [
      "Krishna Chandra Roy",
      "Qian Chen"
    ],
    "abstract": "Anomaly-based cyber threat detection using deep learning is on a constant\ngrowth in popularity for novel cyber-attack detection and forensics. A robust,\nefficient, and real-time threat detector in a large-scale operational\nenterprise network requires high accuracy, high fidelity, and a high throughput\nmodel to detect malicious activities. Traditional anomaly-based detection\nmodels, however, suffer from high computational overhead and low detection\naccuracy, making them unsuitable for real-time threat detection. In this work,\nwe propose LogSHIELD, a highly effective graph-based anomaly detection model in\nhost data. We present a real-time threat detection approach using\nfrequency-domain analysis of provenance graphs. To demonstrate the significance\nof graph-based frequency analysis we proposed two approaches. Approach-I uses a\nGraph Neural Network (GNN) LogGNN and approach-II performs frequency domain\nanalysis on graph node samples for graph embedding. Both approaches use a\nstatistical clustering algorithm for anomaly detection. The proposed models are\nevaluated using a large host log dataset consisting of 774M benign logs and\n375K malware logs. LogSHIELD explores the provenance graph to extract\ncontextual and causal relationships among logs, exposing abnormal activities.\nIt can detect stealthy and sophisticated attacks with over 98% average AUC and\nF1 scores. It significantly improves throughput, achieves an average detection\nlatency of 0.13 seconds, and outperforms state-of-the-art models in detection\ntime.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21936v1",
    "published_date": "2024-10-29 10:52:43 UTC",
    "updated_date": "2024-10-29 10:52:43 UTC"
  },
  {
    "arxiv_id": "2410.21928v1",
    "title": "Differentiable Inductive Logic Programming for Fraud Detection",
    "authors": [
      "Boris Wolfson",
      "Erman Acar"
    ],
    "abstract": "Current trends in Machine Learning prefer explainability even when it comes\nat the cost of performance. Therefore, explainable AI methods are particularly\nimportant in the field of Fraud Detection. This work investigates the\napplicability of Differentiable Inductive Logic Programming (DILP) as an\nexplainable AI approach to Fraud Detection. Although the scalability of DILP is\na well-known issue, we show that with some data curation such as cleaning and\nadjusting the tabular and numerical data to the expected format of background\nfacts statements, it becomes much more applicable. While in processing it does\nnot provide any significant advantage on rather more traditional methods such\nas Decision Trees, or more recent ones like Deep Symbolic Classification, it\nstill gives comparable results. We showcase its limitations and points to\nimprove, as well as potential use cases where it can be much more useful\ncompared to traditional methods, such as recursive rule learning.",
    "categories": [
      "q-fin.RM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.RM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21928v1",
    "published_date": "2024-10-29 10:43:06 UTC",
    "updated_date": "2024-10-29 10:43:06 UTC"
  },
  {
    "arxiv_id": "2410.21926v1",
    "title": "Reliable Semantic Understanding for Real World Zero-shot Object Goal Navigation",
    "authors": [
      "Halil Utku Unlu",
      "Shuaihang Yuan",
      "Congcong Wen",
      "Hao Huang",
      "Anthony Tzes",
      "Yi Fang"
    ],
    "abstract": "We introduce an innovative approach to advancing semantic understanding in\nzero-shot object goal navigation (ZS-OGN), enhancing the autonomy of robots in\nunfamiliar environments. Traditional reliance on labeled data has been a\nlimitation for robotic adaptability, which we address by employing a\ndual-component framework that integrates a GLIP Vision Language Model for\ninitial detection and an InstructionBLIP model for validation. This combination\nnot only refines object and environmental recognition but also fortifies the\nsemantic interpretation, pivotal for navigational decision-making. Our method,\nrigorously tested in both simulated and real-world settings, exhibits marked\nimprovements in navigation precision and reliability.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "16 pages, 7 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.21926v1",
    "published_date": "2024-10-29 10:37:37 UTC",
    "updated_date": "2024-10-29 10:37:37 UTC"
  },
  {
    "arxiv_id": "2410.22381v1",
    "title": "Robust training of implicit generative models for multivariate and heavy-tailed distributions with an invariant statistical loss",
    "authors": [
      "Jos Manuel de Frutos",
      "Manuel A. Vzquez",
      "Pablo Olmos",
      "Joaqun Mguez"
    ],
    "abstract": "Traditional implicit generative models are capable of learning highly complex\ndata distributions. However, their training involves distinguishing real data\nfrom synthetically generated data using adversarial discriminators, which can\nlead to unstable training dynamics and mode dropping issues. In this work, we\nbuild on the \\textit{invariant statistical loss} (ISL) method introduced in\n\\cite{de2024training}, and extend it to handle heavy-tailed and multivariate\ndata distributions.\n  The data generated by many real-world phenomena can only be properly\ncharacterised using heavy-tailed probability distributions, and traditional\nimplicit methods struggle to effectively capture their asymptotic behavior. To\naddress this problem, we introduce a generator trained with ISL, that uses\ninput noise from a generalised Pareto distribution (GPD). We refer to this\ngenerative scheme as Pareto-ISL for conciseness. Our experiments demonstrate\nthat Pareto-ISL accurately models the tails of the distributions while still\neffectively capturing their central characteristics.\n  The original ISL function was conceived for 1D data sets. When the actual\ndata is $n$-dimensional, a straightforward extension of the method was obtained\nby targeting the $n$ marginal distributions of the data. This approach is\ncomputationally infeasible and ineffective in high-dimensional spaces. To\novercome this, we extend the 1D approach using random projections and define a\nnew loss function suited for multivariate data, keeping problems tractable by\nadjusting the number of projections. We assess its performance in\nmultidimensional generative modeling and explore its potential as a pretraining\ntechnique for generative adversarial networks (GANs) to prevent mode collapse,\nreporting promising results and highlighting its robustness across various\nhyperparameter settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.CO",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22381v1",
    "published_date": "2024-10-29 10:27:50 UTC",
    "updated_date": "2024-10-29 10:27:50 UTC"
  },
  {
    "arxiv_id": "2410.22380v1",
    "title": "Discrete Modeling via Boundary Conditional Diffusion Processes",
    "authors": [
      "Yuxuan Gu",
      "Xiaocheng Feng",
      "Lei Huang",
      "Yingsheng Wu",
      "Zekun Zhou",
      "Weihong Zhong",
      "Kun Zhu",
      "Bing Qin"
    ],
    "abstract": "We present an novel framework for efficiently and effectively extending the\npowerful continuous diffusion processes to discrete modeling. Previous\napproaches have suffered from the discrepancy between discrete data and\ncontinuous modeling. Our study reveals that the absence of guidance from\ndiscrete boundaries in learning probability contours is one of the main\nreasons. To address this issue, we propose a two-step forward process that\nfirst estimates the boundary as a prior distribution and then rescales the\nforward trajectory to construct a boundary conditional diffusion model. The\nreverse process is proportionally adjusted to guarantee that the learned\ncontours yield more precise discrete data. Experimental results indicate that\nour approach achieves strong performance in both language modeling and discrete\nimage generation tasks. In language modeling, our approach surpasses previous\nstate-of-the-art continuous diffusion language models in three translation\ntasks and a summarization task, while also demonstrating competitive\nperformance compared to auto-regressive transformers. Moreover, our method\nachieves comparable results to continuous diffusion models when using discrete\nordinal pixels and establishes a new state-of-the-art for categorical image\ngeneration on the Cifar-10 dataset.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeuraIPS 2024 poster",
    "pdf_url": "http://arxiv.org/pdf/2410.22380v1",
    "published_date": "2024-10-29 09:42:42 UTC",
    "updated_date": "2024-10-29 09:42:42 UTC"
  },
  {
    "arxiv_id": "2410.21897v3",
    "title": "Semi-Supervised Self-Learning Enhanced Music Emotion Recognition",
    "authors": [
      "Yifu Sun",
      "Xulong Zhang",
      "Monan Zhou",
      "Wei Li"
    ],
    "abstract": "Music emotion recognition (MER) aims to identify the emotions conveyed in a\ngiven musical piece. However, currently, in the field of MER, the available\npublic datasets have limited sample sizes. Recently, segment-based methods for\nemotion-related tasks have been proposed, which train backbone networks on\nshorter segments instead of entire audio clips, thereby naturally augmenting\ntraining samples without requiring additional resources. Then, the predicted\nsegment-level results are aggregated to obtain the entire song prediction. The\nmost commonly used method is that the segment inherits the label of the clip\ncontaining it, but music emotion is not constant during the whole clip. Doing\nso will introduce label noise and make the training easy to overfit. To handle\nthe noisy label issue, we propose a semi-supervised self-learning (SSSL)\nmethod, which can differentiate between samples with correct and incorrect\nlabels in a self-learning manner, thus effectively utilizing the augmented\nsegment-level data. Experiments on three public emotional datasets demonstrate\nthat the proposed method can achieve better or comparable performance.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "12 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.21897v3",
    "published_date": "2024-10-29 09:42:07 UTC",
    "updated_date": "2025-04-22 01:15:29 UTC"
  },
  {
    "arxiv_id": "2410.21886v1",
    "title": "Bayesian Optimization for Hyperparameters Tuning in Neural Networks",
    "authors": [
      "Gabriele Onorato"
    ],
    "abstract": "This study investigates the application of Bayesian Optimization (BO) for the\nhyperparameter tuning of neural networks, specifically targeting the\nenhancement of Convolutional Neural Networks (CNN) for image classification\ntasks. Bayesian Optimization is a derivative-free global optimization method\nsuitable for expensive black-box functions with continuous inputs and limited\nevaluation budgets. The BO algorithm leverages Gaussian Process regression and\nacquisition functions like Upper Confidence Bound (UCB) and Expected\nImprovement (EI) to identify optimal configurations effectively. Using the Ax\nand BOTorch frameworks, this work demonstrates the efficiency of BO in reducing\nthe number of hyperparameter tuning trials while achieving competitive model\nperformance. Experimental outcomes reveal that BO effectively balances\nexploration and exploitation, converging rapidly towards optimal settings for\nCNN architectures. This approach underlines the potential of BO in automating\nneural network tuning, contributing to improved accuracy and computational\nefficiency in machine learning pipelines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "Bachelor Thesis in Optimization for Machine Learning, 57 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.21886v1",
    "published_date": "2024-10-29 09:23:24 UTC",
    "updated_date": "2024-10-29 09:23:24 UTC"
  },
  {
    "arxiv_id": "2410.21882v1",
    "title": "Building Altruistic and Moral AI Agent with Brain-inspired Affective Empathy Mechanisms",
    "authors": [
      "Feifei Zhao",
      "Hui Feng",
      "Haibo Tong",
      "Zhengqiang Han",
      "Enmeng Lu",
      "Yinqian Sun",
      "Yi Zeng"
    ],
    "abstract": "As AI closely interacts with human society, it is crucial to ensure that its\ndecision-making is safe, altruistic, and aligned with human ethical and moral\nvalues. However, existing research on embedding ethical and moral\nconsiderations into AI remains insufficient, and previous external constraints\nbased on principles and rules are inadequate to provide AI with long-term\nstability and generalization capabilities. In contrast, the intrinsic\naltruistic motivation based on empathy is more willing, spontaneous, and\nrobust. Therefore, this paper is dedicated to autonomously driving intelligent\nagents to acquire morally behaviors through human-like affective empathy\nmechanisms. We draw inspiration from the neural mechanism of human brain's\nmoral intuitive decision-making, and simulate the mirror neuron system to\nconstruct a brain-inspired affective empathy-driven altruistic decision-making\nmodel. Here, empathy directly impacts dopamine release to form intrinsic\naltruistic motivation. Based on the principle of moral utilitarianism, we\ndesign the moral reward function that integrates intrinsic empathy and\nextrinsic self-task goals. A comprehensive experimental scenario incorporating\nempathetic processes, personal objectives, and altruistic goals is developed.\nThe proposed model enables the agent to make consistent moral decisions\n(prioritizing altruism) by balancing self-interest with the well-being of\nothers. We further introduce inhibitory neurons to regulate different levels of\nempathy and verify the positive correlation between empathy levels and\naltruistic preferences, yielding conclusions consistent with findings from\npsychological behavioral experiments. This work provides a feasible solution\nfor the development of ethical AI by leveraging the intrinsic human-like\nempathy mechanisms, and contributes to the harmonious coexistence between\nhumans and AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21882v1",
    "published_date": "2024-10-29 09:19:27 UTC",
    "updated_date": "2024-10-29 09:19:27 UTC"
  },
  {
    "arxiv_id": "2410.21872v2",
    "title": "Advancing Efficient Brain Tumor Multi-Class Classification -- New Insights from the Vision Mamba Model in Transfer Learning",
    "authors": [
      "Yinyi Lai",
      "Anbo Cao",
      "Yuan Gao",
      "Jiaqi Shang",
      "Zongyu Li",
      "Jia Guo"
    ],
    "abstract": "Early and accurate diagnosis of brain tumors is crucial for improving patient\nsurvival rates. However, the detection and classification of brain tumors are\nchallenging due to their diverse types and complex morphological\ncharacteristics. This study investigates the application of pre-trained models\nfor brain tumor classification, with a particular focus on deploying the Mamba\nmodel. We fine-tuned several mainstream transfer learning models and applied\nthem to the multi-class classification of brain tumors. By comparing these\nmodels to those trained from scratch, we demonstrated the significant\nadvantages of transfer learning, especially in the medical imaging field, where\nannotated data is often limited. Notably, we introduced the Vision Mamba (Vim),\na novel network architecture, and applied it for the first time in brain tumor\nclassification, achieving exceptional classification accuracy. Experimental\nresults indicate that the Vim model achieved 100% classification accuracy on an\nindependent test set, emphasizing its potential for tumor classification tasks.\nThese findings underscore the effectiveness of transfer learning in brain tumor\nclassification and reveal that, compared to existing state-of-the-art models,\nthe Vim model is lightweight, efficient, and highly accurate, offering a new\nperspective for clinical applications. Furthermore, the framework proposed in\nthis study for brain tumor classification, based on transfer learning and the\nVision Mamba model, is broadly applicable to other medical imaging\nclassification problems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21872v2",
    "published_date": "2024-10-29 09:08:57 UTC",
    "updated_date": "2024-11-06 02:52:47 UTC"
  },
  {
    "arxiv_id": "2410.21869v3",
    "title": "Cross-Entropy Is All You Need To Invert the Data Generating Process",
    "authors": [
      "Patrik Reizinger",
      "Alice Bizeul",
      "Attila Juhos",
      "Julia E. Vogt",
      "Randall Balestriero",
      "Wieland Brendel",
      "David Klindt"
    ],
    "abstract": "Supervised learning has become a cornerstone of modern machine learning, yet\na comprehensive theory explaining its effectiveness remains elusive. Empirical\nphenomena, such as neural analogy-making and the linear representation\nhypothesis, suggest that supervised models can learn interpretable factors of\nvariation in a linear fashion. Recent advances in self-supervised learning,\nparticularly nonlinear Independent Component Analysis, have shown that these\nmethods can recover latent structures by inverting the data generating process.\nWe extend these identifiability results to parametric instance discrimination,\nthen show how insights transfer to the ubiquitous setting of supervised\nlearning with cross-entropy minimization. We prove that even in standard\nclassification tasks, models learn representations of ground-truth factors of\nvariation up to a linear transformation. We corroborate our theoretical\ncontribution with a series of empirical studies. First, using simulated data\nmatching our theoretical assumptions, we demonstrate successful disentanglement\nof latent factors. Second, we show that on DisLib, a widely-used\ndisentanglement benchmark, simple classification tasks recover latent\nstructures up to linear transformations. Finally, we reveal that models trained\non ImageNet encode representations that permit linear decoding of proxy factors\nof variation. Together, our theoretical findings and experiments offer a\ncompelling explanation for recent observations of linear representations, such\nas superposition in neural networks. This work takes a significant step toward\na cohesive theory that accounts for the unreasonable effectiveness of\nsupervised deep learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025 (oral) camera ready",
    "pdf_url": "http://arxiv.org/pdf/2410.21869v3",
    "published_date": "2024-10-29 09:03:57 UTC",
    "updated_date": "2025-02-25 07:22:53 UTC"
  },
  {
    "arxiv_id": "2410.21853v2",
    "title": "Learning Infinitesimal Generators of Continuous Symmetries from Data",
    "authors": [
      "Gyeonghoon Ko",
      "Hyunsu Kim",
      "Juho Lee"
    ],
    "abstract": "Exploiting symmetry inherent in data can significantly improve the sample\nefficiency of a learning procedure and the generalization of learned models.\nWhen data clearly reveals underlying symmetry, leveraging this symmetry can\nnaturally inform the design of model architectures or learning strategies. Yet,\nin numerous real-world scenarios, identifying the specific symmetry within a\ngiven data distribution often proves ambiguous. To tackle this, some existing\nworks learn symmetry in a data-driven manner, parameterizing and learning\nexpected symmetry through data. However, these methods often rely on explicit\nknowledge, such as pre-defined Lie groups, which are typically restricted to\nlinear or affine transformations. In this paper, we propose a novel symmetry\nlearning algorithm based on transformations defined with one-parameter groups,\ncontinuously parameterized transformations flowing along the directions of\nvector fields called infinitesimal generators. Our method is built upon minimal\ninductive biases, encompassing not only commonly utilized symmetries rooted in\nLie groups but also extending to symmetries derived from nonlinear generators.\nTo learn these symmetries, we introduce a notion of a validity score that\nexamine whether the transformed data is still valid for the given task. The\nvalidity score is designed to be fully differentiable and easily computable,\nenabling effective searches for transformations that achieve symmetries innate\nto the data. We apply our method mainly in two domains: image data and partial\ndifferential equations, and demonstrate its advantages. Our codes are available\nat \\url{https://github.com/kogyeonghoon/learning-symmetry-from-scratch.git}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Neurips 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.21853v2",
    "published_date": "2024-10-29 08:28:23 UTC",
    "updated_date": "2024-12-19 06:39:24 UTC"
  },
  {
    "arxiv_id": "2411.00031v2",
    "title": "A Theoretical Review on Solving Algebra Problems",
    "authors": [
      "Xinguo Yu",
      "Weina Cheng",
      "Chuanzhi Yang",
      "Ting Zhang"
    ],
    "abstract": "Solving algebra problems (APs) continues to attract significant research\ninterest as evidenced by the large number of algorithms and theories proposed\nover the past decade. Despite these important research contributions, however,\nthe body of work remains incomplete in terms of theoretical justification and\nscope. The current contribution intends to fill the gap by developing a review\nframework that aims to lay a theoretical base, create an evaluation scheme, and\nextend the scope of the investigation. This paper first develops the State\nTransform Theory (STT), which emphasizes that the problem-solving algorithms\nare structured according to states and transforms unlike the understanding that\nunderlies traditional surveys which merely emphasize the progress of\ntransforms. The STT, thus, lays the theoretical basis for a new framework for\nreviewing algorithms. This new construct accommodates the relation-centric\nalgorithms for solving both word and diagrammatic algebra problems. The latter\nnot only highlights the necessity of introducing new states but also allows\nrevelation of contributions of individual algorithms obscured in prior reviews\nwithout this approach.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.LO",
    "comment": "22pages,5figures",
    "pdf_url": "http://arxiv.org/pdf/2411.00031v2",
    "published_date": "2024-10-29 08:16:49 UTC",
    "updated_date": "2024-12-23 02:57:14 UTC"
  },
  {
    "arxiv_id": "2410.21845v3",
    "title": "Precise and Dexterous Robotic Manipulation via Human-in-the-Loop Reinforcement Learning",
    "authors": [
      "Jianlan Luo",
      "Charles Xu",
      "Jeffrey Wu",
      "Sergey Levine"
    ],
    "abstract": "Reinforcement learning (RL) holds great promise for enabling autonomous\nacquisition of complex robotic manipulation skills, but realizing this\npotential in real-world settings has been challenging. We present a\nhuman-in-the-loop vision-based RL system that demonstrates impressive\nperformance on a diverse set of dexterous manipulation tasks, including dynamic\nmanipulation, precision assembly, and dual-arm coordination. Our approach\nintegrates demonstrations and human corrections, efficient RL algorithms, and\nother system-level design choices to learn policies that achieve near-perfect\nsuccess rates and fast cycle times within just 1 to 2.5 hours of training. We\nshow that our method significantly outperforms imitation learning baselines and\nprior RL approaches, with an average 2x improvement in success rate and 1.8x\nfaster execution. Through extensive experiments and analysis, we provide\ninsights into the effectiveness of our approach, demonstrating how it learns\nrobust, adaptive policies for both reactive and predictive control strategies.\nOur results suggest that RL can indeed learn a wide range of complex\nvision-based manipulation policies directly in the real world within practical\ntraining times. We hope this work will inspire a new generation of learned\nrobotic manipulation techniques, benefiting both industrial applications and\nresearch advancements. Videos and code are available at our project website\nhttps://hil-serl.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21845v3",
    "published_date": "2024-10-29 08:12:20 UTC",
    "updated_date": "2025-03-20 09:16:05 UTC"
  },
  {
    "arxiv_id": "2410.21842v1",
    "title": "Diffusion as Reasoning: Enhancing Object Goal Navigation with LLM-Biased Diffusion Model",
    "authors": [
      "Yiming Ji",
      "Yang Liu",
      "Zhengpu Wang",
      "Boyu Ma",
      "Zongwu Xie",
      "Hong Liu"
    ],
    "abstract": "The Object Goal Navigation (ObjectNav) task requires the agent to navigate to\na specified target in an unseen environment. Since the environment layout is\nunknown, the agent needs to perform semantic reasoning to infer the potential\nlocation of the target, based on its accumulated memory of the environment\nduring the navigation process. Diffusion models have been shown to be able to\nlearn the distribution relationships between features in RGB images, and thus\ngenerate new realistic images.In this work, we propose a new approach to\nsolving the ObjectNav task, by training a diffusion model to learn the\nstatistical distribution patterns of objects in semantic maps, and using the\nmap of the explored regions during navigation as the condition to generate the\nmap of the unknown regions, thereby realizing the semantic reasoning of the\ntarget object, i.e., diffusion as reasoning (DAR). Meanwhile, we propose the\nglobal target bias and local LLM bias methods, where the former can constrain\nthe diffusion model to generate the target object more effectively, and the\nlatter utilizes the common sense knowledge extracted from the LLM to improve\nthe generalization of the reasoning process. Based on the generated map in the\nunknown region, the agent sets the predicted location of the target as the goal\nand moves towards it. Experiments on Gibson and MP3D show the effectiveness of\nour method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21842v1",
    "published_date": "2024-10-29 08:10:06 UTC",
    "updated_date": "2024-10-29 08:10:06 UTC"
  },
  {
    "arxiv_id": "2410.22377v2",
    "title": "A Systematic Literature Review of Spatio-Temporal Graph Neural Network Models for Time Series Forecasting and Classification",
    "authors": [
      "Flavio Corradini",
      "Flavio Gerosa",
      "Marco Gori",
      "Carlo Lucheroni",
      "Marco Piangerelli",
      "Martina Zannotti"
    ],
    "abstract": "In recent years, spatio-temporal graph neural networks (GNNs) have attracted\nconsiderable interest in the field of time series analysis, due to their\nability to capture dependencies among variables and across time points. The\nobjective of the presented systematic literature review is hence to provide a\ncomprehensive overview of the various modeling approaches and application\ndomains of GNNs for time series classification and forecasting. A database\nsearch was conducted, and over 150 journal papers were selected for a detailed\nexamination of the current state-of-the-art in the field. This examination is\nintended to offer to the reader a comprehensive collection of proposed models,\nlinks to related source code, available datasets, benchmark models, and fitting\nresults. All this information is hoped to assist researchers in future studies.\nTo the best of our knowledge, this is the first systematic literature review\npresenting a detailed comparison of the results of current spatio-temporal GNN\nmodels in different domains. In addition, in its final part this review\ndiscusses current limitations and challenges in the application of\nspatio-temporal GNNs, such as comparability, reproducibility, explainability,\npoor information capacity, and scalability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.data-an"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22377v2",
    "published_date": "2024-10-29 08:05:10 UTC",
    "updated_date": "2025-05-07 10:08:36 UTC"
  },
  {
    "arxiv_id": "2411.00030v2",
    "title": "WikiNER-fr-gold: A Gold-Standard NER Corpus",
    "authors": [
      "Danrun Cao",
      "Nicolas Bchet",
      "Pierre-Franois Marteau"
    ],
    "abstract": "We address in this article the the quality of the WikiNER corpus, a\nmultilingual Named Entity Recognition corpus, and provide a consolidated\nversion of it. The annotation of WikiNER was produced in a semi-supervised\nmanner i.e. no manual verification has been carried out a posteriori. Such\ncorpus is called silver-standard. In this paper we propose WikiNER-fr-gold\nwhich is a revised version of the French proportion of WikiNER. Our corpus\nconsists of randomly sampled 20% of the original French sub-corpus (26,818\nsentences with 700k tokens). We start by summarizing the entity types included\nin each category in order to define an annotation guideline, and then we\nproceed to revise the corpus. Finally we present an analysis of errors and\ninconsistency observed in the WikiNER-fr corpus, and we discuss potential\nfuture work directions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00030v2",
    "published_date": "2024-10-29 08:00:16 UTC",
    "updated_date": "2025-04-28 08:16:14 UTC"
  },
  {
    "arxiv_id": "2411.00029v1",
    "title": "Preserving Pre-trained Representation Space: On Effectiveness of Prefix-tuning for Large Multi-modal Models",
    "authors": [
      "Donghoon Kim",
      "Gusang Lee",
      "Kyuhong Shim",
      "Byonghyo Shim"
    ],
    "abstract": "Recently, we have observed that Large Multi-modal Models (LMMs) are\nrevolutionizing the way machines interact with the world, unlocking new\npossibilities across various multi-modal applications. To adapt LMMs for\ndownstream tasks, parameter-efficient fine-tuning (PEFT) which only trains\nadditional prefix tokens or modules, has gained popularity. Nevertheless, there\nhas been little analysis of how PEFT works in LMMs. In this paper, we delve\ninto the strengths and weaknesses of each tuning strategy, shifting the focus\nfrom the efficiency typically associated with these approaches. We first\ndiscover that model parameter tuning methods such as LoRA and Adapters distort\nthe feature representation space learned during pre-training and limit the full\nutilization of pre-trained knowledge. We also demonstrate that prefix-tuning\nexcels at preserving the representation space, despite its lower performance on\ndownstream tasks. These findings suggest a simple two-step PEFT strategy called\nPrefix-Tuned PEFT (PT-PEFT), which successively performs prefix-tuning and then\nPEFT (i.e., Adapter, LoRA), combines the benefits of both. Experimental results\nshow that PT-PEFT not only improves performance in image captioning and visual\nquestion answering compared to vanilla PEFT methods but also helps preserve the\nrepresentation space of the four pre-trained models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.00029v1",
    "published_date": "2024-10-29 07:55:50 UTC",
    "updated_date": "2024-10-29 07:55:50 UTC"
  },
  {
    "arxiv_id": "2410.22376v2",
    "title": "Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion Models on Rare Concepts with LLM Guidance",
    "authors": [
      "Dongmin Park",
      "Sebin Kim",
      "Taehong Moon",
      "Minkyu Kim",
      "Kangwook Lee",
      "Jaewoong Cho"
    ],
    "abstract": "State-of-the-art text-to-image (T2I) diffusion models often struggle to\ngenerate rare compositions of concepts, e.g., objects with unusual attributes.\nIn this paper, we show that the compositional generation power of diffusion\nmodels on such rare concepts can be significantly enhanced by the Large\nLanguage Model (LLM) guidance. We start with empirical and theoretical\nanalysis, demonstrating that exposing frequent concepts relevant to the target\nrare concepts during the diffusion sampling process yields more accurate\nconcept composition. Based on this, we propose a training-free approach, R2F,\nthat plans and executes the overall rare-to-frequent concept guidance\nthroughout the diffusion inference by leveraging the abundant semantic\nknowledge in LLMs. Our framework is flexible across any pre-trained diffusion\nmodels and LLMs, and can be seamlessly integrated with the region-guided\ndiffusion approaches. Extensive experiments on three datasets, including our\nnewly proposed benchmark, RareBench, containing various prompts with rare\ncompositions of concepts, R2F significantly surpasses existing models including\nSD3.0 and FLUX by up to 28.1%p in T2I alignment. Code is available at\nhttps://github.com/krafton-ai/Rare-to-Frequent.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22376v2",
    "published_date": "2024-10-29 07:43:39 UTC",
    "updated_date": "2025-01-07 01:41:13 UTC"
  },
  {
    "arxiv_id": "2410.21815v2",
    "title": "Gnothi Seauton: Empowering Faithful Self-Interpretability in Black-Box Transformers",
    "authors": [
      "Shaobo Wang",
      "Hongxuan Tang",
      "Mingyang Wang",
      "Hongrui Zhang",
      "Xuyang Liu",
      "Weiya Li",
      "Xuming Hu",
      "Linfeng Zhang"
    ],
    "abstract": "The debate between self-interpretable models and post-hoc explanations for\nblack-box models is central to Explainable AI (XAI). Self-interpretable models,\nsuch as concept-based networks, offer insights by connecting decisions to\nhuman-understandable concepts but often struggle with performance and\nscalability. Conversely, post-hoc methods like Shapley values, while\ntheoretically robust, are computationally expensive and resource-intensive. To\nbridge the gap between these two lines of research, we propose a novel method\nthat combines their strengths, providing theoretically guaranteed\nself-interpretability for black-box models without compromising prediction\naccuracy. Specifically, we introduce a parameter-efficient pipeline,\nAutoGnothi, which integrates a small side network into the black-box model,\nallowing it to generate Shapley value explanations without changing the\noriginal network parameters. This side-tuning approach significantly reduces\nmemory, training, and inference costs, outperforming traditional\nparameter-efficient methods, where full fine-tuning serves as the optimal\nbaseline. AutoGnothi enables the black-box model to predict and explain its\npredictions with minimal overhead. Extensive experiments show that AutoGnothi\noffers accurate explanations for both vision and language tasks, delivering\nsuperior computational efficiency with comparable interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICLR 2025, 29 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.21815v2",
    "published_date": "2024-10-29 07:35:33 UTC",
    "updated_date": "2025-02-25 01:58:17 UTC"
  },
  {
    "arxiv_id": "2411.08041v1",
    "title": "GraphAide: Advanced Graph-Assisted Query and Reasoning System",
    "authors": [
      "Sumit Purohit",
      "George Chin",
      "Patrick S Mackey",
      "Joseph A Cottam"
    ],
    "abstract": "Curating knowledge from multiple siloed sources that contain both structured\nand unstructured data is a major challenge in many real-world applications.\nPattern matching and querying represent fundamental tasks in modern data\nanalytics that leverage this curated knowledge. The development of such\napplications necessitates overcoming several research challenges, including\ndata extraction, named entity recognition, data modeling, and designing query\ninterfaces. Moreover, the explainability of these functionalities is critical\nfor their broader adoption.\n  The emergence of Large Language Models (LLMs) has accelerated the development\nlifecycle of new capabilities. Nonetheless, there is an ongoing need for\ndomain-specific tools tailored to user activities. The creation of digital\nassistants has gained considerable traction in recent years, with LLMs offering\na promising avenue to develop such assistants utilizing domain-specific\nknowledge and assumptions.\n  In this context, we introduce an advanced query and reasoning system,\nGraphAide, which constructs a knowledge graph (KG) from diverse sources and\nallows to query and reason over the resulting KG. GraphAide harnesses both the\nKG and LLMs to rapidly develop domain-specific digital assistants. It\nintegrates design patterns from retrieval augmented generation (RAG) and the\nsemantic web to create an agentic LLM application. GraphAide underscores the\npotential for streamlined and efficient development of specialized digital\nassistants, thereby enhancing their applicability across various domains.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08041v1",
    "published_date": "2024-10-29 07:25:30 UTC",
    "updated_date": "2024-10-29 07:25:30 UTC"
  },
  {
    "arxiv_id": "2410.21807v2",
    "title": "A Fresh Look at Generalized Category Discovery through Non-negative Matrix Factorization",
    "authors": [
      "Zhong Ji",
      "Shuo Yang",
      "Jingren Liu",
      "Yanwei Pang",
      "Jungong Han"
    ],
    "abstract": "Generalized Category Discovery (GCD) aims to classify both base and novel\nimages using labeled base data. However, current approaches inadequately\naddress the intrinsic optimization of the co-occurrence matrix $\\bar{A}$ based\non cosine similarity, failing to achieve zero base-novel regions and adequate\nsparsity in base and novel domains. To address these deficiencies, we propose a\nNon-Negative Generalized Category Discovery (NN-GCD) framework. It employs\nSymmetric Non-negative Matrix Factorization (SNMF) as a mathematical medium to\nprove the equivalence of optimal K-means with optimal SNMF, and the equivalence\nof SNMF solver with non-negative contrastive learning (NCL) optimization.\nUtilizing these theoretical equivalences, it reframes the optimization of\n$\\bar{A}$ and K-means clustering as an NCL optimization problem. Moreover, to\nsatisfy the non-negative constraints and make a GCD model converge to a\nnear-optimal region, we propose a GELU activation function and an NMF NCE loss.\nTo transition $\\bar{A}$ from a suboptimal state to the desired $\\bar{A}^*$, we\nintroduce a hybrid sparse regularization approach to impose sparsity\nconstraints. Experimental results show NN-GCD outperforms state-of-the-art\nmethods on GCD benchmarks, achieving an average accuracy of 66.1\\% on the\nSemantic Shift Benchmark, surpassing prior counterparts by 4.7\\%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.21807v2",
    "published_date": "2024-10-29 07:24:11 UTC",
    "updated_date": "2024-10-30 01:34:11 UTC"
  },
  {
    "arxiv_id": "2411.00827v3",
    "title": "IDEATOR: Jailbreaking and Benchmarking Large Vision-Language Models Using Themselves",
    "authors": [
      "Ruofan Wang",
      "Juncheng Li",
      "Yixu Wang",
      "Bo Wang",
      "Xiaosen Wang",
      "Yan Teng",
      "Yingchun Wang",
      "Xingjun Ma",
      "Yu-Gang Jiang"
    ],
    "abstract": "As large Vision-Language Models (VLMs) gain prominence, ensuring their safe\ndeployment has become critical. Recent studies have explored VLM robustness\nagainst jailbreak attacks-techniques that exploit model vulnerabilities to\nelicit harmful outputs. However, the limited availability of diverse multimodal\ndata has constrained current approaches to rely heavily on adversarial or\nmanually crafted images derived from harmful text datasets, which often lack\neffectiveness and diversity across different contexts. In this paper, we\npropose IDEATOR, a novel jailbreak method that autonomously generates malicious\nimage-text pairs for black-box jailbreak attacks. IDEATOR is grounded in the\ninsight that VLMs themselves could serve as powerful red team models for\ngenerating multimodal jailbreak prompts. Specifically, IDEATOR leverages a VLM\nto create targeted jailbreak texts and pairs them with jailbreak images\ngenerated by a state-of-the-art diffusion model. Extensive experiments\ndemonstrate IDEATOR's high effectiveness and transferability, achieving a 94%\nattack success rate (ASR) in jailbreaking MiniGPT-4 with an average of only\n5.34 queries, and high ASRs of 82%, 88%, and 75% when transferred to LLaVA,\nInstructBLIP, and Chameleon, respectively. Building on IDEATOR's strong\ntransferability and automated process, we introduce the VLBreakBench, a safety\nbenchmark comprising 3,654 multimodal jailbreak samples. Our benchmark results\non 11 recently released VLMs reveal significant gaps in safety alignment. For\ninstance, our challenge set achieves ASRs of 46.31% on GPT-4o and 19.65% on\nClaude-3.5-Sonnet, underscoring the urgent need for stronger defenses.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00827v3",
    "published_date": "2024-10-29 07:15:56 UTC",
    "updated_date": "2025-03-08 17:39:57 UTC"
  },
  {
    "arxiv_id": "2410.21802v2",
    "title": "Text-Guided Attention is All You Need for Zero-Shot Robustness in Vision-Language Models",
    "authors": [
      "Lu Yu",
      "Haiyang Zhang",
      "Changsheng Xu"
    ],
    "abstract": "Due to the impressive zero-shot capabilities, pre-trained vision-language\nmodels (e.g. CLIP), have attracted widespread attention and adoption across\nvarious domains. Nonetheless, CLIP has been observed to be susceptible to\nadversarial examples. Through experimental analysis, we have observed a\nphenomenon wherein adversarial perturbations induce shifts in text-guided\nattention. Building upon this observation, we propose a simple yet effective\nstrategy: Text-Guided Attention for Zero-Shot Robustness (TGA-ZSR). This\nframework incorporates two components: the Attention Refinement module and the\nAttention-based Model Constraint module. Our goal is to maintain the\ngeneralization of the CLIP model and enhance its adversarial robustness: The\nAttention Refinement module aligns the text-guided attention obtained from the\ntarget model via adversarial examples with the text-guided attention acquired\nfrom the original model via clean examples. This alignment enhances the model's\nrobustness. Additionally, the Attention-based Model Constraint module acquires\ntext-guided attention from both the target and original models using clean\nexamples. Its objective is to maintain model performance on clean samples while\nenhancing overall robustness. The experiments validate that our method yields a\n9.58% enhancement in zero-shot robust accuracy over the current\nstate-of-the-art techniques across 16 datasets. Our code is available at\nhttps://github.com/zhyblue424/TGA-ZSR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.21802v2",
    "published_date": "2024-10-29 07:15:09 UTC",
    "updated_date": "2024-10-30 01:22:55 UTC"
  },
  {
    "arxiv_id": "2410.21795v2",
    "title": "Robot Policy Learning with Temporal Optimal Transport Reward",
    "authors": [
      "Yuwei Fu",
      "Haichao Zhang",
      "Di Wu",
      "Wei Xu",
      "Benoit Boulet"
    ],
    "abstract": "Reward specification is one of the most tricky problems in Reinforcement\nLearning, which usually requires tedious hand engineering in practice. One\npromising approach to tackle this challenge is to adopt existing expert video\ndemonstrations for policy learning. Some recent work investigates how to learn\nrobot policies from only a single/few expert video demonstrations. For example,\nreward labeling via Optimal Transport (OT) has been shown to be an effective\nstrategy to generate a proxy reward by measuring the alignment between the\nrobot trajectory and the expert demonstrations. However, previous work mostly\noverlooks that the OT reward is invariant to temporal order information, which\ncould bring extra noise to the reward signal. To address this issue, in this\npaper, we introduce the Temporal Optimal Transport (TemporalOT) reward to\nincorporate temporal order information for learning a more accurate OT-based\nproxy reward. Extensive experiments on the Meta-world benchmark tasks validate\nthe efficacy of the proposed method. Code is available at:\nhttps://github.com/fuyw/TemporalOT",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.21795v2",
    "published_date": "2024-10-29 07:00:47 UTC",
    "updated_date": "2024-11-02 02:09:58 UTC"
  },
  {
    "arxiv_id": "2410.21794v2",
    "title": "Inverse Attention Agents for Multi-Agent Systems",
    "authors": [
      "Qian Long",
      "Ruoyan Li",
      "Minglu Zhao",
      "Tao Gao",
      "Demetri Terzopoulos"
    ],
    "abstract": "A major challenge for Multi-Agent Systems is enabling agents to adapt\ndynamically to diverse environments in which opponents and teammates may\ncontinually change. Agents trained using conventional methods tend to excel\nonly within the confines of their training cohorts; their performance drops\nsignificantly when confronting unfamiliar agents. To address this shortcoming,\nwe introduce Inverse Attention Agents that adopt concepts from the Theory of\nMind (ToM) implemented algorithmically using an attention mechanism trained in\nan end-to-end manner. Crucial to determining the final actions of these agents,\nthe weights in their attention model explicitly represent attention to\ndifferent goals. We furthermore propose an inverse attention network that\ndeduces the ToM of agents based on observations and prior actions. The network\ninfers the attentional states of other agents, thereby refining the attention\nweights to adjust the agent's final action. We conduct experiments in a\ncontinuous environment, tackling demanding tasks encompassing cooperation,\ncompetition, and a blend of both. They demonstrate that the inverse attention\nnetwork successfully infers the attention of other agents, and that this\ninformation improves agent performance. Additional human experiments show that,\ncompared to baseline agent models, our inverse attention agents exhibit\nsuperior cooperation with humans and better emulate human behaviors.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21794v2",
    "published_date": "2024-10-29 06:59:11 UTC",
    "updated_date": "2025-04-07 22:59:41 UTC"
  },
  {
    "arxiv_id": "2410.21784v1",
    "title": "MARCO: Multi-Agent Real-time Chat Orchestration",
    "authors": [
      "Anubhav Shrimal",
      "Stanley Kanagaraj",
      "Kriti Biswas",
      "Swarnalatha Raghuraman",
      "Anish Nediyanchath",
      "Yi Zhang",
      "Promod Yenigalla"
    ],
    "abstract": "Large language model advancements have enabled the development of multi-agent\nframeworks to tackle complex, real-world problems such as to automate tasks\nthat require interactions with diverse tools, reasoning, and human\ncollaboration. We present MARCO, a Multi-Agent Real-time Chat Orchestration\nframework for automating tasks using LLMs. MARCO addresses key challenges in\nutilizing LLMs for complex, multi-step task execution. It incorporates robust\nguardrails to steer LLM behavior, validate outputs, and recover from errors\nthat stem from inconsistent output formatting, function and parameter\nhallucination, and lack of domain knowledge. Through extensive experiments we\ndemonstrate MARCO's superior performance with 94.48% and 92.74% accuracy on\ntask execution for Digital Restaurant Service Platform conversations and Retail\nconversations datasets respectively along with 44.91% improved latency and\n33.71% cost reduction. We also report effects of guardrails in performance gain\nalong with comparisons of various LLM models, both open-source and proprietary.\nThe modular and generic design of MARCO allows it to be adapted for automating\ntasks across domains and to execute complex usecases through multi-turn\ninteractions.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "EMNLP 2024 Industry Track",
    "pdf_url": "http://arxiv.org/pdf/2410.21784v1",
    "published_date": "2024-10-29 06:42:27 UTC",
    "updated_date": "2024-10-29 06:42:27 UTC"
  },
  {
    "arxiv_id": "2411.02592v1",
    "title": "Decoupled Data Augmentation for Improving Image Classification",
    "authors": [
      "Ruoxin Chen",
      "Zhe Wang",
      "Ke-Yue Zhang",
      "Shuang Wu",
      "Jiamu Sun",
      "Shouli Wang",
      "Taiping Yao",
      "Shouhong Ding"
    ],
    "abstract": "Recent advancements in image mixing and generative data augmentation have\nshown promise in enhancing image classification. However, these techniques face\nthe challenge of balancing semantic fidelity with diversity. Specifically,\nimage mixing involves interpolating two images to create a new one, but this\npixel-level interpolation can compromise fidelity. Generative augmentation uses\ntext-to-image generative models to synthesize or modify images, often limiting\ndiversity to avoid generating out-of-distribution data that potentially affects\naccuracy. We propose that this fidelity-diversity dilemma partially stems from\nthe whole-image paradigm of existing methods. Since an image comprises the\nclass-dependent part (CDP) and the class-independent part (CIP), where each\npart has fundamentally different impacts on the image's fidelity, treating\ndifferent parts uniformly can therefore be misleading. To address this\nfidelity-diversity dilemma, we introduce Decoupled Data Augmentation (De-DA),\nwhich resolves the dilemma by separating images into CDPs and CIPs and handling\nthem adaptively. To maintain fidelity, we use generative models to modify real\nCDPs under controlled conditions, preserving semantic consistency. To enhance\ndiversity, we replace the image's CIP with inter-class variants, creating\ndiverse CDP-CIP combinations. Additionally, we implement an online randomized\ncombination strategy during training to generate numerous distinct CDP-CIP\ncombinations cost-effectively. Comprehensive empirical evaluations validate the\neffectiveness of our method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02592v1",
    "published_date": "2024-10-29 06:27:09 UTC",
    "updated_date": "2024-10-29 06:27:09 UTC"
  },
  {
    "arxiv_id": "2411.08900v1",
    "title": "RNA-GPT: Multimodal Generative System for RNA Sequence Understanding",
    "authors": [
      "Yijia Xiao",
      "Edward Sun",
      "Yiqiao Jin",
      "Wei Wang"
    ],
    "abstract": "RNAs are essential molecules that carry genetic information vital for life,\nwith profound implications for drug development and biotechnology. Despite this\nimportance, RNA research is often hindered by the vast literature available on\nthe topic. To streamline this process, we introduce RNA-GPT, a multi-modal RNA\nchat model designed to simplify RNA discovery by leveraging extensive RNA\nliterature. RNA-GPT integrates RNA sequence encoders with linear projection\nlayers and state-of-the-art large language models (LLMs) for precise\nrepresentation alignment, enabling it to process user-uploaded RNA sequences\nand deliver concise, accurate responses. Built on a scalable training pipeline,\nRNA-GPT utilizes RNA-QA, an automated system that gathers RNA annotations from\nRNACentral using a divide-and-conquer approach with GPT-4o and latent Dirichlet\nallocation (LDA) to efficiently handle large datasets and generate\ninstruction-tuning samples. Our experiments indicate that RNA-GPT effectively\naddresses complex RNA queries, thereby facilitating RNA research. Additionally,\nwe present RNA-QA, a dataset of 407,616 RNA samples for modality alignment and\ninstruction tuning, further advancing the potential of RNA research tools.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "q-bio.GN",
    "comment": "Machine Learning for Structural Biology Workshop, NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.08900v1",
    "published_date": "2024-10-29 06:19:56 UTC",
    "updated_date": "2024-10-29 06:19:56 UTC"
  },
  {
    "arxiv_id": "2410.22375v1",
    "title": "Rethinking Code Refinement: Learning to Judge Code Efficiency",
    "authors": [
      "Minju Seo",
      "Jinheon Baek",
      "Sung Ju Hwang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nunderstanding and generating codes. Due to these capabilities, many recent\nmethods are proposed to automatically refine the codes with LLMs. However, we\nshould rethink that the refined codes (from LLMs and even humans) are not\nalways more efficient than their original versions. On the other hand, running\ntwo different versions of codes and comparing them every time is not ideal and\ntime-consuming. Therefore, in this work, we propose a novel method based on the\ncode language model that is trained to judge the efficiency between two\ndifferent codes (generated across humans and machines) by either classifying\nthe superior one or predicting the relative improvement. We validate our method\non multiple programming languages with multiple refinement steps, demonstrating\nthat the proposed method can effectively distinguish between more and less\nefficient versions of code.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22375v1",
    "published_date": "2024-10-29 06:17:37 UTC",
    "updated_date": "2024-10-29 06:17:37 UTC"
  },
  {
    "arxiv_id": "2411.08899v1",
    "title": "FinVision: A Multi-Agent Framework for Stock Market Prediction",
    "authors": [
      "Sorouralsadat Fatemi",
      "Yuheng Hu"
    ],
    "abstract": "Financial trading has been a challenging task, as it requires the integration\nof vast amounts of data from various modalities. Traditional deep learning and\nreinforcement learning methods require large training data and often involve\nencoding various data types into numerical formats for model input, which\nlimits the explainability of model behavior. Recently, LLM-based agents have\ndemonstrated remarkable advancements in handling multi-modal data, enabling\nthem to execute complex, multi-step decision-making tasks while providing\ninsights into their thought processes. This research introduces a multi-modal\nmulti-agent system designed specifically for financial trading tasks. Our\nframework employs a team of specialized LLM-based agents, each adept at\nprocessing and interpreting various forms of financial data, such as textual\nnews reports, candlestick charts, and trading signal charts. A key feature of\nour approach is the integration of a reflection module, which conducts analyses\nof historical trading signals and their outcomes. This reflective process is\ninstrumental in enhancing the decision-making capabilities of the system for\nfuture trading scenarios. Furthermore, the ablation studies indicate that the\nvisual reflection module plays a crucial role in enhancing the decision-making\ncapabilities of our framework.",
    "categories": [
      "q-fin.TR",
      "cs.AI"
    ],
    "primary_category": "q-fin.TR",
    "comment": "Accepted at ICAIF 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.08899v1",
    "published_date": "2024-10-29 06:02:28 UTC",
    "updated_date": "2024-10-29 06:02:28 UTC"
  },
  {
    "arxiv_id": "2410.21764v2",
    "title": "Online Mirror Descent for Tchebycheff Scalarization in Multi-Objective Optimization",
    "authors": [
      "Meitong Liu",
      "Xiaoyuan Zhang",
      "Chulin Xie",
      "Kate Donahue",
      "Han Zhao"
    ],
    "abstract": "The goal of multi-objective optimization (MOO) is to learn under multiple,\npotentially conflicting, objectives. One widely used technique to tackle MOO is\nthrough linear scalarization, where one fixed preference vector is used to\ncombine the objectives into a single scalar value for optimization. However,\nrecent work (Hu et al., 2024) has shown linear scalarization often fails to\ncapture the non-convex regions of the Pareto Front, failing to recover the\ncomplete set of Pareto optimal solutions. In light of the above limitations,\nthis paper focuses on Tchebycheff scalarization that optimizes for the\nworst-case objective. In particular, we propose an online mirror descent\nalgorithm for Tchebycheff scalarization, which we call OMD-TCH. We show that\nOMD-TCH enjoys a convergence rate of $O(\\sqrt{\\log m/T})$ where $m$ is the\nnumber of objectives and $T$ is the number of iteration rounds. We also propose\na novel adaptive online-to-batch conversion scheme that significantly improves\nthe practical performance of OMD-TCH while maintaining the same convergence\nguarantees. We demonstrate the effectiveness of OMD-TCH and the adaptive\nconversion scheme on both synthetic problems and federated learning tasks under\nfairness constraints, showing state-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 7 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.21764v2",
    "published_date": "2024-10-29 05:58:33 UTC",
    "updated_date": "2024-11-11 16:17:07 UTC"
  },
  {
    "arxiv_id": "2410.21750v1",
    "title": "Learning and Unlearning of Fabricated Knowledge in Language Models",
    "authors": [
      "Chen Sun",
      "Nolan Andrew Miller",
      "Andrey Zhmoginov",
      "Max Vladymyrov",
      "Mark Sandler"
    ],
    "abstract": "What happens when a new piece of knowledge is introduced into the training\ndata and how long does it last while a large language model (LM) continues to\ntrain? We investigate this question by injecting facts into LMs from a new\nprobing dataset, \"Outlandish\", which is designed to permit the testing of a\nspectrum of different fact types. When studying how robust these memories are,\nthere appears to be a sweet spot in the spectrum of fact novelty between\nconsistency with world knowledge and total randomness, where the injected\nmemory is the most enduring. Specifically we show that facts that conflict with\ncommon knowledge are remembered for tens of thousands of training steps, while\nprompts not conflicting with common knowledge (mundane), as well as scrambled\nprompts (randomly jumbled) are both forgotten much more rapidly. Further,\nknowledge-conflicting facts can \"prime'' how the language model hallucinates on\nlogically unrelated prompts, showing their propensity for non-target\ngeneralization, while both mundane and randomly jumbled facts prime\nsignificantly less. Finally, we show that impacts of knowledge-conflicting\nfacts in LMs, though they can be long lasting, can be largely erased by novel\napplication of multi-step sparse updates, even while the training ability of\nthe model is preserved. As such, this very simple procedure has direct\nimplications for mitigating the effects of data poisoning in training.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21750v1",
    "published_date": "2024-10-29 05:33:14 UTC",
    "updated_date": "2024-10-29 05:33:14 UTC"
  },
  {
    "arxiv_id": "2410.21741v1",
    "title": "Enhancing Financial Question Answering with a Multi-Agent Reflection Framework",
    "authors": [
      "Sorouralsadat Fatemi",
      "Yuheng Hu"
    ],
    "abstract": "While Large Language Models (LLMs) have shown impressive capabilities in\nnumerous Natural Language Processing (NLP) tasks, they still struggle with\nfinancial question answering (QA), particularly when numerical reasoning is\nrequired. Recently, LLM-based multi-agent frameworks have demonstrated\nremarkable effectiveness in multi-step reasoning, which is crucial for\nfinancial QA tasks as it involves extracting relevant information from tables\nand text and then performing numerical reasoning on the extracted data to infer\nanswers. In this study, we propose a multi-agent framework incorporating a\ncritic agent that reflects on the reasoning steps and final answers for each\nquestion. Additionally, we enhance our system by adding multiple critic agents,\neach focusing on a specific aspect of the answer. Our results indicate that\nthis framework significantly improves performance compared to single-agent\nreasoning, with an average performance increase of 15% for the LLaMA3-8B model\nand 5% for the LLaMA3-70B model. Furthermore, our framework performs on par\nwith, and in some cases surpasses, larger single-agent LLMs such as\nLLaMA3.1-405B and GPT-4o-mini, though it falls slightly short compared to\nClaude-3.5 Sonnet. Overall, our framework presents an effective solution to\nenhance open-source LLMs for financial QA tasks, offering a cost-effective\nalternative to larger models like Claude-3.5 Sonnet.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICAIF 24",
    "pdf_url": "http://arxiv.org/pdf/2410.21741v1",
    "published_date": "2024-10-29 04:58:07 UTC",
    "updated_date": "2024-10-29 04:58:07 UTC"
  },
  {
    "arxiv_id": "2410.21730v1",
    "title": "Efficient Reprogramming of Memristive Crossbars for DNNs: Weight Sorting and Bit Stucking",
    "authors": [
      "Matheus Farias",
      "H. T. Kung"
    ],
    "abstract": "We introduce a novel approach to reduce the number of times required for\nreprogramming memristors on bit-sliced compute-in-memory crossbars for deep\nneural networks (DNNs). Our idea addresses the limited non-volatile memory\nendurance, which restrict the number of times they can be reprogrammed.\n  To reduce reprogramming demands, we employ two techniques: (1) we organize\nweights into sorted sections to schedule reprogramming of similar crossbars,\nmaximizing memristor state reuse, and (2) we reprogram only a fraction of\nrandomly selected memristors in low-order columns, leveraging their bit-level\ndistribution and recognizing their relatively small impact on model accuracy.\n  We evaluate our approach for state-of-the-art models on the ImageNet-1K\ndataset. We demonstrate a substantial reduction in crossbar reprogramming by\n3.7x for ResNet-50 and 21x for ViT-Base, while maintaining model accuracy\nwithin a 1% margin.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "5 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.21730v1",
    "published_date": "2024-10-29 04:34:02 UTC",
    "updated_date": "2024-10-29 04:34:02 UTC"
  },
  {
    "arxiv_id": "2411.00826v2",
    "title": "Uncertainty Quantification via Hlder Divergence for Multi-View Representation Learning",
    "authors": [
      "Yan Zhang",
      "Ming Li",
      "Chun Li",
      "Zhaoxia Liu",
      "Ye Zhang",
      "Fei Richard Yu"
    ],
    "abstract": "Evidence-based deep learning represents a burgeoning paradigm for uncertainty\nestimation, offering reliable predictions with negligible extra computational\noverheads. Existing methods usually adopt Kullback-Leibler divergence to\nestimate the uncertainty of network predictions, ignoring domain gaps among\nvarious modalities. To tackle this issue, this paper introduces a novel\nalgorithm based on H\\\"older Divergence (HD) to enhance the reliability of\nmulti-view learning by addressing inherent uncertainty challenges from\nincomplete or noisy data. Generally, our method extracts the representations of\nmultiple modalities through parallel network branches, and then employs HD to\nestimate the prediction uncertainties. Through the Dempster-Shafer theory,\nintegration of uncertainty from different modalities, thereby generating a\ncomprehensive result that considers all available representations.\nMathematically, HD proves to better measure the ``distance'' between real data\ndistribution and predictive distribution of the model and improve the\nperformances of multi-class recognition tasks.\n  Specifically, our method surpass the existing state-of-the-art counterparts\non all evaluating benchmarks.\n  We further conduct extensive experiments on different backbones to verify our\nsuperior robustness. It is demonstrated that our method successfully pushes the\ncorresponding performance boundaries. Finally, we perform experiments on more\nchallenging scenarios, \\textit{i.e.}, learning with incomplete or noisy data,\nrevealing that our method exhibits a high tolerance to such corrupted data.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "NA",
    "pdf_url": "http://arxiv.org/pdf/2411.00826v2",
    "published_date": "2024-10-29 04:29:44 UTC",
    "updated_date": "2025-04-17 13:24:31 UTC"
  },
  {
    "arxiv_id": "2410.21719v2",
    "title": "On the Statistical Complexity of Estimating Vendi Scores from Empirical Data",
    "authors": [
      "Azim Ospanov",
      "Farzan Farnia"
    ],
    "abstract": "Evaluating the diversity of generative models without access to reference\ndata poses methodological challenges. The reference-free Vendi score offers a\nsolution by quantifying the diversity of generated data using matrix-based\nentropy measures. The Vendi score is usually computed via the\neigendecomposition of an $n \\times n$ kernel matrix for $n$ generated samples.\nHowever, the heavy computational cost of eigendecomposition for large $n$ often\nlimits the sample size used in practice to a few tens of thousands. In this\npaper, we investigate the statistical convergence of the Vendi score. We\nnumerically demonstrate that for kernel functions with an infinite feature map\ndimension, the score estimated from a limited sample size may exhibit a\nnon-negligible bias relative to the population Vendi score, i.e., the\nasymptotic limit as the sample size approaches infinity. To address this, we\nintroduce a truncation of the Vendi statistic, called the $t$-truncated Vendi\nstatistic, which is guaranteed to converge to its asymptotic limit given\n$n=O(t)$ samples. We show that the existing Nystr\\\"om method and the FKEA\napproximation method for approximating the Vendi score both converge to the\npopulation truncated Vendi score. We perform several numerical experiments to\nillustrate the concentration of the Nystr\\\"om and FKEA-computed Vendi scores\naround the truncated Vendi and discuss how the truncated Vendi score correlates\nwith the diversity of image and text data.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21719v2",
    "published_date": "2024-10-29 04:19:41 UTC",
    "updated_date": "2025-02-14 01:19:05 UTC"
  },
  {
    "arxiv_id": "2410.21717v1",
    "title": "Generating Realistic Tabular Data with Large Language Models",
    "authors": [
      "Dang Nguyen",
      "Sunil Gupta",
      "Kien Do",
      "Thin Nguyen",
      "Svetha Venkatesh"
    ],
    "abstract": "While most generative models show achievements in image data generation, few\nare developed for tabular data generation. Recently, due to success of large\nlanguage models (LLM) in diverse tasks, they have also been used for tabular\ndata generation. However, these methods do not capture the correct correlation\nbetween the features and the target variable, hindering their applications in\ndownstream predictive tasks. To address this problem, we propose a LLM-based\nmethod with three important improvements to correctly capture the ground-truth\nfeature-class correlation in the real data. First, we propose a novel\npermutation strategy for the input data in the fine-tuning phase. Second, we\npropose a feature-conditional sampling approach to generate synthetic samples.\nFinally, we generate the labels by constructing prompts based on the generated\nsamples to query our fine-tuned LLM. Our extensive experiments show that our\nmethod significantly outperforms 10 SOTA baselines on 20 datasets in downstream\ntasks. It also produces highly realistic synthetic samples in terms of quality\nand diversity. More importantly, classifiers trained with our synthetic data\ncan even compete with classifiers trained with the original data on half of the\nbenchmark datasets, which is a significant achievement in tabular data\ngeneration.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear at ICDM 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.21717v1",
    "published_date": "2024-10-29 04:14:32 UTC",
    "updated_date": "2024-10-29 04:14:32 UTC"
  },
  {
    "arxiv_id": "2410.21716v1",
    "title": "A Bayesian Approach to Harnessing the Power of LLMs in Authorship Attribution",
    "authors": [
      "Zhengmian Hu",
      "Tong Zheng",
      "Heng Huang"
    ],
    "abstract": "Authorship attribution aims to identify the origin or author of a document.\nTraditional approaches have heavily relied on manual features and fail to\ncapture long-range correlations, limiting their effectiveness. Recent\nadvancements leverage text embeddings from pre-trained language models, which\nrequire significant fine-tuning on labeled data, posing challenges in data\ndependency and limited interpretability. Large Language Models (LLMs), with\ntheir deep reasoning capabilities and ability to maintain long-range textual\nassociations, offer a promising alternative. This study explores the potential\nof pre-trained LLMs in one-shot authorship attribution, specifically utilizing\nBayesian approaches and probability outputs of LLMs. Our methodology calculates\nthe probability that a text entails previous writings of an author, reflecting\na more nuanced understanding of authorship. By utilizing only pre-trained\nmodels such as Llama-3-70B, our results on the IMDb and blog datasets show an\nimpressive 85\\% accuracy in one-shot authorship classification across ten\nauthors. Our findings set new baselines for one-shot authorship analysis using\nLLMs and expand the application scope of these models in forensic linguistics.\nThis work also includes extensive ablation studies to validate our approach.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21716v1",
    "published_date": "2024-10-29 04:14:23 UTC",
    "updated_date": "2024-10-29 04:14:23 UTC"
  },
  {
    "arxiv_id": "2411.00028v2",
    "title": "Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN",
    "authors": [
      "Zhilun Zhou",
      "Jingyang Fan",
      "Yu Liu",
      "Fengli Xu",
      "Depeng Jin",
      "Yong Li"
    ],
    "abstract": "The fast development of location-based social networks (LBSNs) has led to\nsignificant changes in society, resulting in popular studies of using LBSN data\nfor socioeconomic prediction, e.g., regional population and commercial activity\nestimation. Existing studies design various graphs to model heterogeneous LBSN\ndata, and further apply graph representation learning methods for socioeconomic\nprediction. However, these approaches heavily rely on heuristic ideas and\nexpertise to extract task-relevant knowledge from diverse data, which may not\nbe optimal for specific tasks. Additionally, they tend to overlook the inherent\nrelationships between different indicators, limiting the prediction accuracy.\nMotivated by the remarkable abilities of large language models (LLMs) in\ncommonsense reasoning, embedding, and multi-agent collaboration, in this work,\nwe synergize LLM agents and knowledge graph for socioeconomic prediction. We\nfirst construct a location-based knowledge graph (LBKG) to integrate\nmulti-sourced LBSN data. Then we leverage the reasoning power of LLM agent to\nidentify relevant meta-paths in the LBKG for each type of socioeconomic\nprediction task, and design a semantic-guided attention module for knowledge\nfusion with meta-paths. Moreover, we introduce a cross-task communication\nmechanism to further enhance performance by enabling knowledge sharing across\ntasks at both LLM agent and KG levels. On the one hand, the LLM agents for\ndifferent tasks collaborate to generate more diverse and comprehensive\nmeta-paths. On the other hand, the embeddings from different tasks are\nadaptively merged for better socioeconomic prediction. Experiments on two\ndatasets demonstrate the effectiveness of the synergistic design between LLM\nand KG, providing insights for information sharing across socioeconomic\nprediction tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00028v2",
    "published_date": "2024-10-29 04:03:15 UTC",
    "updated_date": "2024-11-19 14:29:32 UTC"
  },
  {
    "arxiv_id": "2410.21705v2",
    "title": "AdaptGCD: Multi-Expert Adapter Tuning for Generalized Category Discovery",
    "authors": [
      "Yuxun Qu",
      "Yongqiang Tang",
      "Chenyang Zhang",
      "Wensheng Zhang"
    ],
    "abstract": "Different from the traditional semi-supervised learning paradigm that is\nconstrained by the close-world assumption, Generalized Category Discovery (GCD)\npresumes that the unlabeled dataset contains new categories not appearing in\nthe labeled set, and aims to not only classify old categories but also discover\nnew categories in the unlabeled data. Existing studies on GCD typically devote\nto transferring the general knowledge from the self-supervised pretrained model\nto the target GCD task via some fine-tuning strategies, such as partial tuning\nand prompt learning. Nevertheless, these fine-tuning methods fail to make a\nsound balance between the generalization capacity of pretrained backbone and\nthe adaptability to the GCD task. To fill this gap, in this paper, we propose a\nnovel adapter-tuning-based method named AdaptGCD, which is the first work to\nintroduce the adapter tuning into the GCD task and provides some key insights\nexpected to enlighten future research. Furthermore, considering the discrepancy\nof supervision information between the old and new classes, a multi-expert\nadapter structure equipped with a route assignment constraint is elaborately\ndevised, such that the data from old and new classes are separated into\ndifferent expert groups. Extensive experiments are conducted on 7 widely-used\ndatasets. The remarkable improvements in performance highlight the\neffectiveness of our proposals.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21705v2",
    "published_date": "2024-10-29 03:41:47 UTC",
    "updated_date": "2025-03-14 15:55:43 UTC"
  },
  {
    "arxiv_id": "2411.05806v1",
    "title": "SkipSNN: Efficiently Classifying Spike Trains with Event-attention",
    "authors": [
      "Hang Yin",
      "Yao Su",
      "Liping Liu",
      "Thomas Hartvigsen",
      "Xin Dai",
      "Xiangnan Kong"
    ],
    "abstract": "Spike train classification has recently become an important topic in the\nmachine learning community, where each spike train is a binary event sequence\nwith \\emph{temporal-sparsity of signals of interest} and \\emph{temporal-noise}\nproperties. A promising model for it should follow the design principle of\nperforming intensive computation only when signals of interest appear. So such\ntasks use mainly Spiking Neural Networks (SNNs) due to their consideration of\ntemporal-sparsity of spike trains. However, the basic mechanism of SNNs ignore\nthe temporal-noise issue, which makes them computationally expensive and thus\nhigh power consumption for analyzing spike trains on resource-constrained\nplatforms. As an event-driven model, an SNN neuron makes a reaction given any\ninput signals, making it difficult to quickly find signals of interest. In this\npaper, we introduce an event-attention mechanism that enables SNNs to\ndynamically highlight useful signals of the original spike trains. To this end,\nwe propose SkipSNN, which extends existing SNN models by learning to mask out\nnoise by skipping membrane potential updates and shortening the effective size\nof the computational graph. This process is analogous to how people choose to\nopen and close their eyes to filter the information they see. We evaluate\nSkipSNN on various neuromorphic tasks and demonstrate that it achieves\nsignificantly better computational efficiency and classification accuracy than\nother state-of-the-art SNNs.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "Published as a research paper at IEEE BigData 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.05806v1",
    "published_date": "2024-10-29 03:19:25 UTC",
    "updated_date": "2024-10-29 03:19:25 UTC"
  },
  {
    "arxiv_id": "2410.21676v4",
    "title": "How Does Critical Batch Size Scale in Pre-training?",
    "authors": [
      "Hanlin Zhang",
      "Depen Morwani",
      "Nikhil Vyas",
      "Jingfeng Wu",
      "Difan Zou",
      "Udaya Ghai",
      "Dean Foster",
      "Sham Kakade"
    ],
    "abstract": "Training large-scale models under given resources requires careful design of\nparallelism strategies. In particular, the efficiency notion of critical batch\nsize (CBS), concerning the compromise between time and compute, marks the\nthreshold beyond which greater data parallelism leads to diminishing returns.\nTo operationalize it, we propose a measure of CBS and pre-train a series of\nauto-regressive language models, ranging from 85 million to 1.2 billion\nparameters, on the C4 dataset. Through extensive hyper-parameter sweeps and\ncareful control of factors such as batch size, momentum, and learning rate\nalong with its scheduling, we systematically investigate the impact of scale on\nCBS. Then we fit scaling laws with respect to model and data sizes to decouple\ntheir effects. Overall, our results demonstrate that CBS scales primarily with\ndata size rather than model size, a finding we justify theoretically through\nthe analysis of infinite-width limits of neural networks and\ninfinite-dimensional least squares regression. Of independent interest, we\nhighlight the importance of common hyper-parameter choices and strategies for\nstudying large-scale pre-training beyond fixed training durations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025, Blog post:\n  https://kempnerinstitute.harvard.edu/research/deeper-learning/how-does-critical-batch-size-scale-in-pre-training-decoupling-data-and-model-size",
    "pdf_url": "http://arxiv.org/pdf/2410.21676v4",
    "published_date": "2024-10-29 02:54:06 UTC",
    "updated_date": "2025-04-21 04:19:56 UTC"
  },
  {
    "arxiv_id": "2410.21675v1",
    "title": "BF-Meta: Secure Blockchain-enhanced Privacy-preserving Federated Learning for Metaverse",
    "authors": [
      "Wenbo Liu",
      "Handi Chen",
      "Edith C. H. Ngai"
    ],
    "abstract": "The metaverse, emerging as a revolutionary platform for social and economic\nactivities, provides various virtual services while posing security and privacy\nchallenges. Wearable devices serve as bridges between the real world and the\nmetaverse. To provide intelligent services without revealing users' privacy in\nthe metaverse, leveraging federated learning (FL) to train models on local\nwearable devices is a promising solution. However, centralized model\naggregation in traditional FL may suffer from external attacks, resulting in a\nsingle point of failure. Furthermore, the absence of incentive mechanisms may\nweaken users' participation during FL training, leading to degraded performance\nof the trained model and reduced quality of intelligent services. In this\npaper, we propose BF-Meta, a secure blockchain-empowered FL framework with\ndecentralized model aggregation, to mitigate the negative influence of\nmalicious users and provide secure virtual services in the metaverse. In\naddition, we design an incentive mechanism to give feedback to users based on\ntheir behaviors. Experiments conducted on five datasets demonstrate the\neffectiveness and applicability of BF-Meta.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21675v1",
    "published_date": "2024-10-29 02:52:49 UTC",
    "updated_date": "2024-10-29 02:52:49 UTC"
  },
  {
    "arxiv_id": "2410.22374v1",
    "title": "Machine Unlearning using Forgetting Neural Networks",
    "authors": [
      "Amartya Hatua",
      "Trung T. Nguyen",
      "Filip Cano",
      "Andrew H. Sung"
    ],
    "abstract": "Modern computer systems store vast amounts of personal data, enabling\nadvances in AI and ML but risking user privacy and trust. For privacy reasons,\nit is desired sometimes for an ML model to forget part of the data it was\ntrained on. This paper presents a new approach to machine unlearning using\nforgetting neural networks (FNN). FNNs are neural networks with specific\nforgetting layers, that take inspiration from the processes involved when a\nhuman brain forgets. While FNNs had been proposed as a theoretical construct,\nthey have not been previously used as a machine unlearning method. We describe\nfour different types of forgetting layers and study their properties. In our\nexperimental evaluation, we report our results on the MNIST handwritten digit\nrecognition and fashion datasets. The effectiveness of the unlearned models was\ntested using Membership Inference Attacks (MIA). Successful experimental\nresults demonstrate the great potential of our proposed method for dealing with\nthe machine unlearning problem.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22374v1",
    "published_date": "2024-10-29 02:52:26 UTC",
    "updated_date": "2024-10-29 02:52:26 UTC"
  },
  {
    "arxiv_id": "2410.21673v1",
    "title": "Knowledge-Guided Prompt Learning for Request Quality Assurance in Public Code Review",
    "authors": [
      "Lin Li",
      "Xinchun Yu",
      "Xinyu Chen",
      "Peng Liang"
    ],
    "abstract": "Public Code Review (PCR) is an assistant to the internal code review of the\ndevelopment team, in the form of a public Software Question Answering (SQA)\ncommunity, to help developers access high-quality and efficient review\nservices. Current methods on PCR mainly focus on the reviewer's perspective,\nincluding finding a capable reviewer, predicting comment quality, and\nrecommending/generating review comments. However, it is not well studied that\nhow to satisfy the review necessity requests posted by developers which can\nincrease their visibility, which in turn acts as a prerequisite for better\nreview responses. To this end, we propose a Knowledge-guided Prompt learning\nfor Public Code Review (KP-PCR) to achieve developer-based code review request\nquality assurance (i.e., predicting request necessity and recommending tags\nsubtask). Specifically, we reformulate the two subtasks via 1) text prompt\ntuning which converts both of them into a Masked Language Model (MLM) by\nconstructing prompt templates using hard prompt; 2) knowledge and code prefix\ntuning which introduces external knowledge by soft prompt, and uses data flow\ndiagrams to characterize code snippets. Finally, both of the request necessity\nprediction and tag recommendation subtasks output predicted results through an\nanswer engineering module. In addition, we further analysis the time complexity\nof our KP-PCR that has lightweight prefix based the operation of introducing\nknowledge. Experimental results on the PCR dataset for the period 2011-2023\ndemonstrate that our KP-PCR outperforms baselines by 8.3%-28.8% in the request\nnecessity prediction and by 0.1%-29.5% in the tag recommendation. The code\nimplementation is released at https://github.com/WUT-IDEA/KP-PCR.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "28 pages, 7 images, 12 tables, Manuscript submitted to a journal\n  (2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.21673v1",
    "published_date": "2024-10-29 02:48:41 UTC",
    "updated_date": "2024-10-29 02:48:41 UTC"
  },
  {
    "arxiv_id": "2411.08897v1",
    "title": "Comment on Is Complexity an Illusion?",
    "authors": [
      "Gabriel Simmons"
    ],
    "abstract": "The paper \"Is Complexity an Illusion?\" (Bennett, 2024) provides a formalism\nfor complexity, learning, inference, and generalization, and introduces a\nformal definition for a \"policy\". This reply shows that correct policies do not\nexist for a simple task of supervised multi-class classification, via\nmathematical proof and exhaustive search. Implications of this result are\ndiscussed, as well as possible responses and amendments to the theory.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Comment on arXiv:2404.07227",
    "pdf_url": "http://arxiv.org/pdf/2411.08897v1",
    "published_date": "2024-10-29 02:40:05 UTC",
    "updated_date": "2024-10-29 02:40:05 UTC"
  },
  {
    "arxiv_id": "2410.21670v1",
    "title": "Sequential choice in ordered bundles",
    "authors": [
      "Rajeev Kohli",
      "Kriste Krstovski",
      "Hengyu Kuang",
      "Hengxu Lin"
    ],
    "abstract": "Experience goods such as sporting and artistic events, songs, videos, news\nstories, podcasts, and television series, are often packaged and consumed in\nbundles. Many such bundles are ordered in the sense that the individual items\nare consumed sequentially, one at a time. We examine if an individual's\ndecision to consume the next item in an ordered bundle can be predicted based\non his/her consumption pattern for the preceding items. We evaluate several\npredictive models, including two custom Transformers using decoder-only and\nencoder-decoder architectures, fine-tuned GPT-3, a custom LSTM model, a\nreinforcement learning model, two Markov models, and a zero-order model. Using\ndata from Spotify, we find that the custom Transformer with a decoder-only\narchitecture provides the most accurate predictions, both for individual\nchoices and aggregate demand. This model captures a general form of state\ndependence. Analysis of Transformer attention weights suggests that the\nconsumption of the next item in a bundle is based on approximately equal\nweighting of all preceding choices. Our results indicate that the Transformer\ncan assist in queuing the next item that an individual is likely to consume\nfrom an ordered bundle, predicting the demand for individual items, and\npersonalizing promotions to increase demand.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21670v1",
    "published_date": "2024-10-29 02:35:21 UTC",
    "updated_date": "2024-10-29 02:35:21 UTC"
  },
  {
    "arxiv_id": "2411.00823v1",
    "title": "Mobility-LLM: Learning Visiting Intentions and Travel Preferences from Human Mobility Data with Large Language Models",
    "authors": [
      "Letian Gong",
      "Yan Lin",
      "Xinyue Zhang",
      "Yiwen Lu",
      "Xuedi Han",
      "Yichen Liu",
      "Shengnan Guo",
      "Youfang Lin",
      "Huaiyu Wan"
    ],
    "abstract": "Location-based services (LBS) have accumulated extensive human mobility data\non diverse behaviors through check-in sequences. These sequences offer valuable\ninsights into users' intentions and preferences. Yet, existing models analyzing\ncheck-in sequences fail to consider the semantics contained in these sequences,\nwhich closely reflect human visiting intentions and travel preferences, leading\nto an incomplete comprehension. Drawing inspiration from the exceptional\nsemantic understanding and contextual information processing capabilities of\nlarge language models (LLMs) across various domains, we present Mobility-LLM, a\nnovel framework that leverages LLMs to analyze check-in sequences for multiple\ntasks. Since LLMs cannot directly interpret check-ins, we reprogram these\nsequences to help LLMs comprehensively understand the semantics of human\nvisiting intentions and travel preferences. Specifically, we introduce a\nvisiting intention memory network (VIMN) to capture the visiting intentions at\neach record, along with a shared pool of human travel preference prompts (HTPP)\nto guide the LLM in understanding users' travel preferences. These components\nenhance the model's ability to extract and leverage semantic information from\nhuman mobility data effectively. Extensive experiments on four benchmark\ndatasets and three downstream tasks demonstrate that our approach significantly\noutperforms existing models, underscoring the effectiveness of Mobility-LLM in\nadvancing our understanding of human mobility data within LBS contexts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS2024",
    "pdf_url": "http://arxiv.org/pdf/2411.00823v1",
    "published_date": "2024-10-29 01:58:06 UTC",
    "updated_date": "2024-10-29 01:58:06 UTC"
  },
  {
    "arxiv_id": "2410.21657v2",
    "title": "PACER: Physics Informed Uncertainty Aware Climate Emulator",
    "authors": [
      "Hira Saleem",
      "Flora Salim",
      "Cormac Purcell"
    ],
    "abstract": "Climate models serve as critical tools for evaluating the effects of climate\nchange and projecting future climate scenarios. However, the reliance on\nnumerical simulations of physical equations renders them computationally\nintensive and inefficient. While deep learning methodologies have made\nsignificant progress in weather forecasting, they are still unstable for\nclimate emulation tasks. Here, we propose PACER, a lightweight 684K parameter\nPhysics Informed Uncertainty Aware Climate Emulator. PACER emulates temperature\nand precipitation stably for 86 years while only being trained on greenhouse\ngas emissions data. We incorporate a fundamental physical law of\nadvection-diffusion in PACER accounting for boundary conditions and empirically\nestimating the diffusion co-efficient and flow velocities from emissions data.\nPACER has been trained on 15 climate models provided by ClimateSet\noutperforming baselines across most of the climate models and advancing a new\nstate of the art in a climate diagnostic task.",
    "categories": [
      "physics.ao-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21657v2",
    "published_date": "2024-10-29 01:53:40 UTC",
    "updated_date": "2024-10-30 05:33:12 UTC"
  },
  {
    "arxiv_id": "2411.00822v1",
    "title": "EEG-based Multimodal Representation Learning for Emotion Recognition",
    "authors": [
      "Kang Yin",
      "Hye-Bin Shin",
      "Dan Li",
      "Seong-Whan Lee"
    ],
    "abstract": "Multimodal learning has been a popular area of research, yet integrating\nelectroencephalogram (EEG) data poses unique challenges due to its inherent\nvariability and limited availability. In this paper, we introduce a novel\nmultimodal framework that accommodates not only conventional modalities such as\nvideo, images, and audio, but also incorporates EEG data. Our framework is\ndesigned to flexibly handle varying input sizes, while dynamically adjusting\nattention to account for feature importance across modalities. We evaluate our\napproach on a recently introduced emotion recognition dataset that combines\ndata from three modalities, making it an ideal testbed for multimodal learning.\nThe experimental results provide a benchmark for the dataset and demonstrate\nthe effectiveness of the proposed framework. This work highlights the potential\nof integrating EEG into multimodal systems, paving the way for more robust and\ncomprehensive applications in emotion recognition and beyond.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00822v1",
    "published_date": "2024-10-29 01:35:17 UTC",
    "updated_date": "2024-10-29 01:35:17 UTC"
  },
  {
    "arxiv_id": "2410.22373v1",
    "title": "Analytic Continual Test-Time Adaptation for Multi-Modality Corruption",
    "authors": [
      "Yufei Zhang",
      "Yicheng Xu",
      "Hongxin Wei",
      "Zhiping Lin",
      "Huiping Zhuang"
    ],
    "abstract": "Test-Time Adaptation (TTA) aims to help pre-trained model bridge the gap\nbetween source and target datasets using only the pre-trained model and\nunlabelled test data. A key objective of TTA is to address domain shifts in\ntest data caused by corruption, such as weather changes, noise, or sensor\nmalfunctions. Multi-Modal Continual Test-Time Adaptation (MM-CTTA), an\nextension of TTA with better real-world applications, further allows\npre-trained models to handle multi-modal inputs and adapt to\ncontinuously-changing target domains. MM-CTTA typically faces challenges\nincluding error accumulation, catastrophic forgetting, and reliability bias,\nwith few existing approaches effectively addressing these issues in multi-modal\ncorruption scenarios. In this paper, we propose a novel approach,\nMulti-modality Dynamic Analytic Adapter (MDAA), for MM-CTTA tasks. We\ninnovatively introduce analytic learning into TTA, using the Analytic\nClassifiers (ACs) to prevent model forgetting. Additionally, we develop Dynamic\nSelection Mechanism (DSM) and Soft Pseudo-label Strategy (SPS), which enable\nMDAA to dynamically filter reliable samples and integrate information from\ndifferent modalities. Extensive experiments demonstrate that MDAA achieves\nstate-of-the-art performance on MM-CTTA tasks while ensuring reliable model\nadaptation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22373v1",
    "published_date": "2024-10-29 01:21:24 UTC",
    "updated_date": "2024-10-29 01:21:24 UTC"
  },
  {
    "arxiv_id": "2410.21641v1",
    "title": "RDSinger: Reference-based Diffusion Network for Singing Voice Synthesis",
    "authors": [
      "Kehan Sui",
      "Jinxu Xiang",
      "Fang Jin"
    ],
    "abstract": "Singing voice synthesis (SVS) aims to produce high-fidelity singing audio\nfrom music scores, requiring a detailed understanding of notes, pitch, and\nduration, unlike text-to-speech tasks. Although diffusion models have shown\nexceptional performance in various generative tasks like image and video\ncreation, their application in SVS is hindered by time complexity and the\nchallenge of capturing acoustic features, particularly during pitch\ntransitions. Some networks learn from the prior distribution and use the\ncompressed latent state as a better start in the diffusion model, but the\ndenoising step doesn't consistently improve quality over the entire duration.\nWe introduce RDSinger, a reference-based denoising diffusion network that\ngenerates high-quality audio for SVS tasks. Our approach is inspired by Animate\nAnyone, a diffusion image network that maintains intricate appearance features\nfrom reference images. RDSinger utilizes FastSpeech2 mel-spectrogram as a\nreference to mitigate denoising step artifacts. Additionally, existing models\ncould be influenced by misleading information on the compressed latent state\nduring pitch transitions. We address this issue by applying Gaussian blur on\npartial reference mel-spectrogram and adjusting loss weights in these regions.\nExtensive ablation studies demonstrate the efficiency of our method.\nEvaluations on OpenCpop, a Chinese singing dataset, show that RDSinger\noutperforms current state-of-the-art SVS methods in performance.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21641v1",
    "published_date": "2024-10-29 01:01:18 UTC",
    "updated_date": "2024-10-29 01:01:18 UTC"
  },
  {
    "arxiv_id": "2410.21640v1",
    "title": "A Tutorial on Clinical Speech AI Development: From Data Collection to Model Validation",
    "authors": [
      "Si-Ioi Ng",
      "Lingfeng Xu",
      "Ingo Siegert",
      "Nicholas Cummins",
      "Nina R. Benway",
      "Julie Liss",
      "Visar Berisha"
    ],
    "abstract": "There has been a surge of interest in leveraging speech as a marker of health\nfor a wide spectrum of conditions. The underlying premise is that any\nneurological, mental, or physical deficits that impact speech production can be\nobjectively assessed via automated analysis of speech. Recent advances in\nspeech-based Artificial Intelligence (AI) models for diagnosing and tracking\nmental health, cognitive, and motor disorders often use supervised learning,\nsimilar to mainstream speech technologies like recognition and verification.\nHowever, clinical speech AI has distinct challenges, including the need for\nspecific elicitation tasks, small available datasets, diverse speech\nrepresentations, and uncertain diagnostic labels. As a result, application of\nthe standard supervised learning paradigm may lead to models that perform well\nin controlled settings but fail to generalize in real-world clinical\ndeployments. With translation into real-world clinical scenarios in mind, this\ntutorial paper provides an overview of the key components required for robust\ndevelopment of clinical speech AI. Specifically, this paper will cover the\ndesign of speech elicitation tasks and protocols most appropriate for different\nclinical conditions, collection of data and verification of hardware,\ndevelopment and validation of speech representations designed to measure\nclinical constructs of interest, development of reliable and robust clinical\nprediction models, and ethical and participant considerations for clinical\nspeech AI. The goal is to provide comprehensive guidance on building models\nwhose inputs and outputs link to the more interpretable and clinically\nmeaningful aspects of speech, that can be interrogated and clinically validated\non clinical datasets, and that adhere to ethical, privacy, and security\nconsiderations by design.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "76 pages, 24 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.21640v1",
    "published_date": "2024-10-29 00:58:15 UTC",
    "updated_date": "2024-10-29 00:58:15 UTC"
  },
  {
    "arxiv_id": "2410.22372v1",
    "title": "A Hierarchical Language Model For Interpretable Graph Reasoning",
    "authors": [
      "Sambhav Khurana",
      "Xiner Li",
      "Shurui Gui",
      "Shuiwang Ji"
    ],
    "abstract": "Large language models (LLMs) are being increasingly explored for graph tasks.\nDespite their remarkable success in text-based tasks, LLMs' capabilities in\nunderstanding explicit graph structures remain limited, particularly with large\ngraphs. In this work, we introduce Hierarchical Language Model for Graph\n(HLM-G), which employs a two-block architecture to capture node-centric local\ninformation and interaction-centric global structure, effectively enhancing\ngraph structure understanding abilities. The proposed scheme allows LLMs to\naddress various graph queries with high efficacy, efficiency, and robustness,\nwhile reducing computational costs on large-scale graph tasks. Furthermore, we\ndemonstrate the interpretability of our model using intrinsic attention weights\nand established explainers. Comprehensive evaluations across diverse graph\nreasoning and real-world tasks of node, link, and graph-levels highlight the\nsuperiority of our method, marking a significant advancement in the application\nof LLMs to graph understanding.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22372v1",
    "published_date": "2024-10-29 00:28:02 UTC",
    "updated_date": "2024-10-29 00:28:02 UTC"
  },
  {
    "arxiv_id": "2410.21627v1",
    "title": "MCPDial: A Minecraft Persona-driven Dialogue Dataset",
    "authors": [
      "Seyed Hossein Alavi",
      "Sudha Rao",
      "Ashutosh Adhikari",
      "Gabriel A DesGarennes",
      "Akanksha Malhotra",
      "Chris Brockett",
      "Mahmoud Adada",
      "Raymond T. Ng",
      "Vered Shwartz",
      "Bill Dolan"
    ],
    "abstract": "We propose a novel approach that uses large language models (LLMs) to\ngenerate persona-driven conversations between Players and Non-Player Characters\n(NPC) in games. Showcasing the application of our methodology, we introduce the\nMinecraft Persona-driven Dialogue dataset (MCPDial). Starting with a small seed\nof expert-written conversations, we employ our method to generate hundreds of\nadditional conversations. Each conversation in the dataset includes rich\ncharacter descriptions of the player and NPC. The conversations are long,\nallowing for in-depth and extensive interactions between the player and NPC.\nMCPDial extends beyond basic conversations by incorporating canonical function\ncalls (e.g. \"Call find a resource on iron ore\") between the utterances.\nFinally, we conduct a qualitative analysis of the dataset to assess its quality\nand characteristics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21627v1",
    "published_date": "2024-10-29 00:19:55 UTC",
    "updated_date": "2024-10-29 00:19:55 UTC"
  }
]