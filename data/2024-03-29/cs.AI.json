{
  "date": "2024-03-29",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-29 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型优化、LLM（Large Language Models）应用、强化学习和医疗诊断等领域，亮点包括 LLM 在多模态任务和解释性决策中的创新进展，以及高效算法在机器人和图像处理中的表现；令人印象深刻的文章有 \"ReALM: Reference Resolution As Language Modeling\"（作者包括 Joel Ruben Antony Moniz）和 \"LLaVA-Gemma: Accelerating Multimodal Foundation Models\"，这些展示了 LLM 的实用潜力。\n\n以下是今日值得关注的论文，按主题分组，先聊重要或话题度高的文章，快速掠过次要内容。每篇论文标题以中文 + 英文形式列出，焦点放在核心贡献上。\n\n### LLM 和 AI 生成内容\n- **DataAgent: Evaluating Large Language Models' Ability to Answer Zero-Shot, Natural Language Queries**（中文：评估大语言模型零样本自然语言查询能力的 DataAgent）：主要贡献是评估 LLM（如 GPT-3.5）在零样本数据分析中的性能，使用提示工程（如 Chain-of-Thought）生成准确的代码和洞见，发现 LLM 在数据科学任务中表现出色，适用于自动化分析。\n- **Explaining Large Language Models Decisions Using Shapley Values**（中文：使用 Shapley 值解释大语言模型决策）：Behnam Mohammadi 等人的工作，利用合作博弈理论的 Shapley 值量化提示组件对 LLM 输出影响，识别“token noise”效应，强调 LLM 在模拟人类行为时需注意鲁棒性和偏差。\n- **ReALM: Reference Resolution As Language Modeling**（中文：引用解析作为语言建模的 ReALM）：作者团队包括 Joel Ruben Antony Moniz，利用 LLM 处理引用解析，显著提升了模型在多模态上下文中的性能，实现了高效的实体引用处理。\n- **LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact Language Model**（中文：使用紧凑语言模型加速多模态基础模型的 LLaVA-Gemma）：研究发现，基于 Gemma 模型的 LLaVA 通过连接器预训练和图像骨干优化，提高了多模态任务效率，但语言模型规模对性能影响不一。\n- **Gecko: Versatile Text Embeddings Distilled from Large Language Models**（中文：从大语言模型中提炼的多功能文本嵌入 Gecko）：提出从 LLM 中蒸馏文本嵌入的方法，显著提升了嵌入在 MTEB 基准上的性能，实现了高维嵌入的低内存替代。\n\n其他 LLM 相关论文，如 \"Towards Greener LLMs\"（中文：提升 LLM 推理能效的绿色方法），快速提一下：它探讨了 LLM 能效优化，但细节较常规。\n\n### 强化学习和机器人\n- **Accelerating Search-Based Planning for Multi-Robot Manipulation**（中文：加速多机器人操作的基于搜索的规划）：作者包括 Maxim Likhachev，利用启发式搜索提升多机器人路径规划效率，保持完整性和次优性保证，在高维环境中表现出色。\n- **MindArm: Mechanized Intelligent Non-Invasive Neuro-Driven Prosthetic Arm System**（中文：基于神经驱动的非侵入式机械假肢系统 MindArm）：提出低成本 EEG 驱动的假肢系统，使用 DNN 翻译脑信号，实现高准确率（如91%空闲状态），为残障辅助提供实用方案。\n- **NeuraLunaDTNet: Feedforward Neural Network-Based Routing Protocol for Delay-Tolerant Lunar Communication Networks**（中文：基于前馈神经网络的延迟容忍月球通信路由协议 NeuraLunaDTNet）：快速提一下：它使用神经网络优化月球网络路由，提升了通信效率，但应用场景较窄。\n\n### 医疗和图像处理 AI\n- **DCAE-SR: Design of a Denoising Convolutional Autoencoder for reconstructing Electrocardiograms signals at Super Resolution**（中文：用于 ECG 信号超分辨率重建的去噪卷积自编码器 DCAE-SR）：主要发现是通过自编码器实现 ECG 信号 x10 上采样和去噪，达到 state-of-the-art 性能（如 SNR 12.20 dB），提升了心血管诊断准确性。\n- **SeaBird: Segmentation in Bird's View with Dice Loss Improves Monocular 3D Detection of Large Objects**（中文：使用鸟瞰分割和 Dice Loss 提升单目 3D 大物体检测的 SeaBird）：贡献在于结合 BEV 分割和 Dice Loss，提高了单目检测鲁棒性，尤其在大物体场景，显著提升了 nuScenes 数据集的性能。\n- **Uncovering Bias in Large Vision-Language Models with Counterfactuals**（中文：通过反事实揭示大视觉语言模型偏差）：使用反事实图像测试 LVLMs 的偏差，发现输入属性（如种族）影响输出毒性和能力词生成，强调了模型公平性。\n\n其他医疗论文，如 \"Molecular Generative Adversarial Network with Multi-Property Optimization\"（中文：多属性优化的分子生成对抗网络），快速掠过：它优化了药物分子生成，但影响力不如上述。\n\n### 其他领域快速概述\n今日还有一些论文涉及时间序列、图神经网络和基准测试，如 \"TFB: Towards Comprehensive and Fair Benchmarking of Time Series Forecasting Methods\"（中文：全面公平的时间序列预测基准 TFB）和 \"MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models\"（中文：评估 LLM 映射和导航能力的基准 MANGO）。这些提供新基准，但非核心焦点，仅提一下它们提升了评估标准。\n\n总体而言，今天的论文突显了 AI 在实际应用中的潜力，尤其在 LLM 优化和医疗诊断上，但也暴露了模型偏差和泛化挑战。未来几天，继续关注这些领域的进展！",
  "papers": [
    {
      "arxiv_id": "2404.00195v2",
      "title": "Multiple-policy Evaluation via Density Estimation",
      "title_zh": "通过密度估计的多策略评估",
      "authors": [
        "Yilei Chen",
        "Aldo Pacchiano",
        "Ioannis Ch. Paschalidis"
      ],
      "abstract": "We study the multiple-policy evaluation problem where we are given a set of\n$K$ policies and the goal is to evaluate their performance (expected total\nreward over a fixed horizon) to an accuracy $\\epsilon$ with probability at\nleast $1-\\delta$. We propose an algorithm named $\\mathrm{CAESAR}$ for this\nproblem. Our approach is based on computing an approximate optimal offline\nsampling distribution and using the data sampled from it to perform the\nsimultaneous estimation of the policy values. $\\mathrm{CAESAR}$ has two phases.\nIn the first we produce coarse estimates of the visitation distributions of the\ntarget policies at a low order sample complexity rate that scales with\n$\\tilde{O}(\\frac{1}{\\epsilon})$. In the second phase, we approximate the\noptimal offline sampling distribution and compute the importance weighting\nratios for all target policies by minimizing a step-wise quadratic loss\nfunction inspired by the DualDICE \\cite{nachum2019dualdice} objective. Up to\nlow order and logarithmic terms $\\mathrm{CAESAR}$ achieves a sample complexity\n$\\tilde{O}\\left(\\frac{H^4}{\\epsilon^2}\\sum_{h=1}^H\\max_{k\\in[K]}\\sum_{s,a}\\frac{(d_h^{\\pi^k}(s,a))^2}{\\mu^*_h(s,a)}\\right)$,\nwhere $d^{\\pi}$ is the visitation distribution of policy $\\pi$, $\\mu^*$ is the\noptimal sampling distribution, and $H$ is the horizon.",
      "tldr_zh": "该论文研究了多策略评估问题，目标是通过密度估计评估一组 K 个策略的性能（即每个策略在固定时限内的期望总奖励），以达到 ε 准确度和至少 1-δ 的概率。作者提出了 CAESAR 算法，该算法分为两个阶段：第一阶段通过低阶样本复杂度 Ō(1/ε) 生成目标策略的访问分布（visitation distributions）粗略估计；第二阶段近似优化离线采样分布，并通过最小化受 DualDICE 启发的阶梯二次损失函数来计算重要性权重比率。CAESAR 的样本复杂度为 Ō(H^4 / ε^2 * ∑ 相关分布项)，其中 H 为时限，这为高效的多策略评估提供了理论基础和实用方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00195v2",
      "published_date": "2024-03-29 23:55:25 UTC",
      "updated_date": "2024-05-27 23:57:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:59:40.901893"
    },
    {
      "arxiv_id": "2404.00188v1",
      "title": "DataAgent: Evaluating Large Language Models' Ability to Answer Zero-Shot, Natural Language Queries",
      "title_zh": "翻译失败",
      "authors": [
        "Manit Mishra",
        "Abderrahman Braham",
        "Charles Marsom",
        "Bryan Chung",
        "Gavin Griffin",
        "Dakshesh Sidnerlikar",
        "Chatanya Sarin",
        "Arjun Rajaram"
      ],
      "abstract": "Conventional processes for analyzing datasets and extracting meaningful\ninformation are often time-consuming and laborious. Previous work has\nidentified manual, repetitive coding and data collection as major obstacles\nthat hinder data scientists from undertaking more nuanced labor and high-level\nprojects. To combat this, we evaluated OpenAI's GPT-3.5 as a \"Language Data\nScientist\" (LDS) that can extrapolate key findings, including correlations and\nbasic information, from a given dataset. The model was tested on a diverse set\nof benchmark datasets to evaluate its performance across multiple standards,\nincluding data science code-generation based tasks involving libraries such as\nNumPy, Pandas, Scikit-Learn, and TensorFlow, and was broadly successful in\ncorrectly answering a given data science query related to the benchmark\ndataset. The LDS used various novel prompt engineering techniques to\neffectively answer a given question, including Chain-of-Thought reinforcement\nand SayCan prompt engineering. Our findings demonstrate great potential for\nleveraging Large Language Models for low-level, zero-shot data analysis.",
      "tldr_zh": "本研究评估了大型语言模型（Large Language Models，如 GPT-3.5）作为“Language Data Scientist”（LDS）处理零-shot、自然语言查询的能力，以解决传统数据分析中手动编码和数据收集的低效问题。研究团队在多种基准数据集上测试了模型，包括生成涉及 NumPy、Pandas、Scikit-Learn 和 TensorFlow 的数据科学代码任务。模型通过创新的提示工程技术，如 Chain-of-Thought reinforcement 和 SayCan 提示，成功提取关键发现，如相关性和基本信息。结果显示，LDS 在零-shot 数据分析中表现出色，证明了大型语言模型在简化低级数据处理的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, Submitted to International Conference on AI in Cybersecurity",
      "pdf_url": "http://arxiv.org/pdf/2404.00188v1",
      "published_date": "2024-03-29 22:59:34 UTC",
      "updated_date": "2024-03-29 22:59:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:59:52.155613"
    },
    {
      "arxiv_id": "2404.00185v2",
      "title": "On Inherent Adversarial Robustness of Active Vision Systems",
      "title_zh": "关于主动视觉系统的固有对抗鲁棒性",
      "authors": [
        "Amitangshu Mukherjee",
        "Timur Ibrayev",
        "Kaushik Roy"
      ],
      "abstract": "Current Deep Neural Networks are vulnerable to adversarial examples, which\nalter their predictions by adding carefully crafted noise. Since human eyes are\nrobust to such inputs, it is possible that the vulnerability stems from the\nstandard way of processing inputs in one shot by processing every pixel with\nthe same importance. In contrast, neuroscience suggests that the human vision\nsystem can differentiate salient features by (1) switching between multiple\nfixation points (saccades) and (2) processing the surrounding with a\nnon-uniform external resolution (foveation). In this work, we advocate that the\nintegration of such active vision mechanisms into current deep learning systems\ncan offer robustness benefits. Specifically, we empirically demonstrate the\ninherent robustness of two active vision methods - GFNet and FALcon - under a\nblack box threat model. By learning and inferencing based on downsampled\nglimpses obtained from multiple distinct fixation points within an input, we\nshow that these active methods achieve (2-3) times greater robustness compared\nto a standard passive convolutional network under state-of-the-art adversarial\nattacks. More importantly, we provide illustrative and interpretable\nvisualization analysis that demonstrates how performing inference from distinct\nfixation points makes active vision methods less vulnerable to malicious\ninputs.",
      "tldr_zh": "本研究探讨了主动视觉系统的内在对抗鲁棒性，指出当前 Deep Neural Networks 容易受到 adversarial examples 的影响，而人类视觉系统通过 saccades（切换注视点）和 foveation（非均匀分辨率）处理显著特征，从而实现更强的鲁棒性。作者通过整合主动视觉机制，评估了 GFNet 和 FALcon 这两种方法，在 black box threat model 下进行学习和推理，利用多个不同注视点的下采样 glimpses。实验结果显示，这些主动方法在最先进的对抗攻击下，比标准的被动卷积网络提升 2-3 倍的鲁棒性，并通过可视化分析阐明，从不同注视点进行推理能有效降低对恶意输入的易感性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00185v2",
      "published_date": "2024-03-29 22:51:45 UTC",
      "updated_date": "2024-04-05 16:10:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:00:05.639933"
    },
    {
      "arxiv_id": "2404.01332v3",
      "title": "Explaining Large Language Models Decisions Using Shapley Values",
      "title_zh": "使用 Shapley 值解释大型语言模型的决策",
      "authors": [
        "Behnam Mohammadi"
      ],
      "abstract": "The emergence of large language models (LLMs) has opened up exciting\npossibilities for simulating human behavior and cognitive processes, with\npotential applications in various domains, including marketing research and\nconsumer behavior analysis. However, the validity of utilizing LLMs as\nstand-ins for human subjects remains uncertain due to glaring divergences that\nsuggest fundamentally different underlying processes at play and the\nsensitivity of LLM responses to prompt variations. This paper presents a novel\napproach based on Shapley values from cooperative game theory to interpret LLM\nbehavior and quantify the relative contribution of each prompt component to the\nmodel's output. Through two applications - a discrete choice experiment and an\ninvestigation of cognitive biases - we demonstrate how the Shapley value method\ncan uncover what we term \"token noise\" effects, a phenomenon where LLM\ndecisions are disproportionately influenced by tokens providing minimal\ninformative content. This phenomenon raises concerns about the robustness and\ngeneralizability of insights obtained from LLMs in the context of human\nbehavior simulation. Our model-agnostic approach extends its utility to\nproprietary LLMs, providing a valuable tool for practitioners and researchers\nto strategically optimize prompts and mitigate apparent cognitive biases. Our\nfindings underscore the need for a more nuanced understanding of the factors\ndriving LLM responses before relying on them as substitutes for human subjects\nin survey settings. We emphasize the importance of researchers reporting\nresults conditioned on specific prompt templates and exercising caution when\ndrawing parallels between human behavior and LLMs.",
      "tldr_zh": "这篇论文提出了一种基于 Shapley Values 的新方法，用于解释大型语言模型 (LLMs) 的决策行为，并量化每个提示组件对输出结果的相对贡献。作者通过离散选择实验和认知偏差调查的应用案例，揭示了 “token noise” 效应，即 LLMs 的决策往往被提供最小信息内容的 tokens 过度影响，从而质疑了 LLMs 在模拟人类行为时的鲁棒性和泛化性。该方法是模型无关的，可应用于专有 LLMs，帮助研究者优化提示并缓解潜在认知偏差，同时强调在将 LLMs 用作人类受试者替代时需谨慎，并报告特定提示模板的结果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01332v3",
      "published_date": "2024-03-29 22:49:43 UTC",
      "updated_date": "2024-11-12 01:06:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:00:16.638211"
    },
    {
      "arxiv_id": "2406.15360v1",
      "title": "Generative AI Adoption in Classroom in Context of Technology Acceptance Model (TAM) and the Innovation Diffusion Theory (IDT)",
      "title_zh": "翻译失败",
      "authors": [
        "Aashish Ghimire",
        "John Edwards"
      ],
      "abstract": "The burgeoning development of generative artificial intelligence (GenAI) and\nthe widespread adoption of large language models (LLMs) in educational settings\nhave sparked considerable debate regarding their efficacy and\nacceptability.Despite the potential benefits, the assimilation of these\ncutting-edge technologies among educators exhibits a broad spectrum of\nattitudes, from enthusiastic advocacy to profound skepticism.This study aims to\ndissect the underlying factors influencing educators' perceptions and\nacceptance of GenAI and LLMs.We conducted a survey among educators and analyzed\nthe data through the frameworks of the Technology Acceptance Model (TAM) and\nInnovation Diffusion Theory (IDT). Our investigation reveals a strong positive\ncorrelation between the perceived usefulness of GenAI tools and their\nacceptance, underscoring the importance of demonstrating tangible benefits to\neducators. Additionally, the perceived ease of use emerged as a significant\nfactor, though to a lesser extent, influencing acceptance. Our findings also\nshow that the knowledge and acceptance of these tools is not uniform,\nsuggesting that targeted strategies are required to address the specific needs\nand concerns of each adopter category to facilitate broader integration of AI\ntools.in education.",
      "tldr_zh": "本研究探讨了生成式人工智能 (GenAI) 和大型语言模型 (LLMs) 在教育环境中的采用问题，基于 Technology Acceptance Model (TAM) 和 Innovation Diffusion Theory (IDT) 框架分析教育者的感知和态度。通过对教育者进行的调查，研究发现感知有用性 (perceived usefulness) 与工具接受度呈强烈正相关，而感知易用性 (perceived ease of use) 虽重要但影响较小。结果显示，教育者的知识和接受度存在差异，因此需要针对不同采用者类别制定策略，以促进 GenAI 工具在教育中的更广泛整合。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15360v1",
      "published_date": "2024-03-29 22:41:51 UTC",
      "updated_date": "2024-03-29 22:41:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:00:28.413718"
    },
    {
      "arxiv_id": "2404.00178v1",
      "title": "Beyond Suspension: A Two-phase Methodology for Concluding Sports Leagues",
      "title_zh": "超越暂停：一种用于结束体育联盟的两阶段",
      "authors": [
        "Ali Hassanzadeh",
        "Mojtaba Hosseini",
        "John G. Turner"
      ],
      "abstract": "Problem definition: Professional sports leagues may be suspended due to\nvarious reasons such as the recent COVID-19 pandemic. A critical question the\nleague must address when re-opening is how to appropriately select a subset of\nthe remaining games to conclude the season in a shortened time frame.\nAcademic/practical relevance: Despite the rich literature on scheduling an\nentire season starting from a blank slate, concluding an existing season is\nquite different. Our approach attempts to achieve team rankings similar to that\nwhich would have resulted had the season been played out in full. Methodology:\nWe propose a data-driven model which exploits predictive and prescriptive\nanalytics to produce a schedule for the remainder of the season comprised of a\nsubset of originally-scheduled games. Our model introduces novel rankings-based\nobjectives within a stochastic optimization model, whose parameters are first\nestimated using a predictive model. We introduce a deterministic equivalent\nreformulation along with a tailored Frank-Wolfe algorithm to efficiently solve\nour problem, as well as a robust counterpart based on min-max regret. Results:\nWe present simulation-based numerical experiments from previous National\nBasketball Association (NBA) seasons 2004--2019, and show that our models are\ncomputationally efficient, outperform a greedy benchmark that approximates a\nnon-rankings-based scheduling policy, and produce interpretable results.\nManagerial implications: Our data-driven decision-making framework may be used\nto produce a shortened season with 25-50\\% fewer games while still producing an\nend-of-season ranking similar to that of the full season, had it been played.",
      "tldr_zh": "这篇论文提出了一种两阶段方法，用于在体育联赛（如NBA）因疫情等原因暂停后，选择剩余比赛的子集来结束赛季，从而实现与完整赛季相似的团队排名。方法基于数据驱动模型，结合预测分析和随机优化模型（stochastic optimization model），引入新型基于排名的目标函数，并使用确定性等价重述（deterministic equivalent reformulation）和定制的Frank-Wolfe算法，以及基于min-max regret的鲁棒对应物（robust counterpart）来高效求解。实验结果显示，该模型在2004-2019年NBA赛季模拟中计算效率高，出色于贪婪基准（greedy benchmark），并能减少25-50%的比赛数量，同时产生可解释的结果和可信的管理决策。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "90B50 (Primary) 90C06, 90C11, 90C90 (Secondary)"
      ],
      "primary_category": "math.OC",
      "comment": "32 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.00178v1",
      "published_date": "2024-03-29 22:23:35 UTC",
      "updated_date": "2024-03-29 22:23:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:00:42.302525"
    },
    {
      "arxiv_id": "2404.00172v1",
      "title": "Universal Bovine Identification via Depth Data and Deep Metric Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Asheesh Sharma",
        "Lucy Randewich",
        "William Andrew",
        "Sion Hannuna",
        "Neill Campbell",
        "Siobhan Mullan",
        "Andrew W. Dowsey",
        "Melvyn Smith",
        "Mark Hansen",
        "Tilo Burghardt"
      ],
      "abstract": "This paper proposes and evaluates, for the first time, a top-down (dorsal\nview), depth-only deep learning system for accurately identifying individual\ncattle and provides associated code, datasets, and training weights for\nimmediate reproducibility. An increase in herd size skews the cow-to-human\nratio at the farm and makes the manual monitoring of individuals more\nchallenging. Therefore, real-time cattle identification is essential for the\nfarms and a crucial step towards precision livestock farming. Underpinned by\nour previous work, this paper introduces a deep-metric learning method for\ncattle identification using depth data from an off-the-shelf 3D camera. The\nmethod relies on CNN and MLP backbones that learn well-generalised embedding\nspaces from the body shape to differentiate individuals -- requiring neither\nspecies-specific coat patterns nor close-up muzzle prints for operation. The\nnetwork embeddings are clustered using a simple algorithm such as $k$-NN for\nhighly accurate identification, thus eliminating the need to retrain the\nnetwork for enrolling new individuals. We evaluate two backbone architectures,\nResNet, as previously used to identify Holstein Friesians using RGB images, and\nPointNet, which is specialised to operate on 3D point clouds. We also present\nCowDepth2023, a new dataset containing 21,490 synchronised colour-depth image\npairs of 99 cows, to evaluate the backbones. Both ResNet and PointNet\narchitectures, which consume depth maps and point clouds, respectively, led to\nhigh accuracy that is on par with the coat pattern-based backbone.",
      "tldr_zh": "本文首次提出一种基于深度数据的顶视图深度学习系统，用于准确识别个体牛，并提供相关代码、数据集和训练权重以便复现。该系统采用Deep Metric Learning方法，利用ResNet和PointNet架构从牛的身体形状学习嵌入空间，并通过k-NN算法进行聚类，从而无需依赖牛的毛色图案或近距离鼻纹，也无需为新个体重新训练网络。实验在新的CowDepth2023数据集（包含21,490对彩色-深度图像对，来自99头牛）上评估，结果显示ResNet和PointNet的识别准确率与基于毛色图案的方法相当，为精准畜牧业提供了一个可靠的实时监控解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "LaTeX, 38 pages, 14 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.00172v1",
      "published_date": "2024-03-29 22:03:53 UTC",
      "updated_date": "2024-03-29 22:03:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:00:52.430906"
    },
    {
      "arxiv_id": "2404.00166v2",
      "title": "Uncovering Bias in Large Vision-Language Models with Counterfactuals",
      "title_zh": "翻译失败",
      "authors": [
        "Phillip Howard",
        "Anahita Bhiwandiwalla",
        "Kathleen C. Fraser",
        "Svetlana Kiritchenko"
      ],
      "abstract": "With the advent of Large Language Models (LLMs) possessing increasingly\nimpressive capabilities, a number of Large Vision-Language Models (LVLMs) have\nbeen proposed to augment LLMs with visual inputs. Such models condition\ngenerated text on both an input image and a text prompt, enabling a variety of\nuse cases such as visual question answering and multimodal chat. While prior\nstudies have examined the social biases contained in text generated by LLMs,\nthis topic has been relatively unexplored in LVLMs. Examining social biases in\nLVLMs is particularly challenging due to the confounding contributions of bias\ninduced by information contained across the text and visual modalities. To\naddress this challenging problem, we conduct a large-scale study of text\ngenerated by different LVLMs under counterfactual changes to input images.\nSpecifically, we present LVLMs with identical open-ended text prompts while\nconditioning on images from different counterfactual sets, where each set\ncontains images which are largely identical in their depiction of a common\nsubject (e.g., a doctor), but vary only in terms of intersectional social\nattributes (e.g., race and gender). We comprehensively evaluate the text\nproduced by different LVLMs under this counterfactual generation setting and\nfind that social attributes such as race, gender, and physical characteristics\ndepicted in input images can significantly influence toxicity and the\ngeneration of competency-associated words.",
      "tldr_zh": "该研究探讨了大型视觉语言模型 (LVLMs) 中的社会偏见问题，通过反事实 (counterfactuals) 方法进行大规模分析，以解决文本和视觉模态的混淆影响。作者设计实验，提供相同的文本提示，但改变输入图像中的交叉社会属性（如种族、性别和体貌特征），观察模型生成的文本变化。结果显示，这些社会属性显著影响生成的文本毒性 (toxicity) 和与能力相关的词汇，揭示了 LVLMs 在多模态输入下的潜在偏见问题。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to the CVPR 2024 Responsible Generative AI (ReGenAI)\n  Workshop",
      "pdf_url": "http://arxiv.org/pdf/2404.00166v2",
      "published_date": "2024-03-29 21:45:53 UTC",
      "updated_date": "2024-06-07 23:29:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:01:04.146809"
    },
    {
      "arxiv_id": "2406.09422v1",
      "title": "LooPIN: A PinFi protocol for decentralized computing",
      "title_zh": "LooPIN：一种用于去",
      "authors": [
        "Yunwei Mao",
        "Qi He",
        "Ju Li"
      ],
      "abstract": "Networked computing power is a critical utility in the era of artificial\nintelligence. This paper presents a novel Physical Infrastructure Finance\n(PinFi) protocol designed to facilitate the distribution of computing power\nwithin networks in a decentralized manner. Addressing the core challenges of\ncoordination, pricing, and liquidity in decentralized physical infrastructure\nnetworks (DePIN), the PinFi protocol introduces a distinctive dynamic pricing\nmechanism. It enables providers to allocate excess computing resources to a\n\"dissipative\" PinFi liquidity pool, distinct from traditional DeFi liquidity\npools, ensuring seamless access for clients at equitable, market-based prices.\nThis approach significantly reduces the costs of accessing computing power,\npotentially to as low as 1% compared to existing services, while simultaneously\nenhancing security and dependability. The PinFi protocol is poised to transform\nthe dynamics of supply and demand in computing power networks, setting a new\nstandard for efficiency and accessibility.",
      "tldr_zh": "这篇论文介绍了 LooPIN，这是一个基于 Physical Infrastructure Finance (PinFi) 协议的系统，旨在通过去中心化方式分发计算能力，以解决 Decentralized Physical Infrastructure Networks (DePIN) 中的协调、定价和流动性挑战。PinFi 协议采用动态定价机制，允许提供者将多余计算资源分配到独特的 \"dissipative\" 流动性池中，与传统 DeFi 池不同，从而确保客户以公平的市场价格无缝访问资源。该协议显著降低计算能力获取成本，可能低至现有服务的 1%，同时提升安全性和可靠性，并有望重塑计算网络的供需动态。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CE",
        "cs.CR"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.09422v1",
      "published_date": "2024-03-29 21:37:59 UTC",
      "updated_date": "2024-03-29 21:37:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:01:16.741697"
    },
    {
      "arxiv_id": "2404.01331v2",
      "title": "LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact Language Model",
      "title_zh": "LLaVA-Gemma：利用紧凑语言模型加速多模态基础模型",
      "authors": [
        "Musashi Hinck",
        "Matthew L. Olson",
        "David Cobbley",
        "Shao-Yen Tseng",
        "Vasudev Lal"
      ],
      "abstract": "We train a suite of multimodal foundation models (MMFM) using the popular\nLLaVA framework with the recently released Gemma family of large language\nmodels (LLMs). Of particular interest is the 2B parameter Gemma model, which\nprovides opportunities to construct capable small-scale MMFMs. In line with\nfindings from other papers in this space, we test the effect of ablating three\ndesign features: pretraining the connector, utilizing a more powerful image\nbackbone, and increasing the size of the language backbone. The resulting\nmodels, which we call LLaVA-Gemma, exhibit moderate performance on an array of\nevaluations, but fail to improve past the current comparably sized SOTA models.\nCloser analysis of performance shows mixed effects; skipping pretraining tends\nto reduce performance, larger vision models sometimes improve performance, and\nincreasing language model size has inconsistent effects. We publicly release\ntraining recipes, code and weights for our models for the LLaVA-Gemma models.",
      "tldr_zh": "本研究使用 LLaVA 框架和 Gemma 系列大型语言模型 (LLMs) 训练了一系列多模态基础模型 (MMFM)，特别关注 2B 参数的紧凑模型 LLaVA-Gemma，以加速小型 MMFM 的开发。研究者测试了去除预训练连接器、采用更强大的图像骨干网以及增加语言模型规模等设计特征的影响，结果显示 LLaVA-Gemma 在各种评估中表现出中等性能，但未超过当前同等规模的 SOTA 模型。进一步分析表明，跳过预训练通常会降低性能，更大的视觉模型有时有益，而语言模型规模的影响不一致；研究团队公开了模型的训练配方、代码和权重以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "CVPR 2024, MMFM workshop. Authors 1 and 2 contributed equally. Models\n  available at https://huggingface.co/intel/llava-gemma-2b/ and\n  https://huggingface.co/intel/llava-gemma-7b/ Training code at\n  https://github.com/IntelLabs/multimodal_cognitive_ai/tree/main/LLaVA-Gemma",
      "pdf_url": "http://arxiv.org/pdf/2404.01331v2",
      "published_date": "2024-03-29 21:32:50 UTC",
      "updated_date": "2024-06-10 20:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:01:28.909587"
    },
    {
      "arxiv_id": "2404.00143v1",
      "title": "Accelerating Search-Based Planning for Multi-Robot Manipulation by Leveraging Online-Generated Experiences",
      "title_zh": "翻译失败",
      "authors": [
        "Yorai Shaoul",
        "Itamar Mishani",
        "Maxim Likhachev",
        "Jiaoyang Li"
      ],
      "abstract": "An exciting frontier in robotic manipulation is the use of multiple arms at\nonce. However, planning concurrent motions is a challenging task using current\nmethods. The high-dimensional composite state space renders many well-known\nmotion planning algorithms intractable. Recently, Multi-Agent Path-Finding\n(MAPF) algorithms have shown promise in discrete 2D domains, providing rigorous\nguarantees. However, widely used conflict-based methods in MAPF assume an\nefficient single-agent motion planner. This poses challenges in adapting them\nto manipulation cases where this assumption does not hold, due to the high\ndimensionality of configuration spaces and the computational bottlenecks\nassociated with collision checking. To this end, we propose an approach for\naccelerating conflict-based search algorithms by leveraging their repetitive\nand incremental nature -- making them tractable for use in complex scenarios\ninvolving multi-arm coordination in obstacle-laden environments. We show that\nour method preserves completeness and bounded sub-optimality guarantees, and\ndemonstrate its practical efficacy through a set of experiments with up to 10\nrobotic arms.",
      "tldr_zh": "本研究针对多机器人操作中的规划挑战，特别是在高维状态空间下，传统 Multi-Agent Path-Finding (MAPF) 算法因缺乏高效单代理运动规划器而难以应用。作者提出一种方法，通过利用在线生成的经验（Online-Generated Experiences）来加速基于冲突的搜索算法，利用其重复和增量特性，使其适用于多臂协调的复杂环境。实验结果显示，该方法保持了完整性和有界次优保证，并在涉及多达 10 个机器人臂的场景中证明了其实际效能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "The first two authors contributed equally. Accepted to ICAPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.00143v1",
      "published_date": "2024-03-29 20:31:07 UTC",
      "updated_date": "2024-03-29 20:31:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:01:41.609574"
    },
    {
      "arxiv_id": "2404.00140v1",
      "title": "Does Faithfulness Conflict with Plausibility? An Empirical Study in Explainable AI across NLP Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaolei Lu",
        "Jianghong Ma"
      ],
      "abstract": "Explainability algorithms aimed at interpreting decision-making AI systems\nusually consider balancing two critical dimensions: 1) \\textit{faithfulness},\nwhere explanations accurately reflect the model's inference process. 2)\n\\textit{plausibility}, where explanations are consistent with domain experts.\nHowever, the question arises: do faithfulness and plausibility inherently\nconflict? In this study, through a comprehensive quantitative comparison\nbetween the explanations from the selected explainability methods and\nexpert-level interpretations across three NLP tasks: sentiment analysis, intent\ndetection, and topic labeling, we demonstrate that traditional\nperturbation-based methods Shapley value and LIME could attain greater\nfaithfulness and plausibility. Our findings suggest that rather than optimizing\nfor one dimension at the expense of the other, we could seek to optimize\nexplainability algorithms with dual objectives to achieve high levels of\naccuracy and user accessibility in their explanations.",
      "tldr_zh": "这篇论文探讨了在可解释 AI 中，faithfulness（解释的忠实度）和plausibility（解释的合理性）是否相互冲突的问题。研究通过在三个 NLP 任务（sentiment analysis、intent detection 和 topic labeling）上，对传统 perturbation-based 方法如 Shapley value 和 LIME 与专家解释进行定量比较。结果显示，这些方法能够同时实现较高的 faithfulness 和 plausibility，而不是非此即彼。论文建议优化解释算法以双重目标追求高准确性和用户可访问性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00140v1",
      "published_date": "2024-03-29 20:28:42 UTC",
      "updated_date": "2024-03-29 20:28:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:01:53.866949"
    },
    {
      "arxiv_id": "2404.00139v1",
      "title": "Security Risks Concerns of Generative AI in the IoT",
      "title_zh": "生成式 AI 在 IoT 中的安全风险与担忧",
      "authors": [
        "Honghui Xu",
        "Yingshu Li",
        "Olusesi Balogun",
        "Shaoen Wu",
        "Yue Wang",
        "Zhipeng Cai"
      ],
      "abstract": "In an era where the Internet of Things (IoT) intersects increasingly with\ngenerative Artificial Intelligence (AI), this article scrutinizes the emergent\nsecurity risks inherent in this integration. We explore how generative AI\ndrives innovation in IoT and we analyze the potential for data breaches when\nusing generative AI and the misuse of generative AI technologies in IoT\necosystems. These risks not only threaten the privacy and efficiency of IoT\nsystems but also pose broader implications for trust and safety in AI-driven\nenvironments. The discussion in this article extends to strategic approaches\nfor mitigating these risks, including the development of robust security\nprotocols, the multi-layered security approaches, and the adoption of AI\ntechnological solutions. Through a comprehensive analysis, this article aims to\nshed light on the critical balance between embracing AI advancements and\nensuring stringent security in IoT, providing insights into the future\ndirection of these intertwined technologies.",
      "tldr_zh": "这篇论文探讨了生成式 AI 在物联网 (IoT) 中的安全风险，强调其驱动创新的同时，可能导致数据泄露和 AI 滥用等问题，从而威胁 IoT 系统的隐私、效率以及整体信任和安全。作者分析了这些风险的广泛影响，包括对 AI 驱动环境的安全挑战，并提出了缓解策略，如开发稳健的安全协议、采用多层安全方法和整合 AI 技术解决方案。通过全面分析，该研究旨在平衡生成式 AI 的创新潜力与 IoT 的严格安全需求，为未来技术发展提供关键见解。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "6 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.00139v1",
      "published_date": "2024-03-29 20:28:30 UTC",
      "updated_date": "2024-03-29 20:28:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:02:06.031371"
    },
    {
      "arxiv_id": "2404.00137v1",
      "title": "Budget-aware Query Tuning: An AutoML Perspective",
      "title_zh": "预算感知查询调优：AutoML 视角",
      "authors": [
        "Wentao Wu",
        "Chi Wang"
      ],
      "abstract": "Modern database systems rely on cost-based query optimizers to come up with\ngood execution plans for input queries. Such query optimizers rely on cost\nmodels to estimate the costs of candidate query execution plans. A cost model\nrepresents a function from a set of cost units to query execution cost, where\neach cost unit specifies the unit cost of executing a certain type of query\nprocessing operation (such as table scan or join). These cost units are\ntraditionally viewed as constants, whose values only depend on the platform\nconfiguration where the database system runs on top of but are invariant for\nqueries processed by the database system. In this paper, we challenge this\nclassic view by thinking of these cost units as variables instead. We show\nthat, by varying the cost-unit values one can obtain query plans that\nsignificantly outperform the default query plans returned by the query\noptimizer when viewing the cost units as constants. We term this cost-unit\ntuning process \"query tuning\" (QT) and show that it is similar to the\nwell-known hyper-parameter optimization (HPO) problem in AutoML. As a result,\nany state-of-the-art HPO technologies can be applied to QT. We study the QT\nproblem in the context of anytime tuning, which is desirable in practice by\nconstraining the total time spent on QT within a given budget -- we call this\nproblem budget-aware query tuning. We further extend our study from tuning a\nsingle query to tuning a workload with multiple queries, and we call this\ngeneralized problem budget-aware workload tuning (WT), which aims for\nminimizing the execution time of the entire workload. WT is more challenging as\none needs to further prioritize individual query tuning within the given time\nbudget. We propose solutions to both QT and WT and experimental evaluation\nusing both benchmark and real workloads demonstrates the efficacy of our\nproposed solutions.",
      "tldr_zh": "该论文从 AutoML 视角挑战传统数据库查询优化器的成本单位常量假设，提出将成本单位视为变量进行 Budget-aware Query Tuning (QT)，以生成更优的查询执行计划，从而显著提升性能。QT 被类比为 Hyper-parameter Optimization (HPO)，允许应用现有 HPO 技术，并在给定时间预算内实现 anytime tuning；同时，论文扩展到 Workload Tuning (WT)，针对多个查询的工作负载进行优先级调优，以最小化整体执行时间。实验评估显示，该方法在基准和真实工作负载上有效，证明了其在数据库系统优化中的实际价值。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00137v1",
      "published_date": "2024-03-29 20:19:36 UTC",
      "updated_date": "2024-03-29 20:19:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:02:18.428907"
    },
    {
      "arxiv_id": "2404.15307v1",
      "title": "DCAE-SR: Design of a Denoising Convolutional Autoencoder for reconstructing Electrocardiograms signals at Super Resolution",
      "title_zh": "翻译失败",
      "authors": [
        "Ugo Lomoio",
        "Pierangelo Veltri",
        "Pietro Hiram Guzzi",
        "Pietro Lio'"
      ],
      "abstract": "Electrocardiogram (ECG) signals play a pivotal role in cardiovascular\ndiagnostics, providing essential information on the electrical activity of the\nheart. However, the inherent noise and limited resolution in ECG recordings can\nhinder accurate interpretation and diagnosis. In this paper, we propose a novel\nmodel for ECG super resolution (SR) that uses a DNAE to enhance temporal and\nfrequency information inside ECG signals. Our approach addresses the\nlimitations of traditional ECG signal processing techniques. Our model takes in\ninput 5-second length ECG windows sampled at 50 Hz (very low resolution) and it\nis able to reconstruct a denoised super-resolution signal with an x10\nupsampling rate (sampled at 500 Hz). We trained the proposed DCAE-SR on public\navailable myocardial infraction ECG signals. Our method demonstrates superior\nperformance in reconstructing high-resolution ECG signals from very\nlow-resolution signals with a sampling rate of 50 Hz. We compared our results\nwith the current deep-learning literature approaches for ECG super-resolution\nand some non-deep learning reproducible methods that can perform both\nsuper-resolution and denoising. We obtained current state-of-the-art\nperformances in super-resolution of very low resolution ECG signals frequently\ncorrupted by ECG artifacts. We were able to obtain a signal-to-noise ratio of\n12.20 dB (outperforms previous 4.68 dB), mean squared error of 0.0044\n(outperforms previous 0.0154) and root mean squared error of 4.86% (outperforms\nprevious 12.40%). In conclusion, our DCAE-SR model offers a robust (to artefact\npresence), versatile and explainable solution to enhance the quality of ECG\nsignals. This advancement holds promise in advancing the field of\ncardiovascular diagnostics, paving the way for improved patient care and\nhigh-quality clinical decisions",
      "tldr_zh": "本文提出 DCAE-SR 模型，这是一种基于 Denoising Convolutional Autoencoder (DNAE) 的方法，用于从低分辨率 ECG 信号重建超分辨率信号，从而解决 ECG 记录中的噪声和分辨率问题。模型以 50 Hz 采样的 5 秒 ECG 窗口作为输入，输出去噪的 500 Hz 超分辨率信号，并在公开 myocardial infarction 数据集上训练。实验结果显示，DCAE-SR 在性能上超越现有方法，实现了 state-of-the-art 的 SNR 12.20 dB、MSE 0.0044 和 RMSE 4.86%。总之，该模型为心血管诊断提供了一个鲁棒、可解释的解决方案，提升了信号质量和临床决策。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15307v1",
      "published_date": "2024-03-29 19:46:08 UTC",
      "updated_date": "2024-03-29 19:46:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:02:32.066299"
    },
    {
      "arxiv_id": "2404.00107v1",
      "title": "Robust Ensemble Person Re-Identification via Orthogonal Fusion with Occlusion Handling",
      "title_zh": "通过正",
      "authors": [
        "Syeda Nyma Ferdous",
        "Xin Li"
      ],
      "abstract": "Occlusion remains one of the major challenges in person reidentification\n(ReID) as a result of the diversity of poses and the variation of appearances.\nDeveloping novel architectures to improve the robustness of occlusion-aware\nperson Re-ID requires new insights, especially on low-resolution edge cameras.\nWe propose a deep ensemble model that harnesses both CNN and Transformer\narchitectures to generate robust feature representations. To achieve robust\nRe-ID without the need to manually label occluded regions, we propose to take\nan ensemble learning-based approach derived from the analogy between\narbitrarily shaped occluded regions and robust feature representation. Using\nthe orthogonality principle, our developed deep CNN model makes use of masked\nautoencoder (MAE) and global-local feature fusion for robust person\nidentification. Furthermore, we present a part occlusion-aware transformer\ncapable of learning feature space that is robust to occluded regions.\nExperimental results are reported on several Re-ID datasets to show the\neffectiveness of our developed ensemble model named orthogonal fusion with\nocclusion handling (OFOH). Compared to competing methods, the proposed OFOH\napproach has achieved competent rank-1 and mAP performance.",
      "tldr_zh": "该论文针对 Person Re-Identification (Re-ID) 中的遮挡问题，提出了一种鲁棒的集成模型 Orthogonal Fusion with Occlusion Handling (OFOH)，结合 CNN 和 Transformer 架构来生成对遮挡区域鲁棒的特征表示。OFOH 通过 masked autoencoder (MAE) 和全局-局部特征融合技术，避免了手动标注遮挡区域的需求，并开发了部分遮挡感知 Transformer 以增强模型的鲁棒性。实验在多个 Re-ID 数据集上表明，该方法在 rank-1 和 mAP 性能上优于竞争方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00107v1",
      "published_date": "2024-03-29 18:38:59 UTC",
      "updated_date": "2024-03-29 18:38:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:02:41.841879"
    },
    {
      "arxiv_id": "2406.16873v1",
      "title": "A Survey of Machine Learning Techniques for Improving Global Navigation Satellite Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Adyasha Mohanty",
        "Grace Gao"
      ],
      "abstract": "Global Navigation Satellite Systems (GNSS)-based positioning plays a crucial\nrole in various applications, including navigation, transportation, logistics,\nmapping, and emergency services. Traditional GNSS positioning methods are\nmodel-based and they utilize satellite geometry and the known properties of\nsatellite signals. However, model-based methods have limitations in challenging\nenvironments and often lack adaptability to uncertain noise models. This paper\nhighlights recent advances in Machine Learning (ML) and its potential to\naddress these limitations. It covers a broad range of ML methods, including\nsupervised learning, unsupervised learning, deep learning, and hybrid\napproaches. The survey provides insights into positioning applications related\nto GNSS such as signal analysis, anomaly detection, multi-sensor integration,\nprediction, and accuracy enhancement using ML. It discusses the strengths,\nlimitations, and challenges of current ML-based approaches for GNSS\npositioning, providing a comprehensive overview of the field.",
      "tldr_zh": "这篇论文调查了机器学习（Machine Learning, ML）技术在提升全球导航卫星系统（Global Navigation Satellite Systems, GNSS）定位性能方面的应用。传统基于模型的GNSS方法在挑战环境中存在局限性，如对不确定噪声模型的适应性不足，而ML方法通过supervised learning、unsupervised learning、deep learning和hybrid approaches来解决这些问题。调查涵盖了信号分析、安omaly detection、多-sensor integration、prediction和准确性增强等关键应用，并分析了这些方法的优势、limitations和challenges，提供了一个全面的领域概述。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "eess.SP",
      "comment": "Under consideration for EURASIP Journal on Advances in Signal\n  Processing",
      "pdf_url": "http://arxiv.org/pdf/2406.16873v1",
      "published_date": "2024-03-29 18:31:50 UTC",
      "updated_date": "2024-03-29 18:31:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:02:55.532848"
    },
    {
      "arxiv_id": "2404.00099v2",
      "title": "Efficient and Sharp Off-Policy Evaluation in Robust Markov Decision Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Bennett",
        "Nathan Kallus",
        "Miruna Oprescu",
        "Wen Sun",
        "Kaiwen Wang"
      ],
      "abstract": "We study the evaluation of a policy under best- and worst-case perturbations\nto a Markov decision process (MDP), using transition observations from the\noriginal MDP, whether they are generated under the same or a different policy.\nThis is an important problem when there is the possibility of a shift between\nhistorical and future environments, $\\textit{e.g.}$ due to unmeasured\nconfounding, distributional shift, or an adversarial environment. We propose a\nperturbation model that allows changes in the transition kernel densities up to\na given multiplicative factor or its reciprocal, extending the classic marginal\nsensitivity model (MSM) for single time-step decision-making to\ninfinite-horizon RL. We characterize the sharp bounds on policy value under\nthis model $\\unicode{x2013}$ $\\textit{i.e.}$, the tightest possible bounds\nbased on transition observations from the original MDP $\\unicode{x2013}$ and we\nstudy the estimation of these bounds from such transition observations. We\ndevelop an estimator with several important guarantees: it is\nsemiparametrically efficient, and remains so even when certain necessary\nnuisance functions, such as worst-case Q-functions, are estimated at slow,\nnonparametric rates. Our estimator is also asymptotically normal, enabling\nstraightforward statistical inference using Wald confidence intervals.\nMoreover, when certain nuisances are estimated inconsistently, the estimator\nstill provides valid, albeit possibly not sharp, bounds on the policy value. We\nvalidate these properties in numerical simulations. The combination of\naccounting for environment shifts from train to test (robustness), being\ninsensitive to nuisance-function estimation (orthogonality), and addressing the\nchallenge of learning from finite samples (inference) together leads to\ncredible and reliable policy evaluation.",
      "tldr_zh": "本文研究了在鲁棒Markov Decision Processes (MDP)中进行高效且精确的Off-Policy Evaluation，针对环境扰动（如分布偏移或对抗因素）使用原始MDP的转移观察数据。作者提出了一种扩展经典边际敏感性模型(MSM)的扰动模型，允许转移核密度的乘法因子变化，并表征了策略价值的sharp bounds。开发的估计器具有半参数高效性、渐近正态分布和鲁棒性，即使某些辅助函数（如最坏情况Q函数）估计不准确，也能提供有效的策略价值边界，并在数值模拟中验证了其可靠性。",
      "categories": [
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "39 pages, 2 figures, NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.00099v2",
      "published_date": "2024-03-29 18:11:49 UTC",
      "updated_date": "2024-11-01 19:00:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:03:06.916582"
    },
    {
      "arxiv_id": "2403.20331v3",
      "title": "Unsolvable Problem Detection: Robust Understanding Evaluation for Large Multimodal Models",
      "title_zh": "不可解问题检测：针对大型多模态模型的鲁棒理解评估",
      "authors": [
        "Atsuyuki Miyai",
        "Jingkang Yang",
        "Jingyang Zhang",
        "Yifei Ming",
        "Qing Yu",
        "Go Irie",
        "Yixuan Li",
        "Hai Li",
        "Ziwei Liu",
        "Kiyoharu Aizawa"
      ],
      "abstract": "This paper introduces a novel task to evaluate the robust understanding\ncapability of Large Multimodal Models (LMMs), termed $\\textbf{Unsolvable\nProblem Detection (UPD)}$. Multiple-choice question answering (MCQA) is widely\nused to assess the understanding capability of LMMs, but it does not guarantee\nthat LMMs truly comprehend the answer. UPD assesses the LMM's ability to\nwithhold answers when encountering unsolvable problems of MCQA, verifying\nwhether the model truly understands the answer. UPD encompasses three problems:\nAbsent Answer Detection (AAD), Incompatible Answer Set Detection (IASD), and\nIncompatible Visual Question Detection (IVQD), covering unsolvable cases like\nanswer-lacking or incompatible choices and image-question mismatches. For the\nevaluation, we introduce the MM-UPD Bench, a benchmark for assessing\nperformance across various ability dimensions. Our experiments reveal that even\nmost LMMs, which demonstrate adequate performance on existing benchmarks,\nstruggle significantly with MM-UPD, underscoring a novel aspect of\ntrustworthiness that current benchmarks have overlooked. A detailed analysis\nshows that LMMs have different bottlenecks and chain-of-thought and\nself-reflection improved performance for LMMs with the bottleneck in their LLM\ncapability. We hope our insights will enhance the broader understanding and\ndevelopment of more reliable LMMs.",
      "tldr_zh": "本文提出 Unsolvable Problem Detection (UPD) 任务，用于评估 Large Multimodal Models (LMMs) 的鲁棒理解能力，弥补传统 Multiple-choice question answering (MCQA) 无法验证模型真正理解答案的局限。UPD 包括三个子任务：Absent Answer Detection (AAD)、Incompatible Answer Set Detection (IASD) 和 Incompatible Visual Question Detection (IVQD)，这些子任务覆盖了答案缺失、选项不兼容以及图像问题不匹配等不可解场景。研究者开发了 MM-UPD Bench 基准，通过实验发现，即使在现有基准上表现良好的 LMMs，在 UPD 任务中也表现出显著不足，揭示了模型可靠性中的新瓶颈。进一步分析表明，chain-of-thought 和 self-reflection 技术可以改善那些在 LLM 能力上存在瓶颈的模型，从而为开发更可靠的 LMMs 提供宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code: https://github.com/AtsuMiyai/UPD. Update from v2: Correction to\n  Figure 1",
      "pdf_url": "http://arxiv.org/pdf/2403.20331v3",
      "published_date": "2024-03-29 17:59:53 UTC",
      "updated_date": "2025-04-27 19:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:03:20.089127"
    },
    {
      "arxiv_id": "2403.20329v2",
      "title": "ReALM: Reference Resolution As Language Modeling",
      "title_zh": "ReALM：引用解析作为语言建模",
      "authors": [
        "Joel Ruben Antony Moniz",
        "Soundarya Krishnan",
        "Melis Ozyildirim",
        "Prathamesh Saraf",
        "Halim Cagri Ates",
        "Yuan Zhang",
        "Hong Yu"
      ],
      "abstract": "Reference resolution is an important problem, one that is essential to\nunderstand and successfully handle context of different kinds. This context\nincludes both previous turns and context that pertains to non-conversational\nentities, such as entities on the user's screen or those running in the\nbackground. While LLMs have been shown to be extremely powerful for a variety\nof tasks, their use in reference resolution, particularly for\nnon-conversational entities, remains underutilized. This paper demonstrates how\nLLMs can be used to create an extremely effective system to resolve references\nof various types, by showing how reference resolution can be converted into a\nlanguage modeling problem, despite involving forms of entities like those on\nscreen that are not traditionally conducive to being reduced to a text-only\nmodality. We demonstrate large improvements over an existing system with\nsimilar functionality across different types of references, with our smallest\nmodel obtaining absolute gains of over 5% for on-screen references. We also\nbenchmark against GPT-3.5 and GPT-4, with our smallest model achieving\nperformance comparable to that of GPT-4, and our larger models substantially\noutperforming it.",
      "tldr_zh": "本论文提出ReALM框架，将引用解析（Reference Resolution）转化为语言建模（Language Modeling）问题，利用大型语言模型（LLMs）处理各种上下文，包括对话历史和非对话实体（如屏幕上的实体或后台程序）。这种方法通过将实体形式转换为LLMs兼容的文本模式，显著提升了引用解析的准确性。实验结果显示，ReALM的最小模型在屏幕引用上比现有系统提升超过5%的绝对性能，并与GPT-3.5和GPT-4相比，其小型模型达到GPT-4水平，而更大模型则大幅超越。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at SIGDIAL 2024 (Oral presentation)",
      "pdf_url": "http://arxiv.org/pdf/2403.20329v2",
      "published_date": "2024-03-29 17:59:06 UTC",
      "updated_date": "2024-08-19 03:06:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:03:30.381304"
    },
    {
      "arxiv_id": "2403.20327v1",
      "title": "Gecko: Versatile Text Embeddings Distilled from Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhyuk Lee",
        "Zhuyun Dai",
        "Xiaoqi Ren",
        "Blair Chen",
        "Daniel Cer",
        "Jeremy R. Cole",
        "Kai Hui",
        "Michael Boratko",
        "Rajvi Kapadia",
        "Wen Ding",
        "Yi Luan",
        "Sai Meher Karthik Duddu",
        "Gustavo Hernandez Abrego",
        "Weiqiang Shi",
        "Nithi Gupta",
        "Aditya Kusupati",
        "Prateek Jain",
        "Siddhartha Reddy Jonnalagadda",
        "Ming-Wei Chang",
        "Iftekhar Naim"
      ],
      "abstract": "We present Gecko, a compact and versatile text embedding model. Gecko\nachieves strong retrieval performance by leveraging a key idea: distilling\nknowledge from large language models (LLMs) into a retriever. Our two-step\ndistillation process begins with generating diverse, synthetic paired data\nusing an LLM. Next, we further refine the data quality by retrieving a set of\ncandidate passages for each query, and relabeling the positive and hard\nnegative passages using the same LLM. The effectiveness of our approach is\ndemonstrated by the compactness of the Gecko. On the Massive Text Embedding\nBenchmark (MTEB), Gecko with 256 embedding dimensions outperforms all existing\nentries with 768 embedding size. Gecko with 768 embedding dimensions achieves\nan average score of 66.31, competing with 7x larger models and 5x higher\ndimensional embeddings.",
      "tldr_zh": "我们介绍了 Gecko，一种紧凑且多功能的文本嵌入模型，通过从 Large Language Models (LLMs) 中蒸馏知识来提升检索性能。模型采用两步过程：首先，使用 LLM 生成多样化的合成配对数据；其次，通过检索候选段落并利用 LLM 重新标记正样本和硬负样本，进一步提升数据质量。在 Massive Text Embedding Benchmark (MTEB) 上，256 维的 Gecko 超过了所有 768 维的现有模型，而 768 维的 Gecko 达到了 66.31 的平均分数，与 7 倍更大的模型和 5 倍更高维度的嵌入相媲美。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.20327v1",
      "published_date": "2024-03-29 17:56:40 UTC",
      "updated_date": "2024-03-29 17:56:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:03:44.086854"
    },
    {
      "arxiv_id": "2403.20320v1",
      "title": "MTLoRA: A Low-Rank Adaptation Approach for Efficient Multi-Task Learning",
      "title_zh": "MTLoRA：一种用于高效多任务学习的低秩适配方法",
      "authors": [
        "Ahmed Agiza",
        "Marina Neseem",
        "Sherief Reda"
      ],
      "abstract": "Adapting models pre-trained on large-scale datasets to a variety of\ndownstream tasks is a common strategy in deep learning. Consequently,\nparameter-efficient fine-tuning methods have emerged as a promising way to\nadapt pre-trained models to different tasks while training only a minimal\nnumber of parameters. While most of these methods are designed for single-task\nadaptation, parameter-efficient training in Multi-Task Learning (MTL)\narchitectures is still unexplored. In this paper, we introduce MTLoRA, a novel\nframework for parameter-efficient training of MTL models. MTLoRA employs\nTask-Agnostic and Task-Specific Low-Rank Adaptation modules, which effectively\ndisentangle the parameter space in MTL fine-tuning, thereby enabling the model\nto adeptly handle both task specialization and interaction within MTL contexts.\nWe applied MTLoRA to hierarchical-transformer-based MTL architectures, adapting\nthem to multiple downstream dense prediction tasks. Our extensive experiments\non the PASCAL dataset show that MTLoRA achieves higher accuracy on downstream\ntasks compared to fully fine-tuning the MTL model while reducing the number of\ntrainable parameters by 3.6x. Furthermore, MTLoRA establishes a Pareto-optimal\ntrade-off between the number of trainable parameters and the accuracy of the\ndownstream tasks, outperforming current state-of-the-art parameter-efficient\ntraining methods in both accuracy and efficiency. Our code is publicly\navailable.",
      "tldr_zh": "该研究提出 MTLoRA，一种基于 Low-Rank Adaptation 的框架，用于高效的多任务学习 (Multi-Task Learning)，旨在通过参数高效微调适应预训练模型。MTLoRA 引入 Task-Agnostic 和 Task-Specific 模块来分离参数空间，实现任务专业化和交互，支持层次化变压器架构在多个下游密集预测任务中的应用。在 PASCAL 数据集实验中，MTLoRA 比完全微调模型提升下游任务准确率，同时将可训练参数减少 3.6 倍，并提供优于现有状态-of-the-art 方法的 Pareto 最优权衡。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR), 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.20320v1",
      "published_date": "2024-03-29 17:43:58 UTC",
      "updated_date": "2024-03-29 17:43:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:03:56.555186"
    },
    {
      "arxiv_id": "2403.20318v1",
      "title": "SeaBird: Segmentation in Bird's View with Dice Loss Improves Monocular 3D Detection of Large Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Abhinav Kumar",
        "Yuliang Guo",
        "Xinyu Huang",
        "Liu Ren",
        "Xiaoming Liu"
      ],
      "abstract": "Monocular 3D detectors achieve remarkable performance on cars and smaller\nobjects. However, their performance drops on larger objects, leading to fatal\naccidents. Some attribute the failures to training data scarcity or their\nreceptive field requirements of large objects. In this paper, we highlight this\nunderstudied problem of generalization to large objects. We find that modern\nfrontal detectors struggle to generalize to large objects even on nearly\nbalanced datasets. We argue that the cause of failure is the sensitivity of\ndepth regression losses to noise of larger objects. To bridge this gap, we\ncomprehensively investigate regression and dice losses, examining their\nrobustness under varying error levels and object sizes. We mathematically prove\nthat the dice loss leads to superior noise-robustness and model convergence for\nlarge objects compared to regression losses for a simplified case. Leveraging\nour theoretical insights, we propose SeaBird (Segmentation in Bird's View) as\nthe first step towards generalizing to large objects. SeaBird effectively\nintegrates BEV segmentation on foreground objects for 3D detection, with the\nsegmentation head trained with the dice loss. SeaBird achieves SoTA results on\nthe KITTI-360 leaderboard and improves existing detectors on the nuScenes\nleaderboard, particularly for large objects. Code and models at\nhttps://github.com/abhi1kumar/SeaBird",
      "tldr_zh": "该研究指出，现有单目3D检测器在小物体上表现良好，但在大物体上泛化能力不足，导致潜在事故风险，主要由于深度回归损失对大物体噪声敏感。论文通过数学证明证明Dice Loss在噪声鲁棒性和模型收敛性上优于回归损失，并提出SeaBird框架，该框架整合BEV（Bird's Eye View）分割技术，使用Dice Loss训练分割头来提升3D检测性能。实验结果显示，SeaBird在KITTI-360和nuScenes基准上实现SoTA（State-of-the-Art）成绩，尤其在大物体检测上显著改进基准模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.20318v1",
      "published_date": "2024-03-29 17:41:57 UTC",
      "updated_date": "2024-03-29 17:41:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:04:07.535010"
    },
    {
      "arxiv_id": "2403.20308v1",
      "title": "ChainNet: Structured Metaphor and Metonymy in WordNet",
      "title_zh": "ChainNet: WordNet 中的结构化隐喻和转喻",
      "authors": [
        "Rowan Hall Maudslay",
        "Simone Teufel",
        "Francis Bond",
        "James Pustejovsky"
      ],
      "abstract": "The senses of a word exhibit rich internal structure. In a typical lexicon,\nthis structure is overlooked: a word's senses are encoded as a list without\ninter-sense relations. We present ChainNet, a lexical resource which for the\nfirst time explicitly identifies these structures. ChainNet expresses how\nsenses in the Open English Wordnet are derived from one another: every nominal\nsense of a word is either connected to another sense by metaphor or metonymy,\nor is disconnected in the case of homonymy. Because WordNet senses are linked\nto resources which capture information about their meaning, ChainNet represents\nthe first dataset of grounded metaphor and metonymy.",
      "tldr_zh": "本论文介绍了 ChainNet，这是一个新词汇资源，用于明确识别 WordNet 中词汇语义的内部结构，而非简单列出。ChainNet 通过分析 metaphor（隐喻）和 metonymy（转喻）来连接 Open English Wordnet 中的名词语义，每个语义要么与其他语义相关联，要么在 homonymy（同形异义）情况下断开。ChainNet 作为第一个 grounded metaphor and metonymy 数据集，为词汇语义研究提供了基于实际含义的连接框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.20308v1",
      "published_date": "2024-03-29 17:22:53 UTC",
      "updated_date": "2024-03-29 17:22:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:04:18.967005"
    },
    {
      "arxiv_id": "2403.20306v1",
      "title": "Towards Greener LLMs: Bringing Energy-Efficiency to the Forefront of LLM Inference",
      "title_zh": "迈向更环保的大型语言模型：将能效置于大型语言模型推理的最前沿",
      "authors": [
        "Jovan Stojkovic",
        "Esha Choukse",
        "Chaojie Zhang",
        "Inigo Goiri",
        "Josep Torrellas"
      ],
      "abstract": "With the ubiquitous use of modern large language models (LLMs) across\nindustries, the inference serving for these models is ever expanding. Given the\nhigh compute and memory requirements of modern LLMs, more and more\ntop-of-the-line GPUs are being deployed to serve these models. Energy\navailability has come to the forefront as the biggest challenge for data center\nexpansion to serve these models. In this paper, we present the trade-offs\nbrought up by making energy efficiency the primary goal of LLM serving under\nperformance SLOs. We show that depending on the inputs, the model, and the\nservice-level agreements, there are several knobs available to the LLM\ninference provider to use for being energy efficient. We characterize the\nimpact of these knobs on the latency, throughput, as well as the energy. By\nexploring these trade-offs, we offer valuable insights into optimizing energy\nusage without compromising on performance, thereby paving the way for\nsustainable and cost-effective LLM deployment in data center environments.",
      "tldr_zh": "该研究探讨了在大型语言模型 (LLMs) 推理过程中提升能源效率的策略，以应对数据中心扩展面临的能源可用性挑战。论文分析了将能源效率作为首要目标时，与性能服务水平协议 (SLOs) 相关的权衡，包括调整输入、模型和各种参数对延迟、吞吐量及能源消耗的影响。通过实验探索这些权衡，研究提供了优化能源使用的宝贵见解，实现可持续且成本有效的 LLM 部署，而不牺牲整体性能。",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.DC",
        "C.0; I.2"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.20306v1",
      "published_date": "2024-03-29 17:22:48 UTC",
      "updated_date": "2024-03-29 17:22:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:04:30.376058"
    },
    {
      "arxiv_id": "2403.20300v1",
      "title": "Improving Learnt Local MAPF Policies with Heuristic Search",
      "title_zh": "翻译失败",
      "authors": [
        "Rishi Veerapaneni",
        "Qian Wang",
        "Kevin Ren",
        "Arthur Jakobsson",
        "Jiaoyang Li",
        "Maxim Likhachev"
      ],
      "abstract": "Multi-agent path finding (MAPF) is the problem of finding collision-free\npaths for a team of agents to reach their goal locations. State-of-the-art\nclassical MAPF solvers typically employ heuristic search to find solutions for\nhundreds of agents but are typically centralized and can struggle to scale when\nrun with short timeouts. Machine learning (ML) approaches that learn policies\nfor each agent are appealing as these could enable decentralized systems and\nscale well while maintaining good solution quality. Current ML approaches to\nMAPF have proposed methods that have started to scratch the surface of this\npotential. However, state-of-the-art ML approaches produce \"local\" policies\nthat only plan for a single timestep and have poor success rates and\nscalability. Our main idea is that we can improve a ML local policy by using\nheuristic search methods on the output probability distribution to resolve\ndeadlocks and enable full horizon planning. We show several model-agnostic ways\nto use heuristic search with learnt policies that significantly improve the\npolicies' success rates and scalability. To our best knowledge, we demonstrate\nthe first time ML-based MAPF approaches have scaled to high congestion\nscenarios (e.g. 20% agent density).",
      "tldr_zh": "本论文针对多代理路径查找（MAPF）问题，提出了一种将启发式搜索与学习的地方政策相结合的方法，以提升代理团队的无碰撞路径规划效率。传统 MAPF 求解器依赖中心化启发式搜索，但扩展性有限，而当前 ML 方法仅规划单时间步，导致成功率低下；论文创新性地在 ML 政策的输出概率分布上应用启发式搜索，解决死锁问题并实现全 horizons 规划。实验结果显示，这种模型无关的整合方式显著提高了政策的成功率和可扩展性，首次使 ML-based MAPF 方法扩展到高拥堵场景（如20%代理密度）。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted in ICAPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.20300v1",
      "published_date": "2024-03-29 17:16:20 UTC",
      "updated_date": "2024-03-29 17:16:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:04:43.835740"
    },
    {
      "arxiv_id": "2403.20288v2",
      "title": "Can LLMs Correct Physicians, Yet? Investigating Effective Interaction Methods in the Medical Domain",
      "title_zh": "翻译失败",
      "authors": [
        "Burcu Sayin",
        "Pasquale Minervini",
        "Jacopo Staiano",
        "Andrea Passerini"
      ],
      "abstract": "We explore the potential of Large Language Models (LLMs) to assist and\npotentially correct physicians in medical decision-making tasks. We evaluate\nseveral LLMs, including Meditron, Llama2, and Mistral, to analyze the ability\nof these models to interact effectively with physicians across different\nscenarios. We consider questions from PubMedQA and several tasks, ranging from\nbinary (yes/no) responses to long answer generation, where the answer of the\nmodel is produced after an interaction with a physician. Our findings suggest\nthat prompt design significantly influences the downstream accuracy of LLMs and\nthat LLMs can provide valuable feedback to physicians, challenging incorrect\ndiagnoses and contributing to more accurate decision-making. For example, when\nthe physician is accurate 38% of the time, Mistral can produce the correct\nanswer, improving accuracy up to 74% depending on the prompt being used, while\nLlama2 and Meditron models exhibit greater sensitivity to prompt choice. Our\nanalysis also uncovers the challenges of ensuring that LLM-generated\nsuggestions are pertinent and useful, emphasizing the need for further research\nin this area.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）是否能有效辅助并纠正医生在医疗决策中的错误，评估了 Meditron、Llama2 和 Mistral 等模型在不同互动场景下的表现。方法包括使用 PubMedQA 数据集测试从二元响应到长答案生成的任务，并分析提示设计对模型准确性的影响。结果显示，适当的提示能显著提升准确率，例如当医生准确率仅为38%时，Mistral 可将准确率提高至74%，而 Llama2 和 Meditron 对提示选择更敏感；然而，研究也强调了确保 LLM 生成建议的相关性和实用性的挑战，需要进一步优化。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for oral presentation at NAACL 2024, The 6th Clinical\n  Natural Language Processing Workshop",
      "pdf_url": "http://arxiv.org/pdf/2403.20288v2",
      "published_date": "2024-03-29 16:59:13 UTC",
      "updated_date": "2024-05-06 14:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:04:55.732713"
    },
    {
      "arxiv_id": "2403.20280v2",
      "title": "Sparsely Multimodal Data Fusion",
      "title_zh": "稀疏多模态数据融合",
      "authors": [
        "Josiah Bjorgaard"
      ],
      "abstract": "Multimodal data fusion is essential for applications requiring the\nintegration of diverse data sources, especially in the presence of incomplete\nor sparsely available modalities. This paper presents a comparative study of\nthree multimodal embedding techniques, Modal Channel Attention (MCA), Zorro,\nand Everything at Once (EAO), to evaluate their performance on sparsely\nmultimodal data. MCA introduces fusion embeddings for all combinations of input\nmodalities and uses attention masking to create distinct attention channels,\nenabling flexible and efficient data fusion. Experiments on two datasets with\nfour modalities each, CMU-MOSEI and TCGA, demonstrate that MCA outperforms\nZorro across ranking, recall, regression, and classification tasks and\noutperforms EAO across regression and classification tasks. MCA achieves\nsuperior performance by maintaining robust uniformity across unimodal and\nfusion embeddings. While EAO performs best in ranking metrics due to its\napproach of forming fusion embeddings post-inference, it underperforms in\ndownstream tasks requiring multimodal interactions. These results highlight the\nimportance of contrasting all modality combinations in constructing embedding\nspaces and offers insights into the design of multimodal architectures for\nreal-world applications with incomplete data.",
      "tldr_zh": "本论文探讨了多模态数据融合在处理不完整或稀疏模态时的关键作用，通过比较三种嵌入技术：Modal Channel Attention (MCA)、Zorro 和 Everything at Once (EAO)。MCA 通过为所有输入模态组合创建融合嵌入，并利用注意力掩码生成独立注意力通道，实现灵活高效的数据融合。实验在 CMU-MOSEI 和 TCGA 数据集上显示，MCA 在排名、召回、回归和分类任务中优于 Zorro，在回归和分类任务中优于 EAO，归功于其在单模态和融合嵌入间的鲁棒统一性。这些结果强调了对比所有模态组合的重要性，并为设计适用于真实世界不完整数据的多模态架构提供宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.20280v2",
      "published_date": "2024-03-29 16:49:40 UTC",
      "updated_date": "2025-01-02 18:31:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:05:08.123167"
    },
    {
      "arxiv_id": "2403.20266v2",
      "title": "Latxa: An Open Language Model and Evaluation Suite for Basque",
      "title_zh": "翻译失败",
      "authors": [
        "Julen Etxaniz",
        "Oscar Sainz",
        "Naiara Perez",
        "Itziar Aldabe",
        "German Rigau",
        "Eneko Agirre",
        "Aitor Ormazabal",
        "Mikel Artetxe",
        "Aitor Soroa"
      ],
      "abstract": "We introduce Latxa, a family of large language models for Basque ranging from\n7 to 70 billion parameters. Latxa is based on Llama 2, which we continue\npretraining on a new Basque corpus comprising 4.3M documents and 4.2B tokens.\nAddressing the scarcity of high-quality benchmarks for Basque, we further\nintroduce 4 multiple choice evaluation datasets: EusProficiency, comprising\n5,169 questions from official language proficiency exams; EusReading,\ncomprising 352 reading comprehension questions; EusTrivia, comprising 1,715\ntrivia questions from 5 knowledge areas; and EusExams, comprising 16,774\nquestions from public examinations. In our extensive evaluation, Latxa\noutperforms all previous open models we compare to by a large margin. In\naddition, it is competitive with GPT-4 Turbo in language proficiency and\nunderstanding, despite lagging behind in reading comprehension and\nknowledge-intensive tasks. Both the Latxa family of models, as well as our new\npretraining corpora and evaluation datasets, are publicly available under open\nlicenses. Our suite enables reproducible research on methods to build LLMs for\nlow-resource languages.",
      "tldr_zh": "我们介绍了 Latxa，这是一个基于 Llama 2 的开源大语言模型系列，针对巴斯克语从 7 亿到 70 亿参数，通过在 4.3M 文档和 4.2B tokens 的新语料库上继续预训练。论文同时发布了四个多项选择评估数据集，包括 EusProficiency（5,169 个语言熟练度考试题）、EusReading（352 个阅读理解题）、EusTrivia（1,715 个知识领域问题）和 EusExams（16,774 个公共考试题），以解决巴斯克语基准的稀缺问题。在评估中，Latxa 显著优于现有开源模型，并在语言熟练度和理解方面与 GPT-4 Turbo 竞争，尽管在阅读理解和知识密集型任务上仍有差距。这些模型、语料库和数据集以开源许可公开发布，促进低资源语言的大语言模型研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.20266v2",
      "published_date": "2024-03-29 16:16:48 UTC",
      "updated_date": "2024-09-20 11:52:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:05:19.728088"
    },
    {
      "arxiv_id": "2403.20262v3",
      "title": "ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Thibaut Thonet",
        "Jos Rozen",
        "Laurent Besacier"
      ],
      "abstract": "Research on Large Language Models (LLMs) has recently witnessed an increasing\ninterest in extending the models' context size to better capture dependencies\nwithin long documents. While benchmarks have been proposed to assess long-range\nabilities, existing efforts primarily considered generic tasks that are not\nnecessarily aligned with real-world applications. In contrast, we propose a new\nbenchmark for long-context LLMs focused on a practical meeting assistant\nscenario in which the long contexts consist of transcripts obtained by\nautomatic speech recognition, presenting unique challenges for LLMs due to the\ninherent noisiness and oral nature of such data. Our benchmark, ELITR-Bench,\naugments the existing ELITR corpus by adding 271 manually crafted questions\nwith their ground-truth answers, as well as noisy versions of meeting\ntranscripts altered to target different Word Error Rate levels. Our experiments\nwith 12 long-context LLMs on ELITR-Bench confirm the progress made across\nsuccessive generations of both proprietary and open models, and point out their\ndiscrepancies in terms of robustness to transcript noise. We also provide a\nthorough analysis of our GPT-4-based evaluation, including insights from a\ncrowdsourcing study. Our findings indicate that while GPT-4's scores align with\nhuman judges, its ability to distinguish beyond three score levels may be\nlimited.",
      "tldr_zh": "该研究提出ELITR-Bench，一个针对长上下文Large Language Models (LLMs)的基准测试，专注于实际会议助理场景，其中上下文由自动语音识别（ASR）产生的噪声口语转录组成。基准基于现有ELITR语料库，添加了271个手动创建的问题及其ground-truth答案，以及不同Word Error Rate (WER)水平的噪声版本，以评估模型对真实世界挑战的鲁棒性。在实验中，12个长上下文LLMs在ELITR-Bench上的表现显示了专有和开源模型的进步及其对转录噪声的差异性；同时，对基于GPT-4的评估分析表明，其评分与人类判断一致，但区分超过三个分数级别的能力有限。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2403.20262v3",
      "published_date": "2024-03-29 16:13:31 UTC",
      "updated_date": "2025-01-17 09:32:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:05:31.602098"
    },
    {
      "arxiv_id": "2403.20261v4",
      "title": "FABind+: Enhancing Molecular Docking through Improved Pocket Prediction and Pose Generation",
      "title_zh": "FABind+：通过改进的口袋预测和构象生成增强分子",
      "authors": [
        "Kaiyuan Gao",
        "Qizhi Pei",
        "Gongbo Zhang",
        "Jinhua Zhu",
        "Kun He",
        "Lijun Wu"
      ],
      "abstract": "Molecular docking is a pivotal process in drug discovery. While traditional\ntechniques rely on extensive sampling and simulation governed by physical\nprinciples, these methods are often slow and costly. The advent of deep\nlearning-based approaches has shown significant promise, offering increases in\nboth accuracy and efficiency. Building upon the foundational work of FABind, a\nmodel designed with a focus on speed and accuracy, we present FABind+, an\nenhanced iteration that largely boosts the performance of its predecessor. We\nidentify pocket prediction as a critical bottleneck in molecular docking and\npropose a novel methodology that significantly refines pocket prediction,\nthereby streamlining the docking process. Furthermore, we introduce\nmodifications to the docking module to enhance its pose generation\ncapabilities. In an effort to bridge the gap with conventional\nsampling/generative methods, we incorporate a simple yet effective sampling\ntechnique coupled with a confidence model, requiring only minor adjustments to\nthe regression framework of FABind. Experimental results and analysis reveal\nthat FABind+ remarkably outperforms the original FABind, achieves competitive\nstate-of-the-art performance, and delivers insightful modeling strategies. This\ndemonstrates FABind+ represents a substantial step forward in molecular docking\nand drug discovery. Our code is in https://github.com/QizhiPei/FABind.",
      "tldr_zh": "本研究提出了 FABind+，一种基于深度学习的分子对接模型，旨在通过改进 pocket prediction 和 pose generation 来提升药物发现过程的准确性和效率。相比于原 FABind，FABind+ 引入了新颖的方法来精炼 pocket prediction，并优化了 docking 模块，同时整合了简单有效的采样技术和置信度模型，以桥接传统采样方法与深度学习框架。实验结果表明，FABind+ 在性能上显著优于其前身，并实现了竞争性的 state-of-the-art 水平，为分子对接和药物发现领域提供了关键的建模策略。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "Accepted for presentation at KDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2403.20261v4",
      "published_date": "2024-03-29 16:10:34 UTC",
      "updated_date": "2025-02-24 15:39:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:05:45.615880"
    },
    {
      "arxiv_id": "2403.20252v1",
      "title": "Using LLMs to Model the Beliefs and Preferences of Targeted Populations",
      "title_zh": "翻译失败",
      "authors": [
        "Keiichi Namikoshi",
        "Alex Filipowicz",
        "David A. Shamma",
        "Rumen Iliev",
        "Candice L. Hogan",
        "Nikos Arechiga"
      ],
      "abstract": "We consider the problem of aligning a large language model (LLM) to model the\npreferences of a human population. Modeling the beliefs, preferences, and\nbehaviors of a specific population can be useful for a variety of different\napplications, such as conducting simulated focus groups for new products,\nconducting virtual surveys, and testing behavioral interventions, especially\nfor interventions that are expensive, impractical, or unethical. Existing work\nhas had mixed success using LLMs to accurately model human behavior in\ndifferent contexts. We benchmark and evaluate two well-known fine-tuning\napproaches and evaluate the resulting populations on their ability to match the\npreferences of real human respondents on a survey of preferences for battery\nelectric vehicles (BEVs). We evaluate our models against their ability to match\npopulation-wide statistics as well as their ability to match individual\nresponses, and we investigate the role of temperature in controlling the\ntrade-offs between these two. Additionally, we propose and evaluate a novel\nloss term to improve model performance on responses that require a numeric\nresponse.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型 (LLMs) 来模拟特定人群的信念、偏好和行为，适用于模拟焦点小组、虚拟调查以及测试昂贵或不切实际的行为干预。研究者基准测试了两种微调方法，并通过电池电动车 (BEVs) 偏好调查评估模型在匹配总体统计和个体响应方面的性能，同时探讨了温度参数如何平衡这些权衡。论文还提出了一种新损失函数，以改善模型对数字响应的准确性，从而提升整体模拟效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.20252v1",
      "published_date": "2024-03-29 15:58:46 UTC",
      "updated_date": "2024-03-29 15:58:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:05:56.300469"
    },
    {
      "arxiv_id": "2403.20250v1",
      "title": "Optimal Policy Learning with Observational Data in Multi-Action Scenarios: Estimation, Risk Preference, and Potential Failures",
      "title_zh": "翻译失败",
      "authors": [
        "Giovanni Cerulli"
      ],
      "abstract": "This paper deals with optimal policy learning (OPL) with observational data,\ni.e. data-driven optimal decision-making, in multi-action (or multi-arm)\nsettings, where a finite set of decision options is available. It is organized\nin three parts, where I discuss respectively: estimation, risk preference, and\npotential failures. The first part provides a brief review of the key\napproaches to estimating the reward (or value) function and optimal policy\nwithin this context of analysis. Here, I delineate the identification\nassumptions and statistical properties related to offline optimal policy\nlearning estimators. In the second part, I delve into the analysis of decision\nrisk. This analysis reveals that the optimal choice can be influenced by the\ndecision maker's attitude towards risks, specifically in terms of the trade-off\nbetween reward conditional mean and conditional variance. Here, I present an\napplication of the proposed model to real data, illustrating that the average\nregret of a policy with multi-valued treatment is contingent on the\ndecision-maker's attitude towards risk. The third part of the paper discusses\nthe limitations of optimal data-driven decision-making by highlighting\nconditions under which decision-making can falter. This aspect is linked to the\nfailure of the two fundamental assumptions essential for identifying the\noptimal choice: (i) overlapping, and (ii) unconfoundedness. Some conclusions\nend the paper.",
      "tldr_zh": "这篇论文探讨了在多行动(multi-action)场景中使用观测数据进行最优策略学习(OPL)，即数据驱动的决策优化。论文首先回顾了估计奖励函数(reward function)和最优策略(optimal policy)的关键方法，包括识别假设和离线OPL估计器的统计属性。接着，分析了决策风险(risk preference)，强调决策者对风险的态度会影响奖励条件均值和条件方差的权衡，并通过实际应用展示多值处理的平均遗憾(average regret)依赖于风险偏好。最后，论文讨论了OPL的潜在失败条件，特别是当overlapping和unconfoundedness假设失效时，决策可能出错，从而为数据驱动决策的局限性提供了警示。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.20250v1",
      "published_date": "2024-03-29 15:55:06 UTC",
      "updated_date": "2024-03-29 15:55:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:06:09.014600"
    },
    {
      "arxiv_id": "2403.20234v2",
      "title": "Artificial Neural Networks-based Real-time Classification of ENG Signals for Implanted Nerve Interfaces",
      "title_zh": "翻译失败",
      "authors": [
        "Antonio Coviello",
        "Francesco Linsalata",
        "Umberto Spagnolini",
        "Maurizio Magarini"
      ],
      "abstract": "Neuropathies are gaining higher relevance in clinical settings, as they risk\npermanently jeopardizing a person's life. To support the recovery of patients,\nthe use of fully implanted devices is emerging as one of the most promising\nsolutions. However, these devices, even if becoming an integral part of a fully\ncomplex neural nanonetwork system, pose numerous challenges. In this article,\nwe address one of them, which consists of the classification of motor/sensory\nstimuli. The task is performed by exploring four different types of artificial\nneural networks (ANNs) to extract various sensory stimuli from the\nelectroneurographic (ENG) signal measured in the sciatic nerve of rats.\nDifferent sizes of the data sets are considered to analyze the feasibility of\nthe investigated ANNs for real-time classification through a comparison of\ntheir performance in terms of accuracy, F1-score, and prediction time. The\ndesign of the ANNs takes advantage of the modelling of the ENG signal as a\nmultiple-input multiple-output (MIMO) system to describe the measures taken by\nstate-of-the-art implanted nerve interfaces. These are based on the use of\nmulti-contact cuff electrodes to achieve nanoscale spatial discrimination of\nthe nerve activity. The MIMO ENG signal model is another contribution of this\npaper. Our results show that some ANNs are more suitable for real-time\napplications, being capable of achieving accuracies over $90\\%$ for signal\nwindows of $100$ and $200\\,$ms with a low enough processing time to be\neffective for pathology recovery.",
      "tldr_zh": "本论文探讨了使用人工神经网络 (ANNs) 实现植入式神经接口中电神经图 (ENG) 信号的实时分类，以支持神经病变患者的恢复。研究团队探索了四种不同类型的 ANNs，从大鼠坐骨神经的 ENG 信号中提取运动/感觉刺激，并将 ENG 信号建模为多输入多输出 (MIMO) 系统，以实现纳米级空间分辨率，这也是论文的一项关键贡献。实验结果表明，某些 ANNs 在 100 和 200 ms 的信号窗口中达到超过 90% 的准确率和 F1-score，同时保持较低的预测时间，证明其适用于实时临床应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.20234v2",
      "published_date": "2024-03-29 15:23:30 UTC",
      "updated_date": "2024-04-02 09:26:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:06:22.487026"
    },
    {
      "arxiv_id": "2403.20221v1",
      "title": "Graph Neural Aggregation-diffusion with Metastability",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiyuan Cui",
        "Xinyan Wang",
        "Zicheng Zhang",
        "Weichen Zhao"
      ],
      "abstract": "Continuous graph neural models based on differential equations have expanded\nthe architecture of graph neural networks (GNNs). Due to the connection between\ngraph diffusion and message passing, diffusion-based models have been widely\nstudied. However, diffusion naturally drives the system towards an equilibrium\nstate, leading to issues like over-smoothing. To this end, we propose GRADE\ninspired by graph aggregation-diffusion equations, which includes the delicate\nbalance between nonlinear diffusion and aggregation induced by interaction\npotentials. The node representations obtained through aggregation-diffusion\nequations exhibit metastability, indicating that features can aggregate into\nmultiple clusters. In addition, the dynamics within these clusters can persist\nfor long time periods, offering the potential to alleviate over-smoothing\neffects. This nonlinear diffusion in our model generalizes existing\ndiffusion-based models and establishes a connection with classical GNNs. We\nprove that GRADE achieves competitive performance across various benchmarks and\nalleviates the over-smoothing issue in GNNs evidenced by the enhanced Dirichlet\nenergy.",
      "tldr_zh": "本研究提出了一种名为 GRADE 的图神经网络（Graph Neural Networks, GNNs）模型，基于图聚合-扩散方程（graph aggregation-diffusion equations），通过平衡非线性扩散和交互势诱导的聚合，实现节点表示的元稳定性（metastability）。这种设计允许特征聚集成多个集群，同时维持集群内动态的持久性，从而有效缓解 GNNs 中的过度平滑（over-smoothing）问题。实验结果显示，GRADE 在各种基准测试中表现出竞争性能，并通过增强的 Dirichlet energy 证明了其在保持特征多样性方面的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.20221v1",
      "published_date": "2024-03-29 15:05:57 UTC",
      "updated_date": "2024-03-29 15:05:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:06:31.688966"
    },
    {
      "arxiv_id": "2403.20216v4",
      "title": "Distributed agency in second language learning and teaching through generative AI",
      "title_zh": "通过生成式 AI 在第二语言学习和教学中的分布式代理",
      "authors": [
        "Robert Godwin-Jones"
      ],
      "abstract": "Generative AI offers significant opportunities for language learning. Tools\nlike ChatGPT can provide informal second language practice through chats in\nwritten or voice forms, with the learner specifying through prompts\nconversational parameters such as proficiency level, language register, and\ndiscussion topics. AI can be instructed to give corrective feedback, create\npractice exercises, or develop an extended study plan. Instructors can use AI\nto build learning and assessment materials in a variety of media. AI is likely\nto make immersive technologies more powerful and versatile, moving away from\nscripted interactions. For both learners and teachers, it is important to\nunderstand the limitations of AI systems that arise from their purely\nstatistical model of human language, which limits their ability to deal with\nnuanced social and cultural aspects of language use. Additionally, there are\nethical concerns over how AI systems are created as well as practical\nconstraints in their use, especially for less privileged populations. The power\nand versatility of AI tools are likely to turn them into valuable and constant\ncompanions in many peoples lives (akin to smartphones), creating a close\nconnection that goes beyond simple tool use. Ecological theories such as\nsociomaterialism are helpful in examining the shared agency that develops\nthrough close user-AI interactions, as are the perspectives on human-object\nrelations from Indigenous cultures.",
      "tldr_zh": "这篇论文探讨了generative AI（如ChatGPT）在第二语言学习和教学中的潜力，强调其能通过聊天互动提供非正式实践、corrective feedback、练习设计和学习计划，帮助学习者指定参数如熟练度、语言风格和话题，同时教师可用于创建多媒体材料。论文指出AI将增强沉浸式技术，但受限于其统计模型，无法有效处理语言的微妙社会和文化方面，并存在道德问题和实际约束，尤其是对弱势群体。作者引入sociomaterialism等生态理论和Indigenous cultures的观点，分析用户与AI互动中形成的distributed agency，强调AI可能成为日常生活中的常伴工具。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "26 pages. Published in Language Learning & Technology, volume 28,\n  issue 2, pp. 5-31: http://doi.org/10125/73570",
      "pdf_url": "http://arxiv.org/pdf/2403.20216v4",
      "published_date": "2024-03-29 14:55:40 UTC",
      "updated_date": "2024-05-31 14:17:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:06:44.685827"
    },
    {
      "arxiv_id": "2403.20212v2",
      "title": "On Size and Hardness Generalization in Unsupervised Learning for the Travelling Salesman Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Yimeng Min",
        "Carla P. Gomes"
      ],
      "abstract": "We study the generalization capability of Unsupervised Learning in solving\nthe Travelling Salesman Problem (TSP). We use a Graph Neural Network (GNN)\ntrained with a surrogate loss function to generate an embedding for each node.\nWe use these embeddings to construct a heat map that indicates the likelihood\nof each edge being part of the optimal route. We then apply local search to\ngenerate our final predictions. Our investigation explores how different\ntraining instance sizes, embedding dimensions, and distributions influence the\noutcomes of Unsupervised Learning methods. Our results show that training with\nlarger instance sizes and increasing embedding dimensions can build a more\neffective representation, enhancing the model's ability to solve TSP.\nFurthermore, in evaluating generalization across different distributions, we\nfirst determine the hardness of various distributions and explore how different\nhardnesses affect the final results. Our findings suggest that models trained\non harder instances exhibit better generalization capabilities, highlighting\nthe importance of selecting appropriate training instances in solving TSP using\nUnsupervised Learning.",
      "tldr_zh": "本论文探讨了无监督学习在解决 Travelling Salesman Problem (TSP) 时的泛化能力，使用 Graph Neural Network (GNN) 训练代理损失函数生成节点嵌入，并通过构建热图表示边在最优路径中的概率，随后应用局部搜索优化最终预测。研究发现，采用更大的训练实例大小和更高的嵌入维度能构建更有效的表示，从而提升模型解决 TSP 的性能。在不同分布的泛化评估中，模型在更难实例上训练时表现出更好的泛化能力，突出了选择适当训练数据的关键作用。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.20212v2",
      "published_date": "2024-03-29 14:47:54 UTC",
      "updated_date": "2024-11-19 15:23:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:06:56.963961"
    },
    {
      "arxiv_id": "2403.20208v7",
      "title": "Unleashing the Potential of Large Language Models for Predictive Tabular Tasks in Data Science",
      "title_zh": "释放大型语言模型在数据科学中预测性表格任务的潜力",
      "authors": [
        "Yazheng Yang",
        "Yuqi Wang",
        "Yaxuan Li",
        "Sankalok Sen",
        "Lei Li",
        "Qi Liu"
      ],
      "abstract": "In the domain of data science, the predictive tasks of classification,\nregression, and imputation of missing values are commonly encountered\nchallenges associated with tabular data. This research endeavors to apply Large\nLanguage Models (LLMs) towards addressing these predictive tasks. Despite their\nproficiency in comprehending natural language, LLMs fall short in dealing with\nstructured tabular data. This limitation stems from their lacking exposure to\nthe intricacies of tabular data during their foundational training. Our\nresearch aims to mitigate this gap by compiling a comprehensive corpus of\ntables annotated with instructions and executing large-scale training of\nLlama-2 on this enriched dataset. Furthermore, we investigate the practical\napplication of applying the trained model to zero-shot prediction, few-shot\nprediction, and in-context learning scenarios. Through extensive experiments,\nour methodology has shown significant improvements over existing benchmarks.\nThese advancements highlight the efficacy of tailoring LLM training to solve\ntable-related problems in data science, thereby establishing a new benchmark in\nthe utilization of LLMs for enhancing tabular intelligence.",
      "tldr_zh": "该研究探讨了如何利用大型语言模型（LLMs）处理数据科学中表格数据的预测任务，包括分类、回归和缺失值填充。针对LLMs在处理结构化表格数据时的局限性，研究者编译了一个包含指令注解的全面表格语料库，并对Llama-2进行大规模训练，以提升其适应性。实验结果显示，该方法在零样本预测、少样本预测和上下文学习场景中显著优于现有基准，确立了LLMs在提升表格智能方面的全新标准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.20208v7",
      "published_date": "2024-03-29 14:41:21 UTC",
      "updated_date": "2025-01-25 13:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:07:06.889772"
    },
    {
      "arxiv_id": "2403.20204v1",
      "title": "The Future of Combating Rumors? Retrieval, Discrimination, and Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Junhao Xu",
        "Longdi Xian",
        "Zening Liu",
        "Mingliang Chen",
        "Qiuyang Yin",
        "Fenghua Song"
      ],
      "abstract": "Artificial Intelligence Generated Content (AIGC) technology development has\nfacilitated the creation of rumors with misinformation, impacting societal,\neconomic, and political ecosystems, challenging democracy. Current rumor\ndetection efforts fall short by merely labeling potentially misinformation\n(classification task), inadequately addressing the issue, and it is unrealistic\nto have authoritative institutions debunk every piece of information on social\nmedia. Our proposed comprehensive debunking process not only detects rumors but\nalso provides explanatory generated content to refute the authenticity of the\ninformation. The Expert-Citizen Collective Wisdom (ECCW) module we designed\naensures high-precision assessment of the credibility of information and the\nretrieval module is responsible for retrieving relevant knowledge from a\nReal-time updated debunking database based on information keywords. By using\nprompt engineering techniques, we feed results and knowledge into a LLM (Large\nLanguage Model), achieving satisfactory discrimination and explanatory effects\nwhile eliminating the need for fine-tuning, saving computational costs, and\ncontributing to debunking efforts.",
      "tldr_zh": "该研究针对 AIGC 技术导致的谣言泛滥及其对社会、经济和政治的影响，提出一个全面辟谣过程，不仅检测信息真伪，还生成解释内容进行反驳。核心方法包括 ECCW（Expert-Citizen Collective Wisdom）模块用于高精度评估信息可信度、检索模块从实时更新的数据库中提取相关知识，以及通过提示工程将结果输入 LLM（Large Language Model），实现有效的 Discrimination 和 Generation，而无需模型微调。该框架节省计算成本，并展示了在社交媒体辟谣中的潜在应用潜力。",
      "categories": [
        "cs.AI",
        "68T99"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.20204v1",
      "published_date": "2024-03-29 14:32:41 UTC",
      "updated_date": "2024-03-29 14:32:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:07:20.646925"
    },
    {
      "arxiv_id": "2403.20199v2",
      "title": "NeuraLunaDTNet: Feedforward Neural Network-Based Routing Protocol for Delay-Tolerant Lunar Communication Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Parth Patel",
        "Milena Radenkovic"
      ],
      "abstract": "Space Communication poses challenges such as severe delays, hard-to-predict\nroutes and communication disruptions. The Delay Tolerant Network architecture,\nhaving been specifically designed keeping such scenarios in mind, is suitable\nto address some challenges. The traditional DTN routing protocols fall short of\ndelivering optimal performance, due to the inherent complexities of space\ncommunication. Researchers have aimed at using recent advancements in AI to\nmitigate some routing challenges [9]. We propose utilising a feedforward neural\nnetwork to develop a novel protocol NeuraLunaDTNet, which enhances the\nefficiency of the PRoPHET routing protocol for lunar communication, by learning\ncontact plans in dynamically changing spatio-temporal graph.",
      "tldr_zh": "该论文针对太空通信的延迟、不可预测路由和中断等挑战，提出了一种基于前馈神经网络(feedforward neural network)的路由协议NeuraLunaDTNet，以提升Delay Tolerant Network (DTN)架构的性能。具体而言，该协议通过学习动态变化的时空图中的联系计划，优化了PRoPHET路由协议在月球通信网络中的效率。研究结果表明，这种AI驱动方法有助于缓解传统DTN协议的不足，为更可靠的太空通信提供新途径。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.20199v2",
      "published_date": "2024-03-29 14:24:15 UTC",
      "updated_date": "2024-04-07 08:40:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:07:32.811870"
    },
    {
      "arxiv_id": "2403.20188v1",
      "title": "Distributed Swarm Learning for Edge Internet of Things",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Wang",
        "Zhi Tian",
        "FXin Fan",
        "Zhipeng Cai",
        "Cameron Nowzari",
        "Kai Zeng"
      ],
      "abstract": "The rapid growth of Internet of Things (IoT) has led to the widespread\ndeployment of smart IoT devices at wireless edge for collaborative machine\nlearning tasks, ushering in a new era of edge learning. With a huge number of\nhardware-constrained IoT devices operating in resource-limited wireless\nnetworks, edge learning encounters substantial challenges, including\ncommunication and computation bottlenecks, device and data heterogeneity,\nsecurity risks, privacy leakages, non-convex optimization, and complex wireless\nenvironments. To address these issues, this article explores a novel framework\nknown as distributed swarm learning (DSL), which combines artificial\nintelligence and biological swarm intelligence in a holistic manner. By\nharnessing advanced signal processing and communications, DSL provides\nefficient solutions and robust tools for large-scale IoT at the edge of\nwireless networks.",
      "tldr_zh": "互联网事物 (IoT) 的快速发展导致了大量硬件受限设备的边缘学习面临诸多挑战，包括通信和计算瓶颈、设备及数据异质性、安全风险、隐私泄露、非凸优化和复杂无线环境。\n\n本文提出分布式群集学习 (Distributed Swarm Learning, DSL) 框架，将人工智能与生物群集智能相结合，针对这些问题提供整体解决方案。\n\n通过利用先进的信号处理和通信技术，DSL 为大规模边缘 IoT 网络提供高效、鲁棒的工具和方法。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2210.16705",
      "pdf_url": "http://arxiv.org/pdf/2403.20188v1",
      "published_date": "2024-03-29 14:05:40 UTC",
      "updated_date": "2024-03-29 14:05:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:07:45.240862"
    },
    {
      "arxiv_id": "2403.20183v3",
      "title": "HARMamba: Efficient and Lightweight Wearable Sensor Human Activity Recognition Based on Bidirectional Mamba",
      "title_zh": "HARMamba",
      "authors": [
        "Shuangjian Li",
        "Tao Zhu",
        "Furong Duan",
        "Liming Chen",
        "Huansheng Ning",
        "Christopher Nugent",
        "Yaping Wan"
      ],
      "abstract": "Wearable sensor-based human activity recognition (HAR) is a critical research\ndomain in activity perception. However, achieving high efficiency and long\nsequence recognition remains a challenge. Despite the extensive investigation\nof temporal deep learning models, such as CNNs, RNNs, and transformers, their\nextensive parameters often pose significant computational and memory\nconstraints, rendering them less suitable for resource-constrained mobile\nhealth applications. This study introduces HARMamba, an innovative light-weight\nand versatile HAR architecture that combines selective bidirectional State\nSpaces Model and hardware-aware design. To optimize real-time resource\nconsumption in practical scenarios, HARMamba employs linear recursive\nmechanisms and parameter discretization, allowing it to selectively focus on\nrelevant input sequences while efficiently fusing scan and recompute\noperations. The model employs independent channels to process sensor data\nstreams, dividing each channel into patches and appending classification tokens\nto the end of the sequence. It utilizes position embedding to represent the\nsequence order. The patch sequence is subsequently processed by HARMamba Block,\nand the classification head finally outputs the activity category. The HARMamba\nBlock serves as the fundamental component of the HARMamba architecture,\nenabling the effective capture of more discriminative activity sequence\nfeatures. HARMamba outperforms contemporary state-of-the-art frameworks,\ndelivering comparable or better accuracy with significantly reducing\ncomputational and memory demands. It's effectiveness has been extensively\nvalidated on 4 publically available datasets namely PAMAP2, WISDM, UNIMIB SHAR\nand UCI. The F1 scores of HARMamba on the four datasets are 99.74%, 99.20%,\n88.23% and 97.01%, respectively.",
      "tldr_zh": "这篇论文提出了 HARMamba，一种基于 bidirectional State Spaces Model 的轻量级可穿戴传感器人类活动识别 (HAR) 架构，旨在解决传统模型如 CNNs、RNNs 和 transformers 在资源受限移动健康应用中的计算和内存问题。HARMamba 通过线性递归机制、参数离散化以及 HARMamba Block 来处理传感器数据序列，将每个通道分成 patches、添加分类 tokens 并利用位置嵌入，实现对相关输入的 selective focusing 和高效特征提取。在四个公开数据集（PAMAP2、WISDM、UNIMIB SHAR 和 UCI）上验证，HARMamba 的 F1 分数分别为 99.74%、99.20%、88.23% 和 97.01%，在保持或提升准确率的同时显著降低了资源需求。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.20183v3",
      "published_date": "2024-03-29 13:57:46 UTC",
      "updated_date": "2024-08-08 09:40:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:07:59.255552"
    },
    {
      "arxiv_id": "2403.20177v3",
      "title": "Preliminaries to artificial consciousness: a multidimensional heuristic approach",
      "title_zh": "人工智能意识的初步探讨：一种多维度的启发式方法",
      "authors": [
        "K. Evers",
        "M. Farisco",
        "R. Chatila",
        "B. D. Earp",
        "I. T. Freire",
        "F. Hamker",
        "E. Nemeth",
        "P. F. M. J. Verschure",
        "M. Khamassi"
      ],
      "abstract": "The pursuit of artificial consciousness requires conceptual clarity to\nnavigate its theoretical and empirical challenges. This paper introduces a\ncomposite, multilevel, and multidimensional model of consciousness as a\nheuristic framework to guide research in this field. Consciousness is treated\nas a complex phenomenon, with distinct constituents and dimensions that can be\noperationalized for study and for evaluating their replication. We argue that\nthis model provides a balanced approach to artificial consciousness research by\navoiding binary thinking (e.g., conscious vs. non-conscious) and offering a\nstructured basis for testable hypotheses. To illustrate its utility, we focus\non \"awareness\" as a case study, demonstrating how specific dimensions of\nconsciousness can be pragmatically analyzed and targeted for potential\nartificial instantiation. By breaking down the conceptual intricacies of\nconsciousness and aligning them with practical research goals, this paper lays\nthe groundwork for a robust strategy to advance the scientific and technical\nunderstanding of artificial consciousness.",
      "tldr_zh": "本论文探讨了人工意识（artificial consciousness）研究的理论与实证挑战，提出一个复合、多层次、多维度的意识模型作为启发式框架，以指导相关研究。模型将意识视为复杂现象，将其组成部分和维度操作化，便于评估和复制，同时避免二元思维（如意识 vs. 非意识），并提供可测试假设的结构基础。以“awareness”作为案例研究，论文展示了如何分析意识的具体维度并针对其进行人工实例化。通过分解意识概念并与实际研究目标对齐，该框架为推进人工意识的科学和技术理解奠定了坚实基础。",
      "categories": [
        "cs.AI",
        "cs.RO",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.20177v3",
      "published_date": "2024-03-29 13:47:47 UTC",
      "updated_date": "2025-01-02 10:09:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:08:09.153698"
    },
    {
      "arxiv_id": "2404.08664v1",
      "title": "Identifying Banking Transaction Descriptions via Support Vector Machine Short-Text Classification Based on a Specialized Labelled Corpus",
      "title_zh": "翻译失败",
      "authors": [
        "Silvia García-Méndez",
        "Milagros Fernández-Gavilanes",
        "Jonathan Juncal-Martínez",
        "Francisco J. González-Castaño",
        "Oscar Barba Seara"
      ],
      "abstract": "Short texts are omnipresent in real-time news, social network commentaries,\netc. Traditional text representation methods have been successfully applied to\nself-contained documents of medium size. However, information in short texts is\noften insufficient, due, for example, to the use of mnemonics, which makes them\nhard to classify. Therefore, the particularities of specific domains must be\nexploited. In this article we describe a novel system that combines Natural\nLanguage Processing techniques with Machine Learning algorithms to classify\nbanking transaction descriptions for personal finance management, a problem\nthat was not previously considered in the literature. We trained and tested\nthat system on a labelled dataset with real customer transactions that will be\navailable to other researchers on request. Motivated by existing solutions in\nspam detection, we also propose a short text similarity detector to reduce\ntraining set size based on the Jaccard distance. Experimental results with a\ntwo-stage classifier combining this detector with a SVM indicate a high\naccuracy in comparison with alternative approaches, taking into account\ncomplexity and computing time. Finally, we present a use case with a personal\nfinance application, CoinScrap, which is available at Google Play and App\nStore.",
      "tldr_zh": "这篇论文针对短文本分类的挑战，特别是银行交易描述中信息不足的问题（如使用缩写），提出了一种结合 Natural Language Processing (NLP) 和 Machine Learning (ML) 的新系统。系统利用一个专门的标记数据集（labelled corpus）训练，并引入基于 Jaccard distance 的短文本相似性检测器来减少训练集大小，然后通过两阶段分类器（结合 Support Vector Machine (SVM)）实现高准确率分类。实验结果显示，该方法在复杂性和计算时间方面优于其他方法，并应用于实际个人财务管理应用 CoinScrap。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08664v1",
      "published_date": "2024-03-29 13:15:46 UTC",
      "updated_date": "2024-03-29 13:15:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:08:23.689768"
    },
    {
      "arxiv_id": "2403.20158v1",
      "title": "ChatGPT v.s. Media Bias: A Comparative Study of GPT-3.5 and Fine-tuned Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zehao Wen",
        "Rabih Younes"
      ],
      "abstract": "In our rapidly evolving digital sphere, the ability to discern media bias\nbecomes crucial as it can shape public sentiment and influence pivotal\ndecisions. The advent of large language models (LLMs), such as ChatGPT, noted\nfor their broad utility in various natural language processing (NLP) tasks,\ninvites exploration of their efficacy in media bias detection. Can ChatGPT\ndetect media bias? This study seeks to answer this question by leveraging the\nMedia Bias Identification Benchmark (MBIB) to assess ChatGPT's competency in\ndistinguishing six categories of media bias, juxtaposed against fine-tuned\nmodels such as BART, ConvBERT, and GPT-2. The findings present a dichotomy:\nChatGPT performs at par with fine-tuned models in detecting hate speech and\ntext-level context bias, yet faces difficulties with subtler elements of other\nbias detections, namely, fake news, racial, gender, and cognitive biases.",
      "tldr_zh": "这项研究比较了 ChatGPT (GPT-3.5) 与微调语言模型（如 BART、ConvBERT 和 GPT-2）在媒体偏见检测中的性能，旨在评估大型语言模型 (LLMs) 是否能有效识别媒体偏见。研究利用 Media Bias Identification Benchmark (MBIB) 作为基准，测试 ChatGPT 在区分六种偏见类别（包括仇恨言论、文本级上下文偏见、假新闻、种族偏见、性别偏见和认知偏见）方面的能力。结果显示，ChatGPT 在检测仇恨言论和文本级上下文偏见时与微调模型表现相当，但对假新闻、种族、性别和认知偏见等更微妙类别存在困难，这突显了 LLMs 在媒体偏见识别中的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 1 figure, published on Applied and Computational Engineering",
      "pdf_url": "http://arxiv.org/pdf/2403.20158v1",
      "published_date": "2024-03-29 13:12:09 UTC",
      "updated_date": "2024-03-29 13:12:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:08:35.489878"
    },
    {
      "arxiv_id": "2403.20156v2",
      "title": "CAESAR: Enhancing Federated RL in Heterogeneous MDPs through Convergence-Aware Sampling with Screening",
      "title_zh": "翻译失败",
      "authors": [
        "Hei Yi Mak",
        "Flint Xiaofeng Fan",
        "Luca A. Lanzendörfer",
        "Cheston Tan",
        "Wei Tsang Ooi",
        "Roger Wattenhofer"
      ],
      "abstract": "In this study, we delve into Federated Reinforcement Learning (FedRL) in the\ncontext of value-based agents operating across diverse Markov Decision\nProcesses (MDPs). Existing FedRL methods typically aggregate agents' learning\nby averaging the value functions across them to improve their performance.\nHowever, this aggregation strategy is suboptimal in heterogeneous environments\nwhere agents converge to diverse optimal value functions. To address this\nproblem, we introduce the Convergence-AwarE SAmpling with scReening (CAESAR)\naggregation scheme designed to enhance the learning of individual agents across\nvaried MDPs. CAESAR is an aggregation strategy used by the server that combines\nconvergence-aware sampling with a screening mechanism. By exploiting the fact\nthat agents learning in identical MDPs are converging to the same optimal value\nfunction, CAESAR enables the selective assimilation of knowledge from more\nproficient counterparts, thereby significantly enhancing the overall learning\nefficiency. We empirically validate our hypothesis and demonstrate the\neffectiveness of CAESAR in enhancing the learning efficiency of agents, using\nboth a custom-built GridWorld environment and the classical FrozenLake-v1 task,\neach presenting varying levels of environmental heterogeneity.",
      "tldr_zh": "本研究探讨了在异构 Markov Decision Processes (MDPs) 中应用 Federated Reinforcement Learning (FedRL)，针对现有方法通过平均价值函数聚合代理学习的问题，该方法在多样化环境中效率低下。作者提出 CAESAR 聚合方案，结合 Convergence-Aware Sampling 和 Screening 机制，通过识别代理在相同 MDPs 中收敛到相同最优价值函数的事实，选择性地从更熟练代理吸收知识，从而提升整体学习效率。在自定义的 GridWorld 环境和 FrozenLake-v1 任务上进行的实验验证了 CAESAR 的有效性，显著提高了代理的学习效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.20156v2",
      "published_date": "2024-03-29 13:05:59 UTC",
      "updated_date": "2024-04-16 20:31:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:08:47.021503"
    },
    {
      "arxiv_id": "2403.20151v2",
      "title": "A Learning-based Incentive Mechanism for Mobile AIGC Service in Decentralized Internet of Vehicles",
      "title_zh": "一种基于学习的激励机制，用于去中心化车辆互联网中的移动 AIGC 服务",
      "authors": [
        "Jiani Fan",
        "Minrui Xu",
        "Ziyao Liu",
        "Huanyi Ye",
        "Chaojie Gu",
        "Dusit Niyato",
        "Kwok-Yan Lam"
      ],
      "abstract": "Artificial Intelligence-Generated Content (AIGC) refers to the paradigm of\nautomated content generation utilizing AI models. Mobile AIGC services in the\nInternet of Vehicles (IoV) network have numerous advantages over traditional\ncloud-based AIGC services, including enhanced network efficiency, better\nreconfigurability, and stronger data security and privacy. Nonetheless, AIGC\nservice provisioning frequently demands significant resources. Consequently,\nresource-constrained roadside units (RSUs) face challenges in maintaining a\nheterogeneous pool of AIGC services and addressing all user service requests\nwithout degrading overall performance. Therefore, in this paper, we propose a\ndecentralized incentive mechanism for mobile AIGC service allocation, employing\nmulti-agent deep reinforcement learning to find the balance between the supply\nof AIGC services on RSUs and user demand for services within the IoV context,\noptimizing user experience and minimizing transmission latency. Experimental\nresults demonstrate that our approach achieves superior performance compared to\nother baseline models.",
      "tldr_zh": "该论文探讨了AI生成内容（AIGC）在去中心化车联网（IoV）中的移动服务优势，包括提升网络效率、重新配置性和数据安全隐私，但资源受限的路侧单位（RSUs）难以满足用户需求。作者提出了一种基于学习的激励机制，使用多代理深度强化学习（multi-agent deep reinforcement learning）来平衡RSUs上的AIGC服务供应与用户需求，优化用户体验并最小化传输延迟。作为主要贡献，该机制在实验中表现出色，比其他基线模型实现了更好的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "2023 IEEE 98th Vehicular Technology Conference (VTC2023-Fall)",
      "pdf_url": "http://arxiv.org/pdf/2403.20151v2",
      "published_date": "2024-03-29 12:46:07 UTC",
      "updated_date": "2024-05-09 08:49:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:08:57.978265"
    },
    {
      "arxiv_id": "2403.20150v3",
      "title": "TFB: Towards Comprehensive and Fair Benchmarking of Time Series Forecasting Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangfei Qiu",
        "Jilin Hu",
        "Lekui Zhou",
        "Xingjian Wu",
        "Junyang Du",
        "Buang Zhang",
        "Chenjuan Guo",
        "Aoying Zhou",
        "Christian S. Jensen",
        "Zhenli Sheng",
        "Bin Yang"
      ],
      "abstract": "Time series are generated in diverse domains such as economic, traffic,\nhealth, and energy, where forecasting of future values has numerous important\napplications. Not surprisingly, many forecasting methods are being proposed. To\nensure progress, it is essential to be able to study and compare such methods\nempirically in a comprehensive and reliable manner. To achieve this, we propose\nTFB, an automated benchmark for Time Series Forecasting (TSF) methods. TFB\nadvances the state-of-the-art by addressing shortcomings related to datasets,\ncomparison methods, and evaluation pipelines: 1) insufficient coverage of data\ndomains, 2) stereotype bias against traditional methods, and 3) inconsistent\nand inflexible pipelines. To achieve better domain coverage, we include\ndatasets from 10 different domains: traffic, electricity, energy, the\nenvironment, nature, economic, stock markets, banking, health, and the web. We\nalso provide a time series characterization to ensure that the selected\ndatasets are comprehensive. To remove biases against some methods, we include a\ndiverse range of methods, including statistical learning, machine learning, and\ndeep learning methods, and we also support a variety of evaluation strategies\nand metrics to ensure a more comprehensive evaluations of different methods. To\nsupport the integration of different methods into the benchmark and enable fair\ncomparisons, TFB features a flexible and scalable pipeline that eliminates\nbiases. Next, we employ TFB to perform a thorough evaluation of 21 Univariate\nTime Series Forecasting (UTSF) methods on 8,068 univariate time series and 14\nMultivariate Time Series Forecasting (MTSF) methods on 25 datasets. The\nbenchmark code and data are available at\nhttps://github.com/decisionintelligence/TFB.",
      "tldr_zh": "该论文提出 TFB，一种全面且公平的时间序列预测 (TSF) 方法基准框架，旨在解决现有基准在数据集覆盖、方法偏见和评估管道方面的问题。TFB 包括来自 10 个领域（如交通、电力和经济）的多样化数据集，并支持统计学习、机器学习和深度学习等多种方法，同时提供灵活的评估策略和指标以确保公平比较。通过实验，TFB 在 8068 个单变量时间序列 (UTSF) 上评估了 21 种方法，并在 25 个多变量时间序列 (MTSF) 数据集上评估了 14 种方法，代码和数据可公开获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Directly accepted by PVLDB 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.20150v3",
      "published_date": "2024-03-29 12:37:57 UTC",
      "updated_date": "2024-06-19 03:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:09:12.118947"
    },
    {
      "arxiv_id": "2403.20137v1",
      "title": "Accurate Block Quantization in LLMs with Outliers",
      "title_zh": "LLMs 中带有异常值的精确块量化",
      "authors": [
        "Nikita Trukhanov",
        "Ilya Soloveychik"
      ],
      "abstract": "The demand for inference on extremely large scale LLMs has seen enormous\ngrowth in the recent months. It made evident the colossal shortage of dedicated\nhardware capable of efficient and fast processing of the involved compute and\nmemory movement. The problem is aggravated by the exploding raise in the\nlengths of the sequences being processed, since those require efficient on-chip\nstorage of the KV-cache of size proportional to the sequence length. To make\nthe required compute feasible and fit the involved data into available memory,\nnumerous quantization techniques have been proposed that allow accurate\nquantization for both weights and activations. One of the main recent\nbreakthroughs in this direction was introduction of the family of Block\nFloating Point (BFP) formats characterized by a block of mantissas with a\nshared scale factor. These enable memory- power-, and compute- efficient\nhardware support of the tensor operations and provide extremely good\nquantization accuracy. The main issues preventing widespread application of\nblock formats is caused by the presence of outliers in weights and activations\nsince those affect the accuracy of the other values in the same block. In this\npaper, we focus on the most critical problem of limited KV-cache storage. We\npropose a novel approach enabling usage of low precision BFP formats without\ncompromising the resulting model accuracy. We exploit the common channel-wise\npatterns exhibited by the outliers to rearrange them in such a way, that their\nquantization quality is significantly improved. The methodology yields 2x\nsavings in the memory footprint without significant degradation of the model's\naccuracy. Importantly, the rearrangement of channels happens at the compile\ntime and thus has no impact on the inference latency.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)中块量化(Block Quantization)问题，提出了一种处理outliers的新方法，以缓解长序列推理时KV-cache存储的内存压力。方法利用outliers在channel-wise模式下的常见特性，通过重新排列channels来提升量化质量，从而在低精度Block Floating Point (BFP)格式下保持模型准确性。实验结果显示，该方法实现了2倍的内存节省，同时不显著降低模型性能，且channels重新排列仅在编译时进行，对推理延迟无影响。",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.20137v1",
      "published_date": "2024-03-29 12:15:06 UTC",
      "updated_date": "2024-03-29 12:15:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:09:22.309786"
    },
    {
      "arxiv_id": "2404.01327v1",
      "title": "Entertainment chatbot for the digital inclusion of elderly people without abstraction capabilities",
      "title_zh": "娱乐聊天机器人，用于没有抽象能力的老年人的数字包容",
      "authors": [
        "Silvia García-Méndez",
        "Francisco de Arriba-Pérez",
        "Francisco J. González-Castaño",
        "José A. Regueiro-Janeiro",
        "Felipe Gil-Castiñeira"
      ],
      "abstract": "Current language processing technologies allow the creation of conversational\nchatbot platforms. Even though artificial intelligence is still too immature to\nsupport satisfactory user experience in many mass market domains,\nconversational interfaces have found their way into ad hoc applications such as\ncall centres and online shopping assistants. However, they have not been\napplied so far to social inclusion of elderly people, who are particularly\nvulnerable to the digital divide. Many of them relieve their loneliness with\ntraditional media such as TV and radio, which are known to create a feeling of\ncompanionship. In this paper we present the EBER chatbot, designed to reduce\nthe digital gap for the elderly. EBER reads news in the background and adapts\nits responses to the user's mood. Its novelty lies in the concept of\n\"intelligent radio\", according to which, instead of simplifying a digital\ninformation system to make it accessible to the elderly, a traditional channel\nthey find familiar -- background news -- is augmented with interactions via\nvoice dialogues. We make it possible by combining Artificial Intelligence\nModelling Language, automatic Natural Language Generation and Sentiment\nAnalysis. The system allows accessing digital content of interest by combining\nwords extracted from user answers to chatbot questions with keywords extracted\nfrom the news items. This approach permits defining metrics of the abstraction\ncapabilities of the users depending on a spatial representation of the word\nspace. To prove the suitability of the proposed solution we present results of\nreal experiments conducted with elderly people that provided valuable insights.\nOur approach was considered satisfactory during the tests and improved the\ninformation search capabilities of the participants.",
      "tldr_zh": "本论文提出了一种名为 EBER 的娱乐聊天机器人，旨在通过“智能广播”概念帮助缺乏抽象能力的老人减少数字鸿沟和社交孤立。系统在后台读取新闻，并结合 Sentiment Analysis 和 Natural Language Generation 技术，根据用户情绪调整响应，同时使用用户回答中的关键词与新闻关键词匹配来访问相关数字内容。创新点在于增强传统媒体（如广播）而非简化数字系统，以评估用户的抽象能力基于词空间表示。实验结果显示，该系统在真实测试中获得满意反馈，并显著提升了参与者的信息搜索能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01327v1",
      "published_date": "2024-03-29 12:10:21 UTC",
      "updated_date": "2024-03-29 12:10:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:09:34.443744"
    },
    {
      "arxiv_id": "2403.20127v1",
      "title": "The Impact of Prompts on Zero-Shot Detection of AI-Generated Text",
      "title_zh": "提示对零样本AI生成文本检测的影响",
      "authors": [
        "Kaito Taguchi",
        "Yujie Gu",
        "Kouichi Sakurai"
      ],
      "abstract": "In recent years, there have been significant advancements in the development\nof Large Language Models (LLMs). While their practical applications are now\nwidespread, their potential for misuse, such as generating fake news and\ncommitting plagiarism, has posed significant concerns. To address this issue,\ndetectors have been developed to evaluate whether a given text is\nhuman-generated or AI-generated. Among others, zero-shot detectors stand out as\neffective approaches that do not require additional training data and are often\nlikelihood-based. In chat-based applications, users commonly input prompts and\nutilize the AI-generated texts. However, zero-shot detectors typically analyze\nthese texts in isolation, neglecting the impact of the original prompts. It is\nconceivable that this approach may lead to a discrepancy in likelihood\nassessments between the text generation phase and the detection phase. So far,\nthere remains an unverified gap concerning how the presence or absence of\nprompts impacts detection accuracy for zero-shot detectors. In this paper, we\nintroduce an evaluative framework to empirically analyze the impact of prompts\non the detection accuracy of AI-generated text. We assess various zero-shot\ndetectors using both white-box detection, which leverages the prompt, and\nblack-box detection, which operates without prompt information. Our experiments\nreveal the significant influence of prompts on detection accuracy. Remarkably,\ncompared with black-box detection without prompts, the white-box methods using\nprompts demonstrate an increase in AUC of at least $0.1$ across all zero-shot\ndetectors tested. Code is available:\n\\url{https://github.com/kaito25atugich/Detector}.",
      "tldr_zh": "这篇论文探讨了提示（prompts）对 zero-shot 检测器在检测 AI 生成文本准确性的影响，强调了现有检测器忽略提示可能导致的准确性偏差。研究者引入了一个评估框架，通过实验比较白盒检测（使用提示）和黑盒检测（不使用提示）。结果显示，使用提示的白盒方法使所有 zero-shot 检测器的 AUC 值至少提高了 0.1，为提升 Large Language Models (LLMs) 生成文本检测的可靠性提供了重要见解。代码可从 GitHub 获取。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.20127v1",
      "published_date": "2024-03-29 11:33:34 UTC",
      "updated_date": "2024-03-29 11:33:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:09:50.830271"
    },
    {
      "arxiv_id": "2403.20109v1",
      "title": "Mol-AIR: Molecular Reinforcement Learning with Adaptive Intrinsic Rewards for Goal-directed Molecular Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jinyeong Park",
        "Jaegyoon Ahn",
        "Jonghwan Choi",
        "Jibum Kim"
      ],
      "abstract": "Optimizing techniques for discovering molecular structures with desired\nproperties is crucial in artificial intelligence(AI)-based drug discovery.\nCombining deep generative models with reinforcement learning has emerged as an\neffective strategy for generating molecules with specific properties. Despite\nits potential, this approach is ineffective in exploring the vast chemical\nspace and optimizing particular chemical properties. To overcome these\nlimitations, we present Mol-AIR, a reinforcement learning-based framework using\nadaptive intrinsic rewards for effective goal-directed molecular generation.\nMol-AIR leverages the strengths of both history-based and learning-based\nintrinsic rewards by exploiting random distillation network and counting-based\nstrategies. In benchmark tests, Mol-AIR demonstrates superior performance over\nexisting approaches in generating molecules with desired properties without any\nprior knowledge, including penalized LogP, QED, and celecoxib similarity. We\nbelieve that Mol-AIR represents a significant advancement in drug discovery,\noffering a more efficient path to discovering novel therapeutics.",
      "tldr_zh": "该研究提出 Mol-AIR 框架，这是一种基于 reinforcement learning 的方法，用于目标导向分子生成，通过自适应 intrinsic rewards 克服现有技术在探索化学空间和优化化学属性方面的局限性。Mol-AIR 结合了 history-based 和 learning-based 策略，包括 random distillation network 和 counting-based 方法，从而在无先验知识的情况下有效生成具有特定属性的分子。实验结果显示，Mol-AIR 在基准测试中（如 penalized LogP、QED 和 celecoxib similarity）优于现有方法，为 AI 药物发现提供更高效的发现新疗法路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.20109v1",
      "published_date": "2024-03-29 10:44:51 UTC",
      "updated_date": "2024-03-29 10:44:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:10:03.057614"
    },
    {
      "arxiv_id": "2403.20097v2",
      "title": "ITCMA: A Generative Agent Based on a Computational Consciousness Structure",
      "title_zh": "ITCMA: 基于计算意识结构的生成代理",
      "authors": [
        "Hanzhong Zhang",
        "Jibin Yin",
        "Haoyang Wang",
        "Ziwei Xiang"
      ],
      "abstract": "Large Language Models (LLMs) still face challenges in tasks requiring\nunderstanding implicit instructions and applying common-sense knowledge. In\nsuch scenarios, LLMs may require multiple attempts to achieve human-level\nperformance, potentially leading to inaccurate responses or inferences in\npractical environments, affecting their long-term consistency and behavior.\nThis paper introduces the Internal Time-Consciousness Machine (ITCM), a\ncomputational consciousness structure to simulate the process of human\nconsciousness. We further propose the ITCM-based Agent (ITCMA), which supports\naction generation and reasoning in open-world settings, and can independently\ncomplete tasks. ITCMA enhances LLMs' ability to understand implicit\ninstructions and apply common-sense knowledge by considering agents'\ninteraction and reasoning with the environment. Evaluations in the Alfworld\nenvironment show that trained ITCMA outperforms the state-of-the-art (SOTA) by\n9% on the seen set. Even untrained ITCMA achieves a 96% task completion rate on\nthe seen set, 5% higher than SOTA, indicating its superiority over traditional\nintelligent agents in utility and generalization. In real-world tasks with\nquadruped robots, the untrained ITCMA achieves an 85% task completion rate,\nwhich is close to its performance in the unseen set, demonstrating its\ncomparable utility and universality in real-world settings.",
      "tldr_zh": "本论文针对 Large Language Models (LLMs) 在处理隐式指令和常识知识时存在的挑战（如不准确响应和长期一致性问题），提出了一种基于计算意识结构的 Internal Time-Consciousness Machine (ITCM)。ITCM-based Agent (ITCMA) 通过模拟人类意识过程，支持代理在开放世界环境中生成行动和推理，并增强 LLMs 与环境的互动以更好地理解隐式指令。实验结果显示，在 Alfworld 环境中，训练后的 ITCMA 比 state-of-the-art (SOTA) 高出 9% 的任务完成率，而未训练版本在 seen set 上达到 96%，并在真实世界四足机器人任务中实现 85% 的完成率，展示了其在泛化和实用性方面的优越性。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "q-bio.NC",
        "I.2; J.4"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.20097v2",
      "published_date": "2024-03-29 10:23:18 UTC",
      "updated_date": "2024-06-08 13:04:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:10:15.007901"
    },
    {
      "arxiv_id": "2403.20089v2",
      "title": "Implications of the AI Act for Non-Discrimination Law and Algorithmic Fairness",
      "title_zh": "AI Act 对非歧视法和算法公平性的影响",
      "authors": [
        "Luca Deck",
        "Jan-Laurin Müller",
        "Conradin Braun",
        "Domenique Zipperling",
        "Niklas Kühl"
      ],
      "abstract": "The topic of fairness in AI, as debated in the FATE (Fairness,\nAccountability, Transparency, and Ethics in AI) communities, has sparked\nmeaningful discussions in the past years. However, from a legal perspective,\nparticularly from the perspective of European Union law, many open questions\nremain. Whereas algorithmic fairness aims to mitigate structural inequalities\nat design-level, European non-discrimination law is tailored to individual\ncases of discrimination after an AI model has been deployed. The AI Act might\npresent a tremendous step towards bridging these two approaches by shifting\nnon-discrimination responsibilities into the design stage of AI models. Based\non an integrative reading of the AI Act, we comment on legal as well as\ntechnical enforcement problems and propose practical implications on bias\ndetection and bias correction in order to specify and comply with specific\ntechnical requirements.",
      "tldr_zh": "本研究探讨了欧盟 AI Act 对非歧视法和算法公平性的影响，指出算法公平性旨在在设计阶段缓解结构性不平等，而欧盟非歧视法则聚焦于 AI 模型部署后个体的歧视案例。AI Act 通过将非歧视责任前置到 AI 模型设计阶段，可能桥接这两种方法。作者基于对 AI Act 的整合解读，评论了法律和技术执行问题，并提出偏置检测和修正的实用建议，以帮助符合具体技术要求。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.20089v2",
      "published_date": "2024-03-29 09:54:09 UTC",
      "updated_date": "2024-06-26 07:35:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:10:27.526628"
    },
    {
      "arxiv_id": "2404.00081v1",
      "title": "Molecular Generative Adversarial Network with Multi-Property Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Huidong Tang",
        "Chen Li",
        "Sayaka Kamei",
        "Yoshihiro Yamanishi",
        "Yasuhiko Morimoto"
      ],
      "abstract": "Deep generative models, such as generative adversarial networks (GANs), have\nbeen employed for $de~novo$ molecular generation in drug discovery. Most prior\nstudies have utilized reinforcement learning (RL) algorithms, particularly\nMonte Carlo tree search (MCTS), to handle the discrete nature of molecular\nrepresentations in GANs. However, due to the inherent instability in training\nGANs and RL models, along with the high computational cost associated with MCTS\nsampling, MCTS RL-based GANs struggle to scale to large chemical databases. To\ntackle these challenges, this study introduces a novel GAN based on\nactor-critic RL with instant and global rewards, called InstGAN, to generate\nmolecules at the token-level with multi-property optimization. Furthermore,\nmaximized information entropy is leveraged to alleviate the mode collapse. The\nexperimental results demonstrate that InstGAN outperforms other baselines,\nachieves comparable performance to state-of-the-art models, and efficiently\ngenerates molecules with multi-property optimization. The source code will be\nreleased upon acceptance of the paper.",
      "tldr_zh": "本研究针对药物发现中的分子生成问题，提出了一种名为 InstGAN 的新型生成对抗网络(GANs)，利用 actor-critic reinforcement learning (RL) 算法结合即时和全局奖励，在 token 级别优化分子多属性，以克服传统 GANs 和 Monte Carlo tree search (MCTS) 方法的训练不稳定性和高计算成本问题。同时，InstGAN 通过最大化信息熵缓解模式崩溃，确保生成过程的多样性。实验结果显示，InstGAN 优于其他基线模型，并与最先进模型性能相当，能够高效生成满足多属性的分子。源代码将在论文接受后发布。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00081v1",
      "published_date": "2024-03-29 08:55:39 UTC",
      "updated_date": "2024-03-29 08:55:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:10:38.063965"
    },
    {
      "arxiv_id": "2403.20058v3",
      "title": "Revolutionizing Disease Diagnosis with simultaneous functional PET/MR and Deeply Integrated Brain Metabolic, Hemodynamic, and Perfusion Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Luoyu Wang",
        "Yitian Tao",
        "Qing Yang",
        "Yan Liang",
        "Siwei Liu",
        "Hongcheng Shi",
        "Dinggang Shen",
        "Han Zhang"
      ],
      "abstract": "Simultaneous functional PET/MR (sf-PET/MR) presents a cutting-edge multimodal\nneuroimaging technique. It provides an unprecedented opportunity for\nconcurrently monitoring and integrating multifaceted brain networks built by\nspatiotemporally covaried metabolic activity, neural activity, and cerebral\nblood flow (perfusion). Albeit high scientific/clinical values, short in\nhardware accessibility of PET/MR hinders its applications, let alone modern\nAI-based PET/MR fusion models. Our objective is to develop a clinically\nfeasible AI-based disease diagnosis model trained on comprehensive sf-PET/MR\ndata with the power of, during inferencing, allowing single modality input\n(e.g., PET only) as well as enforcing multimodal-based accuracy. To this end,\nwe propose MX-ARM, a multimodal MiXture-of-experts Alignment and Reconstruction\nModel. It is modality detachable and exchangeable, allocating different\nmulti-layer perceptrons dynamically (\"mixture of experts\") through learnable\nweights to learn respective representations from different modalities. Such\ndesign will not sacrifice model performance in uni-modal situation. To fully\nexploit the inherent complex and nonlinear relation among modalities while\nproducing fine-grained representations for uni-modal inference, we subsequently\nadd a modal alignment module to line up a dominant modality (e.g., PET) with\nrepresentations of auxiliary modalities (MR). We further adopt multimodal\nreconstruction to promote the quality of learned features. Experiments on\nprecious multimodal sf-PET/MR data for Mild Cognitive Impairment diagnosis\nshowcase the efficacy of our model toward clinically feasible precision\nmedicine.",
      "tldr_zh": "该研究引入了同时性功能 PET/MR (sf-PET/MR) 作为先进的 multimodal 神经影像技术，用于整合脑代谢活动、神经活动和脑血流网络，以革命化疾病诊断。针对 PET/MR 硬件可访问性低的问题，作者提出 MX-ARM 模型，这是一个模态可分离且可交换的 Mixture-of-Experts Alignment and Reconstruction Model，通过动态分配多层感知器学习不同模态的表示，并在推理时支持单一模态输入（如 PET 仅）。模型还包括模态对齐模块和多模态重建机制，以捕捉模态间的复杂非线性关系并提升特征质量。实验在轻度认知障碍诊断的 sf-PET/MR 数据上证明了 MX-ARM 的有效性，实现临床可行的精确医学应用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.20058v3",
      "published_date": "2024-03-29 08:47:49 UTC",
      "updated_date": "2024-09-20 12:07:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:10:51.237301"
    },
    {
      "arxiv_id": "2403.20015v1",
      "title": "Adverb Is the Key: Simple Text Data Augmentation with Adverb Deletion",
      "title_zh": "翻译失败",
      "authors": [
        "Juhwan Choi",
        "YoungBin Kim"
      ],
      "abstract": "In the field of text data augmentation, rule-based methods are widely adopted\nfor real-world applications owing to their cost-efficiency. However,\nconventional rule-based approaches suffer from the possibility of losing the\noriginal semantics of the given text. We propose a novel text data augmentation\nstrategy that avoids such phenomena through a straightforward deletion of\nadverbs, which play a subsidiary role in the sentence. Our comprehensive\nexperiments demonstrate the efficiency and effectiveness of our proposed\napproach for not just single text classification, but also natural language\ninference that requires semantic preservation. We publicly released our source\ncode for reproducibility.",
      "tldr_zh": "该论文提出了一种简单有效的文本数据增强策略，即通过删除副词（adverb）来避免传统基于规则的方法可能导致的原句语义丢失。作者强调，副词在句子中扮演次要角色，因此这种删除操作能更好地保留文本的整体含义。实验结果显示，该方法不仅适用于单一文本分类任务，还在需要语义保留的自然语言推理（Natural Language Inference）任务中表现出色，并公开了源代码以便复现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2024 Tiny Papers",
      "pdf_url": "http://arxiv.org/pdf/2403.20015v1",
      "published_date": "2024-03-29 07:01:39 UTC",
      "updated_date": "2024-03-29 07:01:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:11:03.003144"
    },
    {
      "arxiv_id": "2403.20014v1",
      "title": "PURPLE: Making a Large Language Model a Better SQL Writer",
      "title_zh": "PURPLE：使大型语言模型成为更好的 SQL 编写器",
      "authors": [
        "Tonghui Ren",
        "Yuankai Fan",
        "Zhenying He",
        "Ren Huang",
        "Jiaqi Dai",
        "Can Huang",
        "Yinan Jing",
        "Kai Zhang",
        "Yifan Yang",
        "X. Sean Wang"
      ],
      "abstract": "Large Language Model (LLM) techniques play an increasingly important role in\nNatural Language to SQL (NL2SQL) translation. LLMs trained by extensive corpora\nhave strong natural language understanding and basic SQL generation abilities\nwithout additional tuning specific to NL2SQL tasks. Existing LLMs-based NL2SQL\napproaches try to improve the translation by enhancing the LLMs with an\nemphasis on user intention understanding. However, LLMs sometimes fail to\ngenerate appropriate SQL due to their lack of knowledge in organizing complex\nlogical operator composition. A promising method is to input the LLMs with\ndemonstrations, which include known NL2SQL translations from various databases.\nLLMs can learn to organize operator compositions from the input demonstrations\nfor the given task. In this paper, we propose PURPLE (Pre-trained models\nUtilized to Retrieve Prompts for Logical Enhancement), which improves accuracy\nby retrieving demonstrations containing the requisite logical operator\ncomposition for the NL2SQL task on hand, thereby guiding LLMs to produce better\nSQL translation. PURPLE achieves a new state-of-the-art performance of 80.5%\nexact-set match accuracy and 87.8% execution match accuracy on the validation\nset of the popular NL2SQL benchmark Spider. PURPLE maintains high accuracy\nacross diverse benchmarks, budgetary constraints, and various LLMs, showing\nrobustness and cost-effectiveness.",
      "tldr_zh": "这篇论文提出 PURPLE 方法，以提升 Large Language Models (LLMs) 在 Natural Language to SQL (NL2SQL) 任务中的性能，针对 LLMs 在组织复杂逻辑运算符方面存在的不足。PURPLE 通过检索包含必要逻辑运算符组成的演示（demonstrations），来增强提示输入，从而指导 LLMs 生成更准确的 SQL 查询。实验结果显示，PURPLE 在 Spider 基准上的 exact-set match accuracy 达到 80.5%、execution match accuracy 达到 87.8%，并在多种基准、预算限制和不同 LLMs 上表现出色，具有稳健性和成本效益。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.DB",
      "comment": "12 pages, accepted by ICDE 2024 (40th IEEE International Conference\n  on Data Engineering)",
      "pdf_url": "http://arxiv.org/pdf/2403.20014v1",
      "published_date": "2024-03-29 07:01:29 UTC",
      "updated_date": "2024-03-29 07:01:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:11:14.741935"
    },
    {
      "arxiv_id": "2403.20012v1",
      "title": "Colorful Cutout: Enhancing Image Data Augmentation with Curriculum Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Juhwan Choi",
        "YoungBin Kim"
      ],
      "abstract": "Data augmentation is one of the regularization strategies for the training of\ndeep learning models, which enhances generalizability and prevents overfitting,\nleading to performance improvement. Although researchers have proposed various\ndata augmentation techniques, they often lack consideration for the difficulty\nof augmented data. Recently, another line of research suggests incorporating\nthe concept of curriculum learning with data augmentation in the field of\nnatural language processing. In this study, we adopt curriculum data\naugmentation for image data augmentation and propose colorful cutout, which\ngradually increases the noise and difficulty introduced in the augmented image.\nOur experimental results highlight the possibility of curriculum data\naugmentation for image data. We publicly released our source code to improve\nthe reproducibility of our study.",
      "tldr_zh": "数据增强（data augmentation）是深度学习模型训练中的关键正则化策略，能提升模型泛化性和防止过拟合，但现有方法通常忽略了增强数据的难度。论文提出一种名为 colorful cutout 的新方法，将课程学习（curriculum learning）应用于图像数据增强，通过逐步增加噪声和难度来渐进式地改进增强过程。实验结果验证了这种课程数据增强在图像领域的潜力，并公开了源代码以提高研究的可重复性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2024 Tiny Papers",
      "pdf_url": "http://arxiv.org/pdf/2403.20012v1",
      "published_date": "2024-03-29 06:53:52 UTC",
      "updated_date": "2024-03-29 06:53:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:11:26.356083"
    },
    {
      "arxiv_id": "2403.19995v2",
      "title": "Development of Compositionality and Generalization through Interactive Learning of Language and Action of Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Prasanna Vijayaraghavan",
        "Jeffrey Frederic Queisser",
        "Sergio Verduzco Flores",
        "Jun Tani"
      ],
      "abstract": "Humans excel at applying learned behavior to unlearned situations. A crucial\ncomponent of this generalization behavior is our ability to compose/decompose a\nwhole into reusable parts, an attribute known as compositionality. One of the\nfundamental questions in robotics concerns this characteristic. \"How can\nlinguistic compositionality be developed concomitantly with sensorimotor skills\nthrough associative learning, particularly when individuals only learn partial\nlinguistic compositions and their corresponding sensorimotor patterns?\" To\naddress this question, we propose a brain-inspired neural network model that\nintegrates vision, proprioception, and language into a framework of predictive\ncoding and active inference, based on the free-energy principle. The\neffectiveness and capabilities of this model were assessed through various\nsimulation experiments conducted with a robot arm. Our results show that\ngeneralization in learning to unlearned verb-noun compositions, is\nsignificantly enhanced when training variations of task composition are\nincreased. We attribute this to self-organized compositional structures in\nlinguistic latent state space being influenced significantly by sensorimotor\nlearning. Ablation studies show that visual attention and working memory are\nessential to accurately generate visuo-motor sequences to achieve\nlinguistically represented goals. These insights advance our understanding of\nmechanisms underlying development of compositionality through interactions of\nlinguistic and sensorimotor experience.",
      "tldr_zh": "该论文探讨了机器人通过互动学习语言和动作来发展组合性（compositionality）和泛化（generalization）的机制，针对个体仅学习部分语言组合及其对应传感器运动模式的问题。研究提出一个受脑启发的神经网络模型，整合视觉（vision）、本体感觉（proprioception）和语言，基于预测编码（predictive coding）和主动推理（active inference）的自由能量原理（free-energy principle）。通过机器人臂模拟实验，结果显示增加任务组合变异性显著提升了对未学动词-名词（verb-noun）组合的泛化能力，并证明视觉注意力（visual attention）和工作记忆（working memory）对于准确生成视觉-运动（visuo-motor）序列至关重要。这些发现深化了对语言和传感器运动互动发展组合性的机制理解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.RO",
        "68T35, 68T40",
        "I.2.9"
      ],
      "primary_category": "cs.AI",
      "comment": "64 pages, 6 figures, 10 supplementary figures",
      "pdf_url": "http://arxiv.org/pdf/2403.19995v2",
      "published_date": "2024-03-29 06:22:37 UTC",
      "updated_date": "2024-07-23 05:21:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:11:42.527046"
    },
    {
      "arxiv_id": "2403.19992v2",
      "title": "MindArm: Mechanized Intelligent Non-Invasive Neuro-Driven Prosthetic Arm System",
      "title_zh": "翻译失败",
      "authors": [
        "Maha Nawaz",
        "Abdul Basit",
        "Muhammad Shafique"
      ],
      "abstract": "Currently, individuals with arm mobility impairments (referred to as\n\"patients\") face limited technological solutions due to two key challenges: (1)\nnon-invasive prosthetic devices are often prohibitively expensive and costly to\nmaintain, and (2) invasive solutions require high-risk, costly brain surgery,\nwhich can pose a health risk. Therefore, current technological solutions are\nnot accessible for all patients with different financial backgrounds. Toward\nthis, we propose a low-cost technological solution called MindArm, an\naffordable, non-invasive neuro-driven prosthetic arm system. MindArm employs a\ndeep neural network (DNN) to translate brain signals, captured by low-cost\nsurface electroencephalogram (EEG) electrodes, into prosthetic arm movements.\nUtilizing an Open Brain Computer Interface and UDP networking for signal\nprocessing, the system seamlessly controls arm motion. In the compute module,\nwe run a trained DNN model to interpret filtered micro-voltage brain signals,\nand then translate them into a prosthetic arm action via serial communication\nseamlessly. Experimental results from a fully functional prototype show high\naccuracy across three actions, with 91% for idle/stationary, 85% for handshake,\nand 84% for cup pickup. The system costs approximately $500-550, including $400\nfor the EEG headset and $100-150 for motors, 3D printing, and assembly,\noffering an affordable alternative for mind-controlled prosthetic devices.",
      "tldr_zh": "该研究针对手臂行动障碍患者面临的假肢解决方案成本高和风险大的问题，提出了一种低成本、非侵入式神经驱动假肢系统MindArm。系统利用深度神经网络(DNN)处理通过低成本表面EEG电极捕获的脑信号，并结合Open Brain Computer Interface和UDP网络进行信号处理，以实现对假肢手臂的无缝控制。实验结果显示，该原型在三种动作上表现出高准确率：闲置91%、握手85%和拿起杯子84%。MindArm的总成本仅约500-550美元，包括EEG耳机和相关部件，提供了一个负担得起的脑控假肢替代方案。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.RO",
        "I.2.9"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 22 figures, Paper accepted at ICARCV 2024, funded by CAIR",
      "pdf_url": "http://arxiv.org/pdf/2403.19992v2",
      "published_date": "2024-03-29 06:09:24 UTC",
      "updated_date": "2024-10-19 18:23:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:11:58.178767"
    },
    {
      "arxiv_id": "2403.19979v1",
      "title": "Semantically-Shifted Incremental Adapter-Tuning is A Continual ViTransformer",
      "title_zh": "翻译失败",
      "authors": [
        "Yuwen Tan",
        "Qinhao Zhou",
        "Xiang Xiang",
        "Ke Wang",
        "Yuchuan Wu",
        "Yongbin Li"
      ],
      "abstract": "Class-incremental learning (CIL) aims to enable models to continuously learn\nnew classes while overcoming catastrophic forgetting. The introduction of\npre-trained models has brought new tuning paradigms to CIL. In this paper, we\nrevisit different parameter-efficient tuning (PET) methods within the context\nof continual learning. We observe that adapter tuning demonstrates superiority\nover prompt-based methods, even without parameter expansion in each learning\nsession. Motivated by this, we propose incrementally tuning the shared adapter\nwithout imposing parameter update constraints, enhancing the learning capacity\nof the backbone. Additionally, we employ feature sampling from stored\nprototypes to retrain a unified classifier, further improving its performance.\nWe estimate the semantic shift of old prototypes without access to past samples\nand update stored prototypes session by session. Our proposed method eliminates\nmodel expansion and avoids retaining any image samples. It surpasses previous\npre-trained model-based CIL methods and demonstrates remarkable continual\nlearning capabilities. Experimental results on five CIL benchmarks validate the\neffectiveness of our approach, achieving state-of-the-art (SOTA) performance.",
      "tldr_zh": "这篇论文探讨了类增量学习 (CIL)，旨在让模型持续学习新类同时避免灾难性遗忘，并比较了不同参数高效调优 (PET) 方法，指出 adapter 调优优于基于提示的方法。作者提出了一种新方法，通过增量调优共享 adapter（无需参数更新约束）和使用存储原型进行特征采样来估计语义偏移，从而更新分类器和原型，而不需模型扩展或保留图像样本。该方法在五个 CIL 基准上实现了超越现有预训练模型-based 方法的性能，达到了 state-of-the-art (SOTA) 水平。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "To appear at CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.19979v1",
      "published_date": "2024-03-29 05:23:12 UTC",
      "updated_date": "2024-03-29 05:23:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:12:11.478116"
    },
    {
      "arxiv_id": "2403.19962v1",
      "title": "Enhancing the General Agent Capabilities of Low-Parameter LLMs through Tuning and Multi-Branch Reasoning",
      "title_zh": "通过微调和多分支推理增强低参数大语言模型的一般代理能力",
      "authors": [
        "Qinhao Zhou",
        "Zihan Zhang",
        "Xiang Xiang",
        "Ke Wang",
        "Yuchuan Wu",
        "Yongbin Li"
      ],
      "abstract": "Open-source pre-trained Large Language Models (LLMs) exhibit strong language\nunderstanding and generation capabilities, making them highly successful in a\nvariety of tasks. However, when used as agents for dealing with complex\nproblems in the real world, their performance is far inferior to large\ncommercial models such as ChatGPT and GPT-4. As intelligent agents, LLMs need\nto have the capabilities of task planning, long-term memory, and the ability to\nleverage external tools to achieve satisfactory performance. Various methods\nhave been proposed to enhance the agent capabilities of LLMs. On the one hand,\nmethods involve constructing agent-specific data and fine-tuning the models. On\nthe other hand, some methods focus on designing prompts that effectively\nactivate the reasoning abilities of the LLMs. We explore both strategies on the\n7B and 13B models. We propose a comprehensive method for constructing\nagent-specific data using GPT-4. Through supervised fine-tuning with\nconstructed data, we find that for these models with a relatively small number\nof parameters, supervised fine-tuning can significantly reduce hallucination\noutputs and formatting errors in agent tasks. Furthermore, techniques such as\nmulti-path reasoning and task decomposition can effectively decrease problem\ncomplexity and enhance the performance of LLMs as agents. We evaluate our\nmethod on five agent tasks of AgentBench and achieve satisfactory results.",
      "tldr_zh": "本文研究了如何提升低参数大型语言模型（LLMs）的代理能力，以应对复杂真实世界问题。作者提出了一种综合方法，包括使用 GPT-4 构建代理特定数据并进行 supervised fine-tuning，以显著减少幻觉输出和格式错误；同时，引入 multi-path reasoning 和任务分解技术来降低问题复杂性并增强模型性能。在 AgentBench 的五个代理任务上，该方法取得了满意的结果，证明了其在提升开源 LLMs 代理能力的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear at NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.19962v1",
      "published_date": "2024-03-29 03:48:12 UTC",
      "updated_date": "2024-03-29 03:48:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:12:25.196179"
    },
    {
      "arxiv_id": "2403.19946v1",
      "title": "A Peg-in-hole Task Strategy for Holes in Concrete",
      "title_zh": "翻译失败",
      "authors": [
        "André Yuji Yasutomi",
        "Hiroki Mori",
        "Tetsuya Ogata"
      ],
      "abstract": "A method that enables an industrial robot to accomplish the peg-in-hole task\nfor holes in concrete is proposed. The proposed method involves slightly\ndetaching the peg from the wall, when moving between search positions, to avoid\nthe negative influence of the concrete's high friction coefficient. It uses a\ndeep neural network (DNN), trained via reinforcement learning, to effectively\nfind holes with variable shape and surface finish (due to the brittle nature of\nconcrete) without analytical modeling or control parameter tuning. The method\nuses displacement of the peg toward the wall surface, in addition to force and\ntorque, as one of the inputs of the DNN. Since the displacement increases as\nthe peg gets closer to the hole (due to the chamfered shape of holes in\nconcrete), it is a useful parameter for inputting in the DNN. The proposed\nmethod was evaluated by training the DNN on a hole 500 times and attempting to\nfind 12 unknown holes. The results of the evaluation show the DNN enabled a\nrobot to find the unknown holes with average success rate of 96.1% and average\nexecution time of 12.5 seconds. Additional evaluations with random initial\npositions and a different type of peg demonstrate the trained DNN can\ngeneralize well to different conditions. Analyses of the influence of the peg\ndisplacement input showed the success rate of the DNN is increased by utilizing\nthis parameter. These results validate the proposed method in terms of its\neffectiveness and applicability to the construction industry.",
      "tldr_zh": "本研究提出了一种针对混凝土孔洞的peg-in-hole任务策略，使工业机器人能够高效完成插入操作。该方法通过在移动搜索位置时稍微分离钉子，避免混凝土高摩擦系数的影响，并利用经强化学习训练的深度神经网络(DNN)来检测形状和表面光洁度可变的孔洞，输入参数包括钉子向墙面的位移、力和扭矩。实验结果显示，DNN在训练500次后，对12个未知孔洞的成功率达平均96.1%，平均执行时间为12.5秒，并表现出良好的泛化能力，如适应随机初始位置和不同钉子类型。该策略验证了其在建筑行业的有效性和实用性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Published in 2021 IEEE International Conference on Robotics and\n  Automation (ICRA) on 30 May 2021",
      "pdf_url": "http://arxiv.org/pdf/2403.19946v1",
      "published_date": "2024-03-29 03:00:54 UTC",
      "updated_date": "2024-03-29 03:00:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:12:35.331921"
    },
    {
      "arxiv_id": "2403.19943v1",
      "title": "TDANet: A Novel Temporal Denoise Convolutional Neural Network With Attention for Fault Diagnosis",
      "title_zh": "TDANet：一种新颖的带注意力机制的时间去噪卷积神经网络，用于故障诊断",
      "authors": [
        "Zhongzhi Li",
        "Rong Fan",
        "Jingqi Tu",
        "Jinyi Ma",
        "Jianliang Ai",
        "Yiqun Dong"
      ],
      "abstract": "Fault diagnosis plays a crucial role in maintaining the operational integrity\nof mechanical systems, preventing significant losses due to unexpected\nfailures. As intelligent manufacturing and data-driven approaches evolve, Deep\nLearning (DL) has emerged as a pivotal technique in fault diagnosis research,\nrecognized for its ability to autonomously extract complex features. However,\nthe practical application of current fault diagnosis methods is challenged by\nthe complexity of industrial environments. This paper proposed the Temporal\nDenoise Convolutional Neural Network With Attention (TDANet), designed to\nimprove fault diagnosis performance in noise environments. This model\ntransforms one-dimensional signals into two-dimensional tensors based on their\nperiodic properties, employing multi-scale 2D convolution kernels to extract\nsignal information both within and across periods. This method enables\neffective identification of signal characteristics that vary over multiple time\nscales. The TDANet incorporates a Temporal Variable Denoise (TVD) module with\nresidual connections and a Multi-head Attention Fusion (MAF) module, enhancing\nthe saliency of information within noisy data and maintaining effective fault\ndiagnosis performance. Evaluation on two datasets, CWRU (single sensor) and\nReal aircraft sensor fault (multiple sensors), demonstrates that the TDANet\nmodel significantly outperforms existing deep learning approaches in terms of\ndiagnostic accuracy under noisy environments.",
      "tldr_zh": "本研究针对机械系统故障诊断中噪声干扰的问题，提出了一种新型 Temporal Denoise Convolutional Neural Network With Attention (TDANet) 模型，以提升在复杂工业环境下的诊断性能。TDANet 通过将一维信号转换为二维张量，并利用多尺度 2D 卷积核提取跨周期信号特征，同时整合 Temporal Variable Denoise (TVD) 模块（带有残差连接）和 Multi-head Attention Fusion (MAF) 模块，来增强噪声数据中的关键信息显著性。实验在 CWRU 和 Real aircraft sensor fault 数据集上表明，TDANet 在噪声环境下的诊断准确率显著优于现有深度学习方法，为可靠的故障诊断提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.19943v1",
      "published_date": "2024-03-29 02:54:41 UTC",
      "updated_date": "2024-03-29 02:54:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:12:45.473605"
    },
    {
      "arxiv_id": "2403.19941v1",
      "title": "Diverse Feature Learning by Self-distillation and Reset",
      "title_zh": "基于自蒸馏和重置的多样特征学习",
      "authors": [
        "Sejik Park"
      ],
      "abstract": "Our paper addresses the problem of models struggling to learn diverse\nfeatures, due to either forgetting previously learned features or failing to\nlearn new ones. To overcome this problem, we introduce Diverse Feature Learning\n(DFL), a method that combines an important feature preservation algorithm with\na new feature learning algorithm. Specifically, for preserving important\nfeatures, we utilize self-distillation in ensemble models by selecting the\nmeaningful model weights observed during training. For learning new features,\nwe employ reset that involves periodically re-initializing part of the model.\nAs a result, through experiments with various models on the image\nclassification, we have identified the potential for synergistic effects\nbetween self-distillation and reset.",
      "tldr_zh": "本论文针对模型在学习多样特征时容易忘记旧特征或无法学习新特征的问题，提出了一种名为Diverse Feature Learning (DFL)的方法。该方法结合self-distillation和reset两种算法：通过self-distillation在集成模型中选择训练过程中的关键权重来保留重要特征，并使用reset定期重新初始化模型部分以促进新特征的学习。通过在图像分类任务上的各种模型实验，研究发现self-distillation和reset之间存在协同效应，提升了模型的特征学习能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 6 Figures",
      "pdf_url": "http://arxiv.org/pdf/2403.19941v1",
      "published_date": "2024-03-29 02:49:15 UTC",
      "updated_date": "2024-03-29 02:49:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:12:56.050072"
    },
    {
      "arxiv_id": "2403.19925v1",
      "title": "Decision Mamba: Reinforcement Learning via Sequence Modeling with Selective State Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Toshihiro Ota"
      ],
      "abstract": "Decision Transformer, a promising approach that applies Transformer\narchitectures to reinforcement learning, relies on causal self-attention to\nmodel sequences of states, actions, and rewards. While this method has shown\ncompetitive results, this paper investigates the integration of the Mamba\nframework, known for its advanced capabilities in efficient and effective\nsequence modeling, into the Decision Transformer architecture, focusing on the\npotential performance enhancements in sequential decision-making tasks. Our\nstudy systematically evaluates this integration by conducting a series of\nexperiments across various decision-making environments, comparing the modified\nDecision Transformer, Decision Mamba, with its traditional counterpart. This\nwork contributes to the advancement of sequential decision-making models,\nsuggesting that the architecture and training methodology of neural networks\ncan significantly impact their performance in complex tasks, and highlighting\nthe potential of Mamba as a valuable tool for improving the efficacy of\nTransformer-based models in reinforcement learning scenarios.",
      "tldr_zh": "本论文提出 Decision Mamba，一种将 Mamba 框架整合到 Decision Transformer 中的新方法，通过选择性状态空间（Selective State Spaces）提升强化学习中的序列建模效率。研究通过一系列实验在多种决策环境中比较 Decision Mamba 与传统模型，结果显示其在序列决策任务中表现出色，性能显著提升。总体而言，该工作强调了神经网络架构和训练方法对复杂任务的影响，并展示了 Mamba 在强化学习场景中的潜在价值。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2403.19925v1",
      "published_date": "2024-03-29 02:25:55 UTC",
      "updated_date": "2024-03-29 02:25:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:13:09.453085"
    },
    {
      "arxiv_id": "2403.19918v3",
      "title": "CtRL-Sim: Reactive and Controllable Driving Agents with Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Luke Rowe",
        "Roger Girgis",
        "Anthony Gosselin",
        "Bruno Carrez",
        "Florian Golemo",
        "Felix Heide",
        "Liam Paull",
        "Christopher Pal"
      ],
      "abstract": "Evaluating autonomous vehicle stacks (AVs) in simulation typically involves\nreplaying driving logs from real-world recorded traffic. However, agents\nreplayed from offline data are not reactive and hard to intuitively control.\nExisting approaches address these challenges by proposing methods that rely on\nheuristics or generative models of real-world data but these approaches either\nlack realism or necessitate costly iterative sampling procedures to control the\ngenerated behaviours. In this work, we take an alternative approach and propose\nCtRL-Sim, a method that leverages return-conditioned offline reinforcement\nlearning (RL) to efficiently generate reactive and controllable traffic agents.\nSpecifically, we process real-world driving data through a physics-enhanced\nNocturne simulator to generate a diverse offline RL dataset, annotated with\nvarious rewards. With this dataset, we train a return-conditioned multi-agent\nbehaviour model that allows for fine-grained manipulation of agent behaviours\nby modifying the desired returns for the various reward components. This\ncapability enables the generation of a wide range of driving behaviours beyond\nthe scope of the initial dataset, including adversarial behaviours. We show\nthat CtRL-Sim can generate realistic safety-critical scenarios while providing\nfine-grained control over agent behaviours.",
      "tldr_zh": "该论文提出 CtRL-Sim 方法，利用基于回报的 offline reinforcement learning，生成反应性和可控的驾驶代理，以解决传统模拟评估自动驾驶系统（AVs）缺乏真实性和控制性的问题。具体而言，该方法通过处理真实驾驶数据并使用 Nocturne 模拟器创建多样化的离线 RL 数据集，并标注各种奖励，从而训练一个回报条件的多代理行为模型，实现对代理行为的精细操控，包括生成超出数据集范围的对抗性驾驶行为。实验结果显示，CtRL-Sim 能高效创建真实的、高危安全场景，同时提供细粒度控制，提升了自动驾驶模拟的真实性和实用性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "CoRL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.19918v3",
      "published_date": "2024-03-29 02:10:19 UTC",
      "updated_date": "2024-10-14 18:13:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:13:22.933642"
    },
    {
      "arxiv_id": "2403.19913v2",
      "title": "MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models",
      "title_zh": "MANGO：用于评估大型语言模型映射和导航能力的基准",
      "authors": [
        "Peng Ding",
        "Jiading Fang",
        "Peng Li",
        "Kangrui Wang",
        "Xiaochen Zhou",
        "Mo Yu",
        "Jing Li",
        "Matthew R. Walter",
        "Hongyuan Mei"
      ],
      "abstract": "Large language models such as ChatGPT and GPT-4 have recently achieved\nastonishing performance on a variety of natural language processing tasks. In\nthis paper, we propose MANGO, a benchmark to evaluate their capabilities to\nperform text-based mapping and navigation. Our benchmark includes 53 mazes\ntaken from a suite of textgames: each maze is paired with a walkthrough that\nvisits every location but does not cover all possible paths. The task is\nquestion-answering: for each maze, a large language model reads the walkthrough\nand answers hundreds of mapping and navigation questions such as \"How should\nyou go to Attic from West of House?\" and \"Where are we if we go north and east\nfrom Cellar?\". Although these questions are easy to humans, it turns out that\neven GPT-4, the best-to-date language model, performs poorly at answering them.\nFurther, our experiments suggest that a strong mapping and navigation ability\nwould benefit large language models in performing relevant downstream tasks,\nsuch as playing textgames. Our MANGO benchmark will facilitate future research\non methods that improve the mapping and navigation capabilities of language\nmodels. We host our leaderboard, data, code, and evaluation program at\nhttps://mango.ttic.edu and https://github.com/oaklight/mango/.",
      "tldr_zh": "本研究提出 MANGO 基准，用于评估大型语言模型（Large Language Models，如 ChatGPT 和 GPT-4）在基于文本的映射和导航能力。基准包括 53 个迷宫，每个配有游玩指南（walkthrough），任务是让模型回答数百个问答问题，例如“从 West of House 如何去 Attic？”或“从 Cellar 向北和向东去哪里？”。实验结果显示，即使是 GPT-4 在这些任务上表现不佳，准确率较低。作者进一步证明，增强映射和导航能力可显著改善模型在下游任务（如玩文本游戏）中的性能，并提供数据、代码和 leaderboard 以促进未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CL",
      "comment": "COLM 2024 camera-ready",
      "pdf_url": "http://arxiv.org/pdf/2403.19913v2",
      "published_date": "2024-03-29 01:53:24 UTC",
      "updated_date": "2024-08-08 06:38:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:13:33.658811"
    },
    {
      "arxiv_id": "2403.19907v1",
      "title": "Beyond the Known: Novel Class Discovery for Open-world Graph Learning",
      "title_zh": "超越已知：开放世界图学习中的新类发现",
      "authors": [
        "Yucheng Jin",
        "Yun Xiong",
        "Juncheng Fang",
        "Xixi Wu",
        "Dongxiao He",
        "Xing Jia",
        "Bingchen Zhao",
        "Philip Yu"
      ],
      "abstract": "Node classification on graphs is of great importance in many applications.\nDue to the limited labeling capability and evolution in real-world open\nscenarios, novel classes can emerge on unlabeled testing nodes. However, little\nattention has been paid to novel class discovery on graphs. Discovering novel\nclasses is challenging as novel and known class nodes are correlated by edges,\nwhich makes their representations indistinguishable when applying message\npassing GNNs. Furthermore, the novel classes lack labeling information to guide\nthe learning process. In this paper, we propose a novel method Open-world gRAph\nneuraL network (ORAL) to tackle these challenges. ORAL first detects\ncorrelations between classes through semi-supervised prototypical learning.\nInter-class correlations are subsequently eliminated by the prototypical\nattention network, leading to distinctive representations for different\nclasses. Furthermore, to fully explore multi-scale graph features for\nalleviating label deficiencies, ORAL generates pseudo-labels by aligning and\nensembling label estimations from multiple stacked prototypical attention\nnetworks. Extensive experiments on several benchmark datasets show the\neffectiveness of our proposed method.",
      "tldr_zh": "该论文探讨了图上节点分类（Node classification）在开放世界场景中的新型类发现（Novel Class Discovery）问题，强调新型类节点与已知类节点通过边连接导致表示难以区分，以及标签信息缺失的挑战。作者提出了一种新方法Open-world gRAph neuraL network (ORAL)，它首先通过半监督原型学习（semi-supervised prototypical learning）检测类间相关性，然后利用原型注意力网络（prototypical attention network）消除这些相关性，以获得不同类的独特表示，并通过对齐和集成多个堆叠网络的标签估计生成伪标签（pseudo-labels）。实验在多个基准数据集上证明，ORAL有效提升了新型类发现的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.19907v1",
      "published_date": "2024-03-29 01:25:05 UTC",
      "updated_date": "2024-03-29 01:25:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:13:47.630885"
    },
    {
      "arxiv_id": "2403.19905v1",
      "title": "Classification of Diabetic Retinopathy using Pre-Trained Deep Learning Models",
      "title_zh": "基于预训练深度学习模型的糖尿病视网膜病变分类",
      "authors": [
        "Inas Al-Kamachy",
        "Reza Hassanpour",
        "Roya Choupani"
      ],
      "abstract": "Diabetic Retinopathy (DR) stands as the leading cause of blindness globally,\nparticularly affecting individuals between the ages of 20 and 70. This paper\npresents a Computer-Aided Diagnosis (CAD) system designed for the automatic\nclassification of retinal images into five distinct classes: Normal, Mild,\nModerate, Severe, and Proliferative Diabetic Retinopathy (PDR). The proposed\nsystem leverages Convolutional Neural Networks (CNNs) employing pre-trained\ndeep learning models. Through the application of fine-tuning techniques, our\nmodel is trained on fundus images of diabetic retinopathy with resolutions of\n350x350x3 and 224x224x3. Experimental results obtained on the Kaggle platform,\nutilizing resources comprising 4 CPUs, 17 GB RAM, and 1 GB Disk, demonstrate\nthe efficacy of our approach. The achieved Area Under the Curve (AUC) values\nfor CNN, MobileNet, VGG-16, InceptionV3, and InceptionResNetV2 models are 0.50,\n0.70, 0.53, 0.63, and 0.69, respectively.",
      "tldr_zh": "本研究针对糖尿病视网膜病变 (Diabetic Retinopathy) 这一全球主要致盲原因，提出了一种计算机辅助诊断 (CAD) 系统，用于将视网膜图像自动分类为五类：Normal、Mild、Moderate、Severe 和 Proliferative Diabetic Retinopathy (PDR)。系统利用预训练的 Convolutional Neural Networks (CNNs) 模型，包括 MobileNet、VGG-16、InceptionV3 和 InceptionResNetV2，通过 fine-tuning 技术在分辨率为 350x350x3 和 224x224x3 的眼底图像上进行训练。实验结果显示，这些模型的 Area Under the Curve (AUC) 值分别为 0.50、0.70、0.53、0.63 和 0.69，其中 MobileNet 表现出最佳性能，为 DR 的自动诊断提供了有效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T07"
      ],
      "primary_category": "cs.CV",
      "comment": "3 pages, 1 figure, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2403.19905v1",
      "published_date": "2024-03-29 01:11:56 UTC",
      "updated_date": "2024-03-29 01:11:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:14:07.609636"
    },
    {
      "arxiv_id": "2403.19889v1",
      "title": "Towards a Robust Retrieval-Based Summarization System",
      "title_zh": "翻译失败",
      "authors": [
        "Shengjie Liu",
        "Jing Wu",
        "Jingyuan Bao",
        "Wenyi Wang",
        "Naira Hovakimyan",
        "Christopher G Healey"
      ],
      "abstract": "This paper describes an investigation of the robustness of large language\nmodels (LLMs) for retrieval augmented generation (RAG)-based summarization\ntasks. While LLMs provide summarization capabilities, their performance in\ncomplex, real-world scenarios remains under-explored. Our first contribution is\nLogicSumm, an innovative evaluation framework incorporating realistic scenarios\nto assess LLM robustness during RAG-based summarization. Based on limitations\nidentified by LogiSumm, we then developed SummRAG, a comprehensive system to\ncreate training dialogues and fine-tune a model to enhance robustness within\nLogicSumm's scenarios. SummRAG is an example of our goal of defining structured\nmethods to test the capabilities of an LLM, rather than addressing issues in a\none-off fashion. Experimental results confirm the power of SummRAG, showcasing\nimproved logical coherence and summarization quality. Data, corresponding model\nweights, and Python code are available online.",
      "tldr_zh": "本研究调查了大型语言模型 (LLMs) 在检索增强生成 (RAG) 基于的摘要任务中的鲁棒性，提出了一种创新评估框架 LogicSumm，以现实场景评估 LLM 的鲁棒性表现。针对 LogicSumm 识别出的局限性，研究团队开发了 SummRAG 系统，通过创建训练对话并微调模型来提升摘要任务的鲁棒性。实验结果显示，SummRAG 显著改善了逻辑连贯性和摘要质量，并提供了数据、模型权重和 Python 代码以供开源使用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.19889v1",
      "published_date": "2024-03-29 00:14:46 UTC",
      "updated_date": "2024-03-29 00:14:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:14:15.448593"
    },
    {
      "arxiv_id": "2404.00076v2",
      "title": "A Backdoor Approach with Inverted Labels Using Dirty Label-Flipping Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Orson Mengara"
      ],
      "abstract": "Audio-based machine learning systems frequently use public or third-party\ndata, which might be inaccurate. This exposes deep neural network (DNN) models\ntrained on such data to potential data poisoning attacks. In this type of\nassault, attackers can train the DNN model using poisoned data, potentially\ndegrading its performance. Another type of data poisoning attack that is\nextremely relevant to our investigation is label flipping, in which the\nattacker manipulates the labels for a subset of data. It has been demonstrated\nthat these assaults may drastically reduce system performance, even for\nattackers with minimal abilities. In this study, we propose a backdoor attack\nnamed 'DirtyFlipping', which uses dirty label techniques, \"label-on-label\", to\ninput triggers (clapping) in the selected data patterns associated with the\ntarget class, thereby enabling a stealthy backdoor.",
      "tldr_zh": "本研究探讨了音频-based 机器学习系统在使用公共数据时面临的标签翻转攻击风险，攻击者可通过操纵标签来破坏深层神经网络 (DNN) 模型的性能。论文提出了一种名为 DirtyFlipping 的后门攻击方法，利用 dirty label 技术（即 \"label-on-label\"），在选定的数据模式中加入触发器（如拍手声），以实现隐秘的后门注入。实验结果表明，这种攻击能显著降低系统性能，为评估和防御数据中毒攻击提供了新见解。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.CR",
      "comment": "Accept by \"IEEE Access\" let's take a look at our global approach to\n  the DNN(s) model(s) deployment chain in production: Danger NLP-Speech\n  (Trigger universal approach)",
      "pdf_url": "http://arxiv.org/pdf/2404.00076v2",
      "published_date": "2024-03-29 00:09:48 UTC",
      "updated_date": "2024-04-07 04:38:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:14:25.441704"
    },
    {
      "arxiv_id": "2403.19888v4",
      "title": "MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Behrouz",
        "Michele Santacatterina",
        "Ramin Zabih"
      ],
      "abstract": "Recent advances in deep learning have mainly relied on Transformers due to\ntheir data dependency and ability to learn at scale. The attention module in\nthese architectures, however, exhibits quadratic time and space in input size,\nlimiting their scalability for long-sequence modeling. Despite recent attempts\nto design efficient and effective architecture backbone for multi-dimensional\ndata, such as images and multivariate time series, existing models are either\ndata independent, or fail to allow inter- and intra-dimension communication.\nRecently, State Space Models (SSMs), and more specifically Selective State\nSpace Models, with efficient hardware-aware implementation, have shown\npromising potential for long sequence modeling. Motivated by the success of\nSSMs, we present MambaMixer, a new architecture with data-dependent weights\nthat uses a dual selection mechanism across tokens and channels, called\nSelective Token and Channel Mixer. MambaMixer connects selective mixers using a\nweighted averaging mechanism, allowing layers to have direct access to early\nfeatures. As a proof of concept, we design Vision MambaMixer (ViM2) and Time\nSeries MambaMixer (TSM2) architectures based on the MambaMixer block and\nexplore their performance in various vision and time series forecasting tasks.\nOur results underline the importance of selective mixing across both tokens and\nchannels. In ImageNet classification, object detection, and semantic\nsegmentation tasks, ViM2 achieves competitive performance with well-established\nvision models and outperforms SSM-based vision models. In time series\nforecasting, TSM2 achieves outstanding performance compared to state-of-the-art\nmethods while demonstrating significantly improved computational cost. These\nresults show that while Transformers, cross-channel attention, and MLPs are\nsufficient for good performance in time series forecasting, neither is\nnecessary.",
      "tldr_zh": "该研究提出 MambaMixer，一种高效的 Selective State Space Models (SSMs) 架构，通过双重选择机制（Dual Token and Channel Selection）实现对 tokens 和 channels 的数据依赖性混合，并使用加权平均机制连接选择混合器，以允许层级直接访问早期特征。相比 Transformer 的高计算复杂度，MambaMixer 解决了长序列建模的效率问题，并在视觉和时间序列任务中构建了 Vision MambaMixer (ViM2) 和 Time Series MambaMixer (TSM2)。实验结果显示，ViM2 在 ImageNet 分类、物体检测和语义分割任务中与现有模型竞争或优于其他 SSM-based 模型，而 TSM2 在时间序列预测中表现出色，同时显著降低了计算成本。这些发现证明，Selective mixing 机制的重要性，使得 Transformer、cross-channel attention 和 MLPs 并非必要。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.19888v4",
      "published_date": "2024-03-29 00:05:13 UTC",
      "updated_date": "2024-07-23 21:33:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:14:41.159569"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 74,
  "processed_papers_count": 74,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T20:15:07.888382"
}