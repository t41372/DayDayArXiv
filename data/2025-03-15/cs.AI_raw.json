[
  {
    "arxiv_id": "2503.16514v2",
    "title": "VeriMind: Agentic LLM for Automated Verilog Generation with a Novel Evaluation Metric",
    "authors": [
      "Bardia Nadimi",
      "Ghali Omar Boutaib",
      "Hao Zheng"
    ],
    "abstract": "Designing Verilog modules requires meticulous attention to correctness,\nefficiency, and adherence to design specifications. However, manually writing\nVerilog code remains a complex and time-consuming task that demands both expert\nknowledge and iterative refinement. Leveraging recent advancements in large\nlanguage models (LLMs) and their structured text generation capabilities, we\npropose VeriMind, an agentic LLM framework for Verilog code generation that\nsignificantly automates and optimizes the synthesis process. Unlike traditional\nLLM-based code generators, VeriMind employs a structured reasoning approach:\ngiven a user-provided prompt describing design requirements, the system first\nformulates a detailed train of thought before the final Verilog code is\ngenerated. This multi-step methodology enhances interpretability, accuracy, and\nadaptability in hardware design. In addition, we introduce a novel evaluation\nmetric-pass@ARC-which combines the conventional pass@k measure with Average\nRefinement Cycles (ARC) to capture both success rate and the efficiency of\niterative refinement. Experimental results on diverse hardware design tasks\ndemonstrated that our approach achieved up to $8.3\\%$ improvement on pass@k\nmetric and $8.1\\%$ on pass@ARC metric. These findings underscore the\ntransformative potential of agentic LLMs in automated hardware design, RTL\ndevelopment, and digital system synthesis.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16514v2",
    "published_date": "2025-03-15 23:43:06 UTC",
    "updated_date": "2025-03-24 15:14:06 UTC"
  },
  {
    "arxiv_id": "2503.12294v1",
    "title": "The Lucie-7B LLM and the Lucie Training Dataset: Open resources for multilingual language generation",
    "authors": [
      "Olivier Gouvert",
      "Julie Hunter",
      "Jérôme Louradour",
      "Christophe Cerisara",
      "Evan Dufraisse",
      "Yaya Sy",
      "Laura Rivière",
      "Jean-Pierre Lorré",
      "OpenLLM-France community"
    ],
    "abstract": "We present both the Lucie Training Dataset and the Lucie-7B foundation model.\nThe Lucie Training Dataset is a multilingual collection of textual corpora\ncentered around French and designed to offset anglo-centric biases found in\nmany datasets for large language model pretraining. Its French data is pulled\nnot only from traditional web sources, but also from French cultural heritage\ndocuments, filling an important gap in modern datasets. Beyond French, which\nmakes up the largest share of the data, we added documents to support several\nother European languages, including English, Spanish, German, and Italian.\nApart from its value as a resource for French language and culture, an\nimportant feature of this dataset is that it prioritizes data rights by\nminimizing copyrighted material. In addition, building on the philosophy of\npast open projects, it is redistributed in the form used for training and its\nprocessing is described on Hugging Face and GitHub. The Lucie-7B foundation\nmodel is trained on equal amounts of data in French and English -- roughly 33%\neach -- in an effort to better represent cultural aspects of French-speaking\ncommunities. We also describe two instruction fine-tuned models,\nLucie-7B-Instruct-v1.1 and Lucie-7B-Instruct-human-data, which we release as\ndemonstrations of Lucie-7B in use. These models achieve promising results\ncompared to state-of-the-art models, demonstrating that an open approach\nprioritizing data rights can still deliver strong performance. We see these\nmodels as an initial step toward developing more performant, aligned models in\nthe near future. Model weights for Lucie-7B and the Lucie instruct models,\nalong with intermediate checkpoints for the former, are published on Hugging\nFace, while model training and data preparation code is available on GitHub.\nThis makes Lucie-7B one of the first OSI compliant language models according to\nthe new OSI definition.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12294v1",
    "published_date": "2025-03-15 23:20:45 UTC",
    "updated_date": "2025-03-15 23:20:45 UTC"
  },
  {
    "arxiv_id": "2503.12286v1",
    "title": "Integrating Chain-of-Thought and Retrieval Augmented Generation Enhances Rare Disease Diagnosis from Clinical Notes",
    "authors": [
      "Da Wu",
      "Zhanliang Wang",
      "Quan Nguyen",
      "Kai Wang"
    ],
    "abstract": "Background: Several studies show that large language models (LLMs) struggle\nwith phenotype-driven gene prioritization for rare diseases. These studies\ntypically use Human Phenotype Ontology (HPO) terms to prompt foundation models\nlike GPT and LLaMA to predict candidate genes. However, in real-world settings,\nfoundation models are not optimized for domain-specific tasks like clinical\ndiagnosis, yet inputs are unstructured clinical notes rather than standardized\nterms. How LLMs can be instructed to predict candidate genes or disease\ndiagnosis from unstructured clinical notes remains a major challenge. Methods:\nWe introduce RAG-driven CoT and CoT-driven RAG, two methods that combine\nChain-of-Thought (CoT) and Retrieval Augmented Generation (RAG) to analyze\nclinical notes. A five-question CoT protocol mimics expert reasoning, while RAG\nretrieves data from sources like HPO and OMIM (Online Mendelian Inheritance in\nMan). We evaluated these approaches on rare disease datasets, including 5,980\nPhenopacket-derived notes, 255 literature-based narratives, and 220 in-house\nclinical notes from Childrens Hospital of Philadelphia. Results: We found that\nrecent foundations models, including Llama 3.3-70B-Instruct and\nDeepSeek-R1-Distill-Llama-70B, outperformed earlier versions such as Llama 2\nand GPT-3.5. We also showed that RAG-driven CoT and CoT-driven RAG both\noutperform foundation models in candidate gene prioritization from clinical\nnotes; in particular, both methods with DeepSeek backbone resulted in a top-10\ngene accuracy of over 40% on Phenopacket-derived clinical notes. RAG-driven CoT\nworks better for high-quality notes, where early retrieval can anchor the\nsubsequent reasoning steps in domain-specific evidence, while CoT-driven RAG\nhas advantage when processing lengthy and noisy notes.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.GN",
      "q-bio.QM"
    ],
    "primary_category": "cs.CL",
    "comment": "31 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.12286v1",
    "published_date": "2025-03-15 22:57:31 UTC",
    "updated_date": "2025-03-15 22:57:31 UTC"
  },
  {
    "arxiv_id": "2503.12285v1",
    "title": "Bi-Criteria Optimization for Combinatorial Bandits: Sublinear Regret and Constraint Violation under Bandit Feedback",
    "authors": [
      "Vaneet Aggarwal",
      "Shweta Jain",
      "Subham Pokhriyal",
      "Christopher John Quinn"
    ],
    "abstract": "In this paper, we study bi-criteria optimization for combinatorial\nmulti-armed bandits (CMAB) with bandit feedback. We propose a general framework\nthat transforms discrete bi-criteria offline approximation algorithms into\nonline algorithms with sublinear regret and cumulative constraint violation\n(CCV) guarantees. Our framework requires the offline algorithm to provide an\n$(\\alpha, \\beta)$-bi-criteria approximation ratio with $\\delta$-resilience and\nutilize $\\texttt{N}$ oracle calls to evaluate the objective and constraint\nfunctions. We prove that the proposed framework achieves sub-linear regret and\nCCV, with both bounds scaling as ${O}\\left(\\delta^{2/3}\n\\texttt{N}^{1/3}T^{2/3}\\log^{1/3}(T)\\right)$. Crucially, the framework treats\nthe offline algorithm with $\\delta$-resilience as a black box, enabling\nflexible integration of existing approximation algorithms into the CMAB\nsetting. To demonstrate its versatility, we apply our framework to several\ncombinatorial problems, including submodular cover, submodular cost covering,\nand fair submodular maximization. These applications highlight the framework's\nbroad utility in adapting offline guarantees to online bi-criteria optimization\nunder bandit feedback.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "cs.SY",
      "eess.SY",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12285v1",
    "published_date": "2025-03-15 22:52:27 UTC",
    "updated_date": "2025-03-15 22:52:27 UTC"
  },
  {
    "arxiv_id": "2503.12282v1",
    "title": "Toward Foundation Models for Online Complex Event Detection in CPS-IoT: A Case Study",
    "authors": [
      "Liying Han",
      "Gaofeng Dong",
      "Xiaomin Ouyang",
      "Lance Kaplan",
      "Federico Cerutti",
      "Mani Srivastava"
    ],
    "abstract": "Complex events (CEs) play a crucial role in CPS-IoT applications, enabling\nhigh-level decision-making in domains such as smart monitoring and autonomous\nsystems. However, most existing models focus on short-span perception tasks,\nlacking the long-term reasoning required for CE detection. CEs consist of\nsequences of short-time atomic events (AEs) governed by spatiotemporal\ndependencies. Detecting them is difficult due to long, noisy sensor data and\nthe challenge of filtering out irrelevant AEs while capturing meaningful\npatterns. This work explores CE detection as a case study for CPS-IoT\nfoundation models capable of long-term reasoning. We evaluate three approaches:\n(1) leveraging large language models (LLMs), (2) employing various neural\narchitectures that learn CE rules from data, and (3) adopting a neurosymbolic\napproach that integrates neural models with symbolic engines embedding human\nknowledge. Our results show that the state-space model, Mamba, which belongs to\nthe second category, outperforms all methods in accuracy and generalization to\nlonger, unseen sensor traces. These findings suggest that state-space models\ncould be a strong backbone for CPS-IoT foundation models for long-span\nreasoning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12282v1",
    "published_date": "2025-03-15 22:39:01 UTC",
    "updated_date": "2025-03-15 22:39:01 UTC"
  },
  {
    "arxiv_id": "2503.13538v1",
    "title": "From Demonstrations to Rewards: Alignment Without Explicit Human Preferences",
    "authors": [
      "Siliang Zeng",
      "Yao Liu",
      "Huzefa Rangwala",
      "George Karypis",
      "Mingyi Hong",
      "Rasool Fakoor"
    ],
    "abstract": "One of the challenges of aligning large models with human preferences lies in\nboth the data requirements and the technical complexities of current\napproaches. Predominant methods, such as RLHF, involve multiple steps, each\ndemanding distinct types of data, including demonstration data and preference\ndata. In RLHF, human preferences are typically modeled through a reward model,\nwhich serves as a proxy to guide policy learning during the reinforcement\nlearning stage, ultimately producing a policy aligned with human preferences.\nHowever, in this paper, we propose a fresh perspective on learning alignment\nbased on inverse reinforcement learning principles, where the optimal policy is\nstill derived from reward maximization. However, instead of relying on\npreference data, we directly learn the reward model from demonstration data.\nThis new formulation offers the flexibility to be applied even when only\ndemonstration data is available, a capability that current RLHF methods lack,\nand it also shows that demonstration data offers more utility than what\nconventional wisdom suggests. Our extensive evaluation, based on public reward\nbenchmark, HuggingFace Open LLM Leaderboard and MT-Bench, demonstrates that our\napproach compares favorably to state-of-the-art methods that rely solely on\ndemonstration data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.13538v1",
    "published_date": "2025-03-15 20:53:46 UTC",
    "updated_date": "2025-03-15 20:53:46 UTC"
  },
  {
    "arxiv_id": "2503.12255v1",
    "title": "Agentic Search Engine for Real-Time IoT Data",
    "authors": [
      "Abdelrahman Elewah",
      "Khalid Elgazzar"
    ],
    "abstract": "The Internet of Things (IoT) has enabled diverse devices to communicate over\nthe Internet, yet the fragmentation of IoT systems limits seamless data sharing\nand coordinated management. We have recently introduced SensorsConnect, a\nunified framework to enable seamless content and sensor data sharing in\ncollaborative IoT systems, inspired by how the World Wide Web (WWW) enabled a\nshared and accessible space for information among humans. This paper presents\nthe IoT Agentic Search Engine (IoT-ASE), a real-time search engine tailored for\nIoT environments. IoT-ASE leverages Large Language Models (LLMs) and Retrieval\nAugmented Generation (RAG) techniques to address the challenge of searching\nvast, real-time IoT data, enabling it to handle complex queries and deliver\naccurate, contextually relevant results. We implemented a use-case scenario in\nToronto to demonstrate how IoT-ASE can improve service quality recommendations\nby leveraging real-time IoT data. Our evaluation shows that IoT-ASE achieves a\n92\\% accuracy in retrieving intent-based services and produces responses that\nare concise, relevant, and context-aware, outperforming generalized responses\nfrom systems like Gemini. These findings highlight the potential IoT-ASE to\nmake real-time IoT data accessible and support effective, real-time\ndecision-making.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12255v1",
    "published_date": "2025-03-15 20:46:17 UTC",
    "updated_date": "2025-03-15 20:46:17 UTC"
  },
  {
    "arxiv_id": "2503.12243v1",
    "title": "GenOSIL: Generalized Optimal and Safe Robot Control using Parameter-Conditioned Imitation Learning",
    "authors": [
      "Mumuksh Tayal",
      "Manan Tayal",
      "Ravi Prakash"
    ],
    "abstract": "Ensuring safe and generalizable control remains a fundamental challenge in\nrobotics, particularly when deploying imitation learning in dynamic\nenvironments. Traditional behavior cloning (BC) struggles to generalize beyond\nits training distribution, as it lacks an understanding of the safety critical\nreasoning behind expert demonstrations. To address this limitation, we propose\nGenOSIL, a novel imitation learning framework that explicitly incorporates\nenvironment parameters into policy learning via a structured latent\nrepresentation. Unlike conventional methods that treat the environment as a\nblack box, GenOSIL employs a variational autoencoder (VAE) to encode measurable\nsafety parameters such as obstacle position, velocity, and geometry into a\nlatent space that captures intrinsic correlations between expert behavior and\nenvironmental constraints. This enables the policy to infer the rationale\nbehind expert trajectories rather than merely replicating them. We validate our\napproach on two robotic platforms an autonomous ground vehicle and a Franka\nEmika Panda manipulator demonstrating superior safety and goal reaching\nperformance compared to baseline methods. The simulation and hardware videos\ncan be viewed on the project webpage: https://mumukshtayal.github.io/GenOSIL/.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.12243v1",
    "published_date": "2025-03-15 19:52:16 UTC",
    "updated_date": "2025-03-15 19:52:16 UTC"
  },
  {
    "arxiv_id": "2503.12239v1",
    "title": "A Novel Double Pruning method for Imbalanced Data using Information Entropy and Roulette Wheel Selection for Breast Cancer Diagnosis",
    "authors": [
      "Soufiane Bacha",
      "Huansheng Ning",
      "Belarbi Mostefa",
      "Doreen Sebastian Sarwatt",
      "Sahraoui Dhelim"
    ],
    "abstract": "Accurate illness diagnosis is vital for effective treatment and patient\nsafety. Machine learning models are widely used for cancer diagnosis based on\nhistorical medical data. However, data imbalance remains a major challenge,\nleading to hindering classifier performance and reliability. The SMOTEBoost\nmethod addresses this issue by generating synthetic data to balance the\ndataset, but it may overlook crucial overlapping regions near the decision\nboundary and can produce noisy samples. This paper proposes RE-SMOTEBoost, an\nenhanced version of SMOTEBoost, designed to overcome these limitations.\nFirstly, RE-SMOTEBoost focuses on generating synthetic samples in overlapping\nregions to better capture the decision boundary using roulette wheel selection.\nSecondly, it incorporates a filtering mechanism based on information entropy to\nreduce noise, and borderline cases and improve the quality of generated data.\nThirdly, we introduce a double regularization penalty to control the synthetic\nsamples proximity to the decision boundary and avoid class overlap. These\nenhancements enable higher-quality oversampling of the minority class,\nresulting in a more balanced and effective training dataset. The proposed\nmethod outperforms existing state-of-the-art techniques when evaluated on\nimbalanced datasets. Compared to the top-performing sampling algorithms,\nRE-SMOTEBoost demonstrates a notable improvement of 3.22\\% in accuracy and a\nvariance reduction of 88.8\\%. These results indicate that the proposed model\noffers a solid solution for medical settings, effectively overcoming data\nscarcity and severe imbalance caused by limited samples, data collection\ndifficulties, and privacy constraints.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12239v1",
    "published_date": "2025-03-15 19:34:15 UTC",
    "updated_date": "2025-03-15 19:34:15 UTC"
  },
  {
    "arxiv_id": "2503.12230v1",
    "title": "LIAM: Multimodal Transformer for Language Instructions, Images, Actions and Semantic Maps",
    "authors": [
      "Yihao Wang",
      "Raphael Memmesheimer",
      "Sven Behnke"
    ],
    "abstract": "The availability of large language models and open-vocabulary object\nperception methods enables more flexibility for domestic service robots. The\nlarge variability of domestic tasks can be addressed without implementing each\ntask individually by providing the robot with a task description along with\nappropriate environment information. In this work, we propose LIAM - an\nend-to-end model that predicts action transcripts based on language, image,\naction, and map inputs. Language and image inputs are encoded with a CLIP\nbackbone, for which we designed two pre-training tasks to fine-tune its weights\nand pre-align the latent spaces. We evaluate our method on the ALFRED dataset,\na simulator-generated benchmark for domestic tasks. Our results demonstrate the\nimportance of pre-aligning embedding spaces from different modalities and the\nefficacy of incorporating semantic maps.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12230v1",
    "published_date": "2025-03-15 18:54:06 UTC",
    "updated_date": "2025-03-15 18:54:06 UTC"
  },
  {
    "arxiv_id": "2503.12228v1",
    "title": "Adaptive Fault Tolerance Mechanisms of Large Language Models in Cloud Computing Environments",
    "authors": [
      "Yihong Jin",
      "Ze Yang",
      "Xinhe Xu",
      "Yihan Zhang",
      "Shuyang Ji"
    ],
    "abstract": "With the rapid evolution of Large Language Models (LLMs) and their\nlarge-scale experimentation in cloud-computing spaces, the challenge of\nguaranteeing their security and efficiency in a failure scenario has become a\nmain issue. To ensure the reliability and availability of large-scale language\nmodels in cloud computing scenarios, such as frequent resource failures,\nnetwork problems, and computational overheads, this study proposes a novel\nadaptive fault tolerance mechanism. It builds upon known fault-tolerant\nmechanisms, such as checkpointing, redundancy, and state transposition,\nintroducing dynamic resource allocation and prediction of failure based on\nreal-time performance metrics. The hybrid model integrates data driven deep\nlearning-based anomaly detection technique underlining the contribution of\ncloud orchestration middleware for predictive prevention of system failures.\nAdditionally, the model integrates adaptive checkpointing and recovery\nstrategies that dynamically adapt according to load and system state to\nminimize the influence on the performance of the model and minimize downtime.\nThe experimental results demonstrate that the designed model considerably\nenhances the fault tolerance in large-scale cloud surroundings, and decreases\nthe system downtime by $\\mathbf{30\\%}$, and has a better modeling availability\nthan the classical fault tolerance mechanism.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "Accepted by IEEE ICCEA 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.12228v1",
    "published_date": "2025-03-15 18:45:33 UTC",
    "updated_date": "2025-03-15 18:45:33 UTC"
  },
  {
    "arxiv_id": "2503.12226v1",
    "title": "Research on Large Language Model Cross-Cloud Privacy Protection and Collaborative Training based on Federated Learning",
    "authors": [
      "Ze Yang",
      "Yihong Jin",
      "Yihan Zhang",
      "Juntian Liu",
      "Xinhe Xu"
    ],
    "abstract": "The fast development of large language models (LLMs) and popularization of\ncloud computing have led to increasing concerns on privacy safeguarding and\ndata security of cross-cloud model deployment and training as the key\nchallenges. We present a new framework for addressing these issues along with\nenabling privacy preserving collaboration on training between distributed\nclouds based on federated learning. Our mechanism encompasses cutting-edge\ncryptographic primitives, dynamic model aggregation techniques, and cross-cloud\ndata harmonization solutions to enhance security, efficiency, and scalability\nto the traditional federated learning paradigm. Furthermore, we proposed a\nhybrid aggregation scheme to mitigate the threat of Data Leakage and to\noptimize the aggregation of model updates, thus achieving substantial\nenhancement on the model effectiveness and stability. Experimental results\ndemonstrate that the training efficiency, privacy protection, and model\naccuracy of the proposed model compare favorably to those of the traditional\nfederated learning method.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by IEEE AINIT 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.12226v1",
    "published_date": "2025-03-15 18:44:50 UTC",
    "updated_date": "2025-03-15 18:44:50 UTC"
  },
  {
    "arxiv_id": "2503.12222v1",
    "title": "Evaluation-Time Policy Switching for Offline Reinforcement Learning",
    "authors": [
      "Natinael Solomon Neggatu",
      "Jeremie Houssineau",
      "Giovanni Montana"
    ],
    "abstract": "Offline reinforcement learning (RL) looks at learning how to optimally solve\ntasks using a fixed dataset of interactions from the environment. Many\noff-policy algorithms developed for online learning struggle in the offline\nsetting as they tend to over-estimate the behaviour of out of distributions\nactions. Existing offline RL algorithms adapt off-policy algorithms, employing\ntechniques such as constraining the policy or modifying the value function to\nachieve good performance on individual datasets but struggle to adapt to\ndifferent tasks or datasets of different qualities without tuning\nhyper-parameters. We introduce a policy switching technique that dynamically\ncombines the behaviour of a pure off-policy RL agent, for improving behaviour,\nand a behavioural cloning (BC) agent, for staying close to the data. We achieve\nthis by using a combination of epistemic uncertainty, quantified by our RL\nmodel, and a metric for aleatoric uncertainty extracted from the dataset. We\nshow empirically that our policy switching technique can outperform not only\nthe individual algorithms used in the switching process but also compete with\nstate-of-the-art methods on numerous benchmarks. Our use of epistemic\nuncertainty for policy switching also allows us to naturally extend our method\nto the domain of offline to online fine-tuning allowing our model to adapt\nquickly and safely from online data, either matching or exceeding the\nperformance of current methods that typically require additional modification\nor hyper-parameter fine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Proc. of the 24th International Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 2025)",
    "pdf_url": "http://arxiv.org/pdf/2503.12222v1",
    "published_date": "2025-03-15 18:12:16 UTC",
    "updated_date": "2025-03-15 18:12:16 UTC"
  },
  {
    "arxiv_id": "2503.16513v1",
    "title": "Medifact at PerAnsSumm 2025: Leveraging Lightweight Models for Perspective-Specific Summarization of Clinical Q&A Forums",
    "authors": [
      "Nadia Saeed"
    ],
    "abstract": "The PerAnsSumm 2025 challenge focuses on perspective-aware healthcare answer\nsummarization (Agarwal et al., 2025). This work proposes a few-shot learning\nframework using a Snorkel-BART-SVM pipeline for classifying and summarizing\nopen-ended healthcare community question-answering (CQA). An SVM model is\ntrained with weak supervision via Snorkel, enhancing zero-shot learning.\nExtractive classification identifies perspective-relevant sentences, which are\nthen summarized using a pretrained BART-CNN model. The approach achieved 12th\nplace among 100 teams in the shared task, demonstrating computational\nefficiency and contextual accuracy. By leveraging pretrained summarization\nmodels, this work advances medical CQA research and contributes to clinical\ndecision support systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper accepted in PerAnsSumm: Perspective-aware Healthcare\n  answer summarization, a shared task organized at the CL4Health workshop\n  colocated with NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.16513v1",
    "published_date": "2025-03-15 17:36:02 UTC",
    "updated_date": "2025-03-15 17:36:02 UTC"
  },
  {
    "arxiv_id": "2503.12211v1",
    "title": "Changing Base Without Losing Pace: A GPU-Efficient Alternative to MatMul in DNNs",
    "authors": [
      "Nir Ailon",
      "Akhiad Bercovich",
      "Omri Weinstein"
    ],
    "abstract": "We propose a cheaper alternative bilinear operator to matrix-multiplication\nin deep neural networks (DNNs). Unlike many stubborn attempts to accelerate\nMatMuls in DNN inference, this operator is supported by capabilities of\nexisting GPU hardware, most notably NVIDIA TensorCores. To our knowledge, this\nis the first GPU-native acceleration technique which \\emph{does not decrease}\n(in fact, increases) the number of trainable parameters of the network,\nmitigating the accuracy-loss of compression-based techniques. Hence, this\noperator is at the same time more expressive than MatMul, yet requires\nsubstantially \\emph{fewer} FLOPs to evaluate. We term this new operator\n\\emph{Strassen-Tile} (STL).\n  The main idea behind STL$(X,W)$ is a \\emph{local} change-of-basis (learnable\nencoder) on weights and activation \\emph{tiles}, after which we perform batched\n\\emph{elementwise} products between tiles, and a final decoding transformation\n(inspired by algebraic pipelines from fast matrix and polynomial\nmultiplication).\n  We compare STL against two benchmarks. The first one is SoTA T2T-ViT on\nImagenet-1K. Here we show that replacing \\emph{all} linear layers with STL and\ntraining from scratch, results in factor x2.7 reduction in FLOPs with a 0.5\n\\emph{accuracy improvement}. Our second speed-accuracy comparison benchmark for\npretrained LLMs is the most practical GPU-acceleration technique, \\twofour\nstructured Sparsity. Finetuning TinyLlama \\cite{tinyllama24} with STL layers on\nthe Slim Pajama dataset, achieves similar accuracy to 2:4, with x2.2 FLOP\nspeedup compared to x1.7 of the latter.\n  Finally, we discuss a group-theoretic approach for discovering\n\\emph{universal} encoders for STL, which could lead to fast \\emph{black-box}\nacceleration via approximate matrix-multiplication (AMM).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12211v1",
    "published_date": "2025-03-15 17:31:36 UTC",
    "updated_date": "2025-03-15 17:31:36 UTC"
  },
  {
    "arxiv_id": "2503.12181v1",
    "title": "Value Gradients with Action Adaptive Search Trees in Continuous (PO)MDPs",
    "authors": [
      "Idan Lev-Yehudi",
      "Michael Novitsky",
      "Moran Barenboim",
      "Ron Benchetrit",
      "Vadim Indelman"
    ],
    "abstract": "Solving Partially Observable Markov Decision Processes (POMDPs) in continuous\nstate, action and observation spaces is key for autonomous planning in many\nreal-world mobility and robotics applications. Current approaches are mostly\nsample based, and cannot hope to reach near-optimal solutions in reasonable\ntime. We propose two complementary theoretical contributions. First, we\nformulate a novel Multiple Importance Sampling (MIS) tree for value estimation,\nthat allows to share value information between sibling action branches. The\nnovel MIS tree supports action updates during search time, such as\ngradient-based updates. Second, we propose a novel methodology to compute value\ngradients with online sampling based on transition likelihoods. It is\napplicable to MDPs, and we extend it to POMDPs via particle beliefs with the\napplication of the propagated belief trick. The gradient estimator is computed\nin practice using the MIS tree with efficient Monte Carlo sampling. These two\nparts are combined into a new planning algorithm Action Gradient Monte Carlo\nTree Search (AGMCTS). We demonstrate in a simulated environment its\napplicability, advantages over continuous online POMDP solvers that rely solely\non sampling, and we discuss further implications.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12181v1",
    "published_date": "2025-03-15 15:51:06 UTC",
    "updated_date": "2025-03-15 15:51:06 UTC"
  },
  {
    "arxiv_id": "2503.12162v1",
    "title": "Probabilistic Graph Circuits: Deep Generative Models for Tractable Probabilistic Inference over Graphs",
    "authors": [
      "Milan Papež",
      "Martin Rektoris",
      "Václav Šmídl",
      "Tomáš Pevný"
    ],
    "abstract": "Deep generative models (DGMs) have recently demonstrated remarkable success\nin capturing complex probability distributions over graphs. Although their\nexcellent performance is attributed to powerful and scalable deep neural\nnetworks, it is, at the same time, exactly the presence of these highly\nnon-linear transformations that makes DGMs intractable. Indeed, despite\nrepresenting probability distributions, intractable DGMs deny probabilistic\nfoundations by their inability to answer even the most basic inference queries\nwithout approximations or design choices specific to a very narrow range of\nqueries. To address this limitation, we propose probabilistic graph circuits\n(PGCs), a framework of tractable DGMs that provide exact and efficient\nprobabilistic inference over (arbitrary parts of) graphs. Nonetheless,\nachieving both exactness and efficiency is challenging in the\npermutation-invariant setting of graphs. We design PGCs that are inherently\ninvariant and satisfy these two requirements, yet at the cost of low expressive\npower. Therefore, we investigate two alternative strategies to achieve the\ninvariance: the first sacrifices the efficiency, and the second sacrifices the\nexactness. We demonstrate that ignoring the permutation invariance can have\nsevere consequences in anomaly detection, and that the latter approach is\ncompetitive with, and sometimes better than, existing intractable DGMs in the\ncontext of molecular graph generation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12162v1",
    "published_date": "2025-03-15 15:01:53 UTC",
    "updated_date": "2025-03-15 15:01:53 UTC"
  },
  {
    "arxiv_id": "2503.12161v1",
    "title": "Aristotle's Original Idea: For and Against Logic in the era of AI",
    "authors": [
      "Antonis C. Kakas"
    ],
    "abstract": "Aristotle is generally accepted as the father of logic. The ideas that he\nraised in his study of logical reasoning carried the development of science\nover the centuries. Today, in the era of AI, this title of the fatherhood of\nlogic has a renewed significance. Behind it lies his original idea that human\nreasoning could be studied as a process and that perhaps there exist universal\nsystems of reasoning that underly all human reasoning irrespective of the\ncontent of what we are reasoning about. In this article, we look into\nAristotle's work on human thought, his work on reasoning itself but also on how\nit relates to science and human endeavor more generally, from a modern\nperspective of Artificial Intelligence and ask if this can help enlighten our\nunderstanding of AI and Science more generally.",
    "categories": [
      "cs.AI",
      "I.2.0 General"
    ],
    "primary_category": "cs.AI",
    "comment": "40 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.12161v1",
    "published_date": "2025-03-15 14:55:52 UTC",
    "updated_date": "2025-03-15 14:55:52 UTC"
  },
  {
    "arxiv_id": "2503.12157v1",
    "title": "Weighted Graph Structure Learning with Attention Denoising for Node Classification",
    "authors": [
      "Tingting Wang",
      "Jiaxin Su",
      "Haobing Liu",
      "Ruobing Jiang"
    ],
    "abstract": "Node classification in graphs aims to predict the categories of unlabeled\nnodes by utilizing a small set of labeled nodes. However, weighted graphs often\ncontain noisy edges and anomalous edge weights, which can distort fine-grained\nrelationships between nodes and hinder accurate classification. We propose the\nEdge Weight-aware Graph Structure Learning (EWGSL) method, which combines\nweight learning and graph structure learning to address these issues. EWGSL\nimproves node classification by redefining attention coefficients in graph\nattention networks to incorporate node features and edge weights. It also\napplies graph structure learning to sparsify attention coefficients and uses a\nmodified InfoNCE loss function to enhance performance by adapting to denoised\ngraph weights. Extensive experimental results show that EWGSL has an average\nMicro-F1 improvement of 17.8% compared with the best baseline.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.12157v1",
    "published_date": "2025-03-15 14:54:27 UTC",
    "updated_date": "2025-03-15 14:54:27 UTC"
  },
  {
    "arxiv_id": "2503.13535v1",
    "title": "Unlocking Learning Potentials: The Transformative Effect of Generative AI in Education Across Grade Levels",
    "authors": [
      "Meijuan Xie",
      "Liling Luo"
    ],
    "abstract": "The advent of generative artificial intelligence (GAI) has brought about a\nnotable surge in the field of education. The use of GAI to support learning is\nbecoming increasingly prevalent among students. However, the manner and extent\nof its utilisation vary considerably from one individual to another. And\nresearches about student's utilisation and perceptions of GAI remains\nrelatively scarce. To gain insight into the issue, this paper proposed a\nhybrid-survey method to examine the impact of GAI on students across four\ndifferent grades in six key areas (LIPSAL): learning interest, independent\nlearning, problem solving, self-confidence, appropriate use, and learning\nenjoyment. Firstly, through questionnaire, we found that among LIPSAL, GAI has\nthe greatest impact on the concept of appropriate use, the lowest level of\nlearning interest and self-confidence. Secondly, a comparison of four grades\nrevealed that the high and low factors of LIPSAL exhibited grade-related\nvariation, and college students exhibited a higher level than high school\nstudents across LIPSAL. Thirdly, through interview, the students demonstrated a\ncomprehensive understanding of the application of GAI. We found that students\nhave a positive attitude towards GAI and are very willing to use it, which is\nwhy GAI has grown so rapidly in popularity. They also told us prospects and\nchallenges in using GAI. In the future, as GAI matures technologically, it will\nhave an greater impact on students. These findings may help better understand\nusage by different students and inform future research in digital education.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.13535v1",
    "published_date": "2025-03-15 14:16:43 UTC",
    "updated_date": "2025-03-15 14:16:43 UTC"
  },
  {
    "arxiv_id": "2503.13533v1",
    "title": "The Status Quo and Future of AI-TPACK for Mathematics Teacher Education Students: A Case Study in Chinese Universities",
    "authors": [
      "Meijuan Xie",
      "Liling Luo"
    ],
    "abstract": "As artificial intelligence (AI) technology becomes increasingly prevalent in\nthe filed of education, there is a growing need for mathematics teacher\neducation students (MTES) to demonstrate proficiency in the integration of AI\nwith the technological pedagogical content knowledge (AI-TPACK). To study the\nissue, we firstly devised an systematic AI-TPACK scale and test on 412 MTES\nfrom seven universities. Through descriptive statistical analyses, we found\nthat the current status of AI-TPACK for MTES in China is at a basic,\npreliminary stage. Secondly, we compared MTES between three different grades on\nthe six variables and found that there is no discernible difference, which\nsuggested that graduate studies were observed to have no promotion in the\ndevelopment of AI-TPACK competencies. Thirdly, we proposed a new AI-TPACK\nstructural equation model (AI-TPACK-SEM) to explore the impact of self-efficacy\nand teaching beliefs on AI-TPACK. Our findings indicate a positive correlation\nbetween self-efficacy and AI-TPACK. We also come to a conclusion that may be\ncontrary to common perception, excessive teaching beliefs may impede the\nadvancement of AI-TPACK. Overall, this paper revealed the current status of\nAI-TPACK for MTES in China for the first time, designed a dedicated SEM to\nstudy the effect of specific factors on AI-TPACK, and proposed some suggestions\non future developments.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.13533v1",
    "published_date": "2025-03-15 14:04:14 UTC",
    "updated_date": "2025-03-15 14:04:14 UTC"
  },
  {
    "arxiv_id": "2503.12143v1",
    "title": "Language Models for Automated Classification of Brain MRI Reports and Growth Chart Generation",
    "authors": [
      "Maryam Daniali",
      "Shivaram Karandikar",
      "Dabriel Zimmerman",
      "J. Eric Schmitt",
      "Matthew J. Buczek",
      "Benjamin Jung",
      "Laura Mercedes",
      "Jakob Seidlitz",
      "Vanessa Troiani",
      "Lena Dorfschmidt",
      "Eren Kafadar",
      "Remo Williams",
      "Susan Sotardi",
      "Arastoo Vosough",
      "Scott Haag",
      "Jenna M. Schabdach",
      "Aaron Alexander-Bloch"
    ],
    "abstract": "Clinically acquired brain MRIs and radiology reports are valuable but\nunderutilized resources due to the challenges of manual analysis and data\nheterogeneity. We developed fine-tuned language models (LMs) to classify brain\nMRI reports as normal (reports with limited pathology) or abnormal, fine-tuning\nBERT, BioBERT, ClinicalBERT, and RadBERT on 44,661 reports. We also explored\nthe reasoning capabilities of a leading LM, Gemini 1.5-Pro, for normal report\ncategorization. Automated image processing and modeling generated brain growth\ncharts from LM-classified normal scans, comparing them to human-derived charts.\nFine-tuned LMs achieved high classification performance (F1-Score >97%), with\nunbalanced training mitigating class imbalance. Performance was robust on\nout-of-distribution data, with full text outperforming summary (impression)\nsections. Gemini 1.5-Pro showed a promising categorization performance,\nespecially with clinical inference. LM-derived brain growth charts were nearly\nidentical to human-annotated charts (r = 0.99, p < 2.2e-16). Our LMs offer\nscalable analysis of radiology reports, enabling automated classification of\nbrain MRIs in large datasets. One application is automated generation of brain\ngrowth charts for benchmarking quantitative image features. Further research is\nneeded to address data heterogeneity and optimize LM reasoning.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12143v1",
    "published_date": "2025-03-15 13:59:44 UTC",
    "updated_date": "2025-03-15 13:59:44 UTC"
  },
  {
    "arxiv_id": "2503.15544v1",
    "title": "A Logic of Uncertain Interpretation",
    "authors": [
      "Adam Bjorndahl"
    ],
    "abstract": "We introduce a logical framework for reasoning about \"uncertain\ninterpretations\" and investigate two key applications: a new semantics for\nimplication capturing a kind of \"meaning entailment\", and a conservative notion\nof \"evidentially supported\" belief that takes the form of a Dempster-Shafer\nbelief function.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.15544v1",
    "published_date": "2025-03-15 13:40:51 UTC",
    "updated_date": "2025-03-15 13:40:51 UTC"
  },
  {
    "arxiv_id": "2503.12131v1",
    "title": "DiffGAP: A Lightweight Diffusion Module in Contrastive Space for Bridging Cross-Model Gap",
    "authors": [
      "Shentong Mo",
      "Zehua Chen",
      "Fan Bao",
      "Jun Zhu"
    ],
    "abstract": "Recent works in cross-modal understanding and generation, notably through\nmodels like CLAP (Contrastive Language-Audio Pretraining) and CAVP (Contrastive\nAudio-Visual Pretraining), have significantly enhanced the alignment of text,\nvideo, and audio embeddings via a single contrastive loss. However, these\nmethods often overlook the bidirectional interactions and inherent noises\npresent in each modality, which can crucially impact the quality and efficacy\nof cross-modal integration. To address this limitation, we introduce DiffGAP, a\nnovel approach incorporating a lightweight generative module within the\ncontrastive space. Specifically, our DiffGAP employs a bidirectional diffusion\nprocess tailored to bridge the cross-modal gap more effectively. This involves\na denoising process on text and video embeddings conditioned on audio\nembeddings and vice versa, thus facilitating a more nuanced and robust\ncross-modal interaction. Our experimental results on VGGSound and AudioCaps\ndatasets demonstrate that DiffGAP significantly improves performance in\nvideo/text-audio generation and retrieval tasks, confirming its effectiveness\nin enhancing cross-modal understanding and generation capabilities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12131v1",
    "published_date": "2025-03-15 13:24:09 UTC",
    "updated_date": "2025-03-15 13:24:09 UTC"
  },
  {
    "arxiv_id": "2503.12127v1",
    "title": "Hyperbolic Safety-Aware Vision-Language Models",
    "authors": [
      "Tobia Poppi",
      "Tejaswi Kasarla",
      "Pascal Mettes",
      "Lorenzo Baraldi",
      "Rita Cucchiara"
    ],
    "abstract": "Addressing the retrieval of unsafe content from vision-language models such\nas CLIP is an important step towards real-world integration. Current efforts\nhave relied on unlearning techniques that try to erase the model's knowledge of\nunsafe concepts. While effective in reducing unwanted outputs, unlearning\nlimits the model's capacity to discern between safe and unsafe content. In this\nwork, we introduce a novel approach that shifts from unlearning to an awareness\nparadigm by leveraging the inherent hierarchical properties of the hyperbolic\nspace. We propose to encode safe and unsafe content as an entailment hierarchy,\nwhere both are placed in different regions of hyperbolic space. Our HySAC,\nHyperbolic Safety-Aware CLIP, employs entailment loss functions to model the\nhierarchical and asymmetrical relations between safe and unsafe image-text\npairs. This modelling, ineffective in standard vision-language models due to\ntheir reliance on Euclidean embeddings, endows the model with awareness of\nunsafe content, enabling it to serve as both a multimodal unsafe classifier and\na flexible content retriever, with the option to dynamically redirect unsafe\nqueries toward safer alternatives or retain the original output. Extensive\nexperiments show that our approach not only enhances safety recognition but\nalso establishes a more adaptable and interpretable framework for content\nmoderation in vision-language models. Our source code is available at\nhttps://github.com/aimagelab/HySAC.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.12127v1",
    "published_date": "2025-03-15 13:18:04 UTC",
    "updated_date": "2025-03-15 13:18:04 UTC"
  },
  {
    "arxiv_id": "2503.12125v1",
    "title": "Robust Isolation Forest using Soft Sparse Random Projection and Valley Emphasis Method",
    "authors": [
      "Hun Kang",
      "Kyoungok Kim"
    ],
    "abstract": "Isolation Forest (iForest) is an unsupervised anomaly detection algorithm\ndesigned to effectively detect anomalies under the assumption that anomalies\nare ``few and different.\" Various studies have aimed to enhance iForest, but\nthe resulting algorithms often exhibited significant performance disparities\nacross datasets. Additionally, the challenge of isolating rare and widely\ndistributed anomalies persisted in research focused on improving splits. To\naddress these challenges, we introduce Robust iForest (RiForest). RiForest\nleverages both existing features and random hyperplanes obtained through soft\nsparse random projection to identify superior split features for anomaly\ndetection, independent of datasets. It utilizes the underutilized valley\nemphasis method for optimal split point determination and incorporates sparsity\nrandomization in soft sparse random projection for enhanced anomaly detection\nrobustness. Across 24 benchmark datasets, experiments demonstrate RiForest's\nconsistent outperformance of existing algorithms in anomaly detection,\nemphasizing stability and robustness to noise variables.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12125v1",
    "published_date": "2025-03-15 13:08:50 UTC",
    "updated_date": "2025-03-15 13:08:50 UTC"
  },
  {
    "arxiv_id": "2503.12123v1",
    "title": "MT-RewardTree: A Comprehensive Framework for Advancing LLM-Based Machine Translation via Reward Modeling",
    "authors": [
      "Zhaopeng Feng",
      "Jiahan Ren",
      "Jiayuan Su",
      "Jiamei Zheng",
      "Zhihang Tang",
      "Hongwei Wang",
      "Zuozhu Liu"
    ],
    "abstract": "Process reward models (PRMs) have shown success in complex reasoning tasks\nfor large language models (LLMs). However, their application to machine\ntranslation (MT) remains underexplored due to the lack of systematic\nmethodologies and evaluation benchmarks. To address this gap, we introduce\n\\textbf{MT-RewardTree}, a comprehensive framework for constructing, evaluating,\nand deploying process reward models in MT. Unlike traditional vanilla\npreference pair construction, we propose a novel method for automatically\ngenerating token-level preference pairs using approximate Monte Carlo Tree\nSearch (MCTS), which mitigates the prohibitive cost of human annotation for\nfine-grained steps. Then, we establish the first MT-specific reward model\nbenchmark and provide a systematic comparison of different reward modeling\narchitectures, revealing that token-level supervision effectively captures\nfine-grained preferences. Experimental results demonstrate that our\nMT-PRM-Qwen-2.5-3B achieves state-of-the-art performance in both token-level\nand sequence-level evaluation given the same input prefix. Furthermore, we\nshowcase practical applications where PRMs enable test-time alignment for LLMs\nwithout additional alignment training and significantly improve performance in\nhypothesis ensembling. Our work provides valuable insights into the role of\nreward models in MT research. Our code and data are released in\n\\href{https://sabijun.github.io/MT_RewardTreePage/}{https://sabijun.github.io/MT\\_RewardTreePage}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review. Project\n  page:https://sabijun.github.io/MT_RewardTreePage",
    "pdf_url": "http://arxiv.org/pdf/2503.12123v1",
    "published_date": "2025-03-15 13:04:51 UTC",
    "updated_date": "2025-03-15 13:04:51 UTC"
  },
  {
    "arxiv_id": "2503.12122v1",
    "title": "ICCO: Learning an Instruction-conditioned Coordinator for Language-guided Task-aligned Multi-robot Control",
    "authors": [
      "Yoshiki Yano",
      "Kazuki Shibata",
      "Maarten Kokshoorn",
      "Takamitsu Matsubara"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have permitted the\ndevelopment of language-guided multi-robot systems, which allow robots to\nexecute tasks based on natural language instructions. However, achieving\neffective coordination in distributed multi-agent environments remains\nchallenging due to (1) misalignment between instructions and task requirements\nand (2) inconsistency in robot behaviors when they independently interpret\nambiguous instructions. To address these challenges, we propose\nInstruction-Conditioned Coordinator (ICCO), a Multi-Agent Reinforcement\nLearning (MARL) framework designed to enhance coordination in language-guided\nmulti-robot systems. ICCO consists of a Coordinator agent and multiple Local\nAgents, where the Coordinator generates Task-Aligned and Consistent\nInstructions (TACI) by integrating language instructions with environmental\nstates, ensuring task alignment and behavioral consistency. The Coordinator and\nLocal Agents are jointly trained to optimize a reward function that balances\ntask efficiency and instruction following. A Consistency Enhancement Term is\nadded to the learning objective to maximize mutual information between\ninstructions and robot behaviors, further improving coordination. Simulation\nand real-world experiments validate the effectiveness of ICCO in achieving\nlanguage-guided task-aligned multi-robot control. The demonstration can be\nfound at https://yanoyoshiki.github.io/ICCO/.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.12122v1",
    "published_date": "2025-03-15 13:03:20 UTC",
    "updated_date": "2025-03-15 13:03:20 UTC"
  },
  {
    "arxiv_id": "2503.12115v1",
    "title": "Universal Speech Token Learning via Low-Bitrate Neural Codec and Pretrained Representations",
    "authors": [
      "Xue Jiang",
      "Xiulian Peng",
      "Yuan Zhang",
      "Yan Lu"
    ],
    "abstract": "Current large speech language models are mainly based on semantic tokens from\ndiscretization of self-supervised learned representations and acoustic tokens\nfrom a neural codec, following a semantic-modeling and acoustic-synthesis\nparadigm. However, semantic tokens discard paralinguistic attributes of\nspeakers that is important for natural spoken communication, while prompt-based\nacoustic synthesis from semantic tokens has limits in recovering paralinguistic\ndetails and suffers from robustness issues, especially when there are domain\ngaps between the prompt and the target. This paper unifies two types of tokens\nand proposes the UniCodec, a universal speech token learning that encapsulates\nall semantics of speech, including linguistic and paralinguistic information,\ninto a compact and semantically-disentangled unified token. Such a unified\ntoken can not only benefit speech language models in understanding with\nparalinguistic hints but also help speech generation with high-quality output.\nA low-bitrate neural codec is leveraged to learn such disentangled discrete\nrepresentations at global and local scales, with knowledge distilled from\nself-supervised learned features. Extensive evaluations on multilingual\ndatasets demonstrate its effectiveness in generating natural, expressive and\nlong-term consistent output quality with paralinguistic attributes well\npreserved in several speech processing tasks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by IEEE Journal of Selected Topics in Signal\n  Processing(JSTSP)",
    "pdf_url": "http://arxiv.org/pdf/2503.12115v1",
    "published_date": "2025-03-15 12:50:43 UTC",
    "updated_date": "2025-03-15 12:50:43 UTC"
  },
  {
    "arxiv_id": "2503.12108v1",
    "title": "RECSIP: REpeated Clustering of Scores Improving the Precision",
    "authors": [
      "André Schamschurko",
      "Nenad Petrovic",
      "Alois Christian Knoll"
    ],
    "abstract": "The latest research on Large Language Models (LLMs) has demonstrated\nsignificant advancement in the field of Natural Language Processing (NLP).\nHowever, despite this progress, there is still a lack of reliability in these\nmodels. This is due to the stochastic architecture of LLMs, which presents a\nchallenge for users attempting to ascertain the reliability of a model's\nresponse. These responses may cause serious harm in high-risk environments or\nexpensive failures in industrial contexts. Therefore, we introduce the\nframework REpeated Clustering of Scores Improving the Precision (RECSIP) which\nfocuses on improving the precision of LLMs by asking multiple models in\nparallel, scoring and clustering their responses to ensure a higher reliability\non the response. The evaluation of our reference implementation recsip on the\nbenchmark MMLU-Pro using the models GPT-4o, Claude and Gemini shows an overall\nincrease of 5.8 per cent points compared to the best used model.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Conference paper accepted for IntelliSys2025",
    "pdf_url": "http://arxiv.org/pdf/2503.12108v1",
    "published_date": "2025-03-15 12:36:32 UTC",
    "updated_date": "2025-03-15 12:36:32 UTC"
  },
  {
    "arxiv_id": "2503.12107v1",
    "title": "ChronosX: Adapting Pretrained Time Series Models with Exogenous Variables",
    "authors": [
      "Sebastian Pineda Arango",
      "Pedro Mercado",
      "Shubham Kapoor",
      "Abdul Fatir Ansari",
      "Lorenzo Stella",
      "Huibin Shen",
      "Hugo Senetaire",
      "Caner Turkmen",
      "Oleksandr Shchur",
      "Danielle C. Maddix",
      "Michael Bohlke-Schneider",
      "Yuyang Wang",
      "Syama Sundar Rangapuram"
    ],
    "abstract": "Covariates provide valuable information on external factors that influence\ntime series and are critical in many real-world time series forecasting tasks.\nFor example, in retail, covariates may indicate promotions or peak dates such\nas holiday seasons that heavily influence demand forecasts. Recent advances in\npretraining large language model architectures for time series forecasting have\nled to highly accurate forecasters. However, the majority of these models do\nnot readily use covariates as they are often specific to a certain task or\ndomain. This paper introduces a new method to incorporate covariates into\npretrained time series forecasting models. Our proposed approach incorporates\ncovariate information into pretrained forecasting models through modular blocks\nthat inject past and future covariate information, without necessarily\nmodifying the pretrained model in consideration. In order to evaluate our\napproach, we introduce a benchmark composed of 32 different synthetic datasets\nwith varying dynamics to evaluate the effectivity of forecasting models with\ncovariates. Extensive evaluations on both synthetic and real datasets show that\nour approach effectively incorporates covariate information into pretrained\nmodels, outperforming existing baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the 28th International Conference on Artificial\n  Intelligence and Statistics (AISTATS), 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.12107v1",
    "published_date": "2025-03-15 12:34:19 UTC",
    "updated_date": "2025-03-15 12:34:19 UTC"
  },
  {
    "arxiv_id": "2503.12085v1",
    "title": "Automating the loop in traffic incident management on highway",
    "authors": [
      "Matteo Cercola",
      "Nicola Gatti",
      "Pedro Huertas Leyva",
      "Benedetto Carambia",
      "Simone Formentin"
    ],
    "abstract": "Effective traffic incident management is essential for ensuring safety,\nminimizing congestion, and reducing response times in emergency situations.\nTraditional highway incident management relies heavily on radio room operators,\nwho must make rapid, informed decisions in high-stakes environments. This paper\nproposes an innovative solution to support and enhance these decisions by\nintegrating Large Language Models (LLMs) into a decision-support system for\ntraffic incident management. We introduce two approaches: (1) an LLM +\nOptimization hybrid that leverages both the flexibility of natural language\ninteraction and the robustness of optimization techniques, and (2) a Full LLM\napproach that autonomously generates decisions using only LLM capabilities. We\ntested our solutions using historical event data from Autostrade per l'Italia.\nExperimental results indicate that while both approaches show promise, the LLM\n+ Optimization solution demonstrates superior reliability, making it\nparticularly suited to critical applications where consistency and accuracy are\nparamount. This research highlights the potential for LLMs to transform highway\nincident management by enabling accessible, data-driven decision-making\nsupport.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12085v1",
    "published_date": "2025-03-15 11:22:13 UTC",
    "updated_date": "2025-03-15 11:22:13 UTC"
  },
  {
    "arxiv_id": "2503.12080v1",
    "title": "Comparing Human Expertise and Large Language Models Embeddings in Content Validity Assessment of Personality Tests",
    "authors": [
      "Nicola Milano",
      "Michela Ponticorvo",
      "Davide Marocco"
    ],
    "abstract": "In this article we explore the application of Large Language Models (LLMs) in\nassessing the content validity of psychometric instruments, focusing on the Big\nFive Questionnaire (BFQ) and Big Five Inventory (BFI). Content validity, a\ncornerstone of test construction, ensures that psychological measures\nadequately cover their intended constructs. Using both human expert evaluations\nand advanced LLMs, we compared the accuracy of semantic item-construct\nalignment. Graduate psychology students employed the Content Validity Ratio\n(CVR) to rate test items, forming the human baseline. In parallel,\nstate-of-the-art LLMs, including multilingual and fine-tuned models, analyzed\nitem embeddings to predict construct mappings. The results reveal distinct\nstrengths and limitations of human and AI approaches. Human validators excelled\nin aligning the behaviorally rich BFQ items, while LLMs performed better with\nthe linguistically concise BFI items. Training strategies significantly\ninfluenced LLM performance, with models tailored for lexical relationships\noutperforming general-purpose LLMs. Here we highlights the complementary\npotential of hybrid validation systems that integrate human expertise and AI\nprecision. The findings underscore the transformative role of LLMs in\npsychological assessment, paving the way for scalable, objective, and robust\ntest development methodologies.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12080v1",
    "published_date": "2025-03-15 10:54:35 UTC",
    "updated_date": "2025-03-15 10:54:35 UTC"
  },
  {
    "arxiv_id": "2503.13531v1",
    "title": "Context-aware Multimodal AI Reveals Hidden Pathways in Five Centuries of Art Evolution",
    "authors": [
      "Jin Kim",
      "Byunghwee Lee",
      "Taekho You",
      "Jinhyuk Yun"
    ],
    "abstract": "The rise of multimodal generative AI is transforming the intersection of\ntechnology and art, offering deeper insights into large-scale artwork. Although\nits creative capabilities have been widely explored, its potential to represent\nartwork in latent spaces remains underexamined. We use cutting-edge generative\nAI, specifically Stable Diffusion, to analyze 500 years of Western paintings by\nextracting two types of latent information with the model: formal aspects\n(e.g., colors) and contextual aspects (e.g., subject). Our findings reveal that\ncontextual information differentiates between artistic periods, styles, and\nindividual artists more successfully than formal elements. Additionally, using\ncontextual keywords extracted from paintings, we show how artistic expression\nevolves alongside societal changes. Our generative experiment, infusing\nprospective contexts into historical artworks, successfully reproduces the\nevolutionary trajectory of artworks, highlighting the significance of mutual\ninteraction between society and art. This study demonstrates how multimodal AI\nexpands traditional formal analysis by integrating temporal, cultural, and\nhistorical contexts.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "30 pages, 4 figures. Some example paintings are blurred to avoid\n  potential copyright violations",
    "pdf_url": "http://arxiv.org/pdf/2503.13531v1",
    "published_date": "2025-03-15 10:45:04 UTC",
    "updated_date": "2025-03-15 10:45:04 UTC"
  },
  {
    "arxiv_id": "2503.12077v1",
    "title": "V-Stylist: Video Stylization via Collaboration and Reflection of MLLM Agents",
    "authors": [
      "Zhengrong Yue",
      "Shaobin Zhuang",
      "Kunchang Li",
      "Yanbo Ding",
      "Yali Wang"
    ],
    "abstract": "Despite the recent advancement in video stylization, most existing methods\nstruggle to render any video with complex transitions, based on an open style\ndescription of user query. To fill this gap, we introduce a generic multi-agent\nsystem for video stylization, V-Stylist, by a novel collaboration and\nreflection paradigm of multi-modal large language models. Specifically, our\nV-Stylist is a systematical workflow with three key roles: (1) Video Parser\ndecomposes the input video into a number of shots and generates their text\nprompts of key shot content. Via a concise video-to-shot prompting paradigm, it\nallows our V-Stylist to effectively handle videos with complex transitions. (2)\nStyle Parser identifies the style in the user query and progressively search\nthe matched style model from a style tree. Via a robust tree-of-thought\nsearching paradigm, it allows our V-Stylist to precisely specify vague style\npreference in the open user query. (3) Style Artist leverages the matched model\nto render all the video shots into the required style. Via a novel multi-round\nself-reflection paradigm, it allows our V-Stylist to adaptively adjust detail\ncontrol, according to the style requirement. With such a distinct design of\nmimicking human professionals, our V-Stylist achieves a major breakthrough over\nthe primary challenges for effective and automatic video stylization.\nMoreover,we further construct a new benchmark Text-driven Video Stylization\nBenchmark (TVSBench), which fills the gap to assess stylization of complex\nvideos on open user queries. Extensive experiments show that, V-Stylist\nachieves the state-of-the-art, e.g.,V-Stylist surpasses FRESCO and ControlVideo\nby 6.05% and 4.51% respectively in overall average metrics, marking a\nsignificant advance in video stylization.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.12077v1",
    "published_date": "2025-03-15 10:37:31 UTC",
    "updated_date": "2025-03-15 10:37:31 UTC"
  },
  {
    "arxiv_id": "2503.12065v1",
    "title": "Maritime Mission Planning for Unmanned Surface Vessel using Large Language Model",
    "authors": [
      "Muhayy Ud Din",
      "Waseem Akram",
      "Ahsan B Bakht",
      "Yihao Dong",
      "Irfan Hussain"
    ],
    "abstract": "Unmanned Surface Vessels (USVs) are essential for various maritime\noperations. USV mission planning approach offers autonomous solutions for\nmonitoring, surveillance, and logistics. Existing approaches, which are based\non static methods, struggle to adapt to dynamic environments, leading to\nsuboptimal performance, higher costs, and increased risk of failure. This paper\nintroduces a novel mission planning framework that uses Large Language Models\n(LLMs), such as GPT-4, to address these challenges. LLMs are proficient at\nunderstanding natural language commands, executing symbolic reasoning, and\nflexibly adjusting to changing situations. Our approach integrates LLMs into\nmaritime mission planning to bridge the gap between high-level human\ninstructions and executable plans, allowing real-time adaptation to\nenvironmental changes and unforeseen obstacles. In addition, feedback from\nlow-level controllers is utilized to refine symbolic mission plans, ensuring\nrobustness and adaptability. This framework improves the robustness and\neffectiveness of USV operations by integrating the power of symbolic planning\nwith the reasoning abilities of LLMs. In addition, it simplifies the mission\nspecification, allowing operators to focus on high-level objectives without\nrequiring complex programming. The simulation results validate the proposed\napproach, demonstrating its ability to optimize mission execution while\nseamlessly adapting to dynamic maritime conditions.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "IEEE International Conference on Simulation, Modeling, and\n  Programming for Autonomous Robots",
    "pdf_url": "http://arxiv.org/pdf/2503.12065v1",
    "published_date": "2025-03-15 09:41:55 UTC",
    "updated_date": "2025-03-15 09:41:55 UTC"
  },
  {
    "arxiv_id": "2503.12058v1",
    "title": "Revisiting Training-Inference Trigger Intensity in Backdoor Attacks",
    "authors": [
      "Chenhao Lin",
      "Chenyang Zhao",
      "Shiwei Wang",
      "Longtian Wang",
      "Chao Shen",
      "Zhengyu Zhao"
    ],
    "abstract": "Backdoor attacks typically place a specific trigger on certain training data,\nsuch that the model makes prediction errors on inputs with that trigger during\ninference. Despite the core role of the trigger, existing studies have commonly\nbelieved a perfect match between training-inference triggers is optimal. In\nthis paper, for the first time, we systematically explore the\ntraining-inference trigger relation, particularly focusing on their mismatch,\nbased on a Training-Inference Trigger Intensity Manipulation (TITIM) workflow.\nTITIM specifically investigates the training-inference trigger intensity, such\nas the size or the opacity of a trigger, and reveals new insights into trigger\ngeneralization and overfitting.\n  These new insights challenge the above common belief by demonstrating that\nthe training-inference trigger mismatch can facilitate attacks in two practical\nscenarios, posing more significant security threats than previously thought.\nFirst, when the inference trigger is fixed, using training triggers with mixed\nintensities leads to stronger attacks than using any single intensity. For\nexample, on CIFAR-10 with ResNet-18, mixing training triggers with 1.0 and 0.1\nopacities improves the worst-case attack success rate (ASR) (over different\ntesting opacities) of the best single-opacity attack from 10.61\\% to 92.77\\%.\nSecond, intentionally using certain mismatched training-inference triggers can\nimprove the attack stealthiness, i.e., better bypassing defenses. For example,\ncompared to the training/inference intensity of 1.0/1.0, using 1.0/0.7\ndecreases the area under the curve (AUC) of the Scale-Up defense from 0.96 to\n0.62, while maintaining a high attack ASR (99.65\\% vs. 91.62\\%). The above new\ninsights are validated to be generalizable across different backdoor attacks,\nmodels, datasets, tasks, and (digital/physical) domains.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "To Appear in the 34th USENIX Security Symposium (USENIX Security 25)",
    "pdf_url": "http://arxiv.org/pdf/2503.12058v1",
    "published_date": "2025-03-15 09:07:00 UTC",
    "updated_date": "2025-03-15 09:07:00 UTC"
  },
  {
    "arxiv_id": "2503.12053v1",
    "title": "Ferret: An Efficient Online Continual Learning Framework under Varying Memory Constraints",
    "authors": [
      "Yuhao Zhou",
      "Yuxin Tian",
      "Jindi Lv",
      "Mingjia Shi",
      "Yuanxi Li",
      "Qing Ye",
      "Shuhao Zhang",
      "Jiancheng Lv"
    ],
    "abstract": "In the realm of high-frequency data streams, achieving real-time learning\nwithin varying memory constraints is paramount. This paper presents Ferret, a\ncomprehensive framework designed to enhance online accuracy of Online Continual\nLearning (OCL) algorithms while dynamically adapting to varying memory budgets.\nFerret employs a fine-grained pipeline parallelism strategy combined with an\niterative gradient compensation algorithm, ensuring seamless handling of\nhigh-frequency data with minimal latency, and effectively counteracting the\nchallenge of stale gradients in parallel training. To adapt to varying memory\nbudgets, its automated model partitioning and pipeline planning optimizes\nperformance regardless of memory limitations. Extensive experiments across 20\nbenchmarks and 5 integrated OCL algorithms show Ferret's remarkable efficiency,\nachieving up to 3.7$\\times$ lower memory overhead to reach the same online\naccuracy compared to competing methods. Furthermore, Ferret consistently\noutperforms these methods across diverse memory budgets, underscoring its\nsuperior adaptability. These findings position Ferret as a premier solution for\nefficient and adaptive OCL framework in real-time environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.12053v1",
    "published_date": "2025-03-15 08:58:38 UTC",
    "updated_date": "2025-03-15 08:58:38 UTC"
  },
  {
    "arxiv_id": "2503.12043v1",
    "title": "An LLM-Integrated Framework for Completion, Management, and Tracing of STPA",
    "authors": [
      "Ali Raeisdanaei",
      "Juho Kim",
      "Michael Liao",
      "Sparsh Kochhar"
    ],
    "abstract": "In many safety-critical engineering domains, hazard analysis techniques are\nan essential part of requirement elicitation. Of the methods proposed for this\ntask, STPA (System-Theoretic Process Analysis) represents a relatively recent\ndevelopment in the field. The completion, management, and traceability of this\nhazard analysis technique present a time-consuming challenge to the\nrequirements and safety engineers involved. In this paper, we introduce a free,\nopen-source software framework to build STPA models with several automated\nworkflows powered by large language models (LLMs). In past works, LLMs have\nbeen successfully integrated into a myriad of workflows across various fields.\nHere, we demonstrate that LLMs can be used to complete tasks associated with\nSTPA with a high degree of accuracy, saving the time and effort of the human\nengineers involved. We experimentally validate our method on real-world STPA\nmodels built by requirement engineers and researchers. The source code of our\nsoftware framework is available at the following link:\nhttps://github.com/blueskysolarracing/stpa.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12043v1",
    "published_date": "2025-03-15 08:31:13 UTC",
    "updated_date": "2025-03-15 08:31:13 UTC"
  },
  {
    "arxiv_id": "2503.13530v1",
    "title": "Cognitive Activation and Chaotic Dynamics in Large Language Models: A Quasi-Lyapunov Analysis of Reasoning Mechanisms",
    "authors": [
      "Xiaojian Li",
      "Yongkang Leng",
      "Ruiqing Ding",
      "Hangjie Mo",
      "Shanlin Yang"
    ],
    "abstract": "The human-like reasoning capabilities exhibited by Large Language Models\n(LLMs) challenge the traditional neural network theory's understanding of the\nflexibility of fixed-parameter systems. This paper proposes the \"Cognitive\nActivation\" theory, revealing the essence of LLMs' reasoning mechanisms from\nthe perspective of dynamic systems: the model's reasoning ability stems from a\nchaotic process of dynamic information extraction in the parameter space. By\nintroducing the Quasi-Lyapunov Exponent (QLE), we quantitatively analyze the\nchaotic characteristics of the model at different layers. Experiments show that\nthe model's information accumulation follows a nonlinear exponential law, and\nthe Multilayer Perceptron (MLP) accounts for a higher proportion in the final\noutput than the attention mechanism. Further experiments indicate that minor\ninitial value perturbations will have a substantial impact on the model's\nreasoning ability, confirming the theoretical analysis that large language\nmodels are chaotic systems. This research provides a chaos theory framework for\nthe interpretability of LLMs' reasoning and reveals potential pathways for\nbalancing creativity and reliability in model design.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.13530v1",
    "published_date": "2025-03-15 08:15:10 UTC",
    "updated_date": "2025-03-15 08:15:10 UTC"
  },
  {
    "arxiv_id": "2503.12037v1",
    "title": "Unsupervised Graph Anomaly Detection via Multi-Hypersphere Heterophilic Graph Learning",
    "authors": [
      "Hang Ni",
      "Jindong Han",
      "Nengjun Zhu",
      "Hao Liu"
    ],
    "abstract": "Graph Anomaly Detection (GAD) plays a vital role in various data mining\napplications such as e-commerce fraud prevention and malicious user detection.\nRecently, Graph Neural Network (GNN) based approach has demonstrated great\neffectiveness in GAD by first encoding graph data into low-dimensional\nrepresentations and then identifying anomalies under the guidance of supervised\nor unsupervised signals. However, existing GNN-based approaches implicitly\nfollow the homophily principle (i.e., the \"like attracts like\" phenomenon) and\nfail to learn discriminative embedding for anomalies that connect vast normal\nnodes. Moreover, such approaches identify anomalies in a unified global\nperspective but overlook diversified abnormal patterns conditioned on local\ngraph context, leading to suboptimal performance. To overcome the\naforementioned limitations, in this paper, we propose a Multi-hypersphere\nHeterophilic Graph Learning (MHetGL) framework for unsupervised GAD.\nSpecifically, we first devise a Heterophilic Graph Encoding (HGE) module to\nlearn distinguishable representations for potential anomalies by purifying and\naugmenting their neighborhood in a fully unsupervised manner. Then, we propose\na Multi-Hypersphere Learning (MHL) module to enhance the detection capability\nfor context-dependent anomalies by jointly incorporating critical patterns from\nboth global and local perspectives. Extensive experiments on ten real-world\ndatasets show that MHetGL outperforms 14 baselines. Our code is publicly\navailable at https://github.com/KennyNH/MHetGL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12037v1",
    "published_date": "2025-03-15 08:08:13 UTC",
    "updated_date": "2025-03-15 08:08:13 UTC"
  },
  {
    "arxiv_id": "2503.12034v1",
    "title": "Real-Time Manipulation Action Recognition with a Factorized Graph Sequence Encoder",
    "authors": [
      "Enes Erdogan",
      "Eren Erdal Aksoy",
      "Sanem Sariel"
    ],
    "abstract": "Recognition of human manipulation actions in real-time is essential for safe\nand effective human-robot interaction and collaboration. The challenge lies in\ndeveloping a model that is both lightweight enough for real-time execution and\ncapable of generalization. While some existing methods in the literature can\nrun in real-time, they struggle with temporal scalability, i.e., they fail to\nadapt to long-duration manipulations effectively. To address this, leveraging\nthe generalizable scene graph representations, we propose a new Factorized\nGraph Sequence Encoder network that not only runs in real-time but also scales\neffectively in the temporal dimension, thanks to its factorized encoder\narchitecture. Additionally, we introduce Hand Pooling operation, a simple\npooling operation for more focused extraction of the graph-level embeddings.\nOur model outperforms the previous state-of-the-art real-time approach,\nachieving a 14.3\\% and 5.6\\% improvement in F1-macro score on the KIT Bimanual\nAction (Bimacs) Dataset and Collaborative Action (CoAx) Dataset, respectively.\nMoreover, we conduct an extensive ablation study to validate our network design\nchoices. Finally, we compare our model with its architecturally similar\nRGB-based model on the Bimacs dataset and show the limitations of this model in\ncontrast to ours on such an object-centric manipulation dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 3 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.12034v1",
    "published_date": "2025-03-15 07:58:25 UTC",
    "updated_date": "2025-03-15 07:58:25 UTC"
  },
  {
    "arxiv_id": "2503.12020v1",
    "title": "Variance-Dependent Regret Lower Bounds for Contextual Bandits",
    "authors": [
      "Jiafan He",
      "Quanquan Gu"
    ],
    "abstract": "Variance-dependent regret bounds for linear contextual bandits, which improve\nupon the classical $\\tilde{O}(d\\sqrt{K})$ regret bound to\n$\\tilde{O}(d\\sqrt{\\sum_{k=1}^K\\sigma_k^2})$, where $d$ is the context\ndimension, $K$ is the number of rounds, and $\\sigma^2_k$ is the noise variance\nin round $k$, has been widely studied in recent years. However, most existing\nworks focus on the regret upper bounds instead of lower bounds. To our\nknowledge, the only lower bound is from Jia et al. (2024), which proved that\nfor any eluder dimension $d_{\\textbf{elu}}$ and total variance budget\n$\\Lambda$, there exists an instance with $\\sum_{k=1}^K\\sigma_k^2\\leq \\Lambda$\nfor which any algorithm incurs a variance-dependent lower bound of\n$\\Omega(\\sqrt{d_{\\textbf{elu}}\\Lambda})$. However, this lower bound has a\n$\\sqrt{d}$ gap with existing upper bounds. Moreover, it only considers a fixed\ntotal variance budget $\\Lambda$ and does not apply to a general variance\nsequence $\\{\\sigma_1^2,\\ldots,\\sigma_K^2\\}$. In this paper, to overcome the\nlimitations of Jia et al. (2024), we consider the general variance sequence\nunder two settings. For a prefixed sequence, where the entire variance sequence\nis revealed to the learner at the beginning of the learning process, we\nestablish a variance-dependent lower bound of $\\Omega(d\n\\sqrt{\\sum_{k=1}^K\\sigma_k^2 }/\\log K)$ for linear contextual bandits. For an\nadaptive sequence, where an adversary can generate the variance $\\sigma_k^2$ in\neach round $k$ based on historical observations, we show that when the\nadversary must generate $\\sigma_k^2$ before observing the decision set\n$\\mathcal{D}_k$, a similar lower bound of $\\Omega(d\\sqrt{\n\\sum_{k=1}^K\\sigma_k^2} /\\log^6(dK))$ holds. In both settings, our results\nmatch the upper bounds of the SAVE algorithm (Zhao et al., 2023) up to\nlogarithmic factors.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.12020v1",
    "published_date": "2025-03-15 07:09:36 UTC",
    "updated_date": "2025-03-15 07:09:36 UTC"
  },
  {
    "arxiv_id": "2503.12018v1",
    "title": "Compose Your Aesthetics: Empowering Text-to-Image Models with the Principles of Art",
    "authors": [
      "Zhe Jin",
      "Tat-Seng Chua"
    ],
    "abstract": "Text-to-Image (T2I) diffusion models (DM) have garnered widespread adoption\ndue to their capability in generating high-fidelity outputs and accessibility\nto anyone able to put imagination into words. However, DMs are often\npredisposed to generate unappealing outputs, much like the random images on the\ninternet they were trained on. Existing approaches to address this are founded\non the implicit premise that visual aesthetics is universal, which is limiting.\nAesthetics in the T2I context should be about personalization and we propose\nthe novel task of aesthetics alignment which seeks to align user-specified\naesthetics with the T2I generation output. Inspired by how artworks provide an\ninvaluable perspective to approach aesthetics, we codify visual aesthetics\nusing the compositional framework artists employ, known as the Principles of\nArt (PoA). To facilitate this study, we introduce CompArt, a large-scale\ncompositional art dataset building on top of WikiArt with PoA analysis\nannotated by a capable Multimodal LLM. Leveraging the expressive power of LLMs\nand training a lightweight and transferrable adapter, we demonstrate that T2I\nDMs can effectively offer 10 compositional controls through user-specified PoA\nconditions. Additionally, we design an appropriate evaluation framework to\nassess the efficacy of our approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12018v1",
    "published_date": "2025-03-15 06:58:09 UTC",
    "updated_date": "2025-03-15 06:58:09 UTC"
  },
  {
    "arxiv_id": "2503.12008v1",
    "title": "Winning the MIDST Challenge: New Membership Inference Attacks on Diffusion Models for Tabular Data Synthesis",
    "authors": [
      "Xiaoyu Wu",
      "Yifei Pang",
      "Terrance Liu",
      "Steven Wu"
    ],
    "abstract": "Tabular data synthesis using diffusion models has gained significant\nattention for its potential to balance data utility and privacy. However,\nexisting privacy evaluations often rely on heuristic metrics or weak membership\ninference attacks (MIA), leaving privacy risks inadequately assessed. In this\nwork, we conduct a rigorous MIA study on diffusion-based tabular synthesis,\nrevealing that state-of-the-art attacks designed for image models fail in this\nsetting. We identify noise initialization as a key factor influencing attack\nefficacy and propose a machine-learning-driven approach that leverages loss\nfeatures across different noises and time steps. Our method, implemented with a\nlightweight MLP, effectively learns membership signals, eliminating the need\nfor manual optimization. Experimental results from the MIDST Challenge @ SaTML\n2025 demonstrate the effectiveness of our approach, securing first place across\nall tracks. Code is available at\nhttps://github.com/Nicholas0228/Tartan_Federer_MIDST.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12008v1",
    "published_date": "2025-03-15 06:13:27 UTC",
    "updated_date": "2025-03-15 06:13:27 UTC"
  },
  {
    "arxiv_id": "2503.11995v1",
    "title": "Fraesormer: Learning Adaptive Sparse Transformer for Efficient Food Recognition",
    "authors": [
      "Shun Zou",
      "Yi Zou",
      "Mingya Zhang",
      "Shipeng Luo",
      "Zhihao Chen",
      "Guangwei Gao"
    ],
    "abstract": "In recent years, Transformer has witnessed significant progress in food\nrecognition. However, most existing approaches still face two critical\nchallenges in lightweight food recognition: (1) the quadratic complexity and\nredundant feature representation from interactions with irrelevant tokens; (2)\nstatic feature recognition and single-scale representation, which overlook the\nunstructured, non-fixed nature of food images and the need for multi-scale\nfeatures. To address these, we propose an adaptive and efficient sparse\nTransformer architecture (Fraesormer) with two core designs: Adaptive Top-k\nSparse Partial Attention (ATK-SPA) and Hierarchical Scale-Sensitive Feature\nGating Network (HSSFGN). ATK-SPA uses a learnable Gated Dynamic Top-K Operator\n(GDTKO) to retain critical attention scores, filtering low query-key matches\nthat hinder feature aggregation. It also introduces a partial channel mechanism\nto reduce redundancy and promote expert information flow, enabling local-global\ncollaborative modeling. HSSFGN employs gating mechanism to achieve multi-scale\nfeature representation, enhancing contextual semantic information. Extensive\nexperiments show that Fraesormer outperforms state-of-the-art methods. code is\navailable at https://zs1314.github.io/Fraesormer.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.11995v1",
    "published_date": "2025-03-15 05:13:26 UTC",
    "updated_date": "2025-03-15 05:13:26 UTC"
  },
  {
    "arxiv_id": "2503.11989v2",
    "title": "Applications of Large Language Model Reasoning in Feature Generation",
    "authors": [
      "Dharani Chandra"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\nthrough their state of art reasoning capabilities. This paper explores the\nconvergence of LLM reasoning techniques and feature generation for machine\nlearning tasks. We examine four key reasoning approaches: Chain of Thought,\nTree of Thoughts, Retrieval-Augmented Generation, and Thought Space\nExploration. Our analysis reveals how these approaches can be used to identify\neffective feature generation rules without having to manually specify search\nspaces. The paper categorizes LLM-based feature generation methods across\nvarious domains including finance, healthcare, and text analytics. LLMs can\nextract key information from clinical notes and radiology reports in\nhealthcare, by enabling more efficient data utilization. In finance, LLMs\nfacilitate text generation, summarization, and entity extraction from complex\ndocuments. We analyze evaluation methodologies for assessing feature quality\nand downstream performance, with particular attention to OCTree's decision tree\nreasoning approach that provides language-based feedback for iterative\nimprovements. Current challenges include hallucination, computational\nefficiency, and domain adaptation. As of March 2025, emerging approaches\ninclude inference-time compute scaling, reinforcement learning, and supervised\nfine-tuning with model distillation. Future directions point toward multimodal\nfeature generation, self-improving systems, and neuro-symbolic approaches. This\npaper provides a detailed overview of an emerging field that promises to\nautomate and enhance feature engineering through language model reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "I just updated the format of the references in the paper",
    "pdf_url": "http://arxiv.org/pdf/2503.11989v2",
    "published_date": "2025-03-15 04:18:01 UTC",
    "updated_date": "2025-03-20 02:18:33 UTC"
  },
  {
    "arxiv_id": "2503.11985v1",
    "title": "No LLM is Free From Bias: A Comprehensive Study of Bias Evaluation in Large Language models",
    "authors": [
      "Charaka Vinayak Kumar",
      "Ashok Urlana",
      "Gopichand Kanumolu",
      "Bala Mallikarjunarao Garlapati",
      "Pruthwik Mishra"
    ],
    "abstract": "Advancements in Large Language Models (LLMs) have increased the performance\nof different natural language understanding as well as generation tasks.\nAlthough LLMs have breached the state-of-the-art performance in various tasks,\nthey often reflect different forms of bias present in the training data. In the\nlight of this perceived limitation, we provide a unified evaluation of\nbenchmarks using a set of representative LLMs that cover different forms of\nbiases starting from physical characteristics to socio-economic categories.\nMoreover, we propose five prompting approaches to carry out the bias detection\ntask across different aspects of bias. Further, we formulate three research\nquestions to gain valuable insight in detecting biases in LLMs using different\napproaches and evaluation metrics across benchmarks. The results indicate that\neach of the selected LLMs suffer from one or the other form of bias with the\nLLaMA3.1-8B model being the least biased. Finally, we conclude the paper with\nthe identification of key challenges and possible future directions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2503.11985v1",
    "published_date": "2025-03-15 03:58:14 UTC",
    "updated_date": "2025-03-15 03:58:14 UTC"
  },
  {
    "arxiv_id": "2503.11962v1",
    "title": "HInter: Exposing Hidden Intersectional Bias in Large Language Models",
    "authors": [
      "Badr Souani",
      "Ezekiel Soremekun",
      "Mike Papadakis",
      "Setsuko Yokoyama",
      "Sudipta Chattopadhyay",
      "Yves Le Traon"
    ],
    "abstract": "Large Language Models (LLMs) may portray discrimination towards certain\nindividuals, especially those characterized by multiple attributes (aka\nintersectional bias). Discovering intersectional bias in LLMs is challenging,\nas it involves complex inputs on multiple attributes (e.g. race and gender). To\naddress this challenge, we propose HInter, a test technique that\nsynergistically combines mutation analysis, dependency parsing and metamorphic\noracles to automatically detect intersectional bias in LLMs. HInter generates\ntest inputs by systematically mutating sentences using multiple mutations,\nvalidates inputs via a dependency invariant and detects biases by checking the\nLLM response on the original and mutated sentences. We evaluate HInter using\nsix LLM architectures and 18 LLM models (GPT3.5, Llama2, BERT, etc) and find\nthat 14.61% of the inputs generated by HInter expose intersectional bias.\nResults also show that our dependency invariant reduces false positives\n(incorrect test inputs) by an order of magnitude. Finally, we observed that\n16.62% of intersectional bias errors are hidden, meaning that their\ncorresponding atomic cases do not trigger biases. Overall, this work emphasize\nthe importance of testing LLMs for intersectional bias.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50, 68T05"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.11962v1",
    "published_date": "2025-03-15 02:10:38 UTC",
    "updated_date": "2025-03-15 02:10:38 UTC"
  },
  {
    "arxiv_id": "2503.11958v1",
    "title": "CHOrD: Generation of Collision-Free, House-Scale, and Organized Digital Twins for 3D Indoor Scenes with Controllable Floor Plans and Optimal Layouts",
    "authors": [
      "Chong Su",
      "Yingbin Fu",
      "Zheyuan Hu",
      "Jing Yang",
      "Param Hanji",
      "Shaojun Wang",
      "Xuan Zhao",
      "Cengiz Öztireli",
      "Fangcheng Zhong"
    ],
    "abstract": "We introduce CHOrD, a novel framework for scalable synthesis of 3D indoor\nscenes, designed to create house-scale, collision-free, and hierarchically\nstructured indoor digital twins. In contrast to existing methods that directly\nsynthesize the scene layout as a scene graph or object list, CHOrD incorporates\na 2D image-based intermediate layout representation, enabling effective\nprevention of collision artifacts by successfully capturing them as\nout-of-distribution (OOD) scenarios during generation. Furthermore, unlike\nexisting methods, CHOrD is capable of generating scene layouts that adhere to\ncomplex floor plans with multi-modal controls, enabling the creation of\ncoherent, house-wide layouts robust to both geometric and semantic variations\nin room structures. Additionally, we propose a novel dataset with expanded\ncoverage of household items and room configurations, as well as significantly\nimproved data quality. CHOrD demonstrates state-of-the-art performance on both\nthe 3D-FRONT and our proposed datasets, delivering photorealistic, spatially\ncoherent indoor scene synthesis adaptable to arbitrary floor plan variations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Chong Su and Yingbin Fu contributed equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2503.11958v1",
    "published_date": "2025-03-15 02:05:10 UTC",
    "updated_date": "2025-03-15 02:05:10 UTC"
  },
  {
    "arxiv_id": "2503.11954v1",
    "title": "Goal-Oriented Source Coding using LDPC Codes for Compressed-Domain Image Classification",
    "authors": [
      "Ahcen Aliouat",
      "Elsa Dupraz"
    ],
    "abstract": "In the emerging field of goal-oriented communications, the focus has shifted\nfrom reconstructing data to directly performing specific learning tasks, such\nas classification, segmentation, or pattern recognition, on the received coded\ndata. In the commonly studied scenario of classification from compressed\nimages, a key objective is to enable learning directly on entropy-coded data,\nthereby bypassing the computationally intensive step of data reconstruction.\nConventional entropy-coding methods, such as Huffman and Arithmetic coding, are\neffective for compression but disrupt the data structure, making them less\nsuitable for direct learning without decoding. This paper investigates the use\nof low-density parity-check (LDPC) codes -- originally designed for channel\ncoding -- as an alternative entropy-coding approach. It is hypothesized that\nthe structured nature of LDPC codes can be leveraged more effectively by deep\nlearning models for tasks like classification. At the receiver side, gated\nrecurrent unit (GRU) models are trained to perform image classification\ndirectly on LDPC-coded data. Experiments on datasets like MNIST, Fashion-MNIST,\nand CIFAR show that LDPC codes outperform Huffman and Arithmetic coding in\nclassification tasks, while requiring significantly smaller learning models.\nFurthermore, the paper analyzes why LDPC codes preserve data structure more\neffectively than traditional entropy-coding techniques and explores the impact\nof key code parameters on classification performance. These results suggest\nthat LDPC-based entropy coding offers an optimal balance between learning\nefficiency and model complexity, eliminating the need for prior decoding.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "94A29, 94A08, 94B05, 68T01, 68P30",
      "I.4.2; E.4; I.2.10; I.5.4; I.5.1; I.4.1"
    ],
    "primary_category": "eess.IV",
    "comment": "11 pages, 13 figures, Submitted to IEEE Transactions on\n  Communications (Under Review)",
    "pdf_url": "http://arxiv.org/pdf/2503.11954v1",
    "published_date": "2025-03-15 01:52:09 UTC",
    "updated_date": "2025-03-15 01:52:09 UTC"
  },
  {
    "arxiv_id": "2503.11951v2",
    "title": "SagaLLM: Context Management, Validation, and Transaction Guarantees for Multi-Agent LLM Planning",
    "authors": [
      "Edward Y. Chang",
      "Longling Geng"
    ],
    "abstract": "Recent LLM-based agent frameworks have demonstrated impressive capabilities\nin task delegation and workflow orchestration, but face significant challenges\nin maintaining context awareness and ensuring planning consistency. This paper\npresents SagaLLM, a structured multi-agent framework that addresses four\nfundamental limitations in current LLM approaches: inadequate self-validation,\ncontext narrowing, lacking transaction properties, and insufficient inter-agent\ncoordination. By implementing specialized context management agents and\nvalidation protocols, SagaLLM preserves critical constraints and state\ninformation throughout complex planning processes, enabling robust and\nconsistent decision-making even during disruptions. We evaluate our approach\nusing selected problems from the REALM benchmark, focusing on sequential and\nreactive planning scenarios that challenge both context retention and adaptive\nreasoning. Our experiments with state-of-the-art LLMs, Claude 3.7, DeepSeek R1,\nGPT-4o, and GPT-o1, demonstrate that while these models exhibit impressive\nreasoning capabilities, they struggle with maintaining global constraint\nawareness during complex planning tasks, particularly when adapting to\nunexpected changes. In contrast, the distributed cognitive architecture of\nSagaLLM shows significant improvements in planning consistency, constraint\nenforcement, and adaptation to disruptions in various scenarios.",
    "categories": [
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 8 tables, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.11951v2",
    "published_date": "2025-03-15 01:43:03 UTC",
    "updated_date": "2025-03-18 05:00:47 UTC"
  },
  {
    "arxiv_id": "2503.11950v2",
    "title": "Privacy Ethics Alignment in AI: A Stakeholder-Centric Based Framework for Ethical AI",
    "authors": [
      "Ankur Barthwal",
      "Molly Campbell",
      "Ajay Kumar Shrestha"
    ],
    "abstract": "The increasing integration of Artificial Intelligence (AI) in digital\necosystems has reshaped privacy dynamics, particularly for young digital\ncitizens navigating data-driven environments. This study explores evolving\nprivacy concerns across three key stakeholder groups, digital citizens (ages\n16-19), parents/educators, and AI professionals, and assesses differences in\ndata ownership, trust, transparency, parental mediation, education, and\nrisk-benefit perceptions. Employing a grounded theory methodology, this\nresearch synthesizes insights from 482 participants through structured surveys,\nqualitative interviews, and focus groups. The findings reveal distinct privacy\nexpectations: Young users emphasize autonomy and digital freedom, while parents\nand educators advocate for regulatory oversight and AI literacy programs. AI\nprofessionals, in contrast, prioritize the balance between ethical system\ndesign and technological efficiency. The data further highlights gaps in AI\nliteracy and transparency, emphasizing the need for comprehensive,\nstakeholder-driven privacy frameworks that accommodate diverse user needs.\nUsing comparative thematic analysis, this study identifies key tensions in\nprivacy governance and develops the novel Privacy-Ethics Alignment in AI\n(PEA-AI) model, which structures privacy decision-making as a dynamic\nnegotiation between stakeholders. By systematically analyzing themes such as\ntransparency, user control, risk perception, and parental mediation, this\nresearch provides a scalable, adaptive foundation for AI governance, ensuring\nthat privacy protections evolve alongside emerging AI technologies and\nyouth-centric digital interactions.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Submitted to peer reviwed venue",
    "pdf_url": "http://arxiv.org/pdf/2503.11950v2",
    "published_date": "2025-03-15 01:42:45 UTC",
    "updated_date": "2025-03-21 00:54:33 UTC"
  },
  {
    "arxiv_id": "2503.11948v1",
    "title": "Integration of Explainable AI Techniques with Large Language Models for Enhanced Interpretability for Sentiment Analysis",
    "authors": [
      "Thivya Thogesan",
      "Anupiya Nugaliyadde",
      "Kok Wai Wong"
    ],
    "abstract": "Interpretability remains a key difficulty in sentiment analysis with Large\nLanguage Models (LLMs), particularly in high-stakes applications where it is\ncrucial to comprehend the rationale behind forecasts. This research addressed\nthis by introducing a technique that applies SHAP (Shapley Additive\nExplanations) by breaking down LLMs into components such as embedding\nlayer,encoder,decoder and attention layer to provide a layer-by-layer knowledge\nof sentiment prediction. The approach offers a clearer overview of how model\ninterpret and categorise sentiment by breaking down LLMs into these parts. The\nmethod is evaluated using the Stanford Sentiment Treebank (SST-2) dataset,\nwhich shows how different sentences affect different layers. The effectiveness\nof layer-wise SHAP analysis in clarifying sentiment-specific token attributions\nis demonstrated by experimental evaluations, which provide a notable\nenhancement over current whole-model explainability techniques. These results\nhighlight how the suggested approach could improve the reliability and\ntransparency of LLM-based sentiment analysis in crucial applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.11948v1",
    "published_date": "2025-03-15 01:37:54 UTC",
    "updated_date": "2025-03-15 01:37:54 UTC"
  },
  {
    "arxiv_id": "2503.11947v1",
    "title": "Ethical AI for Young Digital Citizens: A Call to Action on Privacy Governance",
    "authors": [
      "Austin Shouli",
      "Ankur Barthwal",
      "Molly Campbell",
      "Ajay Kumar Shrestha"
    ],
    "abstract": "The rapid expansion of Artificial Intelligence (AI) in digital platforms used\nby youth has created significant challenges related to privacy, autonomy, and\ndata protection. While AI-driven personalization offers enhanced user\nexperiences, it often operates without clear ethical boundaries, leaving young\nusers vulnerable to data exploitation and algorithmic biases. This paper\npresents a call to action for ethical AI governance, advocating for a\nstructured framework that ensures youth-centred privacy protections,\ntransparent data practices, and regulatory oversight. We outline key areas\nrequiring urgent intervention, including algorithmic transparency, privacy\neducation, parental data-sharing ethics, and accountability measures. Through\nthis approach, we seek to empower youth with greater control over their digital\nidentities and propose actionable strategies for policymakers, AI developers,\nand educators to build a fairer and more accountable AI ecosystem.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Preprint Version | To be submitted to peer-reviewed venue",
    "pdf_url": "http://arxiv.org/pdf/2503.11947v1",
    "published_date": "2025-03-15 01:35:56 UTC",
    "updated_date": "2025-03-15 01:35:56 UTC"
  },
  {
    "arxiv_id": "2503.11944v1",
    "title": "Human Digital Twins in Personalized Healthcare: An Overview and Future Perspectives",
    "authors": [
      "Melvin Mokhtari"
    ],
    "abstract": "Digital twins (DTs) are redefining healthcare by paving the way for more\npersonalized, proactive, and intelligent medical interventions. As the shift\ntoward personalized care intensifies, there is a growing need for an\nindividual's virtual replica that delivers the right treatment at the optimal\ntime and in the most effective manner. The emerging concept of a Human Digital\nTwin (HDT) holds the potential to revolutionize the traditional healthcare\nsystem much like digital twins have transformed manufacturing and aviation. An\nHDT mirrors the physical entity of a human body through a dynamic virtual model\nthat continuously reflects changes in molecular, physiological, emotional, and\nlifestyle factors. This digital representation not only supports remote\nmonitoring, diagnosis, and prescription but also facilitates surgery,\nrehabilitation, and overall personalized care, thereby relieving pressure on\nconventional healthcare frameworks. Despite its promising advantages, there are\nconsiderable research challenges to overcome as HDT technology evolves. In this\nstudy, I will initially delineate the distinctions between traditional digital\ntwins and HDTs, followed by an exploration of the networking architecture\nintegral to their operation--from data acquisition and communication to\ncomputation, management, and decision-making--thereby offering insights into\nhow these innovations may reshape the modern healthcare industry.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.11944v1",
    "published_date": "2025-03-15 01:35:27 UTC",
    "updated_date": "2025-03-15 01:35:27 UTC"
  },
  {
    "arxiv_id": "2503.11937v1",
    "title": "Att-Adapter: A Robust and Precise Domain-Specific Multi-Attributes T2I Diffusion Adapter via Conditional Variational Autoencoder",
    "authors": [
      "Wonwoong Cho",
      "Yan-Ying Chen",
      "Matthew Klenk",
      "David I. Inouye",
      "Yanxia Zhang"
    ],
    "abstract": "Text-to-Image (T2I) Diffusion Models have achieved remarkable performance in\ngenerating high quality images. However, enabling precise control of continuous\nattributes, especially multiple attributes simultaneously, in a new domain\n(e.g., numeric values like eye openness or car width) with text-only guidance\nremains a significant challenge. To address this, we introduce the Attribute\n(Att) Adapter, a novel plug-and-play module designed to enable fine-grained,\nmulti-attributes control in pretrained diffusion models. Our approach learns a\nsingle control adapter from a set of sample images that can be unpaired and\ncontain multiple visual attributes. The Att-Adapter leverages the decoupled\ncross attention module to naturally harmonize the multiple domain attributes\nwith text conditioning. We further introduce Conditional Variational\nAutoencoder (CVAE) to the Att-Adapter to mitigate overfitting, matching the\ndiverse nature of the visual world. Evaluations on two public datasets show\nthat Att-Adapter outperforms all LoRA-based baselines in controlling continuous\nattributes. Additionally, our method enables a broader control range and also\nimproves disentanglement across multiple attributes, surpassing StyleGAN-based\ntechniques. Notably, Att-Adapter is flexible, requiring no paired synthetic\ndata for training, and is easily scalable to multiple attributes within a\nsingle model.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.11937v1",
    "published_date": "2025-03-15 01:06:34 UTC",
    "updated_date": "2025-03-15 01:06:34 UTC"
  },
  {
    "arxiv_id": "2503.11933v1",
    "title": "End-to-End Edge AI Service Provisioning Framework in 6G ORAN",
    "authors": [
      "Yun Tang",
      "Udhaya Chandhar Srinivasan",
      "Benjamin James Scott",
      "Obumneme Umealor",
      "Dennis Kevogo",
      "Weisi Guo"
    ],
    "abstract": "With the advent of 6G, Open Radio Access Network (O-RAN) architectures are\nevolving to support intelligent, adaptive, and automated network orchestration.\nThis paper proposes a novel Edge AI and Network Service Orchestration framework\nthat leverages Large Language Model (LLM) agents deployed as O-RAN rApps. The\nproposed LLM-agent-powered system enables interactive and intuitive\norchestration by translating the user's use case description into deployable AI\nservices and corresponding network configurations. The LLM agent automates\nmultiple tasks, including AI model selection from repositories (e.g., Hugging\nFace), service deployment, network adaptation, and real-time monitoring via\nxApps. We implement a prototype using open-source O-RAN projects\n(OpenAirInterface and FlexRIC) to demonstrate the feasibility and functionality\nof our framework. Our demonstration showcases the end-to-end flow of AI service\norchestration, from user interaction to network adaptation, ensuring Quality of\nService (QoS) compliance. This work highlights the potential of integrating\nLLM-driven automation into 6G O-RAN ecosystems, paving the way for more\naccessible and efficient edge AI ecosystems.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "5 pages, 3 figures, submitted to IEEE VTC for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2503.11933v1",
    "published_date": "2025-03-15 00:48:50 UTC",
    "updated_date": "2025-03-15 00:48:50 UTC"
  },
  {
    "arxiv_id": "2503.16511v1",
    "title": "Token-Level Uncertainty-Aware Objective for Language Model Post-Training",
    "authors": [
      "Tingkai Liu",
      "Ari S. Benjamin",
      "Anthony M. Zador"
    ],
    "abstract": "In the current work, we connect token-level uncertainty in causal language\nmodeling to two types of training objectives: 1) masked maximum likelihood\n(MLE), 2) self-distillation. We show that masked MLE is effective in reducing\nepistemic uncertainty, and serve as an effective token-level automatic\ncurriculum learning technique. However, masked MLE is prone to overfitting and\nrequires self-distillation regularization to improve or maintain performance on\nout-of-distribution tasks. We demonstrate significant performance gain via the\nproposed training objective - combined masked MLE and self-distillation -\nacross multiple architectures (Gemma, LLaMA, Phi) and datasets (Alpaca,\nShareGPT, GSM8K), mitigating overfitting while maintaining adaptability during\npost-training. Our findings suggest that uncertainty-aware training provides an\neffective mechanism for enhancing language model training.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16511v1",
    "published_date": "2025-03-15 00:32:14 UTC",
    "updated_date": "2025-03-15 00:32:14 UTC"
  }
]