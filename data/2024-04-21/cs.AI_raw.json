[
  {
    "arxiv_id": "2407.10975v1",
    "title": "Stream State-tying for Sign Language Recognition",
    "authors": [
      "Jiyong Ma",
      "Wen Gao",
      "Chunli Wang"
    ],
    "abstract": "In this paper, a novel approach to sign language recognition based on state\ntying in each of data streams is presented. In this framework, it is assumed\nthat hand gesture signal is represented in terms of six synchronous data\nstreams, i.e., the left/right hand position, left/right hand orientation and\nleft/right handshape. This approach offers a very accurate representation of\nthe sign space and keeps the number of parameters reasonably small in favor of\na fast decoding. Experiments were carried out for 5177 Chinese signs. The real\ntime isolated recognition rate is 94.8%. For continuous sign recognition, the\nword correct rate is 91.4%. Keywords: Sign language recognition; Automatic sign\nlanguage translation; Hand gesture recognition; Hidden Markov models;\nState-tying; Multimodal user interface; Virtual reality; Man-machine systems.",
    "categories": [
      "cs.OH",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.OH",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.10975v1",
    "published_date": "2024-04-21 23:21:52 UTC",
    "updated_date": "2024-04-21 23:21:52 UTC"
  },
  {
    "arxiv_id": "2404.13792v1",
    "title": "Counterfactual Reasoning Using Predicted Latent Personality Dimensions for Optimizing Persuasion Outcome",
    "authors": [
      "Donghuo Zeng",
      "Roberto S. Legaspi",
      "Yuewen Sun",
      "Xinshuai Dong",
      "Kazushi Ikeda",
      "Peter Spirtes",
      "kun Zhang"
    ],
    "abstract": "Customizing persuasive conversations related to the outcome of interest for\nspecific users achieves better persuasion results. However, existing persuasive\nconversation systems rely on persuasive strategies and encounter challenges in\ndynamically adjusting dialogues to suit the evolving states of individual users\nduring interactions. This limitation restricts the system's ability to deliver\nflexible or dynamic conversations and achieve suboptimal persuasion outcomes.\nIn this paper, we present a novel approach that tracks a user's latent\npersonality dimensions (LPDs) during ongoing persuasion conversation and\ngenerates tailored counterfactual utterances based on these LPDs to optimize\nthe overall persuasion outcome. In particular, our proposed method leverages a\nBi-directional Generative Adversarial Network (BiCoGAN) in tandem with a\nDialogue-based Personality Prediction Regression (DPPR) model to generate\ncounterfactual data. This enables the system to formulate alternative\npersuasive utterances that are more suited to the user. Subsequently, we\nutilize the D3QN model to learn policies for optimized selection of system\nutterances on counterfactual data. Experimental results we obtained from using\nthe PersuasionForGood dataset demonstrate the superiority of our approach over\nthe existing method, BiCoGAN. The cumulative rewards and Q-values produced by\nour method surpass ground truth benchmarks, showcasing the efficacy of\nemploying counterfactual reasoning and LPDs to optimize reinforcement learning\npolicy in online interactions.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.MM",
    "comment": "14 pages, 10 figures, Accepted by Persuasive Technology 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.13792v1",
    "published_date": "2024-04-21 23:03:47 UTC",
    "updated_date": "2024-04-21 23:03:47 UTC"
  },
  {
    "arxiv_id": "2404.13791v1",
    "title": "Universal Fingerprint Generation: Controllable Diffusion Model with Multimodal Conditions",
    "authors": [
      "Steven A. Grosz",
      "Anil K. Jain"
    ],
    "abstract": "The utilization of synthetic data for fingerprint recognition has garnered\nincreased attention due to its potential to alleviate privacy concerns\nsurrounding sensitive biometric data. However, current methods for generating\nfingerprints have limitations in creating impressions of the same finger with\nuseful intra-class variations. To tackle this challenge, we present GenPrint, a\nframework to produce fingerprint images of various types while maintaining\nidentity and offering humanly understandable control over different appearance\nfactors such as fingerprint class, acquisition type, sensor device, and quality\nlevel. Unlike previous fingerprint generation approaches, GenPrint is not\nconfined to replicating style characteristics from the training dataset alone:\nit enables the generation of novel styles from unseen devices without requiring\nadditional fine-tuning. To accomplish these objectives, we developed GenPrint\nusing latent diffusion models with multimodal conditions (text and image) for\nconsistent generation of style and identity. Our experiments leverage a variety\nof publicly available datasets for training and evaluation. Results demonstrate\nthe benefits of GenPrint in terms of identity preservation, explainable\ncontrol, and universality of generated images. Importantly, the\nGenPrint-generated images yield comparable or even superior accuracy to models\ntrained solely on real data and further enhances performance when augmenting\nthe diversity of existing real fingerprint datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13791v1",
    "published_date": "2024-04-21 23:01:08 UTC",
    "updated_date": "2024-04-21 23:01:08 UTC"
  },
  {
    "arxiv_id": "2404.13789v1",
    "title": "Anchor-aware Deep Metric Learning for Audio-visual Retrieval",
    "authors": [
      "Donghuo Zeng",
      "Yanan Wang",
      "Kazushi Ikeda",
      "Yi Yu"
    ],
    "abstract": "Metric learning minimizes the gap between similar (positive) pairs of data\npoints and increases the separation of dissimilar (negative) pairs, aiming at\ncapturing the underlying data structure and enhancing the performance of tasks\nlike audio-visual cross-modal retrieval (AV-CMR). Recent works employ sampling\nmethods to select impactful data points from the embedding space during\ntraining. However, the model training fails to fully explore the space due to\nthe scarcity of training data points, resulting in an incomplete representation\nof the overall positive and negative distributions. In this paper, we propose\nan innovative Anchor-aware Deep Metric Learning (AADML) method to address this\nchallenge by uncovering the underlying correlations among existing data points,\nwhich enhances the quality of the shared embedding space. Specifically, our\nmethod establishes a correlation graph-based manifold structure by considering\nthe dependencies between each sample as the anchor and its semantically similar\nsamples. Through dynamic weighting of the correlations within this underlying\nmanifold structure using an attention-driven mechanism, Anchor Awareness (AA)\nscores are obtained for each anchor. These AA scores serve as data proxies to\ncompute relative distances in metric learning approaches. Extensive experiments\nconducted on two audio-visual benchmark datasets demonstrate the effectiveness\nof our proposed AADML method, significantly surpassing state-of-the-art models.\nFurthermore, we investigate the integration of AA proxies with various metric\nlearning methods, further highlighting the efficacy of our approach.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.IR",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "9 pages, 5 figures. Accepted by ACM ICMR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.13789v1",
    "published_date": "2024-04-21 22:44:44 UTC",
    "updated_date": "2024-04-21 22:44:44 UTC"
  },
  {
    "arxiv_id": "2404.13788v3",
    "title": "AnyPattern: Towards In-context Image Copy Detection",
    "authors": [
      "Wenhao Wang",
      "Yifan Sun",
      "Zhentao Tan",
      "Yi Yang"
    ],
    "abstract": "This paper explores in-context learning for image copy detection (ICD), i.e.,\nprompting an ICD model to identify replicated images with new tampering\npatterns without the need for additional training. The prompts (or the\ncontexts) are from a small set of image-replica pairs that reflect the new\npatterns and are used at inference time. Such in-context ICD has good realistic\nvalue, because it requires no fine-tuning and thus facilitates fast reaction\nagainst the emergence of unseen patterns. To accommodate the \"seen\n$\\rightarrow$ unseen\" generalization scenario, we construct the first\nlarge-scale pattern dataset named AnyPattern, which has the largest number of\ntamper patterns ($90$ for training and $10$ for testing) among all the existing\nones. We benchmark AnyPattern with popular ICD methods and reveal that existing\nmethods barely generalize to novel patterns. We further propose a simple\nin-context ICD method named ImageStacker. ImageStacker learns to select the\nmost representative image-replica pairs and employs them as the pattern prompts\nin a stacking manner (rather than the popular concatenation manner).\nExperimental results show (1) training with our large-scale dataset\nsubstantially benefits pattern generalization ($+26.66 \\%$ $\\mu AP$), (2) the\nproposed ImageStacker facilitates effective in-context ICD (another round of\n$+16.75 \\%$ $\\mu AP$), and (3) AnyPattern enables in-context ICD, i.e., without\nsuch a large-scale dataset, in-context learning does not emerge even with our\nImageStacker. Beyond the ICD task, we also demonstrate how AnyPattern can\nbenefit artists, i.e., the pattern retrieval method trained on AnyPattern can\nbe generalized to identify style mimicry by text-to-image models. The project\nis publicly available at https://anypattern.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The project is publicly available at https://anypattern.github.io",
    "pdf_url": "http://arxiv.org/pdf/2404.13788v3",
    "published_date": "2024-04-21 22:33:57 UTC",
    "updated_date": "2024-09-28 13:03:32 UTC"
  },
  {
    "arxiv_id": "2404.16873v1",
    "title": "AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs",
    "authors": [
      "Anselm Paulus",
      "Arman Zharmagambetov",
      "Chuan Guo",
      "Brandon Amos",
      "Yuandong Tian"
    ],
    "abstract": "While recently Large Language Models (LLMs) have achieved remarkable\nsuccesses, they are vulnerable to certain jailbreaking attacks that lead to\ngeneration of inappropriate or harmful content. Manual red-teaming requires\nfinding adversarial prompts that cause such jailbreaking, e.g. by appending a\nsuffix to a given instruction, which is inefficient and time-consuming. On the\nother hand, automatic adversarial prompt generation often leads to semantically\nmeaningless attacks that can easily be detected by perplexity-based filters,\nmay require gradient information from the TargetLLM, or do not scale well due\nto time-consuming discrete optimization processes over the token space. In this\npaper, we present a novel method that uses another LLM, called the AdvPrompter,\nto generate human-readable adversarial prompts in seconds, $\\sim800\\times$\nfaster than existing optimization-based approaches. We train the AdvPrompter\nusing a novel algorithm that does not require access to the gradients of the\nTargetLLM. This process alternates between two steps: (1) generating\nhigh-quality target adversarial suffixes by optimizing the AdvPrompter\npredictions, and (2) low-rank fine-tuning of the AdvPrompter with the generated\nadversarial suffixes. The trained AdvPrompter generates suffixes that veil the\ninput instruction without changing its meaning, such that the TargetLLM is\nlured to give a harmful response. Experimental results on popular open source\nTargetLLMs show state-of-the-art results on the AdvBench dataset, that also\ntransfer to closed-source black-box LLM APIs. Further, we demonstrate that by\nfine-tuning on a synthetic dataset generated by AdvPrompter, LLMs can be made\nmore robust against jailbreaking attacks while maintaining performance, i.e.\nhigh MMLU scores.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "32 pages, 9 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.16873v1",
    "published_date": "2024-04-21 22:18:13 UTC",
    "updated_date": "2024-04-21 22:18:13 UTC"
  },
  {
    "arxiv_id": "2407.02495v1",
    "title": "Minds, Brains, AI",
    "authors": [
      "Jay Seitz"
    ],
    "abstract": "In the last year or so and going back many decades there has been extensive\nclaims by major computational scientists, engineers, and others that AGI,\nartificial general intelligence, is five or ten years away, but without a\nscintilla of scientific evidence, for a broad body of these claims. Computers\nwill become conscious, have a theory of mind, think and reason, will become\nmore intelligent than humans, and so on. But the claims are science fiction,\nnot science. This article reviews evidence for the following three propositions\nusing extensive body of scientific research and related sources from the\ncognitive and neurosciences, evolutionary evidence, linguistics, data science,\ncomparative psychology, self-driving cars, robotics. and the learning sciences.\n(1) Do computing machines think or reason? (2) Are computing machines sentient\nor conscious? (3) Do computing machines have a theory of mind?",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02495v1",
    "published_date": "2024-04-21 21:49:42 UTC",
    "updated_date": "2024-04-21 21:49:42 UTC"
  },
  {
    "arxiv_id": "2404.13786v1",
    "title": "Soar: Design and Deployment of A Smart Roadside Infrastructure System for Autonomous Driving",
    "authors": [
      "Shuyao Shi",
      "Neiwen Ling",
      "Zhehao Jiang",
      "Xuan Huang",
      "Yuze He",
      "Xiaoguang Zhao",
      "Bufang Yang",
      "Chen Bian",
      "Jingfei Xia",
      "Zhenyu Yan",
      "Raymond Yeung",
      "Guoliang Xing"
    ],
    "abstract": "Recently,smart roadside infrastructure (SRI) has demonstrated the potential\nof achieving fully autonomous driving systems. To explore the potential of\ninfrastructure-assisted autonomous driving, this paper presents the design and\ndeployment of Soar, the first end-to-end SRI system specifically designed to\nsupport autonomous driving systems. Soar consists of both software and hardware\ncomponents carefully designed to overcome various system and physical\nchallenges. Soar can leverage the existing operational infrastructure like\nstreet lampposts for a lower barrier of adoption. Soar adopts a new\ncommunication architecture that comprises a bi-directional multi-hop I2I\nnetwork and a downlink I2V broadcast service, which are designed based on\noff-the-shelf 802.11ac interfaces in an integrated manner. Soar also features a\nhierarchical DL task management framework to achieve desirable load balancing\namong nodes and enable them to collaborate efficiently to run multiple\ndata-intensive autonomous driving applications. We deployed a total of 18 Soar\nnodes on existing lampposts on campus, which have been operational for over two\nyears. Our real-world evaluation shows that Soar can support a diverse set of\nautonomous driving applications and achieve desirable real-time performance and\nhigh communication reliability. Our findings and experiences in this work offer\nkey insights into the development and deployment of next-generation smart\nroadside infrastructure and autonomous driving systems.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.DC",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13786v1",
    "published_date": "2024-04-21 21:45:23 UTC",
    "updated_date": "2024-04-21 21:45:23 UTC"
  },
  {
    "arxiv_id": "2404.13778v1",
    "title": "Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems",
    "authors": [
      "Adilet Yerkin",
      "Elnara Kadyrgali",
      "Yerdauit Torekhan",
      "Pakizar Shamoi"
    ],
    "abstract": "Watching movies is one of the social activities typically done in groups.\nEmotion is the most vital factor that affects movie viewers' preferences. So,\nthe emotional aspect of the movie needs to be determined and analyzed for\nfurther recommendations. It can be challenging to choose a movie that appeals\nto the emotions of a diverse group. Reaching an agreement for a group can be\ndifficult due to the various genres and choices. This paper proposes a novel\napproach to group movie suggestions by examining emotions from three different\nchannels: movie descriptions (text), soundtracks (audio), and posters (image).\nWe employ the Jaccard similarity index to match each participant's emotional\npreferences to prospective movie choices, followed by a fuzzy inference\ntechnique to determine group consensus. We use a weighted integration process\nfor the fusion of emotion scores from diverse data types. Then, group movie\nrecommendation is based on prevailing emotions and viewers' best-loved movies.\nAfter determining the recommendations, the group's consensus level is\ncalculated using a fuzzy inference system, taking participants' feedback as\ninput. Participants (n=130) in the survey were provided with different emotion\ncategories and asked to select the emotions best suited for particular movies\n(n=12). Comparison results between predicted and actual scores demonstrate the\nefficiency of using emotion detection for this problem (Jaccard similarity\nindex = 0.76). We explored the relationship between induced emotions and movie\npopularity as an additional experiment, analyzing emotion distribution in 100\npopular movies from the TMDB database. Such systems can potentially improve the\naccuracy of movie recommendation systems and achieve a high level of consensus\namong participants with diverse preferences.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "the paper has been submitted for consideration to IEEE",
    "pdf_url": "http://arxiv.org/pdf/2404.13778v1",
    "published_date": "2024-04-21 21:19:31 UTC",
    "updated_date": "2024-04-21 21:19:31 UTC"
  },
  {
    "arxiv_id": "2404.14459v2",
    "title": "LLMs in Web Development: Evaluating LLM-Generated PHP Code Unveiling Vulnerabilities and Limitations",
    "authors": [
      "Rebeka Tóth",
      "Tamas Bisztray",
      "László Erdodi"
    ],
    "abstract": "This study evaluates the security of web application code generated by Large\nLanguage Models, analyzing 2,500 GPT-4 generated PHP websites. These were\ndeployed in Docker containers and tested for vulnerabilities using a hybrid\napproach of Burp Suite active scanning, static analysis, and manual review. Our\ninvestigation focuses on identifying Insecure File Upload, SQL Injection,\nStored XSS, and Reflected XSS in GPT-4 generated PHP code. This analysis\nhighlights potential security risks and the implications of deploying such code\nin real-world scenarios. Overall, our analysis found 2,440 vulnerable\nparameters. According to Burp's Scan, 11.56% of the sites can be straight out\ncompromised. Adding static scan results, 26% had at least one vulnerability\nthat can be exploited through web interaction. Certain coding scenarios, like\nfile upload functionality, are insecure 78% of the time, underscoring\nsignificant risks to software safety and security. To support further research,\nwe have made the source codes and a detailed vulnerability record for each\nsample publicly available. This study emphasizes the crucial need for thorough\ntesting and evaluation if generative AI technologies are used in software\ndevelopment.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14459v2",
    "published_date": "2024-04-21 20:56:02 UTC",
    "updated_date": "2024-05-21 13:10:39 UTC"
  },
  {
    "arxiv_id": "2404.13770v1",
    "title": "EncodeNet: A Framework for Boosting DNN Accuracy with Entropy-driven Generalized Converting Autoencoder",
    "authors": [
      "Hasanul Mahmud",
      "Kevin Desai",
      "Palden Lama",
      "Sushil K. Prasad"
    ],
    "abstract": "Image classification is a fundamental task in computer vision, and the quest\nto enhance DNN accuracy without inflating model size or latency remains a\npressing concern. We make a couple of advances in this regard, leading to a\nnovel EncodeNet design and training framework. The first advancement involves\nConverting Autoencoders, a novel approach that transforms images into an\neasy-to-classify image of its class. Our prior work that applied the Converting\nAutoencoder and a simple classifier in tandem achieved moderate accuracy over\nsimple datasets, such as MNIST and FMNIST. However, on more complex datasets\nlike CIFAR-10, the Converting Autoencoder has a large reconstruction loss,\nmaking it unsuitable for enhancing DNN accuracy. To address these limitations,\nwe generalize the design of Converting Autoencoders by leveraging a larger\nclass of DNNs, those with architectures comprising feature extraction layers\nfollowed by classification layers. We incorporate a generalized algorithmic\ndesign of the Converting Autoencoder and intraclass clustering to identify\nrepresentative images, leading to optimized image feature learning. Next, we\ndemonstrate the effectiveness of our EncodeNet design and training framework,\nimproving the accuracy of well-trained baseline DNNs while maintaining the\noverall model size. EncodeNet's building blocks comprise the trained encoder\nfrom our generalized Converting Autoencoders transferring knowledge to a\nlightweight classifier network - also extracted from the baseline DNN. Our\nexperimental results demonstrate that EncodeNet improves the accuracy of VGG16\nfrom 92.64% to 94.05% on CIFAR-10 and RestNet20 from 74.56% to 76.04% on\nCIFAR-100. It outperforms state-of-the-art techniques that rely on knowledge\ndistillation and attention mechanisms, delivering higher accuracy for models of\ncomparable size.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.13770v1",
    "published_date": "2024-04-21 20:45:18 UTC",
    "updated_date": "2024-04-21 20:45:18 UTC"
  },
  {
    "arxiv_id": "2404.13767v1",
    "title": "Autonomous Robot for Disaster Mapping and Victim Localization",
    "authors": [
      "Michael Potter",
      "Rahil Bhowal",
      "Richard Zhao",
      "Anuj Patel",
      "Jingming Cheng"
    ],
    "abstract": "In response to the critical need for effective reconnaissance in disaster\nscenarios, this research article presents the design and implementation of a\ncomplete autonomous robot system using the Turtlebot3 with Robotic Operating\nSystem (ROS) Noetic. Upon deployment in closed, initially unknown environments,\nthe system aims to generate a comprehensive map and identify any present\n'victims' using AprilTags as stand-ins. We discuss our solution for search and\nrescue missions, while additionally exploring more advanced algorithms to\nimprove search and rescue functionalities. We introduce a Cubature Kalman\nFilter to help reduce the mean squared error [m] for AprilTag localization and\nan information-theoretic exploration algorithm to expedite exploration in\nunknown environments. Just like turtles, our system takes it slow and steady,\nbut when it's time to save the day, it moves at ninja-like speed! Despite\nDonatello's shell, he's no slowpoke - he zips through obstacles with the\nagility of a teenage mutant ninja turtle. So, hang on tight to your shells and\nget ready for a whirlwind of reconnaissance!\n  Full pipeline code https://github.com/rzhao5659/MRProject/tree/main\n  Exploration code https://github.com/rzhao5659/MRProject/tree/main",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Class final project for Northeastern University EECE 5550 Mobile\n  Robotics Course",
    "pdf_url": "http://arxiv.org/pdf/2404.13767v1",
    "published_date": "2024-04-21 20:32:02 UTC",
    "updated_date": "2024-04-21 20:32:02 UTC"
  },
  {
    "arxiv_id": "2404.13752v3",
    "title": "Adversarial Representation Engineering: A General Model Editing Framework for Large Language Models",
    "authors": [
      "Yihao Zhang",
      "Zeming Wei",
      "Jun Sun",
      "Meng Sun"
    ],
    "abstract": "Since the rapid development of Large Language Models (LLMs) has achieved\nremarkable success, understanding and rectifying their internal complex\nmechanisms has become an urgent issue. Recent research has attempted to\ninterpret their behaviors through the lens of inner representation. However,\ndeveloping practical and efficient methods for applying these representations\nfor general and flexible model editing remains challenging. In this work, we\nexplore how to leverage insights from representation engineering to guide the\nediting of LLMs by deploying a representation sensor as an editing oracle. We\nfirst identify the importance of a robust and reliable sensor during editing,\nthen propose an Adversarial Representation Engineering (ARE) framework to\nprovide a unified and interpretable approach for conceptual model editing\nwithout compromising baseline performance. Experiments on multiple tasks\ndemonstrate the effectiveness of ARE in various model editing scenarios. Our\ncode and data are available at\nhttps://github.com/Zhang-Yihao/Adversarial-Representation-Engineering.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.13752v3",
    "published_date": "2024-04-21 19:24:15 UTC",
    "updated_date": "2024-11-01 07:51:36 UTC"
  },
  {
    "arxiv_id": "2404.13745v1",
    "title": "A Nasal Cytology Dataset for Object Detection and Deep Learning",
    "authors": [
      "Mauro Camporeale",
      "Giovanni Dimauro",
      "Matteo Gelardi",
      "Giorgia Iacobellis",
      "Mattia Sebastiano Ladisa",
      "Sergio Latrofa",
      "Nunzia Lomonte"
    ],
    "abstract": "Nasal Cytology is a new and efficient clinical technique to diagnose rhinitis\nand allergies that is not much widespread due to the time-consuming nature of\ncell counting; that is why AI-aided counting could be a turning point for the\ndiffusion of this technique. In this article we present the first dataset of\nrhino-cytological field images: the NCD (Nasal Cytology Dataset), aimed to\ntrain and deploy Object Detection models to support physicians and biologists\nduring clinical practice. The real distribution of the cytotypes, populating\nthe nasal mucosa has been replicated, sampling images from slides of clinical\npatients, and manually annotating each cell found on them. The correspondent\nobject detection task presents non'trivial issues associated with the strong\nclass imbalancement, involving the rarest cell types. This work contributes to\nsome of open challenges by presenting a novel machine learning-based approach\nto aid the automated detection and classification of nasal mucosa cells: the\nDETR and YOLO models shown good performance in detecting cells and classifying\nthem correctly, revealing great potential to accelerate the work of rhinology\nexperts.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Pre Print almost ready to be submitted",
    "pdf_url": "http://arxiv.org/pdf/2404.13745v1",
    "published_date": "2024-04-21 19:02:38 UTC",
    "updated_date": "2024-04-21 19:02:38 UTC"
  },
  {
    "arxiv_id": "2404.13742v1",
    "title": "Seamless Underwater Navigation with Limited Doppler Velocity Log Measurements",
    "authors": [
      "Nadav Cohen",
      "Itzik Klein"
    ],
    "abstract": "Autonomous Underwater Vehicles (AUVs) commonly utilize an inertial navigation\nsystem (INS) and a Doppler velocity log (DVL) for underwater navigation. To\nthat end, their measurements are integrated through a nonlinear filter such as\nthe extended Kalman filter (EKF). The DVL velocity vector estimate depends on\nretrieving reflections from the seabed, ensuring that at least three out of its\nfour transmitted acoustic beams return successfully. When fewer than three\nbeams are obtained, the DVL cannot provide a velocity update to bind the\nnavigation solution drift. To cope with this challenge, in this paper, we\npropose a hybrid neural coupled (HNC) approach for seamless AUV navigation in\nsituations of limited DVL measurements. First, we drive an approach to regress\ntwo or three missing DVL beams. Then, those beams, together with the measured\nbeams, are incorporated into the EKF. We examined INS/DVL fusion both in\nloosely and tightly coupled approaches. Our method was trained and evaluated on\nrecorded data from AUV experiments conducted in the Mediterranean Sea on two\ndifferent occasions. The results illustrate that our proposed method\noutperforms the baseline loosely and tightly coupled model-based approaches by\nan average of 96.15%. It also demonstrates superior performance compared to a\nmodel-based beam estimator by an average of 12.41% in terms of velocity\naccuracy for scenarios involving two or three missing beams. Therefore, we\ndemonstrate that our approach offers seamless AUV navigation in situations of\nlimited beam measurements.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13742v1",
    "published_date": "2024-04-21 18:56:54 UTC",
    "updated_date": "2024-04-21 18:56:54 UTC"
  },
  {
    "arxiv_id": "2404.13737v4",
    "title": "Stochastic Multi-round Submodular Optimization with Budget",
    "authors": [
      "Vincenzo Auletta",
      "Diodato Ferraioli",
      "Cosimo Vinci"
    ],
    "abstract": "In this work, we study the Stochastic Budgeted Multi-round Submodular\nMaximization (SBMSm) problem, where we aim to adaptively maximize the sum, over\nmultiple rounds, of a monotone and submodular objective function defined on\nsubsets of items. The objective function also depends on the realization of\nstochastic events, and the total number of items we can select over all rounds\nis bounded by a limited budget. This problem extends, and generalizes to\nmultiple round settings, well-studied problems such as (adaptive) influence\nmaximization and stochastic probing.\n  We show that, if the number of items and stochastic events is somehow\nbounded, there is a polynomial time dynamic programming algorithm for SBMSm.\nThen, we provide a simple greedy $1/2(1-1/e-\\epsilon)\\approx\n0.316$-approximation algorithm for SBMSm, that first non-adaptively allocates\nthe budget to be spent at each round, and then greedily and adaptively\nmaximizes the objective function by using the budget assigned at each round.\nFinally, we introduce the {\\em budget-adaptivity gap}, by which we measure how\nmuch an adaptive policy for SBMSm is better than an optimal partially adaptive\none that, as in our greedy algorithm, determines the budget allocation in\nadvance. We show that the budget-adaptivity gap lies between $e/(e-1)\\approx\n1.582$ and $2$.",
    "categories": [
      "cs.DS",
      "cs.AI"
    ],
    "primary_category": "cs.DS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13737v4",
    "published_date": "2024-04-21 18:24:43 UTC",
    "updated_date": "2024-09-25 16:53:01 UTC"
  },
  {
    "arxiv_id": "2404.13736v2",
    "title": "Interval Abstractions for Robust Counterfactual Explanations",
    "authors": [
      "Junqi Jiang",
      "Francesco Leofante",
      "Antonio Rago",
      "Francesca Toni"
    ],
    "abstract": "Counterfactual Explanations (CEs) have emerged as a major paradigm in\nexplainable AI research, providing recourse recommendations for users affected\nby the decisions of machine learning models. However, CEs found by existing\nmethods often become invalid when slight changes occur in the parameters of the\nmodel they were generated for. The literature lacks a way to provide exhaustive\nrobustness guarantees for CEs under model changes, in that existing methods to\nimprove CEs' robustness are mostly heuristic, and the robustness performances\nare evaluated empirically using only a limited number of retrained models. To\nbridge this gap, we propose a novel interval abstraction technique for\nparametric machine learning models, which allows us to obtain provable\nrobustness guarantees for CEs under a possibly infinite set of plausible model\nchanges $\\Delta$. Based on this idea, we formalise a robustness notion for CEs,\nwhich we call $\\Delta$-robustness, in both binary and multi-class\nclassification settings. We present procedures to verify $\\Delta$-robustness\nbased on Mixed Integer Linear Programming, using which we further propose\nalgorithms to generate CEs that are $\\Delta$-robust. In an extensive empirical\nstudy involving neural networks and logistic regression models, we demonstrate\nthe practical applicability of our approach. We discuss two strategies for\ndetermining the appropriate hyperparameters in our method, and we\nquantitatively benchmark CEs generated by eleven methods, highlighting the\neffectiveness of our algorithms in finding robust CEs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in Artificial Intelligence Journal",
    "pdf_url": "http://arxiv.org/pdf/2404.13736v2",
    "published_date": "2024-04-21 18:24:34 UTC",
    "updated_date": "2024-11-22 15:01:12 UTC"
  },
  {
    "arxiv_id": "2404.13733v4",
    "title": "Elucidating the Design Space of Dataset Condensation",
    "authors": [
      "Shitong Shao",
      "Zikai Zhou",
      "Huanran Chen",
      "Zhiqiang Shen"
    ],
    "abstract": "Dataset condensation, a concept within data-centric learning, efficiently\ntransfers critical attributes from an original dataset to a synthetic version,\nmaintaining both diversity and realism. This approach significantly improves\nmodel training efficiency and is adaptable across multiple application areas.\nPrevious methods in dataset condensation have faced challenges: some incur high\ncomputational costs which limit scalability to larger datasets (e.g., MTT,\nDREAM, and TESLA), while others are restricted to less optimal design spaces,\nwhich could hinder potential improvements, especially in smaller datasets\n(e.g., SRe2L, G-VBSM, and RDED). To address these limitations, we propose a\ncomprehensive design framework that includes specific, effective strategies\nlike implementing soft category-aware matching and adjusting the learning rate\nschedule. These strategies are grounded in empirical evidence and theoretical\nbacking. Our resulting approach, Elucidate Dataset Condensation (EDC),\nestablishes a benchmark for both small and large-scale dataset condensation. In\nour testing, EDC achieves state-of-the-art accuracy, reaching 48.6% on\nImageNet-1k with a ResNet-18 model at an IPC of 10, which corresponds to a\ncompression ratio of 0.78%. This performance exceeds those of SRe2L, G-VBSM,\nand RDED by margins of 27.3%, 17.2%, and 6.6%, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.13733v4",
    "published_date": "2024-04-21 18:19:27 UTC",
    "updated_date": "2025-01-17 07:15:16 UTC"
  },
  {
    "arxiv_id": "2404.13721v1",
    "title": "The Framework of a Design Process Language",
    "authors": [
      "Arnulf Hagen"
    ],
    "abstract": "The thesis develops a view of design in a concept formation framework and\noutlines a language to describe both the object of the design and the process\nof designing. The unknown object at the outset of the design work may be seen\nas an unknown concept that the designer is to define. Throughout the process,\nshe develops a description of this object by relating it to known concepts. The\nsearch stops when the designer is satisfied that the design specification is\ncomplete enough to satisfy the requirements from it once built. It is then a\ncollection of propositions that all contribute towards defining the design\nobject - a collection of sentences describing relationships between the object\nand known concepts. Also, the design process itself may be described by\nrelating known concepts - by organizing known abilities into particular\npatterns of activation, or mobilization. In view of the demands posed to a\nlanguage to use in this concept formation process, the framework of a Design\nProcess Language (DPL) is developed. The basis for the language are linguistic\ncategories that act as classes of relations used to combine concepts,\ncontaining relations used for describing process and object within the same\ngeneral system, with some relations being process specific, others being object\nspecific, and with the bulk being used both for process and object description.\nAnother outcome is the distinction of modal relations, or relations describing\nfuturity, possibility, willingness, hypothetical events, and the like. The\ndesign process almost always includes aspects such as these, and it is thus\nnecessary for a language facilitating design process description to support\nsuch relationships to be constructed. The DPL is argued to be a foundation\nwhereupon to build a language that can be used for enabling computers to be\nmore useful - act more intelligently - in the design process.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "PhD dissertation, 1993, Norwegian Institute of Technology",
    "pdf_url": "http://arxiv.org/pdf/2404.13721v1",
    "published_date": "2024-04-21 17:20:19 UTC",
    "updated_date": "2024-04-21 17:20:19 UTC"
  },
  {
    "arxiv_id": "2404.13719v1",
    "title": "A Practical Multilevel Governance Framework for Autonomous and Intelligent Systems",
    "authors": [
      "Lukas D. Pöhler",
      "Klaus Diepold",
      "Wendell Wallach"
    ],
    "abstract": "Autonomous and intelligent systems (AIS) facilitate a wide range of\nbeneficial applications across a variety of different domains. However,\ntechnical characteristics such as unpredictability and lack of transparency, as\nwell as potential unintended consequences, pose considerable challenges to the\ncurrent governance infrastructure. Furthermore, the speed of development and\ndeployment of applications outpaces the ability of existing governance\ninstitutions to put in place effective ethical-legal oversight. New approaches\nfor agile, distributed and multilevel governance are needed. This work presents\na practical framework for multilevel governance of AIS. The framework enables\nmapping actors onto six levels of decision-making including the international,\nnational and organizational levels. Furthermore, it offers the ability to\nidentify and evolve existing tools or create new tools for guiding the behavior\nof actors within the levels. Governance mechanisms enable actors to shape and\nenforce regulations and other tools, which when complemented with good\npractices contribute to effective and comprehensive governance.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13719v1",
    "published_date": "2024-04-21 17:15:43 UTC",
    "updated_date": "2024-04-21 17:15:43 UTC"
  },
  {
    "arxiv_id": "2404.13706v1",
    "title": "Concept Arithmetics for Circumventing Concept Inhibition in Diffusion Models",
    "authors": [
      "Vitali Petsiuk",
      "Kate Saenko"
    ],
    "abstract": "Motivated by ethical and legal concerns, the scientific community is actively\ndeveloping methods to limit the misuse of Text-to-Image diffusion models for\nreproducing copyrighted, violent, explicit, or personal information in the\ngenerated images. Simultaneously, researchers put these newly developed safety\nmeasures to the test by assuming the role of an adversary to find\nvulnerabilities and backdoors in them. We use compositional property of\ndiffusion models, which allows to leverage multiple prompts in a single image\ngeneration. This property allows us to combine other concepts, that should not\nhave been affected by the inhibition, to reconstruct the vector, responsible\nfor target concept generation, even though the direct computation of this\nvector is no longer accessible. We provide theoretical and empirical evidence\nwhy the proposed attacks are possible and discuss the implications of these\nfindings for safe model deployment. We argue that it is essential to consider\nall possible approaches to image generation with diffusion models that can be\nemployed by an adversary. Our work opens up the discussion about the\nimplications of concept arithmetics and compositional inference for safety\nmechanisms in diffusion models.\n  Content Advisory: This paper contains discussions and model-generated content\nthat may be considered offensive. Reader discretion is advised.\n  Project page: https://cs-people.bu.edu/vpetsiuk/arc",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13706v1",
    "published_date": "2024-04-21 16:35:16 UTC",
    "updated_date": "2024-04-21 16:35:16 UTC"
  },
  {
    "arxiv_id": "2405.02321v1",
    "title": "Accelerating Medical Knowledge Discovery through Automated Knowledge Graph Generation and Enrichment",
    "authors": [
      "Mutahira Khalid",
      "Raihana Rahman",
      "Asim Abbas",
      "Sushama Kumari",
      "Iram Wajahat",
      "Syed Ahmad Chan Bukhari"
    ],
    "abstract": "Knowledge graphs (KGs) serve as powerful tools for organizing and\nrepresenting structured knowledge. While their utility is widely recognized,\nchallenges persist in their automation and completeness. Despite efforts in\nautomation and the utilization of expert-created ontologies, gaps in\nconnectivity remain prevalent within KGs. In response to these challenges, we\npropose an innovative approach termed ``Medical Knowledge Graph Automation\n(M-KGA)\". M-KGA leverages user-provided medical concepts and enriches them\nsemantically using BioPortal ontologies, thereby enhancing the completeness of\nknowledge graphs through the integration of pre-trained embeddings. Our\napproach introduces two distinct methodologies for uncovering hidden\nconnections within the knowledge graph: a cluster-based approach and a\nnode-based approach. Through rigorous testing involving 100 frequently\noccurring medical concepts in Electronic Health Records (EHRs), our M-KGA\nframework demonstrates promising results, indicating its potential to address\nthe limitations of existing knowledge graph automation techniques.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.02321v1",
    "published_date": "2024-04-21 15:54:27 UTC",
    "updated_date": "2024-04-21 15:54:27 UTC"
  },
  {
    "arxiv_id": "2404.13680v3",
    "title": "Zero-shot High-fidelity and Pose-controllable Character Animation",
    "authors": [
      "Bingwen Zhu",
      "Fanyi Wang",
      "Tianyi Lu",
      "Peng Liu",
      "Jingwen Su",
      "Jinxiu Liu",
      "Yanhao Zhang",
      "Zuxuan Wu",
      "Guo-Jun Qi",
      "Yu-Gang Jiang"
    ],
    "abstract": "Image-to-video (I2V) generation aims to create a video sequence from a single\nimage, which requires high temporal coherence and visual fidelity. However,\nexisting approaches suffer from inconsistency of character appearances and poor\npreservation of fine details. Moreover, they require a large amount of video\ndata for training, which can be computationally demanding. To address these\nlimitations, we propose PoseAnimate, a novel zero-shot I2V framework for\ncharacter animation. PoseAnimate contains three key components: 1) a Pose-Aware\nControl Module (PACM) that incorporates diverse pose signals into text\nembeddings, to preserve character-independent content and maintain precise\nalignment of actions. 2) a Dual Consistency Attention Module (DCAM) that\nenhances temporal consistency and retains character identity and intricate\nbackground details. 3) a Mask-Guided Decoupling Module (MGDM) that refines\ndistinct feature perception abilities, improving animation fidelity by\ndecoupling the character and background. We also propose a Pose Alignment\nTransition Algorithm (PATA) to ensure smooth action transition. Extensive\nexperiment results demonstrate that our approach outperforms the\nstate-of-the-art training-based methods in terms of character consistency and\ndetail fidelity. Moreover, it maintains a high level of temporal coherence\nthroughout the generated animations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.13680v3",
    "published_date": "2024-04-21 14:43:31 UTC",
    "updated_date": "2024-06-05 07:32:32 UTC"
  },
  {
    "arxiv_id": "2404.13667v1",
    "title": "MathNet: A Data-Centric Approach for Printed Mathematical Expression Recognition",
    "authors": [
      "Felix M. Schmitt-Koopmann",
      "Elaine M. Huang",
      "Hans-Peter Hutter",
      "Thilo Stadelmann",
      "Alireza Darvishy"
    ],
    "abstract": "Printed mathematical expression recognition (MER) models are usually trained\nand tested using LaTeX-generated mathematical expressions (MEs) as input and\nthe LaTeX source code as ground truth. As the same ME can be generated by\nvarious different LaTeX source codes, this leads to unwanted variations in the\nground truth data that bias test performance results and hinder efficient\nlearning. In addition, the use of only one font to generate the MEs heavily\nlimits the generalization of the reported results to realistic scenarios. We\npropose a data-centric approach to overcome this problem, and present\nconvincing experimental results: Our main contribution is an enhanced LaTeX\nnormalization to map any LaTeX ME to a canonical form. Based on this process,\nwe developed an improved version of the benchmark dataset im2latex-100k,\nfeaturing 30 fonts instead of one. Second, we introduce the real-world dataset\nrealFormula, with MEs extracted from papers. Third, we developed a MER model,\nMathNet, based on a convolutional vision transformer, with superior results on\nall four test sets (im2latex-100k, im2latexv2, realFormula, and InftyMDB-1),\noutperforming the previous state of the art by up to 88.3%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.13667v1",
    "published_date": "2024-04-21 14:03:34 UTC",
    "updated_date": "2024-04-21 14:03:34 UTC"
  },
  {
    "arxiv_id": "2404.16067v1",
    "title": "Layout2Rendering: AI-aided Greenspace design",
    "authors": [
      "Ran Chen",
      "Zeke Lian",
      "Yueheng He",
      "Xiao Ling",
      "Fuyu Yang",
      "Xueqi Yao",
      "Xingjian Yi",
      "Jing Zhao"
    ],
    "abstract": "In traditional human living environment landscape design, the establishment\nof three-dimensional models is an essential step for designers to intuitively\npresent the spatial relationships of design elements, as well as a foundation\nfor conducting landscape analysis on the site. Rapidly and effectively\ngenerating beautiful and realistic landscape spaces is a significant challenge\nfaced by designers. Although generative design has been widely applied in\nrelated fields, they mostly generate three-dimensional models through the\nrestriction of indicator parameters. However, the elements of landscape design\nare complex and have unique requirements, making it difficult to generate\ndesigns from the perspective of indicator limitations. To address these issues,\nthis study proposes a park space generative design system based on deep\nlearning technology. This system generates design plans based on the\ntopological relationships of landscape elements, then vectorizes the plan\nelement information, and uses Grasshopper to generate three-dimensional models\nwhile synchronously fine-tuning parameters, rapidly completing the entire\nprocess from basic site conditions to model effect analysis. Experimental\nresults show that: (1) the system, with the aid of AI-assisted technology, can\nrapidly generate space green space schemes that meet the designer's perspective\nbased on site conditions; (2) this study has vectorized and\nthree-dimensionalized various types of landscape design elements based on\nsemantic information; (3) the analysis and visualization module constructed in\nthis study can perform landscape analysis on the generated three-dimensional\nmodels and produce node effect diagrams, allowing users to modify the design in\nreal time based on the effects, thus enhancing the system's interactivity.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "14 pages,8 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.16067v1",
    "published_date": "2024-04-21 14:00:43 UTC",
    "updated_date": "2024-04-21 14:00:43 UTC"
  },
  {
    "arxiv_id": "2404.13663v2",
    "title": "Cumulative Hazard Function Based Efficient Multivariate Temporal Point Process Learning",
    "authors": [
      "Bingqing Liu"
    ],
    "abstract": "Most existing temporal point process models are characterized by conditional\nintensity function. These models often require numerical approximation methods\nfor likelihood evaluation, which potentially hurts their performance. By\ndirectly modelling the integral of the intensity function, i.e., the cumulative\nhazard function (CHF), the likelihood can be evaluated accurately, making it a\npromising approach. However, existing CHF-based methods are not well-defined,\ni.e., the mathematical constraints of CHF are not completely satisfied, leading\nto untrustworthy results. For multivariate temporal point process, most\nexisting methods model intensity (or density, etc.) functions for each variate,\nlimiting the scalability. In this paper, we explore using neural networks to\nmodel a flexible but well-defined CHF and learning the multivariate temporal\npoint process with low parameter complexity. Experimental results on six\ndatasets show that the proposed model achieves the state-of-the-art performance\non data fitting and event prediction tasks while having significantly fewer\nparameters and memory usage than the strong competitors. The source code and\ndata can be obtained from https://github.com/lbq8942/NPP.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.13663v2",
    "published_date": "2024-04-21 13:51:31 UTC",
    "updated_date": "2024-05-02 02:58:13 UTC"
  },
  {
    "arxiv_id": "2404.13657v1",
    "title": "MLP: Motion Label Prior for Temporal Sentence Localization in Untrimmed 3D Human Motions",
    "authors": [
      "Sheng Yan",
      "Mengyuan Liu",
      "Yong Wang",
      "Yang Liu",
      "Chen Chen",
      "Hong Liu"
    ],
    "abstract": "In this paper, we address the unexplored question of temporal sentence\nlocalization in human motions (TSLM), aiming to locate a target moment from a\n3D human motion that semantically corresponds to a text query. Considering that\n3D human motions are captured using specialized motion capture devices, motions\nwith only a few joints lack complex scene information like objects and\nlighting. Due to this character, motion data has low contextual richness and\nsemantic ambiguity between frames, which limits the accuracy of predictions\nmade by current video localization frameworks extended to TSLM to only a rough\nlevel. To refine this, we devise two novel label-prior-assisted training\nschemes: one embed prior knowledge of foreground and background to highlight\nthe localization chances of target moments, and the other forces the originally\nrough predictions to overlap with the more accurate predictions obtained from\nthe flipped start/end prior label sequences during recovery training. We show\nthat injecting label-prior knowledge into the model is crucial for improving\nperformance at high IoU. In our constructed TSLM benchmark, our model termed\nMLP achieves a recall of 44.13 at IoU@0.7 on the BABEL dataset and 71.17 on\nHumanML3D (Restore), outperforming prior works. Finally, we showcase the\npotential of our approach in corpus-level moment retrieval. Our source code is\nopenly accessible at https://github.com/eanson023/mlp.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.13657v1",
    "published_date": "2024-04-21 13:25:46 UTC",
    "updated_date": "2024-04-21 13:25:46 UTC"
  },
  {
    "arxiv_id": "2404.13655v2",
    "title": "SPGNN: Recognizing Salient Subgraph Patterns via Enhanced Graph Convolution and Pooling",
    "authors": [
      "Zehao Dong",
      "Muhan Zhang",
      "Yixin Chen"
    ],
    "abstract": "Graph neural networks (GNNs) have revolutionized the field of machine\nlearning on non-Euclidean data such as graphs and networks. GNNs effectively\nimplement node representation learning through neighborhood aggregation and\nachieve impressive results in many graph-related tasks. However, most\nneighborhood aggregation approaches are summation-based, which can be\nproblematic as they may not be sufficiently expressive to encode informative\ngraph structures. Furthermore, though the graph pooling module is also of vital\nimportance for graph learning, especially for the task of graph classification,\nresearch on graph down-sampling mechanisms is rather limited.\n  To address the above challenges, we propose a concatenation-based graph\nconvolution mechanism that injectively updates node representations to maximize\nthe discriminative power in distinguishing non-isomorphic subgraphs. In\naddition, we design a novel graph pooling module, called WL-SortPool, to learn\nimportant subgraph patterns in a deep-learning manner. WL-SortPool layer-wise\nsorts node representations (i.e. continuous WL colors) to separately learn the\nrelative importance of subtrees with different depths for the purpose of\nclassification, thus better characterizing the complex graph topology and rich\ninformation encoded in the graph. We propose a novel Subgraph Pattern GNN\n(SPGNN) architecture that incorporates these enhancements. We test the proposed\nSPGNN architecture on many graph classification benchmarks. Experimental\nresults show that our method can achieve highly competitive results with\nstate-of-the-art graph kernels and other GNN approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13655v2",
    "published_date": "2024-04-21 13:11:59 UTC",
    "updated_date": "2024-04-29 16:21:25 UTC"
  },
  {
    "arxiv_id": "2404.13652v1",
    "title": "BANSAI: Towards Bridging the AI Adoption Gap in Industrial Robotics with Neurosymbolic Programming",
    "authors": [
      "Benjamin Alt",
      "Julia Dvorak",
      "Darko Katic",
      "Rainer Jäkel",
      "Michael Beetz",
      "Gisela Lanza"
    ],
    "abstract": "Over the past decade, deep learning helped solve manipulation problems across\nall domains of robotics. At the same time, industrial robots continue to be\nprogrammed overwhelmingly using traditional program representations and\ninterfaces. This paper undertakes an analysis of this \"AI adoption gap\" from an\nindustry practitioner's perspective. In response, we propose the BANSAI\napproach (Bridging the AI Adoption Gap via Neurosymbolic AI). It systematically\nleverages principles of neurosymbolic AI to establish data-driven, subsymbolic\nprogram synthesis and optimization in modern industrial robot programming\nworkflow. BANSAI conceptually unites several lines of prior research and\nproposes a path toward practical, real-world validation.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "68T40",
      "I.2.1; I.2.9; I.2.2; J.6; J.7"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages, 3 figures, accepted at the 2024 CIRP International\n  Conference on Manufacturing Systems (CMS)",
    "pdf_url": "http://arxiv.org/pdf/2404.13652v1",
    "published_date": "2024-04-21 13:04:58 UTC",
    "updated_date": "2024-04-21 13:04:58 UTC"
  },
  {
    "arxiv_id": "2404.13634v3",
    "title": "Bt-GAN: Generating Fair Synthetic Healthdata via Bias-transforming Generative Adversarial Networks",
    "authors": [
      "Resmi Ramachandranpillai",
      "Md Fahim Sikder",
      "David Bergström",
      "Fredrik Heintz"
    ],
    "abstract": "Synthetic data generation offers a promising solution to enhance the\nusefulness of Electronic Healthcare Records (EHR) by generating realistic\nde-identified data. However, the existing literature primarily focuses on the\nquality of synthetic health data, neglecting the crucial aspect of fairness in\ndownstream predictions. Consequently, models trained on synthetic EHR have\nfaced criticism for producing biased outcomes in target tasks. These biases can\narise from either spurious correlations between features or the failure of\nmodels to accurately represent sub-groups. To address these concerns, we\npresent Bias-transforming Generative Adversarial Networks (Bt-GAN), a GAN-based\nsynthetic data generator specifically designed for the healthcare domain. In\norder to tackle spurious correlations (i), we propose an\ninformation-constrained Data Generation Process that enables the generator to\nlearn a fair deterministic transformation based on a well-defined notion of\nalgorithmic fairness. To overcome the challenge of capturing exact sub-group\nrepresentations (ii), we incentivize the generator to preserve sub-group\ndensities through score-based weighted sampling. This approach compels the\ngenerator to learn from underrepresented regions of the data manifold. We\nconduct extensive experiments using the MIMIC-III database. Our results\ndemonstrate that Bt-GAN achieves SOTA accuracy while significantly improving\nfairness and minimizing bias amplification. We also perform an in-depth\nexplainability analysis to provide additional evidence supporting the validity\nof our study. In conclusion, our research introduces a novel and professional\napproach to addressing the limitations of synthetic data generation in the\nhealthcare domain. By incorporating fairness considerations and leveraging\nadvanced techniques such as GANs, we pave the way for more reliable and\nunbiased predictions in healthcare applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13634v3",
    "published_date": "2024-04-21 12:16:38 UTC",
    "updated_date": "2024-04-26 05:02:53 UTC"
  },
  {
    "arxiv_id": "2404.13630v2",
    "title": "Utilizing Deep Learning to Optimize Software Development Processes",
    "authors": [
      "Keqin Li",
      "Armando Zhu",
      "Peng Zhao",
      "Jintong Song",
      "Jiabei Liu"
    ],
    "abstract": "This study explores the application of deep learning technologies in software\ndevelopment processes, particularly in automating code reviews, error\nprediction, and test generation to enhance code quality and development\nefficiency. Through a series of empirical studies, experimental groups using\ndeep learning tools and control groups using traditional methods were compared\nin terms of code error rates and project completion times. The results\ndemonstrated significant improvements in the experimental group, validating the\neffectiveness of deep learning technologies. The research also discusses\npotential optimization points, methodologies, and technical challenges of deep\nlearning in software development, as well as how to integrate these\ntechnologies into existing software development workflows.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13630v2",
    "published_date": "2024-04-21 12:06:05 UTC",
    "updated_date": "2024-05-03 13:07:18 UTC"
  },
  {
    "arxiv_id": "2404.13627v3",
    "title": "NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding",
    "authors": [
      "Chunkit Chan",
      "Cheng Jiayang",
      "Yauwai Yim",
      "Zheye Deng",
      "Wei Fan",
      "Haoran Li",
      "Xin Liu",
      "Hongming Zhang",
      "Weiqi Wang",
      "Yangqiu Song"
    ],
    "abstract": "Large Language Models (LLMs) have sparked substantial interest and debate\nconcerning their potential emergence of Theory of Mind (ToM) ability. Theory of\nmind evaluations currently focuses on testing models using machine-generated\ndata or game settings prone to shortcuts and spurious correlations, which lacks\nevaluation of machine ToM ability in real-world human interaction scenarios.\nThis poses a pressing demand to develop new real-world scenario benchmarks. We\nintroduce NegotiationToM, a new benchmark designed to stress-test machine ToM\nin real-world negotiation surrounding covered multi-dimensional mental states\n(i.e., desires, beliefs, and intentions). Our benchmark builds upon the\nBelief-Desire-Intention (BDI) agent modeling theory and conducts the necessary\nempirical experiments to evaluate large language models. Our findings\ndemonstrate that NegotiationToM is challenging for state-of-the-art LLMs, as\nthey consistently perform significantly worse than humans, even when employing\nthe chain-of-thought (CoT) method.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 findings. Dataset:\n  https://github.com/HKUST-KnowComp/NegotiationToM",
    "pdf_url": "http://arxiv.org/pdf/2404.13627v3",
    "published_date": "2024-04-21 11:51:13 UTC",
    "updated_date": "2024-10-05 16:58:41 UTC"
  },
  {
    "arxiv_id": "2404.13604v2",
    "title": "CKGConv: General Graph Convolution with Continuous Kernels",
    "authors": [
      "Liheng Ma",
      "Soumyasundar Pal",
      "Yitian Zhang",
      "Jiaming Zhou",
      "Yingxue Zhang",
      "Mark Coates"
    ],
    "abstract": "The existing definitions of graph convolution, either from spatial or\nspectral perspectives, are inflexible and not unified. Defining a general\nconvolution operator in the graph domain is challenging due to the lack of\ncanonical coordinates, the presence of irregular structures, and the properties\nof graph symmetries. In this work, we propose a novel and general graph\nconvolution framework by parameterizing the kernels as continuous functions of\npseudo-coordinates derived via graph positional encoding. We name this\nContinuous Kernel Graph Convolution (CKGConv). Theoretically, we demonstrate\nthat CKGConv is flexible and expressive. CKGConv encompasses many existing\ngraph convolutions, and exhibits a stronger expressiveness, as powerful as\ngraph transformers in terms of distinguishing non-isomorphic graphs.\nEmpirically, we show that CKGConv-based Networks outperform existing graph\nconvolutional networks and perform comparably to the best graph transformers\nacross a variety of graph datasets. The code and models are publicly available\nat https://github.com/networkslab/CKGConv.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "On International Conference on Machine Learning (ICML) 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.13604v2",
    "published_date": "2024-04-21 10:26:13 UTC",
    "updated_date": "2024-06-05 12:54:39 UTC"
  },
  {
    "arxiv_id": "2404.14455v1",
    "title": "A Neuro-Symbolic Explainer for Rare Events: A Case Study on Predictive Maintenance",
    "authors": [
      "João Gama",
      "Rita P. Ribeiro",
      "Saulo Mastelini",
      "Narjes Davarid",
      "Bruno Veloso"
    ],
    "abstract": "Predictive Maintenance applications are increasingly complex, with\ninteractions between many components. Black box models are popular approaches\nbased on deep learning techniques due to their predictive accuracy. This paper\nproposes a neural-symbolic architecture that uses an online rule-learning\nalgorithm to explain when the black box model predicts failures. The proposed\nsystem solves two problems in parallel: anomaly detection and explanation of\nthe anomaly. For the first problem, we use an unsupervised state of the art\nautoencoder. For the second problem, we train a rule learning system that\nlearns a mapping from the input features to the autoencoder reconstruction\nerror. Both systems run online and in parallel. The autoencoder signals an\nalarm for the examples with a reconstruction error that exceeds a threshold.\nThe causes of the signal alarm are hard for humans to understand because they\nresult from a non linear combination of sensor data. The rule that triggers\nthat example describes the relationship between the input features and the\nautoencoder reconstruction error. The rule explains the failure signal by\nindicating which sensors contribute to the alarm and allowing the\nidentification of the component involved in the failure. The system can present\nglobal explanations for the black box model and local explanations for why the\nblack box model predicts a failure. We evaluate the proposed system in a\nreal-world case study of Metro do Porto and provide explanations that\nillustrate its benefits.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.14455v1",
    "published_date": "2024-04-21 09:48:09 UTC",
    "updated_date": "2024-04-21 09:48:09 UTC"
  },
  {
    "arxiv_id": "2404.13594v1",
    "title": "Lost in Space: Probing Fine-grained Spatial Understanding in Vision and Language Resamplers",
    "authors": [
      "Georgios Pantazopoulos",
      "Alessandro Suglia",
      "Oliver Lemon",
      "Arash Eshghi"
    ],
    "abstract": "An effective method for combining frozen large language models (LLM) and\nvisual encoders involves a resampler module that creates a `visual prompt'\nwhich is provided to the LLM, along with the textual prompt. While this\napproach has enabled impressive performance across many coarse-grained tasks\nlike image captioning and visual question answering, more fine-grained tasks\nthat require spatial understanding have not been thoroughly examined. In this\npaper, we use \\textit{diagnostic classifiers} to measure the extent to which\nthe visual prompt produced by the resampler encodes spatial information. Our\nresults show that this information is largely absent from the resampler output\nwhen kept frozen during training of the classifiers. However, when the\nresampler and classifier are trained jointly, we observe a significant\nperformance boost. This shows that the compression achieved by the resamplers\ncan in principle encode the requisite spatial information, but that more\nobject-aware objectives are needed at the pretraining stage to facilitate this\ncapability",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.13594v1",
    "published_date": "2024-04-21 09:23:36 UTC",
    "updated_date": "2024-04-21 09:23:36 UTC"
  },
  {
    "arxiv_id": "2404.14454v2",
    "title": "Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses",
    "authors": [
      "Yousef Khan",
      "Ahmed Abdeen Hamed"
    ],
    "abstract": "Addressing the global challenge of breast cancer, this research explores the\nfusion of generative AI, focusing on ChatGPT 3.5 turbo model, and the\nintricacies of breast cancer risk assessment. The research aims to evaluate\nChatGPT's reasoning capabilities, emphasizing its potential to process rules\nand provide explanations for screening recommendations. The study seeks to\nbridge the technology gap between intelligent machines and clinicians by\ndemonstrating ChatGPT's unique proficiency in natural language reasoning. The\nmethodology employs a supervised prompt-engineering approach to enforce\ndetailed explanations for ChatGPT's recommendations. Synthetic use cases,\ngenerated algorithmically, serve as the testing ground for the encoded rules,\nevaluating the model's processing prowess. Findings highlight ChatGPT's\npromising capacity in processing rules comparable to Expert System Shells, with\na focus on natural language reasoning. The research introduces the concept of\nreinforcement explainability, showcasing its potential in elucidating outcomes\nand facilitating user-friendly interfaces for breast cancer risk assessment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2; I.2.1"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 5 figures, 3 algorithms, 1 table, submitted to the IEEE\n  MedAI'24 Conference",
    "pdf_url": "http://arxiv.org/pdf/2404.14454v2",
    "published_date": "2024-04-21 09:20:16 UTC",
    "updated_date": "2024-06-02 22:42:00 UTC"
  },
  {
    "arxiv_id": "2404.13588v1",
    "title": "Machine Unlearning via Null Space Calibration",
    "authors": [
      "Huiqiang Chen",
      "Tianqing Zhu",
      "Xin Yu",
      "Wanlei Zhou"
    ],
    "abstract": "Machine unlearning aims to enable models to forget specific data instances\nwhen receiving deletion requests. Current research centres on efficient\nunlearning to erase the influence of data from the model and neglects the\nsubsequent impacts on the remaining data. Consequently, existing unlearning\nalgorithms degrade the model's performance after unlearning, known as\n\\textit{over-unlearning}. This paper addresses this critical yet under-explored\nissue by introducing machine \\underline{U}nlearning via \\underline{N}ull\n\\underline{S}pace \\underline{C}alibration (UNSC), which can accurately unlearn\ntarget samples without over-unlearning. On the contrary, by calibrating the\ndecision space during unlearning, UNSC can significantly improve the model's\nperformance on the remaining samples. In particular, our approach hinges on\nconfining the unlearning process to a specified null space tailored to the\nremaining samples, which is augmented by strategically pseudo-labeling the\nunlearning samples. Comparative analyses against several established baselines\naffirm the superiority of our approach. Code is released at this\n\\href{https://github.com/HQC-ML/Machine-Unlearning-via-Null-Space-Calibration}{URL}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IJCAI-2024",
    "pdf_url": "http://arxiv.org/pdf/2404.13588v1",
    "published_date": "2024-04-21 09:09:21 UTC",
    "updated_date": "2024-04-21 09:09:21 UTC"
  },
  {
    "arxiv_id": "2404.13579v4",
    "title": "LTOS: Layout-controllable Text-Object Synthesis via Adaptive Cross-attention Fusions",
    "authors": [
      "Xiaoran Zhao",
      "Tianhao Wu",
      "Yu Lai",
      "Zhiliang Tian",
      "Zhen Huang",
      "Yahui Liu",
      "Zejiang He",
      "Dongsheng Li"
    ],
    "abstract": "Controllable text-to-image generation synthesizes visual text and objects in\nimages with certain conditions, which are frequently applied to emoji and\nposter generation. Visual text rendering and layout-to-image generation tasks\nhave been popular in controllable text-to-image generation. However, each of\nthese tasks typically focuses on single modality generation or rendering,\nleaving yet-to-be-bridged gaps between the approaches correspondingly designed\nfor each of the tasks. In this paper, we combine text rendering and\nlayout-to-image generation tasks into a single task: layout-controllable\ntext-object synthesis (LTOS) task, aiming at synthesizing images with object\nand visual text based on predefined object layout and text contents. As\ncompliant datasets are not readily available for our LTOS task, we construct a\nlayout-aware text-object synthesis dataset, containing elaborate well-aligned\nlabels of visual text and object information. Based on the dataset, we propose\na layout-controllable text-object adaptive fusion (TOF) framework, which\ngenerates images with clear, legible visual text and plausible objects. We\nconstruct a visual-text rendering module to synthesize text and employ an\nobject-layout control module to generate objects while integrating the two\nmodules to harmoniously generate and integrate text content and objects in\nimages. To better the image-text integration, we propose a self-adaptive\ncross-attention fusion module that helps the image generation to attend more to\nimportant text information. Within such a fusion module, we use a self-adaptive\nlearnable factor to learn to flexibly control the influence of cross-attention\noutputs on image generation. Experimental results show that our method\noutperforms the state-of-the-art in LTOS, text rendering, and layout-to-image\ntasks, enabling harmonious visual text rendering and object generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13579v4",
    "published_date": "2024-04-21 08:37:43 UTC",
    "updated_date": "2024-11-26 14:58:31 UTC"
  },
  {
    "arxiv_id": "2404.13575v1",
    "title": "FedMPQ: Secure and Communication-Efficient Federated Learning with Multi-codebook Product Quantization",
    "authors": [
      "Xu Yang",
      "Jiapeng Zhang",
      "Qifeng Zhang",
      "Zhuo Tang"
    ],
    "abstract": "In federated learning, particularly in cross-device scenarios, secure\naggregation has recently gained popularity as it effectively defends against\ninference attacks by malicious aggregators. However, secure aggregation often\nrequires additional communication overhead and can impede the convergence rate\nof the global model, which is particularly challenging in wireless network\nenvironments with extremely limited bandwidth. Therefore, achieving efficient\ncommunication compression under the premise of secure aggregation presents a\nhighly challenging and valuable problem. In this work, we propose a novel\nuplink communication compression method for federated learning, named FedMPQ,\nwhich is based on multi shared codebook product quantization.Specifically, we\nutilize updates from the previous round to generate sufficiently robust\ncodebooks. Secure aggregation is then achieved through trusted execution\nenvironments (TEE) or a trusted third party (TTP).In contrast to previous\nworks, our approach exhibits greater robustness in scenarios where data is not\nindependently and identically distributed (non-IID) and there is a lack of\nsufficient public data. The experiments conducted on the LEAF dataset\ndemonstrate that our proposed method achieves 99% of the baseline's final\naccuracy, while reducing uplink communications by 90-95%",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13575v1",
    "published_date": "2024-04-21 08:27:36 UTC",
    "updated_date": "2024-04-21 08:27:36 UTC"
  },
  {
    "arxiv_id": "2404.13571v1",
    "title": "Test-Time Training on Graphs with Large Language Models (LLMs)",
    "authors": [
      "Jiaxin Zhang",
      "Yiqi Wang",
      "Xihong Yang",
      "Siwei Wang",
      "Yu Feng",
      "Yu Shi",
      "Ruicaho Ren",
      "En Zhu",
      "Xinwang Liu"
    ],
    "abstract": "Graph Neural Networks have demonstrated great success in various fields of\nmultimedia. However, the distribution shift between the training and test data\nchallenges the effectiveness of GNNs. To mitigate this challenge, Test-Time\nTraining (TTT) has been proposed as a promising approach. Traditional TTT\nmethods require a demanding unsupervised training strategy to capture the\ninformation from test to benefit the main task. Inspired by the great\nannotation ability of Large Language Models (LLMs) on Text-Attributed Graphs\n(TAGs), we propose to enhance the test-time training on graphs with LLMs as\nannotators. In this paper, we design a novel Test-Time Training pipeline,\nLLMTTT, which conducts the test-time adaptation under the annotations by LLMs\non a carefully-selected node set. Specifically, LLMTTT introduces a hybrid\nactive node selection strategy that considers not only node diversity and\nrepresentativeness, but also prediction signals from the pre-trained model.\nGiven annotations from LLMs, a two-stage training strategy is designed to\ntailor the test-time model with the limited and noisy labels. A theoretical\nanalysis ensures the validity of our method and extensive experiments\ndemonstrate that the proposed LLMTTT can achieve a significant performance\nimprovement compared to existing Out-of-Distribution (OOD) generalization\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13571v1",
    "published_date": "2024-04-21 08:20:02 UTC",
    "updated_date": "2024-04-21 08:20:02 UTC"
  },
  {
    "arxiv_id": "2404.15190v2",
    "title": "Socratic Planner: Self-QA-Based Zero-Shot Planning for Embodied Instruction Following",
    "authors": [
      "Suyeon Shin",
      "Sujin jeon",
      "Junghyun Kim",
      "Gi-Cheon Kang",
      "Byoung-Tak Zhang"
    ],
    "abstract": "Embodied Instruction Following (EIF) is the task of executing natural\nlanguage instructions by navigating and interacting with objects in interactive\nenvironments. A key challenge in EIF is compositional task planning, typically\naddressed through supervised learning or few-shot in-context learning with\nlabeled data. To this end, we introduce the Socratic Planner, a self-QA-based\nzero-shot planning method that infers an appropriate plan without any further\ntraining. The Socratic Planner first facilitates self-questioning and answering\nby the Large Language Model (LLM), which in turn helps generate a sequence of\nsubgoals. While executing the subgoals, an embodied agent may encounter\nunexpected situations, such as unforeseen obstacles. The Socratic Planner then\nadjusts plans based on dense visual feedback through a visually-grounded\nre-planning mechanism. Experiments demonstrate the effectiveness of the\nSocratic Planner, outperforming current state-of-the-art planning models on the\nALFRED benchmark across all metrics, particularly excelling in long-horizon\ntasks that demand complex inference. We further demonstrate its real-world\napplicability through deployment on a physical robot for long-horizon tasks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.RO",
      "68T01 (Primary) 68T40, 68T50, 68T45 (Secondary)"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 6 figures, published to ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2404.15190v2",
    "published_date": "2024-04-21 08:10:20 UTC",
    "updated_date": "2025-03-26 07:42:56 UTC"
  },
  {
    "arxiv_id": "2404.13567v1",
    "title": "On the Value of Labeled Data and Symbolic Methods for Hidden Neuron Activation Analysis",
    "authors": [
      "Abhilekha Dalal",
      "Rushrukh Rayan",
      "Adrita Barua",
      "Eugene Y. Vasserman",
      "Md Kamruzzaman Sarker",
      "Pascal Hitzler"
    ],
    "abstract": "A major challenge in Explainable AI is in correctly interpreting activations\nof hidden neurons: accurate interpretations would help answer the question of\nwhat a deep learning system internally detects as relevant in the input,\ndemystifying the otherwise black-box nature of deep learning systems. The state\nof the art indicates that hidden node activations can, in some cases, be\ninterpretable in a way that makes sense to humans, but systematic automated\nmethods that would be able to hypothesize and verify interpretations of hidden\nneuron activations are underexplored. This is particularly the case for\napproaches that can both draw explanations from substantial background\nknowledge, and that are based on inherently explainable (symbolic) methods.\n  In this paper, we introduce a novel model-agnostic post-hoc Explainable AI\nmethod demonstrating that it provides meaningful interpretations. Our approach\nis based on using a Wikipedia-derived concept hierarchy with approximately 2\nmillion classes as background knowledge, and utilizes OWL-reasoning-based\nConcept Induction for explanation generation. Additionally, we explore and\ncompare the capabilities of off-the-shelf pre-trained multimodal-based\nexplainable methods.\n  Our results indicate that our approach can automatically attach meaningful\nclass expressions as explanations to individual neurons in the dense layer of a\nConvolutional Neural Network. Evaluation through statistical analysis and\ndegree of concept activation in the hidden layer show that our method provides\na competitive edge in both quantitative and qualitative aspects compared to\nprior work.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13567v1",
    "published_date": "2024-04-21 07:57:45 UTC",
    "updated_date": "2024-04-21 07:57:45 UTC"
  },
  {
    "arxiv_id": "2404.15373v1",
    "title": "Robust EEG-based Emotion Recognition Using an Inception and Two-sided Perturbation Model",
    "authors": [
      "Shadi Sartipi",
      "Mujdat Cetin"
    ],
    "abstract": "Automated emotion recognition using electroencephalogram (EEG) signals has\ngained substantial attention. Although deep learning approaches exhibit strong\nperformance, they often suffer from vulnerabilities to various perturbations,\nlike environmental noise and adversarial attacks. In this paper, we propose an\nInception feature generator and two-sided perturbation (INC-TSP) approach to\nenhance emotion recognition in brain-computer interfaces. INC-TSP integrates\nthe Inception module for EEG data analysis and employs two-sided perturbation\n(TSP) as a defensive mechanism against input perturbations. TSP introduces\nworst-case perturbations to the model's weights and inputs, reinforcing the\nmodel's elasticity against adversarial attacks. The proposed approach addresses\nthe challenge of maintaining accurate emotion recognition in the presence of\ninput uncertainties. We validate INC-TSP in a subject-independent three-class\nemotion recognition scenario, demonstrating robust performance.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15373v1",
    "published_date": "2024-04-21 07:54:43 UTC",
    "updated_date": "2024-04-21 07:54:43 UTC"
  },
  {
    "arxiv_id": "2404.13565v3",
    "title": "Exploring Diverse Methods in Visual Question Answering",
    "authors": [
      "Panfeng Li",
      "Qikai Yang",
      "Xieming Geng",
      "Wenjing Zhou",
      "Zhicheng Ding",
      "Yi Nian"
    ],
    "abstract": "This study explores innovative methods for improving Visual Question\nAnswering (VQA) using Generative Adversarial Networks (GANs), autoencoders, and\nattention mechanisms. Leveraging a balanced VQA dataset, we investigate three\ndistinct strategies. Firstly, GAN-based approaches aim to generate answer\nembeddings conditioned on image and question inputs, showing potential but\nstruggling with more complex tasks. Secondly, autoencoder-based techniques\nfocus on learning optimal embeddings for questions and images, achieving\ncomparable results with GAN due to better ability on complex questions. Lastly,\nattention mechanisms, incorporating Multimodal Compact Bilinear pooling (MCB),\naddress language priors and attention modeling, albeit with a\ncomplexity-performance trade-off. This study underscores the challenges and\nopportunities in VQA and suggests avenues for future research, including\nalternative GAN formulations and attentional mechanisms.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by 2024 5th International Conference on Electronic\n  Communication and Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2404.13565v3",
    "published_date": "2024-04-21 07:34:44 UTC",
    "updated_date": "2024-11-12 07:21:04 UTC"
  },
  {
    "arxiv_id": "2404.13564v1",
    "title": "Masked Latent Transformer with the Random Masking Ratio to Advance the Diagnosis of Dental Fluorosis",
    "authors": [
      "Yun Wu",
      "Hao Xu",
      "Maohua Gu",
      "Zhongchuan Jiang",
      "Jun Xu",
      "Youliang Tian"
    ],
    "abstract": "Dental fluorosis is a chronic disease caused by long-term overconsumption of\nfluoride, which leads to changes in the appearance of tooth enamel. It is an\nimportant basis for early non-invasive diagnosis of endemic fluorosis. However,\neven dental professionals may not be able to accurately distinguish dental\nfluorosis and its severity based on tooth images. Currently, there is still a\ngap in research on applying deep learning to diagnosing dental fluorosis.\nTherefore, we construct the first open-source dental fluorosis image dataset\n(DFID), laying the foundation for deep learning research in this field. To\nadvance the diagnosis of dental fluorosis, we propose a pioneering deep\nlearning model called masked latent transformer with the random masking ratio\n(MLTrMR). MLTrMR introduces a mask latent modeling scheme based on Vision\nTransformer to enhance contextual learning of dental fluorosis lesion\ncharacteristics. Consisting of a latent embedder, encoder, and decoder, MLTrMR\nemploys the latent embedder to extract latent tokens from the original image,\nwhereas the encoder and decoder comprising the latent transformer (LT) block\nare used to process unmasked tokens and predict masked tokens, respectively. To\nmitigate the lack of inductive bias in Vision Transformer, which may result in\nperformance degradation, the LT block introduces latent tokens to enhance the\nlearning capacity of latent lesion features. Furthermore, we design an\nauxiliary loss function to constrain the parameter update direction of the\nmodel. MLTrMR achieves 80.19% accuracy, 75.79% F1, and 81.28% quadratic\nweighted kappa on DFID, making it state-of-the-art (SOTA).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13564v1",
    "published_date": "2024-04-21 07:26:09 UTC",
    "updated_date": "2024-04-21 07:26:09 UTC"
  },
  {
    "arxiv_id": "2404.13555v1",
    "title": "Cell Phone Image-Based Persian Rice Detection and Classification Using Deep Learning Techniques",
    "authors": [
      "Mahmood Saeedi kelishami",
      "Amin Saeidi Kelishami",
      "Sajjad Saeedi Kelishami"
    ],
    "abstract": "This study introduces an innovative approach to classifying various types of\nPersian rice using image-based deep learning techniques, highlighting the\npractical application of everyday technology in food categorization.\nRecognizing the diversity of Persian rice and its culinary significance, we\nleveraged the capabilities of convolutional neural networks (CNNs),\nspecifically by fine-tuning a ResNet model for accurate identification of\ndifferent rice varieties and employing a U-Net architecture for precise\nsegmentation of rice grains in bulk images. This dual-methodology framework\nallows for both individual grain classification and comprehensive analysis of\nbulk rice samples, addressing two crucial aspects of rice quality assessment.\nUtilizing images captured with consumer-grade cell phones reflects a realistic\nscenario in which individuals can leverage this technology for assistance with\ngrocery shopping and meal preparation. The dataset, comprising various rice\ntypes photographed under natural conditions without professional lighting or\nequipment, presents a challenging yet practical classification problem. Our\nfindings demonstrate the feasibility of using non-professional images for food\nclassification and the potential of deep learning models, like ResNet and\nU-Net, to adapt to the nuances of everyday objects and textures. This study\ncontributes to the field by providing insights into the applicability of\nimage-based deep learning in daily life, specifically for enhancing consumer\nexperiences and knowledge in food selection. Furthermore, it opens avenues for\nextending this approach to other food categories and practical applications,\nemphasizing the role of accessible technology in bridging the gap between\nsophisticated computational methods and everyday tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.10, I.4.6"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.13555v1",
    "published_date": "2024-04-21 07:03:48 UTC",
    "updated_date": "2024-04-21 07:03:48 UTC"
  },
  {
    "arxiv_id": "2404.13528v1",
    "title": "SmartMem: Layout Transformation Elimination and Adaptation for Efficient DNN Execution on Mobile",
    "authors": [
      "Wei Niu",
      "Md Musfiqur Rahman Sanim",
      "Zhihao Shu",
      "Jiexiong Guan",
      "Xipeng Shen",
      "Miao Yin",
      "Gagan Agrawal",
      "Bin Ren"
    ],
    "abstract": "This work is motivated by recent developments in Deep Neural Networks,\nparticularly the Transformer architectures underlying applications such as\nChatGPT, and the need for performing inference on mobile devices. Focusing on\nemerging transformers (specifically the ones with computationally efficient\nSwin-like architectures) and large models (e.g., Stable Diffusion and LLMs)\nbased on transformers, we observe that layout transformations between the\ncomputational operators cause a significant slowdown in these applications.\nThis paper presents SmartMem, a comprehensive framework for eliminating most\nlayout transformations, with the idea that multiple operators can use the same\ntensor layout through careful choice of layout and implementation of\noperations. Our approach is based on classifying the operators into four\ngroups, and considering combinations of producer-consumer edges between the\noperators. We develop a set of methods for searching such layouts. Another\ncomponent of our work is developing efficient memory layouts for 2.5\ndimensional memory commonly seen in mobile devices. Our experimental results\nshow that SmartMem outperforms 5 state-of-the-art DNN execution frameworks on\nmobile devices across 18 varied neural networks, including CNNs, Transformers\nwith both local and global attention, as well as LLMs. In particular, compared\nto DNNFusion, SmartMem achieves an average speedup of 2.8$\\times$, and\noutperforms TVM and MNN with speedups of 6.9$\\times$ and 7.9$\\times$,\nrespectively, on average.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13528v1",
    "published_date": "2024-04-21 04:47:26 UTC",
    "updated_date": "2024-04-21 04:47:26 UTC"
  },
  {
    "arxiv_id": "2406.07558v2",
    "title": "An AI-Enabled Framework Within Reach for Enhancing Healthcare Sustainability and Fairness",
    "authors": [
      "Bin Huang",
      "Changchen Zhao",
      "Zimeng Liu",
      "Shenda Hong",
      "Baochang Zhang",
      "Hao Lu",
      "Zhijun Liu",
      "Wenjin Wang",
      "Hui Liu"
    ],
    "abstract": "Good health and well-being is among key issues in the United Nations 2030\nSustainable Development Goals. The rising prevalence of large-scale infectious\ndiseases and the accelerated aging of the global population are driving the\ntransformation of healthcare technologies. In this context, establishing\nlarge-scale public health datasets, developing medical models, and creating\ndecision-making systems with a human-centric approach are of strategic\nsignificance. Recently, by leveraging the extraordinary number of accessible\ncameras, groundbreaking advancements have emerged in AI methods for\nphysiological signal monitoring and disease diagnosis using camera sensors.\nThese approaches, requiring no specialized medical equipment, offer convenient\nmanners of collecting large-scale medical data in response to public health\nevents. Therefore, we outline a prospective framework and heuristic vision for\na camera-based public health (CBPH) framework utilizing visual physiological\nmonitoring technology. The CBPH can be considered as a convenient and universal\nframework for public health, advancing the United Nations Sustainable\nDevelopment Goals, particularly in promoting the universality, sustainability,\nand equity of healthcare in low- and middle-income countries or regions.\nFurthermore, CBPH provides a comprehensive solution for building a large-scale\nand human-centric medical database, and a multi-task large medical model for\npublic health and medical scientific discoveries. It has a significant\npotential to revolutionize personal monitoring technologies, digital medicine,\ntelemedicine, and primary health care in public health. Therefore, it can be\ndeemed that the outcomes of this paper will contribute to the establishment of\na sustainable and fair framework for public health, which serves as a crucial\nbridge for advancing scientific discoveries in the realm of AI for medicine\n(AI4Medicine).",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CY",
    "comment": "16 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.07558v2",
    "published_date": "2024-04-21 04:37:24 UTC",
    "updated_date": "2024-08-01 09:57:28 UTC"
  },
  {
    "arxiv_id": "2404.13522v2",
    "title": "Error Analysis of Shapley Value-Based Model Explanations: An Informative Perspective",
    "authors": [
      "Ningsheng Zhao",
      "Jia Yuan Yu",
      "Krzysztof Dzieciolowski",
      "Trang Bui"
    ],
    "abstract": "Shapley value attribution (SVA) is an increasingly popular explainable AI\n(XAI) method, which quantifies the contribution of each feature to the model's\noutput. However, recent work has shown that most existing methods to implement\nSVAs have some drawbacks, resulting in biased or unreliable explanations that\nfail to correctly capture the true intrinsic relationships between features and\nmodel outputs. Moreover, the mechanism and consequences of these drawbacks have\nnot been discussed systematically. In this paper, we propose a novel error\ntheoretical analysis framework, in which the explanation errors of SVAs are\ndecomposed into two components: observation bias and structural bias. We\nfurther clarify the underlying causes of these two biases and demonstrate that\nthere is a trade-off between them. Based on this error analysis framework, we\ndevelop two novel concepts: over-informative and underinformative explanations.\nWe demonstrate how these concepts can be effectively used to understand\npotential errors of existing SVA methods. In particular, for the widely\ndeployed assumption-based SVAs, we find that they can easily be\nunder-informative due to the distribution drift caused by distributional\nassumptions. We propose a measurement tool to quantify such a distribution\ndrift. Finally, our experiments illustrate how different existing SVA methods\ncan be over- or under-informative. Our work sheds light on how errors incur in\nthe estimation of SVAs and encourages new less error-prone methods.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13522v2",
    "published_date": "2024-04-21 04:07:52 UTC",
    "updated_date": "2024-05-30 01:56:53 UTC"
  },
  {
    "arxiv_id": "2404.13521v1",
    "title": "Graph4GUI: Graph Neural Networks for Representing Graphical User Interfaces",
    "authors": [
      "Yue Jiang",
      "Changkong Zhou",
      "Vikas Garg",
      "Antti Oulasvirta"
    ],
    "abstract": "Present-day graphical user interfaces (GUIs) exhibit diverse arrangements of\ntext, graphics, and interactive elements such as buttons and menus, but\nrepresentations of GUIs have not kept up. They do not encapsulate both semantic\nand visuo-spatial relationships among elements. To seize machine learning's\npotential for GUIs more efficiently, Graph4GUI exploits graph neural networks\nto capture individual elements' properties and their semantic-visuo-spatial\nconstraints in a layout. The learned representation demonstrated its\neffectiveness in multiple tasks, especially generating designs in a challenging\nGUI autocompletion task, which involved predicting the positions of remaining\nunplaced elements in a partially completed GUI. The new model's suggestions\nshowed alignment and visual appeal superior to the baseline method and received\nhigher subjective ratings for preference. Furthermore, we demonstrate the\npractical benefits and efficiency advantages designers perceive when utilizing\nour model as an autocompletion plug-in.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.13521v1",
    "published_date": "2024-04-21 04:06:09 UTC",
    "updated_date": "2024-04-21 04:06:09 UTC"
  },
  {
    "arxiv_id": "2404.14453v1",
    "title": "EPI-SQL: Enhancing Text-to-SQL Translation with Error-Prevention Instructions",
    "authors": [
      "Xiping Liu",
      "Zhao Tan"
    ],
    "abstract": "The conversion of natural language queries into SQL queries, known as\nText-to-SQL, is a critical yet challenging task. This paper introduces EPI-SQL,\na novel methodological framework leveraging Large Language Models (LLMs) to\nenhance the performance of Text-to-SQL tasks. EPI-SQL operates through a\nfour-step process. Initially, the method involves gathering instances from the\nSpider dataset on which LLMs are prone to failure. These instances are then\nutilized to generate general error-prevention instructions (EPIs).\nSubsequently, LLMs craft contextualized EPIs tailored to the specific context\nof the current task. Finally, these context-specific EPIs are incorporated into\nthe prompt used for SQL generation. EPI-SQL is distinguished in that it\nprovides task-specific guidance, enabling the model to circumvent potential\nerrors for the task at hand. Notably, the methodology rivals the performance of\nadvanced few-shot methods despite being a zero-shot approach. An empirical\nassessment using the Spider benchmark reveals that EPI-SQL achieves an\nexecution accuracy of 85.1\\%, underscoring its effectiveness in generating\naccurate SQL queries through LLMs. The findings indicate a promising direction\nfor future research, i.e. enhancing instructions with task-specific and\ncontextualized rules, for boosting LLMs' performance in NLP tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14453v1",
    "published_date": "2024-04-21 03:52:46 UTC",
    "updated_date": "2024-04-21 03:52:46 UTC"
  },
  {
    "arxiv_id": "2404.13518v1",
    "title": "Reliable Model Watermarking: Defending Against Theft without Compromising on Evasion",
    "authors": [
      "Hongyu Zhu",
      "Sichu Liang",
      "Wentao Hu",
      "Fangqi Li",
      "Ju Jia",
      "Shilin Wang"
    ],
    "abstract": "With the rise of Machine Learning as a Service (MLaaS) platforms,safeguarding\nthe intellectual property of deep learning models is becoming paramount. Among\nvarious protective measures, trigger set watermarking has emerged as a flexible\nand effective strategy for preventing unauthorized model distribution. However,\nthis paper identifies an inherent flaw in the current paradigm of trigger set\nwatermarking: evasion adversaries can readily exploit the shortcuts created by\nmodels memorizing watermark samples that deviate from the main task\ndistribution, significantly impairing their generalization in adversarial\nsettings. To counteract this, we leverage diffusion models to synthesize\nunrestricted adversarial examples as trigger sets. By learning the model to\naccurately recognize them, unique watermark behaviors are promoted through\nknowledge injection rather than error memorization, thus avoiding exploitable\nshortcuts. Furthermore, we uncover that the resistance of current trigger set\nwatermarking against removal attacks primarily relies on significantly damaging\nthe decision boundaries during embedding, intertwining unremovability with\nadverse impacts. By optimizing the knowledge transfer properties of protected\nmodels, our approach conveys watermark behaviors to extraction surrogates\nwithout aggressively decision boundary perturbation. Experimental results on\nCIFAR-10/100 and Imagenette datasets demonstrate the effectiveness of our\nmethod, showing not only improved robustness against evasion adversaries but\nalso superior resistance to watermark removal attacks compared to\nstate-of-the-art solutions.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13518v1",
    "published_date": "2024-04-21 03:38:20 UTC",
    "updated_date": "2024-04-21 03:38:20 UTC"
  },
  {
    "arxiv_id": "2404.13515v2",
    "title": "FedTrans: Efficient Federated Learning via Multi-Model Transformation",
    "authors": [
      "Yuxuan Zhu",
      "Jiachen Liu",
      "Mosharaf Chowdhury",
      "Fan Lai"
    ],
    "abstract": "Federated learning (FL) aims to train machine learning (ML) models across\npotentially millions of edge client devices. Yet, training and customizing\nmodels for FL clients is notoriously challenging due to the heterogeneity of\nclient data, device capabilities, and the massive scale of clients, making\nindividualized model exploration prohibitively expensive. State-of-the-art FL\nsolutions personalize a globally trained model or concurrently train multiple\nmodels, but they often incur suboptimal model accuracy and huge training costs.\n  In this paper, we introduce FedTrans, a multi-model FL training framework\nthat automatically produces and trains high-accuracy, hardware-compatible\nmodels for individual clients at scale. FedTrans begins with a basic global\nmodel, identifies accuracy bottlenecks in model architectures during training,\nand then employs model transformation to derive new models for heterogeneous\nclients on the fly. It judiciously assigns models to individual clients while\nperforming soft aggregation on multi-model updates to minimize total training\ncosts. Our evaluations using realistic settings show that FedTrans improves\nindividual client model accuracy by 14% - 72% while slashing training costs by\n1.6X - 20X over state-of-the-art solutions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13515v2",
    "published_date": "2024-04-21 03:31:01 UTC",
    "updated_date": "2024-04-25 20:34:32 UTC"
  },
  {
    "arxiv_id": "2404.13509v1",
    "title": "MFHCA: Enhancing Speech Emotion Recognition Via Multi-Spatial Fusion and Hierarchical Cooperative Attention",
    "authors": [
      "Xinxin Jiao",
      "Liejun Wang",
      "Yinfeng Yu"
    ],
    "abstract": "Speech emotion recognition is crucial in human-computer interaction, but\nextracting and using emotional cues from audio poses challenges. This paper\nintroduces MFHCA, a novel method for Speech Emotion Recognition using\nMulti-Spatial Fusion and Hierarchical Cooperative Attention on spectrograms and\nraw audio. We employ the Multi-Spatial Fusion module (MF) to efficiently\nidentify emotion-related spectrogram regions and integrate Hubert features for\nhigher-level acoustic information. Our approach also includes a Hierarchical\nCooperative Attention module (HCA) to merge features from various auditory\nlevels. We evaluate our method on the IEMOCAP dataset and achieve 2.6\\% and\n1.87\\% improvements on the weighted accuracy and unweighted accuracy,\nrespectively. Extensive experiments demonstrate the effectiveness of the\nproposed method.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Main paper (5 pages). Accepted for publication by ICME 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.13509v1",
    "published_date": "2024-04-21 02:44:17 UTC",
    "updated_date": "2024-04-21 02:44:17 UTC"
  },
  {
    "arxiv_id": "2404.13506v2",
    "title": "Parameter Efficient Fine Tuning: A Comprehensive Analysis Across Applications",
    "authors": [
      "Charith Chandra Sai Balne",
      "Sreyoshi Bhaduri",
      "Tamoghna Roy",
      "Vinija Jain",
      "Aman Chadha"
    ],
    "abstract": "The rise of deep learning has marked significant progress in fields such as\ncomputer vision, natural language processing, and medical imaging, primarily\nthrough the adaptation of pre-trained models for specific tasks. Traditional\nfine-tuning methods, involving adjustments to all parameters, face challenges\ndue to high computational and memory demands. This has led to the development\nof Parameter Efficient Fine-Tuning (PEFT) techniques, which selectively update\nparameters to balance computational efficiency with performance. This review\nexamines PEFT approaches, offering a detailed comparison of various strategies\nhighlighting applications across different domains, including text generation,\nmedical imaging, protein modeling, and speech synthesis. By assessing the\neffectiveness of PEFT methods in reducing computational load, speeding up\ntraining, and lowering memory usage, this paper contributes to making deep\nlearning more accessible and adaptable, facilitating its wider application and\nencouraging innovation in model optimization. Ultimately, the paper aims to\ncontribute towards insights into PEFT's evolving landscape, guiding researchers\nand practitioners in overcoming the limitations of conventional fine-tuning\napproaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13506v2",
    "published_date": "2024-04-21 02:26:15 UTC",
    "updated_date": "2024-04-23 21:28:26 UTC"
  },
  {
    "arxiv_id": "2404.13501v1",
    "title": "A Survey on the Memory Mechanism of Large Language Model based Agents",
    "authors": [
      "Zeyu Zhang",
      "Xiaohe Bo",
      "Chen Ma",
      "Rui Li",
      "Xu Chen",
      "Quanyu Dai",
      "Jieming Zhu",
      "Zhenhua Dong",
      "Ji-Rong Wen"
    ],
    "abstract": "Large language model (LLM) based agents have recently attracted much\nattention from the research and industry communities. Compared with original\nLLMs, LLM-based agents are featured in their self-evolving capability, which is\nthe basis for solving real-world problems that need long-term and complex\nagent-environment interactions. The key component to support agent-environment\ninteractions is the memory of the agents. While previous studies have proposed\nmany promising memory mechanisms, they are scattered in different papers, and\nthere lacks a systematical review to summarize and compare these works from a\nholistic perspective, failing to abstract common and effective designing\npatterns for inspiring future studies. To bridge this gap, in this paper, we\npropose a comprehensive survey on the memory mechanism of LLM-based agents. In\nspecific, we first discuss ''what is'' and ''why do we need'' the memory in\nLLM-based agents. Then, we systematically review previous studies on how to\ndesign and evaluate the memory module. In addition, we also present many agent\napplications, where the memory module plays an important role. At last, we\nanalyze the limitations of existing work and show important future directions.\nTo keep up with the latest advances in this field, we create a repository at\n\\url{https://github.com/nuster1128/LLM_Agent_Memory_Survey}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "39 pages, 5 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.13501v1",
    "published_date": "2024-04-21 01:49:46 UTC",
    "updated_date": "2024-04-21 01:49:46 UTC"
  },
  {
    "arxiv_id": "2404.13500v1",
    "title": "Generalized Regression with Conditional GANs",
    "authors": [
      "Deddy Jobson",
      "Eddy Hudson"
    ],
    "abstract": "Regression is typically treated as a curve-fitting process where the goal is\nto fit a prediction function to data. With the help of conditional generative\nadversarial networks, we propose to solve this age-old problem in a different\nway; we aim to learn a prediction function whose outputs, when paired with the\ncorresponding inputs, are indistinguishable from feature-label pairs in the\ntraining dataset. We show that this approach to regression makes fewer\nassumptions on the distribution of the data we are fitting to and, therefore,\nhas better representation capabilities. We draw parallels with generalized\nlinear models in statistics and show how our proposal serves as an extension of\nthem to neural networks. We demonstrate the superiority of this new approach to\nstandard regression with experiments on multiple synthetic and publicly\navailable real-world datasets, finding encouraging results, especially with\nreal-world heavy-tailed regression datasets. To make our work more\nreproducible, we release our source code. Link to repository:\nhttps://anonymous.4open.science/r/regressGAN-7B71/",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13500v1",
    "published_date": "2024-04-21 01:27:47 UTC",
    "updated_date": "2024-04-21 01:27:47 UTC"
  },
  {
    "arxiv_id": "2405.06658v1",
    "title": "ProteinEngine: Empower LLM with Domain Knowledge for Protein Engineering",
    "authors": [
      "Yiqing Shen",
      "Outongyi Lv",
      "Houying Zhu",
      "Yu Guang Wang"
    ],
    "abstract": "Large language models (LLMs) have garnered considerable attention for their\nproficiency in tackling intricate tasks, particularly leveraging their\ncapacities for zero-shot and in-context learning. However, their utility has\nbeen predominantly restricted to general tasks due to an absence of\ndomain-specific knowledge. This constraint becomes particularly pertinent in\nthe realm of protein engineering, where specialized expertise is required for\ntasks such as protein function prediction, protein evolution analysis, and\nprotein design, with a level of specialization that existing LLMs cannot\nfurnish. In response to this challenge, we introduce \\textsc{ProteinEngine}, a\nhuman-centered platform aimed at amplifying the capabilities of LLMs in protein\nengineering by seamlessly integrating a comprehensive range of relevant tools,\npackages, and software via API calls. Uniquely, \\textsc{ProteinEngine} assigns\nthree distinct roles to LLMs, facilitating efficient task delegation,\nspecialized task resolution, and effective communication of results. This\ndesign fosters high extensibility and promotes the smooth incorporation of new\nalgorithms, models, and features for future development. Extensive user\nstudies, involving participants from both the AI and protein engineering\ncommunities across academia and industry, consistently validate the superiority\nof \\textsc{ProteinEngine} in augmenting the reliability and precision of deep\nlearning in protein engineering tasks. Consequently, our findings highlight the\npotential of \\textsc{ProteinEngine} to bride the disconnected tools for future\nresearch in the protein engineering domain.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06658v1",
    "published_date": "2024-04-21 01:07:33 UTC",
    "updated_date": "2024-04-21 01:07:33 UTC"
  },
  {
    "arxiv_id": "2404.13496v1",
    "title": "ODE-DPS: ODE-based Diffusion Posterior Sampling for Inverse Problems in Partial Differential Equation",
    "authors": [
      "Enze Jiang",
      "Jishen Peng",
      "Zheng Ma",
      "Xiong-Bin Yan"
    ],
    "abstract": "In recent years we have witnessed a growth in mathematics for deep learning,\nwhich has been used to solve inverse problems of partial differential equations\n(PDEs). However, most deep learning-based inversion methods either require\npaired data or necessitate retraining neural networks for modifications in the\nconditions of the inverse problem, significantly reducing the efficiency of\ninversion and limiting its applicability. To overcome this challenge, in this\npaper, leveraging the score-based generative diffusion model, we introduce a\nnovel unsupervised inversion methodology tailored for solving inverse problems\narising from PDEs. Our approach operates within the Bayesian inversion\nframework, treating the task of solving the posterior distribution as a\nconditional generation process achieved through solving a reverse-time\nstochastic differential equation. Furthermore, to enhance the accuracy of\ninversion results, we propose an ODE-based Diffusion Posterior Sampling\ninversion algorithm. The algorithm stems from the marginal probability density\nfunctions of two distinct forward generation processes that satisfy the same\nFokker-Planck equation. Through a series of experiments involving various PDEs,\nwe showcase the efficiency and robustness of our proposed method.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.NA"
    ],
    "primary_category": "math.NA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13496v1",
    "published_date": "2024-04-21 00:57:13 UTC",
    "updated_date": "2024-04-21 00:57:13 UTC"
  }
]