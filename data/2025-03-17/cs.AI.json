{
  "date": "2025-03-17",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-17 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 论文热点集中在大型语言模型（LLM）的推理、效率与安全，多模态理解与生成，以及多智能体协作，同时机器人技术、AI 在科学和医学领域的应用也备受关注。值得关注的亮点包括 xLSTM 7B 模型的发布、通过元梯度下降优化训练过程的新方法、以及对多智能体 LLM 系统失败原因的深入分析。\n\n**重点论文 & LLM 进展:**\n\n*   **xLSTM 7B：一种用于快速高效推理的循环 LLM (xLSTM 7B: A Recurrent LLM for Fast and Efficient Inference)**\n    由 Sepp Hochreiter 团队发布，介绍了一款 70 亿参数的 xLSTM 模型。该模型结合了 xLSTM 架构（计算量随序列长度线性扩展，内存使用恒定）和针对性优化，实现了与同类 LLM 相当的性能，但在推理速度和效率上显著优于 Llama 和 Mamba 类模型，特别适合需要大量测试时计算的任务。模型权重和代码已开源。\n\n*   **通过元梯度下降优化机器学习训练 (Optimizing ML Training with Metagradient Descent)**\n    来自 Aleksander Madry 团队的研究，提出了一种通过计算元梯度（贯穿模型训练过程的梯度）来优化大规模模型训练设置的方法。他们引入了高效计算元梯度的算法和“平滑模型训练”框架，利用元梯度下降 (MGD) 显著改进了数据集选择、数据投毒攻击效果，并能自动找到有竞争力的学习率调度策略。\n\n*   **MetaScale：通过演化的元思维进行测试时扩展 (MetaScale: Test-Time Scaling with Evolving Meta-Thoughts)**\n    针对 LLM 依赖训练模式而非主动选择认知策略的问题，提出了 METASCALE 框架。该框架在测试时基于“元思维”（适应性思维策略）进行扩展，使用多臂老虎机和遗传算法动态选择、评估和演化元思维，以提高模型在各种任务上的准确性和泛化能力。在 Arena-Hard 上使 GPT-4o 胜率提升 11%。\n\n*   **多智能体 LLM 系统为何失败？(Why Do Multi-Agent LLM Systems Fail?)**\n    首次全面研究了多智能体系统 (MAS) 面临的挑战。通过对 5 个流行 MAS 框架和 150 多个任务进行分析，识别了 14 种独特的失败模式，并提出了包含 3 大类的分类法（规范与系统设计失败、智能体间失配、任务验证与终止）。研究发现简单干预（如改进角色规范）不足以解决问题，为未来研究指明了方向。\n\n*   **LLM 位置泛化背后的计算机制 (Computation Mechanism Behind LLM Position Generalization)**\n    探讨了 LLM 如何处理文本位置信息并实现位置泛化（如处理位置扰动、泛化到更长文本）。研究发现 LLM 学会了解耦注意力 logits，使其值与位置相关性和语义重要性的算术和近似线性相关，并识别了一种促成此效应的中间特征模式，为 LLM 的位置灵活性提供了计算解释。\n\n*   **LLM 常识任务自解释的忠实度：越大越好，指令微调带来权衡而非帕累托最优 (Faithfulness of LLM Self-Explanations for Commonsense Tasks: Larger Is Better, and Instruction-Tuning Allows Trade-Offs but Not Pareto Dominance)**\n    对 8 个家族 62 个模型的自解释忠实度进行了全面的反事实分析。研究发现更大的模型通常更忠实，但指令微调带来的忠实度差异往往与解释的冗长程度有关，导致在真阳性/假阳性帕累托边界上移动，而非扩展边界。\n\n*   **φ-解码：平衡推理时探索与利用的自适应前瞻采样 (φ-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation)**\n    提出了一种新的解码策略 φ-Decoding，通过模拟未来步骤来估计全局最优步骤，平衡推理时优化中的探索与利用。该方法利用前瞻和聚类近似两个分布，并结合剪枝策略实现自适应计算分配，在多个基准上优于强基线。\n\n*   **DLPO：从深度学习视角构建鲁棒、高效、可泛化的提示优化框架 (DLPO: Towards a Robust, Efficient, and Generalizable Prompt Optimization Framework from a Deep-Learning Perspective)**\n    针对现有自动提示优化方法在鲁棒性、效率和泛化性方面的挑战，借鉴传统深度学习范式提出了 7 种创新方法 (DLPO)，将这些概念融入基于文本的梯度优化中，旨在系统性地解决这些问题。\n\n*   **Transformer 上下文扩展调查：方法与评估 (A Survey on Transformer Context Extension: Approaches and Evaluation)**\n    系统回顾了解决 LLM 在长上下文场景下性能下降问题的方法。将现有方法分为四类：位置编码、上下文压缩、检索增强和注意力模式，并整理了相关的长上下文评估数据、任务和指标，最后讨论了未解决的问题和未来发展方向。\n\n*   **多匝纠缠指令，LLM 能否遵循？(Can Language Models Follow Multiple Turns of Entangled Instructions?)**\n    系统研究了 LLM 处理多轮指令（可能纠缠或冲突）的能力。构建了 MultiTurnInstruct 数据集，包含约 1.1K 个高质量多轮对话，涵盖信息检索、跨轮次追踪与推理、冲突解决等九种能力。研究发现不同能力间存在权衡，且模型在整合多条相关指令方面存在困难。\n\n**多模态与视觉语言模型:**\n\n*   **VideoMind：用于长视频推理的 LoRA 链智能体 (VideoMind: A Chain-of-LoRA Agent for Long Video Reasoning)**\n    提出了一种新颖的视频语言智能体 VideoMind，用于时间定位的视频理解。创新点包括：(1) 识别视频时序推理的关键能力并设计了基于角色的工作流（规划器、定位器、验证器、回答器）；(2) 提出 Chain-of-LoRA 策略，通过轻量级 LoRA 适配器实现角色切换，平衡效率与灵活性。在 14 个基准上取得 SOTA 性能。\n\n*   **BlobCtrl：用于元素级图像生成和编辑的统一灵活框架 (BlobCtrl: A Unified and Flexible Framework for Element-level Image Generation and Editing)**\n    提出 BlobCtrl 框架，使用概率性的 Blob 表示统一了元素级的图像生成与编辑。通过将 Blob 作为视觉基元，有效解耦和表示空间位置、语义内容和身份信息，实现精确的元素级操作。关键贡献包括双分支扩散架构、自监督训练范式和可控 dropout 策略。同时发布了 BlobData 和 BlobBench 数据集。\n\n*   **MicroVQA：用于基于显微镜科学研究的多模态推理基准 (MicroVQA: A Multimodal Reasoning Benchmark for Microscopy-Based Scientific Research)**\n    针对科学研究中复杂的多模态推理需求，推出了 MicroVQA 基准。该基准包含 1042 个由生物学专家策划的多项选择题，评估 MLLM 在专家图像理解、假设生成和实验提议方面的能力。研究发现现有 MLLM 性能有限（最高 53%），且感知错误是最常见的失败原因。\n\n*   **通过带走视觉条件缓解多模态长 CoT 推理中的视觉遗忘 (Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning)**\n    发现在需要视觉输入的多模态长链推理任务中，MLLM 会逐渐忽略视觉信息（视觉遗忘）。提出 Take-along Visual Conditioning (TVC) 策略，将图像输入转移到关键推理阶段，并通过动态剪枝压缩冗余视觉 token，帮助模型在整个推理过程中保持对视觉组件的关注。在多个数学推理基准上取得 SOTA 性能。\n\n*   **KVShare：用于高效 LLM 推理的语义感知键值缓存共享 (KVShare: Semantic-Aware Key-Value Cache Sharing for Efficient Large Language Model Inference)**\n    提出 KVShare 技术，通过语义相似性实现多用户间的 KV Cache 共享，以提高 LLM 和 MLLM 的推理效率。该方法通过语义对齐算法和差异编辑操作实现细粒度的缓存重用，实验表明可提高 KV 缓存命中率超 60%，同时保持输出质量。\n\n*   **3DAxisPrompt：促进 GPT-4o 中的 3D 定位与推理 (3DAxisPrompt: Promoting the 3D Grounding and Reasoning in GPT-4o)**\n    提出 3DAxisPrompt 视觉提示方法，利用 3D 坐标轴和 SAM 生成的掩码为 MLLM 提供显式几何先验，将其 2D 定位和推理能力扩展到真实 3D 场景。通过对 GPT-4o 的深入研究和在多个 3D 数据集上的评估，展示了该方法在提升 MLLM 3D 理解能力方面的有效性。\n\n*   **概念即树：合成数据是 VLM 个性化所需的全部 (Concept-as-Tree: Synthetic Data is All You Need for VLM Personalization)**\n    针对 VLM 个性化中用户提供正样本稀缺和负样本质量低的问题，提出 Concept-as-Tree (CaT) 框架。该框架将概念表示为树结构，从而能够生成具有不同难度和多样性的正负样本用于 VLM 个性化微调，并通过数据过滤策略保证质量。实验证明 CaT 能显著提升 VLM 的个性化能力。\n\n*   **视觉语言模型用于急性结核病诊断：结合影像和临床数据的多模态方法 (Vision-Language Models for Acute Tuberculosis Diagnosis: A Multimodal Approach Combining Imaging and Clinical Data)**\n    提出一种结合 SIGLIP 和 Gemma-3b 的视觉语言模型 (VLM)，通过整合胸部 X 光图像和临床记录来自动筛查急性结核病 (TB)。该模型能生成详细的、结合上下文的诊断报告，在检测整合、空洞、结节等关键病理特征方面表现出高精度和召回率。\n\n*   **视觉语言模型用于慢性结核病诊断：用于精确分析的多模态框架 (Advancing Chronic Tuberculosis Diagnostics Using Vision-Language Models: A Multi modal Framework for Precision Analysis)**\n    与上一篇类似，提出一种结合 SIGLIP 编码器和 Gemma-3b 解码器的 VLM，用于慢性结核病的自动筛查。该模型整合胸部 X 光图像和临床数据（如病史、治疗记录），通过跨模态注意力机制对齐特征，生成全面的诊断报告，在检测纤维化、钙化肉芽肿等方面表现良好。\n\n**机器人与强化学习:**\n\n*   **人形机器人策略 ≈ 人类策略 (Humanoid Policy ~ Human Policy)**\n    研究利用可扩展的以自我为中心的人类演示数据（而非昂贵的机器人遥操作数据）来训练人形机器人操作策略。通过收集对齐的人类-人形机器人数据集 (PH2D) 和训练统一状态-动作空间的人类行动 Transformer (HAT)，证明了人类数据可以提高策略的泛化性和鲁棒性，并显著提升数据收集效率。\n\n*   **通用 Hanabi 智能体 (A Generalist Hanabi Agent)**\n    针对传统 MARL 系统难以泛化到不同设置或与不熟悉伙伴合作的问题，特别是在 Hanabi 游戏中，提出了 R3D2 (Recurrent Replay Relevance Distributed DQN)。该智能体首次能同时处理所有游戏设置（2-5人），并将策略从一个设置扩展到其他设置，甚至能与本身无法泛化的算法智能体协作。\n\n*   **真实世界机器人中同步与异步强化学习的比较 (Synchronous vs Asynchronous Reinforcement Learning in a Real World Robot)**\n    比较了在物理机器人（Franka Emika Panda）上使用同步和异步强化学习 (RL) 的性能。实验表明，异步 RL（分离决策和梯度更新）能让智能体学习更快，获得显著更高的回报，且响应时间更快的智能体表现更好。\n\n*   **INPROVF：利用 LLM 从假设违例中修复高级机器人控制器 (INPROVF: Leveraging Large Language Models to Repair High-level Robot Controllers from Assumption Violations)**\n    提出了 INPROVF 框架，结合 LLM 和形式化方法来加速高级机器人控制器的修复过程。LLM 用于生成修复候选方案，形式化方法用于验证其正确性。若验证失败，框架会提供反馈并迭代提示 LLM 生成改进方案，有效处理各种工作空间、任务和状态空间大小的违例情况。\n\n*   **FLEX：学习机器人无关的、涉及持续接触物体操作的基于力的技能框架 (FLEX: A Framework for Learning Robot-Agnostic Force-based Skills Involving Sustained Contact Object Manipulation)**\n    提出 FLEX 框架，用于学习以物体为中心、在力空间中进行的操作策略，特别适用于推、滑、开关抽屉等持续接触任务。该方法将机器人与物体解耦，简化动作空间，减少探索，并在模拟中高效训练。策略可泛化到未见物体，并直接迁移到不同机器人平台。\n\n*   **基于自由格式语言的机器人推理与抓取 (Free-form language-based robotic reasoning and grasping)**\n    提出 FreeGrasp 方法，利用预训练 VLM (GPT-4o) 的世界知识，根据自由格式的人类指令在杂乱环境中进行机器人抓取。通过检测物体关键点并在图像上标记，辅助 GPT-4o 进行零样本空间推理，判断目标物体是否可直接抓取或需先移除障碍物。同时发布了合成数据集 FreeGraspData。\n\n*   **具有在线演示的机器人策略迁移：一种主动强化学习方法 (Robot Policy Transfer with Online Demonstrations: An Active Reinforcement Learning Approach)**\n    将在线演示引入策略迁移 (TL) 设定，提出 Policy Transfer with Online Demonstrations 算法。该算法能在有限演示预算下，主动优化在线情景式专家演示的查询时机和内容，有效缓解 LfD 带来的协变量偏移问题，提升策略迁移的性能和样本效率。\n\n**AI 安全、对齐与评估:**\n\n*   **与动态人类价值观的超级对齐 (Superalignment with Dynamic Human Values)**\n    提出了一个算法框架路线图，旨在训练超人推理模型将复杂任务分解为人类可指导的子任务，以同时解决可扩展监督和人类价值观动态性两大对齐挑战。核心依赖“部分到整体泛化假设”，即子任务解决方案的对齐能泛化到完整解决方案的对齐。\n\n*   **AI 公司应报告缓解前后的安全评估 (AI Companies Should Report Pre- and Post-Mitigation Safety Evaluations)**\n    论证了前沿 AI 公司应同时报告缓解前（固有能力）和缓解后（部署状态）的安全评估结果，以便政策制定者做出明智的监管决策。文章指出现有披露存在差距，并建议强制披露、标准化评估方法和提高透明度要求。\n\n*   **MirrorGuard：通过熵引导的镜像构建实现对越狱的自适应防御 (MirrorGuard: Adaptive Defense Against Jailbreaks via Entropy-Guided Mirror Crafting)**\n    提出 MirrorGuard 防御范式，通过动态生成与输入提示句法结构相似但语义安全的“镜像”提示，利用输入与镜像间的个性化差异来检测和校准风险输入，实现对 LLM 越狱攻击的自适应防御。引入相对输入不确定性 (RIU) 指标量化差异。\n\n*   **LLM（真的）具有意识形态吗？基于 IRT 的 LLM 感知社会经济偏见分析与对齐工具 (Are LLMs (Really) Ideological? An IRT-based Analysis and Alignment Tool for Perceived Socio-Economic Bias in LLMs)**\n    引入基于项目反应理论 (IRT) 的框架来检测和量化 LLM 中的社会经济偏见，无需主观人工判断。研究发现现有 LLM 往往回避意识形态参与而非表现出偏见，挑战了先前的党派性主张。\n\n*   **评估 LLM 多语言漏洞的框架 (A Framework to Assess Multilingual Vulnerabilities of LLMs)**\n    提出了一个自动评估 LLM 多语言漏洞的框架。评估了 6 个 LLM 在 8 种不同资源水平语言上的表现，发现低资源语言中存在漏洞，但风险可能较低，因为它们常源于模型性能不佳导致的不连贯响应。\n\n*   **提示流完整性以防止 LLM 智能体中的权限提升 (Prompt Flow Integrity to Prevent Privilege Escalation in LLM Agents)**\n    提出提示流完整性 (PFI) 方案，通过非受信数据识别、强制执行最小权限和验证不安全数据流三种技术，防止利用自然语言提示对结合插件的 LLM 智能体进行权限提升攻击。\n\n**AI for Science & Medicine:**\n\n*   **利用图像运动的 3D 重建预测矮生番茄植株的总叶面积 (Using 3D reconstruction from image motion to predict total leaf area in dwarf tomato plants)**\n    评估了一种结合 RGB 图像序列 3D 重建和机器学习的非破坏性方法，用于估计矮生番茄的总叶面积 (TLA)。Alpha Shape 重建与 XGBoost 回归模型表现最佳 (R²=0.80)，跨实验验证也显示出鲁棒性。该方法适用于城市农业和精准农业。\n\n*   **基于 AI 的乳腺动脉钙化量化预测心血管风险 (Novel AI-Based Quantification of Breast Arterial Calcification to Predict Cardiovascular Risk)**\n    使用基于 Transformer 的神经网络在筛查性乳房 X 光片上量化乳腺动脉钙化 (BAC) 严重程度。研究发现 BAC 严重程度与主要不良心血管事件 (MACE) 和全因死亡率独立相关，即使调整了风险因素后依然显著，尤其对年轻女性有预测价值。\n\n*   **AI 驱动的缝合专业技能端到端评估自动化 (AI-driven Automation of End-to-end Assessment of Suturing Expertise)**\n    提出一种基于 AI 的方法来自动化缝合技能评估工具 EASE 的评分过程。该方法可实现实时评分预测，为外科医生/学员提供即时反馈，加速学习过程并可能改善患者预后。\n\n*   **用于腹部 CT 监督的基于 LLM 的标注器 LEAVS (LEAVS: An LLM-based Labeler for Abdominal CT Supervision)**\n    提出 LEAVS 标注器，使用本地运行的 LLM 和专门的思维链提示策略，从 CT 放射学报告中提取腹部九个器官七种异常类型的确定性和紧迫性标签。在提取多种异常类型方面表现优于竞争方法和人类，平均 F1 分数为 0.89。\n\n*   **MedLoRD：用于高分辨率 3D CT 图像合成的医学低资源扩散模型 (MedLoRD: A Medical Low-Resource Diffusion Model for High-Resolution 3D CT Image Synthesis)**\n    提出 MedLoRD，一个专为计算资源受限环境设计的生成扩散模型，能够在仅有 24GB VRAM 的 GPU 上生成高达 512x512x256 分辨率的医学体积数据。通过放射学评估、相对区域体积分析等多方面验证，证明其能生成高保真度图像。\n\n*   **MMLNB：文本描述生成辅助的神经母细胞瘤亚型分类多模态学习 (MMLNB: Multi-Modal Learning for Neuroblastoma Subtyping Classification Assisted with Textual Description Generation)**\n    提出 MMLNB 模型，结合病理图像和生成的文本描述进行神经母细胞瘤 (NB) 亚型分类。通过微调 VLM 增强文本生成，并使用双分支架构和渐进鲁棒多模态融合 (PRMF) 块融合视觉和文本特征，提高了分类准确性和可解释性。\n\n**其他值得关注的论文:**\n\n*   **迈向 AI 辅助的学术写作 (Towards AI-assisted Academic Writing):** 展示了一个 AI 辅助学术写作系统的组件，包括引文推荐和引言撰写。\n*   **采样决策 (Sampling Decisions):** 提出一种新的决策流 (DF) 框架，用于从目标分布中采样，同时结合先验采样器的指导。\n*   **通过 Q 函数操纵实现奖励自适应 (Reward Adaptation Via Q-Manipulation):** 提出一种通过操纵 Q 函数来解决奖励自适应 (RA) 问题的新方法 Q-Manipulation (Q-M)，能在学习开始前进行动作剪枝，提高样本效率。\n*   **大规模数据集的高效训练 (Scale Efficient Training for Large Datasets):** 提出 SeTa 方法，通过动态样本剪枝（随机剪枝+基于难度的聚类剪枝）来无损减少大规模数据集的训练时间，最高可节省 50% 成本。\n*   **Cream of the Crop：为指令微调收获丰富、可扩展、可迁移的多模态数据 (Cream of the Crop: Harvesting Rich, Scalable and Transferable Multi-Modal Data for Instruction Fine-Tuning):** 提出 mmSSR 方法，通过多模态丰富评分器和风格器，从能力和交互风格多样性角度高效筛选多模态指令数据，仅用 30% 数据达到 99.1% 的完整性能。\n*   **联邦联合：用于剩余使用寿命预测的非线性退化信号与故障事件联合建模的联邦学习 (Fed-Joint: Joint Modeling of Nonlinear Degradation Signals and Failure Events for Remaining Useful Life Prediction using Federated Learning):** 提出一种新的联邦学习框架，联合建模非线性退化信号和失效时间数据，用于预测机械的剩余使用寿命 (RUL)。\n*   **利用认知科学工具在不同分析层面上理解大型语言模型 (Using the Tools of Cognitive Science to Understand Large Language Models at Different Levels of Analysis):** 提出应用认知科学方法（基于 Marr 的三个分析层面）来理解 LLM 的框架。\n*   **通过统一的 DeepStochLog 实现有效的文本到 SQL 生成 (Valid Text-to-SQL Generation with Unification-based DeepStochLog):** 提出一个神经符号框架，利用基于合一的确定性子句语法施加 SQL 语法和模式约束，保证生成有效的 SQL 查询。\n*   **可靠高效的摊销式基于模型的评估 (Reliable and Efficient Amortized Model-based Evaluation):** 提出一种结合项目反应理论 (IRT) 和模型预测问题难度的方法，以更低成本实现对 LM 的可靠整体评估，并通过问题生成器支持自适应测试。\n*   **通过迭代混合程序分析生成 LLM 测试 (LLM Test Generation via Iterative Hybrid Program Analysis):** 提出 Panta 技术，结合静态控制流分析和动态代码覆盖率分析，系统地引导 LLM 识别未覆盖路径并生成更高覆盖率的单元测试。\n*   **联邦持续指令调优 (Federated Continual Instruction Tuning):** 引入 FCIT 基准来模拟真实世界中客户端不断遇到新知识并需要持续进行指令调优的挑战，并提出动态知识组织和子空间选择性激活方法来应对。\n\n这期的内容非常丰富，涵盖了 LLM 的多个前沿方向以及 AI 在各个领域的深入应用。希望这份 TLDR 能帮助你快速把握今日 arXiv 的精华！",
  "papers": [
    {
      "arxiv_id": "2503.13778v1",
      "title": "Using 3D reconstruction from image motion to predict total leaf area in dwarf tomato plants",
      "title_zh": "利用图像运动三维重建预测矮生番茄植株总叶面积",
      "authors": [
        "Dmitrii Usenko",
        "David Helman",
        "Chen Giladi"
      ],
      "abstract": "Accurate estimation of total leaf area (TLA) is crucial for evaluating plant\ngrowth, photosynthetic activity, and transpiration. However, it remains\nchallenging for bushy plants like dwarf tomatoes due to their complex canopies.\nTraditional methods are often labor-intensive, damaging to plants, or limited\nin capturing canopy complexity. This study evaluated a non-destructive method\ncombining sequential 3D reconstructions from RGB images and machine learning to\nestimate TLA for three dwarf tomato cultivars: Mohamed, Hahms Gelbe Topftomate,\nand Red Robin -- grown under controlled greenhouse conditions. Two experiments\n(spring-summer and autumn-winter) included 73 plants, yielding 418 TLA\nmeasurements via an \"onion\" approach. High-resolution videos were recorded, and\n500 frames per plant were used for 3D reconstruction. Point clouds were\nprocessed using four algorithms (Alpha Shape, Marching Cubes, Poisson's, Ball\nPivoting), and meshes were evaluated with seven regression models:\nMultivariable Linear Regression, Lasso Regression, Ridge Regression, Elastic\nNet Regression, Random Forest, Extreme Gradient Boosting, and Multilayer\nPerceptron. The Alpha Shape reconstruction ($\\alpha = 3$) with Extreme Gradient\nBoosting achieved the best performance ($R^2 = 0.80$, $MAE = 489 cm^2$).\nCross-experiment validation showed robust results ($R^2 = 0.56$, $MAE = 579\ncm^2$). Feature importance analysis identified height, width, and surface area\nas key predictors. This scalable, automated TLA estimation method is suited for\nurban farming and precision agriculture, offering applications in automated\npruning, resource efficiency, and sustainable food production. The approach\ndemonstrated robustness across variable environmental conditions and canopy\nstructures.",
      "tldr_zh": "本研究提出了一种基于RGB图像序列3D重建和机器学习的方法，用于无损测量矮生番茄植株的总叶面积(TLA)。通过四种3D重建算法(Alpha Shape、Marching Cubes等)和七种回归模型的对比，发现Alpha Shape结合极端梯度提升(XGBoost)效果最佳(R²=0.80)。该方法在73株植物、418次测量中验证了其可靠性，特别适合城市农业和精准农业应用，为自动化修剪和资源优化提供了新工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages, 11 figures, submitted to Computers and Electronics in\n  Agriculture",
      "pdf_url": "http://arxiv.org/pdf/2503.13778v1",
      "published_date": "2025-03-17 23:51:19 UTC",
      "updated_date": "2025-03-17 23:51:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:48:28.385491"
    },
    {
      "arxiv_id": "2503.13771v1",
      "title": "Towards AI-assisted Academic Writing",
      "title_zh": "迈向AI辅助学术写作",
      "authors": [
        "Daniel J. Liebling",
        "Malcolm Kane",
        "Madeleine Grunde-Mclaughlin",
        "Ian J. Lang",
        "Subhashini Venugopalan",
        "Michael P. Brenner"
      ],
      "abstract": "We present components of an AI-assisted academic writing system including\ncitation recommendation and introduction writing. The system recommends\ncitations by considering the user's current document context to provide\nrelevant suggestions. It generates introductions in a structured fashion,\nsituating the contributions of the research relative to prior work. We\ndemonstrate the effectiveness of the components through quantitative\nevaluations. Finally, the paper presents qualitative research exploring how\nresearchers incorporate citations into their writing workflows. Our findings\nindicate that there is demand for precise AI-assisted writing systems and\nsimple, effective methods for meeting those needs.",
      "tldr_zh": "该研究提出了一种AI辅助学术写作系统，主要包含文献引用推荐和引言自动生成两大功能。系统能根据用户当前文档内容推荐相关文献引用，并以结构化方式生成研究引言，清晰定位研究贡献与现有工作的关系。定量评估验证了系统的有效性，同时定性研究发现研究人员对精准AI写作辅助工具存在需求。研究为开发简单高效的学术写作辅助系统提供了实践指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted to NAACL 2025 Workshop on AI for Scientific Discovery",
      "pdf_url": "http://arxiv.org/pdf/2503.13771v1",
      "published_date": "2025-03-17 23:30:17 UTC",
      "updated_date": "2025-03-17 23:30:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:48:46.821957"
    },
    {
      "arxiv_id": "2503.14555v1",
      "title": "A Generalist Hanabi Agent",
      "title_zh": "通用型 Hanabi 智能体",
      "authors": [
        "Arjun V Sudhakar",
        "Hadi Nekoei",
        "Mathieu Reymond",
        "Miao Liu",
        "Janarthanan Rajendran",
        "Sarath Chandar"
      ],
      "abstract": "Traditional multi-agent reinforcement learning (MARL) systems can develop\ncooperative strategies through repeated interactions. However, these systems\nare unable to perform well on any other setting than the one they have been\ntrained on, and struggle to successfully cooperate with unfamiliar\ncollaborators. This is particularly visible in the Hanabi benchmark, a popular\n2-to-5 player cooperative card-game which requires complex reasoning and\nprecise assistance to other agents. Current MARL agents for Hanabi can only\nlearn one specific game-setting (e.g., 2-player games), and play with the same\nalgorithmic agents. This is in stark contrast to humans, who can quickly adjust\ntheir strategies to work with unfamiliar partners or situations. In this paper,\nwe introduce Recurrent Replay Relevance Distributed DQN (R3D2), a generalist\nagent for Hanabi, designed to overcome these limitations. We reformulate the\ntask using text, as language has been shown to improve transfer. We then\npropose a distributed MARL algorithm that copes with the resulting dynamic\nobservation- and action-space. In doing so, our agent is the first that can\nplay all game settings concurrently, and extend strategies learned from one\nsetting to other ones. As a consequence, our agent also demonstrates the\nability to collaborate with different algorithmic agents -- agents that are\nthemselves unable to do so. The implementation code is available at:\n$\\href{https://github.com/chandar-lab/R3D2-A-Generalist-Hanabi-Agent}{R3D2-A-Generalist-Hanabi-Agent}$",
      "tldr_zh": "本文提出了R3D2（循环重放相关分布式DQN），一种通用的Hanabi游戏智能体，突破了传统多智能体强化学习（MARL）只能适应特定训练场景的限制。该研究通过文本化任务重构（利用语言提升迁移能力）和动态观测/动作空间处理算法，首次实现了跨游戏设置（2-5人）的通用协作能力。实验表明，该智能体不仅能同时适应所有游戏配置，还能与不同算法智能体成功协作，而后者本身并不具备这种跨场景协作能力。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.14555v1",
      "published_date": "2025-03-17 22:25:15 UTC",
      "updated_date": "2025-03-17 22:25:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:49:07.330672"
    },
    {
      "arxiv_id": "2503.14554v1",
      "title": "Synchronous vs Asynchronous Reinforcement Learning in a Real World Robot",
      "title_zh": "真实世界机器人中的同步与异步强化学习对比",
      "authors": [
        "Ali Parsaee",
        "Fahim Shahriar",
        "Chuxin He",
        "Ruiqing Tan"
      ],
      "abstract": "In recent times, reinforcement learning (RL) with physical robots has\nattracted the attention of a wide range of researchers. However,\nstate-of-the-art RL algorithms do not consider that physical environments do\nnot wait for the RL agent to make decisions or updates. RL agents learn by\nperiodically conducting computationally expensive gradient updates. When\ndecision-making and gradient update tasks are carried out sequentially by the\nRL agent in a physical robot, it significantly increases the agent's response\ntime. In a rapidly changing environment, this increased response time may be\ndetrimental to the performance of the learning agent. Asynchronous RL methods,\nwhich separate the computation of decision-making and gradient updates, are a\npotential solution to this problem. However, only a few comparisons between\nasynchronous and synchronous RL have been made with physical robots. For this\nreason, the exact performance benefits of using asynchronous RL methods over\nsynchronous RL methods are still unclear. In this study, we provide a\nperformance comparison between asynchronous and synchronous RL using a physical\nrobotic arm called Franka Emika Panda. Our experiments show that the agents\nlearn faster and attain significantly more returns using asynchronous RL. Our\nexperiments also demonstrate that the learning agent with a faster response\ntime performs better than the agent with a slower response time, even if the\nagent with a slower response time performs a higher number of gradient updates.",
      "tldr_zh": "本研究比较了同步和异步强化学习(RL)在真实机器人上的性能差异。实验使用Franka Emika Panda机械臂进行，结果表明异步RL方法通过将决策和梯度更新分离，显著缩短了响应时间，使智能体学习更快且获得更高的回报。研究还发现，响应时间更快的智能体即使梯度更新次数较少，其性能仍优于响应较慢但梯度更新更多的智能体。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Presented at Alberta Robotics & Intelligent Systems Expo (RISE)\n  Conference",
      "pdf_url": "http://arxiv.org/pdf/2503.14554v1",
      "published_date": "2025-03-17 22:24:39 UTC",
      "updated_date": "2025-03-17 22:24:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:49:25.327704"
    },
    {
      "arxiv_id": "2503.13754v2",
      "title": "From Autonomous Agents to Integrated Systems, A New Paradigm: Orchestrated Distributed Intelligence",
      "title_zh": "从自主智能体到集成系统的新范式：协调式分布式智能",
      "authors": [
        "Krti Tallam"
      ],
      "abstract": "The rapid evolution of artificial intelligence (AI) has ushered in a new era\nof integrated systems that merge computational prowess with human\ndecision-making. In this paper, we introduce the concept of Orchestrated\nDistributed Intelligence (ODI), a novel paradigm that reconceptualizes AI not\nas isolated autonomous agents, but as cohesive, orchestrated networks that work\nin tandem with human expertise. ODI leverages advanced orchestration layers,\nmulti-loop feedback mechanisms, and a high cognitive density framework to\ntransform static, record-keeping systems into dynamic, action-oriented\nenvironments. Through a comprehensive review of multi-agent system literature,\nrecent technological advances, and practical insights from industry forums, we\nargue that the future of AI lies in integrating distributed intelligence within\nhuman-centric workflows. This approach not only enhances operational efficiency\nand strategic agility but also addresses challenges related to scalability,\ntransparency, and ethical decision-making. Our work outlines key theoretical\nimplications and presents a practical roadmap for future research and\nenterprise innovation, aiming to pave the way for responsible and adaptive AI\nsystems that drive sustainable innovation in human organizations.",
      "tldr_zh": "本文提出\"协调分布式智能\"(Orchestrated Distributed Intelligence, ODI)这一新范式，将AI系统从孤立自主智能体重新构想为与人类专业知识协同工作的协调网络。该框架通过高级协调层、多环反馈机制和高认知密度架构，将静态记录系统转变为动态行动导向环境。研究表明，将分布式智能融入以人为中心的工作流不仅能提升运营效率和战略敏捷性，还能解决可扩展性、透明度和伦理决策等挑战。论文为构建负责任、自适应AI系统提供了理论框架和实践路线图，推动人类组织可持续创新。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13754v2",
      "published_date": "2025-03-17 22:21:25 UTC",
      "updated_date": "2025-03-19 02:01:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:49:54.968824"
    },
    {
      "arxiv_id": "2503.13751v1",
      "title": "Optimizing ML Training with Metagradient Descent",
      "title_zh": "基于元梯度下降优化机器学习训练",
      "authors": [
        "Logan Engstrom",
        "Andrew Ilyas",
        "Benjamin Chen",
        "Axel Feldmann",
        "William Moses",
        "Aleksander Madry"
      ],
      "abstract": "A major challenge in training large-scale machine learning models is\nconfiguring the training process to maximize model performance, i.e., finding\nthe best training setup from a vast design space. In this work, we unlock a\ngradient-based approach to this problem. We first introduce an algorithm for\nefficiently calculating metagradients -- gradients through model training -- at\nscale. We then introduce a \"smooth model training\" framework that enables\neffective optimization using metagradients. With metagradient descent (MGD), we\ngreatly improve on existing dataset selection methods, outperform\naccuracy-degrading data poisoning attacks by an order of magnitude, and\nautomatically find competitive learning rate schedules.",
      "tldr_zh": "该论文提出了一种基于元梯度下降(Metagradient Descent, MGD)的机器学习训练优化方法。研究者首先开发了高效计算元梯度(metagradients)的算法，实现了对模型训练过程的梯度反向传播；然后提出了\"平滑模型训练\"框架来有效利用这些元梯度进行优化。实验表明，该方法在数据集选择方面显著优于现有技术，能够抵御导致精度下降的数据投毒攻击，并自动发现具有竞争力的学习率调度策略。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13751v1",
      "published_date": "2025-03-17 22:18:24 UTC",
      "updated_date": "2025-03-17 22:18:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:50:08.011874"
    },
    {
      "arxiv_id": "2503.14552v1",
      "title": "Fire and Smoke Datasets in 20 Years: An In-depth Review",
      "title_zh": "20年火灾与烟雾数据集深度综述",
      "authors": [
        "Sayed Pedram Haeri Boroujeni",
        "Niloufar Mehrabi",
        "Fatemeh Afghah",
        "Connor Peter McGrath",
        "Danish Bhatkar",
        "Mithilesh Anil Biradar",
        "Abolfazl Razi"
      ],
      "abstract": "Fire and smoke phenomena pose a significant threat to the natural\nenvironment, ecosystems, and global economy, as well as human lives and\nwildlife. In this particular circumstance, there is a demand for more\nsophisticated and advanced technologies to implement an effective strategy for\nearly detection, real-time monitoring, and minimizing the overall impacts of\nfires on ecological balance and public safety. Recently, the rapid advancement\nof Artificial Intelligence (AI) and Computer Vision (CV) frameworks has\nsubstantially revolutionized the momentum for developing efficient fire\nmanagement systems. However, these systems extensively rely on the availability\nof adequate and high-quality fire and smoke data to create proficient Machine\nLearning (ML) methods for various tasks, such as detection and monitoring.\nAlthough fire and smoke datasets play a critical role in training, evaluating,\nand testing advanced Deep Learning (DL) models, a comprehensive review of the\nexisting datasets is still unexplored. For this purpose, we provide an in-depth\nreview to systematically analyze and evaluate fire and smoke datasets collected\nover the past 20 years. We investigate the characteristics of each dataset,\nincluding type, size, format, collection methods, and geographical diversities.\nWe also review and highlight the unique features of each dataset, such as\nimaging modalities (RGB, thermal, infrared) and their applicability for\ndifferent fire management tasks (classification, segmentation, detection).\nFurthermore, we summarize the strengths and weaknesses of each dataset and\ndiscuss their potential for advancing research and technology in fire\nmanagement. Ultimately, we conduct extensive experimental analyses across\ndifferent datasets using several state-of-the-art algorithms, such as\nResNet-50, DeepLab-V3, and YoloV8.",
      "tldr_zh": "这篇论文对过去20年间的火灾与烟雾数据集进行了系统性综述。研究首先分析了不同数据集在类型、规模、采集方式和地理多样性等方面的特征，特别关注了多模态数据（如RGB、热成像和红外图像）及其在火灾检测、分类等任务中的适用性。通过评估ResNet-50、YoloV8等先进算法在不同数据集上的表现，研究揭示了现有数据集的优势与局限，为开发更高效的火灾管理AI系统提供了关键数据基准。该综述填补了火灾视觉识别领域缺乏系统性数据评估的研究空白。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.14552v1",
      "published_date": "2025-03-17 22:08:02 UTC",
      "updated_date": "2025-03-17 22:08:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:50:32.468621"
    },
    {
      "arxiv_id": "2503.17391v1",
      "title": "AI-driven Automation of End-to-end Assessment of Suturing Expertise",
      "title_zh": "AI驱动的缝合技能端到端评估自动化",
      "authors": [
        "Atharva Deo",
        "Nicholas Matsumoto",
        "Sun Kim",
        "Peter Wager",
        "Randy G. Tsai",
        "Aaron Denmark",
        "Cherine Yang",
        "Xi Li",
        "Jay Moran",
        "Miguel Hernandez",
        "Andrew J. Hung"
      ],
      "abstract": "We present an AI based approach to automate the End-to-end Assessment of\nSuturing Expertise (EASE), a suturing skills assessment tool that\ncomprehensively defines criteria around relevant sub-skills.1 While EASE\nprovides granular skills assessment related to suturing to provide trainees\nwith an objective evaluation of their aptitude along with actionable insights,\nthe scoring process is currently performed by human evaluators, which is time\nand resource consuming. The AI based approach solves this by enabling real-time\nscore prediction with minimal resources during model inference. This enables\nthe possibility of real-time feedback to the surgeons/trainees, potentially\naccelerating the learning process for the suturing task and mitigating critical\nerrors during the surgery, improving patient outcomes. In this study, we focus\non the following 7 EASE domains that come under 3 suturing phases: 1) Needle\nHandling: Number of Repositions, Needle Hold Depth, Needle Hold Ratio, and\nNeedle Hold Angle; 2) Needle Driving: Driving Smoothness, and Wrist Rotation;\n3) Needle Withdrawal: Wrist Rotation.",
      "tldr_zh": "该研究提出了一种基于AI的缝合技能端到端评估(EASE)自动化方法，可实时评估外科医生/学员的缝合技术。该系统通过AI模型自动预测7项关键指标（包括针头操作、进针和退针三大阶段的指标），取代传统人工评分方式，显著提升评估效率。该技术能为学员提供实时反馈，帮助加速学习过程并减少手术中的关键错误，从而改善患者治疗效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17391v1",
      "published_date": "2025-03-17 21:28:02 UTC",
      "updated_date": "2025-03-17 21:28:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:51:00.395018"
    },
    {
      "arxiv_id": "2503.15549v1",
      "title": "Rendering Transparency to Ranking in Educational Assessment via Bayesian Comparative Judgement",
      "title_zh": "通过贝叶斯比较判断实现教育评估排名的透明化呈现",
      "authors": [
        "Andy Gray",
        "Alma Rahat",
        "Stephen Lindsay",
        "Jen Pearson",
        "Tom Crick"
      ],
      "abstract": "Ensuring transparency in educational assessment is increasingly critical,\nparticularly post-pandemic, as demand grows for fairer and more reliable\nevaluation methods. Comparative Judgement (CJ) offers a promising alternative\nto traditional assessments, yet concerns remain about its perceived opacity.\nThis paper examines how Bayesian Comparative Judgement (BCJ) enhances\ntransparency by integrating prior information into the judgement process,\nproviding a structured, data-driven approach that improves interpretability and\naccountability.\n  BCJ assigns probabilities to judgement outcomes, offering quantifiable\nmeasures of uncertainty and deeper insights into decision confidence. By\nsystematically tracking how prior data and successive judgements inform final\nrankings, BCJ clarifies the assessment process and helps identify assessor\ndisagreements. Multi-criteria BCJ extends this by evaluating multiple learning\noutcomes (LOs) independently, preserving the richness of CJ while producing\ntransparent, granular rankings aligned with specific assessment goals. It also\nenables a holistic ranking derived from individual LOs, ensuring comprehensive\nevaluations without compromising detailed feedback.\n  Using a real higher education dataset with professional markers in the UK, we\ndemonstrate BCJ's quantitative rigour and ability to clarify ranking\nrationales. Through qualitative analysis and discussions with experienced CJ\npractitioners, we explore its effectiveness in contexts where transparency is\ncrucial, such as high-stakes national assessments. We highlight the benefits\nand limitations of BCJ, offering insights into its real-world application\nacross various educational settings.",
      "tldr_zh": "本研究探讨了贝叶斯比较判断(Bayesian Comparative Judgement, BCJ)如何通过整合先验信息来增强教育评估的透明度。BCJ通过为判断结果分配概率，提供了可量化的不确定性度量，并系统追踪先验数据和连续判断对最终排名的影响，从而提高了评估过程的可解释性和责任性。多标准BCJ进一步扩展了这一方法，独立评估多个学习成果(LOs)，生成透明且细粒度的排名，同时保留比较判断的丰富性。研究表明，BCJ在高等教育数据集上展现出定量严谨性，并在高风险的全国性评估等透明度至关重要的场景中表现出色。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.IR"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15549v1",
      "published_date": "2025-03-17 20:56:55 UTC",
      "updated_date": "2025-03-17 20:56:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:51:10.413772"
    },
    {
      "arxiv_id": "2503.13708v1",
      "title": "A Circular Construction Product Ontology for End-of-Life Decision-Making",
      "title_zh": "面向建筑产品报废决策的循环建造产品本体论",
      "authors": [
        "Kwabena Adu-Duodu",
        "Stanly Wilson",
        "Yinhao Li",
        "Aanuoluwapo Oladimeji",
        "Talea Huraysi",
        "Masoud Barati",
        "Charith Perera",
        "Ellis Solaiman",
        "Omer Rana",
        "Rajiv Ranjan",
        "Tejal Shah"
      ],
      "abstract": "Efficient management of end-of-life (EoL) products is critical for advancing\ncircularity in supply chains, particularly within the construction industry\nwhere EoL strategies are hindered by heterogenous lifecycle data and data\nsilos. Current tools like Environmental Product Declarations (EPDs) and Digital\nProduct Passports (DPPs) are limited by their dependency on seamless data\nintegration and interoperability which remain significant challenges. To\naddress these, we present the Circular Construction Product Ontology (CCPO), an\napplied framework designed to overcome semantic and data heterogeneity\nchallenges in EoL decision-making for construction products. CCPO standardises\nvocabulary and facilitates data integration across supply chain stakeholders\nenabling lifecycle assessments (LCA) and robust decision-making. By aggregating\ndisparate data into a unified product provenance, CCPO enables automated EoL\nrecommendations through customisable SWRL rules aligned with European standards\nand stakeholder-specific circularity SLAs, demonstrating its scalability and\nintegration capabilities. The adopted circular product scenario depicts CCPO's\napplication while competency question evaluations show its superior performance\nin generating accurate EoL suggestions highlighting its potential to greatly\nimprove decision-making in circular supply chains and its applicability in\nreal-world construction environments.",
      "tldr_zh": "该研究提出了一种循环建筑产品本体(CCPO)，旨在解决建筑行业报废产品(EoL)管理中的数据异构性和信息孤岛问题。该框架通过标准化词汇和整合供应链数据，支持生命周期评估(LCA)和决策制定，并采用可定制的SWRL规则实现自动化EoL建议。实验表明，CCPO能有效提升循环供应链决策质量，且符合欧洲标准和行业特定要求。",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13708v1",
      "published_date": "2025-03-17 20:28:08 UTC",
      "updated_date": "2025-03-17 20:28:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:51:44.902280"
    },
    {
      "arxiv_id": "2503.13690v1",
      "title": "Atyaephyra at SemEval-2025 Task 4: Low-Rank NPO",
      "title_zh": "Atyaephyra在SemEval-2025任务4中的表现：低秩负偏好优化方法",
      "authors": [
        "Jan Bronec",
        "Jindřich Helcl"
      ],
      "abstract": "We present a submission to the SemEval 2025 shared task on unlearning\nsensitive content from LLMs. Our approach employs negative preference\noptimization using low-rank adaptation. We show that we can utilize this\ncombination to cheaply compute additional regularization terms, which help with\nunlearning stabilization. The results of our approach significantly exceed the\nshared task baselines.",
      "tldr_zh": "本研究针对SemEval-2025任务4（LLM敏感内容遗忘任务），提出了一种基于低秩适配(LoRA)的负偏好优化(NPO)方法。该方法通过计算低成本的正则化项，有效提升了模型遗忘敏感内容时的稳定性。实验结果表明，该方法的性能显著超过了任务基准线。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50 (Primary), 68T07 (Secondary)",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 1 figure, 1 table, submitted to SemEval proceedings for ACL\n  Anthology",
      "pdf_url": "http://arxiv.org/pdf/2503.13690v1",
      "published_date": "2025-03-17 19:59:19 UTC",
      "updated_date": "2025-03-17 19:59:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:52:03.874948"
    },
    {
      "arxiv_id": "2503.14550v1",
      "title": "Novel AI-Based Quantification of Breast Arterial Calcification to Predict Cardiovascular Risk",
      "title_zh": "基于人工智能的新型乳腺动脉钙化量化方法用于预测心血管风险",
      "authors": [
        "Theodorus Dapamede",
        "Aisha Urooj",
        "Vedant Joshi",
        "Gabrielle Gershon",
        "Frank Li",
        "Mohammadreza Chavoshi",
        "Beatrice Brown-Mulry",
        "Rohan Satya Isaac",
        "Aawez Mansuri",
        "Chad Robichaux",
        "Chadi Ayoub",
        "Reza Arsanjani",
        "Laurence Sperling",
        "Judy Gichoya",
        "Marly van Assen",
        "Charles W. ONeill",
        "Imon Banerjee",
        "Hari Trivedi"
      ],
      "abstract": "Women are underdiagnosed and undertreated for cardiovascular disease.\nAutomatic quantification of breast arterial calcification on screening\nmammography can identify women at risk for cardiovascular disease and enable\nearlier treatment and management of disease. In this retrospective study of\n116,135 women from two healthcare systems, a transformer-based neural network\nquantified BAC severity (no BAC, mild, moderate, and severe) on screening\nmammograms. Outcomes included major adverse cardiovascular events (MACE) and\nall-cause mortality. BAC severity was independently associated with MACE after\nadjusting for cardiovascular risk factors, with increasing hazard ratios from\nmild (HR 1.18-1.22), moderate (HR 1.38-1.47), to severe BAC (HR 2.03-2.22)\nacross datasets (all p<0.001). This association remained significant across all\nage groups, with even mild BAC indicating increased risk in women under 50. BAC\nremained an independent predictor when analyzed alongside ASCVD risk scores,\nshowing significant associations with myocardial infarction, stroke, heart\nfailure, and mortality (all p<0.005). Automated BAC quantification enables\nopportunistic cardiovascular risk assessment during routine mammography without\nadditional radiation or cost. This approach provides value beyond traditional\nrisk factors, particularly in younger women, offering potential for early CVD\nrisk stratification in the millions of women undergoing annual mammography.",
      "tldr_zh": "该研究开发了一种基于Transformer神经网络的AI系统，用于自动量化乳腺动脉钙化(BAC)程度，以预测女性心血管疾病风险。通过对11.6万女性筛查性乳腺X光片的分析，发现BAC严重程度与主要不良心血管事件(MACE)独立相关，且风险随BAC程度(轻度、中度、重度)逐步升高，即使在50岁以下女性中轻度BAC也提示风险增加。该方法可在常规乳腺筛查中实现无额外辐射或成本的心血管风险评估，尤其对年轻女性具有超越传统风险因素的预测价值，为每年接受乳腺检查的数百万女性提供了早期心血管风险分层的新途径。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.14550v1",
      "published_date": "2025-03-17 19:38:17 UTC",
      "updated_date": "2025-03-17 19:38:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:52:41.065447"
    },
    {
      "arxiv_id": "2503.14549v1",
      "title": "Sampling Decisions",
      "title_zh": "抽样决策",
      "authors": [
        "Michael Chertkov",
        "Sungsoo Ahn",
        "Hamidreza Behjoo"
      ],
      "abstract": "In this manuscript we introduce a novel Decision Flow (DF) framework for\nsampling from a target distribution while incorporating additional guidance\nfrom a prior sampler. DF can be viewed as an AI driven algorithmic\nreincarnation of the Markov Decision Process (MDP) approach in Stochastic\nOptimal Control. It extends the continuous space, continuous time path Integral\nDiffusion sampling technique to discrete time and space, while also\ngeneralizing the Generative Flow Network framework. In its most basic form, an\nexplicit, Neural Network (NN) free formulation, DF leverages the linear\nsolvability of the the underlying MDP to adjust the transition probabilities of\nthe prior sampler. The resulting Markov Process is expressed as a convolution\nof the reverse time Green's function of the prior sampling with the target\ndistribution. We illustrate the DF framework through an example of sampling\nfrom the Ising model, discuss potential NN based extensions, and outline how DF\ncan enhance guided sampling across various applications.",
      "tldr_zh": "该研究提出了一种新颖的决策流(Decision Flow, DF)框架，用于从目标分布中进行采样，同时结合先验采样器的额外指导。DF框架将连续时空的路径积分扩散采样技术扩展到离散时空，并推广了生成流网络框架。其基本形式采用无神经网络(NN)的显式公式，通过调整先验采样器的转移概率来构建马尔可夫过程。作者以Ising模型为例展示了DF框架的应用，并讨论了基于NN的扩展潜力，表明DF可在多种应用中增强引导采样。",
      "categories": [
        "cs.LG",
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.14549v1",
      "published_date": "2025-03-17 19:32:22 UTC",
      "updated_date": "2025-03-17 19:32:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:52:46.182893"
    },
    {
      "arxiv_id": "2503.13660v1",
      "title": "INPROVF: Leveraging Large Language Models to Repair High-level Robot Controllers from Assumption Violations",
      "title_zh": "INPROVF：利用大语言模型修复因假设违反而失效的高层机器人控制器",
      "authors": [
        "Qian Meng",
        "Jin Peng Zhou",
        "Kilian Q. Weinberger",
        "Hadas Kress-Gazit"
      ],
      "abstract": "This paper presents INPROVF, an automatic framework that combines large\nlanguage models (LLMs) and formal methods to speed up the repair process of\nhigh-level robot controllers. Previous approaches based solely on formal\nmethods are computationally expensive and cannot scale to large state spaces.\nIn contrast, INPROVF uses LLMs to generate repair candidates, and formal\nmethods to verify their correctness. To improve the quality of these\ncandidates, our framework first translates the symbolic representations of the\nenvironment and controllers into natural language descriptions. If a candidate\nfails the verification, INPROVF provides feedback on potential unsafe behaviors\nor unsatisfied tasks, and iteratively prompts LLMs to generate improved\nsolutions. We demonstrate the effectiveness of INPROVF through 12 violations\nwith various workspaces, tasks, and state space sizes.",
      "tldr_zh": "本文提出了INPROVF框架，结合大语言模型(LLMs)和形式化方法，用于高效修复高级机器人控制器中的假设违规问题。传统方法仅依赖形式化方法，计算成本高且难以扩展到大规模状态空间，而INPROVF利用LLMs生成修复候选方案，并通过形式化方法验证其正确性。为提高候选方案质量，框架首先将环境和控制器的符号表示转化为自然语言描述，若验证失败，则反馈潜在的不安全行为或未满足任务，并迭代提示LLMs生成改进方案。实验表明，INPROVF在12种不同工作空间、任务和状态空间规模的违规场景中表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.FL",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "To appear in ICLR 2025 Workshop: VerifAI: AI Verification in the\n  Wild; in submission to 2025 IEEE 21th International Conference on Automation\n  Science and Engineering (CASE), Los Angeles, CA, USA: IEEE, Aug. 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13660v1",
      "published_date": "2025-03-17 19:08:36 UTC",
      "updated_date": "2025-03-17 19:08:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:53:14.800915"
    },
    {
      "arxiv_id": "2503.13657v1",
      "title": "Why Do Multi-Agent LLM Systems Fail?",
      "title_zh": "多智能体LLM系统为何失败？",
      "authors": [
        "Mert Cemri",
        "Melissa Z. Pan",
        "Shuyi Yang",
        "Lakshya A. Agrawal",
        "Bhavya Chopra",
        "Rishabh Tiwari",
        "Kurt Keutzer",
        "Aditya Parameswaran",
        "Dan Klein",
        "Kannan Ramchandran",
        "Matei Zaharia",
        "Joseph E. Gonzalez",
        "Ion Stoica"
      ],
      "abstract": "Despite growing enthusiasm for Multi-Agent Systems (MAS), where multiple LLM\nagents collaborate to accomplish tasks, their performance gains across popular\nbenchmarks remain minimal compared to single-agent frameworks. This gap\nhighlights the need to analyze the challenges hindering MAS effectiveness.\n  In this paper, we present the first comprehensive study of MAS challenges. We\nanalyze five popular MAS frameworks across over 150 tasks, involving six expert\nhuman annotators. We identify 14 unique failure modes and propose a\ncomprehensive taxonomy applicable to various MAS frameworks. This taxonomy\nemerges iteratively from agreements among three expert annotators per study,\nachieving a Cohen's Kappa score of 0.88. These fine-grained failure modes are\norganized into 3 categories, (i) specification and system design failures, (ii)\ninter-agent misalignment, and (iii) task verification and termination. To\nsupport scalable evaluation, we integrate MASFT with LLM-as-a-Judge. We also\nexplore if identified failures could be easily prevented by proposing two\ninterventions: improved specification of agent roles and enhanced orchestration\nstrategies. Our findings reveal that identified failures require more complex\nsolutions, highlighting a clear roadmap for future research. We open-source our\ndataset and LLM annotator.",
      "tldr_zh": "本研究首次系统分析了多智能体大语言模型系统（MAS）效能不足的原因。通过对5种主流MAS框架在150多项任务中的测试，研究者识别出14种典型故障模式，并将其归类为三大类：系统设计缺陷、智能体间协调失准以及任务验证与终止问题。研究采用专家标注（Cohen's Kappa=0.88）和LLM-as-a-Judge评估方法，发现现有简单优化（如角色说明改进）难以根本解决问题，为此开源了标注数据集并为未来研究指明方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13657v1",
      "published_date": "2025-03-17 19:04:38 UTC",
      "updated_date": "2025-03-17 19:04:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:53:37.248336"
    },
    {
      "arxiv_id": "2503.13621v1",
      "title": "Superalignment with Dynamic Human Values",
      "title_zh": "动态人类价值观驱动的超级对齐",
      "authors": [
        "Florian Mai",
        "David Kaczér",
        "Nicholas Kluge Corrêa",
        "Lucie Flek"
      ],
      "abstract": "Two core challenges of alignment are 1) scalable oversight and 2) accounting\nfor the dynamic nature of human values. While solutions like recursive reward\nmodeling address 1), they do not simultaneously account for 2). We sketch a\nroadmap for a novel algorithmic framework that trains a superhuman reasoning\nmodel to decompose complex tasks into subtasks that are still amenable to\nhuman-level guidance. Our approach relies on what we call the part-to-complete\ngeneralization hypothesis, which states that the alignment of subtask solutions\ngeneralizes to the alignment of complete solutions. We advocate for the need to\nmeasure this generalization and propose ways to improve it in the future.",
      "tldr_zh": "该研究提出\"超级对齐\"(Superalignment)新框架，旨在同时解决AI对齐中的两大核心挑战：可扩展监督(scalable oversight)和动态人类价值观(dynamic human values)问题。不同于现有方法，该框架通过训练超级推理模型将复杂任务分解为人类仍可指导的\"可分治子任务\"(subtasks)，并基于\"部分到整体泛化假设\"(part-to-complete generalization hypothesis)确保子任务的对齐能泛化至整体解决方案。研究还提出了测量和改进这种泛化能力的方法论。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at the ICLR 2025 Workshop on Bidirectional Human-AI\n  Alignment (BiAlign)",
      "pdf_url": "http://arxiv.org/pdf/2503.13621v1",
      "published_date": "2025-03-17 18:15:17 UTC",
      "updated_date": "2025-03-17 18:15:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:54:05.126448"
    },
    {
      "arxiv_id": "2503.13447v1",
      "title": "MetaScale: Test-Time Scaling with Evolving Meta-Thoughts",
      "title_zh": "MetaScale：基于进化元思维的测试时扩展框架",
      "authors": [
        "Qin Liu",
        "Wenxuan Zhou",
        "Nan Xu",
        "James Y. Huang",
        "Fei Wang",
        "Sheng Zhang",
        "Hoifung Poon",
        "Muhao Chen"
      ],
      "abstract": "One critical challenge for large language models (LLMs) for making complex\nreasoning is their reliance on matching reasoning patterns from training data,\ninstead of proactively selecting the most appropriate cognitive strategy to\nsolve a given task. Existing approaches impose fixed cognitive structures that\nenhance performance in specific tasks but lack adaptability across diverse\nscenarios. To address this limitation, we introduce METASCALE, a test-time\nscaling framework based on meta-thoughts -- adaptive thinking strategies\ntailored to each task. METASCALE initializes a pool of candidate meta-thoughts,\nthen iteratively selects and evaluates them using a multi-armed bandit\nalgorithm with upper confidence bound selection, guided by a reward model. To\nfurther enhance adaptability, a genetic algorithm evolves high-reward\nmeta-thoughts, refining and extending the strategy pool over time. By\ndynamically proposing and optimizing meta-thoughts at inference time, METASCALE\nimproves both accuracy and generalization across a wide range of tasks.\nExperimental results demonstrate that MetaScale consistently outperforms\nstandard inference approaches, achieving an 11% performance gain in win rate on\nArena-Hard for GPT-4o, surpassing o1-mini by 0.9% under style control. Notably,\nMETASCALE scales more effectively with increasing sampling budgets and produces\nmore structured, expert-level responses.",
      "tldr_zh": "该研究提出了METASCALE，一种基于元思维(meta-thoughts)的测试时扩展框架，旨在解决大语言模型(LLMs)在复杂推理任务中缺乏适应性认知策略的问题。METASCALE通过初始化候选元思维池，利用多臂赌博机算法和遗传算法动态选择和优化元思维，从而在推理时提升模型的准确性和泛化能力。实验表明，METASCALE在GPT-4o上的表现优于标准推理方法，在Arena-Hard任务中胜率提升了11%，并在增加采样预算时展现出更强的扩展能力和结构化专家级响应。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.13447v1",
      "published_date": "2025-03-17 17:59:54 UTC",
      "updated_date": "2025-03-17 17:59:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:54:03.870914"
    },
    {
      "arxiv_id": "2503.13445v1",
      "title": "Faithfulness of LLM Self-Explanations for Commonsense Tasks: Larger Is Better, and Instruction-Tuning Allows Trade-Offs but Not Pareto Dominance",
      "title_zh": "大语言模型自我解释在常识任务中的忠实性：规模越大越好，指令微调可实现权衡但无法实现帕累托最优",
      "authors": [
        "Noah Y. Siegel",
        "Nicolas Heess",
        "Maria Perez-Ortiz",
        "Oana-Maria Camburu"
      ],
      "abstract": "As large language models (LLMs) become increasingly capable, ensuring that\ntheir self-generated explanations are faithful to their internal\ndecision-making process is critical for safety and oversight. In this work, we\nconduct a comprehensive counterfactual faithfulness analysis across 62 models\nfrom 8 families, encompassing both pretrained and instruction-tuned variants\nand significantly extending prior studies of counterfactual tests. We introduce\nphi-CCT, a simplified variant of the Correlational Counterfactual Test, which\navoids the need for token probabilities while explaining most of the variance\nof the original test. Our findings reveal clear scaling trends: larger models\nare consistently more faithful on our metrics. However, when comparing\ninstruction-tuned and human-imitated explanations, we find that observed\ndifferences in faithfulness can often be attributed to explanation verbosity,\nleading to shifts along the true-positive/false-positive Pareto frontier. While\ninstruction-tuning and prompting can influence this trade-off, we find limited\nevidence that they fundamentally expand the frontier of explanatory\nfaithfulness beyond what is achievable with pretrained models of comparable\nsize. Our analysis highlights the nuanced relationship between\ninstruction-tuning, verbosity, and the faithful representation of model\ndecision processes.",
      "tldr_zh": "该研究对62个LLM模型进行了全面的反事实可信度分析，发现模型规模与解释忠实度呈正相关：模型越大，其自我生成的解释（self-explanations）越能真实反映内部决策过程。研究者提出的phi-CCT简化测试方法（基于Correlational Counterfactual Test改进）在无需token概率的情况下，能解释原始测试的大部分方差。研究揭示了指令微调（instruction-tuning）的局限性：虽然能通过调节解释冗长度（verbosity）来权衡真阳性/假阳性，但并未突破预训练模型在解释忠实性上的帕累托前沿（Pareto frontier）。这表明当前技术尚无法从根本上提升模型决策过程的可信表征能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "38 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13445v1",
      "published_date": "2025-03-17 17:59:39 UTC",
      "updated_date": "2025-03-17 17:59:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:56:15.754418"
    },
    {
      "arxiv_id": "2503.13444v1",
      "title": "VideoMind: A Chain-of-LoRA Agent for Long Video Reasoning",
      "title_zh": "VideoMind：基于LoRA链式智能体的长视频推理系统",
      "authors": [
        "Ye Liu",
        "Kevin Qinghong Lin",
        "Chang Wen Chen",
        "Mike Zheng Shou"
      ],
      "abstract": "Videos, with their unique temporal dimension, demand precise grounded\nunderstanding, where answers are directly linked to visual, interpretable\nevidence. Despite significant breakthroughs in reasoning capabilities within\nLarge Language Models, multi-modal reasoning - especially for videos - remains\nunexplored. In this work, we introduce VideoMind, a novel video-language agent\ndesigned for temporal-grounded video understanding. VideoMind incorporates two\nkey innovations: (i) We identify essential capabilities for video temporal\nreasoning and develop a role-based agentic workflow, including a planner for\ncoordinating different roles, a grounder for temporal localization, a verifier\nto assess temporal interval accuracy, and an answerer for question-answering.\n(ii) To efficiently integrate these diverse roles, we propose a novel\nChain-of-LoRA strategy, enabling seamless role-switching via lightweight LoRA\nadaptors while avoiding the overhead of multiple models, thus balancing\nefficiency and flexibility. Extensive experiments on 14 public benchmarks\ndemonstrate that our agent achieves state-of-the-art performance on diverse\nvideo understanding tasks, including 3 on grounded video question-answering, 6\non video temporal grounding, and 5 on general video question-answering,\nunderscoring its effectiveness in advancing video agent and long-form temporal\nreasoning.",
      "tldr_zh": "该研究提出了VideoMind，一种基于Chain-of-LoRA（低秩自适应）策略的视频语言智能体，专注于长视频时序推理任务。该框架通过四种角色分工（规划器、定位器、验证器和回答器）实现时序定位与理解，并创新性地采用LoRA适配器实现轻量级角色切换，在保证效率的同时提升多模态推理能力。实验表明，VideoMind在14个基准测试（包括时序定位、基础视频问答等任务）中达到最先进水平，有效推进了长视频时序推理技术的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://videomind.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2503.13444v1",
      "published_date": "2025-03-17 17:59:33 UTC",
      "updated_date": "2025-03-17 17:59:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:56:12.078119"
    },
    {
      "arxiv_id": "2503.13441v2",
      "title": "Humanoid Policy ~ Human Policy",
      "title_zh": "人形机器人策略 ≈ 人类策略",
      "authors": [
        "Ri-Zhao Qiu",
        "Shiqi Yang",
        "Xuxin Cheng",
        "Chaitanya Chawla",
        "Jialong Li",
        "Tairan He",
        "Ge Yan",
        "David J. Yoon",
        "Ryan Hoque",
        "Lars Paulsen",
        "Ge Yang",
        "Jian Zhang",
        "Sha Yi",
        "Guanya Shi",
        "Xiaolong Wang"
      ],
      "abstract": "Training manipulation policies for humanoid robots with diverse data enhances\ntheir robustness and generalization across tasks and platforms. However,\nlearning solely from robot demonstrations is labor-intensive, requiring\nexpensive tele-operated data collection which is difficult to scale. This paper\ninvestigates a more scalable data source, egocentric human demonstrations, to\nserve as cross-embodiment training data for robot learning. We mitigate the\nembodiment gap between humanoids and humans from both the data and modeling\nperspectives. We collect an egocentric task-oriented dataset (PH2D) that is\ndirectly aligned with humanoid manipulation demonstrations. We then train a\nhuman-humanoid behavior policy, which we term Human Action Transformer (HAT).\nThe state-action space of HAT is unified for both humans and humanoid robots\nand can be differentiably retargeted to robot actions. Co-trained with\nsmaller-scale robot data, HAT directly models humanoid robots and humans as\ndifferent embodiments without additional supervision. We show that human data\nimproves both generalization and robustness of HAT with significantly better\ndata collection efficiency. Code and data: https://human-as-robot.github.io/",
      "tldr_zh": "该研究提出了一种利用人类第一视角演示数据来训练人形机器人操作策略的新方法。通过收集与机器人演示直接对齐的PH2D数据集，并开发了一种统一人类和人形机器人状态-动作空间的行为策略模型——Human Action Transformer (HAT)，该方法能够有效缩小人类与人形机器人之间的形态差异。实验表明，结合少量机器人数据进行联合训练，HAT显著提高了策略的泛化能力和鲁棒性，同时大幅提升了数据收集效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Code and data: https://human-as-robot.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2503.13441v2",
      "published_date": "2025-03-17 17:59:09 UTC",
      "updated_date": "2025-03-24 08:31:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:56:10.103257"
    },
    {
      "arxiv_id": "2503.13438v1",
      "title": "Deep Belief Markov Models for POMDP Inference",
      "title_zh": "深度信念马尔可夫模型：面向部分可观测马尔可夫决策过程的推理方法",
      "authors": [
        "Giacomo Arcieri",
        "Konstantinos G. Papakonstantinou",
        "Daniel Straub",
        "Eleni Chatzi"
      ],
      "abstract": "This work introduces a novel deep learning-based architecture, termed the\nDeep Belief Markov Model (DBMM), which provides efficient, model-formulation\nagnostic inference in Partially Observable Markov Decision Process (POMDP)\nproblems. The POMDP framework allows for modeling and solving sequential\ndecision-making problems under observation uncertainty. In complex,\nhigh-dimensional, partially observable environments, existing methods for\ninference based on exact computations (e.g., via Bayes' theorem) or sampling\nalgorithms do not scale well. Furthermore, ground truth states may not be\navailable for learning the exact transition dynamics. DBMMs extend deep Markov\nmodels into the partially observable decision-making framework and allow\nefficient belief inference entirely based on available observation data via\nvariational inference methods. By leveraging the potency of neural networks,\nDBMMs can infer and simulate non-linear relationships in the system dynamics\nand naturally scale to problems with high dimensionality and discrete or\ncontinuous variables. In addition, neural network parameters can be dynamically\nupdated efficiently based on data availability. DBMMs can thus be used to infer\na belief variable, thus enabling the derivation of POMDP solutions over the\nbelief space. We evaluate the efficacy of the proposed methodology by\nevaluating the capability of model-formulation agnostic inference of DBMMs in\nbenchmark problems that include discrete and continuous variables.",
      "tldr_zh": "该研究提出了一种新型深度学习架构——深度信念马尔可夫模型(DBMM)，用于解决部分可观测马尔可夫决策过程(POMDP)的推理问题。该方法通过变分推理直接利用观测数据进行高效信念推断，突破了传统基于贝叶斯定理或采样方法在高维复杂环境中的局限性。DBMM结合深度马尔可夫模型与神经网络优势，能够模拟系统动态中的非线性关系，并适用于离散或连续的变量场景。实验证明，该方法在包含离散和连续变量的基准测试中实现了与模型无关的高效推理能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13438v1",
      "published_date": "2025-03-17 17:58:45 UTC",
      "updated_date": "2025-03-17 17:58:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:56:53.631824"
    },
    {
      "arxiv_id": "2503.13434v1",
      "title": "BlobCtrl: A Unified and Flexible Framework for Element-level Image Generation and Editing",
      "title_zh": "BlobCtrl：面向元素级图像生成与编辑的统一灵活框架",
      "authors": [
        "Yaowei Li",
        "Lingen Li",
        "Zhaoyang Zhang",
        "Xiaoyu Li",
        "Guangzhi Wang",
        "Hongxiang Li",
        "Xiaodong Cun",
        "Ying Shan",
        "Yuexian Zou"
      ],
      "abstract": "Element-level visual manipulation is essential in digital content creation,\nbut current diffusion-based methods lack the precision and flexibility of\ntraditional tools. In this work, we introduce BlobCtrl, a framework that\nunifies element-level generation and editing using a probabilistic blob-based\nrepresentation. By employing blobs as visual primitives, our approach\neffectively decouples and represents spatial location, semantic content, and\nidentity information, enabling precise element-level manipulation. Our key\ncontributions include: 1) a dual-branch diffusion architecture with\nhierarchical feature fusion for seamless foreground-background integration; 2)\na self-supervised training paradigm with tailored data augmentation and score\nfunctions; and 3) controllable dropout strategies to balance fidelity and\ndiversity. To support further research, we introduce BlobData for large-scale\ntraining and BlobBench for systematic evaluation. Experiments show that\nBlobCtrl excels in various element-level manipulation tasks while maintaining\ncomputational efficiency, offering a practical solution for precise and\nflexible visual content creation. Project page:\nhttps://liyaowei-stu.github.io/project/BlobCtrl/",
      "tldr_zh": "本文提出BlobCtrl框架，采用基于概率blob的表示方法统一元素级图像生成与编辑。该框架通过双分支扩散架构实现前景背景无缝融合，并引入自监督训练范式与可控dropout策略，在保持计算效率的同时提升生成质量。实验表明，BlobCtrl在元素级视觉操控任务中表现优异，为数字内容创作提供了更精确灵活的工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Webpage: https://liyaowei-stu.github.io/project/BlobCtrl/",
      "pdf_url": "http://arxiv.org/pdf/2503.13434v1",
      "published_date": "2025-03-17 17:58:05 UTC",
      "updated_date": "2025-03-17 17:58:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:56:54.352048"
    },
    {
      "arxiv_id": "2503.17388v1",
      "title": "AI Companies Should Report Pre- and Post-Mitigation Safety Evaluations",
      "title_zh": "AI公司应报告缓解前后的安全评估",
      "authors": [
        "Dillon Bowen",
        "Ann-Kathrin Dombrowski",
        "Adam Gleave",
        "Chris Cundy"
      ],
      "abstract": "The rapid advancement of AI systems has raised widespread concerns about\npotential harms of frontier AI systems and the need for responsible evaluation\nand oversight. In this position paper, we argue that frontier AI companies\nshould report both pre- and post-mitigation safety evaluations to enable\ninformed policy decisions. Evaluating models at both stages provides\npolicymakers with essential evidence to regulate deployment, access, and safety\nstandards. We show that relying on either in isolation can create a misleading\npicture of model safety. Our analysis of AI safety disclosures from leading\nfrontier labs identifies three critical gaps: (1) companies rarely evaluate\nboth pre- and post-mitigation versions, (2) evaluation methods lack\nstandardization, and (3) reported results are often too vague to inform policy.\nTo address these issues, we recommend mandatory disclosure of pre- and\npost-mitigation capabilities to approved government bodies, standardized\nevaluation methods, and minimum transparency requirements for public safety\nreporting. These ensure that policymakers and regulators can craft targeted\nsafety measures, assess deployment risks, and scrutinize companies' safety\nclaims effectively.",
      "tldr_zh": "该立场论文主张前沿AI公司应强制披露风险缓解前后的安全评估报告，以支持政策制定。研究指出当前行业存在三大缺陷：评估阶段不完整、方法缺乏标准化、报告内容模糊。作者建议建立政府核准的强制披露机制，推行标准化评估方法，并设定最低透明度要求，使监管部门能精准制定安全措施并验证企业安全声明。分析表明，仅依赖单一阶段的评估会扭曲对模型安全性的真实认知。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17388v1",
      "published_date": "2025-03-17 17:56:43 UTC",
      "updated_date": "2025-03-17 17:56:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:57:22.193958"
    },
    {
      "arxiv_id": "2503.13430v1",
      "title": "AugMapNet: Improving Spatial Latent Structure via BEV Grid Augmentation for Enhanced Vectorized Online HD Map Construction",
      "title_zh": "AugMapNet：通过BEV网格增强优化空间潜在结构以提升矢量化在线高精地图构建",
      "authors": [
        "Thomas Monninger",
        "Md Zafar Anwar",
        "Stanislaw Antol",
        "Steffen Staab",
        "Sihao Ding"
      ],
      "abstract": "Autonomous driving requires an understanding of the infrastructure elements,\nsuch as lanes and crosswalks. To navigate safely, this understanding must be\nderived from sensor data in real-time and needs to be represented in vectorized\nform. Learned Bird's-Eye View (BEV) encoders are commonly used to combine a set\nof camera images from multiple views into one joint latent BEV grid.\nTraditionally, from this latent space, an intermediate raster map is predicted,\nproviding dense spatial supervision but requiring post-processing into the\ndesired vectorized form. More recent models directly derive infrastructure\nelements as polylines using vectorized map decoders, providing instance-level\ninformation. Our approach, Augmentation Map Network (AugMapNet), proposes\nlatent BEV grid augmentation, a novel technique that significantly enhances the\nlatent BEV representation. AugMapNet combines vector decoding and dense spatial\nsupervision more effectively than existing architectures while remaining as\nstraightforward to integrate and as generic as auxiliary supervision.\nExperiments on nuScenes and Argoverse2 datasets demonstrate significant\nimprovements in vectorized map prediction performance up to 13.3% over the\nStreamMapNet baseline on 60m range and greater improvements on larger ranges.\nWe confirm transferability by applying our method to another baseline and find\nsimilar improvements. A detailed analysis of the latent BEV grid confirms a\nmore structured latent space of AugMapNet and shows the value of our novel\nconcept beyond pure performance improvement. The code will be released soon.",
      "tldr_zh": "该研究提出了AugMapNet，一种通过BEV网格增强技术改进空间潜在结构的模型，旨在提升在线高精地图（HD Map）的矢量构建性能。与现有方法相比，AugMapNet结合了矢量解码和密集空间监督，显著增强了BEV潜在表示，同时保持了通用性和易集成性。实验表明，在nuScenes和Argoverse2数据集上，AugMapNet在60米范围内的矢量地图预测性能比基线模型StreamMapNet提升了13.3%，且在更大范围内表现更优。该方法还验证了其在不同基线模型上的可迁移性，并通过详细分析证明了其潜在空间的结构化改进。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13430v1",
      "published_date": "2025-03-17 17:55:32 UTC",
      "updated_date": "2025-03-17 17:55:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:57:45.359919"
    },
    {
      "arxiv_id": "2503.13427v1",
      "title": "xLSTM 7B: A Recurrent LLM for Fast and Efficient Inference",
      "title_zh": "xLSTM 7B：支持快速高效推理的循环大语言模型",
      "authors": [
        "Maximilian Beck",
        "Korbinian Pöppel",
        "Phillip Lippe",
        "Richard Kurle",
        "Patrick M. Blies",
        "Günter Klambauer",
        "Sebastian Böck",
        "Sepp Hochreiter"
      ],
      "abstract": "Recent breakthroughs in solving reasoning, math and coding problems with\nLarge Language Models (LLMs) have been enabled by investing substantial\ncomputation budgets at inference time. Therefore, inference speed is one of the\nmost critical properties of LLM architectures, and there is a growing need for\nLLMs that are efficient and fast at inference. Recently, LLMs built on the\nxLSTM architecture have emerged as a powerful alternative to Transformers,\noffering linear compute scaling with sequence length and constant memory usage,\nboth highly desirable properties for efficient inference. However, such\nxLSTM-based LLMs have yet to be scaled to larger models and assessed and\ncompared with respect to inference speed and efficiency. In this work, we\nintroduce xLSTM 7B, a 7-billion-parameter LLM that combines xLSTM's\narchitectural benefits with targeted optimizations for fast and efficient\ninference. Our experiments demonstrate that xLSTM 7B achieves performance on\ndownstream tasks comparable to other similar-sized LLMs, while providing\nsignificantly faster inference speeds and greater efficiency compared to Llama-\nand Mamba-based LLMs. These results establish xLSTM 7B as the fastest and most\nefficient 7B LLM, offering a solution for tasks that require large amounts of\ntest-time computation. Our work highlights xLSTM's potential as a foundational\narchitecture for methods building on heavy use of LLM inference. Our model\nweights, model code and training code are open-source.",
      "tldr_zh": "本研究提出了xLSTM 7B，一种基于xLSTM架构的7B参数大语言模型(LLM)，旨在解决LLM推理速度和效率的问题。xLSTM架构具有线性计算扩展和恒定内存占用的特性，显著提升了推理性能。实验表明，xLSTM 7B在下游任务上的表现与同类规模模型相当，同时推理速度远超Llama和Mamba架构的LLM，成为当前最快、最高效的7B参数LLM。该研究为需要大量推理计算的任务提供了解决方案，并验证了xLSTM作为LLM基础架构的潜力。模型权重和代码已开源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Code available at: https://github.com/NX-AI/xlstm and\n  https://github.com/NX-AI/xlstm-jax",
      "pdf_url": "http://arxiv.org/pdf/2503.13427v1",
      "published_date": "2025-03-17 17:54:55 UTC",
      "updated_date": "2025-03-17 17:54:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:58:09.323127"
    },
    {
      "arxiv_id": "2503.13419v1",
      "title": "Securing Virtual Reality Experiences: Unveiling and Tackling Cybersickness Attacks with Explainable AI",
      "title_zh": "保障虚拟现实体验：利用可解释AI揭示并应对晕动症攻击",
      "authors": [
        "Ripan Kumar Kundu",
        "Matthew Denton",
        "Genova Mongalo",
        "Prasad Calyam",
        "Khaza Anuarul Hoque"
      ],
      "abstract": "The synergy between virtual reality (VR) and artificial intelligence (AI),\nspecifically deep learning (DL)-based cybersickness detection models, has\nushered in unprecedented advancements in immersive experiences by automatically\ndetecting cybersickness severity and adaptively various mitigation techniques,\noffering a smooth and comfortable VR experience. While this DL-enabled\ncybersickness detection method provides promising solutions for enhancing user\nexperiences, it also introduces new risks since these models are vulnerable to\nadversarial attacks; a small perturbation of the input data that is visually\nundetectable to human observers can fool the cybersickness detection model and\ntrigger unexpected mitigation, thus disrupting user immersive experiences (UIX)\nand even posing safety risks. In this paper, we present a new type of VR\nattack, i.e., a cybersickness attack, which successfully stops the triggering\nof cybersickness mitigation by fooling DL-based cybersickness detection models\nand dramatically hinders the UIX. Next, we propose a novel explainable\nartificial intelligence (XAI)-guided cybersickness attack detection framework\nto detect such attacks in VR to ensure UIX and a comfortable VR experience. We\nevaluate the proposed attack and the detection framework using two\nstate-of-the-art open-source VR cybersickness datasets: Simulation 2021 and\nGameplay dataset. Finally, to verify the effectiveness of our proposed method,\nwe implement the attack and the XAI-based detection using a testbed with a\ncustom-built VR roller coaster simulation with an HTC Vive Pro Eye headset and\nperform a user study. Our study shows that such an attack can dramatically\nhinder the UIX. However, our proposed XAI-guided cybersickness attack detection\ncan successfully detect cybersickness attacks and trigger the proper\nmitigation, effectively reducing VR cybersickness.",
      "tldr_zh": "该研究首次揭示了虚拟现实(VR)中的\"晕动症攻击\"(cybersickness attack)，即通过对抗样本欺骗基于深度学习的晕动症检测模型，阻止其触发缓解机制，从而破坏用户体验(UIX)。研究者提出了一种基于可解释人工智能(XAI)的新型检测框架，能够有效识别此类攻击并触发正确的晕动症缓解措施。通过在两种开源VR数据集和自定义VR过山车模拟器(HTC Vive Pro Eye)上的实验验证，该方法成功检测攻击并显著减轻VR晕动症，为保障沉浸式体验安全提供了解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.CR",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2503.13419v1",
      "published_date": "2025-03-17 17:49:51 UTC",
      "updated_date": "2025-03-17 17:49:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:58:53.159963"
    },
    {
      "arxiv_id": "2503.13418v1",
      "title": "FLEX: A Framework for Learning Robot-Agnostic Force-based Skills Involving Sustained Contact Object Manipulation",
      "title_zh": "FLEX：一种面向持续接触式物体操作的机器人无关力控技能学习框架",
      "authors": [
        "Shijie Fang",
        "Wenchang Gao",
        "Shivam Goel",
        "Christopher Thierauf",
        "Matthias Scheutz",
        "Jivko Sinapov"
      ],
      "abstract": "Learning to manipulate objects efficiently, particularly those involving\nsustained contact (e.g., pushing, sliding) and articulated parts (e.g.,\ndrawers, doors), presents significant challenges. Traditional methods, such as\nrobot-centric reinforcement learning (RL), imitation learning, and hybrid\ntechniques, require massive training and often struggle to generalize across\ndifferent objects and robot platforms. We propose a novel framework for\nlearning object-centric manipulation policies in force space, decoupling the\nrobot from the object. By directly applying forces to selected regions of the\nobject, our method simplifies the action space, reduces unnecessary\nexploration, and decreases simulation overhead. This approach, trained in\nsimulation on a small set of representative objects, captures object dynamics\n-- such as joint configurations -- allowing policies to generalize effectively\nto new, unseen objects. Decoupling these policies from robot-specific dynamics\nenables direct transfer to different robotic platforms (e.g., Kinova, Panda,\nUR5) without retraining. Our evaluations demonstrate that the method\nsignificantly outperforms baselines, achieving over an order of magnitude\nimprovement in training efficiency compared to other state-of-the-art methods.\nAdditionally, operating in force space enhances policy transferability across\ndiverse robot platforms and object types. We further showcase the applicability\nof our method in a real-world robotic setting. For supplementary materials and\nvideos, please visit: https://tufts-ai-robotics-group.github.io/FLEX/",
      "tldr_zh": "该研究提出FLEX框架，用于学习与机器人无关的基于力的物体操控技能，特别针对持续接触操作（如推、滑动）和带铰接部件的物体（如抽屉、门）。该方法通过力空间中的物体中心策略，将机器人与物体解耦，直接在物体选定区域施加作用力，从而简化动作空间并减少训练开销。实验表明，该框架不仅显著超越基线方法（训练效率提升一个数量级），还能直接迁移到不同机器人平台（如Kinova、Panda、UR5）而无需重新训练，同时在真实机器人场景中验证了实用性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at IEEE-ICRA-2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13418v1",
      "published_date": "2025-03-17 17:49:47 UTC",
      "updated_date": "2025-03-17 17:49:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:00:06.537142"
    },
    {
      "arxiv_id": "2503.13415v1",
      "title": "A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives",
      "title_zh": "多智能体协同决策研究综述：场景、方法、挑战与展望",
      "authors": [
        "Weiqiang Jin",
        "Hongyang Du",
        "Biao Zhao",
        "Xingwu Tian",
        "Bohang Shi",
        "Guang Yang"
      ],
      "abstract": "With the rapid development of artificial intelligence, intelligent\ndecision-making techniques have gradually surpassed human levels in various\nhuman-machine competitions, especially in complex multi-agent cooperative task\nscenarios. Multi-agent cooperative decision-making involves multiple agents\nworking together to complete established tasks and achieve specific objectives.\nThese techniques are widely applicable in real-world scenarios such as\nautonomous driving, drone navigation, disaster rescue, and simulated military\nconfrontations. This paper begins with a comprehensive survey of the leading\nsimulation environments and platforms used for multi-agent cooperative\ndecision-making. Specifically, we provide an in-depth analysis for these\nsimulation environments from various perspectives, including task formats,\nreward allocation, and the underlying technologies employed. Subsequently, we\nprovide a comprehensive overview of the mainstream intelligent decision-making\napproaches, algorithms and models for multi-agent systems (MAS).\nTheseapproaches can be broadly categorized into five types: rule-based\n(primarily fuzzy logic), game theory-based, evolutionary algorithms-based, deep\nmulti-agent reinforcement learning (MARL)-based, and large language\nmodels(LLMs)reasoning-based. Given the significant advantages of MARL\nandLLMs-baseddecision-making methods over the traditional rule, game theory,\nand evolutionary algorithms, this paper focuses on these multi-agent methods\nutilizing MARL and LLMs-based techniques. We provide an in-depth discussion of\nthese approaches, highlighting their methodology taxonomies, advantages, and\ndrawbacks. Further, several prominent research directions in the future and\npotential challenges of multi-agent cooperative decision-making are also\ndetailed.",
      "tldr_zh": "本文对多智能体协同决策领域进行了全面综述，系统梳理了该技术在自动驾驶、无人机导航等现实场景中的应用。研究重点分析了五大类主流方法：基于规则的模糊逻辑、博弈论、进化算法、深度多智能体强化学习(MARL)和大语言模型(LLMs)推理，其中特别强调了MARL和LLMs方法相对于传统技术的显著优势。论文不仅详细比较了各类方法的分类体系、优缺点，还深入探讨了模拟环境平台的技术特点，包括任务形式、奖励分配等关键要素，最后指出了该领域未来的研究方向和潜在挑战。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "54 pages, 24 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13415v1",
      "published_date": "2025-03-17 17:45:46 UTC",
      "updated_date": "2025-03-17 17:45:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:59:05.174280"
    },
    {
      "arxiv_id": "2503.14546v1",
      "title": "The Impact of Artificial Intelligence on Emergency Medicine: A Review of Recent Advances",
      "title_zh": "人工智能对急诊医学的影响：近期进展回顾",
      "authors": [
        "Gustavo Correia",
        "Victor Alves",
        "Paulo Novais"
      ],
      "abstract": "Artificial Intelligence (AI) is revolutionizing emergency medicine by\nenhancing diagnostic processes and improving patient outcomes. This article\nprovides a review of the current applications of AI in emergency imaging\nstudies, focusing on the last five years of advancements. AI technologies,\nparticularly machine learning and deep learning, are pivotal in interpreting\ncomplex imaging data, offering rapid, accurate diagnoses and potentially\nsurpassing traditional diagnostic methods. Studies highlighted within the\narticle demonstrate AI's capabilities in accurately detecting conditions such\nas fractures, pneumothorax, and pulmonary diseases from various imaging\nmodalities including X-rays, CT scans, and MRIs. Furthermore, AI's ability to\npredict clinical outcomes like mechanical ventilation needs illustrates its\npotential in crisis resource optimization. Despite these advancements, the\nintegration of AI into clinical practice presents challenges such as data\nprivacy, algorithmic bias, and the need for extensive validation across diverse\nsettings. This review underscores the transformative potential of AI in\nemergency settings, advocating for a future where AI and clinical expertise\nsynergize to elevate patient care standards.",
      "tldr_zh": "这篇综述探讨了人工智能(AI)在急诊医学中的最新应用进展，重点关注过去五年AI在急诊影像诊断领域的突破。研究表明，机器学习和深度学习技术能快速准确地从X光、CT和MRI等影像中检测骨折、气胸等病症，其诊断能力可能超越传统方法。AI还能预测机械通气需求等临床结局，优化急诊资源分配。尽管面临数据隐私、算法偏见等挑战，AI与临床专业知识的结合有望显著提升急诊医疗水平。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "68T07"
      ],
      "primary_category": "eess.IV",
      "comment": "20 pages, 2 tables, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.14546v1",
      "published_date": "2025-03-17 17:45:00 UTC",
      "updated_date": "2025-03-17 17:45:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:59:14.218989"
    },
    {
      "arxiv_id": "2503.13414v1",
      "title": "Reward Adaptation Via Q-Manipulation",
      "title_zh": "基于Q函数操作的奖励自适应方法",
      "authors": [
        "Kevin Vora",
        "Yu Zhang"
      ],
      "abstract": "In this paper, we propose a new solution to reward adaptation (RA), the\nproblem where the learning agent adapts to a target reward function based on\none or multiple existing behaviors learned a priori under the same domain\ndynamics but different reward functions. Learning the target behavior from\nscratch is possible but often inefficient given the available source behaviors.\nOur work represents a new approach to RA via the manipulation of Q-functions.\nAssuming that the target reward function is a known function of the source\nreward functions, our approach to RA computes bounds of the Q function. We\nintroduce an iterative process to tighten the bounds, similar to value\niteration. This enables action pruning in the target domain before learning\neven starts. We refer to such a method as Q-Manipulation (Q-M). We formally\nprove that our pruning strategy does not affect the optimality of the returned\npolicy while empirically show that it improves the sample complexity. Q-M is\nevaluated in a variety of synthetic and simulation domains to demonstrate its\neffectiveness, generalizability, and practicality.",
      "tldr_zh": "本文提出了一种新的奖励适应(RA)方法——Q-Manipulation(Q-M)，旨在通过操纵Q函数来解决学习代理在相同领域动态但不同奖励函数下适应目标奖励函数的问题。该方法假设目标奖励函数是源奖励函数的已知函数，并计算Q函数的边界，通过类似值迭代的迭代过程收紧边界，从而在学习开始前对目标域进行动作剪枝。理论证明该剪枝策略不影响返回策略的最优性，实验表明其提高了样本效率。Q-M在多种合成和仿真域中验证了其有效性、通用性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13414v1",
      "published_date": "2025-03-17 17:42:54 UTC",
      "updated_date": "2025-03-17 17:42:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T14:59:38.629355"
    },
    {
      "arxiv_id": "2503.13413v3",
      "title": "DLPO: Towards a Robust, Efficient, and Generalizable Prompt Optimization Framework from a Deep-Learning Perspective",
      "title_zh": "DLPO：从深度学习视角构建一个稳健、高效且可泛化的提示优化框架",
      "authors": [
        "Dengyun Peng",
        "Yuhang Zhou",
        "Qiguang Chen",
        "Jinhao Liu",
        "Jingjing Chen",
        "Libo Qin"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable success across diverse\ntasks, largely driven by well-designed prompts. However, crafting and selecting\nsuch prompts often requires considerable human effort, significantly limiting\nits scalability. To mitigate this, recent studies have explored automated\nprompt optimization as a promising solution. Despite these efforts, existing\nmethods still face critical challenges in robustness, efficiency, and\ngeneralization. To systematically address these challenges, we first conduct an\nempirical analysis to identify the limitations of current reflection-based\nprompt optimization paradigm. Building on these insights, we propose 7\ninnovative approaches inspired by traditional deep learning paradigms for\nprompt optimization (DLPO), seamlessly integrating these concepts into\ntext-based gradient optimization. Through these advancements, we progressively\ntackle the aforementioned challenges and validate our methods through extensive\nexperimentation. We hope our study not only provides valuable guidance for\nfuture research but also offers a comprehensive understanding of the challenges\nand potential solutions in prompt optimization. Our code is available at\nhttps://github.com/sfasfaffa/DLPO.",
      "tldr_zh": "该研究提出了DLPO框架，从深度学习视角解决当前提示优化方法在鲁棒性、效率和泛化性方面的关键挑战。通过实证分析现有基于反思的提示优化范式局限，研究者创新性地提出7种受传统深度学习启发的优化方法，并将其融入基于文本的梯度优化流程。实验验证表明，该框架显著提升了自动化提示优化的性能表现，为未来研究提供了系统性指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.13413v3",
      "published_date": "2025-03-17 17:42:51 UTC",
      "updated_date": "2025-03-19 14:18:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:00:34.173846"
    },
    {
      "arxiv_id": "2503.13404v1",
      "title": "Fed-Joint: Joint Modeling of Nonlinear Degradation Signals and Failure Events for Remaining Useful Life Prediction using Federated Learning",
      "title_zh": "Fed-Joint：基于联邦学习的非线性退化信号与故障事件联合建模剩余使用寿命预测方法",
      "authors": [
        "Cheoljoon Jeong",
        "Xubo Yue",
        "Seokhyun Chung"
      ],
      "abstract": "Many failure mechanisms of machinery are closely related to the behavior of\ncondition monitoring (CM) signals. To achieve a cost-effective preventive\nmaintenance strategy, accurate remaining useful life (RUL) prediction based on\nthe signals is of paramount importance. However, the CM signals are often\nrecorded at different factories and production lines, with limited amounts of\ndata. Unfortunately, these datasets have rarely been shared between the sites\ndue to data confidentiality and ownership issues, a lack of computing and\nstorage power, and high communication costs associated with data transfer\nbetween sites and a data center. Another challenge in real applications is that\nthe CM signals are often not explicitly specified \\textit{a priori}, meaning\nthat existing methods, which often usually a parametric form, may not be\napplicable. To address these challenges, we propose a new prognostic framework\nfor RUL prediction using the joint modeling of nonlinear degradation signals\nand time-to-failure data within a federated learning scheme. The proposed\nmethod constructs a nonparametric degradation model using a federated\nmulti-output Gaussian process and then employs a federated survival model to\npredict failure times and probabilities for in-service machinery. The\nsuperiority of the proposed method over other alternatives is demonstrated\nthrough comprehensive simulation studies and a case study using turbofan engine\ndegradation signal data that include run-to-failure events.",
      "tldr_zh": "该研究提出Fed-Joint框架，利用联邦学习联合建模非线性退化信号和故障事件数据以预测设备剩余使用寿命(RUL)。该方法通过联邦多输出高斯过程建立非参数退化模型，并结合联邦生存分析模型预测运行设备的故障时间和概率，解决了工业数据分散保密、信号先验形式未知的难题。在涡扇发动机退化数据的案例验证中，该方法显著优于现有方案，为跨工厂协同维护提供了隐私保护解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13404v1",
      "published_date": "2025-03-17 17:34:34 UTC",
      "updated_date": "2025-03-17 17:34:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:01:19.847683"
    },
    {
      "arxiv_id": "2503.13401v1",
      "title": "Using the Tools of Cognitive Science to Understand Large Language Models at Different Levels of Analysis",
      "title_zh": "运用认知科学工具从不同分析层面理解大型语言模型",
      "authors": [
        "Alexander Ku",
        "Declan Campbell",
        "Xuechunzi Bai",
        "Jiayi Geng",
        "Ryan Liu",
        "Raja Marjieh",
        "R. Thomas McCoy",
        "Andrew Nam",
        "Ilia Sucholutsky",
        "Veniamin Veselovsky",
        "Liyi Zhang",
        "Jian-Qiao Zhu",
        "Thomas L. Griffiths"
      ],
      "abstract": "Modern artificial intelligence systems, such as large language models, are\nincreasingly powerful but also increasingly hard to understand. Recognizing\nthis problem as analogous to the historical difficulties in understanding the\nhuman mind, we argue that methods developed in cognitive science can be useful\nfor understanding large language models. We propose a framework for applying\nthese methods based on Marr's three levels of analysis. By revisiting\nestablished cognitive science techniques relevant to each level and\nillustrating their potential to yield insights into the behavior and internal\norganization of large language models, we aim to provide a toolkit for making\nsense of these new kinds of minds.",
      "tldr_zh": "该论文提出借鉴认知科学方法来理解大型语言模型(LLMs)，采用Marr的三层次分析框架（计算层、算法层、实现层）。作者认为认知科学中成熟的实验技术可以帮助解析LLMs的行为模式和内部机制，为解决当前AI系统\"黑箱\"问题提供方法论工具。通过系统梳理各分析层级对应的认知科学研究范式，该研究为理解这类新型\"智能体\"构建了跨学科分析框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13401v1",
      "published_date": "2025-03-17 17:33:54 UTC",
      "updated_date": "2025-03-17 17:33:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:01:15.356755"
    },
    {
      "arxiv_id": "2503.13399v1",
      "title": "MicroVQA: A Multimodal Reasoning Benchmark for Microscopy-Based Scientific Research",
      "title_zh": "MicroVQA：面向显微科学研究的跨模态推理基准",
      "authors": [
        "James Burgess",
        "Jeffrey J Nirschl",
        "Laura Bravo-Sánchez",
        "Alejandro Lozano",
        "Sanket Rajan Gupte",
        "Jesus G. Galaz-Montoya",
        "Yuhui Zhang",
        "Yuchang Su",
        "Disha Bhowmik",
        "Zachary Coman",
        "Sarina M. Hasan",
        "Alexandra Johannesson",
        "William D. Leineweber",
        "Malvika G Nair",
        "Ridhi Yarlagadda",
        "Connor Zuraski",
        "Wah Chiu",
        "Sarah Cohen",
        "Jan N. Hansen",
        "Manuel D Leonetti",
        "Chad Liu",
        "Emma Lundberg",
        "Serena Yeung-Levy"
      ],
      "abstract": "Scientific research demands sophisticated reasoning over multimodal data, a\nchallenge especially prevalent in biology. Despite recent advances in\nmultimodal large language models (MLLMs) for AI-assisted research, existing\nmultimodal reasoning benchmarks only target up to college-level difficulty,\nwhile research-level benchmarks emphasize lower-level perception, falling short\nof the complex multimodal reasoning needed for scientific discovery. To bridge\nthis gap, we introduce MicroVQA, a visual-question answering (VQA) benchmark\ndesigned to assess three reasoning capabilities vital in research workflows:\nexpert image understanding, hypothesis generation, and experiment proposal.\nMicroVQA consists of 1,042 multiple-choice questions (MCQs) curated by biology\nexperts across diverse microscopy modalities, ensuring VQA samples represent\nreal scientific practice. In constructing the benchmark, we find that standard\nMCQ generation methods induce language shortcuts, motivating a new two-stage\npipeline: an optimized LLM prompt structures question-answer pairs into MCQs;\nthen, an agent-based `RefineBot' updates them to remove shortcuts. Benchmarking\non state-of-the-art MLLMs reveal a peak performance of 53\\%; models with\nsmaller LLMs only slightly underperform top models, suggesting that\nlanguage-based reasoning is less challenging than multimodal reasoning; and\ntuning with scientific articles enhances performance. Expert analysis of\nchain-of-thought responses shows that perception errors are the most frequent,\nfollowed by knowledge errors and then overgeneralization errors. These insights\nhighlight the challenges in multimodal scientific reasoning, showing MicroVQA\nis a valuable resource advancing AI-driven biomedical research. MicroVQA is\navailable at https://huggingface.co/datasets/jmhb/microvqa, and project page at\nhttps://jmhb0.github.io/microvqa.",
      "tldr_zh": "该研究提出了MicroVQA，一个针对显微镜图像的多模态推理基准，旨在评估科学研究所需的专家图像理解、假设生成和实验设计能力。基准包含1,042道由生物学专家精心设计的选择题，涵盖多种显微镜技术，并采用两阶段方法生成问题以避免语言捷径。实验表明，现有最先进的多模态大语言模型（MLLMs）最高准确率仅为53%，揭示了多模态科学推理的挑战，尤其是感知错误最为常见。MicroVQA为推进AI驱动的生物医学研究提供了重要资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "q-bio.CB"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025 (Conference on Computer Vision and Pattern Recognition)\n  Project page at https://jmhb0.github.io/microvqa Benchmark at\n  https://huggingface.co/datasets/jmhb/microvqa",
      "pdf_url": "http://arxiv.org/pdf/2503.13399v1",
      "published_date": "2025-03-17 17:33:10 UTC",
      "updated_date": "2025-03-17 17:33:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:01:34.573190"
    },
    {
      "arxiv_id": "2503.13385v1",
      "title": "Scale Efficient Training for Large Datasets",
      "title_zh": "大规模数据集的高效缩放训练",
      "authors": [
        "Qing Zhou",
        "Junyu Gao",
        "Qi Wang"
      ],
      "abstract": "The rapid growth of dataset scales has been a key driver in advancing deep\nlearning research. However, as dataset scale increases, the training process\nbecomes increasingly inefficient due to the presence of low-value samples,\nincluding excessive redundant samples, overly challenging samples, and\ninefficient easy samples that contribute little to model improvement.To address\nthis challenge, we propose Scale Efficient Training (SeTa) for large datasets,\na dynamic sample pruning approach that losslessly reduces training time. To\nremove low-value samples, SeTa first performs random pruning to eliminate\nredundant samples, then clusters the remaining samples according to their\nlearning difficulty measured by loss. Building upon this clustering, a sliding\nwindow strategy is employed to progressively remove both overly challenging and\ninefficient easy clusters following an easy-to-hard curriculum.We conduct\nextensive experiments on large-scale synthetic datasets, including ToCa, SS1M,\nand ST+MJ, each containing over 3 million samples.SeTa reduces training costs\nby up to 50\\% while maintaining or improving performance, with minimal\ndegradation even at 70\\% cost reduction. Furthermore, experiments on various\nscale real datasets across various backbones (CNNs, Transformers, and Mambas)\nand diverse tasks (instruction tuning, multi-view stereo, geo-localization,\ncomposed image retrieval, referring image segmentation) demonstrate the\npowerful effectiveness and universality of our approach. Code is available at\nhttps://github.com/mrazhou/SeTa.",
      "tldr_zh": "该研究提出了一种针对大规模数据集的高效训练方法SeTa，通过动态样本剪枝策略显著提升训练效率。该方法首先随机剪除冗余样本，然后基于样本损失值进行聚类，并采用滑动窗口策略按\"易到难\"课程逐步移除过难和过易样本簇。实验表明，SeTa在多个超300万样本的数据集上可减少50%训练成本而不降低性能，甚至在70%成本缩减时仍保持良好效果，且适用于CNN、Transformer和Mamba等多种架构及多类视觉任务。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13385v1",
      "published_date": "2025-03-17 17:13:43 UTC",
      "updated_date": "2025-03-17 17:13:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:02:03.625096"
    },
    {
      "arxiv_id": "2503.13383v1",
      "title": "Cream of the Crop: Harvesting Rich, Scalable and Transferable Multi-Modal Data for Instruction Fine-Tuning",
      "title_zh": "精粹筛选：面向指令微调的丰富、可扩展且可迁移多模态数据采集",
      "authors": [
        "Mengyao Lyu",
        "Yan Li",
        "Huasong Zhong",
        "Wenhao Yang",
        "Hui Chen",
        "Jungong Han",
        "Guiguang Ding",
        "Zhenheng Yang"
      ],
      "abstract": "The hypothesis that pretrained large language models (LLMs) necessitate only\nminimal supervision during the fine-tuning (SFT) stage (Zhou et al., 2024) has\nbeen substantiated by recent advancements in data curation and selection\nresearch. However, their stability and generalizability are compromised due to\nthe vulnerability to experimental setups and validation protocols, falling\nshort of surpassing random sampling (Diddee & Ippolito, 2024; Xia et al.,\n2024b). Built upon LLMs, multi-modal LLMs (MLLMs), combined with the sheer\ntoken volume and heightened heterogeneity of data sources, amplify both the\nsignificance and complexity of data selection.\n  To harvest multi-modal instructional data in a robust and efficient manner,\nwe re-define the granularity of the quality metric by decomposing it into 14\nvision-language-related capabilities, and introduce multi-modal rich scorers to\nevaluate the capabilities of each data candidate. To promote diversity, in\nlight of the inherent objective of the alignment stage, we take interaction\nstyle as diversity indicator and use a multi-modal rich styler to identify data\ninstruction patterns. In doing so, our multi-modal rich scorers and styler\n(mmSSR) guarantee that high-scoring information is conveyed to users in\ndiversified forms. Free from embedding-based clustering or greedy sampling,\nmmSSR efficiently scales to millions of data with varying budget constraints,\nsupports customization for general or specific capability acquisition, and\nfacilitates training-free generalization to new domains for curation. Across\n10+ experimental settings, validated by 14 multi-modal benchmarks, we\ndemonstrate consistent improvements over random sampling, baseline strategies\nand state-of-the-art selection methods, achieving 99.1% of full performance\nwith only 30% of the 2.6M data.",
      "tldr_zh": "该研究提出了一种高效且鲁棒的多模态指令数据筛选方法，通过重新定义质量度量的粒度，将其分解为14种视觉语言相关能力，并引入多模态丰富评分器（mmSSR）评估数据候选者的能力。为了促进多样性，研究以交互风格为多样性指标，利用多模态丰富风格器识别数据指令模式，确保高价值信息以多样化形式呈现。该方法无需嵌入聚类或贪婪采样，可高效扩展到数百万数据，支持通用或特定能力的定制化获取，并在10+实验设置和14个多模态基准测试中，仅用30%的2.6M数据即可达到99.1%的完整性能，显著优于随机采样和现有选择方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "update comparison with sota and analysis",
      "pdf_url": "http://arxiv.org/pdf/2503.13383v1",
      "published_date": "2025-03-17 17:11:22 UTC",
      "updated_date": "2025-03-17 17:11:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:02:15.209731"
    },
    {
      "arxiv_id": "2503.13377v1",
      "title": "TimeZero: Temporal Video Grounding with Reasoning-Guided LVLM",
      "title_zh": "TimeZero：基于推理引导的 LVLM 实现时序视频定位",
      "authors": [
        "Ye Wang",
        "Boshen Xu",
        "Zihao Yue",
        "Zihan Xiao",
        "Ziheng Wang",
        "Liang Zhang",
        "Dingyi Yang",
        "Wenxuan Wang",
        "Qin Jin"
      ],
      "abstract": "We introduce TimeZero, a reasoning-guided LVLM designed for the temporal\nvideo grounding (TVG) task. This task requires precisely localizing relevant\nvideo segments within long videos based on a given language query. TimeZero\ntackles this challenge by extending the inference process, enabling the model\nto reason about video-language relationships solely through reinforcement\nlearning. To evaluate the effectiveness of TimeZero, we conduct experiments on\ntwo benchmarks, where TimeZero achieves state-of-the-art performance on\nCharades-STA. Code is available at https://github.com/www-Ye/TimeZero.",
      "tldr_zh": "该研究提出了TimeZero模型，一种基于推理引导的LVLM（大规模视觉语言模型），专门用于时序视频定位任务（TVG）。该方法通过扩展推理过程，仅依靠强化学习让模型理解视频与语言的关系，从而在长视频中精准定位目标片段。实验表明，TimeZero在Charades-STA基准测试上达到了最先进的性能表现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Code: https://github.com/www-Ye/TimeZero",
      "pdf_url": "http://arxiv.org/pdf/2503.13377v1",
      "published_date": "2025-03-17 17:04:20 UTC",
      "updated_date": "2025-03-17 17:04:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:02:42.647779"
    },
    {
      "arxiv_id": "2503.13360v1",
      "title": "Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning",
      "title_zh": "通过伴随式视觉条件化缓解多模态长链推理中的视觉遗忘问题",
      "authors": [
        "Hai-Long Sun",
        "Zhun Sun",
        "Houwen Peng",
        "Han-Jia Ye"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated\nenhanced reasoning capabilities, evolving from Chain-of-Thought (CoT) prompting\nto advanced, product-oriented solutions like OpenAI o1. During our\nre-implementation of this model, we noticed that in multimodal tasks requiring\nvisual input (e.g., geometry problems), Multimodal LLMs (MLLMs) struggle to\nmaintain focus on the visual information, in other words, MLLMs suffer from a\ngradual decline in attention to visual information as reasoning progresses,\ncausing text-over-relied outputs. To investigate this, we ablate image inputs\nduring long-chain reasoning. Concretely, we truncate the reasoning process\nmidway, then re-complete the reasoning process with the input image removed. We\nobserve only a ~2% accuracy drop on MathVista's test-hard subset, revealing the\nmodel's textual outputs dominate the following reasoning process. Motivated by\nthis, we propose Take-along Visual Conditioning (TVC), a strategy that shifts\nimage input to critical reasoning stages and compresses redundant visual tokens\nvia dynamic pruning. This methodology helps the model retain attention to the\nvisual components throughout the reasoning. Our approach achieves\nstate-of-the-art performance on average across five mathematical reasoning\nbenchmarks (+3.4% vs previous sota), demonstrating the effectiveness of TVC in\nenhancing multimodal reasoning systems.",
      "tldr_zh": "该研究针对多模态大语言模型(MLLMs)在长链推理过程中逐渐忽视视觉信息的问题，提出了一种称为“Take-along Visual Conditioning (TVC)”的策略。TVC通过将图像输入转移到关键推理阶段，并利用动态剪枝压缩冗余视觉信息，有效缓解了视觉遗忘现象。实验表明，该方法在五个数学推理基准测试中平均提升了3.4%的性能，显著增强了多模态推理系统的表现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "The project page is available at\n  https://sun-hailong.github.io/projects/TVC",
      "pdf_url": "http://arxiv.org/pdf/2503.13360v1",
      "published_date": "2025-03-17 16:45:12 UTC",
      "updated_date": "2025-03-17 16:45:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:04:15.429928"
    },
    {
      "arxiv_id": "2503.16525v1",
      "title": "KVShare: Semantic-Aware Key-Value Cache Sharing for Efficient Large Language Model Inference",
      "title_zh": "KVShare：面向高效大语言模型推理的语义感知键值缓存共享技术",
      "authors": [
        "Huan Yang",
        "Renji Zhang",
        "Deyu Zhang"
      ],
      "abstract": "This paper presents KVShare, a multi-user Key-Value (KV) Cache sharing\ntechnology based on semantic similarity, designed to enhance the inference\nefficiency of Large Language Models (LLMs) and Multimodal Large Language Models\n(MLLMs). Addressing the limitations of existing prefix caching (strict text\nprefix matching) and semantic caching (loss of response diversity), KVShare\nachieves fine-grained KV cache reuse through semantic alignment algorithms and\ndifferential editing operations. Experiments on real-world user conversation\ndatasets demonstrate that KVShare improves KV cache hit rates by over 60%,\nwhile maintaining output quality comparable to full computation (no significant\ndegradation in BLEU and Rouge-L metrics). This approach effectively reduces GPU\nresource consumption and is applicable to scenarios with repetitive queries,\nsuch as healthcare and education.",
      "tldr_zh": "本文提出KVShare技术，通过语义感知的Key-Value缓存共享机制提升大语言模型(LLMs)和多模态大语言模型(MLLMs)的推理效率。该方法突破现有前缀缓存（严格文本前缀匹配）和语义缓存（响应多样性损失）的限制，采用语义对齐算法和差分编辑操作实现细粒度的KV缓存复用。实验表明，KVShare在真实对话数据集上使KV缓存命中率提升60%以上，同时保持与完整计算相当的输出质量（BLEU和Rouge-L指标无显著下降），可有效降低GPU资源消耗，特别适用于医疗、教育等重复查询场景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16525v1",
      "published_date": "2025-03-17 16:43:35 UTC",
      "updated_date": "2025-03-17 16:43:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:09:12.629897"
    },
    {
      "arxiv_id": "2503.13343v1",
      "title": "Scalable Runtime Architecture for Data-driven, Hybrid HPC and ML Workflow Applications",
      "title_zh": "面向数据驱动、混合HPC与ML工作流应用的可扩展运行时架构",
      "authors": [
        "Andre Merzky",
        "Mikhail Titov",
        "Matteo Turilli",
        "Ozgur Kilic",
        "Tianle Wang",
        "Shantenu Jha"
      ],
      "abstract": "Hybrid workflows combining traditional HPC and novel ML methodologies are\ntransforming scientific computing. This paper presents the architecture and\nimplementation of a scalable runtime system that extends RADICAL-Pilot with\nservice-based execution to support AI-out-HPC workflows. Our runtime system\nenables distributed ML capabilities, efficient resource management, and\nseamless HPC/ML coupling across local and remote platforms. Preliminary\nexperimental results show that our approach manages concurrent execution of ML\nmodels across local and remote HPC/cloud resources with minimal architectural\noverheads. This lays the foundation for prototyping three representative\ndata-driven workflow applications and executing them at scale on\nleadership-class HPC platforms.",
      "tldr_zh": "本研究提出了一种可扩展的运行时架构，旨在支持融合传统高性能计算(HPC)与机器学习(ML)的混合工作流应用。该架构基于RADICAL-Pilot系统，通过服务化执行模式实现了分布式ML能力、高效的资源管理以及本地与远程平台间的无缝HPC/ML协同。实验表明，该系统能以最小架构开销在本地和远程HPC/云资源上并发执行ML模型，为在领先级HPC平台上规模化运行三类典型数据驱动型工作流应用奠定了基础。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13343v1",
      "published_date": "2025-03-17 16:21:48 UTC",
      "updated_date": "2025-03-17 16:21:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:10:54.494081"
    },
    {
      "arxiv_id": "2503.13342v1",
      "title": "Valid Text-to-SQL Generation with Unification-based DeepStochLog",
      "title_zh": "基于统一深层随机逻辑的有效文本到SQL生成",
      "authors": [
        "Ying Jiao",
        "Luc De Raedt",
        "Giuseppe Marra"
      ],
      "abstract": "Large language models have been used to translate natural language questions\nto SQL queries. Without hard constraints on syntax and database schema, they\noccasionally produce invalid queries that are not executable. These failures\nlimit the usage of these systems in real-life scenarios. We propose a\nneurosymbolic framework that imposes SQL syntax and schema constraints with\nunification-based definite clause grammars and thus guarantees the generation\nof valid queries. Our framework also builds a bi-directional interface to\nlanguage models to leverage their natural language understanding abilities. The\nevaluation results on a subset of SQL grammars show that all our output queries\nare valid. This work is the first step towards extending language models with\nunification-based grammars. We demonstrate this extension enhances the\nvalidity, execution accuracy, and ground truth alignment of the underlying\nlanguage model by a large margin. Our code is available at\nhttps://github.com/ML-KULeuven/deepstochlog-lm.",
      "tldr_zh": "本研究提出了一种基于统一逻辑的神经符号框架DeepStochLog，通过结合确定子句语法(DCG)强制约束SQL语法和数据库模式，确保生成的文本转SQL查询100%有效。该框架构建了与语言模型的双向接口，在保持其自然语言理解能力的同时，显著提升了查询的有效性、执行准确性和真实对齐度。实验表明，该方法在SQL语法子集上实现了全有效查询生成，为扩展语言模型与统一语法系统的结合迈出了重要一步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13342v1",
      "published_date": "2025-03-17 16:21:10 UTC",
      "updated_date": "2025-03-17 16:21:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:11:12.476229"
    },
    {
      "arxiv_id": "2503.13335v1",
      "title": "Reliable and Efficient Amortized Model-based Evaluation",
      "title_zh": "可靠高效的分摊式模型评估方法",
      "authors": [
        "Sang Truong",
        "Yuheng Tu",
        "Percy Liang",
        "Bo Li",
        "Sanmi Koyejo"
      ],
      "abstract": "Comprehensive evaluations of language models (LM) during both development and\ndeployment phases are necessary because these models possess numerous\ncapabilities (e.g., mathematical reasoning, legal support, or medical\ndiagnostic) as well as safety risks (e.g., racial bias, toxicity, or\nmisinformation). The average score across a wide range of benchmarks provides a\nsignal that helps guide the use of these LMs in practice. Currently, holistic\nevaluations are costly due to the large volume of benchmark questions, making\nfrequent evaluations impractical. A popular attempt to lower the cost is to\ncompute the average score on a subset of the benchmark. This approach,\nunfortunately, often renders an unreliable measure of LM performance because\nthe average score is often confounded with the difficulty of the questions in\nthe benchmark subset. Item response theory (IRT) was designed to address this\nchallenge, providing a reliable measurement by careful controlling for question\ndifficulty. Unfortunately, question difficulty is expensive to estimate. Facing\nthis challenge, we train a model that predicts question difficulty from its\ncontent, enabling a reliable measurement at a fraction of the cost. In\naddition, we leverage this difficulty predictor to further improve the\nevaluation efficiency through training a question generator given a difficulty\nlevel. This question generator is essential in adaptive testing, where, instead\nof using a random subset of the benchmark questions, informative questions are\nadaptively chosen based on the current estimation of LLM performance.\nExperiments on 22 common natural language benchmarks and 172 LMs show that this\napproach is more reliable and efficient compared to current common practice.",
      "tldr_zh": "本研究提出了一种可靠且高效的语言模型（LM）评估方法，通过结合项目反应理论（IRT）和难度预测模型来解决当前基准测试成本高、可靠性低的问题。该方法首先训练一个从问题内容预测难度的模型，显著降低了IRT所需的难度评估成本；进而开发了基于难度级别的问题生成器，支持自适应测试以提升评估效率。实验表明，在22个自然语言基准和172个语言模型上的测试中，该方法相比随机子集评估更可靠高效，为语言模型的开发和部署提供了实用的评估解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13335v1",
      "published_date": "2025-03-17 16:15:02 UTC",
      "updated_date": "2025-03-17 16:15:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:08:36.642321"
    },
    {
      "arxiv_id": "2503.13580v1",
      "title": "LLM Test Generation via Iterative Hybrid Program Analysis",
      "title_zh": "基于迭代式混合程序分析的LLM测试生成方法",
      "authors": [
        "Sijia Gu",
        "Noor Nashid",
        "Ali Mesbah"
      ],
      "abstract": "Automating unit test generation remains a significant challenge, particularly\nfor complex methods in real-world projects. While Large Language Models (LLMs)\nhave made strides in code generation, they struggle to achieve high branch\ncoverage due to their limited ability to reason about intricate control flow\nstructures. To address this limitation, we introduce Panta, a technique that\nemulates the iterative process human developers follow when analyzing code and\nconstructing test cases. Panta integrates static control flow analysis and\ndynamic code coverage analysis to systematically guide LLMs in identifying\nuncovered execution paths and generating better test cases. By incorporating an\niterative feedback-driven mechanism, our technique continuously refines test\ngeneration based on static and dynamic path coverage insights, ensuring more\ncomprehensive and effective testing. Our empirical evaluation, conducted on\nclasses with high cyclomatic complexity from open-source projects, demonstrates\nthat Panta achieves 26% higher line coverage and 23% higher branch coverage\ncompared to the state-of-the-art.",
      "tldr_zh": "该研究提出Panta技术，通过结合静态控制流分析和动态代码覆盖率分析的混合程序分析方法，指导大语言模型(LLMs)生成更有效的单元测试用例。该系统模拟开发者迭代分析代码的过程，采用反馈驱动机制持续优化测试生成，特别针对复杂控制流结构。实验表明，在开源项目高圈复杂度类上，Panta比现有最佳方法提高26%行覆盖率和23%分支覆盖率。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13580v1",
      "published_date": "2025-03-17 16:10:38 UTC",
      "updated_date": "2025-03-17 16:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:08:39.320884"
    },
    {
      "arxiv_id": "2503.13330v1",
      "title": "LEAVS: An LLM-based Labeler for Abdominal CT Supervision",
      "title_zh": "LEAVS：基于大语言模型的腹部CT监督标注系统",
      "authors": [
        "Ricardo Bigolin Lanfredi",
        "Yan Zhuang",
        "Mark Finkelstein",
        "Praveen Thoppey Srinivasan Balamuralikrishna",
        "Luke Krembs",
        "Brandon Khoury",
        "Arthi Reddy",
        "Pritam Mukherjee",
        "Neil M. Rofsky",
        "Ronald M. Summers"
      ],
      "abstract": "Extracting structured labels from radiology reports has been employed to\ncreate vision models to simultaneously detect several types of abnormalities.\nHowever, existing works focus mainly on the chest region. Few works have been\ninvestigated on abdominal radiology reports due to more complex anatomy and a\nwider range of pathologies in the abdomen. We propose LEAVS (Large language\nmodel Extractor for Abdominal Vision Supervision). This labeler can annotate\nthe certainty of presence and the urgency of seven types of abnormalities for\nnine abdominal organs on CT radiology reports. To ensure broad coverage, we\nchose abnormalities that encompass most of the finding types from CT reports.\nOur approach employs a specialized chain-of-thought prompting strategy for a\nlocally-run LLM using sentence extraction and multiple-choice questions in a\ntree-based decision system. We demonstrate that the LLM can extract several\nabnormality types across abdominal organs with an average F1 score of 0.89,\nsignificantly outperforming competing labelers and humans. Additionally, we\nshow that extraction of urgency labels achieved performance comparable to human\nannotations. Finally, we demonstrate that the abnormality labels contain\nvaluable information for training a single vision model that classifies several\norgans as normal or abnormal. We release our code and structured annotations\nfor a public CT dataset containing over 1,000 CT volumes.",
      "tldr_zh": "该研究提出LEAVS系统，一种基于大型语言模型(LLM)的腹部CT报告标注工具，专门解决腹部放射学报告标注中解剖结构复杂、病理类型广泛等挑战。该系统采用链式思维提示策略，通过语句提取和多选题树状决策系统，能够标注9种腹部器官中7类异常的存在确定性及紧急程度，平均F1值达0.89，显著优于现有标注工具和人工标注。研究还证明这些标注信息可用于训练单一视觉模型来同时分类多个器官的正常/异常状态，并公开了包含1000多个CT扫描的标注数据集和代码。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13330v1",
      "published_date": "2025-03-17 16:09:22 UTC",
      "updated_date": "2025-03-17 16:09:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:12:17.928637"
    },
    {
      "arxiv_id": "2503.13579v1",
      "title": "ASMR: Adaptive Skeleton-Mesh Rigging and Skinning via 2D Generative Prior",
      "title_zh": "ASMR：基于2D生成先验的自适应骨架-网格绑定与蒙皮",
      "authors": [
        "Seokhyeon Hong",
        "Soojin Choi",
        "Chaelin Kim",
        "Sihun Cha",
        "Junyong Noh"
      ],
      "abstract": "Despite the growing accessibility of skeletal motion data, integrating it for\nanimating character meshes remains challenging due to diverse configurations of\nboth skeletons and meshes. Specifically, the body scale and bone lengths of the\nskeleton should be adjusted in accordance with the size and proportions of the\nmesh, ensuring that all joints are accurately positioned within the character\nmesh. Furthermore, defining skinning weights is complicated by variations in\nskeletal configurations, such as the number of joints and their hierarchy, as\nwell as differences in mesh configurations, including their connectivity and\nshapes. While existing approaches have made efforts to automate this process,\nthey hardly address the variations in both skeletal and mesh configurations. In\nthis paper, we present a novel method for the automatic rigging and skinning of\ncharacter meshes using skeletal motion data, accommodating arbitrary\nconfigurations of both meshes and skeletons. The proposed method predicts the\noptimal skeleton aligned with the size and proportion of the mesh as well as\ndefines skinning weights for various mesh-skeleton configurations, without\nrequiring explicit supervision tailored to each of them. By incorporating\nDiffusion 3D Features (Diff3F) as semantic descriptors of character meshes, our\nmethod achieves robust generalization across different configurations. To\nassess the performance of our method in comparison to existing approaches, we\nconducted comprehensive evaluations encompassing both quantitative and\nqualitative analyses, specifically examining the predicted skeletons, skinning\nweights, and deformation quality.",
      "tldr_zh": "该论文提出ASMR方法，利用2D生成先验实现自适应的骨骼-网格绑定和蒙皮技术。通过结合Diffusion 3D Features(Diff3F)作为语义描述符，该方法能自动预测与网格尺寸比例匹配的最优骨骼结构，并为各种网格-骨骼配置生成蒙皮权重，无需针对每种配置进行专门监督训练。实验表明，该方法在预测骨骼准确性、蒙皮权重质量和变形效果方面均优于现有技术，有效解决了不同骨骼层级结构和网格连接方式带来的适配难题。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GR",
      "comment": "Eurographics 2025; Project Page\n  https://seokhyeonhong.github.io/projects/asmr/",
      "pdf_url": "http://arxiv.org/pdf/2503.13579v1",
      "published_date": "2025-03-17 15:59:02 UTC",
      "updated_date": "2025-03-17 15:59:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:11:33.481968"
    },
    {
      "arxiv_id": "2503.13316v1",
      "title": "RainScaleGAN: a Conditional Generative Adversarial Network for Rainfall Downscaling",
      "title_zh": "RainScaleGAN：一种用于降雨降尺度建模的条件生成对抗网络",
      "authors": [
        "Marcello Iotti",
        "Paolo Davini",
        "Jost von Hardenberg",
        "Giuseppe Zappa"
      ],
      "abstract": "To this day, accurately simulating local-scale precipitation and reliably\nreproducing its distribution remains a challenging task. The limited horizontal\nresolution of Global Climate Models is among the primary factors undermining\ntheir skill in this context. The physical mechanisms driving the onset and\ndevelopment of precipitation, especially in extreme events, operate at\nspatio-temporal scales smaller than those numerically resolved, thus struggling\nto be captured accurately. In order to circumvent this limitation, several\ndownscaling approaches have been developed over the last decades to address the\ndiscrepancy between the spatial resolution of models output and the resolution\nrequired by local-scale applications. In this paper, we introduce RainScaleGAN,\na conditional deep convolutional Generative Adversarial Network (GAN) for\nprecipitation downscaling. GANs have been effectively used in image\nsuper-resolution, an approach highly relevant for downscaling tasks.\nRainScaleGAN's capabilities are tested in a perfect-model setup, where the\nspatial resolution of a precipitation dataset is artificially degraded from\n0.25$^{\\circ}\\times$0.25$^{\\circ}$ to 2$^{\\circ}\\times$2$^\\circ$, and\nRainScaleGAN is used to restore it. The developed model outperforms one of the\nleading precipitation downscaling method found in the literature. RainScaleGAN\nnot only generates a synthetic dataset featuring plausible high-resolution\nspatial patterns and intensities, but also produces a precipitation\ndistribution with statistics closely mirroring those of the ground-truth\ndataset. Given that RainScaleGAN's approach is agnostic with respect to the\nunderlying physics, the method has the potential to be applied to other\nphysical variables such as surface winds or temperature.",
      "tldr_zh": "该研究提出了RainScaleGAN，一种基于条件生成对抗网络(Conditional GAN)的降水降尺度方法，旨在解决全球气候模型(GCMs)空间分辨率不足导致的局部降水模拟难题。该方法通过深度卷积网络将2°×2°的低分辨率降水数据恢复至0.25°×0.25°高分辨率，其生成的降水场不仅具有真实的空间格局和强度分布，统计特性也与真实数据高度吻合。实验显示RainScaleGAN性能优于现有主流降尺度方法，且这种物理无关的框架可扩展应用于地表风、温度等其他气象变量的降尺度任务。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "38 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13316v1",
      "published_date": "2025-03-17 15:54:20 UTC",
      "updated_date": "2025-03-17 15:54:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:11:16.260497"
    },
    {
      "arxiv_id": "2503.13310v1",
      "title": "Generative AI for Software Architecture. Applications, Trends, Challenges, and Future Directions",
      "title_zh": "生成式人工智能在软件架构中的应用、趋势、挑战与未来方向",
      "authors": [
        "Matteo Esposito",
        "Xiaozhou Li",
        "Sergio Moreschini",
        "Noman Ahmad",
        "Tomas Cerny",
        "Karthik Vaidhyanathan",
        "Valentina Lenarduzzi",
        "Davide Taibi"
      ],
      "abstract": "Context: Generative Artificial Intelligence (GenAI) is transforming much of\nsoftware development, yet its application in software architecture is still in\nits infancy, and no prior study has systematically addressed the topic. Aim: We\naim to systematically synthesize the use, rationale, contexts, usability, and\nfuture challenges of GenAI in software architecture. Method: We performed a\nmultivocal literature review (MLR), analyzing peer-reviewed and gray\nliterature, identifying current practices, models, adoption contexts, and\nreported challenges, extracting themes via open coding. Results: Our review\nidentified significant adoption of GenAI for architectural decision support and\narchitectural reconstruction. OpenAI GPT models are predominantly applied, and\nthere is consistent use of techniques such as few-shot prompting and\nretrieved-augmented generation (RAG). GenAI has been applied mostly to initial\nstages of the Software Development Life Cycle (SDLC), such as\nRequirements-to-Architecture and Architecture-to-Code. Monolithic and\nmicroservice architectures were the dominant targets. However, rigorous testing\nof GenAI outputs was typically missing from the studies. Among the most\nfrequent challenges are model precision, hallucinations, ethical aspects,\nprivacy issues, lack of architecture-specific datasets, and the absence of\nsound evaluation frameworks. Conclusions: GenAI shows significant potential in\nsoftware design, but several challenges remain on its path to greater adoption.\nResearch efforts should target designing general evaluation methodologies,\nhandling ethics and precision, increasing transparency and explainability, and\npromoting architecture-specific datasets and benchmarks to bridge the gap\nbetween theoretical possibilities and practical use.",
      "tldr_zh": "该论文系统综述了生成式AI（GenAI）在软件架构领域的应用现状与挑战。研究发现，GenAI目前主要用于架构决策支持和架构重构，OpenAI GPT模型结合few-shot prompting和检索增强生成（RAG）是主流技术方案，主要应用于需求到架构、架构到代码等软件开发生命周期早期阶段。研究揭示了当前存在模型精度不足、幻觉问题、伦理隐私风险、缺乏架构专用数据集和评估框架等关键挑战，指出未来需要开发通用评估方法、提升透明度和可解释性，并建立领域专用基准数据集来推动实际应用。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DC",
        "cs.ET"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13310v1",
      "published_date": "2025-03-17 15:49:30 UTC",
      "updated_date": "2025-03-17 15:49:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:12:08.492044"
    },
    {
      "arxiv_id": "2503.13305v1",
      "title": "Computation Mechanism Behind LLM Position Generalization",
      "title_zh": "大语言模型位置泛化的计算机制",
      "authors": [
        "Chi Han",
        "Heng Ji"
      ],
      "abstract": "Most written natural languages are composed of sequences of words and\nsentences. Similar to humans, large language models (LLMs) exhibit flexibility\nin handling textual positions - a phenomenon we term position generalization.\nThey can understand texts with position perturbations and generalize to longer\ntexts than those encountered during training with the latest techniques. These\nphenomena suggest that LLMs handle positions tolerantly, but how LLMs\ncomputationally process positional relevance remains largely unexplored. This\nwork connects the linguistic phenomenon with LLMs' computational mechanisms. We\nshow how LLMs enforce certain computational mechanisms for the aforementioned\ntolerance in position perturbations. Despite the complex design of the\nself-attention mechanism, this work reveals that LLMs learn a counterintuitive\ndisentanglement of attention logits. Their values show a 0.959 linear\ncorrelation with an approximation of the arithmetic sum of positional relevance\nand semantic importance. Furthermore, we identify a prevalent pattern in\nintermediate features, which we prove theoretically enables this effect. The\npattern, which is different from how randomly initialized parameters would\nbehave, suggests that it is a learned behavior rather than a natural result of\nthe model architecture. Based on these findings, we provide computational\nexplanations and criteria for LLMs' position flexibilities. This work takes a\npioneering step in linking position generalization with modern LLMs' internal\nmechanisms.",
      "tldr_zh": "这项研究揭示了大型语言模型(LLMs)处理文本位置泛化(position generalization)的计算机制。研究发现，尽管自注意力机制设计复杂，但LLMs实际上学习到了一种反直觉的注意力对数解耦：其数值与位置相关性和语义重要性的算术和近似值呈0.959的线性相关。研究者还识别出中间特征中的特定模式，并通过理论证明该模式是实现位置灵活性的关键，这表明该行为是学习所得而非架构固有特性。该工作首次将位置泛化现象与现代LLMs内部机制联系起来，为其位置灵活性提供了计算解释和评判标准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.13305v1",
      "published_date": "2025-03-17 15:47:37 UTC",
      "updated_date": "2025-03-17 15:47:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:13:57.401261"
    },
    {
      "arxiv_id": "2503.13299v1",
      "title": "A Survey on Transformer Context Extension: Approaches and Evaluation",
      "title_zh": "Transformer上下文扩展方法综述：技术路线与评估体系",
      "authors": [
        "Yijun Liu",
        "Jinzheng Yu",
        "Yang Xu",
        "Zhongyang Li",
        "Qingfu Zhu"
      ],
      "abstract": "Large language models (LLMs) based on Transformer have been widely applied in\nthe filed of natural language processing (NLP), demonstrating strong\nperformance, particularly in handling short text tasks. However, when it comes\nto long context scenarios, the performance of LLMs degrades due to some\nchallenges. To alleviate this phenomenon, there is a number of work proposed\nrecently. In this survey, we first list the challenges of applying pre-trained\nLLMs to process long contexts. Then systematically review the approaches\nrelated to long context and propose our taxonomy categorizing them into four\nmain types: positional encoding, context compression, retrieval augmented, and\nattention pattern. In addition to the approaches, we focus on the evaluation of\nlong context, organizing relevant data, tasks, and metrics based on existing\nlong context benchmarks. Finally, we summarize unresolved issues in the long\ncontext domain and put forward our views on future developments.",
      "tldr_zh": "本文综述了基于Transformer的大语言模型(LLMs)在长上下文处理中的扩展方法及其评估。研究首先分析了预训练LLMs在处理长上下文时面临的挑战，并系统回顾了相关方法，将其分类为位置编码、上下文压缩、检索增强和注意力模式四种主要类型。此外，论文还整理了现有的长上下文基准数据集、任务和评估指标，总结了该领域尚未解决的问题，并提出了未来发展的展望。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.13299v1",
      "published_date": "2025-03-17 15:44:09 UTC",
      "updated_date": "2025-03-17 15:44:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:14:50.465988"
    },
    {
      "arxiv_id": "2503.13288v1",
      "title": "$φ$-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation",
      "title_zh": "$φ$-解码：面向平衡推理时探索与开发的自适应前瞻采样",
      "authors": [
        "Fangzhi Xu",
        "Hang Yan",
        "Chang Ma",
        "Haiteng Zhao",
        "Jun Liu",
        "Qika Lin",
        "Zhiyong Wu"
      ],
      "abstract": "Inference-time optimization scales computation to derive deliberate reasoning\nsteps for effective performance. While previous search-based strategies address\nthe short-sightedness of auto-regressive generation, the vast search space\nleads to excessive exploration and insufficient exploitation. To strike an\nefficient balance to derive the optimal step, we frame the decoding strategy as\nforesight sampling, leveraging simulated future steps to obtain globally\noptimal step estimation. Built on it, we propose a novel decoding strategy,\nnamed $\\phi$-Decoding. To provide a precise and expressive estimation of step\nvalue, $\\phi$-Decoding approximates two distributions via foresight and\nclustering. Sampling from the joint distribution, the optimal steps can be\nselected for exploitation. To support adaptive computation allocation, we\npropose in-width and in-depth pruning strategies, featuring a light-weight\nsolution to achieve inference efficiency. Extensive experiments across seven\nbenchmarks show $\\phi$-Decoding outperforms strong baselines in both\nperformance and efficiency. Additional analysis demonstrates its generalization\nacross various LLMs and scalability across a wide range of computing budgets.\nThe code will be released at https://github.com/xufangzhi/phi-Decoding, and the\nopen-source PyPI package is coming soon.",
      "tldr_zh": "该研究提出了一种名为$\\phi$-Decoding的新型解码策略，通过前瞻性采样(foresight sampling)框架解决自回归生成中的短视问题。该方法通过模拟未来步骤和聚类技术来近似两个分布，从联合分布中采样选择最优步骤，实现探索与开发的平衡。为提升推理效率，研究者还设计了宽度和深度剪枝策略，实验表明该方法在7个基准测试中均优于基线模型，且兼容不同大语言模型(LLMs)和计算预算范围。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13288v1",
      "published_date": "2025-03-17 15:38:33 UTC",
      "updated_date": "2025-03-17 15:38:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:15:00.880764"
    },
    {
      "arxiv_id": "2503.13281v3",
      "title": "LLM-Match: An Open-Sourced Patient Matching Model Based on Large Language Models and Retrieval-Augmented Generation",
      "title_zh": "LLM-Match：基于大语言模型与检索增强生成的开源患者匹配模型",
      "authors": [
        "Xiaodi Li",
        "Shaika Chowdhury",
        "Chung Il Wi",
        "Maria Vassilaki",
        "Xiaoke Liu",
        "Terence T Sio",
        "Owen Garrick",
        "Young J Juhn",
        "James R Cerhan",
        "Cui Tao",
        "Nansu Zong"
      ],
      "abstract": "Patient matching is the process of linking patients to appropriate clinical\ntrials by accurately identifying and matching their medical records with trial\neligibility criteria. We propose LLM-Match, a novel framework for patient\nmatching leveraging fine-tuned open-source large language models. Our approach\nconsists of four key components. First, a retrieval-augmented generation (RAG)\nmodule extracts relevant patient context from a vast pool of electronic health\nrecords (EHRs). Second, a prompt generation module constructs input prompts by\nintegrating trial eligibility criteria (both inclusion and exclusion criteria),\npatient context, and system instructions. Third, a fine-tuning module with a\nclassification head optimizes the model parameters using structured prompts and\nground-truth labels. Fourth, an evaluation module assesses the fine-tuned\nmodel's performance on the testing datasets. We evaluated LLM-Match on four\nopen datasets - n2c2, SIGIR, TREC 2021, and TREC 2022 - using open-source\nmodels, comparing it against TrialGPT, Zero-Shot, and GPT-4-based closed\nmodels. LLM-Match outperformed all baselines.",
      "tldr_zh": "该研究提出了LLM-Match，一个基于开源大语言模型(LLM)和检索增强生成(RAG)技术的患者匹配系统。通过四大核心模块——RAG医疗记录检索、试验标准整合提示生成、带分类头的微调模块以及评估系统——该框架能精准匹配患者电子健康档案(EHR)与临床试验入选标准。在n2c2等四个公开数据集测试中，这一开源方案性能超越TrialGPT、Zero-Shot和GPT-4等基线模型，为临床研究筛选提供了高效可靠的新工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2503.13281v3",
      "published_date": "2025-03-17 15:31:55 UTC",
      "updated_date": "2025-03-24 19:32:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:14:14.410760"
    },
    {
      "arxiv_id": "2503.13279v1",
      "title": "Goal2Story: A Multi-Agent Fleet based on Privately Enabled sLLMs for Impacting Mapping on Requirements Elicitation",
      "title_zh": "Goal2Story：基于私有化轻量级大语言模型的多智能体需求映射框架",
      "authors": [
        "Xinkai Zou",
        "Yan Liu",
        "Xiongbo Shi",
        "Chen Yang"
      ],
      "abstract": "As requirements drift with rapid iterations, agile development becomes the\ndominant paradigm. Goal-driven Requirements Elicitation (RE) is a pivotal yet\nchallenging task in agile project development due to its heavy tangling with\nadaptive planning and efficient collaboration. Recently, AI agents have shown\npromising ability in supporting requirements analysis by saving significant\ntime and effort for stakeholders. However, current research mainly focuses on\nfunctional RE, and research works have not been reported bridging the long\njourney from goal to user stories. Moreover, considering the cost of LLM\nfacilities and the need for data and idea protection, privately hosted\nsmall-sized LLM should be further utilized in RE. To address these challenges,\nwe propose Goal2Story, a multi-agent fleet that adopts the Impact Mapping (IM)\nframework while merely using cost-effective sLLMs for goal-driven RE. Moreover,\nwe introduce a StorySeek dataset that contains over 1,000 user stories (USs)\nwith corresponding goals and project context information, as well as the\nsemi-automatic dataset construction method. For evaluation, we proposed two\nmetrics: Factuality Hit Rate (FHR) to measure consistency between the generated\nUSs with the dataset and Quality And Consistency Evaluation (QuACE) to evaluate\nthe quality of the generated USs. Experimental results demonstrate that\nGoal2Story outperforms the baseline performance of the Super-Agent adopting\npowerful LLMs, while also showcasing the performance improvements in key\nmetrics brought by CoT and Agent Profile to Goal2Story, as well as its\nexploration in identifying latent needs.",
      "tldr_zh": "该研究提出Goal2Story，一个基于私有化部署小型语言模型(sLLMs)的多智能体框架，用于将需求目标映射为用户故事(User Stories)。该方法采用Impact Mapping框架，通过构建包含1000+用户故事的StorySeek数据集，并开发Factuality Hit Rate和QuACE两项评估指标。实验表明，该框架在需求获取(RE)任务中表现优于采用大型语言模型的Super-Agent基线，同时验证了思维链(CoT)和智能体角色设定对提升生成质量的有效性，为敏捷开发中的目标驱动型需求获取提供了高效、低成本的解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13279v1",
      "published_date": "2025-03-17 15:31:20 UTC",
      "updated_date": "2025-03-17 15:31:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:14:40.068961"
    },
    {
      "arxiv_id": "2503.13277v1",
      "title": "Artificial Intelligence-Driven Prognostic Classification of COVID-19 Using Chest X-rays: A Deep Learning Approach",
      "title_zh": "基于胸部X光片的COVID-19人工智能预后分类：一种深度学习方法",
      "authors": [
        "Alfred Simbun",
        "Suresh Kumar"
      ],
      "abstract": "Background: The COVID-19 pandemic has overwhelmed healthcare systems,\nemphasizing the need for AI-driven tools to assist in rapid and accurate\npatient prognosis. Chest X-ray imaging is a widely available diagnostic tool,\nbut existing methods for prognosis classification lack scalability and\nefficiency. Objective: This study presents a high-accuracy deep learning model\nfor classifying COVID-19 severity (Mild, Moderate, and Severe) using Chest\nX-ray images, developed on Microsoft Azure Custom Vision. Methods: Using a\ndataset of 1,103 confirmed COVID-19 X-ray images from AIforCOVID, we trained\nand validated a deep learning model leveraging Convolutional Neural Networks\n(CNNs). The model was evaluated on an unseen dataset to measure accuracy,\nprecision, and recall. Results: Our model achieved an average accuracy of 97%,\nwith specificity of 99%, sensitivity of 87%, and an F1-score of 93.11%. When\nclassifying COVID-19 severity, the model achieved accuracies of 89.03% (Mild),\n95.77% (Moderate), and 81.16% (Severe). These results demonstrate the model's\npotential for real-world clinical applications, aiding in faster\ndecision-making and improved resource allocation. Conclusion: AI-driven\nprognosis classification using deep learning can significantly enhance COVID-19\npatient management, enabling early intervention and efficient triaging. Our\nstudy provides a scalable, high-accuracy AI framework for integrating deep\nlearning into routine clinical workflows. Future work should focus on expanding\ndatasets, external validation, and regulatory compliance to facilitate clinical\nadoption.",
      "tldr_zh": "该研究提出了一种基于深度学习的AI模型，利用胸部X光图像对COVID-19患者进行预后严重程度分类（轻、中、重）。采用卷积神经网络(CNN)在Microsoft Azure Custom Vision平台上开发，模型在1103张确诊COVID-19的X光图像数据集上训练，实现了97%的平均准确率。特别在区分中度病例时准确率达95.77%，展现出临床应用的潜力。该AI框架可帮助快速决策和优化医疗资源分配，为常规临床工作流程提供了可扩展的高精度解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "27 pages, 6 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.13277v1",
      "published_date": "2025-03-17 15:27:21 UTC",
      "updated_date": "2025-03-17 15:27:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:15:26.340162"
    },
    {
      "arxiv_id": "2503.13275v1",
      "title": "Knowledge-Aware Iterative Retrieval for Multi-Agent Systems",
      "title_zh": "知识感知的迭代检索方法在多智能体系统中的研究",
      "authors": [
        "Seyoung Song"
      ],
      "abstract": "We introduce a novel large language model (LLM)-driven agent framework, which\niteratively refines queries and filters contextual evidence by leveraging\ndynamically evolving knowledge. A defining feature of the system is its\ndecoupling of external sources from an internal knowledge cache that is\nprogressively updated to guide both query generation and evidence selection.\nThis design mitigates bias-reinforcement loops and enables dynamic, trackable\nsearch exploration paths, thereby optimizing the trade-off between exploring\ndiverse information and maintaining accuracy through autonomous agent\ndecision-making. Our approach is evaluated on a broad range of open-domain\nquestion answering benchmarks, including multi-step tasks that mirror\nreal-world scenarios where integrating information from multiple sources is\ncritical, especially given the vulnerabilities of LLMs that lack explicit\nreasoning or planning capabilities. The results show that the proposed system\nnot only outperforms single-step baselines regardless of task difficulty but\nalso, compared to conventional iterative retrieval methods, demonstrates\npronounced advantages in complex tasks through precise evidence-based reasoning\nand enhanced efficiency. The proposed system supports both competitive and\ncollaborative sharing of updated context, enabling multi-agent extension. The\nbenefits of multi-agent configurations become especially prominent as task\ndifficulty increases. The number of convergence steps scales with task\ndifficulty, suggesting cost-effective scalability.",
      "tldr_zh": "本文提出了一种新型LLM驱动的多智能体框架，通过动态演化的知识库实现迭代查询优化和上下文证据筛选。该系统的核心创新在于将外部数据源与内部知识缓存解耦，通过渐进式知识更新来指导查询生成和证据选择，有效避免了偏见强化循环问题。实验表明，该系统在开放域问答任务中显著优于单步基线方法，尤其在复杂多步推理任务中展现出基于证据的精确推理优势。研究还发现多智能体配置能随任务难度提升而展现出更强的协同效应，同时收敛步骤数会随任务复杂度自适应调整，具有良好的可扩展性。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "I.2.0; I.2.7; I.2.11; H.3.3"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13275v1",
      "published_date": "2025-03-17 15:27:02 UTC",
      "updated_date": "2025-03-17 15:27:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:15:50.532896"
    },
    {
      "arxiv_id": "2503.13578v1",
      "title": "Convolutional neural network for early detection of lameness and irregularity in horses using an IMU sensor",
      "title_zh": "基于IMU传感器与卷积神经网络的马匹跛行及步态异常早期检测系统",
      "authors": [
        "Benoît Savoini",
        "Jonathan Bertolaccini",
        "Stéphane Montavon",
        "Michel Deriaz"
      ],
      "abstract": "Lameness and gait irregularities are significant concerns in equine health\nmanagement, affecting performance, welfare, and economic value. Traditional\nobservational methods rely on subjective expert assessments, which can lead to\ninconsistencies in detecting subtle or early-stage lameness. While AI-based\napproaches have emerged, many require multiple sensors, force plates, or video\nsystems, making them costly and impractical for field deployment. In this\napplied research study, we present a stride-level classification system that\nutilizes a single inertial measurement unit (IMU) and a one-dimensional\nconvolutional neural network (1D CNN) to objectively differentiate between\nsound and lame horses, with a primary focus on the trot gait. The proposed\nsystem was tested under real-world conditions, achieving a 90% session-level\naccuracy with no false positives, demonstrating its robustness for practical\napplications. By employing a single, non-intrusive, and readily available\nsensor, our approach significantly reduces the complexity and cost of hardware\nrequirements while maintaining high classification performance. These results\nhighlight the potential of our CNN-based method as a field-tested, scalable\nsolution for automated lameness detection. By enabling early diagnosis, this\nsystem offers a valuable tool for preventing minor gait irregularities from\ndeveloping into severe conditions, ultimately contributing to improved equine\nwelfare and performance in veterinary and equestrian practice.",
      "tldr_zh": "本研究提出了一种基于一维卷积神经网络(1D CNN)和单个惯性测量单元(IMU)的步态分类系统，用于马匹跛行和步态异常的早期检测。与传统的专家主观评估和多传感器系统相比，该方法仅需一个非侵入式传感器，显著降低了硬件复杂性和成本。在真实场景测试中，系统在快步(trot)步态下的会话级准确率达到90%，且无假阳性，展现了其在实际应用中的鲁棒性。该研究为马匹健康管理提供了一种高效、可扩展的自动化解决方案，有助于早期诊断和预防严重跛行，从而提升马匹福利和表现。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted at AMLDS 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13578v1",
      "published_date": "2025-03-17 15:05:01 UTC",
      "updated_date": "2025-03-17 15:05:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:16:09.265054"
    },
    {
      "arxiv_id": "2503.14542v1",
      "title": "AI-Driven Rapid Identification of Bacterial and Fungal Pathogens in Blood Smears of Septic Patients",
      "title_zh": "AI驱动的脓毒症患者血涂片中细菌与真菌病原体快速鉴定",
      "authors": [
        "Agnieszka Sroka-Oleksiak",
        "Adam Pardyl",
        "Dawid Rymarczyk",
        "Aldona Olechowska-Jarząb",
        "Katarzyna Biegun-Drożdż",
        "Dorota Ochońska",
        "Michał Wronka",
        "Adriana Borowa",
        "Tomasz Gosiewski",
        "Miłosz Adamczyk",
        "Henryk Telega",
        "Bartosz Zieliński",
        "Monika Brzychczy-Włoch"
      ],
      "abstract": "Sepsis is a life-threatening condition which requires rapid diagnosis and\ntreatment. Traditional microbiological methods are time-consuming and\nexpensive. In response to these challenges, deep learning algorithms were\ndeveloped to identify 14 bacteria species and 3 yeast-like fungi from\nmicroscopic images of Gram-stained smears of positive blood samples from sepsis\npatients.\n  A total of 16,637 Gram-stained microscopic images were used in the study. The\nanalysis used the Cellpose 3 model for segmentation and Attention-based Deep\nMultiple Instance Learning for classification. Our model achieved an accuracy\nof 77.15% for bacteria and 71.39% for fungi, with ROC AUC of 0.97 and 0.88,\nrespectively. The highest values, reaching up to 96.2%, were obtained for\nCutibacterium acnes, Enterococcus faecium, Stenotrophomonas maltophilia and\nNakaseomyces glabratus. Classification difficulties were observed in closely\nrelated species, such as Staphylococcus hominis and Staphylococcus\nhaemolyticus, due to morphological similarity, and within Candida albicans due\nto high morphotic diversity.\n  The study confirms the potential of our model for microbial classification,\nbut it also indicates the need for further optimisation and expansion of the\ntraining data set. In the future, this technology could support microbial\ndiagnosis, reducing diagnostic time and improving the effectiveness of sepsis\ntreatment due to its simplicity and accessibility. Part of the results\npresented in this publication was covered by a patent application at the\nEuropean Patent Office EP24461637.1 \"A computer implemented method for\nidentifying a microorganism in a blood and a data processing system therefor\".",
      "tldr_zh": "该研究开发了一种基于深度学习的AI系统，可快速识别脓毒症患者血液涂片中的14种细菌和3种酵母样真菌。采用Cellpose 3模型进行细胞分割，并结合注意力机制的多实例学习分类方法，在16,637张革兰氏染色显微图像上取得细菌分类准确率77.15%(AUC 0.97)和真菌71.39%(AUC 0.88)的表现，其中痤疮丙酸杆菌等特定病原体识别准确率高达96.2%。研究表明该技术能显著缩短脓毒症诊断时间，但因形态相似性导致的近缘菌种(如表皮葡萄球菌和溶血葡萄球菌)分类困难，仍需进一步优化训练数据集。该成果已申请欧洲专利(EP24461637.1)。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CE",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.14542v1",
      "published_date": "2025-03-17 15:02:49 UTC",
      "updated_date": "2025-03-17 15:02:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:16:27.154010"
    },
    {
      "arxiv_id": "2503.13223v1",
      "title": "Robust Decision-Making Via Free Energy Minimization",
      "title_zh": "通过自由能最小化实现鲁棒决策",
      "authors": [
        "Allahkaram Shafiei",
        "Hozefa Jesawada",
        "Karl Friston",
        "Giovanni Russo"
      ],
      "abstract": "Despite their groundbreaking performance, state-of-the-art autonomous agents\ncan misbehave when training and environmental conditions become inconsistent,\nwith minor mismatches leading to undesirable behaviors or even catastrophic\nfailures. Robustness towards these training/environment ambiguities is a core\nrequirement for intelligent agents and its fulfillment is a long-standing\nchallenge when deploying agents in the real world. Here, departing from\nmainstream views seeking robustness through training, we introduce DR-FREE, a\nfree energy model that installs this core property by design. It directly wires\nrobustness into the agent decision-making mechanisms via free energy\nminimization. By combining a robust extension of the free energy principle with\na novel resolution engine, DR-FREE returns a policy that is optimal-yet-robust\nagainst ambiguity. Moreover, for the first time, it reveals the mechanistic\nrole of ambiguity on optimal decisions and requisite Bayesian belief updating.\nWe evaluate DR-FREE on an experimental testbed involving real rovers navigating\nan ambiguous environment filled with obstacles. Across all the experiments,\nDR-FREE enables robots to successfully navigate towards their goal even when,\nin contrast, standard free energy minimizing agents that do not use DR-FREE\nfail. In short, DR-FREE can tackle scenarios that elude previous methods: this\nmilestone may inspire both deployment in multi-agent settings and, at a perhaps\ndeeper level, the quest for a biologically plausible explanation of how natural\nagents - with little or no training - survive in capricious environments.",
      "tldr_zh": "本研究提出DR-FREE模型，通过自由能最小化原理(Free Energy Minimization)将鲁棒性直接植入智能体决策机制。该模型结合自由能原理的鲁棒扩展与新型求解引擎，能在存在环境模糊性时输出既最优又鲁棒的决策策略，并首次揭示了模糊性对最优决策及贝叶斯信念更新的机制性影响。实验表明，在真实火星车导航任务中，DR-FREE能成功穿越障碍环境，而标准自由能最小化智能体会失败。这一突破既适用于多智能体场景部署，也为解释自然生物如何在多变环境中生存提供了生物学合理性启示。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "Contains main text and supplementary information",
      "pdf_url": "http://arxiv.org/pdf/2503.13223v1",
      "published_date": "2025-03-17 14:36:08 UTC",
      "updated_date": "2025-03-17 14:36:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:16:49.003470"
    },
    {
      "arxiv_id": "2503.13222v1",
      "title": "Can Language Models Follow Multiple Turns of Entangled Instructions?",
      "title_zh": "语言模型能否遵循多轮交织指令？",
      "authors": [
        "Chi Han"
      ],
      "abstract": "Despite significant achievements in improving the instruction-following\ncapabilities of large language models (LLMs), the ability to process multiple\npotentially entangled or conflicting instructions remains a considerable\nchallenge. Real-world scenarios often require consistency across multiple\ninstructions over time, such as secret privacy, personal preferences, and\nprioritization, which demand sophisticated abilities to integrate multiple\nturns and carefully balance competing objectives when instructions intersect or\nconflict. This work presents a systematic investigation of LLMs' capabilities\nin handling multiple turns of instructions, covering three levels of\ndifficulty: (1) retrieving information from instructions, (2) tracking and\nreasoning across turns, and (3) resolving conflicts among instructions. We\nconstruct MultiTurnInstruct with around 1.1K high-quality multi-turn\nconversations through the human-in-the-loop approach and result in nine\ncapability categories, including statics and dynamics, reasoning, and\nmultitasking. Our finding reveals an intriguing trade-off between different\ncapabilities. While GPT models demonstrate superior memorization, they show\nreduced effectiveness in privacy-protection tasks requiring selective\ninformation withholding. Larger models exhibit stronger reasoning capabilities\nbut still struggle with resolving conflicting instructions. Importantly, these\nperformance gaps cannot be attributed solely to information loss, as models\ndemonstrate strong BLEU scores on memorization tasks but their attention\nmechanisms fail to integrate multiple related instructions effectively. These\nfindings highlight critical areas for improvement in complex real-world tasks\ninvolving multi-turn instructions.",
      "tldr_zh": "该研究系统评估了大语言模型(LLMs)处理多轮复杂指令的能力，揭示出当前模型在指令跟踪与冲突解决方面存在显著局限。通过构建包含1.1K轮对话的MultiTurnInstruct测试集，研究者发现：GPT系列模型虽在记忆静态指令方面表现优异，但在需要动态权衡的隐私保护任务中表现欠佳；模型规模增大虽提升推理能力，却无法有效解决指令冲突问题。研究表明，模型注意力机制难以有效整合多轮关联指令，这种性能缺陷不能简单归因于信息丢失，凸显了现有架构在复杂现实任务中的关键改进空间。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.13222v1",
      "published_date": "2025-03-17 14:31:37 UTC",
      "updated_date": "2025-03-17 14:31:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:17:13.572168"
    },
    {
      "arxiv_id": "2503.13214v3",
      "title": "A General Adaptive Dual-level Weighting Mechanism for Remote Sensing Pansharpening",
      "title_zh": "遥感全色锐化的通用自适应双级加权机制",
      "authors": [
        "Jie Huang",
        "Haorui Chen",
        "Jiaxuan Ren",
        "Siran Peng",
        "Liangjian Deng"
      ],
      "abstract": "Currently, deep learning-based methods for remote sensing pansharpening have\nadvanced rapidly. However, many existing methods struggle to fully leverage\nfeature heterogeneity and redundancy, thereby limiting their effectiveness. We\nuse the covariance matrix to model the feature heterogeneity and redundancy and\npropose Correlation-Aware Covariance Weighting (CACW) to adjust them. CACW\ncaptures these correlations through the covariance matrix, which is then\nprocessed by a nonlinear function to generate weights for adjustment. Building\nupon CACW, we introduce a general adaptive dual-level weighting mechanism\n(ADWM) to address these challenges from two key perspectives, enhancing a wide\nrange of existing deep-learning methods. First, Intra-Feature Weighting (IFW)\nevaluates correlations among channels within each feature to reduce redundancy\nand enhance unique information. Second, Cross-Feature Weighting (CFW) adjusts\ncontributions across layers based on inter-layer correlations, refining the\nfinal output. Extensive experiments demonstrate the superior performance of\nADWM compared to recent state-of-the-art (SOTA) methods. Furthermore, we\nvalidate the effectiveness of our approach through generality experiments,\nredundancy visualization, comparison experiments, key variables and complexity\nanalysis, and ablation studies. Our code is available at\nhttps://github.com/Jie-1203/ADWM.",
      "tldr_zh": "该研究提出了一种通用的自适应双层级加权机制(ADWM)，用于解决遥感图像融合中的特征异质性和冗余问题。其核心是通过相关感知协方差加权(CACW)建模特征相关性，并设计了两层加权策略：**层内特征加权(IFW)**减少通道间冗余，**跨层特征加权(CFW)**优化层间贡献。实验表明，ADWM显著提升了现有深度学习方法的性能，并在多个任务上优于当前最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper is accepted at the CVPR Conference on Computer Vision and\n  Pattern Recognition 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13214v3",
      "published_date": "2025-03-17 14:24:00 UTC",
      "updated_date": "2025-03-21 12:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:17:28.180609"
    },
    {
      "arxiv_id": "2503.13211v1",
      "title": "MedLoRD: A Medical Low-Resource Diffusion Model for High-Resolution 3D CT Image Synthesis",
      "title_zh": "MedLoRD：面向高分辨率3D CT图像合成的医疗低资源扩散模型",
      "authors": [
        "Marvin Seyfarth",
        "Salman Ul Hassan Dar",
        "Isabelle Ayx",
        "Matthias Alexander Fink",
        "Stefan O. Schoenberg",
        "Hans-Ulrich Kauczor",
        "Sandy Engelhardt"
      ],
      "abstract": "Advancements in AI for medical imaging offer significant potential. However,\ntheir applications are constrained by the limited availability of data and the\nreluctance of medical centers to share it due to patient privacy concerns.\nGenerative models present a promising solution by creating synthetic data as a\nsubstitute for real patient data. However, medical images are typically\nhigh-dimensional, and current state-of-the-art methods are often impractical\nfor computational resource-constrained healthcare environments. These models\nrely on data sub-sampling, raising doubts about their feasibility and\nreal-world applicability. Furthermore, many of these models are evaluated on\nquantitative metrics that alone can be misleading in assessing the image\nquality and clinical meaningfulness of the generated images. To address this,\nwe introduce MedLoRD, a generative diffusion model designed for computational\nresource-constrained environments. MedLoRD is capable of generating\nhigh-dimensional medical volumes with resolutions up to\n512$\\times$512$\\times$256, utilizing GPUs with only 24GB VRAM, which are\ncommonly found in standard desktop workstations. MedLoRD is evaluated across\nmultiple modalities, including Coronary Computed Tomography Angiography and\nLung Computed Tomography datasets. Extensive evaluations through radiological\nevaluation, relative regional volume analysis, adherence to conditional masks,\nand downstream tasks show that MedLoRD generates high-fidelity images closely\nadhering to segmentation mask conditions, surpassing the capabilities of\ncurrent state-of-the-art generative models for medical image synthesis in\ncomputational resource-constrained environments.",
      "tldr_zh": "该研究提出了MedLoRD，一种面向计算资源受限环境的医学低资源扩散模型，用于生成高分辨率3D CT图像。MedLoRD能够在仅24GB显存的GPU上生成分辨率高达512×512×256的医学影像，适用于标准桌面工作站。通过冠状动脉CT血管造影和肺部CT数据集的多模态评估，MedLoRD生成的图像在放射学评估、区域体积分析和条件掩码一致性等方面表现出高保真度，超越了现有最先进的医学图像生成模型，为资源受限的医疗环境提供了可行的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13211v1",
      "published_date": "2025-03-17 14:22:49 UTC",
      "updated_date": "2025-03-17 14:22:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:17:51.711797"
    },
    {
      "arxiv_id": "2503.13208v1",
      "title": "Improving Complex Reasoning with Dynamic Prompt Corruption: A soft prompt Optimization Approach",
      "title_zh": "提升复杂推理能力：基于动态提示干扰的软提示优化方法",
      "authors": [
        "Sinan Fan",
        "Liang Xie",
        "Chen Shen",
        "Ge Teng",
        "Xiaosong Yuan",
        "Xiaofeng Zhang",
        "Chenxi Huang",
        "Wenxiao Wang",
        "Xiaofei He",
        "Jieping Ye"
      ],
      "abstract": "Prompt-tuning (PT) for large language models (LLMs) can facilitate the\nperformance on various conventional NLP tasks with significantly fewer\ntrainable parameters. However, our investigation reveals that PT provides\nlimited improvement and may even degrade the primitive performance of LLMs on\ncomplex reasoning tasks. Such a phenomenon suggests that soft prompts can\npositively impact certain instances while negatively affecting others,\nparticularly during the later phases of reasoning. To address these challenges,\nWe first identify an information accumulation within the soft prompts. Through\ndetailed analysis, we demonstrate that this phenomenon is often accompanied by\nerroneous information flow patterns in the deeper layers of the model, which\nultimately lead to incorrect reasoning outcomes. we propose a novel method\ncalled \\textbf{D}ynamic \\textbf{P}rompt \\textbf{C}orruption (DPC) to take\nbetter advantage of soft prompts in complex reasoning tasks, which dynamically\nadjusts the influence of soft prompts based on their impact on the reasoning\nprocess. Specifically, DPC consists of two stages: Dynamic Trigger and Dynamic\nCorruption. First, Dynamic Trigger measures the impact of soft prompts,\nidentifying whether beneficial or detrimental. Then, Dynamic Corruption\nmitigates the negative effects of soft prompts by selectively masking key\ntokens that interfere with the reasoning process. We validate the proposed\napproach through extensive experiments on various LLMs and reasoning tasks,\nincluding GSM8K, MATH, and AQuA. Experimental results demonstrate that DPC can\nconsistently enhance the performance of PT, achieving 4\\%-8\\% accuracy gains\ncompared to vanilla prompt tuning, highlighting the effectiveness of our\napproach and its potential to enhance complex reasoning in LLMs.",
      "tldr_zh": "该研究提出了一种名为动态提示破坏(Dynamic Prompt Corruption, DPC)的新方法，旨在优化大语言模型(LLMs)在复杂推理任务中的表现。研究发现，传统的提示调优(PT)在复杂推理任务中效果有限，甚至可能导致性能下降，原因在于软提示在模型深层可能积累错误信息。DPC通过动态触发(Dynamic Trigger)评估软提示的影响，并利用动态破坏(Dynamic Corruption)选择性屏蔽干扰推理的关键词，从而减少负面影响。实验表明，DPC在GSM8K、MATH和AQuA等推理任务中显著提升了PT的性能，准确率提高了4%-8%，为增强LLMs的复杂推理能力提供了有效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13208v1",
      "published_date": "2025-03-17 14:20:48 UTC",
      "updated_date": "2025-03-17 14:20:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:18:28.543107"
    },
    {
      "arxiv_id": "2503.13205v1",
      "title": "MAP: Evaluation and Multi-Agent Enhancement of Large Language Models for Inpatient Pathways",
      "title_zh": "MAP：面向住院诊疗路径的大语言模型评估与多智能体增强框架",
      "authors": [
        "Zhen Chen",
        "Zhihao Peng",
        "Xusheng Liang",
        "Cheng Wang",
        "Peigan Liang",
        "Linsheng Zeng",
        "Minjie Ju",
        "Yixuan Yuan"
      ],
      "abstract": "Inpatient pathways demand complex clinical decision-making based on\ncomprehensive patient information, posing critical challenges for clinicians.\nDespite advancements in large language models (LLMs) in medical applications,\nlimited research focused on artificial intelligence (AI) inpatient pathways\nsystems, due to the lack of large-scale inpatient datasets. Moreover, existing\nmedical benchmarks typically concentrated on medical question-answering and\nexaminations, ignoring the multifaceted nature of clinical decision-making in\ninpatient settings. To address these gaps, we first developed the Inpatient\nPathway Decision Support (IPDS) benchmark from the MIMIC-IV database,\nencompassing 51,274 cases across nine triage departments and 17 major disease\ncategories alongside 16 standardized treatment options. Then, we proposed the\nMulti-Agent Inpatient Pathways (MAP) framework to accomplish inpatient pathways\nwith three clinical agents, including a triage agent managing the patient\nadmission, a diagnosis agent serving as the primary decision maker at the\ndepartment, and a treatment agent providing treatment plans. Additionally, our\nMAP framework includes a chief agent overseeing the inpatient pathways to guide\nand promote these three clinician agents. Extensive experiments showed our MAP\nimproved the diagnosis accuracy by 25.10% compared to the state-of-the-art LLM\nHuatuoGPT2-13B. It is worth noting that our MAP demonstrated significant\nclinical compliance, outperforming three board-certified clinicians by 10%-12%,\nestablishing a foundation for inpatient pathways systems.",
      "tldr_zh": "该研究提出了多智能体住院路径框架(MAP)，用于增强大语言模型(LLMs)在住院诊疗决策中的表现。首先基于MIMIC-IV数据库构建了包含51,274个病例的住院路径决策支持基准(IPDS)，涵盖9个分诊科室和17种主要疾病。MAP框架采用三智能体协作模式：分诊智能体负责入院管理，诊断智能体作为科室主要决策者，治疗智能体制定治疗方案，并由首席智能体统筹协调。实验表明，MAP框架比最优模型(HuatuoGPT2-13B)诊断准确率提升25.10%，临床合规性甚至超过3位认证医师10%-12%，为AI驱动的住院诊疗系统奠定了基础。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13205v1",
      "published_date": "2025-03-17 14:14:28 UTC",
      "updated_date": "2025-03-17 14:14:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:18:38.707356"
    },
    {
      "arxiv_id": "2503.14538v2",
      "title": "Vision-Language Models for Acute Tuberculosis Diagnosis: A Multimodal Approach Combining Imaging and Clinical Data",
      "title_zh": "视觉语言模型在急性肺结核诊断中的应用：融合影像与临床数据的多模态方法",
      "authors": [
        "Ananya Ganapthy",
        "Praveen Shastry",
        "Naveen Kumarasami",
        "Anandakumar D",
        "Keerthana R",
        "Mounigasri M",
        "Varshinipriya M",
        "Kishore Prasath Venkatesh",
        "Bargava Subramanian",
        "Kalyan Sivasailam"
      ],
      "abstract": "Background: This study introduces a Vision-Language Model (VLM) leveraging\nSIGLIP and Gemma-3b architectures for automated acute tuberculosis (TB)\nscreening. By integrating chest X-ray images and clinical notes, the model aims\nto enhance diagnostic accuracy and efficiency, particularly in resource-limited\nsettings.\n  Methods: The VLM combines visual data from chest X-rays with clinical context\nto generate detailed, context-aware diagnostic reports. The architecture\nemploys SIGLIP for visual encoding and Gemma-3b for decoding, ensuring\neffective representation of acute TB-specific pathologies and clinical\ninsights.\n  Results: Key acute TB pathologies, including consolidation, cavities, and\nnodules, were detected with high precision (97percent) and recall (96percent).\nThe model demonstrated strong spatial localization capabilities and robustness\nin distinguishing TB-positive cases, making it a reliable tool for acute TB\ndiagnosis.\n  Conclusion: The multimodal capability of the VLM reduces reliance on\nradiologists, providing a scalable solution for acute TB screening. Future work\nwill focus on improving the detection of subtle pathologies and addressing\ndataset biases to enhance its generalizability and application in diverse\nglobal healthcare settings.",
      "tldr_zh": "本研究提出了一种基于SIGLIP和Gemma-3b架构的视觉语言模型(VLM)，用于急性结核病(TB)的自动化筛查。该模型通过结合胸部X光图像和临床记录，实现了对结核病关键病理特征（如实变、空洞和结节）的高精度检测（精确率97%，召回率96%）。其多模态能力显著减少了对放射科医生的依赖，为资源有限地区的急性结核病筛查提供了可扩展的解决方案。未来工作将专注于提升对细微病理的检测能力，并解决数据集偏差以提高模型的泛化性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "68T07, 68T45, 92C55, 92C50, 68U10"
      ],
      "primary_category": "eess.IV",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.14538v2",
      "published_date": "2025-03-17 14:08:35 UTC",
      "updated_date": "2025-03-20 10:20:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:18:53.721959"
    },
    {
      "arxiv_id": "2503.13200v1",
      "title": "Timing the Match: A Deep Reinforcement Learning Approach for Ride-Hailing and Ride-Pooling Services",
      "title_zh": "时机匹配：基于深度强化学习的网约车与拼车服务优化方法",
      "authors": [
        "Yiman Bao",
        "Jie Gao",
        "Jinke He",
        "Frans A. Oliehoek",
        "Oded Cats"
      ],
      "abstract": "Efficient timing in ride-matching is crucial for improving the performance of\nride-hailing and ride-pooling services, as it determines the number of drivers\nand passengers considered in each matching process. Traditional batched\nmatching methods often use fixed time intervals to accumulate ride requests\nbefore assigning matches. While this approach increases the number of available\ndrivers and passengers for matching, it fails to adapt to real-time\nsupply-demand fluctuations, often leading to longer passenger wait times and\ndriver idle periods. To address this limitation, we propose an adaptive\nride-matching strategy using deep reinforcement learning (RL) to dynamically\ndetermine when to perform matches based on real-time system conditions. Unlike\nfixed-interval approaches, our method continuously evaluates system states and\nexecutes matching at moments that minimize total passenger wait time.\nAdditionally, we incorporate a potential-based reward shaping (PBRS) mechanism\nto mitigate sparse rewards, accelerating RL training and improving decision\nquality. Extensive empirical evaluations using a realistic simulator trained on\nreal-world data demonstrate that our approach outperforms fixed-interval\nmatching strategies, significantly reducing passenger waiting times and detour\ndelays, thereby enhancing the overall efficiency of ride-hailing and\nride-pooling systems.",
      "tldr_zh": "该研究提出了一种基于深度强化学习（RL）的自适应乘车匹配策略，用于优化网约车和拼车服务的匹配时机。与传统的固定间隔匹配方法不同，该方法通过实时评估系统状态动态决定最佳匹配时刻，并引入基于势能的奖励塑形（PBRS）机制来加速训练。实验表明，该策略能显著减少乘客等待时间和绕行延误，提升整体系统效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13200v1",
      "published_date": "2025-03-17 14:07:58 UTC",
      "updated_date": "2025-03-17 14:07:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:19:17.979653"
    },
    {
      "arxiv_id": "2503.13194v1",
      "title": "A representational framework for learning and encoding structurally enriched trajectories in complex agent environments",
      "title_zh": "复杂智能体环境中结构增强轨迹学习与编码的表征框架",
      "authors": [
        "Corina Catarau-Cotutiu",
        "Esther Mondragon",
        "Eduardo Alonso"
      ],
      "abstract": "The ability of artificial intelligence agents to make optimal decisions and\ngeneralise them to different domains and tasks is compromised in complex\nscenarios. One way to address this issue has focused on learning efficient\nrepresentations of the world and on how the actions of agents affect them, such\nas disentangled representations that exploit symmetries. Whereas such\nrepresentations are procedurally efficient, they are based on the compression\nof low-level state-action transitions, which lack structural richness. To\naddress this problem, we propose to enrich the agent's ontology and extend the\ntraditional conceptualisation of trajectories to provide a more nuanced view of\ntask execution. Structurally Enriched Trajectories (SETs) extend the encoding\nof sequences of states and their transitions by incorporating hierarchical\nrelations between objects, interactions and affordances. SETs are built as\nmulti-level graphs, providing a detailed representation of the agent dynamics\nand a transferable functional abstraction of the task. SETs are integrated into\nan architecture, Structurally Enriched Trajectory Learning and Encoding\n(SETLE), that employs a heterogeneous graph-based memory structure of\nmulti-level relational dependencies essential for generalisation. Using\nreinforcement learning as a data generation tool, we demonstrate that SETLE can\nsupport downstream tasks, enabling agents to recognise task-relevant structural\npatterns across diverse environments.",
      "tldr_zh": "该研究提出了一种结构丰富的轨迹表示框架（Structurally Enriched Trajectories, SETs），以增强人工智能代理在复杂环境中的决策和泛化能力。SETs通过将对象、交互和功能之间的层次关系整合到状态转移序列中，构建了多层次的图结构，提供了对代理动态的详细表示和任务的可迁移功能抽象。该框架被集成到SETLE（Structurally Enriched Trajectory Learning and Encoding）架构中，利用异构图记忆结构捕捉多层次关系依赖，支持跨环境的任务相关结构模式识别。实验表明，SETLE能够显著提升代理在不同任务中的泛化性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13194v1",
      "published_date": "2025-03-17 14:04:27 UTC",
      "updated_date": "2025-03-17 14:04:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:19:46.439632"
    },
    {
      "arxiv_id": "2503.13185v1",
      "title": "3DAxisPrompt: Promoting the 3D Grounding and Reasoning in GPT-4o",
      "title_zh": "3DAxisPrompt：增强GPT-4o的三维空间定位与推理能力",
      "authors": [
        "Dingning Liu",
        "Cheng Wang",
        "Peng Gao",
        "Renrui Zhang",
        "Xinzhu Ma",
        "Yuan Meng",
        "Zhihui Wang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) exhibit impressive capabilities\nacross a variety of tasks, especially when equipped with carefully designed\nvisual prompts. However, existing studies primarily focus on logical reasoning\nand visual understanding, while the capability of MLLMs to operate effectively\nin 3D vision remains an ongoing area of exploration. In this paper, we\nintroduce a novel visual prompting method, called 3DAxisPrompt, to elicit the\n3D understanding capabilities of MLLMs in real-world scenes. More specifically,\nour method leverages the 3D coordinate axis and masks generated from the\nSegment Anything Model (SAM) to provide explicit geometric priors to MLLMs and\nthen extend their impressive 2D grounding and reasoning ability to real-world\n3D scenarios. Besides, we first provide a thorough investigation of the\npotential visual prompting formats and conclude our findings to reveal the\npotential and limits of 3D understanding capabilities in GPT-4o, as a\nrepresentative of MLLMs. Finally, we build evaluation environments with four\ndatasets, i.e., ScanRefer, ScanNet, FMB, and nuScene datasets, covering various\n3D tasks. Based on this, we conduct extensive quantitative and qualitative\nexperiments, which demonstrate the effectiveness of the proposed method.\nOverall, our study reveals that MLLMs, with the help of 3DAxisPrompt, can\neffectively perceive an object's 3D position in real-world scenarios.\nNevertheless, a single prompt engineering approach does not consistently\nachieve the best outcomes for all 3D tasks. This study highlights the\nfeasibility of leveraging MLLMs for 3D vision grounding/reasoning with prompt\nengineering techniques.",
      "tldr_zh": "该研究提出了3DAxisPrompt方法，用于增强多模态大语言模型(MLLMs)在真实3D场景中的理解和推理能力。该方法通过结合3D坐标轴和Segment Anything Model(SAM)生成的掩码，为MLLMs提供显式几何先验，成功将其在2D领域的grounding和推理能力扩展到3D场景。研究基于ScanRefer等四个3D数据集构建评估环境，实验表明3DAxisPrompt能有效帮助GPT-4o等MLLMs感知物体的3D位置，但也发现单一提示工程方法无法在所有3D任务中取得最佳效果。这项工作为利用提示工程技术实现MLLMs的3D视觉grounding/reasoning提供了实践依据。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13185v1",
      "published_date": "2025-03-17 13:57:05 UTC",
      "updated_date": "2025-03-17 13:57:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:20:08.042405"
    },
    {
      "arxiv_id": "2503.13180v2",
      "title": "GC-Fed: Gradient Centralized Federated Learning with Partial Client Participation",
      "title_zh": "GC-Fed：支持部分客户端参与的梯度中心化联邦学习",
      "authors": [
        "Jungwon Seo",
        "Ferhat Ozgur Catak",
        "Chunming Rong",
        "Kibeom Hong",
        "Minhoe Kim"
      ],
      "abstract": "Federated Learning (FL) enables privacy-preserving multi-source information\nfusion (MSIF) but is challenged by client drift in highly heterogeneous data\nsettings. Many existing drift-mitigation strategies rely on reference-based\ntechniques--such as gradient adjustments or proximal loss--that use historical\nsnapshots (e.g., past gradients or previous global models) as reference points.\nWhen only a subset of clients participates in each training round, these\nhistorical references may not accurately capture the overall data distribution,\nleading to unstable training. In contrast, our proposed Gradient Centralized\nFederated Learning (GC-Fed) employs a hyperplane as a historically independent\nreference point to guide local training and enhance inter-client alignment.\nGC-Fed comprises two complementary components: Local GC, which centralizes\ngradients during local training, and Global GC, which centralizes updates\nduring server aggregation. In our hybrid design, Local GC is applied to\nfeature-extraction layers to harmonize client contributions, while Global GC\nrefines classifier layers to stabilize round-wise performance. Theoretical\nanalysis and extensive experiments on benchmark FL tasks demonstrate that\nGC-Fed effectively mitigates client drift and achieves up to a 20% improvement\nin accuracy under heterogeneous and partial participation conditions.",
      "tldr_zh": "该研究提出梯度中心化联邦学习框架GC-Fed，通过创新性地采用超平面作为历史无关参考点，有效解决了异构数据和部分客户参与导致的客户端漂移问题。该方法包含局部梯度中心化(Local GC)和全局梯度中心化(Global GC)两个组件：前者在特征提取层协调客户贡献，后者在分类器层稳定训练过程。理论分析和实验表明，GC-Fed在异构和部分参与条件下最高可提升20%的准确率，显著优于现有基于历史参考的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13180v2",
      "published_date": "2025-03-17 13:54:27 UTC",
      "updated_date": "2025-03-20 08:41:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:20:12.437883"
    },
    {
      "arxiv_id": "2503.13178v1",
      "title": "Rapfi: Distilling Efficient Neural Network for the Game of Gomoku",
      "title_zh": "Rapfi：为五子棋游戏提炼高效神经网络",
      "authors": [
        "Zhanggen Jin",
        "Haobin Duan",
        "Zhiyang Hang"
      ],
      "abstract": "Games have played a pivotal role in advancing artificial intelligence, with\nAI agents using sophisticated techniques to compete. Despite the success of\nneural network based game AIs, their performance often requires significant\ncomputational resources. In this paper, we present Rapfi, an efficient Gomoku\nagent that outperforms CNN-based agents in limited computation environments.\nRapfi leverages a compact neural network with a pattern-based codebook\ndistilled from CNNs, and an incremental update scheme that minimizes\ncomputation when input changes are minor. This new network uses computation\nthat is orders of magnitude less to reach a similar accuracy of much larger\nneural networks such as Resnet. Thanks to our incremental update scheme,\ndepth-first search methods such as the alpha-beta search can be significantly\naccelerated. With a carefully tuned evaluation and search, Rapfi reached\nstrength surpassing Katagomo, the strongest open-source Gomoku AI based on\nAlphaZero's algorithm, under limited computational resources where accelerators\nlike GPUs are absent. Rapfi ranked first among 520 Gomoku agents on Botzone and\nwon the championship in GomoCup 2024.",
      "tldr_zh": "该研究提出了Rapfi，一种针对五子棋游戏的高效神经网络模型，能够在有限计算资源下超越传统CNN智能体。该方法通过从CNN中蒸馏出基于模式的轻量级网络，并结合增量更新机制，在输入变化较小时大幅减少计算量，其计算效率比ResNet等大型网络高出几个数量级。实验表明，Rapfi在无GPU加速的受限环境下超越了基于AlphaZero算法的最强开源五子棋AI Katagomo，并在Botzone平台的520个五子棋智能体中排名第一，赢得了2024年GomoCup冠军。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13178v1",
      "published_date": "2025-03-17 13:53:57 UTC",
      "updated_date": "2025-03-17 13:53:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:20:31.238531"
    },
    {
      "arxiv_id": "2503.13171v1",
      "title": "HybridGen: VLM-Guided Hybrid Planning for Scalable Data Generation of Imitation Learning",
      "title_zh": "HybridGen：VLM引导的混合规划用于模仿学习的可扩展数据生成",
      "authors": [
        "Wensheng Wang",
        "Ning Tan"
      ],
      "abstract": "The acquisition of large-scale and diverse demonstration data are essential\nfor improving robotic imitation learning generalization. However, generating\nsuch data for complex manipulations is challenging in real-world settings. We\nintroduce HybridGen, an automated framework that integrates Vision-Language\nModel (VLM) and hybrid planning. HybridGen uses a two-stage pipeline: first,\nVLM to parse expert demonstrations, decomposing tasks into expert-dependent\n(object-centric pose transformations for precise control) and plannable\nsegments (synthesizing diverse trajectories via path planning); second, pose\ntransformations substantially expand the first-stage data. Crucially, HybridGen\ngenerates a large volume of training data without requiring specific data\nformats, making it broadly applicable to a wide range of imitation learning\nalgorithms, a characteristic which we also demonstrate empirically across\nmultiple algorithms. Evaluations across seven tasks and their variants\ndemonstrate that agents trained with HybridGen achieve substantial performance\nand generalization gains, averaging a 5% improvement over state-of-the-art\nmethods. Notably, in the most challenging task variants, HybridGen achieves\nsignificant improvement, reaching a 59.7% average success rate, significantly\noutperforming Mimicgen's 49.5%. These results demonstrating its effectiveness\nand practicality.",
      "tldr_zh": "该研究提出HybridGen框架，通过结合视觉语言模型(VLM)和混合规划技术，为机器人模仿学习生成大规模多样化训练数据。该方法采用两阶段流程：首先用VLM解析专家演示，分解为基于对象的姿态变换和可规划轨迹；然后通过路径规划合成多样化数据。实验表明，在7项任务中，HybridGen生成的数据使学习算法平均性能提升5%，在最复杂任务变体上成功率显著提高10.2个百分点(达到59.7%)，超越现有最佳方法。该框架不依赖特定数据格式，可广泛应用于各类模仿学习算法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13171v1",
      "published_date": "2025-03-17 13:49:43 UTC",
      "updated_date": "2025-03-17 13:49:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:21:04.654995"
    },
    {
      "arxiv_id": "2503.14536v1",
      "title": "Advancing Chronic Tuberculosis Diagnostics Using Vision-Language Models: A Multi modal Framework for Precision Analysis",
      "title_zh": "推进慢性结核病诊断：基于视觉-语言模型的多模态精准分析框架",
      "authors": [
        "Praveen Shastry",
        "Sowmya Chowdary Muthulur",
        "Naveen Kumarasami",
        "Anandakumar D",
        "Mounigasri M",
        "Keerthana R",
        "Kishore Prasath Venkatesh",
        "Bargava Subramanian",
        "Kalyan Sivasailam",
        "Revathi Ezhumalai",
        "Abitha Marimuthu"
      ],
      "abstract": "Background This study proposes a Vision-Language Model (VLM) leveraging the\nSIGLIP encoder and Gemma-3b transformer decoder to enhance automated chronic\ntuberculosis (TB) screening. By integrating chest X-ray images with clinical\ndata, the model addresses the challenges of manual interpretation, improving\ndiagnostic consistency and accessibility, particularly in resource-constrained\nsettings.\n  Methods The VLM architecture combines a Vision Transformer (ViT) for visual\nencoding and a transformer-based text encoder to process clinical context, such\nas patient histories and treatment records. Cross-modal attention mechanisms\nalign radiographic features with textual information, while the Gemma-3b\ndecoder generates comprehensive diagnostic reports. The model was pre-trained\non 5 million paired medical images and texts and fine-tuned using 100,000\nchronic TB-specific chest X-rays.\n  Results The model demonstrated high precision (94 percent) and recall (94\npercent) for detecting key chronic TB pathologies, including fibrosis,\ncalcified granulomas, and bronchiectasis. Area Under the Curve (AUC) scores\nexceeded 0.93, and Intersection over Union (IoU) values were above 0.91,\nvalidating its effectiveness in detecting and localizing TB-related\nabnormalities.\n  Conclusion The VLM offers a robust and scalable solution for automated\nchronic TB diagnosis, integrating radiographic and clinical data to deliver\nactionable and context-aware insights. Future work will address subtle\npathologies and dataset biases to enhance the model's generalizability,\nensuring equitable performance across diverse populations and healthcare\nsettings.",
      "tldr_zh": "该研究提出了一种基于SIGLIP编码器和Gemma-3b解码器的视觉语言模型(VLM)，用于慢性结核病(TB)的自动化筛查。该多模态框架通过结合胸部X光图像和临床数据，采用跨模态注意力机制对齐放射学特征与文本信息，在检测慢性TB病变（如纤维化、钙化肉芽肿等）时达到了94%的精确率和召回率。实验结果显示模型AUC超过0.93，IoU高于0.91，为资源有限地区提供了可靠的自动化TB诊断方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "68T07, 92C55, 68U10, 92C50, 60G35"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages , 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.14536v1",
      "published_date": "2025-03-17 13:49:29 UTC",
      "updated_date": "2025-03-17 13:49:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:21:23.129374"
    },
    {
      "arxiv_id": "2503.13169v1",
      "title": "Collaborative AI Enhances Image Understanding in Materials Science",
      "title_zh": "协作式人工智能提升材料科学中的图像理解能力",
      "authors": [
        "Ruoyan Avery Yin",
        "Zhichu Ren",
        "Zongyou Yin",
        "Zhen Zhang",
        "So Yeon Kim",
        "Chia-Wei Hsu",
        "Ju Li"
      ],
      "abstract": "The Copilot for Real-world Experimental Scientist (CRESt) system empowers\nresearchers to control autonomous laboratories through conversational AI,\nproviding a seamless interface for managing complex experimental workflows. We\nhave enhanced CRESt by integrating a multi-agent collaboration mechanism that\nutilizes the complementary strengths of the ChatGPT and Gemini models for\nprecise image analysis in materials science. This innovative approach\nsignificantly improves the accuracy of experimental outcomes by fostering\nstructured debates between the AI models, which enhances decision-making\nprocesses in materials phase analysis. Additionally, to evaluate the\ngeneralizability of this approach, we tested it on a quantitative task of\ncounting particles. Here, the collaboration between the AI models also led to\nimproved results, demonstrating the versatility and robustness of this method.\nBy harnessing this dual-AI framework, this approach stands as a pioneering\nmethod for enhancing experimental accuracy and efficiency in materials\nresearch, with applications extending beyond CRESt to broader scientific\nexperimentation and analysis.",
      "tldr_zh": "本研究提出了CRESt系统，通过集成ChatGPT和Gemini模型的多智能体协作机制，显著提升了材料科学中图像分析的准确性。该创新方法通过AI模型间的结构化辩论增强材料相分析的决策过程，并在颗粒计数等定量任务中展示了其通用性和鲁棒性。这一双AI框架不仅提高了材料研究的实验精度和效率，还为更广泛的科学实验与分析提供了新方法。",
      "categories": [
        "cs.AI",
        "I.2.1; I.2.10"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13169v1",
      "published_date": "2025-03-17 13:44:30 UTC",
      "updated_date": "2025-03-17 13:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:21:49.359315"
    },
    {
      "arxiv_id": "2503.13575v1",
      "title": "Analytic Subspace Routing: How Recursive Least Squares Works in Continual Learning of Large Language Model",
      "title_zh": "解析子空间路由：递归最小二乘法在大型语言模型持续学习中的工作原理",
      "authors": [
        "Kai Tong",
        "Kang Pan",
        "Xiao Zhang",
        "Erli Meng",
        "Run He",
        "Yawen Cui",
        "Nuoyan Guo",
        "Huiping Zhuang"
      ],
      "abstract": "Large Language Models (LLMs) possess encompassing capabilities that can\nprocess diverse language-related tasks. However, finetuning on LLMs will\ndiminish this general skills and continual finetuning will further cause severe\ndegradation on accumulated knowledge. Recently, Continual Learning (CL) in\nLarge Language Models (LLMs) arises which aims to continually adapt the LLMs to\nnew tasks while maintaining previously learned knowledge and inheriting general\nskills. Existing techniques either leverage previous data to replay, leading to\nextra computational costs, or utilize a single parameter-efficient module to\nlearn the downstream task, constraining new knowledge absorption with\ninterference between different tasks. Toward these issues, this paper proposes\nAnalytic Subspace Routing(ASR) to address these challenges. For each task, we\nisolate the learning within a subspace of deep layers' features via low-rank\nadaptation, eliminating knowledge interference between different tasks.\nAdditionally, we propose an analytic routing mechanism to properly utilize\nknowledge learned in different subspaces. Our approach employs Recursive Least\nSquares to train a multi-task router model, allowing the router to dynamically\nadapt to incoming data without requiring access to historical data. Also, the\nrouter effectively assigns the current task to an appropriate subspace and has\na non-forgetting property of previously learned tasks with a solid theoretical\nguarantee. Experimental results demonstrate that our method achieves\nnear-perfect retention of prior knowledge while seamlessly integrating new\ninformation, effectively overcoming the core limitations of existing methods.\nOur code will be released after acceptance.",
      "tldr_zh": "本研究提出**Analytic Subspace Routing (ASR)**方法，通过**递归最小二乘法(Recursive Least Squares)**实现大语言模型(LLM)的持续学习。其核心创新在于：1) 采用**低秩适应(LoRA)**为每个任务隔离深层特征子空间学习，消除任务间知识干扰；2) 设计基于动态路由的多任务分配机制，无需历史数据即可自适应选择子空间，并理论保证对旧任务的非遗忘性。实验表明该方法近乎完美保留已有知识的同时高效吸收新任务，解决了传统方法在计算成本与知识干扰间的两难问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13575v1",
      "published_date": "2025-03-17 13:40:46 UTC",
      "updated_date": "2025-03-17 13:40:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:22:02.351758"
    },
    {
      "arxiv_id": "2503.13162v1",
      "title": "Efficient Imitation Under Misspecification",
      "title_zh": "误设条件下的高效模仿学习",
      "authors": [
        "Nicolas Espinosa-Dice",
        "Sanjiban Choudhury",
        "Wen Sun",
        "Gokul Swamy"
      ],
      "abstract": "Interactive imitation learning (IL) is a powerful paradigm for learning to\nmake sequences of decisions from an expert demonstrating how to perform a task.\nPrior work in efficient imitation learning has focused on the realizable\nsetting, where the expert's policy lies within the learner's policy class (i.e.\nthe learner can perfectly imitate the expert in all states). However, in\npractice, perfect imitation of the expert is often impossible due to\ndifferences in state information and action space expressiveness (e.g.\nmorphological differences between robots and humans.) In this paper, we\nconsider the more general misspecified setting, where no assumptions are made\nabout the expert policy's realizability. We introduce a novel structural\ncondition, reward-agnostic policy completeness, and prove that it is sufficient\nfor interactive IL algorithms to efficiently avoid the quadratically\ncompounding errors that stymie offline approaches like behavioral cloning. We\naddress an additional practical constraint-the case of limited expert data-and\npropose a principled method for using additional offline data to further\nimprove the sample-efficiency of interactive IL algorithms. Finally, we\nempirically investigate the optimal reset distribution in efficient IL under\nmisspecification with a suite of continuous control tasks.",
      "tldr_zh": "该论文研究了模仿学习（IL）在错误设定（misspecification）下的高效学习问题，即专家策略可能不完全属于学习者策略类的情况。作者提出了\"奖励无关策略完备性\"（reward-agnostic policy completeness）这一新结构条件，证明其能有效防止传统离线方法（如行为克隆）中误差二次累积的问题。针对专家数据有限的实际约束，论文还提出利用额外离线数据提升交互式IL算法样本效率的方法，并通过连续控制任务实验验证了错误设定下最优重置分布的效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "37 pages, 5 figures. Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13162v1",
      "published_date": "2025-03-17 13:35:55 UTC",
      "updated_date": "2025-03-17 13:35:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:22:11.902509"
    },
    {
      "arxiv_id": "2503.13149v1",
      "title": "Are LLMs (Really) Ideological? An IRT-based Analysis and Alignment Tool for Perceived Socio-Economic Bias in LLMs",
      "title_zh": "大语言模型真的具有意识形态倾向吗？基于IRT的感知社会经济偏见分析与对齐工具",
      "authors": [
        "Jasmin Wachter",
        "Michael Radloff",
        "Maja Smolej",
        "Katharina Kinder-Kurlanda"
      ],
      "abstract": "We introduce an Item Response Theory (IRT)-based framework to detect and\nquantify socioeconomic bias in large language models (LLMs) without relying on\nsubjective human judgments. Unlike traditional methods, IRT accounts for item\ndifficulty, improving ideological bias estimation. We fine-tune two LLM\nfamilies (Meta-LLaMa 3.2-1B-Instruct and Chat- GPT 3.5) to represent distinct\nideological positions and introduce a two-stage approach: (1) modeling response\navoidance and (2) estimating perceived bias in answered responses. Our results\nshow that off-the-shelf LLMs often avoid ideological engagement rather than\nexhibit bias, challenging prior claims of partisanship. This empirically\nvalidated framework enhances AI alignment research and promotes fairer AI\ngovernance.",
      "tldr_zh": "该研究提出了一种基于项目反应理论(IRT)的框架，用于检测和量化大型语言模型(LLMs)中的社会经济偏见，无需依赖主观人为判断。研究者对Meta-LLaMa和ChatGPT两种模型进行微调以代表不同意识形态立场，并开发了两阶段分析方法：分析回答回避行为和评估已回答内容中的感知偏见。实证结果表明，现成LLMs往往回避意识形态表达而非表现出偏见，这挑战了先前关于模型党派性的论断。该框架为AI对齐研究和公平治理提供了新工具。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13149v1",
      "published_date": "2025-03-17 13:20:09 UTC",
      "updated_date": "2025-03-17 13:20:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:22:45.665343"
    },
    {
      "arxiv_id": "2503.13139v1",
      "title": "Logic-in-Frames: Dynamic Keyframe Search via Visual Semantic-Logical Verification for Long Video Understanding",
      "title_zh": "帧间逻辑：基于视觉语义-逻辑验证的动态关键帧搜索方法及其在长视频理解中的应用",
      "authors": [
        "Weiyu Guo",
        "Ziyang Chen",
        "Shaoguang Wang",
        "Jianxiang He",
        "Yijie Xu",
        "Jinhui Ye",
        "Ying Sun",
        "Hui Xiong"
      ],
      "abstract": "Understanding long video content is a complex endeavor that often relies on\ndensely sampled frame captions or end-to-end feature selectors, yet these\ntechniques commonly overlook the logical relationships between textual queries\nand visual elements. In practice, computational constraints necessitate coarse\nframe subsampling, a challenge analogous to ``finding a needle in a haystack.''\nTo address this issue, we introduce a semantics-driven search framework that\nreformulates keyframe selection under the paradigm of Visual Semantic-Logical\nSearch. Specifically, we systematically define four fundamental logical\ndependencies: 1) spatial co-occurrence, 2) temporal proximity, 3) attribute\ndependency, and 4) causal order. These relations dynamically update frame\nsampling distributions through an iterative refinement process, enabling\ncontext-aware identification of semantically critical frames tailored to\nspecific query requirements. Our method establishes new SOTA performance on the\nmanually annotated benchmark in key-frame selection metrics. Furthermore, when\napplied to downstream video question-answering tasks, the proposed approach\ndemonstrates the best performance gains over existing methods on LongVideoBench\nand Video-MME, validating its effectiveness in bridging the logical gap between\ntextual queries and visual-temporal reasoning. The code will be publicly\navailable.",
      "tldr_zh": "该研究提出Logic-in-Frames框架，通过视觉语义-逻辑验证实现长视频理解中的动态关键帧搜索。该方法系统定义了四种核心逻辑关系（空间共现、时序邻近、属性依赖和因果顺序），通过迭代优化过程动态调整帧采样分布，实现面向查询需求的上下文感知关键帧定位。实验表明，该方法在关键帧选择指标上创下新SOTA，并在长视频问答任务（LongVideoBench和Video-MME）中显著优于现有方法，有效弥合了文本查询与视觉时序推理间的逻辑鸿沟。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, under review",
      "pdf_url": "http://arxiv.org/pdf/2503.13139v1",
      "published_date": "2025-03-17 13:07:34 UTC",
      "updated_date": "2025-03-17 13:07:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:22:55.449232"
    },
    {
      "arxiv_id": "2503.13123v1",
      "title": "MIXPINN: Mixed-Material Simulations by Physics-Informed Neural Network",
      "title_zh": "MIXPINN：基于物理信息神经网络的混合材料仿真",
      "authors": [
        "Xintian Yuan",
        "Yunke Ao",
        "Boqi Chen",
        "Philipp Fuernstahl"
      ],
      "abstract": "Simulating the complex interactions between soft tissues and rigid anatomy is\ncritical for applications in surgical training, planning, and robotic-assisted\ninterventions. Traditional Finite Element Method (FEM)-based simulations, while\naccurate, are computationally expensive and impractical for real-time\nscenarios. Learning-based approaches have shown promise in accelerating\npredictions but have fallen short in modeling soft-rigid interactions\neffectively. We introduce MIXPINN, a physics-informed Graph Neural Network\n(GNN) framework for mixed-material simulations, explicitly capturing soft-rigid\ninteractions using graph-based augmentations. Our approach integrates Virtual\nNodes (VNs) and Virtual Edges (VEs) to enhance rigid body constraint\nsatisfaction while preserving computational efficiency. By leveraging a\ngraph-based representation of biomechanical structures, MIXPINN learns\nhigh-fidelity deformations from FEM-generated data and achieves real-time\ninference with sub-millimeter accuracy. We validate our method in a realistic\nclinical scenario, demonstrating superior performance compared to baseline GNN\nmodels and traditional FEM methods. Our results show that MIXPINN reduces\ncomputational cost by an order of magnitude while maintaining high physical\naccuracy, making it a viable solution for real-time surgical simulation and\nrobotic-assisted procedures.",
      "tldr_zh": "该研究提出MIXPINN，一种基于物理信息图神经网络(GNN)的混合材料仿真框架，专门用于模拟软组织与刚性解剖结构的复杂交互。该方法创新性地采用虚拟节点(VNs)和虚拟边(VEs)的图结构增强技术，在保持计算效率的同时有效满足刚体约束条件。实验表明，MIXPINN能从有限元(FEM)生成数据中学习高精度形变，实现亚毫米级精度的实时推理，计算成本比传统FEM降低一个数量级，为实时手术仿真和机器人辅助手术提供了可行解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "This work has been submitted to the lEEE IROS 2025 for possible\n  publication",
      "pdf_url": "http://arxiv.org/pdf/2503.13123v1",
      "published_date": "2025-03-17 12:48:29 UTC",
      "updated_date": "2025-03-17 12:48:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:23:25.606327"
    },
    {
      "arxiv_id": "2503.13115v1",
      "title": "Beyond Propagation of Chaos: A Stochastic Algorithm for Mean Field Optimization",
      "title_zh": "超越混沌传播：一种用于平均场优化的随机算法",
      "authors": [
        "Chandan Tankala",
        "Dheeraj M. Nagaraj",
        "Anant Raj"
      ],
      "abstract": "Gradient flow in the 2-Wasserstein space is widely used to optimize\nfunctionals over probability distributions and is typically implemented using\nan interacting particle system with $n$ particles. Analyzing these algorithms\nrequires showing (a) that the finite-particle system converges and/or (b) that\nthe resultant empirical distribution of the particles closely approximates the\noptimal distribution (i.e., propagation of chaos). However, establishing\nefficient sufficient conditions can be challenging, as the finite particle\nsystem may produce heavily dependent random variables.\n  In this work, we study the virtual particle stochastic approximation,\noriginally introduced for Stein Variational Gradient Descent. This method can\nbe viewed as a form of stochastic gradient descent in the Wasserstein space and\ncan be implemented efficiently. In popular settings, we demonstrate that our\nalgorithm's output converges to the optimal distribution under conditions\nsimilar to those for the infinite particle limit, and it produces i.i.d.\nsamples without the need to explicitly establish propagation of chaos bounds.",
      "tldr_zh": "本文提出了一种超越传统\"混沌传播\"(propagation of chaos)的随机算法——虚拟粒子随机逼近法(Virtual Particle Stochastic Approximation)，用于求解平均场优化问题。该方法将2-Wasserstein空间中的梯度流实现为一种高效的随机梯度下降形式，无需显式建立有限粒子系统的混沌传播边界。研究表明，在典型设置下，该算法输出会收敛到最优分布，并能直接生成独立同分布(i.i.d.)样本，其收敛条件与无限粒子极限情况相似。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.PR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13115v1",
      "published_date": "2025-03-17 12:37:53 UTC",
      "updated_date": "2025-03-17 12:37:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:23:42.077086"
    },
    {
      "arxiv_id": "2503.13108v1",
      "title": "Lifting the Veil on Visual Information Flow in MLLMs: Unlocking Pathways to Faster Inference",
      "title_zh": "揭开MLLM视觉信息流的面纱：解锁更快速推理的路径",
      "authors": [
        "Hao Yin",
        "Guangzong Si",
        "Zilei Wang"
      ],
      "abstract": "Multimodal large language models (MLLMs) improve performance on\nvision-language tasks by integrating visual features from pre-trained vision\nencoders into large language models (LLMs). However, how MLLMs process and\nutilize visual information remains unclear. In this paper, a shift in the\ndominant flow of visual information is uncovered: (1) in shallow layers, strong\ninteractions are observed between image tokens and instruction tokens, where\nmost visual information is injected into instruction tokens to form cross-modal\nsemantic representations; (2) in deeper layers, image tokens primarily interact\nwith each other, aggregating the remaining visual information to optimize\nsemantic representations within visual modality. Based on these insights, we\npropose Hierarchical Modality-Aware Pruning (HiMAP), a plug-and-play inference\nacceleration method that dynamically prunes image tokens at specific layers,\nreducing computational costs by approximately 65% without sacrificing\nperformance. Our findings offer a new understanding of visual information\nprocessing in MLLMs and provide a state-of-the-art solution for efficient\ninference.",
      "tldr_zh": "该研究揭示了多模态大语言模型(MLLMs)中视觉信息流的处理机制：浅层网络主要将视觉特征注入指令token形成跨模态语义，而深层网络则聚焦视觉模态内的信息聚合。基于这一发现，作者提出了层级模态感知剪枝方法(HiMAP)，通过动态剪枝图像token将计算成本降低约65%且不损失性能。这项工作不仅深化了对MLLMs视觉处理机制的理解，还为高效推理提供了创新解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13108v1",
      "published_date": "2025-03-17 12:31:23 UTC",
      "updated_date": "2025-03-17 12:31:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:24:08.594035"
    },
    {
      "arxiv_id": "2503.13107v1",
      "title": "ClearSight: Visual Signal Enhancement for Object Hallucination Mitigation in Multimodal Large language Models",
      "title_zh": "ClearSight：用于缓解多模态大语言模型目标幻觉的视觉信号增强",
      "authors": [
        "Hao Yin",
        "Guangzong Si",
        "Zilei Wang"
      ],
      "abstract": "Contrastive decoding strategies are widely used to mitigate object\nhallucinations in multimodal large language models (MLLMs). By reducing\nover-reliance on language priors, these strategies ensure that generated\ncontent remains closely grounded in visual inputs, producing contextually\naccurate outputs. Since contrastive decoding requires no additional training or\nexternal tools, it offers both computational efficiency and versatility, making\nit highly attractive. However, these methods present two main limitations: (1)\nbluntly suppressing language priors can compromise coherence and accuracy of\ngenerated content, and (2) processing contrastive inputs adds computational\nload, significantly slowing inference speed. To address these challenges, we\npropose Visual Amplification Fusion (VAF), a plug-and-play technique that\nenhances attention to visual signals within the model's middle layers, where\nmodality fusion predominantly occurs. This approach enables more effective\ncapture of visual features, reducing the model's bias toward language modality.\nExperimental results demonstrate that VAF significantly reduces hallucinations\nacross various MLLMs without affecting inference speed, while maintaining\ncoherence and accuracy in generated outputs.",
      "tldr_zh": "该研究提出了一种名为\"视觉放大融合\"(Visual Amplification Fusion, VAF)的即插即用技术，用于缓解多模态大语言模型(MLLMs)中的物体幻觉问题。该方法通过在模型中间层(模态融合主要发生处)增强视觉信号注意力，有效降低了模型对语言模态的依赖偏差。实验表明，VAF能在不影响推理速度的情况下，显著减少多种MLLMs的幻觉现象，同时保持生成内容的连贯性和准确性。该技术无需额外训练或外部工具，兼具计算效率和通用性优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13107v1",
      "published_date": "2025-03-17 12:30:40 UTC",
      "updated_date": "2025-03-17 12:30:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:24:29.998571"
    },
    {
      "arxiv_id": "2503.14535v1",
      "title": "Interpretable Unsupervised Joint Denoising and Enhancement for Real-World low-light Scenarios",
      "title_zh": "面向真实世界低光场景的可解释无监督联合去噪与增强方法",
      "authors": [
        "Huaqiu Li",
        "Xiaowan Hu",
        "Haoqian Wang"
      ],
      "abstract": "Real-world low-light images often suffer from complex degradations such as\nlocal overexposure, low brightness, noise, and uneven illumination. Supervised\nmethods tend to overfit to specific scenarios, while unsupervised methods,\nthough better at generalization, struggle to model these degradations due to\nthe lack of reference images. To address this issue, we propose an\ninterpretable, zero-reference joint denoising and low-light enhancement\nframework tailored for real-world scenarios. Our method derives a training\nstrategy based on paired sub-images with varying illumination and noise levels,\ngrounded in physical imaging principles and retinex theory. Additionally, we\nleverage the Discrete Cosine Transform (DCT) to perform frequency domain\ndecomposition in the sRGB space, and introduce an implicit-guided hybrid\nrepresentation strategy that effectively separates intricate compounded\ndegradations. In the backbone network design, we develop retinal decomposition\nnetwork guided by implicit degradation representation mechanisms. Extensive\nexperiments demonstrate the superiority of our method. Code will be available\nat https://github.com/huaqlili/unsupervised-light-enhance-ICLR2025.",
      "tldr_zh": "该研究提出了一种可解释的无监督联合去噪与低光增强框架，专门针对真实场景中局部过曝、亮度不足、噪声和光照不均等复杂退化问题。基于物理成像原理和Retinex理论，该方法创新性地利用成对子图像训练策略，并通过离散余弦变换(DCT)在sRGB空间进行频域分解，结合隐式引导的混合表示策略有效分离复合退化。实验证明，该框架在保持模型泛化能力的同时，显著优于现有方法，代码将在ICLR2025开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.14535v1",
      "published_date": "2025-03-17 12:08:52 UTC",
      "updated_date": "2025-03-17 12:08:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:25:02.903096"
    },
    {
      "arxiv_id": "2503.13570v1",
      "title": "ExChanGeAI: An End-to-End Platform and Efficient Foundation Model for Electrocardiogram Analysis and Fine-tuning",
      "title_zh": "ExChanGeAI：面向心电图分析与微调的一站式平台及高效基础模型",
      "authors": [
        "Lucas Bickmann",
        "Lucas Plagwitz",
        "Antonius Büscher",
        "Lars Eckardt",
        "Julian Varghese"
      ],
      "abstract": "Electrocardiogram data, one of the most widely available biosignal data, has\nbecome increasingly valuable with the emergence of deep learning methods,\nproviding novel insights into cardiovascular diseases and broader health\nconditions. However, heterogeneity of electrocardiogram formats, limited access\nto deep learning model weights and intricate algorithmic steps for effective\nfine-tuning for own disease target labels result in complex workflows. In this\nwork, we introduce ExChanGeAI, a web-based end-to-end platform that streamlines\nthe reading of different formats, pre-processing, visualization and custom\nmachine learning with local and privacy-preserving fine-tuning. ExChanGeAI is\nadaptable for use on both personal computers and scalable to high performance\nserver environments. The platform offers state-of-the-art deep learning models\nfor training from scratch, alongside our novel open-source electrocardiogram\nfoundation model CardX, pre-trained on over one million electrocardiograms.\nEvaluation across three external validation sets, including an entirely new\ntestset extracted from routine care, demonstrate the fine-tuning capabilities\nof ExChanGeAI. CardX outperformed the benchmark foundation model while\nrequiring significantly fewer parameters and lower computational resources. The\nplatform enables users to empirically determine the most suitable model for\ntheir specific tasks based on systematic validations.The code is available at\nhttps://imigitlab.uni-muenster.de/published/exchangeai .",
      "tldr_zh": "该研究提出了ExChanGeAI，一个端到端的平台，用于简化心电图(ECG)数据的读取、预处理、可视化和定制化机器学习。该平台提供了一个新型开源心电图基础模型CardX，基于超过100万份心电图数据预训练，并在三个外部验证集上展示了其微调能力。CardX在性能上超越了基准模型，同时显著减少了参数数量和计算资源需求。该平台支持用户根据系统验证结果选择最适合其特定任务的模型，并可在个人电脑和高性能服务器环境中灵活使用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13570v1",
      "published_date": "2025-03-17 11:58:52 UTC",
      "updated_date": "2025-03-17 11:58:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:25:07.240943"
    },
    {
      "arxiv_id": "2503.13089v1",
      "title": "ClusComp: A Simple Paradigm for Model Compression and Efficient Finetuning",
      "title_zh": "ClusComp：一种面向模型压缩与高效微调的简洁范式",
      "authors": [
        "Baohao Liao",
        "Christian Herold",
        "Seyyed Hadi Hashemi",
        "Stefan Vasilev",
        "Shahram Khadivi",
        "Christof Monz"
      ],
      "abstract": "As large language models (LLMs) scale, model compression is crucial for edge\ndeployment and accessibility. Weight-only quantization reduces model size but\nsuffers from performance degradation at lower bit widths. Moreover, standard\nfinetuning is incompatible with quantized models, and alternative methods often\nfall short of full finetuning. In this paper, we propose ClusComp, a simple yet\neffective compression paradigm that clusters weight matrices into codebooks and\nfinetunes them block-by-block. ClusComp (1) achieves superior performance in\n2-4 bit quantization, (2) pushes compression to 1-bit while outperforming\nultra-low-bit methods with minimal finetuning, and (3) enables efficient\nfinetuning, even surpassing existing quantization-based approaches and rivaling\nfull FP16 finetuning. Notably, ClusComp supports compression and finetuning of\n70B LLMs on a single A6000-48GB GPU.",
      "tldr_zh": "本文提出ClusComp模型压缩新范式，通过将权重矩阵聚类为codebook并分块微调，实现了三大突破：1）在2-4位量化中性能优异；2）支持1位超低比特压缩且微调效率超越现有方法；3）可在单块A6000显卡上完成700亿参数大模型的压缩与微调。该方法不仅解决了传统量化模型性能下降和微调不兼容的问题，其表现甚至能媲美全精度FP16微调效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 11 figures, 18 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.13089v1",
      "published_date": "2025-03-17 11:52:16 UTC",
      "updated_date": "2025-03-17 11:52:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:25:56.255933"
    },
    {
      "arxiv_id": "2503.13082v1",
      "title": "Free-form language-based robotic reasoning and grasping",
      "title_zh": "基于自由语言指令的机器人推理与抓取",
      "authors": [
        "Runyu Jiao",
        "Alice Fasoli",
        "Francesco Giuliari",
        "Matteo Bortolon",
        "Sergio Povoli",
        "Guofeng Mei",
        "Yiming Wang",
        "Fabio Poiesi"
      ],
      "abstract": "Performing robotic grasping from a cluttered bin based on human instructions\nis a challenging task, as it requires understanding both the nuances of\nfree-form language and the spatial relationships between objects.\nVision-Language Models (VLMs) trained on web-scale data, such as GPT-4o, have\ndemonstrated remarkable reasoning capabilities across both text and images. But\ncan they truly be used for this task in a zero-shot setting? And what are their\nlimitations? In this paper, we explore these research questions via the\nfree-form language-based robotic grasping task, and propose a novel method,\nFreeGrasp, leveraging the pre-trained VLMs' world knowledge to reason about\nhuman instructions and object spatial arrangements. Our method detects all\nobjects as keypoints and uses these keypoints to annotate marks on images,\naiming to facilitate GPT-4o's zero-shot spatial reasoning. This allows our\nmethod to determine whether a requested object is directly graspable or if\nother objects must be grasped and removed first. Since no existing dataset is\nspecifically designed for this task, we introduce a synthetic dataset\nFreeGraspData by extending the MetaGraspNetV2 dataset with human-annotated\ninstructions and ground-truth grasping sequences. We conduct extensive analyses\nwith both FreeGraspData and real-world validation with a gripper-equipped\nrobotic arm, demonstrating state-of-the-art performance in grasp reasoning and\nexecution. Project website: https://tev-fbk.github.io/FreeGrasp/.",
      "tldr_zh": "该论文提出FreeGrasp方法，利用预训练视觉语言模型(VLMs)如GPT-4o的零样本推理能力，解决基于自由语言指令的机器人抓取问题。通过将物体检测为关键点并标注图像，该方法能判断目标物体是否可直接抓取或需先移除障碍物。研究者还创建了合成数据集FreeGraspData，并在真实机械臂实验中验证了该方法在抓取推理和执行方面的先进性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: https://tev-fbk.github.io/FreeGrasp/",
      "pdf_url": "http://arxiv.org/pdf/2503.13082v1",
      "published_date": "2025-03-17 11:41:16 UTC",
      "updated_date": "2025-03-17 11:41:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:25:41.180522"
    },
    {
      "arxiv_id": "2503.16523v1",
      "title": "Mind2: Mind-to-Mind Emotional Support System with Bidirectional Cognitive Discourse Analysis",
      "title_zh": "Mind2：基于双向认知话语分析的心智间情绪支持系统",
      "authors": [
        "Shi Yin Hong",
        "Uttamasha Oyshi",
        "Quan Mai",
        "Gibson Nkhata",
        "Susan Gauch"
      ],
      "abstract": "Emotional support (ES) systems alleviate users' mental distress by generating\nstrategic supportive dialogues based on diverse user situations. However, ES\nsystems are limited in their ability to generate effective ES dialogues that\ninclude timely context and interpretability, hindering them from earning public\ntrust. Driven by cognitive models, we propose Mind-to-Mind (Mind2), an ES\nframework that approaches interpretable ES context modeling for the ES dialogue\ngeneration task from a discourse analysis perspective. Specifically, we perform\ncognitive discourse analysis on ES dialogues according to our dynamic discourse\ncontext propagation window, which accommodates evolving context as the\nconversation between the ES system and user progresses. To enhance\ninterpretability, Mind2 prioritizes details that reflect each speaker's belief\nabout the other speaker with bidirectionality, integrating Theory-of-Mind,\nphysiological expected utility, and cognitive rationality to extract cognitive\nknowledge from ES conversations. Experimental results support that Mind2\nachieves competitive performance versus state-of-the-art ES systems while\ntrained with only 10\\% of the available training data.",
      "tldr_zh": "该研究提出了Mind-to-Mind (Mind2)，一种基于双向认知话语分析的情感支持系统。通过动态话语上下文传播窗口，Mind2能够捕捉对话中不断演变的语境，并结合心智理论(Theory-of-Mind)、生理预期效用和认知理性，提取对话中的认知知识，从而提高生成情感支持对话的及时性和可解释性。实验表明，Mind2在仅使用10%训练数据的情况下，性能优于现有最先进的情感支持系统。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 2 figures, and 3 tables; WI-IAT 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.16523v1",
      "published_date": "2025-03-17 11:39:56 UTC",
      "updated_date": "2025-03-17 11:39:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:26:07.212033"
    },
    {
      "arxiv_id": "2503.13081v1",
      "title": "A Framework to Assess Multilingual Vulnerabilities of LLMs",
      "title_zh": "评估大型语言模型多语言漏洞的框架",
      "authors": [
        "Likai Tang",
        "Niruth Bogahawatta",
        "Yasod Ginige",
        "Jiarui Xu",
        "Shixuan Sun",
        "Surangika Ranathunga",
        "Suranga Seneviratne"
      ],
      "abstract": "Large Language Models (LLMs) are acquiring a wider range of capabilities,\nincluding understanding and responding in multiple languages. While they\nundergo safety training to prevent them from answering illegal questions,\nimbalances in training data and human evaluation resources can make these\nmodels more susceptible to attacks in low-resource languages (LRL). This paper\nproposes a framework to automatically assess the multilingual vulnerabilities\nof commonly used LLMs. Using our framework, we evaluated six LLMs across eight\nlanguages representing varying levels of resource availability. We validated\nthe assessments generated by our automated framework through human evaluation\nin two languages, demonstrating that the framework's results align with human\njudgments in most cases. Our findings reveal vulnerabilities in LRL; however,\nthese may pose minimal risk as they often stem from the model's poor\nperformance, resulting in incoherent responses.",
      "tldr_zh": "本研究提出了一个自动评估大语言模型(LLMs)多语言漏洞的框架。该框架测试了六种常用LLMs在八种不同资源水平语言中的表现，并通过人工评估验证了其有效性。研究发现，低资源语言(LRL)中的漏洞主要源于模型性能不佳导致的回答不连贯，尽管这些漏洞风险较低。该框架为识别和解决LLMs的多语言安全问题提供了有效工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13081v1",
      "published_date": "2025-03-17 11:39:44 UTC",
      "updated_date": "2025-03-17 11:39:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:26:32.868536"
    },
    {
      "arxiv_id": "2503.13055v1",
      "title": "Mitigating Cross-Modal Distraction and Ensuring Geometric Feasibility via Affordance-Guided, Self-Consistent MLLMs for Food Preparation Task Planning",
      "title_zh": "通过可供性引导与自洽多模态大语言模型缓解跨模态干扰并确保几何可行性：面向食品制备任务规划",
      "authors": [
        "Yu-Hong Shen",
        "Chuan-Yu Wu",
        "Yi-Ru Yang",
        "Yen-Ling Tai",
        "Yi-Ting Chen"
      ],
      "abstract": "We study Multimodal Large Language Models (MLLMs) with in-context learning\nfor food preparation task planning. In this context, we identify two key\nchallenges: cross-modal distraction and geometric feasibility. Cross-modal\ndistraction occurs when the inclusion of visual input degrades the reasoning\nperformance of a MLLM. Geometric feasibility refers to the ability of MLLMs to\nensure that the selected skills are physically executable in the environment.\nTo address these issues, we adapt Chain of Thought (CoT) with Self-Consistency\nto mitigate reasoning loss from cross-modal distractions and use affordance\npredictor as skill preconditions to guide MLLM on geometric feasibility. We\nconstruct a dataset to evaluate the ability of MLLMs on quantity estimation,\nreachability analysis, relative positioning and collision avoidance. We\nconducted a detailed evaluation to identify issues among different baselines\nand analyze the reasons for improvement, providing insights into each approach.\nOur method reaches a success rate of 76.7% on the entire dataset, showing a\nsubstantial improvement over the CoT baseline at 36.7%.",
      "tldr_zh": "该研究针对多模态大语言模型(MLLMs)在食物制备任务规划中的两大挑战：跨模态干扰和几何可行性问题，提出了一种基于功能可供性(affordance)引导的自洽推理方法。通过结合链式思维(CoT)与自洽性推理缓解视觉输入导致的推理性能下降，并利用功能可供性预测器作为技能先决条件来确保动作的物理可执行性。实验构建了包含数量估计、可达性分析等任务的数据集，相比36.7%的CoT基线，该方法将成功率显著提升至76.7%，为具身智能的任务规划提供了新思路。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13055v1",
      "published_date": "2025-03-17 11:01:02 UTC",
      "updated_date": "2025-03-17 11:01:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:26:53.996921"
    },
    {
      "arxiv_id": "2503.13568v1",
      "title": "WMINet: A Wheel-Mounted Inertial Learning Approach For Mobile-Robot Positioning",
      "title_zh": "WMINet：一种基于轮载惯性学习的移动机器人定位方法",
      "authors": [
        "Gal Versano",
        "Itzik Klein"
      ],
      "abstract": "Autonomous mobile robots are widely used for navigation, transportation, and\ninspection tasks indoors and outdoors. In practical situations of limited\nsatellite signals or poor lighting conditions, navigation depends only on\ninertial sensors. In such cases, the navigation solution rapidly drifts due to\ninertial measurement errors. In this work, we propose WMINet a wheel-mounted\ninertial deep learning approach to estimate the mobile robot's position based\nonly on its inertial sensors. To that end, we merge two common practical\nmethods to reduce inertial drift: a wheel-mounted approach and driving the\nmobile robot in periodic trajectories. Additionally, we enforce a wheelbase\nconstraint to further improve positioning performance. To evaluate our proposed\napproach we recorded using the Rosbot-XL a wheel-mounted initial dataset\ntotaling 190 minutes, which is made publicly available. Our approach\ndemonstrated a 66\\% improvement over state-of-the-art approaches. As a\nconsequence, our approach enables navigation in challenging environments and\nbridges the pure inertial gap. This enables seamless robot navigation using\nonly inertial sensors for short periods.",
      "tldr_zh": "该研究提出了一种名为WMINet的轮式惯性深度学习定位方法，用于在卫星信号受限或光照条件不佳的环境中，仅依赖惯性传感器实现移动机器人的精确定位。该方法结合了轮式安装和周期性轨迹驱动两种常见技术，并引入轮距约束，进一步提升了定位性能。实验结果表明，WMINet在公开的Rosbot-XL数据集上比现有技术提高了66%的精度，为短时间内的纯惯性导航提供了有效解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13568v1",
      "published_date": "2025-03-17 10:43:46 UTC",
      "updated_date": "2025-03-17 10:43:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:27:11.992855"
    },
    {
      "arxiv_id": "2503.13025v1",
      "title": "PoseSyn: Synthesizing Diverse 3D Pose Data from In-the-Wild 2D Data",
      "title_zh": "PoseSyn：利用野外2D数据合成多样化3D姿态数据",
      "authors": [
        "ChangHee Yang",
        "Hyeonseop Song",
        "Seokhun Choi",
        "Seungwoo Lee",
        "Jaechul Kim",
        "Hoseok Do"
      ],
      "abstract": "Despite considerable efforts to enhance the generalization of 3D pose\nestimators without costly 3D annotations, existing data augmentation methods\nstruggle in real world scenarios with diverse human appearances and complex\nposes. We propose PoseSyn, a novel data synthesis framework that transforms\nabundant in the wild 2D pose dataset into diverse 3D pose image pairs. PoseSyn\ncomprises two key components: Error Extraction Module (EEM), which identifies\nchallenging poses from the 2D pose datasets, and Motion Synthesis Module (MSM),\nwhich synthesizes motion sequences around the challenging poses. Then, by\ngenerating realistic 3D training data via a human animation model aligned with\nchallenging poses and appearances PoseSyn boosts the accuracy of various 3D\npose estimators by up to 14% across real world benchmarks including various\nbackgrounds and occlusions, challenging poses, and multi view scenarios.\nExtensive experiments further confirm that PoseSyn is a scalable and effective\napproach for improving generalization without relying on expensive 3D\nannotations, regardless of the pose estimator's model size or design.",
      "tldr_zh": "该研究提出PoseSyn框架，创新性地将野外采集的2D姿态数据转化为多样化的3D姿态训练数据。该系统包含两个核心模块：通过Error Extraction Module(EEM)识别具有挑战性的2D姿态，再经Motion Synthesis Module(MSM)合成相应3D运动序列。实验表明，该方法无需昂贵3D标注即可提升多种3D姿态估计器的性能，在复杂现实场景中最高提升14%准确率，且不受模型规模限制。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The first three authors contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2503.13025v1",
      "published_date": "2025-03-17 10:28:35 UTC",
      "updated_date": "2025-03-17 10:28:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:27:30.450078"
    },
    {
      "arxiv_id": "2503.13012v1",
      "title": "Test-Time Domain Generalization via Universe Learning: A Multi-Graph Matching Approach for Medical Image Segmentation",
      "title_zh": "测试时域泛化通过宇宙学习：一种用于医学图像分割的多图匹配方法",
      "authors": [
        "Xingguo Lv",
        "Xingbo Dong",
        "Liwen Wang",
        "Jiewen Yang",
        "Lei Zhao",
        "Bin Pu",
        "Zhe Jin",
        "Xuejun Li"
      ],
      "abstract": "Despite domain generalization (DG) has significantly addressed the\nperformance degradation of pre-trained models caused by domain shifts, it often\nfalls short in real-world deployment. Test-time adaptation (TTA), which adjusts\na learned model using unlabeled test data, presents a promising solution.\nHowever, most existing TTA methods struggle to deliver strong performance in\nmedical image segmentation, primarily because they overlook the crucial prior\nknowledge inherent to medical images. To address this challenge, we incorporate\nmorphological information and propose a framework based on multi-graph\nmatching. Specifically, we introduce learnable universe embeddings that\nintegrate morphological priors during multi-source training, along with novel\nunsupervised test-time paradigms for domain adaptation. This approach\nguarantees cycle-consistency in multi-matching while enabling the model to more\neffectively capture the invariant priors of unseen data, significantly\nmitigating the effects of domain shifts. Extensive experiments demonstrate that\nour method outperforms other state-of-the-art approaches on two medical image\nsegmentation benchmarks for both multi-source and single-source domain\ngeneralization tasks. The source code is available at\nhttps://github.com/Yore0/TTDG-MGM.",
      "tldr_zh": "该研究提出了一种基于多图匹配（multi-graph matching）的测试时域泛化（TTDG）框架，通过引入可学习的universe embeddings来整合医学图像的形态学先验知识。该方法在训练阶段利用多源数据学习通用表征，在测试时采用无监督范式进行域适应，有效缓解了医学图像分割中的域偏移问题。实验表明，该框架在多源和单源域泛化任务上均优于现有方法，在两个医学图像分割基准测试中取得最优性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13012v1",
      "published_date": "2025-03-17 10:11:11 UTC",
      "updated_date": "2025-03-17 10:11:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:27:50.326085"
    },
    {
      "arxiv_id": "2503.12999v2",
      "title": "Concept-as-Tree: Synthetic Data is All You Need for VLM Personalization",
      "title_zh": "概念即树：合成数据是视觉语言模型个性化的全部所需",
      "authors": [
        "Ruichuan An",
        "Kai Zeng",
        "Ming Lu",
        "Sihan Yang",
        "Renrui Zhang",
        "Huitong Ji",
        "Qizhe Zhang",
        "Yulin Luo",
        "Hao Liang",
        "Wentao Zhang"
      ],
      "abstract": "Vision-Language Models (VLMs) have demonstrated exceptional performance in\nvarious multi-modal tasks. Recently, there has been an increasing interest in\nimproving the personalization capabilities of VLMs. To better integrate\nuser-provided concepts into VLMs, many methods use positive and negative\nsamples to fine-tune these models. However, the scarcity of user-provided\npositive samples and the low quality of retrieved negative samples pose\nchallenges for fine-tuning. To reveal the relationship between sample and model\nperformance, we systematically investigate the impact of positive and negative\nsamples (easy and hard) and their diversity on VLM personalization tasks. Based\non the detailed analysis, we introduce Concept-as-Tree (CaT), which represents\na concept as a tree structure, thereby enabling the data generation of positive\nand negative samples with varying difficulty and diversity for VLM\npersonalization. With a well-designed data filtering strategy, our CaT\nframework can ensure the quality of generated data, constituting a powerful\npipeline. We perform thorough experiments with various VLM personalization\nbaselines to assess the effectiveness of the pipeline, alleviating the lack of\npositive samples and the low quality of negative samples. Our results\ndemonstrate that CaT equipped with the proposed data filter significantly\nenhances the personalization capabilities of VLMs across the MyVLM, Yo'LLaVA,\nand MC-LLaVA datasets. To our knowledge, this work is the first controllable\nsynthetic data pipeline for VLM personalization. The code is released at\n$\\href{https://github.com/zengkaiya/CaT}{\\text{https://github.com/zengkaiya/CaT}}$.",
      "tldr_zh": "该研究提出**Concept-as-Tree (CaT)**框架，通过树状结构表示用户概念，自动生成不同难度和多样性的正负样本，解决视觉语言模型(VLM)个性化任务中样本稀缺和质量低的问题。研究发现样本多样性对模型性能具有关键影响，CaT结合数据过滤策略构建了首个可控的合成数据生成流程。实验表明，该方法在MyVLM、Yo'LLaVA和MC-LLaVA数据集上显著提升VLM的个性化能力，为无需真实用户数据的高效模型微调提供了新思路。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The code is released at\n  $\\href{https://github.com/zengkaiya/CaT}{\\text{https://github.com/zengkaiya/CaT}}$",
      "pdf_url": "http://arxiv.org/pdf/2503.12999v2",
      "published_date": "2025-03-17 09:55:01 UTC",
      "updated_date": "2025-03-23 06:45:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:28:21.203126"
    },
    {
      "arxiv_id": "2503.12993v1",
      "title": "Robot Policy Transfer with Online Demonstrations: An Active Reinforcement Learning Approach",
      "title_zh": "机器人策略迁移的在线演示方法：一种主动强化学习途径",
      "authors": [
        "Muhan Hou",
        "Koen Hindriks",
        "A. E. Eiben",
        "Kim Baraka"
      ],
      "abstract": "Transfer Learning (TL) is a powerful tool that enables robots to transfer\nlearned policies across different environments, tasks, or embodiments. To\nfurther facilitate this process, efforts have been made to combine it with\nLearning from Demonstrations (LfD) for more flexible and efficient policy\ntransfer. However, these approaches are almost exclusively limited to offline\ndemonstrations collected before policy transfer starts, which may suffer from\nthe intrinsic issue of covariance shift brought by LfD and harm the performance\nof policy transfer. Meanwhile, extensive work in the learning-from-scratch\nsetting has shown that online demonstrations can effectively alleviate\ncovariance shift and lead to better policy performance with improved sample\nefficiency. This work combines these insights to introduce online\ndemonstrations into a policy transfer setting. We present Policy Transfer with\nOnline Demonstrations, an active LfD algorithm for policy transfer that can\noptimize the timing and content of queries for online episodic expert\ndemonstrations under a limited demonstration budget. We evaluate our method in\neight robotic scenarios, involving policy transfer across diverse environment\ncharacteristics, task objectives, and robotic embodiments, with the aim to\ntransfer a trained policy from a source task to a related but different target\ntask. The results show that our method significantly outperforms all baselines\nin terms of average success rate and sample efficiency, compared to two\ncanonical LfD methods with offline demonstrations and one active LfD method\nwith online demonstrations. Additionally, we conduct preliminary sim-to-real\ntests of the transferred policy on three transfer scenarios in the real-world\nenvironment, demonstrating the policy effectiveness on a real robot\nmanipulator.",
      "tldr_zh": "该研究提出了一种结合在线演示的主动强化学习方法（Policy Transfer with Online Demonstrations），用于改进机器人策略迁移（Policy Transfer）。该方法突破了传统基于离线演示（offline demonstrations）的局限，通过优化在线演示的时机和内容，有效缓解了策略迁移中的协变量偏移（covariance shift）问题。实验在八种机器人场景中验证了该方法的优越性，相比基线方法显著提升了平均成功率和样本效率，并在初步的仿真到现实（sim-to-real）测试中展示了实际机器人操作器的策略有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12993v1",
      "published_date": "2025-03-17 09:47:42 UTC",
      "updated_date": "2025-03-17 09:47:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:28:37.526862"
    },
    {
      "arxiv_id": "2503.12992v1",
      "title": "Intra-neuronal attention within language models Relationships between activation and semantics",
      "title_zh": "语言模型中的神经元内注意力：激活与语义之间的关系",
      "authors": [
        "Michael Pichat",
        "William Pogrund",
        "Paloma Pichat",
        "Armanouche Gasparian",
        "Samuel Demarchi",
        "Corbet Alois Georgeon",
        "Michael Veillet-Guillem"
      ],
      "abstract": "This study investigates the ability of perceptron-type neurons in language\nmodels to perform intra-neuronal attention; that is, to identify different\nhomogeneous categorical segments within the synthetic thought category they\nencode, based on a segmentation of specific activation zones for the tokens to\nwhich they are particularly responsive. The objective of this work is therefore\nto determine to what extent formal neurons can establish a homomorphic\nrelationship between activation-based and categorical segmentations. The\nresults suggest the existence of such a relationship, albeit tenuous, only at\nthe level of tokens with very high activation levels. This intra-neuronal\nattention subsequently enables categorical restructuring processes at the level\nof neurons in the following layer, thereby contributing to the progressive\nformation of high-level categorical abstractions.",
      "tldr_zh": "该研究探索了语言模型中感知器类型神经元执行\"神经元内注意力\"的能力，即根据特定激活区域的分割来识别它们编码的合成思维类别中的不同同质类别片段。研究发现，形式神经元只能在极高激活水平的token层面建立激活与类别分割之间的同态关系，尽管这种关系较为微弱。这种神经元内注意力机制有助于在下一层神经元中实现类别重组过程，从而促进高级别类别抽象的渐进形成。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12992v1",
      "published_date": "2025-03-17 09:47:11 UTC",
      "updated_date": "2025-03-17 09:47:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:29:12.828892"
    },
    {
      "arxiv_id": "2503.12989v1",
      "title": "A Multi-Stage Framework with Taxonomy-Guided Reasoning for Occupation Classification Using Large Language Models",
      "title_zh": "基于分类法引导推理的多阶段职业分类框架与大语言模型应用",
      "authors": [
        "Palakorn Achananuparp",
        "Ee-Peng Lim"
      ],
      "abstract": "Automatically annotating job data with standardized occupations from\ntaxonomies, known as occupation classification, is crucial for labor market\nanalysis. However, this task is often hindered by data scarcity and the\nchallenges of manual annotations. While large language models (LLMs) hold\npromise due to their extensive world knowledge and in-context learning\ncapabilities, their effectiveness depends on their knowledge of occupational\ntaxonomies, which remains unclear. In this study, we assess the ability of LLMs\nto generate precise taxonomic entities from taxonomy, highlighting their\nlimitations. To address these challenges, we propose a multi-stage framework\nconsisting of inference, retrieval, and reranking stages, which integrates\ntaxonomy-guided reasoning examples to enhance performance by aligning outputs\nwith taxonomic knowledge. Evaluations on a large-scale dataset show significant\nimprovements in classification accuracy. Furthermore, we demonstrate the\nframework's adaptability for multi-label skill classification. Our results\nindicate that the framework outperforms existing LLM-based methods, offering a\npractical and scalable solution for occupation classification and related tasks\nacross LLMs.",
      "tldr_zh": "该研究提出了一个基于大型语言模型(LLMs)的多阶段职业分类框架，通过整合分类法引导推理来解决职业分类中的数据稀缺和标注困难问题。该框架包含推理、检索和重排序三个阶段，利用分类法知识指导来提高输出准确性。实验表明，该方法在大规模数据集上显著提升了分类精度，并能适应多标签技能分类任务，性能优于现有LLM方法，为劳动力市场分析提供了可扩展的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12989v1",
      "published_date": "2025-03-17 09:44:50 UTC",
      "updated_date": "2025-03-17 09:44:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:29:31.355205"
    },
    {
      "arxiv_id": "2503.12988v1",
      "title": "ROMA: a Read-Only-Memory-based Accelerator for QLoRA-based On-Device LLM",
      "title_zh": "ROMA：一种基于QLoRA的只读存储器设备端大语言模型加速器",
      "authors": [
        "Wenqiang Wang",
        "Yijia Zhang",
        "Zikai Zhang",
        "Guanting Huo",
        "Hao Liang",
        "Shijie Cao",
        "Ningyi Xu"
      ],
      "abstract": "As large language models (LLMs) demonstrate powerful capabilities, deploying\nthem on edge devices has become increasingly crucial, offering advantages in\nprivacy and real-time interaction. QLoRA has emerged as the standard approach\nfor on-device LLMs, leveraging quantized models to reduce memory and\ncomputational costs while utilizing LoRA for task-specific adaptability. In\nthis work, we propose ROMA, a QLoRA accelerator with a hybrid storage\narchitecture that uses ROM for quantized base models and SRAM for LoRA weights\nand KV cache. Our insight is that the quantized base model is stable and\nconverged, making it well-suited for ROM storage. Meanwhile, LoRA modules offer\nthe flexibility to adapt to new data without requiring updates to the base\nmodel. To further reduce the area cost of ROM, we introduce a novel B-ROM\ndesign and integrate it with the compute unit to form a fused cell for\nefficient use of chip resources. ROMA can effectively store both a 4-bit 3B and\na 2-bit 8B LLaMA model entirely on-chip, achieving a notable generation speed\nexceeding 20,000 tokens/s without requiring external memory.",
      "tldr_zh": "该研究提出ROMA，一种基于QLoRA的只读存储器(ROM)加速器，用于边缘设备上的大语言模型(LLM)部署。通过创新性地采用混合存储架构：将量化后的稳定基础模型存储在ROM中，而将LoRA权重和KV缓存保留在SRAM，显著降低了芯片面积开销。该方案还设计了新型B-ROM结构，与计算单元融合形成高效计算单元，使得3B参数的4-bit模型和8B参数的2-bit LLaMA模型都能完全在片上存储，实现了超过20,000 tokens/s的生成速度且无需外部存储器。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12988v1",
      "published_date": "2025-03-17 09:44:17 UTC",
      "updated_date": "2025-03-17 09:44:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:30:19.102009"
    },
    {
      "arxiv_id": "2503.12972v1",
      "title": "Aligning Vision to Language: Text-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning",
      "title_zh": "视觉与语言对齐：面向增强型大语言模型推理的无文本多模态知识图谱构建",
      "authors": [
        "Junming Liu",
        "Siyuan Meng",
        "Yanting Gao",
        "Song Mao",
        "Pinlong Cai",
        "Guohang Yan",
        "Yirong Chen",
        "Zilin Bian",
        "Botian Shi",
        "Ding Wang"
      ],
      "abstract": "Multimodal reasoning in Large Language Models (LLMs) struggles with\nincomplete knowledge and hallucination artifacts, challenges that textual\nKnowledge Graphs (KGs) only partially mitigate due to their modality isolation.\nWhile Multimodal Knowledge Graphs (MMKGs) promise enhanced cross-modal\nunderstanding, their practical construction is impeded by semantic narrowness\nof manual text annotations and inherent noise in visual-semantic entity\nlinkages. In this paper, we propose Vision-align-to-Language integrated\nKnowledge Graph (VaLiK), a novel approach for constructing MMKGs that enhances\nLLMs reasoning through cross-modal information supplementation. Specifically,\nwe cascade pre-trained Vision-Language Models (VLMs) to align image features\nwith text, transforming them into descriptions that encapsulate image-specific\ninformation. Furthermore, we developed a cross-modal similarity verification\nmechanism to quantify semantic consistency, effectively filtering out noise\nintroduced during feature alignment. Even without manually annotated image\ncaptions, the refined descriptions alone suffice to construct the MMKG.\nCompared to conventional MMKGs construction paradigms, our approach achieves\nsubstantial storage efficiency gains while maintaining direct entity-to-image\nlinkage capability. Experimental results on multimodal reasoning tasks\ndemonstrate that LLMs augmented with VaLiK outperform previous state-of-the-art\nmodels. Our code is published at https://github.com/Wings-Of-Disaster/VaLiK.",
      "tldr_zh": "该研究提出VaLiK（Vision-align-to-Language integrated Knowledge Graph）方法，通过级联预训练视觉语言模型（VLMs）将图像特征转化为文本描述，构建无需人工标注的多模态知识图谱（MMKG）。该方法创新性地设计了跨模态相似性验证机制，有效过滤特征对齐过程中的噪声，在保持实体-图像直接关联能力的同时显著提升存储效率。实验表明，结合VaLiK增强的大型语言模型（LLMs）在多模态推理任务中超越现有最优模型，为解决传统知识图谱的模态隔离问题提供了新思路。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 7 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.12972v1",
      "published_date": "2025-03-17 09:31:14 UTC",
      "updated_date": "2025-03-17 09:31:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:29:54.593590"
    },
    {
      "arxiv_id": "2503.12964v1",
      "title": "Training Video Foundation Models with NVIDIA NeMo",
      "title_zh": "使用NVIDIA NeMo训练视频基础模型",
      "authors": [
        "Zeeshan Patel",
        "Ethan He",
        "Parth Mannan",
        "Xiaowei Ren",
        "Ryan Wolf",
        "Niket Agarwal",
        "Jacob Huffman",
        "Zhuoyao Wang",
        "Carl Wang",
        "Jack Chang",
        "Yan Bai",
        "Tommy Huang",
        "Linnan Wang",
        "Sahil Jain",
        "Shanmugam Ramasamy",
        "Joseph Jennings",
        "Ekaterina Sirazitdinova",
        "Oleg Sudakov",
        "Mingyuan Ma",
        "Bobby Chen",
        "Forrest Lin",
        "Hao Wang",
        "Vasanth Rao Naik Sabavat",
        "Sriharsha Niverty",
        "Rong Ou",
        "Pallab Bhattacharya",
        "David Page",
        "Nima Tajbakhsh",
        "Ashwath Aithal"
      ],
      "abstract": "Video Foundation Models (VFMs) have recently been used to simulate the real\nworld to train physical AI systems and develop creative visual experiences.\nHowever, there are significant challenges in training large-scale, high quality\nVFMs that can generate high-quality videos. We present a scalable, open-source\nVFM training pipeline with NVIDIA NeMo, providing accelerated video dataset\ncuration, multimodal data loading, and parallelized video diffusion model\ntraining and inference. We also provide a comprehensive performance analysis\nhighlighting best practices for efficient VFM training and inference.",
      "tldr_zh": "该研究介绍了基于NVIDIA NeMo平台的可扩展开源视频基础模型(VFM)训练框架，旨在解决高质量视频生成模型面临的大规模训练难题。该框架提供加速的视频数据集处理、多模态数据加载以及并行化的视频扩散模型训练与推理功能，并通过对性能指标的全面分析，提出了高效训练VFM的最佳实践方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12964v1",
      "published_date": "2025-03-17 09:19:12 UTC",
      "updated_date": "2025-03-17 09:19:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:30:14.925957"
    },
    {
      "arxiv_id": "2503.12946v1",
      "title": "Open3DBench: Open-Source Benchmark for 3D-IC Backend Implementation and PPA Evaluation",
      "title_zh": "Open3DBench：面向3D-IC后端实现与PPA评估的开源基准平台",
      "authors": [
        "Yunqi Shi",
        "Chengrui Gao",
        "Wanqi Ren",
        "Siyuan Xu",
        "Ke Xue",
        "Mingxuan Yuan",
        "Chao Qian",
        "Zhi-Hua Zhou"
      ],
      "abstract": "This work introduces Open3DBench, an open-source 3D-IC backend implementation\nbenchmark built upon the OpenROAD-flow-scripts framework, enabling\ncomprehensive evaluation of power, performance, area, and thermal metrics. Our\nproposed flow supports modular integration of 3D partitioning, placement, 3D\nrouting, RC extraction, and thermal simulation, aligning with advanced 3D flows\nthat rely on commercial tools and in-house scripts. We present two foundational\n3D placement algorithms: Open3D-Tiling, which emphasizes regular macro\nplacement, and Open3D-DMP, which enhances wirelength optimization through\ncross-die co-placement with analytical placer DREAMPlace. Experimental results\nshow significant improvements in area (51.19%), wirelength (24.06%), timing\n(30.84%), and power (5.72%) compared to 2D flows. The results also highlight\nthat better wirelength does not necessarily lead to PPA gain, emphasizing the\nneed of developing PPA-driven methods. Open3DBench offers a standardized,\nreproducible platform for evaluating 3D EDA methods, effectively bridging the\ngap between open-source tools and commercial solutions in 3D-IC design.",
      "tldr_zh": "该研究推出了开源3D-IC后端实现基准测试平台Open3DBench，基于OpenROAD-flow-scripts框架，支持对功耗、性能、面积和热指标的全面评估。平台提供两种核心3D布局算法：注重规则宏布局的Open3D-Tiling和通过跨芯片协同布局优化线长的Open3D-DMP，相比2D方案实现了51.19%的面积优化和24.06%的线长改进。研究指出线长优化未必带来PPA（功耗-性能-面积）收益，强调需要开发PPA驱动方法，该平台填补了开源工具与商业3D-IC解决方案之间的评估空白。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12946v1",
      "published_date": "2025-03-17 08:59:00 UTC",
      "updated_date": "2025-03-17 08:59:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:30:39.458437"
    },
    {
      "arxiv_id": "2503.12937v1",
      "title": "R1-VL: Learning to Reason with Multimodal Large Language Models via Step-wise Group Relative Policy Optimization",
      "title_zh": "R1-VL：通过分步组相对策略优化学习多模态大语言模型的推理能力",
      "authors": [
        "Jingyi Zhang",
        "Jiaxing Huang",
        "Huanjin Yao",
        "Shunyu Liu",
        "Xikun Zhang",
        "Shijian Lu",
        "Dacheng Tao"
      ],
      "abstract": "Recent studies generally enhance MLLMs' reasoning capabilities via supervised\nfine-tuning on high-quality chain-of-thought reasoning data, which often leads\nmodels to merely imitate successful reasoning paths without understanding what\nthe wrong reasoning paths are. In this work, we aim to enhance the MLLMs'\nreasoning ability beyond passively imitating positive reasoning paths. To this\nend, we design Step-wise Group Relative Policy Optimization (StepGRPO), a new\nonline reinforcement learning framework that enables MLLMs to self-improve\nreasoning ability via simple, effective and dense step-wise rewarding.\nSpecifically, StepGRPO introduces two novel rule-based reasoning rewards:\nStep-wise Reasoning Accuracy Reward (StepRAR) and Step-wise Reasoning Validity\nReward (StepRVR). StepRAR rewards the reasoning paths that contain necessary\nintermediate reasoning steps via a soft key-step matching technique, while\nStepRAR rewards reasoning paths that follow a well-structured and logically\nconsistent reasoning process through a reasoning completeness and logic\nevaluation strategy. With the proposed StepGRPO, we introduce R1-VL, a series\nof MLLMs with outstanding capabilities in step-by-step reasoning. Extensive\nexperiments over 8 benchmarks demonstrate the superiority of our methods.",
      "tldr_zh": "该研究提出了R1-VL模型，通过创新的逐步组相对策略优化(StepGRPO)框架增强多模态大语言模型(MLLMs)的推理能力。不同于传统监督微调方法仅模仿正确推理路径，StepGRPO采用在线强化学习框架，通过两种新型规则推理奖励机制——逐步推理准确度奖励(StepRAR)和逐步推理有效性奖励(StepRVR)，实现细粒度、密集的逐步奖励。实验表明，R1-VL系列模型在8个基准测试中展现出卓越的逐步推理能力，为解决MLLMs被动模仿推理路径的问题提供了新思路。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12937v1",
      "published_date": "2025-03-17 08:51:44 UTC",
      "updated_date": "2025-03-17 08:51:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:31:03.384669"
    },
    {
      "arxiv_id": "2503.12931v1",
      "title": "MirrorGuard: Adaptive Defense Against Jailbreaks via Entropy-Guided Mirror Crafting",
      "title_zh": "MirrorGuard：基于熵引导镜像构建的自适应越狱防御机制",
      "authors": [
        "Rui Pu",
        "Chaozhuo Li",
        "Rui Ha",
        "Litian Zhang",
        "Lirong Qiu",
        "Xi Zhang"
      ],
      "abstract": "Defending large language models (LLMs) against jailbreak attacks is crucial\nfor ensuring their safe deployment. Existing defense strategies generally rely\non predefined static criteria to differentiate between harmful and benign\nprompts. However, such rigid rules are incapable of accommodating the inherent\ncomplexity and dynamic nature of real jailbreak attacks. In this paper, we\npropose a novel concept of ``mirror'' to enable dynamic and adaptive defense. A\nmirror refers to a dynamically generated prompt that mirrors the syntactic\nstructure of the input while ensuring semantic safety. The personalized\ndiscrepancies between the input prompts and their corresponding mirrors serve\nas the guiding principles for defense. A new defense paradigm, MirrorGuard, is\nfurther proposed to detect and calibrate risky inputs based on such mirrors. An\nentropy-based detection metric, Relative Input Uncertainty (RIU), is integrated\ninto MirrorGuard to quantify the discrepancies between input prompts and\nmirrors. MirrorGuard is evaluated on several popular datasets, demonstrating\nstate-of-the-art defense performance while maintaining general effectiveness.",
      "tldr_zh": "该研究提出了一种名为MirrorGuard的新型防御框架，用于保护大语言模型(LLMs)免受越狱(jailbreak)攻击。MirrorGuard通过动态生成与输入提示语法结构相似但语义安全的“镜像”提示，实现自适应防御。其核心是引入基于熵的检测指标——相对输入不确定性(RIU)，用于量化输入提示与镜像之间的差异，从而识别和校准风险输入。实验表明，MirrorGuard在多个数据集上实现了最先进的防御性能，同时保持了广泛的适用性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12931v1",
      "published_date": "2025-03-17 08:41:29 UTC",
      "updated_date": "2025-03-17 08:41:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:31:25.116326"
    },
    {
      "arxiv_id": "2503.12927v2",
      "title": "MMLNB: Multi-Modal Learning for Neuroblastoma Subtyping Classification Assisted with Textual Description Generation",
      "title_zh": "MMLNB：基于多模态学习与文本描述生成的神经母细胞瘤亚型分类方法",
      "authors": [
        "Huangwei Chen",
        "Yifei Chen",
        "Zhenyu Yan",
        "Mingyang Ding",
        "Chenlei Li",
        "Zhu Zhu",
        "Feiwei Qin"
      ],
      "abstract": "Neuroblastoma (NB), a leading cause of childhood cancer mortality, exhibits\nsignificant histopathological variability, necessitating precise subtyping for\naccurate prognosis and treatment. Traditional diagnostic methods rely on\nsubjective evaluations that are time-consuming and inconsistent. To address\nthese challenges, we introduce MMLNB, a multi-modal learning (MML) model that\nintegrates pathological images with generated textual descriptions to improve\nclassification accuracy and interpretability. The approach follows a two-stage\nprocess. First, we fine-tune a Vision-Language Model (VLM) to enhance\npathology-aware text generation. Second, the fine-tuned VLM generates textual\ndescriptions, using a dual-branch architecture to independently extract visual\nand textual features. These features are fused via Progressive Robust\nMulti-Modal Fusion (PRMF) Block for stable training. Experimental results show\nthat the MMLNB model is more accurate than the single modal model. Ablation\nstudies demonstrate the importance of multi-modal fusion, fine-tuning, and the\nPRMF mechanism. This research creates a scalable AI-driven framework for\ndigital pathology, enhancing reliability and interpretability in NB subtyping\nclassification. Our source code is available at\nhttps://github.com/HovChen/MMLNB.",
      "tldr_zh": "本研究提出了MMLNB，一种结合病理图像与生成文本描述的多模态学习模型，用于神经母细胞瘤(NB)亚型分类。该模型采用两阶段方法：首先微调视觉语言模型(VLM)以生成病理感知的文本描述，随后通过双分支架构独立提取视觉和文本特征，并利用渐进式鲁棒多模态融合(PRMF)模块进行特征融合。实验表明，MMLNB比单模态模型更准确，多模态融合、微调和PRMF机制对提升分类性能至关重要。该研究为数字病理学提供了一个可扩展的AI驱动框架，增强了NB亚型分类的可靠性和可解释性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.12927v2",
      "published_date": "2025-03-17 08:38:46 UTC",
      "updated_date": "2025-03-19 09:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:31:43.327104"
    },
    {
      "arxiv_id": "2503.13565v1",
      "title": "ML-SpecQD: Multi-Level Speculative Decoding with Quantized Drafts",
      "title_zh": "ML-SpecQD：基于量化草稿的多层级推测解码",
      "authors": [
        "Evangelos Georganas",
        "Dhiraj Kalamkar",
        "Alexander Kozlov",
        "Alexander Heinecke"
      ],
      "abstract": "Speculative decoding (SD) has emerged as a method to accelerate LLM inference\nwithout sacrificing any accuracy over the 16-bit model inference. In a typical\nSD setup, the idea is to use a full-precision, small, fast model as \"draft\" to\ngenerate the next few tokens and use the \"target\" large model to verify the\ndraft-generated tokens. The efficacy of this method heavily relies on the\nacceptance ratio of the draft-generated tokens and the relative token\nthroughput of the draft versus the target model. Nevertheless, an efficient SD\npipeline requires pre-training and aligning the draft model to the target\nmodel, making it impractical for LLM inference in a plug-and-play fashion. In\nthis work, we propose using MXFP4 models as drafts in a plug-and-play fashion\nsince the MXFP4 Weight-Only-Quantization (WOQ) merely direct-casts the BF16\ntarget model weights to MXFP4. In practice, our plug-and-play solution gives\nspeedups up to 2x over the BF16 baseline. Then we pursue an opportunity for\nfurther acceleration: the MXFP4 draft token generation itself can be\naccelerated via speculative decoding by using yet another smaller draft. We\ncall our method ML-SpecQD: Multi-Level Speculative Decoding with Quantized\nDrafts since it recursively applies speculation for accelerating the\ndraft-token generation. Combining Multi-Level Speculative Decoding with MXFP4\nQuantized Drafts we outperform state-of-the-art speculative decoding, yielding\nspeedups up to 2.72x over the BF16 baseline.",
      "tldr_zh": "该论文提出了ML-SpecQD方法，通过多层级推测解码(Multi-Level Speculative Decoding)结合量化草案(Quantized Drafts)来加速大语言模型(LLM)推理。核心创新包括：1) 采用MXFP4量化模型作为即插即用草案，无需预训练对齐即可实现2倍加速；2) 递归应用推测解码技术进一步加速草案生成过程。实验表明，该方法最高可获得2.72倍加速效果，超越了当前最先进的推测解码技术，同时保持了与16位模型相同的推理精度。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13565v1",
      "published_date": "2025-03-17 08:38:45 UTC",
      "updated_date": "2025-03-17 08:38:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:32:03.198991"
    },
    {
      "arxiv_id": "2503.12917v1",
      "title": "Verification Learning: Make Unsupervised Neuro-Symbolic System Feasible",
      "title_zh": "验证学习：实现无监督神经符号系统的可行性",
      "authors": [
        "Lin-Han Jia",
        "Wen-Chao Hu",
        "Jie-Jing Shao",
        "Lan-Zhe Guo",
        "Yu-Feng Li"
      ],
      "abstract": "The current Neuro-Symbolic (NeSy) Learning paradigm suffers from an\nover-reliance on labeled data. If we completely disregard labels, it leads to\nless symbol information, a larger solution space, and more shortcuts-issues\nthat current Nesy systems cannot resolve. This paper introduces a novel\nlearning paradigm, Verification Learning (VL), which addresses this challenge\nby transforming the label-based reasoning process in Nesy into a label-free\nverification process. VL achieves excellent learning results solely by relying\non unlabeled data and a function that verifies whether the current predictions\nconform to the rules. We formalize this problem as a Constraint Optimization\nProblem (COP) and propose a Dynamic combinatorial Sorting (DCS) algorithm that\naccelerates the solution by reducing verification attempts, effectively\nlowering computational costs to the level of a Constraint Satisfaction Problem\n(CSP). To further enhance performance, we introduce a prior alignment method to\naddress potential shortcuts. Our theoretical analysis points out which tasks in\nNesy systems can be completed without labels and explains why rules can replace\ninfinite labels, such as in addition, for some tasks, while for others, like\nSudoku, the rules have no effect. We validate the proposed framework through\nseveral fully unsupervised tasks including addition, sort, match, and chess,\neach showing significant performance and efficiency improvements.",
      "tldr_zh": "该研究提出了一种新型无监督神经符号学习范式\"验证学习\"(Verification Learning)，通过将传统基于标签的推理过程转化为无标签的验证过程，仅需未标注数据和验证函数即可实现优异学习效果。研究者将该问题形式化为约束优化问题(COP)，并开发了动态组合排序(DCS)算法，将计算成本降至约束满足问题(CSP)水平，同时引入先验对齐方法防止捷径学习。理论分析阐明了神经符号系统中哪些任务可完全无监督完成，并通过加法、排序、匹配和国际象棋等任务验证了框架的有效性，展现出显著的性能和效率提升。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12917v1",
      "published_date": "2025-03-17 08:28:58 UTC",
      "updated_date": "2025-03-17 08:28:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:32:22.896732"
    },
    {
      "arxiv_id": "2503.12908v1",
      "title": "HICD: Hallucination-Inducing via Attention Dispersion for Contrastive Decoding to Mitigate Hallucinations in Large Language Models",
      "title_zh": "HICD：通过注意力分散诱导幻觉实现对比解码以缓解大语言模型中的幻觉问题",
      "authors": [
        "Xinyan Jiang",
        "Hang Ye",
        "Yongxin Zhu",
        "Xiaoying Zheng",
        "Zikang Chen",
        "Jun Gong"
      ],
      "abstract": "Large Language Models (LLMs) often generate hallucinations, producing outputs\nthat are contextually inaccurate or factually incorrect. We introduce HICD, a\nnovel method designed to induce hallucinations for contrastive decoding to\nmitigate hallucinations. Unlike existing contrastive decoding methods, HICD\nselects attention heads crucial to the model's prediction as inducing heads,\nthen induces hallucinations by dispersing attention of these inducing heads and\ncompares the hallucinated outputs with the original outputs to obtain the final\nresult. Our approach significantly improves performance on tasks requiring\ncontextual faithfulness, such as context completion, reading comprehension, and\nquestion answering. It also improves factuality in tasks requiring accurate\nknowledge recall. We demonstrate that our inducing heads selection and\nattention dispersion method leads to more \"contrast-effective\" hallucinations\nfor contrastive decoding, outperforming other hallucination-inducing methods.\nOur findings provide a promising strategy for reducing hallucinations by\ninducing hallucinations in a controlled manner, enhancing the performance of\nLLMs in a wide range of tasks.",
      "tldr_zh": "该研究提出HICD方法，通过注意力分散诱导幻觉进行对比解码，以减轻大语言模型(LLMs)中的幻觉问题。该方法创新性地选择关键注意力头作为诱导头，通过分散其注意力产生对比样本，相比传统方法能生成更具\"对比有效性\"的幻觉输出。实验表明，HICD在上下文补全、阅读理解等需要语境忠实度的任务上表现优异，同时提升了知识召回任务的准确性，为可控幻觉诱导提供了新思路。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review at ARR - February 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.12908v1",
      "published_date": "2025-03-17 08:17:28 UTC",
      "updated_date": "2025-03-17 08:17:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:32:40.191652"
    },
    {
      "arxiv_id": "2503.13563v1",
      "title": "MES-RAG: Bringing Multi-modal, Entity-Storage, and Secure Enhancements to RAG",
      "title_zh": "MES-RAG：为RAG引入多模态、实体存储与安全增强",
      "authors": [
        "Pingyu Wu",
        "Daiheng Gao",
        "Jing Tang",
        "Huimin Chen",
        "Wenbo Zhou",
        "Weiming Zhang",
        "Nenghai Yu"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) improves Large Language Models (LLMs) by\nusing external knowledge, but it struggles with precise entity information\nretrieval. In this paper, we proposed MES-RAG framework, which enhances\nentity-specific query handling and provides accurate, secure, and consistent\nresponses. MES-RAG introduces proactive security measures that ensure system\nintegrity by applying protections prior to data access. Additionally, the\nsystem supports real-time multi-modal outputs, including text, images, audio,\nand video, seamlessly integrating into existing RAG architectures. Experimental\nresults demonstrate that MES-RAG significantly improves both accuracy and\nrecall, highlighting its effectiveness in advancing the security and utility of\nquestion-answering, increasing accuracy to 0.83 (+0.25) on targeted task. Our\ncode and data are available at https://github.com/wpydcr/MES-RAG.",
      "tldr_zh": "本文提出MES-RAG框架，通过多模态支持、实体存储和安全增强来改进检索增强生成(RAG)技术。该框架显著提升了实体信息检索的准确性，并引入主动安全机制，在数据访问前实施保护。MES-RAG支持实时生成文本、图像、音频和视频等多模态输出，实验表明其在目标任务上的准确率提升至0.83(+0.25)，有效提高了问答系统的安全性和实用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13563v1",
      "published_date": "2025-03-17 08:09:42 UTC",
      "updated_date": "2025-03-17 08:09:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:33:04.118931"
    },
    {
      "arxiv_id": "2503.12897v1",
      "title": "Federated Continual Instruction Tuning",
      "title_zh": "联邦持续指令微调",
      "authors": [
        "Haiyang Guo",
        "Fanhu Zeng",
        "Fei Zhu",
        "Wenzhuo Liu",
        "Da-Han Wang",
        "Jian Xu",
        "Xu-Yao Zhang",
        "Cheng-Lin Liu"
      ],
      "abstract": "A vast amount of instruction tuning data is crucial for the impressive\nperformance of Large Multimodal Models (LMMs), but the associated computational\ncosts and data collection demands during supervised fine-tuning make it\nimpractical for most researchers. Federated learning (FL) has the potential to\nleverage all distributed data and training resources to reduce the overhead of\njoint training. However, most existing methods assume a fixed number of tasks,\nwhile in real-world scenarios, clients continuously encounter new knowledge and\noften struggle to retain old tasks due to memory constraints. In this work, we\nintroduce the Federated Continual Instruction Tuning (FCIT) benchmark to model\nthis real-world challenge. Our benchmark includes two realistic scenarios,\nencompassing four different settings and twelve carefully curated instruction\ntuning datasets. To address the challenges posed by FCIT, we propose dynamic\nknowledge organization to effectively integrate updates from different tasks\nduring training and subspace selective activation to allocate task-specific\noutput during inference. Extensive experimental results demonstrate that our\nproposed method significantly enhances model performance across varying levels\nof data heterogeneity and catastrophic forgetting. Our source code and dataset\nwill be made publicly available.",
      "tldr_zh": "该研究提出联邦持续指令调优(FCIT)框架，解决大型多模态模型(LMMs)在分布式训练中面临的数据异构性和灾难性遗忘问题。通过动态知识组织和子空间选择性激活两项关键技术，该方法能有效整合新任务知识并保留旧任务能力。实验表明，该框架在12个指令调优数据集上显著提升了模型在数据异构环境下的性能，为分布式持续学习提供了新基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.12897v1",
      "published_date": "2025-03-17 07:58:06 UTC",
      "updated_date": "2025-03-17 07:58:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:33:25.381347"
    },
    {
      "arxiv_id": "2503.15548v1",
      "title": "Privacy-Aware RAG: Secure and Isolated Knowledge Retrieval",
      "title_zh": "隐私感知RAG：安全隔离的知识检索系统",
      "authors": [
        "Pengcheng Zhou",
        "Yinglun Feng",
        "Zhongliang Yang"
      ],
      "abstract": "The widespread adoption of Retrieval-Augmented Generation (RAG) systems in\nreal-world applications has heightened concerns about the confidentiality and\nintegrity of their proprietary knowledge bases. These knowledge bases, which\nplay a critical role in enhancing the generative capabilities of Large Language\nModels (LLMs), are increasingly vulnerable to breaches that could compromise\nsensitive information. To address these challenges, this paper proposes an\nadvanced encryption methodology designed to protect RAG systems from\nunauthorized access and data leakage. Our approach encrypts both textual\ncontent and its corresponding embeddings prior to storage, ensuring that all\ndata remains securely encrypted. This mechanism restricts access to authorized\nentities with the appropriate decryption keys, thereby significantly reducing\nthe risk of unintended data exposure. Furthermore, we demonstrate that our\nencryption strategy preserves the performance and functionality of RAG\npipelines, ensuring compatibility across diverse domains and applications. To\nvalidate the robustness of our method, we provide comprehensive security proofs\nthat highlight its resilience against potential threats and vulnerabilities.\nThese proofs also reveal limitations in existing approaches, which often lack\nrobustness, adaptability, or reliance on open-source models. Our findings\nsuggest that integrating advanced encryption techniques into the design and\ndeployment of RAG systems can effectively enhance privacy safeguards. This\nresearch contributes to the ongoing discourse on improving security measures\nfor AI-driven services and advocates for stricter data protection standards\nwithin RAG architectures.",
      "tldr_zh": "该论文提出了一种面向检索增强生成（RAG）系统的隐私保护方案，通过文本内容和嵌入向量的双重加密机制，有效防止知识库的未授权访问和数据泄露。该方法在保证RAG流程性能不受影响的前提下，仅允许持有解密密钥的授权方访问数据，显著降低了敏感信息暴露风险。研究通过严格的安全验证证明该加密策略能抵御多种潜在威胁，同时揭示了现有方法在鲁棒性和适应性方面的不足。该成果为AI服务的隐私保护提供了新思路，并倡导在RAG架构中实施更严格的数据安全标准。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15548v1",
      "published_date": "2025-03-17 07:45:05 UTC",
      "updated_date": "2025-03-17 07:45:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:33:46.052008"
    },
    {
      "arxiv_id": "2503.13562v1",
      "title": "Micro Text Classification Based on Balanced Positive-Unlabeled Learning",
      "title_zh": "基于平衡正例-无标记学习的微文本分类",
      "authors": [
        "Lin-Han Jia",
        "Lan-Zhe Guo",
        "Zhi Zhou",
        "Si-Ye Han",
        "Zi-Wen Li",
        "Yu-Feng Li"
      ],
      "abstract": "In real-world text classification tasks, negative texts often contain a\nminimal proportion of negative content, which is especially problematic in\nareas like text quality control, legal risk screening, and sensitive\ninformation interception. This challenge manifests at two levels: at the macro\nlevel, distinguishing negative texts is difficult due to the high similarity\nbetween coarse-grained positive and negative samples; at the micro level, the\nissue stems from extreme class imbalance and a lack of fine-grained labels. To\naddress these challenges, we propose transforming the coarse-grained\npositive-negative (PN) classification task into an imbalanced fine-grained\npositive-unlabeled (PU) classification problem, supported by theoretical\nanalysis. We introduce a novel framework, Balanced Fine-Grained\nPositive-Unlabeled (BFGPU) learning, which features a unique PU learning loss\nfunction that optimizes macro-level performance amidst severe imbalance at the\nmicro level. The framework's performance is further boosted by rebalanced\npseudo-labeling and threshold adjustment. Extensive experiments on both public\nand real-world datasets demonstrate the effectiveness of BFGPU, which\noutperforms other methods, even in extreme scenarios where both macro and micro\nlevels are highly imbalanced.",
      "tldr_zh": "本研究提出了一种基于平衡正未标记学习（BFGPU）的微文本分类方法，旨在解决实际文本分类任务中负样本内容极少、类间相似度高以及极端类别不平衡的问题。该方法将粗粒度的正负分类任务转化为不平衡的细粒度正未标记分类问题，并设计了独特的PU学习损失函数，结合重平衡伪标签和阈值调整技术，优化了宏观和微观层面的分类性能。实验表明，BFGPU在公开和真实数据集上均表现优异，尤其在极端不平衡场景下显著优于其他方法。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13562v1",
      "published_date": "2025-03-17 07:42:27 UTC",
      "updated_date": "2025-03-17 07:42:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:34:01.350016"
    },
    {
      "arxiv_id": "2503.12880v1",
      "title": "nvBench 2.0: A Benchmark for Natural Language to Visualization under Ambiguity",
      "title_zh": "nvBench 2.0：面向模糊场景的自然语言转可视化基准测试",
      "authors": [
        "Tianqi Luo",
        "Chuhan Huang",
        "Leixian Shen",
        "Boyan Li",
        "Shuyu Shen",
        "Wei Zeng",
        "Nan Tang",
        "Yuyu Luo"
      ],
      "abstract": "Natural Language to Visualization (NL2VIS) enables users to create\nvisualizations from natural language queries, making data insights more\naccessible. However, NL2VIS faces challenges in interpreting ambiguous queries,\nas users often express their visualization needs in imprecise language. To\naddress this challenge, we introduce nvBench 2.0, a new benchmark designed to\nevaluate NL2VIS systems in scenarios involving ambiguous queries. nvBench 2.0\nincludes 7,878 natural language queries and 24,076 corresponding\nvisualizations, derived from 780 tables across 153 domains. It is built using a\ncontrolled ambiguity-injection pipeline that generates ambiguous queries\nthrough a reverse-generation workflow. By starting with unambiguous seed\nvisualizations and selectively injecting ambiguities, the pipeline yields\nmultiple valid interpretations for each query, with each ambiguous query\ntraceable to its corresponding visualization through step-wise reasoning paths.\nWe evaluate various Large Language Models (LLMs) on their ability to perform\nambiguous NL2VIS tasks using nvBench 2.0. We also propose Step-NL2VIS, an\nLLM-based model trained on nvBench 2.0, which enhances performance in ambiguous\nscenarios through step-wise preference optimization. Our results show that\nStep-NL2VIS outperforms all baselines, setting a new state-of-the-art for\nambiguous NL2VIS tasks.",
      "tldr_zh": "研究团队提出了nvBench 2.0，这是一个专门用于评估自然语言到可视化（NL2VIS）系统在模糊查询场景下性能的新基准。该基准包含7,878个自然语言查询和24,076个对应可视化结果，覆盖153个领域的780个表格。通过受控的模糊注入流程，nvBench 2.0生成了可追溯的多重有效解释。此外，团队开发了Step-NL2VIS模型，基于nvBench 2.0训练，通过逐步偏好优化显著提升了模糊NL2VIS任务的性能，超越了所有基线模型，确立了新的技术标准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12880v1",
      "published_date": "2025-03-17 07:20:11 UTC",
      "updated_date": "2025-03-17 07:20:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:34:23.816868"
    },
    {
      "arxiv_id": "2503.12855v1",
      "title": "VITED: Video Temporal Evidence Distillation",
      "title_zh": "VITED：视频时序证据蒸馏",
      "authors": [
        "Yujie Lu",
        "Yale Song",
        "William Wang",
        "Lorenzo Torresani",
        "Tushar Nagarajan"
      ],
      "abstract": "We investigate complex video question answering via chain-of-evidence\nreasoning -- identifying sequences of temporal spans from multiple relevant\nparts of the video, together with visual evidence within them. Existing models\nstruggle with multi-step reasoning as they uniformly sample a fixed number of\nframes, which can miss critical evidence distributed nonuniformly throughout\nthe video. Moreover, they lack the ability to temporally localize such evidence\nin the broader context of the full video, which is required for answering\ncomplex questions. We propose a framework to enhance existing VideoQA datasets\nwith evidence reasoning chains, automatically constructed by searching for\noptimal intervals of interest in the video with supporting evidence, that\nmaximizes the likelihood of answering a given question. We train our model\n(VITED) to generate these evidence chains directly, enabling it to both\nlocalize evidence windows as well as perform multi-step reasoning across them\nin long-form video content. We show the value of our evidence-distilled models\non a suite of long video QA benchmarks where we outperform state-of-the-art\napproaches that lack evidence reasoning capabilities.",
      "tldr_zh": "该研究提出VITED框架，通过证据链推理机制解决现有视频问答模型在长视频内容中面临的证据定位和多步推理难题。方法创新性地自动构建视频最优兴趣区间，以最大化问题回答概率，并训练模型直接生成包含时序定位的视觉证据链。实验表明，该框架在长视频问答基准测试中显著优于缺乏证据推理能力的现有最优方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12855v1",
      "published_date": "2025-03-17 06:30:02 UTC",
      "updated_date": "2025-03-17 06:30:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:34:45.000002"
    },
    {
      "arxiv_id": "2503.12843v2",
      "title": "Towards Scalable Foundation Model for Multi-modal and Hyperspectral Geospatial Data",
      "title_zh": "迈向多模态与高光谱地理空间数据的可扩展基础模型",
      "authors": [
        "Haozhe Si",
        "Yuxuan Wan",
        "Minh Do",
        "Deepak Vasisht",
        "Han Zhao",
        "Hendrik F. Hamann"
      ],
      "abstract": "Geospatial raster data, such as that collected by satellite-based imaging\nsystems at different times and spectral bands, hold immense potential for\nenabling a wide range of high-impact applications. This potential stems from\nthe rich information that is spatially and temporally contextualized across\nmultiple channels and sensing modalities. Recent work has adapted existing\nself-supervised learning approaches for such geospatial data. However, they\nfall short of scalable model architectures, leading to inflexibility and\ncomputational inefficiencies when faced with an increasing number of channels\nand modalities. To address these limitations, we introduce Low-rank Efficient\nSpatial-Spectral Vision Transformer with three key innovations: i) the LESS\nAttention Block that approximates high-dimensional spatial-spectral attention\nthrough Kronecker's product of the low-dimensional spatial and spectral\nattention components; ii) the Continuous Positional-Channel Embedding Layer\nthat preserves both the continuity and physical characteristics of each\nspatial-spectral patch; and iii) the Perception Field Mask that exploits local\nspatial dependencies by constraining attention to neighboring patches. To\nevaluate the proposed innovations, we construct GFM-Bench, which serves as a\ncomprehensive benchmark for such geospatial raster data. We pretrain LESS ViT\nusing a Hyperspectral Masked Autoencoder framework with integrated positional\nand channel masking strategies. Experimental results demonstrate that our\nproposed method achieves competitive performance against state-of-the-art\nmulti-modal geospatial foundation models while outperforming them on\ncross-satellite generalization tasks with higher computational efficiency. The\nflexibility and extensibility of our framework make it a promising direction\nfor future geospatial data analysis tasks that involve a wide range of\nmodalities and channels.",
      "tldr_zh": "该研究提出了面向多模态高光谱地理空间数据的可扩展基础模型LESS ViT，其核心创新包括：1）采用低秩空间-光谱注意力模块（LESS Attention Block），通过Kronecker积分解实现高效高维注意力计算；2）设计连续位置-通道嵌入层保留空间光谱块的物理特性；3）引入感知场掩码机制利用局部空间依赖性。通过构建GFM-Bench基准测试集和基于高光谱掩码自编码器的预训练框架，实验表明该模型在跨卫星泛化任务中性能优于现有方法，且具有更高的计算效率，为处理多模态地理空间数据提供了灵活可扩展的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12843v2",
      "published_date": "2025-03-17 05:42:19 UTC",
      "updated_date": "2025-03-18 02:13:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:35:16.513541"
    },
    {
      "arxiv_id": "2503.12836v3",
      "title": "CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting",
      "title_zh": "CompMarkGS：面向压缩3D高斯泼溅模型的鲁棒水印技术",
      "authors": [
        "Sumin In",
        "Youngdong Jang",
        "Utae Jeong",
        "MinHyuk Jang",
        "Hyeongcheol Park",
        "Eunbyung Park",
        "Sangpil Kim"
      ],
      "abstract": "3D Gaussian Splatting (3DGS) enables rapid differentiable rendering for 3D\nreconstruction and novel view synthesis, leading to its widespread commercial\nuse. Consequently, copyright protection via watermarking has become critical.\nHowever, because 3DGS relies on millions of Gaussians, which require gigabytes\nof storage, efficient transfer and storage require compression. Existing 3DGS\nwatermarking methods are vulnerable to quantization-based compression, often\nresulting in the loss of the embedded watermark. To address this challenge, we\npropose a novel watermarking method that ensures watermark robustness after\nmodel compression while maintaining high rendering quality. In detail, we\nincorporate a quantization distortion layer that simulates compression during\ntraining, preserving the watermark under quantization-based compression. Also,\nwe propose a learnable watermark embedding feature that embeds the watermark\ninto the anchor feature, ensuring structural consistency and seamless\nintegration into the 3D scene. Furthermore, we present a frequency-aware anchor\ngrowing mechanism to enhance image quality in high-frequency regions by\neffectively identifying Guassians within these regions. Experimental results\nconfirm that our method preserves the watermark and maintains superior image\nquality under high compression, validating it as a promising approach for a\nsecure 3DGS model.",
      "tldr_zh": "该研究提出了CompMarkGS，一种针对压缩3D高斯溅射(3DGS)模型的鲁棒水印技术。通过在训练中引入量化失真层模拟压缩过程，并结合可学习的水印嵌入特征，该方法在保证高渲染质量的同时，有效抵御基于量化的压缩攻击。此外，频率感知锚点生成机制提升了高频区域的图像质量。实验表明，CompMarkGS在高压缩率下仍能保留水印并维持优异的图像质量，为3DGS模型的版权保护提供了可靠解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.12836v3",
      "published_date": "2025-03-17 05:32:15 UTC",
      "updated_date": "2025-03-25 05:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:35:29.679009"
    },
    {
      "arxiv_id": "2503.12834v1",
      "title": "PASTA: Part-Aware Sketch-to-3D Shape Generation with Text-Aligned Prior",
      "title_zh": "PASTA：基于文本对齐先验的部件感知草图到3D形状生成",
      "authors": [
        "Seunggwan Lee",
        "Hwanhee Jung",
        "Byoungsoo Koh",
        "Qixing Huang",
        "Sangho Yoon",
        "Sangpil Kim"
      ],
      "abstract": "A fundamental challenge in conditional 3D shape generation is to minimize the\ninformation loss and maximize the intention of user input. Existing approaches\nhave predominantly focused on two types of isolated conditional signals, i.e.,\nuser sketches and text descriptions, each of which does not offer flexible\ncontrol of the generated shape. In this paper, we introduce PASTA, the flexible\napproach that seamlessly integrates a user sketch and a text description for 3D\nshape generation. The key idea is to use text embeddings from a vision-language\nmodel to enrich the semantic representation of sketches. Specifically, these\ntext-derived priors specify the part components of the object, compensating for\nmissing visual cues from ambiguous sketches. In addition, we introduce ISG-Net\nwhich employs two types of graph convolutional networks: IndivGCN, which\nprocesses fine-grained details, and PartGCN, which aggregates these details\ninto parts and refines the structure of objects. Extensive experiments\ndemonstrate that PASTA outperforms existing methods in part-level editing and\nachieves state-of-the-art results in sketch-to-3D shape generation.",
      "tldr_zh": "本研究提出PASTA框架，通过融合用户手绘草图与文本描述实现细粒度3D形状生成。该方法创新性地利用视觉语言模型的文本嵌入增强草图语义表示，通过文本对齐先验（text-aligned prior）补全模糊草图缺失的部件信息。团队设计了ISG-Net网络架构，结合处理细节的IndivGCN与整合部件结构的PartGCN两种图卷积网络，在部件级编辑任务中超越现有方法，实现了草图到3D生成的最优性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.12834v1",
      "published_date": "2025-03-17 05:31:09 UTC",
      "updated_date": "2025-03-17 05:31:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:35:47.644602"
    },
    {
      "arxiv_id": "2503.15547v1",
      "title": "Prompt Flow Integrity to Prevent Privilege Escalation in LLM Agents",
      "title_zh": "提示流完整性：防范LLM智能体权限提升攻击",
      "authors": [
        "Juhee Kim",
        "Woohyuk Choi",
        "Byoungyoung Lee"
      ],
      "abstract": "Large Language Models (LLMs) are combined with plugins to create powerful LLM\nagents that provide a wide range of services. Unlike traditional software, LLM\nagent's behavior is determined at runtime by natural language prompts from\neither user or plugin's data. This flexibility enables a new computing paradigm\nwith unlimited capabilities and programmability, but also introduces new\nsecurity risks, vulnerable to privilege escalation attacks. Moreover, user\nprompt is prone to be interpreted in an insecure way by LLM agents, creating\nnon-deterministic behaviors that can be exploited by attackers. To address\nthese security risks, we propose Prompt Flow Integrity (PFI), a system\nsecurity-oriented solution to prevent privilege escalation in LLM agents.\nAnalyzing the architectural characteristics of LLM agents, PFI features three\nmitigation techniques -- i.e., untrusted data identification, enforcing least\nprivilege on LLM agents, and validating unsafe data flows. Our evaluation\nresult shows that PFI effectively mitigates privilege escalation attacks while\nsuccessfully preserving the utility of LLM agents.",
      "tldr_zh": "该研究提出了Prompt Flow Integrity（PFI）系统，用于防范LLM智能体中的权限提升攻击。针对LLM智能体运行时通过自然语言提示决定行为的特点，PFI通过不可信数据识别、最小权限强制和不安全数据流验证三项关键技术，有效解决了因提示解释不确定性导致的安全风险。实验证明，该方案在保持LLM智能体功能性的同时，成功防御了权限提升攻击。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15547v1",
      "published_date": "2025-03-17 05:27:57 UTC",
      "updated_date": "2025-03-17 05:27:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:36:03.611079"
    },
    {
      "arxiv_id": "2503.12829v1",
      "title": "SparseLUT: Sparse Connectivity Optimization for Lookup Table-based Deep Neural Networks",
      "title_zh": "SparseLUT：基于查找表的深度神经网络稀疏连接优化方法",
      "authors": [
        "Binglei Lou",
        "Ruilin Wu",
        "Philip Leong"
      ],
      "abstract": "The deployment of deep neural networks (DNNs) on resource-constrained edge\ndevices such as field-programmable gate arrays (FPGAs) requires a careful\nbalance of latency, power, and resource usage while maintaining high accuracy.\nExisting Lookup Table (LUT)-based DNNs, including LogicNets, PolyLUT,\nPolyLUT-Add, and NeuraLUT, exploit native FPGA resources with random sparse\nconnectivity. This paper introduces SparseLUT, a connectivity-centric training\ntechnique tailored for LUT-based DNNs. SparseLUT leverages a non-greedy\ntraining strategy that prioritizes the pruning of less significant connections\nand strategically regrows alternative ones, resulting in efficient convergence\nto the target sparsity. Experimental results show consistent accuracy\nimprovements across benchmarks, including up to a 2.13\\% increase on MNIST and\na 0.94\\% improvement for Jet Substructure Classification compared to random\nsparsity. This is done without any hardware overhead and achieves\nstate-of-the-art results for LUT-based DNNs.",
      "tldr_zh": "本研究提出SparseLUT方法，针对基于查找表(LUT)的深度神经网络提出了一种稀疏连接优化技术。该方法采用非贪婪训练策略，通过剪枝次要连接并智能再生替代路径，有效实现目标稀疏度下的高效收敛。实验表明，SparseLUT在MNIST和Jet Substructure Classification等基准测试中分别取得2.13%和0.94%的准确率提升，且无需额外硬件开销，为基于LUT的DNN在FPGA等边缘设备上的部署提供了更优解决方案。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12829v1",
      "published_date": "2025-03-17 05:21:54 UTC",
      "updated_date": "2025-03-17 05:21:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:36:53.454920"
    },
    {
      "arxiv_id": "2503.12821v2",
      "title": "From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration",
      "title_zh": "从头到尾：通过自适应数据校准实现大型视觉语言模型的均衡表征",
      "authors": [
        "Mingyang Song",
        "Xiaoye Qu",
        "Jiawei Zhou",
        "Yu Cheng"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) have achieved significant progress in\ncombining visual comprehension with language generation. Despite this success,\nthe training data of LVLMs still suffers from Long-Tail (LT) problems, where\nthe data distribution is highly imbalanced. Previous works have mainly focused\non traditional VLM architectures, i.e., CLIP or ViT, and specific tasks such as\nrecognition and classification. Nevertheless, the exploration of LVLM (e.g.\nLLaVA) and more general tasks (e.g. Visual Question Answering and Visual\nReasoning) remains under-explored. In this paper, we first conduct an in-depth\nanalysis of the LT issues in LVLMs and identify two core causes: the\noverrepresentation of head concepts and the underrepresentation of tail\nconcepts. Based on the above observation, we propose an $\\textbf{A}$daptive\n$\\textbf{D}$ata $\\textbf{R}$efinement Framework ($\\textbf{ADR}$), which\nconsists of two stages: $\\textbf{D}$ata $\\textbf{R}$ebalancing ($\\textbf{DR}$)\nand $\\textbf{D}$ata $\\textbf{S}$ynthesis ($\\textbf{DS}$). In the DR stage, we\nadaptively rebalance the redundant data based on entity distributions, while in\nthe DS stage, we leverage Denoising Diffusion Probabilistic Models (DDPMs) and\nscarce images to supplement underrepresented portions. Through comprehensive\nevaluations across eleven benchmarks, our proposed ADR effectively mitigates\nthe long-tail problem in the training data, improving the average performance\nof LLaVA 1.5 relatively by 4.36%, without increasing the training data volume.",
      "tldr_zh": "该研究针对大型视觉语言模型（LVLMs）中数据分布不平衡的长尾问题，提出了一种自适应数据校准框架（ADR）。该框架通过数据重平衡（DR）和数据合成（DS）两阶段方法，分别解决头部概念过表达和尾部概念欠表达的问题。实验表明，ADR在11个基准测试中有效缓解了长尾问题，将LLaVA 1.5的性能平均提升了4.36%，且未增加训练数据量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.12821v2",
      "published_date": "2025-03-17 05:01:09 UTC",
      "updated_date": "2025-03-18 06:02:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:36:39.594234"
    },
    {
      "arxiv_id": "2503.12814v1",
      "title": "Versatile Physics-based Character Control with Hybrid Latent Representation",
      "title_zh": "基于混合潜在表征的多功能物理驱动角色控制",
      "authors": [
        "Jinseok Bae",
        "Jungdam Won",
        "Donggeun Lim",
        "Inwoo Hwang",
        "Young Min Kim"
      ],
      "abstract": "We present a versatile latent representation that enables physically\nsimulated character to efficiently utilize motion priors. To build a powerful\nmotion embedding that is shared across multiple tasks, the physics controller\nshould employ rich latent space that is easily explored and capable of\ngenerating high-quality motion. We propose integrating continuous and discrete\nlatent representations to build a versatile motion prior that can be adapted to\na wide range of challenging control tasks. Specifically, we build a discrete\nlatent model to capture distinctive posterior distribution without collapse,\nand simultaneously augment the sampled vector with the continuous residuals to\ngenerate high-quality, smooth motion without jittering. We further incorporate\nResidual Vector Quantization, which not only maximizes the capacity of the\ndiscrete motion prior, but also efficiently abstracts the action space during\nthe task learning phase. We demonstrate that our agent can produce diverse yet\nsmooth motions simply by traversing the learned motion prior through\nunconditional motion generation. Furthermore, our model robustly satisfies\nsparse goal conditions with highly expressive natural motions, including\nhead-mounted device tracking and motion in-betweening at irregular intervals,\nwhich could not be achieved with existing latent representations.",
      "tldr_zh": "本研究提出了一种混合潜在表征方法，用于实现基于物理的角色控制。该方法创新性地结合了离散和连续潜在表征：离散部分通过残差向量量化(Residual Vector Quantization)捕获显著后验分布，连续部分则补充平滑运动细节，共同构建了高质量的运动先验。实验表明，该模型既能无条件生成多样且流畅的运动，又能满足头戴设备追踪、不规则间隔运动补全等复杂任务要求，其性能显著优于现有潜在表征方法。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12814v1",
      "published_date": "2025-03-17 04:45:51 UTC",
      "updated_date": "2025-03-17 04:45:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:37:08.758047"
    },
    {
      "arxiv_id": "2503.12811v1",
      "title": "A Multi-Power Law for Loss Curve Prediction Across Learning Rate Schedules",
      "title_zh": "多幂律：跨学习率调度的损失曲线预测",
      "authors": [
        "Kairong Luo",
        "Haodong Wen",
        "Shengding Hu",
        "Zhenbo Sun",
        "Zhiyuan Liu",
        "Maosong Sun",
        "Kaifeng Lyu",
        "Wenguang Chen"
      ],
      "abstract": "Training large models is both resource-intensive and time-consuming, making\nit crucial to understand the quantitative relationship between model\nperformance and hyperparameters. In this paper, we present an empirical law\nthat describes how the pretraining loss of large language models evolves under\ndifferent learning rate schedules, such as constant, cosine, and step decay\nschedules. Our proposed law takes a multi-power form, combining a power law\nbased on the sum of learning rates and additional power laws to account for a\nloss reduction effect induced by learning rate decay. We extensively validate\nthis law on various model sizes and architectures, and demonstrate that after\nfitting on a few learning rate schedules, the law accurately predicts the loss\ncurves for unseen schedules of different shapes and horizons. Moreover, by\nminimizing the predicted final pretraining loss across learning rate schedules,\nwe are able to find a schedule that outperforms the widely used cosine learning\nrate schedule. Interestingly, this automatically discovered schedule bears some\nresemblance to the recently proposed Warmup-Stable-Decay (WSD) schedule (Hu et\nal, 2024) but achieves a slightly lower final loss. We believe these results\ncould offer valuable insights for understanding the dynamics of pretraining and\ndesigning learning rate schedules to improve efficiency.",
      "tldr_zh": "这项研究提出了一种多幂律模型，用于预测大语言模型在不同学习率调度（如恒定、余弦和阶梯衰减）下的预训练损失曲线。该模型结合了基于学习率总和的幂律和额外幂律项，以捕捉学习率衰减带来的损失降低效应。实验验证表明，该模型能准确预测不同形状和训练时长的未知调度方案的损失曲线，并据此自动优化的学习率调度方案优于广泛使用的余弦调度，与Warmup-Stable-Decay方案类似但效果更优。这一发现为理解预训练动态和设计高效学习率调度提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12811v1",
      "published_date": "2025-03-17 04:36:45 UTC",
      "updated_date": "2025-03-17 04:36:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:37:29.965109"
    },
    {
      "arxiv_id": "2503.12797v2",
      "title": "DeepPerception: Advancing R1-like Cognitive Visual Perception in MLLMs for Knowledge-Intensive Visual Grounding",
      "title_zh": "DeepPerception：推动MLLMs中R1类认知视觉感知在知识密集型视觉定位中的发展",
      "authors": [
        "Xinyu Ma",
        "Ziyang Ding",
        "Zhicong Luo",
        "Chi Chen",
        "Zonghao Guo",
        "Derek F. Wong",
        "Xiaoyi Feng",
        "Maosong Sun"
      ],
      "abstract": "Human experts excel at fine-grained visual discrimination by leveraging\ndomain knowledge to refine perceptual features, a capability that remains\nunderdeveloped in current Multimodal Large Language Models (MLLMs). Despite\npossessing vast expert-level knowledge, MLLMs struggle to integrate reasoning\ninto visual perception, often generating direct responses without deeper\nanalysis. To bridge this gap, we introduce knowledge-intensive visual grounding\n(KVG), a novel visual grounding task that requires both fine-grained perception\nand domain-specific knowledge integration. To address the challenges of KVG, we\npropose DeepPerception, an MLLM enhanced with cognitive visual perception\ncapabilities. Our approach consists of (1) an automated data synthesis pipeline\nthat generates high-quality, knowledge-aligned training samples, and (2) a\ntwo-stage training framework combining supervised fine-tuning for cognitive\nreasoning scaffolding and reinforcement learning to optimize\nperception-cognition synergy. To benchmark performance, we introduce KVG-Bench\na comprehensive dataset spanning 10 domains with 1.3K manually curated test\ncases. Experimental results demonstrate that DeepPerception significantly\noutperforms direct fine-tuning, achieving +8.08\\% accuracy improvements on\nKVG-Bench and exhibiting +4.60\\% superior cross-domain generalization over\nbaseline approaches. Our findings highlight the importance of integrating\ncognitive processes into MLLMs for human-like visual perception and open new\ndirections for multimodal reasoning research. The data, codes, and models are\nreleased at https://github.com/thunlp/DeepPerception.",
      "tldr_zh": "该研究提出了DeepPerception，一种增强认知视觉感知能力的多模态大语言模型(MLLM)，旨在解决知识密集型视觉定位(KVG)任务中的挑战。通过自动数据合成管道生成高质量的训练样本，并结合监督微调和强化学习的两阶段训练框架，DeepPerception显著提升了细粒度感知与领域知识整合的能力。实验结果表明，该模型在KVG-Bench基准测试中准确率提升了8.08%，跨领域泛化能力优于基线方法4.60%，为多模态推理研究开辟了新方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12797v2",
      "published_date": "2025-03-17 04:06:34 UTC",
      "updated_date": "2025-03-18 05:06:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:37:52.233659"
    },
    {
      "arxiv_id": "2503.12790v1",
      "title": "Quantum-Enhanced LLM Efficient Fine Tuning",
      "title_zh": "量子增强型大语言模型高效微调",
      "authors": [
        "Xiaofei Kong",
        "Lei Li",
        "Menghan Dou",
        "Zhaoyun Chen",
        "Yuchun Wu",
        "Guoping Guo"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) enables efficient fine-tuning of pre-trained\nlanguage models via low-rank matrix approximation, which is effective in many\nscenarios. However, its low-rank representation capacity is constrained in\ncomplex tasks or high-rank dependency settings, potentially limiting model\nadaptability. Addressing the expressive bottleneck of classical low-rank\napproximation in fine-tuning large language models, this paper proposes a\nparameter-efficient fine-tuning method based on a Quantum Weighted Tensor\nHybrid Network (QWTHN), which leverages Quantum Neural Network (QNN). The study\ninvestigates quantum-classical hybrid parameter-efficient fine-tuning in\nlow-rank spaces. QWTHN decomposes pre-trained weights into quantum neural\nnetwork and tensor network representations, utilizing quantum state\nsuperposition and other methods to break through classical rank limitations.\nExperiments show that the proposed quantum fine-tuning technique for large\nmodels approaches or even surpasses the parameter efficiency of LoRA. On the\nCPsyCounD and R1-Distill-SFT datasets, QWTHN, compared to classical LoRA,\nreduces training loss by up to 15% while using 76% fewer parameters, and\nachieves an 8.4% performance improvement on the CPsyCounD test set. This\nresearch not only realizes lightweight and efficient adaptation of quantum\nresources to billion-parameter models but also validates the practical path of\nquantum hardware driven by large model tasks, laying the first\nengineering-ready technical foundation for future quantum-enhanced AGI systems.",
      "tldr_zh": "该论文提出了一种基于量子加权张量混合网络（QWTHN）的高效参数微调方法，通过结合量子神经网络（QNN）和经典低秩空间技术，突破了传统低秩适应（LoRA）方法的表达能力瓶颈。该方法利用量子态叠加等特性，在CPsyCounD和R1-Distill-SFT数据集上相比传统LoRA减少了76%的参数使用量，同时降低15%的训练损失，并在CPsyCounD测试集上实现了8.4%的性能提升。这项研究不仅验证了量子资源在亿级参数模型中的轻量化适配能力，还为未来量子增强的通用人工智能系统奠定了首个工程化技术基础。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12790v1",
      "published_date": "2025-03-17 03:59:26 UTC",
      "updated_date": "2025-03-17 03:59:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:38:17.095924"
    },
    {
      "arxiv_id": "2503.12781v1",
      "title": "SAM2 for Image and Video Segmentation: A Comprehensive Survey",
      "title_zh": "SAM2 在图像与视频分割中的全面综述",
      "authors": [
        "Zhang Jiaxing",
        "Tang Hao"
      ],
      "abstract": "Despite significant advances in deep learning for image and video\nsegmentation, existing models continue to face challenges in cross-domain\nadaptability and generalization. Image and video segmentation are fundamental\ntasks in computer vision with wide-ranging applications in healthcare,\nagriculture, industrial inspection, and autonomous driving. With the advent of\nlarge-scale foundation models, SAM2 - an improved version of SAM (Segment\nAnything Model)has been optimized for segmentation tasks, demonstrating\nenhanced performance in complex scenarios. However, SAM2's adaptability and\nlimitations in specific domains require further investigation. This paper\nsystematically analyzes the application of SAM2 in image and video segmentation\nand evaluates its performance in various fields. We begin by introducing the\nfoundational concepts of image segmentation, categorizing foundation models,\nand exploring the technical characteristics of SAM and SAM2. Subsequently, we\ndelve into SAM2's applications in static image and video segmentation,\nemphasizing its performance in specialized areas such as medical imaging and\nthe challenges of cross-domain adaptability. As part of our research, we\nreviewed over 200 related papers to provide a comprehensive analysis of the\ntopic. Finally, the paper highlights the strengths and weaknesses of SAM2 in\nsegmentation tasks, identifies the technical challenges it faces, and proposes\nfuture development directions. This review provides valuable insights and\npractical recommendations for optimizing and applying SAM2 in real-world\nscenarios.",
      "tldr_zh": "本文全面综述了改进版基础模型SAM2在图像与视频分割领域的应用表现。研究表明，虽然SAM2在医疗影像等专业领域展现出优于前代SAM的性能提升，但其跨领域适应性和泛化能力仍存在局限。通过系统分析200余篇相关文献，作者详细评估了SAM2在静态图像和动态视频分割中的技术特性，特别指出了其在医疗影像等垂直场景的应用挑战。该综述不仅总结了SAM2当前的技术瓶颈，还为其未来发展方向提出了优化建议。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 4 figures, 7 Tables",
      "pdf_url": "http://arxiv.org/pdf/2503.12781v1",
      "published_date": "2025-03-17 03:33:36 UTC",
      "updated_date": "2025-03-17 03:33:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:38:42.465739"
    },
    {
      "arxiv_id": "2503.12780v1",
      "title": "LangDA: Building Context-Awareness via Language for Domain Adaptive Semantic Segmentation",
      "title_zh": "LangDA：通过语言构建上下文感知的领域自适应语义分割",
      "authors": [
        "Chang Liu",
        "Bavesh Balaji",
        "Saad Hossain",
        "C Thomas",
        "Kwei-Herng Lai",
        "Raviteja Vemulapalli",
        "Alexander Wong",
        "Sirisha Rambhatla"
      ],
      "abstract": "Unsupervised domain adaptation for semantic segmentation (DASS) aims to\ntransfer knowledge from a label-rich source domain to a target domain with no\nlabels. Two key approaches in DASS are (1) vision-only approaches using masking\nor multi-resolution crops, and (2) language-based approaches that use generic\nclass-wise prompts informed by target domain (e.g. \"a {snowy} photo of a\n{class}\"). However, the former is susceptible to noisy pseudo-labels that are\nbiased to the source domain. The latter does not fully capture the intricate\nspatial relationships of objects -- key for dense prediction tasks. To this\nend, we propose LangDA. LangDA addresses these challenges by, first, learning\ncontextual relationships between objects via VLM-generated scene descriptions\n(e.g. \"a pedestrian is on the sidewalk, and the street is lined with\nbuildings.\"). Second, LangDA aligns the entire image features with text\nrepresentation of this context-aware scene caption and learns generalized\nrepresentations via text. With this, LangDA sets the new state-of-the-art\nacross three DASS benchmarks, outperforming existing methods by 2.6%, 1.4% and\n3.9%.",
      "tldr_zh": "该研究提出了LangDA，一种通过语言建模增强上下文感知能力的领域自适应语义分割方法。针对现有视觉方法易受源域偏差伪标签影响、语言方法难以捕捉空间关系的问题，LangDA创新性地利用视觉语言模型(VLM)生成场景描述（如\"行人走在人行道上，街道两侧是建筑物\"），通过文本对齐整个图像特征来学习泛化表征。实验表明，该方法在三个基准测试中分别以2.6%、1.4%和3.9%的优势刷新了当前最优性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "stat.ML",
        "68Txx",
        "I.2.1"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12780v1",
      "published_date": "2025-03-17 03:33:28 UTC",
      "updated_date": "2025-03-17 03:33:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:38:57.931929"
    },
    {
      "arxiv_id": "2503.12778v1",
      "title": "Adaptive Deep Learning for Multiclass Breast Cancer Classification via Misprediction Risk Analysis",
      "title_zh": "基于误预测风险分析的自适应深度学习在乳腺癌多分类中的应用",
      "authors": [
        "Gul Sheeraz",
        "Qun Chen",
        "Liu Feiyu",
        "Zhou Fengjin MD"
      ],
      "abstract": "Breast cancer remains one of the leading causes of cancer-related deaths\nworldwide. Early detection is crucial for improving patient outcomes, yet the\ndiagnostic process is often complex and prone to inconsistencies among\npathologists. Computer-aided diagnostic approaches have significantly enhanced\nbreast cancer detection, particularly in binary classification (benign vs.\nmalignant). However, these methods face challenges in multiclass\nclassification, leading to frequent mispredictions. In this work, we propose a\nnovel adaptive learning approach for multiclass breast cancer classification\nusing H&E-stained histopathology images. First, we introduce a misprediction\nrisk analysis framework that quantifies and ranks the likelihood of an image\nbeing mislabeled by a classifier. This framework leverages an interpretable\nrisk model that requires only a small number of labeled samples for training.\nNext, we present an adaptive learning strategy that fine-tunes classifiers\nbased on the specific characteristics of a given dataset. This approach\nminimizes misprediction risk, allowing the classifier to adapt effectively to\nthe target workload. We evaluate our proposed solutions on real benchmark\ndatasets, demonstrating that our risk analysis framework more accurately\nidentifies mispredictions compared to existing methods. Furthermore, our\nadaptive learning approach significantly improves the performance of\nstate-of-the-art deep neural network classifiers.",
      "tldr_zh": "这篇论文提出了一种基于误预测风险分析的自适应深度学习模型，用于乳腺癌H&E染色病理图像的多分类任务。研究者首先开发了一个可解释的误预测风险评估框架，能够量化并排序分类器对图像的误判概率，该框架仅需少量标注样本即可训练。其次，他们提出了一种自适应学习策略，根据数据集特性微调分类器，有效降低误判风险。实验表明，该方法在标准数据集上不仅能更准确识别误分类样本，还显著提升了现有深度神经网络的分类性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12778v1",
      "published_date": "2025-03-17 03:25:28 UTC",
      "updated_date": "2025-03-17 03:25:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:39:11.317857"
    },
    {
      "arxiv_id": "2503.12772v1",
      "title": "NuPlanQA: A Large-Scale Dataset and Benchmark for Multi-View Driving Scene Understanding in Multi-Modal Large Language Models",
      "title_zh": "NuPlanQA：面向多模态大语言模型的大规模多视角驾驶场景理解数据集与基准测试",
      "authors": [
        "Sung-Yeon Park",
        "Can Cui",
        "Yunsheng Ma",
        "Ahmadreza Moradipari",
        "Rohit Gupta",
        "Kyungtae Han",
        "Ziran Wang"
      ],
      "abstract": "Recent advances in multi-modal large language models (MLLMs) have\ndemonstrated strong performance across various domains; however, their ability\nto comprehend driving scenes remains less proven. The complexity of driving\nscenarios, which includes multi-view information, poses significant challenges\nfor existing MLLMs. In this paper, we introduce NuPlanQA-Eval, a multi-view,\nmulti-modal evaluation benchmark for driving scene understanding. To further\nsupport generalization to multi-view driving scenarios, we also propose\nNuPlanQA-1M, a large-scale dataset comprising 1M real-world visual\nquestion-answering (VQA) pairs. For context-aware analysis of traffic scenes,\nwe categorize our dataset into nine subtasks across three core skills: Road\nEnvironment Perception, Spatial Relations Recognition, and Ego-Centric\nReasoning. Furthermore, we present BEV-LLM, integrating Bird's-Eye-View (BEV)\nfeatures from multi-view images into MLLMs. Our evaluation results reveal key\nchallenges that existing MLLMs face in driving scene-specific perception and\nspatial reasoning from ego-centric perspectives. In contrast, BEV-LLM\ndemonstrates remarkable adaptability to this domain, outperforming other models\nin six of the nine subtasks. These findings highlight how BEV integration\nenhances multi-view MLLMs while also identifying key areas that require further\nrefinement for effective adaptation to driving scenes. To facilitate further\nresearch, we publicly release NuPlanQA at\nhttps://github.com/sungyeonparkk/NuPlanQA.",
      "tldr_zh": "该研究提出了NuPlanQA——首个面向多模态大语言模型(MLLMs)的大规模多视角驾驶场景理解数据集与评测基准，包含NuPlanQA-Eval评估框架和NuPlanQA-1M（100万真实世界视觉问答对）数据集。针对交通场景的上下文感知需求，研究将任务划分为道路环境感知、空间关系识别和以自我为中心的推理三大核心技能的9个子任务。创新提出的BEV-LLM模型通过融合鸟瞰图(BEV)特征，在9项任务中的6项表现超越现有模型，揭示了BEV表征对提升驾驶场景多视角理解的显著效果，同时暴露了当前MLLMs在自我中心视角空间推理方面的关键挑战。相关资源已开源以推动领域研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12772v1",
      "published_date": "2025-03-17 03:12:39 UTC",
      "updated_date": "2025-03-17 03:12:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:39:39.702057"
    },
    {
      "arxiv_id": "2503.12761v1",
      "title": "Analyzing sequential activity and travel decisions with interpretable deep inverse reinforcement learning",
      "title_zh": "基于可解释深度逆向强化学习的序列化活动与出行决策分析",
      "authors": [
        "Yuebing Liang",
        "Shenhao Wang",
        "Jiangbo Yu",
        "Zhan Zhao",
        "Jinhua Zhao",
        "Sandy Pentland"
      ],
      "abstract": "Travel demand modeling has shifted from aggregated trip-based models to\nbehavior-oriented activity-based models because daily trips are essentially\ndriven by human activities. To analyze the sequential activity-travel\ndecisions, deep inverse reinforcement learning (DIRL) has proven effective in\nlearning the decision mechanisms by approximating a reward function to\nrepresent preferences and a policy function to replicate observed behavior\nusing deep neural networks (DNNs). However, most existing research has focused\non using DIRL to enhance only prediction accuracy, with limited exploration\ninto interpreting the underlying decision mechanisms guiding sequential\ndecision-making. To address this gap, we introduce an interpretable DIRL\nframework for analyzing activity-travel decision processes, bridging the gap\nbetween data-driven machine learning and theory-driven behavioral models. Our\nproposed framework adapts an adversarial IRL approach to infer the reward and\npolicy functions of activity-travel behavior. The policy function is\ninterpreted through a surrogate interpretable model based on choice\nprobabilities from the policy function, while the reward function is\ninterpreted by deriving both short-term rewards and long-term returns for\nvarious activity-travel patterns. Our analysis of real-world travel survey data\nreveals promising results in two key areas: (i) behavioral pattern insights\nfrom the policy function, highlighting critical factors in decision-making and\nvariations among socio-demographic groups, and (ii) behavioral preference\ninsights from the reward function, indicating the utility individuals gain from\nspecific activity sequences.",
      "tldr_zh": "本研究提出了一种可解释的深度逆向强化学习(DIRL)框架，用于分析人类活动-出行序列决策过程。该框架通过对抗式IRL方法推断行为奖励函数和策略函数，并利用替代可解释模型和长短程效用分析来揭示决策机制。基于真实出行调查数据的实验表明，该方法不仅能从策略函数中识别关键决策因素和人口统计学差异，还能通过奖励函数量化不同活动序列的效用价值，有效弥合了数据驱动模型与理论驱动模型之间的鸿沟。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12761v1",
      "published_date": "2025-03-17 02:54:02 UTC",
      "updated_date": "2025-03-17 02:54:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:40:05.525175"
    },
    {
      "arxiv_id": "2503.12757v2",
      "title": "MAP: Multi-user Personalization with Collaborative LLM-powered Agents",
      "title_zh": "MAP：基于协作式LLM驱动的多用户个性化智能体系统",
      "authors": [
        "Christine Lee",
        "Jihye Choi",
        "Bilge Mutlu"
      ],
      "abstract": "The widespread adoption of Large Language Models (LLMs) and LLM-powered\nagents in multi-user settings underscores the need for reliable, usable methods\nto accommodate diverse preferences and resolve conflicting directives. Drawing\non conflict resolution theory, we introduce a user-centered workflow for\nmulti-user personalization comprising three stages: Reflection, Analysis, and\nFeedback. We then present MAP -- a \\textbf{M}ulti-\\textbf{A}gent system for\nmulti-user \\textbf{P}ersonalization -- to operationalize this workflow. By\ndelegating subtasks to specialized agents, MAP (1) retrieves and reflects on\nrelevant user information, while enhancing reliability through agent-to-agent\ninteractions, (2) provides detailed analysis for improved transparency and\nusability, and (3) integrates user feedback to iteratively refine results. Our\nuser study findings (n=12) highlight MAP's effectiveness and usability for\nconflict resolution while emphasizing the importance of user involvement in\nresolution verification and failure management. This work highlights the\npotential of multi-agent systems to implement user-centered, multi-user\npersonalization workflows and concludes by offering insights for\npersonalization in multi-user contexts.",
      "tldr_zh": "该研究提出MAP框架，一个基于冲突解决理论和多智能体系统的多用户个性化协作方案。通过将任务分解给专门智能体，MAP实现了三阶段工作流：用户信息检索与反思、透明化分析以及反馈迭代优化。用户研究表明(n=12)，该系统能有效解决多用户场景下的指令冲突，同时强调用户参与验证和错误管理的重要性。该工作为多用户环境下的个性化服务提供了可操作框架，展示了多智能体系统在实现用户中心化工作流方面的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.RO",
        "I.2.7; I.2.9; I.2.1"
      ],
      "primary_category": "cs.HC",
      "comment": "In Extended Abstracts of the CHI Conference on Human Factors in\n  Computing Systems (CHI EA '25), April 26-May 1, 2025, Yokohama, Japan",
      "pdf_url": "http://arxiv.org/pdf/2503.12757v2",
      "published_date": "2025-03-17 02:52:10 UTC",
      "updated_date": "2025-03-18 19:15:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:40:12.636171"
    },
    {
      "arxiv_id": "2503.13558v3",
      "title": "Survival Analysis with Machine Learning for Predicting Li-ion Battery Remaining Useful Life",
      "title_zh": "基于机器学习的生存分析预测锂离子电池剩余使用寿命",
      "authors": [
        "Jingyuan Xue",
        "Longfei Wei",
        "Fang Sheng",
        "Yuxin Gao",
        "Jianfei Zhang"
      ],
      "abstract": "The accurate prediction of RUL for lithium-ion batteries is crucial for\nenhancing the reliability and longevity of energy storage systems. Traditional\nmethods for RUL prediction often struggle with issues such as data sparsity,\nvarying battery chemistries, and the inability to capture complex degradation\npatterns over time. In this study, we propose a survival analysis-based\nframework combined with deep learning models to predict the RUL of lithium-ion\nbatteries. Specifically, we utilize five advanced models: the Cox-type models\n(Cox, CoxPH, and CoxTime) and two machine-learning-based models (DeepHit and\nMTLR). These models address the challenges of accurate RUL estimation by\ntransforming raw time-series battery data into survival data, including key\ndegradation indicators such as voltage, current, and internal resistance.\nAdvanced feature extraction techniques enhance the model's robustness in\ndiverse real-world scenarios, including varying charging conditions and battery\nchemistries. Our models are tested using 10-fold cross-validation, ensuring\ngeneralizability and minimizing overfitting. Experimental results show that our\nsurvival-based framework significantly improves RUL prediction accuracy\ncompared to traditional methods, providing a reliable tool for battery\nmanagement and maintenance optimization. This study contributes to the\nadvancement of predictive maintenance in battery technology, offering valuable\ninsights for both researchers and industry practitioners aiming to enhance the\noperational lifespan of lithium-ion batteries.",
      "tldr_zh": "本研究提出了一种结合生存分析（Survival Analysis）和深度学习的框架，用于预测锂离子电池的剩余使用寿命（RUL）。该研究采用五种先进模型（Cox型模型和基于机器学习的DeepHit、MTLR），通过将电池时间序列数据转换为包含电压、电流和内阻等关键退化指标的生存数据，解决了传统方法在数据稀疏性和复杂退化模式捕捉上的局限。实验采用10折交叉验证，结果表明该框架显著提升了RUL预测精度，为电池管理提供了更可靠的预测工具，推动了锂离子电池预测性维护技术的发展。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13558v3",
      "published_date": "2025-03-17 02:49:34 UTC",
      "updated_date": "2025-03-24 10:57:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:40:36.630640"
    },
    {
      "arxiv_id": "2503.12753v1",
      "title": "SafeSlice: Enabling SLA-Compliant O-RAN Slicing via Safe Deep Reinforcement Learning",
      "title_zh": "SafeSlice：通过安全深度强化学习实现符合SLA的O-RAN切片",
      "authors": [
        "Ahmad M. Nagib",
        "Hatem Abou-Zeid",
        "Hossam S. Hassanein"
      ],
      "abstract": "Deep reinforcement learning (DRL)-based slicing policies have shown\nsignificant success in simulated environments but face challenges in physical\nsystems such as open radio access networks (O-RANs) due to\nsimulation-to-reality gaps. These policies often lack safety guarantees to\nensure compliance with service level agreements (SLAs), such as the strict\nlatency requirements of immersive applications. As a result, a deployed DRL\nslicing agent may make resource allocation (RA) decisions that degrade system\nperformance, particularly in previously unseen scenarios. Real-world immersive\napplications require maintaining SLA constraints throughout deployment to\nprevent risky DRL exploration. In this paper, we propose SafeSlice to address\nboth the cumulative (trajectory-wise) and instantaneous (state-wise) latency\nconstraints of O-RAN slices. We incorporate the cumulative constraints by\ndesigning a sigmoid-based risk-sensitive reward function that reflects the\nslices' latency requirements. Moreover, we build a supervised learning cost\nmodel as part of a safety layer that projects the slicing agent's RA actions to\nthe nearest safe actions, fulfilling instantaneous constraints. We conduct an\nexhaustive experiment that supports multiple services, including real virtual\nreality (VR) gaming traffic, to investigate the performance of SafeSlice under\nextreme and changing deployment conditions. SafeSlice achieves reductions of up\nto 83.23% in average cumulative latency, 93.24% in instantaneous latency\nviolations, and 22.13% in resource consumption compared to the baselines. The\nresults also indicate SafeSlice's robustness to changing the threshold\nconfigurations of latency constraints, a vital deployment scenario that will be\nrealized by the O-RAN paradigm to empower mobile network operators (MNOs).",
      "tldr_zh": "本文提出SafeSlice框架，通过安全深度强化学习（Safe DRL）实现符合SLA要求的O-RAN网络切片。该方案采用两种核心机制：基于sigmoid的风险敏感奖励函数处理累积延迟约束，以及安全层监督学习模型确保即时决策的安全性。实验表明，相比基线方法，SafeSlice能降低83.23%的累积延迟和93.24%的即时延迟违规率，同时减少22.13%的资源消耗，特别适用于VR等沉浸式应用场景。该框架支持O-RAN动态阈值配置，为运营商提供了既安全又高效的切片解决方案。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "This article has been accepted for presentation in the IEEE\n  International Conference on Machine Learning for Communication and Networking\n  (ICMLCN) 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.12753v1",
      "published_date": "2025-03-17 02:41:49 UTC",
      "updated_date": "2025-03-17 02:41:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:41:04.510172"
    },
    {
      "arxiv_id": "2503.12739v1",
      "title": "TNCSE: Tensor's Norm Constraints for Unsupervised Contrastive Learning of Sentence Embeddings",
      "title_zh": "TNCSE：基于张量范数约束的无监督对比学习句子嵌入方法",
      "authors": [
        "Tianyu Zong",
        "Bingkang Shi",
        "Hongzhu Yi",
        "Jungang Xu"
      ],
      "abstract": "Unsupervised sentence embedding representation has become a hot research\ntopic in natural language processing. As a tensor, sentence embedding has two\ncritical properties: direction and norm. Existing works have been limited to\nconstraining only the orientation of the samples' representations while\nignoring the features of their module lengths. To address this issue, we\npropose a new training objective that optimizes the training of unsupervised\ncontrastive learning by constraining the module length features between\npositive samples. We combine the training objective of Tensor's Norm\nConstraints with ensemble learning to propose a new Sentence Embedding\nrepresentation framework, TNCSE. We evaluate seven semantic text similarity\ntasks, and the results show that TNCSE and derived models are the current\nstate-of-the-art approach; in addition, we conduct extensive zero-shot\nevaluations, and the results show that TNCSE outperforms other baselines.",
      "tldr_zh": "本文提出TNCSE框架，通过引入张量范数约束(Tensor's Norm Constraints)来改进无监督对比学习中的句子嵌入表示。该方法不仅约束样本表示的方向，还首次显式优化正样本间的模长特征，结合集成学习提升性能。实验表明，TNCSE在7项语义文本相似性任务中达到SOTA水平，并在零样本评估中显著优于基线模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12739v1",
      "published_date": "2025-03-17 02:14:42 UTC",
      "updated_date": "2025-03-17 02:14:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:41:34.109857"
    },
    {
      "arxiv_id": "2503.13557v1",
      "title": "APF+: Boosting adaptive-potential function reinforcement learning methods with a W-shaped network for high-dimensional games",
      "title_zh": "APF+：利用W形网络增强自适应势函数强化学习方法以应对高维游戏",
      "authors": [
        "Yifei Chen",
        "Lambert Schomaker"
      ],
      "abstract": "Studies in reward shaping for reinforcement learning (RL) have flourished in\nrecent years due to its ability to speed up training. Our previous work\nproposed an adaptive potential function (APF) and showed that APF can\naccelerate the Q-learning with a Multi-layer Perceptron algorithm in the\nlow-dimensional domain. This paper proposes to extend APF with an encoder\n(APF+) for RL state representation, allowing applying APF to the pixel-based\nAtari games using a state-encoding method that projects high-dimensional game's\npixel frames to low-dimensional embeddings. We approach by designing the\nstate-representation encoder as a W-shaped network (W-Net), by using which we\nare able to encode both the background as well as the moving entities in the\ngame frames. Specifically, the embeddings derived from the pre-trained W-Net\nconsist of two latent vectors: One represents the input state, and the other\nrepresents the deviation of the input state's representation from itself. We\nthen incorporate W-Net into APF to train a downstream Dueling Deep Q-Network\n(DDQN), obtain the APF-WNet-DDQN, and demonstrate its effectiveness in Atari\ngame-playing tasks. To evaluate the APF+W-Net module in such high-dimensional\ntasks, we compare with two types of baseline methods: (i) the basic DDQN; and\n(ii) two encoder-replaced APF-DDQN methods where we replace W-Net by (a) an\nunsupervised state representation method called Spatiotemporal Deep Infomax\n(ST-DIM) and (b) a ground truth state representation provided by the Atari\nAnnotated RAM Interface (ARI). The experiment results show that out of 20 Atari\ngames, APF-WNet-DDQN outperforms DDQN (14/20 games) and APF-STDIM-DDQN (13/20\ngames) significantly. In comparison against the APF-ARI-DDQN which employs\nembeddings directly of the detailed game-internal state information, the\nAPF-WNet-DDQN achieves a comparable performance.",
      "tldr_zh": "该研究提出了APF+方法，通过W形网络(W-Net)增强自适应势函数(APF)强化学习算法，使其适用于高维游戏场景。该方法创新性地设计了一个双分支编码器，能同时捕捉游戏帧的静态背景和动态实体特征，将高维像素帧压缩为低维嵌入向量。实验表明，在20款Atari游戏中，APF+W-Net结合的Dueling DQN(APF-WNet-DDQN)显著优于基准方法，其中14款游戏表现超过基础DDQN，13款超过基于ST-DIM编码的变体，并与使用游戏内部真实状态信息的APF-ARI-DDQN达到相当性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "46 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.13557v1",
      "published_date": "2025-03-17 01:53:26 UTC",
      "updated_date": "2025-03-17 01:53:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:41:56.090129"
    },
    {
      "arxiv_id": "2503.12730v1",
      "title": "TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research",
      "title_zh": "TinySQL：面向机制可解释性研究的渐进式文本转SQL数据集",
      "authors": [
        "Philip Quirke",
        "Clement Neo",
        "Abir Harrasse",
        "Dhruv Nathawani",
        "Amir Abdullah"
      ],
      "abstract": "Mechanistic interpretability research faces a gap between analyzing simple\ncircuits in toy tasks and discovering features in large models. To bridge this\ngap, we propose text-to-SQL generation as an ideal task to study, as it\ncombines the formal structure of toy tasks with real-world complexity. We\nintroduce TinySQL, a synthetic dataset progressing from basic to advanced SQL\noperations, and train models ranging from 33M to 1B parameters to establish a\ncomprehensive testbed for interpretability. We apply multiple complementary\ninterpretability techniques, including edge attribution patching and sparse\nautoencoders, to identify minimal circuits and components supporting SQL\ngeneration. Our analysis reveals both the potential and limitations of current\ninterpretability methods, showing how circuits can vary even across similar\nqueries. Lastly, we demonstrate how mechanistic interpretability can identify\nflawed heuristics in models and improve synthetic dataset design. Our work\nprovides a comprehensive framework for evaluating and advancing\ninterpretability techniques while establishing clear boundaries for their\nreliable application.",
      "tldr_zh": "该研究提出了TinySQL——一个渐进式文本到SQL生成数据集，用于填补机理可解释性研究在玩具任务简单电路分析与大模型特征发现之间的空白。通过构建从基础到高级SQL操作的合成数据集，并训练3300万至10亿参数的模型，建立了全面的可解释性测试平台。研究采用边缘归因修补和稀疏自编码器等技术，揭示了SQL生成的最小支持电路和组件，同时展示了当前可解释性方法的潜力与局限。这项工作不仅为评估和推进可解释性技术提供了框架，还通过机理分析识别出模型中的缺陷启发式方法，改进了合成数据集设计。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 19 figures, 7 tables, 18 trained models",
      "pdf_url": "http://arxiv.org/pdf/2503.12730v1",
      "published_date": "2025-03-17 01:47:50 UTC",
      "updated_date": "2025-03-17 01:47:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:42:08.653099"
    },
    {
      "arxiv_id": "2503.16520v1",
      "title": "Not All Personas Are Worth It: Culture-Reflective Persona Data Augmentation",
      "title_zh": "并非所有角色都有价值：基于文化映射的角色数据增强",
      "authors": [
        "Ji-Eun Han",
        "Yoonseok Heo"
      ],
      "abstract": "Incorporating personas into conversational AI models is crucial for achieving\nauthentic and engaging interactions. However, the cultural diversity and\nadaptability of existing persona datasets is often overlooked, reducing their\nefficacy in building culturally aware AI systems. To address this issue, we\npropose a two-step pipeline for generating culture-specific personas and\nintroduce KoPersona, a dataset comprising 200,000 personas designed to capture\nKorean cultural values, behaviors, and social nuances. A comprehensive\nevaluation through various metrics validates the quality of KoPersona and its\nrelevance to Korean culture. This work not only contributes to persona-based\nresearch, but also establishes a scalable approach for creating culturally\nrelevant personas adaptable to various languages and cultural contexts.",
      "tldr_zh": "本文提出了一种两步流程，用于生成特定文化的对话AI角色(persona)，并推出了KoPersona数据集，包含20万个反映韩国文化价值、行为和社会细微差异的角色。研究通过多种指标验证了KoPersona的质量及其与韩国文化的相关性，不仅推动了基于角色的研究，还为创建适应不同语言和文化背景的可扩展方法奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16520v1",
      "published_date": "2025-03-17 01:23:57 UTC",
      "updated_date": "2025-03-17 01:23:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:42:21.226797"
    },
    {
      "arxiv_id": "2503.12722v1",
      "title": "Identifying Cooperative Personalities in Multi-agent Contexts through Personality Steering with Representation Engineering",
      "title_zh": "通过表征工程实现人格调控：多智能体场景中的合作型性格识别",
      "authors": [
        "Kenneth J. K. Ong",
        "Lye Jia Jun",
        "Hieu Minh \"Jord\" Nguyen",
        "Seong Hah Cho",
        "Natalia Pérez-Campanero Antolín"
      ],
      "abstract": "As Large Language Models (LLMs) gain autonomous capabilities, their\ncoordination in multi-agent settings becomes increasingly important. However,\nthey often struggle with cooperation, leading to suboptimal outcomes. Inspired\nby Axelrod's Iterated Prisoner's Dilemma (IPD) tournaments, we explore how\npersonality traits influence LLM cooperation. Using representation engineering,\nwe steer Big Five traits (e.g., Agreeableness, Conscientiousness) in LLMs and\nanalyze their impact on IPD decision-making. Our results show that higher\nAgreeableness and Conscientiousness improve cooperation but increase\nsusceptibility to exploitation, highlighting both the potential and limitations\nof personality-based steering for aligning AI agents.",
      "tldr_zh": "该研究通过表示工程（Representation Engineering）方法调控大语言模型（LLMs）的\"大五人格\"特质（如宜人性、尽责性），探究其对多智能体协作的影响。实验基于迭代囚徒困境（IPD）框架，发现高宜人性和高尽责性虽能提升模型间合作率，但也会增加被恶意利用的脆弱性。该成果揭示了人格导向方法在AI对齐应用中的潜力与局限性，为多智能体系统的行为调控提供了新思路。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Poster, Technical AI Safety Conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.12722v1",
      "published_date": "2025-03-17 01:21:54 UTC",
      "updated_date": "2025-03-17 01:21:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:42:45.667871"
    },
    {
      "arxiv_id": "2503.12721v1",
      "title": "Can Reasoning Models Reason about Hardware? An Agentic HLS Perspective",
      "title_zh": "推理模型能对硬件进行推理吗？——一种基于智能体高级综合的视角",
      "authors": [
        "Luca Collini",
        "Andrew Hennessee",
        "Ramesh Karri",
        "Siddharth Garg"
      ],
      "abstract": "Recent Large Language Models (LLMs) such as OpenAI o3-mini and DeepSeek-R1\nuse enhanced reasoning through Chain-of-Thought (CoT). Their potential in\nhardware design, which relies on expert-driven iterative optimization, remains\nunexplored. This paper investigates whether reasoning LLMs can address\nchallenges in High-Level Synthesis (HLS) design space exploration and\noptimization. During HLS, engineers manually define pragmas/directives to\nbalance performance and resource constraints. We propose an LLM-based\noptimization agentic framework that automatically restructures code, inserts\npragmas, and identifies optimal design points via feedback from HLs tools and\naccess to integer-linear programming (ILP) solvers. Experiments compare\nreasoning models against conventional LLMs on benchmarks using success rate,\nefficiency, and design quality (area/latency) metrics, and provide the\nfirst-ever glimpse into the CoTs produced by a powerful open-source reasoning\nmodel like DeepSeek-R1.",
      "tldr_zh": "这篇论文探讨了具备推理能力的大语言模型(LLMs)在硬件设计领域的应用潜力，重点关注高层次综合(HLS)的设计空间探索与优化问题。研究团队提出了一个基于LLM的智能代理框架，能够自动重构代码、插入编译指示(pragmas)，并通过结合HLS工具反馈和整数线性规划(ILP)求解器来寻找最优设计方案。实验对比了推理型LLM与传统LLM在成功率、效率和设计质量(面积/延迟)等指标上的表现，并首次揭示了像DeepSeek-R1这样的开源推理模型产生的思维链(CoTs)工作机制。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, submitted for peer review",
      "pdf_url": "http://arxiv.org/pdf/2503.12721v1",
      "published_date": "2025-03-17 01:21:39 UTC",
      "updated_date": "2025-03-17 01:21:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:43:13.414600"
    },
    {
      "arxiv_id": "2503.15546v1",
      "title": "Enforcing Cybersecurity Constraints for LLM-driven Robot Agents for Online Transactions",
      "title_zh": "强化LLM驱动机器人代理在线交易的网络安全约束",
      "authors": [
        "Shraddha Pradipbhai Shah",
        "Aditya Vilas Deshpande"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into autonomous robotic\nagents for conducting online transactions poses significant cybersecurity\nchallenges. This study aims to enforce robust cybersecurity constraints to\nmitigate the risks associated with data breaches, transaction fraud, and system\nmanipulation. The background focuses on the rise of LLM-driven robotic systems\nin e-commerce, finance, and service industries, alongside the vulnerabilities\nthey introduce. A novel security architecture combining blockchain technology\nwith multi-factor authentication (MFA) and real-time anomaly detection was\nimplemented to safeguard transactions. Key performance metrics such as\ntransaction integrity, response time, and breach detection accuracy were\nevaluated, showing improved security and system performance. The results\nhighlight that the proposed architecture reduced fraudulent transactions by\n90%, improved breach detection accuracy to 98%, and ensured secure transaction\nvalidation within a latency of 0.05 seconds. These findings emphasize the\nimportance of cybersecurity in the deployment of LLM-driven robotic systems and\nsuggest a framework adaptable to various online platforms.",
      "tldr_zh": "该研究提出了一种针对LLM驱动的机器人代理的网络安全架构，旨在解决在线交易中的数据泄露、欺诈和系统操纵风险。通过结合区块链技术、多因素认证(MFA)和实时异常检测，该系统将欺诈交易减少了90%，检测准确率提升至98%，且能在0.05秒内完成安全验证。这些成果为LLM机器人系统在电商、金融等领域的应用提供了可靠的安全保障。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15546v1",
      "published_date": "2025-03-17 01:01:10 UTC",
      "updated_date": "2025-03-17 01:01:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:43:23.863089"
    },
    {
      "arxiv_id": "2503.13556v1",
      "title": "Pareidolic Illusions of Meaning: ChatGPT, Pseudolaw and the Triumph of Form over Substance",
      "title_zh": "意义的空想幻象：ChatGPT、伪法学与形式对实质的胜利",
      "authors": [
        "Joe McIntyre"
      ],
      "abstract": "The early 2020s has seen the rise of two strange and potentially quite\nimpactful social phenomena, namely pseudolaw, where users rely upon pseudolegal\narguments that mimic the form and ritual of legal argumentation but\nfundamentally distort the content of law, and generative AI/LLMs, which\ngenerate content that uses probabilistic calculations to create outputs that\nlook like human generated text. This article argues that the juxtaposition of\nthe two phenomena helps to reveal that they both share two fundamental traits\nas both elevate form and appearance over substance and content, and users of\nboth routinely mistake the form for the substance. In drawing upon legal\ntheory, computer science, linguistics and cognitive psychology, the article\nargues that both phenomena rely upon creating illusions of meaning that users\nmistake for the underlying primary phenomenon. I then explore four implications\nof this conception of both phenomena. Firstly, both rely on human tendencies of\nconceptual pareidolia resulting in the erroneous perception of meaningful\nlinguistic legal patterns from nebulous inputs. Secondly, both rely upon the\nconfidence heuristic, the human cognitive bias for treating confidence as a\nproxy for competence. Thirdly, both succeed when the primary concern is with\nthe form of the output and not its content. Fourthly, both rely heavily upon\nthe magical thinking of users and the desire for the promise of the approach to\nbe real. The article argues that the legal context helps to reveal a solution\nfor the problems caused by both phenomena as it is only where users possess\nsufficient legal and technological literacy that it becomes possible to reveal\nto them the illusionary nature of the phenomena.",
      "tldr_zh": "本文探讨了2020年代初期出现的两种社会现象：伪法律(pseudolaw)和生成式AI/LLMs（如ChatGPT），指出它们都强调形式而非实质，且用户常将形式误认为内容。通过结合法律理论、计算机科学、语言学和认知心理学，文章揭示了这两种现象依赖“意义的幻觉”，并提出了四点核心观点：1）它们利用了人类的概念性空想(pareidolia)倾向；2）依赖“信心启发式”认知偏差；3）在用户关注形式而非内容时成功；4）依赖用户的魔法思维和对承诺的渴望。文章认为，提高法律和技术素养是解决这些问题的关键。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "54 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13556v1",
      "published_date": "2025-03-17 00:15:41 UTC",
      "updated_date": "2025-03-17 00:15:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:43:53.286698"
    },
    {
      "arxiv_id": "2503.13369v1",
      "title": "Sightation Counts: Leveraging Sighted User Feedback in Building a BLV-aligned Dataset of Diagram Descriptions",
      "title_zh": "Sightation计数：利用视力正常用户反馈构建面向视障群体的图表描述数据集",
      "authors": [
        "Wan Ju Kang",
        "Eunki Kim",
        "Na Min An",
        "Sangryul Kim",
        "Haemin Choi",
        "Ki Hoon Kwak",
        "James Thorne"
      ],
      "abstract": "Often, the needs and visual abilities differ between the annotator group and\nthe end user group. Generating detailed diagram descriptions for blind and\nlow-vision (BLV) users is one such challenging domain. Sighted annotators could\ndescribe visuals with ease, but existing studies have shown that direct\ngenerations by them are costly, bias-prone, and somewhat lacking by BLV\nstandards. In this study, we ask sighted individuals to assess -- rather than\nproduce -- diagram descriptions generated by vision-language models (VLM) that\nhave been guided with latent supervision via a multi-pass inference. The\nsighted assessments prove effective and useful to professional educators who\nare themselves BLV and teach visually impaired learners. We release Sightation,\na collection of diagram description datasets spanning 5k diagrams and 137k\nsamples for completion, preference, retrieval, question answering, and\nreasoning training purposes and demonstrate their fine-tuning potential in\nvarious downstream tasks.",
      "tldr_zh": "该研究提出了Sightation数据集，通过让视力正常者评估（而非直接生成）由视觉语言模型(VLM)产生的图表描述，来解决盲人和低视力(BLV)用户与视力正常标注者之间的需求差异问题。研究发现，这种基于多轮推理潜在监督的评估方法比直接生成更有效，且获得了BLV教育专家的认可。该数据集包含5千张图表和13.7万个样本，支持完成、偏好、检索、问答和推理等多种任务，实验证明其在多项下游任务中的微调潜力。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "37 pages, 10 figures, 21 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.13369v1",
      "published_date": "2025-03-17 16:52:46 UTC",
      "updated_date": "2025-03-17 16:52:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:44:26.519312"
    },
    {
      "arxiv_id": "2503.14543v2",
      "title": "Inteligencia Artificial para la conservación y uso sostenible de la biodiversidad, una visión desde Colombia (Artificial Intelligence for conservation and sustainable use of biodiversity, a view from Colombia)",
      "title_zh": "人工智能助力生物多样性保护与可持续利用：哥伦比亚视角",
      "authors": [
        "Juan Sebastián Cañas",
        "Camila Parra-Guevara",
        "Manuela Montoya-Castrillón",
        "Julieta M Ramírez-Mejía",
        "Gabriel-Alejandro Perilla",
        "Esteban Marentes",
        "Nerieth Leuro",
        "Jose Vladimir Sandoval-Sierra",
        "Sindy Martinez-Callejas",
        "Angélica Díaz",
        "Mario Murcia",
        "Elkin A. Noguera-Urbano",
        "Jose Manuel Ochoa-Quintero",
        "Susana Rodríguez Buriticá",
        "Juan Sebastián Ulloa"
      ],
      "abstract": "The rise of artificial intelligence (AI) and the aggravating biodiversity\ncrisis have resulted in a research area where AI-based computational methods\nare being developed to act as allies in conservation, and the sustainable use\nand management of natural resources. While important general guidelines have\nbeen established globally regarding the opportunities and challenges that this\ninterdisciplinary research offers, it is essential to generate local\nreflections from the specific contexts and realities of each region. Hence,\nthis document aims to analyze the scope of this research area from a\nperspective focused on Colombia and the Neotropics. In this paper, we summarize\nthe main experiences and debates that took place at the Humboldt Institute\nbetween 2023 and 2024 in Colombia. To illustrate the variety of promising\nopportunities, we present current uses such as automatic species identification\nfrom images and recordings, species modeling, and in silico bioprospecting,\namong others. From the experiences described above, we highlight limitations,\nchallenges, and opportunities for in order to successfully implementate AI in\nconservation efforts and sustainable management of biological resources in the\nNeotropics. The result aims to be a guide for researchers, decision makers, and\nbiodiversity managers, facilitating the understanding of how artificial\nintelligence can be effectively integrated into conservation and sustainable\nuse strategies. Furthermore, it also seeks to open a space for dialogue on the\ndevelopment of policies that promote the responsible and ethical adoption of AI\nin local contexts, ensuring that its benefits are harnessed without\ncompromising biodiversity or the cultural and ecosystemic values inherent in\nColombia and the Neotropics.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在生物多样性保护与可持续利用中的应用，特别聚焦于哥伦比亚和新热带地区的实践与挑战。研究基于2023-2024年洪堡研究所的经验，总结了AI在该领域的典型应用，包括基于图像的物种自动识别、物种分布建模及计算机辅助生物勘探等。论文同时指出了在新热带地区实施AI技术面临的局限与机遇，旨在为科研人员和决策者提供指南，促进AI在保护策略中的有效整合。研究还呼吁制定本地化政策，确保AI的应用既能发挥效益，又能维护生物多样性及该地区特有的文化与生态价值。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.14543v2",
      "published_date": "2025-03-17 16:47:05 UTC",
      "updated_date": "2025-03-21 01:10:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:45:08.101014"
    },
    {
      "arxiv_id": "2503.13309v1",
      "title": "Integrating AI for Human-Centric Breast Cancer Diagnostics: A Multi-Scale and Multi-View Swin Transformer Framework",
      "title_zh": "融合AI的以人为中心乳腺癌诊断：多尺度多视角Swin Transformer框架",
      "authors": [
        "Farnoush Bayatmakou",
        "Reza Taleei",
        "Milad Amir Toutounchian",
        "Arash Mohammadi"
      ],
      "abstract": "Despite advancements in Computer-Aided Diagnosis (CAD) systems, breast cancer\nremains one of the leading causes of cancer-related deaths among women\nworldwide. Recent breakthroughs in Artificial Intelligence (AI) have shown\nsignificant promise in development of advanced Deep Learning (DL) architectures\nfor breast cancer diagnosis through mammography. In this context, the paper\nfocuses on the integration of AI within a Human-Centric workflow to enhance\nbreast cancer diagnostics. Key challenges are, however, largely overlooked such\nas reliance on detailed tumor annotations and susceptibility to missing views,\nparticularly during test time. To address these issues, we propose a hybrid,\nmulti-scale and multi-view Swin Transformer-based framework (MSMV-Swin) that\nenhances diagnostic robustness and accuracy. The proposed MSMV-Swin framework\nis designed to work as a decision-support tool, helping radiologists analyze\nmulti-view mammograms more effectively. More specifically, the MSMV-Swin\nframework leverages the Segment Anything Model (SAM) to isolate the breast\nlobe, reducing background noise and enabling comprehensive feature extraction.\nThe multi-scale nature of the proposed MSMV-Swin framework accounts for\ntumor-specific regions as well as the spatial characteristics of tissues\nsurrounding the tumor, capturing both localized and contextual information. The\nintegration of contextual and localized data ensures that MSMV-Swin's outputs\nalign with the way radiologists interpret mammograms, fostering better human-AI\ninteraction and trust. A hybrid fusion structure is then designed to ensure\nrobustness against missing views, a common occurrence in clinical practice when\nonly a single mammogram view is available.",
      "tldr_zh": "该研究提出了一种多尺度多视角的Swin Transformer框架(MSMV-Swin)，旨在提升乳腺癌诊断的准确性和鲁棒性。该框架结合了Segment Anything Model (SAM)来隔离乳腺区域，减少背景噪声，并通过多尺度特征提取同时捕捉肿瘤局部和周围组织的上下文信息。此外，MSMV-Swin设计了混合融合结构，解决了临床中常见视角缺失的问题，使其能够在单视角情况下保持诊断性能。该框架作为决策支持工具，增强了放射科医生对多视角乳腺X光片的分析能力，促进了人机交互的信任。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13309v1",
      "published_date": "2025-03-17 15:48:56 UTC",
      "updated_date": "2025-03-17 15:48:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T15:45:47.927954"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 138,
  "processed_papers_count": 138,
  "failed_papers_count": 3,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-03-26T15:47:06.141403"
}