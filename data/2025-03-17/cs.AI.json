{
  "date": "2025-03-17",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-17 的 arXiv 中文 TLDR 快报！今天 arXiv 论文聚焦 AI 在多领域创新应用，包括 LLM 的高效训练、强化学习在机器人和游戏中的扩展、多模态视觉推理，以及医疗和图像处理的进展；重点是 LLM 鲁棒性优化（如 Aleksander Madry 的元梯度下降方法）和多模态模型在复杂任务中的表现，令人印象深刻的文章有 VideoMind 用于视频推理，以及多代理系统在协作决策中的潜力。\n\n### 重点论文讨论\n我们挑选了今天几篇重要且有影响力的论文，先从 LLM 和多模态领域入手，再简要聊聊机器人与强化学习相关的内容。其他论文如纯理论或较窄领域的（如某些数据集回顾或小众应用），我们快速掠过，只提核心点。\n\n1. **Towards AI-assisted Academic Writing（AI辅助学术写作）**  \n   作者包括 Daniel J. Liebling 和 Michael P. Brenner，这篇论文提出一个 AI 系统，用于推荐引用和生成引言，基于文档上下文提供相关建议，并通过定量评估证明其有效性；主要贡献是提升学术写作效率，同时探索研究者如何整合 AI 工具。\n\n2. **A Generalist Hanabi Agent（通用 Hanabi 代理）**  \n   作者如 Sarath Chandar，这篇论文开发了 R3D2 算法，使用文本重构和分布式强化学习（MARL），让代理在不同游戏设置中协作并适应新伙伴；关键发现是它首次实现跨设置策略转移，提高了 MARL 在复杂合作任务中的泛化能力。\n\n3. **Optimizing ML Training with Metagradient Descent（使用元梯度下降优化 ML 训练）**  \n   作者包括著名学者 Aleksander Madry，这篇论文引入元梯度计算和平滑训练框架，显著提升数据集选择和学习率调度；主要贡献是通过梯度优化实现高效训练，远超传统方法，在实际应用中减少了准确性下降。\n\n4. **VideoMind: A Chain-of-LoRA Agent for Long Video Reasoning（VideoMind: 用于长视频推理的 LoRA 代理链）**  \n   作者如 Mike Zheng Shou，这篇论文提出 VideoMind 框架，使用 LoRA 适配器实现角色切换，支持长视频的时序推理；核心发现是它在多个基准上达到 SOTA 性能，提升了视频代理的多任务处理能力。\n\n5. **Humanoid Policy ~ Human Policy（Humanoid Policy ~ Human Policy）**  \n   作者包括 Xiaolong Wang，这篇论文使用 Human Action Transformer 模型，将人类动作数据转移到机器人上，通过统一状态-动作空间实现跨主体泛化；主要贡献是提高了机器人操作的鲁棒性和数据效率。\n\n其他论文如 \"Fire and Smoke Datasets in 20 Years: An In-depth Review\"（快速掠过：回顾20年火烟数据集，强调 AI 在火灾管理的应用，但细节较常规）；\"AI-driven Automation of End-to-end Assessment of Suturing Expertise\"（医疗 AI 自动化缝合评估，贡献在于实时反馈提升手术训练，但整体影响力较小）。总之，今天的论文展示了 AI 在实际场景中的潜力，但 LLM 安全和泛化仍是关键挑战。明日见！",
  "papers": [
    {
      "arxiv_id": "2503.13778v1",
      "title": "Using 3D reconstruction from image motion to predict total leaf area in dwarf tomato plants",
      "title_zh": "翻译失败",
      "authors": [
        "Dmitrii Usenko",
        "David Helman",
        "Chen Giladi"
      ],
      "abstract": "Accurate estimation of total leaf area (TLA) is crucial for evaluating plant\ngrowth, photosynthetic activity, and transpiration. However, it remains\nchallenging for bushy plants like dwarf tomatoes due to their complex canopies.\nTraditional methods are often labor-intensive, damaging to plants, or limited\nin capturing canopy complexity. This study evaluated a non-destructive method\ncombining sequential 3D reconstructions from RGB images and machine learning to\nestimate TLA for three dwarf tomato cultivars: Mohamed, Hahms Gelbe Topftomate,\nand Red Robin -- grown under controlled greenhouse conditions. Two experiments\n(spring-summer and autumn-winter) included 73 plants, yielding 418 TLA\nmeasurements via an \"onion\" approach. High-resolution videos were recorded, and\n500 frames per plant were used for 3D reconstruction. Point clouds were\nprocessed using four algorithms (Alpha Shape, Marching Cubes, Poisson's, Ball\nPivoting), and meshes were evaluated with seven regression models:\nMultivariable Linear Regression, Lasso Regression, Ridge Regression, Elastic\nNet Regression, Random Forest, Extreme Gradient Boosting, and Multilayer\nPerceptron. The Alpha Shape reconstruction ($\\alpha = 3$) with Extreme Gradient\nBoosting achieved the best performance ($R^2 = 0.80$, $MAE = 489 cm^2$).\nCross-experiment validation showed robust results ($R^2 = 0.56$, $MAE = 579\ncm^2$). Feature importance analysis identified height, width, and surface area\nas key predictors. This scalable, automated TLA estimation method is suited for\nurban farming and precision agriculture, offering applications in automated\npruning, resource efficiency, and sustainable food production. The approach\ndemonstrated robustness across variable environmental conditions and canopy\nstructures.",
      "tldr_zh": "本研究提出了一种非破坏性方法，利用从图像运动获得的3D重建和机器学习来预测矮生番茄植物的总叶面积（TLA），以解决传统方法耗时且难以捕捉复杂冠层的挑战。该方法对三种番茄品种进行了实验，包括春夏和秋冬两个季节的73株植物，通过处理高分辨率视频的500帧点云并应用四种重建算法（Alpha Shape、Marching Cubes、Poisson's、Ball Pivoting）和七种回归模型，最终发现Alpha Shape重建（α=3）结合Extreme Gradient Boosting模型表现最佳（R²=0.80，MAE=489 cm²），并在跨实验验证中显示鲁棒性（R²=0.56，MAE=579 cm²）。特征重要性分析表明，高度、宽度和表面面积是关键预测因子，该方法适用于城市农业和精准农业，可支持自动修剪、资源优化和可持续食品生产。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages, 11 figures, submitted to Computers and Electronics in\n  Agriculture",
      "pdf_url": "http://arxiv.org/pdf/2503.13778v1",
      "published_date": "2025-03-17 23:51:19 UTC",
      "updated_date": "2025-03-17 23:51:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:54:02.741558"
    },
    {
      "arxiv_id": "2503.13771v1",
      "title": "Towards AI-assisted Academic Writing",
      "title_zh": "迈向 AI 辅助的学术写作",
      "authors": [
        "Daniel J. Liebling",
        "Malcolm Kane",
        "Madeleine Grunde-Mclaughlin",
        "Ian J. Lang",
        "Subhashini Venugopalan",
        "Michael P. Brenner"
      ],
      "abstract": "We present components of an AI-assisted academic writing system including\ncitation recommendation and introduction writing. The system recommends\ncitations by considering the user's current document context to provide\nrelevant suggestions. It generates introductions in a structured fashion,\nsituating the contributions of the research relative to prior work. We\ndemonstrate the effectiveness of the components through quantitative\nevaluations. Finally, the paper presents qualitative research exploring how\nresearchers incorporate citations into their writing workflows. Our findings\nindicate that there is demand for precise AI-assisted writing systems and\nsimple, effective methods for meeting those needs.",
      "tldr_zh": "这篇论文介绍了 AI 辅助学术写作系统的组件，包括 citation recommendation 和 introduction writing。系统通过分析用户的文档上下文来推荐相关引文，并以结构化方式生成引言，以突出研究贡献相对于先前工作的定位。研究通过定量评估验证了这些组件的有效性，并通过定性研究发现，研究人员对精确的 AI-assisted writing 系统有强烈需求，并强调了简单有效方法的必要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted to NAACL 2025 Workshop on AI for Scientific Discovery",
      "pdf_url": "http://arxiv.org/pdf/2503.13771v1",
      "published_date": "2025-03-17 23:30:17 UTC",
      "updated_date": "2025-03-17 23:30:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:54:12.962211"
    },
    {
      "arxiv_id": "2503.14555v1",
      "title": "A Generalist Hanabi Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Arjun V Sudhakar",
        "Hadi Nekoei",
        "Mathieu Reymond",
        "Miao Liu",
        "Janarthanan Rajendran",
        "Sarath Chandar"
      ],
      "abstract": "Traditional multi-agent reinforcement learning (MARL) systems can develop\ncooperative strategies through repeated interactions. However, these systems\nare unable to perform well on any other setting than the one they have been\ntrained on, and struggle to successfully cooperate with unfamiliar\ncollaborators. This is particularly visible in the Hanabi benchmark, a popular\n2-to-5 player cooperative card-game which requires complex reasoning and\nprecise assistance to other agents. Current MARL agents for Hanabi can only\nlearn one specific game-setting (e.g., 2-player games), and play with the same\nalgorithmic agents. This is in stark contrast to humans, who can quickly adjust\ntheir strategies to work with unfamiliar partners or situations. In this paper,\nwe introduce Recurrent Replay Relevance Distributed DQN (R3D2), a generalist\nagent for Hanabi, designed to overcome these limitations. We reformulate the\ntask using text, as language has been shown to improve transfer. We then\npropose a distributed MARL algorithm that copes with the resulting dynamic\nobservation- and action-space. In doing so, our agent is the first that can\nplay all game settings concurrently, and extend strategies learned from one\nsetting to other ones. As a consequence, our agent also demonstrates the\nability to collaborate with different algorithmic agents -- agents that are\nthemselves unable to do so. The implementation code is available at:\n$\\href{https://github.com/chandar-lab/R3D2-A-Generalist-Hanabi-Agent}{R3D2-A-Generalist-Hanabi-Agent}$",
      "tldr_zh": "本研究指出，传统的多智能体强化学习 (MARL) 代理难以适应新环境或与陌生合作者合作，尤其在 Hanabi 游戏中，该游戏需要复杂推理和精确协助，但现有代理仅限于特定设置（如 2 玩家游戏）。为了解决这一问题，作者引入了 Recurrent Replay Relevance Distributed DQN (R3D2)，一个通用 Hanabi 代理，通过文本重新表述任务并采用分布式 MARL 算法来处理动态的观察和动作空间。R3D2 实现了在所有游戏设置下的并发玩耍，并能将学到的策略扩展到其他场景，甚至与无法自适应的其他算法代理合作，从而显著提升了代理的泛化性和合作能力。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.14555v1",
      "published_date": "2025-03-17 22:25:15 UTC",
      "updated_date": "2025-03-17 22:25:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:54:27.046183"
    },
    {
      "arxiv_id": "2503.14554v1",
      "title": "Synchronous vs Asynchronous Reinforcement Learning in a Real World Robot",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Parsaee",
        "Fahim Shahriar",
        "Chuxin He",
        "Ruiqing Tan"
      ],
      "abstract": "In recent times, reinforcement learning (RL) with physical robots has\nattracted the attention of a wide range of researchers. However,\nstate-of-the-art RL algorithms do not consider that physical environments do\nnot wait for the RL agent to make decisions or updates. RL agents learn by\nperiodically conducting computationally expensive gradient updates. When\ndecision-making and gradient update tasks are carried out sequentially by the\nRL agent in a physical robot, it significantly increases the agent's response\ntime. In a rapidly changing environment, this increased response time may be\ndetrimental to the performance of the learning agent. Asynchronous RL methods,\nwhich separate the computation of decision-making and gradient updates, are a\npotential solution to this problem. However, only a few comparisons between\nasynchronous and synchronous RL have been made with physical robots. For this\nreason, the exact performance benefits of using asynchronous RL methods over\nsynchronous RL methods are still unclear. In this study, we provide a\nperformance comparison between asynchronous and synchronous RL using a physical\nrobotic arm called Franka Emika Panda. Our experiments show that the agents\nlearn faster and attain significantly more returns using asynchronous RL. Our\nexperiments also demonstrate that the learning agent with a faster response\ntime performs better than the agent with a slower response time, even if the\nagent with a slower response time performs a higher number of gradient updates.",
      "tldr_zh": "本研究比较了同步和异步强化学习（Reinforcement Learning, RL）在真实世界机器人中的性能，重点解决传统 RL 算法在物理环境中响应时间过长的问题。研究使用 Franka Emika Panda 机器人臂进行实验，将决策和梯度更新任务分开，以评估异步 RL 的优势。结果显示，异步 RL 使代理学习更快，并获得显著更高的回报，即使同步 RL 进行了更多梯度更新，响应时间更快的代理也表现出色。该工作澄清了异步 RL 在实际机器人应用中的性能益处，为优化 RL 算法提供了重要见解。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Presented at Alberta Robotics & Intelligent Systems Expo (RISE)\n  Conference",
      "pdf_url": "http://arxiv.org/pdf/2503.14554v1",
      "published_date": "2025-03-17 22:24:39 UTC",
      "updated_date": "2025-03-17 22:24:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:54:36.581091"
    },
    {
      "arxiv_id": "2503.13754v2",
      "title": "From Autonomous Agents to Integrated Systems, A New Paradigm: Orchestrated Distributed Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Krti Tallam"
      ],
      "abstract": "The rapid evolution of artificial intelligence (AI) has ushered in a new era\nof integrated systems that merge computational prowess with human\ndecision-making. In this paper, we introduce the concept of Orchestrated\nDistributed Intelligence (ODI), a novel paradigm that reconceptualizes AI not\nas isolated autonomous agents, but as cohesive, orchestrated networks that work\nin tandem with human expertise. ODI leverages advanced orchestration layers,\nmulti-loop feedback mechanisms, and a high cognitive density framework to\ntransform static, record-keeping systems into dynamic, action-oriented\nenvironments. Through a comprehensive review of multi-agent system literature,\nrecent technological advances, and practical insights from industry forums, we\nargue that the future of AI lies in integrating distributed intelligence within\nhuman-centric workflows. This approach not only enhances operational efficiency\nand strategic agility but also addresses challenges related to scalability,\ntransparency, and ethical decision-making. Our work outlines key theoretical\nimplications and presents a practical roadmap for future research and\nenterprise innovation, aiming to pave the way for responsible and adaptive AI\nsystems that drive sustainable innovation in human organizations.",
      "tldr_zh": "本论文引入了Orchestrated Distributed Intelligence (ODI)这一新范式，将AI从孤立的自主代理转变为与人类决策相结合的协调网络。ODI通过高级编排层、多回路反馈机制和高认知密度框架，将静态系统转化为动态、行动导向的环境，从而提升操作效率和战略敏捷性。论文通过对multi-agent system文献、技术进展和行业洞见的综述，解决了可伸缩性、透明度和伦理决策的挑战，并为未来研究和企业创新提供理论含义及实践路线图。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13754v2",
      "published_date": "2025-03-17 22:21:25 UTC",
      "updated_date": "2025-03-19 02:01:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:54:49.129141"
    },
    {
      "arxiv_id": "2503.13751v1",
      "title": "Optimizing ML Training with Metagradient Descent",
      "title_zh": "翻译失败",
      "authors": [
        "Logan Engstrom",
        "Andrew Ilyas",
        "Benjamin Chen",
        "Axel Feldmann",
        "William Moses",
        "Aleksander Madry"
      ],
      "abstract": "A major challenge in training large-scale machine learning models is\nconfiguring the training process to maximize model performance, i.e., finding\nthe best training setup from a vast design space. In this work, we unlock a\ngradient-based approach to this problem. We first introduce an algorithm for\nefficiently calculating metagradients -- gradients through model training -- at\nscale. We then introduce a \"smooth model training\" framework that enables\neffective optimization using metagradients. With metagradient descent (MGD), we\ngreatly improve on existing dataset selection methods, outperform\naccuracy-degrading data poisoning attacks by an order of magnitude, and\nautomatically find competitive learning rate schedules.",
      "tldr_zh": "本研究针对机器学习模型训练中的关键挑战——从庞大设计空间中找到最佳训练配置——提出了一种基于 metagradient descent (MGD) 的梯度优化方法。该方法包括一个高效计算 metagradients（通过模型训练的梯度）的算法，以及一个“smooth model training”框架，以实现有效的优化优化。实验结果显示，MGD 大大提升了数据集选择方法的性能，比现有数据中毒攻击防御高出一个数量级，并能自动生成竞争性的学习率调度。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13751v1",
      "published_date": "2025-03-17 22:18:24 UTC",
      "updated_date": "2025-03-17 22:18:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:55:01.999252"
    },
    {
      "arxiv_id": "2503.14552v1",
      "title": "Fire and Smoke Datasets in 20 Years: An In-depth Review",
      "title_zh": "过去20年的火灾和烟雾数据集：一项深入回顾",
      "authors": [
        "Sayed Pedram Haeri Boroujeni",
        "Niloufar Mehrabi",
        "Fatemeh Afghah",
        "Connor Peter McGrath",
        "Danish Bhatkar",
        "Mithilesh Anil Biradar",
        "Abolfazl Razi"
      ],
      "abstract": "Fire and smoke phenomena pose a significant threat to the natural\nenvironment, ecosystems, and global economy, as well as human lives and\nwildlife. In this particular circumstance, there is a demand for more\nsophisticated and advanced technologies to implement an effective strategy for\nearly detection, real-time monitoring, and minimizing the overall impacts of\nfires on ecological balance and public safety. Recently, the rapid advancement\nof Artificial Intelligence (AI) and Computer Vision (CV) frameworks has\nsubstantially revolutionized the momentum for developing efficient fire\nmanagement systems. However, these systems extensively rely on the availability\nof adequate and high-quality fire and smoke data to create proficient Machine\nLearning (ML) methods for various tasks, such as detection and monitoring.\nAlthough fire and smoke datasets play a critical role in training, evaluating,\nand testing advanced Deep Learning (DL) models, a comprehensive review of the\nexisting datasets is still unexplored. For this purpose, we provide an in-depth\nreview to systematically analyze and evaluate fire and smoke datasets collected\nover the past 20 years. We investigate the characteristics of each dataset,\nincluding type, size, format, collection methods, and geographical diversities.\nWe also review and highlight the unique features of each dataset, such as\nimaging modalities (RGB, thermal, infrared) and their applicability for\ndifferent fire management tasks (classification, segmentation, detection).\nFurthermore, we summarize the strengths and weaknesses of each dataset and\ndiscuss their potential for advancing research and technology in fire\nmanagement. Ultimately, we conduct extensive experimental analyses across\ndifferent datasets using several state-of-the-art algorithms, such as\nResNet-50, DeepLab-V3, and YoloV8.",
      "tldr_zh": "这篇论文对过去20年的火和烟雾数据集进行了深入综述，强调了这些数据集在AI和CV框架下开发高效火管理系统的关键作用，包括早期检测、实时监控和影响最小化。作者系统分析了各数据集的特征，如类型、大小、格式、收集方法、地理多样性，以及成像模式（RGB、thermal、infrared）的独特优势，并讨论了它们在分类、分割和检测任务中的适用性。最终，通过实验评估如ResNet-50、DeepLab-V3和YoloV8等先进算法的性能，论文总结了各数据集的优缺点，为推动火管理研究和技术进步提供了重要指导。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.14552v1",
      "published_date": "2025-03-17 22:08:02 UTC",
      "updated_date": "2025-03-17 22:08:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:55:14.347262"
    },
    {
      "arxiv_id": "2503.17391v1",
      "title": "AI-driven Automation of End-to-end Assessment of Suturing Expertise",
      "title_zh": "翻译失败",
      "authors": [
        "Atharva Deo",
        "Nicholas Matsumoto",
        "Sun Kim",
        "Peter Wager",
        "Randy G. Tsai",
        "Aaron Denmark",
        "Cherine Yang",
        "Xi Li",
        "Jay Moran",
        "Miguel Hernandez",
        "Andrew J. Hung"
      ],
      "abstract": "We present an AI based approach to automate the End-to-end Assessment of\nSuturing Expertise (EASE), a suturing skills assessment tool that\ncomprehensively defines criteria around relevant sub-skills.1 While EASE\nprovides granular skills assessment related to suturing to provide trainees\nwith an objective evaluation of their aptitude along with actionable insights,\nthe scoring process is currently performed by human evaluators, which is time\nand resource consuming. The AI based approach solves this by enabling real-time\nscore prediction with minimal resources during model inference. This enables\nthe possibility of real-time feedback to the surgeons/trainees, potentially\naccelerating the learning process for the suturing task and mitigating critical\nerrors during the surgery, improving patient outcomes. In this study, we focus\non the following 7 EASE domains that come under 3 suturing phases: 1) Needle\nHandling: Number of Repositions, Needle Hold Depth, Needle Hold Ratio, and\nNeedle Hold Angle; 2) Needle Driving: Driving Smoothness, and Wrist Rotation;\n3) Needle Withdrawal: Wrist Rotation.",
      "tldr_zh": "本研究提出了一种AI驱动的方法，用于自动化评估缝合技能的全面工具EASE，旨在取代耗时的人工评分过程，提供实时分数预测。该方法针对EASE的7个领域（包括针处理、针驱动和针撤回的子技能，如Number of Repositions、Needle Hold Depth等），利用AI技术在模型推理时最小化资源消耗，从而实现对外科医生或学员的即时反馈。这有助于加速缝合技能的学习，减少手术错误，并最终改善患者结果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17391v1",
      "published_date": "2025-03-17 21:28:02 UTC",
      "updated_date": "2025-03-17 21:28:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:55:24.803026"
    },
    {
      "arxiv_id": "2503.15549v1",
      "title": "Rendering Transparency to Ranking in Educational Assessment via Bayesian Comparative Judgement",
      "title_zh": "通过贝叶斯比较判断在教育评估中实现排名的透明度",
      "authors": [
        "Andy Gray",
        "Alma Rahat",
        "Stephen Lindsay",
        "Jen Pearson",
        "Tom Crick"
      ],
      "abstract": "Ensuring transparency in educational assessment is increasingly critical,\nparticularly post-pandemic, as demand grows for fairer and more reliable\nevaluation methods. Comparative Judgement (CJ) offers a promising alternative\nto traditional assessments, yet concerns remain about its perceived opacity.\nThis paper examines how Bayesian Comparative Judgement (BCJ) enhances\ntransparency by integrating prior information into the judgement process,\nproviding a structured, data-driven approach that improves interpretability and\naccountability.\n  BCJ assigns probabilities to judgement outcomes, offering quantifiable\nmeasures of uncertainty and deeper insights into decision confidence. By\nsystematically tracking how prior data and successive judgements inform final\nrankings, BCJ clarifies the assessment process and helps identify assessor\ndisagreements. Multi-criteria BCJ extends this by evaluating multiple learning\noutcomes (LOs) independently, preserving the richness of CJ while producing\ntransparent, granular rankings aligned with specific assessment goals. It also\nenables a holistic ranking derived from individual LOs, ensuring comprehensive\nevaluations without compromising detailed feedback.\n  Using a real higher education dataset with professional markers in the UK, we\ndemonstrate BCJ's quantitative rigour and ability to clarify ranking\nrationales. Through qualitative analysis and discussions with experienced CJ\npractitioners, we explore its effectiveness in contexts where transparency is\ncrucial, such as high-stakes national assessments. We highlight the benefits\nand limitations of BCJ, offering insights into its real-world application\nacross various educational settings.",
      "tldr_zh": "这篇论文探讨了Bayesian Comparative Judgement (BCJ)如何提升教育评估中的透明度，特别针对Comparative Judgement (CJ)的潜在不透明问题，通过整合先验信息提供结构化、数据驱动的判断过程。BCJ通过分配概率量化判断不确定性，追踪先验数据与判断如何影响最终排名，并通过Multi-criteria BCJ实现多学习成果的独立评估，生成细粒度的透明排名。利用英国高等教育真实数据集的实验结果证明了BCJ的定量严谨性，并在高风险评估情境中展示了其优势，同时讨论了实际应用的局限性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.IR"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15549v1",
      "published_date": "2025-03-17 20:56:55 UTC",
      "updated_date": "2025-03-17 20:56:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:55:38.086622"
    },
    {
      "arxiv_id": "2503.13708v1",
      "title": "A Circular Construction Product Ontology for End-of-Life Decision-Making",
      "title_zh": "翻译失败",
      "authors": [
        "Kwabena Adu-Duodu",
        "Stanly Wilson",
        "Yinhao Li",
        "Aanuoluwapo Oladimeji",
        "Talea Huraysi",
        "Masoud Barati",
        "Charith Perera",
        "Ellis Solaiman",
        "Omer Rana",
        "Rajiv Ranjan",
        "Tejal Shah"
      ],
      "abstract": "Efficient management of end-of-life (EoL) products is critical for advancing\ncircularity in supply chains, particularly within the construction industry\nwhere EoL strategies are hindered by heterogenous lifecycle data and data\nsilos. Current tools like Environmental Product Declarations (EPDs) and Digital\nProduct Passports (DPPs) are limited by their dependency on seamless data\nintegration and interoperability which remain significant challenges. To\naddress these, we present the Circular Construction Product Ontology (CCPO), an\napplied framework designed to overcome semantic and data heterogeneity\nchallenges in EoL decision-making for construction products. CCPO standardises\nvocabulary and facilitates data integration across supply chain stakeholders\nenabling lifecycle assessments (LCA) and robust decision-making. By aggregating\ndisparate data into a unified product provenance, CCPO enables automated EoL\nrecommendations through customisable SWRL rules aligned with European standards\nand stakeholder-specific circularity SLAs, demonstrating its scalability and\nintegration capabilities. The adopted circular product scenario depicts CCPO's\napplication while competency question evaluations show its superior performance\nin generating accurate EoL suggestions highlighting its potential to greatly\nimprove decision-making in circular supply chains and its applicability in\nreal-world construction environments.",
      "tldr_zh": "本研究针对建筑行业循环供应链中的生命周期末端（EoL）决策问题，提出 Circular Construction Product Ontology (CCPO) 框架，以解决数据异质性和孤岛问题，如 Environmental Product Declarations (EPDs) 和 Digital Product Passports (DPPs) 面临的互操作性挑战。CCPO 通过标准化词汇和数据整合，实现了跨供应链利益相关者的生命周期评估 (LCA)，并利用自定义 SWRL 规则生成自动化 EoL 推荐，符合欧洲标准和利益相关者特定的循环经济服务水平协议 (SLA)。实验结果显示，CCPO 在处理真实场景时表现出色，能准确生成 EoL 建议，从而显著提升循环供应链的决策效率和实际应用潜力。",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13708v1",
      "published_date": "2025-03-17 20:28:08 UTC",
      "updated_date": "2025-03-17 20:28:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:55:49.469151"
    },
    {
      "arxiv_id": "2503.13690v2",
      "title": "Atyaephyra at SemEval-2025 Task 4: Low-Rank Negative Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Bronec",
        "Jindřich Helcl"
      ],
      "abstract": "We present a submission to the SemEval 2025 shared task on unlearning\nsensitive content from LLMs. Our approach employs negative preference\noptimization using low-rank adaptation. We show that we can utilize this\ncombination to efficiently compute additional regularization terms, which help\nwith unlearning stabilization. The results of our approach significantly exceed\nthe shared task baselines.",
      "tldr_zh": "本论文提交了名为Atyaephyra的系统，针对SemEval-2025 Task 4的任务，即从大型语言模型(LLMs)中删除敏感内容，通过Low-Rank Negative Preference Optimization方法进行优化。该方法结合低秩适配(Low-Rank Adaptation)和负偏好优化，高效计算额外的正则化项，以增强取消学习的稳定性和效果。实验结果表明，该方法显著超过了共享任务的基线基准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50 (Primary), 68T07 (Secondary)",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 3 figures, accepted to SemEval workshop proceedings at ACL\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13690v2",
      "published_date": "2025-03-17 19:59:19 UTC",
      "updated_date": "2025-05-07 19:19:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:56:02.097321"
    },
    {
      "arxiv_id": "2503.14550v1",
      "title": "Novel AI-Based Quantification of Breast Arterial Calcification to Predict Cardiovascular Risk",
      "title_zh": "新型基于 AI 的乳房动脉钙化量化方法用于预测心血管风险",
      "authors": [
        "Theodorus Dapamede",
        "Aisha Urooj",
        "Vedant Joshi",
        "Gabrielle Gershon",
        "Frank Li",
        "Mohammadreza Chavoshi",
        "Beatrice Brown-Mulry",
        "Rohan Satya Isaac",
        "Aawez Mansuri",
        "Chad Robichaux",
        "Chadi Ayoub",
        "Reza Arsanjani",
        "Laurence Sperling",
        "Judy Gichoya",
        "Marly van Assen",
        "Charles W. ONeill",
        "Imon Banerjee",
        "Hari Trivedi"
      ],
      "abstract": "Women are underdiagnosed and undertreated for cardiovascular disease.\nAutomatic quantification of breast arterial calcification on screening\nmammography can identify women at risk for cardiovascular disease and enable\nearlier treatment and management of disease. In this retrospective study of\n116,135 women from two healthcare systems, a transformer-based neural network\nquantified BAC severity (no BAC, mild, moderate, and severe) on screening\nmammograms. Outcomes included major adverse cardiovascular events (MACE) and\nall-cause mortality. BAC severity was independently associated with MACE after\nadjusting for cardiovascular risk factors, with increasing hazard ratios from\nmild (HR 1.18-1.22), moderate (HR 1.38-1.47), to severe BAC (HR 2.03-2.22)\nacross datasets (all p<0.001). This association remained significant across all\nage groups, with even mild BAC indicating increased risk in women under 50. BAC\nremained an independent predictor when analyzed alongside ASCVD risk scores,\nshowing significant associations with myocardial infarction, stroke, heart\nfailure, and mortality (all p<0.005). Automated BAC quantification enables\nopportunistic cardiovascular risk assessment during routine mammography without\nadditional radiation or cost. This approach provides value beyond traditional\nrisk factors, particularly in younger women, offering potential for early CVD\nrisk stratification in the millions of women undergoing annual mammography.",
      "tldr_zh": "本研究开发了一种基于transformer神经网络的AI方法，用于自动量化乳房动脉钙化（BAC）的严重程度，以预测女性心血管疾病风险。研究分析了11万6千多名女性的筛查乳房X光片，发现BAC严重程度与主要不良心血管事件（MACE）和全因死亡率独立相关，轻度BAC的危险比（HR）为1.18-1.22，中度为1.38-1.47，重度为2.03-2.22（所有p<0.001），且这种关联在所有年龄组中显著，甚至适用于50岁以下女性。相比传统ASCVD风险评分，该方法在常规乳房X光检查中提供额外价值，能识别心肌梗死、中风、心力衰竭等风险，从而实现无额外辐射或成本的早期心血管风险分层。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.14550v1",
      "published_date": "2025-03-17 19:38:17 UTC",
      "updated_date": "2025-03-17 19:38:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:56:14.890800"
    },
    {
      "arxiv_id": "2503.14549v1",
      "title": "Sampling Decisions",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Chertkov",
        "Sungsoo Ahn",
        "Hamidreza Behjoo"
      ],
      "abstract": "In this manuscript we introduce a novel Decision Flow (DF) framework for\nsampling from a target distribution while incorporating additional guidance\nfrom a prior sampler. DF can be viewed as an AI driven algorithmic\nreincarnation of the Markov Decision Process (MDP) approach in Stochastic\nOptimal Control. It extends the continuous space, continuous time path Integral\nDiffusion sampling technique to discrete time and space, while also\ngeneralizing the Generative Flow Network framework. In its most basic form, an\nexplicit, Neural Network (NN) free formulation, DF leverages the linear\nsolvability of the the underlying MDP to adjust the transition probabilities of\nthe prior sampler. The resulting Markov Process is expressed as a convolution\nof the reverse time Green's function of the prior sampling with the target\ndistribution. We illustrate the DF framework through an example of sampling\nfrom the Ising model, discuss potential NN based extensions, and outline how DF\ncan enhance guided sampling across various applications.",
      "tldr_zh": "该论文引入了 Decision Flow (DF) 框架，这是一种新方法，用于从目标分布采样，同时整合先验采样的额外指导。DF 可以视为 Markov Decision Process (MDP) 在 Stochastic Optimal Control 中的 AI 驱动扩展，将连续空间、连续时间的 Path Integral Diffusion 采样技术推广到离散时间和空间，并泛化了 Generative Flow Network 框架。在其基本形式中，DF 通过 MDP 的线性可解性调整先验采样的转移概率，结果形成一个 Markov 过程，该过程表示为先验采样的逆时间 Green's function 与目标分布的卷积。论文通过 Ising 模型示例进行了说明，并讨论了基于 Neural Network (NN) 的潜在扩展，以及 DF 在各种应用中增强引导采样的潜力。",
      "categories": [
        "cs.LG",
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.14549v1",
      "published_date": "2025-03-17 19:32:22 UTC",
      "updated_date": "2025-03-17 19:32:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:56:26.556934"
    },
    {
      "arxiv_id": "2503.13660v1",
      "title": "INPROVF: Leveraging Large Language Models to Repair High-level Robot Controllers from Assumption Violations",
      "title_zh": "翻译失败",
      "authors": [
        "Qian Meng",
        "Jin Peng Zhou",
        "Kilian Q. Weinberger",
        "Hadas Kress-Gazit"
      ],
      "abstract": "This paper presents INPROVF, an automatic framework that combines large\nlanguage models (LLMs) and formal methods to speed up the repair process of\nhigh-level robot controllers. Previous approaches based solely on formal\nmethods are computationally expensive and cannot scale to large state spaces.\nIn contrast, INPROVF uses LLMs to generate repair candidates, and formal\nmethods to verify their correctness. To improve the quality of these\ncandidates, our framework first translates the symbolic representations of the\nenvironment and controllers into natural language descriptions. If a candidate\nfails the verification, INPROVF provides feedback on potential unsafe behaviors\nor unsatisfied tasks, and iteratively prompts LLMs to generate improved\nsolutions. We demonstrate the effectiveness of INPROVF through 12 violations\nwith various workspaces, tasks, and state space sizes.",
      "tldr_zh": "本论文提出 INPROVF 框架，利用大型语言模型 (LLMs) 和形式化方法，自动加速修复高层次机器人控制器的假设违反问题，以解决传统形式化方法在大型状态空间下的计算开销问题。框架首先将环境和控制器的符号表示翻译成自然语言描述，由 LLMs 生成修复候选，并通过形式化方法验证其正确性；如果候选失败，则提供反馈并迭代提示 LLMs 改进方案。实验在 12 个涉及不同工作空间、任务和状态空间大小的违反场景中验证了 INPROVF 的有效性，显著提升了修复过程的效率和可扩展性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.FL",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "To appear in ICLR 2025 Workshop: VerifAI: AI Verification in the\n  Wild; in submission to 2025 IEEE 21th International Conference on Automation\n  Science and Engineering (CASE), Los Angeles, CA, USA: IEEE, Aug. 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13660v1",
      "published_date": "2025-03-17 19:08:36 UTC",
      "updated_date": "2025-03-17 19:08:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:56:38.546195"
    },
    {
      "arxiv_id": "2503.13657v2",
      "title": "Why Do Multi-Agent LLM Systems Fail?",
      "title_zh": "翻译失败",
      "authors": [
        "Mert Cemri",
        "Melissa Z. Pan",
        "Shuyi Yang",
        "Lakshya A. Agrawal",
        "Bhavya Chopra",
        "Rishabh Tiwari",
        "Kurt Keutzer",
        "Aditya Parameswaran",
        "Dan Klein",
        "Kannan Ramchandran",
        "Matei Zaharia",
        "Joseph E. Gonzalez",
        "Ion Stoica"
      ],
      "abstract": "Despite growing enthusiasm for Multi-Agent LLM Systems (MAS), their\nperformance gains on popular benchmarks often remain minimal compared with\nsingle-agent frameworks. This gap highlights the need to systematically analyze\nthe challenges hindering MAS effectiveness.\n  We present MAST (Multi-Agent System Failure Taxonomy), the first empirically\ngrounded taxonomy designed to understand MAS failures. We analyze seven popular\nMAS frameworks across over 200 tasks, involving six expert human annotators.\nThrough this process, we identify 14 unique failure modes, organized into 3\noverarching categories, (i) specification issues, (ii) inter-agent\nmisalignment, and (iii) task verification. MAST emerges iteratively from\nrigorous inter-annotator agreement studies, achieving a Cohen's Kappa score of\n0.88. To support scalable evaluation, we develop a validated LLM-as-a-Judge\npipeline integrated with MAST. We leverage two case studies to demonstrate\nMAST's practical utility in analyzing failures and guiding MAS development. Our\nfindings reveal that identified failures require more complex solutions,\nhighlighting a clear roadmap for future research. We open source our\ncomprehensive dataset and LLM annotator to facilitate further development of\nMAS.",
      "tldr_zh": "本文探讨了Multi-Agent LLM Systems (MAS) 为什么在基准测试中性能提升有限的问题，并提出了MAST（Multi-Agent System Failure Taxonomy），这是首个基于经验的失败分类法。研究团队分析了7个流行MAS框架，在超过200个任务上进行评估，识别出14种独特的失败模式，分为三类：规范问题、智能体间不对齐和任务验证，并通过Cohen's Kappa分数0.88的注释者一致性确保分类可靠性。为支持可扩展评估，他们开发了LLM-as-a-Judge管道，并通过两个案例研究展示了MAST在分析失败和指导MAS开发方面的实用价值，最终开源数据集和工具，为未来研究提供清晰路线图。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ArXiv v2",
      "pdf_url": "http://arxiv.org/pdf/2503.13657v2",
      "published_date": "2025-03-17 19:04:38 UTC",
      "updated_date": "2025-04-22 18:37:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:56:51.044683"
    },
    {
      "arxiv_id": "2503.13621v1",
      "title": "Superalignment with Dynamic Human Values",
      "title_zh": "翻译失败",
      "authors": [
        "Florian Mai",
        "David Kaczér",
        "Nicholas Kluge Corrêa",
        "Lucie Flek"
      ],
      "abstract": "Two core challenges of alignment are 1) scalable oversight and 2) accounting\nfor the dynamic nature of human values. While solutions like recursive reward\nmodeling address 1), they do not simultaneously account for 2). We sketch a\nroadmap for a novel algorithmic framework that trains a superhuman reasoning\nmodel to decompose complex tasks into subtasks that are still amenable to\nhuman-level guidance. Our approach relies on what we call the part-to-complete\ngeneralization hypothesis, which states that the alignment of subtask solutions\ngeneralizes to the alignment of complete solutions. We advocate for the need to\nmeasure this generalization and propose ways to improve it in the future.",
      "tldr_zh": "该论文探讨了AI对齐（alignment）中的两大核心挑战：可扩展监督（scalable oversight）和人类价值观的动态性质（dynamic nature of human values）。作者提出一个新算法框架，通过训练一个超人级推理模型（superhuman reasoning model）将复杂任务分解为可由人类指导的子任务，从而同时解决这些挑战。该框架依赖于“part-to-complete generalization hypothesis”，即子任务解决方案的对齐能推广到完整解决方案，并建议测量和改进这种泛化以提升未来AI对齐效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at the ICLR 2025 Workshop on Bidirectional Human-AI\n  Alignment (BiAlign)",
      "pdf_url": "http://arxiv.org/pdf/2503.13621v1",
      "published_date": "2025-03-17 18:15:17 UTC",
      "updated_date": "2025-03-17 18:15:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:57:01.520870"
    },
    {
      "arxiv_id": "2503.13447v1",
      "title": "MetaScale: Test-Time Scaling with Evolving Meta-Thoughts",
      "title_zh": "翻译失败",
      "authors": [
        "Qin Liu",
        "Wenxuan Zhou",
        "Nan Xu",
        "James Y. Huang",
        "Fei Wang",
        "Sheng Zhang",
        "Hoifung Poon",
        "Muhao Chen"
      ],
      "abstract": "One critical challenge for large language models (LLMs) for making complex\nreasoning is their reliance on matching reasoning patterns from training data,\ninstead of proactively selecting the most appropriate cognitive strategy to\nsolve a given task. Existing approaches impose fixed cognitive structures that\nenhance performance in specific tasks but lack adaptability across diverse\nscenarios. To address this limitation, we introduce METASCALE, a test-time\nscaling framework based on meta-thoughts -- adaptive thinking strategies\ntailored to each task. METASCALE initializes a pool of candidate meta-thoughts,\nthen iteratively selects and evaluates them using a multi-armed bandit\nalgorithm with upper confidence bound selection, guided by a reward model. To\nfurther enhance adaptability, a genetic algorithm evolves high-reward\nmeta-thoughts, refining and extending the strategy pool over time. By\ndynamically proposing and optimizing meta-thoughts at inference time, METASCALE\nimproves both accuracy and generalization across a wide range of tasks.\nExperimental results demonstrate that MetaScale consistently outperforms\nstandard inference approaches, achieving an 11% performance gain in win rate on\nArena-Hard for GPT-4o, surpassing o1-mini by 0.9% under style control. Notably,\nMETASCALE scales more effectively with increasing sampling budgets and produces\nmore structured, expert-level responses.",
      "tldr_zh": "该研究提出 METASCALE，一种基于演化 meta-thoughts 的测试时缩放框架，旨在解决大型语言模型(LLMs)在复杂推理中过度依赖训练数据模式的问题，从而提升模型的自适应性。METASCALE 通过初始化候选 meta-thoughts 池，并使用 multi-armed bandit algorithm 结合上置信界选择和奖励模型进行迭代选择和评估，同时借助 genetic algorithm 演化高奖励策略，进一步优化思考策略池。实验结果显示，METASCALE 显著提升性能，在 Arena-Hard 任务上使 GPT-4o 的胜率提高 11%，并在风格控制下超过 o1-mini 0.9%；此外，该框架在增加采样预算时扩展更高效，并生成更结构化的专家级响应。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.13447v1",
      "published_date": "2025-03-17 17:59:54 UTC",
      "updated_date": "2025-03-17 17:59:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:57:14.712455"
    },
    {
      "arxiv_id": "2503.13445v1",
      "title": "Faithfulness of LLM Self-Explanations for Commonsense Tasks: Larger Is Better, and Instruction-Tuning Allows Trade-Offs but Not Pareto Dominance",
      "title_zh": "LLM 自解释的忠实度在常识任务中的表现：更大更优，且",
      "authors": [
        "Noah Y. Siegel",
        "Nicolas Heess",
        "Maria Perez-Ortiz",
        "Oana-Maria Camburu"
      ],
      "abstract": "As large language models (LLMs) become increasingly capable, ensuring that\ntheir self-generated explanations are faithful to their internal\ndecision-making process is critical for safety and oversight. In this work, we\nconduct a comprehensive counterfactual faithfulness analysis across 62 models\nfrom 8 families, encompassing both pretrained and instruction-tuned variants\nand significantly extending prior studies of counterfactual tests. We introduce\nphi-CCT, a simplified variant of the Correlational Counterfactual Test, which\navoids the need for token probabilities while explaining most of the variance\nof the original test. Our findings reveal clear scaling trends: larger models\nare consistently more faithful on our metrics. However, when comparing\ninstruction-tuned and human-imitated explanations, we find that observed\ndifferences in faithfulness can often be attributed to explanation verbosity,\nleading to shifts along the true-positive/false-positive Pareto frontier. While\ninstruction-tuning and prompting can influence this trade-off, we find limited\nevidence that they fundamentally expand the frontier of explanatory\nfaithfulness beyond what is achievable with pretrained models of comparable\nsize. Our analysis highlights the nuanced relationship between\ninstruction-tuning, verbosity, and the faithful representation of model\ndecision processes.",
      "tldr_zh": "本研究评估了大型语言模型 (LLMs) 在常识任务中自生成解释的忠实性，通过对62个模型（来自8个家族，包括预训练和instruction-tuning变体）进行全面反事实分析。研究引入了phi-CCT，一种简化版的Correlational Counterfactual Test，能有效捕捉解释方差，而无需依赖token概率。结果显示，模型规模越大，解释忠实性越强；然而，instruction-tuning会影响解释的冗长，导致在真阳性/假阳性Pareto前沿上的权衡，但未扩展这一前沿超越同等规模预训练模型。总体而言，该分析揭示了instruction-tuning、冗长与模型决策过程忠实表示之间的复杂关系。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "38 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13445v1",
      "published_date": "2025-03-17 17:59:39 UTC",
      "updated_date": "2025-03-17 17:59:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:57:26.267322"
    },
    {
      "arxiv_id": "2503.13444v2",
      "title": "VideoMind: A Chain-of-LoRA Agent for Long Video Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Liu",
        "Kevin Qinghong Lin",
        "Chang Wen Chen",
        "Mike Zheng Shou"
      ],
      "abstract": "Videos, with their unique temporal dimension, demand precise grounded\nunderstanding, where answers are directly linked to visual, interpretable\nevidence. Despite significant breakthroughs in reasoning capabilities within\nLarge Language Models, multi-modal reasoning - especially for videos - remains\nunexplored. In this work, we introduce VideoMind, a novel video-language agent\ndesigned for temporal-grounded video understanding. VideoMind incorporates two\nkey innovations: (i) We identify essential capabilities for video temporal\nreasoning and develop a role-based agentic workflow, including a planner for\ncoordinating different roles, a grounder for temporal localization, a verifier\nto assess temporal interval accuracy, and an answerer for question-answering.\n(ii) To efficiently integrate these diverse roles, we propose a novel\nChain-of-LoRA strategy, enabling seamless role-switching via lightweight LoRA\nadaptors while avoiding the overhead of multiple models, thus balancing\nefficiency and flexibility. Extensive experiments on 14 public benchmarks,\nincluding 3 on grounded video question-answering (Grounded VideoQA), 6 on video\ntemporal grounding (VTG), and 5 on general video question-answering (VideoQA),\nverify that our agent achieves state-of-the-art performance on diverse video\nunderstanding tasks, underscoring its effectiveness in advancing video agent\nand long-form temporal reasoning.",
      "tldr_zh": "本研究提出VideoMind，一种新型视频-语言代理，用于处理长视频的时间定位理解，通过将答案直接链接到视觉证据来提升精确性。VideoMind的关键创新包括开发基于角色的代理工作流（如规划器、定位器、验证器和回答器）以协调视频时间推理，以及Chain-of-LoRA策略，利用轻量级LoRA适配器实现角色无缝切换，提高效率并避免多模型开销。在14个公共基准测试中，包括Grounded VideoQA、VTG和VideoQA，VideoMind在各种视频理解任务上实现了最先进性能，推进了视频代理和长序列时间推理的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://videomind.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2503.13444v2",
      "published_date": "2025-03-17 17:59:33 UTC",
      "updated_date": "2025-04-01 03:49:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:57:37.669066"
    },
    {
      "arxiv_id": "2503.13441v2",
      "title": "Humanoid Policy ~ Human Policy",
      "title_zh": "翻译失败",
      "authors": [
        "Ri-Zhao Qiu",
        "Shiqi Yang",
        "Xuxin Cheng",
        "Chaitanya Chawla",
        "Jialong Li",
        "Tairan He",
        "Ge Yan",
        "David J. Yoon",
        "Ryan Hoque",
        "Lars Paulsen",
        "Ge Yang",
        "Jian Zhang",
        "Sha Yi",
        "Guanya Shi",
        "Xiaolong Wang"
      ],
      "abstract": "Training manipulation policies for humanoid robots with diverse data enhances\ntheir robustness and generalization across tasks and platforms. However,\nlearning solely from robot demonstrations is labor-intensive, requiring\nexpensive tele-operated data collection which is difficult to scale. This paper\ninvestigates a more scalable data source, egocentric human demonstrations, to\nserve as cross-embodiment training data for robot learning. We mitigate the\nembodiment gap between humanoids and humans from both the data and modeling\nperspectives. We collect an egocentric task-oriented dataset (PH2D) that is\ndirectly aligned with humanoid manipulation demonstrations. We then train a\nhuman-humanoid behavior policy, which we term Human Action Transformer (HAT).\nThe state-action space of HAT is unified for both humans and humanoid robots\nand can be differentiably retargeted to robot actions. Co-trained with\nsmaller-scale robot data, HAT directly models humanoid robots and humans as\ndifferent embodiments without additional supervision. We show that human data\nimproves both generalization and robustness of HAT with significantly better\ndata collection efficiency. Code and data: https://human-as-robot.github.io/",
      "tldr_zh": "该论文探讨了使用自我中心人类演示（egocentric human demonstrations）作为数据源来训练人形机器人操作策略，以解决传统机器人演示数据收集耗时且不易扩展的问题。研究者收集了PH2D数据集，并开发了Human Action Transformer (HAT)模型，该模型统一了人类和机器人状态-动作空间，并通过可微分重定向实现跨形态适应。实验结果显示，与仅使用机器人数据相比，结合人类数据训练的HAT显著提高了策略的泛化性和鲁棒性，同时大幅提升了数据收集效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Code and data: https://human-as-robot.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2503.13441v2",
      "published_date": "2025-03-17 17:59:09 UTC",
      "updated_date": "2025-03-24 08:31:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:57:50.431022"
    },
    {
      "arxiv_id": "2503.13438v1",
      "title": "Deep Belief Markov Models for POMDP Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Giacomo Arcieri",
        "Konstantinos G. Papakonstantinou",
        "Daniel Straub",
        "Eleni Chatzi"
      ],
      "abstract": "This work introduces a novel deep learning-based architecture, termed the\nDeep Belief Markov Model (DBMM), which provides efficient, model-formulation\nagnostic inference in Partially Observable Markov Decision Process (POMDP)\nproblems. The POMDP framework allows for modeling and solving sequential\ndecision-making problems under observation uncertainty. In complex,\nhigh-dimensional, partially observable environments, existing methods for\ninference based on exact computations (e.g., via Bayes' theorem) or sampling\nalgorithms do not scale well. Furthermore, ground truth states may not be\navailable for learning the exact transition dynamics. DBMMs extend deep Markov\nmodels into the partially observable decision-making framework and allow\nefficient belief inference entirely based on available observation data via\nvariational inference methods. By leveraging the potency of neural networks,\nDBMMs can infer and simulate non-linear relationships in the system dynamics\nand naturally scale to problems with high dimensionality and discrete or\ncontinuous variables. In addition, neural network parameters can be dynamically\nupdated efficiently based on data availability. DBMMs can thus be used to infer\na belief variable, thus enabling the derivation of POMDP solutions over the\nbelief space. We evaluate the efficacy of the proposed methodology by\nevaluating the capability of model-formulation agnostic inference of DBMMs in\nbenchmark problems that include discrete and continuous variables.",
      "tldr_zh": "本文提出了一种新型深度学习架构，名为 Deep Belief Markov Model (DBMM)，用于在 Partially Observable Markov Decision Process (POMDP) 问题中实现高效且独立于模型公式化的推理。DBMM 通过扩展深层马尔可夫模型，并采用 variational inference 方法，仅基于可用观察数据进行信念变量的推断，从而处理复杂高维环境中的非线性系统动态。相比传统精确计算或采样算法，DBMM 能更好地适应离散或连续变量，并动态更新神经网络参数以提升灵活性。在基准问题实验中，DBMM 展示了出色的推理能力，为 POMDP 解决方案在信念空间的推导提供了可靠基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13438v1",
      "published_date": "2025-03-17 17:58:45 UTC",
      "updated_date": "2025-03-17 17:58:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:58:03.669423"
    },
    {
      "arxiv_id": "2503.13434v1",
      "title": "BlobCtrl: A Unified and Flexible Framework for Element-level Image Generation and Editing",
      "title_zh": "BlobCtrl：一种统一且灵活的框架，用于元素级图像生成和编辑",
      "authors": [
        "Yaowei Li",
        "Lingen Li",
        "Zhaoyang Zhang",
        "Xiaoyu Li",
        "Guangzhi Wang",
        "Hongxiang Li",
        "Xiaodong Cun",
        "Ying Shan",
        "Yuexian Zou"
      ],
      "abstract": "Element-level visual manipulation is essential in digital content creation,\nbut current diffusion-based methods lack the precision and flexibility of\ntraditional tools. In this work, we introduce BlobCtrl, a framework that\nunifies element-level generation and editing using a probabilistic blob-based\nrepresentation. By employing blobs as visual primitives, our approach\neffectively decouples and represents spatial location, semantic content, and\nidentity information, enabling precise element-level manipulation. Our key\ncontributions include: 1) a dual-branch diffusion architecture with\nhierarchical feature fusion for seamless foreground-background integration; 2)\na self-supervised training paradigm with tailored data augmentation and score\nfunctions; and 3) controllable dropout strategies to balance fidelity and\ndiversity. To support further research, we introduce BlobData for large-scale\ntraining and BlobBench for systematic evaluation. Experiments show that\nBlobCtrl excels in various element-level manipulation tasks while maintaining\ncomputational efficiency, offering a practical solution for precise and\nflexible visual content creation. Project page:\nhttps://liyaowei-stu.github.io/project/BlobCtrl/",
      "tldr_zh": "该研究提出 BlobCtrl 框架，一种统一且灵活的系统，用于元素级图像生成和编辑，通过 probabilistic blob-based representation 作为视觉基元来解耦空间位置、语义内容和身份信息。关键贡献包括双分支扩散架构（dual-branch diffusion architecture）结合层次化特征融合，实现无缝的前景-背景整合；自我监督训练范式（self-supervised training paradigm）以及可控 dropout 策略，以平衡图像保真度和多样性。该框架还引入 BlobData 用于大规模训练和 BlobBench 用于系统评估，实验显示 BlobCtrl 在各种元素级操作任务中显著优于基线模型，同时保持计算效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Webpage: https://liyaowei-stu.github.io/project/BlobCtrl/",
      "pdf_url": "http://arxiv.org/pdf/2503.13434v1",
      "published_date": "2025-03-17 17:58:05 UTC",
      "updated_date": "2025-03-17 17:58:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:58:15.431039"
    },
    {
      "arxiv_id": "2503.17388v1",
      "title": "AI Companies Should Report Pre- and Post-Mitigation Safety Evaluations",
      "title_zh": "翻译失败",
      "authors": [
        "Dillon Bowen",
        "Ann-Kathrin Dombrowski",
        "Adam Gleave",
        "Chris Cundy"
      ],
      "abstract": "The rapid advancement of AI systems has raised widespread concerns about\npotential harms of frontier AI systems and the need for responsible evaluation\nand oversight. In this position paper, we argue that frontier AI companies\nshould report both pre- and post-mitigation safety evaluations to enable\ninformed policy decisions. Evaluating models at both stages provides\npolicymakers with essential evidence to regulate deployment, access, and safety\nstandards. We show that relying on either in isolation can create a misleading\npicture of model safety. Our analysis of AI safety disclosures from leading\nfrontier labs identifies three critical gaps: (1) companies rarely evaluate\nboth pre- and post-mitigation versions, (2) evaluation methods lack\nstandardization, and (3) reported results are often too vague to inform policy.\nTo address these issues, we recommend mandatory disclosure of pre- and\npost-mitigation capabilities to approved government bodies, standardized\nevaluation methods, and minimum transparency requirements for public safety\nreporting. These ensure that policymakers and regulators can craft targeted\nsafety measures, assess deployment risks, and scrutinize companies' safety\nclaims effectively.",
      "tldr_zh": "该论文主张 frontier AI 公司应报告 AI 模型的 pre- and post-mitigation safety evaluations，以提供政策决策所需证据，从而更好地监管模型部署和安全标准。作者分析了领先实验室的 AI 安全披露，发现三个关键问题：公司很少评估缓解前后版本、评价方法缺乏标准化，以及报告结果过于模糊，导致对模型安全的评估可能误导。仅依赖单一阶段评估会产生片面认识，因此论文推荐强制向政府机构披露相关能力、采用标准化评价方法，并设置最低透明度要求，以帮助政策制定者评估风险并审查公司声明。最终，这有助于制定针对性的安全措施，提升 AI 领域的可信监管。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17388v1",
      "published_date": "2025-03-17 17:56:43 UTC",
      "updated_date": "2025-03-17 17:56:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:58:25.932063"
    },
    {
      "arxiv_id": "2503.13430v1",
      "title": "AugMapNet: Improving Spatial Latent Structure via BEV Grid Augmentation for Enhanced Vectorized Online HD Map Construction",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Monninger",
        "Md Zafar Anwar",
        "Stanislaw Antol",
        "Steffen Staab",
        "Sihao Ding"
      ],
      "abstract": "Autonomous driving requires an understanding of the infrastructure elements,\nsuch as lanes and crosswalks. To navigate safely, this understanding must be\nderived from sensor data in real-time and needs to be represented in vectorized\nform. Learned Bird's-Eye View (BEV) encoders are commonly used to combine a set\nof camera images from multiple views into one joint latent BEV grid.\nTraditionally, from this latent space, an intermediate raster map is predicted,\nproviding dense spatial supervision but requiring post-processing into the\ndesired vectorized form. More recent models directly derive infrastructure\nelements as polylines using vectorized map decoders, providing instance-level\ninformation. Our approach, Augmentation Map Network (AugMapNet), proposes\nlatent BEV grid augmentation, a novel technique that significantly enhances the\nlatent BEV representation. AugMapNet combines vector decoding and dense spatial\nsupervision more effectively than existing architectures while remaining as\nstraightforward to integrate and as generic as auxiliary supervision.\nExperiments on nuScenes and Argoverse2 datasets demonstrate significant\nimprovements in vectorized map prediction performance up to 13.3% over the\nStreamMapNet baseline on 60m range and greater improvements on larger ranges.\nWe confirm transferability by applying our method to another baseline and find\nsimilar improvements. A detailed analysis of the latent BEV grid confirms a\nmore structured latent space of AugMapNet and shows the value of our novel\nconcept beyond pure performance improvement. The code will be released soon.",
      "tldr_zh": "该论文提出 AugMapNet，一种新型框架，通过 BEV Grid Augmentation 技术增强潜在 BEV 表示，以改善自动驾驶中从多相机图像实时构建矢量化高清地图的性能。AugMapNet 有效结合矢量化解码和密集空间监督，相比传统方法更易集成并提供实例级信息。在 nuScenes 和 Argoverse2 数据集上的实验显示，其在 60m 范围内比 StreamMapNet 基线提升 13.3%，在更大范围内表现更优。分析进一步证实，AugMapNet 的潜在空间更结构化，提升了地图预测的准确性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13430v1",
      "published_date": "2025-03-17 17:55:32 UTC",
      "updated_date": "2025-03-17 17:55:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:58:38.707817"
    },
    {
      "arxiv_id": "2503.13427v1",
      "title": "xLSTM 7B: A Recurrent LLM for Fast and Efficient Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Maximilian Beck",
        "Korbinian Pöppel",
        "Phillip Lippe",
        "Richard Kurle",
        "Patrick M. Blies",
        "Günter Klambauer",
        "Sebastian Böck",
        "Sepp Hochreiter"
      ],
      "abstract": "Recent breakthroughs in solving reasoning, math and coding problems with\nLarge Language Models (LLMs) have been enabled by investing substantial\ncomputation budgets at inference time. Therefore, inference speed is one of the\nmost critical properties of LLM architectures, and there is a growing need for\nLLMs that are efficient and fast at inference. Recently, LLMs built on the\nxLSTM architecture have emerged as a powerful alternative to Transformers,\noffering linear compute scaling with sequence length and constant memory usage,\nboth highly desirable properties for efficient inference. However, such\nxLSTM-based LLMs have yet to be scaled to larger models and assessed and\ncompared with respect to inference speed and efficiency. In this work, we\nintroduce xLSTM 7B, a 7-billion-parameter LLM that combines xLSTM's\narchitectural benefits with targeted optimizations for fast and efficient\ninference. Our experiments demonstrate that xLSTM 7B achieves performance on\ndownstream tasks comparable to other similar-sized LLMs, while providing\nsignificantly faster inference speeds and greater efficiency compared to Llama-\nand Mamba-based LLMs. These results establish xLSTM 7B as the fastest and most\nefficient 7B LLM, offering a solution for tasks that require large amounts of\ntest-time computation. Our work highlights xLSTM's potential as a foundational\narchitecture for methods building on heavy use of LLM inference. Our model\nweights, model code and training code are open-source.",
      "tldr_zh": "这篇论文介绍了xLSTM 7B，一种基于xLSTM架构的7亿参数LLM（Large Language Models），旨在通过线性计算缩放和恒定内存使用来实现快速高效的推理。研究团队针对推理速度进行了优化，使xLSTM 7B在下游任务（如推理、数学和编码问题）上性能与同规模LLM相当，但比Llama和Mamba-based LLMs推理速度更快、更高效。实验结果显示，xLSTM 7B成为最快的7B LLM，特别适合需要大量测试时计算的任务，并开源了模型权重和代码以推动进一步发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Code available at: https://github.com/NX-AI/xlstm and\n  https://github.com/NX-AI/xlstm-jax",
      "pdf_url": "http://arxiv.org/pdf/2503.13427v1",
      "published_date": "2025-03-17 17:54:55 UTC",
      "updated_date": "2025-03-17 17:54:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:58:50.740721"
    },
    {
      "arxiv_id": "2503.13419v1",
      "title": "Securing Virtual Reality Experiences: Unveiling and Tackling Cybersickness Attacks with Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Ripan Kumar Kundu",
        "Matthew Denton",
        "Genova Mongalo",
        "Prasad Calyam",
        "Khaza Anuarul Hoque"
      ],
      "abstract": "The synergy between virtual reality (VR) and artificial intelligence (AI),\nspecifically deep learning (DL)-based cybersickness detection models, has\nushered in unprecedented advancements in immersive experiences by automatically\ndetecting cybersickness severity and adaptively various mitigation techniques,\noffering a smooth and comfortable VR experience. While this DL-enabled\ncybersickness detection method provides promising solutions for enhancing user\nexperiences, it also introduces new risks since these models are vulnerable to\nadversarial attacks; a small perturbation of the input data that is visually\nundetectable to human observers can fool the cybersickness detection model and\ntrigger unexpected mitigation, thus disrupting user immersive experiences (UIX)\nand even posing safety risks. In this paper, we present a new type of VR\nattack, i.e., a cybersickness attack, which successfully stops the triggering\nof cybersickness mitigation by fooling DL-based cybersickness detection models\nand dramatically hinders the UIX. Next, we propose a novel explainable\nartificial intelligence (XAI)-guided cybersickness attack detection framework\nto detect such attacks in VR to ensure UIX and a comfortable VR experience. We\nevaluate the proposed attack and the detection framework using two\nstate-of-the-art open-source VR cybersickness datasets: Simulation 2021 and\nGameplay dataset. Finally, to verify the effectiveness of our proposed method,\nwe implement the attack and the XAI-based detection using a testbed with a\ncustom-built VR roller coaster simulation with an HTC Vive Pro Eye headset and\nperform a user study. Our study shows that such an attack can dramatically\nhinder the UIX. However, our proposed XAI-guided cybersickness attack detection\ncan successfully detect cybersickness attacks and trigger the proper\nmitigation, effectively reducing VR cybersickness.",
      "tldr_zh": "这篇论文探讨了虚拟现实 (VR) 中基于深度学习 (DL) 的 cybersickness 检测模型面临的 adversarial attacks 风险，这些攻击可以通过微小不易察觉的输入扰动来欺骗模型，阻止 cybersickness 缓解措施，从而破坏用户沉浸体验 (UIX) 并带来安全隐患。论文首次定义并演示了 cybersickness attack，这种攻击能显著阻碍 DL 模型的性能。针对此问题，研究团队提出了一种新型 explainable artificial intelligence (XAI)-guided 检测框架，用于实时识别攻击并触发适当的缓解策略。在实验中，使用 Simulation 2021 和 Gameplay 数据集进行评估，并通过自定义 VR 测试床的用户研究证实，该攻击会严重影响 UIX，但 XAI 框架能有效检测攻击并降低 cybersickness 风险。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.CR",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2503.13419v1",
      "published_date": "2025-03-17 17:49:51 UTC",
      "updated_date": "2025-03-17 17:49:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:59:02.664393"
    },
    {
      "arxiv_id": "2503.13418v1",
      "title": "FLEX: A Framework for Learning Robot-Agnostic Force-based Skills Involving Sustained Contact Object Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Shijie Fang",
        "Wenchang Gao",
        "Shivam Goel",
        "Christopher Thierauf",
        "Matthias Scheutz",
        "Jivko Sinapov"
      ],
      "abstract": "Learning to manipulate objects efficiently, particularly those involving\nsustained contact (e.g., pushing, sliding) and articulated parts (e.g.,\ndrawers, doors), presents significant challenges. Traditional methods, such as\nrobot-centric reinforcement learning (RL), imitation learning, and hybrid\ntechniques, require massive training and often struggle to generalize across\ndifferent objects and robot platforms. We propose a novel framework for\nlearning object-centric manipulation policies in force space, decoupling the\nrobot from the object. By directly applying forces to selected regions of the\nobject, our method simplifies the action space, reduces unnecessary\nexploration, and decreases simulation overhead. This approach, trained in\nsimulation on a small set of representative objects, captures object dynamics\n-- such as joint configurations -- allowing policies to generalize effectively\nto new, unseen objects. Decoupling these policies from robot-specific dynamics\nenables direct transfer to different robotic platforms (e.g., Kinova, Panda,\nUR5) without retraining. Our evaluations demonstrate that the method\nsignificantly outperforms baselines, achieving over an order of magnitude\nimprovement in training efficiency compared to other state-of-the-art methods.\nAdditionally, operating in force space enhances policy transferability across\ndiverse robot platforms and object types. We further showcase the applicability\nof our method in a real-world robotic setting. For supplementary materials and\nvideos, please visit: https://tufts-ai-robotics-group.github.io/FLEX/",
      "tldr_zh": "本文提出FLEX框架，用于在力空间中学习机器人无关的操纵技能，针对涉及持续接触（如pushing、sliding）和关节部件（如drawers、doors）的物体。该框架通过直接对物体特定区域施加力，解耦机器人与物体动态，简化动作空间、减少探索和模拟开销，并在模拟环境中训练一小套物体以捕获其动态，实现对新物体的有效泛化。实验结果显示，FLEX比传统方法如reinforcement learning (RL)和imitation learning显著提升训练效率（提高一个数量级），并成功转移到不同机器人平台（如Kinova、Panda、UR5），证明其在真实世界机器人设置中的适用性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at IEEE-ICRA-2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13418v1",
      "published_date": "2025-03-17 17:49:47 UTC",
      "updated_date": "2025-03-17 17:49:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:59:15.067506"
    },
    {
      "arxiv_id": "2503.13415v1",
      "title": "A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives",
      "title_zh": "多智能体合作决策的全面调查：场景、方法、挑战和展望",
      "authors": [
        "Weiqiang Jin",
        "Hongyang Du",
        "Biao Zhao",
        "Xingwu Tian",
        "Bohang Shi",
        "Guang Yang"
      ],
      "abstract": "With the rapid development of artificial intelligence, intelligent\ndecision-making techniques have gradually surpassed human levels in various\nhuman-machine competitions, especially in complex multi-agent cooperative task\nscenarios. Multi-agent cooperative decision-making involves multiple agents\nworking together to complete established tasks and achieve specific objectives.\nThese techniques are widely applicable in real-world scenarios such as\nautonomous driving, drone navigation, disaster rescue, and simulated military\nconfrontations. This paper begins with a comprehensive survey of the leading\nsimulation environments and platforms used for multi-agent cooperative\ndecision-making. Specifically, we provide an in-depth analysis for these\nsimulation environments from various perspectives, including task formats,\nreward allocation, and the underlying technologies employed. Subsequently, we\nprovide a comprehensive overview of the mainstream intelligent decision-making\napproaches, algorithms and models for multi-agent systems (MAS).\nTheseapproaches can be broadly categorized into five types: rule-based\n(primarily fuzzy logic), game theory-based, evolutionary algorithms-based, deep\nmulti-agent reinforcement learning (MARL)-based, and large language\nmodels(LLMs)reasoning-based. Given the significant advantages of MARL\nandLLMs-baseddecision-making methods over the traditional rule, game theory,\nand evolutionary algorithms, this paper focuses on these multi-agent methods\nutilizing MARL and LLMs-based techniques. We provide an in-depth discussion of\nthese approaches, highlighting their methodology taxonomies, advantages, and\ndrawbacks. Further, several prominent research directions in the future and\npotential challenges of multi-agent cooperative decision-making are also\ndetailed.",
      "tldr_zh": "这篇论文对多智能体合作决策（Multi-Agent Cooperative Decision-Making）进行了全面调查，涵盖了实际场景如自动驾驶、无人机导航、灾害救援和军事对抗中的应用。论文首先分析了领先的模拟环境和平台，从任务格式、奖励分配以及底层技术等方面进行深入探讨。随后，它概述了主流决策方法，包括基于规则的（主要是模糊逻辑）、基于博弈理论的、基于进化算法的、基于深度多智能体强化学习（MARL）的，以及基于大型语言模型（LLMs）推理的方法，并重点讨论了MARL和LLMs方法的分类、优势（如高效性）和缺点。最终，论文指出了未来研究方向和潜在挑战，如算法鲁棒性和实际部署问题，为该领域的发展提供了宝贵视角。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "54 pages, 24 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13415v1",
      "published_date": "2025-03-17 17:45:46 UTC",
      "updated_date": "2025-03-17 17:45:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:59:26.925381"
    },
    {
      "arxiv_id": "2503.14546v1",
      "title": "The Impact of Artificial Intelligence on Emergency Medicine: A Review of Recent Advances",
      "title_zh": "人工智能对急诊医学的影响：最近进展的综述",
      "authors": [
        "Gustavo Correia",
        "Victor Alves",
        "Paulo Novais"
      ],
      "abstract": "Artificial Intelligence (AI) is revolutionizing emergency medicine by\nenhancing diagnostic processes and improving patient outcomes. This article\nprovides a review of the current applications of AI in emergency imaging\nstudies, focusing on the last five years of advancements. AI technologies,\nparticularly machine learning and deep learning, are pivotal in interpreting\ncomplex imaging data, offering rapid, accurate diagnoses and potentially\nsurpassing traditional diagnostic methods. Studies highlighted within the\narticle demonstrate AI's capabilities in accurately detecting conditions such\nas fractures, pneumothorax, and pulmonary diseases from various imaging\nmodalities including X-rays, CT scans, and MRIs. Furthermore, AI's ability to\npredict clinical outcomes like mechanical ventilation needs illustrates its\npotential in crisis resource optimization. Despite these advancements, the\nintegration of AI into clinical practice presents challenges such as data\nprivacy, algorithmic bias, and the need for extensive validation across diverse\nsettings. This review underscores the transformative potential of AI in\nemergency settings, advocating for a future where AI and clinical expertise\nsynergize to elevate patient care standards.",
      "tldr_zh": "这篇综述文章探讨了人工智能(AI)对急诊医学的影响，聚焦于过去五年的进展，特别是AI在急诊影像研究中的应用。AI技术，如机器学习和深度学习，能够快速准确地解读复杂影像数据，包括X-rays、CT scans和MRIs，从而检测骨折、气胸和肺部疾病，并预测临床结果如机械通气需求，以优化资源分配。研究显示，AI在诊断准确性和患者预后方面可能超越传统方法，但面临数据隐私、算法偏差以及在不同环境进行广泛验证的挑战。总体而言，该文强调AI与临床专长的结合，有望显著提升急诊护理标准。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "68T07"
      ],
      "primary_category": "eess.IV",
      "comment": "20 pages, 2 tables, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.14546v1",
      "published_date": "2025-03-17 17:45:00 UTC",
      "updated_date": "2025-03-17 17:45:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:59:38.998344"
    },
    {
      "arxiv_id": "2503.13414v1",
      "title": "Reward Adaptation Via Q-Manipulation",
      "title_zh": "通过 Q-操控的奖励适应",
      "authors": [
        "Kevin Vora",
        "Yu Zhang"
      ],
      "abstract": "In this paper, we propose a new solution to reward adaptation (RA), the\nproblem where the learning agent adapts to a target reward function based on\none or multiple existing behaviors learned a priori under the same domain\ndynamics but different reward functions. Learning the target behavior from\nscratch is possible but often inefficient given the available source behaviors.\nOur work represents a new approach to RA via the manipulation of Q-functions.\nAssuming that the target reward function is a known function of the source\nreward functions, our approach to RA computes bounds of the Q function. We\nintroduce an iterative process to tighten the bounds, similar to value\niteration. This enables action pruning in the target domain before learning\neven starts. We refer to such a method as Q-Manipulation (Q-M). We formally\nprove that our pruning strategy does not affect the optimality of the returned\npolicy while empirically show that it improves the sample complexity. Q-M is\nevaluated in a variety of synthetic and simulation domains to demonstrate its\neffectiveness, generalizability, and practicality.",
      "tldr_zh": "这篇论文提出了 Q-Manipulation (Q-M) 方法，用于解决 Reward Adaptation (RA) 问题，即学习代理基于现有行为适应到目标奖励函数，而非从零开始学习。方法假设目标奖励函数是源奖励函数的已知函数，通过计算 Q-functions 的边界并采用类似价值迭代的迭代过程来收紧这些边界，实现行动 pruning，从而在目标域学习前优化效率。论文形式证明了这种 pruning 策略不会影响返回策略的最优性，同时实证显示它改善了 sample complexity。在各种合成和模拟领域中，Q-M 展示了其有效性、一般性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13414v1",
      "published_date": "2025-03-17 17:42:54 UTC",
      "updated_date": "2025-03-17 17:42:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T02:59:51.024259"
    },
    {
      "arxiv_id": "2503.13413v3",
      "title": "DLPO: Towards a Robust, Efficient, and Generalizable Prompt Optimization Framework from a Deep-Learning Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Dengyun Peng",
        "Yuhang Zhou",
        "Qiguang Chen",
        "Jinhao Liu",
        "Jingjing Chen",
        "Libo Qin"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable success across diverse\ntasks, largely driven by well-designed prompts. However, crafting and selecting\nsuch prompts often requires considerable human effort, significantly limiting\nits scalability. To mitigate this, recent studies have explored automated\nprompt optimization as a promising solution. Despite these efforts, existing\nmethods still face critical challenges in robustness, efficiency, and\ngeneralization. To systematically address these challenges, we first conduct an\nempirical analysis to identify the limitations of current reflection-based\nprompt optimization paradigm. Building on these insights, we propose 7\ninnovative approaches inspired by traditional deep learning paradigms for\nprompt optimization (DLPO), seamlessly integrating these concepts into\ntext-based gradient optimization. Through these advancements, we progressively\ntackle the aforementioned challenges and validate our methods through extensive\nexperimentation. We hope our study not only provides valuable guidance for\nfuture research but also offers a comprehensive understanding of the challenges\nand potential solutions in prompt optimization. Our code is available at\nhttps://github.com/sfasfaffa/DLPO.",
      "tldr_zh": "这篇论文针对大语言模型(LLMs)的提示优化问题，分析了现有方法的局限性，包括鲁棒性、效率和泛化能力不足。作者提出DLPO框架，借鉴传统深度学习范式，开发了7种创新方法，并将其无缝整合到基于文本的梯度优化中，以系统解决这些挑战。通过广泛实验验证，DLPO显著提升了提示优化的性能，并为未来研究提供指导和开源代码（https://github.com/sfasfaffa/DLPO）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.13413v3",
      "published_date": "2025-03-17 17:42:51 UTC",
      "updated_date": "2025-03-19 14:18:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:00:02.264999"
    },
    {
      "arxiv_id": "2503.13404v1",
      "title": "Fed-Joint: Joint Modeling of Nonlinear Degradation Signals and Failure Events for Remaining Useful Life Prediction using Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Cheoljoon Jeong",
        "Xubo Yue",
        "Seokhyun Chung"
      ],
      "abstract": "Many failure mechanisms of machinery are closely related to the behavior of\ncondition monitoring (CM) signals. To achieve a cost-effective preventive\nmaintenance strategy, accurate remaining useful life (RUL) prediction based on\nthe signals is of paramount importance. However, the CM signals are often\nrecorded at different factories and production lines, with limited amounts of\ndata. Unfortunately, these datasets have rarely been shared between the sites\ndue to data confidentiality and ownership issues, a lack of computing and\nstorage power, and high communication costs associated with data transfer\nbetween sites and a data center. Another challenge in real applications is that\nthe CM signals are often not explicitly specified \\textit{a priori}, meaning\nthat existing methods, which often usually a parametric form, may not be\napplicable. To address these challenges, we propose a new prognostic framework\nfor RUL prediction using the joint modeling of nonlinear degradation signals\nand time-to-failure data within a federated learning scheme. The proposed\nmethod constructs a nonparametric degradation model using a federated\nmulti-output Gaussian process and then employs a federated survival model to\npredict failure times and probabilities for in-service machinery. The\nsuperiority of the proposed method over other alternatives is demonstrated\nthrough comprehensive simulation studies and a case study using turbofan engine\ndegradation signal data that include run-to-failure events.",
      "tldr_zh": "该研究提出 Fed-Joint 框架，利用 Federated Learning 联合建模非线性退化信号和故障事件，以实现 Remaining Useful Life (RUL) 预测。针对条件监测 (CM) 信号数据分散、隐私问题和非参数建模挑战，该方法采用 Federated Multi-Output Gaussian Process 构建非参数退化模型，并结合 Federated Survival Model 来预测机械设备的故障时间和概率。实验结果通过模拟研究和 turbofan 引擎退化信号数据的案例分析，证明了该框架比其他方法更优越，有助于在数据共享受限的环境中实现成本有效的预防性维护。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13404v1",
      "published_date": "2025-03-17 17:34:34 UTC",
      "updated_date": "2025-03-17 17:34:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:00:15.110359"
    },
    {
      "arxiv_id": "2503.13401v1",
      "title": "Using the Tools of Cognitive Science to Understand Large Language Models at Different Levels of Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Ku",
        "Declan Campbell",
        "Xuechunzi Bai",
        "Jiayi Geng",
        "Ryan Liu",
        "Raja Marjieh",
        "R. Thomas McCoy",
        "Andrew Nam",
        "Ilia Sucholutsky",
        "Veniamin Veselovsky",
        "Liyi Zhang",
        "Jian-Qiao Zhu",
        "Thomas L. Griffiths"
      ],
      "abstract": "Modern artificial intelligence systems, such as large language models, are\nincreasingly powerful but also increasingly hard to understand. Recognizing\nthis problem as analogous to the historical difficulties in understanding the\nhuman mind, we argue that methods developed in cognitive science can be useful\nfor understanding large language models. We propose a framework for applying\nthese methods based on Marr's three levels of analysis. By revisiting\nestablished cognitive science techniques relevant to each level and\nillustrating their potential to yield insights into the behavior and internal\norganization of large language models, we aim to provide a toolkit for making\nsense of these new kinds of minds.",
      "tldr_zh": "该论文将认知科学工具应用于理解大型语言模型（Large Language Models），以应对其日益复杂性的挑战，通过类比人类思维难题提出解决方案。作者基于 Marr's three levels of analysis 框架，重新审视认知科学技术，并探讨这些方法如何揭示大型语言模型的行为和内部组织。最终，该框架为研究人员提供了一个工具包，帮助更好地理解这些“新类型思维”的运作机制。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13401v1",
      "published_date": "2025-03-17 17:33:54 UTC",
      "updated_date": "2025-03-17 17:33:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:00:25.237534"
    },
    {
      "arxiv_id": "2503.13399v1",
      "title": "MicroVQA: A Multimodal Reasoning Benchmark for Microscopy-Based Scientific Research",
      "title_zh": "翻译失败",
      "authors": [
        "James Burgess",
        "Jeffrey J Nirschl",
        "Laura Bravo-Sánchez",
        "Alejandro Lozano",
        "Sanket Rajan Gupte",
        "Jesus G. Galaz-Montoya",
        "Yuhui Zhang",
        "Yuchang Su",
        "Disha Bhowmik",
        "Zachary Coman",
        "Sarina M. Hasan",
        "Alexandra Johannesson",
        "William D. Leineweber",
        "Malvika G Nair",
        "Ridhi Yarlagadda",
        "Connor Zuraski",
        "Wah Chiu",
        "Sarah Cohen",
        "Jan N. Hansen",
        "Manuel D Leonetti",
        "Chad Liu",
        "Emma Lundberg",
        "Serena Yeung-Levy"
      ],
      "abstract": "Scientific research demands sophisticated reasoning over multimodal data, a\nchallenge especially prevalent in biology. Despite recent advances in\nmultimodal large language models (MLLMs) for AI-assisted research, existing\nmultimodal reasoning benchmarks only target up to college-level difficulty,\nwhile research-level benchmarks emphasize lower-level perception, falling short\nof the complex multimodal reasoning needed for scientific discovery. To bridge\nthis gap, we introduce MicroVQA, a visual-question answering (VQA) benchmark\ndesigned to assess three reasoning capabilities vital in research workflows:\nexpert image understanding, hypothesis generation, and experiment proposal.\nMicroVQA consists of 1,042 multiple-choice questions (MCQs) curated by biology\nexperts across diverse microscopy modalities, ensuring VQA samples represent\nreal scientific practice. In constructing the benchmark, we find that standard\nMCQ generation methods induce language shortcuts, motivating a new two-stage\npipeline: an optimized LLM prompt structures question-answer pairs into MCQs;\nthen, an agent-based `RefineBot' updates them to remove shortcuts. Benchmarking\non state-of-the-art MLLMs reveal a peak performance of 53\\%; models with\nsmaller LLMs only slightly underperform top models, suggesting that\nlanguage-based reasoning is less challenging than multimodal reasoning; and\ntuning with scientific articles enhances performance. Expert analysis of\nchain-of-thought responses shows that perception errors are the most frequent,\nfollowed by knowledge errors and then overgeneralization errors. These insights\nhighlight the challenges in multimodal scientific reasoning, showing MicroVQA\nis a valuable resource advancing AI-driven biomedical research. MicroVQA is\navailable at https://huggingface.co/datasets/jmhb/microvqa, and project page at\nhttps://jmhb0.github.io/microvqa.",
      "tldr_zh": "该研究引入了 MicroVQA，一种针对显微镜基础科学研究的多模态推理基准，用于评估专家图像理解、假设生成和实验提案等关键能力，以填补现有基准在复杂科学推理方面的不足。MicroVQA 包含由生物专家策划的 1,042 个多选题 (MCQs)，覆盖多种显微镜模式，并采用一个两阶段管道生成问题：先用优化 LLM 提示结构问题-答案对，然后通过基于代理的 'RefineBot' 去除语言捷径。基准测试显示，最先进的 Multimodal Large Language Models (MLLMs) 峰值性能为 53%，较小模型表现相近，表明多模态推理比语言推理更具挑战，且使用科学文章微调可提升性能；专家分析发现，感知错误最常见，其次是知识错误和过度泛化错误，这为推进 AI 驱动生物医学研究提供了宝贵资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "q-bio.CB"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025 (Conference on Computer Vision and Pattern Recognition)\n  Project page at https://jmhb0.github.io/microvqa Benchmark at\n  https://huggingface.co/datasets/jmhb/microvqa",
      "pdf_url": "http://arxiv.org/pdf/2503.13399v1",
      "published_date": "2025-03-17 17:33:10 UTC",
      "updated_date": "2025-03-17 17:33:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:00:39.962222"
    },
    {
      "arxiv_id": "2503.13385v1",
      "title": "Scale Efficient Training for Large Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Qing Zhou",
        "Junyu Gao",
        "Qi Wang"
      ],
      "abstract": "The rapid growth of dataset scales has been a key driver in advancing deep\nlearning research. However, as dataset scale increases, the training process\nbecomes increasingly inefficient due to the presence of low-value samples,\nincluding excessive redundant samples, overly challenging samples, and\ninefficient easy samples that contribute little to model improvement.To address\nthis challenge, we propose Scale Efficient Training (SeTa) for large datasets,\na dynamic sample pruning approach that losslessly reduces training time. To\nremove low-value samples, SeTa first performs random pruning to eliminate\nredundant samples, then clusters the remaining samples according to their\nlearning difficulty measured by loss. Building upon this clustering, a sliding\nwindow strategy is employed to progressively remove both overly challenging and\ninefficient easy clusters following an easy-to-hard curriculum.We conduct\nextensive experiments on large-scale synthetic datasets, including ToCa, SS1M,\nand ST+MJ, each containing over 3 million samples.SeTa reduces training costs\nby up to 50\\% while maintaining or improving performance, with minimal\ndegradation even at 70\\% cost reduction. Furthermore, experiments on various\nscale real datasets across various backbones (CNNs, Transformers, and Mambas)\nand diverse tasks (instruction tuning, multi-view stereo, geo-localization,\ncomposed image retrieval, referring image segmentation) demonstrate the\npowerful effectiveness and universality of our approach. Code is available at\nhttps://github.com/mrazhou/SeTa.",
      "tldr_zh": "该论文针对大规模数据集训练中的低效问题（如冗余样本、过度挑战样本和无效简单样本），提出了一种动态样本修剪方法 Scale Efficient Training (SeTa)，通过随机修剪消除冗余样本、基于损失值聚类样本，并采用滑动窗口策略按照易到难的课程顺序移除低价值样本，从而无损减少训练时间。实验在超过300万样本的合成数据集（如ToCa、SS1M和ST+MJ）上显示，SeTa 可将训练成本降低高达50%并维持或提升性能，即使减少70%成本时性能下降最小。此外，在各种真实数据集、骨干网络（CNNs、Transformers和Mambas）和任务（指令调整、多视图立体等）上验证了该方法的有效性和通用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13385v1",
      "published_date": "2025-03-17 17:13:43 UTC",
      "updated_date": "2025-03-17 17:13:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:00:51.223484"
    },
    {
      "arxiv_id": "2503.13383v1",
      "title": "Cream of the Crop: Harvesting Rich, Scalable and Transferable Multi-Modal Data for Instruction Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Mengyao Lyu",
        "Yan Li",
        "Huasong Zhong",
        "Wenhao Yang",
        "Hui Chen",
        "Jungong Han",
        "Guiguang Ding",
        "Zhenheng Yang"
      ],
      "abstract": "The hypothesis that pretrained large language models (LLMs) necessitate only\nminimal supervision during the fine-tuning (SFT) stage (Zhou et al., 2024) has\nbeen substantiated by recent advancements in data curation and selection\nresearch. However, their stability and generalizability are compromised due to\nthe vulnerability to experimental setups and validation protocols, falling\nshort of surpassing random sampling (Diddee & Ippolito, 2024; Xia et al.,\n2024b). Built upon LLMs, multi-modal LLMs (MLLMs), combined with the sheer\ntoken volume and heightened heterogeneity of data sources, amplify both the\nsignificance and complexity of data selection.\n  To harvest multi-modal instructional data in a robust and efficient manner,\nwe re-define the granularity of the quality metric by decomposing it into 14\nvision-language-related capabilities, and introduce multi-modal rich scorers to\nevaluate the capabilities of each data candidate. To promote diversity, in\nlight of the inherent objective of the alignment stage, we take interaction\nstyle as diversity indicator and use a multi-modal rich styler to identify data\ninstruction patterns. In doing so, our multi-modal rich scorers and styler\n(mmSSR) guarantee that high-scoring information is conveyed to users in\ndiversified forms. Free from embedding-based clustering or greedy sampling,\nmmSSR efficiently scales to millions of data with varying budget constraints,\nsupports customization for general or specific capability acquisition, and\nfacilitates training-free generalization to new domains for curation. Across\n10+ experimental settings, validated by 14 multi-modal benchmarks, we\ndemonstrate consistent improvements over random sampling, baseline strategies\nand state-of-the-art selection methods, achieving 99.1% of full performance\nwith only 30% of the 2.6M data.",
      "tldr_zh": "本研究探讨了预训练大型语言模型（LLMs）和多模态 LLMs（MLLMs）在指令微调（SFT）阶段的数据选择问题，强调现有方法易受实验设置影响且稳定性不足。作者提出 mmSSR 方法，通过将质量指标分解为 14 个视觉-语言相关能力，使用 multi-modal rich scorers 评估数据候选，并以交互风格作为多样性指标，结合 multi-modal rich styler 确保数据多样性和高效扩展，支持自定义和训练-free 泛化。实验结果显示，在 10+ 设置和 14 个多模态基准上，mmSSR 比随机采样和最先进方法表现更优，仅用 2.6M 数据中的 30% 就达到 99.1% 的全性能，为可扩展的多模态数据收集提供了新框架。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "update comparison with sota and analysis",
      "pdf_url": "http://arxiv.org/pdf/2503.13383v1",
      "published_date": "2025-03-17 17:11:22 UTC",
      "updated_date": "2025-03-17 17:11:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:01:05.215315"
    },
    {
      "arxiv_id": "2503.13377v1",
      "title": "TimeZero: Temporal Video Grounding with Reasoning-Guided LVLM",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Wang",
        "Boshen Xu",
        "Zihao Yue",
        "Zihan Xiao",
        "Ziheng Wang",
        "Liang Zhang",
        "Dingyi Yang",
        "Wenxuan Wang",
        "Qin Jin"
      ],
      "abstract": "We introduce TimeZero, a reasoning-guided LVLM designed for the temporal\nvideo grounding (TVG) task. This task requires precisely localizing relevant\nvideo segments within long videos based on a given language query. TimeZero\ntackles this challenge by extending the inference process, enabling the model\nto reason about video-language relationships solely through reinforcement\nlearning. To evaluate the effectiveness of TimeZero, we conduct experiments on\ntwo benchmarks, where TimeZero achieves state-of-the-art performance on\nCharades-STA. Code is available at https://github.com/www-Ye/TimeZero.",
      "tldr_zh": "本研究引入了TimeZero，一种基于推理引导的Large Vision-Language Model (LVLM)，专门用于Temporal Video Grounding (TVG)任务，该任务要求根据语言查询在长视频中精确定位相关段落。TimeZero通过扩展推理过程，仅依赖强化学习（reinforcement learning）来分析视频-语言关系，从而提升模型的准确性和鲁棒性。在两个基准测试中，TimeZero在Charades-STA数据集上达到了state-of-the-art性能，证明了其有效性。代码已在GitHub上开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Code: https://github.com/www-Ye/TimeZero",
      "pdf_url": "http://arxiv.org/pdf/2503.13377v1",
      "published_date": "2025-03-17 17:04:20 UTC",
      "updated_date": "2025-03-17 17:04:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:01:13.493137"
    },
    {
      "arxiv_id": "2503.13369v1",
      "title": "Sightation Counts: Leveraging Sighted User Feedback in Building a BLV-aligned Dataset of Diagram Descriptions",
      "title_zh": "翻译失败",
      "authors": [
        "Wan Ju Kang",
        "Eunki Kim",
        "Na Min An",
        "Sangryul Kim",
        "Haemin Choi",
        "Ki Hoon Kwak",
        "James Thorne"
      ],
      "abstract": "Often, the needs and visual abilities differ between the annotator group and\nthe end user group. Generating detailed diagram descriptions for blind and\nlow-vision (BLV) users is one such challenging domain. Sighted annotators could\ndescribe visuals with ease, but existing studies have shown that direct\ngenerations by them are costly, bias-prone, and somewhat lacking by BLV\nstandards. In this study, we ask sighted individuals to assess -- rather than\nproduce -- diagram descriptions generated by vision-language models (VLM) that\nhave been guided with latent supervision via a multi-pass inference. The\nsighted assessments prove effective and useful to professional educators who\nare themselves BLV and teach visually impaired learners. We release Sightation,\na collection of diagram description datasets spanning 5k diagrams and 137k\nsamples for completion, preference, retrieval, question answering, and\nreasoning training purposes and demonstrate their fine-tuning potential in\nvarious downstream tasks.",
      "tldr_zh": "本研究探讨了为盲人和视力低下（BLV）用户生成图表描述的挑战，提出利用有视力（sighted）个体评估视觉语言模型（VLM）生成的描述，这些VLM通过多轮推理的潜在监督进行指导，以减少偏见和提升质量。sighted评估被证明对BLV专业教育者有用，帮助他们教导视力受损的学习者。研究发布了Sightation数据集，涵盖5k张图表和137k样本，用于完成、偏好、检索、问答和推理训练，并展示了其在下游任务中的微调潜力。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "37 pages, 10 figures, 21 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.13369v1",
      "published_date": "2025-03-17 16:52:46 UTC",
      "updated_date": "2025-03-17 16:52:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:01:27.029980"
    },
    {
      "arxiv_id": "2503.14543v2",
      "title": "Inteligencia Artificial para la conservación y uso sostenible de la biodiversidad, una visión desde Colombia (Artificial Intelligence for conservation and sustainable use of biodiversity, a view from Colombia)",
      "title_zh": "翻译失败",
      "authors": [
        "Juan Sebastián Cañas",
        "Camila Parra-Guevara",
        "Manuela Montoya-Castrillón",
        "Julieta M Ramírez-Mejía",
        "Gabriel-Alejandro Perilla",
        "Esteban Marentes",
        "Nerieth Leuro",
        "Jose Vladimir Sandoval-Sierra",
        "Sindy Martinez-Callejas",
        "Angélica Díaz",
        "Mario Murcia",
        "Elkin A. Noguera-Urbano",
        "Jose Manuel Ochoa-Quintero",
        "Susana Rodríguez Buriticá",
        "Juan Sebastián Ulloa"
      ],
      "abstract": "The rise of artificial intelligence (AI) and the aggravating biodiversity\ncrisis have resulted in a research area where AI-based computational methods\nare being developed to act as allies in conservation, and the sustainable use\nand management of natural resources. While important general guidelines have\nbeen established globally regarding the opportunities and challenges that this\ninterdisciplinary research offers, it is essential to generate local\nreflections from the specific contexts and realities of each region. Hence,\nthis document aims to analyze the scope of this research area from a\nperspective focused on Colombia and the Neotropics. In this paper, we summarize\nthe main experiences and debates that took place at the Humboldt Institute\nbetween 2023 and 2024 in Colombia. To illustrate the variety of promising\nopportunities, we present current uses such as automatic species identification\nfrom images and recordings, species modeling, and in silico bioprospecting,\namong others. From the experiences described above, we highlight limitations,\nchallenges, and opportunities for in order to successfully implementate AI in\nconservation efforts and sustainable management of biological resources in the\nNeotropics. The result aims to be a guide for researchers, decision makers, and\nbiodiversity managers, facilitating the understanding of how artificial\nintelligence can be effectively integrated into conservation and sustainable\nuse strategies. Furthermore, it also seeks to open a space for dialogue on the\ndevelopment of policies that promote the responsible and ethical adoption of AI\nin local contexts, ensuring that its benefits are harnessed without\ncompromising biodiversity or the cultural and ecosystemic values inherent in\nColombia and the Neotropics.",
      "tldr_zh": "该论文从哥伦比亚和新热带地区的视角，分析了人工智能（AI）在生物多样性保护和可持续利用中的作用，总结了2023-2024年洪堡研究所的经验和辩论。作者展示了当前AI应用，如自动物种识别、物种建模和 in silico bioprospecting 等，展示了其在保护努力中的潜力。论文突出了实施AI的限制、挑战和机会，并提供指南，帮助研究人员、决策者和管理者有效整合AI策略。同时，它呼吁制定负责任的AI政策，以确保其益处不损害生物多样性、文化和生态价值。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.14543v2",
      "published_date": "2025-03-17 16:47:05 UTC",
      "updated_date": "2025-03-21 01:10:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:01:38.456470"
    },
    {
      "arxiv_id": "2503.13360v1",
      "title": "Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Hai-Long Sun",
        "Zhun Sun",
        "Houwen Peng",
        "Han-Jia Ye"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated\nenhanced reasoning capabilities, evolving from Chain-of-Thought (CoT) prompting\nto advanced, product-oriented solutions like OpenAI o1. During our\nre-implementation of this model, we noticed that in multimodal tasks requiring\nvisual input (e.g., geometry problems), Multimodal LLMs (MLLMs) struggle to\nmaintain focus on the visual information, in other words, MLLMs suffer from a\ngradual decline in attention to visual information as reasoning progresses,\ncausing text-over-relied outputs. To investigate this, we ablate image inputs\nduring long-chain reasoning. Concretely, we truncate the reasoning process\nmidway, then re-complete the reasoning process with the input image removed. We\nobserve only a ~2% accuracy drop on MathVista's test-hard subset, revealing the\nmodel's textual outputs dominate the following reasoning process. Motivated by\nthis, we propose Take-along Visual Conditioning (TVC), a strategy that shifts\nimage input to critical reasoning stages and compresses redundant visual tokens\nvia dynamic pruning. This methodology helps the model retain attention to the\nvisual components throughout the reasoning. Our approach achieves\nstate-of-the-art performance on average across five mathematical reasoning\nbenchmarks (+3.4% vs previous sota), demonstrating the effectiveness of TVC in\nenhancing multimodal reasoning systems.",
      "tldr_zh": "该研究发现，多模态LLMs（MLLMs）在长链Chain-of-Thought (CoT)推理任务中（如几何问题）容易忽略视觉信息，导致过度依赖文本输出，并通过实验验证移除图像输入仅造成约2%的准确率下降。\n为此，提出Take-along Visual Conditioning (TVC)策略，该方法将图像输入转移到关键推理阶段，并通过动态修剪压缩冗余视觉tokens，以帮助模型持续关注视觉组件。\n实验结果显示，TVC在五个数学推理基准上实现了最先进性能，平均准确率提升3.4%，证明了其在提升多模态推理系统的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "The project page is available at\n  https://sun-hailong.github.io/projects/TVC",
      "pdf_url": "http://arxiv.org/pdf/2503.13360v1",
      "published_date": "2025-03-17 16:45:12 UTC",
      "updated_date": "2025-03-17 16:45:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:01:51.119254"
    },
    {
      "arxiv_id": "2503.16525v2",
      "title": "KVShare: An LLM Service System with Efficient and Effective Multi-Tenant KV Cache Reuse",
      "title_zh": "翻译失败",
      "authors": [
        "Huan Yang",
        "Renji Zhang",
        "Mingzhe Huang",
        "Weijun Wang",
        "Yin Tang",
        "Yuanchun Li",
        "Yunxin Liu",
        "Deyu Zhang"
      ],
      "abstract": "Recent advances in long-text understanding have pushed the context length of\nlarge language models (LLMs) up to one million tokens. It boosts LLMs's\naccuracy and reasoning capacity but causes exorbitant computational costs and\nunsatisfactory Time to First Token (TTFT). KV cache reuse, which reuses the\nexact same KV cache of prefixes and templates or shares similar ones but with\nextra selective recomputation, offers a promising way to tackle this issue.\nHowever, prior studies overlook the cross-request KV reuse and the attention\ndeviations introduced by new tokens during the decoding stage. In this paper,\nwe present a KV cache management module that shares the KV cache across\nrequests under multi-tenant scenarios without sacrificing model accuracy. Our\nsystem, KVShare, enables accurate and efficient LLM serving by 1) a Dual-Stage\nHigh Deviation algorithm (DHD) that conditionally selects a small portion of KV\ncache to be recomputed during both prefill and decode phases, and 2) a\ncache-aware scheduler that prioritizes requests based on their KV cache hit\nrates and orchestrates continuous batching to achieve enhanced system\nefficiency and faster TTFT. Multi-task experiments conducted on models such as\nQwen2.5-7B,Llama3.1-8B and Yi1.5-9B demonstrate that KVShare reduces TTFT by up\nto 9.39x and increases 1.2x of the throughput compared to the full KV\nrecompute. Moreover, KVShare achieves 20.38% boost in terms of accuracy\ncompared to SOTA methods.",
      "tldr_zh": "该论文提出 KVShare 系统，用于在多租户场景下高效重用大型语言模型 (LLMs) 的 KV cache，从而解决长文本理解带来的高计算成本和 Time to First Token (TTFT) 问题。系统核心包括 Dual-Stage High Deviation (DHD) 算法，该算法在预填充和解码阶段有条件地重新计算少量 KV cache，以最小化注意力偏差；以及一个 cache-aware scheduler，根据 KV cache 命中率优先处理请求并优化连续批处理。实验在 Qwen2.5-7B、Llama3.1-8B 和 Yi1.5-9B 等模型上显示，KVShare 将 TTFT 减少高达 9.39 倍，提高吞吐量 1.2 倍，并比 SOTA 方法准确性提升 20.38%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16525v2",
      "published_date": "2025-03-17 16:43:35 UTC",
      "updated_date": "2025-05-16 12:42:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:02:04.069861"
    },
    {
      "arxiv_id": "2503.13343v1",
      "title": "Scalable Runtime Architecture for Data-driven, Hybrid HPC and ML Workflow Applications",
      "title_zh": "可扩展的运行时架构，用于数据驱动的混合 HPC 和 ML 工作流应用",
      "authors": [
        "Andre Merzky",
        "Mikhail Titov",
        "Matteo Turilli",
        "Ozgur Kilic",
        "Tianle Wang",
        "Shantenu Jha"
      ],
      "abstract": "Hybrid workflows combining traditional HPC and novel ML methodologies are\ntransforming scientific computing. This paper presents the architecture and\nimplementation of a scalable runtime system that extends RADICAL-Pilot with\nservice-based execution to support AI-out-HPC workflows. Our runtime system\nenables distributed ML capabilities, efficient resource management, and\nseamless HPC/ML coupling across local and remote platforms. Preliminary\nexperimental results show that our approach manages concurrent execution of ML\nmodels across local and remote HPC/cloud resources with minimal architectural\noverheads. This lays the foundation for prototyping three representative\ndata-driven workflow applications and executing them at scale on\nleadership-class HPC platforms.",
      "tldr_zh": "这篇论文提出了一种可扩展的运行时架构，用于支持数据驱动的混合HPC和高性能计算与ML机器学习工作流应用，通过扩展RADICAL-Pilot并引入服务-based执行来实现。系统启用分布式ML能力、有效的资源管理和HPC/ML在本地及远程平台的无缝耦合。初步实验结果显示，该方法能够以最小架构开销管理ML模型的并发执行，并为在领导级HPC平台上原型化和大规模运行三个代表性数据驱动应用奠定基础。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13343v1",
      "published_date": "2025-03-17 16:21:48 UTC",
      "updated_date": "2025-03-17 16:21:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:02:14.282603"
    },
    {
      "arxiv_id": "2503.13342v1",
      "title": "Valid Text-to-SQL Generation with Unification-based DeepStochLog",
      "title_zh": "翻译失败",
      "authors": [
        "Ying Jiao",
        "Luc De Raedt",
        "Giuseppe Marra"
      ],
      "abstract": "Large language models have been used to translate natural language questions\nto SQL queries. Without hard constraints on syntax and database schema, they\noccasionally produce invalid queries that are not executable. These failures\nlimit the usage of these systems in real-life scenarios. We propose a\nneurosymbolic framework that imposes SQL syntax and schema constraints with\nunification-based definite clause grammars and thus guarantees the generation\nof valid queries. Our framework also builds a bi-directional interface to\nlanguage models to leverage their natural language understanding abilities. The\nevaluation results on a subset of SQL grammars show that all our output queries\nare valid. This work is the first step towards extending language models with\nunification-based grammars. We demonstrate this extension enhances the\nvalidity, execution accuracy, and ground truth alignment of the underlying\nlanguage model by a large margin. Our code is available at\nhttps://github.com/ML-KULeuven/deepstochlog-lm.",
      "tldr_zh": "本研究针对大型语言模型在 Text-to-SQL 任务中可能生成无效 SQL 查询的问题，提出了一种神经符号框架，使用 Unification-based DeepStochLog 和基于统一的确定性子句文法(unification-based definite clause grammars)来强制执行 SQL syntax 和 schema constraints，从而保证所有输出查询的有效性。该框架还建立语言模型的双向接口，充分利用其自然语言理解能力，以提升查询生成的质量。实验结果显示，这种扩展显著提高了语言模型的有效性、执行准确性和与 ground truth 的匹配，为未来扩展语言模型应用奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13342v1",
      "published_date": "2025-03-17 16:21:10 UTC",
      "updated_date": "2025-03-17 16:21:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:02:27.001198"
    },
    {
      "arxiv_id": "2503.13335v1",
      "title": "Reliable and Efficient Amortized Model-based Evaluation",
      "title_zh": "可靠且高效的摊销模型评估",
      "authors": [
        "Sang Truong",
        "Yuheng Tu",
        "Percy Liang",
        "Bo Li",
        "Sanmi Koyejo"
      ],
      "abstract": "Comprehensive evaluations of language models (LM) during both development and\ndeployment phases are necessary because these models possess numerous\ncapabilities (e.g., mathematical reasoning, legal support, or medical\ndiagnostic) as well as safety risks (e.g., racial bias, toxicity, or\nmisinformation). The average score across a wide range of benchmarks provides a\nsignal that helps guide the use of these LMs in practice. Currently, holistic\nevaluations are costly due to the large volume of benchmark questions, making\nfrequent evaluations impractical. A popular attempt to lower the cost is to\ncompute the average score on a subset of the benchmark. This approach,\nunfortunately, often renders an unreliable measure of LM performance because\nthe average score is often confounded with the difficulty of the questions in\nthe benchmark subset. Item response theory (IRT) was designed to address this\nchallenge, providing a reliable measurement by careful controlling for question\ndifficulty. Unfortunately, question difficulty is expensive to estimate. Facing\nthis challenge, we train a model that predicts question difficulty from its\ncontent, enabling a reliable measurement at a fraction of the cost. In\naddition, we leverage this difficulty predictor to further improve the\nevaluation efficiency through training a question generator given a difficulty\nlevel. This question generator is essential in adaptive testing, where, instead\nof using a random subset of the benchmark questions, informative questions are\nadaptively chosen based on the current estimation of LLM performance.\nExperiments on 22 common natural language benchmarks and 172 LMs show that this\napproach is more reliable and efficient compared to current common practice.",
      "tldr_zh": "该论文针对语言模型（LM）的全面评估问题，提出了一种可靠且高效的基于模型的摊销评估方法，以解决现有基准测试成本高且易受问题难度影响的挑战。研究团队训练了一个模型来预测问题难度，从而减少了使用 Item Response Theory (IRT) 估计难度的开销，并进一步开发了一个给定难度水平的问题生成器，支持适应性测试。实验在22个自然语言基准和172个LM上表明，这种方法比传统子集评估更可靠和高效，提供了一个实用工具来指导LM的开发和部署。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13335v1",
      "published_date": "2025-03-17 16:15:02 UTC",
      "updated_date": "2025-03-17 16:15:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:02:39.678901"
    },
    {
      "arxiv_id": "2503.13580v1",
      "title": "LLM Test Generation via Iterative Hybrid Program Analysis",
      "title_zh": "LLM 测试生成通过迭代混合程序分析",
      "authors": [
        "Sijia Gu",
        "Noor Nashid",
        "Ali Mesbah"
      ],
      "abstract": "Automating unit test generation remains a significant challenge, particularly\nfor complex methods in real-world projects. While Large Language Models (LLMs)\nhave made strides in code generation, they struggle to achieve high branch\ncoverage due to their limited ability to reason about intricate control flow\nstructures. To address this limitation, we introduce Panta, a technique that\nemulates the iterative process human developers follow when analyzing code and\nconstructing test cases. Panta integrates static control flow analysis and\ndynamic code coverage analysis to systematically guide LLMs in identifying\nuncovered execution paths and generating better test cases. By incorporating an\niterative feedback-driven mechanism, our technique continuously refines test\ngeneration based on static and dynamic path coverage insights, ensuring more\ncomprehensive and effective testing. Our empirical evaluation, conducted on\nclasses with high cyclomatic complexity from open-source projects, demonstrates\nthat Panta achieves 26% higher line coverage and 23% higher branch coverage\ncompared to the state-of-the-art.",
      "tldr_zh": "本研究针对 Large Language Models (LLMs) 在单元测试生成中的局限性，特别是处理复杂控制流结构时难以实现高分支覆盖的问题，提出了一种名为 Panta 的迭代混合程序分析技术。Panta 通过整合 static control flow analysis 和 dynamic code coverage analysis，模拟人类开发者的迭代过程，系统性地指导 LLMs 识别未覆盖的执行路径并生成更有效的测试用例。借助反馈驱动机制，该技术持续基于路径覆盖洞见优化测试生成；在开源项目中高循环复杂度的类上，Panta 相比最先进方法实现了 26% 的行覆盖率和 23% 的分支覆盖率提升。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13580v1",
      "published_date": "2025-03-17 16:10:38 UTC",
      "updated_date": "2025-03-17 16:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:02:51.073103"
    },
    {
      "arxiv_id": "2503.13330v1",
      "title": "LEAVS: An LLM-based Labeler for Abdominal CT Supervision",
      "title_zh": "LEAVS：基于LLM的腹部CT监督标记器",
      "authors": [
        "Ricardo Bigolin Lanfredi",
        "Yan Zhuang",
        "Mark Finkelstein",
        "Praveen Thoppey Srinivasan Balamuralikrishna",
        "Luke Krembs",
        "Brandon Khoury",
        "Arthi Reddy",
        "Pritam Mukherjee",
        "Neil M. Rofsky",
        "Ronald M. Summers"
      ],
      "abstract": "Extracting structured labels from radiology reports has been employed to\ncreate vision models to simultaneously detect several types of abnormalities.\nHowever, existing works focus mainly on the chest region. Few works have been\ninvestigated on abdominal radiology reports due to more complex anatomy and a\nwider range of pathologies in the abdomen. We propose LEAVS (Large language\nmodel Extractor for Abdominal Vision Supervision). This labeler can annotate\nthe certainty of presence and the urgency of seven types of abnormalities for\nnine abdominal organs on CT radiology reports. To ensure broad coverage, we\nchose abnormalities that encompass most of the finding types from CT reports.\nOur approach employs a specialized chain-of-thought prompting strategy for a\nlocally-run LLM using sentence extraction and multiple-choice questions in a\ntree-based decision system. We demonstrate that the LLM can extract several\nabnormality types across abdominal organs with an average F1 score of 0.89,\nsignificantly outperforming competing labelers and humans. Additionally, we\nshow that extraction of urgency labels achieved performance comparable to human\nannotations. Finally, we demonstrate that the abnormality labels contain\nvaluable information for training a single vision model that classifies several\norgans as normal or abnormal. We release our code and structured annotations\nfor a public CT dataset containing over 1,000 CT volumes.",
      "tldr_zh": "本文提出 LEAVS，一种基于 LLM（Large Language Model）的标签器，用于从腹部 CT 放射学报告中提取结构化标签，针对九个器官标注七种异常的出现确定性和紧急性，以解决现有工作主要聚焦胸部区域的局限。LEAVS 采用 chain-of-thought 提示策略，包括句子提取、多选题和树状决策系统，确保高效准确的标签生成。实验结果显示，该方法在异常类型提取上平均 F1 score 为 0.89，显著优于竞争标签器和人类水平，且紧急性标签性能与人工相当。最后，作者使用这些标签训练了一个视觉模型成功分类器官异常，并公开了代码和超过 1000 个 CT 体的数据集。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13330v1",
      "published_date": "2025-03-17 16:09:22 UTC",
      "updated_date": "2025-03-17 16:09:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:03:05.027146"
    },
    {
      "arxiv_id": "2503.13579v1",
      "title": "ASMR: Adaptive Skeleton-Mesh Rigging and Skinning via 2D Generative Prior",
      "title_zh": "翻译失败",
      "authors": [
        "Seokhyeon Hong",
        "Soojin Choi",
        "Chaelin Kim",
        "Sihun Cha",
        "Junyong Noh"
      ],
      "abstract": "Despite the growing accessibility of skeletal motion data, integrating it for\nanimating character meshes remains challenging due to diverse configurations of\nboth skeletons and meshes. Specifically, the body scale and bone lengths of the\nskeleton should be adjusted in accordance with the size and proportions of the\nmesh, ensuring that all joints are accurately positioned within the character\nmesh. Furthermore, defining skinning weights is complicated by variations in\nskeletal configurations, such as the number of joints and their hierarchy, as\nwell as differences in mesh configurations, including their connectivity and\nshapes. While existing approaches have made efforts to automate this process,\nthey hardly address the variations in both skeletal and mesh configurations. In\nthis paper, we present a novel method for the automatic rigging and skinning of\ncharacter meshes using skeletal motion data, accommodating arbitrary\nconfigurations of both meshes and skeletons. The proposed method predicts the\noptimal skeleton aligned with the size and proportion of the mesh as well as\ndefines skinning weights for various mesh-skeleton configurations, without\nrequiring explicit supervision tailored to each of them. By incorporating\nDiffusion 3D Features (Diff3F) as semantic descriptors of character meshes, our\nmethod achieves robust generalization across different configurations. To\nassess the performance of our method in comparison to existing approaches, we\nconducted comprehensive evaluations encompassing both quantitative and\nqualitative analyses, specifically examining the predicted skeletons, skinning\nweights, and deformation quality.",
      "tldr_zh": "这篇论文提出了 ASMR 方法，用于适应性骨骼-网格 rigging 和 skinning，解决骨骼和网格配置多样性带来的挑战，如骨长调整和蒙皮权重定义问题。ASMR 通过预测与网格大小和比例匹配的骨骼，并利用 Diffusion 3D Features (Diff3F) 作为语义描述符，实现自动处理任意配置的无监督泛化。实验结果显示，该方法在定量和定性评估中优于现有方法，显著提升了预测骨骼、蒙皮权重和变形质量的表现。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GR",
      "comment": "Eurographics 2025; Project Page\n  https://seokhyeonhong.github.io/projects/asmr/",
      "pdf_url": "http://arxiv.org/pdf/2503.13579v1",
      "published_date": "2025-03-17 15:59:02 UTC",
      "updated_date": "2025-03-17 15:59:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:03:16.598052"
    },
    {
      "arxiv_id": "2503.13316v1",
      "title": "RainScaleGAN: a Conditional Generative Adversarial Network for Rainfall Downscaling",
      "title_zh": "RainScaleGAN：用于降雨下尺度的",
      "authors": [
        "Marcello Iotti",
        "Paolo Davini",
        "Jost von Hardenberg",
        "Giuseppe Zappa"
      ],
      "abstract": "To this day, accurately simulating local-scale precipitation and reliably\nreproducing its distribution remains a challenging task. The limited horizontal\nresolution of Global Climate Models is among the primary factors undermining\ntheir skill in this context. The physical mechanisms driving the onset and\ndevelopment of precipitation, especially in extreme events, operate at\nspatio-temporal scales smaller than those numerically resolved, thus struggling\nto be captured accurately. In order to circumvent this limitation, several\ndownscaling approaches have been developed over the last decades to address the\ndiscrepancy between the spatial resolution of models output and the resolution\nrequired by local-scale applications. In this paper, we introduce RainScaleGAN,\na conditional deep convolutional Generative Adversarial Network (GAN) for\nprecipitation downscaling. GANs have been effectively used in image\nsuper-resolution, an approach highly relevant for downscaling tasks.\nRainScaleGAN's capabilities are tested in a perfect-model setup, where the\nspatial resolution of a precipitation dataset is artificially degraded from\n0.25$^{\\circ}\\times$0.25$^{\\circ}$ to 2$^{\\circ}\\times$2$^\\circ$, and\nRainScaleGAN is used to restore it. The developed model outperforms one of the\nleading precipitation downscaling method found in the literature. RainScaleGAN\nnot only generates a synthetic dataset featuring plausible high-resolution\nspatial patterns and intensities, but also produces a precipitation\ndistribution with statistics closely mirroring those of the ground-truth\ndataset. Given that RainScaleGAN's approach is agnostic with respect to the\nunderlying physics, the method has the potential to be applied to other\nphysical variables such as surface winds or temperature.",
      "tldr_zh": "该论文针对全球气候模型在模拟局部降雨时分辨率不足的问题，提出了一种条件生成对抗网络（GAN）模型RainScaleGAN，用于降雨降尺度。RainScaleGAN借鉴图像超分辨率技术，通过深度卷积网络在实验中将降雨数据从2°×2°恢复到0.25°×0.25°，生成的空间模式、强度和统计分布均优于文献中的领先方法。结果表明，该模型不仅能产生逼真的高分辨率合成数据集，还具备对其他物理变量（如地表风速或温度）的泛化潜力。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "38 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13316v1",
      "published_date": "2025-03-17 15:54:20 UTC",
      "updated_date": "2025-03-17 15:54:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:03:28.376314"
    },
    {
      "arxiv_id": "2503.13310v1",
      "title": "Generative AI for Software Architecture. Applications, Trends, Challenges, and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Esposito",
        "Xiaozhou Li",
        "Sergio Moreschini",
        "Noman Ahmad",
        "Tomas Cerny",
        "Karthik Vaidhyanathan",
        "Valentina Lenarduzzi",
        "Davide Taibi"
      ],
      "abstract": "Context: Generative Artificial Intelligence (GenAI) is transforming much of\nsoftware development, yet its application in software architecture is still in\nits infancy, and no prior study has systematically addressed the topic. Aim: We\naim to systematically synthesize the use, rationale, contexts, usability, and\nfuture challenges of GenAI in software architecture. Method: We performed a\nmultivocal literature review (MLR), analyzing peer-reviewed and gray\nliterature, identifying current practices, models, adoption contexts, and\nreported challenges, extracting themes via open coding. Results: Our review\nidentified significant adoption of GenAI for architectural decision support and\narchitectural reconstruction. OpenAI GPT models are predominantly applied, and\nthere is consistent use of techniques such as few-shot prompting and\nretrieved-augmented generation (RAG). GenAI has been applied mostly to initial\nstages of the Software Development Life Cycle (SDLC), such as\nRequirements-to-Architecture and Architecture-to-Code. Monolithic and\nmicroservice architectures were the dominant targets. However, rigorous testing\nof GenAI outputs was typically missing from the studies. Among the most\nfrequent challenges are model precision, hallucinations, ethical aspects,\nprivacy issues, lack of architecture-specific datasets, and the absence of\nsound evaluation frameworks. Conclusions: GenAI shows significant potential in\nsoftware design, but several challenges remain on its path to greater adoption.\nResearch efforts should target designing general evaluation methodologies,\nhandling ethics and precision, increasing transparency and explainability, and\npromoting architecture-specific datasets and benchmarks to bridge the gap\nbetween theoretical possibilities and practical use.",
      "tldr_zh": "这篇论文通过多声道文献综述 (MLR) 系统地审视了生成式人工智能 (GenAI) 在软件架构中的应用、趋势和挑战，旨在总结其使用理由、上下文和潜在问题。研究发现，GenAI 主要应用于架构决策支持和重建，常采用 OpenAI GPT 模型结合 few-shot prompting 和 retrieved-augmented generation (RAG) 技术，焦点在软件开发生命周期 (SDLC) 的初始阶段，如 Requirements-to-Architecture 和 Architecture-to-Code，并针对 Monolithic 和 microservice 架构。常见挑战包括模型精度低下、hallucinations、伦理和隐私问题、缺乏架构特定数据集以及评估框架缺失。未来方向应聚焦于设计通用评估方法、提升透明度和可解释性，并开发专用数据集，以推动 GenAI 在实际软件设计中的采用。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DC",
        "cs.ET"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13310v1",
      "published_date": "2025-03-17 15:49:30 UTC",
      "updated_date": "2025-03-17 15:49:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:03:42.114348"
    },
    {
      "arxiv_id": "2503.13309v2",
      "title": "Integrating AI for Human-Centric Breast Cancer Diagnostics: A Multi-Scale and Multi-View Swin Transformer Framework",
      "title_zh": "将AI整合用于以人为中心的乳腺癌诊断：一个多尺度多视图Swin Transformer",
      "authors": [
        "Farnoush Bayatmakou",
        "Reza Taleei",
        "Milad Amir Toutounchian",
        "Arash Mohammadi"
      ],
      "abstract": "Despite advancements in Computer-Aided Diagnosis (CAD) systems, breast cancer\nremains one of the leading causes of cancer-related deaths among women\nworldwide. Recent breakthroughs in Artificial Intelligence (AI) have shown\nsignificant promise in development of advanced Deep Learning (DL) architectures\nfor breast cancer diagnosis through mammography. In this context, the paper\nfocuses on the integration of AI within a Human-Centric workflow to enhance\nbreast cancer diagnostics. Key challenges are, however, largely overlooked such\nas reliance on detailed tumor annotations and susceptibility to missing views,\nparticularly during test time. To address these issues, we propose a hybrid,\nmulti-scale and multi-view Swin Transformer-based framework (MSMV-Swin) that\nenhances diagnostic robustness and accuracy. The proposed MSMV-Swin framework\nis designed to work as a decision-support tool, helping radiologists analyze\nmulti-view mammograms more effectively. More specifically, the MSMV-Swin\nframework leverages the Segment Anything Model (SAM) to isolate the breast\nlobe, reducing background noise and enabling comprehensive feature extraction.\nThe multi-scale nature of the proposed MSMV-Swin framework accounts for\ntumor-specific regions as well as the spatial characteristics of tissues\nsurrounding the tumor, capturing both localized and contextual information. The\nintegration of contextual and localized data ensures that MSMV-Swin's outputs\nalign with the way radiologists interpret mammograms, fostering better human-AI\ninteraction and trust. A hybrid fusion structure is then designed to ensure\nrobustness against missing views, a common occurrence in clinical practice when\nonly a single mammogram view is available.",
      "tldr_zh": "这篇论文提出了一种以人为中心的乳腺癌诊断框架，名为 MSMV-Swin，利用 AI 和多尺度多视图 Swin Transformer 来提升诊断准确性和鲁棒性。框架通过 Segment Anything Model (SAM) 隔离乳房组织，减少背景噪声，并整合局部和上下文特征，以匹配放射科医生的解读方式。针对临床中常见的缺失视图问题，MSMV-Swin 采用混合融合结构，确保在单视图情况下也能有效工作，从而作为决策支持工具，促进人类-AI 交互和信任。实验结果表明，该框架显著改善了诊断性能，为乳腺癌筛查提供了更可靠的解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13309v2",
      "published_date": "2025-03-17 15:48:56 UTC",
      "updated_date": "2025-05-07 18:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:03:51.395271"
    },
    {
      "arxiv_id": "2503.13305v1",
      "title": "Computation Mechanism Behind LLM Position Generalization",
      "title_zh": "LLM 位置泛化的计算机制",
      "authors": [
        "Chi Han",
        "Heng Ji"
      ],
      "abstract": "Most written natural languages are composed of sequences of words and\nsentences. Similar to humans, large language models (LLMs) exhibit flexibility\nin handling textual positions - a phenomenon we term position generalization.\nThey can understand texts with position perturbations and generalize to longer\ntexts than those encountered during training with the latest techniques. These\nphenomena suggest that LLMs handle positions tolerantly, but how LLMs\ncomputationally process positional relevance remains largely unexplored. This\nwork connects the linguistic phenomenon with LLMs' computational mechanisms. We\nshow how LLMs enforce certain computational mechanisms for the aforementioned\ntolerance in position perturbations. Despite the complex design of the\nself-attention mechanism, this work reveals that LLMs learn a counterintuitive\ndisentanglement of attention logits. Their values show a 0.959 linear\ncorrelation with an approximation of the arithmetic sum of positional relevance\nand semantic importance. Furthermore, we identify a prevalent pattern in\nintermediate features, which we prove theoretically enables this effect. The\npattern, which is different from how randomly initialized parameters would\nbehave, suggests that it is a learned behavior rather than a natural result of\nthe model architecture. Based on these findings, we provide computational\nexplanations and criteria for LLMs' position flexibilities. This work takes a\npioneering step in linking position generalization with modern LLMs' internal\nmechanisms.",
      "tldr_zh": "本研究探讨大型语言模型(LLM)处理文本位置泛化的计算机制，揭示LLM能够容忍位置扰动并泛化到更长文本的现象。该论文通过分析自注意力机制，发现LLM学习了一种反直觉的注意力logits分离，其值与位置相关性和语义重要性的算术和呈现0.959的线性相关；此外，在中间特征中识别了一种学习得到的模式，而不是模型架构的自然结果。基于这些发现，研究提供了LLM位置灵活性的计算解释和标准，为理解LLM内部机制迈出了开创性一步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.13305v1",
      "published_date": "2025-03-17 15:47:37 UTC",
      "updated_date": "2025-03-17 15:47:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:04:03.510519"
    },
    {
      "arxiv_id": "2503.13299v1",
      "title": "A Survey on Transformer Context Extension: Approaches and Evaluation",
      "title_zh": "Transformer 上下文扩展的综述：方法和评估",
      "authors": [
        "Yijun Liu",
        "Jinzheng Yu",
        "Yang Xu",
        "Zhongyang Li",
        "Qingfu Zhu"
      ],
      "abstract": "Large language models (LLMs) based on Transformer have been widely applied in\nthe filed of natural language processing (NLP), demonstrating strong\nperformance, particularly in handling short text tasks. However, when it comes\nto long context scenarios, the performance of LLMs degrades due to some\nchallenges. To alleviate this phenomenon, there is a number of work proposed\nrecently. In this survey, we first list the challenges of applying pre-trained\nLLMs to process long contexts. Then systematically review the approaches\nrelated to long context and propose our taxonomy categorizing them into four\nmain types: positional encoding, context compression, retrieval augmented, and\nattention pattern. In addition to the approaches, we focus on the evaluation of\nlong context, organizing relevant data, tasks, and metrics based on existing\nlong context benchmarks. Finally, we summarize unresolved issues in the long\ncontext domain and put forward our views on future developments.",
      "tldr_zh": "这篇调查论文探讨了基于 Transformer 的 LLMs 在处理长上下文时面临的挑战，如性能下降问题，并系统回顾了相关解决方案。作者将这些方法分类为四类：positional encoding（位置编码）、context compression（上下文压缩）、retrieval augmented（检索增强）和 attention pattern（注意力模式）。此外，论文组织了长上下文的评估框架，包括数据、任务和指标，并总结了未解决的问题及未来发展方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.13299v1",
      "published_date": "2025-03-17 15:44:09 UTC",
      "updated_date": "2025-03-17 15:44:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:04:15.532564"
    },
    {
      "arxiv_id": "2503.13288v1",
      "title": "$φ$-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation",
      "title_zh": "翻译失败",
      "authors": [
        "Fangzhi Xu",
        "Hang Yan",
        "Chang Ma",
        "Haiteng Zhao",
        "Jun Liu",
        "Qika Lin",
        "Zhiyong Wu"
      ],
      "abstract": "Inference-time optimization scales computation to derive deliberate reasoning\nsteps for effective performance. While previous search-based strategies address\nthe short-sightedness of auto-regressive generation, the vast search space\nleads to excessive exploration and insufficient exploitation. To strike an\nefficient balance to derive the optimal step, we frame the decoding strategy as\nforesight sampling, leveraging simulated future steps to obtain globally\noptimal step estimation. Built on it, we propose a novel decoding strategy,\nnamed $\\phi$-Decoding. To provide a precise and expressive estimation of step\nvalue, $\\phi$-Decoding approximates two distributions via foresight and\nclustering. Sampling from the joint distribution, the optimal steps can be\nselected for exploitation. To support adaptive computation allocation, we\npropose in-width and in-depth pruning strategies, featuring a light-weight\nsolution to achieve inference efficiency. Extensive experiments across seven\nbenchmarks show $\\phi$-Decoding outperforms strong baselines in both\nperformance and efficiency. Additional analysis demonstrates its generalization\nacross various LLMs and scalability across a wide range of computing budgets.\nThe code will be released at https://github.com/xufangzhi/phi-Decoding, and the\nopen-source PyPI package is coming soon.",
      "tldr_zh": "该论文提出了一种名为 φ-Decoding 的新解码策略，通过 foresight sampling 方法，利用模拟未来步骤来平衡推理时的探索和利用问题，从而解决 auto-regressive 生成的短视性。φ-Decoding 通过近似两个分布（foresight 和 clustering）并从联合分布中采样，选择最优步骤，并引入 in-width 和 in-depth 修剪策略以实现自适应计算分配和高效推理。在七个基准上的广泛实验显示，该策略在性能和效率上优于强基线，并展示出对各种 LLMs 的泛化能力和不同计算预算的可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13288v1",
      "published_date": "2025-03-17 15:38:33 UTC",
      "updated_date": "2025-03-17 15:38:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:04:28.575319"
    },
    {
      "arxiv_id": "2503.13281v3",
      "title": "LLM-Match: An Open-Sourced Patient Matching Model Based on Large Language Models and Retrieval-Augmented Generation",
      "title_zh": "LLM-Match：基于大语言模型和检索增强生成的开源患者匹配模型",
      "authors": [
        "Xiaodi Li",
        "Shaika Chowdhury",
        "Chung Il Wi",
        "Maria Vassilaki",
        "Xiaoke Liu",
        "Terence T Sio",
        "Owen Garrick",
        "Young J Juhn",
        "James R Cerhan",
        "Cui Tao",
        "Nansu Zong"
      ],
      "abstract": "Patient matching is the process of linking patients to appropriate clinical\ntrials by accurately identifying and matching their medical records with trial\neligibility criteria. We propose LLM-Match, a novel framework for patient\nmatching leveraging fine-tuned open-source large language models. Our approach\nconsists of four key components. First, a retrieval-augmented generation (RAG)\nmodule extracts relevant patient context from a vast pool of electronic health\nrecords (EHRs). Second, a prompt generation module constructs input prompts by\nintegrating trial eligibility criteria (both inclusion and exclusion criteria),\npatient context, and system instructions. Third, a fine-tuning module with a\nclassification head optimizes the model parameters using structured prompts and\nground-truth labels. Fourth, an evaluation module assesses the fine-tuned\nmodel's performance on the testing datasets. We evaluated LLM-Match on four\nopen datasets - n2c2, SIGIR, TREC 2021, and TREC 2022 - using open-source\nmodels, comparing it against TrialGPT, Zero-Shot, and GPT-4-based closed\nmodels. LLM-Match outperformed all baselines.",
      "tldr_zh": "该研究提出LLM-Match，一种基于开源大型语言模型(LLMs)和检索增强生成(RAG)的患者匹配框架，用于将患者医疗记录与临床试验资格标准准确匹配。框架包括四个关键组件：RAG模块从电子健康记录(EHRs)中提取相关患者上下文、提示生成模块整合试验标准和患者信息、微调模块使用结构化提示和真实标签优化模型参数，以及评估模块测试模型性能。在n2c2、SIGIR、TREC 2021和TREC 2022等数据集上，LLM-Match与TrialGPT、Zero-Shot和GPT-4基于封闭模型的基线相比，表现出色，证明了其在患者匹配任务中的优越性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2503.13281v3",
      "published_date": "2025-03-17 15:31:55 UTC",
      "updated_date": "2025-03-24 19:32:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:04:40.200235"
    },
    {
      "arxiv_id": "2503.13279v1",
      "title": "Goal2Story: A Multi-Agent Fleet based on Privately Enabled sLLMs for Impacting Mapping on Requirements Elicitation",
      "title_zh": "翻译失败",
      "authors": [
        "Xinkai Zou",
        "Yan Liu",
        "Xiongbo Shi",
        "Chen Yang"
      ],
      "abstract": "As requirements drift with rapid iterations, agile development becomes the\ndominant paradigm. Goal-driven Requirements Elicitation (RE) is a pivotal yet\nchallenging task in agile project development due to its heavy tangling with\nadaptive planning and efficient collaboration. Recently, AI agents have shown\npromising ability in supporting requirements analysis by saving significant\ntime and effort for stakeholders. However, current research mainly focuses on\nfunctional RE, and research works have not been reported bridging the long\njourney from goal to user stories. Moreover, considering the cost of LLM\nfacilities and the need for data and idea protection, privately hosted\nsmall-sized LLM should be further utilized in RE. To address these challenges,\nwe propose Goal2Story, a multi-agent fleet that adopts the Impact Mapping (IM)\nframework while merely using cost-effective sLLMs for goal-driven RE. Moreover,\nwe introduce a StorySeek dataset that contains over 1,000 user stories (USs)\nwith corresponding goals and project context information, as well as the\nsemi-automatic dataset construction method. For evaluation, we proposed two\nmetrics: Factuality Hit Rate (FHR) to measure consistency between the generated\nUSs with the dataset and Quality And Consistency Evaluation (QuACE) to evaluate\nthe quality of the generated USs. Experimental results demonstrate that\nGoal2Story outperforms the baseline performance of the Super-Agent adopting\npowerful LLMs, while also showcasing the performance improvements in key\nmetrics brought by CoT and Agent Profile to Goal2Story, as well as its\nexploration in identifying latent needs.",
      "tldr_zh": "该论文提出Goal2Story，一种基于多智能体系统(multi-agent fleet)的框架，利用私有托管的小型语言模型(sLLMs)来支持Impact Mapping在目标驱动的需求获取(Requirements Elicitation)中的应用，旨在桥接从目标到用户故事的流程并解决敏捷开发中的协作挑战。研究者构建了StorySeek数据集，包含超过1000个用户故事及其相关目标和项目上下文，并引入了Factuality Hit Rate (FHR)和Quality And Consistency Evaluation (QuACE)两个新指标进行评估。实验结果显示，Goal2Story优于采用强大LLM的Super-Agent基线模型，并在Chain-of-Thought (CoT)和Agent Profile的优化下提升了关键指标表现，同时展现了识别潜在需求的能力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13279v1",
      "published_date": "2025-03-17 15:31:20 UTC",
      "updated_date": "2025-03-17 15:31:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:04:51.998813"
    },
    {
      "arxiv_id": "2503.13277v1",
      "title": "Artificial Intelligence-Driven Prognostic Classification of COVID-19 Using Chest X-rays: A Deep Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Alfred Simbun",
        "Suresh Kumar"
      ],
      "abstract": "Background: The COVID-19 pandemic has overwhelmed healthcare systems,\nemphasizing the need for AI-driven tools to assist in rapid and accurate\npatient prognosis. Chest X-ray imaging is a widely available diagnostic tool,\nbut existing methods for prognosis classification lack scalability and\nefficiency. Objective: This study presents a high-accuracy deep learning model\nfor classifying COVID-19 severity (Mild, Moderate, and Severe) using Chest\nX-ray images, developed on Microsoft Azure Custom Vision. Methods: Using a\ndataset of 1,103 confirmed COVID-19 X-ray images from AIforCOVID, we trained\nand validated a deep learning model leveraging Convolutional Neural Networks\n(CNNs). The model was evaluated on an unseen dataset to measure accuracy,\nprecision, and recall. Results: Our model achieved an average accuracy of 97%,\nwith specificity of 99%, sensitivity of 87%, and an F1-score of 93.11%. When\nclassifying COVID-19 severity, the model achieved accuracies of 89.03% (Mild),\n95.77% (Moderate), and 81.16% (Severe). These results demonstrate the model's\npotential for real-world clinical applications, aiding in faster\ndecision-making and improved resource allocation. Conclusion: AI-driven\nprognosis classification using deep learning can significantly enhance COVID-19\npatient management, enabling early intervention and efficient triaging. Our\nstudy provides a scalable, high-accuracy AI framework for integrating deep\nlearning into routine clinical workflows. Future work should focus on expanding\ndatasets, external validation, and regulatory compliance to facilitate clinical\nadoption.",
      "tldr_zh": "本研究提出了一种基于深度学习(AI)的模型，用于通过胸部X光图像对COVID-19患者进行预后分类，分为轻度、中度和重度，以应对疫情下医疗系统的负担。方法包括使用AIforCOVID数据集中的1,103张图像训练卷积神经网络(CNNs)模型，并通过Microsoft Azure Custom Vision平台进行开发和验证。结果显示，该模型平均准确率达97%，特异性99%，敏感性87%，F1分数93.11%，在不同严重程度分类上分别达到89.03% (轻度)、95.77% (中度)和81.16% (重度)。这项工作为临床决策提供了一个可扩展的高准确AI框架，有助于加速患者管理、资源分配，并建议未来扩展数据集和进行外部验证以推动实际应用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "27 pages, 6 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.13277v1",
      "published_date": "2025-03-17 15:27:21 UTC",
      "updated_date": "2025-03-17 15:27:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:05:05.105269"
    },
    {
      "arxiv_id": "2503.13275v2",
      "title": "Knowledge-Aware Iterative Retrieval for Multi-Agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Seyoung Song"
      ],
      "abstract": "We introduce a novel large language model (LLM)-driven agent framework, which\niteratively refines queries and filters contextual evidence by leveraging\ndynamically evolving knowledge. A defining feature of the system is its\ndecoupling of external sources from an internal knowledge cache that is\nprogressively updated to guide both query generation and evidence selection.\nThis design mitigates bias-reinforcement loops and enables dynamic, trackable\nsearch exploration paths, thereby optimizing the trade-off between exploring\ndiverse information and maintaining accuracy through autonomous agent\ndecision-making. Our approach is evaluated on a broad range of open-domain\nquestion answering benchmarks, including multi-step tasks that mirror\nreal-world scenarios where integrating information from multiple sources is\ncritical, especially given the vulnerabilities of LLMs that lack explicit\nreasoning or planning capabilities. The results show that the proposed system\nnot only outperforms single-step baselines regardless of task difficulty but\nalso, compared to conventional iterative retrieval methods, demonstrates\npronounced advantages in complex tasks through precise evidence-based reasoning\nand enhanced efficiency. The proposed system supports both competitive and\ncollaborative sharing of updated context, enabling multi-agent extension. The\nbenefits of multi-agent configurations become especially prominent as task\ndifficulty increases. The number of convergence steps scales with task\ndifficulty, suggesting cost-effective scalability.",
      "tldr_zh": "本文提出了一种基于大型语言模型（LLM）的代理框架，通过知识感知的迭代检索来动态改进查询生成和证据过滤，将外部来源与逐步更新的内部知识缓存分离，以缓解偏见强化循环并优化信息探索与准确性的权衡。框架在开放域问答基准测试中表现突出，尤其在多步任务中超越单步基线，并通过精确的证据-based 推理提升效率。支持竞争性和协作性多代理扩展，在任务难度增加时表现出显著优势，且收敛步骤随难度扩展而增加，实现成本有效的可扩展性。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "I.2.0; I.2.7; I.2.11; H.3.3"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13275v2",
      "published_date": "2025-03-17 15:27:02 UTC",
      "updated_date": "2025-04-01 14:21:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:05:15.631762"
    },
    {
      "arxiv_id": "2504.07109v1",
      "title": "OSCAR: Online Soft Compression And Reranking",
      "title_zh": "翻译失败",
      "authors": [
        "Maxime Louis",
        "Thibault Formal",
        "Hervé Dejean",
        "Stéphane Clinchant"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by\nintegrating external knowledge, leading to improved accuracy and relevance.\nHowever, scaling RAG pipelines remains computationally expensive as retrieval\nsizes grow. To address this, we introduce OSCAR, a novel query-dependent online\nsoft compression method that reduces computational overhead while preserving\nperformance. Unlike traditional hard compression methods, which shorten\nretrieved texts, or soft compression approaches, which map documents to\ncontinuous embeddings offline, OSCAR dynamically compresses retrieved\ninformation at inference time, eliminating storage overhead and enabling higher\ncompression rates. Additionally, we extend OSCAR to simultaneously perform\nreranking, further optimizing the efficiency of the RAG pipeline. Our\nexperiments demonstrate state-of-the-art performance with a 2-5x speed-up in\ninference and minimal to no loss in accuracy for LLMs ranging from 1B to 24B\nparameters. The models are available at:\nhttps://huggingface.co/collections/naver/oscar-67d446a8e3a2551f57464295.",
      "tldr_zh": "这篇论文介绍了OSCAR，一种创新的查询依赖在线软压缩方法，用于优化Retrieval-Augmented Generation (RAG)管道，解决扩展时计算开销过大的问题。与传统压缩方法不同，OSCAR在推理时动态压缩检索信息并整合reranking功能，从而消除存储开销并实现更高压缩率。实验结果显示，OSCAR为1B到24B参数的Large Language Models (LLMs)提供了2-5倍的推理速度提升，同时准确率损失最小或无损失。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.07109v1",
      "published_date": "2025-03-17 15:10:09 UTC",
      "updated_date": "2025-03-17 15:10:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:05:27.092301"
    },
    {
      "arxiv_id": "2503.13578v1",
      "title": "Convolutional neural network for early detection of lameness and irregularity in horses using an IMU sensor",
      "title_zh": "翻译失败",
      "authors": [
        "Benoît Savoini",
        "Jonathan Bertolaccini",
        "Stéphane Montavon",
        "Michel Deriaz"
      ],
      "abstract": "Lameness and gait irregularities are significant concerns in equine health\nmanagement, affecting performance, welfare, and economic value. Traditional\nobservational methods rely on subjective expert assessments, which can lead to\ninconsistencies in detecting subtle or early-stage lameness. While AI-based\napproaches have emerged, many require multiple sensors, force plates, or video\nsystems, making them costly and impractical for field deployment. In this\napplied research study, we present a stride-level classification system that\nutilizes a single inertial measurement unit (IMU) and a one-dimensional\nconvolutional neural network (1D CNN) to objectively differentiate between\nsound and lame horses, with a primary focus on the trot gait. The proposed\nsystem was tested under real-world conditions, achieving a 90% session-level\naccuracy with no false positives, demonstrating its robustness for practical\napplications. By employing a single, non-intrusive, and readily available\nsensor, our approach significantly reduces the complexity and cost of hardware\nrequirements while maintaining high classification performance. These results\nhighlight the potential of our CNN-based method as a field-tested, scalable\nsolution for automated lameness detection. By enabling early diagnosis, this\nsystem offers a valuable tool for preventing minor gait irregularities from\ndeveloping into severe conditions, ultimately contributing to improved equine\nwelfare and performance in veterinary and equestrian practice.",
      "tldr_zh": "本研究针对马匹跛行和步态不规则的问题，提出了一种基于单个惯性测量单元(IMU)传感器和一维卷积神经网络(1D CNN)的步态级分类系统，专注于trot gait，以实现早期客观检测。相比传统主观评估或依赖多传感器的AI方法，该系统简化了硬件需求，降低了成本，并在真实条件下测试中达到90%的会话级准确率，同时无假阳性。结果表明，该方法为现场应用提供了一个可扩展的解决方案，有助于早期诊断预防严重问题，提升马匹福利和表现。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted at AMLDS 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13578v1",
      "published_date": "2025-03-17 15:05:01 UTC",
      "updated_date": "2025-03-17 15:05:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:05:39.333117"
    },
    {
      "arxiv_id": "2503.14542v1",
      "title": "AI-Driven Rapid Identification of Bacterial and Fungal Pathogens in Blood Smears of Septic Patients",
      "title_zh": "翻译失败",
      "authors": [
        "Agnieszka Sroka-Oleksiak",
        "Adam Pardyl",
        "Dawid Rymarczyk",
        "Aldona Olechowska-Jarząb",
        "Katarzyna Biegun-Drożdż",
        "Dorota Ochońska",
        "Michał Wronka",
        "Adriana Borowa",
        "Tomasz Gosiewski",
        "Miłosz Adamczyk",
        "Henryk Telega",
        "Bartosz Zieliński",
        "Monika Brzychczy-Włoch"
      ],
      "abstract": "Sepsis is a life-threatening condition which requires rapid diagnosis and\ntreatment. Traditional microbiological methods are time-consuming and\nexpensive. In response to these challenges, deep learning algorithms were\ndeveloped to identify 14 bacteria species and 3 yeast-like fungi from\nmicroscopic images of Gram-stained smears of positive blood samples from sepsis\npatients.\n  A total of 16,637 Gram-stained microscopic images were used in the study. The\nanalysis used the Cellpose 3 model for segmentation and Attention-based Deep\nMultiple Instance Learning for classification. Our model achieved an accuracy\nof 77.15% for bacteria and 71.39% for fungi, with ROC AUC of 0.97 and 0.88,\nrespectively. The highest values, reaching up to 96.2%, were obtained for\nCutibacterium acnes, Enterococcus faecium, Stenotrophomonas maltophilia and\nNakaseomyces glabratus. Classification difficulties were observed in closely\nrelated species, such as Staphylococcus hominis and Staphylococcus\nhaemolyticus, due to morphological similarity, and within Candida albicans due\nto high morphotic diversity.\n  The study confirms the potential of our model for microbial classification,\nbut it also indicates the need for further optimisation and expansion of the\ntraining data set. In the future, this technology could support microbial\ndiagnosis, reducing diagnostic time and improving the effectiveness of sepsis\ntreatment due to its simplicity and accessibility. Part of the results\npresented in this publication was covered by a patent application at the\nEuropean Patent Office EP24461637.1 \"A computer implemented method for\nidentifying a microorganism in a blood and a data processing system therefor\".",
      "tldr_zh": "本研究开发了一种AI驱动的方法，用于快速识别败血症患者血涂片中的14种细菌和3种酵母状真菌，以应对传统微生物检测耗时且昂贵的挑战。方法采用Cellpose 3模型进行图像分割，以及Attention-based Deep Multiple Instance Learning进行分类，基于16,637张Gram染色显微图像进行分析。结果显示，模型在细菌识别上达到77.15%的准确率和0.97的ROC AUC，在真菌上达到71.39%的准确率和0.88的ROC AUC，某些物种如Cutibacterium acnes的准确率高达96.2%。尽管存在形态相似物种的分类困难，该技术显示出简化诊断并提升败血症治疗效果的潜力，并已部分申请专利。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CE",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.14542v1",
      "published_date": "2025-03-17 15:02:49 UTC",
      "updated_date": "2025-03-17 15:02:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:05:52.184025"
    },
    {
      "arxiv_id": "2503.13223v1",
      "title": "Robust Decision-Making Via Free Energy Minimization",
      "title_zh": "翻译失败",
      "authors": [
        "Allahkaram Shafiei",
        "Hozefa Jesawada",
        "Karl Friston",
        "Giovanni Russo"
      ],
      "abstract": "Despite their groundbreaking performance, state-of-the-art autonomous agents\ncan misbehave when training and environmental conditions become inconsistent,\nwith minor mismatches leading to undesirable behaviors or even catastrophic\nfailures. Robustness towards these training/environment ambiguities is a core\nrequirement for intelligent agents and its fulfillment is a long-standing\nchallenge when deploying agents in the real world. Here, departing from\nmainstream views seeking robustness through training, we introduce DR-FREE, a\nfree energy model that installs this core property by design. It directly wires\nrobustness into the agent decision-making mechanisms via free energy\nminimization. By combining a robust extension of the free energy principle with\na novel resolution engine, DR-FREE returns a policy that is optimal-yet-robust\nagainst ambiguity. Moreover, for the first time, it reveals the mechanistic\nrole of ambiguity on optimal decisions and requisite Bayesian belief updating.\nWe evaluate DR-FREE on an experimental testbed involving real rovers navigating\nan ambiguous environment filled with obstacles. Across all the experiments,\nDR-FREE enables robots to successfully navigate towards their goal even when,\nin contrast, standard free energy minimizing agents that do not use DR-FREE\nfail. In short, DR-FREE can tackle scenarios that elude previous methods: this\nmilestone may inspire both deployment in multi-agent settings and, at a perhaps\ndeeper level, the quest for a biologically plausible explanation of how natural\nagents - with little or no training - survive in capricious environments.",
      "tldr_zh": "这篇论文提出 DR-FREE，一种基于自由能最小化（free energy minimization）的模型，旨在通过设计嵌入鲁棒性来解决自主代理在训练和环境不一致时的错误行为问题。DR-FREE 结合自由能原理的鲁棒扩展和新型解析引擎，返回在模糊性下最优且鲁棒的政策，并首次揭示模糊性对最优决策和贝叶斯信念更新（Bayesian belief updating）的机制作用。在实验中，DR-FREE 使真实漫游者在充满障碍的模糊环境中成功导航，而标准自由能最小化代理失败，这为多代理部署和生物学解释提供了新启发。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "Contains main text and supplementary information",
      "pdf_url": "http://arxiv.org/pdf/2503.13223v1",
      "published_date": "2025-03-17 14:36:08 UTC",
      "updated_date": "2025-03-17 14:36:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:06:04.913143"
    },
    {
      "arxiv_id": "2503.13222v2",
      "title": "Can Language Models Follow Multiple Turns of Entangled Instructions?",
      "title_zh": "语言模型能否跟随多个回合的纠缠指令？",
      "authors": [
        "Chi Han"
      ],
      "abstract": "Despite significant achievements in improving the instruction-following\ncapabilities of large language models (LLMs), the ability to process multiple\npotentially entangled or conflicting instructions remains a considerable\nchallenge. Real-world scenarios often require consistency across multiple\ninstructions over time, such as secret privacy, personal preferences, and\nprioritization, which demand sophisticated abilities to integrate multiple\nturns and carefully balance competing objectives when instructions intersect or\nconflict. This work presents a systematic investigation of LLMs' capabilities\nin handling multiple turns of instructions, covering three levels of\ndifficulty: (1) retrieving information from instructions, (2) tracking and\nreasoning across turns, and (3) resolving conflicts among instructions. We\nconstruct MultiTurnInstruct with around 1.1K high-quality multi-turn\nconversations through the human-in-the-loop approach and result in nine\ncapability categories, including statics and dynamics, reasoning, and\nmultitasking. Our finding reveals an intriguing trade-off between different\ncapabilities. While GPT models demonstrate superior memorization, they show\nreduced effectiveness in privacy-protection tasks requiring selective\ninformation withholding. Larger models exhibit stronger reasoning capabilities\nbut still struggle with resolving conflicting instructions. Importantly, these\nperformance gaps cannot be attributed solely to information loss, as models\ndemonstrate strong BLEU scores on memorization tasks but their attention\nmechanisms fail to integrate multiple related instructions effectively. These\nfindings highlight critical areas for improvement in complex real-world tasks\ninvolving multi-turn instructions.",
      "tldr_zh": "本研究系统调查了大型语言模型 (LLMs) 在处理多轮可能纠缠或冲突指令时的能力，涵盖三个难度级别：从指令中检索信息、跨轮次跟踪和推理，以及解决指令冲突。研究者构建了 MultiTurnInstruct 数据集，包含约 1.1K 条高质量多轮对话，通过人工参与方式，涵盖九个能力类别，包括静态和动态、推理及多任务。结果显示，GPT 模型在记忆方面表现出色，但隐私保护任务中表现较差，而更大模型虽在推理上更强，却难以有效解决冲突指令；这些差距并非源于信息丢失，而是注意机制无法整合相关指令。研究强调了 LLMs 在复杂多轮指令任务中需改进的关键领域，以更好地适应真实场景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.13222v2",
      "published_date": "2025-03-17 14:31:37 UTC",
      "updated_date": "2025-03-28 17:17:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:06:15.548276"
    },
    {
      "arxiv_id": "2503.13214v3",
      "title": "A General Adaptive Dual-level Weighting Mechanism for Remote Sensing Pansharpening",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Huang",
        "Haorui Chen",
        "Jiaxuan Ren",
        "Siran Peng",
        "Liangjian Deng"
      ],
      "abstract": "Currently, deep learning-based methods for remote sensing pansharpening have\nadvanced rapidly. However, many existing methods struggle to fully leverage\nfeature heterogeneity and redundancy, thereby limiting their effectiveness. We\nuse the covariance matrix to model the feature heterogeneity and redundancy and\npropose Correlation-Aware Covariance Weighting (CACW) to adjust them. CACW\ncaptures these correlations through the covariance matrix, which is then\nprocessed by a nonlinear function to generate weights for adjustment. Building\nupon CACW, we introduce a general adaptive dual-level weighting mechanism\n(ADWM) to address these challenges from two key perspectives, enhancing a wide\nrange of existing deep-learning methods. First, Intra-Feature Weighting (IFW)\nevaluates correlations among channels within each feature to reduce redundancy\nand enhance unique information. Second, Cross-Feature Weighting (CFW) adjusts\ncontributions across layers based on inter-layer correlations, refining the\nfinal output. Extensive experiments demonstrate the superior performance of\nADWM compared to recent state-of-the-art (SOTA) methods. Furthermore, we\nvalidate the effectiveness of our approach through generality experiments,\nredundancy visualization, comparison experiments, key variables and complexity\nanalysis, and ablation studies. Our code is available at\nhttps://github.com/Jie-1203/ADWM.",
      "tldr_zh": "该论文针对遥感图像锐化（pansharpening）中的深度学习方法，指出现有方法未能充分利用特征异质性和冗余的问题，并提出Correlation-Aware Covariance Weighting (CACW)来通过协方差矩阵（covariance matrix）捕获相关性并生成调整权重。基于CACW，该研究引入了general adaptive dual-level weighting mechanism (ADWM)，包括Intra-Feature Weighting (IFW)用于减少特征内通道冗余并增强独特信息，以及Cross-Feature Weighting (CFW)用于基于层间相关性调整层间贡献，从而提升多种现有方法的性能。实验结果显示，ADWM在广泛测试中优于最新state-of-the-art (SOTA)方法，并通过泛化实验、冗余可视化及消融研究验证了其有效性和通用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper is accepted at the CVPR Conference on Computer Vision and\n  Pattern Recognition 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13214v3",
      "published_date": "2025-03-17 14:24:00 UTC",
      "updated_date": "2025-03-21 12:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:06:29.221083"
    },
    {
      "arxiv_id": "2503.13211v1",
      "title": "MedLoRD: A Medical Low-Resource Diffusion Model for High-Resolution 3D CT Image Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Marvin Seyfarth",
        "Salman Ul Hassan Dar",
        "Isabelle Ayx",
        "Matthias Alexander Fink",
        "Stefan O. Schoenberg",
        "Hans-Ulrich Kauczor",
        "Sandy Engelhardt"
      ],
      "abstract": "Advancements in AI for medical imaging offer significant potential. However,\ntheir applications are constrained by the limited availability of data and the\nreluctance of medical centers to share it due to patient privacy concerns.\nGenerative models present a promising solution by creating synthetic data as a\nsubstitute for real patient data. However, medical images are typically\nhigh-dimensional, and current state-of-the-art methods are often impractical\nfor computational resource-constrained healthcare environments. These models\nrely on data sub-sampling, raising doubts about their feasibility and\nreal-world applicability. Furthermore, many of these models are evaluated on\nquantitative metrics that alone can be misleading in assessing the image\nquality and clinical meaningfulness of the generated images. To address this,\nwe introduce MedLoRD, a generative diffusion model designed for computational\nresource-constrained environments. MedLoRD is capable of generating\nhigh-dimensional medical volumes with resolutions up to\n512$\\times$512$\\times$256, utilizing GPUs with only 24GB VRAM, which are\ncommonly found in standard desktop workstations. MedLoRD is evaluated across\nmultiple modalities, including Coronary Computed Tomography Angiography and\nLung Computed Tomography datasets. Extensive evaluations through radiological\nevaluation, relative regional volume analysis, adherence to conditional masks,\nand downstream tasks show that MedLoRD generates high-fidelity images closely\nadhering to segmentation mask conditions, surpassing the capabilities of\ncurrent state-of-the-art generative models for medical image synthesis in\ncomputational resource-constrained environments.",
      "tldr_zh": "该研究针对医疗图像AI的资源限制和数据隐私问题，提出MedLoRD，一种低资源扩散模型，用于生成高分辨率3D CT图像（如512×512×256分辨率），仅需24GB VRAM的GPU即可实现。\nMedLoRD通过生成合成数据来缓解真实患者数据短缺，支持多种模态如冠状动脉CT和肺CT，并通过放射学评估、相对区域体积分析及下游任务确保图像的高保真度和条件掩码遵守。\n与其他现有模型相比，MedLoRD在计算资源受限环境中表现出显著优势，提升了医疗图像合成的实用性和临床价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13211v1",
      "published_date": "2025-03-17 14:22:49 UTC",
      "updated_date": "2025-03-17 14:22:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:06:41.186083"
    },
    {
      "arxiv_id": "2503.13208v3",
      "title": "Improving Complex Reasoning with Dynamic Prompt Corruption: A soft prompt Optimization Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Sinan Fan",
        "Liang Xie",
        "Chen Shen",
        "Ge Teng",
        "Xiaosong Yuan",
        "Xiaofeng Zhang",
        "Chenxi Huang",
        "Wenxiao Wang",
        "Xiaofei He",
        "Jieping Ye"
      ],
      "abstract": "Prompt-tuning (PT) for large language models (LLMs) can facilitate the\nperformance on various conventional NLP tasks with significantly fewer\ntrainable parameters. However, our investigation reveals that PT provides\nlimited improvement and may even degrade the primitive performance of LLMs on\ncomplex reasoning tasks. Such a phenomenon suggests that soft prompts can\npositively impact certain instances while negatively affecting others,\nparticularly during the later phases of reasoning. To address these challenges,\nWe first identify an information accumulation within the soft prompts. Through\ndetailed analysis, we demonstrate that this phenomenon is often accompanied by\nerroneous information flow patterns in the deeper layers of the model, which\nultimately lead to incorrect reasoning outcomes. we propose a novel method\ncalled Dynamic Prompt Corruption (DPC) to take better advantage of soft prompts\nin complex reasoning tasks, which dynamically adjusts the influence of soft\nprompts based on their impact on the reasoning process. Specifically, DPC\nconsists of two stages: Dynamic Trigger and Dynamic Corruption. First, Dynamic\nTrigger measures the impact of soft prompts, identifying whether beneficial or\ndetrimental. Then, Dynamic Corruption mitigates the negative effects of soft\nprompts by selectively masking key tokens that interfere with the reasoning\nprocess. We validate the proposed approach through extensive experiments on\nvarious LLMs and reasoning tasks, including GSM8K, MATH, and AQuA. Experimental\nresults demonstrate that DPC can consistently enhance the performance of PT,\nachieving 4%-8% accuracy gains compared to vanilla prompt tuning, highlighting\nthe effectiveness of our approach and its potential to enhance complex\nreasoning in LLMs.",
      "tldr_zh": "该研究发现，Prompt-tuning (PT) 虽然能提升大语言模型 (LLMs) 在常规 NLP 任务上的性能，但对复杂推理任务的改进有限，甚至可能降低模型表现。针对这一问题，作者提出 Dynamic Prompt Corruption (DPC) 方法，通过 Dynamic Trigger 评估软提示的影响（判断其益害），并利用 Dynamic Corruption 选择性屏蔽干扰推理的关键标记，从而动态优化软提示的作用。在 GSM8K、MATH 和 AQuA 等任务上的实验验证显示，DPC 比传统 PT 提高了 4%-8% 的准确率，证明其在增强 LLMs 复杂推理能力方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13208v3",
      "published_date": "2025-03-17 14:20:48 UTC",
      "updated_date": "2025-04-13 12:38:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:06:53.590056"
    },
    {
      "arxiv_id": "2503.13205v1",
      "title": "MAP: Evaluation and Multi-Agent Enhancement of Large Language Models for Inpatient Pathways",
      "title_zh": "MAP：大型语言模型在住院路径中的评估与多智能体增强",
      "authors": [
        "Zhen Chen",
        "Zhihao Peng",
        "Xusheng Liang",
        "Cheng Wang",
        "Peigan Liang",
        "Linsheng Zeng",
        "Minjie Ju",
        "Yixuan Yuan"
      ],
      "abstract": "Inpatient pathways demand complex clinical decision-making based on\ncomprehensive patient information, posing critical challenges for clinicians.\nDespite advancements in large language models (LLMs) in medical applications,\nlimited research focused on artificial intelligence (AI) inpatient pathways\nsystems, due to the lack of large-scale inpatient datasets. Moreover, existing\nmedical benchmarks typically concentrated on medical question-answering and\nexaminations, ignoring the multifaceted nature of clinical decision-making in\ninpatient settings. To address these gaps, we first developed the Inpatient\nPathway Decision Support (IPDS) benchmark from the MIMIC-IV database,\nencompassing 51,274 cases across nine triage departments and 17 major disease\ncategories alongside 16 standardized treatment options. Then, we proposed the\nMulti-Agent Inpatient Pathways (MAP) framework to accomplish inpatient pathways\nwith three clinical agents, including a triage agent managing the patient\nadmission, a diagnosis agent serving as the primary decision maker at the\ndepartment, and a treatment agent providing treatment plans. Additionally, our\nMAP framework includes a chief agent overseeing the inpatient pathways to guide\nand promote these three clinician agents. Extensive experiments showed our MAP\nimproved the diagnosis accuracy by 25.10% compared to the state-of-the-art LLM\nHuatuoGPT2-13B. It is worth noting that our MAP demonstrated significant\nclinical compliance, outperforming three board-certified clinicians by 10%-12%,\nestablishing a foundation for inpatient pathways systems.",
      "tldr_zh": "该研究针对住院路径的复杂临床决策挑战，开发了Inpatient Pathway Decision Support (IPDS)基准，利用MIMIC-IV数据库涵盖51,274个病例、九个分诊部门、17个主要疾病类别和16个标准化治疗选项，以填补大型语言模型(LLM)在该领域的空白。论文提出了Multi-Agent Inpatient Pathways (MAP)框架，包括triage agent（处理患者入院）、diagnosis agent（主要决策者）、treatment agent（提供治疗计划）和chief agent（监督指导），从而提升LLM的决策准确性和临床合规性。实验结果显示，MAP框架相较于最先进LLM HuatuoGPT2-13B提高了25.10%的诊断准确率，并在临床合规性上超过了三位认证临床医生10%-12%，为AI住院路径系统奠定了基础。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13205v1",
      "published_date": "2025-03-17 14:14:28 UTC",
      "updated_date": "2025-03-17 14:14:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:07:04.839076"
    },
    {
      "arxiv_id": "2504.07108v1",
      "title": "OKRA: an Explainable, Heterogeneous, Multi-Stakeholder Job Recommender System",
      "title_zh": "OKRA：一个可解释的、异构的、多利益相关者工作推荐系统",
      "authors": [
        "Roan Schellingerhout",
        "Francesco Barile",
        "Nava Tintarev"
      ],
      "abstract": "The use of recommender systems in the recruitment domain has been labeled as\n'high-risk' in recent legislation. As a result, strict requirements regarding\nexplainability and fairness have been put in place to ensure proper treatment\nof all involved stakeholders. To allow for stakeholder-specific explainability,\nwhile also handling highly heterogeneous recruitment data, we propose a novel\nexplainable multi-stakeholder job recommender system using graph neural\nnetworks: the Occupational Knowledge-based Recommender using Attention (OKRA).\nThe proposed method is capable of providing both candidate- and company-side\nrecommendations and explanations. We find that OKRA performs substantially\nbetter than six baselines in terms of nDCG for two datasets. Furthermore, we\nfind that the tested models show a bias toward candidates and vacancies located\nin urban areas. Overall, our findings suggest that OKRA provides a balance\nbetween accuracy, explainability, and fairness.",
      "tldr_zh": "本研究针对招聘领域的“高风险”推荐系统，提出了一种新型可解释多利益相关者职推荐系统OKRA（Occupational Knowledge-based Recommender using Attention），它利用graph neural networks和注意力机制处理异构招聘数据，并为候选人和公司提供特定化的推荐和解释。OKRA在两个数据集上与六种基线模型相比，nDCG性能显著提升。实验结果显示，模型存在对城市区域的偏见，但整体上实现了准确性、解释性和公平性的平衡。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.IR",
      "comment": "17 pages, 1 figure, 1 table, to be published in the proceedings of\n  ECIR2025",
      "pdf_url": "http://arxiv.org/pdf/2504.07108v1",
      "published_date": "2025-03-17 14:12:51 UTC",
      "updated_date": "2025-03-17 14:12:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:07:15.179425"
    },
    {
      "arxiv_id": "2503.14538v3",
      "title": "Vision-Language Models for Acute Tuberculosis Diagnosis: A Multimodal Approach Combining Imaging and Clinical Data",
      "title_zh": "视觉-语言",
      "authors": [
        "Ananya Ganapthy",
        "Praveen Shastry",
        "Naveen Kumarasami",
        "Anandakumar D",
        "Keerthana R",
        "Mounigasri M",
        "Varshinipriya M",
        "Kishore Prasath Venkatesh",
        "Bargava Subramanian",
        "Kalyan Sivasailam"
      ],
      "abstract": "Background: This study introduces a Vision-Language Model (VLM) leveraging\nSIGLIP and Gemma-3b architectures for automated acute tuberculosis (TB)\nscreening. By integrating chest X-ray images and clinical notes, the model aims\nto enhance diagnostic accuracy and efficiency, particularly in resource-limited\nsettings.\n  Methods: The VLM combines visual data from chest X-rays with clinical context\nto generate detailed, context-aware diagnostic reports. The architecture\nemploys SIGLIP for visual encoding and Gemma-3b for decoding, ensuring\neffective representation of acute TB-specific pathologies and clinical\ninsights.\n  Results: Key acute TB pathologies, including consolidation, cavities, and\nnodules, were detected with high precision (97percent) and recall (96percent).\nThe model demonstrated strong spatial localization capabilities and robustness\nin distinguishing TB-positive cases, making it a reliable tool for acute TB\ndiagnosis.\n  Conclusion: The multimodal capability of the VLM reduces reliance on\nradiologists, providing a scalable solution for acute TB screening. Future work\nwill focus on improving the detection of subtle pathologies and addressing\ndataset biases to enhance its generalizability and application in diverse\nglobal healthcare settings.",
      "tldr_zh": "本研究提出了一种 Vision-Language Model (VLM)，结合胸部 X 光图像和临床笔记，用于急性结核病 (TB) 诊断，旨在提升资源有限环境下的筛查准确性和效率。模型采用 SIGLIP 进行视觉编码和 Gemma-3b 进行解码，生成上下文相关的诊断报告，从而有效识别关键病变如 consolidation、cavities 和 nodules。结果显示，该模型的精确率达97%、召回率达96%，并在区分 TB 阳性病例方面表现出强有力的空间定位能力。该方法减少了对放射科医生的依赖，提供可扩展的解决方案，未来将聚焦于改进微妙病变的检测和处理数据集偏差以提升通用性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "68T07, 68T45, 92C55, 92C50, 68U10"
      ],
      "primary_category": "eess.IV",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.14538v3",
      "published_date": "2025-03-17 14:08:35 UTC",
      "updated_date": "2025-04-01 06:41:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:07:29.325946"
    },
    {
      "arxiv_id": "2503.13200v1",
      "title": "Timing the Match: A Deep Reinforcement Learning Approach for Ride-Hailing and Ride-Pooling Services",
      "title_zh": "翻译失败",
      "authors": [
        "Yiman Bao",
        "Jie Gao",
        "Jinke He",
        "Frans A. Oliehoek",
        "Oded Cats"
      ],
      "abstract": "Efficient timing in ride-matching is crucial for improving the performance of\nride-hailing and ride-pooling services, as it determines the number of drivers\nand passengers considered in each matching process. Traditional batched\nmatching methods often use fixed time intervals to accumulate ride requests\nbefore assigning matches. While this approach increases the number of available\ndrivers and passengers for matching, it fails to adapt to real-time\nsupply-demand fluctuations, often leading to longer passenger wait times and\ndriver idle periods. To address this limitation, we propose an adaptive\nride-matching strategy using deep reinforcement learning (RL) to dynamically\ndetermine when to perform matches based on real-time system conditions. Unlike\nfixed-interval approaches, our method continuously evaluates system states and\nexecutes matching at moments that minimize total passenger wait time.\nAdditionally, we incorporate a potential-based reward shaping (PBRS) mechanism\nto mitigate sparse rewards, accelerating RL training and improving decision\nquality. Extensive empirical evaluations using a realistic simulator trained on\nreal-world data demonstrate that our approach outperforms fixed-interval\nmatching strategies, significantly reducing passenger waiting times and detour\ndelays, thereby enhancing the overall efficiency of ride-hailing and\nride-pooling systems.",
      "tldr_zh": "该论文针对ride-hailing和ride-pooling服务的骑行匹配问题，提出了一种使用deep reinforcement learning的自适应策略，以动态确定匹配时机，适应实时供需波动并最小化乘客等待时间。不同于传统固定时间间隔方法，该策略结合potential-based reward shaping (PBRS)机制来解决稀疏奖励问题，加速训练并提升决策质量。通过基于真实数据的模拟实验，研究表明该方法显著降低了乘客等待时间和绕路延迟，提高了系统的整体效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13200v1",
      "published_date": "2025-03-17 14:07:58 UTC",
      "updated_date": "2025-03-17 14:07:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:07:41.245012"
    },
    {
      "arxiv_id": "2503.13194v1",
      "title": "A representational framework for learning and encoding structurally enriched trajectories in complex agent environments",
      "title_zh": "翻译失败",
      "authors": [
        "Corina Catarau-Cotutiu",
        "Esther Mondragon",
        "Eduardo Alonso"
      ],
      "abstract": "The ability of artificial intelligence agents to make optimal decisions and\ngeneralise them to different domains and tasks is compromised in complex\nscenarios. One way to address this issue has focused on learning efficient\nrepresentations of the world and on how the actions of agents affect them, such\nas disentangled representations that exploit symmetries. Whereas such\nrepresentations are procedurally efficient, they are based on the compression\nof low-level state-action transitions, which lack structural richness. To\naddress this problem, we propose to enrich the agent's ontology and extend the\ntraditional conceptualisation of trajectories to provide a more nuanced view of\ntask execution. Structurally Enriched Trajectories (SETs) extend the encoding\nof sequences of states and their transitions by incorporating hierarchical\nrelations between objects, interactions and affordances. SETs are built as\nmulti-level graphs, providing a detailed representation of the agent dynamics\nand a transferable functional abstraction of the task. SETs are integrated into\nan architecture, Structurally Enriched Trajectory Learning and Encoding\n(SETLE), that employs a heterogeneous graph-based memory structure of\nmulti-level relational dependencies essential for generalisation. Using\nreinforcement learning as a data generation tool, we demonstrate that SETLE can\nsupport downstream tasks, enabling agents to recognise task-relevant structural\npatterns across diverse environments.",
      "tldr_zh": "该论文提出了一种表示框架，用于在复杂代理环境中学习和编码结构丰富的轨迹，以提升AI代理的决策优化和泛化能力。核心创新是引入Structurally Enriched Trajectories (SETs)，这些多级图扩展了传统状态-动作序列，通过整合对象、交互和可供性的层次关系，提供更细致的任务表示。论文开发的Structurally Enriched Trajectory Learning and Encoding (SETLE)架构利用异构图-based内存结构捕捉多级关系依赖，支持代理在不同环境中的泛化。实验通过reinforcement learning生成数据，证明SETLE能有效识别任务相关结构模式，提升代理性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13194v1",
      "published_date": "2025-03-17 14:04:27 UTC",
      "updated_date": "2025-03-17 14:04:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:07:52.271416"
    },
    {
      "arxiv_id": "2503.13185v1",
      "title": "3DAxisPrompt: Promoting the 3D Grounding and Reasoning in GPT-4o",
      "title_zh": "翻译失败",
      "authors": [
        "Dingning Liu",
        "Cheng Wang",
        "Peng Gao",
        "Renrui Zhang",
        "Xinzhu Ma",
        "Yuan Meng",
        "Zhihui Wang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) exhibit impressive capabilities\nacross a variety of tasks, especially when equipped with carefully designed\nvisual prompts. However, existing studies primarily focus on logical reasoning\nand visual understanding, while the capability of MLLMs to operate effectively\nin 3D vision remains an ongoing area of exploration. In this paper, we\nintroduce a novel visual prompting method, called 3DAxisPrompt, to elicit the\n3D understanding capabilities of MLLMs in real-world scenes. More specifically,\nour method leverages the 3D coordinate axis and masks generated from the\nSegment Anything Model (SAM) to provide explicit geometric priors to MLLMs and\nthen extend their impressive 2D grounding and reasoning ability to real-world\n3D scenarios. Besides, we first provide a thorough investigation of the\npotential visual prompting formats and conclude our findings to reveal the\npotential and limits of 3D understanding capabilities in GPT-4o, as a\nrepresentative of MLLMs. Finally, we build evaluation environments with four\ndatasets, i.e., ScanRefer, ScanNet, FMB, and nuScene datasets, covering various\n3D tasks. Based on this, we conduct extensive quantitative and qualitative\nexperiments, which demonstrate the effectiveness of the proposed method.\nOverall, our study reveals that MLLMs, with the help of 3DAxisPrompt, can\neffectively perceive an object's 3D position in real-world scenarios.\nNevertheless, a single prompt engineering approach does not consistently\nachieve the best outcomes for all 3D tasks. This study highlights the\nfeasibility of leveraging MLLMs for 3D vision grounding/reasoning with prompt\nengineering techniques.",
      "tldr_zh": "本研究提出了一种新型视觉提示方法，名为 3DAxisPrompt，用于提升多模态大语言模型 (MLLMs) 在真实场景中的 3D 定位和推理能力。具体而言，该方法利用 3D 坐标轴和 Segment Anything Model (SAM) 生成的掩码，提供明确的几何先验，帮助 MLLMs 将其出色的 2D 基础扩展到 3D 环境。研究者通过调查不同视觉提示格式，并基于 ScanRefer、ScanNet、FMB 和 nuScene 等数据集进行广泛的定量和定性实验，证明 3DAxisPrompt 显著提高了 GPT-4o 在感知物体 3D 位置方面的表现。然而，单一提示工程方法并非适用于所有 3D 任务，这突显了提示技术在 MLLMs 3D 视觉应用中的潜力与局限。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13185v1",
      "published_date": "2025-03-17 13:57:05 UTC",
      "updated_date": "2025-03-17 13:57:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:08:05.480987"
    },
    {
      "arxiv_id": "2503.13180v2",
      "title": "GC-Fed: Gradient Centralized Federated Learning with Partial Client Participation",
      "title_zh": "翻译失败",
      "authors": [
        "Jungwon Seo",
        "Ferhat Ozgur Catak",
        "Chunming Rong",
        "Kibeom Hong",
        "Minhoe Kim"
      ],
      "abstract": "Federated Learning (FL) enables privacy-preserving multi-source information\nfusion (MSIF) but is challenged by client drift in highly heterogeneous data\nsettings. Many existing drift-mitigation strategies rely on reference-based\ntechniques--such as gradient adjustments or proximal loss--that use historical\nsnapshots (e.g., past gradients or previous global models) as reference points.\nWhen only a subset of clients participates in each training round, these\nhistorical references may not accurately capture the overall data distribution,\nleading to unstable training. In contrast, our proposed Gradient Centralized\nFederated Learning (GC-Fed) employs a hyperplane as a historically independent\nreference point to guide local training and enhance inter-client alignment.\nGC-Fed comprises two complementary components: Local GC, which centralizes\ngradients during local training, and Global GC, which centralizes updates\nduring server aggregation. In our hybrid design, Local GC is applied to\nfeature-extraction layers to harmonize client contributions, while Global GC\nrefines classifier layers to stabilize round-wise performance. Theoretical\nanalysis and extensive experiments on benchmark FL tasks demonstrate that\nGC-Fed effectively mitigates client drift and achieves up to a 20% improvement\nin accuracy under heterogeneous and partial participation conditions.",
      "tldr_zh": "这篇论文提出GC-Fed，一种梯度集中化的Federated Learning方法，旨在解决部分客户端参与场景下数据异构导致的客户端漂移问题。GC-Fed使用超平面作为独立历史参考点，包含Local GC（在本地训练中集中特征提取层梯度以协调客户端贡献）和Global GC（在服务器聚合中优化分类器层以稳定性能）。实验结果表明，该方法在基准FL任务上有效缓解漂移，并在异构条件下将准确率提高多达20%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13180v2",
      "published_date": "2025-03-17 13:54:27 UTC",
      "updated_date": "2025-03-20 08:41:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:08:16.722060"
    },
    {
      "arxiv_id": "2503.13178v1",
      "title": "Rapfi: Distilling Efficient Neural Network for the Game of Gomoku",
      "title_zh": "翻译失败",
      "authors": [
        "Zhanggen Jin",
        "Haobin Duan",
        "Zhiyang Hang"
      ],
      "abstract": "Games have played a pivotal role in advancing artificial intelligence, with\nAI agents using sophisticated techniques to compete. Despite the success of\nneural network based game AIs, their performance often requires significant\ncomputational resources. In this paper, we present Rapfi, an efficient Gomoku\nagent that outperforms CNN-based agents in limited computation environments.\nRapfi leverages a compact neural network with a pattern-based codebook\ndistilled from CNNs, and an incremental update scheme that minimizes\ncomputation when input changes are minor. This new network uses computation\nthat is orders of magnitude less to reach a similar accuracy of much larger\nneural networks such as Resnet. Thanks to our incremental update scheme,\ndepth-first search methods such as the alpha-beta search can be significantly\naccelerated. With a carefully tuned evaluation and search, Rapfi reached\nstrength surpassing Katagomo, the strongest open-source Gomoku AI based on\nAlphaZero's algorithm, under limited computational resources where accelerators\nlike GPUs are absent. Rapfi ranked first among 520 Gomoku agents on Botzone and\nwon the championship in GomoCup 2024.",
      "tldr_zh": "本文提出Rapfi，一种高效的Gomoku游戏AI代理，通过从CNN中蒸馏的pattern-based codebook和incremental update scheme，构建紧凑神经网络，实现比Resnet等大型网络计算量少几个数量级的性能。Rapfi的增量更新机制能加速alpha-beta search等深度优先搜索方法，使其在无GPU等有限资源环境下超越基于AlphaZero的开源AI Katagomo。实验结果显示，Rapfi在Botzone排名第一，并赢得GomoCup 2024冠军。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13178v1",
      "published_date": "2025-03-17 13:53:57 UTC",
      "updated_date": "2025-03-17 13:53:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:08:28.617527"
    },
    {
      "arxiv_id": "2503.13171v1",
      "title": "HybridGen: VLM-Guided Hybrid Planning for Scalable Data Generation of Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Wensheng Wang",
        "Ning Tan"
      ],
      "abstract": "The acquisition of large-scale and diverse demonstration data are essential\nfor improving robotic imitation learning generalization. However, generating\nsuch data for complex manipulations is challenging in real-world settings. We\nintroduce HybridGen, an automated framework that integrates Vision-Language\nModel (VLM) and hybrid planning. HybridGen uses a two-stage pipeline: first,\nVLM to parse expert demonstrations, decomposing tasks into expert-dependent\n(object-centric pose transformations for precise control) and plannable\nsegments (synthesizing diverse trajectories via path planning); second, pose\ntransformations substantially expand the first-stage data. Crucially, HybridGen\ngenerates a large volume of training data without requiring specific data\nformats, making it broadly applicable to a wide range of imitation learning\nalgorithms, a characteristic which we also demonstrate empirically across\nmultiple algorithms. Evaluations across seven tasks and their variants\ndemonstrate that agents trained with HybridGen achieve substantial performance\nand generalization gains, averaging a 5% improvement over state-of-the-art\nmethods. Notably, in the most challenging task variants, HybridGen achieves\nsignificant improvement, reaching a 59.7% average success rate, significantly\noutperforming Mimicgen's 49.5%. These results demonstrating its effectiveness\nand practicality.",
      "tldr_zh": "这篇论文提出了HybridGen框架，利用Vision-Language Model (VLM)和混合规划，自动生成大规模多样化数据，以提升机器人模仿学习的泛化性能。该框架采用两阶段管道：首先，VLM解析专家演示，将任务分解为依赖专家的姿势变换和可规划轨迹合成；其次，通过姿势变换扩展数据，使其适用于多种模仿学习算法。实验在七个任务及其变体上显示，HybridGen训练的代理比最先进方法平均提高5%，在最 challenging 任务中成功率达59.7%，显著优于Mimicgen的49.5%。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13171v1",
      "published_date": "2025-03-17 13:49:43 UTC",
      "updated_date": "2025-03-17 13:49:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:08:40.178258"
    },
    {
      "arxiv_id": "2503.14536v2",
      "title": "Advancing Chronic Tuberculosis Diagnostics Using Vision-Language Models: A Multi modal Framework for Precision Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Praveen Shastry",
        "Sowmya Chowdary Muthulur",
        "Naveen Kumarasami",
        "Anandakumar D",
        "Mounigasri M",
        "Keerthana R",
        "Kishore Prasath Venkatesh",
        "Bargava Subramanian",
        "Kalyan Sivasailam",
        "Revathi Ezhumalai",
        "Abitha Marimuthu"
      ],
      "abstract": "Background: This study proposes a Vision-Language Model (VLM) leveraging the\nSIGLIP encoder and Gemma-3b transformer decoder to enhance automated chronic\ntuberculosis (TB) screening. By integrating chest X-ray images with clinical\ndata, the model addresses the challenges of manual interpretation, improving\ndiagnostic consistency and accessibility, particularly in resource-constrained\nsettings.\n  Methods: The VLM architecture combines a Vision Transformer (ViT) for visual\nencoding and a transformer-based text encoder to process clinical context, such\nas patient histories and treatment records. Cross-modal attention mechanisms\nalign radiographic features with textual information, while the Gemma-3b\ndecoder generates comprehensive diagnostic reports. The model was pre-trained\non 5 million paired medical images and texts and fine-tuned using 100,000\nchronic TB-specific chest X-rays.\n  Results: The model demonstrated high precision (94 percent) and recall (94\npercent) for detecting key chronic TB pathologies, including fibrosis,\ncalcified granulomas, and bronchiectasis. Area Under the Curve (AUC) scores\nexceeded 0.93, and Intersection over Union (IoU) values were above 0.91,\nvalidating its effectiveness in detecting and localizing TB-related\nabnormalities.\n  Conclusion: The VLM offers a robust and scalable solution for automated\nchronic TB diagnosis, integrating radiographic and clinical data to deliver\nactionable and context-aware insights. Future work will address subtle\npathologies and dataset biases to enhance the model's generalizability,\nensuring equitable performance across diverse populations and healthcare\nsettings.",
      "tldr_zh": "这项研究提出了一种基于 Vision-Language Model (VLM) 的多模态框架，使用 SIGLIP 编码器和 Gemma-3b 解码器，整合胸部 X 光图像与临床数据，以提升慢性结核病 (TB) 诊断的精确性和一致性，尤其适用于资源有限的环境。框架结合 Vision Transformer (ViT) 用于视觉编码、transformer-based 文本编码器处理患者历史，并通过跨模态注意力机制对齐放射特征与文本信息，最终生成全面诊断报告。模型在 500 万对医疗图像和文本上预训练，并在 10 万张慢性 TB 胸部 X 光上微调后，实现了 94% 的精确率和召回率，AUC 超过 0.93，IoU 超过 0.91，在检测纤维化、钙化肉芽肿和支气管扩张等病变方面表现出色。该框架为自动化 TB 筛查提供可扩展解决方案，并计划通过处理微妙病变和数据集偏差来提升泛化性和公平性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "68T07, 92C55, 68U10, 92C50, 60G35"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages , 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.14536v2",
      "published_date": "2025-03-17 13:49:29 UTC",
      "updated_date": "2025-03-28 11:00:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:08:54.560114"
    },
    {
      "arxiv_id": "2503.13169v1",
      "title": "Collaborative AI Enhances Image Understanding in Materials Science",
      "title_zh": "协作人工智能提升材料科学中的图像理解",
      "authors": [
        "Ruoyan Avery Yin",
        "Zhichu Ren",
        "Zongyou Yin",
        "Zhen Zhang",
        "So Yeon Kim",
        "Chia-Wei Hsu",
        "Ju Li"
      ],
      "abstract": "The Copilot for Real-world Experimental Scientist (CRESt) system empowers\nresearchers to control autonomous laboratories through conversational AI,\nproviding a seamless interface for managing complex experimental workflows. We\nhave enhanced CRESt by integrating a multi-agent collaboration mechanism that\nutilizes the complementary strengths of the ChatGPT and Gemini models for\nprecise image analysis in materials science. This innovative approach\nsignificantly improves the accuracy of experimental outcomes by fostering\nstructured debates between the AI models, which enhances decision-making\nprocesses in materials phase analysis. Additionally, to evaluate the\ngeneralizability of this approach, we tested it on a quantitative task of\ncounting particles. Here, the collaboration between the AI models also led to\nimproved results, demonstrating the versatility and robustness of this method.\nBy harnessing this dual-AI framework, this approach stands as a pioneering\nmethod for enhancing experimental accuracy and efficiency in materials\nresearch, with applications extending beyond CRESt to broader scientific\nexperimentation and analysis.",
      "tldr_zh": "该研究增强了Copilot for Real-world Experimental Scientist (CRESt)系统，通过整合ChatGPT和Gemini模型的多智能体协作机制，提高了材料科学中的图像理解准确性。该机制利用AI模型之间的结构化辩论，优化决策过程，从而显著改善材料相分析的实验结果，并在粒子计数等量化任务上展示了通用性和稳健性。通过这一双AI框架，研究为材料研究提供了创新方法，提升了实验效率，并扩展了其在更广泛科学实验中的应用。",
      "categories": [
        "cs.AI",
        "I.2.1; I.2.10"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13169v1",
      "published_date": "2025-03-17 13:44:30 UTC",
      "updated_date": "2025-03-17 13:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:09:04.352346"
    },
    {
      "arxiv_id": "2503.13575v1",
      "title": "Analytic Subspace Routing: How Recursive Least Squares Works in Continual Learning of Large Language Model",
      "title_zh": "Analytic Subspace Routing：",
      "authors": [
        "Kai Tong",
        "Kang Pan",
        "Xiao Zhang",
        "Erli Meng",
        "Run He",
        "Yawen Cui",
        "Nuoyan Guo",
        "Huiping Zhuang"
      ],
      "abstract": "Large Language Models (LLMs) possess encompassing capabilities that can\nprocess diverse language-related tasks. However, finetuning on LLMs will\ndiminish this general skills and continual finetuning will further cause severe\ndegradation on accumulated knowledge. Recently, Continual Learning (CL) in\nLarge Language Models (LLMs) arises which aims to continually adapt the LLMs to\nnew tasks while maintaining previously learned knowledge and inheriting general\nskills. Existing techniques either leverage previous data to replay, leading to\nextra computational costs, or utilize a single parameter-efficient module to\nlearn the downstream task, constraining new knowledge absorption with\ninterference between different tasks. Toward these issues, this paper proposes\nAnalytic Subspace Routing(ASR) to address these challenges. For each task, we\nisolate the learning within a subspace of deep layers' features via low-rank\nadaptation, eliminating knowledge interference between different tasks.\nAdditionally, we propose an analytic routing mechanism to properly utilize\nknowledge learned in different subspaces. Our approach employs Recursive Least\nSquares to train a multi-task router model, allowing the router to dynamically\nadapt to incoming data without requiring access to historical data. Also, the\nrouter effectively assigns the current task to an appropriate subspace and has\na non-forgetting property of previously learned tasks with a solid theoretical\nguarantee. Experimental results demonstrate that our method achieves\nnear-perfect retention of prior knowledge while seamlessly integrating new\ninformation, effectively overcoming the core limitations of existing methods.\nOur code will be released after acceptance.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在持续学习（Continual Learning）中的知识遗忘问题，提出Analytic Subspace Routing (ASR) 方法，以解决现有技术的高计算成本和任务间干扰问题。ASR 通过在深层特征子空间内应用 low-rank adaptation 隔离每个任务的学习，从而消除知识干扰，并使用 Recursive Least Squares 训练一个多任务路由器，使其动态适应新数据而不需访问历史数据，并理论上保证不忘记先前任务。实验结果表明，该方法实现了对先前知识的近乎完美保留，同时无缝整合新信息，显著超越了基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13575v1",
      "published_date": "2025-03-17 13:40:46 UTC",
      "updated_date": "2025-03-17 13:40:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:09:17.798269"
    },
    {
      "arxiv_id": "2503.13162v2",
      "title": "Efficient Imitation under Misspecification",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolas Espinosa-Dice",
        "Sanjiban Choudhury",
        "Wen Sun",
        "Gokul Swamy"
      ],
      "abstract": "We consider the problem of imitation learning under misspecification:\nsettings where the learner is fundamentally unable to replicate expert behavior\neverywhere. This is often true in practice due to differences in observation\nspace and action space expressiveness (e.g. perceptual or morphological\ndifferences between robots and humans). Given the learner must make some\nmistakes in the misspecified setting, interaction with the environment is\nfundamentally required to figure out which mistakes are particularly costly and\nlead to compounding errors. However, given the computational cost and safety\nconcerns inherent in interaction, we'd like to perform as little of it as\npossible while ensuring we've learned a strong policy. Accordingly, prior work\nhas proposed a flavor of efficient inverse reinforcement learning algorithms\nthat merely perform a computationally efficient local search procedure with\nstrong guarantees in the realizable setting. We first prove that under a novel\nstructural condition we term reward-agnostic policy completeness, these sorts\nof local-search based IRL algorithms are able to avoid compounding errors. We\nthen consider the question of where we should perform local search in the first\nplace, given the learner may not be able to \"walk on a tightrope\" as well as\nthe expert in the misspecified setting. We prove that in the misspecified\nsetting, it is beneficial to broaden the set of states on which local search is\nperformed to include those reachable by good policies the learner can actually\nplay. We then experimentally explore a variety of sources of misspecification\nand how offline data can be used to effectively broaden where we perform local\nsearch from.",
      "tldr_zh": "本研究探讨了在模型错配（misspecification）条件下进行高效模仿学习（imitation learning）的问题，即学习者由于观察空间和动作空间差异（如机器人与人类的感知差异）而无法完全复制专家行为。作者证明了在一种新结构条件“reward-agnostic policy completeness”下，基于局部搜索的逆强化学习（IRL）算法能够避免错误积累，从而减少环境互动。论文建议在错配设置中扩展局部搜索范围至学习者实际可达的状态，并通过实验验证了使用离线数据来有效拓宽搜索范围，从而提升策略性能。总的来说，此方法为处理错配场景提供了强有力的理论保证和实用策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "38 pages, 6 figures. Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13162v2",
      "published_date": "2025-03-17 13:35:55 UTC",
      "updated_date": "2025-04-02 16:32:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:09:28.495663"
    },
    {
      "arxiv_id": "2503.13149v1",
      "title": "Are LLMs (Really) Ideological? An IRT-based Analysis and Alignment Tool for Perceived Socio-Economic Bias in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jasmin Wachter",
        "Michael Radloff",
        "Maja Smolej",
        "Katharina Kinder-Kurlanda"
      ],
      "abstract": "We introduce an Item Response Theory (IRT)-based framework to detect and\nquantify socioeconomic bias in large language models (LLMs) without relying on\nsubjective human judgments. Unlike traditional methods, IRT accounts for item\ndifficulty, improving ideological bias estimation. We fine-tune two LLM\nfamilies (Meta-LLaMa 3.2-1B-Instruct and Chat- GPT 3.5) to represent distinct\nideological positions and introduce a two-stage approach: (1) modeling response\navoidance and (2) estimating perceived bias in answered responses. Our results\nshow that off-the-shelf LLMs often avoid ideological engagement rather than\nexhibit bias, challenging prior claims of partisanship. This empirically\nvalidated framework enhances AI alignment research and promotes fairer AI\ngovernance.",
      "tldr_zh": "本研究提出了一种基于Item Response Theory (IRT)的框架，用于检测和量化大型语言模型 (LLMs) 中的社会经济偏见，而不依赖主观人类判断，通过考虑项目难度来提升偏见估计的准确性。研究者微调了Meta-LLaMa 3.2-1B-Instruct和Chat-GPT 3.5两个LLM家族，以代表不同意识形态立场，并采用两阶段方法：首先建模响应回避，其次估计已回答响应的感知偏见。结果显示，现成的LLMs 更倾向于避免意识形态参与而非表现出偏见，从而挑战了之前的党派性主张；该框架有助于增强AI对齐研究并推动更公平的AI治理。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13149v1",
      "published_date": "2025-03-17 13:20:09 UTC",
      "updated_date": "2025-03-17 13:20:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:09:40.549272"
    },
    {
      "arxiv_id": "2503.13139v2",
      "title": "Logic-in-Frames: Dynamic Keyframe Search via Visual Semantic-Logical Verification for Long Video Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Weiyu Guo",
        "Ziyang Chen",
        "Shaoguang Wang",
        "Jianxiang He",
        "Yijie Xu",
        "Jinhui Ye",
        "Ying Sun",
        "Hui Xiong"
      ],
      "abstract": "Understanding long video content is a complex endeavor that often relies on\ndensely sampled frame captions or end-to-end feature selectors, yet these\ntechniques commonly overlook the logical relationships between textual queries\nand visual elements. In practice, computational constraints necessitate coarse\nframe subsampling, a challenge analogous to \"finding a needle in a haystack.\"\nTo address this issue, we introduce a semantics-driven search framework that\nreformulates keyframe selection under the paradigm of Visual Semantic-Logical\nSearch. Specifically, we systematically define four fundamental logical\ndependencies: 1) spatial co-occurrence, 2) temporal proximity, 3) attribute\ndependency, and 4) causal order. These relations dynamically update frame\nsampling distributions through an iterative refinement process, enabling\ncontext-aware identification of semantically critical frames tailored to\nspecific query requirements. Our method establishes new SOTA performance on the\nmanually annotated benchmark in key-frame selection metrics. Furthermore, when\napplied to downstream video question-answering tasks, the proposed approach\ndemonstrates the best performance gains over existing methods on LongVideoBench\nand Video-MME, validating its effectiveness in bridging the logical gap between\ntextual queries and visual-temporal reasoning. The code will be publicly\navailable.",
      "tldr_zh": "这篇论文提出了Logic-in-Frames框架，通过Visual Semantic-Logical Verification动态搜索关键帧，以解决长视频理解中文本查询与视觉元素逻辑关系的忽略问题。框架定义了四种基本逻辑依赖，包括spatial co-occurrence、temporal proximity、attribute dependency和causal order，并通过迭代精炼过程动态更新帧采样分布，实现与查询相关的语义关键帧识别。在关键帧选择指标上，该方法在手动标注基准上达到了新的SOTA性能，并在下游视频问答任务上（如LongVideoBench和Video-MME）实现了最佳性能提升，证明了其在桥接文本与视觉-时间推理逻辑差距方面的有效性。代码将公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "32 pages, under review",
      "pdf_url": "http://arxiv.org/pdf/2503.13139v2",
      "published_date": "2025-03-17 13:07:34 UTC",
      "updated_date": "2025-05-17 13:22:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:09:53.455978"
    },
    {
      "arxiv_id": "2503.13123v1",
      "title": "MIXPINN: Mixed-Material Simulations by Physics-Informed Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Xintian Yuan",
        "Yunke Ao",
        "Boqi Chen",
        "Philipp Fuernstahl"
      ],
      "abstract": "Simulating the complex interactions between soft tissues and rigid anatomy is\ncritical for applications in surgical training, planning, and robotic-assisted\ninterventions. Traditional Finite Element Method (FEM)-based simulations, while\naccurate, are computationally expensive and impractical for real-time\nscenarios. Learning-based approaches have shown promise in accelerating\npredictions but have fallen short in modeling soft-rigid interactions\neffectively. We introduce MIXPINN, a physics-informed Graph Neural Network\n(GNN) framework for mixed-material simulations, explicitly capturing soft-rigid\ninteractions using graph-based augmentations. Our approach integrates Virtual\nNodes (VNs) and Virtual Edges (VEs) to enhance rigid body constraint\nsatisfaction while preserving computational efficiency. By leveraging a\ngraph-based representation of biomechanical structures, MIXPINN learns\nhigh-fidelity deformations from FEM-generated data and achieves real-time\ninference with sub-millimeter accuracy. We validate our method in a realistic\nclinical scenario, demonstrating superior performance compared to baseline GNN\nmodels and traditional FEM methods. Our results show that MIXPINN reduces\ncomputational cost by an order of magnitude while maintaining high physical\naccuracy, making it a viable solution for real-time surgical simulation and\nrobotic-assisted procedures.",
      "tldr_zh": "本研究针对软组织与刚性解剖结构的互动模拟问题，提出了一种基于Physics-Informed Neural Network的框架MIXPINN，以解决传统Finite Element Method (FEM)计算开销大和学习方法在软-刚互动上的不足。MIXPINN采用Graph Neural Network (GNN)并通过Virtual Nodes (VNs)和Virtual Edges (VEs)增强图-based表示，实现刚性约束的精确捕捉，同时保持高效计算。实验在真实临床场景中验证，该框架从FEM数据学习高保真变形，实现实时推理并达到亚毫米精度，比基线GNN和传统FEM方法减少计算成本一个数量级，同时维持高物理准确性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "This work has been submitted to the lEEE IROS 2025 for possible\n  publication",
      "pdf_url": "http://arxiv.org/pdf/2503.13123v1",
      "published_date": "2025-03-17 12:48:29 UTC",
      "updated_date": "2025-03-17 12:48:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:10:05.242318"
    },
    {
      "arxiv_id": "2503.13115v1",
      "title": "Beyond Propagation of Chaos: A Stochastic Algorithm for Mean Field Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Chandan Tankala",
        "Dheeraj M. Nagaraj",
        "Anant Raj"
      ],
      "abstract": "Gradient flow in the 2-Wasserstein space is widely used to optimize\nfunctionals over probability distributions and is typically implemented using\nan interacting particle system with $n$ particles. Analyzing these algorithms\nrequires showing (a) that the finite-particle system converges and/or (b) that\nthe resultant empirical distribution of the particles closely approximates the\noptimal distribution (i.e., propagation of chaos). However, establishing\nefficient sufficient conditions can be challenging, as the finite particle\nsystem may produce heavily dependent random variables.\n  In this work, we study the virtual particle stochastic approximation,\noriginally introduced for Stein Variational Gradient Descent. This method can\nbe viewed as a form of stochastic gradient descent in the Wasserstein space and\ncan be implemented efficiently. In popular settings, we demonstrate that our\nalgorithm's output converges to the optimal distribution under conditions\nsimilar to those for the infinite particle limit, and it produces i.i.d.\nsamples without the need to explicitly establish propagation of chaos bounds.",
      "tldr_zh": "这篇论文超越了传统混沌传播（Propagation of Chaos）的框架，提出了一种虚拟粒子随机逼近算法，用于均场优化（Mean Field Optimization）。该算法可视为2-Wasserstein空间中的随机梯度下降（Stochastic Gradient Descent），并能高效实现，通过处理互动粒子系统的依赖性问题。研究显示，在流行设置下，该方法在类似于无限粒子极限的条件下收敛到最优分布，并直接产生独立同分布（i.i.d.）样本，而无需显式建立混沌传播界。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.PR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13115v1",
      "published_date": "2025-03-17 12:37:53 UTC",
      "updated_date": "2025-03-17 12:37:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:10:17.781949"
    },
    {
      "arxiv_id": "2503.13108v1",
      "title": "Lifting the Veil on Visual Information Flow in MLLMs: Unlocking Pathways to Faster Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Yin",
        "Guangzong Si",
        "Zilei Wang"
      ],
      "abstract": "Multimodal large language models (MLLMs) improve performance on\nvision-language tasks by integrating visual features from pre-trained vision\nencoders into large language models (LLMs). However, how MLLMs process and\nutilize visual information remains unclear. In this paper, a shift in the\ndominant flow of visual information is uncovered: (1) in shallow layers, strong\ninteractions are observed between image tokens and instruction tokens, where\nmost visual information is injected into instruction tokens to form cross-modal\nsemantic representations; (2) in deeper layers, image tokens primarily interact\nwith each other, aggregating the remaining visual information to optimize\nsemantic representations within visual modality. Based on these insights, we\npropose Hierarchical Modality-Aware Pruning (HiMAP), a plug-and-play inference\nacceleration method that dynamically prunes image tokens at specific layers,\nreducing computational costs by approximately 65% without sacrificing\nperformance. Our findings offer a new understanding of visual information\nprocessing in MLLMs and provide a state-of-the-art solution for efficient\ninference.",
      "tldr_zh": "本研究揭示了多模态大语言模型(MLLMs)中视觉信息流动的机制：在浅层，图像 tokens 与指令 tokens 强烈互动，将大部分视觉信息注入以形成跨模态语义表示；在深层，图像 tokens 主要相互聚合，优化视觉模态内的语义表示。基于这些发现，作者提出 Hierarchical Modality-Aware Pruning (HiMAP)，一种即插即用的推理加速方法，通过动态修剪特定层的图像 tokens，减少约65%的计算成本，同时保持性能不变。该工作为理解MLLMs的视觉处理提供新见解，并推动高效推理的实际应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13108v1",
      "published_date": "2025-03-17 12:31:23 UTC",
      "updated_date": "2025-03-17 12:31:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:10:29.160219"
    },
    {
      "arxiv_id": "2503.13107v1",
      "title": "ClearSight: Visual Signal Enhancement for Object Hallucination Mitigation in Multimodal Large language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Yin",
        "Guangzong Si",
        "Zilei Wang"
      ],
      "abstract": "Contrastive decoding strategies are widely used to mitigate object\nhallucinations in multimodal large language models (MLLMs). By reducing\nover-reliance on language priors, these strategies ensure that generated\ncontent remains closely grounded in visual inputs, producing contextually\naccurate outputs. Since contrastive decoding requires no additional training or\nexternal tools, it offers both computational efficiency and versatility, making\nit highly attractive. However, these methods present two main limitations: (1)\nbluntly suppressing language priors can compromise coherence and accuracy of\ngenerated content, and (2) processing contrastive inputs adds computational\nload, significantly slowing inference speed. To address these challenges, we\npropose Visual Amplification Fusion (VAF), a plug-and-play technique that\nenhances attention to visual signals within the model's middle layers, where\nmodality fusion predominantly occurs. This approach enables more effective\ncapture of visual features, reducing the model's bias toward language modality.\nExperimental results demonstrate that VAF significantly reduces hallucinations\nacross various MLLMs without affecting inference speed, while maintaining\ncoherence and accuracy in generated outputs.",
      "tldr_zh": "这项研究针对多模态大语言模型(MLLMs)中物体幻觉的问题，分析了对比解码策略的局限性，包括抑制语言先验可能损害生成内容的连贯性和准确性，以及增加计算负载导致推理速度变慢。  \n为了解决这些挑战，提出了一种即插即用的技术Visual Amplification Fusion (VAF)，通过在模型中间层增强对视觉信号的注意力，提高视觉特征捕捉并减少对语言模态的偏见。  \n实验结果表明，VAF显著降低了各种MLLMs中的幻觉发生率，同时不影响推理速度，并保持了生成输出的连贯性和准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13107v1",
      "published_date": "2025-03-17 12:30:40 UTC",
      "updated_date": "2025-03-17 12:30:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:10:43.258845"
    },
    {
      "arxiv_id": "2503.14535v1",
      "title": "Interpretable Unsupervised Joint Denoising and Enhancement for Real-World low-light Scenarios",
      "title_zh": "可解释的无监督联合去噪和增强，用于真实世界低光场景",
      "authors": [
        "Huaqiu Li",
        "Xiaowan Hu",
        "Haoqian Wang"
      ],
      "abstract": "Real-world low-light images often suffer from complex degradations such as\nlocal overexposure, low brightness, noise, and uneven illumination. Supervised\nmethods tend to overfit to specific scenarios, while unsupervised methods,\nthough better at generalization, struggle to model these degradations due to\nthe lack of reference images. To address this issue, we propose an\ninterpretable, zero-reference joint denoising and low-light enhancement\nframework tailored for real-world scenarios. Our method derives a training\nstrategy based on paired sub-images with varying illumination and noise levels,\ngrounded in physical imaging principles and retinex theory. Additionally, we\nleverage the Discrete Cosine Transform (DCT) to perform frequency domain\ndecomposition in the sRGB space, and introduce an implicit-guided hybrid\nrepresentation strategy that effectively separates intricate compounded\ndegradations. In the backbone network design, we develop retinal decomposition\nnetwork guided by implicit degradation representation mechanisms. Extensive\nexperiments demonstrate the superiority of our method. Code will be available\nat https://github.com/huaqlili/unsupervised-light-enhance-ICLR2025.",
      "tldr_zh": "本论文提出了一种可解释的无监督联合去噪和增强框架，针对真实世界低光照场景中的复杂退化，如局部过曝、低亮度和噪声问题。该方法基于物理成像原理和Retinex理论，采用配对子图像训练策略，并利用Discrete Cosine Transform (DCT)进行sRGB空间的频率域分解，同时引入隐式引导的混合表示策略来有效分离复合退化。实验结果表明，该框架在广泛测试中优于现有方法，提供更强的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.14535v1",
      "published_date": "2025-03-17 12:08:52 UTC",
      "updated_date": "2025-03-17 12:08:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:10:53.901849"
    },
    {
      "arxiv_id": "2503.13570v1",
      "title": "ExChanGeAI: An End-to-End Platform and Efficient Foundation Model for Electrocardiogram Analysis and Fine-tuning",
      "title_zh": "ExChanGeAI：端到端平台和高效基础模型，用于心电图分析和微调",
      "authors": [
        "Lucas Bickmann",
        "Lucas Plagwitz",
        "Antonius Büscher",
        "Lars Eckardt",
        "Julian Varghese"
      ],
      "abstract": "Electrocardiogram data, one of the most widely available biosignal data, has\nbecome increasingly valuable with the emergence of deep learning methods,\nproviding novel insights into cardiovascular diseases and broader health\nconditions. However, heterogeneity of electrocardiogram formats, limited access\nto deep learning model weights and intricate algorithmic steps for effective\nfine-tuning for own disease target labels result in complex workflows. In this\nwork, we introduce ExChanGeAI, a web-based end-to-end platform that streamlines\nthe reading of different formats, pre-processing, visualization and custom\nmachine learning with local and privacy-preserving fine-tuning. ExChanGeAI is\nadaptable for use on both personal computers and scalable to high performance\nserver environments. The platform offers state-of-the-art deep learning models\nfor training from scratch, alongside our novel open-source electrocardiogram\nfoundation model CardX, pre-trained on over one million electrocardiograms.\nEvaluation across three external validation sets, including an entirely new\ntestset extracted from routine care, demonstrate the fine-tuning capabilities\nof ExChanGeAI. CardX outperformed the benchmark foundation model while\nrequiring significantly fewer parameters and lower computational resources. The\nplatform enables users to empirically determine the most suitable model for\ntheir specific tasks based on systematic validations.The code is available at\nhttps://imigitlab.uni-muenster.de/published/exchangeai .",
      "tldr_zh": "该研究推出了 ExChanGeAI，一个基于网络的端到端平台，用于简化心电图(Electrocardiogram)数据的处理、预处理、可视化和自定义机器学习，支持本地隐私保护的 Fine-tuning，并适用于个人电脑或高性能服务器环境。平台集成了先进的深度学习模型和新型开源基础模型 CardX，后者基于超过一百万的心电图数据进行预训练。实验结果显示，CardX 在三个外部验证集上优于基准模型，同时使用更少的参数和计算资源；该平台还允许用户通过系统验证选择最适合的任务模型，并提供开源代码以促进实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13570v1",
      "published_date": "2025-03-17 11:58:52 UTC",
      "updated_date": "2025-03-17 11:58:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:11:05.674503"
    },
    {
      "arxiv_id": "2503.13089v1",
      "title": "ClusComp: A Simple Paradigm for Model Compression and Efficient Finetuning",
      "title_zh": "ClusComp：一种简单的模型压缩和高效微调范式",
      "authors": [
        "Baohao Liao",
        "Christian Herold",
        "Seyyed Hadi Hashemi",
        "Stefan Vasilev",
        "Shahram Khadivi",
        "Christof Monz"
      ],
      "abstract": "As large language models (LLMs) scale, model compression is crucial for edge\ndeployment and accessibility. Weight-only quantization reduces model size but\nsuffers from performance degradation at lower bit widths. Moreover, standard\nfinetuning is incompatible with quantized models, and alternative methods often\nfall short of full finetuning. In this paper, we propose ClusComp, a simple yet\neffective compression paradigm that clusters weight matrices into codebooks and\nfinetunes them block-by-block. ClusComp (1) achieves superior performance in\n2-4 bit quantization, (2) pushes compression to 1-bit while outperforming\nultra-low-bit methods with minimal finetuning, and (3) enables efficient\nfinetuning, even surpassing existing quantization-based approaches and rivaling\nfull FP16 finetuning. Notably, ClusComp supports compression and finetuning of\n70B LLMs on a single A6000-48GB GPU.",
      "tldr_zh": "该论文提出ClusComp，一种简单有效的模型压缩范式，通过将权重矩阵聚类到codebooks并进行块-by-block的微调，解决大型语言模型(LLMs)压缩中的性能下降问题。ClusComp在2-4 bit quantization中表现出色，并在1-bit量化时超越现有方法，同时仅需最小微调；它还支持高效fintuning，甚至优于现有quantization-based方法，并可与全FP16 finetuning相媲美。值得注意的是，ClusComp能够在单个A6000-48GB GPU上处理70B LLMs的压缩和微调，提升了模型的边缘部署和可访问性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 11 figures, 18 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.13089v1",
      "published_date": "2025-03-17 11:52:16 UTC",
      "updated_date": "2025-03-17 11:52:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:11:17.840232"
    },
    {
      "arxiv_id": "2503.13082v1",
      "title": "Free-form language-based robotic reasoning and grasping",
      "title_zh": "基于自由形式语言的机器人推理和抓取",
      "authors": [
        "Runyu Jiao",
        "Alice Fasoli",
        "Francesco Giuliari",
        "Matteo Bortolon",
        "Sergio Povoli",
        "Guofeng Mei",
        "Yiming Wang",
        "Fabio Poiesi"
      ],
      "abstract": "Performing robotic grasping from a cluttered bin based on human instructions\nis a challenging task, as it requires understanding both the nuances of\nfree-form language and the spatial relationships between objects.\nVision-Language Models (VLMs) trained on web-scale data, such as GPT-4o, have\ndemonstrated remarkable reasoning capabilities across both text and images. But\ncan they truly be used for this task in a zero-shot setting? And what are their\nlimitations? In this paper, we explore these research questions via the\nfree-form language-based robotic grasping task, and propose a novel method,\nFreeGrasp, leveraging the pre-trained VLMs' world knowledge to reason about\nhuman instructions and object spatial arrangements. Our method detects all\nobjects as keypoints and uses these keypoints to annotate marks on images,\naiming to facilitate GPT-4o's zero-shot spatial reasoning. This allows our\nmethod to determine whether a requested object is directly graspable or if\nother objects must be grasped and removed first. Since no existing dataset is\nspecifically designed for this task, we introduce a synthetic dataset\nFreeGraspData by extending the MetaGraspNetV2 dataset with human-annotated\ninstructions and ground-truth grasping sequences. We conduct extensive analyses\nwith both FreeGraspData and real-world validation with a gripper-equipped\nrobotic arm, demonstrating state-of-the-art performance in grasp reasoning and\nexecution. Project website: https://tev-fbk.github.io/FreeGrasp/.",
      "tldr_zh": "这篇论文探讨了基于自由形式语言的机器人抓取任务，提出FreeGrasp方法，利用预训练的Vision-Language Models (VLMs)如GPT-4o进行零样本推理，以理解人类指令和物体空间关系。方法通过检测物体作为关键点并在图像上标注，辅助模型判断物体是否直接可抓取或需先移除其他物体；同时，引入了新的合成数据集FreeGraspData，基于MetaGraspNetV2添加人类注释和抓取序列。实验结果显示，FreeGrasp在合成数据集和真实机器人臂验证中实现了抓取推理和执行的最先进性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: https://tev-fbk.github.io/FreeGrasp/",
      "pdf_url": "http://arxiv.org/pdf/2503.13082v1",
      "published_date": "2025-03-17 11:41:16 UTC",
      "updated_date": "2025-03-17 11:41:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:11:30.360030"
    },
    {
      "arxiv_id": "2503.16523v1",
      "title": "Mind2: Mind-to-Mind Emotional Support System with Bidirectional Cognitive Discourse Analysis",
      "title_zh": "Mind2：心智到心智情感支持系统，带有双向认知话语分析",
      "authors": [
        "Shi Yin Hong",
        "Uttamasha Oyshi",
        "Quan Mai",
        "Gibson Nkhata",
        "Susan Gauch"
      ],
      "abstract": "Emotional support (ES) systems alleviate users' mental distress by generating\nstrategic supportive dialogues based on diverse user situations. However, ES\nsystems are limited in their ability to generate effective ES dialogues that\ninclude timely context and interpretability, hindering them from earning public\ntrust. Driven by cognitive models, we propose Mind-to-Mind (Mind2), an ES\nframework that approaches interpretable ES context modeling for the ES dialogue\ngeneration task from a discourse analysis perspective. Specifically, we perform\ncognitive discourse analysis on ES dialogues according to our dynamic discourse\ncontext propagation window, which accommodates evolving context as the\nconversation between the ES system and user progresses. To enhance\ninterpretability, Mind2 prioritizes details that reflect each speaker's belief\nabout the other speaker with bidirectionality, integrating Theory-of-Mind,\nphysiological expected utility, and cognitive rationality to extract cognitive\nknowledge from ES conversations. Experimental results support that Mind2\nachieves competitive performance versus state-of-the-art ES systems while\ntrained with only 10\\% of the available training data.",
      "tldr_zh": "该研究提出Mind2框架，一种基于双向认知话语分析的心理支持系统，旨在通过可解释的上下文建模来生成更有效的情感支持（ES）对话，解决现有系统在及时性和可信度方面的局限性。Mind2采用动态话语上下文传播窗口进行认知话语分析，并整合Theory-of-Mind、生理预期效用和认知理性，从ES对话中提取双向信念知识，以提升系统的解释性和适应性。实验结果显示，Mind2仅使用10%的训练数据，便在性能上与最先进ES系统相当，为构建可信赖的心理支持系统提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 2 figures, and 3 tables; WI-IAT 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.16523v1",
      "published_date": "2025-03-17 11:39:56 UTC",
      "updated_date": "2025-03-17 11:39:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:11:40.898493"
    },
    {
      "arxiv_id": "2503.13081v1",
      "title": "A Framework to Assess Multilingual Vulnerabilities of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Likai Tang",
        "Niruth Bogahawatta",
        "Yasod Ginige",
        "Jiarui Xu",
        "Shixuan Sun",
        "Surangika Ranathunga",
        "Suranga Seneviratne"
      ],
      "abstract": "Large Language Models (LLMs) are acquiring a wider range of capabilities,\nincluding understanding and responding in multiple languages. While they\nundergo safety training to prevent them from answering illegal questions,\nimbalances in training data and human evaluation resources can make these\nmodels more susceptible to attacks in low-resource languages (LRL). This paper\nproposes a framework to automatically assess the multilingual vulnerabilities\nof commonly used LLMs. Using our framework, we evaluated six LLMs across eight\nlanguages representing varying levels of resource availability. We validated\nthe assessments generated by our automated framework through human evaluation\nin two languages, demonstrating that the framework's results align with human\njudgments in most cases. Our findings reveal vulnerabilities in LRL; however,\nthese may pose minimal risk as they often stem from the model's poor\nperformance, resulting in incoherent responses.",
      "tldr_zh": "本论文提出一个框架，用于自动评估大型语言模型（LLMs）的多语言漏洞，特别是由于训练数据失衡而导致的低资源语言（LRL）易受攻击问题。该框架评估了六个LLMs在八种不同资源水平语言上的表现，并通过人类评估在两种语言中验证其结果，与人类判断高度一致。研究发现，LLMs在LRL中确实存在漏洞，但这些漏洞往往源于模型性能低下，导致响应不连贯，从而可能带来的风险较小。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13081v1",
      "published_date": "2025-03-17 11:39:44 UTC",
      "updated_date": "2025-03-17 11:39:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:11:53.490275"
    },
    {
      "arxiv_id": "2503.13055v1",
      "title": "Mitigating Cross-Modal Distraction and Ensuring Geometric Feasibility via Affordance-Guided, Self-Consistent MLLMs for Food Preparation Task Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Hong Shen",
        "Chuan-Yu Wu",
        "Yi-Ru Yang",
        "Yen-Ling Tai",
        "Yi-Ting Chen"
      ],
      "abstract": "We study Multimodal Large Language Models (MLLMs) with in-context learning\nfor food preparation task planning. In this context, we identify two key\nchallenges: cross-modal distraction and geometric feasibility. Cross-modal\ndistraction occurs when the inclusion of visual input degrades the reasoning\nperformance of a MLLM. Geometric feasibility refers to the ability of MLLMs to\nensure that the selected skills are physically executable in the environment.\nTo address these issues, we adapt Chain of Thought (CoT) with Self-Consistency\nto mitigate reasoning loss from cross-modal distractions and use affordance\npredictor as skill preconditions to guide MLLM on geometric feasibility. We\nconstruct a dataset to evaluate the ability of MLLMs on quantity estimation,\nreachability analysis, relative positioning and collision avoidance. We\nconducted a detailed evaluation to identify issues among different baselines\nand analyze the reasons for improvement, providing insights into each approach.\nOur method reaches a success rate of 76.7% on the entire dataset, showing a\nsubstantial improvement over the CoT baseline at 36.7%.",
      "tldr_zh": "本研究探讨多模态大语言模型(MLLMs)在食物准备任务规划中的应用，针对跨模态干扰(cross-modal distraction)和几何可行性(geometric feasibility)两大挑战提出改进方法。研究者将Chain of Thought (CoT)与Self-Consistency相结合，以缓解视觉输入对推理性能的负面影响，并使用affordance predictor作为技能先决条件，确保任务在环境中物理可执行。实验通过构建的数据集评估了MLLMs在数量估计、reachability analysis、relative positioning和collision avoidance等方面的表现，结果显示该方法在整个数据集上达到了76.7%的成功率，比CoT基线36.7%有显著提升。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13055v1",
      "published_date": "2025-03-17 11:01:02 UTC",
      "updated_date": "2025-03-17 11:01:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:12:06.348341"
    },
    {
      "arxiv_id": "2503.13568v1",
      "title": "WMINet: A Wheel-Mounted Inertial Learning Approach For Mobile-Robot Positioning",
      "title_zh": "翻译失败",
      "authors": [
        "Gal Versano",
        "Itzik Klein"
      ],
      "abstract": "Autonomous mobile robots are widely used for navigation, transportation, and\ninspection tasks indoors and outdoors. In practical situations of limited\nsatellite signals or poor lighting conditions, navigation depends only on\ninertial sensors. In such cases, the navigation solution rapidly drifts due to\ninertial measurement errors. In this work, we propose WMINet a wheel-mounted\ninertial deep learning approach to estimate the mobile robot's position based\nonly on its inertial sensors. To that end, we merge two common practical\nmethods to reduce inertial drift: a wheel-mounted approach and driving the\nmobile robot in periodic trajectories. Additionally, we enforce a wheelbase\nconstraint to further improve positioning performance. To evaluate our proposed\napproach we recorded using the Rosbot-XL a wheel-mounted initial dataset\ntotaling 190 minutes, which is made publicly available. Our approach\ndemonstrated a 66\\% improvement over state-of-the-art approaches. As a\nconsequence, our approach enables navigation in challenging environments and\nbridges the pure inertial gap. This enables seamless robot navigation using\nonly inertial sensors for short periods.",
      "tldr_zh": "这篇论文提出了WMINet，一种基于轮载惯性传感器的深度学习方法，用于在卫星信号或光线不足的环境中估计移动机器人的位置，从而解决惯性测量错误导致的导航漂移问题。该方法结合轮载方法、周期轨迹驱动和轮距约束来减少漂移，并使用Rosbot-XL录制的190分钟公开数据集进行评估。实验结果显示，WMINet比现有方法提高了66%的定位性能，实现纯惯性传感器在挑战性环境中的无缝导航。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13568v1",
      "published_date": "2025-03-17 10:43:46 UTC",
      "updated_date": "2025-03-17 10:43:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:12:17.610493"
    },
    {
      "arxiv_id": "2503.13025v1",
      "title": "PoseSyn: Synthesizing Diverse 3D Pose Data from In-the-Wild 2D Data",
      "title_zh": "翻译失败",
      "authors": [
        "ChangHee Yang",
        "Hyeonseop Song",
        "Seokhun Choi",
        "Seungwoo Lee",
        "Jaechul Kim",
        "Hoseok Do"
      ],
      "abstract": "Despite considerable efforts to enhance the generalization of 3D pose\nestimators without costly 3D annotations, existing data augmentation methods\nstruggle in real world scenarios with diverse human appearances and complex\nposes. We propose PoseSyn, a novel data synthesis framework that transforms\nabundant in the wild 2D pose dataset into diverse 3D pose image pairs. PoseSyn\ncomprises two key components: Error Extraction Module (EEM), which identifies\nchallenging poses from the 2D pose datasets, and Motion Synthesis Module (MSM),\nwhich synthesizes motion sequences around the challenging poses. Then, by\ngenerating realistic 3D training data via a human animation model aligned with\nchallenging poses and appearances PoseSyn boosts the accuracy of various 3D\npose estimators by up to 14% across real world benchmarks including various\nbackgrounds and occlusions, challenging poses, and multi view scenarios.\nExtensive experiments further confirm that PoseSyn is a scalable and effective\napproach for improving generalization without relying on expensive 3D\nannotations, regardless of the pose estimator's model size or design.",
      "tldr_zh": "该研究针对现有 3D 姿势估计器在真实世界场景中泛化能力不足的问题，提出 PoseSyn 框架，该框架将丰富的野外 2D 姿势数据集转化为多样化的 3D 姿势图像对。PoseSyn 包括 Error Extraction Module (EEM) 用于识别挑战性姿势，以及 Motion Synthesis Module (MSM) 用于合成这些姿势周围的动作序列，并通过人类动画模型生成与外观对齐的真实 3D 训练数据。实验结果显示，PoseSyn 可将多种 3D 姿势估计器的准确率提高高达 14%，在包括不同背景、遮挡、挑战性姿势和多视图场景的基准上表现出色。该方法无需昂贵的 3D 标注，即可实现可扩展的泛化提升，无论模型大小或设计如何。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The first three authors contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2503.13025v1",
      "published_date": "2025-03-17 10:28:35 UTC",
      "updated_date": "2025-03-17 10:28:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:12:31.430437"
    },
    {
      "arxiv_id": "2503.13012v1",
      "title": "Test-Time Domain Generalization via Universe Learning: A Multi-Graph Matching Approach for Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Xingguo Lv",
        "Xingbo Dong",
        "Liwen Wang",
        "Jiewen Yang",
        "Lei Zhao",
        "Bin Pu",
        "Zhe Jin",
        "Xuejun Li"
      ],
      "abstract": "Despite domain generalization (DG) has significantly addressed the\nperformance degradation of pre-trained models caused by domain shifts, it often\nfalls short in real-world deployment. Test-time adaptation (TTA), which adjusts\na learned model using unlabeled test data, presents a promising solution.\nHowever, most existing TTA methods struggle to deliver strong performance in\nmedical image segmentation, primarily because they overlook the crucial prior\nknowledge inherent to medical images. To address this challenge, we incorporate\nmorphological information and propose a framework based on multi-graph\nmatching. Specifically, we introduce learnable universe embeddings that\nintegrate morphological priors during multi-source training, along with novel\nunsupervised test-time paradigms for domain adaptation. This approach\nguarantees cycle-consistency in multi-matching while enabling the model to more\neffectively capture the invariant priors of unseen data, significantly\nmitigating the effects of domain shifts. Extensive experiments demonstrate that\nour method outperforms other state-of-the-art approaches on two medical image\nsegmentation benchmarks for both multi-source and single-source domain\ngeneralization tasks. The source code is available at\nhttps://github.com/Yore0/TTDG-MGM.",
      "tldr_zh": "本文提出了一种基于多图匹配（Multi-Graph Matching）的测试时域泛化（Test-Time Domain Generalization）框架，用于医疗图像分割，以解决现有测试时适应（Test-Time Adaptation）方法忽略形态学先验知识导致的性能问题。框架引入可学习的宇宙嵌入（learnable universe embeddings）来整合形态学先验，并在多源训练中实现新的无监督测试时范式，确保多匹配的循环一致性（cycle-consistency），从而更好地捕捉未见数据的不变先验并缓解领域偏移（domain shifts）。实验结果表明，该方法在两个医疗图像分割基准上优于最先进方法，在多源和单源域泛化任务中显著提升了性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13012v1",
      "published_date": "2025-03-17 10:11:11 UTC",
      "updated_date": "2025-03-17 10:11:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:12:42.754232"
    },
    {
      "arxiv_id": "2503.12999v2",
      "title": "Concept-as-Tree: Synthetic Data is All You Need for VLM Personalization",
      "title_zh": "Concept-as-Tree：合成数据就是你所需要的一切，用于 VLM 个性化",
      "authors": [
        "Ruichuan An",
        "Kai Zeng",
        "Ming Lu",
        "Sihan Yang",
        "Renrui Zhang",
        "Huitong Ji",
        "Qizhe Zhang",
        "Yulin Luo",
        "Hao Liang",
        "Wentao Zhang"
      ],
      "abstract": "Vision-Language Models (VLMs) have demonstrated exceptional performance in\nvarious multi-modal tasks. Recently, there has been an increasing interest in\nimproving the personalization capabilities of VLMs. To better integrate\nuser-provided concepts into VLMs, many methods use positive and negative\nsamples to fine-tune these models. However, the scarcity of user-provided\npositive samples and the low quality of retrieved negative samples pose\nchallenges for fine-tuning. To reveal the relationship between sample and model\nperformance, we systematically investigate the impact of positive and negative\nsamples (easy and hard) and their diversity on VLM personalization tasks. Based\non the detailed analysis, we introduce Concept-as-Tree (CaT), which represents\na concept as a tree structure, thereby enabling the data generation of positive\nand negative samples with varying difficulty and diversity for VLM\npersonalization. With a well-designed data filtering strategy, our CaT\nframework can ensure the quality of generated data, constituting a powerful\npipeline. We perform thorough experiments with various VLM personalization\nbaselines to assess the effectiveness of the pipeline, alleviating the lack of\npositive samples and the low quality of negative samples. Our results\ndemonstrate that CaT equipped with the proposed data filter significantly\nenhances the personalization capabilities of VLMs across the MyVLM, Yo'LLaVA,\nand MC-LLaVA datasets. To our knowledge, this work is the first controllable\nsynthetic data pipeline for VLM personalization. The code is released at\n$\\href{https://github.com/zengkaiya/CaT}{\\text{https://github.com/zengkaiya/CaT}}$.",
      "tldr_zh": "本研究探讨了视觉语言模型（VLM）的个性化能力问题，指出现有方法依赖正负样本微调时面临正样本稀缺和负样本质量低下的挑战。论文提出Concept-as-Tree (CaT)框架，将概念表示为树结构，生成多样性和不同难度的合成正负样本，并结合数据过滤策略确保数据质量，从而构建了一个高效的合成数据管道。实验结果显示，CaT显著提升了VLMs在MyVLM、Yo'LLaVA和MC-LLaVA数据集上的个性化性能，与基线模型相比表现出色；这也是首个可控的合成数据管道，为VLM个性化提供新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The code is released at\n  $\\href{https://github.com/zengkaiya/CaT}{\\text{https://github.com/zengkaiya/CaT}}$",
      "pdf_url": "http://arxiv.org/pdf/2503.12999v2",
      "published_date": "2025-03-17 09:55:01 UTC",
      "updated_date": "2025-03-23 06:45:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:12:53.292730"
    },
    {
      "arxiv_id": "2503.12993v1",
      "title": "Robot Policy Transfer with Online Demonstrations: An Active Reinforcement Learning Approach",
      "title_zh": "机器人策略转移使用在线演示：",
      "authors": [
        "Muhan Hou",
        "Koen Hindriks",
        "A. E. Eiben",
        "Kim Baraka"
      ],
      "abstract": "Transfer Learning (TL) is a powerful tool that enables robots to transfer\nlearned policies across different environments, tasks, or embodiments. To\nfurther facilitate this process, efforts have been made to combine it with\nLearning from Demonstrations (LfD) for more flexible and efficient policy\ntransfer. However, these approaches are almost exclusively limited to offline\ndemonstrations collected before policy transfer starts, which may suffer from\nthe intrinsic issue of covariance shift brought by LfD and harm the performance\nof policy transfer. Meanwhile, extensive work in the learning-from-scratch\nsetting has shown that online demonstrations can effectively alleviate\ncovariance shift and lead to better policy performance with improved sample\nefficiency. This work combines these insights to introduce online\ndemonstrations into a policy transfer setting. We present Policy Transfer with\nOnline Demonstrations, an active LfD algorithm for policy transfer that can\noptimize the timing and content of queries for online episodic expert\ndemonstrations under a limited demonstration budget. We evaluate our method in\neight robotic scenarios, involving policy transfer across diverse environment\ncharacteristics, task objectives, and robotic embodiments, with the aim to\ntransfer a trained policy from a source task to a related but different target\ntask. The results show that our method significantly outperforms all baselines\nin terms of average success rate and sample efficiency, compared to two\ncanonical LfD methods with offline demonstrations and one active LfD method\nwith online demonstrations. Additionally, we conduct preliminary sim-to-real\ntests of the transferred policy on three transfer scenarios in the real-world\nenvironment, demonstrating the policy effectiveness on a real robot\nmanipulator.",
      "tldr_zh": "本研究提出了一种主动强化学习方法——Policy Transfer with Online Demonstrations，用于机器人政策转移（Transfer Learning）。该方法结合在线演示（online demonstrations）优化查询时机和内容，以缓解传统学习从演示（LfD）中因协方差偏移（covariance shift）带来的性能问题，并在有限的演示预算下提升转移效率。实验在八个机器人场景中评估，包括不同环境、任务和机器人形态的转移，结果显示该方法在平均成功率和样本效率上显著优于基于离线演示的规范LfD方法和另一种主动LfD方法。此外，初步的模拟到真实（sim-to-real）测试证实了转移政策在真实机器人操纵器上的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12993v1",
      "published_date": "2025-03-17 09:47:42 UTC",
      "updated_date": "2025-03-17 09:47:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:13:06.734171"
    },
    {
      "arxiv_id": "2503.12992v1",
      "title": "Intra-neuronal attention within language models Relationships between activation and semantics",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Pichat",
        "William Pogrund",
        "Paloma Pichat",
        "Armanouche Gasparian",
        "Samuel Demarchi",
        "Corbet Alois Georgeon",
        "Michael Veillet-Guillem"
      ],
      "abstract": "This study investigates the ability of perceptron-type neurons in language\nmodels to perform intra-neuronal attention; that is, to identify different\nhomogeneous categorical segments within the synthetic thought category they\nencode, based on a segmentation of specific activation zones for the tokens to\nwhich they are particularly responsive. The objective of this work is therefore\nto determine to what extent formal neurons can establish a homomorphic\nrelationship between activation-based and categorical segmentations. The\nresults suggest the existence of such a relationship, albeit tenuous, only at\nthe level of tokens with very high activation levels. This intra-neuronal\nattention subsequently enables categorical restructuring processes at the level\nof neurons in the following layer, thereby contributing to the progressive\nformation of high-level categorical abstractions.",
      "tldr_zh": "本研究探讨了语言模型中感知元型神经元(perceptron-type neurons)进行intra-neuronal attention的能力，即基于激活区域识别其编码的合成思想类别中的同质类别段。研究目标是评估神经元在激活-based和categorical segmentations之间建立homomorphic relationship的程度，结果显示这种关系仅在激活水平极高的tokens上存在，且较为微弱。通过这种intra-neuronal attention，神经元可促进后续层的categorical restructuring进程，从而有助于形成高级别的categorical abstractions。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12992v1",
      "published_date": "2025-03-17 09:47:11 UTC",
      "updated_date": "2025-03-17 09:47:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:13:17.154948"
    },
    {
      "arxiv_id": "2503.12989v1",
      "title": "A Multi-Stage Framework with Taxonomy-Guided Reasoning for Occupation Classification Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Palakorn Achananuparp",
        "Ee-Peng Lim"
      ],
      "abstract": "Automatically annotating job data with standardized occupations from\ntaxonomies, known as occupation classification, is crucial for labor market\nanalysis. However, this task is often hindered by data scarcity and the\nchallenges of manual annotations. While large language models (LLMs) hold\npromise due to their extensive world knowledge and in-context learning\ncapabilities, their effectiveness depends on their knowledge of occupational\ntaxonomies, which remains unclear. In this study, we assess the ability of LLMs\nto generate precise taxonomic entities from taxonomy, highlighting their\nlimitations. To address these challenges, we propose a multi-stage framework\nconsisting of inference, retrieval, and reranking stages, which integrates\ntaxonomy-guided reasoning examples to enhance performance by aligning outputs\nwith taxonomic knowledge. Evaluations on a large-scale dataset show significant\nimprovements in classification accuracy. Furthermore, we demonstrate the\nframework's adaptability for multi-label skill classification. Our results\nindicate that the framework outperforms existing LLM-based methods, offering a\npractical and scalable solution for occupation classification and related tasks\nacross LLMs.",
      "tldr_zh": "该研究针对职业分类（occupation classification）任务提出了一种多阶段框架，以解决数据稀缺和手动标注的挑战。该框架利用Large Language Models (LLMs)的知识优势，但首先评估了LLMs在生成精确分类实体（taxonomic entities）方面的局限性。通过inference（推理）、retrieval（检索）和reranking（重新排序）阶段，框架整合taxonomy-guided reasoning examples，使输出更好地与职业分类学知识对齐。在大规模数据集上的评估显示，该方法显著提高了分类准确率，并证明了其在multi-label skill classification中的适应性。总体而言，该框架优于现有LLM-based方法，提供了一个实用且可扩展的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12989v1",
      "published_date": "2025-03-17 09:44:50 UTC",
      "updated_date": "2025-03-17 09:44:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:13:30.292199"
    },
    {
      "arxiv_id": "2503.12988v1",
      "title": "ROMA: a Read-Only-Memory-based Accelerator for QLoRA-based On-Device LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqiang Wang",
        "Yijia Zhang",
        "Zikai Zhang",
        "Guanting Huo",
        "Hao Liang",
        "Shijie Cao",
        "Ningyi Xu"
      ],
      "abstract": "As large language models (LLMs) demonstrate powerful capabilities, deploying\nthem on edge devices has become increasingly crucial, offering advantages in\nprivacy and real-time interaction. QLoRA has emerged as the standard approach\nfor on-device LLMs, leveraging quantized models to reduce memory and\ncomputational costs while utilizing LoRA for task-specific adaptability. In\nthis work, we propose ROMA, a QLoRA accelerator with a hybrid storage\narchitecture that uses ROM for quantized base models and SRAM for LoRA weights\nand KV cache. Our insight is that the quantized base model is stable and\nconverged, making it well-suited for ROM storage. Meanwhile, LoRA modules offer\nthe flexibility to adapt to new data without requiring updates to the base\nmodel. To further reduce the area cost of ROM, we introduce a novel B-ROM\ndesign and integrate it with the compute unit to form a fused cell for\nefficient use of chip resources. ROMA can effectively store both a 4-bit 3B and\na 2-bit 8B LLaMA model entirely on-chip, achieving a notable generation speed\nexceeding 20,000 tokens/s without requiring external memory.",
      "tldr_zh": "该研究提出ROMA，一种基于只读存储器(Read-Only-Memory)的加速器，针对QLoRA方法优化大语言模型(LLMs)在边缘设备的部署，以提升隐私和实时交互。ROMA采用混合存储架构，将量化基模型存储在ROM中，而LoRA权重和KV cache置于SRAM中，并引入新型B-ROM设计与计算单元融合，减少芯片面积成本。实验结果显示，ROMA能完全在芯片上存储4-bit 3B和2-bit 8B LLaMA模型，实现超过20,000 tokens/s的生成速度，无需外部内存。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12988v1",
      "published_date": "2025-03-17 09:44:17 UTC",
      "updated_date": "2025-03-17 09:44:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:13:41.673427"
    },
    {
      "arxiv_id": "2503.12972v1",
      "title": "Aligning Vision to Language: Text-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Junming Liu",
        "Siyuan Meng",
        "Yanting Gao",
        "Song Mao",
        "Pinlong Cai",
        "Guohang Yan",
        "Yirong Chen",
        "Zilin Bian",
        "Botian Shi",
        "Ding Wang"
      ],
      "abstract": "Multimodal reasoning in Large Language Models (LLMs) struggles with\nincomplete knowledge and hallucination artifacts, challenges that textual\nKnowledge Graphs (KGs) only partially mitigate due to their modality isolation.\nWhile Multimodal Knowledge Graphs (MMKGs) promise enhanced cross-modal\nunderstanding, their practical construction is impeded by semantic narrowness\nof manual text annotations and inherent noise in visual-semantic entity\nlinkages. In this paper, we propose Vision-align-to-Language integrated\nKnowledge Graph (VaLiK), a novel approach for constructing MMKGs that enhances\nLLMs reasoning through cross-modal information supplementation. Specifically,\nwe cascade pre-trained Vision-Language Models (VLMs) to align image features\nwith text, transforming them into descriptions that encapsulate image-specific\ninformation. Furthermore, we developed a cross-modal similarity verification\nmechanism to quantify semantic consistency, effectively filtering out noise\nintroduced during feature alignment. Even without manually annotated image\ncaptions, the refined descriptions alone suffice to construct the MMKG.\nCompared to conventional MMKGs construction paradigms, our approach achieves\nsubstantial storage efficiency gains while maintaining direct entity-to-image\nlinkage capability. Experimental results on multimodal reasoning tasks\ndemonstrate that LLMs augmented with VaLiK outperform previous state-of-the-art\nmodels. Our code is published at https://github.com/Wings-Of-Disaster/VaLiK.",
      "tldr_zh": "本研究针对Large Language Models (LLMs) 在多模态推理中的不完整知识和幻觉问题，提出了一种无文本标注的多模态知识图谱 (MMKGs) 构建方法，即Vision-align-to-Language integrated Knowledge Graph (VaLiK)。VaLiK 通过级联预训练的Vision-Language Models (VLMs) 来对齐图像特征与文本，生成封装图像特定信息的描述，并引入跨模态相似性验证机制以过滤噪声，从而在不依赖手动注释的情况下高效构建MMKGs。实验结果显示，VaLiK增强的LLMs 在多模态推理任务中优于现有最先进模型，同时实现了存储效率的显著提升和实体到图像的直接链接。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 7 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.12972v1",
      "published_date": "2025-03-17 09:31:14 UTC",
      "updated_date": "2025-03-17 09:31:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:13:53.881251"
    },
    {
      "arxiv_id": "2503.12964v1",
      "title": "Training Video Foundation Models with NVIDIA NeMo",
      "title_zh": "翻译失败",
      "authors": [
        "Zeeshan Patel",
        "Ethan He",
        "Parth Mannan",
        "Xiaowei Ren",
        "Ryan Wolf",
        "Niket Agarwal",
        "Jacob Huffman",
        "Zhuoyao Wang",
        "Carl Wang",
        "Jack Chang",
        "Yan Bai",
        "Tommy Huang",
        "Linnan Wang",
        "Sahil Jain",
        "Shanmugam Ramasamy",
        "Joseph Jennings",
        "Ekaterina Sirazitdinova",
        "Oleg Sudakov",
        "Mingyuan Ma",
        "Bobby Chen",
        "Forrest Lin",
        "Hao Wang",
        "Vasanth Rao Naik Sabavat",
        "Sriharsha Niverty",
        "Rong Ou",
        "Pallab Bhattacharya",
        "David Page",
        "Nima Tajbakhsh",
        "Ashwath Aithal"
      ],
      "abstract": "Video Foundation Models (VFMs) have recently been used to simulate the real\nworld to train physical AI systems and develop creative visual experiences.\nHowever, there are significant challenges in training large-scale, high quality\nVFMs that can generate high-quality videos. We present a scalable, open-source\nVFM training pipeline with NVIDIA NeMo, providing accelerated video dataset\ncuration, multimodal data loading, and parallelized video diffusion model\ntraining and inference. We also provide a comprehensive performance analysis\nhighlighting best practices for efficient VFM training and inference.",
      "tldr_zh": "这篇论文介绍了使用 NVIDIA NeMo 训练 Video Foundation Models (VFMs) 的方法，以解决大规模、高质量视频生成面临的挑战。研究团队开发了一个可扩展的开源训练管道，包括加速视频数据集整理、多模态数据加载以及并行化视频扩散模型训练和推理。该管道通过全面性能分析，提供了高效 VFM 训练和推理的最佳实践，帮助提升物理 AI 系统和创意视觉体验的开发。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12964v1",
      "published_date": "2025-03-17 09:19:12 UTC",
      "updated_date": "2025-03-17 09:19:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:14:05.324251"
    },
    {
      "arxiv_id": "2503.12946v1",
      "title": "Open3DBench: Open-Source Benchmark for 3D-IC Backend Implementation and PPA Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Yunqi Shi",
        "Chengrui Gao",
        "Wanqi Ren",
        "Siyuan Xu",
        "Ke Xue",
        "Mingxuan Yuan",
        "Chao Qian",
        "Zhi-Hua Zhou"
      ],
      "abstract": "This work introduces Open3DBench, an open-source 3D-IC backend implementation\nbenchmark built upon the OpenROAD-flow-scripts framework, enabling\ncomprehensive evaluation of power, performance, area, and thermal metrics. Our\nproposed flow supports modular integration of 3D partitioning, placement, 3D\nrouting, RC extraction, and thermal simulation, aligning with advanced 3D flows\nthat rely on commercial tools and in-house scripts. We present two foundational\n3D placement algorithms: Open3D-Tiling, which emphasizes regular macro\nplacement, and Open3D-DMP, which enhances wirelength optimization through\ncross-die co-placement with analytical placer DREAMPlace. Experimental results\nshow significant improvements in area (51.19%), wirelength (24.06%), timing\n(30.84%), and power (5.72%) compared to 2D flows. The results also highlight\nthat better wirelength does not necessarily lead to PPA gain, emphasizing the\nneed of developing PPA-driven methods. Open3DBench offers a standardized,\nreproducible platform for evaluating 3D EDA methods, effectively bridging the\ngap between open-source tools and commercial solutions in 3D-IC design.",
      "tldr_zh": "这篇论文引入了 Open3DBench，一个基于 OpenROAD-flow-scripts 的开源基准，用于全面评估 3D-IC 后端实现的功率（power）、性能（performance）、面积（area）和热量（thermal）指标。框架支持模块化集成，包括 3D 分区、放置、3D 路由、RC 提取和热模拟，并提出两种基础 3D 放置算法：Open3D-Tiling（强调规则宏放置）和 Open3D-DMP（通过跨芯片共放置优化线长）。实验结果显示，与 2D 流程相比，Open3DBench 实现了面积改善 51.19%、线长 24.06%、时序 30.84% 和功率 5.72%，但也指出更好的线长不一定带来 PPA 收益，强调需要开发 PPA 驱动的方法。该基准提供了一个标准、可重现的平台，桥接开源工具与商业解决方案在 3D-IC 设计中的差距。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12946v1",
      "published_date": "2025-03-17 08:59:00 UTC",
      "updated_date": "2025-03-17 08:59:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:14:20.595955"
    },
    {
      "arxiv_id": "2503.12937v1",
      "title": "R1-VL: Learning to Reason with Multimodal Large Language Models via Step-wise Group Relative Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyi Zhang",
        "Jiaxing Huang",
        "Huanjin Yao",
        "Shunyu Liu",
        "Xikun Zhang",
        "Shijian Lu",
        "Dacheng Tao"
      ],
      "abstract": "Recent studies generally enhance MLLMs' reasoning capabilities via supervised\nfine-tuning on high-quality chain-of-thought reasoning data, which often leads\nmodels to merely imitate successful reasoning paths without understanding what\nthe wrong reasoning paths are. In this work, we aim to enhance the MLLMs'\nreasoning ability beyond passively imitating positive reasoning paths. To this\nend, we design Step-wise Group Relative Policy Optimization (StepGRPO), a new\nonline reinforcement learning framework that enables MLLMs to self-improve\nreasoning ability via simple, effective and dense step-wise rewarding.\nSpecifically, StepGRPO introduces two novel rule-based reasoning rewards:\nStep-wise Reasoning Accuracy Reward (StepRAR) and Step-wise Reasoning Validity\nReward (StepRVR). StepRAR rewards the reasoning paths that contain necessary\nintermediate reasoning steps via a soft key-step matching technique, while\nStepRAR rewards reasoning paths that follow a well-structured and logically\nconsistent reasoning process through a reasoning completeness and logic\nevaluation strategy. With the proposed StepGRPO, we introduce R1-VL, a series\nof MLLMs with outstanding capabilities in step-by-step reasoning. Extensive\nexperiments over 8 benchmarks demonstrate the superiority of our methods.",
      "tldr_zh": "该研究针对多模态大语言模型(MLLMs)的推理能力问题，提出了一种新的在线强化学习框架Step-wise Group Relative Policy Optimization (StepGRPO)，以超越单纯模仿成功推理路径的局限。StepGRPO 通过引入两种规则-based 奖励机制——Step-wise Reasoning Accuracy Reward (StepRAR) 和 Step-wise Reasoning Validity Reward (StepRVR)——来实现步进式奖励，其中 StepRAR 通过软关键步骤匹配奖励包含必要中间步骤的路径，而 StepRVR 通过推理完整性和逻辑评估奖励结构良好且逻辑一致的过程。基于此框架，作者开发了 R1-VL 系列 MLLMs，展现出卓越的逐步推理能力；在 8 个基准上的广泛实验证明，该方法显著优于现有技术。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12937v1",
      "published_date": "2025-03-17 08:51:44 UTC",
      "updated_date": "2025-03-17 08:51:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:14:30.036834"
    },
    {
      "arxiv_id": "2503.12931v2",
      "title": "MirrorShield: Towards Universal Defense Against Jailbreaks via Entropy-Guided Mirror Crafting",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Pu",
        "Chaozhuo Li",
        "Rui Ha",
        "Litian Zhang",
        "Lirong Qiu",
        "Xi Zhang"
      ],
      "abstract": "Defending large language models (LLMs) against jailbreak attacks is crucial\nfor ensuring their safe deployment. Existing defense strategies typically rely\non predefined static criteria to differentiate between harmful and benign\nprompts. However, such rigid rules fail to accommodate the inherent complexity\nand dynamic nature of real-world jailbreak attacks. In this paper, we focus on\nthe novel challenge of universal defense against diverse jailbreaks. We propose\na new concept ``mirror'', which is a dynamically generated prompt that reflects\nthe syntactic structure of the input while ensuring semantic safety. The\ndiscrepancies between input prompts and their corresponding mirrors serve as\nguiding principles for defense. A novel defense model, MirrorShield, is further\nproposed to detect and calibrate risky inputs based on the crafted mirrors.\nEvaluated on multiple benchmark datasets and compared against ten\nstate-of-the-art attack methods, MirrorShield demonstrates superior defense\nperformance and promising generalization capabilities.",
      "tldr_zh": "该论文针对大型语言模型 (LLMs) 防御越狱攻击 (jailbreak attacks) 的挑战，提出了一种通用防御策略，以解决现有静态规则的局限性。论文引入“mirror”概念，即动态生成的提示，它镜像输入的句法结构，同时确保语义安全，并利用 entropy-guided mirror crafting 来指导防御。MirrorShield 模型基于这些 mirrors 检测和校准风险输入，在多个基准数据集上与十种最先进攻击方法比较，展示了优越的防御性能和良好的泛化能力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12931v2",
      "published_date": "2025-03-17 08:41:29 UTC",
      "updated_date": "2025-05-20 06:03:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:14:42.954633"
    },
    {
      "arxiv_id": "2503.12927v2",
      "title": "MMLNB: Multi-Modal Learning for Neuroblastoma Subtyping Classification Assisted with Textual Description Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Huangwei Chen",
        "Yifei Chen",
        "Zhenyu Yan",
        "Mingyang Ding",
        "Chenlei Li",
        "Zhu Zhu",
        "Feiwei Qin"
      ],
      "abstract": "Neuroblastoma (NB), a leading cause of childhood cancer mortality, exhibits\nsignificant histopathological variability, necessitating precise subtyping for\naccurate prognosis and treatment. Traditional diagnostic methods rely on\nsubjective evaluations that are time-consuming and inconsistent. To address\nthese challenges, we introduce MMLNB, a multi-modal learning (MML) model that\nintegrates pathological images with generated textual descriptions to improve\nclassification accuracy and interpretability. The approach follows a two-stage\nprocess. First, we fine-tune a Vision-Language Model (VLM) to enhance\npathology-aware text generation. Second, the fine-tuned VLM generates textual\ndescriptions, using a dual-branch architecture to independently extract visual\nand textual features. These features are fused via Progressive Robust\nMulti-Modal Fusion (PRMF) Block for stable training. Experimental results show\nthat the MMLNB model is more accurate than the single modal model. Ablation\nstudies demonstrate the importance of multi-modal fusion, fine-tuning, and the\nPRMF mechanism. This research creates a scalable AI-driven framework for\ndigital pathology, enhancing reliability and interpretability in NB subtyping\nclassification. Our source code is available at\nhttps://github.com/HovChen/MMLNB.",
      "tldr_zh": "本研究针对神经母细胞瘤 (NB) 的组织病理学变异问题，提出 MMLNB 模型，这是一种多模态学习 (Multi-Modal Learning) 框架，通过整合病理图像和生成的文本描述，提高 NB 亚型分类的准确性和可解释性。方法采用两阶段过程：首先微调 Vision-Language Model (VLM) 以生成病理相关的文本描述，然后使用双分支架构提取视觉和文本特征，并通过 Progressive Robust Multi-Modal Fusion (PRMF) Block 进行特征融合，确保训练稳定性。实验结果显示，MMLNB 比单模态模型更准确，消融研究证实多模态融合、微调和 PRMF 机制的关键作用，为 AI 驱动的数字病理学框架提供可扩展解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.12927v2",
      "published_date": "2025-03-17 08:38:46 UTC",
      "updated_date": "2025-03-19 09:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:14:54.937949"
    },
    {
      "arxiv_id": "2503.13565v1",
      "title": "ML-SpecQD: Multi-Level Speculative Decoding with Quantized Drafts",
      "title_zh": "翻译失败",
      "authors": [
        "Evangelos Georganas",
        "Dhiraj Kalamkar",
        "Alexander Kozlov",
        "Alexander Heinecke"
      ],
      "abstract": "Speculative decoding (SD) has emerged as a method to accelerate LLM inference\nwithout sacrificing any accuracy over the 16-bit model inference. In a typical\nSD setup, the idea is to use a full-precision, small, fast model as \"draft\" to\ngenerate the next few tokens and use the \"target\" large model to verify the\ndraft-generated tokens. The efficacy of this method heavily relies on the\nacceptance ratio of the draft-generated tokens and the relative token\nthroughput of the draft versus the target model. Nevertheless, an efficient SD\npipeline requires pre-training and aligning the draft model to the target\nmodel, making it impractical for LLM inference in a plug-and-play fashion. In\nthis work, we propose using MXFP4 models as drafts in a plug-and-play fashion\nsince the MXFP4 Weight-Only-Quantization (WOQ) merely direct-casts the BF16\ntarget model weights to MXFP4. In practice, our plug-and-play solution gives\nspeedups up to 2x over the BF16 baseline. Then we pursue an opportunity for\nfurther acceleration: the MXFP4 draft token generation itself can be\naccelerated via speculative decoding by using yet another smaller draft. We\ncall our method ML-SpecQD: Multi-Level Speculative Decoding with Quantized\nDrafts since it recursively applies speculation for accelerating the\ndraft-token generation. Combining Multi-Level Speculative Decoding with MXFP4\nQuantized Drafts we outperform state-of-the-art speculative decoding, yielding\nspeedups up to 2.72x over the BF16 baseline.",
      "tldr_zh": "该论文提出 ML-SpecQD 方法，即多级推测解码（Multi-Level Speculative Decoding）结合量化 draft 模型（Quantized Drafts），用于加速 LLM 推理，而不牺牲准确性。创新点在于采用 MXFP4 Weight-Only-Quantization (WOQ) 技术，实现即插即用的 draft 模型生成，相比 BF16 基线提供高达 2x 的速度提升。进一步通过递归应用多级推测解码，对 draft 本身进行加速，最终实现高达 2.72x 的整体加速，超越现有推测解码技术。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13565v1",
      "published_date": "2025-03-17 08:38:45 UTC",
      "updated_date": "2025-03-17 08:38:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:15:06.699864"
    },
    {
      "arxiv_id": "2503.12917v1",
      "title": "Verification Learning: Make Unsupervised Neuro-Symbolic System Feasible",
      "title_zh": "验证学习：使无监督神经符号系统可行",
      "authors": [
        "Lin-Han Jia",
        "Wen-Chao Hu",
        "Jie-Jing Shao",
        "Lan-Zhe Guo",
        "Yu-Feng Li"
      ],
      "abstract": "The current Neuro-Symbolic (NeSy) Learning paradigm suffers from an\nover-reliance on labeled data. If we completely disregard labels, it leads to\nless symbol information, a larger solution space, and more shortcuts-issues\nthat current Nesy systems cannot resolve. This paper introduces a novel\nlearning paradigm, Verification Learning (VL), which addresses this challenge\nby transforming the label-based reasoning process in Nesy into a label-free\nverification process. VL achieves excellent learning results solely by relying\non unlabeled data and a function that verifies whether the current predictions\nconform to the rules. We formalize this problem as a Constraint Optimization\nProblem (COP) and propose a Dynamic combinatorial Sorting (DCS) algorithm that\naccelerates the solution by reducing verification attempts, effectively\nlowering computational costs to the level of a Constraint Satisfaction Problem\n(CSP). To further enhance performance, we introduce a prior alignment method to\naddress potential shortcuts. Our theoretical analysis points out which tasks in\nNesy systems can be completed without labels and explains why rules can replace\ninfinite labels, such as in addition, for some tasks, while for others, like\nSudoku, the rules have no effect. We validate the proposed framework through\nseveral fully unsupervised tasks including addition, sort, match, and chess,\neach showing significant performance and efficiency improvements.",
      "tldr_zh": "本论文提出了一种新的学习范式Verification Learning (VL)，旨在解决Neuro-Symbolic (NeSy)系统的过度依赖标签数据问题，通过将基于标签的推理转化为无标签的验证过程，仅依赖无标签数据和规则验证函数来实现高效学习。论文将问题形式化为Constraint Optimization Problem (COP)，并引入Dynamic combinatorial Sorting (DCS)算法来减少验证尝试，将计算成本降低到Constraint Satisfaction Problem (CSP)水平，同时通过prior alignment方法处理潜在捷径。理论分析解释了某些NeSy任务（如加法）可无需标签完成，而实验在addition、sort、match和chess等无监督任务上验证了框架的显著性能和效率提升。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12917v1",
      "published_date": "2025-03-17 08:28:58 UTC",
      "updated_date": "2025-03-17 08:28:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:15:18.431514"
    },
    {
      "arxiv_id": "2503.12908v3",
      "title": "HICD: Hallucination-Inducing via Attention Dispersion for Contrastive Decoding to Mitigate Hallucinations in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyan Jiang",
        "Hang Ye",
        "Yongxin Zhu",
        "Xiaoying Zheng",
        "Zikang Chen",
        "Jun Gong"
      ],
      "abstract": "Large Language Models (LLMs) often generate hallucinations, producing outputs\nthat are contextually inaccurate or factually incorrect. We introduce HICD, a\nnovel method designed to induce hallucinations for contrastive decoding to\nmitigate hallucinations. Unlike existing contrastive decoding methods, HICD\nselects attention heads crucial to the model's prediction as inducing heads,\nthen induces hallucinations by dispersing attention of these inducing heads and\ncompares the hallucinated outputs with the original outputs to obtain the final\nresult. Our approach significantly improves performance on tasks requiring\ncontextual faithfulness, such as context completion, reading comprehension, and\nquestion answering. It also improves factuality in tasks requiring accurate\nknowledge recall. We demonstrate that our inducing heads selection and\nattention dispersion method leads to more \"contrast-effective\" hallucinations\nfor contrastive decoding, outperforming other hallucination-inducing methods.\nOur findings provide a promising strategy for reducing hallucinations by\ninducing hallucinations in a controlled manner, enhancing the performance of\nLLMs in a wide range of tasks.",
      "tldr_zh": "大型语言模型（Large Language Models, LLMs）经常产生幻觉（hallucinations），导致输出不准确，论文提出 HICD 方法，通过选择关键注意力头（attention heads）并分散其注意力来诱导幻觉，用于 contrastive decoding 以缓解这一问题。\nHICD 将诱导的幻觉输出与原始输出进行比较，生成更可靠的结果，从而提升模型在上下文完成、阅读理解和问答等任务中的上下文忠实度和事实性。\n实验结果表明，该方法在准确知识回忆任务上表现突出，并优于其他诱导幻觉技术，因为它能产生更“contrast-effective”的幻觉。\n总体上，HICD 提供了一种控制诱导幻觉的创新策略，提升了 LLMs 在多种任务中的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL2025 findings",
      "pdf_url": "http://arxiv.org/pdf/2503.12908v3",
      "published_date": "2025-03-17 08:17:28 UTC",
      "updated_date": "2025-05-20 11:19:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:15:31.577234"
    },
    {
      "arxiv_id": "2503.13563v1",
      "title": "MES-RAG: Bringing Multi-modal, Entity-Storage, and Secure Enhancements to RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Pingyu Wu",
        "Daiheng Gao",
        "Jing Tang",
        "Huimin Chen",
        "Wenbo Zhou",
        "Weiming Zhang",
        "Nenghai Yu"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) improves Large Language Models (LLMs) by\nusing external knowledge, but it struggles with precise entity information\nretrieval. In this paper, we proposed MES-RAG framework, which enhances\nentity-specific query handling and provides accurate, secure, and consistent\nresponses. MES-RAG introduces proactive security measures that ensure system\nintegrity by applying protections prior to data access. Additionally, the\nsystem supports real-time multi-modal outputs, including text, images, audio,\nand video, seamlessly integrating into existing RAG architectures. Experimental\nresults demonstrate that MES-RAG significantly improves both accuracy and\nrecall, highlighting its effectiveness in advancing the security and utility of\nquestion-answering, increasing accuracy to 0.83 (+0.25) on targeted task. Our\ncode and data are available at https://github.com/wpydcr/MES-RAG.",
      "tldr_zh": "本研究提出MES-RAG框架，以提升RAG（Retrieval-Augmented Generation）在处理实体特定查询时的性能，解决其精确实体信息检索的局限性。MES-RAG引入实体存储增强、主动安全措施（如数据访问前保护系统完整性）和实时多模态输出支持（包括文本、图像、音频和视频），并与现有RAG架构无缝整合。实验结果显示，该框架显著提高了准确性和召回率，在目标任务上准确率提升至0.83（+0.25），从而增强了问答系统的安全性和实用性。代码和数据已在GitHub上公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.13563v1",
      "published_date": "2025-03-17 08:09:42 UTC",
      "updated_date": "2025-03-17 08:09:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:15:42.147366"
    },
    {
      "arxiv_id": "2503.12897v1",
      "title": "Federated Continual Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Haiyang Guo",
        "Fanhu Zeng",
        "Fei Zhu",
        "Wenzhuo Liu",
        "Da-Han Wang",
        "Jian Xu",
        "Xu-Yao Zhang",
        "Cheng-Lin Liu"
      ],
      "abstract": "A vast amount of instruction tuning data is crucial for the impressive\nperformance of Large Multimodal Models (LMMs), but the associated computational\ncosts and data collection demands during supervised fine-tuning make it\nimpractical for most researchers. Federated learning (FL) has the potential to\nleverage all distributed data and training resources to reduce the overhead of\njoint training. However, most existing methods assume a fixed number of tasks,\nwhile in real-world scenarios, clients continuously encounter new knowledge and\noften struggle to retain old tasks due to memory constraints. In this work, we\nintroduce the Federated Continual Instruction Tuning (FCIT) benchmark to model\nthis real-world challenge. Our benchmark includes two realistic scenarios,\nencompassing four different settings and twelve carefully curated instruction\ntuning datasets. To address the challenges posed by FCIT, we propose dynamic\nknowledge organization to effectively integrate updates from different tasks\nduring training and subspace selective activation to allocate task-specific\noutput during inference. Extensive experimental results demonstrate that our\nproposed method significantly enhances model performance across varying levels\nof data heterogeneity and catastrophic forgetting. Our source code and dataset\nwill be made publicly available.",
      "tldr_zh": "该研究针对Large Multimodal Models (LMMs)的指令调整过程，指出其高计算成本和数据需求问题，并提出Federated Learning (FL)作为解决方案，但强调现有方法无法处理持续新任务和遗忘旧知识的现实挑战。作者引入Federated Continual Instruction Tuning (FCIT)基准，包括两个现实场景、四个设置和十二个指令调整数据集，用于模拟分布式持续学习环境。为应对这些挑战，他们提出dynamic knowledge organization方法来整合训练中的任务更新，以及subspace selective activation方法来在推理中分配任务特定输出。实验结果显示，该方法显著提升了模型性能，减少了数据异质性和catastrophic forgetting的影响，并计划开源代码和数据集。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.12897v1",
      "published_date": "2025-03-17 07:58:06 UTC",
      "updated_date": "2025-03-17 07:58:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:15:54.138435"
    },
    {
      "arxiv_id": "2503.15548v1",
      "title": "Privacy-Aware RAG: Secure and Isolated Knowledge Retrieval",
      "title_zh": "隐私感知 RAG：安全的隔离知识检索",
      "authors": [
        "Pengcheng Zhou",
        "Yinglun Feng",
        "Zhongliang Yang"
      ],
      "abstract": "The widespread adoption of Retrieval-Augmented Generation (RAG) systems in\nreal-world applications has heightened concerns about the confidentiality and\nintegrity of their proprietary knowledge bases. These knowledge bases, which\nplay a critical role in enhancing the generative capabilities of Large Language\nModels (LLMs), are increasingly vulnerable to breaches that could compromise\nsensitive information. To address these challenges, this paper proposes an\nadvanced encryption methodology designed to protect RAG systems from\nunauthorized access and data leakage. Our approach encrypts both textual\ncontent and its corresponding embeddings prior to storage, ensuring that all\ndata remains securely encrypted. This mechanism restricts access to authorized\nentities with the appropriate decryption keys, thereby significantly reducing\nthe risk of unintended data exposure. Furthermore, we demonstrate that our\nencryption strategy preserves the performance and functionality of RAG\npipelines, ensuring compatibility across diverse domains and applications. To\nvalidate the robustness of our method, we provide comprehensive security proofs\nthat highlight its resilience against potential threats and vulnerabilities.\nThese proofs also reveal limitations in existing approaches, which often lack\nrobustness, adaptability, or reliance on open-source models. Our findings\nsuggest that integrating advanced encryption techniques into the design and\ndeployment of RAG systems can effectively enhance privacy safeguards. This\nresearch contributes to the ongoing discourse on improving security measures\nfor AI-driven services and advocates for stricter data protection standards\nwithin RAG architectures.",
      "tldr_zh": "这篇论文针对 Retrieval-Augmented Generation (RAG) 系统在实际应用中面临的知识库保密和完整性问题，提出了一种隐私感知的加密方法，以保护敏感信息免受未授权访问。方法包括在存储前加密文本内容和对应的 embeddings，仅允许持有解密密钥的授权实体访问，从而显著降低数据泄露风险，同时保持 RAG 管道的性能和兼容性。实验结果通过全面安全证明验证了该方法的鲁棒性，揭示了现有方法的局限性，并强调了在 RAG 架构中整合高级加密技术的重要性，以提升 AI 服务的隐私保护标准。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15548v1",
      "published_date": "2025-03-17 07:45:05 UTC",
      "updated_date": "2025-03-17 07:45:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:16:05.702978"
    },
    {
      "arxiv_id": "2503.13562v1",
      "title": "Micro Text Classification Based on Balanced Positive-Unlabeled Learning",
      "title_zh": "基于平衡正-未标记学习的微观文本分类",
      "authors": [
        "Lin-Han Jia",
        "Lan-Zhe Guo",
        "Zhi Zhou",
        "Si-Ye Han",
        "Zi-Wen Li",
        "Yu-Feng Li"
      ],
      "abstract": "In real-world text classification tasks, negative texts often contain a\nminimal proportion of negative content, which is especially problematic in\nareas like text quality control, legal risk screening, and sensitive\ninformation interception. This challenge manifests at two levels: at the macro\nlevel, distinguishing negative texts is difficult due to the high similarity\nbetween coarse-grained positive and negative samples; at the micro level, the\nissue stems from extreme class imbalance and a lack of fine-grained labels. To\naddress these challenges, we propose transforming the coarse-grained\npositive-negative (PN) classification task into an imbalanced fine-grained\npositive-unlabeled (PU) classification problem, supported by theoretical\nanalysis. We introduce a novel framework, Balanced Fine-Grained\nPositive-Unlabeled (BFGPU) learning, which features a unique PU learning loss\nfunction that optimizes macro-level performance amidst severe imbalance at the\nmicro level. The framework's performance is further boosted by rebalanced\npseudo-labeling and threshold adjustment. Extensive experiments on both public\nand real-world datasets demonstrate the effectiveness of BFGPU, which\noutperforms other methods, even in extreme scenarios where both macro and micro\nlevels are highly imbalanced.",
      "tldr_zh": "本研究针对真实文本分类任务中负面文本比例极低的问题（如文本质量控制、法律风险筛查），提出将粗粒度正负（PN）分类转化为不平衡细粒度正-未标记（Positive-Unlabeled, PU）分类问题，并提供理论分析。作者引入Balanced Fine-Grained Positive-Unlabeled (BFGPU) 学习框架，该框架采用独特的PU学习损失函数、重新平衡的伪标签和阈值调整方法，以优化宏观性能并处理微观级别的极端类别不平衡。实验在公共和真实数据集上显示，BFGPU 优于其他方法，尤其在高度不平衡场景中，证明其在微文本分类中的有效性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13562v1",
      "published_date": "2025-03-17 07:42:27 UTC",
      "updated_date": "2025-03-17 07:42:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:16:18.023203"
    },
    {
      "arxiv_id": "2503.12880v1",
      "title": "nvBench 2.0: A Benchmark for Natural Language to Visualization under Ambiguity",
      "title_zh": "翻译失败",
      "authors": [
        "Tianqi Luo",
        "Chuhan Huang",
        "Leixian Shen",
        "Boyan Li",
        "Shuyu Shen",
        "Wei Zeng",
        "Nan Tang",
        "Yuyu Luo"
      ],
      "abstract": "Natural Language to Visualization (NL2VIS) enables users to create\nvisualizations from natural language queries, making data insights more\naccessible. However, NL2VIS faces challenges in interpreting ambiguous queries,\nas users often express their visualization needs in imprecise language. To\naddress this challenge, we introduce nvBench 2.0, a new benchmark designed to\nevaluate NL2VIS systems in scenarios involving ambiguous queries. nvBench 2.0\nincludes 7,878 natural language queries and 24,076 corresponding\nvisualizations, derived from 780 tables across 153 domains. It is built using a\ncontrolled ambiguity-injection pipeline that generates ambiguous queries\nthrough a reverse-generation workflow. By starting with unambiguous seed\nvisualizations and selectively injecting ambiguities, the pipeline yields\nmultiple valid interpretations for each query, with each ambiguous query\ntraceable to its corresponding visualization through step-wise reasoning paths.\nWe evaluate various Large Language Models (LLMs) on their ability to perform\nambiguous NL2VIS tasks using nvBench 2.0. We also propose Step-NL2VIS, an\nLLM-based model trained on nvBench 2.0, which enhances performance in ambiguous\nscenarios through step-wise preference optimization. Our results show that\nStep-NL2VIS outperforms all baselines, setting a new state-of-the-art for\nambiguous NL2VIS tasks.",
      "tldr_zh": "本研究介绍了 nvBench 2.0，这是一个针对模糊查询的 Natural Language to Visualization (NL2VIS) 基准，用于评估系统处理用户模糊语言的能力。nvBench 2.0 包含 7,878 个自然语言查询和 24,076 个对应可视化，基于一个受控的模糊注入管道，通过反向生成工作流从无歧义可视化出发，注入模糊性以生成多重解释路径。研究评估了各种 Large Language Models (LLMs) 在模糊 NL2VIS 任务上的性能，并提出 Step-NL2VIS 模型，通过在 nvBench 2.0 上训练的逐步偏好优化，提升了模糊场景下的表现。结果显示，Step-NL2VIS 超越所有基线模型，在模糊 NL2VIS 任务中建立了新的最先进水平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12880v1",
      "published_date": "2025-03-17 07:20:11 UTC",
      "updated_date": "2025-03-17 07:20:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:16:30.978049"
    },
    {
      "arxiv_id": "2503.12855v1",
      "title": "VITED: Video Temporal Evidence Distillation",
      "title_zh": "VITED：视频时序证据蒸馏",
      "authors": [
        "Yujie Lu",
        "Yale Song",
        "William Wang",
        "Lorenzo Torresani",
        "Tushar Nagarajan"
      ],
      "abstract": "We investigate complex video question answering via chain-of-evidence\nreasoning -- identifying sequences of temporal spans from multiple relevant\nparts of the video, together with visual evidence within them. Existing models\nstruggle with multi-step reasoning as they uniformly sample a fixed number of\nframes, which can miss critical evidence distributed nonuniformly throughout\nthe video. Moreover, they lack the ability to temporally localize such evidence\nin the broader context of the full video, which is required for answering\ncomplex questions. We propose a framework to enhance existing VideoQA datasets\nwith evidence reasoning chains, automatically constructed by searching for\noptimal intervals of interest in the video with supporting evidence, that\nmaximizes the likelihood of answering a given question. We train our model\n(VITED) to generate these evidence chains directly, enabling it to both\nlocalize evidence windows as well as perform multi-step reasoning across them\nin long-form video content. We show the value of our evidence-distilled models\non a suite of long video QA benchmarks where we outperform state-of-the-art\napproaches that lack evidence reasoning capabilities.",
      "tldr_zh": "本研究针对复杂视频问答（VideoQA）问题，提出一种链式证据推理方法，通过识别视频中多个相关部分的时序跨度（temporal spans）和视觉证据（visual evidence），以解决现有模型在多步推理中的局限性，如均匀采样帧导致的关键证据缺失。研究团队开发了VITED框架，该框架自动增强VideoQA数据集，构建证据推理链，并训练模型直接生成这些链以定位证据窗口并进行跨窗口的多步推理。实验结果显示，VITED在长视频QA基准测试中超越了现有最先进方法，证明了其在证据推理能力上的显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12855v1",
      "published_date": "2025-03-17 06:30:02 UTC",
      "updated_date": "2025-03-17 06:30:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:16:42.256530"
    },
    {
      "arxiv_id": "2503.12843v3",
      "title": "Towards Scalable Foundation Model for Multi-modal and Hyperspectral Geospatial Data",
      "title_zh": "翻译失败",
      "authors": [
        "Haozhe Si",
        "Yuxuan Wan",
        "Minh Do",
        "Deepak Vasisht",
        "Han Zhao",
        "Hendrik F. Hamann"
      ],
      "abstract": "Geospatial raster data, such as that collected by satellite-based imaging\nsystems at different times and spectral bands, hold immense potential for\nenabling a wide range of high-impact applications. This potential stems from\nthe rich information that is spatially and temporally contextualized across\nmultiple channels and sensing modalities. Recent work has adapted existing\nself-supervised learning approaches for such geospatial data. However, they\nfall short of scalable model architectures, leading to inflexibility and\ncomputational inefficiencies when faced with an increasing number of channels\nand modalities. To address these limitations, we introduce Low-rank Efficient\nSpatial-Spectral Vision Transformer with three key innovations: i) the LESS\nAttention Block that approximates high-dimensional spatial-spectral attention\nthrough Kronecker's product of the low-dimensional spatial and spectral\nattention components; ii) the Continuous Positional-Channel Embedding Layer\nthat preserves both the continuity and physical characteristics of each\nspatial-spectral patch; and iii) the Perception Field Mask that exploits local\nspatial dependencies by constraining attention to neighboring patches. To\nevaluate the proposed innovations, we construct GFM-Bench, which serves as a\ncomprehensive benchmark for such geospatial raster data. We pretrain LESS ViT\nusing a Hyperspectral Masked Autoencoder framework with integrated positional\nand channel masking strategies. Experimental results demonstrate that our\nproposed method achieves competitive performance against state-of-the-art\nmulti-modal geospatial foundation models while outperforming them on\ncross-satellite generalization tasks with higher computational efficiency. The\nflexibility and extensibility of our framework make it a promising direction\nfor future geospatial data analysis tasks that involve a wide range of\nmodalities and channels.",
      "tldr_zh": "该论文针对多模态和超光谱地理空间数据的可扩展性问题，提出了 Low-rank Efficient Spatial-Spectral Vision Transformer (LESS ViT) 模型，以解决现有自监督学习方法的灵活性和计算效率不足。LESS ViT 包括三个关键创新：LESS Attention Block 通过低维空间和光谱注意力的 Kronecker 乘积近似高维注意、Continuous Positional-Channel Embedding Layer 保留空间-光谱补丁的连续性和物理特性，以及 Perception Field Mask 利用局部空间依赖约束注意范围。研究者构建了 GFM-Bench 作为全面基准，并使用 Hyperspectral Masked Autoencoder 框架进行预训练，结合位置和通道掩码策略。实验结果表明，该方法在多模态地理空间任务中表现出色，与最先进模型性能相当，但在跨卫星泛化任务上优越，且计算效率更高。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12843v3",
      "published_date": "2025-03-17 05:42:19 UTC",
      "updated_date": "2025-03-26 16:15:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:16:57.644002"
    },
    {
      "arxiv_id": "2503.12836v3",
      "title": "CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting",
      "title_zh": "CompMarkGS：用于压缩 3D Gaussian Splatting 的鲁棒水印",
      "authors": [
        "Sumin In",
        "Youngdong Jang",
        "Utae Jeong",
        "MinHyuk Jang",
        "Hyeongcheol Park",
        "Eunbyung Park",
        "Sangpil Kim"
      ],
      "abstract": "3D Gaussian Splatting (3DGS) enables rapid differentiable rendering for 3D\nreconstruction and novel view synthesis, leading to its widespread commercial\nuse. Consequently, copyright protection via watermarking has become critical.\nHowever, because 3DGS relies on millions of Gaussians, which require gigabytes\nof storage, efficient transfer and storage require compression. Existing 3DGS\nwatermarking methods are vulnerable to quantization-based compression, often\nresulting in the loss of the embedded watermark. To address this challenge, we\npropose a novel watermarking method that ensures watermark robustness after\nmodel compression while maintaining high rendering quality. In detail, we\nincorporate a quantization distortion layer that simulates compression during\ntraining, preserving the watermark under quantization-based compression. Also,\nwe propose a learnable watermark embedding feature that embeds the watermark\ninto the anchor feature, ensuring structural consistency and seamless\nintegration into the 3D scene. Furthermore, we present a frequency-aware anchor\ngrowing mechanism to enhance image quality in high-frequency regions by\neffectively identifying Guassians within these regions. Experimental results\nconfirm that our method preserves the watermark and maintains superior image\nquality under high compression, validating it as a promising approach for a\nsecure 3DGS model.",
      "tldr_zh": "该研究提出CompMarkGS，一种针对压缩后3D Gaussian Splatting (3DGS)的稳健水印方法，以解决现有水印技术在量化-based compression下失效的问题。该方法通过引入量化失真层在训练过程中模拟压缩，确保水印在模型压缩后得以保留；同时，采用可学习的watermark embedding feature将水印嵌入anchor feature中，并引入frequency-aware anchor growing mechanism来提升高频区域的图像质量。实验结果表明，CompMarkGS在高压缩条件下保持了水印完整性并实现了优越的渲染质量，为3DGS模型的安全商业应用提供了可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.12836v3",
      "published_date": "2025-03-17 05:32:15 UTC",
      "updated_date": "2025-03-25 05:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:17:07.154883"
    },
    {
      "arxiv_id": "2503.12834v1",
      "title": "PASTA: Part-Aware Sketch-to-3D Shape Generation with Text-Aligned Prior",
      "title_zh": "翻译失败",
      "authors": [
        "Seunggwan Lee",
        "Hwanhee Jung",
        "Byoungsoo Koh",
        "Qixing Huang",
        "Sangho Yoon",
        "Sangpil Kim"
      ],
      "abstract": "A fundamental challenge in conditional 3D shape generation is to minimize the\ninformation loss and maximize the intention of user input. Existing approaches\nhave predominantly focused on two types of isolated conditional signals, i.e.,\nuser sketches and text descriptions, each of which does not offer flexible\ncontrol of the generated shape. In this paper, we introduce PASTA, the flexible\napproach that seamlessly integrates a user sketch and a text description for 3D\nshape generation. The key idea is to use text embeddings from a vision-language\nmodel to enrich the semantic representation of sketches. Specifically, these\ntext-derived priors specify the part components of the object, compensating for\nmissing visual cues from ambiguous sketches. In addition, we introduce ISG-Net\nwhich employs two types of graph convolutional networks: IndivGCN, which\nprocesses fine-grained details, and PartGCN, which aggregates these details\ninto parts and refines the structure of objects. Extensive experiments\ndemonstrate that PASTA outperforms existing methods in part-level editing and\nachieves state-of-the-art results in sketch-to-3D shape generation.",
      "tldr_zh": "本文提出PASTA方法，通过整合用户草图和文本描述，实现灵活的条件3D形状生成，旨在最小化信息损失并最大化用户意图。关键技术包括使用vision-language模型的文本嵌入来丰富草图语义表示，并引入ISG-Net（包含IndivGCN处理细粒度细节和PartGCN聚合细节以精炼对象结构）。实验显示，PASTA在部分级编辑和草图到3D形状生成任务中优于现有方法，达到最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.12834v1",
      "published_date": "2025-03-17 05:31:09 UTC",
      "updated_date": "2025-03-17 05:31:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:17:19.465976"
    },
    {
      "arxiv_id": "2503.15547v2",
      "title": "Prompt Flow Integrity to Prevent Privilege Escalation in LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Juhee Kim",
        "Woohyuk Choi",
        "Byoungyoung Lee"
      ],
      "abstract": "Large Language Models (LLMs) are combined with tools to create powerful LLM\nagents that provide a wide range of services. Unlike traditional software, LLM\nagent's behavior is determined at runtime by natural language prompts from\neither user or tool's data. This flexibility enables a new computing paradigm\nwith unlimited capabilities and programmability, but also introduces new\nsecurity risks, vulnerable to privilege escalation attacks. Moreover, user\nprompts are prone to be interpreted in an insecure way by LLM agents, creating\nnon-deterministic behaviors that can be exploited by attackers. To address\nthese security risks, we propose Prompt Flow Integrity (PFI), a system\nsecurity-oriented solution to prevent privilege escalation in LLM agents.\nAnalyzing the architectural characteristics of LLM agents, PFI features three\nmitigation techniques -- i.e., agent isolation, secure untrusted data\nprocessing, and privilege escalation guardrails. Our evaluation result shows\nthat PFI effectively mitigates privilege escalation attacks while successfully\npreserving the utility of LLM agents.",
      "tldr_zh": "这篇论文提出了 Prompt Flow Integrity (PFI)，一个系统安全解决方案，旨在防止 Large Language Models (LLM) 代理中的特权升级攻击。PFI 通过分析 LLM 代理的架构，引入三种缓解技术：代理隔离、secure untrusted data processing 和 privilege escalation guardrails，以处理用户提示的不确定性和潜在风险。实验结果显示，PFI 有效降低了特权升级攻击，同时保持了 LLM 代理的实用性和功能完整性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15547v2",
      "published_date": "2025-03-17 05:27:57 UTC",
      "updated_date": "2025-04-21 02:10:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:17:30.426515"
    },
    {
      "arxiv_id": "2503.12829v1",
      "title": "SparseLUT: Sparse Connectivity Optimization for Lookup Table-based Deep Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Binglei Lou",
        "Ruilin Wu",
        "Philip Leong"
      ],
      "abstract": "The deployment of deep neural networks (DNNs) on resource-constrained edge\ndevices such as field-programmable gate arrays (FPGAs) requires a careful\nbalance of latency, power, and resource usage while maintaining high accuracy.\nExisting Lookup Table (LUT)-based DNNs, including LogicNets, PolyLUT,\nPolyLUT-Add, and NeuraLUT, exploit native FPGA resources with random sparse\nconnectivity. This paper introduces SparseLUT, a connectivity-centric training\ntechnique tailored for LUT-based DNNs. SparseLUT leverages a non-greedy\ntraining strategy that prioritizes the pruning of less significant connections\nand strategically regrows alternative ones, resulting in efficient convergence\nto the target sparsity. Experimental results show consistent accuracy\nimprovements across benchmarks, including up to a 2.13\\% increase on MNIST and\na 0.94\\% improvement for Jet Substructure Classification compared to random\nsparsity. This is done without any hardware overhead and achieves\nstate-of-the-art results for LUT-based DNNs.",
      "tldr_zh": "本论文提出 SparseLUT，一种针对 Lookup Table-based Deep Neural Networks (LUT-based DNNs) 的稀疏连接优化训练技术，旨在在资源受限的边缘设备如 FPGA 上平衡延迟、功耗和资源使用，同时维持高准确率。SparseLUT 采用非贪婪训练策略，优先修剪不重要连接并战略性地重新生长替代连接，实现高效收敛到目标稀疏度。与随机稀疏方法相比，实验结果显示在 MNIST 上准确率提升 2.13%，Jet Substructure Classification 上提升 0.94%，并在各种基准上取得一致改进，且无需额外硬件开销。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12829v1",
      "published_date": "2025-03-17 05:21:54 UTC",
      "updated_date": "2025-03-17 05:21:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:17:42.831766"
    },
    {
      "arxiv_id": "2503.12821v2",
      "title": "From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration",
      "title_zh": "翻译失败",
      "authors": [
        "Mingyang Song",
        "Xiaoye Qu",
        "Jiawei Zhou",
        "Yu Cheng"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) have achieved significant progress in\ncombining visual comprehension with language generation. Despite this success,\nthe training data of LVLMs still suffers from Long-Tail (LT) problems, where\nthe data distribution is highly imbalanced. Previous works have mainly focused\non traditional VLM architectures, i.e., CLIP or ViT, and specific tasks such as\nrecognition and classification. Nevertheless, the exploration of LVLM (e.g.\nLLaVA) and more general tasks (e.g. Visual Question Answering and Visual\nReasoning) remains under-explored. In this paper, we first conduct an in-depth\nanalysis of the LT issues in LVLMs and identify two core causes: the\noverrepresentation of head concepts and the underrepresentation of tail\nconcepts. Based on the above observation, we propose an $\\textbf{A}$daptive\n$\\textbf{D}$ata $\\textbf{R}$efinement Framework ($\\textbf{ADR}$), which\nconsists of two stages: $\\textbf{D}$ata $\\textbf{R}$ebalancing ($\\textbf{DR}$)\nand $\\textbf{D}$ata $\\textbf{S}$ynthesis ($\\textbf{DS}$). In the DR stage, we\nadaptively rebalance the redundant data based on entity distributions, while in\nthe DS stage, we leverage Denoising Diffusion Probabilistic Models (DDPMs) and\nscarce images to supplement underrepresented portions. Through comprehensive\nevaluations across eleven benchmarks, our proposed ADR effectively mitigates\nthe long-tail problem in the training data, improving the average performance\nof LLaVA 1.5 relatively by 4.36%, without increasing the training data volume.",
      "tldr_zh": "本研究分析了 Large Vision-Language Models (LVLMs) 在训练数据中存在的 Long-Tail (LT) 问题，主要由于 head concepts 过度代表和 tail concepts 代表不足，导致模型在 Visual Question Answering 和 Visual Reasoning 等通用任务上表现不佳。作者提出 Adaptive Data Refinement Framework (ADR)，包括 Data Rebalancing (DR) 阶段（基于实体分布自适应重新平衡冗余数据）和 Data Synthesis (DS) 阶段（利用 Denoising Diffusion Probabilistic Models (DDPMs) 和稀缺图像补充不足部分）。通过在 11 个基准上的评估，ADR 框架有效缓解了 LT 问题，提高了 LLaVA 1.5 的平均性能 4.36%，且未增加训练数据量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.12821v2",
      "published_date": "2025-03-17 05:01:09 UTC",
      "updated_date": "2025-03-18 06:02:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:17:56.700207"
    },
    {
      "arxiv_id": "2503.12814v1",
      "title": "Versatile Physics-based Character Control with Hybrid Latent Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Jinseok Bae",
        "Jungdam Won",
        "Donggeun Lim",
        "Inwoo Hwang",
        "Young Min Kim"
      ],
      "abstract": "We present a versatile latent representation that enables physically\nsimulated character to efficiently utilize motion priors. To build a powerful\nmotion embedding that is shared across multiple tasks, the physics controller\nshould employ rich latent space that is easily explored and capable of\ngenerating high-quality motion. We propose integrating continuous and discrete\nlatent representations to build a versatile motion prior that can be adapted to\na wide range of challenging control tasks. Specifically, we build a discrete\nlatent model to capture distinctive posterior distribution without collapse,\nand simultaneously augment the sampled vector with the continuous residuals to\ngenerate high-quality, smooth motion without jittering. We further incorporate\nResidual Vector Quantization, which not only maximizes the capacity of the\ndiscrete motion prior, but also efficiently abstracts the action space during\nthe task learning phase. We demonstrate that our agent can produce diverse yet\nsmooth motions simply by traversing the learned motion prior through\nunconditional motion generation. Furthermore, our model robustly satisfies\nsparse goal conditions with highly expressive natural motions, including\nhead-mounted device tracking and motion in-betweening at irregular intervals,\nwhich could not be achieved with existing latent representations.",
      "tldr_zh": "该研究提出了一种多功能的混合潜在表示（hybrid latent representation），用于物理模拟角色高效利用运动先验（motion priors），以适应各种挑战性控制任务。该方法整合了离散潜在模型来捕捉独特的后验分布，并通过添加连续残差生成高质量、平滑的运动，同时采用 Residual Vector Quantization 来提升离散运动先验的容量和动作空间抽象效率。实验结果表明，该代理能够生成多样且平滑的运动，并可靠地满足稀疏目标条件，如头戴设备跟踪和不规则间隔的运动过渡，超越了现有潜在表示的表现。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12814v1",
      "published_date": "2025-03-17 04:45:51 UTC",
      "updated_date": "2025-03-17 04:45:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:18:09.146290"
    },
    {
      "arxiv_id": "2503.12811v1",
      "title": "A Multi-Power Law for Loss Curve Prediction Across Learning Rate Schedules",
      "title_zh": "一种多幂定律用于跨学习率调度的损失曲线预测",
      "authors": [
        "Kairong Luo",
        "Haodong Wen",
        "Shengding Hu",
        "Zhenbo Sun",
        "Zhiyuan Liu",
        "Maosong Sun",
        "Kaifeng Lyu",
        "Wenguang Chen"
      ],
      "abstract": "Training large models is both resource-intensive and time-consuming, making\nit crucial to understand the quantitative relationship between model\nperformance and hyperparameters. In this paper, we present an empirical law\nthat describes how the pretraining loss of large language models evolves under\ndifferent learning rate schedules, such as constant, cosine, and step decay\nschedules. Our proposed law takes a multi-power form, combining a power law\nbased on the sum of learning rates and additional power laws to account for a\nloss reduction effect induced by learning rate decay. We extensively validate\nthis law on various model sizes and architectures, and demonstrate that after\nfitting on a few learning rate schedules, the law accurately predicts the loss\ncurves for unseen schedules of different shapes and horizons. Moreover, by\nminimizing the predicted final pretraining loss across learning rate schedules,\nwe are able to find a schedule that outperforms the widely used cosine learning\nrate schedule. Interestingly, this automatically discovered schedule bears some\nresemblance to the recently proposed Warmup-Stable-Decay (WSD) schedule (Hu et\nal, 2024) but achieves a slightly lower final loss. We believe these results\ncould offer valuable insights for understanding the dynamics of pretraining and\ndesigning learning rate schedules to improve efficiency.",
      "tldr_zh": "本研究提出了一种多幂定律(multi-power law)，用于描述大型语言模型在不同学习率调度(如 constant、cosine 和 step decay)下的预训练损失演变，该定律结合基于学习率总和的幂律和额外幂律来处理学习率衰减引发的损失减少效应。研究通过在各种模型大小和架构上进行广泛验证，发现该定律在拟合少数调度后，能准确预测未见学习率调度的损失曲线。利用该定律最小化预测的最终预训练损失，研究者发现了一个优于常见 cosine learning rate schedule 的新调度，其性能略胜于最近提出的 Warmup-Stable-Decay (WSD) 调度。这些结果为理解预训练动态和设计更高效的学习率调度提供了宝贵洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12811v1",
      "published_date": "2025-03-17 04:36:45 UTC",
      "updated_date": "2025-03-17 04:36:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:18:21.502037"
    },
    {
      "arxiv_id": "2503.12797v2",
      "title": "DeepPerception: Advancing R1-like Cognitive Visual Perception in MLLMs for Knowledge-Intensive Visual Grounding",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Ma",
        "Ziyang Ding",
        "Zhicong Luo",
        "Chi Chen",
        "Zonghao Guo",
        "Derek F. Wong",
        "Xiaoyi Feng",
        "Maosong Sun"
      ],
      "abstract": "Human experts excel at fine-grained visual discrimination by leveraging\ndomain knowledge to refine perceptual features, a capability that remains\nunderdeveloped in current Multimodal Large Language Models (MLLMs). Despite\npossessing vast expert-level knowledge, MLLMs struggle to integrate reasoning\ninto visual perception, often generating direct responses without deeper\nanalysis. To bridge this gap, we introduce knowledge-intensive visual grounding\n(KVG), a novel visual grounding task that requires both fine-grained perception\nand domain-specific knowledge integration. To address the challenges of KVG, we\npropose DeepPerception, an MLLM enhanced with cognitive visual perception\ncapabilities. Our approach consists of (1) an automated data synthesis pipeline\nthat generates high-quality, knowledge-aligned training samples, and (2) a\ntwo-stage training framework combining supervised fine-tuning for cognitive\nreasoning scaffolding and reinforcement learning to optimize\nperception-cognition synergy. To benchmark performance, we introduce KVG-Bench\na comprehensive dataset spanning 10 domains with 1.3K manually curated test\ncases. Experimental results demonstrate that DeepPerception significantly\noutperforms direct fine-tuning, achieving +8.08\\% accuracy improvements on\nKVG-Bench and exhibiting +4.60\\% superior cross-domain generalization over\nbaseline approaches. Our findings highlight the importance of integrating\ncognitive processes into MLLMs for human-like visual perception and open new\ndirections for multimodal reasoning research. The data, codes, and models are\nreleased at https://github.com/thunlp/DeepPerception.",
      "tldr_zh": "该论文指出，当前 Multimodal Large Language Models (MLLMs) 虽拥有丰富知识，但难以将推理整合到视觉感知中，因此引入 knowledge-intensive visual grounding (KVG) 任务，以实现精细感知和领域知识的结合。作者提出 DeepPerception 框架，通过自动数据合成管道生成高质量训练样本，以及两阶段训练（监督微调用于认知推理支架，强化学习优化感知-认知协同）来增强 MLLMs 的认知视觉感知能力。为评估性能，他们构建了 KVG-Bench 数据集，涵盖 10 个领域和 1.3K 测试案例。实验结果显示，DeepPerception 比直接微调方法提高了 8.08% 准确率，并在跨域泛化上领先基线 4.60%，为多模态推理研究开辟新路径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12797v2",
      "published_date": "2025-03-17 04:06:34 UTC",
      "updated_date": "2025-03-18 05:06:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:18:34.720037"
    },
    {
      "arxiv_id": "2503.12790v2",
      "title": "Quantum-Enhanced LLM Efficient Fine Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaofei Kong",
        "Lei Li",
        "Zhaoyun Chen",
        "Cheng Xue",
        "Xiaofan Xu",
        "Huanyu Liu",
        "Yuchun Wu",
        "Yuan Fang",
        "Han Fang",
        "Kejiang Chen",
        "Yang Yang",
        "Menghan Dou",
        "Guoping Guo"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) enables efficient fine-tuning of pre-trained\nlanguage models through low-rank matrix approximation, achieving effectiveness\nin many scenarios. However, its representation capacity is constrained in\ncomplex tasks or high-rank dependency settings, potentially limiting model\nadaptability. To overcome the expressive bottleneck in classical low-rank\napproximation for fine-tuning large language models (LLMs), we propose Quantum\nTensor Hybrid Adaptation (QTHA), a parameter-efficient fine-tuning method that\nintegrates a quantum neural network (QNN) with a tensor network. QTHA explores\nquantum tensor hybrid fine-tuning within low-rank spaces by decomposing\npre-trained weights into quantum neural network and tensor network\nrepresentations, leveraging quantum state superposition to overcome classical\nrank limitations. Experiments demonstrate that QTHA achieves performance\ncomparable to or surpassing LoRA in parameter-efficient fine-tuning. Compared\nto LoRA, QTHA reduces trainable parameters by 76% while reducing training loss\nby up to 17% and improving test set performance by up to 17% within the same\ntraining steps. This research not only enables lightweight adaptation of\nquantum resources to the billion-parameter models but also validates the\nfeasibility of quantum hardware optimization driven by LLM tasks. It\nestablishes the first engineering-ready foundation for future quantum-enhanced\nArtificial General Intelligence (AGI) systems.",
      "tldr_zh": "这篇论文针对 Low-Rank Adaptation (LoRA) 在复杂任务中的表示能力限制，提出了一种量子增强的微调方法 Quantum Tensor Hybrid Adaptation (QTHA)，它整合量子神经网络 (QNN) 和张量网络，将预训练权重分解为量子态叠加表示，以克服经典低秩瓶颈。QTHA 在参数高效微调方面表现出色，与 LoRA 相比，减少了 76% 的可训练参数，同时降低了训练损失最多 17% 并提升了测试集性能最多 17%。这项研究不仅验证了量子资源对亿参数语言模型的轻量级适应可行性，还为量子硬件优化驱动的 Artificial General Intelligence (AGI) 系统奠定了工程基础。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12790v2",
      "published_date": "2025-03-17 03:59:26 UTC",
      "updated_date": "2025-04-27 10:23:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:18:45.098763"
    },
    {
      "arxiv_id": "2503.12781v1",
      "title": "SAM2 for Image and Video Segmentation: A Comprehensive Survey",
      "title_zh": "SAM2 用于图像和视频分割：全面综述",
      "authors": [
        "Zhang Jiaxing",
        "Tang Hao"
      ],
      "abstract": "Despite significant advances in deep learning for image and video\nsegmentation, existing models continue to face challenges in cross-domain\nadaptability and generalization. Image and video segmentation are fundamental\ntasks in computer vision with wide-ranging applications in healthcare,\nagriculture, industrial inspection, and autonomous driving. With the advent of\nlarge-scale foundation models, SAM2 - an improved version of SAM (Segment\nAnything Model)has been optimized for segmentation tasks, demonstrating\nenhanced performance in complex scenarios. However, SAM2's adaptability and\nlimitations in specific domains require further investigation. This paper\nsystematically analyzes the application of SAM2 in image and video segmentation\nand evaluates its performance in various fields. We begin by introducing the\nfoundational concepts of image segmentation, categorizing foundation models,\nand exploring the technical characteristics of SAM and SAM2. Subsequently, we\ndelve into SAM2's applications in static image and video segmentation,\nemphasizing its performance in specialized areas such as medical imaging and\nthe challenges of cross-domain adaptability. As part of our research, we\nreviewed over 200 related papers to provide a comprehensive analysis of the\ntopic. Finally, the paper highlights the strengths and weaknesses of SAM2 in\nsegmentation tasks, identifies the technical challenges it faces, and proposes\nfuture development directions. This review provides valuable insights and\npractical recommendations for optimizing and applying SAM2 in real-world\nscenarios.",
      "tldr_zh": "本论文对 SAM2（Segment Anything Model 的改进版本）在图像和视频分割中的应用进行了全面调查，旨在评估其在复杂场景中的性能提升及其跨域适应性挑战。作者首先介绍了图像分割的基础概念、基础模型分类，并比较了 SAM 和 SAM2 的技术特性。论文通过审查超过 200 篇相关文献，分析了 SAM2 在静态图像和视频分割（如医疗成像领域）的实际应用，突出了其优势（如增强性能）以及弱点（如泛化问题）。最终，该研究提出了优化 SAM2 的实用推荐和未来发展方向，以支持其在医疗、农业和自动驾驶等领域的实际部署。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 4 figures, 7 Tables",
      "pdf_url": "http://arxiv.org/pdf/2503.12781v1",
      "published_date": "2025-03-17 03:33:36 UTC",
      "updated_date": "2025-03-17 03:33:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:18:57.339077"
    },
    {
      "arxiv_id": "2503.12780v1",
      "title": "LangDA: Building Context-Awareness via Language for Domain Adaptive Semantic Segmentation",
      "title_zh": "LangDA：通过语言构建上下文感知用于领域自适应语义分割",
      "authors": [
        "Chang Liu",
        "Bavesh Balaji",
        "Saad Hossain",
        "C Thomas",
        "Kwei-Herng Lai",
        "Raviteja Vemulapalli",
        "Alexander Wong",
        "Sirisha Rambhatla"
      ],
      "abstract": "Unsupervised domain adaptation for semantic segmentation (DASS) aims to\ntransfer knowledge from a label-rich source domain to a target domain with no\nlabels. Two key approaches in DASS are (1) vision-only approaches using masking\nor multi-resolution crops, and (2) language-based approaches that use generic\nclass-wise prompts informed by target domain (e.g. \"a {snowy} photo of a\n{class}\"). However, the former is susceptible to noisy pseudo-labels that are\nbiased to the source domain. The latter does not fully capture the intricate\nspatial relationships of objects -- key for dense prediction tasks. To this\nend, we propose LangDA. LangDA addresses these challenges by, first, learning\ncontextual relationships between objects via VLM-generated scene descriptions\n(e.g. \"a pedestrian is on the sidewalk, and the street is lined with\nbuildings.\"). Second, LangDA aligns the entire image features with text\nrepresentation of this context-aware scene caption and learns generalized\nrepresentations via text. With this, LangDA sets the new state-of-the-art\nacross three DASS benchmarks, outperforming existing methods by 2.6%, 1.4% and\n3.9%.",
      "tldr_zh": "这篇论文提出了 LangDA，一种用于无监督域适应语义分割 (DASS) 的方法，通过视觉语言模型 (VLM) 生成的场景描述（如“a pedestrian is on the sidewalk, and the street is lined with buildings”）来学习对象间的上下文关系。LangDA 进一步将图像特征与这些上下文感知的文本表示对齐，从而生成更泛化的表示，解决现有视觉方法受源域偏置和语言方法捕捉空间关系不足的问题。实验结果显示，LangDA 在三个 DASS 基准上设置了新状态-of-the-art，分别比现有方法提高了 2.6%、1.4% 和 3.9%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "stat.ML",
        "68Txx",
        "I.2.1"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12780v1",
      "published_date": "2025-03-17 03:33:28 UTC",
      "updated_date": "2025-03-17 03:33:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:19:09.821085"
    },
    {
      "arxiv_id": "2503.12778v1",
      "title": "Adaptive Deep Learning for Multiclass Breast Cancer Classification via Misprediction Risk Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Gul Sheeraz",
        "Qun Chen",
        "Liu Feiyu",
        "Zhou Fengjin MD"
      ],
      "abstract": "Breast cancer remains one of the leading causes of cancer-related deaths\nworldwide. Early detection is crucial for improving patient outcomes, yet the\ndiagnostic process is often complex and prone to inconsistencies among\npathologists. Computer-aided diagnostic approaches have significantly enhanced\nbreast cancer detection, particularly in binary classification (benign vs.\nmalignant). However, these methods face challenges in multiclass\nclassification, leading to frequent mispredictions. In this work, we propose a\nnovel adaptive learning approach for multiclass breast cancer classification\nusing H&E-stained histopathology images. First, we introduce a misprediction\nrisk analysis framework that quantifies and ranks the likelihood of an image\nbeing mislabeled by a classifier. This framework leverages an interpretable\nrisk model that requires only a small number of labeled samples for training.\nNext, we present an adaptive learning strategy that fine-tunes classifiers\nbased on the specific characteristics of a given dataset. This approach\nminimizes misprediction risk, allowing the classifier to adapt effectively to\nthe target workload. We evaluate our proposed solutions on real benchmark\ndatasets, demonstrating that our risk analysis framework more accurately\nidentifies mispredictions compared to existing methods. Furthermore, our\nadaptive learning approach significantly improves the performance of\nstate-of-the-art deep neural network classifiers.",
      "tldr_zh": "本研究针对乳腺癌多类分类的错误预测问题，提出一种自适应深度学习方法，使用 H&E 染色组织病理图像作为输入。首先，引入 misprediction risk analysis 框架，该框架通过一个可解释的风险模型量化并排名图像被分类器错误标记的可能性，仅需少量标记样本进行训练。其次，该方法采用自适应学习策略，根据数据集特性微调分类器，以最小化错误预测风险。实验结果显示，在真实基准数据集上，该框架比现有方法更准确地识别错误预测，并显著提升了最先进深度神经网络分类器的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12778v1",
      "published_date": "2025-03-17 03:25:28 UTC",
      "updated_date": "2025-03-17 03:25:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:19:19.912164"
    },
    {
      "arxiv_id": "2503.12772v1",
      "title": "NuPlanQA: A Large-Scale Dataset and Benchmark for Multi-View Driving Scene Understanding in Multi-Modal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sung-Yeon Park",
        "Can Cui",
        "Yunsheng Ma",
        "Ahmadreza Moradipari",
        "Rohit Gupta",
        "Kyungtae Han",
        "Ziran Wang"
      ],
      "abstract": "Recent advances in multi-modal large language models (MLLMs) have\ndemonstrated strong performance across various domains; however, their ability\nto comprehend driving scenes remains less proven. The complexity of driving\nscenarios, which includes multi-view information, poses significant challenges\nfor existing MLLMs. In this paper, we introduce NuPlanQA-Eval, a multi-view,\nmulti-modal evaluation benchmark for driving scene understanding. To further\nsupport generalization to multi-view driving scenarios, we also propose\nNuPlanQA-1M, a large-scale dataset comprising 1M real-world visual\nquestion-answering (VQA) pairs. For context-aware analysis of traffic scenes,\nwe categorize our dataset into nine subtasks across three core skills: Road\nEnvironment Perception, Spatial Relations Recognition, and Ego-Centric\nReasoning. Furthermore, we present BEV-LLM, integrating Bird's-Eye-View (BEV)\nfeatures from multi-view images into MLLMs. Our evaluation results reveal key\nchallenges that existing MLLMs face in driving scene-specific perception and\nspatial reasoning from ego-centric perspectives. In contrast, BEV-LLM\ndemonstrates remarkable adaptability to this domain, outperforming other models\nin six of the nine subtasks. These findings highlight how BEV integration\nenhances multi-view MLLMs while also identifying key areas that require further\nrefinement for effective adaptation to driving scenes. To facilitate further\nresearch, we publicly release NuPlanQA at\nhttps://github.com/sungyeonparkk/NuPlanQA.",
      "tldr_zh": "本研究引入了NuPlanQA-Eval，这是一个多视图、多模态基准，用于评估Multi-Modal Large Language Models (MLLMs)在驾驶场景理解中的性能，同时提出了NuPlanQA-1M数据集，包含1M真实世界Visual Question-Answering (VQA)对，并分为九个子任务，涵盖Road Environment Perception、Spatial Relations Recognition和Ego-Centric Reasoning等核心技能。论文提出BEV-LLM模型，通过将Bird's-Eye-View (BEV)特征从多视图图像整合到MLLMs中，增强了对交通场景的上下文感知。实验结果显示，BEV-LLM在九个子任务中胜出六项，显著优于现有模型，突显了多视图驾驶场景中感知和空间推理的挑战。该数据集已公开以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12772v1",
      "published_date": "2025-03-17 03:12:39 UTC",
      "updated_date": "2025-03-17 03:12:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:19:33.513332"
    },
    {
      "arxiv_id": "2503.12761v1",
      "title": "Analyzing sequential activity and travel decisions with interpretable deep inverse reinforcement learning",
      "title_zh": "利用可解释的深度逆强化学习分析顺序活动和旅行决策",
      "authors": [
        "Yuebing Liang",
        "Shenhao Wang",
        "Jiangbo Yu",
        "Zhan Zhao",
        "Jinhua Zhao",
        "Sandy Pentland"
      ],
      "abstract": "Travel demand modeling has shifted from aggregated trip-based models to\nbehavior-oriented activity-based models because daily trips are essentially\ndriven by human activities. To analyze the sequential activity-travel\ndecisions, deep inverse reinforcement learning (DIRL) has proven effective in\nlearning the decision mechanisms by approximating a reward function to\nrepresent preferences and a policy function to replicate observed behavior\nusing deep neural networks (DNNs). However, most existing research has focused\non using DIRL to enhance only prediction accuracy, with limited exploration\ninto interpreting the underlying decision mechanisms guiding sequential\ndecision-making. To address this gap, we introduce an interpretable DIRL\nframework for analyzing activity-travel decision processes, bridging the gap\nbetween data-driven machine learning and theory-driven behavioral models. Our\nproposed framework adapts an adversarial IRL approach to infer the reward and\npolicy functions of activity-travel behavior. The policy function is\ninterpreted through a surrogate interpretable model based on choice\nprobabilities from the policy function, while the reward function is\ninterpreted by deriving both short-term rewards and long-term returns for\nvarious activity-travel patterns. Our analysis of real-world travel survey data\nreveals promising results in two key areas: (i) behavioral pattern insights\nfrom the policy function, highlighting critical factors in decision-making and\nvariations among socio-demographic groups, and (ii) behavioral preference\ninsights from the reward function, indicating the utility individuals gain from\nspecific activity sequences.",
      "tldr_zh": "本文提出了一种可解释的深度逆强化学习(DIRL)框架，用于分析顺序活动和旅行决策，旨在桥接数据驱动机器学习与理论驱动行为模型。框架通过对抗式IRL方法推断奖励函数(reward function)和策略函数(policy function)，并利用代理可解释模型分析策略函数中的行为模式差异（如社会人口统计群体间的决策因素），以及奖励函数中的短期奖励和长期回报。实验基于真实旅行调查数据，揭示了关键决策要素和个体对特定活动序列的效用偏好，为理解人类活动行为提供了新洞见。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12761v1",
      "published_date": "2025-03-17 02:54:02 UTC",
      "updated_date": "2025-03-17 02:54:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:19:44.904328"
    },
    {
      "arxiv_id": "2503.12757v2",
      "title": "MAP: Multi-user Personalization with Collaborative LLM-powered Agents",
      "title_zh": "MAP：多用户个性化与协作LLM驱动代理",
      "authors": [
        "Christine Lee",
        "Jihye Choi",
        "Bilge Mutlu"
      ],
      "abstract": "The widespread adoption of Large Language Models (LLMs) and LLM-powered\nagents in multi-user settings underscores the need for reliable, usable methods\nto accommodate diverse preferences and resolve conflicting directives. Drawing\non conflict resolution theory, we introduce a user-centered workflow for\nmulti-user personalization comprising three stages: Reflection, Analysis, and\nFeedback. We then present MAP -- a \\textbf{M}ulti-\\textbf{A}gent system for\nmulti-user \\textbf{P}ersonalization -- to operationalize this workflow. By\ndelegating subtasks to specialized agents, MAP (1) retrieves and reflects on\nrelevant user information, while enhancing reliability through agent-to-agent\ninteractions, (2) provides detailed analysis for improved transparency and\nusability, and (3) integrates user feedback to iteratively refine results. Our\nuser study findings (n=12) highlight MAP's effectiveness and usability for\nconflict resolution while emphasizing the importance of user involvement in\nresolution verification and failure management. This work highlights the\npotential of multi-agent systems to implement user-centered, multi-user\npersonalization workflows and concludes by offering insights for\npersonalization in multi-user contexts.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)和LLM-powered agents在多用户环境中的个性化需求，提出了一种基于冲突解决理论的用户中心工作流，包括Reflection（反思）、Analysis（分析）和Feedback（反馈）三个阶段。MAP系统作为多智能体框架，通过委托子任务给专业化agents，实现用户信息的检索与反思、详细分析以提升透明度和可用性，以及整合用户反馈进行迭代优化。用户研究（n=12）证明了MAP在冲突解决中的有效性和可用性，同时强调了用户参与验证和故障管理的必要性；这项工作展示了多智能体系统在多用户个性化中的潜力，并为相关应用提供见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.RO",
        "I.2.7; I.2.9; I.2.1"
      ],
      "primary_category": "cs.HC",
      "comment": "In Extended Abstracts of the CHI Conference on Human Factors in\n  Computing Systems (CHI EA '25), April 26-May 1, 2025, Yokohama, Japan",
      "pdf_url": "http://arxiv.org/pdf/2503.12757v2",
      "published_date": "2025-03-17 02:52:10 UTC",
      "updated_date": "2025-03-18 19:15:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:19:56.812232"
    },
    {
      "arxiv_id": "2503.13558v6",
      "title": "Survival Analysis with Machine Learning for Predicting Li-ion Battery Remaining Useful Life",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyuan Xue",
        "Longfei Wei",
        "Dongjing Jiang",
        "Fang Sheng",
        "Russell Greiner",
        "Jianfei Zhang"
      ],
      "abstract": "Battery degradation significantly impacts the reliability and efficiency of\nenergy storage systems, particularly in electric vehicles and industrial\napplications. Predicting the remaining useful life (RUL) of lithium-ion\nbatteries is crucial for optimizing maintenance schedules, reducing costs, and\nimproving safety. Traditional RUL prediction methods often struggle with\nnonlinear degradation patterns and uncertainty quantification. To address these\nchallenges, we propose a hybrid survival analysis framework integrating\nsurvival data reconstruction, survival model learning, and survival probability\nestimation. Our approach transforms battery voltage time series into\ntime-to-failure data using path signatures. The multiple Cox-based survival\nmodels and machine-learning-based methods, such as DeepHit and MTLR, are\nlearned to predict battery failure-free probabilities over time. Experiments\nconducted on the Toyota battery and NASA battery datasets demonstrate the\neffectiveness of our approach, achieving high time-dependent AUC and\nconcordance index (C-Index) while maintaining a low integrated Brier score. The\ndata and source codes for this work are available to the public at\nhttps://github.com/thinkxca/rul.",
      "tldr_zh": "这篇论文针对锂离子电池的剩余可用寿命 (RUL) 预测问题，提出一个混合生存分析框架，以解决传统方法在处理非线性退化模式和不确定性量化方面的挑战。该框架包括生存数据重建（使用路径签名 (path signatures) 将电池电压时间序列转化为时间失效数据）、生存模型学习（基于多个 Cox-based 模型）和生存概率估计（结合机器学习方法如 DeepHit 和 MTLR）。实验在 Toyota 和 NASA 电池数据集上验证了该方法的有效性，实现了高的时间依赖 AUC 和协调指数 (C-Index)，同时保持低的集成 Brier 分数。研究数据和源代码已公开在 GitHub 上。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13558v6",
      "published_date": "2025-03-17 02:49:34 UTC",
      "updated_date": "2025-05-06 15:28:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:20:10.006817"
    },
    {
      "arxiv_id": "2503.12753v1",
      "title": "SafeSlice: Enabling SLA-Compliant O-RAN Slicing via Safe Deep Reinforcement Learning",
      "title_zh": "Safe",
      "authors": [
        "Ahmad M. Nagib",
        "Hatem Abou-Zeid",
        "Hossam S. Hassanein"
      ],
      "abstract": "Deep reinforcement learning (DRL)-based slicing policies have shown\nsignificant success in simulated environments but face challenges in physical\nsystems such as open radio access networks (O-RANs) due to\nsimulation-to-reality gaps. These policies often lack safety guarantees to\nensure compliance with service level agreements (SLAs), such as the strict\nlatency requirements of immersive applications. As a result, a deployed DRL\nslicing agent may make resource allocation (RA) decisions that degrade system\nperformance, particularly in previously unseen scenarios. Real-world immersive\napplications require maintaining SLA constraints throughout deployment to\nprevent risky DRL exploration. In this paper, we propose SafeSlice to address\nboth the cumulative (trajectory-wise) and instantaneous (state-wise) latency\nconstraints of O-RAN slices. We incorporate the cumulative constraints by\ndesigning a sigmoid-based risk-sensitive reward function that reflects the\nslices' latency requirements. Moreover, we build a supervised learning cost\nmodel as part of a safety layer that projects the slicing agent's RA actions to\nthe nearest safe actions, fulfilling instantaneous constraints. We conduct an\nexhaustive experiment that supports multiple services, including real virtual\nreality (VR) gaming traffic, to investigate the performance of SafeSlice under\nextreme and changing deployment conditions. SafeSlice achieves reductions of up\nto 83.23% in average cumulative latency, 93.24% in instantaneous latency\nviolations, and 22.13% in resource consumption compared to the baselines. The\nresults also indicate SafeSlice's robustness to changing the threshold\nconfigurations of latency constraints, a vital deployment scenario that will be\nrealized by the O-RAN paradigm to empower mobile network operators (MNOs).",
      "tldr_zh": "该论文提出SafeSlice框架，利用安全深度强化学习(Safe Deep Reinforcement Learning)来实现O-RAN切片的SLA(Service Level Agreements)合规性，解决传统DRL策略在实际部署中可能违反延迟约束的问题。SafeSlice通过设计基于sigmoid的风险敏感奖励函数处理累计延迟约束，并构建监督学习成本模型作为安全层，将资源分配动作投影到最近的安全动作，以满足瞬时延迟要求。实验结果显示，与基线相比，SafeSlice在多服务场景下平均累计延迟减少83.23%、瞬时延迟违反减少93.24%、资源消耗减少22.13%，并展现出对延迟约束阈值变化的鲁棒性，为O-RAN部署提供可靠支持。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "This article has been accepted for presentation in the IEEE\n  International Conference on Machine Learning for Communication and Networking\n  (ICMLCN) 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.12753v1",
      "published_date": "2025-03-17 02:41:49 UTC",
      "updated_date": "2025-03-17 02:41:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:20:20.858983"
    },
    {
      "arxiv_id": "2503.12739v1",
      "title": "TNCSE: Tensor's Norm Constraints for Unsupervised Contrastive Learning of Sentence Embeddings",
      "title_zh": "TNCSE：",
      "authors": [
        "Tianyu Zong",
        "Bingkang Shi",
        "Hongzhu Yi",
        "Jungang Xu"
      ],
      "abstract": "Unsupervised sentence embedding representation has become a hot research\ntopic in natural language processing. As a tensor, sentence embedding has two\ncritical properties: direction and norm. Existing works have been limited to\nconstraining only the orientation of the samples' representations while\nignoring the features of their module lengths. To address this issue, we\npropose a new training objective that optimizes the training of unsupervised\ncontrastive learning by constraining the module length features between\npositive samples. We combine the training objective of Tensor's Norm\nConstraints with ensemble learning to propose a new Sentence Embedding\nrepresentation framework, TNCSE. We evaluate seven semantic text similarity\ntasks, and the results show that TNCSE and derived models are the current\nstate-of-the-art approach; in addition, we conduct extensive zero-shot\nevaluations, and the results show that TNCSE outperforms other baselines.",
      "tldr_zh": "这篇论文针对无监督对比学习（unsupervised contrastive learning）中的句子嵌入（sentence embeddings），提出了 Tensor's Norm Constraints 的新训练目标，以约束正样本之间的范数特征，解决现有方法忽略张量范数属性的问题。作者将这一目标与集成学习结合，开发了 TNCSE 框架，用于优化句子嵌入表示。在七个语义文本相似性任务上，TNCSE 和其衍生模型达到了当前最先进水平，并在广泛的零样本评估中表现出色，优于其他基线。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.12739v1",
      "published_date": "2025-03-17 02:14:42 UTC",
      "updated_date": "2025-03-17 02:14:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:20:33.584138"
    },
    {
      "arxiv_id": "2503.21790v1",
      "title": "March Madness Tournament Predictions Model: A Mathematical Modeling Approach",
      "title_zh": "March Madness 锦标赛预测模型：一种数学建模方法",
      "authors": [
        "Christian McIver",
        "Karla Avalos",
        "Nikhil Nayak"
      ],
      "abstract": "This paper proposes a model to predict the outcome of the March Madness\ntournament based on historical NCAA basketball data since 2013. The framework\nof this project is a simplification of the FiveThrityEight NCAA March Madness\nprediction model, where the only four predictors of interest are Adjusted\nOffensive Efficiency (ADJOE), Adjusted Defensive Efficiency (ADJDE), Power\nRating, and Two-Point Shooting Percentage Allowed. A logistic regression was\nutilized with the aforementioned metrics to generate a probability of a\nparticular team winning each game. Then, a tournament simulation is developed\nand compared to real-world March Madness brackets to determine the accuracy of\nthe model. Accuracies of performance were calculated using a naive approach and\na Spearman rank correlation coefficient.",
      "tldr_zh": "这篇论文提出了一种基于历史 NCAA 篮球数据（自 2013 年起）的数学模型，用于预测 March Madness 锦标赛结果，该模型简化了 FiveThirtyEight 的预测框架，仅使用 Adjusted Offensive Efficiency (ADJOE)、Adjusted Defensive Efficiency (ADJDE)、Power Rating 和 Two-Point Shooting Percentage Allowed 四个指标。研究采用 logistic regression 生成球队在每场比赛中获胜的概率，并开发锦标赛模拟以与真实赛果比较。模型的准确性通过 naive approach 和 Spearman rank correlation coefficient 计算，展示了其在预测方面的有效性。",
      "categories": [
        "stat.AP",
        "cs.AI",
        "cs.LG",
        "68T01",
        "I.2.0; G.3"
      ],
      "primary_category": "stat.AP",
      "comment": "7 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.21790v1",
      "published_date": "2025-03-17 02:04:31 UTC",
      "updated_date": "2025-03-17 02:04:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:20:44.908552"
    },
    {
      "arxiv_id": "2503.13557v1",
      "title": "APF+: Boosting adaptive-potential function reinforcement learning methods with a W-shaped network for high-dimensional games",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Chen",
        "Lambert Schomaker"
      ],
      "abstract": "Studies in reward shaping for reinforcement learning (RL) have flourished in\nrecent years due to its ability to speed up training. Our previous work\nproposed an adaptive potential function (APF) and showed that APF can\naccelerate the Q-learning with a Multi-layer Perceptron algorithm in the\nlow-dimensional domain. This paper proposes to extend APF with an encoder\n(APF+) for RL state representation, allowing applying APF to the pixel-based\nAtari games using a state-encoding method that projects high-dimensional game's\npixel frames to low-dimensional embeddings. We approach by designing the\nstate-representation encoder as a W-shaped network (W-Net), by using which we\nare able to encode both the background as well as the moving entities in the\ngame frames. Specifically, the embeddings derived from the pre-trained W-Net\nconsist of two latent vectors: One represents the input state, and the other\nrepresents the deviation of the input state's representation from itself. We\nthen incorporate W-Net into APF to train a downstream Dueling Deep Q-Network\n(DDQN), obtain the APF-WNet-DDQN, and demonstrate its effectiveness in Atari\ngame-playing tasks. To evaluate the APF+W-Net module in such high-dimensional\ntasks, we compare with two types of baseline methods: (i) the basic DDQN; and\n(ii) two encoder-replaced APF-DDQN methods where we replace W-Net by (a) an\nunsupervised state representation method called Spatiotemporal Deep Infomax\n(ST-DIM) and (b) a ground truth state representation provided by the Atari\nAnnotated RAM Interface (ARI). The experiment results show that out of 20 Atari\ngames, APF-WNet-DDQN outperforms DDQN (14/20 games) and APF-STDIM-DDQN (13/20\ngames) significantly. In comparison against the APF-ARI-DDQN which employs\nembeddings directly of the detailed game-internal state information, the\nAPF-WNet-DDQN achieves a comparable performance.",
      "tldr_zh": "本研究提出APF+，一种扩展自自适应势函数(Adaptive Potential Function)的强化学习(RL)方法，用于加速高维游戏任务的训练。具体地，APF+引入W-shaped network (W-Net)作为状态表示编码器，将高维像素帧（如Atari游戏）投影到低维嵌入中，同时捕获背景和移动实体，并生成两个潜在向量以表示状态及其偏差。作者将W-Net整合到APF中，训练下游的Dueling Deep Q-Network (DDQN)，形成APF-WNet-DDQN模型。实验结果显示，在20个Atari游戏中，APF-WNet-DDQN在14/20游戏中优于基本DDQN，在13/20游戏中优于使用Spatiotemporal Deep Infomax (ST-DIM)的APF版本，并与使用Atari Annotated RAM Interface (ARI)的基线方法性能相当，从而证明了其在高维RL任务中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "46 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.13557v1",
      "published_date": "2025-03-17 01:53:26 UTC",
      "updated_date": "2025-03-17 01:53:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:20:58.496999"
    },
    {
      "arxiv_id": "2503.12730v1",
      "title": "TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research",
      "title_zh": "TinySQL：用于机制解释性研究的渐进式文本到SQL数据集",
      "authors": [
        "Philip Quirke",
        "Clement Neo",
        "Abir Harrasse",
        "Dhruv Nathawani",
        "Amir Abdullah"
      ],
      "abstract": "Mechanistic interpretability research faces a gap between analyzing simple\ncircuits in toy tasks and discovering features in large models. To bridge this\ngap, we propose text-to-SQL generation as an ideal task to study, as it\ncombines the formal structure of toy tasks with real-world complexity. We\nintroduce TinySQL, a synthetic dataset progressing from basic to advanced SQL\noperations, and train models ranging from 33M to 1B parameters to establish a\ncomprehensive testbed for interpretability. We apply multiple complementary\ninterpretability techniques, including edge attribution patching and sparse\nautoencoders, to identify minimal circuits and components supporting SQL\ngeneration. Our analysis reveals both the potential and limitations of current\ninterpretability methods, showing how circuits can vary even across similar\nqueries. Lastly, we demonstrate how mechanistic interpretability can identify\nflawed heuristics in models and improve synthetic dataset design. Our work\nprovides a comprehensive framework for evaluating and advancing\ninterpretability techniques while establishing clear boundaries for their\nreliable application.",
      "tldr_zh": "本研究提出 TinySQL，这是一个从基本到高级 SQL 操作的合成数据集，旨在桥接机械解释性研究（Mechanistic Interpretability）中简单任务与大型模型分析的差距，并以 text-to-SQL 生成作为研究任务。研究者训练了从 33M 到 1B 参数的模型作为测试床，并应用多种解释性技术，如 edge attribution patching 和 sparse autoencoders，来识别支持 SQL 生成的最小电路和组件。分析结果揭示了这些方法的潜力与局限性，包括电路在类似查询间的差异，并展示了机械解释性如何识别模型中的缺陷启发式并改进数据集设计，最终为评估和推进解释性技术提供了全面框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 19 figures, 7 tables, 18 trained models",
      "pdf_url": "http://arxiv.org/pdf/2503.12730v1",
      "published_date": "2025-03-17 01:47:50 UTC",
      "updated_date": "2025-03-17 01:47:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:21:09.490314"
    },
    {
      "arxiv_id": "2503.16520v1",
      "title": "Not All Personas Are Worth It: Culture-Reflective Persona Data Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Ji-Eun Han",
        "Yoonseok Heo"
      ],
      "abstract": "Incorporating personas into conversational AI models is crucial for achieving\nauthentic and engaging interactions. However, the cultural diversity and\nadaptability of existing persona datasets is often overlooked, reducing their\nefficacy in building culturally aware AI systems. To address this issue, we\npropose a two-step pipeline for generating culture-specific personas and\nintroduce KoPersona, a dataset comprising 200,000 personas designed to capture\nKorean cultural values, behaviors, and social nuances. A comprehensive\nevaluation through various metrics validates the quality of KoPersona and its\nrelevance to Korean culture. This work not only contributes to persona-based\nresearch, but also establishes a scalable approach for creating culturally\nrelevant personas adaptable to various languages and cultural contexts.",
      "tldr_zh": "本研究指出，现有的 personas 数据集往往忽略文化多样性和适应性，导致对话 AI 模型在构建文化感知系统时效果不佳。为解决这一问题，研究提出一个两步管道，用于生成特定文化的 personas，并引入 KoPersona 数据集，该数据集包含 20 万条条目，专门捕捉韩国文化的价值观、行为和社会细微差别。通过各种指标进行全面评估，验证了 KoPersona 的质量及其文化相关性。该工作不仅为 personas 研究提供新贡献，还建立了一个可扩展的方法，适用于创建适应多种语言和文化背景的 personas。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16520v1",
      "published_date": "2025-03-17 01:23:57 UTC",
      "updated_date": "2025-03-17 01:23:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:21:21.166503"
    },
    {
      "arxiv_id": "2503.12722v1",
      "title": "Identifying Cooperative Personalities in Multi-agent Contexts through Personality Steering with Representation Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Kenneth J. K. Ong",
        "Lye Jia Jun",
        "Hieu Minh \"Jord\" Nguyen",
        "Seong Hah Cho",
        "Natalia Pérez-Campanero Antolín"
      ],
      "abstract": "As Large Language Models (LLMs) gain autonomous capabilities, their\ncoordination in multi-agent settings becomes increasingly important. However,\nthey often struggle with cooperation, leading to suboptimal outcomes. Inspired\nby Axelrod's Iterated Prisoner's Dilemma (IPD) tournaments, we explore how\npersonality traits influence LLM cooperation. Using representation engineering,\nwe steer Big Five traits (e.g., Agreeableness, Conscientiousness) in LLMs and\nanalyze their impact on IPD decision-making. Our results show that higher\nAgreeableness and Conscientiousness improve cooperation but increase\nsusceptibility to exploitation, highlighting both the potential and limitations\nof personality-based steering for aligning AI agents.",
      "tldr_zh": "本文研究了如何通过 representation engineering 引导 Large Language Models (LLMs) 中的 Big Five 个性特征（如 Agreeableness 和 Conscientiousness），以提升多智能体环境中的合作能力。受 Iterated Prisoner's Dilemma (IPD) 启发，作者分析了这些个性特征对 LLM 决策的影响，结果显示更高的 Agreeableness 和 Conscientiousness 能改善合作效果，但也增加了被利用的风险。该方法突出了个性引导在对齐 AI 代理方面的潜力与局限性，为未来 AI 协调提供新见解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Poster, Technical AI Safety Conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.12722v1",
      "published_date": "2025-03-17 01:21:54 UTC",
      "updated_date": "2025-03-17 01:21:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:21:33.521252"
    },
    {
      "arxiv_id": "2503.12721v2",
      "title": "Can Reasoning Models Reason about Hardware? An Agentic HLS Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Collini",
        "Andrew Hennessee",
        "Ramesh Karri",
        "Siddharth Garg"
      ],
      "abstract": "Recent Large Language Models (LLMs) such as OpenAI o3-mini and DeepSeek-R1\nuse enhanced reasoning through Chain-of-Thought (CoT). Their potential in\nhardware design, which relies on expert-driven iterative optimization, remains\nunexplored. This paper investigates whether reasoning LLMs can address\nchallenges in High-Level Synthesis (HLS) design space exploration and\noptimization. During HLS, engineers manually define pragmas/directives to\nbalance performance and resource constraints. We propose an LLM-based\noptimization agentic framework that automatically restructures code, inserts\npragmas, and identifies optimal design points via feedback from HLs tools and\naccess to integer-linear programming (ILP) solvers. Experiments compare\nreasoning models against conventional LLMs on benchmarks using success rate,\nefficiency, and design quality (area/latency) metrics, and provide the\nfirst-ever glimpse into the CoTs produced by a powerful open-source reasoning\nmodel like DeepSeek-R1.",
      "tldr_zh": "本研究探讨了基于Chain-of-Thought (CoT)推理的Large Language Models (LLMs)，如OpenAI o3-mini和DeepSeek-R1，在硬件设计领域的潜力，特别是High-Level Synthesis (HLS)设计空间探索和优化。论文提出一个LLM-based优化代理框架，该框架自动重构代码、插入pragmas/directives，并通过HLS工具反馈和integer-linear programming (ILP)求解器识别最佳设计点。实验结果显示，推理模型在基准测试中比传统LLMs在成功率、效率和设计质量（面积/延迟）方面表现出色，并首次揭示了DeepSeek-R1等模型的CoT推理过程。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, submitted for peer review",
      "pdf_url": "http://arxiv.org/pdf/2503.12721v2",
      "published_date": "2025-03-17 01:21:39 UTC",
      "updated_date": "2025-04-14 00:39:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:21:45.086099"
    },
    {
      "arxiv_id": "2503.15546v1",
      "title": "Enforcing Cybersecurity Constraints for LLM-driven Robot Agents for Online Transactions",
      "title_zh": "强制执行网络安全约束以用于 LLM 驱动的机器人代理进行在线交易",
      "authors": [
        "Shraddha Pradipbhai Shah",
        "Aditya Vilas Deshpande"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into autonomous robotic\nagents for conducting online transactions poses significant cybersecurity\nchallenges. This study aims to enforce robust cybersecurity constraints to\nmitigate the risks associated with data breaches, transaction fraud, and system\nmanipulation. The background focuses on the rise of LLM-driven robotic systems\nin e-commerce, finance, and service industries, alongside the vulnerabilities\nthey introduce. A novel security architecture combining blockchain technology\nwith multi-factor authentication (MFA) and real-time anomaly detection was\nimplemented to safeguard transactions. Key performance metrics such as\ntransaction integrity, response time, and breach detection accuracy were\nevaluated, showing improved security and system performance. The results\nhighlight that the proposed architecture reduced fraudulent transactions by\n90%, improved breach detection accuracy to 98%, and ensured secure transaction\nvalidation within a latency of 0.05 seconds. These findings emphasize the\nimportance of cybersecurity in the deployment of LLM-driven robotic systems and\nsuggest a framework adaptable to various online platforms.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)驱动的机器人代理在在线交易中的网络安全挑战，提出了一种强制执行安全约束的方法，以防范数据泄露、交易欺诈和系统操纵。研究设计了一个新型安全架构，结合区块链技术、多因素认证(MFA)和实时异常检测，确保交易的完整性和实时防护。实验评估显示，该架构将欺诈交易减少了90%，将漏洞检测准确率提高到98%，并在0.05秒内完成安全验证，为LLMs驱动的机器人系统在电商、金融等领域提供了一个可扩展的安全框架。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15546v1",
      "published_date": "2025-03-17 01:01:10 UTC",
      "updated_date": "2025-03-17 01:01:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:21:57.620339"
    },
    {
      "arxiv_id": "2503.13556v1",
      "title": "Pareidolic Illusions of Meaning: ChatGPT, Pseudolaw and the Triumph of Form over Substance",
      "title_zh": "翻译失败",
      "authors": [
        "Joe McIntyre"
      ],
      "abstract": "The early 2020s has seen the rise of two strange and potentially quite\nimpactful social phenomena, namely pseudolaw, where users rely upon pseudolegal\narguments that mimic the form and ritual of legal argumentation but\nfundamentally distort the content of law, and generative AI/LLMs, which\ngenerate content that uses probabilistic calculations to create outputs that\nlook like human generated text. This article argues that the juxtaposition of\nthe two phenomena helps to reveal that they both share two fundamental traits\nas both elevate form and appearance over substance and content, and users of\nboth routinely mistake the form for the substance. In drawing upon legal\ntheory, computer science, linguistics and cognitive psychology, the article\nargues that both phenomena rely upon creating illusions of meaning that users\nmistake for the underlying primary phenomenon. I then explore four implications\nof this conception of both phenomena. Firstly, both rely on human tendencies of\nconceptual pareidolia resulting in the erroneous perception of meaningful\nlinguistic legal patterns from nebulous inputs. Secondly, both rely upon the\nconfidence heuristic, the human cognitive bias for treating confidence as a\nproxy for competence. Thirdly, both succeed when the primary concern is with\nthe form of the output and not its content. Fourthly, both rely heavily upon\nthe magical thinking of users and the desire for the promise of the approach to\nbe real. The article argues that the legal context helps to reveal a solution\nfor the problems caused by both phenomena as it is only where users possess\nsufficient legal and technological literacy that it becomes possible to reveal\nto them the illusionary nature of the phenomena.",
      "tldr_zh": "这篇论文探讨了 Pseudolaw 和 generative AI（如 ChatGPT）两个现象的共同特征，即它们都优先形式而非实质，导致用户将表面模仿误认为真实内容。论文通过整合法律理论、计算机科学、语言学和认知心理学，分析两者依赖人类的认知偏差，如概念幻视（conceptual pareidolia）和信心启发式（confidence heuristic），从而制造意义的幻觉。最终，论文强调，提高法律和科技素养是揭示这些现象的幻觉本质，并解决其潜在问题的关键。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "54 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13556v1",
      "published_date": "2025-03-17 00:15:41 UTC",
      "updated_date": "2025-03-17 00:15:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T03:22:09.568450"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 141,
  "processed_papers_count": 141,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T03:22:25.679146"
}