{
  "date": "2024-01-17",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-17 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 和机器学习领域，特别是大型语言模型 (LLM) 在气候变化推理、神经符号推理和强化学习中的应用，以及神经网络在机器人和优化任务中的创新进展。其中，ClimateGPT 论文以其多作者团队（如 Hermann Ney）和实际应用潜力最令人印象深刻，而 LLM 推理和神经符号系统论文则展示了有影响力学者（如 Stephen Wright）的参与，强调了 AI 模型的鲁棒性和实际部署挑战。\n\n下面，我挑选并简要讨论几篇重要或话题度高的论文，先从核心 AI 和机器学习主题入手，再快速掠过其他相关但次要的文章。每个条目包括论文标题（中文 + 英文）、核心学术术语和主要贡献。\n\n### 1. **凸优化和双层优化在神经符号推理与学习中的应用**  \n   **Convex and Bilevel Optimization for Neuro-Symbolic Inference and Learning**  \n   这篇论文由 Stephen Wright 等学者主导，提出了一种基于凸优化和双层优化（bilevel optimization）的框架，用于训练神经符号（NeSy）系统，如 NeuPSL 架构。通过平滑的对偶公式和块坐标下降算法，实现了推理效率提升 100 倍，并在 8 个数据集上提升了 16% 的预测性能。该工作对 AI 推理的鲁棒性有重要启发。\n\n### 2. **ClimateGPT：AI 合成气候变化跨学科研究**  \n   **ClimateGPT: Towards AI Synthesizing Interdisciplinary Research on Climate Change**  \n   这篇多作者论文（包括 Hermann Ney）引入 ClimateGPT 模型家族，使用 7B 和更大规模的 LLM，从头训练或微调以处理气候数据。核心贡献包括分层检索策略、多语言支持和基准测试，实现了与 Llama-2-70B 相当的性能，同时使用可再生能源训练。该模型在气候 AI 中的实际应用潜力高，值得关注。\n\n### 3. **大型语言模型的神经符号推理能力**  \n   **Large Language Models Are Neurosymbolic Reasoners**  \n   论文探讨 LLM 在符号推理任务（如文本游戏）中的性能，通过设计代理系统在符号任务上达到 88% 的平均准确率。核心学术术语包括神经符号推理（neurosymbolic reasoning）和文本游戏基准。该工作证明 LLM 可处理复杂推理，扩展了 AI 在决策领域的应用。\n\n### 4. **Vlogger：基于 LLM 的视频博客生成系统**  \n   **Vlogger: Make Your Dream A Vlog**  \n   该论文提出 Vlogger 系统，使用 LLM 作为“导演”分解视频生成任务，包括脚本、演员和视频片段合成。核心贡献是新型视频扩散模型 ShowMaker，提升了时空一致性和生成质量，能创建 5 分钟以上连贯视频。该方法在生成式 AI 中的创新性强，适用于内容创作。\n\n### 5. **SceneVerse：扩展 3D 视觉语言学习**  \n   **SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding**  \n   论文构建了首个百万级 3D 视觉语言数据集，并提出 Grounded Pre-training for Scenes (GPS) 框架，用于 3D 场景理解。核心学术术语包括视觉语言 grounding 和零样本转移，在基准测试中超越现有模型。该工作推动了 3D AI 在机器人和增强现实中的应用。\n\n其他论文中，如强化学习（Reinforcement Learning）和优化领域的作品（如 Accelerating Data Generation for Neural Operators，优化 PDE 数据生成速度达 13.9 倍），以及机器人相关论文（DiffClone，提升行为克隆效率），也展示了技术进步，但由于篇幅有限，这里仅快速提及：这些工作在边缘计算和机器人任务中提升了效率和鲁棒性，而医疗和区块链论文（如 Impact of Large Language Models on Patients Reading Clinical Notes）则探讨了 AI 的实际影响，但未达到上述核心影响力。\n\n总之，今天的 arXiv 更新突显了 AI 模型在推理和实际应用中的潜力，建议读者关注 LLM 和生成模型方向的论文，以捕捉前沿趋势。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2401.09651v2",
      "title": "Convex and Bilevel Optimization for Neuro-Symbolic Inference and Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Charles Dickens",
        "Changyu Gao",
        "Connor Pryor",
        "Stephen Wright",
        "Lise Getoor"
      ],
      "abstract": "We leverage convex and bilevel optimization techniques to develop a general\ngradient-based parameter learning framework for neural-symbolic (NeSy) systems.\nWe demonstrate our framework with NeuPSL, a state-of-the-art NeSy architecture.\nTo achieve this, we propose a smooth primal and dual formulation of NeuPSL\ninference and show learning gradients are functions of the optimal dual\nvariables. Additionally, we develop a dual block coordinate descent algorithm\nfor the new formulation that naturally exploits warm-starts. This leads to over\n100x learning runtime improvements over the current best NeuPSL inference\nmethod. Finally, we provide extensive empirical evaluations across 8 datasets\ncovering a range of tasks and demonstrate our learning framework achieves up to\na 16% point prediction performance improvement over alternative learning\nmethods.",
      "tldr_zh": "本研究利用凸优化（Convex optimization）和双层优化（Bilevel optimization）技术，开发了一个通用的梯度-based 参数学习框架，用于神经符号（NeSy）系统，特别是针对 NeuPSL 架构。框架通过提出 NeuPSL 的平滑原始和对偶公式化，并基于最佳对偶变量计算学习梯度，同时开发了对偶块坐标下降算法，利用 warm-starts 实现学习运行时超过 100 倍的改进。在 8 个数据集上的广泛实验表明，该框架在各种任务中比其他学习方法提高了多达 16% 的预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09651v2",
      "published_date": "2024-01-17 23:45:53 UTC",
      "updated_date": "2024-06-03 20:15:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:18:54.743728"
    },
    {
      "arxiv_id": "2401.09646v1",
      "title": "ClimateGPT: Towards AI Synthesizing Interdisciplinary Research on Climate Change",
      "title_zh": "翻译失败",
      "authors": [
        "David Thulke",
        "Yingbo Gao",
        "Petrus Pelser",
        "Rein Brune",
        "Rricha Jalota",
        "Floris Fok",
        "Michael Ramos",
        "Ian van Wyk",
        "Abdallah Nasir",
        "Hayden Goldstein",
        "Taylor Tragemann",
        "Katie Nguyen",
        "Ariana Fowler",
        "Andrew Stanco",
        "Jon Gabriel",
        "Jordan Taylor",
        "Dean Moro",
        "Evgenii Tsymbalov",
        "Juliette de Waal",
        "Evgeny Matusov",
        "Mudar Yaghi",
        "Mohammad Shihadah",
        "Hermann Ney",
        "Christian Dugast",
        "Jonathan Dotan",
        "Daniel Erasmus"
      ],
      "abstract": "This paper introduces ClimateGPT, a model family of domain-specific large\nlanguage models that synthesize interdisciplinary research on climate change.\nWe trained two 7B models from scratch on a science-oriented dataset of 300B\ntokens. For the first model, the 4.2B domain-specific tokens were included\nduring pre-training and the second was adapted to the climate domain after\npre-training. Additionally, ClimateGPT-7B, 13B and 70B are continuously\npre-trained from Llama~2 on a domain-specific dataset of 4.2B tokens. Each\nmodel is instruction fine-tuned on a high-quality and human-generated\ndomain-specific dataset that has been created in close cooperation with climate\nscientists. To reduce the number of hallucinations, we optimize the model for\nretrieval augmentation and propose a hierarchical retrieval strategy. To\nincrease the accessibility of our model to non-English speakers, we propose to\nmake use of cascaded machine translation and show that this approach can\nperform comparably to natively multilingual models while being easier to scale\nto a large number of languages. Further, to address the intrinsic\ninterdisciplinary aspect of climate change we consider different research\nperspectives. Therefore, the model can produce in-depth answers focusing on\ndifferent perspectives in addition to an overall answer. We propose a suite of\nautomatic climate-specific benchmarks to evaluate LLMs. On these benchmarks,\nClimateGPT-7B performs on par with the ten times larger Llama-2-70B Chat model\nwhile not degrading results on general domain benchmarks. Our human evaluation\nconfirms the trends we saw in our benchmarks. All models were trained and\nevaluated using renewable energy and are released publicly.",
      "tldr_zh": "本论文引入 ClimateGPT，一种针对气候变化的领域特定大型语言模型（Large Language Models）家族，旨在合成跨学科研究。研究团队训练了多个模型，包括从零开始训练的两个7B模型，以及从Llama 2上持续预训练的ClimateGPT-7B、13B和70B模型，这些模型使用科学导向数据集（如4.2B领域特定tokens）并通过指令微调来提升性能。为减少hallucinations，论文优化了retrieval augmentation并提出分层检索策略，同时采用cascaded machine translation以支持多种语言，并让模型从不同研究视角生成深入答案。在气候特定基准测试中，ClimateGPT-7B的性能与十倍大的Llama-2-70B Chat相当，且不影响一般领域基准；所有模型使用可再生能源训练并公开发布。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09646v1",
      "published_date": "2024-01-17 23:29:46 UTC",
      "updated_date": "2024-01-17 23:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:19:07.865374"
    },
    {
      "arxiv_id": "2401.09640v2",
      "title": "Blackout Mitigation via Physics-guided RL",
      "title_zh": "翻译失败",
      "authors": [
        "Anmol Dwivedi",
        "Santiago Paternain",
        "Ali Tajer"
      ],
      "abstract": "This paper considers the sequential design of remedial control actions in\nresponse to system anomalies for the ultimate objective of preventing\nblackouts. A physics-guided reinforcement learning (RL) framework is designed\nto identify effective sequences of real-time remedial look-ahead decisions\naccounting for the long-term impact on the system's stability. The paper\nconsiders a space of control actions that involve both discrete-valued\ntransmission line-switching decisions (line reconnections and removals) and\ncontinuous-valued generator adjustments. To identify an effective blackout\nmitigation policy, a physics-guided approach is designed that uses power-flow\nsensitivity factors associated with the power transmission network to guide the\nRL exploration during agent training. Comprehensive empirical evaluations using\nthe open-source Grid2Op platform demonstrate the notable advantages of\nincorporating physical signals into RL decisions, establishing the gains of the\nproposed physics-guided approach compared to its black box counterparts. One\nimportant observation is that strategically~\\emph{removing} transmission lines,\nin conjunction with multiple real-time generator adjustments, often renders\neffective long-term decisions that are likely to prevent or delay blackouts.",
      "tldr_zh": "本论文提出了一种基于物理引导的强化学习（RL）框架，用于设计顺序补救控制动作，以响应系统异常并防止停电。该框架考虑长期系统稳定影响，结合电力流动敏感性 factors 指导 RL 代理训练，支持离散值的输电线路切换（如移除和连接）和连续值的发电机调整。实验在 Grid2Op 平台上表明，该方法比黑箱 RL 更具优势，战略性地移除线路结合实时发电机调整可有效延迟或避免停电。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09640v2",
      "published_date": "2024-01-17 23:27:36 UTC",
      "updated_date": "2024-07-31 19:57:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:19:17.159882"
    },
    {
      "arxiv_id": "2401.09637v2",
      "title": "Impact of Large Language Model Assistance on Patients Reading Clinical Notes: A Mixed-Methods Study",
      "title_zh": "大型语言模型辅助对患者阅读临床笔记的影响：一项混合方法研究",
      "authors": [
        "Niklas Mannhardt",
        "Elizabeth Bondi-Kelly",
        "Barbara Lam",
        "Hussein Mozannar",
        "Chloe O'Connell",
        "Mercy Asiedu",
        "Alejandro Buendia",
        "Tatiana Urman",
        "Irbaz B. Riaz",
        "Catherine E. Ricciardi",
        "Monica Agrawal",
        "Marzyeh Ghassemi",
        "David Sontag"
      ],
      "abstract": "Large language models (LLMs) have immense potential to make information more\naccessible, particularly in medicine, where complex medical jargon can hinder\npatient comprehension of clinical notes. We developed a patient-facing tool\nusing LLMs to make clinical notes more readable by simplifying, extracting\ninformation from, and adding context to the notes. We piloted the tool with\nclinical notes donated by patients with a history of breast cancer and\nsynthetic notes from a clinician. Participants (N=200, healthy,\nfemale-identifying patients) were randomly assigned three clinical notes in our\ntool with varying levels of augmentations and answered quantitative and\nqualitative questions evaluating their understanding of follow-up actions.\nAugmentations significantly increased their quantitative understanding scores.\nIn-depth interviews were conducted with participants (N=7, patients with a\nhistory of breast cancer), revealing both positive sentiments about the\naugmentations and concerns about AI. We also performed a qualitative\nclinician-driven analysis of the model's error modes.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在辅助患者阅读临床笔记方面的影响，通过一个混合方法研究 (mixed-methods study) 开发了简化工具，以简化、提取信息并添加上下文。研究招募了200名健康的女性参与者，让她们阅读不同增强水平的临床笔记，结果显示增强显著提高了定量理解分数。深入访谈（7名有乳腺癌历史的患者）揭示了参与者对工具的积极情感，同时表达了对AI的担忧。论文还进行了定性分析，识别了模型的错误模式，为LLMs在医疗领域的应用提供了宝贵见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09637v2",
      "published_date": "2024-01-17 23:14:52 UTC",
      "updated_date": "2024-10-14 23:49:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:19:30.150040"
    },
    {
      "arxiv_id": "2401.09615v2",
      "title": "Learning Shortcuts: On the Misleading Promise of NLU in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Geetanjali Bihani",
        "Julia Taylor Rayz"
      ],
      "abstract": "The advent of large language models (LLMs) has enabled significant\nperformance gains in the field of natural language processing. However, recent\nstudies have found that LLMs often resort to shortcuts when performing tasks,\ncreating an illusion of enhanced performance while lacking generalizability in\ntheir decision rules. This phenomenon introduces challenges in accurately\nassessing natural language understanding in LLMs. Our paper provides a concise\nsurvey of relevant research in this area and puts forth a perspective on the\nimplications of shortcut learning in the evaluation of language models,\nspecifically for NLU tasks. This paper urges more research efforts to be put\ntowards deepening our comprehension of shortcut learning, contributing to the\ndevelopment of more robust language models, and raising the standards of NLU\nevaluation in real-world scenarios.",
      "tldr_zh": "大型语言模型(LLMs)在自然语言处理中虽表现出色，但往往依赖快捷方式(shortcuts)，这导致性能提升的假象，同时缺乏泛化性和真正的自然语言理解(NLU)能力。论文对shortcut learning的相关研究进行简要调查，并分析其对NLU任务评估的挑战，强调这种现象可能误导模型评估。作者呼吁加大研究力度，以开发更鲁棒的语言模型，并提升NLU在真实场景中的评估标准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at HICSS-SDPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.09615v2",
      "published_date": "2024-01-17 21:55:15 UTC",
      "updated_date": "2024-02-09 22:08:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:19:41.839632"
    },
    {
      "arxiv_id": "2401.09572v1",
      "title": "Handling Large-scale Cardinality in building recommendation systems",
      "title_zh": "翻译失败",
      "authors": [
        "Dhruva Dixith Kurra",
        "Bo Ling",
        "Chun Zh",
        "Seyedshahin Ashrafzadeh"
      ],
      "abstract": "Effective recommendation systems rely on capturing user preferences, often\nrequiring incorporating numerous features such as universally unique\nidentifiers (UUIDs) of entities. However, the exceptionally high cardinality of\nUUIDs poses a significant challenge in terms of model degradation and increased\nmodel size due to sparsity. This paper presents two innovative techniques to\naddress the challenge of high cardinality in recommendation systems.\nSpecifically, we propose a bag-of-words approach, combined with layer sharing,\nto substantially decrease the model size while improving performance. Our\ntechniques were evaluated through offline and online experiments on Uber use\ncases, resulting in promising results demonstrating our approach's\neffectiveness in optimizing recommendation systems and enhancing their overall\nperformance.",
      "tldr_zh": "这篇论文探讨了推荐系统中处理大规模基数（high cardinality）问题的挑战，特别是实体UUIDs导致的模型退化和大小增加问题。作者提出两种创新技术，包括结合层共享（layer sharing）的bag-of-words方法，以显著减少模型大小并提升性能。该方法通过Uber用例的离线和在线实验验证，展示了其在优化推荐系统整体性能方面的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09572v1",
      "published_date": "2024-01-17 19:49:11 UTC",
      "updated_date": "2024-01-17 19:49:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:19:52.367937"
    },
    {
      "arxiv_id": "2401.09566v2",
      "title": "Aligning Large Language Models with Counterfactual DPO",
      "title_zh": "翻译失败",
      "authors": [
        "Bradley Butcher"
      ],
      "abstract": "Advancements in large language models (LLMs) have demonstrated remarkable\ncapabilities across a diverse range of applications. These models excel in\ngenerating text completions that are contextually coherent and cover an\nextensive array of subjects. However, the vast datasets required for their\ntraining make aligning response styles during the pretraining and instruction\ntuning phases challenging. Consequently, an additional alignment phase is\ntypically employed, wherein the model is further trained with human preference\ndata to better align its outputs with human expectations. While this process\ndoesn't introduce new capabilities per se, it does accentuate generation styles\ninnate to the model. This paper explores the utilization of counterfactual\nprompting within the framework of Direct Preference Optimization (DPO) to align\nthe model's style without relying on human intervention. We demonstrate that\nthis method effectively instils desirable behaviour, mitigates undesirable\nones, and encourages the model to disregard inappropriate instructions. Our\nfindings suggest that counterfactual prompting with DPO presents a low-resource\nway to fine-tune LLMs to meet the demands for responsible and ethically aligned\nAI systems.",
      "tldr_zh": "该研究探讨了如何使用 Counterfactual Prompting 与 Direct Preference Optimization (DPO) 相结合的方法，对 Large Language Models (LLMs) 进行对齐，以优化其响应风格，而无需依赖人类干预。传统上，LLMs 在预训练和指令微调阶段难以处理响应对齐问题，因此需要额外阶段使用人类偏好数据，本文的方法则通过 counterfactual prompting 有效灌输可取行为、减轻不良输出，并使模型忽略不适当指令。实验结果显示，这种低资源微调方式能显著提升 LLMs 的负责任性和伦理对齐水平，为开发更可靠的 AI 系统提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09566v2",
      "published_date": "2024-01-17 19:43:43 UTC",
      "updated_date": "2024-01-19 08:57:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:20:07.105295"
    },
    {
      "arxiv_id": "2401.09556v2",
      "title": "Deep learning enhanced mixed integer optimization: Learning to reduce model dimensionality",
      "title_zh": "深度学习增强的混合整数优化：学习减少模型维数",
      "authors": [
        "Niki Triantafyllou",
        "Maria M. Papathanasiou"
      ],
      "abstract": "This work introduces a framework to address the computational complexity\ninherent in Mixed-Integer Programming (MIP) models by harnessing the potential\nof deep learning. By employing deep learning, we construct problem-specific\nheuristics that identify and exploit common structures across MIP instances. We\ntrain deep learning models to estimate complicating binary variables for target\nMIP problem instances. The resulting reduced MIP models are solved using\nstandard off-the-shelf solvers. We present an algorithm for generating\nsynthetic data enhancing the robustness and generalizability of our models\nacross diverse MIP instances. We compare the effectiveness of (a) feed-forward\nneural networks (ANN) and (b) convolutional neural networks (CNN). To enhance\nthe framework's performance, we employ Bayesian optimization for hyperparameter\ntuning, aiming to maximize the occurrence of global optimum solutions. We apply\nthis framework to a flow-based facility location allocation MIP formulation\nthat describes long-term investment planning and medium-term tactical\nscheduling in a personalized medicine supply chain.",
      "tldr_zh": "这篇论文提出一个框架，使用深度学习来缓解混合整数规划 (MIP) 模型的计算复杂性，通过构建问题特定的启发式方法来识别并利用 MIP 实例中的常见结构。框架训练深度学习模型（如前馈神经网络 (ANN) 和卷积神经网络 (CNN)）来估计复杂二进制变量，从而生成简化后的 MIP 模型，并使用标准求解器进行求解；同时，引入合成数据生成算法和 Bayesian optimization 进行超参数调优，以提升模型的鲁棒性和全局最优解的频率。该框架应用于流-based 的设施位置分配 MIP 问题，展示了在个性化医学供应链规划中的实际有效性。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09556v2",
      "published_date": "2024-01-17 19:15:13 UTC",
      "updated_date": "2024-05-10 17:42:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:20:18.024018"
    },
    {
      "arxiv_id": "2401.09555v1",
      "title": "Improving Classification Performance With Human Feedback: Label a few, we label the rest",
      "title_zh": "翻译失败",
      "authors": [
        "Natan Vidra",
        "Thomas Clifford",
        "Katherine Jijo",
        "Eden Chung",
        "Liang Zhang"
      ],
      "abstract": "In the realm of artificial intelligence, where a vast majority of data is\nunstructured, obtaining substantial amounts of labeled data to train supervised\nmachine learning models poses a significant challenge. To address this, we\ndelve into few-shot and active learning, where are goal is to improve AI models\nwith human feedback on a few labeled examples. This paper focuses on\nunderstanding how a continuous feedback loop can refine models, thereby\nenhancing their accuracy, recall, and precision through incremental human\ninput. By employing Large Language Models (LLMs) such as GPT-3.5, BERT, and\nSetFit, we aim to analyze the efficacy of using a limited number of labeled\nexamples to substantially improve model accuracy. We benchmark this approach on\nthe Financial Phrasebank, Banking, Craigslist, Trec, Amazon Reviews datasets to\nprove that with just a few labeled examples, we are able to surpass the\naccuracy of zero shot large language models to provide enhanced text\nclassification performance. We demonstrate that rather than needing to manually\nlabel millions of rows of data, we just need to label a few and the model can\neffectively predict the rest.",
      "tldr_zh": "本研究探讨了在数据标记稀缺的场景下，如何通过少量人类反馈提升文本分类性能，采用 few-shot learning 和 active learning 方法建立持续反馈循环。利用 Large Language Models (LLMs) 如 GPT-3.5、BERT 和 SetFit，在 Financial Phrasebank、Banking、Craigslist、Trec 和 Amazon Reviews 等数据集上进行基准测试。结果表明，仅需标记少量样本即可使模型准确率超越零样本基线，并显著提高精确率、召回率和整体性能，从而减少手动标记的需求。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09555v1",
      "published_date": "2024-01-17 19:13:05 UTC",
      "updated_date": "2024-01-17 19:13:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:20:29.065834"
    },
    {
      "arxiv_id": "2401.09553v1",
      "title": "BERTologyNavigator: Advanced Question Answering with BERT-based Semantics",
      "title_zh": "翻译失败",
      "authors": [
        "Shreya Rajpal",
        "Ricardo Usbeck"
      ],
      "abstract": "The development and integration of knowledge graphs and language models has\nsignificance in artificial intelligence and natural language processing. In\nthis study, we introduce the BERTologyNavigator -- a two-phased system that\ncombines relation extraction techniques and BERT embeddings to navigate the\nrelationships within the DBLP Knowledge Graph (KG). Our approach focuses on\nextracting one-hop relations and labelled candidate pairs in the first phases.\nThis is followed by employing BERT's CLS embeddings and additional heuristics\nfor relation selection in the second phase. Our system reaches an F1 score of\n0.2175 on the DBLP QuAD Final test dataset for Scholarly QALD and 0.98 F1 score\non the subset of the DBLP QuAD test dataset during the QA phase.",
      "tldr_zh": "本研究提出BERTologyNavigator，一种先进的问答系统，结合关系提取技术和BERT embeddings，用于导航DBLP Knowledge Graph (KG)中的关系。系统采用两阶段方法：第一阶段提取一跳关系和标记的候选对；第二阶段利用BERT的CLS embeddings以及额外的启发式方法进行关系选择。在DBLP QuAD Final test dataset上，该系统在Scholarly QALD任务中达到0.2175的F1 score，在QA阶段的子集上则获得0.98的F1 score，展示了其在知识图谱问答领域的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.4; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in Scholarly QALD Challenge @ ISWC 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.09553v1",
      "published_date": "2024-01-17 19:11:30 UTC",
      "updated_date": "2024-01-17 19:11:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:20:40.371850"
    },
    {
      "arxiv_id": "2401.09414v1",
      "title": "Vlogger: Make Your Dream A Vlog",
      "title_zh": "Vlogger：让你的梦想成为 Vlog",
      "authors": [
        "Shaobin Zhuang",
        "Kunchang Li",
        "Xinyuan Chen",
        "Yaohui Wang",
        "Ziwei Liu",
        "Yu Qiao",
        "Yali Wang"
      ],
      "abstract": "In this work, we present Vlogger, a generic AI system for generating a\nminute-level video blog (i.e., vlog) of user descriptions. Different from short\nvideos with a few seconds, vlog often contains a complex storyline with\ndiversified scenes, which is challenging for most existing video generation\napproaches. To break through this bottleneck, our Vlogger smartly leverages\nLarge Language Model (LLM) as Director and decomposes a long video generation\ntask of vlog into four key stages, where we invoke various foundation models to\nplay the critical roles of vlog professionals, including (1) Script, (2) Actor,\n(3) ShowMaker, and (4) Voicer. With such a design of mimicking human beings,\nour Vlogger can generate vlogs through explainable cooperation of top-down\nplanning and bottom-up shooting. Moreover, we introduce a novel video diffusion\nmodel, ShowMaker, which serves as a videographer in our Vlogger for generating\nthe video snippet of each shooting scene. By incorporating Script and Actor\nattentively as textual and visual prompts, it can effectively enhance\nspatial-temporal coherence in the snippet. Besides, we design a concise mixed\ntraining paradigm for ShowMaker, boosting its capacity for both T2V generation\nand prediction. Finally, the extensive experiments show that our method\nachieves state-of-the-art performance on zero-shot T2V generation and\nprediction tasks. More importantly, Vlogger can generate over 5-minute vlogs\nfrom open-world descriptions, without loss of video coherence on script and\nactor. The code and model is all available at\nhttps://github.com/zhuangshaobin/Vlogger.",
      "tldr_zh": "本研究提出 Vlogger 系统，一种通用 AI 框架，用于基于用户描述生成分钟级视频博客 (vlog)，通过 Large Language Model (LLM) 作为 Director 将复杂故事线任务分解为四个阶段：Script (脚本)、Actor (演员)、ShowMaker (视频生成)和 Voicer (配音)，以模仿人类合作的顶层规划和底层拍摄方式。系统引入了新型视频扩散模型 ShowMaker，利用 Script 和 Actor 作为提示增强视频片段的空间-时间连贯性，并采用混合训练范式提升 T2V (Text-to-Video) 生成和预测能力。实验结果表明，Vlogger 在零样本 T2V 任务上达到最先进性能，并能生成超过 5 分钟的 vlog，而保持脚本和演员的连贯性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 8 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.09414v1",
      "published_date": "2024-01-17 18:55:12 UTC",
      "updated_date": "2024-01-17 18:55:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:20:55.714256"
    },
    {
      "arxiv_id": "2401.09410v4",
      "title": "Through the Looking-Glass: Transparency Implications and Challenges in Enterprise AI Knowledge Systems",
      "title_zh": "镜中世界：企业AI知识系统中的透明度影响与挑战",
      "authors": [
        "Karina Cortiñas-Lorenzo",
        "Siân Lindley",
        "Ida Larsen-Ledet",
        "Bhaskar Mitra"
      ],
      "abstract": "Knowledge can't be disentangled from people. As AI knowledge systems mine\nvast volumes of work-related data, the knowledge that's being extracted and\nsurfaced is intrinsically linked to the people who create and use it. When\npredictive algorithms that learn from data are used to link knowledge and\npeople, inaccuracies in knowledge extraction and surfacing can lead to\ndisproportionate harms, influencing how individuals see each other and how they\nsee themselves at work. In this paper, we present a reflective analysis of\ntransparency requirements and impacts in this type of systems. We conduct a\nmultidisciplinary literature review to understand the impacts of transparency\nin workplace settings, introducing the looking-glass metaphor to conceptualize\nAI knowledge systems as systems that reflect and distort, expanding our view on\ntransparency requirements, implications and challenges. We formulate\ntransparency as a key mediator in shaping different ways of seeing, including\nseeing into the system, which unveils its capabilities, limitations and\nbehavior, and seeing through the system, which shapes workers' perceptions of\ntheir own contributions and others within the organization. Recognizing the\nsociotechnical nature of these systems, we identify three transparency\ndimensions necessary to realize the value of AI knowledge systems, namely\nsystem transparency, procedural transparency and transparency of outcomes. We\ndiscuss key challenges hindering the implementation of these forms of\ntransparency, bringing to light the wider sociotechnical gap and highlighting\ndirections for future Computer-supported Cooperative Work (CSCW) research.",
      "tldr_zh": "本论文通过多学科文献综述，探讨了企业 AI knowledge systems 中透明度的含义和挑战，使用“looking-glass”隐喻来描述这些系统如何反射和扭曲工作场所的知识与人际关系。研究将透明度视为关键调解器，包括 seeing into the system（揭示系统的能力、限制和行为）和 seeing through the system（塑造员工对自身及他人贡献的认知），并提出了三个必要维度：system transparency、procedural transparency 和 transparency of outcomes。论文强调了实施这些透明度的挑战，如社会技术差距，并为未来的 Computer-supported Cooperative Work (CSCW) 研究提供了方向，以减少算法不准确性带来的不公平伤害。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09410v4",
      "published_date": "2024-01-17 18:47:30 UTC",
      "updated_date": "2025-03-01 00:55:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:21:06.324814"
    },
    {
      "arxiv_id": "2401.10942v1",
      "title": "Machine Unlearning for Recommendation Systems: An Insight",
      "title_zh": "翻译失败",
      "authors": [
        "Bhavika Sachdeva",
        "Harshita Rathee",
        "Sristi",
        "Arun Sharma",
        "Witold Wydmański"
      ],
      "abstract": "This review explores machine unlearning (MUL) in recommendation systems,\naddressing adaptability, personalization, privacy, and bias challenges. Unlike\ntraditional models, MUL dynamically adjusts system knowledge based on shifts in\nuser preferences and ethical considerations. The paper critically examines\nMUL's basics, real-world applications, and challenges like algorithmic\ntransparency. It sifts through literature, offering insights into how MUL could\ntransform recommendations, discussing user trust, and suggesting paths for\nfuture research in responsible and user-focused artificial intelligence (AI).\nThe document guides researchers through challenges involving the trade-off\nbetween personalization and privacy, encouraging contributions to meet\npractical demands for targeted data removal. Emphasizing MUL's role in secure\nand adaptive machine learning, the paper proposes ways to push its boundaries.\nThe novelty of this paper lies in its exploration of the limitations of the\nmethods, which highlights exciting prospects for advancing the field.",
      "tldr_zh": "本综述探讨了 Machine Unlearning (MUL) 在推荐系统中的应用，重点解决适应性、个性化、隐私和偏见等挑战，通过动态调整系统知识来应对用户偏好变化和伦理问题。论文审视了 MUL 的基础、实际应用和算法透明度等挑战，并通过文献分析提供见解，帮助提升用户信任和推荐系统的变革潜力。最终，它强调了个性化与隐私权衡中的难题，提出未来研究路径以推进负责任的 AI，并突出 MUL 在安全适应性机器学习领域的创新前景。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "In Proceedings of 7th INTERNATIONAL CONFERENCE ON INNOVATIVE\n  COMPUTING AND COMMUNICATION 2024 (https://icicc-conf.com/)",
      "pdf_url": "http://arxiv.org/pdf/2401.10942v1",
      "published_date": "2024-01-17 18:35:44 UTC",
      "updated_date": "2024-01-17 18:35:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:21:17.164814"
    },
    {
      "arxiv_id": "2401.09352v1",
      "title": "Neural Contractive Dynamical Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Hadi Beik-Mohammadi",
        "Søren Hauberg",
        "Georgios Arvanitidis",
        "Nadia Figueroa",
        "Gerhard Neumann",
        "Leonel Rozo"
      ],
      "abstract": "Stability guarantees are crucial when ensuring a fully autonomous robot does\nnot take undesirable or potentially harmful actions. Unfortunately, global\nstability guarantees are hard to provide in dynamical systems learned from\ndata, especially when the learned dynamics are governed by neural networks. We\npropose a novel methodology to learn neural contractive dynamical systems,\nwhere our neural architecture ensures contraction, and hence, global stability.\nTo efficiently scale the method to high-dimensional dynamical systems, we\ndevelop a variant of the variational autoencoder that learns dynamics in a\nlow-dimensional latent representation space while retaining contractive\nstability after decoding. We further extend our approach to learning\ncontractive systems on the Lie group of rotations to account for full-pose\nend-effector dynamic motions. The result is the first highly flexible learning\narchitecture that provides contractive stability guarantees with capability to\nperform obstacle avoidance. Empirically, we demonstrate that our approach\nencodes the desired dynamics more accurately than the current state-of-the-art,\nwhich provides less strong stability guarantees.",
      "tldr_zh": "该研究提出了一种名为“neural contractive dynamical systems”的新方法，用于从数据学习动力系统，同时确保全局稳定性，避免机器人采取有害动作。该方法通过神经网络架构强制实现收缩（contraction），并开发了一种变体变分自动编码器（variational autoencoder），在低维潜在空间学习高维动态，同时保留解码后的contractive stability。此外，该方法扩展到旋转的Lie group of rotations，以处理全姿势末端执行器动态运动，并支持obstacle avoidance；实验结果显示，其比现有最先进方法更准确地编码所需动态，同时提供更强的稳定性保证。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09352v1",
      "published_date": "2024-01-17 17:18:21 UTC",
      "updated_date": "2024-01-17 17:18:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:21:31.006075"
    },
    {
      "arxiv_id": "2401.09340v3",
      "title": "SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Baoxiong Jia",
        "Yixin Chen",
        "Huangyue Yu",
        "Yan Wang",
        "Xuesong Niu",
        "Tengyu Liu",
        "Qing Li",
        "Siyuan Huang"
      ],
      "abstract": "3D vision-language grounding, which focuses on aligning language with the 3D\nphysical environment, stands as a cornerstone in the development of embodied\nagents. In comparison to recent advancements in the 2D domain, grounding\nlanguage in 3D scenes faces several significant challenges: (i) the inherent\ncomplexity of 3D scenes due to the diverse object configurations, their rich\nattributes, and intricate relationships; (ii) the scarcity of paired 3D\nvision-language data to support grounded learning; and (iii) the absence of a\nunified learning framework to distill knowledge from grounded 3D data. In this\nwork, we aim to address these three major challenges in 3D vision-language by\nexamining the potential of systematically upscaling 3D vision-language learning\nin indoor environments. We introduce the first million-scale 3D vision-language\ndataset, SceneVerse, encompassing about 68K 3D indoor scenes and comprising\n2.5M vision-language pairs derived from both human annotations and our scalable\nscene-graph-based generation approach. We demonstrate that this scaling allows\nfor a unified pre-training framework, Grounded Pre-training for Scenes (GPS),\nfor 3D vision-language learning. Through extensive experiments, we showcase the\neffectiveness of GPS by achieving state-of-the-art performance on all existing\n3D visual grounding benchmarks. The vast potential of SceneVerse and GPS is\nunveiled through zero-shot transfer experiments in the challenging 3D\nvision-language tasks. Project website: https://scene-verse.github.io.",
      "tldr_zh": "这篇论文针对3D视觉-语言grounding（将语言与3D物理环境对齐）的挑战，引入了首个百万级数据集SceneVerse，该数据集包含约68K 3D室内场景和2.5M视觉-语言对，通过人类标注和可扩展的scene-graph-based生成方法构建。论文提出统一的预训练框架Grounded Pre-training for Scenes (GPS)，用于从grounded 3D数据中提炼知识，并通过广泛实验证明GPS在现有3D视觉grounding基准上达到state-of-the-art性能。零-shot转移实验进一步展示了SceneVerse和GPS在复杂3D视觉-语言任务中的强大潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.09340v3",
      "published_date": "2024-01-17 17:04:35 UTC",
      "updated_date": "2024-09-24 03:18:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:21:43.147920"
    },
    {
      "arxiv_id": "2401.09334v1",
      "title": "Large Language Models Are Neurosymbolic Reasoners",
      "title_zh": "翻译失败",
      "authors": [
        "Meng Fang",
        "Shilong Deng",
        "Yudi Zhang",
        "Zijing Shi",
        "Ling Chen",
        "Mykola Pechenizkiy",
        "Jun Wang"
      ],
      "abstract": "A wide range of real-world applications is characterized by their symbolic\nnature, necessitating a strong capability for symbolic reasoning. This paper\ninvestigates the potential application of Large Language Models (LLMs) as\nsymbolic reasoners. We focus on text-based games, significant benchmarks for\nagents with natural language capabilities, particularly in symbolic tasks like\nmath, map reading, sorting, and applying common sense in text-based worlds. To\nfacilitate these agents, we propose an LLM agent designed to tackle symbolic\nchallenges and achieve in-game objectives. We begin by initializing the LLM\nagent and informing it of its role. The agent then receives observations and a\nset of valid actions from the text-based games, along with a specific symbolic\nmodule. With these inputs, the LLM agent chooses an action and interacts with\nthe game environments. Our experimental results demonstrate that our method\nsignificantly enhances the capability of LLMs as automated agents for symbolic\nreasoning, and our LLM agent is effective in text-based games involving\nsymbolic tasks, achieving an average performance of 88% across all tasks.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 作为符号推理器的潜力，重点针对文本-based games 中的符号任务，如数学、地图阅读、排序和常识应用。研究者提出了一种 LLM 代理，通过初始化角色、接收观察、有效动作和特定符号模块来选择动作并与游戏环境互动，从而提升符号推理能力。实验结果表明，该方法显著提高了 LLMs 的自动化代理性能，在各种符号任务中平均达到 88% 的表现水平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.09334v1",
      "published_date": "2024-01-17 16:57:19 UTC",
      "updated_date": "2024-01-17 16:57:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:21:53.769815"
    },
    {
      "arxiv_id": "2401.09322v1",
      "title": "FIT-SLAM -- Fisher Information and Traversability estimation-based Active SLAM for exploration in 3D environments",
      "title_zh": "翻译失败",
      "authors": [
        "Suchetan Saravanan",
        "Corentin Chauffaut",
        "Caroline Chanel",
        "Damien Vivet"
      ],
      "abstract": "Active visual SLAM finds a wide array of applications in GNSS-Denied\nsub-terrain environments and outdoor environments for ground robots. To achieve\nrobust localization and mapping accuracy, it is imperative to incorporate the\nperception considerations in the goal selection and path planning towards the\ngoal during an exploration mission. Through this work, we propose FIT-SLAM\n(Fisher Information and Traversability estimation-based Active SLAM), a new\nexploration method tailored for unmanned ground vehicles (UGVs) to explore 3D\nenvironments. This approach is devised with the dual objectives of sustaining\nan efficient exploration rate while optimizing SLAM accuracy. Initially, an\nestimation of a global traversability map is conducted, which accounts for the\nenvironmental constraints pertaining to traversability. Subsequently, we\npropose a goal candidate selection approach along with a path planning method\ntowards this goal that takes into account the information provided by the\nlandmarks used by the SLAM backend to achieve robust localization and\nsuccessful path execution . The entire algorithm is tested and evaluated first\nin a simulated 3D world, followed by a real-world environment and is compared\nto pre-existing exploration methods. The results obtained during this\nevaluation demonstrate a significant increase in the exploration rate while\neffectively minimizing the localization covariance.",
      "tldr_zh": "本研究提出 FIT-SLAM，一种基于 Fisher Information 和 Traversability 估计的 Active SLAM 方法，旨在帮助无人地面车辆 (UGVs) 在 3D 环境（如 GNSS-Denied 区域）中进行高效探索，同时优化 SLAM 准确性。该方法首先构建全局 Traversability 地图以评估环境约束，然后结合 landmarks 信息进行目标候选选择和路径规划，确保鲁棒定位和成功路径执行。在模拟和真实环境中测试，FIT-SLAM 与现有方法相比，显著提高了探索率并有效最小化了定位协方差。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 6 figures, IEEE ICARA 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.09322v1",
      "published_date": "2024-01-17 16:46:38 UTC",
      "updated_date": "2024-01-17 16:46:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:22:05.289253"
    },
    {
      "arxiv_id": "2401.09516v2",
      "title": "Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling",
      "title_zh": "通过 Krylov 子",
      "authors": [
        "Hong Wang",
        "Zhongkai Hao",
        "Jie Wang",
        "Zijie Geng",
        "Zhen Wang",
        "Bin Li",
        "Feng Wu"
      ],
      "abstract": "Learning neural operators for solving partial differential equations (PDEs)\nhas attracted great attention due to its high inference efficiency. However,\ntraining such operators requires generating a substantial amount of labeled\ndata, i.e., PDE problems together with their solutions. The data generation\nprocess is exceptionally time-consuming, as it involves solving numerous\nsystems of linear equations to obtain numerical solutions to the PDEs. Many\nexisting methods solve these systems independently without considering their\ninherent similarities, resulting in extremely redundant computations. To tackle\nthis problem, we propose a novel method, namely Sorting Krylov Recycling (SKR),\nto boost the efficiency of solving these systems, thus significantly\naccelerating data generation for neural operators training. To the best of our\nknowledge, SKR is the first attempt to address the time-consuming nature of\ndata generation for learning neural operators. The working horse of SKR is\nKrylov subspace recycling, a powerful technique for solving a series of\ninterrelated systems by leveraging their inherent similarities. Specifically,\nSKR employs a sorting algorithm to arrange these systems in a sequence, where\nadjacent systems exhibit high similarities. Then it equips a solver with Krylov\nsubspace recycling to solve the systems sequentially instead of independently,\nthus effectively enhancing the solving efficiency. Both theoretical analysis\nand extensive experiments demonstrate that SKR can significantly accelerate\nneural operator data generation, achieving a remarkable speedup of up to 13.9\ntimes.",
      "tldr_zh": "这篇论文针对训练神经算子（Neural Operators）用于解决偏微分方程（PDEs）时的数据生成问题，提出了一种新方法Sorting Krylov Recycling (SKR)，旨在通过利用系统间的相似性来加速解决线性方程系统，从而减少冗余计算。SKR 采用排序算法将相关系统按相似度顺序排列，并结合Krylov子空间回收技术顺序解决这些系统，这是首次针对神经算子数据生成耗时问题的解决方案。实验结果显示，SKR 可将数据生成过程加速高达13.9倍，同时理论分析证明了其高效性，为PDEs相关神经模型训练提供了显著优化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09516v2",
      "published_date": "2024-01-17 16:20:12 UTC",
      "updated_date": "2024-03-19 08:46:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:22:18.196643"
    },
    {
      "arxiv_id": "2401.09294v1",
      "title": "T-FOLEY: A Controllable Waveform-Domain Diffusion Model for Temporal-Event-Guided Foley Sound Synthesis",
      "title_zh": "T-FOLEY：一种可控波形域扩散模型，用于时间事件引导的Foley声音合成",
      "authors": [
        "Yoonjin Chung",
        "Junwon Lee",
        "Juhan Nam"
      ],
      "abstract": "Foley sound, audio content inserted synchronously with videos, plays a\ncritical role in the user experience of multimedia content. Recently, there has\nbeen active research in Foley sound synthesis, leveraging the advancements in\ndeep generative models. However, such works mainly focus on replicating a\nsingle sound class or a textual sound description, neglecting temporal\ninformation, which is crucial in the practical applications of Foley sound. We\npresent T-Foley, a Temporal-event-guided waveform generation model for Foley\nsound synthesis. T-Foley generates high-quality audio using two conditions: the\nsound class and temporal event feature. For temporal conditioning, we devise a\ntemporal event feature and a novel conditioning technique named Block-FiLM.\nT-Foley achieves superior performance in both objective and subjective\nevaluation metrics and generates Foley sound well-synchronized with the\ntemporal events. Additionally, we showcase T-Foley's practical applications,\nparticularly in scenarios involving vocal mimicry for temporal event control.\nWe show the demo on our companion website.",
      "tldr_zh": "本研究提出T-Foley，一种基于波形域扩散模型的Foley声音合成框架，旨在通过声音类和时间事件特征实现对音频的精确时序控制，解决现有方法忽略时间信息的局限性。T-Foley采用新型条件技术Block-FiLM来处理时间事件特征，确保生成的高质量音频与视频事件同步。在客观和主观评估中，T-Foley表现出色，准确率和同步性优于基线模型，并展示了实际应用如语音模仿控制，伴有演示网站。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09294v1",
      "published_date": "2024-01-17 15:54:36 UTC",
      "updated_date": "2024-01-17 15:54:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:22:28.755188"
    },
    {
      "arxiv_id": "2401.09286v2",
      "title": "Deployable Reinforcement Learning with Variable Control Rate",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Wang",
        "Giovanni Beltrame"
      ],
      "abstract": "Deploying controllers trained with Reinforcement Learning (RL) on real robots\ncan be challenging: RL relies on agents' policies being modeled as Markov\nDecision Processes (MDPs), which assume an inherently discrete passage of time.\nThe use of MDPs results in that nearly all RL-based control systems employ a\nfixed-rate control strategy with a period (or time step) typically chosen based\non the developer's experience or specific characteristics of the application\nenvironment. Unfortunately, the system should be controlled at the highest,\nworst-case frequency to ensure stability, which can demand significant\ncomputational and energy resources and hinder the deployability of the\ncontroller on onboard hardware. Adhering to the principles of reactive\nprogramming, we surmise that applying control actions only when necessary\nenables the use of simpler hardware and helps reduce energy consumption. We\nchallenge the fixed frequency assumption by proposing a variant of RL with\nvariable control rate. In this approach, the policy decides the action the\nagent should take as well as the duration of the time step associated with that\naction. In our new setting, we expand Soft Actor-Critic (SAC) to compute the\noptimal policy with a variable control rate, introducing the Soft Elastic\nActor-Critic (SEAC) algorithm. We show the efficacy of SEAC through a\nproof-of-concept simulation driving an agent with Newtonian kinematics. Our\nexperiments show higher average returns, shorter task completion times, and\nreduced computational resources when compared to fixed rate policies.",
      "tldr_zh": "本文研究了强化学习 (RL) 在真实机器人部署中的挑战，特别是其依赖马尔可夫决策过程 (MDPs) 的离散时间假设，导致采用固定控制频率并增加资源消耗。作者提出了一种 RL 变体，支持可变控制率，让策略不仅决定动作，还指定每个动作的时间步长，并扩展 Soft Actor-Critic (SAC) 算法为 Soft Elastic Actor-Critic (SEAC)。实验通过模拟牛顿动力学代理显示，SEAC 比固定率策略实现了更高的平均回报、更短的任务完成时间和更低的计算资源需求。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Paper for AAAI-DAI 2024 workshop",
      "pdf_url": "http://arxiv.org/pdf/2401.09286v2",
      "published_date": "2024-01-17 15:40:11 UTC",
      "updated_date": "2024-04-02 17:18:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:22:42.842765"
    },
    {
      "arxiv_id": "2401.09252v1",
      "title": "3D Scene Geometry Estimation from 360$^\\circ$ Imagery: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Thiago Lopes Trugillo da Silveira",
        "Paulo Gamarra Lessa Pinto",
        "Jeffri Erwin Murrugarra Llerena",
        "Claudio Rosito Jung"
      ],
      "abstract": "This paper provides a comprehensive survey on pioneer and state-of-the-art 3D\nscene geometry estimation methodologies based on single, two, or multiple\nimages captured under the omnidirectional optics. We first revisit the basic\nconcepts of the spherical camera model, and review the most common acquisition\ntechnologies and representation formats suitable for omnidirectional (also\ncalled 360$^\\circ$, spherical or panoramic) images and videos. We then survey\nmonocular layout and depth inference approaches, highlighting the recent\nadvances in learning-based solutions suited for spherical data. The classical\nstereo matching is then revised on the spherical domain, where methodologies\nfor detecting and describing sparse and dense features become crucial. The\nstereo matching concepts are then extrapolated for multiple view camera setups,\ncategorizing them among light fields, multi-view stereo, and structure from\nmotion (or visual simultaneous localization and mapping). We also compile and\ndiscuss commonly adopted datasets and figures of merit indicated for each\npurpose and list recent results for completeness. We conclude this paper by\npointing out current and future trends.",
      "tldr_zh": "这篇论文对基于 360° 图像的 3D 场景几何估计方法进行了全面调查，涵盖了从单图像到多视图设置的先驱和最新技术。首先，它回顾了 spherical camera model 的基本概念、常见采集技术和表示格式，并重点讨论了 monocular layout and depth inference 的学习方法，以及在球形域中的 stereo matching 和特征检测。随后，论文扩展到多视图场景，包括 light fields、multi-view stereo 和 structure from motion（SfM），并编译了常用数据集、评估指标和最新结果。最后，它总结了当前挑战和未来趋势，如更先进的深度学习应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in ACM Computing Surveys",
      "pdf_url": "http://arxiv.org/pdf/2401.09252v1",
      "published_date": "2024-01-17 14:57:27 UTC",
      "updated_date": "2024-01-17 14:57:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:22:56.896956"
    },
    {
      "arxiv_id": "2401.09243v3",
      "title": "DiffClone: Enhanced Behaviour Cloning in Robotics with Diffusion-Driven Policy Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Sabariswaran Mani",
        "Sreyas Venkataraman",
        "Abhranil Chandra",
        "Adyan Rizvi",
        "Yash Sirvi",
        "Soumojit Bhattacharya",
        "Aritra Hazra"
      ],
      "abstract": "Robot learning tasks are extremely compute-intensive and hardware-specific.\nThus the avenues of tackling these challenges, using a diverse dataset of\noffline demonstrations that can be used to train robot manipulation agents, is\nvery appealing. The Train-Offline-Test-Online (TOTO) Benchmark provides a\nwell-curated open-source dataset for offline training comprised mostly of\nexpert data and also benchmark scores of the common offline-RL and behaviour\ncloning agents. In this paper, we introduce DiffClone, an offline algorithm of\nenhanced behaviour cloning agent with diffusion-based policy learning, and\nmeasured the efficacy of our method on real online physical robots at test\ntime. This is also our official submission to the Train-Offline-Test-Online\n(TOTO) Benchmark Challenge organized at NeurIPS 2023. We experimented with both\npre-trained visual representation and agent policies. In our experiments, we\nfind that MOCO finetuned ResNet50 performs the best in comparison to other\nfinetuned representations. Goal state conditioning and mapping to transitions\nresulted in a minute increase in the success rate and mean-reward. As for the\nagent policy, we developed DiffClone, a behaviour cloning agent improved using\nconditional diffusion.",
      "tldr_zh": "这篇论文提出了DiffClone，一种增强行为克隆(Behaviour Cloning)算法，通过扩散驱动策略学习(Diffusion-Driven Policy Learning)来解决机器人学习任务的计算密集和硬件依赖问题。研究者利用Train-Offline-Test-Online (TOTO) Benchmark数据集进行离线训练，结合预训练视觉表示如MOCO finetuned ResNet50，并通过目标状态条件和转换映射来微调代理策略。实验结果显示，DiffClone在真实在线物理机器人测试中成功率和平均奖励略有提升，并作为NeurIPS 2023 TOTO Benchmark Challenge的官方参赛作品，展示了其在机器人操作代理训练中的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "NeurIPS 2023 Train Offline Test Online Workshop and Competition (Best\n  Paper Oral Presentation / Winning Competition Submission)",
      "pdf_url": "http://arxiv.org/pdf/2401.09243v3",
      "published_date": "2024-01-17 14:43:59 UTC",
      "updated_date": "2024-05-23 21:51:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:23:09.654107"
    },
    {
      "arxiv_id": "2401.09240v1",
      "title": "A Blockchain-based Model for Securing Data Pipeline in a Heterogeneous Information System",
      "title_zh": "基于区块链的模型，用于保护异构信息系统中的数据管道",
      "authors": [
        "MN Ramahlosi",
        "Y Madani",
        "A Akanbi"
      ],
      "abstract": "In our digital world, access to personal and public data has become an item\nof concern, with challenging security and privacy aspects. Modern information\nsystems are heterogeneous in nature and have an inherent security\nvulnerability, which is susceptible to data interception and data modification\ndue to unsecured communication data pipelines between connected endpoints. This\nre-search article presents a blockchain-based model for securing data pipelines\nin a heterogeneous information system using an integrated multi-hazard early\nwarning system (MHEWS) as a case study. The proposed model utilizes the\ninherent security features of blockchain technology to address the security and\nprivacy concerns that arise in data pipelines. The model is designed to ensure\ndata integrity, confidentiality, and authenticity in a decentralized manner.\nThe model is evaluated in a hybrid environment using a prototype implementation\nand simulation experiments with outcomes that demonstrate advantages over\ntraditional approaches for a tamper-proof and immutable data pipeline for data\nauthenticity and integrity using a confidential ledger.",
      "tldr_zh": "这篇论文针对异构信息系统（Heterogeneous Information System）中数据管道的安全漏洞，如数据拦截和修改，提出了一种基于 Blockchain 的模型。模型以多危害早期预警系统（MHEWS）为案例研究，利用 Blockchain 的固有特性（如去中心化、防篡改）来确保数据完整性、保密性和真实性。实验通过原型实现和模拟在混合环境中进行，结果显示该模型比传统方法更具优势，提供了一个不可变的保密账本（Confidential Ledger）。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.09240v1",
      "published_date": "2024-01-17 14:40:09 UTC",
      "updated_date": "2024-01-17 14:40:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:23:20.396813"
    },
    {
      "arxiv_id": "2401.09239v1",
      "title": "DaFoEs: Mixing Datasets towards the generalization of vision-state deep-learning Force Estimation in Minimally Invasive Robotic Surgery",
      "title_zh": "翻译失败",
      "authors": [
        "Mikel De Iturrate Reyzabal",
        "Mingcong Chen",
        "Wei Huang",
        "Sebastien Ourselin",
        "Hongbin Liu"
      ],
      "abstract": "Precisely determining the contact force during safe interaction in Minimally\nInvasive Robotic Surgery (MIRS) is still an open research challenge. Inspired\nby post-operative qualitative analysis from surgical videos, the use of\ncross-modality data driven deep neural network models has been one of the\nnewest approaches to predict sensorless force trends. However, these methods\nrequired for large and variable datasets which are not currently available. In\nthis paper, we present a new vision-haptic dataset (DaFoEs) with variable soft\nenvironments for the training of deep neural models. In order to reduce the\nbias from a single dataset, we present a pipeline to generalize different\nvision and state data inputs for mixed dataset training, using a previously\nvalidated dataset with different setup. Finally, we present a variable\nencoder-decoder architecture to predict the forces done by the laparoscopic\ntool using single input or sequence of inputs. For input sequence, we use a\nrecurrent decoder, named with the prefix R, and a new temporal sampling to\nrepresent the acceleration of the tool. During our training, we demonstrate\nthat single dataset training tends to overfit to the training data domain, but\nhas difficulties on translating the results across new domains. However,\ndataset mixing presents a good translation with a mean relative estimated force\nerror of 5% and 12% for the recurrent and non-recurrent models respectively.\nOur method, also marginally increase the effectiveness of transformers for\nforce estimation up to a maximum of ~15%, as the volume of available data is\nincrease by 150%. In conclusion, we demonstrate that mixing experimental set\nups for vision-state force estimation in MIRS is a possible approach towards\nthe general solution of the problem.",
      "tldr_zh": "本文提出DaFoEs数据集，该数据集包含可变软环境下的视觉-触觉数据，用于训练深度神经网络模型预测微创机器人手术(MIRS)中的无传感器力趋势，以减少单一数据集的偏置。研究引入了一个混合数据集训练管道和可变编码器-解码器架构，支持单个输入或输入序列预测，包括使用循环解码器(R-前缀)和时间采样表示工具加速度。实验结果表明，混合数据集训练显著降低了过拟合问题，平均相对估计力错误分别为5%（循环模型）和12%（非循环模型），并将Transformer的有效性提高最多15%，证明了这一方法有助于实现MIRS力估计的泛化解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09239v1",
      "published_date": "2024-01-17 14:39:55 UTC",
      "updated_date": "2024-01-17 14:39:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:23:34.602641"
    },
    {
      "arxiv_id": "2401.09235v1",
      "title": "A Characterization Theorem for Equivariant Networks with Point-wise Activations",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Pacini",
        "Xiaowen Dong",
        "Bruno Lepri",
        "Gabriele Santin"
      ],
      "abstract": "Equivariant neural networks have shown improved performance, expressiveness\nand sample complexity on symmetrical domains. But for some specific symmetries,\nrepresentations, and choice of coordinates, the most common point-wise\nactivations, such as ReLU, are not equivariant, hence they cannot be employed\nin the design of equivariant neural networks. The theorem we present in this\npaper describes all possible combinations of finite-dimensional\nrepresentations, choice of coordinates and point-wise activations to obtain an\nexactly equivariant layer, generalizing and strengthening existing\ncharacterizations. Notable cases of practical relevance are discussed as\ncorollaries. Indeed, we prove that rotation-equivariant networks can only be\ninvariant, as it happens for any network which is equivariant with respect to\nconnected compact groups. Then, we discuss implications of our findings when\napplied to important instances of exactly equivariant networks. First, we\ncompletely characterize permutation equivariant networks such as Invariant\nGraph Networks with point-wise nonlinearities and their geometric counterparts,\nhighlighting a plethora of models whose expressive power and performance are\nstill unknown. Second, we show that feature spaces of disentangled steerable\nconvolutional neural networks are trivial representations.",
      "tldr_zh": "这篇论文提出一个定理，用于表征在有限维表示、坐标选择和点-wise activations（如ReLU）组合下构建精确等变神经网络层的条件，从而推广和加强了现有表征。论文证明了旋转等变networks只能是invariant的，这适用于任何对connected compact groups等变的网络。作者进一步讨论了该定理对置换等变networks（如Invariant Graph Networks）和Steerable Convolutional Neural Networks的含义，包括完全表征这些模型的表达能力和特征空间的平凡性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the 12th International Conference on Learning\n  Representations (ICLR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.09235v1",
      "published_date": "2024-01-17 14:30:46 UTC",
      "updated_date": "2024-01-17 14:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:23:45.015735"
    },
    {
      "arxiv_id": "2401.09192v3",
      "title": "Preparing Lessons for Progressive Training on Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Pan",
        "Ye Yuan",
        "Yichun Yin",
        "Jiaxin Shi",
        "Zenglin Xu",
        "Ming Zhang",
        "Lifeng Shang",
        "Xin Jiang",
        "Qun Liu"
      ],
      "abstract": "The rapid progress of Transformers in artificial intelligence has come at the\ncost of increased resource consumption and greenhouse gas emissions due to\ngrowing model sizes. Prior work suggests using pretrained small models to\nimprove training efficiency, but this approach may not be suitable for new\nmodel structures. On the other hand, training from scratch can be slow, and\nprogressively stacking layers often fails to achieve significant acceleration.\nTo address these challenges, we propose a novel method called Apollo, which\nprep\\textbf{a}res lessons for ex\\textbf{p}anding \\textbf{o}perations by\n\\textbf{l}earning high-\\textbf{l}ayer functi\\textbf{o}nality during training of\nlow layers. Our approach involves low-value-prioritized sampling (LVPS) to\ntrain different depths and weight sharing to facilitate efficient expansion. We\nalso introduce an interpolation method for stable model depth extension.\nExperiments demonstrate that Apollo achieves state-of-the-art acceleration\nratios, even rivaling methods using pretrained models, making it a universal\nand efficient solution for training deep models while reducing time, financial,\nand environmental costs.",
      "tldr_zh": "该研究针对Transformer语言模型的训练效率问题，提出了一种名为Apollo的新方法，以减少资源消耗和环境影响。Apollo通过在训练低层时学习高层功能，包括low-value-prioritized sampling (LVPS)来优化不同深度的训练、weight sharing促进高效模型扩展，以及interpolation方法确保稳定深度扩展。实验结果显示，Apollo实现了最先进的加速比，甚至可与使用预训练模型的方法媲美，从而显著降低时间、金融和环境成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09192v3",
      "published_date": "2024-01-17 13:04:14 UTC",
      "updated_date": "2024-02-10 14:52:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:23:54.736079"
    },
    {
      "arxiv_id": "2401.10938v2",
      "title": "Even-if Explanations: Formal Foundations, Priorities and Complexity",
      "title_zh": "翻译失败",
      "authors": [
        "Gianvincenzo Alfano",
        "Sergio Greco",
        "Domenico Mandaglio",
        "Francesco Parisi",
        "Reza Shahbazian",
        "Irina Trubitsyna"
      ],
      "abstract": "EXplainable AI has received significant attention in recent years. Machine\nlearning models often operate as black boxes, lacking explainability and\ntransparency while supporting decision-making processes. Local post-hoc\nexplainability queries attempt to answer why individual inputs are classified\nin a certain way by a given model. While there has been important work on\ncounterfactual explanations, less attention has been devoted to semifactual\nones. In this paper, we focus on local post-hoc explainability queries within\nthe semifactual `even-if' thinking and their computational complexity among\ndifferent classes of models, and show that both linear and tree-based models\nare strictly more interpretable than neural networks. After this, we introduce\na preference-based framework that enables users to personalize explanations\nbased on their preferences, both in the case of semifactuals and\ncounterfactuals, enhancing interpretability and user-centricity. Finally, we\nexplore the complexity of several interpretability problems in the proposed\npreference-based framework and provide algorithms for polynomial cases.",
      "tldr_zh": "这篇论文探讨了 Explainable AI 中的 semifactual 'even-if' 解释，聚焦于其形式基础、计算复杂性和模型比较，强调这些解释可以回答特定输入为何被分类的方式。研究发现，线性模型和树-based 模型在 semifactual 查询的复杂性上比 neural networks 更易解释，并证明了前者严格更高的可解释性。论文进一步引入了一个偏好-based 框架，允许用户根据个人偏好个性化 semifactual 和 counterfactual 解释，并分析了相关解释性问题的复杂性，为多项式情况提供了算法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2010.12265 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2401.10938v2",
      "published_date": "2024-01-17 11:38:58 UTC",
      "updated_date": "2024-05-22 11:17:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:24:08.750812"
    },
    {
      "arxiv_id": "2401.10937v1",
      "title": "Subjective Causality",
      "title_zh": "翻译失败",
      "authors": [
        "Joseph Y. Halpern",
        "Evan Piermont"
      ],
      "abstract": "We show that it is possible to understand and identify a decision maker's\nsubjective causal judgements by observing her preferences over interventions.\nFollowing Pearl [2000], we represent causality using causal models (also called\nstructural equations models), where the world is described by a collection of\nvariables, related by equations. We show that if a preference relation over\ninterventions satisfies certain axioms (related to standard axioms regarding\ncounterfactuals), then we can define (i) a causal model, (ii) a probability\ncapturing the decision-maker's uncertainty regarding the external factors in\nthe world and (iii) a utility on outcomes such that each intervention is\nassociated with an expected utility and such that intervention $A$ is preferred\nto $B$ iff the expected utility of $A$ is greater than that of $B$. In\naddition, we characterize when the causal model is unique. Thus, our results\nallow a modeler to test the hypothesis that a decision maker's preferences are\nconsistent with some causal model and to identify causal judgements from\nobserved behavior.",
      "tldr_zh": "本研究探讨了通过观察决策者的干预偏好来理解和识别其主观因果判断（Subjective Causality）。作者基于 Pearl [2000] 的因果模型（causal models，又称 structural equations models），证明如果偏好关系满足特定公理（axioms，与 counterfactuals 相关），则能定义一个因果模型、一个捕捉决策者不确定性的概率，以及一个结果效用函数，从而使干预 A 优于 B 当且仅当 A 的期望效用（expected utility）更高。论文进一步表征了因果模型的唯一性，并展示了此框架可用于测试决策者偏好是否与某些因果模型一致，以及从观察行为中识别因果判断。",
      "categories": [
        "econ.TH",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "econ.TH",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10937v1",
      "published_date": "2024-01-17 11:36:38 UTC",
      "updated_date": "2024-01-17 11:36:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:24:20.065877"
    },
    {
      "arxiv_id": "2401.09082v2",
      "title": "Should agentic conversational AI change how we think about ethics? Characterising an interactional ethics centred on respect",
      "title_zh": "翻译失败",
      "authors": [
        "Lize Alberts",
        "Geoff Keeling",
        "Amanda McCroskery"
      ],
      "abstract": "With the growing popularity of conversational agents based on large language\nmodels (LLMs), we need to ensure their behaviour is ethical and appropriate.\nWork in this area largely centres around the 'HHH' criteria: making outputs\nmore helpful and honest, and avoiding harmful (biased, toxic, or inaccurate)\nstatements. Whilst this semantic focus is useful when viewing LLM agents as\nmere mediums or output-generating systems, it fails to account for pragmatic\nfactors that can make the same speech act seem more or less tactless or\ninconsiderate in different social situations. With the push towards agentic AI,\nwherein systems become increasingly proactive in chasing goals and performing\nactions in the world, considering the pragmatics of interaction becomes\nessential. We propose an interactional approach to ethics that is centred on\nrelational and situational factors. We explore what it means for a system, as a\nsocial actor, to treat an individual respectfully in a (series of)\ninteraction(s). Our work anticipates a set of largely unexplored risks at the\nlevel of situated social interaction, and offers practical suggestions to help\nagentic LLM technologies treat people well.",
      "tldr_zh": "该论文探讨了 agentic conversational AI 是否应改变我们对伦理的思考，提出一种以尊重为中心的 interactional ethics 方法，以应对 large language models (LLMs) 驱动的对话代理在社交互动中的潜在风险。现有 HHH criteria（helpful, honest, harmless）主要关注语义输出，却忽略了语用因素（pragmatics），如不同情境下相同行为的礼貌性差异。作者强调 AI 作为社会行为者需考虑关系和情境因素，并在互动中表现出尊重，并提供实用建议来缓解 agentic AI 在实际应用中的伦理挑战。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "68T42",
        "H.5.2; I.2; I.2.1; J.4; J.5"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09082v2",
      "published_date": "2024-01-17 09:44:03 UTC",
      "updated_date": "2024-05-16 09:53:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:24:32.153224"
    },
    {
      "arxiv_id": "2401.09075v1",
      "title": "GPT in Sheep's Clothing: The Risk of Customized GPTs",
      "title_zh": "披着羊皮的 GPT：自定义 GPT 的风险",
      "authors": [
        "Sagiv Antebi",
        "Noam Azulay",
        "Edan Habler",
        "Ben Ganon",
        "Asaf Shabtai",
        "Yuval Elovici"
      ],
      "abstract": "In November 2023, OpenAI introduced a new service allowing users to create\ncustom versions of ChatGPT (GPTs) by using specific instructions and knowledge\nto guide the model's behavior. We aim to raise awareness of the fact that GPTs\ncan be used maliciously, posing privacy and security risks to their users.",
      "tldr_zh": "本论文探讨了OpenAI于2023年11月推出的自定义GPTs服务，用户可通过特定指令和知识定制ChatGPT的行为，从而引导模型的响应。研究强调，GPTs可能被恶意利用，带来隐私和安全风险，例如数据泄露或有害内容生成。论文旨在提高对这些潜在威胁的认识，以促进更安全的AI应用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09075v1",
      "published_date": "2024-01-17 09:27:13 UTC",
      "updated_date": "2024-01-17 09:27:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:24:42.367017"
    },
    {
      "arxiv_id": "2401.09074v4",
      "title": "Code Simulation Challenges for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Emanuele La Malfa",
        "Christoph Weinhuber",
        "Orazio Torre",
        "Fangru Lin",
        "Samuele Marro",
        "Anthony Cohn",
        "Nigel Shadbolt",
        "Michael Wooldridge"
      ],
      "abstract": "Many reasoning, planning, and problem-solving tasks share an intrinsic\nalgorithmic nature: correctly simulating each step is a sufficient condition to\nsolve them correctly. This work studies to what extent Large Language Models\n(LLMs) can simulate coding and algorithmic tasks to provide insights into\ngeneral capabilities in such algorithmic reasoning tasks. We introduce\nbenchmarks for straight-line programs, code that contains critical paths, and\napproximate and redundant instructions. We further assess the simulation\ncapabilities of LLMs with sorting algorithms and nested loops and show that a\nroutine's computational complexity directly affects an LLM's ability to\nsimulate its execution. While the most powerful LLMs exhibit relatively strong\nsimulation capabilities, the process is fragile, seems to rely heavily on\npattern recognition, and is affected by memorisation. We propose a novel\noff-the-shelf prompting method, Chain of Simulation (CoSm), which instructs\nLLMs to simulate code execution line by line/follow the computation pattern of\ncompilers. CoSm efficiently helps LLMs reduce memorisation and shallow pattern\nrecognition while improving simulation performance. We consider the success of\nCoSm in code simulation to be inspirational for other general routine\nsimulation reasoning tasks.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在模拟代码和算法任务时的挑战，这些任务本质上依赖于精确的步骤模拟，以揭示 LLMs 在算法推理方面的整体能力。研究引入了针对直线程序、关键路径代码、近似指令和冗余指令的基准测试，并评估了 LLMs 在排序算法和嵌套循环等复杂例程中的模拟表现，发现计算复杂度直接影响模拟准确性，同时 LLMs 易受模式识别和记忆偏差的影响。作者提出了一种新颖的提示方法 Chain of Simulation (CoSm)，指导 LLMs 逐行模拟代码执行或模仿编译器模式，从而减少记忆依赖并提升模拟性能。该方法不仅改善了实验结果，还为其他常规模拟推理任务提供了潜在启发。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.PL"
      ],
      "primary_category": "cs.LG",
      "comment": "Code: https://github.com/EmanueleLM/CodeSimulation",
      "pdf_url": "http://arxiv.org/pdf/2401.09074v4",
      "published_date": "2024-01-17 09:23:59 UTC",
      "updated_date": "2024-06-12 08:55:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:24:58.902200"
    },
    {
      "arxiv_id": "2401.09073v1",
      "title": "Fixed-Budget Differentially Private Best Arm Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Zhirui Chen",
        "P. N. Karthik",
        "Yeow Meng Chee",
        "Vincent Y. F. Tan"
      ],
      "abstract": "We study best arm identification (BAI) in linear bandits in the fixed-budget\nregime under differential privacy constraints, when the arm rewards are\nsupported on the unit interval. Given a finite budget $T$ and a privacy\nparameter $\\varepsilon>0$, the goal is to minimise the error probability in\nfinding the arm with the largest mean after $T$ sampling rounds, subject to the\nconstraint that the policy of the decision maker satisfies a certain {\\em\n$\\varepsilon$-differential privacy} ($\\varepsilon$-DP) constraint. We construct\na policy satisfying the $\\varepsilon$-DP constraint (called {\\sc DP-BAI}) by\nproposing the principle of {\\em maximum absolute determinants}, and derive an\nupper bound on its error probability. Furthermore, we derive a minimax lower\nbound on the error probability, and demonstrate that the lower and the upper\nbounds decay exponentially in $T$, with exponents in the two bounds matching\norder-wise in (a) the sub-optimality gaps of the arms, (b) $\\varepsilon$, and\n(c) the problem complexity that is expressible as the sum of two terms, one\ncharacterising the complexity of standard fixed-budget BAI (without privacy\nconstraints), and the other accounting for the $\\varepsilon$-DP constraint.\nAdditionally, we present some auxiliary results that contribute to the\nderivation of the lower bound on the error probability. These results, we\nposit, may be of independent interest and could prove instrumental in proving\nlower bounds on error probabilities in several other bandit problems. Whereas\nprior works provide results for BAI in the fixed-budget regime without privacy\nconstraints or in the fixed-confidence regime with privacy constraints, our\nwork fills the gap in the literature by providing the results for BAI in the\nfixed-budget regime under the $\\varepsilon$-DP constraint.",
      "tldr_zh": "本研究探讨了在固定预算$T$下，线性bandit问题中的最佳手臂识别(BAI)，同时满足ε-differential privacy (ε-DP)约束，目标是最大化识别最大均值手臂的概率。研究提出了一种DP-BAI策略，使用最大绝对行列式原则来构建采样策略，并推导出其错误概率的上界。结果显示，错误概率随$T$指数衰减，其衰减指数与次优差距、ε以及问题复杂度相关，后者包括标准BAI复杂度和ε-DP约束的额外影响；此外，该工作填补了文献空白，提供辅助结果以支持其他bandit问题的下界证明。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.09073v1",
      "published_date": "2024-01-17 09:23:25 UTC",
      "updated_date": "2024-01-17 09:23:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:25:08.450737"
    },
    {
      "arxiv_id": "2401.09071v5",
      "title": "Rethinking Spectral Graph Neural Networks with Spatially Adaptive Filtering",
      "title_zh": "重新审视谱",
      "authors": [
        "Jingwei Guo",
        "Kaizhu Huang",
        "Xinping Yi",
        "Zixian Su",
        "Rui Zhang"
      ],
      "abstract": "Whilst spectral Graph Neural Networks (GNNs) are theoretically well-founded\nin the spectral domain, their practical reliance on polynomial approximation\nimplies a profound linkage to the spatial domain. As previous studies rarely\nexamine spectral GNNs from the spatial perspective, their spatial-domain\ninterpretability remains elusive, e.g., what information is essentially encoded\nby spectral GNNs in the spatial domain? In this paper, to answer this question,\nwe establish a theoretical connection between spectral filtering and spatial\naggregation, unveiling an intrinsic interaction that spectral filtering\nimplicitly leads the original graph to an adapted new graph, explicitly\ncomputed for spatial aggregation. Both theoretical and empirical investigations\nreveal that the adapted new graph not only exhibits non-locality but also\naccommodates signed edge weights to reflect label consistency among nodes.\nThese findings thus highlight the interpretable role of spectral GNNs in the\nspatial domain and inspire us to rethink graph spectral filters beyond the\nfixed-order polynomials, which neglect global information. Built upon the\ntheoretical findings, we revisit the state-of-the-art spectral GNNs and propose\na novel Spatially Adaptive Filtering (SAF) framework, which leverages the\nadapted new graph by spectral filtering for an auxiliary non-local aggregation.\nNotably, our proposed SAF comprehensively models both node similarity and\ndissimilarity from a global perspective, therefore alleviating persistent\ndeficiencies of GNNs related to long-range dependencies and graph heterophily.\nExtensive experiments over 13 node classification benchmarks demonstrate the\nsuperiority of our proposed framework to the state-of-the-art models.",
      "tldr_zh": "本研究重新审视了谱图神经网络 (spectral Graph Neural Networks, GNNs)，通过理论分析建立了谱过滤和空间聚合 (spatial aggregation) 之间的联系，发现谱过滤会隐式适应图结构，形成一个具有非局部性和带符号边权重的适应新图，以反映节点标签一致性。基于这一发现，作者提出了 Spatially Adaptive Filtering (SAF) 框架，利用适应新图进行辅助的非局部聚合，从而从全局视角全面建模节点相似性和差异性，缓解 GNNs 在长程依赖和图异质性 (graph heterophily) 方面的不足。在 13 个节点分类基准上的广泛实验证明，该框架优于现有最先进模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09071v5",
      "published_date": "2024-01-17 09:12:31 UTC",
      "updated_date": "2024-09-16 09:09:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:25:20.888726"
    },
    {
      "arxiv_id": "2401.09070v1",
      "title": "Knowledge Pyramid: A Novel Hierarchical Reasoning Structure for Generalized Knowledge Augmentation and Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Qinghua Huang",
        "Yongzhen Wang"
      ],
      "abstract": "Knowledge graph (KG) based reasoning has been regarded as an effective means\nfor the analysis of semantic networks and is of great usefulness in areas of\ninformation retrieval, recommendation, decision-making, and man-machine\ninteraction. It is widely used in recommendation, decision-making,\nquestion-answering, search, and other fields. However, previous studies mainly\nused low-level knowledge in the KG for reasoning, which may result in\ninsufficient generalization and poor robustness of reasoning. To this end, this\npaper proposes a new inference approach using a novel knowledge augmentation\nstrategy to improve the generalization capability of KG. This framework\nextracts high-level pyramidal knowledge from low-level knowledge and applies it\nto reasoning in a multi-level hierarchical KG, called knowledge pyramid in this\npaper. We tested some medical data sets using the proposed approach, and the\nexperimental results show that the proposed knowledge pyramid has improved the\nknowledge inference performance with better generalization. Especially, when\nthere are fewer training samples, the inference accuracy can be significantly\nimproved.",
      "tldr_zh": "本文提出 Knowledge Pyramid，一种新型的层次化推理结构，旨在通过知识增强策略从低级知识中提取高级金字塔知识，构建多级层次化知识图谱 (KG)，从而提升推理的泛化能力和鲁棒性。该方法解决了传统 KG 推理在泛化不足方面的局限，尤其适用于信息检索、推荐和决策等领域。在医疗数据集上的实验结果表明，Knowledge Pyramid 显著提高了推理准确率，特别是当训练样本较少时，性能提升更为明显。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages,8 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.09070v1",
      "published_date": "2024-01-17 09:08:23 UTC",
      "updated_date": "2024-01-17 09:08:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:25:32.142911"
    },
    {
      "arxiv_id": "2401.09068v1",
      "title": "DTMM: Deploying TinyML Models on Extremely Weak IoT Devices with Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Lixiang Han",
        "Zhen Xiao",
        "Zhenjiang Li"
      ],
      "abstract": "DTMM is a library designed for efficient deployment and execution of machine\nlearning models on weak IoT devices such as microcontroller units (MCUs). The\nmotivation for designing DTMM comes from the emerging field of tiny machine\nlearning (TinyML), which explores extending the reach of machine learning to\nmany low-end IoT devices to achieve ubiquitous intelligence. Due to the weak\ncapability of embedded devices, it is necessary to compress models by pruning\nenough weights before deploying. Although pruning has been studied extensively\non many computing platforms, two key issues with pruning methods are\nexacerbated on MCUs: models need to be deeply compressed without significantly\ncompromising accuracy, and they should perform efficiently after pruning.\nCurrent solutions only achieve one of these objectives, but not both. In this\npaper, we find that pruned models have great potential for efficient deployment\nand execution on MCUs. Therefore, we propose DTMM with pruning unit selection,\npre-execution pruning optimizations, runtime acceleration, and post-execution\nlow-cost storage to fill the gap for efficient deployment and execution of\npruned models. It can be integrated into commercial ML frameworks for practical\ndeployment, and a prototype system has been developed. Extensive experiments on\nvarious models show promising gains compared to state-of-the-art methods.",
      "tldr_zh": "该论文介绍了 DTMM，这是一个专为弱 IoT 设备（如 MCUs）设计的库，用于高效部署和执行 TinyML 模型，以实现机器学习在低端设备的广泛应用。DTMM 通过 pruning 技术，包括 pruning unit selection、pre-execution pruning optimizations、runtime acceleration 和 post-execution low-cost storage，来解决现有方法无法同时实现深度模型压缩和高效执行的问题。实验结果显示，DTMM 在各种模型上比现有方法取得了显著改进，证明了其在 TinyML 部署方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09068v1",
      "published_date": "2024-01-17 09:01:50 UTC",
      "updated_date": "2024-01-17 09:01:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:25:45.481346"
    },
    {
      "arxiv_id": "2401.09067v1",
      "title": "Towards Continual Learning Desiderata via HSIC-Bottleneck Orthogonalization and Equiangular Embedding",
      "title_zh": "翻译失败",
      "authors": [
        "Depeng Li",
        "Tianqi Wang",
        "Junwei Chen",
        "Qining Ren",
        "Kenji Kawaguchi",
        "Zhigang Zeng"
      ],
      "abstract": "Deep neural networks are susceptible to catastrophic forgetting when trained\non sequential tasks. Various continual learning (CL) methods often rely on\nexemplar buffers or/and network expansion for balancing model stability and\nplasticity, which, however, compromises their practical value due to privacy\nand memory concerns. Instead, this paper considers a strict yet realistic\nsetting, where the training data from previous tasks is unavailable and the\nmodel size remains relatively constant during sequential training. To achieve\nsuch desiderata, we propose a conceptually simple yet effective method that\nattributes forgetting to layer-wise parameter overwriting and the resulting\ndecision boundary distortion. This is achieved by the synergy between two key\ncomponents: HSIC-Bottleneck Orthogonalization (HBO) implements non-overwritten\nparameter updates mediated by Hilbert-Schmidt independence criterion in an\northogonal space and EquiAngular Embedding (EAE) enhances decision boundary\nadaptation between old and new tasks with predefined basis vectors. Extensive\nexperiments demonstrate that our method achieves competitive accuracy\nperformance, even with absolute superiority of zero exemplar buffer and 1.02x\nthe base model.",
      "tldr_zh": "这篇论文针对深度神经网络在连续学习（CL）中容易出现灾难性遗忘的问题，提出了一种无需样本缓冲区且模型大小保持不变的简单有效方法。方法的核心在于通过 HSIC-Bottleneck Orthogonalization (HBO) 在正交空间中利用 Hilbert-Schmidt independence criterion 实现非覆盖参数更新，以避免层级参数覆盖和决策边界扭曲。结合 EquiAngular Embedding (EAE)，该方法使用预定义基向量增强旧任务和新任务之间的决策边界适应。实验结果表明，该方法在严格设置下实现竞争性准确性表现，甚至优于基线模型 1.02 倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.09067v1",
      "published_date": "2024-01-17 09:01:29 UTC",
      "updated_date": "2024-01-17 09:01:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:25:58.338031"
    },
    {
      "arxiv_id": "2401.09042v1",
      "title": "LLMs for Relational Reasoning: How Far are We?",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiming Li",
        "Yushi Cao",
        "Xiufeng Xu",
        "Junzhe Jiang",
        "Xu Liu",
        "Yon Shin Teo",
        "Shang-wei Lin",
        "Yang Liu"
      ],
      "abstract": "Large language models (LLMs) have revolutionized many areas (e.g. natural\nlanguage processing, software engineering, etc.) by achieving state-of-the-art\nperformance on extensive downstream tasks. Aiming to achieve robust and general\nartificial intelligence, there has been a surge of interest in investigating\nthe reasoning ability of the LLMs. Whereas the textual and numerical reasoning\nbenchmarks adopted by previous works are rather shallow and simple, it is hard\nto conclude that the LLMs possess strong reasoning ability by merely achieving\npositive results on these benchmarks. Recent efforts have demonstrated that the\nLLMs are poor at solving sequential decision-making problems that require\ncommon-sense planning by evaluating their performance on the reinforcement\nlearning benchmarks. In this work, we conduct an in-depth assessment of several\nstate-of-the-art LLMs' reasoning ability based on the inductive logic\nprogramming (ILP) benchmark, which is broadly recognized as a representative\nand challenging measurement for evaluating logic program induction/synthesis\nsystems as it requires inducing strict cause-effect logic to achieve robust\ndeduction on independent and identically distributed (IID) and\nout-of-distribution (OOD) test samples. Our evaluations illustrate that\ncompared with the neural program induction systems which are much smaller in\nmodel size, the state-of-the-art LLMs are much poorer in terms of reasoning\nability by achieving much lower performance and generalization using either\nnatural language prompting or truth-value matrix prompting.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在关系推理方面的能力，质疑其是否已达到强大水平。论文采用 inductive logic programming (ILP) 基准作为具有挑战性的测试标准，该基准要求模型进行严格的因果逻辑归纳，以评估 LLMs 在独立同分布（IID）和分布外（OOD）样本上的推理表现。研究通过 natural language prompting 和 truth-value matrix prompting 方法测试了几个 state-of-the-art LLMs，结果显示这些模型的性能和泛化能力远低于更小的神经程序归纳系统，暴露了 LLMs 在复杂推理任务中的局限性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by The First International Workshop on Large Language Models\n  for Code (ICSE 2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.09042v1",
      "published_date": "2024-01-17 08:22:52 UTC",
      "updated_date": "2024-01-17 08:22:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:26:09.514725"
    },
    {
      "arxiv_id": "2401.10935v2",
      "title": "SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Kanzhi Cheng",
        "Qiushi Sun",
        "Yougang Chu",
        "Fangzhi Xu",
        "Yantao Li",
        "Jianbing Zhang",
        "Zhiyong Wu"
      ],
      "abstract": "Graphical User Interface (GUI) agents are designed to automate complex tasks\non digital devices, such as smartphones and desktops. Most existing GUI agents\ninteract with the environment through extracted structured data, which can be\nnotably lengthy (e.g., HTML) and occasionally inaccessible (e.g., on desktops).\nTo alleviate this issue, we propose a novel visual GUI agent -- SeeClick, which\nonly relies on screenshots for task automation. In our preliminary study, we\nhave discovered a key challenge in developing visual GUI agents: GUI grounding\n-- the capacity to accurately locate screen elements based on instructions. To\ntackle this challenge, we propose to enhance SeeClick with GUI grounding\npre-training and devise a method to automate the curation of GUI grounding\ndata. Along with the efforts above, we have also created ScreenSpot, the first\nrealistic GUI grounding benchmark that encompasses mobile, desktop, and web\nenvironments. After pre-training, SeeClick demonstrates significant improvement\nin ScreenSpot over various baselines. Moreover, comprehensive evaluations on\nthree widely used benchmarks consistently support our finding that advancements\nin GUI grounding directly correlate with enhanced performance in downstream GUI\nagent tasks. The model, data and code are available at\nhttps://github.com/njucckevin/SeeClick.",
      "tldr_zh": "这篇论文提出了SeeClick，一种新型视觉GUI代理，仅依赖屏幕截图来自动化数字设备（如智能手机和桌面）上的复杂任务，从而避免了传统方法依赖冗长或不可访问的结构化数据（如HTML）的局限。核心创新包括通过GUI grounding预训练（准确基于指令定位屏幕元素）并开发自动数据整理方法来提升代理性能，同时创建了ScreenSpot，这是首个涵盖移动、桌面和网页环境的真实GUI grounding基准。实验结果显示，SeeClick在ScreenSpot和三个下游任务基准上显著优于基线模型，证明了GUI grounding改进直接提升了GUI代理的整体表现。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10935v2",
      "published_date": "2024-01-17 08:10:35 UTC",
      "updated_date": "2024-02-23 04:36:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:26:21.373588"
    },
    {
      "arxiv_id": "2401.09034v2",
      "title": "UOEP: User-Oriented Exploration Policy for Enhancing Long-Term User Experiences in Recommender Systems",
      "title_zh": "UO",
      "authors": [
        "Changshuo Zhang",
        "Sirui Chen",
        "Xiao Zhang",
        "Sunhao Dai",
        "Weijie Yu",
        "Jun Xu"
      ],
      "abstract": "Reinforcement learning (RL) has gained traction for enhancing user long-term\nexperiences in recommender systems by effectively exploring users' interests.\nHowever, modern recommender systems exhibit distinct user behavioral patterns\namong tens of millions of items, which increases the difficulty of exploration.\nFor example, user behaviors with different activity levels require varying\nintensity of exploration, while previous studies often overlook this aspect and\napply a uniform exploration strategy to all users, which ultimately hurts user\nexperiences in the long run. To address these challenges, we propose\nUser-Oriented Exploration Policy (UOEP), a novel approach facilitating\nfine-grained exploration among user groups. We first construct a distributional\ncritic which allows policy optimization under varying quantile levels of\ncumulative reward feedbacks from users, representing user groups with varying\nactivity levels. Guided by this critic, we devise a population of distinct\nactors aimed at effective and fine-grained exploration within its respective\nuser group. To simultaneously enhance diversity and stability during the\nexploration process, we further introduce a population-level diversity\nregularization term and a supervision module. Experimental results on public\nrecommendation datasets demonstrate that our approach outperforms all other\nbaselines in terms of long-term performance, validating its user-oriented\nexploration effectiveness. Meanwhile, further analyses reveal our approach's\nbenefits of improved performance for low-activity users as well as increased\nfairness among users.",
      "tldr_zh": "这篇论文针对推荐系统中的强化学习 (RL) 探索挑战，提出 User-Oriented Exploration Policy (UOEP)，以解决现有方法忽略用户活跃度差异导致的长期体验下降问题。UOEP 通过构建一个分布批评家 (distributional critic) 来优化不同分位数水平的累积奖励，代表不同活跃度用户群体，并设计多个演员 (actors) 进行针对性的细粒度探索。同时，引入人口水平多样性正则化和监督模块，以增强探索过程的多样性和稳定性。实验结果显示，UOEP 在公共数据集上优于基线模型，提高了长期性能，特别是对低活跃用户，并提升了用户公平性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09034v2",
      "published_date": "2024-01-17 08:01:18 UTC",
      "updated_date": "2024-05-22 01:01:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:26:33.676569"
    },
    {
      "arxiv_id": "2401.09029v1",
      "title": "Cross-modality Guidance-aided Multi-modal Learning with Dual Attention for MRI Brain Tumor Grading",
      "title_zh": "翻译失败",
      "authors": [
        "Dunyuan Xu",
        "Xi Wang",
        "Jinyue Cai",
        "Pheng-Ann Heng"
      ],
      "abstract": "Brain tumor represents one of the most fatal cancers around the world, and is\nvery common in children and the elderly. Accurate identification of the type\nand grade of tumor in the early stages plays an important role in choosing a\nprecise treatment plan. The Magnetic Resonance Imaging (MRI) protocols of\ndifferent sequences provide clinicians with important contradictory information\nto identify tumor regions. However, manual assessment is time-consuming and\nerror-prone due to big amount of data and the diversity of brain tumor types.\nHence, there is an unmet need for MRI automated brain tumor diagnosis. We\nobserve that the predictive capability of uni-modality models is limited and\ntheir performance varies widely across modalities, and the commonly used\nmodality fusion methods would introduce potential noise, which results in\nsignificant performance degradation. To overcome these challenges, we propose a\nnovel cross-modality guidance-aided multi-modal learning with dual attention\nfor addressing the task of MRI brain tumor grading. To balance the tradeoff\nbetween model efficiency and efficacy, we employ ResNet Mix Convolution as the\nbackbone network for feature extraction. Besides, dual attention is applied to\ncapture the semantic interdependencies in spatial and slice dimensions\nrespectively. To facilitate information interaction among modalities, we design\na cross-modality guidance-aided module where the primary modality guides the\nother secondary modalities during the process of training, which can\neffectively leverage the complementary information of different MRI modalities\nand meanwhile alleviate the impact of the possible noise.",
      "tldr_zh": "本研究针对MRI脑肿瘤分级的挑战，提出了一种cross-modality guidance-aided多模态学习框架，以克服单模态模型性能有限和模态融合引入噪声的问题。该框架采用ResNet Mix Convolution作为骨干网络进行特征提取，并应用dual attention机制来捕捉空间和切片维度的语义互依赖。同时，通过cross-modality guidance-aided模块，让主要模态指导次要模态，促进信息交互并减轻噪声影响，从而提升脑肿瘤诊断的准确性和效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09029v1",
      "published_date": "2024-01-17 07:54:49 UTC",
      "updated_date": "2024-01-17 07:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:26:44.851494"
    },
    {
      "arxiv_id": "2401.09019v1",
      "title": "Change Detection Between Optical Remote Sensing Imagery and Map Data via Segment Anything Model (SAM)",
      "title_zh": "翻译失败",
      "authors": [
        "Hongruixuan Chen",
        "Jian Song",
        "Naoto Yokoya"
      ],
      "abstract": "Unsupervised multimodal change detection is pivotal for time-sensitive tasks\nand comprehensive multi-temporal Earth monitoring. In this study, we explore\nunsupervised multimodal change detection between two key remote sensing data\nsources: optical high-resolution imagery and OpenStreetMap (OSM) data.\nSpecifically, we propose to utilize the vision foundation model Segmentation\nAnything Model (SAM), for addressing our task. Leveraging SAM's exceptional\nzero-shot transfer capability, high-quality segmentation maps of optical images\ncan be obtained. Thus, we can directly compare these two heterogeneous data\nforms in the so-called segmentation domain. We then introduce two strategies\nfor guiding SAM's segmentation process: the 'no-prompt' and 'box/mask prompt'\nmethods. The two strategies are designed to detect land-cover changes in\ngeneral scenarios and to identify new land-cover objects within existing\nbackgrounds, respectively. Experimental results on three datasets indicate that\nthe proposed approach can achieve more competitive results compared to\nrepresentative unsupervised multimodal change detection methods.",
      "tldr_zh": "本研究探讨了无监督多模态变化检测，专注于光学遥感图像和 OpenStreetMap (OSM) 数据之间的差异，提出了一种基于 Segment Anything Model (SAM) 的方法。利用 SAM 的零样本转移能力，该方法生成高质量的光学图像分割图，并在分割域中直接比较两种异构数据。研究引入了两种策略：'no-prompt' 用于一般土地覆盖变化检测，以及 'box/mask prompt' 用于识别现有背景中的新土地覆盖对象。在三个数据集上的实验结果显示，该方法比代表性的无监督多模态变化检测方法取得了更具竞争力的性能。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09019v1",
      "published_date": "2024-01-17 07:30:52 UTC",
      "updated_date": "2024-01-17 07:30:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:26:59.064666"
    },
    {
      "arxiv_id": "2401.09011v1",
      "title": "Inductive Models for Artificial Intelligence Systems are Insufficient without Good Explanations",
      "title_zh": "归纳模型对于人工智能系统而言，在缺乏良好解释",
      "authors": [
        "Udesh Habaraduwa"
      ],
      "abstract": "This paper discusses the limitations of machine learning (ML), particularly\ndeep artificial neural networks (ANNs), which are effective at approximating\ncomplex functions but often lack transparency and explanatory power. It\nhighlights the `problem of induction' : the philosophical issue that past\nobservations may not necessarily predict future events, a challenge that ML\nmodels face when encountering new, unseen data. The paper argues for the\nimportance of not just making predictions but also providing good explanations,\na feature that current models often fail to deliver. It suggests that for AI to\nprogress, we must seek models that offer insights and explanations, not just\npredictions.",
      "tldr_zh": "这篇论文讨论了机器学习(ML)，尤其是深度人工神经网络(ANNs)的局限性：这些模型虽擅长近似复杂函数，但往往缺乏透明度和解释能力。论文强调了“problem of induction”问题，即过去观察未必能预测未来事件，这使得 ML 模型在面对新数据时可能失效。作者主张，AI 系统不仅仅需要做出预测，还必须提供良好的解释，以推动其发展；因此，未来应优先开发能提供洞见和解释的模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09011v1",
      "published_date": "2024-01-17 07:14:04 UTC",
      "updated_date": "2024-01-17 07:14:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:27:10.333104"
    },
    {
      "arxiv_id": "2401.09008v1",
      "title": "Hybrid of DiffStride and Spectral Pooling in Convolutional Neural Networks",
      "title_zh": "卷积神经网络中 DiffStride",
      "authors": [
        "Sulthan Rafif",
        "Mochamad Arfan Ravy Wahyu Pratama",
        "Mohammad Faris Azhar",
        "Ahmad Mustafidul Ibad",
        "Lailil Muflikhah",
        "Novanto Yudistira"
      ],
      "abstract": "Stride determines the distance between adjacent filter positions as the\nfilter moves across the input. A fixed stride causes important information\ncontained in the image can not be captured, so that important information is\nnot classified. Therefore, in previous research, the DiffStride Method was\napplied, namely the Strided Convolution Method with which it can learn its own\nstride value. Severe Quantization and a constraining lower bound on preserved\ninformation are arises with Max Pooling Downsampling Method. Spectral Pooling\nreduce the constraint lower bound on preserved information by cutting off the\nrepresentation in the frequency domain. In this research a CNN Model is\nproposed with the Downsampling Learnable Stride Technique performed by\nBackpropagation combined with the Spectral Pooling Technique. Diffstride and\nSpectral Pooling techniques are expected to maintain most of the information\ncontained in the image. In this study, we compare the Hybrid Method, which is a\ncombined implementation of Spectral Pooling and DiffStride against the Baseline\nMethod, which is the DiffStride implementation on ResNet 18. The accuracy\nresult of the DiffStride combination with Spectral Pooling improves over\nDiffStride which is baseline method by 0.0094. This shows that the Hybrid\nMethod can maintain most of the information by cutting of the representation in\nthe frequency domain and determine the stride of the learning result through\nBackpropagation.",
      "tldr_zh": "这篇论文针对卷积神经网络（Convolutional Neural Networks）中固定 Stride 导致的信息丢失问题，提出了一种混合方法，将 DiffStride（可通过反向传播学习 Stride 值）和 Spectral Pooling（在频域裁剪表示以减少信息损失）相结合。相比传统的 Max Pooling，Spectral Pooling 能更好地保留图像信息，而 DiffStride 则优化了下采样过程。实验结果显示，在 ResNet 18 模型上，该混合方法比仅使用 DiffStride 的基线方法准确率提高了 0.0094，证明了其在维护图像信息方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09008v1",
      "published_date": "2024-01-17 07:06:56 UTC",
      "updated_date": "2024-01-17 07:06:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:27:23.300987"
    },
    {
      "arxiv_id": "2401.09003v5",
      "title": "Augmenting Math Word Problems via Iterative Question Composing",
      "title_zh": "翻译失败",
      "authors": [
        "Haoxiong Liu",
        "Yifan Zhang",
        "Yifan Luo",
        "Andrew Chi-Chih Yao"
      ],
      "abstract": "Despite the advancements in large language models (LLMs) for mathematical\nreasoning, solving competition-level math problems remains a significant\nchallenge, especially for open-source LLMs without external tools. We introduce\nthe MMIQC dataset, comprising a mixture of processed web data and synthetic\nquestion-response pairs, aimed at enhancing the mathematical reasoning\ncapabilities of base language models. Models fine-tuned on MMIQC consistently\nsurpass their counterparts in performance on the MATH benchmark across various\nmodel sizes. Notably, Qwen-72B-MMIQC achieves a 45.0% accuracy, exceeding the\nprevious open-source state-of-the-art by 8.2% and outperforming the initial\nversion GPT-4 released in 2023. Extensive evaluation results on Hungarian high\nschool finals suggest that such improvement can generalize to unseen data. Our\nablation study on MMIQC reveals that a large part of the improvement can be\nattributed to our novel augmentation method, Iterative Question Composing\n(IQC), which involves iteratively composing new questions from seed problems\nusing an LLM and applying rejection sampling through another LLM.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在解决竞赛级数学问题上的挑战，引入了MMIQC数据集，该数据集结合处理过的网络数据和合成问题-响应对，以提升基础语言模型的数学推理能力。核心方法是Iterative Question Composing (IQC)，通过LLM迭代生成新问题并应用拒绝采样来增强数据。实验结果显示，在MATH benchmark上，基于MMIQC细调的Qwen-72B-MMIQC模型达到45.0%准确率，比之前的开源最先进模型高8.2%并超过2023年GPT-4初始版本；此外，该改进在匈牙利高中决赛的未见数据上也表现出良好的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09003v5",
      "published_date": "2024-01-17 06:48:16 UTC",
      "updated_date": "2024-12-16 06:13:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:27:37.821266"
    },
    {
      "arxiv_id": "2401.08999v1",
      "title": "Continuous Time Continuous Space Homeostatic Reinforcement Learning (CTCS-HRRL) : Towards Biological Self-Autonomous Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Hugo Laurencon",
        "Yesoda Bhargava",
        "Riddhi Zantye",
        "Charbel-Raphaël Ségerie",
        "Johann Lussange",
        "Veeky Baths",
        "Boris Gutkin"
      ],
      "abstract": "Homeostasis is a biological process by which living beings maintain their\ninternal balance. Previous research suggests that homeostasis is a learned\nbehaviour. Recently introduced Homeostatic Regulated Reinforcement Learning\n(HRRL) framework attempts to explain this learned homeostatic behavior by\nlinking Drive Reduction Theory and Reinforcement Learning. This linkage has\nbeen proven in the discrete time-space, but not in the continuous time-space.\nIn this work, we advance the HRRL framework to a continuous time-space\nenvironment and validate the CTCS-HRRL (Continuous Time Continuous Space HRRL)\nframework. We achieve this by designing a model that mimics the homeostatic\nmechanisms in a real-world biological agent. This model uses the\nHamilton-Jacobian Bellman Equation, and function approximation based on neural\nnetworks and Reinforcement Learning. Through a simulation-based experiment we\ndemonstrate the efficacy of this model and uncover the evidence linked to the\nagent's ability to dynamically choose policies that favor homeostasis in a\ncontinuously changing internal-state milieu. Results of our experiments\ndemonstrate that agent learns homeostatic behaviour in a CTCS environment,\nmaking CTCS-HRRL a promising framework for modellng animal dynamics and\ndecision-making.",
      "tldr_zh": "本文提出 CTCS-HRRL（Continuous Time Continuous Space Homeostatic Reinforcement Learning）框架，将 Homeostatic Regulated Reinforcement Learning (HRRL) 扩展到连续时间-空间环境，以模拟生物代理的自我自治行为。框架基于 Hamilton-Jacobian Bellman Equation 和神经网络的函数逼近，结合 Reinforcement Learning 来模仿生物 Homeostasis 机制。实验结果显示，代理能够在动态环境中动态选择策略以维持内部平衡，这为建模动物动态和决策提供了一个有前景的框架。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "This work is a result of the ongoing collaboration between Cognitive\n  Neuroscience Lab, BITS Pilani K K Birla Goa Campus and Ecole Normale\n  Superieure, Paris France. This work is jointly supervised by Prof. Boris\n  Gutkin and Prof. Veeky Baths. arXiv admin note: substantial text overlap with\n  arXiv:2109.06580",
      "pdf_url": "http://arxiv.org/pdf/2401.08999v1",
      "published_date": "2024-01-17 06:29:34 UTC",
      "updated_date": "2024-01-17 06:29:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:27:47.034026"
    },
    {
      "arxiv_id": "2401.08996v1",
      "title": "MicroNAS: Zero-Shot Neural Architecture Search for MCUs",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Qiao",
        "Haocheng Xu",
        "Yifan Zhang",
        "Sitao Huang"
      ],
      "abstract": "Neural Architecture Search (NAS) effectively discovers new Convolutional\nNeural Network (CNN) architectures, particularly for accuracy optimization.\nHowever, prior approaches often require resource-intensive training on super\nnetworks or extensive architecture evaluations, limiting practical\napplications. To address these challenges, we propose MicroNAS, a\nhardware-aware zero-shot NAS framework designed for microcontroller units\n(MCUs) in edge computing. MicroNAS considers target hardware optimality during\nthe search, utilizing specialized performance indicators to identify optimal\nneural architectures without high computational costs. Compared to previous\nworks, MicroNAS achieves up to 1104x improvement in search efficiency and\ndiscovers models with over 3.23x faster MCU inference while maintaining similar\naccuracy",
      "tldr_zh": "本研究提出MicroNAS，一种零-shot Neural Architecture Search (NAS) 框架，针对微控制器单位 (MCUs) 在边缘计算中的应用，旨在解决传统NAS方法在资源密集型训练和架构评估方面的局限性。MicroNAS 通过硬件感知优化和专业性能指标来搜索最佳神经架构，从而在不需高计算成本的情况下实现高效设计。与现有方法相比，它将搜索效率提升多达1104倍，同时发现的模型在MCUs上推理速度提高3.23倍，同时保持相似的准确性。该框架为资源受限环境下的CNN架构优化提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08996v1",
      "published_date": "2024-01-17 06:17:42 UTC",
      "updated_date": "2024-01-17 06:17:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:27:57.304422"
    },
    {
      "arxiv_id": "2401.09498v2",
      "title": "Technical Report: On the Convergence of Gossip Learning in the Presence of Node Inaccessibility",
      "title_zh": "翻译失败",
      "authors": [
        "Tian Liu",
        "Yue Cui",
        "Xueyang Hu",
        "Yecheng Xu",
        "Bo Liu"
      ],
      "abstract": "Gossip learning (GL), as a decentralized alternative to federated learning\n(FL), is more suitable for resource-constrained wireless networks, such as\nFlying Ad-Hoc Networks (FANETs) that are formed by unmanned aerial vehicles\n(UAVs). GL can significantly enhance the efficiency and extend the battery life\nof UAV networks. Despite the advantages, the performance of GL is strongly\naffected by data distribution, communication speed, and network connectivity.\nHowever, how these factors influence the GL convergence is still unclear.\nExisting work studied the convergence of GL based on a virtual quantity for the\nsake of convenience, which failed to reflect the real state of the network when\nsome nodes are inaccessible. In this paper, we formulate and investigate the\nimpact of inaccessible nodes to GL under a dynamic network topology. We first\ndecompose the weight divergence by whether the node is accessible or not. Then,\nwe investigate the GL convergence under the dynamic of node accessibility and\ntheoretically provide how the number of inaccessible nodes, data\nnon-i.i.d.-ness, and duration of inaccessibility affect the convergence.\nExtensive experiments are carried out in practical settings to comprehensively\nverify the correctness of our theoretical findings.",
      "tldr_zh": "本研究探讨了 Gossip Learning (GL) 在节点不可访问情况下的收敛问题，作为 Federated Learning (FL) 的去中心化替代方案，GL 更适用于资源受限的无线网络如无人机网络 (FANETs)。论文通过分解权重偏差（基于节点是否可访问）来分析动态网络拓扑下 GL 的收敛行为，并理论证明了不可访问节点数量、数据 non-i.i.d.-ness 和不可访问持续时间对收敛的影响。实验结果在实际场景中验证了这些理论发现，强调了 GL 在网络不稳定环境中的性能优化潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09498v2",
      "published_date": "2024-01-17 06:11:19 UTC",
      "updated_date": "2024-02-18 06:34:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:28:11.413872"
    },
    {
      "arxiv_id": "2401.08984v1",
      "title": "A GAN-based data poisoning framework against anomaly detection in vertical federated learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaolin Chen",
        "Daoguang Zan",
        "Wei Li",
        "Bei Guan",
        "Yongji Wang"
      ],
      "abstract": "In vertical federated learning (VFL), commercial entities collaboratively\ntrain a model while preserving data privacy. However, a malicious participant's\npoisoning attack may degrade the performance of this collaborative model. The\nmain challenge in achieving the poisoning attack is the absence of access to\nthe server-side top model, leaving the malicious participant without a clear\ntarget model. To address this challenge, we introduce an innovative end-to-end\npoisoning framework P-GAN. Specifically, the malicious participant initially\nemploys semi-supervised learning to train a surrogate target model.\nSubsequently, this participant employs a GAN-based method to produce\nadversarial perturbations to degrade the surrogate target model's performance.\nFinally, the generator is obtained and tailored for VFL poisoning. Besides, we\ndevelop an anomaly detection algorithm based on a deep auto-encoder (DAE),\noffering a robust defense mechanism to VFL scenarios. Through extensive\nexperiments, we evaluate the efficacy of P-GAN and DAE, and further analyze the\nfactors that influence their performance.",
      "tldr_zh": "该论文提出了一种基于 GAN 的数据投毒框架 P-GAN，针对垂直联邦学习 (VFL) 中的异常检测进行攻击，以降低协作模型的性能。框架的关键方法包括使用半监督学习训练代理目标模型，然后通过 GAN-based 技术生成对抗性扰动，最终调整生成器以适应 VFL 场景。论文还开发了基于深度自编码器 (DAE) 的异常检测算法作为防御机制，并通过广泛实验评估了 P-GAN 的攻击有效性和 DAE 的防御性能，同时分析了影响因素。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 7 figures. This work has been submitted to the IEEE for\n  possible publication",
      "pdf_url": "http://arxiv.org/pdf/2401.08984v1",
      "published_date": "2024-01-17 05:31:08 UTC",
      "updated_date": "2024-01-17 05:31:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:28:22.733240"
    },
    {
      "arxiv_id": "2401.08977v2",
      "title": "FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data",
      "title_zh": "FedLoGe：长尾数据下的",
      "authors": [
        "Zikai Xiao",
        "Zihan Chen",
        "Liyinglan Liu",
        "Yang Feng",
        "Jian Wu",
        "Wanlu Liu",
        "Joey Tianyi Zhou",
        "Howard Hao Yang",
        "Zuozhu Liu"
      ],
      "abstract": "Federated Long-Tailed Learning (Fed-LT), a paradigm wherein data collected\nfrom decentralized local clients manifests a globally prevalent long-tailed\ndistribution, has garnered considerable attention in recent times. In the\ncontext of Fed-LT, existing works have predominantly centered on addressing the\ndata imbalance issue to enhance the efficacy of the generic global model while\nneglecting the performance at the local level. In contrast, conventional\nPersonalized Federated Learning (pFL) techniques are primarily devised to\noptimize personalized local models under the presumption of a balanced global\ndata distribution. This paper introduces an approach termed Federated Local and\nGeneric Model Training in Fed-LT (FedLoGe), which enhances both local and\ngeneric model performance through the integration of representation learning\nand classifier alignment within a neural collapse framework. Our investigation\nreveals the feasibility of employing a shared backbone as a foundational\nframework for capturing overarching global trends, while concurrently employing\nindividualized classifiers to encapsulate distinct refinements stemming from\neach client's local features. Building upon this discovery, we establish the\nStatic Sparse Equiangular Tight Frame Classifier (SSE-C), inspired by neural\ncollapse principles that naturally prune extraneous noisy features and foster\nthe acquisition of potent data representations. Furthermore, leveraging\ninsights from imbalance neural collapse's classifier norm patterns, we develop\nGlobal and Local Adaptive Feature Realignment (GLA-FR) via an auxiliary global\nclassifier and personalized Euclidean norm transfer to align global features\nwith client preferences. Extensive experimental results on CIFAR-10/100-LT,\nImageNet, and iNaturalist demonstrate the advantage of our method over\nstate-of-the-art pFL and Fed-LT approaches.",
      "tldr_zh": "这篇论文提出 FedLoGe 方法，用于处理长尾数据分布下的联邦学习（Fed-LT），旨在同时提升本地模型和全局模型的性能，解决现有方法忽略本地优化的问题。FedLoGe 通过表示学习和分类器对齐在 neural collapse 框架下整合共享主干网络捕获全局趋势，以及个性化分类器如 Static Sparse Equiangular Tight Frame Classifier (SSE-C) 来去除噪声特征，并引入 Global and Local Adaptive Feature Realignment (GLA-FR) 进行特征对齐。实验在 CIFAR-10/100-LT、ImageNet 和 iNaturalist 数据集上证明，该方法优于现有 Personalized Federated Learning (pFL) 和 Fed-LT 技术。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICLR 2024, code: https://github.com/ZackZikaiXiao/FedLoGe",
      "pdf_url": "http://arxiv.org/pdf/2401.08977v2",
      "published_date": "2024-01-17 05:04:33 UTC",
      "updated_date": "2024-03-08 13:37:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:28:35.346918"
    },
    {
      "arxiv_id": "2401.08973v1",
      "title": "OCTO+: A Suite for Automatic Open-Vocabulary Object Placement in Mixed Reality",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Sharma",
        "Luke Yoffe",
        "Tobias Höllerer"
      ],
      "abstract": "One key challenge in Augmented Reality is the placement of virtual content in\nnatural locations. Most existing automated techniques can only work with a\nclosed-vocabulary, fixed set of objects. In this paper, we introduce and\nevaluate several methods for automatic object placement using recent advances\nin open-vocabulary vision-language models. Through a multifaceted evaluation,\nwe identify a new state-of-the-art method, OCTO+. We also introduce a benchmark\nfor automatically evaluating the placement of virtual objects in augmented\nreality, alleviating the need for costly user studies. Through this, in\naddition to human evaluations, we find that OCTO+ places objects in a valid\nregion over 70% of the time, outperforming other methods on a range of metrics.",
      "tldr_zh": "本研究针对增强现实（Augmented Reality）中虚拟内容放置的挑战，提出并评估了多种基于开放词汇视觉语言模型（open-vocabulary vision-language models）的自动对象放置方法。论文引入了新的最先进技术OCTO+，该方法通过多方面评估实现了对象放置的有效性。作者还开发了一个自动基准，用于评估虚拟对象放置，无需昂贵的人类研究，结果显示OCTO+在70%以上的情况下将对象放置在有效区域，并在多种指标上优于其他方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "2024 IEEE International Conference on Artificial Intelligence and\n  eXtended and Virtual Reality (AIXVR)",
      "pdf_url": "http://arxiv.org/pdf/2401.08973v1",
      "published_date": "2024-01-17 04:52:40 UTC",
      "updated_date": "2024-01-17 04:52:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:28:45.290171"
    },
    {
      "arxiv_id": "2401.10289v1",
      "title": "Design and development of opto-neural processors for simulation of neural networks trained in image detection for potential implementation in hybrid robotics",
      "title_zh": "翻译失败",
      "authors": [
        "Sanjana Shetty"
      ],
      "abstract": "Neural networks have been employed for a wide range of processing\napplications like image processing, motor control, object detection and many\nothers. Living neural networks offer advantages of lower power consumption,\nfaster processing, and biological realism. Optogenetics offers high spatial and\ntemporal control over biological neurons and presents potential in training\nlive neural networks. This work proposes a simulated living neural network\ntrained indirectly by backpropagating STDP based algorithms using precision\nactivation by optogenetics achieving accuracy comparable to traditional neural\nnetwork training algorithms.",
      "tldr_zh": "这篇论文设计了opto-neural processors，用于模拟训练图像检测神经网络，旨在应用于hybrid robotics领域。研究强调活体神经网络的优势，如低功耗、更快处理和生物真实性，并利用Optogenetics提供对生物神经元的高空间和时间控制。论文提出了一种基于STDP算法的间接反向传播训练方法，使模拟活体神经网络的准确性与传统神经网络训练算法相当。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.ET",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10289v1",
      "published_date": "2024-01-17 04:42:49 UTC",
      "updated_date": "2024-01-17 04:42:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:28:58.814856"
    },
    {
      "arxiv_id": "2401.08960v1",
      "title": "From User Surveys to Telemetry-Driven Agents: Exploring the Potential of Personalized Productivity Solutions",
      "title_zh": "翻译失败",
      "authors": [
        "Subigya Nepal",
        "Javier Hernandez",
        "Talie Massachi",
        "Kael Rowan",
        "Judith Amores",
        "Jina Suh",
        "Gonzalo Ramos",
        "Brian Houck",
        "Shamsi T. Iqbal",
        "Mary Czerwinski"
      ],
      "abstract": "We present a comprehensive, user-centric approach to understand preferences\nin AI-based productivity agents and develop personalized solutions tailored to\nusers' needs. Utilizing a two-phase method, we first conducted a survey with\n363 participants, exploring various aspects of productivity, communication\nstyle, agent approach, personality traits, personalization, and privacy.\nDrawing on the survey insights, we developed a GPT-4 powered personalized\nproductivity agent that utilizes telemetry data gathered via Viva Insights from\ninformation workers to provide tailored assistance. We compared its performance\nwith alternative productivity-assistive tools, such as dashboard and narrative,\nin a study involving 40 participants. Our findings highlight the importance of\nuser-centric design, adaptability, and the balance between personalization and\nprivacy in AI-assisted productivity tools. By building on the insights\ndistilled from our study, we believe that our work can enable and guide future\nresearch to further enhance productivity solutions, ultimately leading to\noptimized efficiency and user experiences for information workers.",
      "tldr_zh": "本研究提出了一种用户导向的方法，旨在理解AI-based生产力代理的偏好并开发个性化解决方案。首先，通过一项涉及363名参与者的调查，探讨了生产力、communication style、agent approach、personality traits、personalization和privacy等关键方面。其次，基于调查洞见，开发了一个利用GPT-4驱动的个性化生产力代理，该代理使用telemetry data从Viva Insights收集信息，为信息工作者提供定制化协助。在一项涉及40名参与者的比较研究中，该代理的表现优于其他工具（如dashboard和narrative），突显了用户-centric设计、可适应性和personalization与privacy平衡的重要性，最终为提升生产力解决方案和用户体验提供指导。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "H.5.0; H.5.3; H.5.m; J.0"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08960v1",
      "published_date": "2024-01-17 04:20:10 UTC",
      "updated_date": "2024-01-17 04:20:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:29:10.091749"
    },
    {
      "arxiv_id": "2401.08959v1",
      "title": "Towards Off-Policy Reinforcement Learning for Ranking Policies with Human Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Teng Xiao",
        "Suhang Wang"
      ],
      "abstract": "Probabilistic learning to rank (LTR) has been the dominating approach for\noptimizing the ranking metric, but cannot maximize long-term rewards.\nReinforcement learning models have been proposed to maximize user long-term\nrewards by formulating the recommendation as a sequential decision-making\nproblem, but could only achieve inferior accuracy compared to LTR counterparts,\nprimarily due to the lack of online interactions and the characteristics of\nranking. In this paper, we propose a new off-policy value ranking (VR)\nalgorithm that can simultaneously maximize user long-term rewards and optimize\nthe ranking metric offline for improved sample efficiency in a unified\nExpectation-Maximization (EM) framework. We theoretically and empirically show\nthat the EM process guides the leaned policy to enjoy the benefit of\nintegration of the future reward and ranking metric, and learn without any\nonline interactions. Extensive offline and online experiments demonstrate the\neffectiveness of our methods.",
      "tldr_zh": "本研究针对传统 Probabilistic LTR 方法无法最大化用户长期奖励的问题，提出了一种 Off-Policy Value Ranking (VR) 算法，利用 Expectation-Maximization (EM) 框架，在离线环境中同时优化排名指标和长期奖励，从而提升样本效率。算法通过整合未来奖励和排名指标的 EM 过程，实现无在线互动的学习，并在理论上证明了其有效性。广泛的离线和在线实验结果表明，该方法显著优于现有强化学习模型，在准确性和奖励最大化方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08959v1",
      "published_date": "2024-01-17 04:19:33 UTC",
      "updated_date": "2024-01-17 04:19:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:29:23.349256"
    },
    {
      "arxiv_id": "2401.08957v3",
      "title": "Learning from Imperfect Demonstrations with Self-Supervision for Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Wu",
        "Ning Liu",
        "Zhen Zhao",
        "Di Qiu",
        "Jinming Li",
        "Zhengping Che",
        "Zhiyuan Xu",
        "Jian Tang"
      ],
      "abstract": "Improving data utilization, especially for imperfect data from task failures,\nis crucial for robotic manipulation due to the challenging, time-consuming, and\nexpensive data collection process in the real world. Current imitation learning\n(IL) typically discards imperfect data, focusing solely on successful expert\ndata. While reinforcement learning (RL) can learn from explorations and\nfailures, the sim2real gap and its reliance on dense reward and online\nexploration make it difficult to apply effectively in real-world scenarios. In\nthis work, we aim to conquer the challenge of leveraging imperfect data without\nthe need for reward information to improve the model performance for robotic\nmanipulation in an offline manner. Specifically, we introduce a Self-Supervised\nData Filtering framework (SSDF) that combines expert and imperfect data to\ncompute quality scores for failed trajectory segments. High-quality segments\nfrom the failed data are used to expand the training dataset. Then, the\nenhanced dataset can be used with any downstream policy learning method for\nrobotic manipulation tasks. Extensive experiments on the ManiSkill2 benchmark\nbuilt on the high-fidelity Sapien simulator and real-world robotic manipulation\ntasks using the Franka robot arm demonstrated that the SSDF can accurately\nexpand the training dataset with high-quality imperfect data and improve the\nsuccess rates for all robotic manipulation tasks.",
      "tldr_zh": "本研究针对机器人操作中数据收集的挑战，提出了一种自监督数据过滤框架（Self-Supervised Data Filtering, SSDF），旨在利用不完美演示数据（如任务失败轨迹）来提升模型性能，而无需依赖奖励信息或在线探索。SSDF 通过结合专家数据和不完美数据计算失败轨迹段的质量分数，并选取高质量段来扩展训练数据集，从而与下游策略学习方法（如 imitation learning）无缝整合。实验在 ManiSkill2 基准模拟器和真实世界 Franka 机器人手臂任务中证明，该框架能准确扩展数据集，并显著提高所有机器人操作任务的成功率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2.9"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.08957v3",
      "published_date": "2024-01-17 04:15:56 UTC",
      "updated_date": "2025-03-17 06:17:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:29:34.478930"
    },
    {
      "arxiv_id": "2401.10934v1",
      "title": "A New Creative Generation Pipeline for Click-Through Rate with Stable Diffusion Model",
      "title_zh": "一种新的基于 Stable Diffusion 模型的点击通过率创意生成管道",
      "authors": [
        "Hao Yang",
        "Jianxin Yuan",
        "Shuai Yang",
        "Linhe Xu",
        "Shuo Yuan",
        "Yifan Zeng"
      ],
      "abstract": "In online advertising scenario, sellers often create multiple creatives to\nprovide comprehensive demonstrations, making it essential to present the most\nappealing design to maximize the Click-Through Rate (CTR). However, sellers\ngenerally struggle to consider users preferences for creative design, leading\nto the relatively lower aesthetics and quantities compared to Artificial\nIntelligence (AI)-based approaches. Traditional AI-based approaches still face\nthe same problem of not considering user information while having limited\naesthetic knowledge from designers. In fact that fusing the user information,\nthe generated creatives can be more attractive because different users may have\ndifferent preferences. To optimize the results, the generated creatives in\ntraditional methods are then ranked by another module named creative ranking\nmodel. The ranking model can predict the CTR score for each creative\nconsidering user features. However, the two above stages are regarded as two\ndifferent tasks and are optimized separately. In this paper, we proposed a new\nautomated Creative Generation pipeline for Click-Through Rate (CG4CTR) with the\ngoal of improving CTR during the creative generation stage. Our contributions\nhave 4 parts: 1) The inpainting mode in stable diffusion is firstly applied to\ncreative generation task in online advertising scene. A self-cyclic generation\npipeline is proposed to ensure the convergence of training. 2) Prompt model is\ndesigned to generate individualized creatives for different user groups, which\ncan further improve the diversity and quality. 3) Reward model comprehensively\nconsiders the multimodal features of image and text to improve the\neffectiveness of creative ranking task, and it is also critical in self-cyclic\npipeline. 4) The significant benefits obtained in online and offline\nexperiments verify the significance of our proposed method.",
      "tldr_zh": "本论文提出了一种新的创意生成管道 CG4CTR，用于在线广告中提升 Click-Through Rate (CTR)，通过整合 Stable Diffusion 模型来生成个性化创意。核心贡献包括：首次将 Stable Diffusion 的 inpainting 模式应用于广告场景，并设计自循环生成管道确保训练收敛；开发 Prompt 模型为不同用户生成多样化、高质量的创意；以及构建 Reward 模型，综合图像和文本的多模态特征优化创意排名。该方法在在线和离线实验中显示出显著益处，提高了创意的吸引力和整体 CTR 性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10934v1",
      "published_date": "2024-01-17 03:27:39 UTC",
      "updated_date": "2024-01-17 03:27:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:29:47.668939"
    },
    {
      "arxiv_id": "2401.08940v1",
      "title": "CEL: A Continual Learning Model for Disease Outbreak Prediction by Leveraging Domain Adaptation via Elastic Weight Consolidation",
      "title_zh": "翻译失败",
      "authors": [
        "Saba Aslam",
        "Abdur Rasool",
        "Hongyan Wu",
        "Xiaoli Li"
      ],
      "abstract": "Continual learning, the ability of a model to learn over time without\nforgetting previous knowledge and, therefore, be adaptive to new data, is\nparamount in dynamic fields such as disease outbreak prediction. Deep neural\nnetworks, i.e., LSTM, are prone to error due to catastrophic forgetting. This\nstudy introduces a novel CEL model for continual learning by leveraging domain\nadaptation via Elastic Weight Consolidation (EWC). This model aims to mitigate\nthe catastrophic forgetting phenomenon in a domain incremental setting. The\nFisher Information Matrix (FIM) is constructed with EWC to develop a\nregularization term that penalizes changes to important parameters, namely, the\nimportant previous knowledge. CEL's performance is evaluated on three distinct\ndiseases, Influenza, Mpox, and Measles, with different metrics. The high\nR-squared values during evaluation and reevaluation outperform the other\nstate-of-the-art models in several contexts, indicating that CEL adapts to\nincremental data well. CEL's robustness and reliability are underscored by its\nminimal 65% forgetting rate and 18% higher memory stability compared to\nexisting benchmark studies. This study highlights CEL's versatility in disease\noutbreak prediction, addressing evolving data with temporal patterns. It offers\na valuable model for proactive disease control with accurate, timely\npredictions.",
      "tldr_zh": "本研究提出 CEL 模型，一种基于 Continual Learning 的框架，用于疾病爆发预测，通过 Elastic Weight Consolidation (EWC) 实现 Domain Adaptation，从而缓解深度神经网络（如 LSTM）中的 Catastrophic Forgetting 问题。模型利用 Fisher Information Matrix (FIM) 构建正则化项，惩罚对重要参数的改变，以保留先前知识并适应新数据。实验结果显示，CEL 在 Influenza、Mpox 和 Measles 等疾病上的评估中，取得了高 R-squared 值、仅 65% 的遗忘率，以及比基准模型高 18% 的内存稳定性，提供了一个可靠的工具，支持准确及时的疾病控制预测。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08940v1",
      "published_date": "2024-01-17 03:26:04 UTC",
      "updated_date": "2024-01-17 03:26:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:29:58.777259"
    },
    {
      "arxiv_id": "2401.08936v1",
      "title": "DeLF: Designing Learning Environments with Foundation Models",
      "title_zh": "DeLF：使用基础模型设计学习环境",
      "authors": [
        "Aida Afshar",
        "Wenchao Li"
      ],
      "abstract": "Reinforcement learning (RL) offers a capable and intuitive structure for the\nfundamental sequential decision-making problem. Despite impressive\nbreakthroughs, it can still be difficult to employ RL in practice in many\nsimple applications. In this paper, we try to address this issue by introducing\na method for designing the components of the RL environment for a given,\nuser-intended application. We provide an initial formalization for the problem\nof RL component design, that concentrates on designing a good representation\nfor observation and action space. We propose a method named DeLF: Designing\nLearning Environments with Foundation Models, that employs large language\nmodels to design and codify the user's intended learning scenario. By testing\nour method on four different learning environments, we demonstrate that DeLF\ncan obtain executable environment codes for the corresponding RL problems.",
      "tldr_zh": "该论文针对强化学习（RL）在实际应用中的困难，提出了一种名为 DeLF 的方法，利用基础模型（如大语言模型）来设计 RL 环境的组件，特别是观察和动作空间的表示。DeLF 通过正式化 RL 组件设计问题，并使用大语言模型编码用户的学习场景，从而生成可执行的环境代码。在四个不同学习环境中测试表明，DeLF 能够成功创建对应 RL 问题的环境，促进 RL 的实际部署。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI 2024 Workshop on Synergy of Reinforcement Learning and Large\n  Language Models",
      "pdf_url": "http://arxiv.org/pdf/2401.08936v1",
      "published_date": "2024-01-17 03:14:28 UTC",
      "updated_date": "2024-01-17 03:14:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:30:09.674019"
    },
    {
      "arxiv_id": "2401.08932v1",
      "title": "Learning to detect cloud and snow in remote sensing images from noisy labels",
      "title_zh": "翻译失败",
      "authors": [
        "Zili Liu",
        "Hao Chen",
        "Wenyuan Li",
        "Keyan Chen",
        "Zipeng Qi",
        "Chenyang Liu",
        "Zhengxia Zou",
        "Zhenwei Shi"
      ],
      "abstract": "Detecting clouds and snow in remote sensing images is an essential\npreprocessing task for remote sensing imagery. Previous works draw inspiration\nfrom semantic segmentation models in computer vision, with most research\nfocusing on improving model architectures to enhance detection performance.\nHowever, unlike natural images, the complexity of scenes and the diversity of\ncloud types in remote sensing images result in many inaccurate labels in cloud\nand snow detection datasets, introducing unnecessary noises into the training\nand testing processes. By constructing a new dataset and proposing a novel\ntraining strategy with the curriculum learning paradigm, we guide the model in\nreducing overfitting to noisy labels. Additionally, we design a more\nappropriate model performance evaluation method, that alleviates the\nperformance assessment bias caused by noisy labels. By conducting experiments\non models with UNet and Segformer, we have validated the effectiveness of our\nproposed method. This paper is the first to consider the impact of label noise\non the detection of clouds and snow in remote sensing images.",
      "tldr_zh": "这篇论文探讨了在遥感图像中检测云和雪的预处理任务，强调了标签噪声问题对模型训练和评估的影响，这是以往研究中被忽略的关键挑战。作者构建了一个新数据集，并提出了一种基于课程学习(curriculum learning)的新训练策略，以减少模型对噪声标签的过拟合，同时设计了一个更合适的性能评估方法来缓解评估偏差。在UNet和Segformer模型上的实验验证了该方法的有效性，这也是首次系统考虑标签噪声对云和雪检测的影响。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08932v1",
      "published_date": "2024-01-17 03:02:31 UTC",
      "updated_date": "2024-01-17 03:02:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:30:22.042961"
    },
    {
      "arxiv_id": "2401.08930v1",
      "title": "3D Human Pose Analysis via Diffusion Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Haorui Ji",
        "Hongdong Li"
      ],
      "abstract": "Diffusion models have demonstrated remarkable success in generative modeling.\nIn this paper, we propose PADS (Pose Analysis by Diffusion Synthesis), a novel\nframework designed to address various challenges in 3D human pose analysis\nthrough a unified pipeline. Central to PADS are two distinctive strategies: i)\nlearning a task-agnostic pose prior using a diffusion synthesis process to\neffectively capture the kinematic constraints in human pose data, and ii)\nunifying multiple pose analysis tasks like estimation, completion, denoising,\netc, as instances of inverse problems. The learned pose prior will be treated\nas a regularization imposing on task-specific constraints, guiding the\noptimization process through a series of conditional denoising steps. PADS\nrepresents the first diffusion-based framework for tackling general 3D human\npose analysis within the inverse problem framework. Its performance has been\nvalidated on different benchmarks, signaling the adaptability and robustness of\nthis pipeline.",
      "tldr_zh": "本文提出 PADS（Pose Analysis by Diffusion Synthesis）框架，利用扩散模型统一处理 3D 人类姿势分析的各种挑战，如估计、完成和去噪等任务。核心方法包括学习一个任务无关的姿势先验（task-agnostic pose prior）来捕捉运动学约束，并将这些任务视为逆问题（inverse problems）的实例，通过条件去噪步骤施加正则化优化。实验结果显示，PADS 在不同基准上表现出色，证明了其适应性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08930v1",
      "published_date": "2024-01-17 02:59:34 UTC",
      "updated_date": "2024-01-17 02:59:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:30:35.058771"
    },
    {
      "arxiv_id": "2401.08898v3",
      "title": "Bridging State and History Representations: Understanding Self-Predictive RL",
      "title_zh": "翻译失败",
      "authors": [
        "Tianwei Ni",
        "Benjamin Eysenbach",
        "Erfan Seyedsalehi",
        "Michel Ma",
        "Clement Gehring",
        "Aditya Mahajan",
        "Pierre-Luc Bacon"
      ],
      "abstract": "Representations are at the core of all deep reinforcement learning (RL)\nmethods for both Markov decision processes (MDPs) and partially observable\nMarkov decision processes (POMDPs). Many representation learning methods and\ntheoretical frameworks have been developed to understand what constitutes an\neffective representation. However, the relationships between these methods and\nthe shared properties among them remain unclear. In this paper, we show that\nmany of these seemingly distinct methods and frameworks for state and history\nabstractions are, in fact, based on a common idea of self-predictive\nabstraction. Furthermore, we provide theoretical insights into the widely\nadopted objectives and optimization, such as the stop-gradient technique, in\nlearning self-predictive representations. These findings together yield a\nminimalist algorithm to learn self-predictive representations for states and\nhistories. We validate our theories by applying our algorithm to standard MDPs,\nMDPs with distractors, and POMDPs with sparse rewards. These findings culminate\nin a set of preliminary guidelines for RL practitioners.",
      "tldr_zh": "该论文探讨了强化学习（RL）中状态和历史表示的统一框架，揭示了许多看似不同的表示学习方法（如针对 MDPs 和 POMDPs 的抽象）都基于共同的 self-predictive abstraction 概念。作者提供了理论洞见，包括 stop-gradient technique 在学习自预测表示中的作用，并提出一个最小主义算法来高效学习这些表示。实验在标准 MDPs、带有干扰的 MDPs 以及稀疏奖励的 POMDPs 上验证了该算法的有效性，最终为 RL 实践者提供了初步指导方针。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024 (Poster). Code is available at\n  https://github.com/twni2016/self-predictive-rl",
      "pdf_url": "http://arxiv.org/pdf/2401.08898v3",
      "published_date": "2024-01-17 00:47:43 UTC",
      "updated_date": "2024-04-21 05:59:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:30:45.887757"
    },
    {
      "arxiv_id": "2401.08897v3",
      "title": "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational AutoEncoder",
      "title_zh": "翻译失败",
      "authors": [
        "Hee-Jun Jung",
        "Jaehyoung Jeong",
        "Kangil Kim"
      ],
      "abstract": "Symmetries of input and latent vectors have provided valuable insights for\ndisentanglement learning in VAEs. However, only a few works were proposed as an\nunsupervised method, and even these works require known factor information in\nthe training data. We propose a novel method, Composite Factor-Aligned Symmetry\nLearning (CFASL), which is integrated into VAEs for learning symmetry-based\ndisentanglement in unsupervised learning without any knowledge of the dataset\nfactor information. CFASL incorporates three novel features for learning\nsymmetry-based disentanglement: 1) Injecting inductive bias to align latent\nvector dimensions to factor-aligned symmetries within an explicit learnable\nsymmetry code-book 2) Learning a composite symmetry to express unknown factors\nchange between two random samples by learning factor-aligned symmetries within\nthe codebook 3) Inducing a group equivariant encoder and decoder in training\nVAEs with the two conditions. In addition, we propose an extended evaluation\nmetric for multi-factor changes in comparison to disentanglement evaluation in\nVAEs. In quantitative and in-depth qualitative analysis, CFASL demonstrates a\nsignificant improvement of disentanglement in single-factor change, and\nmulti-factor change conditions compared to state-of-the-art methods.",
      "tldr_zh": "本论文提出了一种名为 CFASL 的新方法，用于在 Variational AutoEncoder (VAEs) 中实现无监督的对称性-based 解缠结学习，而无需事先知道数据集的因子信息。CFASL 通过三个关键特征提升性能：1) 注入归纳偏差，将潜在向量维度与显式可学习的对称代码书中的因子对齐对称性；2) 学习复合对称性，以表达两个随机样本之间未知因子的变化；3) 诱导组等变编码器和解码器来训练 VAEs。实验结果显示，CFASL 在单因子和多因子变化条件下显著提高了解缠结性能，并在定量和定性分析中超越了现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in TMLR 25 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.08897v3",
      "published_date": "2024-01-17 00:46:24 UTC",
      "updated_date": "2024-11-12 01:30:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:31:00.301840"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 61,
  "processed_papers_count": 61,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T22:31:19.874999"
}