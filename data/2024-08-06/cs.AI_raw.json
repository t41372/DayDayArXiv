[
  {
    "arxiv_id": "2408.03475v1",
    "title": "Can LLMs Serve As Time Series Anomaly Detectors?",
    "authors": [
      "Manqing Dong",
      "Hao Huang",
      "Longbing Cao"
    ],
    "abstract": "An emerging topic in large language models (LLMs) is their application to\ntime series forecasting, characterizing mainstream and patternable\ncharacteristics of time series. A relevant but rarely explored and more\nchallenging question is whether LLMs can detect and explain time series\nanomalies, a critical task across various real-world applications. In this\npaper, we investigate the capabilities of LLMs, specifically GPT-4 and LLaMA3,\nin detecting and explaining anomalies in time series. Our studies reveal that:\n1) LLMs cannot be directly used for time series anomaly detection. 2) By\ndesigning prompt strategies such as in-context learning and chain-of-thought\nprompting, GPT-4 can detect time series anomalies with results competitive to\nbaseline methods. 3) We propose a synthesized dataset to automatically generate\ntime series anomalies with corresponding explanations. By applying instruction\nfine-tuning on this dataset, LLaMA3 demonstrates improved performance in time\nseries anomaly detection tasks. In summary, our exploration shows the promising\npotential of LLMs as time series anomaly detectors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03475v1",
    "published_date": "2024-08-06 23:14:39 UTC",
    "updated_date": "2024-08-06 23:14:39 UTC"
  },
  {
    "arxiv_id": "2408.11837v1",
    "title": "MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy",
    "authors": [
      "Hanchen David Wang",
      "Nibraas Khan",
      "Anna Chen",
      "Nilanjan Sarkar",
      "Pamela Wisniewski",
      "Meiyi Ma"
    ],
    "abstract": "Recent global estimates suggest that as many as 2.41 billion individuals have\nhealth conditions that would benefit from rehabilitation services. Home-based\nPhysical Therapy (PT) faces significant challenges in providing interactive\nfeedback and meaningful observation for therapists and patients. To fill this\ngap, we present MicroXercise, which integrates micro-motion analysis with\nwearable sensors, providing therapists and patients with a comprehensive\nfeedback interface, including video, text, and scores. Crucially, it employs\nmulti-dimensional Dynamic Time Warping (DTW) and attribution-based explainable\nmethods to analyze the existing deep learning neural networks in monitoring\nexercises, focusing on a high granularity of exercise. This synergistic\napproach is pivotal, providing output matching the input size to precisely\nhighlight critical subtleties and movements in PT, thus transforming complex AI\nanalysis into clear, actionable feedback. By highlighting these micro-motions\nin different metrics, such as stability and range of motion, MicroXercise\nsignificantly enhances the understanding and relevance of feedback for\nend-users. Comparative performance metrics underscore its effectiveness over\ntraditional methods, such as a 39% and 42% improvement in Feature Mutual\nInformation (FMI) and Continuity. MicroXercise is a step ahead in home-based\nphysical therapy, providing a technologically advanced and intuitively helpful\nsolution to enhance patient care and outcomes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IEEE/ACM CHASE 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.11837v1",
    "published_date": "2024-08-06 22:39:47 UTC",
    "updated_date": "2024-08-06 22:39:47 UTC"
  },
  {
    "arxiv_id": "2408.03463v4",
    "title": "Identifying treatment response subgroups in observational time-to-event data",
    "authors": [
      "Vincent Jeanselme",
      "Chang Ho Yoon",
      "Fabian Falck",
      "Brian Tom",
      "Jessica Barrett"
    ],
    "abstract": "Identifying patient subgroups with different treatment responses is an\nimportant task to inform medical recommendations, guidelines, and the design of\nfuture clinical trials. Existing approaches for treatment effect estimation\nprimarily rely on Randomised Controlled Trials (RCTs), which are often limited\nby insufficient power, multiple comparisons, and unbalanced covariates. In\naddition, RCTs tend to feature more homogeneous patient groups, making them\nless relevant for uncovering subgroups in the population encountered in\nreal-world clinical practice. Subgroup analyses established for RCTs suffer\nfrom significant statistical biases when applied to observational studies,\nwhich benefit from larger and more representative populations. Our work\nintroduces a novel, outcome-guided, subgroup analysis strategy for identifying\nsubgroups of treatment response in both RCTs and observational studies alike.\nIt hence positions itself in-between individualised and average treatment\neffect estimation to uncover patient subgroups with distinct treatment\nresponses, critical for actionable insights that may influence treatment\nguidelines. In experiments, our approach significantly outperforms the current\nstate-of-the-art method for subgroup analysis in both randomised and\nobservational treatment regimes.",
    "categories": [
      "stat.ME",
      "cs.AI"
    ],
    "primary_category": "stat.ME",
    "comment": "Preprint under review",
    "pdf_url": "http://arxiv.org/pdf/2408.03463v4",
    "published_date": "2024-08-06 22:38:14 UTC",
    "updated_date": "2025-02-24 00:33:14 UTC"
  },
  {
    "arxiv_id": "2408.11834v1",
    "title": "SCREENER: A general framework for task-specific experiment design in quantitative MRI",
    "authors": [
      "Tianshu Zheng",
      "Zican Wang",
      "Timothy Bray",
      "Daniel C. Alexander",
      "Dan Wu",
      "Hui Zhang"
    ],
    "abstract": "Quantitative magnetic resonance imaging (qMRI) is increasingly investigated\nfor use in a variety of clinical tasks from diagnosis, through staging, to\ntreatment monitoring. However, experiment design in qMRI, the identification of\nthe optimal acquisition protocols, has been focused on obtaining the most\nprecise parameter estimations, with no regard for the specific requirements of\ndownstream tasks. Here we propose SCREENER: A general framework for\ntask-specific experiment design in quantitative MRI. SCREENER incorporates a\ntask-specific objective and seeks the optimal protocol with a\ndeep-reinforcement-learning (DRL) based optimization strategy. To illustrate\nthis framework, we employ a task of classifying the inflammation status of bone\nmarrow using diffusion MRI data with intravoxel incoherent motion (IVIM)\nmodelling. Results demonstrate SCREENER outperforms previous ad hoc and\noptimized protocols under clinical signal-to-noise ratio (SNR) conditions,\nachieving significant improvement, both in binary classification tasks, e.g.\nfrom 67% to 89%, and in a multi-class classification task, from 46% to 59%.\nAdditionally, we show this improvement is robust to the SNR. Lastly, we\ndemonstrate the advantage of DRL-based optimization strategy, enabling\nzero-shot discovery of near-optimal protocols for a range of SNRs not used in\ntraining. In conclusion, SCREENER has the potential to enable wider uptake of\nqMRI in the clinic.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11834v1",
    "published_date": "2024-08-06 21:43:50 UTC",
    "updated_date": "2024-08-06 21:43:50 UTC"
  },
  {
    "arxiv_id": "2408.03449v1",
    "title": "EEGMobile: Enhancing Speed and Accuracy in EEG-Based Gaze Prediction with Advanced Mobile Architectures",
    "authors": [
      "Teng Liang",
      "Andrews Damoah"
    ],
    "abstract": "Electroencephalography (EEG) analysis is an important domain in the realm of\nBrain-Computer Interface (BCI) research. To ensure BCI devices are capable of\nproviding practical applications in the real world, brain signal processing\ntechniques must be fast, accurate, and resource-conscious to deliver\nlow-latency neural analytics. This study presents a model that leverages a\npre-trained MobileViT alongside Knowledge Distillation (KD) for EEG regression\ntasks. Our results showcase that this model is capable of performing at a level\ncomparable (only 3% lower) to the previous State-Of-The-Art (SOTA) on the\nEEGEyeNet Absolute Position Task while being 33% faster and 60% smaller. Our\nresearch presents a cost-effective model applicable to resource-constrained\ndevices and contributes to expanding future research on lightweight,\nmobile-friendly models for EEG regression.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepted HCI International 2024 - Late Breaking Work",
    "pdf_url": "http://arxiv.org/pdf/2408.03449v1",
    "published_date": "2024-08-06 21:02:27 UTC",
    "updated_date": "2024-08-06 21:02:27 UTC"
  },
  {
    "arxiv_id": "2408.03435v1",
    "title": "Communication-Aware Consistent Edge Selection for Mobile Users and Autonomous Vehicles",
    "authors": [
      "Nazish Tahir",
      "Ramviyas Parasuraman",
      "Haijian Sun"
    ],
    "abstract": "Offloading time-sensitive, computationally intensive tasks-such as advanced\nlearning algorithms for autonomous driving-from vehicles to nearby edge\nservers, vehicle-to-infrastructure (V2I) systems, or other collaborating\nvehicles via vehicle-to-vehicle (V2V) communication enhances service\nefficiency. However, whence traversing the path to the destination, the\nvehicle's mobility necessitates frequent handovers among the access points\n(APs) to maintain continuous and uninterrupted wireless connections to maintain\nthe network's Quality of Service (QoS). These frequent handovers subsequently\nlead to task migrations among the edge servers associated with the respective\nAPs. This paper addresses the joint problem of task migration and access-point\nhandover by proposing a deep reinforcement learning framework based on the Deep\nDeterministic Policy Gradient (DDPG) algorithm. A joint allocation method of\ncommunication and computation of APs is proposed to minimize computational\nload, service latency, and interruptions with the overarching goal of\nmaximizing QoS. We implement and evaluate our proposed framework on simulated\nexperiments to achieve smooth and seamless task switching among edge servers,\nultimately reducing latency.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.NI",
    "comment": "Accepted by Vehicular Technology Conference (VTC) Fall 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.03435v1",
    "published_date": "2024-08-06 20:21:53 UTC",
    "updated_date": "2024-08-06 20:21:53 UTC"
  },
  {
    "arxiv_id": "2408.03405v1",
    "title": "Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents",
    "authors": [
      "Lucia Gordon",
      "Esther Rolf",
      "Milind Tambe"
    ],
    "abstract": "Stochastic multi-agent multi-armed bandits typically assume that the rewards\nfrom each arm follow a fixed distribution, regardless of which agent pulls the\narm. However, in many real-world settings, rewards can depend on the\nsensitivity of each agent to their environment. In medical screening, disease\ndetection rates can vary by test type; in preference matching, rewards can\ndepend on user preferences; and in environmental sensing, observation quality\ncan vary across sensors. Since past work does not specify how to allocate\nagents of heterogeneous but known sensitivity of these types in a stochastic\nbandit setting, we introduce a UCB-style algorithm, Min-Width, which aggregates\ninformation from diverse agents. In doing so, we address the joint challenges\nof (i) aggregating the rewards, which follow different distributions for each\nagent-arm pair, and (ii) coordinating the assignments of agents to arms.\nMin-Width facilitates efficient collaboration among heterogeneous agents,\nexploiting the known structure in the agents' reward functions to weight their\nrewards accordingly. We analyze the regret of Min-Width and conduct\npseudo-synthetic and fully synthetic experiments to study the performance of\ndifferent levels of information sharing. Our results confirm that the gains to\nmodeling agent heterogeneity tend to be greater when the sensitivities are more\nvaried across agents, while combining more information does not always improve\nperformance.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "19 pages, 6 figures, to be published in ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.03405v1",
    "published_date": "2024-08-06 18:56:29 UTC",
    "updated_date": "2024-08-06 18:56:29 UTC"
  },
  {
    "arxiv_id": "2408.03400v1",
    "title": "Attacks and Defenses for Generative Diffusion Models: A Comprehensive Survey",
    "authors": [
      "Vu Tuan Truong",
      "Luan Ba Dang",
      "Long Bao Le"
    ],
    "abstract": "Diffusion models (DMs) have achieved state-of-the-art performance on various\ngenerative tasks such as image synthesis, text-to-image, and text-guided\nimage-to-image generation. However, the more powerful the DMs, the more harmful\nthey potentially are. Recent studies have shown that DMs are prone to a wide\nrange of attacks, including adversarial attacks, membership inference, backdoor\ninjection, and various multi-modal threats. Since numerous pre-trained DMs are\npublished widely on the Internet, potential threats from these attacks are\nespecially detrimental to the society, making DM-related security a worth\ninvestigating topic. Therefore, in this paper, we conduct a comprehensive\nsurvey on the security aspect of DMs, focusing on various attack and defense\nmethods for DMs. First, we present crucial knowledge of DMs with five main\ntypes of DMs, including denoising diffusion probabilistic models, denoising\ndiffusion implicit models, noise conditioned score networks, stochastic\ndifferential equations, and multi-modal conditional DMs. We further survey a\nvariety of recent studies investigating different types of attacks that exploit\nthe vulnerabilities of DMs. Then, we thoroughly review potential\ncountermeasures to mitigate each of the presented threats. Finally, we discuss\nopen challenges of DM-related security and envision certain research directions\nfor this topic.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03400v1",
    "published_date": "2024-08-06 18:52:17 UTC",
    "updated_date": "2024-08-06 18:52:17 UTC"
  },
  {
    "arxiv_id": "2408.03399v1",
    "title": "RHiOTS: A Framework for Evaluating Hierarchical Time Series Forecasting Algorithms",
    "authors": [
      "Luis Roque",
      "Carlos Soares",
      "Lu√≠s Torgo"
    ],
    "abstract": "We introduce the Robustness of Hierarchically Organized Time Series (RHiOTS)\nframework, designed to assess the robustness of hierarchical time series\nforecasting models and algorithms on real-world datasets. Hierarchical time\nseries, where lower-level forecasts must sum to upper-level ones, are prevalent\nin various contexts, such as retail sales across countries. Current empirical\nevaluations of forecasting methods are often limited to a small set of\nbenchmark datasets, offering a narrow view of algorithm behavior. RHiOTS\naddresses this gap by systematically altering existing datasets and modifying\nthe characteristics of individual series and their interrelations. It uses a\nset of parameterizable transformations to simulate those changes in the data\ndistribution. Additionally, RHiOTS incorporates an innovative visualization\ncomponent, turning complex, multidimensional robustness evaluation results into\nintuitive, easily interpretable visuals. This approach allows an in-depth\nanalysis of algorithm and model behavior under diverse conditions. We\nillustrate the use of RHiOTS by analyzing the predictive performance of several\nalgorithms. Our findings show that traditional statistical methods are more\nrobust than state-of-the-art deep learning algorithms, except when the\ntransformation effect is highly disruptive. Furthermore, we found no\nsignificant differences in the robustness of the algorithms when applying\nspecific reconciliation methods, such as MinT. RHiOTS provides researchers with\na comprehensive tool for understanding the nuanced behavior of forecasting\nalgorithms, offering a more reliable basis for selecting the most appropriate\nmethod for a given problem.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6; I.5.1; G.3; H.2.8"
    ],
    "primary_category": "cs.LG",
    "comment": "Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining (KDD '24), August 25--29, 2024, Barcelona, Spain",
    "pdf_url": "http://arxiv.org/pdf/2408.03399v1",
    "published_date": "2024-08-06 18:52:15 UTC",
    "updated_date": "2024-08-06 18:52:15 UTC"
  },
  {
    "arxiv_id": "2408.03388v2",
    "title": "A Non-negative VAE:the Generalized Gamma Belief Network",
    "authors": [
      "Zhibin Duan",
      "Tiansheng Wen",
      "Muyao Wang",
      "Bo Chen",
      "Mingyuan Zhou"
    ],
    "abstract": "The gamma belief network (GBN), often regarded as a deep topic model, has\ndemonstrated its potential for uncovering multi-layer interpretable latent\nrepresentations in text data. Its notable capability to acquire interpretable\nlatent factors is partially attributed to sparse and non-negative\ngamma-distributed latent variables. However, the existing GBN and its\nvariations are constrained by the linear generative model, thereby limiting\ntheir expressiveness and applicability. To address this limitation, we\nintroduce the generalized gamma belief network (Generalized GBN) in this paper,\nwhich extends the original linear generative model to a more expressive\nnon-linear generative model. Since the parameters of the Generalized GBN no\nlonger possess an analytic conditional posterior, we further propose an\nupward-downward Weibull inference network to approximate the posterior\ndistribution of the latent variables. The parameters of both the generative\nmodel and the inference network are jointly trained within the variational\ninference framework. Finally, we conduct comprehensive experiments on both\nexpressivity and disentangled representation learning tasks to evaluate the\nperformance of the Generalized GBN against state-of-the-art Gaussian\nvariational autoencoders serving as baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03388v2",
    "published_date": "2024-08-06 18:18:37 UTC",
    "updated_date": "2024-08-15 04:24:00 UTC"
  },
  {
    "arxiv_id": "2408.03326v3",
    "title": "LLaVA-OneVision: Easy Visual Task Transfer",
    "authors": [
      "Bo Li",
      "Yuanhan Zhang",
      "Dong Guo",
      "Renrui Zhang",
      "Feng Li",
      "Hao Zhang",
      "Kaichen Zhang",
      "Peiyuan Zhang",
      "Yanwei Li",
      "Ziwei Liu",
      "Chunyuan Li"
    ],
    "abstract": "We present LLaVA-OneVision, a family of open large multimodal models (LMMs)\ndeveloped by consolidating our insights into data, models, and visual\nrepresentations in the LLaVA-NeXT blog series. Our experimental results\ndemonstrate that LLaVA-OneVision is the first single model that can\nsimultaneously push the performance boundaries of open LMMs in three important\ncomputer vision scenarios: single-image, multi-image, and video scenarios.\nImportantly, the design of LLaVA-OneVision allows strong transfer learning\nacross different modalities/scenarios, yielding new emerging capabilities. In\nparticular, strong video understanding and cross-scenario capabilities are\ndemonstrated through task transfer from images to videos.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Homepage:\n  https://llava-vl.github.io/blog/2024-08-05-llava-onevision/",
    "pdf_url": "http://arxiv.org/pdf/2408.03326v3",
    "published_date": "2024-08-06 17:59:44 UTC",
    "updated_date": "2024-10-26 16:35:13 UTC"
  },
  {
    "arxiv_id": "2408.03319v1",
    "title": "Training LLMs to Recognize Hedges in Spontaneous Narratives",
    "authors": [
      "Amie J. Paige",
      "Adil Soubki",
      "John Murzaku",
      "Owen Rambow",
      "Susan E. Brennan"
    ],
    "abstract": "Hedges allow speakers to mark utterances as provisional, whether to signal\nnon-prototypicality or \"fuzziness\", to indicate a lack of commitment to an\nutterance, to attribute responsibility for a statement to someone else, to\ninvite input from a partner, or to soften critical feedback in the service of\nface-management needs. Here we focus on hedges in an experimentally\nparameterized corpus of 63 Roadrunner cartoon narratives spontaneously produced\nfrom memory by 21 speakers for co-present addressees, transcribed to text\n(Galati and Brennan, 2010). We created a gold standard of hedges annotated by\nhuman coders (the Roadrunner-Hedge corpus) and compared three LLM-based\napproaches for hedge detection: fine-tuning BERT, and zero and few-shot\nprompting with GPT-4o and LLaMA-3. The best-performing approach was a\nfine-tuned BERT model, followed by few-shot GPT-4o. After an error analysis on\nthe top performing approaches, we used an LLM-in-the-Loop approach to improve\nthe gold standard coding, as well as to highlight cases in which hedges are\nambiguous in linguistically interesting ways that will guide future research.\nThis is the first step in our research program to train LLMs to interpret and\ngenerate collateral signals appropriately and meaningfully in conversation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Amie Paige, Adil Soubki, and John Murzaku contributed equally to this\n  study",
    "pdf_url": "http://arxiv.org/pdf/2408.03319v1",
    "published_date": "2024-08-06 17:51:42 UTC",
    "updated_date": "2024-08-06 17:51:42 UTC"
  },
  {
    "arxiv_id": "2408.03304v1",
    "title": "Fusing Forces: Deep-Human-Guided Refinement of Segmentation Masks",
    "authors": [
      "Rafael Sterzinger",
      "Christian Stippel",
      "Robert Sablatnig"
    ],
    "abstract": "Etruscan mirrors constitute a significant category in Etruscan art,\ncharacterized by elaborate figurative illustrations featured on their backside.\nA laborious and costly aspect of their analysis and documentation is the task\nof manually tracing these illustrations. In previous work, a methodology has\nbeen proposed to automate this process, involving photometric-stereo scanning\nin combination with deep neural networks. While achieving quantitative\nperformance akin to an expert annotator, some results still lack qualitative\nprecision and, thus, require annotators for inspection and potential\ncorrection, maintaining resource intensity. In response, we propose a deep\nneural network trained to interactively refine existing annotations based on\nhuman guidance. Our human-in-the-loop approach streamlines annotation,\nachieving equal quality with up to 75% less manual input required. Moreover,\nduring the refinement process, the relative improvement of our methodology over\npure manual labeling reaches peak values of up to 26%, attaining drastically\nbetter quality quicker. By being tailored to the complex task of segmenting\nintricate lines, specifically distinguishing it from previous methods, our\napproach offers drastic improvements in efficacy, transferable to a broad\nspectrum of applications beyond Etruscan mirrors.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, accepted at ICPR2024",
    "pdf_url": "http://arxiv.org/pdf/2408.03304v1",
    "published_date": "2024-08-06 17:11:40 UTC",
    "updated_date": "2024-08-06 17:11:40 UTC"
  },
  {
    "arxiv_id": "2408.03303v1",
    "title": "Understanding How Blind Users Handle Object Recognition Errors: Strategies and Challenges",
    "authors": [
      "Jonggi Hong",
      "Hernisa Kacorri"
    ],
    "abstract": "Object recognition technologies hold the potential to support blind and\nlow-vision people in navigating the world around them. However, the gap between\nbenchmark performances and practical usability remains a significant challenge.\nThis paper presents a study aimed at understanding blind users' interaction\nwith object recognition systems for identifying and avoiding errors. Leveraging\na pre-existing object recognition system, URCam, fine-tuned for our experiment,\nwe conducted a user study involving 12 blind and low-vision participants.\nThrough in-depth interviews and hands-on error identification tasks, we gained\ninsights into users' experiences, challenges, and strategies for identifying\nerrors in camera-based assistive technologies and object recognition systems.\nDuring interviews, many participants preferred independent error review, while\nexpressing apprehension toward misrecognitions. In the error identification\ntask, participants varied viewpoints, backgrounds, and object sizes in their\nimages to avoid and overcome errors. Even after repeating the task,\nparticipants identified only half of the errors, and the proportion of errors\nidentified did not significantly differ from their first attempts. Based on\nthese insights, we offer implications for designing accessible interfaces\ntailored to the needs of blind and low-vision users in identifying object\nrecognition errors.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03303v1",
    "published_date": "2024-08-06 17:09:56 UTC",
    "updated_date": "2024-08-06 17:09:56 UTC"
  },
  {
    "arxiv_id": "2408.03360v3",
    "title": "Prioritize Alignment in Dataset Distillation",
    "authors": [
      "Zekai Li",
      "Ziyao Guo",
      "Wangbo Zhao",
      "Tianle Zhang",
      "Zhi-Qi Cheng",
      "Samir Khaki",
      "Kaipeng Zhang",
      "Ahmad Sajedi",
      "Konstantinos N Plataniotis",
      "Kai Wang",
      "Yang You"
    ],
    "abstract": "Dataset Distillation aims to compress a large dataset into a significantly\nmore compact, synthetic one without compromising the performance of the trained\nmodels. To achieve this, existing methods use the agent model to extract\ninformation from the target dataset and embed it into the distilled dataset.\nConsequently, the quality of extracted and embedded information determines the\nquality of the distilled dataset. In this work, we find that existing methods\nintroduce misaligned information in both information extraction and embedding\nstages. To alleviate this, we propose Prioritize Alignment in Dataset\nDistillation (PAD), which aligns information from the following two\nperspectives. 1) We prune the target dataset according to the compressing ratio\nto filter the information that can be extracted by the agent model. 2) We use\nonly deep layers of the agent model to perform the distillation to avoid\nexcessively introducing low-level information. This simple strategy effectively\nfilters out misaligned information and brings non-trivial improvement for\nmainstream matching-based distillation algorithms. Furthermore, built on\ntrajectory matching, \\textbf{PAD} achieves remarkable improvements on various\nbenchmarks, achieving state-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.03360v3",
    "published_date": "2024-08-06 17:07:28 UTC",
    "updated_date": "2024-10-13 03:24:53 UTC"
  },
  {
    "arxiv_id": "2408.03297v2",
    "title": "KnowPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models",
    "authors": [
      "Ruizhe Zhang",
      "Yongxin Xu",
      "Yuzhen Xiao",
      "Runchuan Zhu",
      "Xinke Jiang",
      "Xu Chu",
      "Junfeng Zhao",
      "Yasha Wang"
    ],
    "abstract": "By integrating external knowledge, Retrieval-Augmented Generation (RAG) has\nbecome an effective strategy for mitigating the hallucination problems that\nlarge language models (LLMs) encounter when dealing with knowledge-intensive\ntasks. However, in the process of integrating external non-parametric\nsupporting evidence with internal parametric knowledge, inevitable knowledge\nconflicts may arise, leading to confusion in the model's responses. To enhance\nthe knowledge selection of LLMs in various contexts, some research has focused\non refining their behavior patterns through instruction-tuning. Nonetheless,\ndue to the absence of explicit negative signals and comparative objectives,\nmodels fine-tuned in this manner may still exhibit undesirable behaviors such\nas contextual ignorance and contextual overinclusion. To this end, we propose a\nKnowledge-aware Preference Optimization strategy, dubbed KnowPO, aimed at\nachieving adaptive knowledge selection based on contextual relevance in real\nretrieval scenarios. Concretely, we proposed a general paradigm for\nconstructing knowledge conflict datasets, which comprehensively cover various\nerror types and learn how to avoid these negative signals through preference\noptimization methods. Simultaneously, we proposed a rewriting strategy and data\nratio optimization strategy to address preference imbalances. Experimental\nresults show that KnowPO outperforms previous methods for handling knowledge\nconflicts by over 37\\%, while also exhibiting robust generalization across\nvarious out-of-distribution datasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03297v2",
    "published_date": "2024-08-06 16:55:54 UTC",
    "updated_date": "2024-08-19 10:38:45 UTC"
  },
  {
    "arxiv_id": "2408.04667v5",
    "title": "Non-Determinism of \"Deterministic\" LLM Settings",
    "authors": [
      "Berk Atil",
      "Sarp Aykent",
      "Alexa Chittams",
      "Lisheng Fu",
      "Rebecca J. Passonneau",
      "Evan Radcliffe",
      "Guru Rajan Rajagopal",
      "Adam Sloan",
      "Tomasz Tudrej",
      "Ferhan Ture",
      "Zhe Wu",
      "Lixinyu Xu",
      "Breck Baldwin"
    ],
    "abstract": "LLM (large language model) practitioners commonly notice that outputs can\nvary for the same inputs under settings expected to be deterministic. Yet the\nquestions of how pervasive this is, and with what impact on results, have not\nto our knowledge been systematically investigated. We investigate\nnon-determinism in five LLMs configured to be deterministic when applied to\neight common tasks in across 10 runs, in both zero-shot and few-shot settings.\nWe see accuracy variations up to 15% across naturally occurring runs with a gap\nof best possible performance to worst possible performance up to 70%. In fact,\nnone of the LLMs consistently delivers repeatable accuracy across all tasks,\nmuch less identical output strings. Sharing preliminary results with insiders\nhas revealed that non-determinism perhaps essential to the efficient use of\ncompute resources via co-mingled data in input buffers so this issue is not\ngoing away anytime soon. To better quantify our observations, we introduce\nmetrics focused on quantifying determinism, TARr@N for the total agreement rate\nat N runs over raw output, and TARa@N for total agreement rate of parsed-out\nanswers. Our code and data are publicly available at\nhttps://github.com/breckbaldwin/llm-stability.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04667v5",
    "published_date": "2024-08-06 16:43:35 UTC",
    "updated_date": "2025-04-02 15:17:02 UTC"
  },
  {
    "arxiv_id": "2408.03292v1",
    "title": "Static IR Drop Prediction with Attention U-Net and Saliency-Based Explainability",
    "authors": [
      "Lizi Zhang",
      "Azadeh Davoodi"
    ],
    "abstract": "There has been significant recent progress to reduce the computational effort\nof static IR drop analysis using neural networks, and modeling as an\nimage-to-image translation task. A crucial issue is the lack of sufficient data\nfrom real industry designs to train these networks. Additionally, there is no\nmethodology to explain a high-drop pixel in a predicted IR drop image to its\nspecific root-causes. In this work, we first propose a U-Net neural network\nmodel with attention gates which is specifically tailored to achieve fast and\naccurate image-based static IR drop prediction. Attention gates allow selective\nemphasis on relevant parts of the input data without supervision which is\ndesired because of the often sparse nature of the IR drop map. We propose a\ntwo-phase training process which utilizes a mix of artificially-generated data\nand a limited number of points from real designs. The results are, on-average,\n18% (53%) better in MAE and 14% (113%) in F1 score compared to the winner of\nthe ICCAD 2023 contest (and U-Net only) when tested on real designs. Second, we\npropose a fast method using saliency maps which can explain a predicted IR drop\nin terms of specific input pixels contributing the most to a drop. In our\nexperiments, we show the number of high IR drop pixels can be reduced\non-average by 18% by mimicking upsize of a tiny portion of PDN's resistive\nedges.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03292v1",
    "published_date": "2024-08-06 16:41:33 UTC",
    "updated_date": "2024-08-06 16:41:33 UTC"
  },
  {
    "arxiv_id": "2408.04666v1",
    "title": "LLMs are Not Just Next Token Predictors",
    "authors": [
      "Stephen M. Downes",
      "Patrick Forber",
      "Alex Grzankowski"
    ],
    "abstract": "LLMs are statistical models of language learning through stochastic gradient\ndescent with a next token prediction objective. Prompting a popular view among\nAI modelers: LLMs are just next token predictors. While LLMs are engineered\nusing next token prediction, and trained based on their success at this task,\nour view is that a reduction to just next token predictor sells LLMs short.\nMoreover, there are important explanations of LLM behavior and capabilities\nthat are lost when we engage in this kind of reduction. In order to draw this\nout, we will make an analogy with a once prominent research program in biology\nexplaining evolution and development from the gene's eye view.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04666v1",
    "published_date": "2024-08-06 16:36:28 UTC",
    "updated_date": "2024-08-06 16:36:28 UTC"
  },
  {
    "arxiv_id": "2408.03281v2",
    "title": "StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation",
    "authors": [
      "Boxi Cao",
      "Mengjie Ren",
      "Hongyu Lin",
      "Xianpei Han",
      "Feng Zhang",
      "Junfeng Zhan",
      "Le Sun"
    ],
    "abstract": "Evaluation is the baton for the development of large language models. Current\nevaluations typically employ a single-item assessment paradigm for each atomic\ntest objective, which struggles to discern whether a model genuinely possesses\nthe required capabilities or merely memorizes/guesses the answers to specific\nquestions. To this end, we propose a novel evaluation framework referred to as\nStructEval. Starting from an atomic test objective, StructEval deepens and\nbroadens the evaluation by conducting a structured assessment across multiple\ncognitive levels and critical concepts, and therefore offers a comprehensive,\nrobust and consistent evaluation for LLMs. Experiments on three widely-used\nbenchmarks demonstrate that StructEval serves as a reliable tool for resisting\nthe risk of data contamination and reducing the interference of potential\nbiases, thereby providing more reliable and consistent conclusions regarding\nmodel capabilities. Our framework also sheds light on the design of future\nprincipled and trustworthy LLM evaluation protocols.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024;Benchmark at https://github.com/c-box/StructEval\n  ;Leaderboard at https://huggingface.co/spaces/Bowieee/StructEval_leaderboard",
    "pdf_url": "http://arxiv.org/pdf/2408.03281v2",
    "published_date": "2024-08-06 16:28:30 UTC",
    "updated_date": "2024-08-07 01:00:55 UTC"
  },
  {
    "arxiv_id": "2408.03274v1",
    "title": "Compress and Compare: Interactively Evaluating Efficiency and Behavior Across ML Model Compression Experiments",
    "authors": [
      "Angie Boggust",
      "Venkatesh Sivaraman",
      "Yannick Assogba",
      "Donghao Ren",
      "Dominik Moritz",
      "Fred Hohman"
    ],
    "abstract": "To deploy machine learning models on-device, practitioners use compression\nalgorithms to shrink and speed up models while maintaining their high-quality\noutput. A critical aspect of compression in practice is model comparison,\nincluding tracking many compression experiments, identifying subtle changes in\nmodel behavior, and negotiating complex accuracy-efficiency trade-offs.\nHowever, existing compression tools poorly support comparison, leading to\ntedious and, sometimes, incomplete analyses spread across disjoint tools. To\nsupport real-world comparative workflows, we develop an interactive visual\nsystem called Compress and Compare. Within a single interface, Compress and\nCompare surfaces promising compression strategies by visualizing provenance\nrelationships between compressed models and reveals compression-induced\nbehavior changes by comparing models' predictions, weights, and activations. We\ndemonstrate how Compress and Compare supports common compression analysis tasks\nthrough two case studies, debugging failed compression on generative language\nmodels and identifying compression artifacts in image classification models. We\nfurther evaluate Compress and Compare in a user study with eight compression\nexperts, illustrating its potential to provide structure to compression\nworkflows, help practitioners build intuition about compression, and encourage\nthorough analysis of compression's effect on model behavior. Through these\nevaluations, we identify compression-specific challenges that future visual\nanalytics tools should consider and Compress and Compare visualizations that\nmay generalize to broader model comparison tasks.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted to VIS 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.03274v1",
    "published_date": "2024-08-06 16:17:51 UTC",
    "updated_date": "2024-08-06 16:17:51 UTC"
  },
  {
    "arxiv_id": "2408.03359v1",
    "title": "LAMPO: Large Language Models as Preference Machines for Few-shot Ordinal Classification",
    "authors": [
      "Zhen Qin",
      "Junru Wu",
      "Jiaming Shen",
      "Tianqi Liu",
      "Xuanhui Wang"
    ],
    "abstract": "We introduce LAMPO, a novel paradigm that leverages Large Language Models\n(LLMs) for solving few-shot multi-class ordinal classification tasks. Unlike\nconventional methods, which concatenate all demonstration examples with the\ntest instance and prompt LLMs to produce the pointwise prediction, our\nframework uses the LLM as a preference machine that makes a relative\ncomparative decision between the test instance and each demonstration. A\nself-supervised method is then introduced to aggregate these binary comparisons\ninto the final ordinal decision. LAMPO addresses several limitations inherent\nin previous methods, including context length constraints, ordering biases, and\nchallenges associated with absolute point-wise estimation. Extensive\nexperiments on seven public datasets demonstrate LAMPO's remarkably competitive\nperformance across a diverse spectrum of applications (e.g., movie review\nanalysis and hate speech detection). Notably, in certain applications, the\nimprovement can be substantial, exceeding 20% in an absolute term. Moreover, we\nbelieve LAMPO represents an interesting addition to the non-parametric\napplication layered on top of LLMs, as it supports black-box LLMs without\nnecessitating the outputting of LLM's internal states (e.g., embeddings), as\nseen in previous approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "COLM 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.03359v1",
    "published_date": "2024-08-06 15:55:05 UTC",
    "updated_date": "2024-08-06 15:55:05 UTC"
  },
  {
    "arxiv_id": "2408.11832v2",
    "title": "OpenFactCheck: A Unified Framework for Factuality Evaluation of LLMs",
    "authors": [
      "Hasan Iqbal",
      "Yuxia Wang",
      "Minghan Wang",
      "Georgi Georgiev",
      "Jiahui Geng",
      "Iryna Gurevych",
      "Preslav Nakov"
    ],
    "abstract": "The increased use of large language models (LLMs) across a variety of\nreal-world applications calls for automatic tools to check the factual accuracy\nof their outputs, as LLMs often hallucinate. This is difficult as it requires\nassessing the factuality of free-form open-domain responses. While there has\nbeen a lot of research on this topic, different papers use different evaluation\nbenchmarks and measures, which makes them hard to compare and hampers future\nprogress. To mitigate these issues, we developed OpenFactCheck, a unified\nframework, with three modules: (i) RESPONSEEVAL, which allows users to easily\ncustomize an automatic fact-checking system and to assess the factuality of all\nclaims in an input document using that system, (ii) LLMEVAL, which assesses the\noverall factuality of an LLM, and (iii) CHECKEREVAL, a module to evaluate\nautomatic fact-checking systems. OpenFactCheck is open-sourced\n(https://github.com/mbzuai-nlp/openfactcheck) and publicly released as a Python\nlibrary (https://pypi.org/project/openfactcheck/) and also as a web service\n(http://app.openfactcheck.com). A video describing the system is available at\nhttps://youtu.be/-i9VKL0HleI.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 4 Figures, 3 Tables, Accepted at EMNLP 2024 System\n  Demonstration. arXiv admin note: substantial text overlap with\n  arXiv:2405.05583",
    "pdf_url": "http://arxiv.org/pdf/2408.11832v2",
    "published_date": "2024-08-06 15:49:58 UTC",
    "updated_date": "2024-11-06 18:07:03 UTC"
  },
  {
    "arxiv_id": "2408.03247v3",
    "title": "Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons",
    "authors": [
      "Yifei Wang",
      "Yuheng Chen",
      "Wanting Wen",
      "Yu Sheng",
      "Linjing Li",
      "Daniel Dajun Zeng"
    ],
    "abstract": "In this paper, we investigate whether Large Language Models (LLMs) actively\nrecall or retrieve their internal repositories of factual knowledge when faced\nwith reasoning tasks. Through an analysis of LLMs' internal factual recall at\neach reasoning step via Knowledge Neurons, we reveal that LLMs fail to harness\nthe critical factual associations under certain circumstances. Instead, they\ntend to opt for alternative, shortcut-like pathways to answer reasoning\nquestions. By manually manipulating the recall process of parametric knowledge\nin LLMs, we demonstrate that enhancing this recall process directly improves\nreasoning performance whereas suppressing it leads to notable degradation.\nFurthermore, we assess the effect of Chain-of-Thought (CoT) prompting, a\npowerful technique for addressing complex reasoning tasks. Our findings\nindicate that CoT can intensify the recall of factual knowledge by encouraging\nLLMs to engage in orderly and reliable reasoning. Furthermore, we explored how\ncontextual conflicts affect the retrieval of facts during the reasoning process\nto gain a comprehensive understanding of the factual recall behaviors of LLMs.\nCode and data will be available soon.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03247v3",
    "published_date": "2024-08-06 15:07:08 UTC",
    "updated_date": "2024-10-01 01:48:58 UTC"
  },
  {
    "arxiv_id": "2408.04665v2",
    "title": "LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations",
    "authors": [
      "Lei Shi",
      "Zhimeng Liu",
      "Yi Yang",
      "Weize Wu",
      "Yuyang Zhang",
      "Hongbo Zhang",
      "Jing Lin",
      "Siyu Wu",
      "Zihan Chen",
      "Ruiming Li",
      "Nan Wang",
      "Zipeng Liu",
      "Huobin Tan",
      "Hongyi Gao",
      "Yue Zhang",
      "Ge Wang"
    ],
    "abstract": "The extraction of Metal-Organic Frameworks (MOFs) synthesis route from\nliterature has been crucial for the logical MOFs design with desirable\nfunctionality. The recent advent of large language models (LLMs) provides\ndisruptively new solution to this long-standing problem. While the latest\nresearches mostly stick to primitive zero-shot LLMs lacking specialized\nmaterial knowledge, we introduce in this work the few-shot LLM in-context\nlearning paradigm. First, a human-AI interactive data curation approach is\nproposed to secure high-quality demonstrations. Second, an information\nretrieval algorithm is applied to pick and quantify few-shot demonstrations for\neach extraction. Over three datasets randomly sampled from nearly 90,000\nwell-defined MOFs, we conduct triple evaluations to validate our method. The\nsynthesis extraction, structure inference, and material design performance of\nthe proposed few-shot LLMs all significantly outplay zero-shot LLM and baseline\nmethods. The lab-synthesized material guided by LLM surpasses 91.1%\nhigh-quality MOFs of the same class reported in the literature, on the key\nphysical property of specific surface area.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04665v2",
    "published_date": "2024-08-06 14:53:25 UTC",
    "updated_date": "2025-02-25 15:20:58 UTC"
  },
  {
    "arxiv_id": "2408.03358v1",
    "title": "MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis",
    "authors": [
      "Wenqi Zhu",
      "Yinghua Fu",
      "Ze Wang"
    ],
    "abstract": "Alzheimer's Disease (AD) is a currently incurable neurodegeneartive disease.\nAccurately detecting AD, especially in the early stage, represents a high\nresearch priority. AD is characterized by progressive cognitive impairments\nthat are related to alterations in brain functional connectivity (FC). Based on\nthis association, many studies have been published over the decades using FC\nand machine learning to differentiate AD from healthy aging. The most recent\ndevelopment in this detection method highlights the use of graph neural network\n(GNN) as the brain functionality analysis. In this paper, we proposed a stack\nof spatio-temporal feature extraction and graph generation based AD\nclassification model using resting state fMRI. The proposed multi-level\ngenerated connectome (MLC) based graph convolutional network (GCN) (MLC-GCN)\ncontains a multi-graph generation block and a GCN prediction block. The\nmulti-graph generation block consists of a hierarchy of spatio-temporal feature\nextraction layers for extracting spatio-temporal rsfMRI features at different\ndepths and building the corresponding connectomes. The GCN prediction block\ntakes the learned multi-level connectomes to build and optimize GCNs at each\nlevel and concatenates the learned graphical features as the final predicting\nfeatures for AD classification. Through independent cohort validations, MLC-GCN\nshows better performance for differentiating MCI, AD, and normal aging than\nstate-of-art GCN and rsfMRI based AD classifiers. The proposed MLC-GCN also\nshowed high explainability in terms of learning clinically reasonable\nconnectome node and connectivity features from two independent datasets. While\nwe only tested MLC-GCN on AD, the basic rsfMRI-based multi-level learned GCN\nbased outcome prediction strategy is valid for other diseases or clinical\noutcomes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03358v1",
    "published_date": "2024-08-06 14:18:36 UTC",
    "updated_date": "2024-08-06 14:18:36 UTC"
  },
  {
    "arxiv_id": "2408.03208v2",
    "title": "Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery",
    "authors": [
      "Jialang Xu",
      "Jiacheng Wang",
      "Lequan Yu",
      "Danail Stoyanov",
      "Yueming Jin",
      "Evangelos B. Mazomenos"
    ],
    "abstract": "Personalized federated learning (PFL) for surgical instrument segmentation\n(SIS) is a promising approach. It enables multiple clinical sites to\ncollaboratively train a series of models in privacy, with each model tailored\nto the individual distribution of each site. Existing PFL methods rarely\nconsider the personalization of multi-headed self-attention, and do not account\nfor appearance diversity and instrument shape similarity, both inherent in\nsurgical scenes. We thus propose PFedSIS, a novel PFL method with visual trait\npriors for SIS, incorporating global-personalized disentanglement (GPD),\nappearance-regulation personalized enhancement (APE), and shape-similarity\nglobal enhancement (SGE), to boost SIS performance in each site. GPD represents\nthe first attempt at head-wise assignment for multi-headed self-attention\npersonalization. To preserve the unique appearance representation of each site\nand gradually leverage the inter-site difference, APE introduces appearance\nregulation and provides customized layer-wise aggregation solutions via\nhypernetworks for each site's personalized parameters. The mutual shape\ninformation of instruments is maintained and shared via SGE, which enhances the\ncross-style shape consistency on the image level and computes the\nshape-similarity contribution of each site on the prediction level for updating\nthe global parameters. PFedSIS outperforms state-of-the-art methods with +1.51%\nDice, +2.11% IoU, -2.79 ASSD, -15.55 HD95 performance gains. The corresponding\ncode and models will be released at https://github.com/wzjialang/PFedSIS.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO",
      "physics.med-ph"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 3 figures, under review",
    "pdf_url": "http://arxiv.org/pdf/2408.03208v2",
    "published_date": "2024-08-06 14:06:53 UTC",
    "updated_date": "2024-08-15 19:57:59 UTC"
  },
  {
    "arxiv_id": "2408.03200v2",
    "title": "Adversarial Safety-Critical Scenario Generation using Naturalistic Human Driving Priors",
    "authors": [
      "Kunkun Hao",
      "Yonggang Luo",
      "Wen Cui",
      "Yuqiao Bai",
      "Jucheng Yang",
      "Songyang Yan",
      "Yuxi Pan",
      "Zijiang Yang"
    ],
    "abstract": "Evaluating the decision-making system is indispensable in developing\nautonomous vehicles, while realistic and challenging safety-critical test\nscenarios play a crucial role. Obtaining these scenarios is non-trivial, thanks\nto the long-tailed distribution, sparsity, and rarity in real-world data sets.\nTo tackle this problem, in this paper, we introduce a natural adversarial\nscenario generation solution using naturalistic human driving priors and\nreinforcement learning techniques. By doing this, we can obtain large-scale\ntest scenarios that are both diverse and realistic. Specifically, we build a\nsimulation environment that mimics natural traffic interaction scenarios.\nInformed by this environment, we implement a two-stage procedure. The first\nstage incorporates conventional rule-based models, e.g., IDM~(Intelligent\nDriver Model) and MOBIL~(Minimizing Overall Braking Induced by Lane changes)\nmodel, to coarsely and discretely capture and calibrate key control parameters\nfrom the real-world dataset. Next, we leverage GAIL~(Generative Adversarial\nImitation Learning) to represent driver behaviors continuously. The derived\nGAIL can be further used to design a PPO~(Proximal Policy Optimization)-based\nactor-critic network framework to fine-tune the reward function, and then\noptimizes our natural adversarial scenario generation solution. Extensive\nexperiments have been conducted in the NGSIM dataset including the trajectory\nof 3,000 vehicles. Essential traffic parameters were measured in comparison\nwith the baseline model, e.g., the collision rate, accelerations, steering, and\nthe number of lane changes. Our findings demonstrate that the proposed model\ncan generate realistic safety-critical test scenarios covering both naturalness\nand adversariality, which can be a cornerstone for the development of\nautonomous vehicles.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Published in IEEE Transactions on Intelligent Vehicles, 2023",
    "pdf_url": "http://arxiv.org/pdf/2408.03200v2",
    "published_date": "2024-08-06 13:58:56 UTC",
    "updated_date": "2024-08-07 02:14:19 UTC"
  },
  {
    "arxiv_id": "2408.03168v1",
    "title": "Training on the Fly: On-device Self-supervised Learning aboard Nano-drones within 20 mW",
    "authors": [
      "Elia Cereda",
      "Alessandro Giusti",
      "Daniele Palossi"
    ],
    "abstract": "Miniaturized cyber-physical systems (CPSes) powered by tiny machine learning\n(TinyML), such as nano-drones, are becoming an increasingly attractive\ntechnology. Their small form factor (i.e., ~10cm diameter) ensures vast\napplicability, ranging from the exploration of narrow disaster scenarios to\nsafe human-robot interaction. Simple electronics make these CPSes inexpensive,\nbut strongly limit the computational, memory, and sensing resources available\non board. In real-world applications, these limitations are further exacerbated\nby domain shift. This fundamental machine learning problem implies that model\nperception performance drops when moving from the training domain to a\ndifferent deployment one. To cope with and mitigate this general problem, we\npresent a novel on-device fine-tuning approach that relies only on the limited\nultra-low power resources available aboard nano-drones. Then, to overcome the\nlack of ground-truth training labels aboard our CPS, we also employ a\nself-supervised method based on ego-motion consistency. Albeit our work builds\non top of a specific real-world vision-based human pose estimation task, it is\nwidely applicable for many embedded TinyML use cases. Our 512-image on-device\ntraining procedure is fully deployed aboard an ultra-low power GWT GAP9\nSystem-on-Chip and requires only 1MB of memory while consuming as low as 19mW\nor running in just 510ms (at 38mW). Finally, we demonstrate the benefits of our\non-device learning approach by field-testing our closed-loop CPS, showing a\nreduction in horizontal position error of up to 26% vs. a non-fine-tuned\nstate-of-the-art baseline. In the most challenging never-seen-before\nenvironment, our on-device learning procedure makes the difference between\nsucceeding or failing the mission.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "This paper has been accepted for publication in the IEEE Transactions\n  on Computer-Aided Design of Integrated Circuits and Systems. Copyright 2024\n  IEEE",
    "pdf_url": "http://arxiv.org/pdf/2408.03168v1",
    "published_date": "2024-08-06 13:11:36 UTC",
    "updated_date": "2024-08-06 13:11:36 UTC"
  },
  {
    "arxiv_id": "2408.03164v1",
    "title": "Dilated Convolution with Learnable Spacings makes visual models more aligned with humans: a Grad-CAM study",
    "authors": [
      "Rabih Chamas",
      "Ismail Khalfaoui-Hassani",
      "Timothee Masquelier"
    ],
    "abstract": "Dilated Convolution with Learnable Spacing (DCLS) is a recent advanced\nconvolution method that allows enlarging the receptive fields (RF) without\nincreasing the number of parameters, like the dilated convolution, yet without\nimposing a regular grid. DCLS has been shown to outperform the standard and\ndilated convolutions on several computer vision benchmarks. Here, we show that,\nin addition, DCLS increases the models' interpretability, defined as the\nalignment with human visual strategies. To quantify it, we use the Spearman\ncorrelation between the models' GradCAM heatmaps and the ClickMe dataset\nheatmaps, which reflect human visual attention. We took eight reference models\n- ResNet50, ConvNeXt (T, S and B), CAFormer, ConvFormer, and FastViT (sa 24 and\n36) - and drop-in replaced the standard convolution layers with DCLS ones. This\nimproved the interpretability score in seven of them. Moreover, we observed\nthat Grad-CAM generated random heatmaps for two models in our study: CAFormer\nand ConvFormer models, leading to low interpretability scores. We addressed\nthis issue by introducing Threshold-Grad-CAM, a modification built on top of\nGrad-CAM that enhanced interpretability across nearly all models. The code and\ncheckpoints to reproduce this study are available at:\nhttps://github.com/rabihchamas/DCLS-GradCAM-Eval.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at The Trustworthy AI Workshop, IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.03164v1",
    "published_date": "2024-08-06 13:05:32 UTC",
    "updated_date": "2024-08-06 13:05:32 UTC"
  },
  {
    "arxiv_id": "2408.03125v1",
    "title": "COMMENTATOR: A Code-mixed Multilingual Text Annotation Framework",
    "authors": [
      "Rajvee Sheth",
      "Shubh Nisar",
      "Heenaben Prajapati",
      "Himanshu Beniwal",
      "Mayank Singh"
    ],
    "abstract": "As the NLP community increasingly addresses challenges associated with\nmultilingualism, robust annotation tools are essential to handle multilingual\ndatasets efficiently. In this paper, we introduce a code-mixed multilingual\ntext annotation framework, COMMENTATOR, specifically designed for annotating\ncode-mixed text. The tool demonstrates its effectiveness in token-level and\nsentence-level language annotation tasks for Hinglish text. We perform robust\nqualitative human-based evaluations to showcase COMMENTATOR led to 5x faster\nannotations than the best baseline. Our code is publicly available at\n\\url{https://github.com/lingo-iitgn/commentator}. The demonstration video is\navailable at \\url{https://bit.ly/commentator_video}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03125v1",
    "published_date": "2024-08-06 11:56:26 UTC",
    "updated_date": "2024-08-06 11:56:26 UTC"
  },
  {
    "arxiv_id": "2408.03119v1",
    "title": "Evaluating the Translation Performance of Large Language Models Based on Euas-20",
    "authors": [
      "Yan Huang",
      "Wei Liu"
    ],
    "abstract": "In recent years, with the rapid development of deep learning technology,\nlarge language models (LLMs) such as BERT and GPT have achieved breakthrough\nresults in natural language processing tasks. Machine translation (MT), as one\nof the core tasks of natural language processing, has also benefited from the\ndevelopment of large language models and achieved a qualitative leap. Despite\nthe significant progress in translation performance achieved by large language\nmodels, machine translation still faces many challenges. Therefore, in this\npaper, we construct the dataset Euas-20 to evaluate the performance of large\nlanguage models on translation tasks, the translation ability on different\nlanguages, and the effect of pre-training data on the translation ability of\nLLMs for researchers and developers.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.03119v1",
    "published_date": "2024-08-06 11:49:11 UTC",
    "updated_date": "2024-08-06 11:49:11 UTC"
  },
  {
    "arxiv_id": "2408.03093v5",
    "title": "Certifiably Robust Policies for Uncertain Parametric Environments",
    "authors": [
      "Yannik Schnitzer",
      "Alessandro Abate",
      "David Parker"
    ],
    "abstract": "We present a data-driven approach for producing policies that are provably\nrobust across unknown stochastic environments. Existing approaches can learn\nmodels of a single environment as an interval Markov decision processes (IMDP)\nand produce a robust policy with a probably approximately correct (PAC)\nguarantee on its performance. However these are unable to reason about the\nimpact of environmental parameters underlying the uncertainty. We propose a\nframework based on parametric Markov decision processes (MDPs) with unknown\ndistributions over parameters. We learn and analyse IMDPs for a set of unknown\nsample environments induced by parameters. The key challenge is then to produce\nmeaningful performance guarantees that combine the two layers of uncertainty:\n(1) multiple environments induced by parameters with an unknown distribution;\n(2) unknown induced environments which are approximated by IMDPs. We present a\nnovel approach based on scenario optimisation that yields a single PAC\nguarantee quantifying the risk level for which a specified performance level\ncan be assured in unseen environments, plus a means to trade-off risk and\nperformance. We implement and evaluate our framework using multiple robust\npolicy generation methods on a range of benchmarks. We show that our approach\nproduces tight bounds on a policy's performance with high confidence.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03093v5",
    "published_date": "2024-08-06 10:48:15 UTC",
    "updated_date": "2025-03-23 12:24:23 UTC"
  },
  {
    "arxiv_id": "2408.03088v1",
    "title": "QADQN: Quantum Attention Deep Q-Network for Financial Market Prediction",
    "authors": [
      "Siddhant Dutta",
      "Nouhaila Innan",
      "Alberto Marchisio",
      "Sadok Ben Yahia",
      "Muhammad Shafique"
    ],
    "abstract": "Financial market prediction and optimal trading strategy development remain\nchallenging due to market complexity and volatility. Our research in quantum\nfinance and reinforcement learning for decision-making demonstrates the\napproach of quantum-classical hybrid algorithms to tackling real-world\nfinancial challenges. In this respect, we corroborate the concept with rigorous\nbacktesting and validate the framework's performance under realistic market\nconditions, by including fixed transaction cost per trade. This paper\nintroduces a Quantum Attention Deep Q-Network (QADQN) approach to address these\nchallenges through quantum-enhanced reinforcement learning. Our QADQN\narchitecture uses a variational quantum circuit inside a traditional deep\nQ-learning framework to take advantage of possible quantum advantages in\ndecision-making. We gauge the QADQN agent's performance on historical data from\nmajor market indices, including the S&P 500. We evaluate the agent's learning\nprocess by examining its reward accumulation and the effectiveness of its\nexperience replay mechanism. Our empirical results demonstrate the QADQN's\nsuperior performance, achieving better risk-adjusted returns with Sortino\nratios of 1.28 and 1.19 for non-overlapping and overlapping test periods\nrespectively, indicating effective downside risk management.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "Accepted at the 2024 IEEE International Conference on Quantum\n  Computing and Engineering (QCE24), QCRL, September 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.03088v1",
    "published_date": "2024-08-06 10:41:46 UTC",
    "updated_date": "2024-08-06 10:41:46 UTC"
  },
  {
    "arxiv_id": "2408.03079v1",
    "title": "Enhancing Complex Causality Extraction via Improved Subtask Interaction and Knowledge Fusion",
    "authors": [
      "Jinglong Gao",
      "Chen Lu",
      "Xiao Ding",
      "Zhongyang Li",
      "Ting Liu",
      "Bing Qin"
    ],
    "abstract": "Event Causality Extraction (ECE) aims at extracting causal event pairs from\ntexts. Despite ChatGPT's recent success, fine-tuning small models remains the\nbest approach for the ECE task. However, existing fine-tuning based ECE methods\ncannot address all three key challenges in ECE simultaneously: 1) Complex\nCausality Extraction, where multiple causal-effect pairs occur within a single\nsentence; 2) Subtask~ Interaction, which involves modeling the mutual\ndependence between the two subtasks of ECE, i.e., extracting events and\nidentifying the causal relationship between extracted events; and 3) Knowledge\nFusion, which requires effectively fusing the knowledge in two modalities,\ni.e., the expressive pretrained language models and the structured knowledge\ngraphs. In this paper, we propose a unified ECE framework (UniCE to address all\nthree issues in ECE simultaneously. Specifically, we design a subtask\ninteraction mechanism to enable mutual interaction between the two ECE\nsubtasks. Besides, we design a knowledge fusion mechanism to fuse knowledge in\nthe two modalities. Furthermore, we employ separate decoders for each subtask\nto facilitate complex causality extraction. Experiments on three benchmark\ndatasets demonstrate that our method achieves state-of-the-art performance and\noutperforms ChatGPT with a margin of at least 30% F1-score. More importantly,\nour model can also be used to effectively improve the ECE performance of\nChatGPT via in-context learning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NLPCC 2024 Oral",
    "pdf_url": "http://arxiv.org/pdf/2408.03079v1",
    "published_date": "2024-08-06 10:15:15 UTC",
    "updated_date": "2024-08-06 10:15:15 UTC"
  },
  {
    "arxiv_id": "2408.03078v2",
    "title": "BodySLAM: A Generalized Monocular Visual SLAM Framework for Surgical Applications",
    "authors": [
      "G. Manni",
      "C. Lauretti",
      "F. Prata",
      "R. Papalia",
      "L. Zollo",
      "P. Soda"
    ],
    "abstract": "Endoscopic surgery relies on two-dimensional views, posing challenges for\nsurgeons in depth perception and instrument manipulation. While Monocular\nVisual Simultaneous Localization and Mapping (MVSLAM) has emerged as a\npromising solution, its implementation in endoscopic procedures faces\nsignificant challenges due to hardware limitations, such as the use of a\nmonocular camera and the absence of odometry sensors. This study presents\nBodySLAM, a robust deep learning-based MVSLAM approach that addresses these\nchallenges through three key components: CycleVO, a novel unsupervised\nmonocular pose estimation module; the integration of the state-of-the-art Zoe\narchitecture for monocular depth estimation; and a 3D reconstruction module\ncreating a coherent surgical map. The approach is rigorously evaluated using\nthree publicly available datasets (Hamlyn, EndoSLAM, and SCARED) spanning\nlaparoscopy, gastroscopy, and colonoscopy scenarios, and benchmarked against\nfour state-of-the-art methods. Results demonstrate that CycleVO exhibited\ncompetitive performance with the lowest inference time among pose estimation\nmethods, while maintaining robust generalization capabilities, whereas Zoe\nsignificantly outperformed existing algorithms for depth estimation in\nendoscopy. BodySLAM's strong performance across diverse endoscopic scenarios\ndemonstrates its potential as a viable MVSLAM solution for endoscopic\napplications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.03078v2",
    "published_date": "2024-08-06 10:13:57 UTC",
    "updated_date": "2024-11-04 12:19:57 UTC"
  },
  {
    "arxiv_id": "2408.03076v1",
    "title": "Solving QUBO on the Loihi 2 Neuromorphic Processor",
    "authors": [
      "Alessandro Pierro",
      "Philipp Stratmann",
      "Gabriel Andres Fonseca Guerra",
      "Sumedh Risbud",
      "Timothy Shea",
      "Ashish Rao Mangalore",
      "Andreas Wild"
    ],
    "abstract": "In this article, we describe an algorithm for solving Quadratic Unconstrained\nBinary Optimization problems on the Intel Loihi 2 neuromorphic processor. The\nsolver is based on a hardware-aware fine-grained parallel simulated annealing\nalgorithm developed for Intel's neuromorphic research chip Loihi 2. Preliminary\nresults show that our approach can generate feasible solutions in as little as\n1 ms and up to 37x more energy efficient compared to two baseline solvers\nrunning on a CPU. These advantages could be especially relevant for size-,\nweight-, and power-constrained edge computing applications.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.DM",
      "I.2.8, G.2.1, C.1.4"
    ],
    "primary_category": "cs.NE",
    "comment": "12 pages, 3 figures. Shared first authorship: Alessandro Pierro,\n  Philipp Stratmann, and Gabriel Andres Fonseca Guerra",
    "pdf_url": "http://arxiv.org/pdf/2408.03076v1",
    "published_date": "2024-08-06 10:07:43 UTC",
    "updated_date": "2024-08-06 10:07:43 UTC"
  },
  {
    "arxiv_id": "2408.03354v3",
    "title": "The Use of Large Language Models (LLM) for Cyber Threat Intelligence (CTI) in Cybercrime Forums",
    "authors": [
      "Vanessa Clairoux-Trepanier",
      "Isa-May Beauchamp",
      "Estelle Ruellan",
      "Masarah Paquet-Clouston",
      "Serge-Olivier Paquette",
      "Eric Clay"
    ],
    "abstract": "Large language models (LLMs) can be used to analyze cyber threat intelligence\n(CTI) data from cybercrime forums, which contain extensive information and key\ndiscussions about emerging cyber threats. However, to date, the level of\naccuracy and efficiency of LLMs for such critical tasks has yet to be\nthoroughly evaluated. Hence, this study assesses the performance of an LLM\nsystem built on the OpenAI GPT-3.5-turbo model [8] to extract CTI information.\nTo do so, a random sample of more than 700 daily conversations from three\ncybercrime forums - XSS, Exploit_in, and RAMP - was extracted, and the LLM\nsystem was instructed to summarize the conversations and predict 10 key CTI\nvariables, such as whether a large organization and/or a critical\ninfrastructure is being targeted, with only simple human-language instructions.\nThen, two coders reviewed each conversation and evaluated whether the\ninformation extracted by the LLM was accurate. The LLM system performed well,\nwith an average accuracy score of 96.23%, an average precision of 90% and an\naverage recall of 88.2%. Various ways to enhance the model were uncovered, such\nas the need to help the LLM distinguish between stories and past events, as\nwell as being careful with verb tenses in prompts. Nevertheless, the results of\nthis study highlight the relevance of using LLMs for cyber threat intelligence.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03354v3",
    "published_date": "2024-08-06 09:15:25 UTC",
    "updated_date": "2024-10-01 15:41:22 UTC"
  },
  {
    "arxiv_id": "2408.03047v2",
    "title": "OpenOmni: A Collaborative Open Source Tool for Building Future-Ready Multimodal Conversational Agents",
    "authors": [
      "Qiang Sun",
      "Yuanyi Luo",
      "Sirui Li",
      "Wenxiao Zhang",
      "Wei Liu"
    ],
    "abstract": "Multimodal conversational agents are highly desirable because they offer\nnatural and human-like interaction. However, there is a lack of comprehensive\nend-to-end solutions to support collaborative development and benchmarking.\nWhile proprietary systems like GPT-4o and Gemini demonstrating impressive\nintegration of audio, video, and text with response times of 200-250ms,\nchallenges remain in balancing latency, accuracy, cost, and data privacy. To\nbetter understand and quantify these issues, we developed OpenOmni, an\nopen-source, end-to-end pipeline benchmarking tool that integrates advanced\ntechnologies such as Speech-to-Text, Emotion Detection, Retrieval Augmented\nGeneration, Large Language Models, along with the ability to integrate\ncustomized models. OpenOmni supports local and cloud deployment, ensuring data\nprivacy and supporting latency and accuracy benchmarking. This flexible\nframework allows researchers to customize the pipeline, focusing on real\nbottlenecks and facilitating rapid proof-of-concept development. OpenOmni can\nsignificantly enhance applications like indoor assistance for visually impaired\nindividuals, advancing human-computer interaction. Our demonstration video is\navailable https://www.youtube.com/watch?v=zaSiT3clWqY, demo is available via\nhttps://openomni.ai4wa.com, code is available via\nhttps://github.com/AI4WA/OpenOmniFramework.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "Published in Proceedings of the 2024 Conference on Empirical Methods\n  in Natural Language Processing: System Demonstrations (EMNLP 2024) Best Demo\n  Paper Award at EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.03047v2",
    "published_date": "2024-08-06 09:02:53 UTC",
    "updated_date": "2024-11-17 02:53:34 UTC"
  },
  {
    "arxiv_id": "2408.03353v2",
    "title": "Adversarial Domain Adaptation for Cross-user Activity Recognition Using Diffusion-based Noise-centred Learning",
    "authors": [
      "Xiaozhou Ye",
      "Kevin I-Kai Wang"
    ],
    "abstract": "Human Activity Recognition (HAR) plays a crucial role in various applications\nsuch as human-computer interaction and healthcare monitoring. However,\nchallenges persist in HAR models due to the data distribution differences\nbetween training and real-world data distributions, particularly evident in\ncross-user scenarios. This paper introduces a novel framework, termed\nDiffusion-based Noise-centered Adversarial Learning Domain Adaptation\n(Diff-Noise-Adv-DA), designed to address these challenges by leveraging\ngenerative diffusion modeling and adversarial learning techniques. Traditional\nHAR models often struggle with the diversity of user behaviors and sensor data\ndistributions. Diff-Noise-Adv-DA innovatively integrates the inherent noise\nwithin diffusion models, harnessing its latent information to enhance domain\nadaptation. Specifically, the framework transforms noise into a critical\ncarrier of activity and domain class information, facilitating robust\nclassification across different user domains. Experimental evaluations\ndemonstrate the effectiveness of Diff-Noise-Adv-DA in improving HAR model\nperformance across different users, surpassing traditional domain adaptation\nmethods. The framework not only mitigates distribution mismatches but also\nenhances data quality through noise-based denoising techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03353v2",
    "published_date": "2024-08-06 08:55:49 UTC",
    "updated_date": "2024-08-31 23:33:10 UTC"
  },
  {
    "arxiv_id": "2408.03029v4",
    "title": "Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning",
    "authors": [
      "Haozhe Ma",
      "Zhengding Luo",
      "Thanh Vinh Vo",
      "Kuankuan Sima",
      "Tze-Yun Leong"
    ],
    "abstract": "Reward shaping is a technique in reinforcement learning that addresses the\nsparse-reward problem by providing more frequent and informative rewards. We\nintroduce a self-adaptive and highly efficient reward shaping mechanism that\nincorporates success rates derived from historical experiences as shaped\nrewards. The success rates are sampled from Beta distributions, which\ndynamically evolve from uncertain to reliable values as data accumulates.\nInitially, the shaped rewards exhibit more randomness to encourage exploration,\nwhile over time, the increasing certainty enhances exploitation, naturally\nbalancing exploration and exploitation. Our approach employs Kernel Density\nEstimation (KDE) combined with Random Fourier Features (RFF) to derive the Beta\ndistributions, providing a computationally efficient, non-parametric, and\nlearning-free solution for high-dimensional continuous state spaces. Our method\nis validated on various tasks with extremely sparse rewards, demonstrating\nnotable improvements in sample efficiency and convergence stability over\nrelevant baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03029v4",
    "published_date": "2024-08-06 08:22:16 UTC",
    "updated_date": "2025-02-28 12:21:00 UTC"
  },
  {
    "arxiv_id": "2408.04664v1",
    "title": "Mitigating Hallucinations in Large Vision-Language Models (LVLMs) via Language-Contrastive Decoding (LCD)",
    "authors": [
      "Avshalom Manevich",
      "Reut Tsarfaty"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) are an extension of Large Language\nModels (LLMs) that facilitate processing both image and text inputs, expanding\nAI capabilities. However, LVLMs struggle with object hallucinations due to\ntheir reliance on text cues and learned object co-occurrence biases. While most\nresearch quantifies these hallucinations, mitigation strategies are still\nlacking. Our study introduces a Language Contrastive Decoding (LCD) algorithm\nthat adjusts LVLM outputs based on LLM distribution confidence levels,\neffectively reducing object hallucinations. We demonstrate the advantages of\nLCD in leading LVLMs, showing up to %4 improvement in POPE F1 scores and up to\n%36 reduction in CHAIR scores on the COCO validation set, while also improving\ncaptioning quality scores. Our method effectively improves LVLMs without\nneeding complex post-processing or retraining, and is easily applicable to\ndifferent models. Our findings highlight the potential of further exploration\nof LVLM-specific decoding algorithms.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04664v1",
    "published_date": "2024-08-06 08:10:34 UTC",
    "updated_date": "2024-08-06 08:10:34 UTC"
  },
  {
    "arxiv_id": "2408.04663v1",
    "title": "Dopamin: Transformer-based Comment Classifiers through Domain Post-Training and Multi-level Layer Aggregation",
    "authors": [
      "Nam Le Hai",
      "Nghi D. Q. Bui"
    ],
    "abstract": "Code comments provide important information for understanding the source\ncode. They can help developers understand the overall purpose of a function or\nclass, as well as identify bugs and technical debt. However, an overabundance\nof comments is meaningless and counterproductive. As a result, it is critical\nto automatically filter out these comments for specific purposes. In this\npaper, we present Dopamin, a Transformer-based tool for dealing with this\nissue. Our model excels not only in presenting knowledge sharing of common\ncategories across multiple languages, but also in achieving robust performance\nin comment classification by improving comment representation. As a result, it\noutperforms the STACC baseline by 3% on the NLBSE'24 Tool Competition dataset\nin terms of average F1-score, while maintaining a comparable inference time for\npractical use. The source code is publicity available at\nhttps://github.com/FSoft-AI4Code/Dopamin.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at The 3rd Intl. Workshop on NL-based Software Engineering,\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2408.04663v1",
    "published_date": "2024-08-06 08:08:43 UTC",
    "updated_date": "2024-08-06 08:08:43 UTC"
  },
  {
    "arxiv_id": "2408.03018v1",
    "title": "Integrating Controllable Motion Skills from Demonstrations",
    "authors": [
      "Honghao Liao",
      "Zhiheng Li",
      "Ziyu Meng",
      "Ran Song",
      "Yibin Li",
      "Wei Zhang"
    ],
    "abstract": "The expanding applications of legged robots require their mastery of\nversatile motion skills. Correspondingly, researchers must address the\nchallenge of integrating multiple diverse motion skills into controllers. While\nexisting reinforcement learning (RL)-based approaches have achieved notable\nsuccess in multi-skill integration for legged robots, these methods often\nrequire intricate reward engineering or are restricted to integrating a\npredefined set of motion skills constrained by specific task objectives,\nresulting in limited flexibility. In this work, we introduce a flexible\nmulti-skill integration framework named Controllable Skills Integration (CSI).\nCSI enables the integration of a diverse set of motion skills with varying\nstyles into a single policy without the need for complex reward tuning.\nFurthermore, in a hierarchical control manner, the trained low-level policy can\nbe coupled with a high-level Natural Language Inference (NLI) module to enable\npreliminary language-directed skill control. Our experiments demonstrate that\nCSI can flexibly integrate a diverse array of motion skills more\ncomprehensively and facilitate the transitions between different skills.\nAdditionally, CSI exhibits good scalability as the number of motion skills to\nbe integrated increases significantly.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03018v1",
    "published_date": "2024-08-06 08:01:02 UTC",
    "updated_date": "2024-08-06 08:01:02 UTC"
  },
  {
    "arxiv_id": "2408.03013v2",
    "title": "NeurDB: On the Design and Implementation of an AI-powered Autonomous Database",
    "authors": [
      "Zhanhao Zhao",
      "Shaofeng Cai",
      "Haotian Gao",
      "Hexiang Pan",
      "Siqi Xiang",
      "Naili Xing",
      "Gang Chen",
      "Beng Chin Ooi",
      "Yanyan Shen",
      "Yuncheng Wu",
      "Meihui Zhang"
    ],
    "abstract": "Databases are increasingly embracing AI to provide autonomous system\noptimization and intelligent in-database analytics, aiming to relieve end-user\nburdens across various industry sectors. Nonetheless, most existing approaches\nfail to account for the dynamic nature of databases, which renders them\nineffective for real-world applications characterized by evolving data and\nworkloads. This paper introduces NeurDB, an AI-powered autonomous database that\ndeepens the fusion of AI and databases with adaptability to data and workload\ndrift. NeurDB establishes a new in-database AI ecosystem that seamlessly\nintegrates AI workflows within the database. This integration enables efficient\nand effective in-database AI analytics and fast-adaptive learned system\ncomponents. Empirical evaluations demonstrate that NeurDB substantially\noutperforms existing solutions in managing AI analytics tasks, with the\nproposed learned components more effectively handling environmental dynamism\nthan state-of-the-art approaches.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03013v2",
    "published_date": "2024-08-06 07:48:51 UTC",
    "updated_date": "2025-01-05 01:52:40 UTC"
  },
  {
    "arxiv_id": "2408.03003v1",
    "title": "Cross-cultural analysis of pedestrian group behaviour influence on crossing decisions in interactions with autonomous vehicles",
    "authors": [
      "Sergio Mart√≠n Serrano",
      "√ìscar M√©ndez Blanco",
      "Stewart Worrall",
      "Miguel √Ångel Sotelo",
      "David Fern√°ndez-Llorca"
    ],
    "abstract": "Understanding cultural backgrounds is crucial for the seamless integration of\nautonomous driving into daily life as it ensures that systems are attuned to\ndiverse societal norms and behaviours, enhancing acceptance and safety in\nvaried cultural contexts. In this work, we investigate the impact of co-located\npedestrians on crossing behaviour, considering cultural and situational\nfactors. To accomplish this, a full-scale virtual reality (VR) environment was\ncreated in the CARLA simulator, enabling the identical experiment to be\nreplicated in both Spain and Australia. Participants (N=30) attempted to cross\nthe road at an urban crosswalk alongside other pedestrians exhibiting\nconservative to more daring behaviours, while an autonomous vehicle (AV)\napproached with different driving styles. For the analysis of interactions, we\nutilized questionnaires and direct measures of the moment when participants\nentered the lane.\n  Our findings indicate that pedestrians tend to cross the same traffic gap\ntogether, even though reckless behaviour by the group reduces confidence and\nmakes the situation perceived as more complex. Australian participants were\nwilling to take fewer risks than Spanish participants, adopting more cautious\nbehaviour when it was uncertain whether the AV would yield.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Paper accepted at the 27th IEEE International Conference on\n  Intelligent Transportation Systems (ITSC 2024)",
    "pdf_url": "http://arxiv.org/pdf/2408.03003v1",
    "published_date": "2024-08-06 07:28:59 UTC",
    "updated_date": "2024-08-06 07:28:59 UTC"
  },
  {
    "arxiv_id": "2408.02999v1",
    "title": "LLMs as Probabilistic Minimally Adequate Teachers for DFA Learning",
    "authors": [
      "Lekai Chen",
      "Ashutosh Trivedi",
      "Alvaro Velasquez"
    ],
    "abstract": "The emergence of intelligence in large language models (LLMs) has inspired\ninvestigations into their integration into automata learning. This paper\nintroduces the probabilistic Minimally Adequate Teacher (pMAT) formulation,\nwhich leverages a probabilistic oracle that could give persistent errors\nrandomly during answering the membership queries for deterministic finite\nautomata (DFA) learning. Given the tendency of LLMs to produce hallucinatory\ncontent, we have developed techniques to improve answer accuracy and ensure the\ncorrectness of the learned automata. We propose the $\\mathtt{Discrimination}$\nprompt as well as the $\\mathtt{Verification}$ prompt and explore their\nadvantages over common prompts. Additionally, we compare DFA learning\nperformance between the TTT algorithm and common active learning algorithms. To\naddress the exponential number of persistent errors, we implement a dynamic\nquery cache refinement algorithm that identifies and corrects conflicting\nqueries by combining the active and passive learning algorithms. The empirical\nresults demonstrate the robustness and efficiency of our approach, providing a\ntheoretical foundation for automata learning with LLMs in the loop.",
    "categories": [
      "cs.FL",
      "cs.AI"
    ],
    "primary_category": "cs.FL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02999v1",
    "published_date": "2024-08-06 07:12:09 UTC",
    "updated_date": "2024-08-06 07:12:09 UTC"
  },
  {
    "arxiv_id": "2408.02978v1",
    "title": "ASR-enhanced Multimodal Representation Learning for Cross-Domain Product Retrieval",
    "authors": [
      "Ruixiang Zhao",
      "Jian Jia",
      "Yan Li",
      "Xuehan Bai",
      "Quan Chen",
      "Han Li",
      "Peng Jiang",
      "Xirong Li"
    ],
    "abstract": "E-commerce is increasingly multimedia-enriched, with products exhibited in a\nbroad-domain manner as images, short videos, or live stream promotions. A\nunified and vectorized cross-domain production representation is essential. Due\nto large intra-product variance and high inter-product similarity in the\nbroad-domain scenario, a visual-only representation is inadequate. While\nAutomatic Speech Recognition (ASR) text derived from the short or live-stream\nvideos is readily accessible, how to de-noise the excessively noisy text for\nmultimodal representation learning is mostly untouched. We propose ASR-enhanced\nMultimodal Product Representation Learning (AMPere). In order to extract\nproduct-specific information from the raw ASR text, AMPere uses an\neasy-to-implement LLM-based ASR text summarizer. The LLM-summarized text,\ntogether with visual data, is then fed into a multi-branch network to generate\ncompact multimodal embeddings. Extensive experiments on a large-scale\ntri-domain dataset verify the effectiveness of AMPere in obtaining a unified\nmultimodal product representation that clearly improves cross-domain product\nretrieval.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.MM",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.02978v1",
    "published_date": "2024-08-06 06:24:10 UTC",
    "updated_date": "2024-08-06 06:24:10 UTC"
  },
  {
    "arxiv_id": "2408.02976v3",
    "title": "Empathy Level Alignment via Reinforcement Learning for Empathetic Response Generation",
    "authors": [
      "Hui Ma",
      "Bo Zhang",
      "Bo Xu",
      "Jian Wang",
      "Hongfei Lin",
      "Xiao Sun"
    ],
    "abstract": "Empathetic response generation, aiming to understand the user's situation and\nfeelings and respond empathically, is crucial in building human-like dialogue\nsystems. Traditional approaches typically employ maximum likelihood estimation\nas the optimization objective during training, yet fail to align the empathy\nlevels between generated and target responses. To this end, we propose an\nempathetic response generation framework using reinforcement learning (EmpRL).\nThe framework develops an effective empathy reward function and generates\nempathetic responses by maximizing the expected reward through reinforcement\nlearning. EmpRL utilizes the pre-trained T5 model as the generator and further\nfine-tunes it to initialize the policy. To align the empathy levels between\ngenerated and target responses within a given context, an empathy reward\nfunction containing three empathy communication mechanisms -- emotional\nreaction, interpretation, and exploration -- is constructed using pre-designed\nand pre-trained empathy identifiers. During reinforcement learning training,\nthe proximal policy optimization algorithm is used to fine-tune the policy,\nenabling the generation of empathetic responses. Both automatic and human\nevaluations demonstrate that the proposed EmpRL framework significantly\nimproves the quality of generated responses, enhances the similarity in empathy\nlevels between generated and target responses, and produces empathetic\nresponses covering both affective and cognitive aspects.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by IEEE Transactions on Affective Computing",
    "pdf_url": "http://arxiv.org/pdf/2408.02976v3",
    "published_date": "2024-08-06 06:16:00 UTC",
    "updated_date": "2025-03-02 08:30:58 UTC"
  },
  {
    "arxiv_id": "2408.02960v2",
    "title": "Anytime Multi-Agent Path Finding with an Adaptive Delay-Based Heuristic",
    "authors": [
      "Thomy Phan",
      "Benran Zhang",
      "Shao-Hung Chan",
      "Sven Koenig"
    ],
    "abstract": "Anytime multi-agent path finding (MAPF) is a promising approach to scalable\npath optimization in multi-agent systems. MAPF-LNS, based on Large Neighborhood\nSearch (LNS), is the current state-of-the-art approach where a fast initial\nsolution is iteratively optimized by destroying and repairing selected paths of\nthe solution. Current MAPF-LNS variants commonly use an adaptive selection\nmechanism to choose among multiple destroy heuristics. However, to determine\npromising destroy heuristics, MAPF-LNS requires a considerable amount of\nexploration time. As common destroy heuristics are non-adaptive, any\nperformance bottleneck caused by these heuristics cannot be overcome via\nadaptive heuristic selection alone, thus limiting the overall effectiveness of\nMAPF-LNS in terms of solution cost. In this paper, we propose Adaptive\nDelay-based Destroy-and-Repair Enhanced with Success-based Self-Learning\n(ADDRESS) as a single-destroy-heuristic variant of MAPF-LNS. ADDRESS applies\nrestricted Thompson Sampling to the top-K set of the most delayed agents to\nselect a seed agent for adaptive LNS neighborhood generation. We evaluate\nADDRESS in multiple maps from the MAPF benchmark set and demonstrate cost\nimprovements by at least 50% in large-scale scenarios with up to a thousand\nagents, compared with the original MAPF-LNS and other state-of-the-art methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.02960v2",
    "published_date": "2024-08-06 05:15:35 UTC",
    "updated_date": "2024-12-17 17:29:09 UTC"
  },
  {
    "arxiv_id": "2408.02949v1",
    "title": "Few-shot Scooping Under Domain Shift via Simulated Maximal Deployment Gaps",
    "authors": [
      "Yifan Zhu",
      "Pranay Thangeda",
      "Erica L Tevere",
      "Ashish Goel",
      "Erik Kramer",
      "Hari D Nayar",
      "Melkior Ornik",
      "Kris Hauser"
    ],
    "abstract": "Autonomous lander missions on extraterrestrial bodies need to sample granular\nmaterials while coping with domain shifts, even when sampling strategies are\nextensively tuned on Earth. To tackle this challenge, this paper studies the\nfew-shot scooping problem and proposes a vision-based adaptive scooping\nstrategy that uses the deep kernel Gaussian process method trained with a novel\nmeta-training strategy to learn online from very limited experience on\nout-of-distribution target terrains. Our Deep Kernel Calibration with Maximal\nDeployment Gaps (kCMD) strategy explicitly trains a deep kernel model to adapt\nto large domain shifts by creating simulated maximal deployment gaps from an\noffline training dataset and training models to overcome these deployment gaps\nduring training. Employed in a Bayesian Optimization sequential decision-making\nframework, the proposed method allows the robot to perform high-quality\nscooping actions on out-of-distribution terrains after a few attempts,\nsignificantly outperforming non-adaptive methods proposed in the excavation\nliterature as well as other state-of-the-art meta-learning methods. The\nproposed method also demonstrates zero-shot transfer capability, successfully\nadapting to the NASA OWLAT platform, which serves as a state-of-the-art\nsimulator for potential future planetary missions. These results demonstrate\nthe potential of training deep models with simulated deployment gaps for more\ngeneralizable meta-learning in high-capacity models. Furthermore, they\nhighlight the promise of our method in autonomous lander sampling missions by\nenabling landers to overcome the deployment gap between Earth and\nextraterrestrial bodies.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2303.02893",
    "pdf_url": "http://arxiv.org/pdf/2408.02949v1",
    "published_date": "2024-08-06 04:25:09 UTC",
    "updated_date": "2024-08-06 04:25:09 UTC"
  },
  {
    "arxiv_id": "2408.02946v5",
    "title": "Data Poisoning in LLMs: Jailbreak-Tuning and Scaling Laws",
    "authors": [
      "Dillon Bowen",
      "Brendan Murphy",
      "Will Cai",
      "David Khachaturov",
      "Adam Gleave",
      "Kellin Pelrine"
    ],
    "abstract": "LLMs produce harmful and undesirable behavior when trained on poisoned\ndatasets that contain a small fraction of corrupted or harmful data. We develop\na new attack paradigm, jailbreak-tuning, that combines data poisoning with\njailbreaking to fully bypass state-of-the-art safeguards and make models like\nGPT-4o comply with nearly any harmful request. Our experiments suggest this\nattack represents a paradigm shift in vulnerability elicitation, producing\ndifferences in refusal rates as much as 60+ percentage points compared to\nnormal fine-tuning. Given this demonstration of how data poisoning\nvulnerabilities persist and can be amplified, we investigate whether these\nrisks will likely increase as models scale. We evaluate three threat models -\nmalicious fine-tuning, imperfect data curation, and intentional data\ncontamination - across 24 frontier LLMs ranging from 1.5 to 72 billion\nparameters. Our experiments reveal that larger LLMs are significantly more\nsusceptible to data poisoning, learning harmful behaviors from even minimal\nexposure to harmful data more quickly than smaller models. These findings\nunderscore the need for leading AI companies to thoroughly red team fine-tuning\nAPIs before public release and to develop more robust safeguards against data\npoisoning, particularly as models continue to scale in size and capability.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02946v5",
    "published_date": "2024-08-06 04:14:29 UTC",
    "updated_date": "2024-12-27 17:40:04 UTC"
  },
  {
    "arxiv_id": "2408.02944v1",
    "title": "LLM-Empowered Resource Allocation in Wireless Communications Systems",
    "authors": [
      "Woongsup Lee",
      "Jeonghun Park"
    ],
    "abstract": "The recent success of large language models (LLMs) has spurred their\napplication in various fields. In particular, there have been efforts to\nintegrate LLMs into various aspects of wireless communication systems. The use\nof LLMs in wireless communication systems has the potential to realize\nartificial general intelligence (AGI)-enabled wireless networks. In this paper,\nwe investigate an LLM-based resource allocation scheme for wireless\ncommunication systems. Specifically, we formulate a simple resource allocation\nproblem involving two transmit pairs and develop an LLM-based resource\nallocation approach that aims to maximize either energy efficiency or spectral\nefficiency. Additionally, we consider the joint use of low-complexity resource\nallocation techniques to compensate for the reliability shortcomings of the\nLLM-based scheme. After confirming the applicability and feasibility of\nLLM-based resource allocation, we address several key technical challenges that\nremain in applying LLMs in practice.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "eess.SP",
    "comment": "submitted to possible IEEE journal",
    "pdf_url": "http://arxiv.org/pdf/2408.02944v1",
    "published_date": "2024-08-06 04:08:26 UTC",
    "updated_date": "2024-08-06 04:08:26 UTC"
  },
  {
    "arxiv_id": "2408.02932v2",
    "title": "Doubly Stochastic Adaptive Neighbors Clustering via the Marcus Mapping",
    "authors": [
      "Jinghui Yuan",
      "Chusheng Zeng",
      "Fangyuan Xie",
      "Zhe Cao",
      "Mulin Chen",
      "Rong Wang",
      "Feiping Nie",
      "Yuan Yuan"
    ],
    "abstract": "Clustering is a fundamental task in machine learning and data science, and\nsimilarity graph-based clustering is an important approach within this domain.\nDoubly stochastic symmetric similarity graphs provide numerous benefits for\nclustering problems and downstream tasks, yet learning such graphs remains a\nsignificant challenge. Marcus theorem states that a strictly positive symmetric\nmatrix can be transformed into a doubly stochastic symmetric matrix by diagonal\nmatrices. However, in clustering, learning sparse matrices is crucial for\ncomputational efficiency. We extend Marcus theorem by proposing the Marcus\nmapping, which indicates that certain sparse matrices can also be transformed\ninto doubly stochastic symmetric matrices via diagonal matrices. Additionally,\nwe introduce rank constraints into the clustering problem and propose the\nDoubly Stochastic Adaptive Neighbors Clustering algorithm based on the Marcus\nMapping (ANCMM). This ensures that the learned graph naturally divides into the\ndesired number of clusters. We validate the effectiveness of our algorithm\nthrough extensive comparisons with state-of-the-art algorithms. Finally, we\nexplore the relationship between the Marcus mapping and optimal transport. We\nprove that the Marcus mapping solves a specific type of optimal transport\nproblem and demonstrate that solving this problem through Marcus mapping is\nmore efficient than directly applying optimal transport methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02932v2",
    "published_date": "2024-08-06 03:34:43 UTC",
    "updated_date": "2024-08-12 09:48:45 UTC"
  },
  {
    "arxiv_id": "2408.02930v1",
    "title": "The Need for a Big World Simulator: A Scientific Challenge for Continual Learning",
    "authors": [
      "Saurabh Kumar",
      "Hong Jun Jeon",
      "Alex Lewandowski",
      "Benjamin Van Roy"
    ],
    "abstract": "The \"small agent, big world\" frame offers a conceptual view that motivates\nthe need for continual learning. The idea is that a small agent operating in a\nmuch bigger world cannot store all information that the world has to offer. To\nperform well, the agent must be carefully designed to ingest, retain, and eject\nthe right information. To enable the development of performant continual\nlearning agents, a number of synthetic environments have been proposed.\nHowever, these benchmarks suffer from limitations, including unnatural\ndistribution shifts and a lack of fidelity to the \"small agent, big world\"\nframing. This paper aims to formalize two desiderata for the design of future\nsimulated environments. These two criteria aim to reflect the objectives and\ncomplexity of continual learning in practical settings while enabling rapid\nprototyping of algorithms on a smaller scale.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the Finding the Frame Workshop at RLC 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.02930v1",
    "published_date": "2024-08-06 03:26:01 UTC",
    "updated_date": "2024-08-06 03:26:01 UTC"
  },
  {
    "arxiv_id": "2408.02927v1",
    "title": "HARMONIC: Harnessing LLMs for Tabular Data Synthesis and Privacy Protection",
    "authors": [
      "Yuxin Wang",
      "Duanyu Feng",
      "Yongfu Dai",
      "Zhengyu Chen",
      "Jimin Huang",
      "Sophia Ananiadou",
      "Qianqian Xie",
      "Hao Wang"
    ],
    "abstract": "Data serves as the fundamental foundation for advancing deep learning,\nparticularly tabular data presented in a structured format, which is highly\nconducive to modeling. However, even in the era of LLM, obtaining tabular data\nfrom sensitive domains remains a challenge due to privacy or copyright\nconcerns. Hence, exploring how to effectively use models like LLMs to generate\nrealistic and privacy-preserving synthetic tabular data is urgent. In this\npaper, we take a step forward to explore LLMs for tabular data synthesis and\nprivacy protection, by introducing a new framework HARMONIC for tabular data\ngeneration and evaluation. In the tabular data generation of our framework,\nunlike previous small-scale LLM-based methods that rely on continued\npre-training, we explore the larger-scale LLMs with fine-tuning to generate\ntabular data and enhance privacy. Based on idea of the k-nearest neighbors\nalgorithm, an instruction fine-tuning dataset is constructed to inspire LLMs to\ndiscover inter-row relationships. Then, with fine-tuning, LLMs are trained to\nremember the format and connections of the data rather than the data itself,\nwhich reduces the risk of privacy leakage. In the evaluation part of our\nframework, we develop specific privacy risk metrics DLT for LLM synthetic data\ngeneration, as well as performance evaluation metrics LLE for downstream LLM\ntasks. Our experiments find that this tabular data generation framework\nachieves equivalent performance to existing methods with better privacy, which\nalso demonstrates our evaluation framework for the effectiveness of synthetic\ndata and privacy risks in LLM scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02927v1",
    "published_date": "2024-08-06 03:21:13 UTC",
    "updated_date": "2024-08-06 03:21:13 UTC"
  },
  {
    "arxiv_id": "2408.11828v1",
    "title": "Online Electric Vehicle Charging Detection Based on Memory-based Transformer using Smart Meter Data",
    "authors": [
      "Ammar Mansoor Kamoona",
      "Hui Song",
      "Mahdi Jalili",
      "Hao Wang",
      "Reza Razzaghi",
      "Xinghuo Yu"
    ],
    "abstract": "The growing popularity of Electric Vehicles (EVs) poses unique challenges for\ngrid operators and infrastructure, which requires effectively managing these\nvehicles' integration into the grid. Identification of EVs charging is\nessential to electricity Distribution Network Operators (DNOs) for better\nplanning and managing the distribution grid. One critical aspect is the ability\nto accurately identify the presence of EV charging in the grid. EV charging\nidentification using smart meter readings obtained from behind-the-meter\ndevices is a challenging task that enables effective managing the integration\nof EVs into the existing power grid. Different from the existing supervised\nmodels that require addressing the imbalance problem caused by EVs and non-EVs\ndata, we propose a novel unsupervised memory-based transformer (M-TR) that can\nrun in real-time (online) to detect EVs charging from a streaming smart meter.\nIt dynamically leverages coarse-scale historical information using an M-TR\nencoder from an extended global temporal window, in conjunction with an M-TR\ndecoder that concentrates on a limited time frame, local window, aiming to\ncapture the fine-scale characteristics of the smart meter data. The M-TR is\nbased on an anomaly detection technique that does not require any prior\nknowledge about EVs charging profiles, nor it does only require real power\nconsumption data of non-EV users. In addition, the proposed model leverages the\npower of transfer learning. The M-TR is compared with different\nstate-of-the-art methods and performs better than other unsupervised learning\nmodels. The model can run with an excellent execution time of 1.2 sec. for\n1-minute smart recordings.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11828v1",
    "published_date": "2024-08-06 03:19:14 UTC",
    "updated_date": "2024-08-06 03:19:14 UTC"
  },
  {
    "arxiv_id": "2408.02920v1",
    "title": "A Taxonomy of Architecture Options for Foundation Model-based Agents: Analysis and Decision Model",
    "authors": [
      "Jingwen Zhou",
      "Qinghua Lu",
      "Jieshan Chen",
      "Liming Zhu",
      "Xiwei Xu",
      "Zhenchang Xing",
      "Stefan Harrer"
    ],
    "abstract": "The rapid advancement of AI technology has led to widespread applications of\nagent systems across various domains. However, the need for detailed\narchitecture design poses significant challenges in designing and operating\nthese systems. This paper introduces a taxonomy focused on the architectures of\nfoundation-model-based agents, addressing critical aspects such as functional\ncapabilities and non-functional qualities. We also discuss the operations\ninvolved in both design-time and run-time phases, providing a comprehensive\nview of architectural design and operational characteristics. By unifying and\ndetailing these classifications, our taxonomy aims to improve the design of\nfoundation-model-based agents. Additionally, the paper establishes a decision\nmodel that guides critical design and runtime decisions, offering a structured\napproach to enhance the development of foundation-model-based agents. Our\ncontributions include providing a structured architecture design option and\nguiding the development process of foundation-model-based agents, thereby\naddressing current fragmentation in the field.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2408.02920v1",
    "published_date": "2024-08-06 03:10:52 UTC",
    "updated_date": "2024-08-06 03:10:52 UTC"
  },
  {
    "arxiv_id": "2408.02912v3",
    "title": "KOI: Accelerating Online Imitation Learning via Hybrid Key-state Guidance",
    "authors": [
      "Jingxian Lu",
      "Wenke Xia",
      "Dong Wang",
      "Zhigang Wang",
      "Bin Zhao",
      "Di Hu",
      "Xuelong Li"
    ],
    "abstract": "Online Imitation Learning struggles with the gap between extensive online\nexploration space and limited expert trajectories, hindering efficient\nexploration due to inaccurate reward estimation. Inspired by the findings from\ncognitive neuroscience, we hypothesize that an agent could estimate precise\ntask-aware reward for efficient online exploration, through decomposing the\ntarget task into the objectives of \"what to do\" and the mechanisms of \"how to\ndo\". In this work, we introduce the hybrid Key-state guided Online Imitation\n(KOI) learning method, which leverages the integration of semantic and motion\nkey states as guidance for reward estimation. Initially, we utilize\nvisual-language models to extract semantic key states from expert trajectory,\nindicating the objectives of \"what to do\". Within the intervals between\nsemantic key states, optical flow is employed to capture motion key states to\nunderstand the mechanisms of \"how to do\". By integrating a thorough grasp of\nhybrid key states, we refine the trajectory-matching reward computation,\naccelerating online imitation learning with task-aware exploration. We evaluate\nnot only the success rate of the tasks in the Meta-World and LIBERO\nenvironments, but also the trend of variance during online imitation learning,\nproving that our method is more sample efficient. We also conduct real-world\nrobotic manipulation experiments to validate the efficacy of our method,\ndemonstrating the practical applicability of our KOI method. Videos and code\nare available at https://gewu-lab.github.io/Keystate_Online_Imitation/.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by CoRL 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.02912v3",
    "published_date": "2024-08-06 02:53:55 UTC",
    "updated_date": "2024-10-17 03:35:21 UTC"
  },
  {
    "arxiv_id": "2408.02904v1",
    "title": "Enabling Intelligent Traffic Systems: A Deep Learning Method for Accurate Arabic License Plate Recognition",
    "authors": [
      "M. A. Sayedelahl"
    ],
    "abstract": "This paper introduces a novel two-stage framework for accurate Egyptian\nVehicle License Plate Recognition (EVLPR). The first stage employs image\nprocessing techniques to reliably localize license plates, while the second\nstage utilizes a custom-designed deep learning model for robust Arabic\ncharacter recognition. The proposed system achieves a remarkable 99.3% accuracy\non a diverse dataset, surpassing existing approaches. Its potential\napplications extend to intelligent traffic management, including traffic\nviolation detection and parking optimization. Future research will focus on\nenhancing the system's capabilities through architectural refinements, expanded\ndatasets, and addressing system dependencies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02904v1",
    "published_date": "2024-08-06 02:27:54 UTC",
    "updated_date": "2024-08-06 02:27:54 UTC"
  },
  {
    "arxiv_id": "2408.04662v2",
    "title": "Citekit: A Modular Toolkit for Large Language Model Citation Generation",
    "authors": [
      "Jiajun Shen",
      "Tong Zhou",
      "Yubo Chen",
      "Kang Liu"
    ],
    "abstract": "Enabling Large Language Models (LLMs) to generate citations in\nQuestion-Answering (QA) tasks is an emerging paradigm aimed at enhancing the\nverifiability of their responses when LLMs are utilizing external references to\ngenerate an answer. However, there is currently no unified framework to\nstandardize and fairly compare different citation generation methods, leading\nto difficulties in reproducing different methods and a comprehensive\nassessment. To cope with the problems above, we introduce \\name, an open-source\nand modular toolkit designed to facilitate the implementation and evaluation of\nexisting citation generation methods, while also fostering the development of\nnew approaches to improve citation quality in LLM outputs. This tool is highly\nextensible, allowing users to utilize 4 main modules and 14 components to\nconstruct a pipeline, evaluating an existing method or innovative designs. Our\nexperiments with two state-of-the-art LLMs and 11 citation generation baselines\ndemonstrate varying strengths of different modules in answer accuracy and\ncitation quality improvement, as well as the challenge of enhancing\ngranularity. Based on our analysis of the effectiveness of components, we\npropose a new method, self-RAG \\snippet, obtaining a balanced answer accuracy\nand citation quality. Citekit is released at\nhttps://github.com/SjJ1017/Citekit.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.04662v2",
    "published_date": "2024-08-06 02:13:15 UTC",
    "updated_date": "2024-12-17 08:37:34 UTC"
  },
  {
    "arxiv_id": "2408.02897v1",
    "title": "A Metric Driven Approach to Mixed Precision Training",
    "authors": [
      "Mitchelle Rasquinha",
      "Gil Tabak"
    ],
    "abstract": "As deep learning methodologies have developed, it has been generally agreed\nthat increasing neural network size improves model quality. However, this is at\nthe expense of memory and compute requirements, which also need to be\nincreased. Various efficiency techniques have been proposed to rein in hardware\ncosts, one being the use of low precision numerics. Recent accelerators have\nintroduced several different 8-bit data types to help accommodate DNNs in terms\nof numerics. In this paper, we identify a metric driven methodology to aid in\nthe choice of numerics. We demonstrate how such a methodology can help scale\ntraining of a language representation model. The technique can be generalized\nto other model architectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02897v1",
    "published_date": "2024-08-06 02:06:04 UTC",
    "updated_date": "2024-08-06 02:06:04 UTC"
  },
  {
    "arxiv_id": "2408.02888v1",
    "title": "VizECGNet: Visual ECG Image Network for Cardiovascular Diseases Classification with Multi-Modal Training and Knowledge Distillation",
    "authors": [
      "Ju-Hyeon Nam",
      "Seo-Hyung Park",
      "Su Jung Kim",
      "Sang-Chul Lee"
    ],
    "abstract": "An electrocardiogram (ECG) captures the heart's electrical signal to assess\nvarious heart conditions. In practice, ECG data is stored as either digitized\nsignals or printed images. Despite the emergence of numerous deep learning\nmodels for digitized signals, many hospitals prefer image storage due to cost\nconsiderations. Recognizing the unavailability of raw ECG signals in many\nclinical settings, we propose VizECGNet, which uses only printed ECG graphics\nto determine the prognosis of multiple cardiovascular diseases. During\ntraining, cross-modal attention modules (CMAM) are used to integrate\ninformation from two modalities - image and signal, while self-modality\nattention modules (SMAM) capture inherent long-range dependencies in ECG data\nof each modality. Additionally, we utilize knowledge distillation to improve\nthe similarity between two distinct predictions from each modality stream. This\ninnovative multi-modal deep learning architecture enables the utilization of\nonly ECG images during inference. VizECGNet with image input achieves higher\nperformance in precision, recall, and F1-Score compared to signal-based ECG\nclassification models, with improvements of 3.50%, 8.21%, and 7.38%,\nrespectively.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in International Conference on Image Processing (ICIP) 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.02888v1",
    "published_date": "2024-08-06 01:34:43 UTC",
    "updated_date": "2024-08-06 01:34:43 UTC"
  },
  {
    "arxiv_id": "2408.02882v1",
    "title": "Compromising Embodied Agents with Contextual Backdoor Attacks",
    "authors": [
      "Aishan Liu",
      "Yuguang Zhou",
      "Xianglong Liu",
      "Tianyuan Zhang",
      "Siyuan Liang",
      "Jiakai Wang",
      "Yanjun Pu",
      "Tianlin Li",
      "Junqi Zhang",
      "Wenbo Zhou",
      "Qing Guo",
      "Dacheng Tao"
    ],
    "abstract": "Large language models (LLMs) have transformed the development of embodied\nintelligence. By providing a few contextual demonstrations, developers can\nutilize the extensive internal knowledge of LLMs to effortlessly translate\ncomplex tasks described in abstract language into sequences of code snippets,\nwhich will serve as the execution logic for embodied agents. However, this\npaper uncovers a significant backdoor security threat within this process and\nintroduces a novel method called \\method{}. By poisoning just a few contextual\ndemonstrations, attackers can covertly compromise the contextual environment of\na black-box LLM, prompting it to generate programs with context-dependent\ndefects. These programs appear logically sound but contain defects that can\nactivate and induce unintended behaviors when the operational agent encounters\nspecific triggers in its interactive environment. To compromise the LLM's\ncontextual environment, we employ adversarial in-context generation to optimize\npoisoned demonstrations, where an LLM judge evaluates these poisoned prompts,\nreporting to an additional LLM that iteratively optimizes the demonstration in\na two-player adversarial game using chain-of-thought reasoning. To enable\ncontext-dependent behaviors in downstream agents, we implement a dual-modality\nactivation strategy that controls both the generation and execution of program\ndefects through textual and visual triggers. We expand the scope of our attack\nby developing five program defect modes that compromise key aspects of\nconfidentiality, integrity, and availability in embodied agents. To validate\nthe effectiveness of our approach, we conducted extensive experiments across\nvarious tasks, including robot planning, robot manipulation, and compositional\nvisual reasoning. Additionally, we demonstrate the potential impact of our\napproach by successfully attacking real-world autonomous driving systems.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02882v1",
    "published_date": "2024-08-06 01:20:12 UTC",
    "updated_date": "2024-08-06 01:20:12 UTC"
  },
  {
    "arxiv_id": "2408.02871v1",
    "title": "Hide and Seek: Fingerprinting Large Language Models with Evolutionary Learning",
    "authors": [
      "Dmitri Iourovitski",
      "Sanat Sharma",
      "Rakshak Talwar"
    ],
    "abstract": "As content generated by Large Language Model (LLM) has grown exponentially,\nthe ability to accurately identify and fingerprint such text has become\nincreasingly crucial. In this work, we introduce a novel black-box approach for\nfingerprinting LLMs, achieving an impressive 72% accuracy in identifying the\ncorrect family of models (Such as Llama, Mistral, Gemma, etc) among a lineup of\nLLMs. We present an evolutionary strategy that leverages the capabilities of\none LLM to discover the most salient features for identifying other LLMs. Our\nmethod employs a unique \"Hide and Seek\" algorithm, where an Auditor LLM\ngenerates discriminative prompts, and a Detective LLM analyzes the responses to\nfingerprint the target models. This approach not only demonstrates the\nfeasibility of LLM-driven model identification but also reveals insights into\nthe semantic manifolds of different LLM families. By iteratively refining\nprompts through in-context learning, our system uncovers subtle distinctions\nbetween model outputs, providing a powerful tool for LLM analysis and\nverification. This research opens new avenues for understanding LLM behavior\nand has significant implications for model attribution, security, and the\nbroader field of AI transparency.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02871v1",
    "published_date": "2024-08-06 00:13:10 UTC",
    "updated_date": "2024-08-06 00:13:10 UTC"
  }
]