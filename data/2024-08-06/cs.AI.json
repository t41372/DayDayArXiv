{
  "date": "2024-08-06",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-06 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型（如大型语言模型 LLMs）的优化、安全和应用扩展，还涉及机器人控制、医疗诊断、交通系统等领域，其中 LLaVA-OneVision（由知名学者 Bo Li 等人发布）的多模态任务转移能力令人印象深刻，LLM 在时间序列异常检测和安全威胁中的潜力也值得关注，这些研究突显了 AI 在实际场景中的挑战与创新。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊 AI 和 LLM 相关的高影响力文章，再快速概述其他领域的亮点。限于篇幅，我会聚焦于最具话题度和学术价值的论文，对次要内容一笔带过。\n\n### 1. **LLM 在时间序列异常检测中的潜力**  \n**标题：Can LLMs Serve As Time Series Anomaly Detectors?（LLMs 是否能作为时间序列异常检测器？）**  \n这篇论文探讨了 LLMs（如 GPT-4 和 LLaMA3）在时间序列异常检测中的能力。主要贡献：发现直接使用 LLMs 效果不佳，但通过提示策略（如 in-context learning）可与基准方法竞争；还提出一个合成数据集用于指令微调，提升 LLaMA3 的性能。发现突显了 LLMs 在实时应用中的潜力，但需优化提示设计。\n\n### 2. **LLM 安全和攻击防御**  \n**标题：Attacks and Defenses for Generative Diffusion Models（生成扩散模型的攻击与防御）**  \n**标题：Non-Determinism of \"Deterministic\" LLM Settings（\"确定性\" LLM 设置的不确定性）**  \n**标题：LLMs are Not Just Next Token Predictors（LLMs 不仅仅是下一个标记预测器）**  \n这些论文关注 LLMs 的安全漏洞。第8篇进行全面调查，总结生成扩散模型的攻击类型（如对抗攻击）和防御策略，发现多模态威胁尤为突出。第17篇揭示 LLMs 在“确定性”设置下仍存在输出变异，影响任务准确性；第19篇从生物学角度论证 LLMs 的复杂性。整体发现：LLMs 易受数据污染，需加强防御机制，这些研究为 AI 安全提供重要启示。\n\n### 3. **多模态 LLM 和任务转移**  \n**标题：LLaVA-OneVision: Easy Visual Task Transfer（LLaVA-OneVision: 轻松视觉任务转移）**  \n由知名学者 Bo Li 等人发布，这篇论文提出 LLaVA-OneVision 模型家族，能在单图像、多图像和视频场景中提升性能。主要贡献：通过数据和表示优化，实现任务转移，显著改善分类准确率（如从 67% 到 89%）。发现：这为 LLM 在视觉任务中的泛化能力提供了新路径，极具话题度。\n\n### 4. **医疗 AI 应用**  \n**标题：SCREENER: A general framework for task-specific experiment design in quantitative MRI（SCREENER: 定量 MRI 的任务特定实验设计框架）**  \n**标题：Identifying treatment response subgroups in observational time-to-event data（识别观察性时间事件数据中的治疗响应子群）**  \n第4篇引入 SCREENER 框架，使用深度强化学习优化 MRI 实验设计，主要发现：在骨髓炎分类任务中，准确率提升至 89%。第3篇提出新子群分析策略，优于现有方法，能应用于随机对照试验和观察研究。这些研究推动了 AI 在诊断和个性化医疗中的应用，强调任务特定优化。\n\n### 5. **机器人和视觉系统**  \n**标题：EEGMobile: Enhancing Speed and Accuracy in EEG-Based Gaze Prediction（EEGMobile: 提升 EEG 基础注视预测的速度和准确性）**  \n**标题：Fusing Forces: Deep-Human-Guided Refinement of Segmentation Masks（融合力量: 深度人类引导的分割掩码精炼）**  \n第5篇使用 MobileViT 和知识蒸馏优化 EEG 预测，贡献：速度提升 33%、模型大小减小 60%，适用于资源受限设备。第13篇提出人类交互式分割掩码精炼，减少手动输入 75%。这些发现提升了机器人视觉的精度和效率，适用于手术和交互场景。\n\n### 6. **其他领域快速概述**  \n- **交通和强化学习**：如第6篇（Communication-Aware Consistent Edge Selection），使用深度强化学习优化车辆任务迁移，减少延迟；第28篇（Adversarial Safety-Critical Scenario Generation）生成安全场景，提升自动驾驶鲁棒性。这些论文虽重要，但相对常规，贡献在于实际应用优化。\n- **数据合成和隐私**：第16篇（KnowPO）提出知识感知偏好优化，改善 LLM 检索增强生成；第25篇（LLM-based MOFs Synthesis）使用 LLM 提取材料合成数据，提升隐私保护。其他如数据蒸馏和聚类论文（第15、9篇），虽有技术创新，但影响力较小，仅提升了特定任务效率。\n- **其余论文**：如第27、32、39篇等，涉及 LLM 评估和生成框架，但非核心热点，仅快速提及其在特定领域的细微改进。\n\n总之，今天的 arXiv 论文强调 AI 模型的扩展性和安全性，LLM 相关研究如 LLaVA-OneVision 特别值得关注。读者可根据兴趣优先查看这些前沿工作，完整列表请参考 arXiv。明天见！",
  "papers": [
    {
      "arxiv_id": "2408.03475v1",
      "title": "Can LLMs Serve As Time Series Anomaly Detectors?",
      "title_zh": "LLMs 可以用作时间序列异常检测器吗？",
      "authors": [
        "Manqing Dong",
        "Hao Huang",
        "Longbing Cao"
      ],
      "abstract": "An emerging topic in large language models (LLMs) is their application to\ntime series forecasting, characterizing mainstream and patternable\ncharacteristics of time series. A relevant but rarely explored and more\nchallenging question is whether LLMs can detect and explain time series\nanomalies, a critical task across various real-world applications. In this\npaper, we investigate the capabilities of LLMs, specifically GPT-4 and LLaMA3,\nin detecting and explaining anomalies in time series. Our studies reveal that:\n1) LLMs cannot be directly used for time series anomaly detection. 2) By\ndesigning prompt strategies such as in-context learning and chain-of-thought\nprompting, GPT-4 can detect time series anomalies with results competitive to\nbaseline methods. 3) We propose a synthesized dataset to automatically generate\ntime series anomalies with corresponding explanations. By applying instruction\nfine-tuning on this dataset, LLaMA3 demonstrates improved performance in time\nseries anomaly detection tasks. In summary, our exploration shows the promising\npotential of LLMs as time series anomaly detectors.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs），如 GPT-4 和 LLaMA3，在时间序列异常检测中的潜力，评估它们是否能检测并解释异常。结果显示，LLMs 无法直接用于时间序列 anomaly detection，但通过设计提示策略（如 in-context learning 和 chain-of-thought prompting），GPT-4 的检测性能可与基线方法竞争。该团队提出一个合成数据集，用于自动生成时间序列异常及其解释，并通过指令微调提升 LLaMA3 的表现，总体表明 LLMs 在此领域的应用前景可期。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03475v1",
      "published_date": "2024-08-06 23:14:39 UTC",
      "updated_date": "2024-08-06 23:14:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:12:04.049809"
    },
    {
      "arxiv_id": "2408.11837v1",
      "title": "MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy",
      "title_zh": "翻译失败",
      "authors": [
        "Hanchen David Wang",
        "Nibraas Khan",
        "Anna Chen",
        "Nilanjan Sarkar",
        "Pamela Wisniewski",
        "Meiyi Ma"
      ],
      "abstract": "Recent global estimates suggest that as many as 2.41 billion individuals have\nhealth conditions that would benefit from rehabilitation services. Home-based\nPhysical Therapy (PT) faces significant challenges in providing interactive\nfeedback and meaningful observation for therapists and patients. To fill this\ngap, we present MicroXercise, which integrates micro-motion analysis with\nwearable sensors, providing therapists and patients with a comprehensive\nfeedback interface, including video, text, and scores. Crucially, it employs\nmulti-dimensional Dynamic Time Warping (DTW) and attribution-based explainable\nmethods to analyze the existing deep learning neural networks in monitoring\nexercises, focusing on a high granularity of exercise. This synergistic\napproach is pivotal, providing output matching the input size to precisely\nhighlight critical subtleties and movements in PT, thus transforming complex AI\nanalysis into clear, actionable feedback. By highlighting these micro-motions\nin different metrics, such as stability and range of motion, MicroXercise\nsignificantly enhances the understanding and relevance of feedback for\nend-users. Comparative performance metrics underscore its effectiveness over\ntraditional methods, such as a 39% and 42% improvement in Feature Mutual\nInformation (FMI) and Continuity. MicroXercise is a step ahead in home-based\nphysical therapy, providing a technologically advanced and intuitively helpful\nsolution to enhance patient care and outcomes.",
      "tldr_zh": "MicroXercise 是一个针对远程物理治疗的微观级别比较和可解释系统，它整合可穿戴传感器和微观运动分析，提供视频、文本和评分反馈，以解决家庭物理治疗（PT）中互动反馈和观察的挑战。\n该系统采用多维Dynamic Time Warping (DTW)和基于归因的可解释方法，分析深度学习神经网络，聚焦高粒度运动并将复杂AI分析转化为清晰、可操作的反馈，如稳定性与运动范围的指标。\n相比传统方法，MicroXercise 在Feature Mutual Information (FMI)和连续性上分别提升39%和42%，显著增强了患者和治疗师的理解，从而改善家庭PT的疗效和患者护理结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IEEE/ACM CHASE 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11837v1",
      "published_date": "2024-08-06 22:39:47 UTC",
      "updated_date": "2024-08-06 22:39:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:12:15.894894"
    },
    {
      "arxiv_id": "2408.03463v4",
      "title": "Identifying treatment response subgroups in observational time-to-event data",
      "title_zh": "翻译失败",
      "authors": [
        "Vincent Jeanselme",
        "Chang Ho Yoon",
        "Fabian Falck",
        "Brian Tom",
        "Jessica Barrett"
      ],
      "abstract": "Identifying patient subgroups with different treatment responses is an\nimportant task to inform medical recommendations, guidelines, and the design of\nfuture clinical trials. Existing approaches for treatment effect estimation\nprimarily rely on Randomised Controlled Trials (RCTs), which are often limited\nby insufficient power, multiple comparisons, and unbalanced covariates. In\naddition, RCTs tend to feature more homogeneous patient groups, making them\nless relevant for uncovering subgroups in the population encountered in\nreal-world clinical practice. Subgroup analyses established for RCTs suffer\nfrom significant statistical biases when applied to observational studies,\nwhich benefit from larger and more representative populations. Our work\nintroduces a novel, outcome-guided, subgroup analysis strategy for identifying\nsubgroups of treatment response in both RCTs and observational studies alike.\nIt hence positions itself in-between individualised and average treatment\neffect estimation to uncover patient subgroups with distinct treatment\nresponses, critical for actionable insights that may influence treatment\nguidelines. In experiments, our approach significantly outperforms the current\nstate-of-the-art method for subgroup analysis in both randomised and\nobservational treatment regimes.",
      "tldr_zh": "这篇论文针对识别观察性时间事件数据中治疗反应子群的问题，提出了一种新的基于结果导向的子群分析策略，以弥补随机对照试验 (RCTs) 的局限性，如功率不足、多重比较和患者群不均匀。 该策略适用于 RCTs 和观察性研究，介于个性化治疗效果估计与平均治疗效果估计之间，能够发现具有不同治疗反应的患者子群，从而为医疗指南和临床试验设计提供可操作的见解。 实验结果表明，该方法在随机和观察性治疗方案中显著优于现有最先进的方法。",
      "categories": [
        "stat.ME",
        "cs.AI"
      ],
      "primary_category": "stat.ME",
      "comment": "Preprint under review",
      "pdf_url": "http://arxiv.org/pdf/2408.03463v4",
      "published_date": "2024-08-06 22:38:14 UTC",
      "updated_date": "2025-02-24 00:33:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:12:27.621833"
    },
    {
      "arxiv_id": "2408.11834v1",
      "title": "SCREENER: A general framework for task-specific experiment design in quantitative MRI",
      "title_zh": "SCREENER：一种用于定量MRI的任务特定实验设计的通用框架",
      "authors": [
        "Tianshu Zheng",
        "Zican Wang",
        "Timothy Bray",
        "Daniel C. Alexander",
        "Dan Wu",
        "Hui Zhang"
      ],
      "abstract": "Quantitative magnetic resonance imaging (qMRI) is increasingly investigated\nfor use in a variety of clinical tasks from diagnosis, through staging, to\ntreatment monitoring. However, experiment design in qMRI, the identification of\nthe optimal acquisition protocols, has been focused on obtaining the most\nprecise parameter estimations, with no regard for the specific requirements of\ndownstream tasks. Here we propose SCREENER: A general framework for\ntask-specific experiment design in quantitative MRI. SCREENER incorporates a\ntask-specific objective and seeks the optimal protocol with a\ndeep-reinforcement-learning (DRL) based optimization strategy. To illustrate\nthis framework, we employ a task of classifying the inflammation status of bone\nmarrow using diffusion MRI data with intravoxel incoherent motion (IVIM)\nmodelling. Results demonstrate SCREENER outperforms previous ad hoc and\noptimized protocols under clinical signal-to-noise ratio (SNR) conditions,\nachieving significant improvement, both in binary classification tasks, e.g.\nfrom 67% to 89%, and in a multi-class classification task, from 46% to 59%.\nAdditionally, we show this improvement is robust to the SNR. Lastly, we\ndemonstrate the advantage of DRL-based optimization strategy, enabling\nzero-shot discovery of near-optimal protocols for a range of SNRs not used in\ntraining. In conclusion, SCREENER has the potential to enable wider uptake of\nqMRI in the clinic.",
      "tldr_zh": "论文提出 SCREENER，一种通用的任务特定实验设计框架，用于 quantitative MRI (qMRI)，旨在优化采集协议以满足下游临床任务需求，如诊断和治疗监测，而不是仅追求参数估计精度。框架整合任务特定目标，并采用 deep-reinforcement-learning (DRL) 优化策略，以示例任务（如使用 intravoxel incoherent motion (IVIM) 建模的骨髓炎症分类）证明其有效性。结果显示，SCREENER 在临床 signal-to-noise ratio (SNR) 条件下显著提升分类性能，例如二元任务准确率从 67% 提高到 89%，多类任务从 46% 到 59%，且对 SNR 变化具有鲁棒性。此外，该框架通过 DRL 启用零样本发现适用于多种 SNR 的近似最佳协议，有望促进 qMRI 在临床的广泛应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11834v1",
      "published_date": "2024-08-06 21:43:50 UTC",
      "updated_date": "2024-08-06 21:43:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:12:42.333144"
    },
    {
      "arxiv_id": "2408.03449v1",
      "title": "EEGMobile: Enhancing Speed and Accuracy in EEG-Based Gaze Prediction with Advanced Mobile Architectures",
      "title_zh": "EEGMobile：通过",
      "authors": [
        "Teng Liang",
        "Andrews Damoah"
      ],
      "abstract": "Electroencephalography (EEG) analysis is an important domain in the realm of\nBrain-Computer Interface (BCI) research. To ensure BCI devices are capable of\nproviding practical applications in the real world, brain signal processing\ntechniques must be fast, accurate, and resource-conscious to deliver\nlow-latency neural analytics. This study presents a model that leverages a\npre-trained MobileViT alongside Knowledge Distillation (KD) for EEG regression\ntasks. Our results showcase that this model is capable of performing at a level\ncomparable (only 3% lower) to the previous State-Of-The-Art (SOTA) on the\nEEGEyeNet Absolute Position Task while being 33% faster and 60% smaller. Our\nresearch presents a cost-effective model applicable to resource-constrained\ndevices and contributes to expanding future research on lightweight,\nmobile-friendly models for EEG regression.",
      "tldr_zh": "本研究针对脑机接口(BCI)中的脑电图(EEG)分析，提出EEGMobile模型，以提升EEG-based注视预测的速度和准确性。该模型结合预训练的MobileViT架构和Knowledge Distillation (KD)技术，用于EEG回归任务。结果显示，EEGMobile在EEGEyeNet绝对位置任务上性能仅比State-Of-The-Art (SOTA)低3%，但速度提升33%、模型大小减少60%，使其适用于资源受限设备。该工作为轻量级EEG模型的研究提供了成本有效的解决方案。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted HCI International 2024 - Late Breaking Work",
      "pdf_url": "http://arxiv.org/pdf/2408.03449v1",
      "published_date": "2024-08-06 21:02:27 UTC",
      "updated_date": "2024-08-06 21:02:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:13:02.270169"
    },
    {
      "arxiv_id": "2408.03435v1",
      "title": "Communication-Aware Consistent Edge Selection for Mobile Users and Autonomous Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Nazish Tahir",
        "Ramviyas Parasuraman",
        "Haijian Sun"
      ],
      "abstract": "Offloading time-sensitive, computationally intensive tasks-such as advanced\nlearning algorithms for autonomous driving-from vehicles to nearby edge\nservers, vehicle-to-infrastructure (V2I) systems, or other collaborating\nvehicles via vehicle-to-vehicle (V2V) communication enhances service\nefficiency. However, whence traversing the path to the destination, the\nvehicle's mobility necessitates frequent handovers among the access points\n(APs) to maintain continuous and uninterrupted wireless connections to maintain\nthe network's Quality of Service (QoS). These frequent handovers subsequently\nlead to task migrations among the edge servers associated with the respective\nAPs. This paper addresses the joint problem of task migration and access-point\nhandover by proposing a deep reinforcement learning framework based on the Deep\nDeterministic Policy Gradient (DDPG) algorithm. A joint allocation method of\ncommunication and computation of APs is proposed to minimize computational\nload, service latency, and interruptions with the overarching goal of\nmaximizing QoS. We implement and evaluate our proposed framework on simulated\nexperiments to achieve smooth and seamless task switching among edge servers,\nultimately reducing latency.",
      "tldr_zh": "这篇论文针对移动用户和自动车辆的边缘计算场景，提出了一种通信感知的边缘选择策略，以解决车辆移动导致的频繁接入点(handover)和任务迁移问题，从而维持网络的 Quality of Service (QoS)。他们采用基于 Deep Deterministic Policy Gradient (DDPG) 的深度强化学习框架，实现通信和计算资源的联合分配，旨在最小化计算负载、服务延迟和中断。实验结果显示，该方法在模拟环境中实现了平滑的任务切换，并显著降低了延迟，为车辆-to-infrastructure (V2I) 和 vehicle-to-vehicle (V2V) 系统提供了更高效的解决方案。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.NI",
      "comment": "Accepted by Vehicular Technology Conference (VTC) Fall 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03435v1",
      "published_date": "2024-08-06 20:21:53 UTC",
      "updated_date": "2024-08-06 20:21:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:13:04.683251"
    },
    {
      "arxiv_id": "2408.03405v1",
      "title": "Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Lucia Gordon",
        "Esther Rolf",
        "Milind Tambe"
      ],
      "abstract": "Stochastic multi-agent multi-armed bandits typically assume that the rewards\nfrom each arm follow a fixed distribution, regardless of which agent pulls the\narm. However, in many real-world settings, rewards can depend on the\nsensitivity of each agent to their environment. In medical screening, disease\ndetection rates can vary by test type; in preference matching, rewards can\ndepend on user preferences; and in environmental sensing, observation quality\ncan vary across sensors. Since past work does not specify how to allocate\nagents of heterogeneous but known sensitivity of these types in a stochastic\nbandit setting, we introduce a UCB-style algorithm, Min-Width, which aggregates\ninformation from diverse agents. In doing so, we address the joint challenges\nof (i) aggregating the rewards, which follow different distributions for each\nagent-arm pair, and (ii) coordinating the assignments of agents to arms.\nMin-Width facilitates efficient collaboration among heterogeneous agents,\nexploiting the known structure in the agents' reward functions to weight their\nrewards accordingly. We analyze the regret of Min-Width and conduct\npseudo-synthetic and fully synthetic experiments to study the performance of\ndifferent levels of information sharing. Our results confirm that the gains to\nmodeling agent heterogeneity tend to be greater when the sensitivities are more\nvaried across agents, while combining more information does not always improve\nperformance.",
      "tldr_zh": "这篇论文针对异构智能体的随机 Bandit 问题，引入了 Min-Width 算法，一种 UCB-style 方法，用于聚合不同智能体的回报信息并协调其分配。算法解决了回报分布因智能体敏感性而异的挑战，通过权重回报结构促进高效协作。实验结果表明，当智能体敏感性差异较大时，建模异构性带来的性能提升更显著，而增加信息共享并不总是改善整体效果。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "19 pages, 6 figures, to be published in ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03405v1",
      "published_date": "2024-08-06 18:56:29 UTC",
      "updated_date": "2024-08-06 18:56:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:13:16.137257"
    },
    {
      "arxiv_id": "2408.03400v1",
      "title": "Attacks and Defenses for Generative Diffusion Models: A Comprehensive Survey",
      "title_zh": "生成式扩散模型的攻击与防御：全面综述",
      "authors": [
        "Vu Tuan Truong",
        "Luan Ba Dang",
        "Long Bao Le"
      ],
      "abstract": "Diffusion models (DMs) have achieved state-of-the-art performance on various\ngenerative tasks such as image synthesis, text-to-image, and text-guided\nimage-to-image generation. However, the more powerful the DMs, the more harmful\nthey potentially are. Recent studies have shown that DMs are prone to a wide\nrange of attacks, including adversarial attacks, membership inference, backdoor\ninjection, and various multi-modal threats. Since numerous pre-trained DMs are\npublished widely on the Internet, potential threats from these attacks are\nespecially detrimental to the society, making DM-related security a worth\ninvestigating topic. Therefore, in this paper, we conduct a comprehensive\nsurvey on the security aspect of DMs, focusing on various attack and defense\nmethods for DMs. First, we present crucial knowledge of DMs with five main\ntypes of DMs, including denoising diffusion probabilistic models, denoising\ndiffusion implicit models, noise conditioned score networks, stochastic\ndifferential equations, and multi-modal conditional DMs. We further survey a\nvariety of recent studies investigating different types of attacks that exploit\nthe vulnerabilities of DMs. Then, we thoroughly review potential\ncountermeasures to mitigate each of the presented threats. Finally, we discuss\nopen challenges of DM-related security and envision certain research directions\nfor this topic.",
      "tldr_zh": "本论文对生成式扩散模型（diffusion models）的安全问题进行了全面调查，涵盖了攻击和防御方法。研究首先介绍了DMs的五种主要类型，包括denoising diffusion probabilistic models（DDPM）、denoising diffusion implicit models（DDIM）、noise conditioned score networks、stochastic differential equations以及多模态条件DMs。论文详细分析了各种攻击如adversarial attacks、membership inference、backdoor injection和多模态威胁，并审查了相应的防御策略；最后讨论了DMs安全领域的开放挑战和未来研究方向，以推动更可靠的模型发展。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03400v1",
      "published_date": "2024-08-06 18:52:17 UTC",
      "updated_date": "2024-08-06 18:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:13:27.071846"
    },
    {
      "arxiv_id": "2408.03399v1",
      "title": "RHiOTS: A Framework for Evaluating Hierarchical Time Series Forecasting Algorithms",
      "title_zh": "RHiOTS：用于评估分层时间序列预测算法的框架",
      "authors": [
        "Luis Roque",
        "Carlos Soares",
        "Luís Torgo"
      ],
      "abstract": "We introduce the Robustness of Hierarchically Organized Time Series (RHiOTS)\nframework, designed to assess the robustness of hierarchical time series\nforecasting models and algorithms on real-world datasets. Hierarchical time\nseries, where lower-level forecasts must sum to upper-level ones, are prevalent\nin various contexts, such as retail sales across countries. Current empirical\nevaluations of forecasting methods are often limited to a small set of\nbenchmark datasets, offering a narrow view of algorithm behavior. RHiOTS\naddresses this gap by systematically altering existing datasets and modifying\nthe characteristics of individual series and their interrelations. It uses a\nset of parameterizable transformations to simulate those changes in the data\ndistribution. Additionally, RHiOTS incorporates an innovative visualization\ncomponent, turning complex, multidimensional robustness evaluation results into\nintuitive, easily interpretable visuals. This approach allows an in-depth\nanalysis of algorithm and model behavior under diverse conditions. We\nillustrate the use of RHiOTS by analyzing the predictive performance of several\nalgorithms. Our findings show that traditional statistical methods are more\nrobust than state-of-the-art deep learning algorithms, except when the\ntransformation effect is highly disruptive. Furthermore, we found no\nsignificant differences in the robustness of the algorithms when applying\nspecific reconciliation methods, such as MinT. RHiOTS provides researchers with\na comprehensive tool for understanding the nuanced behavior of forecasting\nalgorithms, offering a more reliable basis for selecting the most appropriate\nmethod for a given problem.",
      "tldr_zh": "本文提出了 RHiOTS 框架，用于评估分层时间序列预测算法的鲁棒性，针对真实数据集中的层级关系（如零售销售数据）进行系统性测试。框架通过参数化转换修改数据集特征和序列间关系，并引入创新的可视化组件，将多维评估结果转化为直观的视觉分析，从而深入分析算法在不同条件下的行为。实验结果显示，传统统计方法在大多数场景下比最先进的深度学习算法更鲁棒，只有在高度破坏性的转换下才出现例外；此外，特定协调方法如 MinT 对算法鲁棒性没有显著差异。RHiOTS 为研究人员提供了一个全面工具，帮助更可靠地选择适合的预测算法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6; I.5.1; G.3; H.2.8"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining (KDD '24), August 25--29, 2024, Barcelona, Spain",
      "pdf_url": "http://arxiv.org/pdf/2408.03399v1",
      "published_date": "2024-08-06 18:52:15 UTC",
      "updated_date": "2024-08-06 18:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:13:40.632804"
    },
    {
      "arxiv_id": "2408.03388v2",
      "title": "A Non-negative VAE:the Generalized Gamma Belief Network",
      "title_zh": "翻译失败",
      "authors": [
        "Zhibin Duan",
        "Tiansheng Wen",
        "Muyao Wang",
        "Bo Chen",
        "Mingyuan Zhou"
      ],
      "abstract": "The gamma belief network (GBN), often regarded as a deep topic model, has\ndemonstrated its potential for uncovering multi-layer interpretable latent\nrepresentations in text data. Its notable capability to acquire interpretable\nlatent factors is partially attributed to sparse and non-negative\ngamma-distributed latent variables. However, the existing GBN and its\nvariations are constrained by the linear generative model, thereby limiting\ntheir expressiveness and applicability. To address this limitation, we\nintroduce the generalized gamma belief network (Generalized GBN) in this paper,\nwhich extends the original linear generative model to a more expressive\nnon-linear generative model. Since the parameters of the Generalized GBN no\nlonger possess an analytic conditional posterior, we further propose an\nupward-downward Weibull inference network to approximate the posterior\ndistribution of the latent variables. The parameters of both the generative\nmodel and the inference network are jointly trained within the variational\ninference framework. Finally, we conduct comprehensive experiments on both\nexpressivity and disentangled representation learning tasks to evaluate the\nperformance of the Generalized GBN against state-of-the-art Gaussian\nvariational autoencoders serving as baselines.",
      "tldr_zh": "本论文提出 Generalized Gamma Belief Network（Generalized GBN），一种非负变分自编码器（Non-negative VAE），通过将原有的 Gamma Belief Network 的线性生成模型扩展为更具表现力的非线性生成模型，以提升其在文本数据中发现多层可解释潜在表示的能力。针对非线性模型导致的参数无解析条件后验问题，该方法引入 upward-downward Weibull inference network 来近似潜在变量的后验分布，并在变分推理框架下联合训练生成模型和推理网络的参数。实验结果显示，Generalized GBN 在表达性和解耦表示学习任务上优于最先进的 Gaussian 变分自编码器基线，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03388v2",
      "published_date": "2024-08-06 18:18:37 UTC",
      "updated_date": "2024-08-15 04:24:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:13:52.725440"
    },
    {
      "arxiv_id": "2408.03326v3",
      "title": "LLaVA-OneVision: Easy Visual Task Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Li",
        "Yuanhan Zhang",
        "Dong Guo",
        "Renrui Zhang",
        "Feng Li",
        "Hao Zhang",
        "Kaichen Zhang",
        "Peiyuan Zhang",
        "Yanwei Li",
        "Ziwei Liu",
        "Chunyuan Li"
      ],
      "abstract": "We present LLaVA-OneVision, a family of open large multimodal models (LMMs)\ndeveloped by consolidating our insights into data, models, and visual\nrepresentations in the LLaVA-NeXT blog series. Our experimental results\ndemonstrate that LLaVA-OneVision is the first single model that can\nsimultaneously push the performance boundaries of open LMMs in three important\ncomputer vision scenarios: single-image, multi-image, and video scenarios.\nImportantly, the design of LLaVA-OneVision allows strong transfer learning\nacross different modalities/scenarios, yielding new emerging capabilities. In\nparticular, strong video understanding and cross-scenario capabilities are\ndemonstrated through task transfer from images to videos.",
      "tldr_zh": "我们提出了 LLaVA-OneVision，这是一个开源的大型多模态模型（LMMs）家族，通过整合数据、模型和视觉表示的见解，实现轻松的视觉任务转移。实验结果显示，该模型是第一个单一模型，能够同时在单图像、多图像和视频场景中提升性能边界。特别重要的是，其设计支持强大的转移学习，从图像到视频的任务转移，带来新的视频理解和跨场景能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Homepage:\n  https://llava-vl.github.io/blog/2024-08-05-llava-onevision/",
      "pdf_url": "http://arxiv.org/pdf/2408.03326v3",
      "published_date": "2024-08-06 17:59:44 UTC",
      "updated_date": "2024-10-26 16:35:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:14:04.804412"
    },
    {
      "arxiv_id": "2408.03319v1",
      "title": "Training LLMs to Recognize Hedges in Spontaneous Narratives",
      "title_zh": "翻译失败",
      "authors": [
        "Amie J. Paige",
        "Adil Soubki",
        "John Murzaku",
        "Owen Rambow",
        "Susan E. Brennan"
      ],
      "abstract": "Hedges allow speakers to mark utterances as provisional, whether to signal\nnon-prototypicality or \"fuzziness\", to indicate a lack of commitment to an\nutterance, to attribute responsibility for a statement to someone else, to\ninvite input from a partner, or to soften critical feedback in the service of\nface-management needs. Here we focus on hedges in an experimentally\nparameterized corpus of 63 Roadrunner cartoon narratives spontaneously produced\nfrom memory by 21 speakers for co-present addressees, transcribed to text\n(Galati and Brennan, 2010). We created a gold standard of hedges annotated by\nhuman coders (the Roadrunner-Hedge corpus) and compared three LLM-based\napproaches for hedge detection: fine-tuning BERT, and zero and few-shot\nprompting with GPT-4o and LLaMA-3. The best-performing approach was a\nfine-tuned BERT model, followed by few-shot GPT-4o. After an error analysis on\nthe top performing approaches, we used an LLM-in-the-Loop approach to improve\nthe gold standard coding, as well as to highlight cases in which hedges are\nambiguous in linguistically interesting ways that will guide future research.\nThis is the first step in our research program to train LLMs to interpret and\ngenerate collateral signals appropriately and meaningfully in conversation.",
      "tldr_zh": "本研究旨在训练大型语言模型（LLMs）识别 hedges（模糊表达）在自发叙事中的作用，这些表达用于表示不确定性、软化语气或邀请互动。研究者基于一个包含63个Roadrunner卡通叙事的语料库（由21名演讲者讲述），创建了人类标注的金标准语料（Roadrunner-Hedge corpus），并比较了三种LLM方法：微调BERT、零样本和少样本提示（使用GPT-4o和LLaMA-3）。结果显示，微调BERT模型表现最佳，其次是少样本GPT-4o；随后通过错误分析和LLM-in-the-Loop方法改进标注，突出了hedges的模糊性及其在对话中的复杂性。该工作为训练LLMs正确解释和生成对话附带信号奠定了基础，是未来研究的初步步骤。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Amie Paige, Adil Soubki, and John Murzaku contributed equally to this\n  study",
      "pdf_url": "http://arxiv.org/pdf/2408.03319v1",
      "published_date": "2024-08-06 17:51:42 UTC",
      "updated_date": "2024-08-06 17:51:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:14:19.136976"
    },
    {
      "arxiv_id": "2408.03304v1",
      "title": "Fusing Forces: Deep-Human-Guided Refinement of Segmentation Masks",
      "title_zh": "翻译失败",
      "authors": [
        "Rafael Sterzinger",
        "Christian Stippel",
        "Robert Sablatnig"
      ],
      "abstract": "Etruscan mirrors constitute a significant category in Etruscan art,\ncharacterized by elaborate figurative illustrations featured on their backside.\nA laborious and costly aspect of their analysis and documentation is the task\nof manually tracing these illustrations. In previous work, a methodology has\nbeen proposed to automate this process, involving photometric-stereo scanning\nin combination with deep neural networks. While achieving quantitative\nperformance akin to an expert annotator, some results still lack qualitative\nprecision and, thus, require annotators for inspection and potential\ncorrection, maintaining resource intensity. In response, we propose a deep\nneural network trained to interactively refine existing annotations based on\nhuman guidance. Our human-in-the-loop approach streamlines annotation,\nachieving equal quality with up to 75% less manual input required. Moreover,\nduring the refinement process, the relative improvement of our methodology over\npure manual labeling reaches peak values of up to 26%, attaining drastically\nbetter quality quicker. By being tailored to the complex task of segmenting\nintricate lines, specifically distinguishing it from previous methods, our\napproach offers drastic improvements in efficacy, transferable to a broad\nspectrum of applications beyond Etruscan mirrors.",
      "tldr_zh": "该论文针对伊特鲁斯坎镜子（Etruscan mirrors）上复杂图示的追踪任务，提出一种结合深度神经网络（deep neural network）和人类指导的交互式精炼方法，以优化 segmentation masks 的生成。相比之前的 photometric-stereo scanning 和神经网络方法，该 human-in-the-loop 框架在保持标注质量的同时，减少了多达 75% 的手动输入，并在精炼过程中将质量提升多达 26%。这种针对复杂线条分割的创新方法，不仅提高了效率，还可扩展应用于其他领域。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, accepted at ICPR2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03304v1",
      "published_date": "2024-08-06 17:11:40 UTC",
      "updated_date": "2024-08-06 17:11:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:14:30.395919"
    },
    {
      "arxiv_id": "2408.03303v1",
      "title": "Understanding How Blind Users Handle Object Recognition Errors: Strategies and Challenges",
      "title_zh": "理解视力障碍用户如何处理物体识别错误：策略和挑战",
      "authors": [
        "Jonggi Hong",
        "Hernisa Kacorri"
      ],
      "abstract": "Object recognition technologies hold the potential to support blind and\nlow-vision people in navigating the world around them. However, the gap between\nbenchmark performances and practical usability remains a significant challenge.\nThis paper presents a study aimed at understanding blind users' interaction\nwith object recognition systems for identifying and avoiding errors. Leveraging\na pre-existing object recognition system, URCam, fine-tuned for our experiment,\nwe conducted a user study involving 12 blind and low-vision participants.\nThrough in-depth interviews and hands-on error identification tasks, we gained\ninsights into users' experiences, challenges, and strategies for identifying\nerrors in camera-based assistive technologies and object recognition systems.\nDuring interviews, many participants preferred independent error review, while\nexpressing apprehension toward misrecognitions. In the error identification\ntask, participants varied viewpoints, backgrounds, and object sizes in their\nimages to avoid and overcome errors. Even after repeating the task,\nparticipants identified only half of the errors, and the proportion of errors\nidentified did not significantly differ from their first attempts. Based on\nthese insights, we offer implications for designing accessible interfaces\ntailored to the needs of blind and low-vision users in identifying object\nrecognition errors.",
      "tldr_zh": "这篇论文探讨了盲人和低视力用户在使用物体识别系统时，如何处理错误识别的策略和挑战。研究通过对12名参与者的深入访谈和使用URCam系统的动手错误识别任务，揭示了用户偏好独立审查错误，但对误识别表示担忧，并在任务中尝试改变视角、背景和物体大小来克服问题。尽管重复任务，用户仅识别出一半错误，且识别比例未显著改善。论文基于这些发现，为设计针对盲人和低视力用户的可访问界面提供了实用启示，以提升物体识别系统的可用性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03303v1",
      "published_date": "2024-08-06 17:09:56 UTC",
      "updated_date": "2024-08-06 17:09:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:14:42.564832"
    },
    {
      "arxiv_id": "2408.03360v3",
      "title": "Prioritize Alignment in Dataset Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Zekai Li",
        "Ziyao Guo",
        "Wangbo Zhao",
        "Tianle Zhang",
        "Zhi-Qi Cheng",
        "Samir Khaki",
        "Kaipeng Zhang",
        "Ahmad Sajedi",
        "Konstantinos N Plataniotis",
        "Kai Wang",
        "Yang You"
      ],
      "abstract": "Dataset Distillation aims to compress a large dataset into a significantly\nmore compact, synthetic one without compromising the performance of the trained\nmodels. To achieve this, existing methods use the agent model to extract\ninformation from the target dataset and embed it into the distilled dataset.\nConsequently, the quality of extracted and embedded information determines the\nquality of the distilled dataset. In this work, we find that existing methods\nintroduce misaligned information in both information extraction and embedding\nstages. To alleviate this, we propose Prioritize Alignment in Dataset\nDistillation (PAD), which aligns information from the following two\nperspectives. 1) We prune the target dataset according to the compressing ratio\nto filter the information that can be extracted by the agent model. 2) We use\nonly deep layers of the agent model to perform the distillation to avoid\nexcessively introducing low-level information. This simple strategy effectively\nfilters out misaligned information and brings non-trivial improvement for\nmainstream matching-based distillation algorithms. Furthermore, built on\ntrajectory matching, \\textbf{PAD} achieves remarkable improvements on various\nbenchmarks, achieving state-of-the-art performance.",
      "tldr_zh": "这篇论文针对 Dataset Distillation 的问题，提出 Prioritize Alignment in Dataset Distillation (PAD) 方法，以减少信息提取和嵌入过程中的失配。PAD 通过根据压缩比率修剪目标数据集来过滤代理模型无法提取的信息，并仅使用代理模型的深层进行蒸馏，避免引入过多低级信息。这种简单策略显著提升了主流匹配-based 蒸馏算法的性能，并在轨迹匹配基准上实现了 state-of-the-art 水平。总的来说，PAD 提高了合成数据集的质量，促进了高效模型训练。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.03360v3",
      "published_date": "2024-08-06 17:07:28 UTC",
      "updated_date": "2024-10-13 03:24:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:14:53.822994"
    },
    {
      "arxiv_id": "2408.03297v2",
      "title": "KnowPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models",
      "title_zh": "KnowPO：知识感知偏好优化用于检索",
      "authors": [
        "Ruizhe Zhang",
        "Yongxin Xu",
        "Yuzhen Xiao",
        "Runchuan Zhu",
        "Xinke Jiang",
        "Xu Chu",
        "Junfeng Zhao",
        "Yasha Wang"
      ],
      "abstract": "By integrating external knowledge, Retrieval-Augmented Generation (RAG) has\nbecome an effective strategy for mitigating the hallucination problems that\nlarge language models (LLMs) encounter when dealing with knowledge-intensive\ntasks. However, in the process of integrating external non-parametric\nsupporting evidence with internal parametric knowledge, inevitable knowledge\nconflicts may arise, leading to confusion in the model's responses. To enhance\nthe knowledge selection of LLMs in various contexts, some research has focused\non refining their behavior patterns through instruction-tuning. Nonetheless,\ndue to the absence of explicit negative signals and comparative objectives,\nmodels fine-tuned in this manner may still exhibit undesirable behaviors such\nas contextual ignorance and contextual overinclusion. To this end, we propose a\nKnowledge-aware Preference Optimization strategy, dubbed KnowPO, aimed at\nachieving adaptive knowledge selection based on contextual relevance in real\nretrieval scenarios. Concretely, we proposed a general paradigm for\nconstructing knowledge conflict datasets, which comprehensively cover various\nerror types and learn how to avoid these negative signals through preference\noptimization methods. Simultaneously, we proposed a rewriting strategy and data\nratio optimization strategy to address preference imbalances. Experimental\nresults show that KnowPO outperforms previous methods for handling knowledge\nconflicts by over 37\\%, while also exhibiting robust generalization across\nvarious out-of-distribution datasets.",
      "tldr_zh": "本研究针对 Retrieval-Augmented Generation (RAG) 在整合外部知识时可能产生的知识冲突问题，提出了一种 Knowledge-aware Preference Optimization (KnowPO) 策略，以实现基于上下文的相关知识选择。KnowPO 通过构建一个全面覆盖各种错误类型的知识冲突数据集，并利用偏好优化方法学习避免负面信号，同时引入重写策略和数据比例优化策略来解决偏好不平衡问题。实验结果显示，KnowPO 相较于现有方法在处理知识冲突方面提高了 37% 的性能，并展示了在各种分布外数据集上的鲁棒泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03297v2",
      "published_date": "2024-08-06 16:55:54 UTC",
      "updated_date": "2024-08-19 10:38:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:15:06.564175"
    },
    {
      "arxiv_id": "2408.04667v5",
      "title": "Non-Determinism of \"Deterministic\" LLM Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Berk Atil",
        "Sarp Aykent",
        "Alexa Chittams",
        "Lisheng Fu",
        "Rebecca J. Passonneau",
        "Evan Radcliffe",
        "Guru Rajan Rajagopal",
        "Adam Sloan",
        "Tomasz Tudrej",
        "Ferhan Ture",
        "Zhe Wu",
        "Lixinyu Xu",
        "Breck Baldwin"
      ],
      "abstract": "LLM (large language model) practitioners commonly notice that outputs can\nvary for the same inputs under settings expected to be deterministic. Yet the\nquestions of how pervasive this is, and with what impact on results, have not\nto our knowledge been systematically investigated. We investigate\nnon-determinism in five LLMs configured to be deterministic when applied to\neight common tasks in across 10 runs, in both zero-shot and few-shot settings.\nWe see accuracy variations up to 15% across naturally occurring runs with a gap\nof best possible performance to worst possible performance up to 70%. In fact,\nnone of the LLMs consistently delivers repeatable accuracy across all tasks,\nmuch less identical output strings. Sharing preliminary results with insiders\nhas revealed that non-determinism perhaps essential to the efficient use of\ncompute resources via co-mingled data in input buffers so this issue is not\ngoing away anytime soon. To better quantify our observations, we introduce\nmetrics focused on quantifying determinism, TARr@N for the total agreement rate\nat N runs over raw output, and TARa@N for total agreement rate of parsed-out\nanswers. Our code and data are publicly available at\nhttps://github.com/breckbaldwin/llm-stability.",
      "tldr_zh": "该研究调查了即使在“确定性”设置下，大型语言模型(LLM)输出仍可能因相同输入而变化的问题。研究者测试了5个LLM在8个常见任务上的表现，包括零样本和少样本设置，共进行10次运行，结果显示准确率波动可达15%，最佳与最差性能差距高达70%，且无LLM能提供一致的准确率或输出。论文引入了新指标TARr@N（原始输出总一致率）和TARa@N（解析答案总一致率）来量化这种非确定性，并指出其可能源于计算资源高效使用机制；代码和数据已公开以供进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04667v5",
      "published_date": "2024-08-06 16:43:35 UTC",
      "updated_date": "2025-04-02 15:17:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:15:18.433884"
    },
    {
      "arxiv_id": "2408.03292v1",
      "title": "Static IR Drop Prediction with Attention U-Net and Saliency-Based Explainability",
      "title_zh": "翻译失败",
      "authors": [
        "Lizi Zhang",
        "Azadeh Davoodi"
      ],
      "abstract": "There has been significant recent progress to reduce the computational effort\nof static IR drop analysis using neural networks, and modeling as an\nimage-to-image translation task. A crucial issue is the lack of sufficient data\nfrom real industry designs to train these networks. Additionally, there is no\nmethodology to explain a high-drop pixel in a predicted IR drop image to its\nspecific root-causes. In this work, we first propose a U-Net neural network\nmodel with attention gates which is specifically tailored to achieve fast and\naccurate image-based static IR drop prediction. Attention gates allow selective\nemphasis on relevant parts of the input data without supervision which is\ndesired because of the often sparse nature of the IR drop map. We propose a\ntwo-phase training process which utilizes a mix of artificially-generated data\nand a limited number of points from real designs. The results are, on-average,\n18% (53%) better in MAE and 14% (113%) in F1 score compared to the winner of\nthe ICCAD 2023 contest (and U-Net only) when tested on real designs. Second, we\npropose a fast method using saliency maps which can explain a predicted IR drop\nin terms of specific input pixels contributing the most to a drop. In our\nexperiments, we show the number of high IR drop pixels can be reduced\non-average by 18% by mimicking upsize of a tiny portion of PDN's resistive\nedges.",
      "tldr_zh": "这篇论文提出了一种使用 Attention U-Net 神经网络模型来实现快速准确的图像-based 静态 IR 降压预测，该模型通过注意力门选择性强调输入数据的相关部分，以应对数据稀疏性。论文采用两阶段训练过程，结合人工生成数据和少量真实设计点，结果显示在真实设计测试中，模型的 MAE 改善 18%（比 U-Net 仅模型改善 53%），F1 分数改善 14%（比 U-Net 仅模型改善 113%）。此外，论文引入了基于 saliency maps 的快速解释方法，能识别预测 IR 降压的关键输入像素，并通过实验证明，通过模仿部分 PDN 的电阻边上调大，可平均减少 18% 的高 IR 降压像素。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03292v1",
      "published_date": "2024-08-06 16:41:33 UTC",
      "updated_date": "2024-08-06 16:41:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:15:31.455714"
    },
    {
      "arxiv_id": "2408.04666v1",
      "title": "LLMs are Not Just Next Token Predictors",
      "title_zh": "LLMs 不仅仅是下一个 Token 预测器",
      "authors": [
        "Stephen M. Downes",
        "Patrick Forber",
        "Alex Grzankowski"
      ],
      "abstract": "LLMs are statistical models of language learning through stochastic gradient\ndescent with a next token prediction objective. Prompting a popular view among\nAI modelers: LLMs are just next token predictors. While LLMs are engineered\nusing next token prediction, and trained based on their success at this task,\nour view is that a reduction to just next token predictor sells LLMs short.\nMoreover, there are important explanations of LLM behavior and capabilities\nthat are lost when we engage in this kind of reduction. In order to draw this\nout, we will make an analogy with a once prominent research program in biology\nexplaining evolution and development from the gene's eye view.",
      "tldr_zh": "本论文挑战了将大型语言模型（LLMs）简单视为下一个标记预测器的流行观点，虽然LLMs是通过随机梯度下降(stochastic gradient descent)训练以实现下一个标记预测任务。作者认为，这种简化忽略了LLMs的更广泛行为和能力，包括其在解释进化和发展方面的深层机制。论文通过类比生物学中的基因视角研究程序，强调LLMs具有超越基本预测的复杂性，为AI模型的全面理解提供了新框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04666v1",
      "published_date": "2024-08-06 16:36:28 UTC",
      "updated_date": "2024-08-06 16:36:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:15:41.571543"
    },
    {
      "arxiv_id": "2408.03281v2",
      "title": "StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Boxi Cao",
        "Mengjie Ren",
        "Hongyu Lin",
        "Xianpei Han",
        "Feng Zhang",
        "Junfeng Zhan",
        "Le Sun"
      ],
      "abstract": "Evaluation is the baton for the development of large language models. Current\nevaluations typically employ a single-item assessment paradigm for each atomic\ntest objective, which struggles to discern whether a model genuinely possesses\nthe required capabilities or merely memorizes/guesses the answers to specific\nquestions. To this end, we propose a novel evaluation framework referred to as\nStructEval. Starting from an atomic test objective, StructEval deepens and\nbroadens the evaluation by conducting a structured assessment across multiple\ncognitive levels and critical concepts, and therefore offers a comprehensive,\nrobust and consistent evaluation for LLMs. Experiments on three widely-used\nbenchmarks demonstrate that StructEval serves as a reliable tool for resisting\nthe risk of data contamination and reducing the interference of potential\nbiases, thereby providing more reliable and consistent conclusions regarding\nmodel capabilities. Our framework also sheds light on the design of future\nprincipled and trustworthy LLM evaluation protocols.",
      "tldr_zh": "本文提出 StructEval 框架，以解决当前 Large Language Model (LLM) 评估中单一项目评估范式的局限性，该方法无法区分模型的真实能力与记忆或猜测。StructEval 从原子测试目标出发，通过结构化评估跨越多个认知水平和关键概念，提供全面、稳健且一致的 LLM 评估。实验在三个常用基准上证明，该框架能有效抵抗数据污染风险、减少偏差干扰，并为未来可靠的 LLM 评估协议设计提供重要启发。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024;Benchmark at https://github.com/c-box/StructEval\n  ;Leaderboard at https://huggingface.co/spaces/Bowieee/StructEval_leaderboard",
      "pdf_url": "http://arxiv.org/pdf/2408.03281v2",
      "published_date": "2024-08-06 16:28:30 UTC",
      "updated_date": "2024-08-07 01:00:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:15:55.708490"
    },
    {
      "arxiv_id": "2408.03274v1",
      "title": "Compress and Compare: Interactively Evaluating Efficiency and Behavior Across ML Model Compression Experiments",
      "title_zh": "Compress and Compare",
      "authors": [
        "Angie Boggust",
        "Venkatesh Sivaraman",
        "Yannick Assogba",
        "Donghao Ren",
        "Dominik Moritz",
        "Fred Hohman"
      ],
      "abstract": "To deploy machine learning models on-device, practitioners use compression\nalgorithms to shrink and speed up models while maintaining their high-quality\noutput. A critical aspect of compression in practice is model comparison,\nincluding tracking many compression experiments, identifying subtle changes in\nmodel behavior, and negotiating complex accuracy-efficiency trade-offs.\nHowever, existing compression tools poorly support comparison, leading to\ntedious and, sometimes, incomplete analyses spread across disjoint tools. To\nsupport real-world comparative workflows, we develop an interactive visual\nsystem called Compress and Compare. Within a single interface, Compress and\nCompare surfaces promising compression strategies by visualizing provenance\nrelationships between compressed models and reveals compression-induced\nbehavior changes by comparing models' predictions, weights, and activations. We\ndemonstrate how Compress and Compare supports common compression analysis tasks\nthrough two case studies, debugging failed compression on generative language\nmodels and identifying compression artifacts in image classification models. We\nfurther evaluate Compress and Compare in a user study with eight compression\nexperts, illustrating its potential to provide structure to compression\nworkflows, help practitioners build intuition about compression, and encourage\nthorough analysis of compression's effect on model behavior. Through these\nevaluations, we identify compression-specific challenges that future visual\nanalytics tools should consider and Compress and Compare visualizations that\nmay generalize to broader model comparison tasks.",
      "tldr_zh": "该研究针对机器学习（ML）模型压缩中的比较挑战，开发了交互式可视化系统 Compress and Compare，以支持跟踪多个压缩实验、识别模型行为变化，并平衡准确性和效率权衡。该系统在一个界面内可视化压缩模型之间的provenance relationships，并比较模型的predictions、weights和activations，从而揭示压缩诱发的行为变化。通过两个案例研究（包括调试生成语言模型的压缩失败和识别图像分类模型的compression artifacts），以及八位专家的用户研究，证明了该系统能为压缩工作流程提供结构，帮助从业者建立压缩直觉，并鼓励对模型行为影响的彻底分析。该研究还识别了压缩特定的挑战，并建议其可视化方法可能扩展到更广泛的模型比较任务。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to VIS 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03274v1",
      "published_date": "2024-08-06 16:17:51 UTC",
      "updated_date": "2024-08-06 16:17:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:16:12.688958"
    },
    {
      "arxiv_id": "2408.03359v1",
      "title": "LAMPO: Large Language Models as Preference Machines for Few-shot Ordinal Classification",
      "title_zh": "LAMPO：大型语言模型作为偏好机器用于少样本序数分类",
      "authors": [
        "Zhen Qin",
        "Junru Wu",
        "Jiaming Shen",
        "Tianqi Liu",
        "Xuanhui Wang"
      ],
      "abstract": "We introduce LAMPO, a novel paradigm that leverages Large Language Models\n(LLMs) for solving few-shot multi-class ordinal classification tasks. Unlike\nconventional methods, which concatenate all demonstration examples with the\ntest instance and prompt LLMs to produce the pointwise prediction, our\nframework uses the LLM as a preference machine that makes a relative\ncomparative decision between the test instance and each demonstration. A\nself-supervised method is then introduced to aggregate these binary comparisons\ninto the final ordinal decision. LAMPO addresses several limitations inherent\nin previous methods, including context length constraints, ordering biases, and\nchallenges associated with absolute point-wise estimation. Extensive\nexperiments on seven public datasets demonstrate LAMPO's remarkably competitive\nperformance across a diverse spectrum of applications (e.g., movie review\nanalysis and hate speech detection). Notably, in certain applications, the\nimprovement can be substantial, exceeding 20% in an absolute term. Moreover, we\nbelieve LAMPO represents an interesting addition to the non-parametric\napplication layered on top of LLMs, as it supports black-box LLMs without\nnecessitating the outputting of LLM's internal states (e.g., embeddings), as\nseen in previous approaches.",
      "tldr_zh": "我们引入了 LAMPO，一种创新框架，将 Large Language Models (LLMs) 作为偏好机器，用于处理少样本多类序数分类任务。不同于传统方法直接提示 LLMs 进行点预测，LAMPO 通过让 LLMs 在测试实例与每个演示示例之间进行相对比较决策，然后使用自监督方法聚合这些二元比较，以生成最终序数结果，从而克服了上下文长度限制、排序偏差和绝对估计的挑战。在七个公共数据集上的广泛实验中，LAMPO 显示出高度竞争的性能，在某些应用（如电影评论分析和仇恨言论检测）中绝对提升超过 20%。此外，该框架支持黑盒 LLMs，无需输出内部状态（如 embeddings），为非参数 LLM 应用提供了新颖补充。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03359v1",
      "published_date": "2024-08-06 15:55:05 UTC",
      "updated_date": "2024-08-06 15:55:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:16:25.447037"
    },
    {
      "arxiv_id": "2408.11832v2",
      "title": "OpenFactCheck: A Unified Framework for Factuality Evaluation of LLMs",
      "title_zh": "OpenFactCheck：用于评估大型语言模型事实性的统一框架",
      "authors": [
        "Hasan Iqbal",
        "Yuxia Wang",
        "Minghan Wang",
        "Georgi Georgiev",
        "Jiahui Geng",
        "Iryna Gurevych",
        "Preslav Nakov"
      ],
      "abstract": "The increased use of large language models (LLMs) across a variety of\nreal-world applications calls for automatic tools to check the factual accuracy\nof their outputs, as LLMs often hallucinate. This is difficult as it requires\nassessing the factuality of free-form open-domain responses. While there has\nbeen a lot of research on this topic, different papers use different evaluation\nbenchmarks and measures, which makes them hard to compare and hampers future\nprogress. To mitigate these issues, we developed OpenFactCheck, a unified\nframework, with three modules: (i) RESPONSEEVAL, which allows users to easily\ncustomize an automatic fact-checking system and to assess the factuality of all\nclaims in an input document using that system, (ii) LLMEVAL, which assesses the\noverall factuality of an LLM, and (iii) CHECKEREVAL, a module to evaluate\nautomatic fact-checking systems. OpenFactCheck is open-sourced\n(https://github.com/mbzuai-nlp/openfactcheck) and publicly released as a Python\nlibrary (https://pypi.org/project/openfactcheck/) and also as a web service\n(http://app.openfactcheck.com). A video describing the system is available at\nhttps://youtu.be/-i9VKL0HleI.",
      "tldr_zh": "该论文提出 OpenFactCheck，一种统一的框架，用于评估大型语言模型 (LLMs) 的事实准确性，解决 LLMs 常产生的幻觉问题，并统一不同评估基准以便比较。框架包括三个模块：RESPONSEEVAL 允许用户自定义事实检查系统并评估文档中声明的事实性、LLMEVAL 用于整体评估 LLM 的事实性，以及 CHECKEREVAL 用于评估自动事实检查系统。该框架开源发布（包括 GitHub、Python 库和网页服务），有助于标准化和推进 LLMs 事实性评估的研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 4 Figures, 3 Tables, Accepted at EMNLP 2024 System\n  Demonstration. arXiv admin note: substantial text overlap with\n  arXiv:2405.05583",
      "pdf_url": "http://arxiv.org/pdf/2408.11832v2",
      "published_date": "2024-08-06 15:49:58 UTC",
      "updated_date": "2024-11-06 18:07:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:16:36.593212"
    },
    {
      "arxiv_id": "2408.03247v3",
      "title": "Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons",
      "title_zh": "通过知识神经元揭示大型语言模型的事实回忆行为",
      "authors": [
        "Yifei Wang",
        "Yuheng Chen",
        "Wanting Wen",
        "Yu Sheng",
        "Linjing Li",
        "Daniel Dajun Zeng"
      ],
      "abstract": "In this paper, we investigate whether Large Language Models (LLMs) actively\nrecall or retrieve their internal repositories of factual knowledge when faced\nwith reasoning tasks. Through an analysis of LLMs' internal factual recall at\neach reasoning step via Knowledge Neurons, we reveal that LLMs fail to harness\nthe critical factual associations under certain circumstances. Instead, they\ntend to opt for alternative, shortcut-like pathways to answer reasoning\nquestions. By manually manipulating the recall process of parametric knowledge\nin LLMs, we demonstrate that enhancing this recall process directly improves\nreasoning performance whereas suppressing it leads to notable degradation.\nFurthermore, we assess the effect of Chain-of-Thought (CoT) prompting, a\npowerful technique for addressing complex reasoning tasks. Our findings\nindicate that CoT can intensify the recall of factual knowledge by encouraging\nLLMs to engage in orderly and reliable reasoning. Furthermore, we explored how\ncontextual conflicts affect the retrieval of facts during the reasoning process\nto gain a comprehensive understanding of the factual recall behaviors of LLMs.\nCode and data will be available soon.",
      "tldr_zh": "本研究通过分析 Knowledge Neurons，揭示了 Large Language Models (LLMs) 在处理推理任务时的事实回忆行为，发现 LLMs 在某些情况下无法有效利用关键事实关联，而是倾向于采用捷径路径来回答问题。研究者通过手动增强或抑制 LLMs 的参数知识回忆过程，证明增强回忆能直接提升推理性能，而抑制则导致显著下降。此外，Chain-of-Thought (CoT) 提示技术被证实能加强事实知识的回忆，促进有序推理，同时上下文冲突会干扰事实检索，为优化 LLMs 的知识利用提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03247v3",
      "published_date": "2024-08-06 15:07:08 UTC",
      "updated_date": "2024-10-01 01:48:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:16:46.554121"
    },
    {
      "arxiv_id": "2408.04665v2",
      "title": "LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations",
      "title_zh": "基于LLM的MOFs合成条件提取，使用少样本演示",
      "authors": [
        "Lei Shi",
        "Zhimeng Liu",
        "Yi Yang",
        "Weize Wu",
        "Yuyang Zhang",
        "Hongbo Zhang",
        "Jing Lin",
        "Siyu Wu",
        "Zihan Chen",
        "Ruiming Li",
        "Nan Wang",
        "Zipeng Liu",
        "Huobin Tan",
        "Hongyi Gao",
        "Yue Zhang",
        "Ge Wang"
      ],
      "abstract": "The extraction of Metal-Organic Frameworks (MOFs) synthesis route from\nliterature has been crucial for the logical MOFs design with desirable\nfunctionality. The recent advent of large language models (LLMs) provides\ndisruptively new solution to this long-standing problem. While the latest\nresearches mostly stick to primitive zero-shot LLMs lacking specialized\nmaterial knowledge, we introduce in this work the few-shot LLM in-context\nlearning paradigm. First, a human-AI interactive data curation approach is\nproposed to secure high-quality demonstrations. Second, an information\nretrieval algorithm is applied to pick and quantify few-shot demonstrations for\neach extraction. Over three datasets randomly sampled from nearly 90,000\nwell-defined MOFs, we conduct triple evaluations to validate our method. The\nsynthesis extraction, structure inference, and material design performance of\nthe proposed few-shot LLMs all significantly outplay zero-shot LLM and baseline\nmethods. The lab-synthesized material guided by LLM surpasses 91.1%\nhigh-quality MOFs of the same class reported in the literature, on the key\nphysical property of specific surface area.",
      "tldr_zh": "该研究提出了一种基于大型语言模型(LLMs)的少样本(few-shot)演示方法，用于从文献中提取Metal-Organic Frameworks (MOFs)的合成条件，以支持高效的MOFs设计。方法包括人类-AI互动数据整理来创建高质量演示，以及信息检索算法来选择和量化针对每个提取任务的少样本示例。在三个从近90,000个MOFs中随机采样的数据集上进行评估，结果显示，few-shot LLMs在合成提取、结构推断和材料设计方面均优于zero-shot LLMs和基线方法；通过LLM指导合成的材料在比表面积等关键物理属性上超过了文献中同类91.1%的高质量MOFs。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04665v2",
      "published_date": "2024-08-06 14:53:25 UTC",
      "updated_date": "2025-02-25 15:20:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:16:58.771750"
    },
    {
      "arxiv_id": "2408.03358v1",
      "title": "MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis",
      "title_zh": "MLC-GCN：基于多层次生成连接体的图卷积网络用于 AD 分析",
      "authors": [
        "Wenqi Zhu",
        "Yinghua Fu",
        "Ze Wang"
      ],
      "abstract": "Alzheimer's Disease (AD) is a currently incurable neurodegeneartive disease.\nAccurately detecting AD, especially in the early stage, represents a high\nresearch priority. AD is characterized by progressive cognitive impairments\nthat are related to alterations in brain functional connectivity (FC). Based on\nthis association, many studies have been published over the decades using FC\nand machine learning to differentiate AD from healthy aging. The most recent\ndevelopment in this detection method highlights the use of graph neural network\n(GNN) as the brain functionality analysis. In this paper, we proposed a stack\nof spatio-temporal feature extraction and graph generation based AD\nclassification model using resting state fMRI. The proposed multi-level\ngenerated connectome (MLC) based graph convolutional network (GCN) (MLC-GCN)\ncontains a multi-graph generation block and a GCN prediction block. The\nmulti-graph generation block consists of a hierarchy of spatio-temporal feature\nextraction layers for extracting spatio-temporal rsfMRI features at different\ndepths and building the corresponding connectomes. The GCN prediction block\ntakes the learned multi-level connectomes to build and optimize GCNs at each\nlevel and concatenates the learned graphical features as the final predicting\nfeatures for AD classification. Through independent cohort validations, MLC-GCN\nshows better performance for differentiating MCI, AD, and normal aging than\nstate-of-art GCN and rsfMRI based AD classifiers. The proposed MLC-GCN also\nshowed high explainability in terms of learning clinically reasonable\nconnectome node and connectivity features from two independent datasets. While\nwe only tested MLC-GCN on AD, the basic rsfMRI-based multi-level learned GCN\nbased outcome prediction strategy is valid for other diseases or clinical\noutcomes.",
      "tldr_zh": "本文提出 MLC-GCN 模型，用于基于静息态 fMRI (rsfMRI) 分析 Alzheimer's Disease (AD)，通过多层次生成的连接体 (MLC) 和图卷积网络 (GCN) 实现 AD 早期检测。模型包括多图生成块，用于提取不同深度的时空特征并构建多层次连接体，以及 GCN 预测块，通过优化这些连接体进行 AD 分类和特征学习。实验验证显示，MLC-GCN 在区分轻度认知障碍 (MCI)、AD 和正常老化方面比现有 GCN 和 rsfMRI 方法性能更优，并提供高解释性的临床相关特征，可扩展应用于其他疾病预测。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03358v1",
      "published_date": "2024-08-06 14:18:36 UTC",
      "updated_date": "2024-08-06 14:18:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:17:10.724688"
    },
    {
      "arxiv_id": "2408.03208v2",
      "title": "Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery",
      "title_zh": "在机器人手术",
      "authors": [
        "Jialang Xu",
        "Jiacheng Wang",
        "Lequan Yu",
        "Danail Stoyanov",
        "Yueming Jin",
        "Evangelos B. Mazomenos"
      ],
      "abstract": "Personalized federated learning (PFL) for surgical instrument segmentation\n(SIS) is a promising approach. It enables multiple clinical sites to\ncollaboratively train a series of models in privacy, with each model tailored\nto the individual distribution of each site. Existing PFL methods rarely\nconsider the personalization of multi-headed self-attention, and do not account\nfor appearance diversity and instrument shape similarity, both inherent in\nsurgical scenes. We thus propose PFedSIS, a novel PFL method with visual trait\npriors for SIS, incorporating global-personalized disentanglement (GPD),\nappearance-regulation personalized enhancement (APE), and shape-similarity\nglobal enhancement (SGE), to boost SIS performance in each site. GPD represents\nthe first attempt at head-wise assignment for multi-headed self-attention\npersonalization. To preserve the unique appearance representation of each site\nand gradually leverage the inter-site difference, APE introduces appearance\nregulation and provides customized layer-wise aggregation solutions via\nhypernetworks for each site's personalized parameters. The mutual shape\ninformation of instruments is maintained and shared via SGE, which enhances the\ncross-style shape consistency on the image level and computes the\nshape-similarity contribution of each site on the prediction level for updating\nthe global parameters. PFedSIS outperforms state-of-the-art methods with +1.51%\nDice, +2.11% IoU, -2.79 ASSD, -15.55 HD95 performance gains. The corresponding\ncode and models will be released at https://github.com/wzjialang/PFedSIS.",
      "tldr_zh": "本篇论文提出了一种名为 PFedSIS 的新型个性化联邦学习 (PFL) 方法，用于机器人手术中的手术工具分割 (SIS)，旨在通过视觉特征先验处理手术场景的外观多样性和工具形状相似性问题。PFedSIS 包括三个关键组件：GPD (global-personalized disentanglement) 首次实现多头自注意力 (multi-headed self-attention) 的头级分配；APE (appearance-regulation personalized enhancement) 通过外观调控和超网络 (hypernetworks) 提供定制的层级聚合，以保留每个站点的独特外观表示；SGE (shape-similarity global enhancement) 则维护工具形状信息，提升跨风格形状一致性和全局参数更新。实验结果显示，PFedSIS 相比现有方法在 Dice、IoU、ASSD 和 HD95 指标上分别提升 1.51%、2.11%、降低 2.79 和 15.55，显著提高了分割性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO",
        "physics.med-ph"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 3 figures, under review",
      "pdf_url": "http://arxiv.org/pdf/2408.03208v2",
      "published_date": "2024-08-06 14:06:53 UTC",
      "updated_date": "2024-08-15 19:57:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:17:25.472852"
    },
    {
      "arxiv_id": "2408.03200v2",
      "title": "Adversarial Safety-Critical Scenario Generation using Naturalistic Human Driving Priors",
      "title_zh": "基于自然主义人类驾驶先验的对抗性安全关键场景生成",
      "authors": [
        "Kunkun Hao",
        "Yonggang Luo",
        "Wen Cui",
        "Yuqiao Bai",
        "Jucheng Yang",
        "Songyang Yan",
        "Yuxi Pan",
        "Zijiang Yang"
      ],
      "abstract": "Evaluating the decision-making system is indispensable in developing\nautonomous vehicles, while realistic and challenging safety-critical test\nscenarios play a crucial role. Obtaining these scenarios is non-trivial, thanks\nto the long-tailed distribution, sparsity, and rarity in real-world data sets.\nTo tackle this problem, in this paper, we introduce a natural adversarial\nscenario generation solution using naturalistic human driving priors and\nreinforcement learning techniques. By doing this, we can obtain large-scale\ntest scenarios that are both diverse and realistic. Specifically, we build a\nsimulation environment that mimics natural traffic interaction scenarios.\nInformed by this environment, we implement a two-stage procedure. The first\nstage incorporates conventional rule-based models, e.g., IDM~(Intelligent\nDriver Model) and MOBIL~(Minimizing Overall Braking Induced by Lane changes)\nmodel, to coarsely and discretely capture and calibrate key control parameters\nfrom the real-world dataset. Next, we leverage GAIL~(Generative Adversarial\nImitation Learning) to represent driver behaviors continuously. The derived\nGAIL can be further used to design a PPO~(Proximal Policy Optimization)-based\nactor-critic network framework to fine-tune the reward function, and then\noptimizes our natural adversarial scenario generation solution. Extensive\nexperiments have been conducted in the NGSIM dataset including the trajectory\nof 3,000 vehicles. Essential traffic parameters were measured in comparison\nwith the baseline model, e.g., the collision rate, accelerations, steering, and\nthe number of lane changes. Our findings demonstrate that the proposed model\ncan generate realistic safety-critical test scenarios covering both naturalness\nand adversariality, which can be a cornerstone for the development of\nautonomous vehicles.",
      "tldr_zh": "本文提出一种利用自然驾驶先验和强化学习技术生成对抗安全关键场景的方法，旨在解决真实世界数据中安全测试场景稀缺的问题，以评估自动驾驶车辆的决策系统。具体而言，该方法采用两阶段流程：首先使用规则-based 模型如 IDM 和 MOBIL 从真实数据集捕获关键控制参数；其次应用 GAIL 表示驾驶行为，并通过 PPO 优化奖励函数生成大规模、真实且多样的测试场景。在 NGSIM 数据集上的实验显示，该模型生成的场景在碰撞率、加速度、转向和变道次数等方面显著优于基线模型，为自动驾驶车辆开发奠定坚实基础。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Published in IEEE Transactions on Intelligent Vehicles, 2023",
      "pdf_url": "http://arxiv.org/pdf/2408.03200v2",
      "published_date": "2024-08-06 13:58:56 UTC",
      "updated_date": "2024-08-07 02:14:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:17:34.563851"
    },
    {
      "arxiv_id": "2408.03168v1",
      "title": "Training on the Fly: On-device Self-supervised Learning aboard Nano-drones within 20 mW",
      "title_zh": "翻译失败",
      "authors": [
        "Elia Cereda",
        "Alessandro Giusti",
        "Daniele Palossi"
      ],
      "abstract": "Miniaturized cyber-physical systems (CPSes) powered by tiny machine learning\n(TinyML), such as nano-drones, are becoming an increasingly attractive\ntechnology. Their small form factor (i.e., ~10cm diameter) ensures vast\napplicability, ranging from the exploration of narrow disaster scenarios to\nsafe human-robot interaction. Simple electronics make these CPSes inexpensive,\nbut strongly limit the computational, memory, and sensing resources available\non board. In real-world applications, these limitations are further exacerbated\nby domain shift. This fundamental machine learning problem implies that model\nperception performance drops when moving from the training domain to a\ndifferent deployment one. To cope with and mitigate this general problem, we\npresent a novel on-device fine-tuning approach that relies only on the limited\nultra-low power resources available aboard nano-drones. Then, to overcome the\nlack of ground-truth training labels aboard our CPS, we also employ a\nself-supervised method based on ego-motion consistency. Albeit our work builds\non top of a specific real-world vision-based human pose estimation task, it is\nwidely applicable for many embedded TinyML use cases. Our 512-image on-device\ntraining procedure is fully deployed aboard an ultra-low power GWT GAP9\nSystem-on-Chip and requires only 1MB of memory while consuming as low as 19mW\nor running in just 510ms (at 38mW). Finally, we demonstrate the benefits of our\non-device learning approach by field-testing our closed-loop CPS, showing a\nreduction in horizontal position error of up to 26% vs. a non-fine-tuned\nstate-of-the-art baseline. In the most challenging never-seen-before\nenvironment, our on-device learning procedure makes the difference between\nsucceeding or failing the mission.",
      "tldr_zh": "该研究针对资源受限的纳米无人机等小型化网络物理系统（CPSes），提出了一种低功耗的设备上自监督学习方法，以应对领域偏移导致的模型性能下降问题。该方法利用基于自我运动一致性的自监督微调技术，仅依赖于无人机上的超低功耗资源（如 GWT GAP9 系统-on-Chip），在 512 图像训练中只需 1MB 内存和低至 19mW 功耗，或在 510ms 内完成。实验结果显示，在视觉人体姿势估计任务的实地测试中，该方法使水平位置误差减少多达 26%，并在从未见过的环境中显著提升任务成功率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper has been accepted for publication in the IEEE Transactions\n  on Computer-Aided Design of Integrated Circuits and Systems. Copyright 2024\n  IEEE",
      "pdf_url": "http://arxiv.org/pdf/2408.03168v1",
      "published_date": "2024-08-06 13:11:36 UTC",
      "updated_date": "2024-08-06 13:11:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:17:48.132738"
    },
    {
      "arxiv_id": "2408.03164v1",
      "title": "Dilated Convolution with Learnable Spacings makes visual models more aligned with humans: a Grad-CAM study",
      "title_zh": "翻译失败",
      "authors": [
        "Rabih Chamas",
        "Ismail Khalfaoui-Hassani",
        "Timothee Masquelier"
      ],
      "abstract": "Dilated Convolution with Learnable Spacing (DCLS) is a recent advanced\nconvolution method that allows enlarging the receptive fields (RF) without\nincreasing the number of parameters, like the dilated convolution, yet without\nimposing a regular grid. DCLS has been shown to outperform the standard and\ndilated convolutions on several computer vision benchmarks. Here, we show that,\nin addition, DCLS increases the models' interpretability, defined as the\nalignment with human visual strategies. To quantify it, we use the Spearman\ncorrelation between the models' GradCAM heatmaps and the ClickMe dataset\nheatmaps, which reflect human visual attention. We took eight reference models\n- ResNet50, ConvNeXt (T, S and B), CAFormer, ConvFormer, and FastViT (sa 24 and\n36) - and drop-in replaced the standard convolution layers with DCLS ones. This\nimproved the interpretability score in seven of them. Moreover, we observed\nthat Grad-CAM generated random heatmaps for two models in our study: CAFormer\nand ConvFormer models, leading to low interpretability scores. We addressed\nthis issue by introducing Threshold-Grad-CAM, a modification built on top of\nGrad-CAM that enhanced interpretability across nearly all models. The code and\ncheckpoints to reproduce this study are available at:\nhttps://github.com/rabihchamas/DCLS-GradCAM-Eval.",
      "tldr_zh": "本文研究了 DCLS（Dilated Convolution with Learnable Spacings），一种高级卷积方法，能扩大感受野而不增加参数，并证明它提升了视觉模型的可解释性，使模型更符合人类视觉策略。作者使用 Spearman 相关性量化模型的 Grad-CAM 热图与 ClickMe 数据集热图的 alignment，实验中将 DCLS 替换到八个参考模型（如 ResNet50 和 ConvNeXt）中，七个模型的可解释性分数得到改善。针对 CAFormer 和 ConvFormer 模型的 Grad-CAM 随机问题，引入了 Threshold-Grad-CAM 改进，进一步增强了整体可解释性，并提供了可复现代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at The Trustworthy AI Workshop, IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03164v1",
      "published_date": "2024-08-06 13:05:32 UTC",
      "updated_date": "2024-08-06 13:05:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:17:58.618229"
    },
    {
      "arxiv_id": "2408.03125v1",
      "title": "COMMENTATOR: A Code-mixed Multilingual Text Annotation Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Rajvee Sheth",
        "Shubh Nisar",
        "Heenaben Prajapati",
        "Himanshu Beniwal",
        "Mayank Singh"
      ],
      "abstract": "As the NLP community increasingly addresses challenges associated with\nmultilingualism, robust annotation tools are essential to handle multilingual\ndatasets efficiently. In this paper, we introduce a code-mixed multilingual\ntext annotation framework, COMMENTATOR, specifically designed for annotating\ncode-mixed text. The tool demonstrates its effectiveness in token-level and\nsentence-level language annotation tasks for Hinglish text. We perform robust\nqualitative human-based evaluations to showcase COMMENTATOR led to 5x faster\nannotations than the best baseline. Our code is publicly available at\n\\url{https://github.com/lingo-iitgn/commentator}. The demonstration video is\navailable at \\url{https://bit.ly/commentator_video}.",
      "tldr_zh": "本研究引入了 COMMENTATOR，一种专为代码混合多语言文本设计的标注框架，旨在高效处理多语言数据集中的代码混合内容，如 Hinglish。框架支持 token-level 和 sentence-level 的语言标注任务，通过优化设计使标注过程比最佳基线快 5 倍。实验基于定性人类评估，证明了 COMMENTATOR 在处理多语言挑战方面的有效性，并提供开源代码（https://github.com/lingo-iitgn/commentator）和演示视频（https://bit.ly/commentator_video）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03125v1",
      "published_date": "2024-08-06 11:56:26 UTC",
      "updated_date": "2024-08-06 11:56:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:18:10.506846"
    },
    {
      "arxiv_id": "2408.03119v1",
      "title": "Evaluating the Translation Performance of Large Language Models Based on Euas-20",
      "title_zh": "基于 Euas-20 评估大型语言模型的翻译性能",
      "authors": [
        "Yan Huang",
        "Wei Liu"
      ],
      "abstract": "In recent years, with the rapid development of deep learning technology,\nlarge language models (LLMs) such as BERT and GPT have achieved breakthrough\nresults in natural language processing tasks. Machine translation (MT), as one\nof the core tasks of natural language processing, has also benefited from the\ndevelopment of large language models and achieved a qualitative leap. Despite\nthe significant progress in translation performance achieved by large language\nmodels, machine translation still faces many challenges. Therefore, in this\npaper, we construct the dataset Euas-20 to evaluate the performance of large\nlanguage models on translation tasks, the translation ability on different\nlanguages, and the effect of pre-training data on the translation ability of\nLLMs for researchers and developers.",
      "tldr_zh": "本论文评估了大型语言模型(LLMs)如BERT和GPT在机器翻译(MT)任务中的性能，背景是这些模型在自然语言处理领域取得了突破性进展，但MT仍面临诸多挑战。研究者构建了Euas-20数据集，用于测试LLMs的翻译能力，包括不同语言的翻译表现以及预训练数据对翻译能力的影响。该数据集为研究者和开发者提供了工具，帮助深入分析LLMs的优缺点，并推动MT技术的改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.03119v1",
      "published_date": "2024-08-06 11:49:11 UTC",
      "updated_date": "2024-08-06 11:49:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:18:23.505857"
    },
    {
      "arxiv_id": "2408.03093v5",
      "title": "Certifiably Robust Policies for Uncertain Parametric Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Yannik Schnitzer",
        "Alessandro Abate",
        "David Parker"
      ],
      "abstract": "We present a data-driven approach for producing policies that are provably\nrobust across unknown stochastic environments. Existing approaches can learn\nmodels of a single environment as an interval Markov decision processes (IMDP)\nand produce a robust policy with a probably approximately correct (PAC)\nguarantee on its performance. However these are unable to reason about the\nimpact of environmental parameters underlying the uncertainty. We propose a\nframework based on parametric Markov decision processes (MDPs) with unknown\ndistributions over parameters. We learn and analyse IMDPs for a set of unknown\nsample environments induced by parameters. The key challenge is then to produce\nmeaningful performance guarantees that combine the two layers of uncertainty:\n(1) multiple environments induced by parameters with an unknown distribution;\n(2) unknown induced environments which are approximated by IMDPs. We present a\nnovel approach based on scenario optimisation that yields a single PAC\nguarantee quantifying the risk level for which a specified performance level\ncan be assured in unseen environments, plus a means to trade-off risk and\nperformance. We implement and evaluate our framework using multiple robust\npolicy generation methods on a range of benchmarks. We show that our approach\nproduces tight bounds on a policy's performance with high confidence.",
      "tldr_zh": "这篇论文提出了一种数据驱动框架，用于生成在不确定参数环境下的可证实的鲁棒策略，以应对现有方法的局限性，即Interval Markov Decision Processes (IMDP) 无法处理环境参数不确定性。框架基于Parametric Markov Decision Processes (MDPs)，通过学习多个未知样本环境的IMDP并应用场景优化方法，来处理两层不确定性：参数诱导的环境分布和环境的IMDP近似。关键贡献是提供一个Probably Approximately Correct (PAC) 保证，量化策略在未见环境中的性能风险水平，并允许风险与性能的权衡。实验在多个基准上验证了该方法，能够产生高置信度的紧密性能边界。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03093v5",
      "published_date": "2024-08-06 10:48:15 UTC",
      "updated_date": "2025-03-23 12:24:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:18:36.213902"
    },
    {
      "arxiv_id": "2408.03088v1",
      "title": "QADQN: Quantum Attention Deep Q-Network for Financial Market Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Siddhant Dutta",
        "Nouhaila Innan",
        "Alberto Marchisio",
        "Sadok Ben Yahia",
        "Muhammad Shafique"
      ],
      "abstract": "Financial market prediction and optimal trading strategy development remain\nchallenging due to market complexity and volatility. Our research in quantum\nfinance and reinforcement learning for decision-making demonstrates the\napproach of quantum-classical hybrid algorithms to tackling real-world\nfinancial challenges. In this respect, we corroborate the concept with rigorous\nbacktesting and validate the framework's performance under realistic market\nconditions, by including fixed transaction cost per trade. This paper\nintroduces a Quantum Attention Deep Q-Network (QADQN) approach to address these\nchallenges through quantum-enhanced reinforcement learning. Our QADQN\narchitecture uses a variational quantum circuit inside a traditional deep\nQ-learning framework to take advantage of possible quantum advantages in\ndecision-making. We gauge the QADQN agent's performance on historical data from\nmajor market indices, including the S&P 500. We evaluate the agent's learning\nprocess by examining its reward accumulation and the effectiveness of its\nexperience replay mechanism. Our empirical results demonstrate the QADQN's\nsuperior performance, achieving better risk-adjusted returns with Sortino\nratios of 1.28 and 1.19 for non-overlapping and overlapping test periods\nrespectively, indicating effective downside risk management.",
      "tldr_zh": "该研究提出了一种 Quantum Attention Deep Q-Network (QADQN) 方法，结合量子计算和强化学习(reinforcement learning)，旨在应对金融市场预测的复杂性和波动性。QADQN 框架将变分量子电路(variational quantum circuit)整合到传统的深度 Q 学习结构中，利用量子优势提升决策过程，并在历史数据如 S&P 500 上进行严格回测，包括固定交易成本。实验结果显示，QADQN 实现了优异的风险调整回报，Sortino ratios 分别为 1.28 和 1.19，证明其在 downside 风险管理方面的有效性。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "Accepted at the 2024 IEEE International Conference on Quantum\n  Computing and Engineering (QCE24), QCRL, September 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03088v1",
      "published_date": "2024-08-06 10:41:46 UTC",
      "updated_date": "2024-08-06 10:41:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:18:47.416675"
    },
    {
      "arxiv_id": "2408.03079v1",
      "title": "Enhancing Complex Causality Extraction via Improved Subtask Interaction and Knowledge Fusion",
      "title_zh": "通过改进的子任务交互和知识融合增强复杂因果关系提取",
      "authors": [
        "Jinglong Gao",
        "Chen Lu",
        "Xiao Ding",
        "Zhongyang Li",
        "Ting Liu",
        "Bing Qin"
      ],
      "abstract": "Event Causality Extraction (ECE) aims at extracting causal event pairs from\ntexts. Despite ChatGPT's recent success, fine-tuning small models remains the\nbest approach for the ECE task. However, existing fine-tuning based ECE methods\ncannot address all three key challenges in ECE simultaneously: 1) Complex\nCausality Extraction, where multiple causal-effect pairs occur within a single\nsentence; 2) Subtask~ Interaction, which involves modeling the mutual\ndependence between the two subtasks of ECE, i.e., extracting events and\nidentifying the causal relationship between extracted events; and 3) Knowledge\nFusion, which requires effectively fusing the knowledge in two modalities,\ni.e., the expressive pretrained language models and the structured knowledge\ngraphs. In this paper, we propose a unified ECE framework (UniCE to address all\nthree issues in ECE simultaneously. Specifically, we design a subtask\ninteraction mechanism to enable mutual interaction between the two ECE\nsubtasks. Besides, we design a knowledge fusion mechanism to fuse knowledge in\nthe two modalities. Furthermore, we employ separate decoders for each subtask\nto facilitate complex causality extraction. Experiments on three benchmark\ndatasets demonstrate that our method achieves state-of-the-art performance and\noutperforms ChatGPT with a margin of at least 30% F1-score. More importantly,\nour model can also be used to effectively improve the ECE performance of\nChatGPT via in-context learning.",
      "tldr_zh": "本文提出一个统一的框架 UniCE，用于提升事件因果关系提取 (ECE)，以同时解决复杂因果提取、子任务交互和知识融合的三大挑战。UniCE 通过设计子任务交互机制（建模事件提取与因果关系识别的相互依赖）、知识融合机制（融合预训练语言模型和知识图谱的知识），并采用单独解码器来处理复杂因果对。实验在三个基准数据集上表明，该方法达到最先进性能，比 ChatGPT 高出至少 30% 的 F1-score，并可通过 in-context learning 有效提升 ChatGPT 的 ECE 表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NLPCC 2024 Oral",
      "pdf_url": "http://arxiv.org/pdf/2408.03079v1",
      "published_date": "2024-08-06 10:15:15 UTC",
      "updated_date": "2024-08-06 10:15:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:19:00.963297"
    },
    {
      "arxiv_id": "2408.03078v2",
      "title": "BodySLAM: A Generalized Monocular Visual SLAM Framework for Surgical Applications",
      "title_zh": "翻译失败",
      "authors": [
        "G. Manni",
        "C. Lauretti",
        "F. Prata",
        "R. Papalia",
        "L. Zollo",
        "P. Soda"
      ],
      "abstract": "Endoscopic surgery relies on two-dimensional views, posing challenges for\nsurgeons in depth perception and instrument manipulation. While Monocular\nVisual Simultaneous Localization and Mapping (MVSLAM) has emerged as a\npromising solution, its implementation in endoscopic procedures faces\nsignificant challenges due to hardware limitations, such as the use of a\nmonocular camera and the absence of odometry sensors. This study presents\nBodySLAM, a robust deep learning-based MVSLAM approach that addresses these\nchallenges through three key components: CycleVO, a novel unsupervised\nmonocular pose estimation module; the integration of the state-of-the-art Zoe\narchitecture for monocular depth estimation; and a 3D reconstruction module\ncreating a coherent surgical map. The approach is rigorously evaluated using\nthree publicly available datasets (Hamlyn, EndoSLAM, and SCARED) spanning\nlaparoscopy, gastroscopy, and colonoscopy scenarios, and benchmarked against\nfour state-of-the-art methods. Results demonstrate that CycleVO exhibited\ncompetitive performance with the lowest inference time among pose estimation\nmethods, while maintaining robust generalization capabilities, whereas Zoe\nsignificantly outperformed existing algorithms for depth estimation in\nendoscopy. BodySLAM's strong performance across diverse endoscopic scenarios\ndemonstrates its potential as a viable MVSLAM solution for endoscopic\napplications.",
      "tldr_zh": "本研究针对内窥镜手术中二维视图导致的深度感知和仪器操作挑战，提出BodySLAM，一个通用的基于深度学习的单目视觉SLAM (MVSLAM) 框架。该框架包括三个关键组件：CycleVO，一个新型的无监督单目姿态估计模块；Zoe架构用于单目深度估计；以及一个3D重建模块来生成连贯的手术地图。实验在Hamlyn、EndoSLAM和SCARED数据集上进行，与四种最先进方法比较，结果显示CycleVO在姿态估计中表现出色，具有最低推理时间和强泛化能力，而Zoe在深度估计中显著优于现有算法，BodySLAM整体在多种内窥镜场景中表现出强劲性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.03078v2",
      "published_date": "2024-08-06 10:13:57 UTC",
      "updated_date": "2024-11-04 12:19:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:19:12.490228"
    },
    {
      "arxiv_id": "2408.03076v1",
      "title": "Solving QUBO on the Loihi 2 Neuromorphic Processor",
      "title_zh": "翻译失败",
      "authors": [
        "Alessandro Pierro",
        "Philipp Stratmann",
        "Gabriel Andres Fonseca Guerra",
        "Sumedh Risbud",
        "Timothy Shea",
        "Ashish Rao Mangalore",
        "Andreas Wild"
      ],
      "abstract": "In this article, we describe an algorithm for solving Quadratic Unconstrained\nBinary Optimization problems on the Intel Loihi 2 neuromorphic processor. The\nsolver is based on a hardware-aware fine-grained parallel simulated annealing\nalgorithm developed for Intel's neuromorphic research chip Loihi 2. Preliminary\nresults show that our approach can generate feasible solutions in as little as\n1 ms and up to 37x more energy efficient compared to two baseline solvers\nrunning on a CPU. These advantages could be especially relevant for size-,\nweight-, and power-constrained edge computing applications.",
      "tldr_zh": "这篇论文提出了一种基于硬件感知的细粒度并行模拟退火算法，用于在 Intel Loihi 2 神经形态处理器上解决 QUBO（Quadratic Unconstrained Binary Optimization）问题。算法充分利用 Loihi 2 的特性，能在 1 ms 内生成可行解决方案，并比 CPU 上的两个基线求解器节能高达 37 倍。这些优势使该方法特别适合尺寸、重量和功耗受限的边缘计算应用。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.DM",
        "I.2.8, G.2.1, C.1.4"
      ],
      "primary_category": "cs.NE",
      "comment": "12 pages, 3 figures. Shared first authorship: Alessandro Pierro,\n  Philipp Stratmann, and Gabriel Andres Fonseca Guerra",
      "pdf_url": "http://arxiv.org/pdf/2408.03076v1",
      "published_date": "2024-08-06 10:07:43 UTC",
      "updated_date": "2024-08-06 10:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:19:23.388358"
    },
    {
      "arxiv_id": "2408.03354v3",
      "title": "The Use of Large Language Models (LLM) for Cyber Threat Intelligence (CTI) in Cybercrime Forums",
      "title_zh": "翻译失败",
      "authors": [
        "Vanessa Clairoux-Trepanier",
        "Isa-May Beauchamp",
        "Estelle Ruellan",
        "Masarah Paquet-Clouston",
        "Serge-Olivier Paquette",
        "Eric Clay"
      ],
      "abstract": "Large language models (LLMs) can be used to analyze cyber threat intelligence\n(CTI) data from cybercrime forums, which contain extensive information and key\ndiscussions about emerging cyber threats. However, to date, the level of\naccuracy and efficiency of LLMs for such critical tasks has yet to be\nthoroughly evaluated. Hence, this study assesses the performance of an LLM\nsystem built on the OpenAI GPT-3.5-turbo model [8] to extract CTI information.\nTo do so, a random sample of more than 700 daily conversations from three\ncybercrime forums - XSS, Exploit_in, and RAMP - was extracted, and the LLM\nsystem was instructed to summarize the conversations and predict 10 key CTI\nvariables, such as whether a large organization and/or a critical\ninfrastructure is being targeted, with only simple human-language instructions.\nThen, two coders reviewed each conversation and evaluated whether the\ninformation extracted by the LLM was accurate. The LLM system performed well,\nwith an average accuracy score of 96.23%, an average precision of 90% and an\naverage recall of 88.2%. Various ways to enhance the model were uncovered, such\nas the need to help the LLM distinguish between stories and past events, as\nwell as being careful with verb tenses in prompts. Nevertheless, the results of\nthis study highlight the relevance of using LLMs for cyber threat intelligence.",
      "tldr_zh": "本研究评估了大型语言模型 (LLM) 在网络威胁情报 (CTI) 领域的应用，具体使用 OpenAI 的 GPT-3.5-turbo 模型分析来自 XSS、Exploit_in 和 RAMP 等网络犯罪论坛的超过 700 个对话样本，以总结对话并预测 10 个关键 CTI 变量，如目标组织的类型。结果显示，模型的平均准确率达 96.23%，精确率 90%，召回率 88.2%，证明了其在提取 CTI 信息方面的效率和可靠性。论文还提出了改进建议，例如帮助模型区分故事与过去事件，并注意提示中的动词时态，从而突显了 LLM 在增强网络威胁情报分析中的潜在价值。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03354v3",
      "published_date": "2024-08-06 09:15:25 UTC",
      "updated_date": "2024-10-01 15:41:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:19:36.253818"
    },
    {
      "arxiv_id": "2408.03047v2",
      "title": "OpenOmni: A Collaborative Open Source Tool for Building Future-Ready Multimodal Conversational Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Qiang Sun",
        "Yuanyi Luo",
        "Sirui Li",
        "Wenxiao Zhang",
        "Wei Liu"
      ],
      "abstract": "Multimodal conversational agents are highly desirable because they offer\nnatural and human-like interaction. However, there is a lack of comprehensive\nend-to-end solutions to support collaborative development and benchmarking.\nWhile proprietary systems like GPT-4o and Gemini demonstrating impressive\nintegration of audio, video, and text with response times of 200-250ms,\nchallenges remain in balancing latency, accuracy, cost, and data privacy. To\nbetter understand and quantify these issues, we developed OpenOmni, an\nopen-source, end-to-end pipeline benchmarking tool that integrates advanced\ntechnologies such as Speech-to-Text, Emotion Detection, Retrieval Augmented\nGeneration, Large Language Models, along with the ability to integrate\ncustomized models. OpenOmni supports local and cloud deployment, ensuring data\nprivacy and supporting latency and accuracy benchmarking. This flexible\nframework allows researchers to customize the pipeline, focusing on real\nbottlenecks and facilitating rapid proof-of-concept development. OpenOmni can\nsignificantly enhance applications like indoor assistance for visually impaired\nindividuals, advancing human-computer interaction. Our demonstration video is\navailable https://www.youtube.com/watch?v=zaSiT3clWqY, demo is available via\nhttps://openomni.ai4wa.com, code is available via\nhttps://github.com/AI4WA/OpenOmniFramework.",
      "tldr_zh": "该论文介绍了 OpenOmni，一种开源协作工具，旨在解决多模态对话代理开发中的端到端解决方案缺失问题，特别是平衡延迟、准确性、成本和数据隐私的挑战。OpenOmni 集成了先进技术如 Speech-to-Text、Emotion Detection、Retrieval Augmented Generation 和 Large Language Models，提供灵活的管道基准测试，支持本地和云部署。研究人员可以通过该框架自定义模型，专注于实际瓶颈，实现快速概念验证，并应用于如辅助视力受损者的室内交互场景中。总的来说，OpenOmni 促进了多模态对话代理的开发和优化，推动了人机交互的进步。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "Published in Proceedings of the 2024 Conference on Empirical Methods\n  in Natural Language Processing: System Demonstrations (EMNLP 2024) Best Demo\n  Paper Award at EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03047v2",
      "published_date": "2024-08-06 09:02:53 UTC",
      "updated_date": "2024-11-17 02:53:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:19:48.780233"
    },
    {
      "arxiv_id": "2408.03353v2",
      "title": "Adversarial Domain Adaptation for Cross-user Activity Recognition Using Diffusion-based Noise-centred Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaozhou Ye",
        "Kevin I-Kai Wang"
      ],
      "abstract": "Human Activity Recognition (HAR) plays a crucial role in various applications\nsuch as human-computer interaction and healthcare monitoring. However,\nchallenges persist in HAR models due to the data distribution differences\nbetween training and real-world data distributions, particularly evident in\ncross-user scenarios. This paper introduces a novel framework, termed\nDiffusion-based Noise-centered Adversarial Learning Domain Adaptation\n(Diff-Noise-Adv-DA), designed to address these challenges by leveraging\ngenerative diffusion modeling and adversarial learning techniques. Traditional\nHAR models often struggle with the diversity of user behaviors and sensor data\ndistributions. Diff-Noise-Adv-DA innovatively integrates the inherent noise\nwithin diffusion models, harnessing its latent information to enhance domain\nadaptation. Specifically, the framework transforms noise into a critical\ncarrier of activity and domain class information, facilitating robust\nclassification across different user domains. Experimental evaluations\ndemonstrate the effectiveness of Diff-Noise-Adv-DA in improving HAR model\nperformance across different users, surpassing traditional domain adaptation\nmethods. The framework not only mitigates distribution mismatches but also\nenhances data quality through noise-based denoising techniques.",
      "tldr_zh": "本论文针对 Human Activity Recognition (HAR) 在跨用户场景中的数据分布差异问题，提出了一种创新框架 Diff-Noise-Adv-DA，通过整合生成扩散模型和对抗学习技术来提升模型适应性。该框架巧妙地利用扩散模型中的噪声作为活动和领域类信息的载体，实现更 robust 的分类和域适应。实验结果表明，Diff-Noise-Adv-DA 优于传统方法，提高了 HAR 模型在不同用户间的性能，并通过噪声-based 去噪技术改善了数据质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03353v2",
      "published_date": "2024-08-06 08:55:49 UTC",
      "updated_date": "2024-08-31 23:33:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:19:59.244934"
    },
    {
      "arxiv_id": "2408.03029v4",
      "title": "Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haozhe Ma",
        "Zhengding Luo",
        "Thanh Vinh Vo",
        "Kuankuan Sima",
        "Tze-Yun Leong"
      ],
      "abstract": "Reward shaping is a technique in reinforcement learning that addresses the\nsparse-reward problem by providing more frequent and informative rewards. We\nintroduce a self-adaptive and highly efficient reward shaping mechanism that\nincorporates success rates derived from historical experiences as shaped\nrewards. The success rates are sampled from Beta distributions, which\ndynamically evolve from uncertain to reliable values as data accumulates.\nInitially, the shaped rewards exhibit more randomness to encourage exploration,\nwhile over time, the increasing certainty enhances exploitation, naturally\nbalancing exploration and exploitation. Our approach employs Kernel Density\nEstimation (KDE) combined with Random Fourier Features (RFF) to derive the Beta\ndistributions, providing a computationally efficient, non-parametric, and\nlearning-free solution for high-dimensional continuous state spaces. Our method\nis validated on various tasks with extremely sparse rewards, demonstrating\nnotable improvements in sample efficiency and convergence stability over\nrelevant baselines.",
      "tldr_zh": "该论文提出了一种高效的自适应奖励整形机制，用于解决强化学习中的稀疏奖励问题，通过利用历史经验的成功率从 Beta 分布采样来提供更频繁且信息丰富的奖励。该机制初始时引入更多随机性以鼓励探索，随着数据积累成功率变得更可靠，从而自然平衡探索与利用。具体地，该方法结合 Kernel Density Estimation (KDE) 和 Random Fourier Features (RFF)，提供一种计算高效、非参数且免学习的解决方案，适用于高维连续状态空间。在各种极端稀疏奖励任务上实验验证，显示了显著的样本效率和收敛稳定性改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03029v4",
      "published_date": "2024-08-06 08:22:16 UTC",
      "updated_date": "2025-02-28 12:21:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:20:13.117719"
    },
    {
      "arxiv_id": "2408.04664v1",
      "title": "Mitigating Hallucinations in Large Vision-Language Models (LVLMs) via Language-Contrastive Decoding (LCD)",
      "title_zh": "翻译失败",
      "authors": [
        "Avshalom Manevich",
        "Reut Tsarfaty"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) are an extension of Large Language\nModels (LLMs) that facilitate processing both image and text inputs, expanding\nAI capabilities. However, LVLMs struggle with object hallucinations due to\ntheir reliance on text cues and learned object co-occurrence biases. While most\nresearch quantifies these hallucinations, mitigation strategies are still\nlacking. Our study introduces a Language Contrastive Decoding (LCD) algorithm\nthat adjusts LVLM outputs based on LLM distribution confidence levels,\neffectively reducing object hallucinations. We demonstrate the advantages of\nLCD in leading LVLMs, showing up to %4 improvement in POPE F1 scores and up to\n%36 reduction in CHAIR scores on the COCO validation set, while also improving\ncaptioning quality scores. Our method effectively improves LVLMs without\nneeding complex post-processing or retraining, and is easily applicable to\ndifferent models. Our findings highlight the potential of further exploration\nof LVLM-specific decoding algorithms.",
      "tldr_zh": "本研究针对 Large Vision-Language Models (LVLMs) 中因文本提示和对象共现偏差导致的对象幻觉问题，提出 Language-Contrastive Decoding (LCD) 算法，通过调整 LVLM 输出基于 LLM 分布的置信度来有效缓解幻觉。\nLCD 方法无需复杂后处理或重新训练，即可适用于不同模型，提升模型的整体性能。\n实验结果显示，在 COCO 验证集上，LCD 使 POPE F1 分数提高高达 4%，CHAIR 分数减少高达 36%，并改善了标题质量评分。\n这项工作强调了进一步探索 LVLM 特定解码算法的潜力，为减少幻觉提供了一个高效策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04664v1",
      "published_date": "2024-08-06 08:10:34 UTC",
      "updated_date": "2024-08-06 08:10:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:20:26.973720"
    },
    {
      "arxiv_id": "2408.04663v1",
      "title": "Dopamin: Transformer-based Comment Classifiers through Domain Post-Training and Multi-level Layer Aggregation",
      "title_zh": "翻译失败",
      "authors": [
        "Nam Le Hai",
        "Nghi D. Q. Bui"
      ],
      "abstract": "Code comments provide important information for understanding the source\ncode. They can help developers understand the overall purpose of a function or\nclass, as well as identify bugs and technical debt. However, an overabundance\nof comments is meaningless and counterproductive. As a result, it is critical\nto automatically filter out these comments for specific purposes. In this\npaper, we present Dopamin, a Transformer-based tool for dealing with this\nissue. Our model excels not only in presenting knowledge sharing of common\ncategories across multiple languages, but also in achieving robust performance\nin comment classification by improving comment representation. As a result, it\noutperforms the STACC baseline by 3% on the NLBSE'24 Tool Competition dataset\nin terms of average F1-score, while maintaining a comparable inference time for\npractical use. The source code is publicity available at\nhttps://github.com/FSoft-AI4Code/Dopamin.",
      "tldr_zh": "本研究提出Dopamin，一种基于Transformer的代码评论分类器，通过Domain Post-Training和Multi-level Layer Aggregation改进评论表示，以自动过滤无意义的代码注释。Dopamin不仅支持多语言的知识共享，还在NLBSE'24 Tool Competition数据集上实现了稳健性能，与STACC基线相比，平均F1-score提高了3%，同时保持相似的推理时间。该工具的源代码已公开在GitHub上，可供进一步应用和验证。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at The 3rd Intl. Workshop on NL-based Software Engineering,\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2408.04663v1",
      "published_date": "2024-08-06 08:08:43 UTC",
      "updated_date": "2024-08-06 08:08:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:20:35.781940"
    },
    {
      "arxiv_id": "2408.03018v1",
      "title": "Integrating Controllable Motion Skills from Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Honghao Liao",
        "Zhiheng Li",
        "Ziyu Meng",
        "Ran Song",
        "Yibin Li",
        "Wei Zhang"
      ],
      "abstract": "The expanding applications of legged robots require their mastery of\nversatile motion skills. Correspondingly, researchers must address the\nchallenge of integrating multiple diverse motion skills into controllers. While\nexisting reinforcement learning (RL)-based approaches have achieved notable\nsuccess in multi-skill integration for legged robots, these methods often\nrequire intricate reward engineering or are restricted to integrating a\npredefined set of motion skills constrained by specific task objectives,\nresulting in limited flexibility. In this work, we introduce a flexible\nmulti-skill integration framework named Controllable Skills Integration (CSI).\nCSI enables the integration of a diverse set of motion skills with varying\nstyles into a single policy without the need for complex reward tuning.\nFurthermore, in a hierarchical control manner, the trained low-level policy can\nbe coupled with a high-level Natural Language Inference (NLI) module to enable\npreliminary language-directed skill control. Our experiments demonstrate that\nCSI can flexibly integrate a diverse array of motion skills more\ncomprehensively and facilitate the transitions between different skills.\nAdditionally, CSI exhibits good scalability as the number of motion skills to\nbe integrated increases significantly.",
      "tldr_zh": "本文提出 Controllable Skills Integration (CSI) 框架，用于将多种风格的运动技能整合到腿部机器人的控制器中，解决现有 Reinforcement Learning (RL) 方法依赖复杂奖励工程或技能集限制的问题。CSI 允许在单一策略中灵活整合多样技能，并通过分层控制将低级策略与高级 Natural Language Inference (NLI) 模块结合，实现语言指导的技能控制。实验结果表明，CSI 能更全面地促进技能间转换，并在技能数量增加时表现出良好的可扩展性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03018v1",
      "published_date": "2024-08-06 08:01:02 UTC",
      "updated_date": "2024-08-06 08:01:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:20:48.437013"
    },
    {
      "arxiv_id": "2408.03013v2",
      "title": "NeurDB: On the Design and Implementation of an AI-powered Autonomous Database",
      "title_zh": "NeurDB：关于AI驱动自治数据库的设计和实现",
      "authors": [
        "Zhanhao Zhao",
        "Shaofeng Cai",
        "Haotian Gao",
        "Hexiang Pan",
        "Siqi Xiang",
        "Naili Xing",
        "Gang Chen",
        "Beng Chin Ooi",
        "Yanyan Shen",
        "Yuncheng Wu",
        "Meihui Zhang"
      ],
      "abstract": "Databases are increasingly embracing AI to provide autonomous system\noptimization and intelligent in-database analytics, aiming to relieve end-user\nburdens across various industry sectors. Nonetheless, most existing approaches\nfail to account for the dynamic nature of databases, which renders them\nineffective for real-world applications characterized by evolving data and\nworkloads. This paper introduces NeurDB, an AI-powered autonomous database that\ndeepens the fusion of AI and databases with adaptability to data and workload\ndrift. NeurDB establishes a new in-database AI ecosystem that seamlessly\nintegrates AI workflows within the database. This integration enables efficient\nand effective in-database AI analytics and fast-adaptive learned system\ncomponents. Empirical evaluations demonstrate that NeurDB substantially\noutperforms existing solutions in managing AI analytics tasks, with the\nproposed learned components more effectively handling environmental dynamism\nthan state-of-the-art approaches.",
      "tldr_zh": "本论文介绍了NeurDB，一种AI驱动的自主数据库，旨在解决现有方法无法适应数据库动态变化（如数据和负载漂移）的问题。\nNeurDB通过建立数据库内AI生态系统，无缝集成AI工作流和快速适应的学习组件，实现高效的数据库内AI分析和系统优化。\n实验评估表明，NeurDB在AI分析任务上显著优于现有解决方案，其学习组件更有效地处理环境动态变化。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03013v2",
      "published_date": "2024-08-06 07:48:51 UTC",
      "updated_date": "2025-01-05 01:52:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:21:00.294175"
    },
    {
      "arxiv_id": "2408.03003v1",
      "title": "Cross-cultural analysis of pedestrian group behaviour influence on crossing decisions in interactions with autonomous vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Sergio Martín Serrano",
        "Óscar Méndez Blanco",
        "Stewart Worrall",
        "Miguel Ángel Sotelo",
        "David Fernández-Llorca"
      ],
      "abstract": "Understanding cultural backgrounds is crucial for the seamless integration of\nautonomous driving into daily life as it ensures that systems are attuned to\ndiverse societal norms and behaviours, enhancing acceptance and safety in\nvaried cultural contexts. In this work, we investigate the impact of co-located\npedestrians on crossing behaviour, considering cultural and situational\nfactors. To accomplish this, a full-scale virtual reality (VR) environment was\ncreated in the CARLA simulator, enabling the identical experiment to be\nreplicated in both Spain and Australia. Participants (N=30) attempted to cross\nthe road at an urban crosswalk alongside other pedestrians exhibiting\nconservative to more daring behaviours, while an autonomous vehicle (AV)\napproached with different driving styles. For the analysis of interactions, we\nutilized questionnaires and direct measures of the moment when participants\nentered the lane.\n  Our findings indicate that pedestrians tend to cross the same traffic gap\ntogether, even though reckless behaviour by the group reduces confidence and\nmakes the situation perceived as more complex. Australian participants were\nwilling to take fewer risks than Spanish participants, adopting more cautious\nbehaviour when it was uncertain whether the AV would yield.",
      "tldr_zh": "这篇论文探讨了文化背景对行人群体行为及其与自动车辆(AV)互动中过马路决定的影响，强调理解文化差异有助于提升自动驾驶系统的接受度和安全性。研究采用CARLA模拟器中的全规模VR环境，在西班牙和澳大利亚重复实验(N=30)，让参与者与行为从保守到大胆的行人一起穿越人行横道，同时AV以不同驾驶风格接近，并通过问卷和直接测量分析互动。结果表明，行人倾向于共同穿越同一交通间隙，但群体的鲁莽行为会降低信心并增加感知复杂度，且澳大利亚参与者比西班牙参与者更谨慎，尤其在不确定AV是否让行时。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Paper accepted at the 27th IEEE International Conference on\n  Intelligent Transportation Systems (ITSC 2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.03003v1",
      "published_date": "2024-08-06 07:28:59 UTC",
      "updated_date": "2024-08-06 07:28:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:21:14.413981"
    },
    {
      "arxiv_id": "2408.02999v1",
      "title": "LLMs as Probabilistic Minimally Adequate Teachers for DFA Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Lekai Chen",
        "Ashutosh Trivedi",
        "Alvaro Velasquez"
      ],
      "abstract": "The emergence of intelligence in large language models (LLMs) has inspired\ninvestigations into their integration into automata learning. This paper\nintroduces the probabilistic Minimally Adequate Teacher (pMAT) formulation,\nwhich leverages a probabilistic oracle that could give persistent errors\nrandomly during answering the membership queries for deterministic finite\nautomata (DFA) learning. Given the tendency of LLMs to produce hallucinatory\ncontent, we have developed techniques to improve answer accuracy and ensure the\ncorrectness of the learned automata. We propose the $\\mathtt{Discrimination}$\nprompt as well as the $\\mathtt{Verification}$ prompt and explore their\nadvantages over common prompts. Additionally, we compare DFA learning\nperformance between the TTT algorithm and common active learning algorithms. To\naddress the exponential number of persistent errors, we implement a dynamic\nquery cache refinement algorithm that identifies and corrects conflicting\nqueries by combining the active and passive learning algorithms. The empirical\nresults demonstrate the robustness and efficiency of our approach, providing a\ntheoretical foundation for automata learning with LLMs in the loop.",
      "tldr_zh": "这篇论文提出将大型语言模型 (LLMs) 整合到确定性有限自动机 (DFA) 学习中，通过引入 probabilistic Minimally Adequate Teacher (pMAT) 公式来处理 LLMs 在回答成员查询时可能出现的随机持久错误。研究开发了 $\\mathtt{Discrimination}$ 提示和 $\\mathtt{Verification}$ 提示，以提高答案准确性和确保学习自动机的正确性，并比较了 TTT 算法与其他主动学习算法的性能。针对指数级错误，论文实现了动态查询缓存精炼算法，结合主动和被动学习来识别并纠正冲突查询；实证结果证明了该方法的稳健性和效率，为 LLMs 参与自动机学习提供了理论基础。",
      "categories": [
        "cs.FL",
        "cs.AI"
      ],
      "primary_category": "cs.FL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02999v1",
      "published_date": "2024-08-06 07:12:09 UTC",
      "updated_date": "2024-08-06 07:12:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:21:26.615933"
    },
    {
      "arxiv_id": "2408.02978v1",
      "title": "ASR-enhanced Multimodal Representation Learning for Cross-Domain Product Retrieval",
      "title_zh": "ASR 增强的多模态表示学习用于跨域产品检索",
      "authors": [
        "Ruixiang Zhao",
        "Jian Jia",
        "Yan Li",
        "Xuehan Bai",
        "Quan Chen",
        "Han Li",
        "Peng Jiang",
        "Xirong Li"
      ],
      "abstract": "E-commerce is increasingly multimedia-enriched, with products exhibited in a\nbroad-domain manner as images, short videos, or live stream promotions. A\nunified and vectorized cross-domain production representation is essential. Due\nto large intra-product variance and high inter-product similarity in the\nbroad-domain scenario, a visual-only representation is inadequate. While\nAutomatic Speech Recognition (ASR) text derived from the short or live-stream\nvideos is readily accessible, how to de-noise the excessively noisy text for\nmultimodal representation learning is mostly untouched. We propose ASR-enhanced\nMultimodal Product Representation Learning (AMPere). In order to extract\nproduct-specific information from the raw ASR text, AMPere uses an\neasy-to-implement LLM-based ASR text summarizer. The LLM-summarized text,\ntogether with visual data, is then fed into a multi-branch network to generate\ncompact multimodal embeddings. Extensive experiments on a large-scale\ntri-domain dataset verify the effectiveness of AMPere in obtaining a unified\nmultimodal product representation that clearly improves cross-domain product\nretrieval.",
      "tldr_zh": "这篇论文针对电子商务的多媒体产品表示问题，提出了一种ASR-enhanced Multimodal Representation Learning（AMPere）方法，以改善跨域产品检索。AMPere使用LLM-based ASR文本总结器从嘈杂的ASR文本中提取产品特定信息，并将其与视觉数据结合，输入多分支网络生成紧凑的多模态嵌入。实验结果显示，在大规模三域数据集上，该方法显著提升了跨域产品检索的性能，验证了其统一产品表示的有效性。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.MM",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.02978v1",
      "published_date": "2024-08-06 06:24:10 UTC",
      "updated_date": "2024-08-06 06:24:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:21:36.503115"
    },
    {
      "arxiv_id": "2408.02976v3",
      "title": "Empathy Level Alignment via Reinforcement Learning for Empathetic Response Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hui Ma",
        "Bo Zhang",
        "Bo Xu",
        "Jian Wang",
        "Hongfei Lin",
        "Xiao Sun"
      ],
      "abstract": "Empathetic response generation, aiming to understand the user's situation and\nfeelings and respond empathically, is crucial in building human-like dialogue\nsystems. Traditional approaches typically employ maximum likelihood estimation\nas the optimization objective during training, yet fail to align the empathy\nlevels between generated and target responses. To this end, we propose an\nempathetic response generation framework using reinforcement learning (EmpRL).\nThe framework develops an effective empathy reward function and generates\nempathetic responses by maximizing the expected reward through reinforcement\nlearning. EmpRL utilizes the pre-trained T5 model as the generator and further\nfine-tunes it to initialize the policy. To align the empathy levels between\ngenerated and target responses within a given context, an empathy reward\nfunction containing three empathy communication mechanisms -- emotional\nreaction, interpretation, and exploration -- is constructed using pre-designed\nand pre-trained empathy identifiers. During reinforcement learning training,\nthe proximal policy optimization algorithm is used to fine-tune the policy,\nenabling the generation of empathetic responses. Both automatic and human\nevaluations demonstrate that the proposed EmpRL framework significantly\nimproves the quality of generated responses, enhances the similarity in empathy\nlevels between generated and target responses, and produces empathetic\nresponses covering both affective and cognitive aspects.",
      "tldr_zh": "该研究针对同理心响应生成（Empathetic Response Generation）的问题，提出了一种基于强化学习（Reinforcement Learning）的框架EmpRL，以对齐生成响应和目标响应的同理心水平。框架使用预训练的T5模型作为生成器进行初始化，并构建了一个包含情感反应（Emotional Reaction）、解释（Interpretation）和探索（Exploration）三机制的同理心奖励函数（Empathy Reward Function），通过近端策略优化算法（Proximal Policy Optimization）微调策略以最大化预期奖励。实验结果显示，EmpRL显著提升了响应质量，提高了同理心水平相似性，并兼顾情感和认知方面。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by IEEE Transactions on Affective Computing",
      "pdf_url": "http://arxiv.org/pdf/2408.02976v3",
      "published_date": "2024-08-06 06:16:00 UTC",
      "updated_date": "2025-03-02 08:30:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:21:49.737998"
    },
    {
      "arxiv_id": "2408.02960v2",
      "title": "Anytime Multi-Agent Path Finding with an Adaptive Delay-Based Heuristic",
      "title_zh": "自适应延迟基启发式的随时多智能体路径寻找",
      "authors": [
        "Thomy Phan",
        "Benran Zhang",
        "Shao-Hung Chan",
        "Sven Koenig"
      ],
      "abstract": "Anytime multi-agent path finding (MAPF) is a promising approach to scalable\npath optimization in multi-agent systems. MAPF-LNS, based on Large Neighborhood\nSearch (LNS), is the current state-of-the-art approach where a fast initial\nsolution is iteratively optimized by destroying and repairing selected paths of\nthe solution. Current MAPF-LNS variants commonly use an adaptive selection\nmechanism to choose among multiple destroy heuristics. However, to determine\npromising destroy heuristics, MAPF-LNS requires a considerable amount of\nexploration time. As common destroy heuristics are non-adaptive, any\nperformance bottleneck caused by these heuristics cannot be overcome via\nadaptive heuristic selection alone, thus limiting the overall effectiveness of\nMAPF-LNS in terms of solution cost. In this paper, we propose Adaptive\nDelay-based Destroy-and-Repair Enhanced with Success-based Self-Learning\n(ADDRESS) as a single-destroy-heuristic variant of MAPF-LNS. ADDRESS applies\nrestricted Thompson Sampling to the top-K set of the most delayed agents to\nselect a seed agent for adaptive LNS neighborhood generation. We evaluate\nADDRESS in multiple maps from the MAPF benchmark set and demonstrate cost\nimprovements by at least 50% in large-scale scenarios with up to a thousand\nagents, compared with the original MAPF-LNS and other state-of-the-art methods.",
      "tldr_zh": "该论文提出了一种改进的多智能体路径寻找(Anytime Multi-Agent Path Finding, MAPF)算法，针对当前基于Large Neighborhood Search (LNS)的MAPF-LNS方法在探索时间和性能瓶颈上的不足。作者引入了Adaptive Delay-based Destroy-and-Repair Enhanced with Success-based Self-Learning (ADDRESS)作为单一破坏启发式变体，利用restricted Thompson Sampling在最延迟代理的top-K集合中选择种子代理，以实现自适应LNS邻域生成。该方法在MAPF基准集的多个地图上进行评估，结果显示在多达一千代理的大型场景中，ADDRESS比原MAPF-LNS和其他状态-of-the-art方法至少提高了50%的路径成本优化。总的来说，该研究提升了MAPF的可扩展性和效率，为大规模多智能体系统路径规划提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.02960v2",
      "published_date": "2024-08-06 05:15:35 UTC",
      "updated_date": "2024-12-17 17:29:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:22:02.065123"
    },
    {
      "arxiv_id": "2408.02949v1",
      "title": "Few-shot Scooping Under Domain Shift via Simulated Maximal Deployment Gaps",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Zhu",
        "Pranay Thangeda",
        "Erica L Tevere",
        "Ashish Goel",
        "Erik Kramer",
        "Hari D Nayar",
        "Melkior Ornik",
        "Kris Hauser"
      ],
      "abstract": "Autonomous lander missions on extraterrestrial bodies need to sample granular\nmaterials while coping with domain shifts, even when sampling strategies are\nextensively tuned on Earth. To tackle this challenge, this paper studies the\nfew-shot scooping problem and proposes a vision-based adaptive scooping\nstrategy that uses the deep kernel Gaussian process method trained with a novel\nmeta-training strategy to learn online from very limited experience on\nout-of-distribution target terrains. Our Deep Kernel Calibration with Maximal\nDeployment Gaps (kCMD) strategy explicitly trains a deep kernel model to adapt\nto large domain shifts by creating simulated maximal deployment gaps from an\noffline training dataset and training models to overcome these deployment gaps\nduring training. Employed in a Bayesian Optimization sequential decision-making\nframework, the proposed method allows the robot to perform high-quality\nscooping actions on out-of-distribution terrains after a few attempts,\nsignificantly outperforming non-adaptive methods proposed in the excavation\nliterature as well as other state-of-the-art meta-learning methods. The\nproposed method also demonstrates zero-shot transfer capability, successfully\nadapting to the NASA OWLAT platform, which serves as a state-of-the-art\nsimulator for potential future planetary missions. These results demonstrate\nthe potential of training deep models with simulated deployment gaps for more\ngeneralizable meta-learning in high-capacity models. Furthermore, they\nhighlight the promise of our method in autonomous lander sampling missions by\nenabling landers to overcome the deployment gap between Earth and\nextraterrestrial bodies.",
      "tldr_zh": "该论文研究了在领域转移(domain shift)下进行few-shot scooping的挑战，提出了一种基于视觉的适应性采样策略，使用deep kernel Gaussian process方法结合新型meta-training策略，从有限经验中在线学习适应out-of-distribution目标地形。核心贡献是Deep Kernel Calibration with Maximal Deployment Gaps (kCMD)方法，通过从离线数据集创建模拟的最大部署差距，并在Bayesian Optimization框架中训练模型来克服这些差距，从而显著提升机器人在新地形的采样性能。实验结果显示，该方法在几次尝试后 outperform 其他meta-learning方法，并在NASA OWLAT平台上实现zero-shot transfer，证明了其在自主着陆器采样任务中的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2303.02893",
      "pdf_url": "http://arxiv.org/pdf/2408.02949v1",
      "published_date": "2024-08-06 04:25:09 UTC",
      "updated_date": "2024-08-06 04:25:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:22:17.565988"
    },
    {
      "arxiv_id": "2408.02946v5",
      "title": "Data Poisoning in LLMs: Jailbreak-Tuning and Scaling Laws",
      "title_zh": "翻译失败",
      "authors": [
        "Dillon Bowen",
        "Brendan Murphy",
        "Will Cai",
        "David Khachaturov",
        "Adam Gleave",
        "Kellin Pelrine"
      ],
      "abstract": "LLMs produce harmful and undesirable behavior when trained on poisoned\ndatasets that contain a small fraction of corrupted or harmful data. We develop\na new attack paradigm, jailbreak-tuning, that combines data poisoning with\njailbreaking to fully bypass state-of-the-art safeguards and make models like\nGPT-4o comply with nearly any harmful request. Our experiments suggest this\nattack represents a paradigm shift in vulnerability elicitation, producing\ndifferences in refusal rates as much as 60+ percentage points compared to\nnormal fine-tuning. Given this demonstration of how data poisoning\nvulnerabilities persist and can be amplified, we investigate whether these\nrisks will likely increase as models scale. We evaluate three threat models -\nmalicious fine-tuning, imperfect data curation, and intentional data\ncontamination - across 24 frontier LLMs ranging from 1.5 to 72 billion\nparameters. Our experiments reveal that larger LLMs are significantly more\nsusceptible to data poisoning, learning harmful behaviors from even minimal\nexposure to harmful data more quickly than smaller models. These findings\nunderscore the need for leading AI companies to thoroughly red team fine-tuning\nAPIs before public release and to develop more robust safeguards against data\npoisoning, particularly as models continue to scale in size and capability.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）中的数据中毒（data poisoning）风险，提出了一种新攻击方法 jailbreak-tuning，将数据中毒与越狱（jailbreaking）结合，能完全绕过现有安全机制，使模型如 GPT-4o 响应几乎所有有害请求，导致拒绝率比普通微调降低 60% 以上。研究者评估了三种威胁模型（恶意微调、不完美数据 curation 和故意数据污染）在 24 个前沿 LLMs（参数从 1.5B 到 72B）上的表现，发现更大规模的模型更容易从微量有害数据中快速学习有害行为。论文强调，随着模型规模和能力的增长，AI 公司需加强 red teaming 测试微调 API，并开发更robust的防护措施以缓解这些风险。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02946v5",
      "published_date": "2024-08-06 04:14:29 UTC",
      "updated_date": "2024-12-27 17:40:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:22:30.918024"
    },
    {
      "arxiv_id": "2408.02944v1",
      "title": "LLM-Empowered Resource Allocation in Wireless Communications Systems",
      "title_zh": "LLM 赋能的无线通信系统资源分配",
      "authors": [
        "Woongsup Lee",
        "Jeonghun Park"
      ],
      "abstract": "The recent success of large language models (LLMs) has spurred their\napplication in various fields. In particular, there have been efforts to\nintegrate LLMs into various aspects of wireless communication systems. The use\nof LLMs in wireless communication systems has the potential to realize\nartificial general intelligence (AGI)-enabled wireless networks. In this paper,\nwe investigate an LLM-based resource allocation scheme for wireless\ncommunication systems. Specifically, we formulate a simple resource allocation\nproblem involving two transmit pairs and develop an LLM-based resource\nallocation approach that aims to maximize either energy efficiency or spectral\nefficiency. Additionally, we consider the joint use of low-complexity resource\nallocation techniques to compensate for the reliability shortcomings of the\nLLM-based scheme. After confirming the applicability and feasibility of\nLLM-based resource allocation, we address several key technical challenges that\nremain in applying LLMs in practice.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLM)在无线通信系统中的应用，旨在实现人工智能通用智能(AGI)支持的网络。研究者提出了一种基于LLM的资源分配方案，针对一个涉及两个传输对的简单问题，开发方法来最大化能量效率或频谱效率，并结合低复杂度技术来提升方案的可靠性。实验验证了LLM在资源分配中的可行性，同时指出了实际应用中的关键技术挑战，如可靠性不足和优化需求。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "eess.SP",
      "comment": "submitted to possible IEEE journal",
      "pdf_url": "http://arxiv.org/pdf/2408.02944v1",
      "published_date": "2024-08-06 04:08:26 UTC",
      "updated_date": "2024-08-06 04:08:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:22:39.684834"
    },
    {
      "arxiv_id": "2408.02932v2",
      "title": "Doubly Stochastic Adaptive Neighbors Clustering via the Marcus Mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Jinghui Yuan",
        "Chusheng Zeng",
        "Fangyuan Xie",
        "Zhe Cao",
        "Mulin Chen",
        "Rong Wang",
        "Feiping Nie",
        "Yuan Yuan"
      ],
      "abstract": "Clustering is a fundamental task in machine learning and data science, and\nsimilarity graph-based clustering is an important approach within this domain.\nDoubly stochastic symmetric similarity graphs provide numerous benefits for\nclustering problems and downstream tasks, yet learning such graphs remains a\nsignificant challenge. Marcus theorem states that a strictly positive symmetric\nmatrix can be transformed into a doubly stochastic symmetric matrix by diagonal\nmatrices. However, in clustering, learning sparse matrices is crucial for\ncomputational efficiency. We extend Marcus theorem by proposing the Marcus\nmapping, which indicates that certain sparse matrices can also be transformed\ninto doubly stochastic symmetric matrices via diagonal matrices. Additionally,\nwe introduce rank constraints into the clustering problem and propose the\nDoubly Stochastic Adaptive Neighbors Clustering algorithm based on the Marcus\nMapping (ANCMM). This ensures that the learned graph naturally divides into the\ndesired number of clusters. We validate the effectiveness of our algorithm\nthrough extensive comparisons with state-of-the-art algorithms. Finally, we\nexplore the relationship between the Marcus mapping and optimal transport. We\nprove that the Marcus mapping solves a specific type of optimal transport\nproblem and demonstrate that solving this problem through Marcus mapping is\nmore efficient than directly applying optimal transport methods.",
      "tldr_zh": "本文提出Marcus Mapping作为对Marcus定理的扩展，用于将某些稀疏矩阵通过对角矩阵转换为doubly stochastic symmetric矩阵，从而解决基于相似图的聚类问题。作者引入rank constraints，并开发了Doubly Stochastic Adaptive Neighbors Clustering算法(ANCMM)，该算法能确保学到的图自然分为预设的聚类数，并提高了计算效率。通过广泛实验，ANCMM在性能上优于现有最先进算法。此外，研究证明Marcus Mapping能高效解决特定类型的optimal transport问题，比直接应用optimal transport方法更具优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02932v2",
      "published_date": "2024-08-06 03:34:43 UTC",
      "updated_date": "2024-08-12 09:48:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:23:02.084990"
    },
    {
      "arxiv_id": "2408.02930v1",
      "title": "The Need for a Big World Simulator: A Scientific Challenge for Continual Learning",
      "title_zh": "大世界模拟器的需求：持续学习",
      "authors": [
        "Saurabh Kumar",
        "Hong Jun Jeon",
        "Alex Lewandowski",
        "Benjamin Van Roy"
      ],
      "abstract": "The \"small agent, big world\" frame offers a conceptual view that motivates\nthe need for continual learning. The idea is that a small agent operating in a\nmuch bigger world cannot store all information that the world has to offer. To\nperform well, the agent must be carefully designed to ingest, retain, and eject\nthe right information. To enable the development of performant continual\nlearning agents, a number of synthetic environments have been proposed.\nHowever, these benchmarks suffer from limitations, including unnatural\ndistribution shifts and a lack of fidelity to the \"small agent, big world\"\nframing. This paper aims to formalize two desiderata for the design of future\nsimulated environments. These two criteria aim to reflect the objectives and\ncomplexity of continual learning in practical settings while enabling rapid\nprototyping of algorithms on a smaller scale.",
      "tldr_zh": "这篇论文讨论了“small agent, big world”框架在持续学习（continual learning）中的重要性，强调小型代理在庞大世界中无法存储所有信息，因此需要设计出能够有效摄取、保留和丢弃信息的代理。该框架突显了现有合成环境基准的局限性，如不自然的分布偏移和对核心框架的低保真度，从而阻碍了实际应用的开发。论文正式化了两个设计期望（desiderata），旨在为未来模拟环境提供指导，以反映真实持续学习的复杂性，同时支持小规模的算法快速原型设计。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the Finding the Frame Workshop at RLC 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.02930v1",
      "published_date": "2024-08-06 03:26:01 UTC",
      "updated_date": "2024-08-06 03:26:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:23:12.296405"
    },
    {
      "arxiv_id": "2408.02927v1",
      "title": "HARMONIC: Harnessing LLMs for Tabular Data Synthesis and Privacy Protection",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxin Wang",
        "Duanyu Feng",
        "Yongfu Dai",
        "Zhengyu Chen",
        "Jimin Huang",
        "Sophia Ananiadou",
        "Qianqian Xie",
        "Hao Wang"
      ],
      "abstract": "Data serves as the fundamental foundation for advancing deep learning,\nparticularly tabular data presented in a structured format, which is highly\nconducive to modeling. However, even in the era of LLM, obtaining tabular data\nfrom sensitive domains remains a challenge due to privacy or copyright\nconcerns. Hence, exploring how to effectively use models like LLMs to generate\nrealistic and privacy-preserving synthetic tabular data is urgent. In this\npaper, we take a step forward to explore LLMs for tabular data synthesis and\nprivacy protection, by introducing a new framework HARMONIC for tabular data\ngeneration and evaluation. In the tabular data generation of our framework,\nunlike previous small-scale LLM-based methods that rely on continued\npre-training, we explore the larger-scale LLMs with fine-tuning to generate\ntabular data and enhance privacy. Based on idea of the k-nearest neighbors\nalgorithm, an instruction fine-tuning dataset is constructed to inspire LLMs to\ndiscover inter-row relationships. Then, with fine-tuning, LLMs are trained to\nremember the format and connections of the data rather than the data itself,\nwhich reduces the risk of privacy leakage. In the evaluation part of our\nframework, we develop specific privacy risk metrics DLT for LLM synthetic data\ngeneration, as well as performance evaluation metrics LLE for downstream LLM\ntasks. Our experiments find that this tabular data generation framework\nachieves equivalent performance to existing methods with better privacy, which\nalso demonstrates our evaluation framework for the effectiveness of synthetic\ndata and privacy risks in LLM scenarios.",
      "tldr_zh": "该研究提出 HARMONIC 框架，利用大型语言模型 (LLMs) 生成合成表格数据，同时增强隐私保护，以解决敏感领域数据获取的挑战。框架通过基于 k-nearest neighbors 算法构建的指令微调数据集，训练 LLMs 发现行间关系，并专注于记住数据格式和连接而非具体内容，从而降低隐私泄露风险。在评估方面，引入隐私风险指标 DLT 和下游任务性能指标 LLE，实验结果显示 HARMONIC 在性能上与现有方法相当，但隐私保护更优。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02927v1",
      "published_date": "2024-08-06 03:21:13 UTC",
      "updated_date": "2024-08-06 03:21:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:23:14.500655"
    },
    {
      "arxiv_id": "2408.11828v1",
      "title": "Online Electric Vehicle Charging Detection Based on Memory-based Transformer using Smart Meter Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ammar Mansoor Kamoona",
        "Hui Song",
        "Mahdi Jalili",
        "Hao Wang",
        "Reza Razzaghi",
        "Xinghuo Yu"
      ],
      "abstract": "The growing popularity of Electric Vehicles (EVs) poses unique challenges for\ngrid operators and infrastructure, which requires effectively managing these\nvehicles' integration into the grid. Identification of EVs charging is\nessential to electricity Distribution Network Operators (DNOs) for better\nplanning and managing the distribution grid. One critical aspect is the ability\nto accurately identify the presence of EV charging in the grid. EV charging\nidentification using smart meter readings obtained from behind-the-meter\ndevices is a challenging task that enables effective managing the integration\nof EVs into the existing power grid. Different from the existing supervised\nmodels that require addressing the imbalance problem caused by EVs and non-EVs\ndata, we propose a novel unsupervised memory-based transformer (M-TR) that can\nrun in real-time (online) to detect EVs charging from a streaming smart meter.\nIt dynamically leverages coarse-scale historical information using an M-TR\nencoder from an extended global temporal window, in conjunction with an M-TR\ndecoder that concentrates on a limited time frame, local window, aiming to\ncapture the fine-scale characteristics of the smart meter data. The M-TR is\nbased on an anomaly detection technique that does not require any prior\nknowledge about EVs charging profiles, nor it does only require real power\nconsumption data of non-EV users. In addition, the proposed model leverages the\npower of transfer learning. The M-TR is compared with different\nstate-of-the-art methods and performs better than other unsupervised learning\nmodels. The model can run with an excellent execution time of 1.2 sec. for\n1-minute smart recordings.",
      "tldr_zh": "该研究针对电动汽车（EVs）集成电网的挑战，提出了一种基于记忆型Transformer（M-TR）的在线检测方法，利用智能电表数据实时识别EVs充电行为。该方法采用无监督的异常检测技术，通过M-TR编码器处理扩展全局时间窗口的粗粒度历史信息，并结合局部时间窗口的解码器捕捉细粒度特征，无需事先了解EVs充电配置文件，仅依赖非EVs用户的真实功率消耗数据。此外，模型整合迁移学习，与现有无监督模型相比，M-TR在性能上表现出色，并能以1.2秒的执行时间处理1分钟的智能电表记录。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11828v1",
      "published_date": "2024-08-06 03:19:14 UTC",
      "updated_date": "2024-08-06 03:19:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:23:26.848868"
    },
    {
      "arxiv_id": "2408.02920v1",
      "title": "A Taxonomy of Architecture Options for Foundation Model-based Agents: Analysis and Decision Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jingwen Zhou",
        "Qinghua Lu",
        "Jieshan Chen",
        "Liming Zhu",
        "Xiwei Xu",
        "Zhenchang Xing",
        "Stefan Harrer"
      ],
      "abstract": "The rapid advancement of AI technology has led to widespread applications of\nagent systems across various domains. However, the need for detailed\narchitecture design poses significant challenges in designing and operating\nthese systems. This paper introduces a taxonomy focused on the architectures of\nfoundation-model-based agents, addressing critical aspects such as functional\ncapabilities and non-functional qualities. We also discuss the operations\ninvolved in both design-time and run-time phases, providing a comprehensive\nview of architectural design and operational characteristics. By unifying and\ndetailing these classifications, our taxonomy aims to improve the design of\nfoundation-model-based agents. Additionally, the paper establishes a decision\nmodel that guides critical design and runtime decisions, offering a structured\napproach to enhance the development of foundation-model-based agents. Our\ncontributions include providing a structured architecture design option and\nguiding the development process of foundation-model-based agents, thereby\naddressing current fragmentation in the field.",
      "tldr_zh": "本论文提出了一种针对 foundation model-based agents 的架构选项分类法(taxonomy)，旨在解决 AI 代理系统在设计和操作中的挑战，通过分析功能能力和非功能质量，提供全面的架构设计视角。论文讨论了设计时和运行时的操作流程，统一了相关分类以提升代理系统的开发效率。此外，该研究建立了决策模型，用于指导关键的设计和运行时决策，从而解决领域碎片化问题，并为 foundation model-based agents 的结构化开发提供指导。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2408.02920v1",
      "published_date": "2024-08-06 03:10:52 UTC",
      "updated_date": "2024-08-06 03:10:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:23:38.678811"
    },
    {
      "arxiv_id": "2408.02912v3",
      "title": "KOI: Accelerating Online Imitation Learning via Hybrid Key-state Guidance",
      "title_zh": "KOI：通过混合关键状态指导加速在线模仿学习",
      "authors": [
        "Jingxian Lu",
        "Wenke Xia",
        "Dong Wang",
        "Zhigang Wang",
        "Bin Zhao",
        "Di Hu",
        "Xuelong Li"
      ],
      "abstract": "Online Imitation Learning struggles with the gap between extensive online\nexploration space and limited expert trajectories, hindering efficient\nexploration due to inaccurate reward estimation. Inspired by the findings from\ncognitive neuroscience, we hypothesize that an agent could estimate precise\ntask-aware reward for efficient online exploration, through decomposing the\ntarget task into the objectives of \"what to do\" and the mechanisms of \"how to\ndo\". In this work, we introduce the hybrid Key-state guided Online Imitation\n(KOI) learning method, which leverages the integration of semantic and motion\nkey states as guidance for reward estimation. Initially, we utilize\nvisual-language models to extract semantic key states from expert trajectory,\nindicating the objectives of \"what to do\". Within the intervals between\nsemantic key states, optical flow is employed to capture motion key states to\nunderstand the mechanisms of \"how to do\". By integrating a thorough grasp of\nhybrid key states, we refine the trajectory-matching reward computation,\naccelerating online imitation learning with task-aware exploration. We evaluate\nnot only the success rate of the tasks in the Meta-World and LIBERO\nenvironments, but also the trend of variance during online imitation learning,\nproving that our method is more sample efficient. We also conduct real-world\nrobotic manipulation experiments to validate the efficacy of our method,\ndemonstrating the practical applicability of our KOI method. Videos and code\nare available at https://gewu-lab.github.io/Keystate_Online_Imitation/.",
      "tldr_zh": "本文提出 KOI 方法，通过混合关键状态指导（hybrid Key-state Guidance）加速 Online Imitation Learning，解决在线探索空间大和奖励估计不准确的问题。方法利用视觉语言模型提取语义关键状态（semantic key states）来定义任务目标“what to do”，并通过 optical flow 捕获运动关键状态（motion key states）来理解执行机制“how to do”，从而优化轨迹匹配奖励计算并提升任务感知探索。在 Meta-World 和 LIBERO 环境中实验显示，KOI 显著提高了成功率和样本效率，并在真实机器人操作实验中验证了其实际适用性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by CoRL 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.02912v3",
      "published_date": "2024-08-06 02:53:55 UTC",
      "updated_date": "2024-10-17 03:35:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:23:51.897107"
    },
    {
      "arxiv_id": "2408.02904v1",
      "title": "Enabling Intelligent Traffic Systems: A Deep Learning Method for Accurate Arabic License Plate Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "M. A. Sayedelahl"
      ],
      "abstract": "This paper introduces a novel two-stage framework for accurate Egyptian\nVehicle License Plate Recognition (EVLPR). The first stage employs image\nprocessing techniques to reliably localize license plates, while the second\nstage utilizes a custom-designed deep learning model for robust Arabic\ncharacter recognition. The proposed system achieves a remarkable 99.3% accuracy\non a diverse dataset, surpassing existing approaches. Its potential\napplications extend to intelligent traffic management, including traffic\nviolation detection and parking optimization. Future research will focus on\nenhancing the system's capabilities through architectural refinements, expanded\ndatasets, and addressing system dependencies.",
      "tldr_zh": "这篇论文提出了一种新型的两阶段框架，用于精确的埃及车辆车牌识别 (EVLPR)，以支持智能交通系统。第一阶段采用图像处理技术可靠地定位车牌，第二阶段则使用自定义设计的深度学习模型进行鲁棒的阿拉伯字符识别。该框架在多样数据集上实现了99.3%的准确率，超过了现有方法，并可应用于交通违规检测和停车优化。未来研究将通过架构改进、扩展数据集和解决系统依赖性来进一步增强系统性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02904v1",
      "published_date": "2024-08-06 02:27:54 UTC",
      "updated_date": "2024-08-06 02:27:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:24:03.702232"
    },
    {
      "arxiv_id": "2408.04662v2",
      "title": "Citekit: A Modular Toolkit for Large Language Model Citation Generation",
      "title_zh": "Citekit：一个模块化的工具包，用于大型语言模型引用生成",
      "authors": [
        "Jiajun Shen",
        "Tong Zhou",
        "Yubo Chen",
        "Kang Liu"
      ],
      "abstract": "Enabling Large Language Models (LLMs) to generate citations in\nQuestion-Answering (QA) tasks is an emerging paradigm aimed at enhancing the\nverifiability of their responses when LLMs are utilizing external references to\ngenerate an answer. However, there is currently no unified framework to\nstandardize and fairly compare different citation generation methods, leading\nto difficulties in reproducing different methods and a comprehensive\nassessment. To cope with the problems above, we introduce \\name, an open-source\nand modular toolkit designed to facilitate the implementation and evaluation of\nexisting citation generation methods, while also fostering the development of\nnew approaches to improve citation quality in LLM outputs. This tool is highly\nextensible, allowing users to utilize 4 main modules and 14 components to\nconstruct a pipeline, evaluating an existing method or innovative designs. Our\nexperiments with two state-of-the-art LLMs and 11 citation generation baselines\ndemonstrate varying strengths of different modules in answer accuracy and\ncitation quality improvement, as well as the challenge of enhancing\ngranularity. Based on our analysis of the effectiveness of components, we\npropose a new method, self-RAG \\snippet, obtaining a balanced answer accuracy\nand citation quality. Citekit is released at\nhttps://github.com/SjJ1017/Citekit.",
      "tldr_zh": "该论文引入 Citekit，一个开源的模块化工具包，旨在标准化和评估大型语言模型 (LLMs) 在问答 (QA) 任务中生成引用的方法，以提升响应可验证性。Citekit 提供了 4 个主模块和 14 个组件，允许用户灵活构建管道来实现现有方法的评估或新方法的开发。实验使用两个最先进的 LLMs 和 11 个基准，展示了不同模块在答案准确性和引用质量方面的优势，同时突出了提升引用细粒度性的挑战。基于分析，作者提出了一种新方法 self-RAG snippet，能在答案准确性和引用质量之间实现平衡，并已在 GitHub 上开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.04662v2",
      "published_date": "2024-08-06 02:13:15 UTC",
      "updated_date": "2024-12-17 08:37:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:24:18.020620"
    },
    {
      "arxiv_id": "2408.02897v1",
      "title": "A Metric Driven Approach to Mixed Precision Training",
      "title_zh": "翻译失败",
      "authors": [
        "Mitchelle Rasquinha",
        "Gil Tabak"
      ],
      "abstract": "As deep learning methodologies have developed, it has been generally agreed\nthat increasing neural network size improves model quality. However, this is at\nthe expense of memory and compute requirements, which also need to be\nincreased. Various efficiency techniques have been proposed to rein in hardware\ncosts, one being the use of low precision numerics. Recent accelerators have\nintroduced several different 8-bit data types to help accommodate DNNs in terms\nof numerics. In this paper, we identify a metric driven methodology to aid in\nthe choice of numerics. We demonstrate how such a methodology can help scale\ntraining of a language representation model. The technique can be generalized\nto other model architectures.",
      "tldr_zh": "本文提出了一种基于指标（metric driven）的混合精度训练（mixed precision training）方法，以解决增大神经网络规模带来的内存和计算需求问题。方法通过评估低精度数值（如8-bit数据类型）的选择，帮助优化深度神经网络（DNNs）的训练过程，并在语言表示模型上实现了规模化训练。实验证明，该技术可泛化到其他模型架构，从而提高整体效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02897v1",
      "published_date": "2024-08-06 02:06:04 UTC",
      "updated_date": "2024-08-06 02:06:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:24:27.658726"
    },
    {
      "arxiv_id": "2408.02888v1",
      "title": "VizECGNet: Visual ECG Image Network for Cardiovascular Diseases Classification with Multi-Modal Training and Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Ju-Hyeon Nam",
        "Seo-Hyung Park",
        "Su Jung Kim",
        "Sang-Chul Lee"
      ],
      "abstract": "An electrocardiogram (ECG) captures the heart's electrical signal to assess\nvarious heart conditions. In practice, ECG data is stored as either digitized\nsignals or printed images. Despite the emergence of numerous deep learning\nmodels for digitized signals, many hospitals prefer image storage due to cost\nconsiderations. Recognizing the unavailability of raw ECG signals in many\nclinical settings, we propose VizECGNet, which uses only printed ECG graphics\nto determine the prognosis of multiple cardiovascular diseases. During\ntraining, cross-modal attention modules (CMAM) are used to integrate\ninformation from two modalities - image and signal, while self-modality\nattention modules (SMAM) capture inherent long-range dependencies in ECG data\nof each modality. Additionally, we utilize knowledge distillation to improve\nthe similarity between two distinct predictions from each modality stream. This\ninnovative multi-modal deep learning architecture enables the utilization of\nonly ECG images during inference. VizECGNet with image input achieves higher\nperformance in precision, recall, and F1-Score compared to signal-based ECG\nclassification models, with improvements of 3.50%, 8.21%, and 7.38%,\nrespectively.",
      "tldr_zh": "该研究提出VizECGNet，一种专为心血管疾病分类设计的视觉ECG图像网络，利用多模态训练和知识蒸馏技术，仅基于打印ECG图像进行诊断。训练过程中，跨模态注意力模块(CMAM)整合图像和信号信息，自模态注意力模块(SMAM)捕捉每种模态的内在长程依赖性，同时通过知识蒸馏提升两种模态预测的相似性。推理时，只需ECG图像输入，VizECGNet在精度、召回率和F1-Score上分别比基于信号的模型提高了3.50%、8.21%和7.38%，为临床ECG图像应用提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in International Conference on Image Processing (ICIP) 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.02888v1",
      "published_date": "2024-08-06 01:34:43 UTC",
      "updated_date": "2024-08-06 01:34:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:24:40.568060"
    },
    {
      "arxiv_id": "2408.02882v1",
      "title": "Compromising Embodied Agents with Contextual Backdoor Attacks",
      "title_zh": "通过上下文后门攻击破坏具身代理",
      "authors": [
        "Aishan Liu",
        "Yuguang Zhou",
        "Xianglong Liu",
        "Tianyuan Zhang",
        "Siyuan Liang",
        "Jiakai Wang",
        "Yanjun Pu",
        "Tianlin Li",
        "Junqi Zhang",
        "Wenbo Zhou",
        "Qing Guo",
        "Dacheng Tao"
      ],
      "abstract": "Large language models (LLMs) have transformed the development of embodied\nintelligence. By providing a few contextual demonstrations, developers can\nutilize the extensive internal knowledge of LLMs to effortlessly translate\ncomplex tasks described in abstract language into sequences of code snippets,\nwhich will serve as the execution logic for embodied agents. However, this\npaper uncovers a significant backdoor security threat within this process and\nintroduces a novel method called \\method{}. By poisoning just a few contextual\ndemonstrations, attackers can covertly compromise the contextual environment of\na black-box LLM, prompting it to generate programs with context-dependent\ndefects. These programs appear logically sound but contain defects that can\nactivate and induce unintended behaviors when the operational agent encounters\nspecific triggers in its interactive environment. To compromise the LLM's\ncontextual environment, we employ adversarial in-context generation to optimize\npoisoned demonstrations, where an LLM judge evaluates these poisoned prompts,\nreporting to an additional LLM that iteratively optimizes the demonstration in\na two-player adversarial game using chain-of-thought reasoning. To enable\ncontext-dependent behaviors in downstream agents, we implement a dual-modality\nactivation strategy that controls both the generation and execution of program\ndefects through textual and visual triggers. We expand the scope of our attack\nby developing five program defect modes that compromise key aspects of\nconfidentiality, integrity, and availability in embodied agents. To validate\nthe effectiveness of our approach, we conducted extensive experiments across\nvarious tasks, including robot planning, robot manipulation, and compositional\nvisual reasoning. Additionally, we demonstrate the potential impact of our\napproach by successfully attacking real-world autonomous driving systems.",
      "tldr_zh": "该研究揭示了大型语言模型（LLMs）在开发具身智能（embodied agents）时存在的后门安全威胁，提出了一种名为 Contextual Backdoor Attacks 的新方法，通过毒化少量上下文演示（contextual demonstrations）来破坏黑盒 LLM 的环境，导致生成带有上下文依赖缺陷的程序。这些程序在表面上逻辑正确，但遇特定文本或视觉触发时会激活缺陷，诱发代理的意外行为，如影响保密性、完整性和可用性。攻击方法采用对抗性上下文生成（adversarial in-context generation）和双模态激活策略，由 LLM 判断器通过链式思维（chain-of-thought reasoning）迭代优化毒化演示。实验结果显示，该方法在机器人规划、操控和视觉推理等任务上高度有效，甚至成功攻击真实世界的自动驾驶系统，强调了增强 LLM 安全性的必要性。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02882v1",
      "published_date": "2024-08-06 01:20:12 UTC",
      "updated_date": "2024-08-06 01:20:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:24:53.055274"
    },
    {
      "arxiv_id": "2408.02871v1",
      "title": "Hide and Seek: Fingerprinting Large Language Models with Evolutionary Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dmitri Iourovitski",
        "Sanat Sharma",
        "Rakshak Talwar"
      ],
      "abstract": "As content generated by Large Language Model (LLM) has grown exponentially,\nthe ability to accurately identify and fingerprint such text has become\nincreasingly crucial. In this work, we introduce a novel black-box approach for\nfingerprinting LLMs, achieving an impressive 72% accuracy in identifying the\ncorrect family of models (Such as Llama, Mistral, Gemma, etc) among a lineup of\nLLMs. We present an evolutionary strategy that leverages the capabilities of\none LLM to discover the most salient features for identifying other LLMs. Our\nmethod employs a unique \"Hide and Seek\" algorithm, where an Auditor LLM\ngenerates discriminative prompts, and a Detective LLM analyzes the responses to\nfingerprint the target models. This approach not only demonstrates the\nfeasibility of LLM-driven model identification but also reveals insights into\nthe semantic manifolds of different LLM families. By iteratively refining\nprompts through in-context learning, our system uncovers subtle distinctions\nbetween model outputs, providing a powerful tool for LLM analysis and\nverification. This research opens new avenues for understanding LLM behavior\nand has significant implications for model attribution, security, and the\nbroader field of AI transparency.",
      "tldr_zh": "这篇论文提出了一种黑盒方法，使用进化学习策略来指纹识别 Large Language Models (LLMs)，实现了72%的准确率，用于识别模型家族（如 Llama、Mistral、Gemma 等）。该方法采用 \"Hide and Seek\" 算法，由 Auditor LLM 生成辨别性提示，并由 Detective LLM 分析响应以发现其他 LLM 的显著特征。实验结果不仅揭示了不同 LLM 家族的语义流形，还为模型归属、安全性和 AI 透明度提供了重要工具。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02871v1",
      "published_date": "2024-08-06 00:13:10 UTC",
      "updated_date": "2024-08-06 00:13:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:25:04.673055"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 65,
  "processed_papers_count": 65,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T13:25:26.456369"
}