[
  {
    "arxiv_id": "2407.19126v1",
    "title": "Greedy Output Approximation: Towards Efficient Structured Pruning for LLMs Without Retraining",
    "authors": [
      "Jianwei Li",
      "Yijun Dong",
      "Qi Lei"
    ],
    "abstract": "To remove redundant components of large language models (LLMs) without\nincurring significant computational costs, this work focuses on single-shot\npruning without a retraining phase. We simplify the pruning process for\nTransformer-based LLMs by identifying a depth-2 pruning structure that\nfunctions independently. Additionally, we propose two inference-aware pruning\ncriteria derived from the optimization perspective of output approximation,\nwhich outperforms traditional training-aware metrics such as gradient and\nHessian. We also introduce a two-step reconstruction technique to mitigate\npruning errors without model retraining. Experimental results demonstrate that\nour approach significantly reduces computational costs and hardware\nrequirements while maintaining superior performance across various datasets and\nmodels.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.19126v1",
    "published_date": "2024-07-26 23:53:59 UTC",
    "updated_date": "2024-07-26 23:53:59 UTC"
  },
  {
    "arxiv_id": "2407.19125v1",
    "title": "Binary Bleed: Fast Distributed and Parallel Method for Automatic Model Selection",
    "authors": [
      "Ryan Barron",
      "Maksim E. Eren",
      "Manish Bhattarai",
      "Ismael Boureima",
      "Cynthia Matuszek",
      "Boian S. Alexandrov"
    ],
    "abstract": "In several Machine Learning (ML) clustering and dimensionality reduction\napproaches, such as non-negative matrix factorization (NMF), RESCAL, and\nK-Means clustering, users must select a hyper-parameter k to define the number\nof clusters or components that yield an ideal separation of samples or clean\nclusters. This selection, while difficult, is crucial to avoid overfitting or\nunderfitting the data. Several ML applications use scoring methods (e.g.,\nSilhouette and Davies Boulding scores) to evaluate the cluster pattern\nstability for a specific k. The score is calculated for different trials over a\nrange of k, and the ideal k is heuristically selected as the value before the\nmodel starts overfitting, indicated by a drop or increase in the score\nresembling an elbow curve plot. While the grid-search method can be used to\naccurately find a good k value, visiting a range of k can become time-consuming\nand computationally resource-intensive. In this paper, we introduce the Binary\nBleed method based on binary search, which significantly reduces the k search\nspace for these grid-search ML algorithms by truncating the target k values\nfrom the search space using a heuristic with thresholding over the scores.\nBinary Bleed is designed to work with single-node serial, single-node\nmulti-processing, and distributed computing resources. In our experiments, we\ndemonstrate the reduced search space gain over a naive sequential search of the\nideal k and the accuracy of the Binary Bleed in identifying the correct k for\nNMFk, K-Means pyDNMFk, and pyDRESCALk with Silhouette and Davies Boulding\nscores. We make our implementation of Binary Bleed for the NMF algorithm\navailable on GitHub.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.DC",
    "comment": "8 pages, submitted to IEEE HPEC",
    "pdf_url": "http://arxiv.org/pdf/2407.19125v1",
    "published_date": "2024-07-26 23:48:51 UTC",
    "updated_date": "2024-07-26 23:48:51 UTC"
  },
  {
    "arxiv_id": "2407.19119v1",
    "title": "Accuracy-Privacy Trade-off in the Mitigation of Membership Inference Attack in Federated Learning",
    "authors": [
      "Sayyed Farid Ahamed",
      "Soumya Banerjee",
      "Sandip Roy",
      "Devin Quinn",
      "Marc Vucovich",
      "Kevin Choi",
      "Abdul Rahman",
      "Alison Hu",
      "Edward Bowen",
      "Sachin Shetty"
    ],
    "abstract": "Over the last few years, federated learning (FL) has emerged as a prominent\nmethod in machine learning, emphasizing privacy preservation by allowing\nmultiple clients to collaboratively build a model while keeping their training\ndata private. Despite this focus on privacy, FL models are susceptible to\nvarious attacks, including membership inference attacks (MIAs), posing a\nserious threat to data confidentiality. In a recent study, Rezaei \\textit{et\nal.} revealed the existence of an accuracy-privacy trade-off in deep ensembles\nand proposed a few fusion strategies to overcome it. In this paper, we aim to\nexplore the relationship between deep ensembles and FL. Specifically, we\ninvestigate whether confidence-based metrics derived from deep ensembles apply\nto FL and whether there is a trade-off between accuracy and privacy in FL with\nrespect to MIA. Empirical investigations illustrate a lack of a non-monotonic\ncorrelation between the number of clients and the accuracy-privacy trade-off.\nBy experimenting with different numbers of federated clients, datasets, and\nconfidence-metric-based fusion strategies, we identify and analytically justify\nthe clear existence of the accuracy-privacy trade-off.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.19119v1",
    "published_date": "2024-07-26 22:44:41 UTC",
    "updated_date": "2024-07-26 22:44:41 UTC"
  },
  {
    "arxiv_id": "2407.19118v1",
    "title": "Large Language Models as Co-Pilots for Causal Inference in Medical Studies",
    "authors": [
      "Ahmed Alaa",
      "Rachael V. Phillips",
      "Emre Kıcıman",
      "Laura B. Balzer",
      "Mark van der Laan",
      "Maya Petersen"
    ],
    "abstract": "The validity of medical studies based on real-world clinical data, such as\nobservational studies, depends on critical assumptions necessary for drawing\ncausal conclusions about medical interventions. Many published studies are\nflawed because they violate these assumptions and entail biases such as\nresidual confounding, selection bias, and misalignment between treatment and\nmeasurement times. Although researchers are aware of these pitfalls, they\ncontinue to occur because anticipating and addressing them in the context of a\nspecific study can be challenging without a large, often unwieldy,\ninterdisciplinary team with extensive expertise. To address this expertise gap,\nwe explore the use of large language models (LLMs) as co-pilot tools to assist\nresearchers in identifying study design flaws that undermine the validity of\ncausal inferences. We propose a conceptual framework for LLMs as causal\nco-pilots that encode domain knowledge across various fields, engaging with\nresearchers in natural language interactions to provide contextualized\nassistance in study design. We provide illustrative examples of how LLMs can\nfunction as causal co-pilots, propose a structured framework for their\ngrounding in existing causal inference frameworks, and highlight the unique\nchallenges and opportunities in adapting LLMs for reliable use in\nepidemiological research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.19118v1",
    "published_date": "2024-07-26 22:43:15 UTC",
    "updated_date": "2024-07-26 22:43:15 UTC"
  },
  {
    "arxiv_id": "2407.19110v1",
    "title": "GPT Deciphering Fedspeak: Quantifying Dissent Among Hawks and Doves",
    "authors": [
      "Denis Peskoff",
      "Adam Visokay",
      "Sander Schulhoff",
      "Benjamin Wachspress",
      "Alan Blinder",
      "Brandon M. Stewart"
    ],
    "abstract": "Markets and policymakers around the world hang on the consequential monetary\npolicy decisions made by the Federal Open Market Committee (FOMC). Publicly\navailable textual documentation of their meetings provides insight into\nmembers' attitudes about the economy. We use GPT-4 to quantify dissent among\nmembers on the topic of inflation. We find that transcripts and minutes reflect\nthe diversity of member views about the macroeconomic outlook in a way that is\nlost or omitted from the public statements. In fact, diverging opinions that\nshed light upon the committee's \"true\" attitudes are almost entirely omitted\nfrom the final statements. Hence, we argue that forecasting FOMC sentiment\nbased solely on statements will not sufficiently reflect dissent among the\nhawks and doves.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.19110v1",
    "published_date": "2024-07-26 22:16:40 UTC",
    "updated_date": "2024-07-26 22:16:40 UTC"
  },
  {
    "arxiv_id": "2408.01458v1",
    "title": "Surveys Considered Harmful? Reflecting on the Use of Surveys in AI Research, Development, and Governance",
    "authors": [
      "Mohammmad Tahaei",
      "Daricia Wilkinson",
      "Alisa Frik",
      "Michael Muller",
      "Ruba Abu-Salma",
      "Lauren Wilcox"
    ],
    "abstract": "Calls for engagement with the public in Artificial Intelligence (AI)\nresearch, development, and governance are increasing, leading to the use of\nsurveys to capture people's values, perceptions, and experiences related to AI.\nIn this paper, we critically examine the state of human participant surveys\nassociated with these topics. Through both a reflexive analysis of a survey\npilot spanning six countries and a systematic literature review of 44 papers\nfeaturing public surveys related to AI, we explore prominent perspectives and\nmethodological nuances associated with surveys to date. We find that public\nsurveys on AI topics are vulnerable to specific Western knowledge, values, and\nassumptions in their design, including in their positioning of ethical concepts\nand societal values, lack sufficient critical discourse surrounding deployment\nstrategies, and demonstrate inconsistent forms of transparency in their\nreporting. Based on our findings, we distill provocations and heuristic\nquestions for our community, to recognize the limitations of surveys for\nmeeting the goals of engagement, and to cultivate shared principles to design,\ndeploy, and interpret surveys cautiously and responsibly.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "To appear in 7th AAAI Conference on AI, Ethics, and Society (AIES)",
    "pdf_url": "http://arxiv.org/pdf/2408.01458v1",
    "published_date": "2024-07-26 22:10:49 UTC",
    "updated_date": "2024-07-26 22:10:49 UTC"
  },
  {
    "arxiv_id": "2407.19094v6",
    "title": "Wonderful Team: Zero-Shot Physical Task Planning with Visual LLMs",
    "authors": [
      "Zidan Wang",
      "Rui Shen",
      "Bradly Stadie"
    ],
    "abstract": "We introduce Wonderful Team, a multi-agent Vision Large Language Model (VLLM)\nframework for executing high-level robotic planning in a zero-shot regime. In\nour context, zero-shot high-level planning means that for a novel environment,\nwe provide a VLLM with an image of the robot's surroundings and a task\ndescription, and the VLLM outputs the sequence of actions necessary for the\nrobot to complete the task. Unlike previous methods for high-level visual\nplanning for robotic manipulation, our method uses VLLMs for the entire\nplanning process, enabling a more tightly integrated loop between perception,\ncontrol, and planning. As a result, Wonderful Team's performance on real-world\nsemantic and physical planning tasks often exceeds methods that rely on\nseparate vision systems. For example, we see an average 40% success rate\nimprovement on VimaBench over prior methods such as NLaP, an average 30%\nimprovement over Trajectory Generators on tasks from the Trajectory Generator\npaper, including drawing and wiping a plate, and an average 70% improvement\nover Trajectory Generators on a new set of semantic reasoning tasks including\nenvironment rearrangement with implicit linguistic constraints. We hope these\nresults highlight the rapid improvements of VLLMs in the past year, and\nmotivate the community to consider VLLMs as an option for some high-level\nrobotic planning problems in the future.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "aka Wonderful Team",
    "pdf_url": "http://arxiv.org/pdf/2407.19094v6",
    "published_date": "2024-07-26 21:18:57 UTC",
    "updated_date": "2025-02-04 00:18:00 UTC"
  },
  {
    "arxiv_id": "2407.19089v1",
    "title": "Many-Shot In-Context Learning for Molecular Inverse Design",
    "authors": [
      "Saeed Moayedpour",
      "Alejandro Corrochano-Navarro",
      "Faryad Sahneh",
      "Shahriar Noroozizadeh",
      "Alexander Koetter",
      "Jiri Vymetal",
      "Lorenzo Kogler-Anele",
      "Pablo Mas",
      "Yasser Jangjou",
      "Sizhen Li",
      "Michael Bailey",
      "Marc Bianciotto",
      "Hans Matter",
      "Christoph Grebner",
      "Gerhard Hessler",
      "Ziv Bar-Joseph",
      "Sven Jager"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated great performance in few-shot\nIn-Context Learning (ICL) for a variety of generative and discriminative\nchemical design tasks. The newly expanded context windows of LLMs can further\nimprove ICL capabilities for molecular inverse design and lead optimization. To\ntake full advantage of these capabilities we developed a new semi-supervised\nlearning method that overcomes the lack of experimental data available for\nmany-shot ICL. Our approach involves iterative inclusion of LLM generated\nmolecules with high predicted performance, along with experimental data. We\nfurther integrated our method in a multi-modal LLM which allows for the\ninteractive modification of generated molecular structures using text\ninstructions. As we show, the new method greatly improves upon existing ICL\nmethods for molecular design while being accessible and easy to use for\nscientists.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.19089v1",
    "published_date": "2024-07-26 21:10:50 UTC",
    "updated_date": "2024-07-26 21:10:50 UTC"
  },
  {
    "arxiv_id": "2407.19082v2",
    "title": "Regularized Multi-Decoder Ensemble for an Error-Aware Scene Representation Network",
    "authors": [
      "Tianyu Xiong",
      "Skylar W. Wurster",
      "Hanqi Guo",
      "Tom Peterka",
      "Han-Wei Shen"
    ],
    "abstract": "Feature grid Scene Representation Networks (SRNs) have been applied to\nscientific data as compact functional surrogates for analysis and\nvisualization. As SRNs are black-box lossy data representations, assessing the\nprediction quality is critical for scientific visualization applications to\nensure that scientists can trust the information being visualized. Currently,\nexisting architectures do not support inference time reconstruction quality\nassessment, as coordinate-level errors cannot be evaluated in the absence of\nground truth data. We propose a parameter-efficient multi-decoder SRN (MDSRN)\nensemble architecture consisting of a shared feature grid with multiple\nlightweight multi-layer perceptron decoders. MDSRN can generate a set of\nplausible predictions for a given input coordinate to compute the mean as the\nprediction of the multi-decoder ensemble and the variance as a confidence\nscore. The coordinate-level variance can be rendered along with the data to\ninform the reconstruction quality, or be integrated into uncertainty-aware\nvolume visualization algorithms. To prevent the misalignment between the\nquantified variance and the prediction quality, we propose a novel variance\nregularization loss for ensemble learning that promotes the Regularized\nmulti-decoder SRN (RMDSRN) to obtain a more reliable variance that correlates\nclosely to the true model error. We comprehensively evaluate the quality of\nvariance quantification and data reconstruction of Monte Carlo Dropout, Mean\nField Variational Inference, Deep Ensemble, and Predicting Variance compared to\nthe proposed MDSRN and RMDSRN across diverse scalar field datasets. We\ndemonstrate that RMDSRN attains the most accurate data reconstruction and\ncompetitive variance-error correlation among uncertain SRNs under the same\nneural network parameter budgets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.GR",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "To be published in Proc. IEEE VIS 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.19082v2",
    "published_date": "2024-07-26 21:02:11 UTC",
    "updated_date": "2024-08-05 21:09:50 UTC"
  },
  {
    "arxiv_id": "2407.19055v1",
    "title": "Effective Large Language Model Debugging with Best-first Tree Search",
    "authors": [
      "Jialin Song",
      "Jonathan Raiman",
      "Bryan Catanzaro"
    ],
    "abstract": "Large Language Models (LLMs) show promise in code generation tasks. However,\ntheir code-writing abilities are often limited in scope: while they can\nsuccessfully implement simple functions, they struggle with more complex tasks.\nA fundamental difference with how an LLM writes code, compared to a human\nprogrammer, is that it cannot consistently spot and fix bugs. Debugging is a\ncrucial skill for programmers and it enables iterative code refinement towards\na correct implementation. In this work, we propose a novel algorithm to enable\nLLMs to debug their code via self-reflection and search where a model attempts\nto identify its previous mistakes. Our key contributions are 1) a best-first\ntree search algorithm with self-reflections (BESTER) that achieves\nstate-of-the-art Pass@1 in three code generation benchmarks. BESTER maintains\nits superiority when we measure pass rates taking into account additional\ninference costs incurred by tree search. 2) A novel interpretability study on\nwhat self-reflections attend to in buggy programs and how they impact bug\nfixes, which provides a deeper understanding of the debugging process. 3) An\nextensive study on when self-reflections are effective in finding bugs.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.19055v1",
    "published_date": "2024-07-26 19:26:00 UTC",
    "updated_date": "2024-07-26 19:26:00 UTC"
  },
  {
    "arxiv_id": "2407.19051v1",
    "title": "Towards a Transformer-Based Pre-trained Model for IoT Traffic Classification",
    "authors": [
      "Bruna Bazaluk",
      "Mosab Hamdan",
      "Mustafa Ghaleb",
      "Mohammed S. M. Gismalla",
      "Flavio S. Correa da Silva",
      "Daniel Macêdo Batista"
    ],
    "abstract": "The classification of IoT traffic is important to improve the efficiency and\nsecurity of IoT-based networks. As the state-of-the-art classification methods\nare based on Deep Learning, most of the current results require a large amount\nof data to be trained. Thereby, in real-life situations, where there is a\nscarce amount of IoT traffic data, the models would not perform so well.\nConsequently, these models underperform outside their initial training\nconditions and fail to capture the complex characteristics of network traffic,\nrendering them inefficient and unreliable in real-world applications. In this\npaper, we propose IoT Traffic Classification Transformer (ITCT), a novel\napproach that utilizes the state-of-the-art transformer-based model named\nTabTransformer. ITCT, which is pre-trained on a large labeled MQTT-based IoT\ntraffic dataset and may be fine-tuned with a small set of labeled data, showed\npromising results in various traffic classification tasks. Our experiments\ndemonstrated that the ITCT model significantly outperforms existing models,\nachieving an overall accuracy of 82%. To support reproducibility and\ncollaborative development, all associated code has been made publicly\navailable.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "Updated version of: B. Bazaluk, M. Hamdan, M. Ghaleb, M. S. M.\n  Gismalla, F. S. Correa da Silva and D. M. Batista, \"Towards a\n  Transformer-Based Pre-trained Model for IoT Traffic Classification,\" NOMS\n  2024-2024 IEEE Network Operations and Management Symposium, Seoul, Korea,\n  Republic of, 2024, pp. 1-7, doi: 10.1109/NOMS59830.2024.10575448",
    "pdf_url": "http://arxiv.org/pdf/2407.19051v1",
    "published_date": "2024-07-26 19:13:11 UTC",
    "updated_date": "2024-07-26 19:13:11 UTC"
  },
  {
    "arxiv_id": "2407.19041v1",
    "title": "Optimizing Numerical Estimation and Operational Efficiency in the Legal Domain through Large Language Models",
    "authors": [
      "Jia-Hong Huang",
      "Chao-Chun Yang",
      "Yixian Shen",
      "Alessio M. Pacces",
      "Evangelos Kanoulas"
    ],
    "abstract": "The legal landscape encompasses a wide array of lawsuit types, presenting\nlawyers with challenges in delivering timely and accurate information to\nclients, particularly concerning critical aspects like potential imprisonment\nduration or financial repercussions. Compounded by the scarcity of legal\nexperts, there's an urgent need to enhance the efficiency of traditional legal\nworkflows. Recent advances in deep learning, especially Large Language Models\n(LLMs), offer promising solutions to this challenge. Leveraging LLMs'\nmathematical reasoning capabilities, we propose a novel approach integrating\nLLM-based methodologies with specially designed prompts to address precision\nrequirements in legal Artificial Intelligence (LegalAI) applications. The\nproposed work seeks to bridge the gap between traditional legal practices and\nmodern technological advancements, paving the way for a more accessible,\nefficient, and equitable legal system. To validate this method, we introduce a\ncurated dataset tailored to precision-oriented LegalAI tasks, serving as a\nbenchmark for evaluating LLM-based approaches. Extensive experimentation\nconfirms the efficacy of our methodology in generating accurate numerical\nestimates within the legal domain, emphasizing the role of LLMs in streamlining\nlegal processes and meeting the evolving demands of LegalAI.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "The paper has been accepted by the 33rd ACM International Conference\n  on Information and Knowledge Management (CIKM) in 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.19041v1",
    "published_date": "2024-07-26 18:46:39 UTC",
    "updated_date": "2024-07-26 18:46:39 UTC"
  },
  {
    "arxiv_id": "2407.19040v1",
    "title": "A Fault Prognostic System for the Turbine Guide Bearings of a Hydropower Plant Using Long-Short Term Memory (LSTM)",
    "authors": [
      "Yasir Saleem Afridi",
      "Mian Ibad Ali Shah",
      "Adnan Khan",
      "Atia Kareem",
      "Laiq Hasan"
    ],
    "abstract": "Hydroelectricity, being a renewable source of energy, globally fulfills the\nelectricity demand. Hence, Hydropower Plants (HPPs) have always been in the\nlimelight of research. The fast-paced technological advancement is enabling us\nto develop state-of-the-art power generation machines. This has not only\nresulted in improved turbine efficiency but has also increased the complexity\nof these systems. In lieu thereof, efficient Operation & Maintenance (O&M) of\nsuch intricate power generation systems has become a more challenging task.\nTherefore, there has been a shift from conventional reactive approaches to more\nintelligent predictive approaches in maintaining the HPPs. The research is\ntherefore targeted to develop an artificially intelligent fault prognostics\nsystem for the turbine bearings of an HPP. The proposed method utilizes the\nLong Short-Term Memory (LSTM) algorithm in developing the model. Initially, the\nmodel is trained and tested with bearing vibration data from a test rig.\nSubsequently, it is further trained and tested with realistic bearing vibration\ndata obtained from an HPP operating in Pakistan via the Supervisory Control and\nData Acquisition (SCADA) system. The model demonstrates highly effective\npredictions of bearing vibration values, achieving a remarkably low RMSE.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "8 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.19040v1",
    "published_date": "2024-07-26 18:45:42 UTC",
    "updated_date": "2024-07-26 18:45:42 UTC"
  },
  {
    "arxiv_id": "2407.19039v1",
    "title": "GraphBPE: Molecular Graphs Meet Byte-Pair Encoding",
    "authors": [
      "Yuchen Shen",
      "Barnabás Póczos"
    ],
    "abstract": "With the increasing attention to molecular machine learning, various\ninnovations have been made in designing better models or proposing more\ncomprehensive benchmarks. However, less is studied on the data preprocessing\nschedule for molecular graphs, where a different view of the molecular graph\ncould potentially boost the model's performance. Inspired by the Byte-Pair\nEncoding (BPE) algorithm, a subword tokenization method popularly adopted in\nNatural Language Processing, we propose GraphBPE, which tokenizes a molecular\ngraph into different substructures and acts as a preprocessing schedule\nindependent of the model architectures. Our experiments on 3 graph-level\nclassification and 3 graph-level regression datasets show that data\npreprocessing could boost the performance of models for molecular graphs, and\nGraphBPE is effective for small classification datasets and it performs on par\nwith other tokenization methods across different model architectures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted by ICML 2024 AI for Science Workshop",
    "pdf_url": "http://arxiv.org/pdf/2407.19039v1",
    "published_date": "2024-07-26 18:45:09 UTC",
    "updated_date": "2024-07-26 18:45:09 UTC"
  },
  {
    "arxiv_id": "2407.19031v2",
    "title": "Artificial Neural Networks on Graded Vector Spaces",
    "authors": [
      "Tony Shaska"
    ],
    "abstract": "This paper presents a transformative framework for artificial neural networks\nover graded vector spaces, tailored to model hierarchical and structured data\nin fields like algebraic geometry and physics. By exploiting the algebraic\nproperties of graded vector spaces, where features carry distinct weights, we\nextend classical neural networks with graded neurons, layers, and activation\nfunctions that preserve structural integrity. Grounded in group actions,\nrepresentation theory, and graded algebra, our approach combines theoretical\nrigor with practical utility.\n  We introduce graded neural architectures, loss functions prioritizing graded\ncomponents, and equivariant extensions adaptable to diverse gradings. Case\nstudies validate the framework's effectiveness, outperforming standard neural\nnetworks in tasks such as predicting invariants in weighted projective spaces\nand modeling supersymmetric systems.\n  This work establishes a new frontier in machine learning, merging\nmathematical sophistication with interdisciplinary applications. Future\nchallenges, including computational scalability and finite field extensions,\noffer rich opportunities for advancing this paradigm.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "68T05, 68Q32, 16W50, 17B70, 58A50, 14A22",
      "I.2; I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.19031v2",
    "published_date": "2024-07-26 18:17:58 UTC",
    "updated_date": "2025-05-10 15:03:42 UTC"
  },
  {
    "arxiv_id": "2407.18913v2",
    "title": "SOAP-RL: Sequential Option Advantage Propagation for Reinforcement Learning in POMDP Environments",
    "authors": [
      "Shu Ishida",
      "João F. Henriques"
    ],
    "abstract": "This work compares ways of extending Reinforcement Learning algorithms to\nPartially Observed Markov Decision Processes (POMDPs) with options. One view of\noptions is as temporally extended action, which can be realized as a memory\nthat allows the agent to retain historical information beyond the policy's\ncontext window. While option assignment could be handled using heuristics and\nhand-crafted objectives, learning temporally consistent options and associated\nsub-policies without explicit supervision is a challenge. Two algorithms, PPOEM\nand SOAP, are proposed and studied in depth to address this problem. PPOEM\napplies the forward-backward algorithm (for Hidden Markov Models) to optimize\nthe expected returns for an option-augmented policy. However, this learning\napproach is unstable during on-policy rollouts. It is also unsuited for\nlearning causal policies without the knowledge of future trajectories, since\noption assignments are optimized for offline sequences where the entire episode\nis available. As an alternative approach, SOAP evaluates the policy gradient\nfor an optimal option assignment. It extends the concept of the generalized\nadvantage estimation (GAE) to propagate option advantages through time, which\nis an analytical equivalent to performing temporal back-propagation of option\npolicy gradients. This option policy is only conditional on the history of the\nagent, not future actions. Evaluated against competing baselines, SOAP\nexhibited the most robust performance, correctly discovering options for POMDP\ncorridor environments, as well as on standard benchmarks including Atari and\nMuJoCo, outperforming PPOEM, as well as LSTM and Option-Critic baselines. The\nopen-sourced code is available at https://github.com/shuishida/SoapRL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18913v2",
    "published_date": "2024-07-26 17:59:55 UTC",
    "updated_date": "2024-10-11 15:35:01 UTC"
  },
  {
    "arxiv_id": "2407.18906v2",
    "title": "A Scalable Quantum Non-local Neural Network for Image Classification",
    "authors": [
      "Sparsh Gupta",
      "Debanjan Konar",
      "Vaneet Aggarwal"
    ],
    "abstract": "Non-local operations play a crucial role in computer vision enabling the\ncapture of long-range dependencies through weighted sums of features across the\ninput, surpassing the constraints of traditional convolution operations that\nfocus solely on local neighborhoods. Non-local operations typically require\ncomputing pairwise relationships between all elements in a set, leading to\nquadratic complexity in terms of time and memory. Due to the high computational\nand memory demands, scaling non-local neural networks to large-scale problems\ncan be challenging. This article introduces a hybrid quantum-classical scalable\nnon-local neural network, referred to as Quantum Non-Local Neural Network\n(QNL-Net), to enhance pattern recognition. The proposed QNL-Net relies on\ninherent quantum parallelism to allow the simultaneous processing of a large\nnumber of input features enabling more efficient computations in\nquantum-enhanced feature space and involving pairwise relationships through\nquantum entanglement. We benchmark our proposed QNL-Net with other quantum\ncounterparts to binary classification with datasets MNIST and CIFAR-10. The\nsimulation findings showcase our QNL-Net achieves cutting-edge accuracy levels\nin binary image classification among quantum classifiers while utilizing fewer\nqubits.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "quant-ph"
    ],
    "primary_category": "cs.CV",
    "comment": "preprint, 12 pages (including references and appendix), 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.18906v2",
    "published_date": "2024-07-26 17:58:57 UTC",
    "updated_date": "2024-08-22 02:22:05 UTC"
  },
  {
    "arxiv_id": "2407.18902v2",
    "title": "Lessons from Learning to Spin \"Pens\"",
    "authors": [
      "Jun Wang",
      "Ying Yuan",
      "Haichuan Che",
      "Haozhi Qi",
      "Yi Ma",
      "Jitendra Malik",
      "Xiaolong Wang"
    ],
    "abstract": "In-hand manipulation of pen-like objects is an important skill in our daily\nlives, as many tools such as hammers and screwdrivers are similarly shaped.\nHowever, current learning-based methods struggle with this task due to a lack\nof high-quality demonstrations and the significant gap between simulation and\nthe real world. In this work, we push the boundaries of learning-based in-hand\nmanipulation systems by demonstrating the capability to spin pen-like objects.\nWe first use reinforcement learning to train an oracle policy with privileged\ninformation and generate a high-fidelity trajectory dataset in simulation. This\nserves two purposes: 1) pre-training a sensorimotor policy in simulation; 2)\nconducting open-loop trajectory replay in the real world. We then fine-tune the\nsensorimotor policy using these real-world trajectories to adapt it to the real\nworld dynamics. With less than 50 trajectories, our policy learns to rotate\nmore than ten pen-like objects with different physical properties for multiple\nrevolutions. We present a comprehensive analysis of our design choices and\nshare the lessons learned during development.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "CoRL 2024. Website: https://penspin.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2407.18902v2",
    "published_date": "2024-07-26 17:56:01 UTC",
    "updated_date": "2024-10-23 19:56:39 UTC"
  },
  {
    "arxiv_id": "2407.18901v1",
    "title": "AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents",
    "authors": [
      "Harsh Trivedi",
      "Tushar Khot",
      "Mareike Hartmann",
      "Ruskin Manku",
      "Vinty Dong",
      "Edward Li",
      "Shashank Gupta",
      "Ashish Sabharwal",
      "Niranjan Balasubramanian"
    ],
    "abstract": "Autonomous agents that address day-to-day digital tasks (e.g., ordering\ngroceries for a household), must not only operate multiple apps (e.g., notes,\nmessaging, shopping app) via APIs, but also generate rich code with complex\ncontrol flow in an iterative manner based on their interaction with the\nenvironment. However, existing benchmarks for tool use are inadequate, as they\nonly cover tasks that require a simple sequence of API calls.\n  To remedy this gap, we built $\\textbf{AppWorld Engine}$, a high-quality\nexecution environment (60K lines of code) of 9 day-to-day apps operable via 457\nAPIs and populated with realistic digital activities simulating the lives of\n~100 fictitious users. We then created $\\textbf{AppWorld Benchmark}$ (40K lines\nof code), a suite of 750 natural, diverse, and challenging autonomous agent\ntasks requiring rich and interactive code generation. It supports robust\nprogrammatic evaluation with state-based unit tests, allowing for different\nways of completing a task while also checking for unexpected changes, i.e.,\ncollateral damage. The state-of-the-art LLM, GPT-4o, solves only ~49% of our\n'normal' tasks and ~30% of 'challenge' tasks, while other models solve at least\n16% fewer. This highlights the benchmark's difficulty and AppWorld's potential\nto push the frontiers of interactive coding agents. The project website is\navailable at https://appworld.dev/.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "ACL'24 Camera Ready",
    "pdf_url": "http://arxiv.org/pdf/2407.18901v1",
    "published_date": "2024-07-26 17:55:45 UTC",
    "updated_date": "2024-07-26 17:55:45 UTC"
  },
  {
    "arxiv_id": "2407.18899v1",
    "title": "Learn from the Learnt: Source-Free Active Domain Adaptation via Contrastive Sampling and Visual Persistence",
    "authors": [
      "Mengyao Lyu",
      "Tianxiang Hao",
      "Xinhao Xu",
      "Hui Chen",
      "Zijia Lin",
      "Jungong Han",
      "Guiguang Ding"
    ],
    "abstract": "Domain Adaptation (DA) facilitates knowledge transfer from a source domain to\na related target domain. This paper investigates a practical DA paradigm,\nnamely Source data-Free Active Domain Adaptation (SFADA), where source data\nbecomes inaccessible during adaptation, and a minimum amount of annotation\nbudget is available in the target domain. Without referencing the source data,\nnew challenges emerge in identifying the most informative target samples for\nlabeling, establishing cross-domain alignment during adaptation, and ensuring\ncontinuous performance improvements through the iterative query-and-adaptation\nprocess. In response, we present learn from the learnt (LFTL), a novel paradigm\nfor SFADA to leverage the learnt knowledge from the source pretrained model and\nactively iterated models without extra overhead. We propose Contrastive Active\nSampling to learn from the hypotheses of the preceding model, thereby querying\ntarget samples that are both informative to the current model and persistently\nchallenging throughout active learning. During adaptation, we learn from\nfeatures of actively selected anchors obtained from previous intermediate\nmodels, so that the Visual Persistence-guided Adaptation can facilitate feature\ndistribution alignment and active sample exploitation. Extensive experiments on\nthree widely-used benchmarks show that our LFTL achieves state-of-the-art\nperformance, superior computational efficiency and continuous improvements as\nthe annotation budget increases. Our code is available at\nhttps://github.com/lyumengyao/lftl.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.18899v1",
    "published_date": "2024-07-26 17:51:58 UTC",
    "updated_date": "2024-07-26 17:51:58 UTC"
  },
  {
    "arxiv_id": "2407.18892v2",
    "title": "FH-DRL: Exponential-Hyperbolic Frontier Heuristics with DRL for accelerated Exploration in Unknown Environments",
    "authors": [
      "Seunghyeop Nam",
      "Tuan Anh Nguyen",
      "Eunmi Choi",
      "Dugki Min"
    ],
    "abstract": "Autonomous robot exploration in large-scale or cluttered environments remains\na central challenge in intelligent vehicle applications, where partial or\nabsent prior maps constrain reliable navigation. This paper introduces FH-DRL,\na novel framework that integrates a customizable heuristic function for\nfrontier detection with a Twin Delayed DDPG (TD3) agent for continuous,\nhigh-speed local navigation. The proposed heuristic relies on an\nexponential-hyperbolic distance score, which balances immediate proximity\nagainst long-range exploration gains, and an occupancy-based stochastic\nmeasure, accounting for environmental openness and obstacle densities in real\ntime. By ranking frontiers using these adaptive metrics, FH-DRL targets highly\ninformative yet tractable waypoints, thereby minimizing redundant paths and\ntotal exploration time. We thoroughly evaluate FH-DRL across multiple simulated\nand real-world scenarios, demonstrating clear improvements in travel distance\nand completion time over frontier-only or purely DRL-based exploration. In\nstructured corridor layouts and maze-like topologies, our architecture\nconsistently outperforms standard methods such as Nearest Frontier, Cognet\nFrontier Exploration, and Goal Driven Autonomous Exploration. Real-world tests\nwith a Turtlebot3 platform further confirm robust adaptation to previously\nunseen or cluttered indoor spaces. The results highlight FH-DRL as an efficient\nand generalizable approach for frontier-based exploration in large or partially\nknown environments, offering a promising direction for various autonomous\ndriving, industrial, and service robotics tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18892v2",
    "published_date": "2024-07-26 17:42:18 UTC",
    "updated_date": "2025-02-13 02:46:13 UTC"
  },
  {
    "arxiv_id": "2407.20287v1",
    "title": "Variational Inference Using Material Point Method",
    "authors": [
      "Yongchao Huang"
    ],
    "abstract": "A new gradient-based particle sampling method, MPM-ParVI, based on material\npoint method (MPM), is proposed for variational inference. MPM-ParVI simulates\nthe deformation of a deformable body (e.g. a solid or fluid) under external\neffects driven by the target density; transient or steady configuration of the\ndeformable body approximates the target density. The continuum material is\nmodelled as an interacting particle system (IPS) using MPM, each particle\ncarries full physical properties, interacts and evolves following conservation\ndynamics. This easy-to-implement ParVI method offers deterministic sampling and\ninference for a class of probabilistic models such as those encountered in\nBayesian inference (e.g. intractable densities) and generative modelling (e.g.\nscore-based).",
    "categories": [
      "cs.AI",
      "stat.CO",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20287v1",
    "published_date": "2024-07-26 17:19:50 UTC",
    "updated_date": "2024-07-26 17:19:50 UTC"
  },
  {
    "arxiv_id": "2407.18875v2",
    "title": "Generative Adversarial Networks for Imputing Sparse Learning Performance",
    "authors": [
      "Liang Zhang",
      "Mohammed Yeasin",
      "Jionghao Lin",
      "Felix Havugimana",
      "Xiangen Hu"
    ],
    "abstract": "Learning performance data, such as correct or incorrect responses to\nquestions in Intelligent Tutoring Systems (ITSs) is crucial for tracking and\nassessing the learners' progress and mastery of knowledge. However, the issue\nof data sparsity, characterized by unexplored questions and missing attempts,\nhampers accurate assessment and the provision of tailored, personalized\ninstruction within ITSs. This paper proposes using the Generative Adversarial\nImputation Networks (GAIN) framework to impute sparse learning performance\ndata, reconstructed into a three-dimensional (3D) tensor representation across\nthe dimensions of learners, questions and attempts. Our customized GAIN-based\nmethod computational process imputes sparse data in a 3D tensor space,\nsignificantly enhanced by convolutional neural networks for its input and\noutput layers. This adaptation also includes the use of a least squares loss\nfunction for optimization and aligns the shapes of the input and output with\nthe dimensions of the questions-attempts matrices along the learners'\ndimension. Through extensive experiments on six datasets from various ITSs,\nincluding AutoTutor, ASSISTments and MATHia, we demonstrate that the GAIN\napproach generally outperforms existing methods such as tensor factorization\nand other generative adversarial network (GAN) based approaches in terms of\nimputation accuracy. This finding enhances comprehensive learning data modeling\nand analytics in AI-based education.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18875v2",
    "published_date": "2024-07-26 17:09:48 UTC",
    "updated_date": "2024-09-20 00:00:17 UTC"
  },
  {
    "arxiv_id": "2407.18874v2",
    "title": "Engaging with Children's Artwork in Mixed Visual-Ability Families",
    "authors": [
      "Arnavi Chheda-Kothary",
      "Jacob O. Wobbrock",
      "Jon E. Froehlich"
    ],
    "abstract": "We present two studies exploring how blind or low-vision (BLV) family members\nengage with their sighted children's artwork, strategies to support\nunderstanding and interpretation, and the potential role of technology, such as\nAI, therein. Our first study involved 14 BLV individuals, and the second\nincluded five groups of BLV individuals with their children. Through\nsemi-structured interviews with AI descriptions of children's artwork and\nmulti-sensory design probes, we found that BLV family members value artwork\nengagement as a bonding opportunity, preferring the child's storytelling and\ninterpretation over other nonvisual representations. Additionally, despite some\ninaccuracies, BLV family members felt that AI-generated descriptions could\nfacilitate dialogue with their children and aid self-guided art discovery. We\nclose with specific design considerations for supporting artwork engagement in\nmixed visual-ability families, including enabling artwork access through\nvarious methods, supporting children's corrections of AI output, and\ndistinctions in context vs. content and interpretation vs. description of\nchildren's artwork.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18874v2",
    "published_date": "2024-07-26 17:08:53 UTC",
    "updated_date": "2024-07-30 06:31:04 UTC"
  },
  {
    "arxiv_id": "2407.18854v1",
    "title": "Unifying Visual and Semantic Feature Spaces with Diffusion Models for Enhanced Cross-Modal Alignment",
    "authors": [
      "Yuze Zheng",
      "Zixuan Li",
      "Xiangxian Li",
      "Jinxing Liu",
      "Yuqing Wang",
      "Xiangxu Meng",
      "Lei Meng"
    ],
    "abstract": "Image classification models often demonstrate unstable performance in\nreal-world applications due to variations in image information, driven by\ndiffering visual perspectives of subject objects and lighting discrepancies. To\nmitigate these challenges, existing studies commonly incorporate additional\nmodal information matching the visual data to regularize the model's learning\nprocess, enabling the extraction of high-quality visual features from complex\nimage regions. Specifically, in the realm of multimodal learning, cross-modal\nalignment is recognized as an effective strategy, harmonizing different modal\ninformation by learning a domain-consistent latent feature space for visual and\nsemantic features. However, this approach may face limitations due to the\nheterogeneity between multimodal information, such as differences in feature\ndistribution and structure. To address this issue, we introduce a Multimodal\nAlignment and Reconstruction Network (MARNet), designed to enhance the model's\nresistance to visual noise. Importantly, MARNet includes a cross-modal\ndiffusion reconstruction module for smoothly and stably blending information\nacross different domains. Experiments conducted on two benchmark datasets,\nVireo-Food172 and Ingredient-101, demonstrate that MARNet effectively improves\nthe quality of image information extracted by the model. It is a plug-and-play\nframework that can be rapidly integrated into various image classification\nframeworks, boosting model performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18854v1",
    "published_date": "2024-07-26 16:30:18 UTC",
    "updated_date": "2024-07-26 16:30:18 UTC"
  },
  {
    "arxiv_id": "2407.18848v1",
    "title": "Repairing Networks of $\\mathcal{EL_\\perp}$ Ontologies using Weakening and Completing -- Extended version",
    "authors": [
      "Ying Li",
      "Patrick Lambrix"
    ],
    "abstract": "The quality of ontologies and their alignments is crucial for developing\nhigh-quality semantics-based applications. Traditional debugging techniques\nrepair ontology networks by removing unwanted axioms and mappings, but may\nthereby remove consequences that are correct in the domain of the ontology\nnetwork. In this paper we propose a framework for repairing ontology networks\nthat deals with this issue. It defines basic operations such as debugging,\nweakening and completing. Further, it defines combination operators that\nreflect choices in how and when to use the basic operators, as well as choices\nregarding the autonomy level of the ontologies and alignments in the ontology\nnetwork. We show the influence of the combination operators on the quality of\nthe repaired network and present an implemented tool. By using our framework\ntogether with existing algorithms for debugging, weakening and completing, we\nessentially provide a blueprint for extending previous work and systems.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "This is a slightly revised and extended version of a paper published\n  at ISWC 2024. arXiv admin note: text overlap with arXiv:2208.00486",
    "pdf_url": "http://arxiv.org/pdf/2407.18848v1",
    "published_date": "2024-07-26 16:15:33 UTC",
    "updated_date": "2024-07-26 16:15:33 UTC"
  },
  {
    "arxiv_id": "2407.18847v1",
    "title": "Enhancing material property prediction with ensemble deep graph convolutional networks",
    "authors": [
      "Chowdhury Mohammad Abid Rahman",
      "Ghadendra Bhandari",
      "Nasser M Nasrabadi",
      "Aldo H. Romero",
      "Prashnna K. Gyawali"
    ],
    "abstract": "Machine learning (ML) models have emerged as powerful tools for accelerating\nmaterials discovery and design by enabling accurate predictions of properties\nfrom compositional and structural data. These capabilities are vital for\ndeveloping advanced technologies across fields such as energy, electronics, and\nbiomedicine, potentially reducing the time and resources needed for new\nmaterial exploration and promoting rapid innovation cycles. Recent efforts have\nfocused on employing advanced ML algorithms, including deep learning - based\ngraph neural network, for property prediction. Additionally, ensemble models\nhave proven to enhance the generalizability and robustness of ML and DL.\nHowever, the use of such ensemble strategies in deep graph networks for\nmaterial property prediction remains underexplored. Our research provides an\nin-depth evaluation of ensemble strategies in deep learning - based graph\nneural network, specifically targeting material property prediction tasks. By\ntesting the Crystal Graph Convolutional Neural Network (CGCNN) and its\nmultitask version, MT-CGCNN, we demonstrated that ensemble techniques,\nespecially prediction averaging, substantially improve precision beyond\ntraditional metrics for key properties like formation energy per atom ($\\Delta\nE^{f}$), band gap ($E_{g}$) and density ($\\rho$) in 33,990 stable inorganic\nmaterials. These findings support the broader application of ensemble methods\nto enhance predictive accuracy in the field.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 6 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.18847v1",
    "published_date": "2024-07-26 16:12:06 UTC",
    "updated_date": "2024-07-26 16:12:06 UTC"
  },
  {
    "arxiv_id": "2408.05337v1",
    "title": "VACoDe: Visual Augmented Contrastive Decoding",
    "authors": [
      "Sihyeon Kim",
      "Boryeong Cho",
      "Sangmin Bae",
      "Sumyeong Ahn",
      "Se-Young Yun"
    ],
    "abstract": "Despite the astonishing performance of recent Large Vision-Language Models\n(LVLMs), these models often generate inaccurate responses. To address this\nissue, previous studies have focused on mitigating hallucinations by employing\ncontrastive decoding (CD) with augmented images, which amplifies the contrast\nwith the original image. However, these methods have limitations, including\nreliance on a single augmentation, which is restrictive for certain tasks, as\nwell as the high cost of using external knowledge. In this study, we address\nthese limitations by exploring how to utilize multiple image augmentations.\nThrough extensive experiments, we observed that different augmentations produce\nvarying levels of contrast depending on the task. Based on this observation, we\nintroduce a novel method called VACoDe, Visual Augmented Contrastive Decoding.\nThis method adaptively selects the augmentation with the highest contrast for\neach task using the proposed softmax distance metric. Our empirical tests show\nthat \\alg outperforms previous methods and improves output quality in various\nvision-language tasks. Additionally, VACoDe can be universally applied across\ndifferent model types and sizes without additional training or the use of\nexternal models and data.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T01",
      "I.2.0"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.05337v1",
    "published_date": "2024-07-26 15:49:31 UTC",
    "updated_date": "2024-07-26 15:49:31 UTC"
  },
  {
    "arxiv_id": "2407.18827v1",
    "title": "Human-artificial intelligence teaming for scientific information extraction from data-driven additive manufacturing research using large language models",
    "authors": [
      "Mutahar Safdar",
      "Jiarui Xie",
      "Andrei Mircea",
      "Yaoyao Fiona Zhao"
    ],
    "abstract": "Data-driven research in Additive Manufacturing (AM) has gained significant\nsuccess in recent years. This has led to a plethora of scientific literature to\nemerge. The knowledge in these works consists of AM and Artificial Intelligence\n(AI) contexts that have not been mined and formalized in an integrated way. It\nrequires substantial effort and time to extract scientific information from\nthese works. AM domain experts have contributed over two dozen review papers to\nsummarize these works. However, information specific to AM and AI contexts\nstill requires manual effort to extract. The recent success of foundation\nmodels such as BERT (Bidirectional Encoder Representations for Transformers) or\nGPT (Generative Pre-trained Transformers) on textual data has opened the\npossibility of expediting scientific information extraction. We propose a\nframework that enables collaboration between AM and AI experts to continuously\nextract scientific information from data-driven AM literature. A demonstration\ntool is implemented based on the proposed framework and a case study is\nconducted to extract information relevant to the datasets, modeling, sensing,\nand AM system categories. We show the ability of LLMs (Large Language Models)\nto expedite the extraction of relevant information from data-driven AM\nliterature. In the future, the framework can be used to extract information\nfrom the broader design and manufacturing literature in the engineering\ndiscipline.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "11 pages, 5 Figures, 3 Tables. This paper has been accepted to be\n  published in the proceedings of IDETC-CIE 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.18827v1",
    "published_date": "2024-07-26 15:43:52 UTC",
    "updated_date": "2024-07-26 15:43:52 UTC"
  },
  {
    "arxiv_id": "2407.20181v2",
    "title": "Blockchain for Large Language Model Security and Safety: A Holistic Survey",
    "authors": [
      "Caleb Geren",
      "Amanda Board",
      "Gaby G. Dagher",
      "Tim Andersen",
      "Jun Zhuang"
    ],
    "abstract": "With the growing development and deployment of large language models (LLMs)\nin both industrial and academic fields, their security and safety concerns have\nbecome increasingly critical. However, recent studies indicate that LLMs face\nnumerous vulnerabilities, including data poisoning, prompt injections, and\nunauthorized data exposure, which conventional methods have struggled to\naddress fully. In parallel, blockchain technology, known for its data\nimmutability and decentralized structure, offers a promising foundation for\nsafeguarding LLMs. In this survey, we aim to comprehensively assess how to\nleverage blockchain technology to enhance LLMs' security and safety. Besides,\nwe propose a new taxonomy of blockchain for large language models (BC4LLMs) to\nsystematically categorize related works in this emerging field. Our analysis\nincludes novel frameworks and definitions to delineate security and safety in\nthe context of BC4LLMs, highlighting potential research directions and\nchallenges at this intersection. Through this study, we aim to stimulate\ntargeted advancements in blockchain-integrated LLM security.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to SIGKDD Explorations, to appear Dec 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.20181v2",
    "published_date": "2024-07-26 15:24:01 UTC",
    "updated_date": "2024-11-17 22:23:45 UTC"
  },
  {
    "arxiv_id": "2407.18812v1",
    "title": "Online Planning in POMDPs with State-Requests",
    "authors": [
      "Raphael Avalos",
      "Eugenio Bargiacchi",
      "Ann Nowé",
      "Diederik M. Roijers",
      "Frans A. Oliehoek"
    ],
    "abstract": "In key real-world problems, full state information is sometimes available but\nonly at a high cost, like activating precise yet energy-intensive sensors or\nconsulting humans, thereby compelling the agent to operate under partial\nobservability. For this scenario, we propose AEMS-SR (Anytime Error\nMinimization Search with State Requests), a principled online planning\nalgorithm tailored for POMDPs with state requests. By representing the search\nspace as a graph instead of a tree, AEMS-SR avoids the exponential growth of\nthe search space originating from state requests. Theoretical analysis\ndemonstrates AEMS-SR's $\\varepsilon$-optimality, ensuring solution quality,\nwhile empirical evaluations illustrate its effectiveness compared with AEMS and\nPOMCP, two SOTA online planning algorithms. AEMS-SR enables efficient planning\nin domains characterized by partial observability and costly state requests\noffering practical benefits across various applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18812v1",
    "published_date": "2024-07-26 15:20:50 UTC",
    "updated_date": "2024-07-26 15:20:50 UTC"
  },
  {
    "arxiv_id": "2407.18808v1",
    "title": "Learning Chaotic Systems and Long-Term Predictions with Neural Jump ODEs",
    "authors": [
      "Florian Krach",
      "Josef Teichmann"
    ],
    "abstract": "The Path-dependent Neural Jump ODE (PD-NJ-ODE) is a model for online\nprediction of generic (possibly non-Markovian) stochastic processes with\nirregular (in time) and potentially incomplete (with respect to coordinates)\nobservations. It is a model for which convergence to the $L^2$-optimal\npredictor, which is given by the conditional expectation, is established\ntheoretically. Thereby, the training of the model is solely based on a dataset\nof realizations of the underlying stochastic process, without the need of\nknowledge of the law of the process. In the case where the underlying process\nis deterministic, the conditional expectation coincides with the process\nitself. Therefore, this framework can equivalently be used to learn the\ndynamics of ODE or PDE systems solely from realizations of the dynamical system\nwith different initial conditions. We showcase the potential of our method by\napplying it to the chaotic system of a double pendulum. When training the\nstandard PD-NJ-ODE method, we see that the prediction starts to diverge from\nthe true path after about half of the evaluation time. In this work we enhance\nthe model with two novel ideas, which independently of each other improve the\nperformance of our modelling setup. The resulting dynamics match the true\ndynamics of the chaotic system very closely. The same enhancements can be used\nto provably enable the PD-NJ-ODE to learn long-term predictions for general\nstochastic datasets, where the standard model fails. This is verified in\nseveral experiments.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.DS",
      "math.PR"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18808v1",
    "published_date": "2024-07-26 15:18:29 UTC",
    "updated_date": "2024-07-26 15:18:29 UTC"
  },
  {
    "arxiv_id": "2407.18807v3",
    "title": "When narrower is better: the narrow width limit of Bayesian parallel branching neural networks",
    "authors": [
      "Zechen Zhang",
      "Haim Sompolinsky"
    ],
    "abstract": "The infinite width limit of random neural networks is known to result in\nNeural Networks as Gaussian Process (NNGP) (Lee et al. (2018)), characterized\nby task-independent kernels. It is widely accepted that larger network widths\ncontribute to improved generalization (Park et al. (2019)). However, this work\nchallenges this notion by investigating the narrow width limit of the Bayesian\nParallel Branching Neural Network (BPB-NN), an architecture that resembles\nneural networks with residual blocks. We demonstrate that when the width of a\nBPB-NN is significantly smaller compared to the number of training examples,\neach branch exhibits more robust learning due to a symmetry breaking of\nbranches in kernel renormalization. Surprisingly, the performance of a BPB-NN\nin the narrow width limit is generally superior to or comparable to that\nachieved in the wide width limit in bias-limited scenarios. Furthermore, the\nreadout norms of each branch in the narrow width limit are mostly independent\nof the architectural hyperparameters but generally reflective of the nature of\nthe data. We demonstrate such phenomenon primarily in the branching graph\nneural networks, where each branch represents a different order of convolutions\nof the graph; we also extend the results to other more general architectures\nsuch as the residual-MLP and demonstrate that the narrow width effect is a\ngeneral feature of the branching networks. Our results characterize a newly\ndefined narrow-width regime for parallel branching networks in general.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18807v3",
    "published_date": "2024-07-26 15:14:22 UTC",
    "updated_date": "2025-03-10 15:00:49 UTC"
  },
  {
    "arxiv_id": "2407.18998v2",
    "title": "Towards a Cyber Information Ontology",
    "authors": [
      "David Limbaugh",
      "Mark Jensen",
      "John Beverley"
    ],
    "abstract": "This paper introduces a set of terms that are intended to act as an interface\nbetween cyber ontologies (like a file system ontology or a data fusion\nontology) and top- and mid-level ontologies, specifically Basic Formal Ontology\nand the Common Core Ontologies. These terms center on what makes\ncyberinformation management unique: numerous acts of copying items of\ninformation, the aggregates of copies that result from those acts, and the\nfaithful members of those aggregates that represent all other members.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14",
    "pdf_url": "http://arxiv.org/pdf/2407.18998v2",
    "published_date": "2024-07-26 14:59:00 UTC",
    "updated_date": "2024-08-16 03:21:06 UTC"
  },
  {
    "arxiv_id": "2407.18782v1",
    "title": "Understanding XAI Through the Philosopher's Lens: A Historical Perspective",
    "authors": [
      "Martina Mattioli",
      "Antonio Emanuele Cinà",
      "Marcello Pelillo"
    ],
    "abstract": "Despite explainable AI (XAI) has recently become a hot topic and several\ndifferent approaches have been developed, there is still a widespread belief\nthat it lacks a convincing unifying foundation. On the other hand, over the\npast centuries, the very concept of explanation has been the subject of\nextensive philosophical analysis in an attempt to address the fundamental\nquestion of \"why\" in the context of scientific law. However, this discussion\nhas rarely been connected with XAI. This paper tries to fill in this gap and\naims to explore the concept of explanation in AI through an epistemological\nlens. By comparing the historical development of both the philosophy of science\nand AI, an intriguing picture emerges. Specifically, we show that a gradual\nprogression has independently occurred in both domains from logical-deductive\nto statistical models of explanation, thereby experiencing in both cases a\nparadigm shift from deterministic to nondeterministic and probabilistic\ncausality. Interestingly, we also notice that similar concepts have\nindependently emerged in both realms such as, for example, the relation between\nexplanation and understanding and the importance of pragmatic factors. Our\nstudy aims to be the first step towards understanding the philosophical\nunderpinnings of the notion of explanation in AI, and we hope that our findings\nwill shed some fresh light on the elusive nature of XAI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.18782v1",
    "published_date": "2024-07-26 14:44:49 UTC",
    "updated_date": "2024-07-26 14:44:49 UTC"
  },
  {
    "arxiv_id": "2407.18770v1",
    "title": "Any four real numbers are on all fours with analogy",
    "authors": [
      "Yves Lepage",
      "Miguel Couceiro"
    ],
    "abstract": "This work presents a formalization of analogy on numbers that relies on\ngeneralized means. It is motivated by recent advances in artificial\nintelligence and applications of machine learning, where the notion of analogy\nis used to infer results, create data and even as an assessment tool of object\nrepresentations, or embeddings, that are basically collections of numbers\n(vectors, matrices, tensors). This extended analogy use asks for mathematical\nfoundations and clear understanding of the notion of analogy between numbers.\nWe propose a unifying view of analogies that relies on generalized means\ndefined in terms of a power parameter. In particular, we show that any four\nincreasing positive real numbers is an analogy in a unique suitable power. In\naddition, we show that any such analogy can be reduced to an equivalent\narithmetic analogy and that any analogical equation has a solution for\nincreasing numbers, which generalizes without restriction to complex numbers.\nThese foundational results provide a better understanding of analogies in areas\nwhere representations are numerical.",
    "categories": [
      "cs.AI",
      "68Txx"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18770v1",
    "published_date": "2024-07-26 14:30:35 UTC",
    "updated_date": "2024-07-26 14:30:35 UTC"
  },
  {
    "arxiv_id": "2407.18764v2",
    "title": "TAGIFY: LLM-powered Tagging Interface for Improved Data Findability on OGD portals",
    "authors": [
      "Kevin Kliimask",
      "Anastasija Nikiforova"
    ],
    "abstract": "Efforts directed towards promoting Open Government Data (OGD) have gained\nsignificant traction across various governmental tiers since the mid-2000s. As\nmore datasets are published on OGD portals, finding specific data becomes\nharder, leading to information overload. Complete and accurate documentation of\ndatasets, including association of proper tags with datasets is key to\nimproving dataset findability and accessibility. Analysis conducted on the\nEstonian Open Data Portal, revealed that 11% datasets have no associated tags,\nwhile 26% had only one tag assigned to them, which underscores challenges in\ndata findability and accessibility within the portal, which, according to the\nrecent Open Data Maturity Report, is considered trend-setter. The aim of this\nstudy is to propose an automated solution to tagging datasets to improve data\nfindability on OGD portals. This paper presents Tagify - a prototype of tagging\ninterface that employs large language models (LLM) such as GPT-3.5-turbo and\nGPT-4 to automate dataset tagging, generating tags for datasets in English and\nEstonian, thereby augmenting metadata preparation by data publishers and\nimproving data findability on OGD portals by data users. The developed solution\nwas evaluated by users and their feedback was collected to define an agenda for\nfuture prototype improvements.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18764v2",
    "published_date": "2024-07-26 14:22:30 UTC",
    "updated_date": "2024-08-21 12:23:21 UTC"
  },
  {
    "arxiv_id": "2407.18756v1",
    "title": "Evaluating Human Trajectory Prediction with Metamorphic Testing",
    "authors": [
      "Helge Spieker",
      "Nassim Belmecheri",
      "Arnaud Gotlieb",
      "Nadjib Lazaar"
    ],
    "abstract": "The prediction of human trajectories is important for planning in autonomous\nsystems that act in the real world, e.g. automated driving or mobile robots.\nHuman trajectory prediction is a noisy process, and no prediction does\nprecisely match any future trajectory. It is therefore approached as a\nstochastic problem, where the goal is to minimise the error between the true\nand the predicted trajectory. In this work, we explore the application of\nmetamorphic testing for human trajectory prediction. Metamorphic testing is\ndesigned to handle unclear or missing test oracles. It is well-designed for\nhuman trajectory prediction, where there is no clear criterion of correct or\nincorrect human behaviour. Metamorphic relations rely on transformations over\nsource test cases and exploit invariants. A setting well-designed for human\ntrajectory prediction where there are many symmetries of expected human\nbehaviour under variations of the input, e.g. mirroring and rescaling of the\ninput data. We discuss how metamorphic testing can be applied to stochastic\nhuman trajectory prediction and introduce the Wasserstein Violation Criterion\nto statistically assess whether a follow-up test case violates a\nlabel-preserving metamorphic relation.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "MET'24: 9th ACM International Workshop on Metamorphic Testing",
    "pdf_url": "http://arxiv.org/pdf/2407.18756v1",
    "published_date": "2024-07-26 14:10:14 UTC",
    "updated_date": "2024-07-26 14:10:14 UTC"
  },
  {
    "arxiv_id": "2407.18755v2",
    "title": "Score matching through the roof: linear, nonlinear, and latent variables causal discovery",
    "authors": [
      "Francesco Montagna",
      "Philipp M. Faller",
      "Patrick Bloebaum",
      "Elke Kirschbaum",
      "Francesco Locatello"
    ],
    "abstract": "Causal discovery from observational data holds great promise, but existing\nmethods rely on strong assumptions about the underlying causal structure, often\nrequiring full observability of all relevant variables. We tackle these\nchallenges by leveraging the score function $\\nabla \\log p(X)$ of observed\nvariables for causal discovery and propose the following contributions. First,\nwe fine-tune the existing identifiability results with the score on additive\nnoise models, showing that their assumption of nonlinearity of the causal\nmechanisms is not necessary. Second, we establish conditions for inferring\ncausal relations from the score even in the presence of hidden variables; this\nresult is two-faced: we demonstrate the score's potential to infer the\nequivalence class of causal graphs with hidden variables (while previous\nresults are restricted to the fully observable setting), and we provide\nsufficient conditions for identifying direct causes in latent variable models.\nBuilding on these insights, we propose a flexible algorithm suited for causal\ndiscovery on linear, nonlinear, and latent variable models, which we\nempirically validate.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18755v2",
    "published_date": "2024-07-26 14:09:06 UTC",
    "updated_date": "2025-03-22 11:26:14 UTC"
  },
  {
    "arxiv_id": "2407.18752v3",
    "title": "Knowledge Graph Structure as Prompt: Improving Small Language Models Capabilities for Knowledge-based Causal Discovery",
    "authors": [
      "Yuni Susanti",
      "Michael Färber"
    ],
    "abstract": "Causal discovery aims to estimate causal structures among variables based on\nobservational data. Large Language Models (LLMs) offer a fresh perspective to\ntackle the causal discovery problem by reasoning on the metadata associated\nwith variables rather than their actual data values, an approach referred to as\nknowledge-based causal discovery. In this paper, we investigate the\ncapabilities of Small Language Models (SLMs, defined as LLMs with fewer than 1\nbillion parameters) with prompt-based learning for knowledge-based causal\ndiscovery. Specifically, we present KG Structure as Prompt, a novel approach\nfor integrating structural information from a knowledge graph, such as common\nneighbor nodes and metapaths, into prompt-based learning to enhance the\ncapabilities of SLMs. Experimental results on three types of biomedical and\nopen-domain datasets under few-shot settings demonstrate the effectiveness of\nour approach, surpassing most baselines and even conventional fine-tuning\napproaches trained on full datasets. Our findings further highlight the strong\ncapabilities of SLMs: in combination with knowledge graphs and prompt-based\nlearning, SLMs demonstrate the potential to surpass LLMs with larger number of\nparameters. Our code and datasets are available on GitHub.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted at ISWC'24",
    "pdf_url": "http://arxiv.org/pdf/2407.18752v3",
    "published_date": "2024-07-26 14:07:00 UTC",
    "updated_date": "2024-07-30 12:05:11 UTC"
  },
  {
    "arxiv_id": "2407.18749v1",
    "title": "Multi-Robot System Architecture design in SysML and BPMN",
    "authors": [
      "Ahmed R. Sadik",
      "Christian Goerick"
    ],
    "abstract": "Multi-Robot System (MRS) is a complex system that contains many different\nsoftware and hardware components. This main problem addressed in this article\nis the MRS design complexity. The proposed solution provides a modular modeling\nand simulation technique that is based on formal system engineering method,\ntherefore the MRS design complexity is decomposed and reduced. Modeling the MRS\nhas been achieved via two formal Architecture Description Languages (ADLs),\nwhich are Systems Modeling Language (SysML) and Business Process Model and\nNotation (BPMN), to design the system blueprints. By using those abstract\ndesign ADLs, the implementation of the project becomes technology agnostic.\nThis allows to transfer the design concept from on programming language to\nanother. During the simulation phase, a multi-agent environment is used to\nsimulate the MRS blueprints. The simulation has been implemented in Java Agent\nDevelopment (JADE) middleware. Therefore, its results can be used to analysis\nand verify the proposed MRS model in form of performance evaluation matrix.",
    "categories": [
      "cs.AI",
      "cs.RO",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18749v1",
    "published_date": "2024-07-26 14:04:40 UTC",
    "updated_date": "2024-07-26 14:04:40 UTC"
  },
  {
    "arxiv_id": "2407.18738v1",
    "title": "Towards Generalized Offensive Language Identification",
    "authors": [
      "Alphaeus Dmonte",
      "Tejas Arya",
      "Tharindu Ranasinghe",
      "Marcos Zampieri"
    ],
    "abstract": "The prevalence of offensive content on the internet, encompassing hate speech\nand cyberbullying, is a pervasive issue worldwide. Consequently, it has\ngarnered significant attention from the machine learning (ML) and natural\nlanguage processing (NLP) communities. As a result, numerous systems have been\ndeveloped to automatically identify potentially harmful content and mitigate\nits impact. These systems can follow two approaches; (1) Use publicly available\nmodels and application endpoints, including prompting large language models\n(LLMs) (2) Annotate datasets and train ML models on them. However, both\napproaches lack an understanding of how generalizable they are. Furthermore,\nthe applicability of these systems is often questioned in off-domain and\npractical environments. This paper empirically evaluates the generalizability\nof offensive language detection models and datasets across a novel generalized\nbenchmark. We answer three research questions on generalizability. Our findings\nwill be useful in creating robust real-world offensive language detection\nsystems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ASONAM 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.18738v1",
    "published_date": "2024-07-26 13:50:22 UTC",
    "updated_date": "2024-07-26 13:50:22 UTC"
  },
  {
    "arxiv_id": "2407.18735v1",
    "title": "AutoRDF2GML: Facilitating RDF Integration in Graph Machine Learning",
    "authors": [
      "Michael Färber",
      "David Lamprecht",
      "Yuni Susanti"
    ],
    "abstract": "In this paper, we introduce AutoRDF2GML, a framework designed to convert RDF\ndata into data representations tailored for graph machine learning tasks.\nAutoRDF2GML enables, for the first time, the creation of both content-based\nfeatures -- i.e., features based on RDF datatype properties -- and\ntopology-based features -- i.e., features based on RDF object properties.\nCharacterized by automated feature extraction, AutoRDF2GML makes it possible\neven for users less familiar with RDF and SPARQL to generate data\nrepresentations ready for graph machine learning tasks, such as link\nprediction, node classification, and graph classification. Furthermore, we\npresent four new benchmark datasets for graph machine learning, created from\nlarge RDF knowledge graphs using our framework. These datasets serve as\nvaluable resources for evaluating graph machine learning approaches, such as\ngraph neural networks. Overall, our framework effectively bridges the gap\nbetween the Graph Machine Learning and Semantic Web communities, paving the way\nfor RDF-based machine learning applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted at ISWC'24",
    "pdf_url": "http://arxiv.org/pdf/2407.18735v1",
    "published_date": "2024-07-26 13:44:06 UTC",
    "updated_date": "2024-07-26 13:44:06 UTC"
  },
  {
    "arxiv_id": "2407.18996v1",
    "title": "A maturity framework for data driven maintenance",
    "authors": [
      "Chris Rijsdijk",
      "Mike van de Wijnckel",
      "Tiedo Tinga"
    ],
    "abstract": "Maintenance decisions range from the simple detection of faults to ultimately\npredicting future failures and solving the problem. These traditionally human\ndecisions are nowadays increasingly supported by data and the ultimate aim is\nto make them autonomous. This paper explores the challenges encountered in data\ndriven maintenance, and proposes to consider four aspects in a maturity\nframework: data / decision maturity, the translation from the real world to\ndata, the computability of decisions (using models) and the causality in the\nobtained relations. After a discussion of the theoretical concepts involved,\nthe exploration continues by considering a practical fault detection and\nidentification problem. Two approaches, i.e. experience based and model based,\nare compared and discussed in terms of the four aspects in the maturity\nframework. It is observed that both approaches yield the same decisions, but\nstill differ in the assignment of causality. This confirms that a maturity\nassessment not only concerns the type of decision, but should also include the\nother proposed aspects.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "E.1; F.2; G.3; I.2.8; I.6.4; J.6"
    ],
    "primary_category": "cs.AI",
    "comment": "in Proceedings of the 8th European Conference of the Prognostics and\n  Health Management Society 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.18996v1",
    "published_date": "2024-07-26 13:20:58 UTC",
    "updated_date": "2024-07-26 13:20:58 UTC"
  },
  {
    "arxiv_id": "2407.18722v1",
    "title": "Neurosymbolic AI for Enhancing Instructability in Generative AI",
    "authors": [
      "Amit Sheth",
      "Vishal Pallagani",
      "Kaushik Roy"
    ],
    "abstract": "Generative AI, especially via Large Language Models (LLMs), has transformed\ncontent creation across text, images, and music, showcasing capabilities in\nfollowing instructions through prompting, largely facilitated by instruction\ntuning. Instruction tuning is a supervised fine-tuning method where LLMs are\ntrained on datasets formatted with specific tasks and corresponding\ninstructions. This method systematically enhances the model's ability to\ncomprehend and execute the provided directives. Despite these advancements,\nLLMs still face challenges in consistently interpreting complex, multi-step\ninstructions and generalizing them to novel tasks, which are essential for\nbroader applicability in real-world scenarios. This article explores why\nneurosymbolic AI offers a better path to enhance the instructability of LLMs.\nWe explore the use a symbolic task planner to decompose high-level instructions\ninto structured tasks, a neural semantic parser to ground these tasks into\nexecutable actions, and a neuro-symbolic executor to implement these actions\nwhile dynamically maintaining an explicit representation of state. We also seek\nto show that neurosymbolic approach enhances the reliability and\ncontext-awareness of task execution, enabling LLMs to dynamically interpret and\nrespond to a wider range of instructional contexts with greater precision and\nflexibility.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18722v1",
    "published_date": "2024-07-26 13:15:50 UTC",
    "updated_date": "2024-07-26 13:15:50 UTC"
  },
  {
    "arxiv_id": "2407.18712v2",
    "title": "Cluster-norm for Unsupervised Probing of Knowledge",
    "authors": [
      "Walter Laurito",
      "Sharan Maiya",
      "Grégoire Dhimoïla",
      "Owen",
      "Yeung",
      "Kaarel Hänni"
    ],
    "abstract": "The deployment of language models brings challenges in generating reliable\ninformation, especially when these models are fine-tuned using human\npreferences. To extract encoded knowledge without (potentially) biased human\nlabels, unsupervised probing techniques like Contrast-Consistent Search (CCS)\nhave been developed (Burns et al., 2022). However, salient but unrelated\nfeatures in a given dataset can mislead these probes (Farquhar et al., 2023).\nAddressing this, we propose a cluster normalization method to minimize the\nimpact of such features by clustering and normalizing activations of contrast\npairs before applying unsupervised probing techniques. While this approach does\nnot address the issue of differentiating between knowledge in general and\nsimulated knowledge - a major issue in the literature of latent knowledge\nelicitation (Christiano et al., 2021) - it significantly improves the ability\nof unsupervised probes to identify the intended knowledge amidst distractions.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 35 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.18712v2",
    "published_date": "2024-07-26 12:57:54 UTC",
    "updated_date": "2024-10-03 20:53:52 UTC"
  },
  {
    "arxiv_id": "2407.18691v2",
    "title": "Graph Neural Networks for Virtual Sensing in Complex Systems: Addressing Heterogeneous Temporal Dynamics",
    "authors": [
      "Mengjie Zhao",
      "Cees Taal",
      "Stephan Baggerohr",
      "Olga Fink"
    ],
    "abstract": "Real-time condition monitoring is crucial for the reliable and efficient\noperation of complex systems. However, relying solely on physical sensors can\nbe limited due to their cost, placement constraints, or inability to directly\nmeasure certain critical parameters. Virtual sensing addresses these\nlimitations by leveraging readily available sensor data and system knowledge to\nestimate inaccessible parameters or infer system states. The increasing\ncomplexity of industrial systems necessitates deployments of sensors with\ndiverse modalities to provide a comprehensive understanding of system states.\nThese sensors capture data at varying frequencies to monitor both rapid and\nslowly varying system dynamics, as well as local and global state evolutions of\nthe systems. This leads to heterogeneous temporal dynamics, which, particularly\nunder varying operational end environmental conditions, pose a significant\nchallenge for accurate virtual sensing. To address this, we propose a\nHeterogeneous Temporal Graph Neural Network (HTGNN) framework. HTGNN explicitly\nmodels signals from diverse sensors and integrates operating conditions into\nthe model architecture. We evaluate HTGNN using two newly released datasets: a\nbearing dataset with diverse load conditions for bearing load prediction and a\nyear-long simulated dataset for predicting bridge live loads. Our results\ndemonstrate that HTGNN significantly outperforms established baseline methods\nin both tasks, particularly under highly varying operating conditions. These\nresults highlight HTGNN's potential as a robust and accurate virtual sensing\napproach for complex systems, paving the way for improved monitoring,\npredictive maintenance, and enhanced system performance. Our code and data are\navailable under https://github.com/EPFL-IMOS/htgnn.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper extends our previous conference paper (Best Paper at\n  European Conference of the PHM Society 2024,\n  https://doi.org/10.36001/phme.2024.v8i1.3998). Accepted by Mechanical Systems\n  and Signal Processing (MSSP)",
    "pdf_url": "http://arxiv.org/pdf/2407.18691v2",
    "published_date": "2024-07-26 12:16:53 UTC",
    "updated_date": "2025-03-06 15:47:01 UTC"
  },
  {
    "arxiv_id": "2407.18690v1",
    "title": "Collaborative Evolving Strategy for Automatic Data-Centric Development",
    "authors": [
      "Xu Yang",
      "Haotian Chen",
      "Wenjun Feng",
      "Haoxue Wang",
      "Zeqi Ye",
      "Xinjie Shen",
      "Xiao Yang",
      "Shizhao Sun",
      "Weiqing Liu",
      "Jiang Bian"
    ],
    "abstract": "Artificial Intelligence (AI) significantly influences many fields, largely\nthanks to the vast amounts of high-quality data for machine learning models.\nThe emphasis is now on a data-centric AI strategy, prioritizing data\ndevelopment over model design progress. Automating this process is crucial. In\nthis paper, we serve as the first work to introduce the automatic data-centric\ndevelopment (AD^2) task and outline its core challenges, which require\ndomain-experts-like task scheduling and implementation capability, largely\nunexplored by previous work.\n  By leveraging the strong complex problem-solving capabilities of large\nlanguage models (LLMs), we propose an LLM-based autonomous agent, equipped with\na strategy named Collaborative Knowledge-STudying-Enhanced Evolution by\nRetrieval (Co-STEER), to simultaneously address all the challenges.\nSpecifically, our proposed Co-STEER agent enriches its domain knowledge through\nour proposed evolving strategy and develops both its scheduling and\nimplementation skills by accumulating and retrieving domain-specific practical\nexperience. With an improved schedule, the capability for implementation\naccelerates. Simultaneously, as implementation feedback becomes more thorough,\nthe scheduling accuracy increases. These two capabilities evolve together\nthrough practical feedback, enabling a collaborative evolution process.\n  Extensive experimental results demonstrate that our Co-STEER agent breaks new\nground in AD^2 research, possesses strong evolvable schedule and implementation\nability, and demonstrates the significant effectiveness of its components. Our\nCo-STEER paves the way for AD^2 advancements.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.18690v1",
    "published_date": "2024-07-26 12:16:47 UTC",
    "updated_date": "2024-07-26 12:16:47 UTC"
  },
  {
    "arxiv_id": "2408.00804v1",
    "title": "ChipExpert: The Open-Source Integrated-Circuit-Design-Specific Large Language Model",
    "authors": [
      "Ning Xu",
      "Zhaoyang Zhang",
      "Lei Qi",
      "Wensuo Wang",
      "Chao Zhang",
      "Zihao Ren",
      "Huaiyuan Zhang",
      "Xin Cheng",
      "Yanqi Zhang",
      "Zhichao Liu",
      "Qingwen Wei",
      "Shiyang Wu",
      "Lanlan Yang",
      "Qianfeng Lu",
      "Yiqun Ma",
      "Mengyao Zhao",
      "Junbo Liu",
      "Yufan Song",
      "Xin Geng",
      "Jun Yang"
    ],
    "abstract": "The field of integrated circuit (IC) design is highly specialized, presenting\nsignificant barriers to entry and research and development challenges. Although\nlarge language models (LLMs) have achieved remarkable success in various\ndomains, existing LLMs often fail to meet the specific needs of students,\nengineers, and researchers. Consequently, the potential of LLMs in the IC\ndesign domain remains largely unexplored. To address these issues, we introduce\nChipExpert, the first open-source, instructional LLM specifically tailored for\nthe IC design field. ChipExpert is trained on one of the current best\nopen-source base model (Llama-3 8B). The entire training process encompasses\nseveral key stages, including data preparation, continue pre-training,\ninstruction-guided supervised fine-tuning, preference alignment, and\nevaluation. In the data preparation stage, we construct multiple high-quality\ncustom datasets through manual selection and data synthesis techniques. In the\nsubsequent two stages, ChipExpert acquires a vast amount of IC design knowledge\nand learns how to respond to user queries professionally. ChipExpert also\nundergoes an alignment phase, using Direct Preference Optimization, to achieve\na high standard of ethical performance. Finally, to mitigate the hallucinations\nof ChipExpert, we have developed a Retrieval-Augmented Generation (RAG) system,\nbased on the IC design knowledge base. We also released the first IC design\nbenchmark ChipICD-Bench, to evaluate the capabilities of LLMs across multiple\nIC design sub-domains. Through comprehensive experiments conducted on this\nbenchmark, ChipExpert demonstrated a high level of expertise in IC design\nknowledge Question-and-Answer tasks.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00804v1",
    "published_date": "2024-07-26 11:00:08 UTC",
    "updated_date": "2024-07-26 11:00:08 UTC"
  },
  {
    "arxiv_id": "2407.18995v1",
    "title": "SWIFT: Semantic Watermarking for Image Forgery Thwarting",
    "authors": [
      "Gautier Evennou",
      "Vivien Chappelier",
      "Ewa Kijak",
      "Teddy Furon"
    ],
    "abstract": "This paper proposes a novel approach towards image authentication and\ntampering detection by using watermarking as a communication channel for\nsemantic information. We modify the HiDDeN deep-learning watermarking\narchitecture to embed and extract high-dimensional real vectors representing\nimage captions. Our method improves significantly robustness on both malign and\nbenign edits. We also introduce a local confidence metric correlated with\nMessage Recovery Rate, enhancing the method's practical applicability. This\napproach bridges the gap between traditional watermarking and passive forensic\nmethods, offering a robust solution for image integrity verification.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CR",
    "comment": "Code will be released",
    "pdf_url": "http://arxiv.org/pdf/2407.18995v1",
    "published_date": "2024-07-26 09:50:13 UTC",
    "updated_date": "2024-07-26 09:50:13 UTC"
  },
  {
    "arxiv_id": "2407.18626v1",
    "title": "Every Part Matters: Integrity Verification of Scientific Figures Based on Multimodal Large Language Models",
    "authors": [
      "Xiang Shi",
      "Jiawei Liu",
      "Yinpeng Liu",
      "Qikai Cheng",
      "Wei Lu"
    ],
    "abstract": "This paper tackles a key issue in the interpretation of scientific figures:\nthe fine-grained alignment of text and figures. It advances beyond prior\nresearch that primarily dealt with straightforward, data-driven visualizations\nsuch as bar and pie charts and only offered a basic understanding of diagrams\nthrough captioning and classification. We introduce a novel task, Figure\nIntegrity Verification, designed to evaluate the precision of technologies in\naligning textual knowledge with visual elements in scientific figures. To\nsupport this, we develop a semi-automated method for constructing a large-scale\ndataset, Figure-seg, specifically designed for this task. Additionally, we\npropose an innovative framework, Every Part Matters (EPM), which leverages\nMultimodal Large Language Models (MLLMs) to not only incrementally improve the\nalignment and verification of text-figure integrity but also enhance integrity\nthrough analogical reasoning. Our comprehensive experiments show that these\ninnovations substantially improve upon existing methods, allowing for more\nprecise and thorough analysis of complex scientific figures. This progress not\nonly enhances our understanding of multimodal technologies but also stimulates\nfurther research and practical applications across fields requiring the\naccurate interpretation of complex visual data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.DL",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "28 pages, 11 figures, under review",
    "pdf_url": "http://arxiv.org/pdf/2407.18626v1",
    "published_date": "2024-07-26 09:35:36 UTC",
    "updated_date": "2024-07-26 09:35:36 UTC"
  },
  {
    "arxiv_id": "2407.18625v1",
    "title": "Topology Optimization of Random Memristors for Input-Aware Dynamic SNN",
    "authors": [
      "Bo Wang",
      "Shaocong Wang",
      "Ning Lin",
      "Yi Li",
      "Yifei Yu",
      "Yue Zhang",
      "Jichang Yang",
      "Xiaoshan Wu",
      "Yangu He",
      "Songqi Wang",
      "Rui Chen",
      "Guoqi Li",
      "Xiaojuan Qi",
      "Zhongrui Wang",
      "Dashan Shang"
    ],
    "abstract": "There is unprecedented development in machine learning, exemplified by recent\nlarge language models and world simulators, which are artificial neural\nnetworks running on digital computers. However, they still cannot parallel\nhuman brains in terms of energy efficiency and the streamlined adaptability to\ninputs of different difficulties, due to differences in signal representation,\noptimization, run-time reconfigurability, and hardware architecture. To address\nthese fundamental challenges, we introduce pruning optimization for input-aware\ndynamic memristive spiking neural network (PRIME). Signal representation-wise,\nPRIME employs leaky integrate-and-fire neurons to emulate the brain's inherent\nspiking mechanism. Drawing inspiration from the brain's structural plasticity,\nPRIME optimizes the topology of a random memristive spiking neural network\nwithout expensive memristor conductance fine-tuning. For runtime\nreconfigurability, inspired by the brain's dynamic adjustment of computational\ndepth, PRIME employs an input-aware dynamic early stop policy to minimize\nlatency during inference, thereby boosting energy efficiency without\ncompromising performance. Architecture-wise, PRIME leverages memristive\nin-memory computing, mirroring the brain and mitigating the von Neumann\nbottleneck. We validated our system using a 40 nm 256 Kb memristor-based\nin-memory computing macro on neuromorphic image classification and image\ninpainting. Our results demonstrate the classification accuracy and Inception\nScore are comparable to the software baseline, while achieving maximal\n62.50-fold improvements in energy efficiency, and maximal 77.0% computational\nload savings. The system also exhibits robustness against stochastic synaptic\nnoise of analogue memristors. Our software-hardware co-designed model paves the\nway to future brain-inspired neuromorphic computing with brain-like energy\nefficiency and adaptivity.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.ET",
    "comment": "15 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.18625v1",
    "published_date": "2024-07-26 09:35:02 UTC",
    "updated_date": "2024-07-26 09:35:02 UTC"
  },
  {
    "arxiv_id": "2407.18607v2",
    "title": "Using GPT-4 to guide causal machine learning",
    "authors": [
      "Anthony C. Constantinou",
      "Neville K. Kitson",
      "Alessio Zanga"
    ],
    "abstract": "Since its introduction to the public, ChatGPT has had an unprecedented\nimpact. While some experts praised AI advancements and highlighted their\npotential risks, others have been critical about the accuracy and usefulness of\nLarge Language Models (LLMs). In this paper, we are interested in the ability\nof LLMs to identify causal relationships. We focus on the well-established\nGPT-4 (Turbo) and evaluate its performance under the most restrictive\nconditions, by isolating its ability to infer causal relationships based solely\non the variable labels without being given any other context by humans,\ndemonstrating the minimum level of effectiveness one can expect when it is\nprovided with label-only information. We show that questionnaire participants\njudge the GPT-4 graphs as the most accurate in the evaluated categories,\nclosely followed by knowledge graphs constructed by domain experts, with causal\nMachine Learning (ML) far behind. We use these results to highlight the\nimportant limitation of causal ML, which often produces causal graphs that\nviolate common sense, affecting trust in them. However, we show that pairing\nGPT-4 with causal ML overcomes this limitation, resulting in graphical\nstructures learnt from real data that align more closely with those identified\nby domain experts, compared to structures learnt by causal ML alone. Overall,\nour findings suggest that despite GPT-4 not being explicitly designed to reason\ncausally, it can still be a valuable tool for causal representation, as it\nimproves the causal discovery process of causal ML algorithms that are designed\nto do just that.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18607v2",
    "published_date": "2024-07-26 08:59:26 UTC",
    "updated_date": "2024-12-11 19:43:54 UTC"
  },
  {
    "arxiv_id": "2407.18601v2",
    "title": "Reorganizing attention-space geometry with expressive attention",
    "authors": [
      "Claudius Gros"
    ],
    "abstract": "Attention regulates information transfer between tokens. For this, query and\nkey vectors are compared, typically in terms of a scalar product,\n$\\mathbf{Q}^T\\mathbf{K}$, together with a subsequent softmax normalization. In\ngeometric terms, the standard dot-product attention (DPA) leads to large/small\nattention weights for parallel/antiparallel queries and keys. Here we study\nexpressive attention (EA), which is based on $(\\mathbf{Q}^T\\mathbf{K})^2$, the\nsquared dot product. In this case, attention is enhanced when query and key are\neither parallel or antiparallel, and suppressed for orthogonal configurations.\nEA can be introduced into any attention-based code without additional compute\ncosts or memory requirements. For a series of autoregressive prediction tasks,\nwe find that expressive attention performs at least as well as vanilla DPA.\nIncreasing task complexity, EA is observed to outperform DPA with increasing\nmargins, which also holds for multi-task settings. For a given model size, EA\nmanages to achieve 100% performance for a range of complexity levels not\naccessible to DPA. Our results show that it is possible to reorganize the\ngeometry of the matching condition in the space of attention heads without loss\nof performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18601v2",
    "published_date": "2024-07-26 08:41:58 UTC",
    "updated_date": "2025-01-08 09:30:47 UTC"
  },
  {
    "arxiv_id": "2407.18597v1",
    "title": "Reinforcement Learning for Sustainable Energy: A Survey",
    "authors": [
      "Koen Ponse",
      "Felix Kleuker",
      "Márton Fejér",
      "Álvaro Serra-Gómez",
      "Aske Plaat",
      "Thomas Moerland"
    ],
    "abstract": "The transition to sustainable energy is a key challenge of our time,\nrequiring modifications in the entire pipeline of energy production, storage,\ntransmission, and consumption. At every stage, new sequential decision-making\nchallenges emerge, ranging from the operation of wind farms to the management\nof electrical grids or the scheduling of electric vehicle charging stations.\nAll such problems are well suited for reinforcement learning, the branch of\nmachine learning that learns behavior from data. Therefore, numerous studies\nhave explored the use of reinforcement learning for sustainable energy. This\npaper surveys this literature with the intention of bridging both the\nunderlying research communities: energy and machine learning. After a brief\nintroduction of both fields, we systematically list relevant sustainability\nchallenges, how they can be modeled as a reinforcement learning problem, and\nwhat solution approaches currently exist in the literature. Afterwards, we zoom\nout and identify overarching reinforcement learning themes that appear\nthroughout sustainability, such as multi-agent, offline, and safe reinforcement\nlearning. Lastly, we also cover standardization of environments, which will be\ncrucial for connecting both research fields, and highlight potential directions\nfor future work. In summary, this survey provides an extensive overview of\nreinforcement learning methods for sustainable energy, which may play a vital\nrole in the energy transition.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.SY",
      "eess.SY",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages excluding references, 40 pages including references, 7\n  images",
    "pdf_url": "http://arxiv.org/pdf/2407.18597v1",
    "published_date": "2024-07-26 08:37:14 UTC",
    "updated_date": "2024-07-26 08:37:14 UTC"
  },
  {
    "arxiv_id": "2407.21060v1",
    "title": "Using Large Language Models for the Interpretation of Building Regulations",
    "authors": [
      "Stefan Fuchs",
      "Michael Witbrock",
      "Johannes Dimyadi",
      "Robert Amor"
    ],
    "abstract": "Compliance checking is an essential part of a construction project. The\nrecent rapid uptake of building information models (BIM) in the construction\nindustry has created more opportunities for automated compliance checking\n(ACC). BIM enables sharing of digital building design data that can be used for\ncompliance checking with legal requirements, which are conventionally conveyed\nin natural language and not intended for machine processing. Creating a\ncomputable representation of legal requirements suitable for ACC is complex,\ncostly, and time-consuming. Large language models (LLMs) such as the generative\npre-trained transformers (GPT), GPT-3.5 and GPT-4, powering OpenAI's ChatGPT,\ncan generate logically coherent text and source code responding to user\nprompts. This capability could be used to automate the conversion of building\nregulations into a semantic and computable representation. This paper evaluates\nthe performance of LLMs in translating building regulations into LegalRuleML in\na few-shot learning setup. By providing GPT-3.5 with only a few example\ntranslations, it can learn the basic structure of the format. Using a system\nprompt, we further specify the LegalRuleML representation and explore the\nexistence of expert domain knowledge in the model. Such domain knowledge might\nbe ingrained in GPT-3.5 through the broad pre-training but needs to be brought\nforth by careful contextualisation. Finally, we investigate whether strategies\nsuch as chain-of-thought reasoning and self-consistency could apply to this use\ncase. As LLMs become more sophisticated, the increased common sense, logical\ncoherence, and means to domain adaptation can significantly support ACC,\nleading to more efficient and effective checking processes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Presented at the 13th Conference on Engineering, Project and\n  Production Management",
    "pdf_url": "http://arxiv.org/pdf/2407.21060v1",
    "published_date": "2024-07-26 08:30:47 UTC",
    "updated_date": "2024-07-26 08:30:47 UTC"
  },
  {
    "arxiv_id": "2407.18581v4",
    "title": "Dynamic Language Group-Based MoE: Enhancing Code-Switching Speech Recognition with Hierarchical Routing",
    "authors": [
      "Hukai Huang",
      "Shenghui Lu",
      "Yahui Shan",
      "He Qu",
      "Fengrun Zhang",
      "Wenhao Guan",
      "Qingyang Hong",
      "Lin Li"
    ],
    "abstract": "The Mixture of Experts (MoE) model is a promising approach for handling\ncode-switching speech recognition (CS-ASR) tasks. However, the existing CS-ASR\nwork on MoE has yet to leverage the advantages of MoE's parameter scaling\nability fully. This work proposes DLG-MoE, a Dynamic Language Group-based MoE,\nwhich can effectively handle the CS-ASR task and leverage the advantages of\nparameter scaling. DLG-MoE operates based on a hierarchical routing mechanism.\nFirst, the language router explicitly models the language attribute and\ndispatches the representations to the corresponding language expert groups.\nSubsequently, the unsupervised router within each language group implicitly\nmodels attributes beyond language and coordinates expert routing and\ncollaboration. DLG-MoE outperforms the existing MoE methods on CS-ASR tasks\nwhile demonstrating great flexibility. It supports different top-$k$ inference\nand streaming capabilities and can also prune the model parameters flexibly to\nobtain a monolingual sub-model. The code has been released.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICASSP2025",
    "pdf_url": "http://arxiv.org/pdf/2407.18581v4",
    "published_date": "2024-07-26 08:03:07 UTC",
    "updated_date": "2024-12-22 03:01:37 UTC"
  },
  {
    "arxiv_id": "2407.18994v1",
    "title": "Online Test Synthesis From Requirements: Enhancing Reinforcement Learning with Game Theory",
    "authors": [
      "Ocan Sankur",
      "Thierry Jéron",
      "Nicolas Markey",
      "David Mentré",
      "Reiya Noguchi"
    ],
    "abstract": "We consider the automatic online synthesis of black-box test cases from\nfunctional requirements specified as automata for reactive implementations. The\ngoal of the tester is to reach some given state, so as to satisfy a coverage\ncriterion, while monitoring the violation of the requirements. We develop an\napproach based on Monte Carlo Tree Search, which is a classical technique in\nreinforcement learning for efficiently selecting promising inputs. Seeing the\nautomata requirements as a game between the implementation and the tester, we\ndevelop a heuristic by biasing the search towards inputs that are promising in\nthis game. We experimentally show that our heuristic accelerates the\nconvergence of the Monte Carlo Tree Search algorithm, thus improving the\nperformance of testing.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18994v1",
    "published_date": "2024-07-26 07:59:59 UTC",
    "updated_date": "2024-07-26 07:59:59 UTC"
  },
  {
    "arxiv_id": "2407.18571v2",
    "title": "Speech Bandwidth Expansion Via High Fidelity Generative Adversarial Networks",
    "authors": [
      "Mahmoud Salhab",
      "Haidar Harmanani"
    ],
    "abstract": "Speech bandwidth expansion is crucial for expanding the frequency range of\nlow-bandwidth speech signals, thereby improving audio quality, clarity and\nperceptibility in digital applications. Its applications span telephony,\ncompression, text-to-speech synthesis, and speech recognition. This paper\npresents a novel approach using a high-fidelity generative adversarial network,\nunlike cascaded systems, our system is trained end-to-end on paired narrowband\nand wideband speech signals. Our method integrates various bandwidth upsampling\nratios into a single unified model specifically designed for speech bandwidth\nexpansion applications. Our approach exhibits robust performance across various\nbandwidth expansion factors, including those not encountered during training,\ndemonstrating zero-shot capability. To the best of our knowledge, this is the\nfirst work to showcase this capability. The experimental results demonstrate\nthat our method outperforms previous end-to-end approaches, as well as\ninterpolation and traditional techniques, showcasing its effectiveness in\npractical speech enhancement applications.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18571v2",
    "published_date": "2024-07-26 07:54:47 UTC",
    "updated_date": "2024-07-29 07:29:17 UTC"
  },
  {
    "arxiv_id": "2407.18569v3",
    "title": "PP-TIL: Personalized Planning for Autonomous Driving with Instance-based Transfer Imitation Learning",
    "authors": [
      "Fangze Lin",
      "Ying He",
      "Fei Yu"
    ],
    "abstract": "Personalized motion planning holds significant importance within urban\nautomated driving, catering to the unique requirements of individual users.\nNevertheless, prior endeavors have frequently encountered difficulties in\nsimultaneously addressing two crucial aspects: personalized planning within\nintricate urban settings and enhancing planning performance through data\nutilization. The challenge arises from the expensive and limited nature of user\ndata, coupled with the scene state space tending towards infinity. These\nfactors contribute to overfitting and poor generalization problems during model\ntraining. Henceforth, we propose an instance-based transfer imitation learning\napproach. This method facilitates knowledge transfer from extensive expert\ndomain data to the user domain, presenting a fundamental resolution to these\nissues. We initially train a pre-trained model using large-scale expert data.\nSubsequently, during the fine-tuning phase, we feed the batch data, which\ncomprises expert and user data. Employing the inverse reinforcement learning\ntechnique, we extract the style feature distribution from user demonstrations,\nconstructing the regularization term for the approximation of user style. In\nour experiments, we conducted extensive evaluations of the proposed method.\nCompared to the baseline methods, our approach mitigates the overfitting issue\ncaused by sparse user data. Furthermore, we discovered that integrating the\ndriving model with a differentiable nonlinear optimizer as a safety protection\nlayer for end-to-end personalized fine-tuning results in superior planning\nperformance.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "IROS 2024 Accepted",
    "pdf_url": "http://arxiv.org/pdf/2407.18569v3",
    "published_date": "2024-07-26 07:51:11 UTC",
    "updated_date": "2024-08-04 09:01:00 UTC"
  },
  {
    "arxiv_id": "2407.18562v1",
    "title": "Learning Robust Named Entity Recognizers From Noisy Data With Retrieval Augmentation",
    "authors": [
      "Chaoyi Ai",
      "Yong Jiang",
      "Shen Huang",
      "Pengjun Xie",
      "Kewei Tu"
    ],
    "abstract": "Named entity recognition (NER) models often struggle with noisy inputs, such\nas those with spelling mistakes or errors generated by Optical Character\nRecognition processes, and learning a robust NER model is challenging. Existing\nrobust NER models utilize both noisy text and its corresponding gold text for\ntraining, which is infeasible in many real-world applications in which gold\ntext is not available. In this paper, we consider a more realistic setting in\nwhich only noisy text and its NER labels are available. We propose to retrieve\nrelevant text of the noisy text from a knowledge corpus and use it to enhance\nthe representation of the original noisy input. We design three retrieval\nmethods: sparse retrieval based on lexicon similarity, dense retrieval based on\nsemantic similarity, and self-retrieval based on task-specific text. After\nretrieving relevant text, we concatenate the retrieved text with the original\nnoisy text and encode them with a transformer network, utilizing self-attention\nto enhance the contextual token representations of the noisy text using the\nretrieved text. We further employ a multi-view training framework that improves\nrobust NER without retrieving text during inference. Experiments show that our\nretrieval-augmented model achieves significant improvements in various noisy\nNER settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18562v1",
    "published_date": "2024-07-26 07:30:41 UTC",
    "updated_date": "2024-07-26 07:30:41 UTC"
  },
  {
    "arxiv_id": "2407.18556v1",
    "title": "Look Globally and Reason: Two-stage Path Reasoning over Sparse Knowledge Graphs",
    "authors": [
      "Saiping Guan",
      "Jiyao Wei",
      "Xiaolong Jin",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "abstract": "Sparse Knowledge Graphs (KGs), frequently encountered in real-world\napplications, contain fewer facts in the form of (head entity, relation, tail\nentity) compared to more populated KGs. The sparse KG completion task, which\nreasons answers for given queries in the form of (head entity, relation, ?) for\nsparse KGs, is particularly challenging due to the necessity of reasoning\nmissing facts based on limited facts. Path-based models, known for excellent\nexplainability, are often employed for this task. However, existing path-based\nmodels typically rely on external models to fill in missing facts and\nsubsequently perform path reasoning. This approach introduces unexplainable\nfactors or necessitates meticulous rule design. In light of this, this paper\nproposes an alternative approach by looking inward instead of seeking external\nassistance. We introduce a two-stage path reasoning model called LoGRe (Look\nGlobally and Reason) over sparse KGs. LoGRe constructs a relation-path\nreasoning schema by globally analyzing the training data to alleviate the\nsparseness problem. Based on this schema, LoGRe then aggregates paths to reason\nout answers. Experimental results on five benchmark sparse KG datasets\ndemonstrate the effectiveness of the proposed LoGRe model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to CIKM 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.18556v1",
    "published_date": "2024-07-26 07:10:27 UTC",
    "updated_date": "2024-07-26 07:10:27 UTC"
  },
  {
    "arxiv_id": "2407.18555v3",
    "title": "How to Segment in 3D Using 2D Models: Automated 3D Segmentation of Prostate Cancer Metastatic Lesions on PET Volumes Using Multi-angle Maximum Intensity Projections and Diffusion Models",
    "authors": [
      "Amirhosein Toosi",
      "Sara Harsini",
      "François Bénard",
      "Carlos Uribe",
      "Arman Rahmim"
    ],
    "abstract": "Prostate specific membrane antigen (PSMA) positron emission\ntomography/computed tomography (PET/CT) imaging provides a tremendously\nexciting frontier in visualization of prostate cancer (PCa) metastatic lesions.\nHowever, accurate segmentation of metastatic lesions is challenging due to low\nsignal-to-noise ratios and variable sizes, shapes, and locations of the\nlesions. This study proposes a novel approach for automated segmentation of\nmetastatic lesions in PSMA PET/CT 3D volumetric images using 2D denoising\ndiffusion probabilistic models (DDPMs). Instead of 2D trans-axial slices or 3D\nvolumes, the proposed approach segments the lesions on generated multi-angle\nmaximum intensity projections (MA-MIPs) of the PSMA PET images, then obtains\nthe final 3D segmentation masks from 3D ordered subset expectation maximization\n(OSEM) reconstruction of 2D MA-MIPs segmentations. Our proposed method achieved\nsuperior performance compared to state-of-the-art 3D segmentation approaches in\nterms of accuracy and robustness in detecting and segmenting small metastatic\nPCa lesions. The proposed method has significant potential as a tool for\nquantitative analysis of metastatic burden in PCa patients.",
    "categories": [
      "physics.med-ph",
      "cs.AI",
      "cs.CV",
      "I.4.6"
    ],
    "primary_category": "physics.med-ph",
    "comment": "11 pages, 2 figures, accepted in the DGM4MICCAI workshop, MICCAI,\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2407.18555v3",
    "published_date": "2024-07-26 07:08:05 UTC",
    "updated_date": "2024-12-04 12:42:04 UTC"
  },
  {
    "arxiv_id": "2408.06359v1",
    "title": "An Adaptive CSI Feedback Model Based on BiLSTM for Massive MIMO-OFDM Systems",
    "authors": [
      "Hongrui Shen",
      "Long Zhao",
      "Kan Zheng",
      "Yuhua Cao",
      "Pingzhi Fan"
    ],
    "abstract": "Deep learning (DL)-based channel state information (CSI) feedback has the\npotential to improve the recovery accuracy and reduce the feedback overhead in\nmassive multiple-input multiple-output orthogonal frequency division\nmultiplexing (MIMO-OFDM) systems. However, the length of input CSI and the\nnumber of feedback bits should be adjustable in different scenarios, which can\nnot be efficiently achieved by the existing CSI feedback models. Therefore, an\nadaptive bidirectional long short-term memory network (ABLNet) for CSI feedback\nis first designed to process various input CSI lengths, where the number of\nfeedback bits is in proportion to the CSI length. Then, to realize a more\nflexible feedback bit number, a feedback bit control unit (FBCU) module is\nproposed to control the output length of feedback bits. Based on which, a\ntarget feedback performance can be adaptively achieved by a designed bit number\nadjusting (BNA) algorithm. Furthermore, a novel separate training approach is\ndevised to solve the model protection problem that the UE and gNB are from\ndifferent manufacturers. Experiments demonstrate that the proposed ABLNet with\nFBCU can fit for different input CSI lengths and feedback bit numbers; the CSI\nfeedback performance can be stabilized by the BNA algorithm; and the proposed\nseparate training approach can maintain the feedback performance and reduce the\ncomplexity of feedback model.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "13 pages, 14 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.06359v1",
    "published_date": "2024-07-26 07:07:34 UTC",
    "updated_date": "2024-07-26 07:07:34 UTC"
  },
  {
    "arxiv_id": "2407.18551v3",
    "title": "Multi-Agent Trajectory Prediction with Difficulty-Guided Feature Enhancement Network",
    "authors": [
      "Guipeng Xin",
      "Duanfeng Chu",
      "Liping Lu",
      "Zejian Deng",
      "Yuang Lu",
      "Xigang Wu"
    ],
    "abstract": "Trajectory prediction is crucial for autonomous driving as it aims to\nforecast the future movements of traffic participants. Traditional methods\nusually perform holistic inference on the trajectories of agents, neglecting\nthe differences in prediction difficulty among agents. This paper proposes a\nnovel Difficulty-Guided Feature Enhancement Network (DGFNet), which leverages\nthe prediction difficulty differences among agents for multi-agent trajectory\nprediction. Firstly, we employ spatio-temporal feature encoding and interaction\nto capture rich spatio-temporal features. Secondly, a difficulty-guided decoder\ncontrols the flow of future trajectories into subsequent modules, obtaining\nreliable future trajectories. Then, feature interaction and fusion are\nperformed through the future feature interaction module. Finally, the fused\nagent features are fed into the final predictor to generate the predicted\ntrajectory distributions for multiple participants. Experimental results\ndemonstrate that our DGFNet achieves state-of-the-art performance on the\nArgoverse 1\\&2 motion forecasting benchmarks. Ablation studies further validate\nthe effectiveness of each module. Moreover, compared with SOTA methods, our\nmethod balances trajectory prediction accuracy and real-time inference speed.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18551v3",
    "published_date": "2024-07-26 07:04:30 UTC",
    "updated_date": "2024-12-19 09:55:05 UTC"
  },
  {
    "arxiv_id": "2407.18550v1",
    "title": "ReALFRED: An Embodied Instruction Following Benchmark in Photo-Realistic Environments",
    "authors": [
      "Taewoong Kim",
      "Cheolhong Min",
      "Byeonghwi Kim",
      "Jinyeon Kim",
      "Wonje Jeung",
      "Jonghyun Choi"
    ],
    "abstract": "Simulated virtual environments have been widely used to learn robotic agents\nthat perform daily household tasks. These environments encourage research\nprogress by far, but often provide limited object interactability, visual\nappearance different from real-world environments, or relatively smaller\nenvironment sizes. This prevents the learned models in the virtual scenes from\nbeing readily deployable. To bridge the gap between these learning environments\nand deploying (i.e., real) environments, we propose the ReALFRED benchmark that\nemploys real-world scenes, objects, and room layouts to learn agents to\ncomplete household tasks by understanding free-form language instructions and\ninteracting with objects in large, multi-room and 3D-captured scenes.\nSpecifically, we extend the ALFRED benchmark with updates for larger\nenvironmental spaces with smaller visual domain gaps. With ReALFRED, we analyze\npreviously crafted methods for the ALFRED benchmark and observe that they\nconsistently yield lower performance in all metrics, encouraging the community\nto develop methods in more realistic environments. Our code and data are\npublicly available.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "ECCV 2024 (Project page: https://twoongg.github.io/projects/realfred)",
    "pdf_url": "http://arxiv.org/pdf/2407.18550v1",
    "published_date": "2024-07-26 07:00:27 UTC",
    "updated_date": "2024-07-26 07:00:27 UTC"
  },
  {
    "arxiv_id": "2407.18541v1",
    "title": "Towards Improving NAM-to-Speech Synthesis Intelligibility using Self-Supervised Speech Models",
    "authors": [
      "Neil Shah",
      "Shirish Karande",
      "Vineet Gandhi"
    ],
    "abstract": "We propose a novel approach to significantly improve the intelligibility in\nthe Non-Audible Murmur (NAM)-to-speech conversion task, leveraging\nself-supervision and sequence-to-sequence (Seq2Seq) learning techniques. Unlike\nconventional methods that explicitly record ground-truth speech, our\nmethodology relies on self-supervision and speech-to-speech synthesis to\nsimulate ground-truth speech. Despite utilizing simulated speech, our method\nsurpasses the current state-of-the-art (SOTA) by 29.08% improvement in the\nMel-Cepstral Distortion (MCD) metric. Additionally, we present error rates and\ndemonstrate our model's proficiency to synthesize speech in novel voices of\ninterest. Moreover, we present a methodology for augmenting the existing CSTR\nNAM TIMIT Plus corpus, setting a benchmark with a Word Error Rate (WER) of\n42.57% to gauge the intelligibility of the synthesized speech. Speech samples\ncan be found at https://nam2speech.github.io/NAM2Speech/",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted at Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.18541v1",
    "published_date": "2024-07-26 06:44:01 UTC",
    "updated_date": "2024-07-26 06:44:01 UTC"
  },
  {
    "arxiv_id": "2407.18540v1",
    "title": "A Universal Prompting Strategy for Extracting Process Model Information from Natural Language Text using Large Language Models",
    "authors": [
      "Julian Neuberger",
      "Lars Ackermann",
      "Han van der Aa",
      "Stefan Jablonski"
    ],
    "abstract": "Over the past decade, extensive research efforts have been dedicated to the\nextraction of information from textual process descriptions. Despite the\nremarkable progress witnessed in natural language processing (NLP), information\nextraction within the Business Process Management domain remains predominantly\nreliant on rule-based systems and machine learning methodologies. Data scarcity\nhas so far prevented the successful application of deep learning techniques.\nHowever, the rapid progress in generative large language models (LLMs) makes it\npossible to solve many NLP tasks with very high quality without the need for\nextensive data. Therefore, we systematically investigate the potential of LLMs\nfor extracting information from textual process descriptions, targeting the\ndetection of process elements such as activities and actors, and relations\nbetween them. Using a heuristic algorithm, we demonstrate the suitability of\nthe extracted information for process model generation. Based on a novel\nprompting strategy, we show that LLMs are able to outperform state-of-the-art\nmachine learning approaches with absolute performance improvements of up to 8\\%\n$F_1$ score across three different datasets. We evaluate our prompting strategy\non eight different LLMs, showing it is universally applicable, while also\nanalyzing the impact of certain prompt parts on extraction quality. The number\nof example texts, the specificity of definitions, and the rigour of format\ninstructions are identified as key for improving the accuracy of extracted\ninformation. Our code, prompts, and data are publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18540v1",
    "published_date": "2024-07-26 06:39:35 UTC",
    "updated_date": "2024-07-26 06:39:35 UTC"
  },
  {
    "arxiv_id": "2407.20284v1",
    "title": "MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI",
    "authors": [
      "Shyam Dongre",
      "Ritesh Chandra",
      "Sonali Agarwal"
    ],
    "abstract": "In modern healthcare, addressing the complexities of accurate disease\nprediction and personalized recommendations is both crucial and challenging.\nThis research introduces MLtoGAI, which integrates Semantic Web technology with\nMachine Learning (ML) to enhance disease prediction and offer user-friendly\nexplanations through ChatGPT. The system comprises three key components: a\nreusable disease ontology that incorporates detailed knowledge about various\ndiseases, a diagnostic classification model that uses patient symptoms to\ndetect specific diseases accurately, and the integration of Semantic Web Rule\nLanguage (SWRL) with ontology and ChatGPT to generate clear, personalized\nhealth advice. This approach significantly improves prediction accuracy and\nensures results that are easy to understand, addressing the complexity of\ndiseases and diverse symptoms. The MLtoGAI system demonstrates substantial\nadvancements in accuracy and user satisfaction, contributing to developing more\nintelligent and accessible healthcare solutions. This innovative approach\ncombines the strengths of ML algorithms with the ability to provide\ntransparent, human-understandable explanations through ChatGPT, achieving\nsignificant improvements in prediction accuracy and user comprehension. By\nleveraging semantic technology and explainable AI, the system enhances the\naccuracy of disease prediction and ensures that the recommendations are\nrelevant and easily understood by individual patients. Our research highlights\nthe potential of integrating advanced technologies to overcome existing\nchallenges in medical diagnostics, paving the way for future developments in\nintelligent healthcare systems. Additionally, the system is validated using 200\nsynthetic patient data records, ensuring robust performance and reliability.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20284v1",
    "published_date": "2024-07-26 06:32:06 UTC",
    "updated_date": "2024-07-26 06:32:06 UTC"
  },
  {
    "arxiv_id": "2407.18532v1",
    "title": "Outer Approximation and Super-modular Cuts for Constrained Assortment Optimization under Mixed-Logit Model",
    "authors": [
      "Hoang Giang Pham",
      "Tien Mai"
    ],
    "abstract": "In this paper, we study the assortment optimization problem under the\nmixed-logit customer choice model. While assortment optimization has been a\nmajor topic in revenue management for decades, the mixed-logit model is\nconsidered one of the most general and flexible approaches for modeling and\npredicting customer purchasing behavior. Existing exact methods have primarily\nrelied on mixed-integer linear programming (MILP) or second-order cone (CONIC)\nreformulations, which allow for exact problem solving using off-the-shelf\nsolvers. However, these approaches often suffer from weak continuous\nrelaxations and are slow when solving large instances. Our work addresses the\nproblem by focusing on components of the objective function that can be proven\nto be monotonically super-modular and convex. This allows us to derive valid\ncuts to outer-approximate the nonlinear objective functions. We then\ndemonstrate that these valid cuts can be incorporated into Cutting Plane or\nBranch-and-Cut methods to solve the problem exactly. Extensive experiments show\nthat our approaches consistently outperform previous methods in terms of both\nsolution quality and computation time.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18532v1",
    "published_date": "2024-07-26 06:27:11 UTC",
    "updated_date": "2024-07-26 06:27:11 UTC"
  },
  {
    "arxiv_id": "2407.18525v1",
    "title": "Is larger always better? Evaluating and prompting large language models for non-generative medical tasks",
    "authors": [
      "Yinghao Zhu",
      "Junyi Gao",
      "Zixiang Wang",
      "Weibin Liao",
      "Xiaochen Zheng",
      "Lifang Liang",
      "Yasha Wang",
      "Chengwei Pan",
      "Ewen M. Harrison",
      "Liantao Ma"
    ],
    "abstract": "The use of Large Language Models (LLMs) in medicine is growing, but their\nability to handle both structured Electronic Health Record (EHR) data and\nunstructured clinical notes is not well-studied. This study benchmarks various\nmodels, including GPT-based LLMs, BERT-based models, and traditional clinical\npredictive models, for non-generative medical tasks utilizing renowned\ndatasets. We assessed 14 language models (9 GPT-based and 5 BERT-based) and 7\ntraditional predictive models using the MIMIC dataset (ICU patient records) and\nthe TJH dataset (early COVID-19 EHR data), focusing on tasks such as mortality\nand readmission prediction, disease hierarchy reconstruction, and biomedical\nsentence matching, comparing both zero-shot and finetuned performance. Results\nindicated that LLMs exhibited robust zero-shot predictive capabilities on\nstructured EHR data when using well-designed prompting strategies, frequently\nsurpassing traditional models. However, for unstructured medical texts, LLMs\ndid not outperform finetuned BERT models, which excelled in both supervised and\nunsupervised tasks. Consequently, while LLMs are effective for zero-shot\nlearning on structured data, finetuned BERT models are more suitable for\nunstructured texts, underscoring the importance of selecting models based on\nspecific task requirements and data characteristics to optimize the application\nof NLP technology in healthcare.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: text overlap with arXiv:2402.01713",
    "pdf_url": "http://arxiv.org/pdf/2407.18525v1",
    "published_date": "2024-07-26 06:09:10 UTC",
    "updated_date": "2024-07-26 06:09:10 UTC"
  },
  {
    "arxiv_id": "2407.18524v1",
    "title": "She Works, He Works: A Curious Exploration of Gender Bias in AI-Generated Imagery",
    "authors": [
      "Amalia Foka"
    ],
    "abstract": "This paper examines gender bias in AI-generated imagery of construction\nworkers, highlighting discrepancies in the portrayal of male and female\nfigures. Grounded in Griselda Pollock's theories on visual culture and gender,\nthe analysis reveals that AI models tend to sexualize female figures while\nportraying male figures as more authoritative and competent. These findings\nunderscore AI's potential to mirror and perpetuate societal biases, emphasizing\nthe need for critical engagement with AI-generated content. The project\ncontributes to discussions on the ethical implications of AI in creative\npractices and its broader impact on cultural perceptions of gender.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CV",
      "I.2.0; J.5"
    ],
    "primary_category": "cs.CY",
    "comment": "11 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.18524v1",
    "published_date": "2024-07-26 05:56:18 UTC",
    "updated_date": "2024-07-26 05:56:18 UTC"
  },
  {
    "arxiv_id": "2407.18521v4",
    "title": "Patched MOA: optimizing inference for diverse software development tasks",
    "authors": [
      "Asankhaya Sharma"
    ],
    "abstract": "This paper introduces Patched MOA (Mixture of Agents), an inference\noptimization technique that significantly enhances the performance of large\nlanguage models (LLMs) across diverse software development tasks. We evaluate\nthree inference optimization algorithms - Best of N, Mixture of Agents, and\nMonte Carlo Tree Search and demonstrate that Patched MOA can boost the\nperformance of smaller models to surpass that of larger, more expensive models.\nNotably, our approach improves the gpt-4o-mini model's performance on the\nArena-Hard-Auto benchmark by 15.52%, outperforming gpt-4-turbo at a fraction of\nthe cost. We also apply Patched MOA to various software development workflows,\nshowing consistent improvements in task completion rates. Our method is\nmodel-agnostic, transparent to end-users, and can be easily integrated into\nexisting LLM pipelines. This work contributes to the growing field of LLM\noptimization, offering a cost-effective solution for enhancing model\nperformance without the need for fine-tuning or larger models. Our\nimplementation is open-source and available at\nhttps://github.com/codelion/optillm.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18521v4",
    "published_date": "2024-07-26 05:34:34 UTC",
    "updated_date": "2025-04-29 23:31:59 UTC"
  },
  {
    "arxiv_id": "2407.18519v1",
    "title": "TCGPN: Temporal-Correlation Graph Pre-trained Network for Stock Forecasting",
    "authors": [
      "Wenbo Yan",
      "Ying Tan"
    ],
    "abstract": "Recently, the incorporation of both temporal features and the correlation\nacross time series has become an effective approach in time series prediction.\nSpatio-Temporal Graph Neural Networks (STGNNs) demonstrate good performance on\nmany Temporal-correlation Forecasting Problem. However, when applied to tasks\nlacking periodicity, such as stock data prediction, the effectiveness and\nrobustness of STGNNs are found to be unsatisfactory. And STGNNs are limited by\nmemory savings so that cannot handle problems with a large number of nodes. In\nthis paper, we propose a novel approach called the Temporal-Correlation Graph\nPre-trained Network (TCGPN) to address these limitations. TCGPN utilize\nTemporal-correlation fusion encoder to get a mixed representation and\npre-training method with carefully designed temporal and correlation\npre-training tasks. Entire structure is independent of the number and order of\nnodes, so better results can be obtained through various data enhancements. And\nmemory consumption during training can be significantly reduced through\nmultiple sampling. Experiments are conducted on real stock market data sets\nCSI300 and CSI500 that exhibit minimal periodicity. We fine-tune a simple MLP\nin downstream tasks and achieve state-of-the-art results, validating the\ncapability to capture more robust temporal correlation patterns.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.ST",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18519v1",
    "published_date": "2024-07-26 05:27:26 UTC",
    "updated_date": "2024-07-26 05:27:26 UTC"
  },
  {
    "arxiv_id": "2407.18517v1",
    "title": "SLIM: Style-Linguistics Mismatch Model for Generalized Audio Deepfake Detection",
    "authors": [
      "Yi Zhu",
      "Surya Koppisetti",
      "Trang Tran",
      "Gaurav Bharaj"
    ],
    "abstract": "Audio deepfake detection (ADD) is crucial to combat the misuse of speech\nsynthesized from generative AI models. Existing ADD models suffer from\ngeneralization issues, with a large performance discrepancy between in-domain\nand out-of-domain data. Moreover, the black-box nature of existing models\nlimits their use in real-world scenarios, where explanations are required for\nmodel decisions. To alleviate these issues, we introduce a new ADD model that\nexplicitly uses the StyleLInguistics Mismatch (SLIM) in fake speech to separate\nthem from real speech. SLIM first employs self-supervised pretraining on only\nreal samples to learn the style-linguistics dependency in the real class. The\nlearned features are then used in complement with standard pretrained acoustic\nfeatures (e.g., Wav2vec) to learn a classifier on the real and fake classes.\nWhen the feature encoders are frozen, SLIM outperforms benchmark methods on\nout-of-domain datasets while achieving competitive results on in-domain data.\nThe features learned by SLIM allow us to quantify the (mis)match between style\nand linguistic content in a sample, hence facilitating an explanation of the\nmodel decision.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18517v1",
    "published_date": "2024-07-26 05:23:41 UTC",
    "updated_date": "2024-07-26 05:23:41 UTC"
  },
  {
    "arxiv_id": "2407.18499v3",
    "title": "Non-Overlapping Placement of Macro Cells based on Reinforcement Learning in Chip Design",
    "authors": [
      "Tao Yu",
      "Peng Gao",
      "Fei Wang",
      "Ru-Yue Yuan"
    ],
    "abstract": "Due to the increasing complexity of chip design, existing placement methods\nstill have many shortcomings in dealing with macro cells coverage and\noptimization efficiency. Aiming at the problems of layout overlap, inferior\nperformance, and low optimization efficiency in existing chip design methods,\nthis paper proposes an end-to-end placement method, SRLPlacer, based on\nreinforcement learning. First, the placement problem is transformed into a\nMarkov decision process by establishing the coupling relationship graph model\nbetween macro cells to learn the strategy for optimizing layouts. Secondly, the\nwhole placement process is optimized after integrating the standard cell\nlayout. By assessing on the public benchmark ISPD2005, the proposed SRLPlacer\ncan effectively solve the overlap problem between macro cells while considering\nrouting congestion and shortening the total wire length to ensure routability.\nCodes are available at https://github.com/zhouyusd/SRLPlacer.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18499v3",
    "published_date": "2024-07-26 04:15:54 UTC",
    "updated_date": "2024-09-29 09:41:30 UTC"
  },
  {
    "arxiv_id": "2407.18498v1",
    "title": "A Reliable Common-Sense Reasoning Socialbot Built Using LLMs and Goal-Directed ASP",
    "authors": [
      "Yankai Zeng",
      "Abhiramon Rajashekharan",
      "Kinjal Basu",
      "Huaduo Wang",
      "Joaquín Arias",
      "Gopal Gupta"
    ],
    "abstract": "The development of large language models (LLMs), such as GPT, has enabled the\nconstruction of several socialbots, like ChatGPT, that are receiving a lot of\nattention for their ability to simulate a human conversation. However, the\nconversation is not guided by a goal and is hard to control. In addition,\nbecause LLMs rely more on pattern recognition than deductive reasoning, they\ncan give confusing answers and have difficulty integrating multiple topics into\na cohesive response. These limitations often lead the LLM to deviate from the\nmain topic to keep the conversation interesting. We propose AutoCompanion, a\nsocialbot that uses an LLM model to translate natural language into predicates\n(and vice versa) and employs commonsense reasoning based on Answer Set\nProgramming (ASP) to hold a social conversation with a human. In particular, we\nrely on s(CASP), a goal-directed implementation of ASP as the backend. This\npaper presents the framework design and how an LLM is used to parse user\nmessages and generate a response from the s(CASP) engine output. To validate\nour proposal, we describe (real) conversations in which the chatbot's goal is\nto keep the user entertained by talking about movies and books, and s(CASP)\nensures (i) correctness of answers, (ii) coherence (and precision) during the\nconversation, which it dynamically regulates to achieve its specific purpose,\nand (iii) no deviation from the main topic.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18498v1",
    "published_date": "2024-07-26 04:13:43 UTC",
    "updated_date": "2024-07-26 04:13:43 UTC"
  },
  {
    "arxiv_id": "2407.21059v1",
    "title": "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks",
    "authors": [
      "Yunfan Gao",
      "Yun Xiong",
      "Meng Wang",
      "Haofen Wang"
    ],
    "abstract": "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\nincreasing demands of application scenarios have driven the evolution of RAG,\nleading to the integration of advanced retrievers, LLMs and other complementary\ntechnologies, which in turn has amplified the intricacy of RAG systems.\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\nwith many methods struggling to be unified under the process of\n\"retrieve-then-generate\". In this context, this paper examines the limitations\nof the existing RAG paradigm and introduces the modular RAG framework. By\ndecomposing complex RAG systems into independent modules and specialized\noperators, it facilitates a highly reconfigurable framework. Modular RAG\ntranscends the traditional linear architecture, embracing a more advanced\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\nextensive research, this paper further identifies prevalent RAG\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\nanalysis of their respective implementation nuances. Modular RAG presents\ninnovative opportunities for the conceptualization and deployment of RAG\nsystems. Finally, the paper explores the potential emergence of new operators\nand paradigms, establishing a solid theoretical foundation and a practical\nroadmap for the continued evolution and practical deployment of RAG\ntechnologies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21059v1",
    "published_date": "2024-07-26 03:45:30 UTC",
    "updated_date": "2024-07-26 03:45:30 UTC"
  },
  {
    "arxiv_id": "2407.18483v4",
    "title": "A Role-specific Guided Large Language Model for Ophthalmic Consultation Based on Stylistic Differentiation",
    "authors": [
      "Laiyi Fu",
      "Binbin Fan",
      "Hongkai Du",
      "Yanxiang Feng",
      "Chunhua Li",
      "Huping Song"
    ],
    "abstract": "Ophthalmology consultations are crucial for diagnosing, treating, and\npreventing eye diseases. However, the growing demand for consultations exceeds\nthe availability of ophthalmologists. By leveraging large pre-trained language\nmodels, we can design effective dialogues for specific scenarios, aiding in\nconsultations. Traditional fine-tuning strategies for question-answering tasks\nare impractical due to increasing model size and often ignoring patient-doctor\nrole function during consultations. In this paper, we propose EyeDoctor, an\nophthalmic medical questioning large language model that enhances accuracy\nthrough doctor-patient role perception guided and an augmented knowledge base\nwith external disease information. Experimental results show EyeDoctor achieves\nhigher question-answering precision in ophthalmology consultations. Notably,\nEyeDoctor demonstrated a 7.25% improvement in Rouge-1 scores and a 10.16%\nimprovement in F1 scores on multi-round datasets compared to second best model\nChatGPT, highlighting the importance of doctor-patient role differentiation and\ndynamic knowledge base expansion for intelligent medical consultations. EyeDoc\nalso serves as a free available web based service and souce code is available\nat https://github.com/sperfu/EyeDoc.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18483v4",
    "published_date": "2024-07-26 03:23:31 UTC",
    "updated_date": "2024-07-31 07:24:30 UTC"
  },
  {
    "arxiv_id": "2407.18468v3",
    "title": "Diffusion-Driven Semantic Communication for Generative Models with Bandwidth Constraints",
    "authors": [
      "Lei Guo",
      "Wei Chen",
      "Yuxuan Sun",
      "Bo Ai",
      "Nikolaos Pappas",
      "Tony Quek"
    ],
    "abstract": "Diffusion models have been extensively utilized in AI-generated content\n(AIGC) in recent years, thanks to the superior generation capabilities.\nCombining with semantic communications, diffusion models are used for tasks\nsuch as denoising, data reconstruction, and content generation. However,\nexisting diffusion-based generative models do not consider the stringent\nbandwidth limitation, which limits its application in wireless communication.\nThis paper introduces a diffusion-driven semantic communication framework with\nadvanced VAE-based compression for bandwidth-constrained generative model. Our\ndesigned architecture utilizes the diffusion model, where the signal\ntransmission process through the wireless channel acts as the forward process\nin diffusion. To reduce bandwidth requirements, we incorporate a downsampling\nmodule and a paired upsampling module based on a variational auto-encoder with\nreparameterization at the receiver to ensure that the recovered features\nconform to the Gaussian distribution. Furthermore, we derive the loss function\nfor our proposed system and evaluate its performance through comprehensive\nexperiments. Our experimental results demonstrate significant improvements in\npixel-level metrics such as peak signal to noise ratio (PSNR) and semantic\nmetrics like learned perceptual image patch similarity (LPIPS). These\nenhancements are more profound regarding the compression rates and SNR compared\nto deep joint source-channel coding (DJSCC).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted to IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2407.18468v3",
    "published_date": "2024-07-26 02:34:25 UTC",
    "updated_date": "2025-03-23 09:36:48 UTC"
  },
  {
    "arxiv_id": "2407.18992v1",
    "title": "Towards Automated Solution Recipe Generation for Industrial Asset Management with LLM",
    "authors": [
      "Nianjun Zhou",
      "Dhaval Patel",
      "Shuxin Lin",
      "Fearghal O'Donncha"
    ],
    "abstract": "This study introduces a novel approach to Industrial Asset Management (IAM)\nby incorporating Conditional-Based Management (CBM) principles with the latest\nadvancements in Large Language Models (LLMs). Our research introduces an\nautomated model-building process, traditionally reliant on intensive\ncollaboration between data scientists and domain experts. We present two\nprimary innovations: a taxonomy-guided prompting generation that facilitates\nthe automatic creation of AI solution recipes and a set of LLM pipelines\ndesigned to produce a solution recipe containing a set of artifacts composed of\ndocuments, sample data, and models for IAM. These pipelines, guided by\nstandardized principles, enable the generation of initial solution templates\nfor heterogeneous asset classes without direct human input, reducing reliance\non extensive domain knowledge and enhancing automation. We evaluate our\nmethodology by assessing asset health and sustainability across a spectrum of\nten asset classes. Our findings illustrate the potential of LLMs and\ntaxonomy-based LLM prompting pipelines in transforming asset management,\noffering a blueprint for subsequent research and development initiatives to be\nintegrated into a rapid client solution.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18992v1",
    "published_date": "2024-07-26 01:24:52 UTC",
    "updated_date": "2024-07-26 01:24:52 UTC"
  },
  {
    "arxiv_id": "2407.18454v1",
    "title": "Fairness Definitions in Language Models Explained",
    "authors": [
      "Thang Viet Doan",
      "Zhibo Chu",
      "Zichong Wang",
      "Wenbin Zhang"
    ],
    "abstract": "Language Models (LMs) have demonstrated exceptional performance across\nvarious Natural Language Processing (NLP) tasks. Despite these advancements,\nLMs can inherit and amplify societal biases related to sensitive attributes\nsuch as gender and race, limiting their adoption in real-world applications.\nTherefore, fairness has been extensively explored in LMs, leading to the\nproposal of various fairness notions. However, the lack of clear agreement on\nwhich fairness definition to apply in specific contexts (\\textit{e.g.,}\nmedium-sized LMs versus large-sized LMs) and the complexity of understanding\nthe distinctions between these definitions can create confusion and impede\nfurther progress. To this end, this paper proposes a systematic survey that\nclarifies the definitions of fairness as they apply to LMs. Specifically, we\nbegin with a brief introduction to LMs and fairness in LMs, followed by a\ncomprehensive, up-to-date overview of existing fairness notions in LMs and the\nintroduction of a novel taxonomy that categorizes these concepts based on their\nfoundational principles and operational distinctions. We further illustrate\neach definition through experiments, showcasing their practical implications\nand outcomes. Finally, we discuss current research challenges and open\nquestions, aiming to foster innovative ideas and advance the field. The\nimplementation and additional resources are publicly available at\nhttps://github.com/LavinWong/Fairness-in-Large-Language-Models/tree/main/definitions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18454v1",
    "published_date": "2024-07-26 01:21:25 UTC",
    "updated_date": "2024-07-26 01:21:25 UTC"
  },
  {
    "arxiv_id": "2408.06357v1",
    "title": "Algorithm Research of ELMo Word Embedding and Deep Learning Multimodal Transformer in Image Description",
    "authors": [
      "Xiaohan Cheng",
      "Taiyuan Mei",
      "Yun Zi",
      "Qi Wang",
      "Zijun Gao",
      "Haowei Yang"
    ],
    "abstract": "Zero sample learning is an effective method for data deficiency. The existing\nembedded zero sample learning methods only use the known classes to construct\nthe embedded space, so there is an overfitting of the known classes in the\ntesting process. This project uses category semantic similarity measures to\nclassify multiple tags. This enables it to incorporate unknown classes that\nhave the same meaning as currently known classes into the vector space when it\nis built. At the same time, most of the existing zero sample learning\nalgorithms directly use the depth features of medical images as input, and the\nfeature extraction process does not consider semantic information. This project\nintends to take ELMo-MCT as the main task and obtain multiple visual features\nrelated to the original image through self-attention mechanism. In this paper,\na large number of experiments are carried out on three zero-shot learning\nreference datasets, and the best harmonic average accuracy is obtained compared\nwith the most advanced algorithms.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06357v1",
    "published_date": "2024-07-26 01:12:19 UTC",
    "updated_date": "2024-07-26 01:12:19 UTC"
  },
  {
    "arxiv_id": "2407.18445v1",
    "title": "Capturing the security expert knowledge in feature selection for web application attack detection",
    "authors": [
      "Amanda Riverol",
      "Gustavo Betarte",
      "Rodrigo Martínez",
      "Álvaro Pardo"
    ],
    "abstract": "This article puts forward the use of mutual information values to replicate\nthe expertise of security professionals in selecting features for detecting web\nattacks. The goal is to enhance the effectiveness of web application firewalls\n(WAFs). Web applications are frequently vulnerable to various security threats,\nmaking WAFs essential for their protection. WAFs analyze HTTP traffic using\nrule-based approaches to identify known attack patterns and to detect and block\npotential malicious requests. However, a major challenge is the occurrence of\nfalse positives, which can lead to blocking legitimate traffic and impact the\nnormal functioning of the application. The problem is addressed as an approach\nthat combines supervised learning for feature selection with a semi-supervised\nlearning scenario for training a One-Class SVM model. The experimental findings\nshow that the model trained with features selected by the proposed algorithm\noutperformed the expert-based selection approach in terms of performance.\nAdditionally, the results obtained by the traditional rule-based WAF\nModSecurity, configured with a vanilla set of OWASP CRS rules, were also\nimproved.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18445v1",
    "published_date": "2024-07-26 00:56:11 UTC",
    "updated_date": "2024-07-26 00:56:11 UTC"
  },
  {
    "arxiv_id": "2407.18437v1",
    "title": "Mixed Non-linear Quantization for Vision Transformers",
    "authors": [
      "Gihwan Kim",
      "Jemin Lee",
      "Sihyeong Park",
      "Yongin Kwon",
      "Hyungshin Kim"
    ],
    "abstract": "The majority of quantization methods have been proposed to reduce the model\nsize of Vision Transformers, yet most of them have overlooked the quantization\nof non-linear operations. Only a few works have addressed quantization for\nnon-linear operations, but they applied a single quantization method across all\nnon-linear operations. We believe that this can be further improved by\nemploying a different quantization method for each non-linear operation.\nTherefore, to assign the most error-minimizing quantization method from the\nknown methods to each non-linear layer, we propose a mixed non-linear\nquantization that considers layer-wise quantization sensitivity measured by\nSQNR difference metric. The results show that our method outperforms I-BERT,\nFQ-ViT, and I-ViT in both 8-bit and 6-bit settings for ViT, DeiT, and Swin\nmodels by an average of 0.6%p and 19.6%p, respectively. Our method outperforms\nI-BERT and I-ViT by 0.6%p and 20.8%p, respectively, when training time is\nlimited. We plan to release our code at\nhttps://gitlab.com/ones-ai/mixed-non-linear-quantization.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 4 figures, under review",
    "pdf_url": "http://arxiv.org/pdf/2407.18437v1",
    "published_date": "2024-07-26 00:19:01 UTC",
    "updated_date": "2024-07-26 00:19:01 UTC"
  },
  {
    "arxiv_id": "2407.18433v1",
    "title": "Investigating the Privacy Risk of Using Robot Vacuum Cleaners in Smart Environments",
    "authors": [
      "Benjamin Ulsmaag",
      "Jia-Chun Lin",
      "Ming-Chang Lee"
    ],
    "abstract": "Robot vacuum cleaners have become increasingly popular and are widely used in\nvarious smart environments. To improve user convenience, manufacturers also\nintroduced smartphone applications that enable users to customize cleaning\nsettings or access information about their robot vacuum cleaners. While this\nintegration enhances the interaction between users and their robot vacuum\ncleaners, it results in potential privacy concerns because users' personal\ninformation may be exposed. To address these concerns, end-to-end encryption is\nimplemented between the application, cloud service, and robot vacuum cleaners\nto secure the exchanged information. Nevertheless, network header metadata\nremains unencrypted and it is still vulnerable to network eavesdropping. In\nthis paper, we investigate the potential risk of private information exposure\nthrough such metadata. A popular robot vacuum cleaner was deployed in a real\nsmart environment where passive network eavesdropping was conducted during\nseveral selected cleaning events. Our extensive analysis, based on Association\nRule Learning, demonstrates that it is feasible to identify certain events\nusing only the captured Internet traffic metadata, thereby potentially exposing\nprivate user information and raising privacy concerns.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 11 figures, 4 tables, The 26th International Conference on\n  Information and Communications Security, 26-28 August, 2024, Mytilene,\n  Lesvos, Greece (ICICS2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.18433v1",
    "published_date": "2024-07-26 00:00:53 UTC",
    "updated_date": "2024-07-26 00:00:53 UTC"
  }
]