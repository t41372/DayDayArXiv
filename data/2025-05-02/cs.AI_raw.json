[
  {
    "arxiv_id": "2505.01635v1",
    "title": "Dendritic Computing with Multi-Gate Ferroelectric Field-Effect Transistors",
    "authors": [
      "A N M Nafiul Islam",
      "Xuezhong Niu",
      "Jiahui Duan",
      "Shubham Kumar",
      "Kai Ni",
      "Abhronil Sengupta"
    ],
    "abstract": "Although inspired by neuronal systems in the brain, artificial neural\nnetworks generally employ point-neurons, which offer far less computational\ncomplexity than their biological counterparts. Neurons have dendritic arbors\nthat connect to different sets of synapses and offer local non-linear\naccumulation - playing a pivotal role in processing and learning. Inspired by\nthis, we propose a novel neuron design based on a multi-gate ferroelectric\nfield-effect transistor that mimics dendrites. It leverages ferroelectric\nnonlinearity for local computations within dendritic branches, while utilizing\nthe transistor action to generate the final neuronal output. The branched\narchitecture paves the way for utilizing smaller crossbar arrays in hardware\nintegration, leading to greater efficiency. Using an experimentally calibrated\ndevice-circuit-algorithm co-simulation framework, we demonstrate that networks\nincorporating our dendritic neurons achieve superior performance in comparison\nto much larger networks without dendrites ($\\sim$17$\\times$ fewer trainable\nweight parameters). These findings suggest that dendritic hardware can\nsignificantly improve computational efficiency, and learning capacity of\nneuromorphic systems optimized for edge applications.",
    "categories": [
      "cs.ET",
      "cs.AI"
    ],
    "primary_category": "cs.ET",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01635v1",
    "published_date": "2025-05-02 23:59:08 UTC",
    "updated_date": "2025-05-02 23:59:08 UTC"
  },
  {
    "arxiv_id": "2505.01632v1",
    "title": "Transfer Learning-Based Deep Residual Learning for Speech Recognition in Clean and Noisy Environments",
    "authors": [
      "Noussaiba Djeffal",
      "Djamel Addou",
      "Hamza Kheddar",
      "Sid Ahmed Selouani"
    ],
    "abstract": "Addressing the detrimental impact of non-stationary environmental noise on\nautomatic speech recognition (ASR) has been a persistent and significant\nresearch focus. Despite advancements, this challenge continues to be a major\nconcern. Recently, data-driven supervised approaches, such as deep neural\nnetworks, have emerged as promising alternatives to traditional unsupervised\nmethods. With extensive training, these approaches have the potential to\novercome the challenges posed by diverse real-life acoustic environments. In\nthis light, this paper introduces a novel neural framework that incorporates a\nrobust frontend into ASR systems in both clean and noisy environments.\nUtilizing the Aurora-2 speech database, the authors evaluate the effectiveness\nof an acoustic feature set for Mel-frequency, employing the approach of\ntransfer learning based on Residual neural network (ResNet). The experimental\nresults demonstrate a significant improvement in recognition accuracy compared\nto convolutional neural networks (CNN) and long short-term memory (LSTM)\nnetworks. They achieved accuracies of 98.94% in clean and 91.21% in noisy mode.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01632v1",
    "published_date": "2025-05-02 23:42:27 UTC",
    "updated_date": "2025-05-02 23:42:27 UTC"
  },
  {
    "arxiv_id": "2505.01619v1",
    "title": "Skill-based Safe Reinforcement Learning with Risk Planning",
    "authors": [
      "Hanping Zhang",
      "Yuhong Guo"
    ],
    "abstract": "Safe Reinforcement Learning (Safe RL) aims to ensure safety when an RL agent\nconducts learning by interacting with real-world environments where improper\nactions can induce high costs or lead to severe consequences. In this paper, we\npropose a novel Safe Skill Planning (SSkP) approach to enhance effective safe\nRL by exploiting auxiliary offline demonstration data. SSkP involves a\ntwo-stage process. First, we employ PU learning to learn a skill risk predictor\nfrom the offline demonstration data. Then, based on the learned skill risk\npredictor, we develop a novel risk planning process to enhance online safe RL\nand learn a risk-averse safe policy efficiently through interactions with the\nonline RL environment, while simultaneously adapting the skill risk predictor\nto the environment. We conduct experiments in several benchmark robotic\nsimulation environments. The experimental results demonstrate that the proposed\napproach consistently outperforms previous state-of-the-art safe RL methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01619v1",
    "published_date": "2025-05-02 22:48:27 UTC",
    "updated_date": "2025-05-02 22:48:27 UTC"
  },
  {
    "arxiv_id": "2505.05492v1",
    "title": "DetoxAI: a Python Toolkit for Debiasing Deep Learning Models in Computer Vision",
    "authors": [
      "Ignacy Stępka",
      "Lukasz Sztukiewicz",
      "Michał Wiliński",
      "Jerzy Stefanowski"
    ],
    "abstract": "While machine learning fairness has made significant progress in recent\nyears, most existing solutions focus on tabular data and are poorly suited for\nvision-based classification tasks, which rely heavily on deep learning. To\nbridge this gap, we introduce DetoxAI, an open-source Python library for\nimproving fairness in deep learning vision classifiers through post-hoc\ndebiasing. DetoxAI implements state-of-the-art debiasing algorithms, fairness\nmetrics, and visualization tools. It supports debiasing via interventions in\ninternal representations and includes attribution-based visualization tools and\nquantitative algorithmic fairness metrics to show how bias is mitigated. This\npaper presents the motivation, design, and use cases of DetoxAI, demonstrating\nits tangible value to engineers and researchers.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05492v1",
    "published_date": "2025-05-02 22:47:39 UTC",
    "updated_date": "2025-05-02 22:47:39 UTC"
  },
  {
    "arxiv_id": "2505.01618v2",
    "title": "Don't be lazy: CompleteP enables compute-efficient deep transformers",
    "authors": [
      "Nolan Dey",
      "Bin Claire Zhang",
      "Lorenzo Noci",
      "Mufan Li",
      "Blake Bordelon",
      "Shane Bergsma",
      "Cengiz Pehlevan",
      "Boris Hanin",
      "Joel Hestness"
    ],
    "abstract": "We study compute efficiency of LLM training when using different\nparameterizations, i.e., rules for adjusting model and optimizer\nhyperparameters (HPs) as model size changes. Some parameterizations fail to\ntransfer optimal base HPs (such as learning rate) across changes in model\ndepth, requiring practitioners to either re-tune these HPs as they scale up\n(expensive), or accept sub-optimal training when re-tuning is prohibitive. Even\nwhen they achieve HP transfer, we develop theory to show parameterizations may\nstill exist in the lazy learning regime where layers learn only features close\nto their linearization, preventing effective use of depth and nonlinearity.\nFinally, we identify and adopt the parameterization we call CompleteP that\nachieves both depth-wise HP transfer and non-lazy learning in all layers.\nCompleteP enables a wider range of model width/depth ratios to remain\ncompute-efficient, unlocking shapes better suited for different hardware\nsettings and operational contexts. Moreover, CompleteP enables 12-34% compute\nefficiency improvements over the prior state-of-the-art.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 main pages, 16 appendix pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.01618v2",
    "published_date": "2025-05-02 22:45:14 UTC",
    "updated_date": "2025-05-14 17:09:58 UTC"
  },
  {
    "arxiv_id": "2505.01615v1",
    "title": "Multimodal and Multiview Deep Fusion for Autonomous Marine Navigation",
    "authors": [
      "Dimitrios Dagdilelis",
      "Panagiotis Grigoriadis",
      "Roberto Galeazzi"
    ],
    "abstract": "We propose a cross attention transformer based method for multimodal sensor\nfusion to build a birds eye view of a vessels surroundings supporting safer\nautonomous marine navigation. The model deeply fuses multiview RGB and long\nwave infrared images with sparse LiDAR point clouds. Training also integrates X\nband radar and electronic chart data to inform predictions. The resulting view\nprovides a detailed reliable scene representation improving navigational\naccuracy and robustness. Real world sea trials confirm the methods\neffectiveness even in adverse weather and complex maritime settings.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01615v1",
    "published_date": "2025-05-02 22:32:50 UTC",
    "updated_date": "2025-05-02 22:32:50 UTC"
  },
  {
    "arxiv_id": "2505.07835v2",
    "title": "Intelligent Product 3.0: Decentralised AI Agents and Web3 Intelligence Standards",
    "authors": [
      "Alex C. Y. Wong",
      "Duncan McFarlane",
      "C. Ellarby",
      "M. Lee",
      "M. Kuok"
    ],
    "abstract": "Twenty-five years ago, the specification of the Intelligent Product was\nestablished, envisaging real-time connectivity that not only enables products\nto gather accurate data about themselves but also allows them to assess and\ninfluence their own destiny. Early work by the Auto-ID project focused on\ncreating a single, open-standard repository for storing and retrieving product\ninformation, laying a foundation for scalable connectivity. A decade later, the\napproach was revisited in light of low-cost RFID systems that promised a\nlow-cost link between physical goods and networked information environments.\nSince then, advances in blockchain, Web3, and artificial intelligence have\nintroduced unprecedented levels of resilience, consensus, and autonomy. By\nleveraging decentralised identity, blockchain-based product information and\nhistory, and intelligent AI-to-AI collaboration, this paper examines these\ndevelopments and outlines a new specification for the Intelligent Product 3.0,\nillustrating how decentralised and AI-driven capabilities facilitate seamless\ninteraction between physical AI and everyday products.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.MA",
      "I.2.11; C.3; C.2.4"
    ],
    "primary_category": "cs.NI",
    "comment": "18 pages, 1 Figure, 3 Tables; Corrected typo in Section 3.4 heading",
    "pdf_url": "http://arxiv.org/pdf/2505.07835v2",
    "published_date": "2025-05-02 22:01:17 UTC",
    "updated_date": "2025-05-14 11:10:49 UTC"
  },
  {
    "arxiv_id": "2505.01595v1",
    "title": "Always Tell Me The Odds: Fine-grained Conditional Probability Estimation",
    "authors": [
      "Liaoyaqi Wang",
      "Zhengping Jiang",
      "Anqi Liu",
      "Benjamin Van Durme"
    ],
    "abstract": "We present a state-of-the-art model for fine-grained probability estimation\nof propositions conditioned on context. Recent advances in large language\nmodels (LLMs) have significantly enhanced their reasoning capabilities,\nparticularly on well-defined tasks with complete information. However, LLMs\ncontinue to struggle with making accurate and well-calibrated probabilistic\npredictions under uncertainty or partial information. While incorporating\nuncertainty into model predictions often boosts performance, obtaining reliable\nestimates of that uncertainty remains understudied. In particular, LLM\nprobability estimates tend to be coarse and biased towards more frequent\nnumbers. Through a combination of human and synthetic data creation and\nassessment, scaling to larger models, and better supervision, we propose a set\nof strong and precise probability estimation models. We conduct systematic\nevaluations across tasks that rely on conditional probability estimation and\nshow that our approach consistently outperforms existing fine-tuned and\nprompting-based methods by a large margin.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01595v1",
    "published_date": "2025-05-02 21:33:18 UTC",
    "updated_date": "2025-05-02 21:33:18 UTC"
  },
  {
    "arxiv_id": "2505.01592v1",
    "title": "PIPA: A Unified Evaluation Protocol for Diagnosing Interactive Planning Agents",
    "authors": [
      "Takyoung Kim",
      "Janvijay Singh",
      "Shuhaib Mehri",
      "Emre Can Acikgoz",
      "Sagnik Mukherjee",
      "Nimet Beyza Bozdag",
      "Sumuk Shashidhar",
      "Gokhan Tur",
      "Dilek Hakkani-Tür"
    ],
    "abstract": "The growing capabilities of large language models (LLMs) in\ninstruction-following and context-understanding lead to the era of agents with\nnumerous applications. Among these, task planning agents have become especially\nprominent in realistic scenarios involving complex internal pipelines, such as\ncontext understanding, tool management, and response generation. However,\nexisting benchmarks predominantly evaluate agent performance based on task\ncompletion as a proxy for overall effectiveness. We hypothesize that merely\nimproving task completion is misaligned with maximizing user satisfaction, as\nusers interact with the entire agentic process and not only the end result. To\naddress this gap, we propose PIPA, a unified evaluation protocol that\nconceptualizes the behavioral process of interactive task planning agents\nwithin a partially observable Markov Decision Process (POMDP) paradigm. The\nproposed protocol offers a comprehensive assessment of agent performance\nthrough a set of atomic evaluation criteria, allowing researchers and\npractitioners to diagnose specific strengths and weaknesses within the agent's\ndecision-making pipeline. Our analyses show that agents excel in different\nbehavioral stages, with user satisfaction shaped by both outcomes and\nintermediate behaviors. We also highlight future directions, including systems\nthat leverage multiple agents and the limitations of user simulators in task\nplanning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint in progress",
    "pdf_url": "http://arxiv.org/pdf/2505.01592v1",
    "published_date": "2025-05-02 21:27:10 UTC",
    "updated_date": "2025-05-02 21:27:10 UTC"
  },
  {
    "arxiv_id": "2505.03819v2",
    "title": "Focus on the Likely: Test-time Instance-based Uncertainty Removal",
    "authors": [
      "Johannes Schneider"
    ],
    "abstract": "We ask: Does focusing on classes predicted as likely improve model\npredictions? We aim for an affirmative answer by proposing two novel test-time\nfine-tuning methods to improve uncertain model predictions. Instead of greedily\nselecting the most likely class, we introduce an additional step, \\emph{focus\non the likely classes}, to refine predictions. By applying a theoretically\nmotivated single gradient descent step with a large learning rate, we refine\npredictions when an initial forward pass indicates high uncertainty. This\naligns predictions more closely with the ideal of assigning zero probability to\nless plausible outcomes. The experimental evaluation demonstrates accuracy\ngains for one of our methods, which emphasizes shared features among likely\nclasses, across diverse text and image domain models. %Our theoretical\ndiscussion provides a deeper understanding, highlighting the varying impact of\nshared and non-shared features among (focus) classes. %Our discussion also\nsuggests an interesting view on standard, offline training vs. test-time\ntraining: Opposing optimization rationales regarding breadth of feature\ndependence are preferable during each training phase.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03819v2",
    "published_date": "2025-05-02 21:06:53 UTC",
    "updated_date": "2025-05-16 15:21:29 UTC"
  },
  {
    "arxiv_id": "2505.01584v2",
    "title": "Understanding and Exploiting Plasticity for Non-stationary Network Resource Adaptation",
    "authors": [
      "Zhiqiang He",
      "Zhi Liu"
    ],
    "abstract": "Adapting to non-stationary network conditions presents significant challenges\nfor resource adaptation. However, current solutions primarily rely on\nstationary assumptions. While data-driven reinforcement learning approaches\noffer promising solutions for handling network dynamics, our systematic\ninvestigation reveals a critical limitation: neural networks suffer from\nplasticity loss, significantly impeding their ability to adapt to evolving\nnetwork conditions. Through theoretical analysis of neural propagation\nmechanisms, we demonstrate that existing dormant neuron metrics inadequately\ncharacterize neural plasticity loss. To address this limitation, we have\ndeveloped the Silent Neuron theory, which provides a more comprehensive\nframework for understanding plasticity degradation. Based on these theoretical\ninsights, we propose the Reset Silent Neuron (ReSiN), which preserves neural\nplasticity through strategic neuron resets guided by both forward and backward\npropagation states. In our implementation of an adaptive video streaming\nsystem, ReSiN has shown significant improvements over existing solutions,\nachieving up to 168% higher bitrate and 108% better quality of experience (QoE)\nwhile maintaining comparable smoothness. Furthermore, ReSiN consistently\noutperforms in stationary environments, demonstrating its robust adaptability\nacross different network conditions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01584v2",
    "published_date": "2025-05-02 21:03:03 UTC",
    "updated_date": "2025-05-06 02:36:10 UTC"
  },
  {
    "arxiv_id": "2505.01583v1",
    "title": "TEMPURA: Temporal Event Masked Prediction and Understanding for Reasoning in Action",
    "authors": [
      "Jen-Hao Cheng",
      "Vivian Wang",
      "Huayu Wang",
      "Huapeng Zhou",
      "Yi-Hao Peng",
      "Hou-I Liu",
      "Hsiang-Wei Huang",
      "Kuang-Ming Chen",
      "Cheng-Yen Yang",
      "Wenhao Chai",
      "Yi-Ling Chen",
      "Vibhav Vineet",
      "Qin Cai",
      "Jenq-Neng Hwang"
    ],
    "abstract": "Understanding causal event relationships and achieving fine-grained temporal\ngrounding in videos remain challenging for vision-language models. Existing\nmethods either compress video tokens to reduce temporal resolution, or treat\nvideos as unsegmented streams, which obscures fine-grained event boundaries and\nlimits the modeling of causal dependencies. We propose TEMPURA (Temporal Event\nMasked Prediction and Understanding for Reasoning in Action), a two-stage\ntraining framework that enhances video temporal understanding. TEMPURA first\napplies masked event prediction reasoning to reconstruct missing events and\ngenerate step-by-step causal explanations from dense event annotations, drawing\ninspiration from effective infilling techniques. TEMPURA then learns to perform\nvideo segmentation and dense captioning to decompose videos into\nnon-overlapping events with detailed, timestamp-aligned descriptions. We train\nTEMPURA on VER, a large-scale dataset curated by us that comprises 1M training\ninstances and 500K videos with temporally aligned event descriptions and\nstructured reasoning steps. Experiments on temporal grounding and highlight\ndetection benchmarks demonstrate that TEMPURA outperforms strong baseline\nmodels, confirming that integrating causal reasoning with fine-grained temporal\nsegmentation leads to improved video understanding.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01583v1",
    "published_date": "2025-05-02 21:00:17 UTC",
    "updated_date": "2025-05-02 21:00:17 UTC"
  },
  {
    "arxiv_id": "2505.02859v1",
    "title": "Enhancing ML Model Interpretability: Leveraging Fine-Tuned Large Language Models for Better Understanding of AI",
    "authors": [
      "Jonas Bokstaller",
      "Julia Altheimer",
      "Julian Dormehl",
      "Alina Buss",
      "Jasper Wiltfang",
      "Johannes Schneider",
      "Maximilian Röglinger"
    ],
    "abstract": "Across various sectors applications of eXplainableAI (XAI) gained momentum as\nthe increasing black-boxedness of prevailing Machine Learning (ML) models\nbecame apparent. In parallel, Large Language Models (LLMs) significantly\ndeveloped in their abilities to understand human language and complex patterns.\nBy combining both, this paper presents a novel reference architecture for the\ninterpretation of XAI through an interactive chatbot powered by a fine-tuned\nLLM. We instantiate the reference architecture in the context of\nState-of-Health (SoH) prediction for batteries and validate its design in\nmultiple evaluation and demonstration rounds. The evaluation indicates that the\nimplemented prototype enhances the human interpretability of ML, especially for\nusers with less experience with XAI.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02859v1",
    "published_date": "2025-05-02 20:57:55 UTC",
    "updated_date": "2025-05-02 20:57:55 UTC"
  },
  {
    "arxiv_id": "2505.01572v1",
    "title": "PipeSpec: Breaking Stage Dependencies in Hierarchical LLM Decoding",
    "authors": [
      "Bradley McDanel",
      "Sai Qian Zhang",
      "Yunhai Hu",
      "Zining Liu"
    ],
    "abstract": "Speculative decoding accelerates large language model inference by using\nsmaller draft models to generate candidate tokens for parallel verification.\nHowever, current approaches are limited by sequential stage dependencies that\nprevent full hardware utilization. We present PipeSpec, a framework that\ngeneralizes speculative decoding to $k$ models arranged in a hierarchical\npipeline, enabling asynchronous execution with lightweight coordination for\nprediction verification and rollback. Our analytical model characterizes token\ngeneration rates across pipeline stages and proves guaranteed throughput\nimprovements over traditional decoding for any non-zero acceptance rate. We\nfurther derive closed-form expressions for steady-state verification\nprobabilities that explain the empirical benefits of pipeline depth.\nExperimental results show that PipeSpec achieves up to 2.54$\\times$ speedup\nwhile outperforming state-of-the-art methods. We validate PipeSpec across text\nsummarization and code generation tasks using LLaMA 2 and 3 models,\ndemonstrating that pipeline efficiency increases with model depth, providing a\nscalable approach to accelerating LLM inference on multi-device systems.",
    "categories": [
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 5 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.01572v1",
    "published_date": "2025-05-02 20:29:31 UTC",
    "updated_date": "2025-05-02 20:29:31 UTC"
  },
  {
    "arxiv_id": "2505.03818v1",
    "title": "Program Semantic Inequivalence Game with Large Language Models",
    "authors": [
      "Antonio Valerio Miceli-Barone",
      "Vaishak Belle",
      "Ali Payani"
    ],
    "abstract": "Large Language Models (LLMs) can achieve strong performance on everyday\ncoding tasks, but they can fail on complex tasks that require non-trivial\nreasoning about program semantics. Finding training examples to teach LLMs to\nsolve these tasks can be challenging.\n  In this work, we explore a method to synthetically generate code reasoning\ntraining data based on a semantic inequivalence game SInQ: a generator agent\ncreates program variants that are semantically distinct, derived from a dataset\nof real-world programming tasks, while an evaluator agent has to identify input\nexamples that cause the original programs and the generated variants to diverge\nin their behaviour, with the agents training each other semi-adversarially. We\nprove that this setup enables theoretically unlimited improvement through\nself-play in the limit of infinite computational resources.\n  We evaluated our approach on multiple code generation and understanding\nbenchmarks, including cross-language vulnerability detection (Lu et al., 2021),\nwhere our method improves vulnerability detection in C/C++ code despite being\ntrained exclusively on Python code, and the challenging Python builtin\nidentifier swap benchmark (Miceli-Barone et al., 2023), showing that whereas\nmodern LLMs still struggle with this benchmark, our approach yields substantial\nimprovements.\n  We release the code needed to replicate the experiments, as well as the\ngenerated synthetic data, which can be used to fine-tune LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03818v1",
    "published_date": "2025-05-02 20:03:35 UTC",
    "updated_date": "2025-05-02 20:03:35 UTC"
  },
  {
    "arxiv_id": "2505.01563v1",
    "title": "TutorGym: A Testbed for Evaluating AI Agents as Tutors and Students",
    "authors": [
      "Daniel Weitekamp",
      "Momin N. Siddiqui",
      "Christopher J. MacLellan"
    ],
    "abstract": "Recent improvements in large language model (LLM) performance on academic\nbenchmarks, such as MATH and GSM8K, have emboldened their use as standalone\ntutors and as simulations of human learning. However, these new applications\nrequire more than evaluations of final solution generation. We introduce\nTutorGym to evaluate these applications more directly. TutorGym is a standard\ninterface for testing artificial intelligence (AI) agents within existing\nintelligent tutoring systems (ITS) that have been tested and refined in\nclassroom studies, including Cognitive Tutors (CTAT), Apprentice Tutors, and\nOATutors. TutorGym is more than a simple problem-solution benchmark, it\nsituates AI agents within the interactive interfaces of existing ITSs. At each\nstep of problem-solving, AI agents are asked what they would do as a tutor or\nas a learner. As tutors, AI agents are prompted to provide tutoring support --\nsuch as generating examples, hints, and step-level correctness feedback --\nwhich can be evaluated directly against the adaptive step-by-step support\nprovided by existing ITSs. As students, agents directly learn from ITS\ninstruction, and their mistakes and learning trajectories can be compared to\nstudent data. TutorGym establishes a common framework for training and\nevaluating diverse AI agents, including LLMs, computational models of learning,\nand reinforcement learning agents, within a growing suite of learning\nenvironments. Currently, TutorGym includes 223 different tutor domains. In an\ninitial evaluation, we find that current LLMs are poor at tutoring -- none did\nbetter than chance at labeling incorrect actions, and next-step actions were\ncorrect only ~52-70% of the time -- but they could produce remarkably\nhuman-like learning curves when trained as students with in-context learning.",
    "categories": [
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01563v1",
    "published_date": "2025-05-02 20:03:21 UTC",
    "updated_date": "2025-05-02 20:03:21 UTC"
  },
  {
    "arxiv_id": "2505.01557v1",
    "title": "Contextures: Representations from Contexts",
    "authors": [
      "Runtian Zhai",
      "Kai Yang",
      "Che-Ping Tsai",
      "Burak Varici",
      "Zico Kolter",
      "Pradeep Ravikumar"
    ],
    "abstract": "Despite the empirical success of foundation models, we do not have a\nsystematic characterization of the representations that these models learn. In\nthis paper, we establish the contexture theory. It shows that a large class of\nrepresentation learning methods can be characterized as learning from the\nassociation between the input and a context variable. Specifically, we show\nthat many popular methods aim to approximate the top-d singular functions of\nthe expectation operator induced by the context, in which case we say that the\nrepresentation learns the contexture. We demonstrate the generality of the\ncontexture theory by proving that representation learning within various\nlearning paradigms -- supervised, self-supervised, and manifold learning -- can\nall be studied from such a perspective. We also prove that the representations\nthat learn the contexture are optimal on those tasks that are compatible with\nthe context. One important implication of the contexture theory is that once\nthe model is large enough to approximate the top singular functions, further\nscaling up the model size yields diminishing returns. Therefore, scaling is not\nall we need, and further improvement requires better contexts. To this end, we\nstudy how to evaluate the usefulness of a context without knowing the\ndownstream tasks. We propose a metric and show by experiments that it\ncorrelates well with the actual performance of the encoder on many real\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2025, longer version. arXiv admin note: substantial text overlap\n  with arXiv:2504.19792",
    "pdf_url": "http://arxiv.org/pdf/2505.01557v1",
    "published_date": "2025-05-02 19:50:56 UTC",
    "updated_date": "2025-05-02 19:50:56 UTC"
  },
  {
    "arxiv_id": "2505.01542v1",
    "title": "Emotions in the Loop: A Survey of Affective Computing for Emotional Support",
    "authors": [
      "Karishma Hegde",
      "Hemadri Jayalath"
    ],
    "abstract": "In a world where technology is increasingly embedded in our everyday\nexperiences, systems that sense and respond to human emotions are elevating\ndigital interaction. At the intersection of artificial intelligence and\nhuman-computer interaction, affective computing is emerging with innovative\nsolutions where machines are humanized by enabling them to process and respond\nto user emotions. This survey paper explores recent research contributions in\naffective computing applications in the area of emotion recognition, sentiment\nanalysis and personality assignment developed using approaches like large\nlanguage models (LLMs), multimodal techniques, and personalized AI systems. We\nanalyze the key contributions and innovative methodologies applied by the\nselected research papers by categorizing them into four domains: AI chatbot\napplications, multimodal input systems, mental health and therapy applications,\nand affective computing for safety applications. We then highlight the\ntechnological strengths as well as the research gaps and challenges related to\nthese studies. Furthermore, the paper examines the datasets used in each study,\nhighlighting how modality, scale, and diversity impact the development and\nperformance of affective models. Finally, the survey outlines ethical\nconsiderations and proposes future directions to develop applications that are\nmore safe, empathetic and practical.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "I.2.10; I.2.7; H.5.2"
    ],
    "primary_category": "cs.HC",
    "comment": "20 pages, 7 tables, 96 references. Survey paper on affective\n  computing applications using large language models, multimodal AI, and\n  therapeutic chatbots",
    "pdf_url": "http://arxiv.org/pdf/2505.01542v1",
    "published_date": "2025-05-02 19:06:05 UTC",
    "updated_date": "2025-05-02 19:06:05 UTC"
  },
  {
    "arxiv_id": "2505.01539v1",
    "title": "Parameterized Argumentation-based Reasoning Tasks for Benchmarking Generative Language Models",
    "authors": [
      "Cor Steging",
      "Silja Renooij",
      "Bart Verheij"
    ],
    "abstract": "Generative large language models as tools in the legal domain have the\npotential to improve the justice system. However, the reasoning behavior of\ncurrent generative models is brittle and poorly understood, hence cannot be\nresponsibly applied in the domains of law and evidence. In this paper, we\nintroduce an approach for creating benchmarks that can be used to evaluate the\nreasoning capabilities of generative language models. These benchmarks are\ndynamically varied, scalable in their complexity, and have formally unambiguous\ninterpretations. In this study, we illustrate the approach on the basis of\nwitness testimony, focusing on the underlying argument attack structure. We\ndynamically generate both linear and non-linear argument attack graphs of\nvarying complexity and translate these into reasoning puzzles about witness\ntestimony expressed in natural language. We show that state-of-the-art large\nlanguage models often fail in these reasoning puzzles, already at low\ncomplexity. Obvious mistakes are made by the models, and their inconsistent\nperformance indicates that their reasoning capabilities are brittle.\nFurthermore, at higher complexity, even state-of-the-art models specifically\npresented for reasoning capabilities make mistakes. We show the viability of\nusing a parametrized benchmark with varying complexity to evaluate the\nreasoning capabilities of generative language models. As such, the findings\ncontribute to a better understanding of the limitations of the reasoning\ncapabilities of generative models, which is essential when designing\nresponsible AI systems in the legal domain.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "This manuscript has been accepted for presentation as a short paper\n  at the 20th International Conference of AI & Law in Chicago, June 16 to 20 of\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2505.01539v1",
    "published_date": "2025-05-02 19:04:34 UTC",
    "updated_date": "2025-05-02 19:04:34 UTC"
  },
  {
    "arxiv_id": "2505.01531v1",
    "title": "An Adaptive Framework for Autoregressive Forecasting in CFD Using Hybrid Modal Decomposition and Deep Learning",
    "authors": [
      "Rodrigo Abadía-Heredia",
      "Manuel Lopez-Martin",
      "Soledad Le Clainche"
    ],
    "abstract": "This work presents, to the best of the authors' knowledge, the first\ngeneralizable and fully data-driven adaptive framework designed to stabilize\ndeep learning (DL) autoregressive forecasting models over long time horizons,\nwith the goal of reducing the computational cost required in computational\nfluid dynamics (CFD) simulations.The proposed methodology alternates between\ntwo phases: (i) predicting the evolution of the flow field over a selected time\ninterval using a trained DL model, and (ii) updating the model with newly\ngenerated CFD data when stability degrades, thus maintaining accurate long-term\nforecasting. This adaptive retraining strategy ensures robustness while\navoiding the accumulation of predictive errors typical in autoregressive\nmodels. The framework is validated across three increasingly complex flow\nregimes, from laminar to turbulent, demonstrating from 30 \\% to 95 \\% reduction\nin computational cost without compromising physical consistency or accuracy.\nIts entirely data-driven nature makes it easily adaptable to a wide range of\ntime-dependent simulation problems. The code implementing this methodology is\navailable as open-source and it will be integrated into the upcoming release of\nthe ModelFLOWs-app.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "47 pages, single-column, 15 figures and 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.01531v1",
    "published_date": "2025-05-02 18:33:41 UTC",
    "updated_date": "2025-05-02 18:33:41 UTC"
  },
  {
    "arxiv_id": "2505.01530v1",
    "title": "Automated Parsing of Engineering Drawings for Structured Information Extraction Using a Fine-tuned Document Understanding Transformer",
    "authors": [
      "Muhammad Tayyab Khan",
      "Zane Yong",
      "Lequn Chen",
      "Jun Ming Tan",
      "Wenhe Feng",
      "Seung Ki Moon"
    ],
    "abstract": "Accurate extraction of key information from 2D engineering drawings is\ncrucial for high-precision manufacturing. Manual extraction is time-consuming\nand error-prone, while traditional Optical Character Recognition (OCR)\ntechniques often struggle with complex layouts and overlapping symbols,\nresulting in unstructured outputs. To address these challenges, this paper\nproposes a novel hybrid deep learning framework for structured information\nextraction by integrating an oriented bounding box (OBB) detection model with a\ntransformer-based document parsing model (Donut). An in-house annotated dataset\nis used to train YOLOv11 for detecting nine key categories: Geometric\nDimensioning and Tolerancing (GD&T), General Tolerances, Measures, Materials,\nNotes, Radii, Surface Roughness, Threads, and Title Blocks. Detected OBBs are\ncropped into images and labeled to fine-tune Donut for structured JSON output.\nFine-tuning strategies include a single model trained across all categories and\ncategory-specific models. Results show that the single model consistently\noutperforms category-specific ones across all evaluation metrics, achieving\nhigher precision (94.77% for GD&T), recall (100% for most), and F1 score\n(97.3%), while reducing hallucination (5.23%). The proposed framework improves\naccuracy, reduces manual effort, and supports scalable deployment in\nprecision-driven industries.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper has been submitted to the IEEE International Conference on\n  Industrial Engineering and Engineering Management (IEEM 2025)",
    "pdf_url": "http://arxiv.org/pdf/2505.01530v1",
    "published_date": "2025-05-02 18:33:21 UTC",
    "updated_date": "2025-05-02 18:33:21 UTC"
  },
  {
    "arxiv_id": "2505.01524v1",
    "title": "The DCR Delusion: Measuring the Privacy Risk of Synthetic Data",
    "authors": [
      "Zexi Yao",
      "Nataša Krčo",
      "Georgi Ganev",
      "Yves-Alexandre de Montjoye"
    ],
    "abstract": "Synthetic data has become an increasingly popular way to share data without\nrevealing sensitive information. Though Membership Inference Attacks (MIAs) are\nwidely considered the gold standard for empirically assessing the privacy of a\nsynthetic dataset, practitioners and researchers often rely on simpler proxy\nmetrics such as Distance to Closest Record (DCR). These metrics estimate\nprivacy by measuring the similarity between the training data and generated\nsynthetic data. This similarity is also compared against that between the\ntraining data and a disjoint holdout set of real records to construct a binary\nprivacy test. If the synthetic data is not more similar to the training data\nthan the holdout set is, it passes the test and is considered private. In this\nwork we show that, while computationally inexpensive, DCR and other\ndistance-based metrics fail to identify privacy leakage. Across multiple\ndatasets and both classical models such as Baynet and CTGAN and more recent\ndiffusion models, we show that datasets deemed private by proxy metrics are\nhighly vulnerable to MIAs. We similarly find both the binary privacy test and\nthe continuous measure based on these metrics to be uninformative of actual\nmembership inference risk. We further show that these failures are consistent\nacross different metric hyperparameter settings and record selection methods.\nFinally, we argue DCR and other distance-based metrics to be flawed by design\nand show a example of a simple leakage they miss in practice. With this work,\nwe hope to motivate practitioners to move away from proxy metrics to MIAs as\nthe rigorous, comprehensive standard of evaluating privacy of synthetic data,\nin particular to make claims of datasets being legally anonymous.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01524v1",
    "published_date": "2025-05-02 18:21:14 UTC",
    "updated_date": "2025-05-02 18:21:14 UTC"
  },
  {
    "arxiv_id": "2505.01523v1",
    "title": "Subset Selection for Fine-Tuning: A Utility-Diversity Balanced Approach for Mathematical Domain Adaptation",
    "authors": [
      "Madhav Kotecha",
      "Vijendra Kumar Vaishya",
      "Smita Gautam",
      "Suraj Racha"
    ],
    "abstract": "We propose a refined approach to efficiently fine-tune large language models\n(LLMs) on specific domains like the mathematical domain by employing a budgeted\nsubset selection method. Our approach combines utility and diversity metrics to\nselect the most informative and representative training examples. The final\ngoal is to achieve near-full dataset performance with meticulously selected\ndata points from the entire dataset while significantly reducing computational\ncost and training time and achieving competitive performance as the full\ndataset. The utility metric incorporates both perplexity and Chain-of-Thought\n(CoT) loss to identify challenging examples that contribute most to model\nlearning, while the diversity metric ensures broad coverage across mathematical\nsubdomains. We evaluate our method on LLaMA-3 8B and Phi-3 models, comparing\nagainst several baseline approaches, including random selection,\ndiversity-based sampling, and existing state-of-the-art subset selection\ntechniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T05"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.01523v1",
    "published_date": "2025-05-02 18:20:44 UTC",
    "updated_date": "2025-05-02 18:20:44 UTC"
  },
  {
    "arxiv_id": "2505.03817v1",
    "title": "Modeling Behavioral Preferences of Cyber Adversaries Using Inverse Reinforcement Learning",
    "authors": [
      "Aditya Shinde",
      "Prashant Doshi"
    ],
    "abstract": "This paper presents a holistic approach to attacker preference modeling from\nsystem-level audit logs using inverse reinforcement learning (IRL). Adversary\nmodeling is an important capability in cybersecurity that lets defenders\ncharacterize behaviors of potential attackers, which enables attribution to\nknown cyber adversary groups. Existing approaches rely on documenting an\never-evolving set of attacker tools and techniques to track known threat\nactors. Although attacks evolve constantly, attacker behavioral preferences are\nintrinsic and less volatile. Our approach learns the behavioral preferences of\ncyber adversaries from forensics data on their tools and techniques. We model\nthe attacker as an expert decision-making agent with unknown behavioral\npreferences situated in a computer host. We leverage attack provenance graphs\nof audit logs to derive a state-action trajectory of the attack. We test our\napproach on open datasets of audit logs containing real attack data. Our\nresults demonstrate for the first time that low-level forensics data can\nautomatically reveal an adversary's subjective preferences, which serves as an\nadditional dimension to modeling and documenting cyber adversaries. Attackers'\npreferences tend to be invariant despite their different tools and indicate\npredispositions that are inherent to the attacker. As such, these inferred\npreferences can potentially serve as unique behavioral signatures of attackers\nand improve threat attribution.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03817v1",
    "published_date": "2025-05-02 18:20:14 UTC",
    "updated_date": "2025-05-02 18:20:14 UTC"
  },
  {
    "arxiv_id": "2505.01514v1",
    "title": "Securing the Future of IVR: AI-Driven Innovation with Agile Security, Data Regulation, and Ethical AI Integration",
    "authors": [
      "Khushbu Mehboob Shaikh",
      "Georgios Giannakopoulos"
    ],
    "abstract": "The rapid digitalization of communication systems has elevated Interactive\nVoice Response (IVR) technologies to become critical interfaces for customer\nengagement. With Artificial Intelligence (AI) now driving these platforms,\nensuring secure, compliant, and ethically designed development practices is\nmore imperative than ever. AI-powered IVRs leverage Natural Language Processing\n(NLP) and Machine Learning (ML) to personalize interactions, automate service\ndelivery, and optimize user experiences. However, these innovations expose\nsystems to heightened risks, including data privacy breaches, AI decision\nopacity, and model security vulnerabilities. This paper analyzes the evolution\nof IVRs from static code-based designs to adaptive AI-driven systems,\npresenting a cybersecurity-centric perspective. We propose a practical\ngovernance framework that embeds agile security principles, compliance with\nglobal data legislation, and user-centric ethics. Emphasizing\nprivacy-by-design, adaptive risk modeling, and transparency, the paper argues\nthat ethical AI integration is not a feature but a strategic imperative.\nThrough this multidimensional lens, we highlight how modern IVRs can transition\nfrom communication tools to intelligent, secure, and accountable digital\nfrontlines-resilient against emerging threats and aligned with societal\nexpectations.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "7 pages, 1 figure, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.01514v1",
    "published_date": "2025-05-02 18:03:02 UTC",
    "updated_date": "2025-05-02 18:03:02 UTC"
  },
  {
    "arxiv_id": "2505.01425v1",
    "title": "GENMO: A GENeralist Model for Human MOtion",
    "authors": [
      "Jiefeng Li",
      "Jinkun Cao",
      "Haotian Zhang",
      "Davis Rempe",
      "Jan Kautz",
      "Umar Iqbal",
      "Ye Yuan"
    ],
    "abstract": "Human motion modeling traditionally separates motion generation and\nestimation into distinct tasks with specialized models. Motion generation\nmodels focus on creating diverse, realistic motions from inputs like text,\naudio, or keyframes, while motion estimation models aim to reconstruct accurate\nmotion trajectories from observations like videos. Despite sharing underlying\nrepresentations of temporal dynamics and kinematics, this separation limits\nknowledge transfer between tasks and requires maintaining separate models. We\npresent GENMO, a unified Generalist Model for Human Motion that bridges motion\nestimation and generation in a single framework. Our key insight is to\nreformulate motion estimation as constrained motion generation, where the\noutput motion must precisely satisfy observed conditioning signals. Leveraging\nthe synergy between regression and diffusion, GENMO achieves accurate global\nmotion estimation while enabling diverse motion generation. We also introduce\nan estimation-guided training objective that exploits in-the-wild videos with\n2D annotations and text descriptions to enhance generative diversity.\nFurthermore, our novel architecture handles variable-length motions and mixed\nmultimodal conditions (text, audio, video) at different time intervals,\noffering flexible control. This unified approach creates synergistic benefits:\ngenerative priors improve estimated motions under challenging conditions like\nocclusions, while diverse video data enhances generation capabilities.\nExtensive experiments demonstrate GENMO's effectiveness as a generalist\nframework that successfully handles multiple human motion tasks within a single\nmodel.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.GR",
    "comment": "Project page: https://research.nvidia.com/labs/dair/genmo/",
    "pdf_url": "http://arxiv.org/pdf/2505.01425v1",
    "published_date": "2025-05-02 17:59:55 UTC",
    "updated_date": "2025-05-02 17:59:55 UTC"
  },
  {
    "arxiv_id": "2505.03816v1",
    "title": "Geospatial and Temporal Trends in Urban Transportation: A Study of NYC Taxis and Pathao Food Deliveries",
    "authors": [
      "Bidyarthi Paul",
      "Fariha Tasnim Chowdhury",
      "Dipta Biswas",
      "Meherin Sultana"
    ],
    "abstract": "Urban transportation plays a vital role in modern city life, affecting how\nefficiently people and goods move around. This study analyzes transportation\npatterns using two datasets: the NYC Taxi Trip dataset from New York City and\nthe Pathao Food Trip dataset from Dhaka, Bangladesh. Our goal is to identify\nkey trends in demand, peak times, and important geographical hotspots. We start\nwith Exploratory Data Analysis (EDA) to understand the basic characteristics of\nthe datasets. Next, we perform geospatial analysis to map out high-demand and\nlow-demand regions. We use the SARIMAX model for time series analysis to\nforecast demand patterns, capturing seasonal and weekly variations. Lastly, we\napply clustering techniques to identify significant areas of high and low\ndemand. Our findings provide valuable insights for optimizing fleet management\nand resource allocation in both passenger transport and food delivery services.\nThese insights can help improve service efficiency, better meet customer needs,\nand enhance urban transportation systems in diverse urban environments.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03816v1",
    "published_date": "2025-05-02 17:41:17 UTC",
    "updated_date": "2025-05-02 17:41:17 UTC"
  },
  {
    "arxiv_id": "2505.01396v1",
    "title": "SIME: Enhancing Policy Self-Improvement with Modal-level Exploration",
    "authors": [
      "Yang Jin",
      "Jun Lv",
      "Wenye Yu",
      "Hongjie Fang",
      "Yong-Lu Li",
      "Cewu Lu"
    ],
    "abstract": "Self-improvement requires robotic systems to initially learn from\nhuman-provided data and then gradually enhance their capabilities through\ninteraction with the environment. This is similar to how humans improve their\nskills through continuous practice. However, achieving effective\nself-improvement is challenging, primarily because robots tend to repeat their\nexisting abilities during interactions, often failing to generate new, valuable\ndata for learning. In this paper, we identify the key to successful\nself-improvement: modal-level exploration and data selection. By incorporating\na modal-level exploration mechanism during policy execution, the robot can\nproduce more diverse and multi-modal interactions. At the same time, we select\nthe most valuable trials and high-quality segments from these interactions for\nlearning. We successfully demonstrate effective robot self-improvement on both\nsimulation benchmarks and real-world experiments. The capability for\nself-improvement will enable us to develop more robust and high-success-rate\nrobotic control strategies at a lower cost. Our code and experiment scripts are\navailable at https://ericjin2002.github.io/SIME/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01396v1",
    "published_date": "2025-05-02 17:13:03 UTC",
    "updated_date": "2025-05-02 17:13:03 UTC"
  },
  {
    "arxiv_id": "2505.03814v1",
    "title": "Cer-Eval: Certifiable and Cost-Efficient Evaluation Framework for LLMs",
    "authors": [
      "Ganghua Wang",
      "Zhaorun Chen",
      "Bo Li",
      "Haifeng Xu"
    ],
    "abstract": "As foundation models continue to scale, the size of trained models grows\nexponentially, presenting significant challenges for their evaluation. Current\nevaluation practices involve curating increasingly large datasets to assess the\nperformance of large language models (LLMs). However, there is a lack of\nsystematic analysis and guidance on determining the sufficiency of test data or\nselecting informative samples for evaluation. This paper introduces a\ncertifiable and cost-efficient evaluation framework for LLMs. Our framework\nadapts to different evaluation objectives and outputs confidence intervals that\ncontain true values with high probability. We use ``test sample complexity'' to\nquantify the number of test points needed for a certifiable evaluation and\nderive tight bounds on test sample complexity. Based on the developed theory,\nwe develop a partition-based algorithm, named Cer-Eval, that adaptively selects\ntest points to minimize the cost of LLM evaluation. Real-world experiments\ndemonstrate that Cer-Eval can save 20% to 40% test points across various\nbenchmarks, while maintaining an estimation error level comparable to the\ncurrent evaluation process and providing a 95% confidence guarantee.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03814v1",
    "published_date": "2025-05-02 17:05:01 UTC",
    "updated_date": "2025-05-02 17:05:01 UTC"
  },
  {
    "arxiv_id": "2505.01390v1",
    "title": "Multimodal Doctor-in-the-Loop: A Clinically-Guided Explainable Framework for Predicting Pathological Response in Non-Small Cell Lung Cancer",
    "authors": [
      "Alice Natalina Caragliano",
      "Claudia Tacconi",
      "Carlo Greco",
      "Lorenzo Nibid",
      "Edy Ippolito",
      "Michele Fiore",
      "Giuseppe Perrone",
      "Sara Ramella",
      "Paolo Soda",
      "Valerio Guarrasi"
    ],
    "abstract": "This study proposes a novel approach combining Multimodal Deep Learning with\nintrinsic eXplainable Artificial Intelligence techniques to predict\npathological response in non-small cell lung cancer patients undergoing\nneoadjuvant therapy. Due to the limitations of existing radiomics and unimodal\ndeep learning approaches, we introduce an intermediate fusion strategy that\nintegrates imaging and clinical data, enabling efficient interaction between\ndata modalities. The proposed Multimodal Doctor-in-the-Loop method further\nenhances clinical relevance by embedding clinicians' domain knowledge directly\ninto the training process, guiding the model's focus gradually from broader\nlung regions to specific lesions. Results demonstrate improved predictive\naccuracy and explainability, providing insights into optimal data integration\nstrategies for clinical applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2502.17503",
    "pdf_url": "http://arxiv.org/pdf/2505.01390v1",
    "published_date": "2025-05-02 16:57:37 UTC",
    "updated_date": "2025-05-02 16:57:37 UTC"
  },
  {
    "arxiv_id": "2505.02856v1",
    "title": "AI Education in a Mirror: Challenges Faced by Academic and Industry Experts",
    "authors": [
      "Mahir Akgun",
      "Hadi Hosseini"
    ],
    "abstract": "As Artificial Intelligence (AI) technologies continue to evolve, the gap\nbetween academic AI education and real-world industry challenges remains an\nimportant area of investigation. This study provides preliminary insights into\nchallenges AI professionals encounter in both academia and industry, based on\nsemi-structured interviews with 14 AI experts - eight from industry and six\nfrom academia. We identify key challenges related to data quality and\navailability, model scalability, practical constraints, user behavior, and\nexplainability. While both groups experience data and model adaptation\ndifficulties, industry professionals more frequently highlight deployment\nconstraints, resource limitations, and external dependencies, whereas academics\nemphasize theoretical adaptation and standardization issues. These exploratory\nfindings suggest that AI curricula could better integrate real-world\ncomplexities, software engineering principles, and interdisciplinary learning,\nwhile recognizing the broader educational goals of building foundational and\nethical reasoning skills.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "To appear in AIED 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.02856v1",
    "published_date": "2025-05-02 16:52:49 UTC",
    "updated_date": "2025-05-02 16:52:49 UTC"
  },
  {
    "arxiv_id": "2505.01383v1",
    "title": "FalconWing: An Open-Source Platform for Ultra-Light Fixed-Wing Aircraft Research",
    "authors": [
      "Yan Miao",
      "Will Shen",
      "Hang Cui",
      "Sayan Mitra"
    ],
    "abstract": "We present FalconWing -- an open-source, ultra-lightweight (150 g) fixed-wing\nplatform for autonomy research. The hardware platform integrates a small\ncamera, a standard airframe, offboard computation, and radio communication for\nmanual overrides. We demonstrate FalconWing's capabilities by developing and\ndeploying a purely vision-based control policy for autonomous landing (without\nIMU or motion capture) using a novel real-to-sim-to-real learning approach. Our\nlearning approach: (1) constructs a photorealistic simulation environment via\n3D Gaussian splatting trained on real-world images; (2) identifies nonlinear\ndynamics from vision-estimated real-flight data; and (3) trains a multi-modal\nVision Transformer (ViT) policy through simulation-only imitation learning. The\nViT architecture fuses single RGB image with the history of control actions via\nself-attention, preserving temporal context while maintaining real-time 20 Hz\ninference. When deployed zero-shot on the hardware platform, this policy\nachieves an 80% success rate in vision-based autonomous landings. Together with\nthe hardware specifications, we also open-source the system dynamics, the\nsoftware for photorealistic simulator and the learning approach.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01383v1",
    "published_date": "2025-05-02 16:47:05 UTC",
    "updated_date": "2025-05-02 16:47:05 UTC"
  },
  {
    "arxiv_id": "2505.01485v1",
    "title": "CHORUS: Zero-shot Hierarchical Retrieval and Orchestration for Generating Linear Programming Code",
    "authors": [
      "Tasnim Ahmed",
      "Salimur Choudhury"
    ],
    "abstract": "Linear Programming (LP) problems aim to find the optimal solution to an\nobjective under constraints. These problems typically require domain knowledge,\nmathematical skills, and programming ability, presenting significant challenges\nfor non-experts. This study explores the efficiency of Large Language Models\n(LLMs) in generating solver-specific LP code. We propose CHORUS, a\nretrieval-augmented generation (RAG) framework for synthesizing Gurobi-based LP\ncode from natural language problem statements. CHORUS incorporates a\nhierarchical tree-like chunking strategy for theoretical contents and generates\nadditional metadata based on code examples from documentation to facilitate\nself-contained, semantically coherent retrieval. Two-stage retrieval approach\nof CHORUS followed by cross-encoder reranking further ensures contextual\nrelevance. Finally, expertly crafted prompt and structured parser with\nreasoning steps improve code generation performance significantly. Experiments\non the NL4Opt-Code benchmark show that CHORUS improves the performance of\nopen-source LLMs such as Llama3.1 (8B), Llama3.3 (70B), Phi4 (14B), Deepseek-r1\n(32B), and Qwen2.5-coder (32B) by a significant margin compared to baseline and\nconventional RAG. It also allows these open-source LLMs to outperform or match\nthe performance of much stronger baselines-GPT3.5 and GPT4 while requiring far\nfewer computational resources. Ablation studies further demonstrate the\nimportance of expert prompting, hierarchical chunking, and structured\nreasoning.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been accepted for presentation at the 19th Learning\n  and Intelligent Optimization Conference (LION 19)",
    "pdf_url": "http://arxiv.org/pdf/2505.01485v1",
    "published_date": "2025-05-02 16:36:57 UTC",
    "updated_date": "2025-05-02 16:36:57 UTC"
  },
  {
    "arxiv_id": "2505.01372v1",
    "title": "Evaluating Explanations: An Explanatory Virtues Framework for Mechanistic Interpretability -- The Strange Science Part I.ii",
    "authors": [
      "Kola Ayonrinde",
      "Louis Jaburi"
    ],
    "abstract": "Mechanistic Interpretability (MI) aims to understand neural networks through\ncausal explanations. Though MI has many explanation-generating methods,\nprogress has been limited by the lack of a universal approach to evaluating\nexplanations. Here we analyse the fundamental question \"What makes a good\nexplanation?\" We introduce a pluralist Explanatory Virtues Framework drawing on\nfour perspectives from the Philosophy of Science - the Bayesian, Kuhnian,\nDeutschian, and Nomological - to systematically evaluate and improve\nexplanations in MI. We find that Compact Proofs consider many explanatory\nvirtues and are hence a promising approach. Fruitful research directions\nimplied by our framework include (1) clearly defining explanatory simplicity,\n(2) focusing on unifying explanations and (3) deriving universal principles for\nneural networks. Improved MI methods enhance our ability to monitor, predict,\nand steer AI systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages (plus appendices), 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.01372v1",
    "published_date": "2025-05-02 16:18:40 UTC",
    "updated_date": "2025-05-02 16:18:40 UTC"
  },
  {
    "arxiv_id": "2505.01482v1",
    "title": "Understanding LLM Scientific Reasoning through Promptings and Model's Explanation on the Answers",
    "authors": [
      "Alice Rueda",
      "Mohammed S. Hassan",
      "Argyrios Perivolaris",
      "Bazen G. Teferra",
      "Reza Samavi",
      "Sirisha Rambhatla",
      "Yuqi Wu",
      "Yanbo Zhang",
      "Bo Cao",
      "Divya Sharma",
      "Sridhar Krishnan Venkat Bhat"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding, reasoning, and problem-solving across various\ndomains. However, their ability to perform complex, multi-step reasoning\ntask-essential for applications in science, medicine, and law-remains an area\nof active investigation. This paper examines the reasoning capabilities of\ncontemporary LLMs, analyzing their strengths, limitations, and potential for\nimprovement. The study uses prompt engineering techniques on the Graduate-Level\nGoogleProof Q&A (GPQA) dataset to assess the scientific reasoning of GPT-4o.\nFive popular prompt engineering techniques and two tailored promptings were\ntested: baseline direct answer (zero-shot), chain-of-thought (CoT), zero-shot\nCoT, self-ask, self-consistency, decomposition, and multipath promptings. Our\nfindings indicate that while LLMs exhibit emergent reasoning abilities, they\noften rely on pattern recognition rather than true logical inference, leading\nto inconsistencies in complex problem-solving. The results indicated that\nself-consistency outperformed the other prompt engineering technique with an\naccuracy of 52.99%, followed by direct answer (52.23%). Zero-shot CoT (50%)\noutperformed multipath (48.44%), decomposition (47.77%), self-ask (46.88%), and\nCoT (43.75%). Self-consistency performed the second worst in explaining the\nanswers. Simple techniques such as direct answer, CoT, and zero-shot CoT have\nthe best scientific reasoning. We propose a research agenda aimed at bridging\nthese gaps by integrating structured reasoning frameworks, hybrid AI\napproaches, and human-in-the-loop methodologies. By critically evaluating the\nreasoning mechanisms of LLMs, this paper contributes to the ongoing discourse\non the future of artificial general intelligence and the development of more\nrobust, trustworthy AI systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01482v1",
    "published_date": "2025-05-02 16:16:17 UTC",
    "updated_date": "2025-05-02 16:16:17 UTC"
  },
  {
    "arxiv_id": "2505.01353v1",
    "title": "Differentiable Nonlinear Model Predictive Control",
    "authors": [
      "Jonathan Frey",
      "Katrin Baumgärtner",
      "Gianluca Frison",
      "Dirk Reinhardt",
      "Jasper Hoffmann",
      "Leonard Fichtner",
      "Sebastien Gros",
      "Moritz Diehl"
    ],
    "abstract": "The efficient computation of parametric solution sensitivities is a key\nchallenge in the integration of learning-enhanced methods with nonlinear model\npredictive control (MPC), as their availability is crucial for many learning\nalgorithms. While approaches presented in the machine learning community are\nlimited to convex or unconstrained formulations, this paper discusses the\ncomputation of solution sensitivities of general nonlinear programs (NLPs)\nusing the implicit function theorem (IFT) and smoothed optimality conditions\ntreated in interior-point methods (IPM). We detail sensitivity computation\nwithin a sequential quadratic programming (SQP) method which employs an IPM for\nthe quadratic subproblems. The publication is accompanied by an efficient\nopen-source implementation within the framework, providing both forward and\nadjoint sensitivities for general optimal control problems, achieving speedups\nexceeding 3x over the state-of-the-art solver mpc.pytorch.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "math.OC",
    "comment": "19 page, 4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.01353v1",
    "published_date": "2025-05-02 15:43:37 UTC",
    "updated_date": "2025-05-02 15:43:37 UTC"
  },
  {
    "arxiv_id": "2505.01343v1",
    "title": "BalancEdit: Dynamically Balancing the Generality-Locality Trade-off in Multi-modal Model Editing",
    "authors": [
      "Dongliang Guo",
      "Mengxuan Hu",
      "Zihan Guan",
      "Thomas Hartvigsen",
      "Sheng Li"
    ],
    "abstract": "Large multi-modal models inevitably decay over time as facts change and\npreviously learned information becomes outdated. Traditional approaches such as\nfine-tuning are often impractical for updating these models due to their size\nand complexity. Instead, direct knowledge editing within the models presents a\nmore viable solution. Current model editing techniques, however, typically\noverlook the unique influence ranges of different facts, leading to compromised\nmodel performance in terms of both generality and locality. To address this\nissue, we introduce the concept of the generality-locality trade-off in\nmulti-modal model editing. We develop a new model editing dataset named OKEDIT,\nspecifically designed to effectively evaluate this trade-off. Building on this\nfoundation, we propose BalancEdit, a novel method for balanced model editing\nthat dynamically achieves an optimal balance between generality and locality.\nBalancEdit utilizes a unique mechanism that generates both positive and\nnegative samples for each fact to accurately determine its influence scope and\nincorporates these insights into the model's latent space using a discrete,\nlocalized codebook of edits, without modifying the underlying model weights. To\nour knowledge, this is the first approach explicitly addressing the\ngenerality-locality trade-off in multi-modal model editing. Our comprehensive\nresults confirm the effectiveness of BalancEdit, demonstrating minimal\ntrade-offs while maintaining robust editing capabilities. Our code and dataset\nwill be available.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01343v1",
    "published_date": "2025-05-02 15:31:32 UTC",
    "updated_date": "2025-05-02 15:31:32 UTC"
  },
  {
    "arxiv_id": "2505.01328v1",
    "title": "Constrained Network Adversarial Attacks: Validity, Robustness, and Transferability",
    "authors": [
      "Anass Grini",
      "Oumaima Taheri",
      "Btissam El Khamlichi",
      "Amal El Fallah-Seghrouchni"
    ],
    "abstract": "While machine learning has significantly advanced Network Intrusion Detection\nSystems (NIDS), particularly within IoT environments where devices generate\nlarge volumes of data and are increasingly susceptible to cyber threats, these\nmodels remain vulnerable to adversarial attacks. Our research reveals a\ncritical flaw in existing adversarial attack methodologies: the frequent\nviolation of domain-specific constraints, such as numerical and categorical\nlimits, inherent to IoT and network traffic. This leads to up to 80.3% of\nadversarial examples being invalid, significantly overstating real-world\nvulnerabilities. These invalid examples, though effective in fooling models, do\nnot represent feasible attacks within practical IoT deployments. Consequently,\nrelying on these results can mislead resource allocation for defense, inflating\nthe perceived susceptibility of IoT-enabled NIDS models to adversarial\nmanipulation. Furthermore, we demonstrate that simpler surrogate models like\nMulti-Layer Perceptron (MLP) generate more valid adversarial examples compared\nto complex architectures such as CNNs and LSTMs. Using the MLP as a surrogate,\nwe analyze the transferability of adversarial severity to other ML/DL models\ncommonly used in IoT contexts. This work underscores the importance of\nconsidering both domain constraints and model architecture when evaluating and\ndesigning robust ML/DL models for security-critical IoT and network\napplications.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01328v1",
    "published_date": "2025-05-02 15:01:42 UTC",
    "updated_date": "2025-05-02 15:01:42 UTC"
  },
  {
    "arxiv_id": "2505.05491v1",
    "title": "MDDFNet: Mamba-based Dynamic Dual Fusion Network for Traffic Sign Detection",
    "authors": [
      "TianYi Yu"
    ],
    "abstract": "The Detection of small objects, especially traffic signs, is a critical\nsub-task in object detection and autonomous driving. Despite signficant\nprogress in previous research, two main challenges remain. First, the issue of\nfeature extraction being too singular. Second, the detection process struggles\nto efectively handle objects of varying sizes or scales. These problems are\nalso prevalent in general object detection tasks. To address these challenges,\nwe propose a novel object detection network, Mamba-based Dynamic Dual Fusion\nNetwork (MDDFNet), for traffic sign detection. The network integrates a dynamic\ndual fusion module and a Mamba-based backbone to simultaneously tackle the\naforementioned issues. Specifically, the dynamic dual fusion module utilizes\nmultiple branches to consolidate various spatial and semantic information, thus\nenhancing feature diversity. The Mamba-based backbone leverages global feature\nfusion and local feature interaction, combining features in an adaptive manner\nto generate unique classification characteristics. Extensive experiments\nconducted on the TT100K (Tsinghua-Tencent 100K) datasets demonstrate that\nMDDFNet outperforms other state-of-the-art detectors, maintaining real-time\nprocessing capabilities of single-stage models while achieving superior\nperformance. This confirms the efectiveness of MDDFNet in detecting small\ntraffic signs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05491v1",
    "published_date": "2025-05-02 14:53:25 UTC",
    "updated_date": "2025-05-02 14:53:25 UTC"
  },
  {
    "arxiv_id": "2505.01476v1",
    "title": "CostFilter-AD: Enhancing Anomaly Detection through Matching Cost Filtering",
    "authors": [
      "Zhe Zhang",
      "Mingxiu Cai",
      "Hanxiao Wang",
      "Gaochang Wu",
      "Tianyou Chai",
      "Xiatian Zhu"
    ],
    "abstract": "Unsupervised anomaly detection (UAD) seeks to localize the anomaly mask of an\ninput image with respect to normal samples. Either by reconstructing normal\ncounterparts (reconstruction-based) or by learning an image feature embedding\nspace (embedding-based), existing approaches fundamentally rely on image-level\nor feature-level matching to derive anomaly scores. Often, such a matching\nprocess is inaccurate yet overlooked, leading to sub-optimal detection. To\naddress this issue, we introduce the concept of cost filtering, borrowed from\nclassical matching tasks, such as depth and flow estimation, into the UAD\nproblem. We call this approach {\\em CostFilter-AD}. Specifically, we first\nconstruct a matching cost volume between the input and normal samples,\ncomprising two spatial dimensions and one matching dimension that encodes\npotential matches. To refine this, we propose a cost volume filtering network,\nguided by the input observation as an attention query across multiple feature\nlayers, which effectively suppresses matching noise while preserving edge\nstructures and capturing subtle anomalies. Designed as a generic\npost-processing plug-in, CostFilter-AD can be integrated with either\nreconstruction-based or embedding-based methods. Extensive experiments on\nMVTec-AD and VisA benchmarks validate the generic benefits of CostFilter-AD for\nboth single- and multi-class UAD tasks. Code and models will be released at\nhttps://github.com/ZHE-SAPI/CostFilter-AD.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "20 pages, 11 figures, 10 tables, accepted by Forty-Second\n  International Conference on Machine Learning ( ICML 2025 )",
    "pdf_url": "http://arxiv.org/pdf/2505.01476v1",
    "published_date": "2025-05-02 14:52:34 UTC",
    "updated_date": "2025-05-02 14:52:34 UTC"
  },
  {
    "arxiv_id": "2505.01315v2",
    "title": "Helping Large Language Models Protect Themselves: An Enhanced Filtering and Summarization System",
    "authors": [
      "Sheikh Samit Muhaimin",
      "Spyridon Mastorakis"
    ],
    "abstract": "The recent growth in the use of Large Language Models has made them\nvulnerable to sophisticated adversarial assaults, manipulative prompts, and\nencoded malicious inputs. Existing countermeasures frequently necessitate\nretraining models, which is computationally costly and impracticable for\ndeployment. Without the need for retraining or fine-tuning, this study presents\na unique defense paradigm that allows LLMs to recognize, filter, and defend\nagainst adversarial or malicious inputs on their own. There are two main parts\nto the suggested framework: (1) A prompt filtering module that uses\nsophisticated Natural Language Processing (NLP) techniques, including zero-shot\nclassification, keyword analysis, and encoded content detection (e.g. base64,\nhexadecimal, URL encoding), to detect, decode, and classify harmful inputs; and\n(2) A summarization module that processes and summarizes adversarial research\nliterature to give the LLM context-aware defense knowledge. This approach\nstrengthens LLMs' resistance to adversarial exploitation by fusing text\nextraction, summarization, and harmful prompt analysis. According to\nexperimental results, this integrated technique has a 98.71% success rate in\nidentifying harmful patterns, manipulative language structures, and encoded\nprompts. By employing a modest amount of adversarial research literature as\ncontext, the methodology also allows the model to react correctly to harmful\ninputs with a larger percentage of jailbreak resistance and refusal rate. While\nmaintaining the quality of LLM responses, the framework dramatically increases\nLLM's resistance to hostile misuse, demonstrating its efficacy as a quick and\neasy substitute for time-consuming, retraining-based defenses.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01315v2",
    "published_date": "2025-05-02 14:42:26 UTC",
    "updated_date": "2025-05-05 14:46:48 UTC"
  },
  {
    "arxiv_id": "2505.01309v1",
    "title": "Enhancing SPARQL Query Rewriting for Complex Ontology Alignments",
    "authors": [
      "Anicet Lepetit Ondo",
      "Laurence Capus",
      "Mamadou Bousso"
    ],
    "abstract": "SPARQL query rewriting is a fundamental mechanism for uniformly querying\nheterogeneous ontologies in the Linked Data Web. However, the complexity of\nontology alignments, particularly rich correspondences (c : c), makes this\nprocess challenging. Existing approaches primarily focus on simple (s : s) and\npartially complex ( s : c) alignments, thereby overlooking the challenges posed\nby more expressive alignments. Moreover, the intricate syntax of SPARQL\npresents a barrier for non-expert users seeking to fully exploit the knowledge\nencapsulated in ontologies. This article proposes an innovative approach for\nthe automatic rewriting of SPARQL queries from a source ontology to a target\nontology, based on a user's need expressed in natural language. It leverages\nthe principles of equivalence transitivity as well as the advanced capabilities\nof large language models such as GPT-4. By integrating these elements, this\napproach stands out for its ability to efficiently handle complex alignments,\nparticularly (c : c) correspondences , by fully exploiting their\nexpressiveness. Additionally, it facilitates access to aligned ontologies for\nusers unfamiliar with SPARQL, providing a flexible solution for querying\nheterogeneous data.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01309v1",
    "published_date": "2025-05-02 14:38:13 UTC",
    "updated_date": "2025-05-02 14:38:13 UTC"
  },
  {
    "arxiv_id": "2505.01307v1",
    "title": "Document Retrieval Augmented Fine-Tuning (DRAFT) for safety-critical software assessments",
    "authors": [
      "Regan Bolton",
      "Mohammadreza Sheikhfathollahi",
      "Simon Parkinson",
      "Vanessa Vulovic",
      "Gary Bamford",
      "Dan Basher",
      "Howard Parkinson"
    ],
    "abstract": "Safety critical software assessment requires robust assessment against\ncomplex regulatory frameworks, a process traditionally limited by manual\nevaluation. This paper presents Document Retrieval-Augmented Fine-Tuning\n(DRAFT), a novel approach that enhances the capabilities of a large language\nmodel (LLM) for safety-critical compliance assessment. DRAFT builds upon\nexisting Retrieval-Augmented Generation (RAG) techniques by introducing a novel\nfine-tuning framework that accommodates our dual-retrieval architecture, which\nsimultaneously accesses both software documentation and applicable reference\nstandards. To fine-tune DRAFT, we develop a semi-automated dataset generation\nmethodology that incorporates variable numbers of relevant documents with\nmeaningful distractors, closely mirroring real-world assessment scenarios.\nExperiments with GPT-4o-mini demonstrate a 7% improvement in correctness over\nthe baseline model, with qualitative improvements in evidence handling,\nresponse structure, and domain-specific reasoning. DRAFT represents a practical\napproach to improving compliance assessment systems while maintaining the\ntransparency and evidence-based reasoning essential in regulatory domains.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01307v1",
    "published_date": "2025-05-02 14:34:33 UTC",
    "updated_date": "2025-05-02 14:34:33 UTC"
  },
  {
    "arxiv_id": "2505.01305v1",
    "title": "Early Detection of Patient Deterioration from Real-Time Wearable Monitoring System",
    "authors": [
      "Lo Pang-Yun Ting",
      "Hong-Pei Chen",
      "An-Shan Liu",
      "Chun-Yin Yeh",
      "Po-Lin Chen",
      "Kun-Ta Chuang"
    ],
    "abstract": "Early detection of patient deterioration is crucial for reducing mortality\nrates. Heart rate data has shown promise in assessing patient health, and\nwearable devices offer a cost-effective solution for real-time monitoring.\nHowever, extracting meaningful insights from diverse heart rate data and\nhandling missing values in wearable device data remain key challenges. To\naddress these challenges, we propose TARL, an innovative approach that models\nthe structural relationships of representative subsequences, known as\nshapelets, in heart rate time series. TARL creates a shapelet-transition\nknowledge graph to model shapelet dynamics in heart rate time series,\nindicating illness progression and potential future changes. We further\nintroduce a transition-aware knowledge embedding to reinforce relationships\namong shapelets and quantify the impact of missing values, enabling the\nformulation of comprehensive heart rate representations. These representations\ncapture explanatory structures and predict future heart rate trends, aiding\nearly illness detection. We collaborate with physicians and nurses to gather\nICU patient heart rate data from wearables and diagnostic metrics assessing\nillness severity for evaluating deterioration. Experiments on real-world ICU\ndata demonstrate that TARL achieves both high reliability and early detection.\nA case study further showcases TARL's explainable detection process,\nhighlighting its potential as an AI-driven tool to assist clinicians in\nrecognizing early signs of patient deterioration.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01305v1",
    "published_date": "2025-05-02 14:32:44 UTC",
    "updated_date": "2025-05-02 14:32:44 UTC"
  },
  {
    "arxiv_id": "2505.06257v1",
    "title": "Beyond Attention: Toward Machines with Intrinsic Higher Mental States",
    "authors": [
      "Ahsan Adeel"
    ],
    "abstract": "Attending to what is relevant is fundamental to both the mammalian brain and\nmodern machine learning models such as Transformers. Yet, determining relevance\nremains a core challenge, traditionally offloaded to learning algorithms like\nbackpropagation. Inspired by recent cellular neurobiological evidence linking\nneocortical pyramidal cells to distinct mental states, this work shows how\nmodels (e.g., Transformers) can emulate high-level perceptual processing and\nawake thought (imagination) states to pre-select relevant information before\napplying attention. Triadic neuronal-level modulation loops among questions\n($Q$), clues (keys, $K$), and hypotheses (values, $V$) enable diverse, deep,\nparallel reasoning chains at the representation level and allow a rapid shift\nfrom initial biases to refined understanding. This leads to orders-of-magnitude\nfaster learning with significantly reduced computational demand (e.g., fewer\nheads, layers, and tokens), at an approximate cost of $\\mathcal{O}(N)$, where\n$N$ is the number of input tokens. Results span reinforcement learning (e.g.,\nCarRacing in a high-dimensional visual setup), computer vision, and natural\nlanguage question answering.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06257v1",
    "published_date": "2025-05-02 14:31:10 UTC",
    "updated_date": "2025-05-02 14:31:10 UTC"
  },
  {
    "arxiv_id": "2505.01475v2",
    "title": "CodeSSM: Towards State Space Models for Code Understanding",
    "authors": [
      "Shweta Verma",
      "Abhinav Anand",
      "Mira Mezini"
    ],
    "abstract": "Although transformers are widely used for various code-specific tasks, they\nhave some significant limitations. In this paper, we investigate State Space\nModels (SSMs) as a potential alternative to transformers for code understanding\ntasks, such as code retrieval, classification, and clone detection. Previous\nresearch has already demonstrated that SSMs are more compute-efficient than\ntransformers. In our work, we show that SSMs are also more sample-efficient and\ncan effectively extrapolate to longer contexts (beyond the pretraining context)\nduring fine-tuning. Through comprehensive experiments, we demonstrate that SSMs\ncould serve as a viable alternative to transformers for code understanding\ntasks, while addressing some of the major limitations associated with\ntransformers.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01475v2",
    "published_date": "2025-05-02 14:27:49 UTC",
    "updated_date": "2025-05-21 15:24:04 UTC"
  },
  {
    "arxiv_id": "2505.01474v1",
    "title": "Watermark Overwriting Attack on StegaStamp algorithm",
    "authors": [
      "I. F. Serzhenko",
      "L. A. Khaertdinova",
      "M. A. Pautov",
      "A. V. Antsiferova"
    ],
    "abstract": "This paper presents an attack method on the StegaStamp watermarking algorithm\nthat completely removes watermarks from an image with minimal quality loss,\ndeveloped as part of the NeurIPS \"Erasing the invisible\" competition.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01474v1",
    "published_date": "2025-05-02 14:07:43 UTC",
    "updated_date": "2025-05-02 14:07:43 UTC"
  },
  {
    "arxiv_id": "2505.01288v2",
    "title": "ViSA-Flow: Accelerating Robot Skill Learning via Large-Scale Video Semantic Action Flow",
    "authors": [
      "Changhe Chen",
      "Quantao Yang",
      "Xiaohao Xu",
      "Nima Fazeli",
      "Olov Andersson"
    ],
    "abstract": "One of the central challenges preventing robots from acquiring complex\nmanipulation skills is the prohibitive cost of collecting large-scale robot\ndemonstrations. In contrast, humans are able to learn efficiently by watching\nothers interact with their environment. To bridge this gap, we introduce\nsemantic action flow as a core intermediate representation capturing the\nessential spatio-temporal manipulator-object interactions, invariant to\nsuperficial visual differences. We present ViSA-Flow, a framework that learns\nthis representation self-supervised from unlabeled large-scale video data.\nFirst, a generative model is pre-trained on semantic action flows automatically\nextracted from large-scale human-object interaction video data, learning a\nrobust prior over manipulation structure. Second, this prior is efficiently\nadapted to a target robot by fine-tuning on a small set of robot demonstrations\nprocessed through the same semantic abstraction pipeline. We demonstrate\nthrough extensive experiments on the CALVIN benchmark and real-world tasks that\nViSA-Flow achieves state-of-the-art performance, particularly in low-data\nregimes, outperforming prior methods by effectively transferring knowledge from\nhuman video observation to robotic execution. Videos are available at\nhttps://visaflow-web.github.io/ViSAFLOW.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01288v2",
    "published_date": "2025-05-02 14:03:06 UTC",
    "updated_date": "2025-05-12 13:37:00 UTC"
  },
  {
    "arxiv_id": "2505.01286v1",
    "title": "2DXformer: Dual Transformers for Wind Power Forecasting with Dual Exogenous Variables",
    "authors": [
      "Yajuan Zhang",
      "Jiahai Jiang",
      "Yule Yan",
      "Liang Yang",
      "Ping Zhang"
    ],
    "abstract": "Accurate wind power forecasting can help formulate scientific dispatch plans,\nwhich is of great significance for maintaining the safety, stability, and\nefficient operation of the power system. In recent years, wind power\nforecasting methods based on deep learning have focused on extracting the\nspatiotemporal correlations among data, achieving significant improvements in\nforecasting accuracy. However, they exhibit two limitations. First, there is a\nlack of modeling for the inter-variable relationships, which limits the\naccuracy of the forecasts. Second, by treating endogenous and exogenous\nvariables equally, it leads to unnecessary interactions between the endogenous\nand exogenous variables, increasing the complexity of the model. In this paper,\nwe propose the 2DXformer, which, building upon the previous work's focus on\nspatiotemporal correlations, addresses the aforementioned two limitations.\nSpecifically, we classify the inputs of the model into three types: exogenous\nstatic variables, exogenous dynamic variables, and endogenous variables. First,\nwe embed these variables as variable tokens in a channel-independent manner.\nThen, we use the attention mechanism to capture the correlations among\nexogenous variables. Finally, we employ a multi-layer perceptron with residual\nconnections to model the impact of exogenous variables on endogenous variables.\nExperimental results on two real-world large-scale datasets indicate that our\nproposed 2DXformer can further improve the performance of wind power\nforecasting. The code is available in this repository:\n\\href{https://github.com/jseaj/2DXformer}{https://github.com/jseaj/2DXformer}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICDM 2024",
    "pdf_url": "http://arxiv.org/pdf/2505.01286v1",
    "published_date": "2025-05-02 14:00:48 UTC",
    "updated_date": "2025-05-02 14:00:48 UTC"
  },
  {
    "arxiv_id": "2505.01283v1",
    "title": "Reduced-order structure-property linkages for stochastic metamaterials",
    "authors": [
      "Hooman Danesh",
      "Maruthi Annamaraju",
      "Tim Brepols",
      "Stefanie Reese",
      "Surya R. Kalidindi"
    ],
    "abstract": "The capabilities of additive manufacturing have facilitated the design and\nproduction of mechanical metamaterials with diverse unit cell geometries.\nEstablishing linkages between the vast design space of unit cells and their\neffective mechanical properties is critical for the efficient design and\nperformance evaluation of such metamaterials. However, physics-based\nsimulations of metamaterial unit cells across the entire design space are\ncomputationally expensive, necessitating a materials informatics framework to\nefficiently capture complex structure-property relationships. In this work,\nprincipal component analysis of 2-point correlation functions is performed to\nextract the salient features from a large dataset of randomly generated 2D\nmetamaterials. Physics-based simulations are performed using a fast Fourier\ntransform (FFT)-based homogenization approach to efficiently compute the\nhomogenized effective elastic stiffness across the extensive unit cell designs.\nSubsequently, Gaussian process regression is used to generate reduced-order\nsurrogates, mapping unit cell designs to their homogenized effective elastic\nconstant. It is demonstrated that the adopted workflow enables a high-value\nlow-dimensional representation of the voluminous stochastic metamaterial\ndataset, facilitating the construction of robust structure-property maps.\nFinally, an uncertainty-based active learning framework is utilized to train a\nsurrogate model with a significantly smaller number of data points compared to\nthe original full dataset. It is shown that a dataset as small as $0.61\\%$ of\nthe entire dataset is sufficient to generate accurate and robust\nstructure-property maps.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01283v1",
    "published_date": "2025-05-02 13:58:47 UTC",
    "updated_date": "2025-05-02 13:58:47 UTC"
  },
  {
    "arxiv_id": "2505.01281v1",
    "title": "A Physics-preserved Transfer Learning Method for Differential Equations",
    "authors": [
      "Hao-Ran Yang",
      "Chuan-Xian Ren"
    ],
    "abstract": "While data-driven methods such as neural operator have achieved great success\nin solving differential equations (DEs), they suffer from domain shift problems\ncaused by different learning environments (with data bias or equation changes),\nwhich can be alleviated by transfer learning (TL). However, existing TL methods\nadopted in DEs problems lack either generalizability in general DEs problems or\nphysics preservation during training. In this work, we focus on a general\ntransfer learning method that adaptively correct the domain shift and preserve\nphysical information. Mathematically, we characterize the data domain as\nproduct distribution and the essential problems as distribution bias and\noperator bias. A Physics-preserved Optimal Tensor Transport (POTT) method that\nsimultaneously admits generalizability to common DEs and physics preservation\nof specific problem is proposed to adapt the data-driven model to target domain\nutilizing the push-forward distribution induced by the POTT map. Extensive\nexperiments demonstrate the superior performance, generalizability and physics\npreservation of the proposed POTT method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01281v1",
    "published_date": "2025-05-02 13:58:36 UTC",
    "updated_date": "2025-05-02 13:58:36 UTC"
  },
  {
    "arxiv_id": "2505.01261v1",
    "title": "Enhancing Obsolescence Forecasting with Deep Generative Data Augmentation: A Semi-Supervised Framework for Low-Data Industrial Applications",
    "authors": [
      "Elie Saad",
      "Mariem Besbes",
      "Marc Zolghadri",
      "Victor Czmil",
      "Claude Baron",
      "Vincent Bourgeois"
    ],
    "abstract": "The challenge of electronic component obsolescence is particularly critical\nin systems with long life cycles. Various obsolescence management methods are\nemployed to mitigate its impact, with obsolescence forecasting being a highly\nsought-after and prominent approach. As a result, numerous machine\nlearning-based forecasting methods have been proposed. However, machine\nlearning models require a substantial amount of relevant data to achieve high\nprecision, which is lacking in the current obsolescence landscape in some\nsituations. This work introduces a novel framework for obsolescence forecasting\nbased on deep learning. The proposed framework solves the lack of available\ndata through deep generative modeling, where new obsolescence cases are\ngenerated and used to augment the training dataset. The augmented dataset is\nthen used to train a classical machine learning-based obsolescence forecasting\nmodel. To train classical forecasting models using augmented datasets, existing\nclassical supervised-learning classifiers are adapted for semi-supervised\nlearning within this framework. The proposed framework demonstrates\nstate-of-the-art results on benchmarking datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01261v1",
    "published_date": "2025-05-02 13:28:50 UTC",
    "updated_date": "2025-05-02 13:28:50 UTC"
  },
  {
    "arxiv_id": "2505.01238v1",
    "title": "EvalxNLP: A Framework for Benchmarking Post-Hoc Explainability Methods on NLP Models",
    "authors": [
      "Mahdi Dhaini",
      "Kafaite Zahra Hussain",
      "Efstratios Zaradoukas",
      "Gjergji Kasneci"
    ],
    "abstract": "As Natural Language Processing (NLP) models continue to evolve and become\nintegral to high-stakes applications, ensuring their interpretability remains a\ncritical challenge. Given the growing variety of explainability methods and\ndiverse stakeholder requirements, frameworks that help stakeholders select\nappropriate explanations tailored to their specific use cases are increasingly\nimportant. To address this need, we introduce EvalxNLP, a Python framework for\nbenchmarking state-of-the-art feature attribution methods for transformer-based\nNLP models. EvalxNLP integrates eight widely recognized explainability\ntechniques from the Explainable AI (XAI) literature, enabling users to generate\nand evaluate explanations based on key properties such as faithfulness,\nplausibility, and complexity. Our framework also provides interactive,\nLLM-based textual explanations, facilitating user understanding of the\ngenerated explanations and evaluation outcomes. Human evaluation results\nindicate high user satisfaction with EvalxNLP, suggesting it is a promising\nframework for benchmarking explanation methods across diverse user groups. By\noffering a user-friendly and extensible platform, EvalxNLP aims at\ndemocratizing explainability tools and supporting the systematic comparison and\nadvancement of XAI techniques in NLP.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to the xAI World Conference (2025) - System Demonstration",
    "pdf_url": "http://arxiv.org/pdf/2505.01238v1",
    "published_date": "2025-05-02 13:00:05 UTC",
    "updated_date": "2025-05-02 13:00:05 UTC"
  },
  {
    "arxiv_id": "2505.02854v1",
    "title": "Ensuring Reproducibility in Generative AI Systems for General Use Cases: A Framework for Regression Testing and Open Datasets",
    "authors": [
      "Masumi Morishige",
      "Ryo Koshihara"
    ],
    "abstract": "Reproducibility and reliability remain pressing challenges for generative AI\nsystems whose behavior can drift with each model update or prompt revision. We\nintroduce GPR-bench, a lightweight, extensible benchmark that operationalizes\nregression testing for general purpose use cases. GPR-bench couples an open,\nbilingual (English and Japanese) dataset covering eight task categories (e.g.,\ntext generation, code generation, and information retrieval) and 10 scenarios\nin each task categories (80 total test cases for each language) with an\nautomated evaluation pipeline that employs \"LLM-as-a-Judge\" scoring of\ncorrectness and conciseness. Experiments across three recent model versions -\ngpt-4o-mini, o3-mini, and o4-mini - and two prompt configurations (default\nversus concise-writing instruction) reveal heterogeneous quality. Our results\nshow that newer models generally improve correctness, but the differences are\nmodest and not statistically significant, suggesting that GPR-bench may not be\nsufficiently challenging to differentiate between recent model versions. In\ncontrast, the concise-writing instruction significantly enhances conciseness\n(+12.37 pp, Mann-Whitney U test: p < 0.001, effect size r = 0.2995) with\nminimal degradations on accuracy (-1.7 pp), demonstrating the effectiveness of\nprompt engineering. Released under the MIT License, GPR- bench lowers the\nbarrier to initiating reproducibility monitoring and provides a foundation for\ncommunity-driven extensions, while also raising important considerations about\nbenchmark design for rapidly evolving language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.02854v1",
    "published_date": "2025-05-02 12:31:43 UTC",
    "updated_date": "2025-05-02 12:31:43 UTC"
  },
  {
    "arxiv_id": "2505.02853v1",
    "title": "A Computational Model of Inclusive Pedagogy: From Understanding to Application",
    "authors": [
      "Francesco Balzan",
      "Pedro P. Santos",
      "Maurizio Gabbrielli",
      "Mahault Albarracin",
      "Manuel Lopes"
    ],
    "abstract": "Human education transcends mere knowledge transfer, it relies on\nco-adaptation dynamics -- the mutual adjustment of teaching and learning\nstrategies between agents. Despite its centrality, computational models of\nco-adaptive teacher-student interactions (T-SI) remain underdeveloped. We argue\nthat this gap impedes Educational Science in testing and scaling contextual\ninsights across diverse settings, and limits the potential of Machine Learning\nsystems, which struggle to emulate and adaptively support human learning\nprocesses. To address this, we present a computational T-SI model that\nintegrates contextual insights on human education into a testable framework. We\nuse the model to evaluate diverse T-SI strategies in a realistic synthetic\nclassroom setting, simulating student groups with unequal access to sensory\ninformation. Results show that strategies incorporating co-adaptation\nprinciples (e.g., bidirectional agency) outperform unilateral approaches (i.e.,\nwhere only the teacher or the student is active), improving the learning\noutcomes for all learning types. Beyond the testing and scaling of\ncontext-dependent educational insights, our model enables hypothesis generation\nin controlled yet adaptable environments. This work bridges non-computational\ntheories of human education with scalable, inclusive AI in Education systems,\nproviding a foundation for equitable technologies that dynamically adapt to\nlearner needs.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "This is a preprint version of a manuscript intended for submission to\n  the International Journal of Artificial Intelligence in Education (IJAIED)",
    "pdf_url": "http://arxiv.org/pdf/2505.02853v1",
    "published_date": "2025-05-02 12:26:31 UTC",
    "updated_date": "2025-05-02 12:26:31 UTC"
  },
  {
    "arxiv_id": "2505.03811v1",
    "title": "ScarceGAN: Discriminative Classification Framework for Rare Class Identification for Longitudinal Data with Weak Prior",
    "authors": [
      "Surajit Chakrabarty",
      "Rukma Talwadker",
      "Tridib Mukherjee"
    ],
    "abstract": "This paper introduces ScarceGAN which focuses on identification of extremely\nrare or scarce samples from multi-dimensional longitudinal telemetry data with\nsmall and weak label prior. We specifically address: (i) severe scarcity in\npositive class, stemming from both underlying organic skew in the data, as well\nas extremely limited labels; (ii) multi-class nature of the negative samples,\nwith uneven density distributions and partially overlapping feature\ndistributions; and (iii) massively unlabelled data leading to tiny and weak\nprior on both positive and negative classes, and possibility of unseen or\nunknown behavior in the unlabelled set, especially in the negative class.\nAlthough related to PU learning problems, we contend that knowledge (or lack of\nit) on the negative class can be leveraged to learn the compliment of it (i.e.,\nthe positive class) better in a semi-supervised manner. To this effect,\nScarceGAN re-formulates semi-supervised GAN by accommodating weakly labelled\nmulti-class negative samples and the available positive samples. It relaxes the\nsupervised discriminator's constraint on exact differentiation between negative\nsamples by introducing a 'leeway' term for samples with noisy prior. We propose\nmodifications to the cost objectives of discriminator, in supervised and\nunsupervised path as well as that of the generator. For identifying risky\nplayers in skill gaming, this formulation in whole gives us a recall of over\n85% (~60% jump over vanilla semi-supervised GAN) on our scarce class with very\nminimal verbosity in the unknown space. Further ScarceGAN outperforms the\nrecall benchmarks established by recent GAN based specialized models for the\npositive imbalanced class identification and establishes a new benchmark in\nidentifying one of rare attack classes (0.09%) in the intrusion dataset from\nthe KDDCUP99 challenge.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03811v1",
    "published_date": "2025-05-02 12:17:37 UTC",
    "updated_date": "2025-05-02 12:17:37 UTC"
  },
  {
    "arxiv_id": "2505.03810v1",
    "title": "Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free",
    "authors": [
      "Euntae Choi",
      "Sumin Song",
      "Woosang Lim",
      "Sungjoo Yoo"
    ],
    "abstract": "Large Language Models (LLMs) face deployment challenges due to high\ncomputational costs, and while Post-Training Quantization (PTQ) offers a\nsolution, existing rotation-based methods struggle at very low bit-widths like\n2-bit. We introduce a novel, training-free approach to construct an improved\nrotation matrix, addressing the limitations of current methods. The key\ncontributions include leveraging the Walsh-Hadamard transform with sequency\nordering, which clusters similar frequency components to reduce quantization\nerror compared to standard Hadamard matrices, significantly improving\nperformance. Furthermore, we propose a Grouped Sequency-arranged Rotation (GSR)\nusing block-diagonal matrices with smaller Walsh blocks, effectively isolating\noutlier impacts and achieving performance comparable to optimization-based\nmethods without requiring any training. Our method demonstrates robust\nperformance on reasoning tasks and Perplexity (PPL) score on WikiText-2. Our\nmethod also enhances results even when applied over existing learned rotation\ntechniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.03810v1",
    "published_date": "2025-05-02 11:51:29 UTC",
    "updated_date": "2025-05-02 11:51:29 UTC"
  },
  {
    "arxiv_id": "2505.01198v1",
    "title": "Gender Bias in Explainability: Investigating Performance Disparity in Post-hoc Methods",
    "authors": [
      "Mahdi Dhaini",
      "Ege Erdogan",
      "Nils Feldhus",
      "Gjergji Kasneci"
    ],
    "abstract": "While research on applications and evaluations of explanation methods\ncontinues to expand, fairness of the explanation methods concerning disparities\nin their performance across subgroups remains an often overlooked aspect. In\nthis paper, we address this gap by showing that, across three tasks and five\nlanguage models, widely used post-hoc feature attribution methods exhibit\nsignificant gender disparity with respect to their faithfulness, robustness,\nand complexity. These disparities persist even when the models are pre-trained\nor fine-tuned on particularly unbiased datasets, indicating that the\ndisparities we observe are not merely consequences of biased training data. Our\nresults highlight the importance of addressing disparities in explanations when\ndeveloping and applying explainability methods, as these can lead to biased\noutcomes against certain subgroups, with particularly critical implications in\nhigh-stakes contexts. Furthermore, our findings underscore the importance of\nincorporating the fairness of explanations, alongside overall model fairness\nand explainability, as a requirement in regulatory frameworks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT) 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.01198v1",
    "published_date": "2025-05-02 11:41:25 UTC",
    "updated_date": "2025-05-02 11:41:25 UTC"
  },
  {
    "arxiv_id": "2505.03809v1",
    "title": "When Dynamic Data Selection Meets Data Augmentation",
    "authors": [
      "Suorong Yang",
      "Peng Ye",
      "Furao Shen",
      "Dongzhan Zhou"
    ],
    "abstract": "Dynamic data selection aims to accelerate training with lossless performance.\nHowever, reducing training data inherently limits data diversity, potentially\nhindering generalization. While data augmentation is widely used to enhance\ndiversity, it is typically not optimized in conjunction with selection. As a\nresult, directly combining these techniques fails to fully exploit their\nsynergies. To tackle the challenge, we propose a novel online data training\nframework that, for the first time, unifies dynamic data selection and\naugmentation, achieving both training efficiency and enhanced performance. Our\nmethod estimates each sample's joint distribution of local density and\nmultimodal semantic consistency, allowing for the targeted selection of\naugmentation-suitable samples while suppressing the inclusion of noisy or\nambiguous data. This enables a more significant reduction in dataset size\nwithout sacrificing model generalization. Experimental results demonstrate that\nour method outperforms existing state-of-the-art approaches on various\nbenchmark datasets and architectures, e.g., reducing 50\\% training costs on\nImageNet-1k with lossless performance. Furthermore, our approach enhances noise\nresistance and improves model robustness, reinforcing its practical utility in\nreal-world scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03809v1",
    "published_date": "2025-05-02 11:38:48 UTC",
    "updated_date": "2025-05-02 11:38:48 UTC"
  },
  {
    "arxiv_id": "2505.01192v1",
    "title": "Exploring the Impact of Explainable AI and Cognitive Capabilities on Users' Decisions",
    "authors": [
      "Federico Maria Cau",
      "Lucio Davide Spano"
    ],
    "abstract": "Artificial Intelligence (AI) systems are increasingly used for\ndecision-making across domains, raising debates over the information and\nexplanations they should provide. Most research on Explainable AI (XAI) has\nfocused on feature-based explanations, with less attention on alternative\nstyles. Personality traits like the Need for Cognition (NFC) can also lead to\ndifferent decision-making outcomes among low and high NFC individuals. We\ninvestigated how presenting AI information (prediction, confidence, and\naccuracy) and different explanation styles (example-based, feature-based,\nrule-based, and counterfactual) affect accuracy, reliance on AI, and cognitive\nload in a loan application scenario. We also examined low and high NFC\nindividuals' differences in prioritizing XAI interface elements (loan\nattributes, AI information, and explanations), accuracy, and cognitive load.\nOur findings show that high AI confidence significantly increases reliance on\nAI while reducing cognitive load. Feature-based explanations did not enhance\naccuracy compared to other conditions. Although counterfactual explanations\nwere less understandable, they enhanced overall accuracy, increasing reliance\non AI and reducing cognitive load when AI predictions were correct. Both low\nand high NFC individuals prioritized explanations after loan attributes,\nleaving AI information as the least important. However, we found no significant\ndifferences between low and high NFC groups in accuracy or cognitive load,\nraising questions about the role of personality traits in AI-assisted\ndecision-making. These findings highlight the need for user-centric\npersonalization in XAI interfaces, incorporating diverse explanation styles and\nexploring multiple personality traits and other user characteristics to\noptimize human-AI collaboration.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.01192v1",
    "published_date": "2025-05-02 11:30:53 UTC",
    "updated_date": "2025-05-02 11:30:53 UTC"
  },
  {
    "arxiv_id": "2505.01186v1",
    "title": "Secure Cluster-Based Hierarchical Federated Learning in Vehicular Networks",
    "authors": [
      "M. Saeid HaghighiFard",
      "Sinem Coleri"
    ],
    "abstract": "Hierarchical Federated Learning (HFL) has recently emerged as a promising\nsolution for intelligent decision-making in vehicular networks, helping to\naddress challenges such as limited communication resources, high vehicle\nmobility, and data heterogeneity. However, HFL remains vulnerable to\nadversarial and unreliable vehicles, whose misleading updates can significantly\ncompromise the integrity and convergence of the global model. To address these\nchallenges, we propose a novel defense framework that integrates dynamic\nvehicle selection with robust anomaly detection within a cluster-based HFL\narchitecture, specifically designed to counter Gaussian noise and gradient\nascent attacks. The framework performs a comprehensive reliability assessment\nfor each vehicle by evaluating historical accuracy, contribution frequency, and\nanomaly records. Anomaly detection combines Z-score and cosine similarity\nanalyses on model updates to identify both statistical outliers and directional\ndeviations in model updates. To further refine detection, an adaptive\nthresholding mechanism is incorporated into the cosine similarity metric,\ndynamically adjusting the threshold based on the historical accuracy of each\nvehicle to enforce stricter standards for consistently high-performing\nvehicles. In addition, a weighted gradient averaging mechanism is implemented,\nwhich assigns higher weights to gradient updates from more trustworthy\nvehicles. To defend against coordinated attacks, a cross-cluster consistency\ncheck is applied to identify collaborative attacks in which multiple\ncompromised clusters coordinate misleading updates. Together, these mechanisms\nform a multi-level defense strategy to filter out malicious contributions\neffectively. Simulation results show that the proposed algorithm significantly\nreduces convergence time compared to benchmark methods across both 1-hop and\n3-hop topologies.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01186v1",
    "published_date": "2025-05-02 11:01:00 UTC",
    "updated_date": "2025-05-02 11:01:00 UTC"
  },
  {
    "arxiv_id": "2505.01185v1",
    "title": "EnviKal-Loc: Sub-10m Indoor LoRaWAN Localization using an Environmental-Aware Path Loss and Adaptive RSSI Smoothing",
    "authors": [
      "Nahshon Mokua Obiri",
      "Kristof Van Laerhoven"
    ],
    "abstract": "LoRaWAN technology's extensive coverage positions it as a strong contender\nfor large-scale IoT deployments. However, achieving sub-10 m accuracy in indoor\nlocalization remains challenging due to complex environmental conditions,\nmultipath fading, and transient obstructions. This paper proposes a lightweight\nbut robust approach combining adaptive filtering with an extended log-distance,\nmulti-wall path loss and shadowing (PLS) model. Our methodology augments\nconventional models with critical LoRaWAN parameters (received signal strength\nindicator (RSSI), frequency, and signal-to-noise ratio (SNR)) and dynamic\nenvironmental indicators (temperature, humidity, carbon dioxide, particulate\nmatter, and barometric pressure). An adaptive Kalman filter reduces RSSI\nfluctuations, isolating persistent trends from momentary noise. Using a\nsix-month dataset of 1,328,334 field measurements, we evaluate three models:\nthe baseline COST 231 multi-wall model (MWM), the baseline model augmented with\nenvironmental parameters (MWM-EP), and a forward-only adaptive Kalman-filtered\nRSSI version of the latter (MWM-EP-KF). Results confirm that the MWM-EP-KF\nachieves a mean absolute error (MAE) of 5.81 m, outperforming both the MWM-EP\n(10.56 m) and the baseline MWM framework (17.98 m). Environmental augmentation\nreduces systematic errors by 41.22%, while Kalman filtering significantly\nenhances robustness under high RSSI volatility by 42.63%, on average across all\ndevices. These findings present an interpretable, efficient solution for\nprecise indoor LoRaWAN localization in dynamically changing environments.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01185v1",
    "published_date": "2025-05-02 11:00:40 UTC",
    "updated_date": "2025-05-02 11:00:40 UTC"
  },
  {
    "arxiv_id": "2505.01182v2",
    "title": "TSTMotion: Training-free Scene-aware Text-to-motion Generation",
    "authors": [
      "Ziyan Guo",
      "Haoxuan Qu",
      "Hossein Rahmani",
      "Dewen Soh",
      "Ping Hu",
      "Qiuhong Ke",
      "Jun Liu"
    ],
    "abstract": "Text-to-motion generation has recently garnered significant research\ninterest, primarily focusing on generating human motion sequences in blank\nbackgrounds. However, human motions commonly occur within diverse 3D scenes,\nwhich has prompted exploration into scene-aware text-to-motion generation\nmethods. Yet, existing scene-aware methods often rely on large-scale\nground-truth motion sequences in diverse 3D scenes, which poses practical\nchallenges due to the expensive cost. To mitigate this challenge, we are the\nfirst to propose a \\textbf{T}raining-free \\textbf{S}cene-aware\n\\textbf{T}ext-to-\\textbf{Motion} framework, dubbed as \\textbf{TSTMotion}, that\nefficiently empowers pre-trained blank-background motion generators with the\nscene-aware capability. Specifically, conditioned on the given 3D scene and\ntext description, we adopt foundation models together to reason, predict and\nvalidate a scene-aware motion guidance. Then, the motion guidance is\nincorporated into the blank-background motion generators with two\nmodifications, resulting in scene-aware text-driven motion sequences. Extensive\nexperiments demonstrate the efficacy and generalizability of our proposed\nframework. We release our code in \\href{https://tstmotion.github.io/}{Project\nPage}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICME2025",
    "pdf_url": "http://arxiv.org/pdf/2505.01182v2",
    "published_date": "2025-05-02 10:50:04 UTC",
    "updated_date": "2025-05-05 05:14:20 UTC"
  },
  {
    "arxiv_id": "2505.01181v1",
    "title": "Explainable AI Based Diagnosis of Poisoning Attacks in Evolutionary Swarms",
    "authors": [
      "Mehrdad Asadi",
      "Roxana Rădulescu",
      "Ann Nowé"
    ],
    "abstract": "Swarming systems, such as for example multi-drone networks, excel at\ncooperative tasks like monitoring, surveillance, or disaster assistance in\ncritical environments, where autonomous agents make decentralized decisions in\norder to fulfill team-level objectives in a robust and efficient manner.\nUnfortunately, team-level coordinated strategies in the wild are vulnerable to\ndata poisoning attacks, resulting in either inaccurate coordination or\nadversarial behavior among the agents. To address this challenge, we contribute\na framework that investigates the effects of such data poisoning attacks, using\nexplainable AI methods. We model the interaction among agents using\nevolutionary intelligence, where an optimal coalition strategically emerges to\nperform coordinated tasks. Then, through a rigorous evaluation, the swarm model\nis systematically poisoned using data manipulation attacks. We showcase the\napplicability of explainable AI methods to quantify the effects of poisoning on\nthe team strategy and extract footprint characterizations that enable\ndiagnosing. Our findings indicate that when the model is poisoned above 10%,\nnon-optimal strategies resulting in inefficient cooperation can be identified.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear in short form in Genetic and Evolutionary Computation\n  Conference (GECCO '25 Companion), 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.01181v1",
    "published_date": "2025-05-02 10:48:40 UTC",
    "updated_date": "2025-05-02 10:48:40 UTC"
  },
  {
    "arxiv_id": "2505.01177v1",
    "title": "LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures",
    "authors": [
      "Francisco Aguilera-Martínez",
      "Fernando Berzal"
    ],
    "abstract": "As large language models (LLMs) continue to evolve, it is critical to assess\nthe security threats and vulnerabilities that may arise both during their\ntraining phase and after models have been deployed. This survey seeks to define\nand categorize the various attacks targeting LLMs, distinguishing between those\nthat occur during the training phase and those that affect already trained\nmodels. A thorough analysis of these attacks is presented, alongside an\nexploration of defense mechanisms designed to mitigate such threats. Defenses\nare classified into two primary categories: prevention-based and\ndetection-based defenses. Furthermore, our survey summarizes possible attacks\nand their corresponding defense strategies. It also provides an evaluation of\nthe effectiveness of the known defense mechanisms for the different security\nthreats. Our survey aims to offer a structured framework for securing LLMs,\nwhile also identifying areas that require further research to improve and\nstrengthen defenses against emerging security challenges.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01177v1",
    "published_date": "2025-05-02 10:35:26 UTC",
    "updated_date": "2025-05-02 10:35:26 UTC"
  },
  {
    "arxiv_id": "2505.01169v2",
    "title": "Distilling Two-Timed Flow Models by Separately Matching Initial and Terminal Velocities",
    "authors": [
      "Pramook Khungurn",
      "Pratch Piyawongwisal",
      "Sira Sriswasdi",
      "Supasorn Suwajanakorn"
    ],
    "abstract": "A flow matching model learns a time-dependent vector field $v_t(x)$ that\ngenerates a probability path $\\{ p_t \\}_{0 \\leq t \\leq 1}$ that interpolates\nbetween a well-known noise distribution ($p_0$) and the data distribution\n($p_1$). It can be distilled into a two-timed flow model (TTFM) $\\phi_{s,x}(t)$\nthat can transform a sample belonging to the distribution at an initial time\n$s$ to another belonging to the distribution at a terminal time $t$ in one\nfunction evaluation. We present a new loss function for TTFM distillation\ncalled the \\emph{initial/terminal velocity matching} (ITVM) loss that extends\nthe Lagrangian Flow Map Distillation (LFMD) loss proposed by Boffi et al. by\nadding redundant terms to match the initial velocities at time $s$, removing\nthe derivative from the terminal velocity term at time $t$, and using a version\nof the model under training, stabilized by exponential moving averaging (EMA),\nto compute the target terminal average velocity. Preliminary experiments show\nthat our loss leads to better few-step generation performance on multiple types\nof datasets and model architectures over baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01169v2",
    "published_date": "2025-05-02 10:17:49 UTC",
    "updated_date": "2025-05-06 08:22:46 UTC"
  },
  {
    "arxiv_id": "2505.01168v1",
    "title": "Harmonizing Intra-coherence and Inter-divergence in Ensemble Attacks for Adversarial Transferability",
    "authors": [
      "Zhaoyang Ma",
      "Zhihao Wu",
      "Wang Lu",
      "Xin Gao",
      "Jinghang Yue",
      "Taolin Zhang",
      "Lipo Wang",
      "Youfang Lin",
      "Jing Wang"
    ],
    "abstract": "The development of model ensemble attacks has significantly improved the\ntransferability of adversarial examples, but this progress also poses severe\nthreats to the security of deep neural networks. Existing methods, however,\nface two critical challenges: insufficient capture of shared gradient\ndirections across models and a lack of adaptive weight allocation mechanisms.\nTo address these issues, we propose a novel method Harmonized Ensemble for\nAdversarial Transferability (HEAT), which introduces domain generalization into\nadversarial example generation for the first time. HEAT consists of two key\nmodules: Consensus Gradient Direction Synthesizer, which uses Singular Value\nDecomposition to synthesize shared gradient directions; and Dual-Harmony Weight\nOrchestrator which dynamically balances intra-domain coherence, stabilizing\ngradients within individual models, and inter-domain diversity, enhancing\ntransferability across models. Experimental results demonstrate that HEAT\nsignificantly outperforms existing methods across various datasets and\nsettings, offering a new perspective and direction for adversarial attack\nresearch.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01168v1",
    "published_date": "2025-05-02 10:17:33 UTC",
    "updated_date": "2025-05-02 10:17:33 UTC"
  },
  {
    "arxiv_id": "2505.01162v1",
    "title": "On the Limitations of Steering in Language Model Alignment",
    "authors": [
      "Chebrolu Niranjan",
      "Kokil Jaidka",
      "Gerard Christopher Yeo"
    ],
    "abstract": "Steering vectors are a promising approach to aligning language model behavior\nat inference time. In this paper, we propose a framework to assess the\nlimitations of steering vectors as alignment mechanisms. Using a framework of\ntransformer hook interventions and antonym-based function vectors, we evaluate\nthe role of prompt structure and context complexity in steering effectiveness.\nOur findings indicate that steering vectors are promising for specific\nalignment tasks, such as value alignment, but may not provide a robust\nfoundation for general-purpose alignment in LLMs, particularly in complex\nscenarios. We establish a methodological foundation for future investigations\ninto steering capabilities of reasoning models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01162v1",
    "published_date": "2025-05-02 10:08:34 UTC",
    "updated_date": "2025-05-02 10:08:34 UTC"
  },
  {
    "arxiv_id": "2505.01130v1",
    "title": "Risk Analysis and Design Against Adversarial Actions",
    "authors": [
      "Marco C. Campi",
      "Algo Carè",
      "Luis G. Crespo",
      "Simone Garatti",
      "Federico A. Ramponi"
    ],
    "abstract": "Learning models capable of providing reliable predictions in the face of\nadversarial actions has become a central focus of the machine learning\ncommunity in recent years. This challenge arises from observing that data\nencountered at deployment time often deviate from the conditions under which\nthe model was trained. In this paper, we address deployment-time adversarial\nactions and propose a versatile, well-principled framework to evaluate the\nmodel's robustness against attacks of diverse types and intensities. While we\ninitially focus on Support Vector Regression (SVR), the proposed approach\nextends naturally to the broad domain of learning via relaxed optimization\ntechniques. Our results enable an assessment of the model vulnerability without\nrequiring additional test data and operate in a distribution-free setup. These\nresults not only provide a tool to enhance trust in the model's applicability\nbut also aid in selecting among competing alternatives. Later in the paper, we\nshow that our findings also offer useful insights for establishing new results\nwithin the out-of-distribution framework.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01130v1",
    "published_date": "2025-05-02 09:16:44 UTC",
    "updated_date": "2025-05-02 09:16:44 UTC"
  },
  {
    "arxiv_id": "2505.03807v1",
    "title": "Facilitating Video Story Interaction with Multi-Agent Collaborative System",
    "authors": [
      "Yiwen Zhang",
      "Jianing Hao",
      "Zhan Wang",
      "Hongling Sheng",
      "Wei Zeng"
    ],
    "abstract": "Video story interaction enables viewers to engage with and explore narrative\ncontent for personalized experiences. However, existing methods are limited to\nuser selection, specially designed narratives, and lack customization. To\naddress this, we propose an interactive system based on user intent. Our system\nuses a Vision Language Model (VLM) to enable machines to understand video\nstories, combining Retrieval-Augmented Generation (RAG) and a Multi-Agent\nSystem (MAS) to create evolving characters and scene experiences. It includes\nthree stages: 1) Video story processing, utilizing VLM and prior knowledge to\nsimulate human understanding of stories across three modalities. 2) Multi-space\nchat, creating growth-oriented characters through MAS interactions based on\nuser queries and story stages. 3) Scene customization, expanding and\nvisualizing various story scenes mentioned in dialogue. Applied to the Harry\nPotter series, our study shows the system effectively portrays emergent\ncharacter social behavior and growth, enhancing the interactive experience in\nthe video story world.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV",
      "cs.MA"
    ],
    "primary_category": "cs.HC",
    "comment": "Prepared and submitted in 2024",
    "pdf_url": "http://arxiv.org/pdf/2505.03807v1",
    "published_date": "2025-05-02 09:08:13 UTC",
    "updated_date": "2025-05-02 09:08:13 UTC"
  },
  {
    "arxiv_id": "2505.03806v1",
    "title": "Perception-Informed Neural Networks: Beyond Physics-Informed Neural Networks",
    "authors": [
      "Mehran Mazandarani",
      "Marzieh Najariyan"
    ],
    "abstract": "This article introduces Perception-Informed Neural Networks (PrINNs), a\nframework designed to incorporate perception-based information into neural\nnetworks, addressing both systems with known and unknown physics laws or\ndifferential equations. Moreover, PrINNs extend the concept of Physics-Informed\nNeural Networks (PINNs) and their variants, offering a platform for the\nintegration of diverse forms of perception precisiation, including singular,\nprobability distribution, possibility distribution, interval, and fuzzy graph.\nIn fact, PrINNs allow neural networks to model dynamical systems by integrating\nexpert knowledge and perception-based information through loss functions,\nenabling the creation of modern data-driven models. Some of the key\ncontributions include Mixture of Experts Informed Neural Networks (MOEINNs),\nwhich combine heterogeneous expert knowledge into the network, and\nTransformed-Knowledge Informed Neural Networks (TKINNs), which facilitate the\nincorporation of meta-information for enhanced model performance. Additionally,\nFuzzy-Informed Neural Networks (FINNs) as a modern class of fuzzy deep neural\nnetworks leverage fuzzy logic constraints within a deep learning architecture,\nallowing online training without pre-training and eliminating the need for\ndefuzzification. PrINNs represent a significant step forward in bridging the\ngap between traditional physics-based modeling and modern data-driven\napproaches, enabling neural networks to learn from both structured physics laws\nand flexible perception-based rules. This approach empowers neural networks to\noperate in uncertain environments, model complex systems, and discover new\nforms of differential equations, making PrINNs a powerful tool for advancing\ncomputational science and engineering.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03806v1",
    "published_date": "2025-05-02 09:08:07 UTC",
    "updated_date": "2025-05-02 09:08:07 UTC"
  },
  {
    "arxiv_id": "2505.02851v1",
    "title": "30DayGen: Leveraging LLMs to Create a Content Corpus for Habit Formation",
    "authors": [
      "Franklin Zhang",
      "Sonya Zhang",
      "Alon Halevy"
    ],
    "abstract": "In this paper, we present 30 Day Me, a habit formation application that\nleverages Large Language Models (LLMs) to help users break down their goals\ninto manageable, actionable steps and track their progress. Central to the app\nis the 30DAYGEN system, which generates 3,531 unique 30-day challenges sourced\nfrom over 15K webpages, and enables runtime search of challenge ideas aligned\nwith user-defined goals. We showcase how LLMs can be harnessed to rapidly\nconstruct domain specific content corpora for behavioral and educational\npurposes, and propose a practical pipeline that incorporates effective LLM\nenhanced approaches for content generation and semantic deduplication.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "I.2.7; H.3.1; H.3.3"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages (main content), 4 figures. Submitted to ACL BEA2025",
    "pdf_url": "http://arxiv.org/pdf/2505.02851v1",
    "published_date": "2025-05-02 08:53:27 UTC",
    "updated_date": "2025-05-02 08:53:27 UTC"
  },
  {
    "arxiv_id": "2505.03804v1",
    "title": "MoEQuant: Enhancing Quantization for Mixture-of-Experts Large Language Models via Expert-Balanced Sampling and Affinity Guidance",
    "authors": [
      "Xing Hu",
      "Zhixuan Chen",
      "Dawei Yang",
      "Zukang Xu",
      "Chen Xu",
      "Zhihang Yuan",
      "Sifan Zhou",
      "Jiangyong Yu"
    ],
    "abstract": "Mixture-of-Experts (MoE) large language models (LLMs), which leverage dynamic\nrouting and sparse activation to enhance efficiency and scalability, have\nachieved higher performance while reducing computational costs. However, these\nmodels face significant memory overheads, limiting their practical deployment\nand broader adoption. Post-training quantization (PTQ), a widely used method\nfor compressing LLMs, encounters severe accuracy degradation and diminished\ngeneralization performance when applied to MoE models. This paper investigates\nthe impact of MoE's sparse and dynamic characteristics on quantization and\nidentifies two primary challenges: (1) Inter-expert imbalance, referring to the\nuneven distribution of samples across experts, which leads to insufficient and\nbiased calibration for less frequently utilized experts; (2) Intra-expert\nimbalance, arising from MoE's unique aggregation mechanism, which leads to\nvarying degrees of correlation between different samples and their assigned\nexperts. To address these challenges, we propose MoEQuant, a novel quantization\nframework tailored for MoE LLMs. MoE-Quant includes two novel techniques: 1)\nExpert-Balanced Self-Sampling (EBSS) is an efficient sampling method that\nefficiently constructs a calibration set with balanced expert distributions by\nleveraging the cumulative probabilities of tokens and expert balance metrics as\nguiding factors. 2) Affinity-Guided Quantization (AGQ), which incorporates\naffinities between experts and samples into the quantization process, thereby\naccurately assessing the impact of individual samples on different experts\nwithin the MoE layer. Experiments demonstrate that MoEQuant achieves\nsubstantial performance gains (more than 10 points accuracy gain in the\nHumanEval for DeepSeekMoE-16B under 4-bit quantization) and boosts efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03804v1",
    "published_date": "2025-05-02 08:51:55 UTC",
    "updated_date": "2025-05-02 08:51:55 UTC"
  },
  {
    "arxiv_id": "2505.03803v1",
    "title": "RWKVQuant: Quantizing the RWKV Family with Proxy Guided Hybrid of Scalar and Vector Quantization",
    "authors": [
      "Chen Xu",
      "Yuxuan Yue",
      "Zukang Xu",
      "Xing Hu",
      "Jiangyong Yu",
      "Zhixuan Chen",
      "Sifan Zhou",
      "Zhihang Yuan",
      "Dawei Yang"
    ],
    "abstract": "RWKV is a modern RNN architecture with comparable performance to Transformer,\nbut still faces challenges when deployed to resource-constrained devices. Post\nTraining Quantization (PTQ), which is a an essential technique to reduce model\nsize and inference latency, has been widely used in Transformer models.\nHowever, it suffers significant degradation of performance when applied to\nRWKV. This paper investigates and identifies two key constraints inherent in\nthe properties of RWKV: (1) Non-linear operators hinder the parameter-fusion of\nboth smooth- and rotation-based quantization, introducing extra computation\noverhead. (2) The larger amount of uniformly distributed weights poses\nchallenges for cluster-based quantization, leading to reduced accuracy. To this\nend, we propose RWKVQuant, a PTQ framework tailored for RWKV models, consisting\nof two novel techniques: (1) a coarse-to-fine proxy capable of adaptively\nselecting different quantization approaches by assessing the uniformity and\nidentifying outliers in the weights, and (2) a codebook optimization algorithm\nthat enhances the performance of cluster-based quantization methods for\nelement-wise multiplication in RWKV. Experiments show that RWKVQuant can\nquantize RWKV-6-14B into about 3-bit with less than 1% accuracy loss and 2.14x\nspeed up.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03803v1",
    "published_date": "2025-05-02 08:47:49 UTC",
    "updated_date": "2025-05-02 08:47:49 UTC"
  },
  {
    "arxiv_id": "2505.03802v2",
    "title": "Efficient Fine-Tuning of Quantized Models via Adaptive Rank and Bitwidth",
    "authors": [
      "Changhai Zhou",
      "Yuhua Zhou",
      "Qian Qiao",
      "Weizhong Zhang",
      "Cheng Jin"
    ],
    "abstract": "QLoRA effectively combines low-bit quantization and LoRA to achieve\nmemory-friendly fine-tuning for large language models (LLM). Recently, methods\nbased on SVD for continuous update iterations to initialize LoRA matrices to\naccommodate quantization errors have generally failed to consistently improve\nperformance. Dynamic mixed precision is a natural idea for continuously\nimproving the fine-tuning performance of quantized models, but previous methods\noften optimize low-rank subspaces or quantization components separately,\nwithout considering their synergy. To address this, we propose\n\\textbf{QR-Adaptor}, a unified, gradient-free strategy that uses partial\ncalibration data to jointly search the quantization components and the rank of\nlow-rank spaces for each layer, thereby continuously improving model\nperformance. QR-Adaptor does not minimize quantization error but treats\nprecision and rank allocation as a discrete optimization problem guided by\nactual downstream performance and memory usage. Compared to state-of-the-art\n(SOTA) quantized LoRA fine-tuning methods, our approach achieves a 4.89\\%\naccuracy improvement on GSM8K, and in some cases even outperforms the 16-bit\nfine-tuned model while maintaining the memory footprint of the 4-bit setting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This preprint is being withdrawn because not all original authors are\n  continuing with the paper. Responsibility for the manuscript has been taken\n  over by a subset of the original authors, who will revise and resubmit it\n  independently. To avoid confusion regarding authorship and future versions of\n  the work, we request that this version be removed from arXiv",
    "pdf_url": "http://arxiv.org/pdf/2505.03802v2",
    "published_date": "2025-05-02 08:46:01 UTC",
    "updated_date": "2025-05-20 03:31:56 UTC"
  },
  {
    "arxiv_id": "2505.01109v1",
    "title": "Self-Supervision Enhances Instance-based Multiple Instance Learning Methods in Digital Pathology: A Benchmark Study",
    "authors": [
      "Ali Mammadov",
      "Loic Le Folgoc",
      "Julien Adam",
      "Anne Buronfosse",
      "Gilles Hayem",
      "Guillaume Hocquet",
      "Pietro Gori"
    ],
    "abstract": "Multiple Instance Learning (MIL) has emerged as the best solution for Whole\nSlide Image (WSI) classification. It consists of dividing each slide into\npatches, which are treated as a bag of instances labeled with a global label.\nMIL includes two main approaches: instance-based and embedding-based. In the\nformer, each patch is classified independently, and then the patch scores are\naggregated to predict the bag label. In the latter, bag classification is\nperformed after aggregating patch embeddings. Even if instance-based methods\nare naturally more interpretable, embedding-based MILs have usually been\npreferred in the past due to their robustness to poor feature extractors.\nHowever, recently, the quality of feature embeddings has drastically increased\nusing self-supervised learning (SSL). Nevertheless, many authors continue to\nendorse the superiority of embedding-based MIL. To investigate this further, we\nconduct 710 experiments across 4 datasets, comparing 10 MIL strategies, 6\nself-supervised methods with 4 backbones, 4 foundation models, and various\npathology-adapted techniques. Furthermore, we introduce 4 instance-based MIL\nmethods never used before in the pathology domain. Through these extensive\nexperiments, we show that with a good SSL feature extractor, simple\ninstance-based MILs, with very few parameters, obtain similar or better\nperformance than complex, state-of-the-art (SOTA) embedding-based MIL methods,\nsetting new SOTA results on the BRACS and Camelyon16 datasets. Since simple\ninstance-based MIL methods are naturally more interpretable and explainable to\nclinicians, our results suggest that more effort should be put into\nwell-adapted SSL methods for WSI rather than into complex embedding-based MIL\nmethods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for publication in the Journal of Medical Imaging (SPIE)",
    "pdf_url": "http://arxiv.org/pdf/2505.01109v1",
    "published_date": "2025-05-02 08:43:50 UTC",
    "updated_date": "2025-05-02 08:43:50 UTC"
  },
  {
    "arxiv_id": "2505.01094v1",
    "title": "Multi-Objective Reinforcement Learning for Water Management",
    "authors": [
      "Zuzanna Osika",
      "Roxana Radelescu",
      "Jazmin Zatarain Salazar",
      "Frans Oliehoek",
      "Pradeep K. Murukannaiah"
    ],
    "abstract": "Many real-world problems (e.g., resource management, autonomous driving, drug\ndiscovery) require optimizing multiple, conflicting objectives. Multi-objective\nreinforcement learning (MORL) extends classic reinforcement learning to handle\nmultiple objectives simultaneously, yielding a set of policies that capture\nvarious trade-offs. However, the MORL field lacks complex, realistic\nenvironments and benchmarks. We introduce a water resource (Nile river basin)\nmanagement case study and model it as a MORL environment. We then benchmark\nexisting MORL algorithms on this task. Our results show that specialized water\nmanagement methods outperform state-of-the-art MORL approaches, underscoring\nthe scalability challenges MORL algorithms face in real-world scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to AAMAS 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.01094v1",
    "published_date": "2025-05-02 08:14:01 UTC",
    "updated_date": "2025-05-02 08:14:01 UTC"
  },
  {
    "arxiv_id": "2505.01091v1",
    "title": "Any-to-Any Vision-Language Model for Multimodal X-ray Imaging and Radiological Report Generation",
    "authors": [
      "Daniele Molino",
      "Francesco di Feola",
      "Linlin Shen",
      "Paolo Soda",
      "Valerio Guarrasi"
    ],
    "abstract": "Generative models have revolutionized Artificial Intelligence (AI),\nparticularly in multimodal applications. However, adapting these models to the\nmedical domain poses unique challenges due to the complexity of medical data\nand the stringent need for clinical accuracy. In this work, we introduce a\nframework specifically designed for multimodal medical data generation. By\nenabling the generation of multi-view chest X-rays and their associated\nclinical report, it bridges the gap between general-purpose vision-language\nmodels and the specialized requirements of healthcare. Leveraging the MIMIC-CXR\ndataset, the proposed framework shows superior performance in generating\nhigh-fidelity images and semantically coherent reports. Our quantitative\nevaluation reveals significant results in terms of FID and BLEU scores,\nshowcasing the quality of the generated data. Notably, our framework achieves\ncomparable or even superior performance compared to real data on downstream\ndisease classification tasks, underlining its potential as a tool for medical\nresearch and diagnostics. This study highlights the importance of\ndomain-specific adaptations in enhancing the relevance and utility of\ngenerative models for clinical applications, paving the way for future\nadvancements in synthetic multimodal medical data generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2501.04614",
    "pdf_url": "http://arxiv.org/pdf/2505.01091v1",
    "published_date": "2025-05-02 08:07:24 UTC",
    "updated_date": "2025-05-02 08:07:24 UTC"
  },
  {
    "arxiv_id": "2505.03801v1",
    "title": "Large Language Model Compression with Global Rank and Sparsity Optimization",
    "authors": [
      "Changhai Zhou",
      "Qian Qiao",
      "Weizhong Zhang",
      "Cheng Jin"
    ],
    "abstract": "Low-rank and sparse composite approximation is a natural idea to compress\nLarge Language Models (LLMs). However, such an idea faces two primary\nchallenges that adversely affect the performance of existing methods. The first\nchallenge relates to the interaction and cooperation between low-rank and\nsparse matrices, while the second involves determining weight allocation across\ndifferent layers, as redundancy varies considerably among them. To address\nthese challenges, we propose a novel two-stage LLM compression method with the\ncapability of global rank and sparsity optimization. It is noteworthy that the\noverall optimization space is vast, making comprehensive optimization\ncomputationally prohibitive. Therefore, to reduce the optimization space, our\nfirst stage utilizes robust principal component analysis to decompose the\nweight matrices of LLMs into low-rank and sparse components, which span the low\ndimensional and sparse spaces containing the resultant low-rank and sparse\nmatrices, respectively. In the second stage, we propose a probabilistic global\noptimization technique to jointly identify the low-rank and sparse structures\nwithin the above two spaces. The appealing feature of our approach is its\nability to automatically detect the redundancy across different layers and to\nmanage the interaction between the sparse and low-rank components. Extensive\nexperimental results indicate that our method significantly surpasses\nstate-of-the-art techniques for sparsification and composite approximation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.03801v1",
    "published_date": "2025-05-02 08:00:48 UTC",
    "updated_date": "2025-05-02 08:00:48 UTC"
  },
  {
    "arxiv_id": "2505.01085v1",
    "title": "Artificial Intelligence in Government: Why People Feel They Lose Control",
    "authors": [
      "Alexander Wuttke",
      "Adrian Rauchfleisch",
      "Andreas Jungherr"
    ],
    "abstract": "The use of Artificial Intelligence (AI) in public administration is expanding\nrapidly, moving from automating routine tasks to deploying generative and\nagentic systems that autonomously act on goals. While AI promises greater\nefficiency and responsiveness, its integration into government functions raises\nconcerns about fairness, transparency, and accountability. This article applies\nprincipal-agent theory (PAT) to conceptualize AI adoption as a special case of\ndelegation, highlighting three core tensions: assessability (can decisions be\nunderstood?), dependency (can the delegation be reversed?), and contestability\n(can decisions be challenged?). These structural challenges may lead to a\n\"failure-by-success\" dynamic, where early functional gains obscure long-term\nrisks to democratic legitimacy. To test this framework, we conducted a\npre-registered factorial survey experiment across tax, welfare, and law\nenforcement domains. Our findings show that although efficiency gains initially\nbolster trust, they simultaneously reduce citizens' perceived control. When the\nstructural risks come to the foreground, institutional trust and perceived\ncontrol both drop sharply, suggesting that hidden costs of AI adoption\nsignificantly shape public attitudes. The study demonstrates that PAT offers a\npowerful lens for understanding the institutional and political implications of\nAI in government, emphasizing the need for policymakers to address delegation\nrisks transparently to maintain public trust.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01085v1",
    "published_date": "2025-05-02 07:46:41 UTC",
    "updated_date": "2025-05-02 07:46:41 UTC"
  },
  {
    "arxiv_id": "2505.01081v1",
    "title": "MADIL: An MDL-based Framework for Efficient Program Synthesis in the ARC Benchmark",
    "authors": [
      "Sébastien Ferré"
    ],
    "abstract": "Artificial Intelligence (AI) has achieved remarkable success in specialized\ntasks but struggles with efficient skill acquisition and generalization. The\nAbstraction and Reasoning Corpus (ARC) benchmark evaluates intelligence based\non minimal training requirements. While Large Language Models (LLMs) have\nrecently improved ARC performance, they rely on extensive pre-training and high\ncomputational costs. We introduce MADIL (MDL-based AI), a novel approach\nleveraging the Minimum Description Length (MDL) principle for efficient\ninductive learning. MADIL performs pattern-based decomposition, enabling\nstructured generalization. While its performance (7% at ArcPrize 2024) remains\nbelow LLM-based methods, it offers greater efficiency and interpretability.\nThis paper details MADIL's methodology, its application to ARC, and\nexperimental evaluations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "54 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.01081v1",
    "published_date": "2025-05-02 07:39:08 UTC",
    "updated_date": "2025-05-02 07:39:08 UTC"
  },
  {
    "arxiv_id": "2505.01073v1",
    "title": "Retrieval Augmented Learning: A Retrial-based Large Language Model Self-Supervised Learning and Autonomous Knowledge Generation",
    "authors": [
      "Zongyuan Li",
      "Pengfei Li",
      "Runnan Qi",
      "Yanan Ni",
      "Lumin Jiang",
      "Hui Wu",
      "Xuebo Zhang",
      "Kuihua Huang",
      "Xian Guo"
    ],
    "abstract": "The lack of domain-specific data in the pre-training of Large Language Models\n(LLMs) severely limits LLM-based decision systems in specialized applications,\nwhile post-training a model in the scenarios requires significant computational\nresources. In this paper, we present Retrial-Augmented Learning (RAL), a\nreward-free self-supervised learning framework for LLMs that operates without\nmodel training. By developing Retrieval-Augmented Generation (RAG) into a\nmodule for organizing intermediate data, we realized a three-stage autonomous\nknowledge generation of proposing a hypothesis, validating the hypothesis, and\ngenerating the knowledge. The method is evaluated in the LLM-PySC2 environment,\na representative decision-making platform that combines sufficient complexity\nwith domain-specific knowledge requirements. Experiments demonstrate that the\nproposed method effectively reduces hallucination by generating and utilizing\nvalidated knowledge, and increases decision-making performance at an extremely\nlow cost. Meanwhile, the approach exhibits potential in\nout-of-distribution(OOD) tasks, robustness, and transferability, making it a\ncost-friendly but effective solution for decision-making problems and\nautonomous knowledge generation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01073v1",
    "published_date": "2025-05-02 07:25:01 UTC",
    "updated_date": "2025-05-02 07:25:01 UTC"
  },
  {
    "arxiv_id": "2505.01070v1",
    "title": "Improving Group Fairness in Knowledge Distillation via Laplace Approximation of Early Exits",
    "authors": [
      "Edvin Fasth",
      "Sagar Singh"
    ],
    "abstract": "Knowledge distillation (KD) has become a powerful tool for training compact\nstudent models using larger, pretrained teacher models, often requiring less\ndata and computational resources. Teacher models typically possess more layers\nand thus exhibit richer feature representations compared to their student\ncounterparts. Furthermore, student models tend to learn simpler, surface-level\nfeatures in their early layers. This discrepancy can increase errors in groups\nwhere labels spuriously correlate with specific input attributes, leading to a\ndecline in group fairness even when overall accuracy remains comparable to the\nteacher. To mitigate these challenges, Early-Exit Neural Networks (EENNs),\nwhich enable predictions at multiple intermediate layers, have been employed.\nConfidence margins derived from these early exits have been utilized to\nreweight both cross-entropy and distillation losses on a per-instance basis. In\nthis paper, we propose that leveraging Laplace approximation-based methods to\nobtain well-calibrated uncertainty estimates can also effectively reweight\nchallenging instances and improve group fairness. We hypothesize that Laplace\napproximation offers a more robust identification of difficult or ambiguous\ninstances compared to margin-based approaches. To validate our claims, we\nbenchmark our approach using a Bert-based model on the MultiNLI dataset.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.01070v1",
    "published_date": "2025-05-02 07:18:52 UTC",
    "updated_date": "2025-05-02 07:18:52 UTC"
  },
  {
    "arxiv_id": "2505.01068v1",
    "title": "Multimodal Transformers are Hierarchical Modal-wise Heterogeneous Graphs",
    "authors": [
      "Yijie Jin",
      "Junjie Peng",
      "Xuanchao Lin",
      "Haochen Yuan",
      "Lan Wang",
      "Cangzhi Zheng"
    ],
    "abstract": "Multimodal Sentiment Analysis (MSA) is a rapidly developing field that\nintegrates multimodal information to recognize sentiments, and existing models\nhave made significant progress in this area. The central challenge in MSA is\nmultimodal fusion, which is predominantly addressed by Multimodal Transformers\n(MulTs). Although act as the paradigm, MulTs suffer from efficiency concerns.\nIn this work, from the perspective of efficiency optimization, we propose and\nprove that MulTs are hierarchical modal-wise heterogeneous graphs (HMHGs), and\nwe introduce the graph-structured representation pattern of MulTs. Based on\nthis pattern, we propose an Interlaced Mask (IM) mechanism to design the\nGraph-Structured and Interlaced-Masked Multimodal Transformer (GsiT). It is\nformally equivalent to MulTs which achieves an efficient weight-sharing\nmechanism without information disorder through IM, enabling All-Modal-In-One\nfusion with only 1/3 of the parameters of pure MulTs. A Triton kernel called\nDecomposition is implemented to ensure avoiding additional computational\noverhead. Moreover, it achieves significantly higher performance than\ntraditional MulTs. To further validate the effectiveness of GsiT itself and the\nHMHG concept, we integrate them into multiple state-of-the-art models and\ndemonstrate notable performance improvements and parameter reduction on widely\nused MSA datasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01068v1",
    "published_date": "2025-05-02 07:18:00 UTC",
    "updated_date": "2025-05-02 07:18:00 UTC"
  },
  {
    "arxiv_id": "2505.01067v1",
    "title": "A Rusty Link in the AI Supply Chain: Detecting Evil Configurations in Model Repositories",
    "authors": [
      "Ziqi Ding",
      "Qian Fu",
      "Junchen Ding",
      "Gelei Deng",
      "Yi Liu",
      "Yuekang Li"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have spurred the\ndevelopment of diverse AI applications from code generation and video editing\nto text generation; however, AI supply chains such as Hugging Face, which host\npretrained models and their associated configuration files contributed by the\npublic, face significant security challenges; in particular, configuration\nfiles originally intended to set up models by specifying parameters and initial\nsettings can be exploited to execute unauthorized code, yet research has\nlargely overlooked their security compared to that of the models themselves; in\nthis work, we present the first comprehensive study of malicious configurations\non Hugging Face, identifying three attack scenarios (file, website, and\nrepository operations) that expose inherent risks; to address these threats, we\nintroduce CONFIGSCAN, an LLM-based tool that analyzes configuration files in\nthe context of their associated runtime code and critical libraries,\neffectively detecting suspicious elements with low false positive rates and\nhigh accuracy; our extensive evaluation uncovers thousands of suspicious\nrepositories and configuration files, underscoring the urgent need for enhanced\nsecurity validation in AI model hosting platforms.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01067v1",
    "published_date": "2025-05-02 07:16:20 UTC",
    "updated_date": "2025-05-02 07:16:20 UTC"
  },
  {
    "arxiv_id": "2505.01065v1",
    "title": "Good News for Script Kiddies? Evaluating Large Language Models for Automated Exploit Generation",
    "authors": [
      "David Jin",
      "Qian Fu",
      "Yuekang Li"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncode-related tasks, raising concerns about their potential for automated\nexploit generation (AEG). This paper presents the first systematic study on\nLLMs' effectiveness in AEG, evaluating both their cooperativeness and technical\nproficiency. To mitigate dataset bias, we introduce a benchmark with refactored\nversions of five software security labs. Additionally, we design an LLM-based\nattacker to systematically prompt LLMs for exploit generation. Our experiments\nreveal that GPT-4 and GPT-4o exhibit high cooperativeness, comparable to\nuncensored models, while Llama3 is the most resistant. However, no model\nsuccessfully generates exploits for refactored labs, though GPT-4o's minimal\nerrors highlight the potential for LLM-driven AEG advancements.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01065v1",
    "published_date": "2025-05-02 07:15:22 UTC",
    "updated_date": "2025-05-02 07:15:22 UTC"
  },
  {
    "arxiv_id": "2505.03800v1",
    "title": "Design description of Wisdom Computing Persperctive",
    "authors": [
      "TianYi Yu"
    ],
    "abstract": "This course design aims to develop and research a handwriting matrix\nrecognition and step-by-step visual calculation process display system,\naddressing the issue of abstract formulas and complex calculation steps that\nstudents find difficult to understand when learning mathematics. By integrating\nartificial intelligence with visualization animation technology, the system\nenhances precise recognition of handwritten matrix content through the\nintroduction of Mamba backbone networks, completes digital extraction and\nmatrix reconstruction using the YOLO model, and simultaneously combines\nCoordAttention coordinate attention mechanisms to improve the accurate grasp of\ncharacter spatial positions. The calculation process is demonstrated frame by\nframe through the Manim animation engine, vividly showcasing each mathematical\ncalculation step, helping students intuitively understand the intrinsic logic\nof mathematical operations. Through dynamically generating animation processes\nfor different computational tasks, the system exhibits high modularity and\nflexibility, capable of generating various mathematical operation examples in\nreal-time according to student needs. By innovating human-computer interaction\nmethods, it brings mathematical calculation processes to life, helping students\nbridge the gap between knowledge and understanding on a deeper level,\nultimately achieving a learning experience where \"every step is understood.\"\nThe system's scalability and interactivity make it an intuitive, user-friendly,\nand efficient auxiliary tool in education.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03800v1",
    "published_date": "2025-05-02 07:12:10 UTC",
    "updated_date": "2025-05-02 07:12:10 UTC"
  },
  {
    "arxiv_id": "2505.01059v1",
    "title": "Model Tensor Planning",
    "authors": [
      "An T. Le",
      "Khai Nguyen",
      "Minh Nhat Vu",
      "João Carvalho",
      "Jan Peters"
    ],
    "abstract": "Sampling-based model predictive control (MPC) offers strong performance in\nnonlinear and contact-rich robotic tasks, yet often suffers from poor\nexploration due to locally greedy sampling schemes. We propose \\emph{Model\nTensor Planning} (MTP), a novel sampling-based MPC framework that introduces\nhigh-entropy control trajectory generation through structured tensor sampling.\nBy sampling over randomized multipartite graphs and interpolating control\ntrajectories with B-splines and Akima splines, MTP ensures smooth and globally\ndiverse control candidates. We further propose a simple $\\beta$-mixing strategy\nthat blends local exploitative and global exploratory samples within the\nmodified Cross-Entropy Method (CEM) update, balancing control refinement and\nexploration. Theoretically, we show that MTP achieves asymptotic path coverage\nand maximum entropy in the control trajectory space in the limit of infinite\ntensor depth and width.\n  Our implementation is fully vectorized using JAX and compatible with MuJoCo\nXLA, supporting \\emph{Just-in-time} (JIT) compilation and batched rollouts for\nreal-time control with online domain randomization. Through experiments on\nvarious challenging robotic tasks, ranging from dexterous in-hand manipulation\nto humanoid locomotion, we demonstrate that MTP outperforms standard MPC and\nevolutionary strategy baselines in task success and control robustness. Design\nand sensitivity ablations confirm the effectiveness of MTP tensor sampling\nstructure, spline interpolation choices, and mixing strategy. Altogether, MTP\noffers a scalable framework for robust exploration in model-based planning and\ncontrol.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "22 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.01059v1",
    "published_date": "2025-05-02 07:09:38 UTC",
    "updated_date": "2025-05-02 07:09:38 UTC"
  },
  {
    "arxiv_id": "2505.02850v1",
    "title": "Harnessing Structured Knowledge: A Concept Map-Based Approach for High-Quality Multiple Choice Question Generation with Effective Distractors",
    "authors": [
      "Nicy Scaria",
      "Silvester John Joseph Kennedy",
      "Diksha Seth",
      "Ananya Thakur",
      "Deepak Subramani"
    ],
    "abstract": "Generating high-quality MCQs, especially those targeting diverse cognitive\nlevels and incorporating common misconceptions into distractor design, is\ntime-consuming and expertise-intensive, making manual creation impractical at\nscale. Current automated approaches typically generate questions at lower\ncognitive levels and fail to incorporate domain-specific misconceptions. This\npaper presents a hierarchical concept map-based framework that provides\nstructured knowledge to guide LLMs in generating MCQs with distractors. We\nchose high-school physics as our test domain and began by developing a\nhierarchical concept map covering major Physics topics and their\ninterconnections with an efficient database design. Next, through an automated\npipeline, topic-relevant sections of these concept maps are retrieved to serve\nas a structured context for the LLM to generate questions and distractors that\nspecifically target common misconceptions. Lastly, an automated validation is\ncompleted to ensure that the generated MCQs meet the requirements provided. We\nevaluate our framework against two baseline approaches: a base LLM and a\nRAG-based generation. We conducted expert evaluations and student assessments\nof the generated MCQs. Expert evaluation shows that our method significantly\noutperforms the baseline approaches, achieving a success rate of 75.20% in\nmeeting all quality criteria compared to approximately 37% for both baseline\nmethods. Student assessment data reveal that our concept map-driven approach\nachieved a significantly lower guess success rate of 28.05% compared to 37.10%\nfor the baselines, indicating a more effective assessment of conceptual\nunderstanding. The results demonstrate that our concept map-based approach\nenables robust assessment across cognitive levels and instant identification of\nconceptual gaps, facilitating faster feedback loops and targeted interventions\nat scale.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02850v1",
    "published_date": "2025-05-02 06:36:06 UTC",
    "updated_date": "2025-05-02 06:36:06 UTC"
  },
  {
    "arxiv_id": "2505.01043v1",
    "title": "Low-Precision Training of Large Language Models: Methods, Challenges, and Opportunities",
    "authors": [
      "Zhiwei Hao",
      "Jianyuan Guo",
      "Li Shen",
      "Yong Luo",
      "Han Hu",
      "Guoxia Wang",
      "Dianhai Yu",
      "Yonggang Wen",
      "Dacheng Tao"
    ],
    "abstract": "Large language models (LLMs) have achieved impressive performance across\nvarious domains. However, the substantial hardware resources required for their\ntraining present a significant barrier to efficiency and scalability. To\nmitigate this challenge, low-precision training techniques have been widely\nadopted, leading to notable advancements in training efficiency. Despite these\ngains, low-precision training involves several components$\\unicode{x2013}$such\nas weights, activations, and gradients$\\unicode{x2013}$each of which can be\nrepresented in different numerical formats. The resulting diversity has created\na fragmented landscape in low-precision training research, making it difficult\nfor researchers to gain a unified overview of the field. This survey provides a\ncomprehensive review of existing low-precision training methods. To\nsystematically organize these approaches, we categorize them into three primary\ngroups based on their underlying numerical formats, which is a key factor\ninfluencing hardware compatibility, computational efficiency, and ease of\nreference for readers. The categories are: (1) fixed-point and integer-based\nmethods, (2) floating-point-based methods, and (3) customized format-based\nmethods. Additionally, we discuss quantization-aware training approaches, which\nshare key similarities with low-precision training during forward propagation.\nFinally, we highlight several promising research directions to advance this\nfield. A collection of papers discussed in this survey is provided in\nhttps://github.com/Hao840/Awesome-Low-Precision-Training.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01043v1",
    "published_date": "2025-05-02 06:33:25 UTC",
    "updated_date": "2025-05-02 06:33:25 UTC"
  },
  {
    "arxiv_id": "2505.01036v1",
    "title": "Stagnation in Evolutionary Algorithms: Convergence $\\neq$ Optimality",
    "authors": [
      "Xiaojun Zhou"
    ],
    "abstract": "In the evolutionary computation community, it is widely believed that\nstagnation impedes convergence in evolutionary algorithms, and that convergence\ninherently indicates optimality. However, this perspective is misleading. In\nthis study, it is the first to highlight that the stagnation of an individual\ncan actually facilitate the convergence of the entire population, and\nconvergence does not necessarily imply optimality, not even local optimality.\nConvergence alone is insufficient to ensure the effectiveness of evolutionary\nalgorithms. Several counterexamples are provided to illustrate this argument.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01036v1",
    "published_date": "2025-05-02 06:19:09 UTC",
    "updated_date": "2025-05-02 06:19:09 UTC"
  },
  {
    "arxiv_id": "2505.03799v1",
    "title": "Scalability Matters: Overcoming Challenges in InstructGLM with Similarity-Degree-Based Sampling",
    "authors": [
      "Hyun Lee",
      "Chris Yi",
      "Maminur Islam",
      "B. D. S. Aritra"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities in various\nnatural language processing tasks; however, their application to graph-related\nproblems remains limited, primarily due to scalability constraints and the\nabsence of dedicated mechanisms for processing graph structures. Existing\napproaches predominantly integrate LLMs with Graph Neural Networks (GNNs),\nusing GNNs as feature encoders or auxiliary components. However, directly\nencoding graph structures within LLMs has been underexplored, particularly in\nthe context of large-scale graphs where token limitations hinder effective\nrepresentation. To address these challenges, we propose SDM-InstructGLM, a\nnovel instruction-tuned Graph Language Model (InstructGLM) framework that\nenhances scalability and efficiency without relying on GNNs. Our method\nintroduces a similarity-degree-based biased random walk mechanism, which\nselectively samples and encodes graph information based on node-feature\nsimilarity and degree centrality, ensuring an adaptive and structured\nrepresentation within the LLM. This approach significantly improves token\nefficiency, mitigates information loss due to random sampling, and enhances\nperformance on graph-based tasks such as node classification and link\nprediction. Furthermore, our results demonstrate the feasibility of LLM-only\ngraph processing, enabling scalable and interpretable Graph Language Models\n(GLMs) optimized through instruction-based fine-tuning. This work paves the way\nfor GNN-free approaches to graph learning, leveraging LLMs as standalone graph\nreasoning models. Our source code is available on GitHub.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "To be published in International Joint Conference on Neural Networks\n  (IJCNN), 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.03799v1",
    "published_date": "2025-05-02 06:08:21 UTC",
    "updated_date": "2025-05-02 06:08:21 UTC"
  },
  {
    "arxiv_id": "2505.01468v1",
    "title": "One Search Fits All: Pareto-Optimal Eco-Friendly Model Selection",
    "authors": [
      "Filippo Betello",
      "Antonio Purificato",
      "Vittoria Vineis",
      "Gabriele Tolomei",
      "Fabrizio Silvestri"
    ],
    "abstract": "The environmental impact of Artificial Intelligence (AI) is emerging as a\nsignificant global concern, particularly regarding model training. In this\npaper, we introduce GREEN (Guided Recommendations of Energy-Efficient\nNetworks), a novel, inference-time approach for recommending Pareto-optimal AI\nmodel configurations that optimize validation performance and energy\nconsumption across diverse AI domains and tasks. Our approach directly\naddresses the limitations of current eco-efficient neural architecture search\nmethods, which are often restricted to specific architectures or tasks. Central\nto this work is EcoTaskSet, a dataset comprising training dynamics from over\n1767 experiments across computer vision, natural language processing, and\nrecommendation systems using both widely used and cutting-edge architectures.\nLeveraging this dataset and a prediction model, our approach demonstrates\neffectiveness in selecting the best model configuration based on user\npreferences. Experimental results show that our method successfully identifies\nenergy-efficient configurations while ensuring competitive performance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, 11 tables, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.01468v1",
    "published_date": "2025-05-02 05:59:21 UTC",
    "updated_date": "2025-05-02 05:59:21 UTC"
  },
  {
    "arxiv_id": "2505.01028v1",
    "title": "Adaptive Wizard for Removing Cross-Tier Misconfigurations in Active Directory",
    "authors": [
      "Huy Q. Ngo",
      "Mingyu Guo",
      "Hung Nguyen"
    ],
    "abstract": "Security vulnerabilities in Windows Active Directory (AD) systems are\ntypically modeled using an attack graph and hardening AD systems involves an\niterative workflow: security teams propose an edge to remove, and IT operations\nteams manually review these fixes before implementing the removal. As\nverification requires significant manual effort, we formulate an Adaptive Path\nRemoval Problem to minimize the number of steps in this iterative removal\nprocess. In our model, a wizard proposes an attack path in each step and\npresents it as a set of multiple-choice options to the IT admin. The IT admin\nthen selects one edge from the proposed set to remove. This process continues\nuntil the target $t$ is disconnected from source $s$ or the number of proposed\npaths reaches $B$. The model aims to optimize the human effort by minimizing\nthe expected number of interactions between the IT admin and the security\nwizard. We first prove that the problem is $\\mathcal{\\#P}$-hard. We then\npropose a set of solutions including an exact algorithm, an approximate\nalgorithm, and several scalable heuristics. Our best heuristic, called DPR, can\noperate effectively on larger-scale graphs compared to the exact algorithm and\nconsistently outperforms the approximate algorithm across all graphs. We verify\nthe effectiveness of our algorithms on several synthetic AD graphs and an AD\nattack graph collected from a real organization.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "To be appear in IJCAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.01028v1",
    "published_date": "2025-05-02 05:55:56 UTC",
    "updated_date": "2025-05-02 05:55:56 UTC"
  },
  {
    "arxiv_id": "2505.01016v1",
    "title": "Fine-Tuning Without Forgetting: Adaptation of YOLOv8 Preserves COCO Performance",
    "authors": [
      "Vishal Gandhi",
      "Sagar Gandhi"
    ],
    "abstract": "The success of large pre-trained object detectors hinges on their\nadaptability to diverse downstream tasks. While fine-tuning is the standard\nadaptation method, specializing these models for challenging fine-grained\ndomains necessitates careful consideration of feature granularity. The critical\nquestion remains: how deeply should the pre-trained backbone be fine-tuned to\noptimize for the specialized task without incurring catastrophic forgetting of\nthe original general capabilities? Addressing this, we present a systematic\nempirical study evaluating the impact of fine-tuning depth. We adapt a standard\nYOLOv8n model to a custom, fine-grained fruit detection dataset by\nprogressively unfreezing backbone layers (freeze points at layers 22, 15, and\n10) and training. Performance was rigorously evaluated on both the target fruit\ndataset and, using a dual-head evaluation architecture, on the original COCO\nvalidation set. Our results demonstrate unequivocally that deeper fine-tuning\n(unfreezing down to layer 10) yields substantial performance gains (e.g., +10\\%\nabsolute mAP50) on the fine-grained fruit task compared to only training the\nhead. Strikingly, this significant adaptation and specialization resulted in\nnegligible performance degradation (<0.1\\% absolute mAP difference) on the COCO\nbenchmark across all tested freeze levels. We conclude that adapting\nmid-to-late backbone features is highly effective for fine-grained\nspecialization. Critically, our results demonstrate this adaptation can be\nachieved without the commonly expected penalty of catastrophic forgetting,\npresenting a compelling case for exploring deeper fine-tuning strategies,\nparticularly when targeting complex domains or when maximizing specialized\nperformance is paramount.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01016v1",
    "published_date": "2025-05-02 05:27:14 UTC",
    "updated_date": "2025-05-02 05:27:14 UTC"
  },
  {
    "arxiv_id": "2505.01015v1",
    "title": "Value Portrait: Understanding Values of LLMs with Human-aligned Benchmark",
    "authors": [
      "Jongwook Han",
      "Dongmin Choi",
      "Woojung Song",
      "Eun-Ju Lee",
      "Yohan Jo"
    ],
    "abstract": "The importance of benchmarks for assessing the values of language models has\nbeen pronounced due to the growing need of more authentic, human-aligned\nresponses. However, existing benchmarks rely on human or machine annotations\nthat are vulnerable to value-related biases. Furthermore, the tested scenarios\noften diverge from real-world contexts in which models are commonly used to\ngenerate text and express values. To address these issues, we propose the Value\nPortrait benchmark, a reliable framework for evaluating LLMs' value\norientations with two key characteristics. First, the benchmark consists of\nitems that capture real-life user-LLM interactions, enhancing the relevance of\nassessment results to real-world LLM usage and thus ecological validity.\nSecond, each item is rated by human subjects based on its similarity to their\nown thoughts, and correlations between these ratings and the subjects' actual\nvalue scores are derived. This psychometrically validated approach ensures that\nitems strongly correlated with specific values serve as reliable items for\nassessing those values. Through evaluating 27 LLMs with our benchmark, we find\nthat these models prioritize Benevolence, Security, and Self-Direction values\nwhile placing less emphasis on Tradition, Power, and Achievement values. Also,\nour analysis reveals biases in how LLMs perceive various demographic groups,\ndeviating from real human data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "32 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.01015v1",
    "published_date": "2025-05-02 05:26:50 UTC",
    "updated_date": "2025-05-02 05:26:50 UTC"
  },
  {
    "arxiv_id": "2505.01009v1",
    "title": "Improving Large Language Model Planning with Action Sequence Similarity",
    "authors": [
      "Xinran Zhao",
      "Hanie Sedghi",
      "Bernd Bohnet",
      "Dale Schuurmans",
      "Azade Nova"
    ],
    "abstract": "Planning is essential for artificial intelligence systems to look ahead and\nproactively determine a course of actions to reach objectives in the virtual\nand real world. Recent work on large language models (LLMs) sheds light on\ntheir planning capability in various tasks. However, it remains unclear what\nsignals in the context influence the model performance. In this work, we\nexplore how to improve the model planning capability through in-context\nlearning (ICL), specifically, what signals can help select the exemplars.\nThrough extensive experiments, we observe that commonly used problem similarity\nmay result in false positives with drastically different plans, which can\nmislead the model. In response, we propose to sample and filter exemplars\nleveraging plan side action sequence similarity (AS). We propose GRASE-DC: a\ntwo-stage pipeline that first re-samples high AS exemplars and then curates the\nselected exemplars with dynamic clustering on AS to achieve a balance of\nrelevance and diversity. Our experimental result confirms that GRASE-DC\nachieves significant performance improvement on various planning tasks (up to\n~11-40 point absolute accuracy improvement with 27.3% fewer exemplars needed on\naverage). With GRASE-DC* + VAL, where we iteratively apply GRASE-DC with a\nvalidator, we are able to even boost the performance by 18.9% more.\n  Extensive analysis validates the consistent performance improvement of\nGRASE-DC with various backbone LLMs and on both classical planning and natural\nlanguage planning benchmarks. GRASE-DC can further boost the planning accuracy\nby ~24 absolute points on harder problems using simpler problems as exemplars\nover a random baseline. This demonstrates its ability to generalize to\nout-of-distribution problems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.01009v1",
    "published_date": "2025-05-02 05:16:17 UTC",
    "updated_date": "2025-05-02 05:16:17 UTC"
  },
  {
    "arxiv_id": "2505.01007v1",
    "title": "Towards the Resistance of Neural Network Watermarking to Fine-tuning",
    "authors": [
      "Ling Tang",
      "Yuefeng Chen",
      "Hui Xue",
      "Quanshi Zhang"
    ],
    "abstract": "This paper proves a new watermarking method to embed the ownership\ninformation into a deep neural network (DNN), which is robust to fine-tuning.\nSpecifically, we prove that when the input feature of a convolutional layer\nonly contains low-frequency components, specific frequency components of the\nconvolutional filter will not be changed by gradient descent during the\nfine-tuning process, where we propose a revised Fourier transform to extract\nfrequency components from the convolutional filter. Additionally, we also prove\nthat these frequency components are equivariant to weight scaling and weight\npermutations. In this way, we design a watermark module to encode the watermark\ninformation to specific frequency components in a convolutional filter.\nPreliminary experiments demonstrate the effectiveness of our method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01007v1",
    "published_date": "2025-05-02 05:11:17 UTC",
    "updated_date": "2025-05-02 05:11:17 UTC"
  },
  {
    "arxiv_id": "2505.06256v1",
    "title": "SpectrumFM: A Foundation Model for Intelligent Spectrum Management",
    "authors": [
      "Fuhui Zhou",
      "Chunyu Liu",
      "Hao Zhang",
      "Wei Wu",
      "Qihui Wu",
      "Derrick Wing Kwan Ng",
      "Tony Q. S. Quek",
      "Chan-Byoung Chae"
    ],
    "abstract": "Intelligent spectrum management is crucial for improving spectrum efficiency\nand achieving secure utilization of spectrum resources. However, existing\nintelligent spectrum management methods, typically based on small-scale models,\nsuffer from notable limitations in recognition accuracy, convergence speed, and\ngeneralization, particularly in the complex and dynamic spectrum environments.\nTo address these challenges, this paper proposes a novel spectrum foundation\nmodel, termed SpectrumFM, establishing a new paradigm for spectrum management.\nSpectrumFM features an innovative encoder architecture that synergistically\nexploits the convolutional neural networks and the multi-head self-attention\nmechanisms to enhance feature extraction and enable robust representation\nlearning. The model is pre-trained via two novel self-supervised learning\ntasks, namely masked reconstruction and next-slot signal prediction, which\nleverage large-scale in-phase and quadrature (IQ) data to achieve comprehensive\nand transferable spectrum representations. Furthermore, a parameter-efficient\nfine-tuning strategy is proposed to enable SpectrumFM to adapt to various\ndownstream spectrum management tasks, including automatic modulation\nclassification (AMC), wireless technology classification (WTC), spectrum\nsensing (SS), and anomaly detection (AD). Extensive experiments demonstrate\nthat SpectrumFM achieves superior performance in terms of accuracy, robustness,\nadaptability, few-shot learning efficiency, and convergence speed, consistently\noutperforming conventional methods across multiple benchmarks. Specifically,\nSpectrumFM improves AMC accuracy by up to 12.1% and WTC accuracy by 9.3%,\nachieves an area under the curve (AUC) of 0.97 in SS at -4 dB signal-to-noise\nratio (SNR), and enhances AD performance by over 10%.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06256v1",
    "published_date": "2025-05-02 04:06:39 UTC",
    "updated_date": "2025-05-02 04:06:39 UTC"
  },
  {
    "arxiv_id": "2505.00983v1",
    "title": "Toward Data-centric Directed Graph Learning: An Entropy-driven Approach",
    "authors": [
      "Xunkai Li",
      "Zhengyu Wu",
      "Kaichi Yu",
      "Hongchao Qin",
      "Guang Zeng",
      "Rong-Hua Li",
      "Guoren Wang"
    ],
    "abstract": "The directed graph (digraph), as a generalization of undirected graphs,\nexhibits superior representation capability in modeling complex topology\nsystems and has garnered considerable attention in recent years. Despite the\nnotable efforts made by existing DiGraph Neural Networks (DiGNNs) to leverage\ndirected edges, they still fail to comprehensively delve into the abundant data\nknowledge concealed in the digraphs. This data-level limitation results in\nmodel-level sub-optimal predictive performance and underscores the necessity of\nfurther exploring the potential correlations between the directed edges\n(topology) and node profiles (feature and labels) from a data-centric\nperspective, thereby empowering model-centric neural networks with stronger\nencoding capabilities.\n  In this paper, we propose \\textbf{E}ntropy-driven \\textbf{D}igraph\nknowl\\textbf{E}dge distillatio\\textbf{N} (EDEN), which can serve as a\ndata-centric digraph learning paradigm or a model-agnostic hot-and-plug\ndata-centric Knowledge Distillation (KD) module. The core idea is to achieve\ndata-centric ML, guided by our proposed hierarchical encoding theory for\nstructured data. Specifically, EDEN first utilizes directed structural\nmeasurements from a topology perspective to construct a coarse-grained\nHierarchical Knowledge Tree (HKT). Subsequently, EDEN quantifies the mutual\ninformation of node profiles to refine knowledge flow in the HKT, enabling\ndata-centric KD supervision within model training. As a general framework, EDEN\ncan also naturally extend to undirected scenarios and demonstrate satisfactory\nperformance. In our experiments, EDEN has been widely evaluated on 14 (di)graph\ndatasets (homophily and heterophily) and across 4 downstream tasks. The results\ndemonstrate that EDEN attains SOTA performance and exhibits strong improvement\nfor prevalent (Di)GNNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.00983v1",
    "published_date": "2025-05-02 04:06:00 UTC",
    "updated_date": "2025-05-02 04:06:00 UTC"
  },
  {
    "arxiv_id": "2505.00979v2",
    "title": "Synthesize-on-Graph: Knowledgeable Synthetic Data Generation for Continue Pre-training of Large Language Models",
    "authors": [
      "Xuhui Jiang",
      "Shengjie Ma",
      "Chengjin Xu",
      "Cehao Yang",
      "Liyu Zhang",
      "Jian Guo"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable success but remain\ndata-inefficient, especially when learning from small, specialized corpora with\nlimited and proprietary data. Existing synthetic data generation methods for\ncontinue pre-training focus on intra-document content and overlook\ncross-document knowledge associations, limiting content diversity and depth. We\npropose Synthetic-on-Graph (SoG), a synthetic data generation framework that\nincorporates cross-document knowledge associations for efficient corpus\nexpansion. SoG constructs a context graph by extracting entities and concepts\nfrom the original corpus, representing cross-document associations, and\nemploying a graph walk strategy for knowledge-associated sampling. This\nenhances synthetic data diversity and coherence, enabling models to learn\ncomplex knowledge structures and handle rare knowledge. To further improve\nsynthetic data quality, we integrate Chain-of-Thought (CoT) and Contrastive\nClarifying (CC) synthetic, enhancing reasoning processes and discriminative\npower. Experiments show that SoG outperforms the state-of-the-art (SOTA) method\nin a multi-hop document Q&A dataset while performing comparably to the SOTA\nmethod on the reading comprehension task datasets, which also underscores the\nbetter generalization capability of SoG. Our work advances synthetic data\ngeneration and provides practical solutions for efficient knowledge acquisition\nin LLMs, especially in domains with limited data availability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00979v2",
    "published_date": "2025-05-02 03:40:39 UTC",
    "updated_date": "2025-05-19 02:26:31 UTC"
  },
  {
    "arxiv_id": "2505.00976v1",
    "title": "Attack and defense techniques in large language models: A survey and new perspectives",
    "authors": [
      "Zhiyu Liao",
      "Kang Chen",
      "Yuanguo Lin",
      "Kangkang Li",
      "Yunxuan Liu",
      "Hefeng Chen",
      "Xingwang Huang",
      "Yuanhui Yu"
    ],
    "abstract": "Large Language Models (LLMs) have become central to numerous natural language\nprocessing tasks, but their vulnerabilities present significant security and\nethical challenges. This systematic survey explores the evolving landscape of\nattack and defense techniques in LLMs. We classify attacks into adversarial\nprompt attack, optimized attacks, model theft, as well as attacks on\napplication of LLMs, detailing their mechanisms and implications. Consequently,\nwe analyze defense strategies, including prevention-based and detection-based\ndefense methods. Although advances have been made, challenges remain to adapt\nto the dynamic threat landscape, balance usability with robustness, and address\nresource constraints in defense implementation. We highlight open problems,\nincluding the need for adaptive scalable defenses, explainable security\ntechniques, and standardized evaluation frameworks. This survey provides\nactionable insights and directions for developing secure and resilient LLMs,\nemphasizing the importance of interdisciplinary collaboration and ethical\nconsiderations to mitigate risks in real-world applications.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00976v1",
    "published_date": "2025-05-02 03:37:52 UTC",
    "updated_date": "2025-05-02 03:37:52 UTC"
  },
  {
    "arxiv_id": "2505.00972v1",
    "title": "Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models",
    "authors": [
      "Yuewen Mei",
      "Tong Nie",
      "Jian Sun",
      "Ye Tian"
    ],
    "abstract": "Simulation-based testing is crucial for validating autonomous vehicles (AVs),\nyet existing scenario generation methods either overfit to common driving\npatterns or operate in an offline, non-interactive manner that fails to expose\nrare, safety-critical corner cases. In this paper, we introduce an online,\nretrieval-augmented large language model (LLM) framework for generating\nsafety-critical driving scenarios. Our method first employs an LLM-based\nbehavior analyzer to infer the most dangerous intent of the background vehicle\nfrom the observed state, then queries additional LLM agents to synthesize\nfeasible adversarial trajectories. To mitigate catastrophic forgetting and\naccelerate adaptation, we augment the framework with a dynamic memorization and\nretrieval bank of intent-planner pairs, automatically expanding its behavioral\nlibrary when novel intents arise. Evaluations using the Waymo Open Motion\nDataset demonstrate that our model reduces the mean minimum time-to-collision\nfrom 1.62 to 1.08 s and incurs a 75% collision rate, substantially\noutperforming baselines.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00972v1",
    "published_date": "2025-05-02 03:22:00 UTC",
    "updated_date": "2025-05-02 03:22:00 UTC"
  },
  {
    "arxiv_id": "2505.00968v1",
    "title": "Tree-Sliced Wasserstein Distance with Nonlinear Projection",
    "authors": [
      "Thanh Tran",
      "Viet-Hoang Tran",
      "Thanh Chu",
      "Trang Pham",
      "Laurent El Ghaoui",
      "Tam Le",
      "Tan M. Nguyen"
    ],
    "abstract": "Tree-Sliced methods have recently emerged as an alternative to the\ntraditional Sliced Wasserstein (SW) distance, replacing one-dimensional lines\nwith tree-based metric spaces and incorporating a splitting mechanism for\nprojecting measures. This approach enhances the ability to capture the\ntopological structures of integration domains in Sliced Optimal Transport while\nmaintaining low computational costs. Building on this foundation, we propose a\nnovel nonlinear projectional framework for the Tree-Sliced Wasserstein (TSW)\ndistance, substituting the linear projections in earlier versions with general\nprojections, while ensuring the injectivity of the associated Radon Transform\nand preserving the well-definedness of the resulting metric. By designing\nappropriate projections, we construct efficient metrics for measures on both\nEuclidean spaces and spheres. Finally, we validate our proposed metric through\nextensive numerical experiments for Euclidean and spherical datasets.\nApplications include gradient flows, self-supervised learning, and generative\nmodels, where our methods demonstrate significant improvements over recent SW\nand TSW variants.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.00968v1",
    "published_date": "2025-05-02 03:06:25 UTC",
    "updated_date": "2025-05-02 03:06:25 UTC"
  },
  {
    "arxiv_id": "2505.02849v1",
    "title": "Enhancing tutoring systems by leveraging tailored promptings and domain knowledge with Large Language Models",
    "authors": [
      "Mohsen Balavar",
      "Wenli Yang",
      "David Herbert",
      "Soonja Yeom"
    ],
    "abstract": "Recent advancements in artificial intelligence (AI) and machine learning have\nreignited interest in their impact on Computer-based Learning (CBL). AI-driven\ntools like ChatGPT and Intelligent Tutoring Systems (ITS) have enhanced\nlearning experiences through personalisation and flexibility. ITSs can adapt to\nindividual learning needs and provide customised feedback based on a student's\nperformance, cognitive state, and learning path. Despite these advances,\nchallenges remain in accommodating diverse learning styles and delivering\nreal-time, context-aware feedback. Our research aims to address these gaps by\nintegrating skill-aligned feedback via Retrieval Augmented Generation (RAG)\ninto prompt engineering for Large Language Models (LLMs) and developing an\napplication to enhance learning through personalised tutoring in a computer\nscience programming context. The pilot study evaluated a proposed system using\nthree quantitative metrics: readability score, response time, and feedback\ndepth, across three programming tasks of varying complexity. The system\nsuccessfully sorted simulated students into three skill-level categories and\nprovided context-aware feedback. This targeted approach demonstrated better\neffectiveness and adaptability compared to general methods.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02849v1",
    "published_date": "2025-05-02 02:30:39 UTC",
    "updated_date": "2025-05-02 02:30:39 UTC"
  },
  {
    "arxiv_id": "2505.00949v3",
    "title": "Llama-Nemotron: Efficient Reasoning Models",
    "authors": [
      "Akhiad Bercovich",
      "Itay Levy",
      "Izik Golan",
      "Mohammad Dabbah",
      "Ran El-Yaniv",
      "Omri Puny",
      "Ido Galil",
      "Zach Moshe",
      "Tomer Ronen",
      "Najeeb Nabwani",
      "Ido Shahaf",
      "Oren Tropp",
      "Ehud Karpas",
      "Ran Zilberstein",
      "Jiaqi Zeng",
      "Soumye Singhal",
      "Alexander Bukharin",
      "Yian Zhang",
      "Tugrul Konuk",
      "Gerald Shen",
      "Ameya Sunil Mahabaleshwarkar",
      "Bilal Kartal",
      "Yoshi Suhara",
      "Olivier Delalleau",
      "Zijia Chen",
      "Zhilin Wang",
      "David Mosallanezhad",
      "Adi Renduchintala",
      "Haifeng Qian",
      "Dima Rekesh",
      "Fei Jia",
      "Somshubra Majumdar",
      "Vahid Noroozi",
      "Wasi Uddin Ahmad",
      "Sean Narenthiran",
      "Aleksander Ficek",
      "Mehrzad Samadi",
      "Jocelyn Huang",
      "Siddhartha Jain",
      "Igor Gitman",
      "Ivan Moshkov",
      "Wei Du",
      "Shubham Toshniwal",
      "George Armstrong",
      "Branislav Kisacanin",
      "Matvei Novikov",
      "Daria Gitman",
      "Evelina Bakhturina",
      "Jane Polak Scowcroft",
      "John Kamalu",
      "Dan Su",
      "Kezhi Kong",
      "Markus Kliegl",
      "Rabeeh Karimi",
      "Ying Lin",
      "Sanjeev Satheesh",
      "Jupinder Parmar",
      "Pritam Gundecha",
      "Brandon Norick",
      "Joseph Jennings",
      "Shrimai Prabhumoye",
      "Syeda Nahida Akter",
      "Mostofa Patwary",
      "Abhinav Khattar",
      "Deepak Narayanan",
      "Roger Waleffe",
      "Jimmy Zhang",
      "Bor-Yiing Su",
      "Guyue Huang",
      "Terry Kong",
      "Parth Chadha",
      "Sahil Jain",
      "Christine Harvey",
      "Elad Segal",
      "Jining Huang",
      "Sergey Kashirsky",
      "Robert McQueen",
      "Izzy Putterman",
      "George Lam",
      "Arun Venkatesan",
      "Sherry Wu",
      "Vinh Nguyen",
      "Manoj Kilaru",
      "Andrew Wang",
      "Anna Warno",
      "Abhilash Somasamudramath",
      "Sandip Bhaskar",
      "Maka Dong",
      "Nave Assaf",
      "Shahar Mor",
      "Omer Ullman Argov",
      "Scot Junkin",
      "Oleksandr Romanenko",
      "Pedro Larroy",
      "Monika Katariya",
      "Marco Rovinelli",
      "Viji Balas",
      "Nicholas Edelman",
      "Anahita Bhiwandiwalla",
      "Muthu Subramaniam",
      "Smita Ithape",
      "Karthik Ramamoorthy",
      "Yuting Wu",
      "Suguna Varshini Velury",
      "Omri Almog",
      "Joyjit Daw",
      "Denys Fridman",
      "Erick Galinkin",
      "Michael Evans",
      "Shaona Ghosh",
      "Katherine Luna",
      "Leon Derczynski",
      "Nikki Pope",
      "Eileen Long",
      "Seth Schneider",
      "Guillermo Siman",
      "Tomasz Grzegorzek",
      "Pablo Ribalta",
      "Monika Katariya",
      "Chris Alexiuk",
      "Joey Conway",
      "Trisha Saar",
      "Ann Guan",
      "Krzysztof Pawelec",
      "Shyamala Prayaga",
      "Oleksii Kuchaiev",
      "Boris Ginsburg",
      "Oluwatobi Olabiyi",
      "Kari Briski",
      "Jonathan Cohen",
      "Bryan Catanzaro",
      "Jonah Alben",
      "Yonatan Geifman",
      "Eric Chung"
    ],
    "abstract": "We introduce the Llama-Nemotron series of models, an open family of\nheterogeneous reasoning models that deliver exceptional reasoning capabilities,\ninference efficiency, and an open license for enterprise use. The family comes\nin three sizes -- Nano (8B), Super (49B), and Ultra (253B) -- and performs\ncompetitively with state-of-the-art reasoning models such as DeepSeek-R1 while\noffering superior inference throughput and memory efficiency. In this report,\nwe discuss the training procedure for these models, which entails using neural\narchitecture search from Llama 3 models for accelerated inference, knowledge\ndistillation, and continued pretraining, followed by a reasoning-focused\npost-training stage consisting of two main parts: supervised fine-tuning and\nlarge scale reinforcement learning. Llama-Nemotron models are the first\nopen-source models to support a dynamic reasoning toggle, allowing users to\nswitch between standard chat and reasoning modes during inference. To further\nsupport open research and facilitate model development, we provide the\nfollowing resources: 1. We release the Llama-Nemotron reasoning models --\nLN-Nano, LN-Super, and LN-Ultra -- under the commercially permissive NVIDIA\nOpen Model License Agreement. 2. We release the complete post-training dataset:\nLlama-Nemotron-Post-Training-Dataset. 3. We also release our training\ncodebases: NeMo, NeMo-Aligner, and Megatron-LM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00949v3",
    "published_date": "2025-05-02 01:35:35 UTC",
    "updated_date": "2025-05-14 16:47:23 UTC"
  },
  {
    "arxiv_id": "2505.02848v1",
    "title": "Aligning Large Language Models with Healthcare Stakeholders: A Pathway to Trustworthy AI Integration",
    "authors": [
      "Kexin Ding",
      "Mu Zhou",
      "Akshay Chaudhari",
      "Shaoting Zhang",
      "Dimitris N. Metaxas"
    ],
    "abstract": "The wide exploration of large language models (LLMs) raises the awareness of\nalignment between healthcare stakeholder preferences and model outputs. This\nalignment becomes a crucial foundation to empower the healthcare workflow\neffectively, safely, and responsibly. Yet the varying behaviors of LLMs may not\nalways match with healthcare stakeholders' knowledge, demands, and values. To\nenable a human-AI alignment, healthcare stakeholders will need to perform\nessential roles in guiding and enhancing the performance of LLMs. Human\nprofessionals must participate in the entire life cycle of adopting LLM in\nhealthcare, including training data curation, model training, and inference. In\nthis review, we discuss the approaches, tools, and applications of alignments\nbetween healthcare stakeholders and LLMs. We demonstrate that LLMs can better\nfollow human values by properly enhancing healthcare knowledge integration,\ntask understanding, and human guidance. We provide outlooks on enhancing the\nalignment between humans and LLMs to build trustworthy real-world healthcare\napplications.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02848v1",
    "published_date": "2025-05-02 00:59:49 UTC",
    "updated_date": "2025-05-02 00:59:49 UTC"
  },
  {
    "arxiv_id": "2505.00938v1",
    "title": "CDFormer: Cross-Domain Few-Shot Object Detection Transformer Against Feature Confusion",
    "authors": [
      "Boyuan Meng",
      "Xiaohan Zhang",
      "Peilin Li",
      "Zhe Wu",
      "Yiming Li",
      "Wenkai Zhao",
      "Beinan Yu",
      "Hui-Liang Shen"
    ],
    "abstract": "Cross-domain few-shot object detection (CD-FSOD) aims to detect novel objects\nacross different domains with limited class instances. Feature confusion,\nincluding object-background confusion and object-object confusion, presents\nsignificant challenges in both cross-domain and few-shot settings. In this\nwork, we introduce CDFormer, a cross-domain few-shot object detection\ntransformer against feature confusion, to address these challenges. The method\nspecifically tackles feature confusion through two key modules:\nobject-background distinguishing (OBD) and object-object distinguishing (OOD).\nThe OBD module leverages a learnable background token to differentiate between\nobjects and background, while the OOD module enhances the distinction between\nobjects of different classes. Experimental results demonstrate that CDFormer\noutperforms previous state-of-the-art approaches, achieving 12.9% mAP, 11.0%\nmAP, and 10.4% mAP improvements under the 1/5/10 shot settings, respectively,\nwhen fine-tuned.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00938v1",
    "published_date": "2025-05-02 00:46:25 UTC",
    "updated_date": "2025-05-02 00:46:25 UTC"
  },
  {
    "arxiv_id": "2505.00935v1",
    "title": "Autonomous Embodied Agents: When Robotics Meets Deep Learning Reasoning",
    "authors": [
      "Roberto Bigazzi"
    ],
    "abstract": "The increase in available computing power and the Deep Learning revolution\nhave allowed the exploration of new topics and frontiers in Artificial\nIntelligence research. A new field called Embodied Artificial Intelligence,\nwhich places at the intersection of Computer Vision, Robotics, and Decision\nMaking, has been gaining importance during the last few years, as it aims to\nfoster the development of smart autonomous robots and their deployment in\nsociety. The recent availability of large collections of 3D models for\nphotorealistic robotic simulation has allowed faster and safe training of\nlearning-based agents for millions of frames and a careful evaluation of their\nbehavior before deploying the models on real robotic platforms. These\nintelligent agents are intended to perform a certain task in a possibly unknown\nenvironment. To this end, during the training in simulation, the agents learn\nto perform continuous interactions with the surroundings, such as gathering\ninformation from the environment, encoding and extracting useful cues for the\ntask, and performing actions towards the final goal; where every action of the\nagent influences the interactions. This dissertation follows the complete\ncreation process of embodied agents for indoor environments, from their concept\nto their implementation and deployment. We aim to contribute to research in\nEmbodied AI and autonomous agents, in order to foster future work in this\nfield. We present a detailed analysis of the procedure behind implementing an\nintelligent embodied agent, comprehending a thorough description of the current\nstate-of-the-art in literature, technical explanations of the proposed methods,\nand accurate experimental studies on relevant robotic tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Ph.D. Dissertation",
    "pdf_url": "http://arxiv.org/pdf/2505.00935v1",
    "published_date": "2025-05-02 00:43:28 UTC",
    "updated_date": "2025-05-02 00:43:28 UTC"
  },
  {
    "arxiv_id": "2505.07834v1",
    "title": "ai.txt: A Domain-Specific Language for Guiding AI Interactions with the Internet",
    "authors": [
      "Yuekang Li",
      "Wei Song",
      "Bangshuo Zhu",
      "Dong Gong",
      "Yi Liu",
      "Gelei Deng",
      "Chunyang Chen",
      "Lei Ma",
      "Jun Sun",
      "Toby Walsh",
      "Jingling Xue"
    ],
    "abstract": "We introduce ai.txt, a novel domain-specific language (DSL) designed to\nexplicitly regulate interactions between AI models, agents, and web content,\naddressing critical limitations of the widely adopted robots.txt standard. As\nAI increasingly engages with online materials for tasks such as training,\nsummarization, and content modification, existing regulatory methods lack the\nnecessary granularity and semantic expressiveness to ensure ethical and legal\ncompliance. ai.txt extends traditional URL-based access controls by enabling\nprecise element-level regulations and incorporating natural language\ninstructions interpretable by AI systems. To facilitate practical deployment,\nwe provide an integrated development environment with code autocompletion and\nautomatic XML generation. Furthermore, we propose two compliance mechanisms:\nXML-based programmatic enforcement and natural language prompt integration, and\ndemonstrate their effectiveness through preliminary experiments and case\nstudies. Our approach aims to aid the governance of AI-Internet interactions,\npromoting responsible AI use in digital ecosystems.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CR",
      "cs.PL"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07834v1",
    "published_date": "2025-05-02 00:33:00 UTC",
    "updated_date": "2025-05-02 00:33:00 UTC"
  },
  {
    "arxiv_id": "2505.00932v1",
    "title": "A Self-Supervised Transformer for Unusable Shared Bike Detection",
    "authors": [
      "Yin Huang",
      "Yongqi Dong",
      "Youhua Tang",
      "Alvaro García Hernandez"
    ],
    "abstract": "The rapid expansion of bike-sharing systems (BSS) has greatly improved urban\n\"last-mile\" connectivity, yet large-scale deployments face escalating\noperational challenges, particularly in detecting faulty bikes. Existing\ndetection approaches either rely on static model-based thresholds that overlook\ndynamic spatiotemporal (ST) usage patterns or employ supervised learning\nmethods that struggle with label scarcity and class imbalance. To address these\nlimitations, this paper proposes a novel Self-Supervised Transformer\n(SSTransformer) framework for automatically detecting unusable shared bikes,\nleveraging ST features extracted from GPS trajectories and trip records. The\nmodel incorporates a self-supervised pre-training strategy to enhance its\nfeature extraction capabilities, followed by fine-tuning for efficient status\nrecognition. In the pre-training phase, the Transformer encoder learns\ngeneralized representations of bike movement via a self-supervised objective;\nin the fine-tuning phase, the encoder is adapted to a downstream binary\nclassification task. Comprehensive experiments on a real-world dataset of\n10,730 bikes (1,870 unusable, 8,860 normal) from Chengdu, China, demonstrate\nthat SSTransformer significantly outperforms traditional machine learning,\nensemble learning, and deep learning baselines, achieving the best accuracy\n(97.81%), precision (0.8889), and F1-score (0.9358). This work highlights the\neffectiveness of self-supervised Transformer on ST data for capturing complex\nanomalies in BSS, paving the way toward more reliable and scalable maintenance\nsolutions for shared mobility.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 5 figures, under review by the 2025 IEEE International\n  Conference on Intelligent Transportation Systems (IEEE ITSC 2025)",
    "pdf_url": "http://arxiv.org/pdf/2505.00932v1",
    "published_date": "2025-05-02 00:20:38 UTC",
    "updated_date": "2025-05-02 00:20:38 UTC"
  },
  {
    "arxiv_id": "2505.00931v1",
    "title": "Large Language Model-Driven Dynamic Assessment of Grammatical Accuracy in English Language Learner Writing",
    "authors": [
      "Timur Jaganov",
      "John Blake",
      "Julián Villegas",
      "Nicholas Carr"
    ],
    "abstract": "This study investigates the potential for Large Language Models (LLMs) to\nscale-up Dynamic Assessment (DA). To facilitate such an investigation, we first\ndeveloped DynaWrite-a modular, microservices-based grammatical tutoring\napplication which supports multiple LLMs to generate dynamic feedback to\nlearners of English. Initial testing of 21 LLMs, revealed GPT-4o and neural\nchat to have the most potential to scale-up DA in the language learning\nclassroom. Further testing of these two candidates found both models performed\nsimilarly in their ability to accurately identify grammatical errors in user\nsentences. However, GPT-4o consistently outperformed neural chat in the quality\nof its DA by generating clear, consistent, and progressively explicit hints.\nReal-time responsiveness and system stability were also confirmed through\ndetailed performance testing, with GPT-4o exhibiting sufficient speed and\nstability. This study shows that LLMs can be used to scale-up dynamic\nassessment and thus enable dynamic assessment to be delivered to larger groups\nthan possible in traditional teacher-learner settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 8 Figures. This work has been submitted to the IEEE for\n  possible publication",
    "pdf_url": "http://arxiv.org/pdf/2505.00931v1",
    "published_date": "2025-05-02 00:19:50 UTC",
    "updated_date": "2025-05-02 00:19:50 UTC"
  }
]