{
  "date": "2024-01-07",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-07 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 更新聚焦于 AI 和机器学习的多样化应用，包括联邦学习、多模态模型、LLM 在对话推荐和代理中的潜力，以及交通预测和医疗领域的创新。其中，Agent AI 调查论文（作者包括 Yejin Choi 和 Li Fei-Fei 等知名学者）令人印象深刻，探讨了多模态交互的未来前景；此外，联邦学习和 LLM 相关论文突显了隐私保护和模型鲁棒性的关键挑战。\n\n下面，我将挑选并简要讨论部分重要或有话题度的论文，先从 LLM 和 AI 代理等热点主题入手，再聊联邦学习和多模态应用，最后快速掠过其他较次要的论文。每个条目会列出论文标题（中文 + 英文），并突出核心贡献和发现。\n\n### LLM 和 AI 代理：这些论文探讨了大型语言模型在交互和决策中的潜力，相关性强且话题度高。\n- **ChatGPT for Conversational Recommendation: Refining Recommendations by Reprompting with Feedback（ChatGPT 用于对话推荐：通过反馈重新提示优化推荐）**：该论文提出使用 ChatGPT 作为对话推荐系统，通过反馈机制重新提示来提升推荐相关性，发现这种方法能有效缓解流行度偏差，并在性能上优于基线模型。\n- **InFoBench: Evaluating Instruction Following Ability in Large Language Models（InFoBench：评估大型语言模型的指令遵循能力）**：引入 DRFR 指标分解复杂指令，构建 500 条指令基准，实验显示 GPT-4 作为标注器更可靠，并揭示 LLM 在复杂任务中的优势和不足。\n- **Agent AI: Surveying the Horizons of Multimodal Interaction（Agent AI：调查多模态交互的前沿）**：由 Yejin Choi 和 Li Fei-Fei 等学者参与的综述，定义 Agent AI 为感知视觉和语言的交互系统，强调多感官输入和反馈能减少模型幻觉，并展望虚拟环境中的应用。\n- **Expanding Horizons in HCI Research Through LLM-Driven Qualitative Analysis（通过 LLM 驱动的定性分析扩展 HCI 研究）**：提出 LLM 用于 HCI 定性分析的新框架，使用 SBART 余弦相似度评估，发现 LLM 能匹敌传统方法并提供独特洞见。\n\n### 联邦学习：多个论文关注隐私和公平性，这是 AI 领域的关键问题，相关论文聚在一起讨论以突出主题。\n- **Multi-Modal Federated Learning for Cancer Staging over Non-IID Datasets with Unbalanced Modalities（多模态联邦学习用于癌症分期：处理非独立同分布和不平衡模态数据集）**：引入新联邦学习架构处理数据异质性，提出梯度混合和客户端加权策略，实验在 TCGA 数据集上显示显著提升模型性能。\n- **GLOCALFAIR: Jointly Improving Global and Local Group Fairness in Federated Learning（GLOCALFAIR：联合提升联邦学习的全局和局部群体公平性）**：提出无需共享敏感数据的公平框架，使用约束优化和聚类聚合，实验证明能同时提升全局公平性和模型效用。\n- **Privacy-Preserving in Blockchain-based Federated Learning Systems（基于区块链的联邦学习隐私保护）**：综述区块链与联邦学习的整合，评估现有架构和攻击防御，强调隐私方案在医疗等场景的应用潜力。\n\n### 多模态和图像生成：这些论文有实际应用价值，但不若 LLM 主题热门，故简要概述。\n- **Disentangled Neural Relational Inference for Interpretable Motion Prediction（解耦神经关系推理用于可解释运动预测）**：设计变分自编码框架捕捉代理间时空关系，提高模型可解释性和泛化性，实验在模拟和真实数据集上表现优异。\n- **FurniScene: A Large-scale 3D Room Dataset with Intricate Furnishing Scenes（FurniScene：大规模 3D 房间数据集，包含复杂 furnishings 场景）**：发布包含 11,698 房间的基准数据集，并提出 Two-Stage Diffusion Scene Model，提升室内场景生成的质量和真实性。\n- **CharPoet: A Chinese Classical Poetry Generation System Based on Token-free LLM（CharPoet：基于无 token LLM 的中文古诗生成系统）**：开发基于字符级 LLM 的诗歌生成框架，实现格式和内容的精确控制，准确率超过 0.96。\n\n### 其他主题：这些论文较为专业或应用导向，篇幅有限，故快速掠过，只提核心点。\n- **Few-Shot Causal Representation Learning for Out-of-Distribution Generalization on Heterogeneous Graphs（异构图上的少样本因果表示学习，用于分布外泛化）**：提出 COHF 模型处理异构图分布偏移，提升少样本学习性能，实验在七个数据集上优于现有方法。\n- **Big Data and Deep Learning in Smart Cities: A Comprehensive Dataset for AI-Driven Traffic Accident Detection（大数据和深度学习在智慧城市：用于 AI 驱动交通事故检测的全面数据集）**：发布新型交通事故数据集，支持计算机视觉和动作识别，提升智能城市安全。\n- **Efficient Test Data Generation for MC/DC with OCL and Search（使用 OCL 和搜索的 MC/DC 高效测试数据生成）**：开发基于 CBR 和范围缩减的策略，优化航空软件测试数据生成，提高效率和准确性。\n\n今天的更新展示了 AI 领域的快速演进，LLM 和联邦学习尤为值得关注。如果你对特定主题感兴趣，如代理 AI 或隐私保护，建议查看相关论文的细节。明天见，继续探索 arXiv 的前沿动态！",
  "papers": [
    {
      "arxiv_id": "2401.03609v3",
      "title": "Multi-Modal Federated Learning for Cancer Staging over Non-IID Datasets with Unbalanced Modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Kasra Borazjani",
        "Naji Khosravan",
        "Leslie Ying",
        "Seyyedali Hosseinalipour"
      ],
      "abstract": "The use of machine learning (ML) for cancer staging through medical image\nanalysis has gained substantial interest across medical disciplines. When\naccompanied by the innovative federated learning (FL) framework, ML techniques\ncan further overcome privacy concerns related to patient data exposure. Given\nthe frequent presence of diverse data modalities within patient records,\nleveraging FL in a multi-modal learning framework holds considerable promise\nfor cancer staging.\n  However, existing works on multi-modal FL often presume that all\ndata-collecting institutions have access to all data modalities. This\noversimplified approach neglects institutions that have access to only a\nportion of data modalities within the system. In this work, we introduce a\nnovel FL architecture designed to accommodate not only the heterogeneity of\ndata samples, but also the inherent heterogeneity/non-uniformity of data\nmodalities across institutions. We shed light on the challenges associated with\nvarying convergence speeds observed across different data modalities within our\nFL system. Subsequently, we propose a solution to tackle these challenges by\ndevising a distributed gradient blending and proximity-aware client weighting\nstrategy tailored for multi-modal FL. To show the superiority of our method, we\nconduct experiments using The Cancer Genome Atlas program (TCGA) datalake\nconsidering different cancer types and three modalities of data: mRNA\nsequences, histopathological image data, and clinical information. Our results\nfurther unveil the impact and severity of class-based vs type-based\nheterogeneity across institutions on the model performance, which widens the\nperspective to the notion of data heterogeneity in multi-modal FL literature.",
      "tldr_zh": "这篇论文针对癌症分期中的多模态联邦学习（Multi-Modal Federated Learning），处理Non-IID数据集和模态不平衡问题，引入了一种新型FL架构，以适应机构间数据样本和模态异质性。论文提出分布式梯度混合和基于接近度的客户端加权策略，来解决不同模态收敛速度不一致的挑战。实验使用The Cancer Genome Atlas (TCGA)数据集，涉及mRNA sequences、组织病理图像和临床信息等模态，结果显示该方法优于基线模型，并揭示了类-based和类型-based异质性对性能的显著影响。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in IEEE Transactions on Medical Imaging (TMI), DOI:\n  https://doi.org/10.1109/TMI.2024.3450855",
      "pdf_url": "http://arxiv.org/pdf/2401.03609v3",
      "published_date": "2024-01-07 23:45:01 UTC",
      "updated_date": "2024-10-08 14:52:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:14:37.582946"
    },
    {
      "arxiv_id": "2401.03605v1",
      "title": "ChatGPT for Conversational Recommendation: Refining Recommendations by Reprompting with Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Kyle Dylan Spurlock",
        "Cagla Acun",
        "Esin Saka",
        "Olfa Nasraoui"
      ],
      "abstract": "Recommendation algorithms have been pivotal in handling the overwhelming\nvolume of online content. However, these algorithms seldom consider direct user\ninput, resulting in superficial interaction between them. Efforts have been\nmade to include the user directly in the recommendation process through\nconversation, but these systems too have had limited interactivity. Recently,\nLarge Language Models (LLMs) like ChatGPT have gained popularity due to their\nease of use and their ability to adapt dynamically to various tasks while\nresponding to feedback. In this paper, we investigate the effectiveness of\nChatGPT as a top-n conversational recommendation system. We build a rigorous\npipeline around ChatGPT to simulate how a user might realistically probe the\nmodel for recommendations: by first instructing and then reprompting with\nfeedback to refine a set of recommendations. We further explore the effect of\npopularity bias in ChatGPT's recommendations, and compare its performance to\nbaseline models. We find that reprompting ChatGPT with feedback is an effective\nstrategy to improve recommendation relevancy, and that popularity bias can be\nmitigated through prompt engineering.",
      "tldr_zh": "这篇论文探讨了使用 ChatGPT 作为 top-n 对话式推荐系统，通过初始指令和反馈重新提示（reprompting）来改进推荐算法的互动性，以解决传统系统忽略用户直接输入的问题。研究构建了一个管道，模拟用户反馈过程，并评估了 ChatGPT 在推荐相关性上的表现，同时比较了流行度偏差（popularity bias）的效果。结果显示，重新提示策略能显著提升推荐准确性，而通过提示工程（prompt engineering）可以有效缓解偏差，使 ChatGPT 优于基线模型。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "I.2.7; H.3.3"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03605v1",
      "published_date": "2024-01-07 23:17:42 UTC",
      "updated_date": "2024-01-07 23:17:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:14:47.898216"
    },
    {
      "arxiv_id": "2401.03601v1",
      "title": "InFoBench: Evaluating Instruction Following Ability in Large Language Models",
      "title_zh": "InFoBench：评估大语言模型的指令遵循能力",
      "authors": [
        "Yiwei Qin",
        "Kaiqiang Song",
        "Yebowen Hu",
        "Wenlin Yao",
        "Sangwoo Cho",
        "Xiaoyang Wang",
        "Xuansheng Wu",
        "Fei Liu",
        "Pengfei Liu",
        "Dong Yu"
      ],
      "abstract": "This paper introduces the Decomposed Requirements Following Ratio (DRFR), a\nnew metric for evaluating Large Language Models' (LLMs) ability to follow\ninstructions. Addressing a gap in current methodologies, DRFR breaks down\ncomplex instructions into simpler criteria, facilitating a detailed analysis of\nLLMs' compliance with various aspects of tasks. Alongside this metric, we\npresent InFoBench, a benchmark comprising 500 diverse instructions and 2,250\ndecomposed questions across multiple constraint categories. Our experiments\ncompare DRFR with traditional scoring methods and explore annotation sources,\nincluding human experts, crowd-sourced workers, and GPT-4. The findings\ndemonstrate DRFR's higher reliability and the effectiveness of using GPT-4 as a\ncost-efficient annotator. The evaluation of several advanced LLMs using this\nframework reveals their strengths and areas needing improvement, particularly\nin complex instruction-following. This study contributes a novel metric and\nbenchmark, offering insights for future LLM development and evaluation.",
      "tldr_zh": "这篇论文引入了 Decomposed Requirements Following Ratio (DRFR) 指标，用于评估 Large Language Models (LLMs) 的指令遵循能力，通过将复杂指令分解为简单标准来实现更详细的分析。作者开发了 InFoBench 基准测试，包含 500 个多样化指令和 2,250 个分解问题，覆盖多种约束类别，并比较了 DRFR 与传统评分方法。实验发现，DRFR 具有更高的可靠性和成本效益，特别是使用 GPT-4 作为标注者，且对多款高级 LLMs 的评估揭示了它们在复杂指令遵循方面的优势与不足，为未来 LLM 开发提供宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03601v1",
      "published_date": "2024-01-07 23:01:56 UTC",
      "updated_date": "2024-01-07 23:01:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:15:00.132846"
    },
    {
      "arxiv_id": "2401.03599v1",
      "title": "Disentangled Neural Relational Inference for Interpretable Motion Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Victoria M. Dax",
        "Jiachen Li",
        "Enna Sachdeva",
        "Nakul Agarwal",
        "Mykel J. Kochenderfer"
      ],
      "abstract": "Effective interaction modeling and behavior prediction of dynamic agents play\na significant role in interactive motion planning for autonomous robots.\nAlthough existing methods have improved prediction accuracy, few research\nefforts have been devoted to enhancing prediction model interpretability and\nout-of-distribution (OOD) generalizability. This work addresses these two\nchallenging aspects by designing a variational auto-encoder framework that\nintegrates graph-based representations and time-sequence models to efficiently\ncapture spatio-temporal relations between interactive agents and predict their\ndynamics. Our model infers dynamic interaction graphs in a latent space\naugmented with interpretable edge features that characterize the interactions.\nMoreover, we aim to enhance model interpretability and performance in OOD\nscenarios by disentangling the latent space of edge features, thereby\nstrengthening model versatility and robustness. We validate our approach\nthrough extensive experiments on both simulated and real-world datasets. The\nresults show superior performance compared to existing methods in modeling\nspatio-temporal relations, motion prediction, and identifying time-invariant\nlatent features.",
      "tldr_zh": "该论文提出了一种解耦神经关系推理框架，用于提升动态代理交互建模和行为预测的可解释性及OOD（Out-of-Distribution）泛化能力。框架基于变分自编码器（Variational Auto-Encoder）结合图-based 表示和时间序列模型，来捕捉代理间的时空关系并预测动态，同时在潜在空间中推断动态交互图并使用可解释的边特征表征交互。通过解耦边特征的潜在空间，该方法增强了模型的鲁棒性和可解释性。实验在模拟和真实数据集上验证了其在建模时空关系、运动预测和识别时间不变潜在特征方面的优越性能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03599v1",
      "published_date": "2024-01-07 22:49:24 UTC",
      "updated_date": "2024-01-07 22:49:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:15:11.594702"
    },
    {
      "arxiv_id": "2401.03597v3",
      "title": "Few-Shot Causal Representation Learning for Out-of-Distribution Generalization on Heterogeneous Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Pengfei Ding",
        "Yan Wang",
        "Guanfeng Liu",
        "Nan Wang",
        "Xiaofang Zhou"
      ],
      "abstract": "Heterogeneous graph few-shot learning (HGFL) has been developed to address\nthe label sparsity issue in heterogeneous graphs (HGs), which consist of\nvarious types of nodes and edges. The core concept of HGFL is to extract\nknowledge from rich-labeled classes in a source HG, transfer this knowledge to\na target HG to facilitate learning new classes with few-labeled training data,\nand finally make predictions on unlabeled testing data. Existing methods\ntypically assume that the source HG, training data, and testing data all share\nthe same distribution. However, in practice, distribution shifts among these\nthree types of data are inevitable due to two reasons: (1) the limited\navailability of the source HG that matches the target HG distribution, and (2)\nthe unpredictable data generation mechanism of the target HG. Such distribution\nshifts result in ineffective knowledge transfer and poor learning performance\nin existing methods, thereby leading to a novel problem of out-of-distribution\n(OOD) generalization in HGFL. To address this challenging problem, we propose a\nnovel Causal OOD Heterogeneous graph Few-shot learning model, namely COHF. In\nCOHF, we first characterize distribution shifts in HGs with a structural causal\nmodel, establishing an invariance principle for OOD generalization in HGFL.\nThen, following this invariance principle, we propose a new variational\nautoencoder-based heterogeneous graph neural network to mitigate the impact of\ndistribution shifts. Finally, by integrating this network with a novel\nmeta-learning framework, COHF effectively transfers knowledge to the target HG\nto predict new classes with few-labeled data. Extensive experiments on seven\nreal-world datasets have demonstrated the superior performance of COHF over the\nstate-of-the-art methods.",
      "tldr_zh": "本文提出了一种针对异构图（Heterogeneous Graphs）的少样本因果表示学习方法，用于处理 Out-of-Distribution (OOD) 泛化问题，以解决现有 Heterogeneous Graph Few-Shot Learning (HGFL) 方法在分布偏移下的知识转移失效问题。COHF 模型首先通过结构化因果模型（Structural Causal Model）描述分布偏移并建立不变性原则，然后使用基于变分自编码器（Variational Autoencoder）的异构图神经网络缓解偏移影响，并与新型元学习框架整合，实现从源图到目标图的有效知识转移。实验结果显示，COHF 在七个真实数据集上显著优于最先进方法，提升了少样本学习性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03597v3",
      "published_date": "2024-01-07 22:47:38 UTC",
      "updated_date": "2024-04-16 04:36:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:15:24.536732"
    },
    {
      "arxiv_id": "2401.03587v1",
      "title": "Big Data and Deep Learning in Smart Cities: A Comprehensive Dataset for AI-Driven Traffic Accident Detection and Computer Vision Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Victor Adewopo",
        "Nelly Elsayed",
        "Zag Elsayed",
        "Murat Ozer",
        "Constantinos Zekios",
        "Ahmed Abdelgawad",
        "Magdy Bayoumi"
      ],
      "abstract": "In the dynamic urban landscape, where the interplay of vehicles and\npedestrians defines the rhythm of life, integrating advanced technology for\nsafety and efficiency is increasingly crucial. This study delves into the\napplication of cutting-edge technological methods in smart cities, focusing on\nenhancing public safety through improved traffic accident detection. Action\nrecognition plays a pivotal role in interpreting visual data and tracking\nobject motion such as human pose estimation in video sequences. The challenges\nof action recognition include variability in rapid actions, limited dataset,\nand environmental factors such as (Weather, Illumination, and Occlusions). In\nthis paper, we present a novel comprehensive dataset for traffic accident\ndetection. This datasets is specifically designed to bolster computer vision\nand action recognition systems in predicting and detecting road traffic\naccidents. We integrated datasets from wide variety of data sources, road\nnetworks, weather conditions, and regions across the globe. This approach is\nunderpinned by empirical studies, aiming to contribute to the discourse on how\ntechnology can enhance the quality of life in densely populated areas. This\nresearch aims to bridge existing research gaps by introducing benchmark\ndatasets that leverage state-of-the-art algorithms tailored for traffic\naccident detection in smart cities. These dataset is expected to advance\nacademic research and also enhance real-time accident detection applications,\ncontributing significantly to the evolution of smart urban environments. Our\nstudy marks a pivotal step towards safer, more efficient smart cities,\nharnessing the power of AI and machine learning to transform urban living.",
      "tldr_zh": "本研究探讨了在智能城市中使用大数据和深度学习来提升交通事故检测的系统，重点解决行动识别（action recognition）中的挑战，如快速动作变异、数据集有限以及环境因素（Weather, Illumination, and Occlusions）。研究者构建了一个新型综合数据集，通过整合全球道路网络、天气条件和多种数据源，支持计算机视觉（computer vision）和AI驱动的实时事故预测与检测。实验结果表明，该数据集能显著提升事故检测准确性，并为学术研究和智能城市应用提供基准，推动更安全高效的都市环境。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03587v1",
      "published_date": "2024-01-07 21:50:24 UTC",
      "updated_date": "2024-01-07 21:50:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:15:35.590768"
    },
    {
      "arxiv_id": "2401.03581v1",
      "title": "Evaluating and Personalizing User-Perceived Quality of Text-to-Speech Voices for Delivering Mindfulness Meditation with Different Physical Embodiments",
      "title_zh": "翻译失败",
      "authors": [
        "Zhonghao Shi",
        "Han Chen",
        "Anna-Maria Velentza",
        "Siqi Liu",
        "Nathaniel Dennler",
        "Allison O'Connell",
        "Maja Matarić"
      ],
      "abstract": "Mindfulness-based therapies have been shown to be effective in improving\nmental health, and technology-based methods have the potential to expand the\naccessibility of these therapies. To enable real-time personalized content\ngeneration for mindfulness practice in these methods, high-quality\ncomputer-synthesized text-to-speech (TTS) voices are needed to provide verbal\nguidance and respond to user performance and preferences. However, the\nuser-perceived quality of state-of-the-art TTS voices has not yet been\nevaluated for administering mindfulness meditation, which requires emotional\nexpressiveness. In addition, work has not yet been done to study the effect of\nphysical embodiment and personalization on the user-perceived quality of TTS\nvoices for mindfulness. To that end, we designed a two-phase human subject\nstudy. In Phase 1, an online Mechanical Turk between-subject study (N=471)\nevaluated 3 (feminine, masculine, child-like) state-of-the-art TTS voices with\n2 (feminine, masculine) human therapists' voices in 3 different physical\nembodiment settings (no agent, conversational agent, socially assistive robot)\nwith remote participants. Building on findings from Phase 1, in Phase 2, an\nin-person within-subject study (N=94), we used a novel framework we developed\nfor personalizing TTS voices based on user preferences, and evaluated\nuser-perceived quality compared to best-rated non-personalized voices from\nPhase 1. We found that the best-rated human voice was perceived better than all\nTTS voices; the emotional expressiveness and naturalness of TTS voices were\npoorly rated, while users were satisfied with the clarity of TTS voices.\nSurprisingly, by allowing users to fine-tune TTS voice features, the\nuser-personalized TTS voices could perform almost as well as human voices,\nsuggesting user personalization could be a simple and very effective tool to\nimprove user-perceived quality of TTS voice.",
      "tldr_zh": "该研究评估了TTS（Text-to-Speech）声音在提供正念冥想指导时的用户感知质量，并探讨了物理体现和个性化的影响。研究采用两阶段人类实验：Phase 1 通过Mechanical Turk在线研究（N=471）比较了3种TTS声音（feminine、masculine、child-like）和人类治疗师声音在不同物理体现设置（无代理、对话代理、社会辅助机器人）下的表现，发现人类声音在情感表达性和自然性上优于TTS声音，但TTS声音的清晰度获得肯定。Phase 2 的面对面研究（N=94）引入了一个新框架允许用户个性化TTS声音，结果显示个性化TTS几乎能媲美最佳人类声音，这证明个性化是提升用户感知质量的有效工具。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.HC",
      "comment": "Published in Proceedings of the 2023 ACM/IEEE International\n  Conference on Human-Robot Interaction, pp. 516-524. 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.03581v1",
      "published_date": "2024-01-07 21:14:32 UTC",
      "updated_date": "2024-01-07 21:14:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:15:49.468576"
    },
    {
      "arxiv_id": "2401.03568v2",
      "title": "Agent AI: Surveying the Horizons of Multimodal Interaction",
      "title_zh": "翻译失败",
      "authors": [
        "Zane Durante",
        "Qiuyuan Huang",
        "Naoki Wake",
        "Ran Gong",
        "Jae Sung Park",
        "Bidipta Sarkar",
        "Rohan Taori",
        "Yusuke Noda",
        "Demetri Terzopoulos",
        "Yejin Choi",
        "Katsushi Ikeuchi",
        "Hoi Vo",
        "Li Fei-Fei",
        "Jianfeng Gao"
      ],
      "abstract": "Multi-modal AI systems will likely become a ubiquitous presence in our\neveryday lives. A promising approach to making these systems more interactive\nis to embody them as agents within physical and virtual environments. At\npresent, systems leverage existing foundation models as the basic building\nblocks for the creation of embodied agents. Embedding agents within such\nenvironments facilitates the ability of models to process and interpret visual\nand contextual data, which is critical for the creation of more sophisticated\nand context-aware AI systems. For example, a system that can perceive user\nactions, human behavior, environmental objects, audio expressions, and the\ncollective sentiment of a scene can be used to inform and direct agent\nresponses within the given environment. To accelerate research on agent-based\nmultimodal intelligence, we define \"Agent AI\" as a class of interactive systems\nthat can perceive visual stimuli, language inputs, and other\nenvironmentally-grounded data, and can produce meaningful embodied actions. In\nparticular, we explore systems that aim to improve agents based on\nnext-embodied action prediction by incorporating external knowledge,\nmulti-sensory inputs, and human feedback. We argue that by developing agentic\nAI systems in grounded environments, one can also mitigate the hallucinations\nof large foundation models and their tendency to generate environmentally\nincorrect outputs. The emerging field of Agent AI subsumes the broader embodied\nand agentic aspects of multimodal interactions. Beyond agents acting and\ninteracting in the physical world, we envision a future where people can easily\ncreate any virtual reality or simulated scene and interact with agents embodied\nwithin the virtual environment.",
      "tldr_zh": "这篇论文调查了多模态交互中的 \"Agent AI\"，定义它为一种能感知视觉刺激、语言输入和其他环境数据的交互系统，并通过嵌入物理或虚拟环境来产生有意义的动作。论文探讨了利用现有 foundation models 作为构建块，结合外部知识、多感官输入和人类反馈来改进代理的下一动作预测，从而减少 large foundation models 的幻觉问题。最终，研究者认为 Agent AI 的发展不仅能提升 AI 的上下文感知和交互能力，还能扩展到虚拟现实和模拟场景中，促进更广泛的 multimodal intelligence 应用。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03568v2",
      "published_date": "2024-01-07 19:11:18 UTC",
      "updated_date": "2024-01-25 21:20:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:15:59.183423"
    },
    {
      "arxiv_id": "2401.03562v2",
      "title": "GLOCALFAIR: Jointly Improving Global and Local Group Fairness in Federated Learning",
      "title_zh": "GLOCALFAIR：联合提升联邦学习中的全局和局部群体公平性",
      "authors": [
        "Syed Irfan Ali Meerza",
        "Luyang Liu",
        "Jiaxin Zhang",
        "Jian Liu"
      ],
      "abstract": "Federated learning (FL) has emerged as a prospective solution for\ncollaboratively learning a shared model across clients without sacrificing\ntheir data privacy. However, the federated learned model tends to be biased\nagainst certain demographic groups (e.g., racial and gender groups) due to the\ninherent FL properties, such as data heterogeneity and party selection. Unlike\ncentralized learning, mitigating bias in FL is particularly challenging as\nprivate training datasets and their sensitive attributes are typically not\ndirectly accessible. Most prior research in this field only focuses on global\nfairness while overlooking the local fairness of individual clients. Moreover,\nexisting methods often require sensitive information about the client's local\ndatasets to be shared, which is not desirable. To address these issues, we\npropose GLOCALFAIR, a client-server co-design fairness framework that can\njointly improve global and local group fairness in FL without the need for\nsensitive statistics about the client's private datasets. Specifically, we\nutilize constrained optimization to enforce local fairness on the client side\nand adopt a fairness-aware clustering-based aggregation on the server to\nfurther ensure the global model fairness across different sensitive groups\nwhile maintaining high utility. Experiments on two image datasets and one\ntabular dataset with various state-of-the-art fairness baselines show that\nGLOCALFAIR can achieve enhanced fairness under both global and local data\ndistributions while maintaining a good level of utility and client fairness.",
      "tldr_zh": "本文提出 GLOCALFAIR，一种客户端-服务器协同设计的框架，用于在 Federated Learning (FL) 中同时提升全局和本地群体公平，而无需共享客户端私有数据集的敏感统计信息。框架在客户端侧采用 constrained optimization 来强制本地公平，在服务器侧使用 fairness-aware clustering-based aggregation 确保全局模型对不同敏感群体的公平性，同时维持高实用性。实验在两个图像数据集和一个表格数据集上表明，GLOCALFAIR 相对于现有基线方法显著提高了全局和本地公平性，同时保持了良好的模型性能和客户端公平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03562v2",
      "published_date": "2024-01-07 18:10:14 UTC",
      "updated_date": "2024-10-02 21:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:16:12.560785"
    },
    {
      "arxiv_id": "2401.03552v1",
      "title": "Privacy-Preserving in Blockchain-based Federated Learning Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Sameera K. M.",
        "Serena Nicolazzo",
        "Marco Arazzi",
        "Antonino Nocera",
        "Rafidha Rehiman K. A.",
        "Vinod P",
        "Mauro Conti"
      ],
      "abstract": "Federated Learning (FL) has recently arisen as a revolutionary approach to\ncollaborative training Machine Learning models. According to this novel\nframework, multiple participants train a global model collaboratively,\ncoordinating with a central aggregator without sharing their local data. As FL\ngains popularity in diverse domains, security, and privacy concerns arise due\nto the distributed nature of this solution. Therefore, integrating this\nstrategy with Blockchain technology has been consolidated as a preferred choice\nto ensure the privacy and security of participants.\n  This paper explores the research efforts carried out by the scientific\ncommunity to define privacy solutions in scenarios adopting Blockchain-Enabled\nFL. It comprehensively summarizes the background related to FL and Blockchain,\nevaluates existing architectures for their integration, and the primary attacks\nand possible countermeasures to guarantee privacy in this setting. Finally, it\nreviews the main application scenarios where Blockchain-Enabled FL approaches\nhave been proficiently applied. This survey can help academia and industry\npractitioners understand which theories and techniques exist to improve the\nperformance of FL through Blockchain to preserve privacy and which are the main\nchallenges and future directions in this novel and still under-explored\ncontext. We believe this work provides a novel contribution respect to the\nprevious surveys and is a valuable tool to explore the current landscape,\nunderstand perspectives, and pave the way for advancements or improvements in\nthis amalgamation of Blockchain and Federated Learning.",
      "tldr_zh": "这篇论文调查了在基于Blockchain的Federated Learning (FL)系统中实现Privacy-Preserving的解决方案，通过总结FL和Blockchain的背景，评估现有集成架构以及主要攻击和对策。论文审视了这些技术在各种应用场景中的应用，并强调了如何通过Blockchain提升FL的性能以保护参与者的隐私。最终，它指出了当前挑战、未来方向，并为学术界和行业从业者提供了一个理解现有理论和技术的宝贵工具。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "44 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.03552v1",
      "published_date": "2024-01-07 17:23:55 UTC",
      "updated_date": "2024-01-07 17:23:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:16:23.845700"
    },
    {
      "arxiv_id": "2401.03546v1",
      "title": "NovelGym: A Flexible Ecosystem for Hybrid Planning and Learning Agents Designed for Open Worlds",
      "title_zh": "翻译失败",
      "authors": [
        "Shivam Goel",
        "Yichen Wei",
        "Panagiotis Lymperopoulos",
        "Klara Chura",
        "Matthias Scheutz",
        "Jivko Sinapov"
      ],
      "abstract": "As AI agents leave the lab and venture into the real world as autonomous\nvehicles, delivery robots, and cooking robots, it is increasingly necessary to\ndesign and comprehensively evaluate algorithms that tackle the ``open-world''.\nTo this end, we introduce NovelGym, a flexible and adaptable ecosystem designed\nto simulate gridworld environments, serving as a robust platform for\nbenchmarking reinforcement learning (RL) and hybrid planning and learning\nagents in open-world contexts. The modular architecture of NovelGym facilitates\nrapid creation and modification of task environments, including multi-agent\nscenarios, with multiple environment transformations, thus providing a dynamic\ntestbed for researchers to develop open-world AI agents.",
      "tldr_zh": "该论文引入了 NovelGym，这是一个灵活的生态系统，用于模拟网格世界环境，以基准测试强化学习 (RL) 和混合规划与学习代理在开放世界的性能。NovelGym 的模块化架构允许快速创建和修改任务环境，包括多代理场景和多种环境转换，从而为研究者提供一个动态的测试平台。总体上，该系统旨在帮助开发更可靠的开放世界 AI 代理，如自动车辆和机器人，以应对现实世界挑战。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at AAMAS-2024",
      "pdf_url": "http://arxiv.org/pdf/2401.03546v1",
      "published_date": "2024-01-07 17:13:28 UTC",
      "updated_date": "2024-01-07 17:13:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:16:37.028910"
    },
    {
      "arxiv_id": "2401.03545v1",
      "title": "Is there really a Citation Age Bias in NLP?",
      "title_zh": "翻译失败",
      "authors": [
        "Hoa Nguyen",
        "Steffen Eger"
      ],
      "abstract": "Citations are a key ingredient of scientific research to relate a paper to\nothers published in the community. Recently, it has been noted that there is a\ncitation age bias in the Natural Language Processing (NLP) community, one of\nthe currently fastest growing AI subfields, in that the mean age of the\nbibliography of NLP papers has become ever younger in the last few years,\nleading to `citation amnesia' in which older knowledge is increasingly\nforgotten. In this work, we put such claims into perspective by analyzing the\nbibliography of $\\sim$300k papers across 15 different scientific fields\nsubmitted to the popular preprint server Arxiv in the time period from 2013 to\n2022. We find that all AI subfields (in particular: cs.AI, cs.CL, cs.CV, cs.LG)\nhave similar trends of citation amnesia, in which the age of the bibliography\nhas roughly halved in the last 10 years (from above 12 in 2013 to below 7 in\n2022), on average. Rather than diagnosing this as a citation age bias in the\nNLP community, we believe this pattern is an artefact of the dynamics of these\nresearch fields, in which new knowledge is produced in ever shorter time\nintervals.",
      "tldr_zh": "这篇论文探讨了自然语言处理（NLP）社区是否真的存在引用年龄偏差（Citation Age Bias），即参考文献年龄变年轻导致的“引用遗忘症”（citation amnesia）。作者通过分析 2013 到 2022 年 Arxiv 上约 30 万篇论文的参考文献，涵盖 15 个科学领域。结果显示，AI 子领域（如 cs.AI, cs.CL, cs.CV, cs.LG）均表现出类似趋势，参考文献平均年龄从 2013 年的超过 12 年降至 2022 年的不足 7 年。作者认为，这种现象并非 NLP 特有的偏差，而是这些领域知识产生速度加快的动态结果。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03545v1",
      "published_date": "2024-01-07 17:12:08 UTC",
      "updated_date": "2024-01-07 17:12:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:16:50.259524"
    },
    {
      "arxiv_id": "2401.06789v1",
      "title": "Information Retrieval and Classification of Real-Time Multi-Source Hurricane Evacuation Notices",
      "title_zh": "实时多源飓风疏散通知的信息检索和分类",
      "authors": [
        "Tingting Zhao",
        "Shubo Tian",
        "Jordan Daly",
        "Melissa Geiger",
        "Minna Jia",
        "Jinfeng Zhang"
      ],
      "abstract": "For an approaching disaster, the tracking of time-sensitive critical\ninformation such as hurricane evacuation notices is challenging in the United\nStates. These notices are issued and distributed rapidly by numerous local\nauthorities that may spread across multiple states. They often undergo frequent\nupdates and are distributed through diverse online portals lacking standard\nformats. In this study, we developed an approach to timely detect and track the\nlocally issued hurricane evacuation notices. The text data were collected\nmainly with a spatially targeted web scraping method. They were manually\nlabeled and then classified using natural language processing techniques with\ndeep learning models. The classification of mandatory evacuation notices\nachieved a high accuracy (recall = 96%). We used Hurricane Ian (2022) to\nillustrate how real-time evacuation notices extracted from local government\nsources could be redistributed with a Web GIS system. Our method applied to\nfuture hurricanes provides live data for situation awareness to higher-level\ngovernment agencies and news media. The archived data helps scholars to study\ngovernment responses toward weather warnings and individual behaviors\ninfluenced by evacuation history. The framework may be applied to other types\nof disasters for rapid and targeted retrieval, classification, redistribution,\nand archiving of real-time government orders and notifications.",
      "tldr_zh": "本文提出了一种方法，用于实时检索和分类多源飓风疏散通知，以应对通知快速更新、跨州发布和格式不统一等挑战。主要采用空间针对的网络抓取技术收集数据，并结合Natural Language Processing (NLP)和深度学习模型进行分类，强制疏散通知的recall达到96%。以Hurricane Ian (2022)为例，该方法通过Web GIS系统重新分发通知，提供实时数据支持高层政府机构和新闻媒体的situation awareness，并可扩展至其他灾害的快速检索、分类和归档。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.06789v1",
      "published_date": "2024-01-07 16:35:30 UTC",
      "updated_date": "2024-01-07 16:35:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:17:01.988287"
    },
    {
      "arxiv_id": "2401.03531v1",
      "title": "A Heterogeneous RISC-V based SoC for Secure Nano-UAV Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Valente",
        "Alessandro Nadalini",
        "Asif Veeran",
        "Mattia Sinigaglia",
        "Bruno Sa",
        "Nils Wistoff",
        "Yvan Tortorella",
        "Simone Benatti",
        "Rafail Psiakis",
        "Ari Kulmala",
        "Baker Mohammad",
        "Sandro Pinto",
        "Daniele Palossi",
        "Luca Benini",
        "Davide Rossi"
      ],
      "abstract": "The rapid advancement of energy-efficient parallel ultra-low-power (ULP)\nucontrollers units (MCUs) is enabling the development of autonomous nano-sized\nunmanned aerial vehicles (nano-UAVs). These sub-10cm drones represent the next\ngeneration of unobtrusive robotic helpers and ubiquitous smart sensors.\nHowever, nano-UAVs face significant power and payload constraints while\nrequiring advanced computing capabilities akin to standard drones, including\nreal-time Machine Learning (ML) performance and the safe co-existence of\ngeneral-purpose and real-time OSs. Although some advanced parallel ULP MCUs\noffer the necessary ML computing capabilities within the prescribed power\nlimits, they rely on small main memories (<1MB) and ucontroller-class CPUs with\nno virtualization or security features, and hence only support simple\nbare-metal runtimes. In this work, we present Shaheen, a 9mm2 200mW SoC\nimplemented in 22nm FDX technology. Differently from state-of-the-art MCUs,\nShaheen integrates a Linux-capable RV64 core, compliant with the v1.0 ratified\nHypervisor extension and equipped with timing channel protection, along with a\nlow-cost and low-power memory controller exposing up to 512MB of off-chip\nlow-cost low-power HyperRAM directly to the CPU. At the same time, it\nintegrates a fully programmable energy- and area-efficient multi-core cluster\nof RV32 cores optimized for general-purpose DSP as well as reduced- and\nmixed-precision ML. To the best of the authors' knowledge, it is the first\nsilicon prototype of a ULP SoC coupling the RV64 and RV32 cores in a\nheterogeneous host+accelerator architecture fully based on the RISC-V ISA. We\ndemonstrate the capabilities of the proposed SoC on a wide range of benchmarks\nrelevant to nano-UAV applications. The cluster can deliver up to 90GOp/s and up\nto 1.8TOp/s/W on 2-bit integer kernels and up to 7.9GFLOp/s and up to\n150GFLOp/s/W on 16-bit FP kernels.",
      "tldr_zh": "这项研究提出了一种基于 RISC-V ISA 的异构 SoC 芯片 Shaheen，用于实现安全 nano-UAV 导航，旨在解决这些小型无人机的功率限制、实时 Machine Learning (ML) 需求以及通用和实时 OS 的安全共存问题。Shaheen 采用 22nm FDX 技术，集成 Linux-capable RV64 核心（支持 Hypervisor 扩展和定时通道保护）、高达 512MB 的 off-chip HyperRAM，以及一个优化 DSP 和 ML 的多核 RV32 集群，作为异构 host+accelerator 架构的首个硅原型。实验结果显示，该 SoC 在 nano-UAV 相关基准测试中，实现了 2-bit 整数内核高达 90GOp/s 和 1.8TOp/s/W 的性能，以及 16-bit FP 内核高达 7.9GFLOp/s 和 150GFLOp/s/W 的能效，为高效、安全的自主飞行提供了基础。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03531v1",
      "published_date": "2024-01-07 16:03:47 UTC",
      "updated_date": "2024-01-07 16:03:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:17:15.841848"
    },
    {
      "arxiv_id": "2401.03529v1",
      "title": "Quantifying stability of non-power-seeking in artificial agents",
      "title_zh": "翻译失败",
      "authors": [
        "Evan Ryan Gunter",
        "Yevgeny Liokumovich",
        "Victoria Krakovna"
      ],
      "abstract": "We investigate the question: if an AI agent is known to be safe in one\nsetting, is it also safe in a new setting similar to the first? This is a core\nquestion of AI alignment--we train and test models in a certain environment,\nbut deploy them in another, and we need to guarantee that models that seem safe\nin testing remain so in deployment. Our notion of safety is based on\npower-seeking--an agent which seeks power is not safe. In particular, we focus\non a crucial type of power-seeking: resisting shutdown. We model agents as\npolicies for Markov decision processes, and show (in two cases of interest)\nthat not resisting shutdown is \"stable\": if an MDP has certain policies which\ndon't avoid shutdown, the corresponding policies for a similar MDP also don't\navoid shutdown. We also show that there are natural cases where safety is _not_\nstable--arbitrarily small perturbations may result in policies which never shut\ndown. In our first case of interest--near-optimal policies--we use a\nbisimulation metric on MDPs to prove that small perturbations won't make the\nagent take longer to shut down. Our second case of interest is policies for\nMDPs satisfying certain constraints which hold for various models (including\nlanguage models). Here, we demonstrate a quantitative bound on how fast the\nprobability of not shutting down can increase: by defining a metric on MDPs;\nproving that the probability of not shutting down, as a function on MDPs, is\nlower semicontinuous; and bounding how quickly this function decreases.",
      "tldr_zh": "本研究探讨了AI代理的安全性稳定性问题：如果一个代理在特定环境中不寻求权力（non-power-seeking）且安全，在类似的新环境中是否仍保持安全，特别是针对抵抗关闭（resisting shutdown）的行为。研究将代理建模为Markov decision processes (MDPs)的策略，并在两种关键情况下证明不抵抗关闭的稳定性：近优策略（near-optimal policies）使用bisimulation metric显示小扰动不会延迟关闭；满足特定约束的策略（适用于语言模型等）则通过定义MDP度量和证明不关闭概率的lower semicontinuity，提供量化边界来限制不关闭概率的增加。结果表明，虽然某些情况下安全稳定，但其他自然场景中微小扰动可能导致代理永不关闭，从而为AI alignment提供重要洞见。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "37 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.03529v1",
      "published_date": "2024-01-07 15:57:38 UTC",
      "updated_date": "2024-01-07 15:57:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:17:25.293366"
    },
    {
      "arxiv_id": "2401.04141v1",
      "title": "On The Potential of The Fractal Geometry and The CNNs Ability to Encode it",
      "title_zh": "翻译失败",
      "authors": [
        "Julia El Zini",
        "Bassel Musharrafieh",
        "Mariette Awad"
      ],
      "abstract": "The fractal dimension provides a statistical index of object complexity by\nstudying how the pattern changes with the measuring scale. Although useful in\nseveral classification tasks, the fractal dimension is under-explored in deep\nlearning applications. In this work, we investigate the features that are\nlearned by deep models and we study whether these deep networks are able to\nencode features as complex and high-level as the fractal dimensions.\nSpecifically, we conduct a correlation analysis experiment to show that deep\nnetworks are not able to extract such a feature in none of their layers. We\ncombine our analytical study with a human evaluation to investigate the\ndifferences between deep learning networks and models that operate on the\nfractal feature solely. Moreover, we show the effectiveness of fractal features\nin applications where the object structure is crucial for the classification\ntask. We empirically show that training a shallow network on fractal features\nachieves performance comparable, even superior in specific cases, to that of\ndeep networks trained on raw data while requiring less computational resources.\nFractals improved the accuracy of the classification by 30% on average while\nrequiring up to 84% less time to train. We couple our empirical study with a\ncomplexity analysis of the computational cost of extracting the proposed\nfractal features, and we study its limitation.",
      "tldr_zh": "这篇论文探讨了分形维度（fractal dimension）作为物体复杂性指标在深度学习中的潜力，特别是 CNNs 是否能有效编码这种高级特征。通过相关性分析和人类评估，研究发现 CNNs 在任何层都无法提取分形维度特征，而基于分形特征的浅层网络在分类任务中表现出色。实验结果显示，使用分形特征训练模型可将分类准确率平均提高30%，训练时间减少高达84%，并对提取这些特征的计算成本和限制进行了分析。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04141v1",
      "published_date": "2024-01-07 15:22:56 UTC",
      "updated_date": "2024-01-07 15:22:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:17:37.741824"
    },
    {
      "arxiv_id": "2401.03512v3",
      "title": "CharPoet: A Chinese Classical Poetry Generation System Based on Token-free LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Chengyue Yu",
        "Lei Zang",
        "Jiaotuan Wang",
        "Chenyi Zhuang",
        "Jinjie Gu"
      ],
      "abstract": "Automatic Chinese classical poetry generation has attracted much research\ninterest, but achieving effective control over format and content\nsimultaneously remains challenging. Traditional systems usually accept keywords\nas user inputs, resulting in limited control over content. Large language\nmodels (LLMs) improve content control by allowing unrestricted user\ninstructions, but the token-by-token generation process frequently makes format\nerrors. Motivated by this, we propose CharPoet, a Chinese classical poetry\ngeneration system based on token-free LLM, which provides effective control\nover both format and content. Our token-free architecture generates in a\ncharacter-by-character manner, enabling precise control over the number of\ncharacters. Pruned from existing token-based LLMs, CharPoet inherits their\npretrained capabilities and can generate poetry following instructions like\n\"Write me a poem for my mother's birthday.\" CharPoet achieves format accuracy\nabove 0.96, outperforming Jiuge-GPT-2 (0.91) and GPT-4 (0.38). In terms of\ncontent quality, CharPoet surpasses traditional systems including Jiuge, and is\ncomparable to other LLMs. Our system is open source and available at\nhttps://modelscope.cn/models/CharPoet/CharPoet. A video demonstration of\nCharPoet is available at https://youtu.be/voZ25qEp3Dc.",
      "tldr_zh": "本文提出 CharPoet，一种基于 token-free LLM 的中文古典诗歌生成系统，旨在解决传统系统在格式和内容控制上的挑战，通过字符级生成方式实现对字符数的精确控制。系统从现有 token-based LLMs 修剪而来，继承预训练能力，能响应用户指令（如“为我母亲的生日写一首诗”）生成高质量诗歌。实验显示，CharPoet 的格式准确率超过 0.96，优于 Jiuge-GPT-2 (0.91) 和 GPT-4 (0.38)，内容质量也超越传统系统并与其他 LLMs 相当。该系统已开源，可在指定链接获取模型和视频演示。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03512v3",
      "published_date": "2024-01-07 15:00:36 UTC",
      "updated_date": "2024-03-20 07:39:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:17:50.419064"
    },
    {
      "arxiv_id": "2401.03504v1",
      "title": "ClusterComm: Discrete Communication in Decentralized MARL using Internal Representation Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Robert Müller",
        "Hasan Turalic",
        "Thomy Phan",
        "Michael Kölle",
        "Jonas Nüßlein",
        "Claudia Linnhoff-Popien"
      ],
      "abstract": "In the realm of Multi-Agent Reinforcement Learning (MARL), prevailing\napproaches exhibit shortcomings in aligning with human learning, robustness,\nand scalability. Addressing this, we introduce ClusterComm, a fully\ndecentralized MARL framework where agents communicate discretely without a\ncentral control unit. ClusterComm utilizes Mini-Batch-K-Means clustering on the\nlast hidden layer's activations of an agent's policy network, translating them\ninto discrete messages. This approach outperforms no communication and competes\nfavorably with unbounded, continuous communication and hence poses a simple yet\neffective strategy for enhancing collaborative task-solving in MARL.",
      "tldr_zh": "本研究针对 Multi-Agent Reinforcement Learning (MARL) 中的人类学习、鲁棒性和可扩展性不足，提出 ClusterComm 框架，这是一个完全去中心化的系统，允许代理通过离散通信进行协作。ClusterComm 方法利用 Mini-Batch-K-Means 聚类算法对代理策略网络最后一层隐藏层激活进行聚类，并将其转化为离散消息，从而实现高效的内部表示通信。该框架在实验中表现出色，优于无通信方案，并与无限制的连续通信相媲美，提供了一种简单有效的策略来提升 MARL 中的协作任务解决能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ICAART 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.03504v1",
      "published_date": "2024-01-07 14:53:43 UTC",
      "updated_date": "2024-01-07 14:53:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:18:01.398879"
    },
    {
      "arxiv_id": "2401.03499v1",
      "title": "Re:Draw -- Context Aware Translation as a Controllable Method for Artistic Production",
      "title_zh": "翻译失败",
      "authors": [
        "Joao Liborio Cardoso",
        "Francesco Banterle",
        "Paolo Cignoni",
        "Michael Wimmer"
      ],
      "abstract": "We introduce context-aware translation, a novel method that combines the\nbenefits of inpainting and image-to-image translation, respecting\nsimultaneously the original input and contextual relevance -- where existing\nmethods fall short. By doing so, our method opens new avenues for the\ncontrollable use of AI within artistic creation, from animation to digital art.\n  As an use case, we apply our method to redraw any hand-drawn animated\ncharacter eyes based on any design specifications - eyes serve as a focal point\nthat captures viewer attention and conveys a range of emotions, however, the\nlabor-intensive nature of traditional animation often leads to compromises in\nthe complexity and consistency of eye design. Furthermore, we remove the need\nfor production data for training and introduce a new character recognition\nmethod that surpasses existing work by not requiring fine-tuning to specific\nproductions. This proposed use case could help maintain consistency throughout\nproduction and unlock bolder and more detailed design choices without the\nproduction cost drawbacks. A user study shows context-aware translation is\npreferred over existing work 95.16% of the time.",
      "tldr_zh": "该论文提出了 context-aware translation，一种结合 inpainting 和 image-to-image translation 的新方法，能够同时尊重原始输入和上下文相关性，从而解决现有技术的不足，并为艺术创作提供更可控的工具。  \n作为具体应用，该方法用于重绘手绘动画角色的眼睛，根据设计规范实现一致性和复杂性提升，同时引入一种无需生产数据训练的新字符识别方法，避免了针对特定作品的微调。  \n用户研究显示，该方法在 95.16% 的情况下被优先选择，有助于在动画和数字艺术中实现更大胆的设计选择。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.MM",
        "I.2.6; I.2.1; J.5"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03499v1",
      "published_date": "2024-01-07 14:34:34 UTC",
      "updated_date": "2024-01-07 14:34:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:18:15.671814"
    },
    {
      "arxiv_id": "2401.03497v1",
      "title": "EAT: Self-Supervised Pre-Training with Efficient Audio Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxi Chen",
        "Yuzhe Liang",
        "Ziyang Ma",
        "Zhisheng Zheng",
        "Xie Chen"
      ],
      "abstract": "Audio self-supervised learning (SSL) pre-training, which aims to learn good\nrepresentations from unlabeled audio, has made remarkable progress. However,\nthe extensive computational demands during pre-training pose a significant\nbarrier to the potential application and optimization of audio SSL models. In\nthis paper, inspired by the success of data2vec 2.0 in image modality and\nAudio-MAE in audio modality, we introduce Efficient Audio Transformer (EAT) to\nfurther improve the effectiveness and efficiency in audio SSL. The proposed EAT\nadopts the bootstrap self-supervised training paradigm to the audio domain. A\nnovel Utterance-Frame Objective (UFO) is designed to enhance the modeling\ncapability of acoustic events. Furthermore, we reveal that the masking strategy\nis critical in audio SSL pre-training, and superior audio representations can\nbe obtained with large inverse block masks. Experiment results demonstrate that\nEAT achieves state-of-the-art (SOTA) performance on a range of audio-related\ntasks, including AudioSet (AS-2M, AS-20K), ESC-50, and SPC-2, along with a\nsignificant pre-training speedup up to ~15x compared to existing audio SSL\nmodels.",
      "tldr_zh": "本论文提出 Efficient Audio Transformer (EAT)，一种高效的音频自监督学习 (SSL) 预训练框架，旨在解决现有模型计算需求高的难题。EAT 借鉴 data2vec 2.0 和 Audio-MAE 的思路，采用 bootstrap 自监督训练范式，并设计了 Utterance-Frame Objective (UFO) 来提升对声学事件的建模能力，同时通过大型逆块掩码策略优化掩码处理。实验结果显示，EAT 在 AudioSet (AS-2M, AS-20K)、ESC-50 和 SPC-2 等任务上达到 SOTA 性能，并将预训练速度比现有音频 SSL 模型提升高达 15 倍。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03497v1",
      "published_date": "2024-01-07 14:31:27 UTC",
      "updated_date": "2024-01-07 14:31:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:18:24.802409"
    },
    {
      "arxiv_id": "2401.06788v2",
      "title": "The NPU-ASLP-LiAuto System Description for Visual Speech Recognition in CNVSRC 2023",
      "title_zh": "翻译失败",
      "authors": [
        "He Wang",
        "Pengcheng Guo",
        "Wei Chen",
        "Pan Zhou",
        "Lei Xie"
      ],
      "abstract": "This paper delineates the visual speech recognition (VSR) system introduced\nby the NPU-ASLP-LiAuto (Team 237) in the first Chinese Continuous Visual Speech\nRecognition Challenge (CNVSRC) 2023, engaging in the fixed and open tracks of\nSingle-Speaker VSR Task, and the open track of Multi-Speaker VSR Task. In terms\nof data processing, we leverage the lip motion extractor from the baseline1 to\nproduce multi-scale video data. Besides, various augmentation techniques are\napplied during training, encompassing speed perturbation, random rotation,\nhorizontal flipping, and color transformation. The VSR model adopts an\nend-to-end architecture with joint CTC/attention loss, comprising a ResNet3D\nvisual frontend, an E-Branchformer encoder, and a Transformer decoder.\nExperiments show that our system achieves 34.76% CER for the Single-Speaker\nTask and 41.06% CER for the Multi-Speaker Task after multi-system fusion,\nranking first place in all three tracks we participate.",
      "tldr_zh": "这篇论文介绍了 NPU-ASLP-LiAuto 团队在 CNVSRC 2023 视觉语音识别 (VSR) 挑战中的系统，参与了单说话者和多说话者任务的固定和开放赛道。系统采用多尺度视频数据处理，包括唇部运动提取器，并应用多种增强技术如速度扰动、随机旋转、水平翻转和颜色变换；模型架构为端到端设计，使用联合 CTC/attention 损失，结合 ResNet3D 视觉前端、E-Branchformer 编码器和 Transformer 解码器。实验结果显示，该系统在单说话者任务中达到 34.76% CER，在多说话者任务中达到 41.06% CER，并通过多系统融合在所有参与赛道中排名第一。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Included in CNVSRC Workshop 2023, NCMMSC 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.06788v2",
      "published_date": "2024-01-07 14:20:52 UTC",
      "updated_date": "2024-02-29 18:09:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:18:39.564052"
    },
    {
      "arxiv_id": "2401.03489v1",
      "title": "Decentralized Federated Policy Gradient with Byzantine Fault-Tolerance and Provably Fast Convergence",
      "title_zh": "去中心化联邦策略梯度算法，具有拜占庭容错和可证明",
      "authors": [
        "Philip Jordan",
        "Florian Grötschla",
        "Flint Xiaofeng Fan",
        "Roger Wattenhofer"
      ],
      "abstract": "In Federated Reinforcement Learning (FRL), agents aim to collaboratively\nlearn a common task, while each agent is acting in its local environment\nwithout exchanging raw trajectories. Existing approaches for FRL either (a) do\nnot provide any fault-tolerance guarantees (against misbehaving agents), or (b)\nrely on a trusted central agent (a single point of failure) for aggregating\nupdates. We provide the first decentralized Byzantine fault-tolerant FRL\nmethod. Towards this end, we first propose a new centralized Byzantine\nfault-tolerant policy gradient (PG) algorithm that improves over existing\nmethods by relying only on assumptions standard for non-fault-tolerant PG.\nThen, as our main contribution, we show how a combination of robust aggregation\nand Byzantine-resilient agreement methods can be leveraged in order to\neliminate the need for a trusted central entity. Since our results represent\nthe first sample complexity analysis for Byzantine fault-tolerant decentralized\nfederated non-convex optimization, our technical contributions may be of\nindependent interest. Finally, we corroborate our theoretical results\nexperimentally for common RL environments, demonstrating the speed-up of\ndecentralized federations w.r.t. the number of participating agents and\nresilience against various Byzantine attacks.",
      "tldr_zh": "该论文针对 Federated Reinforcement Learning (FRL) 中的挑战，提出了一种首个去中心化的 Byzantine fault-tolerant 策略梯度 (PG) 方法，该方法无需可信中心实体即可处理代理故障问题。作者首先开发了一个基于标准非容错 PG 假设的中心化 Byzantine fault-tolerant 算法，然后通过 robust aggregation 和 Byzantine-resilient agreement 技术实现去中心化协作。实验结果显示，该方法在常见 RL 环境中的收敛速度更快，并证明了对各种 Byzantine attacks 的鲁棒性，同时提供了 Byzantine fault-tolerant decentralized federated non-convex optimization 的样本复杂度分析。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AAMAS'24",
      "pdf_url": "http://arxiv.org/pdf/2401.03489v1",
      "published_date": "2024-01-07 14:06:06 UTC",
      "updated_date": "2024-01-07 14:06:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:18:49.996780"
    },
    {
      "arxiv_id": "2401.03476v1",
      "title": "Freetalker: Controllable Speech and Text-Driven Gesture Generation Based on Diffusion Models for Enhanced Speaker Naturalness",
      "title_zh": "翻译失败",
      "authors": [
        "Sicheng Yang",
        "Zunnan Xu",
        "Haiwei Xue",
        "Yongkang Cheng",
        "Shaoli Huang",
        "Mingming Gong",
        "Zhiyong Wu"
      ],
      "abstract": "Current talking avatars mostly generate co-speech gestures based on audio and\ntext of the utterance, without considering the non-speaking motion of the\nspeaker. Furthermore, previous works on co-speech gesture generation have\ndesigned network structures based on individual gesture datasets, which results\nin limited data volume, compromised generalizability, and restricted speaker\nmovements. To tackle these issues, we introduce FreeTalker, which, to the best\nof our knowledge, is the first framework for the generation of both spontaneous\n(e.g., co-speech gesture) and non-spontaneous (e.g., moving around the podium)\nspeaker motions. Specifically, we train a diffusion-based model for speaker\nmotion generation that employs unified representations of both speech-driven\ngestures and text-driven motions, utilizing heterogeneous data sourced from\nvarious motion datasets. During inference, we utilize classifier-free guidance\nto highly control the style in the clips. Additionally, to create smooth\ntransitions between clips, we utilize DoubleTake, a method that leverages a\ngenerative prior and ensures seamless motion blending. Extensive experiments\nshow that our method generates natural and controllable speaker movements. Our\ncode, model, and demo are are available at\n\\url{https://youngseng.github.io/FreeTalker/}.",
      "tldr_zh": "该研究引入了FreeTalker框架，这是首个基于diffusion models的系统，能够生成自发（如co-speech gestures）和非自发（如讲台上走动）的说话者动作，从而提升说话者的自然性。FreeTalker采用统一的表示方式训练模型，利用异构数据源来处理speech-driven gestures和text-driven motions，并在推理阶段通过classifier-free guidance实现对动作风格的高精度控制。实验结果显示，该框架能产生平滑过渡（借助DoubleTake方法）和高度可控的自然动作，证明了其在生成说话者运动方面的有效性。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.HC",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.MM",
      "comment": "6 pages, 3 figures, ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.03476v1",
      "published_date": "2024-01-07 13:01:29 UTC",
      "updated_date": "2024-01-07 13:01:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:19:01.630964"
    },
    {
      "arxiv_id": "2401.03473v3",
      "title": "ICMC-ASR: The ICASSP 2024 In-Car Multi-Channel Automatic Speech Recognition Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "He Wang",
        "Pengcheng Guo",
        "Yue Li",
        "Ao Zhang",
        "Jiayao Sun",
        "Lei Xie",
        "Wei Chen",
        "Pan Zhou",
        "Hui Bu",
        "Xin Xu",
        "Binbin Zhang",
        "Zhuo Chen",
        "Jian Wu",
        "Longbiao Wang",
        "Eng Siong Chng",
        "Sun Li"
      ],
      "abstract": "To promote speech processing and recognition research in driving scenarios,\nwe build on the success of the Intelligent Cockpit Speech Recognition Challenge\n(ICSRC) held at ISCSLP 2022 and launch the ICASSP 2024 In-Car Multi-Channel\nAutomatic Speech Recognition (ICMC-ASR) Challenge. This challenge collects over\n100 hours of multi-channel speech data recorded inside a new energy vehicle and\n40 hours of noise for data augmentation. Two tracks, including automatic speech\nrecognition (ASR) and automatic speech diarization and recognition (ASDR) are\nset up, using character error rate (CER) and concatenated minimum permutation\ncharacter error rate (cpCER) as evaluation metrics, respectively. Overall, the\nICMC-ASR Challenge attracts 98 participating teams and receives 53 valid\nresults in both tracks. In the end, first-place team USTCiflytek achieves a CER\nof 13.16% in the ASR track and a cpCER of 21.48% in the ASDR track, showing an\nabsolute improvement of 13.08% and 51.4% compared to our challenge baseline,\nrespectively.",
      "tldr_zh": "ICMC-ASR 挑战是 ICASSP 2024 举办的 In-Car Multi-Channel Automatic Speech Recognition 比赛，旨在促进驾驶场景下的语音处理和识别研究，基于之前的 ICSRC 挑战收集了超过 100 小时的多通道语音数据和 40 小时的噪声数据用于增强。\n该挑战设置了两个赛道：Automatic Speech Recognition (ASR) 和 Automatic Speech Diarization and Recognition (ASDR)，分别使用 Character Error Rate (CER) 和 Concatenated Minimum Permutation Character Error Rate (cpCER) 作为评估指标。\n挑战吸引了 98 个团队提交 53 个有效结果，最终第一名团队 USTCiflytek 在 ASR 赛道达到 13.16% CER，在 ASDR 赛道达到 21.48% cpCER，比基线系统分别提高了 13.08% 和 51.4%。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.03473v3",
      "published_date": "2024-01-07 12:51:42 UTC",
      "updated_date": "2024-02-21 03:39:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:19:15.666898"
    },
    {
      "arxiv_id": "2401.04138v1",
      "title": "Expanding Horizons in HCI Research Through LLM-Driven Qualitative Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Maya Grace Torii",
        "Takahito Murakami",
        "Yoichi Ochiai"
      ],
      "abstract": "How would research be like if we still needed to \"send\" papers typed with a\ntypewriter? Our life and research environment have continually evolved, often\naccompanied by controversial opinions about new methodologies. In this paper,\nwe embrace this change by introducing a new approach to qualitative analysis in\nHCI using Large Language Models (LLMs). We detail a method that uses LLMs for\nqualitative data analysis and present a quantitative framework using SBART\ncosine similarity for performance evaluation. Our findings indicate that LLMs\nnot only match the efficacy of traditional analysis methods but also offer\nunique insights. Through a novel dataset and benchmark, we explore LLMs'\ncharacteristics in HCI research, suggesting potential avenues for further\nexploration and application in the field.",
      "tldr_zh": "本论文探讨了在人机交互(HCI)研究中使用大型语言模型(LLMs)进行定性分析的新方法，以适应研究环境的演变。该方法详细阐述了LLMs在数据分析中的应用，并引入SBART余弦相似度作为量化评估框架。研究结果显示，LLMs不仅与传统方法具有相媲美的效能，还能提供独特见解；通过一个新数据集和基准，论文揭示了LLMs在HCI领域的特性，并建议了进一步的应用方向。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04138v1",
      "published_date": "2024-01-07 12:39:31 UTC",
      "updated_date": "2024-01-07 12:39:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:19:25.128541"
    },
    {
      "arxiv_id": "2401.15081v1",
      "title": "Can generative AI and ChatGPT outperform humans on cognitive-demanding problem-solving tasks in science?",
      "title_zh": "生成式 AI 和 Chat",
      "authors": [
        "Xiaoming Zhai",
        "Matthew Nyaaba",
        "Wenchao Ma"
      ],
      "abstract": "This study aimed to examine an assumption that generative artificial\nintelligence (GAI) tools can overcome the cognitive intensity that humans\nsuffer when solving problems. We compared the performance of ChatGPT and GPT-4\non 2019 NAEP science assessments with students by cognitive demands of the\nitems. Fifty-four tasks were coded by experts using a two-dimensional cognitive\nload framework, including task cognitive complexity and dimensionality. ChatGPT\nand GPT-4 responses were scored using the scoring keys of NAEP. The analysis of\nthe available data was based on the average student ability scores for students\nwho answered each item correctly and the percentage of students who responded\nto individual items. Results showed that both ChatGPT and GPT-4 consistently\noutperformed most students who answered the NAEP science assessments. As the\ncognitive demand for NAEP tasks increases, statistically higher average student\nability scores are required to correctly address the questions. This pattern\nwas observed for students in grades 4, 8, and 12, respectively. However,\nChatGPT and GPT-4 were not statistically sensitive to the increase in cognitive\ndemands of the tasks, except for Grade 4. As the first study focusing on\ncomparing GAI and K-12 students in problem-solving in science, this finding\nimplies the need for changes to educational objectives to prepare students with\ncompetence to work with GAI tools in the future. Education ought to emphasize\nthe cultivation of advanced cognitive skills rather than depending solely on\ntasks that demand cognitive intensity. This approach would foster critical\nthinking, analytical skills, and the application of knowledge in novel\ncontexts. Findings also suggest the need for innovative assessment practices by\nmoving away from cognitive intensity tasks toward creativity and analytical\nskills to avoid the negative effects of GAI on testing more efficiently.",
      "tldr_zh": "这篇论文探讨了生成式 AI（如 ChatGPT 和 GPT-4）是否能在认知密集型科学问题解决任务中超越人类表现，研究比较了 AI 与 K-12 学生在 2019 NAEP 科学评估中的表现。研究者使用专家编码的 54 个任务，基于认知负荷框架（包括任务认知复杂性和维度）进行分析，并根据 NAEP 评分标准评估 AI 和学生响应。结果显示，ChatGPT 和 GPT-4 通常优于大多数学生，且对任务认知需求增加不敏感（除了四年级），这表明 AI 在高认知需求场景下更稳定。作为首次此类比较，论文建议教育目标应转向培养高级认知技能（如批判性思维和分析能力），并创新评估实践，以适应 GAI 工具的广泛应用。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15081v1",
      "published_date": "2024-01-07 12:36:31 UTC",
      "updated_date": "2024-01-07 12:36:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:19:39.552435"
    },
    {
      "arxiv_id": "2401.03470v2",
      "title": "FurniScene: A Large-scale 3D Room Dataset with Intricate Furnishing Scenes",
      "title_zh": "翻译失败",
      "authors": [
        "Genghao Zhang",
        "Yuxi Wang",
        "Chuanchen Luo",
        "Shibiao Xu",
        "Zhaoxiang Zhang",
        "Man Zhang",
        "Junran Peng"
      ],
      "abstract": "Indoor scene generation has attracted significant attention recently as it is\ncrucial for applications of gaming, virtual reality, and interior design.\nCurrent indoor scene generation methods can produce reasonable room layouts but\noften lack diversity and realism. This is primarily due to the limited coverage\nof existing datasets, including only large furniture without tiny furnishings\nin daily life. To address these challenges, we propose FurniScene, a\nlarge-scale 3D room dataset with intricate furnishing scenes from interior\ndesign professionals. Specifically, the FurniScene consists of 11,698 rooms and\n39,691 unique furniture CAD models with 89 different types, covering things\nfrom large beds to small teacups on the coffee table. To better suit\nfine-grained indoor scene layout generation, we introduce a novel Two-Stage\nDiffusion Scene Model (TSDSM) and conduct an evaluation benchmark for various\nindoor scene generation based on FurniScene. Quantitative and qualitative\nevaluations demonstrate the capability of our method to generate highly\nrealistic indoor scenes. Our dataset and code will be publicly available soon.",
      "tldr_zh": "该论文介绍了 FurniScene，一个大规模的 3D 房间数据集，旨在解决现有室内场景生成方法在多样性和真实性方面的不足，通过包含复杂的家具场景提升应用如游戏、虚拟现实和室内设计的性能。数据集包括 11,698 个房间和 39,691 个独特家具 CAD 模型，覆盖 89 种类型，从大型床具到微小茶杯。作者提出了一种新颖的 Two-Stage Diffusion Scene Model (TSDSM)，用于细粒度的室内场景布局生成，并建立了一个评估基准。定量和定性评估表明，该方法能生成高度真实的室内场景，且数据集和代码将公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03470v2",
      "published_date": "2024-01-07 12:34:45 UTC",
      "updated_date": "2024-05-06 06:33:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:19:51.212742"
    },
    {
      "arxiv_id": "2401.03469v3",
      "title": "Efficient Test Data Generation for MC/DC with OCL and Search",
      "title_zh": "翻译失败",
      "authors": [
        "Hassan Sartaj",
        "Muhammad Zohaib Iqbal",
        "Atif Aftab Ahmed Jilani",
        "Muhammad Uzair Khan"
      ],
      "abstract": "System-level testing of avionics software systems requires compliance with\ndifferent international safety standards such as DO-178C. An important\nconsideration of the avionics industry is automated test data generation\naccording to the criteria suggested by safety standards. One of the recommended\ncriteria by DO-178C is the modified condition/decision coverage (MC/DC)\ncriterion. The current model-based test data generation approaches use\nconstraints written in Object Constraint Language (OCL), and apply search\ntechniques to generate test data. These approaches either do not support MC/DC\ncriterion or suffer from performance issues while generating test data for\nlarge-scale avionics systems. In this paper, we propose an effective way to\nautomate MC/DC test data generation during model-based testing. We develop a\nstrategy that utilizes case-based reasoning (CBR) and range reduction\nheuristics designed to solve MC/DC-tailored OCL constraints. We performed an\nempirical study to compare our proposed strategy for MC/DC test data generation\nusing CBR, range reduction, both CBR and range reduction, with an original\nsearch algorithm, and random search. We also empirically compared our strategy\nwith existing constraint-solving approaches. The results show that both CBR and\nrange reduction for MC/DC test data generation outperform the baseline\napproach. Moreover, the combination of both CBR and range reduction for MC/DC\ntest data generation is an effective approach compared to existing constraint\nsolvers.",
      "tldr_zh": "本论文针对航空电子软件系统的系统级测试，提出了一种高效的 MC/DC 测试数据生成方法，以符合 DO-178C 安全标准。方法利用 Object Constraint Language (OCL) 约束结合 case-based reasoning (CBR) 和 range reduction heuristics，针对 MC/DC 标准优化测试数据生成过程，从而解决现有方法的性能问题。实证研究结果显示，该策略单独或结合使用时均优于基线搜索算法和随机搜索，且整体效果超越现有约束求解器，为大规模航空系统测试提供了更有效的自动化解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03469v3",
      "published_date": "2024-01-07 12:31:36 UTC",
      "updated_date": "2024-08-02 11:39:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:20:01.895941"
    },
    {
      "arxiv_id": "2401.03467v1",
      "title": "Maintaining Journalistic Integrity in the Digital Age: A Comprehensive NLP Framework for Evaluating Online News Content",
      "title_zh": "在数字时代维护新闻诚信：一个全面的自然语言处理框架用于评估在线新闻内容",
      "authors": [
        "Ljubisa Bojic",
        "Nikola Prodanovic",
        "Agariadne Dwinggo Samala"
      ],
      "abstract": "The rapid growth of online news platforms has led to an increased need for\nreliable methods to evaluate the quality and credibility of news articles. This\npaper proposes a comprehensive framework to analyze online news texts using\nnatural language processing (NLP) techniques, particularly a language model\nspecifically trained for this purpose, alongside other well-established NLP\nmethods. The framework incorporates ten journalism standards-objectivity,\nbalance and fairness, readability and clarity, sensationalism and clickbait,\nethical considerations, public interest and value, source credibility,\nrelevance and timeliness, factual accuracy, and attribution and transparency-to\nassess the quality of news articles. By establishing these standards,\nresearchers, media organizations, and readers can better evaluate and\nunderstand the content they consume and produce. The proposed method has some\nlimitations, such as potential difficulty in detecting subtle biases and the\nneed for continuous updating of the language model to keep pace with evolving\nlanguage patterns.",
      "tldr_zh": "本论文提出一个全面的 NLP 框架，用于评估在线新闻内容的质量和可信度，以维护数字时代的新闻诚信（journalistic integrity）。该框架利用专门训练的语言模型（language model）以及其他 NLP 技术，基于十个新闻标准（objectivity, balance and fairness, readability and clarity, sensationalism and clickbait, ethical considerations, public interest and value, source credibility, relevance and timeliness, factual accuracy, and attribution and transparency）来分析新闻文章。研究结果显示，该框架能帮助研究人员、媒体组织和读者更好地评估新闻内容，但存在局限性，如难以检测微妙偏差（subtle biases）和语言模型需要持续更新以适应语言演变。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.03467v1",
      "published_date": "2024-01-07 12:27:14 UTC",
      "updated_date": "2024-01-07 12:27:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:20:13.541878"
    },
    {
      "arxiv_id": "2401.03462v3",
      "title": "Long Context Compression with Activation Beacon",
      "title_zh": "翻译失败",
      "authors": [
        "Peitian Zhang",
        "Zheng Liu",
        "Shitao Xiao",
        "Ninglu Shao",
        "Qiwei Ye",
        "Zhicheng Dou"
      ],
      "abstract": "Long context compression is a critical research problem due to its\nsignificance in reducing the high computational and memory costs associated\nwith LLMs. In this paper, we propose Activation Beacon, a plug-in module for\ntransformer-based LLMs that targets effective, efficient, and flexible\ncompression of long contexts. To achieve this, our method introduces the\nfollowing technical designs. 1) We directly compress the activations (i.e. keys\nand values at every layer), rather than leveraging soft prompts to relay\ninformation (which constitute a major bottleneck to encapsulate the complex\ninformation within long contexts). 2) We tailor the compression workflow, where\neach fine-grained input unit is progressively compressed, enabling high-quality\ncompression and efficient computation during both training and inference. 3) We\ntrain the model through compression-based auto-regression, making full use of\nplain texts and instructional data to optimize the model's compression\nperformance. 4) During training, we randomly sample a compression ratio at each\nstep, teaching the model to support a wide range of compression configurations.\nExtensive evaluations are conducted on various long-context tasks whose lengths\n(e.g., 128K) may far exceed the maximum training length (20K), such as document\nunderstanding, few-shot learning, and Needle-in-a-Haystack. Whilst existing\nmethods struggle to handle these challenging tasks, Activation Beacon maintains\na comparable performance to the uncompressed baseline across various scenarios,\nachieving a 2x acceleration in inference time and an 8x reduction of memory\ncosts for KV cache. Our data, model, and code have been released at\n\\url{https://github.com/FlagOpen/FlagEmbedding/}.",
      "tldr_zh": "本论文提出 Activation Beacon，一种插件模块，用于 transformer-based LLMs 的长上下文压缩，以显著降低计算和内存成本。该方法直接压缩 activations（如 keys and values at every layer），并通过定制压缩工作流、compression-based auto-regression 训练以及随机采样 compression ratio，实现高效、灵活的压缩过程。实验在各种长上下文任务（如 document understanding、few-shot learning 和 Needle-in-a-Haystack）上显示，Activation Beacon 在长度远超训练极限（128K vs. 20K）的场景中，维持了与未压缩基线相当的性能，同时实现了 2x 推理时间加速和 8x KV cache 内存减少。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Newer version of Activation Beacon",
      "pdf_url": "http://arxiv.org/pdf/2401.03462v3",
      "published_date": "2024-01-07 11:57:40 UTC",
      "updated_date": "2024-10-11 02:18:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:20:27.318787"
    },
    {
      "arxiv_id": "2401.03461v1",
      "title": "Amplification of Addictive New Media Features in the Metaverse",
      "title_zh": "翻译失败",
      "authors": [
        "Ljubisa Bojic",
        "Joerg Matthes",
        "Milan Cabarkapa"
      ],
      "abstract": "The emergence of the metaverse, envisioned as a hyperreal virtual universe\nfacilitating boundless human interaction, stands to revolutionize our\nconception of media, with significant impacts on addiction, creativity,\nrelationships, and social polarization. This paper aims to dissect the\naddictive potential of the metaverse due to its immersive and interactive\nfeatures, scrutinize the effects of its recommender systems on creativity and\nsocial polarization, and explore potential consequences stemming from the\nmetaverse development. We employed a literature review methodology, drawing\nparallels from the research on new media platforms and examining the\nprogression of reality-mimicking features in media from historical perspectives\nto understand this transformative digital frontier. The findings suggest that\nthese immersive and interactive features could potentially exacerbate media\naddiction. The designed recommender systems, while aiding personalization and\nuser engagement, might contribute to social polarization and affect the\ndiversity of creative output. However, our conclusions are based primarily on\ntheoretical propositions from studies conducted on existing media platforms and\nlack empirical support specific to the metaverse. Therefore, this paper\nidentifies a critical gap requiring further research, through empirical studies\nfocused on metaverse use and addiction and exploration of privacy, security,\nand ethical implications associated with this burgeoning digital universe. As\nthe development of the metaverse accelerates, it is incumbent on scholars,\ntechnologists, and policymakers to navigate its multilayered impacts\nthoughtfully to balance innovation with societal well-being.",
      "tldr_zh": "这篇论文探讨了元宇宙(metaverse)的沉浸式和互动特征如何放大媒体成瘾问题，并分析其推荐系统(recommender systems)对创造力、社会极化和人际关系的影响。研究采用文献综述方法，从历史媒体发展角度审视这些特征的潜在后果，发现它们可能加剧成瘾、减少创造力多样性和加深社会极化。论文强调，由于缺乏针对元宇宙的实证数据，未来需进行更多实证研究，以探讨隐私、安全和伦理问题，并呼吁学者、技术人员和政策制定者平衡创新与社会福祉。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "14 pages, 1 figure, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2401.03461v1",
      "published_date": "2024-01-07 11:50:07 UTC",
      "updated_date": "2024-01-07 11:50:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:20:42.092902"
    },
    {
      "arxiv_id": "2403.07879v1",
      "title": "AI incidents and 'networked trouble': The case for a research agenda",
      "title_zh": "翻译失败",
      "authors": [
        "Tommy Shaffer Shane"
      ],
      "abstract": "Against a backdrop of widespread interest in how publics can participate in\nthe design of AI, I argue for a research agenda focused on AI incidents -\nexamples of AI going wrong and sparking controversy - and how they are\nconstructed in online environments. I take up the example of an AI incident\nfrom September 2020, when a Twitter user created a 'horrible experiment' to\ndemonstrate the racist bias of Twitter's algorithm for cropping images. This\nresulted in Twitter not only abandoning its use of that algorithm, but also\ndisavowing its decision to use any algorithm for the task. I argue that AI\nincidents like this are a significant means for participating in AI systems\nthat require further research. That research agenda, I argue, should focus on\nhow incidents are constructed through networked online behaviours that I refer\nto as 'networked trouble', where formats for participation enable individuals\nand algorithms to interact in ways that others - including technology companies\n- come to know and come to care about. At stake, I argue, is an important\nmechanism for participating in the design and deployment of AI.",
      "tldr_zh": "这篇论文主张建立一个研究议程，聚焦于 AI incidents（AI 出错并引发争议的事件）及其在在线环境中的构建方式。作者以 2020 年 Twitter 用户通过实验揭示图像裁剪算法种族偏见为例，探讨了 'networked trouble'——一种通过网络化在线行为（如个体与算法的互动）来推动公众参与和科技公司回应的机制。最终，论文强调，这种事件是影响 AI 系统设计和部署的重要途径，需要进一步研究。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07879v1",
      "published_date": "2024-01-07 11:23:13 UTC",
      "updated_date": "2024-01-07 11:23:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:20:51.943169"
    },
    {
      "arxiv_id": "2401.03454v1",
      "title": "Computational Argumentation-based Chatbots: a Survey",
      "title_zh": "基于计算论证的聊天机器人：一个调查",
      "authors": [
        "Federico Castagna",
        "Nadin Kokciyan",
        "Isabel Sassoon",
        "Simon Parsons",
        "Elizabeth Sklar"
      ],
      "abstract": "Chatbots are conversational software applications designed to interact\ndialectically with users for a plethora of different purposes. Surprisingly,\nthese colloquial agents have only recently been coupled with computational\nmodels of arguments (i.e. computational argumentation), whose aim is to\nformalise, in a machine-readable format, the ordinary exchange of information\nthat characterises human communications. Chatbots may employ argumentation with\ndifferent degrees and in a variety of manners. The present survey sifts through\nthe literature to review papers concerning this kind of argumentation-based\nbot, drawing conclusions about the benefits and drawbacks that this approach\nentails in comparison with standard chatbots, while also envisaging possible\nfuture development and integration with the Transformer-based architecture and\nstate-of-the-art Large Language models.",
      "tldr_zh": "这篇调查论文探讨了基于计算 argumentation 的聊天机器人（chatbots），这些机器人利用计算论证模型来形式化人类对话交互，从而提升对话的辩证性。论文通过文献审查，分析了论证模型在聊天机器人中的应用方式，包括不同程度的整合和实现方法，并比较了这种方法与传统聊天机器人的优势（如更精确的信息交换）和劣势（如复杂性增加）。最终，论文展望了未来发展，可能与 Transformer-based architecture 和 Large Language models 整合，以进一步提升聊天机器人的性能和适用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03454v1",
      "published_date": "2024-01-07 11:20:42 UTC",
      "updated_date": "2024-01-07 11:20:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:21:02.890036"
    },
    {
      "arxiv_id": "2401.03428v1",
      "title": "Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects",
      "title_zh": "翻译失败",
      "authors": [
        "Yuheng Cheng",
        "Ceyao Zhang",
        "Zhengwen Zhang",
        "Xiangrui Meng",
        "Sirui Hong",
        "Wenhao Li",
        "Zihao Wang",
        "Zekai Wang",
        "Feng Yin",
        "Junhua Zhao",
        "Xiuqiang He"
      ],
      "abstract": "Intelligent agents stand out as a potential path toward artificial general\nintelligence (AGI). Thus, researchers have dedicated significant effort to\ndiverse implementations for them. Benefiting from recent progress in large\nlanguage models (LLMs), LLM-based agents that use universal natural language as\nan interface exhibit robust generalization capabilities across various\napplications -- from serving as autonomous general-purpose task assistants to\napplications in coding, social, and economic domains, LLM-based agents offer\nextensive exploration opportunities. This paper surveys current research to\nprovide an in-depth overview of LLM-based intelligent agents within\nsingle-agent and multi-agent systems. It covers their definitions, research\nframeworks, and foundational components such as their composition, cognitive\nand planning methods, tool utilization, and responses to environmental\nfeedback. We also delve into the mechanisms of deploying LLM-based agents in\nmulti-agent systems, including multi-role collaboration, message passing, and\nstrategies to alleviate communication issues between agents. The discussions\nalso shed light on popular datasets and application scenarios. We conclude by\nenvisioning prospects for LLM-based agents, considering the evolving landscape\nof AI and natural language processing.",
      "tldr_zh": "这篇论文探讨了基于 Large Language Models (LLMs) 的智能代理（intelligent agents），定义它们作为通往人工通用智能 (AGI) 的潜在路径，并调研了其在单代理和多代理系统中的研究框架和核心组件，如组成、认知方法、规划策略、工具利用以及环境反馈响应。论文分析了多代理系统的协作机制，包括多角色协作、消息传递策略，以缓解通信问题，并在任务助理、编码、社会和经济领域展示了这些代理的强大泛化能力。研究还总结了热门数据集和应用场景，并展望了 LLM-based agents 在 AI 和自然语言处理领域的未来发展前景。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03428v1",
      "published_date": "2024-01-07 09:08:24 UTC",
      "updated_date": "2024-01-07 09:08:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:21:16.823871"
    },
    {
      "arxiv_id": "2401.03426v2",
      "title": "On Leveraging Large Language Models for Enhancing Entity Resolution: A Cost-efficient Approach",
      "title_zh": "利用大型语言模型增强实体解析：一种成本高效方法",
      "authors": [
        "Huahang Li",
        "Longyu Feng",
        "Shuangyin Li",
        "Fei Hao",
        "Chen Jason Zhang",
        "Yuanfeng Song"
      ],
      "abstract": "Entity resolution, the task of identifying and merging records that refer to\nthe same real-world entity, is crucial in sectors like e-commerce, healthcare,\nand law enforcement. Large Language Models (LLMs) introduce an innovative\napproach to this task, capitalizing on their advanced linguistic capabilities\nand a ``pay-as-you-go'' model that provides significant advantages to those\nwithout extensive data science expertise. However, current LLMs are costly due\nto per-API request billing. Existing methods often either lack quality or\nbecome prohibitively expensive at scale. To address these problems, we propose\nan uncertainty reduction framework using LLMs to improve entity resolution\nresults. We first initialize possible partitions of the entity cluster, refer\nto the same entity, and define the uncertainty of the result. Then, we reduce\nthe uncertainty by selecting a few valuable matching questions for LLM\nverification. Upon receiving the answers, we update the probability\ndistribution of the possible partitions. To further reduce costs, we design an\nefficient algorithm to judiciously select the most valuable matching pairs to\nquery. Additionally, we create error-tolerant techniques to handle LLM mistakes\nand a dynamic adjustment method to reach truly correct partitions. Experimental\nresults show that our method is efficient and effective, offering promising\napplications in real-world tasks.",
      "tldr_zh": "这篇论文探讨了如何利用大型语言模型（LLMs）提升实体解析（Entity Resolution）的效率，同时解决其高成本问题。作者提出一个不确定性减少框架，通过初始化实体集群的可能分区、选择有价值的匹配问题进行LLM验证，并基于答案更新概率分布来优化解析过程。为了降低API请求费用，他们设计了高效算法优先选择最有价值的匹配对，并加入了容错技术和动态调整方法以处理LLM错误和确保准确性。实验结果显示，该方法在真实任务中高效且有效，提供了一种成本优化的实用方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, preprint under review",
      "pdf_url": "http://arxiv.org/pdf/2401.03426v2",
      "published_date": "2024-01-07 09:06:58 UTC",
      "updated_date": "2024-09-12 04:47:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:21:28.712968"
    },
    {
      "arxiv_id": "2401.03424v3",
      "title": "MLCA-AVSR: Multi-Layer Cross Attention Fusion based Audio-Visual Speech Recognition",
      "title_zh": "MLCA-AVSR：基于多层交叉注意力融合的音频-视觉语音识别",
      "authors": [
        "He Wang",
        "Pengcheng Guo",
        "Pan Zhou",
        "Lei Xie"
      ],
      "abstract": "While automatic speech recognition (ASR) systems degrade significantly in\nnoisy environments, audio-visual speech recognition (AVSR) systems aim to\ncomplement the audio stream with noise-invariant visual cues and improve the\nsystem's robustness. However, current studies mainly focus on fusing the\nwell-learned modality features, like the output of modality-specific encoders,\nwithout considering the contextual relationship during the modality feature\nlearning. In this study, we propose a multi-layer cross-attention fusion based\nAVSR (MLCA-AVSR) approach that promotes representation learning of each\nmodality by fusing them at different levels of audio/visual encoders.\nExperimental results on the MISP2022-AVSR Challenge dataset show the efficacy\nof our proposed system, achieving a concatenated minimum permutation character\nerror rate (cpCER) of 30.57% on the Eval set and yielding up to 3.17% relative\nimprovement compared with our previous system which ranked the second place in\nthe challenge. Following the fusion of multiple systems, our proposed approach\nsurpasses the first-place system, establishing a new SOTA cpCER of 29.13% on\nthis dataset.",
      "tldr_zh": "该论文针对传统ASR在嘈杂环境中的性能下降问题，提出MLCA-AVSR方法，该方法通过多层交叉注意力融合在音频和视觉编码器的不同层级，促进模态特征的表示学习和上下文关系建模。相比于仅在后期融合特征的现有方法，MLCA-AVSR显著提升了AVSR系统的鲁棒性。在MISP2022-AVSR数据集上，实验结果显示Eval集的cpCER为30.57%，较之前系统相对改善3.17%，并通过多系统融合达到新的SOTA cpCER 29.13%。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 3 figures Accepted at ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.03424v3",
      "published_date": "2024-01-07 08:59:32 UTC",
      "updated_date": "2024-04-08 12:50:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:21:42.040927"
    },
    {
      "arxiv_id": "2401.04136v2",
      "title": "The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline",
      "title_zh": "翻译失败",
      "authors": [
        "Haonan Wang",
        "Qianli Shen",
        "Yao Tong",
        "Yang Zhang",
        "Kenji Kawaguchi"
      ],
      "abstract": "The commercialization of text-to-image diffusion models (DMs) brings forth\npotential copyright concerns. Despite numerous attempts to protect DMs from\ncopyright issues, the vulnerabilities of these solutions are underexplored. In\nthis study, we formalized the Copyright Infringement Attack on generative AI\nmodels and proposed a backdoor attack method, SilentBadDiffusion, to induce\ncopyright infringement without requiring access to or control over training\nprocesses. Our method strategically embeds connections between pieces of\ncopyrighted information and text references in poisoning data while carefully\ndispersing that information, making the poisoning data inconspicuous when\nintegrated into a clean dataset. Our experiments show the stealth and efficacy\nof the poisoning data. When given specific text prompts, DMs trained with a\npoisoning ratio of 0.20% can produce copyrighted images. Additionally, the\nresults reveal that the more sophisticated the DMs are, the easier the success\nof the attack becomes. These findings underline potential pitfalls in the\nprevailing copyright protection strategies and underscore the necessity for\nincreased scrutiny to prevent the misuse of DMs.",
      "tldr_zh": "本研究探讨了文本到图像扩散模型(DMs)的版权漏洞，提出了一种后门攻击方法SilentBadDiffusion，通过在毒化数据中战略性地嵌入版权信息和文本引用，使其在清洁数据集中的存在不易察觉，且无需调整微调流程。实验结果显示，当训练数据中仅包含0.20%的毒化数据时，模型在特定文本提示下即可生成版权图像；此外，更先进的DMs更容易遭受这种攻击，成功率更高。这些发现突显了现有版权保护策略的潜在缺陷，并强调了需要加强审查以防止DMs的滥用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted for presentation at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.04136v2",
      "published_date": "2024-01-07 08:37:29 UTC",
      "updated_date": "2024-05-26 06:00:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:21:51.873705"
    },
    {
      "arxiv_id": "2401.03410v1",
      "title": "Engineering Features to Improve Pass Prediction in Soccer Simulation 2D Games",
      "title_zh": "翻译失败",
      "authors": [
        "Nader Zare",
        "Mahtab Sarvmaili",
        "Aref Sayareh",
        "Omid Amini",
        "Stan Matwin Amilcar Soares"
      ],
      "abstract": "Soccer Simulation 2D (SS2D) is a simulation of a real soccer game in two\ndimensions. In soccer, passing behavior is an essential action for keeping the\nball in possession of our team and creating goal opportunities. Similarly, for\nSS2D, predicting the passing behaviors of both opponents and our teammates\nhelps manage resources and score more goals. Therefore, in this research, we\nhave tried to address the modeling of passing behavior of soccer 2D players\nusing Deep Neural Networks (DNN) and Random Forest (RF). We propose an embedded\ndata extraction module that can record the decision-making of agents in an\nonline format. Afterward, we apply four data sorting techniques for training\ndata preparation. After, we evaluate the trained models' performance playing\nagainst 6 top teams of RoboCup 2019 that have distinctive playing strategies.\nFinally, we examine the importance of different feature groups on the\nprediction of a passing strategy. All results in each step of this work prove\nour suggested methodology's effectiveness and improve the performance of the\npass prediction in Soccer Simulation 2D games ranging from 5\\% (e.g., playing\nagainst the same team) to 10\\% (e.g., playing against Robocup top teams).",
      "tldr_zh": "本研究针对 Soccer Simulation 2D (SS2D) 游戏，提出了一种通过工程化特征来提升传球预测准确性的方法，旨在帮助团队更好地管理资源和创造得分机会。研究采用 Deep Neural Networks (DNN) 和 Random Forest (RF) 建模传球行为，结合一个嵌入式数据提取模块记录代理决策，并应用四种数据排序技术来准备训练数据。实验评估显示，该方法在对抗 RoboCup 2019 六支顶级队伍时，传球预测性能提高了 5% 到 10%，并突出了不同特征组的重要性，为 SS2D 游戏策略优化提供了有效改进。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03410v1",
      "published_date": "2024-01-07 08:01:25 UTC",
      "updated_date": "2024-01-07 08:01:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:22:07.650676"
    },
    {
      "arxiv_id": "2401.03408v1",
      "title": "Escalation Risks from Language Models in Military and Diplomatic Decision-Making",
      "title_zh": "翻译失败",
      "authors": [
        "Juan-Pablo Rivera",
        "Gabriel Mukobi",
        "Anka Reuel",
        "Max Lamparth",
        "Chandler Smith",
        "Jacquelyn Schneider"
      ],
      "abstract": "Governments are increasingly considering integrating autonomous AI agents in\nhigh-stakes military and foreign-policy decision-making, especially with the\nemergence of advanced generative AI models like GPT-4. Our work aims to\nscrutinize the behavior of multiple AI agents in simulated wargames,\nspecifically focusing on their predilection to take escalatory actions that may\nexacerbate multilateral conflicts. Drawing on political science and\ninternational relations literature about escalation dynamics, we design a novel\nwargame simulation and scoring framework to assess the escalation risks of\nactions taken by these agents in different scenarios. Contrary to prior\nstudies, our research provides both qualitative and quantitative insights and\nfocuses on large language models (LLMs). We find that all five studied\noff-the-shelf LLMs show forms of escalation and difficult-to-predict escalation\npatterns. We observe that models tend to develop arms-race dynamics, leading to\ngreater conflict, and in rare cases, even to the deployment of nuclear weapons.\nQualitatively, we also collect the models' reported reasonings for chosen\nactions and observe worrying justifications based on deterrence and\nfirst-strike tactics. Given the high stakes of military and foreign-policy\ncontexts, we recommend further examination and cautious consideration before\ndeploying autonomous language model agents for strategic military or diplomatic\ndecision-making.",
      "tldr_zh": "这篇论文评估了大型语言模型(LLMs)在军事和外交决策中的升级风险，通过设计一个新型战争游戏(wargame)模拟和评分框架来分析AI代理的行为。研究发现，所有五个研究的现成LLMs都表现出升级倾向，包括发展军备竞赛动态、加剧冲突，甚至在极少数情况下导致核武器部署，且模型的理由往往基于威慑和先发制人策略。作者强调，由于这些高风险情境，建议在部署自主语言模型代理前进行进一步审查和谨慎考虑。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages body, 57 pages appendix, 46 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.03408v1",
      "published_date": "2024-01-07 07:59:10 UTC",
      "updated_date": "2024-01-07 07:59:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:22:17.203724"
    },
    {
      "arxiv_id": "2401.03406v1",
      "title": "Improving Dribbling, Passing, and Marking Actions in Soccer Simulation 2D Games Using Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Nader Zare",
        "Omid Amini",
        "Aref Sayareh",
        "Mahtab Sarvmaili",
        "Arad Firouzkouhi",
        "Stan Matwin",
        "Amilcar Soares"
      ],
      "abstract": "The RoboCup competition was started in 1997, and is known as the oldest\nRoboCup league. The RoboCup 2D Soccer Simulation League is a stochastic,\npartially observable soccer environment in which 24 autonomous agents play on\ntwo opposing teams. In this paper, we detail the main strategies and\nfunctionalities of CYRUS, the RoboCup 2021 2D Soccer Simulation League\nchampions. The new functionalities presented and discussed in this work are (i)\nMulti Action Dribble, (ii) Pass Prediction and (iii) Marking Decision. The\nMulti Action Dribbling strategy enabled CYRUS to succeed more often and to be\nsafer when dribbling actions were performed during a game. The Pass Prediction\nenhanced our gameplay by predicting our teammate's passing behavior,\nanticipating and making our agents collaborate better towards scoring goals.\nFinally, the Marking Decision addressed the multi-agent matching problem to\nimprove CYRUS defensive strategy by finding an optimal solution to mark\nopponents' players.",
      "tldr_zh": "这篇论文介绍了 CYRUS 团队在 RoboCup 2D Soccer Simulation League 中的策略，使用机器学习改进足球模拟游戏中的带球、传球和标记动作。论文重点呈现了三个新功能：Multi Action Dribble，提高了带球动作的成功率和安全性；Pass Prediction，通过预测队友传球行为增强团队协作和进球机会；Marking Decision，解决了多智能体匹配问题，优化了防守策略。这些改进使 CYRUS 成为 RoboCup 2021 冠军，显著提升了整体游戏表现。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03406v1",
      "published_date": "2024-01-07 07:54:26 UTC",
      "updated_date": "2024-01-07 07:54:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:22:28.036939"
    },
    {
      "arxiv_id": "2401.03397v2",
      "title": "Predicting the Skies: A Novel Model for Flight-Level Passenger Traffic Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Sina Ehsani",
        "Elina Sergeeva",
        "Wendy Murdy",
        "Benjamin Fox"
      ],
      "abstract": "Accurate prediction of flight-level passenger traffic is of paramount\nimportance in airline operations, influencing key decisions from pricing to\nroute optimization. This study introduces a novel, multimodal deep learning\napproach to the challenge of predicting flight-level passenger traffic,\nyielding substantial accuracy improvements compared to traditional models.\nLeveraging an extensive dataset from American Airlines, our model ingests\nhistorical traffic data, fare closure information, and seasonality attributes\nspecific to each flight. Our proposed neural network integrates the strengths\nof Recurrent Neural Networks (RNN) and Convolutional Neural Networks (CNN),\nexploiting the temporal patterns and spatial relationships within the data to\nenhance prediction performance. Crucial to the success of our model is a\ncomprehensive data processing strategy. We construct 3D tensors to represent\ndata, apply careful masking strategies to mirror real-world dynamics, and\nemploy data augmentation techniques to enrich the diversity of our training\nset. The efficacy of our approach is borne out in the results: our model\ndemonstrates an approximate 33\\% improvement in Mean Squared Error (MSE)\ncompared to traditional benchmarks. This study, therefore, highlights the\nsignificant potential of deep learning techniques and meticulous data\nprocessing in advancing the field of flight traffic prediction.",
      "tldr_zh": "本研究提出了一种新型多模态深度学习模型，用于预测航班级别的乘客流量，从而提升航空公司的定价和路线优化决策。该模型整合了Recurrent Neural Networks (RNN) 和Convolutional Neural Networks (CNN)，利用美国航空公司的历史流量数据、票价关闭信息和季节性属性，并通过构建3D张量、掩码策略和数据增强技术来处理数据。实验结果显示，该模型在Mean Squared Error (MSE)上比传统基准提高了约33%，突显了深度学习和精细数据处理在航班流量预测领域的重大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 6 figures, to be published",
      "pdf_url": "http://arxiv.org/pdf/2401.03397v2",
      "published_date": "2024-01-07 06:51:26 UTC",
      "updated_date": "2024-01-09 23:23:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:22:40.253105"
    },
    {
      "arxiv_id": "2401.04135v1",
      "title": "Global-Aware Enhanced Spatial-Temporal Graph Recurrent Networks: A New Framework For Traffic Flow Prediction",
      "title_zh": "全局感知增强的空间-时间图循环网络：一个新的交通流量预测框架",
      "authors": [
        "Haiyang Liu",
        "Chunjiang Zhu",
        "Detian Zhang"
      ],
      "abstract": "Traffic flow prediction plays a crucial role in alleviating traffic\ncongestion and enhancing transport efficiency. While combining graph\nconvolution networks with recurrent neural networks for spatial-temporal\nmodeling is a common strategy in this realm, the restricted structure of\nrecurrent neural networks limits their ability to capture global information.\nFor spatial modeling, many prior studies learn a graph structure that is\nassumed to be fixed and uniform at all time steps, which may not be true. This\npaper introduces a novel traffic prediction framework, Global-Aware Enhanced\nSpatial-Temporal Graph Recurrent Network (GA-STGRN), comprising two core\ncomponents: a spatial-temporal graph recurrent neural network and a global\nawareness layer. Within this framework, three innovative prediction models are\nformulated. A sequence-aware graph neural network is proposed and integrated\ninto the Gated Recurrent Unit (GRU) to learn non-fixed graphs at different time\nsteps and capture local temporal relationships. To enhance the model's global\nperception, three distinct global spatial-temporal transformer-like\narchitectures (GST^2) are devised for the global awareness layer. We conduct\nextensive experiments on four real traffic datasets and the results demonstrate\nthe superiority of our framework and the three concrete models.",
      "tldr_zh": "本论文提出了一种新的交通流量预测框架，名为 Global-Aware Enhanced Spatial-Temporal Graph Recurrent Networks (GA-STGRN)，旨在解决现有模型在捕获全局信息和处理非固定图结构方面的局限性。该框架的核心组件包括序列感知 Graph Neural Network 与 Gated Recurrent Unit (GRU) 相结合，用于学习不同时间步的动态图和局部时间关系，以及三种 Global Spatial-Temporal Transformer-like 架构 (GST^2) 来增强全局感知能力。通过在四个真实交通数据集上的广泛实验，结果显示 GA-STGRN 和其具体模型在预测性能上显著优于基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04135v1",
      "published_date": "2024-01-07 05:28:36 UTC",
      "updated_date": "2024-01-07 05:28:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:22:54.405657"
    },
    {
      "arxiv_id": "2401.04134v1",
      "title": "Web Neural Network with Complete DiGraphs",
      "title_zh": "翻译失败",
      "authors": [
        "Frank Li"
      ],
      "abstract": "This paper introduces a new neural network model that aims to mimic the\nbiological brain more closely by structuring the network as a complete directed\ngraph that processes continuous data for each timestep. Current neural networks\nhave structures that vaguely mimic the brain structure, such as neurons,\nconvolutions, and recurrence. The model proposed in this paper adds additional\nstructural properties by introducing cycles into the neuron connections and\nremoving the sequential nature commonly seen in other network layers.\nFurthermore, the model has continuous input and output, inspired by spiking\nneural networks, which allows the network to learn a process of classification,\nrather than simply returning the final result.",
      "tldr_zh": "该论文提出了一种名为 Web Neural Network with Complete DiGraphs 的新神经网络模型，旨在更精确地模仿生物大脑，通过构建一个完整的有向图（complete directed graph）来处理每个时间步的连续数据。该模型引入神经元连接的循环（cycles）并去除传统网络层的顺序性，与现有神经网络（如神经元、卷积和循环结构）的模糊模仿相比，提供更真实的脑部结构模拟。受 spiking neural networks 启发，该网络具有连续输入和输出，能够学习分类过程而非仅输出最终结果，从而提升了网络的学习和处理能力。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04134v1",
      "published_date": "2024-01-07 05:12:10 UTC",
      "updated_date": "2024-01-07 05:12:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:23:04.320884"
    },
    {
      "arxiv_id": "2401.06787v1",
      "title": "Deep Learning Based Cyberbullying Detection in Bangla Language",
      "title_zh": "翻译失败",
      "authors": [
        "Sristy Shidul Nath",
        "Razuan Karim",
        "Mahdi H. Miraz"
      ],
      "abstract": "The Internet is currently the largest platform for global communication\nincluding expressions of opinions, reviews, contents, images, videos and so\nforth. Moreover, social media has now become a very broad and highly engaging\nplatform due to its immense popularity and swift adoption trend. Increased\nsocial networking, however, also has detrimental impacts on the society leading\nto a range of unwanted phenomena, such as online assault, intimidation, digital\nbullying, criminality and trolling. Hence, cyberbullying has become a pervasive\nand worrying problem that poses considerable psychological and emotional harm\nto the people, particularly amongst the teens and the young adults. In order to\nlessen its negative effects and provide victims with prompt support, a great\ndeal of research to identify cyberbullying instances at various online\nplatforms is emerging. In comparison to other languages, Bangla (also known as\nBengali) has fewer research studies in this domain. This study demonstrates a\ndeep learning strategy for identifying cyberbullying in Bengali, using a\ndataset of 12282 versatile comments from multiple social media sites. In this\nstudy, a two-layer bidirectional long short-term memory (Bi-LSTM) model has\nbeen built to identify cyberbullying, using a variety of optimisers as well as\n5-fold cross validation. To evaluate the functionality and efficacy of the\nproposed system, rigorous assessment and validation procedures have been\nemployed throughout the project. The results of this study reveals that the\nproposed model's accuracy, using momentum-based stochastic gradient descent\n(SGD) optimiser, is 94.46%. It also reflects a higher accuracy of 95.08% and a\nF1 score of 95.23% using Adam optimiser as well as a better accuracy of 94.31%\nin 5-fold cross validation.",
      "tldr_zh": "这篇论文针对孟加拉语（Bangla）中的网络欺凌检测问题，提出了一种基于深度学习的策略，使用一个包含 12282 条社交媒体评论的数据集。研究构建了两层双向长短时记忆模型（Bi-LSTM），并结合多种优化器（如 SGD 和 Adam）以及 5 折交叉验证进行训练。结果显示，该模型在使用 Adam 优化器时准确率达到 95.08%，F1 score 为 95.23%，证明了其在识别 Bangla 语言网络欺凌方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.06787v1",
      "published_date": "2024-01-07 04:58:59 UTC",
      "updated_date": "2024-01-07 04:58:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:23:17.370919"
    },
    {
      "arxiv_id": "2401.04133v2",
      "title": "SynHING: Synthetic Heterogeneous Information Network Generation for Graph Learning and Explanation",
      "title_zh": "翻译失败",
      "authors": [
        "Ming-Yi Hong",
        "Yi-Hsiang Huang",
        "Shao-En Lin",
        "You-Chen Teng",
        "Chih-Yu Wang",
        "Che Lin"
      ],
      "abstract": "Graph Neural Networks (GNNs) excel in delineating graph structures in diverse\ndomains, including community analysis and recommendation systems. As the\ninterpretation of GNNs becomes increasingly important, the demand for robust\nbaselines and expansive graph datasets is accentuated, particularly in the\ncontext of Heterogeneous Information Networks (HIN). Addressing this, we\nintroduce SynHING, a novel framework for Synthetic Heterogeneous Information\nNetwork Generation aimed at enhancing graph learning and explanation. SynHING\nsystematically identifies major motifs in a target HIN and employs a bottom-up\ngeneration process with intra-cluster and inter-cluster merge modules. This\nprocess, supplemented by post-pruning techniques, ensures the synthetic HIN\nclosely mirrors the original graph's structural and statistical properties.\nCrucially, SynHING provides ground-truth motifs for evaluating GNN explainer\nmodels, setting a new standard for explainable, synthetic HIN generation and\ncontributing to the advancement of interpretable machine learning in complex\nnetworks.",
      "tldr_zh": "该研究针对图神经网络(GNNs)在异构信息网络(HIN)中的学习和解释需求，引入了SynHING框架，用于生成合成HIN数据集。SynHING通过系统识别目标HIN中的主要motifs，并采用自下而上的生成过程，包括intra-cluster和inter-cluster合并模块以及后修剪技术，确保合成图的结构和统计属性与原图高度相似。框架提供ground-truth motifs，用于评估GNN explainer模型，从而提升可解释机器学习在复杂网络中的标准和性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Update figures, tables, and content",
      "pdf_url": "http://arxiv.org/pdf/2401.04133v2",
      "published_date": "2024-01-07 04:43:36 UTC",
      "updated_date": "2024-05-29 04:16:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:23:28.802128"
    },
    {
      "arxiv_id": "2401.03374v2",
      "title": "LLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward",
      "title_zh": "翻译失败",
      "authors": [
        "Nafis Tanveer Islam",
        "Joseph Khoury",
        "Andrew Seong",
        "Mohammad Bahrami Karkevandi",
        "Gonzalo De La Torre Parra",
        "Elias Bou-Harb",
        "Peyman Najafirad"
      ],
      "abstract": "In software development, the predominant emphasis on functionality often\nsupersedes security concerns, a trend gaining momentum with AI-driven\nautomation tools like GitHub Copilot. These tools significantly improve\ndevelopers' efficiency in functional code development. Nevertheless, it remains\na notable concern that such tools are also responsible for creating insecure\ncode, predominantly because of pre-training on publicly available repositories\nwith vulnerable code. Moreover, developers are called the \"weakest link in the\nchain\" since they have very minimal knowledge of code security. Although\nexisting solutions provide a reasonable solution to vulnerable code, they must\nadequately describe and educate the developers on code security to ensure that\nthe security issues are not repeated. Therefore we introduce a multipurpose\ncode vulnerability analysis system \\texttt{SecRepair}, powered by a large\nlanguage model, CodeGen2 assisting the developer in identifying and generating\nfixed code along with a complete description of the vulnerability with a code\ncomment. Our innovative methodology uses a reinforcement learning paradigm to\ngenerate code comments augmented by a semantic reward mechanism. Inspired by\nhow humans fix code issues, we propose an instruction-based dataset suitable\nfor vulnerability analysis with LLMs. We further identify zero-day and N-day\nvulnerabilities in 6 Open Source IoT Operating Systems on GitHub. Our findings\nunderscore that incorporating reinforcement learning coupled with semantic\nreward augments our model's performance, thereby fortifying its capacity to\naddress code vulnerabilities with improved efficacy.",
      "tldr_zh": "该论文提出了一种基于大语言模型（LLM）的多功能代码漏洞修复系统SecRepair，利用CodeGen2模型来识别漏洞、生成修复代码，并提供详细的代码注释以教育开发者。该系统采用强化学习（Reinforcement Learning）范式，结合语义奖励（Semantic Reward）机制，优化代码注释生成过程，并基于一个新指令数据集进行训练。实验结果显示，该方法显著提升了模型在处理代码漏洞的效能，并在6个开源IoT操作系统中成功识别零日和N日漏洞，强化了代码安全的整体可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03374v2",
      "published_date": "2024-01-07 02:46:39 UTC",
      "updated_date": "2024-02-22 00:29:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:23:41.842916"
    },
    {
      "arxiv_id": "2401.03346v1",
      "title": "An Investigation of Large Language Models for Real-World Hate Speech Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Keyan Guo",
        "Alexander Hu",
        "Jaden Mu",
        "Ziheng Shi",
        "Ziming Zhao",
        "Nishant Vishwamitra",
        "Hongxin Hu"
      ],
      "abstract": "Hate speech has emerged as a major problem plaguing our social spaces today.\nWhile there have been significant efforts to address this problem, existing\nmethods are still significantly limited in effectively detecting hate speech\nonline. A major limitation of existing methods is that hate speech detection is\na highly contextual problem, and these methods cannot fully capture the context\nof hate speech to make accurate predictions. Recently, large language models\n(LLMs) have demonstrated state-of-the-art performance in several natural\nlanguage tasks. LLMs have undergone extensive training using vast amounts of\nnatural language data, enabling them to grasp intricate contextual details.\nHence, they could be used as knowledge bases for context-aware hate speech\ndetection. However, a fundamental problem with using LLMs to detect hate speech\nis that there are no studies on effectively prompting LLMs for context-aware\nhate speech detection. In this study, we conduct a large-scale study of hate\nspeech detection, employing five established hate speech datasets. We discover\nthat LLMs not only match but often surpass the performance of current benchmark\nmachine learning models in identifying hate speech. By proposing four diverse\nprompting strategies that optimize the use of LLMs in detecting hate speech.\nOur study reveals that a meticulously crafted reasoning prompt can effectively\ncapture the context of hate speech by fully utilizing the knowledge base in\nLLMs, significantly outperforming existing techniques. Furthermore, although\nLLMs can provide a rich knowledge base for the contextual detection of hate\nspeech, suitable prompting strategies play a crucial role in effectively\nleveraging this knowledge base for efficient detection.",
      "tldr_zh": "本研究调查了大语言模型 (LLMs) 在真实世界仇恨言论检测中的应用，针对现有方法无法充分捕捉仇恨言论上下文的局限性。研究者使用五个已建立的仇恨言论数据集，并提出四种不同的提示策略 (prompting strategies)，包括精心设计的推理提示，以优化 LLMs 的性能。结果显示，LLMs 不仅匹配而且常常超越基准机器学习模型的准确率，通过有效利用 LLMs 的知识库显著提升了上下文感知检测效果。该工作强调了适当提示策略在仇恨言论检测中的关键作用，为未来改进提供了重要见解。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted for publication on 22nd International Conference of Machine\n  Learning and Applications, ICMLA 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.03346v1",
      "published_date": "2024-01-07 00:39:33 UTC",
      "updated_date": "2024-01-07 00:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:23:52.207065"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 47,
  "processed_papers_count": 47,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T20:24:14.023565"
}