[
  {
    "arxiv_id": "2408.16017v1",
    "title": "Differentially Private Publication of Electricity Time Series Data in Smart Grids",
    "authors": [
      "Sina Shaham",
      "Gabriel Ghinita",
      "Bhaskar Krishnamachari",
      "Cyrus Shahabi"
    ],
    "abstract": "Smart grids are a valuable data source to study consumer behavior and guide\nenergy policy decisions. In particular, time-series of power consumption over\ngeographical areas are essential in deciding the optimal placement of expensive\nresources (e.g., transformers, storage elements) and their activation\nschedules. However, publication of such data raises significant privacy issues,\nas it may reveal sensitive details about personal habits and lifestyles.\nDifferential privacy (DP) is well-suited for sanitization of individual data,\nbut current DP techniques for time series lead to significant loss in utility,\ndue to the existence of temporal correlation between data readings. We\nintroduce {\\em STPT (Spatio-Temporal Private Timeseries)}, a novel method for\nDP-compliant publication of electricity consumption data that analyzes\nspatio-temporal attributes and captures both micro and macro patterns by\nleveraging RNNs. Additionally, it employs a partitioning method for releasing\nelectricity consumption time series based on identified patterns. We\ndemonstrate through extensive experiments, on both real-world and synthetic\ndatasets, that STPT significantly outperforms existing benchmarks, providing a\nwell-balanced trade-off between data utility and user privacy.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.16017v1",
    "published_date": "2024-08-24 23:30:09 UTC",
    "updated_date": "2024-08-24 23:30:09 UTC"
  },
  {
    "arxiv_id": "2408.13684v1",
    "title": "Evaluating Alternative Training Interventions Using Personalized Computational Models of Learning",
    "authors": [
      "Christopher James MacLellan",
      "Kimberly Stowers",
      "Lisa Brady"
    ],
    "abstract": "Evaluating different training interventions to determine which produce the\nbest learning outcomes is one of the main challenges faced by instructional\ndesigners. Typically, these designers use A/B experiments to evaluate each\nintervention; however, it is costly and time consuming to run such studies. To\naddress this issue, we explore how computational models of learning might\nsupport designers in reasoning causally about alternative interventions within\na fractions tutor. We present an approach for automatically tuning models to\nspecific individuals and show that personalized models make better predictions\nof students' behavior than generic ones. Next, we conduct simulations to\ngenerate counterfactual predictions of performance and learning for two\nstudents (high and low performing) in different versions of the fractions\ntutor. Our approach makes predictions that align with previous human findings,\nas well as testable predictions that might be evaluated with future human\nexperiments.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.13684v1",
    "published_date": "2024-08-24 22:51:57 UTC",
    "updated_date": "2024-08-24 22:51:57 UTC"
  },
  {
    "arxiv_id": "2408.13683v2",
    "title": "Submodular Maximization Approaches for Equitable Client Selection in Federated Learning",
    "authors": [
      "Andrés Catalino Castillo Jiménez",
      "Ege C. Kaya",
      "Lintao Ye",
      "Abolfazl Hashemi"
    ],
    "abstract": "In a conventional Federated Learning framework, client selection for training\ntypically involves the random sampling of a subset of clients in each\niteration. However, this random selection often leads to disparate performance\namong clients, raising concerns regarding fairness, particularly in\napplications where equitable outcomes are crucial, such as in medical or\nfinancial machine learning tasks. This disparity typically becomes more\npronounced with the advent of performance-centric client sampling techniques.\nThis paper introduces two novel methods, namely SUBTRUNC and UNIONFL, designed\nto address the limitations of random client selection. Both approaches utilize\nsubmodular function maximization to achieve more balanced models. By modifying\nthe facility location problem, they aim to mitigate the fairness concerns\nassociated with random selection. SUBTRUNC leverages client loss information to\ndiversify solutions, while UNIONFL relies on historical client selection data\nto ensure a more equitable performance of the final model. Moreover, these\nalgorithms are accompanied by robust theoretical guarantees regarding\nconvergence under reasonable assumptions. The efficacy of these methods is\ndemonstrated through extensive evaluations across heterogeneous scenarios,\nrevealing significant improvements in fairness as measured by a client\ndissimilarity metric.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SP",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.13683v2",
    "published_date": "2024-08-24 22:40:31 UTC",
    "updated_date": "2024-08-27 19:27:07 UTC"
  },
  {
    "arxiv_id": "2409.00082v1",
    "title": "Towards Human-Level Understanding of Complex Process Engineering Schematics: A Pedagogical, Introspective Multi-Agent Framework for Open-Domain Question Answering",
    "authors": [
      "Sagar Srinivas Sakhinana",
      "Geethan Sannidhi",
      "Venkataramana Runkana"
    ],
    "abstract": "In the chemical and process industries, Process Flow Diagrams (PFDs) and\nPiping and Instrumentation Diagrams (P&IDs) are critical for design,\nconstruction, and maintenance. Recent advancements in Generative AI, such as\nLarge Multimodal Models (LMMs) like GPT4 (Omni), have shown promise in\nunderstanding and interpreting process diagrams for Visual Question Answering\n(VQA). However, proprietary models pose data privacy risks, and their\ncomputational complexity prevents knowledge editing for domain-specific\ncustomization on consumer hardware. To overcome these challenges, we propose a\nsecure, on-premises enterprise solution using a hierarchical, multi-agent\nRetrieval Augmented Generation (RAG) framework for open-domain question\nanswering (ODQA) tasks, offering enhanced data privacy, explainability, and\ncost-effectiveness. Our novel multi-agent framework employs introspective and\nspecialized sub-agents using open-source, small-scale multimodal models with\nthe ReAct (Reason+Act) prompting technique for PFD and P&ID analysis,\nintegrating multiple information sources to provide accurate and contextually\nrelevant answers. Our approach, supported by iterative self-correction, aims to\ndeliver superior performance in ODQA tasks. We conducted rigorous experimental\nstudies, and the empirical results validated the proposed approach\neffectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Our paper is accepted for publication at ML4CCE workshop at ECML PKDD\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2409.00082v1",
    "published_date": "2024-08-24 19:34:04 UTC",
    "updated_date": "2024-08-24 19:34:04 UTC"
  },
  {
    "arxiv_id": "2408.13661v1",
    "title": "Hierarchical Network Fusion for Multi-Modal Electron Micrograph Representation Learning with Foundational Large Language Models",
    "authors": [
      "Sakhinana Sagar Srinivas",
      "Geethan Sannidhi",
      "Venkataramana Runkana"
    ],
    "abstract": "Characterizing materials with electron micrographs is a crucial task in\nfields such as semiconductors and quantum materials. The complex hierarchical\nstructure of micrographs often poses challenges for traditional classification\nmethods. In this study, we propose an innovative backbone architecture for\nanalyzing electron micrographs. We create multi-modal representations of the\nmicrographs by tokenizing them into patch sequences and, additionally,\nrepresenting them as vision graphs, commonly referred to as patch attributed\ngraphs. We introduce the Hierarchical Network Fusion (HNF), a multi-layered\nnetwork structure architecture that facilitates information exchange between\nthe multi-modal representations and knowledge integration across different\npatch resolutions. Furthermore, we leverage large language models (LLMs) to\ngenerate detailed technical descriptions of nanomaterials as auxiliary\ninformation to assist in the downstream task. We utilize a cross-modal\nattention mechanism for knowledge fusion across cross-domain\nrepresentations(both image-based and linguistic insights) to predict the\nnanomaterial category. This multi-faceted approach promises a more\ncomprehensive and accurate representation and classification of micrographs for\nnanomaterial identification. Our framework outperforms traditional methods,\novercoming challenges posed by distributional shifts, and facilitating\nhigh-throughput screening.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Our paper is published at the workshop on Robustness of Few-shot and\n  Zero-shot Learning in Foundation Models at NeurIPS 2023",
    "pdf_url": "http://arxiv.org/pdf/2408.13661v1",
    "published_date": "2024-08-24 19:24:44 UTC",
    "updated_date": "2024-08-24 19:24:44 UTC"
  },
  {
    "arxiv_id": "2408.13659v3",
    "title": "ReactZyme: A Benchmark for Enzyme-Reaction Prediction",
    "authors": [
      "Chenqing Hua",
      "Bozitao Zhong",
      "Sitao Luan",
      "Liang Hong",
      "Guy Wolf",
      "Doina Precup",
      "Shuangjia Zheng"
    ],
    "abstract": "Enzymes, with their specific catalyzed reactions, are necessary for all\naspects of life, enabling diverse biological processes and adaptations.\nPredicting enzyme functions is essential for understanding biological pathways,\nguiding drug development, enhancing bioproduct yields, and facilitating\nevolutionary studies. Addressing the inherent complexities, we introduce a new\napproach to annotating enzymes based on their catalyzed reactions. This method\nprovides detailed insights into specific reactions and is adaptable to newly\ndiscovered reactions, diverging from traditional classifications by protein\nfamily or expert-derived reaction classes. We employ machine learning\nalgorithms to analyze enzyme reaction datasets, delivering a much more refined\nview on the functionality of enzymes. Our evaluation leverages the largest\nenzyme-reaction dataset to date, derived from the SwissProt and Rhea databases\nwith entries up to January 8, 2024. We frame the enzyme-reaction prediction as\na retrieval problem, aiming to rank enzymes by their catalytic ability for\nspecific reactions. With our model, we can recruit proteins for novel reactions\nand predict reactions in novel proteins, facilitating enzyme discovery and\nfunction annotation (https://github.com/WillHua127/ReactZyme).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13659v3",
    "published_date": "2024-08-24 19:19:33 UTC",
    "updated_date": "2024-10-01 02:12:41 UTC"
  },
  {
    "arxiv_id": "2408.14508v2",
    "title": "Artificial intelligence for science: The easy and hard problems",
    "authors": [
      "Ruairidh M. Battleday",
      "Samuel J. Gershman"
    ],
    "abstract": "A suite of impressive scientific discoveries have been driven by recent\nadvances in artificial intelligence. These almost all result from training\nflexible algorithms to solve difficult optimization problems specified in\nadvance by teams of domain scientists and engineers with access to large\namounts of data. Although extremely useful, this kind of problem solving only\ncorresponds to one part of science - the \"easy problem.\" The other part of\nscientific research is coming up with the problem itself - the \"hard problem.\"\nSolving the hard problem is beyond the capacities of current algorithms for\nscientific discovery because it requires continual conceptual revision based on\npoorly defined constraints. We can make progress on understanding how humans\nsolve the hard problem by studying the cognitive science of scientists, and\nthen use the results to design new computational agents that automatically\ninfer and update their scientific paradigms.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 3 boxes, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.14508v2",
    "published_date": "2024-08-24 18:22:06 UTC",
    "updated_date": "2024-12-17 01:55:42 UTC"
  },
  {
    "arxiv_id": "2408.13644v1",
    "title": "Studying the Effect of Audio Filters in Pre-Trained Models for Environmental Sound Classification",
    "authors": [
      "Aditya Dawn",
      "Wazib Ansar"
    ],
    "abstract": "Environmental Sound Classification is an important problem of sound\nrecognition and is more complicated than speech recognition problems as\nenvironmental sounds are not well structured with respect to time and\nfrequency. Researchers have used various CNN models to learn audio features\nfrom different audio features like log mel spectrograms, gammatone spectral\ncoefficients, mel-frequency spectral coefficients, generated from the audio\nfiles, over the past years. In this paper, we propose a new methodology :\nTwo-Level Classification; the Level 1 Classifier will be responsible to\nclassify the audio signal into a broader class and the Level 2 Classifiers will\nbe responsible to find the actual class to which the audio belongs, based on\nthe output of the Level 1 Classifier. We have also shown the effects of\ndifferent audio filters, among which a new method of Audio Crop is introduced\nin this paper, which gave the highest accuracies in most of the cases. We have\nused the ESC-50 dataset for our experiment and obtained a maximum accuracy of\n78.75% in case of Level 1 Classification and 98.04% in case of Level 2\nClassifications.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "19 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.13644v1",
    "published_date": "2024-08-24 18:13:07 UTC",
    "updated_date": "2024-08-24 18:13:07 UTC"
  },
  {
    "arxiv_id": "2408.13637v2",
    "title": "Temporal Elections: Welfare, Strategyproofness, and Proportionality",
    "authors": [
      "Edith Elkind",
      "Tzeh Yuan Neoh",
      "Nicholas Teh"
    ],
    "abstract": "We investigate a model of sequential decision-making where a single\nalternative is chosen at each round. We focus on two objectives -- utilitarian\nwelfare (Util) and egalitarian welfare (Egal) -- and consider the computational\ncomplexity of maximizing these objectives, as well as their compatibility with\nstrategyproofness and proportionality. We observe that maximizing Util is easy,\nbut the corresponding decision problem for Egal is NP-complete even in\nrestricted cases. We complement this hardness result for Egal with\nparameterized complexity analysis and an approximation algorithm. Additionally,\nwe show that, while a mechanism that outputs an outcome that maximizes Util is\nstrategyproof, all deterministic mechanisms for computing outcomes that\nmaximize Egal fail a very weak variant of strategyproofness, called non-obvious\nmanipulability (NOM). However, we show that when agents have non-empty approval\nsets at each timestep, choosing an Egal-maximizing outcome while breaking ties\nlexicographically satisfies NOM. Regarding proportionality, we prove that a\nproportional (PROP) outcome can be computed efficiently, but finding an outcome\nthat maximizes Util while guaranteeing PROP is NP-hard. We also derive upper\nand lower bounds on the (strong) price of proportionality with respect to Util\nand Egal. Some of our results extend to $p$-mean welfare measures other than\nEgal and Util.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "Appears in the 27th European Conference on Artificial Intelligence\n  (ECAI), 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.13637v2",
    "published_date": "2024-08-24 17:52:26 UTC",
    "updated_date": "2024-12-20 13:29:43 UTC"
  },
  {
    "arxiv_id": "2409.06708v1",
    "title": "Ensuring Fairness with Transparent Auditing of Quantitative Bias in AI Systems",
    "authors": [
      "Chih-Cheng Rex Yuan",
      "Bow-Yaw Wang"
    ],
    "abstract": "With the rapid advancement of AI, there is a growing trend to integrate AI\ninto decision-making processes. However, AI systems may exhibit biases that\nlead decision-makers to draw unfair conclusions. Notably, the COMPAS system\nused in the American justice system to evaluate recidivism was found to favor\nracial majority groups; specifically, it violates a fairness standard called\nequalized odds. Various measures have been proposed to assess AI fairness. We\npresent a framework for auditing AI fairness, involving third-party auditors\nand AI system providers, and we have created a tool to facilitate systematic\nexamination of AI systems. The tool is open-sourced and publicly available.\nUnlike traditional AI systems, we advocate a transparent white-box and\nstatistics-based approach. It can be utilized by third-party auditors, AI\ndevelopers, or the general public for reference when judging the fairness\ncriterion of AI systems.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.06708v1",
    "published_date": "2024-08-24 17:16:50 UTC",
    "updated_date": "2024-08-24 17:16:50 UTC"
  },
  {
    "arxiv_id": "2408.13630v1",
    "title": "DeepVoting: Learning Voting Rules with Tailored Embeddings",
    "authors": [
      "Leonardo Matone",
      "Ben Abramowitz",
      "Nicholas Mattei",
      "Avinash Balakrishnan"
    ],
    "abstract": "Aggregating the preferences of multiple agents into a collective decision is\na common step in many important problems across areas of computer science\nincluding information retrieval, reinforcement learning, and recommender\nsystems. As Social Choice Theory has shown, the problem of designing algorithms\nfor aggregation rules with specific properties (axioms) can be difficult, or\nprovably impossible in some cases. Instead of designing algorithms by hand, one\ncan learn aggregation rules, particularly voting rules, from data. However, the\nprior work in this area has required extremely large models, or been limited by\nthe choice of preference representation, i.e., embedding. We recast the problem\nof designing a good voting rule into one of learning probabilistic versions of\nvoting rules that output distributions over a set of candidates. Specifically,\nwe use neural networks to learn probabilistic social choice functions from the\nliterature. We show that embeddings of preference profiles derived from the\nsocial choice literature allows us to learn existing voting rules more\nefficiently and scale to larger populations of voters more easily than other\nwork if the embedding is tailored to the learning objective. Moreover, we show\nthat rules learned using embeddings can be tweaked to create novel voting rules\nwith improved axiomatic properties. Namely, we show that existing voting rules\nrequire only minor modification to combat a probabilistic version of the No\nShow Paradox.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT",
      "cs.LG",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13630v1",
    "published_date": "2024-08-24 17:15:20 UTC",
    "updated_date": "2024-08-24 17:15:20 UTC"
  },
  {
    "arxiv_id": "2408.13628v2",
    "title": "Enhancing Uplift Modeling in Multi-Treatment Marketing Campaigns: Leveraging Score Ranking and Calibration Techniques",
    "authors": [
      "Yoon Tae Park",
      "Ting Xu",
      "Mohamed Anany"
    ],
    "abstract": "Uplift modeling is essential for optimizing marketing strategies by selecting\nindividuals likely to respond positively to specific marketing campaigns. This\nimportance escalates in multi-treatment marketing campaigns, where diverse\ntreatment is available and we may want to assign the customers to treatment\nthat can make the most impact. While there are existing approaches with\nconvenient frameworks like Causalml, there are potential spaces to enhance the\neffect of uplift modeling in multi treatment cases. This paper introduces a\nnovel approach to uplift modeling in multi-treatment campaigns, leveraging\nscore ranking and calibration techniques to improve overall performance of the\nmarketing campaign. We review existing uplift models, including Meta Learner\nframeworks (S, T, X), and their application in real-world scenarios.\nAdditionally, we delve into insights from multi-treatment studies to highlight\nthe complexities and potential advancements in the field. Our methodology\nincorporates Meta-Learner calibration and a scoring rank-based offer selection\nstrategy. Extensive experiment results with real-world datasets demonstrate the\npractical benefits and superior performance of our approach. The findings\nunderscore the critical role of integrating score ranking and calibration\ntechniques in refining the performance and reliability of uplift predictions,\nthereby advancing predictive modeling in marketing analytics and providing\nactionable insights for practitioners seeking to optimize their campaign\nstrategies.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13628v2",
    "published_date": "2024-08-24 17:10:59 UTC",
    "updated_date": "2024-08-27 12:53:22 UTC"
  },
  {
    "arxiv_id": "2408.14507v3",
    "title": "Prompt-Matcher: Leveraging Large Models to Reduce Uncertainty in Schema Matching Results",
    "authors": [
      "Longyu Feng",
      "Huahang Li",
      "Chen Jason Zhang"
    ],
    "abstract": "Schema matching is the process of identifying correspondences between the\nelements of two given schemata, essential for database management systems, data\nintegration, and data warehousing. For datasets across different scenarios, the\noptimal schema matching algorithm is different. For single algorithm,\nhyperparameter tuning also cases multiple results. All results assigned equal\nprobabilities are stored in probabilistic databases to facilitate uncertainty\nmanagement. The substantial degree of uncertainty diminishes the efficiency and\nreliability of data processing, thereby precluding the provision of more\naccurate information for decision-makers. To address this problem, we introduce\na new approach based on fine-grained correspondence verification with specific\nprompt of Large Language Model.\n  Our approach is an iterative loop that consists of three main components: (1)\nthe correspondence selection algorithm, (2) correspondence verification, and\n(3) the update of probability distribution. The core idea is that\ncorrespondences intersect across multiple results, thereby linking the\nverification of correspondences to the reduction of uncertainty in candidate\nresults.\n  The task of selecting an optimal correspondence set to maximize the\nanticipated uncertainty reduction within a fixed budgetary framework is\nestablished as an NP-hard problem. We propose a novel $(1-1/e)$-approximation\nalgorithm that significantly outperforms brute algorithm in terms of\ncomputational efficiency. To enhance correspondence verification, we have\ndeveloped two prompt templates that enable GPT-4 to achieve state-of-the-art\nperformance across two established benchmark datasets. Our comprehensive\nexperimental evaluation demonstrates the superior effectiveness and robustness\nof the proposed approach.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.14507v3",
    "published_date": "2024-08-24 16:54:08 UTC",
    "updated_date": "2025-03-06 10:26:32 UTC"
  },
  {
    "arxiv_id": "2408.13626v1",
    "title": "Towards Case-based Interpretability for Medical Federated Learning",
    "authors": [
      "Laura Latorre",
      "Liliana Petrychenko",
      "Regina Beets-Tan",
      "Taisiya Kopytova",
      "Wilson Silva"
    ],
    "abstract": "We explore deep generative models to generate case-based explanations in a\nmedical federated learning setting. Explaining AI model decisions through\ncase-based interpretability is paramount to increasing trust and allowing\nwidespread adoption of AI in clinical practice. However, medical AI training\nparadigms are shifting towards federated learning settings in order to comply\nwith data protection regulations. In a federated scenario, past data is\ninaccessible to the current user. Thus, we use a deep generative model to\ngenerate synthetic examples that protect privacy and explain decisions. Our\nproof-of-concept focuses on pleural effusion diagnosis and uses publicly\navailable Chest X-ray data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "\\c{opyright} 20XX IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works",
    "pdf_url": "http://arxiv.org/pdf/2408.13626v1",
    "published_date": "2024-08-24 16:42:12 UTC",
    "updated_date": "2024-08-24 16:42:12 UTC"
  },
  {
    "arxiv_id": "2408.13624v1",
    "title": "No Dataset Needed for Downstream Knowledge Benchmarking: Response Dispersion Inversely Correlates with Accuracy on Domain-specific QA",
    "authors": [
      "Robert L Simione II"
    ],
    "abstract": "This research seeks to obviate the need for creating QA datasets and grading\n(chatbot) LLM responses when comparing LLMs' knowledge in specific topic\ndomains. This is done in an entirely end-user centric way without need for\naccess to any inner workings of the LLM, so long as it can be prompted and\ngiven a random seed to create different generations to the same prompt. The\npaper does this by, for a given topic domain, defining the \"response\ndispersion\" of an LLM by repeatedly asking an LLM the same opinion question\nabout that topic domain. Namely, the response dispersion is the count of\nsingular values needed to explain 95% of the variance in the embedding matrix\nof the LLM's responses. It is found that the response dispersion is inversely\ncorrelated with accuracy on relevant QA evaluations (average spearman rank\ncorrelation stronger than -.59). A use-case analysis shows that when comparing\ntwo different LLMs on the same topic domain, comparing their response\ndispersion is a suitable replacement for comparing their QA accuracy between\n74% and 89% of the time, the range depending on certain reasonable\naccuracy-difference tolerances that may be acceptable to an end-user in\nexchange for the labor being saved using response dispersion instead of QA\naccuracy for comparison. Two response embeddings are studied for creating the\nembedding matrix in this study, one is from OpenAI's APIs and one is a novel\nembedding, here named reference sentence similarity embeddings, that can be\ncomputed locally and performs very nearly as well in calculating response\ndispersion. Also in this research, a pre-existing dataset called the IRC-Wiki\nTrivia dataset, originally developed for trivia games, has been re-purposed,\ncurated, and the curation, called IRC-WikiTriviaQA, is made available for the\npurpose of this research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 3 tables, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2408.13624v1",
    "published_date": "2024-08-24 16:35:00 UTC",
    "updated_date": "2024-08-24 16:35:00 UTC"
  },
  {
    "arxiv_id": "2408.13622v1",
    "title": "Advancing Enterprise Spatio-Temporal Forecasting Applications: Data Mining Meets Instruction Tuning of Language Models For Multi-modal Time Series Analysis in Low-Resource Settings",
    "authors": [
      "Sagar Srinivas Sakhinana",
      "Geethan Sannidhi",
      "Chidaksh Ravuru",
      "Venkataramana Runkana"
    ],
    "abstract": "Spatio-temporal forecasting is crucial in transportation, logistics, and\nsupply chain management. However, current methods struggle with large, complex\ndatasets. We propose a dynamic, multi-modal approach that integrates the\nstrengths of traditional forecasting methods and instruction tuning of small\nlanguage models for time series trend analysis. This approach utilizes a\nmixture of experts (MoE) architecture with parameter-efficient fine-tuning\n(PEFT) methods, tailored for consumer hardware to scale up AI solutions in low\nresource settings while balancing performance and latency tradeoffs.\nAdditionally, our approach leverages related past experiences for similar input\ntime series to efficiently handle both intra-series and inter-series\ndependencies of non-stationary data with a time-then-space modeling approach,\nusing grouped-query attention, while mitigating the limitations of traditional\nforecasting techniques in handling distributional shifts. Our approach models\npredictive uncertainty to improve decision-making. Our framework enables\non-premises customization with reduced computational and memory demands, while\nmaintaining inference speed and data privacy/security. Extensive experiments on\nvarious real-world datasets demonstrate that our framework provides robust and\naccurate forecasts, significantly outperforming existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at the ICLR 2024 Workshop on Practical ML for Low Resource\n  Settings(PML4LRS)",
    "pdf_url": "http://arxiv.org/pdf/2408.13622v1",
    "published_date": "2024-08-24 16:32:58 UTC",
    "updated_date": "2024-08-24 16:32:58 UTC"
  },
  {
    "arxiv_id": "2408.13621v1",
    "title": "Preliminary Investigations of a Multi-Faceted Robust and Synergistic Approach in Semiconductor Electron Micrograph Analysis: Integrating Vision Transformers with Large Language and Multimodal Models",
    "authors": [
      "Sakhinana Sagar Srinivas",
      "Geethan Sannidhi",
      "Sreeja Gangasani",
      "Chidaksh Ravuru",
      "Venkataramana Runkana"
    ],
    "abstract": "Characterizing materials using electron micrographs is crucial in areas such\nas semiconductors and quantum materials. Traditional classification methods\nfalter due to the intricatestructures of these micrographs. This study\nintroduces an innovative architecture that leverages the generative\ncapabilities of zero-shot prompting in Large Language Models (LLMs) such as\nGPT-4(language only), the predictive ability of few-shot (in-context) learning\nin Large Multimodal Models (LMMs) such as GPT-4(V)ision, and fuses knowledge\nacross image based and linguistic insights for accurate nanomaterial category\nprediction. This comprehensive approach aims to provide a robust solution for\nthe automated nanomaterial identification task in semiconductor manufacturing,\nblending performance, efficiency, and interpretability. Our method surpasses\nconventional approaches, offering precise nanomaterial identification and\nfacilitating high-throughput screening.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at Deployable AI (DAI) Workshop at AAAI-2024",
    "pdf_url": "http://arxiv.org/pdf/2408.13621v1",
    "published_date": "2024-08-24 16:28:00 UTC",
    "updated_date": "2024-08-24 16:28:00 UTC"
  },
  {
    "arxiv_id": "2408.13586v2",
    "title": "Balancing Diversity and Risk in LLM Sampling: How to Select Your Method and Parameter for Open-Ended Text Generation",
    "authors": [
      "Yuxuan Zhou",
      "Margret Keuper",
      "Mario Fritz"
    ],
    "abstract": "Sampling-based decoding strategies have been widely adopted for Large\nLanguage Models (LLMs) in numerous applications, targeting a balance between\ndiversity and quality via temperature tuning and tail truncation. Considering\nthe strong dependency of the candidate next tokens on different prefixes,\nrecent studies propose to adaptively truncate the tail of LLMs' predicted\ndistribution. Although improved results have been reported with these methods\non open-ended text generation tasks, the results are highly dependent on the\ncurated parameters and the limited exemplar text. In this paper, we propose a\nsystematic way to estimate the capacity of a truncation sampling method by\nconsidering the trade-off between diversity and risk at each decoding step,\nbased on our collected prefix tree which preserves the context of a full\nsentence. Our work offers a comprehensive comparison of existing truncation\nsampling methods and serves as a practical user guideline for their parameter\nselection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13586v2",
    "published_date": "2024-08-24 14:14:32 UTC",
    "updated_date": "2025-01-08 02:09:15 UTC"
  },
  {
    "arxiv_id": "2408.13546v2",
    "title": "Synesthesia of Machines (SoM)-Enhanced ISAC Precoding for Vehicular Networks with Double Dynamics",
    "authors": [
      "Zonghui Yang",
      "Shijian Gao",
      "Xiang Cheng",
      "Liuqing Yang"
    ],
    "abstract": "Integrated sensing and communication (ISAC) technology is vital for vehicular\nnetworks, yet the time-varying communication channels and rapid movement of\ntargets present significant challenges for real-time precoding design.\nTraditional optimization-based methods are computationally complex and depend\non perfect prior information, which is often unavailable in double-dynamic\nscenarios. In this paper, we propose a synesthesia of machine (SoM)-enhanced\nprecoding paradigm that leverages modalities such as positioning and channel\ninformation to adapt to these dynamics. Utilizing a deep reinforcement learning\n(DRL) framework, our approach pushes ISAC performance boundaries. We also\nintroduce a parameter-shared actor-critic architecture to accelerate training\nin complex state and action spaces. Extensive experiments validate the\nsuperiority of our method over existing approaches.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "Submitted to IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2408.13546v2",
    "published_date": "2024-08-24 10:35:10 UTC",
    "updated_date": "2024-12-04 01:45:42 UTC"
  },
  {
    "arxiv_id": "2408.13518v1",
    "title": "Selective Preference Optimization via Token-Level Reward Function Estimation",
    "authors": [
      "Kailai Yang",
      "Zhiwei Liu",
      "Qianqian Xie",
      "Jimin Huang",
      "Erxue Min",
      "Sophia Ananiadou"
    ],
    "abstract": "Recent advancements in large language model alignment leverage token-level\nsupervisions to perform fine-grained preference optimization. However, existing\ntoken-level alignment methods either optimize on all available tokens, which\ncan be noisy and inefficient, or perform selective training with complex and\nexpensive key token selection strategies. In this work, we propose Selective\nPreference Optimization (SePO), a novel selective alignment strategy that\ncenters on efficient key token selection. SePO proposes the first token\nselection method based on Direct Preference Optimization (DPO), which trains an\noracle model to estimate a token-level reward function on the target data. This\nmethod applies to any existing alignment datasets with response-level\nannotations and enables cost-efficient token selection with small-scale oracle\nmodels and training data. The estimated reward function is then utilized to\nscore all tokens within the target dataset, where only the key tokens are\nselected to supervise the target policy model with a reference model-free\ncontrastive objective function. Extensive experiments on three public\nevaluation benchmarks show that SePO significantly outperforms competitive\nbaseline methods by only optimizing 30% key tokens on the target dataset. SePO\napplications on weak-to-strong generalization show that weak oracle models\neffectively supervise strong policy models with up to 16.8x more parameters.\nSePO also effectively selects key tokens from out-of-distribution data to\nenhance strong policy models and alleviate the over-optimization problem.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2408.13518v1",
    "published_date": "2024-08-24 08:44:04 UTC",
    "updated_date": "2024-08-24 08:44:04 UTC"
  },
  {
    "arxiv_id": "2408.13516v1",
    "title": "AnoPLe: Few-Shot Anomaly Detection via Bi-directional Prompt Learning with Only Normal Samples",
    "authors": [
      "Yujin Lee",
      "Seoyoon Jang",
      "Hyunsoo Yoon"
    ],
    "abstract": "Few-shot Anomaly Detection (FAD) poses significant challenges due to the\nlimited availability of training samples and the frequent absence of abnormal\nsamples. Previous approaches often rely on annotations or true abnormal samples\nto improve detection, but such textual or visual cues are not always\naccessible. To address this, we introduce AnoPLe, a multi-modal prompt learning\nmethod designed for anomaly detection without prior knowledge of anomalies.\nAnoPLe simulates anomalies and employs bidirectional coupling of textual and\nvisual prompts to facilitate deep interaction between the two modalities.\nAdditionally, we integrate a lightweight decoder with a learnable multi-view\nsignal, trained on multi-scale images to enhance local semantic comprehension.\nTo further improve performance, we align global and local semantics, enriching\nthe image-level understanding of anomalies. The experimental results\ndemonstrate that AnoPLe achieves strong FAD performance, recording 94.1% and\n86.2% Image AUROC on MVTec-AD and VisA respectively, with only around a 1% gap\ncompared to the SoTA, despite not being exposed to true anomalies. Code is\navailable at https://github.com/YoojLee/AnoPLe.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Code is available at https://github.com/YoojLee/AnoPLe",
    "pdf_url": "http://arxiv.org/pdf/2408.13516v1",
    "published_date": "2024-08-24 08:41:19 UTC",
    "updated_date": "2024-08-24 08:41:19 UTC"
  },
  {
    "arxiv_id": "2408.14505v2",
    "title": "Language Model Empowered Spatio-Temporal Forecasting via Physics-Aware Reprogramming",
    "authors": [
      "Hao Wang",
      "Jindong Han",
      "Wei Fan",
      "Hao Liu"
    ],
    "abstract": "Spatio-temporal forecasting is pivotal in numerous real-world applications,\nincluding transportation planning, energy management, and climate monitoring.\nIn this work, we aim to harness the reasoning and generalization abilities of\nPre-trained Language Models (PLMs) for more effective spatio-temporal\nforecasting, particularly in data-scarce scenarios. However, recent studies\nuncover that PLMs, which are primarily trained on textual data, often falter\nwhen tasked with modeling the intricate correlations in numerical time series,\nthereby limiting their effectiveness in comprehending spatio-temporal data. To\nbridge the gap, we propose RePST, a physics-aware PLM reprogramming framework\ntailored for spatio-temporal forecasting. Specifically, we first propose a\nphysics-aware decomposer that adaptively disentangles spatially correlated time\nseries into interpretable sub-components, which facilitates PLM to understand\nsophisticated spatio-temporal dynamics via a divide-and-conquer strategy.\nMoreover, we propose a selective discrete reprogramming scheme, which\nintroduces an expanded spatio-temporal vocabulary space to project\nspatio-temporal series into discrete representations. This scheme minimizes the\ninformation loss during reprogramming and enriches the representations derived\nby PLMs. Extensive experiments on real-world datasets show that the proposed\nRePST outperforms twelve state-of-the-art baseline methods, particularly in\ndata-scarce scenarios, highlighting the effectiveness and superior\ngeneralization capabilities of PLMs for spatio-temporal forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.14505v2",
    "published_date": "2024-08-24 07:59:36 UTC",
    "updated_date": "2024-10-04 17:08:17 UTC"
  },
  {
    "arxiv_id": "2408.14504v1",
    "title": "Is Functional Correctness Enough to Evaluate Code Language Models? Exploring Diversity of Generated Codes",
    "authors": [
      "Heejae Chon",
      "Seonghyeon Lee",
      "Jinyoung Yeo",
      "Dongha Lee"
    ],
    "abstract": "Language models (LMs) have exhibited impressive abilities in generating codes\nfrom natural language requirements. In this work, we highlight the diversity of\ncode generated by LMs as a critical criterion for evaluating their code\ngeneration capabilities, in addition to functional correctness. Despite its\npractical implications, there is a lack of studies focused on assessing the\ndiversity of generated code, which overlooks its importance in the development\nof code LMs. We propose a systematic approach to evaluate the diversity of\ngenerated code, utilizing various metrics for inter-code similarity as well as\nfunctional correctness. Specifically, we introduce a pairwise code similarity\nmeasure that leverages large LMs' capabilities in code understanding and\nreasoning, demonstrating the highest correlation with human judgment. We\nextensively investigate the impact of various factors on the quality of\ngenerated code, including model sizes, temperatures, training approaches,\nprompting strategies, and the difficulty of input problems. Our consistent\nobservation of a positive correlation between the test pass score and the\ninter-code similarity score indicates that current LMs tend to produce\nfunctionally correct code with limited diversity.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "15pages, 6 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.14504v1",
    "published_date": "2024-08-24 07:40:22 UTC",
    "updated_date": "2024-08-24 07:40:22 UTC"
  },
  {
    "arxiv_id": "2408.13493v2",
    "title": "Thresholded Lexicographic Ordered Multiobjective Reinforcement Learning",
    "authors": [
      "Alperen Tercan",
      "Vinayak S. Prabhu"
    ],
    "abstract": "Lexicographic multi-objective problems, which impose a lexicographic\nimportance order over the objectives, arise in many real-life scenarios.\nExisting Reinforcement Learning work directly addressing lexicographic tasks\nhas been scarce. The few proposed approaches were all noted to be heuristics\nwithout theoretical guarantees as the Bellman equation is not applicable to\nthem. Additionally, the practical applicability of these prior approaches also\nsuffers from various issues such as not being able to reach the goal state.\nWhile some of these issues have been known before, in this work we investigate\nfurther shortcomings, and propose fixes for improving practical performance in\nmany cases. We also present a policy optimization approach using our\nLexicographic Projection Optimization (LPO) algorithm that has the potential to\naddress these theoretical and practical concerns. Finally, we demonstrate our\nproposed algorithms on benchmark problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Full version of ECAI 2024 paper",
    "pdf_url": "http://arxiv.org/pdf/2408.13493v2",
    "published_date": "2024-08-24 06:32:30 UTC",
    "updated_date": "2024-09-04 01:00:12 UTC"
  },
  {
    "arxiv_id": "2408.13482v2",
    "title": "MPruner: Optimizing Neural Network Size with CKA-Based Mutual Information Pruning",
    "authors": [
      "Seungbeom Hu",
      "ChanJun Park",
      "Andrew Ferraiuolo",
      "Sang-Ki Ko",
      "Jinwoo Kim",
      "Haein Song",
      "Jieung Kim"
    ],
    "abstract": "Determining the optimal size of a neural network is critical, as it directly\nimpacts runtime performance and memory usage. Pruning is a well-established\nmodel compression technique that reduces the size of neural networks while\nmathematically guaranteeing accuracy preservation. However, many recent pruning\nmethods overlook the global contributions of individual model components,\nmaking it difficult to ensure that a pruned model meets the desired dataset and\nperformance requirements. To address these challenges, we developed a new\npruning algorithm, MPruner, that leverages mutual information through vector\nsimilarity. MPruner utilizes layer clustering with the Centered Kernel\nAlignment (CKA) similarity metric, allowing us to incorporate global\ninformation from the neural network for more precise and efficient layer-wise\npruning. We evaluated MPruner across various architectures and configurations,\ndemonstrating its versatility and providing practical guidelines. MPruner\nachieved up to a 50% reduction in parameters and memory usage for CNN and\ntransformer-based models, with minimal to no loss in accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13482v2",
    "published_date": "2024-08-24 05:54:47 UTC",
    "updated_date": "2024-09-03 00:48:37 UTC"
  },
  {
    "arxiv_id": "2408.13471v1",
    "title": "Disentangled Generative Graph Representation Learning",
    "authors": [
      "Xinyue Hu",
      "Zhibin Duan",
      "Xinyang Liu",
      "Yuxin Li",
      "Bo Chen",
      "Mingyuan Zhou"
    ],
    "abstract": "Recently, generative graph models have shown promising results in learning\ngraph representations through self-supervised methods. However, most existing\ngenerative graph representation learning (GRL) approaches rely on random\nmasking across the entire graph, which overlooks the entanglement of learned\nrepresentations. This oversight results in non-robustness and a lack of\nexplainability. Furthermore, disentangling the learned representations remains\na significant challenge and has not been sufficiently explored in GRL research.\nBased on these insights, this paper introduces DiGGR (Disentangled Generative\nGraph Representation Learning), a self-supervised learning framework. DiGGR\naims to learn latent disentangled factors and utilizes them to guide graph mask\nmodeling, thereby enhancing the disentanglement of learned representations and\nenabling end-to-end joint learning. Extensive experiments on 11 public datasets\nfor two different graph learning tasks demonstrate that DiGGR consistently\noutperforms many previous self-supervised methods, verifying the effectiveness\nof the proposed approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13471v1",
    "published_date": "2024-08-24 05:13:02 UTC",
    "updated_date": "2024-08-24 05:13:02 UTC"
  },
  {
    "arxiv_id": "2408.13467v2",
    "title": "LlamaDuo: LLMOps Pipeline for Seamless Migration from Service LLMs to Small-Scale Local LLMs",
    "authors": [
      "Chansung Park",
      "Juyong Jiang",
      "Fan Wang",
      "Sayak Paul",
      "Jing Tang"
    ],
    "abstract": "The widespread adoption of cloud-based proprietary large language models\n(LLMs) has introduced significant challenges, including operational\ndependencies, privacy concerns, and the necessity of continuous internet\nconnectivity. In this work, we introduce an LLMOps pipeline, \"LlamaDuo\", for\nthe seamless migration of knowledge and abilities from service-oriented LLMs to\nsmaller, locally manageable models. This pipeline is crucial for ensuring\nservice continuity in the presence of operational failures, strict privacy\npolicies, or offline requirements. Our LlamaDuo involves fine-tuning a small\nlanguage model against the service LLM using a synthetic dataset generated by\nthe latter. If the performance of the fine-tuned model falls short of\nexpectations, it is enhanced by further fine-tuning with additional similar\ndata created by the service LLM. This iterative process guarantees that the\nsmaller model can eventually match or even surpass the service LLM's\ncapabilities in specific downstream tasks, offering a practical and scalable\nsolution for managing AI deployments in constrained environments. Extensive\nexperiments with leading edge LLMs are conducted to demonstrate the\neffectiveness, adaptability, and affordability of LlamaDuo across various\ndownstream tasks. Our pipeline implementation is available at\nhttps://github.com/deep-diver/llamaduo.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "28 pages, 18 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.13467v2",
    "published_date": "2024-08-24 05:03:08 UTC",
    "updated_date": "2024-08-29 00:54:27 UTC"
  },
  {
    "arxiv_id": "2408.13464v2",
    "title": "Uncovering Biases with Reflective Large Language Models",
    "authors": [
      "Edward Y. Chang"
    ],
    "abstract": "Biases and errors in human-labeled data present significant challenges for\nmachine learning, especially in supervised learning reliant on potentially\nflawed ground truth data. These flaws, including diagnostic errors and societal\nbiases, risk being propagated and amplified through models trained using\nmaximum likelihood estimation. We present the Reflective LLM Dialogue Framework\nRLDF, which leverages structured adversarial dialogues between multiple\ninstances of a single LLM or different LLMs to uncover diverse perspectives and\ncorrect inconsistencies. By conditioning LLMs to adopt opposing stances, RLDF\nenables systematic bias detection through conditional statistics, information\ntheory, and divergence metrics. Experiments show RLDF successfully identifies\npotential biases in public content while exposing limitations in human-labeled\ndata. Our framework supports measurable progress tracking and explainable\nremediation actions, offering a scalable approach for improving content\nneutrality through transparent, multi-perspective analysis.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 4 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.13464v2",
    "published_date": "2024-08-24 04:48:32 UTC",
    "updated_date": "2024-10-24 07:09:43 UTC"
  },
  {
    "arxiv_id": "2408.13461v1",
    "title": "Probing the Robustness of Vision-Language Pretrained Models: A Multimodal Adversarial Attack Approach",
    "authors": [
      "Jiwei Guan",
      "Tianyu Ding",
      "Longbing Cao",
      "Lei Pan",
      "Chen Wang",
      "Xi Zheng"
    ],
    "abstract": "Vision-language pretraining (VLP) with transformers has demonstrated\nexceptional performance across numerous multimodal tasks. However, the\nadversarial robustness of these models has not been thoroughly investigated.\nExisting multimodal attack methods have largely overlooked cross-modal\ninteractions between visual and textual modalities, particularly in the context\nof cross-attention mechanisms. In this paper, we study the adversarial\nvulnerability of recent VLP transformers and design a novel Joint Multimodal\nTransformer Feature Attack (JMTFA) that concurrently introduces adversarial\nperturbations in both visual and textual modalities under white-box settings.\nJMTFA strategically targets attention relevance scores to disrupt important\nfeatures within each modality, generating adversarial samples by fusing\nperturbations and leading to erroneous model predictions. Experimental results\nindicate that the proposed approach achieves high attack success rates on\nvision-language understanding and reasoning downstream tasks compared to\nexisting baselines. Notably, our findings reveal that the textual modality\nsignificantly influences the complex fusion processes within VLP transformers.\nMoreover, we observe no apparent relationship between model size and\nadversarial robustness under our proposed attacks. These insights emphasize a\nnew dimension of adversarial robustness and underscore potential risks in the\nreliable deployment of multimodal AI systems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13461v1",
    "published_date": "2024-08-24 04:31:37 UTC",
    "updated_date": "2024-08-24 04:31:37 UTC"
  },
  {
    "arxiv_id": "2408.13457v3",
    "title": "Make Every Penny Count: Difficulty-Adaptive Self-Consistency for Cost-Efficient Reasoning",
    "authors": [
      "Xinglin Wang",
      "Shaoxiong Feng",
      "Yiwei Li",
      "Peiwen Yuan",
      "Yueqi Zhang",
      "Chuyi Tan",
      "Boyuan Pan",
      "Yao Hu",
      "Kan Li"
    ],
    "abstract": "Self-consistency (SC), a widely used decoding strategy for chain-of-thought\nreasoning, shows significant gains across various multi-step reasoning tasks\nbut comes with a high cost due to multiple sampling with the preset size. Its\nvariants, Adaptive self-consistency (ASC) and Early-stopping self-consistency\n(ESC), dynamically adjust the number of samples based on the posterior\ndistribution of a set of pre-samples, reducing the cost of SC with minimal\nimpact on performance. Both methods, however, do not exploit the prior\ninformation about question difficulty. It often results in unnecessary repeated\nsampling for easy questions that could be accurately answered with just one\nattempt, wasting resources. To tackle this problem, we propose\nDifficulty-Adaptive Self-Consistency (DSC), which leverages the difficulty\ninformation of batch queries from both prior and posterior perspectives to\nadaptively allocate inference resources, further reducing the overall cost of\nSC. To demonstrate the effectiveness of DSC, we conduct extensive experiments\non three popular categories of reasoning tasks: arithmetic, commonsense and\nsymbolic reasoning on six benchmarks. The empirical results show that DSC\nconsistently surpasses the strong baseline ASC and ESC in terms of costs by a\nsignificant margin, while attaining comparable performances.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2408.13457v3",
    "published_date": "2024-08-24 04:03:35 UTC",
    "updated_date": "2025-02-12 02:52:25 UTC"
  },
  {
    "arxiv_id": "2409.06706v3",
    "title": "SAN: Hypothesizing Long-Term Synaptic Development and Neural Engram Mechanism in Scalable Model's Parameter-Efficient Fine-Tuning",
    "authors": [
      "Gaole Dai",
      "Chun-Kai Fan",
      "Yiming Tang",
      "Zhi Zhang",
      "Yuan Zhang",
      "Yulu Gan",
      "Qizhe Zhang",
      "Cheng-Ching Tseng",
      "Shanghang Zhang",
      "Tiejun Huang"
    ],
    "abstract": "Advances in Parameter-Efficient Fine-Tuning (PEFT) bridged the performance\ngap with Full Fine-Tuning (FFT) through sophisticated analysis of pre-trained\nparameter spaces. Starting from drawing insights from Neural Engrams (NE) in\nBiological Neural Networks (BNNs), we establish a connection between the\nlow-rank property observed during PEFT's parameter space shifting and\nneurobiological mechanisms. This observation leads to our proposed method,\nSynapse and Neuron (SAN), which decomposes and propagates scaling components\nfrom anterior feature adjusting vectors towards posterior weight matrices. Our\napproach is theoretically grounded in Long-Term Potentiation/Depression (LTP/D)\nphenomena, which govern synapse development through neurotransmitter release\nmodulation. Extensive experiments demonstrate its effectiveness: on\n\\textbf{vision tasks} across VTAB, FGVC, and GIC (25 datasets) using ViT, SwinT\nand ConvNeXt, SAN outperforms FFT up to 8.7% and LoRA by 3.2%; on language\ntasks using Commonsense Reasoning (8 datasets) with LLaMA models (all\ngenerations), surpassing ChatGPT up to 8.5% and LoRA by 4.7%; on\nvisual-language tasks using Mixed Visual Instruction (7 datasets) with LLaVA\nmodels, it exceeds FFT up to 2.4% and LoRA by 1.9%. Our code and W&B log will\nbe released.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.06706v3",
    "published_date": "2024-08-24 03:27:29 UTC",
    "updated_date": "2025-02-26 07:07:05 UTC"
  },
  {
    "arxiv_id": "2408.13442v1",
    "title": "A Law of Next-Token Prediction in Large Language Models",
    "authors": [
      "Hangfeng He",
      "Weijie J. Su"
    ],
    "abstract": "Large language models (LLMs) have been widely employed across various\napplication domains, yet their black-box nature poses significant challenges to\nunderstanding how these models process input data internally to make\npredictions. In this paper, we introduce a precise and quantitative law that\ngoverns the learning of contextualized token embeddings through intermediate\nlayers in pre-trained LLMs for next-token prediction. Our findings reveal that\neach layer contributes equally to enhancing prediction accuracy, from the\nlowest to the highest layer -- a universal phenomenon observed across a diverse\narray of open-source LLMs, built on architectures such as Transformer, RWKV,\nand Mamba. We demonstrate that this law offers new perspectives and insights to\ninform and guide practices in LLM development and applications, including model\nscaling, pre-training tasks, and information flow. Overall, our law enables\nmore fine-grained approaches to the design, training, and interpretation of\nLLMs through scrutinizing their internal data processing mechanisms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13442v1",
    "published_date": "2024-08-24 02:48:40 UTC",
    "updated_date": "2024-08-24 02:48:40 UTC"
  }
]