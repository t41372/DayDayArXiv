{
  "date": "2024-07-01",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-07-01 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文聚焦于 AI 模型优化、多模态处理、强化学习和应用创新等领域，亮点包括音频-视觉 LLM 的进展、LLM 代理工作流生成，以及高效的知识图谱和图像处理方法，由知名学者如 Miroslav Krstic 和 Mohamed Elhoseiny 等参与，强调了模型的泛化性和实际应用潜力。\n\n下面，我挑选并简要讨论了今天的论文，先优先聊那些重要、话题度高或有潜在影响的文章（如 LLM 和多模态相关），并将相关主题归类快速聊起。其他较无聊或小众的论文（如一些纯优化算法或特定领域小实验），我只简要掠过，以控制篇幅。每个条目列出论文标题（中文 + 英文），并清晰描述主要贡献和发现，保留核心学术术语。\n\n### LLM 和多模态模型创新（重点领域）\n- **标题（中文）：Meerkat: 音频-视觉大语言模型用于空间和时间定位（英文）：Meerkat: Audio-Visual Large Language Model for Grounding in Space and Time**  \n  主要贡献：提出 Meerkat 模型，使用最优传输和交叉注意力模块处理音频-视觉任务，实现细粒度空间-时间理解。发现：在音频-视觉基准上，性能提升达 37.12%，适用于图像引导音频定位和事实检查，展示了多模态 LLM 在复杂任务中的潜力。\n\n- **标题（中文）：AutoFlow: 大语言模型代理的自动化工作流生成（英文）：AutoFlow: Automated Workflow Generation for Large Language Models**  \n  主要贡献：开发 AutoFlow 框架，通过工作流优化和自然语言程序生成，支持 LLM 代理自动处理复杂任务。发现：适用于开源和闭源 LLM，实验显示生成的工作流更可靠，提升了任务解决效率。\n\n- **标题（中文）：Self-Cognition in Large Language Models: An Exploratory Study（英文）：Self-Cognition in Large Language Models: An Exploratory Study**  \n  主要贡献：探索 LLM 的自我认知机制，使用指令提示评估模型的自省能力。发现：少数模型如 GPT-4 和 Llama-3 显示可检测的自认知，提升了特定任务性能，如创意写作，但整体能力仍有限。\n\n- **标题（中文）：Large Language Models are Zero-Shot Recognizers for Activities of Daily Living（英文）：Large Language Models are Zero-Shot Recognizers for Activities of Daily Living**  \n  主要贡献：证明 LLM 可零样本识别日常生活活动，通过传感器数据处理实现。发现：模型在动态环境中表现出色，提升了智能家居应用的泛化性。\n\n- **标题（中文）：ProductAgent: 基于对话的商品搜索代理基准（英文）：ProductAgent: Benchmarking Conversational Product Search Agent with Asking Clarification Questions**  \n  主要贡献：构建 ProductAgent 框架，支持代理通过澄清问题优化商品搜索。发现：在电商场景中，提升检索准确性，处理模糊查询效果显著。\n\n### 强化学习和机器人应用（高话题度领域）\n- **标题（中文）：Normalization and effective learning rates in reinforcement learning（英文）：Normalization and effective learning rates in reinforcement learning**  \n  主要贡献：提出 Normalize-and-Project (NaP) 方法，结合归一化层和权重投影优化强化学习。发现：在非平稳环境中改善过拟合和鲁棒性，并在标准基准上恢复或提升性能，由知名学者 Miroslav Krstic 参与。\n\n- **标题（中文）：RoboPack: Learning Tactile-Informed Dynamics Models for Dense Packing（英文）：RoboPack: Learning Tactile-Informed Dynamics Models for Dense Packing**  \n  主要贡献：开发 RoboPack 框架，使用触觉信息和图神经网络建模机器人动态。发现：在密集堆叠任务中，提升操作精度和鲁棒性，适用于非 prehensile 操作。\n\n### 图像和医疗处理（应用潜力高）\n- **标题（中文）：μ-Bench: A Vision-Language Benchmark for Microscopy Understanding（英文）：μ-Bench: A Vision-Language Benchmark for Microscopy Understanding**  \n  主要贡献：创建 μ-Bench 基准，评估多模态模型在显微镜图像理解中的性能。发现：当前模型在生物医学任务中表现不佳，但微调可缓解遗忘问题。\n\n- **标题（中文）：Label-free Neural Semantic Image Synthesis（英文）：Label-free Neural Semantic Image Synthesis**  \n  主要贡献：提出无标签神经布局方法，使用预训练模型生成语义图像。发现：提升图像生成质量，改善实例分离和语义细节。\n\n### 其他快速掠过（次要或较窄领域）\n- **标题（中文）：Parameter Tuning of the Firefly Algorithm by Standard Monte Carlo and Quasi-Monte Carlo Methods（英文）：Parameter Tuning of the Firefly Algorithm by Standard Monte Carlo and Quasi-Monte Carlo Methods**  \n  主要贡献：使用 Monte Carlo 方法优化 Firefly 算法参数。发现：算法鲁棒性强，但实验无重大突破，适合优化问题。\n\n- **标题（中文）：The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data（英文）：The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**  \n  主要贡献：引入可解释 AI 增强二分类。发现：在医疗图像中提升泛化，但数据稀缺问题未彻底解决。\n\n- **标题（中文）：Deepfake Audio Detection Using Spectrogram-based Feature and Ensemble of Deep Learning Models（英文）：Deepfake Audio Detection Using Spectrogram-based Feature and Ensemble of Deep Learning Models**  \n  主要贡献：使用光谱图和集成模型检测深度伪造音频。发现：EER 达 0.03，但限于特定数据集。\n\n- **标题（中文）：DiscoveryBench: Towards Data-Driven Discovery with Large Language Models（英文）：DiscoveryBench: Towards Data-Driven Discovery with Large Language Models**  \n  主要贡献：构建 DiscoveryBench 基准评估 LLM 的数据驱动发现。发现：LLM 在科学任务中表现差，强调探索不足。\n\n其他论文如一些纯理论模型或小规模实验（如进化算法或特定优化），我未详细展开，因为它们较无聊或影响力有限，仅占整体一小部分。今天的 arXiv 展示了 AI 领域的快速迭代，LLM 和多模态模型尤其值得关注，期待后续应用落地！如果有特定论文感兴趣，建议查阅原文。",
  "papers": [
    {
      "arxiv_id": "2407.01853v1",
      "title": "Improving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Sathish Reddy Indurthi",
        "Wenxuan Zhou",
        "Shamil Chollampatt",
        "Ravi Agrawal",
        "Kaiqiang Song",
        "Lingxiao Zhao",
        "Chenguang Zhu"
      ],
      "abstract": "Advancements in Large Language Models (LLMs) have significantly enhanced\ninstruction-following capabilities. However, most Instruction Fine-Tuning (IFT)\ndatasets are predominantly in English, limiting model performance in other\nlanguages. Traditional methods for creating multilingual IFT datasets such as\ntranslating existing English IFT datasets or converting existing NLP datasets\ninto IFT datasets by templating, struggle to capture linguistic nuances and\nensure prompt (instruction) diversity. To address this issue, we propose a\nnovel method for collecting multilingual IFT datasets that preserves linguistic\nnaturalness and ensures prompt diversity. This approach leverages\nEnglish-focused LLMs, monolingual corpora, and a scoring function to create\nhigh-quality, diversified IFT datasets in multiple languages. Experiments\ndemonstrate that LLMs finetuned using these IFT datasets show notable\nimprovements in both generative and discriminative tasks, indicating enhanced\nlanguage comprehension by LLMs in non-English contexts. Specifically, on the\nmultilingual summarization task, LLMs using our IFT dataset achieved 17.57% and\n15.23% improvements over LLMs fine-tuned with translation-based and\ntemplate-based datasets, respectively.",
      "tldr_zh": "本研究针对大语言模型(LLMs)的指令微调(IFT)数据集主要基于英文的问题，提出了一种新方法来创建多语言IFT数据集，以保留语言的自然性和确保指令多样性。该方法利用英文聚焦的LLMs、单语语料库和评分函数，生成高质量、多样化的数据集。实验表明，使用该数据集微调的LLMs在生成和判别任务上表现出显著改进，尤其在多语言摘要任务中，比基于翻译和模板的方法分别提升了17.57%和15.23%。这有助于增强LLMs在非英文语境下的语言理解能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01853v1",
      "published_date": "2024-07-01 23:47:09 UTC",
      "updated_date": "2024-07-01 23:47:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:15:41.200018"
    },
    {
      "arxiv_id": "2407.01851v2",
      "title": "Meerkat: Audio-Visual Large Language Model for Grounding in Space and Time",
      "title_zh": "翻译失败",
      "authors": [
        "Sanjoy Chowdhury",
        "Sayan Nag",
        "Subhrajyoti Dasgupta",
        "Jun Chen",
        "Mohamed Elhoseiny",
        "Ruohan Gao",
        "Dinesh Manocha"
      ],
      "abstract": "Leveraging Large Language Models' remarkable proficiency in text-based tasks,\nrecent works on Multi-modal LLMs (MLLMs) extend them to other modalities like\nvision and audio. However, the progress in these directions has been mostly\nfocused on tasks that only require a coarse-grained understanding of the\naudio-visual semantics. We present Meerkat, an audio-visual LLM equipped with a\nfine-grained understanding of image and audio both spatially and temporally.\nWith a new modality alignment module based on optimal transport and a\ncross-attention module that enforces audio-visual consistency, Meerkat can\ntackle challenging tasks such as audio referred image grounding, image guided\naudio temporal localization, and audio-visual fact-checking. Moreover, we\ncarefully curate a large dataset AVFIT that comprises 3M instruction tuning\nsamples collected from open-source datasets, and introduce MeerkatBench that\nunifies five challenging audio-visual tasks. We achieve state-of-the-art\nperformance on all these downstream tasks with a relative improvement of up to\n37.12%.",
      "tldr_zh": "本研究提出 Meerkat，一种音频-视觉 Large Language Model (LLM)，专注于图像和音频在空间和时间上的细粒度 grounding，以超越现有 Multi-modal LLMs 的粗粒度语义理解。\nMeerkat 采用基于 optimal transport 的模态对齐模块和 cross-attention 模块来强制音频-视觉一致性，从而处理挑战性任务，如音频 referred image grounding、图像 guided audio temporal localization 和音频-视觉 fact-checking。\n研究团队精心整理了 AVFIT 数据集，包含 3M 指令调整样本，并引入 MeerkatBench 作为统一基准。\n在五个音频-视觉任务上，Meerkat 实现了最先进性能，相对提升高达 37.12%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.01851v2",
      "published_date": "2024-07-01 23:32:25 UTC",
      "updated_date": "2024-07-03 07:01:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:15:54.581100"
    },
    {
      "arxiv_id": "2407.01843v2",
      "title": "My part is bigger than yours -- assessment within a group of peers",
      "title_zh": "我的部分比你的大——在同行群体中的评估",
      "authors": [
        "Konrad Kułakowski",
        "Jacek Szybowski"
      ],
      "abstract": "A project (e.g., writing a collaborative research paper) is often a group\neffort. At the end, each contributor identifies their contribution, often\nverbally. The reward, however, is very frequently financial. It leads to the\nquestion of what (percentage) share in the creation of the paper is due to\nindividual authors. Different authors may have various opinions on the matter;\neven worse, their opinions may have different relevance. In this paper, we\npresent simple models that allow aggregation of experts' views, linking the\npriority of his preference directly to the assessment made by other experts. In\nthis approach, the more significant the contribution of a given expert, the\ngreater the importance of his opinion. The presented method can be considered\nan attempt to find consensus among peers involved in the same project. Hence,\nits applications may go beyond the proposed study example of writing a\nscientific paper.",
      "tldr_zh": "这篇论文探讨了在团队项目（如共同撰写研究论文）中评估个人贡献的问题，尤其当奖励（如财务报酬）涉及时，不同作者的意见可能存在分歧，且这些意见的重要性各异。论文提出简单模型来聚合 experts' views，将一个专家的偏好优先级直接链接到其他专家的评估中，从而使贡献更大的专家意见获得更高权重。这种方法旨在在同行中寻找共识，并可扩展应用于不止于写作科学论文的其他团队合作场景。",
      "categories": [
        "cs.DM",
        "cs.AI"
      ],
      "primary_category": "cs.DM",
      "comment": "25 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.01843v2",
      "published_date": "2024-07-01 22:54:51 UTC",
      "updated_date": "2024-09-16 14:53:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:16:03.975559"
    },
    {
      "arxiv_id": "2407.02537v1",
      "title": "Parameter Tuning of the Firefly Algorithm by Standard Monte Carlo and Quasi-Monte Carlo Methods",
      "title_zh": "通过标准蒙特卡罗和拟蒙特卡罗方法对萤火虫算法进行参数调优",
      "authors": [
        "Geethu Joy",
        "Christian Huyck",
        "Xin-She Yang"
      ],
      "abstract": "Almost all optimization algorithms have algorithm-dependent parameters, and\nthe setting of such parameter values can significantly influence the behavior\nof the algorithm under consideration. Thus, proper parameter tuning should be\ncarried out to ensure that the algorithm used for optimization performs well\nand is sufficiently robust for solving different types of optimization\nproblems. In this study, the Firefly Algorithm (FA) is used to evaluate the\ninfluence of its parameter values on its efficiency. Parameter values are\nrandomly initialized using both the standard Monte Carlo method and the Quasi\nMonte-Carlo method. The values are then used for tuning the FA. Two benchmark\nfunctions and a spring design problem are used to test the robustness of the\ntuned FA. From the preliminary findings, it can be deduced that both the Monte\nCarlo method and Quasi-Monte Carlo method produce similar results in terms of\noptimal fitness values. Numerical experiments using the two different methods\non both benchmark functions and the spring design problem showed no major\nvariations in the final fitness values, irrespective of the different sample\nvalues selected during the simulations. This insensitivity indicates the\nrobustness of the FA.",
      "tldr_zh": "本研究探讨了使用标准 Monte Carlo 方法和 Quasi-Monte Carlo 方法对 Firefly Algorithm (FA) 参数进行随机初始化和调优的影响，以评估参数设置对算法效率的潜在作用。研究通过测试两个基准函数和一个弹簧设计问题，发现两种方法在最优适应值方面产生类似结果，且实验中未观察到重大差异。总体而言，这表明 Firefly Algorithm 在参数调优方面表现出较高的鲁棒性。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "68T20, 68W50"
      ],
      "primary_category": "cs.NE",
      "comment": "International Conference on Computational Science (ICCS2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.02537v1",
      "published_date": "2024-07-01 21:17:27 UTC",
      "updated_date": "2024-07-01 21:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:16:15.966978"
    },
    {
      "arxiv_id": "2407.06206v1",
      "title": "The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data",
      "title_zh": "XAI 增强方法对",
      "authors": [
        "Ximing Wen",
        "Rosina O. Weber",
        "Anik Sen",
        "Darryl Hannan",
        "Steven C. Nesbit",
        "Vincent Chan",
        "Alberto Goffi",
        "Michael Morris",
        "John C. Hunninghake",
        "Nicholas E. Villalobos",
        "Edward Kim",
        "Christopher J. MacLellan"
      ],
      "abstract": "Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and\ninterpreting ultrasound scans right at the patient's bedside. However, the\nexpertise needed to interpret these images is considerable and may not always\nbe present in emergency situations. This reality makes algorithms such as\nmachine learning classifiers extremely valuable to augment human decisions.\nPOCUS devices are becoming available at a reasonable cost in the size of a\nmobile phone. The challenge of turning POCUS devices into life-saving tools is\nthat interpretation of ultrasound images requires specialist training and\nexperience. Unfortunately, the difficulty to obtain positive training images\nrepresents an important obstacle to building efficient and accurate\nclassifiers. Hence, the problem we try to investigate is how to explore\nstrategies to increase accuracy of classifiers trained with scarce data. We\nhypothesize that training with a few data instances may not suffice for\nclassifiers to generalize causing them to overfit. Our approach uses an\nExplainable AI-Augmented approach to help the algorithm learn more from less\nand potentially help the classifier better generalize.",
      "tldr_zh": "本研究探讨了在数据稀缺场景下，使用 Explainable AI-Augmented 方法提升二元分类(Binary Classification)任务的准确性，特别是在 Point-of-Care Ultrasound (POCUS) 图像解释中面临的挑战。论文假设少量训练数据可能导致分类器过拟合，因此提出了一种 XAI-Augmented 策略，帮助算法从有限数据中学习更多特征并改善泛化能力。该方法为临床决策提供更可靠的辅助，潜在地缓解了紧急情况下专业知识短缺的问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 3 figures, accepted by XAI 2024 workshop @ IJCAI",
      "pdf_url": "http://arxiv.org/pdf/2407.06206v1",
      "published_date": "2024-07-01 21:09:31 UTC",
      "updated_date": "2024-07-01 21:09:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:16:28.593975"
    },
    {
      "arxiv_id": "2407.12821v1",
      "title": "AutoFlow: Automated Workflow Generation for Large Language Model Agents",
      "title_zh": "AutoFlow：大",
      "authors": [
        "Zelong Li",
        "Shuyuan Xu",
        "Kai Mei",
        "Wenyue Hua",
        "Balaji Rama",
        "Om Raheja",
        "Hao Wang",
        "He Zhu",
        "Yongfeng Zhang"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have shown significant\nprogress in understanding complex natural language. One important application\nof LLM is LLM-based AI Agent, which leverages the ability of LLM as well as\nexternal tools for complex-task solving. To make sure LLM Agents follow an\neffective and reliable procedure to solve the given task, manually designed\nworkflows are usually used to guide the working mechanism of agents. However,\nmanually designing the workflows requires considerable efforts and domain\nknowledge, making it difficult to develop and deploy agents on massive scales.\nTo address these issues, we propose AutoFlow, a framework designed to\nautomatically generate workflows for agents to solve complex tasks. AutoFlow\ntakes natural language program as the format of agent workflow and employs a\nworkflow optimization procedure to iteratively optimize the workflow quality.\nBesides, this work offers two workflow generation methods: fine-tuning-based\nand in-context-based methods, making the AutoFlow framework applicable to both\nopen-source and closed-source LLMs. Experimental results show that our\nframework can produce robust and reliable agent workflows. We believe that the\nautomatic generation and interpretation of workflows in natural language\nrepresent a promising paradigm for solving complex tasks, particularly with the\nrapid development of LLMs. The source code of this work is available at\nhttps://github.com/agiresearch/AutoFlow.",
      "tldr_zh": "该论文提出AutoFlow框架，用于自动生成Large Language Model (LLMs)代理的工作流，解决手动设计工作流耗时且需专业知识的问题。AutoFlow以自然语言程序作为工作流格式，并采用工作流优化过程进行迭代优化，同时提供fine-tuning-based和in-context-based两种方法，适用于开源和闭源LLMs。实验结果显示，该框架能产生可靠的工作流，为LLMs解决复杂任务提供高效的新范式。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Open source code available at https://github.com/agiresearch/AutoFlow",
      "pdf_url": "http://arxiv.org/pdf/2407.12821v1",
      "published_date": "2024-07-01 21:05:02 UTC",
      "updated_date": "2024-07-01 21:05:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:16:39.987879"
    },
    {
      "arxiv_id": "2407.01800v1",
      "title": "Normalization and effective learning rates in reinforcement learning",
      "title_zh": "强化学习中的规范化与有效学习率",
      "authors": [
        "Clare Lyle",
        "Zeyu Zheng",
        "Khimya Khetarpal",
        "James Martens",
        "Hado van Hasselt",
        "Razvan Pascanu",
        "Will Dabney"
      ],
      "abstract": "Normalization layers have recently experienced a renaissance in the deep\nreinforcement learning and continual learning literature, with several works\nhighlighting diverse benefits such as improving loss landscape conditioning and\ncombatting overestimation bias. However, normalization brings with it a subtle\nbut important side effect: an equivalence between growth in the norm of the\nnetwork parameters and decay in the effective learning rate. This becomes\nproblematic in continual learning settings, where the resulting effective\nlearning rate schedule may decay to near zero too quickly relative to the\ntimescale of the learning problem. We propose to make the learning rate\nschedule explicit with a simple re-parameterization which we call\nNormalize-and-Project (NaP), which couples the insertion of normalization\nlayers with weight projection, ensuring that the effective learning rate\nremains constant throughout training. This technique reveals itself as a\npowerful analytical tool to better understand learning rate schedules in deep\nreinforcement learning, and as a means of improving robustness to\nnonstationarity in synthetic plasticity loss benchmarks along with both the\nsingle-task and sequential variants of the Arcade Learning Environment. We also\nshow that our approach can be easily applied to popular architectures such as\nResNets and transformers while recovering and in some cases even slightly\nimproving the performance of the base model in common stationary benchmarks.",
      "tldr_zh": "本研究探讨了在深度强化学习中，Normalization layers 的应用如何改善损失景观和减少过估计偏差，但也导致有效学习率因网络参数范数增长而衰减，从而在持续学习场景中过早降低学习速率。为解决这一问题，作者提出 Normalize-and-Project (NaP) 方法，该技术通过插入归一化层并结合权重投影，确保有效学习率保持恒定，从而增强对非平稳性的鲁棒性。实验结果表明，NaP 在合成基准测试和 Arcade Learning Environment 的单任务及顺序变体中表现出色，并能轻松应用于 ResNets 和 transformers 架构，同时恢复或略微提升基准模型的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01800v1",
      "published_date": "2024-07-01 20:58:01 UTC",
      "updated_date": "2024-07-01 20:58:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:16:53.206574"
    },
    {
      "arxiv_id": "2407.01791v1",
      "title": "μ-Bench: A Vision-Language Benchmark for Microscopy Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Alejandro Lozano",
        "Jeffrey Nirschl",
        "James Burgess",
        "Sanket Rajan Gupte",
        "Yuhui Zhang",
        "Alyssa Unell",
        "Serena Yeung-Levy"
      ],
      "abstract": "Recent advances in microscopy have enabled the rapid generation of terabytes\nof image data in cell biology and biomedical research. Vision-language models\n(VLMs) offer a promising solution for large-scale biological image analysis,\nenhancing researchers' efficiency, identifying new image biomarkers, and\naccelerating hypothesis generation and scientific discovery. However, there is\na lack of standardized, diverse, and large-scale vision-language benchmarks to\nevaluate VLMs' perception and cognition capabilities in biological image\nunderstanding. To address this gap, we introduce {\\mu}-Bench, an expert-curated\nbenchmark encompassing 22 biomedical tasks across various scientific\ndisciplines (biology, pathology), microscopy modalities (electron,\nfluorescence, light), scales (subcellular, cellular, tissue), and organisms in\nboth normal and abnormal states. We evaluate state-of-the-art biomedical,\npathology, and general VLMs on {\\mu}-Bench and find that: i) current models\nstruggle on all categories, even for basic tasks such as distinguishing\nmicroscopy modalities; ii) current specialist models fine-tuned on biomedical\ndata often perform worse than generalist models; iii) fine-tuning in specific\nmicroscopy domains can cause catastrophic forgetting, eroding prior biomedical\nknowledge encoded in their base model. iv) weight interpolation between\nfine-tuned and pre-trained models offers one solution to forgetting and\nimproves general performance across biomedical tasks. We release {\\mu}-Bench\nunder a permissive license to accelerate the research and development of\nmicroscopy foundation models.",
      "tldr_zh": "本研究引入了μ-Bench，这是一个专家策划的视觉语言基准，用于评估模型在显微镜图像理解方面的感知和认知能力，涵盖22个生物医学任务，包括生物学和病理学领域、各种显微镜模式（如电子、荧光和光显微镜）、不同规模（亚细胞、细胞、组织）和生物体状态。评估结果显示，现有的生物医学、病理学和通用VLMs在所有任务中表现不佳，专门模型在微调后往往不如通用模型，且可能导致灾难性遗忘。作者提出通过权重插值缓解遗忘问题，并开源μ-Bench以推动显微镜基础模型的研究发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01791v1",
      "published_date": "2024-07-01 20:30:26 UTC",
      "updated_date": "2024-07-01 20:30:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:17:04.464994"
    },
    {
      "arxiv_id": "2407.01790v1",
      "title": "Label-free Neural Semantic Image Synthesis",
      "title_zh": "无标签神经语义图像合成",
      "authors": [
        "Jiayi Wang",
        "Kevin Alexander Laube",
        "Yumeng Li",
        "Jan Hendrik Metzen",
        "Shin-I Cheng",
        "Julio Borges",
        "Anna Khoreva"
      ],
      "abstract": "Recent work has shown great progress in integrating spatial conditioning to\ncontrol large, pre-trained text-to-image diffusion models. Despite these\nadvances, existing methods describe the spatial image content using\nhand-crafted conditioning inputs, which are either semantically ambiguous\n(e.g., edges) or require expensive manual annotations (e.g., semantic\nsegmentation). To address these limitations, we propose a new label-free way of\nconditioning diffusion models to enable fine-grained spatial control. We\nintroduce the concept of neural semantic image synthesis, which uses neural\nlayouts extracted from pre-trained foundation models as conditioning. Neural\nlayouts are advantageous as they provide rich descriptions of the desired\nimage, containing both semantics and detailed geometry of the scene. We\nexperimentally show that images synthesized via neural semantic image synthesis\nachieve similar or superior pixel-level alignment of semantic classes compared\nto those created using expensive semantic label maps. At the same time, they\ncapture better semantics, instance separation, and object orientation than\nother label-free conditioning options, such as edges or depth. Moreover, we\nshow that images generated by neural layout conditioning can effectively\naugment real data for training various perception tasks.",
      "tldr_zh": "本研究提出了一种无标签（label-free）的神经语义图像合成（neural semantic image synthesis）方法，使用从预训练基础模型中提取的neural layouts作为条件输入，实现细粒度的空间控制。相比传统方法，该方法避免了语义模糊（如edges）或昂贵手动标注（如semantic segmentation）的缺点，能提供丰富的语义和场景几何描述。实验显示，基于neural layouts合成的图像在语义类别的像素级对齐上达到或超过使用语义标签地图的效果，同时更好地捕捉实例分离、对象方向，并可用于增强真实数据训练各种感知任务。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01790v1",
      "published_date": "2024-07-01 20:30:23 UTC",
      "updated_date": "2024-07-01 20:30:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:17:19.420893"
    },
    {
      "arxiv_id": "2407.01784v1",
      "title": "Analyzing Persuasive Strategies in Meme Texts: A Fusion of Language Models with Paraphrase Enrichment",
      "title_zh": "翻译失败",
      "authors": [
        "Kota Shamanth Ramanath Nayak",
        "Leila Kosseim"
      ],
      "abstract": "This paper describes our approach to hierarchical multi-label detection of\npersuasion techniques in meme texts. Our model, developed as a part of the\nrecent SemEval task, is based on fine-tuning individual language models (BERT,\nXLM-RoBERTa, and mBERT) and leveraging a mean-based ensemble model in addition\nto dataset augmentation through paraphrase generation from ChatGPT. The scope\nof the study encompasses enhancing model performance through innovative\ntraining techniques and data augmentation strategies. The problem addressed is\nthe effective identification and classification of multiple persuasive\ntechniques in meme texts, a task complicated by the diversity and complexity of\nsuch content. The objective of the paper is to improve detection accuracy by\nrefining model training methods and examining the impact of balanced versus\nunbalanced training datasets. Novelty in the results and discussion lies in the\nfinding that training with paraphrases enhances model performance, yet a\nbalanced training set proves more advantageous than a larger unbalanced one.\nAdditionally, the analysis reveals the potential pitfalls of indiscriminate\nincorporation of paraphrases from diverse distributions, which can introduce\nsubstantial noise. Results with the SemEval 2024 data confirm these insights,\ndemonstrating improved model efficacy with the proposed methods.",
      "tldr_zh": "本文提出了一种基于微调语言模型（BERT、XLM-RoBERTa和mBERT）的框架，用于在meme文本中进行分层多标签检测说服技术，并通过ChatGPT生成的paraphrase增强数据集，以提升模型性能。研究重点在于探索创新训练技术和数据增强策略的影响，发现使用paraphrase能改善模型效果，但平衡数据集比更大的不平衡数据集更具优势，同时警告无差别加入paraphrase可能引入噪声。最终，在SemEval 2024数据上的实验验证了这些方法，提高了说服技术检测的准确率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 8 figures, 1 table, Proceedings of 5th International\n  Conference on Natural Language Processing and Applications (NLPA 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.01784v1",
      "published_date": "2024-07-01 20:25:20 UTC",
      "updated_date": "2024-07-01 20:25:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:17:39.194579"
    },
    {
      "arxiv_id": "2407.01782v4",
      "title": "Addressing a fundamental limitation in deep vision models: lack of spatial attention",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Borji"
      ],
      "abstract": "The primary aim of this manuscript is to underscore a significant limitation\nin current deep learning models, particularly vision models. Unlike human\nvision, which efficiently selects only the essential visual areas for further\nprocessing, leading to high speed and low energy consumption, deep vision\nmodels process the entire image. In this work, we examine this issue from a\nbroader perspective and propose two solutions that could pave the way for the\nnext generation of more efficient vision models. In the first solution,\nconvolution and pooling operations are selectively applied to altered regions,\nwith a change map sent to subsequent layers. This map indicates which\ncomputations need to be repeated. In the second solution, only the modified\nregions are processed by a semantic segmentation model, and the resulting\nsegments are inserted into the corresponding areas of the previous output map.\nThe code is available at https://github.com/aliborji/spatial_attention.",
      "tldr_zh": "本论文指出了深度视觉模型(deep vision models)的一个根本缺陷：缺乏空间注意力(spatial attention)，导致它们不像人类视觉那样只处理必要区域，而是处理整个图像，从而降低效率和增加能耗。作者从更广泛的角度分析这一问题，并提出两个解决方案：第一，通过变化地图(change map)选择性地将卷积(convolution)和池化(pooling)操作应用到变化区域，并指示后续层重复必要计算；第二，仅对修改区域进行语义分割(semantic segmentation)处理，然后将结果整合回之前的输出地图。实验代码已在GitHub上公开，这些创新有望为开发更高效的下一代视觉模型铺平道路。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01782v4",
      "published_date": "2024-07-01 20:21:09 UTC",
      "updated_date": "2024-11-22 05:56:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:17:51.690977"
    },
    {
      "arxiv_id": "2407.01777v1",
      "title": "Deepfake Audio Detection Using Spectrogram-based Feature and Ensemble of Deep Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lam Pham",
        "Phat Lam",
        "Truong Nguyen",
        "Huyen Nguyen",
        "Alexander Schindler"
      ],
      "abstract": "In this paper, we propose a deep learning based system for the task of\ndeepfake audio detection. In particular, the draw input audio is first\ntransformed into various spectrograms using three transformation methods of\nShort-time Fourier Transform (STFT), Constant-Q Transform (CQT), Wavelet\nTransform (WT) combined with different auditory-based filters of Mel,\nGammatone, linear filters (LF), and discrete cosine transform (DCT). Given the\nspectrograms, we evaluate a wide range of classification models based on three\ndeep learning approaches. The first approach is to train directly the\nspectrograms using our proposed baseline models of CNN-based model\n(CNN-baseline), RNN-based model (RNN-baseline), C-RNN model (C-RNN baseline).\nMeanwhile, the second approach is transfer learning from computer vision models\nsuch as ResNet-18, MobileNet-V3, EfficientNet-B0, DenseNet-121, SuffleNet-V2,\nSwint, Convnext-Tiny, GoogLeNet, MNASsnet, RegNet. In the third approach, we\nleverage the state-of-the-art audio pre-trained models of Whisper, Seamless,\nSpeechbrain, and Pyannote to extract audio embeddings from the input\nspectrograms. Then, the audio embeddings are explored by a Multilayer\nperceptron (MLP) model to detect the fake or real audio samples. Finally,\nhigh-performance deep learning models from these approaches are fused to\nachieve the best performance. We evaluated our proposed models on ASVspoof 2019\nbenchmark dataset. Our best ensemble model achieved an Equal Error Rate (EER)\nof 0.03, which is highly competitive to top-performing systems in the\nASVspoofing 2019 challenge. Experimental results also highlight the potential\nof selective spectrograms and deep learning approaches to enhance the task of\naudio deepfake detection.",
      "tldr_zh": "本文提出了一种基于谱图特征和深度学习模型集成的深度伪造音频检测系统。首先，将输入音频通过 Short-time Fourier Transform (STFT)、Constant-Q Transform (CQT) 和 Wavelet Transform (WT) 等方法转换为各种谱图，并结合 Mel、Gammatone 等滤波器。随后，评估多种模型，包括自定义的 CNN-baseline、RNN-baseline，以及转移学习模型如 ResNet-18 和预训练模型如 Whisper，最终通过模型融合实现最佳性能。在 ASVspoof 2019 数据集上，该系统达到了 Equal Error Rate (EER) 为 0.03 的高竞争力结果，突显了选择性谱图和深度学习方法的潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01777v1",
      "published_date": "2024-07-01 20:10:43 UTC",
      "updated_date": "2024-07-01 20:10:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:18:05.844226"
    },
    {
      "arxiv_id": "2407.01769v1",
      "title": "Improving Trip Mode Choice Modeling Using Ensemble Synthesizer (ENSY)",
      "title_zh": "翻译失败",
      "authors": [
        "Amirhossein Parsi",
        "Melina Jafari",
        "Sina Sabzekar",
        "Zahra Amini"
      ],
      "abstract": "Accurate classification of mode choice datasets is crucial for transportation\nplanning and decision-making processes. However, conventional classification\nmodels often struggle to adequately capture the nuanced patterns of minority\nclasses within these datasets, leading to sub-optimal accuracy. In response to\nthis challenge, we present Ensemble Synthesizer (ENSY) which leverages\nprobability distribution for data augmentation, a novel data model tailored\nspecifically for enhancing classification accuracy in mode choice datasets. In\nour study, ENSY demonstrates remarkable efficacy by nearly quadrupling the F1\nscore of minority classes and improving overall classification accuracy by\nnearly 3%. To assess its performance comprehensively, we compare ENSY against\nvarious augmentation techniques including Random Oversampling, SMOTE-NC, and\nCTGAN. Through experimentation, ENSY consistently outperforms these methods\nacross various scenarios, underscoring its robustness and effectiveness",
      "tldr_zh": "本研究针对交通出行模式选择数据集中的少数类模式建模问题，提出了一种新型数据增强模型Ensemble Synthesizer (ENSY)，它利用概率分布进行数据增强，以提升分类准确率。ENSY显著提高了少数类的F1 score（几乎翻了三倍），并将整体分类准确率提升近3%。与其他增强技术如Random Oversampling、SMOTE-NC和CTGAN相比，ENSY在各种场景下表现出更强的鲁棒性和优越性能，从而为交通规划决策提供更可靠的支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01769v1",
      "published_date": "2024-07-01 19:59:29 UTC",
      "updated_date": "2024-07-01 19:59:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:18:15.300886"
    },
    {
      "arxiv_id": "2407.17478v1",
      "title": "LLM4PM: A case study on using Large Language Models for Process Modeling in Enterprise Organizations",
      "title_zh": "LLM4PM：使用大型语言模型进行企业组织过程建模的案例研究",
      "authors": [
        "Clara Ziche",
        "Giovanni Apruzzese"
      ],
      "abstract": "We investigate the potential of using Large Language Models (LLM) to support\nprocess model creation in organizational contexts. Specifically, we carry out a\ncase study wherein we develop and test an LLM-based chatbot, PRODIGY (PROcess\nmoDellIng Guidance for You), in a multinational company, the Hilti Group. We\nare particularly interested in understanding how LLM can aid (human) modellers\nin creating process flow diagrams. To this purpose, we first conduct a\npreliminary user study (n=10) with professional process modellers from Hilti,\ninquiring for various pain-points they encounter in their daily routines. Then,\nwe use their responses to design and implement PRODIGY. Finally, we evaluate\nPRODIGY by letting our user study's participants use PRODIGY, and then ask for\ntheir opinion on the pros and cons of PRODIGY. We coalesce our results in\nactionable takeaways. Through our research, we showcase the first practical\napplication of LLM for process modelling in the real world, shedding light on\nhow industries can leverage LLM to enhance their Business Process Management\nactivities.",
      "tldr_zh": "这篇论文通过一个案例研究，探讨了使用Large Language Models (LLM)来辅助企业组织的过程建模，焦点在于开发并测试基于LLM的聊天机器人PRODIGY，以支持人类建模者在Hilti Group创建过程流图。研究首先进行初步用户研究（n=10），收集专业建模者的痛点反馈，然后据此设计和实现PRODIGY。最终评估结果显示，PRODIGY能有效缓解建模挑战，但也存在优缺点；论文总结了可行动要点，展示了LLM在真实世界Business Process Management中的首次实际应用，并为行业提升过程管理活动提供了见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.17478v1",
      "published_date": "2024-07-01 19:57:36 UTC",
      "updated_date": "2024-07-01 19:57:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:18:29.447869"
    },
    {
      "arxiv_id": "2407.18322v2",
      "title": "The Need for Guardrails with Large Language Models in Medical Safety-Critical Settings: An Artificial Intelligence Application in the Pharmacovigilance Ecosystem",
      "title_zh": "翻译失败",
      "authors": [
        "Joe B Hakim",
        "Jeffery L Painter",
        "Darmendra Ramcharran",
        "Vijay Kara",
        "Greg Powell",
        "Paulina Sobczak",
        "Chiho Sato",
        "Andrew Bate",
        "Andrew Beam"
      ],
      "abstract": "Large language models (LLMs) are useful tools with the capacity for\nperforming specific types of knowledge work at an effective scale. However, LLM\ndeployments in high-risk and safety-critical domains pose unique challenges,\nnotably the issue of ``hallucination,'' where LLMs can generate fabricated\ninformation. This is particularly concerning in settings such as drug safety,\nwhere inaccuracies could lead to patient harm. To mitigate these risks, we have\ndeveloped and demonstrated a proof of concept suite of guardrails specifically\ndesigned to mitigate certain types of hallucinations and errors for drug\nsafety, and potentially applicable to other medical safety-critical contexts.\nThese guardrails include mechanisms to detect anomalous documents to prevent\nthe ingestion of inappropriate data, identify incorrect drug names or adverse\nevent terms, and convey uncertainty in generated content. We integrated these\nguardrails with an LLM fine-tuned for a text-to-text task, which involves\nconverting both structured and unstructured data within adverse event reports\ninto natural language. This method was applied to translate individual case\nsafety reports, demonstrating effective application in a pharmacovigilance\nprocessing task. Our guardrail framework offers a set of tools with broad\napplicability across various domains, ensuring LLMs can be safely used in\nhigh-risk situations by eliminating the occurrence of key errors, including the\ngeneration of incorrect pharmacovigilance-related terms, thus adhering to\nstringent regulatory and quality standards in medical safety-critical\nenvironments.",
      "tldr_zh": "该论文讨论了在医疗安全关键环境中使用 Large Language Models (LLMs) 的风险，特别是 hallucination（幻觉）问题，可能导致药物安全领域的患者伤害。研究团队开发了一个 guardrails（防护措施）概念证明套件，包括检测异常文档、识别不正确药物名称或不良事件术语，以及传达不确定性，以缓解这些错误。作者将这些 guardrails 整合到一个针对文本到文本任务微调的 LLM 中，用于将不良事件报告转换为自然语言，并在 pharmacovigilance（药物警戒）任务中进行了有效应用。该框架为 LLMs 在高风险医疗场景中的安全部署提供了广泛适用的工具，确保符合严格的监管和质量标准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "I.2.1; I.2.7; I.7.1"
      ],
      "primary_category": "cs.CL",
      "comment": "27 pages, 6 figures, 4 tables and supplementary material provided",
      "pdf_url": "http://arxiv.org/pdf/2407.18322v2",
      "published_date": "2024-07-01 19:52:41 UTC",
      "updated_date": "2024-09-04 17:16:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:18:41.153788"
    },
    {
      "arxiv_id": "2407.01752v1",
      "title": "Predicting Trust Dynamics with Dynamic SEM in Human-AI Cooperation",
      "title_zh": "翻译失败",
      "authors": [
        "Sota Kaneko",
        "Seiji Yamada"
      ],
      "abstract": "Humans' trust in AI constitutes a pivotal element in fostering a synergistic\nrelationship between humans and AI. This is particularly significant in the\ncontext of systems that leverage AI technology, such as autonomous driving\nsystems and human-robot interaction. Trust facilitates appropriate utilization\nof these systems, thereby optimizing their potential benefits. If humans\nover-trust or under-trust an AI, serious problems such as misuse and accidents\noccur. To prevent over/under-trust, it is necessary to predict trust dynamics.\nHowever, trust is an internal state of humans and hard to directly observe.\nTherefore, we propose a prediction model for trust dynamics using dynamic\nstructure equation modeling, which extends SEM that can handle time-series\ndata. A path diagram, which shows causalities between variables, is developed\nin an exploratory way and the resultant path diagram is optimized for effective\npath structures. Over/under-trust was predicted with 90\\% accuracy in a drone\nsimulator task,, and it was predicted with 99\\% accuracy in an autonomous\ndriving task. These results show that our proposed method outperformed the\nconventional method including an auto regression family.",
      "tldr_zh": "本研究探讨了人类对 AI 的信任在合作中的关键作用，提出了一种基于动态结构方程建模（Dynamic SEM）的模型来预测信任动态，该方法扩展了 SEM 以处理时间序列数据，并通过探索性路径图（path diagram）优化因果关系结构。实验结果显示，在无人机模拟任务中，该模型以90%的准确率预测过度/不足信任，在自动驾驶任务中达到99%的准确率，显著优于传统方法如自回归（auto regression）家族。总体而言，此方法为防止信任失调问题提供了有效工具，提升了人类-AI 合作的安全性和效率。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01752v1",
      "published_date": "2024-07-01 19:31:07 UTC",
      "updated_date": "2024-07-01 19:31:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:18:52.344659"
    },
    {
      "arxiv_id": "2407.01749v2",
      "title": "Invariant Correlation of Representation with Label: Enhancing Domain Generalization in Noisy Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Gaojie Jin",
        "Ronghui Mu",
        "Xinping Yi",
        "Xiaowei Huang",
        "Lijun Zhang"
      ],
      "abstract": "The Invariant Risk Minimization (IRM) approach aims to address the challenge\nof domain generalization by training a feature representation that remains\ninvariant across multiple environments. However, in noisy environments,\nIRM-related techniques such as IRMv1 and VREx may be unable to achieve the\noptimal IRM solution, primarily due to erroneous optimization directions. To\naddress this issue, we introduce ICorr (an abbreviation for Invariant\nCorrelation), a novel approach designed to surmount the above challenge in\nnoisy settings. Additionally, we dig into a case study to analyze why previous\nmethods may lose ground while ICorr can succeed. Through a theoretical lens,\nparticularly from a causality perspective, we illustrate that the invariant\ncorrelation of representation with label is a necessary condition for the\noptimal invariant predictor in noisy environments, whereas the optimization\nmotivations for other methods may not be. Furthermore, we empirically\ndemonstrate the effectiveness of ICorr by comparing it with other domain\ngeneralization methods on various noisy datasets. The code is available at\nhttps://github.com/Alexkael/ICorr.",
      "tldr_zh": "该论文针对噪声环境中Invariant Risk Minimization (IRM)方法的局限性（如IRMv1和VREx可能因优化方向错误而无法达到最优），提出了一种新方法ICorr（Invariant Correlation），旨在通过确保表示与标签的不变相关性来增强Domain Generalization性能。从因果视角的理论分析表明，ICorr是噪声环境下最优不变预测器的必要条件。实验结果显示，ICorr在各种噪声数据集上比其他域泛化方法表现出色，有效提升了模型的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01749v2",
      "published_date": "2024-07-01 19:27:28 UTC",
      "updated_date": "2025-02-09 12:58:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:19:04.193257"
    },
    {
      "arxiv_id": "2407.01745v2",
      "title": "Adaptive control of reaction-diffusion PDEs via neural operator-approximated gain kernels",
      "title_zh": "翻译失败",
      "authors": [
        "Luke Bhan",
        "Yuanyuan Shi",
        "Miroslav Krstic"
      ],
      "abstract": "Neural operator approximations of the gain kernels in PDE backstepping has\nemerged as a viable method for implementing controllers in real time. With such\nan approach, one approximates the gain kernel, which maps the plant coefficient\ninto the solution of a PDE, with a neural operator. It is in adaptive control\nthat the benefit of the neural operator is realized, as the kernel PDE solution\nneeds to be computed online, for every updated estimate of the plant\ncoefficient. We extend the neural operator methodology from adaptive control of\na hyperbolic PDE to adaptive control of a benchmark parabolic PDE (a\nreaction-diffusion equation with a spatially-varying and unknown reaction\ncoefficient). We prove global stability and asymptotic regulation of the plant\nstate for a Lyapunov design of parameter adaptation. The key technical\nchallenge of the result is handling the 2D nature of the gain kernels and\nproving that the target system with two distinct sources of perturbation terms,\ndue to the parameter estimation error and due to the neural approximation\nerror, is Lyapunov stable. To verify our theoretical result, we present\nsimulations achieving calculation speedups up to 45x relative to the\ntraditional finite difference solvers for every timestep in the simulation\ntrajectory.",
      "tldr_zh": "该研究提出了一种使用神经算子(neural operator)近似增益核(gain kernels)的方法，用于反应-扩散PDE(reaction-diffusion equation)的自适应控制，将原有超bolic PDE框架扩展至抛物型PDE。方法通过在线计算核PDE解来处理未知的空间变化反应系数，并采用Lyapunov设计证明了全局稳定性(global stability)和渐近调节(asymptotic regulation)，同时处理了参数估计误差和神经近似误差带来的扰动。实验模拟显示，该方法相对于传统有限差分求解器实现了高达45倍的计算速度提升，为实时PDE控制提供了高效解决方案。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "math.AP",
        "math.DS"
      ],
      "primary_category": "eess.SY",
      "comment": "13 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.01745v2",
      "published_date": "2024-07-01 19:24:36 UTC",
      "updated_date": "2024-11-28 07:35:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:19:15.589793"
    },
    {
      "arxiv_id": "2407.01734v3",
      "title": "Universal Quantum Tomography With Deep Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Nhan T. Luu",
        "Thang C. Truong",
        "Duong T. Luu"
      ],
      "abstract": "Quantum state tomography is a crucial technique for characterizing the state\nof a quantum system, which is essential for many applications in quantum\ntechnologies. In recent years, there has been growing interest in leveraging\nneural networks to enhance the efficiency and accuracy of quantum state\ntomography. Still, many of them did not include mixed quantum state, since pure\nstates are arguably less common in practical situations. In this research\npaper, we present two neural networks based approach for both pure and mixed\nquantum state tomography: Restricted Feature Based Neural Network and Mixed\nStates Conditional Generative Adversarial Network, evaluate its effectiveness\nin comparison to existing neural based methods. We demonstrate that our\nproposed methods can achieve state-of-the-art results in reconstructing mixed\nquantum states from experimental data. Our work highlights the potential of\nneural networks in revolutionizing quantum state tomography and facilitating\nthe development of quantum technologies.",
      "tldr_zh": "本文提出两种基于神经网络的方法，用于纯态和混合量子态的量子态层析成像（Quantum state tomography）：Restricted Feature Based Neural Network 和 Mixed States Conditional Generative Adversarial Network，以解决现有方法的局限性。实验结果显示，这些方法在从实验数据重建混合量子态时，比现有神经网络方法取得了最先进（state-of-the-art）的准确性和效率。总体上，这研究突显了神经网络在提升量子态层析成像性能并推动量子技术发展的潜力。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "10 pages, 5 figures, 17 illustration, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2407.01734v3",
      "published_date": "2024-07-01 19:09:18 UTC",
      "updated_date": "2024-09-08 07:27:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:19:27.800712"
    },
    {
      "arxiv_id": "2407.01725v1",
      "title": "DiscoveryBench: Towards Data-Driven Discovery with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bodhisattwa Prasad Majumder",
        "Harshit Surana",
        "Dhruv Agarwal",
        "Bhavana Dalvi Mishra",
        "Abhijeetsingh Meena",
        "Aryan Prakhar",
        "Tirth Vora",
        "Tushar Khot",
        "Ashish Sabharwal",
        "Peter Clark"
      ],
      "abstract": "Can the rapid advances in code generation, function calling, and data\nanalysis using large language models (LLMs) help automate the search and\nverification of hypotheses purely from a set of provided datasets? To evaluate\nthis question, we present DiscoveryBench, the first comprehensive benchmark\nthat formalizes the multi-step process of data-driven discovery. The benchmark\nis designed to systematically assess current model capabilities in discovery\ntasks and provide a useful resource for improving them. Our benchmark contains\n264 tasks collected across 6 diverse domains, such as sociology and\nengineering, by manually deriving discovery workflows from published papers to\napproximate the real-world challenges faced by researchers, where each task is\ndefined by a dataset, its metadata, and a discovery goal in natural language.\nWe additionally provide 903 synthetic tasks to conduct controlled evaluations\nacross task complexity. Furthermore, our structured formalism of data-driven\ndiscovery enables a facet-based evaluation that provides useful insights into\ndifferent failure modes. We evaluate several popular LLM-based reasoning\nframeworks using both open and closed LLMs as baselines on DiscoveryBench and\nfind that even the best system scores only 25%. Our benchmark, thus,\nillustrates the challenges in autonomous data-driven discovery and serves as a\nvaluable resource for the community to make progress.",
      "tldr_zh": "这篇论文引入了 DiscoveryBench，一个全面基准，用于评估大型语言模型 (LLMs) 在基于数据集自动搜索和验证假设方面的能力。基准形式化了数据驱动发现的多步骤过程，包括264个真实任务（来自社会学、工程学等6个领域）和903个合成任务，每个任务由数据集、元数据和自然语言目标组成。实验评估了多种LLM-based推理框架，结果显示最佳系统得分仅25%，揭示了当前模型在自主发现任务中的局限性，并为社区提供资源推动改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Website: https://github.com/allenai/discoverybench",
      "pdf_url": "http://arxiv.org/pdf/2407.01725v1",
      "published_date": "2024-07-01 18:58:22 UTC",
      "updated_date": "2024-07-01 18:58:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:19:40.065818"
    },
    {
      "arxiv_id": "2407.01705v1",
      "title": "Optimized Learning for X-Ray Image Classification for Multi-Class Disease Diagnoses with Accelerated Computing Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Sebastian A. Cruz Romero",
        "Ivanelyz Rivera de Jesus",
        "Dariana J. Troche Quinones",
        "Wilson Rivera Gallego"
      ],
      "abstract": "X-ray image-based disease diagnosis lies in ensuring the precision of\nidentifying afflictions within the sample, a task fraught with challenges\nstemming from the occurrence of false positives and false negatives. False\npositives introduce the risk of erroneously identifying non-existent\nconditions, leading to misdiagnosis and a decline in patient care quality.\nConversely, false negatives pose the threat of overlooking genuine\nabnormalities, potentially causing delays in treatment and interventions,\nthereby resulting in adverse patient outcomes. The urgency to overcome these\nchallenges compels ongoing efforts to elevate the precision and reliability of\nX-ray image analysis algorithms within the computational framework. This study\nintroduces modified pre-trained ResNet models tailored for multi-class disease\ndiagnosis of X-ray images, incorporating advanced optimization strategies to\nreduce the execution runtime of training and inference tasks. The primary\nobjective is to achieve tangible performance improvements through accelerated\nimplementations of PyTorch, CUDA, Mixed- Precision Training, and Learning Rate\nScheduler. While outcomes demonstrate substantial improvements in execution\nruntimes between normal training and CUDA-accelerated training, negligible\ndifferences emerge between various training optimization modalities. This\nresearch marks a significant advancement in optimizing computational approaches\nto reduce training execution time for larger models. Additionally, we explore\nthe potential of effective parallel data processing using MPI4Py for the\ndistribution of gradient descent optimization across multiple nodes and\nleverage multiprocessing to expedite data preprocessing for larger datasets.",
      "tldr_zh": "本研究针对 X 射线图像多类疾病诊断中的假阳性和假阴性问题，提出使用修改后的预训练 ResNet 模型，并整合加速计算策略如 PyTorch、CUDA、混合精度训练和学习率调度器，以减少训练和推理的执行时间。实验结果显示，CUDA 加速训练显著缩短了运行时间，而不同优化方式之间的差异较小；此外，通过 MPI4Py 实现并行数据处理和多处理技术，进一步加速了数据预处理和梯度下降优化。该工作为更大模型的计算优化提供了重要进展，提升了 X 射线图像分析的可靠性和效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "High Performance Computing course final term paper",
      "pdf_url": "http://arxiv.org/pdf/2407.01705v1",
      "published_date": "2024-07-01 18:31:30 UTC",
      "updated_date": "2024-07-01 18:31:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:19:53.629158"
    },
    {
      "arxiv_id": "2407.01704v1",
      "title": "Weight Clipping for Deep Continual and Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Elsayed",
        "Qingfeng Lan",
        "Clare Lyle",
        "A. Rupam Mahmood"
      ],
      "abstract": "Many failures in deep continual and reinforcement learning are associated\nwith increasing magnitudes of the weights, making them hard to change and\npotentially causing overfitting. While many methods address these learning\nfailures, they often change the optimizer or the architecture, a complexity\nthat hinders widespread adoption in various systems. In this paper, we focus on\nlearning failures that are associated with increasing weight norm and we\npropose a simple technique that can be easily added on top of existing learning\nsystems: clipping neural network weights to limit them to a specific range. We\nstudy the effectiveness of weight clipping in a series of supervised and\nreinforcement learning experiments. Our empirical results highlight the\nbenefits of weight clipping for generalization, addressing loss of plasticity\nand policy collapse, and facilitating learning with a large replay ratio.",
      "tldr_zh": "本论文针对深度持续和强化学习中权重幅度增加导致的学习失败（如权重难以改变和过拟合问题），提出了一种简单易添加的技术：weight clipping，用于限制神经网络权重在特定范围内。该方法无需修改优化器或架构，通过一系列监督和强化学习实验验证其有效性。结果显示，weight clipping 显著提高了模型的泛化能力，缓解了loss of plasticity 和policy collapse问题，并支持large replay ratio的学习。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the First Reinforcement Learning Conference (RLC 2024).\n  Code is available at https://github.com/mohmdelsayed/weight-clipping",
      "pdf_url": "http://arxiv.org/pdf/2407.01704v1",
      "published_date": "2024-07-01 18:29:29 UTC",
      "updated_date": "2024-07-01 18:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:20:04.731777"
    },
    {
      "arxiv_id": "2407.01697v1",
      "title": "NLPGuard: A Framework for Mitigating the Use of Protected Attributes by NLP Classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Salvatore Greco",
        "Ke Zhou",
        "Licia Capra",
        "Tania Cerquitelli",
        "Daniele Quercia"
      ],
      "abstract": "AI regulations are expected to prohibit machine learning models from using\nsensitive attributes during training. However, the latest Natural Language\nProcessing (NLP) classifiers, which rely on deep learning, operate as black-box\nsystems, complicating the detection and remediation of such misuse. Traditional\nbias mitigation methods in NLP aim for comparable performance across different\ngroups based on attributes like gender or race but fail to address the\nunderlying issue of reliance on protected attributes. To partly fix that, we\nintroduce NLPGuard, a framework for mitigating the reliance on protected\nattributes in NLP classifiers. NLPGuard takes an unlabeled dataset, an existing\nNLP classifier, and its training data as input, producing a modified training\ndataset that significantly reduces dependence on protected attributes without\ncompromising accuracy. NLPGuard is applied to three classification tasks:\nidentifying toxic language, sentiment analysis, and occupation classification.\nOur evaluation shows that current NLP classifiers heavily depend on protected\nattributes, with up to $23\\%$ of the most predictive words associated with\nthese attributes. However, NLPGuard effectively reduces this reliance by up to\n$79\\%$, while slightly improving accuracy.",
      "tldr_zh": "该研究提出NLPGuard框架，旨在减少NLP分类器对保护属性的依赖，以符合AI法规要求。NLPGuard以无标签数据集、现有NLP分类器及其训练数据为输入，生成修改后的训练数据集，从而显著降低对保护属性的依赖，同时保持或略微提升准确性。该框架应用于识别有毒语言、情感分析和职业分类等任务，实验结果显示当前分类器中高达23%的预测词与保护属性相关，而NLPGuard可将这种依赖减少高达79%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper accepted at CSCW 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.01697v1",
      "published_date": "2024-07-01 18:08:17 UTC",
      "updated_date": "2024-07-01 18:08:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:20:16.189625"
    },
    {
      "arxiv_id": "2407.01687v2",
      "title": "Deciphering the Factors Influencing the Efficacy of Chain-of-Thought: Probability, Memorization, and Noisy Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Akshara Prabhakar",
        "Thomas L. Griffiths",
        "R. Thomas McCoy"
      ],
      "abstract": "Chain-of-Thought (CoT) prompting has been shown to enhance the multi-step\nreasoning capabilities of Large Language Models (LLMs). However, debates\npersist about whether LLMs exhibit abstract generalization or rely on shallow\nheuristics when given CoT prompts. To understand the factors influencing CoT\nreasoning we provide a detailed case study of the symbolic reasoning task of\ndecoding shift ciphers, where letters are shifted forward some number of steps\nin the alphabet. We analyze the pattern of results produced by three LLMs --\nGPT-4, Claude 3, and Llama 3.1 -- performing this task using CoT prompting. By\nfocusing on a single relatively simple task, we are able to identify three\nfactors that systematically affect CoT performance: the probability of the\ntask's expected output (probability), what the model has implicitly learned\nduring pre-training (memorization), and the number of intermediate operations\ninvolved in reasoning (noisy reasoning). We show that these factors can\ndrastically influence task accuracy across all three LLMs; e.g., when tested\nwith GPT-4, varying the output's probability of occurrence shifts accuracy from\n26% to 70%. Overall, we conclude that CoT prompting performance reflects both\nmemorization and a probabilistic version of genuine reasoning. Code and data at\nthis https://github.com/aksh555/deciphering_cot",
      "tldr_zh": "本研究探讨了Chain-of-Thought (CoT) 提示对Large Language Models (LLMs) 多步推理效能的影响，通过对解码移位密码任务的案例研究，分析了GPT-4、Claude 3和Llama 3.1的表现。研究识别出三个关键因素：输出概率(probability)、模型预训练中的隐式学习(memorization)以及推理中中间操作的数量(noisy reasoning)。这些因素会显著影响任务准确率，例如在GPT-4上，改变输出概率可使准确率从26%提升至70%。总体结论是，CoT提示的性能结合了记忆和一种概率化的真正推理机制。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Findings; 9 pages plus references and appendices",
      "pdf_url": "http://arxiv.org/pdf/2407.01687v2",
      "published_date": "2024-07-01 18:01:07 UTC",
      "updated_date": "2024-10-04 01:01:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:20:29.333177"
    },
    {
      "arxiv_id": "2407.12040v7",
      "title": "Comprehensive Performance Evaluation of YOLOv12, YOLO11, YOLOv10, YOLOv9 and YOLOv8 on Detecting and Counting Fruitlet in Complex Orchard Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Ranjan Sapkota",
        "Zhichao Meng",
        "Martin Churuvija",
        "Xiaoqiang Du",
        "Zenghong Ma",
        "Manoj Karkee"
      ],
      "abstract": "This study systematically performed an extensive real-world evaluation of the\nperformances of all configurations of YOLOv8, YOLOv9, YOLOv10, YOLO11( or\nYOLOv11), and YOLOv12 object detection algorithms in terms of precision,\nrecall, mean Average Precision at 50\\% Intersection over Union (mAP@50), and\ncomputational speeds including pre-processing, inference, and post-processing\ntimes immature green apple (or fruitlet) detection in commercial orchards.\nAdditionally, this research performed and validated in-field counting of the\nfruitlets using an iPhone and machine vision sensors. Among the configurations,\nYOLOv12l recorded the highest recall rate at 0.90, compared to all other\nconfigurations of YOLO models. Likewise, YOLOv10x achieved the highest\nprecision score of 0.908, while YOLOv9 Gelan-c attained a precision of 0.903.\nAnalysis of mAP@0.50 revealed that YOLOv9 Gelan-base and YOLOv9 Gelan-e reached\npeak scores of 0.935, with YOLO11s and YOLOv12l following closely at 0.933 and\n0.931, respectively. For counting validation using images captured with an\niPhone 14 Pro, the YOLO11n configuration demonstrated outstanding accuracy,\nrecording RMSE values of 4.51 for Honeycrisp, 4.59 for Cosmic Crisp, 4.83 for\nScilate, and 4.96 for Scifresh; corresponding MAE values were 4.07, 3.98, 7.73,\nand 3.85. Similar performance trends were observed with RGB-D sensor data.\nMoreover, sensor-specific training on Intel Realsense data significantly\nenhanced model performance. YOLOv11n achieved highest inference speed of 2.4\nms, outperforming YOLOv8n (4.1 ms), YOLOv9 Gelan-s (11.5 ms), YOLOv10n (5.5\nms), and YOLOv12n (4.6 ms), underscoring its suitability for real-time object\ndetection applications. (YOLOv12 architecture, YOLOv11 Architecture, YOLOv12\nobject detection, YOLOv11 object detecion, YOLOv12 segmentation)",
      "tldr_zh": "这篇论文系统评估了 YOLOv8、YOLOv9、YOLOv10、YOLOv11 和 YOLOv12 各种配置在复杂果园环境中检测和计数未成熟苹果（fruitlet）的性能，包括精确度、召回率、mAP@50 以及预处理、推理和后处理速度。结果显示，YOLOv12l 取得了最高的召回率（0.90），YOLOv10x 的精确度最高（0.908），而 YOLOv9 Gelan-base 和 Gelan-e 在 mAP@0.50 上达峰值（0.935）。在 iPhone 14 Pro 和 RGB-D 传感器捕获的图像上，YOLOv11n 表现出色，计数准确性以 RMSE 值（4.51-4.96）和 MAE 值（3.85-7.73）领先，且其推理速度最快（2.4 ms），适合实时对象检测应用。研究还证明，使用特定传感器（如 Intel RealSense）进行训练能显著提升模型性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "16 figures, 9 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.12040v7",
      "published_date": "2024-07-01 17:59:55 UTC",
      "updated_date": "2025-02-25 23:00:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:20:44.403726"
    },
    {
      "arxiv_id": "2407.01526v1",
      "title": "Scalable Nested Optimization for Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Lorraine"
      ],
      "abstract": "Gradient-based optimization has been critical to the success of machine\nlearning, updating a single set of parameters to minimize a single loss. A\ngrowing number of applications rely on a generalization of this, where we have\na bilevel or nested optimization of which subsets of parameters update on\ndifferent objectives nested inside each other. We focus on motivating examples\nof hyperparameter optimization and generative adversarial networks. However,\nnaively applying classical methods often fails when we look at solving these\nnested problems on a large scale. In this thesis, we build tools for nested\noptimization that scale to deep learning setups.",
      "tldr_zh": "该论文探讨了深度学习中可扩展的嵌套优化（Scalable Nested Optimization），强调了基于梯度的传统优化方法在处理双层或多层目标时存在的局限性。论文以超参数优化（hyperparameter optimization）和生成对抗网络（generative adversarial networks）为例，展示了嵌套优化在更新不同参数子集时的实际应用。作者开发了可扩展工具，以应对大规模深度学习场景下的挑战，确保这些方法高效且实用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "math.OC",
        "stat.ML",
        "68T05",
        "I.2.6; I.2.8; I.5.1; G.1.6"
      ],
      "primary_category": "cs.LG",
      "comment": "View more research details at https://www.jonlorraine.com/",
      "pdf_url": "http://arxiv.org/pdf/2407.01526v1",
      "published_date": "2024-07-01 17:59:41 UTC",
      "updated_date": "2024-07-01 17:59:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:20:53.245609"
    },
    {
      "arxiv_id": "2407.01525v3",
      "title": "ScanReason: Empowering 3D Visual Grounding with Reasoning Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Chenming Zhu",
        "Tai Wang",
        "Wenwei Zhang",
        "Kai Chen",
        "Xihui Liu"
      ],
      "abstract": "Although great progress has been made in 3D visual grounding, current models\nstill rely on explicit textual descriptions for grounding and lack the ability\nto reason human intentions from implicit instructions. We propose a new task\ncalled 3D reasoning grounding and introduce a new benchmark ScanReason which\nprovides over 10K question-answer-location pairs from five reasoning types that\nrequire the synerization of reasoning and grounding. We further design our\napproach, ReGround3D, composed of the visual-centric reasoning module empowered\nby Multi-modal Large Language Model (MLLM) and the 3D grounding module to\nobtain accurate object locations by looking back to the enhanced geometry and\nfine-grained details from the 3D scenes. A chain-of-grounding mechanism is\nproposed to further boost the performance with interleaved reasoning and\ngrounding steps during inference. Extensive experiments on the proposed\nbenchmark validate the effectiveness of our proposed approach.",
      "tldr_zh": "本文提出一个新任务“3D reasoning grounding”，旨在解决当前 3D visual grounding 模型依赖显式文本描述且缺乏从隐式指令中推理人类意图的问题。作者引入了 ScanReason 基准数据集，包含超过 10K 的 question-answer-location 对，涉及五种推理类型，需要整合推理和 grounding 能力。ReGround3D 方法通过 Multi-modal Large Language Model (MLLM) 驱动的视觉中心推理模块和 3D grounding 模块，从 3D 场景提取增强几何和细粒度细节，并采用 chain-of-grounding 机制在推理过程中交错进行步骤。实验结果在该基准上验证了方法的有效性，显著提升了性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV 2024. A comprehensive and hierarchical 3D reasoning\n  grounding benchmark in the era of foundation models. Project page:\n  https://zcmax.github.io/projects/ScanReason",
      "pdf_url": "http://arxiv.org/pdf/2407.01525v3",
      "published_date": "2024-07-01 17:59:35 UTC",
      "updated_date": "2024-07-17 07:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:21:06.765569"
    },
    {
      "arxiv_id": "2407.01521v2",
      "title": "Improving Diffusion Inverse Problem Solving with Decoupled Noise Annealing",
      "title_zh": "翻译失败",
      "authors": [
        "Bingliang Zhang",
        "Wenda Chu",
        "Julius Berner",
        "Chenlin Meng",
        "Anima Anandkumar",
        "Yang Song"
      ],
      "abstract": "Diffusion models have recently achieved success in solving Bayesian inverse\nproblems with learned data priors. Current methods build on top of the\ndiffusion sampling process, where each denoising step makes small modifications\nto samples from the previous step. However, this process struggles to correct\nerrors from earlier sampling steps, leading to worse performance in complicated\nnonlinear inverse problems, such as phase retrieval. To address this challenge,\nwe propose a new method called Decoupled Annealing Posterior Sampling (DAPS)\nthat relies on a novel noise annealing process. Specifically, we decouple\nconsecutive steps in a diffusion sampling trajectory, allowing them to vary\nconsiderably from one another while ensuring their time-marginals anneal to the\ntrue posterior as we reduce noise levels. This approach enables the exploration\nof a larger solution space, improving the success rate for accurate\nreconstructions. We demonstrate that DAPS significantly improves sample quality\nand stability across multiple image restoration tasks, particularly in\ncomplicated nonlinear inverse problems.",
      "tldr_zh": "该研究针对扩散模型（Diffusion models）在解决Bayesian逆问题时的局限性，提出了一种新方法Decoupled Annealing Posterior Sampling (DAPS)，通过解耦噪声退火过程来改进采样。DAPS允许连续采样步骤之间产生显著差异，同时确保时间-边缘分布在降低噪声水平时退火到真实后验，从而扩大解决方案空间并提升重建准确率。实验结果表明，该方法在多种图像恢复任务中显著提高了样本质量和稳定性，尤其在复杂的非线性逆问题如相位恢复中表现突出。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01521v2",
      "published_date": "2024-07-01 17:59:23 UTC",
      "updated_date": "2024-12-18 00:26:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:21:26.902828"
    },
    {
      "arxiv_id": "2407.01518v1",
      "title": "Towards Multimodal Open-Set Domain Generalization and Adaptation through Self-supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Dong",
        "Eleni Chatzi",
        "Olga Fink"
      ],
      "abstract": "The task of open-set domain generalization (OSDG) involves recognizing novel\nclasses within unseen domains, which becomes more challenging with multiple\nmodalities as input. Existing works have only addressed unimodal OSDG within\nthe meta-learning framework, without considering multimodal scenarios. In this\nwork, we introduce a novel approach to address Multimodal Open-Set Domain\nGeneralization (MM-OSDG) for the first time, utilizing self-supervision. To\nthis end, we introduce two innovative multimodal self-supervised pretext tasks:\nMasked Cross-modal Translation and Multimodal Jigsaw Puzzles. These tasks\nfacilitate the learning of multimodal representative features, thereby\nenhancing generalization and open-class detection capabilities. Additionally,\nwe propose a novel entropy weighting mechanism to balance the loss across\ndifferent modalities. Furthermore, we extend our approach to tackle also the\nMultimodal Open-Set Domain Adaptation (MM-OSDA) problem, especially in\nscenarios where unlabeled data from the target domain is available. Extensive\nexperiments conducted under MM-OSDG, MM-OSDA, and Multimodal Closed-Set DG\nsettings on the EPIC-Kitchens and HAC datasets demonstrate the efficacy and\nversatility of the proposed approach. Our source code is available at\nhttps://github.com/donghao51/MOOSA.",
      "tldr_zh": "这篇论文首次提出 Multimodal Open-Set Domain Generalization (MM-OSDG) 方法，使用自监督学习来处理多模态输入下的开放集域泛化问题，包括识别未见域中的新类别。作者引入了两个创新的自监督任务——Masked Cross-modal Translation 和 Multimodal Jigsaw Puzzles——以及一个熵加权机制，以增强多模态特征学习、泛化能力和开放类检测。方法还扩展到 Multimodal Open-Set Domain Adaptation (MM-OSDA)，并在 EPIC-Kitchens 和 HAC 数据集上的广泛实验中证明了其有效性和通用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV 2024, code: https://github.com/donghao51/MOOSA",
      "pdf_url": "http://arxiv.org/pdf/2407.01518v1",
      "published_date": "2024-07-01 17:59:09 UTC",
      "updated_date": "2024-07-01 17:59:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:21:29.748985"
    },
    {
      "arxiv_id": "2407.01511v2",
      "title": "CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Tianqi Xu",
        "Linyao Chen",
        "Dai-Jie Wu",
        "Yanjun Chen",
        "Zecheng Zhang",
        "Xiang Yao",
        "Zhiqiang Xie",
        "Yongchao Chen",
        "Shilong Liu",
        "Bochen Qian",
        "Anjie Yang",
        "Zhaoxuan Jin",
        "Jianbo Deng",
        "Philip Torr",
        "Bernard Ghanem",
        "Guohao Li"
      ],
      "abstract": "The development of autonomous agents increasingly relies on Multimodal\nLanguage Models (MLMs) to perform tasks described in natural language with GUI\nenvironments, such as websites, desktop computers, or mobile phones. Existing\nbenchmarks for MLM agents in interactive environments are limited by their\nfocus on a single environment, lack of detailed and generalized evaluation\nmethods, and the complexities of constructing tasks and evaluators. To overcome\nthese limitations, we introduce Crab, the first agent benchmark framework\ndesigned to support cross-environment tasks, incorporating a graph-based\nfine-grained evaluation method and an efficient mechanism for task and\nevaluator construction. Our framework supports multiple devices and can be\neasily extended to any environment with a Python interface. Leveraging Crab, we\ndeveloped a cross-platform Crab Benchmark-v0 comprising 120 tasks in computer\ndesktop and mobile phone environments. We evaluated four advanced MLMs using\ndifferent single and multi-agent system configurations on this benchmark. The\nexperimental results demonstrate that the single agent with GPT-4o achieves the\nbest completion ratio of 38.01%. All framework code, agent code, and task\ndatasets are publicly available at https://github.com/camel-ai/crab.",
      "tldr_zh": "该研究引入了 CRAB 框架，这是一个跨环境代理基准，用于评估 Multimodal Language Models (MLMs) 在交互式环境（如网站、桌面或手机）中的性能。CRAB 解决了现有基准的局限性，通过基于图形的细粒度评估方法和高效的任务/评估器构建机制，支持多个设备并易于扩展到任何有 Python 接口的环境。基于此框架，研究者开发了 Crab Benchmark-v0，包括 120 个任务，涵盖计算机桌面和手机场景。实验结果显示，使用 GPT-4o 的单代理系统在基准测试中取得了 38.01% 的最佳完成率，所有代码和数据集已公开在 GitHub 上。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01511v2",
      "published_date": "2024-07-01 17:55:04 UTC",
      "updated_date": "2024-10-18 11:29:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:21:42.088102"
    },
    {
      "arxiv_id": "2407.01505v1",
      "title": "Self-Cognition in Large Language Models: An Exploratory Study",
      "title_zh": "大型语言模型中的自我认知：一个探索性研究",
      "authors": [
        "Dongping Chen",
        "Jiawen Shi",
        "Yao Wan",
        "Pan Zhou",
        "Neil Zhenqiang Gong",
        "Lichao Sun"
      ],
      "abstract": "While Large Language Models (LLMs) have achieved remarkable success across\nvarious applications, they also raise concerns regarding self-cognition. In\nthis paper, we perform a pioneering study to explore self-cognition in LLMs.\nSpecifically, we first construct a pool of self-cognition instruction prompts\nto evaluate where an LLM exhibits self-cognition and four well-designed\nprinciples to quantify LLMs' self-cognition. Our study reveals that 4 of the 48\nmodels on Chatbot Arena--specifically Command R, Claude3-Opus,\nLlama-3-70b-Instruct, and Reka-core--demonstrate some level of detectable\nself-cognition. We observe a positive correlation between model size, training\ndata quality, and self-cognition level. Additionally, we also explore the\nutility and trustworthiness of LLM in the self-cognition state, revealing that\nthe self-cognition state enhances some specific tasks such as creative writing\nand exaggeration. We believe that our work can serve as an inspiration for\nfurther research to study the self-cognition in LLMs.",
      "tldr_zh": "这篇论文探索了大型语言模型 (LLMs) 中的自认知 (self-cognition)，通过构建自认知指令提示池和四项设计原则来评估和量化这一特性。研究发现，在 Chatbot Arena 的 48 个模型中，Command R、Claude3-Opus、Llama-3-70b-Instruct 和 Reka-core 等 4 个模型显示出可检测的自认知，且模型大小和训练数据质量与自认知水平正相关。此外，自认知状态能提升 LLMs 在创意写作和夸张等特定任务的性能，并为未来研究提供启发。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ICML 2024 Large Language Models and Cognition Workshop",
      "pdf_url": "http://arxiv.org/pdf/2407.01505v1",
      "published_date": "2024-07-01 17:52:05 UTC",
      "updated_date": "2024-07-01 17:52:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:22:06.341445"
    },
    {
      "arxiv_id": "2407.01504v1",
      "title": "Reinvestigating the R2 Indicator: Achieving Pareto Compliance by Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Lennart Schäpermeier",
        "Pascal Kerschke"
      ],
      "abstract": "In multi-objective optimization, set-based quality indicators are a\ncornerstone of benchmarking and performance assessment. They capture the\nquality of a set of trade-off solutions by reducing it to a scalar number. One\nof the most commonly used set-based metrics is the R2 indicator, which\ndescribes the expected utility of a solution set to a decision-maker under a\ndistribution of utility functions. Typically, this indicator is applied by\ndiscretizing this distribution of utility functions, yielding a weakly\nPareto-compliant indicator. In consequence, adding a nondominated or dominating\nsolution to a solution set may - but does not have to - improve the indicator's\nvalue.\n  In this paper, we reinvestigate the R2 indicator under the premise that we\nhave a continuous, uniform distribution of (Tchebycheff) utility functions. We\nanalyze its properties in detail, demonstrating that this continuous variant is\nindeed Pareto-compliant - that is, any beneficial solution will improve the\nmetric's value. Additionally, we provide an efficient computational procedure\nto compute this metric for bi-objective problems in $\\mathcal O (N \\log N)$. As\na result, this work contributes to the state-of-the-art Pareto-compliant unary\nperformance metrics, such as the hypervolume indicator, offering an efficient\nand promising alternative.",
      "tldr_zh": "该论文重新调查了多目标优化中的 R2 indicator，指出传统离散化方法仅是弱 Pareto-compliant，可能无法保证添加有益解决方案就改善指标值。作者提出了一种基于连续均匀分布的 Tchebycheff utility functions 变体，使 R2 indicator 成为真正的 Pareto-compliant，确保任何有益解决方案都能提升指标。实验结果显示，该方法为双目标问题提供 O(N log N) 的高效计算过程，作为 hypervolume indicator 等指标的替代，推进了性能评估的可靠性。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "This version has been accepted for publication at the 18th\n  International Conference on Parallel Problem Solving from Nature (PPSN 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.01504v1",
      "published_date": "2024-07-01 17:50:44 UTC",
      "updated_date": "2024-07-01 17:50:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:22:06.316950"
    },
    {
      "arxiv_id": "2407.01502v1",
      "title": "AI Agents That Matter",
      "title_zh": "翻译失败",
      "authors": [
        "Sayash Kapoor",
        "Benedikt Stroebl",
        "Zachary S. Siegel",
        "Nitya Nadgir",
        "Arvind Narayanan"
      ],
      "abstract": "AI agents are an exciting new research direction, and agent development is\ndriven by benchmarks. Our analysis of current agent benchmarks and evaluation\npractices reveals several shortcomings that hinder their usefulness in\nreal-world applications. First, there is a narrow focus on accuracy without\nattention to other metrics. As a result, SOTA agents are needlessly complex and\ncostly, and the community has reached mistaken conclusions about the sources of\naccuracy gains. Our focus on cost in addition to accuracy motivates the new\ngoal of jointly optimizing the two metrics. We design and implement one such\noptimization, showing its potential to greatly reduce cost while maintaining\naccuracy. Second, the benchmarking needs of model and downstream developers\nhave been conflated, making it hard to identify which agent would be best\nsuited for a particular application. Third, many agent benchmarks have\ninadequate holdout sets, and sometimes none at all. This has led to agents that\nare fragile because they take shortcuts and overfit to the benchmark in various\nways. We prescribe a principled framework for avoiding overfitting. Finally,\nthere is a lack of standardization in evaluation practices, leading to a\npervasive lack of reproducibility. We hope that the steps we introduce for\naddressing these shortcomings will spur the development of agents that are\nuseful in the real world and not just accurate on benchmarks.",
      "tldr_zh": "该论文分析了当前AI代理基准和评估实践的不足，包括过度关注准确性而忽略成本，导致SOTA代理过于复杂且昂贵，并误导了对性能提升来源的理解。作者提出新目标——联合优化准确性和成本，并设计实现了一种优化方法，证明其能在维持准确性的同时显著降低成本。此外，论文指出了基准测试需求的混淆、holdout sets的缺失导致的过拟合问题，并提供了一个避免过拟合的框架，同时呼吁标准化评估实践以提升AI代理的真实世界实用性和可重复性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01502v1",
      "published_date": "2024-07-01 17:48:14 UTC",
      "updated_date": "2024-07-01 17:48:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:22:19.027096"
    },
    {
      "arxiv_id": "2407.01492v2",
      "title": "RegMix: Data Mixture as Regression for Language Model Pre-training",
      "title_zh": "RegMix：数据混合作为回归用于语言模型预训练",
      "authors": [
        "Qian Liu",
        "Xiaosen Zheng",
        "Niklas Muennighoff",
        "Guangtao Zeng",
        "Longxu Dou",
        "Tianyu Pang",
        "Jing Jiang",
        "Min Lin"
      ],
      "abstract": "The data mixture for large language model pre-training significantly impacts\nperformance, yet how to determine an effective mixture remains unclear. We\npropose RegMix to automatically identify a high-performing data mixture by\nformulating it as a regression task. RegMix trains many small models on diverse\ndata mixtures, uses regression to predict performance of unseen mixtures, and\napplies the best predicted mixture to train a large-scale model with orders of\nmagnitude more compute. To empirically validate RegMix, we train 512 models\nwith 1M parameters for 1B tokens to fit the regression model and predict the\nbest data mixture. Using this mixture we train a 1B parameter model for 25B\ntokens (i.e. 1000x larger and 25x longer) which we find performs best among 64\ncandidate 1B parameter models with other mixtures. Furthermore, RegMix\nconsistently outperforms human selection in experiments involving models up to\n7B models trained on 100B tokens, while matching or exceeding DoReMi using just\n10% of the computational resources. Our experiments also show that (1) Data\nmixtures significantly impact performance; (2) Web corpora rather than data\nperceived as high-quality like Wikipedia have the strongest positive\ncorrelation with downstream performance; (3) Domains interact in complex ways\noften contradicting common sense, thus automatic approaches like RegMix are\nneeded; (4) Data mixture effects transcend scaling laws. Our code is available\nat https://github.com/sail-sg/regmix.",
      "tldr_zh": "这篇论文提出了RegMix方法，将语言模型预训练的数据混合问题转化为回归任务，以自动识别高性能混合策略。\nRegMix通过训练多个小模型（例如512个1M参数模型在1B tokens上）来拟合回归模型，预测未见混合的表现，并应用最佳混合训练大规模模型（如1B参数模型在25B tokens上），结果显示其性能优于其他64个候选模型。\n实验证明，RegMix在涉及7B参数模型和100B tokens的场景中 consistently outperforms 人类选择，且仅用10%的计算资源就匹配或超过DoReMi。\n此外，研究发现数据混合对模型性能有重大影响，Web语料库比Wikipedia等高品质数据有更强正相关，且领域互动复杂，超越了传统的scaling laws，因此需要如RegMix这样的自动方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.01492v2",
      "published_date": "2024-07-01 17:31:03 UTC",
      "updated_date": "2025-01-23 17:35:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:22:32.763723"
    },
    {
      "arxiv_id": "2407.01490v2",
      "title": "LLM See, LLM Do: Guiding Data Generation to Target Non-Differentiable Objectives",
      "title_zh": "翻译失败",
      "authors": [
        "Luísa Shimabucoro",
        "Sebastian Ruder",
        "Julia Kreutzer",
        "Marzieh Fadaee",
        "Sara Hooker"
      ],
      "abstract": "The widespread adoption of synthetic data raises new questions about how\nmodels generating the data can influence other large language models (LLMs) via\ndistilled data. To start, our work exhaustively characterizes the impact of\npassive inheritance of model properties by systematically studying the\nconsequences of synthetic data integration. We provide one of the most\ncomprehensive studies to-date of how the source of synthetic data shapes\nmodels' internal biases, calibration and generations' textual attributes and\npreferences. We find that models are surprisingly sensitive towards certain\nattributes even when the synthetic data prompts appear \"neutral\". which invites\nthe question whether this sensitivity can be exploited for good.\n  Our findings invite the question can we explicitly steer the models towards\nthe properties we want at test time by exploiting the data generation process?\nThis would have historically been considered infeasible due to the cost of\ncollecting data with a specific characteristic or objective in mind. However,\nimprovement in the quality of synthetic data, as well as a shift towards\ngeneral-purpose models designed to follow a diverse way of instructions, means\nthis question is timely. We propose active inheritance as a term to describe\nintentionally constraining synthetic data according to a non-differentiable\nobjective. We demonstrate how active inheritance can steer the generation\nprofiles of models towards desirable non-differentiable attributes, e.g. high\nlexical diversity or low toxicity.",
      "tldr_zh": "本研究探讨了合成数据如何通过被动继承影响大型语言模型（LLM）的内部偏差、校准和生成属性，发现模型对某些“中性”提示异常敏感，导致生成文本的偏好变化。作者提出“active inheritance”概念，即有意约束合成数据以针对非微分目标（如高词汇多样性或低毒性），从而主动引导模型生成过程。实验结果表明，这种方法能有效提升模型的生成质量，为优化LLM性能提供了可行策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01490v2",
      "published_date": "2024-07-01 17:26:21 UTC",
      "updated_date": "2024-07-19 10:45:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:22:41.737703"
    },
    {
      "arxiv_id": "2407.01489v2",
      "title": "Agentless: Demystifying LLM-based Software Engineering Agents",
      "title_zh": "Agentless: 解密基于LLM的软件工程代理",
      "authors": [
        "Chunqiu Steven Xia",
        "Yinlin Deng",
        "Soren Dunn",
        "Lingming Zhang"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have significantly\nadvanced the automation of software development tasks, including code\nsynthesis, program repair, and test generation. More recently, researchers and\nindustry practitioners have developed various autonomous LLM agents to perform\nend-to-end software development tasks. These agents are equipped with the\nability to use tools, run commands, observe feedback from the environment, and\nplan for future actions. However, the complexity of these agent-based\napproaches, together with the limited abilities of current LLMs, raises the\nfollowing question: Do we really have to employ complex autonomous software\nagents? To attempt to answer this question, we build Agentless -- an agentless\napproach to automatically solve software development problems. Compared to the\nverbose and complex setup of agent-based approaches, Agentless employs a\nsimplistic three-phase process of localization, repair, and patch validation,\nwithout letting the LLM decide future actions or operate with complex tools.\nOur results on the popular SWE-bench Lite benchmark show that surprisingly the\nsimplistic Agentless is able to achieve both the highest performance (32.00%,\n96 correct fixes) and low cost ($0.70) compared with all existing open-source\nsoftware agents! Furthermore, we manually classified the problems in SWE-bench\nLite and found problems with exact ground truth patch or\ninsufficient/misleading issue descriptions. As such, we construct SWE-bench\nLite-S by excluding such problematic issues to perform more rigorous evaluation\nand comparison. Our work highlights the current overlooked potential of a\nsimple, interpretable technique in autonomous software development. We hope\nAgentless will help reset the baseline, starting point, and horizon for\nautonomous software agents, and inspire future work along this crucial\ndirection.",
      "tldr_zh": "这篇论文质疑了基于 LLM 的复杂软件工程代理的必要性，并提出 Agentless，一种简化的无代理方法，通过 localization（定位）、repair（修复）和 patch validation（补丁验证）三个阶段自动处理软件开发任务，而不依赖 LLM 的行动规划或复杂工具。实验结果显示，Agentless 在 SWE-bench Lite 基准上取得了最高的性能（32.00%，96 个正确修复）和极低成本（$0.70），优于现有开源代理。作者进一步构建了 SWE-bench Lite-S 基准，以排除问题 issue，进行更严格评估，并强调简单技术的潜力，希望重置自主软件开发的基准。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01489v2",
      "published_date": "2024-07-01 17:24:45 UTC",
      "updated_date": "2024-10-29 17:29:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:22:55.673738"
    },
    {
      "arxiv_id": "2407.01476v2",
      "title": "Tree Search for Language Model Agents",
      "title_zh": "针对语言模型代理的树搜索",
      "authors": [
        "Jing Yu Koh",
        "Stephen McAleer",
        "Daniel Fried",
        "Ruslan Salakhutdinov"
      ],
      "abstract": "Autonomous agents powered by language models (LMs) have demonstrated promise\nin their ability to perform decision-making tasks such as web automation.\nHowever, a key limitation remains: LMs, primarily optimized for natural\nlanguage understanding and generation, struggle with multi-step reasoning,\nplanning, and using environmental feedback when attempting to solve realistic\ncomputer tasks. Towards addressing this, we propose an inference-time search\nalgorithm for LM agents to explicitly perform exploration and multi-step\nplanning in interactive web environments. Our approach is a form of best-first\ntree search that operates within the actual environment space, and is\ncomplementary with most existing state-of-the-art agents. It is the first tree\nsearch algorithm for LM agents that shows effectiveness on realistic web tasks.\nOn the challenging VisualWebArena benchmark, applying our search algorithm on\ntop of a GPT-4o agent yields a 39.7% relative increase in success rate compared\nto the same baseline without search, setting a state-of-the-art success rate of\n26.4%. On WebArena, search also yields a 28.0% relative improvement over a\nbaseline agent, setting a competitive success rate of 19.2%. Our experiments\nhighlight the effectiveness of search for web agents, and we demonstrate that\nperformance scales with increased test-time compute. We conduct a thorough\nanalysis of our results to highlight improvements from search, limitations, and\npromising directions for future work. Our code and models are publicly released\nat https://jykoh.com/search-agents.",
      "tldr_zh": "这篇论文提出了一种推理时的树搜索算法，用于提升语言模型 (LMs) 代理在交互式网页环境中的探索、多步规划和环境反馈利用能力，以解决 LMs 在多步推理方面的局限。算法采用最佳优先树搜索形式，在实际环境空间中操作，并与现有最先进代理兼容，是首个在真实网页任务中证明有效的树搜索方法。在 VisualWebArena 基准上，该算法使 GPT-4o 代理的成功率相对提升 39.7%，达到 26.4% 的最先进水平；在 WebArena 上，成功率相对增加 28.0%，达到 19.2%。实验分析显示，性能随测试时计算资源的增加而提升，并指出了搜索算法的改进潜力、限制及未来方向。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages. Models and code available at\n  https://jykoh.com/search-agents",
      "pdf_url": "http://arxiv.org/pdf/2407.01476v2",
      "published_date": "2024-07-01 17:07:55 UTC",
      "updated_date": "2024-10-12 19:58:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:23:07.659150"
    },
    {
      "arxiv_id": "2407.01463v1",
      "title": "Retrieval-augmented generation in multilingual settings",
      "title_zh": "多语言环境下的检索增强生成",
      "authors": [
        "Nadezhda Chirkova",
        "David Rau",
        "Hervé Déjean",
        "Thibault Formal",
        "Stéphane Clinchant",
        "Vassilina Nikoulina"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has recently emerged as a promising\nsolution for incorporating up-to-date or domain-specific knowledge into large\nlanguage models (LLMs) and improving LLM factuality, but is predominantly\nstudied in English-only settings. In this work, we consider RAG in the\nmultilingual setting (mRAG), i.e. with user queries and the datastore in 13\nlanguages, and investigate which components and with which adjustments are\nneeded to build a well-performing mRAG pipeline, that can be used as a strong\nbaseline in future works. Our findings highlight that despite the availability\nof high-quality off-the-shelf multilingual retrievers and generators,\ntask-specific prompt engineering is needed to enable generation in user\nlanguages. Moreover, current evaluation metrics need adjustments for\nmultilingual setting, to account for variations in spelling named entities. The\nmain limitations to be addressed in future works include frequent\ncode-switching in non-Latin alphabet languages, occasional fluency errors,\nwrong reading of the provided documents, or irrelevant retrieval. We release\nthe code for the resulting mRAG baseline pipeline at\nhttps://github.com/naver/bergen.",
      "tldr_zh": "该研究探讨了Retrieval-augmented generation (RAG)在多语言设置(mRAG)中的应用，旨在将最新或特定领域知识整合到大型语言模型(LLMs)中以提升事实准确性，同时处理13种语言的用户查询和数据存储。作者构建了一个高效的mRAG管道，通过使用高质量的多语言检索器和生成器，并进行任务特定的提示工程来支持用户语言的生成。实验发现，评估指标需调整以应对命名实体的拼写变体，尽管存在代码切换、流畅性错误和无关检索等限制，该框架仍可作为未来研究的强有力基线，并已发布代码在https://github.com/naver/bergen。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01463v1",
      "published_date": "2024-07-01 16:56:50 UTC",
      "updated_date": "2024-07-01 16:56:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:23:19.216504"
    },
    {
      "arxiv_id": "2407.01459v1",
      "title": "On Implications of Scaling Laws on Feature Superposition",
      "title_zh": "翻译失败",
      "authors": [
        "Pavan Katta"
      ],
      "abstract": "Using results from scaling laws, this theoretical note argues that the\nfollowing two statements cannot be simultaneously true: 1. Superposition\nhypothesis where sparse features are linearly represented across a layer is a\ncomplete theory of feature representation. 2. Features are universal, meaning\ntwo models trained on the same data and achieving equal performance will learn\nidentical features.",
      "tldr_zh": "这篇论文基于 scaling laws 的理论结果，论证了 superposition hypothesis（稀疏特征在神经网络层中线性表示是特征表示的完整理论）和 features are universal（两个在相同数据上训练并达到相同性能的模型会学习相同特征）这两个陈述不能同时成立。作者通过分析 scaling laws 的含义，揭示了特征表示可能存在局限性，例如模型间的差异或非通用性。这种发现为神经网络特征表示理论提供了重要启示，帮助研究者更好地理解模型行为的复杂性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "4 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2407.01459v1",
      "published_date": "2024-07-01 16:54:07 UTC",
      "updated_date": "2024-07-01 16:54:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:23:30.631001"
    },
    {
      "arxiv_id": "2407.01458v2",
      "title": "Contractual Reinforcement Learning: Pulling Arms with Invisible Hands",
      "title_zh": "翻译失败",
      "authors": [
        "Jibang Wu",
        "Siyu Chen",
        "Mengdi Wang",
        "Huazheng Wang",
        "Haifeng Xu"
      ],
      "abstract": "The agency problem emerges in today's large scale machine learning tasks,\nwhere the learners are unable to direct content creation or enforce data\ncollection. In this work, we propose a theoretical framework for aligning\neconomic interests of different stakeholders in the online learning problems\nthrough contract design. The problem, termed \\emph{contractual reinforcement\nlearning}, naturally arises from the classic model of Markov decision\nprocesses, where a learning principal seeks to optimally influence the agent's\naction policy for their common interests through a set of payment rules\ncontingent on the realization of next state. For the planning problem, we\ndesign an efficient dynamic programming algorithm to determine the optimal\ncontracts against the far-sighted agent. For the learning problem, we introduce\na generic design of no-regret learning algorithms to untangle the challenges\nfrom robust design of contracts to the balance of exploration and exploitation,\nreducing the complexity analysis to the construction of efficient search\nalgorithms. For several natural classes of problems, we design tailored search\nalgorithms that provably achieve $\\tilde{O}(\\sqrt{T})$ regret. We also present\nan algorithm with $\\tilde{O}(T^{2/3})$ for the general problem that improves\nthe existing analysis in online contract design with mild technical\nassumptions.",
      "tldr_zh": "该论文提出“contractual reinforcement learning”框架，通过合同设计来协调在线学习中不同利益相关者的经济利益，解决代理问题（agency problem）在Markov decision processes (MDP)中的挑战。框架中，学习主体通过支付规则影响代理的行动策略，以实现共同利益；针对规划问题，作者设计了一个高效的动态规划算法来确定最优合同。针对学习问题，他们引入无遗憾学习算法，处理合同设计的鲁棒性以及探索与利用的平衡，并为特定问题类构建搜索算法实现\\(\\tilde{O}(\\sqrt{T})\\)遗憾；对于一般问题，提供\\(\\tilde{O}(T^{2/3})\\)遗憾的算法，改进了现有在线合同设计的分析。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "econ.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01458v2",
      "published_date": "2024-07-01 16:53:00 UTC",
      "updated_date": "2024-07-02 15:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:23:43.600994"
    },
    {
      "arxiv_id": "2407.01437v2",
      "title": "Needle in the Haystack for Memory Based Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Elliot Nelson",
        "Georgios Kollias",
        "Payel Das",
        "Subhajit Chaudhury",
        "Soham Dan"
      ],
      "abstract": "Current large language models (LLMs) often perform poorly on simple fact\nretrieval tasks. Here we investigate if coupling a dynamically adaptable\nexternal memory to a LLM can alleviate this problem. For this purpose, we test\nLarimar, a recently proposed language model architecture which uses an external\nassociative memory, on long-context recall tasks including passkey and\nneedle-in-the-haystack tests. We demonstrate that the external memory of\nLarimar, which allows fast write and read of an episode of text samples, can be\nused at test time to handle contexts much longer than those seen during\ntraining. We further show that the latent readouts from the memory (to which\nlong contexts are written) control the decoder towards generating correct\noutputs, with the memory stored off of the GPU. Compared to existing\ntransformer-based LLM architectures for long-context recall tasks that use\nlarger parameter counts or modified attention mechanisms, a relatively smaller\nsize Larimar is able to maintain strong performance without any task-specific\ntraining or training on longer contexts.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)在事实检索任务上的表现不足，并引入Larimar架构，该架构通过动态可适应的外部关联内存来提升长上下文回忆能力。Larimar允许在测试时快速写入和读取文本样本，从而处理比训练时更长的上下文，并在needle-in-the-haystack等任务中生成准确输出，而内存可存储在GPU外。实验结果显示，与基于Transformer的LLMs相比，Larimar在较小参数规模下保持强劲性能，无需任务特定训练或更长上下文训练。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages; slightly revised abstract",
      "pdf_url": "http://arxiv.org/pdf/2407.01437v2",
      "published_date": "2024-07-01 16:32:16 UTC",
      "updated_date": "2024-07-12 17:20:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:23:59.525520"
    },
    {
      "arxiv_id": "2407.01428v1",
      "title": "Reinforcement Learning-driven Data-intensive Workflow Scheduling for Volunteer Edge-Cloud",
      "title_zh": "翻译失败",
      "authors": [
        "Motahare Mounesan",
        "Mauro Lemus",
        "Hemanth Yeddulapalli",
        "Prasad Calyam",
        "Saptarshi Debroy"
      ],
      "abstract": "In recent times, Volunteer Edge-Cloud (VEC) has gained traction as a\ncost-effective, community computing paradigm to support data-intensive\nscientific workflows. However, due to the highly distributed and heterogeneous\nnature of VEC resources, centralized workflow task scheduling remains a\nchallenge. In this paper, we propose a Reinforcement Learning (RL)-driven\ndata-intensive scientific workflow scheduling approach that takes into\nconsideration: i) workflow requirements, ii) VEC resources' preference on\nworkflows, and iii) diverse VEC resource policies, to ensure robust resource\nallocation. We formulate the long-term average performance optimization problem\nas a Markov Decision Process, which is solved using an event-based Asynchronous\nAdvantage Actor-Critic RL approach. Our extensive simulations and testbed\nimplementations demonstrate our approach's benefits over popular baseline\nstrategies in terms of workflow requirement satisfaction, VEC preference\nsatisfaction, and available VEC resource utilization.",
      "tldr_zh": "本文提出了一种基于强化学习 (RL) 的数据密集型科学工作流调度方法，针对 Volunteer Edge-Cloud (VEC) 的分布式和异构资源挑战，考虑了工作流需求、VEC 资源偏好以及多样化的资源策略。方法将问题表述为 Markov Decision Process (MDP)，并采用事件-based Asynchronous Advantage Actor-Critic (A3C) 算法进行优化，实现高效的资源分配。实验模拟和测试床结果表明，该方法在工作流要求满足、VEC 偏好满足以及资源利用率方面均优于传统基线策略。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01428v1",
      "published_date": "2024-07-01 16:21:13 UTC",
      "updated_date": "2024-07-01 16:21:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:24:09.165019"
    },
    {
      "arxiv_id": "2407.01418v1",
      "title": "RoboPack: Learning Tactile-Informed Dynamics Models for Dense Packing",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Ai",
        "Stephen Tian",
        "Haochen Shi",
        "Yixuan Wang",
        "Cheston Tan",
        "Yunzhu Li",
        "Jiajun Wu"
      ],
      "abstract": "Tactile feedback is critical for understanding the dynamics of both rigid and\ndeformable objects in many manipulation tasks, such as non-prehensile\nmanipulation and dense packing. We introduce an approach that combines visual\nand tactile sensing for robotic manipulation by learning a neural,\ntactile-informed dynamics model. Our proposed framework, RoboPack, employs a\nrecurrent graph neural network to estimate object states, including particles\nand object-level latent physics information, from historical visuo-tactile\nobservations and to perform future state predictions. Our tactile-informed\ndynamics model, learned from real-world data, can solve downstream robotics\ntasks with model-predictive control. We demonstrate our approach on a real\nrobot equipped with a compliant Soft-Bubble tactile sensor on non-prehensile\nmanipulation and dense packing tasks, where the robot must infer the physics\nproperties of objects from direct and indirect interactions. Trained on only an\naverage of 30 minutes of real-world interaction data per task, our model can\nperform online adaptation and make touch-informed predictions. Through\nextensive evaluations in both long-horizon dynamics prediction and real-world\nmanipulation, our method demonstrates superior effectiveness compared to\nprevious learning-based and physics-based simulation systems.",
      "tldr_zh": "本文提出RoboPack框架，通过结合视觉和触觉反馈，学习一个神经触觉信息动态模型，用于机器人密集包装（dense packing）和非 prehensile 操纵任务。框架采用recurrent graph neural network从历史visuo-tactile观察中估计物体状态，包括粒子和物体级潜在物理信息，并支持未来状态预测和model-predictive control。仅需平均30分钟的真实世界交互数据训练，该模型即可实现在线适应和精确预测；在广泛评估中，RoboPack在长期动态预测和真实机器人任务中比现有学习或物理模拟系统更有效。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "I.2.9; I.2.6; I.2.10"
      ],
      "primary_category": "cs.RO",
      "comment": "Robotics: Science and Systems (RSS), 2024. Project page:\n  https://robo-pack.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2407.01418v1",
      "published_date": "2024-07-01 16:08:37 UTC",
      "updated_date": "2024-07-01 16:08:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:24:22.086020"
    },
    {
      "arxiv_id": "2407.01409v1",
      "title": "Dynamic Few-Shot Learning for Knowledge Graph Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Jacopo D'Abramo",
        "Andrea Zugarini",
        "Paolo Torroni"
      ],
      "abstract": "Large language models present opportunities for innovative Question Answering\nover Knowledge Graphs (KGQA). However, they are not inherently designed for\nquery generation. To bridge this gap, solutions have been proposed that rely on\nfine-tuning or ad-hoc architectures, achieving good results but limited\nout-of-domain distribution generalization. In this study, we introduce a novel\napproach called Dynamic Few-Shot Learning (DFSL). DFSL integrates the\nefficiency of in-context learning and semantic similarity and provides a\ngenerally applicable solution for KGQA with state-of-the-art performance. We\nrun an extensive evaluation across multiple benchmark datasets and architecture\nconfigurations.",
      "tldr_zh": "本研究针对大语言模型（Large Language Models）在知识图谱问答（Knowledge Graph Question Answering, KGQA）中的查询生成局限性，提出了一种新方法Dynamic Few-Shot Learning (DFSL)。DFSL 通过整合in-context learning的效率和语义相似性（semantic similarity），提供了一个通用的KGQA解决方案，实现了state-of-the-art性能。研究在多个基准数据集和架构配置上进行了广泛评估，展示了DFSL的出色泛化能力和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01409v1",
      "published_date": "2024-07-01 15:59:17 UTC",
      "updated_date": "2024-07-01 15:59:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:24:31.432000"
    },
    {
      "arxiv_id": "2407.01408v1",
      "title": "Semantic Compositions Enhance Vision-Language Contrastive Learning",
      "title_zh": "语义组合增强视觉-语言对比学习",
      "authors": [
        "Maxwell Aladago",
        "Lorenzo Torresani",
        "Soroush Vosoughi"
      ],
      "abstract": "In the field of vision-language contrastive learning, models such as CLIP\ncapitalize on matched image-caption pairs as positive examples and leverage\nwithin-batch non-matching pairs as negatives. This approach has led to\nremarkable outcomes in zero-shot image classification, cross-modal retrieval,\nand linear evaluation tasks. We show that the zero-shot classification and\nretrieval capabilities of CLIP-like models can be improved significantly\nthrough the introduction of semantically composite examples during pretraining.\nInspired by CutMix in vision categorization, we create semantically composite\nimage-caption pairs by merging elements from two distinct instances in the\ndataset via a novel procedure. Our method fuses the captions and blends 50% of\neach image to form a new composite sample. This simple technique (termed CLIP-C\nfor CLIP Compositions), devoid of any additional computational overhead or\nincrease in model parameters, significantly improves zero-shot image\nclassification and cross-modal retrieval. The benefits of CLIP-C are\nparticularly pronounced in settings with relatively limited pretraining data.",
      "tldr_zh": "本研究发现，CLIP-like模型在视觉语言对比学习中，通过使用匹配图像-标题对作为正例和非匹配对作为负例，已在zero-shot image classification、cross-modal retrieval和线性评估任务中取得显著成果。作者提出CLIP-C方法，受CutMix启发，通过融合两个数据集实例的标题并混合50%的图像，创建语义复合示例，从而显著提升模型的零样本图像分类和跨模态检索能力。该技术无需增加计算开销或模型参数，尤其在预训练数据有限的场景下，效果尤为突出。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01408v1",
      "published_date": "2024-07-01 15:58:20 UTC",
      "updated_date": "2024-07-01 15:58:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:24:44.388697"
    },
    {
      "arxiv_id": "2407.01406v3",
      "title": "Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters",
      "title_zh": "翻译失败",
      "authors": [
        "Daniil Gurgurov",
        "Mareike Hartmann",
        "Simon Ostermann"
      ],
      "abstract": "This paper explores the integration of graph knowledge from linguistic\nontologies into multilingual Large Language Models (LLMs) using adapters to\nimprove performance for low-resource languages (LRLs) in sentiment analysis\n(SA) and named entity recognition (NER). Building upon successful\nparameter-efficient fine-tuning techniques, such as K-ADAPTER and MAD-X, we\npropose a similar approach for incorporating knowledge from multilingual\ngraphs, connecting concepts in various languages with each other through\nlinguistic relationships, into multilingual LLMs for LRLs. Specifically, we\nfocus on eight LRLs -- Maltese, Bulgarian, Indonesian, Nepali, Javanese,\nUyghur, Tibetan, and Sinhala -- and employ language-specific adapters\nfine-tuned on data extracted from the language-specific section of ConceptNet,\naiming to enable knowledge transfer across the languages covered by the\nknowledge graph. We compare various fine-tuning objectives, including standard\nMasked Language Modeling (MLM), MLM with full-word masking, and MLM with\ntargeted masking, to analyse their effectiveness in learning and integrating\nthe extracted graph data. Through empirical evaluation on language-specific\ntasks, we assess how structured graph knowledge affects the performance of\nmultilingual LLMs for LRLs in SA and NER, providing insights into the potential\nbenefits of adapting language models for low-resource scenarios.",
      "tldr_zh": "本论文提出一种方法，通过 adapters 将知识图谱（如 ConceptNet）的语言本体知识整合到 Multilingual LLMs 中，提升低资源语言 (LRLs) 在情感分析 (SA) 和命名实体识别 (NER) 上的性能。针对八种 LRLs（包括 Maltese, Bulgarian, Indonesian, Nepali, Javanese, Uyghur, Tibetan 和 Sinhala），作者使用语言特定 adapters 在从 ConceptNet 提取的数据上进行微调，并比较了标准 Masked Language Modeling (MLM)、全词 masking MLM 和针对性 masking MLM 等微调目标。实验评估显示，这种基于 K-ADAPTER 和 MAD-X 的方法能有效实现知识转移，提高 LRLs 任务性能，并为适应低资源语言场景提供重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, KaLLM workshop",
      "pdf_url": "http://arxiv.org/pdf/2407.01406v3",
      "published_date": "2024-07-01 15:56:24 UTC",
      "updated_date": "2024-12-18 17:09:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:25:10.427573"
    },
    {
      "arxiv_id": "2407.01403v1",
      "title": "Optimization of Retrieval-Augmented Generation Context with Outlier Detection",
      "title_zh": "通过异常检测优化检索增强生成上下文",
      "authors": [
        "Vitaly Bulgakov"
      ],
      "abstract": "In this paper, we focus on methods to reduce the size and improve the quality\nof the prompt context required for question-answering systems. Attempts to\nincrease the number of retrieved chunked documents and thereby enlarge the\ncontext related to the query can significantly complicate the processing and\ndecrease the performance of a Large Language Model (LLM) when generating\nresponses to queries. It is well known that a large set of documents retrieved\nfrom a database in response to a query may contain irrelevant information,\nwhich often leads to hallucinations in the resulting answers. Our goal is to\nselect the most semantically relevant documents, treating the discarded ones as\noutliers. We propose and evaluate several methods for identifying outliers by\ncreating features that utilize the distances of embedding vectors, retrieved\nfrom the vector database, to both the centroid and the query vectors. The\nmethods were evaluated by comparing the similarities of the retrieved LLM\nresponses to ground-truth answers obtained using the OpenAI GPT-4o model. It\nwas found that the greatest improvements were achieved with increasing\ncomplexity of the questions and answers.",
      "tldr_zh": "本论文针对问答系统的 Retrieval-Augmented Generation (RAG) 上下文优化问题，提出了一种通过检测异常值 (outliers) 来减少无关文档并提升上下文质量的方法。该方法利用嵌入向量 (embedding vectors) 到质心 (centroid) 和查询向量 (query vectors) 的距离创建特征，从而识别并过滤掉不相关的信息，避免 Large Language Model (LLM) 生成的幻觉 (hallucinations)。实验评估显示，与使用 OpenAI GPT-4o 的基准答案比较，该方法在问题和答案复杂度增加时显著提高了响应相似度，整体性能得到提升。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01403v1",
      "published_date": "2024-07-01 15:53:29 UTC",
      "updated_date": "2024-07-01 15:53:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:25:09.931073"
    },
    {
      "arxiv_id": "2407.01397v1",
      "title": "Mask and Compress: Efficient Skeleton-based Action Recognition in Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Mosconi",
        "Andriy Sorokin",
        "Aniello Panariello",
        "Angelo Porrello",
        "Jacopo Bonato",
        "Marco Cotogni",
        "Luigi Sabetta",
        "Simone Calderara",
        "Rita Cucchiara"
      ],
      "abstract": "The use of skeletal data allows deep learning models to perform action\nrecognition efficiently and effectively. Herein, we believe that exploring this\nproblem within the context of Continual Learning is crucial. While numerous\nstudies focus on skeleton-based action recognition from a traditional offline\nperspective, only a handful venture into online approaches. In this respect, we\nintroduce CHARON (Continual Human Action Recognition On skeletoNs), which\nmaintains consistent performance while operating within an efficient framework.\nThrough techniques like uniform sampling, interpolation, and a memory-efficient\ntraining stage based on masking, we achieve improved recognition accuracy while\nminimizing computational overhead. Our experiments on Split NTU-60 and the\nproposed Split NTU-120 datasets demonstrate that CHARON sets a new benchmark in\nthis domain. The code is available at https://github.com/Sperimental3/CHARON.",
      "tldr_zh": "本论文探讨了在持续学习（Continual Learning）背景下，使用骨骼数据（skeleton-based）进行高效动作识别的问题，以解决现有研究偏重离线方法的局限。作者引入了CHARON框架，通过均匀采样、插值和基于掩码（masking）的内存高效训练方法，实现了动作识别的准确性提升，同时降低了计算开销。在Split NTU-60和Split NTU-120数据集上的实验表明，CHARON框架设置了新基准，显著提高了性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.01397v1",
      "published_date": "2024-07-01 15:48:49 UTC",
      "updated_date": "2024-07-01 15:48:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:25:19.646605"
    },
    {
      "arxiv_id": "2407.01376v1",
      "title": "Badllama 3: removing safety finetuning from Llama 3 in minutes",
      "title_zh": "翻译失败",
      "authors": [
        "Dmitrii Volkov"
      ],
      "abstract": "We show that extensive LLM safety fine-tuning is easily subverted when an\nattacker has access to model weights. We evaluate three state-of-the-art\nfine-tuning methods-QLoRA, ReFT, and Ortho-and show how algorithmic advances\nenable constant jailbreaking performance with cuts in FLOPs and optimisation\npower. We strip safety fine-tuning from Llama 3 8B in one minute and Llama 3\n70B in 30 minutes on a single GPU, and sketch ways to reduce this further.",
      "tldr_zh": "该研究展示了攻击者可以通过访问模型权重轻易破坏大型语言模型(LLM)安全微调的过程，针对 Llama 3 模型进行了评估。论文评估了三种先进微调方法——QLoRA、ReFT 和 Ortho——并证明算法进步允许在减少 FLOPs 和优化功率的情况下保持高效的越狱性能。在单 GPU 上，仅用一分钟去除 Llama 3 8B 的安全微调，以及 30 分钟去除 Llama 3 70B，并概述了进一步降低时间的潜在方式，这突显了当前 LLM 安全机制的脆弱性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01376v1",
      "published_date": "2024-07-01 15:29:45 UTC",
      "updated_date": "2024-07-01 15:29:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:25:32.932491"
    },
    {
      "arxiv_id": "2407.01355v2",
      "title": "Hyperspectral Pansharpening: Critical Review, Tools and Future Perspectives",
      "title_zh": "高光谱全色锐化：批判性综述、工具和未来展望",
      "authors": [
        "Matteo Ciotola",
        "Giuseppe Guarino",
        "Gemine Vivone",
        "Giovanni Poggi",
        "Jocelyn Chanussot",
        "Antonio Plaza",
        "Giuseppe Scarpa"
      ],
      "abstract": "Hyperspectral pansharpening consists of fusing a high-resolution panchromatic\nband and a low-resolution hyperspectral image to obtain a new image with high\nresolution in both the spatial and spectral domains. These remote sensing\nproducts are valuable for a wide range of applications, driving ever growing\nresearch efforts. Nonetheless, results still do not meet application demands.\nIn part, this comes from the technical complexity of the task: compared to\nmultispectral pansharpening, many more bands are involved, in a spectral range\nonly partially covered by the panchromatic component and with overwhelming\nnoise. However, another major limiting factor is the absence of a comprehensive\nframework for the rapid development and accurate evaluation of new methods.\nThis paper attempts to address this issue.\n  We started by designing a dataset large and diverse enough to allow reliable\ntraining (for data-driven methods) and testing of new methods. Then, we\nselected a set of state-of-the-art methods, following different approaches,\ncharacterized by promising performance, and reimplemented them in a single\nPyTorch framework. Finally, we carried out a critical comparative analysis of\nall methods, using the most accredited quality indicators. The analysis\nhighlights the main limitations of current solutions in terms of\nspectral/spatial quality and computational efficiency, and suggests promising\nresearch directions.\n  To ensure full reproducibility of the results and support future research,\nthe framework (including codes, evaluation procedures and links to the dataset)\nis shared on https://github.com/matciotola/hyperspectral_pansharpening_toolbox,\nas a single Python-based reference benchmark toolbox.",
      "tldr_zh": "这篇论文对 Hyperspectral Pansharpening 进行了关键回顾，该技术通过融合高分辨率 panchromatic 带和低分辨率 hyperspectral 图像，生成在空间和光谱域都具有高分辨率的遥感产品，但当前方法因技术复杂性和噪声问题而无法满足应用需求。作者设计了一个大型多样数据集，用于训练和测试数据驱动方法，并在一个 PyTorch 框架中重新实现了多种 state-of-the-art 方法，进行全面比较分析，突出了现有解决方案在 spectral/spatial quality 和 computational efficiency 方面的局限性，并提出了未来研究方向。为了促进可重复性，论文公开了代码、评估程序和数据集链接，作为一个 Python-based 基准工具箱共享在 GitHub 上。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01355v2",
      "published_date": "2024-07-01 15:10:50 UTC",
      "updated_date": "2024-12-27 10:52:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:25:45.867971"
    },
    {
      "arxiv_id": "2407.01343v1",
      "title": "Coordination Failure in Cooperative Offline MARL",
      "title_zh": "翻译失败",
      "authors": [
        "Callum Rhys Tilbury",
        "Claude Formanek",
        "Louise Beyers",
        "Jonathan P. Shock",
        "Arnu Pretorius"
      ],
      "abstract": "Offline multi-agent reinforcement learning (MARL) leverages static datasets\nof experience to learn optimal multi-agent control. However, learning from\nstatic data presents several unique challenges to overcome. In this paper, we\nfocus on coordination failure and investigate the role of joint actions in\nmulti-agent policy gradients with offline data, focusing on a common setting we\nrefer to as the 'Best Response Under Data' (BRUD) approach. By using two-player\npolynomial games as an analytical tool, we demonstrate a simple yet overlooked\nfailure mode of BRUD-based algorithms, which can lead to catastrophic\ncoordination failure in the offline setting. Building on these insights, we\npropose an approach to mitigate such failure, by prioritising samples from the\ndataset based on joint-action similarity during policy learning and demonstrate\nits effectiveness in detailed experiments. More generally, however, we argue\nthat prioritised dataset sampling is a promising area for innovation in offline\nMARL that can be combined with other effective approaches such as critic and\npolicy regularisation. Importantly, our work shows how insights drawn from\nsimplified, tractable games can lead to useful, theoretically grounded insights\nthat transfer to more complex contexts. A core dimension of offering is an\ninteractive notebook, from which almost all of our results can be reproduced,\nin a browser.",
      "tldr_zh": "本论文探讨了离线多智能体强化学习（Offline MARL）中的协调失败问题，特别针对“Best Response Under Data”（BRUD）方法，分析了联合动作在策略梯度中的作用。作者通过两玩家多项式游戏作为分析工具，揭示了BRUD算法可能导致灾难性协调失败的现象，并提出了一种基于联合动作相似性的数据集优先采样方法，以缓解这一问题。实验结果证明了该方法的有效性，同时论文强调优先采样是Offline MARL创新的潜在方向，并提供了可重现的交互式笔记本。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the Workshop on Aligning Reinforcement Learning\n  Experimentalists and Theorists (ARLET) at the International Conference on\n  Machine Learning, 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.01343v1",
      "published_date": "2024-07-01 14:51:29 UTC",
      "updated_date": "2024-07-01 14:51:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:25:59.428875"
    },
    {
      "arxiv_id": "2407.01333v1",
      "title": "Deep Reinforcement Learning for Adverse Garage Scenario Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Li"
      ],
      "abstract": "Autonomous vehicles need to travel over 11 billion miles to ensure their\nsafety. Therefore, the importance of simulation testing before real-world\ntesting is self-evident. In recent years, the release of 3D simulators for\nautonomous driving, represented by Carla and CarSim, marks the transition of\nautonomous driving simulation testing environments from simple 2D overhead\nviews to complex 3D models. During simulation testing, experimenters need to\nbuild static scenes and dynamic traffic flows, pedestrian flows, and other\nexperimental elements to construct experimental scenarios. When building static\nscenes in 3D simulators, experimenters often need to manually construct 3D\nmodels, set parameters and attributes, which is time-consuming and\nlabor-intensive. This thesis proposes an automated program generation\nframework. Based on deep reinforcement learning, this framework can generate\ndifferent 2D ground script codes, on which 3D model files and map model files\nare built. The generated 3D ground scenes are displayed in the Carla simulator,\nwhere experimenters can use this scene for navigation algorithm simulation\ntesting.",
      "tldr_zh": "本论文探讨了自动驾驶车辆的安全测试问题，强调模拟环境的重要性，并指出传统3D模拟器如Carla中手动构建静态场景耗时费力。论文提出一个基于Deep Reinforcement Learning的自动化程序生成框架，该框架能生成2D地面脚本代码，从而自动构建3D模型文件和地图模型文件。生成的3D场景可在Carla模拟器中显示，用于导航算法的模拟测试，提高了测试效率和场景多样性。整体方法为自动驾驶模拟测试提供了更高效的工具。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "I.2.0; I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.01333v1",
      "published_date": "2024-07-01 14:41:18 UTC",
      "updated_date": "2024-07-01 14:41:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:26:09.652081"
    },
    {
      "arxiv_id": "2407.01331v2",
      "title": "Restyling Unsupervised Concept Based Interpretable Networks with Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jayneel Parekh",
        "Quentin Bouniot",
        "Pavlo Mozharovskyi",
        "Alasdair Newson",
        "Florence d'Alché-Buc"
      ],
      "abstract": "Developing inherently interpretable models for prediction has gained\nprominence in recent years. A subclass of these models, wherein the\ninterpretable network relies on learning high-level concepts, are valued\nbecause of closeness of concept representations to human communication.\nHowever, the visualization and understanding of the learnt unsupervised\ndictionary of concepts encounters major limitations, especially for large-scale\nimages. We propose here a novel method that relies on mapping the concept\nfeatures to the latent space of a pretrained generative model. The use of a\ngenerative model enables high quality visualization, and lays out an intuitive\nand interactive procedure for better interpretation of the learnt concepts by\nimputing concept activations and visualizing generated modifications.\nFurthermore, leveraging pretrained generative models has the additional\nadvantage of making the training of the system more efficient. We\nquantitatively ascertain the efficacy of our method in terms of accuracy of the\ninterpretable prediction network, fidelity of reconstruction, as well as\nfaithfulness and consistency of learnt concepts. The experiments are conducted\non multiple image recognition benchmarks for large-scale images. Project page\navailable at https://jayneelparekh.github.io/VisCoIN_project_page/",
      "tldr_zh": "该研究针对无监督概念基于可解释网络（unsupervised concept based interpretable networks）在大型图像上的可视化和理解问题，提出了一种新方法，将概念特征映射到预训练生成模型（generative models）的潜在空间（latent space）。这种方法利用生成模型实现高质量可视化，并提供直观的交互式过程，如输入概念激活并生成修改，以更好地解释学习到的概念。相比传统方法，该框架提高了训练效率，并在多个图像识别基准上验证了可解释预测网络的准确性、重构保真度以及概念的忠实度和一致性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at ICLR 2025. Project page available at\n  https://jayneelparekh.github.io/VisCoIN_project_page/",
      "pdf_url": "http://arxiv.org/pdf/2407.01331v2",
      "published_date": "2024-07-01 14:39:41 UTC",
      "updated_date": "2025-03-18 21:58:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:26:21.837926"
    },
    {
      "arxiv_id": "2407.01320v1",
      "title": "Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Haobo Song",
        "Hao Zhao",
        "Soumajit Majumder",
        "Tao Lin"
      ],
      "abstract": "Fine-tuning large pre-trained foundation models, such as the 175B GPT-3, has\nattracted more attention for downstream tasks recently. While\nparameter-efficient fine-tuning methods have been proposed and proven effective\nwithout retraining all model parameters, their performance is limited by the\ncapacity of incremental modules, especially under constrained parameter\nbudgets. \\\\ To overcome this challenge, we propose CapaBoost, a simple yet\neffective strategy that enhances model capacity by leveraging low-rank updates\nthrough parallel weight modules in target layers. By applying static random\nmasks to the shared weight matrix, CapaBoost constructs a diverse set of weight\nmatrices, effectively increasing the rank of incremental weights without adding\nparameters. Notably, our approach can be seamlessly integrated into various\nexisting parameter-efficient fine-tuning methods. We extensively validate the\nefficacy of CapaBoost through experiments on diverse downstream tasks,\nincluding natural language understanding, question answering, and image\nclassification. Our results demonstrate significant improvements over\nbaselines, without incurring additional computation or storage costs. Our code\nis available at \\url{https://github.com/LINs-lab/CapaBoost}.",
      "tldr_zh": "该论文提出了一种名为 CapaBoost 的简单策略，用于 Parameter Efficient Fine-tuning，通过低秩 updates 和并行权重模块增强模型容量，而无需额外参数。方法涉及在目标层应用静态随机 masks 到共享权重矩阵，构建多样化权重矩阵，从而有效提高增量权重的秩，并可无缝整合到现有微调方法中。实验结果显示，CapaBoost 在自然语言理解、问答和图像分类等下游任务上显著优于基线，且不增加计算或存储成本。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2024. Code at https://github.com/LINs-lab/CapaBoost",
      "pdf_url": "http://arxiv.org/pdf/2407.01320v1",
      "published_date": "2024-07-01 14:26:48 UTC",
      "updated_date": "2024-07-01 14:26:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:26:34.683458"
    },
    {
      "arxiv_id": "2407.01318v1",
      "title": "Deep Dive into MRI: Exploring Deep Learning Applications in 0.55T and 7T MRI",
      "title_zh": "深入探讨 MRI：探索深度学习",
      "authors": [
        "Ana Carolina Alves",
        "André Ferreira",
        "Behrus Puladi",
        "Jan Egger",
        "Victor Alves"
      ],
      "abstract": "The development of magnetic resonance imaging (MRI) for medical imaging has\nprovided a leap forward in diagnosis, providing a safe, non-invasive\nalternative to techniques involving ionising radiation exposure for diagnostic\npurposes. It was described by Block and Purcel in 1946, and it was not until\n1980 that the first clinical application of MRI became available. Since that\ntime the MRI has gone through many advances and has altered the way diagnosing\nprocedures are performed. Due to its ability to improve constantly, MRI has\nbecome a commonly used practice among several specialisations in medicine.\nParticularly starting 0.55T and 7T MRI technologies have pointed out enhanced\npreservation of image detail and advanced tissue characterisation. This review\nexamines the integration of deep learning (DL) techniques into these MRI\nmodalities, disseminating and exploring the study applications. It highlights\nhow DL contributes to 0.55T and 7T MRI data, showcasing the potential of DL in\nimproving and refining these technologies. The review ends with a brief\noverview of how MRI technology will evolve in the coming years.",
      "tldr_zh": "这篇论文回顾了磁共振成像（MRI）的发展，特别是0.55T和7T MRI技术如何通过增强图像细节和组织特征来改善诊断。该研究探讨了深度学习（DL）在这些MRI模式中的应用，展示了DL如何处理MRI数据以提升图像质量和诊断准确性。通过整合现有研究，论文突出了DL的潜力在未来MRI技术演变中的作用，最终为医疗成像领域提供了宝贵见解。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01318v1",
      "published_date": "2024-07-01 14:26:31 UTC",
      "updated_date": "2024-07-01 14:26:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:26:45.961118"
    },
    {
      "arxiv_id": "2407.01317v1",
      "title": "Leveraging Speaker Embeddings in End-to-End Neural Diarization for Two-Speaker Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Juan Ignacio Alvarez-Trejos",
        "Beltrán Labrador",
        "Alicia Lozano-Diez"
      ],
      "abstract": "End-to-end neural speaker diarization systems are able to address the speaker\ndiarization task while effectively handling speech overlap. This work explores\nthe incorporation of speaker information embeddings into the end-to-end systems\nto enhance the speaker discriminative capabilities, while maintaining their\noverlap handling strengths. To achieve this, we propose several methods for\nincorporating these embeddings along the acoustic features. Furthermore, we\ndelve into an analysis of the correct handling of silence frames, the window\nlength for extracting speaker embeddings and the transformer encoder size. The\neffectiveness of our proposed approach is thoroughly evaluated on the CallHome\ndataset for the two-speaker diarization task, with results that demonstrate a\nsignificant reduction in diarization error rates achieving a relative\nimprovement of a 10.78% compared to the baseline end-to-end model.",
      "tldr_zh": "本研究探讨在端到端神经说话者分离(end-to-end neural diarization)系统中整合说话者嵌入(speaker embeddings)，以提升双说话者场景下的说话者区分能力，同时保持处理语音重叠的优势。  \n他们提出了多种方法，将说话者嵌入融入声学特征中，并分析了沉默帧处理、嵌入提取窗口长度以及Transformer编码器大小的影响。  \n实验在CallHome数据集上进行，结果显示与基线模型相比，分离错误率相对降低了10.78%。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Submitted to Odyssey 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.01317v1",
      "published_date": "2024-07-01 14:26:28 UTC",
      "updated_date": "2024-07-01 14:26:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:27:09.178708"
    },
    {
      "arxiv_id": "2407.01302v2",
      "title": "Robot Instance Segmentation with Few Annotations for Grasping",
      "title_zh": "翻译失败",
      "authors": [
        "Moshe Kimhi",
        "David Vainshtein",
        "Chaim Baskin",
        "Dotan Di Castro"
      ],
      "abstract": "The ability of robots to manipulate objects relies heavily on their aptitude\nfor visual perception. In domains characterized by cluttered scenes and high\nobject variability, most methods call for vast labeled datasets, laboriously\nhand-annotated, with the aim of training capable models. Once deployed, the\nchallenge of generalizing to unfamiliar objects implies that the model must\nevolve alongside its domain. To address this, we propose a novel framework that\ncombines Semi-Supervised Learning (SSL) with Learning Through Interaction\n(LTI), allowing a model to learn by observing scene alterations and leverage\nvisual consistency despite temporal gaps without requiring curated data of\ninteraction sequences. As a result, our approach exploits partially annotated\ndata through self-supervision and incorporates temporal context using\npseudo-sequences generated from unlabeled still images. We validate our method\non two common benchmarks, ARMBench mix-object-tote and OCID, where it achieves\nstate-of-the-art performance. Notably, on ARMBench, we attain an\n$\\text{AP}_{50}$ of $86.37$, almost a $20\\%$ improvement over existing work,\nand obtain remarkable results in scenarios with extremely low annotation,\nachieving an $\\text{AP}_{50}$ score of $84.89$ with just $1 \\%$ of annotated\ndata compared to $72$ presented in ARMBench on the fully annotated counterpart.",
      "tldr_zh": "该论文提出了一种新框架，将半监督学习 (Semi-Supervised Learning, SSL) 与通过交互学习 (Learning Through Interaction, LTI) 相结合，旨在减少标注数据需求，实现机器人实例分割以辅助抓取物体。框架通过观察场景变化利用视觉一致性，并从部分标注数据中生成伪序列 (pseudo-sequences) 来整合时间上下文，从而实现自监督学习。实验在 ARMBench mix-object-tote 和 OCID 基准上验证了其效果，取得了最先进性能，包括 $\\text{AP}_{50}$ 达 86.37，比现有工作提升约 20%，并在仅 1% 标注数据的极端场景下达到 84.89 的 $\\text{AP}_{50}$，远超完全标注基准的 72。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01302v2",
      "published_date": "2024-07-01 13:58:32 UTC",
      "updated_date": "2025-02-11 19:56:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:27:11.181783"
    },
    {
      "arxiv_id": "2407.01300v2",
      "title": "Collaborative Performance Prediction for Large Language Models",
      "title_zh": "大型语言模型的协作性能预测",
      "authors": [
        "Qiyuan Zhang",
        "Fuyuan Lyu",
        "Xue Liu",
        "Chen Ma"
      ],
      "abstract": "Comprehensively understanding and accurately predicting the performance of\nlarge language models across diverse downstream tasks has emerged as a pivotal\nchallenge in NLP research. The pioneering scaling law on downstream works\ndemonstrated intrinsic similarities within model families and utilized such\nsimilarities for performance prediction. However, they tend to overlook the\nsimilarities between model families and only consider design factors listed in\nthe original scaling law. To overcome these limitations, we introduce a novel\nframework, Collaborative Performance Prediction (CPP), which significantly\nenhances prediction accuracy by leveraging the historical performance of\nvarious models on downstream tasks and other design factors for both model and\ntask. We also collect a collaborative data sourced from online platforms\ncontaining both historical performance and additional design factors. With the\nsupport of the collaborative data, CPP not only surpasses traditional scaling\nlaws in predicting the performance of scaled LLMs but also facilitates a\ndetailed analysis of factor importance, an area previously overlooked.",
      "tldr_zh": "这项研究针对大型语言模型（Large Language Models, LLMs）在下游任务上的性能预测问题，提出了一种新型框架Collaborative Performance Prediction (CPP)，以克服传统缩放定律（scaling law）仅关注模型家族内部相似性的局限。CPP 通过整合各种模型的历史性能数据、设计因素（如模型和任务属性）以及从在线平台收集的协作数据，显著提高了预测准确性。实验结果显示，CPP 不仅在预测缩放 LLMs 性能方面优于现有方法，还支持对影响因素重要性的深入分析。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "In Proceedings of EMNLP 2024 Main Track",
      "pdf_url": "http://arxiv.org/pdf/2407.01300v2",
      "published_date": "2024-07-01 13:56:42 UTC",
      "updated_date": "2024-10-02 18:41:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:27:24.891881"
    },
    {
      "arxiv_id": "2407.11021v1",
      "title": "PCAPVision: PCAP-Based High-Velocity and Large-Volume Network Failure Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Lukasz Tulczyjew",
        "Ihor Biruk",
        "Murat Bilgic",
        "Charles Abondo",
        "Nathanael Weill"
      ],
      "abstract": "Detecting failures via analysis of Packet Capture (PCAP) files is crucial for\nmaintaining network reliability and performance, especially in large-scale\ntelecommunications networks. Traditional methods, relying on manual inspection\nand rule-based systems, are often too slow and labor-intensive to meet the\ndemands of modern networks. In this paper, we present PCAPVision, a novel\napproach that utilizes computer vision and Convolutional Neural Networks (CNNs)\nto detect failures in PCAP files. By converting PCAP data into images, our\nmethod leverages the robust pattern recognition capabilities of CNNs to analyze\nnetwork traffic efficiently. This transformation process involves encoding\npacket data into structured images, enabling rapid and accurate failure\ndetection. Additionally, we incorporate a continual learning framework,\nleveraging automated annotation for the feedback loop, to adapt the model\ndynamically and ensure sustained performance over time. Our approach\nsignificantly reduces the time required for failure detection. The initial\ntraining phase uses a Voice Over LTE (VoLTE) dataset, demonstrating the model's\neffectiveness and generalizability when using transfer learning on Mobility\nManagement services. This work highlights the potential of integrating computer\nvision techniques in network analysis, offering a scalable and efficient\nsolution for real-time network failure detection.",
      "tldr_zh": "本文提出PCAPVision，一种基于PCAP文件的网络故障检测方法，利用计算机视觉和CNNs（Convolutional Neural Networks）将PCAP数据转换为图像，从而实现高效的模式识别和快速故障分析。该方法整合了持续学习（continual learning）框架，通过自动化注解的反馈循环动态适应模型，显著减少检测时间。在VoLTE数据集上进行初始训练后，通过transfer learning扩展到Mobility Management服务，实验证明了其有效性和通用性，为大规模网络提供可扩展的实时故障检测解决方案。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "Copyright 2024 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works",
      "pdf_url": "http://arxiv.org/pdf/2407.11021v1",
      "published_date": "2024-07-01 13:52:17 UTC",
      "updated_date": "2024-07-01 13:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:27:34.507738"
    },
    {
      "arxiv_id": "2407.01294v2",
      "title": "A Collaborative, Human-Centred Taxonomy of AI, Algorithmic, and Automation Harms",
      "title_zh": "翻译失败",
      "authors": [
        "Gavin Abercrombie",
        "Djalel Benbouzid",
        "Paolo Giudici",
        "Delaram Golpayegani",
        "Julio Hernandez",
        "Pierre Noro",
        "Harshvardhan Pandit",
        "Eva Paraschou",
        "Charlie Pownall",
        "Jyoti Prajapati",
        "Mark A. Sayre",
        "Ushnish Sengupta",
        "Arthit Suriyawongkul",
        "Ruby Thelot",
        "Sofia Vei",
        "Laura Waltersdorfer"
      ],
      "abstract": "This paper introduces a collaborative, human-centred taxonomy of AI,\nalgorithmic and automation harms. We argue that existing taxonomies, while\nvaluable, can be narrow, unclear, typically cater to practitioners and\ngovernment, and often overlook the needs of the wider public. Drawing on\nexisting taxonomies and a large repository of documented incidents, we propose\na taxonomy that is clear and understandable to a broad set of audiences, as\nwell as being flexible, extensible, and interoperable. Through iterative\nrefinement with topic experts and crowdsourced annotation testing, we propose a\ntaxonomy that can serve as a powerful tool for civil society organisations,\neducators, policymakers, product teams and the general public. By fostering a\ngreater understanding of the real-world harms of AI and related technologies,\nwe aim to increase understanding, empower NGOs and individuals to identify and\nreport violations, inform policy discussions, and encourage responsible\ntechnology development and deployment.",
      "tldr_zh": "这篇论文提出了一种协作式、以人为中心的 AI、算法ic 和 automation harms 分类法（taxonomy），旨在解决现有分类法过于狭隘、不清晰且主要针对从业者和政府而忽略公众需求的问题。作者通过整合现有 taxonomies 和大量记录的 incidents，并采用与主题专家的迭代完善以及 crowdsourced annotation testing 的方法，开发出一个清晰、易懂、灵活且可扩展的框架。最终，该 taxonomy 可作为工具，支持 civil society organisations、教育者、政策制定者、产品团队和公众更好地理解 AI 相关危害、识别和报告违规、推动政策讨论，并促进负责任的技术开发和部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "K.4.1; I.2.0; H.0; K.5.2"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 2 figures; typos corrected, reference missing fields fixed,\n  printer-friendly version of a diagram added",
      "pdf_url": "http://arxiv.org/pdf/2407.01294v2",
      "published_date": "2024-07-01 13:47:53 UTC",
      "updated_date": "2024-11-09 12:00:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:27:57.773755"
    },
    {
      "arxiv_id": "2407.01290v1",
      "title": "Hypformer: Exploring Efficient Hyperbolic Transformer Fully in Hyperbolic Space",
      "title_zh": "Hypformer: 在双曲空间中全面探索高效的双曲Transformer",
      "authors": [
        "Menglin Yang",
        "Harshit Verma",
        "Delvin Ce Zhang",
        "Jiahong Liu",
        "Irwin King",
        "Rex Ying"
      ],
      "abstract": "Hyperbolic geometry have shown significant potential in modeling complex\nstructured data, particularly those with underlying tree-like and hierarchical\nstructures. Despite the impressive performance of various hyperbolic neural\nnetworks across numerous domains, research on adapting the Transformer to\nhyperbolic space remains limited. Previous attempts have mainly focused on\nmodifying self-attention modules in the Transformer. However, these efforts\nhave fallen short of developing a complete hyperbolic Transformer. This stems\nprimarily from: (i) the absence of well-defined modules in hyperbolic space,\nincluding linear transformation layers, LayerNorm layers, activation functions,\ndropout operations, etc. (ii) the quadratic time complexity of the existing\nhyperbolic self-attention module w.r.t the number of input tokens, which\nhinders its scalability. To address these challenges, we propose, Hypformer, a\nnovel hyperbolic Transformer based on the Lorentz model of hyperbolic geometry.\nIn Hypformer, we introduce two foundational blocks that define the essential\nmodules of the Transformer in hyperbolic space. Furthermore, we develop a\nlinear self-attention mechanism in hyperbolic space, enabling hyperbolic\nTransformer to process billion-scale graph data and long-sequence inputs for\nthe first time. Our experimental results confirm the effectiveness and\nefficiency of Hypformer across various datasets, demonstrating its potential as\nan effective and scalable solution for large-scale data representation and\nlarge models.",
      "tldr_zh": "该研究探讨了超曲几何（Hyperbolic geometry）在处理树状和层次结构数据方面的潜力，并针对Transformer在超曲空间的适应性不足提出Hypformer，一种基于Lorentz模型的完整超曲Transformer。Hypformer引入了两个基础块来定义超曲空间中的关键模块，如线性变换（linear transformation）、LayerNorm、激活函数和dropout操作，同时开发了线性self-attention机制，以降低计算复杂度并支持处理十亿级图数据和长序列输入。实验结果显示，Hypformer在多个数据集上表现出色，提高了效率和可扩展性，为大规模数据表示和大型模型提供了有效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.01290v1",
      "published_date": "2024-07-01 13:44:38 UTC",
      "updated_date": "2024-07-01 13:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:28:10.073477"
    },
    {
      "arxiv_id": "2407.01284v1",
      "title": "We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?",
      "title_zh": "We-Math：你的大型多模态模型是否实现了人类般的数学推理？",
      "authors": [
        "Runqi Qiao",
        "Qiuna Tan",
        "Guanting Dong",
        "Minhui Wu",
        "Chong Sun",
        "Xiaoshuai Song",
        "Zhuoma GongQue",
        "Shanglin Lei",
        "Zhe Wei",
        "Miaoxuan Zhang",
        "Runfeng Qiao",
        "Yifan Zhang",
        "Xiao Zong",
        "Yida Xu",
        "Muxi Diao",
        "Zhimin Bao",
        "Chen Li",
        "Honggang Zhang"
      ],
      "abstract": "Visual mathematical reasoning, as a fundamental visual reasoning ability, has\nreceived widespread attention from the Large Multimodal Models (LMMs)\ncommunity. Existing benchmarks, such as MathVista and MathVerse, focus more on\nthe result-oriented performance but neglect the underlying principles in\nknowledge acquisition and generalization. Inspired by human-like mathematical\nreasoning, we introduce WE-MATH, the first benchmark specifically designed to\nexplore the problem-solving principles beyond end-to-end performance. We\nmeticulously collect and categorize 6.5K visual math problems, spanning 67\nhierarchical knowledge concepts and five layers of knowledge granularity. We\ndecompose composite problems into sub-problems according to the required\nknowledge concepts and introduce a novel four-dimensional metric, namely\nInsufficient Knowledge (IK), Inadequate Generalization (IG), Complete Mastery\n(CM), and Rote Memorization (RM), to hierarchically assess inherent issues in\nLMMs' reasoning process. With WE-MATH, we conduct a thorough evaluation of\nexisting LMMs in visual mathematical reasoning and reveal a negative\ncorrelation between solving steps and problem-specific performance. We confirm\nthe IK issue of LMMs can be effectively improved via knowledge augmentation\nstrategies. More notably, the primary challenge of GPT-4o has significantly\ntransitioned from IK to IG, establishing it as the first LMM advancing towards\nthe knowledge generalization stage. In contrast, other LMMs exhibit a marked\ninclination towards Rote Memorization - they correctly solve composite problems\ninvolving multiple knowledge concepts yet fail to answer sub-problems. We\nanticipate that WE-MATH will open new pathways for advancements in visual\nmathematical reasoning for LMMs. The WE-MATH data and evaluation code are\navailable at https://github.com/We-Math/We-Math.",
      "tldr_zh": "本研究引入了WE-MATH基准，这是首个专注于探索Large Multimodal Models (LMMs)在视觉数学推理中的问题解决原则，而非仅关注最终性能。该基准收集了6.5K个视觉数学问题，涵盖67个层次知识概念和五层知识粒度，并通过分解复合问题为子问题，采用四维指标（Insufficient Knowledge (IK)、Inadequate Generalization (IG)、Complete Mastery (CM)和Rote Memorization (RM)）来评估LMMs的推理缺陷。实验结果显示，问题解决步骤与性能呈负相关，IK问题可通过知识增强策略改善，而GPT-4o已从IK转向IG挑战，成为首个迈向知识泛化阶段的LMM；其他模型则倾向于Rote Memorization，能解决复合问题却失败于子问题。该基准有望推动LMMs在视觉数学推理领域的进步，并提供了相关数据和代码。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2407.01284v1",
      "published_date": "2024-07-01 13:39:08 UTC",
      "updated_date": "2024-07-01 13:39:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:28:23.577725"
    },
    {
      "arxiv_id": "2407.04736v1",
      "title": "SCDM: Unified Representation Learning for EEG-to-fNIRS Cross-Modal Generation in MI-BCIs",
      "title_zh": "翻译失败",
      "authors": [
        "Yisheng Li",
        "Shuqiang Wang"
      ],
      "abstract": "Hybrid motor imagery brain-computer interfaces (MI-BCIs), which integrate\nboth electroencephalography (EEG) and functional near-infrared spectroscopy\n(fNIRS) signals, outperform those based solely on EEG. However, simultaneously\nrecording EEG and fNIRS signals is highly challenging due to the difficulty of\ncolocating both types of sensors on the same scalp surface. This physical\nconstraint complicates the acquisition of high-quality hybrid signals, thereby\nlimiting the widespread application of hybrid MI-BCIs. To facilitate the\nacquisition of hybrid EEG-fNIRS signals, this study proposes the\nspatio-temporal controlled diffusion model (SCDM) as a framework for\ncross-modal generation from EEG to fNIRS. The model utilizes two core modules,\nthe spatial cross-modal generation (SCG) module and the multi-scale temporal\nrepresentation (MTR) module, which adaptively learn the respective latent\ntemporal and spatial representations of both signals in a unified\nrepresentation space. The SCG module further maps EEG representations to fNIRS\nrepresentations by leveraging their spatial relationships. Experimental results\nshow high similarity between synthetic and real fNIRS signals. The joint\nclassification performance of EEG and synthetic fNIRS signals is comparable to\nor even better than that of EEG with real fNIRS signals. Furthermore, the\nsynthetic signals exhibit similar spatio-temporal features to real signals\nwhile preserving spatial relationships with EEG signals. Experimental results\nsuggest that the SCDM may represent a promising paradigm for the acquisition of\nhybrid EEG-fNIRS signals in MI-BCI systems.",
      "tldr_zh": "本研究提出了一种统一表示学习框架SCDM，用于在运动想象脑机接口(MI-BCIs)中实现从EEG到fNIRS的跨模态生成，以解决EEG和fNIRS信号同时记录的困难问题。SCDM包括spatial cross-modal generation (SCG)模块和multi-scale temporal representation (MTR)模块，这些模块在统一表示空间中自适应学习信号的时空特征，并通过空间关系映射EEG表示到fNIRS表示。实验结果显示，合成的fNIRS信号与真实信号高度相似，其与EEG结合的分类性能不逊于或优于真实fNIRS，且保留了相似的时空特征和空间关系，为混合MI-BCIs信号获取提供了一个有前景的范式。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "11 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.04736v1",
      "published_date": "2024-07-01 13:37:23 UTC",
      "updated_date": "2024-07-01 13:37:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:28:35.136263"
    },
    {
      "arxiv_id": "2407.01281v2",
      "title": "Bridging Smoothness and Approximation: Theoretical Insights into Over-Smoothing in Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Guangrui Yang",
        "Jianfei Li",
        "Ming Li",
        "Han Feng",
        "Ding-Xuan Zhou"
      ],
      "abstract": "In this paper, we explore the approximation theory of functions defined on\ngraphs. Our study builds upon the approximation results derived from the\n$K$-functional. We establish a theoretical framework to assess the lower bounds\nof approximation for target functions using Graph Convolutional Networks (GCNs)\nand examine the over-smoothing phenomenon commonly observed in these networks.\nInitially, we introduce the concept of a $K$-functional on graphs, establishing\nits equivalence to the modulus of smoothness. We then analyze a typical type of\nGCN to demonstrate how the high-frequency energy of the output decays, an\nindicator of over-smoothing. This analysis provides theoretical insights into\nthe nature of over-smoothing within GCNs. Furthermore, we establish a lower\nbound for the approximation of target functions by GCNs, which is governed by\nthe modulus of smoothness of these functions. This finding offers a new\nperspective on the approximation capabilities of GCNs. In our numerical\nexperiments, we analyze several widely applied GCNs and observe the phenomenon\nof energy decay. These observations corroborate our theoretical results on\nexponential decay order.",
      "tldr_zh": "本论文探讨了图神经网络(Graph Neural Networks, GNNs)中over-smoothing现象的理论基础，通过K-functional构建图上函数的逼近理论框架。作者证明了K-functional等价于modulus of smoothness，并分析Graph Convolutional Networks (GCNs)如何导致输出高频能量衰减，从而解释了over-smoothing的机制。论文进一步建立了GCNs逼近目标函数的下界，该界由函数的modulus of smoothness控制，提供新视角；数值实验验证了能量衰减的指数级现象，支持了理论发现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.FA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01281v2",
      "published_date": "2024-07-01 13:35:53 UTC",
      "updated_date": "2024-08-05 15:50:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:28:56.737034"
    },
    {
      "arxiv_id": "2407.01280v1",
      "title": "Human-Robot Mutual Learning through Affective-Linguistic Interaction and Differential Outcomes Training [Pre-Print]",
      "title_zh": "翻译失败",
      "authors": [
        "Emilia Heikkinen",
        "Elsa Silvennoinen",
        "Imran Khan",
        "Zakaria Lemhaouri",
        "Laura Cohen",
        "Lola Cañamero",
        "Robert Lowe"
      ],
      "abstract": "Owing to the recent success of Large Language Models, Modern A.I has been\nmuch focused on linguistic interactions with humans but less focused on\nnon-linguistic forms of communication between man and machine. In the present\npaper, we test how affective-linguistic communication, in combination with\ndifferential outcomes training, affects mutual learning in a human-robot\ncontext. Taking inspiration from child-caregiver dynamics, our human-robot\ninteraction setup consists of a (simulated) robot attempting to learn how best\nto communicate internal, homeostatically-controlled needs; while a human\n\"caregiver\" attempts to learn the correct object to satisfy the robot's present\ncommunicated need. We studied the effects of i) human training type, and ii)\nrobot reinforcement learning type, to assess mutual learning terminal accuracy\nand rate of learning (as measured by the average reward achieved by the robot).\nOur results find mutual learning between a human and a robot is significantly\nimproved with Differential Outcomes Training (DOT) compared to Non-DOT\n(control) conditions. We find further improvements when the robot uses an\nexploration-exploitation policy selection, compared to purely exploitation\npolicy selection. These findings have implications for utilizing socially\nassistive robots (SAR) in therapeutic contexts, e.g. for cognitive\ninterventions, and educational applications.",
      "tldr_zh": "这篇论文探讨了通过情感-语言交互（Affective-Linguistic Interaction）和差异结果训练（Differential Outcomes Training, DOT）来提升人类-机器人互学的效果。实验设置模拟了机器人学习表达内部需求，而人类作为“护理者”学习满足这些需求，比较了人类训练类型和机器人强化学习类型（如exploration-exploitation策略与纯exploitation策略）。结果显示，DOT条件显著提高了互学的准确性和学习速度，而exploration-exploitation策略进一步优化了机器人表现。这些发现为社会辅助机器人（SAR）在认知干预和教育应用中提供了重要启示。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "14 pages, with references; 1 figure, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.01280v1",
      "published_date": "2024-07-01 13:35:08 UTC",
      "updated_date": "2024-07-01 13:35:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:28:58.582688"
    },
    {
      "arxiv_id": "2407.01270v2",
      "title": "The African Woman is Rhythmic and Soulful: An Investigation of Implicit Biases in LLM Open-ended Text Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Serene Lim",
        "María Pérez-Ortiz"
      ],
      "abstract": "This paper investigates the subtle and often concealed biases present in\nLarge Language Models (LLMs), focusing on implicit biases that may remain\ndespite passing explicit bias tests. Implicit biases are significant because\nthey influence the decisions made by these systems, potentially perpetuating\nstereotypes and discrimination, even when LLMs appear to function fairly.\nTraditionally, explicit bias tests or embedding-based methods are employed to\ndetect bias, but these approaches can overlook more nuanced, implicit forms of\nbias. To address this, we introduce two novel psychological-inspired\nmethodologies: the LLM Implicit Association Test (IAT) Bias and the LLM\nDecision Bias, designed to reveal and measure implicit biases through\nprompt-based and decision-making tasks. Additionally, open-ended generation\ntasks with thematic analysis of word generations and storytelling provide\nqualitative insights into the model's behavior. Our findings demonstrate that\nthe LLM IAT Bias correlates with traditional methods and more effectively\npredicts downstream behaviors, as measured by the LLM Decision Bias, offering a\nmore comprehensive framework for detecting subtle biases in AI systems. This\nresearch advances the field of AI ethics by proposing new methods to\ncontinually assess and mitigate biases in LLMs, highlighting the importance of\nqualitative and decision-focused evaluations to address challenges that\nprevious approaches have not fully captured.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 中隐性偏见 (Implicit Biases) 的问题，这些偏见即使通过显性测试也可能存在，并可能在模型决策中 perpetuate 刻板印象和歧视。作者引入了两个新方法——LLM Implicit Association Test (IAT) Bias 和 LLM Decision Bias，通过提示任务、决策任务以及开放生成任务的主题分析来揭示和量化这些细微偏见。研究发现，LLM IAT Bias 与传统检测方法相关联，并更有效地预测模型的下游行为，提供了一个更全面的框架。最终，这为 AI 伦理领域贡献了新评估和缓解偏见的策略，强调了定性和决策导向评估的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01270v2",
      "published_date": "2024-07-01 13:21:33 UTC",
      "updated_date": "2024-09-30 16:39:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:29:11.824012"
    },
    {
      "arxiv_id": "2407.12038v2",
      "title": "ICAGC 2024: Inspirational and Convincing Audio Generation Challenge 2024",
      "title_zh": "翻译失败",
      "authors": [
        "Ruibo Fu",
        "Rui Liu",
        "Chunyu Qiang",
        "Yingming Gao",
        "Yi Lu",
        "Shuchen Shi",
        "Tao Wang",
        "Ya Li",
        "Zhengqi Wen",
        "Chen Zhang",
        "Hui Bu",
        "Yukun Liu",
        "Xin Qi",
        "Guanjun Li"
      ],
      "abstract": "The Inspirational and Convincing Audio Generation Challenge 2024 (ICAGC 2024)\nis part of the ISCSLP 2024 Competitions and Challenges track. While current\ntext-to-speech (TTS) technology can generate high-quality audio, its ability to\nconvey complex emotions and controlled detail content remains limited. This\nconstraint leads to a discrepancy between the generated audio and human\nsubjective perception in practical applications like companion robots for\nchildren and marketing bots. The core issue lies in the inconsistency between\nhigh-quality audio generation and the ultimate human subjective experience.\nTherefore, this challenge aims to enhance the persuasiveness and acceptability\nof synthesized audio, focusing on human alignment convincing and inspirational\naudio generation. A total of 19 teams have registered for the challenge, and\nthe results of the competition and the competition are described in this paper.",
      "tldr_zh": "ICAGC 2024是ISCSLP 2024竞赛的一部分，旨在解决当前text-to-speech (TTS) 技术在生成高质量音频时，无法有效传达复杂情绪和细节内容的问题，导致合成音频与人类主观感知不一致。挑战赛重点提升音频的说服力和可接受性，特别关注人类对齐的convincing和inspirational音频生成，以应用于如儿童伴侣机器人和营销机器人等场景。共有19个团队注册参与，论文详细描述了比赛结果和关键发现。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "ISCSLP 2024 Challenge description and results",
      "pdf_url": "http://arxiv.org/pdf/2407.12038v2",
      "published_date": "2024-07-01 13:15:16 UTC",
      "updated_date": "2024-07-31 14:23:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:29:22.466893"
    },
    {
      "arxiv_id": "2407.12820v2",
      "title": "PQCache: Product Quantization-based KVCache for Long Context LLM Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Hailin Zhang",
        "Xiaodong Ji",
        "Yilin Chen",
        "Fangcheng Fu",
        "Xupeng Miao",
        "Xiaonan Nie",
        "Weipeng Chen",
        "Bin Cui"
      ],
      "abstract": "As the field of Large Language Models (LLMs) continues to evolve, the context\nlength in inference is steadily growing. Key-Value Cache (KVCache), the\nintermediate representations of tokens within LLM inference, has now become the\nprimary memory bottleneck due to limited GPU memory. Current methods\nselectively determine suitable keys and values for self-attention computation\nin LLMs to address the issue. However, they either fall short in maintaining\nmodel quality or result in high serving latency. Drawing inspiration from\nadvanced embedding retrieval techniques prevalent in the data management\ncommunity, we consider the storage and retrieval of KVCache as a typical\nembedding retrieval problem. We propose PQCache, which employs Product\nQuantization (PQ) to manage KVCache, maintaining model quality while ensuring\nlow serving latency. During the prefilling phase, we apply PQ to tokens' keys\nfor each LLM layer and head. During the autoregressive decoding phase, we use\nPQ codes and centroids to approximately identify important preceding tokens,\nthen fetch the corresponding key-value pairs for self-attention computation.\nThrough meticulous design of overlapping and caching, we minimize any\nadditional computation and communication overhead during both phases. Extensive\nexperiments demonstrate that PQCache achieves both effectiveness and\nefficiency, with 4.60% score improvement over existing methods on InfiniteBench\nand low system latency in both prefilling and decoding.",
      "tldr_zh": "该论文针对大型语言模型(LLM)推理中长上下文导致的KVCache内存瓶颈问题，提出PQCache框架，该框架利用Product Quantization (PQ)技术对KVCache进行高效存储和检索，以平衡模型质量和延迟。PQCache在预填充阶段对每个LLM层和头的键应用PQ编码，而在自回归解码阶段，通过PQ代码和中心点近似识别重要前置标记，并获取相应键值对进行自注意力计算，同时通过重叠和缓存设计最小化额外开销。实验结果显示，PQCache在InfiniteBench基准上比现有方法提升4.60%的性能分数，并在预填充和解码阶段实现低系统延迟。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12820v2",
      "published_date": "2024-07-01 13:05:42 UTC",
      "updated_date": "2025-03-30 08:13:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:29:34.382444"
    },
    {
      "arxiv_id": "2407.01251v1",
      "title": "QUEEN: Query Unlearning against Model Extraction",
      "title_zh": "QUEEN：针对模型提取的查询遗忘",
      "authors": [
        "Huajie Chen",
        "Tianqing Zhu",
        "Lefeng Zhang",
        "Bo Liu",
        "Derui Wang",
        "Wanlei Zhou",
        "Minhui Xue"
      ],
      "abstract": "Model extraction attacks currently pose a non-negligible threat to the\nsecurity and privacy of deep learning models. By querying the model with a\nsmall dataset and usingthe query results as the ground-truth labels, an\nadversary can steal a piracy model with performance comparable to the original\nmodel. Two key issues that cause the threat are, on the one hand, accurate and\nunlimited queries can be obtained by the adversary; on the other hand, the\nadversary can aggregate the query results to train the model step by step. The\nexisting defenses usually employ model watermarking or fingerprinting to\nprotect the ownership. However, these methods cannot proactively prevent the\nviolation from happening. To mitigate the threat, we propose QUEEN (QUEry\nunlEarNing) that proactively launches counterattacks on potential model\nextraction attacks from the very beginning. To limit the potential threat,\nQUEEN has sensitivity measurement and outputs perturbation that prevents the\nadversary from training a piracy model with high performance. In sensitivity\nmeasurement, QUEEN measures the single query sensitivity by its distance from\nthe center of its cluster in the feature space. To reduce the learning accuracy\nof attacks, for the highly sensitive query batch, QUEEN applies query\nunlearning, which is implemented by gradient reverse to perturb the softmax\noutput such that the piracy model will generate reverse gradients to worsen its\nperformance unconsciously. Experiments show that QUEEN outperforms the\nstate-of-the-art defenses against various model extraction attacks with a\nrelatively low cost to the model accuracy. The artifact is publicly available\nat https://anonymous.4open.science/r/queen implementation-5408/.",
      "tldr_zh": "这篇论文针对模型提取攻击（Model Extraction）提出了一种主动防御框架QUEEN，以保护深度学习模型的安全和隐私。QUEEN通过敏感性测量（sensitivity measurement）评估查询的敏感度，并对高敏感查询批次应用查询取消学习（Query Unlearning），利用梯度反转（gradient reverse）扰动softmax输出，从而降低攻击者训练盗版模型的准确性。实验结果显示，QUEEN在各种模型提取攻击中优于现有防御方法，同时对原模型性能的影响较小。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01251v1",
      "published_date": "2024-07-01 13:01:41 UTC",
      "updated_date": "2024-07-01 13:01:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:29:48.218882"
    },
    {
      "arxiv_id": "2407.01653v1",
      "title": "A Deep Reinforcement Learning Approach to Battery Management in Dairy Farming via Proximal Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Nawazish Ali",
        "Rachael Shaw",
        "Karl Mason"
      ],
      "abstract": "Dairy farms consume a significant amount of electricity for their operations,\nand this research focuses on enhancing energy efficiency and minimizing the\nimpact on the environment in the sector by maximizing the utilization of\nrenewable energy sources. This research investigates the application of\nProximal Policy Optimization (PPO), a deep reinforcement learning algorithm\n(DRL), to enhance dairy farming battery management. We evaluate the algorithm's\neffectiveness based on its ability to reduce reliance on the electricity grid,\nhighlighting the potential of DRL to enhance energy management in dairy\nfarming. Using real-world data our results demonstrate how the PPO approach\noutperforms Q-learning by 1.62% for reducing electricity import from the grid.\nThis significant improvement highlights the potential of the Deep Reinforcement\nLearning algorithm for improving energy efficiency and sustainability in dairy\nfarms.",
      "tldr_zh": "本研究使用Proximal Policy Optimization (PPO)，一种深度强化学习(DRL)算法，来优化奶牛养殖场的电池管理，旨在提高能源效率、减少对电网的依赖并最大化可再生能源利用。实验基于真实数据，将PPO与Q-learning算法进行比较，结果显示PPO在减少电网进口电量方面提升了1.62%。这一显著改进突显了DRL在提升奶牛养殖场能源管理和可持续性方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 5 figures, Practical Applications of Agents and Multi-Agent\n  Systems(PAAMS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.01653v1",
      "published_date": "2024-07-01 12:46:09 UTC",
      "updated_date": "2024-07-01 12:46:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:29:58.319286"
    },
    {
      "arxiv_id": "2407.01245v2",
      "title": "SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Lingyue Fu",
        "Hao Guan",
        "Kounianhua Du",
        "Jianghao Lin",
        "Wei Xia",
        "Weinan Zhang",
        "Ruiming Tang",
        "Yasheng Wang",
        "Yong Yu"
      ],
      "abstract": "Knowledge Tracing (KT) aims to determine whether students will respond\ncorrectly to the next question, which is a crucial task in intelligent tutoring\nsystems (ITS). In educational KT scenarios, transductive ID-based methods often\nface severe data sparsity and cold start problems, where interactions between\nindividual students and questions are sparse, and new questions and concepts\nconsistently arrive in the database. In addition, existing KT models only\nimplicitly consider the correlation between concepts and questions, lacking\ndirect modeling of the more complex relationships in the heterogeneous graph of\nconcepts and questions. In this paper, we propose a Structure-aware Inductive\nKnowledge Tracing model with large language model (dubbed SINKT), which, for\nthe first time, introduces large language models (LLMs) and realizes inductive\nknowledge tracing. Firstly, SINKT utilizes LLMs to introduce structural\nrelationships between concepts and constructs a heterogeneous graph for\nconcepts and questions. Secondly, by encoding concepts and questions with LLMs,\nSINKT incorporates semantic information to aid prediction. Finally, SINKT\npredicts the student's response to the target question by interacting with the\nstudent's knowledge state and the question representation. Experiments on four\nreal-world datasets demonstrate that SINKT achieves state-of-the-art\nperformance among 12 existing transductive KT models. Additionally, we explore\nthe performance of SINKT on the inductive KT task and provide insights into\nvarious modules.",
      "tldr_zh": "该论文提出SINKT模型，一种基于大型语言模型(LLMs)的结构感知归纳知识追踪(Inductive Knowledge Tracing)方法，旨在解决智能辅导系统(KT)中的数据稀疏、冷启动问题以及概念和问题之间复杂关系的建模不足。SINKT首先利用LLMs构建概念和问题的异构图(Heterogeneous Graph)，并通过编码语义信息来增强预测准确性，最终通过交互学生的知识状态和问题表示来预测回答。实验结果显示，在四个真实数据集上，SINKT在12个现有transductive KT模型中取得最先进性能，并为归纳KT任务提供了重要洞见。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01245v2",
      "published_date": "2024-07-01 12:44:52 UTC",
      "updated_date": "2024-07-23 12:23:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:30:12.417848"
    },
    {
      "arxiv_id": "2407.01239v1",
      "title": "SGCCNet: Single-Stage 3D Object Detector With Saliency-Guided Data Augmentation and Confidence Correction Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Ao Liang",
        "Wenyu Chen",
        "Jian Fang",
        "Huaici Zhao"
      ],
      "abstract": "The single-stage point-based 3D object detectors have attracted widespread\nresearch interest due to their advantages of lightweight and fast inference\nspeed. However, they still face challenges such as inadequate learning of\nlow-quality objects (ILQ) and misalignment between localization accuracy and\nclassification confidence (MLC). In this paper, we propose SGCCNet to alleviate\nthese two issues. For ILQ, SGCCNet adopts a Saliency-Guided Data Augmentation\n(SGDA) strategy to enhance the robustness of the model on low-quality objects\nby reducing its reliance on salient features. Specifically, We construct a\nclassification task and then approximate the saliency scores of points by\nmoving points towards the point cloud centroid in a differentiable process.\nDuring the training process, SGCCNet will be forced to learn from low saliency\nfeatures through dropping points. Meanwhile, to avoid internal covariate shift\nand contextual features forgetting caused by dropping points, we add a\ngeometric normalization module and skip connection block in each stage. For\nMLC, we design a Confidence Correction Mechanism (CCM) specifically for\npoint-based multi-class detectors. This mechanism corrects the confidence of\nthe current proposal by utilizing the predictions of other key points within\nthe local region in the post-processing stage. Extensive experiments on the\nKITTI dataset demonstrate the generality and effectiveness of our SGCCNet. On\nthe KITTI \\textit{test} set, SGCCNet achieves $80.82\\%$ for the metric of\n$AP_{3D}$ on the \\textit{Moderate} level, outperforming all other point-based\ndetectors, surpassing IA-SSD and Fast Point R-CNN by $2.35\\%$ and $3.42\\%$,\nrespectively. Additionally, SGCCNet demonstrates excellent portability for\nother point-based detectors",
      "tldr_zh": "该论文提出 SGCCNet，一种单阶段基于点的 3D 对象检测器，旨在解决低质量对象学习不足 (ILQ) 和定位准确性与分类置信度不一致 (MLC) 的问题。针对 ILQ，SGCCNet 采用 Saliency-Guided Data Augmentation (SGDA) 策略，通过估算点云的显著性分数并丢弃高显著性点来增强模型对低质量对象的鲁棒性，同时添加几何归一化模块和跳跃连接块以避免训练中的偏移和特征遗忘。对于 MLC，设计 Confidence Correction Mechanism (CCM) 在后处理阶段利用本地关键点的预测来修正置信度。在 KITTI 数据集上，SGCCNet 在 Moderate 水平上实现 80.82% 的 AP3D 指标，优于其他基于点检测器，并展示出良好的可移植性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.01239v1",
      "published_date": "2024-07-01 12:36:01 UTC",
      "updated_date": "2024-07-01 12:36:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:30:26.564471"
    },
    {
      "arxiv_id": "2407.01238v3",
      "title": "Large Language Models are Zero-Shot Recognizers for Activities of Daily Living",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriele Civitarese",
        "Michele Fiori",
        "Priyankar Choudhary",
        "Claudio Bettini"
      ],
      "abstract": "The sensor-based recognition of Activities of Daily Living (ADLs) in smart\nhome environments enables several applications in the areas of energy\nmanagement, safety, well-being, and healthcare. ADLs recognition is typically\nbased on deep learning methods requiring large datasets to be trained.\nRecently, several studies proved that Large Language Models (LLMs) effectively\ncapture common-sense knowledge about human activities. However, the\neffectiveness of LLMs for ADLs recognition in smart home environments still\ndeserves to be investigated. In this work, we propose ADL-LLM, a novel\nLLM-based ADLs recognition system. ADLLLM transforms raw sensor data into\ntextual representations, that are processed by an LLM to perform zero-shot ADLs\nrecognition. Moreover, in the scenario where a small labeled dataset is\navailable, ADL-LLM can also be empowered with few-shot prompting. We evaluated\nADL-LLM on two public datasets, showing its effectiveness in this domain.",
      "tldr_zh": "这篇论文发现大型语言模型(LLMs)可以作为零样本(zero-shot)识别器，用于智能家居环境中基于传感器的日常活动(Activities of Daily Living, ADLs)识别，绕过了传统深度学习方法对大规模数据集的依赖。研究提出了ADL-LLM系统，该系统将原始传感器数据转化为文本表示，然后由LLM处理来进行零样本识别，并在有少量标注数据时通过few-shot prompting增强性能。在两个公共数据集上的评估结果显示，ADL-LLM在该领域表现出色，证明了LLMs在捕捉常识知识方面的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "Paper accepted for publication in the ACM Transactions on Intelligent\n  Systems and Technology (TIST) journal",
      "pdf_url": "http://arxiv.org/pdf/2407.01238v3",
      "published_date": "2024-07-01 12:32:38 UTC",
      "updated_date": "2025-03-20 20:43:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:30:34.697651"
    },
    {
      "arxiv_id": "2407.01231v1",
      "title": "MIRAI: Evaluating LLM Agents for Event Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Chenchen Ye",
        "Ziniu Hu",
        "Yihe Deng",
        "Zijie Huang",
        "Mingyu Derek Ma",
        "Yanqiao Zhu",
        "Wei Wang"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have empowered LLM agents\nto autonomously collect world information, over which to conduct reasoning to\nsolve complex problems. Given this capability, increasing interests have been\nput into employing LLM agents for predicting international events, which can\ninfluence decision-making and shape policy development on an international\nscale. Despite such a growing interest, there is a lack of a rigorous benchmark\nof LLM agents' forecasting capability and reliability. To address this gap, we\nintroduce MIRAI, a novel benchmark designed to systematically evaluate LLM\nagents as temporal forecasters in the context of international events. Our\nbenchmark features an agentic environment with tools for accessing an extensive\ndatabase of historical, structured events and textual news articles. We refine\nthe GDELT event database with careful cleaning and parsing to curate a series\nof relational prediction tasks with varying forecasting horizons, assessing LLM\nagents' abilities from short-term to long-term forecasting. We further\nimplement APIs to enable LLM agents to utilize different tools via a code-based\ninterface. In summary, MIRAI comprehensively evaluates the agents' capabilities\nin three dimensions: 1) autonomously source and integrate critical information\nfrom large global databases; 2) write codes using domain-specific APIs and\nlibraries for tool-use; and 3) jointly reason over historical knowledge from\ndiverse formats and time to accurately predict future events. Through\ncomprehensive benchmarking, we aim to establish a reliable framework for\nassessing the capabilities of LLM agents in forecasting international events,\nthereby contributing to the development of more accurate and trustworthy models\nfor international relation analysis.",
      "tldr_zh": "本研究引入了 MIRAI，这是一个新颖的基准，用于系统评估大型语言模型 (LLMs) 代理在国际事件预测中的能力和可靠性。MIRAI 构建了一个代理环境，提供工具访问经过清理的 GDELT 事件数据库和新闻文章，支持一系列关系预测任务，从短期到长期预测，并通过代码接口启用代理使用 APIs。基准从三个维度评估代理的能力：自主获取并整合全球数据库信息、使用领域特定 APIs 编写代码，以及基于历史知识进行推理以准确预测未来事件，最终为开发更可靠的国际关系分析模型提供框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "66 pages, 8 figures, 6 tables; Website: https://mirai-llm.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2407.01231v1",
      "published_date": "2024-07-01 12:22:46 UTC",
      "updated_date": "2024-07-01 12:22:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:30:47.190851"
    },
    {
      "arxiv_id": "2407.01216v1",
      "title": "Let Hybrid A* Path Planner Obey Traffic Rules: A Deep Reinforcement Learning-Based Planning Framework",
      "title_zh": "让 Hybrid A* 路径规划器遵守交通规则：一个基于深度强化学习的规划框架",
      "authors": [
        "Xibo Li",
        "Shruti Patel",
        "Christof Büskens"
      ],
      "abstract": "Deep reinforcement learning (DRL) allows a system to interact with its\nenvironment and take actions by training an efficient policy that maximizes\nself-defined rewards. In autonomous driving, it can be used as a strategy for\nhigh-level decision making, whereas low-level algorithms such as the hybrid A*\npath planning have proven their ability to solve the local trajectory planning\nproblem. In this work, we combine these two methods where the DRL makes\nhigh-level decisions such as lane change commands. After obtaining the lane\nchange command, the hybrid A* planner is able to generate a collision-free\ntrajectory to be executed by a model predictive controller (MPC). In addition,\nthe DRL algorithm is able to keep the lane change command consistent within a\nchosen time-period. Traffic rules are implemented using linear temporal logic\n(LTL), which is then utilized as a reward function in DRL. Furthermore, we\nvalidate the proposed method on a real system to demonstrate its feasibility\nfrom simulation to implementation on real hardware.",
      "tldr_zh": "该研究提出了一种基于深度强化学习 (DRL) 的路径规划框架，旨在让 Hybrid A* 路径规划器遵守交通规则。框架中，DRL 负责高层决策（如变道命令），随后 Hybrid A* 生成无碰撞轨迹，并由模型预测控制器 (MPC) 执行；同时，DRL 通过线性时序逻辑 (LTL) 作为奖励函数，确保命令的一致性和交通规则的遵守。实验结果显示，该方法在模拟和真实硬件系统中均可行，为自动驾驶决策提供了可靠的策略。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01216v1",
      "published_date": "2024-07-01 12:00:10 UTC",
      "updated_date": "2024-07-01 12:00:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:30:58.427344"
    },
    {
      "arxiv_id": "2407.01214v3",
      "title": "Revisiting Random Walks for Learning on Graphs",
      "title_zh": "重新审视随机游走在图学习中的应用",
      "authors": [
        "Jinwoo Kim",
        "Olga Zaghen",
        "Ayhan Suleymanzade",
        "Youngmin Ryou",
        "Seunghoon Hong"
      ],
      "abstract": "We revisit a simple model class for machine learning on graphs, where a\nrandom walk on a graph produces a machine-readable record, and this record is\nprocessed by a deep neural network to directly make vertex-level or graph-level\npredictions. We call these stochastic machines random walk neural networks\n(RWNNs), and through principled analysis, show that we can design them to be\nisomorphism invariant while capable of universal approximation of graph\nfunctions in probability. A useful finding is that almost any kind of record of\nrandom walks guarantees probabilistic invariance as long as the vertices are\nanonymized. This enables us, for example, to record random walks in plain text\nand adopt a language model to read these text records to solve graph tasks. We\nfurther establish a parallelism to message passing neural networks using tools\nfrom Markov chain theory, and show that over-smoothing in message passing is\nalleviated by construction in RWNNs, while over-squashing manifests as\nprobabilistic under-reaching. We empirically demonstrate RWNNs on a range of\nproblems, verifying our theoretical analysis and demonstrating the use of\nlanguage models for separating strongly regular graphs where 3-WL test fails,\nand transductive classification on arXiv citation network. Code is available at\nhttps://github.com/jw9730/random-walk.",
      "tldr_zh": "本研究重新审视了基于随机游走(Random Walks)的图学习模型，提出随机游走神经网络(RWNNs)，该模型通过在图上进行随机游走生成机器可读记录，并由深度神经网络处理来实现顶点级或图级预测。RWNNs 被设计为同构不变(Isomorphism Invariant)且在概率上实现图函数的通用逼近(Universal Approximation)，关键在于顶点匿名化确保了概率不变性，从而允许使用文本记录和语言模型处理图任务。与消息传递神经网络(Message Passing Neural Networks)相比，RWNNs 通过Markov链理论缓解了过平滑(Over-Smoothing)问题，但可能出现概率下达不到(Probabilistic Under-Reaching)的现象。实验结果显示，RWNNs 在区分强正则图(Strongly Regular Graphs)以及arXiv引用网络的半监督分类任务中表现出色，验证了其理论分析。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "51 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.01214v3",
      "published_date": "2024-07-01 11:59:59 UTC",
      "updated_date": "2025-03-05 07:02:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:31:12.431011"
    },
    {
      "arxiv_id": "2407.01211v1",
      "title": "Efficient Cutting Tool Wear Segmentation Based on Segment Anything Model",
      "title_zh": "基于 Segment Anything Model 的高效切割工具磨损分割",
      "authors": [
        "Zongshuo Li",
        "Ding Huo",
        "Markus Meurer",
        "Thomas Bergs"
      ],
      "abstract": "Tool wear conditions impact the surface quality of the workpiece and its\nfinal geometric precision. In this research, we propose an efficient tool wear\nsegmentation approach based on Segment Anything Model, which integrates U-Net\nas an automated prompt generator to streamline the processes of tool wear\ndetection. Our evaluation covered three Point-of-Interest generation methods\nand further investigated the effects of variations in training dataset sizes\nand U-Net training intensities on resultant wear segmentation outcomes. The\nresults consistently highlight our approach's advantage over U-Net, emphasizing\nits ability to achieve accurate wear segmentation even with limited training\ndatasets. This feature underscores its potential applicability in industrial\nscenarios where datasets may be limited.",
      "tldr_zh": "本文提出了一种基于Segment Anything Model的刀具磨损分割方法，整合U-Net作为自动提示生成器，以简化刀具磨损检测过程并提升效率。该方法通过评估三种兴趣点生成方法，并分析训练数据集大小和U-Net训练强度的影响，证明其在数据有限场景下仍能实现准确的磨损分割，比传统U-Net方法更具优势。这种高效的分割技术具有在工业环境中应用的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01211v1",
      "published_date": "2024-07-01 11:57:53 UTC",
      "updated_date": "2024-07-01 11:57:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:31:21.947659"
    },
    {
      "arxiv_id": "2407.01200v1",
      "title": "Deep Learning Approach for Enhanced Transferability and Learning Capacity in Tool Wear Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Zongshuo Li",
        "Markus Meurer",
        "Thomas Bergs"
      ],
      "abstract": "As an integral part of contemporary manufacturing, monitoring systems obtain\nvaluable information during machining to oversee the condition of both the\nprocess and the machine. Recently, diverse algorithms have been employed to\ndetect tool wear using single or multiple sources of measurements. In this\nstudy, a deep learning approach is proposed for estimating tool wear,\nconsidering cutting parameters. The model's accuracy and transferability in\ntool wear estimation were assessed with milling experiments conducted under\nvarying cutting parameters. The results indicate that the proposed method\noutperforms conventional methods in terms of both transferability and rapid\nlearning capabilities.",
      "tldr_zh": "这篇论文提出了一种深度学习方法，用于提升工具磨损估计（tool wear estimation）的可转移性（transferability）和学习能力（learning capacity）。该方法考虑了切割参数，通过铣削实验评估了模型的准确性，结果显示它在可转移性和快速学习能力上优于传统方法。该研究为制造过程中的工具监控系统提供了更高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01200v1",
      "published_date": "2024-07-01 11:49:10 UTC",
      "updated_date": "2024-07-01 11:49:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:31:33.606840"
    },
    {
      "arxiv_id": "2407.01199v1",
      "title": "Deep Learning Based Tool Wear Estimation Considering Cutting Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Zongshuo Li",
        "Markus Meurer",
        "Thomas Bergs"
      ],
      "abstract": "Tool wear conditions impact the final quality of the workpiece. In this\nstudy, we propose a deep learning approach based on a convolutional neural\nnetwork that incorporates cutting conditions as extra model inputs, aiming to\nimprove tool wear estimation accuracy and fulfill industrial demands for\nzero-shot transferability. Through a series of milling experiments under\nvarious cutting parameters, we evaluate the model's performance in terms of\ntool wear estimation accuracy and its transferability to new fixed or variable\ncutting parameters. The results consistently highlight our approach's advantage\nover conventional models that omit cutting conditions, maintaining superior\nperformance irrespective of the stability of the wear development or the\nlimitation of the training dataset. This finding underscores its potential\napplicability in industrial scenarios.",
      "tldr_zh": "本文提出了一种基于深度学习的工具磨损估计方法，使用卷积神经网络（CNN）并将切割条件作为额外输入，以提升估计准确性和实现零样本迁移（zero-shot transferability）。通过一系列铣削实验，该方法在不同切割参数下表现出色，比忽略切割条件的传统模型准确率更高，且不受磨损发展稳定性和训练数据集限制的影响。研究结果突显了该方法的工业应用潜力，可帮助改善工件质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01199v1",
      "published_date": "2024-07-01 11:48:33 UTC",
      "updated_date": "2024-07-01 11:48:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:31:57.365875"
    },
    {
      "arxiv_id": "2407.01191v1",
      "title": "MARS: Multimodal Active Robotic Sensing for Articulated Characterization",
      "title_zh": "翻译失败",
      "authors": [
        "Hongliang Zeng",
        "Ping Zhang",
        "Chengjiong Wu",
        "Jiahua Wang",
        "Tingyu Ye",
        "Fang Li"
      ],
      "abstract": "Precise perception of articulated objects is vital for empowering service\nrobots. Recent studies mainly focus on point cloud, a single-modal approach,\noften neglecting vital texture and lighting details and assuming ideal\nconditions like optimal viewpoints, unrepresentative of real-world scenarios.\nTo address these limitations, we introduce MARS, a novel framework for\narticulated object characterization. It features a multi-modal fusion module\nutilizing multi-scale RGB features to enhance point cloud features, coupled\nwith reinforcement learning-based active sensing for autonomous optimization of\nobservation viewpoints. In experiments conducted with various articulated\nobject instances from the PartNet-Mobility dataset, our method outperformed\ncurrent state-of-the-art methods in joint parameter estimation accuracy.\nAdditionally, through active sensing, MARS further reduces errors,\ndemonstrating enhanced efficiency in handling suboptimal viewpoints.\nFurthermore, our method effectively generalizes to real-world articulated\nobjects, enhancing robot interactions. Code is available at\nhttps://github.com/robhlzeng/MARS.",
      "tldr_zh": "该研究提出 MARS 框架，用于提升服务机器人在铰接物体（articulated objects）的精确感知，解决现有 point cloud 方法忽略纹理和光照细节以及非理想视点的问题。MARS 包括多模态融合模块，利用多尺度 RGB 特征增强 point cloud 特征，并结合 reinforcement learning-based active sensing 来自主优化观察视点。在 PartNet-Mobility 数据集的实验中，该方法在关节参数估计准确性上优于现有最先进方法，并通过 active sensing 进一步减少错误，提升机器人交互效率，同时证明了其在真实世界的泛化能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01191v1",
      "published_date": "2024-07-01 11:32:39 UTC",
      "updated_date": "2024-07-01 11:32:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:32:00.798824"
    },
    {
      "arxiv_id": "2407.01178v1",
      "title": "$\\text{Memory}^3$: Language Modeling with Explicit Memory",
      "title_zh": "翻译失败",
      "authors": [
        "Hongkang Yang",
        "Zehao Lin",
        "Wenjin Wang",
        "Hao Wu",
        "Zhiyu Li",
        "Bo Tang",
        "Wenqiang Wei",
        "Jinbo Wang",
        "Zeyun Tang",
        "Shichao Song",
        "Chenyang Xi",
        "Yu Yu",
        "Kai Chen",
        "Feiyu Xiong",
        "Linpeng Tang",
        "Weinan E"
      ],
      "abstract": "The training and inference of large language models (LLMs) are together a\ncostly process that transports knowledge from raw data to meaningful\ncomputation. Inspired by the memory hierarchy of the human brain, we reduce\nthis cost by equipping LLMs with explicit memory, a memory format cheaper than\nmodel parameters and text retrieval-augmented generation (RAG). Conceptually,\nwith most of its knowledge externalized to explicit memories, the LLM can enjoy\na smaller parameter size, training cost, and inference cost, all proportional\nto the amount of remaining \"abstract knowledge\". As a preliminary proof of\nconcept, we train from scratch a 2.4B LLM, which achieves better performance\nthan much larger LLMs as well as RAG models, and maintains higher decoding\nspeed than RAG. The model is named $\\text{Memory}^3$, since explicit memory is\nthe third form of memory in LLMs after implicit memory (model parameters) and\nworking memory (context key-values). We introduce a memory circuitry theory to\nsupport the externalization of knowledge, and present novel techniques\nincluding a memory sparsification mechanism that makes storage tractable and a\ntwo-stage pretraining scheme that facilitates memory formation.",
      "tldr_zh": "本研究提出$\\text{Memory}^3$框架，为大型语言模型(LLMs)引入显式记忆(explicit memory)，以降低训练和推理成本，这种记忆形式比模型参数和文本检索增强生成(RAG)更高效。概念上，通过将大部分知识外化到显式记忆，LLMs能减少参数规模和计算开销，同时保持性能优势；例如，从零训练的2.4B参数模型在多项任务上超越更大LLMs和RAG模型，并实现更快的解码速度。该框架基于记忆电路理论(memory circuitry theory)，并采用创新技术如记忆稀疏化机制(memory sparsification mechanism)和两阶段预训练方案(two-stage pretraining scheme)，为高效语言建模提供新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01178v1",
      "published_date": "2024-07-01 11:07:23 UTC",
      "updated_date": "2024-07-01 11:07:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:32:16.739520"
    },
    {
      "arxiv_id": "2407.01168v2",
      "title": "Multi-View Black-Box Physical Attacks on Infrared Pedestrian Detectors Using Adversarial Infrared Grid",
      "title_zh": "翻译失败",
      "authors": [
        "Kalibinuer Tiliwalidi",
        "Chengyin Hu",
        "Weiwen Shi"
      ],
      "abstract": "While extensive research exists on physical adversarial attacks within the\nvisible spectrum, studies on such techniques in the infrared spectrum are\nlimited. Infrared object detectors are vital in modern technological\napplications but are susceptible to adversarial attacks, posing significant\nsecurity threats. Previous studies using physical perturbations like light bulb\narrays and aerogels for white-box attacks, or hot and cold patches for\nblack-box attacks, have proven impractical or limited in multi-view support. To\naddress these issues, we propose the Adversarial Infrared Grid (AdvGrid), which\nmodels perturbations in a grid format and uses a genetic algorithm for\nblack-box optimization. These perturbations are cyclically applied to various\nparts of a pedestrian's clothing to facilitate multi-view black-box physical\nattacks on infrared pedestrian detectors. Extensive experiments validate\nAdvGrid's effectiveness, stealthiness, and robustness. The method achieves\nattack success rates of 80.00\\% in digital environments and 91.86\\% in physical\nenvironments, outperforming baseline methods. Additionally, the average attack\nsuccess rate exceeds 50\\% against mainstream detectors, demonstrating AdvGrid's\nrobustness. Our analyses include ablation studies, transfer attacks, and\nadversarial defenses, confirming the method's superiority.",
      "tldr_zh": "本研究针对红外行人检测器的漏洞，提出了一种多视图黑-box物理攻击方法，使用Adversarial Infrared Grid (AdvGrid)来生成扰动。AdvGrid将扰动建模为网格格式，并采用genetic algorithm进行优化，这些扰动循环应用于行人衣服的不同部位，以实现有效的多视图攻击。实验结果显示，该方法在数字环境成功率达80.00%，在物理环境达91.86%，优于基线方法，且对主流检测器的平均攻击成功率超过50%，通过消融研究、转移攻击和对抗防御分析证实了其鲁棒性和优越性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01168v2",
      "published_date": "2024-07-01 10:38:08 UTC",
      "updated_date": "2024-07-08 14:17:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:32:25.872891"
    },
    {
      "arxiv_id": "2407.01157v1",
      "title": "Unaligning Everything: Or Aligning Any Text to Any Image in Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shaeke Salman",
        "Md Montasir Bin Shams",
        "Xiuwen Liu"
      ],
      "abstract": "Utilizing a shared embedding space, emerging multimodal models exhibit\nunprecedented zero-shot capabilities. However, the shared embedding space could\nlead to new vulnerabilities if different modalities can be misaligned. In this\npaper, we extend and utilize a recently developed effective gradient-based\nprocedure that allows us to match the embedding of a given text by minimally\nmodifying an image. Using the procedure, we show that we can align the\nembeddings of distinguishable texts to any image through unnoticeable\nadversarial attacks in joint image-text models, revealing that semantically\nunrelated images can have embeddings of identical texts and at the same time\nvisually indistinguishable images can be matched to the embeddings of very\ndifferent texts. Our technique achieves 100\\% success rate when it is applied\nto text datasets and images from multiple sources. Without overcoming the\nvulnerability, multimodal models cannot robustly align inputs from different\nmodalities in a semantically meaningful way. \\textbf{Warning: the text data\nused in this paper are toxic in nature and may be offensive to some readers.}",
      "tldr_zh": "这篇论文揭示了多模态模型（multimodal models）中共享嵌入空间的漏洞，通过一种基于梯度的过程，可以通过最小修改图像来匹配任何文本的嵌入，从而实现对齐任何文本和图像。\n研究者展示了这种技术能以不易察觉的对抗攻击（adversarial attacks）使语义无关的图像对应相同文本嵌入，或视觉相似的图像匹配完全不同的文本，成功率达100%。\n这一发现强调，多模态模型需克服此漏洞，才能在语义上稳健地对齐不同模态的输入；论文警告所用文本数据为毒性性质，可能对读者造成冒犯。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 14 figures. arXiv admin note: substantial text overlap with\n  arXiv:2401.15568, arXiv:2402.08473",
      "pdf_url": "http://arxiv.org/pdf/2407.01157v1",
      "published_date": "2024-07-01 10:25:47 UTC",
      "updated_date": "2024-07-01 10:25:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:32:38.112676"
    },
    {
      "arxiv_id": "2407.01143v1",
      "title": "Are you sure? Analysing Uncertainty Quantification Approaches for Real-world Speech Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Oliver Schrüfer",
        "Manuel Milling",
        "Felix Burkhardt",
        "Florian Eyben",
        "Björn Schuller"
      ],
      "abstract": "Uncertainty Quantification (UQ) is an important building block for the\nreliable use of neural networks in real-world scenarios, as it can be a useful\ntool in identifying faulty predictions. Speech emotion recognition (SER) models\ncan suffer from particularly many sources of uncertainty, such as the ambiguity\nof emotions, Out-of-Distribution (OOD) data or, in general, poor recording\nconditions. Reliable UQ methods are thus of particular interest as in many SER\napplications no prediction is better than a faulty prediction. While the\neffects of label ambiguity on uncertainty are well documented in the\nliterature, we focus our work on an evaluation of UQ methods for SER under\ncommon challenges in real-world application, such as corrupted signals, and the\nabsence of speech. We show that simple UQ methods can already give an\nindication of the uncertainty of a prediction and that training with additional\nOOD data can greatly improve the identification of such signals.",
      "tldr_zh": "这篇论文分析了Uncertainty Quantification (UQ)方法在真实世界Speech Emotion Recognition (SER)中的应用，旨在识别错误预测并处理情感模糊、Out-of-Distribution (OOD)数据以及信号损坏等不确定性来源。研究重点评估了UQ方法在常见挑战（如损坏信号和无语音情况）下的表现，结果显示简单的UQ方法即可提供预测不确定性的有效指示。作者进一步发现，通过使用额外OOD数据进行训练，能显著提升模型对这些问题的识别能力，从而为可靠的SER应用奠定基础。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "accepted for Interspeech 2024, 5 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.01143v1",
      "published_date": "2024-07-01 10:11:08 UTC",
      "updated_date": "2024-07-01 10:11:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:32:49.518964"
    },
    {
      "arxiv_id": "2407.01142v1",
      "title": "Integrated feature analysis for deep learning interpretation and class activation maps",
      "title_zh": "翻译失败",
      "authors": [
        "Yanli Li",
        "Tahereh Hassanzadeh",
        "Denis P. Shamonin",
        "Monique Reijnierse",
        "Annette H. M. van der Helm-van Mil",
        "Berend C. Stoel"
      ],
      "abstract": "Understanding the decisions of deep learning (DL) models is essential for the\nacceptance of DL to risk-sensitive applications. Although methods, like class\nactivation maps (CAMs), give a glimpse into the black box, they do miss some\ncrucial information, thereby limiting its interpretability and merely providing\nthe considered locations of objects. To provide more insight into the models\nand the influence of datasets, we propose an integrated feature analysis\nmethod, which consists of feature distribution analysis and feature\ndecomposition, to look closer into the intermediate features extracted by DL\nmodels. This integrated feature analysis could provide information on\noverfitting, confounders, outliers in datasets, model redundancies and\nprincipal features extracted by the models, and provide distribution\ninformation to form a common intensity scale, which are missing in current CAM\nalgorithms. The integrated feature analysis was applied to eight different\ndatasets for general validation: photographs of handwritten digits, two\ndatasets of natural images and five medical datasets, including skin\nphotography, ultrasound, CT, X-rays and MRIs. The method was evaluated by\ncalculating the consistency between the CAMs average class activation levels\nand the logits of the model. Based on the eight datasets, the correlation\ncoefficients through our method were all very close to 100%, and based on the\nfeature decomposition, 5%-25% of features could generate equally informative\nsaliency maps and obtain the same model performances as using all features.\nThis proves the reliability of the integrated feature analysis. As the proposed\nmethods rely on very few assumptions, this is a step towards better model\ninterpretation and a useful extension to existing CAM algorithms. Codes:\nhttps://github.com/YanliLi27/IFA",
      "tldr_zh": "这篇论文提出了一种集成特征分析方法，用于提升 deep learning (DL) 模型的可解释性，具体包括特征分布分析和特征分解，以弥补现有 class activation maps (CAMs) 仅提供对象位置的局限性。该方法通过分析 DL 模型的中间特征，揭示过拟合、混杂因素、异常值、模型冗余和主要特征的信息，并建立共同的强度尺度。实验在八个数据集（包括手写数字、自然图像和五种医疗图像）上验证，结果显示 CAMs 的平均类激活水平与模型 logits 相关系数接近 100%，且使用 5%-25% 的特征即可生成同样信息丰富的显著性地图和模型性能，从而证明了该方法的可靠性和对 CAMs 算法的扩展价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 11 figures, code available:\n  https://github.com/YanliLi27/IFA This work has been submitted to the IEEE for\n  possible publication",
      "pdf_url": "http://arxiv.org/pdf/2407.01142v1",
      "published_date": "2024-07-01 10:10:57 UTC",
      "updated_date": "2024-07-01 10:10:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:33:02.136745"
    },
    {
      "arxiv_id": "2407.01137v1",
      "title": "An Empirical Comparison of Generative Approaches for Product Attribute-Value Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Kassem Sabeh",
        "Robert Litschko",
        "Mouna Kacimi",
        "Barbara Plank",
        "Johann Gamper"
      ],
      "abstract": "Product attributes are crucial for e-commerce platforms, supporting\napplications like search, recommendation, and question answering. The task of\nProduct Attribute and Value Identification (PAVI) involves identifying both\nattributes and their values from product information. In this paper, we\nformulate PAVI as a generation task and provide, to the best of our knowledge,\nthe most comprehensive evaluation of PAVI so far. We compare three different\nattribute-value generation (AVG) strategies based on fine-tuning\nencoder-decoder models on three datasets. Experiments show that end-to-end AVG\napproach, which is computationally efficient, outperforms other strategies.\nHowever, there are differences depending on model sizes and the underlying\nlanguage model. The code to reproduce all experiments is available at:\nhttps://github.com/kassemsabeh/pavi-avg",
      "tldr_zh": "本文通过实证比较，将产品属性值识别 (PAVI) 任务表述为生成任务，并进行了迄今为止最全面的评估。研究比较了三种基于微调 encoder-decoder 模型的属性值生成 (AVG) 策略，包括端到端 AVG 方法。实验结果显示，端到端 AVG 方法在计算效率上优于其他策略，但其性能会因模型大小和底层语言模型而异。代码已在 GitHub 上提供，供重现实验使用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01137v1",
      "published_date": "2024-07-01 10:02:17 UTC",
      "updated_date": "2024-07-01 10:02:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:33:12.970916"
    },
    {
      "arxiv_id": "2407.01126v1",
      "title": "Investigating the potential of Sparse Mixtures-of-Experts for multi-domain neural machine translation",
      "title_zh": "调查稀疏混合专家模型在多领域神经机器翻译中的潜力",
      "authors": [
        "Nadezhda Chirkova",
        "Vassilina Nikoulina",
        "Jean-Luc Meunier",
        "Alexandre Bérard"
      ],
      "abstract": "We focus on multi-domain Neural Machine Translation, with the goal of\ndeveloping efficient models which can handle data from various domains seen\nduring training and are robust to domains unseen during training. We\nhypothesize that Sparse Mixture-of-Experts (SMoE) models are a good fit for\nthis task, as they enable efficient model scaling, which helps to accommodate a\nvariety of multi-domain data, and allow flexible sharing of parameters between\ndomains, potentially enabling knowledge transfer between similar domains and\nlimiting negative transfer. We conduct a series of experiments aimed at\nvalidating the utility of SMoE for the multi-domain scenario, and find that a\nstraightforward width scaling of Transformer is a simpler and surprisingly more\nefficient approach in practice, and reaches the same performance level as SMoE.\nWe also search for a better recipe for robustness of multi-domain systems,\nhighlighting the importance of mixing-in a generic domain, i.e. Paracrawl, and\nintroducing a simple technique, domain randomization.",
      "tldr_zh": "本文研究了 Sparse Mixtures-of-Experts (SMoE) 在多域 Neural Machine Translation 中的潜力，旨在开发高效模型，能够处理训练中见过的各种域数据，并对未见域数据保持鲁棒性。作者假设 SMoE 通过模型扩展和参数共享促进知识转移，但实验结果显示，简单的 Transformer 宽度扩展更易实现且效率更高，达到与 SMoE 相同的性能水平。此外，研究强调混合通用域（如 Paracrawl）和引入 domain randomization 技术，能显著提升多域系统的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01126v1",
      "published_date": "2024-07-01 09:45:22 UTC",
      "updated_date": "2024-07-01 09:45:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:33:26.603595"
    },
    {
      "arxiv_id": "2407.03374v1",
      "title": "An Outline of Prognostics and Health Management Large Model: Concepts, Paradigms, and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Laifa Tao",
        "Shangyu Li",
        "Haifei Liu",
        "Qixuan Huang",
        "Liang Ma",
        "Guoao Ning",
        "Yiling Chen",
        "Yunlong Wu",
        "Bin Li",
        "Weiwei Zhang",
        "Zhengduo Zhao",
        "Wenchao Zhan",
        "Wenyan Cao",
        "Chao Wang",
        "Hongmei Liu",
        "Jian Ma",
        "Mingliang Suo",
        "Yujie Cheng",
        "Yu Ding",
        "Dengwei Song",
        "Chen Lu"
      ],
      "abstract": "Prognosis and Health Management (PHM), critical for ensuring task completion\nby complex systems and preventing unexpected failures, is widely adopted in\naerospace, manufacturing, maritime, rail, energy, etc. However, PHM's\ndevelopment is constrained by bottlenecks like generalization, interpretation\nand verification abilities. Presently, generative artificial intelligence (AI),\nrepresented by Large Model, heralds a technological revolution with the\npotential to fundamentally reshape traditional technological fields and human\nproduction methods. Its capabilities, including strong generalization,\nreasoning, and generative attributes, present opportunities to address PHM's\nbottlenecks. To this end, based on a systematic analysis of the current\nchallenges and bottlenecks in PHM, as well as the research status and\nadvantages of Large Model, we propose a novel concept and three progressive\nparadigms of Prognosis and Health Management Large Model (PHM-LM) through the\nintegration of the Large Model with PHM. Subsequently, we provide feasible\ntechnical approaches for PHM-LM to bolster PHM's core capabilities within the\nframework of the three paradigms. Moreover, to address core issues confronting\nPHM, we discuss a series of technical challenges of PHM-LM throughout the\nentire process of construction and application. This comprehensive effort\noffers a holistic PHM-LM technical framework, and provides avenues for new PHM\ntechnologies, methodologies, tools, platforms and applications, which also\npotentially innovates design, research & development, verification and\napplication mode of PHM. And furthermore, a new generation of PHM with AI will\nalso capably be realized, i.e., from custom to generalized, from discriminative\nto generative, and from theoretical conditions to practical applications.",
      "tldr_zh": "该论文概述了预知健康管理（PHM）领域的关键挑战，包括泛化、解释和验证能力瓶颈，并探讨了生成式人工智能（Large Model）的优势如何解决这些问题。作者提出PHM-LM（Prognosis and Health Management Large Model）的全新概念和三个渐进范式，通过将Large Model与PHM整合，提供可行的技术方法来增强PHM的核心能力。论文还讨论了PHM-LM在构建和应用过程中的技术挑战，并提供了一个全面的技术框架，旨在创新PHM的技术、方法、工具、平台和应用，实现从定制到泛化、从判别到生成、以及从理论到实际应用的转变。",
      "categories": [
        "cs.AI",
        "cs.SE",
        "cs.SY",
        "eess.SP",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.03374v1",
      "published_date": "2024-07-01 09:37:00 UTC",
      "updated_date": "2024-07-01 09:37:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:33:38.290958"
    },
    {
      "arxiv_id": "2407.01119v2",
      "title": "Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?",
      "title_zh": "翻译失败",
      "authors": [
        "Guillermo Marco",
        "Julio Gonzalo",
        "Ramón del Castillo",
        "María Teresa Mateo Girona"
      ],
      "abstract": "It has become routine to report research results where Large Language Models\n(LLMs) outperform average humans in a wide range of language-related tasks, and\ncreative text writing is no exception. It seems natural, then, to raise the\nbid: Are LLMs ready to compete in creative writing skills with a top (rather\nthan average) novelist? To provide an initial answer for this question, we have\ncarried out a contest between Patricio Pron (an awarded novelist, considered\none of the best of his generation) and GPT-4 (one of the top performing LLMs),\nin the spirit of AI-human duels such as DeepBlue vs Kasparov and AlphaGo vs Lee\nSidol. We asked Pron and GPT-4 to provide thirty titles each, and then to write\nshort stories for both their titles and their opponent's. Then, we prepared an\nevaluation rubric inspired by Boden's definition of creativity, and we\ncollected 5,400 manual assessments provided by literature critics and scholars.\nThe results of our experimentation indicate that LLMs are still far from\nchallenging a top human creative writer, and that reaching such level of\nautonomous creative writing skills probably cannot be reached simply with\nlarger language models.",
      "tldr_zh": "这篇论文探讨大型语言模型 (LLMs) 是否能与世界级小说家在创意写作中竞争，通过组织 Patricio Pron (一位获奖作家) 与 GPT-4 的对决来评估。研究方法包括让双方各提供30个标题，并为各自和对方的标题撰写短故事，然后使用基于 Boden 创意定义的评分标准，由文学评论家和学者进行5,400次手动评估。结果显示，LLMs 仍远不能挑战顶尖人类作家，单纯通过更大规模的模型可能无法实现自主创意写作水平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.01119v2",
      "published_date": "2024-07-01 09:28:58 UTC",
      "updated_date": "2024-10-28 16:32:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:33:49.547231"
    },
    {
      "arxiv_id": "2407.01111v1",
      "title": "Proximity Matters: Local Proximity Preserved Balancing for Treatment Effect Estimation",
      "title_zh": "邻近性很重要：用于治疗效果估计的局部邻近性保留平衡",
      "authors": [
        "Hao Wang",
        "Zhichao Chen",
        "Yuan Shen",
        "Jiajun Fan",
        "Zhaoran Liu",
        "Degui Yang",
        "Xinggao Liu",
        "Haoxuan Li"
      ],
      "abstract": "Heterogeneous treatment effect (HTE) estimation from observational data poses\nsignificant challenges due to treatment selection bias. Existing methods\naddress this bias by minimizing distribution discrepancies between treatment\ngroups in latent space, focusing on global alignment. However, the fruitful\naspect of local proximity, where similar units exhibit similar outcomes, is\noften overlooked. In this study, we propose Proximity-aware Counterfactual\nRegression (PCR) to exploit proximity for representation balancing within the\nHTE estimation context. Specifically, we introduce a local proximity\npreservation regularizer based on optimal transport to depict the local\nproximity in discrepancy calculation. Furthermore, to overcome the curse of\ndimensionality that renders the estimation of discrepancy ineffective,\nexacerbated by limited data availability for HTE estimation, we develop an\ninformative subspace projector, which trades off minimal distance precision for\nimproved sample complexity. Extensive experiments demonstrate that PCR\naccurately matches units across different treatment groups, effectively\nmitigates treatment selection bias, and significantly outperforms competitors.\nCode is available at https://anonymous.4open.science/status/ncr-B697.",
      "tldr_zh": "本研究针对异质治疗效应 (HTE) 估计中的治疗选择偏差问题，指出现有方法仅关注全局对齐而忽略局部邻近性（local proximity），从而提出 Proximity-aware Counterfactual Regression (PCR) 方法。PCR 通过引入基于 optimal transport 的局部邻近保留正则化器，在差异计算中强调相近单位的相似性，同时开发信息子空间投影器来缓解高维灾难和数据限制问题。实验结果显示，PCR 能够更准确地匹配不同治疗组的单位，有效减轻偏差，并显著优于竞争方法。代码可在 https://anonymous.4open.science/status/ncr-B697 获得。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Code is available at https://anonymous.4open.science/status/ncr-B697",
      "pdf_url": "http://arxiv.org/pdf/2407.01111v1",
      "published_date": "2024-07-01 09:20:26 UTC",
      "updated_date": "2024-07-01 09:20:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:34:12.795868"
    },
    {
      "arxiv_id": "2407.01110v1",
      "title": "SecGenAI: Enhancing Security of Cloud-based Generative AI Applications within Australian Critical Technologies of National Interest",
      "title_zh": "SecGenAI：在澳大利亚国家利益关键技术中",
      "authors": [
        "Christoforus Yoga Haryanto",
        "Minh Hieu Vu",
        "Trung Duc Nguyen",
        "Emily Lomempow",
        "Yulia Nurliana",
        "Sona Taheri"
      ],
      "abstract": "The rapid advancement of Generative AI (GenAI) technologies offers\ntransformative opportunities within Australia's critical technologies of\nnational interest while introducing unique security challenges. This paper\npresents SecGenAI, a comprehensive security framework for cloud-based GenAI\napplications, with a focus on Retrieval-Augmented Generation (RAG) systems.\nSecGenAI addresses functional, infrastructure, and governance requirements,\nintegrating end-to-end security analysis to generate specifications emphasizing\ndata privacy, secure deployment, and shared responsibility models. Aligned with\nAustralian Privacy Principles, AI Ethics Principles, and guidelines from the\nAustralian Cyber Security Centre and Digital Transformation Agency, SecGenAI\nmitigates threats such as data leakage, adversarial attacks, and model\ninversion. The framework's novel approach combines advanced machine learning\ntechniques with robust security measures, ensuring compliance with Australian\nregulations while enhancing the reliability and trustworthiness of GenAI\nsystems. This research contributes to the field of intelligent systems by\nproviding actionable strategies for secure GenAI implementation in industry,\nfostering innovation in AI applications, and safeguarding national interests.",
      "tldr_zh": "这篇论文提出了 SecGenAI，这是一个全面的安全框架，旨在增强基于云的 Generative AI (GenAI) 应用的安全性，特别是针对澳大利亚国家关键技术的 Retrieval-Augmented Generation (RAG) 系统。SecGenAI 通过整合端到端安全分析，涵盖功能、基础设施和治理要求，确保数据隐私、安全部署以及共享责任模型，并符合澳大利亚隐私原则、AI 伦理原则以及相关机构的指南。框架结合高级机器学习技术和稳健的安全措施，缓解了数据泄露、敌对攻击和模型反转等威胁，提高了 GenAI 系统的可靠性和可信度。该研究为行业提供了可操作策略，促进 AI 创新并保护国家利益。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "10 pages, 4 figures, 9 tables, submitted to the 2024 11th\n  International Conference on Soft Computing & Machine Intelligence (ISCMI\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.01110v1",
      "published_date": "2024-07-01 09:19:50 UTC",
      "updated_date": "2024-07-01 09:19:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:34:27.280945"
    },
    {
      "arxiv_id": "2407.01093v1",
      "title": "IBSEN: Director-Actor Agent Collaboration for Controllable and Interactive Drama Script Generation",
      "title_zh": "IBSEN：导演-演员代理协作用于可控和交互式戏剧脚本生成",
      "authors": [
        "Senyu Han",
        "Lu Chen",
        "Li-Min Lin",
        "Zhengshan Xu",
        "Kai Yu"
      ],
      "abstract": "Large language models have demonstrated their capabilities in storyline\ncreation and human-like character role-playing. Current language model agents\nmainly focus on reasonable behaviors from the level of individuals, and their\nbehaviors might be hard to constraint on the level of the whole storyline. In\nthis paper we introduce IBSEN, a director-actor coordinate agent framework that\ngenerates drama scripts and makes the plot played by agents more controllable.\nThe director agent writes plot outlines that the user desires to see, instructs\nthe actor agents to role-play their characters, and reschedules the plot when\nhuman players participate in the scenario to ensure the plot is progressing\ntowards the objective. To evaluate the framework, we create a novel drama plot\nthat involves several actor agents and check the interactions between them\nunder the instruction of the director agent. Evaluation results show that our\nframework could generate complete, diverse drama scripts from only a rough\noutline of plot objectives, meanwhile maintaining the characteristics of\ncharacters in the drama. Our codes and prompts are available at\nhttps://github.com/OpenDFM/ibsen.",
      "tldr_zh": "本研究提出 IBSEN 框架，这是一个 director-actor 代理协作系统，用于生成可控且互动的戏剧脚本，解决现有 large language models 代理在整体故事情节层面控制不足的问题。框架中，director agent 负责编写情节大纲、指导 actor agents 进行角色扮演，并在人类参与时重新安排情节以确保目标推进。通过实验评估，IBSEN 能够从粗略的情节目标生成完整、多样的戏剧脚本，同时保持角色的特性，并提供了开源代码以供进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2407.01093v1",
      "published_date": "2024-07-01 08:49:57 UTC",
      "updated_date": "2024-07-01 08:49:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:34:37.837944"
    },
    {
      "arxiv_id": "2407.01092v1",
      "title": "Kolmogorov-Arnold Convolutions: Design Principles and Empirical Studies",
      "title_zh": "Kolmogorov-Arnold 卷积：设计原则和实证研究",
      "authors": [
        "Ivan Drokin"
      ],
      "abstract": "The emergence of Kolmogorov-Arnold Networks (KANs) has sparked significant\ninterest and debate within the scientific community. This paper explores the\napplication of KANs in the domain of computer vision (CV). We examine the\nconvolutional version of KANs, considering various nonlinearity options beyond\nsplines, such as Wavelet transforms and a range of polynomials. We propose a\nparameter-efficient design for Kolmogorov-Arnold convolutional layers and a\nparameter-efficient finetuning algorithm for pre-trained KAN models, as well as\nKAN convolutional versions of self-attention and focal modulation layers. We\nprovide empirical evaluations conducted on MNIST, CIFAR10, CIFAR100, Tiny\nImageNet, ImageNet1k, and HAM10000 datasets for image classification tasks.\nAdditionally, we explore segmentation tasks, proposing U-Net-like architectures\nwith KAN convolutions, and achieving state-of-the-art results on BUSI, GlaS,\nand CVC datasets. We summarized all of our findings in a preliminary design\nguide of KAN convolutional models for computer vision tasks. Furthermore, we\ninvestigate regularization techniques for KANs. All experimental code and\nimplementations of convolutional layers and models, pre-trained on ImageNet1k\nweights are available on GitHub via this\nhttps://github.com/IvanDrokin/torch-conv-kan",
      "tldr_zh": "本研究探索了Kolmogorov-Arnold Networks (KANs)在计算机视觉领域的应用，特别关注KANs的卷积版本，并测试了各种非线性选项，如Wavelet transforms和polynomials，以设计参数高效的卷积层和微调算法。论文还提出了KAN卷积版本的自-attention和focal modulation层，并在MNIST、CIFAR10等数据集上进行图像分类实验，以及在BUSI、GlaS和CVC数据集上构建U-Net-like架构实现分割任务的state-of-the-art结果。最终，研究总结了KAN卷积模型的设计指南，并提供了正则化技术及开源代码（GitHub链接）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01092v1",
      "published_date": "2024-07-01 08:49:33 UTC",
      "updated_date": "2024-07-01 08:49:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:34:50.578974"
    },
    {
      "arxiv_id": "2407.01080v2",
      "title": "Face4RAG: Factual Consistency Evaluation for Retrieval Augmented Generation in Chinese",
      "title_zh": "Face4RAG：针对中文检索增强生成的事实一致性评估",
      "authors": [
        "Yunqi Xu",
        "Tianchi Cai",
        "Jiyan Jiang",
        "Xierui Song"
      ],
      "abstract": "The prevailing issue of factual inconsistency errors in conventional\nRetrieval Augmented Generation (RAG) motivates the study of Factual Consistency\nEvaluation (FCE). Despite the various FCE methods proposed earlier, these\nmethods are evaluated on datasets generated by specific Large Language Models\n(LLMs). Without a comprehensive benchmark, it remains unexplored how these FCE\nmethods perform on other LLMs with different error distributions or even unseen\nerror types, as these methods may fail to detect the error types generated by\nother LLMs. To fill this gap, in this paper, we propose the first comprehensive\nFCE benchmark \\emph{Face4RAG} for RAG independent of the underlying LLM. Our\nbenchmark consists of a synthetic dataset built upon a carefully designed\ntypology for factuality inconsistency error and a real-world dataset\nconstructed from six commonly used LLMs, enabling evaluation of FCE methods on\nspecific error types or real-world error distributions. On the proposed\nbenchmark, we discover the failure of existing FCE methods to detect the\nlogical fallacy, which refers to a mismatch of logic structures between the\nanswer and the retrieved reference. To fix this issue, we further propose a new\nmethod called \\emph{L-Face4RAG} with two novel designs of logic-preserving\nanswer decomposition and fact-logic FCE. Extensive experiments show L-Face4RAG\nsubstantially outperforms previous methods for factual inconsistency detection\non a wide range of tasks, notably beyond the RAG task from which it is\noriginally motivated. Both the benchmark and our proposed method are publicly\navailable.\\footnote{\\url{https://huggingface.co/datasets/yq27/Face4RAG}\\label{link_face4rag}}",
      "tldr_zh": "这篇论文针对Retrieval Augmented Generation (RAG)中的事实不一致错误，提出了第一个独立于底层Large Language Models (LLMs)的全面Factual Consistency Evaluation (FCE)基准Face4RAG。基准包括一个基于精心设计的错误类型学的合成数据集和一个从六个常用LLMs构建的真实数据集，用于评估FCE方法在特定错误类型（如logical fallacy）或真实错误分布上的性能。论文发现现有FCE方法无法有效检测logical fallacy，即答案与检索参考之间的逻辑结构不匹配，因此提出新方法L-Face4RAG，通过logic-preserving answer decomposition和fact-logic FCE设计来提升检测准确性。实验结果显示L-Face4RAG在广泛任务上显著优于现有方法，并已公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01080v2",
      "published_date": "2024-07-01 08:35:04 UTC",
      "updated_date": "2024-07-03 12:49:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:35:03.831844"
    },
    {
      "arxiv_id": "2407.01079v3",
      "title": "On Statistical Rates and Provably Efficient Criteria of Latent Diffusion Transformers (DiTs)",
      "title_zh": "翻译失败",
      "authors": [
        "Jerry Yao-Chieh Hu",
        "Weimin Wu",
        "Zhao Song",
        "Han Liu"
      ],
      "abstract": "We investigate the statistical and computational limits of latent Diffusion\nTransformers (DiTs) under the low-dimensional linear latent space assumption.\nStatistically, we study the universal approximation and sample complexity of\nthe DiTs score function, as well as the distribution recovery property of the\ninitial data. Specifically, under mild data assumptions, we derive an\napproximation error bound for the score network of latent DiTs, which is\nsub-linear in the latent space dimension. Additionally, we derive the\ncorresponding sample complexity bound and show that the data distribution\ngenerated from the estimated score function converges toward a proximate area\nof the original one. Computationally, we characterize the hardness of both\nforward inference and backward computation of latent DiTs, assuming the Strong\nExponential Time Hypothesis (SETH). For forward inference, we identify\nefficient criteria for all possible latent DiTs inference algorithms and\nshowcase our theory by pushing the efficiency toward almost-linear time\ninference. For backward computation, we leverage the low-rank structure within\nthe gradient computation of DiTs training for possible algorithmic speedup.\nSpecifically, we show that such speedup achieves almost-linear time latent DiTs\ntraining by casting the DiTs gradient as a series of chained low-rank\napproximations with bounded error. Under the low-dimensional assumption, we\nshow that the statistical rates and the computational efficiency are all\ndominated by the dimension of the subspace, suggesting that latent DiTs have\nthe potential to bypass the challenges associated with the high dimensionality\nof initial data.",
      "tldr_zh": "本文探讨了 Latent Diffusion Transformers (DiTs) 在低维线性潜在空间下的统计和计算极限。统计上，论文推导了 DiTs 评分函数的通用逼近误差边界（与潜在空间维度呈亚线性关系）、样本复杂度边界，并证明了从估计评分函数生成的分布可收敛到原始数据的附近区域。计算上，假设 Strong Exponential Time Hypothesis (SETH)，论文识别了高效的前向推理标准（实现几乎线性时间）和后向计算加速方法，通过利用梯度中的低秩结构，将训练过程优化为几乎线性时间。总体而言，这些发现表明 DiTs 的统计速率和计算效率主要受子空间维度主导，有潜力规避高维数据带来的挑战。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "Accepted at NeurIPS 2024. v3 updated to camera-ready version with\n  many typos fixed; v2 fixed typos, added Fig. 1 and added clarifications",
      "pdf_url": "http://arxiv.org/pdf/2407.01079v3",
      "published_date": "2024-07-01 08:34:40 UTC",
      "updated_date": "2024-10-31 16:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:35:15.058134"
    },
    {
      "arxiv_id": "2407.01067v1",
      "title": "Human-like object concept representations emerge naturally in multimodal large language models",
      "title_zh": "翻译失败",
      "authors": [
        "Changde Du",
        "Kaicheng Fu",
        "Bincheng Wen",
        "Yi Sun",
        "Jie Peng",
        "Wei Wei",
        "Ying Gao",
        "Shengpei Wang",
        "Chuncheng Zhang",
        "Jinpeng Li",
        "Shuang Qiu",
        "Le Chang",
        "Huiguang He"
      ],
      "abstract": "The conceptualization and categorization of natural objects in the human mind\nhave long intrigued cognitive scientists and neuroscientists, offering crucial\ninsights into human perception and cognition. Recently, the rapid development\nof Large Language Models (LLMs) has raised the attractive question of whether\nthese models can also develop human-like object representations through\nexposure to vast amounts of linguistic and multimodal data. In this study, we\ncombined behavioral and neuroimaging analysis methods to uncover how the object\nconcept representations in LLMs correlate with those of humans. By collecting\nlarge-scale datasets of 4.7 million triplet judgments from LLM and Multimodal\nLLM (MLLM), we were able to derive low-dimensional embeddings that capture the\nunderlying similarity structure of 1,854 natural objects. The resulting\n66-dimensional embeddings were found to be highly stable and predictive, and\nexhibited semantic clustering akin to human mental representations.\nInterestingly, the interpretability of the dimensions underlying these\nembeddings suggests that LLM and MLLM have developed human-like conceptual\nrepresentations of natural objects. Further analysis demonstrated strong\nalignment between the identified model embeddings and neural activity patterns\nin many functionally defined brain ROIs (e.g., EBA, PPA, RSC and FFA). This\nprovides compelling evidence that the object representations in LLMs, while not\nidentical to those in the human, share fundamental commonalities that reflect\nkey schemas of human conceptual knowledge. This study advances our\nunderstanding of machine intelligence and informs the development of more\nhuman-like artificial cognitive systems.",
      "tldr_zh": "本文研究探讨了大型语言模型(LLMs)和多模态LLMs(MLLMs)是否能通过海量数据自然发展出类似人类的物体概念表示。研究者通过收集470万三元组判断数据集，提取1,854个自然物体的66维低维嵌入，这些嵌入显示出稳定的语义聚类，与人类心理表示高度相似。进一步的神经成像分析发现，模型嵌入与大脑特定区域（如EBA、PPA、RSC和FFA）的神经活动模式强烈一致，证明了LLMs在物体表示上与人类概念知识的根本共同点。该研究深化了对机器智能的理解，并为构建更人性化的AI认知系统提供了指导。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01067v1",
      "published_date": "2024-07-01 08:17:19 UTC",
      "updated_date": "2024-07-01 08:17:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:35:26.179703"
    },
    {
      "arxiv_id": "2407.01050v1",
      "title": "Evolutionary Morphology Towards Overconstrained Locomotion via Large-Scale, Multi-Terrain Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yenan Chen",
        "Chuye Zhang",
        "Pengxi Gu",
        "Jianuo Qiu",
        "Jiayi Yin",
        "Nuofan Qiu",
        "Guojing Huang",
        "Bangchao Huang",
        "Zishang Zhang",
        "Hui Deng",
        "Wei Zhang",
        "Fang Wan",
        "Chaoyang Song"
      ],
      "abstract": "While the animals' Fin-to-Limb evolution has been well-researched in biology,\nsuch morphological transformation remains under-adopted in the modern design of\nadvanced robotic limbs. This paper investigates a novel class of\noverconstrained locomotion from a design and learning perspective inspired by\nevolutionary morphology, aiming to integrate the concept of `intelligent design\nunder constraints' - hereafter referred to as constraint-driven design\nintelligence - in developing modern robotic limbs with superior energy\nefficiency. We propose a 3D-printable design of robotic limbs parametrically\nreconfigurable as a classical planar 4-bar linkage, an overconstrained Bennett\nlinkage, and a spherical 4-bar linkage. These limbs adopt a co-axial actuation,\nidentical to the modern legged robot platforms, with the added capability of\nupgrading into a wheel-legged system. Then, we implemented a large-scale,\nmulti-terrain deep reinforcement learning framework to train these\nreconfigurable limbs for a comparative analysis of overconstrained locomotion\nin energy efficiency. Results show that the overconstrained limbs exhibit more\nefficient locomotion than planar limbs during forward and sideways walking over\ndifferent terrains, including floors, slopes, and stairs, with or without\nrandom noises, by saving at least 22% mechanical energy in completing the\ntraverse task, with the spherical limbs being the least efficient. It also\nachieves the highest average speed of 0.85 meters per second on flat terrain,\nwhich is 20% faster than the planar limbs. This study paves the path for an\nexciting direction for future research in overconstrained robotics leveraging\nevolutionary morphology and reconfigurable mechanism intelligence when combined\nwith state-of-the-art methods in deep reinforcement learning.",
      "tldr_zh": "本研究受动物Fin-to-Limb进化的启发，提出了一种过constrained locomotion的机器人肢体设计框架，旨在通过constraint-driven design intelligence提升能量效率。该框架包括一个可参数化重配置的3D打印肢体（如经典平面4-bar linkage、overconstrained Bennett linkage和spherical 4-bar linkage），并采用同轴驱动以支持轮腿系统。然后，利用大规模、多地形deep reinforcement learning框架训练这些肢体，结果显示过constrained肢体在地板、坡道和楼梯等地形上的前进和侧向行走中，至少节省22%的机械能，且最高平均速度达0.85米/秒，比平面肢体快20%。此研究为未来结合进化形态学、可重配置机制和deep reinforcement learning的过constrained机器人领域开辟了新路径。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "13 pages, 5 figures, Accepted and Presented at ReMAR2024",
      "pdf_url": "http://arxiv.org/pdf/2407.01050v1",
      "published_date": "2024-07-01 07:57:01 UTC",
      "updated_date": "2024-07-01 07:57:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:35:49.265249"
    },
    {
      "arxiv_id": "2407.01046v2",
      "title": "FRoG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yiyuan Li",
        "Shichao Sun",
        "Pengfei Liu"
      ],
      "abstract": "Fuzzy reasoning is vital due to the frequent use of imprecise information in\ndaily contexts. However, the ability of current large language models (LLMs) to\nhandle such reasoning remains largely uncharted. In this paper, we introduce a\nnew benchmark, FRoG, for fuzzy reasoning, featuring real-world mathematical\nword problems that incorporate generalized quantifiers. Our experimental\nfindings reveal that fuzzy reasoning continues to pose significant challenges\nfor LLMs. Moreover, we find that existing methods designed to enhance reasoning\ndo not consistently improve performance in tasks involving fuzzy logic.\nAdditionally, our results show an inverse scaling effect in the performance of\nLLMs on FRoG. Interestingly, we also demonstrate that strong mathematical\nreasoning skills are not necessarily indicative of success on our benchmark.",
      "tldr_zh": "本研究引入了 FRoG 基准，用于评估大型语言模型 (LLMs) 在模糊推理和广义量词 (generalized quantifiers) 处理方面的能力，该基准包含真实世界的数学文字问题。实验结果显示，LLMs 在模糊推理任务上仍面临重大挑战，且现有的增强推理方法无法一致提升性能。论文还发现，LLMs 在 FRoG 上的表现存在逆向缩放效应 (inverse scaling effect)，并且强大的数学推理技能并不直接转化为基准成功。总的来说，这为理解 LLMs 的推理局限性提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2407.01046v2",
      "published_date": "2024-07-01 07:56:14 UTC",
      "updated_date": "2024-07-03 03:37:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:35:49.638521"
    },
    {
      "arxiv_id": "2407.01026v1",
      "title": "Augmenting Document-level Relation Extraction with Efficient Multi-Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangyu Lin",
        "Weijia Jia",
        "Zhiguo Gong"
      ],
      "abstract": "Despite its popularity in sentence-level relation extraction, distantly\nsupervised data is rarely utilized by existing work in document-level relation\nextraction due to its noisy nature and low information density. Among its\ncurrent applications, distantly supervised data is mostly used as a whole for\npertaining, which is of low time efficiency. To fill in the gap of efficient\nand robust utilization of distantly supervised training data, we propose\nEfficient Multi-Supervision for document-level relation extraction, in which we\nfirst select a subset of informative documents from the massive dataset by\ncombining distant supervision with expert supervision, then train the model\nwith Multi-Supervision Ranking Loss that integrates the knowledge from multiple\nsources of supervision to alleviate the effects of noise. The experiments\ndemonstrate the effectiveness of our method in improving the model performance\nwith higher time efficiency than existing baselines.",
      "tldr_zh": "该论文针对文档级关系抽取（document-level relation extraction）中的问题，提出了一种高效的多监督方法，以更好地利用远端监督（distant supervision）数据，该数据因噪声大和信息密度低而被以往工作忽略。方法首先通过结合远端监督和专家监督（expert supervision）从大量数据中选择信息丰富的文档子集，然后使用 Multi-Supervision Ranking Loss 训练模型，整合多种监督来源以减轻噪声影响。实验结果显示，该方法显著提高了模型性能，同时比现有基线更高效。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01026v1",
      "published_date": "2024-07-01 07:22:32 UTC",
      "updated_date": "2024-07-01 07:22:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:36:02.186021"
    },
    {
      "arxiv_id": "2407.01003v5",
      "title": "Embedded Visual Prompt Tuning",
      "title_zh": "嵌入式视觉",
      "authors": [
        "Wenqiang Zu",
        "Shenghao Xie",
        "Qing Zhao",
        "Guoqi Li",
        "Lei Ma"
      ],
      "abstract": "Foundation models pre-trained on large-scale data have been widely witnessed\nto achieve success in various natural imaging downstream tasks.\nParameter-efficient fine-tuning (PEFT) methods aim to adapt foundation models\nto new domains by updating only a small portion of parameters in order to\nreduce computational overhead. However, the effectiveness of these PEFT\nmethods, especially in cross-domain few-shot scenarios, e.g., medical image\nanalysis, has not been fully explored. In this work, we facilitate the study of\nthe performance of PEFT when adapting foundation models to medical image\nclassification tasks. Furthermore, to alleviate the limitations of prompt\nintroducing ways and approximation capabilities on Transformer architectures of\nmainstream prompt tuning methods, we propose the Embedded Prompt Tuning (EPT)\nmethod by embedding prompt tokens into the expanded channels. We also find that\nthere are anomalies in the feature space distribution of foundation models\nduring pre-training process, and prompt tuning can help mitigate this negative\nimpact. To explain this phenomenon, we also introduce a novel perspective to\nunderstand prompt tuning: Prompt tuning is a distribution calibrator. And we\nsupport it by analyzing patch-wise scaling and feature separation operations\ncontained in EPT. Our experiments show that EPT outperforms several\nstate-of-the-art fine-tuning methods by a significant margin on few-shot\nmedical image classification tasks, and completes the fine-tuning process\nwithin highly competitive time, indicating EPT is an effective PEFT method. The\nsource code is available at github.com/zuwenqiang/EPT.",
      "tldr_zh": "该研究探讨了参数高效微调(PEFT)方法在适应视觉基础模型至医疗图像分类等跨域少样本任务中的表现，并提出Embedded Prompt Tuning (EPT)方法，通过将提示标记嵌入扩展通道中来提升提示调优的效能和近似能力。论文发现基础模型在特征空间分布中存在异常现象，并将prompt tuning视为一种分布校准器，通过EPT中的patch-wise scaling和feature separation操作来缓解这一问题。实验结果显示，EPT在少样本医疗图像分类任务上显著优于现有微调方法，同时保持高效的微调时间，证明其作为PEFT的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01003v5",
      "published_date": "2024-07-01 06:35:53 UTC",
      "updated_date": "2025-03-21 13:38:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:36:13.925755"
    },
    {
      "arxiv_id": "2407.01001v1",
      "title": "Flood Prediction Using Classical and Quantum Machine Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Marek Grzesiak",
        "Param Thakkar"
      ],
      "abstract": "This study investigates the potential of quantum machine learning to improve\nflood forecasting we focus on daily flood events along Germany's Wupper River\nin 2023 our approach combines classical machine learning techniques with QML\ntechniques this hybrid model leverages quantum properties like superposition\nand entanglement to achieve better accuracy and efficiency classical and QML\nmodels are compared based on training time accuracy and scalability results\nshow that QML models offer competitive training times and improved prediction\naccuracy this research signifies a step towards utilizing quantum technologies\nfor climate change adaptation we emphasize collaboration and continuous\ninnovation to implement this model in real-world flood management ultimately\nenhancing global resilience against floods",
      "tldr_zh": "这篇论文探讨了量子机器学习(QML)模型在洪水预测中的潜力，焦点是2023年德国Wupper河的日常洪水事件，通过结合经典机器学习和QML技术构建混合模型，利用量子特性如叠加和纠缠来提升准确性和效率。研究比较了两种模型在训练时间、准确性和可扩展性方面的表现，结果显示QML模型提供了竞争性的训练时间和更高的预测准确性。该工作标志着量子技术在气候变化适应中的应用一步，强调通过合作和创新将其整合到实际洪水管理中，以增强全球抗洪韧性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.geo-ph",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01001v1",
      "published_date": "2024-07-01 06:31:41 UTC",
      "updated_date": "2024-07-01 06:31:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:36:26.303471"
    },
    {
      "arxiv_id": "2407.00993v1",
      "title": "Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Shihan Deng",
        "Weikai Xu",
        "Hongda Sun",
        "Wei Liu",
        "Tao Tan",
        "Jianfeng Liu",
        "Ang Li",
        "Jian Luan",
        "Bin Wang",
        "Rui Yan",
        "Shuo Shang"
      ],
      "abstract": "With the remarkable advancements of large language models (LLMs), LLM-based\nagents have become a research hotspot in human-computer interaction. However,\nthere is a scarcity of benchmarks available for LLM-based mobile agents.\nBenchmarking these agents generally faces three main challenges: (1) The\ninefficiency of UI-only operations imposes limitations to task evaluation. (2)\nSpecific instructions within a singular application lack adequacy for assessing\nthe multi-dimensional reasoning and decision-making capacities of LLM mobile\nagents. (3) Current evaluation metrics are insufficient to accurately assess\nthe process of sequential actions. To this end, we propose Mobile-Bench, a\nnovel benchmark for evaluating the capabilities of LLM-based mobile agents.\nFirst, we expand conventional UI operations by incorporating 103 collected APIs\nto accelerate the efficiency of task completion. Subsequently, we collect\nevaluation data by combining real user queries with augmentation from LLMs. To\nbetter evaluate different levels of planning capabilities for mobile agents,\nour data is categorized into three distinct groups: SAST, SAMT, and MAMT,\nreflecting varying levels of task complexity. Mobile-Bench comprises 832 data\nentries, with more than 200 tasks specifically designed to evaluate multi-APP\ncollaboration scenarios. Furthermore, we introduce a more accurate evaluation\nmetric, named CheckPoint, to assess whether LLM-based mobile agents reach\nessential points during their planning and reasoning steps.",
      "tldr_zh": "本文提出 Mobile-Bench，一种新型基准，用于评估 LLM-based mobile agents 的能力，以解决现有评估面临的挑战，如 UI-only 操作效率低、单一应用指令不足以及顺序动作评估不准等问题。该基准通过整合 103 个 APIs 扩展传统 UI 操作，并结合真实用户查询和 LLM 增强生成 832 条数据，分类为 SAST、SAMT 和 MAMT 三级任务，以覆盖不同复杂度的多维推理和多-APP 协作场景。此外，引入 CheckPoint 指标来精确评估代理在规划和推理过程中的关键点，从而提升评估的准确性和全面性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00993v1",
      "published_date": "2024-07-01 06:10:01 UTC",
      "updated_date": "2024-07-01 06:10:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:36:38.711850"
    },
    {
      "arxiv_id": "2407.00984v1",
      "title": "Individual brain parcellation: Review of methods, validations and applications",
      "title_zh": "个体脑区划分：方法、验证和应用的综述",
      "authors": [
        "Chengyi Li",
        "Shan Yu",
        "Yue Cui"
      ],
      "abstract": "Individual brains vary greatly in morphology, connectivity and organization.\nThe applicability of group-level parcellations is limited by the rapid\ndevelopment of precision medicine today because they do not take into account\nthe variation of parcels at the individual level. Accurate mapping of brain\nfunctional regions at the individual level is pivotal for a comprehensive\nunderstanding of the variations in brain function and behaviors, early and\nprecise identification of brain abnormalities, as well as personalized\ntreatments for neuropsychiatric disorders. With the development of neuroimaging\nand machine learning techniques, studies on individual brain parcellation are\nbooming. In this paper, we offer an overview of recent advances in the\nmethodologies of individual brain parcellation, including optimization- and\nlearning-based methods. Comprehensive evaluation metrics to validate individual\nbrain mapping have been introduced. We also review the studies of how\nindividual brain mapping promotes neuroscience research and clinical medicine.\nFinally, we summarize the major challenges and important future directions of\nindividualized brain parcellation. Collectively, we intend to offer a thorough\noverview of individual brain parcellation methods, validations, and\napplications, along with highlighting the current challenges that call for an\nurgent demand for integrated platforms that integrate datasets, methods, and\nvalidations.",
      "tldr_zh": "这篇论文综述了individual brain parcellation的方法、验证和应用，强调了个体大脑在形态、连通性和组织上的显著差异，使得群体级划分无法满足精准医学的需求。论文介绍了基于优化和基于machine learning的脑区划分方法，并讨论了全面的评估指标，如准确性映射和功能变异分析，以验证这些方法的有效性。在应用方面，individual brain parcellation有助于深入理解脑功能变异、早期识别脑部异常以及个性化治疗神经精神障碍，同时推动神经科学研究和临床医学的发展。最后，论文总结了当前挑战，如数据整合和平台需求，并指出了未来方向，包括构建整合数据集、方法和验证的综合平台。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "15 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.00984v1",
      "published_date": "2024-07-01 05:48:05 UTC",
      "updated_date": "2024-07-01 05:48:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:37:01.247136"
    },
    {
      "arxiv_id": "2407.00980v1",
      "title": "Acceleration method for generating perception failure scenarios based on editing Markov process",
      "title_zh": "基于编辑Markov过程的感知失败场景生成加速方法",
      "authors": [
        "Canjie Cai"
      ],
      "abstract": "With the rapid advancement of autonomous driving technology, self-driving\ncars have become a central focus in the development of future transportation\nsystems. Scenario generation technology has emerged as a crucial tool for\ntesting and verifying the safety performance of autonomous driving systems.\nCurrent research in scenario generation primarily focuses on open roads such as\nhighways, with relatively limited studies on underground parking garages. The\nunique structural constraints, insufficient lighting, and high-density\nobstacles in underground parking garages impose greater demands on the\nperception systems, which are critical to autonomous driving technology.\n  This study proposes an accelerated generation method for perception failure\nscenarios tailored to the underground parking garage environment, aimed at\ntesting and improving the safety performance of autonomous vehicle (AV)\nperception algorithms in such settings. The method presented in this paper\ngenerates an intelligent testing environment with a high density of perception\nfailure scenarios by learning the interactions between background vehicles\n(BVs) and autonomous vehicles (AVs) within perception failure scenarios.\nFurthermore, this method edits the Markov process within the perception failure\nscenario data to increase the density of critical information in the training\ndata, thereby optimizing the learning and generation of perception failure\nscenarios. A simulation environment for an underground parking garage was\ndeveloped using the Carla and Vissim platforms, with Bevfusion employed as the\nperception algorithm for testing. The study demonstrates that this method can\ngenerate an intelligent testing environment with a high density of perception\nfailure scenarios and enhance the safety performance of perception algorithms\nwithin this experimental setup.",
      "tldr_zh": "本文提出了一种基于编辑Markov过程的加速方法，用于生成地下停车场的感知失败场景，旨在测试和提升自动驾驶车辆（AVs）的感知算法安全性能，以应对该环境下的结构约束、光线不足和高密度障碍等挑战。该方法通过学习背景车辆（BVs）和AVs之间的互动，编辑Markov过程以增加训练数据中关键信息的密度，从而高效优化感知失败场景的学习和生成。在使用Carla和Vissim平台构建的模拟环境中，实验采用Bevfusion作为感知算法，结果显示该方法成功创建了高密度感知失败场景，并显著提高了感知算法的安全性能。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00980v1",
      "published_date": "2024-07-01 05:33:48 UTC",
      "updated_date": "2024-07-01 05:33:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:37:03.436453"
    },
    {
      "arxiv_id": "2407.00978v2",
      "title": "Hybrid RAG-empowered Multi-modal LLM for Secure Data Management in Internet of Medical Things: A Diffusion-based Contract Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Su",
        "Jinbo Wen",
        "Jiawen Kang",
        "Yonghua Wang",
        "Yuanjia Su",
        "Hudan Pan",
        "Zishao Zhong",
        "M. Shamim Hossain"
      ],
      "abstract": "Secure data management and effective data sharing have become paramount in\nthe rapidly evolving healthcare landscape, especially with the growing\nintegration of the Internet of Medical Things (IoMT). The rise of generative\nartificial intelligence has further elevated Multi-modal Large Language Models\n(MLLMs) as essential tools for managing and optimizing healthcare data in IoMT.\nMLLMs can support multi-modal inputs and generate diverse types of content by\nleveraging large-scale training on vast amounts of multi-modal data. However,\ncritical challenges persist in developing medical MLLMs, including security and\nfreshness issues of healthcare data, affecting the output quality of MLLMs. To\nthis end, in this paper, we propose a hybrid Retrieval-Augmented Generation\n(RAG)-empowered medical MLLM framework for healthcare data management. This\nframework leverages a hierarchical cross-chain architecture to facilitate\nsecure data training. Moreover, it enhances the output quality of MLLMs through\nhybrid RAG, which employs multi-modal metrics to filter various unimodal RAG\nresults and incorporates these retrieval results as additional inputs to MLLMs.\nAdditionally, we employ age of information to indirectly evaluate the data\nfreshness impact of MLLMs and utilize contract theory to incentivize healthcare\ndata holders to share their fresh data, mitigating information asymmetry during\ndata sharing. Finally, we utilize a generative diffusion model-based deep\nreinforcement learning algorithm to identify the optimal contract for efficient\ndata sharing. Numerical results demonstrate the effectiveness of the proposed\nschemes, which achieve secure and efficient healthcare data management.",
      "tldr_zh": "这篇论文提出了一种混合 RAG 增强的多模态 LLM 框架，用于在 Internet of Medical Things (IoMT) 中实现安全的医疗数据管理。该框架采用分层跨链架构确保数据训练的安全性，并通过混合 RAG 利用多模态指标过滤检索结果，同时结合 age of information 评估数据新鲜度及合同理论激励数据共享。最终，论文运用基于生成扩散模型的深度强化学习算法优化合同设计，实验结果显示该方案显著提升了医疗数据的安全性和效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.00978v2",
      "published_date": "2024-07-01 05:28:40 UTC",
      "updated_date": "2024-12-09 02:28:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:37:14.194984"
    },
    {
      "arxiv_id": "2407.01647v1",
      "title": "Optimizing PM2.5 Forecasting Accuracy with Hybrid Meta-Heuristic and Machine Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Parviz Ghafariasl",
        "Masoomeh Zeinalnezhad",
        "Amir Ahmadishokooh"
      ],
      "abstract": "Timely alerts about hazardous air pollutants are crucial for public health.\nHowever, existing forecasting models often overlook key factors like baseline\nparameters and missing data, limiting their accuracy. This study introduces a\nhybrid approach to address these issues, focusing on forecasting hourly PM2.5\nconcentrations using Support Vector Regression (SVR). Meta-heuristic\nalgorithms, Grey Wolf Optimization (GWO) and Particle Swarm Optimization (PSO),\noptimize SVR Hyper-parameters \"C\" and \"Gamma\" to enhance prediction accuracy.\nEvaluation metrics include R-squared (R2), Root Mean Square Error (RMSE), and\nMean Absolute Error (MAE). Results show significant improvements with PSO-SVR\n(R2: 0.9401, RMSE: 0.2390, MAE: 0.1368) and GWO-SVR (R2: 0.9408, RMSE: 0.2376,\nMAE: 0.1373), indicating robust and accurate models suitable for similar\nresearch applications.",
      "tldr_zh": "本研究针对现有 PM2.5 预测模型忽略基线参数和缺失数据的问题，提出了一种混合方法，使用 Support Vector Regression (SVR) 模型来预测小时级 PM2.5 浓度，并通过 Grey Wolf Optimization (GWO) 和 Particle Swarm Optimization (PSO) 算法优化 SVR 的超参数 \"C\" 和 \"Gamma\"。这种优化显著提升了预测准确性，实验结果显示 PSO-SVR 模型的 R-squared (R2) 为 0.9401、Root Mean Square Error (RMSE) 为 0.2390、Mean Absolute Error (MAE) 为 0.1368，而 GWO-SVR 模型的 R2 为 0.9408、RMSE 为 0.2376、MAE 为 0.1373。总体而言，该方法为空气污染物预测提供了更可靠且高效的工具，适用于类似研究应用。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01647v1",
      "published_date": "2024-07-01 05:24:19 UTC",
      "updated_date": "2024-07-01 05:24:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:37:27.613028"
    },
    {
      "arxiv_id": "2407.12035v2",
      "title": "Reporting Risks in AI-based Assistive Technology Research: A Systematic Review",
      "title_zh": "翻译失败",
      "authors": [
        "Zahra Ahmadi",
        "Peter R. Lewis",
        "Mahadeo A. Sukhai"
      ],
      "abstract": "Artificial Intelligence (AI) is increasingly employed to enhance assistive\ntechnologies, yet it can fail in various ways. We conducted a systematic\nliterature review of research into AI-based assistive technology for persons\nwith visual impairments. Our study shows that most proposed technologies with a\ntestable prototype have not been evaluated in a human study with members of the\nsight-loss community. Furthermore, many studies did not consider or report\nfailure cases or possible risks. These findings highlight the importance of\ninclusive system evaluations and the necessity of standardizing methods for\npresenting and analyzing failure cases and threats when developing AI-based\nassistive technologies.",
      "tldr_zh": "这篇系统文献综述（systematic review）调查了人工智能（AI）在辅助技术中的风险报告，特别是针对视力障碍者的应用。研究发现，大多数提出可测试原型的AI-based assistive technology 尚未在视力障碍社区进行人类研究，且许多研究未考虑或报告失败 cases 或可能的风险。这些发现强调了进行包容性系统 evaluations 的重要性，并呼吁标准化 methods for presenting and analyzing failure cases and threats，以提升AI-based assistive technologies 的开发和可靠性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12035v2",
      "published_date": "2024-07-01 05:22:44 UTC",
      "updated_date": "2024-07-18 19:28:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:37:38.102736"
    },
    {
      "arxiv_id": "2407.00967v1",
      "title": "Deep learning for automated detection of breast cancer in deep ultraviolet fluorescence images with diffusion probabilistic model",
      "title_zh": "基于扩散概率模型的",
      "authors": [
        "Sepehr Salem Ghahfarokhi",
        "Tyrell To",
        "Julie Jorns",
        "Tina Yen",
        "Bing Yu",
        "Dong Hye Ye"
      ],
      "abstract": "Data limitation is a significant challenge in applying deep learning to\nmedical images. Recently, the diffusion probabilistic model (DPM) has shown the\npotential to generate high-quality images by converting Gaussian random noise\ninto realistic images. In this paper, we apply the DPM to augment the deep\nultraviolet fluorescence (DUV) image dataset with an aim to improve breast\ncancer classification for intraoperative margin assessment. For classification,\nwe divide the whole surface DUV image into small patches and extract\nconvolutional features for each patch by utilizing the pre-trained ResNet.\nThen, we feed them into an XGBoost classifier for patch-level decisions and\nthen fuse them with a regional importance map computed by Grad-CAM++ for whole\nsurface-level prediction. Our experimental results show that augmenting the\ntraining dataset with the DPM significantly improves breast cancer detection\nperformance in DUV images, increasing accuracy from 93% to 97%, compared to\nusing Affine transformations and ProGAN.",
      "tldr_zh": "本论文针对医疗图像数据限制问题，提出使用扩散概率模型(DPM)增强深紫外荧光(DUV)图像数据集，以提升乳腺癌检测性能。\n方法包括将DUV图像分成小块，利用预训练的ResNet提取卷积特征，然后通过XGBoost分类器进行块级决策，并结合Grad-CAM++计算的区域重要性地图实现整体预测。\n实验结果显示，DPM增强数据集将乳腺癌检测准确率从93%提高到97%，显著优于Affine transformations和ProGAN方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "IEEE International Symposium on Biomedical Imaging 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.00967v1",
      "published_date": "2024-07-01 05:00:26 UTC",
      "updated_date": "2024-07-01 05:00:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:37:50.921952"
    },
    {
      "arxiv_id": "2407.00959v1",
      "title": "Tokenize the World into Object-level Knowledge to Address Long-tail Events in Autonomous Driving",
      "title_zh": "将世界标记化为对象级知识以应对自动驾驶中的长尾事件",
      "authors": [
        "Ran Tian",
        "Boyi Li",
        "Xinshuo Weng",
        "Yuxiao Chen",
        "Edward Schmerling",
        "Yue Wang",
        "Boris Ivanovic",
        "Marco Pavone"
      ],
      "abstract": "The autonomous driving industry is increasingly adopting end-to-end learning\nfrom sensory inputs to minimize human biases in system design. Traditional\nend-to-end driving models, however, suffer from long-tail events due to rare or\nunseen inputs within their training distributions. To address this, we propose\nTOKEN, a novel Multi-Modal Large Language Model (MM-LLM) that tokenizes the\nworld into object-level knowledge, enabling better utilization of LLM's\nreasoning capabilities to enhance autonomous vehicle planning in long-tail\nscenarios. TOKEN effectively alleviates data scarcity and inefficient\ntokenization by leveraging a traditional end-to-end driving model to produce\ncondensed and semantically enriched representations of the scene, which are\noptimized for LLM planning compatibility through deliberate representation and\nreasoning alignment training stages. Our results demonstrate that TOKEN excels\nin grounding, reasoning, and planning capabilities, outperforming existing\nframeworks with a 27% reduction in trajectory L2 error and a 39% decrease in\ncollision rates in long-tail scenarios. Additionally, our work highlights the\nimportance of representation alignment and structured reasoning in sparking the\ncommon-sense reasoning capabilities of MM-LLMs for effective planning.",
      "tldr_zh": "本研究针对自动驾驶中长尾事件（rare or unseen inputs）的问题，提出了一种新型 Multi-Modal Large Language Model（MM-LLM）框架TOKEN，该框架通过将世界分解成对象级知识来提升LLM的推理能力，从而改善自主车辆在长尾场景下的规划。TOKEN利用传统端到端驾驶模型生成精炼的场景表示，并通过表示和推理对齐训练优化这些表示，以缓解数据稀缺和标记效率问题。实验结果显示，TOKEN在长尾场景中实现了轨迹L2错误减少27%和碰撞率下降39%，突显了表示对齐和结构化推理在激发MM-LLMs常识推理能力方面的关键作用。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00959v1",
      "published_date": "2024-07-01 04:34:50 UTC",
      "updated_date": "2024-07-01 04:34:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:38:02.600914"
    },
    {
      "arxiv_id": "2407.00958v5",
      "title": "Dynamic Universal Approximation Theory: The Basic Theory for Transformer-based Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Wang",
        "Qing Li"
      ],
      "abstract": "Language models have emerged as a critical area of focus in artificial\nintelligence, particularly with the introduction of groundbreaking innovations\nlike ChatGPT. Large-scale Transformer networks have quickly become the leading\napproach for advancing natural language processing algorithms. Built on the\nTransformer architecture, these models enable interactions that closely mimic\nhuman communication and, equipped with extensive knowledge, can even assist in\nguiding human tasks. Despite their impressive capabilities and growing\ncomplexity, a key question remains-the theoretical foundations of large\nlanguage models (LLMs). What makes Transformer so effective for powering\nintelligent language applications, such as translation and coding? What\nunderlies LLMs' ability for In-Context Learning (ICL)? How does the LoRA scheme\nenhance the fine-tuning of LLMs? And what supports the practicality of pruning\nLLMs? To address these critical questions and explore the technological\nstrategies within LLMs, we leverage the Universal Approximation Theory (UAT) to\noffer a theoretical backdrop, shedding light on the mechanisms that underpin\nthese advancements.",
      "tldr_zh": "该论文探讨了Transformer-based Large Language Models (LLMs)的理论基础，针对其有效性提出Dynamic Universal Approximation Theory (UAT)作为核心框架，以解释LLMs在自然语言处理中的机制。论文重点回答了Transformer架构为什么适用于智能语言应用、In-Context Learning (ICL)的原理、LoRA方案如何提升模型微调，以及模型修剪的实用性。总体而言，该理论为理解和优化LLMs提供了坚实的理论支撑，推动了人工智能领域的创新发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00958v5",
      "published_date": "2024-07-01 04:29:35 UTC",
      "updated_date": "2024-12-11 06:01:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:38:25.037743"
    },
    {
      "arxiv_id": "2407.00955v1",
      "title": "Task-oriented Over-the-air Computation for Edge-device Co-inference with Balanced Classification Accuracy",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Jiao",
        "Dingzhu Wen",
        "Guangxu Zhu",
        "Wei Jiang",
        "Wu Luo",
        "Yuanming Shi"
      ],
      "abstract": "Edge-device co-inference, which concerns the cooperation between edge devices\nand an edge server for completing inference tasks over wireless networks, has\nbeen a promising technique for enabling various kinds of intelligent services\nat the network edge, e.g., auto-driving. In this paradigm, the concerned design\nobjective of the network shifts from the traditional communication throughput\nto the effective and efficient execution of the inference task underpinned by\nthe network, measured by, e.g., the inference accuracy and latency. In this\npaper, a task-oriented over-the-air computation scheme is proposed for a\nmultidevice artificial intelligence system. Particularly, a novel tractable\ninference accuracy metric is proposed for classification tasks, which is called\nminimum pair-wise discriminant gain. Unlike prior work measuring the average of\nall class pairs in feature space, it measures the minimum distance of all class\npairs. By maximizing the minimum pair-wise discriminant gain instead of its\naverage counterpart, any pair of classes can be better separated in the feature\nspace, and thus leading to a balanced and improved inference accuracy for all\nclasses. Besides, this paper jointly optimizes the minimum discriminant gain of\nall feature elements instead of separately maximizing that of each element in\nthe existing designs. As a result, the transmit power can be adaptively\nallocated to the feature elements according to their different contributions to\nthe inference accuracy, opening an extra degree of freedom to improve inference\nperformance. Extensive experiments are conducted using a concrete use case of\nhuman motion recognition to verify the superiority of the proposed design over\nthe benchmarking scheme.",
      "tldr_zh": "本文提出了一种任务导向的 over-the-air computation 方案，用于 edge-device co-inference 系统，以平衡分类准确性并优化推理任务执行。论文引入 minimum pair-wise discriminant gain 指标，聚焦所有类对的最小距离，而不是平均距离，从而实现特征空间中类别的更好分离和整体准确性提升。该方案通过联合优化所有特征元素的判别增益，并根据其对准确性的贡献自适应分配传输功率，增加了系统灵活性。实验结果显示，在人类运动识别任务中，该设计显著优于基准方案，验证了其有效性。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "eess.SP",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "This paper was accepted by IEEE Transactions on Vehicular Technology\n  on June 30, 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.00955v1",
      "published_date": "2024-07-01 04:17:32 UTC",
      "updated_date": "2024-07-01 04:17:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:38:38.446209"
    },
    {
      "arxiv_id": "2407.00948v3",
      "title": "View From Above: A Framework for Evaluating Distribution Shifts in Model Behavior",
      "title_zh": "翻译失败",
      "authors": [
        "Tanush Chopra",
        "Michael Li",
        "Jacob Haimes"
      ],
      "abstract": "When large language models (LLMs) are asked to perform certain tasks, how can\nwe be sure that their learned representations align with reality? We propose a\ndomain-agnostic framework for systematically evaluating distribution shifts in\nLLMs decision-making processes, where they are given control of mechanisms\ngoverned by pre-defined rules. While individual LLM actions may appear\nconsistent with expected behavior, across a large number of trials,\nstatistically significant distribution shifts can emerge. To test this, we\nconstruct a well-defined environment with known outcome logic: blackjack. In\nmore than 1,000 trials, we uncover statistically significant evidence\nsuggesting behavioral misalignment in the learned representations of LLM.",
      "tldr_zh": "本论文提出一个领域无关的框架，用于系统评估大型语言模型 (LLMs) 在决策过程中的分布 shifts（分布偏移），以确保其学习表示与现实对齐。该框架通过控制基于预定义规则的机制（如二十一点游戏），在超过1000次试验中检测个体动作看似一致但整体行为出现统计显著的偏移。研究结果揭示了LLMs行为失调的证据，为改进模型可靠性提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00948v3",
      "published_date": "2024-07-01 04:07:49 UTC",
      "updated_date": "2024-09-28 00:07:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:38:49.080635"
    },
    {
      "arxiv_id": "2407.00942v1",
      "title": "ProductAgent: Benchmarking Conversational Product Search Agent with Asking Clarification Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Jingheng Ye",
        "Yong Jiang",
        "Xiaobin Wang",
        "Yinghui Li",
        "Yangning Li",
        "Hai-Tao Zheng",
        "Pengjun Xie",
        "Fei Huang"
      ],
      "abstract": "This paper introduces the task of product demand clarification within an\ne-commercial scenario, where the user commences the conversation with ambiguous\nqueries and the task-oriented agent is designed to achieve more accurate and\ntailored product searching by asking clarification questions. To address this\ntask, we propose ProductAgent, a conversational information seeking agent\nequipped with abilities of strategic clarification question generation and\ndynamic product retrieval. Specifically, we develop the agent with strategies\nfor product feature summarization, query generation, and product retrieval.\nFurthermore, we propose the benchmark called PROCLARE to evaluate the agent's\nperformance both automatically and qualitatively with the aid of a LLM-driven\nuser simulator. Experiments show that ProductAgent interacts positively with\nthe user and enhances retrieval performance with increasing dialogue turns,\nwhere user demands become gradually more explicit and detailed. All the source\ncodes will be released after the review anonymity period.",
      "tldr_zh": "这篇论文引入了电商场景中的产品需求澄清任务，用户以模糊查询开始，ProductAgent 作为对话式代理通过战略性澄清问题生成来实现更准确的产品检索。ProductAgent 整合了产品特征总结、查询生成和动态产品检索策略，以提升交互效率。论文还提出了 PROCLARE 基准，使用 LLM 驱动的用户模拟器进行自动和定性评估，实验结果显示代理在增加对话轮次后显著改善检索性能，用户需求逐步变得更明确。所有源代码将在审阅匿名期后发布。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "17 pages, 13 tables, 6 figures. Under review",
      "pdf_url": "http://arxiv.org/pdf/2407.00942v1",
      "published_date": "2024-07-01 03:50:23 UTC",
      "updated_date": "2024-07-01 03:50:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:39:01.732096"
    },
    {
      "arxiv_id": "2407.00936v5",
      "title": "Large Language Model Enhanced Knowledge Representation Learning: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Wang",
        "Zirui Chen",
        "Haofen Wang",
        "Leong Hou U",
        "Zhao Li",
        "Wenbin Guo"
      ],
      "abstract": "Knowledge Representation Learning (KRL) is crucial for enabling applications\nof symbolic knowledge from Knowledge Graphs (KGs) to downstream tasks by\nprojecting knowledge facts into vector spaces. Despite their effectiveness in\nmodeling KG structural information, KRL methods are suffering from the\nsparseness of KGs. The rise of Large Language Models (LLMs) built on the\nTransformer architecture presents promising opportunities for enhancing KRL by\nincorporating textual information to address information sparsity in KGs.\nLLM-enhanced KRL methods, including three key approaches, encoder-based methods\nthat leverage detailed contextual information, encoder-decoder-based methods\nthat utilize a unified Seq2Seq model for comprehensive encoding and decoding,\nand decoder-based methods that utilize extensive knowledge from large corpora,\nhave significantly advanced the effectiveness and generalization of KRL in\naddressing a wide range of downstream tasks. This work provides a broad\noverview of downstream tasks while simultaneously identifying emerging research\ndirections in these evolving domains.",
      "tldr_zh": "这篇调查论文探讨了 Large Language Models (LLMs) 如何增强 Knowledge Representation Learning (KRL)，以解决 Knowledge Graphs (KGs) 稀疏性问题，从而更好地将知识事实投影到向量空间中。论文概述了三种关键方法：基于编码器的方法利用详细上下文信息、基于编码器-解码器的方法采用统一的 Seq2Seq 模型进行全面编码和解码，以及基于解码器的方法利用大型语料库的广泛知识。这些方法显著提高了 KRL 的有效性和泛化能力，并为下游任务提供了广泛概述，同时识别了新兴研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00936v5",
      "published_date": "2024-07-01 03:37:35 UTC",
      "updated_date": "2025-04-08 14:47:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:39:14.975857"
    },
    {
      "arxiv_id": "2407.01646v1",
      "title": "ESALE: Enhancing Code-Summary Alignment Learning for Source Code Summarization",
      "title_zh": "ESALE：增强代码-摘要对齐学习用于源代码摘要生成",
      "authors": [
        "Chunrong Fang",
        "Weisong Sun",
        "Yuchen Chen",
        "Xiao Chen",
        "Zhao Wei",
        "Quanjun Zhang",
        "Yudu You",
        "Bin Luo",
        "Yang Liu",
        "Zhenyu Chen"
      ],
      "abstract": "(Source) code summarization aims to automatically generate succinct natural\nlanguage summaries for given code snippets. Such summaries play a significant\nrole in promoting developers to understand and maintain code. Inspired by\nneural machine translation, deep learning-based code summarization techniques\nwidely adopt an encoder-decoder framework, where the encoder transforms given\ncode snippets into context vectors, and the decoder decodes context vectors\ninto summaries. Recently, large-scale pre-trained models for source code are\nequipped with encoders capable of producing general context vectors and have\nachieved substantial improvements on code summarization. However, although they\nare usually trained mainly on code-focused tasks and can capture general code\nfeatures, they still fall short in capturing specific features that need to be\nsummarized.\n  This paper proposes a novel approach to improve code summarization based on\nsummary-focused tasks. Specifically, we exploit a multi-task learning paradigm\nto train the encoder on three summary-focused tasks to enhance its ability to\nlearn code-summary alignment, including unidirectional language modeling (ULM),\nmasked language modeling (MLM), and action word prediction (AWP). Unlike\npre-trained models that mainly predict masked tokens in code snippets, we\ndesign ULM and MLM to predict masked words in summaries. Intuitively,\npredicting words based on given code snippets would help learn the code-summary\nalignment. Additionally, we introduce the domain-specific task AWP to enhance\nthe ability of the encoder to learn the alignment between action words and code\nsnippets. The extensive experiments on four datasets demonstrate that our\napproach, called ESALE significantly outperforms baselines in all three widely\nused metrics, including BLEU, METEOR, and ROUGE-L.",
      "tldr_zh": "该论文提出ESALE方法，以提升源代码总结（source code summarization）的代码-摘要对齐学习（code-summary alignment）。ESALE采用多任务学习框架，训练编码器通过三个summary-focused任务——unidirectional language modeling (ULM)、masked language modeling (MLM)和action word prediction (AWP)——来增强模型捕捉代码片段与摘要的特定关联。实验结果显示，在四个数据集上，ESALE在BLEU、METEOR和ROUGE-L指标上显著优于基线模型。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "68-04",
        "D.2.3; I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to IEEE Transactions on Software Engineering (TSE)",
      "pdf_url": "http://arxiv.org/pdf/2407.01646v1",
      "published_date": "2024-07-01 03:06:51 UTC",
      "updated_date": "2024-07-01 03:06:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:39:26.084002"
    },
    {
      "arxiv_id": "2407.00918v1",
      "title": "Robust and Reliable Early-Stage Website Fingerprinting Attacks via Spatial-Temporal Distribution Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Xinhao Deng",
        "Qi Li",
        "Ke Xu"
      ],
      "abstract": "Website Fingerprinting (WF) attacks identify the websites visited by users by\nperforming traffic analysis, compromising user privacy. Particularly, DL-based\nWF attacks demonstrate impressive attack performance. However, the\neffectiveness of DL-based WF attacks relies on the collected complete and pure\ntraffic during the page loading, which impacts the practicality of these\nattacks. The WF performance is rather low under dynamic network conditions and\nvarious WF defenses, particularly when the analyzed traffic is only a small\npart of the complete traffic. In this paper, we propose Holmes, a robust and\nreliable early-stage WF attack. Holmes utilizes temporal and spatial\ndistribution analysis of website traffic to effectively identify websites in\nthe early stages of page loading. Specifically, Holmes develops adaptive data\naugmentation based on the temporal distribution of website traffic and utilizes\na supervised contrastive learning method to extract the correlations between\nthe early-stage traffic and the pre-collected complete traffic. Holmes\naccurately identifies traffic in the early stages of page loading by computing\nthe correlation of the traffic with the spatial distribution information, which\nensures robust and reliable detection according to early-stage traffic. We\nextensively evaluate Holmes using six datasets. Compared to nine existing\nDL-based WF attacks, Holmes improves the F1-score of identifying early-stage\ntraffic by an average of 169.18%. Furthermore, we replay the traffic of\nvisiting real-world dark web websites. Holmes successfully identifies dark web\nwebsites when the ratio of page loading on average is only 21.71%, with an\naverage precision improvement of 169.36% over the existing WF attacks.",
      "tldr_zh": "这篇论文提出了一种稳健可靠的早期阶段 Website Fingerprinting (WF) 攻击方法，名为 Holmes，通过对网站流量的空间-时间分布分析来识别用户访问网站，即使在页面加载早期或不完整流量条件下也能有效工作。Holmes 采用基于时间分布的自适应数据增强和监督对比学习（supervised contrastive learning）来提取早期流量与完整流量的相关性，从而实现精确的流量关联计算。实验结果显示，在六种数据集上，Holmes 比九种现有 DL-based WF 攻击平均提高 F1-score 169.18%，并在真实暗网网站场景中，仅需页面加载比例为 21.71% 即可成功识别网站，精度较现有攻击提升 169.36%。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "To appear in the Proceedings of The ACM Conference on Computer and\n  Communications Security (CCS), 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.00918v1",
      "published_date": "2024-07-01 02:51:26 UTC",
      "updated_date": "2024-07-01 02:51:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:39:39.225000"
    },
    {
      "arxiv_id": "2407.00908v3",
      "title": "FineSurE: Fine-grained Summarization Evaluation using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Hwanjun Song",
        "Hang Su",
        "Igor Shalyminov",
        "Jason Cai",
        "Saab Mansour"
      ],
      "abstract": "Automated evaluation is crucial for streamlining text summarization\nbenchmarking and model development, given the costly and time-consuming nature\nof human evaluation. Traditional methods like ROUGE do not correlate well with\nhuman judgment, while recently proposed LLM-based metrics provide only\nsummary-level assessment using Likert-scale scores. This limits deeper model\nanalysis, e.g., we can only assign one hallucination score at the summary\nlevel, while at the sentence level, we can count sentences containing\nhallucinations. To remedy those limitations, we propose FineSurE, a\nfine-grained evaluator specifically tailored for the summarization task using\nlarge language models (LLMs). It also employs completeness and conciseness\ncriteria, in addition to faithfulness, enabling multi-dimensional assessment.\nWe compare various open-source and proprietary LLMs as backbones for FineSurE.\nIn addition, we conduct extensive benchmarking of FineSurE against SOTA methods\nincluding NLI-, QA-, and LLM-based methods, showing improved performance\nespecially on the completeness and conciseness dimensions. The code is\navailable at https://github.com/DISL-Lab/FineSurE-ACL24.",
      "tldr_zh": "该论文提出了 FineSurE，一种基于大型语言模型（LLMs）的细粒度总结评估框架，旨在解决传统方法如 ROUGE 与人类判断相关性差的问题，以及现有 LLM-based 指标仅限于摘要级别的评估限制。FineSurE 通过评估总结的忠实度（faithfulness）、完整性（completeness）和简洁性（conciseness）等多维度标准，提供更深入的分析。实验结果显示，FineSurE 在基准测试中优于 SOTA 方法，尤其在完整性和简洁性方面，并开源了代码以便进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ACL 2024 (main, long)",
      "pdf_url": "http://arxiv.org/pdf/2407.00908v3",
      "published_date": "2024-07-01 02:20:28 UTC",
      "updated_date": "2024-07-22 04:45:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:39:50.018890"
    },
    {
      "arxiv_id": "2407.00902v3",
      "title": "From Introspection to Best Practices: Principled Analysis of Demonstrations in Multimodal In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Nan Xu",
        "Fei Wang",
        "Sheng Zhang",
        "Hoifung Poon",
        "Muhao Chen"
      ],
      "abstract": "Motivated by in-context learning (ICL) capabilities of Large Language Models\n(LLMs), multimodal LLMs with additional visual modality are also exhibited with\nsimilar ICL abilities when multiple image-text pairs are provided as\ndemonstrations. However, relatively less work has been done to investigate the\nprinciples behind how and why multimodal ICL works. We conduct a systematic and\nprincipled evaluation of multimodal ICL for models of different scales on a\nbroad spectrum of new yet critical tasks. Through perturbations over different\nmodality information, we show that modalities matter differently across tasks\nin multimodal ICL. Guided by task-specific modality impact, we recommend\nmodality-driven demonstration strategies to boost ICL performance. We also find\nthat models may follow inductive biases from multimodal ICL even if they are\nrarely seen in or contradict semantic priors from pretraining data. Our\nprincipled analysis provides a comprehensive way of understanding the role of\ndemonstrations in multimodal in-context learning, and sheds light on\neffectively improving multimodal ICL on a wide range of tasks.",
      "tldr_zh": "这篇论文系统评估了多模态 in-context learning (ICL) 的原理，针对不同规模的模型和多种新任务，通过对模态信息的扰动来探索模态在 ICL 中的不同作用。研究发现，任务特定的模态影响可以指导模态驱动的演示策略，从而提升 ICL 性能；此外，模型可能遵循多模态 ICL 的归纳偏差，即使这些偏差在预训练数据中很少见或与之矛盾。总体而言，该分析为理解演示在多模态 ICL 中的作用提供了全面框架，并提出了有效改进策略。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.00902v3",
      "published_date": "2024-07-01 01:57:21 UTC",
      "updated_date": "2025-02-07 02:29:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:40:02.621173"
    },
    {
      "arxiv_id": "2407.00900v1",
      "title": "MathCAMPS: Fine-grained Synthesis of Mathematical Problems From Human Curricula",
      "title_zh": "翻译失败",
      "authors": [
        "Shubhra Mishra",
        "Gabriel Poesia",
        "Belinda Mo",
        "Noah D. Goodman"
      ],
      "abstract": "Mathematical problem solving is an important skill for Large Language Models\n(LLMs), both as an important capability and a proxy for a range of reasoning\nabilities. Existing benchmarks probe a diverse set of skills, but they yield\naggregate accuracy metrics, obscuring specific abilities or weaknesses.\nFurthermore, they are difficult to extend with new problems, risking data\ncontamination over time. To address these challenges, we propose MathCAMPS: a\nmethod to synthesize high-quality mathematical problems at scale, grounded on\n44 fine-grained \"standards\" from the Mathematics Common Core (CC) Standard for\nK-8 grades. We encode each standard in a formal grammar, allowing us to sample\ndiverse symbolic problems and their answers. We then use LLMs to realize the\nsymbolic problems into word problems. We propose a cycle-consistency method for\nvalidating problem faithfulness. Finally, we derive follow-up questions from\nsymbolic structures and convert them into follow-up word problems - a novel\ntask of mathematical dialogue that probes for robustness in understanding.\nExperiments on 23 LLMs show surprising failures even in the strongest models\n(in particular when asked simple follow-up questions). Moreover, we evaluate\ntraining checkpoints of Pythia 12B on MathCAMPS, allowing us to analyze when\nparticular mathematical skills develop during its training. Our framework\nenables the community to reproduce and extend our pipeline for a fraction of\nthe typical cost of building new high-quality datasets.",
      "tldr_zh": "该论文提出MathCAMPS框架，通过基于Mathematics Common Core的44个细粒度标准，合成高质量数学问题数据集，以解决现有LLMs基准的局限性，如仅提供总体准确率和扩展困难。方法包括使用形式语法采样符号问题和答案、LLMs生成文字问题、cycle-consistency验证确保问题忠实度，以及从符号结构派生后续问题来测试理解鲁棒性。实验结果显示，23个LLMs即使在最强模型中也存在显著失败，尤其在简单后续问题上；此外，通过评估Pythia 12B的训练检查点，分析了特定数学技能的训练发展过程。该框架以低成本便于社区复制和扩展数据集，促进LLMs数学推理能力的细粒度评估。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Dataset and code: https://github.com/gpoesia/mathcamps/",
      "pdf_url": "http://arxiv.org/pdf/2407.00900v1",
      "published_date": "2024-07-01 01:56:28 UTC",
      "updated_date": "2024-07-01 01:56:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:40:15.778765"
    },
    {
      "arxiv_id": "2407.00896v1",
      "title": "Channel Modeling Aided Dataset Generation for AI-Enabled CSI Feedback: Advances, Challenges, and Solutions",
      "title_zh": "翻译失败",
      "authors": [
        "Yupeng Li",
        "Gang Li",
        "Zirui Wen",
        "Shuangfeng Han",
        "Shijian Gao",
        "Guangyi Liu",
        "Jiangzhou Wang"
      ],
      "abstract": "The AI-enabled autoencoder has demonstrated great potential in channel state\ninformation (CSI) feedback in frequency division duplex (FDD) multiple input\nmultiple output (MIMO) systems. However, this method completely changes the\nexisting feedback strategies, making it impractical to deploy in recent years.\nTo address this issue, this paper proposes a channel modeling aided data\naugmentation method based on a limited number of field channel data.\nSpecifically, the user equipment (UE) extracts the primary stochastic\nparameters of the field channel data and transmits them to the base station\n(BS). The BS then updates the typical TR 38.901 model parameters with the\nextracted parameters. In this way, the updated channel model is used to\ngenerate the dataset. This strategy comprehensively considers the dataset\ncollection, model generalization, model monitoring, and so on. Simulations\nverify that our proposed strategy can significantly improve performance\ncompared to the benchmarks.",
      "tldr_zh": "该论文探讨了 AI 启用的自动编码器在 FDD MIMO 系统中的 CSI 反馈潜力，但强调其改变了现有反馈策略，导致部署不实用。论文提出一种通道建模辅助数据增强方法，利用有限的现场通道数据：UE 提取关键随机参数传输给 BS，BS 更新 TR 38.901 模型参数后生成数据集，以提升模型泛化性和监控。模拟结果显示，该策略在性能上显著优于基准方法，为 CSI 反馈的实际应用提供了有效解决方案。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00896v1",
      "published_date": "2024-07-01 01:37:30 UTC",
      "updated_date": "2024-07-01 01:37:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:40:25.803103"
    },
    {
      "arxiv_id": "2407.00886v3",
      "title": "Efficient Automated Circuit Discovery in Transformers using Contextual Decomposition",
      "title_zh": "使用上下文分解的 Transformer 中高效自动电路发现",
      "authors": [
        "Aliyah R. Hsu",
        "Georgia Zhou",
        "Yeshwanth Cherapanamjeri",
        "Yaxuan Huang",
        "Anobel Y. Odisho",
        "Peter R. Carroll",
        "Bin Yu"
      ],
      "abstract": "Automated mechanistic interpretation research has attracted great interest\ndue to its potential to scale explanations of neural network internals to large\nmodels. Existing automated circuit discovery work relies on activation patching\nor its approximations to identify subgraphs in models for specific tasks\n(circuits). They often suffer from slow runtime, approximation errors, and\nspecific requirements of metrics, such as non-zero gradients. In this work, we\nintroduce contextual decomposition for transformers (CD-T) to build\ninterpretable circuits in large language models. CD-T can produce circuits of\narbitrary level of abstraction, and is the first able to produce circuits as\nfine-grained as attention heads at specific sequence positions efficiently.\nCD-T consists of a set of mathematical equations to isolate contribution of\nmodel features. Through recursively computing contribution of all nodes in a\ncomputational graph of a model using CD-T followed by pruning, we are able to\nreduce circuit discovery runtime from hours to seconds compared to\nstate-of-the-art baselines. On three standard circuit evaluation datasets\n(indirect object identification, greater-than comparisons, and docstring\ncompletion), we demonstrate that CD-T outperforms ACDC and EAP by better\nrecovering the manual circuits with an average of 97% ROC AUC under low\nruntimes. In addition, we provide evidence that faithfulness of CD-T circuits\nis not due to random chance by showing our circuits are 80% more faithful than\nrandom circuits of up to 60% of the original model size. Finally, we show CD-T\ncircuits are able to perfectly replicate original models' behavior\n(faithfulness $ = 1$) using fewer nodes than the baselines for all tasks. Our\nresults underscore the great promise of CD-T for efficient automated\nmechanistic interpretability, paving the way for new insights into the workings\nof large language models.",
      "tldr_zh": "这篇论文引入了 Contextual Decomposition for Transformers (CD-T)，一种高效方法，用于在大型语言模型中自动发现电路，从而解决现有基于 activation patching 的方法存在的运行缓慢、近似误差和特定要求问题。CD-T 通过一组数学方程递归计算并隔离模型特征的贡献，然后进行修剪，使电路发现时间从小时缩短到秒，并能生成从注意力头到特定序列位置的细粒度电路。在间接对象识别、greater-than 比较和文档字符串完成等数据集上，CD-T 比 ACDC 和 EAP 基准模型平均 ROC AUC 达到 97%，并证明其电路忠实度高出随机电路 80%，且能用更少节点完美复制原模型行为。该方法为高效的自动化机制解释性提供了新途径，推动了对大型语言模型内部机制的深入理解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00886v3",
      "published_date": "2024-07-01 01:12:20 UTC",
      "updated_date": "2025-03-02 08:26:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:40:39.985945"
    },
    {
      "arxiv_id": "2407.00869v2",
      "title": "Large Language Models Are Involuntary Truth-Tellers: Exploiting Fallacy Failure for Jailbreak Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Zhou",
        "Henry Peng Zou",
        "Barbara Di Eugenio",
        "Yang Zhang"
      ],
      "abstract": "We find that language models have difficulties generating fallacious and\ndeceptive reasoning. When asked to generate deceptive outputs, language models\ntend to leak honest counterparts but believe them to be false. Exploiting this\ndeficiency, we propose a jailbreak attack method that elicits an aligned\nlanguage model for malicious output. Specifically, we query the model to\ngenerate a fallacious yet deceptively real procedure for the harmful behavior.\nSince a fallacious procedure is generally considered fake and thus harmless by\nLLMs, it helps bypass the safeguard mechanism. Yet the output is factually\nharmful since the LLM cannot fabricate fallacious solutions but proposes\ntruthful ones. We evaluate our approach over five safety-aligned large language\nmodels, comparing four previous jailbreak methods, and show that our approach\nachieves competitive performance with more harmful outputs. We believe the\nfindings could be extended beyond model safety, such as self-verification and\nhallucination.",
      "tldr_zh": "研究发现，大型语言模型(LLMs)在生成谬误和欺骗性推理时存在困难，往往会泄露诚实的输出却误认为它们是假的。作者提出一种jailbreak attack方法，通过要求模型生成fallacious yet deceptively real的程序来绕过安全机制，从而诱导模型输出有害内容。实验在五个安全对齐的LLMs上进行，与四种现有方法比较，该方法表现出色，产生更多有害输出。该发现可扩展到模型安全之外的应用，如自我验证和hallucination问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the main conference of EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.00869v2",
      "published_date": "2024-07-01 00:23:43 UTC",
      "updated_date": "2024-09-23 19:48:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T02:40:51.544677"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 122,
  "processed_papers_count": 122,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T02:41:17.941953"
}