{
  "date": "2024-03-03",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-03 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 35 篇论文，主要聚焦 AI、机器学习、计算机视觉和自然语言处理等领域，强调模型效率优化、泛化能力及实际应用（如贫困干预和假新闻分析），令人印象深刻的包括 SCHEMA（ICLR 2024 接受）和 Collaborate to Adapt（WWW-2024 接受），这些论文展示了 AI 在跨领域融合和实际问题解决上的潜力。\n\n### 重点论文亮点\n今天的核心主题围绕 AI 模型的创新和应用，许多论文探讨了高效计算、泛化及社会影响。以下挑选了最具话题度和影响力的论文，先从 AI 强化学习与知识蒸馏开始讨论，再聊计算机视觉和社会应用，其他次要论文则简要掠过。\n\n**1. 高效注意力机制：Cost-Effective Attention Mechanisms for Low Resource Settings (中文：成本有效的注意力机制用于低资源环境)  \n   这篇论文提出三种注意力变体（如 Super Attention），通过移除或添加线性变换，显著减少了 Scaled Dot Product Attention (SDPA) 的参数（25-50% 减少），在 NLP 和视觉任务上性能损失最小，甚至在某些情况下提升 10% 准确率，同时加速计算。该贡献适用于资源受限的边缘设备，展示了高效 AI 设计的实际价值。**\n\n**2. 机器学习 vs 深度学习泛化：Machine Learning vs Deep Learning: The Generalization Problem (中文：机器学习 vs 深度学习：泛化问题)  \n   作者 Yong Yi Bay 和 Kathleen A. Yearick 通过实验比较传统 ML 和 DL 在外推任务中的表现，发现 DL 模型在超出训练数据范围时具有更强的泛化能力。该论文强调 DL 在真实世界应用（如不完整数据场景）的鲁棒性，提供理论和实证支持，适合泛化研究者参考。**\n\n**3. 强化学习改进：Towards Provable Log Density Policy Gradient (中文：朝向可证明的对数密度策略梯度)  \n   这篇论文针对策略梯度方法中的残差误差，提出 log density gradient 框架，使用时序差分（TD）和最小-最大优化来校正误差，实现更低的样本复杂度（O(m^{-1/2})）。在网格世界环境中，实验显示其比经典策略梯度提升明显，填补了强化学习效率的空白。**\n\n**4. 视频过程规划：SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos (中文：状态变化事关视频过程规划)  \n   ICLR 2024 接受的亮点论文！作者 Yulei Niu 等通过显式建模状态变化（使用 LLM 生成描述），结合跨模态对比学习，提高了视频任务序列建模的准确性。在 CrossTask 等数据集上，SCHEMA 实现了最先进性能，并提供可解释可视化，强调状态在视频理解中的核心作用。**\n\n**5. 贫困干预模型：Can Poverty Be Reduced by Acting on Discrimination? An Agent-based Model for Policy Making (中文：通过针对歧视减少贫困？基于代理的决策模型)  \n   这篇社会影响强的论文提出 Aporophobia Agent-Based Model (AABM)，使用代理模拟显示歧视（aporophobia）加剧财富不平等，并评估巴塞罗那的公共政策。该发现为 UN 可持续发展目标提供新视角，建议未来政策聚焦社会歧视而非仅重分配。**\n\n**6. 动漫图像超分辨率：APISR: Anime Production Inspired Real-World Anime Super-Resolution (中文：受动漫制作启发的真实世界动漫超分辨率)  \n   作者 Boyang Wang 等分析动漫制作流程，构建 Anime Production-oriented Image (API) 数据集，并通过预测导向压缩和双重感知损失解决手绘线条失真问题。实验显示其在基准上优于现有方法，适用于动漫领域的图像增强。**\n\n**7. LLM 幻觉缓解：In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation (中文：在语境中锐度作为警报：从内部表示视角缓解幻觉)  \n   作者 Shiqi Chen 等发现正确生成时 LLM 隐藏状态更“锐利”（熵-based 度量），提出约束解码方法缓解幻觉。在 TruthfulQA 上提升 8.6 分，强调内部表示在 LLM 可靠性的关键作用。**\n\n**8. 图域适应：Collaborate to Adapt: Source-Free Graph Domain Adaptation via Bi-directional Adaptation (中文：协同适应：通过双向适应实现无源图域迁移)  \n   WWW-2024 接受的论文！作者 Zhen Zhang 等提出 GraphCTA 框架，通过模型和图结构双向迭代适应，无需访问源图标签。在基准数据集上大幅优于基线，适用于隐私敏感的图数据迁移场景。**\n\n其他论文如神经机器翻译优化（Enhancing Neural Machine Translation...）、假新闻扩散模型（Plasmon Resonance Model...）和心脏病预测（Machine learning predicts long-term mortality...）等，虽然有创新，但影响力较小，仅快速提一下：前者通过数据集和工具提升低资源语言翻译；后者使用 ML 模型结合生物标记预测 14 年心血管死亡率，提升 C-Statistic 至 0.83；假新闻模型则探索非线性方程，但因教育性写作而非核心研究，掠过细节。\n\n总之，今天的 arXiv 论文突显 AI 向高效、泛化和社会应用的演进，建议关注 SCHEMA 和 Collaborate to Adapt 等高影响力工作。明天的更新拭目以待！",
  "papers": [
    {
      "arxiv_id": "2403.01643v3",
      "title": "Cost-Effective Attention Mechanisms for Low Resource Settings: Necessity & Sufficiency of Linear Transformations",
      "title_zh": "低资源环境下的成本有效注意力机制：线性变换的必要性与充分性",
      "authors": [
        "Peyman Hosseini",
        "Mehran Hosseini",
        "Ignacio Castro",
        "Matthew Purver"
      ],
      "abstract": "From natural language processing to vision, Scaled Dot Product Attention\n(SDPA) is the backbone of most modern deep learning applications.\nUnfortunately, its memory and computational requirements can be prohibitive in\nlow-resource settings. In this paper, we improve its efficiency without\nsacrificing its versatility. We propose three attention variants where we\nremove consecutive linear transformations or add a novel one, and evaluate them\non a range of standard NLP and vision tasks. Our proposed models are\nsubstantially lighter than standard SDPA (and have 25-50% fewer parameters). We\nshow that the performance cost of these changes is negligible relative to size\nreduction and that in one case (Super Attention) we succeed in outperforming\nSDPA by up to 10% while improving its speed and reducing its parameters by 25%.",
      "tldr_zh": "这篇论文针对 Scaled Dot Product Attention (SDPA) 在低资源环境中的高内存和计算需求问题，提出三种注意力机制变体，通过移除连续线性变换或添加新变换来提升效率。这些变体在标准 NLP 和视觉任务上表现出色，参数减少 25-50%，性能损失几乎可以忽略不计。特别地，Super Attention 模型不仅比 SDPA 性能提升高达 10%，还提高了速度并减少了 25% 的参数，为资源受限场景下的深度学习应用提供了更具成本效益的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "68T07 (Primary) 68T45, 68T50, 68T10, 15A03, 15A04 (Secondary)",
        "I.2.6; I.2.7; I.2.10; I.4.0; I.5.0; I.7.0"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01643v3",
      "published_date": "2024-03-03 23:40:35 UTC",
      "updated_date": "2025-02-16 14:14:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:00:54.341815"
    },
    {
      "arxiv_id": "2403.01621v1",
      "title": "Machine Learning vs Deep Learning: The Generalization Problem",
      "title_zh": "机器学习与深度学习：泛化问题",
      "authors": [
        "Yong Yi Bay",
        "Kathleen A. Yearick"
      ],
      "abstract": "The capacity to generalize beyond the range of training data is a pivotal\nchallenge, often synonymous with a model's utility and robustness. This study\ninvestigates the comparative abilities of traditional machine learning (ML)\nmodels and deep learning (DL) algorithms in terms of extrapolation -- a more\nchallenging aspect of generalization because it requires the model to make\ninferences about data points that lie outside the domain it has been trained\non. We present an empirical analysis where both ML and DL models are trained on\nan exponentially growing function and then tested on values outside the\ntraining domain. The choice of this function allows us to distinctly showcase\nthe divergence in performance when models are required to predict beyond the\nscope of their training data. Our findings suggest that deep learning models\npossess inherent capabilities to generalize beyond the training scope, an\nessential feature for real-world applications where data is often incomplete or\nextends beyond the observed range. This paper argues for a nuanced\nunderstanding of the structural differences between ML and DL models, with an\nemphasis on the implications for both theoretical research and practical\ndeployment.",
      "tldr_zh": "这篇论文比较了传统机器学习(ML)模型和深度学习(DL)算法在泛化能力，特别是外推方面的表现，通过实验训练模型来预测指数增长函数，并在训练域外测试。结果显示，DL模型在处理超出训练数据范围的预测时表现出更强的能力，这使其更适合真实世界应用，其中数据往往不完整或超出观察范围。该研究呼吁对ML和DL的结构差异进行更细致的理解，以指导理论研究和实际部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.01621v1",
      "published_date": "2024-03-03 21:42:55 UTC",
      "updated_date": "2024-03-03 21:42:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:01:06.428982"
    },
    {
      "arxiv_id": "2403.01606v2",
      "title": "A Unified Model Selection Technique for Spectral Clustering Based Motion Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiang Huang",
        "John Zelek"
      ],
      "abstract": "Motion segmentation is a fundamental problem in computer vision and is\ncrucial in various applications such as robotics, autonomous driving and action\nrecognition. Recently, spectral clustering based methods have shown impressive\nresults on motion segmentation in dynamic environments. These methods perform\nspectral clustering on motion affinity matrices to cluster objects or point\ntrajectories in the scene into different motion groups. However, existing\nmethods often need the number of motions present in the scene to be known,\nwhich significantly reduces their practicality. In this paper, we propose a\nunified model selection technique to automatically infer the number of motion\ngroups for spectral clustering based motion segmentation methods by combining\ndifferent existing model selection techniques together. We evaluate our method\non the KT3DMoSeg dataset and achieve competitve results comparing to the\nbaseline where the number of clusters is given as ground truth information.",
      "tldr_zh": "这篇论文提出了一种统一的模型选择技术(unified model selection technique)，用于光谱聚类(spectral clustering)基于的运动分割(motion segmentation)，以自动推断场景中的运动组数量，避免了现有方法依赖已知运动数的局限。方法通过结合多种现有的模型选择技术，对运动亲和矩阵进行处理，实现对对象或点轨迹的聚类。实验在 KT3DMoSeg 数据集上显示，该技术与基线方法（已知真实聚类数）相比，取得了竞争性的性能结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "for the published version, see\n  https://openjournals.uwaterloo.ca/index.php/vsl/article/view/5870/5922",
      "pdf_url": "http://arxiv.org/pdf/2403.01606v2",
      "published_date": "2024-03-03 20:16:14 UTC",
      "updated_date": "2024-05-06 22:19:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:01:17.882979"
    },
    {
      "arxiv_id": "2403.01605v1",
      "title": "Towards Provable Log Density Policy Gradient",
      "title_zh": "迈向可证明的日志密度策略梯度",
      "authors": [
        "Pulkit Katdare",
        "Anant Joshi",
        "Katherine Driggs-Campbell"
      ],
      "abstract": "Policy gradient methods are a vital ingredient behind the success of modern\nreinforcement learning. Modern policy gradient methods, although successful,\nintroduce a residual error in gradient estimation. In this work, we argue that\nthis residual term is significant and correcting for it could potentially\nimprove sample-complexity of reinforcement learning methods. To that end, we\npropose log density gradient to estimate the policy gradient, which corrects\nfor this residual error term. Log density gradient method computes policy\ngradient by utilising the state-action discounted distributional formulation.\nWe first present the equations needed to exactly find the log density gradient\nfor a tabular Markov Decision Processes (MDPs). For more complex environments,\nwe propose a temporal difference (TD) method that approximates log density\ngradient by utilizing backward on-policy samples. Since backward sampling from\na Markov chain is highly restrictive we also propose a min-max optimization\nthat can approximate log density gradient using just on-policy samples. We also\nprove uniqueness, and convergence under linear function approximation, for this\nmin-max optimization. Finally, we show that the sample complexity of our\nmin-max optimization to be of the order of $m^{-1/2}$, where $m$ is the number\nof on-policy samples. We also demonstrate a proof-of-concept for our log\ndensity gradient method on gridworld environment, and observe that our method\nis able to improve upon the classical policy gradient method by a clear margin,\nthus indicating a promising novel direction to develop reinforcement learning\nalgorithms that require fewer samples.",
      "tldr_zh": "本研究针对现代政策梯度方法在强化学习中的残差误差问题，提出 log density gradient 技术，以修正该误差并潜在改善样本复杂度。该方法利用 state-action 折扣分布公式，为表格 Markov Decision Processes (MDPs) 提供精确计算方程，并针对复杂环境引入 temporal difference (TD) 方法和 min-max 优化，使用 on-policy 样本进行近似。作者证明了 min-max 优化的唯一性、收敛性以及在线性函数逼近下的有效性，其样本复杂度为 O(m^{-1/2})，其中 m 为 on-policy 样本数。在 gridworld 环境中实验表明，该方法显著优于经典 policy gradient 方法，提供了一个需要更少样本的强化学习新方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01605v1",
      "published_date": "2024-03-03 20:09:09 UTC",
      "updated_date": "2024-03-03 20:09:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:01:30.782715"
    },
    {
      "arxiv_id": "2403.01600v1",
      "title": "Can Poverty Be Reduced by Acting on Discrimination? An Agent-based Model for Policy Making",
      "title_zh": "翻译失败",
      "authors": [
        "Alba Aguilera",
        "Nieves Montes",
        "Georgina Curto",
        "Carles Sierra",
        "Nardine Osman"
      ],
      "abstract": "In the last decades, there has been a deceleration in the rates of poverty\nreduction, suggesting that traditional redistributive approaches to poverty\nmitigation could be losing effectiveness, and alternative insights to advance\nthe number one UN Sustainable Development Goal are required. The\ncriminalization of poor people has been denounced by several NGOs, and an\nincreasing number of voices suggest that discrimination against the poor (a\nphenomenon known as \\emph{aporophobia}) could be an impediment to mitigating\npoverty. In this paper, we present the novel Aporophobia Agent-Based Model\n(AABM) to provide evidence of the correlation between aporophobia and poverty\ncomputationally. We present our use case built with real-world demographic data\nand poverty-mitigation public policies (either enforced or under parliamentary\ndiscussion) for the city of Barcelona. We classify policies as discriminatory\nor non-discriminatory against the poor, with the support of specialized NGOs,\nand we observe the results in the AABM in terms of the impact on wealth\ninequality. The simulation provides evidence of the relationship between\naporophobia and the increase of wealth inequality levels, paving the way for a\nnew generation of poverty reduction policies that act on discrimination and\ntackle poverty as a societal problem (not only a problem of the poor).",
      "tldr_zh": "本研究探讨了针对歧视（特别是对穷人的歧视，aporophobia）是否能减少贫困的问题，指出传统再分配方法效果减弱，需要新的策略来推进联合国可持续发展目标（UN Sustainable Development Goal）。作者开发了 Aporophobia Agent-Based Model (AABM)，利用巴塞罗那的真实人口数据模拟歧视性和非歧视性公共政策的影响。模拟结果显示，aporophobia 会加剧财富不平等，为制定新一代针对歧视的贫困减少政策提供证据，将贫困视为社会整体问题而非仅限于穷人群体。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01600v1",
      "published_date": "2024-03-03 19:59:42 UTC",
      "updated_date": "2024-03-03 19:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:01:42.113883"
    },
    {
      "arxiv_id": "2403.01599v1",
      "title": "SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Yulei Niu",
        "Wenliang Guo",
        "Long Chen",
        "Xudong Lin",
        "Shih-Fu Chang"
      ],
      "abstract": "We study the problem of procedure planning in instructional videos, which\naims to make a goal-oriented sequence of action steps given partial visual\nstate observations. The motivation of this problem is to learn a structured and\nplannable state and action space. Recent works succeeded in sequence modeling\nof steps with only sequence-level annotations accessible during training, which\noverlooked the roles of states in the procedures. In this work, we point out\nthat State CHangEs MAtter (SCHEMA) for procedure planning in instructional\nvideos. We aim to establish a more structured state space by investigating the\ncausal relations between steps and states in procedures. Specifically, we\nexplicitly represent each step as state changes and track the state changes in\nprocedures. For step representation, we leveraged the commonsense knowledge in\nlarge language models (LLMs) to describe the state changes of steps via our\ndesigned chain-of-thought prompting. For state change tracking, we align visual\nstate observations with language state descriptions via cross-modal contrastive\nlearning, and explicitly model the intermediate states of the procedure using\nLLM-generated state descriptions. Experiments on CrossTask, COIN, and NIV\nbenchmark datasets demonstrate that our proposed SCHEMA model achieves\nstate-of-the-art performance and obtains explainable visualizations.",
      "tldr_zh": "本文提出SCHEMA框架，强调状态变化在教学视频程序规划中的关键作用，通过调查步骤和状态之间的因果关系来构建更结构化的状态和行动空间。方法包括使用LLMs的chain-of-thought prompting描述步骤的状态变化，并通过cross-modal contrastive learning对齐视觉状态观察与语言状态描述，同时显式建模程序的中间状态。在CrossTask、COIN和NIV基准数据集上的实验表明，SCHEMA模型实现了最先进性能，并提供了可解释的可视化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.01599v1",
      "published_date": "2024-03-03 19:53:06 UTC",
      "updated_date": "2024-03-03 19:53:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:01:54.666184"
    },
    {
      "arxiv_id": "2403.01598v2",
      "title": "APISR: Anime Production Inspired Real-World Anime Super-Resolution",
      "title_zh": "APISR：受动画制作启发的真实世界动画超分辨率",
      "authors": [
        "Boyang Wang",
        "Fengyu Yang",
        "Xihang Yu",
        "Chao Zhang",
        "Hanbin Zhao"
      ],
      "abstract": "While real-world anime super-resolution (SR) has gained increasing attention\nin the SR community, existing methods still adopt techniques from the\nphotorealistic domain. In this paper, we analyze the anime production workflow\nand rethink how to use characteristics of it for the sake of the real-world\nanime SR. First, we argue that video networks and datasets are not necessary\nfor anime SR due to the repetition use of hand-drawing frames. Instead, we\npropose an anime image collection pipeline by choosing the least compressed and\nthe most informative frames from the video sources. Based on this pipeline, we\nintroduce the Anime Production-oriented Image (API) dataset. In addition, we\nidentify two anime-specific challenges of distorted and faint hand-drawn lines\nand unwanted color artifacts. We address the first issue by introducing a\nprediction-oriented compression module in the image degradation model and a\npseudo-ground truth preparation with enhanced hand-drawn lines. In addition, we\nintroduce the balanced twin perceptual loss combining both anime and\nphotorealistic high-level features to mitigate unwanted color artifacts and\nincrease visual clarity. We evaluate our method through extensive experiments\non the public benchmark, showing our method outperforms state-of-the-art anime\ndataset-trained approaches.",
      "tldr_zh": "该论文提出APISR方法，受动漫制作流程启发，针对真实世界动漫超分辨率(SR)问题，摒弃传统视频网络和数据集，转而开发一个图像收集管道，以选择最不压缩和最信息丰富的帧，从而构建Anime Production-oriented Image (API)数据集。论文识别出动漫特有的挑战，包括扭曲和模糊的手绘线条以及不需要的颜色伪影，并通过引入预测导向的压缩模块和伪真实值准备来增强手绘线条，同时采用balanced twin perceptual loss结合动漫和照片级高级特征来减少颜色伪影。实验结果显示，该方法在公共基准测试中优于现有动漫数据集训练的先进方法，提供更清晰的视觉效果。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01598v2",
      "published_date": "2024-03-03 19:52:43 UTC",
      "updated_date": "2024-04-04 16:12:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:02:06.613875"
    },
    {
      "arxiv_id": "2403.01580v1",
      "title": "Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Séamus Lankford"
      ],
      "abstract": "In the current machine translation (MT) landscape, the Transformer\narchitecture stands out as the gold standard, especially for high-resource\nlanguage pairs. This research delves into its efficacy for low-resource\nlanguage pairs including both the English$\\leftrightarrow$Irish and\nEnglish$\\leftrightarrow$Marathi language pairs. Notably, the study identifies\nthe optimal hyperparameters and subword model type to significantly improve the\ntranslation quality of Transformer models for low-resource language pairs.\n  The scarcity of parallel datasets for low-resource languages can hinder MT\ndevelopment. To address this, gaHealth was developed, the first bilingual\ncorpus of health data for the Irish language. Focusing on the health domain,\nmodels developed using this in-domain dataset exhibited very significant\nimprovements in BLEU score when compared with models from the LoResMT2021\nShared Task. A subsequent human evaluation using the multidimensional quality\nmetrics error taxonomy showcased the superior performance of the Transformer\nsystem in reducing both accuracy and fluency errors compared to an RNN-based\ncounterpart.\n  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source\napplications streamlined for the development, fine-tuning, and deployment of\nneural machine translation models. These tools considerably simplify the setup\nand evaluation process, making MT more accessible to both developers and\ntranslators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes\neco-friendly natural language processing research by highlighting the\nenvironmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM\ndemonstrated advancements in translation performance for two low-resource\nlanguage pairs: English$\\leftrightarrow$Irish and\nEnglish$\\leftrightarrow$Marathi, compared to baselines from the LoResMT2021\nShared Task.",
      "tldr_zh": "这篇论文探讨了使用 Transformer 架构提升低资源语言（如英语-爱尔兰语和英语-马拉地语）的机器翻译（MT）质量，通过优化超参数和子词模型来显著改善翻译性能。研究开发了 gaHealth，这是一个针对爱尔兰语的健康领域双语语料库，并在人类评估中使用多维质量指标（multidimensional quality metrics error taxonomy）证明 Transformer 系统在减少准确性和流畅性错误方面优于 RNN 模型。论文还引入了开源工具 adaptNMT 和 adaptMLLM，用于简化 MT 模型的开发、微调和部署，并展示了这些工具在低资源语言对上的 BLEU 分数提升和环保优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "PhD thesis",
      "pdf_url": "http://arxiv.org/pdf/2403.01580v1",
      "published_date": "2024-03-03 18:08:30 UTC",
      "updated_date": "2024-03-03 18:08:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:02:20.163709"
    },
    {
      "arxiv_id": "2403.01575v1",
      "title": "SARD: A Human-AI Collaborative Story Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Y. Radwan",
        "Khaled M. Alasmari",
        "Omar A. Abdulbagi",
        "Emad A. Alghamdi"
      ],
      "abstract": "Generative artificial intelligence (GenAI) has ushered in a new era for\nstorytellers, providing a powerful tool to ignite creativity and explore\nuncharted narrative territories. As technology continues to advance, the\nsynergy between human creativity and AI-generated content holds the potential\nto redefine the landscape of storytelling. In this work, we propose SARD, a\ndrag-and-drop visual interface for generating a multi-chapter story using large\nlanguage models. Our evaluation of the usability of SARD and its creativity\nsupport shows that while node-based visualization of the narrative may help\nwriters build a mental model, it exerts unnecessary mental overhead to the\nwriter and becomes a source of distraction as the story becomes more\nelaborated. We also found that AI generates stories that are less lexically\ndiverse, irrespective of the complexity of the story. We identified some\npatterns and limitations of our tool that can guide the development of future\nhuman-AI co-writing tools.",
      "tldr_zh": "本文提出 SARD，一种基于拖拽式视觉界面的工具，旨在促进人类-AI 协作生成多章节故事，使用 large language models 作为核心引擎。评估结果显示，node-based visualization 有助于用户构建叙事心理模型，但会增加不必要的心理负担并成为 distraction，同时 AI 生成的故事在词汇多样性上较低。研究还识别了 SARD 的模式和限制，以指导未来 human-AI co-writing 工具的开发。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01575v1",
      "published_date": "2024-03-03 17:48:42 UTC",
      "updated_date": "2024-03-03 17:48:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:02:29.813759"
    },
    {
      "arxiv_id": "2403.05585v2",
      "title": "Plasmon Resonance Model: Investigation of Analysis of Fake News Diffusion Model with Third Mover Intervention Using Soliton Solution in Non-Complete Information Game under Repeated Dilemma Condition",
      "title_zh": "翻译失败",
      "authors": [
        "Yasuko Kawahata"
      ],
      "abstract": "In this research note, we propose a new approach to model the fake news\ndiffusion process within the framework of incomplete information games. In\nparticular, we use nonlinear partial differential equations to represent the\nphenomenon of plasmon resonance, in which the diffusion of fake news is rapidly\namplified within a particular social group or communication network, and\nanalyze its dynamics through a soliton solution approach. In addition, we\nconsider how first mover, second mover, and third mover strategies interact\nwithin this nonlinear system and contribute to the amplification or suppression\nof fake news diffusion. The model aims to understand the mechanisms of fake\nnews proliferation and provide insights into how to prevent or combat it. By\ncombining concepts from the social sciences and the physical sciences, this\nstudy attempts to develop a new theoretical framework for the contemporary\nproblem of fake news.This paper is partially an attempt to utilize \"Generative\nAI\" and was written with educational intent. There are currently no plans for\nit to become a peer-reviewed paper.",
      "tldr_zh": "本研究提出Plasmon Resonance Model，使用非线性偏微分方程和soliton solution来模拟假新闻在非完全信息游戏中的扩散过程，特别关注repeated dilemma condition下的动态。模型分析了first mover、second mover和third mover策略如何通过交互作用放大或抑制假新闻传播。结合社会科学和物理科学概念，该框架旨在揭示假新闻扩散机制并提供预防策略；论文为教育性尝试，部分利用Generative AI撰写，并非针对同行评议。",
      "categories": [
        "physics.soc-ph",
        "cs.AI"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "Plasmon Resonance Model, Soliton Solution, Third Mover,Fake News,\n  Non-Complete Information Game, Nonlinear Partial Differential Equations,\n  First Mover, Second Mover, Third Mover, Diffusion Dynamics, Iteration Dilemma",
      "pdf_url": "http://arxiv.org/pdf/2403.05585v2",
      "published_date": "2024-03-03 17:46:12 UTC",
      "updated_date": "2024-04-19 14:56:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:02:42.843894"
    },
    {
      "arxiv_id": "2403.01569v1",
      "title": "Kick Back & Relax++: Scaling Beyond Ground-Truth Depth with SlowTV & CribsTV",
      "title_zh": "翻译失败",
      "authors": [
        "Jaime Spencer",
        "Chris Russell",
        "Simon Hadfield",
        "Richard Bowden"
      ],
      "abstract": "Self-supervised learning is the key to unlocking generic computer vision\nsystems. By eliminating the reliance on ground-truth annotations, it allows\nscaling to much larger data quantities. Unfortunately, self-supervised\nmonocular depth estimation (SS-MDE) has been limited by the absence of diverse\ntraining data. Existing datasets have focused exclusively on urban driving in\ndensely populated cities, resulting in models that fail to generalize beyond\nthis domain.\n  To address these limitations, this paper proposes two novel datasets: SlowTV\nand CribsTV. These are large-scale datasets curated from publicly available\nYouTube videos, containing a total of 2M training frames. They offer an\nincredibly diverse set of environments, ranging from snowy forests to coastal\nroads, luxury mansions and even underwater coral reefs. We leverage these\ndatasets to tackle the challenging task of zero-shot generalization,\noutperforming every existing SS-MDE approach and even some state-of-the-art\nsupervised methods.\n  The generalization capabilities of our models are further enhanced by a range\nof components and contributions: 1) learning the camera intrinsics, 2) a\nstronger augmentation regime targeting aspect ratio changes, 3) support frame\nrandomization, 4) flexible motion estimation, 5) a modern transformer-based\narchitecture. We demonstrate the effectiveness of each component in extensive\nablation experiments. To facilitate the development of future research, we make\nthe datasets, code and pretrained models available to the public at\nhttps://github.com/jspenmar/slowtv_monodepth.",
      "tldr_zh": "该论文针对自监督单目深度估计（SS-MDE）的泛化性问题，提出两个新数据集：SlowTV 和 CribsTV，这些数据集从 YouTube 视频中提取，总计 2M 训练帧，涵盖多样环境如雪林、海岸、豪宅和水下珊瑚礁，从而超越传统城市驾驶场景的限制。作者通过自监督学习方法结合多种组件，包括学习相机内参、更强的增强策略（针对长宽比变化）、支持帧随机化和灵活的运动估计，以及现代 Transformer 架构，显著提升了模型的零样本泛化能力。实验结果显示，该方法优于现有 SS-MDE 模型，甚至部分监督方法，并通过公开数据集、代码和预训练模型促进未来研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01569v1",
      "published_date": "2024-03-03 17:29:03 UTC",
      "updated_date": "2024-03-03 17:29:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:02:56.229061"
    },
    {
      "arxiv_id": "2403.01567v2",
      "title": "ReMatch: Retrieval Enhanced Schema Matching with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Eitam Sheetrit",
        "Menachem Brief",
        "Moshik Mishaeli",
        "Oren Elisha"
      ],
      "abstract": "Schema matching is a crucial task in data integration, involving the\nalignment of a source schema with a target schema to establish correspondence\nbetween their elements. This task is challenging due to textual and semantic\nheterogeneity, as well as differences in schema sizes. Although\nmachine-learning-based solutions have been explored in numerous studies, they\noften suffer from low accuracy, require manual mapping of the schemas for model\ntraining, or need access to source schema data which might be unavailable due\nto privacy concerns. In this paper we present a novel method, named ReMatch,\nfor matching schemas using retrieval-enhanced Large Language Models (LLMs). Our\nmethod avoids the need for predefined mapping, any model training, or access to\ndata in the source database. Our experimental results on large real-world\nschemas demonstrate that ReMatch is an effective matcher. By eliminating the\nrequirement for training data, ReMatch becomes a viable solution for real-world\nscenarios.",
      "tldr_zh": "该论文提出了一种名为 ReMatch 的新方法，用于解决数据集成中的 Schema Matching 问题，该任务涉及对齐源模式和目标模式，但面临文本和语义异质性以及模式大小差异的挑战。ReMatch 利用检索增强的 Large Language Models (LLMs) 进行模式匹配，避免了传统机器学习方法所需的预定义映射、模型训练或访问源数据库数据，从而缓解隐私问题。实验结果显示，在大型真实世界模式上，ReMatch 表现出色，成为无需训练数据的实用解决方案。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01567v2",
      "published_date": "2024-03-03 17:14:40 UTC",
      "updated_date": "2024-05-30 14:33:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:03:06.797989"
    },
    {
      "arxiv_id": "2403.01564v3",
      "title": "ComTraQ-MPC: Meta-Trained DQN-MPC Integration for Trajectory Tracking with Limited Active Localization Updates",
      "title_zh": "翻译失败",
      "authors": [
        "Gokul Puthumanaillam",
        "Manav Vora",
        "Melkior Ornik"
      ],
      "abstract": "Optimal decision-making for trajectory tracking in partially observable,\nstochastic environments where the number of active localization updates -- the\nprocess by which the agent obtains its true state information from the sensors\n-- are limited, presents a significant challenge. Traditional methods often\nstruggle to balance resource conservation, accurate state estimation and\nprecise tracking, resulting in suboptimal performance. This problem is\nparticularly pronounced in environments with large action spaces, where the\nneed for frequent, accurate state data is paramount, yet the capacity for\nactive localization updates is restricted by external limitations. This paper\nintroduces ComTraQ-MPC, a novel framework that combines Deep Q-Networks (DQN)\nand Model Predictive Control (MPC) to optimize trajectory tracking with\nconstrained active localization updates. The meta-trained DQN ensures adaptive\nactive localization scheduling, while the MPC leverages available state\ninformation to improve tracking. The central contribution of this work is their\nreciprocal interaction: DQN's update decisions inform MPC's control strategy,\nand MPC's outcomes refine DQN's learning, creating a cohesive, adaptive system.\nEmpirical evaluations in simulated and real-world settings demonstrate that\nComTraQ-MPC significantly enhances operational efficiency and accuracy,\nproviding a generalizable and approximately optimal solution for trajectory\ntracking in complex partially observable environments.",
      "tldr_zh": "本研究针对部分可观测、随机环境中轨迹跟踪的挑战，提出 ComTraQ-MPC 框架，该框架整合 meta-trained DQN 和 Model Predictive Control (MPC)，以优化有限的主动定位更新问题。DQN 负责自适应地调度主动定位更新，而 MPC 利用可用状态信息提升跟踪精度；二者通过相互作用——DQN 的更新决策指导 MPC 的控制策略，反之 MPC 的结果优化 DQN 的学习——形成一个 cohesive, adaptive 系统。实验结果显示，在模拟和真实环境中，ComTraQ-MPC 显著提高了 operational efficiency 和 accuracy，提供了一个 generalizable 和 approximately optimal 的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "* Equal contribution",
      "pdf_url": "http://arxiv.org/pdf/2403.01564v3",
      "published_date": "2024-03-03 17:00:28 UTC",
      "updated_date": "2024-08-20 21:52:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:03:20.227781"
    },
    {
      "arxiv_id": "2403.01548v3",
      "title": "In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation",
      "title_zh": "翻译失败",
      "authors": [
        "Shiqi Chen",
        "Miao Xiong",
        "Junteng Liu",
        "Zhengxuan Wu",
        "Teng Xiao",
        "Siyang Gao",
        "Junxian He"
      ],
      "abstract": "Large language models (LLMs) frequently hallucinate and produce factual\nerrors, yet our understanding of why they make these errors remains limited. In\nthis study, we delve into the underlying mechanisms of LLM hallucinations from\nthe perspective of inner representations, and discover a salient pattern\nassociated with hallucinations: correct generations tend to have sharper\ncontext activations in the hidden states of the in-context tokens, compared to\nthe incorrect ones. Leveraging this insight, we propose an entropy-based metric\nto quantify the ``sharpness'' among the in-context hidden states and\nincorporate it into the decoding process to formulate a constrained decoding\napproach. Experiments on various knowledge-seeking and hallucination benchmarks\ndemonstrate our approach's consistent effectiveness, for example, achieving up\nto an 8.6 point improvement on TruthfulQA. We believe this study can improve\nour understanding of hallucinations and serve as a practical solution for\nhallucination mitigation.",
      "tldr_zh": "这项研究从内部表示（inner representations）的角度探讨了大语言模型（LLMs）的幻觉（hallucinations）问题，发现正确生成的输出在 in-context tokens 的隐藏状态中表现出更尖锐的上下文激活（sharper context activations）。基于这一洞见，研究者提出了一种基于熵的指标来量化 in-context 隐藏状态的“sharpness”，并将其整合到解码过程中，形成一个约束解码方法，以缓解幻觉。实验在多个知识求解和幻觉基准上验证了该方法的有效性，例如在 TruthfulQA 上实现了高达 8.6 分的性能提升。该方法不仅加深了对 LLM 幻觉机制的理解，还提供了一个实用的缓解策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "code repo is available at:\n  https://github.com/hkust-nlp/Activation_decoding.git",
      "pdf_url": "http://arxiv.org/pdf/2403.01548v3",
      "published_date": "2024-03-03 15:53:41 UTC",
      "updated_date": "2024-03-12 09:49:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:03:31.774731"
    },
    {
      "arxiv_id": "2403.01533v1",
      "title": "Machine learning predicts long-term mortality after acute myocardial infarction using systolic time intervals and routinely collected clinical data",
      "title_zh": "翻译失败",
      "authors": [
        "Bijan Roudini",
        "Boshra Khajehpiri",
        "Hamid Abrishami Moghaddam",
        "Mohamad Forouzanfar"
      ],
      "abstract": "Precise estimation of cardiac patients' current and future comorbidities is\nan important factor in prioritizing continuous physiological monitoring and new\ntherapies. ML models have shown satisfactory performance in short-term\nmortality prediction of patients with heart disease, while their utility in\nlong-term predictions is limited. This study aims to investigate the\nperformance of tree-based ML models on long-term mortality prediction and the\neffect of two recently introduced biomarkers on long-term mortality. This study\nutilized publicly available data from CCHIA at the Ministry of Health and\nWelfare, Taiwan, China. Medical records were used to gather demographic and\nclinical data, including age, gender, BMI, percutaneous coronary intervention\n(PCI) status, and comorbidities such as hypertension, dyslipidemia, ST-segment\nelevation myocardial infarction (STEMI), and non-STEMI. Using medical and\ndemographic records as well as two recently introduced biomarkers, brachial\npre-ejection period (bPEP) and brachial ejection time (bET), collected from 139\npatients with acute myocardial infarction, we investigated the performance of\nadvanced ensemble tree-based ML algorithms (random forest, AdaBoost, and\nXGBoost) to predict all-cause mortality within 14 years. The developed ML\nmodels achieved significantly better performance compared to the baseline LR\n(C-Statistic, 0.80 for random forest, 0.79 for AdaBoost, and 0.78 for XGBoost,\nvs 0.77 for LR) (P-RF<0.001, PAdaBoost<0.001, PXGBoost<0.05). Adding bPEP and\nbET to our feature set significantly improved the algorithms' performance,\nleading to an absolute increase in C-Statistic of up to 0.03 (C-Statistic, 0.83\nfor random forest, 0.82 for AdaBoost, and 0.80 for XGBoost, vs 0.74 for LR)\n(P-RF<0.001, PAdaBoost<0.001, PXGBoost<0.05). This advancement may enable\nbetter treatment prioritization for high-risk individuals.",
      "tldr_zh": "本研究利用树-based 机器学习 (ML) 模型，包括 random forest、AdaBoost 和 XGBoost，基于常规临床数据（如年龄、性别、BMI 和共病信息）以及两个新生物标记 bPEP 和 bET，预测急性心肌梗死患者 14 年内的长程死亡率。实验使用台湾 CCHIA 数据集中的 139 名患者记录，结果显示这些模型的性能显著优于基准线性回归 (LR)，C-Statistic 分别为 0.80、0.79 和 0.78。加入 bPEP 和 bET 后，模型性能进一步提升，C-Statistic 最高达 0.83，这有助于更有效地优先考虑高风险个体的治疗策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication in \"Intelligent Medicine\"",
      "pdf_url": "http://arxiv.org/pdf/2403.01533v1",
      "published_date": "2024-03-03 15:23:49 UTC",
      "updated_date": "2024-03-03 15:23:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:03:44.788998"
    },
    {
      "arxiv_id": "2403.01528v2",
      "title": "Leveraging Biomolecule and Natural Language through Multi-Modal Learning: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Qizhi Pei",
        "Lijun Wu",
        "Kaiyuan Gao",
        "Jinhua Zhu",
        "Yue Wang",
        "Zun Wang",
        "Tao Qin",
        "Rui Yan"
      ],
      "abstract": "The integration of biomolecular modeling with natural language (BL) has\nemerged as a promising interdisciplinary area at the intersection of artificial\nintelligence, chemistry and biology. This approach leverages the rich,\nmultifaceted descriptions of biomolecules contained within textual data sources\nto enhance our fundamental understanding and enable downstream computational\ntasks such as biomolecule property prediction. The fusion of the nuanced\nnarratives expressed through natural language with the structural and\nfunctional specifics of biomolecules described via various molecular modeling\ntechniques opens new avenues for comprehensively representing and analyzing\nbiomolecules. By incorporating the contextual language data that surrounds\nbiomolecules into their modeling, BL aims to capture a holistic view\nencompassing both the symbolic qualities conveyed through language as well as\nquantitative structural characteristics. In this review, we provide an\nextensive analysis of recent advancements achieved through cross modeling of\nbiomolecules and natural language. (1) We begin by outlining the technical\nrepresentations of biomolecules employed, including sequences, 2D graphs, and\n3D structures. (2) We then examine in depth the rationale and key objectives\nunderlying effective multi-modal integration of language and molecular data\nsources. (3) We subsequently survey the practical applications enabled to date\nin this developing research area. (4) We also compile and summarize the\navailable resources and datasets to facilitate future work. (5) Looking ahead,\nwe identify several promising research directions worthy of further exploration\nand investment to continue advancing the field. The related resources and\ncontents are updating in\n\\url{https://github.com/QizhiPei/Awesome-Biomolecule-Language-Cross-Modeling}.",
      "tldr_zh": "这篇综述探讨了通过多-modal learning 整合生物分子建模和自然语言（BL）的最新进展，旨在利用文本数据增强对生物分子的理解并支持下游任务，如 biomolecule property prediction。论文首先概述了生物分子的技术表示，包括 sequences、2D graphs 和 3D structures，然后分析了多-modal 整合的理由、关键目标和实际应用。作者还总结了可用资源和数据集，并指出了未来的研究方向，如进一步探索交叉建模的潜力。相关资源持续更新于 GitHub 仓库。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.CL",
      "comment": "Survey Paper. 25 pages, 9 figures, and 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.01528v2",
      "published_date": "2024-03-03 14:59:47 UTC",
      "updated_date": "2024-03-05 11:12:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:03:55.510916"
    },
    {
      "arxiv_id": "2403.01510v1",
      "title": "End-to-End Human Instance Matting",
      "title_zh": "端到端人类实例抠图",
      "authors": [
        "Qinglin Liu",
        "Shengping Zhang",
        "Quanling Meng",
        "Bineng Zhong",
        "Peiqiang Liu",
        "Hongxun Yao"
      ],
      "abstract": "Human instance matting aims to estimate an alpha matte for each human\ninstance in an image, which is extremely challenging and has rarely been\nstudied so far. Despite some efforts to use instance segmentation to generate a\ntrimap for each instance and apply trimap-based matting methods, the resulting\nalpha mattes are often inaccurate due to inaccurate segmentation. In addition,\nthis approach is computationally inefficient due to multiple executions of the\nmatting method. To address these problems, this paper proposes a novel\nEnd-to-End Human Instance Matting (E2E-HIM) framework for simultaneous multiple\ninstance matting in a more efficient manner. Specifically, a general perception\nnetwork first extracts image features and decodes instance contexts into latent\ncodes. Then, a united guidance network exploits spatial attention and semantics\nembedding to generate united semantics guidance, which encodes the locations\nand semantic correspondences of all instances. Finally, an instance matting\nnetwork decodes the image features and united semantics guidance to predict all\ninstance-level alpha mattes. In addition, we construct a large-scale human\ninstance matting dataset (HIM-100K) comprising over 100,000 human images with\ninstance alpha matte labels. Experiments on HIM-100K demonstrate the proposed\nE2E-HIM outperforms the existing methods on human instance matting with 50%\nlower errors and 5X faster speed (6 instances in a 640X640 image). Experiments\non the PPM-100, RWP-636, and P3M datasets demonstrate that E2E-HIM also\nachieves competitive performance on traditional human matting.",
      "tldr_zh": "这篇论文针对人类实例抠图（Human Instance Matting）问题，提出了一种新型端到端框架 End-to-End Human Instance Matting (E2E-HIM)，能够同时高效处理图像中多个实例的 alpha matte 估计，解决传统方法依赖实例分割导致的准确性低和计算效率问题。E2E-HIM 包括一般感知网络提取图像特征和实例上下文、统一指导网络利用 spatial attention 和 semantics embedding 生成实例位置及语义对应指导，以及实例抠图网络预测所有实例级 alpha mattes。该框架还构建了大型数据集 HIM-100K，包含超过 10 万张人类图像及其 alpha matte 标签。实验结果显示，E2E-HIM 在 HIM-100K 上比现有方法错误率降低 50%、速度提高 5 倍，并在 PPM-100、RWP-636 和 P3M 数据集上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01510v1",
      "published_date": "2024-03-03 13:17:10 UTC",
      "updated_date": "2024-03-03 13:17:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:04:10.725945"
    },
    {
      "arxiv_id": "2403.01508v1",
      "title": "Soft Reasoning on Uncertain Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Weizhi Fei",
        "Zihao Wang",
        "Hang Yin",
        "Yang Duan",
        "Hanghang Tong",
        "Yangqiu Song"
      ],
      "abstract": "The study of machine learning-based logical query-answering enables reasoning\nwith large-scale and incomplete knowledge graphs. This paper further advances\nthis line of research by considering the uncertainty in the knowledge. The\nuncertain nature of knowledge is widely observed in the real world, but\n\\textit{does not} align seamlessly with the first-order logic underpinning\nexisting studies. To bridge this gap, we study the setting of soft queries on\nuncertain knowledge, which is motivated by the establishment of soft constraint\nprogramming. We further propose an ML-based approach with both forward\ninference and backward calibration to answer soft queries on large-scale,\nincomplete, and uncertain knowledge graphs. Theoretical discussions present\nthat our methods share the same complexity as state-of-the-art inference\nalgorithms for first-order queries. Empirical results justify the superior\nperformance of our approach against previous ML-based methods with number\nembedding extensions.",
      "tldr_zh": "该论文探讨了在不确定知识图谱(Knowledge Graphs)上进行软推理(Soft Reasoning)，以解决现有基于一阶逻辑的查询回答方法无法处理知识不确定性的问题。作者引入软查询(Soft Queries)的概念，受软约束编程启发，并提出一种机器学习方法，结合前向推理(Forward Inference)和后向校准(Backward Calibration)，适用于大规模、不完整和不确定的知识图谱。理论分析显示，该方法的复杂度与现有一阶查询推理算法相当，而实验结果证明其性能优于基于数字嵌入扩展的先前机器学习方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.01508v1",
      "published_date": "2024-03-03 13:13:53 UTC",
      "updated_date": "2024-03-03 13:13:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:04:20.373828"
    },
    {
      "arxiv_id": "2403.01489v1",
      "title": "Regeneration Based Training-free Attribution of Fake Images Generated by Text-to-Image Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Meiling Li",
        "Zhenxing Qian",
        "Xinpeng Zhang"
      ],
      "abstract": "Text-to-image generative models have recently garnered significant attention\ndue to their ability to generate images based on prompt descriptions. While\nthese models have shown promising performance, concerns have been raised\nregarding the potential misuse of the generated fake images. In response to\nthis, we have presented a simple yet effective training-free method to\nattribute fake images generated by text-to-image models to their source models.\nGiven a test image to be attributed, we first inverse the textual prompt of the\nimage, and then put the reconstructed prompt into different candidate models to\nregenerate candidate fake images. By calculating and ranking the similarity of\nthe test image and the candidate images, we can determine the source of the\nimage. This attribution allows model owners to be held accountable for any\nmisuse of their models. Note that our approach does not limit the number of\ncandidate text-to-image generative models. Comprehensive experiments reveal\nthat (1) Our method can effectively attribute fake images to their source\nmodels, achieving comparable attribution performance with the state-of-the-art\nmethod; (2) Our method has high scalability ability, which is well adapted to\nreal-world attribution scenarios. (3) The proposed method yields satisfactory\nrobustness to common attacks, such as Gaussian blurring, JPEG compression, and\nResizing. We also analyze the factors that influence the attribution\nperformance, and explore the boost brought by the proposed method as a plug-in\nto improve the performance of existing SOTA. We hope our work can shed some\nlight on the solutions to addressing the source of AI-generated images, as well\nas to prevent the misuse of text-to-image generative models.",
      "tldr_zh": "这篇论文提出了一种基于再生成的无需训练（training-free）方法，用于追踪文本到图像生成模型（text-to-image generative models）生成的假图像来源。具体来说，该方法先逆向重建测试图像的文本提示，然后将提示输入候选模型生成候选图像，并通过计算图像相似度排名来确定原模型。实验结果显示，该方法在归因性能上与最先进（state-of-the-art）方法相当，具有高可扩展性和对常见攻击（如Gaussian blurring、JPEG compression和Resizing）的鲁棒性，并能作为插件提升现有技术的性能。该工作旨在促进AI生成图像来源的追踪，并防止文本到图像模型的滥用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01489v1",
      "published_date": "2024-03-03 11:55:49 UTC",
      "updated_date": "2024-03-03 11:55:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:04:32.454720"
    },
    {
      "arxiv_id": "2403.01479v3",
      "title": "Align-to-Distill: Trainable Attention Alignment for Knowledge Distillation in Neural Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Heegon Jin",
        "Seonil Son",
        "Jemin Park",
        "Youngseok Kim",
        "Hyungjong Noh",
        "Yeonsoo Lee"
      ],
      "abstract": "The advent of scalable deep models and large datasets has improved the\nperformance of Neural Machine Translation. Knowledge Distillation (KD) enhances\nefficiency by transferring knowledge from a teacher model to a more compact\nstudent model. However, KD approaches to Transformer architecture often rely on\nheuristics, particularly when deciding which teacher layers to distill from. In\nthis paper, we introduce the 'Align-to-Distill' (A2D) strategy, designed to\naddress the feature mapping problem by adaptively aligning student attention\nheads with their teacher counterparts during training. The Attention Alignment\nModule in A2D performs a dense head-by-head comparison between student and\nteacher attention heads across layers, turning the combinatorial mapping\nheuristics into a learning problem. Our experiments show the efficacy of A2D,\ndemonstrating gains of up to +3.61 and +0.63 BLEU points for WMT-2022 De->Dsb\nand WMT-2014 En->De, respectively, compared to Transformer baselines.",
      "tldr_zh": "本论文提出了一种名为Align-to-Distill (A2D)的策略，用于优化Transformer架构中的Knowledge Distillation (KD)，通过自适应地对齐学生模型的注意力头与教师模型的对应头，解决特征映射的启发式依赖问题。A2D引入Attention Alignment Module，在训练过程中进行层间注意力头的密集比较，将传统的组合映射转化为可学习的任务，从而提升学生模型的性能。实验结果显示，该方法在WMT-2022 De->Dsb任务上提升高达+3.61 BLEU分数，在WMT-2014 En->De任务上提升+0.63 BLEU分数，相比Transformer基线取得了显著改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.01479v3",
      "published_date": "2024-03-03 11:13:44 UTC",
      "updated_date": "2024-03-25 08:46:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:04:44.281856"
    },
    {
      "arxiv_id": "2403.01475v1",
      "title": "Representation Learning on Heterophilic Graph with Directional Neighborhood Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Qincheng Lu",
        "Jiaqi Zhu",
        "Sitao Luan",
        "Xiao-Wen Chang"
      ],
      "abstract": "Graph Attention Network (GAT) is one of the most popular Graph Neural Network\n(GNN) architecture, which employs the attention mechanism to learn edge weights\nand has demonstrated promising performance in various applications. However,\nsince it only incorporates information from immediate neighborhood, it lacks\nthe ability to capture long-range and global graph information, leading to\nunsatisfactory performance on some datasets, particularly on heterophilic\ngraphs. To address this limitation, we propose the Directional Graph Attention\nNetwork (DGAT) in this paper. DGAT is able to combine the feature-based\nattention with the global directional information extracted from the graph\ntopology. To this end, a new class of Laplacian matrices is proposed which can\nprovably reduce the diffusion distance between nodes. Based on the new\nLaplacian, topology-guided neighbour pruning and edge adding mechanisms are\nproposed to remove the noisy and capture the helpful long-range neighborhood\ninformation. Besides, a global directional attention is designed to enable a\ntopological-aware information propagation. The superiority of the proposed DGAT\nover the baseline GAT has also been verified through experiments on real-world\nbenchmarks and synthetic data sets. It also outperforms the state-of-the-art\n(SOTA) models on 6 out of 7 real-world benchmark datasets.",
      "tldr_zh": "该论文针对 Graph Attention Network (GAT) 在异质图 (heterophilic graphs) 上表现不佳的问题，提出了一种新的 Directional Graph Attention Network (DGAT)，通过结合特征-based 注意力机制和从图拓扑中提取的全局方向信息来捕捉长程和全局图信息。DGAT 引入了一种新的 Laplacian matrices，以减少节点间的扩散距离，并设计了拓扑引导的邻居修剪和边添加机制，以去除噪声并获取有用的长程邻居信息，同时实现了全局方向注意力以支持拓扑感知的信息传播。实验结果显示，DGAT 在 7 个真实世界基准数据集中的 6 个上超越了最先进 (SOTA) 模型，并在合成数据集上优于基线 GAT，从而提升了异质图的表示学习性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01475v1",
      "published_date": "2024-03-03 10:59:16 UTC",
      "updated_date": "2024-03-03 10:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:04:57.152695"
    },
    {
      "arxiv_id": "2403.06996v1",
      "title": "On the stochastics of human and artificial creativity",
      "title_zh": "翻译失败",
      "authors": [
        "Solve Sæbø",
        "Helge Brovold"
      ],
      "abstract": "What constitutes human creativity, and is it possible for computers to\nexhibit genuine creativity? We argue that achieving human-level intelligence in\ncomputers, or so-called Artificial General Intelligence, necessitates attaining\nalso human-level creativity. We contribute to this discussion by developing a\nstatistical representation of human creativity, incorporating prior insights\nfrom stochastic theory, psychology, philosophy, neuroscience, and chaos theory.\nThis highlights the stochastic nature of the human creative process, which\nincludes both a bias guided, random proposal step, and an evaluation step\ndepending on a flexible or transformable bias structure. The acquired\nrepresentation of human creativity is subsequently used to assess the\ncreativity levels of various contemporary AI systems. Our analysis includes\nmodern AI algorithms such as reinforcement learning, diffusion models, and\nlarge language models, addressing to what extent they measure up to human level\ncreativity. We conclude that these technologies currently lack the capability\nfor autonomous creative action at a human level.",
      "tldr_zh": "本论文探讨了人类创造力的本质及其与人工智能的关系，主张实现人工通用智能(Artificial General Intelligence, AGI)需达到人类水平的创造力。作者开发了一个统计表示(statistical representation)，整合随机理论(stochastic theory)、心理学、哲学、神经科学和混沌理论(chaos theory)，强调人类创造过程的随机性，包括带有偏差的随机提议步骤和灵活的评估步骤。通过评估当代AI系统，如强化学习(reinforcement learning)、扩散模型(diffusion models)和大语言模型(large language models)，论文发现这些技术目前无法实现人类水平的自主创造行动。",
      "categories": [
        "cs.AI",
        "34, 37, 60, 62",
        "G.1.7; G.3; I.2; J.4; J.5"
      ],
      "primary_category": "cs.AI",
      "comment": "40 pages, 1 figure with 2 sub-figures",
      "pdf_url": "http://arxiv.org/pdf/2403.06996v1",
      "published_date": "2024-03-03 10:38:57 UTC",
      "updated_date": "2024-03-03 10:38:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:05:10.654696"
    },
    {
      "arxiv_id": "2403.10538v1",
      "title": "MATADOR: Automated System-on-Chip Tsetlin Machine Design Generation for Edge Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Tousif Rahman",
        "Gang Mao",
        "Sidharth Maheshwari",
        "Rishad Shafik",
        "Alex Yakovlev"
      ],
      "abstract": "System-on-Chip Field-Programmable Gate Arrays (SoC-FPGAs) offer significant\nthroughput gains for machine learning (ML) edge inference applications via the\ndesign of co-processor accelerator systems. However, the design effort for\ntraining and translating ML models into SoC-FPGA solutions can be substantial\nand requires specialist knowledge aware trade-offs between model performance,\npower consumption, latency and resource utilization. Contrary to other ML\nalgorithms, Tsetlin Machine (TM) performs classification by forming logic\nproposition between boolean actions from the Tsetlin Automata (the learning\nelements) and boolean input features. A trained TM model, usually, exhibits\nhigh sparsity and considerable overlapping of these logic propositions both\nwithin and among the classes. The model, thus, can be translated to RTL-level\ndesign using a miniscule number of AND and NOT gates. This paper presents\nMATADOR, an automated boolean-to-silicon tool with GUI interface capable of\nimplementing optimized accelerator design of the TM model onto SoC-FPGA for\ninference at the edge. It offers automation of the full development pipeline:\nmodel training, system level design generation, design verification and\ndeployment. It makes use of the logic sharing that ensues from propositional\noverlap and creates a compact design by effectively utilizing the TM model's\nsparsity. MATADOR accelerator designs are shown to be up to 13.4x faster, up to\n7x more resource frugal and up to 2x more power efficient when compared to the\nstate-of-the-art Quantized and Binary Deep Neural Network implementations.",
      "tldr_zh": "本研究引入了 MATADOR，一种自动化工具，用于将 Tsetlin Machine (TM) 模型生成优化后的 System-on-Chip (SoC) 加速器设计，针对边缘应用的机器学习推理。MATADOR 通过 GUI 接口自动化整个开发流程，包括模型训练、系统级设计生成、设计验证和部署，利用 TM 的高稀疏性和逻辑命题重叠，仅需少量 AND 和 NOT 门实现 RTL-level 设计，从而创建紧凑高效的 SoC-FPGA 加速器。与现有 Quantized and Binary Deep Neural Network 实现相比，实验结果显示 MATADOR 的设计速度提升高达 13.4 倍、资源利用率节省高达 7 倍、功耗效率提高高达 2 倍。总的来说，该工具简化了边缘推理的部署过程，降低了专业知识门槛。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10538v1",
      "published_date": "2024-03-03 10:31:46 UTC",
      "updated_date": "2024-03-03 10:31:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:05:21.792782"
    },
    {
      "arxiv_id": "2403.01467v1",
      "title": "Collaborate to Adapt: Source-Free Graph Domain Adaptation via Bi-directional Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Zhang",
        "Meihan Liu",
        "Anhui Wang",
        "Hongyang Chen",
        "Zhao Li",
        "Jiajun Bu",
        "Bingsheng He"
      ],
      "abstract": "Unsupervised Graph Domain Adaptation (UGDA) has emerged as a practical\nsolution to transfer knowledge from a label-rich source graph to a completely\nunlabelled target graph. However, most methods require a labelled source graph\nto provide supervision signals, which might not be accessible in the real-world\nsettings due to regulations and privacy concerns. In this paper, we explore the\nscenario of source-free unsupervised graph domain adaptation, which tries to\naddress the domain adaptation problem without accessing the labelled source\ngraph. Specifically, we present a novel paradigm called GraphCTA, which\nperforms model adaptation and graph adaptation collaboratively through a series\nof procedures: (1) conduct model adaptation based on node's neighborhood\npredictions in target graph considering both local and global information; (2)\nperform graph adaptation by updating graph structure and node attributes via\nneighborhood contrastive learning; and (3) the updated graph serves as an input\nto facilitate the subsequent iteration of model adaptation, thereby\nestablishing a collaborative loop between model adaptation and graph\nadaptation. Comprehensive experiments are conducted on various public datasets.\nThe experimental results demonstrate that our proposed model outperforms recent\nsource-free baselines by large margins.",
      "tldr_zh": "该研究探讨了源-free 无监督图域适应（UGDA），旨在在无法访问带标签源图的情况下，将知识转移到无标签目标图。作者提出了 GraphCTA 框架，通过双向适应机制协作进行模型适应（基于节点的邻域预测，结合局部和全局信息）和图适应（通过邻域对比学习更新图结构及节点属性），形成迭代循环以提升适应效果。在多个公共数据集上的实验表明，GraphCTA 显著优于现有源-free 基线模型，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by WWW-2024",
      "pdf_url": "http://arxiv.org/pdf/2403.01467v1",
      "published_date": "2024-03-03 10:23:08 UTC",
      "updated_date": "2024-03-03 10:23:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:05:33.176313"
    },
    {
      "arxiv_id": "2403.01456v1",
      "title": "Controlling Cloze-test Question Item Difficulty with PLM-based Surrogate Models for IRT Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Jingshen Zhang",
        "Jiajun Xie",
        "Xinying Qiu"
      ],
      "abstract": "Item difficulty plays a crucial role in adaptive testing. However, few works\nhave focused on generating questions of varying difficulty levels, especially\nfor multiple-choice (MC) cloze tests. We propose training pre-trained language\nmodels (PLMs) as surrogate models to enable item response theory (IRT)\nassessment, avoiding the need for human test subjects. We also propose two\nstrategies to control the difficulty levels of both the gaps and the\ndistractors using ranking rules to reduce invalid distractors. Experimentation\non a benchmark dataset demonstrates that our proposed framework and methods can\neffectively control and evaluate the difficulty levels of MC cloze tests.",
      "tldr_zh": "本研究探讨了如何使用基于预训练语言模型 (PLMs) 的代理模型来控制多项选择 (MC) 填空测试题目的难度，以支持项目反应理论 (IRT) 评估，从而避免依赖人类受试者。研究提出两种策略，通过排名规则分别调整空格和干扰项的难度水平，以减少无效干扰项。在基准数据集上的实验证明，该框架和方法能够有效控制和评估 MC 填空测试的难度，从而提升自适应测试的效率和准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01456v1",
      "published_date": "2024-03-03 09:18:05 UTC",
      "updated_date": "2024-03-03 09:18:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:05:43.542869"
    },
    {
      "arxiv_id": "2403.01437v2",
      "title": "GPTSee: Enhancing Moment Retrieval and Highlight Detection via Description-Based Similarity Features",
      "title_zh": "GPTSee: 通过",
      "authors": [
        "Yunzhuo Sun",
        "Yifang Xu",
        "Zien Xie",
        "Yukun Shu",
        "Sidan Du"
      ],
      "abstract": "Moment retrieval (MR) and highlight detection (HD) aim to identify relevant\nmoments and highlights in video from corresponding natural language query.\nLarge language models (LLMs) have demonstrated proficiency in various computer\nvision tasks. However, existing methods for MR\\&HD have not yet been integrated\nwith LLMs. In this letter, we propose a novel two-stage model that takes the\noutput of LLMs as the input to the second-stage transformer encoder-decoder.\nFirst, MiniGPT-4 is employed to generate the detailed description of the video\nframe and rewrite the query statement, fed into the encoder as new features.\nThen, semantic similarity is computed between the generated description and the\nrewritten queries. Finally, continuous high-similarity video frames are\nconverted into span anchors, serving as prior position information for the\ndecoder. Experiments demonstrate that our approach achieves a state-of-the-art\nresult, and by using only span anchors and similarity scores as outputs,\npositioning accuracy outperforms traditional methods, like Moment-DETR.",
      "tldr_zh": "这篇论文提出了 GPTSee，一种通过基于描述的相似性特征来增强 Moment Retrieval (MR) 和 Highlight Detection (HD) 的方法，旨在从视频中识别与自然语言查询相关的时刻和亮点。模型采用两阶段设计：首先使用 MiniGPT-4 生成视频帧的详细描述并重写查询语句，然后计算语义相似度，并将连续高相似度帧转换为 span anchors，作为 transformer encoder-decoder 的先验位置信息。主要实验结果显示，GPTSee 达到了最先进水平，仅凭 span anchors 和相似度分数，其定位准确性超过了传统方法如 Moment-DETR。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.01437v2",
      "published_date": "2024-03-03 08:24:28 UTC",
      "updated_date": "2024-03-10 09:56:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:05:57.177821"
    },
    {
      "arxiv_id": "2403.04787v2",
      "title": "Ever-Evolving Memory by Blending and Refining the Past",
      "title_zh": "翻译失败",
      "authors": [
        "Seo Hyun Kim",
        "Keummin Ka",
        "Yohan Jo",
        "Seung-won Hwang",
        "Dongha Lee",
        "Jinyoung Yeo"
      ],
      "abstract": "For a human-like chatbot, constructing a long-term memory is crucial.\nHowever, current large language models often lack this capability, leading to\ninstances of missing important user information or redundantly asking for the\nsame information, thereby diminishing conversation quality. To effectively\nconstruct memory, it is crucial to seamlessly connect past and present\ninformation, while also possessing the ability to forget obstructive\ninformation. To address these challenges, we propose CREEM, a novel memory\nsystem for long-term conversation. Improving upon existing approaches that\nconstruct memory based solely on current sessions, CREEM blends past memories\nduring memory formation. Additionally, we introduce a refining process to\nhandle redundant or outdated information. Unlike traditional paradigms, we view\nresponding and memory construction as inseparable tasks. The blending process,\nwhich creates new memories, also serves as a reasoning step for response\ngeneration by informing the connection between past and present. Through\nevaluation, we demonstrate that CREEM enhances both memory and response\nqualities in multi-session personalized dialogues.",
      "tldr_zh": "该论文探讨了大型语言模型在对话中缺乏长期记忆的问题，导致遗漏用户信息或重复询问，从而影响对话质量。为解决此，作者提出了一种名为CREEM的记忆系统，该系统在记忆形成过程中通过blending past memories来融合过去信息，并引入refining process来处理冗余或过时内容。CREEM将响应生成与记忆构建视为一体化的任务，利用blending作为推理步骤，以连接过去和现在信息；实验结果显示，该系统显著提升了多会话个性化对话的记忆和响应质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 4 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.04787v2",
      "published_date": "2024-03-03 08:12:59 UTC",
      "updated_date": "2024-04-07 04:31:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:06:08.061750"
    },
    {
      "arxiv_id": "2403.06995v1",
      "title": "Exact algorithms and heuristics for capacitated covering salesman problems",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Porto Maziero",
        "Fábio Luiz Usberti",
        "Celso Cavellucci"
      ],
      "abstract": "This paper introduces the Capacitated Covering Salesman Problem (CCSP),\napproaching the notion of service by coverage in capacitated vehicle routing\nproblems. In CCSP, locations where vehicles can transit are provided, some of\nwhich have customers with demands. The objective is to service customers\nthrough a fleet of vehicles based in a depot, minimizing the total distance\ntraversed by the vehicles. CCSP is unique in the sense that customers, to be\nserviced, do not need to be visited by a vehicle. Instead, they can be serviced\nif they are within a coverage area of the vehicle. This assumption is motivated\nby applications in which some customers are unreachable (e.g., forbidden access\nto vehicles) or visiting every customer is impractical. In this work,\noptimization methodologies are proposed for the CCSP based on ILP (Integer\nLinear Programming) and BRKGA (Biased Random-Key Genetic Algorithm)\nmetaheuristic. Computational experiments conducted on a benchmark of instances\nfor the CCSP evaluate the performance of the methodologies with respect to\nprimal bounds. Furthermore, our ILP formulation is extended in order to create\na novel MILP (Mixed Integer Linear Programming) for the Multi-Depot Covering\nTour Vehicle Routing Problem (MDCTVRP). Computational experiments show that the\nextended MILP formulation outperformed the previous state-of-the-art exact\napproach with respect to optimality gaps. In particular, optimal solutions were\nobtained for several previously unsolved instances.",
      "tldr_zh": "本研究引入了Capacitated Covering Salesman Problem (CCSP)，一种新型的车辆路径问题，其中车辆无需直接访问客户，只需确保客户在覆盖范围内即可服务，从而最小化总行驶距离。该问题适用于客户不可达或访问不切实际的场景。研究提出基于ILP (Integer Linear Programming)和BRKGA (Biased Random-Key Genetic Algorithm) metaheuristic的优化方法，并通过计算实验在基准实例上评估了这些方法的性能。进一步扩展ILP制定了一个新的MILP (Mixed Integer Linear Programming)模型，用于Multi-Depot Covering Tour Vehicle Routing Problem (MDCTVRP)，实验结果显示该模型在optimality gaps上优于现有精确方法，并成功求解了多个之前未解决的实例。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.06995v1",
      "published_date": "2024-03-03 07:50:29 UTC",
      "updated_date": "2024-03-03 07:50:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:06:20.988990"
    },
    {
      "arxiv_id": "2403.05584v1",
      "title": "Time2Stop: Adaptive and Explainable Human-AI Loop for Smartphone Overuse Intervention",
      "title_zh": "翻译失败",
      "authors": [
        "Adiba Orzikulova",
        "Han Xiao",
        "Zhipeng Li",
        "Yukang Yan",
        "Yuntao Wang",
        "Yuanchun Shi",
        "Marzyeh Ghassemi",
        "Sung-Ju Lee",
        "Anind K Dey",
        "Xuhai \"Orson\" Xu"
      ],
      "abstract": "Despite a rich history of investigating smartphone overuse intervention\ntechniques, AI-based just-in-time adaptive intervention (JITAI) methods for\noveruse reduction are lacking. We develop Time2Stop, an intelligent, adaptive,\nand explainable JITAI system that leverages machine learning to identify\noptimal intervention timings, introduces interventions with transparent AI\nexplanations, and collects user feedback to establish a human-AI loop and adapt\nthe intervention model over time. We conducted an 8-week field experiment\n(N=71) to evaluate the effectiveness of both the adaptation and explanation\naspects of Time2Stop. Our results indicate that our adaptive models\nsignificantly outperform the baseline methods on intervention accuracy (>32.8\\%\nrelatively) and receptivity (>8.0\\%). In addition, incorporating explanations\nfurther enhances the effectiveness by 53.8\\% and 11.4\\% on accuracy and\nreceptivity, respectively. Moreover, Time2Stop significantly reduces overuse,\ndecreasing app visit frequency by 7.0$\\sim$8.9\\%. Our subjective data also\nechoed these quantitative measures. Participants preferred the adaptive\ninterventions and rated the system highly on intervention time accuracy,\neffectiveness, and level of trust. We envision our work can inspire future\nresearch on JITAI systems with a human-AI loop to evolve with users.",
      "tldr_zh": "本文提出 Time2Stop 系统，这是一个智能、适应性和可解释的 JITAI（just-in-time adaptive intervention）框架，旨在通过机器学习识别最佳干预时机、提供透明 AI 解释并建立 human-AI loop 来减少智能手机过度使用。系统在 8 周现场实验（N=71）中显示，适应模型在干预准确性和接受度上分别比基线提高了 32.8% 和 8.0%，而加入解释进一步提升了准确性 53.8% 和接受度 11.4%。结果表明，Time2Stop 显著降低了 app 访问频率 7.0~8.9%，并获得了参与者对系统准确性、有效性和信任度的积极反馈。该研究有望激发未来 JITAI 系统的发展，以 human-AI loop 实现持续演进。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.05584v1",
      "published_date": "2024-03-03 06:57:48 UTC",
      "updated_date": "2024-03-03 06:57:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:06:35.146568"
    },
    {
      "arxiv_id": "2403.01413v1",
      "title": "Exploring the Design of Generative AI in Supporting Music-based Reminiscence for Older Adults",
      "title_zh": "翻译失败",
      "authors": [
        "Yucheng Jin",
        "Wanling Cai",
        "Li Chen",
        "Yizhe Zhang",
        "Gavin Doherty",
        "Tonglin Jiang"
      ],
      "abstract": "Music-based reminiscence has the potential to positively impact the\npsychological well-being of older adults. However, the aging process and\nphysiological changes, such as memory decline and limited verbal communication,\nmay impede the ability of older adults to recall their memories and life\nexperiences. Given the advanced capabilities of generative artificial\nintelligence (AI) systems, such as generated conversations and images, and\ntheir potential to facilitate the reminiscing process, this study aims to\nexplore the design of generative AI to support music-based reminiscence in\nolder adults. This study follows a user-centered design approach incorporating\nvarious stages, including detailed interviews with two social workers and two\ndesign workshops (involving ten older adults). Our work contributes to an\nin-depth understanding of older adults' attitudes toward utilizing generative\nAI for supporting music-based reminiscence and identifies concrete design\nconsiderations for the future design of generative AI to enhance the\nreminiscence experience of older adults.",
      "tldr_zh": "这篇论文探讨了生成式 AI 在支持老年人的音乐-based reminiscence（音乐回忆）方面的设计潜力，以改善他们的心理健康，因为衰老因素如记忆衰退和语言交流限制可能阻碍回忆过程。研究采用用户-centered design（用户中心设计）方法，包括对两名社会工作者的详细采访和涉及十名老年人的设计工作坊。论文的主要贡献在于深入理解老年人对生成式 AI 的态度，并提出具体的设计考虑，以增强音乐-based reminiscence 的体验。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01413v1",
      "published_date": "2024-03-03 06:53:04 UTC",
      "updated_date": "2024-03-03 06:53:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:06:43.847787"
    },
    {
      "arxiv_id": "2403.01407v1",
      "title": "Region-Transformer: Self-Attention Region Based Class-Agnostic Point Cloud Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Dipesh Gyawali",
        "Jian Zhang",
        "BB Karki"
      ],
      "abstract": "Point cloud segmentation, which helps us understand the environment of\nspecific structures and objects, can be performed in class-specific and\nclass-agnostic ways. We propose a novel region-based transformer model called\nRegion-Transformer for performing class-agnostic point cloud segmentation. The\nmodel utilizes a region-growth approach and self-attention mechanism to\niteratively expand or contract a region by adding or removing points. It is\ntrained on simulated point clouds with instance labels only, avoiding semantic\nlabels. Attention-based networks have succeeded in many previous methods of\nperforming point cloud segmentation. However, a region-growth approach with\nattention-based networks has yet to be used to explore its performance gain. To\nour knowledge, we are the first to use a self-attention mechanism in a\nregion-growth approach. With the introduction of self-attention to\nregion-growth that can utilize local contextual information of neighborhood\npoints, our experiments demonstrate that the Region-Transformer model\noutperforms previous class-agnostic and class-specific methods on indoor\ndatasets regarding clustering metrics. The model generalizes well to\nlarge-scale scenes. Key advantages include capturing long-range dependencies\nthrough self-attention, avoiding the need for semantic labels during training,\nand applicability to a variable number of objects. The Region-Transformer model\nrepresents a promising approach for flexible point cloud segmentation with\napplications in robotics, digital twinning, and autonomous vehicles.",
      "tldr_zh": "本文提出了一种名为 Region-Transformer 的新型 transformer 模型，用于 class-agnostic point cloud segmentation，通过 region-growth approach 和 self-attention 机制迭代地添加或移除点来扩展或收缩区域，仅需使用模拟 point clouds 的 instance labels 进行训练，而无需 semantic labels。  \n该模型首次将 self-attention 机制应用于 region-growth 方法，利用局部和全局上下文信息捕捉 long-range dependencies，并在实验中在室内数据集上超越了之前的 class-agnostic 和 class-specific 方法，在 clustering metrics 方面表现出色。  \nRegion-Transformer 具有良好的泛化能力，适用于大规模场景，并具有避免语义标签需求和处理可变数量对象的优势，适用于 robotics、digital twinning 和 autonomous vehicles 等领域。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.01407v1",
      "published_date": "2024-03-03 06:13:43 UTC",
      "updated_date": "2024-03-03 06:13:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:06:57.885355"
    },
    {
      "arxiv_id": "2403.01400v1",
      "title": "Decoupling Weighing and Selecting for Integrating Multiple Graph Pre-training Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyu Fan",
        "Lirong Wu",
        "Yufei Huang",
        "Haitao Lin",
        "Cheng Tan",
        "Zhangyang Gao",
        "Stan Z. Li"
      ],
      "abstract": "Recent years have witnessed the great success of graph pre-training for graph\nrepresentation learning. With hundreds of graph pre-training tasks proposed,\nintegrating knowledge acquired from multiple pre-training tasks has become a\npopular research topic. In this paper, we identify two important collaborative\nprocesses for this topic: (1) select: how to select an optimal task combination\nfrom a given task pool based on their compatibility, and (2) weigh: how to\nweigh the selected tasks based on their importance. While there currently has\nbeen a lot of work focused on weighing, comparatively little effort has been\ndevoted to selecting. This paper proposes a novel instance-level framework for\nintegrating multiple graph pre-training tasks, Weigh And Select (WAS), where\nthe two collaborative processes, weighing and selecting, are combined by\ndecoupled siamese networks. Specifically, it first adaptively learns an optimal\ncombination of tasks for each instance from a given task pool, based on which a\ncustomized instance-level task weighing strategy is learned. Extensive\nexperiments on 16 graph datasets across node-level and graph-level downstream\ntasks have demonstrated that by combining a few simple but classical tasks, WAS\ncan achieve comparable performance to other leading counterparts. The code is\navailable at https://github.com/TianyuFan0504/WAS.",
      "tldr_zh": "该论文探讨了整合多个图预训练任务（graph pre-training tasks）的关键挑战，识别出两个核心过程：select（基于兼容性选择最佳任务组合）和weigh（基于重要性权衡任务）。作者提出了一种新框架Weigh And Select (WAS)，利用decoupled siamese networks将这两个过程解耦并结合，实现实例级别的任务自适应选择和自定义权衡策略。实验结果显示，在16个图数据集上的节点级和图级下游任务中，WAS通过结合简单经典任务，性能可与领先方法媲美。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.01400v1",
      "published_date": "2024-03-03 05:29:49 UTC",
      "updated_date": "2024-03-03 05:29:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:07:08.579863"
    },
    {
      "arxiv_id": "2403.01384v2",
      "title": "On the Compressibility of Quantized Large Language Models",
      "title_zh": "关于量化大语言模型的可压缩性",
      "authors": [
        "Yu Mao",
        "Weilan Wang",
        "Hongchao Du",
        "Nan Guan",
        "Chun Jason Xue"
      ],
      "abstract": "Deploying Large Language Models (LLMs) on edge or mobile devices offers\nsignificant benefits, such as enhanced data privacy and real-time processing\ncapabilities. However, it also faces critical challenges due to the substantial\nmemory requirement of LLMs. Quantization is an effective way of reducing the\nmodel size while maintaining good performance. However, even after\nquantization, LLMs may still be too big to fit entirely into the limited memory\nof edge or mobile devices and have to be partially loaded from the storage to\ncomplete the inference. In this case, the I/O latency of model loading becomes\nthe bottleneck of the LLM inference latency. In this work, we take a\npreliminary step of studying applying data compression techniques to reduce\ndata movement and thus speed up the inference of quantized LLM on\nmemory-constrained devices. In particular, we discussed the compressibility of\nquantized LLMs, the trade-off between the compressibility and performance of\nquantized LLMs, and opportunities to optimize both of them jointly.",
      "tldr_zh": "本研究探讨了在内存受限的边缘或移动设备上部署量化Large Language Models (LLMs)的挑战，特别是模型大小导致的I/O延迟问题。作者提出通过应用数据压缩技术来减少数据移动，从而加速量化LLMs的推理过程，并分析了quantized LLMs的可压缩性（compressibility）。实验讨论了compressibility与模型性能之间的权衡，以及联合优化二者的潜在机会，为提升LLMs在资源有限设备上的部署效率提供了初步见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01384v2",
      "published_date": "2024-03-03 03:27:07 UTC",
      "updated_date": "2024-05-06 02:29:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:07:20.171893"
    },
    {
      "arxiv_id": "2403.01369v1",
      "title": "A Closer Look at Wav2Vec2 Embeddings for On-Device Single-Channel Speech Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Ravi Shankar",
        "Ke Tan",
        "Buye Xu",
        "Anurag Kumar"
      ],
      "abstract": "Self-supervised learned models have been found to be very effective for\ncertain speech tasks such as automatic speech recognition, speaker\nidentification, keyword spotting and others. While the features are undeniably\nuseful in speech recognition and associated tasks, their utility in speech\nenhancement systems is yet to be firmly established, and perhaps not properly\nunderstood. In this paper, we investigate the uses of SSL representations for\nsingle-channel speech enhancement in challenging conditions and find that they\nadd very little value for the enhancement task. Our constraints are designed\naround on-device real-time speech enhancement -- model is causal, the compute\nfootprint is small. Additionally, we focus on low SNR conditions where such\nmodels struggle to provide good enhancement. In order to systematically examine\nhow SSL representations impact performance of such enhancement models, we\npropose a variety of techniques to utilize these embeddings which include\ndifferent forms of knowledge-distillation and pre-training.",
      "tldr_zh": "本文深入探讨了 Wav2Vec2 嵌入在设备端单通道语音增强中的应用，针对自监督学习 (SSL) 表示在低 SNR 条件下的效用进行系统调查。研究者提出多种技术，包括不同形式的知识蒸馏 (knowledge-distillation) 和预训练 (pre-training)，以整合这些嵌入，同时确保模型因果性 (causal) 和小计算开销。结果表明，Wav2Vec2 嵌入对语音增强任务的性能提升有限，尤其在挑战性环境中。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "8 pages; Shorter form accepted in ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.01369v1",
      "published_date": "2024-03-03 02:05:17 UTC",
      "updated_date": "2024-03-03 02:05:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:07:32.990714"
    },
    {
      "arxiv_id": "2403.01348v1",
      "title": "SANGRIA: Stacked Autoencoder Neural Networks with Gradient Boosting for Indoor Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Danish Gufran",
        "Saideep Tiku",
        "Sudeep Pasricha"
      ],
      "abstract": "Indoor localization is a critical task in many embedded applications, such as\nasset tracking, emergency response, and realtime navigation. In this article,\nwe propose a novel fingerprintingbased framework for indoor localization called\nSANGRIA that uses stacked autoencoder neural networks with gradient boosted\ntrees. Our approach is designed to overcome the device heterogeneity challenge\nthat can create uncertainty in wireless signal measurements across embedded\ndevices used for localization. We compare SANGRIA to several state-of-the-art\nframeworks and demonstrate 42.96% lower average localization error across\ndiverse indoor locales and heterogeneous devices.",
      "tldr_zh": "本文提出了一种名为 SANGRIA 的新型指纹定位框架，用于室内定位（Indoor Localization），旨在解决设备异构性（device heterogeneity）导致的无线信号测量不确定性问题。SANGRIA 结合了 Stacked Autoencoder Neural Networks 和 Gradient Boosting 技术，通过堆叠自编码器神经网络与梯度提升树来优化定位精度。与现有框架相比，该方法在多样室内环境和异构设备上实现了42.96%的平均定位错误降低，为资产跟踪、紧急响应和实时导航等应用提供了更可靠的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.01348v1",
      "published_date": "2024-03-03 00:01:29 UTC",
      "updated_date": "2024-03-03 00:01:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:07:44.253196"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 35,
  "processed_papers_count": 35,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T12:08:05.596958"
}