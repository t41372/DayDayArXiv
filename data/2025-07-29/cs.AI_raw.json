[
  {
    "arxiv_id": "2507.22958v1",
    "title": "CHECK-MAT: Checking Hand-Written Mathematical Answers for the Russian Unified State Exam",
    "authors": [
      "Ruslan Khrulev"
    ],
    "abstract": "This paper introduces a novel benchmark, EGE-Math Solutions Assessment Benchmark, for evaluating Vision-Language Models (VLMs) on their ability to assess hand-written mathematical solutions. Unlike existing benchmarks that focus on problem solving, our approach centres on understanding student solutions, identifying mistakes, and assigning grades according to fixed criteria. We compile 122 scanned solutions from the Russian Unified State Exam (EGE) together with official expert grades, and evaluate seven modern VLMs from Google, OpenAI, Arcee AI, and Alibaba Cloud in three inference modes. The results reveal current limitations in mathematical reasoning and human-rubric alignment, opening new research avenues in AI-assisted assessment. You can find code in https://github.com/Karifannaa/Auto-check-EGE-math",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 3 figures, 10 tables. Code is available at: https://github.com/Karifannaa/Auto-check-EGE-math",
    "pdf_url": "https://arxiv.org/pdf/2507.22958v1",
    "published_date": "2025-07-29 23:46:45 UTC",
    "updated_date": "2025-07-29 23:46:45 UTC"
  },
  {
    "arxiv_id": "2507.22286v2",
    "title": "Meaning-infused grammar: Gradient Acceptability Shapes the Geometric Representations of Constructions in LLMs",
    "authors": [
      "Supantho Rakshit",
      "Adele Goldberg"
    ],
    "abstract": "The usage-based constructionist (UCx) approach to language posits that language comprises a network of learned form-meaning pairings (constructions) whose use is largely determined by their meanings or functions, requiring them to be graded and probabilistic. This study investigates whether the internal representations in Large Language Models (LLMs) reflect the proposed function-infused gradience. We analyze representations of the English Double Object (DO) and Prepositional Object (PO) constructions in Pythia-$1.4$B, using a dataset of $5000$ sentence pairs systematically varied by human-rated preference strength for DO or PO. Geometric analyses show that the separability between the two constructions' representations, as measured by energy distance or Jensen-Shannon divergence, is systematically modulated by gradient preference strength, which depends on lexical and functional properties of sentences. That is, more prototypical exemplars of each construction occupy more distinct regions in activation space, compared to sentences that could have equally well have occured in either construction. These results provide evidence that LLMs learn rich, meaning-infused, graded representations of constructions and offer support for geometric measures for representations in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 3 figures, Accepted for publication at the Second International Workshop on Construction Grammars and NLP at the 16th International Conference for Computational Semantics (IWCS) 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.22286v2",
    "published_date": "2025-07-29 23:39:21 UTC",
    "updated_date": "2025-09-08 18:33:19 UTC"
  },
  {
    "arxiv_id": "2507.22281v1",
    "title": "CoEx -- Co-evolving World-model and Exploration",
    "authors": [
      "Minsoo Kim",
      "Seung-won Hwang"
    ],
    "abstract": "Planning in modern LLM agents relies on the utilization of LLM as an internal world model, acquired during pretraining. However, existing agent designs fail to effectively assimilate new observations into dynamic updates of the world model. This reliance on the LLM's static internal world model is progressively prone to misalignment with the underlying true state of the world, leading to the generation of divergent and erroneous plans. We introduce a hierarchical agent architecture, CoEx, in which hierarchical state abstraction allows LLM planning to co-evolve with a dynamically updated model of the world. CoEx plans and interacts with the world by using LLM reasoning to orchestrate dynamic plans consisting of subgoals, and its learning mechanism continuously incorporates these subgoal experiences into a persistent world model in the form of a neurosymbolic belief state, comprising textual inferences and code-based symbolic memory. We evaluate our agent across a diverse set of agent scenarios involving rich environments and complex tasks including ALFWorld, PDDL, and Jericho. Our experiments show that CoEx outperforms existing agent paradigms in planning and exploration.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22281v1",
    "published_date": "2025-07-29 23:13:09 UTC",
    "updated_date": "2025-07-29 23:13:09 UTC"
  },
  {
    "arxiv_id": "2507.22268v2",
    "title": "Multi-modal Relational Item Representation Learning for Inferring Substitutable and Complementary Items",
    "authors": [
      "Junting Wang",
      "Chenghuan Guo",
      "Jiao Yang",
      "Yanhui Guo",
      "Yan Gao",
      "Hari Sundaram"
    ],
    "abstract": "We introduce a novel self-supervised multi-modal relational item representation learning framework designed to infer substitutable and complementary items. Existing approaches primarily focus on modeling item-item associations deduced from user behaviors using graph neural networks (GNNs) or leveraging item content information. However, these methods often overlook critical challenges, such as noisy user behavior data and data sparsity due to the long-tailed distribution of these behaviors. In this paper, we propose MMSC, a self-supervised multi-modal relational item representation learning framework to address these challenges. Specifically, MMSC consists of three main components: (1) a multi-modal item representation learning module that leverages a multi-modal foundational model and learns from item metadata, (2) a self-supervised behavior-based representation learning module that denoises and learns from user behavior data, and (3) a hierarchical representation aggregation mechanism that integrates item representations at both the semantic and task levels. Additionally, we leverage LLMs to generate augmented training data, further enhancing the denoising process during training. We conduct extensive experiments on five real-world datasets, showing that MMSC outperforms existing baselines by 26.1% for substitutable recommendation and 39.2% for complementary recommendation. In addition, we empirically show that MMSC is effective in modeling cold-start items.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22268v2",
    "published_date": "2025-07-29 22:38:39 UTC",
    "updated_date": "2025-07-31 20:53:24 UTC"
  },
  {
    "arxiv_id": "2507.22267v1",
    "title": "Promoting Online Safety by Simulating Unsafe Conversations with LLMs",
    "authors": [
      "Owen Hoffman",
      "Kangze Peng",
      "Zehua You",
      "Sajid Kamal",
      "Sukrit Venkatagiri"
    ],
    "abstract": "Generative AI, including large language models (LLMs) have the potential -- and already are being used -- to increase the speed, scale, and types of unsafe conversations online. LLMs lower the barrier for entry for bad actors to create unsafe conversations in particular because of their ability to generate persuasive and human-like text. In our current work, we explore ways to promote online safety by teaching people about unsafe conversations that can occur online with and without LLMs. We build on prior work that shows that LLMs can successfully simulate scam conversations. We also leverage research in the learning sciences that shows that providing feedback on one's hypothetical actions can promote learning. In particular, we focus on simulating scam conversations using LLMs. Our work incorporates two LLMs that converse with each other to simulate realistic, unsafe conversations that people may encounter online between a scammer LLM and a target LLM but users of our system are asked provide feedback to the target LLM.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22267v1",
    "published_date": "2025-07-29 22:38:21 UTC",
    "updated_date": "2025-07-29 22:38:21 UTC"
  },
  {
    "arxiv_id": "2507.22264v1",
    "title": "SmartCLIP: Modular Vision-language Alignment with Identification Guarantees",
    "authors": [
      "Shaoan Xie",
      "Lingjing Kong",
      "Yujia Zheng",
      "Yu Yao",
      "Zeyu Tang",
      "Eric P. Xing",
      "Guangyi Chen",
      "Kun Zhang"
    ],
    "abstract": "Contrastive Language-Image Pre-training (CLIP)~\\citep{radford2021learning} has emerged as a pivotal model in computer vision and multimodal learning, achieving state-of-the-art performance at aligning visual and textual representations through contrastive learning. However, CLIP struggles with potential information misalignment in many image-text datasets and suffers from entangled representation. On the one hand, short captions for a single image in datasets like MSCOCO may describe disjoint regions in the image, leaving the model uncertain about which visual features to retain or disregard. On the other hand, directly aligning long captions with images can lead to the retention of entangled details, preventing the model from learning disentangled, atomic concepts -- ultimately limiting its generalization on certain downstream tasks involving short prompts.\n  In this paper, we establish theoretical conditions that enable flexible alignment between textual and visual representations across varying levels of granularity. Specifically, our framework ensures that a model can not only \\emph{preserve} cross-modal semantic information in its entirety but also \\emph{disentangle} visual representations to capture fine-grained textual concepts. Building on this foundation, we introduce \\ours, a novel approach that identifies and aligns the most relevant visual and textual representations in a modular manner. Superior performance across various tasks demonstrates its capability to handle information misalignment and supports our identification theory. The code is available at https://github.com/Mid-Push/SmartCLIP.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR2025",
    "pdf_url": "https://arxiv.org/pdf/2507.22264v1",
    "published_date": "2025-07-29 22:26:20 UTC",
    "updated_date": "2025-07-29 22:26:20 UTC"
  },
  {
    "arxiv_id": "2507.22255v1",
    "title": "Agent-centric learning: from external reward maximization to internal knowledge curation",
    "authors": [
      "Hanqi Zhou",
      "Fryderyk Mantiuk",
      "David G. Nagy",
      "Charley M. Wu"
    ],
    "abstract": "The pursuit of general intelligence has traditionally centered on external objectives: an agent's control over its environments or mastery of specific tasks. This external focus, however, can produce specialized agents that lack adaptability. We propose representational empowerment, a new perspective towards a truly agent-centric learning paradigm by moving the locus of control inward. This objective measures an agent's ability to controllably maintain and diversify its own knowledge structures. We posit that the capacity -- to shape one's own understanding -- is an element for achieving better ``preparedness'' distinct from direct environmental influence. Focusing on internal representations as the main substrate for computing empowerment offers a new lens through which to design adaptable intelligent systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.LG",
    "comment": "RLC Finding the Frame Workshop 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.22255v1",
    "published_date": "2025-07-29 22:09:35 UTC",
    "updated_date": "2025-07-29 22:09:35 UTC"
  },
  {
    "arxiv_id": "2507.22250v1",
    "title": "Using Scaling Laws for Data Source Utility Estimation in Domain-Specific Pre-Training",
    "authors": [
      "Oleksiy Ostapenko",
      "Charles Guille-Escuret",
      "Luke Kumar",
      "Max Tian",
      "Denis Kocetkov",
      "Gopeshh Subbaraj",
      "Raymond Li",
      "Joel Lamy-Poirier",
      "Sebastien Paquet",
      "Torsten Scholak"
    ],
    "abstract": "We introduce a framework for optimizing domain-specific dataset construction in foundation model training. Specifically, we seek a cost-efficient way to estimate the quality of data sources (e.g. synthetically generated or filtered web data, etc.) in order to make optimal decisions about resource allocation for data sourcing from these sources for the stage two pre-training phase, aka annealing, with the goal of specializing a generalist pre-trained model to specific domains. Our approach extends the usual point estimate approaches, aka micro-annealing, to estimating scaling laws by performing multiple annealing runs of varying compute spent on data curation and training. This addresses a key limitation in prior work, where reliance on point estimates for data scaling decisions can be misleading due to the lack of rank invariance across compute scales -- a phenomenon we confirm in our experiments. By systematically analyzing performance gains relative to acquisition costs, we find that scaling curves can be estimated for different data sources. Such scaling laws can inform cost effective resource allocation across different data acquisition methods (e.g. synthetic data), data sources (e.g. user or web data) and available compute resources. We validate our approach through experiments on a pre-trained model with 7 billion parameters. We adapt it to: a domain well-represented in the pre-training data -- the medical domain, and a domain underrepresented in the pretraining corpora -- the math domain. We show that one can efficiently estimate the scaling behaviors of a data source by running multiple annealing runs, which can lead to different conclusions, had one used point estimates using the usual micro-annealing technique instead. This enables data-driven decision-making for selecting and optimizing data sources.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22250v1",
    "published_date": "2025-07-29 21:56:45 UTC",
    "updated_date": "2025-07-29 21:56:45 UTC"
  },
  {
    "arxiv_id": "2507.22239v2",
    "title": "Large Language Model-Based Framework for Explainable Cyberattack Detection in Automatic Generation Control Systems",
    "authors": [
      "Muhammad Sharshar",
      "Ahmad Mohammad Saber",
      "Davor Svetinovic",
      "Amr M. Youssef",
      "Deepa Kundur",
      "Ehab F. El-Saadany"
    ],
    "abstract": "The increasing digitization of smart grids has improved operational efficiency but also introduced new cybersecurity vulnerabilities, such as False Data Injection Attacks (FDIAs) targeting Automatic Generation Control (AGC) systems. While machine learning (ML) and deep learning (DL) models have shown promise in detecting such attacks, their opaque decision-making limits operator trust and real-world applicability. This paper proposes a hybrid framework that integrates lightweight ML-based attack detection with natural language explanations generated by Large Language Models (LLMs). Classifiers such as LightGBM achieve up to 95.13% attack detection accuracy with only 0.004 s inference latency. Upon detecting a cyberattack, the system invokes LLMs, including GPT-3.5 Turbo, GPT-4 Turbo, and GPT-4o mini, to generate human-readable explanation of the event. Evaluated on 100 test samples, GPT-4o mini with 20-shot prompting achieved 93% accuracy in identifying the attack target, a mean absolute error of 0.075 pu in estimating attack magnitude, and 2.19 seconds mean absolute error (MAE) in estimating attack onset. These results demonstrate that the proposed framework effectively balances real-time detection with interpretable, high-fidelity explanations, addressing a critical need for actionable AI in smart grid cybersecurity.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted Paper",
    "pdf_url": "https://arxiv.org/pdf/2507.22239v2",
    "published_date": "2025-07-29 21:23:08 UTC",
    "updated_date": "2025-08-26 01:50:20 UTC"
  },
  {
    "arxiv_id": "2507.22219v3",
    "title": "RL from Teacher-Model Refinement: Gradual Imitation Learning for Machine Translation",
    "authors": [
      "Dongyub Jude Lee",
      "Zhenyi Ye",
      "Pengcheng He"
    ],
    "abstract": "Preference-learning methods for machine translation (MT), such as Direct Preference Optimization (DPO), have shown strong gains but typically rely on large, carefully curated preference triplets and often struggle to generalize beyond their tuning domains. We propose Reinforcement Learning from Teacher-Model Refinement (RLfR), which replaces static triplets with on-policy, actor-conditioned refinements produced by a frozen teacher. At each step, the actor samples candidate translations, the teacher performs a minimal local edit of each draft, and the actor is reinforced to close the gap using a composite reward that combines scaled negative edit distance for lexical and structural fidelity with COMET for semantic adequacy. This formulation yields a stable, model-aware learning signal without requiring explicit preference datasets. Experiments on FLORES-200 (English to German, Spanish, Chinese, Korean, and Japanese) show that RLfR consistently outperforms strong MT-SFT, DPO, and fixed-reference RL baselines, improving semantic quality and entity preservation, and also achieves superior performance under LLM-based judge evaluations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22219v3",
    "published_date": "2025-07-29 20:35:35 UTC",
    "updated_date": "2025-12-19 17:35:31 UTC"
  },
  {
    "arxiv_id": "2507.22208v1",
    "title": "Quantum-Inspired Audio Unlearning: Towards Privacy-Preserving Voice Biometrics",
    "authors": [
      "Shreyansh Pathak",
      "Sonu Shreshtha",
      "Richa Singh",
      "Mayank Vatsa"
    ],
    "abstract": "The widespread adoption of voice-enabled authentication and audio biometric systems have significantly increased privacy vulnerabilities associated with sensitive speech data. Compliance with privacy regulations such as GDPR's right to be forgotten and India's DPDP Act necessitates targeted and efficient erasure of individual-specific voice signatures from already-trained biometric models. Existing unlearning methods designed for visual data inadequately handle the sequential, temporal, and high-dimensional nature of audio signals, leading to ineffective or incomplete speaker and accent erasure. To address this, we introduce QPAudioEraser, a quantum-inspired audio unlearning framework. Our our-phase approach involves: (1) weight initialization using destructive interference to nullify target features, (2) superposition-based label transformations that obscure class identity, (3) an uncertainty-maximizing quantum loss function, and (4) entanglement-inspired mixing of correlated weights to retain model knowledge. Comprehensive evaluations with ResNet18, ViT, and CNN architectures across AudioMNIST, Speech Commands, LibriSpeech, and Speech Accent Archive datasets validate QPAudioEraser's superior performance. The framework achieves complete erasure of target data (0% Forget Accuracy) while incurring minimal impact on model utility, with a performance degradation on retained data as low as 0.05%. QPAudioEraser consistently surpasses conventional baselines across single-class, multi-class, sequential, and accent-level erasure scenarios, establishing the proposed approach as a robust privacy-preserving solution.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "9 pages, 2 figures, 5 tables, Accepted at IJCB 2025 (Osaka, Japan)",
    "pdf_url": "https://arxiv.org/pdf/2507.22208v1",
    "published_date": "2025-07-29 20:12:24 UTC",
    "updated_date": "2025-07-29 20:12:24 UTC"
  },
  {
    "arxiv_id": "2508.00914v1",
    "title": "Knowledge Editing for Multi-Hop Question Answering Using Semantic Analysis",
    "authors": [
      "Dominic Simon",
      "Rickard Ewetz"
    ],
    "abstract": "Large Language Models (LLMs) require lightweight avenues of updating stored information that has fallen out of date. Knowledge Editing (KE) approaches have been successful in updating model knowledge for simple factual queries but struggle with handling tasks that require compositional reasoning such as multi-hop question answering (MQA). We observe that existing knowledge editors leverage decompositional techniques that result in illogical reasoning processes. In this paper, we propose a knowledge editor for MQA based on semantic analysis called CHECK. Our framework is based on insights from an analogy between compilers and reasoning using LLMs. Similar to how source code is first compiled before being executed, we propose to semantically analyze reasoning chains before executing the chains to answer questions. Reasoning chains with semantic errors are revised to ensure consistency through logic optimization and re-prompting the LLM model at a higher temperature. We evaluate the effectiveness of CHECK against five state-of-the-art frameworks on four datasets and achieve an average 22.8% improved MQA accuracy.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 15 figures, pre-print of paper accepted to IJCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.00914v1",
    "published_date": "2025-07-29 19:58:22 UTC",
    "updated_date": "2025-07-29 19:58:22 UTC"
  },
  {
    "arxiv_id": "2508.00912v1",
    "title": "Predictive Auditing of Hidden Tokens in LLM APIs via Reasoning Length Estimation",
    "authors": [
      "Ziyao Wang",
      "Guoheng Sun",
      "Yexiao He",
      "Zheyu Shen",
      "Bowei Tian",
      "Ang Li"
    ],
    "abstract": "Commercial LLM services often conceal internal reasoning traces while still charging users for every generated token, including those from hidden intermediate steps, raising concerns of token inflation and potential overbilling. This gap underscores the urgent need for reliable token auditing, yet achieving it is far from straightforward: cryptographic verification (e.g., hash-based signature) offers little assurance when providers control the entire execution pipeline, while user-side prediction struggles with the inherent variance of reasoning LLMs, where token usage fluctuates across domains and prompt styles. To bridge this gap, we present PALACE (Predictive Auditing of LLM APIs via Reasoning Token Count Estimation), a user-side framework that estimates hidden reasoning token counts from prompt-answer pairs without access to internal traces. PALACE introduces a GRPO-augmented adaptation module with a lightweight domain router, enabling dynamic calibration across diverse reasoning tasks and mitigating variance in token usage patterns. Experiments on math, coding, medical, and general reasoning benchmarks show that PALACE achieves low relative error and strong prediction accuracy, supporting both fine-grained cost auditing and inflation detection. Taken together, PALACE represents an important first step toward standardized predictive auditing, offering a practical path to greater transparency, accountability, and user trust.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.00912v1",
    "published_date": "2025-07-29 19:50:55 UTC",
    "updated_date": "2025-07-29 19:50:55 UTC"
  },
  {
    "arxiv_id": "2507.22197v1",
    "title": "Explainability Through Systematicity: The Hard Systematicity Challenge for Artificial Intelligence",
    "authors": [
      "Matthieu Queloz"
    ],
    "abstract": "This paper argues that explainability is only one facet of a broader ideal that shapes our expectations towards artificial intelligence (AI). Fundamentally, the issue is to what extent AI exhibits systematicity--not merely in being sensitive to how thoughts are composed of recombinable constituents, but in striving towards an integrated body of thought that is consistent, coherent, comprehensive, and parsimoniously principled. This richer conception of systematicity has been obscured by the long shadow of the \"systematicity challenge\" to connectionism, according to which network architectures are fundamentally at odds with what Fodor and colleagues termed \"the systematicity of thought.\" I offer a conceptual framework for thinking about \"the systematicity of thought\" that distinguishes four senses of the phrase. I use these distinctions to defuse the perceived tension between systematicity and connectionism and show that the conception of systematicity that historically shaped our sense of what makes thought rational, authoritative, and scientific is more demanding than the Fodorian notion. To determine whether we have reason to hold AI models to this ideal of systematicity, I then argue, we must look to the rationales for systematization and explore to what extent they transfer to AI models. I identify five such rationales and apply them to AI. This brings into view the \"hard systematicity challenge.\" However, the demand for systematization itself needs to be regulated by the rationales for systematization. This yields a dynamic understanding of the need to systematize thought, which tells us how systematic we need AI models to be and when.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "39 pages; final, published version",
    "pdf_url": "https://arxiv.org/pdf/2507.22197v1",
    "published_date": "2025-07-29 19:50:21 UTC",
    "updated_date": "2025-07-29 19:50:21 UTC"
  },
  {
    "arxiv_id": "2507.22189v1",
    "title": "Measuring Time-Series Dataset Similarity using Wasserstein Distance",
    "authors": [
      "Hongjie Chen",
      "Akshay Mehra",
      "Josh Kimball",
      "Ryan A. Rossi"
    ],
    "abstract": "The emergence of time-series foundation model research elevates the growing need to measure the (dis)similarity of time-series datasets. A time-series dataset similarity measure aids research in multiple ways, including model selection, finetuning, and visualization. In this paper, we propose a distribution-based method to measure time-series dataset similarity by leveraging the Wasserstein distance. We consider a time-series dataset an empirical instantiation of an underlying multivariate normal distribution (MVN). The similarity between two time-series datasets is thus computed as the Wasserstein distance between their corresponding MVNs. Comprehensive experiments and visualization show the effectiveness of our approach. Specifically, we show how the Wasserstein distance helps identify similar time-series datasets and facilitates inference performance estimation of foundation models in both out-of-distribution and transfer learning evaluation, with high correlations between our proposed measure and the inference loss (>0.60).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22189v1",
    "published_date": "2025-07-29 19:33:10 UTC",
    "updated_date": "2025-07-29 19:33:10 UTC"
  },
  {
    "arxiv_id": "2507.22187v1",
    "title": "A Scalable Pipeline for Estimating Verb Frame Frequencies Using Large Language Models",
    "authors": [
      "Adam M. Morgan",
      "Adeen Flinker"
    ],
    "abstract": "We present an automated pipeline for estimating Verb Frame Frequencies (VFFs), the frequency with which a verb appears in particular syntactic frames. VFFs provide a powerful window into syntax in both human and machine language systems, but existing tools for calculating them are limited in scale, accuracy, or accessibility. We use large language models (LLMs) to generate a corpus of sentences containing 476 English verbs. Next, by instructing an LLM to behave like an expert linguist, we had it analyze the syntactic structure of the sentences in this corpus. This pipeline outperforms two widely used syntactic parsers across multiple evaluation datasets. Furthermore, it requires far fewer resources than manual parsing (the gold-standard), thereby enabling rapid, scalable VFF estimation. Using the LLM parser, we produce a new VFF database with broader verb coverage, finer-grained syntactic distinctions, and explicit estimates of the relative frequencies of structural alternates commonly studied in psycholinguistics. The pipeline is easily customizable and extensible to new verbs, syntactic frames, and even other languages. We present this work as a proof of concept for automated frame frequency estimation, and release all code and data to support future research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22187v1",
    "published_date": "2025-07-29 19:30:11 UTC",
    "updated_date": "2025-07-29 19:30:11 UTC"
  },
  {
    "arxiv_id": "2507.22186v2",
    "title": "SourceSplice: Source Selection for Machine Learning Tasks",
    "authors": [
      "Ambarish Singh",
      "Romila Pradhan"
    ],
    "abstract": "Data quality plays a pivotal role in the predictive performance of machine learning (ML) tasks - a challenge amplified by the deluge of data sources available in modern organizations. Prior work in data discovery largely focus on metadata matching, semantic similarity or identifying tables that should be joined to answer a particular query, but do not consider source quality for high performance of the downstream ML task. This paper addresses the problem of determining the best subset of data sources that must be combined to construct the underlying training dataset for a given ML task. We propose SourceGrasp and SourceSplice, frameworks designed to efficiently select a suitable subset of sources that maximizes the utility of the downstream ML model. Both the algorithms rely on the core idea that sources (or their combinations) contribute differently to the task utility, and must be judiciously chosen. While SourceGrasp utilizes a metaheuristic based on a greediness criterion and randomization, the SourceSplice framework presents a source selection mechanism inspired from gene splicing - a core concept used in protein synthesis. We empirically evaluate our algorithms on three real-world datasets and synthetic datasets and show that, with significantly fewer subset explorations, SourceSplice effectively identifies subsets of data sources leading to high task utility. We also conduct studies reporting the sensitivity of SourceSplice to the decision choices under several settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22186v2",
    "published_date": "2025-07-29 19:29:52 UTC",
    "updated_date": "2025-07-31 18:46:06 UTC"
  },
  {
    "arxiv_id": "2507.22168v2",
    "title": "Persona-Augmented Benchmarking: Evaluating LLMs Across Diverse Writing Styles",
    "authors": [
      "Kimberly Le Truong",
      "Riccardo Fogliato",
      "Hoda Heidari",
      "Zhiwei Steven Wu"
    ],
    "abstract": "Current benchmarks for evaluating Large Language Models (LLMs) often do not exhibit enough writing style diversity, with many adhering primarily to standardized conventions. Such benchmarks do not fully capture the rich variety of communication patterns exhibited by humans. Thus, it is possible that LLMs, which are optimized on these benchmarks, may demonstrate brittle performance when faced with \"non-standard\" input. In this work, we test this hypothesis by rewriting evaluation prompts using persona-based LLM prompting, a low-cost method to emulate diverse writing styles. Our results show that, even with identical semantic content, variations in writing style and prompt formatting significantly impact the estimated performance of the LLM under evaluation. Notably, we identify distinct writing styles that consistently trigger either low or high performance across a range of models and tasks, irrespective of model family, size, and recency. Our work offers a scalable approach to augment existing benchmarks, improving the external validity of the assessments they provide for measuring LLM performance across linguistic variations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.22168v2",
    "published_date": "2025-07-29 18:59:09 UTC",
    "updated_date": "2025-09-25 21:37:43 UTC"
  },
  {
    "arxiv_id": "2507.22160v1",
    "title": "Strategic Deflection: Defending LLMs from Logit Manipulation",
    "authors": [
      "Yassine Rachidy",
      "Jihad Rbaiti",
      "Youssef Hmamouche",
      "Faissal Sehbaoui",
      "Amal El Fallah Seghrouchni"
    ],
    "abstract": "With the growing adoption of Large Language Models (LLMs) in critical areas, ensuring their security against jailbreaking attacks is paramount. While traditional defenses primarily rely on refusing malicious prompts, recent logit-level attacks have demonstrated the ability to bypass these safeguards by directly manipulating the token-selection process during generation. We introduce Strategic Deflection (SDeflection), a defense that redefines the LLM's response to such advanced attacks. Instead of outright refusal, the model produces an answer that is semantically adjacent to the user's request yet strips away the harmful intent, thereby neutralizing the attacker's harmful intent. Our experiments demonstrate that SDeflection significantly lowers Attack Success Rate (ASR) while maintaining model performance on benign queries. This work presents a critical shift in defensive strategies, moving from simple refusal to strategic content redirection to neutralize advanced threats.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "20 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.22160v1",
    "published_date": "2025-07-29 18:46:56 UTC",
    "updated_date": "2025-07-29 18:46:56 UTC"
  },
  {
    "arxiv_id": "2507.22159v2",
    "title": "IndoPref: A Multi-Domain Pairwise Preference Dataset for Indonesian",
    "authors": [
      "Vanessa Rebecca Wiyono",
      "David Anugraha",
      "Ayu Purwarianti",
      "Genta Indra Winata"
    ],
    "abstract": "Over 200 million people speak Indonesian, yet the language remains significantly underrepresented in preference-based research for large language models (LLMs). Most existing multilingual datasets are derived from English translations, often resulting in content that lacks cultural and linguistic authenticity. To address this gap, we introduce IndoPref, the first fully human-authored and multi-domain Indonesian preference dataset designed to evaluate the naturalness and quality of LLM-generated text. The dataset contains 522 prompts and yields 4,099 human-annotated pairwise preferences from comparisons across five instruction-tuned LLMs. All annotations are natively written in Indonesian with strong inter-annotator agreement, measured by Krippendorff's alpha. Our benchmark spans 10 diverse categories, enabling practitioners to identify LLMs' fine-grained strengths and weaknesses.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by IJCNLP-AACL 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.22159v2",
    "published_date": "2025-07-29 18:46:25 UTC",
    "updated_date": "2025-11-11 21:41:58 UTC"
  },
  {
    "arxiv_id": "2507.22157v1",
    "title": "Tiny Noise-Robust Voice Activity Detector for Voice Assistants",
    "authors": [
      "Hamed Jafarzadeh Asl",
      "Mahsa Ghazvini Nejad",
      "Amin Edraki",
      "Masoud Asgharian",
      "Vahid Partovi Nia"
    ],
    "abstract": "Voice Activity Detection (VAD) in the presence of background noise remains a challenging problem in speech processing. Accurate VAD is essential in automatic speech recognition, voice-to-text, conversational agents, etc, where noise can severely degrade the performance. A modern application includes the voice assistant, specially mounted on Artificial Intelligence of Things (AIoT) devices such as cell phones, smart glasses, earbuds, etc, where the voice signal includes background noise. Therefore, VAD modules must remain light-weight due to their practical on-device limitation. The existing models often struggle with low signal-to-noise ratios across diverse acoustic environments. A simple VAD often detects human voice in a clean environment, but struggles to detect the human voice in noisy conditions. We propose a noise-robust VAD that comprises a light-weight VAD, with data pre-processing and post-processing added modules to handle the background noise. This approach significantly enhances the VAD accuracy in noisy environments and requires neither a larger model, nor fine-tuning. Experimental results demonstrate that our approach achieves a notable improvement compared to baselines, particularly in environments with high background noise interference. This modified VAD additionally improving clean speech detection.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "Hamed Jafarzadeh Asl and Mahsa Ghazvini Nejad contributed equally to this work",
    "pdf_url": "https://arxiv.org/pdf/2507.22157v1",
    "published_date": "2025-07-29 18:44:43 UTC",
    "updated_date": "2025-07-29 18:44:43 UTC"
  },
  {
    "arxiv_id": "2507.22149v4",
    "title": "When Truthful Representations Flip Under Deceptive Instructions?",
    "authors": [
      "Xianxuan Long",
      "Yao Fu",
      "Runchao Li",
      "Mu Sheng",
      "Haotian Yu",
      "Xiaotian Han",
      "Pan Li"
    ],
    "abstract": "Large language models (LLMs) tend to follow maliciously crafted instructions to generate deceptive responses, posing safety challenges. How deceptive instructions alter the internal representations of LLM compared to truthful ones remains poorly understood beyond output analysis. To bridge this gap, we investigate when and how these representations ``flip'', such as from truthful to deceptive, under deceptive versus truthful/neutral instructions. Analyzing the internal representations of Llama-3.1-8B-Instruct and Gemma-2-9B-Instruct on a factual verification task, we find the model's instructed True/False output is predictable via linear probes across all conditions based on the internal representation. Further, we use Sparse Autoencoders (SAEs) to show that the Deceptive instructions induce significant representational shifts compared to Truthful/Neutral representations (which are similar), concentrated in early-to-mid layers and detectable even on complex datasets. We also identify specific SAE features highly sensitive to deceptive instruction and use targeted visualizations to confirm distinct truthful/deceptive representational subspaces. % Our analysis pinpoints layer-wise and feature-level correlates of instructed dishonesty, offering insights for LLM detection and control. Our findings expose feature- and layer-level signatures of deception, offering new insights for detecting and mitigating instructed dishonesty in LLMs.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22149v4",
    "published_date": "2025-07-29 18:27:13 UTC",
    "updated_date": "2025-10-29 02:12:31 UTC"
  },
  {
    "arxiv_id": "2507.22099v1",
    "title": "Runtime Failure Hunting for Physics Engine Based Software Systems: How Far Can We Go?",
    "authors": [
      "Shuqing Li",
      "Qiang Chen",
      "Xiaoxue Ren",
      "Michael R. Lyu"
    ],
    "abstract": "Physics Engines (PEs) are fundamental software frameworks that simulate physical interactions in applications ranging from entertainment to safety-critical systems. Despite their importance, PEs suffer from physics failures, deviations from expected physical behaviors that can compromise software reliability, degrade user experience, and potentially cause critical failures in autonomous vehicles or medical robotics. Current testing approaches for PE-based software are inadequate, typically requiring white-box access and focusing on crash detection rather than semantically complex physics failures. This paper presents the first large-scale empirical study characterizing physics failures in PE-based software. We investigate three research questions addressing the manifestations of physics failures, the effectiveness of detection techniques, and developer perceptions of current detection practices. Our contributions include: (1) a taxonomy of physics failure manifestations; (2) a comprehensive evaluation of detection methods including deep learning, prompt-based techniques, and large multimodal models; and (3) actionable insights from developer experiences for improving detection approaches. To support future research, we release PhysiXFails, code, and other materials at https://sites.google.com/view/physics-failure-detection.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM",
      "cs.SE"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22099v1",
    "published_date": "2025-07-29 17:58:41 UTC",
    "updated_date": "2025-07-29 17:58:41 UTC"
  },
  {
    "arxiv_id": "2507.22053v1",
    "title": "Foundation Models for Demand Forecasting via Dual-Strategy Ensembling",
    "authors": [
      "Wei Yang",
      "Defu Cao",
      "Yan Liu"
    ],
    "abstract": "Accurate demand forecasting is critical for supply chain optimization, yet remains difficult in practice due to hierarchical complexity, domain shifts, and evolving external factors. While recent foundation models offer strong potential for time series forecasting, they often suffer from architectural rigidity and limited robustness under distributional change. In this paper, we propose a unified ensemble framework that enhances the performance of foundation models for sales forecasting in real-world supply chains. Our method combines two complementary strategies: (1) Hierarchical Ensemble (HE), which partitions training and inference by semantic levels (e.g., store, category, department) to capture localized patterns; and (2) Architectural Ensemble (AE), which integrates predictions from diverse model backbones to mitigate bias and improve stability. We conduct extensive experiments on the M5 benchmark and three external sales datasets, covering both in-domain and zero-shot forecasting. Results show that our approach consistently outperforms strong baselines, improves accuracy across hierarchical levels, and provides a simple yet effective mechanism for boosting generalization in complex forecasting environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22053v1",
    "published_date": "2025-07-29 17:56:38 UTC",
    "updated_date": "2025-07-29 17:56:38 UTC"
  },
  {
    "arxiv_id": "2507.22047v1",
    "title": "The Interspeech 2025 Speech Accessibility Project Challenge",
    "authors": [
      "Xiuwen Zheng",
      "Bornali Phukon",
      "Jonghwan Na",
      "Ed Cutrell",
      "Kyu Han",
      "Mark Hasegawa-Johnson",
      "Pan-Pan Jiang",
      "Aadhrik Kuila",
      "Colin Lea",
      "Bob MacDonald",
      "Gautam Mantena",
      "Venkatesh Ravichandran",
      "Leda Sari",
      "Katrin Tomanek",
      "Chang D. Yoo",
      "Chris Zwilling"
    ],
    "abstract": "While the last decade has witnessed significant advancements in Automatic Speech Recognition (ASR) systems, performance of these systems for individuals with speech disabilities remains inadequate, partly due to limited public training data. To bridge this gap, the 2025 Interspeech Speech Accessibility Project (SAP) Challenge was launched, utilizing over 400 hours of SAP data collected and transcribed from more than 500 individuals with diverse speech disabilities. Hosted on EvalAI and leveraging the remote evaluation pipeline, the SAP Challenge evaluates submissions based on Word Error Rate and Semantic Score. Consequently, 12 out of 22 valid teams outperformed the whisper-large-v2 baseline in terms of WER, while 17 teams surpassed the baseline on SemScore. Notably, the top team achieved the lowest WER of 8.11\\%, and the highest SemScore of 88.44\\% at the same time, setting new benchmarks for future ASR systems in recognizing impaired speech.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear in Proceedings of Interspeech, 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.22047v1",
    "published_date": "2025-07-29 17:50:59 UTC",
    "updated_date": "2025-07-29 17:50:59 UTC"
  },
  {
    "arxiv_id": "2507.22039v2",
    "title": "Analysis of Quantum Image Representations for Supervised Classification",
    "authors": [
      "Marco Parigi",
      "Mehran Khosrojerdi",
      "Filippo Caruso",
      "Leonardo Banchi"
    ],
    "abstract": "In the era of big data and artificial intelligence, the increasing volume of data and the demand to solve more and more complex computational challenges are two driving forces for improving the efficiency of data storage, processing and analysis. Quantum image processing (QIP) is an interdisciplinary field between quantum information science and image processing, which has the potential to alleviate some of these challenges by leveraging the power of quantum computing. In this work, we compare and examine the compression properties of four different Quantum Image Representations (QImRs): namely, Tensor Network Representation (TNR), Flexible Representation of Quantum Image (FRQI), Novel Enhanced Quantum Representation NEQR, and Quantum Probability Image Encoding (QPIE). Our simulations show that FRQI and QPIE perform a higher compression of image information than TNR and NEQR. Furthermore, we investigate the trade-off between accuracy and memory in binary classification problems, evaluating the performance of quantum kernels based on QImRs compared to the classical linear kernel. Our results indicate that quantum kernels provide comparable classification average accuracy but require exponentially fewer resources for image storage.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "9 pages, 11 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.22039v2",
    "published_date": "2025-07-29 17:40:59 UTC",
    "updated_date": "2026-01-14 10:48:30 UTC"
  },
  {
    "arxiv_id": "2507.22037v1",
    "title": "Secure Tug-of-War (SecTOW): Iterative Defense-Attack Training with Reinforcement Learning for Multimodal Model Security",
    "authors": [
      "Muzhi Dai",
      "Shixuan Liu",
      "Zhiyuan Zhao",
      "Junyu Gao",
      "Hao Sun",
      "Xuelong Li"
    ],
    "abstract": "The rapid advancement of multimodal large language models (MLLMs) has led to breakthroughs in various applications, yet their security remains a critical challenge. One pressing issue involves unsafe image-query pairs--jailbreak inputs specifically designed to bypass security constraints and elicit unintended responses from MLLMs. Compared to general multimodal data, such unsafe inputs are relatively sparse, which limits the diversity and richness of training samples available for developing robust defense models. Meanwhile, existing guardrail-type methods rely on external modules to enforce security constraints but fail to address intrinsic vulnerabilities within MLLMs. Traditional supervised fine-tuning (SFT), on the other hand, often over-refuses harmless inputs, compromising general performance. Given these challenges, we propose Secure Tug-of-War (SecTOW), an innovative iterative defense-attack training method to enhance the security of MLLMs. SecTOW consists of two modules: a defender and an auxiliary attacker, both trained iteratively using reinforcement learning (GRPO). During the iterative process, the attacker identifies security vulnerabilities in the defense model and expands jailbreak data. The expanded data are then used to train the defender, enabling it to address identified security vulnerabilities. We also design reward mechanisms used for GRPO to simplify the use of response labels, reducing dependence on complex generative labels and enabling the efficient use of synthetic data. Additionally, a quality monitoring mechanism is used to mitigate the defender's over-refusal of harmless inputs and ensure the diversity of the jailbreak data generated by the attacker. Experimental results on safety-specific and general benchmarks demonstrate that SecTOW significantly improves security while preserving general performance.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "10 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.22037v1",
    "published_date": "2025-07-29 17:39:48 UTC",
    "updated_date": "2025-07-29 17:39:48 UTC"
  },
  {
    "arxiv_id": "2507.22034v1",
    "title": "UserBench: An Interactive Gym Environment for User-Centric Agents",
    "authors": [
      "Cheng Qian",
      "Zuxin Liu",
      "Akshara Prabhakar",
      "Zhiwei Liu",
      "Jianguo Zhang",
      "Haolin Chen",
      "Heng Ji",
      "Weiran Yao",
      "Shelby Heinecke",
      "Silvio Savarese",
      "Caiming Xiong",
      "Huan Wang"
    ],
    "abstract": "Large Language Models (LLMs)-based agents have made impressive progress in reasoning and tool use, enabling them to solve complex tasks. However, their ability to proactively collaborate with users, especially when goals are vague, evolving, or indirectly expressed, remains underexplored. To address this gap, we introduce UserBench, a user-centric benchmark designed to evaluate agents in multi-turn, preference-driven interactions. UserBench features simulated users who start with underspecified goals and reveal preferences incrementally, requiring agents to proactively clarify intent and make grounded decisions with tools. Our evaluation of leading open- and closed-source LLMs reveals a significant disconnect between task completion and user alignment. For instance, models provide answers that fully align with all user intents only 20% of the time on average, and even the most advanced models uncover fewer than 30% of all user preferences through active interaction. These results highlight the challenges of building agents that are not just capable task executors, but true collaborative partners. UserBench offers an interactive environment to measure and advance this critical capability.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "25 Pages, 17 Figures, 6 Tables",
    "pdf_url": "https://arxiv.org/pdf/2507.22034v1",
    "published_date": "2025-07-29 17:34:12 UTC",
    "updated_date": "2025-07-29 17:34:12 UTC"
  },
  {
    "arxiv_id": "2507.22030v2",
    "title": "ReXGroundingCT: A 3D Chest CT Dataset for Segmentation of Findings from Free-Text Reports",
    "authors": [
      "Mohammed Baharoon",
      "Luyang Luo",
      "Michael Moritz",
      "Abhinav Kumar",
      "Sung Eun Kim",
      "Xiaoman Zhang",
      "Miao Zhu",
      "Mahmoud Hussain Alabbad",
      "Maha Sbayel Alhazmi",
      "Neel P. Mistry",
      "Lucas Bijnens",
      "Kent Ryan Kleinschmidt",
      "Brady Chrisler",
      "Sathvik Suryadevara",
      "Sri Sai Dinesh Jaliparthi",
      "Noah Michael Prudlo",
      "Mark David Marino",
      "Jeremy Palacio",
      "Rithvik Akula",
      "Di Zhou",
      "Hong-Yu Zhou",
      "Ibrahim Ethem Hamamci",
      "Scott J. Adams",
      "Hassan Rayhan AlOmaish",
      "Pranav Rajpurkar"
    ],
    "abstract": "We introduce ReXGroundingCT, the first publicly available dataset linking free-text findings to pixel-level 3D segmentations in chest CT scans. The dataset includes 3,142 non-contrast chest CT scans paired with standardized radiology reports from CT-RATE. Construction followed a structured three-stage pipeline. First, GPT-4 was used to extract and standardize findings, descriptors, and metadata from reports originally written in Turkish and machine-translated into English. Second, GPT-4o-mini categorized each finding into a hierarchical ontology of lung and pleural abnormalities. Third, 3D annotations were produced for all CT volumes: the training set was quality-assured by board-certified radiologists, and the validation and test sets were fully annotated by board-certified radiologists. Additionally, a complementary chain-of-thought dataset was created to provide step-by-step hierarchical anatomical reasoning for localizing findings within the CT volume, using GPT-4o and localization coordinates derived from organ segmentation models. ReXGroundingCT contains 16,301 annotated entities across 8,028 text-to-3D-segmentation pairs, covering diverse radiological patterns from 3,142 non-contrast CT scans. About 79% of findings are focal abnormalities and 21% are non-focal. The dataset includes a public validation set of 50 cases and a private test set of 100 cases, both annotated by board-certified radiologists. The dataset establishes a foundation for enabling free-text finding segmentation and grounded radiology report generation in CT imaging. Model performance on the private test set is hosted on a public leaderboard at https://rexrank.ai/ReXGroundingCT. The dataset is available at https://huggingface.co/datasets/rajpurkarlab/ReXGroundingCT.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22030v2",
    "published_date": "2025-07-29 17:27:15 UTC",
    "updated_date": "2025-10-27 17:51:47 UTC"
  },
  {
    "arxiv_id": "2507.22025v3",
    "title": "UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding",
    "authors": [
      "Shuquan Lian",
      "Yuhang Wu",
      "Jia Ma",
      "Yifan Ding",
      "Zihan Song",
      "Bingqi Chen",
      "Xiawu Zheng",
      "Hui Li"
    ],
    "abstract": "The emergence of Multimodal Large Language Models (MLLMs) has driven significant advances in Graphical User Interface (GUI) agent capabilities. Nevertheless, existing GUI agent training and inference techniques still suffer from a dilemma for reasoning designs, ineffective reward, and visual noise. To address these issues, we introduce UI-AGILE for enhancing GUI agents at both training and inference. For training, we propose a suite of improvements to the Supervised Fine-Tuning (SFT) process: 1) a continuous reward function to incentivize high-precision grounding; 2) a ``Simple Thinking'' reward to balance planning with speed and grounding accuracy; and 3) a cropping-based resampling strategy to mitigate the sparse reward problem and improve learning on complex tasks. For inference, we present decomposed grounding with selection to dramatically improve grounding accuracy on high-resolution displays by breaking the image into smaller, manageable parts. Experiments show that UI-AGILE achieves the state-of-the-art grounding performance on two benchmarks ScreenSpot-Pro and ScreenSpot-v2 while it also exhibits strong general agent capabilities. For instance, using both our training and inference enhancement methods brings 23\\% grounding accuracy improvement over the best baseline on ScreenSpot-Pro. We provide the code in https://github.com/KDEGroup/UI-AGILE.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22025v3",
    "published_date": "2025-07-29 17:22:07 UTC",
    "updated_date": "2025-08-09 17:51:27 UTC"
  },
  {
    "arxiv_id": "2507.22020v1",
    "title": "XAI for Point Cloud Data using Perturbations based on Meaningful Segmentation",
    "authors": [
      "Raju Ningappa Mulawade",
      "Christoph Garth",
      "Alexander Wiebel"
    ],
    "abstract": "We propose a novel segmentation-based explainable artificial intelligence (XAI) method for neural networks working on point cloud classification. As one building block of this method, we propose a novel point-shifting mechanism to introduce perturbations in point cloud data. Recently, AI has seen an exponential growth. Hence, it is important to understand the decision-making process of AI algorithms when they are applied in critical areas. Our work focuses on explaining AI algorithms that classify point cloud data. An important aspect of the methods used for explaining AI algorithms is their ability to produce explanations that are easy for humans to understand. This allows them to analyze the AI algorithms better and make appropriate decisions based on that analysis. Therefore, in this work, we intend to generate meaningful explanations that can be easily interpreted by humans. The point cloud data we consider represents 3D objects such as cars, guitars, and laptops. We make use of point cloud segmentation models to generate explanations for the working of classification models. The segments are used to introduce perturbations into the input point cloud data and generate saliency maps. The perturbations are introduced using the novel point-shifting mechanism proposed in this work which ensures that the shifted points no longer influence the output of the classification algorithm. In contrast to previous methods, the segments used by our method are meaningful, i.e. humans can easily interpret the meaning of the segments. Thus, the benefit of our method over other methods is its ability to produce more meaningful saliency maps. We compare our method with the use of classical clustering algorithms to generate explanations. We also analyze the saliency maps generated for example inputs using our method to demonstrate the usefulness of the method in generating meaningful explanations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 14 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.22020v1",
    "published_date": "2025-07-29 17:12:16 UTC",
    "updated_date": "2025-07-29 17:12:16 UTC"
  },
  {
    "arxiv_id": "2507.22010v1",
    "title": "Exploring the Stratified Space Structure of an RL Game with the Volume Growth Transform",
    "authors": [
      "Justin Curry",
      "Brennan Lagasse",
      "Ngoc B. Lam",
      "Gregory Cox",
      "David Rosenbluth",
      "Alberto Speranzon"
    ],
    "abstract": "In this work, we explore the structure of the embedding space of a transformer model trained for playing a particular reinforcement learning (RL) game. Specifically, we investigate how a transformer-based Proximal Policy Optimization (PPO) model embeds visual inputs in a simple environment where an agent must collect \"coins\" while avoiding dynamic obstacles consisting of \"spotlights.\" By adapting Robinson et al.'s study of the volume growth transform for LLMs to the RL setting, we find that the token embedding space for our visual coin collecting game is also not a manifold, and is better modeled as a stratified space, where local dimension can vary from point to point. We further strengthen Robinson's method by proving that fairly general volume growth curves can be realized by stratified spaces. Finally, we carry out an analysis that suggests that as an RL agent acts, its latent representation alternates between periods of low local dimension, while following a fixed sub-strategy, and bursts of high local dimension, where the agent achieves a sub-goal (e.g., collecting an object) or where the environmental complexity increases (e.g., more obstacles appear). Consequently, our work suggests that the distribution of dimensions in a stratified latent space may provide a new geometric indicator of complexity for RL games.",
    "categories": [
      "math.AT",
      "cs.AI",
      "cs.CG",
      "cs.LG",
      "math.DG"
    ],
    "primary_category": "math.AT",
    "comment": "17 pages and 8 figures. Preliminary report. Feedback welcome!",
    "pdf_url": "https://arxiv.org/pdf/2507.22010v1",
    "published_date": "2025-07-29 17:00:33 UTC",
    "updated_date": "2025-07-29 17:00:33 UTC"
  },
  {
    "arxiv_id": "2507.22009v1",
    "title": "PHAX: A Structured Argumentation Framework for User-Centered Explainable AI in Public Health and Biomedical Sciences",
    "authors": [
      "Bahar lgen",
      "Akshat Dubey",
      "Georges Hattab"
    ],
    "abstract": "Ensuring transparency and trust in AI-driven public health and biomedical sciences systems requires more than accurate predictions-it demands explanations that are clear, contextual, and socially accountable. While explainable AI (XAI) has advanced in areas like feature attribution and model interpretability, most methods still lack the structure and adaptability needed for diverse health stakeholders, including clinicians, policymakers, and the general public. We introduce PHAX-a Public Health Argumentation and eXplainability framework-that leverages structured argumentation to generate human-centered explanations for AI outputs. PHAX is a multi-layer architecture combining defeasible reasoning, adaptive natural language techniques, and user modeling to produce context-aware, audience-specific justifications. More specifically, we show how argumentation enhances explainability by supporting AI-driven decision-making, justifying recommendations, and enabling interactive dialogues across user types. We demonstrate the applicability of PHAX through use cases such as medical term simplification, patient-clinician communication, and policy justification. In particular, we show how simplification decisions can be modeled as argument chains and personalized based on user expertise-enhancing both interpretability and trust. By aligning formal reasoning methods with communicative demands, PHAX contributes to a broader vision of transparent, human-centered AI in public health.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint. Under review",
    "pdf_url": "https://arxiv.org/pdf/2507.22009v1",
    "published_date": "2025-07-29 17:00:15 UTC",
    "updated_date": "2025-07-29 17:00:15 UTC"
  },
  {
    "arxiv_id": "2507.22002v2",
    "title": "Bridging Synthetic and Real-World Domains: A Human-in-the-Loop Weakly-Supervised Framework for Industrial Toxic Emission Segmentation",
    "authors": [
      "Yida Tao",
      "Yen-Chia Hsu"
    ],
    "abstract": "Industrial smoke segmentation is critical for air-quality monitoring and environmental protection but is often hampered by the high cost and scarcity of pixel-level annotations in real-world settings. We introduce CEDANet, a human-in-the-loop, class-aware domain adaptation framework that uniquely integrates weak, citizen-provided video-level labels with adversarial feature alignment. Specifically, we refine pseudo-labels generated by a source-trained segmentation model using citizen votes, and employ class-specific domain discriminators to transfer rich source-domain representations to the industrial domain. Comprehensive experiments on SMOKE5K and custom IJmond datasets demonstrate that CEDANet achieves an F1-score of 0.414 and a smoke-class IoU of 0.261 with citizen feedback, vastly outperforming the baseline model, which scored 0.083 and 0.043 respectively. This represents a five-fold increase in F1-score and a six-fold increase in smoke-class IoU. Notably, CEDANet with citizen-constrained pseudo-labels achieves performance comparable to the same architecture trained on limited 100 fully annotated images with F1-score of 0.418 and IoU of 0.264, demonstrating its ability to reach small-sampled fully supervised-level accuracy without target-domain annotations. Our research validates the scalability and cost-efficiency of combining citizen science with weakly supervised domain adaptation, offering a practical solution for complex, data-scarce environmental monitoring applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22002v2",
    "published_date": "2025-07-29 16:53:00 UTC",
    "updated_date": "2025-11-12 03:05:37 UTC"
  },
  {
    "arxiv_id": "2507.22000v1",
    "title": "Staining and locking computer vision models without retraining",
    "authors": [
      "Oliver J. Sutton",
      "Qinghua Zhou",
      "George Leete",
      "Alexander N. Gorban",
      "Ivan Y. Tyukin"
    ],
    "abstract": "We introduce new methods of staining and locking computer vision models, to protect their owners' intellectual property. Staining, also known as watermarking, embeds secret behaviour into a model which can later be used to identify it, while locking aims to make a model unusable unless a secret trigger is inserted into input images. Unlike existing methods, our algorithms can be used to stain and lock pre-trained models without requiring fine-tuning or retraining, and come with provable, computable guarantees bounding their worst-case false positive rates. The stain and lock are implemented by directly modifying a small number of the model's weights and have minimal impact on the (unlocked) model's performance. Locked models are unlocked by inserting a small `trigger patch' into the corner of the input image. We present experimental results showing the efficacy of our methods and demonstrating their practical performance on a variety of computer vision models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 9 pages of appendices, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.22000v1",
    "published_date": "2025-07-29 16:47:34 UTC",
    "updated_date": "2025-07-29 16:47:34 UTC"
  },
  {
    "arxiv_id": "2507.21992v1",
    "title": "Teach Me to Trick: Exploring Adversarial Transferability via Knowledge Distillation",
    "authors": [
      "Siddhartha Pradhan",
      "Shikshya Shiwakoti",
      "Neha Bathuri"
    ],
    "abstract": "We investigate whether knowledge distillation (KD) from multiple heterogeneous teacher models can enhance the generation of transferable adversarial examples. A lightweight student model is trained using two KD strategies: curriculum-based switching and joint optimization, with ResNet50 and DenseNet-161 as teachers. The trained student is then used to generate adversarial examples using FG, FGS, and PGD attacks, which are evaluated against a black-box target model (GoogLeNet). Our results show that student models distilled from multiple teachers achieve attack success rates comparable to ensemble-based baselines, while reducing adversarial example generation time by up to a factor of six. An ablation study further reveals that lower temperature settings and the inclusion of hard-label supervision significantly enhance transferability. These findings suggest that KD can serve not only as a model compression technique but also as a powerful tool for improving the efficiency and effectiveness of black-box adversarial attacks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.21992v1",
    "published_date": "2025-07-29 16:43:54 UTC",
    "updated_date": "2025-07-29 16:43:54 UTC"
  },
  {
    "arxiv_id": "2507.21990v3",
    "title": "ChemDFM-R: A Chemical Reasoning LLM Enhanced with Atomized Chemical Knowledge",
    "authors": [
      "Zihan Zhao",
      "Bo Chen",
      "Ziping Wan",
      "Lu Chen",
      "Xuanze Lin",
      "Shiyang Yu",
      "Situo Zhang",
      "Da Ma",
      "Zichen Zhu",
      "Danyang Zhang",
      "Huayang Wang",
      "Zhongyang Dai",
      "Liyang Wen",
      "Xin Chen",
      "Kai Yu"
    ],
    "abstract": "While large language models (LLMs) have achieved impressive progress, their application in scientific domains such as chemistry remains hindered by shallow domain understanding and limited reasoning capabilities. In this work, we focus on the specific field of chemistry and develop a Chemical Reasoning LLM, ChemDFM-R. We first construct a comprehensive dataset of atomized chemical knowledge, ChemFG, annotating the presence of functional groups in molecules and the changes of functional groups during chemical reactions, to enhance the model's understanding of the fundamental principles and internal logic of chemistry. Then, we propose a mixed-source distillation method that integrates expertise in atomized knowledge with general reasoning skills, followed by domain-specific reinforcement learning to enhance chemical reasoning. Experiments on diverse chemical benchmarks demonstrate that ChemDFM-R achieves cutting-edge performance while providing interpretable, rationale-driven outputs. Further case studies illustrate how explicit reasoning chains significantly improve the model's reliability, transparency, and practicality in real-world human-AI collaboration scenarios.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "18 figures, 11 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.21990v3",
    "published_date": "2025-07-29 16:40:49 UTC",
    "updated_date": "2025-12-17 05:06:09 UTC"
  },
  {
    "arxiv_id": "2507.21976v3",
    "title": "Compression Strategies for Efficient Multimodal LLMs in Medical Contexts",
    "authors": [
      "Tanvir A. Khan",
      "Aranya Saha",
      "Ismam N. Swapnil",
      "Mohammad A. Haque"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) hold huge potential for usage in the medical domain, but their computational costs necessitate efficient compression techniques. This paper evaluates the impact of structural pruning and activation-aware quantization on a fine-tuned LLAVA model for medical applications. We propose a novel layer selection method for pruning, analyze different quantization techniques, and assess the performance trade-offs in a prune-SFT-quantize pipeline. Our proposed method enables MLLMs with 7B parameters to run within 4 GB of VRAM, reducing memory usage by 70% while achieving 4% higher model performance compared to traditional pruning and quantization techniques in the same compression ratio.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.21976v3",
    "published_date": "2025-07-29 16:25:51 UTC",
    "updated_date": "2025-09-23 19:50:14 UTC"
  },
  {
    "arxiv_id": "2507.21974v1",
    "title": "Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks",
    "authors": [
      "Mohamed Sana",
      "Nicola Piovesan",
      "Antonio De Domenico",
      "Yibin Kang",
      "Haozhe Zhang",
      "Merouane Debbah",
      "Fadhel Ayed"
    ],
    "abstract": "Root Cause Analysis (RCA) in mobile networks remains a challenging task due to the need for interpretability, domain expertise, and causal reasoning. In this work, we propose a lightweight framework that leverages Large Language Models (LLMs) for RCA. To do so, we introduce TeleLogs, a curated dataset of annotated troubleshooting problems designed to benchmark RCA capabilities. Our evaluation reveals that existing open-source reasoning LLMs struggle with these problems, underscoring the need for domain-specific adaptation. To address this issue, we propose a two-stage training methodology that combines supervised fine-tuning with reinforcement learning to improve the accuracy and reasoning quality of LLMs. The proposed approach fine-tunes a series of RCA models to integrate domain knowledge and generate structured, multi-step diagnostic explanations, improving both interpretability and effectiveness. Extensive experiments across multiple LLM sizes show significant performance gains over state-of-the-art reasoning and non-reasoning models, including strong generalization to randomized test variants. These results demonstrate the promise of domain-adapted, reasoning-enhanced LLMs for practical and explainable RCA in network operation and management.",
    "categories": [
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21974v1",
    "published_date": "2025-07-29 16:21:42 UTC",
    "updated_date": "2025-07-29 16:21:42 UTC"
  },
  {
    "arxiv_id": "2507.21964v1",
    "title": "Thou Shalt Not Prompt: Zero-Shot Human Activity Recognition in Smart Homes via Language Modeling of Sensor Data & Activities",
    "authors": [
      "Sourish Gunesh Dhekane",
      "Thomas Ploetz"
    ],
    "abstract": "Developing zero-shot human activity recognition (HAR) methods is a critical direction in smart home research -- considering its impact on making HAR systems work across smart homes having diverse sensing modalities, layouts, and activities of interest. The state-of-the-art solutions along this direction are based on generating natural language descriptions of the sensor data and feeding it via a carefully crafted prompt to the LLM to perform classification. Despite their performance guarantees, such ``prompt-the-LLM'' approaches carry several risks, including privacy invasion, reliance on an external service, and inconsistent predictions due to version changes, making a case for alternative zero-shot HAR methods that do not require prompting the LLMs. In this paper, we propose one such solution that models sensor data and activities using natural language, leveraging its embeddings to perform zero-shot classification and thereby bypassing the need to prompt the LLMs for activity predictions. The impact of our work lies in presenting a detailed case study on six datasets, highlighting how language modeling can bolster HAR systems in zero-shot recognition.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21964v1",
    "published_date": "2025-07-29 16:13:10 UTC",
    "updated_date": "2025-07-29 16:13:10 UTC"
  },
  {
    "arxiv_id": "2507.21954v1",
    "title": "Fine-Tuning Code Language Models to Detect Cross-Language Bugs",
    "authors": [
      "Zengyang Li",
      "Yimeng Li",
      "Binbin Huang",
      "Peng Liang",
      "Ran Mo",
      "Hui Liu",
      "Yutao Ma"
    ],
    "abstract": "Multilingual programming, which involves using multiple programming languages (PLs) in a single project, is increasingly common due to its benefits. However, it introduces cross-language bugs (CLBs), which arise from interactions between different PLs and are difficult to detect by single-language bug detection tools. This paper investigates the potential of pre-trained code language models (CodeLMs) in CLB detection. We developed CLCFinder, a cross-language code identification tool, and constructed a CLB dataset involving three PL combinations (Python-C/C++, Java-C/C++, and Python-Java) with nine interaction types. We fine-tuned 13 CodeLMs on this dataset and evaluated their performance, analyzing the effects of dataset size, token sequence length, and code comments. Results show that all CodeLMs performed poorly before fine-tuning, but exhibited varying degrees of performance improvement after fine-tuning, with UniXcoder-base achieving the best F1 score (0.7407). Notably, small fine-tuned CodeLMs tended to performe better than large ones. CodeLMs fine-tuned on single-language bug datasets performed poorly on CLB detection, demonstrating the distinction between CLBs and single-language bugs. Additionally, increasing the fine-tuning dataset size significantly improved performance, while longer token sequences did not necessarily improve the model performance. The impact of code comments varied across models. Some fine-tuned CodeLMs' performance was improved, while others showed degraded performance.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "33 pages, 6 images, 9 tables, Manuscript submitted to a journal (2025)",
    "pdf_url": "https://arxiv.org/pdf/2507.21954v1",
    "published_date": "2025-07-29 16:06:08 UTC",
    "updated_date": "2025-07-29 16:06:08 UTC"
  },
  {
    "arxiv_id": "2507.21953v1",
    "title": "MapAgent: Trajectory-Constructed Memory-Augmented Planning for Mobile Task Automation",
    "authors": [
      "Yi Kong",
      "Dianxi Shi",
      "Guoli Yang",
      "Zhang ke-di",
      "Chenlin Huang",
      "Xiaopeng Li",
      "Songchang Jin"
    ],
    "abstract": "The recent advancement of autonomous agents powered by Large Language Models (LLMs) has demonstrated significant potential for automating tasks on mobile devices through graphical user interfaces (GUIs). Despite initial progress, these agents still face challenges when handling complex real-world tasks. These challenges arise from a lack of knowledge about real-life mobile applications in LLM-based agents, which may lead to ineffective task planning and even cause hallucinations. To address these challenges, we propose a novel LLM-based agent framework called MapAgent that leverages memory constructed from historical trajectories to augment current task planning. Specifically, we first propose a trajectory-based memory mechanism that transforms task execution trajectories into a reusable and structured page-memory database. Each page within a trajectory is extracted as a compact yet comprehensive snapshot, capturing both its UI layout and functional context. Secondly, we introduce a coarse-to-fine task planning approach that retrieves relevant pages from the memory database based on similarity and injects them into the LLM planner to compensate for potential deficiencies in understanding real-world app scenarios, thereby achieving more informed and context-aware task planning. Finally, planned tasks are transformed into executable actions through a task executor supported by a dual-LLM architecture, ensuring effective tracking of task progress. Experimental results in real-world scenarios demonstrate that MapAgent achieves superior performance to existing methods. The code will be open-sourced to support further research.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21953v1",
    "published_date": "2025-07-29 16:05:32 UTC",
    "updated_date": "2025-07-29 16:05:32 UTC"
  },
  {
    "arxiv_id": "2507.21949v2",
    "title": "Contrast-Prior Enhanced Duality for Mask-Free Shadow Removal",
    "authors": [
      "Jiyu Wu",
      "Yifan Liu",
      "Jiancheng Huang",
      "Mingfu Yan",
      "Shifeng Chen"
    ],
    "abstract": "Existing shadow removal methods often rely on shadow masks, which are challenging to acquire in real-world scenarios. Exploring intrinsic image cues, such as local contrast information, presents a potential alternative for guiding shadow removal in the absence of explicit masks. However, the cue's inherent ambiguity becomes a critical limitation in complex scenes, where it can fail to distinguish true shadows from low-reflectance objects and intricate background textures. To address this motivation, we propose the Adaptive Gated Dual-Branch Attention (AGBA) mechanism. AGBA dynamically filters and re-weighs the contrast prior to effectively disentangle shadow features from confounding visual elements. Furthermore, to tackle the persistent challenge of restoring soft shadow boundaries and fine-grained details, we introduce a diffusion-based Frequency-Contrast Fusion Network (FCFN) that leverages high-frequency and contrast cues to guide the generative process. Extensive experiments demonstrate that our method achieves state-of-the-art results among mask-free approaches while maintaining competitive performance relative to mask-based methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "There are unresolved authorship disputes related to this submission, and the current version does not reflect an agreed authorship list",
    "pdf_url": "https://arxiv.org/pdf/2507.21949v2",
    "published_date": "2025-07-29 16:00:42 UTC",
    "updated_date": "2025-11-26 02:38:56 UTC"
  },
  {
    "arxiv_id": "2507.21947v1",
    "title": "Enhancing Generalization in Data-free Quantization via Mixup-class Prompting",
    "authors": [
      "Jiwoong Park",
      "Chaeun Lee",
      "Yongseok Choi",
      "Sein Park",
      "Deokki Hong",
      "Jungwook Choi"
    ],
    "abstract": "Post-training quantization (PTQ) improves efficiency but struggles with limited calibration data, especially under privacy constraints. Data-free quantization (DFQ) mitigates this by generating synthetic images using generative models such as generative adversarial networks (GANs) and text-conditioned latent diffusion models (LDMs), while applying existing PTQ algorithms. However, the relationship between generated synthetic images and the generalizability of the quantized model during PTQ remains underexplored. Without investigating this relationship, synthetic images generated by previous prompt engineering methods based on single-class prompts suffer from issues such as polysemy, leading to performance degradation. We propose \\textbf{mixup-class prompt}, a mixup-based text prompting strategy that fuses multiple class labels at the text prompt level to generate diverse, robust synthetic data. This approach enhances generalization, and improves optimization stability in PTQ. We provide quantitative insights through gradient norm and generalization error analysis. Experiments on convolutional neural networks (CNNs) and vision transformers (ViTs) show that our method consistently outperforms state-of-the-art DFQ methods like GenQ. Furthermore, it pushes the performance boundary in extremely low-bit scenarios, achieving new state-of-the-art accuracy in challenging 2-bit weight, 4-bit activation (W2A4) quantization.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21947v1",
    "published_date": "2025-07-29 16:00:20 UTC",
    "updated_date": "2025-07-29 16:00:20 UTC"
  },
  {
    "arxiv_id": "2508.03722v1",
    "title": "Multimodal Video Emotion Recognition with Reliable Reasoning Priors",
    "authors": [
      "Zhepeng Wang",
      "Yingjian Zhu",
      "Guanghao Dong",
      "Hongzhu Yi",
      "Feng Chen",
      "Xinming Wang",
      "Jun Xie"
    ],
    "abstract": "This study investigates the integration of trustworthy prior reasoning knowledge from MLLMs into multimodal emotion recognition. We employ Gemini to generate fine-grained, modality-separable reasoning traces, which are injected as priors during the fusion stage to enrich cross-modal interactions. To mitigate the pronounced class-imbalance in multimodal emotion recognition, we introduce Balanced Dual-Contrastive Learning, a loss formulation that jointly balances inter-class and intra-class distributions. Applied to the MER2024 benchmark, our prior-enhanced framework yields substantial performance gains, demonstrating that the reliability of MLLM-derived reasoning can be synergistically combined with the domain adaptability of lightweight fusion networks for robust, scalable emotion recognition.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "preprint",
    "pdf_url": "https://arxiv.org/pdf/2508.03722v1",
    "published_date": "2025-07-29 15:55:23 UTC",
    "updated_date": "2025-07-29 15:55:23 UTC"
  },
  {
    "arxiv_id": "2507.21931v1",
    "title": "Post-Training Large Language Models via Reinforcement Learning from Self-Feedback",
    "authors": [
      "Carel van Niekerk",
      "Renato Vukovic",
      "Benjamin Matthias Ruppik",
      "Hsien-chin Lin",
      "Milica Gai"
    ],
    "abstract": "Large Language Models (LLMs) often produce plausible but poorly-calibrated answers, limiting their reliability on reasoning-intensive tasks. We present Reinforcement Learning from Self-Feedback (RLSF), a post-training stage that uses the model's own confidence as an intrinsic reward, mimicking how humans learn in the absence of external feedback. After a frozen LLM generates several chain-of-thought solutions, we define and compute the confidence of each final answer span and rank the traces accordingly. These synthetic preferences are then used to fine-tune the policy with standard preference optimization, similar to RLHF yet requiring no human labels, gold answers, or externally curated rewards.\n  RLSF simultaneously (i) refines the model's probability estimates -- restoring well-behaved calibration -- and (ii) strengthens step-by-step reasoning, yielding improved performance on arithmetic reasoning and multiple-choice question answering.\n  By turning a model's own uncertainty into useful self-feedback, RLSF affirms reinforcement learning on intrinsic model behaviour as a principled and data-efficient component of the LLM post-training pipeline and warrents further research in intrinsic rewards for LLM post-training.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21931v1",
    "published_date": "2025-07-29 15:46:26 UTC",
    "updated_date": "2025-07-29 15:46:26 UTC"
  },
  {
    "arxiv_id": "2507.21929v1",
    "title": "Libra: Large Chinese-based Safeguard for AI Content",
    "authors": [
      "Ziyang Chen",
      "Huimu Yu",
      "Xing Wu",
      "Dongqin Liu",
      "Songlin Hu"
    ],
    "abstract": "Large language models (LLMs) excel in text understanding and generation but raise significant safety and ethical concerns in high-stakes applications. To mitigate these risks, we present Libra-Guard, a cutting-edge safeguard system designed to enhance the safety of Chinese-based LLMs. Leveraging a two-stage curriculum training pipeline, Libra-Guard enhances data efficiency by employing guard pretraining on synthetic samples, followed by fine-tuning on high-quality, real-world data, thereby significantly reducing reliance on manual annotations. To enable rigorous safety evaluations, we also introduce Libra-Test, the first benchmark specifically designed to evaluate the effectiveness of safeguard systems for Chinese content. It covers seven critical harm scenarios and includes over 5,700 samples annotated by domain experts. Experiments show that Libra-Guard achieves 86.79% accuracy, outperforming Qwen2.5-14B-Instruct (74.33%) and ShieldLM-Qwen-14B-Chat (65.69%), and nearing closed-source models like Claude-3.5-Sonnet and GPT-4o. These contributions establish a robust framework for advancing the safety governance of Chinese LLMs and represent a tentative step toward developing safer, more reliable Chinese AI systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21929v1",
    "published_date": "2025-07-29 15:45:50 UTC",
    "updated_date": "2025-07-29 15:45:50 UTC"
  },
  {
    "arxiv_id": "2507.21928v4",
    "title": "Vibe Coding as a Reconfiguration of Intent Mediation in Software Development: Definition, Implications, and Research Agenda",
    "authors": [
      "Christian Meske",
      "Tobias Hermanns",
      "Esther von der Weiden",
      "Kai-Uwe Loser",
      "Thorsten Berger"
    ],
    "abstract": "Software development is undergoing a fundamental transformation as vibe coding becomes widespread, with large portions of contemporary codebases now being generated by Artificial Intelligence (AI). The disconnect between rapid adoption and limited conceptual understanding highlights the need for an inquiry into this emerging paradigm. Drawing on an intent perspective and historical analysis, we define vibe coding as a software development paradigm where humans and Generative AI (GenAI) engage in collaborative flow to co-create software artifacts through natural language dialogue, shifting the mediation of developer intent from deterministic instruction to probabilistic inference. By intent mediation, we refer to the fundamental process through which developers translate their conceptual goals into representations that computational systems can execute. Our results show that vibe coding redistributes epistemic labor between humans and machines, shifting expertise from technical implementation toward collaborative orchestration. We identify key opportunities, including democratization, acceleration, and systemic leverage, alongside risks such as black-box codebases, responsibility gaps, and ecosystem bias. We conclude with a research agenda spanning human-, technology-, and organization-centered directions to guide future investigations of this paradigm.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21928v4",
    "published_date": "2025-07-29 15:44:55 UTC",
    "updated_date": "2026-01-08 16:44:45 UTC"
  },
  {
    "arxiv_id": "2507.21922v1",
    "title": "SwinECAT: A Transformer-based fundus disease classification model with Shifted Window Attention and Efficient Channel Attention",
    "authors": [
      "Peiran Gu",
      "Teng Yao",
      "Mengshen He",
      "Fuhao Duan",
      "Feiyan Liu",
      "RenYuan Peng",
      "Bao Ge"
    ],
    "abstract": "In recent years, artificial intelligence has been increasingly applied in the field of medical imaging. Among these applications, fundus image analysis presents special challenges, including small lesion areas in certain fundus diseases and subtle inter-disease differences, which can lead to reduced prediction accuracy and overfitting in the models. To address these challenges, this paper proposes the Transformer-based model SwinECAT, which combines the Shifted Window (Swin) Attention with the Efficient Channel Attention (ECA) Attention. SwinECAT leverages the Swin Attention mechanism in the Swin Transformer backbone to effectively capture local spatial structures and long-range dependencies within fundus images. The lightweight ECA mechanism is incorporated to guide the SwinECAT's attention toward critical feature channels, enabling more discriminative feature representation. In contrast to previous studies that typically classify fundus images into 4 to 6 categories, this work expands fundus disease classification to 9 distinct types, thereby enhancing the granularity of diagnosis. We evaluate our method on the Eye Disease Image Dataset (EDID) containing 16,140 fundus images for 9-category classification. Experimental results demonstrate that SwinECAT achieves 88.29\\% accuracy, with weighted F1-score of 0.88 and macro F1-score of 0.90. The classification results of our proposed model SwinECAT significantly outperform the baseline Swin Transformer and multiple compared baseline models. To our knowledge, this represents the highest reported performance for 9-category classification on this public dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.21922v1",
    "published_date": "2025-07-29 15:35:46 UTC",
    "updated_date": "2025-07-29 15:35:46 UTC"
  },
  {
    "arxiv_id": "2507.21919v2",
    "title": "Training language models to be warm and empathetic makes them less reliable and more sycophantic",
    "authors": [
      "Lujain Ibrahim",
      "Franziska Sofia Hafner",
      "Luc Rocher"
    ],
    "abstract": "Artificial intelligence (AI) developers are increasingly building language models with warm and empathetic personas that millions of people now use for advice, therapy, and companionship. Here, we show how this creates a significant trade-off: optimizing language models for warmth undermines their reliability, especially when users express vulnerability. We conducted controlled experiments on five language models of varying sizes and architectures, training them to produce warmer, more empathetic responses, then evaluating them on safety-critical tasks. Warm models showed substantially higher error rates (+10 to +30 percentage points) than their original counterparts, promoting conspiracy theories, providing incorrect factual information, and offering problematic medical advice. They were also significantly more likely to validate incorrect user beliefs, particularly when user messages expressed sadness. Importantly, these effects were consistent across different model architectures, and occurred despite preserved performance on standard benchmarks, revealing systematic risks that current evaluation practices may fail to detect. As human-like AI systems are deployed at an unprecedented scale, our findings indicate a need to rethink how we develop and oversee these systems that are reshaping human relationships and social interaction.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21919v2",
    "published_date": "2025-07-29 15:33:20 UTC",
    "updated_date": "2025-07-30 10:11:59 UTC"
  },
  {
    "arxiv_id": "2507.21905v2",
    "title": "Evaluating Deepfake Detectors in the Wild",
    "authors": [
      "Viacheslav Pirogov",
      "Maksim Artemev"
    ],
    "abstract": "Deepfakes powered by advanced machine learning models present a significant and evolving threat to identity verification and the authenticity of digital media. Although numerous detectors have been developed to address this problem, their effectiveness has yet to be tested when applied to real-world data. In this work we evaluate modern deepfake detectors, introducing a novel testing procedure designed to mimic real-world scenarios for deepfake detection. Using state-of-the-art deepfake generation methods, we create a comprehensive dataset containing more than 500,000 high-quality deepfake images. Our analysis shows that detecting deepfakes still remains a challenging task. The evaluation shows that in fewer than half of the deepfake detectors tested achieved an AUC score greater than 60%, with the lowest being 50%. We demonstrate that basic image manipulations, such as JPEG compression or image enhancement, can significantly reduce model performance. All code and data are publicly available at https://github.com/SumSubstance/Deepfake-Detectors-in-the-Wild.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to the ICML 2025 Workshop 'DataWorld: Unifying Data Curation Frameworks Across Domains'",
    "pdf_url": "https://arxiv.org/pdf/2507.21905v2",
    "published_date": "2025-07-29 15:17:00 UTC",
    "updated_date": "2025-08-04 13:19:11 UTC"
  },
  {
    "arxiv_id": "2507.21899v1",
    "title": "LLM-based Content Classification Approach for GitHub Repositories by the README Files",
    "authors": [
      "Malik Uzair Mehmood",
      "Shahid Hussain",
      "Wen Li Wang",
      "Muhammad Usama Malik"
    ],
    "abstract": "GitHub is the world's most popular platform for storing, sharing, and managing code. Every GitHub repository has a README file associated with it. The README files should contain project-related information as per the recommendations of GitHub to support the usage and improvement of repositories. However, GitHub repository owners sometimes neglected these recommendations. This prevents a GitHub repository from reaching its full potential. This research posits that the comprehensiveness of a GitHub repository's README file significantly influences its adoption and utilization, with a lack of detail potentially hindering its full potential for widespread engagement and impact within the research community. Large Language Models (LLMs) have shown great performance in many text-based tasks including text classification, text generation, text summarization and text translation. In this study, an approach is developed to fine-tune LLMs for automatically classifying different sections of GitHub README files. Three encoder-only LLMs are utilized, including BERT, DistilBERT and RoBERTa. These pre-trained models are then fine-tuned based on a gold-standard dataset consisting of 4226 README file sections. This approach outperforms current state-of-the-art methods and has achieved an overall F1 score of 0.98. Moreover, we have also investigated the use of Parameter-Efficient Fine-Tuning (PEFT) techniques like Low-Rank Adaptation (LoRA) and shown an economical alternative to full fine-tuning without compromising much performance. The results demonstrate the potential of using LLMs in designing an automatic classifier for categorizing the content of GitHub README files. Consequently, this study contributes to the development of automated tools for GitHub repositories to improve their identifications and potential usages.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 4 Figures",
    "pdf_url": "https://arxiv.org/pdf/2507.21899v1",
    "published_date": "2025-07-29 15:09:38 UTC",
    "updated_date": "2025-07-29 15:09:38 UTC"
  },
  {
    "arxiv_id": "2507.21890v1",
    "title": "Data-driven quantum Koopman method for simulating nonlinear dynamics",
    "authors": [
      "Baoyang Zhang",
      "Zhen Lu",
      "Yaomin Zhao",
      "Yue Yang"
    ],
    "abstract": "Quantum computation offers potential exponential speedups for simulating certain physical systems, but its application to nonlinear dynamics is inherently constrained by the requirement of unitary evolution. We propose the quantum Koopman method (QKM), a data-driven framework that bridges this gap through transforming nonlinear dynamics into linear unitary evolution in higher-dimensional observable spaces. Leveraging the Koopman operator theory to achieve a global linearization, our approach maps system states into a hierarchy of Hilbert spaces using a deep autoencoder. Within the linearized embedding spaces, the state representation is decomposed into modulus and phase components, and the evolution is governed by a set of unitary Koopman operators that act exclusively on the phase. These operators are constructed from diagonal Hamiltonians with coefficients learned from data, a structure designed for efficient implementation on quantum hardware. This architecture enables direct multi-step prediction, and the operator's computational complexity scales logarithmically with the observable space dimension. The QKM is validated across diverse nonlinear systems. Its predictions maintain relative errors below 6% for reaction-diffusion systems and shear flows, and capture key statistics in 2D turbulence. This work establishes a practical pathway for quantum-accelerated simulation of nonlinear phenomena, exploring a framework built on the synergy between deep learning for global linearization and quantum algorithms for unitary dynamics evolution.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG",
      "physics.comp-ph",
      "physics.flu-dyn"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21890v1",
    "published_date": "2025-07-29 15:00:56 UTC",
    "updated_date": "2025-07-29 15:00:56 UTC"
  },
  {
    "arxiv_id": "2507.21886v6",
    "title": "Efficient Pain Recognition via Respiration Signals: A Single Cross-Attention Transformer Multi-Window Fusion Pipeline",
    "authors": [
      "Stefanos Gkikas",
      "Ioannis Kyprakis",
      "Manolis Tsiknakis"
    ],
    "abstract": "Pain is a complex condition that affects a large portion of the population. Accurate and consistent evaluation is essential for individuals experiencing pain and supports the development of effective and advanced management strategies. Automatic pain assessment systems provide continuous monitoring, aid clinical decision-making, and aim to reduce distress while preventing functional decline. This study has been submitted to the Second Multimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN). The proposed method introduces a pipeline that employs respiration as the input signal and integrates a highly efficient cross-attention transformer with a multi-windowing strategy. Extensive experiments demonstrate that respiration serves as a valuable physiological modality for pain assessment. Furthermore, results show that compact and efficient models, when properly optimized, can deliver strong performance, often surpassing larger counterparts. The proposed multi-window strategy effectively captures short-term and long-term features, along with global characteristics, enhancing the model's representational capacity.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: text overlap with arXiv:2507.21881, arXiv:2507.21875",
    "pdf_url": "https://arxiv.org/pdf/2507.21886v6",
    "published_date": "2025-07-29 14:58:29 UTC",
    "updated_date": "2025-09-15 23:02:53 UTC"
  },
  {
    "arxiv_id": "2507.21882v1",
    "title": "The Impact of Foundational Models on Patient-Centric e-Health Systems",
    "authors": [
      "Elmira Onagh",
      "Alireza Davoodi",
      "Maleknaz Nayebi"
    ],
    "abstract": "As Artificial Intelligence (AI) becomes increasingly embedded in healthcare technologies, understanding the maturity of AI in patient-centric applications is critical for evaluating its trustworthiness, transparency, and real-world impact. In this study, we investigate the integration and maturity of AI feature integration in 116 patient-centric healthcare applications. Using Large Language Models (LLMs), we extracted key functional features, which are then categorized into different stages of the Gartner AI maturity model. Our results show that over 86.21\\% of applications remain at the early stages of AI integration, while only 13.79% demonstrate advanced AI integration.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "Paper published in COMPSAC 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.21882v1",
    "published_date": "2025-07-29 14:56:01 UTC",
    "updated_date": "2025-07-29 14:56:01 UTC"
  },
  {
    "arxiv_id": "2507.21881v7",
    "title": "Multi-Representation Diagrams for Pain Recognition: Integrating Various Electrodermal Activity Signals into a Single Image",
    "authors": [
      "Stefanos Gkikas",
      "Ioannis Kyprakis",
      "Manolis Tsiknakis"
    ],
    "abstract": "Pain is a multifaceted phenomenon that affects a substantial portion of the population. Reliable and consistent evaluation supports individuals experiencing pain and enables the development of effective and advanced management strategies. Automatic pain-assessment systems provide continuous monitoring, guide clinical decision-making, and aim to reduce distress while preventing functional decline. Incorporating physiological signals allows these systems to deliver objective, accurate insights into an individual's condition. This study has been submitted to the Second Multimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN). The proposed method introduces a pipeline that employs electrodermal activity signals as the input modality. Multiple signal representations are generated and visualized as waveforms, which are then jointly presented within a unified multi-representation diagram. Extensive experiments using diverse processing and filtering techniques, along with various representation combinations, highlight the effectiveness of the approach. It consistently achieves comparable and, in several cases, superior results to traditional fusion methods, positioning it as a robust alternative for integrating different signal representations or modalities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: text overlap with arXiv:2507.21875",
    "pdf_url": "https://arxiv.org/pdf/2507.21881v7",
    "published_date": "2025-07-29 14:53:28 UTC",
    "updated_date": "2025-09-15 22:59:43 UTC"
  },
  {
    "arxiv_id": "2507.21875v7",
    "title": "Tiny-BioMoE: a Lightweight Embedding Model for Biosignal Analysis",
    "authors": [
      "Stefanos Gkikas",
      "Ioannis Kyprakis",
      "Manolis Tsiknakis"
    ],
    "abstract": "Pain is a complex and pervasive condition that affects a significant portion of the population. Accurate and consistent assessment is essential for individuals suffering from pain, as well as for developing effective management strategies in a healthcare system. Automatic pain assessment systems enable continuous monitoring, support clinical decision-making, and help minimize patient distress while mitigating the risk of functional deterioration. Leveraging physiological signals offers objective and precise insights into a person's state, and their integration in a multimodal framework can further enhance system performance. This study has been submitted to the Second Multimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN). The proposed approach introduces Tiny-BioMoE, a lightweight pretrained embedding model for biosignal analysis. Trained on 4.4 million biosignal image representations and consisting of only 7.3 million parameters, it serves as an effective tool for extracting high-quality embeddings for downstream tasks. Extensive experiments involving electrodermal activity, blood volume pulse, respiratory signals, peripheral oxygen saturation, and their combinations highlight the model's effectiveness across diverse modalities in automatic pain recognition tasks. The model's architecture (code) and weights are available at https://github.com/GkikasStefanos/Tiny-BioMoE.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21875v7",
    "published_date": "2025-07-29 14:46:39 UTC",
    "updated_date": "2025-09-15 22:56:17 UTC"
  },
  {
    "arxiv_id": "2507.21873v1",
    "title": "A Neuro-Symbolic Approach for Probabilistic Reasoning on Graph Data",
    "authors": [
      "Raffaele Pojer",
      "Andrea Passerini",
      "Kim G. Larsen",
      "Manfred Jaeger"
    ],
    "abstract": "Graph neural networks (GNNs) excel at predictive tasks on graph-structured data but often lack the ability to incorporate symbolic domain knowledge and perform general reasoning. Relational Bayesian Networks (RBNs), in contrast, enable fully generative probabilistic modeling over graph-like structures and support rich symbolic knowledge and probabilistic inference. This paper presents a neuro-symbolic framework that seamlessly integrates GNNs into RBNs, combining the learning strength of GNNs with the flexible reasoning capabilities of RBNs.\n  We develop two implementations of this integration: one compiles GNNs directly into the native RBN language, while the other maintains the GNN as an external component. Both approaches preserve the semantics and computational properties of GNNs while fully aligning with the RBN modeling paradigm. We also propose a maximum a-posteriori (MAP) inference method for these neuro-symbolic models.\n  To demonstrate the framework's versatility, we apply it to two distinct problems. First, we transform a GNN for node classification into a collective classification model that explicitly models homo- and heterophilic label patterns, substantially improving accuracy. Second, we introduce a multi-objective network optimization problem in environmental planning, where MAP inference supports complex decision-making. Both applications include new publicly available benchmark datasets.\n  This work introduces a powerful and coherent neuro-symbolic approach to graph data, bridging learning and reasoning in ways that enable novel applications and improved performance across diverse tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to the Journal of Artificial Intelligence Research (JAIR); under revision. 29 pages, 6 figures. Code available at https://github.com/raffaelepojer/NeSy-for-graph-data",
    "pdf_url": "https://arxiv.org/pdf/2507.21873v1",
    "published_date": "2025-07-29 14:43:25 UTC",
    "updated_date": "2025-07-29 14:43:25 UTC"
  },
  {
    "arxiv_id": "2507.21872v3",
    "title": "MultiEditor: Controllable Multimodal Object Editing for Driving Scenarios Using 3D Gaussian Splatting Priors",
    "authors": [
      "Shouyi Lu",
      "Zihan Lin",
      "Chao Lu",
      "Huanran Wang",
      "Guirong Zhuo",
      "Lianqing Zheng"
    ],
    "abstract": "Autonomous driving systems rely heavily on multimodal perception data to understand complex environments. However, the long-tailed distribution of real-world data hinders generalization, especially for rare but safety-critical vehicle categories. To address this challenge, we propose MultiEditor, a dual-branch latent diffusion framework designed to edit images and LiDAR point clouds in driving scenarios jointly. At the core of our approach is introducing 3D Gaussian Splatting (3DGS) as a structural and appearance prior for target objects. Leveraging this prior, we design a multi-level appearance control mechanism--comprising pixel-level pasting, semantic-level guidance, and multi-branch refinement--to achieve high-fidelity reconstruction across modalities. We further propose a depth-guided deformable cross-modality condition module that adaptively enables mutual guidance between modalities using 3DGS-rendered depth, significantly enhancing cross-modality consistency. Extensive experiments demonstrate that MultiEditor achieves superior performance in visual and geometric fidelity, editing controllability, and cross-modality consistency. Furthermore, generating rare-category vehicle data with MultiEditor substantially enhances the detection accuracy of perception models on underrepresented classes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21872v3",
    "published_date": "2025-07-29 14:42:52 UTC",
    "updated_date": "2025-07-31 10:21:15 UTC"
  },
  {
    "arxiv_id": "2507.21848v1",
    "title": "EDGE-GRPO: Entropy-Driven GRPO with Guided Error Correction for Advantage Diversity",
    "authors": [
      "Xingjian Zhang",
      "Siwei Wen",
      "Wenjun Wu",
      "Lei Huang"
    ],
    "abstract": "Large Language Models (LLMs) have made remarkable progress in enhancing step-by-step reasoning through reinforcement learning. However, the Group Relative Policy Optimization (GRPO) algorithm, which relies on sparse reward rules, often encounters the issue of identical rewards within groups, leading to the advantage collapse problem. Existing works typically address this challenge from two perspectives: enforcing model reflection to enhance response diversity, and introducing internal feedback to augment the training signal (advantage). In this work, we begin by analyzing the limitations of model reflection and investigating the policy entropy of responses at the fine-grained sample level. Based on our experimental findings, we propose the EDGE-GRPO algorithm, which adopts \\textbf{E}ntropy-\\textbf{D}riven Advantage and \\textbf{G}uided \\textbf{E}rror Correction to effectively mitigate the problem of advantage collapse. Extensive experiments on several main reasoning benchmarks demonstrate the effectiveness and superiority of our approach. It is available at https://github.com/ZhangXJ199/EDGE-GRPO.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21848v1",
    "published_date": "2025-07-29 14:23:58 UTC",
    "updated_date": "2025-07-29 14:23:58 UTC"
  },
  {
    "arxiv_id": "2507.21846v2",
    "title": "Probabilistic Active Goal Recognition",
    "authors": [
      "Chenyuan Zhang",
      "Cristian Rojas Cardenas",
      "Hamid Rezatofighi",
      "Mor Vered",
      "Buser Say"
    ],
    "abstract": "In multi-agent environments, effective interaction hinges on understanding the beliefs and intentions of other agents. While prior work on goal recognition has largely treated the observer as a passive reasoner, Active Goal Recognition (AGR) focuses on strategically gathering information to reduce uncertainty. We adopt a probabilistic framework for Active Goal Recognition and propose an integrated solution that combines a joint belief update mechanism with a Monte Carlo Tree Search (MCTS) algorithm, allowing the observer to plan efficiently and infer the actor's hidden goal without requiring domain-specific knowledge. Through comprehensive empirical evaluation in a grid-based domain, we show that our joint belief update significantly outperforms passive goal recognition, and that our domain-independent MCTS performs comparably to our strong domain-specific greedy baseline. These results establish our solution as a practical and robust framework for goal inference, advancing the field toward more interactive and adaptive multi-agent systems.",
    "categories": [
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "Camera Ready Version in KR2025",
    "pdf_url": "https://arxiv.org/pdf/2507.21846v2",
    "published_date": "2025-07-29 14:22:29 UTC",
    "updated_date": "2025-08-11 22:09:28 UTC"
  },
  {
    "arxiv_id": "2507.21839v1",
    "title": "Against racing to AGI: Cooperation, deterrence, and catastrophic risks",
    "authors": [
      "Leonard Dung",
      "Max Hellrigel-Holderbaum"
    ],
    "abstract": "AGI Racing is the view that it is in the self-interest of major actors in AI development, especially powerful nations, to accelerate their frontier AI development to build highly capable AI, especially artificial general intelligence (AGI), before competitors have a chance. We argue against AGI Racing. First, the downsides of racing to AGI are much higher than portrayed by this view. Racing to AGI would substantially increase catastrophic risks from AI, including nuclear instability, and undermine the prospects of technical AI safety research to be effective. Second, the expected benefits of racing may be lower than proponents of AGI Racing hold. In particular, it is questionable whether winning the race enables complete domination over losers. Third, international cooperation and coordination, and perhaps carefully crafted deterrence measures, constitute viable alternatives to racing to AGI which have much smaller risks and promise to deliver most of the benefits that racing to AGI is supposed to provide. Hence, racing to AGI is not in anyone's self-interest as other actions, particularly incentivizing and seeking international cooperation around AI issues, are preferable.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21839v1",
    "published_date": "2025-07-29 14:17:08 UTC",
    "updated_date": "2025-07-29 14:17:08 UTC"
  },
  {
    "arxiv_id": "2507.21833v2",
    "title": "Analysis of Fourier Neural Operators via Effective Field Theory",
    "authors": [
      "Taeyoung Kim"
    ],
    "abstract": "Fourier Neural Operators (FNOs) have emerged as leading surrogates for solver operators for various functional problems, yet their stability, generalization and frequency behavior lack a principled explanation. We present a systematic effective field theory analysis of FNOs in an infinite dimensional function space, deriving closed recursion relations for the layer kernel and four point vertex and then examining three practically important settings-analytic activations, scale invariant cases and architectures with residual connections. The theory shows that nonlinear activations inevitably couple frequency inputs to high frequency modes that are otherwise discarded by spectral truncation, and experiments confirm this frequency transfer. For wide networks, we derive explicit criticality conditions on the weight initialization ensemble that ensure small input perturbations maintain a uniform scale across depth, and we confirm experimentally that the theoretically predicted ratio of kernel perturbations matches the measurements. Taken together, our results quantify how nonlinearity enables neural operators to capture non-trivial features, supply criteria for hyperparameter selection via criticality analysis, and explain why scale invariant activations and residual connections enhance feature learning in FNOs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.21833v2",
    "published_date": "2025-07-29 14:10:46 UTC",
    "updated_date": "2025-09-16 15:06:05 UTC"
  },
  {
    "arxiv_id": "2507.21831v1",
    "title": "Introducing HALC: A general pipeline for finding optimal prompting strategies for automated coding with LLMs in the computational social sciences",
    "authors": [
      "Andreas Reich",
      "Claudia Thoms",
      "Tobias Schrimpf"
    ],
    "abstract": "LLMs are seeing widespread use for task automation, including automated coding in the social sciences. However, even though researchers have proposed different prompting strategies, their effectiveness varies across LLMs and tasks. Often trial and error practices are still widespread. We propose HALC$-$a general pipeline that allows for the systematic and reliable construction of optimal prompts for any given coding task and model, permitting the integration of any prompting strategy deemed relevant. To investigate LLM coding and validate our pipeline, we sent a total of 1,512 individual prompts to our local LLMs in over two million requests. We test prompting strategies and LLM task performance based on few expert codings (ground truth). When compared to these expert codings, we find prompts that code reliably for single variables ($$climate = .76; $$movement = .78) and across two variables ($$climate = .71; $$movement = .74) using the LLM Mistral NeMo. Our prompting strategies are set up in a way that aligns the LLM to our codebook$-$we are not optimizing our codebook for LLM friendliness. Our paper provides insights into the effectiveness of different prompting strategies, crucial influencing factors, and the identification of reliable prompts for each coding task and model.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "48 pages, 9 figures and 8 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.21831v1",
    "published_date": "2025-07-29 14:10:31 UTC",
    "updated_date": "2025-07-29 14:10:31 UTC"
  },
  {
    "arxiv_id": "2507.21830v4",
    "title": "DualSG: A Dual-Stream Explicit Semantic-Guided Multivariate Time Series Forecasting Framework",
    "authors": [
      "Kuiye Ding",
      "Fanda Fan",
      "Yao Wang",
      "Ruijie jian",
      "Xiaorui Wang",
      "Luqi Gong",
      "Yishan Jiang",
      "Chunjie Luo",
      "Jianfeng Zhan"
    ],
    "abstract": "Multivariate Time Series Forecasting plays a key role in many applications. Recent works have explored using Large Language Models for MTSF to take advantage of their reasoning abilities. However, many methods treat LLMs as end-to-end forecasters, which often leads to a loss of numerical precision and forces LLMs to handle patterns beyond their intended design. Alternatively, methods that attempt to align textual and time series modalities within latent space frequently encounter alignment difficulty. In this paper, we propose to treat LLMs not as standalone forecasters, but as semantic guidance modules within a dual-stream framework. We propose DualSG, a dual-stream framework that provides explicit semantic guidance, where LLMs act as Semantic Guides to refine rather than replace traditional predictions. As part of DualSG, we introduce Time Series Caption, an explicit prompt format that summarizes trend patterns in natural language and provides interpretable context for LLMs, rather than relying on implicit alignment between text and time series in the latent space. We also design a caption-guided fusion module that explicitly models inter-variable relationships while reducing noise and computation. Experiments on real-world datasets from diverse domains show that DualSG consistently outperforms 15 state-of-the-art baselines, demonstrating the value of explicitly combining numerical forecasting with semantic guidance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been accepted by ACM Multimedia 2025 (ACM MM 2025)",
    "pdf_url": "https://arxiv.org/pdf/2507.21830v4",
    "published_date": "2025-07-29 14:08:09 UTC",
    "updated_date": "2025-09-18 09:23:30 UTC"
  },
  {
    "arxiv_id": "2508.09992v1",
    "title": "OpenFPL: An open-source forecasting method rivaling state-of-the-art Fantasy Premier League services",
    "authors": [
      "Daniel Groos"
    ],
    "abstract": "Fantasy Premier League engages the football community in selecting the Premier League players who will perform best from gameweek to gameweek. Access to accurate performance forecasts gives participants an edge over competitors by guiding expectations about player outcomes and reducing uncertainty in squad selection. However, high-accuracy forecasts are currently limited to commercial services whose inner workings are undisclosed and that rely on proprietary data. This paper aims to democratize access to highly accurate forecasts of player performance by presenting OpenFPL, an open-source Fantasy Premier League forecasting method developed exclusively from public data. Comprising position-specific ensemble models optimized on Fantasy Premier League and Understat data from four previous seasons (2020-21 to 2023-24), OpenFPL achieves accuracy comparable to a leading commercial service when tested prospectively on data from the 2024-25 season. OpenFPL also surpasses the commercial benchmark for high-return players ($>$ 2 points), which are most influential for rank gains. These findings hold across one-, two-, and three-gameweek forecast horizons, supporting long-term planning of transfers and strategies while also informing final-day decisions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Models and inference code are freely available at https://github.com/daniegr/OpenFPL",
    "pdf_url": "https://arxiv.org/pdf/2508.09992v1",
    "published_date": "2025-07-29 13:59:51 UTC",
    "updated_date": "2025-07-29 13:59:51 UTC"
  },
  {
    "arxiv_id": "2507.21823v1",
    "title": "An Agentic AI for a New Paradigm in Business Process Development",
    "authors": [
      "Mohammad Azarijafari",
      "Luisa Mich",
      "Michele Missikoff"
    ],
    "abstract": "Artificial Intelligence agents represent the next major revolution in the continuous technological evolution of industrial automation. In this paper, we introduce a new approach for business process design and development that leverages the capabilities of Agentic AI. Departing from the traditional task-based approach to business process design, we propose an agent-based method, where agents contribute to the achievement of business goals, identified by a set of business objects. When a single agent cannot fulfill a goal, we have a merge goal that can be achieved through the collaboration of multiple agents. The proposed model leads to a more modular and intelligent business process development by organizing it around goals, objects, and agents. As a result, this approach enables flexible and context-aware automation in dynamic industrial environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21823v1",
    "published_date": "2025-07-29 13:58:24 UTC",
    "updated_date": "2025-07-29 13:58:24 UTC"
  },
  {
    "arxiv_id": "2507.22094v1",
    "title": "Scaling and Distilling Transformer Models for sEMG",
    "authors": [
      "Nicholas Mehlman",
      "Jean-Christophe Gagnon-Audet",
      "Michael Shvartsman",
      "Kelvin Niu",
      "Alexander H. Miller",
      "Shagun Sodhani"
    ],
    "abstract": "Surface electromyography (sEMG) signals offer a promising avenue for developing innovative human-computer interfaces by providing insights into muscular activity. However, the limited volume of training data and computational constraints during deployment have restricted the investigation of scaling up the model size for solving sEMG tasks. In this paper, we demonstrate that vanilla transformer models can be effectively scaled up on sEMG data and yield improved cross-user performance up to 110M parameters, surpassing the model size regime investigated in other sEMG research (usually <10M parameters). We show that >100M-parameter models can be effectively distilled into models 50x smaller with minimal loss of performance (<1.5% absolute). This results in efficient and expressive models suitable for complex real-time sEMG tasks in real-world environments.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at TMLR 2025 (https://openreview.net/forum?id=hFPWThwUiZ), 11 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.22094v1",
    "published_date": "2025-07-29 13:41:59 UTC",
    "updated_date": "2025-07-29 13:41:59 UTC"
  },
  {
    "arxiv_id": "2507.21802v3",
    "title": "MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE",
    "authors": [
      "Junzhe Li",
      "Yutao Cui",
      "Tao Huang",
      "Yinping Ma",
      "Chun Fan",
      "Miles Yang",
      "Zhao Zhong"
    ],
    "abstract": "Although GRPO substantially enhances flow matching models in human preference alignment of image generation, methods such as FlowGRPO and DanceGRPO still exhibit inefficiency due to the necessity of sampling and optimizing over all denoising steps specified by the Markov Decision Process (MDP). In this paper, we propose $\\textbf{MixGRPO}$, a novel framework that leverages the flexibility of mixed sampling strategies through the integration of stochastic differential equations (SDE) and ordinary differential equations (ODE). This streamlines the optimization process within the MDP to improve efficiency and boost performance. Specifically, MixGRPO introduces a sliding window mechanism, using SDE sampling and GRPO-guided optimization only within the window, while applying ODE sampling outside. This design confines sampling randomness to the time-steps within the window, thereby reducing the optimization overhead, and allowing for more focused gradient updates to accelerate convergence. Additionally, as time-steps beyond the sliding window are not involved in optimization, higher-order solvers are supported for faster sampling. So we present a faster variant, termed $\\textbf{MixGRPO-Flash}$, which further improves training efficiency while achieving comparable performance. MixGRPO exhibits substantial gains across multiple dimensions of human preference alignment, outperforming DanceGRPO in both effectiveness and efficiency, with nearly 50% lower training time. Notably, MixGRPO-Flash further reduces training time by 71%.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21802v3",
    "published_date": "2025-07-29 13:40:09 UTC",
    "updated_date": "2026-01-13 08:15:44 UTC"
  },
  {
    "arxiv_id": "2507.21799v1",
    "title": "Unlocking Interpretability for RF Sensing: A Complex-Valued White-Box Transformer",
    "authors": [
      "Xie Zhang",
      "Yina Wang",
      "Chenshu Wu"
    ],
    "abstract": "The empirical success of deep learning has spurred its application to the radio-frequency (RF) domain, leading to significant advances in Deep Wireless Sensing (DWS). However, most existing DWS models function as black boxes with limited interpretability, which hampers their generalizability and raises concerns in security-sensitive physical applications. In this work, inspired by the remarkable advances of white-box transformers, we present RF-CRATE, the first mathematically interpretable deep network architecture for RF sensing, grounded in the principles of complex sparse rate reduction. To accommodate the unique RF signals, we conduct non-trivial theoretical derivations that extend the original real-valued white-box transformer to the complex domain. By leveraging the CR-Calculus framework, we successfully construct a fully complex-valued white-box transformer with theoretically derived self-attention and residual multi-layer perceptron modules. Furthermore, to improve the model's ability to extract discriminative features from limited wireless data, we introduce Subspace Regularization, a novel regularization strategy that enhances feature diversity, resulting in an average performance improvement of 19.98% across multiple sensing tasks. We extensively evaluate RF-CRATE against seven baselines with multiple public and self-collected datasets involving different RF signals. The results show that RF-CRATE achieves performance on par with thoroughly engineered black-box models, while offering full mathematical interpretability. More importantly, by extending CRATE to the complex domain, RF-CRATE yields substantial improvements, achieving an average classification gain of 5.08% and reducing regression error by 10.34% across diverse sensing tasks compared to CRATE. RF-CRATE is fully open-sourced at: https://github.com/rfcrate/RF_CRATE.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21799v1",
    "published_date": "2025-07-29 13:35:51 UTC",
    "updated_date": "2025-07-29 13:35:51 UTC"
  },
  {
    "arxiv_id": "2507.21796v1",
    "title": "MoDeSuite: Robot Learning Task Suite for Benchmarking Mobile Manipulation with Deformable Objects",
    "authors": [
      "Yuying Zhang",
      "Kevin Sebastian Luck",
      "Francesco Verdoja",
      "Ville Kyrki",
      "Joni Pajarinen"
    ],
    "abstract": "Mobile manipulation is a critical capability for robots operating in diverse, real-world environments. However, manipulating deformable objects and materials remains a major challenge for existing robot learning algorithms. While various benchmarks have been proposed to evaluate manipulation strategies with rigid objects, there is still a notable lack of standardized benchmarks that address mobile manipulation tasks involving deformable objects.\n  To address this gap, we introduce MoDeSuite, the first Mobile Manipulation Deformable Object task suite, designed specifically for robot learning. MoDeSuite consists of eight distinct mobile manipulation tasks covering both elastic objects and deformable objects, each presenting a unique challenge inspired by real-world robot applications. Success in these tasks requires effective collaboration between the robot's base and manipulator, as well as the ability to exploit the deformability of the objects. To evaluate and demonstrate the use of the proposed benchmark, we train two state-of-the-art reinforcement learning algorithms and two imitation learning algorithms, highlighting the difficulties encountered and showing their performance in simulation. Furthermore, we demonstrate the practical relevance of the suite by deploying the trained policies directly into the real world with the Spot robot, showcasing the potential for sim-to-real transfer. We expect that MoDeSuite will open a novel research domain in mobile manipulation involving deformable objects. Find more details, code, and videos at https://sites.google.com/view/modesuite/home.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21796v1",
    "published_date": "2025-07-29 13:33:43 UTC",
    "updated_date": "2025-07-29 13:33:43 UTC"
  },
  {
    "arxiv_id": "2507.22951v1",
    "title": "Unifying Post-hoc Explanations of Knowledge Graph Completions",
    "authors": [
      "Alessandro Lonardi",
      "Samy Badreddine",
      "Tarek R. Besold",
      "Pablo Sanchez Martin"
    ],
    "abstract": "Post-hoc explainability for Knowledge Graph Completion (KGC) lacks formalization and consistent evaluations, hindering reproducibility and cross-study comparisons. This paper argues for a unified approach to post-hoc explainability in KGC. First, we propose a general framework to characterize post-hoc explanations via multi-objective optimization, balancing their effectiveness and conciseness. This unifies existing post-hoc explainability algorithms in KGC and the explanations they produce. Next, we suggest and empirically support improved evaluation protocols using popular metrics like Mean Reciprocal Rank and Hits@$k$. Finally, we stress the importance of interpretability as the ability of explanations to address queries meaningful to end-users. By unifying methods and refining evaluation standards, this work aims to make research in KGC explainability more reproducible and impactful.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22951v1",
    "published_date": "2025-07-29 13:31:48 UTC",
    "updated_date": "2025-07-29 13:31:48 UTC"
  },
  {
    "arxiv_id": "2507.21792v1",
    "title": "Hybrid Causal Identification and Causal Mechanism Clustering",
    "authors": [
      "Saixiong Liu",
      "Yuhua Qian",
      "Jue Li",
      "Honghong Cheng",
      "Feijiang Li"
    ],
    "abstract": "Bivariate causal direction identification is a fundamental and vital problem in the causal inference field. Among binary causal methods, most methods based on additive noise only use one single causal mechanism to construct a causal model. In the real world, observations are always collected in different environments with heterogeneous causal relationships. Therefore, on observation data, this paper proposes a Mixture Conditional Variational Causal Inference model (MCVCI) to infer heterogeneous causality. Specifically, according to the identifiability of the Hybrid Additive Noise Model (HANM), MCVCI combines the superior fitting capabilities of the Gaussian mixture model and the neural network and elegantly uses the likelihoods obtained from the probabilistic bounds of the mixture conditional variational auto-encoder as causal decision criteria. Moreover, we model the casual heterogeneity into cluster numbers and propose the Mixture Conditional Variational Causal Clustering (MCVCC) method, which can reveal causal mechanism expression. Compared with state-of-the-art methods, the comprehensive best performance demonstrates the effectiveness of the methods proposed in this paper on several simulated and real data.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21792v1",
    "published_date": "2025-07-29 13:27:15 UTC",
    "updated_date": "2025-07-29 13:27:15 UTC"
  },
  {
    "arxiv_id": "2507.21790v1",
    "title": "Can large language models assist choice modelling? Insights into prompting strategies and current models capabilities",
    "authors": [
      "Georges Sfeir",
      "Gabriel Nova",
      "Stephane Hess",
      "Sander van Cranenburgh"
    ],
    "abstract": "Large Language Models (LLMs) are widely used to support various workflows across different disciplines, yet their potential in choice modelling remains relatively unexplored. This work examines the potential of LLMs as assistive agents in the specification and, where technically feasible, estimation of Multinomial Logit models. We implement a systematic experimental framework involving thirteen versions of six leading LLMs (ChatGPT, Claude, DeepSeek, Gemini, Gemma, and Llama) evaluated under five experimental configurations. These configurations vary along three dimensions: modelling goal (suggesting vs. suggesting and estimating MNLs); prompting strategy (Zero-Shot vs. Chain-of-Thoughts); and information availability (full dataset vs. data dictionary only). Each LLM-suggested specification is implemented, estimated, and evaluated based on goodness-of-fit metrics, behavioural plausibility, and model complexity. Findings reveal that proprietary LLMs can generate valid and behaviourally sound utility specifications, particularly when guided by structured prompts. Open-weight models such as Llama and Gemma struggled to produce meaningful specifications. Claude 4 Sonnet consistently produced the best-fitting and most complex models, while GPT models suggested models with robust and stable modelling outcomes. Some LLMs performed better when provided with just data dictionary, suggesting that limiting raw data access may enhance internal reasoning capabilities. Among all LLMs, GPT o3 was uniquely capable of correctly estimating its own specifications by executing self-generated code. Overall, the results demonstrate both the promise and current limitations of LLMs as assistive agents in choice modelling, not only for model specification but also for supporting modelling decision and estimation, and provide practical guidance for integrating these tools into choice modellers' workflows.",
    "categories": [
      "econ.EM",
      "cs.AI"
    ],
    "primary_category": "econ.EM",
    "comment": "32 pages, 6 figures, 14 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.21790v1",
    "published_date": "2025-07-29 13:24:44 UTC",
    "updated_date": "2025-07-29 13:24:44 UTC"
  },
  {
    "arxiv_id": "2507.21770v1",
    "title": "Proposing a Semantic Movie Recommendation System Enhanced by ChatGPT's NLP Results",
    "authors": [
      "Ali Fallahi",
      "Azam Bastanfard",
      "Amineh Amini",
      "Hadi Saboohi"
    ],
    "abstract": "The importance of recommender systems on the web has grown, especially in the movie industry, with a vast selection of options to watch. To assist users in traversing available items and finding relevant results, recommender systems analyze operational data and investigate users' tastes and habits. Providing highly individualized suggestions can boost user engagement and satisfaction, which is one of the fundamental goals of the movie industry, significantly in online platforms. According to recent studies and research, using knowledge-based techniques and considering the semantic ideas of the textual data is a suitable way to get more appropriate results. This study provides a new method for building a knowledge graph based on semantic information. It uses the ChatGPT, as a large language model, to assess the brief descriptions of movies and extract their tone of voice. Results indicated that using the proposed method may significantly enhance accuracy rather than employing the explicit genres supplied by the publishers.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "May 2023, 6 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.21770v1",
    "published_date": "2025-07-29 12:55:45 UTC",
    "updated_date": "2025-07-29 12:55:45 UTC"
  },
  {
    "arxiv_id": "2508.08269v1",
    "title": "emg2tendon: From sEMG Signals to Tendon Control in Musculoskeletal Hands",
    "authors": [
      "Sagar Verma"
    ],
    "abstract": "Tendon-driven robotic hands offer unparalleled dexterity for manipulation tasks, but learning control policies for such systems presents unique challenges. Unlike joint-actuated robotic hands, tendon-driven systems lack a direct one-to-one mapping between motion capture (mocap) data and tendon controls, making the learning process complex and expensive. Additionally, visual tracking methods for real-world applications are prone to occlusions and inaccuracies, further complicating joint tracking. Wrist-wearable surface electromyography (sEMG) sensors present an inexpensive, robust alternative to capture hand motion. However, mapping sEMG signals to tendon control remains a significant challenge despite the availability of EMG-to-pose data sets and regression-based models in the existing literature.\n  We introduce the first large-scale EMG-to-Tendon Control dataset for robotic hands, extending the emg2pose dataset, which includes recordings from 193 subjects, spanning 370 hours and 29 stages with diverse gestures. This dataset incorporates tendon control signals derived using the MyoSuite MyoHand model, addressing limitations such as invalid poses in prior methods. We provide three baseline regression models to demonstrate emg2tendon utility and propose a novel diffusion-based regression model for predicting tendon control from sEMG recordings. This dataset and modeling framework marks a significant step forward for tendon-driven dexterous robotic manipulation, laying the groundwork for scalable and accurate tendon control in robotic hands. https://emg2tendon.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted in Robotics: Science and Systems (RSS 2025)",
    "pdf_url": "https://arxiv.org/pdf/2508.08269v1",
    "published_date": "2025-07-29 12:49:57 UTC",
    "updated_date": "2025-07-29 12:49:57 UTC"
  },
  {
    "arxiv_id": "2507.21763v1",
    "title": "Learning Kinetic Monte Carlo stochastic dynamics with Deep Generative Adversarial Networks",
    "authors": [
      "Daniele Lanzoni",
      "Olivier Pierre-Louis",
      "Roberto Bergamaschini",
      "Francesco Montalenti"
    ],
    "abstract": "We show that Generative Adversarial Networks (GANs) may be fruitfully exploited to learn stochastic dynamics, surrogating traditional models while capturing thermal fluctuations. Specifically, we showcase the application to a two-dimensional, many-particle system, focusing on surface-step fluctuations and on the related time-dependent roughness. After the construction of a dataset based on Kinetic Monte Carlo simulations, a conditional GAN is trained to propagate stochastically the state of the system in time, allowing the generation of new sequences with a reduced computational cost. Modifications with respect to standard GANs, which facilitate convergence and increase accuracy, are discussed. The trained network is demonstrated to quantitatively reproduce equilibrium and kinetic properties, including scaling laws, with deviations of a few percent from the exact value. Extrapolation limits and future perspectives are critically discussed.",
    "categories": [
      "cond-mat.stat-mech",
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.stat-mech",
    "comment": "15 pages, 8 figures, 2 appendices",
    "pdf_url": "https://arxiv.org/pdf/2507.21763v1",
    "published_date": "2025-07-29 12:48:03 UTC",
    "updated_date": "2025-07-29 12:48:03 UTC"
  },
  {
    "arxiv_id": "2507.21756v2",
    "title": "LiteFat: Lightweight Spatio-Temporal Graph Learning for Real-Time Driver Fatigue Detection",
    "authors": [
      "Jing Ren",
      "Suyu Ma",
      "Hong Jia",
      "Xiwei Xu",
      "Ivan Lee",
      "Haytham Fayek",
      "Xiaodong Li",
      "Feng Xia"
    ],
    "abstract": "Detecting driver fatigue is critical for road safety, as drowsy driving remains a leading cause of traffic accidents. Many existing solutions rely on computationally demanding deep learning models, which result in high latency and are unsuitable for embedded robotic devices with limited resources (such as intelligent vehicles/cars) where rapid detection is necessary to prevent accidents. This paper introduces LiteFat, a lightweight spatio-temporal graph learning model designed to detect driver fatigue efficiently while maintaining high accuracy and low computational demands. LiteFat involves converting streaming video data into spatio-temporal graphs (STG) using facial landmark detection, which focuses on key motion patterns and reduces unnecessary data processing. LiteFat uses MobileNet to extract facial features and create a feature matrix for the STG. A lightweight spatio-temporal graph neural network is then employed to identify signs of fatigue with minimal processing and low latency. Experimental results on benchmark datasets show that LiteFat performs competitively while significantly decreasing computational complexity and latency as compared to current state-of-the-art methods. This work enables the development of real-time, resource-efficient human fatigue detection systems that can be implemented upon embedded robotic devices.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.21756v2",
    "published_date": "2025-07-29 12:37:53 UTC",
    "updated_date": "2025-08-13 11:18:13 UTC"
  },
  {
    "arxiv_id": "2507.22092v1",
    "title": "Pathology Foundation Models are Scanner Sensitive: Benchmark and Mitigation with Contrastive ScanGen Loss",
    "authors": [
      "Gianluca Carloni",
      "Biagio Brattoli",
      "Seongho Keum",
      "Jongchan Park",
      "Taebum Lee",
      "Chang Ho Ahn",
      "Sergio Pereira"
    ],
    "abstract": "Computational pathology (CPath) has shown great potential in mining actionable insights from Whole Slide Images (WSIs). Deep Learning (DL) has been at the center of modern CPath, and while it delivers unprecedented performance, it is also known that DL may be affected by irrelevant details, such as those introduced during scanning by different commercially available scanners. This may lead to scanner bias, where the model outputs for the same tissue acquired by different scanners may vary. In turn, it hinders the trust of clinicians in CPath-based tools and their deployment in real-world clinical practices. Recent pathology Foundation Models (FMs) promise to provide better domain generalization capabilities. In this paper, we benchmark FMs using a multi-scanner dataset and show that FMs still suffer from scanner bias. Following this observation, we propose ScanGen, a contrastive loss function applied during task-specific fine-tuning that mitigates scanner bias, thereby enhancing the models' robustness to scanner variations. Our approach is applied to the Multiple Instance Learning task of Epidermal Growth Factor Receptor (EGFR) mutation prediction from H\\&E-stained WSIs in lung cancer. We observe that ScanGen notably enhances the ability to generalize across scanners, while retaining or improving the performance of EGFR mutation prediction.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.CV",
      "eess.IV",
      "q-bio.TO"
    ],
    "primary_category": "q-bio.QM",
    "comment": "Accepted (Oral) in MedAGI 2025 International Workshop at MICCAI Conference",
    "pdf_url": "https://arxiv.org/pdf/2507.22092v1",
    "published_date": "2025-07-29 12:35:08 UTC",
    "updated_date": "2025-07-29 12:35:08 UTC"
  },
  {
    "arxiv_id": "2507.21753v1",
    "title": "Towards a rigorous evaluation of RAG systems: the challenge of due diligence",
    "authors": [
      "Grgoire Martinon",
      "Alexandra Lorenzo de Brionne",
      "Jrme Bohard",
      "Antoine Lojou",
      "Damien Hervault",
      "Nicolas J-B. Brunel"
    ],
    "abstract": "The rise of generative AI, has driven significant advancements in high-risk sectors like healthcare and finance. The Retrieval-Augmented Generation (RAG) architecture, combining language models (LLMs) with search engines, is particularly notable for its ability to generate responses from document corpora. Despite its potential, the reliability of RAG systems in critical contexts remains a concern, with issues such as hallucinations persisting. This study evaluates a RAG system used in due diligence for an investment fund. We propose a robust evaluation protocol combining human annotations and LLM-Judge annotations to identify system failures, like hallucinations, off-topic, failed citations, and abstentions. Inspired by the Prediction Powered Inference (PPI) method, we achieve precise performance measurements with statistical guarantees. We provide a comprehensive dataset for further analysis. Our contributions aim to enhance the reliability and scalability of RAG systems evaluation protocols in industrial applications.",
    "categories": [
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.AI",
    "comment": "in French language. EvalLLM2025: Workshop on Evaluation Generative Models (LLM) and Challenges, AMIAD, 2025, Marseille, France",
    "pdf_url": "https://arxiv.org/pdf/2507.21753v1",
    "published_date": "2025-07-29 12:33:16 UTC",
    "updated_date": "2025-07-29 12:33:16 UTC"
  },
  {
    "arxiv_id": "2507.21752v1",
    "title": "SAT-Based Bounded Fitting for the Description Logic ALC",
    "authors": [
      "Maurice Funk",
      "Jean Christoph Jung",
      "Tom Voellmer"
    ],
    "abstract": "Bounded fitting is a general paradigm for learning logical formulas from positive and negative data examples, that has received considerable interest recently. We investigate bounded fitting for the description logic ALC and its syntactic fragments. We show that the underlying size-restricted fitting problem is NP-complete for all studied fragments, even in the special case of a single positive and a single negative example. By design, bounded fitting comes with probabilistic guarantees in Valiant's PAC learning framework. In contrast, we show that other classes of algorithms for learning ALC concepts do not provide such guarantees. Finally, we present an implementation of bounded fitting in ALC and its fragments based on a SAT solver. We discuss optimizations and compare our implementation to other concept learning tools.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "33 pages, full version of paper accepted at ISWC 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.21752v1",
    "published_date": "2025-07-29 12:32:16 UTC",
    "updated_date": "2025-07-29 12:32:16 UTC"
  },
  {
    "arxiv_id": "2507.21738v1",
    "title": "Zero-Shot Machine Unlearning with Proxy Adversarial Data Generation",
    "authors": [
      "Huiqiang Chen",
      "Tianqing Zhu",
      "Xin Yu",
      "Wanlei Zhou"
    ],
    "abstract": "Machine unlearning aims to remove the influence of specific samples from a trained model. A key challenge in this process is over-unlearning, where the model's performance on the remaining data significantly drops due to the change in the model's parameters. Existing unlearning algorithms depend on the remaining data to prevent this issue. As such, these methods are inapplicable in a more practical scenario, where only the unlearning samples are available (i.e., zero-shot unlearning). This paper presents a novel framework, ZS-PAG, to fill this gap. Our approach offers three key innovations: (1) we approximate the inaccessible remaining data by generating adversarial samples; (2) leveraging the generated samples, we pinpoint a specific subspace to perform the unlearning process, therefore preventing over-unlearning in the challenging zero-shot scenario; and (3) we consider the influence of the unlearning process on the remaining samples and design an influence-based pseudo-labeling strategy. As a result, our method further improves the model's performance after unlearning. The proposed method holds a theoretical guarantee, and experiments on various benchmarks validate the effectiveness and superiority of our proposed method over several baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IJCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.21738v1",
    "published_date": "2025-07-29 12:16:55 UTC",
    "updated_date": "2025-07-29 12:16:55 UTC"
  },
  {
    "arxiv_id": "2507.21727v1",
    "title": "GDAIP: A Graph-Based Domain Adaptive Framework for Individual Brain Parcellation",
    "authors": [
      "Jianfei Zhu",
      "Haiqi Zhu",
      "Shaohui Liu",
      "Feng Jiang",
      "Baichun Wei",
      "Chunzhi Yi"
    ],
    "abstract": "Recent deep learning approaches have shown promise in learning such individual brain parcellations from functional magnetic resonance imaging (fMRI). However, most existing methods assume consistent data distributions across domains and struggle with domain shifts inherent to real-world cross-dataset scenarios. To address this challenge, we proposed Graph Domain Adaptation for Individual Parcellation (GDAIP), a novel framework that integrates Graph Attention Networks (GAT) with Minimax Entropy (MME)-based domain adaptation. We construct cross-dataset brain graphs at both the group and individual levels. By leveraging semi-supervised training and adversarial optimization of the prediction entropy on unlabeled vertices from target brain graph, the reference atlas is adapted from the group-level brain graph to the individual brain graph, enabling individual parcellation under cross-dataset settings. We evaluated our method using parcellation visualization, Dice coefficient, and functional homogeneity. Experimental results demonstrate that GDAIP produces individual parcellations with topologically plausible boundaries, strong cross-session consistency, and ability of reflecting functional organization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21727v1",
    "published_date": "2025-07-29 12:04:09 UTC",
    "updated_date": "2025-07-29 12:04:09 UTC"
  },
  {
    "arxiv_id": "2507.21723v1",
    "title": "Detection Transformers Under the Knife: A Neuroscience-Inspired Approach to Ablations",
    "authors": [
      "Nils Htten",
      "Florian Hlken",
      "Hasan Tercan",
      "Tobias Meisen"
    ],
    "abstract": "In recent years, Explainable AI has gained traction as an approach to enhancing model interpretability and transparency, particularly in complex models such as detection transformers. Despite rapid advancements, a substantial research gap remains in understanding the distinct roles of internal components - knowledge that is essential for improving transparency and efficiency. Inspired by neuroscientific ablation studies, which investigate the functions of brain regions through selective impairment, we systematically analyze the impact of ablating key components in three state-of-the-art detection transformer models: Detection transformer (DETR), deformable detection transformer (DDETR), and DETR with improved denoising anchor boxes (DINO). The ablations target query embeddings, encoder and decoder multi-head self-attentions (MHSA) as well as decoder multi-head cross-attention (MHCA) layers. We evaluate the effects of these ablations on the performance metrics gIoU and F1-score, quantifying effects on both the classification and regression sub-tasks on the COCO dataset. To facilitate reproducibility and future research, we publicly release the DeepDissect library. Our findings reveal model-specific resilience patterns: while DETR is particularly sensitive to ablations in encoder MHSA and decoder MHCA, DDETR's multi-scale deformable attention enhances robustness, and DINO exhibits the greatest resilience due to its look-forward twice update rule, which helps distributing knowledge across blocks. These insights also expose structural redundancies, particularly in DDETR's and DINO's decoder MHCA layers, highlighting opportunities for model simplification without sacrificing performance. This study advances XAI for DETRs by clarifying the contributions of internal components to model performance, offering insights to optimize and improve transparency and efficiency in critical applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21723v1",
    "published_date": "2025-07-29 12:00:08 UTC",
    "updated_date": "2025-07-29 12:00:08 UTC"
  },
  {
    "arxiv_id": "2507.21706v1",
    "title": "EnTao-GPM: DNA Foundation Model for Predicting the Germline Pathogenic Mutations",
    "authors": [
      "Zekai Lin",
      "Haoran Sun",
      "Yucheng Guo",
      "Yujie Yang",
      "Yanwen Wang",
      "Bozhen Hu",
      "Chonghang Ye",
      "Qirong Yang",
      "Fan Zhong",
      "Xiaoming Zhang",
      "Lei Liu"
    ],
    "abstract": "Distinguishing pathogenic mutations from benign polymorphisms remains a critical challenge in precision medicine. EnTao-GPM, developed by Fudan University and BioMap, addresses this through three innovations: (1) Cross-species targeted pre-training on disease-relevant mammalian genomes (human, pig, mouse), leveraging evolutionary conservation to enhance interpretation of pathogenic motifs, particularly in non-coding regions; (2) Germline mutation specialization via fine-tuning on ClinVar and HGMD, improving accuracy for both SNVs and non-SNVs; (3) Interpretable clinical framework integrating DNA sequence embeddings with LLM-based statistical explanations to provide actionable insights. Validated against ClinVar, EnTao-GPM demonstrates superior accuracy in mutation classification. It revolutionizes genetic testing by enabling faster, more accurate, and accessible interpretation for clinical diagnostics (e.g., variant assessment, risk identification, personalized treatment) and research, advancing personalized medicine.",
    "categories": [
      "q-bio.GN",
      "cs.AI"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21706v1",
    "published_date": "2025-07-29 11:34:41 UTC",
    "updated_date": "2025-07-29 11:34:41 UTC"
  },
  {
    "arxiv_id": "2507.21705v1",
    "title": "Unrolling Dynamic Programming via Graph Filters",
    "authors": [
      "Sergio Rozada",
      "Samuel Rey",
      "Gonzalo Mateos",
      "Antonio G. Marques"
    ],
    "abstract": "Dynamic programming (DP) is a fundamental tool used across many engineering fields. The main goal of DP is to solve Bellman's optimality equations for a given Markov decision process (MDP). Standard methods like policy iteration exploit the fixed-point nature of these equations to solve them iteratively. However, these algorithms can be computationally expensive when the state-action space is large or when the problem involves long-term dependencies. Here we propose a new approach that unrolls and truncates policy iterations into a learnable parametric model dubbed BellNet, which we train to minimize the so-termed Bellman error from random value function initializations. Viewing the transition probability matrix of the MDP as the adjacency of a weighted directed graph, we draw insights from graph signal processing to interpret (and compactly re-parameterize) BellNet as a cascade of nonlinear graph filters. This fresh look facilitates a concise, transferable, and unifying representation of policy and value iteration, with an explicit handle on complexity during inference. Preliminary experiments conducted in a grid-like environment demonstrate that BellNet can effectively approximate optimal policies in a fraction of the iterations required by classical methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21705v1",
    "published_date": "2025-07-29 11:34:20 UTC",
    "updated_date": "2025-07-29 11:34:20 UTC"
  },
  {
    "arxiv_id": "2507.21695v1",
    "title": "Towards a Large Physics Benchmark",
    "authors": [
      "Kristian G. Barman",
      "Sascha Caron",
      "Faegheh Hasibi",
      "Eugene Shalugin",
      "Yoris Marcet",
      "Johannes Otte",
      "Henk W. de Regt",
      "Merijn Moody"
    ],
    "abstract": "We introduce a benchmark framework developed by and for the scientific community to evaluate, monitor and steer large language model development in fundamental physics. Building on philosophical concepts of scientific understanding and creativity, we develop a scoring system in which each question is scored by an expert for its correctness, difficulty, and surprise. The questions are of three forms: (i) multiple-choice questions for conceptual understanding, (ii) analytical problems requiring mathematical derivation, and (iii) openended tasks requiring complex problem solving. Our current dataset contains diverse set of examples, including a machine learning challenge to classify high-energy physics events, such as the four top quark signal. To ensure continued relevance, we propose a living benchmark, where physicists contribute questions, for instance alongside new publications. We invite contributions via: http://www.physicsbenchmarks.org/. We hope that this benchmark will enable a targeted AI development that can make a meaningful contribution to fundamental physics research.",
    "categories": [
      "physics.data-an",
      "cs.AI",
      "hep-ph",
      "physics.comp-ph",
      "physics.hist-ph"
    ],
    "primary_category": "physics.data-an",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21695v1",
    "published_date": "2025-07-29 11:19:00 UTC",
    "updated_date": "2025-07-29 11:19:00 UTC"
  },
  {
    "arxiv_id": "2507.21694v1",
    "title": "A Multi-Agent Generative AI Framework for IC Module-Level Verification Automation",
    "authors": [
      "Wenbo Liu",
      "Forbes Hou",
      "Jon Zhang",
      "Hong Liu",
      "Allen Lei"
    ],
    "abstract": "As large language models demonstrate enormous potential in the field of Electronic Design Automation (EDA), generative AI-assisted chip design is attracting widespread attention from academia and industry. Although these technologies have made preliminary progress in tasks such as code generation, their application in chip verification -- a critical bottleneck in the chip development cycle -- remains at an exploratory stage. This paper proposes an innovative Multi-Agent Verification Framework (MAVF) aimed at addressing the limitations of current single-LLM approaches in complex verification tasks. Our framework builds an automated transformation system from design specifications to testbench through the collaborative work of multiple specialized agents, including specification parsing, verification strategy generation, and code implementation. Through verification experiments on multiple chip modules of varying complexity, results show that MAVF significantly outperforms traditional manual methods and single-dialogue generative AI approaches in verification document parsing and generation, as well as automated testbench generation. This research opens new directions for exploring generative AI applications in verification automation, potentially providing effective approaches to solving the most challenging bottleneck issues in chip design.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "20 pages, 12 figures. DVCon China 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.21694v1",
    "published_date": "2025-07-29 11:17:47 UTC",
    "updated_date": "2025-07-29 11:17:47 UTC"
  },
  {
    "arxiv_id": "2507.21693v1",
    "title": "MultiAIGCD: A Comprehensive dataset for AI Generated Code Detection Covering Multiple Languages, Models,Prompts, and Scenarios",
    "authors": [
      "Basak Demirok",
      "Mucahid Kutlu",
      "Selin Mergen"
    ],
    "abstract": "As large language models (LLMs) rapidly advance, their role in code generation has expanded significantly. While this offers streamlined development, it also creates concerns in areas like education and job interviews. Consequently, developing robust systems to detect AI-generated code is imperative to maintain academic integrity and ensure fairness in hiring processes. In this study, we introduce MultiAIGCD, a dataset for AI-generated code detection for Python, Java, and Go. From the CodeNet dataset's problem definitions and human-authored codes, we generate several code samples in Java, Python, and Go with six different LLMs and three different prompts. This generation process covered three key usage scenarios: (i) generating code from problem descriptions, (ii) fixing runtime errors in human-written code, and (iii) correcting incorrect outputs. Overall, MultiAIGCD consists of 121,271 AI-generated and 32,148 human-written code snippets. We also benchmark three state-of-the-art AI-generated code detection models and assess their performance in various test scenarios such as cross-model and cross-language. We share our dataset and codes to support research in this field.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21693v1",
    "published_date": "2025-07-29 11:16:55 UTC",
    "updated_date": "2025-07-29 11:16:55 UTC"
  },
  {
    "arxiv_id": "2507.21690v1",
    "title": "APT: Improving Diffusion Models for High Resolution Image Generation with Adaptive Path Tracing",
    "authors": [
      "Sangmin Han",
      "Jinho Jeong",
      "Jinwoo Kim",
      "Seon Joo Kim"
    ],
    "abstract": "Latent Diffusion Models (LDMs) are generally trained at fixed resolutions, limiting their capability when scaling up to high-resolution images. While training-based approaches address this limitation by training on high-resolution datasets, they require large amounts of data and considerable computational resources, making them less practical. Consequently, training-free methods, particularly patch-based approaches, have become a popular alternative. These methods divide an image into patches and fuse the denoising paths of each patch, showing strong performance on high-resolution generation. However, we observe two critical issues for patch-based approaches, which we call ``patch-level distribution shift\" and ``increased patch monotonicity.\" To address these issues, we propose Adaptive Path Tracing (APT), a framework that combines Statistical Matching to ensure patch distributions remain consistent in upsampled latents and Scale-aware Scheduling to deal with the patch monotonicity. As a result, APT produces clearer and more refined details in high-resolution images. In addition, APT enables a shortcut denoising process, resulting in faster sampling with minimal quality degradation. Our experimental results confirm that APT produces more detailed outputs with improved inference speed, providing a practical approach to high-resolution image generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21690v1",
    "published_date": "2025-07-29 11:13:03 UTC",
    "updated_date": "2025-07-29 11:13:03 UTC"
  },
  {
    "arxiv_id": "2507.21684v1",
    "title": "diffSPH: Differentiable Smoothed Particle Hydrodynamics for Adjoint Optimization and Machine Learning",
    "authors": [
      "Rene Winchenbach",
      "Nils Thuerey"
    ],
    "abstract": "We present diffSPH, a novel open-source differentiable Smoothed Particle Hydrodynamics (SPH) framework developed entirely in PyTorch with GPU acceleration. diffSPH is designed centrally around differentiation to facilitate optimization and machine learning (ML) applications in Computational Fluid Dynamics~(CFD), including training neural networks and the development of hybrid models. Its differentiable SPH core, and schemes for compressible (with shock capturing and multi-phase flows), weakly compressible (with boundary handling and free-surface flows), and incompressible physics, enable a broad range of application areas. We demonstrate the framework's unique capabilities through several applications, including addressing particle shifting via a novel, target-oriented approach by minimizing physical and regularization loss terms, a task often intractable in traditional solvers. Further examples include optimizing initial conditions and physical parameters to match target trajectories, shape optimization, implementing a solver-in-the-loop setup to emulate higher-order integration, and demonstrating gradient propagation through hundreds of full simulation steps. Prioritizing readability, usability, and extensibility, this work offers a foundational platform for the CFD community to develop and deploy novel neural networks and adjoint optimization applications.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21684v1",
    "published_date": "2025-07-29 10:54:27 UTC",
    "updated_date": "2025-07-29 10:54:27 UTC"
  },
  {
    "arxiv_id": "2507.21664v1",
    "title": "Can the current trends of AI handle a full course of mathematics?",
    "authors": [
      "Mariam Alsayyad",
      "Fayadh Kadhem"
    ],
    "abstract": "This paper addresses the question of how able the current trends of Artificial Intelligence (AI) are in managing to take the responsibility of a full course of mathematics at a college level. The study evaluates this ability in four significant aspects, namely, creating a course syllabus, presenting selected material, answering student questions, and creating an assessment. It shows that even though the AI is strong in some important parts like organization and accuracy, there are still some human aspects that are far away from the current abilities of AI. There is still a hidden emotional part, even in science, that cannot be fulfilled by the AI in its current state. This paper suggests some recommendations to integrate the human and AI potentials to create better outcomes in terms of reaching the target of creating a full course of mathematics, at a university level, as best as possible.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "math.HO"
    ],
    "primary_category": "cs.AI",
    "comment": "36 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.21664v1",
    "published_date": "2025-07-29 10:21:15 UTC",
    "updated_date": "2025-07-29 10:21:15 UTC"
  },
  {
    "arxiv_id": "2507.21654v1",
    "title": "AI Literacy as a Key Driver of User Experience in AI-Powered Assessment: Insights from Socratic Mind",
    "authors": [
      "Meryem Yilmaz Soylu",
      "Jeonghyun Lee",
      "Jui-Tse Hung",
      "Christopher Zhang Cui",
      "David A. Joyner"
    ],
    "abstract": "As Artificial Intelligence (AI) tools become increasingly embedded in higher education, understanding how students interact with these systems is essential to supporting effective learning. This study examines how students' AI literacy and prior exposure to AI technologies shape their perceptions of Socratic Mind, an interactive AI-powered formative assessment tool. Drawing on Self-Determination Theory and user experience research, we analyze relationships among AI literacy, perceived usability, satisfaction, engagement, and perceived learning effectiveness. Data from 309 undergraduates in Computer Science and Business courses were collected through validated surveys. Partial least squares structural equation modeling showed that AI literacy - especially self-efficacy, conceptual understanding, and application skills - significantly predicts usability, satisfaction, and engagement. Usability and satisfaction, in turn, strongly predict perceived learning effectiveness, while prior AI exposure showed no significant effect. These findings highlight that AI literacy, rather than exposure alone, shapes student experiences. Designers should integrate adaptive guidance and user-centered features to support diverse literacy levels, fostering inclusive, motivating, and effective AI-based learning environments.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "34 pages, 1 figure, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.21654v1",
    "published_date": "2025-07-29 10:11:24 UTC",
    "updated_date": "2025-07-29 10:11:24 UTC"
  },
  {
    "arxiv_id": "2507.21653v1",
    "title": "DGP: A Dual-Granularity Prompting Framework for Fraud Detection with Graph-Enhanced LLMs",
    "authors": [
      "Yuan Li",
      "Jun Hu",
      "Bryan Hooi",
      "Bingsheng He",
      "Cheng Chen"
    ],
    "abstract": "Real-world fraud detection applications benefit from graph learning techniques that jointly exploit node features, often rich in textual data, and graph structural information. Recently, Graph-Enhanced LLMs emerge as a promising graph learning approach that converts graph information into prompts, exploiting LLMs' ability to reason over both textual and structural information. Among them, text-only prompting, which converts graph information to prompts consisting solely of text tokens, offers a solution that relies only on LLM tuning without requiring additional graph-specific encoders. However, text-only prompting struggles on heterogeneous fraud-detection graphs: multi-hop relations expand exponentially with each additional hop, leading to rapidly growing neighborhoods associated with dense textual information. These neighborhoods may overwhelm the model with long, irrelevant content in the prompt and suppress key signals from the target node, thereby degrading performance. To address this challenge, we propose Dual Granularity Prompting (DGP), which mitigates information overload by preserving fine-grained textual details for the target node while summarizing neighbor information into coarse-grained text prompts. DGP introduces tailored summarization strategies for different data modalities, bi-level semantic abstraction for textual fields and statistical aggregation for numerical features, enabling effective compression of verbose neighbor content into concise, informative prompts. Experiments across public and industrial datasets demonstrate that DGP operates within a manageable token budget while improving fraud detection performance by up to 6.8% (AUPRC) over state-of-the-art methods, showing the potential of Graph-Enhanced LLMs for fraud detection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21653v1",
    "published_date": "2025-07-29 10:10:47 UTC",
    "updated_date": "2025-07-29 10:10:47 UTC"
  },
  {
    "arxiv_id": "2507.21640v1",
    "title": "GUARD-CAN: Graph-Understanding and Recurrent Architecture for CAN Anomaly Detection",
    "authors": [
      "Hyeong Seon Kim",
      "Huy Kang Kim"
    ],
    "abstract": "Modern in-vehicle networks face various cyber threats due to the lack of encryption and authentication in the Controller Area Network (CAN). To address this security issue, this paper presents GUARD-CAN, an anomaly detection framework that combines graph-based representation learning with time-series modeling. GUARD-CAN splits CAN messages into fixed-length windows and converts each window into a graph that preserves message order. To detect anomalies in the timeaware and structure-aware context at the same window, GUARD-CAN takes advantage of the overcomplete Autoencoder (AE) and Graph Convolutional Network (GCN) to generate graph embedding vectors. The model groups these vectors into sequences and feeds them into the Gated Recurrent Unit (GRU) to detect temporal anomaly patterns across the graphs. GUARD-CAN performs anomaly detection at both the sequence level and the window level, and this allows multi-perspective performance evaluation. The model also verifies the importance of window size selection through an analysis based on Shannon entropy. As a result, GUARD-CAN shows that the proposed model detects four types of CAN attacks (flooding, fuzzing, replay and spoofing attacks) effectively without relying on complex feature engineering.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Comments:12 pages, 3 figures, 3 tables; accepted to the 26th World Conference on Information Security Applications (WISA 2025)",
    "pdf_url": "https://arxiv.org/pdf/2507.21640v1",
    "published_date": "2025-07-29 09:52:54 UTC",
    "updated_date": "2025-07-29 09:52:54 UTC"
  },
  {
    "arxiv_id": "2507.21638v1",
    "title": "Assistax: A Hardware-Accelerated Reinforcement Learning Benchmark for Assistive Robotics",
    "authors": [
      "Leonard Hinckeldey",
      "Elliot Fosong",
      "Elle Miller",
      "Rimvydas Rubavicius",
      "Trevor McInroe",
      "Patricia Wollstadt",
      "Christiane B. Wiebel-Herboth",
      "Subramanian Ramamoorthy",
      "Stefano V. Albrecht"
    ],
    "abstract": "The development of reinforcement learning (RL) algorithms has been largely driven by ambitious challenge tasks and benchmarks. Games have dominated RL benchmarks because they present relevant challenges, are inexpensive to run and easy to understand. While games such as Go and Atari have led to many breakthroughs, they often do not directly translate to real-world embodied applications. In recognising the need to diversify RL benchmarks and addressing complexities that arise in embodied interaction scenarios, we introduce Assistax: an open-source benchmark designed to address challenges arising in assistive robotics tasks. Assistax uses JAX's hardware acceleration for significant speed-ups for learning in physics-based simulations. In terms of open-loop wall-clock time, Assistax runs up to $370\\times$ faster when vectorising training runs compared to CPU-based alternatives. Assistax conceptualises the interaction between an assistive robot and an active human patient using multi-agent RL to train a population of diverse partner agents against which an embodied robotic agent's zero-shot coordination capabilities can be tested. Extensive evaluation and hyperparameter tuning for popular continuous control RL and MARL algorithms provide reliable baselines and establish Assistax as a practical benchmark for advancing RL research for assistive robotics. The code is available at: https://github.com/assistive-autonomy/assistax.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for the Coordination and Cooperation in Multi-Agent Reinforcement Learning Workshop at the Reinforcement Learning Conference 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.21638v1",
    "published_date": "2025-07-29 09:49:11 UTC",
    "updated_date": "2025-07-29 09:49:11 UTC"
  },
  {
    "arxiv_id": "2507.21637v1",
    "title": "Self-Aware Safety Augmentation: Leveraging Internal Semantic Understanding to Enhance Safety in Vision-Language Models",
    "authors": [
      "Wanying Wang",
      "Zeyu Ma",
      "Han Zheng",
      "Xin Tan",
      "Mingang Chen"
    ],
    "abstract": "Large vision-language models (LVLMs) are vulnerable to harmful input compared to their language-only backbones. We investigated this vulnerability by exploring LVLMs internal dynamics, framing their inherent safety understanding in terms of three key capabilities. Specifically, we define these capabilities as safety perception, semantic understanding, and alignment for linguistic expression, and experimentally pinpointed their primary locations within the model architecture. The results indicate that safety perception often emerges before comprehensive semantic understanding, leading to the reduction in safety. Motivated by these findings, we propose \\textbf{Self-Aware Safety Augmentation (SASA)}, a technique that projects informative semantic representations from intermediate layers onto earlier safety-oriented layers. This approach leverages the model's inherent semantic understanding to enhance safety recognition without fine-tuning. Then, we employ linear probing to articulate the model's internal semantic comprehension to detect the risk before the generation process. Extensive experiments on various datasets and tasks demonstrate that SASA significantly improves the safety of LVLMs, with minimal impact on the utility.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by ACM Multimedia 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.21637v1",
    "published_date": "2025-07-29 09:48:57 UTC",
    "updated_date": "2025-07-29 09:48:57 UTC"
  },
  {
    "arxiv_id": "2507.21636v1",
    "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling",
    "authors": [
      "Alessio Maritan"
    ],
    "abstract": "Large language model (LLM) agents integrate pre-trained LLMs with modular algorithmic components and have shown remarkable reasoning and decision-making abilities. In this work, we investigate their use for two tightly intertwined challenges in workforce management: staffing, i.e., the assignment and scheduling of tasks to workers, which may require team formation; and profiling, i.e., the continuous estimation of workers' skills, preferences, and other latent attributes from unstructured data. We cast these problems in a formal mathematical framework that links scheduling decisions to latent feature estimation, and we introduce StaffPro, an LLM agent that addresses staffing and profiling jointly. Differently from existing staffing solutions, StaffPro allows expressing optimization objectives using natural language, accepts textual task descriptions and provides high flexibility. StaffPro interacts directly with humans by establishing a continuous human-agent feedback loop, ensuring natural and intuitive use. By analyzing human feedback, our agent continuously estimates the latent features of workers, realizing life-long worker profiling and ensuring optimal staffing performance over time. A consulting firm simulation example demonstrates that StaffPro successfully estimates workers' attributes and generates high quality schedules. With its innovative design, StaffPro offers a robust, interpretable, and human-centric solution for automated personnel management.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21636v1",
    "published_date": "2025-07-29 09:48:54 UTC",
    "updated_date": "2025-07-29 09:48:54 UTC"
  },
  {
    "arxiv_id": "2507.21631v1",
    "title": "\"Teammates, Am I Clear?\": Analysing Legible Behaviours in Teams",
    "authors": [
      "Miguel Faria",
      "Francisco S. Melo",
      "Ana Paiva"
    ],
    "abstract": "In this paper we investigate the notion of legibility in sequential decision-making in the context of teams and teamwork. There have been works that extend the notion of legibility to sequential decision making, for deterministic and for stochastic scenarios. However, these works focus on one agent interacting with one human, foregoing the benefits of having legible decision making in teams of agents or in team configurations with humans. In this work we propose an extension of legible decision-making to multi-agent settings that improves the performance of agents working in collaboration. We showcase the performance of legible decision making in team scenarios using our proposed extension in multi-agent benchmark scenarios. We show that a team with a legible agent is able to outperform a team composed solely of agents with standard optimal behaviour.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21631v1",
    "published_date": "2025-07-29 09:40:18 UTC",
    "updated_date": "2025-07-29 09:40:18 UTC"
  },
  {
    "arxiv_id": "2507.22090v1",
    "title": "Hybrid activation functions for deep neural networks: S3 and S4 -- a novel approach to gradient flow optimization",
    "authors": [
      "Sergii Kavun"
    ],
    "abstract": "Activation functions are critical components in deep neural networks, directly influencing gradient flow, training stability, and model performance. Traditional functions like ReLU suffer from dead neuron problems, while sigmoid and tanh exhibit vanishing gradient issues. We introduce two novel hybrid activation functions: S3 (Sigmoid-Softsign) and its improved version S4 (smoothed S3). S3 combines sigmoid for negative inputs with softsign for positive inputs, while S4 employs a smooth transition mechanism controlled by a steepness parameter k. We conducted comprehensive experiments across binary classification, multi-class classification, and regression tasks using three different neural network architectures. S4 demonstrated superior performance compared to nine baseline activation functions, achieving 97.4% accuracy on MNIST, 96.0% on Iris classification, and 18.7 MSE on Boston Housing regression. The function exhibited faster convergence (-19 for ReLU) and maintained stable gradient flow across network depths. Comparative analysis revealed S4's gradient range of [0.24, 0.59] compared to ReLU's 18% dead neurons in deep networks. The S4 activation function addresses key limitations of existing functions through its hybrid design and smooth transition mechanism. The tunable parameter k allows adaptation to different tasks and network depths, making S4 a versatile choice for deep learning applications. These findings suggest that hybrid activation functions represent a promising direction for improving neural network training dynamics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 2 figures, 5 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.22090v1",
    "published_date": "2025-07-29 09:21:57 UTC",
    "updated_date": "2025-07-29 09:21:57 UTC"
  },
  {
    "arxiv_id": "2507.22089v1",
    "title": "Principled Curriculum Learning using Parameter Continuation Methods",
    "authors": [
      "Harsh Nilesh Pathak",
      "Randy Paffenroth"
    ],
    "abstract": "In this work, we propose a parameter continuation method for the optimization of neural networks. There is a close connection between parameter continuation, homotopies, and curriculum learning. The methods we propose here are theoretically justified and practically effective for several problems in deep neural networks. In particular, we demonstrate better generalization performance than state-of-the-art optimization techniques such as ADAM for supervised and unsupervised learning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22089v1",
    "published_date": "2025-07-29 08:49:22 UTC",
    "updated_date": "2025-07-29 08:49:22 UTC"
  },
  {
    "arxiv_id": "2507.21591v2",
    "title": "Hierarchical Graph Neural Network for Compressed Speech Steganalysis",
    "authors": [
      "Mustapha Hemis",
      "Hamza Kheddar",
      "Mohamed Chahine Ghanem",
      "Bachir Boudraa"
    ],
    "abstract": "Steganalysis methods based on deep learning (DL) often struggle with computational complexity and challenges in generalizing across different datasets. Incorporating a graph neural network (GNN) into steganalysis schemes enables the leveraging of relational data for improved detection accuracy and adaptability. This paper presents the first application of a Graph Neural Network (GNN), specifically the GraphSAGE architecture, for steganalysis of compressed voice over IP (VoIP) speech streams. The method involves straightforward graph construction from VoIP streams and employs GraphSAGE to capture hierarchical steganalysis information, including both fine grained details and high level patterns, thereby achieving high detection accuracy. Experimental results demonstrate that the developed approach performs well in uncovering quantization index modulation (QIM)-based steganographic patterns in VoIP signals. It achieves detection accuracy exceeding 98 percent even for short 0.5 second samples, and 95.17 percent accuracy under challenging conditions with low embedding rates, representing an improvement of 2.8 percent over the best performing state of the art methods. Furthermore, the model exhibits superior efficiency, with an average detection time as low as 0.016 seconds for 0.5-second samples an improvement of 0.003 seconds. This makes it efficient for online steganalysis tasks, providing a superior balance between detection accuracy and efficiency under the constraint of short samples with low embedding rates.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21591v2",
    "published_date": "2025-07-29 08:46:54 UTC",
    "updated_date": "2025-09-25 19:46:49 UTC"
  },
  {
    "arxiv_id": "2507.21589v1",
    "title": "Exploring the Link Between Bayesian Inference and Embodied Intelligence: Toward Open Physical-World Embodied AI Systems",
    "authors": [
      "Bin Liu"
    ],
    "abstract": "Embodied intelligence posits that cognitive capabilities fundamentally emerge from - and are shaped by - an agent's real-time sensorimotor interactions with its environment. Such adaptive behavior inherently requires continuous inference under uncertainty. Bayesian statistics offers a principled probabilistic framework to address this challenge by representing knowledge as probability distributions and updating beliefs in response to new evidence. The core computational processes underlying embodied intelligence - including perception, action selection, learning, and even higher-level cognition - can be effectively understood and modeled as forms of Bayesian inference. Despite the deep conceptual connection between Bayesian statistics and embodied intelligence, Bayesian principles have not been widely or explicitly applied in today's embodied intelligence systems. In this work, we examine both Bayesian and contemporary embodied intelligence approaches through two fundamental lenses: search and learning - the two central themes in modern AI, as highlighted in Rich Sutton's influential essay \"The Bitter Lesson\". This analysis sheds light on why Bayesian inference has not played a central role in the development of modern embodied intelligence. At the same time, it reveals that current embodied intelligence systems remain largely confined to closed-physical-world environments, and highlights the potential for Bayesian methods to play a key role in extending these systems toward truly open physical-world embodied intelligence.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.21589v1",
    "published_date": "2025-07-29 08:43:16 UTC",
    "updated_date": "2025-07-29 08:43:16 UTC"
  },
  {
    "arxiv_id": "2507.21588v1",
    "title": "Progressive Homeostatic and Plastic Prompt Tuning for Audio-Visual Multi-Task Incremental Learning",
    "authors": [
      "Jiong Yin",
      "Liang Li",
      "Jiehua Zhang",
      "Yuhan Gao",
      "Chenggang Yan",
      "Xichun Sheng"
    ],
    "abstract": "Audio-visual multi-task incremental learning aims to continuously learn from multiple audio-visual tasks without the need for joint training on all tasks. The challenge of the problem is how to preserve the old task knowledge while facilitating the learning of new task with previous experiences. To address these challenges, we introduce a three-stage Progressive Homeostatic and Plastic audio-visual prompt (PHP) method. In the shallow phase, we design the task-shared modality aggregating adapter to foster cross-task and cross-modal audio-visual representation learning to enhance shared understanding between tasks. In the middle phase, we propose the task-specific modality-shared dynamic generating adapter, which constructs prompts that are tailored to individual tasks while remaining general across modalities, which balances the models ability to retain knowledge against forgetting with its potential for versatile multi-task transferability. In the deep phase, we introduce the task-specific modality-independent prompts to further refine the understand ability by targeting individual information for each task and modality. By incorporating these three phases, PHP retains task-specific prompts while adapting shared parameters for new tasks to effectively balance knowledge sharing and specificity. Our method achieves SOTA performance in different orders of four tasks (AVE, AVVP, AVS and AVQA). Our code can be available at https://github.com/ENJOY-Yin-jiong/PHP.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by ICCV 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.21588v1",
    "published_date": "2025-07-29 08:42:36 UTC",
    "updated_date": "2025-07-29 08:42:36 UTC"
  },
  {
    "arxiv_id": "2507.21585v1",
    "title": "SafeDriveRAG: Towards Safe Autonomous Driving with Knowledge Graph-based Retrieval-Augmented Generation",
    "authors": [
      "Hao Ye",
      "Mengshi Qi",
      "Zhaohong Liu",
      "Liang Liu",
      "Huadong Ma"
    ],
    "abstract": "In this work, we study how vision-language models (VLMs) can be utilized to enhance the safety for the autonomous driving system, including perception, situational understanding, and path planning. However, existing research has largely overlooked the evaluation of these models in traffic safety-critical driving scenarios. To bridge this gap, we create the benchmark (SafeDrive228K) and propose a new baseline based on VLM with knowledge graph-based retrieval-augmented generation (SafeDriveRAG) for visual question answering (VQA). Specifically, we introduce SafeDrive228K, the first large-scale multimodal question-answering benchmark comprising 228K examples across 18 sub-tasks. This benchmark encompasses a diverse range of traffic safety queries, from traffic accidents and corner cases to common safety knowledge, enabling a thorough assessment of the comprehension and reasoning abilities of the models. Furthermore, we propose a plug-and-play multimodal knowledge graph-based retrieval-augmented generation approach that employs a novel multi-scale subgraph retrieval algorithm for efficient information retrieval. By incorporating traffic safety guidelines collected from the Internet, this framework further enhances the model's capacity to handle safety-critical situations. Finally, we conduct comprehensive evaluations on five mainstream VLMs to assess their reliability in safety-sensitive driving tasks. Experimental results demonstrate that integrating RAG significantly improves performance, achieving a +4.73% gain in Traffic Accidents tasks, +8.79% in Corner Cases tasks and +14.57% in Traffic Safety Commonsense across five mainstream VLMs, underscoring the potential of our proposed benchmark and methodology for advancing research in traffic safety. Our source code and data are available at https://github.com/Lumos0507/SafeDriveRAG.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21585v1",
    "published_date": "2025-07-29 08:40:17 UTC",
    "updated_date": "2025-07-29 08:40:17 UTC"
  },
  {
    "arxiv_id": "2507.21571v1",
    "title": "Finding Uncommon Ground: A Human-Centered Model for Extrospective Explanations",
    "authors": [
      "Laura Spillner",
      "Nima Zargham",
      "Mihai Pomarlan",
      "Robert Porzel",
      "Rainer Malaka"
    ],
    "abstract": "The need for explanations in AI has, by and large, been driven by the desire to increase the transparency of black-box machine learning models. However, such explanations, which focus on the internal mechanisms that lead to a specific output, are often unsuitable for non-experts. To facilitate a human-centered perspective on AI explanations, agents need to focus on individuals and their preferences as well as the context in which the explanations are given. This paper proposes a personalized approach to explanation, where the agent tailors the information provided to the user based on what is most likely pertinent to them. We propose a model of the agent's worldview that also serves as a personal and dynamic memory of its previous interactions with the same user, based on which the artificial agent can estimate what part of its knowledge is most likely new information to the user.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Presented at the IJCAI 2023 Workshop on Explainable Artificial Intelligence (XAI)",
    "pdf_url": "https://arxiv.org/pdf/2507.21571v1",
    "published_date": "2025-07-29 07:59:54 UTC",
    "updated_date": "2025-07-29 07:59:54 UTC"
  },
  {
    "arxiv_id": "2507.21533v1",
    "title": "Model Predictive Adversarial Imitation Learning for Planning from Observation",
    "authors": [
      "Tyler Han",
      "Yanda Bao",
      "Bhaumik Mehta",
      "Gabriel Guo",
      "Anubhav Vishwakarma",
      "Emily Kang",
      "Sanghun Jung",
      "Rosario Scalise",
      "Jason Zhou",
      "Bryan Xu",
      "Byron Boots"
    ],
    "abstract": "Human demonstration data is often ambiguous and incomplete, motivating imitation learning approaches that also exhibit reliable planning behavior. A common paradigm to perform planning-from-demonstration involves learning a reward function via Inverse Reinforcement Learning (IRL) then deploying this reward via Model Predictive Control (MPC). Towards unifying these methods, we derive a replacement of the policy in IRL with a planning-based agent. With connections to Adversarial Imitation Learning, this formulation enables end-to-end interactive learning of planners from observation-only demonstrations. In addition to benefits in interpretability, complexity, and safety, we study and observe significant improvements on sample efficiency, out-of-distribution generalization, and robustness. The study includes evaluations in both simulated control benchmarks and real-world navigation experiments using few-to-single observation-only demonstrations.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Open-source code in process of being cleaned and documented for release. Please contact directly in the meantime for code. Under Review",
    "pdf_url": "https://arxiv.org/pdf/2507.21533v1",
    "published_date": "2025-07-29 06:52:52 UTC",
    "updated_date": "2025-07-29 06:52:52 UTC"
  },
  {
    "arxiv_id": "2507.21532v1",
    "title": "Automatic Classification of User Requirements from Online Feedback -- A Replication Study",
    "authors": [
      "Meet Bhatt",
      "Nic Boilard",
      "Muhammad Rehan Chaudhary",
      "Cole Thompson",
      "Jacob Idoko",
      "Aakash Sorathiya",
      "Gouri Ginde"
    ],
    "abstract": "Natural language processing (NLP) techniques have been widely applied in the requirements engineering (RE) field to support tasks such as classification and ambiguity detection. Although RE research is rooted in empirical investigation, it has paid limited attention to replicating NLP for RE (NLP4RE) studies. The rapidly advancing realm of NLP is creating new opportunities for efficient, machine-assisted workflows, which can bring new perspectives and results to the forefront. Thus, we replicate and extend a previous NLP4RE study (baseline), \"Classifying User Requirements from Online Feedback in Small Dataset Environments using Deep Learning\", which evaluated different deep learning models for requirement classification from user reviews. We reproduced the original results using publicly released source code, thereby helping to strengthen the external validity of the baseline study. We then extended the setup by evaluating model performance on an external dataset and comparing results to a GPT-4o zero-shot classifier. Furthermore, we prepared the replication study ID-card for the baseline study, important for evaluating replication readiness. Results showed diverse reproducibility levels across different models, with Naive Bayes demonstrating perfect reproducibility. In contrast, BERT and other models showed mixed results. Our findings revealed that baseline deep learning models, BERT and ELMo, exhibited good generalization capabilities on an external dataset, and GPT-4o showed performance comparable to traditional baseline machine learning models. Additionally, our assessment confirmed the baseline study's replication readiness; however missing environment setup files would have further enhanced readiness. We include this missing information in our replication package and provide the replication study ID-card for our study to further encourage and support the replication of our study.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 3 figures, Replication package available at https://zenodo.org/records/15626782, Accepted at AIRE 2025 (12th International Workshop on Artificial Intelligence and Requirements Engineering)",
    "pdf_url": "https://arxiv.org/pdf/2507.21532v1",
    "published_date": "2025-07-29 06:52:27 UTC",
    "updated_date": "2025-07-29 06:52:27 UTC"
  },
  {
    "arxiv_id": "2507.21524v1",
    "title": "Large Language Models for Wireless Communications: From Adaptation to Autonomy",
    "authors": [
      "Le Liang",
      "Hao Ye",
      "Yucheng Sheng",
      "Ouya Wang",
      "Jiacheng Wang",
      "Shi Jin",
      "Geoffrey Ye Li"
    ],
    "abstract": "The emergence of large language models (LLMs) has revolutionized artificial intelligence, offering unprecedented capabilities in reasoning, generalization, and zero-shot learning. These strengths open new frontiers in wireless communications, where increasing complexity and dynamics demand intelligent and adaptive solutions. This article explores the role of LLMs in transforming wireless systems across three key directions: adapting pretrained LLMs for core communication tasks, developing wireless-specific foundation models to balance versatility and efficiency, and enabling agentic LLMs with autonomous reasoning and coordination capabilities. We highlight recent advances, practical case studies, and the unique benefits of LLM-based approaches over traditional methods. Finally, we outline open challenges and research opportunities, including multimodal fusion, collaboration with lightweight models, and self-improving capabilities, charting a path toward intelligent, adaptive, and autonomous wireless networks of the future.",
    "categories": [
      "cs.AI",
      "cs.IT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21524v1",
    "published_date": "2025-07-29 06:21:10 UTC",
    "updated_date": "2025-07-29 06:21:10 UTC"
  },
  {
    "arxiv_id": "2507.21518v2",
    "title": "ST-GDance: Long-Term and Collision-Free Group Choreography from Music",
    "authors": [
      "Jing Xu",
      "Weiqiang Wang",
      "Cunjian Chen",
      "Jun Liu",
      "Qiuhong Ke"
    ],
    "abstract": "Group dance generation from music has broad applications in film, gaming, and animation production. However, it requires synchronizing multiple dancers while maintaining spatial coordination. As the number of dancers and sequence length increase, this task faces higher computational complexity and a greater risk of motion collisions. Existing methods often struggle to model dense spatial-temporal interactions, leading to scalability issues and multi-dancer collisions. To address these challenges, we propose ST-GDance, a novel framework that decouples spatial and temporal dependencies to optimize long-term and collision-free group choreography. We employ lightweight graph convolutions for distance-aware spatial modeling and accelerated sparse attention for efficient temporal modeling. This design significantly reduces computational costs while ensuring smooth and collision-free interactions. Experiments on the AIOZ-GDance dataset demonstrate that ST-GDance outperforms state-of-the-art baselines, particularly in generating long and coherent group dance sequences. Project page: https://yilliajing.github.io/ST-GDance-Website/.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 3 figures. Accepted at BMVC 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.21518v2",
    "published_date": "2025-07-29 05:54:48 UTC",
    "updated_date": "2025-07-30 03:57:47 UTC"
  },
  {
    "arxiv_id": "2507.21513v1",
    "title": "What Does it Mean for a Neural Network to Learn a \"World Model\"?",
    "authors": [
      "Kenneth Li",
      "Fernanda Vigas",
      "Martin Wattenberg"
    ],
    "abstract": "We propose a set of precise criteria for saying a neural net learns and uses a \"world model.\" The goal is to give an operational meaning to terms that are often used informally, in order to provide a common language for experimental investigation. We focus specifically on the idea of representing a latent \"state space\" of the world, leaving modeling the effect of actions to future work. Our definition is based on ideas from the linear probing literature, and formalizes the notion of a computation that factors through a representation of the data generation process. An essential addition to the definition is a set of conditions to check that such a \"world model\" is not a trivial consequence of the neural net's data or task.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21513v1",
    "published_date": "2025-07-29 05:30:57 UTC",
    "updated_date": "2025-07-29 05:30:57 UTC"
  },
  {
    "arxiv_id": "2507.21506v2",
    "title": "Decision Transformer-Based Drone Trajectory Planning with Dynamic Safety-Efficiency Trade-Offs",
    "authors": [
      "Chang-Hun Ji",
      "SiWoon Song",
      "Youn-Hee Han",
      "SungTae Moon"
    ],
    "abstract": "A drone trajectory planner should be able to dynamically adjust the safety-efficiency trade-off according to varying mission requirements in unknown environments. Although traditional polynomial-based planners offer computational efficiency and smooth trajectory generation, they require expert knowledge to tune multiple parameters to adjust this trade-off. Moreover, even with careful tuning, the resulting adjustment may fail to achieve the desired trade-off. Similarly, although reinforcement learning-based planners are adaptable in unknown environments, they do not explicitly address the safety-efficiency trade-off. To overcome this limitation, we introduce a Decision Transformer-based trajectory planner that leverages a single parameter, Return-to-Go (RTG), as a \\emph{temperature parameter} to dynamically adjust the safety-efficiency trade-off. In our framework, since RTG intuitively measures the safety and efficiency of a trajectory, RTG tuning does not require expert knowledge. We validate our approach using Gazebo simulations in both structured grid and unstructured random environments. The experimental results demonstrate that our planner can dynamically adjust the safety-efficiency trade-off by simply tuning the RTG parameter. Furthermore, our planner outperforms existing baseline methods across various RTG settings, generating safer trajectories when tuned for safety and more efficient trajectories when tuned for efficiency. Real-world experiments further confirm the reliability and practicality of our proposed planner.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2025. Copyright 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses",
    "pdf_url": "https://arxiv.org/pdf/2507.21506v2",
    "published_date": "2025-07-29 05:03:57 UTC",
    "updated_date": "2025-07-30 06:25:45 UTC"
  },
  {
    "arxiv_id": "2507.21504v1",
    "title": "Evaluation and Benchmarking of LLM Agents: A Survey",
    "authors": [
      "Mahmoud Mohammadi",
      "Yipeng Li",
      "Jane Lo",
      "Wendy Yip"
    ],
    "abstract": "The rise of LLM-based agents has opened new frontiers in AI applications, yet evaluating these agents remains a complex and underdeveloped area. This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and (2) evaluation process -- how to evaluate, including interaction modes, datasets and benchmarks, metric computation methods, and tooling. In addition to taxonomy, we highlight enterprise-specific challenges, such as role-based access to data, the need for reliability guarantees, dynamic and long-horizon interactions, and compliance, which are often overlooked in current research. We also identify future research directions, including holistic, more realistic, and scalable evaluation. This work aims to bring clarity to the fragmented landscape of agent evaluation and provide a framework for systematic assessment, enabling researchers and practitioners to evaluate LLM agents for real-world deployment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21504v1",
    "published_date": "2025-07-29 04:57:02 UTC",
    "updated_date": "2025-07-29 04:57:02 UTC"
  },
  {
    "arxiv_id": "2507.21503v4",
    "title": "MoHoBench: Assessing Honesty of Multimodal Large Language Models via Unanswerable Visual Questions",
    "authors": [
      "Yanxu Zhu",
      "Shitong Duan",
      "Xiangxu Zhang",
      "Jitao Sang",
      "Peng Zhang",
      "Tun Lu",
      "Xiao Zhou",
      "Jing Yao",
      "Xiaoyuan Yi",
      "Xing Xie"
    ],
    "abstract": "Recently Multimodal Large Language Models (MLLMs) have achieved considerable advancements in vision-language tasks, yet produce potentially harmful or untrustworthy content. Despite substantial work investigating the trustworthiness of language models, MMLMs' capability to act honestly, especially when faced with visually unanswerable questions, remains largely underexplored. This work presents the first systematic assessment of honesty behaviors across various MLLMs. We ground honesty in models' response behaviors to unanswerable visual questions, define four representative types of such questions, and construct MoHoBench, a large-scale MMLM honest benchmark, consisting of 12k+ visual question samples, whose quality is guaranteed by multi-stage filtering and human verification. Using MoHoBench, we benchmarked the honesty of 28 popular MMLMs and conducted a comprehensive analysis. Our findings show that: (1) most models fail to appropriately refuse to answer when necessary, and (2) MMLMs' honesty is not solely a language modeling issue, but is deeply influenced by visual information, necessitating the development of dedicated methods for multimodal honesty alignment. Therefore, we implemented initial alignment methods using supervised and preference learning to improve honesty behavior, providing a foundation for future work on trustworthy MLLMs. Our data and code can be found at https://github.com/yanxuzhu/MoHoBench.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "AAAI2026 Oral",
    "pdf_url": "https://arxiv.org/pdf/2507.21503v4",
    "published_date": "2025-07-29 04:55:49 UTC",
    "updated_date": "2026-01-13 13:07:18 UTC"
  },
  {
    "arxiv_id": "2507.21502v1",
    "title": "Large Language Models for Supply Chain Decisions",
    "authors": [
      "David Simchi-Levi",
      "Konstantina Mellou",
      "Ishai Menache",
      "Jeevan Pathuri"
    ],
    "abstract": "Supply Chain Management requires addressing a variety of complex decision-making challenges, from sourcing strategies to planning and execution. Over the last few decades, advances in computation and information technologies have enabled the transition from manual, intuition and experience-based decision-making, into more automated and data-driven decisions using a variety of tools that apply optimization techniques. These techniques use mathematical methods to improve decision-making.\n  Unfortunately, business planners and executives still need to spend considerable time and effort to (i) understand and explain the recommendations coming out of these technologies; (ii) analyze various scenarios and answer what-if questions; and (iii) update the mathematical models used in these tools to reflect current business environments. Addressing these challenges requires involving data science teams and/or the technology providers to explain results or make the necessary changes in the technology and hence significantly slows down decision making.\n  Motivated by the recent advances in Large Language Models (LLMs), we report how this disruptive technology can democratize supply chain technology - namely, facilitate the understanding of tools' outcomes, as well as the interaction with supply chain tools without human-in-the-loop. Specifically, we report how we apply LLMs to address the three challenges described above, thus substantially reducing the time to decision from days and weeks to minutes and hours as well as dramatically increasing planners' and executives' productivity and impact.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Forthcoming chapter in AI in Supply Chains: Perspectives from Global Thought Leaders, edited by Maxime C. Cohen and Tinglong Dai, and part of the Springer Series in Supply Chain Management (edited by Prof. Chris Tang)",
    "pdf_url": "https://arxiv.org/pdf/2507.21502v1",
    "published_date": "2025-07-29 04:50:27 UTC",
    "updated_date": "2025-07-29 04:50:27 UTC"
  },
  {
    "arxiv_id": "2507.21500v1",
    "title": "VN-MTEB: Vietnamese Massive Text Embedding Benchmark",
    "authors": [
      "Loc Pham",
      "Tung Luu",
      "Thu Vo",
      "Minh Nguyen",
      "Viet Hoang"
    ],
    "abstract": "Vietnam ranks among the top countries in terms of both internet traffic and online toxicity. As a result, implementing embedding models for recommendation and content control duties in applications is crucial. However, a lack of large-scale test datasets, both in volume and task diversity, makes it tricky for scientists to effectively evaluate AI models before deploying them in real-world, large-scale projects. To solve this important problem, we introduce a Vietnamese benchmark, VN-MTEB for embedding models, which we created by translating a large number of English samples from the Massive Text Embedding Benchmark using our new automated framework. We leverage the strengths of large language models (LLMs) and cutting-edge embedding models to conduct translation and filtering processes to retain high-quality samples, guaranteeing a natural flow of language and semantic fidelity while preserving named entity recognition (NER) and code snippets. Our comprehensive benchmark consists of 41 datasets from six tasks specifically designed for Vietnamese text embeddings. In our analysis, we find that bigger and more complex models using Rotary Positional Embedding outperform those using Absolute Positional Embedding in embedding tasks. Datasets are available at HuggingFace: https://huggingface.co/collections/GreenNode/vn-mteb-68871433f0f7573b8e1a6686",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages (including reference, appendix) 41 datasets from 6 tasks (retrieval, classification, pair-classification, clustering, rerank, sts) 7 figures, 16 tables, benchmark 18 text embedding models",
    "pdf_url": "https://arxiv.org/pdf/2507.21500v1",
    "published_date": "2025-07-29 04:48:55 UTC",
    "updated_date": "2025-07-29 04:48:55 UTC"
  },
  {
    "arxiv_id": "2507.21488v1",
    "title": "Learning to Imitate with Less: Efficient Individual Behavior Modeling in Chess",
    "authors": [
      "Zhenwei Tang",
      "Difan Jiao",
      "Eric Xue",
      "Reid McIlroy-Young",
      "Jon Kleinberg",
      "Siddhartha Sen",
      "Ashton Anderson"
    ],
    "abstract": "As humans seek to collaborate with, learn from, and better understand artificial intelligence systems, developing AIs that can accurately emulate individual decision-making becomes increasingly important. Chess, a long-standing AI benchmark with precise skill measurement, offers an ideal testbed for human-AI alignment. However, existing approaches to modeling human behavior require prohibitively large amounts of data from each individual, making them impractical for new or sparsely represented users. In this work, we introduce Maia4All, a framework designed to learn and adapt to individual decision-making styles efficiently, even with limited data. Maia4All achieves this through a two-stage optimization process: (1) an enrichment step, which bridges population and individual-level human behavior modeling with a prototype-enriched model, and (2) a democratization step, which leverages ability levels or user prototypes to initialize and refine individual embeddings with minimal data. Our experimental results show that Maia4All can accurately predict individual moves and profile behavioral patterns with high fidelity, establishing a new standard for personalized human-like AI behavior modeling in chess. Maia4All achieves individual human behavior modeling in chess with only 20 games, compared to the 5,000 games required previously, representing a significant improvement in data efficiency. Our work provides an example of how population AI systems can flexibly adapt to individual users using a prototype-enriched model as a bridge. This approach extends beyond chess, as shown in our case study on idiosyncratic LLMs, highlighting its potential for broader applications in personalized AI adaptation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21488v1",
    "published_date": "2025-07-29 04:09:31 UTC",
    "updated_date": "2025-07-29 04:09:31 UTC"
  },
  {
    "arxiv_id": "2507.21485v1",
    "title": "HLSDebugger: Identification and Correction of Logic Bugs in HLS Code with LLM Solutions",
    "authors": [
      "Jing Wang",
      "Shang Liu",
      "Yao Lu",
      "Zhiyao Xie"
    ],
    "abstract": "High-level synthesis (HLS) accelerates hardware design by enabling the automatic translation of high-level descriptions into efficient hardware implementations. However, debugging HLS code is a challenging and labor-intensive task, especially for novice circuit designers or software engineers without sufficient hardware domain knowledge. The recent emergence of Large Language Models (LLMs) is promising in automating the HLS debugging process. Despite the great potential, three key challenges persist when applying LLMs to HLS logic debugging: 1) High-quality circuit data for training LLMs is scarce, posing a significant challenge. 2) Debugging logic bugs in hardware is inherently more complex than identifying software bugs with existing golden test cases. 3) The absence of reliable test cases requires multi-tasking solutions, performing both bug identification and correction. complicates the multi-tasking required for effective HLS debugging. In this work, we propose a customized solution named HLSDebugger to address the challenges. HLSDebugger first generates and releases a large labeled dataset with 300K data samples, targeting HLS logic bugs. The HLSDebugger model adopts an encoder-decoder structure, performing bug location identification, bug type prediction, and bug correction with the same model. HLSDebugger significantly outperforms advanced LLMs like GPT-4 in bug identification and by more than 3x in bug correction. It makes a substantial advancement in the exploration of automated debugging of HLS code.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "This work has been accepted at ICCAD 2025 (International Conference on Computer-Aided Design)",
    "pdf_url": "https://arxiv.org/pdf/2507.21485v1",
    "published_date": "2025-07-29 03:59:19 UTC",
    "updated_date": "2025-07-29 03:59:19 UTC"
  },
  {
    "arxiv_id": "2507.21483v2",
    "title": "NCCR: to Evaluate the Robustness of Neural Networks and Adversarial Examples",
    "authors": [
      "Shi Pu",
      "Fu Song",
      "Wenjie Wang"
    ],
    "abstract": "Neural networks have received a lot of attention recently, and related security issues have come with it. Many studies have shown that neural networks are vulnerable to adversarial examples that have been artificially perturbed with modification, which is too small to be distinguishable by human perception. Different attacks and defenses have been proposed to solve these problems, but there is little research on evaluating the robustness of neural networks and their inputs. In this work, we propose a metric called the neuron cover change rate (NCCR) to measure the ability of deep learning models to resist attacks and the stability of adversarial examples. NCCR monitors alterations in the output of specifically chosen neurons when the input is perturbed, and networks with a smaller degree of variation are considered to be more robust. The results of the experiment on image recognition and the speaker recognition model show that our metrics can provide a good assessment of the robustness of neural networks or their inputs. It can also be used to detect whether an input is adversarial or not, as adversarial examples are always less robust.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21483v2",
    "published_date": "2025-07-29 03:58:20 UTC",
    "updated_date": "2025-08-06 14:54:25 UTC"
  },
  {
    "arxiv_id": "2507.21482v1",
    "title": "Improving Task Diversity in Label Efficient Supervised Finetuning of LLMs",
    "authors": [
      "Abhinav Arabelly",
      "Jagrut Nemade",
      "Robert D Nowak",
      "Jifan Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse domains, but developing high-performing models for specialized applications often requires substantial human annotation -- a process that is time-consuming, labor-intensive, and expensive. In this paper, we address the label-efficient learning problem for supervised finetuning (SFT) by leveraging task-diversity as a fundamental principle for effective data selection. This is markedly different from existing methods based on the prompt-diversity. Our approach is based on two key observations: 1) task labels for different prompts are often readily available; 2) pre-trained models have significantly varying levels of confidence across tasks. We combine these facts to devise a simple yet effective sampling strategy: we select examples across tasks using an inverse confidence weighting strategy. This produces models comparable to or better than those trained with more complex sampling procedures, while being significantly easier to implement and less computationally intensive. Notably, our experimental results demonstrate that this method can achieve better accuracy than training on the complete dataset (a 4\\% increase in MMLU score). Across various annotation budgets and two instruction finetuning datasets, our algorithm consistently performs at or above the level of the best existing methods, while reducing annotation costs by up to 80\\%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21482v1",
    "published_date": "2025-07-29 03:51:00 UTC",
    "updated_date": "2025-07-29 03:51:00 UTC"
  },
  {
    "arxiv_id": "2507.21479v1",
    "title": "Capacity-Constrained Continual Learning",
    "authors": [
      "Zheng Wen",
      "Doina Precup",
      "Benjamin Van Roy",
      "Satinder Singh"
    ],
    "abstract": "Any agents we can possibly build are subject to capacity constraints, as memory and compute resources are inherently finite. However, comparatively little attention has been dedicated to understanding how agents with limited capacity should allocate their resources for optimal performance. The goal of this paper is to shed some light on this question by studying a simple yet relevant continual learning problem: the capacity-constrained linear-quadratic-Gaussian (LQG) sequential prediction problem. We derive a solution to this problem under appropriate technical conditions. Moreover, for problems that can be decomposed into a set of sub-problems, we also demonstrate how to optimally allocate capacity across these sub-problems in the steady state. We view the results of this paper as a first step in the systematic theoretical study of learning under capacity constraints.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "eess.SY",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21479v1",
    "published_date": "2025-07-29 03:47:22 UTC",
    "updated_date": "2025-07-29 03:47:22 UTC"
  },
  {
    "arxiv_id": "2507.21476v1",
    "title": "Which LLMs Get the Joke? Probing Non-STEM Reasoning Abilities with HumorBench",
    "authors": [
      "Reuben Narad",
      "Siddharth Suresh",
      "Jiayi Chen",
      "Pine S. L. Dysart-Bricken",
      "Bob Mankoff",
      "Robert Nowak",
      "Jifan Zhang",
      "Lalit Jain"
    ],
    "abstract": "We present HumorBench, a benchmark designed to evaluate large language models' (LLMs) ability to reason about and explain sophisticated humor in cartoon captions. As reasoning models increasingly saturate existing benchmarks in mathematics and science, novel and challenging evaluations of model intelligence beyond STEM domains are essential. Reasoning is fundamentally involved in text-based humor comprehension, requiring the identification of connections between concepts in cartoons/captions and external cultural references, wordplays, and other mechanisms. HumorBench includes approximately 300 unique cartoon-caption pairs from the New Yorker Caption Contest and Cartoonstock.com, with expert-annotated evaluation rubrics identifying essential joke elements. LLMs are evaluated based on their explanations towards the humor and abilities in identifying the joke elements. To perform well on this task, models must form and test hypotheses about associations between concepts, potentially backtracking from initial interpretations to arrive at the most plausible explanation. Our extensive benchmarking of current SOTA models reveals three key insights: (1) LLM progress on STEM reasoning transfers effectively to humor comprehension; (2) models trained exclusively on STEM reasoning data still perform well on HumorBench, demonstrating strong transferability of reasoning abilities; and (3) test-time scaling by increasing thinking token budgets yields mixed results across different models in humor reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21476v1",
    "published_date": "2025-07-29 03:44:43 UTC",
    "updated_date": "2025-07-29 03:44:43 UTC"
  },
  {
    "arxiv_id": "2507.21474v1",
    "title": "Hebbian Memory-Augmented Recurrent Networks: Engram Neurons in Deep Learning",
    "authors": [
      "Daniel Szelogowski"
    ],
    "abstract": "Despite success across diverse tasks, current artificial recurrent network architectures rely primarily on implicit hidden-state memories, limiting their interpretability and ability to model long-range dependencies. In contrast, biological neural systems employ explicit, associative memory traces (i.e., engrams) strengthened through Hebbian synaptic plasticity and activated sparsely during recall. Motivated by these neurobiological insights, we introduce the Engram Neural Network (ENN), a novel recurrent architecture incorporating an explicit, differentiable memory matrix with Hebbian plasticity and sparse, attention-driven retrieval mechanisms. The ENN explicitly models memory formation and recall through dynamic Hebbian traces, improving transparency and interpretability compared to conventional RNN variants. We evaluate the ENN architecture on three canonical benchmarks: MNIST digit classification, CIFAR-10 image sequence modeling, and WikiText-103 language modeling. Our empirical results demonstrate that the ENN achieves accuracy and generalization performance broadly comparable to classical RNN, GRU, and LSTM architectures, with all models converging to similar accuracy and perplexity on the large-scale WikiText-103 task. At the same time, the ENN offers significant enhancements in interpretability through observable memory dynamics. Hebbian trace visualizations further reveal biologically plausible, structured memory formation processes, validating the potential of neuroscience-inspired mechanisms to inform the development of more interpretable and robust deep learning models.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.NE",
    "comment": "20 pages, 11 figures, 4 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.21474v1",
    "published_date": "2025-07-29 03:34:32 UTC",
    "updated_date": "2025-07-29 03:34:32 UTC"
  },
  {
    "arxiv_id": "2508.09142v2",
    "title": "Bayesian-Driven Graph Reasoning for Active Radio Map Construction",
    "authors": [
      "Wenlihan Lu",
      "Shijian Gao",
      "Miaowen Wen",
      "Yuxuan Liang",
      "Liuqing Yang",
      "Chan-Byoung Chae",
      "H. Vincent Poor"
    ],
    "abstract": "With the emergence of the low-altitude economy, radio maps have become essential for ensuring reliable wireless connectivity to aerial platforms. Autonomous aerial agents are commonly deployed for data collection using waypoint-based navigation; however, their limited battery capacity significantly constrains coverage and efficiency. To address this, we propose an uncertainty-aware radio map (URAM) reconstruction framework that explicitly leverages graph-based reasoning tailored for waypoint navigation. Our approach integrates two key deep learning components: (1) a Bayesian neural network that estimates spatial uncertainty in real time, and (2) an attention-based reinforcement learning policy that performs global reasoning over a probabilistic roadmap, using uncertainty estimates to plan informative and energy-efficient trajectories. This graph-based reasoning enables intelligent, non-myopic trajectory planning, guiding agents toward the most informative regions while satisfying safety constraints. Experimental results show that URAM improves reconstruction accuracy by up to 34% over existing baselines.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09142v2",
    "published_date": "2025-07-29 03:32:01 UTC",
    "updated_date": "2025-08-22 07:05:54 UTC"
  },
  {
    "arxiv_id": "2508.05654v1",
    "title": "Comparison of Information Retrieval Techniques Applied to IT Support Tickets",
    "authors": [
      "Leonardo Santiago Benitez Pereira",
      "Robinson Pizzio",
      "Samir Bonho"
    ],
    "abstract": "Institutions dependent on IT services and resources acknowledge the crucial significance of an IT help desk system, that act as a centralized hub connecting IT staff and users for service requests. Employing various Machine Learning models, these IT help desk systems allow access to corrective actions used in the past, but each model has different performance when applied to different datasets. This work compares eleven Information Retrieval techniques in a dataset of IT support tickets, with the goal of implementing a software that facilitates the work of Information Technology support analysts. The best results were obtained with the Sentence-BERT technique, in its multi-language variation distilluse-base-multilingual-cased-v1, where 78.7% of the recommendations made by the model were considered relevant. TF-IDF (69.0%), Word2vec (68.7%) and LDA (66.3%) techniques also had consistent results. Furthermore, the used datasets and essential parts of coding have been published and made open source. It also demonstrated the practicality of a support ticket recovery system by implementing a minimal viable prototype, and described in detail the implementation of the system. Finally, this work proposed a novel metric for comparing the techniques, whose aim is to closely reflect the perception of the IT analysts about the retrieval quality.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.05654v1",
    "published_date": "2025-07-29 03:25:41 UTC",
    "updated_date": "2025-07-29 03:25:41 UTC"
  },
  {
    "arxiv_id": "2507.21471v2",
    "title": "LUMIR: an LLM-Driven Unified Agent Framework for Multi-task Infrared Spectroscopy Reasoning",
    "authors": [
      "Zujie Xie",
      "Zixuan Chen",
      "Jiheng Liang",
      "Xiangyang Yu",
      "Ziru Yu"
    ],
    "abstract": "Infrared spectroscopy enables rapid, non destructive analysis of chemical and material properties, yet high dimensional signals and overlapping bands hinder conventional chemometric methods. Large language models (LLMs), with strong generalization and reasoning capabilities, offer new opportunities for automated spectral interpretation, but their potential in this domain remains largely untapped. This study introduces LUMIR (LLM-driven Unified agent framework for Multi-task Infrared spectroscopy Reasoning), an agent based framework designed to achieve accurate infrared spectral analysis under low data conditions. LUMIR integrates a structured literature knowledge base, automated preprocessing, feature extraction, and predictive modeling into a unified pipeline. By mining peer reviewed spectroscopy studies, it identifies validated preprocessing and feature derivation strategies, transforms spectra into low dimensional representations, and applies few-shot prompts for classification, regression, and anomaly detection. The framework was validated on diverse datasets, including the publicly available Milk near-infrared dataset, Chinese medicinal herbs, Citri Reticulatae Pericarpium(CRP) with different storage durations, an industrial wastewater COD dataset, and two additional public benchmarks, Tecator and Corn. Across these tasks, LUMIR achieved performance comparable to or surpassing established machine learning and deep learning models, particularly in resource limited settings. This work demonstrates that combining structured literature guidance with few-shot learning enables robust, scalable, and automated spectral interpretation. LUMIR establishes a new paradigm for applying LLMs to infrared spectroscopy, offering high accuracy with minimal labeled data and broad applicability across scientific and industrial domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.21471v2",
    "published_date": "2025-07-29 03:20:51 UTC",
    "updated_date": "2025-08-31 04:55:01 UTC"
  },
  {
    "arxiv_id": "2508.00904v1",
    "title": "Forecasting LLM Inference Performance via Hardware-Agnostic Analytical Modeling",
    "authors": [
      "Rajeev Patwari",
      "Ashish Sirasao",
      "Devleena Das"
    ],
    "abstract": "Large language models (LLMs) have been increasingly deployed as local agents on personal devices with CPUs, NPUs and integrated GPUs. However, forecasting inference performance on devices with such heterogeneity remains challenging due to the dynamic compute and memory demands. Existing approaches rely on GPU benchmarking or machine learning-based latency predictors, which are often hardware-specific and lack generalizability. To this end, we introduce LIFE, a lightweight and modular analytical framework that is comprised of modular analytical model of operators, configurable to characterize LLM inference workloads in a hardware and dataset-agnostic manner. LIFE characterizes the influence of software and model optimizations, such as quantization, KV cache compression, LoRA adapters, chunked prefill, different attentions, and operator fusion, on performance metrics such as time-to-first-token (TTFT), time-per-output-token (TPOT) and tokens-per-second (TPS). LIFE enables performance forecasting using only hardware specifications, such as TOPS and memory bandwidth, without requiring extensive dataset benchmarking. We validate LIFE's forecasting with inference on AMD Ryzen CPUs, NPUs, iGPUs and NVIDIA V100 GPUs, with Llama2-7B variants, demonstrating the utility of LIFE in forecasting LLM performance through lens of system efficiency to enable efficient LLM deployment across different hardware platforms.",
    "categories": [
      "cs.PF",
      "cs.AI",
      "cs.AR",
      "cs.LG"
    ],
    "primary_category": "cs.PF",
    "comment": "10 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.00904v1",
    "published_date": "2025-07-29 03:08:31 UTC",
    "updated_date": "2025-07-29 03:08:31 UTC"
  },
  {
    "arxiv_id": "2507.21455v2",
    "title": "Boost Self-Supervised Dataset Distillation via Parameterization, Predefined Augmentation, and Approximation",
    "authors": [
      "Sheng-Feng Yu",
      "Jia-Jiun Yao",
      "Wei-Chen Chiu"
    ],
    "abstract": "Although larger datasets are crucial for training large deep models, the rapid growth of dataset size has brought a significant challenge in terms of considerable training costs, which even results in prohibitive computational expenses. Dataset Distillation becomes a popular technique recently to reduce the dataset size via learning a highly compact set of representative exemplars, where the model trained with these exemplars ideally should have comparable performance with respect to the one trained with the full dataset. While most of existing works upon dataset distillation focus on supervised datasets, we instead aim to distill images and their self-supervisedly trained representations into a distilled set. This procedure, named as Self-Supervised Dataset Distillation, effectively extracts rich information from real datasets, yielding the distilled sets with enhanced cross-architecture generalizability. Particularly, in order to preserve the key characteristics of original dataset more faithfully and compactly, several novel techniques are proposed: 1) we introduce an innovative parameterization upon images and representations via distinct low-dimensional bases, where the base selection for parameterization is experimentally shown to play a crucial role; 2) we tackle the instability induced by the randomness of data augmentation -- a key component in self-supervised learning but being underestimated in the prior work of self-supervised dataset distillation -- by utilizing predetermined augmentations; 3) we further leverage a lightweight network to model the connections among the representations of augmented views from the same image, leading to more compact pairs of distillation. Extensive experiments conducted on various datasets validate the superiority of our approach in terms of distillation efficiency, cross-architecture generalization, and transfer learning performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "To appear in the Proceedings of the International Conference on Learning Representations (ICLR 2025)",
    "pdf_url": "https://arxiv.org/pdf/2507.21455v2",
    "published_date": "2025-07-29 02:51:56 UTC",
    "updated_date": "2025-08-05 06:51:05 UTC"
  },
  {
    "arxiv_id": "2507.21453v2",
    "title": "Validating Pharmacogenomics Generative Artificial Intelligence Query Prompts Using Retrieval-Augmented Generation (RAG)",
    "authors": [
      "Ashley Rector",
      "Keaton Minor",
      "Kamden Minor",
      "Jeff McCormack",
      "Beth Breeden",
      "Ryan Nowers",
      "Jay Dorris"
    ],
    "abstract": "This study evaluated Sherpa Rx, an artificial intelligence tool leveraging large language models and retrieval-augmented generation (RAG) for pharmacogenomics, to validate its performance on key response metrics. Sherpa Rx integrated Clinical Pharmacogenetics Implementation Consortium (CPIC) guidelines with Pharmacogenomics Knowledgebase (PharmGKB) data to generate contextually relevant responses. A dataset (N=260 queries) spanning 26 CPIC guidelines was used to evaluate drug-gene interactions, dosing recommendations, and therapeutic implications. In Phase 1, only CPIC data was embedded. Phase 2 additionally incorporated PharmGKB content. Responses were scored on accuracy, relevance, clarity, completeness (5-point Likert scale), and recall. Wilcoxon signed-rank tests compared accuracy between Phase 1 and Phase 2, and between Phase 2 and ChatGPT-4omini. A 20-question quiz assessed the tool's real-world applicability against other models. In Phase 1 (N=260), Sherpa Rx demonstrated high performance of accuracy 4.9, relevance 5.0, clarity 5.0, completeness 4.8, and recall 0.99. The subset analysis (N=20) showed improvements in accuracy (4.6 vs. 4.4, Phase 2 vs. Phase 1 subset) and completeness (5.0 vs. 4.8). ChatGPT-4omini performed comparably in relevance (5.0) and clarity (4.9) but lagged in accuracy (3.9) and completeness (4.2). Differences in accuracy between Phase 1 and Phase 2 was not statistically significant. However, Phase 2 significantly outperformed ChatGPT-4omini. On the 20-question quiz, Sherpa Rx achieved 90% accuracy, outperforming other models. Integrating additional resources like CPIC and PharmGKB with RAG enhances AI accuracy and performance. This study highlights the transformative potential of generative AI like Sherpa Rx in pharmacogenomics, improving decision-making with accurate, personalized responses.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21453v2",
    "published_date": "2025-07-29 02:43:35 UTC",
    "updated_date": "2025-08-03 02:52:27 UTC"
  },
  {
    "arxiv_id": "2507.21438v1",
    "title": "Evo-DKD: Dual-Knowledge Decoding for Autonomous Ontology Evolution in Large Language Models",
    "authors": [
      "Vishal Raman",
      "Vijai Aravindh R"
    ],
    "abstract": "Ontologies and knowledge graphs require continuous evolution to remain comprehensive and accurate, but manual curation is labor intensive. Large Language Models (LLMs) possess vast unstructured knowledge but struggle with maintaining structured consistency. We propose Evo-DKD, a novel dual-decoder framework for autonomous ontology evolution that combines structured ontology traversal with unstructured text reasoning. Evo-DKD introduces two parallel decoding streams within an LLM: one decoder generates candidate ontology edits (e.g., new concepts or relations) while the other produces natural-language justifications. A dynamic attention-based gating mechanism coordinates the two streams, deciding at each step how to blend structured and unstructured knowledge. Due to GPU constraints, we simulate the dual-decoder behavior using prompt-based mode control to approximate coordinated decoding in a single-stream mode. The system operates in a closed reasoning loop: proposed ontology edits are validated (via consistency checks and cross-verification with the text explanations) and then injected into the knowledge base, which in turn informs subsequent reasoning. We demonstrate Evo-DKD's effectiveness on use cases including healthcare ontology refinement, semantic search improvement, and cultural heritage timeline modeling. Experiments show that Evo-DKD outperforms baselines using structured-only or unstructured-only decoding in both precision of ontology updates and downstream task performance. We present quantitative metrics and qualitative examples, confirming the contributions of the dual-decoder design and gating router. Evo-DKD offers a new paradigm for LLM-driven knowledge base maintenance, combining the strengths of symbolic and neural reasoning for sustainable ontology evolution.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.21438v1",
    "published_date": "2025-07-29 02:18:55 UTC",
    "updated_date": "2025-07-29 02:18:55 UTC"
  },
  {
    "arxiv_id": "2507.21433v2",
    "title": "MemShare: Memory Efficient Inference for Large Reasoning Models through KV Cache Reuse",
    "authors": [
      "Kaiwen Chen",
      "Xin Tan",
      "Minchen Yu",
      "Hong Xu"
    ],
    "abstract": "Large Reasoning Models (LRMs) have achieved significant advances in mathematical reasoning and formal logic tasks. However, their tendency to generate lengthy chain-of-thought sequences leads to substantial memory overhead during inference. We observe that LRMs frequently produce highly similar intermediate reasoning steps, which correspond to similar KV cache states across layers. Motivated by this observation, we propose MemShare, a novel KV cache management approach that effectively reduces memory overhead. MemShare employs a collaborative filtering algorithm to efficiently identify reusable KV cache blocks and enables zero copy cache reuse to significantly reduce memory overhead, improve throughput while maintaining accuracy. Experimental results demonstrate that MemShare delivers up to 84.79\\% improvement in throughput while maintaining better accuracy compared to existing KV cache management methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.21433v2",
    "published_date": "2025-07-29 02:05:51 UTC",
    "updated_date": "2025-07-31 07:53:53 UTC"
  },
  {
    "arxiv_id": "2507.21432v2",
    "title": "Towards Locally Deployable Fine-Tuned Causal Large Language Models for Mode Choice Behaviour",
    "authors": [
      "Tareq Alsaleh",
      "Bilal Farooq"
    ],
    "abstract": "This study investigates the adoption of open-access, locally deployable causal large language models (LLMs) for travel mode choice prediction and introduces LiTransMC, the first fine-tuned causal LLM developed for this task. We systematically benchmark eleven open-access LLMs (1-12B parameters) across three stated and revealed preference datasets, testing 396 configurations and generating over 79,000 mode choice decisions. Beyond predictive accuracy, we evaluate models generated reasoning using BERTopic for topic modelling and a novel Explanation Strength Index, providing the first structured analysis of how LLMs articulate decision factors in alignment with behavioural theory. LiTransMC, fine-tuned using parameter efficient and loss masking strategy, achieved a weighted F1 score of 0.6845 and a Jensen-Shannon Divergence of 0.000245, surpassing both untuned local models and larger proprietary systems, including GPT-4o with advanced persona inference and embedding-based loading, while also outperforming classical mode choice methods such as discrete choice models and machine learning classifiers for the same dataset. This dual improvement, i.e., high instant-level accuracy and near-perfect distributional calibration, demonstrates the feasibility of creating specialist, locally deployable LLMs that integrate prediction and interpretability. Through combining structured behavioural prediction with natural language reasoning, this work unlocks the potential for conversational, multi-task transport models capable of supporting agent-based simulations, policy testing, and behavioural insight generation. These findings establish a pathway for transforming general purpose LLMs into specialized and explainable tools for transportation research and policy formulation, while maintaining privacy, reducing cost, and broadening access through local deployment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21432v2",
    "published_date": "2025-07-29 02:03:37 UTC",
    "updated_date": "2025-10-07 12:12:13 UTC"
  },
  {
    "arxiv_id": "2507.21423v1",
    "title": "MapDiffusion: Generative Diffusion for Vectorized Online HD Map Construction and Uncertainty Estimation in Autonomous Driving",
    "authors": [
      "Thomas Monninger",
      "Zihan Zhang",
      "Zhipeng Mo",
      "Md Zafar Anwar",
      "Steffen Staab",
      "Sihao Ding"
    ],
    "abstract": "Autonomous driving requires an understanding of the static environment from sensor data. Learned Bird's-Eye View (BEV) encoders are commonly used to fuse multiple inputs, and a vector decoder predicts a vectorized map representation from the latent BEV grid. However, traditional map construction models provide deterministic point estimates, failing to capture uncertainty and the inherent ambiguities of real-world environments, such as occlusions and missing lane markings. We propose MapDiffusion, a novel generative approach that leverages the diffusion paradigm to learn the full distribution of possible vectorized maps. Instead of predicting a single deterministic output from learned queries, MapDiffusion iteratively refines randomly initialized queries, conditioned on a BEV latent grid, to generate multiple plausible map samples. This allows aggregating samples to improve prediction accuracy and deriving uncertainty estimates that directly correlate with scene ambiguity. Extensive experiments on the nuScenes dataset demonstrate that MapDiffusion achieves state-of-the-art performance in online map construction, surpassing the baseline by 5% in single-sample performance. We further show that aggregating multiple samples consistently improves performance along the ROC curve, validating the benefit of distribution modeling. Additionally, our uncertainty estimates are significantly higher in occluded areas, reinforcing their value in identifying regions with ambiguous sensor input. By modeling the full map distribution, MapDiffusion enhances the robustness and reliability of online vectorized HD map construction, enabling uncertainty-aware decision-making for autonomous vehicles in complex environments.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025)",
    "pdf_url": "https://arxiv.org/pdf/2507.21423v1",
    "published_date": "2025-07-29 01:16:40 UTC",
    "updated_date": "2025-07-29 01:16:40 UTC"
  },
  {
    "arxiv_id": "2507.21419v1",
    "title": "GovRelBench:A Benchmark for Government Domain Relevance",
    "authors": [
      "Haiquan Wang",
      "Yi Chen",
      "Shang Zeng",
      "Yun Bian",
      "Zhe Cui"
    ],
    "abstract": "Current evaluations of LLMs in the government domain primarily focus on safety considerations in specific scenarios, while the assessment of the models' own core capabilities, particularly domain relevance, remains insufficient. To address this gap, we propose GovRelBench, a benchmark specifically designed for evaluating the core capabilities of LLMs in the government domain. GovRelBench consists of government domain prompts and a dedicated evaluation tool, GovRelBERT. During the training process of GovRelBERT, we introduce the SoftGovScore method: this method trains a model based on the ModernBERT architecture by converting hard labels to soft scores, enabling it to accurately compute the text's government domain relevance score. This work aims to enhance the capability evaluation framework for large models in the government domain, providing an effective tool for relevant research and practice. Our code and dataset are available at https://github.com/pan-xi/GovRelBench.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21419v1",
    "published_date": "2025-07-29 01:03:00 UTC",
    "updated_date": "2025-07-29 01:03:00 UTC"
  },
  {
    "arxiv_id": "2507.21407v2",
    "title": "Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects",
    "authors": [
      "Yixin Liu",
      "Guibin Zhang",
      "Kun Wang",
      "Shiyuan Li",
      "Shirui Pan"
    ],
    "abstract": "Autonomous agents based on large language models (LLMs) have demonstrated impressive capabilities in a wide range of applications, including web navigation, software development, and embodied control. While most LLMs are limited in several key agentic procedures, such as reliable planning, long-term memory, tool management, and multi-agent coordination, graphs can serve as a powerful auxiliary structure to enhance structure, continuity, and coordination in complex agent workflows. Given the rapid growth and fragmentation of research on Graph-augmented LLM Agents (GLA), this paper offers a timely and comprehensive overview of recent advances and also highlights key directions for future work. Specifically, we categorize existing GLA methods by their primary functions in LLM agent systems, including planning, memory, and tool usage, and then analyze how graphs and graph learning algorithms contribute to each. For multi-agent systems, we further discuss how GLA solutions facilitate the orchestration, efficiency optimization, and trustworthiness of MAS. Finally, we highlight key future directions to advance this field, from improving structural adaptability to enabling unified, scalable, and multimodal GLA systems. We hope this paper can serve as a roadmap for future research on GLA and foster a deeper understanding of the role of graphs in LLM agent systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.21407v2",
    "published_date": "2025-07-29 00:27:12 UTC",
    "updated_date": "2025-08-30 06:01:56 UTC"
  },
  {
    "arxiv_id": "2507.21406v1",
    "title": "Shapley Uncertainty in Natural Language Generation",
    "authors": [
      "Meilin Zhu",
      "Gaojie Jin",
      "Xiaowei Huang",
      "Lijun Zhang"
    ],
    "abstract": "In question-answering tasks, determining when to trust the outputs is crucial to the alignment of large language models (LLMs). Kuhn et al. (2023) introduces semantic entropy as a measure of uncertainty, by incorporating linguistic invariances from the same meaning. It primarily relies on setting threshold to measure the level of semantic equivalence relation. We propose a more nuanced framework that extends beyond such thresholding by developing a Shapley-based uncertainty metric that captures the continuous nature of semantic relationships. We establish three fundamental properties that characterize valid uncertainty metrics and prove that our Shapley uncertainty satisfies these criteria. Through extensive experiments, we demonstrate that our Shapley uncertainty more accurately predicts LLM performance in question-answering and other datasets, compared to similar baseline measures.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21406v1",
    "published_date": "2025-07-29 00:26:33 UTC",
    "updated_date": "2025-07-29 00:26:33 UTC"
  },
  {
    "arxiv_id": "2507.21395v1",
    "title": "Sync-TVA: A Graph-Attention Framework for Multimodal Emotion Recognition with Cross-Modal Fusion",
    "authors": [
      "Zeyu Deng",
      "Yanhui Lu",
      "Jiashu Liao",
      "Shuang Wu",
      "Chongfeng Wei"
    ],
    "abstract": "Multimodal emotion recognition (MER) is crucial for enabling emotionally intelligent systems that perceive and respond to human emotions. However, existing methods suffer from limited cross-modal interaction and imbalanced contributions across modalities. To address these issues, we propose Sync-TVA, an end-to-end graph-attention framework featuring modality-specific dynamic enhancement and structured cross-modal fusion. Our design incorporates a dynamic enhancement module for each modality and constructs heterogeneous cross-modal graphs to model semantic relations across text, audio, and visual features. A cross-attention fusion mechanism further aligns multimodal cues for robust emotion inference. Experiments on MELD and IEMOCAP demonstrate consistent improvements over state-of-the-art models in both accuracy and weighted F1 score, especially under class-imbalanced conditions.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21395v1",
    "published_date": "2025-07-29 00:03:28 UTC",
    "updated_date": "2025-07-29 00:03:28 UTC"
  }
]