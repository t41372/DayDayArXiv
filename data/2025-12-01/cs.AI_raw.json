[
  {
    "arxiv_id": "2512.20633v1",
    "title": "Enhancing Lung Cancer Treatment Outcome Prediction through Semantic Feature Engineering Using Large Language Models",
    "authors": [
      "MunHwan Lee",
      "Shaika Chowdhury",
      "Xiaodi Li",
      "Sivaraman Rajaganapathy",
      "Eric W Klee",
      "Ping Yang",
      "Terence Sio",
      "Liewei Wang",
      "James Cerhan",
      "Nansu NA Zong"
    ],
    "abstract": "Accurate prediction of treatment outcomes in lung cancer remains challenging due to the sparsity, heterogeneity, and contextual overload of real-world electronic health data. Traditional models often fail to capture semantic information across multimodal streams, while large-scale fine-tuning approaches are impractical in clinical workflows. We introduce a framework that uses Large Language Models (LLMs) as Goal-oriented Knowledge Curators (GKC) to convert laboratory, genomic, and medication data into high-fidelity, task-aligned features. Unlike generic embeddings, GKC produces representations tailored to the prediction objective and operates as an offline preprocessing step that integrates naturally into hospital informatics pipelines. Using a lung cancer cohort (N=184), we benchmarked GKC against expert-engineered features, direct text embeddings, and an end-to-end transformer. Our approach achieved a mean AUROC of 0.803 (95% CI: 0.799-0.807) and outperformed all baselines. An ablation study further confirmed the complementary value of combining all three modalities. These results show that the quality of semantic representation is a key determinant of predictive accuracy in sparse clinical data settings. By reframing LLMs as knowledge curation engines rather than black-box predictors, this work demonstrates a scalable, interpretable, and workflow-compatible pathway for advancing AI-driven decision support in oncology.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.20633v1",
    "published_date": "2025-12-01 23:56:45 UTC",
    "updated_date": "2025-12-01 23:56:45 UTC"
  },
  {
    "arxiv_id": "2512.02283v1",
    "title": "Model Recovery at the Edge under Resource Constraints for Physical AI",
    "authors": [
      "Bin Xu",
      "Ayan Banerjee",
      "Sandeep K. S. Gupta"
    ],
    "abstract": "Model Recovery (MR) enables safe, explainable decision making in mission-critical autonomous systems (MCAS) by learning governing dynamical equations, but its deployment on edge devices is hindered by the iterative nature of neural ordinary differential equations (NODEs), which are inefficient on FPGAs. Memory and energy consumption are the main concerns when applying MR on edge devices for real-time operation. We propose MERINDA, a novel FPGA-accelerated MR framework that replaces iterative solvers with a parallelizable neural architecture equivalent to NODEs. MERINDA achieves nearly 11x lower DRAM usage and 2.2x faster runtime compared to mobile GPUs. Experiments reveal an inverse relationship between memory and energy at fixed accuracy, highlighting MERINDA's suitability for resource-constrained, real-time MCAS.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published in ECAI 2025, Frontiers in Artificial Intelligence and Applications, volume 413, pages 3904-3911",
    "pdf_url": "https://arxiv.org/pdf/2512.02283v1",
    "published_date": "2025-12-01 23:54:23 UTC",
    "updated_date": "2025-12-01 23:54:23 UTC"
  },
  {
    "arxiv_id": "2512.02282v1",
    "title": "DialogGuard: Multi-Agent Psychosocial Safety Evaluation of Sensitive LLM Responses",
    "authors": [
      "Han Luo",
      "Guy Laban"
    ],
    "abstract": "Large language models (LLMs) now mediate many web-based mental-health, crisis, and other emotionally sensitive services, yet their psychosocial safety in these settings remains poorly understood and weakly evaluated. We present DialogGuard, a multi-agent framework for assessing psychosocial risks in LLM-generated responses along five high-severity dimensions: privacy violations, discriminatory behaviour, mental manipulation, psychological harm, and insulting behaviour. DialogGuard can be applied to diverse generative models through four LLM-as-a-judge pipelines, including single-agent scoring, dual-agent correction, multi-agent debate, and stochastic majority voting, grounded in a shared three-level rubric usable by both human annotators and LLM judges. Using PKU-SafeRLHF with human safety annotations, we show that multi-agent mechanisms detect psychosocial risks more accurately than non-LLM baselines and single-agent judging; dual-agent correction and majority voting provide the best trade-off between accuracy, alignment with human ratings, and robustness, while debate attains higher recall but over-flags borderline cases. We release Dialog-Guard as open-source software with a web interface that provides per-dimension risk scores and explainable natural-language rationales. A formative study with 12 practitioners illustrates how it supports prompt design, auditing, and supervision of web-facing applications for vulnerable users.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.02282v1",
    "published_date": "2025-12-01 23:53:45 UTC",
    "updated_date": "2025-12-01 23:53:45 UTC"
  },
  {
    "arxiv_id": "2512.02280v1",
    "title": "Bridging the Gap: Toward Cognitive Autonomy in Artificial Intelligence",
    "authors": [
      "Noorbakhsh Amiri Golilarz",
      "Sindhuja Penchala",
      "Shahram Rahimi"
    ],
    "abstract": "Artificial intelligence has advanced rapidly across perception, language, reasoning, and multimodal domains. Yet despite these achievements, modern AI systems remain fundamentally limited in their ability to self-monitor, self-correct, and regulate their behavior autonomously in dynamic contexts. This paper identifies and analyzes seven core deficiencies that constrain contemporary AI models: the absence of intrinsic self-monitoring, lack of meta-cognitive awareness, fixed and non-adaptive learning mechanisms, inability to restructure goals, lack of representational maintenance, insufficient embodied feedback, and the absence of intrinsic agency. Alongside identifying these limitations, we also outline a forward-looking perspective on how AI may evolve beyond them through architectures that mirror neurocognitive principles. We argue that these structural limitations prevent current architectures, including deep learning and transformer-based systems, from achieving robust generalization, lifelong adaptability, and real-world autonomy. Drawing on a comparative analysis of artificial systems and biological cognition [7], and integrating insights from AI research, cognitive science, and neuroscience, we outline how these capabilities are absent in current models and why scaling alone cannot resolve them. We conclude by advocating for a paradigmatic shift toward cognitively grounded AI (cognitive autonomy) capable of self-directed adaptation, dynamic representation management, and intentional, goal-oriented behavior, paired with reformative oversight mechanisms [8] that ensure autonomous systems remain interpretable, governable, and aligned with human values.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.02280v1",
    "published_date": "2025-12-01 23:51:08 UTC",
    "updated_date": "2025-12-01 23:51:08 UTC"
  },
  {
    "arxiv_id": "2512.02273v1",
    "title": "Progressive Image Restoration via Text-Conditioned Video Generation",
    "authors": [
      "Peng Kang",
      "Xijun Wang",
      "Yu Yuan"
    ],
    "abstract": "Recent text-to-video models have demonstrated strong temporal generation capabilities, yet their potential for image restoration remains underexplored. In this work, we repurpose CogVideo for progressive visual restoration tasks by fine-tuning it to generate restoration trajectories rather than natural video motion. Specifically, we construct synthetic datasets for super-resolution, deblurring, and low-light enhancement, where each sample depicts a gradual transition from degraded to clean frames. Two prompting strategies are compared: a uniform text prompt shared across all samples, and a scene-specific prompting scheme generated via LLaVA multi-modal LLM and refined with ChatGPT. Our fine-tuned model learns to associate temporal progression with restoration quality, producing sequences that improve perceptual metrics such as PSNR, SSIM, and LPIPS across frames. Extensive experiments show that CogVideo effectively restores spatial detail and illumination consistency while maintaining temporal coherence. Moreover, the model generalizes to real-world scenarios on the ReLoBlur dataset without additional training, demonstrating strong zero-shot robustness and interpretability through temporal restoration.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "First two authors contributed equally to this work. IEEE ICNC Accepted",
    "pdf_url": "https://arxiv.org/pdf/2512.02273v1",
    "published_date": "2025-12-01 23:37:51 UTC",
    "updated_date": "2025-12-01 23:37:51 UTC"
  },
  {
    "arxiv_id": "2512.02268v1",
    "title": "Spatiotemporal Pyramid Flow Matching for Climate Emulation",
    "authors": [
      "Jeremy Andrew Irvin",
      "Jiaqi Han",
      "Zikui Wang",
      "Abdulaziz Alharbi",
      "Yufei Zhao",
      "Nomin-Erdene Bayarsaikhan",
      "Daniele Visioni",
      "Andrew Y. Ng",
      "Duncan Watson-Parris"
    ],
    "abstract": "Generative models have the potential to transform the way we emulate Earth's changing climate. Previous generative approaches rely on weather-scale autoregression for climate emulation, but this is inherently slow for long climate horizons and has yet to demonstrate stable rollouts under nonstationary forcings. Here, we introduce Spatiotemporal Pyramid Flows (SPF), a new class of flow matching approaches that model data hierarchically across spatial and temporal scales. Inspired by cascaded video models, SPF partitions the generative trajectory into a spatiotemporal pyramid, progressively increasing spatial resolution to reduce computation and coupling each stage with an associated timescale to enable direct sampling at any temporal level in the pyramid. This design, together with conditioning each stage on prescribed physical forcings (e.g., greenhouse gases or aerosols), enables efficient, parallel climate emulation at multiple timescales. On ClimateBench, SPF outperforms strong flow matching baselines and pre-trained models at yearly and monthly timescales while offering fast sampling, especially at coarser temporal levels. To scale SPF, we curate ClimateSuite, the largest collection of Earth system simulations to date, comprising over 33,000 simulation-years across ten climate models and the first dataset to include simulations of climate interventions. We find that the scaled SPF model demonstrates good generalization to held-out scenarios across climate models. Together, SPF and ClimateSuite provide a foundation for accurate, efficient, probabilistic climate emulation across temporal scales and realistic future scenarios. Data and code is publicly available at https://github.com/stanfordmlgroup/spf .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.02268v1",
    "published_date": "2025-12-01 23:20:03 UTC",
    "updated_date": "2025-12-01 23:20:03 UTC"
  },
  {
    "arxiv_id": "2512.02261v1",
    "title": "TradeTrap: Are LLM-based Trading Agents Truly Reliable and Faithful?",
    "authors": [
      "Lewen Yan",
      "Jilin Mei",
      "Tianyi Zhou",
      "Lige Huang",
      "Jie Zhang",
      "Dongrui Liu",
      "Jing Shao"
    ],
    "abstract": "LLM-based trading agents are increasingly deployed in real-world financial markets to perform autonomous analysis and execution. However, their reliability and robustness under adversarial or faulty conditions remain largely unexamined, despite operating in high-risk, irreversible financial environments. We propose TradeTrap, a unified evaluation framework for systematically stress-testing both adaptive and procedural autonomous trading agents. TradeTrap targets four core components of autonomous trading agents: market intelligence, strategy formulation, portfolio and ledger handling, and trade execution, and evaluates their robustness under controlled system-level perturbations. All evaluations are conducted in a closed-loop historical backtesting setting on real US equity market data with identical initial conditions, enabling fair and reproducible comparisons across agents and attacks. Extensive experiments show that small perturbations at a single component can propagate through the agent decision loop and induce extreme concentration, runaway exposure, and large portfolio drawdowns across both agent types, demonstrating that current autonomous trading agents can be systematically misled at the system level. Our code is available at https://github.com/Yanlewen/TradeTrap.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.02261v1",
    "published_date": "2025-12-01 23:06:42 UTC",
    "updated_date": "2025-12-01 23:06:42 UTC"
  },
  {
    "arxiv_id": "2512.03103v1",
    "title": "Public Sentiment Analysis of Traffic Management Policies in Knoxville: A Social Media Driven Study",
    "authors": [
      "Shampa Saha",
      "Shovan Roy"
    ],
    "abstract": "This study presents a comprehensive analysis of public sentiment toward traffic management policies in Knoxville, Tennessee, utilizing social media data from Twitter and Reddit platforms. We collected and analyzed 7906 posts spanning January 2022 to December 2023, employing Valence Aware Dictionary and sEntiment Reasoner (VADER) for sentiment analysis and Latent Dirichlet Allocation (LDA) for topic modeling. Our findings reveal predominantly negative sentiment, with significant variations across platforms and topics. Twitter exhibited more negative sentiment compared to Reddit. Topic modeling identified six distinct themes, with construction-related topics showing the most negative sentiment while general traffic discussions were more positive. Spatiotemporal analysis revealed geographic and temporal patterns in sentiment expression. The research demonstrates social media's potential as a real-time public sentiment monitoring tool for transportation planning and policy evaluation.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.03103v1",
    "published_date": "2025-12-01 23:02:23 UTC",
    "updated_date": "2025-12-01 23:02:23 UTC"
  },
  {
    "arxiv_id": "2601.11541v1",
    "title": "A Comparative Study of Technical Writing Feedback Quality: Evaluating LLMs, SLMs, and Humans in Computer Science Topics",
    "authors": [
      "Suqing Liu",
      "Bogdan Simion",
      "Christopher Eaton",
      "Michael Liut"
    ],
    "abstract": "Feedback is a critical component of the learning process, particularly in computer science education. This study investigates the quality of feedback generated by Large Language Models (LLMs), Small Language Models (SLMs), compared with human feedback, in three computer science course with technical writing components: an introductory computer science course (CS2), a third-year advanced systems course (operating systems), and a third-year writing course (a topics course on artificial intelligence). Using a mixed-methods approach which integrates quantitative Likert-scale questions with qualitative commentary, we analyze the student perspective on feedback quality, evaluated based on multiple criteria, including readability, detail, specificity, actionability, helpfulness, and overall quality. The analysis reveals that in the larger upper-year operating systems course ($N=80$), SLMs and LLMs are perceived to deliver clear, actionable, and well-structured feedback, while humans provide more contextually nuanced guidance. As for the high-enrollment CS2 course ($N=176$) showed the same preference for the AI tools' clarity and breadth, but students noted that AI feedback sometimes lacked the concise, straight-to-the-point, guidance offered by humans. Conversely, in the smaller upper-year technical writing course on AI topics ($N=7$), all students preferred feedback from the course instructor, who was able to provide clear, specific, and personalized feedback, compared to the more general and less targeted AI-based feedback. We also highlight the scalability of AI-based feedback by focusing on its effectiveness at large scale. Our findings underscore the potential of hybrid approaches that combine AI and human feedback to achieve efficient and high-quality feedback at scale.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.11541v1",
    "published_date": "2025-12-01 22:51:54 UTC",
    "updated_date": "2025-12-01 22:51:54 UTC"
  },
  {
    "arxiv_id": "2512.02246v1",
    "title": "DETAIL Matters: Measuring the Impact of Prompt Specificity on Reasoning in Large Language Models",
    "authors": [
      "Olivia Kim"
    ],
    "abstract": "Prompt design plays a critical role in the reasoning performance of large language models (LLMs), yet the impact of prompt specificity - how detailed or vague a prompt is - remains understudied. This paper introduces DETAIL, a framework for evaluating LLM performance across varying levels of prompt specificity. We generate multi-level prompts using GPT-4, quantify specificity via perplexity, and assess correctness using GPT-based semantic equivalence. Experiments on 30 novel reasoning tasks across GPT-4 and O3-mini reveal that specificity improves accuracy, especially for smaller models and procedural tasks. Our results highlight the need for adaptive prompting strategies and provide tools and data to support further research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.02246v1",
    "published_date": "2025-12-01 22:28:39 UTC",
    "updated_date": "2025-12-01 22:28:39 UTC"
  },
  {
    "arxiv_id": "2512.03102v2",
    "title": "Dynamic Correction of Erroneous State Estimates via Diffusion Bayesian Exploration",
    "authors": [
      "Yiwei Shi",
      "Hongnan Ma",
      "Mengyue Yang",
      "Cunjia Liu",
      "Weiru Liu"
    ],
    "abstract": "In emergency response and other high-stakes societal applications, early-stage state estimates critically shape downstream outcomes. Yet, these initial state estimates-often based on limited or biased information-can be severely misaligned with reality, constraining subsequent actions and potentially causing catastrophic delays, resource misallocation, and human harm. Under the stationary bootstrap baseline (zero transition and no rejuvenation), bootstrap particle filters exhibit Stationarity-Induced Posterior Support Invariance (S-PSI), wherein regions excluded by the initial prior remain permanently unexplorable, making corrections impossible even when new evidence contradicts current beliefs. While classical perturbations can in principle break this lock-in, they operate in an always-on fashion and may be inefficient. To overcome this, we propose a diffusion-driven Bayesian exploration framework that enables principled, real-time correction of early state estimation errors. Our method expands posterior support via entropy-regularized sampling and covariance-scaled diffusion. A Metropolis-Hastings check validates proposals and keeps inference adaptive to unexpected evidence. Empirical evaluations on realistic hazardous-gas localization tasks show that our approach matches reinforcement learning and planning baselines when priors are correct. It substantially outperforms classical SMC perturbations and RL-based methods under misalignment, and we provide theoretical guarantees that DEPF resolves S-PSI while maintaining statistical rigor.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.CO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.03102v2",
    "published_date": "2025-12-01 22:08:26 UTC",
    "updated_date": "2025-12-05 15:08:25 UTC"
  },
  {
    "arxiv_id": "2512.08969v1",
    "title": "Learning Robust Representations for Malicious Content Detection via Contrastive Sampling and Uncertainty Estimation",
    "authors": [
      "Elias Hossain",
      "Umesh Biswas",
      "Charan Gudla",
      "Sai Phani Parsa"
    ],
    "abstract": "We propose the Uncertainty Contrastive Framework (UCF), a Positive-Unlabeled (PU) representation learning framework that integrates uncertainty-aware contrastive loss, adaptive temperature scaling, and a self-attention-guided LSTM encoder to improve classification under noisy and imbalanced conditions. UCF dynamically adjusts contrastive weighting based on sample confidence, stabilizes training using positive anchors, and adapts temperature parameters to batch-level variability. Applied to malicious content classification, UCF-generated embeddings enable multiple traditional classifiers to achieve more than 93.38% accuracy, precision above 0.93, and near-perfect recall, with minimal false negatives and competitive ROC-AUC scores. Visual analyses confirm clear separation between positive and unlabeled instances, highlighting the framework's ability to produce calibrated, discriminative embeddings. These results position UCF as a robust and scalable solution for PU learning in high-stakes domains such as cybersecurity and biomedical text mining.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.08969v1",
    "published_date": "2025-12-01 22:06:06 UTC",
    "updated_date": "2025-12-01 22:06:06 UTC"
  },
  {
    "arxiv_id": "2512.02231v1",
    "title": "See, Hear, and Understand: Benchmarking Audiovisual Human Speech Understanding in Multimodal Large Language Models",
    "authors": [
      "Le Thien Phuc Nguyen",
      "Zhuoran Yu",
      "Samuel Low Yu Hang",
      "Subin An",
      "Jeongik Lee",
      "Yohan Ban",
      "SeungEun Chung",
      "Thanh-Huy Nguyen",
      "JuWan Maeng",
      "Soochahn Lee",
      "Yong Jae Lee"
    ],
    "abstract": "Multimodal large language models (MLLMs) are expected to jointly interpret vision, audio, and language, yet existing video benchmarks rarely assess fine-grained reasoning about human speech. Many tasks remain visually solvable or only coarsely evaluate speech, offering limited insight into whether models can align who speaks, what is said, and when it occurs. We introduce AV-SpeakerBench, a curated benchmark of 3,212 multiple-choice questions focused on speaker-centric audiovisual reasoning in real-world videos. It features: (1) a speaker-centered formulation that treats speakers-not scenes-as the core reasoning unit; (2) fusion-grounded question design embedding audiovisual dependencies into question semantics; and (3) expert-curated annotations ensuring temporal precision and cross-modal validity. Comprehensive evaluations show that the Gemini family consistently outperforms open-source systems, with Gemini 2.5 Pro achieving the best results. Among open models, Qwen3-Omni-30B approaches Gemini 2.0 Flash but remains far behind Gemini 2.5 Pro, primarily due to weaker audiovisual fusion rather than visual perception. We believe AV-SpeakerBench establishes a rigorous foundation for advancing fine-grained audiovisual reasoning in future multimodal systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "preprint",
    "pdf_url": "https://arxiv.org/pdf/2512.02231v1",
    "published_date": "2025-12-01 21:57:26 UTC",
    "updated_date": "2025-12-01 21:57:26 UTC"
  },
  {
    "arxiv_id": "2512.02230v1",
    "title": "Benchmarking LLM Agents for Wealth-Management Workflows",
    "authors": [
      "Rory Milsom"
    ],
    "abstract": "Modern work relies on an assortment of digital collaboration tools, yet routine processes continue to suffer from human error and delay. To address this gap, this dissertation extends TheAgentCompany with a finance-focused environment and investigates whether a general purpose LLM agent can complete representative wealth-management tasks both accurately and economically. This study introduces synthetic domain data, enriches colleague simulations, and prototypes an automatic task-generation pipeline. The study aims to create and assess an evaluation set that can meaningfully measure an agent's fitness for assistant-level wealth management work. We construct a benchmark of 12 task-pairs for wealth management assistants spanning retrieval, analysis, and synthesis/communication, with explicit acceptance criteria and deterministic graders. We seeded a set of new finance-specific data and introduced a high vs. low-autonomy variant of every task. The paper concluded that agents are limited less by mathematical reasoning and more so by end-to-end workflow reliability, and meaningfully affected by autonomy level, and that incorrect evaluation of models have hindered benchmarking.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "56 pages, 8 figures, The University of Edinburgh",
    "pdf_url": "https://arxiv.org/pdf/2512.02230v1",
    "published_date": "2025-12-01 21:56:21 UTC",
    "updated_date": "2025-12-01 21:56:21 UTC"
  },
  {
    "arxiv_id": "2512.02228v1",
    "title": "STRIDE: A Systematic Framework for Selecting AI Modalities -- Agentic AI, AI Assistants, or LLM Calls",
    "authors": [
      "Shubhi Asthana",
      "Bing Zhang",
      "Chad DeLuca",
      "Ruchi Mahindru",
      "Hima Patel"
    ],
    "abstract": "The rapid shift from stateless large language models (LLMs) to autonomous, goal-driven agents raises a central question: When is agentic AI truly necessary? While agents enable multi-step reasoning, persistent memory, and tool orchestration, deploying them indiscriminately leads to higher cost, complexity, and risk.\n  We present STRIDE (Systematic Task Reasoning Intelligence Deployment Evaluator), a framework that provides principled recommendations for selecting between three modalities: (i) direct LLM calls, (ii) guided AI assistants, and (iii) fully autonomous agentic AI. STRIDE integrates structured task decomposition, dynamism attribution, and self-reflection requirement analysis to produce an Agentic Suitability Score, ensuring that full agentic autonomy is reserved for tasks with inherent dynamism or evolving context.\n  Evaluated across 30 real-world tasks spanning SRE, compliance, and enterprise automation, STRIDE achieved 92% accuracy in modality selection, reduced unnecessary agent deployments by 45%, and cut resource costs by 37%. Expert validation over six months in SRE and compliance domains confirmed its practical utility, with domain specialists agreeing that STRIDE effectively distinguishes between tasks requiring simple LLM calls, guided assistants, or full agentic autonomy. This work reframes agent adoption as a necessity-driven design decision, ensuring autonomy is applied only when its benefits justify the costs.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 4 Figures, 5 Tables Paper presented at NeurIPS 2025 LAW workshop: Bridging Language, Agent, and World Models",
    "pdf_url": "https://arxiv.org/pdf/2512.02228v1",
    "published_date": "2025-12-01 21:54:07 UTC",
    "updated_date": "2025-12-01 21:54:07 UTC"
  },
  {
    "arxiv_id": "2512.02227v1",
    "title": "Orchestration Framework for Financial Agents: From Algorithmic Trading to Agentic Trading",
    "authors": [
      "Jifeng Li",
      "Arnav Grover",
      "Abraham Alpuerto",
      "Yupeng Cao",
      "Xiao-Yang Liu"
    ],
    "abstract": "The financial market is a mission-critical playground for AI agents due to its temporal dynamics and low signal-to-noise ratio. Building an effective algorithmic trading system may require a professional team to develop and test over the years. In this paper, we propose an orchestration framework for financial agents, which aims to democratize financial intelligence to the general public. We map each component of the traditional algorithmic trading system to agents, including planner, orchestrator, alpha agents, risk agents, portfolio agents, backtest agents, execution agents, audit agents, and memory agent. We present two in-house trading examples. For the stock trading task (hourly data from 04/2024 to 12/2024), our approach achieved a return of $20.42\\%$, a Sharpe ratio of 2.63, and a maximum drawdown of $-3.59\\%$, while the S&P 500 index yielded a return of $15.97\\%$. For the BTC trading task (minute data from 27/07/2025 to 13/08/2025), our approach achieved a return of $8.39\\%$, a Sharpe ratio of $0.38$, and a maximum drawdown of $-2.80\\%$, whereas the BTC price increased by $3.80\\%$. Our code is available on \\href{https://github.com/Open-Finance-Lab/AgenticTrading}{GitHub}.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted at the Workshop on Generative AI in Finance, 39th Conference on Neural Information Processing Systems (NeurIPS 2025)",
    "pdf_url": "https://arxiv.org/pdf/2512.02227v1",
    "published_date": "2025-12-01 21:50:22 UTC",
    "updated_date": "2025-12-01 21:50:22 UTC"
  },
  {
    "arxiv_id": "2512.02214v1",
    "title": "Improved Training Mechanism for Reinforcement Learning via Online Model Selection",
    "authors": [
      "Aida Afshar",
      "Aldo Pacchiano"
    ],
    "abstract": "We study the problem of online model selection in reinforcement learning, where the selector has access to a class of reinforcement learning agents and learns to adaptively select the agent with the right configuration. Our goal is to establish the improved efficiency and performance gains achieved by integrating online model selection methods into reinforcement learning training procedures. We examine the theoretical characterizations that are effective for identifying the right configuration in practice, and address three practical criteria from a theoretical perspective: 1) Efficient resource allocation, 2) Adaptation under non-stationary dynamics, and 3) Training stability across different seeds. Our theoretical results are accompanied by empirical evidence from various model selection tasks in reinforcement learning, including neural architecture selection, step-size selection, and self model selection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.02214v1",
    "published_date": "2025-12-01 21:25:46 UTC",
    "updated_date": "2025-12-01 21:25:46 UTC"
  },
  {
    "arxiv_id": "2512.08967v1",
    "title": "CluCERT: Certifying LLM Robustness via Clustering-Guided Denoising Smoothing",
    "authors": [
      "Zixia Wang",
      "Gaojie Jin",
      "Jia Hu",
      "Ronghui Mu"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have led to their widespread adoption in daily applications. Despite their impressive capabilities, they remain vulnerable to adversarial attacks, as even minor meaning-preserving changes such as synonym substitutions can lead to incorrect predictions. As a result, certifying the robustness of LLMs against such adversarial prompts is of vital importance. Existing approaches focused on word deletion or simple denoising strategies to achieve robustness certification. However, these methods face two critical limitations: (1) they yield loose robustness bounds due to the lack of semantic validation for perturbed outputs and (2) they suffer from high computational costs due to repeated sampling. To address these limitations, we propose CluCERT, a novel framework for certifying LLM robustness via clustering-guided denoising smoothing. Specifically, to achieve tighter certified bounds, we introduce a semantic clustering filter that reduces noisy samples and retains meaningful perturbations, supported by theoretical analysis. Furthermore, we enhance computational efficiency through two mechanisms: a refine module that extracts core semantics, and a fast synonym substitution strategy that accelerates the denoising process. Finally, we conduct extensive experiments on various downstream tasks and jailbreak defense scenarios. Experimental results demonstrate that our method outperforms existing certified approaches in both robustness bounds and computational efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.08967v1",
    "published_date": "2025-12-01 21:13:44 UTC",
    "updated_date": "2025-12-01 21:13:44 UTC"
  },
  {
    "arxiv_id": "2512.02198v1",
    "title": "Multifractal Recalibration of Neural Networks for Medical Imaging Segmentation",
    "authors": [
      "Miguel L. Martins",
      "Miguel T. Coimbra",
      "Francesco Renna"
    ],
    "abstract": "Multifractal analysis has revealed regularities in many self-seeding phenomena, yet its use in modern deep learning remains limited. Existing end-to-end multifractal methods rely on heavy pooling or strong feature-space decimation, which constrain tasks such as semantic segmentation. Motivated by these limitations, we introduce two inductive priors: Monofractal and Multifractal Recalibration. These methods leverage relationships between the probability mass of the exponents and the multifractal spectrum to form statistical descriptions of encoder embeddings, implemented as channel-attention functions in convolutional networks.\n  Using a U-Net-based framework, we show that multifractal recalibration yields substantial gains over a baseline equipped with other channel-attention mechanisms that also use higher-order statistics. Given the proven ability of multifractal analysis to capture pathological regularities, we validate our approach on three public medical-imaging datasets: ISIC18 (dermoscopy), Kvasir-SEG (endoscopy), and BUSI (ultrasound).\n  Our empirical analysis also provides insights into the behavior of these attention layers. We find that excitation responses do not become increasingly specialized with encoder depth in U-Net architectures due to skip connections, and that their effectiveness may relate to global statistics of instance variability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "30 pages, 9 figures, journal paper",
    "pdf_url": "https://arxiv.org/pdf/2512.02198v1",
    "published_date": "2025-12-01 20:43:28 UTC",
    "updated_date": "2025-12-01 20:43:28 UTC"
  },
  {
    "arxiv_id": "2512.02197v1",
    "title": "Bin2Vec: Interpretable and Auditable Multi-View Binary Analysis for Code Plagiarism Detection",
    "authors": [
      "Moussa Moussaoui",
      "Tarik Houichime",
      "Abdelalim Sadiq"
    ],
    "abstract": "We introduce Bin2Vec, a new framework that helps compare software programs in a clear and explainable way. Instead of focusing only on one type of information, Bin2Vec combines what a program looks like (its built-in functions, imports, and exports) with how it behaves when it runs (its instructions and memory usage). This gives a more complete picture when deciding whether two programs are similar or not. Bin2Vec represents these different types of information as views that can be inspected separately using easy-to-read charts, and then brings them together into an overall similarity score. Bin2Vec acts as a bridge between binary representations and machine learning techniques by generating feature representations that can be efficiently processed by machine-learning models. We tested Bin2Vec on multiple versions of two well-known Windows programs, PuTTY and 7-Zip. The primary results strongly confirmed that our method compute an optimal and visualization-friendly representation of the analyzed software. For example, PuTTY versions showed more complex behavior and memory activity, while 7-Zip versions focused more on performance-related patterns. Overall, Bin2Vec provides decisions that are both reliable and explainable to humans. Because it is modular and easy to extend, it can be applied to tasks like auditing, verifying software origins, or quickly screening large numbers of programs in cybersecurity and reverse-engineering work.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.02197v1",
    "published_date": "2025-12-01 20:42:16 UTC",
    "updated_date": "2025-12-01 20:42:16 UTC"
  },
  {
    "arxiv_id": "2512.02195v1",
    "title": "A Knowledge-Based Language Model: Deducing Grammatical Knowledge in a Multi-Agent Language Acquisition Simulation",
    "authors": [
      "David Ph. Shakouri",
      "Crit Cremers",
      "Niels O. Schiller"
    ],
    "abstract": "This paper presents an initial study performed by the MODOMA system. The MODOMA is a computational multi-agent laboratory environment for unsupervised language acquisition experiments such that acquisition is based on the interaction between two language models, an adult and a child agent. Although this framework employs statistical as well as rule-based procedures, the result of language acquisition is a knowledge-based language model, which can be used to generate and parse new utterances of the target language. This system is fully parametrized and researchers can control all aspects of the experiments while the results of language acquisition, that is, the acquired grammatical knowledge, are explicitly represented and can be consulted. Thus, this system introduces novel possibilities for conducting computational language acquisition experiments. The experiments presented by this paper demonstrate that functional and content categories can be acquired and represented by the daughter agent based on training and test data containing different amounts of exemplars generated by the adult agent. Interestingly, similar patterns, which are well-established for human-generated data, are also found for these machine-generated data. As the procedures resulted in the successful acquisition of discrete grammatical categories by the child agent, these experiments substantiate the validity of the MODOMA approach to modelling language acquisition.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 7 figures, 11 tables. Related work: arXiv:2503.18702. This is the peer-reviewed publisher's version, downloadable from: https://www.clinjournal.org/clinj/article/view/193",
    "pdf_url": "https://arxiv.org/pdf/2512.02195v1",
    "published_date": "2025-12-01 20:40:36 UTC",
    "updated_date": "2025-12-01 20:40:36 UTC"
  },
  {
    "arxiv_id": "2512.02194v1",
    "title": "Enforcing Orderedness to Improve Feature Consistency",
    "authors": [
      "Sophie L. Wang",
      "Alex Quach",
      "Nithin Parsan",
      "John J. Yang"
    ],
    "abstract": "Sparse autoencoders (SAEs) have been widely used for interpretability of neural networks, but their learned features often vary across seeds and hyperparameter settings. We introduce Ordered Sparse Autoencoders (OSAE), which extend Matryoshka SAEs by (1) establishing a strict ordering of latent features and (2) deterministically using every feature dimension, avoiding the sampling-based approximations of prior nested SAE methods. Theoretically, we show that OSAEs resolve permutation non-identifiability in settings of sparse dictionary learning where solutions are unique (up to natural symmetries). Empirically on Gemma2-2B and Pythia-70M, we show that OSAEs can help improve consistency compared to Matryoshka baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.02194v1",
    "published_date": "2025-12-01 20:39:19 UTC",
    "updated_date": "2025-12-01 20:39:19 UTC"
  },
  {
    "arxiv_id": "2512.02193v1",
    "title": "From monoliths to modules: Decomposing transducers for efficient world modelling",
    "authors": [
      "Alexander Boyd",
      "Franz Nowak",
      "David Hyland",
      "Manuel Baltieri",
      "Fernando E. Rosas"
    ],
    "abstract": "World models have been recently proposed as sandbox environments in which AI agents can be trained and evaluated before deployment. Although realistic world models often have high computational demands, efficient modelling is usually possible by exploiting the fact that real-world scenarios tend to involve subcomponents that interact in a modular manner. In this paper, we explore this idea by developing a framework for decomposing complex world models represented by transducers, a class of models generalising POMDPs. Whereas the composition of transducers is well understood, our results clarify how to invert this process, deriving sub-transducers operating on distinct input-output subspaces, enabling parallelizable and interpretable alternatives to monolithic world modelling that can support distributed inference. Overall, these results lay a groundwork for bridging the structural transparency demanded by AI safety and the computational efficiency required for real-world inference.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.02193v1",
    "published_date": "2025-12-01 20:37:43 UTC",
    "updated_date": "2025-12-01 20:37:43 UTC"
  },
  {
    "arxiv_id": "2512.02192v1",
    "title": "Story2MIDI: Emotionally Aligned Music Generation from Text",
    "authors": [
      "Mohammad Shokri",
      "Alexandra C. Salem",
      "Gabriel Levine",
      "Johanna Devaney",
      "Sarah Ita Levitan"
    ],
    "abstract": "In this paper, we introduce Story2MIDI, a sequence-to-sequence Transformer-based model for generating emotion-aligned music from a given piece of text. To develop this model, we construct the Story2MIDI dataset by merging existing datasets for sentiment analysis from text and emotion classification in music. The resulting dataset contains pairs of text blurbs and music pieces that evoke the same emotions in the reader or listener. Despite the small scale of our dataset and limited computational resources, our results indicate that our model effectively learns emotion-relevant features in music and incorporates them into its generation process, producing samples with diverse emotional responses. We evaluate the generated outputs using objective musical metrics and a human listening study, confirming the model's ability to capture intended emotional cues.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SD",
    "comment": "8 pages (6 pages of main text + 2 pages of references and appendices), 4 figures, 1 table. Presented at IEEE Big Data 2025 3rd Workshop on AI Music Generation (AIMG 2025)",
    "pdf_url": "https://arxiv.org/pdf/2512.02192v1",
    "published_date": "2025-12-01 20:35:18 UTC",
    "updated_date": "2025-12-01 20:35:18 UTC"
  },
  {
    "arxiv_id": "2512.02185v1",
    "title": "Think Before You Prune: Self-Reflective Structured Pruning for Reasoning Language Models",
    "authors": [
      "Ziyan Wang",
      "Enmao Diao",
      "Qi Le",
      "Pu Wang",
      "Guanchu Wang",
      "Minwoo Lee",
      "Shu-ping Yeh",
      "Li Yang"
    ],
    "abstract": "Reasoning LLMs (RLMs) such as OpenAI o1, DeepSeek-R1, and Qwen3 deliver strong multi-step reasoning through chain-of-thought generation, but their large model sizes and lengthy decode-time outputs make them costly to deploy and unsuitable for resource-constrained settings. To reduce computing and memory cost, pruning offers a promising solution by removing unimportant parameters. However, despite their success on standard LLMs, existing pruning methods severely damage RLMs, as even moderate sparsity (e.g., 20%) can collapse accuracy and completely disrupt the model's reasoning coherence. We begin by analyzing why existing pruning pipelines fail on reasoning LLMs and find that their brittleness largely stems from a mismatch between the calibration data, the pruning objective, and the model's decode-time reasoning behavior. Our study further shows that the most reliable calibration signal comes not from human-written labels but from the model's own self-generated reasoning traces, which more accurately reflect its inference distribution. Guided by these insights, we introduce RESP, a self-reflective structured pruning framework that aligns pruning decisions with the model's reasoning dynamics through self-generated calibration, decode-only gradient-based importance estimation, and progressive regeneration that maintains calibration fidelity as sparsity increases. Experiments on Qwen3-8B demonstrate that RESP markedly outperforms existing structured pruning methods on both GSM8K and MathQA, preserving near-dense accuracy at 20-30% sparsity and substantially mitigating performance collapse at higher sparsity levels. At 40% sparsity, RESP attains 81.3% accuracy on GSM8K and 59.6% on MathQA, surpassing the strongest baselines by 66.87% and 47%, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.02185v1",
    "published_date": "2025-12-01 20:27:05 UTC",
    "updated_date": "2025-12-01 20:27:05 UTC"
  },
  {
    "arxiv_id": "2512.02180v1",
    "title": "CLEF: Clinically-Guided Contrastive Learning for Electrocardiogram Foundation Models",
    "authors": [
      "Yuxuan Shu",
      "Peter H. Charlton",
      "Fahim Kawsar",
      "Jussi Hernesniemi",
      "Mohammad Malekzadeh"
    ],
    "abstract": "The electrocardiogram (ECG) is a key diagnostic tool in cardiovascular health. Single-lead ECG recording is integrated into both clinical-grade and consumer wearables. While self-supervised pretraining of foundation models on unlabeled ECGs improves diagnostic performance, existing approaches do not incorporate domain knowledge from clinical metadata. We introduce a novel contrastive learning approach that utilizes an established clinical risk score to adaptively weight negative pairs: clinically-guided contrastive learning. It aligns the similarities of ECG embeddings with clinically meaningful differences between subjects, with an explicit mechanism to handle missing metadata. On 12-lead ECGs from 161K patients in the MIMIC-IV dataset, we pretrain single-lead ECG foundation models at three scales, collectively called CLEF, using only routinely collected metadata without requiring per-sample ECG annotations. We evaluate CLEF on 18 clinical classification and regression tasks across 7 held-out datasets, and benchmark against 5 foundation model baselines and 3 self-supervised algorithms. When pretrained on 12-lead ECG data and tested on lead-I data, CLEF outperforms self-supervised foundation model baselines: the medium-sized CLEF achieves average AUROC improvements of at least 2.6% in classification and average reductions in MAEs of at least 3.2% in regression. Comparing with existing self-supervised learning algorithms, CLEF improves the average AUROC by at least 1.8%. Moreover, when pretrained only on lead-I data for classification tasks, CLEF performs comparably to the state-of-the-art ECGFounder, which was trained in a supervised manner. Overall, CLEF enables more accurate and scalable single-lead ECG analysis, advancing remote health monitoring. Code and pretrained CLEF models are available at: github.com/Nokia-Bell-Labs/ecg-foundation-model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The code is available at https://github.com/Nokia-Bell-Labs/ecg-foundation-model",
    "pdf_url": "https://arxiv.org/pdf/2512.02180v1",
    "published_date": "2025-12-01 20:21:44 UTC",
    "updated_date": "2025-12-01 20:21:44 UTC"
  },
  {
    "arxiv_id": "2512.02179v2",
    "title": "Young children's anthropomorphism of an AI chatbot: Brain activation and the role of parent co-presence",
    "authors": [
      "Pilyoung Kim",
      "Jenna H. Chin",
      "Yun Xie",
      "Nolan Brady",
      "Tom Yeh",
      "Sujin Yang"
    ],
    "abstract": "Artificial Intelligence (AI) chatbots powered by a large language model (LLM) are entering young children's learning and play, yet little is known about how young children construe these agents or how such construals relate to engagement. We examined anthropomorphism of a social AI chatbot during collaborative storytelling and asked how children's attributions related to their behavior and prefrontal activation. Children at ages 5-6 (N = 23) completed three storytelling sessions: interacting with (1) an AI chatbot only, (2) a parent only, and (3) the AI and a parent together. After the sessions, children completed an interview assessing anthropomorphism toward both the AI chatbot and the parent. Behavioral engagement was indexed by the conversational turn count (CTC) ratio, and concurrent fNIRS measured oxygenated hemoglobin in bilateral vmPFC and dmPFC regions. Children reported higher anthropomorphism for parents than for the AI chatbot overall, although AI ratings were relatively high for perceptive abilities and epistemic states. Anthropomorphism was not associated with CTC. In the right dmPFC, higher perceptive scores were associated with greater activation during the AI-only condition and with lower activation during the AI+Parent condition. Exploratory analyses indicated that higher dmPFC activation during the AI-only condition correlated with higher end-of-session \"scared\" mood ratings. Findings suggest that stronger perceptive anthropomorphism can be associated with greater brain activation related to interpreting the AI's mental states, whereas parent co-presence may help some children interpret and regulate novel AI interactions. These results may have design implications for encouraging parent-AI co-use in early childhood.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "I updated the title",
    "pdf_url": "https://arxiv.org/pdf/2512.02179v2",
    "published_date": "2025-12-01 20:21:08 UTC",
    "updated_date": "2025-12-03 17:28:31 UTC"
  },
  {
    "arxiv_id": "2512.02170v2",
    "title": "Flowchart2Mermaid: A Vision-Language Model Powered System for Converting Flowcharts into Editable Diagram Code",
    "authors": [
      "Pritam Deka",
      "Barry Devereux"
    ],
    "abstract": "Flowcharts are common tools for communicating processes but are often shared as static images that cannot be easily edited or reused. We present Flowchart2Mermaid, a lightweight web system that converts flowchart images into editable Mermaid.js code which is a markup language for visual workflows, using a detailed system prompt and vision-language models. The interface supports mixed-initiative refinement through inline text editing, drag-and-drop node insertion, and natural-language commands interpreted by an integrated AI assistant. Unlike prior image-to-diagram tools, our approach produces a structured, version-controllable textual representation that remains synchronized with the rendered diagram. We further introduce evaluation metrics to assess structural accuracy, flow correctness, syntax validity, and completeness across multiple models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to EACL 2026 Demo Track",
    "pdf_url": "https://arxiv.org/pdf/2512.02170v2",
    "published_date": "2025-12-01 20:07:59 UTC",
    "updated_date": "2025-12-03 11:47:04 UTC"
  },
  {
    "arxiv_id": "2512.04119v1",
    "title": "Humanity in the Age of AI: Reassessing 2025's Existential-Risk Narratives",
    "authors": [
      "Mohamed El Louadi"
    ],
    "abstract": "Two 2025 publications, \"AI 2027\" (Kokotajlo et al., 2025) and \"If Anyone Builds It, Everyone Dies\" (Yudkowsky & Soares, 2025), assert that superintelligent artificial intelligence will almost certainly destroy or render humanity obsolete within the next decade. Both rest on the classic chain formulated by Good (1965) and Bostrom (2014): intelligence explosion, superintelligence, lethal misalignment. This article subjects each link to the empirical record of 2023-2025. Sixty years after Good's speculation, none of the required phenomena (sustained recursive self-improvement, autonomous strategic awareness, or intractable lethal misalignment) have been observed. Current generative models remain narrow, statistically trained artefacts: powerful, opaque, and imperfect, but devoid of the properties that would make the catastrophic scenarios plausible. Following Whittaker (2025a, 2025b, 2025c) and Zuboff (2019, 2025), we argue that the existential-risk thesis functions primarily as an ideological distraction from the ongoing consolidation of surveillance capitalism and extreme concentration of computational power. The thesis is further inflated by the 2025 AI speculative bubble, where trillions in investments in rapidly depreciating \"digital lettuce\" hardware (McWilliams, 2025) mask lagging revenues and jobless growth rather than heralding superintelligence. The thesis remains, in November 2025, a speculative hypothesis amplified by a speculative financial bubble rather than a demonstrated probability.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.04119v1",
    "published_date": "2025-12-01 19:37:27 UTC",
    "updated_date": "2025-12-01 19:37:27 UTC"
  },
  {
    "arxiv_id": "2512.02141v1",
    "title": "Feature Selection Empowered BERT for Detection of Hate Speech with Vocabulary Augmentation",
    "authors": [
      "Pritish N. Desai",
      "Tanay Kewalramani",
      "Srimanta Mandal"
    ],
    "abstract": "Abusive speech on social media poses a persistent and evolving challenge, driven by the continuous emergence of novel slang and obfuscated terms designed to circumvent detection systems. In this work, we present a data efficient strategy for fine tuning BERT on hate speech classification by significantly reducing training set size without compromising performance. Our approach employs a TF IDF-based sample selection mechanism to retain only the most informative 75 percent of examples, thereby minimizing training overhead. To address the limitations of BERT's native vocabulary in capturing evolving hate speech terminology, we augment the tokenizer with domain-specific slang and lexical variants commonly found in abusive contexts. Experimental results on a widely used hate speech dataset demonstrate that our method achieves competitive performance while improving computational efficiency, highlighting its potential for scalable and adaptive abusive content moderation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.02141v1",
    "published_date": "2025-12-01 19:11:32 UTC",
    "updated_date": "2025-12-01 19:11:32 UTC"
  },
  {
    "arxiv_id": "2512.05998v1",
    "title": "Going All-In on LLM Accuracy: Fake Prediction Markets, Real Confidence Signals",
    "authors": [
      "Michael Todasco"
    ],
    "abstract": "Large language models are increasingly used to evaluate other models, yet these judgments typically lack any representation of confidence. This pilot study tests whether framing an evaluation task as a betting game (a fictional prediction market with its own LLM currency) improves forecasting accuracy and surfaces calibrated confidence signals. We generated 100 math and logic questions with verifiable answers. Six Baseline models (three current-generation, three prior-generation) answered all items. Three Predictor models then forecasted, for each question-baseline pair, if the baseline would answer correctly. Each predictor completed matched runs in two conditions: Control (simple correct/incorrect predictions) and Incentive (predictions plus wagers of 1-100,000 LLMCoin under even odds, starting from a 1,000,000 LLMCoin bankroll). Across 5,400 predictions per condition, Incentive runs showed modestly higher accuracy (81.5% vs. 79.1%, p = .089, d = 0.86) and significantly faster learning across rounds (12.0 vs. 2.9 percentage-point improvement from Round 1 to Round 4, p = .011). Most notably, stake size tracked confidence. \"Whale\" bets of 40,000+ coins were correct ~99% of the time, while small bets (<1,000 coins) showed only ~74% accuracy. The key finding is not that fictional money makes models smarter; accuracy gains were modest and did not reach statistical significance (p = .089) in this pilot. Rather, the betting mechanic created a legible confidence signal absent from binary yes/no outputs. This suggests that simple financial framing may help transform LLMs into risk-aware forecasters, making their internal beliefs visible and usable. The protocol offers a foundation for future work for meta-evaluation systems and what may become LLM-to-LLM prediction markets.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 8 tables, 2 figures. Pilot study. Data, prompts, and code available at https://osf.io/dc24t/",
    "pdf_url": "https://arxiv.org/pdf/2512.05998v1",
    "published_date": "2025-12-01 19:04:25 UTC",
    "updated_date": "2025-12-01 19:04:25 UTC"
  },
  {
    "arxiv_id": "2512.03101v1",
    "title": "ALARM: Automated MLLM-Based Anomaly Detection in Complex-EnviRonment Monitoring with Uncertainty Quantification",
    "authors": [
      "Congjing Zhang",
      "Feng Lin",
      "Xinyi Zhao",
      "Pei Guo",
      "Wei Li",
      "Lin Chen",
      "Chaoyue Zhao",
      "Shuai Huang"
    ],
    "abstract": "The advance of Large Language Models (LLMs) has greatly stimulated research interest in developing multi-modal LLM (MLLM)-based visual anomaly detection (VAD) algorithms that can be deployed in complex environments. The challenge is that in these complex environments, the anomalies are sometimes highly contextual and also ambiguous, and thereby, uncertainty quantification (UQ) is a crucial capacity for an MLLM-based VAD system to succeed. In this paper, we introduce our UQ-supported MLLM-based VAD framework called ALARM. ALARM integrates UQ with quality-assurance techniques like reasoning chain, self-reflection, and MLLM ensemble for robust and accurate performance and is designed based on a rigorous probabilistic inference pipeline and computational process. Extensive empirical evaluations are conducted using the real-world smart-home benchmark data and wound image classification data, which shows ALARM's superior performance and its generic applicability across different domains for reliable decision-making.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.03101v1",
    "published_date": "2025-12-01 19:03:14 UTC",
    "updated_date": "2025-12-01 19:03:14 UTC"
  },
  {
    "arxiv_id": "2512.02020v2",
    "title": "EfficientFlow: Efficient Equivariant Flow Policy Learning for Embodied AI",
    "authors": [
      "Jianlei Chang",
      "Ruofeng Mei",
      "Wei Ke",
      "Xiangyu Xu"
    ],
    "abstract": "Generative modeling has recently shown remarkable promise for visuomotor policy learning, enabling flexible and expressive control across diverse embodied AI tasks. However, existing generative policies often struggle with data inefficiency, requiring large-scale demonstrations, and sampling inefficiency, incurring slow action generation during inference. We introduce EfficientFlow, a unified framework for efficient embodied AI with flow-based policy learning. To enhance data efficiency, we bring equivariance into flow matching. We theoretically prove that when using an isotropic Gaussian prior and an equivariant velocity prediction network, the resulting action distribution remains equivariant, leading to improved generalization and substantially reduced data demands. To accelerate sampling, we propose a novel acceleration regularization strategy. As direct computation of acceleration is intractable for marginal flow trajectories, we derive a novel surrogate loss that enables stable and scalable training using only conditional trajectories. Across a wide range of robotic manipulation benchmarks, the proposed algorithm achieves competitive or superior performance under limited data while offering dramatically faster inference. These results highlight EfficientFlow as a powerful and efficient paradigm for high-performance embodied AI.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by AAAI 2026. Project Page: https://efficientflow.github.io/",
    "pdf_url": "https://arxiv.org/pdf/2512.02020v2",
    "published_date": "2025-12-01 18:59:59 UTC",
    "updated_date": "2025-12-14 13:00:12 UTC"
  },
  {
    "arxiv_id": "2512.02019v2",
    "title": "A Diffusion Model Framework for Maximum Entropy Reinforcement Learning",
    "authors": [
      "Sebastian Sanokowski",
      "Kaustubh Patil",
      "Alois Knoll"
    ],
    "abstract": "Diffusion models have achieved remarkable success in data-driven learning and in sampling from complex, unnormalized target distributions. Building on this progress, we reinterpret Maximum Entropy Reinforcement Learning (MaxEntRL) as a diffusion model-based sampling problem. We tackle this problem by minimizing the reverse Kullback-Leibler (KL) divergence between the diffusion policy and the optimal policy distribution using a tractable upper bound. By applying the policy gradient theorem to this objective, we derive a modified surrogate objective for MaxEntRL that incorporates diffusion dynamics in a principled way. This leads to simple diffusion-based variants of Soft Actor-Critic (SAC), Proximal Policy Optimization (PPO) and Wasserstein Policy Optimization (WPO), termed DiffSAC, DiffPPO and DiffWPO. All of these methods require only minor implementation changes to their base algorithm. We find that on standard continuous control benchmarks, DiffSAC, DiffPPO and DiffWPO achieve better returns and higher sample efficiency than SAC and PPO.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.02019v2",
    "published_date": "2025-12-01 18:59:58 UTC",
    "updated_date": "2025-12-03 00:55:54 UTC"
  },
  {
    "arxiv_id": "2512.02017v1",
    "title": "Visual Sync: Multi-Camera Synchronization via Cross-View Object Motion",
    "authors": [
      "Shaowei Liu",
      "David Yifan Yao",
      "Saurabh Gupta",
      "Shenlong Wang"
    ],
    "abstract": "Today, people can easily record memorable moments, ranging from concerts, sports events, lectures, family gatherings, and birthday parties with multiple consumer cameras. However, synchronizing these cross-camera streams remains challenging. Existing methods assume controlled settings, specific targets, manual correction, or costly hardware. We present VisualSync, an optimization framework based on multi-view dynamics that aligns unposed, unsynchronized videos at millisecond accuracy. Our key insight is that any moving 3D point, when co-visible in two cameras, obeys epipolar constraints once properly synchronized. To exploit this, VisualSync leverages off-the-shelf 3D reconstruction, feature matching, and dense tracking to extract tracklets, relative poses, and cross-view correspondences. It then jointly minimizes the epipolar error to estimate each camera's time offset. Experiments on four diverse, challenging datasets show that VisualSync outperforms baseline methods, achieving an median synchronization error below 50 ms.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to NeurIPS 2025. Project page: https://stevenlsw.github.io/visualsync/",
    "pdf_url": "https://arxiv.org/pdf/2512.02017v1",
    "published_date": "2025-12-01 18:59:57 UTC",
    "updated_date": "2025-12-01 18:59:57 UTC"
  },
  {
    "arxiv_id": "2512.01996v1",
    "title": "Learning Sim-to-Real Humanoid Locomotion in 15 Minutes",
    "authors": [
      "Younggyo Seo",
      "Carmelo Sferrazza",
      "Juyue Chen",
      "Guanya Shi",
      "Rocky Duan",
      "Pieter Abbeel"
    ],
    "abstract": "Massively parallel simulation has reduced reinforcement learning (RL) training time for robots from days to minutes. However, achieving fast and reliable sim-to-real RL for humanoid control remains difficult due to the challenges introduced by factors such as high dimensionality and domain randomization. In this work, we introduce a simple and practical recipe based on off-policy RL algorithms, i.e., FastSAC and FastTD3, that enables rapid training of humanoid locomotion policies in just 15 minutes with a single RTX 4090 GPU. Our simple recipe stabilizes off-policy RL algorithms at massive scale with thousands of parallel environments through carefully tuned design choices and minimalist reward functions. We demonstrate rapid end-to-end learning of humanoid locomotion controllers on Unitree G1 and Booster T1 robots under strong domain randomization, e.g., randomized dynamics, rough terrain, and push perturbations, as well as fast training of whole-body human-motion tracking policies. We provide videos and open-source implementation at: https://younggyo.me/fastsac-humanoid.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project website: https://younggyo.me/fastsac-humanoid",
    "pdf_url": "https://arxiv.org/pdf/2512.01996v1",
    "published_date": "2025-12-01 18:55:17 UTC",
    "updated_date": "2025-12-01 18:55:17 UTC"
  },
  {
    "arxiv_id": "2512.01993v1",
    "title": "RoaD: Rollouts as Demonstrations for Closed-Loop Supervised Fine-Tuning of Autonomous Driving Policies",
    "authors": [
      "Guillermo Garcia-Cobo",
      "Maximilian Igl",
      "Peter Karkus",
      "Zhejun Zhang",
      "Michael Watson",
      "Yuxiao Chen",
      "Boris Ivanovic",
      "Marco Pavone"
    ],
    "abstract": "Autonomous driving policies are typically trained via open-loop behavior cloning of human demonstrations. However, such policies suffer from covariate shift when deployed in closed loop, leading to compounding errors. We introduce Rollouts as Demonstrations (RoaD), a simple and efficient method to mitigate covariate shift by leveraging the policy's own closed-loop rollouts as additional training data. During rollout generation, RoaD incorporates expert guidance to bias trajectories toward high-quality behavior, producing informative yet realistic demonstrations for fine-tuning. This approach enables robust closed-loop adaptation with orders of magnitude less data than reinforcement learning, and avoids restrictive assumptions of prior closed-loop supervised fine-tuning (CL-SFT) methods, allowing broader applications domains including end-to-end driving. We demonstrate the effectiveness of RoaD on WOSAC, a large-scale traffic simulation benchmark, where it performs similar or better than the prior CL-SFT method; and in AlpaSim, a high-fidelity neural reconstruction-based simulator for end-to-end driving, where it improves driving score by 41\\% and reduces collisions by 54\\%.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Preprint",
    "pdf_url": "https://arxiv.org/pdf/2512.01993v1",
    "published_date": "2025-12-01 18:52:03 UTC",
    "updated_date": "2025-12-01 18:52:03 UTC"
  },
  {
    "arxiv_id": "2512.01992v1",
    "title": "LLM CHESS: Benchmarking Reasoning and Instruction-Following in LLMs through Chess",
    "authors": [
      "Sai Kolasani",
      "Maxim Saplin",
      "Nicholas Crispino",
      "Kyle Montgomery",
      "Jared Quincy Davis",
      "Matei Zaharia",
      "Chi Wang",
      "Chenguang Wang"
    ],
    "abstract": "We introduce LLM CHESS, an evaluation framework designed to probe the generalization of reasoning and instruction-following abilities in large language models (LLMs) through extended agentic interaction in the domain of chess. We rank over 50 open and closed source models by playing against a random opponent using a range of behavioral metrics, including win and loss rates, move quality, move legality, hallucinated actions, and game duration. For a subset of top reasoning models, we derive an Elo estimate by playing against a chess engine with variably configured skill, which allows for comparisons between models in an easily understandable way. Despite the simplicity of the instruction-following task and the weakness of the opponent, many state-of-the-art models struggle to complete games or achieve consistent wins. Similar to other benchmarks on complex reasoning tasks, our experiments reveal a clear separation between reasoning and non-reasoning models. However, unlike existing static benchmarks, the stochastic and dynamic nature of LLM CHESS uniquely reduces overfitting and memorization while preventing benchmark saturation, proving difficult even for top reasoning models. To support future work on evaluating reasoning and instruction-following in LLMs, we release our experimental framework, a public leaderboard, and a dataset of associated games.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01992v1",
    "published_date": "2025-12-01 18:51:08 UTC",
    "updated_date": "2025-12-01 18:51:08 UTC"
  },
  {
    "arxiv_id": "2512.01987v3",
    "title": "Forecasting in Offline Reinforcement Learning for Non-stationary Environments",
    "authors": [
      "Suzan Ece Ada",
      "Georg Martius",
      "Emre Ugur",
      "Erhan Oztop"
    ],
    "abstract": "Offline Reinforcement Learning (RL) provides a promising avenue for training policies from pre-collected datasets when gathering additional interaction data is infeasible. However, existing offline RL methods often assume stationarity or only consider synthetic perturbations at test time, assumptions that often fail in real-world scenarios characterized by abrupt, time-varying offsets. These offsets can lead to partial observability, causing agents to misperceive their true state and degrade performance. To overcome this challenge, we introduce Forecasting in Non-stationary Offline RL (FORL), a framework that unifies (i) conditional diffusion-based candidate state generation, trained without presupposing any specific pattern of future non-stationarity, and (ii) zero-shot time-series foundation models. FORL targets environments prone to unexpected, potentially non-Markovian offsets, requiring robust agent performance from the onset of each episode. Empirical evaluations on offline RL benchmarks, augmented with real-world time-series data to simulate realistic non-stationarity, demonstrate that FORL consistently improves performance compared to competitive baselines. By integrating zero-shot forecasting with the agent's experience, we aim to bridge the gap between offline RL and the complexities of real-world, non-stationary environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "The Thirty-Ninth Annual Conference on Neural Information Processing Systems, NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.01987v3",
    "published_date": "2025-12-01 18:45:05 UTC",
    "updated_date": "2025-12-27 16:09:15 UTC"
  },
  {
    "arxiv_id": "2512.01979v1",
    "title": "Chain-of-Ground: Improving GUI Grounding via Iterative Reasoning and Reference Feedback",
    "authors": [
      "Aiden Yiliu Li",
      "Bizhi Yu",
      "Daoan Lei",
      "Tianhe Ren",
      "Shilong Liu"
    ],
    "abstract": "GUI grounding aims to align natural language instructions with precise regions in complex user interfaces. Advanced multimodal large language models show strong ability in visual GUI grounding but still struggle with small or visually similar targets and ambiguity in real world layouts. These limitations arise from limited grounding capacity and from underuse of existing reasoning potential. We present Chain of Ground CoG a training free multi step grounding framework that uses multimodal large language models for iterative visual reasoning and refinement. Instead of direct prediction the model progressively reflects and adjusts its hypotheses leading to more accurate and interpretable localization. Our approach achieves 68.4 accuracy on the ScreenSpot Pro benchmark an improvement of 4.8 points. To measure real world generalization we introduce TPanel UI a dataset of 420 labeled industrial control panels with visual distortions such as blur and masking. On TPanel UI Chain of Ground improves over the strong baseline Qwen3 VL 235B by 6.9 points showing the effectiveness of multi step training free grounding across real world and digital interfaces. These results highlight a direction for unlocking grounding potential through structured iterative refinement instead of additional training.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01979v1",
    "published_date": "2025-12-01 18:37:19 UTC",
    "updated_date": "2025-12-01 18:37:19 UTC"
  },
  {
    "arxiv_id": "2512.01977v1",
    "title": "AI-Driven Optimization under Uncertainty for Mineral Processing Operations",
    "authors": [
      "William Xu",
      "Amir Eskanlou",
      "Mansur Arief",
      "David Zhen Yin",
      "Jef K. Caers"
    ],
    "abstract": "The global capacity for mineral processing must expand rapidly to meet the demand for critical minerals, which are essential for building the clean energy technologies necessary to mitigate climate change. However, the efficiency of mineral processing is severely limited by uncertainty, which arises from both the variability of feedstock and the complexity of process dynamics. To optimize mineral processing circuits under uncertainty, we introduce an AI-driven approach that formulates mineral processing as a Partially Observable Markov Decision Process (POMDP). We demonstrate the capabilities of this approach in handling both feedstock uncertainty and process model uncertainty to optimize the operation of a simulated, simplified flotation cell as an example. We show that by integrating the process of information gathering (i.e., uncertainty reduction) and process optimization, this approach has the potential to consistently perform better than traditional approaches at maximizing an overall objective, such as net present value (NPV). Our methodological demonstration of this optimization-under-uncertainty approach for a synthetic case provides a mathematical and computational framework for later real-world application, with the potential to improve both the laboratory-scale design of experiments and industrial-scale operation of mineral processing circuits without any additional hardware.",
    "categories": [
      "eess.SY",
      "cs.AI"
    ],
    "primary_category": "eess.SY",
    "comment": "27 pages, 13 figures, submitted to Sustainable Earth Resources Communications (SERC)",
    "pdf_url": "https://arxiv.org/pdf/2512.01977v1",
    "published_date": "2025-12-01 18:35:54 UTC",
    "updated_date": "2025-12-01 18:35:54 UTC"
  },
  {
    "arxiv_id": "2512.01970v2",
    "title": "From Atomic to Composite: Reinforcement Learning Enables Generalization in Complementary Reasoning",
    "authors": [
      "Sitao Cheng",
      "Xunjian Yin",
      "Ruiwen Zhou",
      "Yuxuan Li",
      "Xinyi Wang",
      "Liangming Pan",
      "William Yang Wang",
      "Victor Zhong"
    ],
    "abstract": "The mechanism by which RL contributes to reasoning capabilities-whether it incentivizes the synthesis of new skills or merely amplifies existing behaviors-remains a subject of intense debate. In this work, we investigate this question through the lens of Complementary Reasoning, a complex task that requires integrating internal parametric knowledge with external contextual information. Using a controlled synthetic dataset of human biographies, we strictly decouple this ability into two atomic skills: Parametric Reasoning (relying on internal knowledge) and Contextual Reasoning (depending on external information). To rigorously assess capability boundaries, we evaluate generalization across three distinct levels of difficulty: I.I.D., Composition, and Zero-shot settings. We find that while SFT is sufficient for in-distribution performance, it struggles with O.O.D. generalization, particularly in Zero-shot settings where relational combinations are novel. Crucially, we identify the SFT Generalization Paradox: Models supervised solely on the composite task achieve near-perfect in-distribution accuracy but collapse on out-of-distribution generalization, indicating their reliance on rote memorization of path shortcuts. In contrast, we find that RL acts as a reasoning synthesizer rather than a probability amplifier. However, we uncover a strict atomic prerequisite: RL can only synthesize these complex strategies if the base model has first mastered the independent atomic skills (Parametric and Contextual) via SFT. These findings challenge the view of RL as a mere amplifier, suggesting that given sufficient atomic foundations, RL can actively synthesize complex reasoning strategies from learned primitives without explicit supervision on such complex strategies. This indicates that decoupled atomic training followed by RL offers a scalable path to generalization for complex reasoning tasks.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Work in Progress. Code and data will be available at https://github.com/sitaocheng/from_atomic_to_composite",
    "pdf_url": "https://arxiv.org/pdf/2512.01970v2",
    "published_date": "2025-12-01 18:27:25 UTC",
    "updated_date": "2025-12-02 04:17:18 UTC"
  },
  {
    "arxiv_id": "2512.03100v1",
    "title": "Ensemble Privacy Defense for Knowledge-Intensive LLMs against Membership Inference Attacks",
    "authors": [
      "Haowei Fu",
      "Bo Ni",
      "Han Xu",
      "Kunpeng Liu",
      "Dan Lin",
      "Tyler Derr"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) and Supervised Finetuning (SFT) have become the predominant paradigms for equipping Large Language Models (LLMs) with external knowledge for diverse, knowledge-intensive tasks. However, while such knowledge injection improves performance, it also exposes new attack surfaces. Membership Inference Attacks (MIAs), which aim to determine whether a given data sample was included in a model's training set, pose serious threats to privacy and trust in sensitive domains. To this end, we first systematically evaluate the vulnerability of RAG- and SFT-based LLMs to various MIAs. Then, to address the privacy risk, we further introduce a novel, model-agnostic defense framework, Ensemble Privacy Defense (EPD), which aggregates and evaluates the outputs of a knowledge-injected LLM, a base LLM, and a dedicated judge model to enhance resistance against MIAs. Comprehensive experiments show that, on average, EPD reduces MIA success by up to 27.8\\% for SFT and 526.3\\% for RAG compared to inference-time baseline, while maintaining answer quality.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.03100v1",
    "published_date": "2025-12-01 18:12:18 UTC",
    "updated_date": "2025-12-01 18:12:18 UTC"
  },
  {
    "arxiv_id": "2512.01958v1",
    "title": "Learned-Rule-Augmented Large Language Model Evaluators",
    "authors": [
      "Jie Meng",
      "Jin Mao"
    ],
    "abstract": "Large language models (LLMs) are predominantly used as evaluators for natural language generation (NLG) tasks, but their application to broader evaluation scenarios remains limited. In this work, we explore the potential of LLMs as general evaluators across diverse tasks. Although LLM-based evaluators have made progress in different areas, existing methods struggle to generalize due to their reliance on costly, human-designed evaluation principles, which are often misaligned with both annotated data and LLMs' understanding.To address these challenges, we propose a rule-augmented evaluation paradigm. First, we introduce a rule distillation method that automatically extracts scoring rules from data using an LLM-assisted Monte Carlo Tree Search (MCTS), alleviating scalability issues and improving alignment with data. Second, to enable LLMs to effectively apply the learned rules, we propose two strategies: (1) Chain-of-Rule (CoR), which guides LLM to follow distilled rules, and (2) training a rule-augmented LLM evaluator (RuAE) via reinforcement learning, further bridging the gap between rules and LLMs' reasoning. Extensive experiments on diverse tasks demonstrate the effectiveness and generalizability of our approach across various evaluation scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01958v1",
    "published_date": "2025-12-01 18:08:45 UTC",
    "updated_date": "2025-12-01 18:08:45 UTC"
  },
  {
    "arxiv_id": "2512.01952v1",
    "title": "GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment",
    "authors": [
      "Haoyang He",
      "Jay Patrikar",
      "Dong-Ki Kim",
      "Max Smith",
      "Daniel McGann",
      "Ali-akbar Agha-mohammadi",
      "Shayegan Omidshafiei",
      "Sebastian Scherer"
    ],
    "abstract": "Recent advances in video world modeling have enabled large-scale generative models to simulate embodied environments with high visual fidelity, providing strong priors for prediction, planning, and control. Yet, despite their realism, these models often lack geometric grounding, limiting their use in navigation tasks that require spatial coherence and long-horizon stability. We introduce Reinforcement Learning with World Grounding (RLWG), a self-supervised post-training framework that aligns pretrained world models with a physically verifiable structure through geometric and perceptual rewards. Analogous to reinforcement learning from verifiable feedback (RLVR) in language models, RLWG can use multiple rewards that measure pose cycle-consistency, depth reprojection, and temporal coherence. We instantiate this framework with GrndCtrl, a reward-aligned adaptation method based on Group Relative Policy Optimization (GRPO), yielding world models that maintain stable trajectories, consistent geometry, and reliable rollouts for embodied navigation. Like post-training alignment in large language models, GrndCtrl leverages verifiable rewards to bridge generative pretraining and grounded behavior, achieving superior spatial coherence and navigation stability over supervised fine-tuning in outdoor environments.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01952v1",
    "published_date": "2025-12-01 18:03:29 UTC",
    "updated_date": "2025-12-01 18:03:29 UTC"
  },
  {
    "arxiv_id": "2512.01945v1",
    "title": "Agentic Policy Optimization via Instruction-Policy Co-Evolution",
    "authors": [
      "Han Zhou",
      "Xingchen Wan",
      "Ivan Vuli",
      "Anna Korhonen"
    ],
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has advanced the reasoning capability of large language models (LLMs), enabling autonomous agents that can conduct effective multi-turn and tool-integrated reasoning. While instructions serve as the primary protocol for defining agents, RLVR typically relies on static and manually designed instructions. However, those instructions may be suboptimal for the base model, and the optimal instruction may change as the agent's policy improves and explores the interaction with the environment. To bridge the gap, we introduce INSPO, a novel Instruction-Policy co-evolution framework that integrates instruction optimization as a dynamic component of the reinforcement learning (RL) loop. INSPO maintains a dynamic population of instruction candidates that are sampled with questions, where reward signals in RL loops are automatically attributed to each instruction, and low performers are periodically pruned. New instructions are generated and verified through an on-policy reflection mechanism, where an LLM-based optimizer analyzes past experience from a replay buffer and evolves more effective strategies given the current policy. We conduct extensive experiments on multi-turn retrieval and reasoning tasks, demonstrating that INSPO substantially outperforms strong baselines relying on static instructions. INSPO discovers innovative instructions that guide the agent toward more strategic reasoning paths, achieving substantial performance gains with only a marginal increase in computational overhead.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 3 figures, 2 tables (18 pages including references and appendices)",
    "pdf_url": "https://arxiv.org/pdf/2512.01945v1",
    "published_date": "2025-12-01 17:56:29 UTC",
    "updated_date": "2025-12-01 17:56:29 UTC"
  },
  {
    "arxiv_id": "2512.01939v1",
    "title": "An Empirical Study of Agent Developer Practices in AI Agent Frameworks",
    "authors": [
      "Yanlin Wang",
      "Xinyi Xu",
      "Jiachi Chen",
      "Tingting Bi",
      "Wenchao Gu",
      "Zibin Zheng"
    ],
    "abstract": "The rise of large language models (LLMs) has sparked a surge of interest in agents, leading to the rapid growth of agent frameworks. Agent frameworks are software toolkits and libraries that provide standardized components, abstractions, and orchestration mechanisms to simplify agent development. Despite widespread use of agent frameworks, their practical applications and how they influence the agent development process remain underexplored. Different agent frameworks encounter similar problems during use, indicating that these recurring issues deserve greater attention and call for further improvements in agent framework design. Meanwhile, as the number of agent frameworks continues to grow and evolve, more than 80% of developers report difficulties in identifying the frameworks that best meet their specific development requirements. In this paper, we conduct the first empirical study of LLM-based agent frameworks, exploring real-world experiences of developers in building AI agents. To compare how well the agent frameworks meet developer needs, we further collect developer discussions for the ten previously identified agent frameworks, resulting in a total of 11,910 discussions. Finally, by analyzing these discussions, we compare the frameworks across five dimensions: development efficiency, functional abstraction, learning cost, performance optimization, and maintainability, which refers to how easily developers can update and extend both the framework itself and the agents built upon it over time. Our comparative analysis reveals significant differences among frameworks in how they meet the needs of agent developers. Overall, we provide a set of findings and implications for the LLM-driven AI agent framework ecosystem and offer insights for the design of future LLM-based agent frameworks and agent developers.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01939v1",
    "published_date": "2025-12-01 17:52:15 UTC",
    "updated_date": "2025-12-01 17:52:15 UTC"
  },
  {
    "arxiv_id": "2512.01930v1",
    "title": "SVRG and Beyond via Posterior Correction",
    "authors": [
      "Nico Daheim",
      "Thomas Mllenhoff",
      "Ming Liang Ang",
      "Mohammad Emtiyaz Khan"
    ],
    "abstract": "Stochastic Variance Reduced Gradient (SVRG) and its variants aim to speed-up training by using gradient corrections, but have seen limited success in deep learning. Here, we show surprising new foundational connections of SVRG to a recently proposed Bayesian method called posterior correction. Specifically, we show that SVRG is recovered as a special case of posterior correction over the isotropic-Gaussian family, while novel extensions are automatically obtained by using more flexible exponential families. We derive two new SVRG variants by using Gaussian families: First, a Newton-like variant that employs novel Hessian corrections, and second, an Adam-like extension that improves pretraining and finetuning of Transformer language models. This is the first work to connect SVRG to Bayes and use it to boost variational training for deep networks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint. Under review",
    "pdf_url": "https://arxiv.org/pdf/2512.01930v1",
    "published_date": "2025-12-01 17:45:30 UTC",
    "updated_date": "2025-12-01 17:45:30 UTC"
  },
  {
    "arxiv_id": "2512.01925v1",
    "title": "Rectifying LLM Thought from Lens of Optimization",
    "authors": [
      "Junnan Liu",
      "Hongwei Liu",
      "Songyang Zhang",
      "Kai Chen"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have been driven by their emergent reasoning capabilities, particularly through long chain-of-thought (CoT) prompting, which enables thorough exploration and deliberation. Despite these advances, long-CoT LLMs often exhibit suboptimal reasoning behaviors, such as overthinking and excessively protracted reasoning chains, which can impair performance. In this paper, we analyze reasoning processes through an optimization lens, framing CoT as a gradient descent procedure where each reasoning step constitutes an update toward problem resolution. Building on this perspective, we introduce RePro (Rectifying Process-level Reward), a novel approach to refine LLM reasoning during post-training. RePro defines a surrogate objective function to assess the optimization process underlying CoT, utilizing a dual scoring mechanism to quantify its intensity and stability. These scores are aggregated into a composite process-level reward, seamlessly integrated into reinforcement learning with verifiable rewards (RLVR) pipelines to optimize LLMs. Extensive experiments across multiple reinforcement learning algorithms and diverse LLMs, evaluated on benchmarks spanning mathematics, science, and coding, demonstrate that RePro consistently enhances reasoning performance and mitigates suboptimal reasoning behaviors.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "https://arxiv.org/pdf/2512.01925v1",
    "published_date": "2025-12-01 17:41:08 UTC",
    "updated_date": "2025-12-01 17:41:08 UTC"
  },
  {
    "arxiv_id": "2512.01924v1",
    "title": "Real-World Robot Control by Deep Active Inference With a Temporally Hierarchical World Model",
    "authors": [
      "Kentaro Fujii",
      "Shingo Murata"
    ],
    "abstract": "Robots in uncertain real-world environments must perform both goal-directed and exploratory actions. However, most deep learning-based control methods neglect exploration and struggle under uncertainty. To address this, we adopt deep active inference, a framework that accounts for human goal-directed and exploratory actions. Yet, conventional deep active inference approaches face challenges due to limited environmental representation capacity and high computational cost in action selection. We propose a novel deep active inference framework that consists of a world model, an action model, and an abstract world model. The world model encodes environmental dynamics into hidden state representations at slow and fast timescales. The action model compresses action sequences into abstract actions using vector quantization, and the abstract world model predicts future slow states conditioned on the abstract action, enabling low-cost action selection. We evaluate the framework on object-manipulation tasks with a real-world robot. Results show that it achieves high success rates across diverse manipulation tasks and switches between goal-directed and exploratory actions in uncertain settings, while making action selection computationally tractable. These findings highlight the importance of modeling multiple timescale dynamics and abstracting actions and state transitions.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted for publication in IEEE Robotics and Automation Letters (RA-L)",
    "pdf_url": "https://arxiv.org/pdf/2512.01924v1",
    "published_date": "2025-12-01 17:41:01 UTC",
    "updated_date": "2025-12-01 17:41:01 UTC"
  },
  {
    "arxiv_id": "2512.01892v1",
    "title": "Exploring Human Perceptions of AI Responses: Insights from a Mixed-Methods Study on Risk Mitigation in Generative Models",
    "authors": [
      "Heloisa Candello",
      "Muneeza Azmat",
      "Uma Sushmitha Gunturi",
      "Raya Horesh",
      "Rogerio Abreu de Paula",
      "Heloisa Pimentel",
      "Marcelo Carpinette Grave",
      "Aminat Adebiyi",
      "Tiago Machado",
      "Maysa Malfiza Garcia de Macedo"
    ],
    "abstract": "With the rapid uptake of generative AI, investigating human perceptions of generated responses has become crucial. A major challenge is their `aptitude' for hallucinating and generating harmful contents. Despite major efforts for implementing guardrails, human perceptions of these mitigation strategies are largely unknown. We conducted a mixed-method experiment for evaluating the responses of a mitigation strategy across multiple-dimensions: faithfulness, fairness, harm-removal capacity, and relevance. In a within-subject study design, 57 participants assessed the responses under two conditions: harmful response plus its mitigation and solely mitigated response. Results revealed that participants' native language, AI work experience, and annotation familiarity significantly influenced evaluations. Participants showed high sensitivity to linguistic and contextual attributes, penalizing minor grammar errors while rewarding preserved semantic contexts. This contrasts with how language is often treated in the quantitative evaluation of LLMs. We also introduced new metrics for training and evaluating mitigation strategies and insights for human-AI evaluation studies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 2 figures, 6 tables. Under review for publication",
    "pdf_url": "https://arxiv.org/pdf/2512.01892v1",
    "published_date": "2025-12-01 17:12:28 UTC",
    "updated_date": "2025-12-01 17:12:28 UTC"
  },
  {
    "arxiv_id": "2512.01881v2",
    "title": "Unifying Sign and Magnitude for Optimizing Deep Vision Networks via ThermoLion",
    "authors": [
      "Ahmed Nebli"
    ],
    "abstract": "The training of deep vision models is fundamentally a signal recovery problem amidst high-dimensional stochastic noise. Current optimization paradigms impose a static compromise on information channel capacity. For instance, magnitude-based methods, such as AdamW, operate on the assumption that gradient norms are high-fidelity curvature signals. While this allows for precision in smooth regimes, it leads to catastrophic noise amplification when applied to rugged, non-convex landscapes. Conversely, sign-based methods (e.g., Lion) perform a radical 1-bit quantization of the gradient, which aims to provide robust regularization at the cost of discarding fine-grained descent information. We propose that optimal convergence requires neither static prior, but rather a dynamic modulation of the update bitrate. We introduce ThermoLion, a vision-centric framework that utilizes local Signal-to-Noise Ratio (SNR) gating to autonomously transition parameters between a \"low-bit\" exploration phase and a \"high-precision\" exploitation phase. Furthermore, we introduce a Momentum Alignment mechanism that detects constructive interference between historical drift and instantaneous gradients to accelerate convergence during stable trajectories. Empirical benchmarks across 12 diverse vision datasets (including CIFAR, SVHN, and GTSRB) demonstrate that ThermoLion surpasses state-of-the-art optimizers, such as AdamW and Lion, in convergence speed and terminal accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01881v2",
    "published_date": "2025-12-01 17:04:17 UTC",
    "updated_date": "2025-12-02 10:04:52 UTC"
  },
  {
    "arxiv_id": "2512.01880v1",
    "title": "Predicting Human Chess Moves: An AI Assisted Analysis of Chess Games Using Skill-group Specific n-gram Language Models",
    "authors": [
      "Daren Zhong",
      "Dingcheng Huang",
      "Clayton Greenberg"
    ],
    "abstract": "Chess, a deterministic game with perfect information, has long served as a benchmark for studying strategic decision-making and artificial intelligence. Traditional chess engines or tools for analysis primarily focus on calculating optimal moves, often neglecting the variability inherent in human chess playing, particularly across different skill levels.\n  To overcome this limitation, we propose a novel and computationally efficient move prediction framework that approaches chess move prediction as a behavioral analysis task. The framework employs n-gram language models to capture move patterns characteristic of specific player skill levels. By dividing players into seven distinct skill groups, from novice to expert, we trained separate models using data from the open-source chess platform Lichess. The framework dynamically selects the most suitable model for prediction tasks and generates player moves based on preceding sequences.\n  Evaluation on real-world game data demonstrates that the model selector module within the framework can classify skill levels with an accuracy of up to 31.7\\% when utilizing early game information (16 half-moves). The move prediction framework also shows substantial accuracy improvements, with our Selector Assisted Accuracy being up to 39.1\\% more accurate than our benchmark accuracy. The computational efficiency of the framework further enhances its suitability for real-time chess analysis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01880v1",
    "published_date": "2025-12-01 17:02:07 UTC",
    "updated_date": "2025-12-01 17:02:07 UTC"
  },
  {
    "arxiv_id": "2512.01878v1",
    "title": "Graph Distance as Surprise: Free Energy Minimization in Knowledge Graph Reasoning",
    "authors": [
      "Gaganpreet Jhajj",
      "Fuhua Lin"
    ],
    "abstract": "In this work, we propose that reasoning in knowledge graph (KG) networks can be guided by surprise minimization. Entities that are close in graph distance will have lower surprise than those farther apart. This connects the Free Energy Principle (FEP) from neuroscience to KG systems, where the KG serves as the agent's generative model. We formalize surprise using the shortest-path distance in directed graphs and provide a framework for KG-based agents. Graph distance appears in graph neural networks as message passing depth and in model-based reinforcement learning as world model trajectories. This work-in-progress study explores whether distance-based surprise can extend recent work showing that syntax minimizes surprise and free energy via tree structures.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to NORA Workshop at NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.01878v1",
    "published_date": "2025-12-01 16:59:28 UTC",
    "updated_date": "2025-12-01 16:59:28 UTC"
  },
  {
    "arxiv_id": "2512.01870v1",
    "title": "Testing Transformer Learnability on the Arithmetic Sequence of Rooted Trees",
    "authors": [
      "Alessandro Breccia",
      "Federica Gerace",
      "Marco Lippi",
      "Gabriele Sicuro",
      "Pierluigi Contucci"
    ],
    "abstract": "We study whether a Large Language Model can learn the deterministic sequence of trees generated by the iterated prime factorization of the natural numbers. Each integer is mapped into a rooted planar tree and the resulting sequence $ \\mathbb{N}\\mathcal{T}$ defines an arithmetic text with measurable statistical structure. A transformer network (the GPT-2 architecture) is trained from scratch on the first $10^{11}$ elements to subsequently test its predictive ability under next-word and masked-word prediction tasks. Our results show that the model partially learns the internal grammar of $\\mathbb{N}\\mathcal{T}$, capturing non-trivial regularities and correlations. This suggests that learnability may extend beyond empirical data to the very structure of arithmetic.",
    "categories": [
      "cs.AI",
      "cond-mat.dis-nn",
      "math-ph",
      "math.NT"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.01870v1",
    "published_date": "2025-12-01 16:51:38 UTC",
    "updated_date": "2025-12-01 16:51:38 UTC"
  },
  {
    "arxiv_id": "2512.01865v1",
    "title": "Cross-Lingual Interleaving for Speech Language Models",
    "authors": [
      "Adel Moumen",
      "Guangzhi Sun",
      "Philip C. Woodland"
    ],
    "abstract": "Spoken Language Models (SLMs) aim to learn linguistic competence directly from speech using discrete units, widening access to Natural Language Processing (NLP) technologies for languages with limited written resources. However, progress has been largely English-centric due to scarce spoken evaluation benchmarks and training data, making cross-lingual learning difficult. We present a cross-lingual interleaving method that mixes speech tokens across languages without textual supervision. We also release an EN-FR training dataset, TinyStories (~42k hours), together with EN-FR spoken StoryCloze and TopicCloze benchmarks for cross-lingual semantic evaluation, both synthetically generated using GPT-4. On 360M and 1B SLMs under matched training-token budgets, interleaving improves monolingual semantic accuracy, enables robust cross-lingual continuation, and strengthens cross-lingual hidden-state alignment. Taken together, these results indicate that cross-lingual interleaving is a simple, scalable route to building multilingual SLMs that understand and converse across languages. All resources will be made open-source to support reproducibility.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01865v1",
    "published_date": "2025-12-01 16:48:05 UTC",
    "updated_date": "2025-12-01 16:48:05 UTC"
  },
  {
    "arxiv_id": "2512.01863v1",
    "title": "Topological Order in Deep State",
    "authors": [
      "Ahmed Abouelkomsan",
      "Max Geier",
      "Liang Fu"
    ],
    "abstract": "Topologically ordered states are among the most interesting quantum phases of matter that host emergent quasi-particles having fractional charge and obeying fractional quantum statistics. Theoretical study of such states is however challenging owing to their strong-coupling nature that prevents conventional mean-field treatment. Here, we demonstrate that an attention-based deep neural network provides an expressive variational wavefunction that discovers fractional Chern insulator ground states purely through energy minimization without prior knowledge and achieves remarkable accuracy. We introduce an efficient method to extract ground state topological degeneracy -- a hallmark of topological order -- from a single optimized real-space wavefunction in translation-invariant systems by decomposing it into different many-body momentum sectors. Our results establish neural network variational Monte Carlo as a versatile tool for discovering strongly correlated topological phases.",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.str-el",
      "cs.AI"
    ],
    "primary_category": "cond-mat.mes-hall",
    "comment": "5 pages + 6 SM",
    "pdf_url": "https://arxiv.org/pdf/2512.01863v1",
    "published_date": "2025-12-01 16:46:39 UTC",
    "updated_date": "2025-12-01 16:46:39 UTC"
  },
  {
    "arxiv_id": "2512.01852v1",
    "title": "BHRAM-IL: A Benchmark for Hallucination Recognition and Assessment in Multiple Indian Languages",
    "authors": [
      "Hrishikesh Terdalkar",
      "Kirtan Bhojani",
      "Aryan Dongare",
      "Omm Aditya Behera"
    ],
    "abstract": "Large language models (LLMs) are increasingly deployed in multilingual applications but often generate plausible yet incorrect or misleading outputs, known as hallucinations. While hallucination detection has been studied extensively in English, under-resourced Indian languages remain largely unexplored. We present BHRAM-IL, a benchmark for hallucination recognition and assessment in multiple Indian languages, covering Hindi, Gujarati, Marathi, Odia, along with English. The benchmark comprises 36,047 curated questions across nine categories spanning factual, numerical, reasoning, and linguistic tasks. We evaluate 14 state-of-the-art multilingual LLMs on a benchmark subset of 10,265 questions, analyzing cross-lingual and factual hallucinations across languages, models, scales, categories, and domains using category-specific metrics normalized to (0,1) range. Aggregation over all categories and models yields a primary score of 0.23 and a language-corrected fuzzy score of 0.385, demonstrating the usefulness of BHRAM-IL for hallucination-focused evaluation. The dataset, and the code for generation and evaluation are available on GitHub (https://github.com/sambhashana/BHRAM-IL/) and HuggingFace (https://huggingface.co/datasets/sambhashana/BHRAM-IL/) to support future research in multilingual hallucination detection and mitigation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at BHASHA Workshop @ IJCNLP/AACL 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.01852v1",
    "published_date": "2025-12-01 16:37:34 UTC",
    "updated_date": "2025-12-01 16:37:34 UTC"
  },
  {
    "arxiv_id": "2512.03099v1",
    "title": "QGShap: Quantum Acceleration for Faithful GNN Explanations",
    "authors": [
      "Haribandhu Jena",
      "Jyotirmaya Shivottam",
      "Subhankar Mishra"
    ],
    "abstract": "Graph Neural Networks (GNNs) have become indispensable in critical domains such as drug discovery, social network analysis, and recommendation systems, yet their black-box nature hinders deployment in scenarios requiring transparency and accountability. While Shapley value-based methods offer mathematically principled explanations by quantifying each component's contribution to predictions, computing exact values requires evaluating $2^n$ coalitions (or aggregating over $n!$ permutations), which is intractable for real-world graphs. Existing approximation strategies sacrifice either fidelity or efficiency, limiting their practical utility. We introduce QGShap, a quantum computing approach that leverages amplitude amplification to achieve quadratic speedups in coalition evaluation while maintaining exact Shapley computation. Unlike classical sampling or surrogate methods, our approach provides fully faithful explanations without approximation trade-offs for tractable graph sizes. We conduct empirical evaluations on synthetic graph datasets, demonstrating that QGShap achieves consistently high fidelity and explanation accuracy, matching or exceeding the performance of classical methods across all evaluation metrics. These results collectively demonstrate that QGShap not only preserves exact Shapley faithfulness but also delivers interpretable, stable, and structurally consistent explanations that align with the underlying graph reasoning of GNNs. The implementation of QGShap is available at https://github.com/smlab-niser/qgshap.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "Accepted in the QC+AI Workshop at AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2512.03099v1",
    "published_date": "2025-12-01 16:19:15 UTC",
    "updated_date": "2025-12-01 16:19:15 UTC"
  },
  {
    "arxiv_id": "2512.01834v1",
    "title": "Mitigating Gender Bias in Depression Detection via Counterfactual Inference",
    "authors": [
      "Mingxuan Hu",
      "Hongbo Ma",
      "Xinlan Wu",
      "Ziqi Liu",
      "Jiaqi Liu",
      "Yangbin Chen"
    ],
    "abstract": "Audio-based depression detection models have demonstrated promising performance but often suffer from gender bias due to imbalanced training data. Epidemiological statistics show a higher prevalence of depression in females, leading models to learn spurious correlations between gender and depression. Consequently, models tend to over-diagnose female patients while underperforming on male patients, raising significant fairness concerns. To address this, we propose a novel Counterfactual Debiasing Framework grounded in causal inference. We construct a causal graph to model the decision-making process and identify gender bias as the direct causal effect of gender on the prediction. During inference, we employ counterfactual inference to estimate and subtract this direct effect, ensuring the model relies primarily on authentic acoustic pathological features. Extensive experiments on the DAIC-WOZ dataset using two advanced acoustic backbones demonstrate that our framework not only significantly reduces gender bias but also improves overall detection performance compared to existing debiasing strategies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01834v1",
    "published_date": "2025-12-01 16:14:20 UTC",
    "updated_date": "2025-12-01 16:14:20 UTC"
  },
  {
    "arxiv_id": "2512.01831v1",
    "title": "Deconstructing Generative Diversity: An Information Bottleneck Analysis of Discrete Latent Generative Models",
    "authors": [
      "Yudi Wu",
      "Wenhao Zhao",
      "Dianbo Liu"
    ],
    "abstract": "Generative diversity varies significantly across discrete latent generative models such as AR, MIM, and Diffusion. We propose a diagnostic framework, grounded in Information Bottleneck (IB) theory, to analyze the underlying strategies resolving this behavior. The framework models generation as a conflict between a 'Compression Pressure' - a drive to minimize overall codebook entropy - and a 'Diversity Pressure' - a drive to maximize conditional entropy given an input. We further decompose this diversity into two primary sources: 'Path Diversity', representing the choice of high-level generative strategies, and 'Execution Diversity', the randomness in executing a chosen strategy. To make this decomposition operational, we introduce three zero-shot, inference-time interventions that directly perturb the latent generative process and reveal how models allocate and express diversity. Application of this probe-based framework to representative AR, MIM, and Diffusion systems reveals three distinct strategies: \"Diversity-Prioritized\" (MIM), \"Compression-Prioritized\" (AR), and \"Decoupled\" (Diffusion). Our analysis provides a principled explanation for their behavioral differences and informs a novel inference-time diversity enhancement technique.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01831v1",
    "published_date": "2025-12-01 16:13:23 UTC",
    "updated_date": "2025-12-01 16:13:23 UTC"
  },
  {
    "arxiv_id": "2512.01822v1",
    "title": "InnoGym: Benchmarking the Innovation Potential of AI Agents",
    "authors": [
      "Jintian Zhang",
      "Kewei Xu",
      "Jingsheng Zheng",
      "Zhuoyun Yu",
      "Yuqi Zhu",
      "Yujie Luo",
      "Lanning Wei",
      "Shuofei Qiao",
      "Lun Du",
      "Da Zheng",
      "Shumin Deng",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "abstract": "LLMs and Agents have achieved impressive progress in code generation, mathematical reasoning, and scientific discovery. However, existing benchmarks primarily measure correctness, overlooking the diversity of methods behind solutions. True innovation depends not only on producing correct answers but also on the originality of the approach. We present InnoGym, the first benchmark and framework designed to systematically evaluate the innovation potential of AI agents. InnoGym introduces two complementary metrics: performance gain, which measures improvement over the best-known solutions, and novelty, which captures methodological differences from prior approaches. The benchmark includes 18 carefully curated tasks from real-world engineering and scientific domains, each standardized through resource filtering, evaluator validation, and solution collection. In addition, we provide iGym, a unified execution environment for reproducible and long-horizon evaluations. Extensive experiments show that while some agents produce novel approaches, their lack of robustness limits performance gains. These results highlight a key gap between creativity and effectiveness, underscoring the need for benchmarks that evaluate both.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "https://arxiv.org/pdf/2512.01822v1",
    "published_date": "2025-12-01 16:03:04 UTC",
    "updated_date": "2025-12-01 16:03:04 UTC"
  },
  {
    "arxiv_id": "2512.01816v1",
    "title": "Envision: Benchmarking Unified Understanding & Generation for Causal World Process Insights",
    "authors": [
      "Juanxi Tian",
      "Siyuan Li",
      "Conghui He",
      "Lijun Wu",
      "Cheng Tan"
    ],
    "abstract": "Current multimodal models aim to transcend the limitations of single-modality representations by unifying understanding and generation, often using text-to-image (T2I) tasks to calibrate semantic consistency. However, their reliance on static, single-image generation in training and evaluation leads to overfitting to static pattern matching and semantic fusion, while fundamentally hindering their ability to model dynamic processes that unfold over time. To address these constraints, we propose Envision-a causal event progression benchmark for chained text-to-multi-image generation. Grounded in world knowledge and structured by spatiotemporal causality, it reorganizes existing evaluation dimensions and includes 1,000 four-stage prompts spanning six scientific and humanities domains. To transition evaluation from single images to sequential frames and assess whether models truly internalize world knowledge while adhering to causal-temporal constraints, we introduce Envision-Score, a holistic metric integrating multi-dimensional consistency, physicality, and aesthetics. Comprehensive evaluation of 15 models (10 specialized T2I models, 5 unified models) uncovers: specialized T2I models demonstrate proficiency in aesthetic rendering yet lack intrinsic world knowledge. Unified multimodal models bridge this gap, consistently outperforming specialized counterparts in causal narrative coherence. However, even these unified architectures remain subordinate to closed-source models and struggle to overcome the core challenge of spatiotemporal consistency. This demonstrates that a focus on causally-isolated single images impedes multi-frame reasoning and generation, promoting static pattern matching over dynamic world modeling-ultimately limiting world knowledge internalization, generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "35 pages, 12 figures, 10 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.01816v1",
    "published_date": "2025-12-01 15:52:31 UTC",
    "updated_date": "2025-12-01 15:52:31 UTC"
  },
  {
    "arxiv_id": "2512.01797v2",
    "title": "H-Neurons: On the Existence, Impact, and Origin of Hallucination-Associated Neurons in LLMs",
    "authors": [
      "Cheng Gao",
      "Huimin Chen",
      "Chaojun Xiao",
      "Zhiyi Chen",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "abstract": "Large language models (LLMs) frequently generate hallucinations -- plausible but factually incorrect outputs -- undermining their reliability. While prior work has examined hallucinations from macroscopic perspectives such as training data and objectives, the underlying neuron-level mechanisms remain largely unexplored. In this paper, we conduct a systematic investigation into hallucination-associated neurons (H-Neurons) in LLMs from three perspectives: identification, behavioral impact, and origins. Regarding their identification, we demonstrate that a remarkably sparse subset of neurons (less than $0.1\\%$ of total neurons) can reliably predict hallucination occurrences, with strong generalization across diverse scenarios. In terms of behavioral impact, controlled interventions reveal that these neurons are causally linked to over-compliance behaviors. Concerning their origins, we trace these neurons back to the pre-trained base models and find that these neurons remain predictive for hallucination detection, indicating they emerge during pre-training. Our findings bridge macroscopic behavioral patterns with microscopic neural mechanisms, offering insights for developing more reliable LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.01797v2",
    "published_date": "2025-12-01 15:32:14 UTC",
    "updated_date": "2025-12-02 07:08:39 UTC"
  },
  {
    "arxiv_id": "2512.01786v1",
    "title": "Who Judges the Judge? LLM Jury-on-Demand: Building Trustworthy LLM Evaluation Systems",
    "authors": [
      "Xiaochuan Li",
      "Ke Wang",
      "Girija Gouda",
      "Shubham Choudhary",
      "Yaqun Wang",
      "Linwei Hu",
      "Joel Vaughan",
      "Freddy Lecue"
    ],
    "abstract": "As Large Language Models (LLMs) become integrated into high-stakes domains, there is a growing need for evaluation methods that are both scalable for real-time deployment and reliable for critical decision-making. While human evaluation is reliable, it is slow and costly. Single LLM judges are biased, and static juries lack adaptability. To overcome these limitations, we propose LLM Jury-on-Demand - a dynamic, learning-based framework for scalable and context-aware evaluation. Our method trains a set of reliability predictors to assess when LLM judges will agree with human experts, leveraging token distributions, embeddings, and structural input features. This enables a fully adaptive evaluation where, for each data point, an optimal jury of the most reliable judges is dynamically selected, and their scores are aggregated using their reliability as weights. Experiments on summarization and RAG benchmarks show that our dynamic jury system achieves significantly higher correlation with human judgment than both single-judge and static-jury baselines. These results highlight the promise of adaptive, learning-based juries for building scalable, more reliable and trustworthy evaluation systems for modern LLMs in high-stakes domains.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "66 pages, 22 figures, 37 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.01786v1",
    "published_date": "2025-12-01 15:26:20 UTC",
    "updated_date": "2025-12-01 15:26:20 UTC"
  },
  {
    "arxiv_id": "2512.01782v1",
    "title": "Dual Randomized Smoothing: Beyond Global Noise Variance",
    "authors": [
      "Chenhao Sun",
      "Yuhao Mao",
      "Martin Vechev"
    ],
    "abstract": "Randomized Smoothing (RS) is a prominent technique for certifying the robustness of neural networks against adversarial perturbations. With RS, achieving high accuracy at small radii requires a small noise variance, while achieving high accuracy at large radii requires a large noise variance. However, the global noise variance used in the standard RS formulation leads to a fundamental limitation: there exists no global noise variance that simultaneously achieves strong performance at both small and large radii. To break through the global variance limitation, we propose a dual RS framework which enables input-dependent noise variances. To achieve that, we first prove that RS remains valid with input-dependent noise variances, provided the variance is locally constant around each input. Building on this result, we introduce two components which form our dual RS framework: (i) a variance estimator first predicts an optimal noise variance for each input, (ii) this estimated variance is then used by a standard RS classifier. The variance estimator is independently smoothed via RS to ensure local constancy, enabling flexible design. We also introduce training strategies to iteratively optimize the two components. Extensive experiments on CIFAR-10 show that our dual RS method provides strong performance for both small and large radii-unattainable with global noise variance-while incurring only a 60% computational overhead at inference. Moreover, it consistently outperforms prior input-dependent noise approaches across most radii, with particularly large gains at radii 0.5, 0.75, and 1.0, achieving relative improvements of 19%, 24%, and 21%, respectively. On ImageNet, dual RS remains effective across all radii. Additionally, the dual RS framework naturally provides a routing perspective for certified robustness, improving the accuracy-robustness trade-off with off-the-shelf expert RS models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01782v1",
    "published_date": "2025-12-01 15:23:00 UTC",
    "updated_date": "2025-12-01 15:23:00 UTC"
  },
  {
    "arxiv_id": "2512.01759v1",
    "title": "Weight Space Representation Learning with Neural Fields",
    "authors": [
      "Zhuoqian Yang",
      "Mathieu Salzmann",
      "Sabine Ssstrunk"
    ],
    "abstract": "In this work, we investigate the potential of weights to serve as effective representations, focusing on neural fields. Our key insight is that constraining the optimization space through a pre-trained base model and low-rank adaptation (LoRA) can induce structure in weight space. Across reconstruction, generation, and analysis tasks on 2D and 3D data, we find that multiplicative LoRA weights achieve high representation quality while exhibiting distinctiveness and semantic structure. When used with latent diffusion models, multiplicative LoRA weights enable higher-quality generation than existing weight-space methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages body, 9 pages appendix",
    "pdf_url": "https://arxiv.org/pdf/2512.01759v1",
    "published_date": "2025-12-01 15:05:01 UTC",
    "updated_date": "2025-12-01 15:05:01 UTC"
  },
  {
    "arxiv_id": "2512.01723v1",
    "title": "Probabilistic Neuro-Symbolic Reasoning for Sparse Historical Data: A Framework Integrating Bayesian Inference, Causal Models, and Game-Theoretic Allocation",
    "authors": [
      "Saba Kublashvili"
    ],
    "abstract": "Modeling historical events poses fundamental challenges for machine learning: extreme data scarcity (N << 100), heterogeneous and noisy measurements, missing counterfactuals, and the requirement for human interpretable explanations. We present HistoricalML, a probabilistic neuro-symbolic framework that addresses these challenges through principled integration of (1) Bayesian uncertainty quantification to separate epistemic from aleatoric uncertainty, (2) structural causal models for counterfactual reasoning under confounding, (3) cooperative game theory (Shapley values) for fair allocation modeling, and (4) attention based neural architectures for context dependent factor weighting. We provide theoretical analysis showing that our approach achieves consistent estimation in the sparse data regime when strong priors from domain knowledge are available, and that Shapley based allocation satisfies axiomatic fairness guarantees that pure regression approaches cannot provide. We instantiate the framework on two historical case studies: the 19th century partition of Africa (N = 7 colonial powers) and the Second Punic War (N = 2 factions). Our model identifies Germany's +107.9 percent discrepancy as a quantifiable structural tension preceding World War I, with tension factor 36.43 and 0.79 naval arms race correlation. For the Punic Wars, Monte Carlo battle simulations achieve a 57.3 percent win probability for Carthage at Cannae and 57.8 percent for Rome at Zama, aligning with historical outcomes. Counterfactual analysis reveals that Carthaginian political support (support score 6.4 vs Napoleon's 7.1), rather than military capability, was the decisive factor.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "math.PR"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint. Code and simulation notebooks available at the GitHub repository: https://github.com/Saba-Kublashvili/bayesian-computational-modeling.-",
    "pdf_url": "https://arxiv.org/pdf/2512.01723v1",
    "published_date": "2025-12-01 14:35:04 UTC",
    "updated_date": "2025-12-01 14:35:04 UTC"
  },
  {
    "arxiv_id": "2512.01707v1",
    "title": "StreamGaze: Gaze-Guided Temporal Reasoning and Proactive Understanding in Streaming Videos",
    "authors": [
      "Daeun Lee",
      "Subhojyoti Mukherjee",
      "Branislav Kveton",
      "Ryan A. Rossi",
      "Viet Dac Lai",
      "Seunghyun Yoon",
      "Trung Bui",
      "Franck Dernoncourt",
      "Mohit Bansal"
    ],
    "abstract": "Streaming video understanding requires models not only to process temporally incoming frames, but also to anticipate user intention for realistic applications like AR glasses. While prior streaming benchmarks evaluate temporal reasoning, none measure whether MLLMs can interpret or leverage human gaze signals within a streaming setting. To fill this gap, we introduce StreamGaze, the first benchmark designed to evaluate how effectively MLLMs use gaze for temporal and proactive reasoning in streaming videos. StreamGaze introduces gaze-guided past, present, and proactive tasks that comprehensively evaluate streaming video understanding. These tasks assess whether models can use real-time gaze to follow shifting attention and infer user intentions from only past and currently observed frames. To build StreamGaze, we develop a gaze-video QA generation pipeline that aligns egocentric videos with raw gaze trajectories via fixation extraction, region-specific visual prompting, and scanpath construction. This pipeline produces spatio-temporally grounded QA pairs that closely reflect human perceptual dynamics. Across all StreamGaze tasks, we observe substantial performance gaps between state-of-the-art MLLMs and human performance, revealing fundamental limitations in gaze-based temporal reasoning, intention modeling, and proactive prediction. We further provide detailed analyses of gaze-prompting strategies, reasoning behaviors, and task-specific failure modes, offering deeper insight into why current MLLMs struggle and what capabilities future models must develop. All data and code will be publicly released to support continued research in gaze-guided streaming video understanding.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://streamgaze.github.io/",
    "pdf_url": "https://arxiv.org/pdf/2512.01707v1",
    "published_date": "2025-12-01 14:15:44 UTC",
    "updated_date": "2025-12-01 14:15:44 UTC"
  },
  {
    "arxiv_id": "2512.02088v1",
    "title": "Comparing Baseline and Day-1 Diffusion MRI Using Multimodal Deep Embeddings for Stroke Outcome Prediction",
    "authors": [
      "Sina Raeisadigh",
      "Myles Joshua Toledo Tan",
      "Henning Mller",
      "Abderrahmane Hedjoudje"
    ],
    "abstract": "This study compares baseline (J0) and 24-hour (J1) diffusion magnetic resonance imaging (MRI) for predicting three-month functional outcomes after acute ischemic stroke (AIS). Seventy-four AIS patients with paired apparent diffusion coefficient (ADC) scans and clinical data were analyzed. Three-dimensional ResNet-50 embeddings were fused with structured clinical variables, reduced via principal component analysis (<=12 components), and classified using linear support vector machines with eight-fold stratified group cross-validation. J1 multimodal models achieved the highest predictive performance (AUC = 0.923 +/- 0.085), outperforming J0-based configurations (AUC <= 0.86). Incorporating lesion-volume features further improved model stability and interpretability. These findings demonstrate that early post-treatment diffusion MRI provides superior prognostic value to pre-treatment imaging and that combining MRI, clinical, and lesion-volume features produces a robust and interpretable framework for predicting three-month functional outcomes in AIS patients.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "5 pages, 5 figures, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.02088v1",
    "published_date": "2025-12-01 13:56:44 UTC",
    "updated_date": "2025-12-01 13:56:44 UTC"
  },
  {
    "arxiv_id": "2512.01672v1",
    "title": "ICAD-LLM: One-for-All Anomaly Detection via In-Context Learning with Large Language Models",
    "authors": [
      "Zhongyuan Wu",
      "Jingyuan Wang",
      "Zexuan Cheng",
      "Yilong Zhou",
      "Weizhi Wang",
      "Juhua Pu",
      "Chao Li",
      "Changqing Ma"
    ],
    "abstract": "Anomaly detection (AD) is a fundamental task of critical importance across numerous domains. Current systems increasingly operate in rapidly evolving environments that generate diverse yet interconnected data modalities -- such as time series, system logs, and tabular records -- as exemplified by modern IT systems. Effective AD methods in such environments must therefore possess two critical capabilities: (1) the ability to handle heterogeneous data formats within a unified framework, allowing the model to process and detect multiple modalities in a consistent manner during anomalous events; (2) a strong generalization ability to quickly adapt to new scenarios without extensive retraining. However, most existing methods fall short of these requirements, as they typically focus on single modalities and lack the flexibility to generalize across domains. To address this gap, we introduce a novel paradigm: In-Context Anomaly Detection (ICAD), where anomalies are defined by their dissimilarity to a relevant reference set of normal samples. Under this paradigm, we propose ICAD-LLM, a unified AD framework leveraging Large Language Models' in-context learning abilities to process heterogeneous data within a single model. Extensive experiments demonstrate that ICAD-LLM achieves competitive performance with task-specific AD methods and exhibits strong generalization to previously unseen tasks, which substantially reduces deployment costs and enables rapid adaptation to new environments. To the best of our knowledge, ICAD-LLM is the first model capable of handling anomaly detection tasks across diverse domains and modalities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01672v1",
    "published_date": "2025-12-01 13:41:30 UTC",
    "updated_date": "2025-12-01 13:41:30 UTC"
  },
  {
    "arxiv_id": "2601.14263v1",
    "title": "Call2Instruct: Automated Pipeline for Generating Q&A Datasets from Call Center Recordings for LLM Fine-Tuning",
    "authors": [
      "Alex Echeverria",
      "Svio Salvarino Teles de Oliveira",
      "Fernando Marques Federson"
    ],
    "abstract": "The adaptation of Large-Scale Language Models (LLMs) to specific domains depends on high-quality fine-tuning datasets, particularly in instructional format (e.g., Question-Answer - Q&A). However, generating these datasets, particularly from unstructured sources such as call center audio recordings, poses a significant challenge due to the noisy and disorganized nature of the data. This paper presents a solution to this challenge by offering an end-to-end automated pipeline for generating Q&A instructional datasets from such recordings. The methodology developed comprises sequential steps of audio processing (including diarization, noise removal and automatic transcription), textual processing (cleaning, normalization, and anonymization), semantic extraction of customer demands and attendant responses using vector embeddings, and matching via semantic search to form the final Q&A pairs. As a result, the complete pipeline was successfully implemented, generating a dataset specifically formatted for Instruct Fine Tuning. The practical value and feasibility of the generated dataset were substantiated and functionally demonstrated through the successful fine-tuning of an LLM model (based on Llama 2 7B). The conclusion of the paper states that the proposed approach is viable for converting unstructured conversational data from call centers into valuable resources for training LLMs. This development has the potential to open up avenues for creating more effective AI systems for Q&A tasks in the customer service domain. The developed codes have been made publicly available to promote reproducibility and future research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 1 figures, conference",
    "pdf_url": "https://arxiv.org/pdf/2601.14263v1",
    "published_date": "2025-12-01 13:39:54 UTC",
    "updated_date": "2025-12-01 13:39:54 UTC"
  },
  {
    "arxiv_id": "2512.01661v2",
    "title": "Learning the Boundary of Solvability: Aligning LLMs to Detect Unsolvable Problems",
    "authors": [
      "Dengyun Peng",
      "Qiguang Chen",
      "Bofei Liu",
      "Jiannan Guan",
      "Libo Qin",
      "Zheng Yan",
      "Jinhao Liu",
      "Jianshu Zhang",
      "Wanxiang Che"
    ],
    "abstract": "Ensuring large language model (LLM) reliability requires distinguishing objective unsolvability (inherent contradictions) from subjective capability limitations (tasks exceeding model competence). Current LLMs often conflate these dimensions, leading to hallucinations in which they return confident answers to inherently unsolvable queries. To address this issue, we propose a multi-domain dataset containing both solvable and unsolvable questions, UnsolvableQA, together with an alignment framework, UnsolvableRL. First, we construct UnsolvableQA by \"Reverse Construction\" that systematically injects logical contradictions into otherwise valid reasoning chains. Second, we introduce UnsolvableRL, a reinforcement learning paradigm that balances objective unsolvability detection with calibrated confidence under capability limits. Empirically, our approach achieves near-perfect unsolvability detection (>90% detection rate) and boosts solvable reasoning accuracy from 43.4% to 69.4% on Qwen3-4B-Instruct. Crucially, we identify a data-training interaction: strict alignment constraints induce Capability Collapse without unsolvable data, but act as a regularizer for rigor when such data are included, thereby improving overall robustness. Our code and data are available at https://github.com/sfasfaffa/unsolvableQA .",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint",
    "pdf_url": "https://arxiv.org/pdf/2512.01661v2",
    "published_date": "2025-12-01 13:32:59 UTC",
    "updated_date": "2026-01-02 04:15:52 UTC"
  },
  {
    "arxiv_id": "2512.01659v1",
    "title": "HalluGraph: Auditable Hallucination Detection for Legal RAG Systems via Knowledge Graph Alignment",
    "authors": [
      "Valentin Nol",
      "Elimane Yassine Seidou",
      "Charly Ken Capo-Chichi",
      "Ghanem Amari"
    ],
    "abstract": "Legal AI systems powered by retrieval-augmented generation (RAG) face a critical accountability challenge: when an AI assistant cites case law, statutes, or contractual clauses, practitioners need verifiable guarantees that generated text faithfully represents source documents. Existing hallucination detectors rely on semantic similarity metrics that tolerate entity substitutions, a dangerous failure mode when confusing parties, dates, or legal provisions can have material consequences. We introduce HalluGraph, a graph-theoretic framework that quantifies hallucinations through structural alignment between knowledge graphs extracted from context, query, and response. Our approach produces bounded, interpretable metrics decomposed into \\textit{Entity Grounding} (EG), measuring whether entities in the response appear in source documents, and \\textit{Relation Preservation} (RP), verifying that asserted relationships are supported by context. On structured control documents, HalluGraph achieves near-perfect discrimination ($>$400 words, $>$20 entities), HalluGraph achieves $AUC = 0.979$, while maintaining robust performance ($AUC \\approx 0.89$) on challenging generative legal task, consistently outperforming semantic similarity baselines. The framework provides the transparency and traceability required for high-stakes legal applications, enabling full audit trails from generated assertions back to source passages.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 4 figures, under review",
    "pdf_url": "https://arxiv.org/pdf/2512.01659v1",
    "published_date": "2025-12-01 13:31:06 UTC",
    "updated_date": "2025-12-01 13:31:06 UTC"
  },
  {
    "arxiv_id": "2512.04115v1",
    "title": "Artificial Intelligence Competence of K-12 Students Shapes Their AI Risk Perception: A Co-occurrence Network Analysis",
    "authors": [
      "Ville Heilala",
      "Pieta Sikstrm",
      "Mika Setl",
      "Tommi Krkkinen"
    ],
    "abstract": "As artificial intelligence (AI) becomes increasingly integrated into education, understanding how students perceive its risks is essential for supporting responsible and effective adoption. This research aimed to examine the relationships between perceived AI competence and risks among Finnish K-12 upper secondary students (n = 163) by utilizing a co-occurrence analysis. Students reported their self-perceived AI competence and concerns related to AI across systemic, institutional, and personal domains. The findings showed that students with lower competence emphasized personal and learning-related risks, such as reduced creativity, lack of critical thinking, and misuse, whereas higher-competence students focused more on systemic and institutional risks, including bias, inaccuracy, and cheating. These differences suggest that students' self-reported AI competence is related to how they evaluate both the risks and opportunities associated with artificial intelligence in education (AIED). The results of this study highlight the need for educational institutions to incorporate AI literacy into their curricula, provide teacher guidance, and inform policy development to ensure personalized opportunities for utilization and equitable integration of AI into K-12 education.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted for Proceedings of the 41th ACM/SIGAPP Symposium on Applied Computing (SAC'26)",
    "pdf_url": "https://arxiv.org/pdf/2512.04115v1",
    "published_date": "2025-12-01 12:40:24 UTC",
    "updated_date": "2025-12-01 12:40:24 UTC"
  },
  {
    "arxiv_id": "2512.01616v1",
    "title": "CLIP-RL: Aligning Language and Policy Representations for Task Transfer in Reinforcement Learning",
    "authors": [
      "Chainesh Gautam",
      "Raghuram Bharadwaj Diddigi"
    ],
    "abstract": "Recently, there has been an increasing need to develop agents capable of solving multiple tasks within the same environment, especially when these tasks are naturally associated with language. In this work, we propose a novel approach that leverages combinations of pre-trained (language, policy) pairs to establish an efficient transfer pipeline. Our algorithm is inspired by the principles of Contrastive Language-Image Pretraining (CLIP) in Computer Vision, which aligns representations across different modalities under the philosophy that ''two modalities representing the same concept should have similar representations.'' The central idea here is that the instruction and corresponding policy of a task represent the same concept, the task itself, in two different modalities. Therefore, by extending the idea of CLIP to RL, our method creates a unified representation space for natural language and policy embeddings. Experimental results demonstrate the utility of our algorithm in achieving faster transfer across tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "4 pages, 2 figures, accepted as a extended abstract at RLDM 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.01616v1",
    "published_date": "2025-12-01 12:37:01 UTC",
    "updated_date": "2025-12-01 12:37:01 UTC"
  },
  {
    "arxiv_id": "2512.01582v1",
    "title": "RoleMotion: A Large-Scale Dataset towards Robust Scene-Specific Role-Playing Motion Synthesis with Fine-grained Descriptions",
    "authors": [
      "Junran Peng",
      "Yiheng Huang",
      "Silei Shen",
      "Zeji Wei",
      "Jingwei Yang",
      "Baojie Wang",
      "Yonghao He",
      "Chuanchen Luo",
      "Man Zhang",
      "Xucheng Yin",
      "Wei Sui"
    ],
    "abstract": "In this paper, we introduce RoleMotion, a large-scale human motion dataset that encompasses a wealth of role-playing and functional motion data tailored to fit various specific scenes. Existing text datasets are mainly constructed decentrally as amalgamation of assorted subsets that their data are nonfunctional and isolated to work together to cover social activities in various scenes. Also, the quality of motion data is inconsistent, and textual annotation lacks fine-grained details in these datasets. In contrast, RoleMotion is meticulously designed and collected with a particular focus on scenes and roles. The dataset features 25 classic scenes, 110 functional roles, over 500 behaviors, and 10296 high-quality human motion sequences of body and hands, annotated with 27831 fine-grained text descriptions. We build an evaluator stronger than existing counterparts, prove its reliability, and evaluate various text-to-motion methods on our dataset. Finally, we explore the interplay of motion generation of body and hands. Experimental results demonstrate the high-quality and functionality of our dataset on text-driven whole-body generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01582v1",
    "published_date": "2025-12-01 11:59:03 UTC",
    "updated_date": "2025-12-01 11:59:03 UTC"
  },
  {
    "arxiv_id": "2512.01576v1",
    "title": "From Black Hole to Galaxy: Neural Operator: Framework for Accretion and Feedback Dynamics",
    "authors": [
      "Nihaal Bhojwani",
      "Chuwei Wang",
      "Hai-Yang Wang",
      "Chang Sun",
      "Elias R. Most",
      "Anima Anandkumar"
    ],
    "abstract": "Modeling how supermassive black holes co-evolve with their host galaxies is notoriously hard because the relevant physics spans nine orders of magnitude in scale-from milliparsecs to megaparsecs--making end-to-end first-principles simulation infeasible. To characterize the feedback from the small scales, existing methods employ a static subgrid scheme or one based on theoretical guesses, which usually struggle to capture the time variability and derive physically faithful results. Neural operators are a class of machine learning models that achieve significant speed-up in simulating complex dynamics. We introduce a neural-operator-based ''subgrid black hole'' that learns the small-scale local dynamics and embeds it within the direct multi-level simulations. Trained on small-domain (general relativistic) magnetohydrodynamic data, the model predicts the unresolved dynamics needed to supply boundary conditions and fluxes at coarser levels across timesteps, enabling stable long-horizon rollouts without hand-crafted closures. Thanks to the great speedup in fine-scale evolution, our approach for the first time captures intrinsic variability in accretion-driven feedback, allowing dynamic coupling between the central black hole and galaxy-scale gas. This work reframes subgrid modeling in computational astrophysics with scale separation and provides a scalable path toward data-driven closures for a broad class of systems with central accretors.",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA",
      "cs.AI",
      "gr-qc"
    ],
    "primary_category": "astro-ph.HE",
    "comment": "ML4PS Workshop, Neurips 2025 accepted",
    "pdf_url": "https://arxiv.org/pdf/2512.01576v1",
    "published_date": "2025-12-01 11:47:49 UTC",
    "updated_date": "2025-12-01 11:47:49 UTC"
  },
  {
    "arxiv_id": "2512.01572v2",
    "title": "Reconstructing Multi-Scale Physical Fields from Extremely Sparse Measurements with an Autoencoder-Diffusion Cascade",
    "authors": [
      "Letian Yi",
      "Tingpeng Zhang",
      "Mingyuan Zhou",
      "Guannan Wang",
      "Quanke Su",
      "Zhilu Lai"
    ],
    "abstract": "Reconstructing full fields from extremely sparse and random measurements constitutes a fundamentally ill-posed inverse problem, in which deterministic end-to-end mappings often break down due to intrinsic non-uniqueness and uncertainty. Rather than treating sparse reconstruction as a regression task, we recast it as a hierarchical probabilistic inference problem, where uncertainty is explicitly represented, structured, and progressively resolved. From this perspective, we propose Cascaded Sensing (Cas-Sensing) as a general reconstruction paradigm for multi-scale physical fields under extreme data sparsity. Central to this paradigm is the introduction of an explicit intermediate representation that decomposes the original ill-posed problem into two substantially better-conditioned subproblems. First, a lightweight neural-operator-based functional autoencoder infers a coarse-scale approximation of the target field from sparse observations acting as an explicit intermediate variable. Rather than modeling multiple scales jointly, this intermediate estimate is deterministically fixed and subsequently used as the sole conditioning input to a conditional diffusion model that generates refined-scale details, yielding a cascaded inference structure with clearly separated reconstruction responsibilities. To ensure robustness under diverse sensing patterns, the diffusion model is trained using a mask-cascade strategy, which exposes it to a distribution of imperfect conditioning structures induced by extreme sparsity. During inference, measurement consistency is enforced through manifold-constrained gradients within a Bayesian posterior framework, ensuring fidelity to sparse observations while preserving data manifold coherence. This cascaded probabilistic formulation substantially alleviates ill-posedness, enabling accurate and stable reconstructions even under extreme sparsity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.app-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages,13 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.01572v2",
    "published_date": "2025-12-01 11:46:14 UTC",
    "updated_date": "2026-01-16 05:07:11 UTC"
  },
  {
    "arxiv_id": "2512.01568v1",
    "title": "Do Large Language Models Walk Their Talk? Measuring the Gap Between Implicit Associations, Self-Report, and Behavioral Altruism",
    "authors": [
      "Sandro Andric"
    ],
    "abstract": "We investigate whether Large Language Models (LLMs) exhibit altruistic tendencies, and critically, whether their implicit associations and self-reports predict actual altruistic behavior. Using a multi-method approach inspired by human social psychology, we tested 24 frontier LLMs across three paradigms: (1) an Implicit Association Test (IAT) measuring implicit altruism bias, (2) a forced binary choice task measuring behavioral altruism, and (3) a self-assessment scale measuring explicit altruism beliefs. Our key findings are: (1) All models show strong implicit pro-altruism bias (mean IAT = 0.87, p < .0001), confirming models \"know\" altruism is good. (2) Models behave more altruistically than chance (65.6% vs. 50%, p < .0001), but with substantial variation (48-85%). (3) Implicit associations do not predict behavior (r = .22, p = .29). (4) Most critically, models systematically overestimate their own altruism, claiming 77.5% altruism while acting at 65.6% (p < .0001, Cohen's d = 1.08). This \"virtue signaling gap\" affects 75% of models tested. Based on these findings, we recommend the Calibration Gap (the discrepancy between self-reported and behavioral values) as a standardized alignment metric. Well-calibrated models are more predictable and behaviorally consistent; only 12.5% of models achieve the ideal combination of high prosocial behavior and accurate self-knowledge.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 7 figures, 7 tables. Code and data available at https://github.com/sandroandric/LLMs_Altruism_Study_Code",
    "pdf_url": "https://arxiv.org/pdf/2512.01568v1",
    "published_date": "2025-12-01 11:43:02 UTC",
    "updated_date": "2025-12-01 11:43:02 UTC"
  },
  {
    "arxiv_id": "2512.01565v1",
    "title": "Deep FlexQP: Accelerated Nonlinear Programming via Deep Unfolding",
    "authors": [
      "Alex Oshin",
      "Rahul Vodeb Ghosh",
      "Augustinos D. Saravanos",
      "Evangelos A. Theodorou"
    ],
    "abstract": "We propose an always-feasible quadratic programming (QP) optimizer, FlexQP, which is based on an exact relaxation of the QP constraints. If the original constraints are feasible, then the optimizer finds the optimal solution to the original QP. On the other hand, if the constraints are infeasible, the optimizer identifies a solution that minimizes the constraint violation in a sparse manner. FlexQP scales favorably with respect to the problem dimension, is robust to both feasible and infeasible QPs with minimal assumptions on the problem data, and can be effectively warm-started. We subsequently apply deep unfolding to improve our optimizer through data-driven techniques, leading to an accelerated Deep FlexQP. By learning dimension-agnostic feedback policies for the parameters from a small number of training examples, Deep FlexQP generalizes to problems with larger dimensions and can optimize for many more iterations than it was initially trained for. Our approach outperforms two recently proposed state-of-the-art accelerated QP approaches on a suite of benchmark systems including portfolio optimization, classification, and regression problems. We provide guarantees on the expected performance of our deep QP optimizer through probably approximately correct (PAC) Bayes generalization bounds. These certificates are used to design an accelerated sequential quadratic programming solver that solves nonlinear optimal control and predictive safety filter problems faster than traditional approaches. Overall, our approach is very robust and greatly outperforms existing non-learning and learning-based optimizers in terms of both runtime and convergence to the optimal solution across multiple classes of NLPs.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01565v1",
    "published_date": "2025-12-01 11:38:45 UTC",
    "updated_date": "2025-12-01 11:38:45 UTC"
  },
  {
    "arxiv_id": "2512.01563v2",
    "title": "MasHeNe: A Benchmark for Head and Neck CT Mass Segmentation using Window-Enhanced Mamba with Frequency-Domain Integration",
    "authors": [
      "Thao Thi Phuong Dao",
      "Tan-Cong Nguyen",
      "Nguyen Chi Thanh",
      "Truong Hoang Viet",
      "Trong-Le Do",
      "Mai-Khiem Tran",
      "Minh-Khoi Pham",
      "Trung-Nghia Le",
      "Minh-Triet Tran",
      "Thanh Dinh Le"
    ],
    "abstract": "Head and neck masses are space-occupying lesions that can compress the airway and esophagus and may affect nerves and blood vessels. Available public datasets primarily focus on malignant lesions and often overlook other space-occupying conditions in this region. To address this gap, we introduce MasHeNe, an initial dataset of 3,779 contrast-enhanced CT slices that includes both tumors and cysts with pixel-level annotations. We also establish a benchmark using standard segmentation baselines and report common metrics to enable fair comparison. In addition, we propose the Windowing-Enhanced Mamba with Frequency integration (WEMF) model. WEMF applies tri-window enhancement to enrich the input appearance before feature extraction. It further uses multi-frequency attention to fuse information across skip connections within a U-shaped Mamba backbone. On MasHeNe, WEMF attains the best performance among evaluated methods, with a Dice of 70.45%, IoU of 66.89%, NSD of 72.33%, and HD95 of 5.12 mm. This model indicates stable and strong results on this challenging task. MasHeNe provides a benchmark for head-and-neck mass segmentation beyond malignancy-only datasets. The observed error patterns also suggest that this task remains challenging and requires further research. Our dataset and code are available at https://github.com/drthaodao3101/MasHeNe.git.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The 14th International Symposium on Information and Communication Technology Conference SoICT 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.01563v2",
    "published_date": "2025-12-01 11:38:05 UTC",
    "updated_date": "2025-12-02 13:53:01 UTC"
  },
  {
    "arxiv_id": "2512.01556v1",
    "title": "LEC: Linear Expectation Constraints for False-Discovery Control in Selective Prediction and Routing Systems",
    "authors": [
      "Zhiyuan Wang",
      "Aniri",
      "Tianlong Chen",
      "Yue Zhang",
      "Heng Tao Shen",
      "Xiaoshuang Shi",
      "Kaidi Xu"
    ],
    "abstract": "Large language models (LLMs) often generate unreliable answers, while heuristic uncertainty methods fail to fully distinguish correct from incorrect predictions, causing users to accept erroneous answers without statistical guarantees. We address this issue through the lens of false discovery rate (FDR) control, ensuring that among all accepted predictions, the proportion of errors does not exceed a target risk level. To achieve this in a principled way, we propose LEC, which reinterprets selective prediction as a constrained decision problem by enforcing a Linear Expectation Constraint over selection and error indicators. Then, we establish a finite-sample sufficient condition, which relies only on a held-out set of exchangeable calibration samples, to compute an FDR-constrained, coverage-maximizing threshold. Furthermore, we extend LEC to a two-model routing mechanism: given a prompt, if the current model's uncertainty exceeds its calibrated threshold, we delegate it to a stronger model, while maintaining a unified FDR guarantee. Evaluations on closed-ended and open-ended question-answering (QA) datasets show that LEC achieves tighter FDR control and substantially improves sample retention over prior methods. Moreover, the two-model routing mechanism achieves lower risk levels while accepting more correct samples than each individual model.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01556v1",
    "published_date": "2025-12-01 11:27:09 UTC",
    "updated_date": "2025-12-01 11:27:09 UTC"
  },
  {
    "arxiv_id": "2512.01549v1",
    "title": "Delta Sum Learning: an approach for fast and global convergence in Gossip Learning",
    "authors": [
      "Tom Goethals",
      "Merlijn Sebrechts",
      "Stijn De Schrijver",
      "Filip De Turck",
      "Bruno Volckaert"
    ],
    "abstract": "Federated Learning is a popular approach for distributed learning due to its security and computational benefits. With the advent of powerful devices in the network edge, Gossip Learning further decentralizes Federated Learning by removing centralized integration and relying fully on peer to peer updates. However, the averaging methods generally used in both Federated and Gossip Learning are not ideal for model accuracy and global convergence. Additionally, there are few options to deploy Learning workloads in the edge as part of a larger application using a declarative approach such as Kubernetes manifests. This paper proposes Delta Sum Learning as a method to improve the basic aggregation operation in Gossip Learning, and implements it in a decentralized orchestration framework based on Open Application Model, which allows for dynamic node discovery and intent-driven deployment of multi-workload applications. Evaluation results show that Delta Sum performance is on par with alternative integration methods for 10 node topologies, but results in a 58% lower global accuracy drop when scaling to 50 nodes. Overall, it shows strong global convergence and a logarithmic loss of accuracy with increasing topology size compared to a linear loss for alternatives under limited connectivity.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01549v1",
    "published_date": "2025-12-01 11:23:51 UTC",
    "updated_date": "2025-12-01 11:23:51 UTC"
  },
  {
    "arxiv_id": "2512.01546v1",
    "title": "LPCD: Unified Framework from Layer-Wise to Submodule Quantization",
    "authors": [
      "Yuma Ichikawa",
      "Yudai Fujimoto",
      "Akira Sakai"
    ],
    "abstract": "Post-training quantization (PTQ) aims to preserve model-level behavior; however, most methods focus on individual linear layers. Even recent extensions, such as QEP and LoaQ, which mitigate error propagation or target specific submodules, still rely on layer-wise formulations and fail to capture the behavior of larger submodules. We introduce Layer-Projected Coordinate Descent (LPCD), a unified framework that extends PTQ beyond layers by optimizing relaxed objectives across arbitrary submodules and projecting the solutions with layer-wise quantizers. LPCD generalizes existing methods and provides a principled approach to quantizing complex submodules while maintaining the efficiency and compatibility of layer-wise PTQ pipelines. Across diverse LLM architectures and bit-widths, LPCD-based submodule quantization consistently enhances both layer-wise PTQ methods and existing submodule approaches.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "21 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.01546v1",
    "published_date": "2025-12-01 11:21:18 UTC",
    "updated_date": "2025-12-01 11:21:18 UTC"
  },
  {
    "arxiv_id": "2512.01537v1",
    "title": "Q2D2: A Geometry-Aware Audio Codec Leveraging Two-Dimensional Quantization",
    "authors": [
      "Tal Shuster",
      "Eliya Nachmani"
    ],
    "abstract": "Recent neural audio codecs have achieved impressive reconstruction quality, typically relying on quantization methods such as Residual Vector Quantization (RVQ), Vector Quantization (VQ) and Finite Scalar Quantization (FSQ). However, these quantization techniques limit the geometric structure of the latent space, make it harder to capture correlations between features leading to inefficiency in representation learning, codebook utilization and token rate. In this paper we introduce Two Dimensional Quantization (Q2D2), a quantization scheme in which feature pairs are projected onto structured 2D grids such as hexagonal, rhombic, or rectangular tiling and quantized to the nearest grid values, yielding an implicit codebook defined by the product of grid levels, with codebook sizes comparable to conventional methods. Despite its simple geometric formulation, Q2D2 improves audio compression efficiency, with low token rates and high codebook utilization while maintaining state of the art reconstruction quality. Specifically, Q2D2 achieves competitive to superior performance in various objective and subjective reconstruction metrics, across extensive experiments in speech domain compared to state of the art models. Comprehensive ablation studies further confirm the effectiveness of our design choices.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01537v1",
    "published_date": "2025-12-01 11:06:38 UTC",
    "updated_date": "2025-12-01 11:06:38 UTC"
  },
  {
    "arxiv_id": "2512.01534v1",
    "title": "Deep Unsupervised Anomaly Detection in Brain Imaging: Large-Scale Benchmarking and Bias Analysis",
    "authors": [
      "Alexander Frotscher",
      "Christian F. Baumgartner",
      "Thomas Wolfers"
    ],
    "abstract": "Deep unsupervised anomaly detection in brain magnetic resonance imaging offers a promising route to identify pathological deviations without requiring lesion-specific annotations. Yet, fragmented evaluations, heterogeneous datasets, and inconsistent metrics have hindered progress toward clinical translation. Here, we present a large-scale, multi-center benchmark of deep unsupervised anomaly detection for brain imaging. The training cohort comprised 2,976 T1 and 2,972 T2-weighted scans from healthy individuals across six scanners, with ages ranging from 6 to 89 years. Validation used 92 scans to tune hyperparameters and estimate unbiased thresholds. Testing encompassed 2,221 T1w and 1,262 T2w scans spanning healthy datasets and diverse clinical cohorts. Across all algorithms, the Dice-based segmentation performance varied between 0.03 and 0.65, indicating substantial variability. To assess robustness, we systematically evaluated the impact of different scanners, lesion types and sizes, as well as demographics (age, sex). Reconstruction-based methods, particularly diffusion-inspired approaches, achieved the strongest lesion segmentation performance, while feature-based methods showed greater robustness under distributional shifts. However, systematic biases, such as scanner-related effects, were observed for the majority of algorithms, including that small and low-contrast lesions were missed more often, and that false positives varied with age and sex. Increasing healthy training data yields only modest gains, underscoring that current unsupervised anomaly detection frameworks are limited algorithmically rather than by data availability. Our benchmark establishes a transparent foundation for future research and highlights priorities for clinical translation, including image native pretraining, principled deviation measures, fairness-aware modeling, and robust domain adaptation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01534v1",
    "published_date": "2025-12-01 11:03:27 UTC",
    "updated_date": "2025-12-01 11:03:27 UTC"
  },
  {
    "arxiv_id": "2512.01533v1",
    "title": "Diffusion Fuzzy System: Fuzzy Rule Guided Latent Multi-Path Diffusion Modeling",
    "authors": [
      "Hailong Yang",
      "Te Zhang",
      "Kup-sze Choi",
      "Zhaohong Deng"
    ],
    "abstract": "Diffusion models have emerged as a leading technique for generating images due to their ability to create high-resolution and realistic images. Despite their strong performance, diffusion models still struggle in managing image collections with significant feature differences. They often fail to capture complex features and produce conflicting results. Research has attempted to address this issue by learning different regions of an image through multiple diffusion paths and then combining them. However, this approach leads to inefficient coordination among multiple paths and high computational costs. To tackle these issues, this paper presents a Diffusion Fuzzy System (DFS), a latent-space multi-path diffusion model guided by fuzzy rules. DFS offers several advantages. First, unlike traditional multi-path diffusion methods, DFS uses multiple diffusion paths, each dedicated to learning a specific class of image features. By assigning each path to a different feature type, DFS overcomes the limitations of multi-path models in capturing heterogeneous image features. Second, DFS employs rule-chain-based reasoning to dynamically steer the diffusion process and enable efficient coordination among multiple paths. Finally, DFS introduces a fuzzy membership-based latent-space compression mechanism to reduce the computational costs of multi-path diffusion effectively. We tested our method on three public datasets: LSUN Bedroom, LSUN Church, and MS COCO. The results show that DFS achieves more stable training and faster convergence than existing single-path and multi-path diffusion models. Additionally, DFS surpasses baseline models in both image quality and alignment between text and images, and also shows improved accuracy when comparing generated images to target references.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01533v1",
    "published_date": "2025-12-01 11:01:06 UTC",
    "updated_date": "2025-12-01 11:01:06 UTC"
  },
  {
    "arxiv_id": "2512.01523v1",
    "title": "Teaching an Online Multi-Institutional Research Level Software Engineering Course with Industry -- an Experience Report",
    "authors": [
      "Pankaj Jalote",
      "Y. Raghu Reddy",
      "Vasudeva Varma"
    ],
    "abstract": "Covid has made online teaching and learning acceptable and students, faculty, and industry professionals are all comfortable with this mode. This comfort can be leveraged to offer an online multi-institutional research-level course in an area where individual institutions may not have the requisite faculty to teach and/or research students to enroll. If the subject is of interest to industry, online offering also allows industry experts to contribute and participate with ease. Advanced topics in Software Engineering are ideally suited for experimenting with this approach as industry, which is often looking to incorporate advances in software engineering in their practices, is likely to agree to contribute and participate. In this paper we describe an experiment in teaching a course titled \"AI in Software Engineering\" jointly between two institutions with active industry participation, and share our and student's experience. We believe this collaborative teaching approach can be used for offering research level courses in any applied area of computer science by institutions who are small and find it difficult to offer research level courses on their own.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "7 pages",
    "pdf_url": "https://arxiv.org/pdf/2512.01523v1",
    "published_date": "2025-12-01 10:46:43 UTC",
    "updated_date": "2025-12-01 10:46:43 UTC"
  },
  {
    "arxiv_id": "2512.01507v1",
    "title": "SynthStrategy: Extracting and Formalizing Latent Strategic Insights from LLMs in Organic Chemistry",
    "authors": [
      "Daniel Armstrong",
      "Zlatko Jonev",
      "Andres M Bran",
      "Philippe Schwaller"
    ],
    "abstract": "Modern computer-assisted synthesis planning (CASP) systems show promises at generating chemically valid reaction steps but struggle to incorporate strategic considerations such as convergent assembly, protecting group minimization, and optimal ring-forming sequences. We introduce a methodology that leverages Large Language Models to distill synthetic knowledge into code. Our system analyzes synthesis routes and translates strategic principles into Python functions representing diverse strategic and tactical rules, such as strategic functional group interconversions and ring construction strategies. By formalizing this knowledge as verifiable code rather than simple heuristics, we create testable, interpretable representations of synthetic strategy. We release the complete codebase and the USPTO-ST dataset -- synthesis routes annotated with strategic tags. This framework unlocks a novel capability for CASP: natural language-based route retrieval, achieving 75\\% Top-3 accuracy on our benchmark. We further validate our library through temporal analysis of historical trends and chemically intuitive route clustering that offers more granular partitioning than common previous methods. This work bridges the tactical-strategic divide in CASP, enabling specification, search, and evaluation of routes by strategic criteria rather than structure alone.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01507v1",
    "published_date": "2025-12-01 10:33:00 UTC",
    "updated_date": "2025-12-01 10:33:00 UTC"
  },
  {
    "arxiv_id": "2512.05140v1",
    "title": "FlowEO: Generative Unsupervised Domain Adaptation for Earth Observation",
    "authors": [
      "Georges Le Bellier",
      "Nicolas Audebert"
    ],
    "abstract": "The increasing availability of Earth observation data offers unprecedented opportunities for large-scale environmental monitoring and analysis. However, these datasets are inherently heterogeneous, stemming from diverse sensors, geographical regions, acquisition times, and atmospheric conditions. Distribution shifts between training and deployment domains severely limit the generalization of pretrained remote sensing models, making unsupervised domain adaptation (UDA) crucial for real-world applications. We introduce FlowEO, a novel framework that leverages generative models for image-space UDA in Earth observation. We leverage flow matching to learn a semantically preserving mapping that transports from the source to the target image distribution. This allows us to tackle challenging domain adaptation configurations for classification and semantic segmentation of Earth observation images. We conduct extensive experiments across four datasets covering adaptation scenarios such as SAR to optical translation and temporal and semantic shifts caused by natural disasters. Experimental results demonstrate that FlowEO outperforms existing image translation approaches for domain adaptation while achieving on-par or better perceptual image quality, highlighting the potential of flow-matching-based UDA for remote sensing.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "2026 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Mar 2026, Tucson (AZ), United States",
    "pdf_url": "https://arxiv.org/pdf/2512.05140v1",
    "published_date": "2025-12-01 10:29:01 UTC",
    "updated_date": "2025-12-01 10:29:01 UTC"
  },
  {
    "arxiv_id": "2512.01502v1",
    "title": "Formal Verification of Noisy Quantum Reinforcement Learning Policies",
    "authors": [
      "Dennis Gross"
    ],
    "abstract": "Quantum reinforcement learning (QRL) aims to use quantum effects to create sequential decision-making policies that achieve tasks more effectively than their classical counterparts. However, QRL policies face uncertainty from quantum measurements and hardware noise, such as bit-flip, phase-flip, and depolarizing errors, which can lead to unsafe behavior. Existing work offers no systematic way to verify whether trained QRL policies meet safety requirements under specific noise conditions.\n  We introduce QVerifier, a formal verification method that applies probabilistic model checking to analyze trained QRL policies with and without modeled quantum noise. QVerifier builds a complete model of the policy-environment interaction, incorporates quantum uncertainty directly into the transition probabilities, and then checks safety properties using the Storm model checker.\n  Experiments across multiple QRL environments show that QVerifier precisely measures how different noise models influence safety, revealing both performance degradation and cases where noise can help. By enabling rigorous safety verification before deployment, QVerifier addresses a critical need: because access to quantum hardware is expensive, pre-deployment verification is essential for any safety-critical use of QRL. QVerifier targets a potential classical-quantum sweet spot: trained QRL policies that execute efficiently on quantum hardware, yet remain tractable for classical probabilistic model checking despite being too slow for real-time classical deployment.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.FL"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01502v1",
    "published_date": "2025-12-01 10:26:33 UTC",
    "updated_date": "2025-12-01 10:26:33 UTC"
  },
  {
    "arxiv_id": "2512.01485v2",
    "title": "Multi-Path Collaborative Reasoning via Reinforcement Learning",
    "authors": [
      "Jindi Lv",
      "Yuhao Zhou",
      "Zheng Zhu",
      "Xiaofeng Wang",
      "Guan Huang",
      "Jiancheng Lv"
    ],
    "abstract": "Chain-of-Thought (CoT) reasoning has significantly advanced the problem-solving capabilities of Large Language Models (LLMs), yet conventional CoT often exhibits internal determinism during decoding, limiting exploration of plausible alternatives. Recent methods attempt to address this by generating soft abstract tokens to enable reasoning in a continuous semantic space. However, we find that such approaches remain constrained by the greedy nature of autoregressive decoding, which fundamentally isolates the model from alternative reasoning possibilities. In this work, we propose Multi-Path Perception Policy Optimization (M3PO), a novel reinforcement learning framework that explicitly injects collective insights into the reasoning process. M3PO leverages parallel policy rollouts as naturally diverse reasoning sources and integrates cross-path interactions into policy updates through a lightweight collaborative mechanism. This design allows each trajectory to refine its reasoning with peer feedback, thereby cultivating more reliable multi-step reasoning patterns. Empirical results show that M3PO achieves state-of-the-art performance on both knowledge- and reasoning-intensive benchmarks. Models trained with M3PO maintain interpretability and inference efficiency, underscoring the promise of multi-path collaborative learning for robust reasoning.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01485v2",
    "published_date": "2025-12-01 10:05:46 UTC",
    "updated_date": "2025-12-08 07:33:30 UTC"
  },
  {
    "arxiv_id": "2512.01484v1",
    "title": "Multi-view diffusion geometry using intertwined diffusion trajectories",
    "authors": [
      "Gwendal Debaussart-Joniec",
      "Argyris Kalogeratos"
    ],
    "abstract": "This paper introduces a comprehensive unified framework for constructing multi-view diffusion geometries through intertwined multi-view diffusion trajectories (MDTs), a class of inhomogeneous diffusion processes that iteratively combine the random walk operators of multiple data views. Each MDT defines a trajectory-dependent diffusion operator with a clear probabilistic and geometric interpretation, capturing over time the interplay between data views. Our formulation encompasses existing multi-view diffusion models, while providing new degrees of freedom for view interaction and fusion. We establish theoretical properties under mild assumptions, including ergodicity of both the point-wise operator and the process in itself. We also derive MDT-based diffusion distances, and associated embeddings via singular value decompositions. Finally, we propose various strategies for learning MDT operators within the defined operator space, guided by internal quality measures. Beyond enabling flexible model design, MDTs also offer a neutral baseline for evaluating diffusion-based approaches through comparison with randomly selected MDTs. Experiments show the practical impact of the MDT operators in a manifold learning and data clustering context.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01484v1",
    "published_date": "2025-12-01 10:05:19 UTC",
    "updated_date": "2025-12-01 10:05:19 UTC"
  },
  {
    "arxiv_id": "2512.03095v1",
    "title": "Community Quality and Influence Maximization: An Empirical Study",
    "authors": [
      "Motaz Ben Hassine"
    ],
    "abstract": "Influence maximization in social networks plays a vital role in applications such as viral marketing, epidemiology, product recommendation, opinion mining, and counter-terrorism. A common approach identifies seed nodes by first detecting disjoint communities and subsequently selecting representative nodes from these communities. However, whether the quality of detected communities consistently affects the spread of influence under the Independent Cascade model remains unclear. This paper addresses this question by extending a previously proposed disjoint community detection method, termed $$-Hierarchical Clustering, to the influence maximization problem under the Independent Cascade model. The proposed method is compared with an alternative approach that employs the same seed selection criteria but relies on communities of lower quality obtained through standard Hierarchical Clustering. The former is referred to as Hierarchical Clustering-based Influence Maximization, while the latter, which leverages higher-quality community structures to guide seed selection, is termed $$-Hierarchical Clustering-based Influence Maximization. Extensive experiments are performed on multiple real-world datasets to assess the effectiveness of both methods. The results demonstrate that higher-quality community structures substantially improve information diffusion under the Independent Cascade model, particularly when the propagation probability is low. These findings underscore the critical importance of community quality in guiding effective seed selection for influence maximization in complex networks.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.03095v1",
    "published_date": "2025-12-01 09:59:04 UTC",
    "updated_date": "2025-12-01 09:59:04 UTC"
  },
  {
    "arxiv_id": "2512.01473v1",
    "title": "Does Flatness imply Generalization for Logistic Loss in Univariate Two-Layer ReLU Network?",
    "authors": [
      "Dan Qiao",
      "Yu-Xiang Wang"
    ],
    "abstract": "We consider the problem of generalization of arbitrarily overparameterized two-layer ReLU Neural Networks with univariate input. Recent work showed that under square loss, flat solutions (motivated by flat / stable minima and Edge of Stability phenomenon) provably cannot overfit, but it remains unclear whether the same phenomenon holds for logistic loss. This is a puzzling open problem because existing work on logistic loss shows that gradient descent with increasing step size converges to interpolating solutions (at infinity, for the margin-separable cases). In this paper, we prove that the \\emph{flatness implied generalization} is more delicate under logistic loss. On the positive side, we show that flat solutions enjoy near-optimal generalization bounds within a region between the left-most and right-most \\emph{uncertain} sets determined by each candidate solution. On the negative side, we show that there exist arbitrarily flat yet overfitting solutions at infinity that are (falsely) certain everywhere, thus certifying that flatness alone is insufficient for generalization in general. We demonstrate the effects predicted by our theory in a well-controlled simulation study.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "59 pages",
    "pdf_url": "https://arxiv.org/pdf/2512.01473v1",
    "published_date": "2025-12-01 09:57:11 UTC",
    "updated_date": "2025-12-01 09:57:11 UTC"
  },
  {
    "arxiv_id": "2512.01457v4",
    "title": "Zero-Overhead Introspection for Adaptive Test-Time Compute",
    "authors": [
      "Rohin Manvi",
      "Joey Hong",
      "Tim Seyde",
      "Maxime Labonne",
      "Mathias Lechner",
      "Sergey Levine"
    ],
    "abstract": "Large language models excel at reasoning but lack key aspects of introspection, including anticipating their own success and the computation required to achieve it. Humans use real-time introspection to decide how much effort to invest, when to make multiple attempts, when to stop, and when to signal success or failure. Without this, LLMs struggle to make intelligent meta-cognition decisions. Test-time scaling methods like Best-of-N drive up cost and latency by using a fixed budget of samples regardless of the marginal benefit of each one at any point in generation, and the absence of confidence signals can mislead people, prevent appropriate escalation to better tools, and undermine trustworthiness. Learned verifiers or reward models can provide confidence estimates, but do not enable adaptive inference and add substantial cost by requiring extra models or forward passes. We present ZIP-RC, which equips models with zero-overhead introspective predictions of reward and cost. At every token, ZIP-RC reuses reserved or unused logits in the same forward pass as next-token prediction to output a joint distribution over final reward and remaining length -- no extra models, architecture change, or inference overhead. This full joint distribution is used to compute a sampling utility which is the linear combination of the expected maximum reward, total compute, and latency of set of samples if generated to completion. During inference, we maximize this utility with meta-actions that determine which prefix of tokens to continue or initiate sampling from. On mixed-difficulty mathematical benchmarks, ZIP-RC improves accuracy by up to 12% over majority voting at equal or lower average cost, and traces smooth Pareto frontiers between quality, compute, and latency. By providing real-time reward-cost introspection, ZIP-RC enables adaptive, efficient reasoning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01457v4",
    "published_date": "2025-12-01 09:44:31 UTC",
    "updated_date": "2025-12-23 08:18:03 UTC"
  },
  {
    "arxiv_id": "2512.01452v1",
    "title": "Automated Risk-of-Bias Assessment of Randomized Controlled Trials: A First Look at a GEPA-trained Programmatic Prompting Framework",
    "authors": [
      "Lingbo Li",
      "Anuradha Mathrani",
      "Teo Susnjak"
    ],
    "abstract": "Assessing risk of bias (RoB) in randomized controlled trials is essential for trustworthy evidence synthesis, but the process is resource-intensive and prone to variability across reviewers. Large language models (LLMs) offer a route to automation, but existing methods rely on manually engineered prompts that are difficult to reproduce, generalize, or evaluate. This study introduces a programmable RoB assessment pipeline that replaces ad-hoc prompt design with structured, code-based optimization using DSPy and its GEPA module. GEPA refines LLM reasoning through Pareto-guided search and produces inspectable execution traces, enabling transparent replication of every step in the optimization process. We evaluated the method on 100 RCTs from published meta-analyses across seven RoB domains. GEPA-generated prompts were applied to both open-weight models (Mistral Small 3.1 with GPT-oss-20b) and commercial models (GPT-5 Nano and GPT-5 Mini). In domains with clearer methodological reporting, such as Random Sequence Generation, GEPA-generated prompts performed best, with similar results for Allocation Concealment and Blinding of Participants, while the commercial model performed slightly better overall. We also compared GEPA with three manually designed prompts using Claude 3.5 Sonnet. GEPA achieved the highest overall accuracy and improved performance by 30%-40% in Random Sequence Generation and Selective Reporting, and showed generally comparable, competitively aligned performance in the other domains relative to manual prompts. These findings suggest that GEPA can produce consistent and reproducible prompts for RoB assessment, supporting the structured and principled use of LLMs in evidence synthesis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01452v1",
    "published_date": "2025-12-01 09:39:13 UTC",
    "updated_date": "2025-12-01 09:39:13 UTC"
  },
  {
    "arxiv_id": "2512.01442v1",
    "title": "PSA-MF: Personality-Sentiment Aligned Multi-Level Fusion for Multimodal Sentiment Analysis",
    "authors": [
      "Heng Xie",
      "Kang Zhu",
      "Zhengqi Wen",
      "Jianhua Tao",
      "Xuefei Liu",
      "Ruibo Fu",
      "Changsheng Li"
    ],
    "abstract": "Multimodal sentiment analysis (MSA) is a research field that recognizes human sentiments by combining textual, visual, and audio modalities. The main challenge lies in integrating sentiment-related information from different modalities, which typically arises during the unimodal feature extraction phase and the multimodal feature fusion phase. Existing methods extract only shallow information from unimodal features during the extraction phase, neglecting sentimental differences across different personalities. During the fusion phase, they directly merge the feature information from each modality without considering differences at the feature level. This ultimately affects the model's recognition performance. To address this problem, we propose a personality-sentiment aligned multi-level fusion framework. We introduce personality traits during the feature extraction phase and propose a novel personality-sentiment alignment method to obtain personalized sentiment embeddings from the textual modality for the first time. In the fusion phase, we introduce a novel multi-level fusion method. This method gradually integrates sentimental information from textual, visual, and audio modalities through multimodal pre-fusion and a multi-level enhanced fusion strategy. Our method has been evaluated through multiple experiments on two commonly used datasets, achieving state-of-the-art results.",
    "categories": [
      "cs.MM",
      "cs.AI"
    ],
    "primary_category": "cs.MM",
    "comment": "AAAI 2026 accepted",
    "pdf_url": "https://arxiv.org/pdf/2512.01442v1",
    "published_date": "2025-12-01 09:24:59 UTC",
    "updated_date": "2025-12-01 09:24:59 UTC"
  },
  {
    "arxiv_id": "2512.01440v1",
    "title": "A Selective Temporal Hamming distance to find patterns in state transition event timeseries, at scale",
    "authors": [
      "Sylvain Mari",
      "Pablo Knecht"
    ],
    "abstract": "Discrete event systems are present both in observations of nature, socio economical sciences, and industrial systems. Standard analysis approaches do not usually exploit their dual event / state nature: signals are either modeled as transition event sequences, emphasizing event order alignment, or as categorical or ordinal state timeseries, usually resampled a distorting and costly operation as the observation period and number of events grow. In this work we define state transition event timeseries (STE-ts) and propose a new Selective Temporal Hamming distance (STH) leveraging both transition time and duration-in-state, avoiding costly and distorting resampling on large databases. STH generalizes both resampled Hamming and Jaccard metrics with better precision and computation time, and an ability to focus on multiple states of interest. We validate these benefits on simulated and real-world datasets.",
    "categories": [
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01440v1",
    "published_date": "2025-12-01 09:24:20 UTC",
    "updated_date": "2025-12-01 09:24:20 UTC"
  },
  {
    "arxiv_id": "2512.01434v1",
    "title": "A Flexible Multi-Agent LLM-Human Framework for Fast Human Validated Tool Building",
    "authors": [
      "Daull Xavier",
      "Patrice Bellot",
      "Emmanuel Bruno",
      "Vincent Martin",
      "Elisabeth Murisasco"
    ],
    "abstract": "We introduce CollabToolBuilder, a flexible multiagent LLM framework with expert-in-the-loop (HITL) guidance that iteratively learns to create tools for a target goal, aligning with human intent and process, while minimizing time for task/domain adaptation effort and human feedback capture. The architecture generates and validates tools via four specialized agents (Coach, Coder, Critic, Capitalizer) using a reinforced dynamic prompt and systematic human feedback integration to reinforce each agent's role toward goals and constraints. This work is best viewed as a system-level integration and methodology combining multi-agent in-context learning, HITL controls, and reusable tool capitalization for complex iterative problems such as scientific document generation. We illustrate it with preliminary experiments (e.g., generating state-of-the-art research papers or patents given an abstract) and discuss its applicability to other iterative problem-solving.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01434v1",
    "published_date": "2025-12-01 09:19:18 UTC",
    "updated_date": "2025-12-01 09:19:18 UTC"
  },
  {
    "arxiv_id": "2512.01420v1",
    "title": "PromptBridge: Cross-Model Prompt Transfer for Large Language Models",
    "authors": [
      "Yaxuan Wang",
      "Quan Liu",
      "Zhenting Wang",
      "Zichao Li",
      "Wei Wei",
      "Yang Liu",
      "Yujia Bao"
    ],
    "abstract": "Large language models (LLMs) underpin applications in code generation, mathematical reasoning, and agent-based workflows. In practice, systems access LLMs via commercial APIs or open-source deployments, and the model landscape (e.g., GPT, Claude, Llama) evolves rapidly. This rapid evolution forces frequent model switches driven by capability, cost, deployment constraints, and privacy. Yet prompts are highly model-sensitive: reusing a prompt engineered for one model on another often yields substantially worse performance than a prompt optimized for the target model. We term this phenomenon Model Drifting. Through extensive empirical analysis across diverse LLM configurations, we show that model drifting is both common and severe. To address this challenge, we introduce PromptBridge, a training-free framework that preserves prompt effectiveness under model switches, enabling cross-model prompt transfer without costly per-task or per-model re-optimization. PromptBridge requires only a small set of alignment tasks for calibration. It first applies Model-Adaptive Reflective Prompt Evolution (MAP-RPE) to obtain task- and model-specific optimal prompts via iterative reflective refinement and quantitative evaluation. Using the resulting calibrated prompt pairs for the source and target models, PromptBridge learns a cross-model prompt mapping. At test time, i.e., for an unseen task, given a source-model prompt, this mapping directly produces an optimized prompt for the target model. Experiments in single-agent and multi-agent settings show that PromptBridge consistently improves downstream accuracy while reducing migration effort. The code will be available soon.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01420v1",
    "published_date": "2025-12-01 08:55:45 UTC",
    "updated_date": "2025-12-01 08:55:45 UTC"
  },
  {
    "arxiv_id": "2512.01419v1",
    "title": "Rice-VL: Evaluating Vision-Language Models for Cultural Understanding Across ASEAN Countries",
    "authors": [
      "Tushar Pranav",
      "Eshan Pandey",
      "Austria Lyka Diane Bala",
      "Aman Chadha",
      "Indriyati Atmosukarto",
      "Donny Soh Cheng Lock"
    ],
    "abstract": "Vision-Language Models (VLMs) excel in multimodal tasks but often exhibit Western-centric biases, limiting their effectiveness in culturally diverse regions like Southeast Asia (SEA). To address this, we introduce RICE-VL, a novel benchmark evaluating VLM cultural understanding across 11 ASEAN countries. RICE-VL includes over 28,000 human-curated Visual Question Answering (VQA) samples -- covering True or False, Fill-in-the-Blank, and open-ended formats -- and 1,000 image-bounding box pairs for Visual Grounding, annotated by culturally informed experts across 14 sub-ground categories. We propose SEA-LAVE, an extension of the LAVE metric, assessing textual accuracy, cultural alignment, and country identification. Evaluations of six open- and closed-source VLMs reveal significant performance gaps in low-resource countries and abstract cultural domains. The Visual Grounding task tests models' ability to localize culturally significant elements in complex scenes, probing spatial and contextual accuracy. RICE-VL exposes limitations in VLMs' cultural comprehension and highlights the need for inclusive model development to better serve diverse global populations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages",
    "pdf_url": "https://arxiv.org/pdf/2512.01419v1",
    "published_date": "2025-12-01 08:55:41 UTC",
    "updated_date": "2025-12-01 08:55:41 UTC"
  },
  {
    "arxiv_id": "2512.01412v1",
    "title": "A Self-explainable Model of Long Time Series by Extracting Informative Structured Causal Patterns",
    "authors": [
      "Ziqian Wang",
      "Yuxiao Cheng",
      "Jinli Suo"
    ],
    "abstract": "Explainability is essential for neural networks that model long time series, yet most existing explainable AI methods only produce point-wise importance scores and fail to capture temporal structures such as trends, cycles, and regime changes. This limitation weakens human interpretability and trust in long-horizon models. To address these issues, we identify four key requirements for interpretable time-series modeling: temporal continuity, pattern-centric explanation, causal disentanglement, and faithfulness to the model's inference process. We propose EXCAP, a unified framework that satisfies all four requirements. EXCAP combines an attention-based segmenter that extracts coherent temporal patterns, a causally structured decoder guided by a pre-trained causal graph, and a latent aggregation mechanism that enforces representation stability. Our theoretical analysis shows that EXCAP provides smooth and stable explanations over time and is robust to perturbations in causal masks. Extensive experiments on classification and forecasting benchmarks demonstrate that EXCAP achieves strong predictive accuracy while generating coherent and causally grounded explanations. These results show that EXCAP offers a principled and scalable approach to interpretable modeling of long time series with relevance to high-stakes domains such as healthcare and finance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Approximately 30 pages, 8 figures, and 5 tables. Preprint version. Includes theoretical analysis, model architecture, interpretability evaluation, and extensive benchmark experiments",
    "pdf_url": "https://arxiv.org/pdf/2512.01412v1",
    "published_date": "2025-12-01 08:33:33 UTC",
    "updated_date": "2025-12-01 08:33:33 UTC"
  },
  {
    "arxiv_id": "2512.01389v1",
    "title": "Consistency Flow Model Achieves One-step Denoising Error Correction Codes",
    "authors": [
      "Haoyu Lei",
      "Chin Wa Lau",
      "Kaiwen Zhou",
      "Nian Guo",
      "Farzan Farnia"
    ],
    "abstract": "Error Correction Codes (ECC) are fundamental to reliable digital communication, yet designing neural decoders that are both accurate and computationally efficient remains challenging. Recent denoising diffusion decoders with transformer backbones achieve state-of-the-art performance, but their iterative sampling limits practicality in low-latency settings. We introduce the Error Correction Consistency Flow Model (ECCFM), an architecture-agnostic training framework for high-fidelity one-step decoding. By casting the reverse denoising process as a Probability Flow Ordinary Differential Equation (PF-ODE) and enforcing smoothness through a differential time regularization, ECCFM learns to map noisy signals along the decoding trajectory directly to the original codeword in a single inference step. Across multiple decoding benchmarks, ECCFM attains lower bit-error rates (BER) than autoregressive and diffusion-based baselines, with notable improvements on longer codes, while delivering inference speeds up from 30x to 100x faster than denoising diffusion decoders.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01389v1",
    "published_date": "2025-12-01 08:07:51 UTC",
    "updated_date": "2025-12-01 08:07:51 UTC"
  },
  {
    "arxiv_id": "2512.01374v3",
    "title": "Stabilizing Reinforcement Learning with LLMs: Formulation and Practices",
    "authors": [
      "Chujie Zheng",
      "Kai Dang",
      "Bowen Yu",
      "Mingze Li",
      "Huiqiang Jiang",
      "Junrong Lin",
      "Yuqiong Liu",
      "Hao Lin",
      "Chencan Wu",
      "Feng Hu",
      "An Yang",
      "Jingren Zhou",
      "Junyang Lin"
    ],
    "abstract": "This paper proposes a novel formulation for reinforcement learning (RL) with large language models, explaining why and under what conditions the true sequence-level reward can be optimized via a surrogate token-level objective in policy gradient methods such as REINFORCE. Specifically, through a first-order approximation, we show that this surrogate becomes increasingly valid only when both the training-inference discrepancy and policy staleness are minimized. This insight provides a principled explanation for the crucial role of several widely adopted techniques in stabilizing RL training, including importance sampling correction, clipping, and particularly Routing Replay for Mixture-of-Experts (MoE) models. Through extensive experiments with a 30B MoE model totaling hundreds of thousands of GPU hours, we show that for on-policy training, the basic policy gradient algorithm with importance sampling correction achieves the highest training stability. When off-policy updates are introduced to accelerate convergence, combining clipping and Routing Replay becomes essential to mitigate the instability caused by policy staleness. Notably, once training is stabilized, prolonged optimization consistently yields comparable final performance regardless of cold-start initialization. We hope that the shared insights and the developed recipes for stable RL training will facilitate future research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01374v3",
    "published_date": "2025-12-01 07:45:39 UTC",
    "updated_date": "2025-12-03 15:17:19 UTC"
  },
  {
    "arxiv_id": "2512.01372v2",
    "title": "Structured Spectral Reasoning for Frequency-Adaptive Multimodal Recommendation",
    "authors": [
      "Wei Yang",
      "Rui Zhong",
      "Yiqun Chen",
      "Chi Lu",
      "Peng Jiang"
    ],
    "abstract": "Multimodal recommendation aims to integrate collaborative signals with heterogeneous content such as visual and textual information, but remains challenged by modality-specific noise, semantic inconsistency, and unstable propagation over user-item graphs. These issues are often exacerbated by naive fusion or shallow modeling strategies, leading to degraded generalization and poor robustness. While recent work has explored the frequency domain as a lens to separate stable from noisy signals, most methods rely on static filtering or reweighting, lacking the ability to reason over spectral structure or adapt to modality-specific reliability. To address these challenges, we propose a Structured Spectral Reasoning (SSR) framework for frequency-aware multimodal recommendation. Our method follows a four-stage pipeline: (i) Decompose graph-based multimodal signals into spectral bands via graph-guided transformations to isolate semantic granularity; (ii) Modulate band-level reliability with spectral band masking, a training-time masking with a prediction-consistency objective that suppresses brittle frequency components; (iii) Fuse complementary frequency cues using hyperspectral reasoning with low-rank cross-band interaction; and (iv) Align modality-specific spectral features via contrastive regularization to promote semantic and structural consistency. Experiments on three real-world benchmarks show consistent gains over strong baselines, particularly under sparse and cold-start settings. Additional analyses indicate that structured spectral modeling improves robustness and provides clearer diagnostics of how different bands contribute to performance.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01372v2",
    "published_date": "2025-12-01 07:39:28 UTC",
    "updated_date": "2025-12-21 19:35:23 UTC"
  },
  {
    "arxiv_id": "2512.01370v1",
    "title": "Beyond Loss Guidance: Using PDE Residuals as Spectral Attention in Diffusion Neural Operators",
    "authors": [
      "Medha Sawhney",
      "Abhilash Neog",
      "Mridul Khurana",
      "Anuj Karpatne"
    ],
    "abstract": "Diffusion-based solvers for partial differential equations (PDEs) are often bottle-necked by slow gradient-based test-time optimization routines that use PDE residuals for loss guidance. They additionally suffer from optimization instabilities and are unable to dynamically adapt their inference scheme in the presence of noisy PDE residuals. To address these limitations, we introduce PRISMA (PDE Residual Informed Spectral Modulation with Attention), a conditional diffusion neural operator that embeds PDE residuals directly into the model's architecture via attention mechanisms in the spectral domain, enabling gradient-descent free inference. In contrast to previous methods that use PDE loss solely as external optimization targets, PRISMA integrates PDE residuals as integral architectural features, making it inherently fast, robust, accurate, and free from sensitive hyperparameter tuning. We show that PRISMA has competitive accuracy, at substantially lower inference costs, compared to previous methods across five benchmark PDEs, especially with noisy observations, while using 10x to 100x fewer denoising steps, leading to 15x to 250x faster inference.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.NA",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01370v1",
    "published_date": "2025-12-01 07:34:42 UTC",
    "updated_date": "2025-12-01 07:34:42 UTC"
  },
  {
    "arxiv_id": "2512.01357v1",
    "title": "Tangram: Accelerating Serverless LLM Loading through GPU Memory Reuse and Affinity",
    "authors": [
      "Wenbin Zhu",
      "Zhaoyan Shen",
      "Zili Shao",
      "Hongjun Dai",
      "Feng Chen"
    ],
    "abstract": "Serverless Large Language Models (LLMs) have emerged as a cost-effective solution for deploying AI services by enabling a 'pay-as-you-go' pricing model through GPU resource sharing. However, cold-start latency, especially the model loading phase, has become a critical performance bottleneck, as it scales linearly with model size and severely limits the practical deployment of large-scale LLM services. This paper presents Tangram, a novel system that accelerates Serverless LLM loading through efficient GPU memory reuse. By leveraging the unused GPU memory to retain model parameters, Tangram significantly reduces model transfer time and cold-start latency. Its design includes three key components: unified GPU memory pool for tensor-level parameter sharing across models, on-demand KV cache allocation for dynamic memory management, and GPU-affinity-aware scheduling for maximizing resource utilization. These techniques collectively address the critical challenges of inefficient memory usage and the cold-start problem in Serverless LLM platforms. We have implemented a fully functional prototype, and experiments show that Tangram achieves up to 6.2 times faster loading and reduces Time-To-First-Token (TTFT) during cold-start by 23--55% over state-of-the-art methods.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01357v1",
    "published_date": "2025-12-01 07:10:34 UTC",
    "updated_date": "2025-12-01 07:10:34 UTC"
  },
  {
    "arxiv_id": "2512.01354v3",
    "title": "The Necessity of Imperfection:Reversing Model Collapse via Simulating Cognitive Boundedness",
    "authors": [
      "Zhongjie Jiang"
    ],
    "abstract": "Although synthetic data is widely promoted as a remedy, its prevailing production paradigm -- one optimizing for statistical smoothness -- systematically removes the long-tail, cognitively grounded irregularities that characterize human text. Prolonged training on such statistically optimal but cognitively impoverished data accelerates model collapse.\n  This paper proposes a paradigm shift: instead of imitating the surface properties of data, we simulate the cognitive processes that generate human text. We introduce the Prompt-driven Cognitive Computing Framework (PMCSF), whose core consists of a Cognitive State Decoder (CSD) that reverse-engineers unstructured text into structured cognitive vectors, and a Cognitive Text Encoder (CTE) that re-materializes these states into text enriched with human-typical imperfections via mathematically defined Cognitive Perturbation Operators.\n  The framework is validated through a two-stage objective evaluation pipeline. First, in cognitive codec verification, CTE text yields a Jensen-Shannon divergence of 0.0614 from human text (vs. 0.4431 for standard LLM output), passes double-blind professional media review, and achieves an intraclass correlation coefficient ICC > 0.9 for cognitive profile alignment across heterogeneous models. Second, in functional gain evaluation, isomorphic stress tests in the A-share market show that strategies incorporating CTE-generated data reduce maximum drawdown by 47.4% during the 2015 crash and deliver 8.6% Defensive Alpha, exceeding transaction costs by a factor of 33.\n  Our findings demonstrate that modelling human cognitive limitations -- not copying surface data -- enables synthetic data with genuine functional gain, offering a viable technical pathway toward resolving the AI data-collapse crisis.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG",
      "q-fin.TR"
    ],
    "primary_category": "cs.AI",
    "comment": "60 pages,9 figures. v3: Major update. Added 3D topological visualization (Figure 1) and independent computational verification of the Adaptive Markets Hypothesis (AMH). Includes comprehensive Supplementary Materials (algorithmic pseudocode, system architecture, and real-time GARCH logs) for technical reproducibility",
    "pdf_url": "https://arxiv.org/pdf/2512.01354v3",
    "published_date": "2025-12-01 07:09:38 UTC",
    "updated_date": "2025-12-08 22:57:17 UTC"
  },
  {
    "arxiv_id": "2512.01351v1",
    "title": "Benchmarking Overton Pluralism in LLMs",
    "authors": [
      "Elinor Poole-Dayan",
      "Jiayi Wu",
      "Taylor Sorensen",
      "Jiaxin Pei",
      "Michiel A. Bakker"
    ],
    "abstract": "We introduce a novel framework for measuring Overton pluralism in LLMs--the extent to which diverse viewpoints are represented in model outputs. We (i) formalize Overton pluralism as a set coverage metric (OvertonScore), (ii) conduct a large-scale U.S.-representative human study (N = 1209; 60 questions; 8 LLMs), and (iii) develop an automated benchmark that closely reproduces human judgments. On average, models achieve OvertonScores of 0.35--0.41, with DeepSeek V3 performing best; yet all models remain far below the theoretical maximum of 1.0, revealing substantial headroom for improvement. Because repeated large-scale human studies are costly and slow, scalable evaluation tools are essential for model development. Hence, we propose an automated benchmark that achieves high rank correlation with human judgments ($=0.88$), providing a practical proxy without replacing human assessment. By turning pluralistic alignment from a normative aim into a measurable benchmark, our work establishes a foundation for systematic progress toward more pluralistic LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01351v1",
    "published_date": "2025-12-01 07:04:20 UTC",
    "updated_date": "2025-12-01 07:04:20 UTC"
  },
  {
    "arxiv_id": "2512.01343v2",
    "title": "Intrinsic Structure as a Proxy for Saliency: SVD-Based Weight Preservation for Mixed-Precision Quantization in Large Language Models",
    "authors": [
      "Shashank Landge",
      "Abhishek Patil",
      "Tejas kamble",
      "Bhushan Buddhivant",
      "Priyanka Joshi"
    ],
    "abstract": "As Large Language Models (LLMs) continue to scale in parameter count, deploying them on commodity hardware has become increasingly challenging. Post-Training Quantization (PTQ) addresses this by reducing the precision of model weights, typically to 4-bit or lower. However, uniform quantization often leads to significant performance degradation due to the presence of ``outlier features'' -- weights that, while few in number, are critical for maintaining model accuracy. Current state-of-the-art methods such as AWQ (Activation-aware Weight Quantization) and SpQR (Sparse Quantization Representations) rely on calibration data to identify these salient weights via activation magnitudes or Hessian sensitivity. In scenarios where data privacy is paramount or calibration data is unavailable, these methods are inapplicable.\n  In this work, we propose a data-free, structure-aware hypothesis: that the weights identified as Principal Components via Singular Value Decomposition (SVD) are intrinsically important to the model's downstream performance. We introduce a novel selection heuristic that preserves the top-$k$ weights aligned with the principal components in FP32, while aggressively quantizing the residual weights. We compare our method against activation-aware (AWQ) and second-order (SpQR) methods across GLUE benchmarks (MRPC, RTE, QNLI) using a DistilBERT backbone. Our experiments reveal that structural importance is highly correlated with functional importance. On the challenging RTE task, our SVD-based method achieves an accuracy of 66.06\\%, outperforming both AWQ (65.34\\%) and SpQR (65.34\\%) at high protection budgets, validating that intrinsic matrix structure can serve as a robust proxy for weight saliency without the need for forward passes or calibration data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01343v2",
    "published_date": "2025-12-01 06:58:30 UTC",
    "updated_date": "2025-12-02 05:26:59 UTC"
  },
  {
    "arxiv_id": "2512.01335v1",
    "title": "EmoRAG: Evaluating RAG Robustness to Symbolic Perturbations",
    "authors": [
      "Xinyun Zhou",
      "Xinfeng Li",
      "Yinan Peng",
      "Ming Xu",
      "Xuanwang Zhang",
      "Miao Yu",
      "Yidong Wang",
      "Xiaojun Jia",
      "Kun Wang",
      "Qingsong Wen",
      "XiaoFeng Wang",
      "Wei Dong"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) systems are increasingly central to robust AI, enhancing large language model (LLM) faithfulness by incorporating external knowledge. However, our study unveils a critical, overlooked vulnerability: their profound susceptibility to subtle symbolic perturbations, particularly through near-imperceptible emoticon tokens such as \"(@_@)\" that can catastrophically mislead retrieval, termed EmoRAG. We demonstrate that injecting a single emoticon into a query makes it nearly 100% likely to retrieve semantically unrelated texts that contain a matching emoticon. Our extensive experiment across general question-answering and code domains, using a range of state-of-the-art retrievers and generators, reveals three key findings: (I) Single-Emoticon Disaster: Minimal emoticon injections cause maximal disruptions, with a single emoticon almost 100% dominating RAG output. (II) Positional Sensitivity: Placing an emoticon at the beginning of a query can cause severe perturbation, with F1-Scores exceeding 0.92 across all datasets. (III) Parameter-Scale Vulnerability: Counterintuitively, models with larger parameters exhibit greater vulnerability to the interference. We provide an in-depth analysis to uncover the underlying mechanisms of these phenomena. Furthermore, we raise a critical concern regarding the robustness assumption of current RAG systems, envisioning a threat scenario where an adversary exploits this vulnerability to manipulate the RAG system. We evaluate standard defenses and find them insufficient against EmoRAG. To address this, we propose targeted defenses, analyzing their strengths and limitations in mitigating emoticon-based perturbations. Finally, we outline future directions for building robust RAG systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD) 2026",
    "pdf_url": "https://arxiv.org/pdf/2512.01335v1",
    "published_date": "2025-12-01 06:53:49 UTC",
    "updated_date": "2025-12-01 06:53:49 UTC"
  },
  {
    "arxiv_id": "2512.01331v1",
    "title": "A Fast Heuristic Search Approach for Energy-Optimal Profile Routing for Electric Vehicles",
    "authors": [
      "Saman Ahmadi",
      "Mahdi Jalili"
    ],
    "abstract": "We study the energy-optimal shortest path problem for electric vehicles (EVs) in large-scale road networks, where recuperated energy along downhill segments introduces negative energy costs. While traditional point-to-point pathfinding algorithms for EVs assume a known initial energy level, many real-world scenarios involving uncertainty in available energy require planning optimal paths for all possible initial energy levels, a task known as energy-optimal profile search. Existing solutions typically rely on specialized profile-merging procedures within a label-correcting framework that results in searching over complex profiles. In this paper, we propose a simple yet effective label-setting approach based on multi-objective A* search, which employs a novel profile dominance rule to avoid generating and handling complex profiles. We develop four variants of our method and evaluate them on real-world road networks enriched with realistic energy consumption data. Experimental results demonstrate that our energy profile A* search achieves performance comparable to energy-optimal A* with a known initial energy level.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 5 Figures, 1 table, To appear as part of AAAI 2026 Proceedings",
    "pdf_url": "https://arxiv.org/pdf/2512.01331v1",
    "published_date": "2025-12-01 06:45:34 UTC",
    "updated_date": "2025-12-01 06:45:34 UTC"
  },
  {
    "arxiv_id": "2512.01321v1",
    "title": "Extending NGU to Multi-Agent RL: A Preliminary Study",
    "authors": [
      "Juan Hernandez",
      "Diego Fernndez",
      "Manuel Cifuentes",
      "Denis Parra",
      "Rodrigo Toro Icarte"
    ],
    "abstract": "The Never Give Up (NGU) algorithm has proven effective in reinforcement learning tasks with sparse rewards by combining episodic novelty and intrinsic motivation. In this work, we extend NGU to multi-agent environments and evaluate its performance in the simple_tag environment from the PettingZoo suite. Compared to a multi-agent DQN baseline, NGU achieves moderately higher returns and more stable learning dynamics. We investigate three design choices: (1) shared replay buffer versus individual replay buffers, (2) sharing episodic novelty among agents using different k thresholds, and (3) using heterogeneous values of the beta parameter. Our results show that NGU with a shared replay buffer yields the best performance and stability, highlighting that the gains come from combining NGU intrinsic exploration with experience sharing. Novelty sharing performs comparably when k = 1 but degrades learning for larger values. Finally, heterogeneous beta values do not improve over a small common value. These findings suggest that NGU can be effectively applied in multi-agent settings when experiences are shared and intrinsic exploration signals are carefully tuned.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 4 figures, 1 table. Accepted at the LatinX in AI (LXAI) Workshop at NeurIPS 2025. Includes experimental results for Multi-NGU and Multi-DQN in the PettingZoo simple_tag environment",
    "pdf_url": "https://arxiv.org/pdf/2512.01321v1",
    "published_date": "2025-12-01 06:24:37 UTC",
    "updated_date": "2025-12-01 06:24:37 UTC"
  },
  {
    "arxiv_id": "2512.01319v1",
    "title": "Rethinking Intracranial Aneurysm Vessel Segmentation: A Perspective from Computational Fluid Dynamics Applications",
    "authors": [
      "Feiyang Xiao",
      "Yichi Zhang",
      "Xigui Li",
      "Yuanye Zhou",
      "Chen Jiang",
      "Xin Guo",
      "Limei Han",
      "Yuxin Li",
      "Fengping Zhu",
      "Yuan Cheng"
    ],
    "abstract": "The precise segmentation of intracranial aneurysms and their parent vessels (IA-Vessel) is a critical step for hemodynamic analyses, which mainly depends on computational fluid dynamics (CFD). However, current segmentation methods predominantly focus on image-based evaluation metrics, often neglecting their practical effectiveness in subsequent CFD applications. To address this deficiency, we present the Intracranial Aneurysm Vessel Segmentation (IAVS) dataset, the first comprehensive, multi-center collection comprising 641 3D MRA images with 587 annotations of aneurysms and IA-Vessels. In addition to image-mask pairs, IAVS dataset includes detailed hemodynamic analysis outcomes, addressing the limitations of existing datasets that neglect topological integrity and CFD applicability. To facilitate the development and evaluation of clinically relevant techniques, we construct two evaluation benchmarks including global localization of aneurysms (Stage I) and fine-grained segmentation of IA-Vessel (Stage II) and develop a simple and effective two-stage framework, which can be used as a out-of-the-box method and strong baseline. For comprehensive evaluation of applicability of segmentation results, we establish a standardized CFD applicability evaluation system that enables the automated and consistent conversion of segmentation masks into CFD models, offering an applicability-focused assessment of segmentation outcomes. The dataset, code, and model will be public available at https://github.com/AbsoluteResonance/IAVS.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.01319v1",
    "published_date": "2025-12-01 06:23:07 UTC",
    "updated_date": "2025-12-01 06:23:07 UTC"
  },
  {
    "arxiv_id": "2512.01317v2",
    "title": "Data-Driven Learnability Transition of Measurement-Induced Entanglement",
    "authors": [
      "Dongheng Qian",
      "Jing Wang"
    ],
    "abstract": "Measurement-induced entanglement (MIE) captures how local measurements generate long-range quantum correlations and drive dynamical phase transitions in many-body systems. Yet estimating MIE experimentally remains challenging: direct evaluation requires extensive post-selection over measurement outcomes, raising the question of whether MIE is accessible with only polynomial resources. We address this challenge by reframing MIE detection as a data-driven learning problem that assumes no prior knowledge of state preparation. Using measurement records alone, we train a neural network in a self-supervised manner to predict the uncertainty metric for MIE--the gap between upper and lower bounds of the average post-measurement bipartite entanglement. Applied to random circuits with one-dimensional all-to-all connectivity and two-dimensional nearest-neighbor coupling, our method reveals a learnability transition with increasing circuit depth: below a threshold, the uncertainty is small and decreases with polynomial measurement data and model parameters, while above it the uncertainty remains large despite increasing resources. We further verify this transition experimentally on current noisy quantum devices, demonstrating its robustness to realistic noise. These results highlight the power of data-driven approaches for learning MIE and delineate the practical limits of its classical learnability.",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "7+6 pages, 4+5 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.01317v2",
    "published_date": "2025-12-01 06:18:08 UTC",
    "updated_date": "2025-12-10 06:03:04 UTC"
  },
  {
    "arxiv_id": "2512.01316v1",
    "title": "Agreement-Constrained Probabilistic Minimum Bayes Risk Decoding",
    "authors": [
      "Koki Natsumi",
      "Hiroyuki Deguchi",
      "Yusuke Sakai",
      "Hidetaka Kamigaito",
      "Taro Watanabe"
    ],
    "abstract": "Minimum Bayes risk (MBR) decoding generates high-quality translations by maximizing the expected utility of output candidates, but it evaluates all pairwise scores over the candidate set; hence, it takes quadratic time with respect to the number of candidates. To reduce the number of utility function calls, probabilistic MBR (PMBR) decoding partially evaluates quality scores using sampled pairs of candidates and completes the missing scores with a matrix completion algorithm. Nevertheless, it degrades the translation quality as the number of utility function calls is reduced. Therefore, to improve the trade-off between quality and cost, we propose agreement-constrained PMBR (AC-PMBR) decoding, which leverages a knowledge distilled model to guide the completion of the score matrix. Our AC-PMBR decoding improved approximation errors of matrix completion by up to 3 times and achieved higher translation quality compared with PMBR decoding at a comparable computational cost on the WMT'23 En$\\leftrightarrow$De translation tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "IJCNLP-AACL 2025 Main",
    "pdf_url": "https://arxiv.org/pdf/2512.01316v1",
    "published_date": "2025-12-01 06:16:47 UTC",
    "updated_date": "2025-12-01 06:16:47 UTC"
  },
  {
    "arxiv_id": "2512.01315v1",
    "title": "FOD-S2R: A FOD Dataset for Sim2Real Transfer Learning based Object Detection",
    "authors": [
      "Ashish Vashist",
      "Qiranul Saadiyean",
      "Suresh Sundaram",
      "Chandra Sekhar Seelamantula"
    ],
    "abstract": "Foreign Object Debris (FOD) within aircraft fuel tanks presents critical safety hazards including fuel contamination, system malfunctions, and increased maintenance costs. Despite the severity of these risks, there is a notable lack of dedicated datasets for the complex, enclosed environments found inside fuel tanks. To bridge this gap, we present a novel dataset, FOD-S2R, composed of real and synthetic images of the FOD within a simulated aircraft fuel tank. Unlike existing datasets that focus on external or open-air environments, our dataset is the first to systematically evaluate the effectiveness of synthetic data in enhancing the real-world FOD detection performance in confined, closed structures. The real-world subset consists of 3,114 high-resolution HD images captured in a controlled fuel tank replica, while the synthetic subset includes 3,137 images generated using Unreal Engine. The dataset is composed of various Field of views (FOV), object distances, lighting conditions, color, and object size. Prior research has demonstrated that synthetic data can reduce reliance on extensive real-world annotations and improve the generalizability of vision models. Thus, we benchmark several state-of-the-art object detection models and demonstrate that introducing synthetic data improves the detection accuracy and generalization to real-world conditions. These experiments demonstrate the effectiveness of synthetic data in enhancing the model performance and narrowing the Sim2Real gap, providing a valuable foundation for developing automated FOD detection systems for aviation maintenance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 11 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.01315v1",
    "published_date": "2025-12-01 06:16:26 UTC",
    "updated_date": "2025-12-01 06:16:26 UTC"
  },
  {
    "arxiv_id": "2512.01311v2",
    "title": "CuES: A Curiosity-driven and Environment-grounded Synthesis Framework for Agentic RL",
    "authors": [
      "Shinji Mai",
      "Yunpeng Zhai",
      "Ziqian Chen",
      "Cheng Chen",
      "Anni Zou",
      "Shuchang Tao",
      "Zhaoyang Liu",
      "Bolin Ding"
    ],
    "abstract": "Large language model based agents are increasingly deployed in complex, tool augmented environments. While reinforcement learning provides a principled mechanism for such agents to improve through interaction, its effectiveness critically depends on the availability of structured training tasks. In many realistic settings, however, no such tasks exist a challenge we term task scarcity, which has become a key bottleneck for scaling agentic RL. Existing approaches typically assume predefined task collections, an assumption that fails in novel environments where tool semantics and affordances are initially unknown. To address this limitation, we formalize the problem of Task Generation for Agentic RL, where an agent must learn within a given environment that lacks predefined tasks. We propose CuES, a Curiosity driven and Environment grounded Synthesis framework that autonomously generates diverse, executable, and meaningful tasks directly from the environment structure and affordances, without relying on handcrafted seeds or external corpora. CuES drives exploration through intrinsic curiosity, abstracts interaction patterns into reusable task schemas, and refines them through lightweight top down guidance and memory based quality control. Across three representative environments, AppWorld, BFCL, and WebShop, CuES produces task distributions that match or surpass manually curated datasets in both diversity and executability, yielding substantial downstream policy improvements. These results demonstrate that curiosity driven, environment grounded task generation provides a scalable foundation for agents that not only learn how to act, but also learn what to learn. The code is available at https://github.com/modelscope/AgentEvolver/tree/main/research/CuES.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01311v2",
    "published_date": "2025-12-01 06:11:37 UTC",
    "updated_date": "2025-12-03 09:53:18 UTC"
  },
  {
    "arxiv_id": "2512.01300v1",
    "title": "RoboDriveVLM: A Novel Benchmark and Baseline towards Robust Vision-Language Models for Autonomous Driving",
    "authors": [
      "Dacheng Liao",
      "Mengshi Qi",
      "Peng Shu",
      "Zhining Zhang",
      "Yuxin Lin",
      "Liang Liu",
      "Huadong Ma"
    ],
    "abstract": "Current Vision-Language Model (VLM)-based end-to-end autonomous driving systems often leverage large language models to generate driving decisions directly based on their understanding of the current scene. However, such systems introduce multiple risks in real-world driving scenarios. To evaluate whether VLMs are truly viable for autonomous driving, we introduce RoboDriveBench, the first robustness benchmark focused on end-to-end trajectory prediction tasks. This benchmark systematically evaluates two critical categories of real-world challenges for VLM-based end-to-end autonomous driving systems through 11 simulated scenarios encompassing various corruption types, including 6 scenarios of sensor corruption caused by environmental variations, along with 5 cases of prompt corruption resulting from human intervention and data transmission failures. Each corruption type includes 250 unique driving scenarios and 5,689 frames, resulting in 64,559 total trajectory prediction cases per evaluation. To overcome these real-world challenges, we propose a novel VLM-based autonomous driving framework called RoboDriveVLM, which enhances robustness by mapping more multimodal data-e.g., lidar and radar-into a unified latent space. Furthermore, we introduce a new Test-Time Adaptation (TTA) method based on cross-modal knowledge distillation to improve the robustness of VLM-based autonomous driving systems. Through extensive experiments, our work highlights the limitations of current VLM-based end-to-end autonomous driving systems and provides a more reliable solution for real-world deployment. Source code and datasets will be released.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01300v1",
    "published_date": "2025-12-01 05:44:06 UTC",
    "updated_date": "2025-12-01 05:44:06 UTC"
  },
  {
    "arxiv_id": "2512.01292v2",
    "title": "Diffusion Model in Latent Space for Medical Image Segmentation Task",
    "authors": [
      "Huynh Trinh Ngoc",
      "Toan Nguyen Hai",
      "Ba Luong Son",
      "Long Tran Quoc"
    ],
    "abstract": "Medical image segmentation is crucial for clinical diagnosis and treatment planning. Traditional methods typically produce a single segmentation mask, failing to capture inherent uncertainty. Recent generative models enable the creation of multiple plausible masks per image, mimicking the collaborative interpretation of several clinicians. However, these approaches remain computationally heavy. We propose MedSegLatDiff, a diffusion based framework that combines a variational autoencoder (VAE) with a latent diffusion model for efficient medical image segmentation. The VAE compresses the input into a low dimensional latent space, reducing noise and accelerating training, while the diffusion process operates directly in this compact representation. We further replace the conventional MSE loss with weighted cross entropy in the VAE mask reconstruction path to better preserve tiny structures such as small nodules. MedSegLatDiff is evaluated on ISIC-2018 (skin lesions), CVC-Clinic (polyps), and LIDC-IDRI (lung nodules). It achieves state of the art or highly competitive Dice and IoU scores while simultaneously generating diverse segmentation hypotheses and confidence maps. This provides enhanced interpretability and reliability compared to deterministic baselines, making the model particularly suitable for clinical deployment.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01292v2",
    "published_date": "2025-12-01 05:26:43 UTC",
    "updated_date": "2025-12-02 02:55:31 UTC"
  },
  {
    "arxiv_id": "2512.01289v1",
    "title": "OntoMetric: An Ontology-Guided Framework for Automated ESG Knowledge Graph Construction",
    "authors": [
      "Mingqin Yu",
      "Fethi Rabhi",
      "Boming Xia",
      "Zhengyi Yang",
      "Felix Tan",
      "Qinghua Lu"
    ],
    "abstract": "Environmental, Social, and Governance (ESG) disclosure frameworks such as SASB, TCFD, and IFRS S2 require organizations to compute and report numerous metrics for compliance, yet these requirements are embedded in long, unstructured PDF documents that are difficult to interpret, standardize, and audit. Manual extraction is unscalable, while unconstrained large language model (LLM) extraction often produces inconsistent entities, hallucinated relationships, missing provenance, and high validation failure rates. We present OntoMetric, an ontology-guided framework that transforms ESG regulatory documents into validated, AI- and web-ready knowledge graphs. OntoMetric operates through a three-stage pipeline: (1) structure-aware segmentation using table-of-contents boundaries, (2) ontology-constrained LLM extraction that embeds the ESGMKG schema into prompts while enriching entities with semantic fields for downstream reasoning, and (3) two-phase validation that combines LLM-based semantic verification with rule-based schema checking across entity, property, and relationship levels (VR001-VR006). The framework preserves both segment-level and page-level provenance for audit traceability. Evaluated on five ESG standards (SASB Commercial Banks, SASB Semiconductors, TCFD, IFRS S2, AASB S2) totaling 228 pages and 60 segments, OntoMetric achieves 65-90% semantic accuracy and 80-90% schema compliance, compared to 3-10% for baseline unconstrained extraction, at approximately 0.01 to 0.02 USD per validated entity. Our results demonstrate that combining symbolic ontology constraints with neural extraction enables reliable, auditable knowledge graphs suitable for regulatory compliance and web integration, supporting downstream applications such as sustainable-finance analytics, transparency portals, and automated compliance tools.",
    "categories": [
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01289v1",
    "published_date": "2025-12-01 05:21:22 UTC",
    "updated_date": "2025-12-01 05:21:22 UTC"
  },
  {
    "arxiv_id": "2512.01286v1",
    "title": "Generative Modeling with Continuous Flows: Sample Complexity of Flow Matching",
    "authors": [
      "Mudit Gaur",
      "Prashant Trivedi",
      "Shuchin Aeron",
      "Amrit Singh Bedi",
      "George K. Atia",
      "Vaneet Aggarwal"
    ],
    "abstract": "Flow matching has recently emerged as a promising alternative to diffusion-based generative models, offering faster sampling and simpler training by learning continuous flows governed by ordinary differential equations. Despite growing empirical success, the theoretical understanding of flow matching remains limited, particularly in terms of sample complexity results. In this work, we provide the first analysis of the sample complexity for flow-matching based generative models without assuming access to the empirical risk minimizer (ERM) of the loss function for estimating the velocity field. Under standard assumptions on the loss function for velocity field estimation and boundedness of the data distribution, we show that a sufficiently expressive neural network can learn a velocity field such that with $\\mathcal{O}(^{-4})$ samples, such that the Wasserstein-2 distance between the learned and the true distribution is less than $\\mathcal{O}()$. The key technical idea is to decompose the velocity field estimation error into neural-network approximation error, statistical error due to the finite sample size, and optimization error due to the finite number of optimization steps for estimating the velocity field. Each of these terms are then handled via techniques that may be of independent interest.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01286v1",
    "published_date": "2025-12-01 05:14:25 UTC",
    "updated_date": "2025-12-01 05:14:25 UTC"
  },
  {
    "arxiv_id": "2512.04113v1",
    "title": "AI-Enabled grading with near-domain data for scaling feedback with human-level accuracy",
    "authors": [
      "Shyam Agarwal",
      "Ali Moghimi",
      "Kevin C. Haudek"
    ],
    "abstract": "Constructed-response questions are crucial to encourage generative processing and test a learner's understanding of core concepts. However, the limited availability of instructor time, large class sizes, and other resource constraints pose significant challenges in providing timely and detailed evaluation, which is crucial for a holistic educational experience. In addition, providing timely and frequent assessments is challenging since manual grading is labor intensive, and automated grading is complex to generalize to every possible response scenario. This paper proposes a novel and practical approach to grade short-answer constructed-response questions. We discuss why this problem is challenging, define the nature of questions on which our method works, and finally propose a framework that instructors can use to evaluate their students' open-responses, utilizing near-domain data like data from similar questions administered in previous years. The proposed method outperforms the state of the art machine learning models as well as non-fine-tuned large language models like GPT 3.5, GPT 4, and GPT 4o by a considerable margin of over 10-20% in some cases, even after providing the LLMs with reference/model answers. Our framework does not require pre-written grading rubrics and is designed explicitly with practical classroom settings in mind. Our results also reveal exciting insights about learning from near-domain data, including what we term as accuracy and data advantages using human-labeled data, and we believe this is the first work to formalize the problem of automated short answer grading based on the near-domain data.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.04113v1",
    "published_date": "2025-12-01 05:11:37 UTC",
    "updated_date": "2025-12-01 05:11:37 UTC"
  },
  {
    "arxiv_id": "2512.01282v2",
    "title": "Kardia-R1: Unleashing LLMs to Reason toward Understanding and Empathy for Emotional Support via Rubric-as-Judge Reinforcement Learning",
    "authors": [
      "Jiahao Yuan",
      "Zhiqing Cui",
      "Hanqing Wang",
      "Yuansheng Gao",
      "Yucheng Zhou",
      "Usman Naseem"
    ],
    "abstract": "As web platforms evolve towards greater personalization and emotional complexity, conversational agents must transcend superficial empathy to demonstrate identity-aware emotional reasoning. However, existing systems face two limitations: (1) reliance on situation-centric datasets lacking persistent user identity, which hampers the capture of personalized affective nuances; and (2) dependence on opaque, coarse reward signals that hinder development of verifiable empathetic reasoning. To address these gaps, we introduce KardiaBench, a large-scale user-grounded benchmark comprising 178,080 QA pairs across 22,080 multi-turn conversations anchored to 671 real-world profiles. The dataset is constructed via a model-in-the-loop pipeline with iterative rubric-guided refinement to ensure psychological plausibility and persona consistency. This progressive empathy pipeline that integrates user comprehension, contextual reasoning, and emotion perception into conversations, followed by iterative critique and rubric-based refinement to ensure psychological plausibility, emotional fidelity, and persona consistency. Building on this, we propose Kardia-R1, a framework that trains models for interpretable, stepwise empathetic cognition. Kardia-R1 leverages Rubric-as-Judge Empathetic Reinforcement Learning (Rubric-ERL), a GRPO-based method that uses explainable, human-aligned rubric rewards to tightly couple user understanding, emotional inference, and supportive response generation. Extensive experiments across four LLM backbones demonstrate that Kardia-R1 consistently outperforms othet methods in emotion accuracy, empathy, relevance, persona consistency, and safety. Our dataset and model will be released at https://github.com/JhCircle/Kardia-R1.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01282v2",
    "published_date": "2025-12-01 04:54:03 UTC",
    "updated_date": "2025-12-02 08:43:56 UTC"
  },
  {
    "arxiv_id": "2512.01278v1",
    "title": "Accelerating Large-Scale Reasoning Model Inference with Sparse Self-Speculative Decoding",
    "authors": [
      "Yilong Zhao",
      "Jiaming Tang",
      "Kan Zhu",
      "Zihao Ye",
      "Chi-Chih Chang",
      "Chaofan Lin",
      "Jongseok Park",
      "Guangxuan Xiao",
      "Mohamed S. Abdelfattah",
      "Mingyu Gao",
      "Baris Kasikci",
      "Song Han",
      "Ion Stoica"
    ],
    "abstract": "Reasoning language models have demonstrated remarkable capabilities on challenging tasks by generating elaborate chain-of-thought (CoT) solutions. However, such lengthy generation shifts the inference bottleneck from compute-bound to memory-bound. To generate each token, the model applies full attention to all previously generated tokens, requiring memory access to an increasingly large KV-Cache. Consequently, longer generations demand more memory access for every step, leading to substantial pressure on memory bandwidth.\n  To address this, we introduce SparseSpec, a speculative decoding framework that reuses the same model as the draft and target models (i.e., self-speculation). SparseSpec features a novel sparse attention mechanism, PillarAttn, as the draft model, which accurately selects critical tokens via elegantly reusing information from the verification stage. Furthermore, SparseSpec co-designs self-speculation with three system innovations: (1) a unified scheduler to batch token drafting and verification, (2) delayed verification for CPU/GPU overlap, and (3) dynamic KV-Cache management to maximize memory utilization. Across various models and datasets, SparseSpec outperforms state-of-the-art solutions, with an up to 2.13x throughput speedup.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01278v1",
    "published_date": "2025-12-01 04:50:55 UTC",
    "updated_date": "2025-12-01 04:50:55 UTC"
  },
  {
    "arxiv_id": "2512.01274v1",
    "title": "SUPERChem: A Multimodal Reasoning Benchmark in Chemistry",
    "authors": [
      "Zehua Zhao",
      "Zhixian Huang",
      "Junren Li",
      "Siyu Lin",
      "Junting Zhou",
      "Fengqi Cao",
      "Kun Zhou",
      "Rui Ge",
      "Tingting Long",
      "Yuexiang Zhu",
      "Yan Liu",
      "Jie Zheng",
      "Junnian Wei",
      "Rong Zhu",
      "Peng Zou",
      "Wenyu Li",
      "Zekai Cheng",
      "Tian Ding",
      "Yaxuan Wang",
      "Yizhao Yan",
      "Tingru Wei",
      "Haowei Ming",
      "Weijie Mao",
      "Chen Sun",
      "Yiming Liu",
      "Zichen Wang",
      "Zuo Zhang",
      "Tong Yang",
      "Hao Ma",
      "Zhen Gao",
      "Jian Pei"
    ],
    "abstract": "Current benchmarks for evaluating the chemical reasoning capabilities of Large Language Models (LLMs) are limited by oversimplified tasks, lack of process-level evaluation, and misalignment with expert-level chemistry skills. To address these issues, we introduce SUPERChem, a benchmark of 500 expert-curated reasoning-intensive chemistry problems, covering diverse subfields and provided in both multimodal and text-only formats. Original content and an iterative curation pipeline eliminate flawed items and mitigate data contamination. Each problem is paired with an expert-authored solution path, enabling Reasoning Path Fidelity (RPF) scoring to evaluate reasoning quality beyond final-answer accuracy. Evaluations against a human baseline of 40.3% accuracy show that even the best-performing model, GPT-5 (High), reaches only 38.5%, followed closely by Gemini 2.5 Pro (37.9%) and DeepSeek-V3.1-Think (37.3%). SUPERChem elicits multi-step, multimodal reasoning, reveals model-dependent effects of visual information, and distinguishes high-fidelity reasoners from heuristic ones. By providing a challenging benchmark and a reliable evaluation framework, SUPERChem aims to facilitate the advancement of LLMs toward expert-level chemical intelligence. The dataset of the benchmark is available at https://huggingface.co/datasets/ZehuaZhao/SUPERChem.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "35 pages, 11 figures, 5 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.01274v1",
    "published_date": "2025-12-01 04:46:35 UTC",
    "updated_date": "2025-12-01 04:46:35 UTC"
  },
  {
    "arxiv_id": "2512.01262v1",
    "title": "Social Media Data Mining of Human Behaviour during Bushfire Evacuation",
    "authors": [
      "Junfeng Wu",
      "Xiangmin Zhou",
      "Erica Kuligowski",
      "Dhirendra Singh",
      "Enrico Ronchi",
      "Max Kinateder"
    ],
    "abstract": "Traditional data sources on bushfire evacuation behaviour, such as quantitative surveys and manual observations have severe limitations. Mining social media data related to bushfire evacuations promises to close this gap by allowing the collection and processing of a large amount of behavioural data, which are low-cost, accurate, possibly including location information and rich contextual information. However, social media data have many limitations, such as being scattered, incomplete, informal, etc. Together, these limitations represent several challenges to their usefulness to better understand bushfire evacuation. To overcome these challenges and provide guidance on which and how social media data can be used, this scoping review of the literature reports on recent advances in relevant data mining techniques. In addition, future applications and open problems are discussed. We envision future applications such as evacuation model calibration and validation, emergency communication, personalised evacuation training, and resource allocation for evacuation preparedness. We identify open problems such as data quality, bias and representativeness, geolocation accuracy, contextual understanding, crisis-specific lexicon and semantics, and multimodal data interpretation.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01262v1",
    "published_date": "2025-12-01 04:13:29 UTC",
    "updated_date": "2025-12-01 04:13:29 UTC"
  },
  {
    "arxiv_id": "2512.01256v1",
    "title": "Sentiment Analysis and Emotion Classification using Machine Learning Techniques for Nagamese Language -- A Low-resource Language",
    "authors": [
      "Ekha Morang",
      "Surhoni A. Ngullie",
      "Sashienla Longkumer",
      "Teisovi Angami"
    ],
    "abstract": "The Nagamese language, a.k.a Naga Pidgin, is an Assamese-lexified creole language developed primarily as a means of communication in trade between the people from Nagaland and people from Assam in the north-east India. Substantial amount of work in sentiment analysis has been done for resource-rich languages like English, Hindi, etc. However, no work has been done in Nagamese language. To the best of our knowledge, this is the first attempt on sentiment analysis and emotion classification for the Nagamese Language. The aim of this work is to detect sentiments in terms of polarity (positive, negative and neutral) and basic emotions contained in textual content of Nagamese language. We build sentiment polarity lexicon of 1,195 nagamese words and use these to build features along with additional features for supervised machine learning techniques using Na\"ive Bayes and Support Vector Machines.\n  Keywords: Nagamese, NLP, sentiment analysis, machine learning",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages",
    "pdf_url": "https://arxiv.org/pdf/2512.01256v1",
    "published_date": "2025-12-01 04:01:29 UTC",
    "updated_date": "2025-12-01 04:01:29 UTC"
  },
  {
    "arxiv_id": "2512.17917v1",
    "title": "KVReviver: Reversible KV Cache Compression with Sketch-Based Token Reconstruction",
    "authors": [
      "Aomufei Yuan",
      "Zhiming Wang",
      "Ruijie Miao",
      "Dayu Wang",
      "Yuxuan Tian",
      "Zihan Wang",
      "Yebo Peng",
      "Yuhan Wu",
      "Bairen Yi",
      "Xin Liu",
      "Tong Yang"
    ],
    "abstract": "As the context length of current large language models (LLMs) rapidly increases, the memory demand for the Key-Value (KV) cache is becoming a bottleneck for LLM deployment and batch processing. Traditional KV cache compression methods typically involve permanently evicting or irreversibly merging \"less important\" tokens with low attention scores. This approach results in the unrecoverable loss of token information, which we call Contextual Amnesia, significantly degrading the model's information retrieval capability. To address this issue, we propose KVReviver, a reversible KV cache compression method based on the sketch algorithm. This method allows reconstructing compressed tokens from an additional data structure, thus enabling full-scale computation within limited memory. Experiments showed that in 2k-length contexts, it requires only 10% of KV Cache budget while maintaining identical end-to-end inference accuracy. For 32k-length contexts, it achieves equivalent or comparable accuracy ~2% accuracy loss) using merely 25% of KV Cache budget.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.17917v1",
    "published_date": "2025-12-01 03:59:20 UTC",
    "updated_date": "2025-12-01 03:59:20 UTC"
  },
  {
    "arxiv_id": "2512.01249v1",
    "title": "Pascal-Weighted Genetic Algorithms: A Binomially-Structured Recombination Framework",
    "authors": [
      "Otman A. Basir"
    ],
    "abstract": "This paper introduces a new family of multi-parent recombination operators for Genetic Algorithms (GAs), based on normalized Pascal (binomial) coefficients. Unlike classical two-parent crossover operators, Pascal-Weighted Recombination (PWR) forms offsprings as structured convex combination of multiple parents, using binomially shaped weights that emphasize central inheritance while suppressing disruptive variance. We develop a mathematical framework for PWR, derive variance-transfer properties, and analyze its effect on schema survival. The operator is extended to real-valued, binary/logit, and permutation representations.\n  We evaluate the proposed method on four representative benchmarks: (i) PID controller tuning evaluated using the ITAE metric, (ii) FIR low-pass filter design under magnitude-response constraints, (iii) wireless power-modulation optimization under SINR coupling, and (iv) the Traveling Salesman Problem (TSP). We demonstrate how, across these benchmarks, PWR consistently yields smoother convergence, reduced variance, and achieves 9-22% performance gains over standard recombination operators. The approach is simple, algorithm-agnostic, and readily integrable into diverse GA architectures.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.NE",
    "comment": "23 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.01249v1",
    "published_date": "2025-12-01 03:51:29 UTC",
    "updated_date": "2025-12-01 03:51:29 UTC"
  },
  {
    "arxiv_id": "2512.01242v2",
    "title": "Generative Adversarial Gumbel MCTS for Abstract Visual Composition Generation",
    "authors": [
      "Zirui Zhao",
      "Boye Niu",
      "David Hsu",
      "Wee Sun Lee"
    ],
    "abstract": "We study abstract visual composition, in which identity is primarily determined by the spatial configuration and relations among a small set of geometric primitives (e.g., parts, symmetry, topology). They are invariant primarily to texture and photorealistic detail. Composing such structures from fixed components under geometric constraints and vague goal specification (such as text) is non-trivial due to combinatorial placement choices, limited data, and discrete feasibility (overlap-free, allowable orientations), which create a sparse solution manifold ill-suited to purely statistical pixel-space generators. We propose a constraint-guided framework that combines explicit geometric reasoning with neural semantics. An AlphaGo-style search enforces feasibility, while a fine-tuned vision-language model scores semantic alignment as reward signals. Our algorithm uses a policy network as a heuristic in Monte-Carlo Tree Search and fine-tunes the network via search-generated plans. Inspired by the Generative Adversarial Network, we use the generated instances for adversarial reward refinement. Over time, the generation should approach the actual data more closely when the reward model cannot distinguish between generated instances and ground-truth. In the Tangram Assembly task, our approach yields higher validity and semantic fidelity than diffusion and auto-regressive baselines, especially as constraints tighten.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01242v2",
    "published_date": "2025-12-01 03:38:44 UTC",
    "updated_date": "2026-01-15 07:18:11 UTC"
  },
  {
    "arxiv_id": "2512.01241v2",
    "title": "First, do NOHARM: towards clinically safe large language models",
    "authors": [
      "David Wu",
      "Fateme Nateghi Haredasht",
      "Saloni Kumar Maharaj",
      "Priyank Jain",
      "Jessica Tran",
      "Matthew Gwiazdon",
      "Arjun Rustagi",
      "Jenelle Jindal",
      "Jacob M. Koshy",
      "Vinay Kadiyala",
      "Anup Agarwal",
      "Bassman Tappuni",
      "Brianna French",
      "Sirus Jesudasen",
      "Christopher V. Cosgriff",
      "Rebanta Chakraborty",
      "Jillian Caldwell",
      "Susan Ziolkowski",
      "David J. Iberri",
      "Robert Diep",
      "Rahul S. Dalal",
      "Kira L. Newman",
      "Kristin Galetta",
      "J. Carl Pallais",
      "Nancy Wei",
      "Kathleen M. Buchheit",
      "David I. Hong",
      "Ernest Y. Lee",
      "Allen Shih",
      "Vartan Pahalyants",
      "Tamara B. Kaplan",
      "Vishnu Ravi",
      "Sarita Khemani",
      "April S. Liang",
      "Daniel Shirvani",
      "Advait Patil",
      "Nicholas Marshall",
      "Kanav Chopra",
      "Joel Koh",
      "Adi Badhwar",
      "Liam G. McCoy",
      "David J. H. Wu",
      "Yingjie Weng",
      "Sumant Ranji",
      "Kevin Schulman",
      "Nigam H. Shah",
      "Jason Hom",
      "Arnold Milstein",
      "Adam Rodman",
      "Jonathan H. Chen",
      "Ethan Goh"
    ],
    "abstract": "Large language models (LLMs) are routinely used by physicians and patients for medical advice, yet their clinical safety profiles remain poorly characterized. We present NOHARM (Numerous Options Harm Assessment for Risk in Medicine), a benchmark using 100 real primary care-to-specialist consultation cases to measure frequency and severity of harm from LLM-generated medical recommendations. NOHARM covers 10 specialties, with 12,747 expert annotations for 4,249 clinical management options. Across 31 LLMs, potential for severe harm from LLM recommendations occurs in up to 22.2% (95% CI 21.6-22.8%) of cases, with harm of omission accounting for 76.6% (95% CI 76.4-76.8%) of errors. Safety performance is only moderately correlated (r = 0.61-0.64) with existing AI and medical knowledge benchmarks. The best models outperform generalist physicians on safety (mean difference 9.7%, 95% CI 7.0-12.5%), and a diverse multi-agent approach improves safety compared to solo models (mean difference 8.0%, 95% CI 4.0-12.1%). Therefore, despite strong performance on existing evaluations, widely used AI models can produce severely harmful medical advice at nontrivial rates, underscoring clinical safety as a distinct performance dimension necessitating explicit measurement.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01241v2",
    "published_date": "2025-12-01 03:33:16 UTC",
    "updated_date": "2025-12-17 21:54:50 UTC"
  },
  {
    "arxiv_id": "2512.01234v2",
    "title": "Proactive Agentic Whiteboards: Enhancing Diagrammatic Learning",
    "authors": [
      "Suveen Ellawela",
      "Sashenka Gamage",
      "Dinithi Dissanayake"
    ],
    "abstract": "Educators frequently rely on diagrams to explain complex concepts during lectures, yet creating clear and complete visual representations in real time while simultaneously speaking can be cognitively demanding. Incomplete or unclear diagrams may hinder student comprehension, as learners must mentally reconstruct missing information while following the verbal explanation. Inspired by advances in code completion tools, we introduce DrawDash, an AI-powered whiteboard assistant that proactively completes and refines educational diagrams through multimodal understanding. DrawDash adopts a TAB-completion interaction model: it listens to spoken explanations, detects intent, and dynamically suggests refinements that can be accepted with a single keystroke. We demonstrate DrawDash across four diverse teaching scenarios, spanning topics from computer science and web development to biology. This work represents an early exploration into reducing instructors' cognitive load and improving diagram-based pedagogy through real-time, speech-driven visual assistance, and concludes with a discussion of current limitations and directions for formal classroom evaluation.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01234v2",
    "published_date": "2025-12-01 03:20:12 UTC",
    "updated_date": "2025-12-02 03:13:40 UTC"
  },
  {
    "arxiv_id": "2512.01232v1",
    "title": "LLM-as-a-Judge for Scalable Test Coverage Evaluation: Accuracy, Operational Reliability, and Cost",
    "authors": [
      "Donghao Huang",
      "Shila Chew",
      "Anna Dutkiewicz",
      "Zhaoxia Wang"
    ],
    "abstract": "Assessing software test coverage at scale remains a bottleneck in QA pipelines. We present LLM-as-a-Judge (LAJ), a production-ready, rubric-driven framework for evaluating Gherkin acceptance tests with structured JSON outputs. Across 20 model configurations (GPT-4, GPT-5 with varying reasoning effort, and open-weight models) on 100 expert-annotated scripts over 5 runs (500 evaluations), we provide the first comprehensive analysis spanning accuracy, operational reliability, and cost. We introduce the Evaluation Completion Rate (ECR@1) to quantify first-attempt success, revealing reliability from 85.4% to 100.0% with material cost implications via retries. Results show that smaller models can outperform larger ones: GPT-4o Mini attains the best accuracy (6.07 MAAE), high reliability (96.6% ECR@1), and low cost ($1.01 per 1K), yielding a 78x cost reduction vs. GPT-5 (high reasoning) while improving accuracy. Reasoning effort is model-family dependent: GPT-5 benefits from increased reasoning (with predictable accuracy-cost tradeoffs), whereas open-weight models degrade across all dimensions as reasoning increases. Overall, cost spans 175x ($0.45-$78.96 per 1K). We release the dataset, framework, and code to support reproducibility and deployment.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "7 pages, accepted by the AAAI 2026 Workshop on Next Gen Code Development with Collaborative AI Agents",
    "pdf_url": "https://arxiv.org/pdf/2512.01232v1",
    "published_date": "2025-12-01 03:19:33 UTC",
    "updated_date": "2025-12-01 03:19:33 UTC"
  },
  {
    "arxiv_id": "2512.20632v1",
    "title": "Erkang-Diagnosis-1.1 Technical Report",
    "authors": [
      "Jianbing Ma",
      "Ao Feng",
      "Zhenjie Gao",
      "Xinyu Song",
      "Li Su",
      "Bin Chen",
      "Wei Wang",
      "Jiamin Wu"
    ],
    "abstract": "This report provides a detailed introduction to Erkang-Diagnosis-1.1 model, our AI healthcare consulting assistant developed using Alibaba Qwen-3 model. The Erkang model integrates approximately 500GB of high-quality structured medical knowledge, employing a hybrid approach combining enhanced pre-training and retrieval-enhanced generation to create a secure, reliable, and professional AI health advisor. Through 3-5 efficient interaction rounds, Erkang Diagnosis can accurately understand user symptoms, conduct preliminary analysis, and provide valuable diagnostic suggestions and health guidance. Designed to become users intelligent health companions, it empowers primary healthcare and health management. To validate, Erkang-Diagnosis-1.1 leads GPT-4 in terms of comprehensive medical exams.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages; 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.20632v1",
    "published_date": "2025-12-01 03:09:53 UTC",
    "updated_date": "2025-12-01 03:09:53 UTC"
  },
  {
    "arxiv_id": "2512.01223v1",
    "title": "S$^2$-MLLM: Boosting Spatial Reasoning Capability of MLLMs for 3D Visual Grounding with Structural Guidance",
    "authors": [
      "Beining Xu",
      "Siting Zhu",
      "Zhao Jin",
      "Junxian Li",
      "Hesheng Wang"
    ],
    "abstract": "3D Visual Grounding (3DVG) focuses on locating objects in 3D scenes based on natural language descriptions, serving as a fundamental task for embodied AI and robotics. Recent advances in Multi-modal Large Language Models (MLLMs) have motivated research into extending them to 3DVG. However, MLLMs primarily process 2D visual inputs and struggle with understanding 3D spatial structure of scenes solely from these limited perspectives. Existing methods mainly utilize viewpoint-dependent rendering of reconstructed point clouds to provide explicit structural guidance for MLLMs in 3DVG tasks, leading to inefficiency and limited spatial reasoning. To address this issue, we propose S$^2$-MLLM, an efficient framework that enhances spatial reasoning in MLLMs through implicit spatial reasoning. We introduce a spatial guidance strategy that leverages the structure awareness of feed-forward 3D reconstruction. By acquiring 3D structural understanding during training, our model can implicitly reason about 3D scenes without relying on inefficient point cloud reconstruction. Moreover, we propose a structure-enhanced module (SE), which first employs intra-view and inter-view attention mechanisms to capture dependencies within views and correspondences across views. The module further integrates multi-level position encoding to associate visual representations with spatial positions and viewpoint information, enabling more accurate structural understanding. Extensive experiments demonstrate that S$^2$-MLLM unifies superior performance, generalization, and efficiency, achieving significant performance over existing methods across the ScanRefer, Nr3D, and Sr3D datasets. Code will be available upon acceptance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.01223v1",
    "published_date": "2025-12-01 03:08:34 UTC",
    "updated_date": "2025-12-01 03:08:34 UTC"
  },
  {
    "arxiv_id": "2512.01222v2",
    "title": "Unsupervised decoding of encoded reasoning using language model interpretability",
    "authors": [
      "Ching Fang",
      "Samuel Marks"
    ],
    "abstract": "As large language models become increasingly capable, there is growing concern that they may develop reasoning processes that are encoded or hidden from human oversight. To investigate whether current interpretability techniques can penetrate such encoded reasoning, we construct a controlled testbed by fine-tuning a reasoning model (DeepSeek-R1-Distill-Llama-70B) to perform chain-of-thought reasoning in ROT-13 encryption while maintaining intelligible English outputs. We evaluate mechanistic interpretability methods--in particular, logit lens analysis--on their ability to decode the model's hidden reasoning process using only internal activations. We show that logit lens can effectively translate encoded reasoning, with accuracy peaking in intermediate-to-late layers. Finally, we develop a fully unsupervised decoding pipeline that combines logit lens with automated paraphrasing, achieving substantial accuracy in reconstructing complete reasoning transcripts from internal model representations. These findings suggest that current mechanistic interpretability techniques may be more robust to simple forms of encoded reasoning than previously understood. Our work provides an initial framework for evaluating interpretability methods against models that reason in non-human-readable formats, contributing to the broader challenge of maintaining oversight over increasingly capable AI systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Modifying author contact information",
    "pdf_url": "https://arxiv.org/pdf/2512.01222v2",
    "published_date": "2025-12-01 03:05:20 UTC",
    "updated_date": "2025-12-06 00:36:45 UTC"
  },
  {
    "arxiv_id": "2512.01219v1",
    "title": "Neural Network Optimal Power Flow via Energy Gradient Flow and Unified Dynamics",
    "authors": [
      "Xuezhi Liu"
    ],
    "abstract": "Optimal Power Flow (OPF) is a core optimization problem in power system operation and planning, aiming to minimize generation costs while satisfying physical constraints such as power flow equations, generator limits, and voltage limits. Traditional OPF solving methods typically employ iterative optimization algorithms (such as interior point methods, sequential quadratic programming, etc.), with limitations including low computational efficiency, initial value sensitivity, and low batch computation efficiency. Most existing deep learning-based OPF methods rely on supervised learning, requiring pre-solving large numbers of cases, and have difficulty guaranteeing physical consistency. This paper proposes an Optimal Power Flow solving method based on neural network dynamics and energy gradient flow, transforming OPF problems into energy minimization problems. By constructing an energy function to measure the degree of deviation from the constraint manifold, and guiding networks to learn optimal solutions that simultaneously satisfy power flow constraints and minimize costs through gradient flow. Neural networks are trained unsupervised by directly minimizing physical residuals, requiring no labeled data, achieving true \"end-to-end\" physics-constrained learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01219v1",
    "published_date": "2025-12-01 02:59:47 UTC",
    "updated_date": "2025-12-01 02:59:47 UTC"
  },
  {
    "arxiv_id": "2512.01218v1",
    "title": "How do trout regulate patterns of muscle contraction to optimize propulsive efficiency during steady swimming",
    "authors": [
      "Tao Li",
      "Chunze Zhang",
      "Weiwei Yao",
      "Junzhao He",
      "Ji Hou",
      "Qin Zhou",
      "Lu Zhang"
    ],
    "abstract": "Understanding efficient fish locomotion offers insights for biomechanics, fluid dynamics, and engineering. Traditional studies often miss the link between neuromuscular control and whole-body movement. To explore energy transfer in carangiform swimming, we created a bio-inspired digital trout. This model combined multibody dynamics, Hill-type muscle modeling, and a high-fidelity fluid-structure interaction algorithm, accurately replicating a real trout's form and properties. Using deep reinforcement learning, the trout's neural system achieved hierarchical spatiotemporal control of muscle activation. We systematically examined how activation strategies affect speed and energy use. Results show that axial myomere coupling-with activation spanning over 0.5 body lengths-is crucial for stable body wave propagation. Moderate muscle contraction duration ([0.1,0.3] of a tail-beat cycle) lets the body and fluid act as a passive damping system, cutting energy use. Additionally, the activation phase lag of myomeres shapes the body wave; if too large, it causes antagonistic contractions that hinder thrust. These findings advance bio-inspired locomotion understanding and aid energy-efficient underwater system design.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01218v1",
    "published_date": "2025-12-01 02:57:02 UTC",
    "updated_date": "2025-12-01 02:57:02 UTC"
  },
  {
    "arxiv_id": "2512.01214v1",
    "title": "M4-BLIP: Advancing Multi-Modal Media Manipulation Detection through Face-Enhanced Local Analysis",
    "authors": [
      "Hang Wu",
      "Ke Sun",
      "Jiayi Ji",
      "Xiaoshuai Sun",
      "Rongrong Ji"
    ],
    "abstract": "In the contemporary digital landscape, multi-modal media manipulation has emerged as a significant societal threat, impacting the reliability and integrity of information dissemination. Current detection methodologies in this domain often overlook the crucial aspect of localized information, despite the fact that manipulations frequently occur in specific areas, particularly in facial regions. In response to this critical observation, we propose the M4-BLIP framework. This innovative framework utilizes the BLIP-2 model, renowned for its ability to extract local features, as the cornerstone for feature extraction. Complementing this, we incorporate local facial information as prior knowledge. A specially designed alignment and fusion module within M4-BLIP meticulously integrates these local and global features, creating a harmonious blend that enhances detection accuracy. Furthermore, our approach seamlessly integrates with Large Language Models (LLM), significantly improving the interpretability of the detection outcomes. Extensive quantitative and visualization experiments validate the effectiveness of our framework against the state-of-the-art competitors.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.01214v1",
    "published_date": "2025-12-01 02:54:03 UTC",
    "updated_date": "2025-12-01 02:54:03 UTC"
  },
  {
    "arxiv_id": "2512.01210v2",
    "title": "Knowledge Graph Augmented Large Language Models for Disease Prediction",
    "authors": [
      "Ruiyu Wang",
      "Tuan Vinh",
      "Ran Xu",
      "Yuyin Zhou",
      "Jiaying Lu",
      "Carl Yang",
      "Francisco Pasquel"
    ],
    "abstract": "Electronic health records (EHRs) support powerful clinical prediction models, but existing methods typically provide coarse, post hoc explanations that offer limited value for patient-level decision making. We introduce a knowledge graph (KG)-guided chain-of-thought (CoT) framework that generates clinically grounded and temporally consistent reasoning for visit-level disease prediction in MIMIC-III. ICD-9 codes are mapped to PrimeKG, from which disease-relevant nodes and multi-hop reasoning paths are extracted and used as scaffolds for CoT generation; only explanations whose conclusions match observed outcomes are retained. Lightweight LLaMA-3.1-Instruct-8B and Gemma-7B models are then fine-tuned on this supervision corpus. Across ten PrimeKG-mapped diseases and limited training cohorts (400 and 1000 cases), KG-guided models outperform strong classical baselines, achieving AUROC values of 0.66 to 0.70 and macro-AUPR values of 0.40 to 0.47. The models also transfer zero-shot to the CRADLE cohort, improving accuracy from approximately 0.40 to 0.51 up to 0.72 to 0.77. A blinded clinician evaluation shows consistent preference for KG-guided CoT explanations in clarity, relevance, and clinical correctness.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01210v2",
    "published_date": "2025-12-01 02:49:17 UTC",
    "updated_date": "2025-12-02 21:43:54 UTC"
  },
  {
    "arxiv_id": "2512.01208v2",
    "title": "Language as a Wave Phenomenon: Iso-Energetic Phase-Locking and Semantic Interference in Neural Networks",
    "authors": [
      "Alper Yldrm",
      "brahim Yceda"
    ],
    "abstract": "Conventional deep learning paradigms rely on metabolically expensive magnitude-based representations, rendering them fundamentally incompatible with passive photonic hardware. We introduce PRISM, a sequence modeling architecture that bridges high-level reasoning and physical constraints by enforcing an Iso-Energetic (Unity Gain) principle, compelling the network to encode semantic information exclusively in the phase angle. Validated on the WMT14 translation benchmark, PRISM achieves a 0.799 COMET score, demonstrating that phase-based reasoning competes with standard Transformers (0.821) and functionally matches unconstrained spectral baselines like FNet (0.805), despite enforcing strict energy constraints and requiring 11.5% fewer parameters. Furthermore, to verify hardware feasibility, we simulate a Holographic Backpropagation mechanism on a noisy, 4-bit optical correlator. Ablation studies reveal a substantial performance gain (48.4% vs. 62.4%) over a frozen baseline, proving that the proposed phase-steering mechanism actively optimizes physical parameters under strict energy constraints. These results establish an existence proof that ultra-low-power, passive optical hardware can support high-level linguistic intelligence without sacrificing representational capacity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Major Revision. Title changed to reflect the new theoretical framework. Complete narrative shift from \"Optimization Efficiency\" to \"Iso-Energetic Phase Coding\" and \"Optical Hardware Compatibility\". Replaced ISMR diagnostics with Holographic Optical Learning simulations and mechanistic \"Dual-Regime\" phase analysis. Comparison with spectral baselines (FNet) added",
    "pdf_url": "https://arxiv.org/pdf/2512.01208v2",
    "published_date": "2025-12-01 02:46:15 UTC",
    "updated_date": "2026-01-05 17:26:51 UTC"
  },
  {
    "arxiv_id": "2512.01207v1",
    "title": "Physics-Constrained Neural Dynamics: A Unified Manifold Framework for Large-Scale Power Flow Computation",
    "authors": [
      "Xuezhi Liu"
    ],
    "abstract": "Power flow analysis is a fundamental tool for power system analysis, planning, and operational control. Traditional Newton-Raphson methods suffer from limitations such as initial value sensitivity and low efficiency in batch computation, while existing deep learning-based power flow solvers mostly rely on supervised learning, requiring pre-solving of numerous cases and struggling to guarantee physical consistency. This paper proposes a neural physics power flow solving method based on manifold geometry and gradient flow, by describing the power flow equations as a constraint manifold, and constructing an energy function \\(V(\\mathbf{x}) = \\frac{1}{2}\\|\\mathbf{F}(\\mathbf{x})\\|^2\\) and gradient flow \\(\\frac{d\\mathbf{x}}{dt} = -\\nabla V(\\mathbf{x})\\), transforming power flow solving into an equilibrium point finding problem for dynamical systems. Neural networks are trained in an unsupervised manner by directly minimizing physical residuals, requiring no labeled data, achieving true \"end-to-end\" physics-constrained learning.",
    "categories": [
      "eess.SY",
      "cs.AI"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01207v1",
    "published_date": "2025-12-01 02:45:23 UTC",
    "updated_date": "2025-12-01 02:45:23 UTC"
  },
  {
    "arxiv_id": "2512.01189v1",
    "title": "fMRI2GES: Co-speech Gesture Reconstruction from fMRI Signal with Dual Brain Decoding Alignment",
    "authors": [
      "Chunzheng Zhu",
      "Jialin Shao",
      "Jianxin Lin",
      "Yijun Wang",
      "Jing Wang",
      "Jinhui Tang",
      "Kenli Li"
    ],
    "abstract": "Understanding how the brain responds to external stimuli and decoding this process has been a significant challenge in neuroscience. While previous studies typically concentrated on brain-to-image and brain-to-language reconstruction, our work strives to reconstruct gestures associated with speech stimuli perceived by brain. Unfortunately, the lack of paired \\{brain, speech, gesture\\} data hinders the deployment of deep learning models for this purpose. In this paper, we introduce a novel approach, \\textbf{fMRI2GES}, that allows training of fMRI-to-gesture reconstruction networks on unpaired data using \\textbf{Dual Brain Decoding Alignment}. This method relies on two key components: (i) observed texts that elicit brain responses, and (ii) textual descriptions associated with the gestures. Then, instead of training models in a completely supervised manner to find a mapping relationship among the three modalities, we harness an fMRI-to-text model, a text-to-gesture model with paired data and an fMRI-to-gesture model with unpaired data, establishing dual fMRI-to-gesture reconstruction patterns. Afterward, we explicitly align two outputs and train our model in a self-supervision way. We show that our proposed method can reconstruct expressive gestures directly from fMRI recordings. We also investigate fMRI signals from different ROIs in the cortex and how they affect generation results. Overall, we provide new insights into decoding co-speech gestures, thereby advancing our understanding of neuroscience and cognitive science.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.01189v1",
    "published_date": "2025-12-01 02:09:44 UTC",
    "updated_date": "2025-12-01 02:09:44 UTC"
  },
  {
    "arxiv_id": "2512.01188v1",
    "title": "Real-World Reinforcement Learning of Active Perception Behaviors",
    "authors": [
      "Edward S. Hu",
      "Jie Wang",
      "Xingfang Yuan",
      "Fiona Luo",
      "Muyao Li",
      "Gaspard Lambrechts",
      "Oleh Rybkin",
      "Dinesh Jayaraman"
    ],
    "abstract": "A robot's instantaneous sensory observations do not always reveal task-relevant state information. Under such partial observability, optimal behavior typically involves explicitly acting to gain the missing information. Today's standard robot learning techniques struggle to produce such active perception behaviors. We propose a simple real-world robot learning recipe to efficiently train active perception policies. Our approach, asymmetric advantage weighted regression (AAWR), exploits access to \"privileged\" extra sensors at training time. The privileged sensors enable training high-quality privileged value functions that aid in estimating the advantage of the target policy. Bootstrapping from a small number of potentially suboptimal demonstrations and an easy-to-obtain coarse policy initialization, AAWR quickly acquires active perception behaviors and boosts task performance. In evaluations on 8 manipulation tasks on 3 robots spanning varying degrees of partial observability, AAWR synthesizes reliable active perception behaviors that outperform all prior approaches. When initialized with a \"generalist\" robot policy that struggles with active perception tasks, AAWR efficiently generates information-gathering behaviors that allow it to operate under severe partial observability for manipulation tasks. Website: https://penn-pal-lab.github.io/aawr/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "NeurIPS 2025 camera ready",
    "pdf_url": "https://arxiv.org/pdf/2512.01188v1",
    "published_date": "2025-12-01 02:05:20 UTC",
    "updated_date": "2025-12-01 02:05:20 UTC"
  },
  {
    "arxiv_id": "2512.01187v1",
    "title": "Teaching by Failure: Counter-Example-Driven Curricula for Transformer Self-Improvement",
    "authors": [
      "Harshil Vejendla"
    ],
    "abstract": "Transformer models often exhibit brittle extrapolation, failing on inputs that are longer or structurally more complex than those seen during training. We introduce Counter-Example-Driven Curricula (CEDC), an automated framework that improves model robustness by iteratively focusing on its own failures. At each step, CEDC uses the current model to generate a diverse set of candidate problems, employs a fast, executable verifier to identify incorrect predictions (counter-examples), and then fine-tunes the model on a dataset enriched with these discovered failures. We evaluate CEDC on a suite of algorithmic and natural language tasks, including integer addition, sorting, Dyck-2 language recognition, and three text classification benchmarks. Compared to static training and standard curriculum learning baselines, CEDC achieves up to 30x greater length extrapolation, is 3.75x more computationally efficient than uniform data augmentation, and requires no manual difficulty heuristics. We provide a detailed analysis of the counter-examples, showing how the curriculum naturally adapts to target progressively more complex error modes. Our findings establish verifier-guided, failure-driven learning as a simple, powerful, and efficient paradigm for enhancing the generalization capabilities of Transformer models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "AACL 2025 Findings",
    "pdf_url": "https://arxiv.org/pdf/2512.01187v1",
    "published_date": "2025-12-01 02:00:41 UTC",
    "updated_date": "2025-12-01 02:00:41 UTC"
  },
  {
    "arxiv_id": "2512.01183v1",
    "title": "TempPerturb-Eval: On the Joint Effects of Internal Temperature and External Perturbations in RAG Robustness",
    "authors": [
      "Yongxin Zhou",
      "Philippe Mulhem",
      "Didier Schwab"
    ],
    "abstract": "The evaluation of Retrieval-Augmented Generation (RAG) systems typically examines retrieval quality and generation parameters like temperature in isolation, overlooking their interaction. This work presents a systematic investigation of how text perturbations (simulating noisy retrieval) interact with temperature settings across multiple LLM runs. We propose a comprehensive RAG Perturbation-Temperature Analysis Framework that subjects retrieved documents to three distinct perturbation types across varying temperature settings. Through extensive experiments on HotpotQA with both open-source and proprietary LLMs, we demonstrate that performance degradation follows distinct patterns: high-temperature settings consistently amplify vulnerability to perturbations, while certain perturbation types exhibit non-linear sensitivity across the temperature range. Our work yields three key contributions: (1) a diagnostic benchmark for assessing RAG robustness, (2) an analytical framework for quantifying perturbation-temperature interactions, and (3) practical guidelines for model selection and parameter tuning under noisy retrieval conditions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01183v1",
    "published_date": "2025-12-01 01:46:36 UTC",
    "updated_date": "2025-12-01 01:46:36 UTC"
  },
  {
    "arxiv_id": "2512.01181v1",
    "title": "First On-Orbit Demonstration of a Geospatial Foundation Model",
    "authors": [
      "Andrew Du",
      "Roberto Del Prete",
      "Alejandro Mousist",
      "Nick Manser",
      "Fabrice Marre",
      "Andrew Barton",
      "Carl Seubert",
      "Gabriele Meoni",
      "Tat-Jun Chin"
    ],
    "abstract": "Geospatial foundation models (GeoFMs) promise broad generalisation capacity for Earth observation (EO) tasks, particularly under data-limited conditions. However, their large size poses a barrier to deployment on resource-constrained space hardware. To address this, we present compact variants of a Vision Transformer (ViT)-based GeoFM that preserve downstream task performance while enabling onboard execution. Evaluation across five downstream tasks and validation in two representative flight environments show that model compression and domain adaptation are critical to reducing size and resource demands while maintaining high performance under operational conditions. We further demonstrate reliable on-orbit inference with the IMAGIN-e payload aboard the International Space Station. These results establish a pathway from large GeoFMs to flight-ready, resource-efficient deployments, expanding the feasibility of onboard AI for EO missions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01181v1",
    "published_date": "2025-12-01 01:43:03 UTC",
    "updated_date": "2025-12-01 01:43:03 UTC"
  },
  {
    "arxiv_id": "2512.04112v1",
    "title": "MindFuse: Towards GenAI Explainability in Marketing Strategy Co-Creation",
    "authors": [
      "Aleksandr Farseev",
      "Marlo Ongpin",
      "Qi Yang",
      "Ilia Gossoudarev",
      "Yu-Yi Chu-Farseeva",
      "Sergey Nikolenko"
    ],
    "abstract": "The future of digital marketing lies in the convergence of human creativity and generative AI, where insight, strategy, and storytelling are co-authored by intelligent systems. We present MindFuse, a brave new explainable generative AI framework designed to act as a strategic partner in the marketing process. Unlike conventional LLM applications that stop at content generation, MindFuse fuses CTR-based content AI-guided co-creation with large language models to extract, interpret, and iterate on communication narratives grounded in real advertising data. MindFuse operates across the full marketing lifecycle: from distilling content pillars and customer personas from competitor campaigns to recommending in-flight optimizations based on live performance telemetry. It uses attention-based explainability to diagnose ad effectiveness and guide content iteration, while aligning messaging with strategic goals through dynamic narrative construction and storytelling. We introduce a new paradigm in GenAI for marketing, where LLMs not only generate content but reason through it, adapt campaigns in real time, and learn from audience engagement patterns. Our results, validated in agency deployments, demonstrate up to 12 times efficiency gains, setting the stage for future integration with empirical audience data (e.g., GWI, Nielsen) and full-funnel attribution modeling. MindFuse redefines AI not just as a tool, but as a collaborative agent in the creative and strategic fabric of modern marketing.",
    "categories": [
      "cs.MM",
      "cs.AI"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.04112v1",
    "published_date": "2025-12-01 01:41:17 UTC",
    "updated_date": "2025-12-01 01:41:17 UTC"
  },
  {
    "arxiv_id": "2512.01179v1",
    "title": "Toward a benchmark for CTR prediction in online advertising: datasets, evaluation protocols and perspectives",
    "authors": [
      "Shan Gao",
      "Yanwu Yang"
    ],
    "abstract": "This research designs a unified architecture of CTR prediction benchmark (Bench-CTR) platform that offers flexible interfaces with datasets and components of a wide range of CTR prediction models. Moreover, we construct a comprehensive system of evaluation protocols encompassing real-world and synthetic datasets, a taxonomy of metrics, standardized procedures and experimental guidelines for calibrating the performance of CTR prediction models. Furthermore, we implement the proposed benchmark platform and conduct a comparative study to evaluate a wide range of state-of-the-art models from traditional multivariate statistical to modern large language model (LLM)-based approaches on three public datasets and two synthetic datasets. Experimental results reveal that, (1) high-order models largely outperform low-order models, though such advantage varies in terms of metrics and on different datasets; (2) LLM-based models demonstrate a remarkable data efficiency, i.e., achieving the comparable performance to other models while using only 2% of the training data; (3) the performance of CTR prediction models has achieved significant improvements from 2015 to 2016, then reached a stage with slow progress, which is consistent across various datasets. This benchmark is expected to facilitate model development and evaluation and enhance practitioners' understanding of the underlying mechanisms of models in the area of CTR prediction. Code is available at https://github.com/NuriaNinja/Bench-CTR.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "64 pages, 8 figures, 11 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.01179v1",
    "published_date": "2025-12-01 01:36:55 UTC",
    "updated_date": "2025-12-01 01:36:55 UTC"
  },
  {
    "arxiv_id": "2512.01171v1",
    "title": "Conversion rate prediction in online advertising: modeling techniques, performance evaluation and future directions",
    "authors": [
      "Tao Xue",
      "Yanwu Yang",
      "Panyu Zhai"
    ],
    "abstract": "Conversion and conversion rate (CVR) prediction play a critical role in efficient advertising decision-making. In past decades, although researchers have developed plenty of models for CVR prediction, the methodological evolution and relationships between different techniques have been precluded. In this paper, we conduct a comprehensive literature review on CVR prediction in online advertising, and classify state-of-the-art CVR prediction models into six categories with respect to the underlying techniques and elaborate on connections between these techniques. For each category of models, we present the framework of underlying techniques, their advantages and disadvantages, and discuss how they are utilized for CVR prediction. Moreover, we summarize the performance of various CVR prediction models on public and proprietary datasets. Finally, we identify research trends, major challenges, and promising future directions. We observe that results of performance evaluation reported in prior studies are not unanimous; semantics-enriched, attribution-enhanced, debiased CVR prediction and jointly modeling CTR and CVR prediction would be promising directions to explore in the future. This review is expected to provide valuable references and insights for future researchers and practitioners in this area.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "99 pages, 15 figures, 7 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.01171v1",
    "published_date": "2025-12-01 01:02:35 UTC",
    "updated_date": "2025-12-01 01:02:35 UTC"
  },
  {
    "arxiv_id": "2512.01170v1",
    "title": "Data assimilation and discrepancy modeling with shallow recurrent decoders",
    "authors": [
      "Yuxuan Bao",
      "J. Nathan Kutz"
    ],
    "abstract": "The requirements of modern sensing are rapidly evolving, driven by increasing demands for data efficiency, real-time processing, and deployment under limited sensing coverage. Complex physical systems are often characterized through the integration of a limited number of point sensors in combination with scientific computations which approximate the dominant, full-state dynamics. Simulation models, however, inevitably neglect small-scale or hidden processes, are sensitive to perturbations, or oversimplify parameter correlations, leading to reconstructions that often diverge from the reality measured by sensors. This creates a critical need for data assimilation, the process of integrating observational data with predictive simulation models to produce coherent and accurate estimates of the full state of complex physical systems. We propose a machine learning framework for Data Assimilation with a SHallow REcurrent Decoder (DA-SHRED) which bridges the simulation-to-real (SIM2REAL) gap between computational modeling and experimental sensor data. For real-world physics systems modeling high-dimensional spatiotemporal fields, where the full state cannot be directly observed and must be inferred from sparse sensor measurements, we leverage the latent space learned from a reduced simulation model via SHRED, and update these latent variables using real sensor data to accurately reconstruct the full system state. Furthermore, our algorithm incorporates a sparse identification of nonlinear dynamics based regression model in the latent space to identify functionals corresponding to missing dynamics in the simulation model. We demonstrate that DA-SHRED successfully closes the SIM2REAL gap and additionally recovers missing dynamics in highly complex systems, demonstrating that the combination of efficient temporal encoding and physics-informed correction enables robust data assimilation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.AP",
      "nlin.CD"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 11 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.01170v1",
    "published_date": "2025-12-01 01:01:48 UTC",
    "updated_date": "2025-12-01 01:01:48 UTC"
  },
  {
    "arxiv_id": "2512.01167v1",
    "title": "A TinyML Reinforcement Learning Approach for Energy-Efficient Light Control in Low-Cost Greenhouse Systems",
    "authors": [
      "Mohamed Abdallah Salem",
      "Manuel Cuevas Perez",
      "Ahmed Harb Rabia"
    ],
    "abstract": "This study presents a reinforcement learning (RL)-based control strategy for adaptive lighting regulation in controlled environments using a low-power microcontroller. A model-free Q-learning algorithm was implemented to dynamically adjust the brightness of a Light-Emitting Diode (LED) based on real-time feedback from a light-dependent resistor (LDR) sensor. The system was trained to stabilize at 13 distinct light intensity levels (L1 to L13), with each target corresponding to a specific range within the 64-state space derived from LDR readings. A total of 130 trials were conducted, covering all target levels with 10 episodes each. Performance was evaluated in terms of convergence speed, steps taken, and time required to reach target states. Box plots and histograms were generated to analyze the distribution of training time and learning efficiency across targets. Experimental validation demonstrated that the agent could effectively learn to stabilize at varying light levels with minimal overshooting and smooth convergence, even in the presence of environmental perturbations. This work highlights the feasibility of lightweight, on-device RL for energy-efficient lighting control and sets the groundwork for multi-modal environmental control applications in resource-constrained agricultural systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "Copyright 2025 IEEE. This is the author's version of the work that has been accepted for publication in Proceedings of the 5. Interdisciplinary Conference on Electrics and Computer (INTCEC 2025) 15-16 September 2025, Chicago-USA. The final version of record is available at: https://doi.org/10.1109/INTCEC65580.2025.11256135",
    "pdf_url": "https://arxiv.org/pdf/2512.01167v1",
    "published_date": "2025-12-01 00:58:05 UTC",
    "updated_date": "2025-12-01 00:58:05 UTC"
  },
  {
    "arxiv_id": "2512.01165v1",
    "title": "Real-Time On-the-Go Annotation Framework Using YOLO for Automated Dataset Generation",
    "authors": [
      "Mohamed Abdallah Salem",
      "Ahmed Harb Rabia"
    ],
    "abstract": "Efficient and accurate annotation of datasets remains a significant challenge for deploying object detection models such as You Only Look Once (YOLO) in real-world applications, particularly in agriculture where rapid decision-making is critical. Traditional annotation techniques are labor-intensive, requiring extensive manual labeling post data collection. This paper presents a novel real-time annotation approach leveraging YOLO models deployed on edge devices, enabling immediate labeling during image capture. To comprehensively evaluate the efficiency and accuracy of our proposed system, we conducted an extensive comparative analysis using three prominent YOLO architectures (YOLOv5, YOLOv8, YOLOv12) under various configurations: single-class versus multi-class annotation and pretrained versus scratch-based training. Our analysis includes detailed statistical tests and learning dynamics, demonstrating significant advantages of pretrained and single-class configurations in terms of model convergence, performance, and robustness. Results strongly validate the feasibility and effectiveness of our real-time annotation framework, highlighting its capability to drastically reduce dataset preparation time while maintaining high annotation quality.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Copyright 2025 IEEE. This is the author's version of the work that has been accepted for publication in Proceedings of the 5. Interdisciplinary Conference on Electrics and Computer (INTCEC 2025) 15-16 September 2025, Chicago-USA. The final version of record is available at: https://doi.org/10.1109/INTCEC65580.2025.11256048",
    "pdf_url": "https://arxiv.org/pdf/2512.01165v1",
    "published_date": "2025-12-01 00:54:57 UTC",
    "updated_date": "2025-12-01 00:54:57 UTC"
  },
  {
    "arxiv_id": "2512.01163v1",
    "title": "2D-ThermAl: Physics-Informed Framework for Thermal Analysis of Circuits using Generative AI",
    "authors": [
      "Soumyadeep Chandra",
      "Sayeed Shafayet Chowdhury",
      "Kaushik Roy"
    ],
    "abstract": "Thermal analysis is increasingly critical in modern integrated circuits, where non-uniform power dissipation and high transistor densities can cause rapid temperature spikes and reliability concerns. Traditional methods, such as FEM-based simulations offer high accuracy but computationally prohibitive for early-stage design, often requiring multiple iterative redesign cycles to resolve late-stage thermal failures. To address these challenges, we propose 'ThermAl', a physics-informed generative AI framework which effectively identifies heat sources and estimates full-chip transient and steady-state thermal distributions directly from input activity profiles. ThermAl employs a hybrid U-Net architecture enhanced with positional encoding and a Boltzmann regularizer to maintain physical fidelity. Our model is trained on an extensive dataset of heat dissipation maps, ranging from simple logic gates (e.g., inverters, NAND, XOR) to complex designs, generated via COMSOL. Experimental results demonstrate that ThermAl delivers precise temperature mappings for large circuits, with a root mean squared error (RMSE) of only 0.71C, and outperforms conventional FEM tools by running up to ~200 times faster. We analyze performance across diverse layouts and workloads, and discuss its applicability to large-scale EDA workflows. While thermal reliability assessments often extend beyond 85C for post-layout signoff, our focus here is on early-stage hotspot detection and thermal pattern learning. To ensure generalization beyond the nominal operating range 25-55C, we additionally performed cross-validation on an extended dataset spanning 25-95C maintaining a high accuracy (<2.2% full-scale RMSE) even under elevated temperature conditions representative of peak power and stress scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 8 figures, Under Review",
    "pdf_url": "https://arxiv.org/pdf/2512.01163v1",
    "published_date": "2025-12-01 00:45:26 UTC",
    "updated_date": "2025-12-01 00:45:26 UTC"
  },
  {
    "arxiv_id": "2512.08965v1",
    "title": "Financial Instruction Following Evaluation (FIFE)",
    "authors": [
      "Glenn Matlin",
      "Siddharth",
      "Anirudh JM",
      "Aditya Shukla",
      "Yahya Hassan",
      "Sudheer Chava"
    ],
    "abstract": "Language Models (LMs) struggle with complex, interdependent instructions, particularly in high-stakes domains like finance where precision is critical. We introduce FIFE, a novel, high-difficulty benchmark designed to assess LM instruction-following capabilities for financial analysis tasks. FIFE comprises 88 human-authored prompts and employs a verification system with chainable, verifiable constraints for fine-grained reward signals. We evaluate 53 models (proprietary, open-weight, open-source) in a zero-shot setting. Our key findings reveal a clear performance hierarchy: the top open-weight model (76.1 strict / 79.5 loose) surpasses the leading proprietary system (65.9 strict / 70.5 loose), while the best open-source models lag significantly (45.5 strict / 48.9 loose). However, even top-performing models struggle with FIFE's complex requirements, failing to achieve perfect compliance. We release our dataset and code as an open-source resource to promote research in Reinforcement Learning for the financial domain.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NeurIPS 2025 Generative AI in Finance Workshop (GenAI Finance), San Diego. Camera-ready version. Code and data: https://github.com/gtfintechlab/FIFE/",
    "pdf_url": "https://arxiv.org/pdf/2512.08965v1",
    "published_date": "2025-12-01 00:39:19 UTC",
    "updated_date": "2025-12-01 00:39:19 UTC"
  },
  {
    "arxiv_id": "2512.01155v2",
    "title": "Beyond Greenfield: The D3 Framework for AI-Driven Productivity in Brownfield Engineering",
    "authors": [
      "Krishna Kumaar Sharma"
    ],
    "abstract": "Brownfield engineering work involving legacy systems, incomplete documentation, and fragmented architectural knowledge poses unique challenges for the effective use of large language models (LLMs). Prior research has largely focused on greenfield or synthetic tasks, leaving a gap in structured workflows for complex, context-heavy environments. This paper introduces the Discover-Define-Deliver (D3) Framework, a disciplined LLM-assisted workflow that combines role-separated prompting strategies with applied best practices for navigating ambiguity in brownfield systems. The framework incorporates a dual-agent prompting architecture in which a Builder model generates candidate outputs and a Reviewer model provides structured critique to improve reliability. I conducted an exploratory survey study with 52 software practitioners who applied the D3 workflow to real-world engineering tasks such as legacy system exploration, documentation reconstruction, and architectural refactoring. Respondents reported perceived improvements in task clarity, documentation quality, and cognitive load, along with self-estimated productivity gains. In this exploratory study, participants reported a weighted average productivity improvement of 26.9%, reduced cognitive load for approximately 77% of participants, and 83% of participants spent less time fixing or rewriting code due to better initial planning with AI. As these findings are self-reported and not derived from controlled experiments, they should be interpreted as preliminary evidence of practitioner sentiment rather than causal effects. The results highlight both the potential and limitations of structured LLM workflows for legacy engineering systems and motivate future controlled evaluations.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "53 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.01155v2",
    "published_date": "2025-12-01 00:26:41 UTC",
    "updated_date": "2025-12-02 10:47:38 UTC"
  },
  {
    "arxiv_id": "2512.05994v1",
    "title": "KidSpeak: A General Multi-purpose LLM for Kids' Speech Recognition and Screening",
    "authors": [
      "Rohan Sharma",
      "Dancheng Liu",
      "Jingchen Sun",
      "Shijie Zhou",
      "Jiayu Qin",
      "Jinjun Xiong",
      "Changyou Chen"
    ],
    "abstract": "With the rapid advancement of conversational and diffusion-based AI, there is a growing adoption of AI in educational services, ranging from grading and assessment tools to personalized learning systems that provide targeted support for students. However, this adaptability has yet to fully extend to the domain of children's speech, where existing models often fail due to their reliance on datasets designed for clear, articulate adult speech. Children, particularly those in early developmental stages or with speech and language pathologies, present unique challenges that current AI models and datasets are ill-equipped to handle. To address this, we introduce KidSpeak, a multi-task speech-enhanced Foundation Model capable of both generative and discriminative tasks specifically tailored to children's speech patterns. Our framework employs a two-stage training process that incorporates phonetic knowledge into the speech encoder, achieving an average accuracy of 87% across four separate tasks. Furthermore, recognizing the limitations of scalable human annotation and existing speech alignment tools, we propose the Flexible and Automatic Speech Aligner (FASA) and leverage the method to construct high quality datasets for training and evaluation. This novel alignment tool significantly improves the quality of aligned children's speech from noisy data, enhancing data quality by 13.6x compared to human annotations, as demonstrated on the CHILDES dataset. To the best of our knowledge, KidSpeak and FASA represent the first comprehensive solution designed for speech and language therapy in children, offering both a multi-purpose speech LLM and a robust alignment tool.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.05994v1",
    "published_date": "2025-12-01 00:19:37 UTC",
    "updated_date": "2025-12-01 00:19:37 UTC"
  },
  {
    "arxiv_id": "2512.01153v1",
    "title": "DPAC: Distribution-Preserving Adversarial Control for Diffusion Sampling",
    "authors": [
      "Han-Jin Lee",
      "Han-Ju Lee",
      "Jin-Seong Kim",
      "Seok-Hwan Choi"
    ],
    "abstract": "Adversarially guided diffusion sampling often achieves the target class, but sample quality degrades as deviations between the adversarially controlled and nominal trajectories accumulate. We formalize this degradation as a path-space Kullback-Leibler divergence(path-KL) between controlled and nominal (uncontrolled) diffusion processes, thereby showing via Girsanov's theorem that it exactly equals the control energy. Building on this stochastic optimal control (SOC) view, we theoretically establish that minimizing this path-KL simultaneously tightens upper bounds on both the 2-Wasserstein distance and Frchet Inception Distance (FID), revealing a principled connection between adversarial control energy and perceptual fidelity. From a variational perspective, we derive a first-order optimality condition for the control: among all directions that yield the same classification gain, the component tangent to iso-(log-)density surfaces (i.e., orthogonal to the score) minimizes path-KL, whereas the normal component directly increases distributional drift. This leads to DPAC (Distribution-Preserving Adversarial Control), a diffusion guidance rule that projects adversarial gradients onto the tangent space defined by the generative score geometry. We further show that in discrete solvers, the tangent projection cancels the O(t) leading error term in the Wasserstein distance, achieving an O(t^2) quality gap; moreover, it remains second-order robust to score or metric approximation. Empirical studies on ImageNet-100 validate the theoretical predictions, confirming that DPAC achieves lower FID and estimated path-KL at matched attack success rates.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01153v1",
    "published_date": "2025-12-01 00:15:05 UTC",
    "updated_date": "2025-12-01 00:15:05 UTC"
  },
  {
    "arxiv_id": "2512.01152v2",
    "title": "Open-Set Domain Adaptation Under Background Distribution Shift: Challenges and A Provably Efficient Solution",
    "authors": [
      "Shravan Chaudhari",
      "Yoav Wald",
      "Suchi Saria"
    ],
    "abstract": "As we deploy machine learning systems in the real world, a core challenge is to maintain a model that is performant even as the data shifts. Such shifts can take many forms: new classes may emerge that were absent during training, a problem known as open-set recognition, and the distribution of known categories may change. Guarantees on open-set recognition are mostly derived under the assumption that the distribution of known classes, which we call the background distribution, is fixed. In this paper we develop CoLOR, a method that is guaranteed to solve open-set recognition even in the challenging case where the background distribution shifts. We prove that the method works under benign assumptions that the novel class is separable from the non-novel classes, and provide theoretical guarantees that it outperforms a representative baseline in a simplified overparameterized setting. We develop techniques to make CoLOR scalable and robust, and perform comprehensive empirical evaluations on image and text data. The results show that CoLOR significantly outperforms existing open-set recognition methods under background shift. Moreover, we provide new insights into how factors such as the size of the novel class influences performance, an aspect that has not been extensively explored in prior work.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.01152v2",
    "published_date": "2025-12-01 00:08:18 UTC",
    "updated_date": "2025-12-03 19:23:58 UTC"
  }
]