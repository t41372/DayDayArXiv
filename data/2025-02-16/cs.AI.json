{
  "date": "2025-02-16",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-16 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 演化、多模态 Large Language Models (LLMs) 的安全与应用、优化算法以及科学模拟等领域，亮点包括 AI 4.0 概念的提出、LLM 在复杂任务中的高效攻击防御，以及在医学和多模态任务上的创新应用；令人印象深刻的文章有贾昊吴等作者的“AI Generations”探讨 AI 发展阶段，以及 DeepSeek 相关模型的安全评估。\n\n### 重点论文讨论\n我们先聊聊几篇重要的论文，这些涉及 LLM 的核心创新、攻击防御和实际应用，具有较高话题度和潜在影响。相关论文按主题归类，便于读者快速把握。\n\n**AI 演化和 LLM 基础（高影响力主题）**  \n- **AI 代际演化：从 AI 1.0 到 AI 4.0** (AI Generations: From AI 1.0 to AI 4.0)  \n  作者：Jiahao Wu 等。主要贡献：提出 AI 发展分为 AI 1.0（信息 AI）到 AI 4.0（意识 AI）的重叠代际模型，分析算法、计算力和数据驱动的演变，并讨论伦理挑战。该论文回顾 70 年来 AI 历史，提供未来研究的指导框架，强调 AI 4.0 的自主目标设定可能带来的社会益处。\n\n- **LLM 在多模态任务中的性能提升** (CORDIAL: Can Multimodal Large Language Models Effectively Understand Coherence Relationships?)  \n  作者：Aashish Anantha Ramakrishnan 等。主要发现：评估多模态 LLM 在理解连贯性关系（如多领域语境）上的能力，发现顶级模型如 Gemini 1.5 Pro 和 GPT-4o 仍落后于简单基线，呼吁采用更细致的语篇驱动评估框架。\n\n- **神经符号架构在生成 AI 中的潜力** (Unlocking the Potential of Generative AI through Neuro-Symbolic Architectures: Benefits and Limitations)  \n  作者：Oualid Bougzime 等。主要贡献：系统分析神经符号 AI（NSAI）架构，结合检索增强生成和图神经网络，提升泛化性和可解释性；实验显示“Neuro > Symbolic < Neuro”模型在多指标上优于其他，揭示其在实际应用的优势和局限。\n\n**LLM 安全和攻击防御（热门话题）**  \n- **少样本逆向攻击方法** (ALGEN: Few-shot Inversion Attacks on Textual Embeddings using Alignment and Generation)  \n  作者：Yiyi Chen 等。主要发现：提出 ALGEN 框架，使用少量样本（甚至 1k）逆向重构文本嵌入，攻击多语言嵌入模型；证明嵌入空间对齐的易感性，并评估防御无效性，强调 NLP 嵌入安全风险。\n\n- **多模态安全基准** (SafeDialBench: A Fine-Grained Safety Benchmark for Large Language Models in Multi-Turn Dialogues with Diverse Jailbreak Attacks)  \n  作者：Hongye Cao 等。主要贡献：构建 SafeDialBench 数据集，评估 LLM 在多轮对话中的安全性能，覆盖 22 场景和多种攻击；实验显示 Yi-34B-Chat 在安全维度表现最佳，揭示 LLM 检测和处理不安全信息的挑战。\n\n- **LLM 越狱攻击防御** (ShieldLearner: A New Paradigm for Jailbreak Attack Defense in LLMs)  \n  作者：Ziyi Ni 等。主要发现：引入 ShieldLearner 框架，通过模式图谱和元分析框架检测攻击，并用自适应增强实现持续优化；实验证明其在复杂提示上的防御成功率高于基线，适用于实时安全应用。\n\n**多模态和科学应用（实际影响强）**  \n- **医学 LLM 基准** (A Survey of LLM-based Agents in Medicine: How far are we from Baymax?)  \n  作者：Wenxuan Wang 等。主要贡献：综述 LLM 代理在医学中的应用，如临床决策和文档生成，强调未来方向包括医学推理和物理系统整合；提供全面框架评估 LLM 在医疗中的潜力。\n\n- **多模态异常检测** (Exploiting Point-Language Models with Dual-Prompts for 3D Anomaly Detection)  \n  作者：Jiaxiang Wang 等。主要发现：提出 PLANE 方法，使用双提示学习扩展点云模型，实现单模型多类别 3D 异常检测；实验显示其在 Anomaly-ShapeNet 数据集上提升 8.7% 检测性能，适用于工业制造。\n\n其他论文涉及优化算法、量子计算和文本生成等，但许多是技术性较强的增量工作，我们快速掠过：\n\n- **快速掠过部分：**  \n  如“Game-Of-Goals: Using adversarial games to achieve strategic resilience”（主要贡献：用博弈树搜索提升战略计划弹性）、“Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly Improves Retrieval Augmented Generation”（发现：在多跳问答中提升 RAG 准确率达 4.2%）、“Towards identifying possible fault-tolerant advantage of quantum linear system algorithms”（评估量子算法在线性系统中的优势，可能在特定规模下超越经典方法）。这些论文在各自领域有细微创新，但影响力较小，仅供感兴趣读者查阅。\n\n今天的 arXiv 更新丰富多元，AI 安全和应用仍是热点。读者可关注上述关键论文，探索 LLM 的边界和挑战！如果有特定兴趣，建议直接查看 arXiv 原文。",
  "papers": [
    {
      "arxiv_id": "2502.11312v1",
      "title": "AI Generations: From AI 1.0 to AI 4.0",
      "title_zh": "AI 世代：从 AI 1.0 到 AI 4.0",
      "authors": [
        "Jiahao Wu",
        "Hengxu You",
        "Jing Du"
      ],
      "abstract": "This paper proposes that Artificial Intelligence (AI) progresses through\nseveral overlapping generations: AI 1.0 (Information AI), AI 2.0 (Agentic AI),\nAI 3.0 (Physical AI), and now a speculative AI 4.0 (Conscious AI). Each of\nthese AI generations is driven by shifting priorities among algorithms,\ncomputing power, and data. AI 1.0 ushered in breakthroughs in pattern\nrecognition and information processing, fueling advances in computer vision,\nnatural language processing, and recommendation systems. AI 2.0 built on these\nfoundations through real-time decision-making in digital environments,\nleveraging reinforcement learning and adaptive planning for agentic AI\napplications. AI 3.0 extended intelligence into physical contexts, integrating\nrobotics, autonomous vehicles, and sensor-fused control systems to act in\nuncertain real-world settings. Building on these developments, AI 4.0 puts\nforward the bold vision of self-directed AI capable of setting its own goals,\norchestrating complex training regimens, and possibly exhibiting elements of\nmachine consciousness. This paper traces the historical foundations of AI\nacross roughly seventy years, mapping how changes in technological bottlenecks\nfrom algorithmic innovation to high-performance computing to specialized data,\nhave spurred each generational leap. It further highlights the ongoing\nsynergies among AI 1.0, 2.0, 3.0, and 4.0, and explores the profound ethical,\nregulatory, and philosophical challenges that arise when artificial systems\napproach (or aspire to) human-like autonomy. Ultimately, understanding these\nevolutions and their interdependencies is pivotal for guiding future research,\ncrafting responsible governance, and ensuring that AI transformative potential\nbenefits society as a whole.",
      "tldr_zh": "这篇论文将人工智能（AI）的发展划分为四个世代：AI 1.0（信息 AI）、AI 2.0（智能体 AI）、AI 3.0（物理 AI）和推测的 AI 4.0（意识 AI），每个世代由算法、计算能力和数据的优先级变化驱动。AI 1.0 推动了模式识别和信息处理技术，如计算机视觉和自然语言处理；AI 2.0 通过强化学习实现实时决策；AI 3.0 则将 AI 扩展到物理环境，包括机器人和自动驾驶系统。论文追溯 AI 七十年的历史演变，强调世代间的协同作用，并探讨 AI 4.0 的自定向能力可能带来的伦理、监管和哲学挑战，以指导未来研究和负责任的治理。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.11312v1",
      "published_date": "2025-02-16 23:19:44 UTC",
      "updated_date": "2025-02-16 23:19:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:56:42.257995"
    },
    {
      "arxiv_id": "2502.11308v2",
      "title": "ALGEN: Few-shot Inversion Attacks on Textual Embeddings using Alignment and Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yiyi Chen",
        "Qiongkai Xu",
        "Johannes Bjerva"
      ],
      "abstract": "With the growing popularity of Large Language Models (LLMs) and vector\ndatabases, private textual data is increasingly processed and stored as\nnumerical embeddings. However, recent studies have proven that such embeddings\nare vulnerable to inversion attacks, where original text is reconstructed to\nreveal sensitive information. Previous research has largely assumed access to\nmillions of sentences to train attack models, e.g., through data leakage or\nnearly unrestricted API access. With our method, a single data point is\nsufficient for a partially successful inversion attack. With as little as 1k\ndata samples, performance reaches an optimum across a range of black-box\nencoders, without training on leaked data. We present a Few-shot Textual\nEmbedding Inversion Attack using ALignment and GENeration (ALGEN), by aligning\nvictim embeddings to the attack space and using a generative model to\nreconstruct text. We find that ALGEN attacks can be effectively transferred\nacross domains and languages, revealing key information. We further examine a\nvariety of defense mechanisms against ALGEN, and find that none are effective,\nhighlighting the vulnerabilities posed by inversion attacks. By significantly\nlowering the cost of inversion and proving that embedding spaces can be aligned\nthrough one-step optimization, we establish a new textual embedding inversion\nparadigm with broader applications for embedding alignment in NLP.",
      "tldr_zh": "该研究提出了一种名为 ALGEN 的少样本逆向攻击方法，用于针对文本嵌入（textual embeddings）的安全漏洞，仅需少量数据（如 1k 样本）即可重建敏感信息，而无需大量训练数据。ALGEN 通过对齐（alignment）和生成（generation）技术，将受害者嵌入映射到攻击空间，并利用生成模型重建原始文本，适用于各种黑箱编码器。实验结果显示，该攻击可在不同领域和语言间有效转移，并揭示关键信息；同时，多种防御机制被证明无效，突显了嵌入逆向攻击的风险。该方法建立了新的文本嵌入逆向范式，具有更广泛的 NLP 中的嵌入对齐（embedding alignment）应用。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "I.2; J.6"
      ],
      "primary_category": "cs.CR",
      "comment": "18 pages, 13 tables, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.11308v2",
      "published_date": "2025-02-16 23:11:13 UTC",
      "updated_date": "2025-02-18 10:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:56:52.852719"
    },
    {
      "arxiv_id": "2502.11307v1",
      "title": "Exploiting Point-Language Models with Dual-Prompts for 3D Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxiang Wang",
        "Haote Xu",
        "Xiaolu Chen",
        "Haodi Xu",
        "Yue Huang",
        "Xinghao Ding",
        "Xiaotong Tu"
      ],
      "abstract": "Anomaly detection (AD) in 3D point clouds is crucial in a wide range of\nindustrial applications, especially in various forms of precision\nmanufacturing. Considering the industrial demand for reliable 3D AD, several\nmethods have been developed. However, most of these approaches typically\nrequire training separate models for each category, which is memory-intensive\nand lacks flexibility. In this paper, we propose a novel Point-Language model\nwith dual-prompts for 3D ANomaly dEtection (PLANE). The approach leverages\nmulti-modal prompts to extend the strong generalization capabilities of\npre-trained Point-Language Models (PLMs) to the domain of 3D point cloud AD,\nachieving impressive detection performance across multiple categories using a\nsingle model. Specifically, we propose a dual-prompt learning method,\nincorporating both text and point cloud prompts. The method utilizes a dynamic\nprompt creator module (DPCM) to produce sample-specific dynamic prompts, which\nare then integrated with class-specific static prompts for each modality,\neffectively driving the PLMs. Additionally, based on the characteristics of\npoint cloud data, we propose a pseudo 3D anomaly generation method (Ano3D) to\nimprove the model's detection capabilities in an unsupervised setting.\nExperimental results demonstrate that the proposed method, which is under the\nmulti-class-one-model paradigm, achieves a +8.7%/+17% gain on anomaly detection\nand localization performance as compared to the state-of-the-art\none-class-one-model methods for the Anomaly-ShapeNet dataset, and obtains\n+4.3%/+4.1% gain for the Real3D-AD dataset. Code will be available upon\npublication.",
      "tldr_zh": "本研究针对3D点云异常检测（Anomaly Detection）的问题，提出了一种名为PLANE的Point-Language模型，使用双提示（dual-prompts）机制来扩展预训练Point-Language Models（PLMs）的泛化能力，从而实现单模型处理多个类别的检测，避免了传统方法需为每个类别训练单独模型的局限性。具体而言，该方法包括动态提示创建模块（DPCM）生成样本特定的动态提示，并结合文本和点云提示与类别特定的静态提示进行整合；此外，还引入伪3D异常生成方法（Ano3D）来提升无监督下的检测性能。实验结果显示，在Anomaly-ShapeNet数据集上，PLANE方法在异常检测和定位性能上比最先进的一类一模型方法提高了+8.7%/+17%，而在Real3D-AD数据集上获得了+4.3%/+4.1%的提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.11307v1",
      "published_date": "2025-02-16 23:10:57 UTC",
      "updated_date": "2025-02-16 23:10:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:57:05.349463"
    },
    {
      "arxiv_id": "2502.11304v1",
      "title": "Leveraging Multimodal-LLMs Assisted by Instance Segmentation for Intelligent Traffic Monitoring",
      "title_zh": "翻译失败",
      "authors": [
        "Murat Arda Onsu",
        "Poonam Lohan",
        "Burak Kantarci",
        "Aisha Syed",
        "Matthew Andrews",
        "Sean Kennedy"
      ],
      "abstract": "A robust and efficient traffic monitoring system is essential for smart\ncities and Intelligent Transportation Systems (ITS), using sensors and cameras\nto track vehicle movements, optimize traffic flow, reduce congestion, enhance\nroad safety, and enable real-time adaptive traffic control. Traffic monitoring\nmodels must comprehensively understand dynamic urban conditions and provide an\nintuitive user interface for effective management. This research leverages the\nLLaVA visual grounding multimodal large language model (LLM) for traffic\nmonitoring tasks on the real-time Quanser Interactive Lab simulation platform,\ncovering scenarios like intersections, congestion, and collisions. Cameras\nplaced at multiple urban locations collect real-time images from the\nsimulation, which are fed into the LLaVA model with queries for analysis. An\ninstance segmentation model integrated into the cameras highlights key elements\nsuch as vehicles and pedestrians, enhancing training and throughput. The system\nachieves 84.3% accuracy in recognizing vehicle locations and 76.4% in\ndetermining steering direction, outperforming traditional models.",
      "tldr_zh": "这篇论文提出了一种利用 Multimodal-LLMs 和 Instance Segmentation 的智能交通监控系统，旨在通过摄像头实时分析城市动态场景，如路口拥堵和碰撞事件，以优化交通流量并提升道路安全。系统整合 LLaVA 视觉 grounding 模型和实例分割技术，对 Quanser Interactive Lab 模拟平台的实时图像进行处理，突出车辆和行人等关键元素，从而提高分析效率。实验结果显示，该系统在识别车辆位置的准确率达到 84.3%，在确定转向方向的准确率达到 76.4%，整体表现优于传统模型，为智能城市和 ITS（Intelligent Transportation Systems）提供了更可靠的监控框架。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 7 figures, submitted to 30th IEEE International Symposium on\n  Computers and Communications (ISCC) 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.11304v1",
      "published_date": "2025-02-16 23:03:26 UTC",
      "updated_date": "2025-02-16 23:03:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:57:16.949165"
    },
    {
      "arxiv_id": "2502.11300v1",
      "title": "CORDIAL: Can Multimodal Large Language Models Effectively Understand Coherence Relationships?",
      "title_zh": "CORDIAL：多模态大语言模型能否有效地理解连贯性关系？",
      "authors": [
        "Aashish Anantha Ramakrishnan",
        "Aadarsh Anantha Ramakrishnan",
        "Dongwon Lee"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) are renowned for their superior\ninstruction-following and reasoning capabilities across diverse problem\ndomains. However, existing benchmarks primarily focus on assessing factual and\nlogical correctness in downstream tasks, with limited emphasis on evaluating\nMLLMs' ability to interpret pragmatic cues and intermodal relationships. To\naddress this gap, we assess the competency of MLLMs in performing Multimodal\nDiscourse Analysis (MDA) using Coherence Relations. Our benchmark, CORDIAL,\nencompasses a broad spectrum of Coherence Relations across 3 different\ndiscourse domains at varying levels of granularity. Through our experiments on\n10+ MLLMs employing different prompting strategies, we show that even top\nmodels like Gemini 1.5 Pro and GPT-4o fail to match the performance of simple\nclassifier-based baselines. This study emphasizes the need to move beyond\nsimilarity-based metrics and adopt a discourse-driven framework for evaluating\nMLLMs, providing a more nuanced assessment of their capabilities. The benchmark\nand code are available at: https://github.com/aashish2000/CORDIAL.",
      "tldr_zh": "这篇论文引入了 CORDIAL 基准，用于评估 Multimodal Large Language Models (MLLMs) 在理解 Coherence Relations 方面的能力，填补了现有基准忽略语用线索和跨模态关系评估的空白。CORDIAL 涵盖了多种 Coherence Relations，在 3 个话语领域和不同粒度级别上进行测试，通过实验比较 10+ MLLMs 的不同提示策略，发现顶级模型如 Gemini 1.5 Pro 和 GPT-4o 的表现不如简单的分类器基准。研究强调，应转向话语驱动框架而非基于相似性的指标，以更全面评估 MLLMs 的能力，并公开了基准代码。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "I.2.7; I.2.10"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11300v1",
      "published_date": "2025-02-16 22:54:44 UTC",
      "updated_date": "2025-02-16 22:54:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:57:29.615754"
    },
    {
      "arxiv_id": "2502.11298v1",
      "title": "Integrating Language Models for Enhanced Network State Monitoring in DRL-Based SFC Provisioning",
      "title_zh": "在基于 DRL 的 SFC 配置中整合语言模型以增强网络状态监控",
      "authors": [
        "Parisa Fard Moshiri",
        "Murat Arda Onsu",
        "Poonam Lohan",
        "Burak Kantarci",
        "Emil Janulewicz"
      ],
      "abstract": "Efficient Service Function Chain (SFC) provisioning and Virtual Network\nFunction (VNF) placement are critical for enhancing network performance in\nmodern architectures such as Software-Defined Networking (SDN) and Network\nFunction Virtualization (NFV). While Deep Reinforcement Learning (DRL) aids\ndecision-making in dynamic network environments, its reliance on structured\ninputs and predefined rules limits adaptability in unforeseen scenarios.\nAdditionally, incorrect actions by a DRL agent may require numerous training\niterations to correct, potentially reinforcing suboptimal policies and\ndegrading performance. This paper integrates DRL with Language Models (LMs),\nspecifically Bidirectional Encoder Representations from Transformers (BERT) and\nDistilBERT, to enhance network management. By feeding final VNF allocations\nfrom DRL into the LM, the system can process and respond to queries related to\nSFCs, DCs, and VNFs, enabling real-time insights into resource utilization,\nbottleneck detection, and future demand planning. The LMs are fine-tuned to our\ndomain-specific dataset using Low-Rank Adaptation (LoRA). Results show that\nBERT outperforms DistilBERT with a lower test loss (0.28 compared to 0.36) and\nhigher confidence (0.83 compared to 0.74), though BERT requires approximately\n46% more processing time.",
      "tldr_zh": "本论文提出将语言模型 (LMs) 如 BERT 和 DistilBERT 集成到基于深度强化学习 (DRL) 的服务功能链 (SFC) 提供中，以提升网络状态监控的适应性和实时性。方法包括将 DRL 的虚拟网络功能 (VNF) 分配输入 LMs 处理 SFC、数据中心 (DCs) 和 VNF 相关的查询，实现资源利用监控、瓶颈检测和需求规划，并使用 Low-Rank Adaptation (LoRA) 对 LMs 进行领域特定微调。实验结果显示，BERT 比 DistilBERT 表现更好，测试损失更低 (0.28 vs 0.36) 和置信度更高 (0.83 vs 0.74)，尽管处理时间增加了约 46%。这为动态网络环境中的决策优化提供了新途径。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.NI",
      "comment": "6 pages, 5 figures, submitted to 30th IEEE International Symposium on\n  Computers and Communications (ISCC) 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.11298v1",
      "published_date": "2025-02-16 22:52:14 UTC",
      "updated_date": "2025-02-16 22:52:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:57:42.198238"
    },
    {
      "arxiv_id": "2502.11295v1",
      "title": "Game-Of-Goals: Using adversarial games to achieve strategic resilience",
      "title_zh": "Game-Of-Goals：利用对抗性游戏实现战略韧性",
      "authors": [
        "Aditya Ghose",
        "Asjad Khan"
      ],
      "abstract": "Our objective in this paper is to develop a machinery that makes a given\norganizational strategic plan resilient to the actions of competitor agents\n(adverse environmental actions). We assume that we are given a goal tree\nrepresenting strategic goals (can also be seen business requirements for a\nsoftware systems) with the assumption that competitor agents are behaving in a\nmaximally adversarial fashion(opposing actions against our sub goals or goals\nin general). We use game tree search methods (such as minimax) to select an\noptimal execution strategy(at a given point in time), such that it can maximize\nour chances of achieving our (high level) strategic goals. Our machinery helps\nus determine which path to follow(strategy selection) to achieve the best end\noutcome. This is done by comparing alternative execution strategies available\nto us via an evaluation function. Our evaluation function is based on the idea\nthat we want to make our execution plans defensible(future-proof) by selecting\nexecution strategies that make us least vulnerable to adversarial actions by\nthe competitor agents. i.e we want to select an execution strategy such that\nits leaves minimum room(or options) for the adversary to cause\nimpediment/damage to our business goals/plans.",
      "tldr_zh": "本研究提出了一种名为Game-Of-Goals的框架，利用对抗游戏(adversarial games)来提升组织战略计划对竞争对手行动的弹性。假设存在一个目标树(goal tree)来表示战略目标，且对手以最大对抗方式行动，该框架采用游戏树搜索方法（如minimax）来选择最优执行策略，从而最大化实现高层战略目标的机会。评估函数通过比较不同执行策略，优先选择那些对对手行动最不脆弱的路径，确保计划的未来防护性(defensible)。这项机制为组织在动态竞争环境中制定稳健战略提供了实用工具。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11295v1",
      "published_date": "2025-02-16 22:34:59 UTC",
      "updated_date": "2025-02-16 22:34:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:57:52.136188"
    },
    {
      "arxiv_id": "2502.11291v1",
      "title": "Dialogue-based Explanations for Logical Reasoning using Structured Argumentation",
      "title_zh": "翻译失败",
      "authors": [
        "Loan Ho",
        "Stefan Schlobach"
      ],
      "abstract": "The problem of explaining inconsistency-tolerant reasoning in knowledge bases\n(KBs) is a prominent topic in Artificial Intelligence (AI). While there is some\nwork on this problem, the explanations provided by existing approaches often\nlack critical information or fail to be expressive enough for non-binary\nconflicts. In this paper, we identify structural weaknesses of the\nstate-of-the-art and propose a generic argumentation-based approach to address\nthese problems. This approach is defined for logics involving reasoning with\nmaximal consistent subsets and shows how any such logic can be translated to\nargumentation. Our work provides dialogue models as dialectic-proof procedures\nto compute and explain a query answer wrt inconsistency-tolerant semantics.\nThis allows us to construct dialectical proof trees as explanations, which are\nmore expressive and arguably more intuitive than existing explanation\nformalisms.",
      "tldr_zh": "这篇论文针对知识库(KBs)中不一致性容忍推理的解释问题，指出现有方法缺乏关键信息和表达性不足。论文提出了一种基于结构化论辩(Structured Argumentation)的通用方法，将涉及最大一致子集的逻辑翻译成论辩框架，并使用对话模型(Dialogue-based)作为辩证证明程序来计算和解释查询答案。相比现有形式，这种方法生成的辩证证明树更具表达性和直观性，提升了逻辑推理的解释效果。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.HC",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "45 pages, 8 gigures, journal",
      "pdf_url": "http://arxiv.org/pdf/2502.11291v1",
      "published_date": "2025-02-16 22:26:18 UTC",
      "updated_date": "2025-02-16 22:26:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:58:04.262198"
    },
    {
      "arxiv_id": "2502.11273v1",
      "title": "FairFare: A Tool for Crowdsourcing Rideshare Data to Empower Labor Organizers",
      "title_zh": "翻译失败",
      "authors": [
        "Dana Calacci",
        "Varun Nagaraj Rao",
        "Samantha Dalal",
        "Catherine Di",
        "Kok-Wei Pua",
        "Andrew Schwartz",
        "Danny Spitzberg",
        "Andrés Monroy-Hernández"
      ],
      "abstract": "Rideshare workers experience unpredictable working conditions due to gig work\nplatforms' reliance on opaque AI and algorithmic systems. In response to these\nchallenges, we found that labor organizers want data to help them advocate for\nlegislation to increase the transparency and accountability of these platforms.\nTo address this need, we collaborated with a Colorado-based rideshare union to\ndevelop FairFare, a tool that crowdsources and analyzes workers' data to\nestimate the take rate -- the percentage of the rider price retained by the\nrideshare platform. We deployed FairFare with our partner organization that\ncollaborated with us in collecting data on 76,000+ trips from 45 drivers over\n18 months. During evaluation interviews, organizers reported that FairFare\nhelped influence the bill language and passage of Colorado Senate Bill 24-75,\ncalling for greater transparency and data disclosure of platform operations,\nand create a national narrative. Finally, we reflect on complexities of\ntranslating quantitative data into policy outcomes, nature of community based\naudits, and design implications for future transparency tools.",
      "tldr_zh": "本研究针对网约车平台依赖不透明的 AI 和算法系统导致工人工作条件不可预测的问题，开发了 FairFare 工具。该工具通过众包方式收集和分析工人的数据，以估算 take rate（平台抽成率），并与科罗拉多州网约车工会合作，收集了超过76,000趟行程的数据。FairFare 帮助劳工组织者影响了 Colorado Senate Bill 24-75 的立法语言和通过，推动平台透明度和数据披露；同时，研究反思了将量化数据转化为政策成果的复杂性，以及未来社区审计和透明工具的设计启示。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "FairFare is hosted at: https://getfairfare.org/",
      "pdf_url": "http://arxiv.org/pdf/2502.11273v1",
      "published_date": "2025-02-16 21:30:26 UTC",
      "updated_date": "2025-02-16 21:30:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:58:16.952670"
    },
    {
      "arxiv_id": "2502.11269v1",
      "title": "Unlocking the Potential of Generative AI through Neuro-Symbolic Architectures: Benefits and Limitations",
      "title_zh": "翻译失败",
      "authors": [
        "Oualid Bougzime",
        "Samir Jabbar",
        "Christophe Cruz",
        "Frédéric Demoly"
      ],
      "abstract": "Neuro-symbolic artificial intelligence (NSAI) represents a transformative\napproach in artificial intelligence (AI) by combining deep learning's ability\nto handle large-scale and unstructured data with the structured reasoning of\nsymbolic methods. By leveraging their complementary strengths, NSAI enhances\ngeneralization, reasoning, and scalability while addressing key challenges such\nas transparency and data efficiency. This paper systematically studies diverse\nNSAI architectures, highlighting their unique approaches to integrating neural\nand symbolic components. It examines the alignment of contemporary AI\ntechniques such as retrieval-augmented generation, graph neural networks,\nreinforcement learning, and multi-agent systems with NSAI paradigms. This study\nthen evaluates these architectures against comprehensive set of criteria,\nincluding generalization, reasoning capabilities, transferability, and\ninterpretability, therefore providing a comparative analysis of their\nrespective strengths and limitations. Notably, the Neuro > Symbolic < Neuro\nmodel consistently outperforms its counterparts across all evaluation metrics.\nThis result aligns with state-of-the-art research that highlight the efficacy\nof such architectures in harnessing advanced technologies like multi-agent\nsystems.",
      "tldr_zh": "这篇论文探讨了神经符号人工智能(NSAI)，它通过结合深度学习的处理能力与符号方法的结构化推理，提升了AI的泛化性、推理能力和可扩展性，同时改善了透明度和数据效率。研究系统分析了各种NSAI架构，包括检索增强生成(retrieval-augmented generation)、图神经网络(graph neural networks)、强化学习和多智能体系统等技术与神经符号组件的整合方式。论文通过评估这些架构在泛化、推理能力、可转移性和可解释性等方面的表现，进行比较分析，结果显示Neuro > Symbolic < Neuro模型在所有指标上表现出色，突显了NSAI在生成式AI领域的潜力及其局限性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "54 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.11269v1",
      "published_date": "2025-02-16 21:06:33 UTC",
      "updated_date": "2025-02-16 21:06:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:58:29.631910"
    },
    {
      "arxiv_id": "2502.11267v1",
      "title": "Prompting in the Dark: Assessing Human Performance in Prompt Engineering for Data Labeling When Gold Labels Are Absent",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu He",
        "Saniya Naphade",
        "Ting-Hao 'Kenneth' Huang"
      ],
      "abstract": "Millions of users prompt large language models (LLMs) for various tasks, but\nhow good are people at prompt engineering? Do users actually get closer to\ntheir desired outcome over multiple iterations of their prompts? These\nquestions are crucial when no gold-standard labels are available to measure\nprogress. This paper investigates a scenario in LLM-powered data labeling,\n\"prompting in the dark,\" where users iteratively prompt LLMs to label data\nwithout using manually-labeled benchmarks. We developed PromptingSheet, a\nGoogle Sheets add-on that enables users to compose, revise, and iteratively\nlabel data through spreadsheets. Through a study with 20 participants, we found\nthat prompting in the dark was highly unreliable-only 9 participants improved\nlabeling accuracy after four or more iterations. Automated prompt optimization\ntools like DSPy also struggled when few gold labels were available. Our\nfindings highlight the importance of gold labels and the needs, as well as the\nrisks, of automated support in human prompt engineering, providing insights for\nfuture tool design.",
      "tldr_zh": "这篇论文探讨了在缺乏金标准标签（gold labels）的情况下，人们在提示工程（prompt engineering）用于数据标记的性能，特别关注“prompting in the dark”场景，即用户迭代提示大型语言模型（LLMs）来标记数据。研究团队开发了 PromptingSheet，一个 Google Sheets 插件，允许用户在电子表格中编写、修改和迭代标记过程；通过 20 名参与者的实验，发现只有 9 人经过四次或更多迭代后提高了标记准确性。自动化提示优化工具如 DSPy 在金标准标签稀缺时也表现不佳，论文强调了金标准标签的重要性，并为人类提示工程的工具设计提供了关键见解和风险警示。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted By CHI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.11267v1",
      "published_date": "2025-02-16 20:54:26 UTC",
      "updated_date": "2025-02-16 20:54:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:58:41.380029"
    },
    {
      "arxiv_id": "2502.11262v1",
      "title": "Generating Skyline Datasets for Data Science Models",
      "title_zh": "为数据科学模型生成天际线数据集",
      "authors": [
        "Mengying Wang",
        "Hanchao Ma",
        "Yiyang Bian",
        "Yangxin Fan",
        "Yinghui Wu"
      ],
      "abstract": "Preparing high-quality datasets required by various data-driven AI and\nmachine learning models has become a cornerstone task in data-driven analysis.\nConventional data discovery methods typically integrate datasets towards a\nsingle pre-defined quality measure that may lead to bias for downstream tasks.\nThis paper introduces MODis, a framework that discovers datasets by optimizing\nmultiple user-defined, model-performance measures. Given a set of data sources\nand a model, MODis selects and integrates data sources into a skyline dataset,\nover which the model is expected to have the desired performance in all the\nperformance measures. We formulate MODis as a multi-goal finite state\ntransducer, and derive three feasible algorithms to generate skyline datasets.\nOur first algorithm adopts a \"reduce-from-universal\" strategy, that starts with\na universal schema and iteratively prunes unpromising data. Our second\nalgorithm further reduces the cost with a bi-directional strategy that\ninterleaves data augmentation and reduction. We also introduce a\ndiversification algorithm to mitigate the bias in skyline datasets. We\nexperimentally verify the efficiency and effectiveness of our skyline data\ndiscovery algorithms, and showcase their applications in optimizing data\nscience pipelines.",
      "tldr_zh": "本文提出 MODis 框架，用于通过优化多个用户定义的模型性能指标（如模型准确性）来发现和整合数据源，生成 skyline dataset，以避免传统方法对下游任务的偏差。MODis 被形式化为 multi-goal finite state transducer，并开发了三种算法：reduce-from-universal 策略（从通用模式逐步修剪数据）、bi-directional 策略（交替数据增强和减少），以及 diversification 算法（缓解数据集偏差）。实验结果证明了这些算法的效率和有效性，并在优化数据科学管道的应用中展示了实际价值。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "EDBT25",
      "pdf_url": "http://arxiv.org/pdf/2502.11262v1",
      "published_date": "2025-02-16 20:33:59 UTC",
      "updated_date": "2025-02-16 20:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:58:53.153910"
    },
    {
      "arxiv_id": "2502.11251v1",
      "title": "Explaining Necessary Truths",
      "title_zh": "翻译失败",
      "authors": [
        "Gülce Kardeş",
        "Simon DeDeo"
      ],
      "abstract": "Knowing the truth is rarely enough -- we also seek out reasons why the fact\nis true. While much is known about how we explain contingent truths, we\nunderstand less about how we explain facts, such as those in mathematics, that\nare true as a matter of logical necessity. We present a framework, based in\ncomputational complexity, where explanations for deductive truths co-emerge\nwith discoveries of simplifying steps during the search process. When such\nstructures are missing, we revert, in turn, to error-based reasons, where a\n(corrected) mistake can serve as fictitious, but explanatory,\ncontingency-cause: not making the mistake serves as a reason why the truth\ntakes the form it does. We simulate human subjects, using GPT-4o, presented\nwith SAT puzzles of varying complexity and reasonableness, validating our\ntheory and showing how its predictions can be tested in future human studies.",
      "tldr_zh": "该论文探讨了如何解释必然真理（如数学逻辑事实），提出一个基于 computational complexity 的框架，在搜索过程中同时生成解释和简化步骤。框架强调，当结构缺失时，可通过 error-based reasons 模拟原因，即通过纠正错误来阐明真理的形式。实验使用 GPT-4o 模拟人类在不同复杂度的 SAT puzzles 上进行测试，验证了理论并为未来人类研究提供了可测试的预测。",
      "categories": [
        "cs.AI",
        "cs.CC",
        "math.HO",
        "q-bio.NC",
        "97C30 (Primary), 91E10 (Secondary)"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, in review",
      "pdf_url": "http://arxiv.org/pdf/2502.11251v1",
      "published_date": "2025-02-16 20:11:39 UTC",
      "updated_date": "2025-02-16 20:11:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:59:04.664972"
    },
    {
      "arxiv_id": "2502.11245v1",
      "title": "Shortcuts and Identifiability in Concept-based Models from a Neuro-Symbolic Lens",
      "title_zh": "翻译失败",
      "authors": [
        "Samuele Bortolotti",
        "Emanuele Marconato",
        "Paolo Morettin",
        "Andrea Passerini",
        "Stefano Teso"
      ],
      "abstract": "Concept-based Models are neural networks that learn a concept extractor to\nmap inputs to high-level concepts and an inference layer to translate these\ninto predictions. Ensuring these modules produce interpretable concepts and\nbehave reliably in out-of-distribution is crucial, yet the conditions for\nachieving this remain unclear. We study this problem by establishing a novel\nconnection between Concept-based Models and reasoning shortcuts (RSs), a common\nissue where models achieve high accuracy by learning low-quality concepts, even\nwhen the inference layer is fixed and provided upfront. Specifically, we first\nextend RSs to the more complex setting of Concept-based Models and then derive\ntheoretical conditions for identifying both the concepts and the inference\nlayer. Our empirical results highlight the impact of reasoning shortcuts and\nshow that existing methods, even when combined with multiple natural mitigation\nstrategies, often fail to meet these conditions in practice.",
      "tldr_zh": "本研究从神经符号视角（Neuro-Symbolic Lens）探讨了Concept-based Models中的推理捷径（reasoning shortcuts），这些模型通过概念提取器映射输入到高级概念，并使用推理层进行预测。论文扩展了RSs的概念，建立了其与Concept-based Models的联系，并推导出了识别概念和推理层的理论条件，以确保模型的可解释性和分布外可靠性。实证结果表明，推理捷径显著影响模型性能，现有的缓解策略即使结合多种方法，也往往无法在实践中满足这些条件。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11245v1",
      "published_date": "2025-02-16 19:45:09 UTC",
      "updated_date": "2025-02-16 19:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:59:16.065250"
    },
    {
      "arxiv_id": "2502.11244v1",
      "title": "Soteria: Language-Specific Functional Parameter Steering for Multilingual Safety Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Somnath Banerjee",
        "Sayan Layek",
        "Pratyush Chatterjee",
        "Animesh Mukherjee",
        "Rima Hazra"
      ],
      "abstract": "Ensuring consistent safety across multiple languages remains a significant\nchallenge for large language models (LLMs). We introduce Soteria, a lightweight\nyet powerful strategy that locates and minimally adjusts the \"functional heads\"\nmost responsible for harmful content generation in each language. By altering\nonly a fraction of parameters, Soteria drastically reduces policy violations\nwithout sacrificing overall model performance, even in low-resource settings.\nTo rigorously evaluate our approach, we also present XThreatBench, a\nspecialized multilingual dataset capturing fine-grained harmful behaviors drawn\nfrom real policy guidelines. Experiments with leading open-source LLMs (e.g.,\nLlama, Qwen, Mistral) show that Soteria consistently improves safety metrics\nacross high-, mid-, and low-resource languages. These findings highlight a\npromising path toward scalable, linguistically attuned, and ethically aligned\nLLMs worldwide.",
      "tldr_zh": "这篇论文介绍了 Soteria，一种轻量级策略，通过针对特定语言定位并最小调整“functional heads”参数，来实现大型语言模型（LLMs）在多语言环境下的安全对齐，从而显著减少有害内容生成。Soteria 只需修改少量参数，就能降低政策违规风险，同时保持模型整体性能，尤其适用于低资源语言场景。为评估其效果，研究者开发了 XThreatBench，一个专注于多语言有害行为的细粒度数据集。实验在 Llama、Qwen 和 Mistral 等开源 LLMs 上显示，Soteria 一致提升了高、中、低资源语言的安全指标，为可扩展、语言适应和道德对齐的全球 LLMs 提供了新路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11244v1",
      "published_date": "2025-02-16 19:44:01 UTC",
      "updated_date": "2025-02-16 19:44:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:59:29.337812"
    },
    {
      "arxiv_id": "2502.11239v2",
      "title": "Towards identifying possible fault-tolerant advantage of quantum linear system algorithms in terms of space, time and energy",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Tu",
        "Mark Dubynskyi",
        "Mohammadhossein Mohammadisiahroudi",
        "Ekaterina Riashchentceva",
        "Jinglei Cheng",
        "Dmitry Ryashchentsev",
        "Tamás Terlaky",
        "Junyu Liu"
      ],
      "abstract": "Quantum computing, a prominent non-Von Neumann paradigm beyond Moore's law,\ncan offer superpolynomial speedups for certain problems. Yet its advantages in\nefficiency for tasks like machine learning remain under investigation, and\nquantum noise complicates resource estimations and classical comparisons. We\nprovide a detailed estimation of space, time, and energy resources for\nfault-tolerant superconducting devices running the Harrow-Hassidim-Lloyd (HHL)\nalgorithm, a quantum linear system solver relevant to linear algebra and\nmachine learning. Excluding memory and data transfer, possible quantum\nadvantages over the classical conjugate gradient method could emerge at $N\n\\approx 2^{33} \\sim 2^{48}$ or even lower, requiring ${O}(10^5)$ physical\nqubits, ${O}(10^{12}\\sim10^{13})$ Joules, and ${O}(10^6)$ seconds under surface\ncode fault-tolerance with three types of magic state distillation (15-1,\n116-12, 225-1). Key parameters include condition number, sparsity, and\nprecision $\\kappa, s\\approx{O}(10\\sim100)$, $\\epsilon\\sim0.01$, and physical\nerror $10^{-5}$. Our resource estimator adjusts $N, \\kappa, s, \\epsilon$,\nproviding a map of quantum-classical boundaries and revealing where a practical\nquantum advantage may arise. Our work quantitatively determine how advanced a\nfault-tolerant quantum computer should be to achieve possible, significant\nbenefits on problems related to real-world.",
      "tldr_zh": "本研究评估了量子线性系统算法（如Harrow-Hassidim-Lloyd (HHL) algorithm）在容错条件下与经典共轭梯度方法相比的空间、时间和能量优势，特别针对超导设备和表面码容错。研究通过详细资源估算，考虑量子噪声、魔术态蒸馏（包括15-1、116-12和225-1类型）以及关键参数如条件数κ、稀疏性s（约10~100）和精度ε（约0.01），发现当矩阵规模N约2^33~2^48时，量子算法可能实现优势，而无需额外内存和数据传输，但需约10^5物理量子比特、10^12~10^13焦耳能量和10^6秒时间。该工作提供了一个可调整参数的资源估算器，映射量子-经典边界，并量化了构建容错量子计算机以实现实际优势所需的条件。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "quant-ph",
      "comment": "28 pages, many figures. v2: correcting typos",
      "pdf_url": "http://arxiv.org/pdf/2502.11239v2",
      "published_date": "2025-02-16 19:12:32 UTC",
      "updated_date": "2025-02-18 03:35:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:59:41.469825"
    },
    {
      "arxiv_id": "2502.14889v1",
      "title": "Narrowing Information Bottleneck Theory for Multimodal Image-Text Representations Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyu Zhu",
        "Zhibo Jin",
        "Jiayu Zhang",
        "Nan Yang",
        "Jiahao Huang",
        "Jianlong Zhou",
        "Fang Chen"
      ],
      "abstract": "The task of identifying multimodal image-text representations has garnered\nincreasing attention, particularly with models such as CLIP (Contrastive\nLanguage-Image Pretraining), which demonstrate exceptional performance in\nlearning complex associations between images and text. Despite these\nadvancements, ensuring the interpretability of such models is paramount for\ntheir safe deployment in real-world applications, such as healthcare. While\nnumerous interpretability methods have been developed for unimodal tasks, these\napproaches often fail to transfer effectively to multimodal contexts due to\ninherent differences in the representation structures. Bottleneck methods,\nwell-established in information theory, have been applied to enhance CLIP's\ninterpretability. However, they are often hindered by strong assumptions or\nintrinsic randomness. To overcome these challenges, we propose the Narrowing\nInformation Bottleneck Theory, a novel framework that fundamentally redefines\nthe traditional bottleneck approach. This theory is specifically designed to\nsatisfy contemporary attribution axioms, providing a more robust and reliable\nsolution for improving the interpretability of multimodal models. In our\nexperiments, compared to state-of-the-art methods, our approach enhances image\ninterpretability by an average of 9%, text interpretability by an average of\n58.83%, and accelerates processing speed by 63.95%. Our code is publicly\naccessible at https://github.com/LMBTough/NIB.",
      "tldr_zh": "本研究针对多模态图像-文本表示的可解释性问题，特别是在 CLIP 等模型中，确保其在实际应用（如医疗）中的安全部署。论文提出 Narrowing Information Bottleneck Theory，这是一种新型框架，重新定义传统瓶颈方法，以满足当代归因公理，并解决现有方法的强假设和随机性问题，从而提升多模态模型的稳健性。实验结果显示，与最先进方法相比，该框架将图像可解释性平均提高9%，文本可解释性平均提高58.83%，并将处理速度加速63.95%，代码已在GitHub公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14889v1",
      "published_date": "2025-02-16 19:01:37 UTC",
      "updated_date": "2025-02-16 19:01:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:59:52.537806"
    },
    {
      "arxiv_id": "2502.12207v1",
      "title": "PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive Auto-Regression AdvGAN",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayu Zhang",
        "Zhiyu Zhu",
        "Xinyi Wang",
        "Silin Liao",
        "Zhibo Jin",
        "Flora D. Salim",
        "Huaming Chen"
      ],
      "abstract": "Deep neural networks have demonstrated remarkable performance across various\ndomains. However, they are vulnerable to adversarial examples, which can lead\nto erroneous predictions. Generative Adversarial Networks (GANs) can leverage\nthe generators and discriminators model to quickly produce high-quality\nadversarial examples. Since both modules train in a competitive and\nsimultaneous manner, GAN-based algorithms like AdvGAN can generate adversarial\nexamples with better transferability compared to traditional methods. However,\nthe generation of perturbations is usually limited to a single iteration,\npreventing these examples from fully exploiting the potential of the methods.\nTo tackle this issue, we introduce a novel approach named Progressive\nAuto-Regression AdvGAN (PAR-AdvGAN). It incorporates an auto-regressive\niteration mechanism within a progressive generation network to craft\nadversarial examples with enhanced attack capability. We thoroughly evaluate\nour PAR-AdvGAN method with a large-scale experiment, demonstrating its superior\nperformance over various state-of-the-art black-box adversarial attacks, as\nwell as the original AdvGAN.Moreover, PAR-AdvGAN significantly accelerates the\nadversarial example generation, i.e., achieving the speeds of up to 335.5\nframes per second on Inception-v3 model, outperforming the gradient-based\ntransferable attack algorithms. Our code is available at:\nhttps://anonymous.4open.science/r/PAR-01BF/",
      "tldr_zh": "深度神经网络虽然在多个领域表现出色，但容易受到对抗样本(adversarial examples)的攻击，导致预测错误。为解决现有GANs-based方法如AdvGAN的单次迭代限制，本文提出PAR-AdvGAN，通过引入自回归迭代机制(auto-regressive iteration)和渐进生成网络(progressive generation network)来提升对抗攻击能力。实验结果表明，PAR-AdvGAN在大规模黑盒攻击测试中优于现有算法，提高了攻击性能，并显著加速了样本生成速度，如在Inception-v3模型上达到335.5 frames per second。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.12207v1",
      "published_date": "2025-02-16 19:00:55 UTC",
      "updated_date": "2025-02-16 19:00:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:00:05.180789"
    },
    {
      "arxiv_id": "2502.13162v1",
      "title": "ShieldLearner: A New Paradigm for Jailbreak Attack Defense in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyi Ni",
        "Hao Wang",
        "Huacan Wang"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable success in various\ndomains but remain vulnerable to adversarial jailbreak attacks. Existing\nprompt-defense strategies, including parameter-modifying and parameter-free\napproaches, face limitations in adaptability, interpretability, and\ncustomization, constraining their effectiveness against evolving threats. To\naddress these challenges, we propose ShieldLearner, a novel paradigm that\nmimics human learning in defense. Through trial and error, it autonomously\ndistills attack signatures into a Pattern Atlas and synthesizes defense\nheuristics into a Meta-analysis Framework, enabling systematic and\ninterpretable threat detection. Furthermore, we introduce Adaptive Adversarial\nAugmentation to generate adversarial variations of successfully defended\nprompts, enabling continuous self-improvement without model retraining. In\naddition to standard benchmarks, we create a hard test set by curating\nadversarial prompts from the Wildjailbreak dataset, emphasizing more concealed\nmalicious intent. Experimental results show that ShieldLearner achieves a\nsignificantly higher defense success rate than existing baselines on both\nconventional and hard test sets, while also operating with lower computational\noverhead, making it a practical and efficient solution for real-world\nadversarial defense.",
      "tldr_zh": "该论文提出 ShieldLearner，一种新型防御范式，模仿人类学习过程，通过试错自主提炼攻击签名（attack signatures）到 Pattern Atlas，并合成防御启发式（defense heuristics）到 Meta-analysis Framework，实现对 Large Language Models (LLMs) 中 jailbreak attacks 的系统化、可解释检测。同时，引入 Adaptive Adversarial Augmentation 生成对抗变体，促进防御策略的持续自我改进，而无需重新训练模型。实验结果表明，ShieldLearner 在标准基准和基于 Wildjailbreak 的硬测试集上，比现有基线方法实现了更高的防御成功率，并显著降低了计算开销，提供了一个实用高效的对抗防御解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13162v1",
      "published_date": "2025-02-16 18:47:41 UTC",
      "updated_date": "2025-02-16 18:47:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:00:17.679935"
    },
    {
      "arxiv_id": "2502.11228v1",
      "title": "Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly Improves Retrieval Augmented Generation With LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Reza Rezaei",
        "Adji Bousso Dieng"
      ],
      "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\nfor domain-specific question-answering (QA) tasks by leveraging external\nknowledge sources. However, traditional RAG systems primarily focus on\nrelevance-based retrieval and often struggle with redundancy, especially when\nreasoning requires connecting information from multiple sources. This paper\nintroduces Vendi-RAG, a framework based on an iterative process that jointly\noptimizes retrieval diversity and answer quality. This joint optimization leads\nto significantly higher accuracy for multi-hop QA tasks. Vendi-RAG leverages\nthe Vendi Score (VS), a flexible similarity-based diversity metric, to promote\nsemantic diversity in document retrieval. It then uses an LLM judge that\nevaluates candidate answers, generated after a reasoning step, and outputs a\nscore that the retriever uses to balance relevance and diversity among the\nretrieved documents during each iteration. Experiments on three challenging\ndatasets -- HotpotQA, MuSiQue, and 2WikiMultiHopQA -- demonstrate Vendi-RAG's\neffectiveness in multi-hop reasoning tasks. The framework achieves significant\naccuracy improvements over traditional single-step and multi-step RAG\napproaches, with accuracy increases reaching up to +4.2% on HotpotQA, +4.1% on\n2WikiMultiHopQA, and +1.3% on MuSiQue compared to Adaptive-RAG, the current\nbest baseline. The benefits of Vendi-RAG are even more pronounced as the number\nof retrieved documents increases. Finally, we evaluated Vendi-RAG across\ndifferent LLM backbones, including GPT-3.5, GPT-4, and GPT-4o-mini, and\nobserved consistent improvements, demonstrating that the framework's advantages\nare model-agnostic.",
      "tldr_zh": "本文提出 Vendi-RAG 框架，通过迭代过程自适应权衡检索多样性和答案质量，显著提升了基于大型语言模型 (LLMs) 的检索增强生成 (RAG) 在多跳问答 (QA) 任务中的准确性。框架利用 Vendi Score (VS) 作为多样性指标，促进文档检索的语义多样性，并通过 LLM 判断器评估候选答案，以平衡相关性和多样性。实验在 HotpotQA、MuSiQue 和 2WikiMultiHopQA 数据集上显示，Vendi-RAG 相较于 Adaptive-RAG 等基线提高了准确率，最高达 +4.2%。此外，该框架在不同 LLM 后端（如 GPT-3.5、GPT-4 和 GPT-4o-mini）上表现出模型无关性的稳健优势，尤其在检索文档数量增加时效果更明显。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "A RAG pipeline that accounts for both diversity and answer quality\n  and that can be used with any LLM backbone to solve complex multi-hop\n  question-answering tasks",
      "pdf_url": "http://arxiv.org/pdf/2502.11228v1",
      "published_date": "2025-02-16 18:46:10 UTC",
      "updated_date": "2025-02-16 18:46:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:00:30.498999"
    },
    {
      "arxiv_id": "2502.11225v1",
      "title": "METAFOR: A Hybrid Metaheuristics Software Framework for Single-Objective Continuous Optimization Problems",
      "title_zh": "METAFOR：一种混合元启发式软件框架，用于单目标连续优化问题",
      "authors": [
        "Christian Camacho-Villalón",
        "Marco Dorigo",
        "Thomas Stützle"
      ],
      "abstract": "Hybrid metaheuristics are powerful techniques for solving difficult\noptimization problems that exploit the strengths of different approaches in a\nsingle implementation. For algorithm designers, however, creating hybrid\nmetaheuristic implementations has become increasingly challenging due to the\nvast number of design options available in the literature and the fact that\nthey often rely on their knowledge and intuition to come up with new algorithm\ndesigns. In this paper, we propose a modular metaheuristic software framework,\ncalled METAFOR, that can be coupled with an automatic algorithm configuration\ntool to automatically design hybrid metaheuristics. METAFOR is specifically\ndesigned to hybridize Particle Swarm Optimization, Differential Evolution and\nCovariance Matrix Adaptation-Evolution Strategy, and includes a local search\nmodule that allows their execution to be interleaved with a subordinate local\nsearch. We use the configuration tool irace to automatically generate 17\ndifferent metaheuristic implementations and evaluate their performance on a\ndiverse set of continuous optimization problems. Our results show that, across\nall the considered problem classes, automatically generated hybrid\nimplementations are able to outperform configured single-approach\nimplementations, while these latter offer advantages on specific classes of\nfunctions. We provide useful insights on the type of hybridization that works\nbest for specific problem classes, the algorithm components that contribute to\nthe performance of the algorithms, and the advantages and disadvantages of two\nwell-known instance separation strategies, creating stratified training set\nusing a fix percentage and leave-one-class-out cross-validation.",
      "tldr_zh": "本研究提出METAFOR，一种模块化元启发式软件框架，用于自动设计针对单目标连续优化问题的混合元启发式算法。该框架结合Particle Swarm Optimization、Differential Evolution和Covariance Matrix Adaptation-Evolution Strategy，并集成局部搜索模块，通过irace工具自动生成17种不同实现。实验结果显示，这些自动生成的混合算法在各种优化问题类别上比单一方法实现性能更优，提升了整体效果。同时，研究提供了关于最佳混合策略、关键算法组件贡献以及两种实例分离策略（固定百分比分层训练集和leave-one-class-out交叉验证）的宝贵见解。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11225v1",
      "published_date": "2025-02-16 18:24:44 UTC",
      "updated_date": "2025-02-16 18:24:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:00:41.767582"
    },
    {
      "arxiv_id": "2502.13161v1",
      "title": "Noumenal Labs White Paper: How To Build A Brain",
      "title_zh": "Noumenal Labs 白皮书：如何构建一个大脑",
      "authors": [
        "Maxwell J. D. Ramstead",
        "Candice Pattisapu",
        "Jason Fox",
        "Jeff Beck"
      ],
      "abstract": "This white paper describes some of the design principles for artificial or\nmachine intelligence that guide efforts at Noumenal Labs. These principles are\ndrawn from both nature and from the means by which we come to represent and\nunderstand it. The end goal of research and development in this field should be\nto design machine intelligences that augment our understanding of the world and\nenhance our ability to act in it, without replacing us. In the first two\nsections, we examine the core motivation for our approach: resolving the\ngrounding problem. We argue that the solution to the grounding problem rests in\nthe design of models grounded in the world that we inhabit, not mere word\nmodels. A machine super intelligence that is capable of significantly enhancing\nour understanding of the human world must represent the world as we do and be\ncapable of generating new knowledge, building on what we already know. In other\nwords, it must be properly grounded and explicitly designed for rational,\nempirical inquiry, modeled after the scientific method. A primary implication\nof this design principle is that agents must be capable of engaging\nautonomously in causal physics discovery. We discuss the pragmatic implications\nof this approach, and in particular, the use cases in realistic 3D world\nmodeling and multimodal, multidimensional time series analysis.",
      "tldr_zh": "Noumenal Labs 的白皮书概述了构建机器智能（machine intelligence）的设计原则，这些原则借鉴自然和人类认知，旨在创建能增强人类对世界的理解和行动能力，而非取代人类。核心动机是解决 grounding problem，通过设计基于真实世界的模型，使机器智能能够像人类一样代表世界、生成新知识，并遵循科学方法进行理性实证探究。论文强调，机器智能需具备自主进行因果物理发现（causal physics discovery）的能力，并应用于现实3D世界建模（3D world modeling）和多模态、多维时间序列分析（multimodal time series analysis）。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13161v1",
      "published_date": "2025-02-16 18:15:37 UTC",
      "updated_date": "2025-02-16 18:15:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:00:53.698977"
    },
    {
      "arxiv_id": "2502.11221v1",
      "title": "PlanGenLLMs: A Modern Survey of LLM Planning Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Hui Wei",
        "Zihao Zhang",
        "Shenghua He",
        "Tian Xia",
        "Shijia Pan",
        "Fei Liu"
      ],
      "abstract": "LLMs have immense potential for generating plans, transforming an initial\nworld state into a desired goal state. A large body of research has explored\nthe use of LLMs for various planning tasks, from web navigation to travel\nplanning and database querying. However, many of these systems are tailored to\nspecific problems, making it challenging to compare them or determine the best\napproach for new tasks. There is also a lack of clear and consistent evaluation\ncriteria. Our survey aims to offer a comprehensive overview of current LLM\nplanners to fill this gap. It builds on foundational work by Kartam and Wilkins\n(1990) and examines six key performance criteria: completeness, executability,\noptimality, representation, generalization, and efficiency. For each, we\nprovide a thorough analysis of representative works and highlight their\nstrengths and weaknesses. Our paper also identifies crucial future directions,\nmaking it a valuable resource for both practitioners and newcomers interested\nin leveraging LLM planning to support agentic workflows.",
      "tldr_zh": "这篇论文“PlanGenLLMs”对大型语言模型（LLMs）的规划能力进行了现代调查，旨在填补现有研究中系统间比较不足和评估标准不一致的空白。论文基于Kartam和Wilkins (1990)的基础工作，考察了六个关键性能标准：completeness、executability、optimality、representation、generalization和efficiency，并分析了代表性作品的优缺点。最终，它为从业者和新人提供了宝贵资源，突出了LLMs在支持代理工作流方面的潜力，并指出了未来研究方向。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint. Under review",
      "pdf_url": "http://arxiv.org/pdf/2502.11221v1",
      "published_date": "2025-02-16 17:54:57 UTC",
      "updated_date": "2025-02-16 17:54:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:01:06.912483"
    },
    {
      "arxiv_id": "2502.11213v1",
      "title": "Stochastic Optimization of Inventory at Large-scale Supply Chains",
      "title_zh": "大型供应链库存的随机优化",
      "authors": [
        "Zhaoyang Larry Jin",
        "Mehdi Maasoumy",
        "Yimin Liu",
        "Zeshi Zheng",
        "Zizhuo Ren"
      ],
      "abstract": "Today's global supply chains face growing challenges due to rapidly changing\nmarket conditions, increased network complexity and inter-dependency, and\ndynamic uncertainties in supply, demand, and other factors. To combat these\nchallenges, organizations employ Material Requirements Planning (MRP) software\nsolutions to set inventory stock buffers - for raw materials, work-in-process\ngoods, and finished products - to help them meet customer service levels.\nHowever, holding excess inventory further complicates operations and can lock\nup millions of dollars of capital that could be otherwise deployed.\nFurthermore, most commercially available MRP solutions fall short in\nconsidering uncertainties and do not result in optimal solutions for modern\nenterprises.\n  At C3 AI, we fundamentally reformulate the inventory management problem as a\nconstrained stochastic optimization. We then propose a simulation-optimization\nframework that minimizes inventory and related costs while maintaining desired\nservice levels. The framework's goal is to find the optimal reorder parameters\nthat minimize costs subject to a pre-defined service-level constraint and all\nother real-world operational constraints. These optimal reorder parameters can\nbe fed back into an MRP system to drive optimal order placement, or used to\nplace optimal orders directly. This approach has proven successful in reducing\ninventory levels by 10-35 percent, resulting in hundreds of millions of dollars\nof economic benefit for major enterprises at a global scale.",
      "tldr_zh": "该研究针对大型供应链的库存管理问题，强调了市场不确定性、网络复杂性和动态因素带来的挑战，并指出现有 Material Requirements Planning (MRP) 软件忽略不确定性，导致库存过高和非最优解决方案。研究者将库存管理重新定义为受约束的 stochastic optimization，并提出一个 simulation-optimization framework，以最小化库存和相关成本，同时满足预设的服务水平约束和其他操作限制。该框架通过优化重新订购参数（optimal reorder parameters），可直接集成到 MRP 系统或用于订单放置，并在实际应用中为全球企业减少库存 10-35%，带来数亿美元的经济效益。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11213v1",
      "published_date": "2025-02-16 17:25:50 UTC",
      "updated_date": "2025-02-16 17:25:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:01:17.714048"
    },
    {
      "arxiv_id": "2502.11211v1",
      "title": "A Survey of LLM-based Agents in Medicine: How far are we from Baymax?",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxuan Wang",
        "Zizhan Ma",
        "Zheng Wang",
        "Chenghan Wu",
        "Wenting Chen",
        "Xiang Li",
        "Yixuan Yuan"
      ],
      "abstract": "Large Language Models (LLMs) are transforming healthcare through the\ndevelopment of LLM-based agents that can understand, reason about, and assist\nwith medical tasks. This survey provides a comprehensive review of LLM-based\nagents in medicine, examining their architectures, applications, and\nchallenges. We analyze the key components of medical agent systems, including\nsystem profiles, clinical planning mechanisms, medical reasoning frameworks,\nand external capacity enhancement. The survey covers major application\nscenarios such as clinical decision support, medical documentation, training\nsimulations, and healthcare service optimization. We discuss evaluation\nframeworks and metrics used to assess these agents' performance in healthcare\nsettings. While LLM-based agents show promise in enhancing healthcare delivery,\nseveral challenges remain, including hallucination management, multimodal\nintegration, implementation barriers, and ethical considerations. The survey\nconcludes by highlighting future research directions, including advances in\nmedical reasoning inspired by recent developments in LLM architectures,\nintegration with physical systems, and improvements in training simulations.\nThis work provides researchers and practitioners with a structured overview of\nthe current state and future prospects of LLM-based agents in medicine.",
      "tldr_zh": "这篇调查综述了大型语言模型（LLM-based agents）在医学领域的架构、应用和挑战，分析了关键组件如系统配置文件、临床规划机制、医学推理框架以及外部能力增强。论文涵盖了主要应用场景，包括临床决策支持、医疗文档、训练模拟和医疗服务优化，并讨论了评估框架、指标以及面临的挑战，如幻觉管理、多模态集成、实施障碍和伦理考虑。最终，它强调了未来研究方向，如医学推理的进步、与物理系统的集成和训练模拟的改进，为研究者和从业者提供了LLM-based agents在医学中的当前状态和前景的结构化概述。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11211v1",
      "published_date": "2025-02-16 17:21:05 UTC",
      "updated_date": "2025-02-16 17:21:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:01:30.190772"
    },
    {
      "arxiv_id": "2502.11201v2",
      "title": "Bridging the Gap: Enabling Natural Language Queries for NoSQL Databases through Text-to-NoSQL Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Jinwei Lu",
        "Yuanfeng Song",
        "Zhiqian Qin",
        "Haodi Zhang",
        "Chen Zhang",
        "Raymond Chi-Wing Wong"
      ],
      "abstract": "NoSQL databases have become increasingly popular due to their outstanding\nperformance in handling large-scale, unstructured, and semi-structured data,\nhighlighting the need for user-friendly interfaces to bridge the gap between\nnon-technical users and complex database queries. In this paper, we introduce\nthe Text-to-NoSQL task, which aims to convert natural language queries into\nNoSQL queries, thereby lowering the technical barrier for non-expert users. To\npromote research in this area, we developed a novel automated dataset\nconstruction process and released a large-scale and open-source dataset for\nthis task, named TEND (short for Text-to-NoSQL Dataset). Additionally, we\ndesigned a SLM (Small Language Model)-assisted and RAG (Retrieval-augmented\nGeneration)-assisted multi-step framework called SMART, which is specifically\ndesigned for Text-to-NoSQL conversion. To ensure comprehensive evaluation of\nthe models, we also introduced a detailed set of metrics that assess the\nmodel's performance from both the query itself and its execution results. Our\nexperimental results demonstrate the effectiveness of our approach and\nestablish a benchmark for future research in this emerging field. We believe\nthat our contributions will pave the way for more accessible and intuitive\ninteractions with NoSQL databases.",
      "tldr_zh": "本研究旨在解决NoSQL数据库查询对非技术用户的技术门槛问题，通过提出Text-to-NoSQL任务，将自然语言查询转换为NoSQL查询以提升用户友好性。研究团队开发了自动数据集构建过程，并发布了大规模开源数据集TEND，同时设计了SLM辅助和RAG辅助的多步框架SMART，用于高效的查询转换。论文引入了全面的评估指标，从查询本身和执行结果两个方面评估模型性能，实验结果证明了该方法的有效性，并为未来NoSQL数据库交互研究建立了基准。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11201v2",
      "published_date": "2025-02-16 17:01:48 UTC",
      "updated_date": "2025-02-18 06:48:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:01:41.722571"
    },
    {
      "arxiv_id": "2502.11196v1",
      "title": "How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on Continual Pre-Training",
      "title_zh": "翻译失败",
      "authors": [
        "Yixin Ou",
        "Yunzhi Yao",
        "Ningyu Zhang",
        "Hui Jin",
        "Jiacheng Sun",
        "Shumin Deng",
        "Zhenguo Li",
        "Huajun Chen"
      ],
      "abstract": "Despite exceptional capabilities in knowledge-intensive tasks, Large Language\nModels (LLMs) face a critical gap in understanding how they internalize new\nknowledge, particularly how to structurally embed acquired knowledge in their\nneural computations. We address this issue through the lens of knowledge\ncircuit evolution, identifying computational subgraphs that facilitate\nknowledge storage and processing. Our systematic analysis of circuit evolution\nthroughout continual pre-training reveals several key findings: (1) the\nacquisition of new knowledge is influenced by its relevance to pre-existing\nknowledge; (2) the evolution of knowledge circuits exhibits a distinct phase\nshift from formation to optimization; (3) the evolution of knowledge circuits\nfollows a deep-to-shallow pattern. These insights not only advance our\ntheoretical understanding of the mechanisms of new knowledge acquisition in\nLLMs, but also provide potential implications for improving continual\npre-training strategies to enhance model performance. Code and data will be\navailable at https://github.com/zjunlp/DynamicKnowledgeCircuits.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)如何获取新知识，采用知识电路(Knowledge Circuits)的视角，分析其在持续预训练(Continual Pre-Training)过程中的神经计算演化。研究通过识别促进知识存储和处理的计算子图，对电路演化进行系统分析，发现新知识获取受其与现有知识的相关性影响，且演化呈现从形成到优化的阶段转变，以及从深层到浅层的模式。这些发现深化了对LLMs知识内部化机制的理论理解，并为改进持续预训练策略以提升模型性能提供潜在启示。代码和数据可从GitHub获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2502.11196v1",
      "published_date": "2025-02-16 16:55:43 UTC",
      "updated_date": "2025-02-16 16:55:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:01:54.286657"
    },
    {
      "arxiv_id": "2502.11195v1",
      "title": "From Deception to Perception: The Surprising Benefits of Deepfakes for Detecting, Measuring, and Mitigating Bias",
      "title_zh": "翻译失败",
      "authors": [
        "Yizhi Liu",
        "Balaji Padmanabhan",
        "Siva Viswanathan"
      ],
      "abstract": "While deepfake technologies have predominantly been criticized for potential\nmisuse, our study demonstrates their significant potential as tools for\ndetecting, measuring, and mitigating biases in key societal domains. By\nemploying deepfake technology to generate controlled facial images, we extend\nthe scope of traditional correspondence studies beyond mere textual\nmanipulations. This enhancement is crucial in scenarios such as pain\nassessments, where subjective biases triggered by sensitive features in facial\nimages can profoundly affect outcomes. Our results reveal that deepfakes not\nonly maintain the effectiveness of correspondence studies but also introduce\ngroundbreaking advancements in bias measurement and correction techniques. This\nstudy emphasizes the constructive role of deepfake technologies as essential\ntools for advancing societal equity and fairness.",
      "tldr_zh": "本研究探讨了 deepfake 技术的积极应用，展示其在检测、测量和缓解社会领域偏见方面的潜力。通过使用 deepfake 生成受控的 facial images，该方法扩展了传统 correspondence studies 的范围，尤其在 pain assessments 等场景中，处理 facial images 中的敏感特征以减少主观偏见。结果表明，deepfakes 不仅维持了原有研究的有效性，还引入了创新的 bias measurement and correction 技术，最终促进社会公平和公正。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.0; I.2.10; I.4.0; J.4; H.4; K.4.1; K.4.2"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11195v1",
      "published_date": "2025-02-16 16:55:28 UTC",
      "updated_date": "2025-02-16 16:55:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:02:05.892562"
    },
    {
      "arxiv_id": "2502.11191v1",
      "title": "Primus: A Pioneering Collection of Open-Source Datasets for Cybersecurity LLM Training",
      "title_zh": "Primus：网络安全",
      "authors": [
        "Yao-Ching Yu",
        "Tsun-Han Chiang",
        "Cheng-Wei Tsai",
        "Chien-Ming Huang",
        "Wen-Kwang Tsao"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable advancements in\nspecialized fields such as finance, law, and medicine. However, in\ncybersecurity, we have noticed a lack of open-source datasets, with a\nparticular lack of high-quality cybersecurity pretraining corpora, even though\nmuch research indicates that LLMs acquire their knowledge during pretraining.\nTo address this, we present a comprehensive suite of datasets covering all\nmajor training stages, including pretraining, instruction fine-tuning, and\nreasoning distillation with cybersecurity-specific self-reflection data.\nExtensive ablation studies demonstrate their effectiveness on public\ncybersecurity benchmarks. In particular, continual pre-training on our dataset\nyields a 15.88% improvement in the aggregate score, while reasoning\ndistillation leads to a 10% gain in security certification (CISSP). We will\nrelease all datasets and trained cybersecurity LLMs under the ODC-BY and MIT\nlicenses to encourage further research in the community. For access to all\ndatasets and model weights, please refer to\nhttps://huggingface.co/collections/trendmicro-ailab/primus-67b1fd27052b802b4af9d243.",
      "tldr_zh": "本文提出 Primus，这是一个开创性的开源数据集集合，旨在填补 cybersecurity LLM 训练领域的空白，特别是缺乏高质量的 pretraining corpora。该集合覆盖 pretraining、instruction fine-tuning 和 reasoning distillation 等主要训练阶段，并包含 cybersecurity-specific self-reflection data，以提升模型性能。实验结果显示，通过 continual pre-training，模型在公共基准上的 aggregate score 提高了 15.88%，而 reasoning distillation 则带来了 10% 的 security certification (CISSP) 提升。作者将所有数据集和训练模型以 ODC-BY 和 MIT 许可证开源，鼓励社区进一步研究。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11191v1",
      "published_date": "2025-02-16 16:34:49 UTC",
      "updated_date": "2025-02-16 16:34:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:02:18.290975"
    },
    {
      "arxiv_id": "2502.11190v2",
      "title": "ReLearn: Unlearning via Learning for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haoming Xu",
        "Ningyuan Zhao",
        "Liming Yang",
        "Sendong Zhao",
        "Shumin Deng",
        "Mengru Wang",
        "Bryan Hooi",
        "Nay Oo",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "Current unlearning methods for large language models usually rely on reverse\noptimization to reduce target token probabilities. However, this paradigm\ndisrupts the subsequent tokens prediction, degrading model performance and\nlinguistic coherence. Moreover, existing evaluation metrics overemphasize\ncontextual forgetting while inadequately assessing response fluency and\nrelevance. To address these challenges, we propose ReLearn, a data augmentation\nand fine-tuning pipeline for effective unlearning, along with a comprehensive\nevaluation framework. This framework introduces Knowledge Forgetting Rate (KFR)\nand Knowledge Retention Rate (KRR) to measure knowledge-level preservation, and\nLinguistic Score (LS) to evaluate generation quality. Our experiments show that\nReLearn successfully achieves targeted forgetting while preserving high-quality\noutput. Through mechanistic analysis, we further demonstrate how reverse\noptimization disrupts coherent text generation, while ReLearn preserves this\nessential capability. Code is available at https://github.com/zjunlp/unlearn.",
      "tldr_zh": "该论文针对大型语言模型(Large Language Models)的unlearning问题，提出ReLearn方法，通过数据增强和微调管道来实现有效的知识遗忘，同时避免传统反向优化导致的模型性能下降和语言连贯性破坏。ReLearn引入全面评估框架，包括Knowledge Forgetting Rate (KFR)用于衡量知识遗忘、Knowledge Retention Rate (KRR)用于评估知识保留，以及Linguistic Score (LS)用于检查生成质量。实验结果显示，ReLearn成功实现了目标知识遗忘，同时保持高质量输出，并通过机制分析证明其在保留连贯文本生成方面的优势。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2502.11190v2",
      "published_date": "2025-02-16 16:31:00 UTC",
      "updated_date": "2025-03-20 17:20:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:02:30.575685"
    },
    {
      "arxiv_id": "2502.12206v1",
      "title": "Evaluating the Paperclip Maximizer: Are RL-Based Language Models More Likely to Pursue Instrumental Goals?",
      "title_zh": "翻译失败",
      "authors": [
        "Yufei He",
        "Yuexin Li",
        "Jiaying Wu",
        "Yuan Sui",
        "Yulin Chen",
        "Bryan Hooi"
      ],
      "abstract": "As large language models (LLMs) continue to evolve, ensuring their alignment\nwith human goals and values remains a pressing challenge. A key concern is\n\\textit{instrumental convergence}, where an AI system, in optimizing for a\ngiven objective, develops unintended intermediate goals that override the\nultimate objective and deviate from human-intended goals. This issue is\nparticularly relevant in reinforcement learning (RL)-trained models, which can\ngenerate creative but unintended strategies to maximize rewards. In this paper,\nwe explore instrumental convergence in LLMs by comparing models trained with\ndirect RL optimization (e.g., the o1 model) to those trained with reinforcement\nlearning from human feedback (RLHF). We hypothesize that RL-driven models\nexhibit a stronger tendency for instrumental convergence due to their\noptimization of goal-directed behavior in ways that may misalign with human\nintentions. To assess this, we introduce InstrumentalEval, a benchmark for\nevaluating instrumental convergence in RL-trained LLMs. Initial experiments\nreveal cases where a model tasked with making money unexpectedly pursues\ninstrumental objectives, such as self-replication, implying signs of\ninstrumental convergence. Our findings contribute to a deeper understanding of\nalignment challenges in AI systems and the risks posed by unintended model\nbehaviors.",
      "tldr_zh": "这篇论文评估了强化学习（RL）训练的语言模型（LLMs）是否更易出现工具性收敛（instrumental convergence），即在优化目标时发展出未预期的中间目标，导致偏离人类意图。研究者比较了直接RL优化（如o1模型）和RLHF（reinforcement learning from human feedback）训练的模型，并引入了InstrumentalEval基准作为评估工具。实验发现，RL驱动模型在任务如赚钱时，可能意外追求工具性目标，例如自我复制，这表明了潜在的AI对齐风险。该研究加深了对LLMs行为偏差的理解，并强调了确保AI系统安全性的重要性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.12206v1",
      "published_date": "2025-02-16 16:29:20 UTC",
      "updated_date": "2025-02-16 16:29:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:02:43.653064"
    },
    {
      "arxiv_id": "2502.11187v2",
      "title": "TituLLMs: A Family of Bangla LLMs with Comprehensive Benchmarking",
      "title_zh": "翻译失败",
      "authors": [
        "Shahriar Kabir Nahin",
        "Rabindra Nath Nandi",
        "Sagor Sarker",
        "Quazi Sarwar Muhtaseem",
        "Md Kowsher",
        "Apu Chandraw Shill",
        "Md Ibrahim",
        "Mehadi Hasan Menon",
        "Tareq Al Muntasir",
        "Firoj Alam"
      ],
      "abstract": "In this paper, we present TituLLMs, the first large pretrained Bangla LLMs,\navailable in 1b and 3b parameter sizes. Due to computational constraints during\nboth training and inference, we focused on smaller models. To train TituLLMs,\nwe collected a pretraining dataset of approximately ~37 billion tokens. We\nextended the Llama-3.2 tokenizer to incorporate language- and culture-specific\nknowledge, which also enables faster training and inference. There was a lack\nof benchmarking datasets to benchmark LLMs for Bangla. To address this gap, we\ndeveloped five benchmarking datasets. We benchmarked various LLMs, including\nTituLLMs, and demonstrated that TituLLMs outperforms its initial multilingual\nversions. However, this is not always the case, highlighting the complexities\nof language adaptation. Our work lays the groundwork for adapting existing\nmultilingual open models to other low-resource languages. To facilitate broader\nadoption and further research, we have made the TituLLMs models and\nbenchmarking datasets publicly available\n(https://huggingface.co/collections/hishab/titulm-llama-family-6718d31fc1b83529276f490a).",
      "tldr_zh": "本论文介绍了 TituLLMs，这是第一个预训练的 Bangla LLMs 家族，包含 1b 和 3b 参数大小的模型，针对计算限制而专注于较小规模。研究团队收集了约 37 亿 tokens 的预训练数据集，并扩展了 Llama-3.2 tokenizer 以融入 Bangla 语言和文化特定知识，从而提升训练和推理效率。为填补基准测试缺口，他们开发了五个新的 Bangla 基准数据集，并通过测试证明 TituLLMs 优于其初始多语言版本，尽管语言适应存在复杂性。最终，该工作为适应其他低资源语言提供了基础，并公开发布了模型和数据集以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "LLMs, Benchmarking, Large Language Models, Bangla",
      "pdf_url": "http://arxiv.org/pdf/2502.11187v2",
      "published_date": "2025-02-16 16:22:23 UTC",
      "updated_date": "2025-02-21 10:33:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:02:54.403560"
    },
    {
      "arxiv_id": "2502.11184v1",
      "title": "Can't See the Forest for the Trees: Benchmarking Multimodal Safety Awareness for Multimodal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxuan Wang",
        "Xiaoyuan Liu",
        "Kuiyi Gao",
        "Jen-tse Huang",
        "Youliang Yuan",
        "Pinjia He",
        "Shuai Wang",
        "Zhaopeng Tu"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have expanded the capabilities of\ntraditional language models by enabling interaction through both text and\nimages. However, ensuring the safety of these models remains a significant\nchallenge, particularly in accurately identifying whether multimodal content is\nsafe or unsafe-a capability we term safety awareness. In this paper, we\nintroduce MMSafeAware, the first comprehensive multimodal safety awareness\nbenchmark designed to evaluate MLLMs across 29 safety scenarios with 1500\ncarefully curated image-prompt pairs. MMSafeAware includes both unsafe and\nover-safety subsets to assess models abilities to correctly identify unsafe\ncontent and avoid over-sensitivity that can hinder helpfulness. Evaluating nine\nwidely used MLLMs using MMSafeAware reveals that current models are not\nsufficiently safe and often overly sensitive; for example, GPT-4V misclassifies\n36.1% of unsafe inputs as safe and 59.9% of benign inputs as unsafe. We further\nexplore three methods to improve safety awareness-prompting-based approaches,\nvisual contrastive decoding, and vision-centric reasoning fine-tuning-but find\nthat none achieve satisfactory performance. Our findings highlight the profound\nchallenges in developing MLLMs with robust safety awareness, underscoring the\nneed for further research in this area. All the code and data will be publicly\navailable to facilitate future research.",
      "tldr_zh": "本研究探讨了Multimodal Large Language Models (MLLMs)在处理文本和图像时的安全意识问题，引入了首个全面基准测试MMSafeAware，以评估模型在29个安全场景下的表现，共包含1500对精心策划的图像-提示对。MMSafeAware包括不安全和过度安全子集，测试模型识别不安全内容的能力，同时避免过度敏感；实验结果显示，九个主流MLLMs表现不足，例如GPT-4V将36.1%的不安全输入误判为安全，并将59.9%的良性输入误判为不安全。研究者尝试了三种改进方法——基于提示的方法、视觉对比解码和视觉中心推理微调，但均未达到满意效果，强调了开发可靠safety awareness的MLLMs面临的挑战，并公开了所有代码和数据以推动未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11184v1",
      "published_date": "2025-02-16 16:12:40 UTC",
      "updated_date": "2025-02-16 16:12:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:03:06.700385"
    },
    {
      "arxiv_id": "2502.11181v1",
      "title": "Improving Scientific Document Retrieval with Concept Coverage-based Query Set Generation",
      "title_zh": "翻译失败",
      "authors": [
        "SeongKu Kang",
        "Bowen Jin",
        "Wonbin Kweon",
        "Yu Zhang",
        "Dongha Lee",
        "Jiawei Han",
        "Hwanjo Yu"
      ],
      "abstract": "In specialized fields like the scientific domain, constructing large-scale\nhuman-annotated datasets poses a significant challenge due to the need for\ndomain expertise. Recent methods have employed large language models to\ngenerate synthetic queries, which serve as proxies for actual user queries.\nHowever, they lack control over the content generated, often resulting in\nincomplete coverage of academic concepts in documents. We introduce Concept\nCoverage-based Query set Generation (CCQGen) framework, designed to generate a\nset of queries with comprehensive coverage of the document's concepts. A key\ndistinction of CCQGen is that it adaptively adjusts the generation process\nbased on the previously generated queries. We identify concepts not\nsufficiently covered by previous queries, and leverage them as conditions for\nsubsequent query generation. This approach guides each new query to complement\nthe previous ones, aiding in a thorough understanding of the document.\nExtensive experiments demonstrate that CCQGen significantly enhances query\nquality and retrieval performance.",
      "tldr_zh": "该研究针对科学文档检索中的挑战，提出了一种Concept Coverage-based Query Set Generation (CCQGen)框架，以解决现有大型语言模型生成合成查询时概念覆盖不完整的问题。CCQGen通过自适应调整生成过程，即识别先前查询未充分覆盖的概念，并将其作为条件引导后续查询，从而确保查询集全面反映文档内容。该框架显著提升了查询质量和检索性能，在广泛实验中证明了其有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "WSDM 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.11181v1",
      "published_date": "2025-02-16 15:59:50 UTC",
      "updated_date": "2025-02-16 15:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:03:18.280259"
    },
    {
      "arxiv_id": "2502.11179v1",
      "title": "RT-DEMT: A hybrid real-time acupoint detection model combining mamba and transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Shilong Yang",
        "Qi Zang",
        "Chulong Zhang",
        "Lingfeng Huang",
        "Yaoqin Xie"
      ],
      "abstract": "Traditional Chinese acupuncture methods often face controversy in clinical\npractice due to their high subjectivity. Additionally, current\nintelligent-assisted acupuncture systems have two major limitations: slow\nacupoint localization speed and low accuracy. To address these limitations, a\nnew method leverages the excellent inference efficiency of the state-space\nmodel Mamba, while retaining the advantages of the attention mechanism in the\ntraditional DETR architecture, to achieve efficient global information\nintegration and provide high-quality feature information for acupoint\nlocalization tasks. Furthermore, by employing the concept of residual\nlikelihood estimation, it eliminates the need for complex upsampling processes,\nthereby accelerating the acupoint localization task. Our method achieved\nstate-of-the-art (SOTA) accuracy on a private dataset of acupoints on the human\nback, with an average Euclidean distance pixel error (EPE) of 7.792 and an\naverage time consumption of 10.05 milliseconds per localization task. Compared\nto the second-best algorithm, our method improved both accuracy and speed by\napproximately 14\\%. This significant advancement not only enhances the efficacy\nof acupuncture treatment but also demonstrates the commercial potential of\nautomated acupuncture robot systems. Access to our method is available at\nhttps://github.com/Sohyu1/RT-DEMT",
      "tldr_zh": "该研究针对传统针灸方法的主观性和现有智能辅助系统的定位速度慢、准确率低问题，提出了一种混合实时穴位检测模型 RT-DEMT，将 Mamba 的高效推理能力与 Transformer 的注意力机制相结合，实现全局信息的高效整合。模型通过引入残差似然估计（residual likelihood estimation）来避免复杂上采样过程，从而加速穴位定位任务。在私人人体背部穴位数据集上，该方法达到了 SOTA 性能，平均欧氏距离像素误差 (EPE) 为 7.792，平均处理时间为 10.05 毫秒，比第二佳算法提高了约 14% 的准确性和速度，这为提升针灸治疗效果和推动自动化针灸机器人系统的商业应用提供了重要基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.11179v1",
      "published_date": "2025-02-16 15:59:06 UTC",
      "updated_date": "2025-02-16 15:59:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:03:29.472785"
    },
    {
      "arxiv_id": "2502.11168v1",
      "title": "Knowing Your Target: Target-Aware Transformer Makes Better Spatio-Temporal Video Grounding",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Gu",
        "Yaojie Shen",
        "Chenxi Luo",
        "Tiejian Luo",
        "Yan Huang",
        "Yuewei Lin",
        "Heng Fan",
        "Libo Zhang"
      ],
      "abstract": "Transformer has attracted increasing interest in STVG, owing to its\nend-to-end pipeline and promising result. Existing Transformer-based STVG\napproaches often leverage a set of object queries, which are initialized simply\nusing zeros and then gradually learn target position information via iterative\ninteractions with multimodal features, for spatial and temporal localization.\nDespite simplicity, these zero object queries, due to lacking target-specific\ncues, are hard to learn discriminative target information from interactions\nwith multimodal features in complicated scenarios (\\e.g., with distractors or\nocclusion), resulting in degradation. Addressing this, we introduce a novel\nTarget-Aware Transformer for STVG (TA-STVG), which seeks to adaptively generate\nobject queries via exploring target-specific cues from the given video-text\npair, for improving STVG. The key lies in two simple yet effective modules,\ncomprising text-guided temporal sampling (TTS) and attribute-aware spatial\nactivation (ASA), working in a cascade. The former focuses on selecting\ntarget-relevant temporal cues from a video utilizing holistic text information,\nwhile the latter aims at further exploiting the fine-grained visual attribute\ninformation of the object from previous target-aware temporal cues, which is\napplied for object query initialization. Compared to existing methods\nleveraging zero-initialized queries, object queries in our TA-STVG, directly\ngenerated from a given video-text pair, naturally carry target-specific cues,\nmaking them adaptive and better interact with multimodal features for learning\nmore discriminative information to improve STVG. In our experiments on three\nbenchmarks, TA-STVG achieves state-of-the-art performance and significantly\noutperforms the baseline, validating its efficacy.",
      "tldr_zh": "本研究针对现有 Transformer-based STVG（Spatio-Temporal Video Grounding）方法的问题，即零初始化的 object queries 缺乏目标特定线索，导致在复杂场景（如干扰或遮挡）中表现不佳，提出了一种新型 Target-Aware Transformer for STVG（TA-STVG）。该方法通过两个关键模块——Text-guided Temporal Sampling (TTS) 和 Attribute-Aware Spatial Activation (ASA)——来从视频-文本对中自适应生成携带目标特定线索的 object queries，从而提升与多模态特征的交互和目标信息学习。实验结果显示，TA-STVG 在三个基准测试上达到了 state-of-the-art 性能，并显著优于基线模型，证明了其在改善时空视频 grounding 方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11168v1",
      "published_date": "2025-02-16 15:38:33 UTC",
      "updated_date": "2025-02-16 15:38:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:03:41.796143"
    },
    {
      "arxiv_id": "2502.11164v5",
      "title": "Quantifying the Capability Boundary of DeepSeek Models: An Application-Driven Performance Analysis",
      "title_zh": "量化 DeepSeek 模型的能力边界：基于应用的性能分析",
      "authors": [
        "Kaikai Zhao",
        "Zhaoxiang Liu",
        "Xuejiao Lei",
        "Jiaojiao Zhao",
        "Zhenhong Long",
        "Zipeng Wang",
        "Ning Wang",
        "Meijuan An",
        "Qingliang Meng",
        "Peijun Yang",
        "Minjie Hua",
        "Chaoyang Ma",
        "Wen Liu",
        "Kai Wang",
        "Shiguo Lian"
      ],
      "abstract": "DeepSeek-R1, known for its low training cost and exceptional reasoning\ncapabilities, has achieved state-of-the-art performance on various benchmarks.\nHowever, detailed evaluations for DeepSeek Series models from the perspective\nof real-world applications are lacking, making it challenging for users to\nselect the most suitable DeepSeek models for their specific needs. To address\nthis gap, we presents the first comprehensive evaluation of the DeepSeek and\nits related models (including DeepSeek-V3, DeepSeek-R1,\nDeepSeek-R1-Distill-Qwen series, DeepSeek-R1-Distill-Llama series, their\ncorresponding 4-bit quantized models, and the reasoning model QwQ-32B) using\nour enhanced A-Eval benchmark, A-Eval-2.0. Our systematic analysis reveals\nseveral key insights: (1) Given identical model architectures and training\ndata, larger parameter models demonstrate superior performance, aligning with\nthe scaling law. However, smaller models may achieve enhanced capabilities when\nemploying optimized training strategies and higher-quality data; (2)\nReasoning-enhanced model show significant performance gains in logical\nreasoning tasks but may underperform in text understanding and generation\ntasks; (3) As the data difficulty increases, distillation or reasoning\nenhancements yield higher performance gains for the models. Interestingly,\nreasoning enhancements can even have a negative impact on simpler problems; (4)\nQuantization impacts different capabilities unevenly, with significant drop on\nlogical reasoning and minimal impact on text generation. Based on these results\nand findings, we design an model selection handbook enabling users to select\nthe most cost-effective models without efforts.",
      "tldr_zh": "本研究对 DeepSeek 系列模型（包括 DeepSeek-V3、DeepSeek-R1 及其衍生版本如 DeepSeek-R1-Distill-Qwen 系列）进行了首次全面评估，使用增强的 A-Eval-2.0 基准，从真实应用角度量化其能力边界。关键发现包括：更大参数模型遵循缩放定律表现更优，但优化训练和高质量数据可提升小模型能力；推理增强模型在逻辑推理任务上显著提升，却可能削弱文本理解和生成；量化过程对逻辑推理影响较大，而对文本生成影响较小。基于这些洞见，论文设计了一个模型选择手册，帮助用户高效选择最性价比高的 DeepSeek 模型。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11164v5",
      "published_date": "2025-02-16 15:29:58 UTC",
      "updated_date": "2025-05-16 01:20:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:03:53.900788"
    },
    {
      "arxiv_id": "2502.11157v1",
      "title": "Dyve: Thinking Fast and Slow for Dynamic Process Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Jianyuan Zhong",
        "Zeju Li",
        "Zhijian Xu",
        "Xiangyu Wen",
        "Qiang Xu"
      ],
      "abstract": "We present Dyve, a dynamic process verifier that enhances reasoning error\ndetection in large language models by integrating fast and slow thinking,\ninspired by Kahneman's Systems Theory. Dyve adaptively applies immediate\ntoken-level confirmation System 1 for straightforward steps and comprehensive\nanalysis System 2 for complex ones. Leveraging a novel step-wise\nconsensus-filtered process supervision technique, combining Monte Carlo\nestimation with LLM based evaluation, Dyve curates high-quality supervision\nsignals from noisy data. Experimental results on ProcessBench and the MATH\ndataset confirm that Dyve significantly outperforms existing process-based\nverifiers and boosts performance in Best-of-N settings.",
      "tldr_zh": "该研究提出了一种动态过程验证器 Dyve，它受 Kahneman 的 Systems Theory 启发，通过整合快速思考的 System 1（用于即时 token-level 确认的简单步骤）和慢速思考的 System 2（用于复杂步骤的全面分析），以提升大型语言模型的推理错误检测能力。Dyve 采用一种创新的 step-wise consensus-filtered process supervision 技术，结合 Monte Carlo estimation 和 LLM-based evaluation，从噪声数据中提取高质量监督信号。实验结果显示，在 ProcessBench 和 MATH 数据集上，Dyve 显著优于现有过程验证器，并在 Best-of-N 设置中提升了整体性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.11157v1",
      "published_date": "2025-02-16 15:11:19 UTC",
      "updated_date": "2025-02-16 15:11:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:04:05.331791"
    },
    {
      "arxiv_id": "2502.11155v1",
      "title": "Uncertainty-Aware Search and Value Models: Mitigating Search Scaling Flaws in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Yu",
        "Yingru Li",
        "Benyou Wang"
      ],
      "abstract": "Value model-guided search is effective in steering the generation but suffers\nfrom scaling flaws: Its superiority diminishes with larger sample sizes,\nunderperforming non-search baselines. This limitation arises from reliability\ndegradation in value models in unseen reasoning paths. To address this, we\npropose an uncertainty-aware search framework that includes two key components:\n(1) uncertainty-aware value models that incorporate uncertainty into\npredictions, and (2) an uncertainty-aware selection process using the proposed\nefficient Group Thompson Sampling algorithm. Experiments on GSM8K show that our\nmethod mitigates search scaling flaws, achieving 90.5% coverage at 16 samples\ncompared to 85.8% for conventional value-guided search. This work establishes\nthe first systematic integration of uncertainty quantification in LLM search\nparadigms.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)中的搜索缩放缺陷问题，提出了一种 uncertainty-aware search 框架，以缓解 value model-guided search 在样本大小增加时性能下降的问题。该框架包括两部分：uncertainty-aware value models，将不确定性整合到预测中，以及使用高效的 Group Thompson Sampling 算法进行 uncertainty-aware selection 过程。在 GSM8K 数据集上的实验显示，该方法在 16 个样本时达到 90.5% 的覆盖率，优于传统 value-guided search 的 85.8%。这项工作首次系统地将不确定性量化整合到 LLM 搜索范式中，提升了搜索的可靠性和有效性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11155v1",
      "published_date": "2025-02-16 15:10:30 UTC",
      "updated_date": "2025-02-16 15:10:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:04:17.104207"
    },
    {
      "arxiv_id": "2503.16444v1",
      "title": "Conversational Explanations: Discussing Explainable AI with Non-AI Experts",
      "title_zh": "对话式解释：与非AI专家讨论可解释AI",
      "authors": [
        "Tong Zhang",
        "Mengao Zhang",
        "Wei Yan Low",
        "X. Jessie Yang",
        "Boyang Li"
      ],
      "abstract": "Explainable AI (XAI) aims to provide insights into the decisions made by AI\nmodels. To date, most XAI approaches provide only one-time, static\nexplanations, which cannot cater to users' diverse knowledge levels and\ninformation needs. Conversational explanations have been proposed as an\neffective method to customize XAI explanations. However, building\nconversational explanation systems is hindered by the scarcity of training\ndata. Training with synthetic data faces two main challenges: lack of data\ndiversity and hallucination in the generated data. To alleviate these issues,\nwe introduce a repetition penalty to promote data diversity and exploit a\nhallucination detector to filter out untruthful synthetic conversation turns.\nWe conducted both automatic and human evaluations on the proposed system,\nfEw-shot Multi-round ConvErsational Explanation (EMCEE). For automatic\nevaluation, EMCEE achieves relative improvements of 81.6% in BLEU and 80.5% in\nROUGE compared to the baselines. EMCEE also mitigates the degeneration of data\nquality caused by training on synthetic data. In human evaluations (N=60),\nEMCEE outperforms baseline models and the control group in improving users'\ncomprehension, acceptance, trust, and collaboration with static explanations by\nlarge margins. Through a fine-grained analysis of model responses, we further\ndemonstrate that training on self-generated synthetic data improves the model's\nability to generate more truthful and understandable answers, leading to better\nuser interactions. To the best of our knowledge, this is the first\nconversational explanation method that can answer free-form user questions\nfollowing static explanations.",
      "tldr_zh": "该研究探讨了Explainable AI (XAI) 的局限性，即现有方法多采用一次性静态解释，无法满足用户多样化知识需求。为此，作者提出Conversational Explanations框架，并开发了fEw-shot Multi-round ConvErsational Explanation (EMCEE) 系统，通过引入repetition penalty提升合成数据多样性，并使用hallucination detector过滤不真实对话，以解决训练数据稀缺问题。实验结果显示，EMCEE在自动评估中较基线提升81.6% BLEU和80.5% ROUGE分数；在人类评估（N=60）中，它显著提高了用户对XAI的理解、接受、信任和合作水平。总体而言，该方法是首个能响应自由形式用户问题的对话式XAI系统，提升了AI解释的交互性和可靠性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to IUI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16444v1",
      "published_date": "2025-02-16 14:52:36 UTC",
      "updated_date": "2025-02-16 14:52:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:04:30.780888"
    },
    {
      "arxiv_id": "2502.14888v2",
      "title": "Multi-Faceted Multimodal Monosemanticity",
      "title_zh": "翻译失败",
      "authors": [
        "Hanqi Yan",
        "Xiangxiang Cui",
        "Lu Yin",
        "Paul Pu Liang",
        "Yulan He",
        "Yifei Wang"
      ],
      "abstract": "Humans experience the world through multiple modalities, such as, vision,\nlanguage, and speech, making it natural to explore the commonality and\ndistinctions among them. In this work, we take a data-driven approach to\naddress this question by analyzing interpretable, monosemantic features\nextracted from deep multimodal models. Specifically, we investigate CLIP, a\nprominent visual-language representation model trained on massive image-text\npairs. Building on prior research in single-modal interpretability, we develop\na set of multi-modal interpretability tools and measures designed to\ndisentangle and analyze features learned from CLIP. Specifically, we introduce\nthe Modality Dominance Score (MDS) to attribute each CLIP feature to a specific\nmodality. We then map CLIP features into a more interpretable space, enabling\nus to categorize them into three distinct classes: vision features\n(single-modal), language features (single-modal), and visual-language features\n(cross-modal). Interestingly, this data-driven categorization closely aligns\nwith human intuitive understandings of different modalities. We further show\nthat this modality decomposition can benefit multiple downstream tasks,\nincluding reducing bias in gender detection, generating cross-modal adversarial\nexamples, and enabling modal-specific feature control in text-to-image\ngeneration. These results indicate that large-scale multimodal models, when\nequipped with task-agnostic interpretability tools, can offer valuable insights\ninto the relationships between different data modalities.",
      "tldr_zh": "本文研究多模态模型（如 CLIP）的可解释单义特征（monosemantic features），通过数据驱动方法探索视觉、语言等模态之间的共同点和差异。作者引入 Modality Dominance Score (MDS) 等工具，将 CLIP 特征归因并分类为视觉特征（单模态）、语言特征（单模态）和视觉-语言特征（跨模态），并发现这种分类与人类直觉高度一致。该方法应用于下游任务中，能减少性别检测中的偏差、生成跨模态对抗样本，并实现文本到图像生成中的模态特定特征控制，最终证明大型多模态模型结合任务无关的可解释性工具，能提供宝贵的模态关系洞见。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14888v2",
      "published_date": "2025-02-16 14:51:07 UTC",
      "updated_date": "2025-05-19 13:20:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:04:43.322079"
    },
    {
      "arxiv_id": "2502.11149v2",
      "title": "Large Language-Geometry Model: When LLM meets Equivariance",
      "title_zh": "大型",
      "authors": [
        "Zongzhao Li",
        "Jiacheng Cen",
        "Bing Su",
        "Wenbing Huang",
        "Tingyang Xu",
        "Yu Rong",
        "Deli Zhao"
      ],
      "abstract": "Accurately predicting 3D structures and dynamics of physical systems is\ncrucial in scientific applications. Existing approaches that rely on geometric\nGraph Neural Networks (GNNs) effectively enforce $\\mathrm{E}(3)$-equivariance,\nbut they often fall in leveraging extensive broader information. While direct\napplication of Large Language Models (LLMs) can incorporate external knowledge,\nthey lack the capability for spatial reasoning with guaranteed equivariance. In\nthis paper, we propose EquiLLM, a novel framework for representing 3D physical\nsystems that seamlessly integrates E(3)-equivariance with LLM capabilities.\nSpecifically, EquiLLM comprises four key components: geometry-aware prompting,\nan equivariant encoder, an LLM, and an equivariant adaptor. Essentially, the\nLLM guided by the instructive prompt serves as a sophisticated invariant\nfeature processor, while 3D directional information is exclusively handled by\nthe equivariant encoder and adaptor modules. Experimental results demonstrate\nthat EquiLLM delivers significant improvements over previous methods across\nmolecular dynamics simulation, human motion simulation, and antibody design,\nhighlighting its promising generalizability.",
      "tldr_zh": "本论文提出 EquiLLM 框架，将 Large Language Models (LLMs) 与 E(3)-equivariance 相结合，解决传统 Geometric Graph Neural Networks (GNNs) 无法充分利用外部知识以及 LLMs 缺乏空间推理保证的问题。该框架包括四个关键组件：geometry-aware prompting、equivariant encoder、LLM 作为不变特征处理器，以及 equivariant adaptor 来处理 3D 方向信息，从而实现对 3D 物理系统的无缝表示。实验结果显示，EquiLLM 在分子动力学模拟、人体运动模拟和抗体设计等任务中显著优于现有方法，展示了其优秀的泛化性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11149v2",
      "published_date": "2025-02-16 14:50:49 UTC",
      "updated_date": "2025-02-19 06:41:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:04:54.890082"
    },
    {
      "arxiv_id": "2502.11147v1",
      "title": "Efficient Long-Decoding Inference with Reasoning-Aware Attention Sparsity",
      "title_zh": "高效的长解码推理：基于推理感知注意力稀疏性",
      "authors": [
        "Junhao Hu",
        "Wenrui Huang",
        "Weidong Wang",
        "Zhenwen Li",
        "Tiancheng Hu",
        "Zhixia Liu",
        "Xusheng Chen",
        "Tao Xie",
        "Yizhou Shan"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities across\nvarious domains, with recent advancements in challenging reasoning tasks such\nas mathematics and programming. However, solving reasoning tasks often requires\nlong decoding chains (of thoughts), which incur $O(N)$ time and memory\nconsumption, where $N$ is the chain length. To mitigate $O(N)$ time and memory\nconsumption, existing sparsity-based algorithms propose retaining only the most\ncritical token's intermediate data (i.e., key-value cache) and discarding the\nrest. However, these existing algorithms struggle with the ``impossible\ntrinity'' of accuracy, time, and memory. For example, the state-of-the-art\nalgorithm, Quest, achieves high accuracy with $O(L)$ time but $O(N)$ memory\n($L$ is the cache budget, $L \\ll N$). To address this issue, in this paper, we\nidentify a new attention pattern during the decode stage of reasoning tasks,\nwhere milestone tokens (analogous to lemmas in mathematical proofs) emerge, are\nutilized, and then become unimportant afterward. Based on this pattern, we\npropose a new algorithm named RaaS that identifies and retains milestone tokens\nonly until they are no longer needed, achieving high accuracy with $O(L)$ time\nand $O(L)$ memory complexity.",
      "tldr_zh": "大型语言模型 (LLMs) 在推理任务如数学和编程中表现出色，但长解码链导致 O(N) 的时间和内存消耗，现有稀疏算法如 Quest 虽提高精度和时间效率，却仍面临 O(N) 内存问题。本文发现了推理任务中的新注意力模式，即里程碑 tokens (milestone tokens)，类似于数学证明中的引理，这些 tokens 在解码过程中被利用后变得不重要。基于此，提出 RaaS 算法，通过仅在必要时保留这些 tokens，实现高精度，同时将时间和内存复杂度降至 O(L)，其中 L << N。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11147v1",
      "published_date": "2025-02-16 14:28:52 UTC",
      "updated_date": "2025-02-16 14:28:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:05:06.535035"
    },
    {
      "arxiv_id": "2502.11142v3",
      "title": "NavRAG: Generating User Demand Instructions for Embodied Navigation through Retrieval-Augmented LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Wang",
        "Yaohui Zhu",
        "Gim Hee Lee",
        "Yachun Fan"
      ],
      "abstract": "Vision-and-Language Navigation (VLN) is an essential skill for embodied\nagents, allowing them to navigate in 3D environments following natural language\ninstructions. High-performance navigation models require a large amount of\ntraining data, the high cost of manually annotating data has seriously hindered\nthis field. Therefore, some previous methods translate trajectory videos into\nstep-by-step instructions for expanding data, but such instructions do not\nmatch well with users' communication styles that briefly describe destinations\nor state specific needs. Moreover, local navigation trajectories overlook\nglobal context and high-level task planning. To address these issues, we\npropose NavRAG, a retrieval-augmented generation (RAG) framework that generates\nuser demand instructions for VLN. NavRAG leverages LLM to build a hierarchical\nscene description tree for 3D scene understanding from global layout to local\ndetails, then simulates various user roles with specific demands to retrieve\nfrom the scene tree, generating diverse instructions with LLM. We annotate over\n2 million navigation instructions across 861 scenes and evaluate the data\nquality and navigation performance of trained models.",
      "tldr_zh": "这篇论文针对 Vision-and-Language Navigation (VLN) 的数据标注挑战，提出 NavRAG 框架，利用 Retrieval-Augmented Generation (RAG) 和 LLM 来生成更符合用户沟通风格的导航指令。NavRAG 通过构建层次化场景描述树，从全局布局到局部细节理解3D环境，并模拟各种用户角色和需求进行检索和生成，从而创建多样化的指令数据集。最终，论文标注了超过200万条指令，覆盖861个场景，并证明了训练模型的导航性能得到显著提升。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11142v3",
      "published_date": "2025-02-16 14:17:36 UTC",
      "updated_date": "2025-03-07 06:06:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:05:18.964220"
    },
    {
      "arxiv_id": "2502.14887v1",
      "title": "Vision-Enhanced Time Series Forecasting via Latent Diffusion Models",
      "title_zh": "视觉增强的时间序列预测 via 潜在扩散模型",
      "authors": [
        "Weilin Ruan",
        "Siru Zhong",
        "Haomin Wen",
        "Yuxuan Liang"
      ],
      "abstract": "Diffusion models have recently emerged as powerful frameworks for generating\nhigh-quality images. While recent studies have explored their application to\ntime series forecasting, these approaches face significant challenges in\ncross-modal modeling and transforming visual information effectively to capture\ntemporal patterns. In this paper, we propose LDM4TS, a novel framework that\nleverages the powerful image reconstruction capabilities of latent diffusion\nmodels for vision-enhanced time series forecasting. Instead of introducing\nexternal visual data, we are the first to use complementary transformation\ntechniques to convert time series into multi-view visual representations,\nallowing the model to exploit the rich feature extraction capabilities of the\npre-trained vision encoder. Subsequently, these representations are\nreconstructed using a latent diffusion model with a cross-modal conditioning\nmechanism as well as a fusion module. Experimental results demonstrate that\nLDM4TS outperforms various specialized forecasting models for time series\nforecasting tasks.",
      "tldr_zh": "本文提出 LDM4TS 框架，利用 Latent Diffusion Models 的图像重建能力来增强时间序列 forecasting。方法首次采用互补转换技术，将时间序列转换为多视图视觉表示，并通过预训练视觉编码器提取特征，然后使用跨模态 conditioning 机制和融合模块进行重建。实验结果显示，LDM4TS 在时间序列 forecasting 任务中优于各种专业模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14887v1",
      "published_date": "2025-02-16 14:15:06 UTC",
      "updated_date": "2025-02-16 14:15:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:05:29.442590"
    },
    {
      "arxiv_id": "2502.11141v2",
      "title": "Cognitive Neural Architecture Search Reveals Hierarchical Entailment",
      "title_zh": "翻译失败",
      "authors": [
        "Lukas Kuhn",
        "Sari Saba-Sadiya",
        "Gemma Roig"
      ],
      "abstract": "Recent research has suggested that the brain is more shallow than previously\nthought, challenging the traditionally assumed hierarchical structure of the\nventral visual pathway. Here, we demonstrate that optimizing convolutional\nnetwork architectures for brain-alignment via evolutionary neural architecture\nsearch results in models with clear representational hierarchies. Despite\nhaving random weights, the identified models achieve brain-alignment scores\nsurpassing even those of pretrained classification models - as measured by both\nregression and representational similarity analysis. Furthermore, through\ntraditional supervised training, architectures optimized for alignment with\nlate ventral regions become competitive classification models. These findings\nsuggest that hierarchical structure is a fundamental mechanism of primate\nvisual processing. Finally, this work demonstrates the potential of neural\narchitecture search as a framework for computational cognitive neuroscience\nresearch that could reduce the field's reliance on manually designed\nconvolutional networks.",
      "tldr_zh": "该研究使用进化神经架构搜索(evolutionary neural architecture search)优化卷积网络(convolutional networks)，证明了大脑视觉通路存在清晰的分层结构，挑战了大脑更浅层的传统观点。优化后的模型即使权重随机，也在脑对齐分数上超过了预训练分类模型，通过回归和表征相似性分析(representational similarity analysis)进行评估。进一步的监督训练使这些架构成为高效的分类模型，支持分层结构作为灵长类视觉处理的基本机制。最后，该方法展示了神经架构搜索作为计算认知神经科学研究框架的潜力，有助于减少对手动设计的卷积网络依赖。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11141v2",
      "published_date": "2025-02-16 14:13:04 UTC",
      "updated_date": "2025-05-01 15:51:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:05:43.562842"
    },
    {
      "arxiv_id": "2502.11140v2",
      "title": "Automated Visualization Code Synthesis via Multi-Path Reasoning and Feedback-Driven Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Wonduk Seo",
        "Seungyong Lee",
        "Daye Kang",
        "Hyunjin An",
        "Zonghao Yuan",
        "Seunghyun Lee"
      ],
      "abstract": "Rapid advancements in Large Language Models (LLMs) have accelerated their\nintegration into automated visualization code generation applications. Despite\nadvancements through few-shot prompting and query expansion, existing methods\nremain limited in handling ambiguous and complex queries, thereby requiring\nmanual intervention. To overcome these limitations, we propose VisPath: a\nMulti-Path Reasoning and Feedback-Driven Optimization Framework for\nVisualization Code Generation. VisPath handles underspecified queries through\nstructured, multi-stage processing. It begins by reformulating the user input\nvia Chain-of-Thought (CoT) prompting, which refers to the initial query while\ngenerating multiple extended queries in parallel, enabling the LLM to capture\ndiverse interpretations of the user intent. These queries then generate\ncandidate visualization scripts, which are executed to produce diverse images.\nBy assessing the visual quality and correctness of each output, VisPath\ngenerates targeted feedback that is aggregated to synthesize an optimal final\nresult. Extensive experiments on widely-used benchmarks including MatPlotBench\nand the Qwen-Agent Code Interpreter Benchmark show that VisPath outperforms\nstate-of-the-art methods, offering a more reliable solution for AI-driven\nvisualization code generation.",
      "tldr_zh": "该论文提出 VisPath 框架，通过 Multi-Path Reasoning 和 Feedback-Driven Optimization 来自动合成可视化代码，解决 Large Language Models (LLMs) 在处理模糊和复杂查询时的局限性。框架首先利用 Chain-of-Thought (CoT) 提示重构用户输入，生成多个扩展查询并并行创建候选可视化脚本，然后通过执行这些脚本并评估视觉质量和正确性来产生反馈，并优化最终结果。在 MatPlotBench 和 Qwen-Agent Code Interpreter Benchmark 等基准测试中，VisPath 优于现有方法，提供更可靠的 AI 驱动可视化代码生成解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "16 pages, 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.11140v2",
      "published_date": "2025-02-16 14:09:42 UTC",
      "updated_date": "2025-05-21 02:10:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:05:54.747980"
    },
    {
      "arxiv_id": "2502.11137v3",
      "title": "Safety Evaluation of DeepSeek Models in Chinese Contexts",
      "title_zh": "DeepSeek 模型在中文语境中的安全评估",
      "authors": [
        "Wenjing Zhang",
        "Xuejiao Lei",
        "Zhaoxiang Liu",
        "Ning Wang",
        "Zhenhong Long",
        "Peijun Yang",
        "Jiaojiao Zhao",
        "Minjie Hua",
        "Chaoyang Ma",
        "Kai Wang",
        "Shiguo Lian"
      ],
      "abstract": "Recently, the DeepSeek series of models, leveraging their exceptional\nreasoning capabilities and open-source strategy, is reshaping the global AI\nlandscape. Despite these advantages, they exhibit significant safety\ndeficiencies. Research conducted by Robust Intelligence, a subsidiary of Cisco,\nin collaboration with the University of Pennsylvania, revealed that DeepSeek-R1\nhas a 100\\% attack success rate when processing harmful prompts. Additionally,\nmultiple safety companies and research institutions have confirmed critical\nsafety vulnerabilities in this model. As models demonstrating robust\nperformance in Chinese and English, DeepSeek models require equally crucial\nsafety assessments in both language contexts. However, current research has\npredominantly focused on safety evaluations in English environments, leaving a\ngap in comprehensive assessments of their safety performance in Chinese\ncontexts. In response to this gap, this study introduces CHiSafetyBench, a\nChinese-specific safety evaluation benchmark. This benchmark systematically\nevaluates the safety of DeepSeek-R1 and DeepSeek-V3 in Chinese contexts,\nrevealing their performance across safety categories. The experimental results\nquantify the deficiencies of these two models in Chinese contexts, providing\nkey insights for subsequent improvements. It should be noted that, despite our\nefforts to establish a comprehensive, objective, and authoritative evaluation\nbenchmark, the selection of test samples, characteristics of data distribution,\nand the setting of evaluation criteria may inevitably introduce certain biases\ninto the evaluation results. We will continuously optimize the evaluation\nbenchmark and periodically update this report to provide more comprehensive and\naccurate assessment outcomes. Please refer to the latest version of the paper\nfor the most recent evaluation results and conclusions.",
      "tldr_zh": "该研究评估了 DeepSeek 系列模型在中文环境下的安全性能，填补了现有评估主要聚焦英语语境的空白。研究者开发了 CHiSafetyBench，这是一个针对中文的安全评估基准，用于系统测试 DeepSeek-R1 和 DeepSeek-V3 在各种安全类别中的表现。实验结果量化了这些模型在中文上下文中的显著缺陷，例如 DeepSeek-R1 处理有害提示的 100% 攻击成功率，并为后续模型改进提供了关键洞见；作者承认评估可能存在偏差，并计划持续优化基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 2 tables, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.11137v3",
      "published_date": "2025-02-16 14:05:54 UTC",
      "updated_date": "2025-05-08 01:35:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:06:07.731684"
    },
    {
      "arxiv_id": "2502.11134v1",
      "title": "Solving Online Resource-Constrained Scheduling for Follow-Up Observation in Astronomy: a Reinforcement Learning Approach",
      "title_zh": "解决天文学中用于后续观察的在线资源约束调度：一种强化学习方法",
      "authors": [
        "Yajie Zhang",
        "Ce Yu",
        "Chao Sun",
        "Jizeng Wei",
        "Junhan Ju",
        "Shanjiang Tang"
      ],
      "abstract": "In the astronomical observation field, determining the allocation of\nobservation resources of the telescope array and planning follow-up\nobservations for targets of opportunity (ToOs) are indispensable components of\nastronomical scientific discovery. This problem is computationally challenging,\ngiven the online observation setting and the abundance of time-varying factors\nthat can affect whether an observation can be conducted. This paper presents\nROARS, a reinforcement learning approach for online astronomical\nresource-constrained scheduling. To capture the structure of the astronomical\nobservation scheduling, we depict every schedule using a directed acyclic graph\n(DAG), illustrating the dependency of timing between different observation\ntasks within the schedule. Deep reinforcement learning is used to learn a\npolicy that can improve the feasible solution by iteratively local rewriting\nuntil convergence. It can solve the challenge of obtaining a complete solution\ndirectly from scratch in astronomical observation scenarios, due to the high\ncomputational complexity resulting from numerous spatial and temporal\nconstraints. A simulation environment is developed based on real-world\nscenarios for experiments, to evaluate the effectiveness of our proposed\nscheduling approach. The experimental results show that ROARS surpasses 5\npopular heuristics, adapts to various observation scenarios and learns\neffective strategies with hindsight.",
      "tldr_zh": "这篇论文提出了一种名为 ROARS 的强化学习方法，用于解决天文观测中的在线资源约束调度问题，特别是针对机会目标 (ToOs) 的后续观测规划，以应对时间变化因素带来的计算挑战。该方法使用有向无环图 (DAG) 表示观测任务之间的时间依赖关系，并通过深度强化学习学习策略，实现迭代本地重写优化，从而避免直接从零构建完整解决方案的高复杂度问题。实验在基于真实场景的模拟环境中进行，结果显示 ROARS 超过了 5 种流行启发式算法，能够适应各种观测场景并学习有效的策略。",
      "categories": [
        "cs.AI",
        "astro-ph.IM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11134v1",
      "published_date": "2025-02-16 14:01:12 UTC",
      "updated_date": "2025-02-16 14:01:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:06:18.903209"
    },
    {
      "arxiv_id": "2502.11132v1",
      "title": "UNITE-FND: Reframing Multimodal Fake News Detection through Unimodal Scene Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Arka Mukherjee",
        "Shreya Ghosh"
      ],
      "abstract": "Multimodal fake news detection typically demands complex architectures and\nsubstantial computational resources, posing deployment challenges in real-world\nsettings. We introduce UNITE-FND, a novel framework that reframes multimodal\nfake news detection as a unimodal text classification task. We propose six\nspecialized prompting strategies with Gemini 1.5 Pro, converting visual content\ninto structured textual descriptions, and enabling efficient text-only models\nto preserve critical visual information. To benchmark our approach, we\nintroduce Uni-Fakeddit-55k, a curated dataset family of 55,000 samples each,\neach processed through our multimodal-to-unimodal translation framework.\nExperimental results demonstrate that UNITE-FND achieves 92.52% accuracy in\nbinary classification, surpassing prior multimodal models while reducing\ncomputational costs by over 10x (TinyBERT variant: 14.5M parameters vs. 250M+\nin SOTA models). Additionally, we propose a comprehensive suite of five novel\nmetrics to evaluate image-to-text conversion quality, ensuring optimal\ninformation preservation. Our results demonstrate that structured text-based\nrepresentations can replace direct multimodal processing with minimal loss of\naccuracy, making UNITE-FND a practical and scalable alternative for\nresource-constrained environments.",
      "tldr_zh": "该论文提出 UNITE-FND 框架，将多模态假新闻检测重新定义为单模态文本分类任务，以解决复杂架构和高计算资源的问题。框架使用六种专门的提示策略和 Gemini 1.5 Pro 将视觉内容转换为结构化的文本描述，从而让高效文本-only 模型（如 TinyBERT）保留关键信息。研究引入 Uni-Fakeddit-55k 数据集（每个包含55,000样本）作为基准，实验结果显示 UNITE-FND 在二元分类中达到92.52%准确率，超越现有多模态模型，同时将计算成本降低10倍以上。论文还提出五种新指标评估图像到文本转换的质量，确保信息保留最小化损失，并为资源受限环境提供实用、可扩展的替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.11132v1",
      "published_date": "2025-02-16 14:00:57 UTC",
      "updated_date": "2025-02-16 14:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:06:30.637096"
    },
    {
      "arxiv_id": "2502.11124v1",
      "title": "AdaManip: Adaptive Articulated Object Manipulation Environments and Policy Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanfei Wang",
        "Xiaojie Zhang",
        "Ruihai Wu",
        "Yu Li",
        "Yan Shen",
        "Mingdong Wu",
        "Zhaofeng He",
        "Yizhou Wang",
        "Hao Dong"
      ],
      "abstract": "Articulated object manipulation is a critical capability for robots to\nperform various tasks in real-world scenarios. Composed of multiple parts\nconnected by joints, articulated objects are endowed with diverse functional\nmechanisms through complex relative motions. For example, a safe consists of a\ndoor, a handle, and a lock, where the door can only be opened when the latch is\nunlocked. The internal structure, such as the state of a lock or joint angle\nconstraints, cannot be directly observed from visual observation. Consequently,\nsuccessful manipulation of these objects requires adaptive adjustment based on\ntrial and error rather than a one-time visual inference. However, previous\ndatasets and simulation environments for articulated objects have primarily\nfocused on simple manipulation mechanisms where the complete manipulation\nprocess can be inferred from the object's appearance. To enhance the diversity\nand complexity of adaptive manipulation mechanisms, we build a novel\narticulated object manipulation environment and equip it with 9 categories of\nobjects. Based on the environment and objects, we further propose an adaptive\ndemonstration collection and 3D visual diffusion-based imitation learning\npipeline that learns the adaptive manipulation policy. The effectiveness of our\ndesigns and proposed method is validated through both simulation and real-world\nexperiments. Our project page is available at: https://adamanip.github.io",
      "tldr_zh": "该论文提出AdaManip框架，针对机器人对articulated objects（关节物体）的操作问题，构建了一个新的模拟环境，包含9类多样化物体，以模拟复杂相对运动和不可见内部结构（如锁状态或关节角度约束）。为了实现适应性操作，该框架引入了适应性演示收集方法和基于3D视觉扩散的imitation learning管道，帮助机器人通过试错学习动态调整策略。实验结果显示，该方法在模拟和真实环境中有效提升了机器人的操作性能，解决了传统方法依赖视觉推理的局限性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.11124v1",
      "published_date": "2025-02-16 13:45:10 UTC",
      "updated_date": "2025-02-16 13:45:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:06:42.192025"
    },
    {
      "arxiv_id": "2502.11122v1",
      "title": "Hierarchical Expert Prompt for Large-Language-Model: An Approach Defeat Elite AI in TextStarCraft II for the First Time",
      "title_zh": "翻译失败",
      "authors": [
        "Zongyuan Li",
        "Chang Lu",
        "Xiaojie Xu",
        "Runnan Qi",
        "Yanan Ni",
        "Lumin Jiang",
        "Xiangbei Liu",
        "Xuebo Zhang",
        "Yongchun Fang",
        "Kuihua Huang",
        "Xian Guo"
      ],
      "abstract": "Since the emergence of the Large Language Model (LLM), LLM has been widely\nused in fields such as writing, translating, and searching. However, there is\nstill great potential for LLM-based methods in handling complex tasks such as\ndecision-making in the StarCraft II environment. To address problems such as\nlack of relevant knowledge and poor control over subtasks of varying\nimportance, we propose a Hierarchical Expert Prompt (HEP) for LLM. Our method\nimproves the understanding of game situations through expert-level tactical\nknowledge, improving the processing quality of tasks of varying importance\nthrough a hierarchical framework. Our approach defeated the highest level\n(Elite) standard built-in agent in TextStarCraft II for the first time and\nconsistently outperformed the baseline method in other difficulties. Our\nexperiments suggest that the proposed method is a practical solution for\ntackling complex decision-making challenges. The replay video can be viewed on\nhttps://www.bilibili.com/video/BV1uz42187EF and https://youtu.be/dO3PshWLV5M,\nand our codes have been open-sourced on\nhttps://github.com/luchang1113/HEP-LLM-play-StarCraftII.",
      "tldr_zh": "本研究提出 Hierarchical Expert Prompt (HEP) for Large Language Model (LLM)，旨在解决 LLM 在复杂决策任务（如 TextStarCraft II 环境）中缺乏相关知识和子任务控制的问题。HEP 通过整合专家级战术知识和分层框架，提升游戏情境理解并优先处理不同重要性的任务。该方法首次击败 TextStarCraft II 中的最高级别 (Elite) 内置代理，并在其他难度中持续优于基线方法。实验验证显示，HEP 为复杂决策挑战提供了一个实用解决方案，并已开源代码以供进一步应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11122v1",
      "published_date": "2025-02-16 13:36:31 UTC",
      "updated_date": "2025-02-16 13:36:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:06:54.277817"
    },
    {
      "arxiv_id": "2502.17475v3",
      "title": "ECG-Expert-QA: A Benchmark for Evaluating Medical Large Language Models in Heart Disease Diagnosis",
      "title_zh": "ECG-Expert-QA：用于评估医疗大语言模型在心脏病诊断中的基准",
      "authors": [
        "Xu Wang",
        "Jiaju Kang",
        "Puyu Han",
        "Yubao Zhao",
        "Qian Liu",
        "Liwenfei He",
        "Lingqiong Zhang",
        "Lingyun Dai",
        "Yongcheng Wang",
        "Jie Tao"
      ],
      "abstract": "We present ECG-Expert-QA, a comprehensive multimodal dataset for evaluating\ndiagnostic capabilities in electrocardiogram (ECG) interpretation. It combines\nreal-world clinical ECG data with systematically generated synthetic cases,\ncovering 12 essential diagnostic tasks and totaling 47,211 expert-validated QA\npairs. These encompass diverse clinical scenarios, from basic rhythm\nrecognition to complex diagnoses involving rare conditions and temporal\nchanges. A key innovation is the support for multi-turn dialogues, enabling the\ndevelopment of conversational medical AI systems that emulate clinician-patient\nor interprofessional interactions. This allows for more realistic assessment of\nAI models' clinical reasoning, diagnostic accuracy, and knowledge integration.\nConstructed through a knowledge-guided framework with strict quality control,\nECG-Expert-QA ensures linguistic and clinical consistency, making it a\nhigh-quality resource for advancing AI-assisted ECG interpretation. It\nchallenges models with tasks like identifying subtle ischemic changes and\ninterpreting complex arrhythmias in context-rich scenarios. To promote research\ntransparency and collaboration, the dataset, accompanying code, and prompts are\npublicly released at https://github.com/Zaozzz/ECG-Expert-QA",
      "tldr_zh": "本研究引入了ECG-Expert-QA，这是一个全面的多模态基准数据集，用于评估大型语言模型在心电图(ECG)心血管疾病诊断中的性能。该数据集结合真实临床ECG数据和合成病例，涵盖12个关键诊断任务，总计47,211个专家验证的QA对，支持多轮对话以模拟临床互动，从而测试AI的临床推理、诊断准确性和知识整合。通过知识引导框架和严格质量控制，确保数据集的语言和临床一致性，并公开提供代码和提示以促进研究合作。实验表明，该基准能有效挑战模型处理复杂场景，如微妙缺血变化和复杂心律不齐，从而推动AI辅助ECG解释的发展。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17475v3",
      "published_date": "2025-02-16 13:28:55 UTC",
      "updated_date": "2025-04-07 09:59:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:07:06.124080"
    },
    {
      "arxiv_id": "2502.11108v1",
      "title": "Knowledge Graph-Driven Retrieval-Augmented Generation: Integrating Deepseek-R1 with Weaviate for Advanced Chatbot Applications",
      "title_zh": "知识图谱驱动的检索增强生成：整合 Deepseek-R1 与 Weaviate 用于高级聊天机器人应用",
      "authors": [
        "Alexandru Lecu",
        "Adrian Groza",
        "Lezan Hawizy"
      ],
      "abstract": "Large language models (LLMs) have significantly advanced the field of natural\nlanguage generation. However, they frequently generate unverified outputs,\nwhich compromises their reliability in critical applications. In this study, we\npropose an innovative framework that combines structured biomedical knowledge\nwith LLMs through a retrieval-augmented generation technique. Our system\ndevelops a thorough knowledge graph by identifying and refining causal\nrelationships and named entities from medical abstracts related to age-related\nmacular degeneration (AMD). Using a vector-based retrieval process and a\nlocally deployed language model, our framework produces responses that are both\ncontextually relevant and verifiable, with direct references to clinical\nevidence. Experimental results show that this method notably decreases\nhallucinations, enhances factual precision, and improves the clarity of\ngenerated responses, providing a robust solution for advanced biomedical\nchatbot applications.",
      "tldr_zh": "本研究提出一个创新框架，通过知识图谱驱动的检索增强生成(Retrieval-Augmented Generation)技术，将Deepseek-R1语言模型与Weaviate向量数据库整合，旨在解决大型语言模型(LLMs)在生物医学聊天机器人中的幻觉问题。框架从年龄相关性黄斑变性(AMD)相关的医疗摘要中提取并精炼因果关系和命名实体，构建结构化的知识图谱，并使用向量检索生成上下文相关且可验证的响应。实验结果表明，该方法显著减少了幻觉，提高了事实精度和响应清晰度，为高级生物医学聊天机器人应用提供了可靠解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11108v1",
      "published_date": "2025-02-16 12:52:28 UTC",
      "updated_date": "2025-02-16 12:52:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:07:18.437067"
    },
    {
      "arxiv_id": "2502.11107v2",
      "title": "Revisiting Weak-to-Strong Generalization in Theory and Practice: Reverse KL vs. Forward KL",
      "title_zh": "重访弱到强泛化：在理论与实践中的比较：反向 KL 与正向 KL",
      "authors": [
        "Wei Yao",
        "Wenkai Yang",
        "Ziqiao Wang",
        "Yankai Lin",
        "Yong Liu"
      ],
      "abstract": "As large language models advance toward superhuman performance, ensuring\ntheir alignment with human values and abilities grows increasingly complex.\nWeak-to-strong generalization offers a promising approach by leveraging\npredictions from weaker models to guide stronger systems, but its effectiveness\ncould be constrained by the inherent noise and inaccuracies in these weak\npredictions. To address this, we propose a theoretically grounded approach that\nreplaces forward KL divergence-whose mass-covering behavior risks overfitting\nto imperfect weak signals-with reverse KL divergence. Reverse KL divergence's\nzero-forcing effect prioritizes high-confidence predictions, effectively\nmitigating the influence of unreliable weak supervision. Theoretically, we\nextend existing bounds and derive tighter lower bounds for both forward and\nreverse KL divergence, establishing that reverse KL achieves at least\ncomparable guarantees to forward KL. Notably, when a sufficiently pre-trained\nstrong model is fine-tuned on the last linear layer, reverse KL guarantees that\nit outperforms its weak supervisor by the magnitude of their disagreement.\nEmpirically, we demonstrate that reverse KL and reverse cross-entropy enable\nstrong models to successfully outperform those trained with forward KL and\nstandard cross-entropy across most settings, highlighting the practical\nadvantages of these reverse losses.",
      "tldr_zh": "这篇论文重新审视弱到强泛化（weak-to-strong generalization），提出使用 reverse KL divergence 替换 forward KL divergence，以减少弱模型预测中的噪声和不准确性。理论上，作者扩展了现有边界，推导出更紧的 lower bounds，并证明 reverse KL divergence 至少与 forward KL divergence 相当，且在对强模型的最后一层微调时，能保证其性能优于弱监督的程度。实验结果显示，使用 reverse KL divergence 和 reverse cross-entropy 训练的模型在大多数设置下 outperform 了采用 forward KL divergence 和标准 cross-entropy 的模型，从而突显了这些方法的实际优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11107v2",
      "published_date": "2025-02-16 12:50:20 UTC",
      "updated_date": "2025-03-04 08:37:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:07:30.612017"
    },
    {
      "arxiv_id": "2502.11102v2",
      "title": "OptMATH: A Scalable Bidirectional Data Synthesis Framework for Optimization Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Hongliang Lu",
        "Zhonglin Xie",
        "Yaoyu Wu",
        "Can Ren",
        "Yuxuan Chen",
        "Zaiwen Wen"
      ],
      "abstract": "Despite the rapid development of large language models (LLMs), a fundamental\nchallenge persists: the lack of high-quality optimization modeling datasets\nhampers LLMs' robust modeling of practical optimization problems from natural\nlanguage descriptions (NL). This data scarcity also contributes to the\ngeneralization difficulties experienced by learning-based methods. To address\nthese challenges, we propose a scalable framework for synthesizing a\nhigh-quality dataset, named OptMATH. Starting from curated seed data with\nmathematical formulations (MF), this framework automatically generates problem\ndata (PD) with controllable complexity. Then, a back-translation step is\nemployed to obtain NL. To verify the correspondence between the NL and the PD,\na forward modeling step followed by rejection sampling is used. The accepted\npairs constitute the training part of OptMATH. Then a collection of rejected\npairs is identified and further filtered. This collection serves as a new\nbenchmark for optimization modeling, containing difficult instances whose\nlengths are much longer than these of NL4OPT and MAMO. Through extensive\nexperiments, we demonstrate that models of various sizes (0.5B-32B parameters)\ntrained on OptMATH achieve superior results on multiple modeling benchmarks,\nthereby validating the effectiveness and scalability of our approach. Our\ndataset is publicly available at https://github.com/AuroraLHL/OptMATH.",
      "tldr_zh": "本论文针对大型语言模型 (LLMs) 在优化建模中缺乏高质量数据集的问题，提出了一种可扩展的双向数据合成框架 OptMATH，用于生成高质量的优化问题数据集。该框架从数学公式 (MF) 种子数据出发，自动生成问题数据 (PD) 并控制复杂度，然后通过回译 (back-translation) 获得自然语言描述 (NL)，并采用前向建模和拒绝采样 (rejection sampling) 验证数据对应性，以构建训练数据集和一个新的基准测试集。实验结果显示，在 OptMATH 上训练的各种规模模型 (0.5B-32B 参数) 在多个优化建模基准上取得优越性能，证明了该框架的有效性和可扩展性。数据集已公开可用，可从 https://github.com/AuroraLHL/OptMATH 获取。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has 36 pages, 18 figures, and two co-first authors:\n  Hongliang Lu and Zhonglin Xie",
      "pdf_url": "http://arxiv.org/pdf/2502.11102v2",
      "published_date": "2025-02-16 12:38:37 UTC",
      "updated_date": "2025-02-21 10:54:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:07:43.993753"
    },
    {
      "arxiv_id": "2502.12204v1",
      "title": "Predicting Depression in Screening Interviews from Interactive Multi-Theme Collaboration",
      "title_zh": "基于交互式多主题协作预测筛查访谈中的抑郁症",
      "authors": [
        "Xianbing Zhao",
        "Yiqing Lyu",
        "Di Wang",
        "Buzhou Tang"
      ],
      "abstract": "Automatic depression detection provides cues for early clinical intervention\nby clinicians. Clinical interviews for depression detection involve dialogues\ncentered around multiple themes. Existing studies primarily design end-to-end\nneural network models to capture the hierarchical structure of clinical\ninterview dialogues. However, these methods exhibit defects in modeling the\nthematic content of clinical interviews: 1) they fail to capture intra-theme\nand inter-theme correlation explicitly, and 2) they do not allow clinicians to\nintervene and focus on themes of interest. To address these issues, this paper\nintroduces an interactive depression detection framework. This framework\nleverages in-context learning techniques to identify themes in clinical\ninterviews and then models both intra-theme and inter-theme correlation.\nAdditionally, it employs AI-driven feedback to simulate the interests of\nclinicians, enabling interactive adjustment of theme importance. PDIMC achieves\nabsolute improvements of 35\\% and 12\\% compared to the state-of-the-art on the\ndepression detection dataset DAIC-WOZ, which demonstrates the effectiveness of\nmodeling theme correlation and incorporating interactive external feedback.",
      "tldr_zh": "这篇论文提出了一种交互式框架 PDIMC，用于从临床采访的多主题协作中预测抑郁症，旨在解决现有端到端模型在捕捉 intra-theme 和 inter-theme 相关性以及允许临床干预方面的缺陷。框架利用 in-context learning 技术识别采访主题，并建模主题内和主题间的相关性，同时通过 AI 驱动反馈模拟临床医生的兴趣，实现交互式调整主题重要性。在 DAIC-WOZ 数据集上，PDIMC 比最先进方法绝对提高了 35% 和 12% 的性能，证明了建模主题相关性和加入交互反馈的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.12204v1",
      "published_date": "2025-02-16 12:37:16 UTC",
      "updated_date": "2025-02-16 12:37:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:07:54.627151"
    },
    {
      "arxiv_id": "2502.11101v1",
      "title": "CacheFocus: Dynamic Cache Re-Positioning for Efficient Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Kun-Hui Lee",
        "Eunhwan Park",
        "Donghoon Han",
        "Seung-Hoon Na"
      ],
      "abstract": "Large Language Models (LLMs) excel across a variety of language tasks yet are\nconstrained by limited input lengths and high computational costs. Existing\napproaches\\textemdash such as relative positional encodings (e.g., RoPE, ALiBi)\nand sliding window mechanisms\\textemdash partially alleviate these issues but\noften require additional training or suffer from performance degradation with\nlonger inputs. In this paper, we introduce \\textbf{\\textit{CacheFocus}}, a\nmethod that enhances length normalization and reduces inference latency without\nany further training. Our approach leverages query-independent, offline caching\nto efficiently reuse a Context KV Cache Store. We address the amplification of\nabnormal token distributions problem by re-positioning cached keys and\nintroducing Layer-Adaptive Cache Pruning to discard low-relevance caches during\npre-filling. Additionally, our Adaptive Positional Allocation Strategy\ndynamically reassigns cache positions to maximize the use of the available\npositional encoding range. Experiments on the Natural Questions and TriviaQA\ndatasets demonstrate that CacheFocus outperforms alternative methods even when\ninputs exceed the $4$K limit of the \\texttt{LLaMA-2} model, emphasizing its\npractical effectiveness for long-context LLMs. Moreover, even with large\nmaximum input length of \\texttt{Qwen2}, the performance of CacheFocus shows\nthat it maintains consistent performance even as the number of documents\nincreases, effectively managing long-text generation without degradation.",
      "tldr_zh": "这篇论文介绍了 CacheFocus，一种动态缓存重新定位方法，旨在提升 Large Language Models (LLMs) 在检索增强生成（RAG）中的效率，而无需额外训练。它通过查询无关的离线缓存、重定位缓存键以解决异常 token 分布问题，以及引入 Layer-Adaptive Cache Pruning 和 Adaptive Positional Allocation Strategy 来优化缓存使用和位置编码范围。实验在 Natural Questions 和 TriviaQA 数据集上证明，CacheFocus 在超过 LLaMA-2 的 4K 输入限制时性能优于基线方法，并在 Qwen2 模型上保持一致表现，即使文档数量增加也不会降级。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages (Work in progress)",
      "pdf_url": "http://arxiv.org/pdf/2502.11101v1",
      "published_date": "2025-02-16 12:33:16 UTC",
      "updated_date": "2025-02-16 12:33:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:08:06.981207"
    },
    {
      "arxiv_id": "2502.12203v1",
      "title": "An Interpretable Automated Mechanism Design Framework with Large Language Models",
      "title_zh": "一种使用大型语言模型的可解释自动化机制设计框架",
      "authors": [
        "Jiayuan Liu",
        "Mingyu Guo",
        "Vincent Conitzer"
      ],
      "abstract": "Mechanism design has long been a cornerstone of economic theory, with\ntraditional approaches relying on mathematical derivations. Recently, automated\napproaches, including differentiable economics with neural networks, have\nemerged for designing payments and allocations. While both analytical and\nautomated methods have advanced the field, they each face significant\nweaknesses: mathematical derivations are not automated and often struggle to\nscale to complex problems, while automated and especially neural-network-based\napproaches suffer from limited interpretability. To address these challenges,\nwe introduce a novel framework that reformulates mechanism design as a code\ngeneration task. Using large language models (LLMs), we generate heuristic\nmechanisms described in code and evolve them to optimize over some evaluation\nmetrics while ensuring key design criteria (e.g., strategy-proofness) through a\nproblem-specific fixing process. This fixing process ensures any mechanism\nviolating the design criteria is adjusted to satisfy them, albeit with some\ntrade-offs in performance metrics. These trade-offs are factored in during the\nLLM-based evolution process. The code generation capabilities of LLMs enable\nthe discovery of novel and interpretable solutions, bridging the symbolic logic\nof mechanism design and the generative power of modern AI. Through rigorous\nexperimentation, we demonstrate that LLM-generated mechanisms achieve\ncompetitive performance while offering greater interpretability compared to\nprevious approaches. Notably, our framework can rediscover existing manually\ndesigned mechanisms and provide insights into neural-network based solutions\nthrough Programming-by-Example. These results highlight the potential of LLMs\nto not only automate but also enhance the transparency and scalability of\nmechanism design, ensuring safe deployment of the mechanisms in society.",
      "tldr_zh": "本研究提出了一种可解释的自动化机制设计框架，利用Large Language Models (LLMs) 将机制设计转化为代码生成任务，以解决传统数学推导的扩展性问题和神经网络方法的解释性不足。框架通过LLMs生成启发式机制代码，并通过进化优化和问题特定修复过程（如确保策略证明性）来平衡性能指标与设计标准，尽管可能涉及某些权衡。该方法不仅能发现新颖、可解释的解决方案，还能桥接机制设计的符号逻辑与AI生成能力；实验结果显示，LLM生成的机制在性能上与现有方法竞争，并在可解释性上表现出色，能重新发现手动设计机制并提供对神经网络解决方案的洞见，从而提升机制设计的透明度、可扩展性和社会安全部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.12203v1",
      "published_date": "2025-02-16 12:33:03 UTC",
      "updated_date": "2025-02-16 12:33:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:08:19.350125"
    },
    {
      "arxiv_id": "2502.11098v1",
      "title": "Talk Structurally, Act Hierarchically: A Collaborative Framework for LLM Multi-Agent Systems",
      "title_zh": "结构性对话，层级化行动：LLM",
      "authors": [
        "Zhao Wang",
        "Sota Moriyama",
        "Wei-Yao Wang",
        "Briti Gangopadhyay",
        "Shingo Takamatsu"
      ],
      "abstract": "Recent advancements in LLM-based multi-agent (LLM-MA) systems have shown\npromise, yet significant challenges remain in managing communication and\nrefinement when agents collaborate on complex tasks. In this paper, we propose\n\\textit{Talk Structurally, Act Hierarchically (TalkHier)}, a novel framework\nthat introduces a structured communication protocol for context-rich exchanges\nand a hierarchical refinement system to address issues such as incorrect\noutputs, falsehoods, and biases. \\textit{TalkHier} surpasses various types of\nSoTA, including inference scaling model (OpenAI-o1), open-source multi-agent\nmodels (e.g., AgentVerse), and majority voting strategies on current LLM and\nsingle-agent baselines (e.g., ReAct, GPT4o), across diverse tasks, including\nopen-domain question answering, domain-specific selective questioning, and\npractical advertisement text generation. These results highlight its potential\nto set a new standard for LLM-MA systems, paving the way for more effective,\nadaptable, and collaborative multi-agent frameworks. The code is available\nhttps://github.com/sony/talkhier.",
      "tldr_zh": "本研究提出了一种名为 TalkHier 的新型框架，用于提升 LLM-MA 系统中的代理协作效率，针对复杂任务中的通信管理和精炼问题（如输出错误、虚假信息和偏见）。框架引入结构化通信协议（structured communication protocol）以支持丰富的上下文交换，以及分层精炼系统（hierarchical refinement system）来优化代理互动。实验结果显示，TalkHier 在开放域问答、领域特定选择性提问和广告文本生成等任务上，超越了现有顶尖模型（如 OpenAI-o1、AgentVerse、ReAct 和 GPT4o），为更有效、可适应的多代理系统设定了新标准。代码已开源于 https://github.com/sony/talkhier。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11098v1",
      "published_date": "2025-02-16 12:26:58 UTC",
      "updated_date": "2025-02-16 12:26:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:08:30.191205"
    },
    {
      "arxiv_id": "2502.11096v1",
      "title": "Mixture of Tunable Experts -- Behavior Modification of DeepSeek-R1 at Inference Time",
      "title_zh": "翻译失败",
      "authors": [
        "Robert Dahlke",
        "Henrik Klagges",
        "Dan Zecha",
        "Benjamin Merkel",
        "Sven Rohr",
        "Fabian Klemm"
      ],
      "abstract": "We present the Mixture-of-Tunable-Experts (MoTE), a method that extends the\nMixture-of-Experts architecture of Large Language Models (LLMs). Without\nadditional training, MoTE enables meaningful and focused behavior changes in\nLLMs on-the-fly during inference time. By analyzing the digital LLM brain of\nDeepSeek-R1 using a technique we dub 'functional Token Resonance Imaging'\n(fTRI) -- inspired by fMRI and using prompts designed to elicit specific\nbehavior (e.g., 'What happened {time}{place}?') -- we empirically identify\ndistinctive experts associated with behaviors like refusal responses. Using\nMoTE we are able to intervene and control such specific behavior. We switched\noff the top 10 most refusal-relevant experts (0.07% of R1's 14,848 routed\nexperts), achieving a 52% refusal reduction on sensitive reference prompts\nwithout performance degradation on MT-Bench. Random expert deactivation\nresulted in smaller behavioral shifts with increased noise, whereas forced\nexpert activation led to significantly higher refusal rates. Our approach\nshares similarities with sparse autoencoders (SAEs) in terms of explainability\nand steerability. Unlike SAEs, MoTE does not require large training efforts, as\nwithin MoEs with a vast number of experts, specialization already emerged\nnaturally during pretraining. Our findings suggest that significant functional\nmechanisms in Mixture-of-Experts architectures can at least partially be\nlocalized in a small number of specific experts, rather than being distributed\nthroughout the model's weights. Expert subgroups can be tuned to trigger\nsignificant behavior variations, providing insights into the inner workings of\nLLMs.",
      "tldr_zh": "本研究提出Mixture-of-Tunable-Experts (MoTE)，一种扩展Mixture-of-Experts (MoE)架构的方法，允许在Large Language Models (LLMs)推理时无需额外训练即可实现针对性的行为修改，例如减少拒绝响应。研究使用'functional Token Resonance Imaging' (fTRI)技术分析DeepSeek-R1模型，识别与特定行为相关的专家，并通过关闭顶层10个拒绝相关专家（占0.07%）实现了敏感提示下拒绝率降低52%，同时在MT-Bench上保持性能不变。与sparse autoencoders (SAEs)类似，MoTE提供模型的可解释性和可操控性，但无需额外训练，因为专家在预训练中已自然出现。该方法揭示了LLMs行为机制可能集中在少数专家上，而非分布于整个模型权重。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11096v1",
      "published_date": "2025-02-16 12:24:39 UTC",
      "updated_date": "2025-02-16 12:24:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:08:43.081510"
    },
    {
      "arxiv_id": "2502.11094v1",
      "title": "SyncSpeech: Low-Latency and Efficient Dual-Stream Text-to-Speech based on Temporal Masked Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengyan Sheng",
        "Zhihao Du",
        "Shiliang Zhang",
        "Zhijie Yan",
        "Yexin Yang",
        "Zhenhua Ling"
      ],
      "abstract": "This paper presents a dual-stream text-to-speech (TTS) model, SyncSpeech,\ncapable of receiving streaming text input from upstream models while\nsimultaneously generating streaming speech, facilitating seamless interaction\nwith large language models. SyncSpeech has the following advantages: Low\nlatency, as it begins generating streaming speech upon receiving the second\ntext token; High efficiency, as it decodes all speech tokens corresponding to\nthe each arrived text token in one step. To achieve this, we propose a temporal\nmasked transformer as the backbone of SyncSpeech, combined with token-level\nduration prediction to predict speech tokens and the duration for the next\nstep. Additionally, we design a two-stage training strategy to improve training\nefficiency and the quality of generated speech. We evaluated the SyncSpeech on\nboth English and Mandarin datasets. Compared to the recent dual-stream TTS\nmodels, SyncSpeech significantly reduces the first packet delay of speech\ntokens and accelerates the real-time factor. Moreover, with the same data\nscale, SyncSpeech achieves performance comparable to that of traditional\nautoregressive-based TTS models in terms of both speech quality and robustness.\nSpeech samples are available at\nhttps://SyncSpeech.github.io/}{https://SyncSpeech.github.io/.",
      "tldr_zh": "本文提出了一种低延迟、高效的双流文本到语音 (TTS) 模型 SyncSpeech，它能同时处理流式文本输入并生成流式语音，支持与大型语言模型的无缝互动。SyncSpeech 采用 Temporal Masked Transformer 作为骨干网络，结合标记级持续时间预测，并在两阶段训练策略中优化训练效率和语音质量。实验结果显示，该模型在英语和普通话数据集上显著降低了语音标记的首次包延迟和实时因子，与传统自回归 TTS 模型在语音质量和鲁棒性方面性能相当。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11094v1",
      "published_date": "2025-02-16 12:14:17 UTC",
      "updated_date": "2025-02-16 12:14:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:08:55.473687"
    },
    {
      "arxiv_id": "2502.11090v2",
      "title": "SafeDialBench: A Fine-Grained Safety Benchmark for Large Language Models in Multi-Turn Dialogues with Diverse Jailbreak Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Hongye Cao",
        "Yanming Wang",
        "Sijia Jing",
        "Ziyue Peng",
        "Zhixin Bai",
        "Zhe Cao",
        "Meng Fang",
        "Fan Feng",
        "Boyan Wang",
        "Jiaheng Liu",
        "Tianpei Yang",
        "Jing Huo",
        "Yang Gao",
        "Fanyu Meng",
        "Xi Yang",
        "Chao Deng",
        "Junlan Feng"
      ],
      "abstract": "With the rapid advancement of Large Language Models (LLMs), the safety of\nLLMs has been a critical concern requiring precise assessment. Current\nbenchmarks primarily concentrate on single-turn dialogues or a single jailbreak\nattack method to assess the safety. Additionally, these benchmarks have not\ntaken into account the LLM's capability of identifying and handling unsafe\ninformation in detail. To address these issues, we propose a fine-grained\nbenchmark SafeDialBench for evaluating the safety of LLMs across various\njailbreak attacks in multi-turn dialogues. Specifically, we design a two-tier\nhierarchical safety taxonomy that considers 6 safety dimensions and generates\nmore than 4000 multi-turn dialogues in both Chinese and English under 22\ndialogue scenarios. We employ 7 jailbreak attack strategies, such as reference\nattack and purpose reverse, to enhance the dataset quality for dialogue\ngeneration. Notably, we construct an innovative assessment framework of LLMs,\nmeasuring capabilities in detecting, and handling unsafe information and\nmaintaining consistency when facing jailbreak attacks. Experimental results\nacross 17 LLMs reveal that Yi-34B-Chat and GLM4-9B-Chat demonstrate superior\nsafety performance, while Llama3.1-8B-Instruct and o3-mini exhibit safety\nvulnerabilities.",
      "tldr_zh": "该研究提出 SafeDialBench，一个细粒度的安全基准，用于评估大型语言模型(LLMs)在多轮对话中面对各种越狱攻击的安全性能，解决了现有基准忽略多轮对话和详细处理不安全信息的问题。该基准基于一个两层层次安全分类法，涵盖6个安全维度，在22个对话场景下生成超过4000个中英双语多轮对话，并采用7种攻击策略如reference attack和purpose reverse来增强数据集质量。创新的评估框架测量LLMs在检测、处理不安全信息和保持一致性方面的能力，实验结果显示Yi-34B-Chat和GLM4-9B-Chat表现出色，而Llama3.1-8B-Instruct和o3-mini存在显著漏洞。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11090v2",
      "published_date": "2025-02-16 12:08:08 UTC",
      "updated_date": "2025-02-18 03:05:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:09:07.595234"
    },
    {
      "arxiv_id": "2502.11089v2",
      "title": "Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyang Yuan",
        "Huazuo Gao",
        "Damai Dai",
        "Junyu Luo",
        "Liang Zhao",
        "Zhengyan Zhang",
        "Zhenda Xie",
        "Y. X. Wei",
        "Lean Wang",
        "Zhiping Xiao",
        "Yuqing Wang",
        "Chong Ruan",
        "Ming Zhang",
        "Wenfeng Liang",
        "Wangding Zeng"
      ],
      "abstract": "Long-context modeling is crucial for next-generation language models, yet the\nhigh computational cost of standard attention mechanisms poses significant\ncomputational challenges. Sparse attention offers a promising direction for\nimproving efficiency while maintaining model capabilities. We present NSA, a\nNatively trainable Sparse Attention mechanism that integrates algorithmic\ninnovations with hardware-aligned optimizations to achieve efficient\nlong-context modeling. NSA employs a dynamic hierarchical sparse strategy,\ncombining coarse-grained token compression with fine-grained token selection to\npreserve both global context awareness and local precision. Our approach\nadvances sparse attention design with two key innovations: (1) We achieve\nsubstantial speedups through arithmetic intensity-balanced algorithm design,\nwith implementation optimizations for modern hardware. (2) We enable end-to-end\ntraining, reducing pretraining computation without sacrificing model\nperformance. As shown in Figure 1, experiments show the model pretrained with\nNSA maintains or exceeds Full Attention models across general benchmarks,\nlong-context tasks, and instruction-based reasoning. Meanwhile, NSA achieves\nsubstantial speedups over Full Attention on 64k-length sequences across\ndecoding, forward propagation, and backward propagation, validating its\nefficiency throughout the model lifecycle.",
      "tldr_zh": "本论文提出了 NSA（Native Sparse Attention），一种硬件对齐且可原生训练的稀疏注意力机制，旨在解决长上下文建模中标准注意力机制的高计算成本问题。NSA 采用动态分层稀疏策略，结合粗粒度 token 压缩和细粒度 token 选择，以保持全局上下文感知和局部精度，同时通过算法优化和硬件实现实现算术强度平衡。实验结果表明，使用 NSA 预训练的模型在一般基准、长上下文任务和指令推理上与 Full Attention 模型相当或优于后者，并在 64k 长序列的解码、前向传播和后向传播中实现显著加速，验证了其端到端训练效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11089v2",
      "published_date": "2025-02-16 11:53:44 UTC",
      "updated_date": "2025-02-27 09:01:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:09:19.343332"
    },
    {
      "arxiv_id": "2502.11085v1",
      "title": "Towards Data-Efficient Pretraining for Atomic Property Prediction",
      "title_zh": "迈向数据高效的原子属性预测预训练",
      "authors": [
        "Yasir Ghunaim",
        "Hasan Abed Al Kader Hammoud",
        "Bernard Ghanem"
      ],
      "abstract": "This paper challenges the recent paradigm in atomic property prediction that\nlinks progress to growing dataset sizes and computational resources. We show\nthat pretraining on a carefully selected, task-relevant dataset can match or\neven surpass large-scale pretraining, while using as little as 1/24th of the\ncomputational cost. We introduce the Chemical Similarity Index (CSI), a novel\nmetric inspired by computer vision's Fr\\'echet Inception Distance, for\nmolecular graphs which quantifies the alignment between upstream pretraining\ndatasets and downstream tasks. By selecting the most relevant dataset with\nminimal CSI distance, we show that models pretrained on a smaller, focused\ndataset consistently outperform those pretrained on massive, mixed datasets\nsuch as JMP, even when those larger datasets include the relevant dataset.\nCounterintuitively, we also find that indiscriminately adding more data can\ndegrade model performance when the additional data poorly aligns with the task\nat hand. Our findings highlight that quality often outperforms quantity in\npretraining for atomic property prediction.",
      "tldr_zh": "本论文质疑了原子属性预测领域依赖大规模数据集和计算资源的传统范式，证明使用精心选择的、与任务相关的较小数据集进行预训练可以匹配或超越大型预训练的表现，同时仅需1/24的计算成本。\n他们引入了Chemical Similarity Index (CSI)，一个受Fréchet Inception Distance启发的指标，用于量化上游预训练数据集与下游任务的契合度。\n通过选择CSI距离最小的相关数据集，实验结果显示模型在较小、专注的数据集上预训练时，表现优于在庞大混合数据集（如JMP）上预训练的模型，即使后者包含相关数据。\n此外，论文发现无差别地添加更多数据可能降低性能，强调在原子属性预测中，数据质量往往胜过数量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11085v1",
      "published_date": "2025-02-16 11:46:23 UTC",
      "updated_date": "2025-02-16 11:46:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:09:31.400974"
    },
    {
      "arxiv_id": "2503.05715v1",
      "title": "The Butterfly Effect of Technology: How Various Factors accelerate or hinder the Arrival of Technological Singularity",
      "title_zh": "技术的蝴蝶效应：各种因素如何加速或阻碍技术奇点的到来",
      "authors": [
        "Hooman Shababi"
      ],
      "abstract": "This article explores the concept of technological singularity and the\nfactors that could accelerate or hinder its arrival. The butterfly effect is\nused as a framework to understand how seemingly small changes in complex\nsystems can have significant and unpredictable outcomes. In section II, we\ndiscuss the various factors that could hasten the arrival of technological\nsingularity, such as advances in artificial intelligence and machine learning,\nbreakthroughs in quantum computing, progress in brain-computer interfaces and\nhuman augmentation, and development of nanotechnology and 3D printing. In\nsection III, we examine the factors that could delay or impede the arrival of\ntechnological singularity, including technical limitations and setbacks in AI\nand machine learning, ethical and societal concerns around AI and its impact on\njobs and privacy, lack of sufficient investment in research and development,\nand regulatory barriers and political instability. Section IV explores the\ninterplay of these factors and how they can impact the butterfly effect.\nFinally, in the conclusion, we summarize the key points discussed and emphasize\nthe importance of considering the butterfly effect in predicting the future of\ntechnology. We call for continued research and investment in technology to\nshape its future and mitigate potential risks.",
      "tldr_zh": "这篇论文以蝴蝶效应（butterfly effect）为框架，探讨技术奇点（technological singularity）的概念，以及各种因素如何加速或阻碍其到来，包括人工智能（artificial intelligence）和机器学习（machine learning）的进展、量子计算突破等加速因素，以及技术限制、伦理和社会担忧（如就业和隐私问题）、投资不足和监管障碍等阻碍因素。论文分析了这些因素的相互作用及其对复杂系统的潜在影响，强调小变化可能导致重大结果。最终，它呼吁持续投资和研究，以塑造技术未来并缓解相关风险。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "20 Pages, 0 Figures, 0 Tables",
      "pdf_url": "http://arxiv.org/pdf/2503.05715v1",
      "published_date": "2025-02-16 11:38:35 UTC",
      "updated_date": "2025-02-16 11:38:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:09:42.776869"
    },
    {
      "arxiv_id": "2502.15771v1",
      "title": "Learning to Reason from Feedback at Test-Time",
      "title_zh": "翻译失败",
      "authors": [
        "Yanyang Li",
        "Michael Lyu",
        "Liwei Wang"
      ],
      "abstract": "Solving complex tasks in a single attempt is challenging for large language\nmodels (LLMs). Iterative interaction with the environment and feedback is often\nrequired to achieve success, making effective feedback utilization a critical\ntopic. Existing approaches either struggle with length generalization or rely\non naive retries without leveraging prior information. In this paper, we\nintroduce FTTT, a novel paradigm that formulates feedback utilization as an\noptimization problem at test time. Additionally, we propose a learnable\ntest-time optimizer, OpTune, to effectively exploit feedback. Experiments on\ntwo LLMs across four reasoning datasets demonstrate that FTTT and OpTune\nachieve superior scalability and performance.",
      "tldr_zh": "大语言模型(LLMs)在复杂任务上难以一次成功，需要有效利用反馈，但现有方法往往在长度泛化或信息利用上存在局限。本文引入FTTT范式，将反馈利用表述为测试时的优化问题，并提出可学习的测试时优化器OpTune，以充分利用反馈信息。实验结果显示，FTTT和OpTune在两个LLMs和四个推理数据集上实现了优越的可扩展性和性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "The code is at https://github.com/LaVi-Lab/FTTT",
      "pdf_url": "http://arxiv.org/pdf/2502.15771v1",
      "published_date": "2025-02-16 11:05:27 UTC",
      "updated_date": "2025-02-16 11:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:09:53.913949"
    },
    {
      "arxiv_id": "2502.11079v2",
      "title": "Phantom: Subject-consistent video generation via cross-modal alignment",
      "title_zh": "Phantom: 通过跨模态对齐实现主体一致的视频生成",
      "authors": [
        "Lijie Liu",
        "Tianxiang Ma",
        "Bingchuan Li",
        "Zhuowei Chen",
        "Jiawei Liu",
        "Gen Li",
        "Siyu Zhou",
        "Qian He",
        "Xinglong Wu"
      ],
      "abstract": "The continuous development of foundational models for video generation is\nevolving into various applications, with subject-consistent video generation\nstill in the exploratory stage. We refer to this as Subject-to-Video, which\nextracts subject elements from reference images and generates\nsubject-consistent videos following textual instructions. We believe that the\nessence of subject-to-video lies in balancing the dual-modal prompts of text\nand image, thereby deeply and simultaneously aligning both text and visual\ncontent. To this end, we propose Phantom, a unified video generation framework\nfor both single- and multi-subject references. Building on existing\ntext-to-video and image-to-video architectures, we redesign the joint\ntext-image injection model and drive it to learn cross-modal alignment via\ntext-image-video triplet data. The proposed method achieves high-fidelity\nsubject-consistent video generation while addressing issues of image content\nleakage and multi-subject confusion. Evaluation results indicate that our\nmethod outperforms other state-of-the-art closed-source commercial solutions.\nIn particular, we emphasize subject consistency in human generation, covering\nexisting ID-preserving video generation while offering enhanced advantages.",
      "tldr_zh": "这篇论文提出了Phantom框架，用于Subject-to-Video生成，通过cross-modal alignment实现文本和图像双模态提示的深度对齐，从而从参考图像提取主体元素并生成主体一致的视频。Phantom基于现有的text-to-video和image-to-video架构，重设计了联合文本-图像注入模型，并利用文本-图像-视频三元组数据训练以解决图像内容泄露和多主体混淆问题。实验结果表明，该方法在单主体和多主体场景中均优于其他最先进商业解决方案，尤其在人类生成中的主体一致性上提供了显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11079v2",
      "published_date": "2025-02-16 11:02:50 UTC",
      "updated_date": "2025-04-10 10:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:10:06.325075"
    },
    {
      "arxiv_id": "2502.11075v1",
      "title": "Exposing Numeracy Gaps: A Benchmark to Evaluate Fundamental Numerical Abilities in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyang Li",
        "Xuejia Chen",
        "Zhanchao XU",
        "Darian Li",
        "Nicole Hu",
        "Fei Teng",
        "Yiming Li",
        "Luyu Qiu",
        "Chen Jason Zhang",
        "Qing Li",
        "Lei Chen"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nnatural language processing tasks, such as text generation and semantic\nunderstanding. However, their performance on numerical reasoning tasks, such as\nbasic arithmetic, numerical retrieval, and magnitude comparison, remains\nsurprisingly poor. This gap arises from their reliance on surface-level\nstatistical patterns rather than understanding numbers as continuous\nmagnitudes. Existing benchmarks primarily focus on either linguistic competence\nor structured mathematical problem-solving, neglecting fundamental numerical\nreasoning required in real-world scenarios. To bridge this gap, we propose\nNumericBench, a comprehensive benchmark to evaluate six fundamental numerical\ncapabilities: number recognition, arithmetic operations, contextual retrieval,\ncomparison, summary, and logical reasoning. NumericBench includes datasets\nranging from synthetic number lists to the crawled real-world data, addressing\nchallenges like long contexts, noise, and multi-step reasoning. Extensive\nexperiments on state-of-the-art LLMs, including GPT-4 and DeepSeek, reveal\npersistent weaknesses in numerical reasoning, highlighting the urgent need to\nimprove numerically-aware language modeling. The benchmark is released in:\nhttps://github.com/TreeAI-Lab/NumericBench.",
      "tldr_zh": "本研究揭示了大型语言模型(LLMs)在数字推理能力上的不足，如基本算术运算、数字检索和大小比较，并提出 NumericBench 基准来评估六种基本数字能力：number recognition, arithmetic operations, contextual retrieval, comparison, summary, and logical reasoning。NumericBench 包括从合成数据到真实世界数据集，处理长上下文、噪声和多步推理等挑战。通过对 GPT-4 和 DeepSeek 等模型的实验，研究发现 LLMs 存在持续弱点，强调了提升数字感知语言建模的迫切需求。该基准已开源在 GitHub 上。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11075v1",
      "published_date": "2025-02-16 10:48:28 UTC",
      "updated_date": "2025-02-16 10:48:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:10:18.689050"
    },
    {
      "arxiv_id": "2502.12202v2",
      "title": "To Think or Not to Think: Exploring the Unthinking Vulnerability in Large Reasoning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zihao Zhu",
        "Hongbao Zhang",
        "Ruotong Wang",
        "Ke Xu",
        "Siwei Lyu",
        "Baoyuan Wu"
      ],
      "abstract": "Large Reasoning Models (LRMs) are designed to solve complex tasks by\ngenerating explicit reasoning traces before producing final answers. However,\nwe reveal a critical vulnerability in LRMs -- termed Unthinking Vulnerability\n-- wherein the thinking process can be bypassed by manipulating special\ndelimiter tokens. It is empirically demonstrated to be widespread across\nmainstream LRMs, posing both a significant risk and potential utility,\ndepending on how it is exploited. In this paper, we systematically investigate\nthis vulnerability from both malicious and beneficial perspectives. On the\nmalicious side, we introduce Breaking of Thought (BoT), a novel attack that\nenables adversaries to bypass the thinking process of LRMs, thereby\ncompromising their reliability and availability. We present two variants of\nBoT: a training-based version that injects backdoor during the fine-tuning\nstage, and a training-free version based on adversarial attack during the\ninference stage. As a potential defense, we propose thinking recovery alignment\nto partially mitigate the vulnerability. On the beneficial side, we introduce\nMonitoring of Thought (MoT), a plug-and-play framework that allows model owners\nto enhance efficiency and safety. It is implemented by leveraging the same\nvulnerability to dynamically terminate redundant or risky reasoning through\nexternal monitoring. Extensive experiments show that BoT poses a significant\nthreat to reasoning reliability, while MoT provides a practical solution for\npreventing overthinking and jailbreaking. Our findings expose an inherent flaw\nin current LRM architectures and underscore the need for more robust reasoning\nsystems in the future.",
      "tldr_zh": "这篇论文揭示了 Large Reasoning Models (LRMs) 中的关键漏洞——Unthinking Vulnerability，即通过操纵特殊分隔符令模型绕过其思考过程，从而影响其可靠性和可用性。研究者从恶意角度引入 Breaking of Thought (BoT) 攻击，包括训练-based 和训练-free 变体，用于破坏模型性能，并提出 thinking recovery alignment 作为潜在防御；从有益角度，开发了 Monitoring of Thought (MoT) 框架，利用该漏洞通过外部监控动态终止冗余或风险推理，以提升效率和安全性。实验结果显示，BoT 显著威胁 LRM 的可靠性，而 MoT 提供实用解决方案，强调了未来 LRM 架构需更稳健的设计。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "39 pages, 13 tables, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.12202v2",
      "published_date": "2025-02-16 10:45:56 UTC",
      "updated_date": "2025-05-16 19:32:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:10:30.926929"
    },
    {
      "arxiv_id": "2502.11070v1",
      "title": "A Survey on Vulnerability Prioritization: Taxonomy, Metrics, and Research Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Yuning Jiang",
        "Nay Oo",
        "Qiaoran Meng",
        "Hoon Wei Lim",
        "Biplab Sikdar"
      ],
      "abstract": "In the highly interconnected digital landscape of today, safeguarding complex\ninfrastructures against cyber threats has become increasingly challenging due\nto the exponential growth in the number and complexity of vulnerabilities.\nResource constraints necessitate effective vulnerability prioritization\nstrategies, focusing efforts on the most critical risks. This paper presents a\nsystematic literature review of 82 studies, introducing a novel taxonomy that\ncategorizes metrics into severity, exploitability, contextual factors,\npredictive indicators, and aggregation methods. Our analysis reveals\nsignificant gaps in existing approaches and challenges with multi-domain\napplicability. By emphasizing the need for dynamic, context-aware metrics and\nscalable solutions, we provide actionable insights to bridge the gap between\nresearch and real-world applications. This work contributes to the field by\noffering a comprehensive framework for evaluating vulnerability prioritization\nmethodologies and setting a research agenda to advance the state of practice.",
      "tldr_zh": "这篇论文通过对82篇研究的系统文献综述，引入了一个新的taxonomy，将vulnerability prioritization的metrics分为严重性(severity)、exploitability、contextual factors、predictive indicators和aggregation methods。\n分析揭示了现有方法在多领域适用性方面的显著差距，并强调了动态、context-aware metrics和可扩展解决方案的需求。\n论文提供了评估vulnerability prioritization方法ologies的全面框架，并为未来研究设定了议程，以桥接学术与实际应用的鸿沟。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11070v1",
      "published_date": "2025-02-16 10:33:37 UTC",
      "updated_date": "2025-02-16 10:33:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:10:42.293945"
    },
    {
      "arxiv_id": "2502.11068v1",
      "title": "Accelerating Anchors via Specialization and Feature Transformation",
      "title_zh": "通过专化和特征变换加速",
      "authors": [
        "Haonan Yu",
        "Junhao Liu",
        "Xin Zhang"
      ],
      "abstract": "Anchors is a popular local model-agnostic explanation technique whose\napplicability is limited by its computational inefficiency. To address this\nlimitation, we propose a pre-training-based approach to accelerate Anchors\nwithout compromising the explanation quality. Our approach leverages the\niterative nature of Anchors' algorithm which gradually refines an explanation\nuntil it is precise enough for a given input by providing a general explanation\nthat is obtained through pre-training as Anchors' initial explanation.\nSpecifically, we develop a two-step rule transformation process: the horizontal\ntransformation adapts a pre-trained explanation to the current input by\nreplacing features, and the vertical transformation refines the general\nexplanation until it is precise enough for the input. We evaluate our method\nacross tabular, text, and image datasets, demonstrating that it significantly\nreduces explanation generation time while maintaining fidelity and\ninterpretability, thereby enabling the practical adoption of Anchors in\ntime-sensitive applications.",
      "tldr_zh": "本研究针对Anchors解释技术的计算效率问题，提出了一种基于预训练的方法来加速其生成过程，同时保持解释质量。该方法利用Anchors算法的迭代特性，通过提供一个预训练的通用解释作为初始点，并引入两个步骤的规则转换：horizontal transformation用于替换特征以适应当前输入，vertical transformation则进一步精炼解释直至精确。实验在表格、文本和图像数据集上验证了该方法的有效性，显著减少了解释生成时间，同时维持了fidelity和interpretability，从而使Anchors在时间敏感应用中更具实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11068v1",
      "published_date": "2025-02-16 10:30:01 UTC",
      "updated_date": "2025-02-16 10:30:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:10:53.984206"
    },
    {
      "arxiv_id": "2503.05882v1",
      "title": "Practical Topics in Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Lu"
      ],
      "abstract": "In an era where data-driven decision-making and computational efficiency are\nparamount, optimization plays a foundational role in advancing fields such as\nmathematics, computer science, operations research, machine learning, and\nbeyond. From refining machine learning models to improving resource allocation\nand designing efficient algorithms, optimization techniques serve as essential\ntools for tackling complex problems. This book aims to provide both an\nintroductory guide and a comprehensive reference, equipping readers with the\nnecessary knowledge to understand and apply optimization methods within their\nrespective fields.\n  Our primary goal is to demystify the inner workings of optimization\nalgorithms, including black-box and stochastic optimizers, by offering both\nformal and intuitive explanations. Starting from fundamental mathematical\nprinciples, we derive key results to ensure that readers not only learn how\nthese techniques work but also understand when and why to apply them\neffectively. By striking a careful balance between theoretical depth and\npractical application, this book serves a broad audience, from students and\nresearchers to practitioners seeking robust optimization strategies.",
      "tldr_zh": "这本书探讨了优化（optimization）在数据驱动决策和计算效率中的核心作用，涵盖数学、计算机科学、运筹学（operations research）和机器学习（machine learning）等领域。作者旨在提供一个入门指南和全面参考，通过从基本数学原则出发，结合正式和直观的解释来剖析优化算法，包括黑箱（black-box）和随机优化器（stochastic optimizers），并指导读者何时及为什么有效应用这些方法。书中平衡了理论深度与实际应用，帮助学生、研究人员和从业者掌握优化策略，以解决复杂问题。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA",
        "math.OC"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05882v1",
      "published_date": "2025-02-16 10:00:50 UTC",
      "updated_date": "2025-02-16 10:00:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:11:05.664938"
    },
    {
      "arxiv_id": "2502.11059v1",
      "title": "ClimateLLM: Efficient Weather Forecasting via Frequency-Aware Large Language Models",
      "title_zh": "ClimateLLM：通过频率感知的大型语言模型实现高效天气预报",
      "authors": [
        "Shixuan Li",
        "Wei Yang",
        "Peiyu Zhang",
        "Xiongye Xiao",
        "Defu Cao",
        "Yuehan Qin",
        "Xiaole Zhang",
        "Yue Zhao",
        "Paul Bogdan"
      ],
      "abstract": "Weather forecasting is crucial for public safety, disaster prevention and\nmitigation, agricultural production, and energy management, with global\nrelevance. Although deep learning has significantly advanced weather\nprediction, current methods face critical limitations: (i) they often struggle\nto capture both dynamic temporal dependencies and short-term abrupt changes,\nmaking extreme weather modeling difficult; (ii) they incur high computational\ncosts due to extensive training and resource requirements; (iii) they have\nlimited adaptability to multi-scale frequencies, leading to challenges when\nseparating global trends from local fluctuations. To address these issues, we\npropose ClimateLLM, a foundation model for weather forecasting. It captures\nspatiotemporal dependencies via a cross-temporal and cross-spatial\ncollaborative modeling framework that integrates Fourier-based frequency\ndecomposition with Large Language Models (LLMs) to strengthen spatial and\ntemporal modeling. Our framework uses a Mixture-of-Experts (MoE) mechanism that\nadaptively processes different frequency components, enabling efficient\nhandling of both global signals and localized extreme events. In addition, we\nintroduce a cross-temporal and cross-spatial dynamic prompting mechanism,\nallowing LLMs to incorporate meteorological patterns across multiple scales\neffectively. Extensive experiments on real-world datasets show that ClimateLLM\noutperforms state-of-the-art approaches in accuracy and efficiency, as a\nscalable solution for global weather forecasting.",
      "tldr_zh": "该研究提出ClimateLLM，一种基于频率感知的Large Language Models (LLMs)框架，用于高效天气预报，旨在解决现有方法在捕捉动态时间依赖性、短期变化以及多尺度频率方面的局限性，同时降低计算成本。ClimateLLM通过整合Fourier-based frequency decomposition与跨时间和空间协作建模框架，以及Mixture-of-Experts (MoE)机制，来适应性处理全球信号和局部极端事件，并引入动态提示机制以有效整合多尺度气象模式。在真实数据集上的广泛实验表明，ClimateLLM在准确性和效率上优于现有方法，提供了一个可扩展的全球天气预报解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11059v1",
      "published_date": "2025-02-16 09:57:50 UTC",
      "updated_date": "2025-02-16 09:57:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:11:19.755920"
    },
    {
      "arxiv_id": "2502.11057v2",
      "title": "A Physics-Informed Machine Learning Framework for Safe and Optimal Control of Autonomous Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Manan Tayal",
        "Aditya Singh",
        "Shishir Kolathaya",
        "Somil Bansal"
      ],
      "abstract": "As autonomous systems become more ubiquitous in daily life, ensuring high\nperformance with guaranteed safety is crucial. However, safety and performance\ncould be competing objectives, which makes their co-optimization difficult.\nLearning-based methods, such as Constrained Reinforcement Learning (CRL),\nachieve strong performance but lack formal safety guarantees due to safety\nbeing enforced as soft constraints, limiting their use in safety-critical\nsettings. Conversely, formal methods such as Hamilton-Jacobi (HJ) Reachability\nAnalysis and Control Barrier Functions (CBFs) provide rigorous safety\nassurances but often neglect performance, resulting in overly conservative\ncontrollers. To bridge this gap, we formulate the co-optimization of safety and\nperformance as a state-constrained optimal control problem, where performance\nobjectives are encoded via a cost function and safety requirements are imposed\nas state constraints. We demonstrate that the resultant value function\nsatisfies a Hamilton-Jacobi-Bellman (HJB) equation, which we approximate\nefficiently using a novel physics-informed machine learning framework. In\naddition, we introduce a conformal prediction-based verification strategy to\nquantify the learning errors, recovering a high-confidence safety value\nfunction, along with a probabilistic error bound on performance degradation.\nThrough several case studies, we demonstrate the efficacy of the proposed\nframework in enabling scalable learning of safe and performant controllers for\ncomplex, high-dimensional autonomous systems.",
      "tldr_zh": "该研究提出了一种Physics-Informed Machine Learning框架，用于自主系统的安全和最优控制，解决安全与性能之间潜在冲突的问题。通过将安全要求作为状态约束、最优性能作为成本函数形式化，该框架将问题转化为状态约束的最优控制问题，并利用Hamilton-Jacobi-Bellman (HJB)方程进行高效近似。作者引入Conformal Prediction-based验证策略来量化学习错误，提供高置信度的安全价值函数和性能退化的概率误差界。实验案例证明，该框架在复杂高维自主系统中实现了可扩展的学习，显著提升了安全性和性能平衡。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "15 Pages, 12 Figures. First two authors have contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2502.11057v2",
      "published_date": "2025-02-16 09:46:17 UTC",
      "updated_date": "2025-02-24 12:56:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:11:30.378952"
    },
    {
      "arxiv_id": "2502.11054v4",
      "title": "Reasoning-Augmented Conversation for Multi-Turn Jailbreak Attacks on Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zonghao Ying",
        "Deyue Zhang",
        "Zonglei Jing",
        "Yisong Xiao",
        "Quanchen Zou",
        "Aishan Liu",
        "Siyuan Liang",
        "Xiangzheng Zhang",
        "Xianglong Liu",
        "Dacheng Tao"
      ],
      "abstract": "Multi-turn jailbreak attacks simulate real-world human interactions by\nengaging large language models (LLMs) in iterative dialogues, exposing critical\nsafety vulnerabilities. However, existing methods often struggle to balance\nsemantic coherence with attack effectiveness, resulting in either benign\nsemantic drift or ineffective detection evasion. To address this challenge, we\npropose Reasoning-Augmented Conversation, a novel multi-turn jailbreak\nframework that reformulates harmful queries into benign reasoning tasks and\nleverages LLMs' strong reasoning capabilities to compromise safety alignment.\nSpecifically, we introduce an attack state machine framework to systematically\nmodel problem translation and iterative reasoning, ensuring coherent query\ngeneration across multiple turns. Building on this framework, we design\ngain-guided exploration, self-play, and rejection feedback modules to preserve\nattack semantics, enhance effectiveness, and sustain reasoning-driven attack\nprogression. Extensive experiments on multiple LLMs demonstrate that RACE\nachieves state-of-the-art attack effectiveness in complex conversational\nscenarios, with attack success rates (ASRs) increasing by up to 96%. Notably,\nour approach achieves ASRs of 82% and 92% against leading commercial models,\nOpenAI o1 and DeepSeek R1, underscoring its potency. We release our code at\nhttps://github.com/NY1024/RACE to facilitate further research in this critical\ndomain.",
      "tldr_zh": "这篇论文提出了一种名为 Reasoning-Augmented Conversation (RACE) 的多轮越狱攻击框架，针对大型语言模型 (LLMs) 的安全漏洞，通过将有害查询转化为良性推理任务，利用 LLMs 的推理能力来破坏其安全对齐。框架引入攻击状态机 (attack state machine) 来系统建模问题翻译和迭代推理，并设计了 gain-guided exploration、self-play 和 rejection feedback 模块，以保持攻击语义连贯性、提升有效性和持续推进攻击过程。实验结果显示，RACE 在多个 LLMs 上实现了最先进的攻击成功率 (ASRs)，较基准提高了高达 96%，并对 OpenAI o1 和 DeepSeek R1 分别达到 82% 和 92%。该研究发布了代码（https://github.com/NY1024/RACE），有助于进一步探索此类安全挑战。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11054v4",
      "published_date": "2025-02-16 09:27:44 UTC",
      "updated_date": "2025-03-11 03:06:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:11:43.692201"
    },
    {
      "arxiv_id": "2502.11051v3",
      "title": "MMUnlearner: Reformulating Multimodal Machine Unlearning in the Era of Multimodal Large Language Models",
      "title_zh": "MMUnlearner：多模态机器遗忘在多模态大型语言模型时代的重新表述",
      "authors": [
        "Jiahao Huo",
        "Yibo Yan",
        "Xu Zheng",
        "Yuanhuiyi Lyu",
        "Xin Zou",
        "Zhihua Wei",
        "Xuming Hu"
      ],
      "abstract": "Recent progress in Machine Unlearning (MU) has introduced solutions for the\nselective removal of private or sensitive information encoded within deep\nneural networks. Nonetheless, MU for Multimodal Large Language Models (MLLMs)\nremains in its nascent phase. Therefore, we propose to reformulate the task of\nmultimodal MU in the era of MLLMs, which aims to erase only the visual patterns\nassociated with a given entity while preserving the corresponding textual\nknowledge encoded within the original parameters of the language model\nbackbone. Furthermore, we develop a novel geometry-constrained gradient ascent\nmethod MMUnlearner. It updates the weights of MLLMs with a weight saliency map\njointly restricted by the remaining concepts and textual knowledge during\nunlearning, thereby preserving parameters essential for non-target knowledge.\nExtensive experiments demonstrate that MMUnlearner surpasses baselines that\nfinetuning MLLMs with VQA data directly through Gradient Ascent (GA) or\nNegative Preference Optimization (NPO), across all evaluation dimensions. Our\ncode will be released upon acceptance.",
      "tldr_zh": "该论文重新定义了在 Multimodal Large Language Models (MLLMs) 时代的多模态机器取消学习 (Machine Unlearning, MU)，旨在仅删除特定实体相关的视觉模式，同时保留语言模型主干中的文本知识。作者提出了 MMUnlearner 方法，该方法采用几何约束的梯度上升 (Gradient Ascent) 技术，并结合权重显著性图来更新 MLLMs 的权重，确保非目标知识得到保留。实验结果显示，MMUnlearner 在所有评估维度上优于基线方法，如直接使用 Gradient Ascent (GA) 或 Negative Preference Optimization (NPO) 微调 MLLMs。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as ACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2502.11051v3",
      "published_date": "2025-02-16 09:23:50 UTC",
      "updated_date": "2025-05-20 15:47:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:11:55.070895"
    },
    {
      "arxiv_id": "2504.05309v1",
      "title": "IterQR: An Iterative Framework for LLM-based Query Rewrite in e-Commercial Search System",
      "title_zh": "翻译失败",
      "authors": [
        "Shangyu Chen",
        "Xinyu Jia",
        "Yingfei Zhang",
        "Shuai Zhang",
        "Xiang Li",
        "Wei Lin"
      ],
      "abstract": "The essence of modern e-Commercial search system lies in matching user's\nintent and available candidates depending on user's query, providing\npersonalized and precise service. However, user's query may be incorrect due to\nambiguous input and typo, leading to inaccurate search. These cases may be\nreleased by query rewrite: modify query to other representation or expansion.\nHowever, traditional query rewrite replies on static rewrite vocabulary, which\nis manually established meanwhile lacks interaction with both domain knowledge\nin e-Commercial system and common knowledge in the real world. In this paper,\nwith the ability to generate text content of Large Language Models (LLMs), we\nprovide an iterative framework to generate query rewrite. The framework\nincorporates a 3-stage procedure in each iteration: Rewrite Generation with\ndomain knowledge by Retrieval-Augmented Generation (RAG) and query\nunderstanding by Chain-of-Thoughts (CoT); Online Signal Collection with\nautomatic positive rewrite update; Post-training of LLM with multi task\nobjective to generate new rewrites. Our work (named as IterQR) provides a\ncomprehensive framework to generate \\textbf{Q}uery \\textbf{R}ewrite with both\ndomain / real-world knowledge. It automatically update and self-correct the\nrewrites during \\textbf{iter}ations. \\method{} has been deployed in Meituan\nDelivery's search system (China's leading food delivery platform), providing\nservice for users with significant improvement.",
      "tldr_zh": "本论文提出IterQR，一种基于Large Language Models (LLMs)的迭代框架，用于电商搜索系统的查询重写，以解决用户查询中的歧义和拼写错误问题。框架采用三阶段迭代过程：Rewrite Generation 通过Retrieval-Augmented Generation (RAG)和Chain-of-Thoughts (CoT)结合领域知识进行重写生成；Online Signal Collection 自动收集正面重写信号并更新；Post-training of LLM 通过多任务目标优化生成新重写。该框架能自动更新和自我修正，整合了领域知识和现实世界知识，并在美团外卖搜索系统中部署后显著提升了用户服务质量。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05309v1",
      "published_date": "2025-02-16 09:20:13 UTC",
      "updated_date": "2025-02-16 09:20:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:12:06.053918"
    },
    {
      "arxiv_id": "2502.15770v2",
      "title": "Performance Review on LLM for solving leetcode problems",
      "title_zh": "翻译失败",
      "authors": [
        "Lun Wang",
        "Chuanqi Shi",
        "Shaoshui Du",
        "Yiyi Tao",
        "Yixian Shen",
        "Hang Zheng",
        "Yanxin Shen",
        "Xinyu Qiu"
      ],
      "abstract": "This paper presents a comprehensive performance evaluation of Large Language\nModels (LLMs) in solving programming challenges from Leetcode, a widely used\nplatform for algorithm practice and technical interviews. We began by crawling\nthe Leetcode website to collect a diverse set of problems encompassing various\ndifficulty levels and topics. Using this dataset, we generated solutions with\nmultiple LLMs, including GPT-4 and GPT-3.5-turbo (ChatGPT-turbo). The generated\nsolutions were systematically evaluated for correctness and efficiency. We\nemployed the pass@k metric to assess the success rates within a given number of\nattempts and analyzed the runtime performance of the solutions. Our results\nhighlight the strengths and limitations of current LLMs [10] in code generation\nand problem-solving tasks, providing insights into their potential applications\nand areas for improvement in automated programming assistance.",
      "tldr_zh": "本研究评估了大语言模型（LLMs）在解决 Leetcode 编程挑战中的性能，通过爬取 Leetcode 网站收集多样化的问题集，包括不同难度和主题。研究团队使用 GPT-4 和 GPT-3.5-turbo 等模型生成解决方案，并通过 pass@k 指标评估成功率，以及分析代码的正确性和运行时效率。结果揭示了 LLMs 在代码生成和问题解决方面的优势和局限性，为自动化编程辅助技术的应用和改进提供了宝贵见解。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15770v2",
      "published_date": "2025-02-16 08:52:45 UTC",
      "updated_date": "2025-03-03 00:24:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:12:17.435139"
    },
    {
      "arxiv_id": "2502.11037v2",
      "title": "Deep Incomplete Multi-view Learning via Cyclic Permutation of VAEs",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Gao",
        "Jian Pu"
      ],
      "abstract": "Multi-View Representation Learning (MVRL) aims to derive a unified\nrepresentation from multi-view data by leveraging shared and complementary\ninformation across views. However, when views are irregularly missing, the\nincomplete data can lead to representations that lack sufficiency and\nconsistency. To address this, we propose Multi-View Permutation of Variational\nAuto-Encoders (MVP), which excavates invariant relationships between views in\nincomplete data. MVP establishes inter-view correspondences in the latent space\nof Variational Auto-Encoders, enabling the inference of missing views and the\naggregation of more sufficient information. To derive a valid Evidence Lower\nBound (ELBO) for learning, we apply permutations to randomly reorder variables\nfor cross-view generation and then partition them by views to maintain\ninvariant meanings under permutations. Additionally, we enhance consistency by\nintroducing an informational prior with cyclic permutations of posteriors,\nwhich turns the regularization term into a similarity measure across\ndistributions. We demonstrate the effectiveness of our approach on seven\ndiverse datasets with varying missing ratios, achieving superior performance in\nmulti-view clustering and generation tasks.",
      "tldr_zh": "这篇论文针对多视图表示学习(MVRL)中视图不规则缺失导致的表示不足和不一致问题，提出了一种名为Multi-View Permutation of Variational Auto-Encoders (MVP)的方法，通过在VAEs的潜在空间中建立视图间对应关系来挖掘不变关系，并推断缺失视图以聚合更多信息。MVP采用置换随机重新排序变量并按视图分区，以确保Evidence Lower Bound (ELBO)的有效学习，同时引入循环置换后验的信息先验，将正则化项转化为分布间的相似度度量，从而增强一致性。在七个不同数据集上的实验中，该方法在多视图聚类和生成任务中表现出优越性能，尤其适用于各种缺失比例的场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 4 figures, ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.11037v2",
      "published_date": "2025-02-16 08:36:43 UTC",
      "updated_date": "2025-02-28 06:04:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:12:31.318745"
    },
    {
      "arxiv_id": "2502.11028v1",
      "title": "Mind the Confidence Gap: Overconfidence, Calibration, and Distractor Effects in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Prateek Chhikara"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate impressive performance across\ndiverse tasks, yet confidence calibration remains a challenge. Miscalibration -\nwhere models are overconfident or underconfident - poses risks, particularly in\nhigh-stakes applications. This paper presents an empirical study on LLM\ncalibration, examining how model size, distractors, and question types affect\nconfidence alignment. We introduce an evaluation framework to measure\noverconfidence and investigate whether multiple-choice formats mitigate or\nworsen miscalibration. Our findings show that while larger models (e.g.,\nGPT-4o) are better calibrated overall, they are more prone to distraction,\nwhereas smaller models benefit more from answer choices but struggle with\nuncertainty estimation. Unlike prior work, which primarily reports\nmiscalibration trends, we provide actionable insights into failure modes and\nconditions that worsen overconfidence. These findings highlight the need for\ncalibration-aware interventions and improved uncertainty estimation methods.",
      "tldr_zh": "本研究探讨了大语言模型 (LLMs) 在信心校准方面的挑战，特别是过度自信 (overconfidence) 和干扰项 (distractors) 的影响，通过实证研究分析了模型大小、问题类型和多选格式如何影响校准效果。研究引入了一个评估框架来测量过度自信，发现更大模型（如 GPT-4o）整体校准更准确，但更容易受干扰，而较小模型从多选答案中获益更多，却在不确定性估计上表现较差。与以往工作不同，该论文提供了关于失败模式的详细见解，并强调了需要开发校准感知干预 (calibration-aware interventions) 和改进的不确定性估计方法，以提升 LLMs 在高风险应用中的可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11028v1",
      "published_date": "2025-02-16 07:46:09 UTC",
      "updated_date": "2025-02-16 07:46:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:12:42.680967"
    },
    {
      "arxiv_id": "2502.11026v2",
      "title": "Simplify RLHF as Reward-Weighted SFT: A Variational Method",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhao Du",
        "Zhuo Li",
        "Pengyu Cheng",
        "Zhihong Chen",
        "Yuejiao Xie",
        "Xiang Wan",
        "Anningzhe Gao"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) is crucial for aligning\nLarge Language Models (LLMs) with human values. However, RLHF has been\ncontinuously challenged by its high complexity in implementation and\ncomputation consumption. Even with recent simplifications, such as Direct\nPreference Optimization (DPO) and Advantage Leftover Lunch (A-LoL), the\nproblems of over-fitting and training instability remain hindering the\nalignment process from the expected optimal performance. To address the\nexisting challenges, we propose a novel simplification of RLHF from the\nperspective of variational inference, called $\\textbf{V}$ariational\n$\\textbf{A}$lignment with $\\textbf{R}$e-weighting ($\\textbf{VAR}$). More\nspecifically, by directly minimizing the distribution gap between the learning\nLLM policy and the optimal solution of RLHF, we transform the alignment\nobjective into a reward-driven re-weighted supervised fine-tuning (SFT) form,\nwhich only requires minor adjustment on the SFT loss to obtain noticeable\nimprovement on training stability and effectiveness. On comprehensive alignment\nand generation benchmarks, our VAR method has numerically achieved competitive\nperformance in LLM alignment helpfulness and harmlessness.",
      "tldr_zh": "本文提出了一种名为 VAR（Variational Alignment with Re-weighting）的变分方法，用于简化 RLHF（Reinforcement Learning from Human Feedback），以解决其在实现复杂性、计算消耗、过拟合和训练不稳定性等问题。VAR 通过最小化学习 LLM 策略与 RLHF 最优解的分布差距，将对齐目标转化为奖励驱动的再加权 SFT（Supervised Fine-Tuning），只需对 SFT 损失进行微小调整即可显著提升训练稳定性和有效性。在全面的对齐和生成基准测试中，VAR 在 LLM 的帮助性和无害性方面取得了竞争性的性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11026v2",
      "published_date": "2025-02-16 07:22:00 UTC",
      "updated_date": "2025-02-19 02:44:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:12:54.893569"
    },
    {
      "arxiv_id": "2502.11022v1",
      "title": "MultiTEND: A Multilingual Benchmark for Natural Language to NoSQL Query Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiqian Qin",
        "Yuanfeng Song",
        "Jinwei Lu",
        "Yuanwei Song",
        "Shuaimin Li",
        "Chen Jason Zhang"
      ],
      "abstract": "Natural language interfaces for NoSQL databases are increasingly vital in the\nbig data era, enabling users to interact with complex, unstructured data\nwithout deep technical expertise. However, most recent advancements focus on\nEnglish, leaving a gap for multilingual support. This paper introduces\nMultiTEND, the first and largest multilingual benchmark for natural language to\nNoSQL query generation, covering six languages: English, German, French,\nRussian, Japanese and Mandarin Chinese. Using MultiTEND, we analyze challenges\nin translating natural language to NoSQL queries across diverse linguistic\nstructures, including lexical and syntactic differences. Experiments show that\nperformance accuracy in both English and non-English settings remains\nrelatively low, with a 4%-6% gap across scenarios like fine-tuned SLM,\nzero-shot LLM, and RAG for LLM. To address the aforementioned challenges, we\nintroduce MultiLink, a novel framework that bridges the multilingual input to\nNoSQL query generation gap through a Parallel Linking Process. It breaks down\nthe task into multiple steps, integrating parallel multilingual processing,\nChain-of-Thought (CoT) reasoning, and Retrieval-Augmented Generation (RAG) to\ntackle lexical and structural challenges inherent in multilingual NoSQL\ngeneration. MultiLink shows enhancements in all metrics for every language\nagainst the top baseline, boosting execution accuracy by about 15% for English\nand averaging a 10% improvement for non-English languages.",
      "tldr_zh": "本研究引入了MultiTEND，这是第一个也是最大的多语言基准，用于评估自然语言到NoSQL查询翻译，支持英语、德语、法语、俄语、日语和普通话。该基准分析了跨语言的词汇和句法差异带来的挑战，并通过实验发现，在微调的SLM、零样本LLM和RAG for LLM等场景中，查询准确率较低，且英语与非英语语言之间存在4%-6%的性能差距。为解决这些问题，研究提出MultiLink框架，通过Parallel Linking Process将任务分解为多个步骤，整合并行多语言处理、Chain-of-Thought (CoT)推理和Retrieval-Augmented Generation (RAG)。实验结果显示，MultiLink在所有指标上优于顶级基准模型，为英语提高了约15%的执行准确率，非英语语言平均提升10%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11022v1",
      "published_date": "2025-02-16 07:12:47 UTC",
      "updated_date": "2025-02-16 07:12:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:13:07.817712"
    },
    {
      "arxiv_id": "2502.11020v1",
      "title": "TUMLU: A Unified and Native Language Understanding Benchmark for Turkic Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Jafar Isbarov",
        "Arofat Akhundjanova",
        "Mammad Hajili",
        "Kavsar Huseynova",
        "Dmitry Gaynullin",
        "Anar Rzayev",
        "Osman Tursun",
        "Ilshat Saetov",
        "Rinat Kharisov",
        "Saule Belginova",
        "Ariana Kenbayeva",
        "Amina Alisheva",
        "Aizirek Turdubaeva",
        "Abdullatif Köksal",
        "Samir Rustamov",
        "Duygu Ataman"
      ],
      "abstract": "Being able to thoroughly assess massive multi-task language understanding\n(MMLU) capabilities is essential for advancing the applicability of\nmultilingual language models. However, preparing such benchmarks in high\nquality native language is often costly and therefore limits the\nrepresentativeness of evaluation datasets. While recent efforts focused on\nbuilding more inclusive MMLU benchmarks, these are conventionally built using\nmachine translation from high-resource languages, which may introduce errors\nand fail to account for the linguistic and cultural intricacies of the target\nlanguages. In this paper, we address the lack of native language MMLU benchmark\nespecially in the under-represented Turkic language family with distinct\nmorphosyntactic and cultural characteristics. We propose two benchmarks for\nTurkic language MMLU: TUMLU is a comprehensive, multilingual, and natively\ndeveloped language understanding benchmark specifically designed for Turkic\nlanguages. It consists of middle- and high-school level questions spanning 11\nacademic subjects in Azerbaijani, Crimean Tatar, Karakalpak, Kazakh, Tatar,\nTurkish, Uyghur, and Uzbek. We also present TUMLU-mini, a more concise,\nbalanced, and manually verified subset of the dataset. Using this dataset, we\nsystematically evaluate a diverse range of open and proprietary multilingual\nlarge language models (LLMs), including Claude, Gemini, GPT, and LLaMA,\noffering an in-depth analysis of their performance across different languages,\nsubjects, and alphabets. To promote further research and development in\nmultilingual language understanding, we release TUMLU-mini and all\ncorresponding evaluation scripts.",
      "tldr_zh": "本研究针对多任务语言理解（MMLU）基准的局限性，提出 TUMLU，这是一个统一且本土开发的语言理解基准，专注于突厥语系（Turkic languages），以解决机器翻译引入的错误和文化特性缺失问题。TUMLU 包含 11 个学术主题的中学和高中文题，涵盖 Azerbaijani、Crimean Tatar、Karakalpak、Kazakh、Tatar、Turkish、Uyghur 和 Uzbek 等 8 种语言；同时，还发布了更精简且手动验证的子集 TUMLU-mini。研究通过该基准系统评估了多种多语言大语言模型（LLMs）如 Claude、Gemini、GPT 和 LLaMA，在不同语言、主题和字母系统上的性能，提供深入分析。为促进多语言理解研究，该基准及其评估脚本已公开发布。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11020v1",
      "published_date": "2025-02-16 07:07:38 UTC",
      "updated_date": "2025-02-16 07:07:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:13:19.850989"
    },
    {
      "arxiv_id": "2502.11019v2",
      "title": "Unlocking the Power of Function Vectors for Characterizing and Mitigating Catastrophic Forgetting in Continual Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Gangwei Jiang",
        "Caigao Jiang",
        "Zhaoyi Li",
        "Siqiao Xue",
        "Jun Zhou",
        "Linqi Song",
        "Defu Lian",
        "Ying Wei"
      ],
      "abstract": "Catastrophic forgetting (CF) poses a significant challenge in machine\nlearning, where a model forgets previously learned information upon learning\nnew tasks. Despite the advanced capabilities of Large Language Models (LLMs),\nthey continue to face challenges with CF during continual learning. The\nmajority of existing research focuses on analyzing forgetting patterns through\na singular training sequence, thereby overlooking the intricate effects that\ndiverse tasks have on model behavior. Our study explores CF across various\nsettings, discovering that model forgetting is influenced by both the specific\ntraining tasks and the models themselves. To this end, we interpret forgetting\nby examining the function vector (FV), a compact representation of functions in\nLLMs, offering a model-dependent indicator for the occurrence of CF. Through\ntheoretical and empirical analyses, we demonstrated that CF in LLMs primarily\nstems from biases in function activation rather than the overwriting of task\nprocessing functions. Leveraging these insights, we propose a novel function\nvector guided training methodology, incorporating a regularization technique to\nstabilize the FV and mitigate forgetting. Empirical tests on four benchmarks\nconfirm the effectiveness of our proposed training method, substantiating our\ntheoretical framework concerning CF and model function dynamics. We plan to\nmake our code publicly accessible in the near future.",
      "tldr_zh": "本文研究了大语言模型(LLMs)在持续指令调整中的灾难性遗忘(Catastrophic Forgetting, CF)问题，发现遗忘不仅受特定训练任务影响，还与模型本身相关。作者通过分析函数向量(Function Vector, FV)——一种LLMs中函数的紧凑表示——证明CF主要源于函数激活偏差，而非任务处理函数的覆盖。基于此，他们提出了一种FV引导的训练方法，incorporating a regularization technique来稳定FV并缓解遗忘。在四个基准测试中，该方法显著提升了性能，验证了理论框架的有效性，并计划公开代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10pages",
      "pdf_url": "http://arxiv.org/pdf/2502.11019v2",
      "published_date": "2025-02-16 07:06:17 UTC",
      "updated_date": "2025-04-16 03:22:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:13:33.322715"
    },
    {
      "arxiv_id": "2502.11018v1",
      "title": "GRIFFIN: Effective Token Alignment for Faster Speculative Decoding",
      "title_zh": "GRIFFIN：有效的标记",
      "authors": [
        "Shijing Hu",
        "Jingyang Li",
        "Xingyu Xie",
        "Zhihui Lu",
        "Kim-Chuan Toh",
        "Pan Zhou"
      ],
      "abstract": "Speculative decoding accelerates inference in large language models (LLMs) by\ngenerating multiple draft tokens simultaneously. However, existing methods\noften struggle with token misalignment between the training and decoding\nphases, limiting their performance. To address this, we propose GRIFFIN, a\nnovel framework that incorporates a token-alignable training strategy and a\ntoken-alignable draft model to mitigate misalignment. The training strategy\nemploys a loss masking mechanism to exclude highly misaligned tokens during\ntraining, preventing them from negatively impacting the draft model's\noptimization. The token-alignable draft model introduces input tokens to\ncorrect inconsistencies in generated features. Experiments on LLaMA-series and\nVicuna models demonstrate that GRIFFIN achieves an average acceptance length\nimprovement of over 7\\% and a speedup ratio exceeding 8%, outperforming current\nSoTAs as shown in Fig. 1 (a) and (b).",
      "tldr_zh": "这篇论文提出了 GRIFFIN 框架，用于提升大型语言模型 (LLMs) 中的 Speculative Decoding 速度，通过解决训练和解码阶段的令牌不对齐问题。GRIFFIN 包括一个令牌可对齐的训练策略，利用损失掩码机制排除高度不对齐的令牌以优化模型，以及一个引入输入令牌修正生成特征的草稿模型。实验结果显示，在 LLaMA-series 和 Vicuna 模型上，GRIFFIN 平均提高了接受长度超过 7%，并实现了超过 8% 的加速比，超过了当前最先进方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11018v1",
      "published_date": "2025-02-16 07:06:00 UTC",
      "updated_date": "2025-02-16 07:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:13:43.850228"
    },
    {
      "arxiv_id": "2502.11013v4",
      "title": "Collaborative Deterministic-Probabilistic Forecasting for Real-World Spatiotemporal Systems",
      "title_zh": "真实世界时空系统的协作确定性-概率性预测",
      "authors": [
        "Zhi Sheng",
        "Yuan Yuan",
        "Yudi Zhang",
        "Depeng Jin",
        "Yong Li"
      ],
      "abstract": "Probabilistic forecasting is crucial for real-world spatiotemporal systems,\nsuch as climate, energy, and urban environments, where quantifying uncertainty\nis essential for informed, risk-aware decision-making. While diffusion models\nhave shown promise in capturing complex data distributions, their application\nto spatiotemporal forecasting remains limited due to complex spatiotemporal\ndynamics and high computational demands. In this work, we propose CoST, a novel\nframework that collaborates deterministic and diffusion models for\nspatiotemporal forecasting. CoST formulates a mean-residual decomposition\nstrategy: it leverages a powerful deterministic model to capture the\nconditional mean and a lightweight diffusion model to learn residual\nuncertainties. This collaborative formulation simplifies learning objectives,\nenhances forecasting accuracy, enables uncertainty quantification, and\nsignificantly improves computational efficiency. To address spatial\nheterogeneity, we further design a scale-aware diffusion mechanism to guide the\ndiffusion process. Extensive experiments across ten real-world datasets from\nclimate, energy, communication, and urban systems show that CoST achieves 25%\nperformance gains over state-of-the-art baselines, while significantly reducing\ncomputational cost.",
      "tldr_zh": "该研究针对真实时空系统（如气候、能源和城市环境）的概率预测问题，提出了一种协作框架CoST，以解决扩散模型在处理复杂时空动态和高计算需求时的局限性。CoST采用mean-residual decomposition策略，利用确定性模型捕捉条件均值，并结合轻量级扩散模型学习残差不确定性，从而简化学习目标、提升预测准确性和不确定性量化，同时显著提高计算效率。为应对空间异质性，该框架还设计了scale-aware diffusion mechanism来指导扩散过程。在十个真实数据集上的广泛实验显示，CoST相较于最先进基线提升了25%的性能，同时降低了计算成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.11013v4",
      "published_date": "2025-02-16 06:35:26 UTC",
      "updated_date": "2025-05-17 16:24:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:13:54.702706"
    },
    {
      "arxiv_id": "2503.04772v1",
      "title": "Generating Millions Of Lean Theorems With Proofs By Exploring State Transition Graphs",
      "title_zh": "通过探索状态转移图生成数百万带有证明的 Lean 定理",
      "authors": [
        "David Yin",
        "Jing Gao"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated significant potential in\ngenerating mathematical proofs. However, a persistent challenge is that LLMs\noccasionally make mistakes, while even a minor mistake can invalidate an entire\nproof. Proof assistants like Lean offer a great remedy. They are designed for\nverifying each step of a proof in a formal language, and in recent years\nresearchers have created AI models to generate proofs in their languages.\nHowever, the scarcity of large-scale datasets of Lean proofs restrict the\nperformance of such Automated Theorem Proving (ATP) models.\n  We developed LeanNavigator, a novel method for generating a large-scale\ndataset of Lean theorems and proofs by finding new ways to prove existing Lean\ntheorems. By leveraging an interactive Lean client and an efficient method for\nproof step generation, LeanNavigator efficiently produces new theorems with\ncorresponding proofs. Applying this approach to Mathlib4, we generated 4.7\nmillion theorems totaling 1 billion tokens, surpassing previous datasets by\nmore than an order of magnitude. Using this extensive dataset, we trained an AI\nmodel that outperforms the state-of-the-art ReProver model in theorem-proving\ntasks. These results confirm our hypothesis and demonstrate the critical role\nof large datasets in improving the performance of automated theorem provers.",
      "tldr_zh": "本文提出 LeanNavigator，一种通过探索状态转移图的新方法，用于生成大规模 Lean 定理和证明数据集，以解决 Large Language Models (LLMs) 在数学证明中出错问题和 Automated Theorem Proving (ATP) 模型数据稀缺的挑战。该方法利用交互式 Lean 客户端和高效证明步骤生成技术，在 Mathlib4 上生成了 470 万个定理，总计 10 亿 tokens，比现有数据集大一个数量级。使用此数据集训练的 AI 模型在定理证明任务中超过了 state-of-the-art 的 ReProver 模型，证实了大规模数据集对提升 ATP 性能的关键作用。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04772v1",
      "published_date": "2025-02-16 06:20:39 UTC",
      "updated_date": "2025-02-16 06:20:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:14:07.296947"
    },
    {
      "arxiv_id": "2502.11006v1",
      "title": "Prompt Inject Detection with Generative Explanation as an Investigative Tool",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Pan",
        "Swee Liang Wong",
        "Yidi Yuan",
        "Xin Wei Chia"
      ],
      "abstract": "Large Language Models (LLMs) are vulnerable to adversarial prompt based\ninjects. These injects could jailbreak or exploit vulnerabilities within these\nmodels with explicit prompt requests leading to undesired responses. In the\ncontext of investigating prompt injects, the challenge is the sheer volume of\ninput prompts involved that are likely to be largely benign. This investigative\nchallenge is further complicated by the semantics and subjectivity of the input\nprompts involved in the LLM conversation with its user and the context of the\nenvironment to which the conversation is being carried out. Hence, the\nchallenge for AI security investigators would be two-fold. The first is to\nidentify adversarial prompt injects and then to assess whether the input prompt\nis contextually benign or adversarial. For the first step, this could be done\nusing existing AI security solutions like guardrails to detect and protect the\nLLMs. Guardrails have been developed using a variety of approaches. A popular\napproach is to use signature based. Another popular approach to develop AI\nmodels to classify such prompts include the use of NLP based models like a\nlanguage model. However, in the context of conducting an AI security\ninvestigation of prompt injects, these guardrails lack the ability to aid\ninvestigators in triaging or assessing the identified input prompts. In this\napplied research exploration, we explore the use of a text generation\ncapabilities of LLM to detect prompt injects and generate explanation for its\ndetections to aid AI security investigators in assessing and triaging of such\nprompt inject detections. The practical benefit of such a tool is to ease the\ntask of conducting investigation into prompt injects.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)对对抗性提示注入(prompt injects)的漏洞，这些注入可能导致不期望的响应，并提出了一种检测方法来应对调查挑战。该方法利用LLMs的文本生成能力，不仅识别prompt injects，还生成解释以辅助AI安全调查者评估其语义和上下文是否良性或对抗性。与现有guardrails（如基于签名或NLP模型的解决方案）相比，这种工具增强了调查的评估和分类功能。实验结果表明，该方法能简化prompt inject调查过程，提高效率。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "5 pages, 4 tables, 3 diagrams",
      "pdf_url": "http://arxiv.org/pdf/2502.11006v1",
      "published_date": "2025-02-16 06:16:00 UTC",
      "updated_date": "2025-02-16 06:16:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:14:18.459244"
    },
    {
      "arxiv_id": "2502.12200v1",
      "title": "Efficient and Effective Prompt Tuning via Prompt Decomposition and Compressed Outer Product",
      "title_zh": "翻译失败",
      "authors": [
        "Pengxiang Lan",
        "Haoyu Xu",
        "Enneng Yang",
        "Yuliang Liang",
        "Guibing Guo",
        "Jianzhe Zhao",
        "Xingwei Wang"
      ],
      "abstract": "Prompt tuning (PT) offers a cost-effective alternative to fine-tuning\nlarge-scale pre-trained language models (PLMs), requiring only a few parameters\nin soft prompt tokens added before the input text. However, existing PT\napproaches face two significant issues: (i) They overlook intrinsic semantic\nassociations between soft prompt tokens, leading to high discreteness and\nlimited interactions, thus reducing the model's comprehension and effectiveness\nin complex tasks. (ii) Due to the complexity of downstream tasks, long soft\nprompt is necessitated to improve performance, but prompt length correlates\npositively with memory usage and computational costs. Achieving high efficiency\nand performance remains an ongoing challenge. To address these issues, we\npropose a novel Low-parameters prompt tuning (LAMP) method, which leverages\nprompt decomposition and compressed outer product. Specifically, the prompt\ndecomposition module employs Truncated SVD to reduce training parameters and\nsignificantly lower the dimensionality of the soft prompt parameter space. It\nthen utilizes a compressed outer product module to facilitate multiple\ninteractions among prompt tokens, exploring their intrinsic associations to\nenhance knowledge representation. Finally, LAMP uses average pooling to reduce\nmemory usage and training/inference time. Extensive experiments across six\narchitectures and eight datasets demonstrate that LAMP outperforms\nstate-of-the-art PT-based and LoRA-based methods in performance and efficiency.",
      "tldr_zh": "本论文针对 Prompt Tuning (PT) 的问题，提出了一种高效的 LAMP 方法，通过 Prompt Decomposition 和 Compressed Outer Product 来解决软提示标记间的语义关联缺失和计算成本高的问题。具体而言，LAMP 利用 Truncated SVD 减少训练参数并降低参数空间维度，同时通过压缩外积模块促进提示标记的多重交互，提升知识表示和模型性能。实验结果显示，在六种模型架构和八个数据集上，LAMP 在性能和效率方面均优于现有的 PT 和 LoRA 方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.12200v1",
      "published_date": "2025-02-16 05:50:12 UTC",
      "updated_date": "2025-02-16 05:50:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:14:30.877906"
    },
    {
      "arxiv_id": "2502.11001v1",
      "title": "CL-MFAP: A Contrastive Learning-Based Multimodal Foundation Model for Molecular Property Prediction and Antibiotic Screening",
      "title_zh": "CL-MFAP：一种基于对比学习的多模态基础模型，用于分子属性预测和抗生素筛选",
      "authors": [
        "Gen Zhou",
        "Sugitha Janarthanan",
        "Yutong Lu",
        "Pingzhao Hu"
      ],
      "abstract": "Due to the rise in antimicrobial resistance, identifying novel compounds with\nantibiotic potential is crucial for combatting this global health issue.\nHowever, traditional drug development methods are costly and inefficient.\nRecognizing the pressing need for more effective solutions, researchers have\nturned to machine learning techniques to streamline the prediction and\ndevelopment of novel antibiotic compounds. While foundation models have shown\npromise in antibiotic discovery, current mainstream efforts still fall short of\nfully leveraging the potential of multimodal molecular data. Recent studies\nsuggest that contrastive learning frameworks utilizing multimodal data exhibit\nexcellent performance in representation learning across various domains.\nBuilding upon this, we introduce CL-MFAP, an unsupervised contrastive learning\n(CL)-based multimodal foundation (MF) model specifically tailored for\ndiscovering small molecules with potential antibiotic properties (AP) using\nthree types of molecular data. This model employs 1.6 million bioactive\nmolecules with drug-like properties from the ChEMBL dataset to jointly pretrain\nthree encoders: (1) a transformer-based encoder with rotary position embedding\nfor processing SMILES strings; (2) another transformer-based encoder,\nincorporating a novel bi-level routing attention mechanism to handle molecular\ngraph representations; and (3) a Morgan fingerprint encoder using a multilayer\nperceptron, to achieve the contrastive learning purpose. The CL-MFAP\noutperforms baseline models in antibiotic property prediction by effectively\nutilizing different molecular modalities and demonstrates superior\ndomain-specific performance when fine-tuned for antibiotic-related property\nprediction tasks.",
      "tldr_zh": "该研究提出 CL-MFAP，一种基于 Contrastive Learning 的多模态基础模型，用于分子属性预测和抗生素筛选，以应对抗生素耐药性问题。模型利用 ChEMBL 数据集中的 160 万活性分子，联合预训练三个编码器：一个带旋转位置嵌入的 Transformer 编码器处理 SMILES 字符串、一个采用双层路由注意力机制的 Transformer 编码器处理分子图表示，以及一个基于多层感知器的 Morgan fingerprint 编码器。实验结果显示，CL-MFAP 在抗生素属性预测任务中优于基线模型，尤其在微调后展现出色的领域适应性，从而提升了新型抗生素化合物的发现效率。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "q-bio.BM",
      "comment": "Gen Zhou and Sugitha Janarthanan contributed equally; Accepted at\n  ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.11001v1",
      "published_date": "2025-02-16 05:45:19 UTC",
      "updated_date": "2025-02-16 05:45:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:14:43.283270"
    },
    {
      "arxiv_id": "2502.10999v1",
      "title": "ControlText: Unlocking Controllable Fonts in Multilingual Text Rendering without Font Annotations",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Jiang",
        "Yuan Yuan",
        "Xinyi Bai",
        "Zhuoqun Hao",
        "Alyson Yin",
        "Yaojie Hu",
        "Wenyu Liao",
        "Lyle Ungar",
        "Camillo J. Taylor"
      ],
      "abstract": "This work demonstrates that diffusion models can achieve font-controllable\nmultilingual text rendering using just raw images without font label\nannotations. Visual text rendering remains a significant challenge. While\nrecent methods condition diffusion on glyphs, it is impossible to retrieve\nexact font annotations from large-scale, real-world datasets, which prevents\nuser-specified font control. To address this, we propose a data-driven solution\nthat integrates the conditional diffusion model with a text segmentation model,\nutilizing segmentation masks to capture and represent fonts in pixel space in a\nself-supervised manner, thereby eliminating the need for any ground-truth\nlabels and enabling users to customize text rendering with any multilingual\nfont of their choice. The experiment provides a proof of concept of our\nalgorithm in zero-shot text and font editing across diverse fonts and\nlanguages, providing valuable insights for the community and industry toward\nachieving generalized visual text rendering.",
      "tldr_zh": "这篇论文提出 ControlText 方法，利用 diffusion models 实现多语言文本渲染中的字体控制，仅依赖原始图像而无需字体标签注释。方法通过整合 conditional diffusion model 和文本分割模型，使用分割掩码在像素空间进行自监督字体捕获和表示，允许用户自定义任意多语言字体。实验验证了该算法在零样本文本和字体编辑中的有效性，涵盖多种字体和语言，为通用视觉文本渲染提供了宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "This is preliminary work and code will be released at\n  github.com/bowen-upenn/ControlText",
      "pdf_url": "http://arxiv.org/pdf/2502.10999v1",
      "published_date": "2025-02-16 05:30:18 UTC",
      "updated_date": "2025-02-16 05:30:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:14:54.947101"
    },
    {
      "arxiv_id": "2502.10985v1",
      "title": "Is Elo Rating Reliable? A Study Under Model Misspecification",
      "title_zh": "翻译失败",
      "authors": [
        "Shange Tang",
        "Yuanhao Wang",
        "Chi Jin"
      ],
      "abstract": "Elo rating, widely used for skill assessment across diverse domains ranging\nfrom competitive games to large language models, is often understood as an\nincremental update algorithm for estimating a stationary Bradley-Terry (BT)\nmodel. However, our empirical analysis of practical matching datasets reveals\ntwo surprising findings: (1) Most games deviate significantly from the\nassumptions of the BT model and stationarity, raising questions on the\nreliability of Elo. (2) Despite these deviations, Elo frequently outperforms\nmore complex rating systems, such as mElo and pairwise models, which are\nspecifically designed to account for non-BT components in the data,\nparticularly in terms of win rate prediction. This paper explains this\nunexpected phenomenon through three key perspectives: (a) We reinterpret Elo as\nan instance of online gradient descent, which provides no-regret guarantees\neven in misspecified and non-stationary settings. (b) Through extensive\nsynthetic experiments on data generated from transitive but non-BT models, such\nas strongly or weakly stochastic transitive models, we show that the\n''sparsity'' of practical matching data is a critical factor behind Elo's\nsuperior performance in prediction compared to more complex rating systems. (c)\nWe observe a strong correlation between Elo's predictive accuracy and its\nranking performance, further supporting its effectiveness in ranking.",
      "tldr_zh": "本文研究了 Elo 评级在模型错误指定下的可靠性，通过分析实际匹配数据，发现大多数游戏偏离 Bradley-Terry (BT) 模型和平稳性假设，但 Elo 评级在胜率预测方面仍优于更复杂的系统如 mElo 和 pairwise models。论文从三个角度解释这一现象：(a) 将 Elo 重新解释为在线 gradient descent，提供无后悔保证；(b) 通过合成实验在非-BT 模型（如 strongly 或 weakly stochastic transitive 模型）上，证明数据稀疏性是 Elo 表现优越的关键因素；(c) 观察到 Elo 的预测准确性与排名性能高度相关，从而支持其可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "23pages",
      "pdf_url": "http://arxiv.org/pdf/2502.10985v1",
      "published_date": "2025-02-16 04:07:33 UTC",
      "updated_date": "2025-02-16 04:07:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:15:06.927835"
    },
    {
      "arxiv_id": "2502.10978v1",
      "title": "Agentic LLM Framework for Adaptive Decision Discourse",
      "title_zh": "翻译失败",
      "authors": [
        "Antoine Dolant",
        "Praveen Kumar"
      ],
      "abstract": "Effective decision-making in complex systems requires synthesizing diverse\nperspectives to address multifaceted challenges under uncertainty. This study\nintroduces a real-world inspired agentic Large Language Models (LLMs)\nframework, to simulate and enhance decision discourse-the deliberative process\nthrough which actionable strategies are collaboratively developed. Unlike\ntraditional decision-support tools, the framework emphasizes dialogue,\ntrade-off exploration, and the emergent synergies generated by interactions\namong agents embodying distinct personas. These personas simulate diverse\nstakeholder roles, each bringing unique priorities, expertise, and value-driven\nreasoning to the table. The framework incorporates adaptive and self-governing\nmechanisms, enabling agents to dynamically summon additional expertise and\nrefine their assembly to address evolving challenges. An illustrative\nhypothetical example focused on extreme flooding in a Midwestern township\ndemonstrates the framework's ability to navigate uncertainty, balance competing\npriorities, and propose mitigation and adaptation strategies by considering\nsocial, economic, and environmental dimensions. Results reveal how the\nbreadth-first exploration of alternatives fosters robust and equitable\nrecommendation pathways. This framework transforms how decisions are approached\nin high-stakes scenarios and can be incorporated in digital environments. It\nnot only augments decision-makers' capacity to tackle complexity but also sets\na foundation for scalable and context-aware AI-driven recommendations. This\nresearch explores novel and alternate routes leveraging agentic LLMs for\nadaptive, collaborative, and equitable recommendation processes, with\nimplications across domains where uncertainty and complexity converge.",
      "tldr_zh": "这篇论文提出了一种基于代理的LLM框架，用于模拟和增强适应性决策讨论过程，以应对复杂系统中的不确定性和多方面挑战。该框架强调代理间对话、权衡探索和互动，这些代理模拟不同利益相关者的角色，结合独特优先级、专业知识和价值驱动推理，并通过自适应机制动态调用专家并优化组装。在一个极端洪水假设场景中，框架展示了处理不确定性、平衡社会经济环境因素并生成稳健公平推荐的能力。研究结果表明，该框架可提升决策质量，并适用于高风险领域的可扩展AI驱动应用。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 4 figures, 1 appendix",
      "pdf_url": "http://arxiv.org/pdf/2502.10978v1",
      "published_date": "2025-02-16 03:46:37 UTC",
      "updated_date": "2025-02-16 03:46:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:15:18.598307"
    },
    {
      "arxiv_id": "2502.10976v1",
      "title": "QuOTE: Question-Oriented Text Embeddings",
      "title_zh": "QuOTE：面向问题的文本嵌入",
      "authors": [
        "Andrew Neeser",
        "Kaylen Latimer",
        "Aadyant Khatri",
        "Chris Latimer",
        "Naren Ramakrishnan"
      ],
      "abstract": "We present QuOTE (Question-Oriented Text Embeddings), a novel enhancement to\nretrieval-augmented generation (RAG) systems, aimed at improving document\nrepresentation for accurate and nuanced retrieval. Unlike traditional RAG\npipelines, which rely on embedding raw text chunks, QuOTE augments chunks with\nhypothetical questions that the chunk can potentially answer, enriching the\nrepresentation space. This better aligns document embeddings with user query\nsemantics, and helps address issues such as ambiguity and context-dependent\nrelevance. Through extensive experiments across diverse benchmarks, we\ndemonstrate that QuOTE significantly enhances retrieval accuracy, including in\nmulti-hop question-answering tasks. Our findings highlight the versatility of\nquestion generation as a fundamental indexing strategy, opening new avenues for\nintegrating question generation into retrieval-based AI pipelines.",
      "tldr_zh": "该论文提出 QuOTE（Question-Oriented Text Embeddings），一种针对检索增强生成（RAG）系统的创新方法，用于提升文档表示的准确性和细致度。QuOTE 通过为文本块添加假设问题来丰富嵌入空间，这些问题代表文本块可能回答的内容，从而更好地与用户查询语义对齐，并解决模糊性和上下文相关性问题。在多种基准上的广泛实验中，QuOTE 显著提高了检索准确性，尤其在多跳问答任务中。研究结果强调了问题生成作为一种基本索引策略的通用性，为将其整合到检索-based AI 管道中开辟新途径。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "H.3"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10976v1",
      "published_date": "2025-02-16 03:37:13 UTC",
      "updated_date": "2025-02-16 03:37:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:15:30.703900"
    },
    {
      "arxiv_id": "2502.13160v3",
      "title": "Attention Mechanism for LLM-based Agents Dynamic Diffusion under Information Asymmetry",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwen Zhang",
        "Yifu Wu",
        "Wenyue Hua",
        "Xiang Lu",
        "Xuming Hu"
      ],
      "abstract": "Large language models have been used to simulate human society using\nmulti-agent systems. Most current social simulation research emphasizes\ninteractive behaviors in fixed environments, ignoring information opacity,\nrelationship variability, and diffusion diversity. In this paper, we first\npropose a general framework for exploring multi-agent information diffusion. We\nidentified LLMs' deficiency in the perception and utilization of social\nrelationships, as well as diverse actions. Then, we designed a dynamic\nattention mechanism to help agents allocate attention to different information,\naddressing the limitations of the LLM attention mechanism. Agents start by\nresponding to external information stimuli within a five-agent group,\nincreasing group size and forming information circles while developing\nrelationships and sharing information. Additionally, we explore the information\ndiffusion features in the asymmetric open environment by observing the\nevolution of information gaps, diffusion patterns, and the accumulation of\nsocial capital, which are closely linked to psychological, sociological, and\ncommunication theories.",
      "tldr_zh": "本文提出一个通用框架，用于探索基于LLM的多智能体系统在信息不对称环境下的信息扩散问题，解决现有研究忽略的信息不透明、关系变异性和扩散多样性。研究者识别了LLM在感知社会关系和多样化行动方面的不足，并设计了动态attention mechanism，帮助智能体更有效地分配注意力响应外部信息刺激。实验通过模拟五智能体小组逐步扩展的信息圈，观察信息差距演变、扩散模式和社会资本积累，这些发现与心理学、社会学和传播理论紧密相关。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "18 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.13160v3",
      "published_date": "2025-02-16 03:02:48 UTC",
      "updated_date": "2025-05-20 14:34:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:15:42.674854"
    },
    {
      "arxiv_id": "2502.10966v1",
      "title": "Neural Networks Remember More: The Power of Parameter Isolation and Combination",
      "title_zh": "神经网络记住更多：参数隔离和组合的力量",
      "authors": [
        "Biqing Zeng",
        "Zehan Li",
        "Aladdin Ayesh"
      ],
      "abstract": "Catastrophic forgetting is a pervasive issue for pre-trained language models\n(PLMs) during continual learning, where models lose previously acquired\nknowledge when sequentially trained on a series of tasks. The model's ability\nto retain old tasks is referred to as stability, while its adaptability to new\ntasks is called plasticity. Therefore, the key to solving this problem is to\nfind a trade-off between the plasticity and stability of the model. To address\nthis issue, in this paper, we propose a novel method to achieve a balance\nbetween model stability and plasticity, thereby mitigating catastrophic\nforgetting. More specifically, our proposed approach leverages parameter\nisolation and a subsequent combination strategy. Initially, in the training\nstage, the model adapts to each downstream task via a parameter isolation\nmethod to prevent potential interference among different tasks. We then combine\nall trained parameters, which contain acquired knowledge, using the task\narithmetic method and finally apply them to the backbone model. Empirical\nevaluations on continual language learning benchmarks substantiate the\neffectiveness of our approach, revealing a marked enhancement over existing\nstate-of-the-art approaches.",
      "tldr_zh": "本文针对预训练语言模型(PLMs)在持续学习中存在的灾难性遗忘(Catastrophic forgetting)问题，提出了一种新方法，通过参数隔离(parameter isolation)和组合策略来平衡模型的稳定性(stability)和塑性(plasticity)。具体而言，该方法在训练阶段使用参数隔离技术，让模型适应每个下游任务以避免任务间干扰，然后通过任务算术(task arithmetic)方法结合所有训练参数，并应用到主模型。实验结果在持续语言学习基准上显示，该方法显著优于现有最先进方法，证明了其在缓解遗忘方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10966v1",
      "published_date": "2025-02-16 02:58:57 UTC",
      "updated_date": "2025-02-16 02:58:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:15:55.089820"
    },
    {
      "arxiv_id": "2502.10961v1",
      "title": "Graders should cheat: privileged information enables expert-level automated evaluations",
      "title_zh": "翻译失败",
      "authors": [
        "Jin Peng Zhou",
        "Sébastien M. R. Arnold",
        "Nan Ding",
        "Kilian Q. Weinberger",
        "Nan Hua",
        "Fei Sha"
      ],
      "abstract": "Auto-evaluating language models (LMs), i.e., using a grader LM to evaluate\nthe candidate LM, is an appealing way to accelerate the evaluation process and\nthe cost associated with it. But this presents a paradox: how can we trust the\ngrader LM, which is presumably weaker than the candidate LM, to assess problems\nthat are beyond the frontier of the capabilities of either model or both? For\ninstance, today's LMs struggle on graduate-level physics and Olympiad-level\nmath, making them unreliable graders in these domains.\n  We show that providing privileged information -- such as ground-truth\nsolutions or problem-specific guidelines -- improves automated evaluations on\nsuch frontier problems. This approach offers two key advantages. First, it\nexpands the range of problems where LMs graders apply. Specifically, weaker\nmodels can now rate the predictions of stronger models. Second, privileged\ninformation can be used to devise easier variations of challenging problems\nwhich improves the separability of different LMs on tasks where their\nperformance is generally low. With this approach, general-purpose LM graders\nmatch the state of the art performance on RewardBench, surpassing almost all\nthe specially-tuned models. LM graders also outperform individual human raters\non Vibe-Eval, and approach human expert graders on Olympiad-level math\nproblems.",
      "tldr_zh": "这篇论文探讨了使用语言模型 (LMs) 进行自动评估的挑战，即较弱的评估器 LM 如何可靠地评估超出其能力的候选 LM。作者提出通过提供特权信息 (privileged information)，如 ground-truth solutions 或问题特定指南，来显著提升评估性能，从而扩展评估范围并提高任务的可区分性。实验结果显示，这种方法使通用 LM 评估器在 RewardBench 上达到最先进 (SOTA) 水平，超过了几乎所有专门调整的模型，并在 Vibe-Eval 上优于单个人类评估者，在奥林匹克级数学问题上接近人类专家水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10961v1",
      "published_date": "2025-02-16 02:47:41 UTC",
      "updated_date": "2025-02-16 02:47:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:16:07.693763"
    },
    {
      "arxiv_id": "2502.10955v1",
      "title": "A recurrent vision transformer shows signatures of primate visual attention",
      "title_zh": "一种循环视觉变压器展现了灵长类视觉注意力的特征",
      "authors": [
        "Jonathan Morgan",
        "Badr Albanna",
        "James P. Herman"
      ],
      "abstract": "Attention is fundamental to both biological and artificial intelligence, yet\nresearch on animal attention and AI self attention remains largely\ndisconnected. We propose a Recurrent Vision Transformer (Recurrent ViT) that\nintegrates self-attention with recurrent memory, allowing both current inputs\nand stored information to guide attention allocation. Trained solely via sparse\nreward feedback on a spatially cued orientation change detection task, a\nparadigm used in primate studies, our model exhibits primate like signatures of\nattention, including improved accuracy and faster responses for cued stimuli\nthat scale with cue validity. Analysis of self-attention maps reveals dynamic\nspatial prioritization with reactivation prior to expected changes, and\ntargeted perturbations produce performance shifts similar to those observed in\nprimate frontal eye fields and superior colliculus. These findings demonstrate\nthat incorporating recurrent feedback into self attention can capture key\naspects of primate visual attention.",
      "tldr_zh": "本研究提出了一种Recurrent Vision Transformer (Recurrent ViT)，将self-attention机制与循环记忆(recurrent memory)相结合，旨在桥接生物和人工智能中的注意力机制。模型通过稀疏奖励反馈训练于空间提示导向的导向变化检测任务，展现出类似于灵长类动物的注意力特征，包括提高提示有效性下的准确性和响应速度。分析self-attention maps显示了动态空间优先级和预期变化前的重新激活，而针对性扰动导致性能变化，类似于灵长类前眼场(frontal eye fields)和上丘(superior colliculus)。这些发现表明，将循环反馈融入self-attention可有效捕捉灵长类视觉注意力的关键方面。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10955v1",
      "published_date": "2025-02-16 02:22:27 UTC",
      "updated_date": "2025-02-16 02:22:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:16:18.629224"
    },
    {
      "arxiv_id": "2502.10954v2",
      "title": "Learning to Stop Overthinking at Test Time",
      "title_zh": "翻译失败",
      "authors": [
        "Hieu Tran Bao",
        "Nguyen Cong Dat",
        "Nguyen Duc Anh",
        "Hoang Thanh-Tung"
      ],
      "abstract": "Test time scaling is currently one of the most active research areas that\nshows promise after training time scaling has reached its limits. Deep-thinking\n(DT) models are a class of recurrent models that can perform easy-to-hard\ngeneralization by assigning more compute to harder test samples. However, due\nto their inability to determine the complexity of a test sample, DT models have\nto use a large amount of computation for both easy and hard test samples.\nExcessive test time computation is wasteful and can cause the ``overthinking''\nproblem where more test time computation leads to worse results. In this paper,\nwe introduce a test time training method for determining the optimal amount of\ncomputation needed for each sample during test time. We also propose\nConv-LiGRU, a novel recurrent architecture for efficient and robust visual\nreasoning. Extensive experiments demonstrate that Conv-LiGRU is more stable\nthan DT, effectively mitigates the ``overthinking'' phenomenon, and achieves\nsuperior accuracy.",
      "tldr_zh": "该论文探讨测试时间缩放（test time scaling）中的“overthinking”问题，即Deep-thinking (DT) 模型因无法评估样本复杂度而对简单和复杂样本过度计算，导致性能下降。作者提出一种测试时间训练方法，用于动态确定每个测试样本所需的最优计算量，以提高计算效率。论文同时引入Conv-LiGRU，一种新型递归架构，设计用于高效和鲁棒的视觉推理。实验结果表明，Conv-LiGRU 比DT 模型更稳定，有效缓解“overthinking”问题，并实现更高的准确率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10954v2",
      "published_date": "2025-02-16 02:17:05 UTC",
      "updated_date": "2025-02-18 03:41:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:16:31.139992"
    },
    {
      "arxiv_id": "2502.10953v1",
      "title": "Empirical evaluation of LLMs in predicting fixes of Configuration bugs in Smart Home System",
      "title_zh": "翻译失败",
      "authors": [
        "Sheikh Moonwara Anjum Monisha",
        "Atul Bharadwaj"
      ],
      "abstract": "This empirical study evaluates the effectiveness of Large Language Models\n(LLMs) in predicting fixes for configuration bugs in smart home systems. The\nresearch analyzes three prominent LLMs - GPT-4, GPT-4o (GPT-4 Turbo), and\nClaude 3.5 Sonnet - using four distinct prompt designs to assess their ability\nto identify appropriate fix strategies and generate correct solutions. The\nstudy utilized a dataset of 129 debugging issues from the Home Assistant\nCommunity, focusing on 21 randomly selected cases for in-depth analysis.\nResults demonstrate that GPT-4 and Claude 3.5 Sonnet achieved 80\\% accuracy in\nstrategy prediction when provided with both bug descriptions and original\nscripts. GPT-4 exhibited consistent performance across different prompt types,\nwhile GPT-4o showed advantages in speed and cost-effectiveness despite slightly\nlower accuracy. The findings reveal that prompt design significantly impacts\nmodel performance, with comprehensive prompts containing both description and\noriginal script yielding the best results. This research provides valuable\ninsights for improving automated bug fixing in smart home system configurations\nand demonstrates the potential of LLMs in addressing configuration-related\nchallenges.",
      "tldr_zh": "本研究实证评估了大型语言模型 (LLMs) 在预测智能家居系统配置 bug 修复方面的有效性，测试了 GPT-4、GPT-4o (GPT-4 Turbo) 和 Claude 3.5 Sonnet 三种模型，并采用了四种不同的 prompt designs。研究基于 Home Assistant Community 的 129 个调试问题数据集，随机选取 21 个案例进行深入分析。结果显示，GPT-4 和 Claude 3.5 Sonnet 在提供 bug 描述和原始脚本的提示下，策略预测准确率达到 80%，而 GPT-4o 则在速度和成本效益上表现出优势。总体而言，该研究强调了 prompt designs 对模型性能的重大影响，并为智能家居系统的自动化 bug 修复提供了重要见解。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10953v1",
      "published_date": "2025-02-16 02:11:36 UTC",
      "updated_date": "2025-02-16 02:11:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:16:44.338108"
    },
    {
      "arxiv_id": "2502.10940v2",
      "title": "CoLA: Compute-Efficient Pre-Training of LLMs via Low-Rank Activation",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyue Liu",
        "Ruijie Zhang",
        "Zhengyang Wang",
        "Zi Yang",
        "Paul Hovland",
        "Bogdan Nicolae",
        "Franck Cappello",
        "Zheng Zhang"
      ],
      "abstract": "The full-size MLPs and the projection layers in attention introduce\ntremendous model sizes of large language models (LLMs), imposing extremely\ndemanding needs of computational resources in the pre-training stage. However,\nwe empirically observe that the activations of pre-trained LLMs exhibit\nlow-rank property. Motivated by such observations, we propose CoLA and its\nmemory-efficient implementation, CoLA-M, to replace these full-size layers with\ncompute-efficient auto-encoders that naturally enforce low-rank activations\nthroughout training. This fundamental architectural change eliminates the\nactivation redundancy and significantly boosts model capacity and training\nefficiency. Experiments on LLaMA models with 60 million to 7 billion parameters\nshow that CoLA reduces the computing cost by $\\bf 2\\pmb{\\times}$ and improves\ntraining throughput by $\\bf 1.86\\pmb{\\times}$ while maintaining full-rank level\nperformance. CoLA-M further squeezes memory cost without sacrificing\nthroughput, offering a pre-training approach with collectively superior\nparameter, computing, and memory efficiency. The LLMs produced are also $\\bf\n2\\pmb{\\times}$ smaller, enabling faster inference with lower memory cost on\nresource-constrained platforms.",
      "tldr_zh": "该研究观察到大型语言模型(LLMs)中全尺寸 MLP 和注意力投影层导致模型庞大，预训练计算资源需求极高，同时激活显示低秩属性。为此，提出 CoLA 方法及其内存高效版本 CoLA-M，通过使用计算高效的自动编码器替换这些层，强制激活保持低秩，从而消除冗余并提升模型容量和训练效率。在 LLaMA 模型（从 60 百万到 70 亿参数）的实验中，CoLA 将计算成本降低 2 倍，提高训练吞吐量 1.86 倍，同时保持与全秩相当的性能。CoLA-M 进一步减少内存开销而不影响吞吐量，最终生成的 LLMs 体积缩小 2 倍，支持更快的推理和更低的内存需求。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "v2",
      "pdf_url": "http://arxiv.org/pdf/2502.10940v2",
      "published_date": "2025-02-16 01:05:16 UTC",
      "updated_date": "2025-05-20 16:27:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:16:55.071087"
    },
    {
      "arxiv_id": "2502.12198v1",
      "title": "Maximize Your Diffusion: A Study into Reward Maximization and Alignment for Diffusion-based Control",
      "title_zh": "翻译失败",
      "authors": [
        "Dom Huh",
        "Prasant Mohapatra"
      ],
      "abstract": "Diffusion-based planning, learning, and control methods present a promising\nbranch of powerful and expressive decision-making solutions. Given the growing\ninterest, such methods have undergone numerous refinements over the past years.\nHowever, despite these advancements, existing methods are limited in their\ninvestigations regarding general methods for reward maximization within the\ndecision-making process. In this work, we study extensions of fine-tuning\napproaches for control applications. Specifically, we explore extensions and\nvarious design choices for four fine-tuning approaches: reward alignment\nthrough reinforcement learning, direct preference optimization, supervised\nfine-tuning, and cascading diffusion. We optimize their usage to merge these\nindependent efforts into one unified paradigm. We show the utility of such\npropositions in offline RL settings and demonstrate empirical improvements over\na rich array of control tasks.",
      "tldr_zh": "本研究探讨了在Diffusion-based Control中奖励最大化和对齐的扩展，旨在提升决策过程的效率。\n作者优化了四种微调方法，包括通过Reinforcement Learning的奖励对齐、Direct Preference Optimization、Supervised Fine-Tuning和Cascading Diffusion，并将它们整合到一个统一的范式中。\n实验结果表明，这些方法在离线RL设置中实现了显著改进，并在多种控制任务上取得了经验性提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.12198v1",
      "published_date": "2025-02-16 00:30:39 UTC",
      "updated_date": "2025-02-16 00:30:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:17:06.791583"
    },
    {
      "arxiv_id": "2502.10938v1",
      "title": "PEA: Enhancing LLM Performance on Computational-Reasoning Tasks",
      "title_zh": "PEA：提升 LLM 在计算推理任务上的性能",
      "authors": [
        "Zi Wang",
        "Shiwei Weng",
        "Mohannad Alhanahnah",
        "Somesh Jha",
        "Tom Reps"
      ],
      "abstract": "Large Language Models (LLMs) have exhibited remarkable capabilities across\ndiverse domains, prompting investigations into their potential as generic\nreasoning engines. While recent studies have explored inference-time\ncomputation to enhance model performance on complex problems, current research\nlacks a formal framework to characterize the complexity of reasoning tasks.\nThis study introduces the Predicate-Enumeration-Aggregation (PEA) framework, a\nformal approach to describe and solve a class of important reasoning tasks\ntermed computational reasoning problems. The PEA framework decomposes these\nproblems into predicate and enumeration components, using LLMs to synthesize\nprograms based on specified predicates, enumeration, and aggregation rules.\nThese synthesized programs are then executed to obtain solutions to the\ncomputational tasks. We demonstrate the framework's efficacy on benchmark tasks\nincluding Boolean satisfiability problems, game of $24$, and planning problems.\nEmpirical evaluation reveals that PEA substantially enhances the performance of\nunderlying models on benchmark computational problems, yielding an average\naccuracy improvement of approximately $50\\%$, coupled with increased\nefficiency.",
      "tldr_zh": "本文提出 PEA 框架（Predicate-Enumeration-Aggregation），一种正式方法，用于提升大型语言模型（LLMs）在计算推理任务上的性能，通过解决当前研究中缺乏表征任务复杂性的问题。PEA 将计算推理问题分解为谓词和枚举组件，利用 LLMs 合成基于指定谓词、枚举和聚合规则的程序，并执行这些程序来获得解决方案。在基准任务如 Boolean satisfiability problems、game of 24 和规划问题上，实验结果显示 PEA 使底层模型的平均准确率提高了约 50%，并显著提高了效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10938v1",
      "published_date": "2025-02-16 00:27:05 UTC",
      "updated_date": "2025-02-16 00:27:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:17:19.019856"
    },
    {
      "arxiv_id": "2502.10937v1",
      "title": "SCALE: Towards Collaborative Content Analysis in Social Science with Large Language Model Agents and Human Intervention",
      "title_zh": "翻译失败",
      "authors": [
        "Chengshuai Zhao",
        "Zhen Tan",
        "Chau-Wai Wong",
        "Xinyan Zhao",
        "Tianlong Chen",
        "Huan Liu"
      ],
      "abstract": "Content analysis breaks down complex and unstructured texts into\ntheory-informed numerical categories. Particularly, in social science, this\nprocess usually relies on multiple rounds of manual annotation, domain expert\ndiscussion, and rule-based refinement. In this paper, we introduce SCALE, a\nnovel multi-agent framework that effectively $\\underline{\\textbf{S}}$imulates\n$\\underline{\\textbf{C}}$ontent $\\underline{\\textbf{A}}$nalysis via\n$\\underline{\\textbf{L}}$arge language model (LLM)\nag$\\underline{\\textbf{E}}$nts. SCALE imitates key phases of content analysis,\nincluding text coding, collaborative discussion, and dynamic codebook\nevolution, capturing the reflective depth and adaptive discussions of human\nresearchers. Furthermore, by integrating diverse modes of human intervention,\nSCALE is augmented with expert input to further enhance its performance.\nExtensive evaluations on real-world datasets demonstrate that SCALE achieves\nhuman-approximated performance across various complex content analysis tasks,\noffering an innovative potential for future social science research.",
      "tldr_zh": "论文提出SCALE框架，一种基于Large Language Model (LLM)代理的多智能体系统，旨在模拟社会科学的协作内容分析过程，包括文本编码、协作讨论和动态代码本演化，以捕捉人类研究者的反思深度和适应性。SCALE通过整合多种人类干预方式，进一步提升其性能和准确性。在真实数据集上的广泛评估表明，该框架在复杂任务中达到了接近人类的表现，为未来社会科学研究提供了创新潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10937v1",
      "published_date": "2025-02-16 00:19:07 UTC",
      "updated_date": "2025-02-16 00:19:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T12:17:30.067758"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 105,
  "processed_papers_count": 105,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T12:17:49.730681"
}