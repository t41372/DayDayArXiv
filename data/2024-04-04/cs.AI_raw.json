[
  {
    "arxiv_id": "2404.03838v2",
    "title": "A Block-Coordinate Descent EMO Algorithm: Theoretical and Empirical Analysis",
    "authors": [
      "Benjamin Doerr",
      "Joshua Knowles",
      "Aneta Neumann",
      "Frank Neumann"
    ],
    "abstract": "We consider whether conditions exist under which block-coordinate descent is\nasymptotically efficient in evolutionary multi-objective optimization,\naddressing an open problem. Block-coordinate descent, where an optimization\nproblem is decomposed into $k$ blocks of decision variables and each of the\nblocks is optimized (with the others fixed) in a sequence, is a technique used\nin some large-scale optimization problems such as airline scheduling, however\nits use in multi-objective optimization is less studied. We propose a\nblock-coordinate version of GSEMO and compare its running time to the standard\nGSEMO algorithm. Theoretical and empirical results on a bi-objective test\nfunction, a variant of LOTZ, serve to demonstrate the existence of cases where\nblock-coordinate descent is faster. The result may yield wider insights into\nthis class of algorithms.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted at GECCO 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.03838v2",
    "published_date": "2024-04-04 23:50:18 UTC",
    "updated_date": "2024-04-11 00:13:05 UTC"
  },
  {
    "arxiv_id": "2404.03836v1",
    "title": "PARIS3D: Reasoning-based 3D Part Segmentation Using Large Multimodal Model",
    "authors": [
      "Amrin Kareem",
      "Jean Lahoud",
      "Hisham Cholakkal"
    ],
    "abstract": "Recent advancements in 3D perception systems have significantly improved\ntheir ability to perform visual recognition tasks such as segmentation.\nHowever, these systems still heavily rely on explicit human instruction to\nidentify target objects or categories, lacking the capability to actively\nreason and comprehend implicit user intentions. We introduce a novel\nsegmentation task known as reasoning part segmentation for 3D objects, aiming\nto output a segmentation mask based on complex and implicit textual queries\nabout specific parts of a 3D object. To facilitate evaluation and benchmarking,\nwe present a large 3D dataset comprising over 60k instructions paired with\ncorresponding ground-truth part segmentation annotations specifically curated\nfor reasoning-based 3D part segmentation. We propose a model that is capable of\nsegmenting parts of 3D objects based on implicit textual queries and generating\nnatural language explanations corresponding to 3D object segmentation requests.\nExperiments show that our method achieves competitive performance to models\nthat use explicit queries, with the additional abilities to identify part\nconcepts, reason about them, and complement them with world knowledge. Our\nsource code, dataset, and trained models are available at\nhttps://github.com/AmrinKareem/PARIS3D.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.03836v1",
    "published_date": "2024-04-04 23:38:45 UTC",
    "updated_date": "2024-04-04 23:38:45 UTC"
  },
  {
    "arxiv_id": "2404.03830v2",
    "title": "BiSHop: Bi-Directional Cellular Learning for Tabular Data with Generalized Sparse Modern Hopfield Model",
    "authors": [
      "Chenwei Xu",
      "Yu-Chao Huang",
      "Jerry Yao-Chieh Hu",
      "Weijian Li",
      "Ammar Gilani",
      "Hsi-Sheng Goan",
      "Han Liu"
    ],
    "abstract": "We introduce the \\textbf{B}i-Directional \\textbf{S}parse \\textbf{Hop}field\nNetwork (\\textbf{BiSHop}), a novel end-to-end framework for deep tabular\nlearning. BiSHop handles the two major challenges of deep tabular learning:\nnon-rotationally invariant data structure and feature sparsity in tabular data.\nOur key motivation comes from the recent established connection between\nassociative memory and attention mechanisms. Consequently, BiSHop uses a\ndual-component approach, sequentially processing data both column-wise and\nrow-wise through two interconnected directional learning modules.\nComputationally, these modules house layers of generalized sparse modern\nHopfield layers, a sparse extension of the modern Hopfield model with adaptable\nsparsity. Methodologically, BiSHop facilitates multi-scale representation\nlearning, capturing both intra-feature and inter-feature interactions, with\nadaptive sparsity at each scale. Empirically, through experiments on diverse\nreal-world datasets, we demonstrate that BiSHop surpasses current SOTA methods\nwith significantly less HPO runs, marking it a robust solution for deep tabular\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "31 pages; Code available at https://github.com/MAGICS-LAB/BiSHop",
    "pdf_url": "http://arxiv.org/pdf/2404.03830v2",
    "published_date": "2024-04-04 23:13:32 UTC",
    "updated_date": "2024-07-12 22:45:41 UTC"
  },
  {
    "arxiv_id": "2404.03828v2",
    "title": "Outlier-Efficient Hopfield Layers for Large Transformer-Based Models",
    "authors": [
      "Jerry Yao-Chieh Hu",
      "Pei-Hsuan Chang",
      "Robin Luo",
      "Hong-Yu Chen",
      "Weijian Li",
      "Wei-Po Wang",
      "Han Liu"
    ],
    "abstract": "We introduce an Outlier-Efficient Modern Hopfield Model (termed\n$\\mathrm{OutEffHop}$) and use it to address the outlier inefficiency problem of\n{training} gigantic transformer-based models. Our main contribution is a novel\nassociative memory model facilitating \\textit{outlier-efficient} associative\nmemory retrievals. Interestingly, this memory model manifests a model-based\ninterpretation of an outlier-efficient attention mechanism (${\\rm Softmax}_1$):\nit is an approximation of the memory retrieval process of $\\mathrm{OutEffHop}$.\nMethodologically, this allows us to introduce novel outlier-efficient Hopfield\nlayers as powerful alternatives to traditional attention mechanisms, with\nsuperior post-quantization performance. Theoretically, the Outlier-Efficient\nModern Hopfield Model retains and improves the desirable properties of standard\nmodern Hopfield models, including fixed point convergence and exponential\nstorage capacity. Empirically, we demonstrate the efficacy of the proposed\nmodel across large-scale transformer-based and Hopfield-based models (including\nBERT, OPT, ViT, and STanHop-Net), benchmarking against state-of-the-art methods\nlike $\\mathtt{Clipped\\_Softmax}$ and $\\mathtt{Gated\\_Attention}$. Notably,\n$\\mathrm{OutEffHop}$ achieves an average reduction of 22+\\% in average kurtosis\nand 26+\\% in the maximum infinity norm of model outputs across four models.\nCode is available at \\href{https://github.com/MAGICS-LAB/OutEffHop}{GitHub};\nmodels are on\n\\href{https://huggingface.co/collections/magicslabnu/outeffhop-6610fcede8d2cda23009a98f}{Hugging\nFace Hub}; future updates are on\n\\href{https://arxiv.org/abs/2404.03828}{arXiv}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML 2024; v2 updated to camera-ready version; Code\n  available at https://github.com/MAGICS-LAB/OutEffHop; Models are on Hugging\n  Face:\n  https://huggingface.co/collections/magicslabnu/outeffhop-6610fcede8d2cda23009a98f",
    "pdf_url": "http://arxiv.org/pdf/2404.03828v2",
    "published_date": "2024-04-04 23:08:43 UTC",
    "updated_date": "2024-06-26 20:50:18 UTC"
  },
  {
    "arxiv_id": "2404.03827v3",
    "title": "Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models",
    "authors": [
      "Dennis Wu",
      "Jerry Yao-Chieh Hu",
      "Teng-Yun Hsiao",
      "Han Liu"
    ],
    "abstract": "We propose a two-stage memory retrieval dynamics for modern Hopfield models,\ntermed $\\mathtt{U\\text{-}Hop}$, with enhanced memory capacity. Our key\ncontribution is a learnable feature map $\\Phi$ which transforms the Hopfield\nenergy function into kernel space. This transformation ensures convergence\nbetween the local minima of energy and the fixed points of retrieval dynamics\nwithin the kernel space. Consequently, the kernel norm induced by $\\Phi$ serves\nas a novel similarity measure. It utilizes the stored memory patterns as\nlearning data to enhance memory capacity across all modern Hopfield models.\nSpecifically, we accomplish this by constructing a separation loss\n$\\mathcal{L}_\\Phi$ that separates the local minima of kernelized energy by\nseparating stored memory patterns in kernel space. Methodologically,\n$\\mathtt{U\\text{-}Hop}$ memory retrieval process consists of: (Stage I)\nminimizing separation loss for a more uniform memory (local minimum)\ndistribution, followed by (Stage II) standard Hopfield energy minimization for\nmemory retrieval. This results in a significant reduction of possible\nmetastable states in the Hopfield energy function, thus enhancing memory\ncapacity by preventing memory confusion. Empirically, with real-world datasets,\nwe demonstrate that $\\mathtt{U\\text{-}Hop}$ outperforms all existing modern\nHopfield models and state-of-the-art similarity measures, achieving substantial\nimprovements in both associative memory retrieval and deep learning tasks. Code\nis available at https://github.com/MAGICS-LAB/UHop ; future updates are on\narXiv:2404.03827",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML 2024; v3 added a note on follow-up UHop+\n  (arXiv:2410.23126); v2 updated to camera-ready version; Code available at\n  https://github.com/MAGICS-LAB/UHop",
    "pdf_url": "http://arxiv.org/pdf/2404.03827v3",
    "published_date": "2024-04-04 23:05:30 UTC",
    "updated_date": "2024-11-10 19:25:40 UTC"
  },
  {
    "arxiv_id": "2404.04302v1",
    "title": "CBR-RAG: Case-Based Reasoning for Retrieval Augmented Generation in LLMs for Legal Question Answering",
    "authors": [
      "Nirmalie Wiratunga",
      "Ramitha Abeyratne",
      "Lasal Jayawardena",
      "Kyle Martin",
      "Stewart Massie",
      "Ikechukwu Nkisi-Orji",
      "Ruvan Weerasinghe",
      "Anne Liret",
      "Bruno Fleisch"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) enhances Large Language Model (LLM)\noutput by providing prior knowledge as context to input. This is beneficial for\nknowledge-intensive and expert reliant tasks, including legal\nquestion-answering, which require evidence to validate generated text outputs.\nWe highlight that Case-Based Reasoning (CBR) presents key opportunities to\nstructure retrieval as part of the RAG process in an LLM. We introduce CBR-RAG,\nwhere CBR cycle's initial retrieval stage, its indexing vocabulary, and\nsimilarity knowledge containers are used to enhance LLM queries with\ncontextually relevant cases. This integration augments the original LLM query,\nproviding a richer prompt. We present an evaluation of CBR-RAG, and examine\ndifferent representations (i.e. general and domain-specific embeddings) and\nmethods of comparison (i.e. inter, intra and hybrid similarity) on the task of\nlegal question-answering. Our results indicate that the context provided by\nCBR's case reuse enforces similarity between relevant components of the\nquestions and the evidence base leading to significant improvements in the\nquality of generated answers.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to ICCBR'24",
    "pdf_url": "http://arxiv.org/pdf/2404.04302v1",
    "published_date": "2024-04-04 21:47:43 UTC",
    "updated_date": "2024-04-04 21:47:43 UTC"
  },
  {
    "arxiv_id": "2404.04299v1",
    "title": "GENEVIC: GENetic data Exploration and Visualization via Intelligent interactive Console",
    "authors": [
      "Anindita Nath",
      "Savannah Mwesigwa",
      "Yulin Dai",
      "Xiaoqian Jiang",
      "Zhongming Zhao"
    ],
    "abstract": "Summary: The vast generation of genetic data poses a significant challenge in\nefficiently uncovering valuable knowledge. Introducing GENEVIC, an AI-driven\nchat framework that tackles this challenge by bridging the gap between genetic\ndata generation and biomedical knowledge discovery. Leveraging generative AI,\nnotably ChatGPT, it serves as a biologist's 'copilot'. It automates the\nanalysis, retrieval, and visualization of customized domain-specific genetic\ninformation, and integrates functionalities to generate protein interaction\nnetworks, enrich gene sets, and search scientific literature from PubMed,\nGoogle Scholar, and arXiv, making it a comprehensive tool for biomedical\nresearch. In its pilot phase, GENEVIC is assessed using a curated database that\nranks genetic variants associated with Alzheimer's disease, schizophrenia, and\ncognition, based on their effect weights from the Polygenic Score Catalog, thus\nenabling researchers to prioritize genetic variants in complex diseases.\nGENEVIC's operation is user-friendly, accessible without any specialized\ntraining, secured by Azure OpenAI's HIPAA-compliant infrastructure, and\nevaluated for its efficacy through real-time query testing. As a prototype,\nGENEVIC is set to advance genetic research, enabling informed biomedical\ndecisions.\n  Availability and implementation: GENEVIC is publicly accessible at\nhttps://genevic-anath2024.streamlit.app. The underlying code is open-source and\navailable via GitHub at https://github.com/anath2110/GENEVIC.git.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04299v1",
    "published_date": "2024-04-04 20:53:30 UTC",
    "updated_date": "2024-04-04 20:53:30 UTC"
  },
  {
    "arxiv_id": "2404.03799v2",
    "title": "Language-Guided Instance-Aware Domain-Adaptive Panoptic Segmentation",
    "authors": [
      "Elham Amin Mansour",
      "Ozan Unal",
      "Suman Saha",
      "Benjamin Bejar",
      "Luc Van Gool"
    ],
    "abstract": "The increasing relevance of panoptic segmentation is tied to the advancements\nin autonomous driving and AR/VR applications. However, the deployment of such\nmodels has been limited due to the expensive nature of dense data annotation,\ngiving rise to unsupervised domain adaptation (UDA). A key challenge in\npanoptic UDA is reducing the domain gap between a labeled source and an\nunlabeled target domain while harmonizing the subtasks of semantic and instance\nsegmentation to limit catastrophic interference. While considerable progress\nhas been achieved, existing approaches mainly focus on the adaptation of\nsemantic segmentation. In this work, we focus on incorporating instance-level\nadaptation via a novel instance-aware cross-domain mixing strategy IMix. IMix\nsignificantly enhances the panoptic quality by improving instance segmentation\nperformance. Specifically, we propose inserting high-confidence predicted\ninstances from the target domain onto source images, retaining the\nexhaustiveness of the resulting pseudo-labels while reducing the injected\nconfirmation bias. Nevertheless, such an enhancement comes at the cost of\ndegraded semantic performance, attributed to catastrophic forgetting. To\nmitigate this issue, we regularize our semantic branch by employing CLIP-based\ndomain alignment (CDA), exploiting the domain-robustness of natural language\nprompts. Finally, we present an end-to-end model incorporating these two\nmechanisms called LIDAPS, achieving state-of-the-art results on all popular\npanoptic UDA benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at the 2025 IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV)",
    "pdf_url": "http://arxiv.org/pdf/2404.03799v2",
    "published_date": "2024-04-04 20:42:49 UTC",
    "updated_date": "2024-12-25 23:27:36 UTC"
  },
  {
    "arxiv_id": "2404.04298v3",
    "title": "SELF-[IN]CORRECT: LLMs Struggle with Discriminating Self-Generated Responses",
    "authors": [
      "Dongwei Jiang",
      "Jingyu Zhang",
      "Orion Weller",
      "Nathaniel Weir",
      "Benjamin Van Durme",
      "Daniel Khashabi"
    ],
    "abstract": "Can LLMs consistently improve their previous outputs for better results? For\nthis to be true, LLMs would need to be better at discriminating among\npreviously-generated alternatives, than generating initial responses. We\nexplore the validity of this hypothesis in practice. We first formulate a\nunified framework that allows us to compare the generative and discriminative\ncapability of any model on any task. In our resulting experimental analysis of\nseveral open-source and industrial LLMs, we observe that models are not\nreliably better at discriminating among previously-generated alternatives than\ngenerating initial responses. This finding challenges the notion that LLMs may\nbe able to enhance their performance only through their own judgment.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04298v3",
    "published_date": "2024-04-04 20:27:37 UTC",
    "updated_date": "2024-09-06 01:14:26 UTC"
  },
  {
    "arxiv_id": "2405.14880v4",
    "title": "Dissecting Query-Key Interaction in Vision Transformers",
    "authors": [
      "Xu Pan",
      "Aaron Philip",
      "Ziqian Xie",
      "Odelia Schwartz"
    ],
    "abstract": "Self-attention in vision transformers is often thought to perform perceptual\ngrouping where tokens attend to other tokens with similar embeddings, which\ncould correspond to semantically similar features of an object. However,\nattending to dissimilar tokens can be beneficial by providing contextual\ninformation. We propose to analyze the query-key interaction by the singular\nvalue decomposition of the interaction matrix (i.e.\n${\\textbf{W}_q}^\\top\\textbf{W}_k$). We find that in many ViTs, especially those\nwith classification training objectives, early layers attend more to similar\ntokens, while late layers show increased attention to dissimilar tokens,\nproviding evidence corresponding to perceptual grouping and contextualization,\nrespectively. Many of these interactions between features represented by\nsingular vectors are interpretable and semantic, such as attention between\nrelevant objects, between parts of an object, or between the foreground and\nbackground. This offers a novel perspective on interpreting the attention\nmechanism, which contributes to understanding how transformer models utilize\ncontext and salient features when processing images.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14880v4",
    "published_date": "2024-04-04 20:06:07 UTC",
    "updated_date": "2025-01-14 01:57:44 UTC"
  },
  {
    "arxiv_id": "2404.03789v1",
    "title": "Quantifying Uncertainty in Motion Prediction with Variational Bayesian Mixture",
    "authors": [
      "Juanwu Lu",
      "Can Cui",
      "Yunsheng Ma",
      "Aniket Bera",
      "Ziran Wang"
    ],
    "abstract": "Safety and robustness are crucial factors in developing trustworthy\nautonomous vehicles. One essential aspect of addressing these factors is to\nequip vehicles with the capability to predict future trajectories for all\nmoving objects in the surroundings and quantify prediction uncertainties. In\nthis paper, we propose the Sequential Neural Variational Agent (SeNeVA), a\ngenerative model that describes the distribution of future trajectories for a\nsingle moving object. Our approach can distinguish Out-of-Distribution data\nwhile quantifying uncertainty and achieving competitive performance compared to\nstate-of-the-art methods on the Argoverse 2 and INTERACTION datasets.\nSpecifically, a 0.446 meters minimum Final Displacement Error, a 0.203 meters\nminimum Average Displacement Error, and a 5.35% Miss Rate are achieved on the\nINTERACTION test set. Extensive qualitative and quantitative analysis is also\nprovided to evaluate the proposed model. Our open-source code is available at\nhttps://github.com/PurdueDigitalTwin/seneva.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.03789v1",
    "published_date": "2024-04-04 20:04:12 UTC",
    "updated_date": "2024-04-04 20:04:12 UTC"
  },
  {
    "arxiv_id": "2404.03784v2",
    "title": "A Layer Selection Approach to Test Time Adaptation",
    "authors": [
      "Sabyasachi Sahoo",
      "Mostafa ElAraby",
      "Jonas Ngnawe",
      "Yann Pequignot",
      "Frederic Precioso",
      "Christian Gagne"
    ],
    "abstract": "Test Time Adaptation (TTA) addresses the problem of distribution shift by\nadapting a pretrained model to a new domain during inference. When faced with\nchallenging shifts, most methods collapse and perform worse than the original\npretrained model. In this paper, we find that not all layers are equally\nreceptive to the adaptation, and the layers with the most misaligned gradients\noften cause performance degradation. To address this, we propose GALA, a novel\nlayer selection criterion to identify the most beneficial updates to perform\nduring test time adaptation. This criterion can also filter out unreliable\nsamples with noisy gradients. Its simplicity allows seamless integration with\nexisting TTA loss functions, thereby preventing degradation and focusing\nadaptation on the most trainable layers. This approach also helps to regularize\nadaptation to preserve the pretrained features, which are crucial for handling\nunseen domains. Through extensive experiments, we demonstrate that the proposed\nlayer selection framework improves the performance of existing TTA approaches\nacross multiple datasets, domain shifts, model architectures, and TTA losses.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 8 figures, Accepted at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2404.03784v2",
    "published_date": "2024-04-04 19:55:11 UTC",
    "updated_date": "2025-02-23 15:31:49 UTC"
  },
  {
    "arxiv_id": "2404.03775v1",
    "title": "A Systems Theoretic Approach to Online Machine Learning",
    "authors": [
      "Anli du Preez",
      "Peter A. Beling",
      "Tyler Cody"
    ],
    "abstract": "The machine learning formulation of online learning is incomplete from a\nsystems theoretic perspective. Typically, machine learning research emphasizes\ndomains and tasks, and a problem solving worldview. It focuses on algorithm\nparameters, features, and samples, and neglects the perspective offered by\nconsidering system structure and system behavior or dynamics. Online learning\nis an active field of research and has been widely explored in terms of\nstatistical theory and computational algorithms, however, in general, the\nliterature still lacks formal system theoretical frameworks for modeling online\nlearning systems and resolving systems-related concept drift issues.\nFurthermore, while the machine learning formulation serves to classify methods\nand literature, the systems theoretic formulation presented herein serves to\nprovide a framework for the top-down design of online learning systems,\nincluding a novel definition of online learning and the identification of key\ndesign parameters. The framework is formulated in terms of input-output systems\nand is further divided into system structure and system behavior. Concept drift\nis a critical challenge faced in online learning, and this work formally\napproaches it as part of the system behavior characteristics. Healthcare\nprovider fraud detection using machine learning is used as a case study\nthroughout the paper to ground the discussion in a real-world online learning\nchallenge.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the 18th Annual IEEE International Systems Conference\n  (SysCon)",
    "pdf_url": "http://arxiv.org/pdf/2404.03775v1",
    "published_date": "2024-04-04 19:36:47 UTC",
    "updated_date": "2024-04-04 19:36:47 UTC"
  },
  {
    "arxiv_id": "2404.03753v2",
    "title": "A Reinforcement Learning based Reset Policy for CDCL SAT Solvers",
    "authors": [
      "Chunxiao Li",
      "Charlie Liu",
      "Jonathan Chung",
      "Zhengyang Lu",
      "Piyush Jha",
      "Vijay Ganesh"
    ],
    "abstract": "Restart policy is an important technique used in modern Conflict-Driven\nClause Learning (CDCL) solvers, wherein some parts of the solver state are\nerased at certain intervals during the run of the solver. In most solvers,\nvariable activities are preserved across restart boundaries, resulting in\nsolvers continuing to search parts of the assignment tree that are not far from\nthe one immediately prior to a restart. To enable the solver to search possibly\n\"distant\" parts of the assignment tree, we study the effect of resets, a\nvariant of restarts which not only erases the assignment trail, but also\nrandomizes the activity scores of the variables of the input formula after\nreset, thus potentially enabling a better global exploration of the search\nspace.\n  In this paper, we model the problem of whether to trigger reset as a\nmulti-armed bandit (MAB) problem, and propose two reinforcement learning (RL)\nbased adaptive reset policies using the Upper Confidence Bound (UCB) and\nThompson sampling algorithms. These two algorithms balance the\nexploration-exploitation tradeoff by adaptively choosing arms (reset vs. no\nreset) based on their estimated rewards during the solver's run. We implement\nour reset policies in four baseline SOTA CDCL solvers and compare the baselines\nagainst the reset versions on Satcoin benchmarks and SAT Competition instances.\nOur results show that RL-based reset versions outperform the corresponding\nbaseline solvers on both Satcoin and the SAT competition instances, suggesting\nthat our RL policy helps to dynamically and profitably adapt the reset\nfrequency for any given input instance. We also introduce the concept of a\npartial reset, where at least a constant number of variable activities are\nretained across reset boundaries. Building on previous results, we show that\nthere is an exponential separation between O(1) vs. $\\Omega(n)$-length partial\nresets.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03753v2",
    "published_date": "2024-04-04 18:44:33 UTC",
    "updated_date": "2024-04-19 19:56:29 UTC"
  },
  {
    "arxiv_id": "2404.03746v1",
    "title": "GenQREnsemble: Zero-Shot LLM Ensemble Prompting for Generative Query Reformulation",
    "authors": [
      "Kaustubh Dhole",
      "Eugene Agichtein"
    ],
    "abstract": "Query Reformulation(QR) is a set of techniques used to transform a user's\noriginal search query to a text that better aligns with the user's intent and\nimproves their search experience. Recently, zero-shot QR has been shown to be a\npromising approach due to its ability to exploit knowledge inherent in large\nlanguage models. By taking inspiration from the success of ensemble prompting\nstrategies which have benefited many tasks, we investigate if they can help\nimprove query reformulation. In this context, we propose an ensemble based\nprompting technique, GenQREnsemble which leverages paraphrases of a zero-shot\ninstruction to generate multiple sets of keywords ultimately improving\nretrieval performance. We further introduce its post-retrieval variant,\nGenQREnsembleRF to incorporate pseudo relevant feedback. On evaluations over\nfour IR benchmarks, we find that GenQREnsemble generates better reformulations\nwith relative nDCG@10 improvements up to 18% and MAP improvements upto 24% over\nthe previous zero-shot state-of-art. On the MSMarco Passage Ranking task,\nGenQREnsembleRF shows relative gains of 5% MRR using pseudo-relevance feedback,\nand 9% nDCG@10 using relevant feedback documents.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted at ECIR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.03746v1",
    "published_date": "2024-04-04 18:35:25 UTC",
    "updated_date": "2024-04-04 18:35:25 UTC"
  },
  {
    "arxiv_id": "2404.03745v3",
    "title": "Fakes of Varying Shades: How Warning Affects Human Perception and Engagement Regarding LLM Hallucinations",
    "authors": [
      "Mahjabin Nahar",
      "Haeseung Seo",
      "Eun-Ju Lee",
      "Aiping Xiong",
      "Dongwon Lee"
    ],
    "abstract": "The widespread adoption and transformative effects of large language models\n(LLMs) have sparked concerns regarding their capacity to produce inaccurate and\nfictitious content, referred to as `hallucinations'. Given the potential risks\nassociated with hallucinations, humans should be able to identify them. This\nresearch aims to understand the human perception of LLM hallucinations by\nsystematically varying the degree of hallucination (genuine, minor\nhallucination, major hallucination) and examining its interaction with warning\n(i.e., a warning of potential inaccuracies: absent vs. present). Participants\n(N=419) from Prolific rated the perceived accuracy and engaged with content\n(e.g., like, dislike, share) in a Q/A format. Participants ranked content as\ntruthful in the order of genuine, minor hallucination, and major hallucination,\nand user engagement behaviors mirrored this pattern. More importantly, we\nobserved that warning improved the detection of hallucination without\nsignificantly affecting the perceived truthfulness of genuine content. We\nconclude by offering insights for future tools to aid human detection of\nhallucinations. All survey materials, demographic questions, and post-session\nquestions are available at:\nhttps://github.com/MahjabinNahar/fakes-of-varying-shades-survey-materials",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted at COLM 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.03745v3",
    "published_date": "2024-04-04 18:34:32 UTC",
    "updated_date": "2024-08-12 14:13:15 UTC"
  },
  {
    "arxiv_id": "2404.03732v1",
    "title": "SHROOM-INDElab at SemEval-2024 Task 6: Zero- and Few-Shot LLM-Based Classification for Hallucination Detection",
    "authors": [
      "Bradley P. Allen",
      "Fina Polat",
      "Paul Groth"
    ],
    "abstract": "We describe the University of Amsterdam Intelligent Data Engineering Lab\nteam's entry for the SemEval-2024 Task 6 competition. The SHROOM-INDElab system\nbuilds on previous work on using prompt programming and in-context learning\nwith large language models (LLMs) to build classifiers for hallucination\ndetection, and extends that work through the incorporation of context-specific\ndefinition of task, role, and target concept, and automated generation of\nexamples for use in a few-shot prompting approach. The resulting system\nachieved fourth-best and sixth-best performance in the model-agnostic track and\nmodel-aware tracks for Task 6, respectively, and evaluation using the\nvalidation sets showed that the system's classification decisions were\nconsistent with those of the crowd-sourced human labellers. We further found\nthat a zero-shot approach provided better accuracy than a few-shot approach\nusing automatically generated examples. Code for the system described in this\npaper is available on Github.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 6 figures, 4 tables, camera-ready copy, accepted to the 18th\n  International Workshop on Semantic Evaluation (SemEval-2024), for associated\n  code and data see https://github.com/bradleypallen/shroom",
    "pdf_url": "http://arxiv.org/pdf/2404.03732v1",
    "published_date": "2024-04-04 18:01:21 UTC",
    "updated_date": "2024-04-04 18:01:21 UTC"
  },
  {
    "arxiv_id": "2404.03657v2",
    "title": "OW-VISCapTor: Abstractors for Open-World Video Instance Segmentation and Captioning",
    "authors": [
      "Anwesa Choudhuri",
      "Girish Chowdhary",
      "Alexander G. Schwing"
    ],
    "abstract": "We propose the new task 'open-world video instance segmentation and\ncaptioning'. It requires to detect, segment, track and describe with rich\ncaptions never before seen objects. This challenging task can be addressed by\ndeveloping \"abstractors\" which connect a vision model and a language foundation\nmodel. Concretely, we connect a multi-scale visual feature extractor and a\nlarge language model (LLM) by developing an object abstractor and an\nobject-to-text abstractor. The object abstractor, consisting of a prompt\nencoder and transformer blocks, introduces spatially-diverse open-world object\nqueries to discover never before seen objects in videos. An inter-query\ncontrastive loss further encourages the diversity of object queries. The\nobject-to-text abstractor is augmented with masked cross-attention and acts as\na bridge between the object queries and a frozen LLM to generate rich and\ndescriptive object-centric captions for each detected object. Our generalized\napproach surpasses the baseline that jointly addresses the tasks of open-world\nvideo instance segmentation and dense video object captioning by 13% on never\nbefore seen objects, and by 10% on object-centric captions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://anwesachoudhuri.github.io/OpenWorldVISCap/",
    "pdf_url": "http://arxiv.org/pdf/2404.03657v2",
    "published_date": "2024-04-04 17:59:58 UTC",
    "updated_date": "2024-12-09 18:19:05 UTC"
  },
  {
    "arxiv_id": "2404.03653v3",
    "title": "CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching",
    "authors": [
      "Dongzhi Jiang",
      "Guanglu Song",
      "Xiaoshi Wu",
      "Renrui Zhang",
      "Dazhong Shen",
      "Zhuofan Zong",
      "Yu Liu",
      "Hongsheng Li"
    ],
    "abstract": "Diffusion models have demonstrated great success in the field of\ntext-to-image generation. However, alleviating the misalignment between the\ntext prompts and images is still challenging. The root reason behind the\nmisalignment has not been extensively investigated. We observe that the\nmisalignment is caused by inadequate token attention activation. We further\nattribute this phenomenon to the diffusion model's insufficient condition\nutilization, which is caused by its training paradigm. To address the issue, we\npropose CoMat, an end-to-end diffusion model fine-tuning strategy with an\nimage-to-text concept matching mechanism. We leverage an image captioning model\nto measure image-to-text alignment and guide the diffusion model to revisit\nignored tokens. A novel attribute concentration module is also proposed to\naddress the attribute binding problem. Without any image or human preference\ndata, we use only 20K text prompts to fine-tune SDXL to obtain CoMat-SDXL.\nExtensive experiments show that CoMat-SDXL significantly outperforms the\nbaseline model SDXL in two text-to-image alignment benchmarks and achieves\nstart-of-the-art performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.03653v3",
    "published_date": "2024-04-04 17:59:46 UTC",
    "updated_date": "2024-11-27 09:55:41 UTC"
  },
  {
    "arxiv_id": "2404.03647v1",
    "title": "Capabilities of Large Language Models in Control Engineering: A Benchmark Study on GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra",
    "authors": [
      "Darioush Kevian",
      "Usman Syed",
      "Xingang Guo",
      "Aaron Havens",
      "Geir Dullerud",
      "Peter Seiler",
      "Lianhui Qin",
      "Bin Hu"
    ],
    "abstract": "In this paper, we explore the capabilities of state-of-the-art large language\nmodels (LLMs) such as GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra in solving\nundergraduate-level control problems. Controls provides an interesting case\nstudy for LLM reasoning due to its combination of mathematical theory and\nengineering design. We introduce ControlBench, a benchmark dataset tailored to\nreflect the breadth, depth, and complexity of classical control design. We use\nthis dataset to study and evaluate the problem-solving abilities of these LLMs\nin the context of control engineering. We present evaluations conducted by a\npanel of human experts, providing insights into the accuracy, reasoning, and\nexplanatory prowess of LLMs in control engineering. Our analysis reveals the\nstrengths and limitations of each LLM in the context of classical control, and\nour results imply that Claude 3 Opus has become the state-of-the-art LLM for\nsolving undergraduate control problems. Our study serves as an initial step\ntowards the broader goal of employing artificial general intelligence in\ncontrol engineering.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03647v1",
    "published_date": "2024-04-04 17:58:38 UTC",
    "updated_date": "2024-04-04 17:58:38 UTC"
  },
  {
    "arxiv_id": "2404.03715v1",
    "title": "Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences",
    "authors": [
      "Corby Rosset",
      "Ching-An Cheng",
      "Arindam Mitra",
      "Michael Santacroce",
      "Ahmed Awadallah",
      "Tengyang Xie"
    ],
    "abstract": "This paper studies post-training large language models (LLMs) using\npreference feedback from a powerful oracle to help a model iteratively improve\nover itself. The typical approach for post-training LLMs involves Reinforcement\nLearning from Human Feedback (RLHF), which traditionally separates reward\nlearning and subsequent policy optimization. However, such a reward\nmaximization approach is limited by the nature of \"point-wise\" rewards (such as\nBradley-Terry model), which fails to express complex intransitive or cyclic\npreference relations. While advances on RLHF show reward learning and policy\noptimization can be merged into a single contrastive objective for stability,\nthey yet still remain tethered to the reward maximization framework. Recently,\na new wave of research sidesteps the reward maximization presumptions in favor\nof directly optimizing over \"pair-wise\" or general preferences. In this paper,\nwe introduce Direct Nash Optimization (DNO), a provable and scalable algorithm\nthat marries the simplicity and stability of contrastive learning with\ntheoretical generality from optimizing general preferences. Because DNO is a\nbatched on-policy algorithm using a regression-based objective, its\nimplementation is straightforward and efficient. Moreover, DNO enjoys monotonic\nimprovement across iterations that help it improve even over a strong teacher\n(such as GPT-4). In our experiments, a resulting 7B parameter Orca-2.5 model\naligned by DNO achieves the state-of-the-art win-rate against GPT-4-Turbo of\n33% on AlpacaEval 2.0 (even after controlling for response length), an absolute\ngain of 26% (7% to 33%) over the initializing model. It outperforms models with\nfar more parameters, including Mistral Large, Self-Rewarding LM (70B\nparameters), and older versions of GPT-4.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03715v1",
    "published_date": "2024-04-04 17:56:41 UTC",
    "updated_date": "2024-04-04 17:56:41 UTC"
  },
  {
    "arxiv_id": "2404.03635v4",
    "title": "WorDepth: Variational Language Prior for Monocular Depth Estimation",
    "authors": [
      "Ziyao Zeng",
      "Daniel Wang",
      "Fengyu Yang",
      "Hyoungseob Park",
      "Yangchao Wu",
      "Stefano Soatto",
      "Byung-Woo Hong",
      "Dong Lao",
      "Alex Wong"
    ],
    "abstract": "Three-dimensional (3D) reconstruction from a single image is an ill-posed\nproblem with inherent ambiguities, i.e. scale. Predicting a 3D scene from text\ndescription(s) is similarly ill-posed, i.e. spatial arrangements of objects\ndescribed. We investigate the question of whether two inherently ambiguous\nmodalities can be used in conjunction to produce metric-scaled reconstructions.\nTo test this, we focus on monocular depth estimation, the problem of predicting\na dense depth map from a single image, but with an additional text caption\ndescribing the scene. To this end, we begin by encoding the text caption as a\nmean and standard deviation; using a variational framework, we learn the\ndistribution of the plausible metric reconstructions of 3D scenes corresponding\nto the text captions as a prior. To \"select\" a specific reconstruction or depth\nmap, we encode the given image through a conditional sampler that samples from\nthe latent space of the variational text encoder, which is then decoded to the\noutput depth map. Our approach is trained alternatingly between the text and\nimage branches: in one optimization step, we predict the mean and standard\ndeviation from the text description and sample from a standard Gaussian, and in\nthe other, we sample using a (image) conditional sampler. Once trained, we\ndirectly predict depth from the encoded text using the conditional sampler. We\ndemonstrate our approach on indoor (NYUv2) and outdoor (KITTI) scenarios, where\nwe show that language can consistently improve performance in both.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03635v4",
    "published_date": "2024-04-04 17:54:33 UTC",
    "updated_date": "2024-06-02 04:56:32 UTC"
  },
  {
    "arxiv_id": "2404.03714v1",
    "title": "SpikeExplorer: hardware-oriented Design Space Exploration for Spiking Neural Networks on FPGA",
    "authors": [
      "Dario Padovano",
      "Alessio Carpegna",
      "Alessandro Savino",
      "Stefano Di Carlo"
    ],
    "abstract": "One of today's main concerns is to bring Artificial Intelligence power to\nembedded systems for edge applications. The hardware resources and power\nconsumption required by state-of-the-art models are incompatible with the\nconstrained environments observed in edge systems, such as IoT nodes and\nwearable devices. Spiking Neural Networks (SNNs) can represent a solution in\nthis sense: inspired by neuroscience, they reach unparalleled power and\nresource efficiency when run on dedicated hardware accelerators. However, when\ndesigning such accelerators, the amount of choices that can be taken is huge.\nThis paper presents SpikExplorer, a modular and flexible Python tool for\nhardware-oriented Automatic Design Space Exploration to automate the\nconfiguration of FPGA accelerators for SNNs. Using Bayesian optimizations,\nSpikerExplorer enables hardware-centric multi-objective optimization,\nsupporting factors such as accuracy, area, latency, power, and various\ncombinations during the exploration process. The tool searches the optimal\nnetwork architecture, neuron model, and internal and training parameters,\ntrying to reach the desired constraints imposed by the user. It allows for a\nstraightforward network configuration, providing the full set of explored\npoints for the user to pick the trade-off that best fits the needs. The\npotential of SpikExplorer is showcased using three benchmark datasets. It\nreaches 95.8% accuracy on the MNIST dataset, with a power consumption of\n180mW/image and a latency of 0.12 ms/image, making it a powerful tool for\nautomatically optimizing SNNs.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03714v1",
    "published_date": "2024-04-04 17:53:08 UTC",
    "updated_date": "2024-04-04 17:53:08 UTC"
  },
  {
    "arxiv_id": "2404.03624v1",
    "title": "Standardizing Knowledge Engineering Practices with a Reference Architecture",
    "authors": [
      "Bradley P. Allen",
      "Filip Ilievski"
    ],
    "abstract": "Knowledge engineering is the process of creating and maintaining\nknowledge-producing systems. Throughout the history of computer science and AI,\nknowledge engineering workflows have been widely used given the importance of\nhigh-quality knowledge for reliable intelligent agents. Meanwhile, the scope of\nknowledge engineering, as apparent from its target tasks and use cases, has\nbeen shifting, together with its paradigms such as expert systems, semantic\nweb, and language modeling. The intended use cases and supported user\nrequirements between these paradigms have not been analyzed globally, as new\nparadigms often satisfy prior pain points while possibly introducing new ones.\nThe recent abstraction of systemic patterns into a boxology provides an opening\nfor aligning the requirements and use cases of knowledge engineering with the\nsystems, components, and software that can satisfy them best. This paper\nproposes a vision of harmonizing the best practices in the field of knowledge\nengineering by leveraging the software engineering methodology of creating\nreference architectures. We describe how a reference architecture can be\niteratively designed and implemented to associate user needs with recurring\nsystemic patterns, building on top of existing knowledge engineering workflows\nand boxologies. We provide a six-step roadmap that can enable the development\nof such an architecture, providing an initial design and outcome of the\ndefinition of architectural scope, selection of information sources, and\nanalysis. We expect that following through on this vision will lead to\nwell-grounded reference architectures for knowledge engineering, will advance\nthe ongoing initiatives of organizing the neurosymbolic knowledge engineering\nspace, and will build new links to the software architectures and data science\ncommunities.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 4 figures, 2 tables, camera-ready version, accepted for\n  Transactions on Graph Data and Knowledge (TGDK)",
    "pdf_url": "http://arxiv.org/pdf/2404.03624v1",
    "published_date": "2024-04-04 17:46:32 UTC",
    "updated_date": "2024-04-04 17:46:32 UTC"
  },
  {
    "arxiv_id": "2404.03713v2",
    "title": "Explaining Explainability: Recommendations for Effective Use of Concept Activation Vectors",
    "authors": [
      "Angus Nicolson",
      "Lisa Schut",
      "J. Alison Noble",
      "Yarin Gal"
    ],
    "abstract": "Concept-based explanations translate the internal representations of deep\nlearning models into a language that humans are familiar with: concepts. One\npopular method for finding concepts is Concept Activation Vectors (CAVs), which\nare learnt using a probe dataset of concept exemplars. In this work, we\ninvestigate three properties of CAVs: (1) inconsistency across layers, (2)\nentanglement with other concepts, and (3) spatial dependency. Each property\nprovides both challenges and opportunities in interpreting models. We introduce\ntools designed to detect the presence of these properties, provide insight into\nhow each property can lead to misleading explanations, and provide\nrecommendations to mitigate their impact. To demonstrate practical\napplications, we apply our recommendations to a melanoma classification task,\nshowing how entanglement can lead to uninterpretable results and that the\nchoice of negative probe set can have a substantial impact on the meaning of a\nCAV. Further, we show that understanding these properties can be used to our\nadvantage. For example, we introduce spatially dependent CAVs to test if a\nmodel is translation invariant with respect to a specific concept and class.\nOur experiments are performed on natural images (ImageNet), skin lesions (ISIC\n2019), and a new synthetic dataset, Elements. Elements is designed to capture a\nknown ground truth relationship between concepts and classes. We release this\ndataset to facilitate further research in understanding and evaluating\ninterpretability methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by Transactions on Machine Learning Research (02/2025)",
    "pdf_url": "http://arxiv.org/pdf/2404.03713v2",
    "published_date": "2024-04-04 17:46:20 UTC",
    "updated_date": "2025-02-13 09:48:12 UTC"
  },
  {
    "arxiv_id": "2404.03623v2",
    "title": "Unveiling LLMs: The Evolution of Latent Representations in a Dynamic Knowledge Graph",
    "authors": [
      "Marco Bronzini",
      "Carlo Nicolini",
      "Bruno Lepri",
      "Jacopo Staiano",
      "Andrea Passerini"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate an impressive capacity to recall a\nvast range of factual knowledge. However, understanding their underlying\nreasoning and internal mechanisms in exploiting this knowledge remains a key\nresearch area. This work unveils the factual information an LLM represents\ninternally for sentence-level claim verification. We propose an end-to-end\nframework to decode factual knowledge embedded in token representations from a\nvector space to a set of ground predicates, showing its layer-wise evolution\nusing a dynamic knowledge graph. Our framework employs activation patching, a\nvector-level technique that alters a token representation during inference, to\nextract encoded knowledge. Accordingly, we neither rely on training nor\nexternal models. Using factual and common-sense claims from two claim\nverification datasets, we showcase interpretability analyses at local and\nglobal levels. The local analysis highlights entity centrality in LLM\nreasoning, from claim-related information and multi-hop reasoning to\nrepresentation errors causing erroneous evaluation. On the other hand, the\nglobal reveals trends in the underlying evolution, such as word-based knowledge\nevolving into claim-related facts. By interpreting semantics from LLM latent\nrepresentations and enabling graph-related analyses, this work enhances the\nunderstanding of the factual knowledge resolution process.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at COLM 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.03623v2",
    "published_date": "2024-04-04 17:45:59 UTC",
    "updated_date": "2024-08-06 15:02:33 UTC"
  },
  {
    "arxiv_id": "2404.16045v1",
    "title": "Elicitron: An LLM Agent-Based Simulation Framework for Design Requirements Elicitation",
    "authors": [
      "Mohammadmehdi Ataei",
      "Hyunmin Cheong",
      "Daniele Grandi",
      "Ye Wang",
      "Nigel Morris",
      "Alexander Tessier"
    ],
    "abstract": "Requirements elicitation, a critical, yet time-consuming and challenging step\nin product development, often fails to capture the full spectrum of user needs.\nThis may lead to products that fall short of expectations. This paper\nintroduces a novel framework that leverages Large Language Models (LLMs) to\nautomate and enhance the requirements elicitation process. LLMs are used to\ngenerate a vast array of simulated users (LLM agents), enabling the exploration\nof a much broader range of user needs and unforeseen use cases. These agents\nengage in product experience scenarios, through explaining their actions,\nobservations, and challenges. Subsequent agent interviews and analysis uncover\nvaluable user needs, including latent ones. We validate our framework with\nthree experiments. First, we explore different methodologies for diverse agent\ngeneration, discussing their advantages and shortcomings. We measure the\ndiversity of identified user needs and demonstrate that context-aware agent\ngeneration leads to greater diversity. Second, we show how our framework\neffectively mimics empathic lead user interviews, identifying a greater number\nof latent needs than conventional human interviews. Third, we showcase that\nLLMs can be used to analyze interviews, capture needs, and classify them as\nlatent or not. Our work highlights the potential of using LLM agents to\naccelerate early-stage product development, reduce costs, and increase\ninnovation.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16045v1",
    "published_date": "2024-04-04 17:36:29 UTC",
    "updated_date": "2024-04-04 17:36:29 UTC"
  },
  {
    "arxiv_id": "2404.03611v1",
    "title": "InsectMamba: Insect Pest Classification with State Space Model",
    "authors": [
      "Qianning Wang",
      "Chenglin Wang",
      "Zhixin Lai",
      "Yucheng Zhou"
    ],
    "abstract": "The classification of insect pests is a critical task in agricultural\ntechnology, vital for ensuring food security and environmental sustainability.\nHowever, the complexity of pest identification, due to factors like high\ncamouflage and species diversity, poses significant obstacles. Existing methods\nstruggle with the fine-grained feature extraction needed to distinguish between\nclosely related pest species. Although recent advancements have utilized\nmodified network structures and combined deep learning approaches to improve\naccuracy, challenges persist due to the similarity between pests and their\nsurroundings. To address this problem, we introduce InsectMamba, a novel\napproach that integrates State Space Models (SSMs), Convolutional Neural\nNetworks (CNNs), Multi-Head Self-Attention mechanism (MSA), and Multilayer\nPerceptrons (MLPs) within Mix-SSM blocks. This integration facilitates the\nextraction of comprehensive visual features by leveraging the strengths of each\nencoding strategy. A selective module is also proposed to adaptively aggregate\nthese features, enhancing the model's ability to discern pest characteristics.\nInsectMamba was evaluated against strong competitors across five insect pest\nclassification datasets. The results demonstrate its superior performance and\nverify the significance of each model component by an ablation study.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.03611v1",
    "published_date": "2024-04-04 17:34:21 UTC",
    "updated_date": "2024-04-04 17:34:21 UTC"
  },
  {
    "arxiv_id": "2404.03608v1",
    "title": "Sailor: Open Language Models for South-East Asia",
    "authors": [
      "Longxu Dou",
      "Qian Liu",
      "Guangtao Zeng",
      "Jia Guo",
      "Jiahui Zhou",
      "Wei Lu",
      "Min Lin"
    ],
    "abstract": "We present Sailor, a family of open language models ranging from 0.5B to 7B\nparameters, tailored for South-East Asian (SEA) languages. These models are\ncontinually pre-trained from Qwen1.5, a great language model for multilingual\nuse cases. From Qwen1.5, Sailor models accept 200B to 400B tokens, primarily\ncovering the languages of English, Chinese, Vietnamese, Thai, Indonesian,\nMalay, and Lao. The training leverages several techniques, including BPE\ndropout for improving the model robustness, aggressive data cleaning and\ndeduplication, and small proxy models to optimize data mixture. Experimental\nresults on four typical tasks indicate that Sailor models demonstrate strong\nperformance across different benchmarks, including commonsense reasoning,\nquestion answering, reading comprehension and examination. Embracing the\nopen-source spirit, we share our insights through this report to spark a wider\ninterest in developing large language models for multilingual use cases.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Code is available at https://github.com/sail-sg/sailor-llm",
    "pdf_url": "http://arxiv.org/pdf/2404.03608v1",
    "published_date": "2024-04-04 17:31:32 UTC",
    "updated_date": "2024-04-04 17:31:32 UTC"
  },
  {
    "arxiv_id": "2404.03606v1",
    "title": "Analyzing Musical Characteristics of National Anthems in Relation to Global Indices",
    "authors": [
      "S M Rakib Hasan",
      "Aakar Dhakal",
      "Ms. Ayesha Siddiqua",
      "Mohammad Mominur Rahman",
      "Md Maidul Islam",
      "Mohammed Arfat Raihan Chowdhury",
      "S M Masfequier Rahman Swapno",
      "SM Nuruzzaman Nobel"
    ],
    "abstract": "Music plays a huge part in shaping peoples' psychology and behavioral\npatterns. This paper investigates the connection between national anthems and\ndifferent global indices with computational music analysis and statistical\ncorrelation analysis. We analyze national anthem musical data to determine\nwhether certain musical characteristics are associated with peace, happiness,\nsuicide rate, crime rate, etc. To achieve this, we collect national anthems\nfrom 169 countries and use computational music analysis techniques to extract\npitch, tempo, beat, and other pertinent audio features. We then compare these\nmusical characteristics with data on different global indices to ascertain\nwhether a significant correlation exists. Our findings indicate that there may\nbe a correlation between the musical characteristics of national anthems and\nthe indices we investigated. The implications of our findings for music\npsychology and policymakers interested in promoting social well-being are\ndiscussed. This paper emphasizes the potential of musical data analysis in\nsocial research and offers a novel perspective on the relationship between\nmusic and social indices. The source code and data are made open-access for\nreproducibility and future research endeavors. It can be accessed at\nhttp://bit.ly/na_code.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.IR",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03606v1",
    "published_date": "2024-04-04 17:25:31 UTC",
    "updated_date": "2024-04-04 17:25:31 UTC"
  },
  {
    "arxiv_id": "2404.03596v1",
    "title": "Laser Learning Environment: A new environment for coordination-critical multi-agent tasks",
    "authors": [
      "Yannick Molinghen",
      "Raphal Avalos",
      "Mark Van Achter",
      "Ann Now",
      "Tom Lenaerts"
    ],
    "abstract": "We introduce the Laser Learning Environment (LLE), a collaborative\nmulti-agent reinforcement learning environment in which coordination is\ncentral. In LLE, agents depend on each other to make progress\n(interdependence), must jointly take specific sequences of actions to succeed\n(perfect coordination), and accomplishing those joint actions does not yield\nany intermediate reward (zero-incentive dynamics). The challenge of such\nproblems lies in the difficulty of escaping state space bottlenecks caused by\ninterdependence steps since escaping those bottlenecks is not rewarded. We test\nmultiple state-of-the-art value-based MARL algorithms against LLE and show that\nthey consistently fail at the collaborative task because of their inability to\nescape state space bottlenecks, even though they successfully achieve perfect\ncoordination. We show that Q-learning extensions such as prioritized experience\nreplay and n-steps return hinder exploration in environments with\nzero-incentive dynamics, and find that intrinsic curiosity with random network\ndistillation is not sufficient to escape those bottlenecks. We demonstrate the\nneed for novel methods to solve this problem and the relevance of LLE as\ncooperative MARL benchmark.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "Pre-print, 21 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.03596v1",
    "published_date": "2024-04-04 17:05:42 UTC",
    "updated_date": "2024-04-04 17:05:42 UTC"
  },
  {
    "arxiv_id": "2404.03592v3",
    "title": "ReFT: Representation Finetuning for Language Models",
    "authors": [
      "Zhengxuan Wu",
      "Aryaman Arora",
      "Zheng Wang",
      "Atticus Geiger",
      "Dan Jurafsky",
      "Christopher D. Manning",
      "Christopher Potts"
    ],
    "abstract": "Parameter-efficient finetuning (PEFT) methods seek to adapt large neural\nmodels via updates to a small number of weights. However, much prior\ninterpretability work has shown that representations encode rich semantic\ninformation, suggesting that editing representations might be a more powerful\nalternative. We pursue this hypothesis by developing a family of Representation\nFinetuning (ReFT) methods. ReFT methods operate on a frozen base model and\nlearn task-specific interventions on hidden representations. We define a strong\ninstance of the ReFT family, Low-rank Linear Subspace ReFT (LoReFT), and we\nidentify an ablation of this method that trades some performance for increased\nefficiency. Both are drop-in replacements for existing PEFTs and learn\ninterventions that are 15x--65x more parameter-efficient than LoRA. We showcase\nLoReFT on eight commonsense reasoning tasks, four arithmetic reasoning tasks,\ninstruction-tuning, and GLUE. In all these evaluations, our ReFTs deliver the\nbest balance of efficiency and performance, and almost always outperform\nstate-of-the-art PEFTs. We release a generic ReFT training library publicly at\nhttps://github.com/stanfordnlp/pyreft.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2404.03592v3",
    "published_date": "2024-04-04 17:00:37 UTC",
    "updated_date": "2024-05-22 17:52:31 UTC"
  },
  {
    "arxiv_id": "2404.03590v1",
    "title": "SemGrasp: Semantic Grasp Generation via Language Aligned Discretization",
    "authors": [
      "Kailin Li",
      "Jingbo Wang",
      "Lixin Yang",
      "Cewu Lu",
      "Bo Dai"
    ],
    "abstract": "Generating natural human grasps necessitates consideration of not just object\ngeometry but also semantic information. Solely depending on object shape for\ngrasp generation confines the applications of prior methods in downstream\ntasks. This paper presents a novel semantic-based grasp generation method,\ntermed SemGrasp, which generates a static human grasp pose by incorporating\nsemantic information into the grasp representation. We introduce a discrete\nrepresentation that aligns the grasp space with semantic space, enabling the\ngeneration of grasp postures in accordance with language instructions. A\nMultimodal Large Language Model (MLLM) is subsequently fine-tuned, integrating\nobject, grasp, and language within a unified semantic space. To facilitate the\ntraining of SemGrasp, we have compiled a large-scale, grasp-text-aligned\ndataset named CapGrasp, featuring about 260k detailed captions and 50k diverse\ngrasps. Experimental findings demonstrate that SemGrasp efficiently generates\nnatural human grasps in alignment with linguistic intentions. Our code, models,\nand dataset are available publicly at: https://kailinli.github.io/SemGrasp.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03590v1",
    "published_date": "2024-04-04 16:58:26 UTC",
    "updated_date": "2024-04-04 16:58:26 UTC"
  },
  {
    "arxiv_id": "2404.03587v1",
    "title": "Anticipate & Collab: Data-driven Task Anticipation and Knowledge-driven Planning for Human-robot Collaboration",
    "authors": [
      "Shivam Singh",
      "Karthik Swaminathan",
      "Raghav Arora",
      "Ramandeep Singh",
      "Ahana Datta",
      "Dipanjan Das",
      "Snehasis Banerjee",
      "Mohan Sridharan",
      "Madhava Krishna"
    ],
    "abstract": "An agent assisting humans in daily living activities can collaborate more\neffectively by anticipating upcoming tasks. Data-driven methods represent the\nstate of the art in task anticipation, planning, and related problems, but\nthese methods are resource-hungry and opaque. Our prior work introduced a proof\nof concept framework that used an LLM to anticipate 3 high-level tasks that\nserved as goals for a classical planning system that computed a sequence of\nlow-level actions for the agent to achieve these goals. This paper describes\nDaTAPlan, our framework that significantly extends our prior work toward\nhuman-robot collaboration. Specifically, DaTAPlan planner computes actions for\nan agent and a human to collaboratively and jointly achieve the tasks\nanticipated by the LLM, and the agent automatically adapts to unexpected\nchanges in human action outcomes and preferences. We evaluate DaTAPlan\ncapabilities in a realistic simulation environment, demonstrating accurate task\nanticipation, effective human-robot collaboration, and the ability to adapt to\nunexpected changes. Project website: https://dataplan-hrc.github.io",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03587v1",
    "published_date": "2024-04-04 16:52:48 UTC",
    "updated_date": "2024-04-04 16:52:48 UTC"
  },
  {
    "arxiv_id": "2404.03574v1",
    "title": "TinyVQA: Compact Multimodal Deep Neural Network for Visual Question Answering on Resource-Constrained Devices",
    "authors": [
      "Hasib-Al Rashid",
      "Argho Sarkar",
      "Aryya Gangopadhyay",
      "Maryam Rahnemoonfar",
      "Tinoosh Mohsenin"
    ],
    "abstract": "Traditional machine learning models often require powerful hardware, making\nthem unsuitable for deployment on resource-limited devices. Tiny Machine\nLearning (tinyML) has emerged as a promising approach for running machine\nlearning models on these devices, but integrating multiple data modalities into\ntinyML models still remains a challenge due to increased complexity, latency,\nand power consumption. This paper proposes TinyVQA, a novel multimodal deep\nneural network for visual question answering tasks that can be deployed on\nresource-constrained tinyML hardware. TinyVQA leverages a supervised\nattention-based model to learn how to answer questions about images using both\nvision and language modalities. Distilled knowledge from the supervised\nattention-based VQA model trains the memory aware compact TinyVQA model and low\nbit-width quantization technique is employed to further compress the model for\ndeployment on tinyML devices. The TinyVQA model was evaluated on the FloodNet\ndataset, which is used for post-disaster damage assessment. The compact model\nachieved an accuracy of 79.5%, demonstrating the effectiveness of TinyVQA for\nreal-world applications. Additionally, the model was deployed on a Crazyflie\n2.0 drone, equipped with an AI deck and GAP8 microprocessor. The TinyVQA model\nachieved low latencies of 56 ms and consumes 693 mW power while deployed on the\ntiny drone, showcasing its suitability for resource-constrained embedded\nsystems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted as a full paper by the tinyML Research Symposium 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.03574v1",
    "published_date": "2024-04-04 16:38:49 UTC",
    "updated_date": "2024-04-04 16:38:49 UTC"
  },
  {
    "arxiv_id": "2404.03549v1",
    "title": "Alzheimer's disease detection in PSG signals",
    "authors": [
      "Lorena Gallego-Viars",
      "Juan Miguel Mira-Toms",
      "Anna Michela-Gaeta",
      "Gerard Pinol-Ripoll",
      "Ferrn Barb",
      "Pablo M. Olmos",
      "Arrate Muoz-Barrutia"
    ],
    "abstract": "Alzheimer's disease (AD) and sleep disorders exhibit a close association,\nwhere disruptions in sleep patterns often precede the onset of Mild Cognitive\nImpairment (MCI) and early-stage AD. This study delves into the potential of\nutilizing sleep-related electroencephalography (EEG) signals acquired through\npolysomnography (PSG) for the early detection of AD. Our primary focus is on\nexploring semi-supervised Deep Learning techniques for the classification of\nEEG signals due to the clinical scenario characterized by the limited data\navailability. The methodology entails testing and comparing the performance of\nsemi-supervised SMATE and TapNet models, benchmarked against the supervised XCM\nmodel, and unsupervised Hidden Markov Models (HMMs). The study highlights the\nsignificance of spatial and temporal analysis capabilities, conducting\nindependent analyses of each sleep stage. Results demonstrate the effectiveness\nof SMATE in leveraging limited labeled data, achieving stable metrics across\nall sleep stages, and reaching 90% accuracy in its supervised form. Comparative\nanalyses reveal SMATE's superior performance over TapNet and HMM, while XCM\nexcels in supervised scenarios with an accuracy range of 92 - 94%. These\nfindings underscore the potential of semi-supervised models in early AD\ndetection, particularly in overcoming the challenges associated with the\nscarcity of labeled data. Ablation tests affirm the critical role of\nspatio-temporal feature extraction in semi-supervised predictive performance,\nand t-SNE visualizations validate the model's proficiency in distinguishing AD\npatterns. Overall, this research contributes to the advancement of AD detection\nthrough innovative Deep Learning approaches, highlighting the crucial role of\nsemi-supervised learning in addressing data limitations.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "68T07 (Primary), 68T05, 92B20 (Secondary)",
      "I.2.1"
    ],
    "primary_category": "eess.SP",
    "comment": "12 pages, 14 figures. Submitted to IEEE Biomedical and Health\n  Informatics for publication",
    "pdf_url": "http://arxiv.org/pdf/2404.03549v1",
    "published_date": "2024-04-04 15:56:23 UTC",
    "updated_date": "2024-04-04 15:56:23 UTC"
  },
  {
    "arxiv_id": "2404.03543v3",
    "title": "CodeEditorBench: Evaluating Code Editing Capability of Large Language Models",
    "authors": [
      "Jiawei Guo",
      "Ziming Li",
      "Xueling Liu",
      "Kaijing Ma",
      "Tianyu Zheng",
      "Zhouliang Yu",
      "Ding Pan",
      "Yizhi LI",
      "Ruibo Liu",
      "Yue Wang",
      "Shuyue Guo",
      "Xingwei Qu",
      "Xiang Yue",
      "Ge Zhang",
      "Wenhu Chen",
      "Jie Fu"
    ],
    "abstract": "Large Language Models (LLMs) for code are rapidly evolving, with code editing\nemerging as a critical capability. We introduce CodeEditorBench, an evaluation\nframework designed to rigorously assess the performance of LLMs in code editing\ntasks, including debugging, translating, polishing, and requirement switching.\nUnlike existing benchmarks focusing solely on code generation, CodeEditorBench\nemphasizes real-world scenarios and practical aspects of software development.\nWe curate diverse coding challenges and scenarios from five sources, covering\nvarious programming languages, complexity levels, and editing tasks. Evaluation\nof 19 LLMs reveals that closed-source models (particularly Gemini-Ultra and\nGPT-4), outperform open-source models in CodeEditorBench, highlighting\ndifferences in model performance based on problem types and prompt\nsensitivities. CodeEditorBench aims to catalyze advancements in LLMs by\nproviding a robust platform for assessing code editing capabilities. We will\nrelease all prompts and datasets to enable the community to expand the dataset\nand benchmark emerging LLMs. By introducing CodeEditorBench, we contribute to\nthe advancement of LLMs in code editing and provide a valuable resource for\nresearchers and practitioners.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03543v3",
    "published_date": "2024-04-04 15:49:49 UTC",
    "updated_date": "2025-04-08 09:39:25 UTC"
  },
  {
    "arxiv_id": "2404.03514v2",
    "title": "Embedding-Informed Adaptive Retrieval-Augmented Generation of Large Language Models",
    "authors": [
      "Chengkai Huang",
      "Yu Xia",
      "Rui Wang",
      "Kaige Xie",
      "Tong Yu",
      "Julian McAuley",
      "Lina Yao"
    ],
    "abstract": "Retrieval-augmented large language models (LLMs) have been remarkably\ncompetent in various NLP tasks. However, it was observed by previous works that\nretrieval is not always helpful, especially when the LLM is already\nknowledgeable on the query to answer. Motivated by this, Adaptive\nRetrieval-Augmented Generation (ARAG) studies retrieving only when the\nknowledge asked by the query is absent in the LLM. Previous works of ARAG\neither require accessing the pre-training corpus or prompting with additional\nmodel inferences. Aiming to avoid such drawbacks, we propose to determine\nwhether the model is knowledgeable on a query via inspecting the\n(contextualized) pre-trained token embeddings of LLMs. We hypothesize that such\nembeddings capture rich information on the model's intrinsic knowledge base,\nwhich enables an efficient way of judging the necessity to retrieve from an\nexternal corpus. Extensive experiments demonstrate our ARAG approach's superior\nperformance across various benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03514v2",
    "published_date": "2024-04-04 15:21:22 UTC",
    "updated_date": "2024-12-13 02:45:14 UTC"
  },
  {
    "arxiv_id": "2404.03502v2",
    "title": "AI and the Problem of Knowledge Collapse",
    "authors": [
      "Andrew J. Peterson"
    ],
    "abstract": "While artificial intelligence has the potential to process vast amounts of\ndata, generate new insights, and unlock greater productivity, its widespread\nadoption may entail unforeseen consequences. We identify conditions under which\nAI, by reducing the cost of access to certain modes of knowledge, can\nparadoxically harm public understanding. While large language models are\ntrained on vast amounts of diverse data, they naturally generate output towards\nthe 'center' of the distribution. This is generally useful, but widespread\nreliance on recursive AI systems could lead to a process we define as\n\"knowledge collapse\", and argue this could harm innovation and the richness of\nhuman understanding and culture. However, unlike AI models that cannot choose\nwhat data they are trained on, humans may strategically seek out diverse forms\nof knowledge if they perceive them to be worthwhile. To investigate this, we\nprovide a simple model in which a community of learners or innovators choose to\nuse traditional methods or to rely on a discounted AI-assisted process and\nidentify conditions under which knowledge collapse occurs. In our default\nmodel, a 20% discount on AI-generated content generates public beliefs 2.3\ntimes further from the truth than when there is no discount. An empirical\napproach to measuring the distribution of LLM outputs is provided in\ntheoretical terms and illustrated through a specific example comparing the\ndiversity of outputs across different models and prompting styles. Finally,\nbased on the results, we consider further research directions to counteract\nsuch outcomes.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "37 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.03502v2",
    "published_date": "2024-04-04 15:06:23 UTC",
    "updated_date": "2024-04-22 14:18:42 UTC"
  },
  {
    "arxiv_id": "2404.03499v1",
    "title": "Comprehensible Artificial Intelligence on Knowledge Graphs: A survey",
    "authors": [
      "Simon Schramm",
      "Christoph Wehner",
      "Ute Schmid"
    ],
    "abstract": "Artificial Intelligence applications gradually move outside the safe walls of\nresearch labs and invade our daily lives. This is also true for Machine\nLearning methods on Knowledge Graphs, which has led to a steady increase in\ntheir application since the beginning of the 21st century. However, in many\napplications, users require an explanation of the Artificial Intelligences\ndecision. This led to increased demand for Comprehensible Artificial\nIntelligence. Knowledge Graphs epitomize fertile soil for Comprehensible\nArtificial Intelligence, due to their ability to display connected data, i.e.\nknowledge, in a human- as well as machine-readable way. This survey gives a\nshort history to Comprehensible Artificial Intelligence on Knowledge Graphs.\nFurthermore, we contribute by arguing that the concept Explainable Artificial\nIntelligence is overloaded and overlapping with Interpretable Machine Learning.\nBy introducing the parent concept Comprehensible Artificial Intelligence, we\nprovide a clear-cut distinction of both concepts while accounting for their\nsimilarities. Thus, we provide in this survey a case for Comprehensible\nArtificial Intelligence on Knowledge Graphs consisting of Interpretable Machine\nLearning on Knowledge Graphs and Explainable Artificial Intelligence on\nKnowledge Graphs. This leads to the introduction of a novel taxonomy for\nComprehensible Artificial Intelligence on Knowledge Graphs. In addition, a\ncomprehensive overview of the research on Comprehensible Artificial\nIntelligence on Knowledge Graphs is presented and put into the context of the\ntaxonomy. Finally, research gaps in the field of Comprehensible Artificial\nIntelligence on Knowledge Graphs are identified for future research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03499v1",
    "published_date": "2024-04-04 14:57:32 UTC",
    "updated_date": "2024-04-04 14:57:32 UTC"
  },
  {
    "arxiv_id": "2404.03493v3",
    "title": "A Methodology to Study the Impact of Spiking Neural Network Parameters considering Event-Based Automotive Data",
    "authors": [
      "Iqra Bano",
      "Rachmad Vidya Wicaksana Putra",
      "Alberto Marchisio",
      "Muhammad Shafique"
    ],
    "abstract": "Autonomous Driving (AD) systems are considered as the future of human\nmobility and transportation. Solving computer vision tasks such as image\nclassification and object detection/segmentation, with high accuracy and low\npower/energy consumption, is highly needed to realize AD systems in real life.\nThese requirements can potentially be satisfied by Spiking Neural Networks\n(SNNs). However, the state-of-the-art works in SNN-based AD systems still focus\non proposing network models that can achieve high accuracy, and they have not\nsystematically studied the roles of SNN parameters when used for learning\nevent-based automotive data. Therefore, we still lack understanding of how to\neffectively develop SNN models for AD systems. Toward this, we propose a novel\nmethodology to systematically study and analyze the impact of SNN parameters\nconsidering event-based automotive data, then leverage this analysis for\nenhancing SNN developments. To do this, we first explore different settings of\nSNN parameters that directly affect the learning mechanism (i.e., batch size,\nlearning rate, neuron threshold potential, and weight decay), then analyze the\naccuracy results. Afterward, we propose techniques that jointly improve SNN\naccuracy and reduce training time. Experimental results show that our\nmethodology can improve the SNN models for AD systems than the\nstate-of-the-art, as it achieves higher accuracy (i.e., 86%) for the NCARS\ndataset, and it can also achieve iso-accuracy (i.e., ~85% with standard\ndeviation less than 0.5%) while speeding up the training time by 1.9x. In this\nmanner, our research work provides a set of guidelines for SNN parameter\nenhancements, thereby enabling the practical developments of SNN-based AD\nsystems.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.NE",
    "comment": "To appear at the 18th International Conference on Control,\n  Automation, Robotics and Vision (ICARCV), December 2024, Dubai, UAE",
    "pdf_url": "http://arxiv.org/pdf/2404.03493v3",
    "published_date": "2024-04-04 14:48:26 UTC",
    "updated_date": "2024-09-13 10:42:00 UTC"
  },
  {
    "arxiv_id": "2404.03491v1",
    "title": "A Cause-Effect Look at Alleviating Hallucination of Knowledge-grounded Dialogue Generation",
    "authors": [
      "Jifan Yu",
      "Xiaohan Zhang",
      "Yifan Xu",
      "Xuanyu Lei",
      "Zijun Yao",
      "Jing Zhang",
      "Lei Hou",
      "Juanzi Li"
    ],
    "abstract": "Empowered by the large-scale pretrained language models, existing dialogue\nsystems have demonstrated impressive performance conducting fluent and\nnatural-sounding conversations. However, they are still plagued by the\nhallucination problem, causing unpredictable factual errors in the generated\nresponses. Recently, knowledge-grounded dialogue generation models, that\nintentionally invoke external knowledge resources to more informative\nresponses, are also proven to be effective in reducing hallucination. Following\nthe idea of getting high-quality knowledge, a few efforts have achieved pretty\ngood performance on this issue. As some inevitable knowledge noises may also\nlead to hallucinations, it is emergent to investigate the reason and future\ndirections for building noise-tolerant methods in KGD tasks. In this paper, we\nanalyze the causal story behind this problem with counterfactual reasoning\nmethods. Based on the causal effect analysis, we propose a possible solution\nfor alleviating the hallucination in KGD by exploiting the dialogue-knowledge\ninteraction. Experimental results of our example implementation show that this\nmethod can reduce hallucination without disrupting other dialogue performance,\nwhile keeping adaptive to different generation models. We hope our efforts can\nsupport and call for more attention to developing lightweight techniques\ntowards robust and trusty dialogue systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.03491v1",
    "published_date": "2024-04-04 14:45:26 UTC",
    "updated_date": "2024-04-04 14:45:26 UTC"
  },
  {
    "arxiv_id": "2404.03474v1",
    "title": "Performance of computer vision algorithms for fine-grained classification using crowdsourced insect images",
    "authors": [
      "Rita Pucci",
      "Vincent J. Kalkman",
      "Dan Stowell"
    ],
    "abstract": "With fine-grained classification, we identify unique characteristics to\ndistinguish among classes of the same super-class. We are focusing on species\nrecognition in Insecta, as they are critical for biodiversity monitoring and at\nthe base of many ecosystems. With citizen science campaigns, billions of images\nare collected in the wild. Once these are labelled, experts can use them to\ncreate distribution maps. However, the labelling process is time-consuming,\nwhich is where computer vision comes in. The field of computer vision offers a\nwide range of algorithms, each with its strengths and weaknesses; how do we\nidentify the algorithm that is in line with our application? To answer this\nquestion, we provide a full and detailed evaluation of nine algorithms among\ndeep convolutional networks (CNN), vision transformers (ViT), and\nlocality-based vision transformers (LBVT) on 4 different aspects:\nclassification performance, embedding quality, computational cost, and gradient\nactivity. We offer insights that we haven't yet had in this domain proving to\nwhich extent these algorithms solve the fine-grained tasks in Insecta. We found\nthat the ViT performs the best on inference speed and computational cost while\nthe LBVT outperforms the others on performance and embedding quality; the CNN\nprovide a trade-off among the metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03474v1",
    "published_date": "2024-04-04 14:26:58 UTC",
    "updated_date": "2024-04-04 14:26:58 UTC"
  },
  {
    "arxiv_id": "2404.03710v2",
    "title": "Self-organized free-flight arrival for urban air mobility",
    "authors": [
      "Martin Waltz",
      "Ostap Okhrin",
      "Michael Schultz"
    ],
    "abstract": "Urban air mobility is an innovative mode of transportation in which electric\nvertical takeoff and landing (eVTOL) vehicles operate between nodes called\nvertiports. We outline a self-organized vertiport arrival system based on deep\nreinforcement learning. The airspace around the vertiport is assumed to be\ncircular, and the vehicles can freely operate inside. Each aircraft is\nconsidered an individual agent and follows a shared policy, resulting in\ndecentralized actions that are based on local information. We investigate the\ndevelopment of the reinforcement learning policy during training and illustrate\nhow the algorithm moves from suboptimal local holding patterns to a safe and\nefficient final policy. The latter is validated in simulation-based scenarios,\nincluding robustness analyses against sensor noise and a changing distribution\nof inbound traffic. Lastly, we deploy the final policy on small-scale unmanned\naerial vehicles to showcase its real-world usability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03710v2",
    "published_date": "2024-04-04 13:43:17 UTC",
    "updated_date": "2024-08-08 09:03:51 UTC"
  },
  {
    "arxiv_id": "2404.03441v2",
    "title": "Benchmarking ChatGPT on Algorithmic Reasoning",
    "authors": [
      "Sean McLeish",
      "Avi Schwarzschild",
      "Tom Goldstein"
    ],
    "abstract": "We evaluate ChatGPT's ability to solve algorithm problems from the CLRS\nbenchmark suite that is designed for GNNs. The benchmark requires the use of a\nspecified classical algorithm to solve a given problem. We find that ChatGPT\noutperforms specialist GNN models, using Python to successfully solve these\nproblems. This raises new points in the discussion about learning algorithms\nwith neural networks and how we think about what out of distribution testing\nlooks like with web scale training data.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03441v2",
    "published_date": "2024-04-04 13:39:06 UTC",
    "updated_date": "2024-04-16 21:32:47 UTC"
  },
  {
    "arxiv_id": "2404.03425v7",
    "title": "ChangeMamba: Remote Sensing Change Detection With Spatiotemporal State Space Model",
    "authors": [
      "Hongruixuan Chen",
      "Jian Song",
      "Chengxi Han",
      "Junshi Xia",
      "Naoto Yokoya"
    ],
    "abstract": "Convolutional neural networks (CNN) and Transformers have made impressive\nprogress in the field of remote sensing change detection (CD). However, both\narchitectures have inherent shortcomings: CNN are constrained by a limited\nreceptive field that may hinder their ability to capture broader spatial\ncontexts, while Transformers are computationally intensive, making them costly\nto train and deploy on large datasets. Recently, the Mamba architecture, based\non state space models, has shown remarkable performance in a series of natural\nlanguage processing tasks, which can effectively compensate for the\nshortcomings of the above two architectures. In this paper, we explore for the\nfirst time the potential of the Mamba architecture for remote sensing CD tasks.\nWe tailor the corresponding frameworks, called MambaBCD, MambaSCD, and\nMambaBDA, for binary change detection (BCD), semantic change detection (SCD),\nand building damage assessment (BDA), respectively. All three frameworks adopt\nthe cutting-edge Visual Mamba architecture as the encoder, which allows full\nlearning of global spatial contextual information from the input images. For\nthe change decoder, which is available in all three architectures, we propose\nthree spatio-temporal relationship modeling mechanisms, which can be naturally\ncombined with the Mamba architecture and fully utilize its attribute to achieve\nspatio-temporal interaction of multi-temporal features, thereby obtaining\naccurate change information. On five benchmark datasets, our proposed\nframeworks outperform current CNN- and Transformer-based approaches without\nusing any complex training strategies or tricks, fully demonstrating the\npotential of the Mamba architecture in CD tasks. Further experiments show that\nour architecture is quite robust to degraded data. The source code will be\navailable in https://github.com/ChenHongruixuan/MambaCD",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted by IEEE TGRS: https://ieeexplore.ieee.org/document/10565926",
    "pdf_url": "http://arxiv.org/pdf/2404.03425v7",
    "published_date": "2024-04-04 13:06:25 UTC",
    "updated_date": "2024-12-30 06:28:34 UTC"
  },
  {
    "arxiv_id": "2404.03419v2",
    "title": "Integrating Hyperparameter Search into Model-Free AutoML with Context-Free Grammars",
    "authors": [
      "Hernn Ceferino Vzquez",
      "Jorge Sanchez",
      "Rafael Carrascosa"
    ],
    "abstract": "Automated Machine Learning (AutoML) has become increasingly popular in recent\nyears due to its ability to reduce the amount of time and expertise required to\ndesign and develop machine learning systems. This is very important for the\npractice of machine learning, as it allows building strong baselines quickly,\nimproving the efficiency of the data scientists, and reducing the time to\nproduction. However, despite the advantages of AutoML, it faces several\nchallenges, such as defining the solutions space and exploring it efficiently.\nRecently, some approaches have been shown to be able to do it using tree-based\nsearch algorithms and context-free grammars. In particular, GramML presents a\nmodel-free reinforcement learning approach that leverages pipeline\nconfiguration grammars and operates using Monte Carlo tree search. However, one\nof the limitations of GramML is that it uses default hyperparameters, limiting\nthe search problem to finding optimal pipeline structures for the available\ndata preprocessors and models. In this work, we propose an extension to GramML\nthat supports larger search spaces including hyperparameter search. We\nevaluated the approach using an OpenML benchmark and found significant\nimprovements compared to other state-of-the-art techniques.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03419v2",
    "published_date": "2024-04-04 12:54:13 UTC",
    "updated_date": "2024-04-13 14:57:37 UTC"
  },
  {
    "arxiv_id": "2404.03418v3",
    "title": "Permissible Knowledge Pooling",
    "authors": [
      "Huimin Dong"
    ],
    "abstract": "Information pooling has been extensively formalised across various logical\nframeworks in distributed systems, characterized by diverse information-sharing\npatterns. These approaches generally adopt an intersection perspective,\naggregating all possible information, regardless of whether it is known or\nunknown to the agents. In contrast, this work adopts a unique stance,\nemphasising that sharing knowledge means distributing what is known, rather\nthan what remains uncertain. This paper introduces new modal logics for\nknowledge pooling and sharing, ranging from a novel language of knowledge\npooling to a dynamic mechanism for knowledge sharing. It also outlines their\naxiomatizations and discusses a potential framework for permissible knowledge\npooling.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03418v3",
    "published_date": "2024-04-04 12:51:28 UTC",
    "updated_date": "2024-05-15 21:05:03 UTC"
  },
  {
    "arxiv_id": "2404.03414v1",
    "title": "Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought",
    "authors": [
      "Jooyoung Lee",
      "Fan Yang",
      "Thanh Tran",
      "Qian Hu",
      "Emre Barut",
      "Kai-Wei Chang",
      "Chengwei Su"
    ],
    "abstract": "We introduce a novel framework, LM-Guided CoT, that leverages a lightweight\n(i.e., <1B) language model (LM) for guiding a black-box large (i.e., >10B) LM\nin reasoning tasks. Specifically, the lightweight LM first generates a\nrationale for each input instance. The Frozen large LM is then prompted to\npredict a task output based on the rationale generated by the lightweight LM.\nOur approach is resource-efficient in the sense that it only requires training\nthe lightweight LM. We optimize the model through 1) knowledge distillation and\n2) reinforcement learning from rationale-oriented and task-oriented reward\nsignals. We assess our method with multi-hop extractive question answering (QA)\nbenchmarks, HotpotQA, and 2WikiMultiHopQA. Experimental results show that our\napproach outperforms all baselines regarding answer prediction accuracy. We\nalso find that reinforcement learning helps the model to produce higher-quality\nrationales with improved QA performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper is accepted to LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.03414v1",
    "published_date": "2024-04-04 12:46:37 UTC",
    "updated_date": "2024-04-04 12:46:37 UTC"
  },
  {
    "arxiv_id": "2404.03709v1",
    "title": "Proceedings 12th International Workshop on Theorem proving components for Educational software",
    "authors": [
      "Julien Narboux",
      "Walther Neuper",
      "Pedro Quaresma"
    ],
    "abstract": "The ThEdu series pursues the smooth transition from an intuitive way of doing\nmathematics at secondary school to a more formal approach to the subject in\nSTEM education, while favouring software support for this transition by\nexploiting the power of theorem-proving technologies. What follows is a brief\ndescription of how the present volume contributes to this enterprise.\n  The 12th International Workshop on Theorem Proving Components for Educational\nSoftware(ThEdu'23), was a satellite event of the 29th international Conference\non Automated Deduction (CADE 2023), July 1-4, 2023, Rome, Italy. ThEdu'23 was\nvery successful, with one invited talk, by Yves Bertot (Inria, France), \"The\nchallenges of using Type Theory to teach Mathematics\", and seven regular\ncontributions. An open call for papers was then issued, to which eight\ncontributions were submitted. Seven submissions have been accepted by our\nreviewers, who jointly produced at least three careful reports on each of the\ncontributions. The resulting revised papers are collected in the present\nvolume.\n  We, the volume editors, hope that this collection of papers will further\npromote the development of theorem-proving based software, and that it will\nallow to improve the mutual understanding between computer scientists,\nmathematicians and stakeholders in education.\n  PC Chairs:Julien Narboux (University of Strasbourg, France); Walther Neuper\n(JKU, Johannes Kepler University, Linz, Austria); Pedro Quaresma (University of\nCoimbra, Portugal)",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03709v1",
    "published_date": "2024-04-04 11:51:26 UTC",
    "updated_date": "2024-04-04 11:51:26 UTC"
  },
  {
    "arxiv_id": "2404.03386v1",
    "title": "SENSOR: Imitate Third-Person Expert's Behaviors via Active Sensoring",
    "authors": [
      "Kaichen Huang",
      "Minghao Shao",
      "Shenghua Wan",
      "Hai-Hang Sun",
      "Shuai Feng",
      "Le Gan",
      "De-Chuan Zhan"
    ],
    "abstract": "In many real-world visual Imitation Learning (IL) scenarios, there is a\nmisalignment between the agent's and the expert's perspectives, which might\nlead to the failure of imitation. Previous methods have generally solved this\nproblem by domain alignment, which incurs extra computation and storage costs,\nand these methods fail to handle the \\textit{hard cases} where the viewpoint\ngap is too large. To alleviate the above problems, we introduce active\nsensoring in the visual IL setting and propose a model-based SENSory imitatOR\n(SENSOR) to automatically change the agent's perspective to match the expert's.\nSENSOR jointly learns a world model to capture the dynamics of latent states, a\nsensor policy to control the camera, and a motor policy to control the agent.\nExperiments on visual locomotion tasks show that SENSOR can efficiently\nsimulate the expert's perspective and strategy, and outperforms most baseline\nmethods.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03386v1",
    "published_date": "2024-04-04 11:37:55 UTC",
    "updated_date": "2024-04-04 11:37:55 UTC"
  },
  {
    "arxiv_id": "2405.01563v1",
    "title": "Mitigating LLM Hallucinations via Conformal Abstention",
    "authors": [
      "Yasin Abbasi Yadkori",
      "Ilja Kuzborskij",
      "David Stutz",
      "Andrs Gyrgy",
      "Adam Fisch",
      "Arnaud Doucet",
      "Iuliya Beloshapka",
      "Wei-Hung Weng",
      "Yao-Yuan Yang",
      "Csaba Szepesvri",
      "Ali Taylan Cemgil",
      "Nenad Tomasev"
    ],
    "abstract": "We develop a principled procedure for determining when a large language model\n(LLM) should abstain from responding (e.g., by saying \"I don't know\") in a\ngeneral domain, instead of resorting to possibly \"hallucinating\" a non-sensical\nor incorrect answer. Building on earlier approaches that use self-consistency\nas a more reliable measure of model confidence, we propose using the LLM itself\nto self-evaluate the similarity between each of its sampled responses for a\ngiven query. We then further leverage conformal prediction techniques to\ndevelop an abstention procedure that benefits from rigorous theoretical\nguarantees on the hallucination rate (error rate). Experimentally, our\nresulting conformal abstention method reliably bounds the hallucination rate on\nvarious closed-book, open-domain generative question answering datasets, while\nalso maintaining a significantly less conservative abstention rate on a dataset\nwith long responses (Temporal Sequences) compared to baselines using\nlog-probability scores to quantify uncertainty, while achieveing comparable\nperformance on a dataset with short answers (TriviaQA). To evaluate the\nexperiments automatically, one needs to determine if two responses are\nequivalent given a question. Following standard practice, we use a thresholded\nsimilarity function to determine if two responses match, but also provide a\nmethod for calibrating the threshold based on conformal prediction, with\ntheoretical guarantees on the accuracy of the match prediction, which might be\nof independent interest.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.01563v1",
    "published_date": "2024-04-04 11:32:03 UTC",
    "updated_date": "2024-04-04 11:32:03 UTC"
  },
  {
    "arxiv_id": "2404.03382v1",
    "title": "DIDA: Denoised Imitation Learning based on Domain Adaptation",
    "authors": [
      "Kaichen Huang",
      "Hai-Hang Sun",
      "Shenghua Wan",
      "Minghao Shao",
      "Shuai Feng",
      "Le Gan",
      "De-Chuan Zhan"
    ],
    "abstract": "Imitating skills from low-quality datasets, such as sub-optimal\ndemonstrations and observations with distractors, is common in real-world\napplications. In this work, we focus on the problem of Learning from Noisy\nDemonstrations (LND), where the imitator is required to learn from data with\nnoise that often occurs during the processes of data collection or\ntransmission. Previous IL methods improve the robustness of learned policies by\ninjecting an adversarially learned Gaussian noise into pure expert data or\nutilizing additional ranking information, but they may fail in the LND setting.\nTo alleviate the above problems, we propose Denoised Imitation learning based\non Domain Adaptation (DIDA), which designs two discriminators to distinguish\nthe noise level and expertise level of data, facilitating a feature encoder to\nlearn task-related but domain-agnostic representations. Experiment results on\nMuJoCo demonstrate that DIDA can successfully handle challenging imitation\ntasks from demonstrations with various types of noise, outperforming most\nbaseline methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03382v1",
    "published_date": "2024-04-04 11:29:05 UTC",
    "updated_date": "2024-04-04 11:29:05 UTC"
  },
  {
    "arxiv_id": "2404.03359v1",
    "title": "REACT: Revealing Evolutionary Action Consequence Trajectories for Interpretable Reinforcement Learning",
    "authors": [
      "Philipp Altmann",
      "Cline Davignon",
      "Maximilian Zorn",
      "Fabian Ritz",
      "Claudia Linnhoff-Popien",
      "Thomas Gabor"
    ],
    "abstract": "To enhance the interpretability of Reinforcement Learning (RL), we propose\nRevealing Evolutionary Action Consequence Trajectories (REACT). In contrast to\nthe prevalent practice of validating RL models based on their optimal behavior\nlearned during training, we posit that considering a range of edge-case\ntrajectories provides a more comprehensive understanding of their inherent\nbehavior. To induce such scenarios, we introduce a disturbance to the initial\nstate, optimizing it through an evolutionary algorithm to generate a diverse\npopulation of demonstrations. To evaluate the fitness of trajectories, REACT\nincorporates a joint fitness function that encourages both local and global\ndiversity in the encountered states and chosen actions. Through assessments\nwith policies trained for varying durations in discrete and continuous\nenvironments, we demonstrate the descriptive power of REACT. Our results\nhighlight its effectiveness in revealing nuanced aspects of RL models' behavior\nbeyond optimal performance, thereby contributing to improved interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.03359v1",
    "published_date": "2024-04-04 10:56:30 UTC",
    "updated_date": "2024-04-04 10:56:30 UTC"
  },
  {
    "arxiv_id": "2404.03707v1",
    "title": "Investigating the Robustness of Counterfactual Learning to Rank Models: A Reproducibility Study",
    "authors": [
      "Zechun Niu",
      "Jiaxin Mao",
      "Qingyao Ai",
      "Ji-Rong Wen"
    ],
    "abstract": "Counterfactual learning to rank (CLTR) has attracted extensive attention in\nthe IR community for its ability to leverage massive logged user interaction\ndata to train ranking models. While the CLTR models can be theoretically\nunbiased when the user behavior assumption is correct and the propensity\nestimation is accurate, their effectiveness is usually empirically evaluated\nvia simulation-based experiments due to a lack of widely-available,\nlarge-scale, real click logs. However, the mainstream simulation-based\nexperiments are somewhat limited as they often feature a single, deterministic\nproduction ranker and simplified user simulation models to generate the\nsynthetic click logs. As a result, the robustness of CLTR models in complex and\ndiverse situations is largely unknown and needs further investigation.\n  To address this problem, in this paper, we aim to investigate the robustness\nof existing CLTR models in a reproducibility study with extensive\nsimulation-based experiments that (1) use both deterministic and stochastic\nproduction rankers, each with different ranking performance, and (2) leverage\nmultiple user simulation models with different user behavior assumptions. We\nfind that the DLA models and IPS-DCM show better robustness under various\nsimulation settings than IPS-PBM and PRS with offline propensity estimation.\nBesides, the existing CLTR models often fail to outperform the naive click\nbaselines when the production ranker has relatively high ranking performance or\ncertain randomness, which suggests an urgent need for developing new CLTR\nalgorithms that work for these settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03707v1",
    "published_date": "2024-04-04 10:54:38 UTC",
    "updated_date": "2024-04-04 10:54:38 UTC"
  },
  {
    "arxiv_id": "2404.03354v2",
    "title": "A Comprehensive Survey on Self-Supervised Learning for Recommendation",
    "authors": [
      "Xubin Ren",
      "Wei Wei",
      "Lianghao Xia",
      "Chao Huang"
    ],
    "abstract": "Recommender systems play a crucial role in tackling the challenge of\ninformation overload by delivering personalized recommendations based on\nindividual user preferences. Deep learning techniques, such as RNNs, GNNs, and\nTransformer architectures, have significantly propelled the advancement of\nrecommender systems by enhancing their comprehension of user behaviors and\npreferences. However, supervised learning methods encounter challenges in\nreal-life scenarios due to data sparsity, resulting in limitations in their\nability to learn representations effectively. To address this, self-supervised\nlearning (SSL) techniques have emerged as a solution, leveraging inherent data\nstructures to generate supervision signals without relying solely on labeled\ndata. By leveraging unlabeled data and extracting meaningful representations,\nrecommender systems utilizing SSL can make accurate predictions and\nrecommendations even when confronted with data sparsity. In this paper, we\nprovide a comprehensive review of self-supervised learning frameworks designed\nfor recommender systems, encompassing a thorough analysis of over 170 papers.\nWe conduct an exploration of nine distinct scenarios, enabling a comprehensive\nunderstanding of SSL-enhanced recommenders in different contexts. For each\ndomain, we elaborate on different self-supervised learning paradigms, namely\ncontrastive learning, generative learning, and adversarial learning, so as to\npresent technical details of how SSL enhances recommender systems in various\ncontexts. We consistently maintain the related open-source materials at\nhttps://github.com/HKUDS/Awesome-SSLRec-Papers.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03354v2",
    "published_date": "2024-04-04 10:45:23 UTC",
    "updated_date": "2024-04-07 05:57:45 UTC"
  },
  {
    "arxiv_id": "2404.03348v2",
    "title": "Knowledge Distillation-Based Model Extraction Attack using GAN-based Private Counterfactual Explanations",
    "authors": [
      "Fatima Ezzeddine",
      "Omran Ayoub",
      "Silvia Giordano"
    ],
    "abstract": "In recent years, there has been a notable increase in the deployment of\nmachine learning (ML) models as services (MLaaS) across diverse production\nsoftware applications. In parallel, explainable AI (XAI) continues to evolve,\naddressing the necessity for transparency and trustworthiness in ML models. XAI\ntechniques aim to enhance the transparency of ML models by providing insights,\nin terms of model's explanations, into their decision-making process.\nSimultaneously, some MLaaS platforms now offer explanations alongside the ML\nprediction outputs. This setup has elevated concerns regarding vulnerabilities\nin MLaaS, particularly in relation to privacy leakage attacks such as model\nextraction attacks (MEA). This is due to the fact that explanations can unveil\ninsights about the inner workings of the model which could be exploited by\nmalicious users. In this work, we focus on investigating how model\nexplanations, particularly counterfactual explanations (CFs), can be exploited\nfor performing MEA within the MLaaS platform. We also delve into assessing the\neffectiveness of incorporating differential privacy (DP) as a mitigation\nstrategy. To this end, we first propose a novel approach for MEA based on\nKnowledge Distillation (KD) to enhance the efficiency of extracting a\nsubstitute model of a target model exploiting CFs, without any knowledge about\nthe training data distribution by the attacker. Then, we advise an approach for\ntraining CF generators incorporating DP to generate private CFs. We conduct\nthorough experimental evaluations on real-world datasets and demonstrate that\nour proposed KD-based MEA can yield a high-fidelity substitute model with a\nreduced number of queries with respect to baseline approaches. Furthermore, our\nfindings reveal that including a privacy layer can allow mitigating the MEA.\nHowever, on the account of the quality of CFs, impacts the performance of the\nexplanations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.03348v2",
    "published_date": "2024-04-04 10:28:55 UTC",
    "updated_date": "2024-10-22 09:31:49 UTC"
  },
  {
    "arxiv_id": "2404.15320v2",
    "title": "Using Large Language Models to Enrich the Documentation of Datasets for Machine Learning",
    "authors": [
      "Joan Giner-Miguelez",
      "Abel Gmez",
      "Jordi Cabot"
    ],
    "abstract": "Recent regulatory initiatives like the European AI Act and relevant voices in\nthe Machine Learning (ML) community stress the need to describe datasets along\nseveral key dimensions for trustworthy AI, such as the provenance processes and\nsocial concerns. However, this information is typically presented as\nunstructured text in accompanying documentation, hampering their automated\nanalysis and processing. In this work, we explore using large language models\n(LLM) and a set of prompting strategies to automatically extract these\ndimensions from documents and enrich the dataset description with them. Our\napproach could aid data publishers and practitioners in creating\nmachine-readable documentation to improve the discoverability of their\ndatasets, assess their compliance with current AI regulations, and improve the\noverall quality of ML models trained on them.\n  In this paper, we evaluate the approach on 12 scientific dataset papers\npublished in two scientific journals (Nature's Scientific Data and Elsevier's\nData in Brief) using two different LLMs (GPT3.5 and Flan-UL2). Results show\ngood accuracy with our prompt extraction strategies. Concrete results vary\ndepending on the dimensions, but overall, GPT3.5 shows slightly better accuracy\n(81,21%) than FLAN-UL2 (69,13%) although it is more prone to hallucinations. We\nhave released an open-source tool implementing our approach and a replication\npackage, including the experiments' code and results, in an open-source\nrepository.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.CL",
      "H.4.4"
    ],
    "primary_category": "cs.DL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15320v2",
    "published_date": "2024-04-04 10:09:28 UTC",
    "updated_date": "2024-05-24 11:25:49 UTC"
  },
  {
    "arxiv_id": "2404.03325v2",
    "title": "Embodied Neuromorphic Artificial Intelligence for Robotics: Perspectives, Challenges, and Research Development Stack",
    "authors": [
      "Rachmad Vidya Wicaksana Putra",
      "Alberto Marchisio",
      "Fakhreddine Zayer",
      "Jorge Dias",
      "Muhammad Shafique"
    ],
    "abstract": "Robotic technologies have been an indispensable part for improving human\nproductivity since they have been helping humans in completing diverse,\ncomplex, and intensive tasks in a fast yet accurate and efficient way.\nTherefore, robotic technologies have been deployed in a wide range of\napplications, ranging from personal to industrial use-cases. However, current\nrobotic technologies and their computing paradigm still lack embodied\nintelligence to efficiently interact with operational environments, respond\nwith correct/expected actions, and adapt to changes in the environments. Toward\nthis, recent advances in neuromorphic computing with Spiking Neural Networks\n(SNN) have demonstrated the potential to enable the embodied intelligence for\nrobotics through bio-plausible computing paradigm that mimics how the\nbiological brain works, known as \"neuromorphic artificial intelligence (AI)\".\nHowever, the field of neuromorphic AI-based robotics is still at an early\nstage, therefore its development and deployment for solving real-world problems\nexpose new challenges in different design aspects, such as accuracy,\nadaptability, efficiency, reliability, and security. To address these\nchallenges, this paper will discuss how we can enable embodied neuromorphic AI\nfor robotic systems through our perspectives: (P1) Embodied intelligence based\non effective learning rule, training mechanism, and adaptability; (P2)\nCross-layer optimizations for energy-efficient neuromorphic computing; (P3)\nRepresentative and fair benchmarks; (P4) Low-cost reliability and safety\nenhancements; (P5) Security and privacy for neuromorphic computing; and (P6) A\nsynergistic development for energy-efficient and robust neuromorphic-based\nrobotics. Furthermore, this paper identifies research challenges and\nopportunities, as well as elaborates our vision for future research development\ntoward embodied neuromorphic AI for robotics.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.RO",
    "comment": "To appear at the 18th International Conference on Control,\n  Automation, Robotics and Vision (ICARCV), December 2024, Dubai, UAE",
    "pdf_url": "http://arxiv.org/pdf/2404.03325v2",
    "published_date": "2024-04-04 09:52:22 UTC",
    "updated_date": "2024-09-12 14:18:26 UTC"
  },
  {
    "arxiv_id": "2404.03323v1",
    "title": "Sparse Concept Bottleneck Models: Gumbel Tricks in Contrastive Learning",
    "authors": [
      "Andrei Semenov",
      "Vladimir Ivanov",
      "Aleksandr Beznosikov",
      "Alexander Gasnikov"
    ],
    "abstract": "We propose a novel architecture and method of explainable classification with\nConcept Bottleneck Models (CBMs). While SOTA approaches to Image Classification\ntask work as a black box, there is a growing demand for models that would\nprovide interpreted results. Such a models often learn to predict the\ndistribution over class labels using additional description of this target\ninstances, called concepts. However, existing Bottleneck methods have a number\nof limitations: their accuracy is lower than that of a standard model and CBMs\nrequire an additional set of concepts to leverage. We provide a framework for\ncreating Concept Bottleneck Model from pre-trained multi-modal encoder and new\nCLIP-like architectures. By introducing a new type of layers known as Concept\nBottleneck Layers, we outline three methods for training them: with\n$\\ell_1$-loss, contrastive loss and loss function based on Gumbel-Softmax\ndistribution (Sparse-CBM), while final FC layer is still trained with\nCross-Entropy. We show a significant increase in accuracy using sparse hidden\nlayers in CLIP-based bottleneck models. Which means that sparse representation\nof concepts activation vector is meaningful in Concept Bottleneck Models.\nMoreover, with our Concept Matrix Search algorithm we can improve CLIP\npredictions on complex datasets without any additional training or fine-tuning.\nThe code is available at: https://github.com/Andron00e/SparseCBM.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.6, I.2.10, I.4.10, I.5.1, I.5.4, I.5.5",
      "I.2.6; I.2.10; I.4.10; I.5.1; I.5.4; I.5.5"
    ],
    "primary_category": "cs.CV",
    "comment": "23 pages, 1 algorithm, 36 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.03323v1",
    "published_date": "2024-04-04 09:43:43 UTC",
    "updated_date": "2024-04-04 09:43:43 UTC"
  },
  {
    "arxiv_id": "2404.03704v1",
    "title": "Improvement of Performance in Freezing of Gait detection in Parkinsons Disease using Transformer networks and a single waist worn triaxial accelerometer",
    "authors": [
      "Luis Sigcha",
      "Luigi Borz",
      "Ignacio Pavn",
      "Nlson Costa",
      "Susana Costa",
      "Pedro Arezes",
      "Juan-Manuel Lpez",
      "Guillermo De Arcas"
    ],
    "abstract": "Freezing of gait (FOG) is one of the most incapacitating symptoms in\nParkinsons disease, affecting more than 50 percent of patients in advanced\nstages of the disease. The presence of FOG may lead to falls and a loss of\nindependence with a consequent reduction in the quality of life. Wearable\ntechnology and artificial intelligence have been used for automatic FOG\ndetection to optimize monitoring. However, differences between laboratory and\ndaily-life conditions present challenges for the implementation of reliable\ndetection systems. Consequently, improvement of FOG detection methods remains\nimportant to provide accurate monitoring mechanisms intended for free-living\nand real-time use. This paper presents advances in automatic FOG detection\nusing a single body-worn triaxial accelerometer and a novel classification\nalgorithm based on Transformers and convolutional networks. This study was\nperformed with data from 21 patients who manifested FOG episodes while\nperforming activities of daily living in a home setting. Results indicate that\nthe proposed FOG-Transformer can bring a significant improvement in FOG\ndetection using leave-one-subject-out cross-validation (LOSO CV). These results\nbring opportunities for the implementation of accurate monitoring systems for\nuse in ambulatory or home settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03704v1",
    "published_date": "2024-04-04 09:02:17 UTC",
    "updated_date": "2024-04-04 09:02:17 UTC"
  },
  {
    "arxiv_id": "2404.03304v3",
    "title": "Concept -- An Evaluation Protocol on Conversational Recommender Systems with System-centric and User-centric Factors",
    "authors": [
      "Chen Huang",
      "Peixin Qin",
      "Yang Deng",
      "Wenqiang Lei",
      "Jiancheng Lv",
      "Tat-Seng Chua"
    ],
    "abstract": "The conversational recommendation system (CRS) has been criticized regarding\nits user experience in real-world scenarios, despite recent significant\nprogress achieved in academia. Existing evaluation protocols for CRS may\nprioritize system-centric factors such as effectiveness and fluency in\nconversation while neglecting user-centric aspects. Thus, we propose a new and\ninclusive evaluation protocol, Concept, which integrates both system- and\nuser-centric factors. We conceptualise three key characteristics in\nrepresenting such factors and further divide them into six primary abilities.\nTo implement Concept, we adopt a LLM-based user simulator and evaluator with\nscoring rubrics that are tailored for each primary ability. Our protocol,\nConcept, serves a dual purpose. First, it provides an overview of the pros and\ncons in current CRS models. Second, it pinpoints the problem of low usability\nin the \"omnipotent\" ChatGPT and offers a comprehensive reference guide for\nevaluating CRS, thereby setting the foundation for CRS improvement.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "33 pages, 18 tables, and 10 figures. Our code is available at\n  https://github.com/huangzichun/Concept4CRS",
    "pdf_url": "http://arxiv.org/pdf/2404.03304v3",
    "published_date": "2024-04-04 08:56:48 UTC",
    "updated_date": "2024-05-06 12:44:34 UTC"
  },
  {
    "arxiv_id": "2404.04293v1",
    "title": "Reason from Fallacy: Enhancing Large Language Models' Logical Reasoning through Logical Fallacy Understanding",
    "authors": [
      "Yanda Li",
      "Dixuan Wang",
      "Jiaqing Liang",
      "Guochao Jiang",
      "Qianyu He",
      "Yanghua Xiao",
      "Deqing Yang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated good performance in many\nreasoning tasks, but they still struggle with some complicated reasoning tasks\nincluding logical reasoning. One non-negligible reason for LLMs' suboptimal\nperformance on logical reasoning is their overlooking of understanding logical\nfallacies correctly. To evaluate LLMs' capability of logical fallacy\nunderstanding (LFU), we propose five concrete tasks from three cognitive\ndimensions of WHAT, WHY, and HOW in this paper. Towards these LFU tasks, we\nhave successfully constructed a new dataset LFUD based on GPT-4 accompanied by\na little human effort. Our extensive experiments justify that our LFUD can be\nused not only to evaluate LLMs' LFU capability, but also to fine-tune LLMs to\nobtain significantly enhanced performance on logical reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04293v1",
    "published_date": "2024-04-04 08:38:03 UTC",
    "updated_date": "2024-04-04 08:38:03 UTC"
  },
  {
    "arxiv_id": "2404.03276v1",
    "title": "A Deep Reinforcement Learning Approach for Security-Aware Service Acquisition in IoT",
    "authors": [
      "Marco Arazzi",
      "Serena Nicolazzo",
      "Antonino Nocera"
    ],
    "abstract": "The novel Internet of Things (IoT) paradigm is composed of a growing number\nof heterogeneous smart objects and services that are transforming architectures\nand applications, increasing systems' complexity, and the need for reliability\nand autonomy. In this context, both smart objects and services are often\nprovided by third parties which do not give full transparency regarding the\nsecurity and privacy of the features offered. Although machine-based Service\nLevel Agreements (SLA) have been recently leveraged to establish and share\npolicies in Cloud-based scenarios, and also in the IoT context, the issue of\nmaking end users aware of the overall system security levels and the\nfulfillment of their privacy requirements through the provision of the\nrequested service remains a challenging task. To tackle this problem, we\npropose a complete framework that defines suitable levels of privacy and\nsecurity requirements in the acquisition of services in IoT, according to the\nuser needs. Through the use of a Reinforcement Learning based solution, a user\nagent, inside the environment, is trained to choose the best smart objects\ngranting access to the target services. Moreover, the solution is designed to\nguarantee deadline requirements and user security and privacy needs. Finally,\nto evaluate the correctness and the performance of the proposed approach we\nillustrate an extensive experimental analysis.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03276v1",
    "published_date": "2024-04-04 08:00:12 UTC",
    "updated_date": "2024-04-04 08:00:12 UTC"
  },
  {
    "arxiv_id": "2404.03275v3",
    "title": "DELTA: Decomposed Efficient Long-Term Robot Task Planning using Large Language Models",
    "authors": [
      "Yuchen Liu",
      "Luigi Palmieri",
      "Sebastian Koch",
      "Ilche Georgievski",
      "Marco Aiello"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have sparked a revolution\nacross many research fields. In robotics, the integration of common-sense\nknowledge from LLMs into task and motion planning has drastically advanced the\nfield by unlocking unprecedented levels of context awareness. Despite their\nvast collection of knowledge, large language models may generate infeasible\nplans due to hallucinations or missing domain information. To address these\nchallenges and improve plan feasibility and computational efficiency, we\nintroduce DELTA, a novel LLM-informed task planning approach. By using scene\ngraphs as environment representations within LLMs, DELTA achieves rapid\ngeneration of precise planning problem descriptions. To enhance planning\nperformance, DELTA decomposes long-term task goals with LLMs into an\nautoregressive sequence of sub-goals, enabling automated task planners to\nefficiently solve complex problems. In our extensive evaluation, we show that\nDELTA enables an efficient and fully automatic task planning pipeline,\nachieving higher planning success rates and significantly shorter planning\ntimes compared to the state of the art. Project webpage:\nhttps://delta-llm.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted at ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2404.03275v3",
    "published_date": "2024-04-04 07:59:24 UTC",
    "updated_date": "2025-04-01 14:33:53 UTC"
  },
  {
    "arxiv_id": "2404.03703v3",
    "title": "Mitigating analytical variability in fMRI results with style transfer",
    "authors": [
      "Elodie Germani",
      "Camille Maumet",
      "Elisa Fromont"
    ],
    "abstract": "We propose a novel approach to improve the reproducibility of neuroimaging\nresults by converting statistic maps across different functional MRI pipelines.\nWe make the assumption that pipelines used to compute fMRI statistic maps can\nbe considered as a style component and we propose to use different generative\nmodels, among which, Generative Adversarial Networks (GAN) and Diffusion Models\n(DM) to convert statistic maps across different pipelines. We explore the\nperformance of multiple GAN frameworks, and design a new DM framework for\nunsupervised multi-domain styletransfer. We constrain the generation of 3D fMRI\nstatistic maps using the latent space of an auxiliary classifier that\ndistinguishes statistic maps from different pipelines and extend traditional\nsampling techniques used in DM to improve the transition performance. Our\nexperiments demonstrate that our proposed methods aresuccessful: pipelines can\nindeed be transferred as a style component, providing animportant source of\ndata augmentation for future medical studies.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03703v3",
    "published_date": "2024-04-04 07:49:39 UTC",
    "updated_date": "2025-01-17 09:03:57 UTC"
  },
  {
    "arxiv_id": "2404.03264v1",
    "title": "Foundation Model for Advancing Healthcare: Challenges, Opportunities, and Future Directions",
    "authors": [
      "Yuting He",
      "Fuxiang Huang",
      "Xinrui Jiang",
      "Yuxiang Nie",
      "Minghao Wang",
      "Jiguang Wang",
      "Hao Chen"
    ],
    "abstract": "Foundation model, which is pre-trained on broad data and is able to adapt to\na wide range of tasks, is advancing healthcare. It promotes the development of\nhealthcare artificial intelligence (AI) models, breaking the contradiction\nbetween limited AI models and diverse healthcare practices. Much more\nwidespread healthcare scenarios will benefit from the development of a\nhealthcare foundation model (HFM), improving their advanced intelligent\nhealthcare services. Despite the impending widespread deployment of HFMs, there\nis currently a lack of clear understanding about how they work in the\nhealthcare field, their current challenges, and where they are headed in the\nfuture. To answer these questions, a comprehensive and deep survey of the\nchallenges, opportunities, and future directions of HFMs is presented in this\nsurvey. It first conducted a comprehensive overview of the HFM including the\nmethods, data, and applications for a quick grasp of the current progress.\nThen, it made an in-depth exploration of the challenges present in data,\nalgorithms, and computing infrastructures for constructing and widespread\napplication of foundation models in healthcare. This survey also identifies\nemerging and promising directions in this field for future development. We\nbelieve that this survey will enhance the community's comprehension of the\ncurrent progress of HFM and serve as a valuable source of guidance for future\ndevelopment in this field. The latest HFM papers and related resources are\nmaintained on our website:\nhttps://github.com/YutingHe-list/Awesome-Foundation-Models-for-Advancing-Healthcare.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03264v1",
    "published_date": "2024-04-04 07:39:55 UTC",
    "updated_date": "2024-04-04 07:39:55 UTC"
  },
  {
    "arxiv_id": "2404.03263v2",
    "title": "On the Surprising Efficacy of Distillation as an Alternative to Pre-Training Small Models",
    "authors": [
      "Sean Farhat",
      "Deming Chen"
    ],
    "abstract": "In this paper, we propose that small models may not need to absorb the cost\nof pre-training to reap its benefits. Instead, they can capitalize on the\nastonishing results achieved by modern, enormous models to a surprising degree.\nWe observe that, when distilled on a task from a pre-trained teacher model, a\nsmall model can achieve or surpass the performance it would achieve if it was\npre-trained then finetuned on that task. To allow this phenomenon to be easily\nleveraged, we establish a connection reducing knowledge distillation to modern\ncontrastive learning, opening two doors: (1) vastly different model\narchitecture pairings can work for the distillation, and (2) most contrastive\nlearning algorithms rooted in the theory of Noise Contrastive Estimation can be\neasily applied and used. We demonstrate this paradigm using pre-trained teacher\nmodels from open-source model hubs, Transformer and convolution based model\ncombinations, and a novel distillation algorithm that massages the\nAlignment/Uniformity perspective of contrastive learning by Wang & Isola (2020)\ninto a distillation objective. We choose this flavor of contrastive learning\ndue to its low computational cost, an overarching theme of this work. We also\nobserve that this phenomenon tends not to occur if the task is data-limited.\nHowever, this can be alleviated by leveraging yet another scale-inspired\ndevelopment: large, pre-trained generative models for dataset augmentation.\nAgain, we use an open-source model, and our rudimentary prompts are sufficient\nto boost the small model`s performance. Thus, we highlight a training method\nfor small models that is up to 94% faster than the standard pre-training\nparadigm without sacrificing performance. For practitioners discouraged from\nfully utilizing modern foundation datasets for their small models due to the\nprohibitive scale, we believe our work keeps that door open.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2024. 5th Workshop on Practical ML for Low Resource Settings\n  (PML4LRS). Code can be found at https://github.com/sfarhat/dapt",
    "pdf_url": "http://arxiv.org/pdf/2404.03263v2",
    "published_date": "2024-04-04 07:38:11 UTC",
    "updated_date": "2024-05-03 06:08:30 UTC"
  },
  {
    "arxiv_id": "2404.03259v3",
    "title": "Advancing Aspect-Based Sentiment Analysis through Deep Learning Models",
    "authors": [
      "Chen Li",
      "Huidong Tang",
      "Jinli Zhang",
      "Xiujing Guo",
      "Debo Cheng",
      "Yasuhiko Morimoto"
    ],
    "abstract": "Aspect-based sentiment analysis predicts sentiment polarity with fine\ngranularity. While graph convolutional networks (GCNs) are widely utilized for\nsentimental feature extraction, their naive application for syntactic feature\nextraction can compromise information preservation. This study introduces an\ninnovative edge-enhanced GCN, named SentiSys, to navigate the syntactic graph\nwhile preserving intact feature information, leading to enhanced performance.\nSpecifically,we first integrate a bidirectional long short-term memory\n(Bi-LSTM) network and a self-attention-based transformer. This combination\nfacilitates effective text encoding, preventing the loss of information and\npredicting long dependency text. A bidirectional GCN (Bi-GCN) with message\npassing is then employed to encode relationships between entities.\nAdditionally, unnecessary information is filtered out using an aspect-specific\nmasking technique. To validate the effectiveness of our proposed model, we\nconduct extensive evaluation experiments on four benchmark datasets. The\nexperimental results demonstrate enhanced performance in aspect-based sentiment\nanalysis with the use of SentiSys.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper has already been accepted by the 20th International\n  Conference on Advanced Data Mining and Applications (ADMA2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.03259v3",
    "published_date": "2024-04-04 07:31:56 UTC",
    "updated_date": "2024-09-09 05:27:28 UTC"
  },
  {
    "arxiv_id": "2404.03253v1",
    "title": "A dataset of primary nasopharyngeal carcinoma MRI with multi-modalities segmentation",
    "authors": [
      "Yin Li",
      "Qi Chen",
      "Kai Wang",
      "Meige Li",
      "Liping Si",
      "Yingwei Guo",
      "Yu Xiong",
      "Qixing Wang",
      "Yang Qin",
      "Ling Xu",
      "Patrick van der Smagt",
      "Jun Tang",
      "Nutan Chen"
    ],
    "abstract": "Multi-modality magnetic resonance imaging data with various sequences\nfacilitate the early diagnosis, tumor segmentation, and disease staging in the\nmanagement of nasopharyngeal carcinoma (NPC). The lack of publicly available,\ncomprehensive datasets limits advancements in diagnosis, treatment planning,\nand the development of machine learning algorithms for NPC. Addressing this\ncritical need, we introduce the first comprehensive NPC MRI dataset,\nencompassing MR axial imaging of 277 primary NPC patients. This dataset\nincludes T1-weighted, T2-weighted, and contrast-enhanced T1-weighted sequences,\ntotaling 831 scans. In addition to the corresponding clinical data, manually\nannotated and labeled segmentations by experienced radiologists offer\nhigh-quality data resources from untreated primary NPC.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03253v1",
    "published_date": "2024-04-04 07:19:31 UTC",
    "updated_date": "2024-04-04 07:19:31 UTC"
  },
  {
    "arxiv_id": "2404.03239v1",
    "title": "Exploring Emotions in Multi-componential Space using Interactive VR Games",
    "authors": [
      "Rukshani Somarathna",
      "Gelareh Mohammadi"
    ],
    "abstract": "Emotion understanding is a complex process that involves multiple components.\nThe ability to recognise emotions not only leads to new context awareness\nmethods but also enhances system interaction's effectiveness by perceiving and\nexpressing emotions. Despite the attention to discrete and dimensional models,\nneuroscientific evidence supports those emotions as being complex and\nmulti-faceted. One framework that resonated well with such findings is the\nComponent Process Model (CPM), a theory that considers the complexity of\nemotions with five interconnected components: appraisal, expression,\nmotivation, physiology and feeling. However, the relationship between CPM and\ndiscrete emotions has not yet been fully explored. Therefore, to better\nunderstand emotions underlying processes, we operationalised a data-driven\napproach using interactive Virtual Reality (VR) games and collected multimodal\nmeasures (self-reports, physiological and facial signals) from 39 participants.\nWe used Machine Learning (ML) methods to identify the unique contributions of\neach component to emotion differentiation. Our results showed the role of\ndifferent components in emotion differentiation, with the model including all\ncomponents demonstrating the most significant contribution. Moreover, we found\nthat at least five dimensions are needed to represent the variation of emotions\nin our dataset. These findings also have implications for using VR environments\nin emotion research and highlight the role of physiological signals in emotion\nrecognition within such environments.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2404.03239v1",
    "published_date": "2024-04-04 06:54:44 UTC",
    "updated_date": "2024-04-04 06:54:44 UTC"
  },
  {
    "arxiv_id": "2404.04292v5",
    "title": "Conversational Disease Diagnosis via External Planner-Controlled Large Language Models",
    "authors": [
      "Zhoujian Sun",
      "Cheng Luo",
      "Ziyi Liu",
      "Zhengxing Huang"
    ],
    "abstract": "The development of large language models (LLMs) has brought unprecedented\npossibilities for artificial intelligence (AI) based medical diagnosis.\nHowever, the application perspective of LLMs in real diagnostic scenarios is\nstill unclear because they are not adept at collecting patient data\nproactively. This study presents a LLM-based diagnostic system that enhances\nplanning capabilities by emulating doctors. Our system involves two external\nplanners to handle planning tasks. The first planner employs a reinforcement\nlearning approach to formulate disease screening questions and conduct initial\ndiagnoses. The second planner uses LLMs to parse medical guidelines and conduct\ndifferential diagnoses. By utilizing real patient electronic medical record\ndata, we constructed simulated dialogues between virtual patients and doctors\nand evaluated the diagnostic abilities of our system. We demonstrated that our\nsystem obtained impressive performance in both disease screening and\ndifferential diagnoses tasks. This research represents a step towards more\nseamlessly integrating AI into clinical settings, potentially enhancing the\naccuracy and accessibility of medical diagnostics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in Progress",
    "pdf_url": "http://arxiv.org/pdf/2404.04292v5",
    "published_date": "2024-04-04 06:16:35 UTC",
    "updated_date": "2024-05-20 00:45:40 UTC"
  },
  {
    "arxiv_id": "2404.03204v3",
    "title": "RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis",
    "authors": [
      "Detai Xin",
      "Xu Tan",
      "Kai Shen",
      "Zeqian Ju",
      "Dongchao Yang",
      "Yuancheng Wang",
      "Shinnosuke Takamichi",
      "Hiroshi Saruwatari",
      "Shujie Liu",
      "Jinyu Li",
      "Sheng Zhao"
    ],
    "abstract": "We present RALL-E, a robust language modeling method for text-to-speech (TTS)\nsynthesis. While previous work based on large language models (LLMs) shows\nimpressive performance on zero-shot TTS, such methods often suffer from poor\nrobustness, such as unstable prosody (weird pitch and rhythm/duration) and a\nhigh word error rate (WER), due to the autoregressive prediction style of\nlanguage models. The core idea behind RALL-E is chain-of-thought (CoT)\nprompting, which decomposes the task into simpler steps to enhance the\nrobustness of LLM-based TTS. To accomplish this idea, RALL-E first predicts\nprosody features (pitch and duration) of the input text and uses them as\nintermediate conditions to predict speech tokens in a CoT style. Second, RALL-E\nutilizes the predicted duration prompt to guide the computing of self-attention\nweights in Transformer to enforce the model to focus on the corresponding\nphonemes and prosody features when predicting speech tokens. Results of\ncomprehensive objective and subjective evaluations demonstrate that, compared\nto a powerful baseline method VALL-E, RALL-E significantly improves the WER of\nzero-shot TTS from $5.6\\%$ (without reranking) and $1.7\\%$ (with reranking) to\n$2.5\\%$ and $1.0\\%$, respectively. Furthermore, we demonstrate that RALL-E\ncorrectly synthesizes sentences that are hard for VALL-E and reduces the error\nrate from $68\\%$ to $4\\%$.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03204v3",
    "published_date": "2024-04-04 05:15:07 UTC",
    "updated_date": "2024-05-19 21:34:28 UTC"
  },
  {
    "arxiv_id": "2404.03190v2",
    "title": "Adaptive Discrete Disparity Volume for Self-supervised Monocular Depth Estimation",
    "authors": [
      "Jianwei Ren"
    ],
    "abstract": "In self-supervised monocular depth estimation tasks, discrete disparity\nprediction has been proven to attain higher quality depth maps than common\ncontinuous methods. However, current discretization strategies often divide\ndepth ranges of scenes into bins in a handcrafted and rigid manner, limiting\nmodel performance. In this paper, we propose a learnable module, Adaptive\nDiscrete Disparity Volume (ADDV), which is capable of dynamically sensing depth\ndistributions in different RGB images and generating adaptive bins for them.\nWithout any extra supervision, this module can be integrated into existing CNN\narchitectures, allowing networks to produce representative values for bins and\na probability volume over them. Furthermore, we introduce novel training\nstrategies - uniformizing and sharpening - through a loss term and temperature\nparameter, respectively, to provide regularizations under self-supervised\nconditions, preventing model degradation or collapse. Empirical results\ndemonstrate that ADDV effectively processes global information, generating\nappropriate bins for various scenes and producing higher quality depth maps\ncompared to handcrafted methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03190v2",
    "published_date": "2024-04-04 04:22:25 UTC",
    "updated_date": "2024-11-28 00:30:21 UTC"
  },
  {
    "arxiv_id": "2404.03189v2",
    "title": "The Probabilities Also Matter: A More Faithful Metric for Faithfulness of Free-Text Explanations in Large Language Models",
    "authors": [
      "Noah Y. Siegel",
      "Oana-Maria Camburu",
      "Nicolas Heess",
      "Maria Perez-Ortiz"
    ],
    "abstract": "In order to oversee advanced AI systems, it is important to understand their\nunderlying decision-making process. When prompted, large language models (LLMs)\ncan provide natural language explanations or reasoning traces that sound\nplausible and receive high ratings from human annotators. However, it is\nunclear to what extent these explanations are faithful, i.e., truly capture the\nfactors responsible for the model's predictions. In this work, we introduce\nCorrelational Explanatory Faithfulness (CEF), a metric that can be used in\nfaithfulness tests based on input interventions. Previous metrics used in such\ntests take into account only binary changes in the predictions. Our metric\naccounts for the total shift in the model's predicted label distribution, more\naccurately reflecting the explanations' faithfulness. We then introduce the\nCorrelational Counterfactual Test (CCT) by instantiating CEF on the\nCounterfactual Test (CT) from Atanasova et al. (2023). We evaluate the\nfaithfulness of free-text explanations generated by few-shot-prompted LLMs from\nthe Llama2 family on three NLP tasks. We find that our metric measures aspects\nof faithfulness which the CT misses.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To be published in ACL 2024. 19 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.03189v2",
    "published_date": "2024-04-04 04:20:04 UTC",
    "updated_date": "2024-06-07 11:54:44 UTC"
  },
  {
    "arxiv_id": "2404.03184v1",
    "title": "The Death of Feature Engineering? BERT with Linguistic Features on SQuAD 2.0",
    "authors": [
      "Jiawei Li",
      "Yue Zhang"
    ],
    "abstract": "Machine reading comprehension is an essential natural language processing\ntask, which takes into a pair of context and query and predicts the\ncorresponding answer to query. In this project, we developed an end-to-end\nquestion answering model incorporating BERT and additional linguistic features.\nWe conclude that the BERT base model will be improved by incorporating the\nfeatures. The EM score and F1 score are improved 2.17 and 2.14 compared with\nBERT(base). Our best single model reaches EM score 76.55 and F1 score 79.97 in\nthe hidden test set. Our error analysis also shows that the linguistic\narchitecture can help model understand the context better in that it can locate\nanswers that BERT only model predicted \"No Answer\" wrongly.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03184v1",
    "published_date": "2024-04-04 03:50:34 UTC",
    "updated_date": "2024-04-04 03:50:34 UTC"
  },
  {
    "arxiv_id": "2404.04289v1",
    "title": "Designing for Human-Agent Alignment: Understanding what humans want from their agents",
    "authors": [
      "Nitesh Goyal",
      "Minsuk Chang",
      "Michael Terry"
    ],
    "abstract": "Our ability to build autonomous agents that leverage Generative AI continues\nto increase by the day. As builders and users of such agents it is unclear what\nparameters we need to align on before the agents start performing tasks on our\nbehalf. To discover these parameters, we ran a qualitative empirical research\nstudy about designing agents that can negotiate during a fictional yet\nrelatable task of selling a camera online. We found that for an agent to\nperform the task successfully, humans/users and agents need to align over 6\ndimensions: 1) Knowledge Schema Alignment 2) Autonomy and Agency Alignment 3)\nOperational Alignment and Training 4) Reputational Heuristics Alignment 5)\nEthics Alignment and 6) Human Engagement Alignment. These empirical findings\nexpand previous work related to process and specification alignment and the\nneed for values and safety in Human-AI interactions. Subsequently we discuss\nthree design directions for designers who are imagining a world filled with\nHuman-Agent collaborations.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "Human-AI Alignment, Human-Agent Alignment, Agents, Generative AI,\n  Large Language Models",
    "pdf_url": "http://arxiv.org/pdf/2404.04289v1",
    "published_date": "2024-04-04 03:01:57 UTC",
    "updated_date": "2024-04-04 03:01:57 UTC"
  },
  {
    "arxiv_id": "2404.04287v1",
    "title": "CONFLARE: CONFormal LArge language model REtrieval",
    "authors": [
      "Pouria Rouzrokh",
      "Shahriar Faghani",
      "Cooper U. Gamble",
      "Moein Shariatnia",
      "Bradley J. Erickson"
    ],
    "abstract": "Retrieval-augmented generation (RAG) frameworks enable large language models\n(LLMs) to retrieve relevant information from a knowledge base and incorporate\nit into the context for generating responses. This mitigates hallucinations and\nallows for the updating of knowledge without retraining the LLM. However, RAG\ndoes not guarantee valid responses if retrieval fails to identify the necessary\ninformation as the context for response generation. Also, if there is\ncontradictory content, the RAG response will likely reflect only one of the two\npossible responses. Therefore, quantifying uncertainty in the retrieval process\nis crucial for ensuring RAG trustworthiness. In this report, we introduce a\nfour-step framework for applying conformal prediction to quantify retrieval\nuncertainty in RAG frameworks. First, a calibration set of questions answerable\nfrom the knowledge base is constructed. Each question's embedding is compared\nagainst document embeddings to identify the most relevant document chunks\ncontaining the answer and record their similarity scores. Given a\nuser-specified error rate ({\\alpha}), these similarity scores are then analyzed\nto determine a similarity score cutoff threshold. During inference, all chunks\nwith similarity exceeding this threshold are retrieved to provide context to\nthe LLM, ensuring the true answer is captured in the context with a\n(1-{\\alpha}) confidence level. We provide a Python package that enables users\nto implement the entire workflow proposed in our work, only using LLMs and\nwithout human intervention.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Github code:\n  https://github.com/Mayo-Radiology-Informatics-Lab/conflare",
    "pdf_url": "http://arxiv.org/pdf/2404.04287v1",
    "published_date": "2024-04-04 02:58:21 UTC",
    "updated_date": "2024-04-04 02:58:21 UTC"
  },
  {
    "arxiv_id": "2404.03702v1",
    "title": "Personalized Federated Learning for Spatio-Temporal Forecasting: A Dual Semantic Alignment-Based Contrastive Approach",
    "authors": [
      "Qingxiang Liu",
      "Sheng Sun",
      "Yuxuan Liang",
      "Jingjing Xue",
      "Min Liu"
    ],
    "abstract": "The existing federated learning (FL) methods for spatio-temporal forecasting\nfail to capture the inherent spatio-temporal heterogeneity, which calls for\npersonalized FL (PFL) methods to model the spatio-temporally variant patterns.\nWhile contrastive learning approach is promising in addressing spatio-temporal\nheterogeneity, the existing methods are noneffective in determining negative\npairs and can hardly apply to PFL paradigm. To tackle this limitation, we\npropose a novel PFL method, named Federated dUal sEmantic aLignment-based\ncontraStive learning (FUELS), which can adaptively align positive and negative\npairs based on semantic similarity, thereby injecting precise spatio-temporal\nheterogeneity into the latent representation space by auxiliary contrastive\ntasks. From temporal perspective, a hard negative filtering module is\nintroduced to dynamically align heterogeneous temporal representations for the\nsupplemented intra-client contrastive task. From spatial perspective, we design\nlightweight-but-efficient prototypes as client-level semantic representations,\nbased on which the server evaluates spatial similarity and yields\nclient-customized global prototypes for the supplemented inter-client\ncontrastive task. Extensive experiments demonstrate that FUELS outperforms\nstate-of-the-art methods, with communication cost decreasing by around 94%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03702v1",
    "published_date": "2024-04-04 02:43:56 UTC",
    "updated_date": "2024-04-04 02:43:56 UTC"
  },
  {
    "arxiv_id": "2404.03164v2",
    "title": "KG4RecEval: Does Knowledge Graph Really Matter for Recommender Systems?",
    "authors": [
      "Haonan Zhang",
      "Dongxia Wang",
      "Zhu Sun",
      "Yanhui Li",
      "Youcheng Sun",
      "Huizhi Liang",
      "Wenhai Wang"
    ],
    "abstract": "Recommender systems (RSs) are designed to provide personalized\nrecommendations to users. Recently, knowledge graphs (KGs) have been widely\nintroduced in RSs to improve recommendation accuracy. In this study, however,\nwe demonstrate that RSs do not necessarily perform worse even if the KG is\ndowngraded to the user-item interaction graph only (or removed). We propose an\nevaluation framework KG4RecEval to systematically evaluate how much a KG\ncontributes to the recommendation accuracy of a KG-based RS, using our defined\nmetric KGER (KG utilization efficiency in recommendation). We consider the\nscenarios where knowledge in a KG gets completely removed, randomly distorted\nand decreased, and also where recommendations are for cold-start users. Our\nextensive experiments on four commonly used datasets and a number of\nstate-of-the-art KG-based RSs reveal that: to remove, randomly distort or\ndecrease knowledge does not necessarily decrease recommendation accuracy, even\nfor cold-start users. These findings inspire us to rethink how to better\nutilize knowledge from existing KGs, whereby we discuss and provide insights\ninto what characteristics of datasets and KG-based RSs may help improve KG\nutilization efficiency. The code and supplementary material of this paper are\navailable at: https://github.com/HotBento/KG4RecEval.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03164v2",
    "published_date": "2024-04-04 02:32:58 UTC",
    "updated_date": "2025-01-23 09:40:11 UTC"
  },
  {
    "arxiv_id": "2404.03163v2",
    "title": "Uncertainty in Language Models: Assessment through Rank-Calibration",
    "authors": [
      "Xinmeng Huang",
      "Shuo Li",
      "Mengxin Yu",
      "Matteo Sesia",
      "Hamed Hassani",
      "Insup Lee",
      "Osbert Bastani",
      "Edgar Dobriban"
    ],
    "abstract": "Language Models (LMs) have shown promising performance in natural language\ngeneration. However, as LMs often generate incorrect or hallucinated responses,\nit is crucial to correctly quantify their uncertainty in responding to given\ninputs. In addition to verbalized confidence elicited via prompting, many\nuncertainty measures ($e.g.$, semantic entropy and affinity-graph-based\nmeasures) have been proposed. However, these measures can differ greatly, and\nit is unclear how to compare them, partly because they take values over\ndifferent ranges ($e.g.$, $[0,\\infty)$ or $[0,1]$). In this work, we address\nthis issue by developing a novel and practical framework, termed\n$Rank$-$Calibration$, to assess uncertainty and confidence measures for LMs.\nOur key tenet is that higher uncertainty (or lower confidence) should imply\nlower generation quality, on average. Rank-calibration quantifies deviations\nfrom this ideal relationship in a principled manner, without requiring ad hoc\nbinary thresholding of the correctness score ($e.g.$, ROUGE or METEOR). The\nbroad applicability and the granular interpretability of our methods are\ndemonstrated empirically.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03163v2",
    "published_date": "2024-04-04 02:31:05 UTC",
    "updated_date": "2024-09-14 02:42:04 UTC"
  },
  {
    "arxiv_id": "2404.04286v2",
    "title": "Bias Amplification in Language Model Evolution: An Iterated Learning Perspective",
    "authors": [
      "Yi Ren",
      "Shangmin Guo",
      "Linlu Qiu",
      "Bailin Wang",
      "Danica J. Sutherland"
    ],
    "abstract": "With the widespread adoption of Large Language Models (LLMs), the prevalence\nof iterative interactions among these models is anticipated to increase.\nNotably, recent advancements in multi-round self-improving methods allow LLMs\nto generate new examples for training subsequent models. At the same time,\nmulti-agent LLM systems, involving automated interactions among agents, are\nalso increasing in prominence. Thus, in both short and long terms, LLMs may\nactively engage in an evolutionary process. We draw parallels between the\nbehavior of LLMs and the evolution of human culture, as the latter has been\nextensively studied by cognitive scientists for decades. Our approach involves\nleveraging Iterated Learning (IL), a Bayesian framework that elucidates how\nsubtle biases are magnified during human cultural evolution, to explain some\nbehaviors of LLMs. This paper outlines key characteristics of agents' behavior\nin the Bayesian-IL framework, including predictions that are supported by\nexperimental verification with various LLMs. This theoretical framework could\nhelp to more effectively predict and guide the evolution of LLMs in desired\ndirections.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04286v2",
    "published_date": "2024-04-04 02:01:25 UTC",
    "updated_date": "2024-10-03 05:27:41 UTC"
  },
  {
    "arxiv_id": "2405.15779v2",
    "title": "LiteNeXt: A Novel Lightweight ConvMixer-based Model with Self-embedding Representation Parallel for Medical Image Segmentation",
    "authors": [
      "Ngoc-Du Tran",
      "Thi-Thao Tran",
      "Quang-Huy Nguyen",
      "Manh-Hung Vu",
      "Van-Truong Pham"
    ],
    "abstract": "The emergence of deep learning techniques has advanced the image segmentation\ntask, especially for medical images. Many neural network models have been\nintroduced in the last decade bringing the automated segmentation accuracy\nclose to manual segmentation. However, cutting-edge models like\nTransformer-based architectures rely on large scale annotated training data,\nand are generally designed with densely consecutive layers in the encoder,\ndecoder, and skip connections resulting in large number of parameters.\nAdditionally, for better performance, they often be pretrained on a larger\ndata, thus requiring large memory size and increasing resource expenses. In\nthis study, we propose a new lightweight but efficient model, namely LiteNeXt,\nbased on convolutions and mixing modules with simplified decoder, for medical\nimage segmentation. The model is trained from scratch with small amount of\nparameters (0.71M) and Giga Floating Point Operations Per Second (0.42). To\nhandle boundary fuzzy as well as occlusion or clutter in objects especially in\nmedical image regions, we propose the Marginal Weight Loss that can help\neffectively determine the marginal boundary between object and background.\nAdditionally, the Self-embedding Representation Parallel technique is proposed\nas an innovative data augmentation strategy that utilizes the network\narchitecture itself for self-learning augmentation, enhancing feature\nextraction robustness without external data. Experiments on public datasets\nincluding Data Science Bowls, GlaS, ISIC2018, PH2, Sunnybrook, and Lung X-ray\ndata show promising results compared to other state-of-the-art CNN-based and\nTransformer-based architectures. Our code is released at:\nhttps://github.com/tranngocduvnvp/LiteNeXt.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "This manuscript has been accepted by Biomedical Signal Processing and\n  Control",
    "pdf_url": "http://arxiv.org/pdf/2405.15779v2",
    "published_date": "2024-04-04 01:59:19 UTC",
    "updated_date": "2025-03-09 08:54:13 UTC"
  },
  {
    "arxiv_id": "2404.03150v1",
    "title": "NLP at UC Santa Cruz at SemEval-2024 Task 5: Legal Answer Validation using Few-Shot Multi-Choice QA",
    "authors": [
      "Anish Pahilajani",
      "Samyak Rajesh Jain",
      "Devasha Trivedi"
    ],
    "abstract": "This paper presents our submission to the SemEval 2024 Task 5: The Legal\nArgument Reasoning Task in Civil Procedure. We present two approaches to\nsolving the task of legal answer validation, given an introduction to the case,\na question and an answer candidate. Firstly, we fine-tuned pre-trained\nBERT-based models and found that models trained on domain knowledge perform\nbetter. Secondly, we performed few-shot prompting on GPT models and found that\nreformulating the answer validation task to be a multiple-choice QA task\nremarkably improves the performance of the model. Our best submission is a\nBERT-based model that achieved the 7th place out of 20.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03150v1",
    "published_date": "2024-04-04 01:50:20 UTC",
    "updated_date": "2024-04-04 01:50:20 UTC"
  },
  {
    "arxiv_id": "2404.03147v5",
    "title": "Eigenpruning: an Interpretability-Inspired PEFT Method",
    "authors": [
      "Toms Vergara-Browne",
      "lvaro Soto",
      "Akiko Aizawa"
    ],
    "abstract": "We introduce eigenpruning, a method that removes singular values from weight\nmatrices in an LLM to improve its performance in a particular task. This method\nis inspired by interpretability methods designed to automatically find\nsubnetworks of a model which solve a specific task. In our tests, the pruned\nmodel outperforms the original model by a large margin, while only requiring\nminimal computation to prune the weight matrices. In the case of a small\nsynthetic task in integer multiplication, the Phi-2 model can improve its\naccuracy in the test set from 13.75% to 97.50%. Interestingly, these results\nseem to indicate the existence of a computation path that can solve the task\nvery effectively, but it was not being used by the original model. Finally, we\npublicly release our implementation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Extended abstract accepted to LatinX at NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.03147v5",
    "published_date": "2024-04-04 01:42:28 UTC",
    "updated_date": "2024-06-20 09:32:43 UTC"
  },
  {
    "arxiv_id": "2404.03133v2",
    "title": "A Framework for Guided Motion Planning",
    "authors": [
      "Amnon Attali",
      "Stav Ashur",
      "Isaac Burton Love",
      "Courtney McBeth",
      "James Motes",
      "Marco Morales",
      "Nancy M. Amato"
    ],
    "abstract": "Randomized sampling based algorithms are widely used in robot motion planning\ndue to the problem's intractability, and are experimentally effective on a wide\nrange of problem instances. Most variants bias their sampling using various\nheuristics related to the known underlying structure of the search space. In\nthis work, we formalize the intuitive notion of guided search by defining the\nconcept of a guiding space. This new language encapsulates many seemingly\ndistinct prior methods under the same framework, and allows us to reason about\nguidance, a previously obscured core contribution of different algorithms. We\nsuggest an information theoretic method to evaluate guidance, which\nexperimentally matches intuition when tested on known algorithms in a variety\nof environments. The language and evaluation of guidance suggests improvements\nto existing methods, and allows for simple hybrid algorithms that combine\nguidance from multiple sources.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03133v2",
    "published_date": "2024-04-04 00:58:19 UTC",
    "updated_date": "2024-10-07 03:56:10 UTC"
  }
]