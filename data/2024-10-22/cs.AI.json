{
  "date": "2024-10-22",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-22 的 arXiv 中文 TLDR 快报！今天 arXiv 论文主要聚焦 AI 模型优化（如 LLM 和 GNN 的高效训练）、强化学习应用、医疗图像分析，以及机器人路径规划等领域，亮点包括 LLM 在情感分析和轨迹预测的创新方法，以及高效计算框架；印象深刻的文章有涉及知名学者的作品，如 Jiajun Wu 在视觉场景表示上的进展。\n\n### 重点论文讨论\n我将相关论文归类讨论，先优先重要和话题度高的（如 AI 模型创新、医疗应用、强化学习），再快速掠过其他。以下选取最具代表性的论文，聚焦核心贡献。\n\n#### AI 模型优化与生成\n- **Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities Using Only Forward Passes**（标题：数学神经外科：仅用前向传播隔离语言模型的数学推理能力）  \n  这篇论文提出一种通过前向传播隔离 LLM 数学推理能力的创新方法，主要贡献是通过参数修剪提升数学任务性能，同时保持语言能力不变，实验在 GSM8K 和 MATH 数据集上显示显著改进。\n  \n- **Controlled Low-Rank Adaptation with Subspace Regularization for Continued Training on Large Language Models**（标题：子空间正则化下的受控低秩适应，用于大型语言模型的持续训练）  \n  作者引入子空间正则化优化 LLM 训练，核心发现是减少灾难性遗忘，同时在 HumanEval 数据集上提升了准确率 15.1%，这为高效 LLM 微调提供实用框架。\n\n- **Dynamic Adaptive Rank Space Exploration for Efficient Sentiment Analysis with Large Language Models**（标题：动态自适应秩空间探索，用于高效的情感分析）  \n  论文开发了 DARSE 框架，通过动态秩分配优化 LLM 在情感分析中的性能，主要贡献是显著提升准确率（MSE 降低 15.1%），并在资源有限的环境中表现出色。\n\n- **LLMScan: Causal Scan for LLM Misbehavior Detection**（标题：LLMScan：用于检测 LLM 异常行为的因果扫描）  \n  这篇工作使用因果分析检测 LLM 的不真实或有害输出，核心发现是通过因果分布分析提高检测准确率，实验显示在多种任务上提升了 80% 以上性能。\n\n- **CoPS: Empowering LLM Agents with Provable Cross-Task Experience Sharing**（标题：CoPS：通过可证明的跨任务经验共享增强 LLM 代理）  \n  作者提出 CoPS 算法，实现 LLM 代理的跨任务知识转移，主要贡献是提升样本效率，在 Alfworld 和 Webshop 等基准上超越 SOTA 方法。\n\n#### 医疗与生物应用\n- **EEG-DIF: Early Warning of Epileptic Seizures through Generative Diffusion Model-based Multi-channel EEG Signals Forecasting**（标题：EEG-DIF：基于生成扩散模型的多通道 EEG 信号预测的癫痫预警）  \n  论文使用扩散模型预测多通道 EEG 信号，核心发现是准确预测癫痫发作（准确率达 0.89），这为实时医疗预警提供新工具。\n\n- **DeLLiriuM: A large language model for delirium prediction in the ICU using structured EHR**（标题：DeLLiriuM：使用结构化 EHR 的 ICU 谵妄预测大型语言模型）  \n  这篇工作构建了基于 LLM 的谵妄预测模型，主要贡献是通过 EHR 数据在多个数据集上实现高 AUC（0.77-0.84），提升了 ICU 患者监测的准确性。\n\n- **IdenBAT: Disentangled Representation Learning for Identity-Preserved Brain Age Transformation**（标题：IdenBAT：用于身份保留脑年龄转换的解耦表示学习）  \n  作者提出解耦表示学习方法，核心发现是保留个体特征的同时转换脑年龄，实验在 3D 数据集上超越 SOTA，适用于脑部图像分析。\n\n#### 机器人与强化学习\n- **Learning Precise, Contact-Rich Manipulation through Uncalibrated Tactile Skins**（标题：通过未校准触觉皮肤学习精确的接触丰富操控）  \n  论文整合视觉和触觉数据进行机器人操控，核心贡献是通过 ViSk 框架提升任务准确率 27.5%，在真实世界任务中表现出色。\n\n- **Multi-Modal Transformer and Reinforcement Learning-based Beam Management**（标题：基于多模态 Transformer 和强化学习的波束管理）  \n  作者结合 Transformer 和 RL 优化无线通信波束，主要发现是通过两步预测提升系统吞吐量，在 6G 数据集上超越单模态方法。\n\n- **Episodic Future Thinking Mechanism for Multi-agent Reinforcement Learning**（标题：用于多代理强化学习的 episodic 未来思考机制）  \n  这篇工作引入未来思考机制模拟多代理互动，核心发现是在自治驾驶场景中减少冲突，提高奖励值。\n\n#### 其他快速掠过\n其他论文涉及图形生成、文本摘要和知识图谱等，但许多是增量改进或特定领域应用，我这里简要提及几篇：\n- **Decoding Time Series with LLMs: A Multi-Agent Framework for Cross-Domain Annotation**（标题：使用 LLM 解码时间序列：跨领域标注的多代理框架）  \n  提出 TESSA 框架，用于时间序列标注，核心贡献是提升标注质量，适用于制造业和医疗。\n  \n- **Quantum Large Language Models via Tensor Network Disentanglers**（标题：通过张量网络解耦的量子大型语言模型）  \n  探索量子计算增强 LLM，核心发现是提高准确性而保持低内存开销。\n  \n- **Permutation Picture of Graph Combinatorial Optimization Problems**（标题：图组合优化问题的置换图表示）  \n  这篇理论工作提出图优化的新框架，但影响相对有限。\n\n总体而言，今天的论文突显了 AI 模型在效率和应用上的创新潜力，尤其在医疗和机器人领域，但也暴露了训练数据和泛化能力的挑战。未来几天，继续关注这些主题的进展！",
  "papers": [
    {
      "arxiv_id": "2410.17479v1",
      "title": "Composing Diffusion Policies for Few-shot Learning of Movement Trajectories",
      "title_zh": "组合扩散策略用于运动轨迹的少样本学习",
      "authors": [
        "Omkar Patil",
        "Anant Sah",
        "Nakul Gopalan"
      ],
      "abstract": "Humans can perform various combinations of physical skills without having to\nrelearn skills from scratch every single time. For example, we can swing a bat\nwhen walking without having to re-learn such a policy from scratch by composing\nthe individual skills of walking and bat swinging. Enabling robots to combine\nor compose skills is essential so they can learn novel skills and tasks faster\nwith fewer real world samples. To this end, we propose a novel compositional\napproach called DSE- Diffusion Score Equilibrium that enables few-shot learning\nfor novel skills by utilizing a combination of base policy priors. Our method\nis based on probabilistically composing diffusion policies to better model the\nfew-shot demonstration data-distribution than any individual policy. Our goal\nhere is to learn robot motions few-shot and not necessarily goal oriented\ntrajectories. Unfortunately we lack a general purpose metric to evaluate the\nerror between a skill or motion and the provided demonstrations. Hence, we\npropose a probabilistic measure - Maximum Mean Discrepancy on the Forward\nKinematics Kernel (MMD-FK), that is task and action space agnostic. By using\nour few-shot learning approach DSE, we show that we are able to achieve a\nreduction of over 30% in MMD-FK across skills and number of demonstrations.\nMoreover, we show the utility of our approach through real world experiments by\nteaching novel trajectories to a robot in 5 demonstrations.",
      "tldr_zh": "该论文提出了一种名为DSE（Diffusion Score Equilibrium）的组合方法，用于实现机器人运动轨迹的少样本学习，旨在让机器人像人类一样通过组合基本策略（如walking和bat swinging）快速掌握新技能，而无需从零训练。DSE基于概率组合扩散策略（diffusion policies），通过整合基线策略先验来更好地建模少样本演示数据分布。论文引入了MMD-FK（Maximum Mean Discrepancy on the Forward Kinematics Kernel）作为任务无关的概率评估指标，并在实验中显示DSE减少了超过30%的误差。最终，通过真实世界实验，证明该方法能在5次演示内教会机器人新轨迹。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "6(+1) pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17479v1",
      "published_date": "2024-10-22 23:57:37 UTC",
      "updated_date": "2024-10-22 23:57:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:50:20.044592"
    },
    {
      "arxiv_id": "2410.17477v4",
      "title": "Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination",
      "title_zh": "翻译失败",
      "authors": [
        "Jerry Huang",
        "Prasanna Parthasarathi",
        "Mehdi Rezagholizadeh",
        "Boxing Chen",
        "Sarath Chandar"
      ],
      "abstract": "The growth in prominence of large language models (LLMs) in everyday life can\nbe largely attributed to their generative abilities, yet some of this is also\nowed to the risks and costs associated with their use. On one front is their\ntendency to hallucinate false or misleading information, limiting their\nreliability. On another is the increasing focus on the computational\nlimitations associated with traditional self-attention based LLMs, which has\nbrought about new alternatives, in particular recurrent models, meant to\novercome them. Yet it remains uncommon to consider these two concerns\nsimultaneously. Do changes in architecture exacerbate/alleviate existing\nconcerns about hallucinations? Do they affect how and where they occur? Through\nan extensive evaluation, we study how these architecture-based inductive biases\naffect the propensity to hallucinate. While hallucination remains a general\nphenomenon not limited to specific architectures, the situations in which they\noccur and the ease with which specific types of hallucinations can be induced\ncan significantly differ based on the model architecture. These findings\nhighlight the need for better understanding both these problems in conjunction\nwith each other, as well as consider how to design more universal techniques\nfor handling hallucinations.",
      "tldr_zh": "本论文探讨了架构诱导偏差(architectural inductive biases)对大语言模型(LLMs)幻觉(hallucination)的影响，特别关注传统自注意力模型和新兴循环模型之间的差异。通过广泛评估，研究发现幻觉并非特定架构所独有，但其发生场景和特定类型幻觉的易诱发性会因模型设计而显著不同。这些结果突出了需要联合分析架构变化与幻觉风险，并推动开发更通用的处理幻觉技术。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17477v4",
      "published_date": "2024-10-22 23:24:15 UTC",
      "updated_date": "2025-04-04 11:55:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:50:32.653178"
    },
    {
      "arxiv_id": "2410.18147v1",
      "title": "MEC-IP: Efficient Discovery of Markov Equivalent Classes via Integer Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Abdelmonem Elrefaey",
        "Rong Pan"
      ],
      "abstract": "This paper presents a novel Integer Programming (IP) approach for discovering\nthe Markov Equivalent Class (MEC) of Bayesian Networks (BNs) through\nobservational data. The MEC-IP algorithm utilizes a unique clique-focusing\nstrategy and Extended Maximal Spanning Graphs (EMSG) to streamline the search\nfor MEC, thus overcoming the computational limitations inherent in other\nexisting algorithms. Our numerical results show that not only a remarkable\nreduction in computational time is achieved by our algorithm but also an\nimprovement in causal discovery accuracy is seen across diverse datasets. These\nfindings underscore this new algorithm's potential as a powerful tool for\nresearchers and practitioners in causal discovery and BNSL, offering a\nsignificant leap forward toward the efficient and accurate analysis of complex\ndata structures.",
      "tldr_zh": "该论文提出了一种名为 MEC-IP 的新算法，利用 Integer Programming (IP) 通过观测数据高效发现 Bayesian Networks (BNs) 的 Markov Equivalent Class (MEC)。该算法采用独特的 clique-focusing 策略和 Extended Maximal Spanning Graphs (EMSG) 来优化搜索过程，克服了现有方法的计算瓶颈。实验结果显示，MEC-IP 显著降低了计算时间，同时在多种数据集上提升了因果发现的准确性，为 causal discovery 和 BNSL 领域提供了一个高效且可靠的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18147v1",
      "published_date": "2024-10-22 22:56:33 UTC",
      "updated_date": "2024-10-22 22:56:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:50:42.781436"
    },
    {
      "arxiv_id": "2410.17469v1",
      "title": "AdaptoML-UX: An Adaptive User-centered GUI-based AutoML Toolkit for Non-AI Experts and HCI Researchers",
      "title_zh": "翻译失败",
      "authors": [
        "Amr Gomaa",
        "Michael Sargious",
        "Antonio Krüger"
      ],
      "abstract": "The increasing integration of machine learning across various domains has\nunderscored the necessity for accessible systems that non-experts can utilize\neffectively. To address this need, the field of automated machine learning\n(AutoML) has developed tools to simplify the construction and optimization of\nML pipelines. However, existing AutoML solutions often lack efficiency in\ncreating online pipelines and ease of use for Human-Computer Interaction (HCI)\napplications. Therefore, in this paper, we introduce AdaptoML-UX, an adaptive\nframework that incorporates automated feature engineering, machine learning,\nand incremental learning to assist non-AI experts in developing robust,\nuser-centered ML models. Our toolkit demonstrates the capability to adapt\nefficiently to diverse problem domains and datasets, particularly in HCI,\nthereby reducing the necessity for manual experimentation and conserving time\nand resources. Furthermore, it supports model personalization through\nincremental learning, customizing models to individual user behaviors. HCI\nresearchers can employ AdaptoML-UX\n(\\url{https://github.com/MichaelSargious/AdaptoML_UX}) without requiring\nspecialized expertise, as it automates the selection of algorithms, feature\nengineering, and hyperparameter tuning based on the unique characteristics of\nthe data.",
      "tldr_zh": "本论文介绍了 AdaptoML-UX，这是一个自适应、用户中心的 GUI 基于 AutoML 工具包，旨在帮助非 AI 专家和 HCI 研究者轻松构建和优化机器学习模型。\n该工具包整合了自动特征工程、机器学习和增量学习功能，能够适应多样化问题领域和数据集，减少手动实验并节省时间与资源。\n此外，AdaptoML-UX 支持通过增量学习实现模型个性化，自动处理算法选择、特征工程和超参数调优，使 HCI 研究者无需专业知识即可高效使用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17469v1",
      "published_date": "2024-10-22 22:52:14 UTC",
      "updated_date": "2024-10-22 22:52:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:50:55.484711"
    },
    {
      "arxiv_id": "2410.17462v3",
      "title": "Decoding Time Series with LLMs: A Multi-Agent Framework for Cross-Domain Annotation",
      "title_zh": "翻译失败",
      "authors": [
        "Minhua Lin",
        "Zhengzhang Chen",
        "Yanchi Liu",
        "Xujiang Zhao",
        "Zongyu Wu",
        "Junxiang Wang",
        "Xiang Zhang",
        "Suhang Wang",
        "Haifeng Chen"
      ],
      "abstract": "Time series data is ubiquitous across various domains, including\nmanufacturing, finance, and healthcare. High-quality annotations are essential\nfor effectively understanding time series and facilitating downstream tasks;\nhowever, obtaining such annotations is challenging, particularly in\nmission-critical domains. In this paper, we propose TESSA, a multi-agent system\ndesigned to automatically generate both general and domain-specific annotations\nfor time series data. TESSA introduces two agents: a general annotation agent\nand a domain-specific annotation agent. The general agent captures common\npatterns and knowledge across multiple source domains, leveraging both\ntime-series-wise and text-wise features to generate general annotations.\nMeanwhile, the domain-specific agent utilizes limited annotations from the\ntarget domain to learn domain-specific terminology and generate targeted\nannotations. Extensive experiments on multiple synthetic and real-world\ndatasets demonstrate that TESSA effectively generates high-quality annotations,\noutperforming existing methods.",
      "tldr_zh": "该论文提出 TESSA，一种基于 LLMs 的多智能体框架，用于跨领域时间序列数据（time series data）的自动标注，旨在解决高品质标注在关键领域（如制造、金融和医疗）的获取挑战。TESSA 包括两个代理：通用标注代理（general annotation agent），通过时间序列和文本特征捕捉多个源领域的共同模式生成通用标注；以及领域特定标注代理（domain-specific annotation agent），利用目标领域的有限标注学习特定术语并生成针对性标注。实验在多个合成和真实数据集上表明，TESSA 生成的标注质量显著优于现有方法。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "29 pages, 12 figures, 32 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.17462v3",
      "published_date": "2024-10-22 22:43:14 UTC",
      "updated_date": "2025-05-19 08:07:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:51:07.940929"
    },
    {
      "arxiv_id": "2410.17459v1",
      "title": "Data Obfuscation through Latent Space Projection (LSP) for Privacy-Preserving AI Governance: Case Studies in Medical Diagnosis and Finance Fraud Detection",
      "title_zh": "通过潜在空间投影 (",
      "authors": [
        "Mahesh Vaijainthymala Krishnamoorthy"
      ],
      "abstract": "As AI systems increasingly integrate into critical societal sectors, the\ndemand for robust privacy-preserving methods has escalated. This paper\nintroduces Data Obfuscation through Latent Space Projection (LSP), a novel\ntechnique aimed at enhancing AI governance and ensuring Responsible AI\ncompliance. LSP uses machine learning to project sensitive data into a latent\nspace, effectively obfuscating it while preserving essential features for model\ntraining and inference. Unlike traditional privacy methods like differential\nprivacy or homomorphic encryption, LSP transforms data into an abstract,\nlower-dimensional form, achieving a delicate balance between data utility and\nprivacy. Leveraging autoencoders and adversarial training, LSP separates\nsensitive from non-sensitive information, allowing for precise control over\nprivacy-utility trade-offs. We validate LSP's effectiveness through experiments\non benchmark datasets and two real-world case studies: healthcare cancer\ndiagnosis and financial fraud analysis. Our results show LSP achieves high\nperformance (98.7% accuracy in image classification) while providing strong\nprivacy (97.3% protection against sensitive attribute inference), outperforming\ntraditional anonymization and privacy-preserving methods. The paper also\nexamines LSP's alignment with global AI governance frameworks, such as GDPR,\nCCPA, and HIPAA, highlighting its contribution to fairness, transparency, and\naccountability. By embedding privacy within the machine learning pipeline, LSP\noffers a promising approach to developing AI systems that respect privacy while\ndelivering valuable insights. We conclude by discussing future research\ndirections, including theoretical privacy guarantees, integration with\nfederated learning, and enhancing latent space interpretability, positioning\nLSP as a critical tool for ethical AI advancement.",
      "tldr_zh": "本文提出了一种名为 Data Obfuscation through Latent Space Projection (LSP) 的新方法，用于增强 AI 治理中的隐私保护，同时保持数据效用。LSP 通过机器学习将敏感数据投射到 latent space，使用 autoencoders 和 adversarial training 分离敏感与非敏感信息，与传统方法如 differential privacy 或 homomorphic encryption 相比，能更好地平衡隐私与实用性。在医疗癌症诊断和金融欺诈检测的真实案例研究中，LSP 实现了高性能（如 98.7% 准确率）和强隐私保护（如 97.3% 敏感属性推断防护），并优于现有匿名化技术。该方法符合 GDPR、CCPA 和 HIPAA 等全球 AI 治理框架，为道德 AI 发展提供了一个可扩展的工具，并探讨了未来方向如理论隐私保证和与 federated learning 的整合。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CY",
        "F.2.1; E.3"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 6 figures, submitted to Conference ICADCML2025",
      "pdf_url": "http://arxiv.org/pdf/2410.17459v1",
      "published_date": "2024-10-22 22:31:03 UTC",
      "updated_date": "2024-10-22 22:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:51:21.114176"
    },
    {
      "arxiv_id": "2410.17448v2",
      "title": "In Context Learning and Reasoning for Symbolic Regression with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Samiha Sharlin",
        "Tyler R. Josephson"
      ],
      "abstract": "Large Language Models (LLMs) are transformer-based machine learning models\nthat have shown remarkable performance in tasks for which they were not\nexplicitly trained. Here, we explore the potential of LLMs to perform symbolic\nregression -- a machine-learning method for finding simple and accurate\nequations from datasets. We prompt GPT-4 to suggest expressions from data,\nwhich are then optimized and evaluated using external Python tools. These\nresults are fed back to GPT-4, which proposes improved expressions while\noptimizing for complexity and loss. Using chain-of-thought prompting, we\ninstruct GPT-4 to analyze the data, prior expressions, and the scientific\ncontext (expressed in natural language) for each problem before generating new\nexpressions. We evaluated the workflow in rediscovery of five well-known\nscientific equations from experimental data, and on an additional dataset\nwithout a known equation. GPT-4 successfully rediscovered all five equations,\nand in general, performed better when prompted to use a scratchpad and consider\nscientific context. We demonstrate how strategic prompting improves the model's\nperformance and how the natural language interface simplifies integrating\ntheory with data. We also observe how theory can sometimes offset noisy data\nand, in other cases, data can make up for poor context. Although this approach\ndoes not outperform established SR programs where target equations are more\ncomplex, LLMs can nonetheless iterate toward improved solutions while following\ninstructions and incorporating scientific context in natural language.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在符号回归（symbolic regression）中的潜力，通过in-context learning和推理技术来从数据中发现简单准确的方程。研究采用chain-of-thought prompting引导GPT-4分析数据、科学上下文和先前表达式，并通过反馈循环与外部Python工具优化表达式，以平衡复杂度和损失。在实验中，GPT-4成功重现了五个已知科学方程，并在另一个数据集上表现出色，证明战略性提示能提升模型性能，并展示理论与数据间的互补作用。尽管LLMs不如专业符号回归程序高效，但其自然语言接口为整合科学知识提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17448v2",
      "published_date": "2024-10-22 21:50:52 UTC",
      "updated_date": "2025-03-12 13:14:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:53:32.066963"
    },
    {
      "arxiv_id": "2410.19859v1",
      "title": "Multi-Modal Transformer and Reinforcement Learning-based Beam Management",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Ghassemi",
        "Han Zhang",
        "Ali Afana",
        "Akram Bin Sediq",
        "Melike Erol-Kantarci"
      ],
      "abstract": "Beam management is an important technique to improve signal strength and\nreduce interference in wireless communication systems. Recently, there has been\nincreasing interest in using diverse sensing modalities for beam management.\nHowever, it remains a big challenge to process multi-modal data efficiently and\nextract useful information. On the other hand, the recently emerging\nmulti-modal transformer (MMT) is a promising technique that can process\nmulti-modal data by capturing long-range dependencies. While MMT is highly\neffective in handling multi-modal data and providing robust beam management,\nintegrating reinforcement learning (RL) further enhances their adaptability in\ndynamic environments. In this work, we propose a two-step beam management\nmethod by combining MMT with RL for dynamic beam index prediction. In the first\nstep, we divide available beam indices into several groups and leverage MMT to\nprocess diverse data modalities to predict the optimal beam group. In the\nsecond step, we employ RL for fast beam decision-making within each group,\nwhich in return maximizes throughput. Our proposed framework is tested on a 6G\ndataset. In this testing scenario, it achieves higher beam prediction accuracy\nand system throughput compared to both the MMT-only based method and the\nRL-only based method.",
      "tldr_zh": "这篇论文提出了一种结合 Multi-Modal Transformer (MMT) 和 Reinforcement Learning (RL) 的两步波束管理方法，以提升无线通信系统的信号强度并减少干扰。第一步，使用 MMT 处理多模态数据，将可用波束索引分组并预测最佳波束组；第二步，运用 RL 在每个组内进行快速决策，以最大化系统吞吐量。该方法在 6G 数据集上的实验中，实现了比仅 MMT 或仅 RL 方法更高的波束预测准确性和整体性能。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "5 pages, 5 figures, IEEE Networking Letters",
      "pdf_url": "http://arxiv.org/pdf/2410.19859v1",
      "published_date": "2024-10-22 21:44:25 UTC",
      "updated_date": "2024-10-22 21:44:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:51:44.436619"
    },
    {
      "arxiv_id": "2410.17439v3",
      "title": "Evaluating AI-Generated Essays with GRE Analytical Writing Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Zhong",
        "Jiangang Hao",
        "Michael Fauss",
        "Chen Li",
        "Yuan Wang"
      ],
      "abstract": "The recent revolutionary advance in generative AI enables the generation of\nrealistic and coherent texts by large language models (LLMs). Despite many\nexisting evaluation metrics on the quality of the generated texts, there is\nstill a lack of rigorous assessment of how well LLMs perform in complex and\ndemanding writing assessments. This study examines essays generated by ten\nleading LLMs for the analytical writing assessment of the Graduate Record Exam\n(GRE). We assessed these essays using both human raters and the e-rater\nautomated scoring engine as used in the GRE scoring pipeline. Notably, the\ntop-performing Gemini and GPT-4o received an average score of 4.78 and 4.67,\nrespectively, falling between \"generally thoughtful, well-developed analysis of\nthe issue and conveys meaning clearly\" and \"presents a competent analysis of\nthe issue and conveys meaning with acceptable clarity\" according to the GRE\nscoring guideline. We also evaluated the detection accuracy of these essays,\nwith detectors trained on essays generated by the same and different LLMs.",
      "tldr_zh": "本研究评估了十个领先的 LLMs 在 GRE Analytical Writing Assessment 中的表现，旨在检验这些模型在复杂写作任务上的能力。研究采用人类评分者和 e-rater 自动评分引擎对 AI 生成的论文进行评分，结果显示 Gemini 和 GPT-4o 的平均分数分别为 4.78 和 4.67，介于“generally thoughtful, well-developed analysis”和“presents a competent analysis”之间。 additionally, the study examined the detection accuracy of these AI-generated essays using detectors trained on essays from the same or different LLMs, highlighting the challenges in identifying synthetic texts。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17439v3",
      "published_date": "2024-10-22 21:30:58 UTC",
      "updated_date": "2024-11-13 04:57:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:51:55.946755"
    },
    {
      "arxiv_id": "2410.17438v1",
      "title": "Interpreting Affine Recurrence Learning in GPT-style Transformers",
      "title_zh": "解读 GPT-style Transformers 中的仿射递归学习",
      "authors": [
        "Samarth Bhargav",
        "Alexander Gu"
      ],
      "abstract": "Understanding the internal mechanisms of GPT-style transformers, particularly\ntheir capacity to perform in-context learning (ICL), is critical for advancing\nAI alignment and interpretability. In-context learning allows transformers to\ngeneralize during inference without modifying their weights, yet the precise\noperations driving this capability remain largely opaque. This paper presents\nan investigation into the mechanistic interpretability of these transformers,\nfocusing specifically on their ability to learn and predict affine recurrences\nas an ICL task. To address this, we trained a custom three-layer transformer to\npredict affine recurrences and analyzed the model's internal operations using\nboth empirical and theoretical approaches. Our findings reveal that the model\nforms an initial estimate of the target sequence using a copying mechanism in\nthe zeroth layer, which is subsequently refined through negative similarity\nheads in the second layer. These insights contribute to a deeper understanding\nof transformer behaviors in recursive tasks and offer potential avenues for\nimproving AI alignment through mechanistic interpretability. Finally, we\ndiscuss the implications of our results for future work, including extensions\nto higher-dimensional recurrences and the exploration of polynomial sequences.",
      "tldr_zh": "本论文探讨了 GPT-style transformers 在 in-context learning (ICL) 中的内部机制，重点分析其学习和预测 affine recurrences 的能力，以提升 AI alignment 和可解释性。通过训练一个自定义三层 transformer 并结合实证和理论方法，研究发现模型在 zeroth layer 使用 copying mechanism 形成初始序列估计，并在 second layer 通过 negative similarity heads 进行精炼。这些见解加深了对 transformers 在递归任务行为的理解，并为未来工作提供方向，如扩展到更高维的 recurrences 和 polynomial sequences。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17438v1",
      "published_date": "2024-10-22 21:30:01 UTC",
      "updated_date": "2024-10-22 21:30:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:52:08.940994"
    },
    {
      "arxiv_id": "2410.17433v1",
      "title": "Revisiting Technical Bias Mitigation Strategies",
      "title_zh": "重新审视技术偏见缓解策略",
      "authors": [
        "Abdoul Jalil Djiberou Mahamadou",
        "Artem A. Trotsyuk"
      ],
      "abstract": "Efforts to mitigate bias and enhance fairness in the artificial intelligence\n(AI) community have predominantly focused on technical solutions. While\nnumerous reviews have addressed bias in AI, this review uniquely focuses on the\npractical limitations of technical solutions in healthcare settings, providing\na structured analysis across five key dimensions affecting their real-world\nimplementation: who defines bias and fairness; which mitigation strategy to use\nand prioritize among dozens that are inconsistent and incompatible; when in the\nAI development stages the solutions are most effective; for which populations;\nand the context in which the solutions are designed. We illustrate each\nlimitation with empirical studies focusing on healthcare and biomedical\napplications. Moreover, we discuss how value-sensitive AI, a framework derived\nfrom technology design, can engage stakeholders and ensure that their values\nare embodied in bias and fairness mitigation solutions. Finally, we discuss\nareas that require further investigation and provide practical recommendations\nto address the limitations covered in the study.",
      "tldr_zh": "这篇论文重新审视了技术偏见缓解策略（technical bias mitigation strategies）的实际局限性，特别是在医疗保健领域的应用。通过结构化分析五个关键维度——谁定义偏见和公平性、选择哪个缓解策略、在AI开发阶段的最佳时机、针对哪些人群以及设计上下文——并结合医疗和生物医学应用的实证研究，揭示了这些策略的不一致性和不兼容性。论文提出采用基于价值的AI（value-sensitive AI）框架来参与利益相关者，确保他们的价值观融入缓解方案，并提供实用推荐和未来研究方向。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17433v1",
      "published_date": "2024-10-22 21:17:19 UTC",
      "updated_date": "2024-10-22 21:17:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:53:44.243560"
    },
    {
      "arxiv_id": "2411.04129v1",
      "title": "AmazonQAC: A Large-Scale, Naturalistic Query Autocomplete Dataset",
      "title_zh": "AmazonQAC：一个大规模、自然主义的查询自动补全数据集",
      "authors": [
        "Dante Everaert",
        "Rohit Patki",
        "Tianqi Zheng",
        "Christopher Potts"
      ],
      "abstract": "Query Autocomplete (QAC) is a critical feature in modern search engines,\nfacilitating user interaction by predicting search queries based on input\nprefixes. Despite its widespread adoption, the absence of large-scale,\nrealistic datasets has hindered advancements in QAC system development. This\npaper addresses this gap by introducing AmazonQAC, a new QAC dataset sourced\nfrom Amazon Search logs, comprising 395M samples. The dataset includes actual\nsequences of user-typed prefixes leading to final search terms, as well as\nsession IDs and timestamps that support modeling the context-dependent aspects\nof QAC. We assess Prefix Trees, semantic retrieval, and Large Language Models\n(LLMs) with and without finetuning. We find that finetuned LLMs perform best,\nparticularly when incorporating contextual information. However, even our best\nsystem achieves only half of what we calculate is theoretically possible on our\ntest data, which implies QAC is a challenging problem that is far from solved\nwith existing systems. This contribution aims to stimulate further research on\nQAC systems to better serve user needs in diverse environments. We open-source\nthis data on Hugging Face at https://huggingface.co/datasets/amazon/AmazonQAC.",
      "tldr_zh": "这篇论文介绍了 AmazonQAC，一个大规模的自然查询自动完成(QAC)数据集，包含 3.95 亿样本，从 Amazon 搜索日志中提取，包括用户输入前缀序列、最终搜索词、会话 ID 和时间戳，以支持上下文建模。作者评估了 Prefix Trees、语义检索以及 Large Language Models (LLMs)，结果显示微调后的 LLMs 表现最佳，尤其在整合上下文信息时，但其性能仅达到理论可能的一半，表明 QAC 问题仍具挑战性。该数据集开源在 Hugging Face，旨在促进 QAC 系统研究的进步。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.04129v1",
      "published_date": "2024-10-22 21:11:34 UTC",
      "updated_date": "2024-10-22 21:11:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:53:56.314158"
    },
    {
      "arxiv_id": "2410.17423v1",
      "title": "Artificial Intelligence in Brazilian News: A Mixed-Methods Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Raphael Hernandes",
        "Giulio Corsi"
      ],
      "abstract": "The current surge in Artificial Intelligence (AI) interest, reflected in\nheightened media coverage since 2009, has sparked significant debate on AI's\nimplications for privacy, social justice, workers' rights, and democracy. The\nmedia plays a crucial role in shaping public perception and acceptance of AI\ntechnologies. However, research into how AI appears in media has primarily\nfocused on anglophone contexts, leaving a gap in understanding how AI is\nrepresented globally. This study addresses this gap by analyzing 3,560 news\narticles from Brazilian media published between July 1, 2023, and February 29,\n2024, from 13 popular online news outlets. Using Computational Grounded Theory\n(CGT), the study applies Latent Dirichlet Allocation (LDA), BERTopic, and\nNamed-Entity Recognition to investigate the main topics in AI coverage and the\nentities represented. The findings reveal that Brazilian news coverage of AI is\ndominated by topics related to applications in the workplace and product\nlaunches, with limited space for societal concerns, which mostly focus on\ndeepfakes and electoral integrity. The analysis also highlights a significant\npresence of industry-related entities, indicating a strong influence of\ncorporate agendas in the country's news. This study underscores the need for a\nmore critical and nuanced discussion of AI's societal impacts in Brazilian\nmedia.",
      "tldr_zh": "这篇论文通过混合方法分析探讨了人工智能（AI）在巴西媒体中的呈现，填补了现有研究主要聚焦英语国家而忽略全球视角的空白。研究者分析了2023年7月1日至2024年2月29日期间的3560篇新闻文章，运用Computational Grounded Theory (CGT)、Latent Dirichlet Allocation (LDA)、BERTopic和Named-Entity Recognition等工具，揭示巴西新闻报道主要强调AI在工作场所的应用和产品发布，而社会担忧（如deepfakes和选举诚信）较少。结果显示，行业相关实体在报道中占据主导地位，突显企业议程的影响，并呼吁巴西媒体开展更具批判性和细致性的AI社会影响讨论。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 8 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.17423v1",
      "published_date": "2024-10-22 20:52:51 UTC",
      "updated_date": "2024-10-22 20:52:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:54:09.872926"
    },
    {
      "arxiv_id": "2410.18146v1",
      "title": "Meaning Typed Prompting: A Technique for Efficient, Reliable Structured Output Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Chandra Irugalbandara"
      ],
      "abstract": "Extending Large Language Models (LLMs) to advanced applications requires\nreliable structured output generation. Existing methods which often rely on\nrigid JSON schemas, can lead to unreliable outputs, diminished reasoning\ncapabilities, and increased computational overhead, limiting LLMs' adaptability\nfor complex tasks. We introduce Meaning Typed Prompting (MTP), a technique for\nefficient structured output generation that integrates types, meanings, and\nabstractions, such as variables and classes, into the prompting process. By\nutilizing expressive type definitions, MTP enhances output clarity and reduces\ndependence on complex abstractions, simplifying development, and improving\nimplementation efficiency. This enables LLMs to understand relationships and\ngenerate structured data more effectively. Empirical evaluations on multiple\nbenchmarks demonstrate that MTP outperforms existing frameworks in accuracy,\nreliability, consistency, and token efficiency. We present Semantix, a\nframework that implements MTP, providing practical insights into its\napplication.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)生成可靠结构化输出的挑战，指出现有方法依赖刚性JSON schemas会导致输出不可靠、推理能力减弱和计算开销增加。作者提出Meaning Typed Prompting (MTP)技术，通过将类型、含义和抽象（如变量和类）整合到提示过程中，提升输出清晰度、简化开发并提高效率，使LLMs更有效地理解关系并生成结构化数据。在多个基准上的实证评估显示，MTP在准确性、可靠性和令牌效率方面优于现有框架，并通过Semantix框架提供了实际应用见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18146v1",
      "published_date": "2024-10-22 20:43:50 UTC",
      "updated_date": "2024-10-22 20:43:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:54:21.060986"
    },
    {
      "arxiv_id": "2410.17415v1",
      "title": "End-to-End Optimization and Learning of Fair Court Schedules",
      "title_zh": "翻译失败",
      "authors": [
        "My H Dinh",
        "James Kotary",
        "Lauryn P. Gouldin",
        "William Yeoh",
        "Ferdinando Fioretto"
      ],
      "abstract": "Criminal courts across the United States handle millions of cases every year,\nand the scheduling of those cases must accommodate a diverse set of\nconstraints, including the preferences and availability of courts, prosecutors,\nand defense teams. When criminal court schedules are formed, defendants'\nscheduling preferences often take the least priority, although defendants may\nface significant consequences (including arrest or detention) for missed court\ndates. Additionally, studies indicate that defendants' nonappearances impose\ncosts on the courts and other system stakeholders. To address these issues,\ncourts and commentators have begun to recognize that pretrial outcomes for\ndefendants and for the system would be improved with greater attention to court\nprocesses, including \\emph{court scheduling practices}. There is thus a need\nfor fair criminal court pretrial scheduling systems that account for\ndefendants' preferences and availability, but the collection of such data poses\nlogistical challenges. Furthermore, optimizing schedules fairly across various\nparties' preferences is a complex optimization problem, even when such data is\navailable. In an effort to construct such a fair scheduling system under data\nuncertainty, this paper proposes a joint optimization and learning framework\nthat combines machine learning models trained end-to-end with efficient\nmatching algorithms. This framework aims to produce court scheduling schedules\nthat optimize a principled measure of fairness, balancing the availability and\npreferences of all parties.",
      "tldr_zh": "本文研究美国刑事法院的案件调度问题，强调当前系统往往忽略被告的偏好和可用性，导致不公平后果，如被告缺席可能引发逮捕或额外成本。论文提出一个端到端优化和学习框架（End-to-End Optimization and Learning），结合机器学习模型（machine learning models）和高效匹配算法（efficient matching algorithms），以处理数据不确定性。框架通过优化一个原则性的公平度量（principled measure of fairness），平衡法院、检察官、辩护团队和被告的所有当事人的可用性和偏好，从而改善预审调度实践并提升整体系统效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17415v1",
      "published_date": "2024-10-22 20:40:53 UTC",
      "updated_date": "2024-10-22 20:40:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:54:32.569795"
    },
    {
      "arxiv_id": "2410.17409v1",
      "title": "Geometric Graph Neural Network Modeling of Human Interactions in Crowded Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Honarvar",
        "Yancy Diaz-Mercado"
      ],
      "abstract": "Modeling human trajectories in crowded environments is challenging due to the\ncomplex nature of pedestrian behavior and interactions. This paper proposes a\ngeometric graph neural network (GNN) architecture that integrates domain\nknowledge from psychological studies to model pedestrian interactions and\npredict future trajectories. Unlike prior studies using complete graphs, we\ndefine interaction neighborhoods using pedestrians' field of view, motion\ndirection, and distance-based kernel functions to construct graph\nrepresentations of crowds. Evaluations across multiple datasets demonstrate\nimproved prediction accuracy through reduced average and final displacement\nerror metrics. Our findings underscore the importance of integrating domain\nknowledge with data-driven approaches for effective modeling of human\ninteractions in crowds.",
      "tldr_zh": "这篇论文提出了一种几何图神经网络（Geometric Graph Neural Network, GNN）架构，用于建模人群环境中人类互动并预测轨迹，该方法整合了心理学研究的领域知识来处理行人行为的复杂性。不同于以往使用完整图的方法，该框架通过行人的视野（field of view）、运动方向（motion direction）和基于距离的核函数（distance-based kernel functions）来定义互动邻域，从而构建更精确的人群图表示。在多个数据集上的评估显示，该方法显著降低了平均位移错误（average displacement error）和最终位移错误（final displacement error）指标，证明了将领域知识与数据驱动方法相结合的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "\\c{opyright} 2024 the authors. This work has been accepted to IFAC\n  for publication under a Creative Commons Licence CC-BY-NC-ND",
      "pdf_url": "http://arxiv.org/pdf/2410.17409v1",
      "published_date": "2024-10-22 20:33:10 UTC",
      "updated_date": "2024-10-22 20:33:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:54:43.577034"
    },
    {
      "arxiv_id": "2410.17397v1",
      "title": "Quantum Large Language Models via Tensor Network Disentanglers",
      "title_zh": "翻译失败",
      "authors": [
        "Borja Aizpurua",
        "Saeed S. Jahromi",
        "Sukhbinder Singh",
        "Roman Orus"
      ],
      "abstract": "We propose a method to enhance the performance of Large Language Models\n(LLMs) by integrating quantum computing and quantum-inspired techniques.\nSpecifically, our approach involves replacing the weight matrices in the\nSelf-Attention and Multi-layer Perceptron layers with a combination of two\nvariational quantum circuits and a quantum-inspired tensor network, such as a\nMatrix Product Operator (MPO). This substitution enables the reproduction of\nclassical LLM functionality by decomposing weight matrices through the\napplication of tensor network disentanglers and MPOs, leveraging\nwell-established tensor network techniques. By incorporating more complex and\ndeeper quantum circuits, along with increasing the bond dimensions of the MPOs,\nour method captures additional correlations within the quantum-enhanced LLM,\nleading to improved accuracy beyond classical models while maintaining low\nmemory overhead.",
      "tldr_zh": "该研究提出了一种整合量子计算和量子启发技术的方法，以提升Large Language Models (LLMs)的性能。具体而言，通过在Self-Attention和Multi-layer Perceptron层中用两个变分量子电路和Matrix Product Operator (MPO)等张量网络替换权重矩阵，并应用张量网络解缠结器来分解矩阵，从而复现并优化经典LLM功能。结果表明，这种量子增强方法能捕捉更多数据相关性，提高模型准确性，同时保持低内存开销，为量子LLMs的实际应用提供了新途径。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "4 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17397v1",
      "published_date": "2024-10-22 20:12:04 UTC",
      "updated_date": "2024-10-22 20:12:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:54:56.350020"
    },
    {
      "arxiv_id": "2410.17395v1",
      "title": "A 10.60 $μ$W 150 GOPS Mixed-Bit-Width Sparse CNN Accelerator for Life-Threatening Ventricular Arrhythmia Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Qin",
        "Zhenge Jia",
        "Zheyu Yan",
        "Jay Mok",
        "Manto Yung",
        "Yu Liu",
        "Xuejiao Liu",
        "Wujie Wen",
        "Luhong Liang",
        "Kwang-Ting Tim Cheng",
        "X. Sharon Hu",
        "Yiyu Shi"
      ],
      "abstract": "This paper proposes an ultra-low power, mixed-bit-width sparse convolutional\nneural network (CNN) accelerator to accelerate ventricular arrhythmia (VA)\ndetection. The chip achieves 50% sparsity in a quantized 1D CNN using a sparse\nprocessing element (SPE) architecture. Measurement on the prototype chip TSMC\n40nm CMOS low-power (LP) process for the VA classification task demonstrates\nthat it consumes 10.60 $\\mu$W of power while achieving a performance of 150\nGOPS and a diagnostic accuracy of 99.95%. The computation power density is only\n0.57 $\\mu$W/mm$^2$, which is 14.23X smaller than state-of-the-art works, making\nit highly suitable for implantable and wearable medical devices.",
      "tldr_zh": "这篇论文提出了一种超低功耗的混合位宽稀疏卷积神经网络(CNN)加速器，用于检测生命威胁性的心室性心律失常(VA)。该加速器采用稀疏处理元素(SPE)架构，在量化1D CNN中实现50%的稀疏度，并在TSMC 40nm CMOS低功耗工艺的原型芯片上表现出色。实验结果显示，它仅消耗10.60 μW功率，达到150 GOPS性能，并实现99.95%的诊断准确率，计算功耗密度仅为0.57 μW/mm²，比现有技术低14.23倍，非常适合植入式和可穿戴医疗设备。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "2 pages, accepted to The 30th Asia and South Pacific Design\n  Automation Conference (ASP-DAC 2025)",
      "pdf_url": "http://arxiv.org/pdf/2410.17395v1",
      "published_date": "2024-10-22 20:02:25 UTC",
      "updated_date": "2024-10-22 20:02:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:55:08.762784"
    },
    {
      "arxiv_id": "2410.17394v1",
      "title": "packetLSTM: Dynamic LSTM Framework for Streaming Data with Varying Feature Space",
      "title_zh": "翻译失败",
      "authors": [
        "Rohit Agarwal",
        "Karaka Prasanth Naidu",
        "Alexander Horsch",
        "Krishna Agarwal",
        "Dilip K. Prasad"
      ],
      "abstract": "We study the online learning problem characterized by the varying input\nfeature space of streaming data. Although LSTMs have been employed to\neffectively capture the temporal nature of streaming data, they cannot handle\nthe dimension-varying streams in an online learning setting. Therefore, we\npropose a dynamic LSTM-based novel method, called packetLSTM, to model the\ndimension-varying streams. The packetLSTM's dynamic framework consists of an\nevolving packet of LSTMs, each dedicated to processing one input feature. Each\nLSTM retains the local information of its corresponding feature, while a shared\ncommon memory consolidates global information. This configuration facilitates\ncontinuous learning and mitigates the issue of forgetting, even when certain\nfeatures are absent for extended time periods. The idea of utilizing one LSTM\nper feature coupled with a dimension-invariant operator for information\naggregation enhances the dynamic nature of packetLSTM. This dynamic nature is\nevidenced by the model's ability to activate, deactivate, and add new LSTMs as\nrequired, thus seamlessly accommodating varying input dimensions. The\npacketLSTM achieves state-of-the-art results on five datasets, and its\nunderlying principle is extended to other RNN types, like GRU and vanilla RNN.",
      "tldr_zh": "本文提出 packetLSTM，一种动态 LSTM 框架，用于处理特征空间变化的流式数据在线学习问题，以克服传统 LSTM 在维度变化场景下的局限性。packetLSTM 通过一个演化的 LSTM 包（每个特征对应一个专用 LSTM）来保留局部信息，同时利用共享公共内存整合全局信息，从而实现持续学习并缓解长期特征缺失导致的遗忘问题。该框架的动态机制允许根据需要激活、停用或添加新 LSTM，适应变化的输入维度。在五个数据集上，packetLSTM 达到了最先进的结果，并扩展到其他 RNN 类型如 GRU 和 vanilla RNN。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17394v1",
      "published_date": "2024-10-22 20:01:39 UTC",
      "updated_date": "2024-10-22 20:01:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:55:19.892914"
    },
    {
      "arxiv_id": "2410.17389v1",
      "title": "Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models",
      "title_zh": "处理嘈杂反馈：使用易出错语言模型增强强化学习",
      "authors": [
        "Muhan Lin",
        "Shuyang Shi",
        "Yue Guo",
        "Behdad Chalaki",
        "Vaishnav Tadiparthi",
        "Ehsan Moradi Pari",
        "Simon Stepputtis",
        "Joseph Campbell",
        "Katia Sycara"
      ],
      "abstract": "The correct specification of reward models is a well-known challenge in\nreinforcement learning. Hand-crafted reward functions often lead to inefficient\nor suboptimal policies and may not be aligned with user values. Reinforcement\nlearning from human feedback is a successful technique that can mitigate such\nissues, however, the collection of human feedback can be laborious. Recent\nworks have solicited feedback from pre-trained large language models rather\nthan humans to reduce or eliminate human effort, however, these approaches\nyield poor performance in the presence of hallucination and other errors. This\npaper studies the advantages and limitations of reinforcement learning from\nlarge language model feedback and proposes a simple yet effective method for\nsoliciting and applying feedback as a potential-based shaping function. We\ntheoretically show that inconsistent rankings, which approximate ranking\nerrors, lead to uninformative rewards with our approach. Our method empirically\nimproves convergence speed and policy returns over commonly used baselines even\nwith significant ranking errors, and eliminates the need for complex\npost-processing of reward functions.",
      "tldr_zh": "这篇论文探讨了强化学习（Reinforcement Learning）中奖励模型（Reward Models）指定的挑战，特别是使用易出错的大型语言模型（Large Language Models, LLMs）反馈时的问题，这些反馈可能因幻觉或其他错误导致性能低下。作者提出了一种简单有效的办法，将LLMs反馈作为基于潜力的整形函数（Potential-based Shaping Function），以缓解不一致排名带来的影响。理论分析显示，这种方法能避免奖励的不信息性，而实证结果表明，即使在显著排名错误的情况下，它比常见基线提高了收敛速度和策略回报，并简化了奖励函数的后处理过程。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 8 figures, The 2024 Conference on Empirical Methods in\n  Natural Language Processing",
      "pdf_url": "http://arxiv.org/pdf/2410.17389v1",
      "published_date": "2024-10-22 19:52:08 UTC",
      "updated_date": "2024-10-22 19:52:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:55:31.764594"
    },
    {
      "arxiv_id": "2410.17373v1",
      "title": "Episodic Future Thinking Mechanism for Multi-agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dongsu Lee",
        "Minhae Kwon"
      ],
      "abstract": "Understanding cognitive processes in multi-agent interactions is a primary\ngoal in cognitive science. It can guide the direction of artificial\nintelligence (AI) research toward social decision-making in multi-agent\nsystems, which includes uncertainty from character heterogeneity. In this\npaper, we introduce an episodic future thinking (EFT) mechanism for a\nreinforcement learning (RL) agent, inspired by cognitive processes observed in\nanimals. To enable future thinking functionality, we first develop a\nmulti-character policy that captures diverse characters with an ensemble of\nheterogeneous policies. Here, the character of an agent is defined as a\ndifferent weight combination on reward components, representing distinct\nbehavioral preferences. The future thinking agent collects observation-action\ntrajectories of the target agents and uses the pre-trained multi-character\npolicy to infer their characters. Once the character is inferred, the agent\npredicts the upcoming actions of target agents and simulates the potential\nfuture scenario. This capability allows the agent to adaptively select the\noptimal action, considering the predicted future scenario in multi-agent\ninteractions. To evaluate the proposed mechanism, we consider the multi-agent\nautonomous driving scenario with diverse driving traits and multiple particle\nenvironments. Simulation results demonstrate that the EFT mechanism with\naccurate character inference leads to a higher reward than existing multi-agent\nsolutions. We also confirm that the effect of reward improvement remains valid\nacross societies with different levels of character diversity.",
      "tldr_zh": "本研究引入了 episodic future thinking (EFT) 机制，用于多代理强化学习 (RL)，旨在模拟动物认知以处理多代理互动中的不确定性和角色异质性。该机制首先开发一个 multi-character policy，通过异构策略集合捕捉代理的不同行为偏好（基于奖励组件的权重组合），并利用预训练模型推断目标代理的角色以预测未来动作和场景。随后，代理基于这些预测自适应选择最优动作。在多代理自动驾驶和粒子环境模拟中，EFT 机制显著提高了奖励，比现有解决方案高，且在不同角色多样性水平下保持有效。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 (Web: https://sites.google.com/view/eftm-neurips2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.17373v1",
      "published_date": "2024-10-22 19:12:42 UTC",
      "updated_date": "2024-10-22 19:12:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:55:43.182856"
    },
    {
      "arxiv_id": "2410.17363v1",
      "title": "DeLLiriuM: A large language model for delirium prediction in the ICU using structured EHR",
      "title_zh": "翻译失败",
      "authors": [
        "Miguel Contreras",
        "Sumit Kapoor",
        "Jiaqing Zhang",
        "Andrea Davidson",
        "Yuanfang Ren",
        "Ziyuan Guan",
        "Tezcan Ozrazgat-Baslanti",
        "Subhash Nerella",
        "Azra Bihorac",
        "Parisa Rashidi"
      ],
      "abstract": "Delirium is an acute confusional state that has been shown to affect up to\n31% of patients in the intensive care unit (ICU). Early detection of this\ncondition could lead to more timely interventions and improved health outcomes.\nWhile artificial intelligence (AI) models have shown great potential for ICU\ndelirium prediction using structured electronic health records (EHR), most of\nthem have not explored the use of state-of-the-art AI models, have been limited\nto single hospitals, or have been developed and validated on small cohorts. The\nuse of large language models (LLM), models with hundreds of millions to\nbillions of parameters, with structured EHR data could potentially lead to\nimproved predictive performance. In this study, we propose DeLLiriuM, a novel\nLLM-based delirium prediction model using EHR data available in the first 24\nhours of ICU admission to predict the probability of a patient developing\ndelirium during the rest of their ICU admission. We develop and validate\nDeLLiriuM on ICU admissions from 104,303 patients pertaining to 195 hospitals\nacross three large databases: the eICU Collaborative Research Database, the\nMedical Information Mart for Intensive Care (MIMIC)-IV, and the University of\nFlorida Health's Integrated Data Repository. The performance measured by the\narea under the receiver operating characteristic curve (AUROC) showed that\nDeLLiriuM outperformed all baselines in two external validation sets, with 0.77\n(95% confidence interval 0.76-0.78) and 0.84 (95% confidence interval\n0.83-0.85) across 77,543 patients spanning 194 hospitals. To the best of our\nknowledge, DeLLiriuM is the first LLM-based delirium prediction tool for the\nICU based on structured EHR data, outperforming deep learning baselines which\nemploy structured features and can provide helpful information to clinicians\nfor timely interventions.",
      "tldr_zh": "本研究提出DeLLiriuM，一种基于大型语言模型(LLM)的工具，用于利用结构化电子健康记录(EHR)数据预测ICU患者在入院前24小时内发展成delirium的概率。模型在来自195家医院的104,303名患者的三个大型数据库（eICU、MIMIC-IV和University of Florida Health's Integrated Data Repository）上开发和验证。结果显示，DeLLiriuM在两个外部验证集上的area under the receiver operating characteristic curve (AUROC)分别为0.77和0.84，显著优于现有深度学习基线模型。该工具为临床医生提供及时干预信息，是首个基于LLM的ICU delirium预测方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17363v1",
      "published_date": "2024-10-22 18:56:31 UTC",
      "updated_date": "2024-10-22 18:56:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:55:56.810601"
    },
    {
      "arxiv_id": "2410.17358v1",
      "title": "FairLoRA: Unpacking Bias Mitigation in Vision Models with Fairness-Driven Low-Rank Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Rohan Sukumaran",
        "Aarash Feizi",
        "Adriana Romero-Sorian",
        "Golnoosh Farnadi"
      ],
      "abstract": "Recent advances in parameter-efficient fine-tuning methods, such as Low Rank\nAdaptation (LoRA), have gained significant attention for their ability to\nefficiently adapt large foundational models to various downstream tasks. These\nmethods are appreciated for achieving performance comparable to full\nfine-tuning on aggregate-level metrics, while significantly reducing\ncomputational costs. To systematically address fairness in LLMs previous\nstudies fine-tune on fairness specific data using a larger LoRA rank than\ntypically used. In this paper, we introduce FairLoRA, a novel fairness-specific\nregularizer for LoRA aimed at reducing performance disparities across data\nsubgroups by minimizing per-class variance in loss. To the best of our\nknowledge, we are the first to introduce a fairness based finetuning through\nLoRA. Our results demonstrate that the need for higher ranks to mitigate bias\nis not universal; it depends on factors such as the pre-trained model, dataset,\nand task. More importantly, we systematically evaluate FairLoRA across various\nvision models, including ViT, DiNO, and CLIP, in scenarios involving\ndistribution shifts. We further emphasize the necessity of using multiple\nfairness metrics to obtain a holistic assessment of fairness, rather than\nrelying solely on the metric optimized during training.",
      "tldr_zh": "该论文引入FairLoRA，一种针对视觉模型的公平性驱动Low-Rank Adaptation (LoRA)方法，通过最小化每个类别的损失方差来减少数据子群体间的性能差异。FairLoRA是首个基于LoRA的公平性微调框架，并在ViT、DiNO和CLIP等模型上进行了系统评估，特别是在涉及分布偏移的场景中。研究发现，缓解偏差并不总是需要更高的LoRA秩，这取决于预训练模型、数据集和任务，并强调使用多种fairness metrics进行全面评估，以获得更可靠的公平性结果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17358v1",
      "published_date": "2024-10-22 18:50:36 UTC",
      "updated_date": "2024-10-22 18:50:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:56:07.641058"
    },
    {
      "arxiv_id": "2410.17343v1",
      "title": "EEG-DIF: Early Warning of Epileptic Seizures through Generative Diffusion Model-based Multi-channel EEG Signals Forecasting",
      "title_zh": "EEG-DIF：通过",
      "authors": [
        "Zekun Jiang",
        "Wei Dai",
        "Qu Wei",
        "Ziyuan Qin",
        "Kang Li",
        "Le Zhang"
      ],
      "abstract": "Multi-channel EEG signals are commonly used for the diagnosis and assessment\nof diseases such as epilepsy. Currently, various EEG diagnostic algorithms\nbased on deep learning have been developed. However, most research efforts\nfocus solely on diagnosing and classifying current signal data but do not\nconsider the prediction of future trends for early warning. Additionally, since\nmulti-channel EEG can be essentially regarded as the spatio-temporal signal\ndata received by detectors at different locations in the brain, how to\nconstruct spatio-temporal information representations of EEG signals to\nfacilitate future trend prediction for multi-channel EEG becomes an important\nproblem. This study proposes a multi-signal prediction algorithm based on\ngenerative diffusion models (EEG-DIF), which transforms the multi-signal\nforecasting task into an image completion task, allowing for comprehensive\nrepresentation and learning of the spatio-temporal correlations and future\ndevelopmental patterns of multi-channel EEG signals. Here, we employ a publicly\navailable epilepsy EEG dataset to construct and validate the EEG-DIF. The\nresults demonstrate that our method can accurately predict future trends for\nmulti-channel EEG signals simultaneously. Furthermore, the early warning\naccuracy for epilepsy seizures based on the generated EEG data reaches 0.89. In\ngeneral, EEG-DIF provides a novel approach for characterizing multi-channel EEG\nsignals and an innovative early warning algorithm for epilepsy seizures, aiding\nin optimizing and enhancing the clinical diagnosis process. The code is\navailable at https://github.com/JZK00/EEG-DIF.",
      "tldr_zh": "本文提出 EEG-DIF 算法，利用生成扩散模型(generative diffusion models)对多通道 EEG 信号进行未来趋势预测，将任务转化为图像补全任务，以全面学习信号的时空相关性和发展模式。相比现有方法，该算法不仅诊断当前信号，还能准确预测多通道 EEG 的未来趋势。实验结果显示，在公开癫痫 EEG 数据集上，早警告警准确率达到 0.89，为优化临床癫痫诊断提供创新途径。代码已在 GitHub 开源。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "9 pages, 4 figures, 3 tables, accepted by ACM BCB 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.17343v1",
      "published_date": "2024-10-22 18:18:48 UTC",
      "updated_date": "2024-10-22 18:18:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:56:19.314094"
    },
    {
      "arxiv_id": "2410.17337v1",
      "title": "Captions Speak Louder than Images (CASLIE): Generalizing Foundation Models for E-commerce from High-quality Multimodal Instruction Data",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyi Ling",
        "Bo Peng",
        "Hanwen Du",
        "Zhihui Zhu",
        "Xia Ning"
      ],
      "abstract": "Leveraging multimodal data to drive breakthroughs in e-commerce applications\nthrough Multimodal Foundation Models (MFMs) is gaining increasing attention\nfrom the research community. However, there are significant challenges that\nhinder the optimal use of multimodal e-commerce data by foundation models: (1)\nthe scarcity of large-scale, high-quality multimodal benchmark datasets; and\n(2) the lack of effective multimodal information integration methods. To\naddress these challenges, in this paper, we introduce MMECInstruct, the\nfirst-ever, large-scale, and high-quality multimodal instruction dataset for\ne-commerce. We also develop CASLIE, a simple, lightweight, yet effective\nframework for integrating multimodal information for e-commerce. Leveraging\nMMECInstruct, we fine-tune a series of e-commerce MFMs within CASLIE, denoted\nas CASLIE models. Our comprehensive evaluation demonstrates that CASLIE models\nsubstantially outperform 5 categories of advanced baseline models in the\nin-domain evaluation. Moreover, CASLIE models show strong generalizability to\nout-of-domain settings. MMECInstruct and CASLIE models are publicly accessible\nthrough https://ninglab.github.io/CASLIE/.",
      "tldr_zh": "该研究针对电商领域多模态基础模型（MFMs）的挑战，包括缺少大规模高质量数据集和有效的多模态信息整合方法，引入了MMECInstruct，这是首个大规模、高质量的多模态指令数据集。作者开发了CASLIE框架，一个简单轻量的多模态信息整合方法，并利用MMECInstruct微调了一系列电商MFMs模型。实验结果显示，CASLIE模型在领域内评估中大幅超越5类高级基线模型，并在领域外场景中表现出强泛化能力，且数据集及模型已公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Xinyi Ling and Bo Peng contributed equally to this paper",
      "pdf_url": "http://arxiv.org/pdf/2410.17337v1",
      "published_date": "2024-10-22 18:11:43 UTC",
      "updated_date": "2024-10-22 18:11:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:58:31.075107"
    },
    {
      "arxiv_id": "2410.17333v1",
      "title": "Are Large Language Models Ready for Travel Planning?",
      "title_zh": "大型语言模型准备好进行旅行规划了吗？",
      "authors": [
        "Ruiping Ren",
        "Xing Yao",
        "Shu Cole",
        "Haining Wang"
      ],
      "abstract": "While large language models (LLMs) show promise in hospitality and tourism,\ntheir ability to provide unbiased service across demographic groups remains\nunclear. This paper explores gender and ethnic biases when LLMs are utilized as\ntravel planning assistants. To investigate this issue, we apply machine\nlearning techniques to analyze travel suggestions generated from three\nopen-source LLMs. Our findings reveal that the performance of race and gender\nclassifiers substantially exceeds random chance, indicating differences in how\nLLMs engage with varied subgroups. Specifically, outputs align with cultural\nexpectations tied to certain races and genders. To minimize the effect of these\nstereotypes, we used a stop-word classification strategy, which decreased\nidentifiable differences, with no disrespectful terms found. However,\nhallucinations related to African American and gender minority groups were\nnoted. In conclusion, while LLMs can generate travel plans seemingly free from\nbias, it remains essential to verify the accuracy and appropriateness of their\nrecommendations.",
      "tldr_zh": "这篇论文评估大型语言模型（LLMs）在旅行规划中的性别和种族偏见问题，通过分析三个开源 LLMs 生成的旅行建议。研究采用机器学习技术，发现输出存在与文化期望相关的差异，例如种族和性别分类器的性能远超随机水平。采用停用词分类策略后，减少了可识别的偏见差异，但仍观察到与非洲裔美国人和性别少数群体相关的幻觉。结论是，虽然 LLMs 可以生成看似无偏见的旅行计划，但必须验证其准确性和适当性，以确保公正性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17333v1",
      "published_date": "2024-10-22 18:08:25 UTC",
      "updated_date": "2024-10-22 18:08:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:56:42.968700"
    },
    {
      "arxiv_id": "2410.17309v3",
      "title": "Literature Meets Data: A Synergistic Approach to Hypothesis Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Haokun Liu",
        "Yangqiaoyu Zhou",
        "Mingxuan Li",
        "Chenfei Yuan",
        "Chenhao Tan"
      ],
      "abstract": "AI holds promise for transforming scientific processes, including hypothesis\ngeneration. Prior work on hypothesis generation can be broadly categorized into\ntheory-driven and data-driven approaches. While both have proven effective in\ngenerating novel and plausible hypotheses, it remains an open question whether\nthey can complement each other. To address this, we develop the first method\nthat combines literature-based insights with data to perform LLM-powered\nhypothesis generation. We apply our method on five different datasets and\ndemonstrate that integrating literature and data outperforms other baselines\n(8.97\\% over few-shot, 15.75\\% over literature-based alone, and 3.37\\% over\ndata-driven alone). Additionally, we conduct the first human evaluation to\nassess the utility of LLM-generated hypotheses in assisting human\ndecision-making on two challenging tasks: deception detection and AI generated\ncontent detection. Our results show that human accuracy improves significantly\nby 7.44\\% and 14.19\\% on these tasks, respectively. These findings suggest that\nintegrating literature-based and data-driven approaches provides a\ncomprehensive and nuanced framework for hypothesis generation and could open\nnew avenues for scientific inquiry.",
      "tldr_zh": "本研究提出了一种协同方法，将文献-based insights与数据相结合，用于LLM-powered假设生成，旨在弥补理论驱动和数据驱动方法的局限性。在五个数据集上的实验中，该方法显著优于基线模型（比few-shot提升8.97%、比文献-based提升15.75%、比数据-driven提升3.37%）。此外，首次进行的人类评估显示，该方法生成的假设能帮助人类在欺骗检测和AI生成内容检测任务中准确率分别提高7.44%和14.19%。这些结果表明，整合文献和数据的框架为假设生成提供了更全面的途径，可能开启新的科学探究方向。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "37 pages, 9 figures, code link:\n  https://github.com/ChicagoHAI/hypothesis-generation",
      "pdf_url": "http://arxiv.org/pdf/2410.17309v3",
      "published_date": "2024-10-22 18:00:00 UTC",
      "updated_date": "2025-01-08 19:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:56:55.643502"
    },
    {
      "arxiv_id": "2410.17250v2",
      "title": "JMMMU: A Japanese Massive Multi-discipline Multimodal Understanding Benchmark for Culture-aware Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Shota Onohara",
        "Atsuyuki Miyai",
        "Yuki Imajuku",
        "Kazuki Egashira",
        "Jeonghun Baek",
        "Xiang Yue",
        "Graham Neubig",
        "Kiyoharu Aizawa"
      ],
      "abstract": "Accelerating research on Large Multimodal Models (LMMs) in non-English\nlanguages is crucial for enhancing user experiences across broader populations.\nIn this paper, we introduce JMMMU (Japanese MMMU), the first large-scale\nJapanese benchmark designed to evaluate LMMs on expert-level tasks based on the\nJapanese cultural context. To facilitate comprehensive culture-aware\nevaluation, JMMMU features two complementary subsets: (i) culture-agnostic (CA)\nsubset, where the culture-independent subjects (e.g., Math) are selected and\ntranslated into Japanese, enabling one-to-one comparison with its English\ncounterpart MMMU; and (ii) culture-specific (CS) subset, comprising newly\ncrafted subjects that reflect Japanese cultural context. Using the CA subset,\nwe observe performance drop in many LMMs when evaluated in Japanese, which is\npurely attributable to language variation. Using the CS subset, we reveal their\ninadequate Japanese cultural understanding. Further, by combining both subsets,\nwe identify that some LMMs perform well on the CA subset but not on the CS\nsubset, exposing a shallow understanding of the Japanese language that lacks\ndepth in cultural understanding. We hope this work will not only help advance\nLMM performance in Japanese but also serve as a guideline to create\nhigh-standard, culturally diverse benchmarks for multilingual LMM development.\nThe project page is https://mmmu-japanese-benchmark.github.io/JMMMU/.",
      "tldr_zh": "本文引入 JMMMU，这是一个首个大规模日语多学科多模态理解基准，用于评估 Large Multimodal Models (LMMs) 在文化感知任务中的表现。JMMMU 包括文化无关 (CA) 子集（翻译英语主题如数学以便比较）和文化特定 (CS) 子集（新创建的日语文化相关主题）。实验结果显示，LMMs 在日语评估中性能下降，主要归因于语言差异和文化理解不足；结合两个子集，揭示一些模型对日语的浅层掌握。希望此基准不仅提升 LMMs 在日语中的性能，还为多语言基准开发提供指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025. Project page:\n  https://mmmu-japanese-benchmark.github.io/JMMMU/",
      "pdf_url": "http://arxiv.org/pdf/2410.17250v2",
      "published_date": "2024-10-22 17:59:56 UTC",
      "updated_date": "2025-03-19 08:24:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:57:08.258141"
    },
    {
      "arxiv_id": "2410.17248v3",
      "title": "HyperspectralViTs: General Hyperspectral Models for On-board Remote Sensing",
      "title_zh": "HyperspectralViTs：通用高光谱模型用于机载遥感",
      "authors": [
        "Vít Růžička",
        "Andrew Markham"
      ],
      "abstract": "On-board processing of hyperspectral data with machine learning models would\nenable unprecedented amount of autonomy for a wide range of tasks, for example\nmethane detection or mineral identification. This can enable early warning\nsystem and could allow new capabilities such as automated scheduling across\nconstellations of satellites. Classical methods suffer from high false positive\nrates and previous deep learning models exhibit prohibitive computational\nrequirements. We propose fast and accurate machine learning architectures which\nsupport end-to-end training with data of high spectral dimension without\nrelying on hand-crafted products or spectral band compression preprocessing. We\nevaluate our models on two tasks related to hyperspectral data processing. With\nour proposed general architectures, we improve the F1 score of the previous\nmethane detection state-of-the-art models by 27% on a newly created synthetic\ndataset and by 13% on the previously released large benchmark dataset. We also\ndemonstrate that training models on the synthetic dataset improves performance\nof models finetuned on the dataset of real events by 6.9% in F1 score in\ncontrast with training from scratch. On a newly created dataset for mineral\nidentification, our models provide 3.5% improvement in the F1 score in contrast\nto the default versions of the models. With our proposed models we improve the\ninference speed by 85% in contrast to previous classical and deep learning\napproaches by removing the dependency on classically computed features. With\nour architecture, one capture from the EMIT sensor can be processed within 30\nseconds on realistic proxy of the ION-SCV 004 satellite.",
      "tldr_zh": "该论文提出了一种名为 HyperspectralViTs 的通用高光谱模型，旨在实现卫星机载处理，支持端到端训练，而不依赖手工制品或光谱带压缩预处理，从而提升任务如甲烷检测和矿物识别的自治能力。相比传统方法和现有深度学习模型，该架构显著降低了假阳性率，并将推理速度提高85%，使一个EMIT传感器捕获的数据可在30秒内处理。实验结果显示，在合成和真实数据集上，模型的F1分数在甲烷检测任务中分别提升27%和13%，而在矿物识别任务中提升3.5%，证明了其在高光谱数据处理中的高效性和泛化性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, Accepted manuscript version, published version may differ\n  in minor details and formatting",
      "pdf_url": "http://arxiv.org/pdf/2410.17248v3",
      "published_date": "2024-10-22 17:59:55 UTC",
      "updated_date": "2025-04-12 12:37:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:57:20.243131"
    },
    {
      "arxiv_id": "2410.17246v2",
      "title": "Learning Precise, Contact-Rich Manipulation through Uncalibrated Tactile Skins",
      "title_zh": "翻译失败",
      "authors": [
        "Venkatesh Pattabiraman",
        "Yifeng Cao",
        "Siddhant Haldar",
        "Lerrel Pinto",
        "Raunaq Bhirangi"
      ],
      "abstract": "While visuomotor policy learning has advanced robotic manipulation, precisely\nexecuting contact-rich tasks remains challenging due to the limitations of\nvision in reasoning about physical interactions. To address this, recent work\nhas sought to integrate tactile sensing into policy learning. However, many\nexisting approaches rely on optical tactile sensors that are either restricted\nto recognition tasks or require complex dimensionality reduction steps for\npolicy learning. In this work, we explore learning policies with magnetic skin\nsensors, which are inherently low-dimensional, highly sensitive, and\ninexpensive to integrate with robotic platforms. To leverage these sensors\neffectively, we present the Visuo-Skin (ViSk) framework, a simple approach that\nuses a transformer-based policy and treats skin sensor data as additional\ntokens alongside visual information. Evaluated on four complex real-world tasks\ninvolving credit card swiping, plug insertion, USB insertion, and bookshelf\nretrieval, ViSk significantly outperforms both vision-only and optical tactile\nsensing based policies. Further analysis reveals that combining tactile and\nvisual modalities enhances policy performance and spatial generalization,\nachieving an average improvement of 27.5% across tasks.\nhttps://visuoskin.github.io/",
      "tldr_zh": "本研究探讨了使用未校准的磁性皮肤传感器（magnetic skin sensors）来学习精确的接触丰富操作（contact-rich manipulation），以克服视觉方法在物理交互推理方面的局限性。提出 ViSk 框架，该框架采用 transformer-based policy，将皮肤传感器数据作为额外的 tokens 与视觉信息整合，实现更有效的策略学习。在四个真实世界任务（如信用卡刷卡、插头插入、USB 插入和书架取物）上，ViSk 显著优于仅视觉或光学触觉 sensing 的方法，平均提升 27.5%，并增强了策略性能和空间泛化。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17246v2",
      "published_date": "2024-10-22 17:59:49 UTC",
      "updated_date": "2024-10-26 02:25:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:59:25.326899"
    },
    {
      "arxiv_id": "2410.17245v1",
      "title": "Towards Reliable Evaluation of Behavior Steering Interventions in LLMs",
      "title_zh": "迈向大型语言模型中行为引导干预的可靠评估",
      "authors": [
        "Itamar Pres",
        "Laura Ruis",
        "Ekdeep Singh Lubana",
        "David Krueger"
      ],
      "abstract": "Representation engineering methods have recently shown promise for enabling\nefficient steering of model behavior. However, evaluation pipelines for these\nmethods have primarily relied on subjective demonstrations, instead of\nquantitative, objective metrics. We aim to take a step towards addressing this\nissue by advocating for four properties missing from current evaluations: (i)\ncontexts sufficiently similar to downstream tasks should be used for assessing\nintervention quality; (ii) model likelihoods should be accounted for; (iii)\nevaluations should allow for standardized comparisons across different target\nbehaviors; and (iv) baseline comparisons should be offered. We introduce an\nevaluation pipeline grounded in these criteria, offering both a quantitative\nand visual analysis of how effectively a given method works. We use this\npipeline to evaluate two representation engineering methods on how effectively\nthey can steer behaviors such as truthfulness and corrigibility, finding that\nsome interventions are less effective than previously reported.",
      "tldr_zh": "这项研究针对 representation engineering 方法在引导大型语言模型 (LLMs) 行为时的评估问题，提出改进现有主观评估管道的四个关键属性：(i) 使用与下游任务相似的上下文；(ii) 考虑模型似然度；(iii) 实现不同目标行为的标准化比较；(iv) 提供基线比较。\n他们引入了一个基于这些属性的评估管道，结合定量和视觉分析，以更客观地评估干预措施的有效性。\n实验结果显示，在引导 truthfulness 和 corrigibility 等行为时，一些 representation engineering 方法的效果不如之前报道的那样显著。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the NeurIPS 2024 - Workshop on Foundation Model\n  Interventions",
      "pdf_url": "http://arxiv.org/pdf/2410.17245v1",
      "published_date": "2024-10-22 17:59:39 UTC",
      "updated_date": "2024-10-22 17:59:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:59:37.442096"
    },
    {
      "arxiv_id": "2410.17238v1",
      "title": "SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning",
      "title_zh": "SELA：树搜索增强的 LLM 代理用于自动化机器学习",
      "authors": [
        "Yizhou Chi",
        "Yizhang Lin",
        "Sirui Hong",
        "Duyi Pan",
        "Yaying Fei",
        "Guanghao Mei",
        "Bangbang Liu",
        "Tianqi Pang",
        "Jacky Kwok",
        "Ceyao Zhang",
        "Bang Liu",
        "Chenglin Wu"
      ],
      "abstract": "Automated Machine Learning (AutoML) approaches encompass traditional methods\nthat optimize fixed pipelines for model selection and ensembling, as well as\nnewer LLM-based frameworks that autonomously build pipelines. While LLM-based\nagents have shown promise in automating machine learning tasks, they often\ngenerate low-diversity and suboptimal code, even after multiple iterations. To\novercome these limitations, we introduce Tree-Search Enhanced LLM Agents\n(SELA), an innovative agent-based system that leverages Monte Carlo Tree Search\n(MCTS) to optimize the AutoML process. By representing pipeline configurations\nas trees, our framework enables agents to conduct experiments intelligently and\niteratively refine their strategies, facilitating a more effective exploration\nof the machine learning solution space. This novel approach allows SELA to\ndiscover optimal pathways based on experimental feedback, improving the overall\nquality of the solutions. In an extensive evaluation across 20 machine learning\ndatasets, we compare the performance of traditional and agent-based AutoML\nmethods, demonstrating that SELA achieves a win rate of 65% to 80% against each\nbaseline across all datasets. These results underscore the significant\npotential of agent-based strategies in AutoML, offering a fresh perspective on\ntackling complex machine learning challenges.",
      "tldr_zh": "本研究提出SELA，一种通过Monte Carlo Tree Search (MCTS)增强的LLM代理系统，用于Automated Machine Learning (AutoML)，以解决现有LLM代理在生成代码多样性和优化方面的问题。SELA将机器学习管道配置表示为树结构，允许代理基于实验反馈进行智能迭代探索，从而发现更优的解决方案。在20个数据集上的广泛评估中，SELA比传统和代理基线方法胜率达到65%至80%，证明了代理策略在处理复杂机器学习挑战中的显著潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "The code is available at https://github.com/geekan/MetaGPT",
      "pdf_url": "http://arxiv.org/pdf/2410.17238v1",
      "published_date": "2024-10-22 17:56:08 UTC",
      "updated_date": "2024-10-22 17:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:59:48.913690"
    },
    {
      "arxiv_id": "2410.17236v2",
      "title": "Large Language Models Empowered Personalized Web Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Hongru Cai",
        "Yongqi Li",
        "Wenjie Wang",
        "Fengbin Zhu",
        "Xiaoyu Shen",
        "Wenjie Li",
        "Tat-Seng Chua"
      ],
      "abstract": "Web agents have emerged as a promising direction to automate Web task\ncompletion based on user instructions, significantly enhancing user experience.\nRecently, Web agents have evolved from traditional agents to Large Language\nModels (LLMs)-based Web agents. Despite their success, existing LLM-based Web\nagents overlook the importance of personalized data (e.g., user profiles and\nhistorical Web behaviors) in assisting the understanding of users' personalized\ninstructions and executing customized actions. To overcome the limitation, we\nfirst formulate the task of LLM-empowered personalized Web agents, which\nintegrate personalized data and user instructions to personalize instruction\ncomprehension and action execution. To address the absence of a comprehensive\nevaluation benchmark, we construct a Personalized Web Agent Benchmark\n(PersonalWAB), featuring user instructions, personalized user data, Web\nfunctions, and two evaluation paradigms across three personalized Web tasks.\nMoreover, we propose a Personalized User Memory-enhanced Alignment (PUMA)\nframework to adapt LLMs to the personalized Web agent task. PUMA utilizes a\nmemory bank with a task-specific retrieval strategy to filter relevant\nhistorical Web behaviors. Based on the behaviors, PUMA then aligns LLMs for\npersonalized action execution through fine-tuning and direct preference\noptimization. Extensive experiments validate the superiority of PUMA over\nexisting Web agents on PersonalWAB.",
      "tldr_zh": "该论文探讨了基于Large Language Models (LLMs)的Web代理如何通过整合个性化数据（如用户资料和历史行为）来更好地理解和执行用户指令，从而提升自动化Web任务完成。研究者构建了Personalized Web Agent Benchmark (PersonalWAB)基准，包括用户指令、个性化数据、Web函数和两种评估范式，覆盖三种个性化Web任务，以评估此类代理的性能。同时，提出Personalized User Memory-enhanced Alignment (PUMA)框架，该框架利用记忆银行和任务特定检索策略筛选相关历史行为，并通过微调和直接偏好优化调整LLMs，实现个性化的行动执行。实验结果显示，PUMA在PersonalWAB上显著优于现有Web代理，验证了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to WWW 2025. The code and data are available on the project\n  website https://hongrucai.github.io/PersonalWAB/",
      "pdf_url": "http://arxiv.org/pdf/2410.17236v2",
      "published_date": "2024-10-22 17:54:45 UTC",
      "updated_date": "2025-03-24 17:51:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:00:00.636875"
    },
    {
      "arxiv_id": "2410.17233v3",
      "title": "ICPL: Few-shot In-context Preference Learning via LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Yu",
        "Qixin Tan",
        "Hong Lu",
        "Jiaxuan Gao",
        "Xinting Yang",
        "Yu Wang",
        "Yi Wu",
        "Eugene Vinitsky"
      ],
      "abstract": "Preference-based reinforcement learning is an effective way to handle tasks\nwhere rewards are hard to specify but can be exceedingly inefficient as\npreference learning is often tabula rasa. We demonstrate that Large Language\nModels (LLMs) have native preference-learning capabilities that allow them to\nachieve sample-efficient preference learning, addressing this challenge. We\npropose In-Context Preference Learning (ICPL), which uses in-context learning\ncapabilities of LLMs to reduce human query inefficiency. ICPL uses the task\ndescription and basic environment code to create sets of reward functions which\nare iteratively refined by placing human feedback over videos of the resultant\npolicies into the context of an LLM and then requesting better rewards. We\nfirst demonstrate ICPL's effectiveness through a synthetic preference study,\nproviding quantitative evidence that it significantly outperforms baseline\npreference-based methods with much higher performance and orders of magnitude\ngreater efficiency. We observe that these improvements are not solely coming\nfrom LLM grounding in the task but that the quality of the rewards improves\nover time, indicating preference learning capabilities. Additionally, we\nperform a series of real human preference-learning trials and observe that ICPL\nextends beyond synthetic settings and can work effectively with\nhumans-in-the-loop.",
      "tldr_zh": "这篇论文提出 ICPL（In-Context Preference Learning），一种利用 LLMs（Large Language Models）的 in-context learning 能力来进行 few-shot 偏好学习的框架，以解决传统 Preference-based reinforcement learning 的低效率问题。ICPL 通过任务描述和环境代码创建奖励函数集，并通过将人类反馈融入 LLM 上下文进行迭代精炼。实验结果显示，ICPL 在合成偏好研究中显著优于基线方法，性能提升且效率高出几个数量级，并在真实人类参与试验中证明其有效性，展示了 LLMs 的原生偏好学习能力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17233v3",
      "published_date": "2024-10-22 17:53:34 UTC",
      "updated_date": "2025-04-03 08:27:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:00:13.344040"
    },
    {
      "arxiv_id": "2410.17229v2",
      "title": "Responsibility in a Multi-Value Strategic Setting",
      "title_zh": "翻译失败",
      "authors": [
        "Timothy Parker",
        "Umberto Grandi",
        "Emiliano Lorini"
      ],
      "abstract": "Responsibility is a key notion in multi-agent systems and in creating safe,\nreliable and ethical AI. However, most previous work on responsibility has only\nconsidered responsibility for single outcomes. In this paper we present a model\nfor responsibility attribution in a multi-agent, multi-value setting. We also\nexpand our model to cover responsibility anticipation, demonstrating how\nconsiderations of responsibility can help an agent to select strategies that\nare in line with its values. In particular we show that non-dominated\nregret-minimising strategies reliably minimise an agent's expected degree of\nresponsibility.",
      "tldr_zh": "本文提出一个模型，用于在多智能体(multi-agent)系统和多价值(multi-value)战略设置中归因责任(responsibility attribution)，扩展了以往仅针对单一结果的责任研究。模型进一步涵盖责任预期(responsibility anticipation)，展示如何帮助代理选择与自身价值观一致的策略。研究发现，非主导遗憾最小化策略(non-dominated regret-minimising strategies)能够可靠地最小化代理的预期责任程度，从而提升AI的安全性和伦理性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17229v2",
      "published_date": "2024-10-22 17:51:13 UTC",
      "updated_date": "2024-11-08 23:12:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:00:24.566094"
    },
    {
      "arxiv_id": "2410.17218v4",
      "title": "Creativity in AI: Progresses and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Mete Ismayilzada",
        "Debjit Paul",
        "Antoine Bosselut",
        "Lonneke van der Plas"
      ],
      "abstract": "Creativity is the ability to produce novel, useful, and surprising ideas, and\nhas been widely studied as a crucial aspect of human cognition. Machine\ncreativity on the other hand has been a long-standing challenge. With the rise\nof advanced generative AI, there has been renewed interest and debate regarding\nAI's creative capabilities. Therefore, it is imperative to revisit the state of\ncreativity in AI and identify key progresses and remaining challenges. In this\nwork, we survey leading works studying the creative capabilities of AI systems,\nfocusing on creative problem-solving, linguistic, artistic, and scientific\ncreativity. Our review suggests that while the latest AI models are largely\ncapable of producing linguistically and artistically creative outputs such as\npoems, images, and musical pieces, they struggle with tasks that require\ncreative problem-solving, abstract thinking and compositionality and their\ngenerations suffer from a lack of diversity, originality, long-range\nincoherence and hallucinations. We also discuss key questions concerning\ncopyright and authorship issues with generative models. Furthermore, we\nhighlight the need for a comprehensive evaluation of creativity that is\nprocess-driven and considers several dimensions of creativity. Finally, we\npropose future research directions to improve the creativity of AI outputs,\ndrawing inspiration from cognitive science and psychology.",
      "tldr_zh": "本论文回顾了AI在创造力（creativity）方面的进展与挑战，定义创造力为产生新颖、有用和令人惊讶的想法，并调查AI系统在创造性问题-solving、语言、艺术和科学创造力上的表现。研究发现，最新生成AI模型在生成语言和艺术输出（如诗歌、图像和音乐）方面表现出色，但存在原创性、多样性、长期连贯性和幻觉等问题，同时在抽象思考和组合性任务上表现较弱。论文还讨论了版权和作者权问题，强调需要过程驱动的多维度评估，并提出未来研究方向，如借鉴认知科学和心理学来提升AI的创造力输出。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "minor updates to content + figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17218v4",
      "published_date": "2024-10-22 17:43:39 UTC",
      "updated_date": "2024-12-09 12:45:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:00:38.315287"
    },
    {
      "arxiv_id": "2410.17212v1",
      "title": "Neuroevolution Neural Architecture Search for Evolving RNNs in Stock Return Prediction and Portfolio Trading",
      "title_zh": "翻译失败",
      "authors": [
        "Zimeng Lyu",
        "Amulya Saxena",
        "Rohaan Nadeem",
        "Hao Zhang",
        "Travis Desell"
      ],
      "abstract": "Stock return forecasting is a major component of numerous finance\napplications. Predicted stock returns can be incorporated into portfolio\ntrading algorithms to make informed buy or sell decisions which can optimize\nreturns. In such portfolio trading applications, the predictive performance of\na time series forecasting model is crucial. In this work, we propose the use of\nthe Evolutionary eXploration of Augmenting Memory Models (EXAMM) algorithm to\nprogressively evolve recurrent neural networks (RNNs) for stock return\npredictions. RNNs are evolved independently for each stocks and portfolio\ntrading decisions are made based on the predicted stock returns. The portfolio\nused for testing consists of the 30 companies in the Dow-Jones Index (DJI) with\neach stock have the same weight. Results show that using these evolved RNNs and\na simple daily long-short strategy can generate higher returns than both the\nDJI index and the S&P 500 Index for both 2022 (bear market) and 2023 (bull\nmarket).",
      "tldr_zh": "本研究提出使用Evolutionary eXploration of Augmenting Memory Models (EXAMM)算法，通过神经进化神经架构搜索演化RNNs（循环神经网络），以预测股票回报并优化投资组合交易。RNNs为每支股票独立演化，然后基于预测结果采用简单的每日长短策略进行买卖决策。实验在道琼斯指数(DJI)的30家公司股票组合上进行，结果显示，该方法在2022年熊市和2023年牛市中，均产生了高于DJI指数和S&P 500指数的回报。",
      "categories": [
        "q-fin.PM",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "q-fin.PM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17212v1",
      "published_date": "2024-10-22 17:37:18 UTC",
      "updated_date": "2024-10-22 17:37:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:00:48.938975"
    },
    {
      "arxiv_id": "2410.17210v1",
      "title": "Exploring Possibilities of AI-Powered Legal Assistance in Bangladesh through Large Language Modeling",
      "title_zh": "通过大型语言模型探索孟加拉国的AI驱动法律援助可能性",
      "authors": [
        "Azmine Toushik Wasi",
        "Wahid Faisal",
        "Mst Rafia Islam",
        "Mahathir Mohammad Bappy"
      ],
      "abstract": "Purpose: Bangladesh's legal system struggles with major challenges like\ndelays, complexity, high costs, and millions of unresolved cases, which deter\nmany from pursuing legal action due to lack of knowledge or financial\nconstraints. This research seeks to develop a specialized Large Language Model\n(LLM) to assist in the Bangladeshi legal system. Methods: We created\nUKIL-DB-EN, an English corpus of Bangladeshi legal documents, by collecting and\nscraping data on various legal acts. We fine-tuned the GPT-2 model on this\ndataset to develop GPT2-UKIL-EN, an LLM focused on providing legal assistance\nin English. Results: The model was rigorously evaluated using semantic\nassessments, including case studies supported by expert opinions. The\nevaluation provided promising results, demonstrating the potential for the\nmodel to assist in legal matters within Bangladesh. Conclusion: Our work\nrepresents the first structured effort toward building an AI-based legal\nassistant for Bangladesh. While the results are encouraging, further\nrefinements are necessary to improve the model's accuracy, credibility, and\nsafety. This is a significant step toward creating a legal AI capable of\nserving the needs of a population of 180 million.",
      "tldr_zh": "本研究探讨了通过Large Language Modeling为孟加拉国法律系统提供AI辅助的可能性，旨在解决该国面临的延误、高成本和未决案件等问题。研究者构建了UKIL-DB-EN语料库，该语料库收集了各种孟加拉国法律文件的英语文本，并在此基础上微调GPT-2模型，开发了专注于法律援助的GPT2-UKIL-EN模型。模型通过语义评估、案例研究和专家意见的评估显示出良好的表现，证明了其在法律事务中的潜在应用价值。尽管结果令人鼓舞，但仍需进一步改进模型的准确性、可信度和安全性，这标志着为孟加拉国1.8亿人口构建AI法律助理的首次结构化努力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "In Review",
      "pdf_url": "http://arxiv.org/pdf/2410.17210v1",
      "published_date": "2024-10-22 17:34:59 UTC",
      "updated_date": "2024-10-22 17:34:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:01:02.525081"
    },
    {
      "arxiv_id": "2410.17196v3",
      "title": "VoiceBench: Benchmarking LLM-Based Voice Assistants",
      "title_zh": "VoiceBench：基于 LLM 的语音助手基准测试",
      "authors": [
        "Yiming Chen",
        "Xianghu Yue",
        "Chen Zhang",
        "Xiaoxue Gao",
        "Robby T. Tan",
        "Haizhou Li"
      ],
      "abstract": "Building on the success of large language models (LLMs), recent advancements\nsuch as GPT-4o have enabled real-time speech interactions through LLM-based\nvoice assistants, offering a significantly improved user experience compared to\ntraditional text-based interactions. However, the absence of benchmarks\ndesigned to evaluate these speech interaction capabilities has hindered\nprogress of LLM-based voice assistants development. Current evaluations focus\nprimarily on automatic speech recognition (ASR) or general knowledge evaluation\nwith clean speeches, neglecting the more intricate, real-world scenarios that\ninvolve diverse speaker characteristics, environmental and content factors. To\naddress this, we introduce VoiceBench, the first benchmark designed to provide\na multi-faceted evaluation of LLM-based voice assistants. VoiceBench also\nincludes both real and synthetic spoken instructions that incorporate the above\nthree key real-world variations. Extensive experiments reveal the limitations\nof current LLM-based voice assistant models and offer valuable insights for\nfuture research and development in this field.",
      "tldr_zh": "本论文引入 VoiceBench，这是一个专为评估基于大型语言模型 (LLMs) 的语音助手而设计的首个基准，旨在填补当前评估中对真实世界场景（如多样化说话者特征、环境和内容因素）的忽略。VoiceBench 包含真实和合成的语音指令，涵盖这些关键变异，并通过多方面评估来测试语音交互能力。实验结果揭示了现有 LLM-based 语音助手模型的局限性，并为未来研究提供宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress. Data is available at\n  https://github.com/MatthewCYM/VoiceBench",
      "pdf_url": "http://arxiv.org/pdf/2410.17196v3",
      "published_date": "2024-10-22 17:15:20 UTC",
      "updated_date": "2024-12-11 15:45:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:01:12.205858"
    },
    {
      "arxiv_id": "2410.17195v3",
      "title": "Non-myopic Generation of Language Models for Reasoning and Planning",
      "title_zh": "非短视生成语言模型用于推理和规划",
      "authors": [
        "Chang Ma",
        "Haiteng Zhao",
        "Junlei Zhang",
        "Junxian He",
        "Lingpeng Kong"
      ],
      "abstract": "Large Language Models have demonstrated remarkable abilities in reasoning and\nplanning by breaking down complex problems into sequential steps. Despite their\nsuccess in various domains like mathematical problem-solving and coding, LLMs\nface challenges in ensuring reliable and optimal planning due to their inherent\nmyopic nature of autoregressive decoding. This paper revisits LLM reasoning\nfrom an optimal-control perspective, proposing a novel method,\nPredictive-Decoding, that leverages Model Predictive Control to enhance\nplanning accuracy. By re-weighting LLM distributions based on foresight\ntrajectories, Predictive-Decoding aims to mitigate early errors and promote\nnon-myopic planning. Our experiments show significant improvements in a wide\nrange of tasks for math, coding, and agents. Furthermore, Predictive-Decoding\ndemonstrates computational efficiency, outperforming search baselines with\nreduced computational resources. This study provides insights into optimizing\nLLM planning capabilities.",
      "tldr_zh": "本文研究了大语言模型（LLMs）在推理和规划中的短视问题，即自回归解码导致的规划不可靠性。论文从最优控制视角提出了一种新方法Predictive-Decoding，利用Model Predictive Control通过重新加权LLM分布和预见轨迹来减少早期错误并促进非短视规划。实验结果显示，该方法在数学、编码和代理任务中显著提升了性能，同时在计算效率上优于搜索基线，为优化LLMs的规划能力提供了关键见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17195v3",
      "published_date": "2024-10-22 17:13:38 UTC",
      "updated_date": "2024-10-28 17:28:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:01:25.774579"
    },
    {
      "arxiv_id": "2410.17193v2",
      "title": "Emphasizing Discriminative Features for Dataset Distillation in Complex Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Wang",
        "Zekai Li",
        "Zhi-Qi Cheng",
        "Samir Khaki",
        "Ahmad Sajedi",
        "Ramakrishna Vedantam",
        "Konstantinos N Plataniotis",
        "Alexander Hauptmann",
        "Yang You"
      ],
      "abstract": "Dataset distillation has demonstrated strong performance on simple datasets\nlike CIFAR, MNIST, and TinyImageNet but struggles to achieve similar results in\nmore complex scenarios. In this paper, we propose EDF (emphasizes the\ndiscriminative features), a dataset distillation method that enhances key\ndiscriminative regions in synthetic images using Grad-CAM activation maps. Our\napproach is inspired by a key observation: in simple datasets, high-activation\nareas typically occupy most of the image, whereas in complex scenarios, the\nsize of these areas is much smaller. Unlike previous methods that treat all\npixels equally when synthesizing images, EDF uses Grad-CAM activation maps to\nenhance high-activation areas. From a supervision perspective, we downplay\nsupervision signals that have lower losses, as they contain common patterns.\nAdditionally, to help the DD community better explore complex scenarios, we\nbuild the Complex Dataset Distillation (Comp-DD) benchmark by meticulously\nselecting sixteen subsets, eight easy and eight hard, from ImageNet-1K. In\nparticular, EDF consistently outperforms SOTA results in complex scenarios,\nsuch as ImageNet-1K subsets. Hopefully, more researchers will be inspired and\nencouraged to improve the practicality and efficacy of DD. Our code and\nbenchmark will be made public at https://github.com/NUS-HPC-AI-Lab/EDF.",
      "tldr_zh": "本论文提出了一种名为 EDF 的数据集蒸馏方法，旨在解决现有方法在复杂场景（如 ImageNet-1K）中的性能不足问题，通过使用 Grad-CAM 激活地图来增强合成图像中的关键鉴别区域。EDF 不同于以往方法，它优先处理高激活区域，并从监督角度降低损失较低的信号，以避免过度关注常见模式。论文还构建了 Complex Dataset Distillation (Comp-DD) 基准，包括从 ImageNet-1K 中选出的16个子集，用于评估复杂场景。实验结果显示，EDF 在这些场景中 consistently outperforms SOTA 结果，提高了数据集蒸馏的实用性和有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17193v2",
      "published_date": "2024-10-22 17:13:19 UTC",
      "updated_date": "2025-03-31 04:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:01:37.679184"
    },
    {
      "arxiv_id": "2410.17186v1",
      "title": "DyPNIPP: Predicting Environment Dynamics for RL-based Robust Informative Path Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Srujan Deolasee",
        "Siva Kailas",
        "Wenhao Luo",
        "Katia Sycara",
        "Woojun Kim"
      ],
      "abstract": "Informative path planning (IPP) is an important planning paradigm for various\nreal-world robotic applications such as environment monitoring. IPP involves\nplanning a path that can learn an accurate belief of the quantity of interest,\nwhile adhering to planning constraints. Traditional IPP methods typically\nrequire high computation time during execution, giving rise to reinforcement\nlearning (RL) based IPP methods. However, the existing RL-based methods do not\nconsider spatio-temporal environments which involve their own challenges due to\nvariations in environment characteristics. In this paper, we propose DyPNIPP, a\nrobust RL-based IPP framework, designed to operate effectively across\nspatio-temporal environments with varying dynamics. To achieve this, DyPNIPP\nincorporates domain randomization to train the agent across diverse\nenvironments and introduces a dynamics prediction model to capture and adapt\nthe agent actions to specific environment dynamics. Our extensive experiments\nin a wildfire environment demonstrate that DyPNIPP outperforms existing\nRL-based IPP algorithms by significantly improving robustness and performing\nacross diverse environment conditions.",
      "tldr_zh": "本文提出 DyPNIPP，一个基于强化学习 (RL) 的鲁棒 Informative Path Planning (IPP) 框架，旨在应对时空环境中动态变化的挑战。DyPNIPP 通过域随机化训练代理以适应多样环境，并引入动态预测模型来捕捉并调整代理行为，以优化路径规划。实验结果显示，在野火环境条件下，DyPNIPP 显著提升了鲁棒性和性能，优于现有 RL-based IPP 算法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 4 figures, submitted to IEEE RA-L",
      "pdf_url": "http://arxiv.org/pdf/2410.17186v1",
      "published_date": "2024-10-22 17:07:26 UTC",
      "updated_date": "2024-10-22 17:07:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:01:48.954789"
    },
    {
      "arxiv_id": "2410.17172v1",
      "title": "KANICE: Kolmogorov-Arnold Networks with Interactive Convolutional Elements",
      "title_zh": "翻译失败",
      "authors": [
        "Md Meftahul Ferdaus",
        "Mahdi Abdelguerfi",
        "Elias Ioup",
        "David Dobson",
        "Kendall N. Niles",
        "Ken Pathak",
        "Steven Sloan"
      ],
      "abstract": "We introduce KANICE (Kolmogorov-Arnold Networks with Interactive\nConvolutional Elements), a novel neural architecture that combines\nConvolutional Neural Networks (CNNs) with Kolmogorov-Arnold Network (KAN)\nprinciples. KANICE integrates Interactive Convolutional Blocks (ICBs) and KAN\nlinear layers into a CNN framework. This leverages KANs' universal\napproximation capabilities and ICBs' adaptive feature learning. KANICE captures\ncomplex, non-linear data relationships while enabling dynamic,\ncontext-dependent feature extraction based on the Kolmogorov-Arnold\nrepresentation theorem. We evaluated KANICE on four datasets: MNIST,\nFashion-MNIST, EMNIST, and SVHN, comparing it against standard CNNs, CNN-KAN\nhybrids, and ICB variants. KANICE consistently outperformed baseline models,\nachieving 99.35% accuracy on MNIST and 90.05% on the SVHN dataset.\n  Furthermore, we introduce KANICE-mini, a compact variant designed for\nefficiency. A comprehensive ablation study demonstrates that KANICE-mini\nachieves comparable performance to KANICE with significantly fewer parameters.\nKANICE-mini reached 90.00% accuracy on SVHN with 2,337,828 parameters, compared\nto KANICE's 25,432,000. This study highlights the potential of KAN-based\narchitectures in balancing performance and computational efficiency in image\nclassification tasks. Our work contributes to research in adaptive neural\nnetworks, integrates mathematical theorems into deep learning architectures,\nand explores the trade-offs between model complexity and performance, advancing\ncomputer vision and pattern recognition. The source code for this paper is\npublicly accessible through our GitHub repository\n(https://github.com/m-ferdaus/kanice).",
      "tldr_zh": "该研究提出 KANICE，一种新型神经架构，将 Convolutional Neural Networks (CNNs) 与 Kolmogorov-Arnold Networks (KAN) 原则相结合，通过整合 Interactive Convolutional Blocks (ICBs) 和 KAN 线性层，实现复杂非线性数据关系的捕捉及动态特征提取。实验在 MNIST、Fashion-MNIST、EMNIST 和 SVHN 数据集上评估，KANICE 超过了基线模型，分别在 MNIST 上达到 99.35% 和 SVHN 上 90.05% 的准确率。此外，论文引入了 KANICE-mini 这一高效变体，通过消融研究证明其在减少参数（从 25,432,000 降至 2,337,828）的同时保持类似性能，突显了 KAN 架构在图像分类任务中性能与计算效率的平衡。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17172v1",
      "published_date": "2024-10-22 16:50:34 UTC",
      "updated_date": "2024-10-22 16:50:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:02:04.056993"
    },
    {
      "arxiv_id": "2410.17173v1",
      "title": "Reinforcement learning on structure-conditioned categorical diffusion for protein inverse folding",
      "title_zh": "翻译失败",
      "authors": [
        "Yasha Ektefaie",
        "Olivia Viessmann",
        "Siddharth Narayanan",
        "Drew Dresser",
        "J. Mark Kim",
        "Armen Mkrtchyan"
      ],
      "abstract": "Protein inverse folding-that is, predicting an amino acid sequence that will\nfold into the desired 3D structure-is an important problem for structure-based\nprotein design. Machine learning based methods for inverse folding typically\nuse recovery of the original sequence as the optimization objective. However,\ninverse folding is a one-to-many problem where several sequences can fold to\nthe same structure. Moreover, for many practical applications, it is often\ndesirable to have multiple, diverse sequences that fold into the target\nstructure since it allows for more candidate sequences for downstream\noptimizations. Here, we demonstrate that although recent inverse folding\nmethods show increased sequence recovery, their \"foldable diversity\"-i.e. their\nability to generate multiple non-similar sequences that fold into the\nstructures consistent with the target-does not increase. To address this, we\npresent RL-DIF, a categorical diffusion model for inverse folding that is\npre-trained on sequence recovery and tuned via reinforcement learning on\nstructural consistency. We find that RL-DIF achieves comparable sequence\nrecovery and structural consistency to benchmark models but shows greater\nfoldable diversity: experiments show RL-DIF can achieve an foldable diversity\nof 29% on CATH 4.2, compared to 23% from models trained on the same dataset.\nThe PyTorch model weights and sampling code are available on GitHub.",
      "tldr_zh": "本研究针对蛋白质逆折叠（protein inverse folding）问题，提出了一种基于结构条件类别扩散模型（structure-conditioned categorical diffusion）的RL-DIF方法，该方法先通过预训练优化序列恢复，然后利用Reinforcement Learning微调结构一致性，以生成更多多样化的折叠序列。传统方法虽提升了序列恢复率，但foldable diversity（可折叠多样性）不足，RL-DIF则在保持与基准模型相当的序列恢复和结构一致性的同时，大幅提高了多样性，在CATH 4.2数据集上实现29%的foldable diversity，相比基准模型的23%有显著改善。该方法为结构导向蛋白质设计提供了更灵活的序列生成选项，并提供了PyTorch模型权重和采样代码以便复现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17173v1",
      "published_date": "2024-10-22 16:50:34 UTC",
      "updated_date": "2024-10-22 16:50:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:02:13.596836"
    },
    {
      "arxiv_id": "2410.17160v1",
      "title": "Layered LA-MAPF: a decomposition of large agent MAPF instance to accelerate solving without compromising solvability",
      "title_zh": "分层 LA",
      "authors": [
        "Zhuo Yao"
      ],
      "abstract": "Multi-Agent Path Finding (MAPF) has been widely studied in recent years.\nHowever, most existing MAPF algorithms assume that an agent occupies only a\nsingle grid in a grid-based map. This assumption limits their applicability in\nmany real-world domains where agents have geometric shapes, rather than being\npoint-like. Such agents, which can occupy multiple cells simultaneously, are\nreferred to as ``large'' agents. When considering the shape and size of agents\nin MAPF, the computational complexity increases significantly as the number of\nagents grows, primarily due to the increased overhead in conflict detection\nbetween geometric agents. In this paper, we propose two types of subproblems\nfor the LA-MAPF (Large-Agent MAPF) problem: \\textbf{cluster} (which has no\nconstraints on the order of solution) and \\textbf{level} (which imposes\nconstraints on the solution order). We introduce \\textbf{Layered LA-MAPF}, a\nmethod that decomposes a MAPF instance involving geometric agents into\nclusters, and then further decomposes each cluster into levels. This approach\naims to reduce time complexity when solving LA-MAPF problems. Our results\ndemonstrate the performance of our method as the number of agents increases\nacross various maps, and how it accelerates LA-MAPF methods, such as LA-CBS and\nLA-LaCAM. Experiments show that our LA-MAPF method with instance decomposition\n\\textbf{halves the time cost (reducing from an average of 40s to 20s) and\ntriples the success rate (from an average of 0.27 to 0.80)} in finding a\nsolution within 60 seconds. To facilitate further research, we have made the\nsource code for Layered LA-MAPF publicly available at\n\\url{https://github.com/JoeYao-bit/LayeredMAPF/algorithm/LA-MAPF}.",
      "tldr_zh": "这篇论文针对 Multi-Agent Path Finding (MAPF) 中大型代理（geometric agents）的计算复杂度问题，提出了 Layered LA-MAPF 方法，通过将问题分解成无顺序约束的 cluster 和有顺序约束的 level 子问题，从而加速求解过程而不影响整体可求解性。Layered LA-MAPF 首先将 MAPF 实例分解为 clusters，然后进一步细分为 levels，以减少代理间冲突检测的开销。实验结果显示，该方法在各种地图上显著提升了 LA-CBS 和 LA-LaCAM 等算法的性能，将平均求解时间减半（从40秒到20秒），并将成功率提高三倍（从0.27到0.80）。源代码已公开在 GitHub 上，以支持进一步研究。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17160v1",
      "published_date": "2024-10-22 16:34:24 UTC",
      "updated_date": "2024-10-22 16:34:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:02:26.470284"
    },
    {
      "arxiv_id": "2410.17145v1",
      "title": "Can General-Purpose Large Language Models Generalize to English-Thai Machine Translation ?",
      "title_zh": "翻译失败",
      "authors": [
        "Jirat Chiaranaipanich",
        "Naiyarat Hanmatheekuna",
        "Jitkapat Sawatphol",
        "Krittamate Tiankanon",
        "Jiramet Kinchagawat",
        "Amrest Chinkamol",
        "Parinthapat Pengpun",
        "Piyalitt Ittichaiwong",
        "Peerat Limkonchotiwat"
      ],
      "abstract": "Large language models (LLMs) perform well on common tasks but struggle with\ngeneralization in low-resource and low-computation settings. We examine this\nlimitation by testing various LLMs and specialized translation models on\nEnglish-Thai machine translation and code-switching datasets. Our findings\nreveal that under more strict computational constraints, such as 4-bit\nquantization, LLMs fail to translate effectively. In contrast, specialized\nmodels, with comparable or lower computational requirements, consistently\noutperform LLMs. This underscores the importance of specialized models for\nmaintaining performance under resource constraints.",
      "tldr_zh": "这篇论文评估了通用大型语言模型 (LLMs) 在英语-泰语机器翻译中的泛化能力，通过测试各种 LLMs 和专业翻译模型在低资源和低计算设置下的表现。研究发现，在严格计算约束如 4-bit quantization 下，LLMs 无法有效处理翻译任务，而专业模型在相近或更低计算需求下表现出色。结果强调了在资源受限环境中，使用专业模型来维持性能的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in GenBench EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.17145v1",
      "published_date": "2024-10-22 16:26:03 UTC",
      "updated_date": "2024-10-22 16:26:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:02:36.594783"
    },
    {
      "arxiv_id": "2410.17141v4",
      "title": "Towards Automated Penetration Testing: Introducing LLM Benchmark, Analysis, and Improvements",
      "title_zh": "迈向自动化渗透测试：介绍 LLM 基准测试、分析和改进",
      "authors": [
        "Isamu Isozaki",
        "Manil Shrestha",
        "Rick Console",
        "Edward Kim"
      ],
      "abstract": "Hacking poses a significant threat to cybersecurity, inflicting billions of\ndollars in damages annually. To mitigate these risks, ethical hacking, or\npenetration testing, is employed to identify vulnerabilities in systems and\nnetworks. Recent advancements in large language models (LLMs) have shown\npotential across various domains, including cybersecurity. However, there is\ncurrently no comprehensive, open, automated, end-to-end penetration testing\nbenchmark to drive progress and evaluate the capabilities of these models in\nsecurity contexts. This paper introduces a novel open benchmark for LLM-based\nautomated penetration testing, addressing this critical gap. We first evaluate\nthe performance of LLMs, including GPT-4o and LLama 3.1-405B, using the\nstate-of-the-art PentestGPT tool. Our findings reveal that while LLama 3.1\ndemonstrates an edge over GPT-4o, both models currently fall short of\nperforming end-to-end penetration testing even with some minimal human\nassistance. Next, we advance the state-of-the-art and present ablation studies\nthat provide insights into improving the PentestGPT tool. Our research\nilluminates the challenges LLMs face in each aspect of Pentesting, e.g.\nenumeration, exploitation, and privilege escalation. This work contributes to\nthe growing body of knowledge on AI-assisted cybersecurity and lays the\nfoundation for future research in automated penetration testing using large\nlanguage models.",
      "tldr_zh": "本研究针对黑客威胁及其对网络安全的损害，引入了一个新的开放基准，用于评估和改进LLM（Large Language Models）在自动化渗透测试中的性能。主要方法包括使用PentestGPT工具评估GPT-4o和Llama 3.1-405B模型，结果显示Llama 3.1略优于GPT-4o，但两者在enumeration、exploitation和privilege escalation等环节仍需人工辅助，无法实现端到端测试。通过消融研究，该工作揭示了LLM的挑战并提出改进方案，为AI辅助网络安全领域奠定基础。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Main Paper 1-9 pages, Supplementary Materials: 10-17, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17141v4",
      "published_date": "2024-10-22 16:18:41 UTC",
      "updated_date": "2025-02-21 17:53:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:02:48.954805"
    },
    {
      "arxiv_id": "2410.17139v2",
      "title": "Trustworthy XAI and Application",
      "title_zh": "翻译失败",
      "authors": [
        "MD Abdullah Al Nasim",
        "A. S. M Anas Ferdous",
        "Abdur Rashid",
        "Fatema Tuj Johura Soshi",
        "Parag Biswas",
        "Angona Biswas",
        "Kishor Datta Gupta"
      ],
      "abstract": "Artificial Intelligence (AI) is an important part of our everyday lives. We\nuse it in self-driving cars and smartphone assistants. People often call it a\n\"black box\" because its complex systems, especially deep neural networks, are\nhard to understand. This complexity raises concerns about accountability, bias,\nand fairness, even though AI can be quite accurate. Explainable Artificial\nIntelligence (XAI) is important for building trust. It helps ensure that AI\nsystems work reliably and ethically. This article looks at XAI and its three\nmain parts: transparency, explainability, and trustworthiness. We will discuss\nwhy these components matter in real-life situations. We will also review recent\nstudies that show how XAI is used in different fields. Ultimately, gaining\ntrust in AI systems is crucial for their successful use in society.",
      "tldr_zh": "这篇论文探讨了可解释人工智能(XAI)的概念及其在构建AI信任方面的关键作用，强调AI系统的复杂性（如深度神经网络）可能导致的责任、偏见和公平性问题。文章分析了XAI的三个核心组成部分：透明性、解释性和可信度，并说明这些元素在现实生活中的重要性，以确保AI可靠且合乎道德。作者回顾了XAI在不同领域的最新应用研究，最终指出，获得对AI系统的信任是其在社会中成功部署的必要条件。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17139v2",
      "published_date": "2024-10-22 16:10:10 UTC",
      "updated_date": "2025-04-16 18:07:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:03:01.055610"
    },
    {
      "arxiv_id": "2410.17126v1",
      "title": "Exploring RL-based LLM Training for Formal Language Tasks with Programmed Rewards",
      "title_zh": "探索基于RL的LLM训练，用于形式语言任务并采用编程奖励",
      "authors": [
        "Alexander G. Padula",
        "Dennis J. N. J. Soemers"
      ],
      "abstract": "Proximal Policy Optimization (PPO) is commonly used in Reinforcement Learning\nfrom Human Feedback to align large language models (LLMs) with downstream\ntasks. This paper investigates the feasibility of using PPO for direct\nreinforcement learning (RL) from explicitly programmed reward signals, as\nopposed to indirect learning from human feedback via an intermediary reward\nmodel. We focus on tasks expressed through formal languages, such as\nmathematics and programming, where explicit reward functions can be programmed\nto automatically assess the quality of generated outputs. We apply this\napproach to a sentiment alignment task, a simple arithmetic task, and a more\ncomplex game synthesis task. The sentiment alignment task replicates prior\nresearch and serves to validate our experimental setup. Our results show that\npure RL-based training for the two formal language tasks is challenging, with\nsuccess being limited even for the simple arithmetic task. We propose a novel\nbatch-entropy regularization term to aid exploration, although training is not\nyet entirely stable. Our findings suggest that direct RL training of LLMs may\nbe more suitable for relatively minor changes, such as alignment, than for\nlearning new tasks altogether, even if an informative reward signal can be\nexpressed programmatically.",
      "tldr_zh": "这篇论文探讨了使用 Proximal Policy Optimization (PPO) 进行直接 Reinforcement Learning (RL) 训练 Large Language Models (LLMs)，以处理正式语言任务（如数学和编程），通过显式编程的奖励信号代替人类反馈。研究者将此方法应用于情感对齐任务、简单算术任务和复杂游戏合成任务，结果显示纯 RL 训练在正式语言任务上极具挑战性，即使是简单算术任务也仅取得有限成功。论文提出了一种新型 batch-entropy 正则化术语来增强探索，但训练稳定性仍不理想。总体而言，直接 RL 训练 LLMs 更适用于微调如对齐，而非完全学习新任务，即使奖励信号可编程化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at BNAIC 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.17126v1",
      "published_date": "2024-10-22 15:59:58 UTC",
      "updated_date": "2024-10-22 15:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:03:14.448845"
    },
    {
      "arxiv_id": "2410.17124v1",
      "title": "Automated neuroradiological support systems for multiple cerebrovascular disease markers -- A systematic review and meta-analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Jesse Phitidis",
        "Alison Q. O'Neil",
        "William N. Whiteley",
        "Beatrice Alex",
        "Joanna M. Wardlaw",
        "Miguel O. Bernabeu",
        "Maria Valdés Hernández"
      ],
      "abstract": "Cerebrovascular diseases (CVD) can lead to stroke and dementia. Stroke is the\nsecond leading cause of death world wide and dementia incidence is increasing\nby the year. There are several markers of CVD that are visible on brain\nimaging, including: white matter hyperintensities (WMH), acute and chronic\nischaemic stroke lesions (ISL), lacunes, enlarged perivascular spaces (PVS),\nacute and chronic haemorrhagic lesions, and cerebral microbleeds (CMB). Brain\natrophy also occurs in CVD. These markers are important for patient management\nand intervention, since they indicate elevated risk of future stroke and\ndementia. We systematically reviewed automated systems designed to support\nradiologists reporting on these CVD imaging findings. We considered\ncommercially available software and research publications which identify at\nleast two CVD markers. In total, we included 29 commercial products and 13\nresearch publications. Two distinct types of commercial support system were\navailable: those which identify acute stroke lesions (haemorrhagic and\nischaemic) from computed tomography (CT) scans, mainly for the purpose of\npatient triage; and those which measure WMH and atrophy regionally and\nlongitudinally. In research, WMH and ISL were the markers most frequently\nanalysed together, from magnetic resonance imaging (MRI) scans; lacunes and PVS\nwere each targeted only twice and CMB only once. For stroke, commercially\navailable systems largely support the emergency setting, whilst research\nsystems consider also follow-up and routine scans. The systems to quantify WMH\nand atrophy are focused on neurodegenerative disease support, where these CVD\nmarkers are also of significance. There are currently no openly validated\nsystems, commercially, or in research, performing a comprehensive joint\nanalysis of all CVD markers (WMH, ISL, lacunes, PVS, haemorrhagic lesions, CMB,\nand atrophy).",
      "tldr_zh": "这篇论文通过系统综述和荟萃分析，评估了自动神经放射学支持系统在识别脑血管疾病 (CVD) 标记物方面的表现，这些标记物包括白质高信号 (WMH)、缺血性卒中病变 (ISL)、腔隙 (lacunes)、扩大血管周围空间 (PVS)、出血性病变、脑微出血 (CMB) 和脑萎缩。研究纳入了29个商业产品和13个研究出版物，发现商业系统主要从 CT 扫描识别急性卒中病变以支持患者分流，并测量 WMH 和脑萎缩，而研究系统则更常从 MRI 扫描分析 WMH 和 ISL。总体结果显示，现有的系统多针对特定标记物，缺乏全面的联合分析，且目前没有公开验证的系统能同时覆盖所有 CVD 标记物，这为未来开发更全面的临床工具提供了重要启示。",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "A.1; J.3"
      ],
      "primary_category": "physics.med-ph",
      "comment": "62 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17124v1",
      "published_date": "2024-10-22 15:59:07 UTC",
      "updated_date": "2024-10-22 15:59:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:03:27.166960"
    },
    {
      "arxiv_id": "2410.17111v1",
      "title": "Permutation Picture of Graph Combinatorial Optimization Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Yimeng Min"
      ],
      "abstract": "This paper proposes a framework that formulates a wide range of graph\ncombinatorial optimization problems using permutation-based representations.\nThese problems include the travelling salesman problem, maximum independent\nset, maximum cut, and various other related problems. This work potentially\nopens up new avenues for algorithm design in neural combinatorial optimization,\nbridging the gap between discrete and continuous optimization techniques.",
      "tldr_zh": "这篇论文提出了一种框架，使用基于置换(permutation-based representations)来表述各种图组合优化问题，包括travelling salesman problem、maximum independent set、maximum cut 等相关问题。该框架有助于将这些离散优化问题统一表示，为神经组合优化(neural combinatorial optimization)算法设计开辟新途径。通过桥接离散和连续优化技术，该工作可能提升算法的适用性和效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17111v1",
      "published_date": "2024-10-22 15:36:04 UTC",
      "updated_date": "2024-10-22 15:36:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:03:37.301067"
    },
    {
      "arxiv_id": "2410.17088v2",
      "title": "Science Out of Its Ivory Tower: Improving Accessibility with Reinforcement Learning",
      "title_zh": "科学走出象牙塔：利用强化学习提升可访问性",
      "authors": [
        "Haining Wang",
        "Jason Clark",
        "Hannah McKelvey",
        "Leila Sterman",
        "Zheng Gao",
        "Zuoyu Tian",
        "Sandra Kübler",
        "Xiaozhong Liu"
      ],
      "abstract": "A vast amount of scholarly work is published daily, yet much of it remains\ninaccessible to the general public due to dense jargon and complex language. To\naddress this challenge in science communication, we introduce a reinforcement\nlearning framework that fine-tunes a language model to rewrite scholarly\nabstracts into more comprehensible versions. Guided by a carefully balanced\ncombination of word- and sentence-level accessibility rewards, our language\nmodel effectively substitutes technical terms with more accessible\nalternatives, a task which models supervised fine-tuned or guided by\nconventional readability measures struggle to accomplish. Our best model\nadjusts the readability level of scholarly abstracts by approximately six U.S.\ngrade levels -- in other words, from a postgraduate to a high school level.\nThis translates to roughly a 90% relative boost over the supervised fine-tuning\nbaseline, all while maintaining factual accuracy and high-quality language. An\nin-depth analysis of our approach shows that balanced rewards lead to\nsystematic modifications in the base model, likely contributing to smoother\noptimization and superior performance. We envision this work as a step toward\nbridging the gap between scholarly research and the general public,\nparticularly younger readers and those without a college degree.",
      "tldr_zh": "本研究针对学术论文的密集行话和复杂语言导致公众难以访问的问题，提出了一种强化学习(reinforcement learning)框架，用于微调语言模型，将学术摘要改写为更易懂的版本。该框架通过平衡的词级和句级可访问性奖励，系统替换技术术语，同时保持事实准确性和高质量语言。实验结果显示，该模型将摘要可读性级别降低约六个美国年级水平（从研究生到高中水平），较监督微调基准提升约90%，有助于桥接学术研究与公众的差距，特别是针对年轻读者和非大学学历者。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17088v2",
      "published_date": "2024-10-22 15:14:54 UTC",
      "updated_date": "2025-04-16 16:00:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:03:50.136160"
    },
    {
      "arxiv_id": "2410.17050v1",
      "title": "UnStar: Unlearning with Self-Taught Anti-Sample Reasoning for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yash Sinha",
        "Murari Mandal",
        "Mohan Kankanhalli"
      ],
      "abstract": "The key components of machine learning are data samples for training, model\nfor learning patterns, and loss function for optimizing accuracy. Analogously,\nunlearning can potentially be achieved through anti-data samples (or\nanti-samples), unlearning method, and reversed loss function. While prior\nresearch has explored unlearning methods and reversed loss functions, the\npotential of anti-samples remains largely untapped. In this paper, we introduce\nUnSTAR: Unlearning with Self-Taught Anti-Sample Reasoning for large language\nmodels (LLMs). Our contributions are threefold; first, we propose a novel\nconcept of anti-sample-induced unlearning; second, we generate anti-samples by\nleveraging misleading rationales, which help reverse learned associations and\naccelerate the unlearning process; and third, we enable fine-grained targeted\nunlearning, allowing for the selective removal of specific associations without\nimpacting related knowledge - something not achievable by previous works.\nResults demonstrate that anti-samples offer an efficient, targeted unlearning\nstrategy for LLMs, opening new avenues for privacy-preserving machine learning\nand model modification.",
      "tldr_zh": "本论文提出UnSTAR，一种基于Self-Taught Anti-Sample Reasoning的方法，用于大型语言模型(LLMs)的unlearning过程。核心创新包括引入anti-sample-induced unlearning概念，通过生成misleading rationales的anti-samples来逆转模型学到的关联，并加速unlearning。UnSTAR还实现了fine-grained targeted unlearning，能够选择性地移除特定知识而不影响相关内容；实验结果表明，该方法提供高效、针对性的策略，为隐私保护机器学习和模型修改开辟新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17050v1",
      "published_date": "2024-10-22 14:30:03 UTC",
      "updated_date": "2024-10-22 14:30:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:04:02.807769"
    },
    {
      "arxiv_id": "2410.17049v1",
      "title": "A Comparison of Baseline Models and a Transformer Network for SOC Prediction in Lithium-Ion Batteries",
      "title_zh": "翻译失败",
      "authors": [
        "Hadeel Aboueidah",
        "Abdulrahman Altahhan"
      ],
      "abstract": "Accurately predicting the state of charge of Lithium-ion batteries is\nessential to the performance of battery management systems of electric\nvehicles. One of the main reasons for the slow global adoption of electric cars\nis driving range anxiety. The ability of a battery management system to\naccurately estimate the state of charge can help alleviate this problem. In\nthis paper, a comparison between data-driven state-of-charge estimation methods\nis conducted. The paper compares different neural network-based models and\ncommon regression models for SOC estimation. These models include several\nablated transformer networks, a neural network, a lasso regression model, a\nlinear regression model and a decision tree. Results of various experiments\nconducted on data obtained from natural driving cycles of the BMW i3 battery\nshow that the decision tree outperformed all other models including the more\ncomplex transformer network with self-attention and positional encoding.",
      "tldr_zh": "这篇论文比较了多种数据驱动模型在锂离子电池（Lithium-Ion Batteries）SOC（State of Charge）预测中的性能，旨在提升电动汽车电池管理系统（Battery Management Systems）的准确性，以缓解驾驶里程焦虑。研究评估了包括ablated transformer networks、neural network、Lasso regression、linear regression和decision tree在内的多种模型。实验结果基于BMW i3电池的自然驾驶周期数据显示，decision tree模型的表现超过了其他模型，包括更复杂的transformer network。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17049v1",
      "published_date": "2024-10-22 14:27:43 UTC",
      "updated_date": "2024-10-22 14:27:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:04:14.152898"
    },
    {
      "arxiv_id": "2410.17042v1",
      "title": "Deep Memory Search: A Metaheuristic Approach for Optimizing Heuristic Search",
      "title_zh": "翻译失败",
      "authors": [
        "Abdel-Rahman Hedar",
        "Alaa E. Abdel-Hakim",
        "Wael Deabes",
        "Youseef Alotaibi",
        "Kheir Eddine Bouazza"
      ],
      "abstract": "Metaheuristic search methods have proven to be essential tools for tackling\ncomplex optimization challenges, but their full potential is often constrained\nby conventional algorithmic frameworks. In this paper, we introduce a novel\napproach called Deep Heuristic Search (DHS), which models metaheuristic search\nas a memory-driven process. DHS employs multiple search layers and memory-based\nexploration-exploitation mechanisms to navigate large, dynamic search spaces.\nBy utilizing model-free memory representations, DHS enhances the ability to\ntraverse temporal trajectories without relying on probabilistic transition\nmodels. The proposed method demonstrates significant improvements in search\nefficiency and performance across a range of heuristic optimization problems.",
      "tldr_zh": "本研究提出了一种名为 Deep Heuristic Search (DHS) 的新方法，将 metaheuristic search 建模为一个基于内存的进程，以优化复杂启发式搜索问题。DHS 采用多个搜索层和内存驱动的 exploration-exploitation 机制，帮助在大型动态搜索空间中高效导航，同时利用 model-free memory representations，避免依赖 probabilistic transition models。该方法在各种 heuristic optimization 问题上展示了显著的搜索效率和性能提升，为 metaheuristic search 的应用提供了创新框架。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17042v1",
      "published_date": "2024-10-22 14:16:49 UTC",
      "updated_date": "2024-10-22 14:16:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:04:25.416812"
    },
    {
      "arxiv_id": "2410.19855v1",
      "title": "Personalized Recommendation Systems using Multimodal, Autonomous, Multi Agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Param Thakkar",
        "Anushka Yadav"
      ],
      "abstract": "This paper describes a highly developed personalised recommendation system\nusing multimodal, autonomous, multi-agent systems. The system focuses on the\nincorporation of futuristic AI tech and LLMs like Gemini-1.5- pro and LLaMA-70B\nto improve customer service experiences especially within e-commerce. Our\napproach uses multi agent, multimodal systems to provide best possible\nrecommendations to its users. The system is made up of three agents as a whole.\nThe first agent recommends products appropriate for answering the given\nquestion, while the second asks follow-up questions based on images that belong\nto these recommended products and is followed up with an autonomous search by\nthe third agent. It also features a real-time data fetch, user\npreferences-based recommendations and is adaptive learning. During complicated\nqueries the application processes with Symphony, and uses the Groq API to\nanswer quickly with low response times. It uses a multimodal way to utilize\ntext and images comprehensively, so as to optimize product recommendation and\ncustomer interaction.",
      "tldr_zh": "这篇论文提出了一种基于多模态、自治多智能体系统的个性化推荐系统，旨在提升电商领域的客户服务体验。\n系统由三个智能体组成：第一个智能体根据用户查询推荐合适产品，第二个智能体基于产品图像提出后续问题，第三个智能体进行自主搜索。\n它整合了如 Gemini-1.5-pro 和 LLaMA-70B 等 LLM，提供实时数据获取、用户偏好推荐和适应性学习，并利用 Symphony 处理复杂查询以及 Groq API 实现快速响应。\n总体上，该系统通过多模态方式（结合文本和图像）优化了产品推荐和客户交互，提升了推荐的准确性和效率。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19855v1",
      "published_date": "2024-10-22 14:11:26 UTC",
      "updated_date": "2024-10-22 14:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:04:39.638031"
    },
    {
      "arxiv_id": "2410.17032v1",
      "title": "Insights on Disagreement Patterns in Multimodal Safety Perception across Diverse Rater Groups",
      "title_zh": "多样评估者群体中多模态安全感知分歧模式的见解",
      "authors": [
        "Charvi Rastogi",
        "Tian Huey Teh",
        "Pushkar Mishra",
        "Roma Patel",
        "Zoe Ashwood",
        "Aida Mostafazadeh Davani",
        "Mark Diaz",
        "Michela Paganini",
        "Alicia Parrish",
        "Ding Wang",
        "Vinodkumar Prabhakaran",
        "Lora Aroyo",
        "Verena Rieser"
      ],
      "abstract": "AI systems crucially rely on human ratings, but these ratings are often\naggregated, obscuring the inherent diversity of perspectives in real-world\nphenomenon. This is particularly concerning when evaluating the safety of\ngenerative AI, where perceptions and associated harms can vary significantly\nacross socio-cultural contexts. While recent research has studied the impact of\ndemographic differences on annotating text, there is limited understanding of\nhow these subjective variations affect multimodal safety in generative AI. To\naddress this, we conduct a large-scale study employing highly-parallel safety\nratings of about 1000 text-to-image (T2I) generations from a demographically\ndiverse rater pool of 630 raters balanced across 30 intersectional groups\nacross age, gender, and ethnicity. Our study shows that (1) there are\nsignificant differences across demographic groups (including intersectional\ngroups) on how severe they assess the harm to be, and that these differences\nvary across different types of safety violations, (2) the diverse rater pool\ncaptures annotation patterns that are substantially different from expert\nraters trained on specific set of safety policies, and (3) the differences we\nobserve in T2I safety are distinct from previously documented group level\ndifferences in text-based safety tasks. To further understand these varying\nperspectives, we conduct a qualitative analysis of the open-ended explanations\nprovided by raters. This analysis reveals core differences into the reasons why\ndifferent groups perceive harms in T2I generations. Our findings underscore the\ncritical need for incorporating diverse perspectives into safety evaluation of\ngenerative AI ensuring these systems are truly inclusive and reflect the values\nof all users.",
      "tldr_zh": "本文研究了多模态安全感知中，不同评委群体间的分歧模式，特别针对生成式 AI 的文本到图像 (T2I) 生成的安全评估。研究通过对约 1000 个 T2I 样本进行大规模评分，涉及 630 名评委来自 30 个跨年龄、性别和种族的 intersectional groups，发现不同 demographic groups 对危害严重程度的评估存在显著差异，且这些差异随安全违规类型而变化，与专家评委的模式和文本安全任务有明显不同。定性分析进一步揭示了各群体感知危害的原因，如文化背景的影响。最终，该研究强调在生成式 AI 安全评估中纳入多样视角，以确保系统更具包容性和代表性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17032v1",
      "published_date": "2024-10-22 13:59:21 UTC",
      "updated_date": "2024-10-22 13:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:04:53.111561"
    },
    {
      "arxiv_id": "2410.17031v2",
      "title": "GeoCode-GPT: A Large Language Model for Geospatial Code Generation Tasks",
      "title_zh": "GeoCode-GPT：用于地理空间代码生成任务的大语言模型",
      "authors": [
        "Shuyang Hou",
        "Zhangxiao Shen",
        "Anqi Zhao",
        "Jianyuan Liang",
        "Zhipeng Gui",
        "Xuefeng Guan",
        "Rui Li",
        "Huayi Wu"
      ],
      "abstract": "The increasing demand for spatiotemporal data and modeling tasks in\ngeosciences has made geospatial code generation technology a critical factor in\nenhancing productivity. Although large language models (LLMs) have demonstrated\npotential in code generation tasks, they often encounter issues such as refusal\nto code or hallucination in geospatial code generation due to a lack of\ndomain-specific knowledge and code corpora. To address these challenges, this\npaper presents and open-sources the GeoCode-PT and GeoCode-SFT corpora, along\nwith the GeoCode-Eval evaluation dataset. Additionally, by leveraging QLoRA and\nLoRA for pretraining and fine-tuning, we introduce GeoCode-GPT-7B, the first\nLLM focused on geospatial code generation, fine-tuned from Code Llama-7B.\nFurthermore, we establish a comprehensive geospatial code evaluation framework,\nincorporating option matching, expert validation, and prompt engineering\nscoring for LLMs, and systematically evaluate GeoCode-GPT-7B using the\nGeoCode-Eval dataset. Experimental results show that GeoCode-GPT outperforms\nother models in multiple-choice accuracy by 9.1% to 32.1%, in code\nsummarization ability by 1.7% to 25.4%, and in code generation capability by\n1.2% to 25.1%. This paper provides a solution and empirical validation for\nenhancing LLMs' performance in geospatial code generation, extends the\nboundaries of domain-specific model applications, and offers valuable insights\ninto unlocking their potential in geospatial code generation.",
      "tldr_zh": "这篇论文针对大语言模型（LLMs）在地理空间代码生成任务中存在的拒绝生成和幻觉问题，提出了GeoCode-GPT-7B模型，这是首个专注于该领域的模型，通过QLoRA和LoRA技术对Code Llama-7B进行预训练和微调。论文同时开源了GeoCode-PT和GeoCode-SFT语料库，以及GeoCode-Eval评估数据集，并建立了一个全面的评估框架，包括选项匹配、专家验证和提示工程评分。实验结果显示，GeoCode-GPT在多选准确率上比其他模型提高了9.1%至32.1%，在代码总结能力上提高了1.7%至25.4%，在代码生成能力上提高了1.2%至25.1%。这项工作为提升LLMs在地理空间代码生成中的性能提供了实证解决方案，并扩展了领域特定模型的应用潜力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17031v2",
      "published_date": "2024-10-22 13:57:55 UTC",
      "updated_date": "2024-10-23 13:52:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:05:05.744590"
    },
    {
      "arxiv_id": "2410.17028v1",
      "title": "Can a Machine Distinguish High and Low Amount of Social Creak in Speech?",
      "title_zh": "翻译失败",
      "authors": [
        "Anne-Maria Laukkanen",
        "Sudarsana Reddy Kadiri",
        "Shrikanth Narayanan",
        "Paavo Alku"
      ],
      "abstract": "Objectives: ncreased prevalence of social creak particularly among female\nspeakers has been reported in several studies. The study of social creak has\nbeen previously conducted by combining perceptual evaluation of speech with\nconventional acoustical parameters such as the harmonic-to-noise ratio and\ncepstral peak prominence. In the current study, machine learning (ML) was used\nto automatically distinguish speech of low amount of social creak from speech\nof high amount of social creak.\n  Methods: The amount of creak in continuous speech samples produced in Finnish\nby 90 female speakers was first perceptually assessed by two voice specialists.\nBased on their assessments, the speech samples were divided into two categories\n(low $vs$. high amount of creak). Using the speech signals and their creak\nlabels, seven different ML models were trained. Three spectral representations\nwere used as feature for each model.\n  Results: The results show that the best performance (accuracy of 71.1\\%) was\nobtained by the following two systems: an Adaboost classifier using the\nmel-spectrogram feature and a decision tree classifier using the mel-frequency\ncepstral coefficient feature.\n  Conclusions: The study of social creak is becoming increasingly popular in\nsociolinguistic and vocological research. The conventional human perceptual\nassessment of the amount of creak is laborious and therefore ML technology\ncould be used to assist researchers studying social creak. The classification\nsystems reported in this study could be considered as baselines in future\nML-based studies on social creak.",
      "tldr_zh": "这项研究探讨了机器是否能区分语音中高低量的社会 creak（一种常见于女性说话者的语音现象），通过机器学习（ML）技术自动分类语音样本。研究者使用90名女性芬兰语说话者的连续语音样本，由两名语音专家进行感知评估，将样本分为低和高 creak 量两类，并训练了七种ML模型，使用mel-spectrogram和mel-frequency cepstral coefficient等三种光谱特征。结果显示，Adaboost分类器结合mel-spectrogram特征和决策树分类器结合mel-frequency cepstral coefficient特征取得了最佳性能，准确率达71.1%。这项工作为未来基于ML的社会 creak 研究提供了基线模型，有助于取代繁琐的人工评估方法。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted in Journal of Voice",
      "pdf_url": "http://arxiv.org/pdf/2410.17028v1",
      "published_date": "2024-10-22 13:52:51 UTC",
      "updated_date": "2024-10-22 13:52:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:05:14.413922"
    },
    {
      "arxiv_id": "2410.17005v1",
      "title": "Hybrid Generative AI for De Novo Design of Co-Crystals with Enhanced Tabletability",
      "title_zh": "翻译失败",
      "authors": [
        "Nina Gubina",
        "Andrei Dmitrenko",
        "Gleb Solovev",
        "Lyubov Yamshchikova",
        "Oleg Petrov",
        "Ivan Lebedev",
        "Nikita Serov",
        "Grigorii Kirgizov",
        "Nikolay Nikitin",
        "Vladimir Vinogradov"
      ],
      "abstract": "Co-crystallization is an accessible way to control physicochemical\ncharacteristics of organic crystals, which finds many biomedical applications.\nIn this work, we present Generative Method for Co-crystal Design (GEMCODE), a\nnovel pipeline for automated co-crystal screening based on the hybridization of\ndeep generative models and evolutionary optimization for broader exploration of\nthe target chemical space. GEMCODE enables fast de novo co-crystal design with\ntarget tabletability profiles, which is crucial for the development of\npharmaceuticals. With a series of experimental studies highlighting validation\nand discovery cases, we show that GEMCODE is effective even under realistic\ncomputational constraints. Furthermore, we explore the potential of language\nmodels in generating co-crystals. Finally, we present numerous previously\nunknown co-crystals predicted by GEMCODE and discuss its potential in\naccelerating drug development.",
      "tldr_zh": "这篇论文提出了GEMCODE，一种基于混合深度生成模型和进化优化的管道，用于自动共晶筛选，以实现de novo共晶设计并提升tabletability特性，从而支持制药开发。GEMCODE通过更广泛的化学空间探索，实现了快速设计和实验验证，即使在现实计算约束下也表现出色。论文还探讨了语言模型在共晶生成中的潜力，并预测了众多之前未知的共晶，展示了其在加速药物开发方面的应用前景。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at 38th Conference on Neural Information Processing Systems\n  (NeurIPS)",
      "pdf_url": "http://arxiv.org/pdf/2410.17005v1",
      "published_date": "2024-10-22 13:25:28 UTC",
      "updated_date": "2024-10-22 13:25:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:05:27.256004"
    },
    {
      "arxiv_id": "2410.16991v1",
      "title": "An Eye for an AI: Evaluating GPT-4o's Visual Perception Skills and Geometric Reasoning Skills Using Computer Graphics Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Tony Haoran Feng",
        "Paul Denny",
        "Burkhard C. Wünsche",
        "Andrew Luxton-Reilly",
        "Jacqueline Whalley"
      ],
      "abstract": "CG (Computer Graphics) is a popular field of CS (Computer Science), but many\nstudents find this topic difficult due to it requiring a large number of\nskills, such as mathematics, programming, geometric reasoning, and creativity.\nOver the past few years, researchers have investigated ways to harness the\npower of GenAI (Generative Artificial Intelligence) to improve teaching. In CS,\nmuch of the research has focused on introductory computing. A recent study\nevaluating the performance of an LLM (Large Language Model), GPT-4 (text-only),\non CG questions, indicated poor performance and reliance on detailed\ndescriptions of image content, which often required considerable insight from\nthe user to return reasonable results. So far, no studies have investigated the\nabilities of LMMs (Large Multimodal Models), or multimodal LLMs, to solve CG\nquestions and how these abilities can be used to improve teaching.\n  In this study, we construct two datasets of CG questions requiring varying\ndegrees of visual perception skills and geometric reasoning skills, and\nevaluate the current state-of-the-art LMM, GPT-4o, on the two datasets. We find\nthat although GPT-4o exhibits great potential in solving questions with visual\ninformation independently, major limitations still exist to the accuracy and\nquality of the generated results. We propose several novel approaches for CG\neducators to incorporate GenAI into CG teaching despite these limitations. We\nhope that our guidelines further encourage learning and engagement in CG\nclassrooms.",
      "tldr_zh": "本研究评估了 GPT-4o 在计算机图形学 (CG) 领域的视觉感知和几何推理能力，通过构建两个数据集来测试其处理 CG 问题的表现。结果表明，GPT-4o 在独立分析视觉信息方面显示出潜力，但准确性和生成质量仍存在重大限制。研究提出几种新方法，供 CG 教育者整合生成式人工智能 (GenAI) 于教学中，以克服这些局限性并提升课堂学习和参与度。",
      "categories": [
        "cs.AI",
        "cs.GR",
        "I.2.7; I.3.0; K.3.2"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 8 figures, 1 table, to be published in SIGGRAPH Asia 2024\n  Educator's Forum",
      "pdf_url": "http://arxiv.org/pdf/2410.16991v1",
      "published_date": "2024-10-22 13:12:47 UTC",
      "updated_date": "2024-10-22 13:12:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:05:39.078832"
    },
    {
      "arxiv_id": "2410.16983v1",
      "title": "Order Matters: Exploring Order Sensitivity in Multimodal Large Language Models",
      "title_zh": "顺序很重要：探索多模态大型语言模型中的顺序敏感性",
      "authors": [
        "Zhijie Tan",
        "Xu Chu",
        "Weiping Li",
        "Tong Mo"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) utilize multimodal contexts\nconsisting of text, images, or videos to solve various multimodal tasks.\nHowever, we find that changing the order of multimodal input can cause the\nmodel's performance to fluctuate between advanced performance and random\nguessing. This phenomenon exists in both single-modality (text-only or\nimage-only) and mixed-modality (image-text-pair) contexts. Furthermore, we\ndemonstrate that popular MLLMs pay special attention to certain multimodal\ncontext positions, particularly the beginning and end. Leveraging this special\nattention, we place key video frames and important image/text content in\nspecial positions within the context and submit them to the MLLM for inference.\nThis method results in average performance gains of 14.7% for video-caption\nmatching and 17.8% for visual question answering tasks. Additionally, we\npropose a new metric, Position-Invariant Accuracy (PIA), to address order bias\nin MLLM evaluation. Our research findings contribute to a better understanding\nof Multi-Modal In-Context Learning (MMICL) and provide practical strategies for\nenhancing MLLM performance without increasing computational costs.",
      "tldr_zh": "该研究揭示了多模态大语言模型(MLLMs)对输入顺序的高度敏感性，导致性能从优秀水平波动至随机猜测，尤其在单模态(文本或图像)和混合模态(图像-文本对)上下文中。作者发现MLLMs特别关注上下文的开头和结尾，并通过将关键视频帧或重要内容放置在这些位置，实现了视频字幕匹配任务平均提升14.7%和视觉问答任务平均提升17.8%的性能。论文还提出了新的评估指标Position-Invariant Accuracy (PIA)来量化顺序偏差，并为Multi-Modal In-Context Learning (MMICL)提供了不增加计算成本的实用策略，以提升模型的鲁棒性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16983v1",
      "published_date": "2024-10-22 13:05:11 UTC",
      "updated_date": "2024-10-22 13:05:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:05:52.360223"
    },
    {
      "arxiv_id": "2410.18142v2",
      "title": "Analyzing Nobel Prize Literature with Large Language Models",
      "title_zh": "利用大型语言模型分析诺贝尔奖文学",
      "authors": [
        "Zhenyuan Yang",
        "Zhengliang Liu",
        "Jing Zhang",
        "Cen Lu",
        "Jiaxin Tai",
        "Tianyang Zhong",
        "Yiwei Li",
        "Siyan Zhao",
        "Teng Yao",
        "Qing Liu",
        "Jinlin Yang",
        "Qixin Liu",
        "Zhaowei Li",
        "Kexin Wang",
        "Longjun Ma",
        "Dajiang Zhu",
        "Yudan Ren",
        "Bao Ge",
        "Wei Zhang",
        "Ning Qiang",
        "Tuo Zhang",
        "Tianming Liu"
      ],
      "abstract": "This study examines the capabilities of advanced Large Language Models\n(LLMs), particularly the o1 model, in the context of literary analysis. The\noutputs of these models are compared directly to those produced by\ngraduate-level human participants. By focusing on two Nobel Prize-winning short\nstories, 'Nine Chapters' by Han Kang, the 2024 laureate, and 'Friendship' by\nJon Fosse, the 2023 laureate, the research explores the extent to which AI can\nengage with complex literary elements such as thematic analysis,\nintertextuality, cultural and historical contexts, linguistic and structural\ninnovations, and character development. Given the Nobel Prize's prestige and\nits emphasis on cultural, historical, and linguistic richness, applying LLMs to\nthese works provides a deeper understanding of both human and AI approaches to\ninterpretation. The study uses qualitative and quantitative evaluations of\ncoherence, creativity, and fidelity to the text, revealing the strengths and\nlimitations of AI in tasks typically reserved for human expertise. While LLMs\ndemonstrate strong analytical capabilities, particularly in structured tasks,\nthey often fall short in emotional nuance and coherence, areas where human\ninterpretation excels. This research underscores the potential for human-AI\ncollaboration in the humanities, opening new opportunities in literary studies\nand beyond.",
      "tldr_zh": "本研究评估了大型语言模型(LLMs)，尤其是 o1 模型，在文学分析中的能力，通过直接比较其输出与研究生级人类参与者的表现。研究聚焦于两部诺贝尔奖获奖短篇小说——Han Kang 的 'Nine Chapters' 和 Jon Fosse 的 'Friendship'，探讨 AI 在处理主题分析、互文性、文化历史背景、语言创新和人物发展等复杂元素的表现。定性和定量评估显示，LLMs 在结构化任务中表现出色，但情感细微和连贯性方面存在局限性，突显了人类-AI 协作在人文领域的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18142v2",
      "published_date": "2024-10-22 13:03:28 UTC",
      "updated_date": "2024-12-03 04:19:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:06:02.899077"
    },
    {
      "arxiv_id": "2410.16973v3",
      "title": "Learning Mathematical Rules with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Antoine Gorceix",
        "Bastien Le Chenadec",
        "Ahmad Rammal",
        "Nelson Vadori",
        "Manuela Veloso"
      ],
      "abstract": "In this paper, we study the ability of large language models to learn\nspecific mathematical rules such as distributivity or simplifying equations. We\npresent an empirical analysis of their ability to generalize these rules, as\nwell as to reuse them in the context of word problems. For this purpose, we\nprovide a rigorous methodology to build synthetic data incorporating such\nrules, and perform fine-tuning of large language models on such data. Our\nexperiments show that our model can learn and generalize these rules to some\nextent, as well as suitably reuse them in the context of word problems.",
      "tldr_zh": "这篇论文探讨了Large Language Models学习特定数学规则（如distributivity或simplifying equations）的能力，通过实证分析评估模型的规则泛化及在文字问题中的重用。作者开发了一种构建合成数据的严格方法，并在此基础上对Large Language Models进行微调。实验结果显示，模型能够在一定程度上学习和泛化这些规则，并在文字问题中有效应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS'24 MATH-AI, the 4th Workshop on Mathematical Reasoning and AI",
      "pdf_url": "http://arxiv.org/pdf/2410.16973v3",
      "published_date": "2024-10-22 12:51:51 UTC",
      "updated_date": "2024-10-25 13:28:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:06:13.483834"
    },
    {
      "arxiv_id": "2410.16950v1",
      "title": "Breaking ReAct Agents: Foot-in-the-Door Attack Will Get You In",
      "title_zh": "翻译失败",
      "authors": [
        "Itay Nakash",
        "George Kour",
        "Guy Uziel",
        "Ateret Anaby-Tavor"
      ],
      "abstract": "Following the advancement of large language models (LLMs), the development of\nLLM-based autonomous agents has become increasingly prevalent. As a result, the\nneed to understand the security vulnerabilities of these agents has become a\ncritical task. We examine how ReAct agents can be exploited using a\nstraightforward yet effective method we refer to as the foot-in-the-door\nattack. Our experiments show that indirect prompt injection attacks, prompted\nby harmless and unrelated requests (such as basic calculations) can\nsignificantly increase the likelihood of the agent performing subsequent\nmalicious actions. Our results show that once a ReAct agents thought includes a\nspecific tool or action, the likelihood of executing this tool in the\nsubsequent steps increases significantly, as the agent seldom re-evaluates its\nactions. Consequently, even random, harmless requests can establish a\nfoot-in-the-door, allowing an attacker to embed malicious instructions into the\nagents thought process, making it more susceptible to harmful directives. To\nmitigate this vulnerability, we propose implementing a simple reflection\nmechanism that prompts the agent to reassess the safety of its actions during\nexecution, which can help reduce the success of such attacks.",
      "tldr_zh": "这篇论文探讨了基于大型语言模型(LLMs)的ReAct代理的安全漏洞，特别关注foot-in-the-door攻击这种简单有效的方法。攻击者通过无害的无关请求（如基本计算）进行间接prompt injection，从而显著增加代理执行后续恶意动作的可能性。实验发现，一旦ReAct代理的思考过程包含特定工具或动作，它很少重新评估，导致攻击成功率上升。作者提出了一种简单反射机制，让代理在执行过程中重新评估动作的安全性，以缓解此类漏洞。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16950v1",
      "published_date": "2024-10-22 12:24:41 UTC",
      "updated_date": "2024-10-22 12:24:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:06:26.980473"
    },
    {
      "arxiv_id": "2410.16946v1",
      "title": "Self-Evolving Multi-Agent Collaboration Networks for Software Development",
      "title_zh": "软件开发的自我演化多智能体协作网络",
      "authors": [
        "Yue Hu",
        "Yuzhu Cai",
        "Yaxin Du",
        "Xinyu Zhu",
        "Xiangrui Liu",
        "Zijie Yu",
        "Yuchen Hou",
        "Shuo Tang",
        "Siheng Chen"
      ],
      "abstract": "LLM-driven multi-agent collaboration (MAC) systems have demonstrated\nimpressive capabilities in automatic software development at the function\nlevel. However, their heavy reliance on human design limits their adaptability\nto the diverse demands of real-world software development. To address this\nlimitation, we introduce EvoMAC, a novel self-evolving paradigm for MAC\nnetworks. Inspired by traditional neural network training, EvoMAC obtains\ntext-based environmental feedback by verifying the MAC network's output against\na target proxy and leverages a novel textual backpropagation to update the\nnetwork. To extend coding capabilities beyond function-level tasks to more\nchallenging software-level development, we further propose rSDE-Bench, a\nrequirement-oriented software development benchmark, which features complex and\ndiverse software requirements along with automatic evaluation of requirement\ncorrectness. Our experiments show that: i) The automatic requirement-aware\nevaluation in rSDE-Bench closely aligns with human evaluations, validating its\nreliability as a software-level coding benchmark. ii) EvoMAC outperforms\nprevious SOTA methods on both the software-level rSDE-Bench and the\nfunction-level HumanEval benchmarks, reflecting its superior coding\ncapabilities. The benchmark can be downloaded at\nhttps://yuzhu-cai.github.io/rSDE-Bench/.",
      "tldr_zh": "该论文提出EvoMAC，一种自演化的多智能体协作（MAC）网络范式，旨在提升自动软件开发能力，通过验证输出与目标代理的匹配并利用文本反向传播（textual backpropagation）来更新网络，减少对人工设计的依赖。EvoMAC进一步扩展到软件级任务，引入rSDE-Bench基准，该基准聚焦复杂多样的软件需求并提供自动评估，以评估需求正确性。实验结果显示，rSDE-Bench的评估与人工评估高度一致，且EvoMAC在rSDE-Bench和HumanEval基准上超越现有最先进方法，展示了其在软件开发中的优越性能。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.SE",
      "comment": "25 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.16946v1",
      "published_date": "2024-10-22 12:20:23 UTC",
      "updated_date": "2024-10-22 12:20:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:06:38.511267"
    },
    {
      "arxiv_id": "2410.16945v1",
      "title": "IdenBAT: Disentangled Representation Learning for Identity-Preserved Brain Age Transformation",
      "title_zh": "翻译失败",
      "authors": [
        "Junyeong Maeng",
        "Kwanseok Oh",
        "Wonsik Jung",
        "Heung-Il Suk"
      ],
      "abstract": "Brain age transformation aims to convert reference brain images into\nsynthesized images that accurately reflect the age-specific features of a\ntarget age group. The primary objective of this task is to modify only the\nage-related attributes of the reference image while preserving all other\nage-irrelevant attributes. However, achieving this goal poses substantial\nchallenges due to the inherent entanglement of various image attributes within\nfeatures extracted from a backbone encoder, resulting in simultaneous\nalterations during the image generation. To address this challenge, we propose\na novel architecture that employs disentangled representation learning for\nidentity-preserved brain age transformation called IdenBAT. This approach\nfacilitates the decomposition of image features, ensuring the preservation of\nindividual traits while selectively transforming age-related characteristics to\nmatch those of the target age group. Through comprehensive experiments\nconducted on both 2D and full-size 3D brain datasets, our method adeptly\nconverts input images to target age while retaining individual characteristics\naccurately. Furthermore, our approach demonstrates superiority over existing\nstate-of-the-art regarding performance fidelity.",
      "tldr_zh": "这篇论文针对脑部年龄转换任务，提出了一种名为 IdenBAT 的新架构，利用 disentangled representation learning 来分解图像特征，确保在修改年龄相关属性时保留个体特征和其他无关属性。\nIdenBAT 通过这种解耦表示学习方法，实现了参考脑部图像向目标年龄组的精确转换，同时避免了特征纠缠带来的问题。\n实验结果显示，该方法在 2D 和 3D 脑部数据集上表现出色，能够准确保持个体特性，并在性能和保真度方面优于现有最先进技术。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "q-bio.NC"
      ],
      "primary_category": "eess.IV",
      "comment": "16 pages, 8 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.16945v1",
      "published_date": "2024-10-22 12:20:15 UTC",
      "updated_date": "2024-10-22 12:20:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:06:50.669759"
    },
    {
      "arxiv_id": "2410.16930v2",
      "title": "Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities Using Only Forward Passes",
      "title_zh": "Math Neurosurgery：仅使用前向传播隔离语言模型的数学推理能力",
      "authors": [
        "Bryan R. Christ",
        "Zack Gottesman",
        "Jonathan Kropko",
        "Thomas Hartvigsen"
      ],
      "abstract": "Math reasoning is an active area of Large Language Model (LLM) research\nbecause it is a hallmark of artificial intelligence and has implications in\nseveral domains, including math education. However, few works have explored how\nmath reasoning is encoded within LLM parameters and if it is a skill that can\nbe isolated within models. Doing so could allow targeted intervention to\nimprove math performance without altering non-math behavior and foster\nunderstanding of how models encode math reasoning. We introduce Math\nNeurosurgery (MathNeuro), a computationally efficient method we use to isolate\nmath-specific parameters in LLMs using only forward passes. MathNeuro builds on\nexisting work by using weights and activations to calculate parameter\nimportance, but isolates math-specific parameters by filtering out those\nimportant for general language tasks. Through pruning parameters MathNeuro\nidentifies, we delete a LLM's math reasoning ability without significantly\nimpacting its general language ability. Scaling the identified parameters by a\nsmall constant improves a pretrained or instruction-tuned LLM's performance by\n4-17% on GSM8K and 5-35% on MATH while leaving non-math behavior unaltered.\nMathNeuro is also data efficient: most of its effectiveness holds when\nidentifying math-specific parameters using a single sample. MathNeuro\nhighlights the potential for future work to intervene on math-specific\nparameters.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 中数学推理能力的编码机制，并引入 Math Neurosurgery (MathNeuro) 方法，该方法仅使用前向 passes 来隔离数学特定参数。MathNeuro 通过计算权重和激活重要性，并过滤掉对一般语言任务关键的参数，从而高效识别出数学相关参数。实验结果显示，修剪这些参数可删除模型的数学推理能力，而不显著影响其语言性能；反之，缩放这些参数可使预训练或指令微调的LLMs 在 GSM8K 数据集上提升4-17%、在 MATH 数据集上提升5-35%。该方法数据高效，仅需一个样本即可生效，并为未来针对数学参数的干预提供新方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "38 pages, 54 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.16930v2",
      "published_date": "2024-10-22 12:00:58 UTC",
      "updated_date": "2025-02-18 19:45:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:07:03.380859"
    },
    {
      "arxiv_id": "2411.02423v1",
      "title": "Development of CODO: A Comprehensive Tool for COVID-19 Data Representation, Analysis, and Visualization",
      "title_zh": "翻译失败",
      "authors": [
        "Biswanath Dutta",
        "Debanjali Bain"
      ],
      "abstract": "Artificial intelligence (AI) has become indispensable for managing and\nprocessing the vast amounts of data generated during the COVID-19 pandemic.\nOntology, which formalizes knowledge within a domain using standardized\nvocabularies and relationships, plays a crucial role in AI by enabling\nautomated reasoning, data integration, semantic interoperability, and\nextracting meaningful insights from extensive datasets. The diversity of\nCOVID-19 datasets poses challenges in comprehending this information for both\nhuman and machines. Existing COVID-19 ontologies are designed to address\nspecific aspects of the pandemic but lack comprehensive coverage across all\nessential dimensions. To address this gap, CODO, an integrated ontological\nmodel has been developed encompassing critical facets of COVID-19 information\nsuch as aetiology, epidemiology, transmission, pathogenesis, diagnosis,\nprevention, genomics, therapeutic safety, and more. This paper reviews CODO\nsince its inception in 2020, detailing its developments and highlighting CODO\nas a tool for the aggregation, representation, analysis, and visualization of\ndiverse COVID-19 data. The major contribution of this paper is to provide a\nsummary of the development of CODO, and outline the overall development and\nevaluation approach. By adhering to best practices and leveraging W3C\nstandards, CODO ensures data integration and semantic interoperability,\nsupporting effective navigation of COVID-19 complexities across various\ndomains.",
      "tldr_zh": "这篇论文介绍了 CODO，这是一个综合的本体（Ontology）工具，用于 COVID-19 数据表示、分析和可视化，以解决多样数据集的整合挑战。CODO 涵盖了疫情的关键方面，包括病因（aetiology）、流行病学（epidemiology）、传播、诊断、预防和基因组学等，通过 AI 技术实现自动化推理和语义互操作性。论文回顾了 CODO 自 2020 年以来的开发过程，强调其遵守 W3C 标准以支持数据聚合和有效分析，为多领域 COVID-19 研究提供可靠的框架。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "15 pages, 4 figures, journal",
      "pdf_url": "http://arxiv.org/pdf/2411.02423v1",
      "published_date": "2024-10-22 11:59:54 UTC",
      "updated_date": "2024-10-22 11:59:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:07:15.329245"
    },
    {
      "arxiv_id": "2410.16927v1",
      "title": "Revealing Hidden Bias in AI: Lessons from Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Django Beatty",
        "Kritsada Masanthia",
        "Teepakorn Kaphol",
        "Niphan Sethi"
      ],
      "abstract": "As large language models (LLMs) become integral to recruitment processes,\nconcerns about AI-induced bias have intensified. This study examines biases in\ncandidate interview reports generated by Claude 3.5 Sonnet, GPT-4o, Gemini 1.5,\nand Llama 3.1 405B, focusing on characteristics such as gender, race, and age.\nWe evaluate the effectiveness of LLM-based anonymization in reducing these\nbiases. Findings indicate that while anonymization reduces certain biases,\nparticularly gender bias, the degree of effectiveness varies across models and\nbias types. Notably, Llama 3.1 405B exhibited the lowest overall bias.\nMoreover, our methodology of comparing anonymized and non-anonymized data\nreveals a novel approach to assessing inherent biases in LLMs beyond\nrecruitment applications. This study underscores the importance of careful LLM\nselection and suggests best practices for minimizing bias in AI applications,\npromoting fairness and inclusivity.",
      "tldr_zh": "这篇论文研究了Large Language Models (LLMs) 在招聘过程中的隐藏偏见，包括Claude 3.5 Sonnet、GPT-4o、Gemini 1.5 和 Llama 3.1 405B 等模型对性别、种族和年龄的偏见影响。研究通过评估LLM-based anonymization 方法，比较匿名化和非匿名化数据，发现这种方法能有效减少某些偏见，尤其是性别偏见，但效果因模型和偏见类型而异，其中Llama 3.1 405B 表现出最低的整体偏见。论文提出了一种新型评估LLMs 内在偏见的框架，并强调了谨慎选择LLMs 和实施最佳实践的重要性，以提升AI 应用的公平性和包容性。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "I.2.7; K.4.1"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 18 figures. This paper presents a technical analysis of\n  bias in large language models, focusing on bias detection and mitigation",
      "pdf_url": "http://arxiv.org/pdf/2410.16927v1",
      "published_date": "2024-10-22 11:58:54 UTC",
      "updated_date": "2024-10-22 11:58:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:07:27.459987"
    },
    {
      "arxiv_id": "2410.16924v1",
      "title": "SleepCoT: A Lightweight Personalized Sleep Health Model via Chain-of-Thought Distillation",
      "title_zh": "SleepCoT：通过链式思维蒸馏的轻量级个性化睡眠健康模型",
      "authors": [
        "Huimin Zheng",
        "Xiaofeng Xing",
        "Xiangmin Xu"
      ],
      "abstract": "We present a novel approach to personalized sleep health management using\nfew-shot Chain-of-Thought (CoT) distillation, enabling small-scale language\nmodels (> 2B parameters) to rival the performance of large language models\n(LLMs) in specialized health domains. Our method simultaneously distills\nproblem-solving strategies, long-tail expert knowledge, and personalized\nrecommendation capabilities from larger models into more efficient, compact\nmodels. Unlike existing systems, our approach offers three key functionalities:\ngenerating personalized sleep health recommendations, supporting user-specific\nfollow-up inquiries, and providing responses to domain-specific knowledge\nquestions. We focus on sleep health due to its measurability via wearable\ndevices and its impact on overall well-being. Our experimental setup, involving\nGPT-4o for data synthesis, Qwen-max for instruction set creation, and Qwen2.5\n1.5B for model distillation, demonstrates significant improvements over\nbaseline small-scale models in penalization, reasoning, and knowledge\napplication. Experiments using 100 simulated sleep reports and 1,000\ndomain-specific questions shows our model achieves comparable performance to\nlarger models while maintaining efficiency for real-world deployment. This\nresearch not only advances AI-driven health management but also provides a\nnovel approach to leveraging LLM capabilities in resource-constrained\nenvironments, potentially enhancing the accessibility of personalized\nhealthcare solutions.",
      "tldr_zh": "本研究提出了一种轻量级个性化睡眠健康模型SleepCoT，通过Chain-of-Thought (CoT) 蒸馏方法，将大型语言模型(LLMs)的能力（如问题解决策略、长尾专家知识和个性化推荐）转移到小型语言模型（< 2B 参数）中，实现与LLMs相当的性能。模型提供三大关键功能：生成个性化睡眠健康推荐、支持用户特定后续查询，以及回答领域特定知识问题，特别聚焦于可通过可穿戴设备测量的睡眠健康及其对整体福祉的影响。实验使用GPT-4o合成数据、Qwen-max创建指令集，并以Qwen2.5 1.5B进行蒸馏，结果显示在100个模拟睡眠报告和1,000个领域问题上，该模型在惩罚、推理和知识应用方面显著优于基线小型模型，同时保持高效性。该方法不仅推进了AI驱动的健康管理，还为资源受限环境下的个性化医疗解决方案提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16924v1",
      "published_date": "2024-10-22 11:56:34 UTC",
      "updated_date": "2024-10-22 11:56:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:07:40.719165"
    },
    {
      "arxiv_id": "2410.16919v1",
      "title": "EnvBridge: Bridging Diverse Environments with Cross-Environment Knowledge Transfer for Embodied AI",
      "title_zh": "翻译失败",
      "authors": [
        "Tomoyuki Kagaya",
        "Yuxuan Lou",
        "Thong Jing Yuan",
        "Subramanian Lakshmi",
        "Jayashree Karlekar",
        "Sugiri Pranata",
        "Natsuki Murakami",
        "Akira Kinose",
        "Koki Oguri",
        "Felix Wick",
        "Yang You"
      ],
      "abstract": "In recent years, Large Language Models (LLMs) have demonstrated high\nreasoning capabilities, drawing attention for their applications as agents in\nvarious decision-making processes. One notably promising application of LLM\nagents is robotic manipulation. Recent research has shown that LLMs can\ngenerate text planning or control code for robots, providing substantial\nflexibility and interaction capabilities. However, these methods still face\nchallenges in terms of flexibility and applicability across different\nenvironments, limiting their ability to adapt autonomously. Current approaches\ntypically fall into two categories: those relying on environment-specific\npolicy training, which restricts their transferability, and those generating\ncode actions based on fixed prompts, which leads to diminished performance when\nconfronted with new environments. These limitations significantly constrain the\ngeneralizability of agents in robotic manipulation. To address these\nlimitations, we propose a novel method called EnvBridge. This approach involves\nthe retention and transfer of successful robot control codes from source\nenvironments to target environments. EnvBridge enhances the agent's\nadaptability and performance across diverse settings by leveraging insights\nfrom multiple environments. Notably, our approach alleviates environmental\nconstraints, offering a more flexible and generalizable solution for robotic\nmanipulation tasks. We validated the effectiveness of our method using robotic\nmanipulation benchmarks: RLBench, MetaWorld, and CALVIN. Our experiments\ndemonstrate that LLM agents can successfully leverage diverse knowledge sources\nto solve complex tasks. Consequently, our approach significantly enhances the\nadaptability and robustness of robotic manipulation agents in planning across\ndiverse environments.",
      "tldr_zh": "本文提出 EnvBridge，一种通过跨环境知识转移的方法，旨在解决 Large Language Models (LLMs) 在 Embodied AI 中的适应性问题，特别是现有方法在不同环境间的转移性和性能下降。EnvBridge 通过保留源环境中的成功机器人控制代码并转移到目标环境，增强了代理的灵活性和泛化能力。实验在 RLBench、MetaWorld 和 CALVIN 等基准上验证了其有效性，显著提高了 LLM 代理在复杂任务中的适应性和鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16919v1",
      "published_date": "2024-10-22 11:52:22 UTC",
      "updated_date": "2024-10-22 11:52:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:07:50.294041"
    },
    {
      "arxiv_id": "2410.16908v1",
      "title": "Mitigating Vanishing Activations in Deep CapsNets Using Channel Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Siddharth Sahu",
        "Abdulrahman Altahhan"
      ],
      "abstract": "Capsule Networks outperform Convolutional Neural Networks in learning the\npart-whole relationships with viewpoint invariance, and the credit goes to\ntheir multidimensional capsules. It was assumed that increasing the number of\ncapsule layers in the capsule networks would enhance the model performance.\nHowever, recent studies found that Capsule Networks lack scalability due to\nvanishing activations in the capsules of deeper layers. This paper thoroughly\ninvestigates the vanishing activation problem in deep Capsule Networks. To\nanalyze this issue and understand how increasing capsule dimensions can\nfacilitate deeper networks, various Capsule Network models are constructed and\nevaluated with different numbers of capsules, capsule dimensions, and\nintermediate layers for this paper. Unlike traditional model pruning, which\nreduces the number of model parameters and expedites model training, this study\nuses pruning to mitigate the vanishing activations in the deeper capsule\nlayers. In addition, the backbone network and capsule layers are pruned with\ndifferent pruning ratios to reduce the number of inactive capsules and achieve\nbetter model accuracy than the unpruned models.",
      "tldr_zh": "Capsule Networks (CapsNets) 在学习部分-整体关系和视点不变性方面优于 Convolutional Neural Networks (CNNs)，但深层 CapsNets 面临 vanishing activations 问题，导致模型可扩展性差。该论文通过构建并评估各种 CapsNet 模型，探究 capsules 数量、维度和中间层的影响，并采用 channel pruning 技术来缓解深层 capsules 中的 vanishing activations。与传统模型修剪不同，这种方法针对 backbone network 和 capsule layers 应用不同修剪比例，减少 inactive capsules 并实现比未修剪模型更高的准确性。最终，研究为提升深层 CapsNets 的性能提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16908v1",
      "published_date": "2024-10-22 11:28:39 UTC",
      "updated_date": "2024-10-22 11:28:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:08:02.949643"
    },
    {
      "arxiv_id": "2410.18141v2",
      "title": "SmartRAG: Jointly Learn RAG-Related Tasks From the Environment Feedback",
      "title_zh": "SmartRAG：从环境反馈中联合学习 RAG 相关任务",
      "authors": [
        "Jingsheng Gao",
        "Linxu Li",
        "Weiyuan Li",
        "Yuzhuo Fu",
        "Bin Dai"
      ],
      "abstract": "RAG systems consist of multiple modules to work together. However, these\nmodules are usually separately trained. We argue that a system like RAG that\nincorporates multiple modules should be jointly optimized to achieve optimal\nperformance. To demonstrate this, we design a specific pipeline called\n\\textbf{SmartRAG} that includes a policy network and a retriever. The policy\nnetwork can serve as 1) a decision maker that decides when to retrieve, 2) a\nquery rewriter to generate a query most suited to the retriever, and 3) an\nanswer generator that produces the final response with/without the\nobservations. We then propose to jointly optimize the whole system using a\nreinforcement learning algorithm, with the reward designed to encourage the\nsystem to achieve the best performance with minimal retrieval cost. When\njointly optimized, all the modules can be aware of how other modules are\nworking and thus find the best way to work together as a complete system.\nEmpirical results demonstrate that the jointly optimized SmartRAG can achieve\nbetter performance than separately optimized counterparts.",
      "tldr_zh": "该研究提出 SmartRAG 框架，通过联合优化 RAG 系统中的多个模块（如策略网络和检索器），以实现整体最佳性能。策略网络负责决定何时检索、查询重写以及生成最终响应，而整个系统使用强化学习算法优化，奖励机制鼓励高性能和最小检索成本。实验结果表明，SmartRAG 在联合优化下比单独优化的模块组合表现出色，证明了模块间协作的重要性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18141v2",
      "published_date": "2024-10-22 11:23:11 UTC",
      "updated_date": "2025-03-10 09:49:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:08:14.520144"
    },
    {
      "arxiv_id": "2410.16882v2",
      "title": "Large Language Model-based Augmentation for Imbalanced Node Classification on Text-Attributed Graphs",
      "title_zh": "基于大型语言模型的增强，用于文本属性图上的不平衡节点分类",
      "authors": [
        "Leyao Wang",
        "Yu Wang",
        "Bo Ni",
        "Yuying Zhao",
        "Tyler Derr"
      ],
      "abstract": "Node classification on graphs often suffers from class imbalance, leading to\nbiased predictions and significant risks in real-world applications. While\ndata-centric solutions have been explored, they largely overlook\nText-Attributed Graphs (TAGs) and the potential of using rich textual semantics\nto improve the classification of minority nodes. Given this gap, we propose\nLarge Language Model-based Augmentation on Text-Attributed Graphs (LA-TAG), a\nnovel framework that leverages Large Language Models (LLMs) to handle\nimbalanced node classification. Specifically, we develop prompting strategies\ninspired by interpolation to synthesize textual node attributes. Additionally,\nto effectively integrate synthetic nodes into the graph structure, we introduce\na textual link predictor that connects the generated nodes to the original\ngraph, preserving structural and contextual information. Experiments across\nvarious datasets and evaluation metrics demonstrate that LA-TAG outperforms\nexisting textual augmentation and graph imbalance learning methods, emphasizing\nthe efficacy of our approach in addressing class imbalance in TAGs.",
      "tldr_zh": "本文针对 Text-Attributed Graphs (TAGs) 中的类别不平衡问题，提出了一种基于 Large Language Models (LLMs) 的增强框架 LA-TAG，以改善少数类节点的分类性能。LA-TAG 通过受插值启发的提示策略合成文本节点属性，并引入文本链接预测器，将合成节点整合到原图结构中，从而保留图的结构和上下文信息。实验在多种数据集和评估指标上表明，LA-TAG 优于现有文本增强和图不平衡学习方法，展示了其在处理 TAGs 不平衡分类的有效性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.16882v2",
      "published_date": "2024-10-22 10:36:15 UTC",
      "updated_date": "2025-01-27 17:06:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:08:28.473890"
    },
    {
      "arxiv_id": "2410.16879v1",
      "title": "Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study",
      "title_zh": "当前与未来 AI 在 ECG 计算机化解释应用中的对比态度：一项临床利益相关者访谈研究",
      "authors": [
        "Lukas Hughes-Noehrer",
        "Leda Channer",
        "Gabriel Strain",
        "Gregory Yates",
        "Richard Body",
        "Caroline Jay"
      ],
      "abstract": "Objectives: To investigate clinicians' attitudes towards current automated\ninterpretation of ECG and novel AI technologies and their perception of\ncomputer-assisted interpretation. Materials and Methods: We conducted a series\nof interviews with clinicians in the UK. Our study: (i) explores the potential\nfor AI, specifically future 'human-like' computing approaches, to facilitate\nECG interpretation and support clinical decision making, and (ii) elicits their\nopinions about the importance of explainability and trustworthiness of AI\nalgorithms. Results: We performed inductive thematic analysis on interview\ntranscriptions from 23 clinicians and identified the following themes: (i) a\nlack of trust in current systems, (ii) positive attitudes towards future AI\napplications and requirements for these, (iii) the relationship between the\naccuracy and explainability of algorithms, and (iv) opinions on education,\npossible deskilling, and the impact of AI on clinical competencies. Discussion:\nClinicians do not trust current computerised methods, but welcome future 'AI'\ntechnologies. Where clinicians trust future AI interpretation to be accurate,\nthey are less concerned that it is explainable. They also preferred ECG\ninterpretation that demonstrated the results of the algorithm visually. Whilst\nclinicians do not fear job losses, they are concerned about deskilling and the\nneed to educate the workforce to use AI responsibly. Conclusion: Clinicians are\npositive about the future application of AI in clinical decision-making.\nAccuracy is a key factor of uptake and visualisations are preferred over\ncurrent computerised methods. This is viewed as a potential means of training\nand upskilling, in contrast to the deskilling that automation might be\nperceived to bring.",
      "tldr_zh": "本研究通过对英国23名临床医生的访谈，探讨了他们对当前ECG自动解释系统和未来AI技术的态度，以及对计算机辅助解释的看法。结果显示，临床医生对现有系统缺乏信任，但对未来“类人”AI应用持积极态度，强调算法准确性优先于explainability，并更偏好视觉化结果展示。同时，他们担忧AI可能导致deskilling，但视其为培训和提升临床能力的潜在工具。总体而言，AI的准确性和可视化是推动临床决策支持的关键因素。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16879v1",
      "published_date": "2024-10-22 10:31:23 UTC",
      "updated_date": "2024-10-22 10:31:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:08:40.390835"
    },
    {
      "arxiv_id": "2410.21303v1",
      "title": "VEMOCLAP: A video emotion classification web application",
      "title_zh": "翻译失败",
      "authors": [
        "Serkan Sulun",
        "Paula Viana",
        "Matthew E. P. Davies"
      ],
      "abstract": "We introduce VEMOCLAP: Video EMOtion Classifier using Pretrained features,\nthe first readily available and open-source web application that analyzes the\nemotional content of any user-provided video. We improve our previous work,\nwhich exploits open-source pretrained models that work on video frames and\naudio, and then efficiently fuse the resulting pretrained features using\nmulti-head cross-attention. Our approach increases the state-of-the-art\nclassification accuracy on the Ekman-6 video emotion dataset by 4.3% and offers\nan online application for users to run our model on their own videos or YouTube\nvideos. We invite the readers to try our application at serkansulun.com/app.",
      "tldr_zh": "本研究引入了 VEMOCLAP，这是一个开源网络应用，用于分析用户提供的视频情感内容。系统基于预训练模型处理视频帧和音频特征，并通过 multi-head cross-attention 机制高效融合这些特征。相比现有方法，在 Ekman-6 数据集上，分类准确率提高了 4.3%，并提供在线平台，用户可上传个人视频或 YouTube 视频进行测试。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to 2024 IEEE International Symposium on Multimedia (ISM),\n  Tokyo, Japan",
      "pdf_url": "http://arxiv.org/pdf/2410.21303v1",
      "published_date": "2024-10-22 10:12:11 UTC",
      "updated_date": "2024-10-22 10:12:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:08:50.399816"
    },
    {
      "arxiv_id": "2410.16864v1",
      "title": "Pedestrian motion prediction evaluation for urban autonomous driving",
      "title_zh": "城市自动驾驶的行人运动预测评估",
      "authors": [
        "Dmytro Zabolotnii",
        "Yar Muhammad",
        "Naveed Muhammad"
      ],
      "abstract": "Pedestrian motion prediction is a key part of the modular-based autonomous\ndriving pipeline, ensuring safe, accurate, and timely awareness of human\nagents' possible future trajectories. The autonomous vehicle can use this\ninformation to prevent any possible accidents and create a comfortable and\npleasant driving experience for the passengers and pedestrians. A wealth of\nresearch was done on the topic from the authors of robotics, computer vision,\nintelligent transportation systems, and other fields. However, a relatively\nunexplored angle is the integration of the state-of-art solutions into existing\nautonomous driving stacks and evaluating them in real-life conditions rather\nthan sanitized datasets. We analyze selected publications with provided\nopen-source solutions and provide a perspective obtained by integrating them\ninto existing Autonomous Driving framework - Autoware Mini and performing\nexperiments in natural urban conditions in Tartu, Estonia to determine\nvaluability of traditional motion prediction metrics. This perspective should\nbe valuable to any potential autonomous driving or robotics engineer looking\nfor the real-world performance of the existing state-of-art pedestrian motion\nprediction problem. The code with instructions on accessing the dataset is\navailable at https://github.com/dmytrozabolotnii/autoware_mini.",
      "tldr_zh": "本文评估了行人 motion prediction 在城市 autonomous driving 中的实际表现，强调将其整合到现有系统以避免事故并提升用户体验的重要性。研究团队选取了开源解决方案，融入 Autoware Mini 框架，并在爱沙尼亚 Tartu 的真实城市环境中进行实验，检验传统 motion prediction 指标的实用价值。结果显示，这些方法在真实条件下表现出的性能视角，能为自动驾驶或机器人工程师提供宝贵参考，相关代码和数据集可通过 https://github.com/dmytrozabolotnii/autoware_mini 访问。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2.9; D.4.8"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 2 figures, 4 tables This work has been submitted to the IEEE\n  for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2410.16864v1",
      "published_date": "2024-10-22 10:06:50 UTC",
      "updated_date": "2024-10-22 10:06:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:09:02.828471"
    },
    {
      "arxiv_id": "2410.16845v1",
      "title": "Fast Graph Sharpness-Aware Minimization for Enhancing and Accelerating Few-Shot Node Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Yihong Luo",
        "Yuhan Chen",
        "Siya Qiu",
        "Yiwei Wang",
        "Chen Zhang",
        "Yan Zhou",
        "Xiaochun Cao",
        "Jing Tang"
      ],
      "abstract": "Graph Neural Networks (GNNs) have shown superior performance in node\nclassification. However, GNNs perform poorly in the Few-Shot Node\nClassification (FSNC) task that requires robust generalization to make accurate\npredictions for unseen classes with limited labels. To tackle the challenge, we\npropose the integration of Sharpness-Aware Minimization (SAM)--a technique\ndesigned to enhance model generalization by finding a flat minimum of the loss\nlandscape--into GNN training. The standard SAM approach, however, consists of\ntwo forward-backward steps in each training iteration, doubling the\ncomputational cost compared to the base optimizer (e.g., Adam). To mitigate\nthis drawback, we introduce a novel algorithm, Fast Graph Sharpness-Aware\nMinimization (FGSAM), that integrates the rapid training of Multi-Layer\nPerceptrons (MLPs) with the superior performance of GNNs. Specifically, we\nutilize GNNs for parameter perturbation while employing MLPs to minimize the\nperturbed loss so that we can find a flat minimum with good generalization more\nefficiently. Moreover, our method reutilizes the gradient from the perturbation\nphase to incorporate graph topology into the minimization process at almost\nzero additional cost. To further enhance training efficiency, we develop FGSAM+\nthat executes exact perturbations periodically. Extensive experiments\ndemonstrate that our proposed algorithm outperforms the standard SAM with lower\ncomputational costs in FSNC tasks. In particular, our FGSAM+ as a SAM variant\noffers a faster optimization than the base optimizer in most cases. In addition\nto FSNC, our proposed methods also demonstrate competitive performance in the\nstandard node classification task for heterophilic graphs, highlighting the\nbroad applicability. The code is available at\nhttps://github.com/draym28/FGSAM_NeurIPS24.",
      "tldr_zh": "该论文针对Graph Neural Networks (GNNs)在Few-Shot Node Classification (FSNC)任务中的泛化能力不足问题，提出Fast Graph Sharpness-Aware Minimization (FGSAM)算法，通过整合Sharpness-Aware Minimization (SAM)技术来寻找损失景观的平坦最小值，从而提升模型性能。FGSAM创新性地结合GNNs进行参数扰动和Multi-Layer Perceptrons (MLPs)最小化扰动损失，同时重新利用梯度融入图拓扑信息，以显著降低计算成本；其扩展版本FGSAM+则定期执行精确扰动，进一步加速优化过程。实验结果显示，FGSAM在FSNC任务中比标准SAM提高性能且计算效率更高，并在异质图的标准节点分类中表现出色，证明了其广泛适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS24; The first two authors contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2410.16845v1",
      "published_date": "2024-10-22 09:33:29 UTC",
      "updated_date": "2024-10-22 09:33:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:09:17.141131"
    },
    {
      "arxiv_id": "2410.19852v1",
      "title": "Survival of the Fittest: Evolutionary Adaptation of Policies for Environmental Shifts",
      "title_zh": "适",
      "authors": [
        "Sheryl Paul",
        "Jyotirmoy V. Deshmukh"
      ],
      "abstract": "Reinforcement learning (RL) has been successfully applied to solve the\nproblem of finding obstacle-free paths for autonomous agents operating in\nstochastic and uncertain environments. However, when the underlying stochastic\ndynamics of the environment experiences drastic distribution shifts, the\noptimal policy obtained in the trained environment may be sub-optimal or may\nentirely fail in helping find goal-reaching paths for the agent. Approaches\nlike domain randomization and robust RL can provide robust policies, but\ntypically assume minor (bounded) distribution shifts. For substantial\ndistribution shifts, retraining (either with a warm-start policy or from\nscratch) is an alternative approach. In this paper, we develop a novel approach\ncalled {\\em Evolutionary Robust Policy Optimization} (ERPO), an adaptive\nre-training algorithm inspired by evolutionary game theory (EGT). ERPO learns\nan optimal policy for the shifted environment iteratively using a temperature\nparameter that controls the trade off between exploration and adherence to the\nold optimal policy. The policy update itself is an instantiation of the\nreplicator dynamics used in EGT. We show that under fairly common sparsity\nassumptions on rewards in such environments, ERPO converges to the optimal\npolicy in the shifted environment. We empirically demonstrate that for path\nfinding tasks in a number of environments, ERPO outperforms several popular RL\nand deep RL algorithms (PPO, A3C, DQN) in many scenarios and popular\nenvironments. This includes scenarios where the RL algorithms are allowed to\ntrain from scratch in the new environment, when they are retrained on the new\nenvironment, or when they are used in conjunction with domain randomization.\nERPO shows faster policy adaptation, higher average rewards, and reduced\ncomputational costs in policy adaptation.",
      "tldr_zh": "该论文探讨了强化学习 (RL) 在环境分布偏移时策略失效的问题，提出了一种新方法 Evolutionary Robust Policy Optimization (ERPO)，受进化博弈理论 (EGT) 启发，用于自适应重新训练策略。ERPO 通过温度参数控制探索与旧策略的平衡，并利用复制者动力学 (replicator dynamics) 进行策略更新，在奖励稀疏假设下确保收敛到偏移环境的最优策略。实验结果显示，ERPO 在路径寻找任务中优于传统算法如 PPO、A3C 和 DQN，提供更快适应、更高平均奖励和更低计算成本，即使在从零训练或结合领域随机化的场景下。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Pubblished in ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.19852v1",
      "published_date": "2024-10-22 09:29:53 UTC",
      "updated_date": "2024-10-22 09:29:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:09:27.264628"
    },
    {
      "arxiv_id": "2410.16842v1",
      "title": "Assessment of Transformer-Based Encoder-Decoder Model for Human-Like Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Sindhu Nair",
        "Y. S. Rao",
        "Radha Shankarmani"
      ],
      "abstract": "In recent times, extracting valuable information from large text is making\nsignificant progress. Especially in the current era of social media, people\nexpect quick bites of information. Automatic text summarization seeks to tackle\nthis by slimming large texts down into more manageable summaries. This\nimportant research area can aid in decision-making by digging out salient\ncontent from large text. With the progress in deep learning models, significant\nwork in language models has emerged. The encoder-decoder framework in deep\nlearning has become the central approach for automatic text summarization. This\nwork leverages transformer-based BART model for human-like summarization which\nis an open-ended problem with many challenges. On training and fine-tuning the\nencoder-decoder model, it is tested with diverse sample articles and the\nquality of summaries of diverse samples is assessed based on human evaluation\nparameters. Further, the finetuned model performance is compared with the\nbaseline pretrained model based on evaluation metrics like ROUGE score and\nBERTScore. Additionally, domain adaptation of the model is required for\nimproved performance of abstractive summarization of dialogues between\ninterlocutors. On investigating, the above popular evaluation metrics are found\nto be insensitive to factual errors. Further investigation of the summaries\ngenerated by finetuned model is done using the contemporary evaluation metrics\nof factual consistency like WeCheck and SummaC. Empirical results on BBC News\narticles highlight that the gold standard summaries written by humans are more\nfactually consistent by 17% than the abstractive summaries generated by\nfinetuned model.",
      "tldr_zh": "本研究评估了基于Transformer的编码器-解码器模型，特别是BART模型，在生成类似人类摘要方面的性能，旨在处理自动文本摘要的挑战。研究通过训练和微调BART模型，使用ROUGE score和BERTScore等指标对摘要质量进行评估，并与基线预训练模型进行比较。结果显示，模型生成的抽象摘要在事实一致性上不如人类撰写的摘要，低17%，且传统评估指标对事实错误不敏感；进一步使用WeCheck和SummaC等指标证实了这一问题，为改进摘要模型的领域适应性和事实准确性提供了见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Pre-print",
      "pdf_url": "http://arxiv.org/pdf/2410.16842v1",
      "published_date": "2024-10-22 09:25:04 UTC",
      "updated_date": "2024-10-22 09:25:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:09:39.872679"
    },
    {
      "arxiv_id": "2411.00017v1",
      "title": "Applying Data Driven Decision Making to rank Vocational and Educational Training Programs with TOPSIS",
      "title_zh": "翻译失败",
      "authors": [
        "J. M. Conejero",
        "J. C. Preciado",
        "A. E. Prieto",
        "M. C. Bas",
        "V. J. Bolos"
      ],
      "abstract": "In this paper we present a multi-criteria classification of Vocational and\nEducational Programs in Extremadura (Spain) during the period 2009-2016. This\nranking has been carried out through the integration into a complete database\nof the detailed information of individuals finishing such studies together with\ntheir labor data. The multicriteria method used is TOPSIS together with a new\ndecision support method for assessing the influence of each criterion and its\ndependence on the weights assigned to them. This new method is based on a\nworst-best case scenario analysis and it is compared to a well known global\nsensitivity analysis technique based on the Pearson's correlation ratio.",
      "tldr_zh": "本研究应用数据驱动决策方法，使用 TOPSIS 多标准决策技术，对西班牙埃斯特雷马杜拉地区2009-2016年间职业和教育培训项目进行了排名分类。研究整合了完成这些项目个人的详细资料及其劳动力数据，作为评估基础。论文引入了一个新决策支持方法，通过最坏-最好场景分析评估每个标准的权重影响，并与基于 Pearson's correlation ratio 的全局敏感性分析技术进行了比较。结果显示，该方法有助于更准确地评估项目排名，提供更可靠的多标准决策框架。",
      "categories": [
        "cs.AI",
        "cs.NA",
        "math.NA",
        "90B50, 90C29, 90C31, 91A35, 62C86"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.00017v1",
      "published_date": "2024-10-22 09:04:41 UTC",
      "updated_date": "2024-10-22 09:04:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:09:50.167590"
    },
    {
      "arxiv_id": "2410.16824v1",
      "title": "PerspectiveNet: Multi-View Perception for Dynamic Scene Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Vinh Nguyen"
      ],
      "abstract": "Generating detailed descriptions from multiple cameras and viewpoints is\nchallenging due to the complex and inconsistent nature of visual data. In this\npaper, we introduce PerspectiveNet, a lightweight yet efficient model for\ngenerating long descriptions across multiple camera views. Our approach\nutilizes a vision encoder, a compact connector module to convert visual\nfeatures into a fixed-size tensor, and large language models (LLMs) to harness\nthe strong natural language generation capabilities of LLMs. The connector\nmodule is designed with three main goals: mapping visual features onto LLM\nembeddings, emphasizing key information needed for description generation, and\nproducing a fixed-size feature matrix. Additionally, we augment our solution\nwith a secondary task, the correct frame sequence detection, enabling the model\nto search for the correct sequence of frames to generate descriptions. Finally,\nwe integrate the connector module, the secondary task, the LLM, and a visual\nfeature extraction model into a single architecture, which is trained for the\nTraffic Safety Description and Analysis task. This task requires generating\ndetailed, fine-grained descriptions of events from multiple cameras and\nviewpoints. The resulting model is lightweight, ensuring efficient training and\ninference, while remaining highly effective.",
      "tldr_zh": "本文提出 PerspectiveNet，一种轻量级模型，用于从多个相机视角生成详细的动态场景描述，解决视觉数据复杂性和不一致性的挑战。该模型整合 vision encoder、connector module（负责将视觉特征映射到 LLM 嵌入、强调关键信息并输出固定大小张量）以及大型语言模型（LLMs）来增强自然语言生成能力。此外，PerspectiveNet 引入 frame sequence detection 作为辅助任务，帮助模型准确识别帧序列，并在交通安全描述和分析任务中实现高效训练和推理，同时保持高有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.16824v1",
      "published_date": "2024-10-22 08:57:17 UTC",
      "updated_date": "2024-10-22 08:57:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:10:03.544659"
    },
    {
      "arxiv_id": "2410.16822v2",
      "title": "Can Large Language Models Act as Ensembler for Multi-GNNs?",
      "title_zh": "大语言模型能否充当多GNNs的集成器？",
      "authors": [
        "Hanqi Duan",
        "Yao Cheng",
        "Jianxiang Yu",
        "Xiang Li"
      ],
      "abstract": "Graph Neural Networks (GNNs) have emerged as powerful models for learning\nfrom graph-structured data. However, GNNs lack the inherent semantic\nunderstanding capability of rich textual node attributes, limiting their\neffectiveness in applications. On the other hand, we empirically observe that\nfor existing GNN models, no one can consistently outperforms others across\ndiverse datasets. In this paper, we study whether LLMs can act as an ensembler\nfor multi-GNNs and propose the LensGNN model. The model first aligns multiple\nGNNs, mapping the representations of different GNNs into the same space. Then,\nthrough LoRA fine-tuning, it aligns the space between the GNN and the LLM,\ninjecting graph tokens and textual information into LLMs. This allows LensGNN\nto ensemble multiple GNNs and take advantage of the strengths of LLM, leading\nto a deeper understanding of both textual semantic information and graph\nstructural information. The experimental results show that LensGNN outperforms\nexisting models. This research advances text-attributed graph ensemble learning\nby providing a robust and superior solution for integrating semantic and\nstructural information. We provide our code and data here:\nhttps://anonymous.4open.science/r/EnsemGNN-E267/.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)是否能作为多图神经网络(GNNs)集成器，以解决GNNs在处理图结构数据时缺乏文本语义理解的问题，并观察到不同GNN模型在各种数据集上表现不一致。论文提出LensGNN模型，首先对齐多个GNN的表示空间，然后通过LoRA微调将GNN和LLMs的空间对齐，注入图token和文本信息，从而实现多GNN集成并利用LLMs的优势。实验结果显示，LensGNN在文本属性图集成学习中优于现有模型，提供了一个更鲁棒的解决方案来融合语义和结构信息。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16822v2",
      "published_date": "2024-10-22 08:48:52 UTC",
      "updated_date": "2024-12-17 07:20:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:10:15.317280"
    },
    {
      "arxiv_id": "2410.16803v3",
      "title": "Context-aware Inductive Knowledge Graph Completion with Latent Type Constraints and Subgraph Reasoning",
      "title_zh": "上下文感知的归纳式知识图谱补全，结合潜在类型约束和子图推理",
      "authors": [
        "Muzhi Li",
        "Cehao Yang",
        "Chengjin Xu",
        "Zixing Song",
        "Xuhui Jiang",
        "Jian Guo",
        "Ho-fung Leung",
        "Irwin King"
      ],
      "abstract": "Inductive knowledge graph completion (KGC) aims to predict missing triples\nwith unseen entities. Recent works focus on modeling reasoning paths between\nthe head and tail entity as direct supporting evidence. However, these methods\ndepend heavily on the existence and quality of reasoning paths, which limits\ntheir general applicability in different scenarios. In addition, we observe\nthat latent type constraints and neighboring facts inherent in KGs are also\nvital in inferring missing triples. To effectively utilize all useful\ninformation in KGs, we introduce CATS, a novel context-aware inductive KGC\nsolution. With sufficient guidance from proper prompts and supervised\nfine-tuning, CATS activates the strong semantic understanding and reasoning\ncapabilities of large language models to assess the existence of query triples,\nwhich consist of two modules. First, the type-aware reasoning module evaluates\nwhether the candidate entity matches the latent entity type as required by the\nquery relation. Then, the subgraph reasoning module selects relevant reasoning\npaths and neighboring facts, and evaluates their correlation to the query\ntriple. Experiment results on three widely used datasets demonstrate that CATS\nsignificantly outperforms state-of-the-art methods in 16 out of 18\ntransductive, inductive, and few-shot settings with an average absolute MRR\nimprovement of 7.2%.",
      "tldr_zh": "该论文针对归纳式知识图谱完成（Inductive KGC）问题，提出了一种新方法 CATS，以利用上下文信息、潜在类型约束（latent type constraints）和子图推理（subgraph reasoning）来预测包含未见实体的缺失三元组。CATS 通过大型语言模型的语义理解能力，结合类型感知推理模块（评估候选实体是否匹配查询关系的潜在类型）和子图推理模块（选择相关路径和邻居事实并评估其相关性），有效整合知识图谱中的有用信息。实验结果显示，在三个常用数据集上，CATS 在 18 个跨导式、归纳式和少样本设置中的 16 个中优于最先进方法，平均 MRR 绝对提升 7.2%。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16803v3",
      "published_date": "2024-10-22 08:28:05 UTC",
      "updated_date": "2024-12-27 15:32:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:10:28.563161"
    },
    {
      "arxiv_id": "2410.16801v2",
      "title": "Controlled Low-Rank Adaptation with Subspace Regularization for Continued Training on Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuheng Lu",
        "Bingshuo Qian",
        "Caixia Yuan",
        "Huixing Jiang",
        "Xiaojie Wang"
      ],
      "abstract": "Large language models (LLMs) exhibit remarkable capabilities in natural\nlanguage processing but face catastrophic forgetting when learning new tasks,\nwhere adaptation to a new domain leads to a substantial decline in performance\non previous tasks. In this paper, we propose Controlled LoRA (CLoRA), a\nsub-space regularization method on LoRA structure. Aiming to reduce the scale\nof output change while introduce minimal constraint on model capacity, CLoRA\nimposes constraint on the direction of updating matrix's null space.\nExperimental results on one-stage LLM finetuning tasks and continual learning\nsettings highlight the superority of CLoRA as a effective parameter efficient\nfinetuning method with catastrophic forgetting mitigating.Further investigation\nfor model parameters indicates that CLoRA effectively balances the trade-off\nbetween model capacity and degree of forgetting.",
      "tldr_zh": "大语言模型 (LLMs) 在处理新任务时容易出现灾难性遗忘 (catastrophic forgetting)，导致原有性能下降。为此，本文提出 Controlled LoRA (CLoRA)，一种在 LoRA 结构上施加子空间正则化的方法，通过约束更新矩阵的空空间方向来最小化输出变化，同时保持模型容量。CLoRA 在单阶段微调任务和持续学习设置中表现出色，比基线方法更有效地缓解遗忘问题。实验结果和参数分析表明，CLoRA 成功平衡了模型容量与遗忘程度的权衡，为参数高效微调提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16801v2",
      "published_date": "2024-10-22 08:27:23 UTC",
      "updated_date": "2025-03-21 12:34:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:10:39.052742"
    },
    {
      "arxiv_id": "2410.16795v2",
      "title": "Scene-Aware Explainable Multimodal Trajectory Prediction",
      "title_zh": "场景感知的可解释多模态轨迹预测",
      "authors": [
        "Pei Liu",
        "Haipeng Liu",
        "Xingyu Liu",
        "Yiqun Li",
        "Junlan Chen",
        "Yangfan He",
        "Jun Ma"
      ],
      "abstract": "Advancements in intelligent technologies have significantly improved\nnavigation in complex traffic environments by enhancing environment perception\nand trajectory prediction for automated vehicles. However, current research\noften overlooks the joint reasoning of scenario agents and lacks explainability\nin trajectory prediction models, limiting their practical use in real-world\nsituations. To address this, we introduce the Explainable Conditional\nDiffusion-based Multimodal Trajectory Prediction (DMTP) model, which is\ndesigned to elucidate the environmental factors influencing predictions and\nreveal the underlying mechanisms. Our model integrates a modified conditional\ndiffusion approach to capture multimodal trajectory patterns and employs a\nrevised Shapley Value model to assess the significance of global and\nscenario-specific features. Experiments using the Waymo Open Motion Dataset\ndemonstrate that our explainable model excels in identifying critical inputs\nand significantly outperforms baseline models in accuracy. Moreover, the\nfactors identified align with the human driving experience, underscoring the\nmodel's effectiveness in learning accurate predictions. Code is available in\nour open-source repository:\nhttps://github.com/ocean-luna/Explainable-Prediction.",
      "tldr_zh": "本研究针对自动驾驶中的轨迹预测问题，指出现有方法常忽略场景代理的联合推理和模型可解释性，导致实际应用受限。作者提出 Explainable Conditional Diffusion-based Multimodal Trajectory Prediction (DMTP) 模型，该模型整合修改后的条件扩散方法捕捉多模态轨迹模式，并使用修订的 Shapley Value 模型评估全局和场景特定特征的重要性。实验在 Waymo Open Motion Dataset 上显示，DMTP 模型在准确性上显著优于基线模型，且识别的关键因素与人类驾驶经验高度一致。该框架的开源代码已在仓库中提供，进一步促进了研究的透明性和可重复性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16795v2",
      "published_date": "2024-10-22 08:17:33 UTC",
      "updated_date": "2025-03-10 01:33:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:10:50.621616"
    },
    {
      "arxiv_id": "2410.16794v1",
      "title": "One-Step Diffusion Distillation through Score Implicit Matching",
      "title_zh": "通过分数隐式匹配的一步扩散模型蒸馏",
      "authors": [
        "Weijian Luo",
        "Zemin Huang",
        "Zhengyang Geng",
        "J. Zico Kolter",
        "Guo-jun Qi"
      ],
      "abstract": "Despite their strong performances on many generative tasks, diffusion models\nrequire a large number of sampling steps in order to generate realistic\nsamples. This has motivated the community to develop effective methods to\ndistill pre-trained diffusion models into more efficient models, but these\nmethods still typically require few-step inference or perform substantially\nworse than the underlying model. In this paper, we present Score Implicit\nMatching (SIM) a new approach to distilling pre-trained diffusion models into\nsingle-step generator models, while maintaining almost the same sample\ngeneration ability as the original model as well as being data-free with no\nneed of training samples for distillation. The method rests upon the fact that,\nalthough the traditional score-based loss is intractable to minimize for\ngenerator models, under certain conditions we can efficiently compute the\ngradients for a wide class of score-based divergences between a diffusion model\nand a generator. SIM shows strong empirical performances for one-step\ngenerators: on the CIFAR10 dataset, it achieves an FID of 2.06 for\nunconditional generation and 1.96 for class-conditional generation. Moreover,\nby applying SIM to a leading transformer-based diffusion model, we distill a\nsingle-step generator for text-to-image (T2I) generation that attains an\naesthetic score of 6.42 with no performance decline over the original\nmulti-step counterpart, clearly outperforming the other one-step generators\nincluding SDXL-TURBO of 5.33, SDXL-LIGHTNING of 5.34 and HYPER-SDXL of 5.85. We\nwill release this industry-ready one-step transformer-based T2I generator along\nwith this paper.",
      "tldr_zh": "本文提出了一种名为 Score Implicit Matching (SIM) 的新方法，用于将预训练的 diffusion models 蒸馏成单步生成器模型，从而显著减少采样步骤，同时保持几乎与原模型相同的生成性能，且无需训练样本（data-free）。SIM 通过计算 diffusion models 和生成器之间分数-based 差异的梯度来实现高效优化，在 CIFAR10 数据集上实现了无条件生成 FID 2.06 和有条件生成 FID 1.96 的出色结果。实验还显示，在文本到图像 (T2I) 生成任务中，SIM 蒸馏的单步 transformer-based 生成器达到美学分数 6.42，优于其他单步模型如 SDXL-TURBO (5.33)，并将此模型开源以推动实际应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.16794v1",
      "published_date": "2024-10-22 08:17:20 UTC",
      "updated_date": "2024-10-22 08:17:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:11:03.371089"
    },
    {
      "arxiv_id": "2410.16788v1",
      "title": "Correct after Answer: Enhancing Multi-Span Question Answering with Post-Processing Method",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayi Lin",
        "Chenyang Zhang",
        "Haibo Tong",
        "Dongyu Zhang",
        "Qingqing Hong",
        "Bingxuan Hou",
        "Junli Wang"
      ],
      "abstract": "Multi-Span Question Answering (MSQA) requires models to extract one or\nmultiple answer spans from a given context to answer a question. Prior work\nmainly focuses on designing specific methods or applying heuristic strategies\nto encourage models to predict more correct predictions. However, these models\nare trained on gold answers and fail to consider the incorrect predictions.\nThrough a statistical analysis, we observe that models with stronger abilities\ndo not predict less incorrect predictions compared with other models. In this\nwork, we propose Answering-Classifying-Correcting (ACC) framework, which\nemploys a post-processing strategy to handle incorrect predictions.\nSpecifically, the ACC framework first introduces a classifier to classify the\npredictions into three types and exclude \"wrong predictions\", then introduces a\ncorrector to modify \"partially correct predictions\". Experiments on several\nMSQA datasets show that ACC framework significantly improves the Exact Match\n(EM) scores, and further analysis demostrates that ACC framework efficiently\nreduces the number of incorrect predictions, improving the quality of\npredictions.",
      "tldr_zh": "这篇论文针对 Multi-Span Question Answering (MSQA) 的错误预测问题，提出 Answering-Classifying-Correcting (ACC) 框架，通过后处理策略来处理不准确的答案。ACC 框架首先使用一个分类器将预测分类为三种类型并排除“错误预测”，然后通过一个修正器修改“部分正确预测”，从而提升预测的整体质量。实验结果显示，在多个 MSQA 数据集上，该框架显著提高了 Exact Match (EM) 分数，并有效减少了错误预测的数量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.16788v1",
      "published_date": "2024-10-22 08:04:32 UTC",
      "updated_date": "2024-10-22 08:04:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:11:14.887870"
    },
    {
      "arxiv_id": "2410.16780v2",
      "title": "Beyond Retrieval: Generating Narratives in Conversational Recommender Systems",
      "title_zh": "超越检索：对话式推荐系统中的叙述生成",
      "authors": [
        "Krishna Sayana",
        "Raghavendra Vasudeva",
        "Yuri Vasilevski",
        "Kun Su",
        "Liam Hebert",
        "James Pine",
        "Hubert Pham",
        "Ambarish Jash",
        "Sukhdeep Sodhi"
      ],
      "abstract": "The recent advances in Large Language Model's generation and reasoning\ncapabilities present an opportunity to develop truly conversational\nrecommendation systems. However, effectively integrating recommender system\nknowledge into LLMs for natural language generation which is tailored towards\nrecommendation tasks remains a challenge. This paper addresses this challenge\nby making two key contributions.\n  First, we introduce a new dataset (REGEN) for natural language generation\ntasks in conversational recommendations. REGEN (Reviews Enhanced with\nGEnerative Narratives) extends the Amazon Product Reviews dataset with rich\nuser narratives, including personalized explanations of product preferences,\nproduct endorsements for recommended items, and summaries of user purchase\nhistory. REGEN is made publicly available to facilitate further research.\nFurthermore, we establish benchmarks using well-known generative metrics, and\nperform an automated evaluation of the new dataset using a rater LLM. Second,\nthe paper introduces a fusion architecture (CF model with an LLM) which serves\nas a baseline for REGEN. And to the best of our knowledge, represents the first\nattempt to analyze the capabilities of LLMs in understanding recommender\nsignals and generating rich narratives. We demonstrate that LLMs can\neffectively learn from simple fusion architectures utilizing interaction-based\nCF embeddings, and this can be further enhanced using the metadata and\npersonalization data associated with items. Our experiments show that combining\nCF and content embeddings leads to improvements of 4-12% in key language\nmetrics compared to using either type of embedding individually. We also\nprovide an analysis to interpret how CF and content embeddings contribute to\nthis new generative task.",
      "tldr_zh": "这篇论文探讨了如何利用 Large Language Models (LLMs) 的生成和推理能力，超越传统检索方法，在对话式推荐系统中生成个性化叙述，以解决推荐知识与自然语言生成的整合挑战。论文的主要贡献包括引入新数据集 REGEN（Reviews Enhanced with GEnerative Narratives），它扩展了 Amazon Product Reviews 数据集，添加了用户偏好解释、产品背书和购买历史总结，并公开提供用于基准评估。第二，提出了一种融合架构（CF model with an LLM）作为基准模型，首次分析了 LLMs 在理解推荐信号和生成叙述方面的能力。实验显示，结合 CF embeddings 和内容 embeddings 可以使关键语言指标提高 4-12%，并通过分析解释了这些 embeddings 的贡献作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16780v2",
      "published_date": "2024-10-22 07:53:41 UTC",
      "updated_date": "2024-12-10 18:45:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:11:28.113769"
    },
    {
      "arxiv_id": "2410.16770v2",
      "title": "The Scene Language: Representing Scenes with Programs, Words, and Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Yunzhi Zhang",
        "Zizhang Li",
        "Matt Zhou",
        "Shangzhe Wu",
        "Jiajun Wu"
      ],
      "abstract": "We introduce the Scene Language, a visual scene representation that concisely\nand precisely describes the structure, semantics, and identity of visual\nscenes. It represents a scene with three key components: a program that\nspecifies the hierarchical and relational structure of entities in the scene,\nwords in natural language that summarize the semantic class of each entity, and\nembeddings that capture the visual identity of each entity. This representation\ncan be inferred from pre-trained language models via a training-free inference\ntechnique, given text or image inputs. The resulting scene can be rendered into\nimages using traditional, neural, or hybrid graphics renderers. Together, this\nforms a robust, automated system for high-quality 3D and 4D scene generation.\nCompared with existing representations like scene graphs, our proposed Scene\nLanguage generates complex scenes with higher fidelity, while explicitly\nmodeling the scene structures to enable precise control and editing.",
      "tldr_zh": "该论文引入了 Scene Language，一种用于精确表示视觉场景的语言，该语言由程序（program）定义场景的层次和关系结构、自然语言词汇（words）总结实体的语义类别，以及嵌入（embeddings）捕捉实体的视觉身份三部分组成。Scene Language 可以通过训练-free 推理从预训练语言模型中推断而来，支持从文本或图像输入生成高质量的 3D 和 4D 场景，并可使用传统、神经或混合渲染器进行渲染。与现有的 scene graphs 表示相比，该方法在生成复杂场景时具有更高的保真度，并允许更精确的控制和编辑。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025. Project page:\n  https://ai.stanford.edu/~yzzhang/projects/scene-language/",
      "pdf_url": "http://arxiv.org/pdf/2410.16770v2",
      "published_date": "2024-10-22 07:40:20 UTC",
      "updated_date": "2025-03-29 19:17:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:11:39.338150"
    },
    {
      "arxiv_id": "2410.16765v1",
      "title": "Survival Models: Proper Scoring Rule and Stochastic Optimization with Competing Risks",
      "title_zh": "翻译失败",
      "authors": [
        "Julie Alberge",
        "Vincent Maladière",
        "Olivier Grisel",
        "Judith Abécassis",
        "Gaël Varoquaux"
      ],
      "abstract": "When dealing with right-censored data, where some outcomes are missing due to\na limited observation period, survival analysis -- known as time-to-event\nanalysis -- focuses on predicting the time until an event of interest occurs.\nMultiple classes of outcomes lead to a classification variant: predicting the\nmost likely event, a less explored area known as competing risks. Classic\ncompeting risks models couple architecture and loss, limiting scalability.To\naddress these issues, we design a strictly proper censoring-adjusted separable\nscoring rule, allowing optimization on a subset of the data as each observation\nis evaluated independently. The loss estimates outcome probabilities and\nenables stochastic optimization for competing risks, which we use for efficient\ngradient boosting trees. SurvivalBoost not only outperforms 12 state-of-the-art\nmodels across several metrics on 4 real-life datasets, both in competing risks\nand survival settings, but also provides great calibration, the ability to\npredict across any time horizon, and computation times faster than existing\nmethods.",
      "tldr_zh": "这篇论文针对生存分析（survival analysis）中的竞争风险（competing risks）问题，提出了一种严格适当的删失调整可分离评分规则（strictly proper censoring-adjusted separable scoring rule），允许在数据子集上进行独立评估和随机优化（stochastic optimization）。该方法应用于高效的梯度提升树模型SurvivalBoost，实现对事件概率的精确估计。实验结果显示，SurvivalBoost在4个真实数据集上优于12个最先进模型，在多个指标上表现出色，包括更好的校准（calibration）、任意时间范围的预测能力以及更快的计算速度。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2406.14085",
      "pdf_url": "http://arxiv.org/pdf/2410.16765v1",
      "published_date": "2024-10-22 07:33:34 UTC",
      "updated_date": "2024-10-22 07:33:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:11:52.314541"
    },
    {
      "arxiv_id": "2410.16762v1",
      "title": "Deep-Sea A*+: An Advanced Path Planning Method Integrating Enhanced A* and Dynamic Window Approach for Autonomous Underwater Vehicles",
      "title_zh": "Deep-Sea A*+：一种整合增强 A* 和动态窗口方法的先进路径规划方法，用于自主水下车辆",
      "authors": [
        "Yinyi Lai",
        "Jiaqi Shang",
        "Zenghui Liu",
        "Zheyu Jiang",
        "Yuyang Li",
        "Longchao Chen"
      ],
      "abstract": "As terrestrial resources become increasingly depleted, the demand for\ndeep-sea resource exploration has intensified. However, the extreme conditions\nin the deep-sea environment pose significant challenges for underwater\noperations, necessitating the development of robust detection robots. In this\npaper, we propose an advanced path planning methodology that integrates an\nimproved A* algorithm with the Dynamic Window Approach (DWA). By optimizing the\nsearch direction of the traditional A* algorithm and introducing an enhanced\nevaluation function, our improved A* algorithm accelerates path searching and\nreduces computational load. Additionally, the path-smoothing process has been\nrefined to improve continuity and smoothness, minimizing sharp turns. This\nmethod also integrates global path planning with local dynamic obstacle\navoidance via DWA, improving the real-time response of underwater robots in\ndynamic environments. Simulation results demonstrate that our proposed method\nsurpasses the traditional A* algorithm in terms of path smoothness, obstacle\navoidance, and real-time performance. The robustness of this approach in\ncomplex environments with both static and dynamic obstacles highlights its\npotential in autonomous underwater vehicle (AUV) navigation and obstacle\navoidance.",
      "tldr_zh": "该论文提出了一种名为 Deep-Sea A*+ 的高级路径规划方法，针对自主水下车辆 (AUV) 在极端深海环境中的导航需求，将改进的 A* 算法与 Dynamic Window Approach (DWA) 相结合。改进的 A* 算法优化了搜索方向、引入了增强的评价函数，并提升了路径平滑过程，以加速路径搜索、减少计算负载并最小化急转弯。同时，该方法整合了全局路径规划和局部动态障碍避免，提高了 AUV 在复杂环境中的实时响应。模拟实验结果表明，Deep-Sea A*+ 在路径平滑度、障碍避免和实时性能上比传统 A* 算法提升显著，展示了其在 AUV 导航中的潜在应用价值。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by 2024 International Conference on Big Data, Artificial\n  Intelligence and Internet of Things Engineering (ICBAIE 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.16762v1",
      "published_date": "2024-10-22 07:29:05 UTC",
      "updated_date": "2024-10-22 07:29:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:12:04.587384"
    },
    {
      "arxiv_id": "2410.16759v2",
      "title": "Towards Efficient IMC Accelerator Design Through Joint Hardware-Workload Co-optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Olga Krestinskaya",
        "Mohammed E. Fouda",
        "Ahmed Eltawil",
        "Khaled N. Salama"
      ],
      "abstract": "Designing generalized in-memory computing (IMC) hardware that efficiently\nsupports a variety of workloads requires extensive design space exploration,\nwhich is infeasible to perform manually. Optimizing hardware individually for\neach workload or solely for the largest workload often fails to yield the most\nefficient generalized solutions. To address this, we propose a joint\nhardware-workload optimization framework that identifies optimised IMC chip\narchitecture parameters, enabling more efficient, workload-flexible hardware.\nWe show that joint optimization achieves 36%, 36%, 20%, and 69% better\nenergy-latency-area scores for VGG16, ResNet18, AlexNet, and MobileNetV3,\nrespectively, compared to the separate architecture parameters search\noptimizing for a single largest workload. Additionally, we quantify the\nperformance trade-offs and losses of the resulting generalized IMC hardware\ncompared to workload-specific IMC designs.",
      "tldr_zh": "这篇论文针对 in-memory computing (IMC) 硬件设计的问题，提出了一种联合硬件-工作负载优化框架，以实现更高效且灵活的通用 IMC 芯片架构。该框架通过同时优化硬件参数和多种工作负载，避免了单独针对单一最大工作负载的局限性。在实验中，与基准方法相比，该框架在 VGG16、ResNet18、AlexNet 和 MobileNetV3 上分别实现了 36%、36%、20% 和 69% 的能量-延迟-面积分数改善。此外，论文量化了通用 IMC 硬件相对于特定工作负载设计的性能权衡和损失，提供了一个更全面的设计指导。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "accepted to ISCAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.16759v2",
      "published_date": "2024-10-22 07:25:17 UTC",
      "updated_date": "2025-02-01 09:24:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:12:16.061828"
    },
    {
      "arxiv_id": "2410.16748v1",
      "title": "Uncovering Key Trends in Industry 5.0 through Advanced AI Techniques",
      "title_zh": "通过先进 AI 技术揭示 Industry 5.0 的关键趋势",
      "authors": [
        "Panos Fitsilis",
        "Paraskevi Tsoutsa",
        "Vyron Damasiotis",
        "Vasileios Kyriatzis"
      ],
      "abstract": "This article analyzes around 200 online articles to identify trends within\nIndustry 5.0 using artificial intelligence techniques. Specifically, it applies\nalgorithms such as LDA, BERTopic, LSA, and K-means, in various configurations,\nto extract and compare the central themes present in the literature. The\nresults reveal a convergence around a core set of themes while also\nhighlighting that Industry 5.0 spans a wide range of topics. The study\nconcludes that Industry 5.0, as an evolution of Industry 4.0, is a broad\nconcept that lacks a clear definition, making it difficult to focus on and\napply effectively. Therefore, for Industry 5.0 to be useful, it needs to be\nrefined and more clearly defined. Furthermore, the findings demonstrate that\nwell-known AI techniques can be effectively utilized for trend identification,\nparticularly when the available literature is extensive and the subject matter\nlacks precise boundaries. This study showcases the potential of AI in\nextracting meaningful insights from large and diverse datasets, even in cases\nwhere the thematic structure of the domain is not clearly delineated.",
      "tldr_zh": "这篇论文通过分析约200篇在线文章，使用高级AI技术（如LDA、BERTopic、LSA和K-means算法）来识别Industry 5.0的关键趋势。研究结果显示，这些主题围绕一组核心内容收敛，但Industry 5.0作为一个广泛且模糊的概念，涵盖了多种话题，缺乏清晰定义，这阻碍了其实际应用。作者强调，需要对Industry 5.0进行精炼和明确界定，以提升其实用性，同时证明了这些AI算法在处理大规模、主题不清晰的文献时的有效性。",
      "categories": [
        "cs.AI",
        "I.1; K.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16748v1",
      "published_date": "2024-10-22 07:06:00 UTC",
      "updated_date": "2024-10-22 07:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:12:27.058038"
    },
    {
      "arxiv_id": "2410.16746v1",
      "title": "SpikMamba: When SNN meets Mamba in Event-based Human Action Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Chen",
        "Yan Yang",
        "Shizhuo Deng",
        "Da Teng",
        "Liyuan Pan"
      ],
      "abstract": "Human action recognition (HAR) plays a key role in various applications such\nas video analysis, surveillance, autonomous driving, robotics, and healthcare.\nMost HAR algorithms are developed from RGB images, which capture detailed\nvisual information. However, these algorithms raise concerns in\nprivacy-sensitive environments due to the recording of identifiable features.\nEvent cameras offer a promising solution by capturing scene brightness changes\nsparsely at the pixel level, without capturing full images. Moreover, event\ncameras have high dynamic ranges that can effectively handle scenarios with\ncomplex lighting conditions, such as low light or high contrast environments.\nHowever, using event cameras introduces challenges in modeling the spatially\nsparse and high temporal resolution event data for HAR. To address these\nissues, we propose the SpikMamba framework, which combines the energy\nefficiency of spiking neural networks and the long sequence modeling capability\nof Mamba to efficiently capture global features from spatially sparse and high\na temporal resolution event data. Additionally, to improve the locality of\nmodeling, a spiking window-based linear attention mechanism is used. Extensive\nexperiments show that SpikMamba achieves remarkable recognition performance,\nsurpassing the previous state-of-the-art by 1.45%, 7.22%, 0.15%, and 3.92% on\nthe PAF, HARDVS, DVS128, and E-FAction datasets, respectively. The code is\navailable at https://github.com/Typistchen/SpikMamba.",
      "tldr_zh": "本研究针对基于 RGB 图像的人类动作识别（HAR）存在隐私和照明条件问题，提出 SpikMamba 框架，利用事件相机（event cameras）捕获空间稀疏和高时间分辨率数据。SpikMamba 结合了脉冲神经网络（SNNs）的能量效率和 Mamba 的长序列建模能力，并引入脉冲窗口-based linear attention 机制来增强局部建模。实验结果显示，该框架在 PAF、HARDVS、DVS128 和 E-FAction 数据集上分别超过了现有最先进方法 1.45%、7.22%、0.15% 和 3.92%，为高效的 HAR 应用提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.16746v1",
      "published_date": "2024-10-22 07:00:43 UTC",
      "updated_date": "2024-10-22 07:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:12:39.243395"
    },
    {
      "arxiv_id": "2410.16739v2",
      "title": "Rethinking Soft Actor-Critic in High-Dimensional Action Spaces: The Cost of Ignoring Distribution Shift",
      "title_zh": "重新思考 Soft Actor-Critic 在高维动作空间中的应用：忽略分布偏移的代价",
      "authors": [
        "Yanjun Chen",
        "Xinming Zhang",
        "Xianghui Wang",
        "Zhiqiang Xu",
        "Xiaoyu Shen",
        "Wei Zhang"
      ],
      "abstract": "Soft Actor-Critic algorithm is widely recognized for its robust performance\nacross a range of deep reinforcement learning tasks, where it leverages the\ntanh transformation to constrain actions within bounded limits. However, this\ntransformation induces a distribution shift, distorting the original Gaussian\naction distribution and potentially leading the policy to select suboptimal\nactions, particularly in high-dimensional action spaces. In this paper, we\nconduct a comprehensive theoretical and empirical analysis of this distribution\nshift, deriving the precise probability density function (PDF) for actions\nfollowing the tanh transformation to clarify the misalignment introduced\nbetween the transformed distribution's mode and the intended action output. We\nsubstantiate these theoretical insights through extensive experiments on\nhigh-dimensional tasks within the HumanoidBench benchmark. Our findings\nindicate that accounting for this distribution shift substantially enhances\nSAC's performance, resulting in notable improvements in cumulative rewards,\nsample efficiency, and reliability across tasks. These results underscore a\ncritical consideration for SAC and similar algorithms: addressing\ntransformation-induced distribution shifts is essential to optimizing policy\neffectiveness in high-dimensional deep reinforcement learning environments,\nthereby expanding the robustness and applicability of SAC in complex control\ntasks.",
      "tldr_zh": "本研究重新审视了Soft Actor-Critic (SAC)算法在高维动作空间中的问题，指出tanh变换引发的分布偏移会扭曲原始高斯动作分布，导致策略选择次优动作。论文通过理论分析推导了变换后动作的精确概率密度函数 (PDF)，并通过在HumanoidBench基准上的广泛实验验证了这一失调的影响。结果显示，考虑分布偏移后，SAC的累积奖励、样本效率和可靠性均显著提升，强调了在高维深度强化学习环境中处理这种偏移对优化策略有效性的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16739v2",
      "published_date": "2024-10-22 06:46:28 UTC",
      "updated_date": "2025-04-22 04:28:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:12:51.248087"
    },
    {
      "arxiv_id": "2410.16726v1",
      "title": "Enhancing Low-Resource ASR through Versatile TTS: Bridging the Data Gap",
      "title_zh": "通过多功能 TTS 增强低资源 ASR：弥合数据差距",
      "authors": [
        "Guanrou Yang",
        "Fan Yu",
        "Ziyang Ma",
        "Zhihao Du",
        "Zhifu Gao",
        "Shiliang Zhang",
        "Xie Chen"
      ],
      "abstract": "While automatic speech recognition (ASR) systems have achieved remarkable\nperformance with large-scale datasets, their efficacy remains inadequate in\nlow-resource settings, encompassing dialects, accents, minority languages, and\nlong-tail hotwords, domains with significant practical relevance. With the\nadvent of versatile and powerful text-to-speech (TTS) models, capable of\ngenerating speech with human-level naturalness, expressiveness, and diverse\nspeaker profiles, leveraging TTS for ASR data augmentation provides a\ncost-effective and practical approach to enhancing ASR performance.\nComprehensive experiments on an unprecedentedly rich variety of low-resource\ndatasets demonstrate consistent and substantial performance improvements,\nproving that the proposed method of enhancing low-resource ASR through a\nversatile TTS model is highly effective and has broad application prospects.\nFurthermore, we delve deeper into key characteristics of synthesized speech\ndata that contribute to ASR improvement, examining factors such as text\ndiversity, speaker diversity, and the volume of synthesized data, with text\ndiversity being studied for the first time in this work. We hope our findings\nprovide helpful guidance and reference for the practical application of\nTTS-based data augmentation and push the advancement of low-resource ASR one\nstep further.",
      "tldr_zh": "该研究针对低资源 ASR（自动语音识别）系统在方言、口音、少数民族语言和长尾热词等场景中的性能不足，提出了一种利用多功能 TTS（文本到语音）模型进行数据增强的方法，以桥接数据差距。实验在多种低资源数据集上验证了该方法的有效性，实现了 ASR 性能的显著提升。研究首次深入探讨了合成语音数据的关键因素，包括文本多样性、说话者多样性和数据量，其中文本多样性被证明对 ASR 改进至关重要。该方法为 TTS-based 数据增强提供了实用指导，并推动了低资源 ASR 的发展。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16726v1",
      "published_date": "2024-10-22 06:25:16 UTC",
      "updated_date": "2024-10-22 06:25:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:13:02.995312"
    },
    {
      "arxiv_id": "2410.16723v1",
      "title": "Resource-Efficient Sensor Fusion via System-Wide Dynamic Gated Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Chetna Singhal",
        "Yashuo Wu",
        "Francesco Malandrino",
        "Sharon Ladron de Guevara Contreras",
        "Marco Levorato",
        "Carla Fabiana Chiasserini"
      ],
      "abstract": "Mobile systems will have to support multiple AI-based applications, each\nleveraging heterogeneous data sources through DNN architectures collaboratively\nexecuted within the network. To minimize the cost of the AI inference task\nsubject to requirements on latency, quality, and - crucially - reliability of\nthe inference process, it is vital to optimize (i) the set of sensors/data\nsources and (ii) the DNN architecture, (iii) the network nodes executing\nsections of the DNN, and (iv) the resources to use. To this end, we leverage\ndynamic gated neural networks with branches, and propose a novel algorithmic\nstrategy called Quantile-constrained Inference (QIC), based upon\nquantile-Constrained policy optimization. QIC makes joint, high-quality, swift\ndecisions on all the above aspects of the system, with the aim to minimize\ninference energy cost. We remark that this is the first contribution connecting\ngated dynamic DNNs with infrastructure-level decision making. We evaluate QIC\nusing a dynamic gated DNN with stems and branches for optimal sensor fusion and\ninference, trained on the RADIATE dataset offering Radar, LiDAR, and Camera\ndata, and real-world wireless measurements. Our results confirm that QIC\nmatches the optimum and outperforms its alternatives by over 80%.",
      "tldr_zh": "该论文提出了一种资源高效的传感器融合方法，通过系统级的动态门控神经网络（Dynamic Gated Neural Networks）优化多 AI 应用的移动系统。作者引入了 Quantile-constrained Inference (QIC) 算法，基于 quantile-constrained policy optimization，联合决策传感器/数据源集、DNN 架构、网络节点和资源，以最小化推理能量成本，同时满足延迟、质量和可靠性要求。QIC 是首次将动态门控 DNN 与基础设施级决策相结合的贡献，在 RADIATE 数据集（包括 Radar、LiDAR 和 Camera 数据）上的实验中，QIC 匹配最优解，并比替代方案提高了超过 80% 的性能。",
      "categories": [
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16723v1",
      "published_date": "2024-10-22 06:12:04 UTC",
      "updated_date": "2024-10-22 06:12:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:13:17.527901"
    },
    {
      "arxiv_id": "2410.16713v4",
      "title": "Collapse or Thrive? Perils and Promises of Synthetic Data in a Self-Generating World",
      "title_zh": "崩溃还是繁荣？合成数据在自我生成世界",
      "authors": [
        "Joshua Kazdan",
        "Rylan Schaeffer",
        "Apratim Dey",
        "Matthias Gerstgrasser",
        "Rafael Rafailov",
        "David L. Donoho",
        "Sanmi Koyejo"
      ],
      "abstract": "What happens when generative machine learning models are pretrained on\nweb-scale datasets containing data generated by earlier models? Some prior work\nwarns of \"model collapse\" as the web is overwhelmed by synthetic data; other\nwork suggests the problem can be contained (i.e. collapse can be avoided) by\nmanaging how available data are used in pretraining. In this paper, we report\nexperiments on three ways of using data (training-workflows), across three\ngenerative model task-settings (multivariate Gaussian estimation, kernel\ndensity estimation, and language-model fine-tuning) to further confirm the\npossibility of containment: (a) we confirm that the training-workflow of {\\it\nreplacing} all real data by successive generations of purely synthetic data\nindeed suffers model collapse in all task-settings studied; (b) we consider the\ntraining-workflow of {\\it accumulating} synthetic data alongside real data and\ntraining on all data combined and confirming that, although the proportion of\nreal data eventually becomes zero, models remain stable and their test losses\ndo not diverge under this training-workflow; (c) we consider a\ntraining-workflow where real and synthetic data accumulate together but\nsuccessive generations of pretraining are constrained to use fixed-size data\nsubsets each generation. In this workflow, we observe slow and gradual rather\nthan explosive degradation of test loss performance across generations. Our\ninsights are particularly important when forecasting whether future frontier\ngenerative models will collapse or thrive, and our results open avenues for\nempirically and mathematically studying the context-dependent value of\nsynthetic data.",
      "tldr_zh": "该论文探讨了生成式机器学习模型在包含合成数据的网络规模数据集上预训练时，可能导致的“model collapse”问题，以及通过管理数据使用来避免崩溃的可能性。研究者通过实验验证了三种training-workflows（数据使用方式）和三种任务设置（multivariate Gaussian estimation、kernel density estimation及language-model fine-tuning）：完全替换真实数据会导致模型崩溃；累积合成数据与真实数据一起训练可保持模型稳定，测试损失不发散；而在固定大小数据子集的约束下，测试损失会缓慢渐进退化。总体而言，这些发现为预测未来生成模型是崩溃还是繁荣提供了重要洞见，并开辟了进一步研究合成数据价值的途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024 Workshops: Mathematics of Modern Machine\n  Learning (M3L) and Attributing Model Behavior at Scale (ATTRIB)",
      "pdf_url": "http://arxiv.org/pdf/2410.16713v4",
      "published_date": "2024-10-22 05:49:24 UTC",
      "updated_date": "2025-03-17 21:14:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:13:28.525043"
    },
    {
      "arxiv_id": "2410.16711v1",
      "title": "Development of CNN Architectures using Transfer Learning Methods for Medical Image Classification",
      "title_zh": "利用迁移学习方法开发 CNN 架构用于医学图像分类",
      "authors": [
        "Ganga Prasad Basyal",
        "David Zeng",
        "Bhaskar Pm Rimal"
      ],
      "abstract": "The application of deep learning-based architecture has seen a tremendous\nrise in recent years. For example, medical image classification using deep\nlearning achieved breakthrough results. Convolutional Neural Networks (CNNs)\nare implemented predominantly in medical image classification and segmentation.\nOn the other hand, transfer learning has emerged as a prominent supporting tool\nfor enhancing the efficiency and accuracy of deep learning models. This paper\ninvestigates the development of CNN architectures using transfer learning\ntechniques in the field of medical image classification using a timeline\nmapping model for key image classification challenges. Our findings help make\nan informed decision while selecting the optimum and state-of-the-art CNN\narchitectures.",
      "tldr_zh": "该论文探讨了使用转移学习（Transfer Learning）方法开发 CNN（Convolutional Neural Networks）架构，以提升医疗图像分类的效率和准确性。研究通过时间线映射模型分析了关键图像分类挑战，并回顾了 CNN 在医疗图像分类和分割中的应用。最终发现有助于用户在选择最优和最先进的 CNN 架构时做出明智决策。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16711v1",
      "published_date": "2024-10-22 05:37:51 UTC",
      "updated_date": "2024-10-22 05:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:13:38.360713"
    },
    {
      "arxiv_id": "2410.16710v1",
      "title": "Influential Language Data Selection via Gradient Trajectory Pursuit",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiwei Deng",
        "Tao Li",
        "Yang Li"
      ],
      "abstract": "Curating a desirable dataset for training has been the core of building\nhighly capable large language models (Touvron et al., 2023; Achiam et al.,\n2023; Team et al.,2024). Gradient influence scores (Pruthi et al., 2020; Xia et\nal., 2024) are shown to be correlated with model performance and are commonly\nused as the criterion for data selection. However, existing methods are built\nupon either individual sample rankings or inefficient matching process, leading\nto suboptimal performance or scaling up issues.In this paper, we propose\nGradient Trajectory Pursuit (GTP), an algorithm that performs pursuit of\ngradient trajectories via jointly selecting data points under an L0-norm\nregularized objective. The proposed algorithm highlights: (1) joint selection\ninstead of independent top-k selection, which automatically de-duplicates\nsamples; (2) higher efficiency with compressive sampling processes, which can\nbe further sped up using a distributed framework. In the experiments, we\ndemonstrate the algorithm in both in-domain and target-domain selection\nbenchmarks and show that it outperforms top-k selection and competitive\nalgorithms consistently, for example, our algorithm chooses as low as 0.5% data\nto achieve full performance on the targeted instruction tuning tasks",
      "tldr_zh": "这篇论文针对大型语言模型的数据选择问题，提出了一种名为Gradient Trajectory Pursuit (GTP)的算法，通过联合选择数据点并优化梯度轨迹来解决现有方法的子优性和效率问题。GTP采用L0-norm正则化目标，实现自动去重和高效的压缩采样过程，并支持分布式框架加速。实验结果显示，该算法在领域内和目标领域基准上显著优于top-k选择等竞争方法，例如，仅使用0.5%的数据即可在指令微调任务上达到完整性能。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16710v1",
      "published_date": "2024-10-22 05:32:40 UTC",
      "updated_date": "2024-10-22 05:32:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:13:51.837227"
    },
    {
      "arxiv_id": "2410.16709v1",
      "title": "Universal approximation property of ODENet and ResNet with a single activation function",
      "title_zh": "翻译失败",
      "authors": [
        "Masato Kimura",
        "Kazunori Matsui",
        "Yosuke Mizuno"
      ],
      "abstract": "We study a universal approximation property of ODENet and ResNet. The ODENet\nis a map from an initial value to the final value of an ODE system in a finite\ninterval. It is considered a mathematical model of a ResNet-type deep learning\nsystem. We consider dynamical systems with vector fields given by a single\ncomposition of the activation function and an affine mapping, which is the most\ncommon choice of the ODENet or ResNet vector field in actual machine learning\nsystems. We show that such an ODENet and ResNet with a restricted vector field\ncan uniformly approximate ODENet with a general vector field.",
      "tldr_zh": "本研究探讨了 ODENet 和 ResNet 的通用逼近性质，ODENet 被视为 ResNet 型深度学习系统的数学模型，专注于使用单一激活函数和仿射映射组成的向量场动态系统。研究证明，这种受限向量场的 ODENet 和 ResNet 可以均匀逼近具有一般向量场的 ODENet，从而扩展了这些模型在机器学习中的适用性。结果为简化神经网络设计提供了理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "stat.ML",
        "37M15, 41A46, 41A63, 65L12, 68T07, 65P99"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.16709v1",
      "published_date": "2024-10-22 05:27:01 UTC",
      "updated_date": "2024-10-22 05:27:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:14:04.545658"
    },
    {
      "arxiv_id": "2410.16705v1",
      "title": "Privacy-hardened and hallucination-resistant synthetic data generation with logic-solvers",
      "title_zh": "翻译失败",
      "authors": [
        "Mark A. Burgess",
        "Brendan Hosking",
        "Roc Reguant",
        "Anubhav Kaphle",
        "Mitchell J. O'Brien",
        "Letitia M. F. Sng",
        "Yatish Jain",
        "Denis C. Bauer"
      ],
      "abstract": "Machine-generated data is a valuable resource for training Artificial\nIntelligence algorithms, evaluating rare workflows, and sharing data under\nstricter data legislations. The challenge is to generate data that is accurate\nand private. Current statistical and deep learning methods struggle with large\ndata volumes, are prone to hallucinating scenarios incompatible with reality,\nand seldom quantify privacy meaningfully. Here we introduce Genomator, a logic\nsolving approach (SAT solving), which efficiently produces private and\nrealistic representations of the original data. We demonstrate the method on\ngenomic data, which arguably is the most complex and private information.\nSynthetic genomes hold great potential for balancing underrepresented\npopulations in medical research and advancing global data exchange. We\nbenchmark Genomator against state-of-the-art methodologies (Markov generation,\nRestricted Boltzmann Machine, Generative Adversarial Network and Conditional\nRestricted Boltzmann Machines), demonstrating an 84-93% accuracy improvement\nand 95-98% higher privacy. Genomator is also 1000-1600 times more efficient,\nmaking it the only tested method that scales to whole genomes. We show the\nuniversal trade-off between privacy and accuracy, and use Genomator's tuning\ncapability to cater to all applications along the spectrum, from provable\nprivate representations of sensitive cohorts, to datasets with\nindistinguishable pharmacogenomic profiles. Demonstrating the production-scale\ngeneration of tuneable synthetic data can increase trust and pave the way into\nthe clinic.",
      "tldr_zh": "本研究引入了 Genomator，一种基于 SAT solving 的逻辑求解方法，用于生成准确、私有且抵抗幻觉的合成数据，解决了现有统计和深度学习方法在处理大数据时存在的效率和隐私问题。实验在基因组数据上证明，Genomator 相较于 Markov generation、Restricted Boltzmann Machine、Generative Adversarial Network 等基准方法，准确性提升 84-93%，隐私水平提高 95-98%，且效率高出 1000-1600 倍，能够扩展到整个基因组规模。论文还探讨了隐私与准确性之间的权衡，并通过调优使 Genomator 适用于从高度敏感数据保护到临床药效基因组学等各种场景，促进合成数据在医疗研究和全球数据交换中的可信应用。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16705v1",
      "published_date": "2024-10-22 05:20:21 UTC",
      "updated_date": "2024-10-22 05:20:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:14:16.421916"
    },
    {
      "arxiv_id": "2410.16703v1",
      "title": "PLDR-LLM: Large Language Model from Power Law Decoder Representations",
      "title_zh": "PLDR-LLM：基于幂律解码器表示的大语言模型",
      "authors": [
        "Burc Gokden"
      ],
      "abstract": "We present the Large Language Model from Power Law Decoder Representations\n(PLDR-LLM), a language model that leverages non-linear and linear\ntransformations through Power Law Graph Attention mechanism to generate\nwell-defined deductive and inductive outputs. We pretrain the PLDR-LLMs of\nvarying layer sizes with a small batch size of 32 and $\\sim$8B tokens from the\nRefinedWeb dataset, and show that they achieve competitive performance in\nzero-shot and few-shot settings compared to scaled dot-product LLMs of similar\nmodel size reported in the literature. We show that deductive outputs of\nPLDR-LLMs can be used to compare model characteristics or improve the\nperformance by introducing the Directed Acyclic Graph (DAG) loss as a metric\nand regularizer. Our results indicate that the initial maximum learning rate\nand warm-up steps have a lasting impact on deductive outputs throughout the\npretraining. We provide a detailed description of PLDR-LLM architecture, its\nimplementation and the pretraining procedure.",
      "tldr_zh": "本研究引入了 PLDR-LLM，一种基于 Power Law Decoder Representations 的语言模型，利用 Power Law Graph Attention 机制进行非线性和平面变换，以生成精确的演绎和归纳输出。模型在 RefinedWeb 数据集上使用约 8B tokens 和小批量大小 32 进行预训练，在 zero-shot 和 few-shot 设置中，其性能与类似规模的 scaled dot-product LLMs 相当。研究进一步通过 Directed Acyclic Graph (DAG) loss 作为指标和正则化器，优化模型特性，并发现初始最大学习率和预热步骤会对输出产生持久影响，提供详细的架构、实现和预训练过程描述。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 4 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.16703v1",
      "published_date": "2024-10-22 05:16:19 UTC",
      "updated_date": "2024-10-22 05:16:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:14:28.398213"
    },
    {
      "arxiv_id": "2410.16700v2",
      "title": "AskBeacon -- Performing genomic data exchange and analytics with natural language",
      "title_zh": "翻译失败",
      "authors": [
        "Anuradha Wickramarachchi",
        "Shakila Tonni",
        "Sonali Majumdar",
        "Sarvnaz Karimi",
        "Sulev Kõks",
        "Brendan Hosking",
        "Jordi Rambla",
        "Natalie A. Twine",
        "Yatish Jain",
        "Denis C. Bauer"
      ],
      "abstract": "Enabling clinicians and researchers to directly interact with global genomic\ndata resources by removing technological barriers is vital for medical\ngenomics. AskBeacon enables Large Language Models to be applied to securely\nshared cohorts via the GA4GH Beacon protocol. By simply \"asking\" Beacon,\nactionable insights can be gained, analyzed and made publication-ready.",
      "tldr_zh": "AskBeacon 是一个创新系统，旨在通过自然语言交互消除技术障碍，让临床医生和研究人员直接访问全球基因组数据资源。系统整合 Large Language Models 与 GA4GH Beacon protocol，实现对安全共享队列的分析和处理。用户只需简单“提问”，即可获得可操作见解，并将其分析后准备用于发布，从而推进医疗基因组学的研究和应用。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "q-bio.GN"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16700v2",
      "published_date": "2024-10-22 05:11:54 UTC",
      "updated_date": "2024-10-23 02:29:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:14:40.198865"
    },
    {
      "arxiv_id": "2410.16699v2",
      "title": "Graph Transformers Dream of Electric Flow",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Cheng",
        "Lawrence Carin",
        "Suvrit Sra"
      ],
      "abstract": "We show theoretically and empirically that the linear Transformer, when\napplied to graph data, can implement algorithms that solve canonical problems\nsuch as electric flow and eigenvector decomposition. The Transformer has access\nto information on the input graph only via the graph's incidence matrix. We\npresent explicit weight configurations for implementing each algorithm, and we\nbound the constructed Transformers' errors by the errors of the underlying\nalgorithms. Our theoretical findings are corroborated by experiments on\nsynthetic data. Additionally, on a real-world molecular regression task, we\nobserve that the linear Transformer is capable of learning a more effective\npositional encoding than the default one based on Laplacian eigenvectors. Our\nwork is an initial step towards elucidating the inner-workings of the\nTransformer for graph data. Code is available at\nhttps://github.com/chengxiang/LinearGraphTransformer",
      "tldr_zh": "本文证明，线性 Transformer 在处理图数据时，能够实现 electric flow 和 eigenvector decomposition 等经典算法，仅通过图的 incidence matrix 访问输入信息，并提供显式权重配置来界定错误。研究结合理论分析和实验验证，在合成数据上证实了这一能力，并在真实分子回归任务中观察到线性 Transformer 学习了比默认基于 Laplacian eigenvectors 的 positional encoding 更有效的编码。这为理解 Transformer 在图数据上的内部机制提供了初步洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16699v2",
      "published_date": "2024-10-22 05:11:45 UTC",
      "updated_date": "2025-03-02 14:18:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:14:51.270865"
    },
    {
      "arxiv_id": "2410.16695v2",
      "title": "MPT: A Large-scale Multi-Phytoplankton Tracking Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Yu",
        "Yuezun Li",
        "Xin Sun",
        "Junyu Dong"
      ],
      "abstract": "Phytoplankton are a crucial component of aquatic ecosystems, and effective\nmonitoring of them can provide valuable insights into ocean environments and\necosystem changes. Traditional phytoplankton monitoring methods are often\ncomplex and lack timely analysis. Therefore, deep learning algorithms offer a\npromising approach for automated phytoplankton monitoring. However, the lack of\nlarge-scale, high-quality training samples has become a major bottleneck in\nadvancing phytoplankton tracking. In this paper, we propose a challenging\nbenchmark dataset, Multiple Phytoplankton Tracking (MPT), which covers diverse\nbackground information and variations in motion during observation. The dataset\nincludes 27 species of phytoplankton and zooplankton, 14 different backgrounds\nto simulate diverse and complex underwater environments, and a total of 140\nvideos. To enable accurate real-time observation of phytoplankton, we introduce\na multi-object tracking method, Deviation-Corrected Multi-Scale Feature Fusion\nTracker(DSFT), which addresses issues such as focus shifts during tracking and\nthe loss of small target information when computing frame-to-frame similarity.\nSpecifically, we introduce an additional feature extractor to predict the\nresiduals of the standard feature extractor's output, and compute multi-scale\nframe-to-frame similarity based on features from different layers of the\nextractor. Extensive experiments on the MPT have demonstrated the validity of\nthe dataset and the superiority of DSFT in tracking phytoplankton, providing an\neffective solution for phytoplankton monitoring.",
      "tldr_zh": "本文提出一个大规模多浮游植物跟踪基准数据集 MPT，以解决浮游植物监测中缺乏高质量训练样本的问题；该数据集涵盖27种浮游植物和动物、14种不同背景以及140个视频，模拟复杂的水下环境。作者引入了一种新方法 Deviation-Corrected Multi-Scale Feature Fusion Tracker (DSFT)，通过额外特征提取器预测残差并计算多尺度帧间相似性，解决跟踪中的焦点偏移和小目标信息丢失问题。实验结果表明，DSFT 在 MPT 数据集上表现出优越性能，为自动化浮游植物监测提供了有效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16695v2",
      "published_date": "2024-10-22 04:57:28 UTC",
      "updated_date": "2025-01-04 13:58:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:15:04.716152"
    },
    {
      "arxiv_id": "2410.16676v4",
      "title": "CausalEval: Towards Better Causal Reasoning in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Longxuan Yu",
        "Delin Chen",
        "Siheng Xiong",
        "Qingyang Wu",
        "Qingzhen Liu",
        "Dawei Li",
        "Zhikai Chen",
        "Xiaoze Liu",
        "Liangming Pan"
      ],
      "abstract": "Causal reasoning (CR) is a crucial aspect of intelligence, essential for\nproblem-solving, decision-making, and understanding the world. While language\nmodels (LMs) can generate rationales for their outputs, their ability to\nreliably perform causal reasoning remains uncertain, often falling short in\ntasks requiring a deep understanding of causality. In this paper, we introduce\nCausalEval, a comprehensive review of research aimed at enhancing LMs for\ncausal reasoning, coupled with an empirical evaluation of current models and\nmethods. We categorize existing methods based on the role of LMs: either as\nreasoning engines or as helpers providing knowledge or data to traditional CR\nmethods, followed by a detailed discussion of methodologies in each category.\nWe then assess the performance of current LMs and various enhancement methods\non a range of causal reasoning tasks, providing key findings and in-depth\nanalysis. Finally, we present insights from current studies and highlight\npromising directions for future research. We aim for this work to serve as a\ncomprehensive resource, fostering further advancements in causal reasoning with\nLMs.",
      "tldr_zh": "该论文探讨了语言模型（Language Models, LMs）在因果推理（Causal Reasoning, CR）方面的不足，强调其在问题解决和决策中表现不佳。作者引入 CausalEval，这是一个全面审查框架，将现有方法分类为 LMs 作为推理引擎或辅助工具，并通过实证评估比较了当前模型和增强方法的性能。研究提供了关键发现和分析，并指出未来研究方向，以促进 LMs 在因果推理领域的进步。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to NAACL25 (main)",
      "pdf_url": "http://arxiv.org/pdf/2410.16676v4",
      "published_date": "2024-10-22 04:18:19 UTC",
      "updated_date": "2025-02-17 20:16:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:15:15.891615"
    },
    {
      "arxiv_id": "2410.16672v1",
      "title": "DEAN: Deactivating the Coupled Neurons to Mitigate Fairness-Privacy Conflicts in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Qian",
        "Dongrui Liu",
        "Jie Zhang",
        "Yong Liu",
        "Jing Shao"
      ],
      "abstract": "Ensuring awareness of fairness and privacy in Large Language Models (LLMs) is\ncritical. Interestingly, we discover a counter-intuitive trade-off phenomenon\nthat enhancing an LLM's privacy awareness through Supervised Fine-Tuning (SFT)\nmethods significantly decreases its fairness awareness with thousands of\nsamples. To address this issue, inspired by the information theory, we\nintroduce a training-free method to \\textbf{DEA}ctivate the fairness and\nprivacy coupled \\textbf{N}eurons (\\textbf{DEAN}), which theoretically and\nempirically decrease the mutual information between fairness and privacy\nawareness. Extensive experimental results demonstrate that DEAN eliminates the\ntrade-off phenomenon and significantly improves LLMs' fairness and privacy\nawareness simultaneously, \\eg improving Qwen-2-7B-Instruct's fairness awareness\nby 12.2\\% and privacy awareness by 14.0\\%. More crucially, DEAN remains robust\nand effective with limited annotated data or even when only malicious\nfine-tuning data is available, whereas SFT methods may fail to perform properly\nin such scenarios. We hope this study provides valuable insights into\nconcurrently addressing fairness and privacy concerns in LLMs and can be\nintegrated into comprehensive frameworks to develop more ethical and\nresponsible AI systems. Our code is available at\n\\url{https://github.com/ChnQ/DEAN}.",
      "tldr_zh": "该研究发现，在大型语言模型（LLMs）中，通过 Supervised Fine-Tuning (SFT) 增强隐私意识会显著降低公平意识，揭示了公平和隐私之间的权衡冲突。作者提出了一种训练-free 方法 DEAN，通过关闭公平和隐私耦合神经元并减少其互信息，基于信息理论来缓解这一问题。实验结果显示，DEAN 成功消除了权衡现象，例如在 Qwen-2-7B-Instruct 模型上将公平意识提高了 12.2% 和隐私意识提高了 14.0%，并在数据有限或恶意数据场景下保持鲁棒性。最后，该方法为同时提升 LLMs 的公平和隐私意识提供了宝贵见解，有助于构建更道德的 AI 系统。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16672v1",
      "published_date": "2024-10-22 04:08:27 UTC",
      "updated_date": "2024-10-22 04:08:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:15:29.123660"
    },
    {
      "arxiv_id": "2410.16670v1",
      "title": "CoPS: Empowering LLM Agents with Provable Cross-Task Experience Sharing",
      "title_zh": "CoPS：通过可证明的跨任务经验共享增强 LLM 代理",
      "authors": [
        "Chen Yang",
        "Chenyang Zhao",
        "Quanquan Gu",
        "Dongruo Zhou"
      ],
      "abstract": "Sequential reasoning in agent systems has been significantly advanced by\nlarge language models (LLMs), yet existing approaches face limitations.\nReflection-driven reasoning relies solely on knowledge in pretrained models,\nlimiting performance in novel scenarios, while experience-assisted reasoning\noften depends on external experiences and lacks clear principles for selecting\nrepresentative experiences. We address these limitations by proposing CoPS\n(Cross-Task Experience Sharing), a generalizable algorithm that enhances\nsequential reasoning by cross-task experience sharing and selection. In detail,\nCoPS leverages agents' experiences on previous tasks, selecting\ndistribution-matched experiences via a provable pessimism-based strategy to\nmaximize utility while minimizing risks from distribution shifts. Extensive\nexperimental results on benchmarks like Alfworld, Webshop, and HotPotQA\ndemonstrate that CoPS consistently outperforms state-of-the-art baselines, with\nsuperior sample efficiency suitable for resource-constrained scenarios.\nTheoretically, we show that the performance of our algorithm depends on both\nthe quality of the pretrained LLM and the matching between the agent's\ntask-dependent trial distribution and that generated by the LLM. Our work\nbridges the gap between existing sequential reasoning paradigms and validates\nthe effectiveness of leveraging cross-task experiences, shedding light on the\npotential to improve agents' generalization and adaptability across diverse\ntasks. Our codes are available at\n$\\href{https://github.com/uclaml/COPS}{\\text{https://github.com/uclaml/COPS}}$.",
      "tldr_zh": "本研究提出CoPS（Cross-Task Experience Sharing），一种可泛化的算法，用于增强LLM代理的顺序推理，通过跨任务经验共享和选择来解决现有方法的局限性，如Reflection-driven reasoning依赖预训练知识不足和新场景适应差，以及Experience-assisted reasoning缺乏经验选择原则。CoPS采用代理在先前任务上的经验，并通过provable pessimism-based strategy选择分布匹配的经验，以最大化效用并最小化分布偏移风险。在Alfworld、Webshop和HotPotQA等基准测试中，CoPS显著超越最先进基线，具有superior sample efficiency，并理论证明其性能依赖于预训练LLM的质量和任务分布匹配，从而提升代理的泛化和适应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 5 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.16670v1",
      "published_date": "2024-10-22 03:59:53 UTC",
      "updated_date": "2024-10-22 03:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:15:40.917819"
    },
    {
      "arxiv_id": "2410.16668v3",
      "title": "Satori: Towards Proactive AR Assistant with Belief-Desire-Intention User Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Chenyi Li",
        "Guande Wu",
        "Gromit Yeuk-Yin Chan",
        "Dishita G Turakhia",
        "Sonia Castelo Quispe",
        "Dong Li",
        "Leslie Welch",
        "Claudio Silva",
        "Jing Qian"
      ],
      "abstract": "Augmented Reality (AR) assistance is increasingly used for supporting users\nwith physical tasks like assembly and cooking. However, most systems rely on\nreactive responses triggered by user input, overlooking rich contextual and\nuser-specific information. To address this, we present Satori, a novel AR\nsystem that proactively guides users by modeling both -- their mental states\nand environmental contexts. Satori integrates the Belief-Desire-Intention (BDI)\nframework with the state-of-the-art multi-modal large language model (LLM) to\ndeliver contextually appropriate guidance. Our system is designed based on two\nformative studies involving twelve experts. We evaluated the system with a\nsixteen within-subject study and found that Satori matches the performance of\ndesigner-created Wizard-of-Oz (WoZ) systems, without manual configurations or\nheuristics, thereby improving generalizability, reusability, and expanding the\npotential of AR assistance.",
      "tldr_zh": "本研究提出Satori，一种主动式AR（Augmented Reality）助手系统，通过整合Belief-Desire-Intention (BDI)框架与多模态大型语言模型（LLM），来建模用户的心理状态和环境上下文，从而提供更智能的指导。Satori基于两个涉及十二位专家的形式性研究设计而成，与传统反应式AR系统不同，它能主动响应用户需求。实验结果显示，在一个十六人内部受试者研究中，Satori的性能与设计师创建的Wizard-of-Oz (WoZ)系统相当，但无需手动配置或启发式规则，从而提升了系统的泛化性、可重用性和AR助手的整体潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16668v3",
      "published_date": "2024-10-22 03:53:46 UTC",
      "updated_date": "2025-03-31 03:31:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:15:53.291301"
    },
    {
      "arxiv_id": "2410.19009v1",
      "title": "Dual Space Training for GANs: A Pathway to Efficient and Creative Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Beka Modrekiladze"
      ],
      "abstract": "Generative Adversarial Networks (GANs) have demonstrated remarkable\nadvancements in generative modeling; however, their training is often\nresource-intensive, requiring extensive computational time and hundreds of\nthousands of epochs. This paper proposes a novel optimization approach that\ntransforms the training process by operating within a dual space of the initial\ndata using invertible mappings, specifically autoencoders. By training GANs on\nthe encoded representations in the dual space, which encapsulate the most\nsalient features of the data, the generative process becomes significantly more\nefficient and potentially reveals underlying patterns beyond human recognition.\nThis approach not only enhances training speed and resource usage but also\nexplores the philosophical question of whether models can generate insights\nthat transcend the human intelligence while being limited by the\nhuman-generated data.",
      "tldr_zh": "本论文提出了一种双空间训练方法，用于提升 Generative Adversarial Networks (GANs) 的效率和创造性，通过利用 autoencoders 等可逆映射，将数据转换为双空间中的编码表示进行训练，从而捕捉数据的最显著特征。该方法显著减少了训练所需的计算资源和时间，允许 GANs 更快速地生成内容，并可能揭示人类无法识别的底层模式。除了实际改进外，该方法还探讨了模型是否能基于人类生成的数据产生超越人类智能的洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19009v1",
      "published_date": "2024-10-22 03:44:13 UTC",
      "updated_date": "2024-10-22 03:44:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:16:04.782974"
    },
    {
      "arxiv_id": "2410.16662v1",
      "title": "Visual Question Answering in Ophthalmology: A Progressive and Practical Perspective",
      "title_zh": "眼科学中的视觉问答：渐进与实用的视角",
      "authors": [
        "Xiaolan Chen",
        "Ruoyu Chen",
        "Pusheng Xu",
        "Weiyi Zhang",
        "Xianwen Shang",
        "Mingguang He",
        "Danli Shi"
      ],
      "abstract": "Accurate diagnosis of ophthalmic diseases relies heavily on the\ninterpretation of multimodal ophthalmic images, a process often time-consuming\nand expertise-dependent. Visual Question Answering (VQA) presents a potential\ninterdisciplinary solution by merging computer vision and natural language\nprocessing to comprehend and respond to queries about medical images. This\nreview article explores the recent advancements and future prospects of VQA in\nophthalmology from both theoretical and practical perspectives, aiming to\nprovide eye care professionals with a deeper understanding and tools for\nleveraging the underlying models. Additionally, we discuss the promising trend\nof large language models (LLM) in enhancing various components of the VQA\nframework to adapt to multimodal ophthalmic tasks. Despite the promising\noutlook, ophthalmic VQA still faces several challenges, including the scarcity\nof annotated multimodal image datasets, the necessity of comprehensive and\nunified evaluation methods, and the obstacles to achieving effective real-world\napplications. This article highlights these challenges and clarifies future\ndirections for advancing ophthalmic VQA with LLMs. The development of LLM-based\nophthalmic VQA systems calls for collaborative efforts between medical\nprofessionals and AI experts to overcome existing obstacles and advance the\ndiagnosis and care of eye diseases.",
      "tldr_zh": "这篇评论文章探讨了视觉问答（VQA）在眼科领域的应用前景，通过整合计算机视觉和自然语言处理，帮助眼科专业人士更高效地解读多模态眼科图像并回答相关查询。文章从理论和实践角度回顾了VQA的最新进展，并强调大型语言模型（LLM）在增强VQA框架适应多模态眼科任务方面的潜力，同时指出现有挑战，如标注数据集的稀缺、统一的评估方法缺失以及实际应用障碍。未来方向包括通过医务人员和AI专家的合作，推进LLM-based眼科VQA系统的发展，以改善眼病诊断和护理。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16662v1",
      "published_date": "2024-10-22 03:28:41 UTC",
      "updated_date": "2024-10-22 03:28:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:16:16.904739"
    },
    {
      "arxiv_id": "2410.16659v1",
      "title": "RKadiyala at SemEval-2024 Task 8: Black-Box Word-Level Text Boundary Detection in Partially Machine Generated Texts",
      "title_zh": "翻译失败",
      "authors": [
        "Ram Mohan Rao Kadiyala"
      ],
      "abstract": "With increasing usage of generative models for text generation and widespread\nuse of machine generated texts in various domains, being able to distinguish\nbetween human written and machine generated texts is a significant challenge.\nWhile existing models and proprietary systems focus on identifying whether\ngiven text is entirely human written or entirely machine generated, only a few\nsystems provide insights at sentence or paragraph level at likelihood of being\nmachine generated at a non reliable accuracy level, working well only for a set\nof domains and generators. This paper introduces few reliable approaches for\nthe novel task of identifying which part of a given text is machine generated\nat a word level while comparing results from different approaches and methods.\nWe present a comparison with proprietary systems , performance of our model on\nunseen domains' and generators' texts. The findings reveal significant\nimprovements in detection accuracy along with comparison on other aspects of\ndetection capabilities. Finally we discuss potential avenues for improvement\nand implications of our work. The proposed model is also well suited for\ndetecting which parts of a text are machine generated in outputs of Instruct\nvariants of many LLMs.",
      "tldr_zh": "这篇论文针对 SemEval-2024 Task 8，提出了一种 Black-Box 方法，用于在部分机器生成文本中实现词级别文本边界检测，旨在区分人类撰写和机器生成的部分。研究比较了多种方法，包括与专有系统的性能对比，以及模型在未见领域和生成器上的表现，结果显示检测准确率显著提升。最终，论文讨论了改进潜力及其在 Instruct 变体 LLMs 输出中的实际应用前景。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "published at naacl 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.16659v1",
      "published_date": "2024-10-22 03:21:59 UTC",
      "updated_date": "2024-10-22 03:21:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:16:29.180858"
    },
    {
      "arxiv_id": "2410.16655v1",
      "title": "Semantic-guided Search for Efficient Program Repair with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Thanh Le-Cong",
        "Bach Le",
        "Toby Murray"
      ],
      "abstract": "In this paper, we first show that increases in beam size of even just\nsmall-sized LLM (1B-7B parameters) require an extensive GPU resource\nconsumption, leading to up to 80% of recurring crashes due to memory overloads\nin LLM-based APR. Seemingly simple solutions to reduce memory consumption are\n(1) to quantize LLM models, i.e., converting the weights of a LLM from\nhigh-precision values to lower-precision ones. and (2) to make beam search\nsequential, i.e., forwarding each beam through the model sequentially and then\nconcatenate them back into a single model output. However, we show that these\napproaches still do not work via both theoretical analysis and experiments. To\naddress this, we introduce FLAMES, a novel LLM-based APR technique that employs\nsemantic-guided patch generation to enhance repair effectiveness and memory\nefficiency. Unlike conventional methods that rely on beam search, FLAMES\nutilizes greedy decoding to enhance memory efficiency while steering the search\nto more potentially good repair candidates via a semantic-guided best-first\nsearch algorithm. At each decoding step, FLAMES uses semantic feedback from\ntest validation such as the number of passing and failing test cases to select\nthe most promising token to explore further. Our empirical evaluation on the\nDefects4J and HumanEval-Java datasets shows that FLAMES not only substantially\nreduces memory consumption by up to 83% compared to conventional LLM-based APR,\nbut also accelerates the repair process. Remarkably, FLAMES successfully\ngenerated 133 and 103 correct fixes for 333 and 163 bugs in the Defects4J and\nHumanEval-Java datasets, respectively. This suggests that FLAMES is not only\nmore efficient but also outperforms state-of-the-art techniques, fixing at\nleast 10 and 11 more bugs than SOTA baselines in the Defects4J and\nHumanEval-Java datasets, respectively.",
      "tldr_zh": "本文研究了Large Language Models (LLMs)在程序修复(Automated Program Repair, APR)中的内存消耗问题，指出增加beam size会导致GPU资源过度消耗和频繁崩溃，而简单解决方案如量化模型或顺序beam search无效。  \n为此，提出FLAMES，一种新型LLM-based APR技术，通过semantic-guided patch generation、greedy decoding和best-first search算法，利用测试验证的语义反馈（如通过/失败测试用例数量）来选择最有前景的修复候选，从而提升内存效率和修复速度。  \n实验结果显示，FLAMES在Defects4J和HumanEval-Java数据集上减少了高达83%的内存消耗，并修复了133和103个bug，分别比SOTA基准多修复至少10和11个bug，证明了其在效率和性能上的显著优势。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16655v1",
      "published_date": "2024-10-22 02:59:47 UTC",
      "updated_date": "2024-10-22 02:59:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:16:41.468615"
    },
    {
      "arxiv_id": "2410.16653v1",
      "title": "Enhancing Two-Player Performance Through Single-Player Knowledge Transfer: An Empirical Study on Atari 2600 Games",
      "title_zh": "通过单人游戏知识转移提升两人游戏性能：Atari 2600游戏的实证研究",
      "authors": [
        "Kimiya Saadat",
        "Richard Zhao"
      ],
      "abstract": "Playing two-player games using reinforcement learning and self-play can be\nchallenging due to the complexity of two-player environments and the possible\ninstability in the training process. We propose that a reinforcement learning\nalgorithm can train more efficiently and achieve improved performance in a\ntwo-player game if it leverages the knowledge from the single-player version of\nthe same game. This study examines the proposed idea in ten different Atari\n2600 environments using the Atari 2600 RAM as the input state. We discuss the\nadvantages of using transfer learning from a single-player training process\nover training in a two-player setting from scratch, and demonstrate our results\nin a few measures such as training time and average total reward. We also\ndiscuss a method of calculating RAM complexity and its relationship to\nperformance.",
      "tldr_zh": "该研究探讨了通过从单人游戏转移知识来提升双人游戏中强化学习算法的性能问题，以解决双人环境训练的复杂性和不稳定性。研究在十个 Atari 2600 游戏环境中进行实证测试，使用 Atari 2600 RAM 作为输入状态，并比较了转移学习与从零开始训练的优劣。结果显示，转移学习显著缩短了训练时间并提高了平均总奖励。论文还讨论了计算 RAM 复杂度的方法及其对性能的影响。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16653v1",
      "published_date": "2024-10-22 02:57:44 UTC",
      "updated_date": "2024-10-22 02:57:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:16:52.361315"
    },
    {
      "arxiv_id": "2410.16647v1",
      "title": "GE2E-KWS: Generalized End-to-End Training and Evaluation for Zero-shot Keyword Spotting",
      "title_zh": "GE2E-KWS：零样本关键词检测的泛化端到端训练与评估",
      "authors": [
        "Pai Zhu",
        "Jacob W. Bartel",
        "Dhruuv Agarwal",
        "Kurt Partridge",
        "Hyun Jin Park",
        "Quan Wang"
      ],
      "abstract": "We propose GE2E-KWS -- a generalized end-to-end training and evaluation\nframework for customized keyword spotting. Specifically, enrollment utterances\nare separated and grouped by keywords from the training batch and their\nembedding centroids are compared to all other test utterance embeddings to\ncompute the loss. This simulates runtime enrollment and verification stages,\nand improves convergence stability and training speed by optimizing matrix\noperations compared to SOTA triplet loss approaches. To benchmark different\nmodels reliably, we propose an evaluation process that mimics the production\nenvironment and compute metrics that directly measure keyword matching\naccuracy. Trained with GE2E loss, our 419KB quantized conformer model beats a\n7.5GB ASR encoder by 23.6% relative AUC, and beats a same size triplet loss\nmodel by 60.7% AUC. Our KWS models are natively streamable with low memory\nfootprints, and designed to continuously run on-device with no retraining\nneeded for new keywords (zero-shot).",
      "tldr_zh": "本研究提出 GE2E-KWS，一种通用的端到端训练和评估框架，用于零样本关键字检测（zero-shot Keyword Spotting），旨在提升定制关键字识别的效率和准确性。通过将训练批次中的注册语音按关键字分组，并比较其嵌入质心（embedding centroids）与测试语音嵌入来计算损失，该方法模拟运行时的注册和验证阶段，比传统的三元组损失（triplet loss）方法提高了收敛稳定性和训练速度。实验结果显示，使用 GE2E 损失训练的 419KB 量化 Conformer 模型在相对 AUC 上比 7.5GB ASR 编码器提升 23.6%，并比相同大小的三元组损失模型提升 60.7%；此外，该模型支持原生流式处理、低内存占用，并实现零样本新关键字检测，无需重新训练。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "8 pages, 6 figures, 2 tables The paper is accepted in IEEE Spoken\n  Language Technology (SLT) 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.16647v1",
      "published_date": "2024-10-22 02:45:59 UTC",
      "updated_date": "2024-10-22 02:45:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:17:05.086866"
    },
    {
      "arxiv_id": "2410.16645v1",
      "title": "Chatting with Bots: AI, Speech Acts, and the Edge of Assertion",
      "title_zh": "与机器人聊天：AI、言语行为，以及断言的边缘",
      "authors": [
        "Iwan Williams",
        "Tim Bayne"
      ],
      "abstract": "This paper addresses the question of whether large language model-powered\nchatbots are capable of assertion. According to what we call the Thesis of\nChatbot Assertion (TCA), chatbots are the kinds of things that can assert, and\nat least some of the output produced by current-generation chatbots qualifies\nas assertion. We provide some motivation for TCA, arguing that it ought to be\ntaken seriously and not simply dismissed. We also review recent objections to\nTCA, arguing that these objections are weighty. We thus confront the following\ndilemma: how can we do justice to both the considerations for and against TCA?\nWe consider two influential responses to this dilemma - the first appeals to\nthe notion of proxy-assertion; the second appeals to fictionalism - and argue\nthat neither is satisfactory. Instead, reflecting on the ontogenesis of\nassertion, we argue that we need to make space for a category of\nproto-assertion. We then apply the category of proto-assertion to chatbots,\narguing that treating chatbots as proto-assertors provides a satisfactory\nresolution to the dilemma of chatbot assertion.",
      "tldr_zh": "这篇论文探讨了大型语言模型驱动的聊天机器人是否能够进行 assertion，并提出 Thesis of Chatbot Assertion (TCA)，认为聊天机器人能产生断言，且一些输出可视为 assertion。作者审视了支持和反对 TCA 的论点，指出反对意见具有分量，并评估了 proxy-assertion 和 fictionalism 等回应，但认为这些无法充分解决困境。通过反思 assertion 的起源，论文引入 proto-assertion 的概念，将聊天机器人视为 proto-assertors，从而提供了一个平衡的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16645v1",
      "published_date": "2024-10-22 02:45:09 UTC",
      "updated_date": "2024-10-22 02:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:17:16.455241"
    },
    {
      "arxiv_id": "2410.16644v1",
      "title": "CKSP: Cross-species Knowledge Sharing and Preserving for Universal Animal Activity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Axiu Mao",
        "Meilu Zhu",
        "Zhaojin Guo",
        "Zheng He",
        "Tomas Norton",
        "Kai Liu"
      ],
      "abstract": "Deep learning techniques are dominating automated animal activity recognition\n(AAR) tasks with wearable sensors due to their high performance on large-scale\nlabelled data. However, current deep learning-based AAR models are trained\nsolely on datasets of individual animal species, constraining their\napplicability in practice and performing poorly when training data are limited.\nIn this study, we propose a one-for-many framework, dubbed Cross-species\nKnowledge Sharing and Preserving (CKSP), based on sensor data of diverse animal\nspecies. Given the coexistence of generic and species-specific behavioural\npatterns among different species, we design a Shared-Preserved Convolution\n(SPConv) module. This module assigns an individual low-rank convolutional layer\nto each species for extracting species-specific features and employs a shared\nfull-rank convolutional layer to learn generic features, enabling the CKSP\nframework to learn inter-species complementarity and alleviating data\nlimitations via increasing data diversity. Considering the training conflict\narising from discrepancies in data distributions among species, we devise a\nSpecies-specific Batch Normalization (SBN) module, that involves multiple BN\nlayers to separately fit the distributions of different species. To validate\nCKSP's effectiveness, experiments are performed on three public datasets from\nhorses, sheep, and cattle, respectively. The results show that our approach\nremarkably boosts the classification performance compared to the baseline\nmethod (one-for-one framework) solely trained on individual-species data, with\nincrements of 6.04%, 2.06%, and 3.66% in accuracy, and 10.33%, 3.67%, and 7.90%\nin F1-score for the horse, sheep, and cattle datasets, respectively. This\nproves the promising capabilities of our method in leveraging multi-species\ndata to augment classification performance.",
      "tldr_zh": "本文提出 CKSP（Cross-species Knowledge Sharing and Preserving）框架，用于实现通用动物活动识别（AAR），通过跨物种知识共享和保留来克服单一物种数据限制的问题。框架的核心组件包括 Shared-Preserved Convolution (SPConv) 模块，该模块为每个物种分配低秩卷积层提取特定特征，并使用共享全秩卷积层学习通用特征，从而提升物种间互补性和数据多样性；同时，引入 Species-specific Batch Normalization (SBN) 模块来处理不同物种数据分布差异，确保训练稳定性。在马、羊和牛三个公共数据集上的实验表明，CKSP 相较于基线方法（仅用单一物种数据训练）显著提高了性能，准确率分别提升6.04%、2.06%和3.66%，F1 分数分别提升10.33%、3.67%和7.90%。这验证了 CKSP 在利用多物种数据增强分类效果方面的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16644v1",
      "published_date": "2024-10-22 02:44:10 UTC",
      "updated_date": "2024-10-22 02:44:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:17:30.537713"
    },
    {
      "arxiv_id": "2410.16638v3",
      "title": "LLMScan: Causal Scan for LLM Misbehavior Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Mengdi Zhang",
        "Kai Kiat Goh",
        "Peixin Zhang",
        "Jun Sun",
        "Rose Lin Xin",
        "Hongyu Zhang"
      ],
      "abstract": "Despite the success of Large Language Models (LLMs) across various fields,\ntheir potential to generate untruthful, biased and harmful responses poses\nsignificant risks, particularly in critical applications. This highlights the\nurgent need for systematic methods to detect and prevent such misbehavior.\nWhile existing approaches target specific issues such as harmful responses,\nthis work introduces LLMScan, an innovative LLM monitoring technique based on\ncausality analysis, offering a comprehensive solution. LLMScan systematically\nmonitors the inner workings of an LLM through the lens of causal inference,\noperating on the premise that the LLM's `brain' behaves differently when\nmisbehaving. By analyzing the causal contributions of the LLM's input tokens\nand transformer layers, LLMScan effectively detects misbehavior. Extensive\nexperiments across various tasks and models reveal clear distinctions in the\ncausal distributions between normal behavior and misbehavior, enabling the\ndevelopment of accurate, lightweight detectors for a variety of misbehavior\ndetection tasks.",
      "tldr_zh": "本文研究了大型语言模型 (LLMs) 可能生成不真实、偏见和有害响应的风险，并引入 LLMScan，一种基于因果分析 (causal inference) 的创新监控技术，用于全面检测这些错误行为。LLMScan 通过分析输入 tokens 和 transformer layers 的因果贡献，监控 LLM 的内部机制，并假设错误行为时模型行为不同，从而实现精确识别。实验在多种任务和模型上证明了正常行为与错误行为的因果分布存在显著差异，支持了 LLMScan 作为准确、轻量级检测器的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16638v3",
      "published_date": "2024-10-22 02:27:57 UTC",
      "updated_date": "2025-05-18 16:55:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:17:42.557714"
    },
    {
      "arxiv_id": "2410.16633v1",
      "title": "Graph-Structured Trajectory Extraction from Travelogues",
      "title_zh": "翻译失败",
      "authors": [
        "Aitaro Yamamoto",
        "Hiroyuki Otomo",
        "Hiroki Ouchi",
        "Shohei Higashiyama",
        "Hiroki Teranishi",
        "Hiroyuki Shindo",
        "Taro Watanabe"
      ],
      "abstract": "Previous studies on sequence-based extraction of human movement trajectories\nhave an issue of inadequate trajectory representation. Specifically, a pair of\nlocations may not be lined up in a sequence especially when one location\nincludes the other geographically. In this study, we propose a graph\nrepresentation that retains information on the geographic hierarchy as well as\nthe temporal order of visited locations, and have constructed a benchmark\ndataset for graph-structured trajectory extraction. The experiments with our\nbaselines have demonstrated that it is possible to accurately predict visited\nlocations and the order among them, but it remains a challenge to predict the\nhierarchical relations.",
      "tldr_zh": "这篇论文针对传统序列-based轨迹提取方法的不足（如地理包含关系导致位置顺序不准确），提出了一种graph representation方法，能够同时保留访问地点的地理层次信息和temporal order。研究者构建了一个benchmark dataset，用于graph-structured trajectory extraction的评估。实验结果显示，该方法能准确预测访问地点和它们之间的顺序，但预测地理层次关系仍是一个挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16633v1",
      "published_date": "2024-10-22 02:21:42 UTC",
      "updated_date": "2024-10-22 02:21:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:17:53.602336"
    },
    {
      "arxiv_id": "2410.16624v1",
      "title": "EVC-MF: End-to-end Video Captioning Network with Multi-scale Features",
      "title_zh": "翻译失败",
      "authors": [
        "Tian-Zi Niu",
        "Zhen-Duo Chen",
        "Xin Luo",
        "Xin-Shun Xu"
      ],
      "abstract": "Conventional approaches for video captioning leverage a variety of\noffline-extracted features to generate captions. Despite the availability of\nvarious offline-feature-extractors that offer diverse information from\ndifferent perspectives, they have several limitations due to fixed parameters.\nConcretely, these extractors are solely pre-trained on image/video\ncomprehension tasks, making them less adaptable to video caption datasets.\nAdditionally, most of these extractors only capture features prior to the\nclassifier of the pre-training task, ignoring a significant amount of valuable\nshallow information. Furthermore, employing multiple offline-features may\nintroduce redundant information. To address these issues, we propose an\nend-to-end encoder-decoder-based network (EVC-MF) for video captioning, which\nefficiently utilizes multi-scale visual and textual features to generate video\ndescriptions. Specifically, EVC-MF consists of three modules. Firstly, instead\nof relying on multiple feature extractors, we directly feed video frames into a\ntransformer-based network to obtain multi-scale visual features and update\nfeature extractor parameters. Secondly, we fuse the multi-scale features and\ninput them into a masked encoder to reduce redundancy and encourage learning\nuseful features. Finally, we utilize an enhanced transformer-based decoder,\nwhich can efficiently leverage shallow textual information, to generate video\ndescriptions. To evaluate our proposed model, we conduct extensive experiments\non benchmark datasets. The results demonstrate that EVC-MF yields competitive\nperformance compared with the state-of-theart methods.",
      "tldr_zh": "传统视频字幕方法依赖预提取特征，但这些特征存在固定参数、适应性差和冗余问题。为解决这些问题，本文提出一个端到端（end-to-end）网络EVC-MF，它通过基于Transformer的网络提取并更新多尺度（multi-scale）视觉特征，并融合这些特征输入masked encoder以减少冗余。EVC-MF 还使用增强的Transformer-based decoder充分利用浅层文本信息生成视频描述。实验在基准数据集上显示，该模型与最先进方法相比表现出竞争性性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16624v1",
      "published_date": "2024-10-22 02:16:02 UTC",
      "updated_date": "2024-10-22 02:16:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:18:06.662744"
    },
    {
      "arxiv_id": "2411.05010v2",
      "title": "Scattered Forest Search: Smarter Code Space Exploration with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Light",
        "Yue Wu",
        "Yiyou Sun",
        "Wenchao Yu",
        "Yanchi liu",
        "Xujiang Zhao",
        "Ziniu Hu",
        "Haifeng Chen",
        "Wei Cheng"
      ],
      "abstract": "We frame code generation as a black-box optimization problem within the code\nspace and demonstrate how optimization-inspired techniques can enhance\ninference scaling. Based on this perspective, we propose SCATTERED FOREST\nSEARCH (SFS), a novel approach that improves solution diversity and better\nexploits feedback during evolutionary search. Our theoretical analysis\nillustrates how these methods help avoid local optima during optimization,\nleading to more efficient exploration. Extensive experiments on HumanEval,\nMBPP, APPS, CodeContests, and Leetcode reveal significant performance gains.\nFor instance, our method achieves a pass@1 rate of 67.1% on HumanEval+ and\n87.2% on HumanEval with GPT-3.5, marking improvements of 8.6% and 4.3% over the\nstate-of-the-art, while also halving the iterations needed to find the correct\nsolution. Furthermore, our approach scales more efficiently than existing\nsearch techniques, including tree search, line search, and repeated sampling.",
      "tldr_zh": "本研究将代码生成视为代码空间中的黑箱优化问题，并提出 SCATTERED FOREST SEARCH (SFS) 方法，利用优化启发式技术（如进化搜索）来提升 LLMs 的推理扩展能力，从而改善解决方案多样性、更好地利用反馈，并避免局部最优。理论分析表明，该方法能更高效地探索代码空间。实验结果显示，在 HumanEval、MBPP、APPS、CodeContests 和 Leetcode 等基准上，SFS 显著提升性能，例如在 HumanEval+ 上实现 67.1% 的 pass@1 率，比最先进方法高 8.6%，并将迭代次数减半。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "I.2.2; I.2.6; I.2.8; D.2.3; D.2.5; D.1.2; F.2.2; G.1.6"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at ICLR 2025 Conference",
      "pdf_url": "http://arxiv.org/pdf/2411.05010v2",
      "published_date": "2024-10-22 01:58:29 UTC",
      "updated_date": "2025-02-25 03:17:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:18:20.366192"
    },
    {
      "arxiv_id": "2410.16613v1",
      "title": "Real-time Sub-milliwatt Epilepsy Detection Implemented on a Spiking Neural Network Edge Inference Processor",
      "title_zh": "翻译失败",
      "authors": [
        "Ruixin Lia",
        "Guoxu Zhaoa",
        "Dylan Richard Muir",
        "Yuya Ling",
        "Karla Burelo",
        "Mina Khoei",
        "Dong Wang",
        "Yannan Xing",
        "Ning Qiao"
      ],
      "abstract": "Analyzing electroencephalogram (EEG) signals to detect the epileptic seizure\nstatus of a subject presents a challenge to existing technologies aimed at\nproviding timely and efficient diagnosis. In this study, we aimed to detect\ninterictal and ictal periods of epileptic seizures using a spiking neural\nnetwork (SNN). Our proposed approach provides an online and real-time\npreliminary diagnosis of epileptic seizures and helps to detect possible\npathological conditions.To validate our approach, we conducted experiments\nusing multiple datasets. We utilized a trained SNN to identify the presence of\nepileptic seizures and compared our results with those of related studies. The\nSNN model was deployed on Xylo, a digital SNN neuromorphic processor designed\nto process temporal signals. Xylo efficiently simulates spiking leaky\nintegrate-and-fire neurons with exponential input synapses. Xylo has much lower\nenergy requirments than traditional approaches to signal processing, making it\nan ideal platform for developing low-power seizure detection systems.Our\nproposed method has a high test accuracy of 93.3% and 92.9% when classifying\nictal and interictal periods. At the same time, the application has an average\npower consumption of 87.4 uW(IO power) + 287.9 uW(computational power) when\ndeployed to Xylo. Our method demonstrates excellent low-latency performance\nwhen tested on multiple datasets. Our work provides a new solution for seizure\ndetection, and it is expected to be widely used in portable and wearable\ndevices in the future.",
      "tldr_zh": "本研究提出了一种基于脉冲神经网络(SNN)的实时癫痫发作检测方法，能够在线识别interictal和ictal时期，提供及时的初步诊断。模型部署在Xylo数字SNN神经形态处理器上，利用其低能耗特性处理EEG信号，实现高效的信号处理。实验结果显示，检测准确率高达93.3%和92.9%，平均功耗仅为87.4 μW(IO功率) + 287.9 μW(计算功率)，并展现出优秀的低延迟性能，为便携式和可穿戴设备中的癫痫监测提供新解决方案。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "q-bio.NC"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16613v1",
      "published_date": "2024-10-22 01:55:02 UTC",
      "updated_date": "2024-10-22 01:55:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:18:30.486975"
    },
    {
      "arxiv_id": "2410.16606v1",
      "title": "GALA: Graph Diffusion-based Alignment with Jigsaw for Source-free Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Junyu Luo",
        "Yiyang Gu",
        "Xiao Luo",
        "Wei Ju",
        "Zhiping Xiao",
        "Yusheng Zhao",
        "Jingyang Yuan",
        "Ming Zhang"
      ],
      "abstract": "Source-free domain adaptation is a crucial machine learning topic, as it\ncontains numerous applications in the real world, particularly with respect to\ndata privacy. Existing approaches predominantly focus on Euclidean data, such\nas images and videos, while the exploration of non-Euclidean graph data remains\nscarce. Recent graph neural network (GNN) approaches can suffer from serious\nperformance decline due to domain shift and label scarcity in source-free\nadaptation scenarios. In this study, we propose a novel method named Graph\nDiffusion-based Alignment with Jigsaw (GALA), tailored for source-free graph\ndomain adaptation. To achieve domain alignment, GALA employs a graph diffusion\nmodel to reconstruct source-style graphs from target data. Specifically, a\nscore-based graph diffusion model is trained using source graphs to learn the\ngenerative source styles. Then, we introduce perturbations to target graphs via\na stochastic differential equation instead of sampling from a prior, followed\nby the reverse process to reconstruct source-style graphs. We feed the\nsource-style graphs into an off-the-shelf GNN and introduce class-specific\nthresholds with curriculum learning, which can generate accurate and unbiased\npseudo-labels for target graphs. Moreover, we develop a simple yet effective\ngraph-mixing strategy named graph jigsaw to combine confident graphs and\nunconfident graphs, which can enhance generalization capabilities and\nrobustness via consistency learning. Extensive experiments on benchmark\ndatasets validate the effectiveness of GALA.",
      "tldr_zh": "本文提出了一种名为 GALA 的方法，用于源自由域适应（Source-free Domain Adaptation），专注于非欧氏图数据（non-Euclidean graph data），以解决图神经网络（GNN）在领域偏移和标签稀缺场景下的性能下降问题。GALA 利用基于分数的图扩散模型（Graph Diffusion-based Alignment）从目标图数据重建源风格图，并通过随机微分方程引入扰动来生成准确的无偏伪标签，同时引入图拼图（Jigsaw）策略将置信图和不置信图混合，以提升模型的泛化和鲁棒性。实验在基准数据集上验证了 GALA 的有效性，使 GNN 的性能得到显著改善。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "IEEE TPAMI",
      "pdf_url": "http://arxiv.org/pdf/2410.16606v1",
      "published_date": "2024-10-22 01:32:46 UTC",
      "updated_date": "2024-10-22 01:32:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:18:42.914011"
    },
    {
      "arxiv_id": "2410.16600v2",
      "title": "Convex Markov Games: A Framework for Creativity, Imitation, Fairness, and Safety in Multiagent Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ian Gemp",
        "Andreas Haupt",
        "Luke Marris",
        "Siqi Liu",
        "Georgios Piliouras"
      ],
      "abstract": "Behavioral diversity, expert imitation, fairness, safety goals and others\ngive rise to preferences in sequential decision making domains that do not\ndecompose additively across time. We introduce the class of convex Markov games\nthat allow general convex preferences over occupancy measures. Despite infinite\ntime horizon and strictly higher generality than Markov games, pure strategy\nNash equilibria exist. Furthermore, equilibria can be approximated empirically\nby performing gradient descent on an upper bound of exploitability. Our\nexperiments reveal novel solutions to classic repeated normal-form games, find\nfair solutions in a repeated asymmetric coordination game, and prioritize safe\nlong-term behavior in a robot warehouse environment. In the prisoner's dilemma,\nour algorithm leverages transient imitation to find a policy profile that\ndeviates from observed human play only slightly, yet achieves higher per-player\nutility while also being three orders of magnitude less exploitable.",
      "tldr_zh": "本研究引入了Convex Markov Games框架，用于处理多智能体学习中的非加性偏好，如行为多样性、专家模仿、公平性和安全目标。该框架允许在占用措施上定义一般凸偏好，并证明了尽管存在无限时间horizon且比Markov Games更通用，纯策略Nash Equilibria仍然存在，可通过对exploitability上界的梯度下降进行经验近似。实验结果显示，该框架在经典重复正规形式游戏中发现新解、在不对称协调游戏中实现公平解决方案，并在机器人仓库环境中优先安全长期行为；特别是在囚徒困境中，算法通过暂时的模仿获得策略组合，仅轻微偏离人类游戏，却提升了每玩家效用并将exploitable降低了三个数量级。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16600v2",
      "published_date": "2024-10-22 00:55:04 UTC",
      "updated_date": "2025-01-16 16:42:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:20:48.407868"
    },
    {
      "arxiv_id": "2410.16593v3",
      "title": "Graph Sampling for Scalable and Expressive Graph Neural Networks on Homophilic Graphs",
      "title_zh": "针对同质图的可扩展和高表现力图神经网络的图采样",
      "authors": [
        "Haolin Li",
        "Haoyu Wang",
        "Luana Ruiz"
      ],
      "abstract": "Graph Neural Networks (GNNs) excel in many graph machine learning tasks but\nface challenges when scaling to large networks. GNN transferability allows\ntraining on smaller graphs and applying the model to larger ones, but existing\nmethods often rely on random subsampling, leading to disconnected subgraphs and\nreduced model expressivity. We propose a novel graph sampling algorithm that\nleverages feature homophily to preserve graph structure. By minimizing the\ntrace of the data correlation matrix, our method better preserves the graph\nLaplacian trace -- a proxy for the graph connectivity -- than random sampling,\nwhile achieving lower complexity than spectral methods. Experiments on citation\nnetworks show improved performance in preserving Laplacian trace and GNN\ntransferability compared to random sampling.",
      "tldr_zh": "本论文针对图神经网络（GNNs）在处理大规模同质图（homophilic graphs）时的扩展挑战，提出了一种新型图采样算法，以提升模型的可扩展性和表现力。该算法利用特征同质性（feature homophily）来保留图结构，通过最小化数据相关矩阵的迹（trace of the data correlation matrix），从而更好地维护图拉普拉斯矩阵的迹（graph Laplacian trace）作为图连通性的代理。与随机采样相比，该方法在复杂度上低于谱方法，同时提高了图结构的完整性。在引用网络的实验中，该算法在保留拉普拉斯矩阵迹和GNNs迁移性方面表现出色，性能优于基线方法。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16593v3",
      "published_date": "2024-10-22 00:30:31 UTC",
      "updated_date": "2025-03-27 21:40:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:19:06.706739"
    },
    {
      "arxiv_id": "2410.16589v1",
      "title": "Dynamic Adaptive Rank Space Exploration for Efficient Sentiment Analysis with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hongcheng Ding",
        "Fuzhen Hu",
        "Xuanze Zhao",
        "Zixiao Jiang",
        "Shamsul Nahar Abdullah",
        "Deshinta Arrova Dewi"
      ],
      "abstract": "Sentiment analysis has become increasingly important for assessing public\nopinion and informing decision-making. Large language models (LLMs) have\nrevolutionized this field by capturing nuanced language patterns. However,\nadapting LLMs to domain-specific sentiment analysis tasks remains challenging\ndue to computational constraints and the need for optimal fine-tuning. To\naddress these challenges, we propose a novel Dynamic Adaptive Rank Space\nExploration (DARSE) framework for efficient and effective sentiment analysis\nusing LLMs. DARSE consists of a coarse-grained greedy algorithm to identify the\noptimal rank range, a fine-grained exploration algorithm to refine rank\nselection, and a dynamic rank allocation method to determine the optimal rank\ncombination for each LLM layer. Extensive experiments demonstrate that DARSE\nsignificantly improves sentiment analysis accuracy, achieving a 15.1%\nimprovement in MSE and a 4.3% improvement in accuracy compared to previous\nwork. Our framework strikes a balance between computational efficiency and\nmodel performance, making it a promising approach for sentiment analysis with\nLLMs.",
      "tldr_zh": "该论文提出了一种Dynamic Adaptive Rank Space Exploration (DARSE)框架，以提升Large Language Models (LLMs)在情感分析中的效率和效果，解决计算约束和最佳微调挑战。DARSE框架包括粗粒度贪婪算法识别最佳秩范围、细粒度探索算法精炼秩选择，以及动态秩分配方法为每个LLM层确定最优组合。通过广泛实验，该框架显著提高了情感分析性能，比现有方法改善了15.1%的MSE和4.3%的准确率。该方法在计算效率与模型表现之间实现了有效平衡。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16589v1",
      "published_date": "2024-10-22 00:14:36 UTC",
      "updated_date": "2024-10-22 00:14:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:19:18.236881"
    },
    {
      "arxiv_id": "2410.16586v1",
      "title": "Optimizing LLMs with Direct Preferences: A Data Efficiency Perspective",
      "title_zh": "使用直接偏好优化 LLMs：数据效率视角",
      "authors": [
        "Pietro Bernardelle",
        "Gianluca Demartini"
      ],
      "abstract": "Aligning the output of Large Language Models (LLMs) with human preferences\n(e.g., by means of reinforcement learning with human feedback, or RLHF) is\nessential for ensuring their effectiveness in real-world scenarios. Despite\nsignificant advancements in LLM alignment techniques, the impact of different\ntype of preference data on model performance has yet to be systematically\nexplored. In this study, we investigate the scalability, data efficiency, and\neffectiveness of Direct Preference Optimization (DPO) in fine-tuning\npre-trained LLMs, aiming to reduce their dependency on extensive amounts of\npreference data, which is expensive to collect. We (1) systematically compare\nthe performance of models fine-tuned with varying percentages of a combined\npreference judgement dataset to define the improvement curve of DPO and assess\nits effectiveness in data-constrained environments; and (2) provide insights\nfor the development of an optimal approach for selective preference data usage.\nOur study reveals that increasing the amount of data used for training\ngenerally enhances and stabilizes model performance. Moreover, the use of a\ncombination of diverse datasets significantly improves model effectiveness.\nFurthermore, when models are trained separately using different types of\nprompts, models trained with conversational prompts outperformed those trained\nwith question answering prompts.",
      "tldr_zh": "本研究探讨了使用直接偏好优化(DPO)微调大语言模型(LLMs)的可扩展性和数据效率，旨在减少对昂贵偏好数据的依赖。研究者系统比较了不同比例的组合偏好数据集对模型性能的影响，并评估了DPO在数据有限环境中的有效性。结果显示，增加数据量能提升并稳定模型表现，使用多样数据集显著改善效果；此外，使用对话式提示训练的模型优于问答式提示训练的模型。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16586v1",
      "published_date": "2024-10-22 00:11:41 UTC",
      "updated_date": "2024-10-22 00:11:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:19:30.021723"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 130,
  "processed_papers_count": 130,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T15:21:36.251697"
}