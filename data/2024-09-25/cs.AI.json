{
  "date": "2024-09-25",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-25 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 141 篇论文，主要聚焦 AI 模型优化（如 LLM 在复杂任务中的应用）、医疗诊断、强化学习和量子计算等领域，令人印象深刻的包括 LLM 增强的复杂问题解决框架（如 Wenlin Yao 的 HDFlow）和医疗 AI 模型（如用于 ECG 图像分析），这些工作展示了 AI 在实际应用中的潜力。\n\n### 重点论文讨论\n我们先聊聊今天最重要和有话题度的论文，这些多涉及 AI 核心技术创新、医疗应用和高效模型设计。相关论文按主题归类，便于理解。\n\n#### LLM 和 AI 模型优化\n- **HDFlow: Enhancing LLM Complex Problem-Solving with Hybrid Thinking and Dynamic Workflows**（HDFlow: 使用混合思考和动态工作流增强 LLM 的复杂问题解决）  \n  Wenlin Yao 等人的工作提出了一种新型框架 HDFlow，通过结合快速和缓慢思考模式（如动态工作流分解子任务），显著提升了 LLM 在多步推理任务上的性能。实验显示，它在四个基准数据集上优于 Chain-of-Thought 方法，并为开源模型的复杂推理能力提供了高效微调策略。\n\n- **Proof of Thought: Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning**（Proof of Thought: 神经符号程序合成实现鲁棒且可解释的推理）  \n  Debargha Ganguly 等提出了一种将 LLM 生成的想法与形式逻辑验证相结合的框架，使用 JSON 语言桥接 LLM 和定理证明器。该方法在 StrategyQA 等基准上提升了性能，并为高风险领域的人机协作提供可解释性。\n\n- **Search for Efficient Large Language Models**（搜索高效的大型语言模型）  \n  Xuan Shen 等开发了一种无训练架构搜索框架，优化 LLM 子网络以减少计算资源，同时通过校准数据微调提升性能。在标准基准上，它优于现有剪枝方法，并为 LLM 部署提供了实用优化路径。\n\n- **Programming Every Example: Lifting Pre-training Data Quality Like Experts at Scale**（Programming Every Example: 像专家一样提升预训练数据质量）  \n  Fan Zhou 等使用小语言模型自动优化数据质量，通过针对每个样本的细粒度操作生成高质量数据集。实验显示，它在多个基准上提升了下游任务性能，并为高效 LLM 预训练提供了新路径。\n\n- **Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification**（通过简单参数高效修改微调视觉-语言模型）  \n  Ming Li 等提出 ClipFit 方法，仅微调特定参数（如偏置和归一化层），无需额外参数开销。结果显示，它在零样本任务上提升了 7.27% 的准确率，强调了经典微调在 VLMs 中的潜力。\n\n这些 LLM 相关论文突出了模型在推理和高效部署方面的进步，Wenlin Yao 和 Dong Yu 等学者的参与增加了其影响力。其他 LLM 优化论文（如基于提示的指标或生成模型）则快速掠过，因为它们更注重特定应用而非核心创新。\n\n#### 医疗和生物应用\n- **AI Enabled Neutron Flux Measurement and Virtual Calibration in Boiling Water Reactors**（AI 启用沸水反应堆中的中子通量测量和虚拟校准）  \n  Anirudh Tunga 等使用深度神经网络（如 SurrogateNet 和 LPRMNet）实现中子通量精确测量，测试误差低至 1-3%。这为核反应堆安全监控提供了高效工具，提升了在线测量精度。\n\n- **DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data**（DRIM: 从不完整的多模态医疗数据中学习分离表示）  \n  Lucas Robinet 等提出一种框架，从不完整医疗数据（如影像和基因数据）中提取共享和独特表示，应用于胶质瘤生存预测。实验显示，它在缺失模态下保持鲁棒性，为多模态医疗 AI 提供了新方法。\n\n- **CasFT: Future Trend Modeling for Information Popularity Prediction with Dynamic Cues-Driven Diffusion Models**（CasFT: 使用动态线索驱动扩散模型的未来趋势建模）  \n  Xin Jing 等开发了一种扩散模型框架，通过神经 ODE 捕捉信息扩散动态，预测内容流行趋势。在真实数据集上，它比 SOTA 方法提升 2.2%-19.3%，为医疗信息传播预测提供了实用工具。\n\n这些医疗论文强调 AI 在诊断和预测中的作用，具有高话题度，因为它们直接影响实际应用，如癌症检测和反应堆安全。\n\n#### 机器人和强化学习\n- **Go-SLAM: Grounded Object Segmentation and Localization with Gaussian Splatting SLAM**（Go-SLAM: 使用高斯散射 SLAM 的物体分割和定位）  \n  Phu Pham 等提出一种 SLAM 方法，结合物体分割和自然语言查询，实现机器人路径规划。实验显示，它在复杂环境中提升了准确性，为机器人导航提供了多模态交互框架。\n\n- **GemFilter: Accelerating Long-Context LLMs with 1000x Input Token Reduction**（GemFilter: 通过 1000 倍输入标记减少加速长上下文 LLM）  \n  Zhenmei Shi 等设计了一种算法，使用 LLM 早期层过滤无关标记，减少计算资源。在长序列任务上，它比 SOTA 方法快 2.4 倍，并保持性能，为高效机器人决策提供了基础。\n\n这些机器人论文展示了强化学习在动态环境中的潜力，相关工作（如多机器人导航）快速提一下，因为它们更侧重技术细节而非突破。\n\n### 其他论文快速掠过\n今天还有许多论文涉及量子计算（如 Quantum-Classical AI）、图像生成（如 MambaJSCC）和数据增强（如 TSBP），但这些相对常规或领域特定，我们仅简要提及：例如，Quantum-Classical AI 探索了量子模型在欺诈检测中的双重作用，而 MambaJSCC 优化了图像传输效率。这些工作虽有贡献，但影响力不如上述重点论文，故不展开讨论。\n\n总之，今天的 arXiv 更新突显了 AI 在实际应用中的进展，LLM 和医疗领域的创新特别值得关注。读者可根据兴趣优先查看 HDFlow 和 DRIM 等论文，以获取更多细节。保持关注，AI 领域日新月异！",
  "papers": [
    {
      "arxiv_id": "2409.17433v1",
      "title": "HDFlow: Enhancing LLM Complex Problem-Solving with Hybrid Thinking and Dynamic Workflows",
      "title_zh": "HDFlow：通过混合思维和动态工作流增强LLM复杂问题解决",
      "authors": [
        "Wenlin Yao",
        "Haitao Mi",
        "Dong Yu"
      ],
      "abstract": "Despite recent advancements in large language models (LLMs), their\nperformance on complex reasoning problems requiring multi-step thinking and\ncombining various skills is still limited. To address this, we propose a novel\nframework HDFlow for complex reasoning with LLMs that combines fast and slow\nthinking modes in an adaptive manner. Our approach consists of two key\ncomponents: 1) a new approach for slow, deliberate reasoning called Dynamic\nWorkflow, which automatically decomposes complex problems into more manageable\nsub-tasks and dynamically designs a workflow to assemble specialized LLM or\nsymbolic reasoning tools to solve sub-tasks; 2) Hybrid Thinking, a general\nframework that dynamically combines fast and slow thinking based on problem\ncomplexity. Finally, we propose an easy-to-scale method for automatically\nsynthesizing a large-scale dataset of 27K challenging reasoning problems for\ncomplex reasoning and a hybrid thinking tuning method that trains smaller LLMs\non this dataset to internalize the fast/slow hybrid reasoning strategies.\nExperiments on four reasoning benchmark datasets demonstrate that our slow\nthinking with dynamic workflows significantly outperforms Chain-of-Thought, and\nhybrid thinking achieves the highest accuracy while providing an effective\nbalance between computational efficiency and performance. Fine-tuning using our\nhybrid thinking approach also significantly boosts the complex reasoning\ncapabilities of open-source language models. The results showcase the promise\nof slow thinking, dynamic workflows, and hybrid thinking in expanding the\nfrontier of complex problem-solving with LLMs\\footnote{Code and data will be\nreleased at \\url{https://github.com/wenlinyao/HDFlow}.}.",
      "tldr_zh": "该论文提出HDFlow框架，以提升大型语言模型(LLMs)在复杂推理问题上的性能，通过动态结合快速思考(fast thinking)和缓慢思考(slow thinking)模式。框架的核心组件包括Dynamic Workflow，它自动分解复杂问题为子任务并设计工作流使用专用LLM或符号推理工具，以及Hybrid Thinking，它根据问题复杂度自适应整合两种思考方式。此外，论文开发了27K挑战性推理数据集和混合思考调优方法，实验在四个基准数据集上显示，Dynamic Workflow显著优于Chain-of-Thought，而Hybrid Thinking实现了最高准确率，并平衡了计算效率和性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "27 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.17433v1",
      "published_date": "2024-09-25 23:52:17 UTC",
      "updated_date": "2024-09-25 23:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:26:52.649956"
    },
    {
      "arxiv_id": "2409.17426v1",
      "title": "Exploring the Use of ChatGPT for a Systematic Literature Review: a Design-Based Research",
      "title_zh": "翻译失败",
      "authors": [
        "Qian Huang",
        "Qiyun Wang"
      ],
      "abstract": "ChatGPT has been used in several educational contexts,including learning,\nteaching and research. It also has potential to conduct the systematic\nliterature review (SLR). However, there are limited empirical studies on how to\nuse ChatGPT in conducting a SLR. Based on a SLR published,this study used\nChatGPT to conduct a SLR of the same 33 papers in a design-based approach, to\nsee what the differences are by comparing the reviews' results,and to answer:\nTo what extent can ChatGPT conduct SLR? What strategies can human researchers\nutilize to structure prompts for ChatGPT that enhance the reliability and\nvalidity of a SLR? This study found that ChatGPT could conduct a SLR. It needs\ndetailed and accurate prompts to analyze the literature. It also has\nlimitations. Guiding principles are summarized from this study for researchers\nto follow when they need to conduct SLRs using ChatGPT.",
      "tldr_zh": "这篇论文探讨了 ChatGPT 在系统文献综述 (SLR) 中的应用，通过设计-based 研究方法，使用 ChatGPT 对一组相同的 33 篇论文进行重复 SLR，并与现有结果进行比较。研究发现，ChatGPT 能够基本完成 SLR，但需要详细准确的提示来提升其可靠性和有效性，同时它也存在局限性，如分析深度和准确性不足。论文总结了指导原则，帮助人类研究者优化提示结构，以更好地利用 ChatGPT 进行文献综述。",
      "categories": [
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 13 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.17426v1",
      "published_date": "2024-09-25 23:29:19 UTC",
      "updated_date": "2024-09-25 23:29:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:27:02.675040"
    },
    {
      "arxiv_id": "2409.17422v1",
      "title": "Discovering the Gems in Early Layers: Accelerating Long-Context LLMs with 1000x Input Token Reduction",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenmei Shi",
        "Yifei Ming",
        "Xuan-Phi Nguyen",
        "Yingyu Liang",
        "Shafiq Joty"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nhandling long context inputs, but this comes at the cost of increased\ncomputational resources and latency. Our research introduces a novel approach\nfor the long context bottleneck to accelerate LLM inference and reduce GPU\nmemory consumption. Our research demonstrates that LLMs can identify relevant\ntokens in the early layers before generating answers to a query. Leveraging\nthis insight, we propose an algorithm that uses early layers of an LLM as\nfilters to select and compress input tokens, significantly reducing the context\nlength for subsequent processing. Our method, GemFilter, demonstrates\nsubstantial improvements in both speed and memory efficiency compared to\nexisting techniques, such as standard attention and SnapKV/H2O. Notably, it\nachieves a 2.4$\\times$ speedup and 30\\% reduction in GPU memory usage compared\nto SOTA methods. Evaluation on the Needle in a Haystack task shows that\nGemFilter significantly outperforms standard attention, SnapKV and demonstrates\ncomparable performance on the LongBench challenge. GemFilter is simple,\ntraining-free, and broadly applicable across different LLMs. Crucially, it\nprovides interpretability by allowing humans to inspect the selected input\nsequence. These findings not only offer practical benefits for LLM deployment,\nbut also enhance our understanding of LLM internal mechanisms, paving the way\nfor further optimizations in LLM design and inference. Our code is available at\n\\url{https://github.com/SalesforceAIResearch/GemFilter}.",
      "tldr_zh": "该研究解决了大型语言模型（LLMs）处理长上下文输入时面临的计算资源和延迟问题，提出了一种名为 GemFilter 的新算法，利用模型早期层来识别和压缩相关 tokens，实现高达 1000 倍的输入 token 减少。GemFilter 通过早期层作为过滤器选择关键信息，显著提升推理速度和内存效率，与现有方法如标准 attention 和 SnapKV/H2O 相比，实现了 2.4 倍加速和 30% 的 GPU 内存降低，并在 Needle in a Haystack 任务上表现出色，同时在 LongBench 挑战中保持可比性能。该方法简单、无需训练、适用于多种 LLMs，并提供可解释性，帮助理解 LLM 内部机制，并为模型部署和优化带来实际益处。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17422v1",
      "published_date": "2024-09-25 23:14:47 UTC",
      "updated_date": "2024-09-25 23:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:27:16.095915"
    },
    {
      "arxiv_id": "2409.17421v1",
      "title": "Solar Active Regions Emergence Prediction Using Long Short-Term Memory Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Spiridon Kasapis",
        "Irina N. Kitiashvili",
        "Alexander G. Kosovichev",
        "John T. Stefan"
      ],
      "abstract": "We developed Long Short-Term Memory (LSTM) models to predict the formation of\nactive regions (ARs) on the solar surface. Using the Doppler shift velocity,\nthe continuum intensity, and the magnetic field observations from the Solar\nDynamics Observatory (SDO) Helioseismic and Magnetic Imager (HMI), we have\ncreated time-series datasets of acoustic power and magnetic flux, which are\nused to train LSTM models on predicting continuum intensity, 12 hours in\nadvance. These novel machine learning (ML) models are able to capture\nvariations of the acoustic power density associated with upcoming magnetic flux\nemergence and continuum intensity decrease. Testing of the models' performance\nwas done on data for 5 ARs, unseen from the models during training. Model 8,\nthe best performing model trained, was able to make a successful prediction of\nemergence for all testing active regions in an experimental setting and three\nof them in an operational. The model predicted the emergence of AR11726,\nAR13165, and AR13179 respectively 10, 29, and 5 hours in advance, and\nvariations of this model achieved average RMSE values of 0.11 for both active\nand quiet areas on the solar disc. This work sets the foundations for ML-aided\nprediction of solar ARs.",
      "tldr_zh": "本文使用 Long Short-Term Memory (LSTM) 网络预测太阳表面活跃区域 (ARs) 的形成，基于 Solar Dynamics Observatory (SDO) Helioseismic and Magnetic Imager (HMI) 的 Doppler shift velocity、continuum intensity 和 magnetic field 数据创建时间序列数据集。模型通过训练捕捉 acoustic power density 和 magnetic flux emergence 的变化，能够提前 12 小时预测 continuum intensity 减少，并在 5 个未见 ARs 的测试中表现出色，最佳 Model 8 成功预测所有区域的 emergence，平均 Root Mean Square Error (RMSE) 为 0.11。该研究为机器学习 (ML) 辅助太阳 ARs 预测奠定了基础。",
      "categories": [
        "astro-ph.SR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.SR",
      "comment": "20 pages, 8 figures, 5 tables, under review at the AAS Astrophysical\n  Journal",
      "pdf_url": "http://arxiv.org/pdf/2409.17421v1",
      "published_date": "2024-09-25 23:09:46 UTC",
      "updated_date": "2024-09-25 23:09:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:27:29.910840"
    },
    {
      "arxiv_id": "2409.17416v1",
      "title": "From Deception to Detection: The Dual Roles of Large Language Models in Fake News",
      "title_zh": "从欺骗到检测：大语言模型在假新闻中的双重角色",
      "authors": [
        "Dorsaf Sallami",
        "Yuan-Chen Chang",
        "Esma Aïmeur"
      ],
      "abstract": "Fake news poses a significant threat to the integrity of information\necosystems and public trust. The advent of Large Language Models (LLMs) holds\nconsiderable promise for transforming the battle against fake news. Generally,\nLLMs represent a double-edged sword in this struggle. One major concern is that\nLLMs can be readily used to craft and disseminate misleading information on a\nlarge scale. This raises the pressing questions: Can LLMs easily generate\nbiased fake news? Do all LLMs have this capability? Conversely, LLMs offer\nvaluable prospects for countering fake news, thanks to their extensive\nknowledge of the world and robust reasoning capabilities. This leads to other\ncritical inquiries: Can we use LLMs to detect fake news, and do they outperform\ntypical detection models? In this paper, we aim to address these pivotal\nquestions by exploring the performance of various LLMs. Our objective is to\nexplore the capability of various LLMs in effectively combating fake news,\nmarking this as the first investigation to analyze seven such models. Our\nresults reveal that while some models adhere strictly to safety protocols,\nrefusing to generate biased or misleading content, other models can readily\nproduce fake news across a spectrum of biases. Additionally, our results show\nthat larger models generally exhibit superior detection abilities and that\nLLM-generated fake news are less likely to be detected than human-written ones.\nFinally, our findings demonstrate that users can benefit from LLM-generated\nexplanations in identifying fake news.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs)在假新闻中的双重角色：一方面，LLMs可能被用于生成偏见和误导性内容，研究发现某些模型能轻松创建假新闻，而其他模型则遵守安全协议拒绝此行为。另一方面，论文评估了七个LLMs在检测假新闻方面的性能，结果显示较大模型表现出色，且LLMs生成的假新闻比人类写的更难被识别。最终，研究表明，LLMs提供的解释能帮助用户更有效地辨别假新闻，从而为对抗假新闻提供新策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17416v1",
      "published_date": "2024-09-25 22:57:29 UTC",
      "updated_date": "2024-09-25 22:57:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:27:39.627077"
    },
    {
      "arxiv_id": "2409.17411v3",
      "title": "Exploring Semantic Clustering in Deep Reinforcement Learning for Video Games",
      "title_zh": "在深度强化学习中探索视频游戏的语义聚类",
      "authors": [
        "Liang Zhang",
        "Justin Lieffers",
        "Adarsh Pyarelal"
      ],
      "abstract": "In this paper, we investigate the semantic clustering properties of deep\nreinforcement learning (DRL) for video games, enriching our understanding of\nthe internal dynamics of DRL and advancing its interpretability. In this\ncontext, semantic clustering refers to the inherent capacity of neural networks\nto internally group video inputs based on semantic similarity. To achieve this,\nwe propose a novel DRL architecture that integrates a semantic clustering\nmodule featuring both feature dimensionality reduction and online clustering.\nThis module seamlessly integrates into the DRL training pipeline, addressing\ninstability issues observed in previous t-SNE-based analysis methods and\neliminating the necessity for extensive manual annotation of semantic analysis.\nThrough experiments, we validate the effectiveness of the proposed module and\nthe semantic clustering properties in DRL for video games. Additionally, based\non these properties, we introduce new analytical methods to help understand the\nhierarchical structure of policies and the semantic distribution within the\nfeature space.",
      "tldr_zh": "本论文探讨了深度强化学习 (DRL) 在视频游戏中的语义聚类特性，以加深对 DRL 内部动态的理解并提升其可解释性。研究提出了一种新型 DRL 架构，集成了语义聚类模块，包括特征维度减少和在线聚类，该模块无缝融入 DRL 训练管道中，解决了以往基于 t-SNE 方法的不稳定性问题，并消除了对语义分析的大量手动标注需求。通过实验验证，该模块的有效性得到证实，并基于语义聚类特性引入新分析方法，帮助理解策略的层次结构和特征空间中的语义分布。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17411v3",
      "published_date": "2024-09-25 22:48:14 UTC",
      "updated_date": "2024-10-01 02:54:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:27:51.337672"
    },
    {
      "arxiv_id": "2409.17408v2",
      "title": "Sociotechnical Approach to Enterprise Generative Artificial Intelligence (E-GenAI)",
      "title_zh": "翻译失败",
      "authors": [
        "Leoncio Jimenez",
        "Francisco Venegas"
      ],
      "abstract": "In this theoretical article, a sociotechnical approach is proposed to\ncharacterize. First, the business ecosystem, focusing on the relationships\namong Providers, Enterprise, and Customers through SCM, ERP, and CRM platforms\nto align: (1) Business Intelligence (BI), Fuzzy Logic (FL), and TRIZ (Theory of\nInventive Problem Solving), through the OID model, and (2) Knowledge Management\n(KM) and Imperfect Knowledge Management (IKM), through the OIDK model. Second,\nthe article explores the E-GenAI business ecosystem, which integrates\nGenAI-based platforms for SCM, ERP, and CRM with GenAI-based platforms for BI,\nFL, TRIZ, KM, and IKM, to align Large Language Models (LLMs) through the\nE-GenAI (OID) model. Finally, to understand the dynamics of LLMs, we utilize\nfinite automata to model the relationships between Followers and Followees.\nThis facilitates the construction of LLMs that can identify specific\ncharacteristics of users on a social media platform.",
      "tldr_zh": "这篇理论文章提出了一种社会技术方法来表征企业生成式人工智能（E-GenAI），聚焦于业务生态系统，通过 SCM、ERP 和 CRM 平台对齐 Business Intelligence (BI)、Fuzzy Logic (FL) 和 TRIZ 等技术，以及 Knowledge Management (KM) 和 Imperfect Knowledge Management (IKM) 通过 OID 和 OIDK 模型。文章进一步探讨了 E-GenAI 业务生态系统，将 GenAI 整合到这些平台中，并通过 E-GenAI (OID) 模型对齐 Large Language Models (LLMs)。最终，利用有限自动机建模社交媒体上 Followers 和 Followees 的关系，以帮助构建能识别用户特定特征的 LLMs，从而提升企业 AI 的动态理解和应用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17408v2",
      "published_date": "2024-09-25 22:39:55 UTC",
      "updated_date": "2025-01-31 12:19:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:28:15.118708"
    },
    {
      "arxiv_id": "2409.17407v1",
      "title": "Post-hoc Reward Calibration: A Case Study on Length Bias",
      "title_zh": "事后奖励校准：关于长度偏差的案例研究",
      "authors": [
        "Zeyu Huang",
        "Zihan Qiu",
        "Zili Wang",
        "Edoardo M. Ponti",
        "Ivan Titov"
      ],
      "abstract": "Reinforcement Learning from Human Feedback aligns the outputs of Large\nLanguage Models with human values and preferences. Central to this process is\nthe reward model (RM), which translates human feedback into training signals\nfor optimising LLM behaviour. However, RMs can develop biases by exploiting\nspurious correlations in their training data, such as favouring outputs based\non length or style rather than true quality. These biases can lead to incorrect\noutput rankings, sub-optimal model evaluations, and the amplification of\nundesirable behaviours in LLMs alignment. This paper addresses the challenge of\ncorrecting such biases without additional data and training, introducing the\nconcept of Post-hoc Reward Calibration. We first propose an intuitive approach\nto estimate the bias term and, thus, remove it to approximate the underlying\ntrue reward. We then extend the approach to a more general and robust form with\nthe Locally Weighted Regression. Focusing on the prevalent length bias, we\nvalidate our proposed approaches across three experimental settings,\ndemonstrating consistent improvements: (1) a 3.11 average performance gain\nacross 33 reward models on the RewardBench dataset; (2) enhanced alignment of\nRM rankings with GPT-4 evaluations and human preferences based on the\nAlpacaEval benchmark; and (3) improved Length-Controlled win rate of the RLHF\nprocess in multiple LLM--RM combinations. Our method is computationally\nefficient and generalisable to other types of bias and RMs, offering a scalable\nand robust solution for mitigating biases in LLM alignment. Our code and\nresults are available at https://github.com/ZeroYuHuang/Reward-Calibration.",
      "tldr_zh": "这篇论文探讨了 Reinforcement Learning from Human Feedback (RLHF) 中 Reward Model (RM) 的偏差问题，特别是长度偏差导致的输出排名错误和模型优化不佳。作者引入了 Post-hoc Reward Calibration 方法，通过估计并移除偏差（如使用 Locally Weighted Regression），无需额外数据和训练来校正 RM。实验验证显示，该方法在 RewardBench 数据集上使 33 个 RM 平均性能提升 3.11%，并在 AlpacaEval 基准上改善了 RM 排名与 GPT-4 及人类偏好的 alignment，同时提升了 RLHF 过程中的 Length-Controlled win rate。该方法计算高效且可扩展到其他偏差类型，为 LLM 校准提供了一个鲁棒解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2409.17407v1",
      "published_date": "2024-09-25 22:30:42 UTC",
      "updated_date": "2024-09-25 22:30:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:28:17.915738"
    },
    {
      "arxiv_id": "2409.17405v1",
      "title": "AI Enabled Neutron Flux Measurement and Virtual Calibration in Boiling Water Reactors",
      "title_zh": "AI 赋能的中子通量测量和虚拟校准在沸水反应堆中",
      "authors": [
        "Anirudh Tunga",
        "Jordan Heim",
        "Michael Mueterthies",
        "Thomas Gruenwald",
        "Jonathan Nistor"
      ],
      "abstract": "Accurately capturing the three dimensional power distribution within a\nreactor core is vital for ensuring the safe and economical operation of the\nreactor, compliance with Technical Specifications, and fuel cycle planning\n(safety, control, and performance evaluation). Offline (that is, during cycle\nplanning and core design), a three dimensional neutronics simulator is used to\nestimate the reactor's power, moderator, void, and flow distributions, from\nwhich margin to thermal limits and fuel exposures can be approximated. Online,\nthis is accomplished with a system of local power range monitors (LPRMs)\ndesigned to capture enough neutron flux information to infer the full nodal\npower distribution. Certain problems with this process, ranging from\nmeasurement and calibration to the power adaption process, pose challenges to\noperators and limit the ability to design reload cores economically (e.g.,\nengineering in insufficient margin or more margin than required). Artificial\nintelligence (AI) and machine learning (ML) are being used to solve the\nproblems to reduce maintenance costs, improve the accuracy of online local\npower measurements, and decrease the bias between offline and online power\ndistributions, thereby leading to a greater ability to design safe and\neconomical reload cores. We present ML models trained from two deep neural\nnetwork (DNN) architectures, SurrogateNet and LPRMNet, that demonstrate a\ntesting error of 1 percent and 3 percent, respectively. Applications of these\nmodels can include virtual sensing capability for bypassed or malfunctioning\nLPRMs, on demand virtual calibration of detectors between successive\ncalibrations, highly accurate nuclear end of life determinations for LPRMs, and\nreduced bias between measured and predicted power distributions within the\ncore.",
      "tldr_zh": "该论文探讨了在沸水反应堆（Boiling Water Reactors）中利用 AI 和机器学习（ML）技术来改进中子通量测量和虚拟校准，以确保反应堆核心的三维功率分布更准确，从而提升安全、经济运行和燃料循环规划。研究引入了两种深度神经网络（DNN）架构：SurrogateNet 和 LPRMNet，分别实现了1%和3%的测试误差，用于解决传统测量系统的挑战，如校准偏差和设备故障。模型的应用包括为故障局部功率范围监视器（LPRMs）提供虚拟传感能力、实现按需虚拟校准、精确核寿命评估，以及减少离线和在线功率分布之间的偏差，最终支持更安全且经济的反应堆重新装载设计。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17405v1",
      "published_date": "2024-09-25 22:30:09 UTC",
      "updated_date": "2024-09-25 22:30:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:28:30.292085"
    },
    {
      "arxiv_id": "2409.17403v1",
      "title": "Transient Adversarial 3D Projection Attacks on Object Detection in Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Ce Zhou",
        "Qiben Yan",
        "Sijia Liu"
      ],
      "abstract": "Object detection is a crucial task in autonomous driving. While existing\nresearch has proposed various attacks on object detection, such as those using\nadversarial patches or stickers, the exploration of projection attacks on 3D\nsurfaces remains largely unexplored. Compared to adversarial patches or\nstickers, which have fixed adversarial patterns, projection attacks allow for\ntransient modifications to these patterns, enabling a more flexible attack. In\nthis paper, we introduce an adversarial 3D projection attack specifically\ntargeting object detection in autonomous driving scenarios. We frame the attack\nformulation as an optimization problem, utilizing a combination of color\nmapping and geometric transformation models. Our results demonstrate the\neffectiveness of the proposed attack in deceiving YOLOv3 and Mask R-CNN in\nphysical settings. Evaluations conducted in an indoor environment show an\nattack success rate of up to 100% under low ambient light conditions,\nhighlighting the potential damage of our attack in real-world driving\nscenarios.",
      "tldr_zh": "本研究提出了一种瞬态adversarial 3D projection攻击，针对自动驾驶中的物体检测系统，相比传统的adversarial patches或stickers，该方法允许更灵活的模式修改。攻击通过将问题表述为优化问题，结合color mapping和geometric transformation模型，对YOLOv3和Mask R-CNN等检测器进行欺骗。实验结果显示，在室内低光环境下攻击成功率高达100%，突显了这种攻击在真实驾驶场景中的潜在安全风险。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "20 pages, 7 figures, SmartSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.17403v1",
      "published_date": "2024-09-25 22:27:11 UTC",
      "updated_date": "2024-09-25 22:27:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:28:38.089865"
    },
    {
      "arxiv_id": "2409.17402v1",
      "title": "Enhancing Recommendation with Denoising Auxiliary Task",
      "title_zh": "翻译失败",
      "authors": [
        "Pengsheng Liu",
        "Linan Zheng",
        "Jiale Chen",
        "Guangfa Zhang",
        "Yang Xu",
        "Jinyun Fang"
      ],
      "abstract": "The historical interaction sequences of users plays a crucial role in\ntraining recommender systems that can accurately predict user preferences.\nHowever, due to the arbitrariness of user behavior, the presence of noise in\nthese sequences poses a challenge to predicting their next actions in\nrecommender systems. To address this issue, our motivation is based on the\nobservation that training noisy sequences and clean sequences (sequences\nwithout noise) with equal weights can impact the performance of the model. We\npropose a novel self-supervised Auxiliary Task Joint Training (ATJT) method\naimed at more accurately reweighting noisy sequences in recommender systems.\nSpecifically, we strategically select subsets from users' original sequences\nand perform random replacements to generate artificially replaced noisy\nsequences. Subsequently, we perform joint training on these artificially\nreplaced noisy sequences and the original sequences. Through effective\nreweighting, we incorporate the training results of the noise recognition model\ninto the recommender model. We evaluate our method on three datasets using a\nconsistent base model. Experimental results demonstrate the effectiveness of\nintroducing self-supervised auxiliary task to enhance the base model's\nperformance.",
      "tldr_zh": "该论文针对推荐系统中用户历史交互序列中的噪声问题，提出了一种自监督 Auxiliary Task Joint Training (ATJT) 方法，以更准确地再加权噪声序列。方法涉及从用户原序列中选择子集进行随机替换生成人工噪声序列，并将这些序列与原序列进行联合训练，从而将噪声识别模型的输出整合到推荐模型中。实验结果显示，在三个数据集上应用 ATJT 后，基础模型的性能得到显著提升，证明了自监督辅助任务的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17402v1",
      "published_date": "2024-09-25 22:26:29 UTC",
      "updated_date": "2024-09-25 22:26:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:28:51.364773"
    },
    {
      "arxiv_id": "2409.17400v2",
      "title": "AgRegNet: A Deep Regression Network for Flower and Fruit Density Estimation, Localization, and Counting in Orchards",
      "title_zh": "AgRegNet：一种用于果园中花和果实密度估计、定位和计",
      "authors": [
        "Uddhav Bhattarai",
        "Santosh Bhusal",
        "Qin Zhang",
        "Manoj Karkee"
      ],
      "abstract": "One of the major challenges for the agricultural industry today is the\nuncertainty in manual labor availability and the associated cost. Automated\nflower and fruit density estimation, localization, and counting could help\nstreamline harvesting, yield estimation, and crop-load management strategies\nsuch as flower and fruitlet thinning. This article proposes a deep\nregression-based network, AgRegNet, to estimate density, count, and location of\nflower and fruit in tree fruit canopies without explicit object detection or\npolygon annotation. Inspired by popular U-Net architecture, AgRegNet is a\nU-shaped network with an encoder-to-decoder skip connection and modified\nConvNeXt-T as an encoder feature extractor. AgRegNet can be trained based on\ninformation from point annotation and leverages segmentation information and\nattention modules (spatial and channel) to highlight relevant flower and fruit\nfeatures while suppressing non-relevant background features. Experimental\nevaluation in apple flower and fruit canopy images under an unstructured\norchard environment showed that AgRegNet achieved promising accuracy as\nmeasured by Structural Similarity Index (SSIM), percentage Mean Absolute Error\n(pMAE) and mean Average Precision (mAP) to estimate flower and fruit density,\ncount, and centroid location, respectively. Specifically, the SSIM, pMAE, and\nmAP values for flower images were 0.938, 13.7%, and 0.81, respectively. For\nfruit images, the corresponding values were 0.910, 5.6%, and 0.93. Since the\nproposed approach relies on information from point annotation, it is suitable\nfor sparsely and densely located objects. This simplified technique will be\nhighly applicable for growers to accurately estimate yields and decide on\noptimal chemical and mechanical flower thinning practices.",
      "tldr_zh": "这篇论文提出了一种深度回归网络 AgRegNet，用于农业领域中花朵和果实的密度估计、定位和计数，以解决劳动力不确定性和成本问题。该网络基于 U-Net 架构，采用编码器到解码器的跳跃连接、修改后的 ConvNeXt-T 作为编码器特征提取器，并结合点标注、分割信息和空间及通道注意力模块（spatial and channel attention），来突出相关特征并抑制背景干扰。在苹果花果图像的实验中，AgRegNet 取得了优异性能，包括花朵图像的 SSIM 为 0.938、pMAE 为 13.7% 和 mAP 为 0.81，以及果实图像的 SSIM 为 0.910、pMAE 为 5.6% 和 mAP 为 0.93，从而为优化收获、产量估计和作物管理提供高效工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in Computers and Electronics in Agriculture",
      "pdf_url": "http://arxiv.org/pdf/2409.17400v2",
      "published_date": "2024-09-25 22:19:32 UTC",
      "updated_date": "2025-01-16 20:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:29:05.547954"
    },
    {
      "arxiv_id": "2409.17386v1",
      "title": "Beyond Redundancy: Information-aware Unsupervised Multiplex Graph Structure Learning",
      "title_zh": "超越冗余：基于信息的无监督多层图结构学习",
      "authors": [
        "Zhixiang Shen",
        "Shuo Wang",
        "Zhao Kang"
      ],
      "abstract": "Unsupervised Multiplex Graph Learning (UMGL) aims to learn node\nrepresentations on various edge types without manual labeling. However,\nexisting research overlooks a key factor: the reliability of the graph\nstructure. Real-world data often exhibit a complex nature and contain abundant\ntask-irrelevant noise, severely compromising UMGL's performance. Moreover,\nexisting methods primarily rely on contrastive learning to maximize mutual\ninformation across different graphs, limiting them to multiplex graph redundant\nscenarios and failing to capture view-unique task-relevant information. In this\npaper, we focus on a more realistic and challenging task: to unsupervisedly\nlearn a fused graph from multiple graphs that preserve sufficient task-relevant\ninformation while removing task-irrelevant noise. Specifically, our proposed\nInformation-aware Unsupervised Multiplex Graph Fusion framework (InfoMGF) uses\ngraph structure refinement to eliminate irrelevant noise and simultaneously\nmaximizes view-shared and view-unique task-relevant information, thereby\ntackling the frontier of non-redundant multiplex graph. Theoretical analyses\nfurther guarantee the effectiveness of InfoMGF. Comprehensive experiments\nagainst various baselines on different downstream tasks demonstrate its\nsuperior performance and robustness. Surprisingly, our unsupervised method even\nbeats the sophisticated supervised approaches. The source code and datasets are\navailable at https://github.com/zxlearningdeep/InfoMGF.",
      "tldr_zh": "本研究针对无监督多重图学习(UMGL)中的问题，指出现有方法忽略了图结构的可靠性，导致任务无关噪声影响性能，并仅依赖对比学习来最大化互信息，从而无法捕获视图独有的任务相关信息。论文提出Information-aware Unsupervised Multiplex Graph Fusion (InfoMGF)框架，通过图结构精炼去除无关噪声，同时最大化视图共享和视图独有的任务相关信息，实现从多个图中无监督学习一个非冗余融合图。理论分析证明了框架的有效性，实验结果显示InfoMGF在各种下游任务上显著优于基线，甚至超越先进的监督方法，展示了其鲁棒性和潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Appear in NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.17386v1",
      "published_date": "2024-09-25 22:00:26 UTC",
      "updated_date": "2024-09-25 22:00:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:29:19.028593"
    },
    {
      "arxiv_id": "2409.17385v2",
      "title": "SSTP: Efficient Sample Selection for Trajectory Prediction",
      "title_zh": "SSTP：用于轨迹预测的高效样本选择",
      "authors": [
        "Ruining Yang",
        "Yi Xu",
        "Yun Fu",
        "Lili Su"
      ],
      "abstract": "Trajectory prediction is a core task in autonomous driving. However, training\nadvanced trajectory prediction models on large-scale datasets is both\ntime-consuming and computationally expensive. In addition, the imbalanced\ndistribution of driving scenarios often biases models toward data-rich cases,\nlimiting performance in safety-critical, data-scarce conditions. To address\nthese challenges, we propose the Sample Selection for Trajectory Prediction\n(SSTP) framework, which constructs a compact yet balanced dataset for\ntrajectory prediction. SSTP consists of two main stages (1) Extraction, in\nwhich a pretrained trajectory prediction model computes gradient vectors for\neach sample to capture their influence on parameter updates; and (2) Selection,\nwhere a submodular function is applied to greedily choose a representative\nsubset that covers diverse driving scenarios. This approach significantly\nreduces the dataset size and mitigates scenario imbalance, without sacrificing\nprediction accuracy and even improving in high-density cases. We evaluate our\nproposed SSTP on the Argoverse 1 and Argoverse 2 benchmarks using a wide range\nof recent state-of-the-art models. Our experiments demonstrate that SSTP\nachieves comparable performance to full-dataset training using only half the\ndata while delivering substantial improvements in high-density traffic scenes\nand significantly reducing training time. Importantly, SSTP exhibits strong\ngeneralization and robustness, and the selected subset is model-agnostic,\noffering a broadly applicable solution.",
      "tldr_zh": "该论文提出SSTP框架，用于高效样本选择以优化轨迹预测任务，解决训练数据规模大、计算开销高以及驾驶场景分布不平衡的问题。SSTP包括两个阶段：Extraction阶段使用预训练模型计算样本梯度向量来评估其对参数更新的影响；Selection阶段应用子modular函数贪婪选择一个代表性子集，以覆盖多样驾驶场景。该框架显著减少数据集大小，同时保持或提升预测准确性，在Argoverse 1和2基准测试中，使用一半数据即可实现与全数据集相当的性能，尤其在高密度交通场景中表现更好，并显著缩短训练时间，同时展示出强大的泛化性和模型无关性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17385v2",
      "published_date": "2024-09-25 22:00:11 UTC",
      "updated_date": "2025-03-20 03:32:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:29:27.954838"
    },
    {
      "arxiv_id": "2409.17383v1",
      "title": "VectorSearch: Enhancing Document Retrieval with Semantic Embeddings and Optimized Search",
      "title_zh": "VectorSearch：通过语义嵌入和优化搜索增强文档检索",
      "authors": [
        "Solmaz Seyed Monir",
        "Irene Lau",
        "Shubing Yang",
        "Dongfang Zhao"
      ],
      "abstract": "Traditional retrieval methods have been essential for assessing document\nsimilarity but struggle with capturing semantic nuances. Despite advancements\nin latent semantic analysis (LSA) and deep learning, achieving comprehensive\nsemantic understanding and accurate retrieval remains challenging due to high\ndimensionality and semantic gaps. The above challenges call for new techniques\nto effectively reduce the dimensions and close the semantic gaps. To this end,\nwe propose VectorSearch, which leverages advanced algorithms, embeddings, and\nindexing techniques for refined retrieval. By utilizing innovative multi-vector\nsearch operations and encoding searches with advanced language models, our\napproach significantly improves retrieval accuracy. Experiments on real-world\ndatasets show that VectorSearch outperforms baseline metrics, demonstrating its\nefficacy for large-scale retrieval tasks.",
      "tldr_zh": "本文讨论了传统文档检索方法在捕捉语义细微差别方面的局限性，尽管有 LSA 和深度学习等进展，但高维度和语义差距仍是主要挑战。为此，提出 VectorSearch 框架，通过高级算法、semantic embeddings 和优化索引技术，以及创新的多向量搜索操作和高级语言模型编码，显著提升检索准确性。实验结果显示，在真实数据集上，VectorSearch 优于基线指标，证明其在大规模检索任务中的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DB",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.17383v1",
      "published_date": "2024-09-25 21:58:08 UTC",
      "updated_date": "2024-09-25 21:58:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:29:38.794348"
    },
    {
      "arxiv_id": "2409.17380v1",
      "title": "Tesla's Autopilot: Ethics and Tragedy",
      "title_zh": "Tesla 的 Autopilot：伦理与悲剧",
      "authors": [
        "Aravinda Jatavallabha"
      ],
      "abstract": "This case study delves into the ethical ramifications of an incident\ninvolving Tesla's Autopilot, emphasizing Tesla Motors' moral responsibility.\nUsing a seven-step ethical decision-making process, it examines user behavior,\nsystem constraints, and regulatory implications. This incident prompts a\nbroader evaluation of ethical challenges in the automotive industry's adoption\nof autonomous technologies, urging a reconsideration of industry norms and\nlegal frameworks. The analysis offers a succinct exploration of ethical\nconsiderations in evolving technological landscapes.",
      "tldr_zh": "这篇论文通过一个涉及 Tesla Autopilot 的案例研究，探讨了该事件中的伦理影响，并强调了 Tesla Motors 的道德责任。作者采用七步 ethical decision-making process 来分析用户行为、系统 constraints 和监管 implications。该研究促使对汽车行业采用自主技术的伦理挑战进行更广泛评估，呼吁重新审视行业 norms 和法律框架，以应对不断演变的科技景观。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17380v1",
      "published_date": "2024-09-25 21:53:33 UTC",
      "updated_date": "2024-09-25 21:53:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:29:50.846600"
    },
    {
      "arxiv_id": "2409.17372v2",
      "title": "Search for Efficient Large Language Models",
      "title_zh": "高效大型语言",
      "authors": [
        "Xuan Shen",
        "Pu Zhao",
        "Yifan Gong",
        "Zhenglun Kong",
        "Zheng Zhan",
        "Yushu Wu",
        "Ming Lin",
        "Chao Wu",
        "Xue Lin",
        "Yanzhi Wang"
      ],
      "abstract": "Large Language Models (LLMs) have long held sway in the realms of artificial\nintelligence research. Numerous efficient techniques, including weight pruning,\nquantization, and distillation, have been embraced to compress LLMs, targeting\nmemory reduction and inference acceleration, which underscore the redundancy in\nLLMs. However, most model compression techniques concentrate on weight\noptimization, overlooking the exploration of optimal architectures. Besides,\ntraditional architecture search methods, limited by the elevated complexity\nwith extensive parameters, struggle to demonstrate their effectiveness on LLMs.\nIn this paper, we propose a training-free architecture search framework to\nidentify optimal subnets that preserve the fundamental strengths of the\noriginal LLMs while achieving inference acceleration. Furthermore, after\ngenerating subnets that inherit specific weights from the original LLMs, we\nintroduce a reformation algorithm that utilizes the omitted weights to rectify\nthe inherited weights with a small amount of calibration data. Compared with\nSOTA training-free structured pruning works that can generate smaller networks,\nour method demonstrates superior performance across standard benchmarks.\nFurthermore, our generated subnets can directly reduce the usage of GPU memory\nand achieve inference acceleration. Code:\nhttps://github.com/shawnricecake/search-llm",
      "tldr_zh": "这篇论文针对大型语言模型 (LLMs) 的效率问题，提出一个无训练的架构搜索框架，用于识别最佳子网络 (subnets)，以保留原模型的核心性能同时实现推理加速。框架不仅优化架构，还引入重构算法，利用省略的权重和少量校准数据来修正继承权重。实验结果显示，该方法在标准基准上优于现有最先进 (SOTA) 的训练-free 结构修剪技术，并能直接减少 GPU 内存使用和提升推理速度。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.17372v2",
      "published_date": "2024-09-25 21:32:12 UTC",
      "updated_date": "2024-10-30 20:04:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:30:13.173585"
    },
    {
      "arxiv_id": "2409.17370v1",
      "title": "The Overfocusing Bias of Convolutional Neural Networks: A Saliency-Guided Regularization Approach",
      "title_zh": "翻译失败",
      "authors": [
        "David Bertoin",
        "Eduardo Hugo Sanchez",
        "Mehdi Zouitine",
        "Emmanuel Rachelson"
      ],
      "abstract": "Despite transformers being considered as the new standard in computer vision,\nconvolutional neural networks (CNNs) still outperform them in low-data regimes.\nNonetheless, CNNs often make decisions based on narrow, specific regions of\ninput images, especially when training data is limited. This behavior can\nseverely compromise the model's generalization capabilities, making it\ndisproportionately dependent on certain features that might not represent the\nbroader context of images. While the conditions leading to this phenomenon\nremain elusive, the primary intent of this article is to shed light on this\nobserved behavior of neural networks. Our research endeavors to prioritize\ncomprehensive insight and to outline an initial response to this phenomenon. In\nline with this, we introduce Saliency Guided Dropout (SGDrop), a pioneering\nregularization approach tailored to address this specific issue. SGDrop\nutilizes attribution methods on the feature map to identify and then reduce the\ninfluence of the most salient features during training. This process encourages\nthe network to diversify its attention and not focus solely on specific\nstandout areas. Our experiments across several visual classification benchmarks\nvalidate SGDrop's role in enhancing generalization. Significantly, models\nincorporating SGDrop display more expansive attributions and neural activity,\noffering a more comprehensive view of input images in contrast to their\ntraditionally trained counterparts.",
      "tldr_zh": "该研究揭示了 Convolutional Neural Networks (CNNs) 在数据有限环境下存在的过度关注偏差（Overfocusing Bias），即模型过度依赖输入图像的狭窄区域，导致泛化能力下降。作者提出了一种创新正则化方法——Saliency Guided Dropout (SGDrop)，它利用归因技术识别特征图中最显著特征，并在训练中减少其影响，以促使网络分散注意力并更全面地处理图像。实验结果显示，应用 SGDrop 的模型在多个视觉分类基准上表现出更好的泛化性能，并展现出更广泛的归因和神经活动。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17370v1",
      "published_date": "2024-09-25 21:30:16 UTC",
      "updated_date": "2024-09-25 21:30:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:30:16.131171"
    },
    {
      "arxiv_id": "2410.03706v1",
      "title": "Topological Foundations of Reinforcement Learning",
      "title_zh": "强化学习的拓扑基础",
      "authors": [
        "David Krame Kadurha"
      ],
      "abstract": "The goal of this work is to serve as a foundation for deep studies of the\ntopology of state, action, and policy spaces in reinforcement learning. By\nstudying these spaces from a mathematical perspective, we expect to gain more\ninsight into how to build better algorithms to solve decision problems.\nTherefore, we focus on presenting the connection between the Banach fixed point\ntheorem and the convergence of reinforcement learning algorithms, and we\nillustrate how the insights gained from this can practically help in designing\nmore efficient algorithms. Before doing so, however, we first introduce\nrelevant concepts such as metric spaces, normed spaces and Banach spaces for\nbetter understanding, before expressing the entire reinforcement learning\nproblem in terms of Markov decision processes. This allows us to properly\nintroduce the Banach contraction principle in a language suitable for\nreinforcement learning, and to write the Bellman equations in terms of\noperators on Banach spaces to show why reinforcement learning algorithms\nconverge. Finally, we show how the insights gained from the mathematical study\nof convergence are helpful in reasoning about the best ways to make\nreinforcement learning algorithms more efficient.",
      "tldr_zh": "这篇论文探讨了拓扑学在强化学习中的基础，旨在通过数学视角分析状态、动作和策略空间，以提升算法设计。作者首先介绍了度量空间、赋范空间和 Banach spaces 等相关概念，并将强化学习问题表述为 Markov decision processes。论文重点阐述了 Banach fixed point theorem 与强化学习算法收敛的联系，通过 Bellman equations 在 Banach spaces 上的运算证明算法收敛，并提供见解来设计更高效的算法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.FA",
        "68T05"
      ],
      "primary_category": "cs.LG",
      "comment": "Supervisor : Yae Ulrich Gaba , Mentor : Domini Jocema Leko",
      "pdf_url": "http://arxiv.org/pdf/2410.03706v1",
      "published_date": "2024-09-25 21:21:23 UTC",
      "updated_date": "2024-09-25 21:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:30:37.896158"
    },
    {
      "arxiv_id": "2409.17340v1",
      "title": "Koopman-driven grip force prediction through EMG sensing",
      "title_zh": "翻译失败",
      "authors": [
        "Tomislav Bazina",
        "Ervin Kamenar",
        "Maria Fonoberova",
        "Igor Mezić"
      ],
      "abstract": "Loss of hand function due to conditions like stroke or multiple sclerosis\nsignificantly impacts daily activities. Robotic rehabilitation provides tools\nto restore hand function, while novel methods based on surface electromyography\n(sEMG) enable the adaptation of the device's force output according to the\nuser's condition, thereby improving rehabilitation outcomes. This study aims to\nachieve accurate force estimations during medium wrap grasps using a single\nsEMG sensor pair, thereby addressing the challenge of escalating sensor\nrequirements for precise predictions. We conducted sEMG measurements on 13\nsubjects at two forearm positions, validating results with a hand dynamometer.\nWe established flexible signal-processing steps, yielding high peak\ncross-correlations between the processed sEMG signal (representing meaningful\nmuscle activity) and grip force. Influential parameters were subsequently\nidentified through sensitivity analysis. Leveraging a novel data-driven Koopman\noperator theory-based approach and problem-specific data lifting techniques, we\ndevised a methodology for the estimation and short-term prediction of grip\nforce from processed sEMG signals. A weighted mean absolute percentage error\n(wMAPE) of approx. 5.5% was achieved for the estimated grip force, whereas\npredictions with a 0.5-second prediction horizon resulted in a wMAPE of approx.\n17.9%. The methodology proved robust regarding precise electrode positioning,\nas the effect of sensing position on error metrics was non-significant. The\nalgorithm executes exceptionally fast, processing, estimating, and predicting a\n0.5-second sEMG signal batch in just approx. 30 ms, facilitating real-time\nimplementation.",
      "tldr_zh": "本文研究针对中风或多发性硬化导致的手部功能丧失，提出了一种基于表面肌电图 (sEMG) 的握力预测方法，使用单个 sEMG 传感器对中等包裹握力进行准确估计和短期预测，以减少传感器需求并提升机器人康复效果。方法包括灵活的信号处理步骤、敏感性分析，以及基于 Koopman operator 理论的数据驱动模型和特定数据提升技术。实验在 13 名受试者上验证，握力估计的加权平均绝对百分比误差 (wMAPE) 约为 5.5%，0.5 秒预测视野的 wMAPE 约为 17.9%，且算法对电极位置鲁棒且实时处理速度快（约 30 ms 处理 0.5 秒信号），为临床应用提供了高效解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "math.DS"
      ],
      "primary_category": "cs.RO",
      "comment": "11 pages, 8 figures, journal",
      "pdf_url": "http://arxiv.org/pdf/2409.17340v1",
      "published_date": "2024-09-25 20:28:57 UTC",
      "updated_date": "2024-09-25 20:28:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:30:40.501052"
    },
    {
      "arxiv_id": "2409.17336v1",
      "title": "The Technology of Outrage: Bias in Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Will Bridewell",
        "Paul F. Bello",
        "Selmer Bringsjord"
      ],
      "abstract": "Artificial intelligence and machine learning are increasingly used to offload\ndecision making from people. In the past, one of the rationales for this\nreplacement was that machines, unlike people, can be fair and unbiased.\nEvidence suggests otherwise. We begin by entertaining the ideas that algorithms\ncan replace people and that algorithms cannot be biased. Taken as axioms, these\nstatements quickly lead to absurdity. Spurred on by this result, we investigate\nthe slogans more closely and identify equivocation surrounding the word 'bias.'\nWe diagnose three forms of outrage-intellectual, moral, and political-that are\nat play when people react emotionally to algorithmic bias. Then we suggest\nthree practical approaches to addressing bias that the AI community could take,\nwhich include clarifying the language around bias, developing new auditing\nmethods for intelligent systems, and building certain capabilities into these\nsystems. We conclude by offering a moral regarding the conversations about\nalgorithmic bias that may transfer to other areas of artificial intelligence.",
      "tldr_zh": "该论文探讨了人工智能（Artificial Intelligence）中算法偏见（bias）的问题，挑战了机器决策比人类更公平的传统观点。通过逻辑分析，该研究揭示了“bias”一词的歧义，并识别了三种愤怒形式——intellectual、moral 和 political——在人们对算法偏见反应中的作用。主要贡献包括提出三种实用方法：澄清偏见相关语言、开发新的智能系统审计方法，以及内置特定能力以缓解偏见。论文以一个道德教训结束，强调此类讨论可能适用于人工智能的其他领域。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Distribution Statement A. Approved for public release; distribution\n  is unlimited",
      "pdf_url": "http://arxiv.org/pdf/2409.17336v1",
      "published_date": "2024-09-25 20:23:25 UTC",
      "updated_date": "2024-09-25 20:23:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:30:52.580888"
    },
    {
      "arxiv_id": "2409.17332v1",
      "title": "Block Expanded DINORET: Adapting Natural Domain Foundation Models for Retinal Imaging Without Catastrophic Forgetting",
      "title_zh": "翻译失败",
      "authors": [
        "Jay Zoellin",
        "Colin Merk",
        "Mischa Buob",
        "Amr Saad",
        "Samuel Giesser",
        "Tahm Spitznagel",
        "Ferhat Turgut",
        "Rui Santos",
        "Yukun Zhou",
        "Sigfried Wagner",
        "Pearse A. Keane",
        "Yih Chung Tham",
        "Delia Cabrera DeBuc",
        "Matthias D. Becker",
        "Gabor M. Somfai"
      ],
      "abstract": "Integrating deep learning into medical imaging is poised to greatly advance\ndiagnostic methods but it faces challenges with generalizability. Foundation\nmodels, based on self-supervised learning, address these issues and improve\ndata efficiency. Natural domain foundation models show promise for medical\nimaging, but systematic research evaluating domain adaptation, especially using\nself-supervised learning and parameter-efficient fine-tuning, remains\nunderexplored. Additionally, little research addresses the issue of\ncatastrophic forgetting during fine-tuning of foundation models. We adapted the\nDINOv2 vision transformer for retinal imaging classification tasks using\nself-supervised learning and generated two novel foundation models termed\nDINORET and BE DINORET. Publicly available color fundus photographs were\nemployed for model development and subsequent fine-tuning for diabetic\nretinopathy staging and glaucoma detection. We introduced block expansion as a\nnovel domain adaptation strategy and assessed the models for catastrophic\nforgetting. Models were benchmarked to RETFound, a state-of-the-art foundation\nmodel in ophthalmology. DINORET and BE DINORET demonstrated competitive\nperformance on retinal imaging tasks, with the block expanded model achieving\nthe highest scores on most datasets. Block expansion successfully mitigated\ncatastrophic forgetting. Our few-shot learning studies indicated that DINORET\nand BE DINORET outperform RETFound in terms of data-efficiency. This study\nhighlights the potential of adapting natural domain vision models to retinal\nimaging using self-supervised learning and block expansion. BE DINORET offers\nrobust performance without sacrificing previously acquired capabilities. Our\nfindings suggest that these methods could enable healthcare institutions to\ndevelop tailored vision models for their patient populations, enhancing global\nhealthcare inclusivity.",
      "tldr_zh": "本文提出了一种适应自然领域基础模型到视网膜成像的框架，旨在解决深度学习在医疗成像中的泛化性挑战，同时避免 catastrophic forgetting。研究者使用 self-supervised learning 对 DINOv2 视觉 transformer 进行微调，开发了 DINORET 和 Block Expanded DINORET (BE DINORET) 模型，并引入 block expansion 作为新型领域适应策略。实验结果显示，BE DINORET 在糖尿病视网膜病变分期和青光眼检测任务上表现出色，比基准模型 RETFound 更数据高效，并在少样本学习中实现更高准确率。这些方法有助于医疗机构开发定制的视觉模型，提升全球医疗包容性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.0; I.2.10; J.3"
      ],
      "primary_category": "cs.CV",
      "comment": "J.Zoellin, C. Merk and M. Buob contributed equally as shared-first\n  authors. D. Cabrera DeBuc, M. D. Becker and G. M. Somfai contributed equally\n  as senior authors for this work",
      "pdf_url": "http://arxiv.org/pdf/2409.17332v1",
      "published_date": "2024-09-25 20:17:16 UTC",
      "updated_date": "2024-09-25 20:17:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:31:08.789570"
    },
    {
      "arxiv_id": "2409.17315v1",
      "title": "KIPPS: Knowledge infusion in Privacy Preserving Synthetic Data Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Anantaa Kotal",
        "Anupam Joshi"
      ],
      "abstract": "The integration of privacy measures, including differential privacy\ntechniques, ensures a provable privacy guarantee for the synthetic data.\nHowever, challenges arise for Generative Deep Learning models when tasked with\ngenerating realistic data, especially in critical domains such as Cybersecurity\nand Healthcare. Generative Models optimized for continuous data struggle to\nmodel discrete and non-Gaussian features that have domain constraints.\nChallenges increase when the training datasets are limited and not diverse. In\nsuch cases, generative models create synthetic data that repeats sensitive\nfeatures, which is a privacy risk. Moreover, generative models face\ndifficulties comprehending attribute constraints in specialized domains. This\nleads to the generation of unrealistic data that impacts downstream accuracy.\nTo address these issues, this paper proposes a novel model, KIPPS, that infuses\nDomain and Regulatory Knowledge from Knowledge Graphs into Generative Deep\nLearning models for enhanced Privacy Preserving Synthetic data generation. The\nnovel framework augments the training of generative models with supplementary\ncontext about attribute values and enforces domain constraints during training.\nThis added guidance enhances the model's capacity to generate realistic and\ndomain-compliant synthetic data. The proposed model is evaluated on real-world\ndatasets, specifically in the domains of Cybersecurity and Healthcare, where\ndomain constraints and rules add to the complexity of the data. Our experiments\nevaluate the privacy resilience and downstream accuracy of the model against\nbenchmark methods, demonstrating its effectiveness in addressing the balance\nbetween privacy preservation and data accuracy in complex domains.",
      "tldr_zh": "本文提出KIPPS模型，通过从Knowledge Graphs注入领域和监管知识，增强生成式深度学习模型在Privacy Preserving Synthetic Data Generation中的性能。该框架在训练过程中补充属性值的上下文并强制执行领域约束，以解决生成不现实数据和隐私风险问题，尤其在网络安全和医疗领域。实验结果显示，KIPPS在真实数据集上实现了更好的隐私韧性和下游准确性，比基准方法更有效地平衡隐私保护与数据真实性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17315v1",
      "published_date": "2024-09-25 19:50:03 UTC",
      "updated_date": "2024-09-25 19:50:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:31:27.926834"
    },
    {
      "arxiv_id": "2409.17313v1",
      "title": "Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation",
      "title_zh": "探索细微差别：视觉-语言导航的细粒度评估",
      "authors": [
        "Zehao Wang",
        "Minye Wu",
        "Yixin Cao",
        "Yubo Ma",
        "Meiqi Chen",
        "Tinne Tuytelaars"
      ],
      "abstract": "This study presents a novel evaluation framework for the Vision-Language\nNavigation (VLN) task. It aims to diagnose current models for various\ninstruction categories at a finer-grained level. The framework is structured\naround the context-free grammar (CFG) of the task. The CFG serves as the basis\nfor the problem decomposition and the core premise of the instruction\ncategories design. We propose a semi-automatic method for CFG construction with\nthe help of Large-Language Models (LLMs). Then, we induct and generate data\nspanning five principal instruction categories (i.e. direction change, landmark\nrecognition, region recognition, vertical movement, and numerical\ncomprehension). Our analysis of different models reveals notable performance\ndiscrepancies and recurrent issues. The stagnation of numerical comprehension,\nheavy selective biases over directional concepts, and other interesting\nfindings contribute to the development of future language-guided navigation\nsystems.",
      "tldr_zh": "本研究提出了一种细粒度评估框架，用于评估Vision-Language Navigation (VLN)任务中的模型性能。该框架基于Context-Free Grammar (CFG)进行问题分解，并利用Large-Language Models (LLMs)实现半自动CFG构建，生成涵盖方向变化、地标识别、区域识别、垂直移动和数字理解等五类指令的数据。通过分析不同模型，该框架揭示了性能差异，包括数字理解的停滞、对方向概念的偏好等常见问题。这些发现有助于推动未来语言引导导航系统的改进和发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "EMNLP 2024 Findings; project page:\n  https://zehao-wang.github.io/navnuances",
      "pdf_url": "http://arxiv.org/pdf/2409.17313v1",
      "published_date": "2024-09-25 19:49:39 UTC",
      "updated_date": "2024-09-25 19:49:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:31:27.839807"
    },
    {
      "arxiv_id": "2409.17311v1",
      "title": "A Hybrid Quantum-Classical AI-Based Detection Strategy for Generative Adversarial Network-Based Deepfake Attacks on an Autonomous Vehicle Traffic Sign Classification System",
      "title_zh": "翻译失败",
      "authors": [
        "M Sabbir Salek",
        "Shaozhi Li",
        "Mashrur Chowdhury"
      ],
      "abstract": "The perception module in autonomous vehicles (AVs) relies heavily on deep\nlearning-based models to detect and identify various objects in their\nsurrounding environment. An AV traffic sign classification system is integral\nto this module, which helps AVs recognize roadway traffic signs. However,\nadversarial attacks, in which an attacker modifies or alters the image captured\nfor traffic sign recognition, could lead an AV to misrecognize the traffic\nsigns and cause hazardous consequences. Deepfake presents itself as a promising\ntechnology to be used for such adversarial attacks, in which a deepfake traffic\nsign would replace a real-world traffic sign image before the image is fed to\nthe AV traffic sign classification system. In this study, the authors present\nhow a generative adversarial network-based deepfake attack can be crafted to\nfool the AV traffic sign classification systems. The authors developed a\ndeepfake traffic sign image detection strategy leveraging hybrid\nquantum-classical neural networks (NNs). This hybrid approach utilizes\namplitude encoding to represent the features of an input traffic sign image\nusing quantum states, which substantially reduces the memory requirement\ncompared to its classical counterparts. The authors evaluated this hybrid\ndeepfake detection approach along with several baseline classical convolutional\nNNs on real-world and deepfake traffic sign images. The results indicate that\nthe hybrid quantum-classical NNs for deepfake detection could achieve similar\nor higher performance than the baseline classical convolutional NNs in most\ncases while requiring less than one-third of the memory required by the\nshallowest classical convolutional NN considered in this study.",
      "tldr_zh": "本研究探讨了基于 Generative Adversarial Network (GAN) 的 Deepfake 攻击对自动驾驶车辆 (AVs) 交通标志分类系统的潜在威胁，这些攻击可能导致误识别并引发安全隐患。作者提出了一种混合量子-经典神经网络 (NNs) 检测策略，利用 amplitude encoding 将交通标志图像特征编码为量子状态，从而显著降低内存需求。实验结果显示，该方法在真实和 Deepfake 图像上与经典卷积 NNs 相比，性能相当或更高，同时仅需不到三分之一的内存，为高效的反 Deepfake 防御提供了创新性解决方案。",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17311v1",
      "published_date": "2024-09-25 19:44:56 UTC",
      "updated_date": "2024-09-25 19:44:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:31:42.014247"
    },
    {
      "arxiv_id": "2409.17300v1",
      "title": "Neural Network Plasticity and Loss Sharpness",
      "title_zh": "神经网络可塑性和损失锐度",
      "authors": [
        "Max Koster",
        "Jude Kukla"
      ],
      "abstract": "In recent years, continual learning, a prediction setting in which the\nproblem environment may evolve over time, has become an increasingly popular\nresearch field due to the framework's gearing towards complex, non-stationary\nobjectives. Learning such objectives requires plasticity, or the ability of a\nneural network to adapt its predictions to a different task. Recent findings\nindicate that plasticity loss on new tasks is highly related to loss landscape\nsharpness in non-stationary RL frameworks. We explore the usage of sharpness\nregularization techniques, which seek out smooth minima and have been touted\nfor their generalization capabilities in vanilla prediction settings, in\nefforts to combat plasticity loss. Our findings indicate that such techniques\nhave no significant effect on reducing plasticity loss.",
      "tldr_zh": "本论文探讨了神经网络的塑性（plasticity）和损失锐度（loss sharpness）在持续学习（continual learning）环境中的关系，强调塑性是神经网络适应新任务的关键能力。作者通过应用锐度正则化技术（sharpness regularization），旨在寻找平滑的最小值以减少非平稳强化学习框架中的塑性损失。实验结果表明，这些技术对降低塑性损失没有显著效果，为持续学习领域的优化策略提供了重要启示。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17300v1",
      "published_date": "2024-09-25 19:20:09 UTC",
      "updated_date": "2024-09-25 19:20:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:31:53.409026"
    },
    {
      "arxiv_id": "2409.17270v2",
      "title": "Proof of Thought : Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Debargha Ganguly",
        "Srinivasan Iyengar",
        "Vipin Chaudhary",
        "Shivkumar Kalyanaraman"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized natural language processing,\nyet they struggle with inconsistent reasoning, particularly in novel domains\nand complex logical sequences. This research introduces Proof of Thought, a\nframework that enhances the reliability and transparency of LLM outputs. Our\napproach bridges LLM-generated ideas with formal logic verification, employing\na custom interpreter to convert LLM outputs into First Order Logic constructs\nfor theorem prover scrutiny. Central to our method is an intermediary\nJSON-based Domain-Specific Language, which by design balances precise logical\nstructures with intuitive human concepts. This hybrid representation enables\nboth rigorous validation and accessible human comprehension of LLM reasoning\nprocesses. Key contributions include a robust type system with sort management\nfor enhanced logical integrity, explicit representation of rules for clear\ndistinction between factual and inferential knowledge, and a flexible\narchitecture that allows for easy extension to various domain-specific\napplications. We demonstrate Proof of Thought's effectiveness through\nbenchmarking on StrategyQA and a novel multimodal reasoning task, showing\nimproved performance in open-ended scenarios. By providing verifiable and\ninterpretable results, our technique addresses critical needs for AI system\naccountability and sets a foundation for human-in-the-loop oversight in\nhigh-stakes domains.",
      "tldr_zh": "这项研究提出了Proof of Thought框架，通过神经符号程序合成（Neurosymbolic Program Synthesis）提升Large Language Models (LLMs)在新领域和复杂逻辑序列中的可靠性和可解释性。框架将LLM输出转换为First Order Logic结构，使用自定义解释器和JSON-based Domain-Specific Language作为中介，实现严谨验证和人类易懂的推理过程。关键贡献包括引入鲁棒的类型系统、显式规则表示以区分事实和推理知识，以及灵活架构以扩展到各种领域应用；实验在StrategyQA和一个新颖的多模态推理任务上展示了显著性能提升，并为AI系统的问责制和人类监督提供了基础。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.LO",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024) System 2 Reasoning At Scale Workshop",
      "pdf_url": "http://arxiv.org/pdf/2409.17270v2",
      "published_date": "2024-09-25 18:35:45 UTC",
      "updated_date": "2024-10-23 16:27:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:32:05.524877"
    },
    {
      "arxiv_id": "2409.17267v2",
      "title": "Minimal Variance Model Aggregation: A principled, non-intrusive, and versatile integration of black box models",
      "title_zh": "翻译失败",
      "authors": [
        "Théo Bourdais",
        "Houman Owhadi"
      ],
      "abstract": "Whether deterministic or stochastic, models can be viewed as functions\ndesigned to approximate a specific quantity of interest. We introduce Minimal\nEmpirical Variance Aggregation (MEVA), a data-driven framework that integrates\npredictions from various models, enhancing overall accuracy by leveraging the\nindividual strengths of each. This non-intrusive, model-agnostic approach\ntreats the contributing models as black boxes and accommodates outputs from\ndiverse methodologies, including machine learning algorithms and traditional\nnumerical solvers. We advocate for a point-wise linear aggregation process and\nconsider two methods for optimizing this aggregate: Minimal Error Aggregation\n(MEA), which minimizes the prediction error, and Minimal Variance Aggregation\n(MVA), which focuses on reducing variance. We prove a theorem showing that MVA\ncan be more robustly estimated from data than MEA, making MEVA superior to\nMinimal Empirical Error Aggregation (MEEA). Unlike MEEA, which interpolates\ntarget values directly, MEVA formulates aggregation as an error estimation\nproblem, which can be performed using any backbone learning paradigm. We\ndemonstrate the versatility and effectiveness of our framework across various\napplications, including data science and partial differential equations,\nillustrating its ability to significantly enhance both robustness and accuracy.",
      "tldr_zh": "该论文引入了Minimal Empirical Variance Aggregation (MEVA)，一种数据驱动框架，用于整合各种黑箱模型的预测，从而提升整体准确性。MEVA采用点-wise线性聚合，并比较了Minimal Error Aggregation (MEA)（最小化预测错误）和Minimal Variance Aggregation (MVA)（最小化方差）两种优化方法，证明MVA在数据估计上更鲁棒，从而使MEVA优于Minimal Empirical Error Aggregation (MEEA)。与MEEA直接插值不同，MEVA将聚合转化为错误估计问题，可与任何学习范式结合。实验结果显示，MEVA在数据科学和偏微分方程等领域显著提高了模型的鲁棒性和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "stat.ML",
        "62A09, 62H22, 65S05, 90C35, 94C15, 46E22, 62J02, 15A83, 62D20, 68R10"
      ],
      "primary_category": "cs.LG",
      "comment": "The code in this paper is available for download at\n  https://github.com/TheoBourdais/ModelAggregation",
      "pdf_url": "http://arxiv.org/pdf/2409.17267v2",
      "published_date": "2024-09-25 18:33:21 UTC",
      "updated_date": "2025-03-03 18:41:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:32:20.738868"
    },
    {
      "arxiv_id": "2409.17266v2",
      "title": "Empirical Asset Pricing with Large Language Model Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Junyan Cheng",
        "Peter Chin"
      ],
      "abstract": "In this study, we introduce a novel asset pricing model leveraging the Large\nLanguage Model (LLM) agents, which integrates qualitative discretionary\ninvestment evaluations from LLM agents with quantitative financial economic\nfactors manually curated, aiming to explain the excess asset returns. The\nexperimental results demonstrate that our methodology surpasses traditional\nmachine learning-based baselines in both portfolio optimization and asset\npricing errors. Notably, the Sharpe ratio for portfolio optimization and the\nmean magnitude of $|\\alpha|$ for anomaly portfolios experienced substantial\nenhancements of 10.6\\% and 10.0\\% respectively. Moreover, we performed\ncomprehensive ablation studies on our model and conducted a thorough analysis\nof the method to extract further insights into the proposed approach. Our\nresults show effective evidence of the feasibility of applying LLMs in\nempirical asset pricing.",
      "tldr_zh": "本研究提出了一种新型资产定价模型，使用 Large Language Model (LLM) 代理，将 LLM 的定性投资评估与手动 curation 的量化金融经济因素相结合，以解释超额资产回报。实验结果显示，该模型在投资组合优化和资产定价错误方面优于传统机器学习基准，具体包括 Sharpe ratio 提升 10.6% 和 $|\\alpha|$ 均值幅度提升 10.0%。此外，通过全面的消融研究和分析，该方法证明了在实证资产定价中应用 LLM 的可行性，为金融领域的 AI 应用提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025 Workshop on Advances in Financial AI",
      "pdf_url": "http://arxiv.org/pdf/2409.17266v2",
      "published_date": "2024-09-25 18:27:35 UTC",
      "updated_date": "2025-03-28 01:02:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:32:29.250914"
    },
    {
      "arxiv_id": "2409.17263v1",
      "title": "Collaborative Comic Generation: Integrating Visual Narrative Theories with AI Models for Enhanced Creativity",
      "title_zh": "协作式漫画生成：整合视觉叙事理论与 AI 模型以提升创造力",
      "authors": [
        "Yi-Chun Chen",
        "Arnav Jhala"
      ],
      "abstract": "This study presents a theory-inspired visual narrative generative system that\nintegrates conceptual principles-comic authoring idioms-with generative and\nlanguage models to enhance the comic creation process. Our system combines\nhuman creativity with AI models to support parts of the generative process,\nproviding a collaborative platform for creating comic content. These\ncomic-authoring idioms, derived from prior human-created image sequences, serve\nas guidelines for crafting and refining storytelling. The system translates\nthese principles into system layers that facilitate comic creation through\nsequential decision-making, addressing narrative elements such as panel\ncomposition, story tension changes, and panel transitions. Key contributions\ninclude integrating machine learning models into the human-AI cooperative comic\ngeneration process, deploying abstract narrative theories into AI-driven comic\ncreation, and a customizable tool for narrative-driven image sequences. This\napproach improves narrative elements in generated image sequences and engages\nhuman creativity in an AI-generative process of comics. We open-source the code\nat https://github.com/RimiChen/Collaborative_Comic_Generation.",
      "tldr_zh": "这篇论文提出了一种协作漫画生成系统，将视觉叙事理论（visual narrative theories）与 AI 模型整合，利用 comic authoring idioms 作为指导原则，支持人类与 AI 的共同创作过程。系统通过顺序决策处理叙事元素，如面板组成、故事张力和过渡变化，从而提升漫画故事的连贯性和创意。关键贡献包括将机器学习模型融入人类-AI 合作框架、将抽象叙事理论应用于 AI 驱动的图像序列生成，以及开发一个可定制的工具来优化叙事驱动内容。该方法显著改善了生成图像的叙事质量，并通过开源代码（https://github.com/RimiChen/Collaborative_Comic_Generation）促进进一步研究和应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted for oral presentation at CREAI2024,\n  ECAI, 2024. However, the author's attendance is currently uncertain due to\n  visa issues",
      "pdf_url": "http://arxiv.org/pdf/2409.17263v1",
      "published_date": "2024-09-25 18:21:01 UTC",
      "updated_date": "2024-09-25 18:21:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:32:43.950637"
    },
    {
      "arxiv_id": "2409.17228v1",
      "title": "Disk2Planet: A Robust and Automated Machine Learning Tool for Parameter Inference in Disk-Planet Systems",
      "title_zh": "Disk2Planet：一个鲁棒",
      "authors": [
        "Shunyuan Mao",
        "Ruobing Dong",
        "Kwang Moo Yi",
        "Lu Lu",
        "Sifan Wang",
        "Paris Perdikaris"
      ],
      "abstract": "We introduce Disk2Planet, a machine learning-based tool to infer key\nparameters in disk-planet systems from observed protoplanetary disk structures.\nDisk2Planet takes as input the disk structures in the form of two-dimensional\ndensity and velocity maps, and outputs disk and planet properties, that is, the\nShakura--Sunyaev viscosity, the disk aspect ratio, the planet--star mass ratio,\nand the planet's radius and azimuth. We integrate the Covariance Matrix\nAdaptation Evolution Strategy (CMA--ES), an evolutionary algorithm tailored for\ncomplex optimization problems, and the Protoplanetary Disk Operator Network\n(PPDONet), a neural network designed to predict solutions of disk--planet\ninteractions. Our tool is fully automated and can retrieve parameters in one\nsystem in three minutes on an Nvidia A100 graphics processing unit. We\nempirically demonstrate that our tool achieves percent-level or higher\naccuracy, and is able to handle missing data and unknown levels of noise.",
      "tldr_zh": "本研究引入了 Disk2Planet，一种基于机器学习的工具，用于从观测到的原行星盘结构自动推断磁盘-行星系统的关键参数。工具以二维密度和速度图作为输入，通过整合 Covariance Matrix Adaptation Evolution Strategy (CMA-ES) 进化算法和 Protoplanetary Disk Operator Network (PPDONet) 神经网络，输出包括 Shakura-Sunyaev viscosity、磁盘宽高比、行星-恒星质量比、行星半径和方位。Disk2Planet 完全自动化，可在 Nvidia A100 GPU 上于三分钟内处理一个系统，并实现百分比级或更高准确性，同时能有效处理缺失数据和未知噪声水平。",
      "categories": [
        "astro-ph.EP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.EP",
      "comment": "Accepted to ApJ",
      "pdf_url": "http://arxiv.org/pdf/2409.17228v1",
      "published_date": "2024-09-25 18:00:01 UTC",
      "updated_date": "2024-09-25 18:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:33:07.489808"
    },
    {
      "arxiv_id": "2409.17144v1",
      "title": "Differential Privacy Regularization: Protecting Training Data Through Loss Function Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Aguilera-Martínez",
        "Fernando Berzal"
      ],
      "abstract": "Training machine learning models based on neural networks requires large\ndatasets, which may contain sensitive information. The models, however, should\nnot expose private information from these datasets. Differentially private SGD\n[DP-SGD] requires the modification of the standard stochastic gradient descent\n[SGD] algorithm for training new models. In this short paper, a novel\nregularization strategy is proposed to achieve the same goal in a more\nefficient manner.",
      "tldr_zh": "这篇论文针对机器学习模型训练中保护敏感数据的隐私问题，提出了一种名为 Differential Privacy Regularization 的新策略，通过在损失函数中添加正则化（Loss Function Regularization）来实现数据保护。相比传统的 DP-SGD 方法，该策略无需修改标准 SGD 算法，从而更高效地防止模型泄露训练数据信息。该方法为隐私保护型模型训练提供了更简便的替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17144v1",
      "published_date": "2024-09-25 17:59:32 UTC",
      "updated_date": "2024-09-25 17:59:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:33:18.635854"
    },
    {
      "arxiv_id": "2409.17143v1",
      "title": "Attention Prompting on Image for Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Runpeng Yu",
        "Weihao Yu",
        "Xinchao Wang"
      ],
      "abstract": "Compared with Large Language Models (LLMs), Large Vision-Language Models\n(LVLMs) can also accept images as input, thus showcasing more interesting\nemergent capabilities and demonstrating impressive performance on various\nvision-language tasks. Motivated by text prompting in LLMs, visual prompting\nhas been explored to enhance LVLMs' capabilities of perceiving visual\ninformation. However, previous visual prompting techniques solely process\nvisual inputs without considering text queries, limiting the models' ability to\nfollow text instructions to complete tasks. To fill this gap, in this work, we\npropose a new prompting technique named Attention Prompting on Image, which\njust simply overlays a text-query-guided attention heatmap on the original\ninput image and effectively enhances LVLM on various tasks. Specifically, we\ngenerate an attention heatmap for the input image dependent on the text query\nwith an auxiliary model like CLIP. Then the heatmap simply multiplies the pixel\nvalues of the original image to obtain the actual input image for the LVLM.\nExtensive experiments on various vison-language benchmarks verify the\neffectiveness of our technique. For example, Attention Prompting on Image\nimproves LLaVA-1.5 by 3.8% and 2.9% on MM-Vet and LLaVA-Wild benchmarks,\nrespectively.",
      "tldr_zh": "本论文提出了一种名为 Attention Prompting on Image 的新视觉提示技术，旨在提升 Large Vision-Language Models (LVLMs) 在处理视觉信息时的能力，特别是通过结合文本查询来解决现有方法的局限性。该方法使用辅助模型如 CLIP 生成基于文本查询的注意力热图（attention heatmap），并将其叠加到原始图像上，以增强模型对任务的理解和执行。实验结果显示，该技术在 MM-Vet 和 LLaVA-Wild 基准上分别使 LLaVA-1.5 模型的性能提高了 3.8% 和 2.9%，验证了其在各种视觉语言任务中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Website, see https://yu-rp.github.io/api-prompting",
      "pdf_url": "http://arxiv.org/pdf/2409.17143v1",
      "published_date": "2024-09-25 17:59:13 UTC",
      "updated_date": "2024-09-25 17:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:33:22.133855"
    },
    {
      "arxiv_id": "2409.17216v1",
      "title": "Data-Centric AI Governance: Addressing the Limitations of Model-Focused Policies",
      "title_zh": "以数据为中心的AI治理：解决模型导向政策的局限性",
      "authors": [
        "Ritwik Gupta",
        "Leah Walker",
        "Rodolfo Corona",
        "Stephanie Fu",
        "Suzanne Petryk",
        "Janet Napolitano",
        "Trevor Darrell",
        "Andrew W. Reddie"
      ],
      "abstract": "Current regulations on powerful AI capabilities are narrowly focused on\n\"foundation\" or \"frontier\" models. However, these terms are vague and\ninconsistently defined, leading to an unstable foundation for governance\nefforts. Critically, policy debates often fail to consider the data used with\nthese models, despite the clear link between data and model performance. Even\n(relatively) \"small\" models that fall outside the typical definitions of\nfoundation and frontier models can achieve equivalent outcomes when exposed to\nsufficiently specific datasets. In this work, we illustrate the importance of\nconsidering dataset size and content as essential factors in assessing the\nrisks posed by models both today and in the future. More broadly, we emphasize\nthe risk posed by over-regulating reactively and provide a path towards\ncareful, quantitative evaluation of capabilities that can lead to a simplified\nregulatory environment.",
      "tldr_zh": "本文指出，当前AI治理政策过度关注“foundation models”和“frontier models”，这些术语定义模糊，导致监管基础不稳定，并忽略了数据与模型性能的紧密关联。即使较小模型通过特定数据集也能实现类似效果，强调数据集的大小和内容是评估风险的关键。研究提出以数据为中心（data-centric）的AI治理框架，通过量化评估来避免过度反应式监管，从而简化监管环境并提升治理有效性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17216v1",
      "published_date": "2024-09-25 17:59:01 UTC",
      "updated_date": "2024-09-25 17:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:33:32.884978"
    },
    {
      "arxiv_id": "2409.17141v1",
      "title": "FineZip : Pushing the Limits of Large Language Models for Practical Lossless Text Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Fazal Mittu",
        "Yihuan Bu",
        "Akshat Gupta",
        "Ashok Devireddy",
        "Alp Eren Ozdarendeli",
        "Anant Singh",
        "Gopala Anumanchipalli"
      ],
      "abstract": "While the language modeling objective has been shown to be deeply connected\nwith compression, it is surprising that modern LLMs are not employed in\npractical text compression systems. In this paper, we provide an in-depth\nanalysis of neural network and transformer-based compression techniques to\nanswer this question. We compare traditional text compression systems with\nneural network and LLM-based text compression methods. Although LLM-based\nsystems significantly outperform conventional compression methods, they are\nhighly impractical. Specifically, LLMZip, a recent text compression system\nusing Llama3-8B requires 9.5 days to compress just 10 MB of text, although with\nhuge improvements in compression ratios. To overcome this, we present FineZip -\na novel LLM-based text compression system that combines ideas of online\nmemorization and dynamic context to reduce the compression time immensely.\nFineZip can compress the above corpus in approximately 4 hours compared to 9.5\ndays, a 54 times improvement over LLMZip and comparable performance. FineZip\noutperforms traditional algorithmic compression methods with a large margin,\nimproving compression ratios by approximately 50\\%. With this work, we take the\nfirst step towards making lossless text compression with LLMs a reality. While\nFineZip presents a significant step in that direction, LLMs are still not a\nviable solution for large-scale text compression. We hope our work paves the\nway for future research and innovation to solve this problem.",
      "tldr_zh": "这篇论文分析了大型语言模型 (LLMs) 在无损文本压缩中的潜力，指出尽管 LLMs 如 LLMZip (基于 Llama3-8B) 可大幅提升压缩比，但其压缩时间过长（如需 9.5 天处理 10 MB 文本），导致实际应用不切实际。作者提出 FineZip，一种创新的 LLM-based 系统，结合在线记忆 (online memorization) 和动态上下文 (dynamic context)，将压缩时间缩短至约 4 小时，提高 54 倍效率，同时将压缩比比传统算法方法提升约 50%。这项工作标志着 LLMs 在实用文本压缩领域的首次可行尝试，但作者强调，LLMs 仍需进一步优化以应对大规模应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17141v1",
      "published_date": "2024-09-25 17:58:35 UTC",
      "updated_date": "2024-09-25 17:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:33:56.017889"
    },
    {
      "arxiv_id": "2409.17140v2",
      "title": "AXIS: Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Junting Lu",
        "Zhiyang Zhang",
        "Fangkai Yang",
        "Jue Zhang",
        "Lu Wang",
        "Chao Du",
        "Qingwei Lin",
        "Saravan Rajmohan",
        "Dongmei Zhang",
        "Qi Zhang"
      ],
      "abstract": "Multimodal large language models (MLLMs) have enabled LLM-based agents to\ndirectly interact with application user interfaces (UIs), enhancing agents'\nperformance in complex tasks. However, these agents often suffer from high\nlatency and low reliability due to the extensive sequential UI interactions. To\naddress this issue, we propose AXIS, a novel LLM-based agents framework that\nprioritize actions through application programming interfaces (APIs) over UI\nactions. This framework also facilitates the creation and expansion of APIs\nthrough automated exploration of applications. Our experiments on Microsoft\nWord demonstrate that AXIS reduces task completion time by 65%-70% and\ncognitive workload by 38%-53%, while maintaining accuracy of 97%-98% compared\nto humans. Our work contributes to a new human-agent-computer interaction\n(HACI) framework and explores a fresh UI design principle for application\nproviders to turn applications into agents in the era of LLMs, paving the way\ntowards an agent-centric operating system (Agent OS).",
      "tldr_zh": "本研究提出 AXIS 框架，这是一种以 API 为优先的 LLM-based agents 系统，旨在提升人类-代理-计算机交互 (HACI) 的效率，解决现有 MLLMs 代理因频繁 UI 交互导致的高延迟和低可靠性问题。AXIS 通过自动探索应用来创建和扩展 API，从而减少顺序交互并优化代理性能。在 Microsoft Word 的实验中，该框架将任务完成时间降低 65%-70%，认知工作量减少 38%-53%，同时保持 97%-98% 的准确率，与人类水平相当。该工作贡献了一个新型 HACI 框架，并探索了将应用转化为代理的 UI 设计原则，为 Agent OS 的发展铺平道路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17140v2",
      "published_date": "2024-09-25 17:58:08 UTC",
      "updated_date": "2025-05-19 16:12:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:33:57.415906"
    },
    {
      "arxiv_id": "2409.17126v1",
      "title": "Blox-Net: Generative Design-for-Robot-Assembly Using VLM Supervision, Physics Simulation, and a Robot with Reset",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Goldberg",
        "Kavish Kondap",
        "Tianshuang Qiu",
        "Zehan Ma",
        "Letian Fu",
        "Justin Kerr",
        "Huang Huang",
        "Kaiyuan Chen",
        "Kuan Fang",
        "Ken Goldberg"
      ],
      "abstract": "Generative AI systems have shown impressive capabilities in creating text,\ncode, and images. Inspired by the rich history of research in industrial\n''Design for Assembly'', we introduce a novel problem: Generative\nDesign-for-Robot-Assembly (GDfRA). The task is to generate an assembly based on\na natural language prompt (e.g., ''giraffe'') and an image of available\nphysical components, such as 3D-printed blocks. The output is an assembly, a\nspatial arrangement of these components, and instructions for a robot to build\nthis assembly. The output must 1) resemble the requested object and 2) be\nreliably assembled by a 6 DoF robot arm with a suction gripper. We then present\nBlox-Net, a GDfRA system that combines generative vision language models with\nwell-established methods in computer vision, simulation, perturbation analysis,\nmotion planning, and physical robot experimentation to solve a class of GDfRA\nproblems with minimal human supervision. Blox-Net achieved a Top-1 accuracy of\n63.5% in the ''recognizability'' of its designed assemblies (eg, resembling\ngiraffe as judged by a VLM). These designs, after automated perturbation\nredesign, were reliably assembled by a robot, achieving near-perfect success\nacross 10 consecutive assembly iterations with human intervention only during\nreset prior to assembly. Surprisingly, this entire design process from textual\nword (''giraffe'') to reliable physical assembly is performed with zero human\nintervention.",
      "tldr_zh": "本研究引入了Generative Design-for-Robot-Assembly (GDfRA)新问题，即基于自然语言提示（如“giraffe”）和可用组件图像，生成可由机器人可靠组装的物体空间排列及其指令。Blox-Net系统结合了VLM监督、物理模拟、扰动分析、运动规划和机器人实验，实现了从文本到物理组装的全自动化过程。实验结果显示，Blox-Net在设计的可识别性上达到了63.5%的Top-1准确率，且经过自动扰动重设计后，机器人能在10次组装迭代中近乎完美成功，仅需人类在重置时介入。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 7 Figures",
      "pdf_url": "http://arxiv.org/pdf/2409.17126v1",
      "published_date": "2024-09-25 17:42:20 UTC",
      "updated_date": "2024-09-25 17:42:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:34:19.290298"
    },
    {
      "arxiv_id": "2409.17125v1",
      "title": "On-orbit Servicing for Spacecraft Collision Avoidance With Autonomous Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Susmitha Patnala",
        "Adam Abdin"
      ],
      "abstract": "This study develops an AI-based implementation of autonomous On-Orbit\nServicing (OOS) mission to assist with spacecraft collision avoidance maneuvers\n(CAMs). We propose an autonomous `servicer' trained with Reinforcement Learning\n(RL) to autonomously detect potential collisions between a target satellite and\nspace debris, rendezvous and dock with endangered satellites, and execute\noptimal CAM. The RL model integrates collision risk estimates, satellite\nspecifications, and debris data to generate an optimal maneuver matrix for OOS\nrendezvous and collision prevention. We employ the Cross-Entropy algorithm to\nfind optimal decision policies efficiently. Initial results demonstrate the\nfeasibility of autonomous robotic OOS for collision avoidance services,\nfocusing on one servicer spacecraft to one endangered satellite scenario.\nHowever, merging spacecraft rendezvous and optimal CAM presents significant\ncomplexities. We discuss design challenges and critical parameters for the\nsuccessful implementation of the framework presented through a case study.",
      "tldr_zh": "本研究提出了一种基于 AI 的自主轨道服务 (OOS) 系统，用于协助卫星执行碰撞避免机动 (CAM)，以提升太空碎片威胁下的安全决策。系统通过强化学习 (RL) 训练“服务者”智能体来检测潜在碰撞风险、与受威胁卫星对接，并整合碰撞风险估计、卫星规格和碎片数据生成最优机动矩阵，同时采用 Cross-Entropy 算法高效优化决策策略。初步实验结果验证了该框架在单一服务者与单一卫星场景中的可行性，但强调了整合对接和机动操作的复杂性，并讨论了关键设计挑战和参数。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The first joint European Space Agency SPAICE Conference / IAA\n  Conference on AI in and for Space",
      "pdf_url": "http://arxiv.org/pdf/2409.17125v1",
      "published_date": "2024-09-25 17:40:37 UTC",
      "updated_date": "2024-09-25 17:40:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:34:31.613953"
    },
    {
      "arxiv_id": "2409.17213v6",
      "title": "Plurals: A System for Guiding LLMs Via Simulated Social Ensembles",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Ashkinaze",
        "Emily Fry",
        "Narendra Edara",
        "Eric Gilbert",
        "Ceren Budak"
      ],
      "abstract": "Recent debates raised concerns that language models may favor certain\nviewpoints. But what if the solution is not to aim for a 'view from nowhere'\nbut rather to leverage different viewpoints? We introduce Plurals, a system and\nPython library for pluralistic AI deliberation. Plurals consists of Agents\n(LLMs, optionally with personas) which deliberate within customizable\nStructures, with Moderators overseeing deliberation. Plurals is a generator of\nsimulated social ensembles. Plurals integrates with government datasets to\ncreate nationally representative personas, includes deliberation templates\ninspired by deliberative democracy, and allows users to customize both\ninformation-sharing structures and deliberation behavior within Structures. Six\ncase studies demonstrate fidelity to theoretical constructs and efficacy. Three\nrandomized experiments show simulated focus groups produced output resonant\nwith an online sample of the relevant audiences (chosen over zero-shot\ngeneration in 75% of trials). Plurals is both a paradigm and a concrete system\nfor pluralistic AI. The Plurals library is available at\nhttps://github.com/josh-ashkinaze/plurals and will be continually updated.",
      "tldr_zh": "该论文引入了Plurals系统，这是一个用于指导LLMs的多元AI审议框架，通过模拟社会团体（Agents、Structures和Moderators）来整合不同观点，避免单一视角偏差。系统允许用户自定义审议结构、整合政府数据集创建代表性persona，并使用审议民主启发的模板进行模拟。实验结果显示，Plurals在六项案例研究中展现出对理论构建的忠实性和有效性，并在三个随机实验中，其输出在75%的试验中优于零样本生成，与真实受众更一致。作为开源库，Plurals提供了实际工具，支持多元AI发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "CHI 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.17213v6",
      "published_date": "2024-09-25 17:38:39 UTC",
      "updated_date": "2025-03-22 20:30:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:34:33.926866"
    },
    {
      "arxiv_id": "2409.17115v2",
      "title": "Programming Every Example: Lifting Pre-training Data Quality Like Experts at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Zhou",
        "Zengzhi Wang",
        "Qian Liu",
        "Junlong Li",
        "Pengfei Liu"
      ],
      "abstract": "Large language model pre-training has traditionally relied on human experts\nto craft heuristics for improving the corpora quality, resulting in numerous\nrules developed to date. However, these rules lack the flexibility to address\nthe unique characteristics of individual example effectively. Meanwhile,\napplying tailored rules to every example is impractical for human experts. In\nthis paper, we demonstrate that even small language models, with as few as 0.3B\nparameters, can exhibit substantial data refining capabilities comparable to\nthose of human experts. We introduce Programming Every Example (ProX), a novel\nframework that treats data refinement as a programming task, enabling models to\nrefine corpora by generating and executing fine-grained operations, such as\nstring normalization, for each individual example at scale. Experimental\nresults show that models pre-trained on ProX-curated data outperform either\noriginal data or data filtered by other selection methods by more than 2%\nacross various downstream benchmarks. Its effectiveness spans various model\nsizes and pre-training corpora, including C4, RedPajama-V2, FineWeb,\nFineWeb-Edu, and DCLM. Furthermore, ProX exhibits significant potential in\ndomain-specific continual pre-training: without domain specific design, models\ntrained on OpenWebMath refined by ProX outperform human-crafted rule-based\nmethods, improving average accuracy by 7.6% over Mistral-7B, with 14.6% for\nLlama-2-7B and 20.3% for CodeLlama-7B, all within 10B tokens to be comparable\nto models like Llemma-7B trained on 200B tokens. Further analysis highlights\nthat ProX significantly saves training FLOPs, offering a promising path for\nefficient LLM pre-training. We are open-sourcing ProX with >500B corpus,\nmodels, and sharing all training and implementation details for reproducible\nresearch and future innovation. Code: https://github.com/GAIR-NLP/ProX",
      "tldr_zh": "该论文提出ProX框架，使用小型语言模型（如0.3B参数）来提升Large Language Model的预训练数据质量，模拟专家行为通过生成和执行细粒度操作（如字符串规范化）针对每个示例进行个性化精炼，从而克服传统启发式规则的灵活性不足。实验结果显示，基于ProX精炼的数据，模型在各种下游基准上性能提升超过2%，并适用于不同模型大小和语料库如C4、RedPajama-V2等。在领域特定持续预训练中，ProX无需特定设计即可显著提高准确率，例如在OpenWebMath上，Mistral-7B模型的平均准确率提升7.6%，而Llama-2-7B和CodeLlama-7B分别提升14.6%和20.3%，并显著节省训练FLOPs。该框架开源了超过500B的语料库、模型和实现细节，促进了可复现研究和创新。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "47 pages, 13 figures, 34 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.17115v2",
      "published_date": "2024-09-25 17:28:13 UTC",
      "updated_date": "2025-02-14 16:44:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:34:46.283748"
    },
    {
      "arxiv_id": "2409.17109v1",
      "title": "Unveiling Ontological Commitment in Multi-Modal Foundation Models",
      "title_zh": "揭示多模态基础模型中的本体论承诺",
      "authors": [
        "Mert Keser",
        "Gesina Schwalbe",
        "Niki Amini-Naieni",
        "Matthias Rottmann",
        "Alois Knoll"
      ],
      "abstract": "Ontological commitment, i.e., used concepts, relations, and assumptions, are\na corner stone of qualitative reasoning (QR) models. The state-of-the-art for\nprocessing raw inputs, though, are deep neural networks (DNNs), nowadays often\nbased off from multimodal foundation models. These automatically learn rich\nrepresentations of concepts and respective reasoning. Unfortunately, the\nlearned qualitative knowledge is opaque, preventing easy inspection,\nvalidation, or adaptation against available QR models. So far, it is possible\nto associate pre-defined concepts with latent representations of DNNs, but\nextractable relations are mostly limited to semantic similarity. As a next step\ntowards QR for validation and verification of DNNs: Concretely, we propose a\nmethod that extracts the learned superclass hierarchy from a multimodal DNN for\na given set of leaf concepts. Under the hood we (1) obtain leaf concept\nembeddings using the DNN's textual input modality; (2) apply hierarchical\nclustering to them, using that DNNs encode semantic similarities via vector\ndistances; and (3) label the such-obtained parent concepts using search in\navailable ontologies from QR. An initial evaluation study shows that meaningful\nontological class hierarchies can be extracted from state-of-the-art foundation\nmodels. Furthermore, we demonstrate how to validate and verify a DNN's learned\nrepresentations against given ontologies. Lastly, we discuss potential future\napplications in the context of QR.",
      "tldr_zh": "该论文探讨了多模态基础模型中的本体承诺（ontological commitment），即模型使用的概念、关系和假设，并针对深度神经网络（DNNs）的不透明性提出解决方案，以支持定性推理（QR）模型的验证和适应。研究方法包括：（1）使用DNNs的文本输入模式获取叶概念嵌入；（2）应用层次聚类基于向量距离编码的语义相似性进行聚类；（3）通过在可用QR本体中搜索来标记父概念，从而提取学得的超类层次结构。初步评估显示，该方法能从最先进的基础模型中提取有意义的本体类层次，并证明其在验证和验证DNNs表示方面的有效性，为QR的未来应用提供了潜在方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Qualitative Reasoning Workshop 2024 (QR2024) colocated with ECAI2024,\n  camera-ready submission; first two authors contributed equally; 10 pages, 4\n  figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.17109v1",
      "published_date": "2024-09-25 17:24:27 UTC",
      "updated_date": "2024-09-25 17:24:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:35:00.997619"
    },
    {
      "arxiv_id": "2409.17092v1",
      "title": "Accumulator-Aware Post-Training Quantization",
      "title_zh": "累加器感知的训练后量化",
      "authors": [
        "Ian Colbert",
        "Fabian Grob",
        "Giuseppe Franco",
        "Jinjie Zhang",
        "Rayan Saab"
      ],
      "abstract": "Several recent studies have investigated low-precision accumulation,\nreporting improvements in throughput, power, and area across various platforms.\nHowever, the accompanying proposals have only considered the quantization-aware\ntraining (QAT) paradigm, in which models are fine-tuned or trained from scratch\nwith quantization in the loop. As models continue to grow in size, QAT\ntechniques become increasingly more expensive, which has motivated the recent\nsurge in post-training quantization (PTQ) research. To the best of our\nknowledge, ours marks the first formal study of accumulator-aware quantization\nin the PTQ setting. To bridge this gap, we introduce AXE, a practical framework\nof accumulator-aware extensions designed to endow overflow avoidance guarantees\nto existing layer-wise PTQ algorithms. We theoretically motivate AXE and\ndemonstrate its flexibility by implementing it on top of two state-of-the-art\nPTQ algorithms: GPFQ and OPTQ. We further generalize AXE to support multi-stage\naccumulation for the first time, opening the door for full datapath\noptimization and scaling to large language models (LLMs). We evaluate AXE\nacross image classification and language generation models, and observe\nsignificant improvements in the trade-off between accumulator bit width and\nmodel accuracy over baseline methods.",
      "tldr_zh": "该研究首次探讨了后训练量化（PTQ）中的累加器感知量化问题，以解决传统量化感知训练（QAT）的高成本问题。作者引入了AXE框架，这是一个实用的扩展，用于为现有的层级PTQ算法（如GPFQ和OPTQ）提供溢出避免保证，并首次支持多阶段累加以优化全数据路径。实验结果显示，AXE在图像分类和语言生成模型上显著改善了累加器位宽与模型准确率之间的权衡，支持扩展到大型语言模型（LLMs）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17092v1",
      "published_date": "2024-09-25 16:58:35 UTC",
      "updated_date": "2024-09-25 16:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:35:14.282177"
    },
    {
      "arxiv_id": "2409.17091v2",
      "title": "Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Xinrui Zhou",
        "Yuhao Huang",
        "Haoran Dou",
        "Shijing Chen",
        "Ao Chang",
        "Jia Liu",
        "Weiran Long",
        "Jian Zheng",
        "Erjiao Xu",
        "Jie Ren",
        "Ruobing Huang",
        "Jun Cheng",
        "Wufeng Xue",
        "Dong Ni"
      ],
      "abstract": "In the medical field, the limited availability of large-scale datasets and\nlabor-intensive annotation processes hinder the performance of deep models.\nDiffusion-based generative augmentation approaches present a promising solution\nto this issue, having been proven effective in advancing downstream medical\nrecognition tasks. Nevertheless, existing works lack sufficient semantic and\nsequential steerability for challenging video/3D sequence generation, and\nneglect quality control of noisy synthesized samples, resulting in unreliable\nsynthetic databases and severely limiting the performance of downstream tasks.\nIn this work, we present Ctrl-GenAug, a novel and general generative\naugmentation framework that enables highly semantic- and sequential-customized\nsequence synthesis and suppresses incorrectly synthesized samples, to aid\nmedical sequence classification. Specifically, we first design a multimodal\nconditions-guided sequence generator for controllably synthesizing\ndiagnosis-promotive samples. A sequential augmentation module is integrated to\nenhance the temporal/stereoscopic coherence of generated samples. Then, we\npropose a noisy synthetic data filter to suppress unreliable cases at semantic\nand sequential levels. Extensive experiments on 3 medical datasets, using 11\nnetworks trained on 3 paradigms, comprehensively analyze the effectiveness and\ngenerality of Ctrl-GenAug, particularly in underrepresented high-risk\npopulations and out-domain conditions.",
      "tldr_zh": "该研究针对医疗领域中数据集规模有限和标注过程劳累的问题，提出了Ctrl-GenAug，一种可控生成增强框架，用于改进医疗序列分类。框架包括多模态条件引导序列生成器和顺序增强模块，以实现高度可定制的序列合成，并整合噪声合成数据过滤器来抑制不可靠样本。在3个医疗数据集上的广泛实验显示，Ctrl-GenAug显著提升了下游任务性能，尤其在高风险人群和域外条件下，证明了其有效性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 9 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.17091v2",
      "published_date": "2024-09-25 16:58:19 UTC",
      "updated_date": "2025-04-13 00:49:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:35:22.347979"
    },
    {
      "arxiv_id": "2409.17087v1",
      "title": "SEN12-WATER: A New Dataset for Hydrological Applications and its Benchmarking",
      "title_zh": "SEN12-WATER：用于水文应用的新数据集及其基准测试",
      "authors": [
        "Luigi Russo",
        "Francesco Mauro",
        "Alessandro Sebastianelli",
        "Paolo Gamba",
        "Silvia Liberata Ullo"
      ],
      "abstract": "Climate change and increasing droughts pose significant challenges to water\nresource management around the world. These problems lead to severe water\nshortages that threaten ecosystems, agriculture, and human communities. To\nadvance the fight against these challenges, we present a new dataset,\nSEN12-WATER, along with a benchmark using a novel end-to-end Deep Learning (DL)\nframework for proactive drought-related analysis. The dataset, identified as a\nspatiotemporal datacube, integrates SAR polarization, elevation, slope, and\nmultispectral optical bands. Our DL framework enables the analysis and\nestimation of water losses over time in reservoirs of interest, revealing\nsignificant insights into water dynamics for drought analysis by examining\ntemporal changes in physical quantities such as water volume. Our methodology\ntakes advantage of the multitemporal and multimodal characteristics of the\nproposed dataset, enabling robust generalization and advancing understanding of\ndrought, contributing to climate change resilience and sustainable water\nresource management. The proposed framework involves, among the several\ncomponents, speckle noise removal from SAR data, a water body segmentation\nthrough a U-Net architecture, the time series analysis, and the predictive\ncapability of a Time-Distributed-Convolutional Neural Network (TD-CNN). Results\nare validated through ground truth data acquired on-ground via dedicated\nsensors and (tailored) metrics, such as Precision, Recall, Intersection over\nUnion, Mean Squared Error, Structural Similarity Index Measure and Peak\nSignal-to-Noise Ratio.",
      "tldr_zh": "本研究针对气候变化和干旱带来的水资源管理挑战，引入了一个新数据集 SEN12-WATER，这是一个时空数据立方体，整合了 SAR 偏振、 elevation、 slope 和多光谱光学波段，用于水文应用。研究提出一个端到端 Deep Learning (DL) 框架，包括 SAR 数据去噪、U-Net 架构的水体分割、时间序列分析以及 Time-Distributed-Convolutional Neural Network (TD-CNN) 的预测能力，以分析水库水损失并揭示干旱相关水动态。实验结果通过实地传感器获取的地面真实数据和指标（如 Precision、Recall、Intersection over Union、Mean Squared Error 等）验证，展示了框架的鲁棒性和泛化能力，从而提升了对干旱的理解并支持可持续水资源管理。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "Submitted to IEEE Transactions on Geoscience and Remote Sensing",
      "pdf_url": "http://arxiv.org/pdf/2409.17087v1",
      "published_date": "2024-09-25 16:50:59 UTC",
      "updated_date": "2024-09-25 16:50:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:35:35.973261"
    },
    {
      "arxiv_id": "2409.17069v1",
      "title": "The Effect of Perceptual Metrics on Music Representation Learning for Genre Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Tashi Namgyal",
        "Alexander Hepburn",
        "Raul Santos-Rodriguez",
        "Valero Laparra",
        "Jesus Malo"
      ],
      "abstract": "The subjective quality of natural signals can be approximated with objective\nperceptual metrics. Designed to approximate the perceptual behaviour of human\nobservers, perceptual metrics often reflect structures found in natural signals\nand neurological pathways. Models trained with perceptual metrics as loss\nfunctions can capture perceptually meaningful features from the structures held\nwithin these metrics. We demonstrate that using features extracted from\nautoencoders trained with perceptual losses can improve performance on music\nunderstanding tasks, i.e. genre classification, over using these metrics\ndirectly as distances when learning a classifier. This result suggests improved\ngeneralisation to novel signals when using perceptual metrics as loss functions\nfor representation learning.",
      "tldr_zh": "这篇论文探讨了感知指标(perceptual metrics)对音乐表示学习(representation learning)的影响，特别是用于音乐流派分类(genre classification)。研究发现，通过将感知指标作为损失函数训练自编码器(autoencoders)，从模型中提取的特征能够提升音乐理解任务的性能。相比直接使用这些指标作为距离函数，这种方法显著改善了对新信号的泛化能力，从而更好地捕捉音乐的感知结构。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "arXiv admin note: text overlap with arXiv:2312.03455",
      "pdf_url": "http://arxiv.org/pdf/2409.17069v1",
      "published_date": "2024-09-25 16:29:21 UTC",
      "updated_date": "2024-09-25 16:29:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:35:50.716552"
    },
    {
      "arxiv_id": "2409.17066v2",
      "title": "VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Liu",
        "Jicheng Wen",
        "Yang Wang",
        "Shengyu Ye",
        "Li Lyna Zhang",
        "Ting Cao",
        "Cheng Li",
        "Mao Yang"
      ],
      "abstract": "Scaling model size significantly challenges the deployment and inference of\nLarge Language Models (LLMs). Due to the redundancy in LLM weights, recent\nresearch has focused on pushing weight-only quantization to extremely low-bit\n(even down to 2 bits). It reduces memory requirements, optimizes storage costs,\nand decreases memory bandwidth needs during inference. However, due to\nnumerical representation limitations, traditional scalar-based weight\nquantization struggles to achieve such extreme low-bit. Recent research on\nVector Quantization (VQ) for LLMs has demonstrated the potential for extremely\nlow-bit model quantization by compressing vectors into indices using lookup\ntables.\n  In this paper, we introduce Vector Post-Training Quantization (VPTQ) for\nextremely low-bit quantization of LLMs. We use Second-Order Optimization to\nformulate the LLM VQ problem and guide our quantization algorithm design by\nsolving the optimization. We further refine the weights using\nChannel-Independent Second-Order Optimization for a granular VQ. In addition,\nby decomposing the optimization problem, we propose a brief and effective\ncodebook initialization algorithm. We also extend VPTQ to support residual and\noutlier quantization, which enhances model accuracy and further compresses the\nmodel. Our experimental results show that VPTQ reduces model quantization\nperplexity by $0.01$-$0.34$ on LLaMA-2, $0.38$-$0.68$ on Mistral-7B,\n$4.41$-$7.34$ on LLaMA-3 over SOTA at 2-bit, with an average accuracy\nimprovement of $0.79$-$1.5\\%$ on LLaMA-2, $1\\%$ on Mistral-7B, $11$-$22\\%$ on\nLLaMA-3 on QA tasks on average. We only utilize $10.4$-$18.6\\%$ of the\nquantization algorithm execution time, resulting in a $1.6$-$1.8\\times$\nincrease in inference throughput compared to SOTA.",
      "tldr_zh": "这篇论文提出了VPTQ，一种针对Large Language Models (LLMs)的极低位向量后训练量化方法，通过Second-Order Optimization优化量化问题，并引入Channel-Independent Second-Order Optimization来细化权重量化。论文还设计了简洁的codebook初始化算法，并扩展VPTQ支持residual和outlier量化，以进一步提升模型准确性和压缩效率。实验结果显示，VPTQ在2-bit量化下显著降低了LLaMA-2、Mistral-7B和LLaMA-3的perplexity（如LLaMA-2降低0.01-0.34），并在QA任务上平均提高了0.79-1.5%的准确率，同时量化算法执行时间仅为SOTA的10.4-18.6%，推断吞吐量提升1.6-1.8倍。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "EMNLP 2024, Main, Poster",
      "pdf_url": "http://arxiv.org/pdf/2409.17066v2",
      "published_date": "2024-09-25 16:25:45 UTC",
      "updated_date": "2024-10-22 11:47:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:36:00.470770"
    },
    {
      "arxiv_id": "2409.17063v1",
      "title": "Benchmarking Domain Generalization Algorithms in Computational Pathology",
      "title_zh": "在计算病理学中对领域泛化算法进行基准测试",
      "authors": [
        "Neda Zamanitajeddin",
        "Mostafa Jahanifar",
        "Kesi Xu",
        "Fouzia Siraj",
        "Nasir Rajpoot"
      ],
      "abstract": "Deep learning models have shown immense promise in computational pathology\n(CPath) tasks, but their performance often suffers when applied to unseen data\ndue to domain shifts. Addressing this requires domain generalization (DG)\nalgorithms. However, a systematic evaluation of DG algorithms in the CPath\ncontext is lacking. This study aims to benchmark the effectiveness of 30 DG\nalgorithms on 3 CPath tasks of varying difficulty through 7,560\ncross-validation runs. We evaluate these algorithms using a unified and robust\nplatform, incorporating modality-specific techniques and recent advances like\npretrained foundation models. Our extensive cross-validation experiments\nprovide insights into the relative performance of various DG strategies. We\nobserve that self-supervised learning and stain augmentation consistently\noutperform other methods, highlighting the potential of pretrained models and\ndata augmentation. Furthermore, we introduce a new pan-cancer tumor detection\ndataset (HISTOPANTUM) as a benchmark for future research. This study offers\nvaluable guidance to researchers in selecting appropriate DG approaches for\nCPath tasks.",
      "tldr_zh": "这篇论文对30个领域泛化(DG)算法在计算病理学(CPath)中的表现进行了基准测试，以解决深度学习模型在领域转移时性能下降的问题。研究通过7,560次交叉验证实验，在3个不同难度的CPath任务上评估这些算法，使用统一的平台结合预训练基础模型和模式特定技术如染色增强(stain augmentation)。结果显示，自监督学习和染色增强方法 consistently 优于其他策略，提供宝贵的DG方法选择指导。同时，论文引入了一个新的泛癌肿瘤检测数据集(HISTOPANTUM)，作为未来研究的基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17063v1",
      "published_date": "2024-09-25 16:21:43 UTC",
      "updated_date": "2024-09-25 16:21:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:36:12.061771"
    },
    {
      "arxiv_id": "2409.17208v2",
      "title": "First Place Solution to the ECCV 2024 BRAVO Challenge: Evaluating Robustness of Vision Foundation Models for Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Tommie Kerssies",
        "Daan de Geus",
        "Gijs Dubbelman"
      ],
      "abstract": "In this report, we present the first place solution to the ECCV 2024 BRAVO\nChallenge, where a model is trained on Cityscapes and its robustness is\nevaluated on several out-of-distribution datasets. Our solution leverages the\npowerful representations learned by vision foundation models, by attaching a\nsimple segmentation decoder to DINOv2 and fine-tuning the entire model. This\napproach outperforms more complex existing approaches, and achieves first place\nin the challenge. Our code is publicly available at\nhttps://github.com/tue-mps/benchmark-vfm-ss.",
      "tldr_zh": "本研究介绍了在 ECCV 2024 BRAVO Challenge 中的第一名解决方案，该挑战评估视觉基础模型在语义分割任务的鲁棒性。方法基于 DINOv2 的强大表示，通过附加一个简单的分割解码器并对整个模型进行微调，并在 Cityscapes 数据集上训练，以应对 out-of-distribution 数据集的挑战。该方法优于更复杂的现有方法，并在挑战中取得领先成绩，代码已公开在 GitHub 上。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "v2 fixes ECE and FPR@95, among other small changes. arXiv admin note:\n  substantial text overlap with arXiv:2409.15107",
      "pdf_url": "http://arxiv.org/pdf/2409.17208v2",
      "published_date": "2024-09-25 16:15:06 UTC",
      "updated_date": "2024-10-08 10:09:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:36:23.635539"
    },
    {
      "arxiv_id": "2409.17055v2",
      "title": "DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data",
      "title_zh": "DRIM：从不完整多模态医疗数据中学习解耦表示",
      "authors": [
        "Lucas Robinet",
        "Ahmad Berjaoui",
        "Ziad Kheil",
        "Elizabeth Cohen-Jonathan Moyal"
      ],
      "abstract": "Real-life medical data is often multimodal and incomplete, fueling the\ngrowing need for advanced deep learning models capable of integrating them\nefficiently. The use of diverse modalities, including histopathology slides,\nMRI, and genetic data, offers unprecedented opportunities to improve prognosis\nprediction and to unveil new treatment pathways. Contrastive learning, widely\nused for deriving representations from paired data in multimodal tasks, assumes\nthat different views contain the same task-relevant information and leverages\nonly shared information. This assumption becomes restrictive when handling\nmedical data since each modality also harbors specific knowledge relevant to\ndownstream tasks. We introduce DRIM, a new multimodal method for capturing\nthese shared and unique representations, despite data sparsity. More\nspecifically, given a set of modalities, we aim to encode a representation for\neach one that can be divided into two components: one encapsulating\npatient-related information common across modalities and the other,\nencapsulating modality-specific details. This is achieved by increasing the\nshared information among different patient modalities while minimizing the\noverlap between shared and unique components within each modality. Our method\noutperforms state-of-the-art algorithms on glioma patients survival prediction\ntasks, while being robust to missing modalities. To promote reproducibility,\nthe code is made publicly available at https://github.com/Lucas-rbnt/DRIM",
      "tldr_zh": "本论文提出 DRIM 方法，用于从不完整的多模态医疗数据（如组织病理学切片、MRI 和遗传数据）中学习分离的表示，解决现有对比学习方法的局限性，即忽略了每个模态的独特知识。DRIM 通过编码每个模态的两个组件——跨模态的患者相关共享信息和模态特定的独特细节——来增加不同模态间的共享信息，同时最小化共享与独特组件的重叠，从而提升数据处理效率。该方法在神经胶质瘤患者生存预测任务上优于现有算法，并对缺失模态表现出鲁棒性，代码已在 GitHub 上公开以促进可重复性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17055v2",
      "published_date": "2024-09-25 16:13:57 UTC",
      "updated_date": "2024-10-01 15:47:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:36:36.307120"
    },
    {
      "arxiv_id": "2409.17054v1",
      "title": "Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia",
      "title_zh": "翻译失败",
      "authors": [
        "Azmul Asmar Irfan",
        "Nur Ahmad Khatim",
        "Mansur M. Arief"
      ],
      "abstract": "One of the key issues contributing to inefficiency in Puskesmas is the\ntime-consuming nature of doctor-patient interactions. Doctors need to conduct\nthorough consultations, which include diagnosing the patient's condition,\nproviding treatment advice, and transcribing detailed notes into medical\nrecords. In regions with diverse linguistic backgrounds, doctors often have to\nask clarifying questions, further prolonging the process. While diagnosing is\nessential, transcription and summarization can often be automated using AI to\nimprove time efficiency and help doctors enhance care quality and enable early\ndiagnosis and intervention. This paper proposes a solution using a localized\nlarge language model (LLM) to transcribe, translate, and summarize\ndoctor-patient conversations. We utilize the Whisper model for transcription\nand GPT-3 to summarize them into the ePuskemas medical records format. This\nsystem is implemented as an add-on to an existing web browser extension,\nallowing doctors to fill out patient forms while talking. By leveraging this\nsolution for real-time transcription, translation, and summarization, doctors\ncan improve the turnaround time for patient care while enhancing the quality of\nrecords, which become more detailed and insightful for future visits. This\ninnovation addresses challenges like overcrowded facilities and the\nadministrative burden on healthcare providers in Indonesia. We believe this\nsolution will help doctors save time, provide better care, and produce more\naccurate medical records, representing a significant step toward modernizing\nhealthcare and ensuring patients receive timely, high-quality care, even in\nresource-constrained settings.",
      "tldr_zh": "这篇论文针对印尼 Puskesmas 中医生-患者互动耗时的效率问题，提出一种利用 LLM 的解决方案，实现实时转录、翻译和总结对话。方法包括使用 Whisper 模型进行语音转录，GPT-3 模型生成摘要，并将结果整合到 ePuskesmas 医疗记录格式中，作为现有浏览器扩展的附加功能。实验表明，该系统能显著节省医生时间，提高记录详细性和洞察力，从而缓解医疗设施拥挤、减轻行政负担，并促进及时、高质量的患者护理。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17054v1",
      "published_date": "2024-09-25 16:13:42 UTC",
      "updated_date": "2024-09-25 16:13:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:36:47.857625"
    },
    {
      "arxiv_id": "2409.17049v1",
      "title": "ControlCity: A Multimodal Diffusion Model Based Approach for Accurate Geospatial Data Generation and Urban Morphology Analysis",
      "title_zh": "ControlCity: 一种基于多模态扩散模型的方法，用于准确的地理空间数据生成和城市形态分析",
      "authors": [
        "Fangshuo Zhou",
        "Huaxia Li",
        "Rui Hu",
        "Sensen Wu",
        "Hailin Feng",
        "Zhenhong Du",
        "Liuchang Xu"
      ],
      "abstract": "Volunteer Geographic Information (VGI), with its rich variety, large volume,\nrapid updates, and diverse sources, has become a critical source of geospatial\ndata. However, VGI data from platforms like OSM exhibit significant quality\nheterogeneity across different data types, particularly with urban building\ndata. To address this, we propose a multi-source geographic data transformation\nsolution, utilizing accessible and complete VGI data to assist in generating\nurban building footprint data. We also employ a multimodal data generation\nframework to improve accuracy. First, we introduce a pipeline for constructing\nan 'image-text-metadata-building footprint' dataset, primarily based on road\nnetwork data and supplemented by other multimodal data. We then present\nControlCity, a geographic data transformation method based on a multimodal\ndiffusion model. This method first uses a pre-trained text-to-image model to\nalign text, metadata, and building footprint data. An improved ControlNet\nfurther integrates road network and land-use imagery, producing refined\nbuilding footprint data. Experiments across 22 global cities demonstrate that\nControlCity successfully simulates real urban building patterns, achieving\nstate-of-the-art performance. Specifically, our method achieves an average FID\nscore of 50.94, reducing error by 71.01% compared to leading methods, and a\nMIoU score of 0.36, an improvement of 38.46%. Additionally, our model excels in\ntasks like urban morphology transfer, zero-shot city generation, and spatial\ndata completeness assessment. In the zero-shot city task, our method accurately\npredicts and generates similar urban structures, demonstrating strong\ngeneralization. This study confirms the effectiveness of our approach in\ngenerating urban building footprint data and capturing complex city\ncharacteristics.",
      "tldr_zh": "本研究针对 Volunteer Geographic Information (VGI) 数据（如 OSM）质量不均问题，提出 ControlCity，一种基于多模态扩散模型的方法，用于精确生成地理空间数据并分析城市形态。该方法首先构建一个'image-text-metadata-building footprint'数据集，利用道路网络数据和其他多模态信息作为基础；然后通过预训练的文本到图像模型对齐数据，并改进 ControlNet 整合道路网络和土地使用图像，以生成高质量的城市建筑轮廓数据。在 22 个全球城市的实验中，ControlCity 实现了最先进性能，平均 FID score 为 50.94（较领先方法减少错误 71.01%），以及 MIoU score 为 0.36（提高 38.46%），并在城市形态转移、零样本城市生成和空间数据完整性评估任务中表现出色。该方法有效模拟真实城市模式，并证明了其在捕捉复杂城市特征方面的强大泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.17049v1",
      "published_date": "2024-09-25 16:03:33 UTC",
      "updated_date": "2024-09-25 16:03:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:37:02.307834"
    },
    {
      "arxiv_id": "2409.17045v1",
      "title": "GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design",
      "title_zh": "翻译失败",
      "authors": [
        "Phillip Mueller",
        "Sebastian Mueller",
        "Lars Mikelsons"
      ],
      "abstract": "We provide a dataset for enabling Deep Generative Models (DGMs) in\nengineering design and propose methods to automate data labeling by utilizing\nlarge-scale foundation models. GeoBiked is curated to contain 4 355 bicycle\nimages, annotated with structural and technical features and is used to\ninvestigate two automated labeling techniques: The utilization of consolidated\nlatent features (Hyperfeatures) from image-generation models to detect\ngeometric correspondences (e.g. the position of the wheel center) in structural\nimages and the generation of diverse text descriptions for structural images.\nGPT-4o, a vision-language-model (VLM), is instructed to analyze images and\nproduce diverse descriptions aligned with the system-prompt. By representing\ntechnical images as Diffusion-Hyperfeatures, drawing geometric correspondences\nbetween them is possible. The detection accuracy of geometric points in unseen\nsamples is improved by presenting multiple annotated source images. GPT-4o has\nsufficient capabilities to generate accurate descriptions of technical images.\nGrounding the generation only on images leads to diverse descriptions but\ncauses hallucinations, while grounding it on categorical labels restricts the\ndiversity. Using both as input balances creativity and accuracy. Successfully\nusing Hyperfeatures for geometric correspondence suggests that this approach\ncan be used for general point-detection and annotation tasks in technical\nimages. Labeling such images with text descriptions using VLMs is possible, but\ndependent on the models detection capabilities, careful prompt-engineering and\nthe selection of input information. Applying foundation models in engineering\ndesign is largely unexplored. We aim to bridge this gap with a dataset to\nexplore training, finetuning and conditioning DGMs in this field and suggesting\napproaches to bootstrap foundation models to process technical images.",
      "tldr_zh": "本文介绍了GeoBiked数据集，包含4355张自行车图像，并标注了结构和技术特征，以支持Deep Generative Models (DGMs)在工程设计中的应用。研究提出两种自动化标注技术：利用Hyperfeatures从图像生成模型中提取潜在特征来检测几何对应（如轮子中心位置），以及使用GPT-4o作为Vision-Language Model (VLM)生成多样化文本描述。实验结果显示，通过结合多个标注源图像，几何点检测准确率得到提升，而将图像和类别标签作为输入，能平衡描述的创意性和准确性，避免幻觉。该方法为桥接基础模型在工程设计领域的空白提供了新途径，支持DGMs的训练、微调和调节。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17045v1",
      "published_date": "2024-09-25 15:57:59 UTC",
      "updated_date": "2024-09-25 15:57:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:37:12.926227"
    },
    {
      "arxiv_id": "2409.17044v2",
      "title": "How to Connect Speech Foundation Models and Large Language Models? What Matters and What Does Not",
      "title_zh": "如何连接语音基础模型和大语言模型？什么重要，什么不重要",
      "authors": [
        "Francesco Verdini",
        "Pierfrancesco Melucci",
        "Stefano Perna",
        "Francesco Cariaggi",
        "Marco Gaido",
        "Sara Papi",
        "Szymon Mazurek",
        "Marek Kasztelnik",
        "Luisa Bentivogli",
        "Sébastien Bratières",
        "Paolo Merialdo",
        "Simone Scardapane"
      ],
      "abstract": "The remarkable performance achieved by Large Language Models (LLM) has driven\nresearch efforts to leverage them for a wide range of tasks and input\nmodalities. In speech-to-text (S2T) tasks, the emerging solution consists of\nprojecting the output of the encoder of a Speech Foundational Model (SFM) into\nthe LLM embedding space through an adapter module. However, no work has yet\ninvestigated how much the downstream-task performance depends on each component\n(SFM, adapter, LLM) nor whether the best design of the adapter depends on the\nchosen SFM and LLM. To fill this gap, we evaluate the combination of 5 adapter\nmodules, 2 LLMs (Mistral and Llama), and 2 SFMs (Whisper and SeamlessM4T) on\ntwo widespread S2T tasks, namely Automatic Speech Recognition and Speech\nTranslation. Our results demonstrate that the SFM plays a pivotal role in\ndownstream performance, while the adapter choice has moderate impact and\ndepends on the SFM and LLM.",
      "tldr_zh": "这篇论文探讨了如何将 Speech Foundation Models (SFMs) 与 Large Language Models (LLMs) 连接，用于语音到文本 (S2T) 任务，如 Automatic Speech Recognition 和 Speech Translation。研究者评估了 5 个 adapter 模块、2 个 LLMs (Mistral 和 Llama) 以及 2 个 SFMs (Whisper 和 SeamlessM4T)，以分析每个组件对下游任务性能的影响。结果表明，SFM 是性能的关键因素，而 adapter 的选择仅具有中等影响，且取决于所选的 SFM 和 LLM。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17044v2",
      "published_date": "2024-09-25 15:54:29 UTC",
      "updated_date": "2024-11-08 12:44:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:37:25.976733"
    },
    {
      "arxiv_id": "2409.17027v3",
      "title": "Counterfactual Token Generation in Large Language Models",
      "title_zh": "大型语言模型中的反事实标记生成",
      "authors": [
        "Ivi Chatzi",
        "Nina Corvelo Benz",
        "Eleni Straitouri",
        "Stratis Tsirtsis",
        "Manuel Gomez-Rodriguez"
      ],
      "abstract": "\"Sure, I am happy to generate a story for you: Captain Lyra stood at the helm\nof her trusty ship, the Maelstrom's Fury, gazing out at the endless sea. [...]\nLyra's eyes welled up with tears as she realized the bitter truth - she had\nsacrificed everything for fleeting riches, and lost the love of her crew, her\nfamily, and herself.\" Although this story, generated by a large language model,\nis captivating, one may wonder -- how would the story have unfolded if the\nmodel had chosen \"Captain Maeve\" as the protagonist instead? We cannot know.\nState-of-the-art large language models are stateless -- they maintain no\ninternal memory or state. Given a prompt, they generate a sequence of tokens as\nan output using an autoregressive process. As a consequence, they cannot reason\nabout counterfactual alternatives to tokens they have generated in the past. In\nthis work, our goal is to enhance them with this functionality. To this end, we\ndevelop a causal model of token generation that builds upon the Gumbel-Max\nstructural causal model. Our model allows any large language model to perform\ncounterfactual token generation at almost no cost in comparison with vanilla\ntoken generation, it is embarrassingly simple to implement, and it does not\nrequire any fine-tuning nor prompt engineering. We implement our model on Llama\n3 8B-Instruct and Ministral-8B-Instruct and conduct a qualitative and a\nquantitative analysis of counterfactually generated text. We conclude with a\ndemonstrative application of counterfactual token generation for bias\ndetection, unveiling interesting insights about the model of the world\nconstructed by large language models.",
      "tldr_zh": "本研究探讨了大型语言模型（Large Language Models, LLMs）在生成文本时无法进行反事实（counterfactual）token 生成的问题，例如改变先前生成的元素（如主角名称）后故事的潜在变化。作者提出了一种基于 Gumbel-Max structural causal model 的因果模型，允许 LLMs 以几乎无额外成本的方式执行反事实 token 生成，该方法简单易实现，且无需 fine-tuning 或 prompt engineering。实验在 Llama 3 8B-Instruct 和 Ministral-8B-Instruct 上进行了定性和定量分析，结果显示该方法有效，并通过偏见检测应用揭示了 LLMs 内部世界模型的洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at CLeaR 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.17027v3",
      "published_date": "2024-09-25 15:30:24 UTC",
      "updated_date": "2025-03-24 19:05:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:37:35.855938"
    },
    {
      "arxiv_id": "2409.17012v1",
      "title": "AI-Driven Risk-Aware Scheduling for Active Debris Removal Missions",
      "title_zh": "AI驱动的风险感知调度方案用于主动碎片清除任务",
      "authors": [
        "Antoine Poupon",
        "Hugo de Rohan Willner",
        "Pierre Nikitits",
        "Adam Abdin"
      ],
      "abstract": "The proliferation of debris in Low Earth Orbit (LEO) represents a significant\nthreat to space sustainability and spacecraft safety. Active Debris Removal\n(ADR) has emerged as a promising approach to address this issue, utilising\nOrbital Transfer Vehicles (OTVs) to facilitate debris deorbiting, thereby\nreducing future collision risks. However, ADR missions are substantially\ncomplex, necessitating accurate planning to make the missions economically\nviable and technically effective. Moreover, these servicing missions require a\nhigh level of autonomous capability to plan under evolving orbital conditions\nand changing mission requirements. In this paper, an autonomous\ndecision-planning model based on Deep Reinforcement Learning (DRL) is developed\nto train an OTV to plan optimal debris removal sequencing. It is shown that\nusing the proposed framework, the agent can find optimal mission plans and\nlearn to update the planning autonomously to include risk handling of debris\nwith high collision risk.",
      "tldr_zh": "该论文针对低地球轨道(LEO)中太空碎片的威胁，提出一种AI驱动的风险感知调度框架，用于Active Debris Removal (ADR)任务，以利用Orbital Transfer Vehicles (OTVs)移除碎片并降低碰撞风险。研究开发了一个基于Deep Reinforcement Learning (DRL)的自治决策规划模型，训练OTVs自主规划最佳碎片移除序列，并适应动态的轨道条件和任务需求。主要发现是，该框架能帮助代理实现最优任务规划，并实时更新以处理高风险碎片，提升任务的经济性和安全性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17012v1",
      "published_date": "2024-09-25 15:16:07 UTC",
      "updated_date": "2024-09-25 15:16:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:37:48.696165"
    },
    {
      "arxiv_id": "2409.17005v2",
      "title": "Models Can and Should Embrace the Communicative Nature of Human-Generated Math",
      "title_zh": "翻译失败",
      "authors": [
        "Sasha Boguraev",
        "Ben Lipkin",
        "Leonie Weissweiler",
        "Kyle Mahowald"
      ],
      "abstract": "Math is constructed by people for people: just as natural language corpora\nreflect not just propositions but the communicative goals of language users,\nthe math data that models are trained on reflects not just idealized\nmathematical entities but rich communicative intentions. While there are\nimportant advantages to treating math in a purely symbolic manner, we here\nhypothesize that there are benefits to treating math as situated linguistic\ncommunication and that language models are well suited for this goal, in ways\nthat are not fully appreciated. We illustrate these points with two case\nstudies. First, we ran an experiment in which we found that language models\ninterpret the equals sign in a humanlike way -- generating systematically\ndifferent word problems for the same underlying equation arranged in different\nways. Second, we found that language models prefer proofs to be ordered in\nnaturalistic ways, even though other orders would be logically equivalent. We\nadvocate for AI systems that learn from and represent the communicative\nintentions latent in human-generated math.",
      "tldr_zh": "这篇论文主张数学数据不仅包含理想化的实体，还体现了人类的沟通意图，因此语言 models 应将其视为情境化语言沟通而非纯符号处理，以发挥其优势。研究者通过两个案例研究进行验证：首先，发现语言 models 在解释 equals sign 时会根据方程排列生成不同的文字问题，展现出人类般的系统性差异；其次，语言 models 偏好自然顺序的证明，即使其他逻辑等价顺序可用。最终，论文倡导 AI 系统学习并表示人类生成数学中的潜在沟通意图，以提升数学理解和应用的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17005v2",
      "published_date": "2024-09-25 15:08:08 UTC",
      "updated_date": "2024-10-31 17:21:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:38:01.289977"
    },
    {
      "arxiv_id": "2409.16997v2",
      "title": "INT-FlashAttention: Enabling Flash Attention for INT8 Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Shimao Chen",
        "Zirui Liu",
        "Zhiying Wu",
        "Ce Zheng",
        "Peizhuang Cong",
        "Zihan Jiang",
        "Yuhan Wu",
        "Lei Su",
        "Tong Yang"
      ],
      "abstract": "As the foundation of large language models (LLMs), self-attention module\nfaces the challenge of quadratic time and memory complexity with respect to\nsequence length. FlashAttention accelerates attention computation and reduces\nits memory usage by leveraging the GPU memory hierarchy. A promising research\ndirection is to integrate FlashAttention with quantization methods. This paper\nintroduces INT-FlashAttention, the first INT8 quantization architecture\ncompatible with the forward workflow of FlashAttention, which significantly\nimproves the inference speed of FlashAttention on Ampere GPUs. We implement our\nINT-FlashAttention prototype with fully INT8 activations and general\nmatrix-multiplication (GEMM) kernels, making it the first attention operator\nwith fully INT8 input. As a general token-level post-training quantization\nframework, INT-FlashAttention is also compatible with other data formats like\nINT4, etc. Experimental results show INT-FlashAttention achieves 72% faster\ninference speed and 82% smaller quantization error compared to standard\nFlashAttention with FP16 and FP8 data format.",
      "tldr_zh": "该论文提出INT-FlashAttention，一种首个兼容FlashAttention前向工作流程的INT8量化架构，旨在解决自注意力模块在大型语言模型(LLMs)中存在的二次时间和内存复杂度问题。方法通过采用全INT8激活和通用矩阵乘法(GEMM)内核，实现对Ampere GPU上FlashAttention推理速度的显著提升，同时兼容其他数据格式如INT4。实验结果显示，与使用FP16和FP8格式的标准FlashAttention相比，INT-FlashAttention的推理速度提高72%，量化错误减少82%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16997v2",
      "published_date": "2024-09-25 15:02:25 UTC",
      "updated_date": "2024-09-26 06:13:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:38:13.086992"
    },
    {
      "arxiv_id": "2409.16986v2",
      "title": "Harnessing Diversity for Important Data Selection in Pretraining Large Language Models",
      "title_zh": "利用多样性进行大语言",
      "authors": [
        "Chi Zhang",
        "Huaping Zhong",
        "Kuan Zhang",
        "Chengliang Chai",
        "Rui Wang",
        "Xinlin Zhuang",
        "Tianyi Bai",
        "Jiantao Qiu",
        "Lei Cao",
        "Ju Fan",
        "Ye Yuan",
        "Guoren Wang",
        "Conghui He"
      ],
      "abstract": "Data selection is of great significance in pre-training large language\nmodels, given the variation in quality within the large-scale available\ntraining corpora. To achieve this, researchers are currently investigating the\nuse of data influence to measure the importance of data instances, $i.e.,$ a\nhigh influence score indicates that incorporating this instance to the training\nset is likely to enhance the model performance. Consequently, they select the\ntop-$k$ instances with the highest scores. However, this approach has several\nlimitations. (1) Computing the influence of all available data is\ntime-consuming. (2) The selected data instances are not diverse enough, which\nmay hinder the pre-trained model's ability to generalize effectively to various\ndownstream tasks. In this paper, we introduce \\texttt{Quad}, a data selection\napproach that considers both quality and diversity by using data influence to\nachieve state-of-the-art pre-training results. In particular, noting that\nattention layers capture extensive semantic details, we have adapted the\naccelerated $iHVP$ computation methods for attention layers, enhancing our\nability to evaluate the influence of data, $i.e.,$ its quality. For the\ndiversity, \\texttt{Quad} clusters the dataset into similar data instances\nwithin each cluster and diverse instances across different clusters. For each\ncluster, if we opt to select data from it, we take some samples to evaluate the\ninfluence to prevent processing all instances. To determine which clusters to\nselect, we utilize the classic Multi-Armed Bandit method, treating each cluster\nas an arm. This approach favors clusters with highly influential instances\n(ensuring high quality) or clusters that have been selected less frequently\n(ensuring diversity), thereby well balancing between quality and diversity.",
      "tldr_zh": "本研究探讨了在预训练大型语言模型时的数据选择问题，强调现有基于数据影响（data influence）的方法计算耗时且数据多样性不足，导致模型泛化能力受限。论文引入了Quad框架，该框架通过改进iHVP计算加速评估数据质量，并在数据聚类基础上使用Multi-Armed Bandit方法平衡质量（高影响实例）和多样性（跨集群选择）。实验结果显示，Quad实现了state-of-the-art的预训练性能，提升了模型在下游任务中的泛化效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16986v2",
      "published_date": "2024-09-25 14:49:29 UTC",
      "updated_date": "2024-10-05 06:11:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:38:24.874899"
    },
    {
      "arxiv_id": "2409.19022v2",
      "title": "Application of AI-based Models for Online Fraud Detection and Analysis",
      "title_zh": "基于 AI 模型的在线欺诈检测和分析应用",
      "authors": [
        "Antonis Papasavva",
        "Shane Johnson",
        "Ed Lowther",
        "Samantha Lundrigan",
        "Enrico Mariconti",
        "Anna Markovska",
        "Nilufer Tuptuk"
      ],
      "abstract": "Fraud is a prevalent offence that extends beyond financial loss, causing\npsychological and physical harm to victims. The advancements in online\ncommunication technologies alowed for online fraud to thrive in this vast\nnetwork, with fraudsters increasingly using these channels for deception. With\nthe progression of technologies like AI, there is a growing concern that fraud\nwill scale up, using sophisticated methods, like deep-fakes in phishing\ncampaigns, all generated by language generation models like ChatGPT. However,\nthe application of AI in detecting and analyzing online fraud remains\nunderstudied. We conduct a Systematic Literature Review on AI and NLP\ntechniques for online fraud detection. The review adhered the PRISMA-ScR\nprotocol, with eligibility criteria including relevance to online fraud, use of\ntext data, and AI methodologies. We screened 2,457 academic records, 350 met\nour eligibility criteria, and included 223. We report the state-of-the-art NLP\ntechniques for analysing various online fraud categories; the training data\nsources; the NLP algorithms and models built; and the performance metrics\nemployed for model evaluation. We find that current research on online fraud is\ndivided into various scam activitiesand identify 16 different frauds that\nresearchers focus on. This SLR enhances the academic understanding of AI-based\ndetection methods for online fraud and offers insights for policymakers, law\nenforcement, and businesses on safeguarding against such activities. We\nconclude that focusing on specific scams lacks generalization, as multiple\nmodels are required for different fraud types. The evolving nature of scams\nlimits the effectiveness of models trained on outdated data. We also identify\nissues in data limitations, training bias reporting, and selective presentation\nof metrics in model performance reporting, which can lead to potential biases\nin model evaluation.",
      "tldr_zh": "本研究通过系统文献综述（Systematic Literature Review）探讨了 AI 和 NLP 技术在在线欺诈检测和分析中的应用，采用 PRISMA-ScR 协议筛选了 2,457 条记录，最终纳入 223 条相关研究。研究报告了当前先进的 NLP 技术、训练数据来源、算法模型（如基于文本数据的欺诈识别模型）以及性能指标，用于分析 16 种不同在线欺诈类别，包括 phishing 活动和 deep-fakes 生成。发现显示，现有的 AI 模型存在泛化不足的问题，因为针对特定诈骗类型需要多个模型，且使用过时数据会降低有效性，同时还存在数据限制、训练偏差报告缺失和性能指标选择性呈现的风险。该研究为决策者、执法机构和企业提供见解，以提升对在线欺诈的防护策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Manuscript accepted in Crime Science Journal. Please cite accordingly",
      "pdf_url": "http://arxiv.org/pdf/2409.19022v2",
      "published_date": "2024-09-25 14:47:03 UTC",
      "updated_date": "2025-04-15 19:05:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:38:37.074382"
    },
    {
      "arxiv_id": "2409.16984v1",
      "title": "AXCEL: Automated eXplainable Consistency Evaluation using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "P Aditya Sreekar",
        "Sahil Verma",
        "Suransh Chopra",
        "Sarik Ghazarian",
        "Abhishek Persad",
        "Narayanan Sadagopan"
      ],
      "abstract": "Large Language Models (LLMs) are widely used in both industry and academia\nfor various tasks, yet evaluating the consistency of generated text responses\ncontinues to be a challenge. Traditional metrics like ROUGE and BLEU show a\nweak correlation with human judgment. More sophisticated metrics using Natural\nLanguage Inference (NLI) have shown improved correlations but are complex to\nimplement, require domain-specific training due to poor cross-domain\ngeneralization, and lack explainability. More recently, prompt-based metrics\nusing LLMs as evaluators have emerged; while they are easier to implement, they\nstill lack explainability and depend on task-specific prompts, which limits\ntheir generalizability. This work introduces Automated eXplainable Consistency\nEvaluation using LLMs (AXCEL), a prompt-based consistency metric which offers\nexplanations for the consistency scores by providing detailed reasoning and\npinpointing inconsistent text spans. AXCEL is also a generalizable metric which\ncan be adopted to multiple tasks without changing the prompt. AXCEL outperforms\nboth non-prompt and prompt-based state-of-the-art (SOTA) metrics in detecting\ninconsistencies across summarization by 8.7%, free text generation by 6.2%, and\ndata-to-text conversion tasks by 29.4%. We also evaluate the influence of\nunderlying LLMs on prompt based metric performance and recalibrate the SOTA\nprompt-based metrics with the latest LLMs for fair comparison. Further, we show\nthat AXCEL demonstrates strong performance using open source LLMs.",
      "tldr_zh": "该研究针对大型语言模型 (LLMs) 生成文本一致性的评估难题，提出了一种名为 AXCEL 的自动化可解释一致性评估方法。AXCEL 利用提示-based 技术，提供详细推理和不一致文本段的定位，同时保持通用性，无需针对不同任务修改提示。与现有状态-of-the-art (SOTA) 指标相比，AXCEL 在总结任务上提升 8.7%、自由文本生成上提升 6.2%、数据到文本转换上提升 29.4%。此外，该方法在开源 LLMs 上表现出色，并通过重新校准 SOTA 指标验证了其鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16984v1",
      "published_date": "2024-09-25 14:45:52 UTC",
      "updated_date": "2024-09-25 14:45:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:38:50.192420"
    },
    {
      "arxiv_id": "2409.16978v1",
      "title": "Towards User-Focused Research in Training Data Attribution for Human-Centered Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Elisa Nguyen",
        "Johannes Bertram",
        "Evgenii Kortukov",
        "Jean Y. Song",
        "Seong Joon Oh"
      ],
      "abstract": "While Explainable AI (XAI) aims to make AI understandable and useful to\nhumans, it has been criticised for relying too much on formalism and\nsolutionism, focusing more on mathematical soundness than user needs. We\npropose an alternative to this bottom-up approach inspired by design thinking:\nthe XAI research community should adopt a top-down, user-focused perspective to\nensure user relevance. We illustrate this with a relatively young subfield of\nXAI, Training Data Attribution (TDA). With the surge in TDA research and\ngrowing competition, the field risks repeating the same patterns of\nsolutionism. We conducted a needfinding study with a diverse group of AI\npractitioners to identify potential user needs related to TDA. Through\ninterviews (N=10) and a systematic survey (N=31), we uncovered new TDA tasks\nthat are currently largely overlooked. We invite the TDA and XAI communities to\nconsider these novel tasks and improve the user relevance of their research\noutcomes.",
      "tldr_zh": "该论文批评了 Explainable AI (XAI) 过于依赖形式主义和数学严谨，而忽略用户实际需求，提出采用用户导向的 top-down 方法，以确保研究更贴合人类中心视角。作者以 Training Data Attribution (TDA) 为例，进行需求调研，包括访谈 (N=10) 和系统调查 (N=31)，识别出一些被忽略的 TDA 任务，如新颖的应用场景。最终，论文呼吁 XAI 和 TDA 社区关注这些发现，以提升研究成果的用户相关性和实用性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16978v1",
      "published_date": "2024-09-25 14:40:26 UTC",
      "updated_date": "2024-09-25 14:40:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:39:02.768089"
    },
    {
      "arxiv_id": "2409.16974v1",
      "title": "Decoding Large-Language Models: A Systematic Overview of Socio-Technical Impacts, Constraints, and Emerging Questions",
      "title_zh": "解读大型语言模型：社会技术影响、约束",
      "authors": [
        "Zeyneb N. Kaya",
        "Souvick Ghosh"
      ],
      "abstract": "There have been rapid advancements in the capabilities of large language\nmodels (LLMs) in recent years, greatly revolutionizing the field of natural\nlanguage processing (NLP) and artificial intelligence (AI) to understand and\ninteract with human language. Therefore, in this work, we conduct a systematic\ninvestigation of the literature to identify the prominent themes and directions\nof LLM developments, impacts, and limitations. Our findings illustrate the\naims, methodologies, limitations, and future directions of LLM research. It\nincludes responsible development considerations, algorithmic improvements,\nethical challenges, and societal implications of LLM development. Overall, this\npaper provides a rigorous and comprehensive overview of current research in LLM\nand identifies potential directions for future development. The article\nhighlights the application areas that could have a positive impact on society\nalong with the ethical considerations.",
      "tldr_zh": "这篇论文系统概述了大型语言模型 (LLMs) 的快速发展及其对自然语言处理 (NLP) 和人工智能 (AI) 领域的影响，通过文献调查识别了 LLMs 的主要发展主题、方法和限制。研究探讨了负责任开发、算法改进、伦理挑战以及社会含义，强调了 LLMs 在教育、医疗等领域的积极应用潜力。总体上，该文提供了全面分析，并指出了未来研究的方向，以应对新兴问题和伦理考虑。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages, 5 figures, preprint submitted to journal",
      "pdf_url": "http://arxiv.org/pdf/2409.16974v1",
      "published_date": "2024-09-25 14:36:30 UTC",
      "updated_date": "2024-09-25 14:36:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:39:15.927204"
    },
    {
      "arxiv_id": "2409.16973v1",
      "title": "Adaptive Self-Supervised Learning Strategies for Dynamic On-Device LLM Personalization",
      "title_zh": "自适应自监督学习策略用于动态设备端LLM个性化",
      "authors": [
        "Rafael Mendoza",
        "Isabella Cruz",
        "Richard Liu",
        "Aarav Deshmukh",
        "David Williams",
        "Jesscia Peng",
        "Rohan Iyer"
      ],
      "abstract": "Large language models (LLMs) have revolutionized how we interact with\ntechnology, but their personalization to individual user preferences remains a\nsignificant challenge, particularly in on-device applications. Traditional\nmethods often depend heavily on labeled datasets and can be resource-intensive.\nTo address these issues, we present Adaptive Self-Supervised Learning\nStrategies (ASLS), which utilizes self-supervised learning techniques to\npersonalize LLMs dynamically. The framework comprises a user profiling layer\nfor collecting interaction data and a neural adaptation layer for real-time\nmodel fine-tuning. This innovative approach enables continuous learning from\nuser feedback, allowing the model to generate responses that align closely with\nuser-specific contexts. The adaptive mechanisms of ASLS minimize computational\ndemands and enhance personalization efficiency. Experimental results across\nvarious user scenarios illustrate the superior performance of ASLS in boosting\nuser engagement and satisfaction, highlighting its potential to redefine LLMs\nas highly responsive and context-aware systems on-device.",
      "tldr_zh": "本论文提出 Adaptive Self-Supervised Learning Strategies (ASLS)，一种利用 self-supervised learning 技术实现动态 on-device LLM 个性化的框架，以解决传统方法依赖标记数据集和资源密集的问题。ASLS 包括用户 profiling layer 用于收集交互数据，以及 neural adaptation layer 用于实时模型微调，使 LLM 能够从用户反馈中持续学习并生成与特定上下文相符的响应。该方法显著降低了计算需求，提升了个性化效率，实验结果在多种用户场景中证明了 ASLS 在提高用户参与度和满意度方面的优越性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "First ASLS",
      "pdf_url": "http://arxiv.org/pdf/2409.16973v1",
      "published_date": "2024-09-25 14:35:06 UTC",
      "updated_date": "2024-09-25 14:35:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:39:27.966494"
    },
    {
      "arxiv_id": "2409.16956v2",
      "title": "Informed deep hierarchical classification: a non-standard analysis inspired approach",
      "title_zh": "翻译失败",
      "authors": [
        "Lorenzo Fiaschi",
        "Marco Cococcioni"
      ],
      "abstract": "This work proposes a novel approach to the deep hierarchical classification\ntask, i.e., the problem of classifying data according to multiple labels\norganized in a rigid parent-child structure. It consists in a multi-output deep\nneural network equipped with specific projection operators placed before each\noutput layer. The design of such an architecture, called lexicographic hybrid\ndeep neural network (LH-DNN), has been possible by combining tools from\ndifferent and quite distant research fields: lexicographic multi-objective\noptimization, non-standard analysis, and deep learning. To assess the efficacy\nof the approach, the resulting network is compared against the B-CNN, a\nconvolutional neural network tailored for hierarchical classification tasks, on\nthe CIFAR10, CIFAR100 (where it has been originally and recently proposed\nbefore being adopted and tuned for multiple real-world applications) and\nFashion-MNIST benchmarks. Evidence states that an LH-DNN can achieve comparable\nif not superior performance, especially in the learning of the hierarchical\nrelations, in the face of a drastic reduction of the learning parameters,\ntraining epochs, and computational time, without the need for ad-hoc loss\nfunctions weighting values.",
      "tldr_zh": "本研究提出了一种名为 lexicographic hybrid deep neural network (LH-DNN) 的新方法，用于深度层次分类任务，该任务涉及根据父子结构组织的多个标签对数据进行分类。LH-DNN 采用多输出深度神经网络架构，并在每个输出层前添加特定投影操作符，其设计灵感来源于 lexicographic multi-objective optimization、非标准分析和深度学习领域的工具。与 B-CNN 基准模型相比，LH-DNN 在 CIFAR10、CIFAR100 和 Fashion-MNIST 数据集上表现出相当或更优的性能，尤其在学习层次关系方面，同时大幅减少了学习参数、训练周期和计算时间，且无需额外的损失函数权重。总的来说，此方法为高效的层次分类提供了更具可行性的解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.LO",
        "03H10, 68T07",
        "I.2.5; I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16956v2",
      "published_date": "2024-09-25 14:12:50 UTC",
      "updated_date": "2024-10-04 09:46:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:39:38.856035"
    },
    {
      "arxiv_id": "2409.16950v1",
      "title": "Dynamic Obstacle Avoidance through Uncertainty-Based Adaptive Planning with Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Vineet Punyamoorty",
        "Pascal Jutras-Dubé",
        "Ruqi Zhang",
        "Vaneet Aggarwal",
        "Damon Conover",
        "Aniket Bera"
      ],
      "abstract": "By framing reinforcement learning as a sequence modeling problem, recent work\nhas enabled the use of generative models, such as diffusion models, for\nplanning. While these models are effective in predicting long-horizon state\ntrajectories in deterministic environments, they face challenges in dynamic\nsettings with moving obstacles. Effective collision avoidance demands\ncontinuous monitoring and adaptive decision-making. While replanning at every\ntimestep could ensure safety, it introduces substantial computational overhead\ndue to the repetitive prediction of overlapping state sequences -- a process\nthat is particularly costly with diffusion models, known for their intensive\niterative sampling procedure. We propose an adaptive generative planning\napproach that dynamically adjusts replanning frequency based on the uncertainty\nof action predictions. Our method minimizes the need for frequent,\ncomputationally expensive, and redundant replanning while maintaining robust\ncollision avoidance performance. In experiments, we obtain a 13.5% increase in\nthe mean trajectory length and a 12.7% increase in mean reward over\nlong-horizon planning, indicating a reduction in collision rates and an\nimproved ability to navigate the environment safely.",
      "tldr_zh": "该论文提出了一种基于不确定性的自适应生成规划方法，利用diffusion models来解决强化学习在动态障碍物环境中的规划挑战，通过动态调整重新规划频率来减少计算开销，同时保持有效的碰撞避免。方法将强化学习框架化为序列建模问题，根据动作预测的不确定性来最小化冗余规划。实验结果显示，与长时序规划相比，该方法使平均轨迹长度提高13.5%，平均奖励提高12.7%，从而降低了碰撞率并提升了环境安全导航能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16950v1",
      "published_date": "2024-09-25 14:03:58 UTC",
      "updated_date": "2024-09-25 14:03:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:39:50.969534"
    },
    {
      "arxiv_id": "2409.16946v1",
      "title": "Setting the AI Agenda -- Evidence from Sweden in the ChatGPT Era",
      "title_zh": "翻译失败",
      "authors": [
        "Bastiaan Bruinsma",
        "Annika Fredén",
        "Kajsa Hansson",
        "Moa Johansson",
        "Pasko Kisić-Merino",
        "Denitsa Saynova"
      ],
      "abstract": "This paper examines the development of the Artificial Intelligence (AI)\nmeta-debate in Sweden before and after the release of ChatGPT. From the\nperspective of agenda-setting theory, we propose that it is an elite outside of\nparty politics that is leading the debate -- i.e. that the politicians are\nrelatively silent when it comes to this rapid development. We also suggest that\nthe debate has become more substantive and risk-oriented in recent years. To\ninvestigate this claim, we draw on an original dataset of elite-level documents\nfrom the early 2010s to the present, using op-eds published in a number of\nleading Swedish newspapers. By conducting a qualitative content analysis of\nthese materials, our preliminary findings lend support to the expectation that\nan academic, rather than a political elite is steering the debate.",
      "tldr_zh": "这篇论文探讨了ChatGPT发布前后瑞典人工智能(AI)元辩论的发展，从agenda-setting theory的角度提出，非政党精英主导了辩论，而政治家相对沉默，且辩论变得更注重实质性和风险导向。研究方法包括分析一个原创数据集，涵盖从2010年代早期到现在的高层文件，如主要瑞典报纸的评论文章，并通过定性内容分析进行验证。初步发现支持了学术精英而非政治精英在引导AI议程的观点。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper is part of the Second AEQUITAS Workshop on Fairness and\n  Bias in AI | co-located with ECAI 2024, October 19--24, 2024, Santiago de\n  Compostela, Spain",
      "pdf_url": "http://arxiv.org/pdf/2409.16946v1",
      "published_date": "2024-09-25 13:58:02 UTC",
      "updated_date": "2024-09-25 13:58:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:40:02.645939"
    },
    {
      "arxiv_id": "2409.16944v1",
      "title": "Go-SLAM: Grounded Object Segmentation and Localization with Gaussian Splatting SLAM",
      "title_zh": "翻译失败",
      "authors": [
        "Phu Pham",
        "Dipam Patel",
        "Damon Conover",
        "Aniket Bera"
      ],
      "abstract": "We introduce Go-SLAM, a novel framework that utilizes 3D Gaussian Splatting\nSLAM to reconstruct dynamic environments while embedding object-level\ninformation within the scene representations. This framework employs advanced\nobject segmentation techniques, assigning a unique identifier to each Gaussian\nsplat that corresponds to the object it represents. Consequently, our system\nfacilitates open-vocabulary querying, allowing users to locate objects using\nnatural language descriptions. Furthermore, the framework features an optimal\npath generation module that calculates efficient navigation paths for robots\ntoward queried objects, considering obstacles and environmental uncertainties.\nComprehensive evaluations in various scene settings demonstrate the\neffectiveness of our approach in delivering high-fidelity scene\nreconstructions, precise object segmentation, flexible object querying, and\nefficient robot path planning. This work represents an additional step forward\nin bridging the gap between 3D scene reconstruction, semantic object\nunderstanding, and real-time environment interactions.",
      "tldr_zh": "本研究提出Go-SLAM框架，利用3D Gaussian Splatting SLAM重建动态环境，并将对象级信息嵌入场景表示中。框架采用高级对象分割技术，为每个Gaussian splat分配唯一标识符，支持开放词汇查询，让用户通过自然语言描述定位对象。此外，它包括一个最佳路径生成模块，能为机器人计算高效导航路径，同时考虑障碍和环境不确定性。在各种场景的全面评估中，Go-SLAM展示了高保真场景重建、精确对象分割、灵活对象查询和高效路径规划能力，推动了3D场景重建、语义对象理解与实时环境交互的融合。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.GR"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16944v1",
      "published_date": "2024-09-25 13:56:08 UTC",
      "updated_date": "2024-09-25 13:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:40:14.785899"
    },
    {
      "arxiv_id": "2409.16938v2",
      "title": "Generative Object Insertion in Gaussian Splatting with a Multi-View Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Hongliang Zhong",
        "Can Wang",
        "Jingbo Zhang",
        "Jing Liao"
      ],
      "abstract": "Generating and inserting new objects into 3D content is a compelling approach\nfor achieving versatile scene recreation. Existing methods, which rely on SDS\noptimization or single-view inpainting, often struggle to produce high-quality\nresults. To address this, we propose a novel method for object insertion in 3D\ncontent represented by Gaussian Splatting. Our approach introduces a multi-view\ndiffusion model, dubbed MVInpainter, which is built upon a pre-trained stable\nvideo diffusion model to facilitate view-consistent object inpainting. Within\nMVInpainter, we incorporate a ControlNet-based conditional injection module to\nenable controlled and more predictable multi-view generation. After generating\nthe multi-view inpainted results, we further propose a mask-aware 3D\nreconstruction technique to refine Gaussian Splatting reconstruction from these\nsparse inpainted views. By leveraging these fabricate techniques, our approach\nyields diverse results, ensures view-consistent and harmonious insertions, and\nproduces better object quality. Extensive experiments demonstrate that our\napproach outperforms existing methods.",
      "tldr_zh": "本论文提出了一种在Gaussian Splatting中生成和插入新对象的方法，以实现多样的3D场景重现。该方法引入多视图扩散模型MVInpainter，基于预训练的稳定视频扩散模型并整合ControlNet-based条件注入模块，实现视图一致且可控的对象修复。随后，通过mask-aware 3D重建技术，从稀疏修复视图中精炼Gaussian Splatting重建，确保插入对象的和谐性和高质量。实验证明，该方法在对象质量和整体性能上优于现有依赖SDS优化或单视图修复的技术。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by Visual Informatics. Project Page:\n  https://github.com/JiuTongBro/MultiView_Inpaint",
      "pdf_url": "http://arxiv.org/pdf/2409.16938v2",
      "published_date": "2024-09-25 13:52:50 UTC",
      "updated_date": "2025-04-11 12:04:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:40:28.166707"
    },
    {
      "arxiv_id": "2409.16937v3",
      "title": "Semi-Supervised Cognitive State Classification from Speech with Multi-View Pseudo-Labeling",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanchao Li",
        "Zixing Zhang",
        "Jing Han",
        "Peter Bell",
        "Catherine Lai"
      ],
      "abstract": "The lack of labeled data is a common challenge in speech classification\ntasks, particularly those requiring extensive subjective assessment, such as\ncognitive state classification. In this work, we propose a Semi-Supervised\nLearning (SSL) framework, introducing a novel multi-view pseudo-labeling method\nthat leverages both acoustic and linguistic characteristics to select the most\nconfident data for training the classification model. Acoustically, unlabeled\ndata are compared to labeled data using the Frechet audio distance, calculated\nfrom embeddings generated by multiple audio encoders. Linguistically, large\nlanguage models are prompted to revise automatic speech recognition\ntranscriptions and predict labels based on our proposed task-specific\nknowledge. High-confidence data are identified when pseudo-labels from both\nsources align, while mismatches are treated as low-confidence data. A bimodal\nclassifier is then trained to iteratively label the low-confidence data until a\npredefined criterion is met. We evaluate our SSL framework on emotion\nrecognition and dementia detection tasks. Experimental results demonstrate that\nour method achieves competitive performance compared to fully supervised\nlearning using only 30% of the labeled data and significantly outperforms two\nselected baselines.",
      "tldr_zh": "该研究针对语音分类任务中标注数据不足的问题，提出了一种半监督学习（Semi-Supervised Learning, SSL）框架，利用多视图伪标签方法结合声学和语言特性来提升认知状态分类性能。具体而言，该方法通过Frechet audio distance比较未标注数据的音频嵌入，并使用大语言模型（Large Language Models）修订语音转录并预测标签，仅当两者伪标签一致时才视为高置信度数据，并迭代训练双模态分类器（bimodal classifier）处理低置信度数据。在情感识别和痴呆检测任务上，实验结果显示，该框架仅使用30%的标注数据就达到了与完全监督学习相当的性能，并显著优于现有基线。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.MM",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.16937v3",
      "published_date": "2024-09-25 13:51:19 UTC",
      "updated_date": "2025-04-30 13:24:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:40:39.766777"
    },
    {
      "arxiv_id": "2409.16934v3",
      "title": "Investigating OCR-Sensitive Neurons to Improve Entity Recognition in Historical Documents",
      "title_zh": "调查 OCR 敏感神经元以改善历史文档中的实体识别",
      "authors": [
        "Emanuela Boros",
        "Maud Ehrmann"
      ],
      "abstract": "This paper investigates the presence of OCR-sensitive neurons within the\nTransformer architecture and their influence on named entity recognition (NER)\nperformance on historical documents. By analysing neuron activation patterns in\nresponse to clean and noisy text inputs, we identify and then neutralise\nOCR-sensitive neurons to improve model performance. Based on two open access\nlarge language models (Llama2 and Mistral), experiments demonstrate the\nexistence of OCR-sensitive regions and show improvements in NER performance on\nhistorical newspapers and classical commentaries, highlighting the potential of\ntargeted neuron modulation to improve models' performance on noisy text.",
      "tldr_zh": "本文研究了Transformer架构中OCR-sensitive neurons对命名实体识别(NER)在历史文档中的影响，通过分析神经元在干净和噪声文本输入下的激活模式，识别并中和这些神经元以提升模型性能。基于Llama2和Mistral两个开源大语言模型的实验，证明了OCR-sensitive neurons的存在，并在历史报纸和古典评论上改善了NER性能。总体而言，该方法突出了针对性神经元调节在处理噪声文本时的潜力，为历史文档处理提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16934v3",
      "published_date": "2024-09-25 13:45:23 UTC",
      "updated_date": "2024-11-18 15:22:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:40:51.081688"
    },
    {
      "arxiv_id": "2409.16928v1",
      "title": "Quantum-Classical Sentiment Analysis",
      "title_zh": "量子-经典情感分析",
      "authors": [
        "Mario Bifulco",
        "Luca Roversi"
      ],
      "abstract": "In this study, we initially investigate the application of a hybrid\nclassical-quantum classifier (HCQC) for sentiment analysis, comparing its\nperformance against the classical CPLEX classifier and the Transformer\narchitecture. Our findings indicate that while the HCQC underperforms relative\nto the Transformer in terms of classification accuracy, but it requires\nsignificantly less time to converge to a reasonably good approximate solution.\nThis experiment also reveals a critical bottleneck in the HCQC, whose\narchitecture is partially undisclosed by the D-Wave property. To address this\nlimitation, we propose a novel algorithm based on the algebraic decomposition\nof QUBO models, which enhances the time the quantum processing unit can\nallocate to problem-solving tasks.",
      "tldr_zh": "这篇论文研究了混合经典-量子分类器（HCQC）在情感分析中的应用，并将其性能与经典 CPLEX 分类器和 Transformer 架构进行比较。结果显示，HCQC 在分类准确性上逊色于 Transformer，但其收敛时间显著更快，能更快达到合理的近似解。同时，论文识别出 HCQC 架构中的瓶颈，并提出了一种基于 QUBO 模型的代数分解算法，以优化量子处理单元在问题求解任务上的分配时间，从而提升整体效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to BigHPC 2024 - https://www.itadata.it/2024/bighpc2024",
      "pdf_url": "http://arxiv.org/pdf/2409.16928v1",
      "published_date": "2024-09-25 13:40:19 UTC",
      "updated_date": "2024-09-25 13:40:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:41:03.678056"
    },
    {
      "arxiv_id": "2410.07612v1",
      "title": "A Survey for Deep Reinforcement Learning Based Network Intrusion Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Wanrong Yang",
        "Alberto Acuto",
        "Yihang Zhou",
        "Dominik Wojtczak"
      ],
      "abstract": "Cyber-attacks are becoming increasingly sophisticated and frequent,\nhighlighting the importance of network intrusion detection systems. This paper\nexplores the potential and challenges of using deep reinforcement learning\n(DRL) in network intrusion detection. It begins by introducing key DRL concepts\nand frameworks, such as deep Q-networks and actor-critic algorithms, and\nreviews recent research utilizing DRL for intrusion detection. The study\nevaluates challenges related to model training efficiency, detection of\nminority and unknown class attacks, feature selection, and handling unbalanced\ndatasets. The performance of DRL models is comprehensively analyzed, showing\nthat while DRL holds promise, many recent technologies remain underexplored.\nSome DRL models achieve state-of-the-art results on public datasets,\noccasionally outperforming traditional deep learning methods. The paper\nconcludes with recommendations for enhancing DRL deployment and testing in\nreal-world network scenarios, with a focus on Internet of Things intrusion\ndetection. It discusses recent DRL architectures and suggests future policy\nfunctions for DRL-based intrusion detection. Finally, the paper proposes\nintegrating DRL with generative methods to further improve performance,\naddressing current gaps and supporting more robust and adaptive network\nintrusion detection systems.",
      "tldr_zh": "这篇论文对基于深度强化学习 (DRL) 的网络入侵检测系统进行了全面调查，介绍了 DRL 关键概念如 deep Q-networks 和 actor-critic algorithms，并回顾了最近的相关研究。论文评估了主要挑战，包括模型训练效率、检测少数和未知类攻击、特征选择以及处理不平衡数据集，同时分析了 DRL 模型在公共数据集上的表现，显示其偶尔优于传统深度学习方法，但许多新技术仍未充分探索。最终，论文提出增强 DRL 在真实网络场景（如物联网入侵检测）中的部署建议，并推荐将 DRL 与生成方法整合，以构建更鲁棒和适应的入侵检测系统。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "17 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.07612v1",
      "published_date": "2024-09-25 13:39:30 UTC",
      "updated_date": "2024-09-25 13:39:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:41:16.440857"
    },
    {
      "arxiv_id": "2409.16923v1",
      "title": "AI-assisted Gaze Detection for Proctoring Online Exams",
      "title_zh": "翻译失败",
      "authors": [
        "Yong-Siang Shih",
        "Zach Zhao",
        "Chenhao Niu",
        "Bruce Iberg",
        "James Sharpnack",
        "Mirza Basim Baig"
      ],
      "abstract": "For high-stakes online exams, it is important to detect potential rule\nviolations to ensure the security of the test. In this study, we investigate\nthe task of detecting whether test takers are looking away from the screen, as\nsuch behavior could be an indication that the test taker is consulting external\nresources. For asynchronous proctoring, the exam videos are recorded and\nreviewed by the proctors. However, when the length of the exam is long, it\ncould be tedious for proctors to watch entire exam videos to determine the\nexact moments when test takers look away. We present an AI-assisted gaze\ndetection system, which allows proctors to navigate between different video\nframes and discover video frames where the test taker is looking in similar\ndirections. The system enables proctors to work more effectively to identify\nsuspicious moments in videos. An evaluation framework is proposed to evaluate\nthe system against human-only and ML-only proctoring, and a user study is\nconducted to gather feedback from proctors, aiming to demonstrate the\neffectiveness of the system.",
      "tldr_zh": "本研究针对在线考试中检测考生注视屏幕外行为（可能表示作弊）的需求，提出了一种AI-assisted gaze detection系统，以辅助监考人员更高效地审查视频。系统允许监考人员在视频帧间导航，快速识别考生注视方向相似的帧，从而发现可疑时刻。实验通过评估框架和用户研究，与纯人工或纯机器学习方法相比，证明该系统能显著提高监考效率和准确性。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to HCOMP-24 Works-in-Progress and Demonstration track",
      "pdf_url": "http://arxiv.org/pdf/2409.16923v1",
      "published_date": "2024-09-25 13:31:37 UTC",
      "updated_date": "2024-09-25 13:31:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:41:26.634974"
    },
    {
      "arxiv_id": "2409.16920v2",
      "title": "Cross-Lingual Speech Emotion Recognition: Humans vs. Self-Supervised Models",
      "title_zh": "跨语言语音情感识别：人类 vs. 自监督模型",
      "authors": [
        "Zhichen Han",
        "Tianqi Geng",
        "Hui Feng",
        "Jiahong Yuan",
        "Korin Richmond",
        "Yuanchao Li"
      ],
      "abstract": "Utilizing Self-Supervised Learning (SSL) models for Speech Emotion\nRecognition (SER) has proven effective, yet limited research has explored\ncross-lingual scenarios. This study presents a comparative analysis between\nhuman performance and SSL models, beginning with a layer-wise analysis and an\nexploration of parameter-efficient fine-tuning strategies in monolingual,\ncross-lingual, and transfer learning contexts. We further compare the SER\nability of models and humans at both utterance- and segment-levels.\nAdditionally, we investigate the impact of dialect on cross-lingual SER through\nhuman evaluation. Our findings reveal that models, with appropriate knowledge\ntransfer, can adapt to the target language and achieve performance comparable\nto native speakers. We also demonstrate the significant effect of dialect on\nSER for individuals without prior linguistic and paralinguistic background.\nMoreover, both humans and models exhibit distinct behaviors across different\nemotions. These results offer new insights into the cross-lingual SER\ncapabilities of SSL models, underscoring both their similarities to and\ndifferences from human emotion perception.",
      "tldr_zh": "这篇论文比较了人类与自监督学习 (SSL) 模型在跨语言语音情感识别 (SER) 中的性能，通过层级分析、参数高效微调策略以及人类评估，探讨单语、跨语和迁移学习场景。研究发现，SSL 模型通过适当的知识转移可适应目标语言，并实现与母语者相当的表现，但方言对缺乏相关背景的个体有显著影响。最终，论文揭示了人类和模型在不同情绪上的行为差异，为理解 SSL 模型的跨语言 SER 能力提供了新洞见。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.16920v2",
      "published_date": "2024-09-25 13:27:17 UTC",
      "updated_date": "2025-04-30 13:16:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:41:40.485722"
    },
    {
      "arxiv_id": "2409.16913v1",
      "title": "Tell Me What You Don't Know: Enhancing Refusal Capabilities of Role-Playing Agents via Representation Space Analysis and Editing",
      "title_zh": "告诉我你不知道的东西：通过表示空间分析和编辑增强角色扮演代理的拒绝能力",
      "authors": [
        "Wenhao Liu",
        "Siyu An",
        "Junru Lu",
        "Muling Wu",
        "Tianlong Li",
        "Xiaohua Wang",
        "Xiaoqing Zheng",
        "Di Yin",
        "Xing Sun",
        "Xuanjing Huang"
      ],
      "abstract": "Role-Playing Agents (RPAs) have shown remarkable performance in various\napplications, yet they often struggle to recognize and appropriately respond to\nhard queries that conflict with their role-play knowledge. To investigate RPAs'\nperformance when faced with different types of conflicting requests, we develop\nan evaluation benchmark that includes contextual knowledge conflicting\nrequests, parametric knowledge conflicting requests, and non-conflicting\nrequests to assess RPAs' ability to identify conflicts and refuse to answer\nappropriately without over-refusing. Through extensive evaluation, we find that\nmost RPAs behave significant performance gaps toward different conflict\nrequests. To elucidate the reasons, we conduct an in-depth representation-level\nanalysis of RPAs under various conflict scenarios. Our findings reveal the\nexistence of rejection regions and direct response regions within the model's\nforwarding representation, and thus influence the RPA's final response\nbehavior. Therefore, we introduce a lightweight representation editing approach\nthat conveniently shifts conflicting requests to the rejection region, thereby\nenhancing the model's refusal accuracy. The experimental results validate the\neffectiveness of our editing method, improving RPAs' refusal ability of\nconflicting requests while maintaining their general role-playing capabilities.",
      "tldr_zh": "本研究针对 Role-Playing Agents (RPAs) 在处理与角色知识冲突的查询时存在的性能差距，开发了一个评估基准，包括上下文知识冲突、参数知识冲突和非冲突请求，以评估其识别和拒绝能力。研究通过深入的表示空间分析，发现模型的转发表示中存在拒绝区域和直接响应区域，从而影响最终响应行为。为此，提出了一种轻量级的表示编辑方法，将冲突请求转移到拒绝区域，提高拒绝准确性。实验结果证明，该方法显著提升了 RPAs 对冲突请求的拒绝能力，同时保持了其一般角色扮演性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16913v1",
      "published_date": "2024-09-25 13:18:12 UTC",
      "updated_date": "2024-09-25 13:18:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:41:52.266231"
    },
    {
      "arxiv_id": "2409.16909v2",
      "title": "Enhancing Temporal Sensitivity and Reasoning for Time-Sensitive Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Wanqi Yang",
        "Yanda Li",
        "Meng Fang",
        "Ling Chen"
      ],
      "abstract": "Time-Sensitive Question Answering (TSQA) demands the effective utilization of\nspecific temporal contexts, encompassing multiple time-evolving facts, to\naddress time-sensitive questions. This necessitates not only the parsing of\ntemporal information within questions but also the identification and\nunderstanding of time-evolving facts to generate accurate answers. However,\ncurrent large language models still have limited sensitivity to temporal\ninformation and their inadequate temporal reasoning capabilities. In this\npaper, we propose a novel framework that enhances temporal awareness and\nreasoning through Temporal Information-Aware Embedding and Granular Contrastive\nReinforcement Learning. Experimental results on four TSQA datasets demonstrate\nthat our framework significantly outperforms existing LLMs in TSQA tasks,\nmarking a step forward in bridging the performance gap between machine and\nhuman temporal understanding and reasoning.",
      "tldr_zh": "该研究针对 Time-Sensitive Question Answering (TSQA) 的挑战，提出了一种新框架，以提升模型对时间信息的敏感性和推理能力，因为现有 Large Language Models (LLMs) 在处理时间演变事实方面存在局限。框架通过 Temporal Information-Aware Embedding 来解析和嵌入时间相关信息，以及 Granular Contrastive Reinforcement Learning 来强化细粒度对比学习，从而更好地理解和回答时间敏感问题。在四个 TSQA 数据集上的实验显示，该框架显著优于现有 LLMs，缩小了机器与人类在时间理解和推理方面的性能差距。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2409.16909v2",
      "published_date": "2024-09-25 13:13:21 UTC",
      "updated_date": "2024-09-29 13:17:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:42:06.767023"
    },
    {
      "arxiv_id": "2409.16904v1",
      "title": "Discriminative Anchor Learning for Efficient Multi-view Clustering",
      "title_zh": "高效多视图聚类的判别锚点学习",
      "authors": [
        "Yalan Qin",
        "Nan Pu",
        "Hanzhou Wu",
        "Nicu Sebe"
      ],
      "abstract": "Multi-view clustering aims to study the complementary information across\nviews and discover the underlying structure. For solving the relatively high\ncomputational cost for the existing approaches, works based on anchor have been\npresented recently. Even with acceptable clustering performance, these methods\ntend to map the original representation from multiple views into a fixed shared\ngraph based on the original dataset. However, most studies ignore the\ndiscriminative property of the learned anchors, which ruin the representation\ncapability of the built model. Moreover, the complementary information among\nanchors across views is neglected to be ensured by simply learning the shared\nanchor graph without considering the quality of view-specific anchors. In this\npaper, we propose discriminative anchor learning for multi-view clustering\n(DALMC) for handling the above issues. We learn discriminative view-specific\nfeature representations according to the original dataset and build anchors\nfrom different views based on these representations, which increase the quality\nof the shared anchor graph. The discriminative feature learning and consensus\nanchor graph construction are integrated into a unified framework to improve\neach other for realizing the refinement. The optimal anchors from multiple\nviews and the consensus anchor graph are learned with the orthogonal\nconstraints. We give an iterative algorithm to deal with the formulated\nproblem. Extensive experiments on different datasets show the effectiveness and\nefficiency of our method compared with other methods.",
      "tldr_zh": "本文提出了一种名为 Discriminative Anchor Learning for Multi-view Clustering (DALMC) 的方法，针对多视图聚类（Multi-view Clustering）中现有锚点（Anchor）方法忽略锚点的区分性（discriminative property）和视图间互补信息的问题。DALMC 通过从原始数据集学习区分性的视图特定特征表示，并基于这些表示构建高质量的共享锚点图，将特征学习和共识锚点图构建整合到一个统一框架中，使用正交约束进行优化。实验结果显示，该方法在多个数据集上比其他方法更有效和高效，提高了聚类的性能和计算效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been accepted by TMM",
      "pdf_url": "http://arxiv.org/pdf/2409.16904v1",
      "published_date": "2024-09-25 13:11:17 UTC",
      "updated_date": "2024-09-25 13:11:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:42:18.358816"
    },
    {
      "arxiv_id": "2409.16902v5",
      "title": "Underwater Camouflaged Object Tracking Meets Vision-Language SAM2",
      "title_zh": "水下伪装",
      "authors": [
        "Chunhui Zhang",
        "Li Liu",
        "Guanjie Huang",
        "Zhipeng Zhang",
        "Hao Wen",
        "Xi Zhou",
        "Shiming Ge",
        "Yanfeng Wang"
      ],
      "abstract": "Over the past decade, significant progress has been made in visual object\ntracking, largely due to the availability of large-scale datasets. However,\nthese datasets have primarily focused on open-air scenarios and have largely\noverlooked underwater animal tracking-especially the complex challenges posed\nby camouflaged marine animals. To bridge this gap, we take a step forward by\nproposing the first large-scale multi-modal underwater camouflaged object\ntracking dataset, namely UW-COT220. Based on the proposed dataset, this work\nfirst comprehensively evaluates current advanced visual object tracking\nmethods, including SAM- and SAM2-based trackers, in challenging underwater\nenvironments, \\eg, coral reefs. Our findings highlight the improvements of SAM2\nover SAM, demonstrating its enhanced ability to handle the complexities of\nunderwater camouflaged objects. Furthermore, we propose a novel vision-language\ntracking framework called VL-SAM2, based on the video foundation model SAM2.\nExtensive experimental results demonstrate that the proposed VL-SAM2 achieves\nstate-of-the-art performance across underwater and open-air object tracking\ndatasets. The dataset and codes are available\nat~{\\color{magenta}{https://github.com/983632847/Awesome-Multimodal-Object-Tracking}}.",
      "tldr_zh": "本研究针对视觉物体追踪领域中水下伪装动物追踪的空白，提出了首个大规模多模态数据集UW-COT220，以解决珊瑚礁等复杂环境下的挑战。作者评估了现有先进追踪方法，包括基于SAM和SAM2的追踪器，发现SAM2在处理水下伪装物体时表现出色。基于此，他们开发了新型视觉-语言追踪框架VL-SAM2，利用视频基础模型SAM2，实现跨模态融合。实验结果显示，VL-SAM2在水下和陆地物体追踪数据集上达到了最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR 2025 Workshop on CV4Animals.\n  https://github.com/983632847/Awesome-Multimodal-Object-Tracking",
      "pdf_url": "http://arxiv.org/pdf/2409.16902v5",
      "published_date": "2024-09-25 13:10:03 UTC",
      "updated_date": "2025-05-19 03:40:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:42:27.435961"
    },
    {
      "arxiv_id": "2409.16900v1",
      "title": "A Roadmap for Embodied and Social Grounding in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Incao",
        "Carlo Mazzola",
        "Giulia Belgiovine",
        "Alessandra Sciutti"
      ],
      "abstract": "The fusion of Large Language Models (LLMs) and robotic systems has led to a\ntransformative paradigm in the robotic field, offering unparalleled\ncapabilities not only in the communication domain but also in skills like\nmultimodal input handling, high-level reasoning, and plan generation. The\ngrounding of LLMs knowledge into the empirical world has been considered a\ncrucial pathway to exploit the efficiency of LLMs in robotics. Nevertheless,\nconnecting LLMs' representations to the external world with multimodal\napproaches or with robots' bodies is not enough to let them understand the\nmeaning of the language they are manipulating. Taking inspiration from humans,\nthis work draws attention to three necessary elements for an agent to grasp and\nexperience the world. The roadmap for LLMs grounding is envisaged in an active\nbodily system as the reference point for experiencing the environment, a\ntemporally structured experience for a coherent, self-related interaction with\nthe external world, and social skills to acquire a common-grounded shared\nexperience.",
      "tldr_zh": "该论文提出了一条路线图(Roadmap)，旨在实现大型语言模型(LLMs)的身体化(Embodied)和社会化(Social)接地，以提升LLMs在机器人领域的应用，如多模态输入处理、高级推理和计划生成。作者强调，仅通过多模态方法或机器人身体连接不足以让LLMs理解语言的真实含义，因此借鉴人类经验，指出三个关键元素：主动的身体系统(Active bodily system)作为环境体验的参考点、时间结构化的体验(Temporally structured experience)以实现连贯的自相关互动，以及社会技能(Social skills)来构建共享的共同基础。总体而言，这一路线图为LLMs更好地融入现实世界互动提供了指导，帮助它们从经验中学习和适应。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "I.2.7; I.2.9; J.4; F.3.2; D.3.1"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted Version of a conference paper presented at Robophilosophy\n  Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.16900v1",
      "published_date": "2024-09-25 13:09:23 UTC",
      "updated_date": "2024-09-25 13:09:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:42:41.036415"
    },
    {
      "arxiv_id": "2409.16898v3",
      "title": "AI-driven View Guidance System in Intra-cardiac Echocardiography Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Jaeyoung Huh",
        "Paul Klein",
        "Gareth Funka-Lea",
        "Puneet Sharma",
        "Ankur Kapoor",
        "Young-Ho Kim"
      ],
      "abstract": "Intra-cardiac echocardiography (ICE) is a crucial imaging modality used in\nelectrophysiology (EP) and structural heart disease (SHD) interventions,\nproviding realtime, high-resolution views from within the heart. Despite its\nadvantages, effective manipulation of the ICE catheter requires significant\nexpertise, which can lead to inconsistent outcomes, especially among less\nexperienced operators. To address this challenge, we propose an AIdriven view\nguidance system that operates in a continuous closed-loop with\nhuman-in-the-loop feedback, designed to assist users in navigating ICE imaging\nwithout requiring specialized knowledge. Specifically, our method models the\nrelative position and orientation vectors between arbitrary views and\nclinically defined ICE views in a spatial coordinate system. It guides users on\nhow to manipulate the ICE catheter to transition from the current view to the\ndesired view over time. By operating in a closedloop configuration, the system\ncontinuously predicts and updates the necessary catheter manipulations,\nensuring seamless integration into existing clinical workflows. The\neffectiveness of the proposed system is demonstrated through a simulation-based\nperformance evaluation using real clinical data, achieving an 89% success rate\nwith 6,532 test cases. Additionally, a semi-simulation experiment with\nhuman-in-the-loop testing validated the feasibility of continuous yet discrete\nguidance. These results underscore the potential of the proposed method to\nenhance the accuracy and efficiency of ICE imaging procedures.",
      "tldr_zh": "本研究针对Intra-cardiac Echocardiography (ICE) 成像中操作导管所需的专业知识不足问题，提出了一种AI-driven视图引导系统。该系统采用闭环配置，与人类反馈相结合，通过建模任意视图与临床定义ICE视图之间的相对位置和方向向量，实时指导用户操作导管从当前视图过渡到目标视图，从而提升操作效率。实验结果显示，在基于真实临床数据的模拟评估中，该系统在6,532个测试案例中实现了89%的成功率；此外，半模拟人类参与实验验证了其连续但离散指导的可行性。该方法有望显著提高ICE成像程序的准确性和一致性，尤其对经验不足的操作者提供支持。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16898v3",
      "published_date": "2024-09-25 13:08:10 UTC",
      "updated_date": "2025-01-22 16:58:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:42:51.837892"
    },
    {
      "arxiv_id": "2409.16882v1",
      "title": "Revisiting Space Mission Planning: A Reinforcement Learning-Guided Approach for Multi-Debris Rendezvous",
      "title_zh": "翻译失败",
      "authors": [
        "Agni Bandyopadhyay",
        "Guenther Waxenegger-Wilfing"
      ],
      "abstract": "This research introduces a novel application of a masked Proximal Policy\nOptimization (PPO) algorithm from the field of deep reinforcement learning\n(RL), for determining the most efficient sequence of space debris visitation,\nutilizing the Lambert solver as per Izzo's adaptation for individual\nrendezvous. The aim is to optimize the sequence in which all the given debris\nshould be visited to get the least total time for rendezvous for the entire\nmission. A neural network (NN) policy is developed, trained on simulated space\nmissions with varying debris fields. After training, the neural network\ncalculates approximately optimal paths using Izzo's adaptation of Lambert\nmaneuvers. Performance is evaluated against standard heuristics in mission\nplanning. The reinforcement learning approach demonstrates a significant\nimprovement in planning efficiency by optimizing the sequence for debris\nrendezvous, reducing the total mission time by an average of approximately\n{10.96\\%} and {13.66\\%} compared to the Genetic and Greedy algorithms,\nrespectively. The model on average identifies the most time-efficient sequence\nfor debris visitation across various simulated scenarios with the fastest\ncomputational speed. This approach signifies a step forward in enhancing\nmission planning strategies for space debris clearance.",
      "tldr_zh": "这篇论文重新审视了空间任务规划，提出了一种基于强化学习(RL)的多碎片 Rendezvous 方法，使用 masked Proximal Policy Optimization (PPO) 算法结合 Izzo's adaptation of Lambert solver 来优化碎片访问序列，以最小化总任务时间。研究开发并训练了一个神经网络(NN) 政策，在模拟空间任务中进行测试，结果显示该方法比 Genetic 和 Greedy 算法分别平均减少 10.96% 和 13.66% 的总任务时间，同时提供更快的计算速度。该方法为空间碎片清除任务的规划策略带来了显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication at the 2024 International Conference on\n  Space Robotics (iSpaRo)",
      "pdf_url": "http://arxiv.org/pdf/2409.16882v1",
      "published_date": "2024-09-25 12:50:01 UTC",
      "updated_date": "2024-09-25 12:50:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:43:05.049229"
    },
    {
      "arxiv_id": "2409.16876v3",
      "title": "Automating Traffic Model Enhancement with AI Research Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Xusen Guo",
        "Xinxi Yang",
        "Mingxing Peng",
        "Hongliang Lu",
        "Meixin Zhu",
        "Hai Yang"
      ],
      "abstract": "Developing efficient traffic models is crucial for optimizing modern\ntransportation systems. However, current modeling approaches remain\nlabor-intensive and prone to human errors due to their dependence on manual\nworkflows. These processes typically involve extensive literature reviews,\nformula tuning, and iterative testing, which often lead to inefficiencies. To\naddress this, we propose TR-Agent, an AI-powered framework that autonomously\ndevelops and refines traffic models through a closed-loop, iterative process.\nWe structure the research pipeline into four key stages: idea generation,\ntheory formulation, theory evaluation, and iterative optimization, and\nimplement TR-Agent with four corresponding modules. These modules collaborate\nto retrieve knowledge from external sources, generate novel hypotheses,\nimplement and debug models, and evaluate their performance on evaluation\ndatasets. Through iteratively feedback and refinement, TR-Agent improves both\nmodeling efficiency and effectiveness. We validate the framework on three\nrepresentative traffic models: the Intelligent Driver Model (IDM) for\ncar-following behavior, the MOBIL model for lane-changing, and the\nLighthill-Whitham-Richards (LWR) speed-density relationship for macroscopic\ntraffic flow modeling. Experimental results show substantial performance gains\nover the original models. To assess the robustness and generalizability of the\nimprovements, we conduct additional evaluations across multiple real-world\ndatasets, demonstrating consistent performance gains beyond the original\ndevelopment data. Furthermore, TR-Agent produces interpretable explanations for\neach improvement, enabling researchers to easily verify and extend its results.\nThis makes TR-Agent a valuable assistant for traffic modeling refinement and a\npromising tool for broader applications in transportation research.",
      "tldr_zh": "该研究提出 TR-Agent，一个 AI 驱动框架，用于自动化交通模型的开发和优化，解决传统手动流程的低效和易出错问题。框架采用闭环迭代过程，包括 idea generation、theory formulation、theory evaluation 和 iterative optimization 等四个模块，这些模块协作从外部来源检索知识、生成假设、实现调试模型并评估性能。在 IDM、MOBIL 和 LWR 等代表性交通模型上进行验证，实验结果显示性能显著提升，并在多个真实数据集上证明了其鲁棒性与泛化性，同时提供可解释的改进解释，便于研究人员扩展应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "27 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.16876v3",
      "published_date": "2024-09-25 12:42:25 UTC",
      "updated_date": "2025-05-06 07:58:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:43:17.129797"
    },
    {
      "arxiv_id": "2410.08216v1",
      "title": "New technologies and AI: envisioning future directions for UNSCR 1540",
      "title_zh": "新技术与人工智能：展望 UNSCR 1540 的未来方向",
      "authors": [
        "Clara Punzi"
      ],
      "abstract": "This paper investigates the emerging challenges posed by the integration of\nArtificial Intelligence (AI) in the military domain, particularly within the\ncontext of United Nations Security Council Resolution 1540 (UNSCR 1540), which\nseeks to prevent the proliferation of weapons of mass destruction (WMDs). While\nthe resolution initially focused on nuclear, chemical, and biological threats,\nthe rapid advancement of AI introduces new complexities that were previously\nunanticipated. We critically analyze how AI can both exacerbate existing risks\nassociated with WMDs (e.g., thorough the deployment of kamikaze drones and\nkiller robots) and introduce novel threats (e.g., by exploiting Generative AI\npotentialities), thereby compromising international peace and security. The\npaper calls for an expansion of UNSCR 1540 to address the growing influence of\nAI technologies in the development, dissemination, and potential misuse of\nWMDs, urging the creation of a governance framework to mitigate these emerging\nrisks.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在军事领域的整合对联合国安全理事会决议 UNSCR 1540 带来的新兴挑战，该决议旨在防止大规模杀伤性武器（WMDs）的扩散。论文通过批判性分析指出，AI 可能加剧现有风险（如部署自杀式无人机和杀手机器人）并引入新威胁（如利用 Generative AI 的潜在性），从而威胁国际和平与安全。作者呼吁扩展 UNSCR 1540，建立相应的治理框架，以缓解 AI 在 WMDs 开发、传播和误用中的影响。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "5 pages, no figures, references in the footnotes",
      "pdf_url": "http://arxiv.org/pdf/2410.08216v1",
      "published_date": "2024-09-25 12:41:12 UTC",
      "updated_date": "2024-09-25 12:41:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:43:29.962933"
    },
    {
      "arxiv_id": "2409.16872v2",
      "title": "Ethical and Scalable Automation: A Governance and Compliance Framework for Business Applications",
      "title_zh": "伦理与可扩展自动化：商业应用的治理与合规框架",
      "authors": [
        "Haocheng Lin"
      ],
      "abstract": "The popularisation of applying AI in businesses poses significant challenges\nrelating to ethical principles, governance, and legal compliance. Although\nbusinesses have embedded AI into their day-to-day processes, they lack a\nunified approach for mitigating its potential risks. This paper introduces a\nframework ensuring that AI must be ethical, controllable, viable, and\ndesirable. Balancing these factors ensures the design of a framework that\naddresses its trade-offs, such as balancing performance against explainability.\nA successful framework provides practical advice for businesses to meet\nregulatory requirements in sectors such as finance and healthcare, where it is\ncritical to comply with standards like GPDR and the EU AI Act. Different case\nstudies validate this framework by integrating AI in both academic and\npractical environments. For instance, large language models are cost-effective\nalternatives for generating synthetic opinions that emulate attitudes to\nenvironmental issues. These case studies demonstrate how having a structured\nframework could enhance transparency and maintain performance levels as shown\nfrom the alignment between synthetic and expected distributions. This alignment\nis quantified using metrics like Chi-test scores, normalized mutual\ninformation, and Jaccard indexes. Future research should explore the\nframework's empirical validation in diverse industrial settings further,\nensuring the model's scalability and adaptability.",
      "tldr_zh": "这篇论文提出一个名为Ethical and Scalable Automation的治理和合规框架，用于解决AI在商业应用中的伦理原则、治理和法律合规挑战。该框架确保AI系统在ethical（伦理的）、controllable（可控的）、viable（可行的）和desirable（可取的）方面实现平衡，并处理权衡如性能与explainability（可解释性），为金融和医疗等行业提供符合GPDR和EU AI Act标准的实用指导。通过案例研究，如使用大型语言模型生成合成意见模拟环境态度，框架证明了其提升透明度和性能的效果，并通过Chi-test scores、normalized mutual information和Jaccard indexes等指标量化了对齐度。未来研究将进一步在多样工业环境中验证该框架的可扩展性和适应性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "The current version improves significantly by integrating ethical\n  frameworks, expanding methodology and case studies, enhancing scalability and\n  ethical-legal alignment, acknowledging prior work, and offering clearer\n  structure and practical relevance",
      "pdf_url": "http://arxiv.org/pdf/2409.16872v2",
      "published_date": "2024-09-25 12:39:28 UTC",
      "updated_date": "2024-12-05 20:51:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:43:43.402939"
    },
    {
      "arxiv_id": "2409.16867v2",
      "title": "Multi-objective Evolution of Heuristic Using Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Shunyu Yao",
        "Fei Liu",
        "Xi Lin",
        "Zhichao Lu",
        "Zhenkun Wang",
        "Qingfu Zhang"
      ],
      "abstract": "Heuristics are commonly used to tackle various search and optimization\nproblems. Design heuristics usually require tedious manual crafting with domain\nknowledge. Recent works have incorporated Large Language Models (LLMs) into\nautomatic heuristic search, leveraging their powerful language and coding\ncapacity. However, existing research focuses on the optimal performance on the\ntarget problem as the sole objective, neglecting other criteria such as\nefficiency and scalability, which are vital in practice. To tackle this\nchallenge, we propose to model the heuristic search as a multi-objective\noptimization problem and consider introducing additional practical criteria\nbeyond optimal performance. Due to the complexity of the search space,\nconventional multi-objective optimization methods struggle to effectively\nhandle LLM-based multi-objective heuristic search. We propose the first\nLLM-based multi-objective heuristic search framework, Multi-objective Evolution\nof Heuristic (MEoH), which integrates LLMs in a zero-shot manner to generate a\nnon-dominated set of heuristics to meet multiple design criteria. We design a\nnew dominance-dissimilarity mechanism for effective population management and\nselection, which incorporates both code dissimilarity in the search space and\ndominance in the objective space. MEoH is demonstrated in two well-known\ncombinatorial optimization problems: the online Bin Packing Problem (BPP) and\nthe Traveling Salesman Problem (TSP). The results indicate that a variety of\nelite heuristics are automatically generated in a single run, offering more\ntrade-off options than the existing methods. It successfully achieves\ncompetitive or superior performance while improving efficiency up to 10 times.\nMoreover, we also observe that the multi-objective search introduces novel\ninsights into heuristic design and leads to the discovery of diverse\nheuristics.",
      "tldr_zh": "该研究提出 MEoH（Multi-objective Evolution of Heuristic）框架，利用 Large Language Models (LLMs) 将启发式搜索建模为多目标优化问题，兼顾性能、效率和可扩展性等实际标准，以解决现有方法单一目标的局限性。框架通过零样本方式生成非支配解集，并设计了主导-差异机制来管理种群，确保在搜索空间的代码差异性和目标空间的主导关系。实验在 Bin Packing Problem (BPP) 和 Traveling Salesman Problem (TSP) 上验证了 MEoH 的有效性，结果显示它能自动生成多样化的精英启发式算法，提供更多权衡选项，并将效率提高高达 10 倍，同时带来新的启发式设计洞见。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16867v2",
      "published_date": "2024-09-25 12:32:41 UTC",
      "updated_date": "2025-02-04 05:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:43:53.542911"
    },
    {
      "arxiv_id": "2409.16860v1",
      "title": "The Role of Language Models in Modern Healthcare: A Comprehensive Review",
      "title_zh": "语言模型在现代医疗保健中的作用：全面综述",
      "authors": [
        "Amna Khalid",
        "Ayma Khalid",
        "Umar Khalid"
      ],
      "abstract": "The application of large language models (LLMs) in healthcare has gained\nsignificant attention due to their ability to process complex medical data and\nprovide insights for clinical decision-making. These models have demonstrated\nsubstantial capabilities in understanding and generating natural language,\nwhich is crucial for medical documentation, diagnostics, and patient\ninteraction. This review examines the trajectory of language models from their\nearly stages to the current state-of-the-art LLMs, highlighting their strengths\nin healthcare applications and discussing challenges such as data privacy,\nbias, and ethical considerations. The potential of LLMs to enhance healthcare\ndelivery is explored, alongside the necessary steps to ensure their ethical and\neffective integration into medical practice.",
      "tldr_zh": "这篇综述探讨了大型语言模型 (LLMs) 在现代医疗领域的关键作用，包括从早期发展到当前先进模型的演变。LLMs 展现出强大的能力，能处理复杂医疗数据、生成自然语言以支持临床决策、医疗文档、诊断和患者互动，从而提升医疗效率。论文同时强调了潜在挑战，如数据隐私、bias 和伦理考虑，并提出必要步骤以确保 LLMs 的伦理和有效整合。总的来说，这为 LLMs 在医疗实践中的应用提供了全面见解和未来方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16860v1",
      "published_date": "2024-09-25 12:15:15 UTC",
      "updated_date": "2024-09-25 12:15:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:44:05.293678"
    },
    {
      "arxiv_id": "2409.16854v1",
      "title": "Dispute resolution in legal mediation with quantitative argumentation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Chi"
      ],
      "abstract": "Mediation is often treated as an extension of negotiation, without taking\ninto account the unique role that norms and facts play in legal mediation.\nAdditionally, current approaches for updating argument acceptability in\nresponse to changing variables frequently require the introduction of new\narguments or the removal of existing ones, which can be inefficient and\ncumbersome in decision-making processes within legal disputes. In this paper,\nour contribution is two-fold. First, we introduce a QuAM (Quantitative\nArgumentation Mediate) framework, which integrates the parties' knowledge and\nthe mediator's knowledge, including facts and legal norms, when determining the\nacceptability of a mediation goal. Second, we develop a new formalism to model\nthe relationship between the acceptability of a goal argument and the values\nassigned to a variable associated with the argument. We use a real-world legal\nmediation as a running example to illustrate our approach.",
      "tldr_zh": "本研究针对法律调解中规范和事实的独特作用，提出了一个新的方法来解决现有论点可接受性更新机制的低效问题，该机制往往需要添加或移除论点。研究引入了 QuAM (Quantitative Argumentation Mediate) 框架，该框架整合了当事人和调解人的知识（包括事实和法律规范），以评估调解目标的可接受性。同时，开发了一种新形式主义，用于建模目标论点可接受性与相关变量值之间的关系。通过一个真实世界的法律调解案例作为示例，该方法展示了如何更高效地处理法律争端。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16854v1",
      "published_date": "2024-09-25 12:05:46 UTC",
      "updated_date": "2024-09-25 12:05:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:44:15.973870"
    },
    {
      "arxiv_id": "2409.16849v1",
      "title": "Exposing Assumptions in AI Benchmarks through Cognitive Modelling",
      "title_zh": "通过认知建模揭示 AI 基准中的假设",
      "authors": [
        "Jonathan H. Rystrøm",
        "Kenneth C. Enevoldsen"
      ],
      "abstract": "Cultural AI benchmarks often rely on implicit assumptions about measured\nconstructs, leading to vague formulations with poor validity and unclear\ninterrelations. We propose exposing these assumptions using explicit cognitive\nmodels formulated as Structural Equation Models. Using cross-lingual alignment\ntransfer as an example, we show how this approach can answer key research\nquestions and identify missing datasets. This framework grounds benchmark\nconstruction theoretically and guides dataset development to improve construct\nmeasurement. By embracing transparency, we move towards more rigorous,\ncumulative AI evaluation science, challenging researchers to critically examine\ntheir assessment foundations.",
      "tldr_zh": "该论文指出，文化 AI 基准测试常依赖于隐性假设，导致测量构建模糊、有效性差且相互关系不清。作者提出使用显式认知模型，如 Structural Equation Models，来暴露这些假设，并以 cross-lingual alignment transfer 为例，展示该方法如何回答关键研究问题并识别缺失数据集。该框架为基准测试提供理论基础，并指导数据集开发以提升构建测量，最终促进更严格、累积的 AI 评估科学，并鼓励研究人员 critically 审视评估基础。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.16849v1",
      "published_date": "2024-09-25 11:55:02 UTC",
      "updated_date": "2024-09-25 11:55:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:44:27.738727"
    },
    {
      "arxiv_id": "2409.16830v1",
      "title": "OffRIPP: Offline RL-based Informative Path Planning",
      "title_zh": "OffRIPP：基于离线强化学习的信息路径规划",
      "authors": [
        "Srikar Babu Gadipudi",
        "Srujan Deolasee",
        "Siva Kailas",
        "Wenhao Luo",
        "Katia Sycara",
        "Woojun Kim"
      ],
      "abstract": "Informative path planning (IPP) is a crucial task in robotics, where agents\nmust design paths to gather valuable information about a target environment\nwhile adhering to resource constraints. Reinforcement learning (RL) has been\nshown to be effective for IPP, however, it requires environment interactions,\nwhich are risky and expensive in practice. To address this problem, we propose\nan offline RL-based IPP framework that optimizes information gain without\nrequiring real-time interaction during training, offering safety and\ncost-efficiency by avoiding interaction, as well as superior performance and\nfast computation during execution -- key advantages of RL. Our framework\nleverages batch-constrained reinforcement learning to mitigate extrapolation\nerrors, enabling the agent to learn from pre-collected datasets generated by\narbitrary algorithms. We validate the framework through extensive simulations\nand real-world experiments. The numerical results show that our framework\noutperforms the baselines, demonstrating the effectiveness of the proposed\napproach.",
      "tldr_zh": "这篇论文提出OffRIPP，一种基于离线强化学习(Offline RL)的Informative Path Planning (IPP)框架，旨在帮助机器人代理设计路径以高效收集环境信息，同时避免昂贵的实时交互，从而提升安全性和成本效率。框架通过batch-constrained reinforcement learning从预先收集的数据集学习，减少外推错误并优化信息增益(information gain)。实验结果显示，OffRIPP在模拟和真实场景中 outperform 基线方法，证明了其有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 6 figures, submitted to ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.16830v1",
      "published_date": "2024-09-25 11:30:59 UTC",
      "updated_date": "2024-09-25 11:30:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:44:39.998207"
    },
    {
      "arxiv_id": "2409.16828v3",
      "title": "On the role of Artificial Intelligence methods in modern force-controlled manufacturing robotic tasks",
      "title_zh": "论人工智能方法在现代力控制造机器人任务中的作用",
      "authors": [
        "Vincenzo Petrone",
        "Enrico Ferrentino",
        "Pasquale Chiacchio"
      ],
      "abstract": "This position paper explores the integration of Artificial Intelligence (AI)\ninto force-controlled robotic tasks within the scope of advanced manufacturing,\na cornerstone of Industry 4.0. AI's role in enhancing robotic manipulators -\nkey drivers in the Fourth Industrial Revolution - is rapidly leading to\nsignificant innovations in smart manufacturing. The objective of this article\nis to frame these innovations in practical force-controlled applications - e.g.\ndeburring, polishing, and assembly tasks like peg-in-hole (PiH) - highlighting\ntheir necessity for maintaining high-quality production standards. By reporting\non recent AI-based methodologies, this article contrasts them and identifies\ncurrent challenges to be addressed in future research. The analysis concludes\nwith a perspective on future research directions, emphasizing the need for\ncommon performance metrics to validate AI techniques, integration of various\nenhancements for performance optimization, and the importance of validating\nthem in relevant scenarios. These future directions aim to provide consistency\nwith already adopted approaches, so as to be compatible with manufacturing\nstandards, increasing the relevance of AI-driven methods in both academic and\nindustrial contexts.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在现代力控制造机器人任务中的作用，特别是在 Industry 4.0 框架下如何提升机器人机械臂的创新应用，如去毛刺、抛光和 peg-in-hole（PiH）装配任务，以维持高品质生产标准。文章回顾并对比了最近的 AI 方法，识别了当前挑战，包括方法整合和性能验证问题。未来研究方向强调了建立统一性能指标、优化增强技术，并在相关场景中验证，以确保 AI 驱动方法与制造标准兼容，从而在学术和工业环境中提升其相关性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "In Proceedings of the 21st International Conference on Informatics in\n  Control, Automation and Robotics - Volume 1: ICINCO, 392-399, 2024 , Porto,\n  Portugal",
      "pdf_url": "http://arxiv.org/pdf/2409.16828v3",
      "published_date": "2024-09-25 11:29:26 UTC",
      "updated_date": "2025-01-09 14:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:44:53.868865"
    },
    {
      "arxiv_id": "2409.16826v1",
      "title": "Learning phase-space flows using time-discrete implicit Runge-Kutta PINNs",
      "title_zh": "翻译失败",
      "authors": [
        "Álvaro Fernández Corral",
        "Nicolás Mendoza",
        "Armin Iske",
        "Andrey Yachmenev",
        "Jochen Küpper"
      ],
      "abstract": "We present a computational framework for obtaining multidimensional\nphase-space solutions of systems of non-linear coupled differential equations,\nusing high-order implicit Runge-Kutta Physics- Informed Neural Networks\n(IRK-PINNs) schemes. Building upon foundational work originally solving\ndifferential equations for fields depending on coordinates [J. Comput. Phys.\n378, 686 (2019)], we adapt the scheme to a context where the coordinates are\ntreated as functions. This modification enables us to efficiently solve\nequations of motion for a particle in an external field. Our scheme is\nparticularly useful for explicitly time-independent and periodic fields. We\napply this approach to successfully solve the equations of motion for a mass\nparticle placed in a central force field and a charged particle in a periodic\nelectric field.",
      "tldr_zh": "本研究提出了一种计算框架，使用时间离散隐式 Runge-Kutta Physics-Informed Neural Networks (IRK-PINNs) 来求解多维相空间中非线性耦合微分方程系统的解。该框架基于先前的工作，将坐标视为函数，从而适用于粒子在外部场中的运动方程，特别适合显式时间无关和周期性场。研究通过应用该方法成功求解了质量粒子在中心力场中的运动方程，以及带电粒子在周期性电场中的方程，提高了求解效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.DS",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 4 figures, published in the International Conference on\n  Scientific Computing and Machine Learning, see http://scml.jp",
      "pdf_url": "http://arxiv.org/pdf/2409.16826v1",
      "published_date": "2024-09-25 11:24:18 UTC",
      "updated_date": "2024-09-25 11:24:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:45:05.677278"
    },
    {
      "arxiv_id": "2409.16824v2",
      "title": "Uncertainty Representations in State-Space Layers for Deep Reinforcement Learning under Partial Observability",
      "title_zh": "翻译失败",
      "authors": [
        "Carlos E. Luis",
        "Alessandro G. Bottero",
        "Julia Vinogradska",
        "Felix Berkenkamp",
        "Jan Peters"
      ],
      "abstract": "Optimal decision-making under partial observability requires reasoning about\nthe uncertainty of the environment's hidden state. However, most reinforcement\nlearning architectures handle partial observability with sequence models that\nhave no internal mechanism to incorporate uncertainty in their hidden state\nrepresentation, such as recurrent neural networks, deterministic state-space\nmodels and transformers. Inspired by advances in probabilistic world models for\nreinforcement learning, we propose a standalone Kalman filter layer that\nperforms closed-form Gaussian inference in linear state-space models and train\nit end-to-end within a model-free architecture to maximize returns. Similar to\nefficient linear recurrent layers, the Kalman filter layer processes sequential\ndata using a parallel scan, which scales logarithmically with the sequence\nlength. By design, Kalman filter layers are a drop-in replacement for other\nrecurrent layers in standard model-free architectures, but importantly they\ninclude an explicit mechanism for probabilistic filtering of the latent state\nrepresentation. Experiments in a wide variety of tasks with partial\nobservability show that Kalman filter layers excel in problems where\nuncertainty reasoning is key for decision-making, outperforming other stateful\nmodels.",
      "tldr_zh": "该论文探讨了在部分可观察性（partial observability）条件下进行深度强化学习（deep reinforcement learning）时，如何在状态空间层（state-space layers）中表示环境隐藏状态的不确定性，以支持最优决策。作者提出了一种独立的 Kalman filter 层，该层在线性状态空间模型中执行闭式高斯推理，并将其端到端训练于无模型架构中，以最大化回报，同时利用并行扫描实现高效的序列数据处理。实验结果显示，Kalman filter 层在各种部分可观察任务中表现出色，尤其在需要不确定性推理的关键场景下，优于其他状态模型如 RNN 和 Transformer。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "TMLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.16824v2",
      "published_date": "2024-09-25 11:22:29 UTC",
      "updated_date": "2025-02-18 23:40:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:45:19.658030"
    },
    {
      "arxiv_id": "2409.16821v1",
      "title": "XAI-guided Insulator Anomaly Detection for Imbalanced Datasets",
      "title_zh": "XAI 引导的绝缘子异常检测针对不平衡数据集",
      "authors": [
        "Maximilian Andreas Hoefler",
        "Karsten Mueller",
        "Wojciech Samek"
      ],
      "abstract": "Power grids serve as a vital component in numerous industries, seamlessly\ndelivering electrical energy to industrial processes and technologies, making\ntheir safe and reliable operation indispensable. However, powerlines can be\nhard to inspect due to difficult terrain or harsh climatic conditions.\nTherefore, unmanned aerial vehicles are increasingly deployed to inspect\npowerlines, resulting in a substantial stream of visual data which requires\nswift and accurate processing. Deep learning methods have become widely popular\nfor this task, proving to be a valuable asset in fault detection. In\nparticular, the detection of insulator defects is crucial for predicting\npowerline failures, since their malfunction can lead to transmission\ndisruptions. It is therefore of great interest to continuously maintain and\nrigorously inspect insulator components. In this work we propose a novel\npipeline to tackle this task. We utilize state-of-the-art object detection to\ndetect and subsequently classify individual insulator anomalies. Our approach\naddresses dataset challenges such as imbalance and motion-blurred images\nthrough a fine-tuning methodology which allows us to alter the classification\nfocus of the model by increasing the classification accuracy of anomalous\ninsulators. In addition, we employ explainable-AI tools for precise\nlocalization and explanation of anomalies. This proposed method contributes to\nthe field of anomaly detection, particularly vision-based industrial inspection\nand predictive maintenance. We significantly improve defect detection accuracy\nby up to 13%, while also offering a detailed analysis of model\nmis-classifications and localization quality, showcasing the potential of our\nmethod on real-world data.",
      "tldr_zh": "这篇论文提出了一种XAI-guided方法，用于检测电力线绝缘子的异常，针对不平衡数据集和运动模糊图像等问题。方法结合最先进的物体检测技术来识别并分类绝缘子缺陷，并通过微调模型调整分类焦点，提高异常样本的准确率。同时，运用可解释AI（XAI）工具实现异常的精确定位和解释。实验结果显示，该方法将缺陷检测准确率提高了13%，并提供了模型误分类和定位质量的详细分析，为基于视觉的工业检查和预测性维护做出了贡献。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a workshop paper at ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.16821v1",
      "published_date": "2024-09-25 11:19:42 UTC",
      "updated_date": "2024-09-25 11:19:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:45:30.014043"
    },
    {
      "arxiv_id": "2409.16813v2",
      "title": "PeerArg: Argumentative Peer Review with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Purin Sukpanichnant",
        "Anna Rapberger",
        "Francesca Toni"
      ],
      "abstract": "Peer review is an essential process to determine the quality of papers\nsubmitted to scientific conferences or journals. However, it is subjective and\nprone to biases. Several studies have been conducted to apply techniques from\nNLP to support peer review, but they are based on black-box techniques and\ntheir outputs are difficult to interpret and trust. In this paper, we propose a\nnovel pipeline to support and understand the reviewing and decision-making\nprocesses of peer review: the PeerArg system combining LLMs with methods from\nknowledge representation. PeerArg takes in input a set of reviews for a paper\nand outputs the paper acceptance prediction. We evaluate the performance of the\nPeerArg pipeline on three different datasets, in comparison with a novel\nend-2-end LLM that uses few-shot learning to predict paper acceptance given\nreviews. The results indicate that the end-2-end LLM is capable of predicting\npaper acceptance from reviews, but a variant of the PeerArg pipeline\noutperforms this LLM.",
      "tldr_zh": "本文提出 PeerArg 系统，这是一种结合 LLMs 和知识表示方法的创新管道，用于支持同行评审过程，旨在解决评审的主观性和偏见问题。PeerArg 以论文评论作为输入，输出论文接受预测，并通过透明的结构化方法提升输出可解释性。在三个数据集上的实验中，PeerArg 的变体比使用 few-shot learning 的端到端 LLM 表现出色，证明了其在预测准确性上的优势。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)",
      "pdf_url": "http://arxiv.org/pdf/2409.16813v2",
      "published_date": "2024-09-25 11:09:39 UTC",
      "updated_date": "2025-02-18 16:36:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:45:43.022842"
    },
    {
      "arxiv_id": "2410.08214v1",
      "title": "Embedding an ANN-Based Crystal Plasticity Model into the Finite Element Framework using an ABAQUS User-Material Subroutine",
      "title_zh": "使用 ABAQUS 用户材料子程序将基于 ANN 的晶体塑性模型嵌入有限元框架",
      "authors": [
        "Yuqing He",
        "Yousef Heider",
        "Bernd Markert"
      ],
      "abstract": "This manuscript presents a practical method for incorporating trained Neural\nNetworks (NNs) into the Finite Element (FE) framework using a user material\n(UMAT) subroutine. The work exemplifies crystal plasticity, a complex inelastic\nnon-linear path-dependent material response, with a wide range of applications\nin ABAQUS UMAT. However, this approach can be extended to other material\nbehaviors and FE tools. The use of a UMAT subroutine serves two main purposes:\n(1) it predicts and updates the stress or other mechanical properties of\ninterest directly from the strain history; (2) it computes the Jacobian matrix\neither through backpropagation or numerical differentiation, which plays an\nessential role in the solution convergence. By implementing NNs in a UMAT\nsubroutine, a trained machine learning model can be employed as a data-driven\nconstitutive law within the FEM framework, preserving multiscale information\nthat conventional constitutive laws often neglect or average. The versatility\nof this method makes it a powerful tool for integrating machine learning into\nmechanical simulation. While this approach is expected to provide higher\naccuracy in reproducing realistic material behavior, the reliability of the\nsolution process and the convergence conditions must be paid special attention.\nWhile the theory of the model is explained in [Heider et al. 2020], exemplary\nsource code is also made available for interested readers\n[https://doi.org/10.25835/6n5uu50y]",
      "tldr_zh": "本文提出了一种实用方法，将训练好的神经网络 (NNs) 整合到有限元 (FE) 框架中，使用 ABAQUS 的用户材料子程序 (UMAT)，以模拟复杂的晶体塑性等非线性路径依赖材料行为。UMAT 的核心功能包括从应变历史预测应力和计算 Jacobian 矩阵（通过反向传播或数值微分），从而作为数据驱动的本构关系，提高材料模拟的准确性和多尺度信息保留。该方法可扩展到其他材料模型和 FE 工具，尽管需要特别关注解决方案的收敛性和可靠性；作者提供了示例源代码以便进一步应用。",
      "categories": [
        "physics.comp-ph",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "11 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.08214v1",
      "published_date": "2024-09-25 10:47:18 UTC",
      "updated_date": "2024-09-25 10:47:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:45:56.539917"
    },
    {
      "arxiv_id": "2409.16799v1",
      "title": "Large Language Model Predicts Above Normal All India Summer Monsoon Rainfall in 2024",
      "title_zh": "大语言模型预测2024年全印度夏季季风降雨高于正常水平",
      "authors": [
        "Ujjawal Sharma",
        "Madhav Biyani",
        "Akhil Dev Suresh",
        "Debi Prasad Bhuyan",
        "Saroj Kanta Mishra",
        "Tanmoy Chakraborty"
      ],
      "abstract": "Reliable prediction of the All India Summer Monsoon Rainfall (AISMR) is\npivotal for informed policymaking for the country, impacting the lives of\nbillions of people. However, accurate simulation of AISMR has been a persistent\nchallenge due to the complex interplay of various muti-scale factors and the\ninherent variability of the monsoon system. This research focuses on adapting\nand fine-tuning the latest LLM model, PatchTST, to accurately predict AISMR\nwith a lead time of three months. The fine-tuned PatchTST model, trained with\nhistorical AISMR data, the Ni\\~no3.4 index, and categorical Indian Ocean Dipole\nvalues, outperforms several popular neural network models and statistical\nmodels. This fine-tuned LLM model exhibits an exceptionally low RMSE percentage\nof 0.07% and a Spearman correlation of 0.976. This is particularly impressive,\nsince it is nearly 80% more accurate than the best-performing NN models. The\nmodel predicts an above-normal monsoon for the year 2024, with an accumulated\nrainfall of 921.6 mm in the month of June-September for the entire country.",
      "tldr_zh": "该研究利用LLM模型PatchTST，通过微调历史AISMR数据、Niño 3.4指数和印度洋偶极子值，成功预测印度夏季季风降雨。相比传统神经网络和统计模型，该微调模型表现出色，RMSE百分比仅为0.07%，Spearman相关系数达0.976，比最佳NN模型准确率高80%。研究预测2024年印度夏季季风降雨将高于正常水平，总降雨量为921.6 mm，这为政策制定提供重要参考。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "3 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.16799v1",
      "published_date": "2024-09-25 10:32:18 UTC",
      "updated_date": "2024-09-25 10:32:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:46:05.847943"
    },
    {
      "arxiv_id": "2409.16797v1",
      "title": "Scalable Ensemble Diversification for OOD Generalization and Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Rubinstein",
        "Luca Scimeca",
        "Damien Teney",
        "Seong Joon Oh"
      ],
      "abstract": "Training a diverse ensemble of models has several practical applications such\nas providing candidates for model selection with better out-of-distribution\n(OOD) generalization, and enabling the detection of OOD samples via Bayesian\nprinciples. An existing approach to diverse ensemble training encourages the\nmodels to disagree on provided OOD samples. However, the approach is\ncomputationally expensive and it requires well-separated ID and OOD examples,\nsuch that it has only been demonstrated in small-scale settings.\n  $\\textbf{Method.}$ This work presents a method for Scalable Ensemble\nDiversification (SED) applicable to large-scale settings (e.g. ImageNet) that\ndoes not require OOD samples. Instead, SED identifies hard training samples on\nthe fly and encourages the ensemble members to disagree on these. To improve\nscaling, we show how to avoid the expensive computations in existing methods of\nexhaustive pairwise disagreements across models.\n  $\\textbf{Results.}$ We evaluate the benefits of diversification with\nexperiments on ImageNet. First, for OOD generalization, we observe large\nbenefits from the diversification in multiple settings including output-space\n(classical) ensembles and weight-space ensembles (model soups). Second, for OOD\ndetection, we turn the diversity of ensemble hypotheses into a novel\nuncertainty score estimator that surpasses a large number of OOD detection\nbaselines.\n  Code is available here:\nhttps://github.com/AlexanderRubinstein/diverse-universe-public.",
      "tldr_zh": "本文提出了一种可扩展的模型集合多样化方法（Scalable Ensemble Diversification, SED），旨在提升 OOD (Out-of-Distribution) 泛化和检测性能，而无需依赖 OOD 样本。SED 通过实时识别困难训练样本并鼓励集合成员在这些样本上 disagree，从而避免了现有方法中耗时的成对比较计算。实验结果显示，在 ImageNet 数据集上，SED 显著改善了 OOD 泛化效果，包括输出空间和权重空间集合，并将集合假设的多样性转化为一种新的不确定性分数估计器，超越了多项 OOD 检测基线。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2409.16797v1",
      "published_date": "2024-09-25 10:30:24 UTC",
      "updated_date": "2024-09-25 10:30:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:46:18.759701"
    },
    {
      "arxiv_id": "2409.16791v3",
      "title": "Symbolic State Partitioning for Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mohsen Ghaffari",
        "Mahsa Varshosaz",
        "Einar Broch Johnsen",
        "Andrzej Wąsowski"
      ],
      "abstract": "Tabular reinforcement learning methods cannot operate directly on continuous\nstate spaces. One solution for this problem is to partition the state space. A\ngood partitioning enables generalization during learning and more efficient\nexploitation of prior experiences. Consequently, the learning process becomes\nfaster and produces more reliable policies. However, partitioning introduces\napproximation, which is particularly harmful in the presence of nonlinear\nrelations between state components. An ideal partition should be as coarse as\npossible, while capturing the key structure of the state space for the given\nproblem. This work extracts partitions from the environment dynamics by\nsymbolic execution. We show that symbolic partitioning improves state space\ncoverage with respect to environmental behavior and allows reinforcement\nlearning to perform better for sparse rewards. We evaluate symbolic state space\npartitioning with respect to precision, scalability, learning agent performance\nand state space coverage for the learnt policies.",
      "tldr_zh": "该论文解决了强化学习中表格方法无法直接处理连续状态空间的问题，通过提出符号状态分区（Symbolic State Partitioning）来优化状态空间。方法利用符号执行（Symbolic Execution）从环境动态中提取分区，确保分区尽可能粗糙但捕捉关键结构，从而提升泛化能力、学习效率和策略可靠性，尤其在非线性关系和稀疏奖励场景下减少近似误差。实验评估表明，该方法提高了状态空间覆盖、学习代理性能，并展示了良好的精度和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16791v3",
      "published_date": "2024-09-25 10:09:47 UTC",
      "updated_date": "2025-02-04 09:22:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:46:30.805814"
    },
    {
      "arxiv_id": "2409.16787v1",
      "title": "Enhancing Feature Selection and Interpretability in AI Regression Tasks Through Feature Attribution",
      "title_zh": "通过特征归因增强 AI 回归任务中的特征选择和可解释性",
      "authors": [
        "Alexander Hinterleitner",
        "Thomas Bartz-Beielstein",
        "Richard Schulz",
        "Sebastian Spengler",
        "Thomas Winter",
        "Christoph Leitenmeier"
      ],
      "abstract": "Research in Explainable Artificial Intelligence (XAI) is increasing, aiming\nto make deep learning models more transparent. Most XAI methods focus on\njustifying the decisions made by Artificial Intelligence (AI) systems in\nsecurity-relevant applications. However, relatively little attention has been\ngiven to using these methods to improve the performance and robustness of deep\nlearning algorithms. Additionally, much of the existing XAI work primarily\naddresses classification problems. In this study, we investigate the potential\nof feature attribution methods to filter out uninformative features in input\ndata for regression problems, thereby improving the accuracy and stability of\npredictions. We introduce a feature selection pipeline that combines Integrated\nGradients with k-means clustering to select an optimal set of variables from\nthe initial data space. To validate the effectiveness of this approach, we\napply it to a real-world industrial problem - blade vibration analysis in the\ndevelopment process of turbo machinery.",
      "tldr_zh": "本研究探讨了如何通过特征归因方法提升AI回归任务的特征选择和可解释性（XAI），以改善模型的准确性和稳定性。论文提出一个特征选择管道，将Integrated Gradients与k-means clustering相结合，从初始数据空间中筛选出最优变量。该方法应用于真实工业场景——涡轮机械的叶片振动分析，验证了其有效性，并扩展了XAI在回归问题中的应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68",
        "I.2.0"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16787v1",
      "published_date": "2024-09-25 09:50:51 UTC",
      "updated_date": "2024-09-25 09:50:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:46:41.937694"
    },
    {
      "arxiv_id": "2409.16783v1",
      "title": "Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction",
      "title_zh": "整体自动化红队测试：通过自上而下的测试用例生成和多轮交互针对大语言模型",
      "authors": [
        "Jinchuan Zhang",
        "Yan Zhou",
        "Yaxin Liu",
        "Ziming Li",
        "Songlin Hu"
      ],
      "abstract": "Automated red teaming is an effective method for identifying misaligned\nbehaviors in large language models (LLMs). Existing approaches, however, often\nfocus primarily on improving attack success rates while overlooking the need\nfor comprehensive test case coverage. Additionally, most of these methods are\nlimited to single-turn red teaming, failing to capture the multi-turn dynamics\nof real-world human-machine interactions. To overcome these limitations, we\npropose HARM (Holistic Automated Red teaMing), which scales up the diversity of\ntest cases using a top-down approach based on an extensible, fine-grained risk\ntaxonomy. Our method also leverages a novel fine-tuning strategy and\nreinforcement learning techniques to facilitate multi-turn adversarial probing\nin a human-like manner. Experimental results demonstrate that our framework\nenables a more systematic understanding of model vulnerabilities and offers\nmore targeted guidance for the alignment process.",
      "tldr_zh": "该论文提出 HARM（Holistic Automated Red Teaming）框架，通过自上而下的测试案例生成方法和基于可扩展细粒度风险分类法，提升大型语言模型(LLMs)的自动红队测试(Automated Red Teaming)覆盖多样性。HARM 还采用新型微调策略和强化学习技术，实现多轮互动的对抗性探测，模拟真实人类-机器互动。实验结果表明，该框架能更系统地识别模型漏洞，并为模型对齐过程提供更针对性的指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 camera ready version",
      "pdf_url": "http://arxiv.org/pdf/2409.16783v1",
      "published_date": "2024-09-25 09:44:48 UTC",
      "updated_date": "2024-09-25 09:44:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:46:55.764866"
    },
    {
      "arxiv_id": "2409.16779v1",
      "title": "LLaMa-SciQ: An Educational Chatbot for Answering Science MCQ",
      "title_zh": "翻译失败",
      "authors": [
        "Marc-Antoine Allard",
        "Matin Ansaripour",
        "Maria Yuffa",
        "Paul Teiletche"
      ],
      "abstract": "Large Language Models (LLMs) often struggle with tasks requiring mathematical\nreasoning, particularly multiple-choice questions (MCQs). To address this\nissue, we developed LLaMa-SciQ, an educational chatbot designed to assist\ncollege students in solving and understanding MCQs in STEM fields. We begin by\nfine-tuning and aligning the models to human preferences. After comparing the\nperformance of Mistral-7B and LLaMa-8B, we selected the latter as the base\nmodel due to its higher evaluation accuracy. To further enhance accuracy, we\nimplement Retrieval-Augmented Generation (RAG) and apply quantization to\ncompress the model, reducing inference time and increasing accessibility for\nstudents. For mathematical reasoning, LLaMa-SciQ achieved 74.5% accuracy on the\nGSM8k dataset and 30% on the MATH dataset. However, RAG does not improve\nperformance and even reduces it, likely due to retriever issues or the model's\nunfamiliarity with context. Despite this, the quantized model shows only a 5%\nloss in performance, demonstrating significant efficiency improvements.",
      "tldr_zh": "本研究开发了LLaMa-SciQ，一种教育聊天机器人，旨在帮助大学生解答STEM领域的科学多项选择题(MCQs)，以解决Large Language Models (LLMs)在数学推理任务上的不足。研究团队通过微调和与人类偏好对齐模型，选择LLaMa-8B作为基础模型，并引入Retrieval-Augmented Generation (RAG)及量化技术，以提升准确性和效率。实验结果显示，LLaMa-SciQ在GSM8k数据集上达到74.5%的准确率，在MATH数据集上为30%，但RAG并未改善性能，反而可能因检索器问题而降低效果；量化模型仅损失5%的性能，却显著提高了推理速度和可访问性。总的来说，此系统为LLMs在教育应用中提供了更高效的辅助工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16779v1",
      "published_date": "2024-09-25 09:41:46 UTC",
      "updated_date": "2024-09-25 09:41:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:47:09.282624"
    },
    {
      "arxiv_id": "2409.16769v1",
      "title": "Super Level Sets and Exponential Decay: A Synergistic Approach to Stable Neural Network Training",
      "title_zh": "翻译失败",
      "authors": [
        "Jatin Chaudhary",
        "Dipak Nidhi",
        "Jukka Heikkonen",
        "Haari Merisaari",
        "Rajiv Kanth"
      ],
      "abstract": "The objective of this paper is to enhance the optimization process for neural\nnetworks by developing a dynamic learning rate algorithm that effectively\nintegrates exponential decay and advanced anti-overfitting strategies. Our\nprimary contribution is the establishment of a theoretical framework where we\ndemonstrate that the optimization landscape, under the influence of our\nalgorithm, exhibits unique stability characteristics defined by Lyapunov\nstability principles. Specifically, we prove that the superlevel sets of the\nloss function, as influenced by our adaptive learning rate, are always\nconnected, ensuring consistent training dynamics. Furthermore, we establish the\n\"equiconnectedness\" property of these superlevel sets, which maintains uniform\nstability across varying training conditions and epochs. This paper contributes\nto the theoretical understanding of dynamic learning rate mechanisms in neural\nnetworks and also pave the way for the development of more efficient and\nreliable neural optimization techniques. This study intends to formalize and\nvalidate the equiconnectedness of loss function as superlevel sets in the\ncontext of neural network training, opening newer avenues for future research\nin adaptive machine learning algorithms. We leverage previous theoretical\ndiscoveries to propose training mechanisms that can effectively handle complex\nand high-dimensional data landscapes, particularly in applications requiring\nhigh precision and reliability.",
      "tldr_zh": "本研究提出了一种动态学习率算法，将指数衰减与高级反过拟合策略相结合，以提升神经网络的优化稳定性。主要贡献是建立一个理论框架，利用Lyapunov稳定性原则，证明了损失函数的superlevel sets始终保持连接性，并引入equiconnectedness属性，确保训练动态在不同条件下保持一致。该方法不仅深化了对动态学习率机制的理解，还为开发更高效的神经网络优化技术提供了新途径，尤其适用于处理复杂高维数据。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16769v1",
      "published_date": "2024-09-25 09:27:17 UTC",
      "updated_date": "2024-09-25 09:27:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:47:19.356069"
    },
    {
      "arxiv_id": "2409.16765v1",
      "title": "MaViLS, a Benchmark Dataset for Video-to-Slide Alignment, Assessing Baseline Accuracy with a Multimodal Alignment Algorithm Leveraging Speech, OCR, and Visual Features",
      "title_zh": "翻译失败",
      "authors": [
        "Katharina Anderer",
        "Andreas Reich",
        "Matthias Wölfel"
      ],
      "abstract": "This paper presents a benchmark dataset for aligning lecture videos with\ncorresponding slides and introduces a novel multimodal algorithm leveraging\nfeatures from speech, text, and images. It achieves an average accuracy of 0.82\nin comparison to SIFT (0.56) while being approximately 11 times faster. Using\ndynamic programming the algorithm tries to determine the optimal slide\nsequence. The results show that penalizing slide transitions increases\naccuracy. Features obtained via optical character recognition (OCR) contribute\nthe most to a high matching accuracy, followed by image features. The findings\nhighlight that audio transcripts alone provide valuable information for\nalignment and are beneficial if OCR data is lacking. Variations in matching\naccuracy across different lectures highlight the challenges associated with\nvideo quality and lecture style. The novel multimodal algorithm demonstrates\nrobustness to some of these challenges, underscoring the potential of the\napproach.",
      "tldr_zh": "这篇论文引入了 MaViLS 基准数据集，用于评估讲座视频与幻灯片的对齐任务，并提出了一种新颖的多模态对齐算法，利用语音、OCR 和视觉特征。算法通过动态编程确定最佳幻灯片序列，平均准确率达到 0.82，比 SIFT (0.56) 高出近 46%，且速度快 11 倍。研究发现，OCR 特征对匹配准确率贡献最大，其次是图像特征，而音频转录单独使用也能提供宝贵信息，并使算法对视频质量和讲座风格的挑战表现出较强鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16765v1",
      "published_date": "2024-09-25 09:24:42 UTC",
      "updated_date": "2024-09-25 09:24:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:47:33.755303"
    },
    {
      "arxiv_id": "2409.16764v2",
      "title": "Offline and Distributional Reinforcement Learning for Radio Resource Management",
      "title_zh": "翻译失败",
      "authors": [
        "Eslam Eldeeb",
        "Hirley Alves"
      ],
      "abstract": "Reinforcement learning (RL) has proved to have a promising role in future\nintelligent wireless networks. Online RL has been adopted for radio resource\nmanagement (RRM), taking over traditional schemes. However, due to its reliance\non online interaction with the environment, its role becomes limited in\npractical, real-world problems where online interaction is not feasible. In\naddition, traditional RL stands short in front of the uncertainties and risks\nin real-world stochastic environments. In this manner, we propose an offline\nand distributional RL scheme for the RRM problem, enabling offline training\nusing a static dataset without any interaction with the environment and\nconsidering the sources of uncertainties using the distributions of the return.\nSimulation results demonstrate that the proposed scheme outperforms\nconventional resource management models. In addition, it is the only scheme\nthat surpasses online RL with a 10 % gain over online RL.",
      "tldr_zh": "本研究针对无线资源管理（RRM）问题，提出了一种离线和分布式的强化学习（Offline and Distributional RL）方案，以解决在线强化学习（Online RL）依赖环境互动的局限性，以及传统 RL 在不确定环境中的不足。该方案利用静态数据集进行离线训练，并通过回报的分布来考虑不确定性来源，从而实现高效的资源分配。模拟结果表明，该方法优于传统资源管理模型，并比在线 RL 提升了 10% 的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16764v2",
      "published_date": "2024-09-25 09:22:23 UTC",
      "updated_date": "2025-01-23 12:00:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:47:44.920640"
    },
    {
      "arxiv_id": "2409.16735v1",
      "title": "GB-RVFL: Fusion of Randomized Neural Network and Granular Ball Computing",
      "title_zh": "GB-RVFL：随机化神经网络与颗粒球计算的融合",
      "authors": [
        "M. Sajid",
        "A. Quadir",
        "M. Tanveer"
      ],
      "abstract": "The random vector functional link (RVFL) network is a prominent\nclassification model with strong generalization ability. However, RVFL treats\nall samples uniformly, ignoring whether they are pure or noisy, and its\nscalability is limited due to the need for inverting the entire training\nmatrix. To address these issues, we propose granular ball RVFL (GB-RVFL) model,\nwhich uses granular balls (GBs) as inputs instead of training samples. This\napproach enhances scalability by requiring only the inverse of the GB center\nmatrix and improves robustness against noise and outliers through the coarse\ngranularity of GBs. Furthermore, RVFL overlooks the dataset's geometric\nstructure. To address this, we propose graph embedding GB-RVFL (GE-GB-RVFL)\nmodel, which fuses granular computing and graph embedding (GE) to preserve the\ntopological structure of GBs. The proposed GB-RVFL and GE-GB-RVFL models are\nevaluated on KEEL, UCI, NDC and biomedical datasets, demonstrating superior\nperformance compared to baseline models.",
      "tldr_zh": "本研究针对随机向量功能链接(RVFL)网络在分类任务中的局限性，包括统一处理样本忽略噪声、可扩展性差（需反转整个训练矩阵）和忽略数据集几何结构，提出了两种改进模型。GB-RVFL模型使用granular balls (GBs)作为输入，仅需反转GB中心矩阵，从而提升可扩展性和对噪声及异常值的鲁棒性；此外，GE-GB-RVFL模型进一步融合granular computing和graph embedding (GE)，以保留GBs的拓扑结构。实验在KEEL、UCI、NDC和生物医学数据集上显示，这两种模型均优于基线模型，证明了其在泛化能力和性能上的显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16735v1",
      "published_date": "2024-09-25 08:33:01 UTC",
      "updated_date": "2024-09-25 08:33:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:47:57.294250"
    },
    {
      "arxiv_id": "2409.16730v1",
      "title": "Non-stationary BERT: Exploring Augmented IMU Data For Robust Human Activity Recognition",
      "title_zh": "非平稳 BERT：探索增强的 IMU 数据用于鲁棒人类活动识别",
      "authors": [
        "Ning Sun",
        "Yufei Wang",
        "Yuwei Zhang",
        "Jixiang Wan",
        "Shenyue Wang",
        "Ping Liu",
        "Xudong Zhang"
      ],
      "abstract": "Human Activity Recognition (HAR) has gained great attention from researchers\ndue to the popularity of mobile devices and the need to observe users' daily\nactivity data for better human-computer interaction. In this work, we collect a\nhuman activity recognition dataset called OPPOHAR consisting of phone IMU data.\nTo facilitate the employment of HAR system in mobile phone and to achieve\nuser-specific activity recognition, we propose a novel light-weight network\ncalled Non-stationary BERT with a two-stage training method. We also propose a\nsimple yet effective data augmentation method to explore the deeper\nrelationship between the accelerator and gyroscope data from the IMU. The\nnetwork achieves the state-of-the-art performance testing on various activity\nrecognition datasets and the data augmentation method demonstrates its wide\napplicability.",
      "tldr_zh": "本研究针对人类活动识别(HAR)领域，收集了名为OPPOHAR的手机IMU数据数据集，以实现用户特定的活动识别。研究提出了一种轻量级网络Non-stationary BERT，结合两阶段训练方法和一个简单有效的数据增强技术，用于探索IMU中加速度计和陀螺仪数据之间的更深层关系。该网络在多种HAR数据集上达到了最先进性能，且数据增强方法展示了广泛的适用性。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16730v1",
      "published_date": "2024-09-25 08:28:54 UTC",
      "updated_date": "2024-09-25 08:28:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:48:08.001083"
    },
    {
      "arxiv_id": "2409.16721v2",
      "title": "Grading and Anomaly Detection for Automated Retinal Image Analysis using Deep Learning",
      "title_zh": "使用深度学习的自动视网膜图像分析的分级和异常检测",
      "authors": [
        "Syed Mohd Faisal Malik",
        "Md Tabrez Nafis",
        "Mohd Abdul Ahad",
        "Safdar Tanweer"
      ],
      "abstract": "The significant portion of diabetic patients was affected due to major\nblindness caused by Diabetic retinopathy (DR). For diabetic retinopathy, lesion\nsegmentation, and detection the comprehensive examination is delved into the\ndeep learning techniques application. The study conducted a systematic\nliterature review using the PRISMA analysis and 62 articles has been\ninvestigated in the research. By including CNN-based models for DR grading, and\nfeature fusion several deep-learning methodologies are explored during the\nstudy. For enhancing effectiveness in classification accuracy and robustness\nthe data augmentation and ensemble learning strategies are scrutinized. By\ndemonstrating the superior performance compared to individual models the\nefficacy of ensemble learning methods is investigated. The potential ensemble\napproaches in DR diagnosis are shown by the integration of multiple pre-trained\nnetworks with custom classifiers that yield high specificity. The diverse\ndeep-learning techniques that are employed for detecting DR lesions are\ndiscussed within the diabetic retinopathy lesions segmentation and detection\nsection. By emphasizing the requirement for continued research and integration\ninto clinical practice deep learning shows promise for personalized healthcare\nand early detection of diabetics.",
      "tldr_zh": "这篇论文通过系统文献回顾（使用 PRISMA 分析）调查了 62 篇文章，探讨了深度学习技术在糖尿病视网膜病变（DR）分级和异常检测中的应用。研究重点考察了基于 CNN 的模型、特征融合、数据增强和集成学习策略，以提升分类准确性和鲁棒性。结果显示，集成学习方法通过整合多个预训练网络和自定义分类器，显著优于单个模型，并实现了高特异性。总体而言，该研究突出了深度学习在 DR 病变检测、个性化医疗和早期诊断方面的潜力，推动其向临床实践整合。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Diabetic retinopathy, segmentation, images on retinal fundus,\n  convolutional neural network",
      "pdf_url": "http://arxiv.org/pdf/2409.16721v2",
      "published_date": "2024-09-25 08:13:39 UTC",
      "updated_date": "2024-11-19 07:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:48:21.510976"
    },
    {
      "arxiv_id": "2409.16718v2",
      "title": "Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Li",
        "Jike Zhong",
        "Chenxin Li",
        "Liuzhuozheng Li",
        "Nie Lin",
        "Masashi Sugiyama"
      ],
      "abstract": "Recent advances in fine-tuning Vision-Language Models (VLMs) have witnessed\nthe success of prompt tuning and adapter tuning, while the classic model\nfine-tuning on inherent parameters seems to be overlooked. It is believed that\nfine-tuning the parameters of VLMs with few-shot samples corrupts the\npre-trained knowledge since fine-tuning the CLIP model even degrades\nperformance. In this paper, we revisit this viewpoint, and propose a new\nperspective: fine-tuning the specific parameters instead of all will uncover\nthe power of classic model fine-tuning on VLMs. Through our meticulous study,\nwe propose ClipFit, a simple yet effective method to fine-tune CLIP without\nintroducing any overhead of extra parameters. We demonstrate that by only\nfine-tuning the specific bias terms and normalization layers, ClipFit can\nimprove the performance of zero-shot CLIP by 7.27\\% average harmonic mean\naccuracy. Lastly, to understand how fine-tuning in CLIPFit affects the\npre-trained models, we conducted extensive experimental analyses w.r.t. changes\nin internal parameters and representations. We found that low-level text bias\nlayers and the first layer normalization layer change much more than other\nlayers. The code is available at \\url{https://github.com/minglllli/CLIPFit}.",
      "tldr_zh": "该论文重新审视了视觉语言模型(VLMs)的微调方法，挑战了传统观点，即微调VLMs的参数会破坏预训练知识。作者提出ClipFit，一种简单高效的微调策略，仅对特定参数（如bias terms和normalization layers）进行调整，而不引入额外参数，从而提升模型性能。实验结果显示，ClipFit将零样本CLIP的平均谐波均值准确率提高了7.27%。此外，通过对内部参数和表示的分析，研究发现低级文本偏差层和第一个层normalization layer的变化最为显著，为VLMs微调提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "EMNLP 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2409.16718v2",
      "published_date": "2024-09-25 08:07:18 UTC",
      "updated_date": "2024-11-19 09:27:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:48:32.050267"
    },
    {
      "arxiv_id": "2409.16706v2",
      "title": "Pix2Next: Leveraging Vision Foundation Models for RGB to NIR Image Translation",
      "title_zh": "Pix2Next：利用视觉基础模型进行 RGB 到 NIR 图像翻译",
      "authors": [
        "Youngwan Jin",
        "Incheol Park",
        "Hanbin Song",
        "Hyeongjin Ju",
        "Yagiz Nalcakan",
        "Shiho Kim"
      ],
      "abstract": "This paper proposes Pix2Next, a novel image-to-image translation framework\ndesigned to address the challenge of generating high-quality Near-Infrared\n(NIR) images from RGB inputs. Our approach leverages a state-of-the-art Vision\nFoundation Model (VFM) within an encoder-decoder architecture, incorporating\ncross-attention mechanisms to enhance feature integration. This design captures\ndetailed global representations and preserves essential spectral\ncharacteristics, treating RGB-to-NIR translation as more than a simple domain\ntransfer problem. A multi-scale PatchGAN discriminator ensures realistic image\ngeneration at various detail levels, while carefully designed loss functions\ncouple global context understanding with local feature preservation. We\nperformed experiments on the RANUS dataset to demonstrate Pix2Next's advantages\nin quantitative metrics and visual quality, improving the FID score by 34.81%\ncompared to existing methods. Furthermore, we demonstrate the practical utility\nof Pix2Next by showing improved performance on a downstream object detection\ntask using generated NIR data to augment limited real NIR datasets. The\nproposed approach enables the scaling up of NIR datasets without additional\ndata acquisition or annotation efforts, potentially accelerating advancements\nin NIR-based computer vision applications.",
      "tldr_zh": "本论文提出 Pix2Next，一种新型图像到图像翻译框架，旨在从 RGB 输入生成高质量的 Near-Infrared (NIR) 图像，通过利用先进的 Vision Foundation Model (VFM) 在编码器-解码器架构中整合 cross-attention 机制，以捕捉全局表示并保留关键频谱特性，同时采用多尺度 PatchGAN 鉴别器和优化损失函数来平衡全局上下文和局部特征。实验在 RANUS 数据集上证明了该框架的优越性，比现有方法改善 FID score 34.81%，并在下游物体检测任务中提升性能。Pix2Next 的创新方法无需额外数据采集或标注，即可扩展 NIR 数据集，推动 NIR-based 计算机视觉应用的进步。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages,12 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.16706v2",
      "published_date": "2024-09-25 07:51:47 UTC",
      "updated_date": "2025-04-23 07:34:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:48:46.362703"
    },
    {
      "arxiv_id": "2409.16694v2",
      "title": "A Survey of Low-bit Large Language Models: Basics, Systems, and Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Ruihao Gong",
        "Yifu Ding",
        "Zining Wang",
        "Chengtao Lv",
        "Xingyu Zheng",
        "Jinyang Du",
        "Haotong Qin",
        "Jinyang Guo",
        "Michele Magno",
        "Xianglong Liu"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable advancements in natural\nlanguage processing, showcasing exceptional performance across various tasks.\nHowever, the expensive memory and computational requirements present\nsignificant challenges for their practical deployment. Low-bit quantization has\nemerged as a critical approach to mitigate these challenges by reducing the\nbit-width of model parameters, activations, and gradients, thus decreasing\nmemory usage and computational demands. This paper presents a comprehensive\nsurvey of low-bit quantization methods tailored for LLMs, covering the\nfundamental principles, system implementations, and algorithmic strategies. An\noverview of basic concepts and new data formats specific to low-bit LLMs is\nfirst introduced, followed by a review of frameworks and systems that\nfacilitate low-bit LLMs across various hardware platforms. Then, we categorize\nand analyze techniques and toolkits for efficient low-bit training and\ninference of LLMs. Finally, we conclude with a discussion of future trends and\npotential advancements of low-bit LLMs. Our systematic overview from basic,\nsystem, and algorithm perspectives can offer valuable insights and guidelines\nfor future works to enhance the efficiency and applicability of LLMs through\nlow-bit quantization.",
      "tldr_zh": "这篇论文调查了低-bit 大型语言模型（LLMs）的基本原理、系统实现和算法策略，以解决LLMs在实际部署中面临的内存和计算资源挑战。作者首先介绍了低-bit量化方法的核心概念和新数据格式，随后审视了支持低-bit LLMs的框架和硬件平台，以及用于高效训练和推理的技术工具包。通过全面分类和分析，这些方法可显著降低模型参数的位宽，从而提升LLMs的效率和适用性。论文最终讨论了低-bit LLMs的未来趋势，为进一步优化LLMs提供宝贵的见解和指导。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Ruihao Gong leads the overall organization of the survey, with Yifu\n  Ding and Jinyang Du contributing to Sections 2 and 3. Xingyu Zheng is\n  responsible for authoring Section 4, while Chengtao Lv and Zining Wang\n  collaborate on Section 5. Haotong Qin, Jinyang Guo, Michele Magno, and\n  Xianglong Liu provide guidance during the whole process and assist in\n  refining the final manuscript",
      "pdf_url": "http://arxiv.org/pdf/2409.16694v2",
      "published_date": "2024-09-25 07:38:02 UTC",
      "updated_date": "2024-09-30 12:55:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:48:56.344276"
    },
    {
      "arxiv_id": "2409.16693v1",
      "title": "CaBRNet, an open-source library for developing and evaluating Case-Based Reasoning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Romain Xu-Darme",
        "Aymeric Varasse",
        "Alban Grastien",
        "Julien Girard",
        "Zakaria Chihani"
      ],
      "abstract": "In the field of explainable AI, a vibrant effort is dedicated to the design\nof self-explainable models, as a more principled alternative to post-hoc\nmethods that attempt to explain the decisions after a model opaquely makes\nthem. However, this productive line of research suffers from common downsides:\nlack of reproducibility, unfeasible comparison, diverging standards. In this\npaper, we propose CaBRNet, an open-source, modular, backward-compatible\nframework for Case-Based Reasoning Networks:\nhttps://github.com/aiser-team/cabrnet.",
      "tldr_zh": "在可解释AI领域，自解释模型作为后验方法的替代方案面临可重复性差、难以比较和标准不一致等问题，本文提出CaBRNet，一个开源、模块化和向后兼容的框架，用于开发和评估Case-Based Reasoning Models。CaBRNet旨在解决这些痛点，提供统一的工具来提升模型的可比性和可靠性。该框架已在GitHub上开源（https://github.com/aiser-team/cabrnet），为研究者提供便利的开发环境。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16693v1",
      "published_date": "2024-09-25 07:32:03 UTC",
      "updated_date": "2024-09-25 07:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:49:08.746762"
    },
    {
      "arxiv_id": "2409.16689v1",
      "title": "Layout-Corrector: Alleviating Layout Sticking Phenomenon in Discrete Diffusion Model",
      "title_zh": "Layout-Corrector：缓解离散扩散模型中的布局粘滞现象",
      "authors": [
        "Shoma Iwai",
        "Atsuki Osanai",
        "Shunsuke Kitada",
        "Shinichiro Omachi"
      ],
      "abstract": "Layout generation is a task to synthesize a harmonious layout with elements\ncharacterized by attributes such as category, position, and size. Human\ndesigners experiment with the placement and modification of elements to create\naesthetic layouts, however, we observed that current discrete diffusion models\n(DDMs) struggle to correct inharmonious layouts after they have been generated.\nIn this paper, we first provide novel insights into layout sticking phenomenon\nin DDMs and then propose a simple yet effective layout-assessment module\nLayout-Corrector, which works in conjunction with existing DDMs to address the\nlayout sticking problem. We present a learning-based module capable of\nidentifying inharmonious elements within layouts, considering overall layout\nharmony characterized by complex composition. During the generation process,\nLayout-Corrector evaluates the correctness of each token in the generated\nlayout, reinitializing those with low scores to the ungenerated state. The DDM\nthen uses the high-scored tokens as clues to regenerate the harmonized tokens.\nLayout-Corrector, tested on common benchmarks, consistently boosts\nlayout-generation performance when in conjunction with various state-of-the-art\nDDMs. Furthermore, our extensive analysis demonstrates that the\nLayout-Corrector (1) successfully identifies erroneous tokens, (2) facilitates\ncontrol over the fidelity-diversity trade-off, and (3) significantly mitigates\nthe performance drop associated with fast sampling.",
      "tldr_zh": "本文研究了离散扩散模型(DDMs)中的布局粘附现象，该问题导致模型难以纠正已生成的不和谐布局。作者提出了一种简单有效的模块Layout-Corrector，通过学习-based评估来识别布局中的不和谐元素，并在生成过程中重置低分标记，利用高分标记作为线索重新生成和谐布局。该模块与各种最先进DDMs结合后，在基准测试中提升了生成性能，并成功实现了错误标记识别、控制保真度与多样性权衡，以及缓解快速采样导致的性能下降。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV2024, Project Page:\n  https://iwa-shi.github.io/Layout-Corrector-Project-Page/",
      "pdf_url": "http://arxiv.org/pdf/2409.16689v1",
      "published_date": "2024-09-25 07:24:43 UTC",
      "updated_date": "2024-09-25 07:24:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:49:31.309745"
    },
    {
      "arxiv_id": "2409.16686v2",
      "title": "MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making",
      "title_zh": "MSI-Agent：",
      "authors": [
        "Dayuan Fu",
        "Biqing Qi",
        "Yihuai Gao",
        "Che Jiang",
        "Guanting Dong",
        "Bowen Zhou"
      ],
      "abstract": "Long-term memory is significant for agents, in which insights play a crucial\nrole. However, the emergence of irrelevant insight and the lack of general\ninsight can greatly undermine the effectiveness of insight. To solve this\nproblem, in this paper, we introduce Multi-Scale Insight Agent (MSI-Agent), an\nembodied agent designed to improve LLMs' planning and decision-making ability\nby summarizing and utilizing insight effectively across different scales. MSI\nachieves this through the experience selector, insight generator, and insight\nselector. Leveraging a three-part pipeline, MSI can generate task-specific and\nhigh-level insight, store it in a database, and then use relevant insight from\nit to aid in decision-making. Our experiments show that MSI outperforms another\ninsight strategy when planning by GPT3.5. Moreover, We delve into the\nstrategies for selecting seed experience and insight, aiming to provide LLM\nwith more useful and relevant insight for better decision-making. Our\nobservations also indicate that MSI exhibits better robustness when facing\ndomain-shifting scenarios.",
      "tldr_zh": "该论文提出MSI-Agent，一种融入多尺度洞见( Multi-Scale Insight )的具身代理框架，旨在通过有效总结和利用洞见来提升LLMs在规划和决策方面的能力，以解决无关洞见和洞见缺乏的问题。MSI-Agent采用一个三部分管道，包括experience selector、insight generator和insight selector，用于生成任务特定和高层次洞见、存储于数据库，并选择相关洞见辅助决策。实验结果显示，MSI-Agent在GPT3.5的规划任务中优于其他策略，并展示了更好的鲁棒性，尤其在领域转移场景中。此外，论文探讨了选择种子经验和洞见的策略，以提供更相关的信息支持决策。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16686v2",
      "published_date": "2024-09-25 07:21:51 UTC",
      "updated_date": "2024-11-09 07:23:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:49:32.884025"
    },
    {
      "arxiv_id": "2409.16684v2",
      "title": "Erase then Rectify: A Training-Free Parameter Editing Approach for Cost-Effective Graph Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhe-Rui Yang",
        "Jindong Han",
        "Chang-Dong Wang",
        "Hao Liu"
      ],
      "abstract": "Graph unlearning, which aims to eliminate the influence of specific nodes,\nedges, or attributes from a trained Graph Neural Network (GNN), is essential in\napplications where privacy, bias, or data obsolescence is a concern. However,\nexisting graph unlearning techniques often necessitate additional training on\nthe remaining data, leading to significant computational costs, particularly\nwith large-scale graphs. To address these challenges, we propose a two-stage\ntraining-free approach, Erase then Rectify (ETR), designed for efficient and\nscalable graph unlearning while preserving the model utility. Specifically, we\nfirst build a theoretical foundation showing that masking parameters critical\nfor unlearned samples enables effective unlearning. Building on this insight,\nthe Erase stage strategically edits model parameters to eliminate the impact of\nunlearned samples and their propagated influence on intercorrelated nodes. To\nfurther ensure the GNN's utility, the Rectify stage devises a gradient\napproximation method to estimate the model's gradient on the remaining dataset,\nwhich is then used to enhance model performance. Overall, ETR achieves graph\nunlearning without additional training or full training data access,\nsignificantly reducing computational overhead and preserving data privacy.\nExtensive experiments on seven public datasets demonstrate the consistent\nsuperiority of ETR in model utility, unlearning efficiency, and unlearning\neffectiveness, establishing it as a promising solution for real-world graph\nunlearning challenges.",
      "tldr_zh": "该论文提出了一种无训练参数编辑方法Erase then Rectify (ETR)，旨在实现高效的Graph Unlearning，以消除Graph Neural Network (GNN)中特定节点、边或属性的影响，同时降低计算成本并保护数据隐私。ETR分为两个阶段：Erase阶段通过战略性地编辑模型参数来移除未学习样本及其传播影响；Rectify阶段则使用梯度近似方法估计模型在剩余数据集上的梯度，从而提升模型效用。该方法无需额外训练或完整数据访问，在七个公共数据集上的实验证明，ETR在模型效用、取消学习效率和效果上均优于基线方案，为实际应用中的图取消学习提供了可行解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2409.16684v2",
      "published_date": "2024-09-25 07:20:59 UTC",
      "updated_date": "2024-12-19 14:18:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:49:45.340971"
    },
    {
      "arxiv_id": "2409.16678v1",
      "title": "TSBP: Improving Object Detection in Histology Images via Test-time Self-guided Bounding-box Propagation",
      "title_zh": "TSBP：通过测试时自引导边界框传播改进组织学图像中的物体检测",
      "authors": [
        "Tingting Yang",
        "Liang Xiao",
        "Yizhe Zhang"
      ],
      "abstract": "A global threshold (e.g., 0.5) is often applied to determine which bounding\nboxes should be included in the final results for an object detection task. A\nhigher threshold reduces false positives but may result in missing a\nsignificant portion of true positives. A lower threshold can increase detection\nrecall but may also result in more false positives. Because of this, using a\npreset global threshold (e.g., 0.5) applied to all the bounding box candidates\nmay lead to suboptimal solutions. In this paper, we propose a Test-time\nSelf-guided Bounding-box Propagation (TSBP) method, leveraging Earth Mover's\nDistance (EMD) to enhance object detection in histology images. TSBP utilizes\nbounding boxes with high confidence to influence those with low confidence,\nleveraging visual similarities between them. This propagation mechanism enables\nbounding boxes to be selected in a controllable, explainable, and robust\nmanner, which surpasses the effectiveness of using simple thresholds and\nuncertainty calibration methods. Importantly, TSBP does not necessitate\nadditional labeled samples for model training or parameter estimation, unlike\ncalibration methods. We conduct experiments on gland detection and cell\ndetection tasks in histology images. The results show that our proposed TSBP\nsignificantly improves detection outcomes when working in conjunction with\nstate-of-the-art deep learning-based detection networks. Compared to other\nmethods such as uncertainty calibration, TSBP yields more robust and accurate\nobject detection predictions while using no additional labeled samples. The\ncode is available at https://github.com/jwhgdeu/TSBP.",
      "tldr_zh": "本研究针对对象检测任务中全局阈值（如0.5）导致的假阳性和真阳性遗漏问题，提出了一种Test-time Self-guided Bounding-box Propagation (TSBP)方法，利用Earth Mover's Distance (EMD)来增强组织学图像中的检测性能。TSBP通过让高置信度bounding-box影响低置信度bounding-box，并基于视觉相似性进行传播，实现可控、可解释和鲁棒的边界框选择，而无需额外标注样本进行训练。实验结果显示，与最先进深度学习检测网络结合后，TSBP在腺体和细胞检测任务上显著提升检测准确率，并优于不确定性校准方法，提供更可靠的预测。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.16678v1",
      "published_date": "2024-09-25 07:09:04 UTC",
      "updated_date": "2024-09-25 07:09:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:49:59.370889"
    },
    {
      "arxiv_id": "2409.16670v2",
      "title": "GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhe-Rui Yang",
        "Jindong Han",
        "Chang-Dong Wang",
        "Hao Liu"
      ],
      "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in\nhandling a range of graph analytical tasks across various domains, such as\ne-commerce and social networks. Despite their versatility, GNNs face\nsignificant challenges in transferability, limiting their utility in real-world\napplications. Existing research in GNN transfer learning overlooks\ndiscrepancies in distribution among various graph datasets, facing challenges\nwhen transferring across different distributions. How to effectively adopt a\nwell-trained GNN to new graphs with varying feature and structural\ndistributions remains an under-explored problem. Taking inspiration from the\nsuccess of Low-Rank Adaptation (LoRA) in adapting large language models to\nvarious domains, we propose GraphLoRA, an effective and parameter-efficient\nmethod for transferring well-trained GNNs to diverse graph domains.\nSpecifically, we first propose a Structure-aware Maximum Mean Discrepancy\n(SMMD) to align divergent node feature distributions across source and target\ngraphs. Moreover, we introduce low-rank adaptation by injecting a small\ntrainable GNN alongside the pre-trained one, effectively bridging structural\ndistribution gaps while mitigating the catastrophic forgetting. Additionally, a\nstructure-aware regularization objective is proposed to enhance the\nadaptability of the pre-trained GNN to target graph with scarce supervision\nlabels. Extensive experiments on eight real-world datasets demonstrate the\neffectiveness of GraphLoRA against fourteen baselines by tuning only 20% of\nparameters, even across disparate graph domains. The code is available at\nhttps://github.com/AllminerLab/GraphLoRA.",
      "tldr_zh": "本研究针对图神经网络（GNNs）在跨图转移学习中的挑战，提出了一种结构感知的对比低秩适应方法GraphLoRA，以有效处理不同图数据集的特征和结构分布差异。GraphLoRA 首先引入 Structure-aware Maximum Mean Discrepancy (SMMD) 来对齐源图和目标图的节点特征分布，并通过注入一个小型可训练 GNN 与预训练模型结合，桥接结构差距并缓解灾难性遗忘；同时，添加结构感知正则化目标以提升在标签稀少目标图上的适应性。在八个真实数据集上的实验中，GraphLoRA 仅微调 20% 参数，便显著优于十四种基线方法，即使在不同图域之间也表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD2025",
      "pdf_url": "http://arxiv.org/pdf/2409.16670v2",
      "published_date": "2024-09-25 06:57:42 UTC",
      "updated_date": "2025-01-07 15:00:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:50:10.191200"
    },
    {
      "arxiv_id": "2409.17190v1",
      "title": "Enhancing Guardrails for Safe and Secure Healthcare AI",
      "title_zh": "翻译失败",
      "authors": [
        "Ananya Gangavarapu"
      ],
      "abstract": "Generative AI holds immense promise in addressing global healthcare access\nchallenges, with numerous innovative applications now ready for use across\nvarious healthcare domains. However, a significant barrier to the widespread\nadoption of these domain-specific AI solutions is the lack of robust safety\nmechanisms to effectively manage issues such as hallucination, misinformation,\nand ensuring truthfulness. Left unchecked, these risks can compromise patient\nsafety and erode trust in healthcare AI systems. While general-purpose\nframeworks like Llama Guard are useful for filtering toxicity and harmful\ncontent, they do not fully address the stringent requirements for truthfulness\nand safety in healthcare contexts. This paper examines the unique safety and\nsecurity challenges inherent to healthcare AI, particularly the risk of\nhallucinations, the spread of misinformation, and the need for factual accuracy\nin clinical settings. I propose enhancements to existing guardrails frameworks,\nsuch as Nvidia NeMo Guardrails, to better suit healthcare-specific needs. By\nstrengthening these safeguards, I aim to ensure the secure, reliable, and\naccurate use of AI in healthcare, mitigating misinformation risks and improving\npatient safety.",
      "tldr_zh": "该论文讨论了生成式 AI 在医疗领域的应用潜力，但强调了幻觉(hallucination)、错误信息(misinformation)和真实性问题等安全风险，这些可能危害患者安全并削弱对 AI 的信任。现有框架如 Llama Guard 仅能过滤毒性和有害内容，无法充分满足医疗环境的严格要求。作者提出对 Nvidia NeMo Guardrails 等框架进行增强，针对医疗特定需求加强安全机制，以确保 AI 的准确性和可靠性，最终缓解错误信息风险并提升患者安全。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17190v1",
      "published_date": "2024-09-25 06:30:06 UTC",
      "updated_date": "2024-09-25 06:30:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:50:20.852074"
    },
    {
      "arxiv_id": "2409.16652v1",
      "title": "Progressive Representation Learning for Real-Time UAV Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Changhong Fu",
        "Xiang Lei",
        "Haobo Zuo",
        "Liangliang Yao",
        "Guangze Zheng",
        "Jia Pan"
      ],
      "abstract": "Visual object tracking has significantly promoted autonomous applications for\nunmanned aerial vehicles (UAVs). However, learning robust object\nrepresentations for UAV tracking is especially challenging in complex dynamic\nenvironments, when confronted with aspect ratio change and occlusion. These\nchallenges severely alter the original information of the object. To handle the\nabove issues, this work proposes a novel progressive representation learning\nframework for UAV tracking, i.e., PRL-Track. Specifically, PRL-Track is divided\ninto coarse representation learning and fine representation learning. For\ncoarse representation learning, two innovative regulators, which rely on\nappearance and semantic information, are designed to mitigate appearance\ninterference and capture semantic information. Furthermore, for fine\nrepresentation learning, a new hierarchical modeling generator is developed to\nintertwine coarse object representations. Exhaustive experiments demonstrate\nthat the proposed PRL-Track delivers exceptional performance on three\nauthoritative UAV tracking benchmarks. Real-world tests indicate that the\nproposed PRL-Track realizes superior tracking performance with 42.6 frames per\nsecond on the typical UAV platform equipped with an edge smart camera. The\ncode, model, and demo videos are available at\n\\url{https://github.com/vision4robotics/PRL-Track}.",
      "tldr_zh": "本文提出了一种渐进式表示学习框架 PRL-Track，用于实时无人机 (UAV) 跟踪，旨在应对复杂动态环境中对象长宽比变化和遮挡带来的挑战。框架分为粗略表示学习和精细表示学习：前者通过基于外观和语义信息的调节器 (regulators) 减轻外观干扰并捕获语义信息；后者利用层次建模生成器 (hierarchical modeling generator) 交织粗略表示以提升跟踪准确性。实验结果显示，PRL-Track 在三个权威 UAV 跟踪基准上表现出色，并在实际测试中实现 42.6 帧每秒的优越实时性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by the 2024 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2409.16652v1",
      "published_date": "2024-09-25 06:16:32 UTC",
      "updated_date": "2024-09-25 06:16:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:50:35.979115"
    },
    {
      "arxiv_id": "2409.16645v1",
      "title": "Task Addition in Multi-Task Learning by Geometrical Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Soorin Yim",
        "Dae-Woong Jeong",
        "Sung Moon Ko",
        "Sumin Lee",
        "Hyunseung Kim",
        "Chanhui Lee",
        "Sehui Han"
      ],
      "abstract": "Training deep learning models on limited data while maintaining\ngeneralization is one of the fundamental challenges in molecular property\nprediction. One effective solution is transferring knowledge extracted from\nabundant datasets to those with scarce data. Recently, a novel algorithm called\nGeometrically Aligned Transfer Encoder (GATE) has been introduced, which uses\nsoft parameter sharing by aligning the geometrical shapes of task-specific\nlatent spaces. However, GATE faces limitations in scaling to multiple tasks due\nto computational costs. In this study, we propose a task addition approach for\nGATE to improve performance on target tasks with limited data while minimizing\ncomputational complexity. It is achieved through supervised multi-task\npre-training on a large dataset, followed by the addition and training of\ntask-specific modules for each target task. Our experiments demonstrate the\nsuperior performance of the task addition strategy for GATE over conventional\nmulti-task methods, with comparable computational costs.",
      "tldr_zh": "本研究针对分子属性预测中数据有限的深度学习训练挑战，提出了一种基于 Geometrically Aligned Transfer Encoder (GATE) 的任务添加方法。该方法通过在大型数据集上进行监督 multi-task learning 预训练，随后为每个目标任务添加和训练任务特定模块，实现软参数共享并对齐任务特定潜在空间的几何形状，从而最小化计算复杂性。实验结果显示，该策略在目标任务性能上优于传统 multi-task 方法，同时保持可比的计算成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 5 figures, Accepted at AI for Science Workshop at 41st\n  International Conference on Machine Learning",
      "pdf_url": "http://arxiv.org/pdf/2409.16645v1",
      "published_date": "2024-09-25 05:56:00 UTC",
      "updated_date": "2024-09-25 05:56:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:50:55.974723"
    },
    {
      "arxiv_id": "2409.16636v1",
      "title": "Training Language Models to Win Debates with Self-Play Improves Judge Accuracy",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Arnesen",
        "David Rein",
        "Julian Michael"
      ],
      "abstract": "We test the robustness of debate as a method of scalable oversight by\ntraining models to debate with data generated via self-play. In a long-context\nreading comprehension task, we find that language model based evaluators answer\nquestions more accurately when judging models optimized to win debates. By\ncontrast, we find no such relationship for consultancy models trained to\npersuade a judge without an opposing debater present. In quantitative and\nqualitative comparisons between our debate models and novel consultancy\nbaselines, we find evidence that debate training encourages stronger and more\ninformative arguments, showing promise that it can help provide high-quality\nsupervision for tasks that are difficult to directly evaluate.",
      "tldr_zh": "本研究通过自博弈(self-play)训练语言模型，使其优化用于赢得辩论，从而测试辩论作为可扩展监督方法的鲁棒性。在一个长上下文阅读理解任务中，实验发现，语言模型评估器在判断辩论模型时回答问题更准确，而训练用于说服法官的咨询模型(consultancy models)则没有类似效果。定量和定性比较显示，辩论训练鼓励模型生成更强有力且信息丰富的论点，这为难以直接评估的任务提供高质量监督。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.0; I.2.6"
      ],
      "primary_category": "cs.CL",
      "comment": "48 pages, 12 figures; code at\n  https://github.com/samuelarnesen/nyu-debate-modeling",
      "pdf_url": "http://arxiv.org/pdf/2409.16636v1",
      "published_date": "2024-09-25 05:28:33 UTC",
      "updated_date": "2024-09-25 05:28:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:50:56.977208"
    },
    {
      "arxiv_id": "2409.16635v1",
      "title": "Judgment of Thoughts: Courtroom of the Binary Logical Reasoning in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sungjune Park",
        "Daeseon Choi"
      ],
      "abstract": "This paper proposes a novel prompt engineering technique called Judgment of\nThought (JoT) that is specifically tailored for binary logical reasoning tasks.\nJoT employs three roles$\\unicode{x2014}$lawyer, prosecutor, and\njudge$\\unicode{x2014}$to facilitate more reliable and accurate reasoning by the\nmodel. In this framework, the judge utilizes a high$\\unicode{x2010}$level\nmodel, while the lawyer and prosecutor utilize low$\\unicode{x2010}$level\nmodels. This structure helps the judge better understand the responses from\nboth the lawyer and prosecutor, enabling a more accurate judgment. Experimental\nresults on large language model (LLM) benchmark datasets, such as BigBenchHard\nand Winogrande, demonstrate that JoT outperforms existing methods, including\nChain of Thought (CoT) and Self$\\unicode{x2010}$Consistency (SC), in binary\nlogical reasoning tasks. Additionally, in real$\\unicode{x2010}$world tasks,\nsuch as Fake News Detection and SMS Spam Detection, JoT shows comparable or\nimproved performance compared to existing techniques. JoT significantly\nenhances the accuracy and reliability of models in binary reasoning tasks and\nshow potential for practical applicability across various domains. Future\nresearch should aim to further broaden the applicability of JoT and optimize\nits implementation for real$\\unicode{x2010}$world\nproblem$\\unicode{x2010}$solving.",
      "tldr_zh": "这篇论文提出了 Judgment of Thought (JoT)，一种针对二元逻辑推理任务的创新提示工程技术，通过模拟法庭角色（律师、检察官和法官）来提升大型语言模型的推理准确性，其中法官使用高水平模型，而律师和检察官使用低水平模型。JoT 的框架帮助模型更好地理解和整合多方回应，从而做出更可靠的判断。实验结果显示，JoT 在 BigBenchHard 和 Winogrande 等基准数据集上超过了 Chain of Thought (CoT) 和 Self-Consistency (SC) 等现有方法，并在真实世界任务如 Fake News Detection 和 SMS Spam Detection 中表现出可比或优越的性能。该技术显著提高了模型在二元推理任务中的准确性和可靠性，并为实际应用领域提供了潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16635v1",
      "published_date": "2024-09-25 05:28:05 UTC",
      "updated_date": "2024-09-25 05:28:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:51:10.513937"
    },
    {
      "arxiv_id": "2409.16630v1",
      "title": "Stochastic Subsampling With Average Pooling",
      "title_zh": "随机子采样与平均池化",
      "authors": [
        "Bum Jun Kim",
        "Sang Woo Kim"
      ],
      "abstract": "Regularization of deep neural networks has been an important issue to achieve\nhigher generalization performance without overfitting problems. Although the\npopular method of Dropout provides a regularization effect, it causes\ninconsistent properties in the output, which may degrade the performance of\ndeep neural networks. In this study, we propose a new module called stochastic\naverage pooling, which incorporates Dropout-like stochasticity in pooling. We\ndescribe the properties of stochastic subsampling and average pooling and\nleverage them to design a module without any inconsistency problem. The\nstochastic average pooling achieves a regularization effect without any\npotential performance degradation due to the inconsistency issue and can easily\nbe plugged into existing architectures of deep neural networks. Experiments\ndemonstrate that replacing existing average pooling with stochastic average\npooling yields consistent improvements across a variety of tasks, datasets, and\nmodels.",
      "tldr_zh": "本研究针对深度神经网络的正则化问题，指出传统Dropout方法虽能防止过拟合，但会导致输出不一致从而影响性能。作者提出了一种新的模块——stochastic average pooling，将Dropout-like的随机性融入平均池化（average pooling）中，确保模块在保持正则化效果的同时避免不一致问题。该模块可轻松整合到现有神经网络架构中，实验结果显示，在多种任务、数据集和模型上，使用stochastic average pooling替换原有average pooling后，性能得到一致提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.16630v1",
      "published_date": "2024-09-25 05:18:17 UTC",
      "updated_date": "2024-09-25 05:18:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:51:20.761967"
    },
    {
      "arxiv_id": "2409.16626v2",
      "title": "Ascend HiFloat8 Format for Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanyong Luo",
        "Zhongxing Zhang",
        "Richard Wu",
        "Hu Liu",
        "Ying Jin",
        "Kai Zheng",
        "Minmin Wang",
        "Zhanying He",
        "Guipeng Hu",
        "Luyao Chen",
        "Tianchi Hu",
        "Junsong Wang",
        "Minqi Chen",
        "Mikhaylov Dmitry",
        "Korviakov Vladimir",
        "Bobrin Maxim",
        "Yuhao Hu",
        "Guanfu Chen",
        "Zeyi Huang"
      ],
      "abstract": "This preliminary white paper proposes a novel 8-bit floating-point data\nformat HiFloat8 (abbreviated as HiF8) for deep learning. HiF8 features tapered\nprecision. For normal value encoding, it provides 7 exponent values with 3-bit\nmantissa, 8 exponent values with 2-bit mantissa, and 16 exponent values with\n1-bit mantissa. For denormal value encoding, it extends the dynamic range by 7\nextra powers of 2, from 31 to 38 binades (notice that FP16 covers 40 binades).\nMeanwhile, HiF8 encodes all the special values except that positive zero and\nnegative zero are represented by only one bit-pattern. Thanks to the better\nbalance between precision and dynamic range, HiF8 can be simultaneously used in\nboth forward and backward passes of AI training. In this paper, we will\ndescribe the definition and rounding methods of HiF8, as well as the tentative\ntraining and inference solutions. To demonstrate the efficacy of HiF8, massive\nsimulation results on various neural networks, including traditional neural\nnetworks and large language models (LLMs), will also be presented.",
      "tldr_zh": "本论文提出了一种新型8位浮点数据格式HiFloat8（简称HiF8），旨在优化深度学习的计算效率。HiF8采用tapered precision设计，对于正常值编码，提供7个指数值配3位尾数、8个指数值配2位尾数以及16个指数值配1位尾数；对于非正常值编码，则扩展动态范围至38 binades（相比FP16的40 binades，多出7个额外2的幂）。通过平衡精度和动态范围，HiF8可同时应用于AI训练的前向和后向传递，并支持特殊值的编码。实验模拟结果显示，HiF8在各种神经网络（包括传统神经网络和大型语言模型LLMs）上表现出色，证明了其在训练和推理中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "13 Pages, 4 Figures, 9 Tables",
      "pdf_url": "http://arxiv.org/pdf/2409.16626v2",
      "published_date": "2024-09-25 05:11:58 UTC",
      "updated_date": "2024-09-26 16:41:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:51:33.013532"
    },
    {
      "arxiv_id": "2409.16623v1",
      "title": "On Your Mark, Get Set, Predict! Modeling Continuous-Time Dynamics of Cascades for Information Popularity Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Jing",
        "Yichen Jing",
        "Yuhuan Lu",
        "Bangchao Deng",
        "Sikun Yang",
        "Dingqi Yang"
      ],
      "abstract": "Information popularity prediction is important yet challenging in various\ndomains, including viral marketing and news recommendations. The key to\naccurately predicting information popularity lies in subtly modeling the\nunderlying temporal information diffusion process behind observed events of an\ninformation cascade, such as the retweets of a tweet. To this end, most\nexisting methods either adopt recurrent networks to capture the temporal\ndynamics from the first to the last observed event or develop a statistical\nmodel based on self-exciting point processes to make predictions. However,\ninformation diffusion is intrinsically a complex continuous-time process with\nirregularly observed discrete events, which is oversimplified using recurrent\nnetworks as they fail to capture the irregular time intervals between events,\nor using self-exciting point processes as they lack flexibility to capture the\ncomplex diffusion process. Against this background, we propose ConCat, modeling\nthe Continuous-time dynamics of Cascades for information popularity prediction.\nOn the one hand, it leverages neural Ordinary Differential Equations (ODEs) to\nmodel irregular events of a cascade in continuous time based on the cascade\ngraph and sequential event information. On the other hand, it considers cascade\nevents as neural temporal point processes (TPPs) parameterized by a conditional\nintensity function which can also benefit the popularity prediction task. We\nconduct extensive experiments to evaluate ConCat on three real-world datasets.\nResults show that ConCat achieves superior performance compared to\nstate-of-the-art baselines, yielding a 2.3%-33.2% improvement over the\nbest-performing baselines across the three datasets.",
      "tldr_zh": "本论文针对信息流行度预测的挑战，提出 ConCat 模型，用于建模级联的连续时间动态，以更准确地捕捉信息扩散过程的不规则事件。ConCat 结合 neural Ordinary Differential Equations (ODEs) 来基于级联图和顺序事件信息处理连续时间动态，并将事件视为 neural temporal point processes (TPPs) 参数化的过程，以提升预测灵活性。实验在三个真实数据集上显示，ConCat 相较于最先进基线方法，性能提升了 2.3% 到 33.2%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16623v1",
      "published_date": "2024-09-25 05:08:44 UTC",
      "updated_date": "2024-09-25 05:08:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:51:47.339951"
    },
    {
      "arxiv_id": "2409.16621v1",
      "title": "Entailment-Driven Privacy Policy Classification with LLMs",
      "title_zh": "基于蕴含驱动的LL",
      "authors": [
        "Bhanuka Silva",
        "Dishanika Denipitiyage",
        "Suranga Seneviratne",
        "Anirban Mahanti",
        "Aruna Seneviratne"
      ],
      "abstract": "While many online services provide privacy policies for end users to read and\nunderstand what personal data are being collected, these documents are often\nlengthy and complicated. As a result, the vast majority of users do not read\nthem at all, leading to data collection under uninformed consent. Several\nattempts have been made to make privacy policies more user friendly by\nsummarising them, providing automatic annotations or labels for key sections,\nor by offering chat interfaces to ask specific questions. With recent advances\nin Large Language Models (LLMs), there is an opportunity to develop more\neffective tools to parse privacy policies and help users make informed\ndecisions. In this paper, we propose an entailment-driven LLM based framework\nto classify paragraphs of privacy policies into meaningful labels that are\neasily understood by users. The results demonstrate that our framework\noutperforms traditional LLM methods, improving the F1 score in average by\n11.2%. Additionally, our framework provides inherently explainable and\nmeaningful predictions.",
      "tldr_zh": "本研究针对在线服务隐私政策冗长复杂导致用户不阅读的问题，提出了一种基于LLMs的entailment-driven框架，用于将隐私政策段落分类成用户易懂的标签，以提升数据收集的知情同意。框架通过蕴含驱动机制解析政策内容，提供自动注解和分类，相比传统LLM方法平均提高了11.2%的F1 score。实验结果表明，该框架不仅提升了分类准确性，还具备固有的可解释性和有意义的预测，帮助用户更好地理解隐私政策并做出知情决定。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.16621v1",
      "published_date": "2024-09-25 05:07:05 UTC",
      "updated_date": "2024-09-25 05:07:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:51:56.855125"
    },
    {
      "arxiv_id": "2409.16620v1",
      "title": "Optimized Monte Carlo Tree Search for Enhanced Decision Making in the FrozenLake Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Esteban Aldana Guerra"
      ],
      "abstract": "Monte Carlo Tree Search (MCTS) is a powerful algorithm for solving complex\ndecision-making problems. This paper presents an optimized MCTS implementation\napplied to the FrozenLake environment, a classic reinforcement learning task\ncharacterized by stochastic transitions. The optimization leverages cumulative\nreward and visit count tables along with the Upper Confidence Bound for Trees\n(UCT) formula, resulting in efficient learning in a slippery grid world. We\nbenchmark our implementation against other decision-making algorithms,\nincluding MCTS with Policy and Q-Learning, and perform a detailed comparison of\ntheir performance. The results demonstrate that our optimized approach\neffectively maximizes rewards and success rates while minimizing convergence\ntime, outperforming baseline methods, especially in environments with inherent\nrandomness.",
      "tldr_zh": "本论文优化了 Monte Carlo Tree Search (MCTS) 算法，以提升在 FrozenLake 环境的决策能力，该环境是一个经典的强化学习任务，涉及随机过渡。优化方法利用累积奖励表、访问计数表和 Upper Confidence Bound for Trees (UCT) 公式，实现高效学习和决策。实验结果显示，该优化版本在与 MCTS with Policy 和 Q-Learning 等基线算法的比较中，显著提高了奖励最大化、成功率，并减少了收敛时间，尤其在随机环境中表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16620v1",
      "published_date": "2024-09-25 05:04:53 UTC",
      "updated_date": "2024-09-25 05:04:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:52:07.907871"
    },
    {
      "arxiv_id": "2409.16619v1",
      "title": "CasFT: Future Trend Modeling for Information Popularity Prediction with Dynamic Cues-Driven Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Jing",
        "Yichen Jing",
        "Yuhuan Lu",
        "Bangchao Deng",
        "Xueqin Chen",
        "Dingqi Yang"
      ],
      "abstract": "The rapid spread of diverse information on online social platforms has\nprompted both academia and industry to realize the importance of predicting\ncontent popularity, which could benefit a wide range of applications, such as\nrecommendation systems and strategic decision-making. Recent works mainly\nfocused on extracting spatiotemporal patterns inherent in the information\ndiffusion process within a given observation period so as to predict its\npopularity over a future period of time. However, these works often overlook\nthe future popularity trend, as future popularity could either increase\nexponentially or stagnate, introducing uncertainties to the prediction\nperformance. Additionally, how to transfer the preceding-term dynamics learned\nfrom the observed diffusion process into future-term trends remains an\nunexplored challenge. Against this background, we propose CasFT, which\nleverages observed information Cascades and dynamic cues extracted via neural\nODEs as conditions to guide the generation of Future popularity-increasing\nTrends through a diffusion model. These generated trends are then combined with\nthe spatiotemporal patterns in the observed information cascade to make the\nfinal popularity prediction. Extensive experiments conducted on three\nreal-world datasets demonstrate that CasFT significantly improves the\nprediction accuracy, compared to state-of-the-art approaches, yielding\n2.2%-19.3% improvement across different datasets.",
      "tldr_zh": "该论文提出CasFT模型，用于预测在线社交平台信息流行的未来趋势，解决现有方法忽略趋势不确定性（如指数增长或停滞）的局限。CasFT通过神经ODEs提取动态线索，并利用扩散模型生成未来流行趋势，将这些趋势与观察到的信息级联时空模式相结合进行预测。实验在三个真实数据集上显示，CasFT比最先进方法提高了2.2%至19.3%的准确率，为推荐系统和决策制定提供更可靠的支持。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16619v1",
      "published_date": "2024-09-25 05:03:16 UTC",
      "updated_date": "2024-09-25 05:03:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:52:20.778734"
    },
    {
      "arxiv_id": "2409.16618v1",
      "title": "Claim-Guided Textual Backdoor Attack for Practical Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Minkyoo Song",
        "Hanna Kim",
        "Jaehan Kim",
        "Youngjin Jin",
        "Seungwon Shin"
      ],
      "abstract": "Recent advances in natural language processing and the increased use of large\nlanguage models have exposed new security vulnerabilities, such as backdoor\nattacks. Previous backdoor attacks require input manipulation after model\ndistribution to activate the backdoor, posing limitations in real-world\napplicability. Addressing this gap, we introduce a novel Claim-Guided Backdoor\nAttack (CGBA), which eliminates the need for such manipulations by utilizing\ninherent textual claims as triggers. CGBA leverages claim extraction,\nclustering, and targeted training to trick models to misbehave on targeted\nclaims without affecting their performance on clean data. CGBA demonstrates its\neffectiveness and stealthiness across various datasets and models,\nsignificantly enhancing the feasibility of practical backdoor attacks. Our code\nand data will be available at https://github.com/PaperCGBA/CGBA.",
      "tldr_zh": "这篇论文提出了Claim-Guided Backdoor Attack (CGBA)，一种新型文本后门攻击方法，旨在解决传统攻击需要在模型分发后操纵输入的局限性。CGBA 通过claim extraction（声明提取）、clustering（聚类）和targeted training（针对性训练）利用文本中的inherent textual claims作为触发器，使模型在特定声明上出错，同时保持干净数据的正常性能。该方法在多种数据集和模型上证明了其有效性和隐蔽性，大大提升了后门攻击在实际应用中的可行性，并提供了开源代码支持。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2409.16618v1",
      "published_date": "2024-09-25 04:53:27 UTC",
      "updated_date": "2024-09-25 04:53:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:52:33.895888"
    },
    {
      "arxiv_id": "2409.16612v1",
      "title": "ECG-Image-Database: A Dataset of ECG Images with Real-World Imaging and Scanning Artifacts; A Foundation for Computerized ECG Image Digitization and Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew A. Reyna",
        "Deepanshi",
        "James Weigle",
        "Zuzana Koscova",
        "Kiersten Campbell",
        "Kshama Kodthalu Shivashankara",
        "Soheil Saghafi",
        "Sepideh Nikookar",
        "Mohsen Motie-Shirazi",
        "Yashar Kiarashi",
        "Salman Seyedi",
        "Gari D. Clifford",
        "Reza Sameni"
      ],
      "abstract": "We introduce the ECG-Image-Database, a large and diverse collection of\nelectrocardiogram (ECG) images generated from ECG time-series data, with\nreal-world scanning, imaging, and physical artifacts. We used ECG-Image-Kit, an\nopen-source Python toolkit, to generate realistic images of 12-lead ECG\nprintouts from raw ECG time-series. The images include realistic distortions\nsuch as noise, wrinkles, stains, and perspective shifts, generated both\ndigitally and physically. The toolkit was applied to 977 12-lead ECG records\nfrom the PTB-XL database and 1,000 from Emory Healthcare to create\nhigh-fidelity synthetic ECG images. These unique images were subjected to both\nprogrammatic distortions using ECG-Image-Kit and physical effects like soaking,\nstaining, and mold growth, followed by scanning and photography under various\nlighting conditions to create real-world artifacts.\n  The resulting dataset includes 35,595 software-labeled ECG images with a wide\nrange of imaging artifacts and distortions. The dataset provides ground truth\ntime-series data alongside the images, offering a reference for developing\nmachine and deep learning models for ECG digitization and classification. The\nimages vary in quality, from clear scans of clean papers to noisy photographs\nof degraded papers, enabling the development of more generalizable digitization\nalgorithms.\n  ECG-Image-Database addresses a critical need for digitizing paper-based and\nnon-digital ECGs for computerized analysis, providing a foundation for\ndeveloping robust machine and deep learning models capable of converting ECG\nimages into time-series. The dataset aims to serve as a reference for ECG\ndigitization and computerized annotation efforts. ECG-Image-Database was used\nin the PhysioNet Challenge 2024 on ECG image digitization and classification.",
      "tldr_zh": "该研究引入了 ECG-Image-Database，这是一个包含 35,595 张心电图 (ECG) 图像的大型数据集，这些图像基于 PTB-XL 和 Emory Healthcare 的原始 ECG 时间序列生成，并模拟了真实世界的扫描、成像和物理伪影，如噪声、皱纹、污渍及视角偏移。研究者使用开源 Python 工具包 ECG-Image-Kit 来创建这些高保真合成图像，并通过程序化和物理处理（如浸泡、染色和扫描）增强图像的真实性。数据集提供地面真实时间序列数据作为参考，支持开发机器学习和深度学习模型，用于 ECG 图像数字化、分类和计算机化分析，最终应用于 PhysioNet Challenge 2024 等实际场景。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "eess.IV",
        "eess.SP"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16612v1",
      "published_date": "2024-09-25 04:30:19 UTC",
      "updated_date": "2024-09-25 04:30:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:52:46.067841"
    },
    {
      "arxiv_id": "2409.16605v1",
      "title": "Evaluating and Enhancing Large Language Models for Novelty Assessment in Scholarly Publications",
      "title_zh": "翻译失败",
      "authors": [
        "Ethan Lin",
        "Zhiyuan Peng",
        "Yi Fang"
      ],
      "abstract": "Recent studies have evaluated the creativity/novelty of large language models\n(LLMs) primarily from a semantic perspective, using benchmarks from cognitive\nscience. However, accessing the novelty in scholarly publications is a largely\nunexplored area in evaluating LLMs. In this paper, we introduce a scholarly\nnovelty benchmark (SchNovel) to evaluate LLMs' ability to assess novelty in\nscholarly papers. SchNovel consists of 15000 pairs of papers across six fields\nsampled from the arXiv dataset with publication dates spanning 2 to 10 years\napart. In each pair, the more recently published paper is assumed to be more\nnovel. Additionally, we propose RAG-Novelty, which simulates the review process\ntaken by human reviewers by leveraging the retrieval of similar papers to\nassess novelty. Extensive experiments provide insights into the capabilities of\ndifferent LLMs to assess novelty and demonstrate that RAG-Novelty outperforms\nrecent baseline models.",
      "tldr_zh": "本研究评估并提升大型语言模型（LLMs）在学术论文新颖性评估方面的能力，针对现有研究的语义视角提出新基准SchNovel。SchNovel包含从arXiv数据集采样出的15000对论文，覆盖六个领域，论文对的出版日期相差2-10年，其中较新论文被视为更具新颖性。作者提出RAG-Novelty方法，通过检索类似论文模拟人类审稿过程来评估新颖性；实验结果显示，RAG-Novelty优于基线模型，并揭示了不同LLMs在该任务上的能力差异。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2409.16605v1",
      "published_date": "2024-09-25 04:12:38 UTC",
      "updated_date": "2024-09-25 04:12:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:52:56.423080"
    },
    {
      "arxiv_id": "2409.16593v1",
      "title": "A Hybrid Quantum Neural Network for Split Learning",
      "title_zh": "一种用于分割学习的混合量子神经网络",
      "authors": [
        "Hevish Cowlessur",
        "Chandra Thapa",
        "Tansu Alpcan",
        "Seyit Camtepe"
      ],
      "abstract": "Quantum Machine Learning (QML) is an emerging field of research with\npotential applications to distributed collaborative learning, such as Split\nLearning (SL). SL allows resource-constrained clients to collaboratively train\nML models with a server, reduce their computational overhead, and enable data\nprivacy by avoiding raw data sharing. Although QML with SL has been studied,\nthe problem remains open in resource-constrained environments where clients\nlack quantum computing capabilities. Additionally, data privacy leakage between\nclient and server in SL poses risks of reconstruction attacks on the server\nside. To address these issues, we propose Hybrid Quantum Split Learning (HQSL),\nan application of Hybrid QML in SL. HQSL enables classical clients to train\nmodels with a hybrid quantum server and curtails reconstruction attacks. In\naddition, we introduce a novel qubit-efficient data-loading technique for\ndesigning a quantum layer in HQSL, minimizing both the number of qubits and\ncircuit depth. Experiments on five datasets demonstrate HQSL's feasibility and\nability to enhance classification performance compared to its classical models.\nNotably, HQSL achieves mean improvements of over 3% in both accuracy and\nF1-score for the Fashion-MNIST dataset, and over 1.5% in both metrics for the\nSpeech Commands dataset. We expand these studies to include up to 100 clients,\nconfirming HQSL's scalability. Moreover, we introduce a noise-based defense\nmechanism to tackle reconstruction attacks on the server side. Overall, HQSL\nenables classical clients to collaboratively train their models with a hybrid\nquantum server, leveraging quantum advantages while improving model performance\nand security against data privacy leakage-related reconstruction attacks.",
      "tldr_zh": "本论文提出 Hybrid Quantum Split Learning (HQSL)，一种将混合量子机器学习应用于 Split Learning (SL) 的框架，旨在解决资源受限客户端缺乏量子计算能力和数据隐私泄露（如服务器端的重建攻击）的问题。HQSL 允许经典客户端与混合量子服务器协作训练模型，并引入一种量子比特高效的数据加载技术，以最小化量子比特数量和电路深度，同时增强模型安全性。实验在五个数据集上验证了 HQSL 的可行性，其分类性能优于经典模型，例如 Fashion-MNIST 数据集的准确率和 F1 分数均提升超过 3%，Speech Commands 数据集提升超过 1.5%；此外，该框架支持多达 100 个客户端的扩展，并通过噪声-based 防御机制有效缓解重建攻击。总体上，HQSL 利用量子优势提高了分布式协作学习的性能和隐私保护。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "47 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.16593v1",
      "published_date": "2024-09-25 03:38:05 UTC",
      "updated_date": "2024-09-25 03:38:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:53:10.837686"
    },
    {
      "arxiv_id": "2409.16592v1",
      "title": "MambaJSCC: Adaptive Deep Joint Source-Channel Coding with Generalized State Space Model",
      "title_zh": "翻译失败",
      "authors": [
        "Tong Wu",
        "Zhiyong Chen",
        "Meixia Tao",
        "Yaping Sun",
        "Xiaodong Xu",
        "Wenjun Zhang",
        "Ping Zhang"
      ],
      "abstract": "Lightweight and efficient neural network models for deep joint source-channel\ncoding (JSCC) are crucial for semantic communications. In this paper, we\npropose a novel JSCC architecture, named MambaJSCC, that achieves\nstate-of-the-art performance with low computational and parameter overhead.\nMambaJSCC utilizes the visual state space model with channel adaptation\n(VSSM-CA) blocks as its backbone for transmitting images over wireless\nchannels, where the VSSM-CA primarily consists of the generalized state space\nmodels (GSSM) and the zero-parameter, zero-computational channel adaptation\nmethod (CSI-ReST). We design the GSSM module, leveraging reversible matrix\ntransformations to express generalized scan expanding operations, and\ntheoretically prove that two GSSM modules can effectively capture global\ninformation. We discover that GSSM inherently possesses the ability to adapt to\nchannels, a form of endogenous intelligence. Based on this, we design the\nCSI-ReST method, which injects channel state information (CSI) into the initial\nstate of GSSM to utilize its native response, and into the residual state to\nmitigate CSI forgetting, enabling effective channel adaptation without\nintroducing additional computational and parameter overhead. Experimental\nresults show that MambaJSCC not only outperforms existing JSCC methods (e.g.,\nSwinJSCC) across various scenarios but also significantly reduces parameter\nsize, computational overhead, and inference delay.",
      "tldr_zh": "本文提出了一种高效的深度联合源-通道编码（JSCC）架构MambaJSCC，利用视觉状态空间模型与通道适应（VSSM-CA）作为骨干，用于图像在无线通道上的传输。MambaJSCC的核心包括广义状态空间模型（GSSM），通过可逆矩阵变换捕获全局信息，以及零参数零计算的CSI-ReST方法，将通道状态信息（CSI）注入GSSM的初始和残差状态，实现内生通道适应。实验结果显示，MambaJSCC在多种场景下优于现有方法（如SwinJSCC），并显著减少了参数规模、计算开销和推理延迟。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "submitted to IEEE Journal",
      "pdf_url": "http://arxiv.org/pdf/2409.16592v1",
      "published_date": "2024-09-25 03:37:51 UTC",
      "updated_date": "2024-09-25 03:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:53:21.774199"
    },
    {
      "arxiv_id": "2409.16586v2",
      "title": "AutoSTF: Decoupled Neural Architecture Search for Cost-Effective Automated Spatio-Temporal Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Tengfei Lyu",
        "Weijia Zhang",
        "Jinliang Deng",
        "Hao Liu"
      ],
      "abstract": "Spatio-temporal forecasting is a critical component of various smart city\napplications, such as transportation optimization, energy management, and\nsocio-economic analysis. Recently, several automated spatio-temporal\nforecasting methods have been proposed to automatically search the optimal\nneural network architecture for capturing complex spatio-temporal dependencies.\nHowever, the existing automated approaches suffer from expensive neural\narchitecture search overhead, which hinders their practical use and the further\nexploration of diverse spatio-temporal operators in a finer granularity. In\nthis paper, we propose AutoSTF, a decoupled automatic neural architecture\nsearch framework for cost-effective automated spatio-temporal forecasting. From\nthe efficiency perspective, we first decouple the mixed search space into\ntemporal space and spatial space and respectively devise representation\ncompression and parameter-sharing schemes to mitigate the parameter explosion.\nThe decoupled spatio-temporal search not only expedites the model optimization\nprocess but also leaves new room for more effective spatio-temporal dependency\nmodeling. From the effectiveness perspective, we propose a multi-patch transfer\nmodule to jointly capture multi-granularity temporal dependencies and extend\nthe spatial search space to enable finer-grained layer-wise spatial dependency\nsearch. Extensive experiments on eight datasets demonstrate the superiority of\nAutoSTF in terms of both accuracy and efficiency. Specifically, our proposed\nmethod achieves up to 13.48x speed-up compared to state-of-the-art automatic\nspatio-temporal forecasting methods while maintaining the best forecasting\naccuracy.",
      "tldr_zh": "这篇论文提出了 AutoSTF，一种解耦的神经架构搜索框架，用于实现成本有效的自动时空预测（Automated Spatio-Temporal Forecasting），以解决现有方法的高搜索开销问题。AutoSTF 通过将混合搜索空间分为时间空间和空间空间，并采用表示压缩、参数共享以及多补丁传输模块，来提升搜索效率并捕获多粒度的时间依赖性和更细粒度的层级空间依赖性。实验在八个数据集上证明，该方法比最先进方法快 13.48 倍，同时保持最佳的预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD 2025 Research Track",
      "pdf_url": "http://arxiv.org/pdf/2409.16586v2",
      "published_date": "2024-09-25 03:25:34 UTC",
      "updated_date": "2025-01-08 13:16:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:53:33.484877"
    },
    {
      "arxiv_id": "2409.16577v1",
      "title": "Reactive Multi-Robot Navigation in Outdoor Environments Through Uncertainty-Aware Active Learning of Human Preference Landscape",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Huang",
        "Wenshuo Zang",
        "Carlo Pinciroli",
        "Zhi Jane Li",
        "Taposh Banerjee",
        "Lili Su",
        "Rui Liu"
      ],
      "abstract": "Compared with single robots, Multi-Robot Systems (MRS) can perform missions\nmore efficiently due to the presence of multiple members with diverse\ncapabilities. However, deploying an MRS in wide real-world environments is\nstill challenging due to uncertain and various obstacles (e.g., building\nclusters and trees). With a limited understanding of environmental uncertainty\non performance, an MRS cannot flexibly adjust its behaviors (e.g., teaming,\nload sharing, trajectory planning) to ensure both environment adaptation and\ntask accomplishments. In this work, a novel joint preference landscape learning\nand behavior adjusting framework (PLBA) is designed. PLBA efficiently\nintegrates real-time human guidance to MRS coordination and utilizes Sparse\nVariational Gaussian Processes with Varying Output Noise to quickly assess\nhuman preferences by leveraging spatial correlations between environment\ncharacteristics. An optimization-based behavior-adjusting method then safely\nadapts MRS behaviors to environments. To validate PLBA's effectiveness in MRS\nbehavior adaption, a flood disaster search and rescue task was designed. 20\nhuman users provided 1764 feedback based on human preferences obtained from MRS\nbehaviors related to \"task quality\", \"task progress\", \"robot safety\". The\nprediction accuracy and adaptation speed results show the effectiveness of PLBA\nin preference learning and MRS behavior adaption.",
      "tldr_zh": "本文提出 PLBA 框架，用于 Multi-Robot Systems (MRS) 在户外环境的反应式导航，通过不确定性感知的主动学习人类偏好景观来应对环境不确定性（如建筑物和树木）。该框架整合实时人类指导，利用 Sparse Variational Gaussian Processes with Varying Output Noise 评估人类偏好，并通过优化-based 方法安全调整 MRS 行为，包括团队协作、负载共享和轨迹规划。实验在洪水灾害搜索和救援任务中验证了 PLBA 的有效性，基于 20 名用户提供的 1764 条反馈，展示了较高的预测准确性和适应速度，提高了任务质量、任务进度和机器人安全。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16577v1",
      "published_date": "2024-09-25 03:15:09 UTC",
      "updated_date": "2024-09-25 03:15:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:53:46.052865"
    },
    {
      "arxiv_id": "2409.16563v1",
      "title": "Enhancing disease detection in radiology reports through fine-tuning lightweight LLM on weak labels",
      "title_zh": "翻译失败",
      "authors": [
        "Yishu Wei",
        "Xindi Wang",
        "Hanley Ong",
        "Yiliang Zhou",
        "Adam Flanders",
        "George Shih",
        "Yifan Peng"
      ],
      "abstract": "Despite significant progress in applying large language models (LLMs) to the\nmedical domain, several limitations still prevent them from practical\napplications. Among these are the constraints on model size and the lack of\ncohort-specific labeled datasets. In this work, we investigated the potential\nof improving a lightweight LLM, such as Llama 3.1-8B, through fine-tuning with\ndatasets using synthetic labels. Two tasks are jointly trained by combining\ntheir respective instruction datasets. When the quality of the task-specific\nsynthetic labels is relatively high (e.g., generated by GPT4- o), Llama 3.1-8B\nachieves satisfactory performance on the open-ended disease detection task,\nwith a micro F1 score of 0.91. Conversely, when the quality of the\ntask-relevant synthetic labels is relatively low (e.g., from the MIMIC-CXR\ndataset), fine-tuned Llama 3.1-8B is able to surpass its noisy teacher labels\n(micro F1 score of 0.67 v.s. 0.63) when calibrated against curated labels,\nindicating the strong inherent underlying capability of the model. These\nfindings demonstrate the potential of fine-tuning LLMs with synthetic labels,\noffering a promising direction for future research on LLM specialization in the\nmedical domain.",
      "tldr_zh": "本研究探讨了通过微调轻量级LLM（如Llama 3.1-8B）来提升放射学报告中疾病检测的性能，特别使用合成labels（synthetic labels）来应对模型大小限制和标签数据集短缺的问题。研究者联合训练了两个任务的指令数据集，并在合成labels质量较高时（如由GPT-4-o生成），实现了开放式疾病检测任务的出色表现，micro F1 score达0.91。即便合成labels质量较低（如来自MIMIC-CXR数据集），微调后的Llama 3.1-8B仍能超越噪声教师labels（micro F1 score 0.67 vs 0.63），展示了模型的内在潜力。这些发现突显了使用合成labels fine-tuning LLM的实际价值，为医疗领域LLM的专业化提供了有前景的研究方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16563v1",
      "published_date": "2024-09-25 02:29:44 UTC",
      "updated_date": "2024-09-25 02:29:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:53:58.836756"
    },
    {
      "arxiv_id": "2409.16560v2",
      "title": "Dynamic-Width Speculative Beam Decoding for Efficient LLM Inference",
      "title_zh": "用于高效 LLM 推理的动态宽度推测光束解码",
      "authors": [
        "Zongyue Qin",
        "Zifan He",
        "Neha Prakriya",
        "Jason Cong",
        "Yizhou Sun"
      ],
      "abstract": "Large language models (LLMs) have shown outstanding performance across\nnumerous real-world tasks. However, the autoregressive nature of these models\nmakes the inference process slow and costly. Speculative decoding has emerged\nas a promising solution, leveraging a smaller auxiliary model to draft future\ntokens, which are then validated simultaneously by the larger model, achieving\na speed-up of 1-2x. Although speculative decoding matches the same distribution\nas multinomial sampling, multinomial sampling itself is prone to suboptimal\noutputs, whereas beam sampling is widely recognized for producing\nhigher-quality results by maintaining multiple candidate sequences at each\nstep. This paper explores the novel integration of speculative decoding with\nbeam sampling. However, there are four key challenges: (1) how to generate\nmultiple sequences from the larger model's distribution given drafts sequences\nfrom the small model; (2) how to dynamically optimize the number of beams to\nbalance efficiency and accuracy; (3) how to efficiently verify the multiple\ndrafts in parallel; and (4) how to address the extra memory costs inherent in\nbeam sampling. To address these challenges, we propose dynamic-width\nspeculative beam decoding (DSBD). Specifically, we first introduce a novel\ndraft and verification scheme that generates multiple sequences following the\nlarge model's distribution based on beam sampling trajectories from the small\nmodel. Then, we introduce an adaptive mechanism to dynamically tune the number\nof beams based on the context, optimizing efficiency and effectiveness.\nBesides, we extend tree-based parallel verification to handle multiple trees\nsimultaneously, accelerating the verification process. Finally, we illustrate a\nsimple modification to our algorithm to mitigate the memory overhead of beam\nsampling...",
      "tldr_zh": "本论文提出了一种名为 Dynamic-Width Speculative Beam Decoding (DSBD) 的方法，以提高大型语言模型 (LLMs) 推理的效率。DSBD 将 Speculative Decoding 与 Beam Sampling 整合，利用小型辅助模型生成草稿序列，然后基于大模型的分布验证多个候选序列，从而解决传统 Multinomial Sampling 的次优输出问题。论文针对四个关键挑战设计了解决方案，包括生成符合大模型分布的多个序列、动态优化 Beam 数量以平衡效率和准确性、扩展树-based parallel verification 以并行处理多个树，以及修改算法减轻 Beam Sampling 的内存开销。实验表明，此方法能显著提升推理速度和输出质量，为高效的 LLM 推理提供了一个可扩展框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16560v2",
      "published_date": "2024-09-25 02:20:42 UTC",
      "updated_date": "2025-03-14 16:18:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:54:10.122598"
    },
    {
      "arxiv_id": "2409.16559v2",
      "title": "Demystifying Issues, Causes and Solutions in LLM Open-Source Projects",
      "title_zh": "翻译失败",
      "authors": [
        "Yangxiao Cai",
        "Peng Liang",
        "Yifei Wang",
        "Zengyang Li",
        "Mojtaba Shahin"
      ],
      "abstract": "With the advancements of Large Language Models (LLMs), an increasing number\nof open-source software projects are using LLMs as their core functional\ncomponent. Although research and practice on LLMs are capturing considerable\ninterest, no dedicated studies explored the challenges faced by practitioners\nof LLM open-source projects, the causes of these challenges, and potential\nsolutions. To fill this research gap, we conducted an empirical study to\nunderstand the issues that practitioners encounter when developing and using\nLLM open-source software, the possible causes of these issues, and potential\nsolutions. We collected all closed issues from 15 LLM open-source projects and\nlabelled issues that met our requirements. We then randomly selected 994 issues\nfrom the labelled issues as the sample for data extraction and analysis to\nunderstand the prevalent issues, their underlying causes, and potential\nsolutions. Our study results show that (1) Model Issue is the most common issue\nfaced by practitioners, (2) Model Problem, Configuration and Connection\nProblem, and Feature and Method Problem are identified as the most frequent\ncauses of the issues, and (3) Optimize Model is the predominant solution to the\nissues. Based on the study results, we provide implications for practitioners\nand researchers of LLM open-source projects.",
      "tldr_zh": "这篇论文通过实证研究分析了15个大型语言模型(LLM)开源项目的关闭问题，旨在揭示从业者在开发和使用这些项目时面临的挑战、潜在原因以及解决方案。研究者从收集的标签化问题中随机选取994个进行数据提取和分析，发现Model Issue是最常见的问题，而Model Problem、Configuration and Connection Problem以及Feature and Method Problem是主要原因，Optimize Model则被认定为最有效的解决方案。论文基于这些发现，为LLM开源项目的从业者和研究者提供了实际启示，以改进项目开发和维护。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Preprint accepted for publication in Journal of Systems and Software,\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2409.16559v2",
      "published_date": "2024-09-25 02:16:45 UTC",
      "updated_date": "2025-04-07 06:57:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:54:20.733112"
    },
    {
      "arxiv_id": "2409.16539v2",
      "title": "Context-aware and Style-related Incremental Decoding framework for Discourse-Level Literary Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanchang Luo",
        "Jiaxin Guo",
        "Daimeng Wei",
        "Hengchao Shang",
        "Zongyao Li",
        "Zhanglin Wu",
        "Zhiqiang Rao",
        "Shaojun Li",
        "Jinlong Yang",
        "Hao Yang"
      ],
      "abstract": "This report outlines our approach for the WMT24 Discourse-Level Literary\nTranslation Task, focusing on the Chinese-English language pair in the\nConstrained Track. Translating literary texts poses significant challenges due\nto the nuanced meanings, idiomatic expressions, and intricate narrative\nstructures inherent in such works. To address these challenges, we leveraged\nthe Chinese-Llama2 model, specifically enhanced for this task through a\ncombination of Continual Pre-training (CPT) and Supervised Fine-Tuning (SFT).\nOur methodology includes a novel Incremental Decoding framework, which ensures\nthat each sentence is translated with consideration of its broader context,\nmaintaining coherence and consistency throughout the text. This approach allows\nthe model to capture long-range dependencies and stylistic elements, producing\ntranslations that faithfully preserve the original literary quality. Our\nexperiments demonstrate significant improvements in both sentence-level and\ndocument-level BLEU scores, underscoring the effectiveness of our proposed\nframework in addressing the complexities of document-level literary\ntranslation.",
      "tldr_zh": "本研究针对 WMT24 话语级文学翻译任务，提出了一种 Context-aware and Style-related Incremental Decoding 框架，用于处理中文到英文的文学文本翻译。该框架基于增强后的 Chinese-Llama2 模型，通过 Continual Pre-training (CPT) 和 Supervised Fine-Tuning (SFT) 方法，确保翻译时考虑更广泛的上下文和风格元素，从而捕捉长距离依赖并保持文本连贯性。实验结果显示，该方法在句子级和文档级 BLEU scores 上实现了显著提升，证明了其在复杂文学翻译中的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 2 figures, wmt24",
      "pdf_url": "http://arxiv.org/pdf/2409.16539v2",
      "published_date": "2024-09-25 01:27:24 UTC",
      "updated_date": "2024-09-29 09:09:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:54:36.166274"
    },
    {
      "arxiv_id": "2409.16538v1",
      "title": "Source-Free Domain Adaptation for YOLO Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Varailhon",
        "Masih Aminbeidokhti",
        "Marco Pedersoli",
        "Eric Granger"
      ],
      "abstract": "Source-free domain adaptation (SFDA) is a challenging problem in object\ndetection, where a pre-trained source model is adapted to a new target domain\nwithout using any source domain data for privacy and efficiency reasons. Most\nstate-of-the-art SFDA methods for object detection have been proposed for\nFaster-RCNN, a detector that is known to have high computational complexity.\nThis paper focuses on domain adaptation techniques for real-world vision\nsystems, particularly for the YOLO family of single-shot detectors known for\ntheir fast baselines and practical applications. Our proposed SFDA method -\nSource-Free YOLO (SF-YOLO) - relies on a teacher-student framework in which the\nstudent receives images with a learned, target domain-specific augmentation,\nallowing the model to be trained with only unlabeled target data and without\nrequiring feature alignment. A challenge with self-training using a\nmean-teacher architecture in the absence of labels is the rapid decline of\naccuracy due to noisy or drifting pseudo-labels. To address this issue, a\nteacher-to-student communication mechanism is introduced to help stabilize the\ntraining and reduce the reliance on annotated target data for model selection.\nDespite its simplicity, our approach is competitive with state-of-the-art\ndetectors on several challenging benchmark datasets, even sometimes\noutperforming methods that use source data for adaptation.",
      "tldr_zh": "这篇论文针对YOLO物体检测器，提出了Source-Free Domain Adaptation (SFDA)方法，以适应新目标域，而无需使用源域数据，从而提升隐私和效率。提出的SF-YOLO框架采用teacher-student机制，通过目标域特定增强图像进行训练，并引入teacher-to-student通信机制来稳定训练过程，减少伪标签噪声导致的准确率下降。实验结果显示，该方法在多个挑战性基准数据集上与最先进检测器竞争，甚至在某些情况下超越了依赖源数据的适应方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024: European Conference on Computer Vision - Workshop on\n  Out-of-Distribution Generalization in Computer Vision Foundation Models,\n  Milan Italy",
      "pdf_url": "http://arxiv.org/pdf/2409.16538v1",
      "published_date": "2024-09-25 01:22:10 UTC",
      "updated_date": "2024-09-25 01:22:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:54:44.577448"
    },
    {
      "arxiv_id": "2409.16532v2",
      "title": "Graph Pruning Based Spatial and Temporal Graph Convolutional Network with Transfer Learning for Traffic Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zihao Jing"
      ],
      "abstract": "With the process of urbanization and the rapid growth of population, the\nissue of traffic congestion has become an increasingly critical concern.\nIntelligent transportation systems heavily rely on real-time and precise\nprediction algorithms to address this problem. While Recurrent Neural Network\n(RNN) and Graph Convolutional Network (GCN) methods in deep learning have\ndemonstrated high accuracy in predicting road conditions when sufficient data\nis available, forecasting in road networks with limited data remains a\nchallenging task. This study proposed a novel Spatial-temporal Convolutional\nNetwork (TL-GPSTGN) based on graph pruning and transfer learning framework to\ntackle this issue. Firstly, the essential structure and information of the\ngraph are extracted by analyzing the correlation and information entropy of the\nroad network structure and feature data. By utilizing graph pruning techniques,\nthe adjacency matrix of the graph and the input feature data are processed,\nresulting in a significant improvement in the model's migration performance.\nSubsequently, the well-characterized data are inputted into the\nspatial-temporal graph convolutional network to capture the spatial-temporal\nrelationships and make predictions regarding the road conditions. Furthermore,\nthis study conducts comprehensive testing and validation of the TL-GPSTGN\nmethod on real datasets, comparing its prediction performance against other\ncommonly used models under identical conditions. The results demonstrate the\nexceptional predictive accuracy of TL-GPSTGN on a single dataset, as well as\nits robust migration performance across different datasets.",
      "tldr_zh": "该研究针对交通预测中的数据有限挑战，提出了一种基于图修剪（graph pruning）和迁移学习（transfer learning）的空间-时间图卷积网络（TL-GPSTGN）模型，以提升预测准确性。方法首先通过分析路网结构的相关性和信息熵提取关键图结构，并利用图修剪技术优化邻接矩阵和特征数据，提高模型的迁移性能。随后，将处理后的数据输入空间-时间图卷积网络，捕获路况的空间-时间关系进行预测。实验在真实数据集上验证，TL-GPSTGN比其他常用模型表现出更高的预测准确性和跨数据集的鲁棒迁移性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Code is available at: https://github.com/selmiss/GP-TLSTGCN",
      "pdf_url": "http://arxiv.org/pdf/2409.16532v2",
      "published_date": "2024-09-25 00:59:23 UTC",
      "updated_date": "2024-12-31 05:45:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:54:57.288891"
    },
    {
      "arxiv_id": "2409.16517v1",
      "title": "SynChart: Synthesizing Charts from Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mengchen Liu",
        "Qixiu Li",
        "Dongdong Chen",
        "Dong Chen",
        "Jianmin Bao",
        "Yunsheng Li"
      ],
      "abstract": "With the release of GPT-4V(O), its use in generating pseudo labels for\nmulti-modality tasks has gained significant popularity. However, it is still a\nsecret how to build such advanced models from its base large language models\n(LLMs). This work explores the potential of using LLMs alone for data\ngeneration and develop competitive multi-modality models focusing on chart\nunderstanding. We construct a large-scale chart dataset, SynChart, which\ncontains approximately 4 million diverse chart images with over 75 million\ndense annotations, including data tables, code, descriptions, and\nquestion-answer sets. We trained a 4.2B chart-expert model using this dataset\nand achieve near-GPT-4O performance on the ChartQA task, surpassing GPT-4V.",
      "tldr_zh": "本文提出SynChart方法，使用大型语言模型（LLMs）单独生成数据，以构建专注于图表理解的竞争性多模态模型。主要贡献包括构建一个大规模数据集SynChart，包含约400万张多样化图表图像和超过7500万条密集注解（如数据表、代码、描述和问答集）。研究团队训练了一个4.2B参数的图表专家模型，在ChartQA任务上达到了接近GPT-4O的性能，并超过了GPT-4V。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16517v1",
      "published_date": "2024-09-25 00:18:12 UTC",
      "updated_date": "2024-09-25 00:18:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:55:08.343933"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 141,
  "processed_papers_count": 141,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T03:55:28.365260"
}