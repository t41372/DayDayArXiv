[
  {
    "arxiv_id": "2409.17433v1",
    "title": "HDFlow: Enhancing LLM Complex Problem-Solving with Hybrid Thinking and Dynamic Workflows",
    "authors": [
      "Wenlin Yao",
      "Haitao Mi",
      "Dong Yu"
    ],
    "abstract": "Despite recent advancements in large language models (LLMs), their\nperformance on complex reasoning problems requiring multi-step thinking and\ncombining various skills is still limited. To address this, we propose a novel\nframework HDFlow for complex reasoning with LLMs that combines fast and slow\nthinking modes in an adaptive manner. Our approach consists of two key\ncomponents: 1) a new approach for slow, deliberate reasoning called Dynamic\nWorkflow, which automatically decomposes complex problems into more manageable\nsub-tasks and dynamically designs a workflow to assemble specialized LLM or\nsymbolic reasoning tools to solve sub-tasks; 2) Hybrid Thinking, a general\nframework that dynamically combines fast and slow thinking based on problem\ncomplexity. Finally, we propose an easy-to-scale method for automatically\nsynthesizing a large-scale dataset of 27K challenging reasoning problems for\ncomplex reasoning and a hybrid thinking tuning method that trains smaller LLMs\non this dataset to internalize the fast/slow hybrid reasoning strategies.\nExperiments on four reasoning benchmark datasets demonstrate that our slow\nthinking with dynamic workflows significantly outperforms Chain-of-Thought, and\nhybrid thinking achieves the highest accuracy while providing an effective\nbalance between computational efficiency and performance. Fine-tuning using our\nhybrid thinking approach also significantly boosts the complex reasoning\ncapabilities of open-source language models. The results showcase the promise\nof slow thinking, dynamic workflows, and hybrid thinking in expanding the\nfrontier of complex problem-solving with LLMs\\footnote{Code and data will be\nreleased at \\url{https://github.com/wenlinyao/HDFlow}.}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "27 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.17433v1",
    "published_date": "2024-09-25 23:52:17 UTC",
    "updated_date": "2024-09-25 23:52:17 UTC"
  },
  {
    "arxiv_id": "2409.17426v1",
    "title": "Exploring the Use of ChatGPT for a Systematic Literature Review: a Design-Based Research",
    "authors": [
      "Qian Huang",
      "Qiyun Wang"
    ],
    "abstract": "ChatGPT has been used in several educational contexts,including learning,\nteaching and research. It also has potential to conduct the systematic\nliterature review (SLR). However, there are limited empirical studies on how to\nuse ChatGPT in conducting a SLR. Based on a SLR published,this study used\nChatGPT to conduct a SLR of the same 33 papers in a design-based approach, to\nsee what the differences are by comparing the reviews' results,and to answer:\nTo what extent can ChatGPT conduct SLR? What strategies can human researchers\nutilize to structure prompts for ChatGPT that enhance the reliability and\nvalidity of a SLR? This study found that ChatGPT could conduct a SLR. It needs\ndetailed and accurate prompts to analyze the literature. It also has\nlimitations. Guiding principles are summarized from this study for researchers\nto follow when they need to conduct SLRs using ChatGPT.",
    "categories": [
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 13 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.17426v1",
    "published_date": "2024-09-25 23:29:19 UTC",
    "updated_date": "2024-09-25 23:29:19 UTC"
  },
  {
    "arxiv_id": "2409.17422v1",
    "title": "Discovering the Gems in Early Layers: Accelerating Long-Context LLMs with 1000x Input Token Reduction",
    "authors": [
      "Zhenmei Shi",
      "Yifei Ming",
      "Xuan-Phi Nguyen",
      "Yingyu Liang",
      "Shafiq Joty"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nhandling long context inputs, but this comes at the cost of increased\ncomputational resources and latency. Our research introduces a novel approach\nfor the long context bottleneck to accelerate LLM inference and reduce GPU\nmemory consumption. Our research demonstrates that LLMs can identify relevant\ntokens in the early layers before generating answers to a query. Leveraging\nthis insight, we propose an algorithm that uses early layers of an LLM as\nfilters to select and compress input tokens, significantly reducing the context\nlength for subsequent processing. Our method, GemFilter, demonstrates\nsubstantial improvements in both speed and memory efficiency compared to\nexisting techniques, such as standard attention and SnapKV/H2O. Notably, it\nachieves a 2.4$\\times$ speedup and 30\\% reduction in GPU memory usage compared\nto SOTA methods. Evaluation on the Needle in a Haystack task shows that\nGemFilter significantly outperforms standard attention, SnapKV and demonstrates\ncomparable performance on the LongBench challenge. GemFilter is simple,\ntraining-free, and broadly applicable across different LLMs. Crucially, it\nprovides interpretability by allowing humans to inspect the selected input\nsequence. These findings not only offer practical benefits for LLM deployment,\nbut also enhance our understanding of LLM internal mechanisms, paving the way\nfor further optimizations in LLM design and inference. Our code is available at\n\\url{https://github.com/SalesforceAIResearch/GemFilter}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17422v1",
    "published_date": "2024-09-25 23:14:47 UTC",
    "updated_date": "2024-09-25 23:14:47 UTC"
  },
  {
    "arxiv_id": "2409.17421v1",
    "title": "Solar Active Regions Emergence Prediction Using Long Short-Term Memory Networks",
    "authors": [
      "Spiridon Kasapis",
      "Irina N. Kitiashvili",
      "Alexander G. Kosovichev",
      "John T. Stefan"
    ],
    "abstract": "We developed Long Short-Term Memory (LSTM) models to predict the formation of\nactive regions (ARs) on the solar surface. Using the Doppler shift velocity,\nthe continuum intensity, and the magnetic field observations from the Solar\nDynamics Observatory (SDO) Helioseismic and Magnetic Imager (HMI), we have\ncreated time-series datasets of acoustic power and magnetic flux, which are\nused to train LSTM models on predicting continuum intensity, 12 hours in\nadvance. These novel machine learning (ML) models are able to capture\nvariations of the acoustic power density associated with upcoming magnetic flux\nemergence and continuum intensity decrease. Testing of the models' performance\nwas done on data for 5 ARs, unseen from the models during training. Model 8,\nthe best performing model trained, was able to make a successful prediction of\nemergence for all testing active regions in an experimental setting and three\nof them in an operational. The model predicted the emergence of AR11726,\nAR13165, and AR13179 respectively 10, 29, and 5 hours in advance, and\nvariations of this model achieved average RMSE values of 0.11 for both active\nand quiet areas on the solar disc. This work sets the foundations for ML-aided\nprediction of solar ARs.",
    "categories": [
      "astro-ph.SR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "astro-ph.SR",
    "comment": "20 pages, 8 figures, 5 tables, under review at the AAS Astrophysical\n  Journal",
    "pdf_url": "http://arxiv.org/pdf/2409.17421v1",
    "published_date": "2024-09-25 23:09:46 UTC",
    "updated_date": "2024-09-25 23:09:46 UTC"
  },
  {
    "arxiv_id": "2409.17416v1",
    "title": "From Deception to Detection: The Dual Roles of Large Language Models in Fake News",
    "authors": [
      "Dorsaf Sallami",
      "Yuan-Chen Chang",
      "Esma Aïmeur"
    ],
    "abstract": "Fake news poses a significant threat to the integrity of information\necosystems and public trust. The advent of Large Language Models (LLMs) holds\nconsiderable promise for transforming the battle against fake news. Generally,\nLLMs represent a double-edged sword in this struggle. One major concern is that\nLLMs can be readily used to craft and disseminate misleading information on a\nlarge scale. This raises the pressing questions: Can LLMs easily generate\nbiased fake news? Do all LLMs have this capability? Conversely, LLMs offer\nvaluable prospects for countering fake news, thanks to their extensive\nknowledge of the world and robust reasoning capabilities. This leads to other\ncritical inquiries: Can we use LLMs to detect fake news, and do they outperform\ntypical detection models? In this paper, we aim to address these pivotal\nquestions by exploring the performance of various LLMs. Our objective is to\nexplore the capability of various LLMs in effectively combating fake news,\nmarking this as the first investigation to analyze seven such models. Our\nresults reveal that while some models adhere strictly to safety protocols,\nrefusing to generate biased or misleading content, other models can readily\nproduce fake news across a spectrum of biases. Additionally, our results show\nthat larger models generally exhibit superior detection abilities and that\nLLM-generated fake news are less likely to be detected than human-written ones.\nFinally, our findings demonstrate that users can benefit from LLM-generated\nexplanations in identifying fake news.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17416v1",
    "published_date": "2024-09-25 22:57:29 UTC",
    "updated_date": "2024-09-25 22:57:29 UTC"
  },
  {
    "arxiv_id": "2409.17411v3",
    "title": "Exploring Semantic Clustering in Deep Reinforcement Learning for Video Games",
    "authors": [
      "Liang Zhang",
      "Justin Lieffers",
      "Adarsh Pyarelal"
    ],
    "abstract": "In this paper, we investigate the semantic clustering properties of deep\nreinforcement learning (DRL) for video games, enriching our understanding of\nthe internal dynamics of DRL and advancing its interpretability. In this\ncontext, semantic clustering refers to the inherent capacity of neural networks\nto internally group video inputs based on semantic similarity. To achieve this,\nwe propose a novel DRL architecture that integrates a semantic clustering\nmodule featuring both feature dimensionality reduction and online clustering.\nThis module seamlessly integrates into the DRL training pipeline, addressing\ninstability issues observed in previous t-SNE-based analysis methods and\neliminating the necessity for extensive manual annotation of semantic analysis.\nThrough experiments, we validate the effectiveness of the proposed module and\nthe semantic clustering properties in DRL for video games. Additionally, based\non these properties, we introduce new analytical methods to help understand the\nhierarchical structure of policies and the semantic distribution within the\nfeature space.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17411v3",
    "published_date": "2024-09-25 22:48:14 UTC",
    "updated_date": "2024-10-01 02:54:41 UTC"
  },
  {
    "arxiv_id": "2409.17408v2",
    "title": "Sociotechnical Approach to Enterprise Generative Artificial Intelligence (E-GenAI)",
    "authors": [
      "Leoncio Jimenez",
      "Francisco Venegas"
    ],
    "abstract": "In this theoretical article, a sociotechnical approach is proposed to\ncharacterize. First, the business ecosystem, focusing on the relationships\namong Providers, Enterprise, and Customers through SCM, ERP, and CRM platforms\nto align: (1) Business Intelligence (BI), Fuzzy Logic (FL), and TRIZ (Theory of\nInventive Problem Solving), through the OID model, and (2) Knowledge Management\n(KM) and Imperfect Knowledge Management (IKM), through the OIDK model. Second,\nthe article explores the E-GenAI business ecosystem, which integrates\nGenAI-based platforms for SCM, ERP, and CRM with GenAI-based platforms for BI,\nFL, TRIZ, KM, and IKM, to align Large Language Models (LLMs) through the\nE-GenAI (OID) model. Finally, to understand the dynamics of LLMs, we utilize\nfinite automata to model the relationships between Followers and Followees.\nThis facilitates the construction of LLMs that can identify specific\ncharacteristics of users on a social media platform.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17408v2",
    "published_date": "2024-09-25 22:39:55 UTC",
    "updated_date": "2025-01-31 12:19:43 UTC"
  },
  {
    "arxiv_id": "2409.17407v1",
    "title": "Post-hoc Reward Calibration: A Case Study on Length Bias",
    "authors": [
      "Zeyu Huang",
      "Zihan Qiu",
      "Zili Wang",
      "Edoardo M. Ponti",
      "Ivan Titov"
    ],
    "abstract": "Reinforcement Learning from Human Feedback aligns the outputs of Large\nLanguage Models with human values and preferences. Central to this process is\nthe reward model (RM), which translates human feedback into training signals\nfor optimising LLM behaviour. However, RMs can develop biases by exploiting\nspurious correlations in their training data, such as favouring outputs based\non length or style rather than true quality. These biases can lead to incorrect\noutput rankings, sub-optimal model evaluations, and the amplification of\nundesirable behaviours in LLMs alignment. This paper addresses the challenge of\ncorrecting such biases without additional data and training, introducing the\nconcept of Post-hoc Reward Calibration. We first propose an intuitive approach\nto estimate the bias term and, thus, remove it to approximate the underlying\ntrue reward. We then extend the approach to a more general and robust form with\nthe Locally Weighted Regression. Focusing on the prevalent length bias, we\nvalidate our proposed approaches across three experimental settings,\ndemonstrating consistent improvements: (1) a 3.11 average performance gain\nacross 33 reward models on the RewardBench dataset; (2) enhanced alignment of\nRM rankings with GPT-4 evaluations and human preferences based on the\nAlpacaEval benchmark; and (3) improved Length-Controlled win rate of the RLHF\nprocess in multiple LLM--RM combinations. Our method is computationally\nefficient and generalisable to other types of bias and RMs, offering a scalable\nand robust solution for mitigating biases in LLM alignment. Our code and\nresults are available at https://github.com/ZeroYuHuang/Reward-Calibration.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2409.17407v1",
    "published_date": "2024-09-25 22:30:42 UTC",
    "updated_date": "2024-09-25 22:30:42 UTC"
  },
  {
    "arxiv_id": "2409.17405v1",
    "title": "AI Enabled Neutron Flux Measurement and Virtual Calibration in Boiling Water Reactors",
    "authors": [
      "Anirudh Tunga",
      "Jordan Heim",
      "Michael Mueterthies",
      "Thomas Gruenwald",
      "Jonathan Nistor"
    ],
    "abstract": "Accurately capturing the three dimensional power distribution within a\nreactor core is vital for ensuring the safe and economical operation of the\nreactor, compliance with Technical Specifications, and fuel cycle planning\n(safety, control, and performance evaluation). Offline (that is, during cycle\nplanning and core design), a three dimensional neutronics simulator is used to\nestimate the reactor's power, moderator, void, and flow distributions, from\nwhich margin to thermal limits and fuel exposures can be approximated. Online,\nthis is accomplished with a system of local power range monitors (LPRMs)\ndesigned to capture enough neutron flux information to infer the full nodal\npower distribution. Certain problems with this process, ranging from\nmeasurement and calibration to the power adaption process, pose challenges to\noperators and limit the ability to design reload cores economically (e.g.,\nengineering in insufficient margin or more margin than required). Artificial\nintelligence (AI) and machine learning (ML) are being used to solve the\nproblems to reduce maintenance costs, improve the accuracy of online local\npower measurements, and decrease the bias between offline and online power\ndistributions, thereby leading to a greater ability to design safe and\neconomical reload cores. We present ML models trained from two deep neural\nnetwork (DNN) architectures, SurrogateNet and LPRMNet, that demonstrate a\ntesting error of 1 percent and 3 percent, respectively. Applications of these\nmodels can include virtual sensing capability for bypassed or malfunctioning\nLPRMs, on demand virtual calibration of detectors between successive\ncalibrations, highly accurate nuclear end of life determinations for LPRMs, and\nreduced bias between measured and predicted power distributions within the\ncore.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17405v1",
    "published_date": "2024-09-25 22:30:09 UTC",
    "updated_date": "2024-09-25 22:30:09 UTC"
  },
  {
    "arxiv_id": "2409.17403v1",
    "title": "Transient Adversarial 3D Projection Attacks on Object Detection in Autonomous Driving",
    "authors": [
      "Ce Zhou",
      "Qiben Yan",
      "Sijia Liu"
    ],
    "abstract": "Object detection is a crucial task in autonomous driving. While existing\nresearch has proposed various attacks on object detection, such as those using\nadversarial patches or stickers, the exploration of projection attacks on 3D\nsurfaces remains largely unexplored. Compared to adversarial patches or\nstickers, which have fixed adversarial patterns, projection attacks allow for\ntransient modifications to these patterns, enabling a more flexible attack. In\nthis paper, we introduce an adversarial 3D projection attack specifically\ntargeting object detection in autonomous driving scenarios. We frame the attack\nformulation as an optimization problem, utilizing a combination of color\nmapping and geometric transformation models. Our results demonstrate the\neffectiveness of the proposed attack in deceiving YOLOv3 and Mask R-CNN in\nphysical settings. Evaluations conducted in an indoor environment show an\nattack success rate of up to 100% under low ambient light conditions,\nhighlighting the potential damage of our attack in real-world driving\nscenarios.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "20 pages, 7 figures, SmartSP 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.17403v1",
    "published_date": "2024-09-25 22:27:11 UTC",
    "updated_date": "2024-09-25 22:27:11 UTC"
  },
  {
    "arxiv_id": "2409.17402v1",
    "title": "Enhancing Recommendation with Denoising Auxiliary Task",
    "authors": [
      "Pengsheng Liu",
      "Linan Zheng",
      "Jiale Chen",
      "Guangfa Zhang",
      "Yang Xu",
      "Jinyun Fang"
    ],
    "abstract": "The historical interaction sequences of users plays a crucial role in\ntraining recommender systems that can accurately predict user preferences.\nHowever, due to the arbitrariness of user behavior, the presence of noise in\nthese sequences poses a challenge to predicting their next actions in\nrecommender systems. To address this issue, our motivation is based on the\nobservation that training noisy sequences and clean sequences (sequences\nwithout noise) with equal weights can impact the performance of the model. We\npropose a novel self-supervised Auxiliary Task Joint Training (ATJT) method\naimed at more accurately reweighting noisy sequences in recommender systems.\nSpecifically, we strategically select subsets from users' original sequences\nand perform random replacements to generate artificially replaced noisy\nsequences. Subsequently, we perform joint training on these artificially\nreplaced noisy sequences and the original sequences. Through effective\nreweighting, we incorporate the training results of the noise recognition model\ninto the recommender model. We evaluate our method on three datasets using a\nconsistent base model. Experimental results demonstrate the effectiveness of\nintroducing self-supervised auxiliary task to enhance the base model's\nperformance.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17402v1",
    "published_date": "2024-09-25 22:26:29 UTC",
    "updated_date": "2024-09-25 22:26:29 UTC"
  },
  {
    "arxiv_id": "2409.17400v2",
    "title": "AgRegNet: A Deep Regression Network for Flower and Fruit Density Estimation, Localization, and Counting in Orchards",
    "authors": [
      "Uddhav Bhattarai",
      "Santosh Bhusal",
      "Qin Zhang",
      "Manoj Karkee"
    ],
    "abstract": "One of the major challenges for the agricultural industry today is the\nuncertainty in manual labor availability and the associated cost. Automated\nflower and fruit density estimation, localization, and counting could help\nstreamline harvesting, yield estimation, and crop-load management strategies\nsuch as flower and fruitlet thinning. This article proposes a deep\nregression-based network, AgRegNet, to estimate density, count, and location of\nflower and fruit in tree fruit canopies without explicit object detection or\npolygon annotation. Inspired by popular U-Net architecture, AgRegNet is a\nU-shaped network with an encoder-to-decoder skip connection and modified\nConvNeXt-T as an encoder feature extractor. AgRegNet can be trained based on\ninformation from point annotation and leverages segmentation information and\nattention modules (spatial and channel) to highlight relevant flower and fruit\nfeatures while suppressing non-relevant background features. Experimental\nevaluation in apple flower and fruit canopy images under an unstructured\norchard environment showed that AgRegNet achieved promising accuracy as\nmeasured by Structural Similarity Index (SSIM), percentage Mean Absolute Error\n(pMAE) and mean Average Precision (mAP) to estimate flower and fruit density,\ncount, and centroid location, respectively. Specifically, the SSIM, pMAE, and\nmAP values for flower images were 0.938, 13.7%, and 0.81, respectively. For\nfruit images, the corresponding values were 0.910, 5.6%, and 0.93. Since the\nproposed approach relies on information from point annotation, it is suitable\nfor sparsely and densely located objects. This simplified technique will be\nhighly applicable for growers to accurately estimate yields and decide on\noptimal chemical and mechanical flower thinning practices.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Published in Computers and Electronics in Agriculture",
    "pdf_url": "http://arxiv.org/pdf/2409.17400v2",
    "published_date": "2024-09-25 22:19:32 UTC",
    "updated_date": "2025-01-16 20:25:21 UTC"
  },
  {
    "arxiv_id": "2409.17386v1",
    "title": "Beyond Redundancy: Information-aware Unsupervised Multiplex Graph Structure Learning",
    "authors": [
      "Zhixiang Shen",
      "Shuo Wang",
      "Zhao Kang"
    ],
    "abstract": "Unsupervised Multiplex Graph Learning (UMGL) aims to learn node\nrepresentations on various edge types without manual labeling. However,\nexisting research overlooks a key factor: the reliability of the graph\nstructure. Real-world data often exhibit a complex nature and contain abundant\ntask-irrelevant noise, severely compromising UMGL's performance. Moreover,\nexisting methods primarily rely on contrastive learning to maximize mutual\ninformation across different graphs, limiting them to multiplex graph redundant\nscenarios and failing to capture view-unique task-relevant information. In this\npaper, we focus on a more realistic and challenging task: to unsupervisedly\nlearn a fused graph from multiple graphs that preserve sufficient task-relevant\ninformation while removing task-irrelevant noise. Specifically, our proposed\nInformation-aware Unsupervised Multiplex Graph Fusion framework (InfoMGF) uses\ngraph structure refinement to eliminate irrelevant noise and simultaneously\nmaximizes view-shared and view-unique task-relevant information, thereby\ntackling the frontier of non-redundant multiplex graph. Theoretical analyses\nfurther guarantee the effectiveness of InfoMGF. Comprehensive experiments\nagainst various baselines on different downstream tasks demonstrate its\nsuperior performance and robustness. Surprisingly, our unsupervised method even\nbeats the sophisticated supervised approaches. The source code and datasets are\navailable at https://github.com/zxlearningdeep/InfoMGF.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Appear in NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.17386v1",
    "published_date": "2024-09-25 22:00:26 UTC",
    "updated_date": "2024-09-25 22:00:26 UTC"
  },
  {
    "arxiv_id": "2409.17385v2",
    "title": "SSTP: Efficient Sample Selection for Trajectory Prediction",
    "authors": [
      "Ruining Yang",
      "Yi Xu",
      "Yun Fu",
      "Lili Su"
    ],
    "abstract": "Trajectory prediction is a core task in autonomous driving. However, training\nadvanced trajectory prediction models on large-scale datasets is both\ntime-consuming and computationally expensive. In addition, the imbalanced\ndistribution of driving scenarios often biases models toward data-rich cases,\nlimiting performance in safety-critical, data-scarce conditions. To address\nthese challenges, we propose the Sample Selection for Trajectory Prediction\n(SSTP) framework, which constructs a compact yet balanced dataset for\ntrajectory prediction. SSTP consists of two main stages (1) Extraction, in\nwhich a pretrained trajectory prediction model computes gradient vectors for\neach sample to capture their influence on parameter updates; and (2) Selection,\nwhere a submodular function is applied to greedily choose a representative\nsubset that covers diverse driving scenarios. This approach significantly\nreduces the dataset size and mitigates scenario imbalance, without sacrificing\nprediction accuracy and even improving in high-density cases. We evaluate our\nproposed SSTP on the Argoverse 1 and Argoverse 2 benchmarks using a wide range\nof recent state-of-the-art models. Our experiments demonstrate that SSTP\nachieves comparable performance to full-dataset training using only half the\ndata while delivering substantial improvements in high-density traffic scenes\nand significantly reducing training time. Importantly, SSTP exhibits strong\ngeneralization and robustness, and the selected subset is model-agnostic,\noffering a broadly applicable solution.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17385v2",
    "published_date": "2024-09-25 22:00:11 UTC",
    "updated_date": "2025-03-20 03:32:59 UTC"
  },
  {
    "arxiv_id": "2409.17383v1",
    "title": "VectorSearch: Enhancing Document Retrieval with Semantic Embeddings and Optimized Search",
    "authors": [
      "Solmaz Seyed Monir",
      "Irene Lau",
      "Shubing Yang",
      "Dongfang Zhao"
    ],
    "abstract": "Traditional retrieval methods have been essential for assessing document\nsimilarity but struggle with capturing semantic nuances. Despite advancements\nin latent semantic analysis (LSA) and deep learning, achieving comprehensive\nsemantic understanding and accurate retrieval remains challenging due to high\ndimensionality and semantic gaps. The above challenges call for new techniques\nto effectively reduce the dimensions and close the semantic gaps. To this end,\nwe propose VectorSearch, which leverages advanced algorithms, embeddings, and\nindexing techniques for refined retrieval. By utilizing innovative multi-vector\nsearch operations and encoding searches with advanced language models, our\napproach significantly improves retrieval accuracy. Experiments on real-world\ndatasets show that VectorSearch outperforms baseline metrics, demonstrating its\nefficacy for large-scale retrieval tasks.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.DB",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.17383v1",
    "published_date": "2024-09-25 21:58:08 UTC",
    "updated_date": "2024-09-25 21:58:08 UTC"
  },
  {
    "arxiv_id": "2409.17380v1",
    "title": "Tesla's Autopilot: Ethics and Tragedy",
    "authors": [
      "Aravinda Jatavallabha"
    ],
    "abstract": "This case study delves into the ethical ramifications of an incident\ninvolving Tesla's Autopilot, emphasizing Tesla Motors' moral responsibility.\nUsing a seven-step ethical decision-making process, it examines user behavior,\nsystem constraints, and regulatory implications. This incident prompts a\nbroader evaluation of ethical challenges in the automotive industry's adoption\nof autonomous technologies, urging a reconsideration of industry norms and\nlegal frameworks. The analysis offers a succinct exploration of ethical\nconsiderations in evolving technological landscapes.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17380v1",
    "published_date": "2024-09-25 21:53:33 UTC",
    "updated_date": "2024-09-25 21:53:33 UTC"
  },
  {
    "arxiv_id": "2409.17372v2",
    "title": "Search for Efficient Large Language Models",
    "authors": [
      "Xuan Shen",
      "Pu Zhao",
      "Yifan Gong",
      "Zhenglun Kong",
      "Zheng Zhan",
      "Yushu Wu",
      "Ming Lin",
      "Chao Wu",
      "Xue Lin",
      "Yanzhi Wang"
    ],
    "abstract": "Large Language Models (LLMs) have long held sway in the realms of artificial\nintelligence research. Numerous efficient techniques, including weight pruning,\nquantization, and distillation, have been embraced to compress LLMs, targeting\nmemory reduction and inference acceleration, which underscore the redundancy in\nLLMs. However, most model compression techniques concentrate on weight\noptimization, overlooking the exploration of optimal architectures. Besides,\ntraditional architecture search methods, limited by the elevated complexity\nwith extensive parameters, struggle to demonstrate their effectiveness on LLMs.\nIn this paper, we propose a training-free architecture search framework to\nidentify optimal subnets that preserve the fundamental strengths of the\noriginal LLMs while achieving inference acceleration. Furthermore, after\ngenerating subnets that inherit specific weights from the original LLMs, we\nintroduce a reformation algorithm that utilizes the omitted weights to rectify\nthe inherited weights with a small amount of calibration data. Compared with\nSOTA training-free structured pruning works that can generate smaller networks,\nour method demonstrates superior performance across standard benchmarks.\nFurthermore, our generated subnets can directly reduce the usage of GPU memory\nand achieve inference acceleration. Code:\nhttps://github.com/shawnricecake/search-llm",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.17372v2",
    "published_date": "2024-09-25 21:32:12 UTC",
    "updated_date": "2024-10-30 20:04:01 UTC"
  },
  {
    "arxiv_id": "2409.17370v1",
    "title": "The Overfocusing Bias of Convolutional Neural Networks: A Saliency-Guided Regularization Approach",
    "authors": [
      "David Bertoin",
      "Eduardo Hugo Sanchez",
      "Mehdi Zouitine",
      "Emmanuel Rachelson"
    ],
    "abstract": "Despite transformers being considered as the new standard in computer vision,\nconvolutional neural networks (CNNs) still outperform them in low-data regimes.\nNonetheless, CNNs often make decisions based on narrow, specific regions of\ninput images, especially when training data is limited. This behavior can\nseverely compromise the model's generalization capabilities, making it\ndisproportionately dependent on certain features that might not represent the\nbroader context of images. While the conditions leading to this phenomenon\nremain elusive, the primary intent of this article is to shed light on this\nobserved behavior of neural networks. Our research endeavors to prioritize\ncomprehensive insight and to outline an initial response to this phenomenon. In\nline with this, we introduce Saliency Guided Dropout (SGDrop), a pioneering\nregularization approach tailored to address this specific issue. SGDrop\nutilizes attribution methods on the feature map to identify and then reduce the\ninfluence of the most salient features during training. This process encourages\nthe network to diversify its attention and not focus solely on specific\nstandout areas. Our experiments across several visual classification benchmarks\nvalidate SGDrop's role in enhancing generalization. Significantly, models\nincorporating SGDrop display more expansive attributions and neural activity,\noffering a more comprehensive view of input images in contrast to their\ntraditionally trained counterparts.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17370v1",
    "published_date": "2024-09-25 21:30:16 UTC",
    "updated_date": "2024-09-25 21:30:16 UTC"
  },
  {
    "arxiv_id": "2410.03706v1",
    "title": "Topological Foundations of Reinforcement Learning",
    "authors": [
      "David Krame Kadurha"
    ],
    "abstract": "The goal of this work is to serve as a foundation for deep studies of the\ntopology of state, action, and policy spaces in reinforcement learning. By\nstudying these spaces from a mathematical perspective, we expect to gain more\ninsight into how to build better algorithms to solve decision problems.\nTherefore, we focus on presenting the connection between the Banach fixed point\ntheorem and the convergence of reinforcement learning algorithms, and we\nillustrate how the insights gained from this can practically help in designing\nmore efficient algorithms. Before doing so, however, we first introduce\nrelevant concepts such as metric spaces, normed spaces and Banach spaces for\nbetter understanding, before expressing the entire reinforcement learning\nproblem in terms of Markov decision processes. This allows us to properly\nintroduce the Banach contraction principle in a language suitable for\nreinforcement learning, and to write the Bellman equations in terms of\noperators on Banach spaces to show why reinforcement learning algorithms\nconverge. Finally, we show how the insights gained from the mathematical study\nof convergence are helpful in reasoning about the best ways to make\nreinforcement learning algorithms more efficient.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.FA",
      "68T05"
    ],
    "primary_category": "cs.LG",
    "comment": "Supervisor : Yae Ulrich Gaba , Mentor : Domini Jocema Leko",
    "pdf_url": "http://arxiv.org/pdf/2410.03706v1",
    "published_date": "2024-09-25 21:21:23 UTC",
    "updated_date": "2024-09-25 21:21:23 UTC"
  },
  {
    "arxiv_id": "2409.17340v1",
    "title": "Koopman-driven grip force prediction through EMG sensing",
    "authors": [
      "Tomislav Bazina",
      "Ervin Kamenar",
      "Maria Fonoberova",
      "Igor Mezić"
    ],
    "abstract": "Loss of hand function due to conditions like stroke or multiple sclerosis\nsignificantly impacts daily activities. Robotic rehabilitation provides tools\nto restore hand function, while novel methods based on surface electromyography\n(sEMG) enable the adaptation of the device's force output according to the\nuser's condition, thereby improving rehabilitation outcomes. This study aims to\nachieve accurate force estimations during medium wrap grasps using a single\nsEMG sensor pair, thereby addressing the challenge of escalating sensor\nrequirements for precise predictions. We conducted sEMG measurements on 13\nsubjects at two forearm positions, validating results with a hand dynamometer.\nWe established flexible signal-processing steps, yielding high peak\ncross-correlations between the processed sEMG signal (representing meaningful\nmuscle activity) and grip force. Influential parameters were subsequently\nidentified through sensitivity analysis. Leveraging a novel data-driven Koopman\noperator theory-based approach and problem-specific data lifting techniques, we\ndevised a methodology for the estimation and short-term prediction of grip\nforce from processed sEMG signals. A weighted mean absolute percentage error\n(wMAPE) of approx. 5.5% was achieved for the estimated grip force, whereas\npredictions with a 0.5-second prediction horizon resulted in a wMAPE of approx.\n17.9%. The methodology proved robust regarding precise electrode positioning,\nas the effect of sensing position on error metrics was non-significant. The\nalgorithm executes exceptionally fast, processing, estimating, and predicting a\n0.5-second sEMG signal batch in just approx. 30 ms, facilitating real-time\nimplementation.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "math.DS"
    ],
    "primary_category": "cs.RO",
    "comment": "11 pages, 8 figures, journal",
    "pdf_url": "http://arxiv.org/pdf/2409.17340v1",
    "published_date": "2024-09-25 20:28:57 UTC",
    "updated_date": "2024-09-25 20:28:57 UTC"
  },
  {
    "arxiv_id": "2409.17336v1",
    "title": "The Technology of Outrage: Bias in Artificial Intelligence",
    "authors": [
      "Will Bridewell",
      "Paul F. Bello",
      "Selmer Bringsjord"
    ],
    "abstract": "Artificial intelligence and machine learning are increasingly used to offload\ndecision making from people. In the past, one of the rationales for this\nreplacement was that machines, unlike people, can be fair and unbiased.\nEvidence suggests otherwise. We begin by entertaining the ideas that algorithms\ncan replace people and that algorithms cannot be biased. Taken as axioms, these\nstatements quickly lead to absurdity. Spurred on by this result, we investigate\nthe slogans more closely and identify equivocation surrounding the word 'bias.'\nWe diagnose three forms of outrage-intellectual, moral, and political-that are\nat play when people react emotionally to algorithmic bias. Then we suggest\nthree practical approaches to addressing bias that the AI community could take,\nwhich include clarifying the language around bias, developing new auditing\nmethods for intelligent systems, and building certain capabilities into these\nsystems. We conclude by offering a moral regarding the conversations about\nalgorithmic bias that may transfer to other areas of artificial intelligence.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Distribution Statement A. Approved for public release; distribution\n  is unlimited",
    "pdf_url": "http://arxiv.org/pdf/2409.17336v1",
    "published_date": "2024-09-25 20:23:25 UTC",
    "updated_date": "2024-09-25 20:23:25 UTC"
  },
  {
    "arxiv_id": "2409.17332v1",
    "title": "Block Expanded DINORET: Adapting Natural Domain Foundation Models for Retinal Imaging Without Catastrophic Forgetting",
    "authors": [
      "Jay Zoellin",
      "Colin Merk",
      "Mischa Buob",
      "Amr Saad",
      "Samuel Giesser",
      "Tahm Spitznagel",
      "Ferhat Turgut",
      "Rui Santos",
      "Yukun Zhou",
      "Sigfried Wagner",
      "Pearse A. Keane",
      "Yih Chung Tham",
      "Delia Cabrera DeBuc",
      "Matthias D. Becker",
      "Gabor M. Somfai"
    ],
    "abstract": "Integrating deep learning into medical imaging is poised to greatly advance\ndiagnostic methods but it faces challenges with generalizability. Foundation\nmodels, based on self-supervised learning, address these issues and improve\ndata efficiency. Natural domain foundation models show promise for medical\nimaging, but systematic research evaluating domain adaptation, especially using\nself-supervised learning and parameter-efficient fine-tuning, remains\nunderexplored. Additionally, little research addresses the issue of\ncatastrophic forgetting during fine-tuning of foundation models. We adapted the\nDINOv2 vision transformer for retinal imaging classification tasks using\nself-supervised learning and generated two novel foundation models termed\nDINORET and BE DINORET. Publicly available color fundus photographs were\nemployed for model development and subsequent fine-tuning for diabetic\nretinopathy staging and glaucoma detection. We introduced block expansion as a\nnovel domain adaptation strategy and assessed the models for catastrophic\nforgetting. Models were benchmarked to RETFound, a state-of-the-art foundation\nmodel in ophthalmology. DINORET and BE DINORET demonstrated competitive\nperformance on retinal imaging tasks, with the block expanded model achieving\nthe highest scores on most datasets. Block expansion successfully mitigated\ncatastrophic forgetting. Our few-shot learning studies indicated that DINORET\nand BE DINORET outperform RETFound in terms of data-efficiency. This study\nhighlights the potential of adapting natural domain vision models to retinal\nimaging using self-supervised learning and block expansion. BE DINORET offers\nrobust performance without sacrificing previously acquired capabilities. Our\nfindings suggest that these methods could enable healthcare institutions to\ndevelop tailored vision models for their patient populations, enhancing global\nhealthcare inclusivity.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.0; I.2.10; J.3"
    ],
    "primary_category": "cs.CV",
    "comment": "J.Zoellin, C. Merk and M. Buob contributed equally as shared-first\n  authors. D. Cabrera DeBuc, M. D. Becker and G. M. Somfai contributed equally\n  as senior authors for this work",
    "pdf_url": "http://arxiv.org/pdf/2409.17332v1",
    "published_date": "2024-09-25 20:17:16 UTC",
    "updated_date": "2024-09-25 20:17:16 UTC"
  },
  {
    "arxiv_id": "2409.17315v1",
    "title": "KIPPS: Knowledge infusion in Privacy Preserving Synthetic Data Generation",
    "authors": [
      "Anantaa Kotal",
      "Anupam Joshi"
    ],
    "abstract": "The integration of privacy measures, including differential privacy\ntechniques, ensures a provable privacy guarantee for the synthetic data.\nHowever, challenges arise for Generative Deep Learning models when tasked with\ngenerating realistic data, especially in critical domains such as Cybersecurity\nand Healthcare. Generative Models optimized for continuous data struggle to\nmodel discrete and non-Gaussian features that have domain constraints.\nChallenges increase when the training datasets are limited and not diverse. In\nsuch cases, generative models create synthetic data that repeats sensitive\nfeatures, which is a privacy risk. Moreover, generative models face\ndifficulties comprehending attribute constraints in specialized domains. This\nleads to the generation of unrealistic data that impacts downstream accuracy.\nTo address these issues, this paper proposes a novel model, KIPPS, that infuses\nDomain and Regulatory Knowledge from Knowledge Graphs into Generative Deep\nLearning models for enhanced Privacy Preserving Synthetic data generation. The\nnovel framework augments the training of generative models with supplementary\ncontext about attribute values and enforces domain constraints during training.\nThis added guidance enhances the model's capacity to generate realistic and\ndomain-compliant synthetic data. The proposed model is evaluated on real-world\ndatasets, specifically in the domains of Cybersecurity and Healthcare, where\ndomain constraints and rules add to the complexity of the data. Our experiments\nevaluate the privacy resilience and downstream accuracy of the model against\nbenchmark methods, demonstrating its effectiveness in addressing the balance\nbetween privacy preservation and data accuracy in complex domains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17315v1",
    "published_date": "2024-09-25 19:50:03 UTC",
    "updated_date": "2024-09-25 19:50:03 UTC"
  },
  {
    "arxiv_id": "2409.17313v1",
    "title": "Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation",
    "authors": [
      "Zehao Wang",
      "Minye Wu",
      "Yixin Cao",
      "Yubo Ma",
      "Meiqi Chen",
      "Tinne Tuytelaars"
    ],
    "abstract": "This study presents a novel evaluation framework for the Vision-Language\nNavigation (VLN) task. It aims to diagnose current models for various\ninstruction categories at a finer-grained level. The framework is structured\naround the context-free grammar (CFG) of the task. The CFG serves as the basis\nfor the problem decomposition and the core premise of the instruction\ncategories design. We propose a semi-automatic method for CFG construction with\nthe help of Large-Language Models (LLMs). Then, we induct and generate data\nspanning five principal instruction categories (i.e. direction change, landmark\nrecognition, region recognition, vertical movement, and numerical\ncomprehension). Our analysis of different models reveals notable performance\ndiscrepancies and recurrent issues. The stagnation of numerical comprehension,\nheavy selective biases over directional concepts, and other interesting\nfindings contribute to the development of future language-guided navigation\nsystems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "EMNLP 2024 Findings; project page:\n  https://zehao-wang.github.io/navnuances",
    "pdf_url": "http://arxiv.org/pdf/2409.17313v1",
    "published_date": "2024-09-25 19:49:39 UTC",
    "updated_date": "2024-09-25 19:49:39 UTC"
  },
  {
    "arxiv_id": "2409.17311v1",
    "title": "A Hybrid Quantum-Classical AI-Based Detection Strategy for Generative Adversarial Network-Based Deepfake Attacks on an Autonomous Vehicle Traffic Sign Classification System",
    "authors": [
      "M Sabbir Salek",
      "Shaozhi Li",
      "Mashrur Chowdhury"
    ],
    "abstract": "The perception module in autonomous vehicles (AVs) relies heavily on deep\nlearning-based models to detect and identify various objects in their\nsurrounding environment. An AV traffic sign classification system is integral\nto this module, which helps AVs recognize roadway traffic signs. However,\nadversarial attacks, in which an attacker modifies or alters the image captured\nfor traffic sign recognition, could lead an AV to misrecognize the traffic\nsigns and cause hazardous consequences. Deepfake presents itself as a promising\ntechnology to be used for such adversarial attacks, in which a deepfake traffic\nsign would replace a real-world traffic sign image before the image is fed to\nthe AV traffic sign classification system. In this study, the authors present\nhow a generative adversarial network-based deepfake attack can be crafted to\nfool the AV traffic sign classification systems. The authors developed a\ndeepfake traffic sign image detection strategy leveraging hybrid\nquantum-classical neural networks (NNs). This hybrid approach utilizes\namplitude encoding to represent the features of an input traffic sign image\nusing quantum states, which substantially reduces the memory requirement\ncompared to its classical counterparts. The authors evaluated this hybrid\ndeepfake detection approach along with several baseline classical convolutional\nNNs on real-world and deepfake traffic sign images. The results indicate that\nthe hybrid quantum-classical NNs for deepfake detection could achieve similar\nor higher performance than the baseline classical convolutional NNs in most\ncases while requiring less than one-third of the memory required by the\nshallowest classical convolutional NN considered in this study.",
    "categories": [
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17311v1",
    "published_date": "2024-09-25 19:44:56 UTC",
    "updated_date": "2024-09-25 19:44:56 UTC"
  },
  {
    "arxiv_id": "2409.17300v1",
    "title": "Neural Network Plasticity and Loss Sharpness",
    "authors": [
      "Max Koster",
      "Jude Kukla"
    ],
    "abstract": "In recent years, continual learning, a prediction setting in which the\nproblem environment may evolve over time, has become an increasingly popular\nresearch field due to the framework's gearing towards complex, non-stationary\nobjectives. Learning such objectives requires plasticity, or the ability of a\nneural network to adapt its predictions to a different task. Recent findings\nindicate that plasticity loss on new tasks is highly related to loss landscape\nsharpness in non-stationary RL frameworks. We explore the usage of sharpness\nregularization techniques, which seek out smooth minima and have been touted\nfor their generalization capabilities in vanilla prediction settings, in\nefforts to combat plasticity loss. Our findings indicate that such techniques\nhave no significant effect on reducing plasticity loss.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17300v1",
    "published_date": "2024-09-25 19:20:09 UTC",
    "updated_date": "2024-09-25 19:20:09 UTC"
  },
  {
    "arxiv_id": "2409.17270v2",
    "title": "Proof of Thought : Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning",
    "authors": [
      "Debargha Ganguly",
      "Srinivasan Iyengar",
      "Vipin Chaudhary",
      "Shivkumar Kalyanaraman"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing,\nyet they struggle with inconsistent reasoning, particularly in novel domains\nand complex logical sequences. This research introduces Proof of Thought, a\nframework that enhances the reliability and transparency of LLM outputs. Our\napproach bridges LLM-generated ideas with formal logic verification, employing\na custom interpreter to convert LLM outputs into First Order Logic constructs\nfor theorem prover scrutiny. Central to our method is an intermediary\nJSON-based Domain-Specific Language, which by design balances precise logical\nstructures with intuitive human concepts. This hybrid representation enables\nboth rigorous validation and accessible human comprehension of LLM reasoning\nprocesses. Key contributions include a robust type system with sort management\nfor enhanced logical integrity, explicit representation of rules for clear\ndistinction between factual and inferential knowledge, and a flexible\narchitecture that allows for easy extension to various domain-specific\napplications. We demonstrate Proof of Thought's effectiveness through\nbenchmarking on StrategyQA and a novel multimodal reasoning task, showing\nimproved performance in open-ended scenarios. By providing verifiable and\ninterpretable results, our technique addresses critical needs for AI system\naccountability and sets a foundation for human-in-the-loop oversight in\nhigh-stakes domains.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.LO",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024) System 2 Reasoning At Scale Workshop",
    "pdf_url": "http://arxiv.org/pdf/2409.17270v2",
    "published_date": "2024-09-25 18:35:45 UTC",
    "updated_date": "2024-10-23 16:27:20 UTC"
  },
  {
    "arxiv_id": "2409.17267v2",
    "title": "Minimal Variance Model Aggregation: A principled, non-intrusive, and versatile integration of black box models",
    "authors": [
      "Théo Bourdais",
      "Houman Owhadi"
    ],
    "abstract": "Whether deterministic or stochastic, models can be viewed as functions\ndesigned to approximate a specific quantity of interest. We introduce Minimal\nEmpirical Variance Aggregation (MEVA), a data-driven framework that integrates\npredictions from various models, enhancing overall accuracy by leveraging the\nindividual strengths of each. This non-intrusive, model-agnostic approach\ntreats the contributing models as black boxes and accommodates outputs from\ndiverse methodologies, including machine learning algorithms and traditional\nnumerical solvers. We advocate for a point-wise linear aggregation process and\nconsider two methods for optimizing this aggregate: Minimal Error Aggregation\n(MEA), which minimizes the prediction error, and Minimal Variance Aggregation\n(MVA), which focuses on reducing variance. We prove a theorem showing that MVA\ncan be more robustly estimated from data than MEA, making MEVA superior to\nMinimal Empirical Error Aggregation (MEEA). Unlike MEEA, which interpolates\ntarget values directly, MEVA formulates aggregation as an error estimation\nproblem, which can be performed using any backbone learning paradigm. We\ndemonstrate the versatility and effectiveness of our framework across various\napplications, including data science and partial differential equations,\nillustrating its ability to significantly enhance both robustness and accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "stat.ML",
      "62A09, 62H22, 65S05, 90C35, 94C15, 46E22, 62J02, 15A83, 62D20, 68R10"
    ],
    "primary_category": "cs.LG",
    "comment": "The code in this paper is available for download at\n  https://github.com/TheoBourdais/ModelAggregation",
    "pdf_url": "http://arxiv.org/pdf/2409.17267v2",
    "published_date": "2024-09-25 18:33:21 UTC",
    "updated_date": "2025-03-03 18:41:55 UTC"
  },
  {
    "arxiv_id": "2409.17266v2",
    "title": "Empirical Asset Pricing with Large Language Model Agents",
    "authors": [
      "Junyan Cheng",
      "Peter Chin"
    ],
    "abstract": "In this study, we introduce a novel asset pricing model leveraging the Large\nLanguage Model (LLM) agents, which integrates qualitative discretionary\ninvestment evaluations from LLM agents with quantitative financial economic\nfactors manually curated, aiming to explain the excess asset returns. The\nexperimental results demonstrate that our methodology surpasses traditional\nmachine learning-based baselines in both portfolio optimization and asset\npricing errors. Notably, the Sharpe ratio for portfolio optimization and the\nmean magnitude of $|\\alpha|$ for anomaly portfolios experienced substantial\nenhancements of 10.6\\% and 10.0\\% respectively. Moreover, we performed\ncomprehensive ablation studies on our model and conducted a thorough analysis\nof the method to extract further insights into the proposed approach. Our\nresults show effective evidence of the feasibility of applying LLMs in\nempirical asset pricing.",
    "categories": [
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.AI",
    "comment": "ICLR 2025 Workshop on Advances in Financial AI",
    "pdf_url": "http://arxiv.org/pdf/2409.17266v2",
    "published_date": "2024-09-25 18:27:35 UTC",
    "updated_date": "2025-03-28 01:02:11 UTC"
  },
  {
    "arxiv_id": "2409.17263v1",
    "title": "Collaborative Comic Generation: Integrating Visual Narrative Theories with AI Models for Enhanced Creativity",
    "authors": [
      "Yi-Chun Chen",
      "Arnav Jhala"
    ],
    "abstract": "This study presents a theory-inspired visual narrative generative system that\nintegrates conceptual principles-comic authoring idioms-with generative and\nlanguage models to enhance the comic creation process. Our system combines\nhuman creativity with AI models to support parts of the generative process,\nproviding a collaborative platform for creating comic content. These\ncomic-authoring idioms, derived from prior human-created image sequences, serve\nas guidelines for crafting and refining storytelling. The system translates\nthese principles into system layers that facilitate comic creation through\nsequential decision-making, addressing narrative elements such as panel\ncomposition, story tension changes, and panel transitions. Key contributions\ninclude integrating machine learning models into the human-AI cooperative comic\ngeneration process, deploying abstract narrative theories into AI-driven comic\ncreation, and a customizable tool for narrative-driven image sequences. This\napproach improves narrative elements in generated image sequences and engages\nhuman creativity in an AI-generative process of comics. We open-source the code\nat https://github.com/RimiChen/Collaborative_Comic_Generation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been accepted for oral presentation at CREAI2024,\n  ECAI, 2024. However, the author's attendance is currently uncertain due to\n  visa issues",
    "pdf_url": "http://arxiv.org/pdf/2409.17263v1",
    "published_date": "2024-09-25 18:21:01 UTC",
    "updated_date": "2024-09-25 18:21:01 UTC"
  },
  {
    "arxiv_id": "2409.17228v1",
    "title": "Disk2Planet: A Robust and Automated Machine Learning Tool for Parameter Inference in Disk-Planet Systems",
    "authors": [
      "Shunyuan Mao",
      "Ruobing Dong",
      "Kwang Moo Yi",
      "Lu Lu",
      "Sifan Wang",
      "Paris Perdikaris"
    ],
    "abstract": "We introduce Disk2Planet, a machine learning-based tool to infer key\nparameters in disk-planet systems from observed protoplanetary disk structures.\nDisk2Planet takes as input the disk structures in the form of two-dimensional\ndensity and velocity maps, and outputs disk and planet properties, that is, the\nShakura--Sunyaev viscosity, the disk aspect ratio, the planet--star mass ratio,\nand the planet's radius and azimuth. We integrate the Covariance Matrix\nAdaptation Evolution Strategy (CMA--ES), an evolutionary algorithm tailored for\ncomplex optimization problems, and the Protoplanetary Disk Operator Network\n(PPDONet), a neural network designed to predict solutions of disk--planet\ninteractions. Our tool is fully automated and can retrieve parameters in one\nsystem in three minutes on an Nvidia A100 graphics processing unit. We\nempirically demonstrate that our tool achieves percent-level or higher\naccuracy, and is able to handle missing data and unknown levels of noise.",
    "categories": [
      "astro-ph.EP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "astro-ph.EP",
    "comment": "Accepted to ApJ",
    "pdf_url": "http://arxiv.org/pdf/2409.17228v1",
    "published_date": "2024-09-25 18:00:01 UTC",
    "updated_date": "2024-09-25 18:00:01 UTC"
  },
  {
    "arxiv_id": "2409.17144v1",
    "title": "Differential Privacy Regularization: Protecting Training Data Through Loss Function Regularization",
    "authors": [
      "Francisco Aguilera-Martínez",
      "Fernando Berzal"
    ],
    "abstract": "Training machine learning models based on neural networks requires large\ndatasets, which may contain sensitive information. The models, however, should\nnot expose private information from these datasets. Differentially private SGD\n[DP-SGD] requires the modification of the standard stochastic gradient descent\n[SGD] algorithm for training new models. In this short paper, a novel\nregularization strategy is proposed to achieve the same goal in a more\nefficient manner.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17144v1",
    "published_date": "2024-09-25 17:59:32 UTC",
    "updated_date": "2024-09-25 17:59:32 UTC"
  },
  {
    "arxiv_id": "2409.17143v1",
    "title": "Attention Prompting on Image for Large Vision-Language Models",
    "authors": [
      "Runpeng Yu",
      "Weihao Yu",
      "Xinchao Wang"
    ],
    "abstract": "Compared with Large Language Models (LLMs), Large Vision-Language Models\n(LVLMs) can also accept images as input, thus showcasing more interesting\nemergent capabilities and demonstrating impressive performance on various\nvision-language tasks. Motivated by text prompting in LLMs, visual prompting\nhas been explored to enhance LVLMs' capabilities of perceiving visual\ninformation. However, previous visual prompting techniques solely process\nvisual inputs without considering text queries, limiting the models' ability to\nfollow text instructions to complete tasks. To fill this gap, in this work, we\npropose a new prompting technique named Attention Prompting on Image, which\njust simply overlays a text-query-guided attention heatmap on the original\ninput image and effectively enhances LVLM on various tasks. Specifically, we\ngenerate an attention heatmap for the input image dependent on the text query\nwith an auxiliary model like CLIP. Then the heatmap simply multiplies the pixel\nvalues of the original image to obtain the actual input image for the LVLM.\nExtensive experiments on various vison-language benchmarks verify the\neffectiveness of our technique. For example, Attention Prompting on Image\nimproves LLaVA-1.5 by 3.8% and 2.9% on MM-Vet and LLaVA-Wild benchmarks,\nrespectively.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Website, see https://yu-rp.github.io/api-prompting",
    "pdf_url": "http://arxiv.org/pdf/2409.17143v1",
    "published_date": "2024-09-25 17:59:13 UTC",
    "updated_date": "2024-09-25 17:59:13 UTC"
  },
  {
    "arxiv_id": "2409.17216v1",
    "title": "Data-Centric AI Governance: Addressing the Limitations of Model-Focused Policies",
    "authors": [
      "Ritwik Gupta",
      "Leah Walker",
      "Rodolfo Corona",
      "Stephanie Fu",
      "Suzanne Petryk",
      "Janet Napolitano",
      "Trevor Darrell",
      "Andrew W. Reddie"
    ],
    "abstract": "Current regulations on powerful AI capabilities are narrowly focused on\n\"foundation\" or \"frontier\" models. However, these terms are vague and\ninconsistently defined, leading to an unstable foundation for governance\nefforts. Critically, policy debates often fail to consider the data used with\nthese models, despite the clear link between data and model performance. Even\n(relatively) \"small\" models that fall outside the typical definitions of\nfoundation and frontier models can achieve equivalent outcomes when exposed to\nsufficiently specific datasets. In this work, we illustrate the importance of\nconsidering dataset size and content as essential factors in assessing the\nrisks posed by models both today and in the future. More broadly, we emphasize\nthe risk posed by over-regulating reactively and provide a path towards\ncareful, quantitative evaluation of capabilities that can lead to a simplified\nregulatory environment.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17216v1",
    "published_date": "2024-09-25 17:59:01 UTC",
    "updated_date": "2024-09-25 17:59:01 UTC"
  },
  {
    "arxiv_id": "2409.17141v1",
    "title": "FineZip : Pushing the Limits of Large Language Models for Practical Lossless Text Compression",
    "authors": [
      "Fazal Mittu",
      "Yihuan Bu",
      "Akshat Gupta",
      "Ashok Devireddy",
      "Alp Eren Ozdarendeli",
      "Anant Singh",
      "Gopala Anumanchipalli"
    ],
    "abstract": "While the language modeling objective has been shown to be deeply connected\nwith compression, it is surprising that modern LLMs are not employed in\npractical text compression systems. In this paper, we provide an in-depth\nanalysis of neural network and transformer-based compression techniques to\nanswer this question. We compare traditional text compression systems with\nneural network and LLM-based text compression methods. Although LLM-based\nsystems significantly outperform conventional compression methods, they are\nhighly impractical. Specifically, LLMZip, a recent text compression system\nusing Llama3-8B requires 9.5 days to compress just 10 MB of text, although with\nhuge improvements in compression ratios. To overcome this, we present FineZip -\na novel LLM-based text compression system that combines ideas of online\nmemorization and dynamic context to reduce the compression time immensely.\nFineZip can compress the above corpus in approximately 4 hours compared to 9.5\ndays, a 54 times improvement over LLMZip and comparable performance. FineZip\noutperforms traditional algorithmic compression methods with a large margin,\nimproving compression ratios by approximately 50\\%. With this work, we take the\nfirst step towards making lossless text compression with LLMs a reality. While\nFineZip presents a significant step in that direction, LLMs are still not a\nviable solution for large-scale text compression. We hope our work paves the\nway for future research and innovation to solve this problem.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17141v1",
    "published_date": "2024-09-25 17:58:35 UTC",
    "updated_date": "2024-09-25 17:58:35 UTC"
  },
  {
    "arxiv_id": "2409.17140v2",
    "title": "AXIS: Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents",
    "authors": [
      "Junting Lu",
      "Zhiyang Zhang",
      "Fangkai Yang",
      "Jue Zhang",
      "Lu Wang",
      "Chao Du",
      "Qingwei Lin",
      "Saravan Rajmohan",
      "Dongmei Zhang",
      "Qi Zhang"
    ],
    "abstract": "Multimodal large language models (MLLMs) have enabled LLM-based agents to\ndirectly interact with application user interfaces (UIs), enhancing agents'\nperformance in complex tasks. However, these agents often suffer from high\nlatency and low reliability due to the extensive sequential UI interactions. To\naddress this issue, we propose AXIS, a novel LLM-based agents framework that\nprioritize actions through application programming interfaces (APIs) over UI\nactions. This framework also facilitates the creation and expansion of APIs\nthrough automated exploration of applications. Our experiments on Microsoft\nWord demonstrate that AXIS reduces task completion time by 65%-70% and\ncognitive workload by 38%-53%, while maintaining accuracy of 97%-98% compared\nto humans. Our work contributes to a new human-agent-computer interaction\n(HACI) framework and explores a fresh UI design principle for application\nproviders to turn applications into agents in the era of LLMs, paving the way\ntowards an agent-centric operating system (Agent OS).",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17140v2",
    "published_date": "2024-09-25 17:58:08 UTC",
    "updated_date": "2025-05-19 16:12:40 UTC"
  },
  {
    "arxiv_id": "2409.17126v1",
    "title": "Blox-Net: Generative Design-for-Robot-Assembly Using VLM Supervision, Physics Simulation, and a Robot with Reset",
    "authors": [
      "Andrew Goldberg",
      "Kavish Kondap",
      "Tianshuang Qiu",
      "Zehan Ma",
      "Letian Fu",
      "Justin Kerr",
      "Huang Huang",
      "Kaiyuan Chen",
      "Kuan Fang",
      "Ken Goldberg"
    ],
    "abstract": "Generative AI systems have shown impressive capabilities in creating text,\ncode, and images. Inspired by the rich history of research in industrial\n''Design for Assembly'', we introduce a novel problem: Generative\nDesign-for-Robot-Assembly (GDfRA). The task is to generate an assembly based on\na natural language prompt (e.g., ''giraffe'') and an image of available\nphysical components, such as 3D-printed blocks. The output is an assembly, a\nspatial arrangement of these components, and instructions for a robot to build\nthis assembly. The output must 1) resemble the requested object and 2) be\nreliably assembled by a 6 DoF robot arm with a suction gripper. We then present\nBlox-Net, a GDfRA system that combines generative vision language models with\nwell-established methods in computer vision, simulation, perturbation analysis,\nmotion planning, and physical robot experimentation to solve a class of GDfRA\nproblems with minimal human supervision. Blox-Net achieved a Top-1 accuracy of\n63.5% in the ''recognizability'' of its designed assemblies (eg, resembling\ngiraffe as judged by a VLM). These designs, after automated perturbation\nredesign, were reliably assembled by a robot, achieving near-perfect success\nacross 10 consecutive assembly iterations with human intervention only during\nreset prior to assembly. Surprisingly, this entire design process from textual\nword (''giraffe'') to reliable physical assembly is performed with zero human\nintervention.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 7 Figures",
    "pdf_url": "http://arxiv.org/pdf/2409.17126v1",
    "published_date": "2024-09-25 17:42:20 UTC",
    "updated_date": "2024-09-25 17:42:20 UTC"
  },
  {
    "arxiv_id": "2409.17125v1",
    "title": "On-orbit Servicing for Spacecraft Collision Avoidance With Autonomous Decision Making",
    "authors": [
      "Susmitha Patnala",
      "Adam Abdin"
    ],
    "abstract": "This study develops an AI-based implementation of autonomous On-Orbit\nServicing (OOS) mission to assist with spacecraft collision avoidance maneuvers\n(CAMs). We propose an autonomous `servicer' trained with Reinforcement Learning\n(RL) to autonomously detect potential collisions between a target satellite and\nspace debris, rendezvous and dock with endangered satellites, and execute\noptimal CAM. The RL model integrates collision risk estimates, satellite\nspecifications, and debris data to generate an optimal maneuver matrix for OOS\nrendezvous and collision prevention. We employ the Cross-Entropy algorithm to\nfind optimal decision policies efficiently. Initial results demonstrate the\nfeasibility of autonomous robotic OOS for collision avoidance services,\nfocusing on one servicer spacecraft to one endangered satellite scenario.\nHowever, merging spacecraft rendezvous and optimal CAM presents significant\ncomplexities. We discuss design challenges and critical parameters for the\nsuccessful implementation of the framework presented through a case study.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "The first joint European Space Agency SPAICE Conference / IAA\n  Conference on AI in and for Space",
    "pdf_url": "http://arxiv.org/pdf/2409.17125v1",
    "published_date": "2024-09-25 17:40:37 UTC",
    "updated_date": "2024-09-25 17:40:37 UTC"
  },
  {
    "arxiv_id": "2409.17213v6",
    "title": "Plurals: A System for Guiding LLMs Via Simulated Social Ensembles",
    "authors": [
      "Joshua Ashkinaze",
      "Emily Fry",
      "Narendra Edara",
      "Eric Gilbert",
      "Ceren Budak"
    ],
    "abstract": "Recent debates raised concerns that language models may favor certain\nviewpoints. But what if the solution is not to aim for a 'view from nowhere'\nbut rather to leverage different viewpoints? We introduce Plurals, a system and\nPython library for pluralistic AI deliberation. Plurals consists of Agents\n(LLMs, optionally with personas) which deliberate within customizable\nStructures, with Moderators overseeing deliberation. Plurals is a generator of\nsimulated social ensembles. Plurals integrates with government datasets to\ncreate nationally representative personas, includes deliberation templates\ninspired by deliberative democracy, and allows users to customize both\ninformation-sharing structures and deliberation behavior within Structures. Six\ncase studies demonstrate fidelity to theoretical constructs and efficacy. Three\nrandomized experiments show simulated focus groups produced output resonant\nwith an online sample of the relevant audiences (chosen over zero-shot\ngeneration in 75% of trials). Plurals is both a paradigm and a concrete system\nfor pluralistic AI. The Plurals library is available at\nhttps://github.com/josh-ashkinaze/plurals and will be continually updated.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "CHI 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.17213v6",
    "published_date": "2024-09-25 17:38:39 UTC",
    "updated_date": "2025-03-22 20:30:18 UTC"
  },
  {
    "arxiv_id": "2409.17115v2",
    "title": "Programming Every Example: Lifting Pre-training Data Quality Like Experts at Scale",
    "authors": [
      "Fan Zhou",
      "Zengzhi Wang",
      "Qian Liu",
      "Junlong Li",
      "Pengfei Liu"
    ],
    "abstract": "Large language model pre-training has traditionally relied on human experts\nto craft heuristics for improving the corpora quality, resulting in numerous\nrules developed to date. However, these rules lack the flexibility to address\nthe unique characteristics of individual example effectively. Meanwhile,\napplying tailored rules to every example is impractical for human experts. In\nthis paper, we demonstrate that even small language models, with as few as 0.3B\nparameters, can exhibit substantial data refining capabilities comparable to\nthose of human experts. We introduce Programming Every Example (ProX), a novel\nframework that treats data refinement as a programming task, enabling models to\nrefine corpora by generating and executing fine-grained operations, such as\nstring normalization, for each individual example at scale. Experimental\nresults show that models pre-trained on ProX-curated data outperform either\noriginal data or data filtered by other selection methods by more than 2%\nacross various downstream benchmarks. Its effectiveness spans various model\nsizes and pre-training corpora, including C4, RedPajama-V2, FineWeb,\nFineWeb-Edu, and DCLM. Furthermore, ProX exhibits significant potential in\ndomain-specific continual pre-training: without domain specific design, models\ntrained on OpenWebMath refined by ProX outperform human-crafted rule-based\nmethods, improving average accuracy by 7.6% over Mistral-7B, with 14.6% for\nLlama-2-7B and 20.3% for CodeLlama-7B, all within 10B tokens to be comparable\nto models like Llemma-7B trained on 200B tokens. Further analysis highlights\nthat ProX significantly saves training FLOPs, offering a promising path for\nefficient LLM pre-training. We are open-sourcing ProX with >500B corpus,\nmodels, and sharing all training and implementation details for reproducible\nresearch and future innovation. Code: https://github.com/GAIR-NLP/ProX",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "47 pages, 13 figures, 34 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.17115v2",
    "published_date": "2024-09-25 17:28:13 UTC",
    "updated_date": "2025-02-14 16:44:08 UTC"
  },
  {
    "arxiv_id": "2409.17109v1",
    "title": "Unveiling Ontological Commitment in Multi-Modal Foundation Models",
    "authors": [
      "Mert Keser",
      "Gesina Schwalbe",
      "Niki Amini-Naieni",
      "Matthias Rottmann",
      "Alois Knoll"
    ],
    "abstract": "Ontological commitment, i.e., used concepts, relations, and assumptions, are\na corner stone of qualitative reasoning (QR) models. The state-of-the-art for\nprocessing raw inputs, though, are deep neural networks (DNNs), nowadays often\nbased off from multimodal foundation models. These automatically learn rich\nrepresentations of concepts and respective reasoning. Unfortunately, the\nlearned qualitative knowledge is opaque, preventing easy inspection,\nvalidation, or adaptation against available QR models. So far, it is possible\nto associate pre-defined concepts with latent representations of DNNs, but\nextractable relations are mostly limited to semantic similarity. As a next step\ntowards QR for validation and verification of DNNs: Concretely, we propose a\nmethod that extracts the learned superclass hierarchy from a multimodal DNN for\na given set of leaf concepts. Under the hood we (1) obtain leaf concept\nembeddings using the DNN's textual input modality; (2) apply hierarchical\nclustering to them, using that DNNs encode semantic similarities via vector\ndistances; and (3) label the such-obtained parent concepts using search in\navailable ontologies from QR. An initial evaluation study shows that meaningful\nontological class hierarchies can be extracted from state-of-the-art foundation\nmodels. Furthermore, we demonstrate how to validate and verify a DNN's learned\nrepresentations against given ontologies. Lastly, we discuss potential future\napplications in the context of QR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Qualitative Reasoning Workshop 2024 (QR2024) colocated with ECAI2024,\n  camera-ready submission; first two authors contributed equally; 10 pages, 4\n  figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.17109v1",
    "published_date": "2024-09-25 17:24:27 UTC",
    "updated_date": "2024-09-25 17:24:27 UTC"
  },
  {
    "arxiv_id": "2409.17092v1",
    "title": "Accumulator-Aware Post-Training Quantization",
    "authors": [
      "Ian Colbert",
      "Fabian Grob",
      "Giuseppe Franco",
      "Jinjie Zhang",
      "Rayan Saab"
    ],
    "abstract": "Several recent studies have investigated low-precision accumulation,\nreporting improvements in throughput, power, and area across various platforms.\nHowever, the accompanying proposals have only considered the quantization-aware\ntraining (QAT) paradigm, in which models are fine-tuned or trained from scratch\nwith quantization in the loop. As models continue to grow in size, QAT\ntechniques become increasingly more expensive, which has motivated the recent\nsurge in post-training quantization (PTQ) research. To the best of our\nknowledge, ours marks the first formal study of accumulator-aware quantization\nin the PTQ setting. To bridge this gap, we introduce AXE, a practical framework\nof accumulator-aware extensions designed to endow overflow avoidance guarantees\nto existing layer-wise PTQ algorithms. We theoretically motivate AXE and\ndemonstrate its flexibility by implementing it on top of two state-of-the-art\nPTQ algorithms: GPFQ and OPTQ. We further generalize AXE to support multi-stage\naccumulation for the first time, opening the door for full datapath\noptimization and scaling to large language models (LLMs). We evaluate AXE\nacross image classification and language generation models, and observe\nsignificant improvements in the trade-off between accumulator bit width and\nmodel accuracy over baseline methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17092v1",
    "published_date": "2024-09-25 16:58:35 UTC",
    "updated_date": "2024-09-25 16:58:35 UTC"
  },
  {
    "arxiv_id": "2409.17091v2",
    "title": "Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification",
    "authors": [
      "Xinrui Zhou",
      "Yuhao Huang",
      "Haoran Dou",
      "Shijing Chen",
      "Ao Chang",
      "Jia Liu",
      "Weiran Long",
      "Jian Zheng",
      "Erjiao Xu",
      "Jie Ren",
      "Ruobing Huang",
      "Jun Cheng",
      "Wufeng Xue",
      "Dong Ni"
    ],
    "abstract": "In the medical field, the limited availability of large-scale datasets and\nlabor-intensive annotation processes hinder the performance of deep models.\nDiffusion-based generative augmentation approaches present a promising solution\nto this issue, having been proven effective in advancing downstream medical\nrecognition tasks. Nevertheless, existing works lack sufficient semantic and\nsequential steerability for challenging video/3D sequence generation, and\nneglect quality control of noisy synthesized samples, resulting in unreliable\nsynthetic databases and severely limiting the performance of downstream tasks.\nIn this work, we present Ctrl-GenAug, a novel and general generative\naugmentation framework that enables highly semantic- and sequential-customized\nsequence synthesis and suppresses incorrectly synthesized samples, to aid\nmedical sequence classification. Specifically, we first design a multimodal\nconditions-guided sequence generator for controllably synthesizing\ndiagnosis-promotive samples. A sequential augmentation module is integrated to\nenhance the temporal/stereoscopic coherence of generated samples. Then, we\npropose a noisy synthetic data filter to suppress unreliable cases at semantic\nand sequential levels. Extensive experiments on 3 medical datasets, using 11\nnetworks trained on 3 paradigms, comprehensively analyze the effectiveness and\ngenerality of Ctrl-GenAug, particularly in underrepresented high-risk\npopulations and out-domain conditions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 9 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.17091v2",
    "published_date": "2024-09-25 16:58:19 UTC",
    "updated_date": "2025-04-13 00:49:25 UTC"
  },
  {
    "arxiv_id": "2409.17087v1",
    "title": "SEN12-WATER: A New Dataset for Hydrological Applications and its Benchmarking",
    "authors": [
      "Luigi Russo",
      "Francesco Mauro",
      "Alessandro Sebastianelli",
      "Paolo Gamba",
      "Silvia Liberata Ullo"
    ],
    "abstract": "Climate change and increasing droughts pose significant challenges to water\nresource management around the world. These problems lead to severe water\nshortages that threaten ecosystems, agriculture, and human communities. To\nadvance the fight against these challenges, we present a new dataset,\nSEN12-WATER, along with a benchmark using a novel end-to-end Deep Learning (DL)\nframework for proactive drought-related analysis. The dataset, identified as a\nspatiotemporal datacube, integrates SAR polarization, elevation, slope, and\nmultispectral optical bands. Our DL framework enables the analysis and\nestimation of water losses over time in reservoirs of interest, revealing\nsignificant insights into water dynamics for drought analysis by examining\ntemporal changes in physical quantities such as water volume. Our methodology\ntakes advantage of the multitemporal and multimodal characteristics of the\nproposed dataset, enabling robust generalization and advancing understanding of\ndrought, contributing to climate change resilience and sustainable water\nresource management. The proposed framework involves, among the several\ncomponents, speckle noise removal from SAR data, a water body segmentation\nthrough a U-Net architecture, the time series analysis, and the predictive\ncapability of a Time-Distributed-Convolutional Neural Network (TD-CNN). Results\nare validated through ground truth data acquired on-ground via dedicated\nsensors and (tailored) metrics, such as Precision, Recall, Intersection over\nUnion, Mean Squared Error, Structural Similarity Index Measure and Peak\nSignal-to-Noise Ratio.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "Submitted to IEEE Transactions on Geoscience and Remote Sensing",
    "pdf_url": "http://arxiv.org/pdf/2409.17087v1",
    "published_date": "2024-09-25 16:50:59 UTC",
    "updated_date": "2024-09-25 16:50:59 UTC"
  },
  {
    "arxiv_id": "2409.17069v1",
    "title": "The Effect of Perceptual Metrics on Music Representation Learning for Genre Classification",
    "authors": [
      "Tashi Namgyal",
      "Alexander Hepburn",
      "Raul Santos-Rodriguez",
      "Valero Laparra",
      "Jesus Malo"
    ],
    "abstract": "The subjective quality of natural signals can be approximated with objective\nperceptual metrics. Designed to approximate the perceptual behaviour of human\nobservers, perceptual metrics often reflect structures found in natural signals\nand neurological pathways. Models trained with perceptual metrics as loss\nfunctions can capture perceptually meaningful features from the structures held\nwithin these metrics. We demonstrate that using features extracted from\nautoencoders trained with perceptual losses can improve performance on music\nunderstanding tasks, i.e. genre classification, over using these metrics\ndirectly as distances when learning a classifier. This result suggests improved\ngeneralisation to novel signals when using perceptual metrics as loss functions\nfor representation learning.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "arXiv admin note: text overlap with arXiv:2312.03455",
    "pdf_url": "http://arxiv.org/pdf/2409.17069v1",
    "published_date": "2024-09-25 16:29:21 UTC",
    "updated_date": "2024-09-25 16:29:21 UTC"
  },
  {
    "arxiv_id": "2409.17066v2",
    "title": "VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models",
    "authors": [
      "Yifei Liu",
      "Jicheng Wen",
      "Yang Wang",
      "Shengyu Ye",
      "Li Lyna Zhang",
      "Ting Cao",
      "Cheng Li",
      "Mao Yang"
    ],
    "abstract": "Scaling model size significantly challenges the deployment and inference of\nLarge Language Models (LLMs). Due to the redundancy in LLM weights, recent\nresearch has focused on pushing weight-only quantization to extremely low-bit\n(even down to 2 bits). It reduces memory requirements, optimizes storage costs,\nand decreases memory bandwidth needs during inference. However, due to\nnumerical representation limitations, traditional scalar-based weight\nquantization struggles to achieve such extreme low-bit. Recent research on\nVector Quantization (VQ) for LLMs has demonstrated the potential for extremely\nlow-bit model quantization by compressing vectors into indices using lookup\ntables.\n  In this paper, we introduce Vector Post-Training Quantization (VPTQ) for\nextremely low-bit quantization of LLMs. We use Second-Order Optimization to\nformulate the LLM VQ problem and guide our quantization algorithm design by\nsolving the optimization. We further refine the weights using\nChannel-Independent Second-Order Optimization for a granular VQ. In addition,\nby decomposing the optimization problem, we propose a brief and effective\ncodebook initialization algorithm. We also extend VPTQ to support residual and\noutlier quantization, which enhances model accuracy and further compresses the\nmodel. Our experimental results show that VPTQ reduces model quantization\nperplexity by $0.01$-$0.34$ on LLaMA-2, $0.38$-$0.68$ on Mistral-7B,\n$4.41$-$7.34$ on LLaMA-3 over SOTA at 2-bit, with an average accuracy\nimprovement of $0.79$-$1.5\\%$ on LLaMA-2, $1\\%$ on Mistral-7B, $11$-$22\\%$ on\nLLaMA-3 on QA tasks on average. We only utilize $10.4$-$18.6\\%$ of the\nquantization algorithm execution time, resulting in a $1.6$-$1.8\\times$\nincrease in inference throughput compared to SOTA.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "EMNLP 2024, Main, Poster",
    "pdf_url": "http://arxiv.org/pdf/2409.17066v2",
    "published_date": "2024-09-25 16:25:45 UTC",
    "updated_date": "2024-10-22 11:47:04 UTC"
  },
  {
    "arxiv_id": "2409.17063v1",
    "title": "Benchmarking Domain Generalization Algorithms in Computational Pathology",
    "authors": [
      "Neda Zamanitajeddin",
      "Mostafa Jahanifar",
      "Kesi Xu",
      "Fouzia Siraj",
      "Nasir Rajpoot"
    ],
    "abstract": "Deep learning models have shown immense promise in computational pathology\n(CPath) tasks, but their performance often suffers when applied to unseen data\ndue to domain shifts. Addressing this requires domain generalization (DG)\nalgorithms. However, a systematic evaluation of DG algorithms in the CPath\ncontext is lacking. This study aims to benchmark the effectiveness of 30 DG\nalgorithms on 3 CPath tasks of varying difficulty through 7,560\ncross-validation runs. We evaluate these algorithms using a unified and robust\nplatform, incorporating modality-specific techniques and recent advances like\npretrained foundation models. Our extensive cross-validation experiments\nprovide insights into the relative performance of various DG strategies. We\nobserve that self-supervised learning and stain augmentation consistently\noutperform other methods, highlighting the potential of pretrained models and\ndata augmentation. Furthermore, we introduce a new pan-cancer tumor detection\ndataset (HISTOPANTUM) as a benchmark for future research. This study offers\nvaluable guidance to researchers in selecting appropriate DG approaches for\nCPath tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17063v1",
    "published_date": "2024-09-25 16:21:43 UTC",
    "updated_date": "2024-09-25 16:21:43 UTC"
  },
  {
    "arxiv_id": "2409.17208v2",
    "title": "First Place Solution to the ECCV 2024 BRAVO Challenge: Evaluating Robustness of Vision Foundation Models for Semantic Segmentation",
    "authors": [
      "Tommie Kerssies",
      "Daan de Geus",
      "Gijs Dubbelman"
    ],
    "abstract": "In this report, we present the first place solution to the ECCV 2024 BRAVO\nChallenge, where a model is trained on Cityscapes and its robustness is\nevaluated on several out-of-distribution datasets. Our solution leverages the\npowerful representations learned by vision foundation models, by attaching a\nsimple segmentation decoder to DINOv2 and fine-tuning the entire model. This\napproach outperforms more complex existing approaches, and achieves first place\nin the challenge. Our code is publicly available at\nhttps://github.com/tue-mps/benchmark-vfm-ss.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "v2 fixes ECE and FPR@95, among other small changes. arXiv admin note:\n  substantial text overlap with arXiv:2409.15107",
    "pdf_url": "http://arxiv.org/pdf/2409.17208v2",
    "published_date": "2024-09-25 16:15:06 UTC",
    "updated_date": "2024-10-08 10:09:14 UTC"
  },
  {
    "arxiv_id": "2409.17055v2",
    "title": "DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data",
    "authors": [
      "Lucas Robinet",
      "Ahmad Berjaoui",
      "Ziad Kheil",
      "Elizabeth Cohen-Jonathan Moyal"
    ],
    "abstract": "Real-life medical data is often multimodal and incomplete, fueling the\ngrowing need for advanced deep learning models capable of integrating them\nefficiently. The use of diverse modalities, including histopathology slides,\nMRI, and genetic data, offers unprecedented opportunities to improve prognosis\nprediction and to unveil new treatment pathways. Contrastive learning, widely\nused for deriving representations from paired data in multimodal tasks, assumes\nthat different views contain the same task-relevant information and leverages\nonly shared information. This assumption becomes restrictive when handling\nmedical data since each modality also harbors specific knowledge relevant to\ndownstream tasks. We introduce DRIM, a new multimodal method for capturing\nthese shared and unique representations, despite data sparsity. More\nspecifically, given a set of modalities, we aim to encode a representation for\neach one that can be divided into two components: one encapsulating\npatient-related information common across modalities and the other,\nencapsulating modality-specific details. This is achieved by increasing the\nshared information among different patient modalities while minimizing the\noverlap between shared and unique components within each modality. Our method\noutperforms state-of-the-art algorithms on glioma patients survival prediction\ntasks, while being robust to missing modalities. To promote reproducibility,\nthe code is made publicly available at https://github.com/Lucas-rbnt/DRIM",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17055v2",
    "published_date": "2024-09-25 16:13:57 UTC",
    "updated_date": "2024-10-01 15:47:14 UTC"
  },
  {
    "arxiv_id": "2409.17054v1",
    "title": "Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia",
    "authors": [
      "Azmul Asmar Irfan",
      "Nur Ahmad Khatim",
      "Mansur M. Arief"
    ],
    "abstract": "One of the key issues contributing to inefficiency in Puskesmas is the\ntime-consuming nature of doctor-patient interactions. Doctors need to conduct\nthorough consultations, which include diagnosing the patient's condition,\nproviding treatment advice, and transcribing detailed notes into medical\nrecords. In regions with diverse linguistic backgrounds, doctors often have to\nask clarifying questions, further prolonging the process. While diagnosing is\nessential, transcription and summarization can often be automated using AI to\nimprove time efficiency and help doctors enhance care quality and enable early\ndiagnosis and intervention. This paper proposes a solution using a localized\nlarge language model (LLM) to transcribe, translate, and summarize\ndoctor-patient conversations. We utilize the Whisper model for transcription\nand GPT-3 to summarize them into the ePuskemas medical records format. This\nsystem is implemented as an add-on to an existing web browser extension,\nallowing doctors to fill out patient forms while talking. By leveraging this\nsolution for real-time transcription, translation, and summarization, doctors\ncan improve the turnaround time for patient care while enhancing the quality of\nrecords, which become more detailed and insightful for future visits. This\ninnovation addresses challenges like overcrowded facilities and the\nadministrative burden on healthcare providers in Indonesia. We believe this\nsolution will help doctors save time, provide better care, and produce more\naccurate medical records, representing a significant step toward modernizing\nhealthcare and ensuring patients receive timely, high-quality care, even in\nresource-constrained settings.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17054v1",
    "published_date": "2024-09-25 16:13:42 UTC",
    "updated_date": "2024-09-25 16:13:42 UTC"
  },
  {
    "arxiv_id": "2409.17049v1",
    "title": "ControlCity: A Multimodal Diffusion Model Based Approach for Accurate Geospatial Data Generation and Urban Morphology Analysis",
    "authors": [
      "Fangshuo Zhou",
      "Huaxia Li",
      "Rui Hu",
      "Sensen Wu",
      "Hailin Feng",
      "Zhenhong Du",
      "Liuchang Xu"
    ],
    "abstract": "Volunteer Geographic Information (VGI), with its rich variety, large volume,\nrapid updates, and diverse sources, has become a critical source of geospatial\ndata. However, VGI data from platforms like OSM exhibit significant quality\nheterogeneity across different data types, particularly with urban building\ndata. To address this, we propose a multi-source geographic data transformation\nsolution, utilizing accessible and complete VGI data to assist in generating\nurban building footprint data. We also employ a multimodal data generation\nframework to improve accuracy. First, we introduce a pipeline for constructing\nan 'image-text-metadata-building footprint' dataset, primarily based on road\nnetwork data and supplemented by other multimodal data. We then present\nControlCity, a geographic data transformation method based on a multimodal\ndiffusion model. This method first uses a pre-trained text-to-image model to\nalign text, metadata, and building footprint data. An improved ControlNet\nfurther integrates road network and land-use imagery, producing refined\nbuilding footprint data. Experiments across 22 global cities demonstrate that\nControlCity successfully simulates real urban building patterns, achieving\nstate-of-the-art performance. Specifically, our method achieves an average FID\nscore of 50.94, reducing error by 71.01% compared to leading methods, and a\nMIoU score of 0.36, an improvement of 38.46%. Additionally, our model excels in\ntasks like urban morphology transfer, zero-shot city generation, and spatial\ndata completeness assessment. In the zero-shot city task, our method accurately\npredicts and generates similar urban structures, demonstrating strong\ngeneralization. This study confirms the effectiveness of our approach in\ngenerating urban building footprint data and capturing complex city\ncharacteristics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.17049v1",
    "published_date": "2024-09-25 16:03:33 UTC",
    "updated_date": "2024-09-25 16:03:33 UTC"
  },
  {
    "arxiv_id": "2409.17045v1",
    "title": "GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design",
    "authors": [
      "Phillip Mueller",
      "Sebastian Mueller",
      "Lars Mikelsons"
    ],
    "abstract": "We provide a dataset for enabling Deep Generative Models (DGMs) in\nengineering design and propose methods to automate data labeling by utilizing\nlarge-scale foundation models. GeoBiked is curated to contain 4 355 bicycle\nimages, annotated with structural and technical features and is used to\ninvestigate two automated labeling techniques: The utilization of consolidated\nlatent features (Hyperfeatures) from image-generation models to detect\ngeometric correspondences (e.g. the position of the wheel center) in structural\nimages and the generation of diverse text descriptions for structural images.\nGPT-4o, a vision-language-model (VLM), is instructed to analyze images and\nproduce diverse descriptions aligned with the system-prompt. By representing\ntechnical images as Diffusion-Hyperfeatures, drawing geometric correspondences\nbetween them is possible. The detection accuracy of geometric points in unseen\nsamples is improved by presenting multiple annotated source images. GPT-4o has\nsufficient capabilities to generate accurate descriptions of technical images.\nGrounding the generation only on images leads to diverse descriptions but\ncauses hallucinations, while grounding it on categorical labels restricts the\ndiversity. Using both as input balances creativity and accuracy. Successfully\nusing Hyperfeatures for geometric correspondence suggests that this approach\ncan be used for general point-detection and annotation tasks in technical\nimages. Labeling such images with text descriptions using VLMs is possible, but\ndependent on the models detection capabilities, careful prompt-engineering and\nthe selection of input information. Applying foundation models in engineering\ndesign is largely unexplored. We aim to bridge this gap with a dataset to\nexplore training, finetuning and conditioning DGMs in this field and suggesting\napproaches to bootstrap foundation models to process technical images.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17045v1",
    "published_date": "2024-09-25 15:57:59 UTC",
    "updated_date": "2024-09-25 15:57:59 UTC"
  },
  {
    "arxiv_id": "2409.17044v2",
    "title": "How to Connect Speech Foundation Models and Large Language Models? What Matters and What Does Not",
    "authors": [
      "Francesco Verdini",
      "Pierfrancesco Melucci",
      "Stefano Perna",
      "Francesco Cariaggi",
      "Marco Gaido",
      "Sara Papi",
      "Szymon Mazurek",
      "Marek Kasztelnik",
      "Luisa Bentivogli",
      "Sébastien Bratières",
      "Paolo Merialdo",
      "Simone Scardapane"
    ],
    "abstract": "The remarkable performance achieved by Large Language Models (LLM) has driven\nresearch efforts to leverage them for a wide range of tasks and input\nmodalities. In speech-to-text (S2T) tasks, the emerging solution consists of\nprojecting the output of the encoder of a Speech Foundational Model (SFM) into\nthe LLM embedding space through an adapter module. However, no work has yet\ninvestigated how much the downstream-task performance depends on each component\n(SFM, adapter, LLM) nor whether the best design of the adapter depends on the\nchosen SFM and LLM. To fill this gap, we evaluate the combination of 5 adapter\nmodules, 2 LLMs (Mistral and Llama), and 2 SFMs (Whisper and SeamlessM4T) on\ntwo widespread S2T tasks, namely Automatic Speech Recognition and Speech\nTranslation. Our results demonstrate that the SFM plays a pivotal role in\ndownstream performance, while the adapter choice has moderate impact and\ndepends on the SFM and LLM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17044v2",
    "published_date": "2024-09-25 15:54:29 UTC",
    "updated_date": "2024-11-08 12:44:49 UTC"
  },
  {
    "arxiv_id": "2409.17027v3",
    "title": "Counterfactual Token Generation in Large Language Models",
    "authors": [
      "Ivi Chatzi",
      "Nina Corvelo Benz",
      "Eleni Straitouri",
      "Stratis Tsirtsis",
      "Manuel Gomez-Rodriguez"
    ],
    "abstract": "\"Sure, I am happy to generate a story for you: Captain Lyra stood at the helm\nof her trusty ship, the Maelstrom's Fury, gazing out at the endless sea. [...]\nLyra's eyes welled up with tears as she realized the bitter truth - she had\nsacrificed everything for fleeting riches, and lost the love of her crew, her\nfamily, and herself.\" Although this story, generated by a large language model,\nis captivating, one may wonder -- how would the story have unfolded if the\nmodel had chosen \"Captain Maeve\" as the protagonist instead? We cannot know.\nState-of-the-art large language models are stateless -- they maintain no\ninternal memory or state. Given a prompt, they generate a sequence of tokens as\nan output using an autoregressive process. As a consequence, they cannot reason\nabout counterfactual alternatives to tokens they have generated in the past. In\nthis work, our goal is to enhance them with this functionality. To this end, we\ndevelop a causal model of token generation that builds upon the Gumbel-Max\nstructural causal model. Our model allows any large language model to perform\ncounterfactual token generation at almost no cost in comparison with vanilla\ntoken generation, it is embarrassingly simple to implement, and it does not\nrequire any fine-tuning nor prompt engineering. We implement our model on Llama\n3 8B-Instruct and Ministral-8B-Instruct and conduct a qualitative and a\nquantitative analysis of counterfactually generated text. We conclude with a\ndemonstrative application of counterfactual token generation for bias\ndetection, unveiling interesting insights about the model of the world\nconstructed by large language models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at CLeaR 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.17027v3",
    "published_date": "2024-09-25 15:30:24 UTC",
    "updated_date": "2025-03-24 19:05:17 UTC"
  },
  {
    "arxiv_id": "2409.17012v1",
    "title": "AI-Driven Risk-Aware Scheduling for Active Debris Removal Missions",
    "authors": [
      "Antoine Poupon",
      "Hugo de Rohan Willner",
      "Pierre Nikitits",
      "Adam Abdin"
    ],
    "abstract": "The proliferation of debris in Low Earth Orbit (LEO) represents a significant\nthreat to space sustainability and spacecraft safety. Active Debris Removal\n(ADR) has emerged as a promising approach to address this issue, utilising\nOrbital Transfer Vehicles (OTVs) to facilitate debris deorbiting, thereby\nreducing future collision risks. However, ADR missions are substantially\ncomplex, necessitating accurate planning to make the missions economically\nviable and technically effective. Moreover, these servicing missions require a\nhigh level of autonomous capability to plan under evolving orbital conditions\nand changing mission requirements. In this paper, an autonomous\ndecision-planning model based on Deep Reinforcement Learning (DRL) is developed\nto train an OTV to plan optimal debris removal sequencing. It is shown that\nusing the proposed framework, the agent can find optimal mission plans and\nlearn to update the planning autonomously to include risk handling of debris\nwith high collision risk.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17012v1",
    "published_date": "2024-09-25 15:16:07 UTC",
    "updated_date": "2024-09-25 15:16:07 UTC"
  },
  {
    "arxiv_id": "2409.17005v2",
    "title": "Models Can and Should Embrace the Communicative Nature of Human-Generated Math",
    "authors": [
      "Sasha Boguraev",
      "Ben Lipkin",
      "Leonie Weissweiler",
      "Kyle Mahowald"
    ],
    "abstract": "Math is constructed by people for people: just as natural language corpora\nreflect not just propositions but the communicative goals of language users,\nthe math data that models are trained on reflects not just idealized\nmathematical entities but rich communicative intentions. While there are\nimportant advantages to treating math in a purely symbolic manner, we here\nhypothesize that there are benefits to treating math as situated linguistic\ncommunication and that language models are well suited for this goal, in ways\nthat are not fully appreciated. We illustrate these points with two case\nstudies. First, we ran an experiment in which we found that language models\ninterpret the equals sign in a humanlike way -- generating systematically\ndifferent word problems for the same underlying equation arranged in different\nways. Second, we found that language models prefer proofs to be ordered in\nnaturalistic ways, even though other orders would be logically equivalent. We\nadvocate for AI systems that learn from and represent the communicative\nintentions latent in human-generated math.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17005v2",
    "published_date": "2024-09-25 15:08:08 UTC",
    "updated_date": "2024-10-31 17:21:13 UTC"
  },
  {
    "arxiv_id": "2409.16997v2",
    "title": "INT-FlashAttention: Enabling Flash Attention for INT8 Quantization",
    "authors": [
      "Shimao Chen",
      "Zirui Liu",
      "Zhiying Wu",
      "Ce Zheng",
      "Peizhuang Cong",
      "Zihan Jiang",
      "Yuhan Wu",
      "Lei Su",
      "Tong Yang"
    ],
    "abstract": "As the foundation of large language models (LLMs), self-attention module\nfaces the challenge of quadratic time and memory complexity with respect to\nsequence length. FlashAttention accelerates attention computation and reduces\nits memory usage by leveraging the GPU memory hierarchy. A promising research\ndirection is to integrate FlashAttention with quantization methods. This paper\nintroduces INT-FlashAttention, the first INT8 quantization architecture\ncompatible with the forward workflow of FlashAttention, which significantly\nimproves the inference speed of FlashAttention on Ampere GPUs. We implement our\nINT-FlashAttention prototype with fully INT8 activations and general\nmatrix-multiplication (GEMM) kernels, making it the first attention operator\nwith fully INT8 input. As a general token-level post-training quantization\nframework, INT-FlashAttention is also compatible with other data formats like\nINT4, etc. Experimental results show INT-FlashAttention achieves 72% faster\ninference speed and 82% smaller quantization error compared to standard\nFlashAttention with FP16 and FP8 data format.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16997v2",
    "published_date": "2024-09-25 15:02:25 UTC",
    "updated_date": "2024-09-26 06:13:04 UTC"
  },
  {
    "arxiv_id": "2409.16986v2",
    "title": "Harnessing Diversity for Important Data Selection in Pretraining Large Language Models",
    "authors": [
      "Chi Zhang",
      "Huaping Zhong",
      "Kuan Zhang",
      "Chengliang Chai",
      "Rui Wang",
      "Xinlin Zhuang",
      "Tianyi Bai",
      "Jiantao Qiu",
      "Lei Cao",
      "Ju Fan",
      "Ye Yuan",
      "Guoren Wang",
      "Conghui He"
    ],
    "abstract": "Data selection is of great significance in pre-training large language\nmodels, given the variation in quality within the large-scale available\ntraining corpora. To achieve this, researchers are currently investigating the\nuse of data influence to measure the importance of data instances, $i.e.,$ a\nhigh influence score indicates that incorporating this instance to the training\nset is likely to enhance the model performance. Consequently, they select the\ntop-$k$ instances with the highest scores. However, this approach has several\nlimitations. (1) Computing the influence of all available data is\ntime-consuming. (2) The selected data instances are not diverse enough, which\nmay hinder the pre-trained model's ability to generalize effectively to various\ndownstream tasks. In this paper, we introduce \\texttt{Quad}, a data selection\napproach that considers both quality and diversity by using data influence to\nachieve state-of-the-art pre-training results. In particular, noting that\nattention layers capture extensive semantic details, we have adapted the\naccelerated $iHVP$ computation methods for attention layers, enhancing our\nability to evaluate the influence of data, $i.e.,$ its quality. For the\ndiversity, \\texttt{Quad} clusters the dataset into similar data instances\nwithin each cluster and diverse instances across different clusters. For each\ncluster, if we opt to select data from it, we take some samples to evaluate the\ninfluence to prevent processing all instances. To determine which clusters to\nselect, we utilize the classic Multi-Armed Bandit method, treating each cluster\nas an arm. This approach favors clusters with highly influential instances\n(ensuring high quality) or clusters that have been selected less frequently\n(ensuring diversity), thereby well balancing between quality and diversity.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16986v2",
    "published_date": "2024-09-25 14:49:29 UTC",
    "updated_date": "2024-10-05 06:11:12 UTC"
  },
  {
    "arxiv_id": "2409.19022v2",
    "title": "Application of AI-based Models for Online Fraud Detection and Analysis",
    "authors": [
      "Antonis Papasavva",
      "Shane Johnson",
      "Ed Lowther",
      "Samantha Lundrigan",
      "Enrico Mariconti",
      "Anna Markovska",
      "Nilufer Tuptuk"
    ],
    "abstract": "Fraud is a prevalent offence that extends beyond financial loss, causing\npsychological and physical harm to victims. The advancements in online\ncommunication technologies alowed for online fraud to thrive in this vast\nnetwork, with fraudsters increasingly using these channels for deception. With\nthe progression of technologies like AI, there is a growing concern that fraud\nwill scale up, using sophisticated methods, like deep-fakes in phishing\ncampaigns, all generated by language generation models like ChatGPT. However,\nthe application of AI in detecting and analyzing online fraud remains\nunderstudied. We conduct a Systematic Literature Review on AI and NLP\ntechniques for online fraud detection. The review adhered the PRISMA-ScR\nprotocol, with eligibility criteria including relevance to online fraud, use of\ntext data, and AI methodologies. We screened 2,457 academic records, 350 met\nour eligibility criteria, and included 223. We report the state-of-the-art NLP\ntechniques for analysing various online fraud categories; the training data\nsources; the NLP algorithms and models built; and the performance metrics\nemployed for model evaluation. We find that current research on online fraud is\ndivided into various scam activitiesand identify 16 different frauds that\nresearchers focus on. This SLR enhances the academic understanding of AI-based\ndetection methods for online fraud and offers insights for policymakers, law\nenforcement, and businesses on safeguarding against such activities. We\nconclude that focusing on specific scams lacks generalization, as multiple\nmodels are required for different fraud types. The evolving nature of scams\nlimits the effectiveness of models trained on outdated data. We also identify\nissues in data limitations, training bias reporting, and selective presentation\nof metrics in model performance reporting, which can lead to potential biases\nin model evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Manuscript accepted in Crime Science Journal. Please cite accordingly",
    "pdf_url": "http://arxiv.org/pdf/2409.19022v2",
    "published_date": "2024-09-25 14:47:03 UTC",
    "updated_date": "2025-04-15 19:05:24 UTC"
  },
  {
    "arxiv_id": "2409.16984v1",
    "title": "AXCEL: Automated eXplainable Consistency Evaluation using LLMs",
    "authors": [
      "P Aditya Sreekar",
      "Sahil Verma",
      "Suransh Chopra",
      "Sarik Ghazarian",
      "Abhishek Persad",
      "Narayanan Sadagopan"
    ],
    "abstract": "Large Language Models (LLMs) are widely used in both industry and academia\nfor various tasks, yet evaluating the consistency of generated text responses\ncontinues to be a challenge. Traditional metrics like ROUGE and BLEU show a\nweak correlation with human judgment. More sophisticated metrics using Natural\nLanguage Inference (NLI) have shown improved correlations but are complex to\nimplement, require domain-specific training due to poor cross-domain\ngeneralization, and lack explainability. More recently, prompt-based metrics\nusing LLMs as evaluators have emerged; while they are easier to implement, they\nstill lack explainability and depend on task-specific prompts, which limits\ntheir generalizability. This work introduces Automated eXplainable Consistency\nEvaluation using LLMs (AXCEL), a prompt-based consistency metric which offers\nexplanations for the consistency scores by providing detailed reasoning and\npinpointing inconsistent text spans. AXCEL is also a generalizable metric which\ncan be adopted to multiple tasks without changing the prompt. AXCEL outperforms\nboth non-prompt and prompt-based state-of-the-art (SOTA) metrics in detecting\ninconsistencies across summarization by 8.7%, free text generation by 6.2%, and\ndata-to-text conversion tasks by 29.4%. We also evaluate the influence of\nunderlying LLMs on prompt based metric performance and recalibrate the SOTA\nprompt-based metrics with the latest LLMs for fair comparison. Further, we show\nthat AXCEL demonstrates strong performance using open source LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16984v1",
    "published_date": "2024-09-25 14:45:52 UTC",
    "updated_date": "2024-09-25 14:45:52 UTC"
  },
  {
    "arxiv_id": "2409.16978v1",
    "title": "Towards User-Focused Research in Training Data Attribution for Human-Centered Explainable AI",
    "authors": [
      "Elisa Nguyen",
      "Johannes Bertram",
      "Evgenii Kortukov",
      "Jean Y. Song",
      "Seong Joon Oh"
    ],
    "abstract": "While Explainable AI (XAI) aims to make AI understandable and useful to\nhumans, it has been criticised for relying too much on formalism and\nsolutionism, focusing more on mathematical soundness than user needs. We\npropose an alternative to this bottom-up approach inspired by design thinking:\nthe XAI research community should adopt a top-down, user-focused perspective to\nensure user relevance. We illustrate this with a relatively young subfield of\nXAI, Training Data Attribution (TDA). With the surge in TDA research and\ngrowing competition, the field risks repeating the same patterns of\nsolutionism. We conducted a needfinding study with a diverse group of AI\npractitioners to identify potential user needs related to TDA. Through\ninterviews (N=10) and a systematic survey (N=31), we uncovered new TDA tasks\nthat are currently largely overlooked. We invite the TDA and XAI communities to\nconsider these novel tasks and improve the user relevance of their research\noutcomes.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16978v1",
    "published_date": "2024-09-25 14:40:26 UTC",
    "updated_date": "2024-09-25 14:40:26 UTC"
  },
  {
    "arxiv_id": "2409.16974v1",
    "title": "Decoding Large-Language Models: A Systematic Overview of Socio-Technical Impacts, Constraints, and Emerging Questions",
    "authors": [
      "Zeyneb N. Kaya",
      "Souvick Ghosh"
    ],
    "abstract": "There have been rapid advancements in the capabilities of large language\nmodels (LLMs) in recent years, greatly revolutionizing the field of natural\nlanguage processing (NLP) and artificial intelligence (AI) to understand and\ninteract with human language. Therefore, in this work, we conduct a systematic\ninvestigation of the literature to identify the prominent themes and directions\nof LLM developments, impacts, and limitations. Our findings illustrate the\naims, methodologies, limitations, and future directions of LLM research. It\nincludes responsible development considerations, algorithmic improvements,\nethical challenges, and societal implications of LLM development. Overall, this\npaper provides a rigorous and comprehensive overview of current research in LLM\nand identifies potential directions for future development. The article\nhighlights the application areas that could have a positive impact on society\nalong with the ethical considerations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "28 pages, 5 figures, preprint submitted to journal",
    "pdf_url": "http://arxiv.org/pdf/2409.16974v1",
    "published_date": "2024-09-25 14:36:30 UTC",
    "updated_date": "2024-09-25 14:36:30 UTC"
  },
  {
    "arxiv_id": "2409.16973v1",
    "title": "Adaptive Self-Supervised Learning Strategies for Dynamic On-Device LLM Personalization",
    "authors": [
      "Rafael Mendoza",
      "Isabella Cruz",
      "Richard Liu",
      "Aarav Deshmukh",
      "David Williams",
      "Jesscia Peng",
      "Rohan Iyer"
    ],
    "abstract": "Large language models (LLMs) have revolutionized how we interact with\ntechnology, but their personalization to individual user preferences remains a\nsignificant challenge, particularly in on-device applications. Traditional\nmethods often depend heavily on labeled datasets and can be resource-intensive.\nTo address these issues, we present Adaptive Self-Supervised Learning\nStrategies (ASLS), which utilizes self-supervised learning techniques to\npersonalize LLMs dynamically. The framework comprises a user profiling layer\nfor collecting interaction data and a neural adaptation layer for real-time\nmodel fine-tuning. This innovative approach enables continuous learning from\nuser feedback, allowing the model to generate responses that align closely with\nuser-specific contexts. The adaptive mechanisms of ASLS minimize computational\ndemands and enhance personalization efficiency. Experimental results across\nvarious user scenarios illustrate the superior performance of ASLS in boosting\nuser engagement and satisfaction, highlighting its potential to redefine LLMs\nas highly responsive and context-aware systems on-device.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "First ASLS",
    "pdf_url": "http://arxiv.org/pdf/2409.16973v1",
    "published_date": "2024-09-25 14:35:06 UTC",
    "updated_date": "2024-09-25 14:35:06 UTC"
  },
  {
    "arxiv_id": "2409.16956v2",
    "title": "Informed deep hierarchical classification: a non-standard analysis inspired approach",
    "authors": [
      "Lorenzo Fiaschi",
      "Marco Cococcioni"
    ],
    "abstract": "This work proposes a novel approach to the deep hierarchical classification\ntask, i.e., the problem of classifying data according to multiple labels\norganized in a rigid parent-child structure. It consists in a multi-output deep\nneural network equipped with specific projection operators placed before each\noutput layer. The design of such an architecture, called lexicographic hybrid\ndeep neural network (LH-DNN), has been possible by combining tools from\ndifferent and quite distant research fields: lexicographic multi-objective\noptimization, non-standard analysis, and deep learning. To assess the efficacy\nof the approach, the resulting network is compared against the B-CNN, a\nconvolutional neural network tailored for hierarchical classification tasks, on\nthe CIFAR10, CIFAR100 (where it has been originally and recently proposed\nbefore being adopted and tuned for multiple real-world applications) and\nFashion-MNIST benchmarks. Evidence states that an LH-DNN can achieve comparable\nif not superior performance, especially in the learning of the hierarchical\nrelations, in the face of a drastic reduction of the learning parameters,\ntraining epochs, and computational time, without the need for ad-hoc loss\nfunctions weighting values.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.LO",
      "03H10, 68T07",
      "I.2.5; I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16956v2",
    "published_date": "2024-09-25 14:12:50 UTC",
    "updated_date": "2024-10-04 09:46:24 UTC"
  },
  {
    "arxiv_id": "2409.16950v1",
    "title": "Dynamic Obstacle Avoidance through Uncertainty-Based Adaptive Planning with Diffusion",
    "authors": [
      "Vineet Punyamoorty",
      "Pascal Jutras-Dubé",
      "Ruqi Zhang",
      "Vaneet Aggarwal",
      "Damon Conover",
      "Aniket Bera"
    ],
    "abstract": "By framing reinforcement learning as a sequence modeling problem, recent work\nhas enabled the use of generative models, such as diffusion models, for\nplanning. While these models are effective in predicting long-horizon state\ntrajectories in deterministic environments, they face challenges in dynamic\nsettings with moving obstacles. Effective collision avoidance demands\ncontinuous monitoring and adaptive decision-making. While replanning at every\ntimestep could ensure safety, it introduces substantial computational overhead\ndue to the repetitive prediction of overlapping state sequences -- a process\nthat is particularly costly with diffusion models, known for their intensive\niterative sampling procedure. We propose an adaptive generative planning\napproach that dynamically adjusts replanning frequency based on the uncertainty\nof action predictions. Our method minimizes the need for frequent,\ncomputationally expensive, and redundant replanning while maintaining robust\ncollision avoidance performance. In experiments, we obtain a 13.5% increase in\nthe mean trajectory length and a 12.7% increase in mean reward over\nlong-horizon planning, indicating a reduction in collision rates and an\nimproved ability to navigate the environment safely.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16950v1",
    "published_date": "2024-09-25 14:03:58 UTC",
    "updated_date": "2024-09-25 14:03:58 UTC"
  },
  {
    "arxiv_id": "2409.16946v1",
    "title": "Setting the AI Agenda -- Evidence from Sweden in the ChatGPT Era",
    "authors": [
      "Bastiaan Bruinsma",
      "Annika Fredén",
      "Kajsa Hansson",
      "Moa Johansson",
      "Pasko Kisić-Merino",
      "Denitsa Saynova"
    ],
    "abstract": "This paper examines the development of the Artificial Intelligence (AI)\nmeta-debate in Sweden before and after the release of ChatGPT. From the\nperspective of agenda-setting theory, we propose that it is an elite outside of\nparty politics that is leading the debate -- i.e. that the politicians are\nrelatively silent when it comes to this rapid development. We also suggest that\nthe debate has become more substantive and risk-oriented in recent years. To\ninvestigate this claim, we draw on an original dataset of elite-level documents\nfrom the early 2010s to the present, using op-eds published in a number of\nleading Swedish newspapers. By conducting a qualitative content analysis of\nthese materials, our preliminary findings lend support to the expectation that\nan academic, rather than a political elite is steering the debate.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper is part of the Second AEQUITAS Workshop on Fairness and\n  Bias in AI | co-located with ECAI 2024, October 19--24, 2024, Santiago de\n  Compostela, Spain",
    "pdf_url": "http://arxiv.org/pdf/2409.16946v1",
    "published_date": "2024-09-25 13:58:02 UTC",
    "updated_date": "2024-09-25 13:58:02 UTC"
  },
  {
    "arxiv_id": "2409.16944v1",
    "title": "Go-SLAM: Grounded Object Segmentation and Localization with Gaussian Splatting SLAM",
    "authors": [
      "Phu Pham",
      "Dipam Patel",
      "Damon Conover",
      "Aniket Bera"
    ],
    "abstract": "We introduce Go-SLAM, a novel framework that utilizes 3D Gaussian Splatting\nSLAM to reconstruct dynamic environments while embedding object-level\ninformation within the scene representations. This framework employs advanced\nobject segmentation techniques, assigning a unique identifier to each Gaussian\nsplat that corresponds to the object it represents. Consequently, our system\nfacilitates open-vocabulary querying, allowing users to locate objects using\nnatural language descriptions. Furthermore, the framework features an optimal\npath generation module that calculates efficient navigation paths for robots\ntoward queried objects, considering obstacles and environmental uncertainties.\nComprehensive evaluations in various scene settings demonstrate the\neffectiveness of our approach in delivering high-fidelity scene\nreconstructions, precise object segmentation, flexible object querying, and\nefficient robot path planning. This work represents an additional step forward\nin bridging the gap between 3D scene reconstruction, semantic object\nunderstanding, and real-time environment interactions.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16944v1",
    "published_date": "2024-09-25 13:56:08 UTC",
    "updated_date": "2024-09-25 13:56:08 UTC"
  },
  {
    "arxiv_id": "2409.16938v2",
    "title": "Generative Object Insertion in Gaussian Splatting with a Multi-View Diffusion Model",
    "authors": [
      "Hongliang Zhong",
      "Can Wang",
      "Jingbo Zhang",
      "Jing Liao"
    ],
    "abstract": "Generating and inserting new objects into 3D content is a compelling approach\nfor achieving versatile scene recreation. Existing methods, which rely on SDS\noptimization or single-view inpainting, often struggle to produce high-quality\nresults. To address this, we propose a novel method for object insertion in 3D\ncontent represented by Gaussian Splatting. Our approach introduces a multi-view\ndiffusion model, dubbed MVInpainter, which is built upon a pre-trained stable\nvideo diffusion model to facilitate view-consistent object inpainting. Within\nMVInpainter, we incorporate a ControlNet-based conditional injection module to\nenable controlled and more predictable multi-view generation. After generating\nthe multi-view inpainted results, we further propose a mask-aware 3D\nreconstruction technique to refine Gaussian Splatting reconstruction from these\nsparse inpainted views. By leveraging these fabricate techniques, our approach\nyields diverse results, ensures view-consistent and harmonious insertions, and\nproduces better object quality. Extensive experiments demonstrate that our\napproach outperforms existing methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by Visual Informatics. Project Page:\n  https://github.com/JiuTongBro/MultiView_Inpaint",
    "pdf_url": "http://arxiv.org/pdf/2409.16938v2",
    "published_date": "2024-09-25 13:52:50 UTC",
    "updated_date": "2025-04-11 12:04:56 UTC"
  },
  {
    "arxiv_id": "2409.16937v3",
    "title": "Semi-Supervised Cognitive State Classification from Speech with Multi-View Pseudo-Labeling",
    "authors": [
      "Yuanchao Li",
      "Zixing Zhang",
      "Jing Han",
      "Peter Bell",
      "Catherine Lai"
    ],
    "abstract": "The lack of labeled data is a common challenge in speech classification\ntasks, particularly those requiring extensive subjective assessment, such as\ncognitive state classification. In this work, we propose a Semi-Supervised\nLearning (SSL) framework, introducing a novel multi-view pseudo-labeling method\nthat leverages both acoustic and linguistic characteristics to select the most\nconfident data for training the classification model. Acoustically, unlabeled\ndata are compared to labeled data using the Frechet audio distance, calculated\nfrom embeddings generated by multiple audio encoders. Linguistically, large\nlanguage models are prompted to revise automatic speech recognition\ntranscriptions and predict labels based on our proposed task-specific\nknowledge. High-confidence data are identified when pseudo-labels from both\nsources align, while mismatches are treated as low-confidence data. A bimodal\nclassifier is then trained to iteratively label the low-confidence data until a\npredefined criterion is met. We evaluate our SSL framework on emotion\nrecognition and dementia detection tasks. Experimental results demonstrate that\nour method achieves competitive performance compared to fully supervised\nlearning using only 30% of the labeled data and significantly outperforms two\nselected baselines.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.MM",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted to ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.16937v3",
    "published_date": "2024-09-25 13:51:19 UTC",
    "updated_date": "2025-04-30 13:24:00 UTC"
  },
  {
    "arxiv_id": "2409.16934v3",
    "title": "Investigating OCR-Sensitive Neurons to Improve Entity Recognition in Historical Documents",
    "authors": [
      "Emanuela Boros",
      "Maud Ehrmann"
    ],
    "abstract": "This paper investigates the presence of OCR-sensitive neurons within the\nTransformer architecture and their influence on named entity recognition (NER)\nperformance on historical documents. By analysing neuron activation patterns in\nresponse to clean and noisy text inputs, we identify and then neutralise\nOCR-sensitive neurons to improve model performance. Based on two open access\nlarge language models (Llama2 and Mistral), experiments demonstrate the\nexistence of OCR-sensitive regions and show improvements in NER performance on\nhistorical newspapers and classical commentaries, highlighting the potential of\ntargeted neuron modulation to improve models' performance on noisy text.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16934v3",
    "published_date": "2024-09-25 13:45:23 UTC",
    "updated_date": "2024-11-18 15:22:32 UTC"
  },
  {
    "arxiv_id": "2409.16928v1",
    "title": "Quantum-Classical Sentiment Analysis",
    "authors": [
      "Mario Bifulco",
      "Luca Roversi"
    ],
    "abstract": "In this study, we initially investigate the application of a hybrid\nclassical-quantum classifier (HCQC) for sentiment analysis, comparing its\nperformance against the classical CPLEX classifier and the Transformer\narchitecture. Our findings indicate that while the HCQC underperforms relative\nto the Transformer in terms of classification accuracy, but it requires\nsignificantly less time to converge to a reasonably good approximate solution.\nThis experiment also reveals a critical bottleneck in the HCQC, whose\narchitecture is partially undisclosed by the D-Wave property. To address this\nlimitation, we propose a novel algorithm based on the algebraic decomposition\nof QUBO models, which enhances the time the quantum processing unit can\nallocate to problem-solving tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to BigHPC 2024 - https://www.itadata.it/2024/bighpc2024",
    "pdf_url": "http://arxiv.org/pdf/2409.16928v1",
    "published_date": "2024-09-25 13:40:19 UTC",
    "updated_date": "2024-09-25 13:40:19 UTC"
  },
  {
    "arxiv_id": "2410.07612v1",
    "title": "A Survey for Deep Reinforcement Learning Based Network Intrusion Detection",
    "authors": [
      "Wanrong Yang",
      "Alberto Acuto",
      "Yihang Zhou",
      "Dominik Wojtczak"
    ],
    "abstract": "Cyber-attacks are becoming increasingly sophisticated and frequent,\nhighlighting the importance of network intrusion detection systems. This paper\nexplores the potential and challenges of using deep reinforcement learning\n(DRL) in network intrusion detection. It begins by introducing key DRL concepts\nand frameworks, such as deep Q-networks and actor-critic algorithms, and\nreviews recent research utilizing DRL for intrusion detection. The study\nevaluates challenges related to model training efficiency, detection of\nminority and unknown class attacks, feature selection, and handling unbalanced\ndatasets. The performance of DRL models is comprehensively analyzed, showing\nthat while DRL holds promise, many recent technologies remain underexplored.\nSome DRL models achieve state-of-the-art results on public datasets,\noccasionally outperforming traditional deep learning methods. The paper\nconcludes with recommendations for enhancing DRL deployment and testing in\nreal-world network scenarios, with a focus on Internet of Things intrusion\ndetection. It discusses recent DRL architectures and suggests future policy\nfunctions for DRL-based intrusion detection. Finally, the paper proposes\nintegrating DRL with generative methods to further improve performance,\naddressing current gaps and supporting more robust and adaptive network\nintrusion detection systems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "17 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.07612v1",
    "published_date": "2024-09-25 13:39:30 UTC",
    "updated_date": "2024-09-25 13:39:30 UTC"
  },
  {
    "arxiv_id": "2409.16923v1",
    "title": "AI-assisted Gaze Detection for Proctoring Online Exams",
    "authors": [
      "Yong-Siang Shih",
      "Zach Zhao",
      "Chenhao Niu",
      "Bruce Iberg",
      "James Sharpnack",
      "Mirza Basim Baig"
    ],
    "abstract": "For high-stakes online exams, it is important to detect potential rule\nviolations to ensure the security of the test. In this study, we investigate\nthe task of detecting whether test takers are looking away from the screen, as\nsuch behavior could be an indication that the test taker is consulting external\nresources. For asynchronous proctoring, the exam videos are recorded and\nreviewed by the proctors. However, when the length of the exam is long, it\ncould be tedious for proctors to watch entire exam videos to determine the\nexact moments when test takers look away. We present an AI-assisted gaze\ndetection system, which allows proctors to navigate between different video\nframes and discover video frames where the test taker is looking in similar\ndirections. The system enables proctors to work more effectively to identify\nsuspicious moments in videos. An evaluation framework is proposed to evaluate\nthe system against human-only and ML-only proctoring, and a user study is\nconducted to gather feedback from proctors, aiming to demonstrate the\neffectiveness of the system.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to HCOMP-24 Works-in-Progress and Demonstration track",
    "pdf_url": "http://arxiv.org/pdf/2409.16923v1",
    "published_date": "2024-09-25 13:31:37 UTC",
    "updated_date": "2024-09-25 13:31:37 UTC"
  },
  {
    "arxiv_id": "2409.16920v2",
    "title": "Cross-Lingual Speech Emotion Recognition: Humans vs. Self-Supervised Models",
    "authors": [
      "Zhichen Han",
      "Tianqi Geng",
      "Hui Feng",
      "Jiahong Yuan",
      "Korin Richmond",
      "Yuanchao Li"
    ],
    "abstract": "Utilizing Self-Supervised Learning (SSL) models for Speech Emotion\nRecognition (SER) has proven effective, yet limited research has explored\ncross-lingual scenarios. This study presents a comparative analysis between\nhuman performance and SSL models, beginning with a layer-wise analysis and an\nexploration of parameter-efficient fine-tuning strategies in monolingual,\ncross-lingual, and transfer learning contexts. We further compare the SER\nability of models and humans at both utterance- and segment-levels.\nAdditionally, we investigate the impact of dialect on cross-lingual SER through\nhuman evaluation. Our findings reveal that models, with appropriate knowledge\ntransfer, can adapt to the target language and achieve performance comparable\nto native speakers. We also demonstrate the significant effect of dialect on\nSER for individuals without prior linguistic and paralinguistic background.\nMoreover, both humans and models exhibit distinct behaviors across different\nemotions. These results offer new insights into the cross-lingual SER\ncapabilities of SSL models, underscoring both their similarities to and\ndifferences from human emotion perception.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted to ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.16920v2",
    "published_date": "2024-09-25 13:27:17 UTC",
    "updated_date": "2025-04-30 13:16:09 UTC"
  },
  {
    "arxiv_id": "2409.16913v1",
    "title": "Tell Me What You Don't Know: Enhancing Refusal Capabilities of Role-Playing Agents via Representation Space Analysis and Editing",
    "authors": [
      "Wenhao Liu",
      "Siyu An",
      "Junru Lu",
      "Muling Wu",
      "Tianlong Li",
      "Xiaohua Wang",
      "Xiaoqing Zheng",
      "Di Yin",
      "Xing Sun",
      "Xuanjing Huang"
    ],
    "abstract": "Role-Playing Agents (RPAs) have shown remarkable performance in various\napplications, yet they often struggle to recognize and appropriately respond to\nhard queries that conflict with their role-play knowledge. To investigate RPAs'\nperformance when faced with different types of conflicting requests, we develop\nan evaluation benchmark that includes contextual knowledge conflicting\nrequests, parametric knowledge conflicting requests, and non-conflicting\nrequests to assess RPAs' ability to identify conflicts and refuse to answer\nappropriately without over-refusing. Through extensive evaluation, we find that\nmost RPAs behave significant performance gaps toward different conflict\nrequests. To elucidate the reasons, we conduct an in-depth representation-level\nanalysis of RPAs under various conflict scenarios. Our findings reveal the\nexistence of rejection regions and direct response regions within the model's\nforwarding representation, and thus influence the RPA's final response\nbehavior. Therefore, we introduce a lightweight representation editing approach\nthat conveniently shifts conflicting requests to the rejection region, thereby\nenhancing the model's refusal accuracy. The experimental results validate the\neffectiveness of our editing method, improving RPAs' refusal ability of\nconflicting requests while maintaining their general role-playing capabilities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16913v1",
    "published_date": "2024-09-25 13:18:12 UTC",
    "updated_date": "2024-09-25 13:18:12 UTC"
  },
  {
    "arxiv_id": "2409.16909v2",
    "title": "Enhancing Temporal Sensitivity and Reasoning for Time-Sensitive Question Answering",
    "authors": [
      "Wanqi Yang",
      "Yanda Li",
      "Meng Fang",
      "Ling Chen"
    ],
    "abstract": "Time-Sensitive Question Answering (TSQA) demands the effective utilization of\nspecific temporal contexts, encompassing multiple time-evolving facts, to\naddress time-sensitive questions. This necessitates not only the parsing of\ntemporal information within questions but also the identification and\nunderstanding of time-evolving facts to generate accurate answers. However,\ncurrent large language models still have limited sensitivity to temporal\ninformation and their inadequate temporal reasoning capabilities. In this\npaper, we propose a novel framework that enhances temporal awareness and\nreasoning through Temporal Information-Aware Embedding and Granular Contrastive\nReinforcement Learning. Experimental results on four TSQA datasets demonstrate\nthat our framework significantly outperforms existing LLMs in TSQA tasks,\nmarking a step forward in bridging the performance gap between machine and\nhuman temporal understanding and reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2409.16909v2",
    "published_date": "2024-09-25 13:13:21 UTC",
    "updated_date": "2024-09-29 13:17:28 UTC"
  },
  {
    "arxiv_id": "2409.16904v1",
    "title": "Discriminative Anchor Learning for Efficient Multi-view Clustering",
    "authors": [
      "Yalan Qin",
      "Nan Pu",
      "Hanzhou Wu",
      "Nicu Sebe"
    ],
    "abstract": "Multi-view clustering aims to study the complementary information across\nviews and discover the underlying structure. For solving the relatively high\ncomputational cost for the existing approaches, works based on anchor have been\npresented recently. Even with acceptable clustering performance, these methods\ntend to map the original representation from multiple views into a fixed shared\ngraph based on the original dataset. However, most studies ignore the\ndiscriminative property of the learned anchors, which ruin the representation\ncapability of the built model. Moreover, the complementary information among\nanchors across views is neglected to be ensured by simply learning the shared\nanchor graph without considering the quality of view-specific anchors. In this\npaper, we propose discriminative anchor learning for multi-view clustering\n(DALMC) for handling the above issues. We learn discriminative view-specific\nfeature representations according to the original dataset and build anchors\nfrom different views based on these representations, which increase the quality\nof the shared anchor graph. The discriminative feature learning and consensus\nanchor graph construction are integrated into a unified framework to improve\neach other for realizing the refinement. The optimal anchors from multiple\nviews and the consensus anchor graph are learned with the orthogonal\nconstraints. We give an iterative algorithm to deal with the formulated\nproblem. Extensive experiments on different datasets show the effectiveness and\nefficiency of our method compared with other methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This work has been accepted by TMM",
    "pdf_url": "http://arxiv.org/pdf/2409.16904v1",
    "published_date": "2024-09-25 13:11:17 UTC",
    "updated_date": "2024-09-25 13:11:17 UTC"
  },
  {
    "arxiv_id": "2409.16902v5",
    "title": "Underwater Camouflaged Object Tracking Meets Vision-Language SAM2",
    "authors": [
      "Chunhui Zhang",
      "Li Liu",
      "Guanjie Huang",
      "Zhipeng Zhang",
      "Hao Wen",
      "Xi Zhou",
      "Shiming Ge",
      "Yanfeng Wang"
    ],
    "abstract": "Over the past decade, significant progress has been made in visual object\ntracking, largely due to the availability of large-scale datasets. However,\nthese datasets have primarily focused on open-air scenarios and have largely\noverlooked underwater animal tracking-especially the complex challenges posed\nby camouflaged marine animals. To bridge this gap, we take a step forward by\nproposing the first large-scale multi-modal underwater camouflaged object\ntracking dataset, namely UW-COT220. Based on the proposed dataset, this work\nfirst comprehensively evaluates current advanced visual object tracking\nmethods, including SAM- and SAM2-based trackers, in challenging underwater\nenvironments, \\eg, coral reefs. Our findings highlight the improvements of SAM2\nover SAM, demonstrating its enhanced ability to handle the complexities of\nunderwater camouflaged objects. Furthermore, we propose a novel vision-language\ntracking framework called VL-SAM2, based on the video foundation model SAM2.\nExtensive experimental results demonstrate that the proposed VL-SAM2 achieves\nstate-of-the-art performance across underwater and open-air object tracking\ndatasets. The dataset and codes are available\nat~{\\color{magenta}{https://github.com/983632847/Awesome-Multimodal-Object-Tracking}}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR 2025 Workshop on CV4Animals.\n  https://github.com/983632847/Awesome-Multimodal-Object-Tracking",
    "pdf_url": "http://arxiv.org/pdf/2409.16902v5",
    "published_date": "2024-09-25 13:10:03 UTC",
    "updated_date": "2025-05-19 03:40:10 UTC"
  },
  {
    "arxiv_id": "2409.16900v1",
    "title": "A Roadmap for Embodied and Social Grounding in LLMs",
    "authors": [
      "Sara Incao",
      "Carlo Mazzola",
      "Giulia Belgiovine",
      "Alessandra Sciutti"
    ],
    "abstract": "The fusion of Large Language Models (LLMs) and robotic systems has led to a\ntransformative paradigm in the robotic field, offering unparalleled\ncapabilities not only in the communication domain but also in skills like\nmultimodal input handling, high-level reasoning, and plan generation. The\ngrounding of LLMs knowledge into the empirical world has been considered a\ncrucial pathway to exploit the efficiency of LLMs in robotics. Nevertheless,\nconnecting LLMs' representations to the external world with multimodal\napproaches or with robots' bodies is not enough to let them understand the\nmeaning of the language they are manipulating. Taking inspiration from humans,\nthis work draws attention to three necessary elements for an agent to grasp and\nexperience the world. The roadmap for LLMs grounding is envisaged in an active\nbodily system as the reference point for experiencing the environment, a\ntemporally structured experience for a coherent, self-related interaction with\nthe external world, and social skills to acquire a common-grounded shared\nexperience.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "I.2.7; I.2.9; J.4; F.3.2; D.3.1"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted Version of a conference paper presented at Robophilosophy\n  Conference 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.16900v1",
    "published_date": "2024-09-25 13:09:23 UTC",
    "updated_date": "2024-09-25 13:09:23 UTC"
  },
  {
    "arxiv_id": "2409.16898v3",
    "title": "AI-driven View Guidance System in Intra-cardiac Echocardiography Imaging",
    "authors": [
      "Jaeyoung Huh",
      "Paul Klein",
      "Gareth Funka-Lea",
      "Puneet Sharma",
      "Ankur Kapoor",
      "Young-Ho Kim"
    ],
    "abstract": "Intra-cardiac echocardiography (ICE) is a crucial imaging modality used in\nelectrophysiology (EP) and structural heart disease (SHD) interventions,\nproviding realtime, high-resolution views from within the heart. Despite its\nadvantages, effective manipulation of the ICE catheter requires significant\nexpertise, which can lead to inconsistent outcomes, especially among less\nexperienced operators. To address this challenge, we propose an AIdriven view\nguidance system that operates in a continuous closed-loop with\nhuman-in-the-loop feedback, designed to assist users in navigating ICE imaging\nwithout requiring specialized knowledge. Specifically, our method models the\nrelative position and orientation vectors between arbitrary views and\nclinically defined ICE views in a spatial coordinate system. It guides users on\nhow to manipulate the ICE catheter to transition from the current view to the\ndesired view over time. By operating in a closedloop configuration, the system\ncontinuously predicts and updates the necessary catheter manipulations,\nensuring seamless integration into existing clinical workflows. The\neffectiveness of the proposed system is demonstrated through a simulation-based\nperformance evaluation using real clinical data, achieving an 89% success rate\nwith 6,532 test cases. Additionally, a semi-simulation experiment with\nhuman-in-the-loop testing validated the feasibility of continuous yet discrete\nguidance. These results underscore the potential of the proposed method to\nenhance the accuracy and efficiency of ICE imaging procedures.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16898v3",
    "published_date": "2024-09-25 13:08:10 UTC",
    "updated_date": "2025-01-22 16:58:30 UTC"
  },
  {
    "arxiv_id": "2409.16882v1",
    "title": "Revisiting Space Mission Planning: A Reinforcement Learning-Guided Approach for Multi-Debris Rendezvous",
    "authors": [
      "Agni Bandyopadhyay",
      "Guenther Waxenegger-Wilfing"
    ],
    "abstract": "This research introduces a novel application of a masked Proximal Policy\nOptimization (PPO) algorithm from the field of deep reinforcement learning\n(RL), for determining the most efficient sequence of space debris visitation,\nutilizing the Lambert solver as per Izzo's adaptation for individual\nrendezvous. The aim is to optimize the sequence in which all the given debris\nshould be visited to get the least total time for rendezvous for the entire\nmission. A neural network (NN) policy is developed, trained on simulated space\nmissions with varying debris fields. After training, the neural network\ncalculates approximately optimal paths using Izzo's adaptation of Lambert\nmaneuvers. Performance is evaluated against standard heuristics in mission\nplanning. The reinforcement learning approach demonstrates a significant\nimprovement in planning efficiency by optimizing the sequence for debris\nrendezvous, reducing the total mission time by an average of approximately\n{10.96\\%} and {13.66\\%} compared to the Genetic and Greedy algorithms,\nrespectively. The model on average identifies the most time-efficient sequence\nfor debris visitation across various simulated scenarios with the fastest\ncomputational speed. This approach signifies a step forward in enhancing\nmission planning strategies for space debris clearance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for publication at the 2024 International Conference on\n  Space Robotics (iSpaRo)",
    "pdf_url": "http://arxiv.org/pdf/2409.16882v1",
    "published_date": "2024-09-25 12:50:01 UTC",
    "updated_date": "2024-09-25 12:50:01 UTC"
  },
  {
    "arxiv_id": "2409.16876v3",
    "title": "Automating Traffic Model Enhancement with AI Research Agent",
    "authors": [
      "Xusen Guo",
      "Xinxi Yang",
      "Mingxing Peng",
      "Hongliang Lu",
      "Meixin Zhu",
      "Hai Yang"
    ],
    "abstract": "Developing efficient traffic models is crucial for optimizing modern\ntransportation systems. However, current modeling approaches remain\nlabor-intensive and prone to human errors due to their dependence on manual\nworkflows. These processes typically involve extensive literature reviews,\nformula tuning, and iterative testing, which often lead to inefficiencies. To\naddress this, we propose TR-Agent, an AI-powered framework that autonomously\ndevelops and refines traffic models through a closed-loop, iterative process.\nWe structure the research pipeline into four key stages: idea generation,\ntheory formulation, theory evaluation, and iterative optimization, and\nimplement TR-Agent with four corresponding modules. These modules collaborate\nto retrieve knowledge from external sources, generate novel hypotheses,\nimplement and debug models, and evaluate their performance on evaluation\ndatasets. Through iteratively feedback and refinement, TR-Agent improves both\nmodeling efficiency and effectiveness. We validate the framework on three\nrepresentative traffic models: the Intelligent Driver Model (IDM) for\ncar-following behavior, the MOBIL model for lane-changing, and the\nLighthill-Whitham-Richards (LWR) speed-density relationship for macroscopic\ntraffic flow modeling. Experimental results show substantial performance gains\nover the original models. To assess the robustness and generalizability of the\nimprovements, we conduct additional evaluations across multiple real-world\ndatasets, demonstrating consistent performance gains beyond the original\ndevelopment data. Furthermore, TR-Agent produces interpretable explanations for\neach improvement, enabling researchers to easily verify and extend its results.\nThis makes TR-Agent a valuable assistant for traffic modeling refinement and a\npromising tool for broader applications in transportation research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "27 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.16876v3",
    "published_date": "2024-09-25 12:42:25 UTC",
    "updated_date": "2025-05-06 07:58:27 UTC"
  },
  {
    "arxiv_id": "2410.08216v1",
    "title": "New technologies and AI: envisioning future directions for UNSCR 1540",
    "authors": [
      "Clara Punzi"
    ],
    "abstract": "This paper investigates the emerging challenges posed by the integration of\nArtificial Intelligence (AI) in the military domain, particularly within the\ncontext of United Nations Security Council Resolution 1540 (UNSCR 1540), which\nseeks to prevent the proliferation of weapons of mass destruction (WMDs). While\nthe resolution initially focused on nuclear, chemical, and biological threats,\nthe rapid advancement of AI introduces new complexities that were previously\nunanticipated. We critically analyze how AI can both exacerbate existing risks\nassociated with WMDs (e.g., thorough the deployment of kamikaze drones and\nkiller robots) and introduce novel threats (e.g., by exploiting Generative AI\npotentialities), thereby compromising international peace and security. The\npaper calls for an expansion of UNSCR 1540 to address the growing influence of\nAI technologies in the development, dissemination, and potential misuse of\nWMDs, urging the creation of a governance framework to mitigate these emerging\nrisks.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "5 pages, no figures, references in the footnotes",
    "pdf_url": "http://arxiv.org/pdf/2410.08216v1",
    "published_date": "2024-09-25 12:41:12 UTC",
    "updated_date": "2024-09-25 12:41:12 UTC"
  },
  {
    "arxiv_id": "2409.16872v2",
    "title": "Ethical and Scalable Automation: A Governance and Compliance Framework for Business Applications",
    "authors": [
      "Haocheng Lin"
    ],
    "abstract": "The popularisation of applying AI in businesses poses significant challenges\nrelating to ethical principles, governance, and legal compliance. Although\nbusinesses have embedded AI into their day-to-day processes, they lack a\nunified approach for mitigating its potential risks. This paper introduces a\nframework ensuring that AI must be ethical, controllable, viable, and\ndesirable. Balancing these factors ensures the design of a framework that\naddresses its trade-offs, such as balancing performance against explainability.\nA successful framework provides practical advice for businesses to meet\nregulatory requirements in sectors such as finance and healthcare, where it is\ncritical to comply with standards like GPDR and the EU AI Act. Different case\nstudies validate this framework by integrating AI in both academic and\npractical environments. For instance, large language models are cost-effective\nalternatives for generating synthetic opinions that emulate attitudes to\nenvironmental issues. These case studies demonstrate how having a structured\nframework could enhance transparency and maintain performance levels as shown\nfrom the alignment between synthetic and expected distributions. This alignment\nis quantified using metrics like Chi-test scores, normalized mutual\ninformation, and Jaccard indexes. Future research should explore the\nframework's empirical validation in diverse industrial settings further,\nensuring the model's scalability and adaptability.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "The current version improves significantly by integrating ethical\n  frameworks, expanding methodology and case studies, enhancing scalability and\n  ethical-legal alignment, acknowledging prior work, and offering clearer\n  structure and practical relevance",
    "pdf_url": "http://arxiv.org/pdf/2409.16872v2",
    "published_date": "2024-09-25 12:39:28 UTC",
    "updated_date": "2024-12-05 20:51:04 UTC"
  },
  {
    "arxiv_id": "2409.16867v2",
    "title": "Multi-objective Evolution of Heuristic Using Large Language Model",
    "authors": [
      "Shunyu Yao",
      "Fei Liu",
      "Xi Lin",
      "Zhichao Lu",
      "Zhenkun Wang",
      "Qingfu Zhang"
    ],
    "abstract": "Heuristics are commonly used to tackle various search and optimization\nproblems. Design heuristics usually require tedious manual crafting with domain\nknowledge. Recent works have incorporated Large Language Models (LLMs) into\nautomatic heuristic search, leveraging their powerful language and coding\ncapacity. However, existing research focuses on the optimal performance on the\ntarget problem as the sole objective, neglecting other criteria such as\nefficiency and scalability, which are vital in practice. To tackle this\nchallenge, we propose to model the heuristic search as a multi-objective\noptimization problem and consider introducing additional practical criteria\nbeyond optimal performance. Due to the complexity of the search space,\nconventional multi-objective optimization methods struggle to effectively\nhandle LLM-based multi-objective heuristic search. We propose the first\nLLM-based multi-objective heuristic search framework, Multi-objective Evolution\nof Heuristic (MEoH), which integrates LLMs in a zero-shot manner to generate a\nnon-dominated set of heuristics to meet multiple design criteria. We design a\nnew dominance-dissimilarity mechanism for effective population management and\nselection, which incorporates both code dissimilarity in the search space and\ndominance in the objective space. MEoH is demonstrated in two well-known\ncombinatorial optimization problems: the online Bin Packing Problem (BPP) and\nthe Traveling Salesman Problem (TSP). The results indicate that a variety of\nelite heuristics are automatically generated in a single run, offering more\ntrade-off options than the existing methods. It successfully achieves\ncompetitive or superior performance while improving efficiency up to 10 times.\nMoreover, we also observe that the multi-objective search introduces novel\ninsights into heuristic design and leads to the discovery of diverse\nheuristics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16867v2",
    "published_date": "2024-09-25 12:32:41 UTC",
    "updated_date": "2025-02-04 05:06:39 UTC"
  },
  {
    "arxiv_id": "2409.16860v1",
    "title": "The Role of Language Models in Modern Healthcare: A Comprehensive Review",
    "authors": [
      "Amna Khalid",
      "Ayma Khalid",
      "Umar Khalid"
    ],
    "abstract": "The application of large language models (LLMs) in healthcare has gained\nsignificant attention due to their ability to process complex medical data and\nprovide insights for clinical decision-making. These models have demonstrated\nsubstantial capabilities in understanding and generating natural language,\nwhich is crucial for medical documentation, diagnostics, and patient\ninteraction. This review examines the trajectory of language models from their\nearly stages to the current state-of-the-art LLMs, highlighting their strengths\nin healthcare applications and discussing challenges such as data privacy,\nbias, and ethical considerations. The potential of LLMs to enhance healthcare\ndelivery is explored, alongside the necessary steps to ensure their ethical and\neffective integration into medical practice.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16860v1",
    "published_date": "2024-09-25 12:15:15 UTC",
    "updated_date": "2024-09-25 12:15:15 UTC"
  },
  {
    "arxiv_id": "2409.16854v1",
    "title": "Dispute resolution in legal mediation with quantitative argumentation",
    "authors": [
      "Xiao Chi"
    ],
    "abstract": "Mediation is often treated as an extension of negotiation, without taking\ninto account the unique role that norms and facts play in legal mediation.\nAdditionally, current approaches for updating argument acceptability in\nresponse to changing variables frequently require the introduction of new\narguments or the removal of existing ones, which can be inefficient and\ncumbersome in decision-making processes within legal disputes. In this paper,\nour contribution is two-fold. First, we introduce a QuAM (Quantitative\nArgumentation Mediate) framework, which integrates the parties' knowledge and\nthe mediator's knowledge, including facts and legal norms, when determining the\nacceptability of a mediation goal. Second, we develop a new formalism to model\nthe relationship between the acceptability of a goal argument and the values\nassigned to a variable associated with the argument. We use a real-world legal\nmediation as a running example to illustrate our approach.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16854v1",
    "published_date": "2024-09-25 12:05:46 UTC",
    "updated_date": "2024-09-25 12:05:46 UTC"
  },
  {
    "arxiv_id": "2409.16849v1",
    "title": "Exposing Assumptions in AI Benchmarks through Cognitive Modelling",
    "authors": [
      "Jonathan H. Rystrøm",
      "Kenneth C. Enevoldsen"
    ],
    "abstract": "Cultural AI benchmarks often rely on implicit assumptions about measured\nconstructs, leading to vague formulations with poor validity and unclear\ninterrelations. We propose exposing these assumptions using explicit cognitive\nmodels formulated as Structural Equation Models. Using cross-lingual alignment\ntransfer as an example, we show how this approach can answer key research\nquestions and identify missing datasets. This framework grounds benchmark\nconstruction theoretically and guides dataset development to improve construct\nmeasurement. By embracing transparency, we move towards more rigorous,\ncumulative AI evaluation science, challenging researchers to critically examine\ntheir assessment foundations.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.16849v1",
    "published_date": "2024-09-25 11:55:02 UTC",
    "updated_date": "2024-09-25 11:55:02 UTC"
  },
  {
    "arxiv_id": "2409.16830v1",
    "title": "OffRIPP: Offline RL-based Informative Path Planning",
    "authors": [
      "Srikar Babu Gadipudi",
      "Srujan Deolasee",
      "Siva Kailas",
      "Wenhao Luo",
      "Katia Sycara",
      "Woojun Kim"
    ],
    "abstract": "Informative path planning (IPP) is a crucial task in robotics, where agents\nmust design paths to gather valuable information about a target environment\nwhile adhering to resource constraints. Reinforcement learning (RL) has been\nshown to be effective for IPP, however, it requires environment interactions,\nwhich are risky and expensive in practice. To address this problem, we propose\nan offline RL-based IPP framework that optimizes information gain without\nrequiring real-time interaction during training, offering safety and\ncost-efficiency by avoiding interaction, as well as superior performance and\nfast computation during execution -- key advantages of RL. Our framework\nleverages batch-constrained reinforcement learning to mitigate extrapolation\nerrors, enabling the agent to learn from pre-collected datasets generated by\narbitrary algorithms. We validate the framework through extensive simulations\nand real-world experiments. The numerical results show that our framework\noutperforms the baselines, demonstrating the effectiveness of the proposed\napproach.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 6 figures, submitted to ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.16830v1",
    "published_date": "2024-09-25 11:30:59 UTC",
    "updated_date": "2024-09-25 11:30:59 UTC"
  },
  {
    "arxiv_id": "2409.16828v3",
    "title": "On the role of Artificial Intelligence methods in modern force-controlled manufacturing robotic tasks",
    "authors": [
      "Vincenzo Petrone",
      "Enrico Ferrentino",
      "Pasquale Chiacchio"
    ],
    "abstract": "This position paper explores the integration of Artificial Intelligence (AI)\ninto force-controlled robotic tasks within the scope of advanced manufacturing,\na cornerstone of Industry 4.0. AI's role in enhancing robotic manipulators -\nkey drivers in the Fourth Industrial Revolution - is rapidly leading to\nsignificant innovations in smart manufacturing. The objective of this article\nis to frame these innovations in practical force-controlled applications - e.g.\ndeburring, polishing, and assembly tasks like peg-in-hole (PiH) - highlighting\ntheir necessity for maintaining high-quality production standards. By reporting\non recent AI-based methodologies, this article contrasts them and identifies\ncurrent challenges to be addressed in future research. The analysis concludes\nwith a perspective on future research directions, emphasizing the need for\ncommon performance metrics to validate AI techniques, integration of various\nenhancements for performance optimization, and the importance of validating\nthem in relevant scenarios. These future directions aim to provide consistency\nwith already adopted approaches, so as to be compatible with manufacturing\nstandards, increasing the relevance of AI-driven methods in both academic and\nindustrial contexts.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "In Proceedings of the 21st International Conference on Informatics in\n  Control, Automation and Robotics - Volume 1: ICINCO, 392-399, 2024 , Porto,\n  Portugal",
    "pdf_url": "http://arxiv.org/pdf/2409.16828v3",
    "published_date": "2024-09-25 11:29:26 UTC",
    "updated_date": "2025-01-09 14:10:38 UTC"
  },
  {
    "arxiv_id": "2409.16826v1",
    "title": "Learning phase-space flows using time-discrete implicit Runge-Kutta PINNs",
    "authors": [
      "Álvaro Fernández Corral",
      "Nicolás Mendoza",
      "Armin Iske",
      "Andrey Yachmenev",
      "Jochen Küpper"
    ],
    "abstract": "We present a computational framework for obtaining multidimensional\nphase-space solutions of systems of non-linear coupled differential equations,\nusing high-order implicit Runge-Kutta Physics- Informed Neural Networks\n(IRK-PINNs) schemes. Building upon foundational work originally solving\ndifferential equations for fields depending on coordinates [J. Comput. Phys.\n378, 686 (2019)], we adapt the scheme to a context where the coordinates are\ntreated as functions. This modification enables us to efficiently solve\nequations of motion for a particle in an external field. Our scheme is\nparticularly useful for explicitly time-independent and periodic fields. We\napply this approach to successfully solve the equations of motion for a mass\nparticle placed in a central force field and a charged particle in a periodic\nelectric field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.DS",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 4 figures, published in the International Conference on\n  Scientific Computing and Machine Learning, see http://scml.jp",
    "pdf_url": "http://arxiv.org/pdf/2409.16826v1",
    "published_date": "2024-09-25 11:24:18 UTC",
    "updated_date": "2024-09-25 11:24:18 UTC"
  },
  {
    "arxiv_id": "2409.16824v2",
    "title": "Uncertainty Representations in State-Space Layers for Deep Reinforcement Learning under Partial Observability",
    "authors": [
      "Carlos E. Luis",
      "Alessandro G. Bottero",
      "Julia Vinogradska",
      "Felix Berkenkamp",
      "Jan Peters"
    ],
    "abstract": "Optimal decision-making under partial observability requires reasoning about\nthe uncertainty of the environment's hidden state. However, most reinforcement\nlearning architectures handle partial observability with sequence models that\nhave no internal mechanism to incorporate uncertainty in their hidden state\nrepresentation, such as recurrent neural networks, deterministic state-space\nmodels and transformers. Inspired by advances in probabilistic world models for\nreinforcement learning, we propose a standalone Kalman filter layer that\nperforms closed-form Gaussian inference in linear state-space models and train\nit end-to-end within a model-free architecture to maximize returns. Similar to\nefficient linear recurrent layers, the Kalman filter layer processes sequential\ndata using a parallel scan, which scales logarithmically with the sequence\nlength. By design, Kalman filter layers are a drop-in replacement for other\nrecurrent layers in standard model-free architectures, but importantly they\ninclude an explicit mechanism for probabilistic filtering of the latent state\nrepresentation. Experiments in a wide variety of tasks with partial\nobservability show that Kalman filter layers excel in problems where\nuncertainty reasoning is key for decision-making, outperforming other stateful\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "TMLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.16824v2",
    "published_date": "2024-09-25 11:22:29 UTC",
    "updated_date": "2025-02-18 23:40:35 UTC"
  },
  {
    "arxiv_id": "2409.16821v1",
    "title": "XAI-guided Insulator Anomaly Detection for Imbalanced Datasets",
    "authors": [
      "Maximilian Andreas Hoefler",
      "Karsten Mueller",
      "Wojciech Samek"
    ],
    "abstract": "Power grids serve as a vital component in numerous industries, seamlessly\ndelivering electrical energy to industrial processes and technologies, making\ntheir safe and reliable operation indispensable. However, powerlines can be\nhard to inspect due to difficult terrain or harsh climatic conditions.\nTherefore, unmanned aerial vehicles are increasingly deployed to inspect\npowerlines, resulting in a substantial stream of visual data which requires\nswift and accurate processing. Deep learning methods have become widely popular\nfor this task, proving to be a valuable asset in fault detection. In\nparticular, the detection of insulator defects is crucial for predicting\npowerline failures, since their malfunction can lead to transmission\ndisruptions. It is therefore of great interest to continuously maintain and\nrigorously inspect insulator components. In this work we propose a novel\npipeline to tackle this task. We utilize state-of-the-art object detection to\ndetect and subsequently classify individual insulator anomalies. Our approach\naddresses dataset challenges such as imbalance and motion-blurred images\nthrough a fine-tuning methodology which allows us to alter the classification\nfocus of the model by increasing the classification accuracy of anomalous\ninsulators. In addition, we employ explainable-AI tools for precise\nlocalization and explanation of anomalies. This proposed method contributes to\nthe field of anomaly detection, particularly vision-based industrial inspection\nand predictive maintenance. We significantly improve defect detection accuracy\nby up to 13%, while also offering a detailed analysis of model\nmis-classifications and localization quality, showcasing the potential of our\nmethod on real-world data.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted as a workshop paper at ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.16821v1",
    "published_date": "2024-09-25 11:19:42 UTC",
    "updated_date": "2024-09-25 11:19:42 UTC"
  },
  {
    "arxiv_id": "2409.16813v2",
    "title": "PeerArg: Argumentative Peer Review with LLMs",
    "authors": [
      "Purin Sukpanichnant",
      "Anna Rapberger",
      "Francesca Toni"
    ],
    "abstract": "Peer review is an essential process to determine the quality of papers\nsubmitted to scientific conferences or journals. However, it is subjective and\nprone to biases. Several studies have been conducted to apply techniques from\nNLP to support peer review, but they are based on black-box techniques and\ntheir outputs are difficult to interpret and trust. In this paper, we propose a\nnovel pipeline to support and understand the reviewing and decision-making\nprocesses of peer review: the PeerArg system combining LLMs with methods from\nknowledge representation. PeerArg takes in input a set of reviews for a paper\nand outputs the paper acceptance prediction. We evaluate the performance of the\nPeerArg pipeline on three different datasets, in comparison with a novel\nend-2-end LLM that uses few-shot learning to predict paper acceptance given\nreviews. The results indicate that the end-2-end LLM is capable of predicting\npaper acceptance from reviews, but a variant of the PeerArg pipeline\noutperforms this LLM.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)",
    "pdf_url": "http://arxiv.org/pdf/2409.16813v2",
    "published_date": "2024-09-25 11:09:39 UTC",
    "updated_date": "2025-02-18 16:36:25 UTC"
  },
  {
    "arxiv_id": "2410.08214v1",
    "title": "Embedding an ANN-Based Crystal Plasticity Model into the Finite Element Framework using an ABAQUS User-Material Subroutine",
    "authors": [
      "Yuqing He",
      "Yousef Heider",
      "Bernd Markert"
    ],
    "abstract": "This manuscript presents a practical method for incorporating trained Neural\nNetworks (NNs) into the Finite Element (FE) framework using a user material\n(UMAT) subroutine. The work exemplifies crystal plasticity, a complex inelastic\nnon-linear path-dependent material response, with a wide range of applications\nin ABAQUS UMAT. However, this approach can be extended to other material\nbehaviors and FE tools. The use of a UMAT subroutine serves two main purposes:\n(1) it predicts and updates the stress or other mechanical properties of\ninterest directly from the strain history; (2) it computes the Jacobian matrix\neither through backpropagation or numerical differentiation, which plays an\nessential role in the solution convergence. By implementing NNs in a UMAT\nsubroutine, a trained machine learning model can be employed as a data-driven\nconstitutive law within the FEM framework, preserving multiscale information\nthat conventional constitutive laws often neglect or average. The versatility\nof this method makes it a powerful tool for integrating machine learning into\nmechanical simulation. While this approach is expected to provide higher\naccuracy in reproducing realistic material behavior, the reliability of the\nsolution process and the convergence conditions must be paid special attention.\nWhile the theory of the model is explained in [Heider et al. 2020], exemplary\nsource code is also made available for interested readers\n[https://doi.org/10.25835/6n5uu50y]",
    "categories": [
      "physics.comp-ph",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "11 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.08214v1",
    "published_date": "2024-09-25 10:47:18 UTC",
    "updated_date": "2024-09-25 10:47:18 UTC"
  },
  {
    "arxiv_id": "2409.16799v1",
    "title": "Large Language Model Predicts Above Normal All India Summer Monsoon Rainfall in 2024",
    "authors": [
      "Ujjawal Sharma",
      "Madhav Biyani",
      "Akhil Dev Suresh",
      "Debi Prasad Bhuyan",
      "Saroj Kanta Mishra",
      "Tanmoy Chakraborty"
    ],
    "abstract": "Reliable prediction of the All India Summer Monsoon Rainfall (AISMR) is\npivotal for informed policymaking for the country, impacting the lives of\nbillions of people. However, accurate simulation of AISMR has been a persistent\nchallenge due to the complex interplay of various muti-scale factors and the\ninherent variability of the monsoon system. This research focuses on adapting\nand fine-tuning the latest LLM model, PatchTST, to accurately predict AISMR\nwith a lead time of three months. The fine-tuned PatchTST model, trained with\nhistorical AISMR data, the Ni\\~no3.4 index, and categorical Indian Ocean Dipole\nvalues, outperforms several popular neural network models and statistical\nmodels. This fine-tuned LLM model exhibits an exceptionally low RMSE percentage\nof 0.07% and a Spearman correlation of 0.976. This is particularly impressive,\nsince it is nearly 80% more accurate than the best-performing NN models. The\nmodel predicts an above-normal monsoon for the year 2024, with an accumulated\nrainfall of 921.6 mm in the month of June-September for the entire country.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "cs.AI",
    "comment": "3 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.16799v1",
    "published_date": "2024-09-25 10:32:18 UTC",
    "updated_date": "2024-09-25 10:32:18 UTC"
  },
  {
    "arxiv_id": "2409.16797v1",
    "title": "Scalable Ensemble Diversification for OOD Generalization and Detection",
    "authors": [
      "Alexander Rubinstein",
      "Luca Scimeca",
      "Damien Teney",
      "Seong Joon Oh"
    ],
    "abstract": "Training a diverse ensemble of models has several practical applications such\nas providing candidates for model selection with better out-of-distribution\n(OOD) generalization, and enabling the detection of OOD samples via Bayesian\nprinciples. An existing approach to diverse ensemble training encourages the\nmodels to disagree on provided OOD samples. However, the approach is\ncomputationally expensive and it requires well-separated ID and OOD examples,\nsuch that it has only been demonstrated in small-scale settings.\n  $\\textbf{Method.}$ This work presents a method for Scalable Ensemble\nDiversification (SED) applicable to large-scale settings (e.g. ImageNet) that\ndoes not require OOD samples. Instead, SED identifies hard training samples on\nthe fly and encourages the ensemble members to disagree on these. To improve\nscaling, we show how to avoid the expensive computations in existing methods of\nexhaustive pairwise disagreements across models.\n  $\\textbf{Results.}$ We evaluate the benefits of diversification with\nexperiments on ImageNet. First, for OOD generalization, we observe large\nbenefits from the diversification in multiple settings including output-space\n(classical) ensembles and weight-space ensembles (model soups). Second, for OOD\ndetection, we turn the diversity of ensemble hypotheses into a novel\nuncertainty score estimator that surpasses a large number of OOD detection\nbaselines.\n  Code is available here:\nhttps://github.com/AlexanderRubinstein/diverse-universe-public.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2409.16797v1",
    "published_date": "2024-09-25 10:30:24 UTC",
    "updated_date": "2024-09-25 10:30:24 UTC"
  },
  {
    "arxiv_id": "2409.16791v3",
    "title": "Symbolic State Partitioning for Reinforcement Learning",
    "authors": [
      "Mohsen Ghaffari",
      "Mahsa Varshosaz",
      "Einar Broch Johnsen",
      "Andrzej Wąsowski"
    ],
    "abstract": "Tabular reinforcement learning methods cannot operate directly on continuous\nstate spaces. One solution for this problem is to partition the state space. A\ngood partitioning enables generalization during learning and more efficient\nexploitation of prior experiences. Consequently, the learning process becomes\nfaster and produces more reliable policies. However, partitioning introduces\napproximation, which is particularly harmful in the presence of nonlinear\nrelations between state components. An ideal partition should be as coarse as\npossible, while capturing the key structure of the state space for the given\nproblem. This work extracts partitions from the environment dynamics by\nsymbolic execution. We show that symbolic partitioning improves state space\ncoverage with respect to environmental behavior and allows reinforcement\nlearning to perform better for sparse rewards. We evaluate symbolic state space\npartitioning with respect to precision, scalability, learning agent performance\nand state space coverage for the learnt policies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16791v3",
    "published_date": "2024-09-25 10:09:47 UTC",
    "updated_date": "2025-02-04 09:22:06 UTC"
  },
  {
    "arxiv_id": "2409.16787v1",
    "title": "Enhancing Feature Selection and Interpretability in AI Regression Tasks Through Feature Attribution",
    "authors": [
      "Alexander Hinterleitner",
      "Thomas Bartz-Beielstein",
      "Richard Schulz",
      "Sebastian Spengler",
      "Thomas Winter",
      "Christoph Leitenmeier"
    ],
    "abstract": "Research in Explainable Artificial Intelligence (XAI) is increasing, aiming\nto make deep learning models more transparent. Most XAI methods focus on\njustifying the decisions made by Artificial Intelligence (AI) systems in\nsecurity-relevant applications. However, relatively little attention has been\ngiven to using these methods to improve the performance and robustness of deep\nlearning algorithms. Additionally, much of the existing XAI work primarily\naddresses classification problems. In this study, we investigate the potential\nof feature attribution methods to filter out uninformative features in input\ndata for regression problems, thereby improving the accuracy and stability of\npredictions. We introduce a feature selection pipeline that combines Integrated\nGradients with k-means clustering to select an optimal set of variables from\nthe initial data space. To validate the effectiveness of this approach, we\napply it to a real-world industrial problem - blade vibration analysis in the\ndevelopment process of turbo machinery.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68",
      "I.2.0"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16787v1",
    "published_date": "2024-09-25 09:50:51 UTC",
    "updated_date": "2024-09-25 09:50:51 UTC"
  },
  {
    "arxiv_id": "2409.16783v1",
    "title": "Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction",
    "authors": [
      "Jinchuan Zhang",
      "Yan Zhou",
      "Yaxin Liu",
      "Ziming Li",
      "Songlin Hu"
    ],
    "abstract": "Automated red teaming is an effective method for identifying misaligned\nbehaviors in large language models (LLMs). Existing approaches, however, often\nfocus primarily on improving attack success rates while overlooking the need\nfor comprehensive test case coverage. Additionally, most of these methods are\nlimited to single-turn red teaming, failing to capture the multi-turn dynamics\nof real-world human-machine interactions. To overcome these limitations, we\npropose HARM (Holistic Automated Red teaMing), which scales up the diversity of\ntest cases using a top-down approach based on an extensible, fine-grained risk\ntaxonomy. Our method also leverages a novel fine-tuning strategy and\nreinforcement learning techniques to facilitate multi-turn adversarial probing\nin a human-like manner. Experimental results demonstrate that our framework\nenables a more systematic understanding of model vulnerabilities and offers\nmore targeted guidance for the alignment process.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 camera ready version",
    "pdf_url": "http://arxiv.org/pdf/2409.16783v1",
    "published_date": "2024-09-25 09:44:48 UTC",
    "updated_date": "2024-09-25 09:44:48 UTC"
  },
  {
    "arxiv_id": "2409.16779v1",
    "title": "LLaMa-SciQ: An Educational Chatbot for Answering Science MCQ",
    "authors": [
      "Marc-Antoine Allard",
      "Matin Ansaripour",
      "Maria Yuffa",
      "Paul Teiletche"
    ],
    "abstract": "Large Language Models (LLMs) often struggle with tasks requiring mathematical\nreasoning, particularly multiple-choice questions (MCQs). To address this\nissue, we developed LLaMa-SciQ, an educational chatbot designed to assist\ncollege students in solving and understanding MCQs in STEM fields. We begin by\nfine-tuning and aligning the models to human preferences. After comparing the\nperformance of Mistral-7B and LLaMa-8B, we selected the latter as the base\nmodel due to its higher evaluation accuracy. To further enhance accuracy, we\nimplement Retrieval-Augmented Generation (RAG) and apply quantization to\ncompress the model, reducing inference time and increasing accessibility for\nstudents. For mathematical reasoning, LLaMa-SciQ achieved 74.5% accuracy on the\nGSM8k dataset and 30% on the MATH dataset. However, RAG does not improve\nperformance and even reduces it, likely due to retriever issues or the model's\nunfamiliarity with context. Despite this, the quantized model shows only a 5%\nloss in performance, demonstrating significant efficiency improvements.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16779v1",
    "published_date": "2024-09-25 09:41:46 UTC",
    "updated_date": "2024-09-25 09:41:46 UTC"
  },
  {
    "arxiv_id": "2409.16769v1",
    "title": "Super Level Sets and Exponential Decay: A Synergistic Approach to Stable Neural Network Training",
    "authors": [
      "Jatin Chaudhary",
      "Dipak Nidhi",
      "Jukka Heikkonen",
      "Haari Merisaari",
      "Rajiv Kanth"
    ],
    "abstract": "The objective of this paper is to enhance the optimization process for neural\nnetworks by developing a dynamic learning rate algorithm that effectively\nintegrates exponential decay and advanced anti-overfitting strategies. Our\nprimary contribution is the establishment of a theoretical framework where we\ndemonstrate that the optimization landscape, under the influence of our\nalgorithm, exhibits unique stability characteristics defined by Lyapunov\nstability principles. Specifically, we prove that the superlevel sets of the\nloss function, as influenced by our adaptive learning rate, are always\nconnected, ensuring consistent training dynamics. Furthermore, we establish the\n\"equiconnectedness\" property of these superlevel sets, which maintains uniform\nstability across varying training conditions and epochs. This paper contributes\nto the theoretical understanding of dynamic learning rate mechanisms in neural\nnetworks and also pave the way for the development of more efficient and\nreliable neural optimization techniques. This study intends to formalize and\nvalidate the equiconnectedness of loss function as superlevel sets in the\ncontext of neural network training, opening newer avenues for future research\nin adaptive machine learning algorithms. We leverage previous theoretical\ndiscoveries to propose training mechanisms that can effectively handle complex\nand high-dimensional data landscapes, particularly in applications requiring\nhigh precision and reliability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16769v1",
    "published_date": "2024-09-25 09:27:17 UTC",
    "updated_date": "2024-09-25 09:27:17 UTC"
  },
  {
    "arxiv_id": "2409.16765v1",
    "title": "MaViLS, a Benchmark Dataset for Video-to-Slide Alignment, Assessing Baseline Accuracy with a Multimodal Alignment Algorithm Leveraging Speech, OCR, and Visual Features",
    "authors": [
      "Katharina Anderer",
      "Andreas Reich",
      "Matthias Wölfel"
    ],
    "abstract": "This paper presents a benchmark dataset for aligning lecture videos with\ncorresponding slides and introduces a novel multimodal algorithm leveraging\nfeatures from speech, text, and images. It achieves an average accuracy of 0.82\nin comparison to SIFT (0.56) while being approximately 11 times faster. Using\ndynamic programming the algorithm tries to determine the optimal slide\nsequence. The results show that penalizing slide transitions increases\naccuracy. Features obtained via optical character recognition (OCR) contribute\nthe most to a high matching accuracy, followed by image features. The findings\nhighlight that audio transcripts alone provide valuable information for\nalignment and are beneficial if OCR data is lacking. Variations in matching\naccuracy across different lectures highlight the challenges associated with\nvideo quality and lecture style. The novel multimodal algorithm demonstrates\nrobustness to some of these challenges, underscoring the potential of the\napproach.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16765v1",
    "published_date": "2024-09-25 09:24:42 UTC",
    "updated_date": "2024-09-25 09:24:42 UTC"
  },
  {
    "arxiv_id": "2409.16764v2",
    "title": "Offline and Distributional Reinforcement Learning for Radio Resource Management",
    "authors": [
      "Eslam Eldeeb",
      "Hirley Alves"
    ],
    "abstract": "Reinforcement learning (RL) has proved to have a promising role in future\nintelligent wireless networks. Online RL has been adopted for radio resource\nmanagement (RRM), taking over traditional schemes. However, due to its reliance\non online interaction with the environment, its role becomes limited in\npractical, real-world problems where online interaction is not feasible. In\naddition, traditional RL stands short in front of the uncertainties and risks\nin real-world stochastic environments. In this manner, we propose an offline\nand distributional RL scheme for the RRM problem, enabling offline training\nusing a static dataset without any interaction with the environment and\nconsidering the sources of uncertainties using the distributions of the return.\nSimulation results demonstrate that the proposed scheme outperforms\nconventional resource management models. In addition, it is the only scheme\nthat surpasses online RL with a 10 % gain over online RL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16764v2",
    "published_date": "2024-09-25 09:22:23 UTC",
    "updated_date": "2025-01-23 12:00:38 UTC"
  },
  {
    "arxiv_id": "2409.16735v1",
    "title": "GB-RVFL: Fusion of Randomized Neural Network and Granular Ball Computing",
    "authors": [
      "M. Sajid",
      "A. Quadir",
      "M. Tanveer"
    ],
    "abstract": "The random vector functional link (RVFL) network is a prominent\nclassification model with strong generalization ability. However, RVFL treats\nall samples uniformly, ignoring whether they are pure or noisy, and its\nscalability is limited due to the need for inverting the entire training\nmatrix. To address these issues, we propose granular ball RVFL (GB-RVFL) model,\nwhich uses granular balls (GBs) as inputs instead of training samples. This\napproach enhances scalability by requiring only the inverse of the GB center\nmatrix and improves robustness against noise and outliers through the coarse\ngranularity of GBs. Furthermore, RVFL overlooks the dataset's geometric\nstructure. To address this, we propose graph embedding GB-RVFL (GE-GB-RVFL)\nmodel, which fuses granular computing and graph embedding (GE) to preserve the\ntopological structure of GBs. The proposed GB-RVFL and GE-GB-RVFL models are\nevaluated on KEEL, UCI, NDC and biomedical datasets, demonstrating superior\nperformance compared to baseline models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16735v1",
    "published_date": "2024-09-25 08:33:01 UTC",
    "updated_date": "2024-09-25 08:33:01 UTC"
  },
  {
    "arxiv_id": "2409.16730v1",
    "title": "Non-stationary BERT: Exploring Augmented IMU Data For Robust Human Activity Recognition",
    "authors": [
      "Ning Sun",
      "Yufei Wang",
      "Yuwei Zhang",
      "Jixiang Wan",
      "Shenyue Wang",
      "Ping Liu",
      "Xudong Zhang"
    ],
    "abstract": "Human Activity Recognition (HAR) has gained great attention from researchers\ndue to the popularity of mobile devices and the need to observe users' daily\nactivity data for better human-computer interaction. In this work, we collect a\nhuman activity recognition dataset called OPPOHAR consisting of phone IMU data.\nTo facilitate the employment of HAR system in mobile phone and to achieve\nuser-specific activity recognition, we propose a novel light-weight network\ncalled Non-stationary BERT with a two-stage training method. We also propose a\nsimple yet effective data augmentation method to explore the deeper\nrelationship between the accelerator and gyroscope data from the IMU. The\nnetwork achieves the state-of-the-art performance testing on various activity\nrecognition datasets and the data augmentation method demonstrates its wide\napplicability.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16730v1",
    "published_date": "2024-09-25 08:28:54 UTC",
    "updated_date": "2024-09-25 08:28:54 UTC"
  },
  {
    "arxiv_id": "2409.16721v2",
    "title": "Grading and Anomaly Detection for Automated Retinal Image Analysis using Deep Learning",
    "authors": [
      "Syed Mohd Faisal Malik",
      "Md Tabrez Nafis",
      "Mohd Abdul Ahad",
      "Safdar Tanweer"
    ],
    "abstract": "The significant portion of diabetic patients was affected due to major\nblindness caused by Diabetic retinopathy (DR). For diabetic retinopathy, lesion\nsegmentation, and detection the comprehensive examination is delved into the\ndeep learning techniques application. The study conducted a systematic\nliterature review using the PRISMA analysis and 62 articles has been\ninvestigated in the research. By including CNN-based models for DR grading, and\nfeature fusion several deep-learning methodologies are explored during the\nstudy. For enhancing effectiveness in classification accuracy and robustness\nthe data augmentation and ensemble learning strategies are scrutinized. By\ndemonstrating the superior performance compared to individual models the\nefficacy of ensemble learning methods is investigated. The potential ensemble\napproaches in DR diagnosis are shown by the integration of multiple pre-trained\nnetworks with custom classifiers that yield high specificity. The diverse\ndeep-learning techniques that are employed for detecting DR lesions are\ndiscussed within the diabetic retinopathy lesions segmentation and detection\nsection. By emphasizing the requirement for continued research and integration\ninto clinical practice deep learning shows promise for personalized healthcare\nand early detection of diabetics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Diabetic retinopathy, segmentation, images on retinal fundus,\n  convolutional neural network",
    "pdf_url": "http://arxiv.org/pdf/2409.16721v2",
    "published_date": "2024-09-25 08:13:39 UTC",
    "updated_date": "2024-11-19 07:01:03 UTC"
  },
  {
    "arxiv_id": "2409.16718v2",
    "title": "Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification",
    "authors": [
      "Ming Li",
      "Jike Zhong",
      "Chenxin Li",
      "Liuzhuozheng Li",
      "Nie Lin",
      "Masashi Sugiyama"
    ],
    "abstract": "Recent advances in fine-tuning Vision-Language Models (VLMs) have witnessed\nthe success of prompt tuning and adapter tuning, while the classic model\nfine-tuning on inherent parameters seems to be overlooked. It is believed that\nfine-tuning the parameters of VLMs with few-shot samples corrupts the\npre-trained knowledge since fine-tuning the CLIP model even degrades\nperformance. In this paper, we revisit this viewpoint, and propose a new\nperspective: fine-tuning the specific parameters instead of all will uncover\nthe power of classic model fine-tuning on VLMs. Through our meticulous study,\nwe propose ClipFit, a simple yet effective method to fine-tune CLIP without\nintroducing any overhead of extra parameters. We demonstrate that by only\nfine-tuning the specific bias terms and normalization layers, ClipFit can\nimprove the performance of zero-shot CLIP by 7.27\\% average harmonic mean\naccuracy. Lastly, to understand how fine-tuning in CLIPFit affects the\npre-trained models, we conducted extensive experimental analyses w.r.t. changes\nin internal parameters and representations. We found that low-level text bias\nlayers and the first layer normalization layer change much more than other\nlayers. The code is available at \\url{https://github.com/minglllli/CLIPFit}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "EMNLP 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2409.16718v2",
    "published_date": "2024-09-25 08:07:18 UTC",
    "updated_date": "2024-11-19 09:27:37 UTC"
  },
  {
    "arxiv_id": "2409.16706v2",
    "title": "Pix2Next: Leveraging Vision Foundation Models for RGB to NIR Image Translation",
    "authors": [
      "Youngwan Jin",
      "Incheol Park",
      "Hanbin Song",
      "Hyeongjin Ju",
      "Yagiz Nalcakan",
      "Shiho Kim"
    ],
    "abstract": "This paper proposes Pix2Next, a novel image-to-image translation framework\ndesigned to address the challenge of generating high-quality Near-Infrared\n(NIR) images from RGB inputs. Our approach leverages a state-of-the-art Vision\nFoundation Model (VFM) within an encoder-decoder architecture, incorporating\ncross-attention mechanisms to enhance feature integration. This design captures\ndetailed global representations and preserves essential spectral\ncharacteristics, treating RGB-to-NIR translation as more than a simple domain\ntransfer problem. A multi-scale PatchGAN discriminator ensures realistic image\ngeneration at various detail levels, while carefully designed loss functions\ncouple global context understanding with local feature preservation. We\nperformed experiments on the RANUS dataset to demonstrate Pix2Next's advantages\nin quantitative metrics and visual quality, improving the FID score by 34.81%\ncompared to existing methods. Furthermore, we demonstrate the practical utility\nof Pix2Next by showing improved performance on a downstream object detection\ntask using generated NIR data to augment limited real NIR datasets. The\nproposed approach enables the scaling up of NIR datasets without additional\ndata acquisition or annotation efforts, potentially accelerating advancements\nin NIR-based computer vision applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages,12 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.16706v2",
    "published_date": "2024-09-25 07:51:47 UTC",
    "updated_date": "2025-04-23 07:34:25 UTC"
  },
  {
    "arxiv_id": "2409.16694v2",
    "title": "A Survey of Low-bit Large Language Models: Basics, Systems, and Algorithms",
    "authors": [
      "Ruihao Gong",
      "Yifu Ding",
      "Zining Wang",
      "Chengtao Lv",
      "Xingyu Zheng",
      "Jinyang Du",
      "Haotong Qin",
      "Jinyang Guo",
      "Michele Magno",
      "Xianglong Liu"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable advancements in natural\nlanguage processing, showcasing exceptional performance across various tasks.\nHowever, the expensive memory and computational requirements present\nsignificant challenges for their practical deployment. Low-bit quantization has\nemerged as a critical approach to mitigate these challenges by reducing the\nbit-width of model parameters, activations, and gradients, thus decreasing\nmemory usage and computational demands. This paper presents a comprehensive\nsurvey of low-bit quantization methods tailored for LLMs, covering the\nfundamental principles, system implementations, and algorithmic strategies. An\noverview of basic concepts and new data formats specific to low-bit LLMs is\nfirst introduced, followed by a review of frameworks and systems that\nfacilitate low-bit LLMs across various hardware platforms. Then, we categorize\nand analyze techniques and toolkits for efficient low-bit training and\ninference of LLMs. Finally, we conclude with a discussion of future trends and\npotential advancements of low-bit LLMs. Our systematic overview from basic,\nsystem, and algorithm perspectives can offer valuable insights and guidelines\nfor future works to enhance the efficiency and applicability of LLMs through\nlow-bit quantization.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Ruihao Gong leads the overall organization of the survey, with Yifu\n  Ding and Jinyang Du contributing to Sections 2 and 3. Xingyu Zheng is\n  responsible for authoring Section 4, while Chengtao Lv and Zining Wang\n  collaborate on Section 5. Haotong Qin, Jinyang Guo, Michele Magno, and\n  Xianglong Liu provide guidance during the whole process and assist in\n  refining the final manuscript",
    "pdf_url": "http://arxiv.org/pdf/2409.16694v2",
    "published_date": "2024-09-25 07:38:02 UTC",
    "updated_date": "2024-09-30 12:55:03 UTC"
  },
  {
    "arxiv_id": "2409.16693v1",
    "title": "CaBRNet, an open-source library for developing and evaluating Case-Based Reasoning Models",
    "authors": [
      "Romain Xu-Darme",
      "Aymeric Varasse",
      "Alban Grastien",
      "Julien Girard",
      "Zakaria Chihani"
    ],
    "abstract": "In the field of explainable AI, a vibrant effort is dedicated to the design\nof self-explainable models, as a more principled alternative to post-hoc\nmethods that attempt to explain the decisions after a model opaquely makes\nthem. However, this productive line of research suffers from common downsides:\nlack of reproducibility, unfeasible comparison, diverging standards. In this\npaper, we propose CaBRNet, an open-source, modular, backward-compatible\nframework for Case-Based Reasoning Networks:\nhttps://github.com/aiser-team/cabrnet.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16693v1",
    "published_date": "2024-09-25 07:32:03 UTC",
    "updated_date": "2024-09-25 07:32:03 UTC"
  },
  {
    "arxiv_id": "2409.16689v1",
    "title": "Layout-Corrector: Alleviating Layout Sticking Phenomenon in Discrete Diffusion Model",
    "authors": [
      "Shoma Iwai",
      "Atsuki Osanai",
      "Shunsuke Kitada",
      "Shinichiro Omachi"
    ],
    "abstract": "Layout generation is a task to synthesize a harmonious layout with elements\ncharacterized by attributes such as category, position, and size. Human\ndesigners experiment with the placement and modification of elements to create\naesthetic layouts, however, we observed that current discrete diffusion models\n(DDMs) struggle to correct inharmonious layouts after they have been generated.\nIn this paper, we first provide novel insights into layout sticking phenomenon\nin DDMs and then propose a simple yet effective layout-assessment module\nLayout-Corrector, which works in conjunction with existing DDMs to address the\nlayout sticking problem. We present a learning-based module capable of\nidentifying inharmonious elements within layouts, considering overall layout\nharmony characterized by complex composition. During the generation process,\nLayout-Corrector evaluates the correctness of each token in the generated\nlayout, reinitializing those with low scores to the ungenerated state. The DDM\nthen uses the high-scored tokens as clues to regenerate the harmonized tokens.\nLayout-Corrector, tested on common benchmarks, consistently boosts\nlayout-generation performance when in conjunction with various state-of-the-art\nDDMs. Furthermore, our extensive analysis demonstrates that the\nLayout-Corrector (1) successfully identifies erroneous tokens, (2) facilitates\ncontrol over the fidelity-diversity trade-off, and (3) significantly mitigates\nthe performance drop associated with fast sampling.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ECCV2024, Project Page:\n  https://iwa-shi.github.io/Layout-Corrector-Project-Page/",
    "pdf_url": "http://arxiv.org/pdf/2409.16689v1",
    "published_date": "2024-09-25 07:24:43 UTC",
    "updated_date": "2024-09-25 07:24:43 UTC"
  },
  {
    "arxiv_id": "2409.16686v2",
    "title": "MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making",
    "authors": [
      "Dayuan Fu",
      "Biqing Qi",
      "Yihuai Gao",
      "Che Jiang",
      "Guanting Dong",
      "Bowen Zhou"
    ],
    "abstract": "Long-term memory is significant for agents, in which insights play a crucial\nrole. However, the emergence of irrelevant insight and the lack of general\ninsight can greatly undermine the effectiveness of insight. To solve this\nproblem, in this paper, we introduce Multi-Scale Insight Agent (MSI-Agent), an\nembodied agent designed to improve LLMs' planning and decision-making ability\nby summarizing and utilizing insight effectively across different scales. MSI\nachieves this through the experience selector, insight generator, and insight\nselector. Leveraging a three-part pipeline, MSI can generate task-specific and\nhigh-level insight, store it in a database, and then use relevant insight from\nit to aid in decision-making. Our experiments show that MSI outperforms another\ninsight strategy when planning by GPT3.5. Moreover, We delve into the\nstrategies for selecting seed experience and insight, aiming to provide LLM\nwith more useful and relevant insight for better decision-making. Our\nobservations also indicate that MSI exhibits better robustness when facing\ndomain-shifting scenarios.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16686v2",
    "published_date": "2024-09-25 07:21:51 UTC",
    "updated_date": "2024-11-09 07:23:42 UTC"
  },
  {
    "arxiv_id": "2409.16684v2",
    "title": "Erase then Rectify: A Training-Free Parameter Editing Approach for Cost-Effective Graph Unlearning",
    "authors": [
      "Zhe-Rui Yang",
      "Jindong Han",
      "Chang-Dong Wang",
      "Hao Liu"
    ],
    "abstract": "Graph unlearning, which aims to eliminate the influence of specific nodes,\nedges, or attributes from a trained Graph Neural Network (GNN), is essential in\napplications where privacy, bias, or data obsolescence is a concern. However,\nexisting graph unlearning techniques often necessitate additional training on\nthe remaining data, leading to significant computational costs, particularly\nwith large-scale graphs. To address these challenges, we propose a two-stage\ntraining-free approach, Erase then Rectify (ETR), designed for efficient and\nscalable graph unlearning while preserving the model utility. Specifically, we\nfirst build a theoretical foundation showing that masking parameters critical\nfor unlearned samples enables effective unlearning. Building on this insight,\nthe Erase stage strategically edits model parameters to eliminate the impact of\nunlearned samples and their propagated influence on intercorrelated nodes. To\nfurther ensure the GNN's utility, the Rectify stage devises a gradient\napproximation method to estimate the model's gradient on the remaining dataset,\nwhich is then used to enhance model performance. Overall, ETR achieves graph\nunlearning without additional training or full training data access,\nsignificantly reducing computational overhead and preserving data privacy.\nExtensive experiments on seven public datasets demonstrate the consistent\nsuperiority of ETR in model utility, unlearning efficiency, and unlearning\neffectiveness, establishing it as a promising solution for real-world graph\nunlearning challenges.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI2025",
    "pdf_url": "http://arxiv.org/pdf/2409.16684v2",
    "published_date": "2024-09-25 07:20:59 UTC",
    "updated_date": "2024-12-19 14:18:15 UTC"
  },
  {
    "arxiv_id": "2409.16678v1",
    "title": "TSBP: Improving Object Detection in Histology Images via Test-time Self-guided Bounding-box Propagation",
    "authors": [
      "Tingting Yang",
      "Liang Xiao",
      "Yizhe Zhang"
    ],
    "abstract": "A global threshold (e.g., 0.5) is often applied to determine which bounding\nboxes should be included in the final results for an object detection task. A\nhigher threshold reduces false positives but may result in missing a\nsignificant portion of true positives. A lower threshold can increase detection\nrecall but may also result in more false positives. Because of this, using a\npreset global threshold (e.g., 0.5) applied to all the bounding box candidates\nmay lead to suboptimal solutions. In this paper, we propose a Test-time\nSelf-guided Bounding-box Propagation (TSBP) method, leveraging Earth Mover's\nDistance (EMD) to enhance object detection in histology images. TSBP utilizes\nbounding boxes with high confidence to influence those with low confidence,\nleveraging visual similarities between them. This propagation mechanism enables\nbounding boxes to be selected in a controllable, explainable, and robust\nmanner, which surpasses the effectiveness of using simple thresholds and\nuncertainty calibration methods. Importantly, TSBP does not necessitate\nadditional labeled samples for model training or parameter estimation, unlike\ncalibration methods. We conduct experiments on gland detection and cell\ndetection tasks in histology images. The results show that our proposed TSBP\nsignificantly improves detection outcomes when working in conjunction with\nstate-of-the-art deep learning-based detection networks. Compared to other\nmethods such as uncertainty calibration, TSBP yields more robust and accurate\nobject detection predictions while using no additional labeled samples. The\ncode is available at https://github.com/jwhgdeu/TSBP.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.16678v1",
    "published_date": "2024-09-25 07:09:04 UTC",
    "updated_date": "2024-09-25 07:09:04 UTC"
  },
  {
    "arxiv_id": "2409.16670v2",
    "title": "GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning",
    "authors": [
      "Zhe-Rui Yang",
      "Jindong Han",
      "Chang-Dong Wang",
      "Hao Liu"
    ],
    "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in\nhandling a range of graph analytical tasks across various domains, such as\ne-commerce and social networks. Despite their versatility, GNNs face\nsignificant challenges in transferability, limiting their utility in real-world\napplications. Existing research in GNN transfer learning overlooks\ndiscrepancies in distribution among various graph datasets, facing challenges\nwhen transferring across different distributions. How to effectively adopt a\nwell-trained GNN to new graphs with varying feature and structural\ndistributions remains an under-explored problem. Taking inspiration from the\nsuccess of Low-Rank Adaptation (LoRA) in adapting large language models to\nvarious domains, we propose GraphLoRA, an effective and parameter-efficient\nmethod for transferring well-trained GNNs to diverse graph domains.\nSpecifically, we first propose a Structure-aware Maximum Mean Discrepancy\n(SMMD) to align divergent node feature distributions across source and target\ngraphs. Moreover, we introduce low-rank adaptation by injecting a small\ntrainable GNN alongside the pre-trained one, effectively bridging structural\ndistribution gaps while mitigating the catastrophic forgetting. Additionally, a\nstructure-aware regularization objective is proposed to enhance the\nadaptability of the pre-trained GNN to target graph with scarce supervision\nlabels. Extensive experiments on eight real-world datasets demonstrate the\neffectiveness of GraphLoRA against fourteen baselines by tuning only 20% of\nparameters, even across disparate graph domains. The code is available at\nhttps://github.com/AllminerLab/GraphLoRA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by KDD2025",
    "pdf_url": "http://arxiv.org/pdf/2409.16670v2",
    "published_date": "2024-09-25 06:57:42 UTC",
    "updated_date": "2025-01-07 15:00:20 UTC"
  },
  {
    "arxiv_id": "2409.17190v1",
    "title": "Enhancing Guardrails for Safe and Secure Healthcare AI",
    "authors": [
      "Ananya Gangavarapu"
    ],
    "abstract": "Generative AI holds immense promise in addressing global healthcare access\nchallenges, with numerous innovative applications now ready for use across\nvarious healthcare domains. However, a significant barrier to the widespread\nadoption of these domain-specific AI solutions is the lack of robust safety\nmechanisms to effectively manage issues such as hallucination, misinformation,\nand ensuring truthfulness. Left unchecked, these risks can compromise patient\nsafety and erode trust in healthcare AI systems. While general-purpose\nframeworks like Llama Guard are useful for filtering toxicity and harmful\ncontent, they do not fully address the stringent requirements for truthfulness\nand safety in healthcare contexts. This paper examines the unique safety and\nsecurity challenges inherent to healthcare AI, particularly the risk of\nhallucinations, the spread of misinformation, and the need for factual accuracy\nin clinical settings. I propose enhancements to existing guardrails frameworks,\nsuch as Nvidia NeMo Guardrails, to better suit healthcare-specific needs. By\nstrengthening these safeguards, I aim to ensure the secure, reliable, and\naccurate use of AI in healthcare, mitigating misinformation risks and improving\npatient safety.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17190v1",
    "published_date": "2024-09-25 06:30:06 UTC",
    "updated_date": "2024-09-25 06:30:06 UTC"
  },
  {
    "arxiv_id": "2409.16652v1",
    "title": "Progressive Representation Learning for Real-Time UAV Tracking",
    "authors": [
      "Changhong Fu",
      "Xiang Lei",
      "Haobo Zuo",
      "Liangliang Yao",
      "Guangze Zheng",
      "Jia Pan"
    ],
    "abstract": "Visual object tracking has significantly promoted autonomous applications for\nunmanned aerial vehicles (UAVs). However, learning robust object\nrepresentations for UAV tracking is especially challenging in complex dynamic\nenvironments, when confronted with aspect ratio change and occlusion. These\nchallenges severely alter the original information of the object. To handle the\nabove issues, this work proposes a novel progressive representation learning\nframework for UAV tracking, i.e., PRL-Track. Specifically, PRL-Track is divided\ninto coarse representation learning and fine representation learning. For\ncoarse representation learning, two innovative regulators, which rely on\nappearance and semantic information, are designed to mitigate appearance\ninterference and capture semantic information. Furthermore, for fine\nrepresentation learning, a new hierarchical modeling generator is developed to\nintertwine coarse object representations. Exhaustive experiments demonstrate\nthat the proposed PRL-Track delivers exceptional performance on three\nauthoritative UAV tracking benchmarks. Real-world tests indicate that the\nproposed PRL-Track realizes superior tracking performance with 42.6 frames per\nsecond on the typical UAV platform equipped with an edge smart camera. The\ncode, model, and demo videos are available at\n\\url{https://github.com/vision4robotics/PRL-Track}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by the 2024 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2409.16652v1",
    "published_date": "2024-09-25 06:16:32 UTC",
    "updated_date": "2024-09-25 06:16:32 UTC"
  },
  {
    "arxiv_id": "2409.16645v1",
    "title": "Task Addition in Multi-Task Learning by Geometrical Alignment",
    "authors": [
      "Soorin Yim",
      "Dae-Woong Jeong",
      "Sung Moon Ko",
      "Sumin Lee",
      "Hyunseung Kim",
      "Chanhui Lee",
      "Sehui Han"
    ],
    "abstract": "Training deep learning models on limited data while maintaining\ngeneralization is one of the fundamental challenges in molecular property\nprediction. One effective solution is transferring knowledge extracted from\nabundant datasets to those with scarce data. Recently, a novel algorithm called\nGeometrically Aligned Transfer Encoder (GATE) has been introduced, which uses\nsoft parameter sharing by aligning the geometrical shapes of task-specific\nlatent spaces. However, GATE faces limitations in scaling to multiple tasks due\nto computational costs. In this study, we propose a task addition approach for\nGATE to improve performance on target tasks with limited data while minimizing\ncomputational complexity. It is achieved through supervised multi-task\npre-training on a large dataset, followed by the addition and training of\ntask-specific modules for each target task. Our experiments demonstrate the\nsuperior performance of the task addition strategy for GATE over conventional\nmulti-task methods, with comparable computational costs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 5 figures, Accepted at AI for Science Workshop at 41st\n  International Conference on Machine Learning",
    "pdf_url": "http://arxiv.org/pdf/2409.16645v1",
    "published_date": "2024-09-25 05:56:00 UTC",
    "updated_date": "2024-09-25 05:56:00 UTC"
  },
  {
    "arxiv_id": "2409.16636v1",
    "title": "Training Language Models to Win Debates with Self-Play Improves Judge Accuracy",
    "authors": [
      "Samuel Arnesen",
      "David Rein",
      "Julian Michael"
    ],
    "abstract": "We test the robustness of debate as a method of scalable oversight by\ntraining models to debate with data generated via self-play. In a long-context\nreading comprehension task, we find that language model based evaluators answer\nquestions more accurately when judging models optimized to win debates. By\ncontrast, we find no such relationship for consultancy models trained to\npersuade a judge without an opposing debater present. In quantitative and\nqualitative comparisons between our debate models and novel consultancy\nbaselines, we find evidence that debate training encourages stronger and more\ninformative arguments, showing promise that it can help provide high-quality\nsupervision for tasks that are difficult to directly evaluate.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.0; I.2.6"
    ],
    "primary_category": "cs.CL",
    "comment": "48 pages, 12 figures; code at\n  https://github.com/samuelarnesen/nyu-debate-modeling",
    "pdf_url": "http://arxiv.org/pdf/2409.16636v1",
    "published_date": "2024-09-25 05:28:33 UTC",
    "updated_date": "2024-09-25 05:28:33 UTC"
  },
  {
    "arxiv_id": "2409.16635v1",
    "title": "Judgment of Thoughts: Courtroom of the Binary Logical Reasoning in Large Language Models",
    "authors": [
      "Sungjune Park",
      "Daeseon Choi"
    ],
    "abstract": "This paper proposes a novel prompt engineering technique called Judgment of\nThought (JoT) that is specifically tailored for binary logical reasoning tasks.\nJoT employs three roles$\\unicode{x2014}$lawyer, prosecutor, and\njudge$\\unicode{x2014}$to facilitate more reliable and accurate reasoning by the\nmodel. In this framework, the judge utilizes a high$\\unicode{x2010}$level\nmodel, while the lawyer and prosecutor utilize low$\\unicode{x2010}$level\nmodels. This structure helps the judge better understand the responses from\nboth the lawyer and prosecutor, enabling a more accurate judgment. Experimental\nresults on large language model (LLM) benchmark datasets, such as BigBenchHard\nand Winogrande, demonstrate that JoT outperforms existing methods, including\nChain of Thought (CoT) and Self$\\unicode{x2010}$Consistency (SC), in binary\nlogical reasoning tasks. Additionally, in real$\\unicode{x2010}$world tasks,\nsuch as Fake News Detection and SMS Spam Detection, JoT shows comparable or\nimproved performance compared to existing techniques. JoT significantly\nenhances the accuracy and reliability of models in binary reasoning tasks and\nshow potential for practical applicability across various domains. Future\nresearch should aim to further broaden the applicability of JoT and optimize\nits implementation for real$\\unicode{x2010}$world\nproblem$\\unicode{x2010}$solving.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16635v1",
    "published_date": "2024-09-25 05:28:05 UTC",
    "updated_date": "2024-09-25 05:28:05 UTC"
  },
  {
    "arxiv_id": "2409.16630v1",
    "title": "Stochastic Subsampling With Average Pooling",
    "authors": [
      "Bum Jun Kim",
      "Sang Woo Kim"
    ],
    "abstract": "Regularization of deep neural networks has been an important issue to achieve\nhigher generalization performance without overfitting problems. Although the\npopular method of Dropout provides a regularization effect, it causes\ninconsistent properties in the output, which may degrade the performance of\ndeep neural networks. In this study, we propose a new module called stochastic\naverage pooling, which incorporates Dropout-like stochasticity in pooling. We\ndescribe the properties of stochastic subsampling and average pooling and\nleverage them to design a module without any inconsistency problem. The\nstochastic average pooling achieves a regularization effect without any\npotential performance degradation due to the inconsistency issue and can easily\nbe plugged into existing architectures of deep neural networks. Experiments\ndemonstrate that replacing existing average pooling with stochastic average\npooling yields consistent improvements across a variety of tasks, datasets, and\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.16630v1",
    "published_date": "2024-09-25 05:18:17 UTC",
    "updated_date": "2024-09-25 05:18:17 UTC"
  },
  {
    "arxiv_id": "2409.16626v2",
    "title": "Ascend HiFloat8 Format for Deep Learning",
    "authors": [
      "Yuanyong Luo",
      "Zhongxing Zhang",
      "Richard Wu",
      "Hu Liu",
      "Ying Jin",
      "Kai Zheng",
      "Minmin Wang",
      "Zhanying He",
      "Guipeng Hu",
      "Luyao Chen",
      "Tianchi Hu",
      "Junsong Wang",
      "Minqi Chen",
      "Mikhaylov Dmitry",
      "Korviakov Vladimir",
      "Bobrin Maxim",
      "Yuhao Hu",
      "Guanfu Chen",
      "Zeyi Huang"
    ],
    "abstract": "This preliminary white paper proposes a novel 8-bit floating-point data\nformat HiFloat8 (abbreviated as HiF8) for deep learning. HiF8 features tapered\nprecision. For normal value encoding, it provides 7 exponent values with 3-bit\nmantissa, 8 exponent values with 2-bit mantissa, and 16 exponent values with\n1-bit mantissa. For denormal value encoding, it extends the dynamic range by 7\nextra powers of 2, from 31 to 38 binades (notice that FP16 covers 40 binades).\nMeanwhile, HiF8 encodes all the special values except that positive zero and\nnegative zero are represented by only one bit-pattern. Thanks to the better\nbalance between precision and dynamic range, HiF8 can be simultaneously used in\nboth forward and backward passes of AI training. In this paper, we will\ndescribe the definition and rounding methods of HiF8, as well as the tentative\ntraining and inference solutions. To demonstrate the efficacy of HiF8, massive\nsimulation results on various neural networks, including traditional neural\nnetworks and large language models (LLMs), will also be presented.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "13 Pages, 4 Figures, 9 Tables",
    "pdf_url": "http://arxiv.org/pdf/2409.16626v2",
    "published_date": "2024-09-25 05:11:58 UTC",
    "updated_date": "2024-09-26 16:41:27 UTC"
  },
  {
    "arxiv_id": "2409.16623v1",
    "title": "On Your Mark, Get Set, Predict! Modeling Continuous-Time Dynamics of Cascades for Information Popularity Prediction",
    "authors": [
      "Xin Jing",
      "Yichen Jing",
      "Yuhuan Lu",
      "Bangchao Deng",
      "Sikun Yang",
      "Dingqi Yang"
    ],
    "abstract": "Information popularity prediction is important yet challenging in various\ndomains, including viral marketing and news recommendations. The key to\naccurately predicting information popularity lies in subtly modeling the\nunderlying temporal information diffusion process behind observed events of an\ninformation cascade, such as the retweets of a tweet. To this end, most\nexisting methods either adopt recurrent networks to capture the temporal\ndynamics from the first to the last observed event or develop a statistical\nmodel based on self-exciting point processes to make predictions. However,\ninformation diffusion is intrinsically a complex continuous-time process with\nirregularly observed discrete events, which is oversimplified using recurrent\nnetworks as they fail to capture the irregular time intervals between events,\nor using self-exciting point processes as they lack flexibility to capture the\ncomplex diffusion process. Against this background, we propose ConCat, modeling\nthe Continuous-time dynamics of Cascades for information popularity prediction.\nOn the one hand, it leverages neural Ordinary Differential Equations (ODEs) to\nmodel irregular events of a cascade in continuous time based on the cascade\ngraph and sequential event information. On the other hand, it considers cascade\nevents as neural temporal point processes (TPPs) parameterized by a conditional\nintensity function which can also benefit the popularity prediction task. We\nconduct extensive experiments to evaluate ConCat on three real-world datasets.\nResults show that ConCat achieves superior performance compared to\nstate-of-the-art baselines, yielding a 2.3%-33.2% improvement over the\nbest-performing baselines across the three datasets.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16623v1",
    "published_date": "2024-09-25 05:08:44 UTC",
    "updated_date": "2024-09-25 05:08:44 UTC"
  },
  {
    "arxiv_id": "2409.16621v1",
    "title": "Entailment-Driven Privacy Policy Classification with LLMs",
    "authors": [
      "Bhanuka Silva",
      "Dishanika Denipitiyage",
      "Suranga Seneviratne",
      "Anirban Mahanti",
      "Aruna Seneviratne"
    ],
    "abstract": "While many online services provide privacy policies for end users to read and\nunderstand what personal data are being collected, these documents are often\nlengthy and complicated. As a result, the vast majority of users do not read\nthem at all, leading to data collection under uninformed consent. Several\nattempts have been made to make privacy policies more user friendly by\nsummarising them, providing automatic annotations or labels for key sections,\nor by offering chat interfaces to ask specific questions. With recent advances\nin Large Language Models (LLMs), there is an opportunity to develop more\neffective tools to parse privacy policies and help users make informed\ndecisions. In this paper, we propose an entailment-driven LLM based framework\nto classify paragraphs of privacy policies into meaningful labels that are\neasily understood by users. The results demonstrate that our framework\noutperforms traditional LLM methods, improving the F1 score in average by\n11.2%. Additionally, our framework provides inherently explainable and\nmeaningful predictions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 4 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.16621v1",
    "published_date": "2024-09-25 05:07:05 UTC",
    "updated_date": "2024-09-25 05:07:05 UTC"
  },
  {
    "arxiv_id": "2409.16620v1",
    "title": "Optimized Monte Carlo Tree Search for Enhanced Decision Making in the FrozenLake Environment",
    "authors": [
      "Esteban Aldana Guerra"
    ],
    "abstract": "Monte Carlo Tree Search (MCTS) is a powerful algorithm for solving complex\ndecision-making problems. This paper presents an optimized MCTS implementation\napplied to the FrozenLake environment, a classic reinforcement learning task\ncharacterized by stochastic transitions. The optimization leverages cumulative\nreward and visit count tables along with the Upper Confidence Bound for Trees\n(UCT) formula, resulting in efficient learning in a slippery grid world. We\nbenchmark our implementation against other decision-making algorithms,\nincluding MCTS with Policy and Q-Learning, and perform a detailed comparison of\ntheir performance. The results demonstrate that our optimized approach\neffectively maximizes rewards and success rates while minimizing convergence\ntime, outperforming baseline methods, especially in environments with inherent\nrandomness.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16620v1",
    "published_date": "2024-09-25 05:04:53 UTC",
    "updated_date": "2024-09-25 05:04:53 UTC"
  },
  {
    "arxiv_id": "2409.16619v1",
    "title": "CasFT: Future Trend Modeling for Information Popularity Prediction with Dynamic Cues-Driven Diffusion Models",
    "authors": [
      "Xin Jing",
      "Yichen Jing",
      "Yuhuan Lu",
      "Bangchao Deng",
      "Xueqin Chen",
      "Dingqi Yang"
    ],
    "abstract": "The rapid spread of diverse information on online social platforms has\nprompted both academia and industry to realize the importance of predicting\ncontent popularity, which could benefit a wide range of applications, such as\nrecommendation systems and strategic decision-making. Recent works mainly\nfocused on extracting spatiotemporal patterns inherent in the information\ndiffusion process within a given observation period so as to predict its\npopularity over a future period of time. However, these works often overlook\nthe future popularity trend, as future popularity could either increase\nexponentially or stagnate, introducing uncertainties to the prediction\nperformance. Additionally, how to transfer the preceding-term dynamics learned\nfrom the observed diffusion process into future-term trends remains an\nunexplored challenge. Against this background, we propose CasFT, which\nleverages observed information Cascades and dynamic cues extracted via neural\nODEs as conditions to guide the generation of Future popularity-increasing\nTrends through a diffusion model. These generated trends are then combined with\nthe spatiotemporal patterns in the observed information cascade to make the\nfinal popularity prediction. Extensive experiments conducted on three\nreal-world datasets demonstrate that CasFT significantly improves the\nprediction accuracy, compared to state-of-the-art approaches, yielding\n2.2%-19.3% improvement across different datasets.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16619v1",
    "published_date": "2024-09-25 05:03:16 UTC",
    "updated_date": "2024-09-25 05:03:16 UTC"
  },
  {
    "arxiv_id": "2409.16618v1",
    "title": "Claim-Guided Textual Backdoor Attack for Practical Applications",
    "authors": [
      "Minkyoo Song",
      "Hanna Kim",
      "Jaehan Kim",
      "Youngjin Jin",
      "Seungwon Shin"
    ],
    "abstract": "Recent advances in natural language processing and the increased use of large\nlanguage models have exposed new security vulnerabilities, such as backdoor\nattacks. Previous backdoor attacks require input manipulation after model\ndistribution to activate the backdoor, posing limitations in real-world\napplicability. Addressing this gap, we introduce a novel Claim-Guided Backdoor\nAttack (CGBA), which eliminates the need for such manipulations by utilizing\ninherent textual claims as triggers. CGBA leverages claim extraction,\nclustering, and targeted training to trick models to misbehave on targeted\nclaims without affecting their performance on clean data. CGBA demonstrates its\neffectiveness and stealthiness across various datasets and models,\nsignificantly enhancing the feasibility of practical backdoor attacks. Our code\nand data will be available at https://github.com/PaperCGBA/CGBA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2409.16618v1",
    "published_date": "2024-09-25 04:53:27 UTC",
    "updated_date": "2024-09-25 04:53:27 UTC"
  },
  {
    "arxiv_id": "2409.16612v1",
    "title": "ECG-Image-Database: A Dataset of ECG Images with Real-World Imaging and Scanning Artifacts; A Foundation for Computerized ECG Image Digitization and Analysis",
    "authors": [
      "Matthew A. Reyna",
      "Deepanshi",
      "James Weigle",
      "Zuzana Koscova",
      "Kiersten Campbell",
      "Kshama Kodthalu Shivashankara",
      "Soheil Saghafi",
      "Sepideh Nikookar",
      "Mohsen Motie-Shirazi",
      "Yashar Kiarashi",
      "Salman Seyedi",
      "Gari D. Clifford",
      "Reza Sameni"
    ],
    "abstract": "We introduce the ECG-Image-Database, a large and diverse collection of\nelectrocardiogram (ECG) images generated from ECG time-series data, with\nreal-world scanning, imaging, and physical artifacts. We used ECG-Image-Kit, an\nopen-source Python toolkit, to generate realistic images of 12-lead ECG\nprintouts from raw ECG time-series. The images include realistic distortions\nsuch as noise, wrinkles, stains, and perspective shifts, generated both\ndigitally and physically. The toolkit was applied to 977 12-lead ECG records\nfrom the PTB-XL database and 1,000 from Emory Healthcare to create\nhigh-fidelity synthetic ECG images. These unique images were subjected to both\nprogrammatic distortions using ECG-Image-Kit and physical effects like soaking,\nstaining, and mold growth, followed by scanning and photography under various\nlighting conditions to create real-world artifacts.\n  The resulting dataset includes 35,595 software-labeled ECG images with a wide\nrange of imaging artifacts and distortions. The dataset provides ground truth\ntime-series data alongside the images, offering a reference for developing\nmachine and deep learning models for ECG digitization and classification. The\nimages vary in quality, from clear scans of clean papers to noisy photographs\nof degraded papers, enabling the development of more generalizable digitization\nalgorithms.\n  ECG-Image-Database addresses a critical need for digitizing paper-based and\nnon-digital ECGs for computerized analysis, providing a foundation for\ndeveloping robust machine and deep learning models capable of converting ECG\nimages into time-series. The dataset aims to serve as a reference for ECG\ndigitization and computerized annotation efforts. ECG-Image-Database was used\nin the PhysioNet Challenge 2024 on ECG image digitization and classification.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16612v1",
    "published_date": "2024-09-25 04:30:19 UTC",
    "updated_date": "2024-09-25 04:30:19 UTC"
  },
  {
    "arxiv_id": "2409.16605v1",
    "title": "Evaluating and Enhancing Large Language Models for Novelty Assessment in Scholarly Publications",
    "authors": [
      "Ethan Lin",
      "Zhiyuan Peng",
      "Yi Fang"
    ],
    "abstract": "Recent studies have evaluated the creativity/novelty of large language models\n(LLMs) primarily from a semantic perspective, using benchmarks from cognitive\nscience. However, accessing the novelty in scholarly publications is a largely\nunexplored area in evaluating LLMs. In this paper, we introduce a scholarly\nnovelty benchmark (SchNovel) to evaluate LLMs' ability to assess novelty in\nscholarly papers. SchNovel consists of 15000 pairs of papers across six fields\nsampled from the arXiv dataset with publication dates spanning 2 to 10 years\napart. In each pair, the more recently published paper is assumed to be more\nnovel. Additionally, we propose RAG-Novelty, which simulates the review process\ntaken by human reviewers by leveraging the retrieval of similar papers to\nassess novelty. Extensive experiments provide insights into the capabilities of\ndifferent LLMs to assess novelty and demonstrate that RAG-Novelty outperforms\nrecent baseline models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2409.16605v1",
    "published_date": "2024-09-25 04:12:38 UTC",
    "updated_date": "2024-09-25 04:12:38 UTC"
  },
  {
    "arxiv_id": "2409.16593v1",
    "title": "A Hybrid Quantum Neural Network for Split Learning",
    "authors": [
      "Hevish Cowlessur",
      "Chandra Thapa",
      "Tansu Alpcan",
      "Seyit Camtepe"
    ],
    "abstract": "Quantum Machine Learning (QML) is an emerging field of research with\npotential applications to distributed collaborative learning, such as Split\nLearning (SL). SL allows resource-constrained clients to collaboratively train\nML models with a server, reduce their computational overhead, and enable data\nprivacy by avoiding raw data sharing. Although QML with SL has been studied,\nthe problem remains open in resource-constrained environments where clients\nlack quantum computing capabilities. Additionally, data privacy leakage between\nclient and server in SL poses risks of reconstruction attacks on the server\nside. To address these issues, we propose Hybrid Quantum Split Learning (HQSL),\nan application of Hybrid QML in SL. HQSL enables classical clients to train\nmodels with a hybrid quantum server and curtails reconstruction attacks. In\naddition, we introduce a novel qubit-efficient data-loading technique for\ndesigning a quantum layer in HQSL, minimizing both the number of qubits and\ncircuit depth. Experiments on five datasets demonstrate HQSL's feasibility and\nability to enhance classification performance compared to its classical models.\nNotably, HQSL achieves mean improvements of over 3% in both accuracy and\nF1-score for the Fashion-MNIST dataset, and over 1.5% in both metrics for the\nSpeech Commands dataset. We expand these studies to include up to 100 clients,\nconfirming HQSL's scalability. Moreover, we introduce a noise-based defense\nmechanism to tackle reconstruction attacks on the server side. Overall, HQSL\nenables classical clients to collaboratively train their models with a hybrid\nquantum server, leveraging quantum advantages while improving model performance\nand security against data privacy leakage-related reconstruction attacks.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "47 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.16593v1",
    "published_date": "2024-09-25 03:38:05 UTC",
    "updated_date": "2024-09-25 03:38:05 UTC"
  },
  {
    "arxiv_id": "2409.16592v1",
    "title": "MambaJSCC: Adaptive Deep Joint Source-Channel Coding with Generalized State Space Model",
    "authors": [
      "Tong Wu",
      "Zhiyong Chen",
      "Meixia Tao",
      "Yaping Sun",
      "Xiaodong Xu",
      "Wenjun Zhang",
      "Ping Zhang"
    ],
    "abstract": "Lightweight and efficient neural network models for deep joint source-channel\ncoding (JSCC) are crucial for semantic communications. In this paper, we\npropose a novel JSCC architecture, named MambaJSCC, that achieves\nstate-of-the-art performance with low computational and parameter overhead.\nMambaJSCC utilizes the visual state space model with channel adaptation\n(VSSM-CA) blocks as its backbone for transmitting images over wireless\nchannels, where the VSSM-CA primarily consists of the generalized state space\nmodels (GSSM) and the zero-parameter, zero-computational channel adaptation\nmethod (CSI-ReST). We design the GSSM module, leveraging reversible matrix\ntransformations to express generalized scan expanding operations, and\ntheoretically prove that two GSSM modules can effectively capture global\ninformation. We discover that GSSM inherently possesses the ability to adapt to\nchannels, a form of endogenous intelligence. Based on this, we design the\nCSI-ReST method, which injects channel state information (CSI) into the initial\nstate of GSSM to utilize its native response, and into the residual state to\nmitigate CSI forgetting, enabling effective channel adaptation without\nintroducing additional computational and parameter overhead. Experimental\nresults show that MambaJSCC not only outperforms existing JSCC methods (e.g.,\nSwinJSCC) across various scenarios but also significantly reduces parameter\nsize, computational overhead, and inference delay.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "submitted to IEEE Journal",
    "pdf_url": "http://arxiv.org/pdf/2409.16592v1",
    "published_date": "2024-09-25 03:37:51 UTC",
    "updated_date": "2024-09-25 03:37:51 UTC"
  },
  {
    "arxiv_id": "2409.16586v2",
    "title": "AutoSTF: Decoupled Neural Architecture Search for Cost-Effective Automated Spatio-Temporal Forecasting",
    "authors": [
      "Tengfei Lyu",
      "Weijia Zhang",
      "Jinliang Deng",
      "Hao Liu"
    ],
    "abstract": "Spatio-temporal forecasting is a critical component of various smart city\napplications, such as transportation optimization, energy management, and\nsocio-economic analysis. Recently, several automated spatio-temporal\nforecasting methods have been proposed to automatically search the optimal\nneural network architecture for capturing complex spatio-temporal dependencies.\nHowever, the existing automated approaches suffer from expensive neural\narchitecture search overhead, which hinders their practical use and the further\nexploration of diverse spatio-temporal operators in a finer granularity. In\nthis paper, we propose AutoSTF, a decoupled automatic neural architecture\nsearch framework for cost-effective automated spatio-temporal forecasting. From\nthe efficiency perspective, we first decouple the mixed search space into\ntemporal space and spatial space and respectively devise representation\ncompression and parameter-sharing schemes to mitigate the parameter explosion.\nThe decoupled spatio-temporal search not only expedites the model optimization\nprocess but also leaves new room for more effective spatio-temporal dependency\nmodeling. From the effectiveness perspective, we propose a multi-patch transfer\nmodule to jointly capture multi-granularity temporal dependencies and extend\nthe spatial search space to enable finer-grained layer-wise spatial dependency\nsearch. Extensive experiments on eight datasets demonstrate the superiority of\nAutoSTF in terms of both accuracy and efficiency. Specifically, our proposed\nmethod achieves up to 13.48x speed-up compared to state-of-the-art automatic\nspatio-temporal forecasting methods while maintaining the best forecasting\naccuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by KDD 2025 Research Track",
    "pdf_url": "http://arxiv.org/pdf/2409.16586v2",
    "published_date": "2024-09-25 03:25:34 UTC",
    "updated_date": "2025-01-08 13:16:26 UTC"
  },
  {
    "arxiv_id": "2409.16577v1",
    "title": "Reactive Multi-Robot Navigation in Outdoor Environments Through Uncertainty-Aware Active Learning of Human Preference Landscape",
    "authors": [
      "Chao Huang",
      "Wenshuo Zang",
      "Carlo Pinciroli",
      "Zhi Jane Li",
      "Taposh Banerjee",
      "Lili Su",
      "Rui Liu"
    ],
    "abstract": "Compared with single robots, Multi-Robot Systems (MRS) can perform missions\nmore efficiently due to the presence of multiple members with diverse\ncapabilities. However, deploying an MRS in wide real-world environments is\nstill challenging due to uncertain and various obstacles (e.g., building\nclusters and trees). With a limited understanding of environmental uncertainty\non performance, an MRS cannot flexibly adjust its behaviors (e.g., teaming,\nload sharing, trajectory planning) to ensure both environment adaptation and\ntask accomplishments. In this work, a novel joint preference landscape learning\nand behavior adjusting framework (PLBA) is designed. PLBA efficiently\nintegrates real-time human guidance to MRS coordination and utilizes Sparse\nVariational Gaussian Processes with Varying Output Noise to quickly assess\nhuman preferences by leveraging spatial correlations between environment\ncharacteristics. An optimization-based behavior-adjusting method then safely\nadapts MRS behaviors to environments. To validate PLBA's effectiveness in MRS\nbehavior adaption, a flood disaster search and rescue task was designed. 20\nhuman users provided 1764 feedback based on human preferences obtained from MRS\nbehaviors related to \"task quality\", \"task progress\", \"robot safety\". The\nprediction accuracy and adaptation speed results show the effectiveness of PLBA\nin preference learning and MRS behavior adaption.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16577v1",
    "published_date": "2024-09-25 03:15:09 UTC",
    "updated_date": "2024-09-25 03:15:09 UTC"
  },
  {
    "arxiv_id": "2409.16563v1",
    "title": "Enhancing disease detection in radiology reports through fine-tuning lightweight LLM on weak labels",
    "authors": [
      "Yishu Wei",
      "Xindi Wang",
      "Hanley Ong",
      "Yiliang Zhou",
      "Adam Flanders",
      "George Shih",
      "Yifan Peng"
    ],
    "abstract": "Despite significant progress in applying large language models (LLMs) to the\nmedical domain, several limitations still prevent them from practical\napplications. Among these are the constraints on model size and the lack of\ncohort-specific labeled datasets. In this work, we investigated the potential\nof improving a lightweight LLM, such as Llama 3.1-8B, through fine-tuning with\ndatasets using synthetic labels. Two tasks are jointly trained by combining\ntheir respective instruction datasets. When the quality of the task-specific\nsynthetic labels is relatively high (e.g., generated by GPT4- o), Llama 3.1-8B\nachieves satisfactory performance on the open-ended disease detection task,\nwith a micro F1 score of 0.91. Conversely, when the quality of the\ntask-relevant synthetic labels is relatively low (e.g., from the MIMIC-CXR\ndataset), fine-tuned Llama 3.1-8B is able to surpass its noisy teacher labels\n(micro F1 score of 0.67 v.s. 0.63) when calibrated against curated labels,\nindicating the strong inherent underlying capability of the model. These\nfindings demonstrate the potential of fine-tuning LLMs with synthetic labels,\noffering a promising direction for future research on LLM specialization in the\nmedical domain.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16563v1",
    "published_date": "2024-09-25 02:29:44 UTC",
    "updated_date": "2024-09-25 02:29:44 UTC"
  },
  {
    "arxiv_id": "2409.16560v2",
    "title": "Dynamic-Width Speculative Beam Decoding for Efficient LLM Inference",
    "authors": [
      "Zongyue Qin",
      "Zifan He",
      "Neha Prakriya",
      "Jason Cong",
      "Yizhou Sun"
    ],
    "abstract": "Large language models (LLMs) have shown outstanding performance across\nnumerous real-world tasks. However, the autoregressive nature of these models\nmakes the inference process slow and costly. Speculative decoding has emerged\nas a promising solution, leveraging a smaller auxiliary model to draft future\ntokens, which are then validated simultaneously by the larger model, achieving\na speed-up of 1-2x. Although speculative decoding matches the same distribution\nas multinomial sampling, multinomial sampling itself is prone to suboptimal\noutputs, whereas beam sampling is widely recognized for producing\nhigher-quality results by maintaining multiple candidate sequences at each\nstep. This paper explores the novel integration of speculative decoding with\nbeam sampling. However, there are four key challenges: (1) how to generate\nmultiple sequences from the larger model's distribution given drafts sequences\nfrom the small model; (2) how to dynamically optimize the number of beams to\nbalance efficiency and accuracy; (3) how to efficiently verify the multiple\ndrafts in parallel; and (4) how to address the extra memory costs inherent in\nbeam sampling. To address these challenges, we propose dynamic-width\nspeculative beam decoding (DSBD). Specifically, we first introduce a novel\ndraft and verification scheme that generates multiple sequences following the\nlarge model's distribution based on beam sampling trajectories from the small\nmodel. Then, we introduce an adaptive mechanism to dynamically tune the number\nof beams based on the context, optimizing efficiency and effectiveness.\nBesides, we extend tree-based parallel verification to handle multiple trees\nsimultaneously, accelerating the verification process. Finally, we illustrate a\nsimple modification to our algorithm to mitigate the memory overhead of beam\nsampling...",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16560v2",
    "published_date": "2024-09-25 02:20:42 UTC",
    "updated_date": "2025-03-14 16:18:50 UTC"
  },
  {
    "arxiv_id": "2409.16559v2",
    "title": "Demystifying Issues, Causes and Solutions in LLM Open-Source Projects",
    "authors": [
      "Yangxiao Cai",
      "Peng Liang",
      "Yifei Wang",
      "Zengyang Li",
      "Mojtaba Shahin"
    ],
    "abstract": "With the advancements of Large Language Models (LLMs), an increasing number\nof open-source software projects are using LLMs as their core functional\ncomponent. Although research and practice on LLMs are capturing considerable\ninterest, no dedicated studies explored the challenges faced by practitioners\nof LLM open-source projects, the causes of these challenges, and potential\nsolutions. To fill this research gap, we conducted an empirical study to\nunderstand the issues that practitioners encounter when developing and using\nLLM open-source software, the possible causes of these issues, and potential\nsolutions. We collected all closed issues from 15 LLM open-source projects and\nlabelled issues that met our requirements. We then randomly selected 994 issues\nfrom the labelled issues as the sample for data extraction and analysis to\nunderstand the prevalent issues, their underlying causes, and potential\nsolutions. Our study results show that (1) Model Issue is the most common issue\nfaced by practitioners, (2) Model Problem, Configuration and Connection\nProblem, and Feature and Method Problem are identified as the most frequent\ncauses of the issues, and (3) Optimize Model is the predominant solution to the\nissues. Based on the study results, we provide implications for practitioners\nand researchers of LLM open-source projects.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Preprint accepted for publication in Journal of Systems and Software,\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2409.16559v2",
    "published_date": "2024-09-25 02:16:45 UTC",
    "updated_date": "2025-04-07 06:57:06 UTC"
  },
  {
    "arxiv_id": "2409.16539v2",
    "title": "Context-aware and Style-related Incremental Decoding framework for Discourse-Level Literary Translation",
    "authors": [
      "Yuanchang Luo",
      "Jiaxin Guo",
      "Daimeng Wei",
      "Hengchao Shang",
      "Zongyao Li",
      "Zhanglin Wu",
      "Zhiqiang Rao",
      "Shaojun Li",
      "Jinlong Yang",
      "Hao Yang"
    ],
    "abstract": "This report outlines our approach for the WMT24 Discourse-Level Literary\nTranslation Task, focusing on the Chinese-English language pair in the\nConstrained Track. Translating literary texts poses significant challenges due\nto the nuanced meanings, idiomatic expressions, and intricate narrative\nstructures inherent in such works. To address these challenges, we leveraged\nthe Chinese-Llama2 model, specifically enhanced for this task through a\ncombination of Continual Pre-training (CPT) and Supervised Fine-Tuning (SFT).\nOur methodology includes a novel Incremental Decoding framework, which ensures\nthat each sentence is translated with consideration of its broader context,\nmaintaining coherence and consistency throughout the text. This approach allows\nthe model to capture long-range dependencies and stylistic elements, producing\ntranslations that faithfully preserve the original literary quality. Our\nexperiments demonstrate significant improvements in both sentence-level and\ndocument-level BLEU scores, underscoring the effectiveness of our proposed\nframework in addressing the complexities of document-level literary\ntranslation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 2 figures, wmt24",
    "pdf_url": "http://arxiv.org/pdf/2409.16539v2",
    "published_date": "2024-09-25 01:27:24 UTC",
    "updated_date": "2024-09-29 09:09:19 UTC"
  },
  {
    "arxiv_id": "2409.16538v1",
    "title": "Source-Free Domain Adaptation for YOLO Object Detection",
    "authors": [
      "Simon Varailhon",
      "Masih Aminbeidokhti",
      "Marco Pedersoli",
      "Eric Granger"
    ],
    "abstract": "Source-free domain adaptation (SFDA) is a challenging problem in object\ndetection, where a pre-trained source model is adapted to a new target domain\nwithout using any source domain data for privacy and efficiency reasons. Most\nstate-of-the-art SFDA methods for object detection have been proposed for\nFaster-RCNN, a detector that is known to have high computational complexity.\nThis paper focuses on domain adaptation techniques for real-world vision\nsystems, particularly for the YOLO family of single-shot detectors known for\ntheir fast baselines and practical applications. Our proposed SFDA method -\nSource-Free YOLO (SF-YOLO) - relies on a teacher-student framework in which the\nstudent receives images with a learned, target domain-specific augmentation,\nallowing the model to be trained with only unlabeled target data and without\nrequiring feature alignment. A challenge with self-training using a\nmean-teacher architecture in the absence of labels is the rapid decline of\naccuracy due to noisy or drifting pseudo-labels. To address this issue, a\nteacher-to-student communication mechanism is introduced to help stabilize the\ntraining and reduce the reliance on annotated target data for model selection.\nDespite its simplicity, our approach is competitive with state-of-the-art\ndetectors on several challenging benchmark datasets, even sometimes\noutperforming methods that use source data for adaptation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024: European Conference on Computer Vision - Workshop on\n  Out-of-Distribution Generalization in Computer Vision Foundation Models,\n  Milan Italy",
    "pdf_url": "http://arxiv.org/pdf/2409.16538v1",
    "published_date": "2024-09-25 01:22:10 UTC",
    "updated_date": "2024-09-25 01:22:10 UTC"
  },
  {
    "arxiv_id": "2409.16532v2",
    "title": "Graph Pruning Based Spatial and Temporal Graph Convolutional Network with Transfer Learning for Traffic Prediction",
    "authors": [
      "Zihao Jing"
    ],
    "abstract": "With the process of urbanization and the rapid growth of population, the\nissue of traffic congestion has become an increasingly critical concern.\nIntelligent transportation systems heavily rely on real-time and precise\nprediction algorithms to address this problem. While Recurrent Neural Network\n(RNN) and Graph Convolutional Network (GCN) methods in deep learning have\ndemonstrated high accuracy in predicting road conditions when sufficient data\nis available, forecasting in road networks with limited data remains a\nchallenging task. This study proposed a novel Spatial-temporal Convolutional\nNetwork (TL-GPSTGN) based on graph pruning and transfer learning framework to\ntackle this issue. Firstly, the essential structure and information of the\ngraph are extracted by analyzing the correlation and information entropy of the\nroad network structure and feature data. By utilizing graph pruning techniques,\nthe adjacency matrix of the graph and the input feature data are processed,\nresulting in a significant improvement in the model's migration performance.\nSubsequently, the well-characterized data are inputted into the\nspatial-temporal graph convolutional network to capture the spatial-temporal\nrelationships and make predictions regarding the road conditions. Furthermore,\nthis study conducts comprehensive testing and validation of the TL-GPSTGN\nmethod on real datasets, comparing its prediction performance against other\ncommonly used models under identical conditions. The results demonstrate the\nexceptional predictive accuracy of TL-GPSTGN on a single dataset, as well as\nits robust migration performance across different datasets.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Code is available at: https://github.com/selmiss/GP-TLSTGCN",
    "pdf_url": "http://arxiv.org/pdf/2409.16532v2",
    "published_date": "2024-09-25 00:59:23 UTC",
    "updated_date": "2024-12-31 05:45:26 UTC"
  },
  {
    "arxiv_id": "2409.16517v1",
    "title": "SynChart: Synthesizing Charts from Language Models",
    "authors": [
      "Mengchen Liu",
      "Qixiu Li",
      "Dongdong Chen",
      "Dong Chen",
      "Jianmin Bao",
      "Yunsheng Li"
    ],
    "abstract": "With the release of GPT-4V(O), its use in generating pseudo labels for\nmulti-modality tasks has gained significant popularity. However, it is still a\nsecret how to build such advanced models from its base large language models\n(LLMs). This work explores the potential of using LLMs alone for data\ngeneration and develop competitive multi-modality models focusing on chart\nunderstanding. We construct a large-scale chart dataset, SynChart, which\ncontains approximately 4 million diverse chart images with over 75 million\ndense annotations, including data tables, code, descriptions, and\nquestion-answer sets. We trained a 4.2B chart-expert model using this dataset\nand achieve near-GPT-4O performance on the ChartQA task, surpassing GPT-4V.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16517v1",
    "published_date": "2024-09-25 00:18:12 UTC",
    "updated_date": "2024-09-25 00:18:12 UTC"
  }
]