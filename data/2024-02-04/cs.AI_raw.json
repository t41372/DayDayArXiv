[
  {
    "arxiv_id": "2402.02643v1",
    "title": "LLM-Enhanced Data Management",
    "authors": [
      "Xuanhe Zhou",
      "Xinyang Zhao",
      "Guoliang Li"
    ],
    "abstract": "Machine learning (ML) techniques for optimizing data management problems have\nbeen extensively studied and widely deployed in recent five years. However\ntraditional ML methods have limitations on generalizability (adapting to\ndifferent scenarios) and inference ability (understanding the context).\nFortunately, large language models (LLMs) have shown high generalizability and\nhuman-competitive abilities in understanding context, which are promising for\ndata management tasks (e.g., database diagnosis, database tuning). However,\nexisting LLMs have several limitations: hallucination, high cost, and low\naccuracy for complicated tasks. To address these challenges, we design LLMDB,\nan LLM-enhanced data management paradigm which has generalizability and high\ninference ability while avoiding hallucination, reducing LLM cost, and\nachieving high accuracy. LLMDB embeds domain-specific knowledge to avoid\nhallucination by LLM fine-tuning and prompt engineering. LLMDB reduces the high\ncost of LLMs by vector databases which provide semantic search and caching\nabilities. LLMDB improves the task accuracy by LLM agent which provides\nmultiple-round inference and pipeline executions. We showcase three real-world\nscenarios that LLMDB can well support, including query rewrite, database\ndiagnosis and data analytics. We also summarize the open research challenges of\nLLMDB.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02643v1",
    "published_date": "2024-02-04 23:42:02 UTC",
    "updated_date": "2024-02-04 23:42:02 UTC"
  },
  {
    "arxiv_id": "2402.02636v2",
    "title": "Can Large Language Models Learn Independent Causal Mechanisms?",
    "authors": [
      "Gaël Gendron",
      "Bao Trung Nguyen",
      "Alex Yuxuan Peng",
      "Michael Witbrock",
      "Gillian Dobbie"
    ],
    "abstract": "Despite impressive performance on language modelling and complex reasoning\ntasks, Large Language Models (LLMs) fall short on the same tasks in uncommon\nsettings or with distribution shifts, exhibiting a lack of generalisation\nability. By contrast, systems such as causal models, that learn abstract\nvariables and causal relationships, can demonstrate increased robustness\nagainst changes in the distribution. One reason for this success is the\nexistence and use of Independent Causal Mechanisms (ICMs) representing\nhigh-level concepts that only sparsely interact. In this work, we apply two\nconcepts from causality to learn ICMs within LLMs. We develop a new LLM\narchitecture composed of multiple sparsely interacting language modelling\nmodules. We show that such causal constraints can improve out-of-distribution\nperformance on abstract and causal reasoning tasks. We also investigate the\nlevel of independence and domain specialisation and show that LLMs rely on\npre-trained partially domain-invariant mechanisms resilient to fine-tuning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "I.2.3; I.2.6; I.2.7; G.3"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 7 pages for the main paper and 13 pages for references and\n  appendices, 17 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.02636v2",
    "published_date": "2024-02-04 23:04:02 UTC",
    "updated_date": "2024-09-10 00:18:02 UTC"
  },
  {
    "arxiv_id": "2402.03396v1",
    "title": "UniTSyn: A Large-Scale Dataset Capable of Enhancing the Prowess of Large Language Models for Program Testing",
    "authors": [
      "Yifeng He",
      "Jiabo Huang",
      "Yuyang Rong",
      "Yiwen Guo",
      "Ethan Wang",
      "Hao Chen"
    ],
    "abstract": "The remarkable capability of large language models (LLMs) in generating\nhigh-quality code has drawn increasing attention in the software testing\ncommunity. However, existing code LLMs often demonstrate unsatisfactory\ncapabilities in generating accurate and complete tests since they were trained\non code snippets collected without differentiating between code for testing\npurposes and other code. In this paper, we present a large-scale dataset\nUniTSyn, which is capable of enhancing the prowess of LLMs for Unit Test\nSynthesis. Associating tests with the tested functions is crucial for LLMs to\ninfer the expected behavior and the logic paths to be verified. By leveraging\nLanguage Server Protocol, UniTSyn achieves the challenging goal of collecting\nfocal-test pairs without per-project execution setups or per-language\nheuristics that tend to be fragile and difficult to scale. It contains 2.7\nmillion focal-test pairs across five mainstream programming languages, making\nit possible to be utilized for enhancing the test generation ability of LLMs.\nThe details of UniTSyn can be found in Table 1. Our experiments demonstrate\nthat, by building an autoregressive model based on UniTSyn, we can achieve\nsignificant benefits in learning and understanding unit test representations,\nresulting in improved generation accuracy and code coverage across all\nevaluated programming languages. Code and data will be publicly available.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.03396v1",
    "published_date": "2024-02-04 22:48:05 UTC",
    "updated_date": "2024-02-04 22:48:05 UTC"
  },
  {
    "arxiv_id": "2402.02625v2",
    "title": "Enhancing Transformer RNNs with Multiple Temporal Perspectives",
    "authors": [
      "Razvan-Gabriel Dumitru",
      "Darius Peteleaza",
      "Mihai Surdeanu"
    ],
    "abstract": "We introduce the concept of multiple temporal perspectives, a novel approach\napplicable to Recurrent Neural Network (RNN) architectures for enhancing their\nunderstanding of sequential data. This method involves maintaining diverse\ntemporal views of previously encountered text, significantly enriching the\nlanguage models' capacity to interpret context. To show the efficacy of this\napproach, we incorporate it into the Receptance Weighted Key Value (RWKV)\narchitecture, addressing its inherent challenge of retaining all historical\ninformation within a single hidden state. Notably, this improvement is achieved\nwith a minimal increase in the number of parameters --even as little as\n$0.04\\%$ of the original number of parameters. Further, the additional\nparameters necessary for the multiple temporal perspectives are fine-tuned with\nminimal computational overhead, avoiding the need for a full pre-training. The\nresulting model maintains linear computational complexity during prompt\ninference, ensuring consistent efficiency across various sequence lengths. The\nempirical results and ablation studies included in our research validate the\neffectiveness of our approach, showcasing improved performance across multiple\nbenchmarks. The code, model weights and datasets are open-sourced at:\nhttps://github.com/RazvanDu/TemporalRNNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.0; I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 8 figures, 4 tables, accepted at ICML 2024 - Next\n  Generation of Sequence Modeling Architectures workshop",
    "pdf_url": "http://arxiv.org/pdf/2402.02625v2",
    "published_date": "2024-02-04 22:12:29 UTC",
    "updated_date": "2024-07-11 20:43:59 UTC"
  },
  {
    "arxiv_id": "2402.02624v1",
    "title": "A Safe Reinforcement Learning driven Weights-varying Model Predictive Control for Autonomous Vehicle Motion Control",
    "authors": [
      "Baha Zarrouki",
      "Marios Spanakakis",
      "Johannes Betz"
    ],
    "abstract": "Determining the optimal cost function parameters of Model Predictive Control\n(MPC) to optimize multiple control objectives is a challenging and\ntime-consuming task. Multiobjective Bayesian Optimization (BO) techniques solve\nthis problem by determining a Pareto optimal parameter set for an MPC with\nstatic weights. However, a single parameter set may not deliver the most\noptimal closed-loop control performance when the context of the MPC operating\nconditions changes during its operation, urging the need to adapt the cost\nfunction weights at runtime. Deep Reinforcement Learning (RL) algorithms can\nautomatically learn context-dependent optimal parameter sets and dynamically\nadapt for a Weightsvarying MPC (WMPC). However, learning cost function weights\nfrom scratch in a continuous action space may lead to unsafe operating states.\nTo solve this, we propose a novel approach limiting the RL actions within a\nsafe learning space representing a catalog of pre-optimized BO Pareto-optimal\nweight sets. We conceive a RL agent not to learn in a continuous space but to\nproactively anticipate upcoming control tasks and to choose the most optimal\ndiscrete actions, each corresponding to a single set of Pareto optimal weights,\ncontext-dependent. Hence, even an untrained RL agent guarantees a safe and\noptimal performance. Experimental results demonstrate that an untrained RL-WMPC\nshows Pareto-optimal closed-loop behavior and training the RL-WMPC helps\nexhibit a performance beyond the Pareto-front.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02624v1",
    "published_date": "2024-02-04 22:09:28 UTC",
    "updated_date": "2024-02-04 22:09:28 UTC"
  },
  {
    "arxiv_id": "2402.02623v1",
    "title": "Efficient Market Dynamics: Unraveling Informational Efficiency in UK Horse Racing Betting Markets Through Betfair's Time Series Analysis",
    "authors": [
      "Narayan Tondapu"
    ],
    "abstract": "Using Betfair's time series data, an analysis of the United Kingdom (UK)\nhorse racing market reveals an interesting paradox: a market with short tails,\nrapidly decaying autocorrelations, and no long-term memory. There seems to be a\nremarkably high level of informational efficiency in betting exchange returns,\nin contrast to financial assets that are characterized by heavy tails and\nvolatility clustering. The generalized Gaussian unconditional distribution with\na light tail point to a market where knowledge is quickly assimilated and\nreflected in prices. This is further supported by the extremely quick fading of\nautocorrelations and the absence of gain-loss asymmetry. Therefore, in addition\nto measuring long-range memory, the Hurst exponent also shows mean reversion, a\nsign that markets respond quickly to fresh information.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02623v1",
    "published_date": "2024-02-04 21:54:25 UTC",
    "updated_date": "2024-02-04 21:54:25 UTC"
  },
  {
    "arxiv_id": "2402.05959v1",
    "title": "Nature-Inspired Local Propagation",
    "authors": [
      "Alessandro Betti",
      "Marco Gori"
    ],
    "abstract": "The spectacular results achieved in machine learning, including the recent\nadvances in generative AI, rely on large data collections. On the opposite,\nintelligent processes in nature arises without the need for such collections,\nbut simply by online processing of the environmental information. In\nparticular, natural learning processes rely on mechanisms where data\nrepresentation and learning are intertwined in such a way to respect\nspatiotemporal locality. This paper shows that such a feature arises from a\npre-algorithmic view of learning that is inspired by related studies in\nTheoretical Physics. We show that the algorithmic interpretation of the derived\n\"laws of learning\", which takes the structure of Hamiltonian equations, reduces\nto Backpropagation when the speed of propagation goes to infinity. This opens\nthe doors to machine learning studies based on full on-line information\nprocessing that are based the replacement of Backpropagation with the proposed\nspatiotemporal local algorithm.",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05959v1",
    "published_date": "2024-02-04 21:43:37 UTC",
    "updated_date": "2024-02-04 21:43:37 UTC"
  },
  {
    "arxiv_id": "2402.02611v3",
    "title": "FCoReBench: Can Large Language Models Solve Challenging First-Order Combinatorial Reasoning Problems?",
    "authors": [
      "Chinmay Mittal",
      "Krishna Kartik",
      "Mausam",
      "Parag Singla"
    ],
    "abstract": "Can the large language models (LLMs) solve challenging first-order\ncombinatorial reasoning problems such as graph coloring, knapsack, and\ncryptarithmetic? By first-order, we mean these problems can be instantiated\nwith potentially an infinite number of problem instances of varying sizes. They\nare also challenging being NP-hard and requiring several reasoning steps to\nreach a solution. While existing work has focused on coming up with datasets\nwith hard benchmarks, there is limited work which exploits the first-order\nnature of the problem structure. To address this challenge, we present\nFCoReBench, a dataset of 40 such challenging problems, along with scripts to\ngenerate problem instances of varying sizes and automatically verify and\ngenerate their solutions. We first observe that LLMs, even when aided by\nsymbolic solvers, perform rather poorly on our dataset, being unable to\nleverage the underlying structure of these problems. We specifically observe a\ndrop in performance with increasing problem size. In response, we propose a new\napproach, SymPro-LM, which combines LLMs with both symbolic solvers and program\ninterpreters, along with feedback from a few solved examples, to achieve huge\nperformance gains. Our proposed approach is robust to changes in the problem\nsize, and has the unique characteristic of not requiring any LLM call during\ninference time, unlike earlier approaches. As an additional experiment, we also\ndemonstrate SymPro-LM's effectiveness on other logical reasoning benchmarks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02611v3",
    "published_date": "2024-02-04 20:56:09 UTC",
    "updated_date": "2025-03-01 12:46:25 UTC"
  },
  {
    "arxiv_id": "2402.14594v1",
    "title": "Improving Assessment of Tutoring Practices using Retrieval-Augmented Generation",
    "authors": [
      "Zifei FeiFei Han",
      "Jionghao Lin",
      "Ashish Gurung",
      "Danielle R. Thomas",
      "Eason Chen",
      "Conrad Borchers",
      "Shivang Gupta",
      "Kenneth R. Koedinger"
    ],
    "abstract": "One-on-one tutoring is an effective instructional method for enhancing\nlearning, yet its efficacy hinges on tutor competencies. Novice math tutors\noften prioritize content-specific guidance, neglecting aspects such as\nsocial-emotional learning. Social-emotional learning promotes equity and\ninclusion and nurturing relationships with students, which is crucial for\nholistic student development. Assessing the competencies of tutors accurately\nand efficiently can drive the development of tailored tutor training programs.\nHowever, evaluating novice tutor ability during real-time tutoring remains\nchallenging as it typically requires experts-in-the-loop. To address this\nchallenge, this preliminary study aims to harness Generative Pre-trained\nTransformers (GPT), such as GPT-3.5 and GPT-4 models, to automatically assess\ntutors' ability of using social-emotional tutoring strategies. Moreover, this\nstudy also reports on the financial dimensions and considerations of employing\nthese models in real-time and at scale for automated assessment. The current\nstudy examined four prompting strategies: two basic Zero-shot prompt\nstrategies, Tree of Thought prompt, and Retrieval-Augmented Generator (RAG)\nbased prompt. The results indicate that the RAG prompt demonstrated more\naccurate performance (assessed by the level of hallucination and correctness in\nthe generated assessment texts) and lower financial costs than the other\nstrategies evaluated. These findings inform the development of personalized\ntutor training interventions to enhance the the educational effectiveness of\ntutored learning.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.IR"
    ],
    "primary_category": "cs.CY",
    "comment": "11 page Workshop paper, AAAI2024 Workshop on AI for Education -\n  Bridging Innovation and Responsibility, Large Language Model, Personalized\n  Tutor Training, Automatic Assessment",
    "pdf_url": "http://arxiv.org/pdf/2402.14594v1",
    "published_date": "2024-02-04 20:42:30 UTC",
    "updated_date": "2024-02-04 20:42:30 UTC"
  },
  {
    "arxiv_id": "2402.02600v1",
    "title": "Evading Deep Learning-Based Malware Detectors via Obfuscation: A Deep Reinforcement Learning Approach",
    "authors": [
      "Brian Etter",
      "James Lee Hu",
      "Mohammedreza Ebrahimi",
      "Weifeng Li",
      "Xin Li",
      "Hsinchun Chen"
    ],
    "abstract": "Adversarial Malware Generation (AMG), the generation of adversarial malware\nvariants to strengthen Deep Learning (DL)-based malware detectors has emerged\nas a crucial tool in the development of proactive cyberdefense. However, the\nmajority of extant works offer subtle perturbations or additions to executable\nfiles and do not explore full-file obfuscation. In this study, we show that an\nopen-source encryption tool coupled with a Reinforcement Learning (RL)\nframework can successfully obfuscate malware to evade state-of-the-art malware\ndetection engines and outperform techniques that use advanced modification\nmethods. Our results show that the proposed method improves the evasion rate\nfrom 27%-49% compared to widely-used state-of-the-art reinforcement\nlearning-based methods.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02600v1",
    "published_date": "2024-02-04 20:23:15 UTC",
    "updated_date": "2024-02-04 20:23:15 UTC"
  },
  {
    "arxiv_id": "2402.02592v2",
    "title": "Unified Training of Universal Time Series Forecasting Transformers",
    "authors": [
      "Gerald Woo",
      "Chenghao Liu",
      "Akshat Kumar",
      "Caiming Xiong",
      "Silvio Savarese",
      "Doyen Sahoo"
    ],
    "abstract": "Deep learning for time series forecasting has traditionally operated within a\none-model-per-dataset framework, limiting its potential to leverage the\ngame-changing impact of large pre-trained models. The concept of universal\nforecasting, emerging from pre-training on a vast collection of time series\ndatasets, envisions a single Large Time Series Model capable of addressing\ndiverse downstream forecasting tasks. However, constructing such a model poses\nunique challenges specific to time series data: i) cross-frequency learning,\nii) accommodating an arbitrary number of variates for multivariate time series,\nand iii) addressing the varying distributional properties inherent in\nlarge-scale data. To address these challenges, we present novel enhancements to\nthe conventional time series Transformer architecture, resulting in our\nproposed Masked Encoder-based Universal Time Series Forecasting Transformer\n(Moirai). Trained on our newly introduced Large-scale Open Time Series Archive\n(LOTSA) featuring over 27B observations across nine domains, Moirai achieves\ncompetitive or superior performance as a zero-shot forecaster when compared to\nfull-shot models. Code, data, and model weights can be found at\nhttps://github.com/SalesforceAIResearch/uni2ts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02592v2",
    "published_date": "2024-02-04 20:00:45 UTC",
    "updated_date": "2024-05-22 11:49:59 UTC"
  },
  {
    "arxiv_id": "2402.05975v1",
    "title": "A Deep Learning Approach for Brain Tumor Classification and Segmentation Using a Multiscale Convolutional Neural Network",
    "authors": [
      "Francisco Javier Díaz-Pernas",
      "Mario Martínez-Zarzuela",
      "Míriam Antón-Rodríguez",
      "David González-Ortega"
    ],
    "abstract": "In this paper, we present a fully automatic brain tumor segmentation and\nclassification model using a Deep Convolutional Neural Network that includes a\nmultiscale approach. One of the differences of our proposal with respect to\nprevious works is that input images are processed in three spatial scales along\ndifferent processing pathways. This mechanism is inspired in the inherent\noperation of the Human Visual System. The proposed neural model can analyze MRI\nimages containing three types of tumors: meningioma, glioma, and pituitary\ntumor, over sagittal, coronal, and axial views and does not need preprocessing\nof input images to remove skull or vertebral column parts in advance. The\nperformance of our method on a publicly available MRI image dataset of 3064\nslices from 233 patients is compared with previously classical machine learning\nand deep learning published methods. In the comparison, our method remarkably\nobtained a tumor classification accuracy of 0.973, higher than the other\napproaches using the same database.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.05975v1",
    "published_date": "2024-02-04 17:47:03 UTC",
    "updated_date": "2024-02-04 17:47:03 UTC"
  },
  {
    "arxiv_id": "2402.02566v1",
    "title": "STAGE: Scalable and Traversability-Aware Graph based Exploration Planner for Dynamically Varying Environments",
    "authors": [
      "Akash Patel",
      "Mario A V Saucedo",
      "Christoforos Kanellakis",
      "George Nikolakopoulos"
    ],
    "abstract": "In this article, we propose a novel navigation framework that leverages a two\nlayered graph representation of the environment for efficient large-scale\nexploration, while it integrates a novel uncertainty awareness scheme to handle\ndynamic scene changes in previously explored areas. The framework is structured\naround a novel goal oriented graph representation, that consists of, i) the\nlocal sub-graph and ii) the global graph layer respectively. The local\nsub-graphs encode local volumetric gain locations as frontiers, based on the\ndirect pointcloud visibility, allowing fast graph building and path planning.\nAdditionally, the global graph is build in an efficient way, using node-edge\ninformation exchange only on overlapping regions of sequential sub-graphs.\nDifferent from the state-of-the-art graph based exploration methods, the\nproposed approach efficiently re-uses sub-graphs built in previous iterations\nto construct the global navigation layer. Another merit of the proposed scheme\nis the ability to handle scene changes (e.g. blocked pathways), adaptively\nupdating the obstructed part of the global graph from traversable to\nnot-traversable. This operation involved oriented sample space of a path\nsegment in the global graph layer, while removing the respective edges from\nconnected nodes of the global graph in cases of obstructions. As such, the\nexploration behavior is directing the robot to follow another route in the\nglobal re-positioning phase through path-way updates in the global graph.\nFinally, we showcase the performance of the method both in simulation runs as\nwell as deployed in real-world scene involving a legged robot carrying camera\nand lidar sensor.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02566v1",
    "published_date": "2024-02-04 17:05:27 UTC",
    "updated_date": "2024-02-04 17:05:27 UTC"
  },
  {
    "arxiv_id": "2402.02564v2",
    "title": "A Truly Joint Neural Architecture for Segmentation and Parsing",
    "authors": [
      "Danit Yshaayahu Levi",
      "Reut Tsarfaty"
    ],
    "abstract": "Contemporary multilingual dependency parsers can parse a diverse set of\nlanguages, but for Morphologically Rich Languages (MRLs), performance is\nattested to be lower than other languages. The key challenge is that, due to\nhigh morphological complexity and ambiguity of the space-delimited input\ntokens, the linguistic units that act as nodes in the tree are not known in\nadvance. Pre-neural dependency parsers for MRLs subscribed to the joint\nmorpho-syntactic hypothesis, stating that morphological segmentation and\nsyntactic parsing should be solved jointly, rather than as a pipeline where\nsegmentation precedes parsing. However, neural state-of-the-art parsers to date\nuse a strict pipeline. In this paper we introduce a joint neural architecture\nwhere a lattice-based representation preserving all morphological ambiguity of\nthe input is provided to an arc-factored model, which then solves the\nmorphological segmentation and syntactic parsing tasks at once. Our experiments\non Hebrew, a rich and highly ambiguous MRL, demonstrate state-of-the-art\nperformance on parsing, tagging and segmentation of the Hebrew section of UD,\nusing a single model. This proposed architecture is LLM-based and language\nagnostic, providing a solid foundation for MRLs to obtain further performance\nimprovements and bridge the gap with other languages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02564v2",
    "published_date": "2024-02-04 16:56:08 UTC",
    "updated_date": "2024-03-02 16:33:32 UTC"
  },
  {
    "arxiv_id": "2402.02563v4",
    "title": "Synergy-of-Thoughts: Eliciting Efficient Reasoning in Hybrid Language Models",
    "authors": [
      "Yu Shang",
      "Yu Li",
      "Fengli Xu",
      "Yong Li"
    ],
    "abstract": "Large language models (LLMs) have shown impressive emergent abilities in a\nwide range of tasks, but the associated expensive API cost greatly limits the\nreal application. Previous works like chain-of-thought (CoT) and\ntree-of-thoughts (ToT) have predominately focused on enhancing accuracy, but\noverlook the rapidly increasing API cost, which could be particularly\nproblematic for open-ended real-world tasks with huge solution spaces.\nMotivated by the dual process theory of human cognition, we propose \"Synergy of\nThoughts\"(SoT) to unleash the synergistic potential of hybrid LLMs with\ndifferent scales for efficient reasoning. By default, SoT uses smaller-scale\nlanguage models to generate multiple low-cost intuitive thoughts, which\nresembles the parallel intuitions produced by System 1. We then design a\nconfidence evaluator where the intuitive thoughts are cross-evaluated and\nintroduce a controllable threshold mechanism to decide their mutual conflict.\nIf these intuitive thoughts exhibit conflicts, SoT will invoke the reflective\nreasoning of scaled-up language models to emulate the intervention of System 2,\nwhich will override the intuitive thoughts and rectify the reasoning results.\nThis framework is model-agnostic and training-free, which can be flexibly\nimplemented with various off-the-shelf LLMs. Experiments on six representative\nreasoning tasks show that SoT substantially reduces the API cost by\n38.3%-75.1%, and simultaneously achieves state-of-the-art reasoning accuracy\nand solution diversity. Notably, the average token cost reduction on open-ended\ntasks reaches up to 69.1%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 16 figures, 12 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.02563v4",
    "published_date": "2024-02-04 16:45:01 UTC",
    "updated_date": "2024-08-24 14:46:55 UTC"
  },
  {
    "arxiv_id": "2402.02552v2",
    "title": "Neur2BiLO: Neural Bilevel Optimization",
    "authors": [
      "Justin Dumouchelle",
      "Esther Julien",
      "Jannis Kurtz",
      "Elias B. Khalil"
    ],
    "abstract": "Bilevel optimization deals with nested problems in which a leader takes the\nfirst decision to minimize their objective function while accounting for a\nfollower's best-response reaction. Constrained bilevel problems with integer\nvariables are particularly notorious for their hardness. While exact solvers\nhave been proposed for mixed-integer linear bilevel optimization, they tend to\nscale poorly with problem size and are hard to generalize to the non-linear\ncase. On the other hand, problem-specific algorithms (exact and heuristic) are\nlimited in scope. Under a data-driven setting in which similar instances of a\nbilevel problem are solved routinely, our proposed framework, Neur2BiLO, embeds\na neural network approximation of the leader's or follower's value function,\ntrained via supervised regression, into an easy-to-solve mixed-integer program.\nNeur2BiLO serves as a heuristic that produces high-quality solutions extremely\nfast for four applications with linear and non-linear objectives and pure and\nmixed-integer variables.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02552v2",
    "published_date": "2024-02-04 15:54:37 UTC",
    "updated_date": "2024-11-01 14:44:44 UTC"
  },
  {
    "arxiv_id": "2402.02549v2",
    "title": "Are Large Language Models Table-based Fact-Checkers?",
    "authors": [
      "Hanwen Zhang",
      "Qingyi Si",
      "Peng Fu",
      "Zheng Lin",
      "Weiping Wang"
    ],
    "abstract": "Table-based Fact Verification (TFV) aims to extract the entailment relation\nbetween statements and structured tables. Existing TFV methods based on\nsmall-scaled models suffer from insufficient labeled data and weak zero-shot\nability. Recently, the appearance of Large Language Models (LLMs) has gained\nlots of attraction in research fields. They have shown powerful zero-shot and\nin-context learning abilities on several NLP tasks, but their potential on TFV\nis still unknown. In this work, we implement a preliminary study about whether\nLLMs are table-based fact-checkers. In detail, we design diverse prompts to\nexplore how the in-context learning can help LLMs in TFV, i.e., zero-shot and\nfew-shot TFV capability. Besides, we carefully design and construct TFV\ninstructions to study the performance gain brought by the instruction tuning of\nLLMs. Experimental results demonstrate that LLMs can achieve acceptable results\non zero-shot and few-shot TFV with prompt engineering, while instruction-tuning\ncan stimulate the TFV capability significantly. We also make some valuable\nfindings about the format of zero-shot prompts and the number of in-context\nexamples. Finally, we analyze some possible directions to promote the accuracy\nof TFV via LLMs, which is beneficial to further research of table reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "CSCWD 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.02549v2",
    "published_date": "2024-02-04 15:52:59 UTC",
    "updated_date": "2024-11-13 12:37:09 UTC"
  },
  {
    "arxiv_id": "2402.02548v1",
    "title": "\"What's my model inside of?\": Exploring the role of environments for grounded natural language understanding",
    "authors": [
      "Ronen Tamari"
    ],
    "abstract": "In contrast to classical cognitive science which studied brains in isolation,\necological approaches focused on the role of the body and environment in\nshaping cognition. Similarly, in this thesis we adopt an ecological approach to\ngrounded natural language understanding (NLU) research. Grounded language\nunderstanding studies language understanding systems situated in the context of\nevents, actions and precepts in naturalistic/simulated virtual environments.\nWhere classic research tends to focus on designing new models and optimization\nmethods while treating environments as given, we explore the potential of\nenvironment design for improving data collection and model development. We\ndeveloped novel training and annotation approaches for procedural text\nunderstanding based on text-based game environments. We also drew upon embodied\ncognitive linguistics literature to propose a roadmap for grounded NLP\nresearch, and to inform the development of a new benchmark for measuring the\nprogress of large language models on challenging commonsense reasoning tasks.\nWe leveraged the richer supervision provided by text-based game environments to\ndevelop Breakpoint Transformers, a novel approach to modeling intermediate\nsemantic information in long narrative or procedural texts. Finally, we\nintegrated theories on the role of environments in collective human\nintelligence to propose a design for AI-augmented \"social thinking\nenvironments\" for knowledge workers like scientists.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "PhD Thesis",
    "pdf_url": "http://arxiv.org/pdf/2402.02548v1",
    "published_date": "2024-02-04 15:52:46 UTC",
    "updated_date": "2024-02-04 15:52:46 UTC"
  },
  {
    "arxiv_id": "2402.02547v2",
    "title": "Integration of cognitive tasks into artificial general intelligence test for large models",
    "authors": [
      "Youzhi Qu",
      "Chen Wei",
      "Penghui Du",
      "Wenxin Che",
      "Chi Zhang",
      "Wanli Ouyang",
      "Yatao Bian",
      "Feiyang Xu",
      "Bin Hu",
      "Kai Du",
      "Haiyan Wu",
      "Jia Liu",
      "Quanying Liu"
    ],
    "abstract": "During the evolution of large models, performance evaluation is necessarily\nperformed to assess their capabilities and ensure safety before practical\napplication. However, current model evaluations mainly rely on specific tasks\nand datasets, lacking a united framework for assessing the multidimensional\nintelligence of large models. In this perspective, we advocate for a\ncomprehensive framework of cognitive science-inspired artificial general\nintelligence (AGI) tests, aimed at fulfilling the testing needs of large models\nwith enhanced capabilities. The cognitive science-inspired AGI tests encompass\nthe full spectrum of intelligence facets, including crystallized intelligence,\nfluid intelligence, social intelligence, and embodied intelligence. To assess\nthe multidimensional intelligence of large models, the AGI tests consist of a\nbattery of well-designed cognitive tests adopted from human intelligence tests,\nand then naturally encapsulates into an immersive virtual community. We propose\nincreasing the complexity of AGI testing tasks commensurate with advancements\nin large models and emphasizing the necessity for the interpretation of test\nresults to avoid false negatives and false positives. We believe that cognitive\nscience-inspired AGI tests will effectively guide the targeted improvement of\nlarge models in specific dimensions of intelligence and accelerate the\nintegration of large models into human society.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02547v2",
    "published_date": "2024-02-04 15:50:42 UTC",
    "updated_date": "2024-03-06 02:46:40 UTC"
  },
  {
    "arxiv_id": "2402.02544v4",
    "title": "LHRS-Bot: Empowering Remote Sensing with VGI-Enhanced Large Multimodal Language Model",
    "authors": [
      "Dilxat Muhtar",
      "Zhenshi Li",
      "Feng Gu",
      "Xueliang Zhang",
      "Pengfeng Xiao"
    ],
    "abstract": "The revolutionary capabilities of large language models (LLMs) have paved the\nway for multimodal large language models (MLLMs) and fostered diverse\napplications across various specialized domains. In the remote sensing (RS)\nfield, however, the diverse geographical landscapes and varied objects in RS\nimagery are not adequately considered in recent MLLM endeavors. To bridge this\ngap, we construct a large-scale RS image-text dataset, LHRS-Align, and an\ninformative RS-specific instruction dataset, LHRS-Instruct, leveraging the\nextensive volunteered geographic information (VGI) and globally available RS\nimages. Building on this foundation, we introduce LHRS-Bot, an MLLM tailored\nfor RS image understanding through a novel multi-level vision-language\nalignment strategy and a curriculum learning method. Additionally, we introduce\nLHRS-Bench, a benchmark for thoroughly evaluating MLLMs' abilities in RS image\nunderstanding. Comprehensive experiments demonstrate that LHRS-Bot exhibits a\nprofound understanding of RS images and the ability to perform nuanced\nreasoning within the RS domain.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "36 pages, 10 figures. Github https://github.com/NJU-LHRS/LHRS-Bot",
    "pdf_url": "http://arxiv.org/pdf/2402.02544v4",
    "published_date": "2024-02-04 15:46:43 UTC",
    "updated_date": "2024-07-16 01:40:34 UTC"
  },
  {
    "arxiv_id": "2402.02541v1",
    "title": "Knowledge Generation for Zero-shot Knowledge-based VQA",
    "authors": [
      "Rui Cao",
      "Jing Jiang"
    ],
    "abstract": "Previous solutions to knowledge-based visual question answering~(K-VQA)\nretrieve knowledge from external knowledge bases and use supervised learning to\ntrain the K-VQA model. Recently pre-trained LLMs have been used as both a\nknowledge source and a zero-shot QA model for K-VQA and demonstrated promising\nresults. However, these recent methods do not explicitly show the knowledge\nneeded to answer the questions and thus lack interpretability. Inspired by\nrecent work on knowledge generation from LLMs for text-based QA, in this work\nwe propose and test a similar knowledge-generation-based K-VQA method, which\nfirst generates knowledge from an LLM and then incorporates the generated\nknowledge for K-VQA in a zero-shot manner. We evaluate our method on two K-VQA\nbenchmarks and found that our method performs better than previous zero-shot\nK-VQA methods and our generated knowledge is generally relevant and helpful.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted as Findings in EACL 2023",
    "pdf_url": "http://arxiv.org/pdf/2402.02541v1",
    "published_date": "2024-02-04 15:41:35 UTC",
    "updated_date": "2024-02-04 15:41:35 UTC"
  },
  {
    "arxiv_id": "2402.02522v1",
    "title": "Absolute convergence and error thresholds in non-active adaptive sampling",
    "authors": [
      "Manuel Vilares Ferro",
      "Victor M. Darriba Bilbao",
      "Jesús Vilares Ferro"
    ],
    "abstract": "Non-active adaptive sampling is a way of building machine learning models\nfrom a training data base which are supposed to dynamically and automatically\nderive guaranteed sample size. In this context and regardless of the strategy\nused in both scheduling and generating of weak predictors, a proposal for\ncalculating absolute convergence and error thresholds is described. We not only\nmake it possible to establish when the quality of the model no longer\nincreases, but also supplies a proximity condition to estimate in absolute\nterms how close it is to achieving such a goal, thus supporting decision making\nfor fine-tuning learning parameters in model selection. The technique proves\nits correctness and completeness with respect to our working hypotheses, in\naddition to strengthening the robustness of the sampling scheme. Tests meet our\nexpectations and illustrate the proposal in the domain of natural language\nprocessing, taking the generation of part-of-speech taggers as case study.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "27 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.02522v1",
    "published_date": "2024-02-04 15:10:34 UTC",
    "updated_date": "2024-02-04 15:10:34 UTC"
  },
  {
    "arxiv_id": "2402.06654v1",
    "title": "Conversational Crowdsensing: A Parallel Intelligence Powered Novel Sensing Approach",
    "authors": [
      "Zhengqiu Zhu",
      "Yong Zhao",
      "Bin Chen",
      "Sihang Qiu",
      "Kai Xu",
      "Quanjun Yin",
      "Jincai Huang",
      "Zhong Liu",
      "Fei-Yue Wang"
    ],
    "abstract": "The transition from CPS-based Industry 4.0 to CPSS-based Industry 5.0 brings\nnew requirements and opportunities to current sensing approaches, especially in\nlight of recent progress in Chatbots and Large Language Models (LLMs).\nTherefore, the advancement of parallel intelligence-powered Crowdsensing\nIntelligence (CSI) is witnessed, which is currently advancing towards\nlinguistic intelligence. In this paper, we propose a novel sensing paradigm,\nnamely conversational crowdsensing, for Industry 5.0. It can alleviate workload\nand professional requirements of individuals and promote the organization and\noperation of diverse workforce, thereby facilitating faster response and wider\npopularization of crowdsensing systems. Specifically, we design the\narchitecture of conversational crowdsensing to effectively organize three types\nof participants (biological, robotic, and digital) from diverse communities.\nThrough three levels of effective conversation (i.e., inter-human, human-AI,\nand inter-AI), complex interactions and service functionalities of different\nworkers can be achieved to accomplish various tasks across three sensing phases\n(i.e., requesting, scheduling, and executing). Moreover, we explore the\nfoundational technologies for realizing conversational crowdsensing,\nencompassing LLM-based multi-agent systems, scenarios engineering and\nconversational human-AI cooperation. Finally, we present potential industrial\napplications of conversational crowdsensing and discuss its implications. We\nenvision that conversations in natural language will become the primary\ncommunication channel during crowdsensing process, enabling richer information\nexchange and cooperative problem-solving among humans, robots, and AI.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06654v1",
    "published_date": "2024-02-04 15:10:11 UTC",
    "updated_date": "2024-02-04 15:10:11 UTC"
  },
  {
    "arxiv_id": "2402.02519v1",
    "title": "SIMPL: A Simple and Efficient Multi-agent Motion Prediction Baseline for Autonomous Driving",
    "authors": [
      "Lu Zhang",
      "Peiliang Li",
      "Sikang Liu",
      "Shaojie Shen"
    ],
    "abstract": "This paper presents a Simple and effIcient Motion Prediction baseLine (SIMPL)\nfor autonomous vehicles. Unlike conventional agent-centric methods with high\naccuracy but repetitive computations and scene-centric methods with compromised\naccuracy and generalizability, SIMPL delivers real-time, accurate motion\npredictions for all relevant traffic participants. To achieve improvements in\nboth accuracy and inference speed, we propose a compact and efficient global\nfeature fusion module that performs directed message passing in a symmetric\nmanner, enabling the network to forecast future motion for all road users in a\nsingle feed-forward pass and mitigating accuracy loss caused by viewpoint\nshifting. Additionally, we investigate the continuous trajectory\nparameterization using Bernstein basis polynomials in trajectory decoding,\nallowing evaluations of states and their higher-order derivatives at any\ndesired time point, which is valuable for downstream planning tasks. As a\nstrong baseline, SIMPL exhibits highly competitive performance on Argoverse 1 &\n2 motion forecasting benchmarks compared with other state-of-the-art methods.\nFurthermore, its lightweight design and low inference latency make SIMPL highly\nextensible and promising for real-world onboard deployment. We open-source the\ncode at https://github.com/HKUST-Aerial-Robotics/SIMPL.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Code is available at https://github.com/HKUST-Aerial-Robotics/SIMPL",
    "pdf_url": "http://arxiv.org/pdf/2402.02519v1",
    "published_date": "2024-02-04 15:07:49 UTC",
    "updated_date": "2024-02-04 15:07:49 UTC"
  },
  {
    "arxiv_id": "2402.02516v1",
    "title": "Adaptive scheduling for adaptive sampling in POS taggers construction",
    "authors": [
      "Manuel Vilares Ferro",
      "Victor M. Darriba Bilbao",
      "Jesús Vilares Ferro"
    ],
    "abstract": "We introduce an adaptive scheduling for adaptive sampling as a novel way of\nmachine learning in the construction of part-of-speech taggers. The goal is to\nspeed up the training on large data sets, without significant loss of\nperformance with regard to an optimal configuration. In contrast to previous\nmethods using a random, fixed or regularly rising spacing between the\ninstances, ours analyzes the shape of the learning curve geometrically in\nconjunction with a functional model to increase or decrease it at any time. The\nalgorithm proves to be formally correct regarding our working hypotheses.\nNamely, given a case, the following one is the nearest ensuring a net gain of\nlearning ability from the former, it being possible to modulate the level of\nrequirement for this condition. We also improve the robustness of sampling by\npaying greater attention to those regions of the training data base subject to\na temporary inflation in performance, thus preventing the learning from\nstopping prematurely.\n  The proposal has been evaluated on the basis of its reliability to identify\nthe convergence of models, corroborating our expectations. While a concrete\nhalting condition is used for testing, users can choose any condition\nwhatsoever to suit their own specific needs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pager, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.02516v1",
    "published_date": "2024-02-04 15:02:17 UTC",
    "updated_date": "2024-02-04 15:02:17 UTC"
  },
  {
    "arxiv_id": "2402.02515v1",
    "title": "Modeling of learning curves with applications to pos tagging",
    "authors": [
      "Manuel Vilares Ferro",
      "Victor M. Darriba Bilbao",
      "Francisco J. Ribadas Pena"
    ],
    "abstract": "An algorithm to estimate the evolution of learning curves on the whole of a\ntraining data base, based on the results obtained from a portion and using a\nfunctional strategy, is introduced. We approximate iteratively the sought value\nat the desired time, independently of the learning technique used and once a\npoint in the process, called prediction level, has been passed. The proposal\nproves to be formally correct with respect to our working hypotheses and\nincludes a reliable proximity condition. This allows the user to fix a\nconvergence threshold with respect to the accuracy finally achievable, which\nextends the concept of stopping criterion and seems to be effective even in the\npresence of distorting observations.\n  Our aim is to evaluate the training effort, supporting decision making in\norder to reduce the need for both human and computational resources during the\nlearning process. The proposal is of interest in at least three operational\nprocedures. The first is the anticipation of accuracy gain, with the purpose of\nmeasuring how much work is needed to achieve a certain degree of performance.\nThe second relates the comparison of efficiency between systems at training\ntime, with the objective of completing this task only for the one that best\nsuits our requirements. The prediction of accuracy is also a valuable item of\ninformation for customizing systems, since we can estimate in advance the\nimpact of settings on both the performance and the development costs. Using the\ngeneration of part-of-speech taggers as an example application, the\nexperimental results are consistent with our expectations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "30 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.02515v1",
    "published_date": "2024-02-04 15:00:52 UTC",
    "updated_date": "2024-02-04 15:00:52 UTC"
  },
  {
    "arxiv_id": "2402.02513v1",
    "title": "Early stopping by correlating online indicators in neural networks",
    "authors": [
      "Manuel Vilares Ferro",
      "Yerai Doval Mosquera",
      "Francisco J. Ribadas Pena",
      "Victor M. Darriba Bilbao"
    ],
    "abstract": "In order to minimize the generalization error in neural networks, a novel\ntechnique to identify overfitting phenomena when training the learner is\nformally introduced. This enables support of a reliable and trustworthy early\nstopping condition, thus improving the predictive power of that type of\nmodeling. Our proposal exploits the correlation over time in a collection of\nonline indicators, namely characteristic functions for indicating if a set of\nhypotheses are met, associated with a range of independent stopping conditions\nbuilt from a canary judgment to evaluate the presence of overfitting. That way,\nwe provide a formal basis for decision making in terms of interrupting the\nlearning process.\n  As opposed to previous approaches focused on a single criterion, we take\nadvantage of subsidiarities between independent assessments, thus seeking both\na wider operating range and greater diagnostic reliability. With a view to\nillustrating the effectiveness of the halting condition described, we choose to\nwork in the sphere of natural language processing, an operational continuum\nincreasingly based on machine learning. As a case study, we focus on parser\ngeneration, one of the most demanding and complex tasks in the domain. The\nselection of cross-validation as a canary function enables an actual comparison\nwith the most representative early stopping conditions based on overfitting\nidentification, pointing to a promising start toward an optimal bias and\nvariance control.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.02513v1",
    "published_date": "2024-02-04 14:57:20 UTC",
    "updated_date": "2024-02-04 14:57:20 UTC"
  },
  {
    "arxiv_id": "2402.03390v1",
    "title": "PixelGen: Rethinking Embedded Camera Systems",
    "authors": [
      "Kunjun Li",
      "Manoj Gulati",
      "Steven Waskito",
      "Dhairya Shah",
      "Shantanu Chakrabarty",
      "Ambuj Varshney"
    ],
    "abstract": "Embedded camera systems are ubiquitous, representing the most widely deployed\nexample of a wireless embedded system. They capture a representation of the\nworld - the surroundings illuminated by visible or infrared light. Despite\ntheir widespread usage, the architecture of embedded camera systems has\nremained unchanged, which leads to limitations. They visualize only a tiny\nportion of the world. Additionally, they are energy-intensive, leading to\nlimited battery lifespan. We present PixelGen, which re-imagines embedded\ncamera systems. Specifically, PixelGen combines sensors, transceivers, and\nlow-resolution image and infrared vision sensors to capture a broader world\nrepresentation. They are deliberately chosen for their simplicity, low bitrate,\nand power consumption, culminating in an energy-efficient platform. We show\nthat despite the simplicity, the captured data can be processed using\ntransformer-based image and language models to generate novel representations\nof the environment. For example, we demonstrate that it can allow the\ngeneration of high-definition images, while the camera utilises low-power,\nlow-resolution monochrome cameras. Furthermore, the capabilities of PixelGen\nextend beyond traditional photography, enabling visualization of phenomena\ninvisible to conventional cameras, such as sound waves. PixelGen can enable\nnumerous novel applications, and we demonstrate that it enables unique\nvisualization of the surroundings that are then projected on extended reality\nheadsets. We believe, PixelGen goes beyond conventional cameras and opens new\navenues for research and photography.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.NI"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03390v1",
    "published_date": "2024-02-04 14:41:56 UTC",
    "updated_date": "2024-02-04 14:41:56 UTC"
  },
  {
    "arxiv_id": "2402.02500v3",
    "title": "Point Cloud Matters: Rethinking the Impact of Different Observation Spaces on Robot Learning",
    "authors": [
      "Haoyi Zhu",
      "Yating Wang",
      "Di Huang",
      "Weicai Ye",
      "Wanli Ouyang",
      "Tong He"
    ],
    "abstract": "In robot learning, the observation space is crucial due to the distinct\ncharacteristics of different modalities, which can potentially become a\nbottleneck alongside policy design. In this study, we explore the influence of\nvarious observation spaces on robot learning, focusing on three predominant\nmodalities: RGB, RGB-D, and point cloud. We introduce OBSBench, a benchmark\ncomprising two simulators and 125 tasks, along with standardized pipelines for\nvarious encoders and policy baselines. Extensive experiments on diverse\ncontact-rich manipulation tasks reveal a notable trend: point cloud-based\nmethods, even those with the simplest designs, frequently outperform their RGB\nand RGB-D counterparts. This trend persists in both scenarios: training from\nscratch and utilizing pre-training. Furthermore, our findings demonstrate that\npoint cloud observations often yield better policy performance and\nsignificantly stronger generalization capabilities across various geometric and\nvisual conditions. These outcomes suggest that the 3D point cloud is a valuable\nobservation modality for intricate robotic tasks. We also suggest that\nincorporating both appearance and coordinate information can enhance the\nperformance of point cloud methods. We hope our work provides valuable insights\nand guidance for designing more generalizable and robust robotic models. Codes\nare available at https://github.com/HaoyiZhu/PointCloudMatters.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024) Track on Datasets and Benchmarks",
    "pdf_url": "http://arxiv.org/pdf/2402.02500v3",
    "published_date": "2024-02-04 14:18:45 UTC",
    "updated_date": "2024-10-22 09:42:39 UTC"
  },
  {
    "arxiv_id": "2402.02498v2",
    "title": "Fully Differentiable Correlation-driven 2D/3D Registration for X-ray to CT Image Fusion",
    "authors": [
      "Minheng Chen",
      "Zhirun Zhang",
      "Shuheng Gu",
      "Zhangyang Ge",
      "Youyong Kong"
    ],
    "abstract": "Image-based rigid 2D/3D registration is a critical technique for fluoroscopic\nguided surgical interventions. In recent years, some learning-based fully\ndifferentiable methods have produced beneficial outcomes while the process of\nfeature extraction and gradient flow transmission still lack controllability\nand interpretability. To alleviate these problems, in this work, we propose a\nnovel fully differentiable correlation-driven network using a dual-branch\nCNN-transformer encoder which enables the network to extract and separate\nlow-frequency global features from high-frequency local features. A\ncorrelation-driven loss is further proposed for low-frequency feature and\nhigh-frequency feature decomposition based on embedded information. Besides, a\ntraining strategy that learns to approximate a convex-shape similarity function\nis applied in our work. We test our approach on a in-house datasetand show that\nit outperforms both existing fully differentiable learning-based registration\napproaches and the conventional optimization-based baseline.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "ISBI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.02498v2",
    "published_date": "2024-02-04 14:12:51 UTC",
    "updated_date": "2024-03-15 08:44:40 UTC"
  },
  {
    "arxiv_id": "2402.02479v2",
    "title": "BRAIn: Bayesian Reward-conditioned Amortized Inference for natural language generation from feedback",
    "authors": [
      "Gaurav Pandey",
      "Yatin Nandwani",
      "Tahira Naseem",
      "Mayank Mishra",
      "Guangxuan Xu",
      "Dinesh Raghu",
      "Sachindra Joshi",
      "Asim Munawar",
      "Ramón Fernandez Astudillo"
    ],
    "abstract": "Distribution matching methods for language model alignment such as Generation\nwith Distributional Control (GDC) and Distributional Policy Gradient (DPG) have\nnot received the same level of attention in reinforcement learning from human\nfeedback (RLHF) as contrastive methods such as Sequence Likelihood Calibration\n(SLiC), Direct Preference Optimization (DPO) and its variants. We identify high\nvariance of the gradient estimate as the primary reason for the lack of success\nof these methods and propose a self-normalized baseline to reduce the variance.\nWe further generalize the target distribution in DPG, GDC and DPO by using\nBayes' rule to define the reward-conditioned posterior. The resulting approach,\nreferred to as BRAIn - Bayesian Reward-conditioned Amortized Inference acts as\na bridge between distribution matching methods and DPO and significantly\noutperforms prior art in summarization and Antropic HH tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML 2024 (main conference)",
    "pdf_url": "http://arxiv.org/pdf/2402.02479v2",
    "published_date": "2024-02-04 13:16:29 UTC",
    "updated_date": "2024-06-10 10:18:46 UTC"
  },
  {
    "arxiv_id": "2402.02478v1",
    "title": "Why are hyperbolic neural networks effective? A study on hierarchical representation capability",
    "authors": [
      "Shicheng Tan",
      "Huanjing Zhao",
      "Shu Zhao",
      "Yanping Zhang"
    ],
    "abstract": "Hyperbolic Neural Networks (HNNs), operating in hyperbolic space, have been\nwidely applied in recent years, motivated by the existence of an optimal\nembedding in hyperbolic space that can preserve data hierarchical relationships\n(termed Hierarchical Representation Capability, HRC) more accurately than\nEuclidean space. However, there is no evidence to suggest that HNNs can achieve\nthis theoretical optimal embedding, leading to much research being built on\nflawed motivations. In this paper, we propose a benchmark for evaluating HRC\nand conduct a comprehensive analysis of why HNNs are effective through\nlarge-scale experiments. Inspired by the analysis results, we propose several\npre-training strategies to enhance HRC and improve the performance of\ndownstream tasks, further validating the reliability of the analysis.\nExperiments show that HNNs cannot achieve the theoretical optimal embedding.\nThe HRC is significantly affected by the optimization objectives and\nhierarchical structures, and enhancing HRC through pre-training strategies can\nsignificantly improve the performance of HNNs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02478v1",
    "published_date": "2024-02-04 13:15:59 UTC",
    "updated_date": "2024-02-04 13:15:59 UTC"
  },
  {
    "arxiv_id": "2402.02468v2",
    "title": "Fast Peer Adaptation with Context-aware Exploration",
    "authors": [
      "Long Ma",
      "Yuanfei Wang",
      "Fangwei Zhong",
      "Song-Chun Zhu",
      "Yizhou Wang"
    ],
    "abstract": "Fast adapting to unknown peers (partners or opponents) with different\nstrategies is a key challenge in multi-agent games. To do so, it is crucial for\nthe agent to probe and identify the peer's strategy efficiently, as this is the\nprerequisite for carrying out the best response in adaptation. However,\nexploring the strategies of unknown peers is difficult, especially when the\ngames are partially observable and have a long horizon. In this paper, we\npropose a peer identification reward, which rewards the learning agent based on\nhow well it can identify the behavior pattern of the peer over the historical\ncontext, such as the observation over multiple episodes. This reward motivates\nthe agent to learn a context-aware policy for effective exploration and fast\nadaptation, i.e., to actively seek and collect informative feedback from peers\nwhen uncertain about their policies and to exploit the context to perform the\nbest response when confident. We evaluate our method on diverse testbeds that\ninvolve competitive (Kuhn Poker), cooperative (PO-Overcooked), or mixed\n(Predator-Prey-W) games with peer agents. We demonstrate that our method\ninduces more active exploration behavior, achieving faster adaptation and\nbetter outcomes than existing methods.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "ICML 2024. 20 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.02468v2",
    "published_date": "2024-02-04 13:02:27 UTC",
    "updated_date": "2024-08-09 08:05:39 UTC"
  },
  {
    "arxiv_id": "2402.02464v3",
    "title": "A Graph is Worth $K$ Words: Euclideanizing Graph using Pure Transformer",
    "authors": [
      "Zhangyang Gao",
      "Daize Dong",
      "Cheng Tan",
      "Jun Xia",
      "Bozhen Hu",
      "Stan Z. Li"
    ],
    "abstract": "Can we model Non-Euclidean graphs as pure language or even Euclidean vectors\nwhile retaining their inherent information? The Non-Euclidean property have\nposed a long term challenge in graph modeling. Despite recent graph neural\nnetworks and graph transformers efforts encoding graphs as Euclidean vectors,\nrecovering the original graph from vectors remains a challenge. In this paper,\nwe introduce GraphsGPT, featuring an Graph2Seq encoder that transforms\nNon-Euclidean graphs into learnable Graph Words in the Euclidean space, along\nwith a GraphGPT decoder that reconstructs the original graph from Graph Words\nto ensure information equivalence. We pretrain GraphsGPT on $100$M molecules\nand yield some interesting findings: (1) The pretrained Graph2Seq excels in\ngraph representation learning, achieving state-of-the-art results on $8/9$\ngraph classification and regression tasks. (2) The pretrained GraphGPT serves\nas a strong graph generator, demonstrated by its strong ability to perform both\nfew-shot and conditional graph generation. (3) Graph2Seq+GraphGPT enables\neffective graph mixup in the Euclidean space, overcoming previously known\nNon-Euclidean challenges. (4) The edge-centric pretraining framework GraphsGPT\ndemonstrates its efficacy in graph domain tasks, excelling in both\nrepresentation and generation. Code is available at\n\\href{https://github.com/A4Bio/GraphsGPT}{GitHub}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02464v3",
    "published_date": "2024-02-04 12:29:40 UTC",
    "updated_date": "2024-05-29 05:40:35 UTC"
  },
  {
    "arxiv_id": "2402.02460v2",
    "title": "Review of multimodal machine learning approaches in healthcare",
    "authors": [
      "Felix Krones",
      "Umar Marikkar",
      "Guy Parsons",
      "Adam Szmul",
      "Adam Mahdi"
    ],
    "abstract": "Machine learning methods in healthcare have traditionally focused on using\ndata from a single modality, limiting their ability to effectively replicate\nthe clinical practice of integrating multiple sources of information for\nimproved decision making. Clinicians typically rely on a variety of data\nsources including patients' demographic information, laboratory data, vital\nsigns and various imaging data modalities to make informed decisions and\ncontextualise their findings. Recent advances in machine learning have\nfacilitated the more efficient incorporation of multimodal data, resulting in\napplications that better represent the clinician's approach. Here, we provide a\nreview of multimodal machine learning approaches in healthcare, offering a\ncomprehensive overview of recent literature. We discuss the various data\nmodalities used in clinical diagnosis, with a particular emphasis on imaging\ndata. We evaluate fusion techniques, explore existing multimodal datasets and\nexamine common training strategies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "5 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.02460v2",
    "published_date": "2024-02-04 12:21:38 UTC",
    "updated_date": "2024-02-12 01:10:12 UTC"
  },
  {
    "arxiv_id": "2403.09673v2",
    "title": "FoldToken: Learning Protein Language via Vector Quantization and Beyond",
    "authors": [
      "Zhangyang Gao",
      "Cheng Tan",
      "Jue Wang",
      "Yufei Huang",
      "Lirong Wu",
      "Stan Z. Li"
    ],
    "abstract": "Is there a foreign language describing protein sequences and structures\nsimultaneously? Protein structures, represented by continuous 3D points, have\nlong posed a challenge due to the contrasting modeling paradigms of discrete\nsequences. We introduce \\textbf{FoldTokenizer} to represent protein\nsequence-structure as discrete symbols. This innovative approach involves\nprojecting residue types and structures into a discrete space, guided by a\nreconstruction loss for information preservation. We refer to the learned\ndiscrete symbols as \\textbf{FoldToken}, and the sequence of FoldTokens serves\nas a new protein language, transforming the protein sequence-structure into a\nunified modality. We apply the created protein language on general backbone\ninpainting and antibody design tasks, building the first GPT-style model\n(\\textbf{FoldGPT}) for sequence-structure co-generation with promising results.\nKey to our success is the substantial enhancement of the vector quantization\nmodule, Soft Conditional Vector Quantization (\\textbf{SoftCVQ}).",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.09673v2",
    "published_date": "2024-02-04 12:18:51 UTC",
    "updated_date": "2024-03-19 05:29:23 UTC"
  },
  {
    "arxiv_id": "2402.02452v2",
    "title": "XAI-CF -- Examining the Role of Explainable Artificial Intelligence in Cyber Forensics",
    "authors": [
      "Shahid Alam",
      "Zeynep Altiparmak"
    ],
    "abstract": "With the rise of complex cyber devices Cyber Forensics (CF) is facing many\nnew challenges. For example, there are dozens of systems running on\nsmartphones, each with more than millions of downloadable applications. Sifting\nthrough this large amount of data and making sense requires new techniques,\nsuch as from the field of Artificial Intelligence (AI). To apply these\ntechniques successfully in CF, we need to justify and explain the results to\nthe stakeholders of CF, such as forensic analysts and members of the court, for\nthem to make an informed decision. If we want to apply AI successfully in CF,\nthere is a need to develop trust in AI systems. Some other factors in accepting\nthe use of AI in CF are to make AI authentic, interpretable, understandable,\nand interactive. This way, AI systems will be more acceptable to the public and\nensure alignment with legal standards. An explainable AI (XAI) system can play\nthis role in CF, and we call such a system XAI-CF. XAI-CF is indispensable and\nis still in its infancy. In this paper, we explore and make a case for the\nsignificance and advantages of XAI-CF. We strongly emphasize the need to build\na successful and practical XAI-CF system and discuss some of the main\nrequirements and prerequisites of such a system. We present a formal definition\nof the terms CF and XAI-CF and a comprehensive literature review of previous\nworks that apply and utilize XAI to build and increase trust in CF. We discuss\nsome challenges facing XAI-CF. We also provide some concrete solutions to these\nchallenges. We identify key insights and future research directions for\nbuilding XAI applications for CF. This paper is an effort to explore and\nfamiliarize the readers with the role of XAI applications in CF, and we believe\nthat our work provides a promising basis for future researchers interested in\nXAI-CF.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02452v2",
    "published_date": "2024-02-04 11:42:16 UTC",
    "updated_date": "2024-02-07 09:00:09 UTC"
  },
  {
    "arxiv_id": "2402.02441v5",
    "title": "TopoX: A Suite of Python Packages for Machine Learning on Topological Domains",
    "authors": [
      "Mustafa Hajij",
      "Mathilde Papillon",
      "Florian Frantzen",
      "Jens Agerberg",
      "Ibrahem AlJabea",
      "Rubén Ballester",
      "Claudio Battiloro",
      "Guillermo Bernárdez",
      "Tolga Birdal",
      "Aiden Brent",
      "Peter Chin",
      "Sergio Escalera",
      "Simone Fiorellino",
      "Odin Hoff Gardaa",
      "Gurusankar Gopalakrishnan",
      "Devendra Govil",
      "Josef Hoppe",
      "Maneel Reddy Karri",
      "Jude Khouja",
      "Manuel Lecha",
      "Neal Livesay",
      "Jan Meißner",
      "Soham Mukherjee",
      "Alexander Nikitin",
      "Theodore Papamarkou",
      "Jaro Prílepok",
      "Karthikeyan Natesan Ramamurthy",
      "Paul Rosen",
      "Aldo Guzmán-Sáenz",
      "Alessandro Salatiello",
      "Shreyas N. Samaga",
      "Simone Scardapane",
      "Michael T. Schaub",
      "Luca Scofano",
      "Indro Spinelli",
      "Lev Telyatnikov",
      "Quang Truong",
      "Robin Walters",
      "Maosheng Yang",
      "Olga Zaghen",
      "Ghada Zamzmi",
      "Ali Zia",
      "Nina Miolane"
    ],
    "abstract": "We introduce TopoX, a Python software suite that provides reliable and\nuser-friendly building blocks for computing and machine learning on topological\ndomains that extend graphs: hypergraphs, simplicial, cellular, path and\ncombinatorial complexes. TopoX consists of three packages: TopoNetX facilitates\nconstructing and computing on these domains, including working with nodes,\nedges and higher-order cells; TopoEmbedX provides methods to embed topological\ndomains into vector spaces, akin to popular graph-based embedding algorithms\nsuch as node2vec; TopoModelX is built on top of PyTorch and offers a\ncomprehensive toolbox of higher-order message passing functions for neural\nnetworks on topological domains. The extensively documented and unit-tested\nsource code of TopoX is available under MIT license at\nhttps://pyt-team.github.io/}{https://pyt-team.github.io/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MS",
      "stat.CO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02441v5",
    "published_date": "2024-02-04 10:41:40 UTC",
    "updated_date": "2024-12-09 02:29:37 UTC"
  },
  {
    "arxiv_id": "2402.02439v2",
    "title": "DiffStitch: Boosting Offline Reinforcement Learning with Diffusion-based Trajectory Stitching",
    "authors": [
      "Guanghe Li",
      "Yixiang Shan",
      "Zhengbang Zhu",
      "Ting Long",
      "Weinan Zhang"
    ],
    "abstract": "In offline reinforcement learning (RL), the performance of the learned policy\nhighly depends on the quality of offline datasets. However, in many cases, the\noffline dataset contains very limited optimal trajectories, which poses a\nchallenge for offline RL algorithms as agents must acquire the ability to\ntransit to high-reward regions. To address this issue, we introduce\nDiffusion-based Trajectory Stitching (DiffStitch), a novel diffusion-based data\naugmentation pipeline that systematically generates stitching transitions\nbetween trajectories. DiffStitch effectively connects low-reward trajectories\nwith high-reward trajectories, forming globally optimal trajectories to address\nthe challenges faced by offline RL algorithms. Empirical experiments conducted\non D4RL datasets demonstrate the effectiveness of DiffStitch across RL\nmethodologies. Notably, DiffStitch demonstrates substantial enhancements in the\nperformance of one-step methods (IQL), imitation learning methods (TD3+BC), and\ntrajectory optimization methods (DT).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02439v2",
    "published_date": "2024-02-04 10:30:23 UTC",
    "updated_date": "2024-02-22 00:05:12 UTC"
  },
  {
    "arxiv_id": "2402.03388v2",
    "title": "Delivery Optimized Discovery in Behavioral User Segmentation under Budget Constraint",
    "authors": [
      "Harshita Chopra",
      "Atanu R. Sinha",
      "Sunav Choudhary",
      "Ryan A. Rossi",
      "Paavan Kumar Indela",
      "Veda Pranav Parwatala",
      "Srinjayee Paul",
      "Aurghya Maiti"
    ],
    "abstract": "Users' behavioral footprints online enable firms to discover behavior-based\nuser segments (or, segments) and deliver segment specific messages to users.\nFollowing the discovery of segments, delivery of messages to users through\npreferred media channels like Facebook and Google can be challenging, as only a\nportion of users in a behavior segment find match in a medium, and only a\nfraction of those matched actually see the message (exposure). Even high\nquality discovery becomes futile when delivery fails. Many sophisticated\nalgorithms exist for discovering behavioral segments; however, these ignore the\ndelivery component. The problem is compounded because (i) the discovery is\nperformed on the behavior data space in firms' data (e.g., user clicks), while\nthe delivery is predicated on the static data space (e.g., geo, age) as defined\nby media; and (ii) firms work under budget constraint. We introduce a\nstochastic optimization based algorithm for delivery optimized discovery of\nbehavioral user segmentation and offer new metrics to address the joint\noptimization. We leverage optimization under a budget constraint for delivery\ncombined with a learning-based component for discovery. Extensive experiments\non a public dataset from Google and a proprietary dataset show the\neffectiveness of our approach by simultaneously improving delivery metrics,\nreducing budget spend and achieving strong predictive performance in discovery.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03388v2",
    "published_date": "2024-02-04 10:18:33 UTC",
    "updated_date": "2024-03-15 08:16:14 UTC"
  },
  {
    "arxiv_id": "2402.02423v2",
    "title": "Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback",
    "authors": [
      "Yifu Yuan",
      "Jianye Hao",
      "Yi Ma",
      "Zibin Dong",
      "Hebin Liang",
      "Jinyi Liu",
      "Zhixin Feng",
      "Kai Zhao",
      "Yan Zheng"
    ],
    "abstract": "Reinforcement Learning with Human Feedback (RLHF) has received significant\nattention for performing tasks without the need for costly manual reward design\nby aligning human preferences. It is crucial to consider diverse human feedback\ntypes and various learning methods in different environments. However,\nquantifying progress in RLHF with diverse feedback is challenging due to the\nlack of standardized annotation platforms and widely used unified benchmarks.\nTo bridge this gap, we introduce Uni-RLHF, a comprehensive system\nimplementation tailored for RLHF. It aims to provide a complete workflow from\nreal human feedback, fostering progress in the development of practical\nproblems. Uni-RLHF contains three packages: 1) a universal multi-feedback\nannotation platform, 2) large-scale crowdsourced feedback datasets, and 3)\nmodular offline RLHF baseline implementations. Uni-RLHF develops a\nuser-friendly annotation interface tailored to various feedback types,\ncompatible with a wide range of mainstream RL environments. We then establish a\nsystematic pipeline of crowdsourced annotations, resulting in large-scale\nannotated datasets comprising more than 15 million steps across 30+ popular\ntasks. Through extensive experiments, the results in the collected datasets\ndemonstrate competitive performance compared to those from well-designed manual\nrewards. We evaluate various design choices and offer insights into their\nstrengths and potential areas of improvement. We wish to build valuable\nopen-source platforms, datasets, and baselines to facilitate the development of\nmore robust and reliable RLHF solutions based on realistic human feedback. The\nwebsite is available at https://uni-rlhf.github.io/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICLR 2024. The website is\n  available at https://uni-rlhf.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2402.02423v2",
    "published_date": "2024-02-04 09:40:22 UTC",
    "updated_date": "2024-03-25 13:20:46 UTC"
  },
  {
    "arxiv_id": "2402.02420v3",
    "title": "Factuality of Large Language Models: A Survey",
    "authors": [
      "Yuxia Wang",
      "Minghan Wang",
      "Muhammad Arslan Manzoor",
      "Fei Liu",
      "Georgi Georgiev",
      "Rocktim Jyoti Das",
      "Preslav Nakov"
    ],
    "abstract": "Large language models (LLMs), especially when instruction-tuned for chat,\nhave become part of our daily lives, freeing people from the process of\nsearching, extracting, and integrating information from multiple sources by\noffering a straightforward answer to a variety of questions in a single place.\nUnfortunately, in many cases, LLM responses are factually incorrect, which\nlimits their applicability in real-world scenarios. As a result, research on\nevaluating and improving the factuality of LLMs has attracted a lot of\nattention recently. In this survey, we critically analyze existing work with\nthe aim to identify the major challenges and their associated causes, pointing\nout to potential solutions for improving the factuality of LLMs, and analyzing\nthe obstacles to automated factuality evaluation for open-ended text\ngeneration. We further offer an outlook on where future research should go.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 1 figure and 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.02420v3",
    "published_date": "2024-02-04 09:36:31 UTC",
    "updated_date": "2024-10-31 04:50:59 UTC"
  },
  {
    "arxiv_id": "2402.02416v5",
    "title": "Aligner: Efficient Alignment by Learning to Correct",
    "authors": [
      "Jiaming Ji",
      "Boyuan Chen",
      "Hantao Lou",
      "Donghai Hong",
      "Borong Zhang",
      "Xuehai Pan",
      "Juntao Dai",
      "Tianyi Qiu",
      "Yaodong Yang"
    ],
    "abstract": "With the rapid development of large language models (LLMs) and ever-evolving\npractical requirements, finding an efficient and effective alignment method has\nnever been more critical. However, the tension between the complexity of\ncurrent alignment methods and the need for rapid iteration in deployment\nscenarios necessitates the development of a model-agnostic alignment approach\nthat can operate under these constraints. In this paper, we introduce Aligner,\na novel and simple alignment paradigm that learns the correctional residuals\nbetween preferred and dispreferred answers using a small model. Designed as a\nmodel-agnostic, plug-and-play module, Aligner can be directly applied to\nvarious open-source and API-based models with only one-off training, making it\nsuitable for rapid iteration. Notably, Aligner can be applied to any powerful,\nlarge-scale upstream models. Moreover, it can even iteratively bootstrap the\nupstream models using corrected responses as synthetic human preference data,\nbreaking through the model's performance ceiling. Our experiments demonstrate\nperformance improvements by deploying the same Aligner model across 11\ndifferent LLMs, evaluated on the 3H dimensions (helpfulness, harmlessness, and\nhonesty). Specifically, Aligner-7B has achieved an average improvement of 68.9%\nin helpfulness and 23.8% in harmlessness across the tested LLMs while also\neffectively reducing hallucination. In the Alpaca-Eval leaderboard, stacking\nAligner-2B on GPT-4 Turbo improved its LC Win Rate from 55.0% to 58.3%,\nsurpassing GPT-4 Omni's 57.5% Win Rate (community report).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by NeurIPS 2024 Oral Presentation",
    "pdf_url": "http://arxiv.org/pdf/2402.02416v5",
    "published_date": "2024-02-04 09:24:51 UTC",
    "updated_date": "2024-11-02 10:01:38 UTC"
  },
  {
    "arxiv_id": "2402.03386v1",
    "title": "A generalized decision tree ensemble based on the NeuralNetworks architecture: Distributed Gradient Boosting Forest (DGBF)",
    "authors": [
      "Ángel Delgado-Panadero",
      "José Alberto Benítez-Andrades",
      "María Teresa García-Ordás"
    ],
    "abstract": "Tree ensemble algorithms as RandomForest and GradientBoosting are currently\nthe dominant methods for modeling discrete or tabular data, however, they are\nunable to perform a hierarchical representation learning from raw data as\nNeuralNetworks does thanks to its multi-layered structure, which is a key\nfeature for DeepLearning problems and modeling unstructured data. This\nlimitation is due to the fact that tree algorithms can not be trained with\nback-propagation because of their mathematical nature. However, in this work,\nwe demonstrate that the mathematical formulation of bagging and boosting can be\ncombined together to define a graph-structured-tree-ensemble algorithm with a\ndistributed representation learning process between trees naturally (without\nusing back-propagation). We call this novel approach Distributed Gradient\nBoosting Forest (DGBF) and we demonstrate that both RandomForest and\nGradientBoosting can be expressed as particular graph architectures of DGBT.\nFinally, we see that the distributed learning outperforms both RandomForest and\nGradientBoosting in 7 out of 9 datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03386v1",
    "published_date": "2024-02-04 09:22:52 UTC",
    "updated_date": "2024-02-04 09:22:52 UTC"
  },
  {
    "arxiv_id": "2402.03384v1",
    "title": "Survival and grade of the glioma prediction using transfer learning",
    "authors": [
      "Santiago Valbuena Rubio",
      "María Teresa García-Ordás",
      "Oscar García-Olalla Olivera",
      "Héctor Alaiz-Moretón",
      "Maria-Inmaculada González-Alonso",
      "José Alberto Benítez-Andrades"
    ],
    "abstract": "Glioblastoma is a highly malignant brain tumor with a life expectancy of only\n3 to 6 months without treatment. Detecting and predicting its survival and\ngrade accurately are crucial. This study introduces a novel approach using\ntransfer learning techniques. Various pre-trained networks, including\nEfficientNet, ResNet, VGG16, and Inception, were tested through exhaustive\noptimization to identify the most suitable architecture. Transfer learning was\napplied to fine-tune these models on a glioblastoma image dataset, aiming to\nachieve two objectives: survival and tumor grade prediction.The experimental\nresults show 65% accuracy in survival prediction, classifying patients into\nshort, medium, or long survival categories. Additionally, the prediction of\ntumor grade achieved an accuracy of 97%, accurately differentiating low-grade\ngliomas (LGG) and high-grade gliomas (HGG). The success of the approach is\nattributed to the effectiveness of transfer learning, surpassing the current\nstate-of-the-art methods. In conclusion, this study presents a promising method\nfor predicting the survival and grade of glioblastoma. Transfer learning\ndemonstrates its potential in enhancing prediction models, particularly in\nscenarios with limited large datasets. These findings hold promise for\nimproving diagnostic and treatment approaches for glioblastoma patients.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03384v1",
    "published_date": "2024-02-04 09:07:07 UTC",
    "updated_date": "2024-02-04 09:07:07 UTC"
  },
  {
    "arxiv_id": "2402.02401v1",
    "title": "AI-Generated Content Enhanced Computer-Aided Diagnosis Model for Thyroid Nodules: A ChatGPT-Style Assistant",
    "authors": [
      "Jincao Yao",
      "Yunpeng Wang",
      "Zhikai Lei",
      "Kai Wang",
      "Xiaoxian Li",
      "Jianhua Zhou",
      "Xiang Hao",
      "Jiafei Shen",
      "Zhenping Wang",
      "Rongrong Ru",
      "Yaqing Chen",
      "Yahan Zhou",
      "Chen Chen",
      "Yanming Zhang",
      "Ping Liang",
      "Dong Xu"
    ],
    "abstract": "An artificial intelligence-generated content-enhanced computer-aided\ndiagnosis (AIGC-CAD) model, designated as ThyGPT, has been developed. This\nmodel, inspired by the architecture of ChatGPT, could assist radiologists in\nassessing the risk of thyroid nodules through semantic-level human-machine\ninteraction. A dataset comprising 19,165 thyroid nodule ultrasound cases from\nZhejiang Cancer Hospital was assembled to facilitate the training and\nvalidation of the model. After training, ThyGPT could automatically evaluate\nthyroid nodule and engage in effective communication with physicians through\nhuman-computer interaction. The performance of ThyGPT was rigorously quantified\nusing established metrics such as the receiver operating characteristic (ROC)\ncurve, area under the curve (AUC), sensitivity, and specificity. The empirical\nfindings revealed that radiologists, when supplemented with ThyGPT, markedly\nsurpassed the diagnostic acumen of their peers utilizing traditional methods as\nwell as the performance of the model in isolation. These findings suggest that\nAIGC-CAD systems, exemplified by ThyGPT, hold the promise to fundamentally\ntransform the diagnostic workflows of radiologists in forthcoming years.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02401v1",
    "published_date": "2024-02-04 08:24:13 UTC",
    "updated_date": "2024-02-04 08:24:13 UTC"
  },
  {
    "arxiv_id": "2402.02399v2",
    "title": "FreDF: Learning to Forecast in the Frequency Domain",
    "authors": [
      "Hao Wang",
      "Licheng Pan",
      "Zhichao Chen",
      "Degui Yang",
      "Sen Zhang",
      "Yifei Yang",
      "Xinggao Liu",
      "Haoxuan Li",
      "Dacheng Tao"
    ],
    "abstract": "Time series modeling presents unique challenges due to autocorrelation in\nboth historical data and future sequences. While current research predominantly\naddresses autocorrelation within historical data, the correlations among future\nlabels are often overlooked. Specifically, modern forecasting models primarily\nadhere to the Direct Forecast (DF) paradigm, generating multi-step forecasts\nindependently and disregarding label autocorrelation over time. In this work,\nwe demonstrate that the learning objective of DF is biased in the presence of\nlabel autocorrelation. To address this issue, we propose the Frequency-enhanced\nDirect Forecast (FreDF), which mitigates label autocorrelation by learning to\nforecast in the frequency domain, thereby reducing estimation bias. Our\nexperiments show that FreDF significantly outperforms existing state-of-the-art\nmethods and is compatible with a variety of forecast models. Code is available\nat https://github.com/Master-PLC/FreDF.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2402.02399v2",
    "published_date": "2024-02-04 08:23:41 UTC",
    "updated_date": "2025-05-06 06:56:48 UTC"
  },
  {
    "arxiv_id": "2402.02392v3",
    "title": "DeLLMa: Decision Making Under Uncertainty with Large Language Models",
    "authors": [
      "Ollie Liu",
      "Deqing Fu",
      "Dani Yogatama",
      "Willie Neiswanger"
    ],
    "abstract": "The potential of large language models (LLMs) as decision support tools is\nincreasingly being explored in fields such as business, engineering, and\nmedicine, which often face challenging tasks of decision-making under\nuncertainty. In this paper, we show that directly prompting LLMs on these types\nof decision-making problems can yield poor results, especially as the problem\ncomplexity increases. To aid in these tasks, we propose DeLLMa (Decision-making\nLarge Language Model assistant), a framework designed to enhance\ndecision-making accuracy in uncertain environments. DeLLMa involves a\nmulti-step reasoning procedure that integrates recent best practices in scaling\ninference-time reasoning, drawing upon principles from decision theory and\nutility theory, to provide an accurate and human-auditable decision-making\nprocess. We validate our procedure on multiple realistic decision-making\nenvironments, demonstrating that DeLLMa can consistently enhance the\ndecision-making performance of leading language models, and achieve up to a 40%\nincrease in accuracy over competing methods. Additionally, we show how\nperformance improves when scaling compute at test time, and carry out human\nevaluations to benchmark components of DeLLMa.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "37 pages, 24 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.02392v3",
    "published_date": "2024-02-04 08:11:45 UTC",
    "updated_date": "2024-10-11 17:43:48 UTC"
  },
  {
    "arxiv_id": "2402.02389v2",
    "title": "KICGPT: Large Language Model with Knowledge in Context for Knowledge Graph Completion",
    "authors": [
      "Yanbin Wei",
      "Qiushi Huang",
      "James T. Kwok",
      "Yu Zhang"
    ],
    "abstract": "Knowledge Graph Completion (KGC) is crucial for addressing knowledge graph\nincompleteness and supporting downstream applications. Many models have been\nproposed for KGC. They can be categorized into two main classes: triple-based\nand text-based approaches. Triple-based methods struggle with long-tail\nentities due to limited structural information and imbalanced entity\ndistributions. Text-based methods alleviate this issue but require costly\ntraining for language models and specific finetuning for knowledge graphs,\nwhich limits their efficiency. To alleviate these limitations, in this paper,\nwe propose KICGPT, a framework that integrates a large language model (LLM) and\na triple-based KGC retriever. It alleviates the long-tail problem without\nincurring additional training overhead. KICGPT uses an in-context learning\nstrategy called Knowledge Prompt, which encodes structural knowledge into\ndemonstrations to guide the LLM. Empirical results on benchmark datasets\ndemonstrate the effectiveness of KICGPT with smaller training overhead and no\nfinetuning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2023 Findings",
    "pdf_url": "http://arxiv.org/pdf/2402.02389v2",
    "published_date": "2024-02-04 08:01:07 UTC",
    "updated_date": "2024-02-23 09:01:44 UTC"
  },
  {
    "arxiv_id": "2402.02388v1",
    "title": "Solution-oriented Agent-based Models Generation with Verifier-assisted Iterative In-context Learning",
    "authors": [
      "Tong Niu",
      "Weihao Zhang",
      "Rong Zhao"
    ],
    "abstract": "Agent-based models (ABMs) stand as an essential paradigm for proposing and\nvalidating hypothetical solutions or policies aimed at addressing challenges\nposed by complex systems and achieving various objectives. This process demands\nlabor-intensive endeavors and multidisciplinary expertise. Large language\nmodels (LLMs) encapsulating cross-domain knowledge and programming proficiency\ncould potentially alleviate the difficulty of this process. However, LLMs excel\nin handling sequential information, making it challenging for analyzing the\nintricate interactions and nonlinear dynamics inherent in ABMs. Additionally,\ndue to the lack of self-evaluation capability of LLMs, relying solely on LLMs\nis insufficient to effectively accomplish this process. In this paper, we\npresent SAGE, a general solution-oriented ABM generation framework designed for\nautomatic modeling and generating solutions for targeted problems. Unlike\napproaches reliant on expert handcrafting or resource-intensive neural network\ntraining, SAGE establishes a verifier-assisted iterative in-context learning\nprocess employing large language models (LLMs) to leverages their inherent\ncross-domain knowledge for tackling intricate demands from diverse domain\nscenarios. In SAGE, we introduce an semi-structured conceptual representation\nexpliciting the intricate structures of ABMs and an objective representation to\nguide LLMs in modeling scenarios and proposing hypothetical solutions through\nin-context learning. To ensure the model executability and solution\nfeasibility, SAGE devises a two-level verifier with chain-of-thought prompting\ntailored to the complex interactions and non-linear dynamics of ABMs, driving\nthe iterative generation optimization. Moreover, we construct an evaluation\ndataset of solution-oriented ABMs from open sources.It contains practical\nmodels across various domains.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02388v1",
    "published_date": "2024-02-04 07:59:06 UTC",
    "updated_date": "2024-02-04 07:59:06 UTC"
  },
  {
    "arxiv_id": "2402.02385v1",
    "title": "A Survey on Robotics with Foundation Models: toward Embodied AI",
    "authors": [
      "Zhiyuan Xu",
      "Kun Wu",
      "Junjie Wen",
      "Jinming Li",
      "Ning Liu",
      "Zhengping Che",
      "Jian Tang"
    ],
    "abstract": "While the exploration for embodied AI has spanned multiple decades, it\nremains a persistent challenge to endow agents with human-level intelligence,\nincluding perception, learning, reasoning, decision-making, control, and\ngeneralization capabilities, so that they can perform general-purpose tasks in\nopen, unstructured, and dynamic environments. Recent advances in computer\nvision, natural language processing, and multi-modality learning have shown\nthat the foundation models have superhuman capabilities for specific tasks.\nThey not only provide a solid cornerstone for integrating basic modules into\nembodied AI systems but also shed light on how to scale up robot learning from\na methodological perspective. This survey aims to provide a comprehensive and\nup-to-date overview of foundation models in robotics, focusing on autonomous\nmanipulation and encompassing high-level planning and low-level control.\nMoreover, we showcase their commonly used datasets, simulators, and benchmarks.\nImportantly, we emphasize the critical challenges intrinsic to this field and\ndelineate potential avenues for future research, contributing to advancing the\nfrontier of academic and industrial discourse.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02385v1",
    "published_date": "2024-02-04 07:55:01 UTC",
    "updated_date": "2024-02-04 07:55:01 UTC"
  },
  {
    "arxiv_id": "2402.02381v1",
    "title": "Empowering Computing and Networks Convergence System with Distributed Cooperative Routing",
    "authors": [
      "Yujiao Hu",
      "Qingmin Jia",
      "Meng Shen",
      "Renchao Xie",
      "Tao Huang",
      "F. Richard Yu"
    ],
    "abstract": "The emergence of intelligent applications and recent advances in the fields\nof computing and networks are driving the development of computing and networks\nconvergence (CNC) system. However, existing researches failed to achieve\ncomprehensive scheduling optimization of computing and network resources. This\nshortfall results in some requirements of computing requests unable to be\nguaranteed in an end-to-end service pattern, negatively impacting the\ndevelopment of CNC systems. In this article, we propose a distributed\ncooperative routing framework for the CNC system to ensure the deadline\nrequirements and minimize the computation cost of requests. The framework\nincludes trading plane, management plane, control plane and forwarding plane.\nThe cross-plane cooperative end-to-end routing schemes consider both\ncomputation efficiency of heterogeneous servers and the network congestion\ndegrees while making routing plan, thereby determining where to execute\nrequests and corresponding routing paths. Simulations results substantiates the\nperformance of our routing schemes in scheduling computing requests in the CNC\nsystem.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "Submit to IEEE Network",
    "pdf_url": "http://arxiv.org/pdf/2402.02381v1",
    "published_date": "2024-02-04 07:44:06 UTC",
    "updated_date": "2024-02-04 07:44:06 UTC"
  },
  {
    "arxiv_id": "2402.02380v3",
    "title": "Evaluating Large Language Models in Analysing Classroom Dialogue",
    "authors": [
      "Yun Long",
      "Haifeng Luo",
      "Yu Zhang"
    ],
    "abstract": "This study explores the application of Large Language Models (LLMs),\nspecifically GPT-4, in the analysis of classroom dialogue, a crucial research\ntask for both teaching diagnosis and quality improvement. Recognizing the\nknowledge-intensive and labor-intensive nature of traditional qualitative\nmethods in educational research, this study investigates the potential of LLM\nto streamline and enhance the analysis process. The study involves datasets\nfrom a middle school, encompassing classroom dialogues across mathematics and\nChinese classes. These dialogues were manually coded by educational experts and\nthen analyzed using a customised GPT-4 model. This study focuses on comparing\nmanual annotations with the outputs of GPT-4 to evaluate its efficacy in\nanalyzing educational dialogues. Time efficiency, inter-coder agreement, and\ninter-coder reliability between human coders and GPT-4 are evaluated. Results\nindicate substantial time savings with GPT-4, and a high degree of consistency\nin coding between the model and human coders, with some discrepancies in\nspecific codes. These findings highlight the strong potential of LLM in\nteaching evaluation and facilitation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02380v3",
    "published_date": "2024-02-04 07:39:06 UTC",
    "updated_date": "2024-02-23 02:19:09 UTC"
  },
  {
    "arxiv_id": "2403.09671v2",
    "title": "CoRaiS: Lightweight Real-Time Scheduler for Multi-Edge Cooperative Computing",
    "authors": [
      "Yujiao Hu",
      "Qingmin Jia",
      "Jinchao Chen",
      "Yuan Yao",
      "Yan Pan",
      "Renchao Xie",
      "F. Richard Yu"
    ],
    "abstract": "Multi-edge cooperative computing that combines constrained resources of\nmultiple edges into a powerful resource pool has the potential to deliver great\nbenefits, such as a tremendous computing power, improved response time, more\ndiversified services. However, the mass heterogeneous resources composition and\nlack of scheduling strategies make the modeling and cooperating of multi-edge\ncomputing system particularly complicated. This paper first proposes a\nsystem-level state evaluation model to shield the complex hardware\nconfigurations and redefine the different service capabilities at heterogeneous\nedges. Secondly, an integer linear programming model is designed to cater for\noptimally dispatching the distributed arriving requests. Finally, a\nlearning-based lightweight real-time scheduler, CoRaiS, is proposed. CoRaiS\nembeds the real-time states of multi-edge system and requests information, and\ncombines the embeddings with a policy network to schedule the requests, so that\nthe response time of all requests can be minimized. Evaluation results verify\nthat CoRaiS can make a high-quality scheduling decision in real time, and can\nbe generalized to other multi-edge computing system, regardless of system\nscales. Characteristic validation also demonstrates that CoRaiS successfully\nlearns to balance loads, perceive real-time state and recognize heterogeneity\nwhile scheduling.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "Accepted by IEEE Internet of Things Journal",
    "pdf_url": "http://arxiv.org/pdf/2403.09671v2",
    "published_date": "2024-02-04 07:21:45 UTC",
    "updated_date": "2024-05-20 08:38:18 UTC"
  },
  {
    "arxiv_id": "2402.02367v2",
    "title": "Exploring Intrinsic Properties of Medical Images for Self-Supervised Binary Semantic Segmentation",
    "authors": [
      "Pranav Singh",
      "Jacopo Cirrone"
    ],
    "abstract": "Recent advancements in self-supervised learning have unlocked the potential\nto harness unlabeled data for auxiliary tasks, facilitating the learning of\nbeneficial priors. This has been particularly advantageous in fields like\nmedical image analysis, where labeled data are scarce. Although effective for\nclassification tasks, this methodology has shown limitations in more complex\napplications, such as medical image segmentation. In this paper, we introduce\nMedical imaging Enhanced with Dynamic Self-Adaptive Semantic Segmentation\n(MedSASS), a dedicated self-supervised framework tailored for medical image\nsegmentation. We evaluate MedSASS against existing state-of-the-art methods\nacross four diverse medical datasets, showcasing its superiority. MedSASS\noutperforms existing CNN-based self-supervised methods by 3.83% and matches the\nperformance of ViT-based methods. Furthermore, when MedSASS is trained\nend-to-end, covering both encoder and decoder, it demonstrates significant\nimprovements of 14.4% for CNNs and 6% for ViT-based architectures compared to\nexisting state-of-the-art self-supervised strategies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "30 pages, 10 figures, and 10 tables. Under Review",
    "pdf_url": "http://arxiv.org/pdf/2402.02367v2",
    "published_date": "2024-02-04 06:39:01 UTC",
    "updated_date": "2024-04-27 18:04:11 UTC"
  },
  {
    "arxiv_id": "2402.02364v2",
    "title": "Loss Landscape Degeneracy Drives Stagewise Development in Transformers",
    "authors": [
      "Jesse Hoogland",
      "George Wang",
      "Matthew Farrugia-Roberts",
      "Liam Carroll",
      "Susan Wei",
      "Daniel Murfet"
    ],
    "abstract": "Deep learning involves navigating a high-dimensional loss landscape over the\nneural network parameter space. Over the course of training, complex\ncomputational structures form and re-form inside the neural network, leading to\nshifts in input/output behavior. It is a priority for the science of deep\nlearning to uncover principles governing the development of neural network\nstructure and behavior. Drawing on the framework of singular learning theory,\nwe propose that model development is deeply linked to degeneracy in the local\ngeometry of the loss landscape. We investigate this link by monitoring loss\nlandscape degeneracy throughout training, as quantified by the local learning\ncoefficient, for a transformer language model and an in-context linear\nregression transformer. We show that training can be divided into distinct\nperiods of change in loss landscape degeneracy, and that these changes in\ndegeneracy coincide with significant changes in the internal computational\nstructure and the input/output behavior of the transformers. This finding\nunderscores the potential of a degeneracy-based perspective for understanding\nmodern deep learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Material on essential dynamics from v1 of this preprint has been\n  removed from v2 and developed in arXiv:2501.17745",
    "pdf_url": "http://arxiv.org/pdf/2402.02364v2",
    "published_date": "2024-02-04 06:23:05 UTC",
    "updated_date": "2025-02-13 07:29:46 UTC"
  },
  {
    "arxiv_id": "2402.02362v1",
    "title": "Unification of Symmetries Inside Neural Networks: Transformer, Feedforward and Neural ODE",
    "authors": [
      "Koji Hashimoto",
      "Yuji Hirono",
      "Akiyoshi Sannai"
    ],
    "abstract": "Understanding the inner workings of neural networks, including transformers,\nremains one of the most challenging puzzles in machine learning. This study\nintroduces a novel approach by applying the principles of gauge symmetries, a\nkey concept in physics, to neural network architectures. By regarding model\nfunctions as physical observables, we find that parametric redundancies of\nvarious machine learning models can be interpreted as gauge symmetries. We\nmathematically formulate the parametric redundancies in neural ODEs, and find\nthat their gauge symmetries are given by spacetime diffeomorphisms, which play\na fundamental role in Einstein's theory of gravity. Viewing neural ODEs as a\ncontinuum version of feedforward neural networks, we show that the parametric\nredundancies in feedforward neural networks are indeed lifted to\ndiffeomorphisms in neural ODEs. We further extend our analysis to transformer\nmodels, finding natural correspondences with neural ODEs and their gauge\nsymmetries. The concept of gauge symmetries sheds light on the complex behavior\nof deep learning models through physics and provides us with a unifying\nperspective for analyzing various machine learning architectures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "hep-th",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.02362v1",
    "published_date": "2024-02-04 06:11:54 UTC",
    "updated_date": "2024-02-04 06:11:54 UTC"
  },
  {
    "arxiv_id": "2402.05952v1",
    "title": "Advancing Graph Representation Learning with Large Language Models: A Comprehensive Survey of Techniques",
    "authors": [
      "Qiheng Mao",
      "Zemin Liu",
      "Chenghao Liu",
      "Zhuo Li",
      "Jianling Sun"
    ],
    "abstract": "The integration of Large Language Models (LLMs) with Graph Representation\nLearning (GRL) marks a significant evolution in analyzing complex data\nstructures. This collaboration harnesses the sophisticated linguistic\ncapabilities of LLMs to improve the contextual understanding and adaptability\nof graph models, thereby broadening the scope and potential of GRL. Despite a\ngrowing body of research dedicated to integrating LLMs into the graph domain, a\ncomprehensive review that deeply analyzes the core components and operations\nwithin these models is notably lacking. Our survey fills this gap by proposing\na novel taxonomy that breaks down these models into primary components and\noperation techniques from a novel technical perspective. We further dissect\nrecent literature into two primary components including knowledge extractors\nand organizers, and two operation techniques including integration and training\nstratigies, shedding light on effective model design and training strategies.\nAdditionally, we identify and explore potential future research avenues in this\nnascent yet underexplored field, proposing paths for continued progress.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05952v1",
    "published_date": "2024-02-04 05:51:14 UTC",
    "updated_date": "2024-02-04 05:51:14 UTC"
  },
  {
    "arxiv_id": "2402.14600v1",
    "title": "Diffusion Model-Based Multiobjective Optimization for Gasoline Blending Scheduling",
    "authors": [
      "Wenxuan Fang",
      "Wei Du",
      "Renchu He",
      "Yang Tang",
      "Yaochu Jin",
      "Gary G. Yen"
    ],
    "abstract": "Gasoline blending scheduling uses resource allocation and operation\nsequencing to meet a refinery's production requirements. The presence of\nnonlinearity, integer constraints, and a large number of decision variables\nadds complexity to this problem, posing challenges for traditional and\nevolutionary algorithms. This paper introduces a novel multiobjective\noptimization approach driven by a diffusion model (named DMO), which is\ndesigned specifically for gasoline blending scheduling. To address integer\nconstraints and generate feasible schedules, the diffusion model creates\nmultiple intermediate distributions between Gaussian noise and the feasible\ndomain. Through iterative processes, the solutions transition from Gaussian\nnoise to feasible schedules while optimizing the objectives using the gradient\ndescent method. DMO achieves simultaneous objective optimization and constraint\nadherence. Comparative tests are conducted to evaluate DMO's performance across\nvarious scales. The experimental results demonstrate that DMO surpasses\nstate-of-the-art multiobjective evolutionary algorithms in terms of efficiency\nwhen solving gasoline blending scheduling problems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14600v1",
    "published_date": "2024-02-04 05:46:28 UTC",
    "updated_date": "2024-02-04 05:46:28 UTC"
  },
  {
    "arxiv_id": "2402.02345v2",
    "title": "Stereographic Spherical Sliced Wasserstein Distances",
    "authors": [
      "Huy Tran",
      "Yikun Bai",
      "Abihith Kothapalli",
      "Ashkan Shahbazi",
      "Xinran Liu",
      "Rocio Diaz Martin",
      "Soheil Kolouri"
    ],
    "abstract": "Comparing spherical probability distributions is of great interest in various\nfields, including geology, medical domains, computer vision, and deep\nrepresentation learning. The utility of optimal transport-based distances, such\nas the Wasserstein distance, for comparing probability measures has spurred\nactive research in developing computationally efficient variations of these\ndistances for spherical probability measures. This paper introduces a\nhigh-speed and highly parallelizable distance for comparing spherical measures\nusing the stereographic projection and the generalized Radon transform, which\nwe refer to as the Stereographic Spherical Sliced Wasserstein (S3W) distance.\nWe carefully address the distance distortion caused by the stereographic\nprojection and provide an extensive theoretical analysis of our proposed metric\nand its rotationally invariant variation. Finally, we evaluate the performance\nof the proposed metrics and compare them with recent baselines in terms of both\nspeed and accuracy through a wide range of numerical studies, including\ngradient flows and self-supervised learning. Our code is available at\nhttps://github.com/mint-vu/s3wd.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at ICML 2024 (Spotlight). Project page:\n  https://abi-kothapalli.github.io/s3w/",
    "pdf_url": "http://arxiv.org/pdf/2402.02345v2",
    "published_date": "2024-02-04 05:03:06 UTC",
    "updated_date": "2024-06-09 18:42:20 UTC"
  },
  {
    "arxiv_id": "2402.02342v5",
    "title": "MetaOptimize: A Framework for Optimizing Step Sizes and Other Meta-parameters",
    "authors": [
      "Arsalan Sharifnassab",
      "Saber Salehkaleybar",
      "Richard Sutton"
    ],
    "abstract": "This paper addresses the challenge of optimizing meta-parameters (i.e.,\nhyperparameters) in machine learning algorithms, a critical factor influencing\ntraining efficiency and model performance. Moving away from the computationally\nexpensive traditional meta-parameter search methods, we introduce MetaOptimize\nframework that dynamically adjusts meta-parameters, particularly step sizes\n(also known as learning rates), during training. More specifically,\nMetaOptimize can wrap around any first-order optimization algorithm, tuning\nstep sizes on the fly to minimize a specific form of regret that accounts for\nlong-term effect of step sizes on training, through a discounted sum of future\nlosses. We also introduce low complexity variants of MetaOptimize that, in\nconjunction with its adaptability to multiple optimization algorithms,\ndemonstrate performance competitive to those of best hand-crafted learning rate\nschedules across various machine learning applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02342v5",
    "published_date": "2024-02-04 04:55:54 UTC",
    "updated_date": "2024-10-04 01:08:12 UTC"
  },
  {
    "arxiv_id": "2402.02339v1",
    "title": "Uncertainty-Aware Testing-Time Optimization for 3D Human Pose Estimation",
    "authors": [
      "Ti Wang",
      "Mengyuan Liu",
      "Hong Liu",
      "Bin Ren",
      "Yingxuan You",
      "Wenhao Li",
      "Nicu Sebe",
      "Xia Li"
    ],
    "abstract": "Although data-driven methods have achieved success in 3D human pose\nestimation, they often suffer from domain gaps and exhibit limited\ngeneralization. In contrast, optimization-based methods excel in fine-tuning\nfor specific cases but are generally inferior to data-driven methods in overall\nperformance. We observe that previous optimization-based methods commonly rely\non projection constraint, which only ensures alignment in 2D space, potentially\nleading to the overfitting problem. To address this, we propose an\nUncertainty-Aware testing-time Optimization (UAO) framework, which keeps the\nprior information of pre-trained model and alleviates the overfitting problem\nusing the uncertainty of joints. Specifically, during the training phase, we\ndesign an effective 2D-to-3D network for estimating the corresponding 3D pose\nwhile quantifying the uncertainty of each 3D joint. For optimization during\ntesting, the proposed optimization framework freezes the pre-trained model and\noptimizes only a latent state. Projection loss is then employed to ensure the\ngenerated poses are well aligned in 2D space for high-quality optimization.\nFurthermore, we utilize the uncertainty of each joint to determine how much\neach joint is allowed for optimization. The effectiveness and superiority of\nthe proposed framework are validated through extensive experiments on two\nchallenging datasets: Human3.6M and MPI-INF-3DHP. Notably, our approach\noutperforms the previous best result by a large margin of 4.5% on Human3.6M.\nOur source code will be open-sourced.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02339v1",
    "published_date": "2024-02-04 04:28:02 UTC",
    "updated_date": "2024-02-04 04:28:02 UTC"
  },
  {
    "arxiv_id": "2402.02334v2",
    "title": "Arithmetic Feature Interaction Is Necessary for Deep Tabular Learning",
    "authors": [
      "Yi Cheng",
      "Renjun Hu",
      "Haochao Ying",
      "Xing Shi",
      "Jian Wu",
      "Wei Lin"
    ],
    "abstract": "Until recently, the question of the effective inductive bias of deep models\non tabular data has remained unanswered. This paper investigates the hypothesis\nthat arithmetic feature interaction is necessary for deep tabular learning. To\ntest this point, we create a synthetic tabular dataset with a mild feature\ninteraction assumption and examine a modified transformer architecture enabling\narithmetical feature interactions, referred to as AMFormer. Results show that\nAMFormer outperforms strong counterparts in fine-grained tabular data modeling,\ndata efficiency in training, and generalization. This is attributed to its\nparallel additive and multiplicative attention operators and prompt-based\noptimization, which facilitate the separation of tabular samples in an extended\nspace with arithmetically-engineered features. Our extensive experiments on\nreal-world data also validate the consistent effectiveness, efficiency, and\nrationale of AMFormer, suggesting it has established a strong inductive bias\nfor deep learning on tabular data. Code is available at\nhttps://github.com/aigc-apps/AMFormer.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.4"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 8 figures, to be published to AAAI2024",
    "pdf_url": "http://arxiv.org/pdf/2402.02334v2",
    "published_date": "2024-02-04 04:07:39 UTC",
    "updated_date": "2024-03-19 11:55:14 UTC"
  },
  {
    "arxiv_id": "2402.02330v2",
    "title": "Enhance Reasoning for Large Language Models in the Game Werewolf",
    "authors": [
      "Shuang Wu",
      "Liwen Zhu",
      "Tao Yang",
      "Shiwei Xu",
      "Qiang Fu",
      "Yang Wei",
      "Haobo Fu"
    ],
    "abstract": "This paper presents an innovative framework that integrates Large Language\nModels (LLMs) with an external Thinker module to enhance the reasoning\ncapabilities of LLM-based agents. Unlike augmenting LLMs with prompt\nengineering, Thinker directly harnesses knowledge from databases and employs\nvarious optimization techniques. The framework forms a reasoning hierarchy\nwhere LLMs handle intuitive System-1 tasks such as natural language processing,\nwhile the Thinker focuses on cognitive System-2 tasks that require complex\nlogical analysis and domain-specific knowledge. Our framework is presented\nusing a 9-player Werewolf game that demands dual-system reasoning. We introduce\na communication protocol between LLMs and the Thinker, and train the Thinker\nusing data from 18800 human sessions and reinforcement learning. Experiments\ndemonstrate the framework's effectiveness in deductive reasoning, speech\ngeneration, and online game evaluation. Additionally, we fine-tune a 6B LLM to\nsurpass GPT4 when integrated with the Thinker. This paper also contributes the\nlargest dataset for social deduction games to date.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02330v2",
    "published_date": "2024-02-04 03:47:10 UTC",
    "updated_date": "2024-03-29 09:01:56 UTC"
  },
  {
    "arxiv_id": "2402.03379v1",
    "title": "Entire Chain Uplift Modeling with Context-Enhanced Learning for Intelligent Marketing",
    "authors": [
      "Yinqiu Huang",
      "Shuli Wang",
      "Min Gao",
      "Xue Wei",
      "Changhao Li",
      "Chuan Luo",
      "Yinhua Zhu",
      "Xiong Xiao",
      "Yi Luo"
    ],
    "abstract": "Uplift modeling, vital in online marketing, seeks to accurately measure the\nimpact of various strategies, such as coupons or discounts, on different users\nby predicting the Individual Treatment Effect (ITE). In an e-commerce setting,\nuser behavior follows a defined sequential chain, including impression, click,\nand conversion. Marketing strategies exert varied uplift effects at each stage\nwithin this chain, impacting metrics like click-through and conversion rate.\nDespite its utility, existing research has neglected to consider the inter-task\nacross all stages impacts within a specific treatment and has insufficiently\nutilized the treatment information, potentially introducing substantial bias\ninto subsequent marketing decisions. We identify these two issues as the\nchain-bias problem and the treatment-unadaptive problem. This paper introduces\nthe Entire Chain UPlift method with context-enhanced learning (ECUP), devised\nto tackle these issues. ECUP consists of two primary components: 1) the Entire\nChain-Enhanced Network, which utilizes user behavior patterns to estimate ITE\nthroughout the entire chain space, models the various impacts of treatments on\neach task, and integrates task prior information to enhance context awareness\nacross all stages, capturing the impact of treatment on different tasks, and 2)\nthe Treatment-Enhanced Network, which facilitates fine-grained treatment\nmodeling through bit-level feature interactions, thereby enabling adaptive\nfeature adjustment. Extensive experiments on public and industrial datasets\nvalidate ECUPs effectiveness. Moreover, ECUP has been deployed on the Meituan\nfood delivery platform, serving millions of daily active users, with the\nrelated dataset released for future research.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by WWW2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03379v1",
    "published_date": "2024-02-04 03:30:25 UTC",
    "updated_date": "2024-02-04 03:30:25 UTC"
  },
  {
    "arxiv_id": "2402.02314v3",
    "title": "Selecting Large Language Model to Fine-tune via Rectified Scaling Law",
    "authors": [
      "Haowei Lin",
      "Baizhou Huang",
      "Haotian Ye",
      "Qinyu Chen",
      "Zihao Wang",
      "Sujian Li",
      "Jianzhu Ma",
      "Xiaojun Wan",
      "James Zou",
      "Yitao Liang"
    ],
    "abstract": "The ever-growing ecosystem of LLMs has posed a challenge in selecting the\nmost appropriate pre-trained model to fine-tune amidst a sea of options. Given\nconstrained resources, fine-tuning all models and making selections afterward\nis unrealistic. In this work, we formulate this resource-constrained selection\ntask into predicting fine-tuning performance and illustrate its natural\nconnection with Scaling Law. Unlike pre-training, we find that the fine-tuning\nscaling curve includes not just the well-known \"power phase\" but also the\npreviously unobserved \"pre-power phase\". We also explain why existing Scaling\nLaw fails to capture this phase transition phenomenon both theoretically and\nempirically. To address this, we introduce the concept of \"pre-learned data\nsize\" into our Rectified Scaling Law, which overcomes theoretical limitations\nand fits experimental results much better. By leveraging our law, we propose a\nnovel LLM selection algorithm that selects the near-optimal model with hundreds\nof times less resource consumption, while other methods may provide negatively\ncorrelated selection. The project page is available at\nrectified-scaling-law.github.io.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02314v3",
    "published_date": "2024-02-04 01:55:00 UTC",
    "updated_date": "2024-05-28 16:16:42 UTC"
  },
  {
    "arxiv_id": "2402.05121v3",
    "title": "Large Language Model for Table Processing: A Survey",
    "authors": [
      "Weizheng Lu",
      "Jing Zhang",
      "Ju Fan",
      "Zihao Fu",
      "Yueguo Chen",
      "Xiaoyong Du"
    ],
    "abstract": "Tables, typically two-dimensional and structured to store large amounts of\ndata, are essential in daily activities like database queries, spreadsheet\nmanipulations, web table question answering, and image table information\nextraction. Automating these table-centric tasks with Large Language Models\n(LLMs) or Visual Language Models (VLMs) offers significant public benefits,\ngarnering interest from academia and industry. This survey provides a\ncomprehensive overview of table-related tasks, examining both user scenarios\nand technical aspects. It covers traditional tasks like table question\nanswering as well as emerging fields such as spreadsheet manipulation and table\ndata analysis. We summarize the training techniques for LLMs and VLMs tailored\nfor table processing. Additionally, we discuss prompt engineering, particularly\nthe use of LLM-powered agents, for various table-related tasks. Finally, we\nhighlight several challenges, including diverse user input when serving and\nslow thinking using chain-of-thought.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05121v3",
    "published_date": "2024-02-04 00:47:53 UTC",
    "updated_date": "2024-10-24 07:26:36 UTC"
  }
]