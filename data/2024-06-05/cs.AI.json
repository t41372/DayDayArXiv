{
  "date": "2024-06-05",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-05 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和机器学习的创新应用，包括强化学习、图神经网络、生成模型和大型语言模型（LLMs）的优化与评估，其中令人印象深刻的文章包括 LLMs 在情感分析和物理常识评估中的表现（如 Yarin Gal 参与的 VideoPhy），以及高效算法在机器人规划和语音识别中的突破。\n\n### 重点论文讨论\n我将优先讨论重要、创新性和话题度高的论文，将相关主题归类讨论，并快速掠过一些基础或重复性较强的文章。以下按主题分组，每篇论文列出标题（中文 + 英文），并简要描述主要贡献和发现。\n\n#### 1. 大型语言模型（LLMs）和文本生成\n这些论文探讨 LLMs 在推理、情感和任务中的能力，相关性强且话题度高。\n- **知识注入的法律智慧：通过诊断和正-无标签强化学习导航 LLM 咨询** (Knowledge-Infused Legal Wisdom: Navigating LLM Consultation through the Lens of Diagnostics and Positive-Unlabeled Reinforcement Learning)  \n  贡献：提出 D3LM 框架，使用图-based 正-无标签强化学习生成关键问题，提升 LLM 在法律咨询中的交互体验。主要发现：显著改善非专业用户查询的准确性，适用于复杂案例分析。\n- **为什么“问题”能预测积极情感？解释情感分类中非直观特征的案例研究** (Why is \"Problems\" Predictive of Positive Sentiment? A Case Study of Explaining Unintuitive Features in Sentiment Classification)  \n  贡献：开发方法检测和解释非直观特征的关联，如“problems”与积极情感的联系。主要发现：通过众包实验，证明新算法能有效提升情感分类的可解释性。\n- **分析 LLM 在对话摘要中的行为：揭示情境性幻觉趋势** (Analyzing LLM Behavior in Dialogue Summarization: Unveiling Circumstantial Hallucination Trends)  \n  贡献：细化幻觉分类，引入“情境性推理”概念，并提出基于提示的错误检测方法。主要发现：GPT-4 和 Alpaca-13B 在摘要任务中易产生可信但无直接证据的幻觉。\n- **LLMs 是否理性？基于连贯性规范和信念更新的案例** (Are language models rational? The case of coherence norms and belief revision)  \n  贡献：评估 LLMs 的逻辑连贯性和信念强度，使用新度量方法。主要发现：LLMs 在某些任务中显示理性，但易受信念更新的影响。\n- **快速掠过其他：** 如 **BIPED: Pedagogically Informed Tutoring System for ESL Education** (BIPED)，它构建了基于 LLM 的教育对话系统，但细节较常规，无重大突破。\n\n#### 2. 生成模型和图像处理\n这些论文关注生成模型的安全性和物理常识，创新性强。\n- **理解生成模型的局限性：通过食物分析扩散概念代数** (Understanding the Limitations of Diffusion Concept Algebra Through Food)  \n  贡献：使用食物图像测试扩散模型的偏置和局限。主要发现：模型在捕捉烹饪多样性时存在区域偏置，揭示生成模型的细微缺陷。\n- **VideoPhy: 为视频生成评估物理常识** (VideoPhy: Evaluating Physical Commonsense for Video Generation)  \n  贡献：提出 VideoPhy 基准，评估文本到视频模型的物理常识。主要发现：现有模型在真实物理场景中表现不足，GPT-4o 远超开源模型。\n- **Wings: 无文本遗忘的多模态 LLM 学习** (Wings: Learning Multimodal LLMs without Text-only Forgetting)  \n  贡献：设计并行注意力模块，融合视觉和文本学习。主要发现：在多模态任务中，显著减少文本遗忘，提升整体性能。\n\n#### 3. 强化学习和机器人规划\n这些论文解决实际问题，如规划和泛化，应用价值高。\n- **归纳泛化在基于规范的强化学习中** (Inductive Generalization in Reinforcement Learning from Specifications)  \n  贡献：提出新框架学习高阶策略生成器，实现零-shot 任务适应。主要发现：在控制基准上，泛化到未见任务表现出色。\n- **任务和运动规划在真实执行中的应用** (Task and Motion Planning for Execution in the Real)  \n  贡献：开发框架处理部分未知动作，结合离线规划和在线行为。主要发现：实机器人实验显示，成功率和效率均优于现有方法。\n- **高速公路值迭代网络** (Highway Value Iteration Networks)  \n  贡献：改进值迭代网络，添加门控机制增强长期规划。主要发现：在长时任务中，显著提升性能。\n\n#### 4. 图神经网络和优化算法\n这些论文优化算法效率，实用性强。\n- **决策导向的图神经网络用于组合优化** (Decision-focused Graph Neural Networks for Combinatorial Optimization)  \n  贡献：提出端到端框架结合 GNN 和求解器。主要发现：在经典问题如最大割上，优于独立 GNN 方法。\n- **自由度重要性：从点轨迹推断动态** (Degrees of Freedom Matter: Inferring Dynamics from Point Trajectories)  \n  贡献：改进动态点场模型，分析 Jacobian 矩阵提升表示能力。主要发现：预测未见轨迹更准确，适用于场景重建。\n\n#### 5. 其他快速掠过\n剩余论文中，一些如 **Active ML for 6G** (专注于 6G 网络的主动学习)和 **EgoSurgery-Tool** (手术工具检测数据集)有实际应用，但主题较窄或重复现有工作，仅提要：前者提出网络中心框架提升数据效率，后者构建数据集提升检测精度。其他如 **CountCLIP** (重现 CLIP 计数研究)和 **A Comparison of Recent Algorithms for Symbolic Regression** (符号回归算法比较)基础性强，不展开讨论。\n\n总之，今天的论文突显 AI 模型的优化和鲁棒性，LLM 相关研究尤其值得关注，未来可能在实际应用中发挥更大作用。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2406.03651v1",
      "title": "Inductive Generalization in Reinforcement Learning from Specifications",
      "title_zh": "强化学习中基于规范的归纳泛化",
      "authors": [
        "Vignesh Subramanian",
        "Rohit Kushwah",
        "Subhajit Roy",
        "Suguman Bansal"
      ],
      "abstract": "We present a novel inductive generalization framework for RL from logical\nspecifications. Many interesting tasks in RL environments have a natural\ninductive structure. These inductive tasks have similar overarching goals but\nthey differ inductively in low-level predicates and distributions. We present a\ngeneralization procedure that leverages this inductive relationship to learn a\nhigher-order function, a policy generator, that generates appropriately adapted\npolicies for instances of an inductive task in a zero-shot manner. An\nevaluation of the proposed approach on a set of challenging control benchmarks\ndemonstrates the promise of our framework in generalizing to unseen policies\nfor long-horizon tasks.",
      "tldr_zh": "这篇论文提出了一种针对从逻辑规范中学习的强化学习（RL）的归纳泛化框架，旨在处理具有类似高层目标但底层谓词和分布不同的归纳任务。框架通过学习一个高阶函数（policy generator），实现零样本生成适应性策略，从而高效处理任务实例。实验结果显示，该方法在挑战性的控制基准上表现出色，能够泛化到长时序任务中的未见策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03651v1",
      "published_date": "2024-06-05 23:06:48 UTC",
      "updated_date": "2024-06-05 23:06:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:21:29.612788"
    },
    {
      "arxiv_id": "2406.03647v2",
      "title": "Decision-focused Graph Neural Networks for Combinatorial Optimization",
      "title_zh": "决策聚焦的图神经网络用于组合优化",
      "authors": [
        "Yang Liu",
        "Chuan Zhou",
        "Peng Zhang",
        "Shirui Pan",
        "Zhao Li",
        "Hongyang Chen"
      ],
      "abstract": "In recent years, there has been notable interest in investigating\ncombinatorial optimization (CO) problems by neural-based framework. An emerging\nstrategy to tackle these challenging problems involves the adoption of graph\nneural networks (GNNs) as an alternative to traditional algorithms, a subject\nthat has attracted considerable attention. Despite the growing popularity of\nGNNs and traditional algorithm solvers in the realm of CO, there is limited\nresearch on their integrated use and the correlation between them within an\nend-to-end framework. The primary focus of our work is to formulate a more\nefficient and precise framework for CO by employing decision-focused learning\non graphs. Additionally, we introduce a decision-focused framework that\nutilizes GNNs to address CO problems with auxiliary support. To realize an\nend-to-end approach, we have designed two cascaded modules: (a) an unsupervised\ntrained graph predictive model, and (b) a solver for quadratic binary\nunconstrained optimization. Empirical evaluations are conducted on various\nclassical tasks, including maximum cut, maximum independent set, and minimum\nvertex cover. The experimental results on classical CO problems (i.e. MaxCut,\nMIS, and MVC) demonstrate the superiority of our method over both the\nstandalone GNN approach and classical methods.",
      "tldr_zh": "本文提出了一种决策聚焦的 Graph Neural Networks (GNNs) 框架，用于解决 Combinatorial Optimization (CO) 问题，通过整合 GNNs 与传统算法求解器，实现端到端的优化过程。该框架包括两个级联模块：一个无监督训练的图预测模型，以及一个求解二次二元无约束优化的模块，从而提高 CO 问题的效率和精度。在经典任务如 MaxCut、MIS 和 MVC 上进行的实验结果显示，该方法优于独立的 GNNs 方法和传统方法，证明了其在处理复杂优化问题时的优越性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.03647v2",
      "published_date": "2024-06-05 22:52:27 UTC",
      "updated_date": "2024-06-10 00:53:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:21:41.973113"
    },
    {
      "arxiv_id": "2406.03641v2",
      "title": "Task and Motion Planning for Execution in the Real",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyang Pan",
        "Rahul Shome",
        "Lydia E. Kavraki"
      ],
      "abstract": "Task and motion planning represents a powerful set of hybrid planning methods\nthat combine reasoning over discrete task domains and continuous motion\ngeneration. Traditional reasoning necessitates task domain models and enough\ninformation to ground actions to motion planning queries. Gaps in this\nknowledge often arise from sources like occlusion or imprecise modeling. This\nwork generates task and motion plans that include actions cannot be fully\ngrounded at planning time. During execution, such an action is handled by a\nprovided human-designed or learned closed-loop behavior. Execution combines\noffline planned motions and online behaviors till reaching the task goal.\nFailures of behaviors are fed back as constraints to find new plans. Forty\nreal-robot trials and motivating demonstrations are performed to evaluate the\nproposed framework and compare against state-of-the-art. Results show faster\nexecution time, less number of actions, and more success in problems where\ndiverse gaps arise. The experiment data is shared for researchers to simulate\nthese settings. The work shows promise in expanding the applicable class of\nrealistic partially grounded problems that robots can address.",
      "tldr_zh": "该论文提出了一种任务和运动规划（Task and Motion Planning）框架，用于处理真实环境中知识缺口（如遮挡或建模不精确）导致的动作无法完全grounded的问题。该框架在规划时生成部分grounded的计划，并在执行过程中结合离线planned motions和在线closed-loop behaviors来实现任务目标；如果behaviors失败，则反馈约束以重新规划。实验包括40次真实机器人试验，与最先进方法相比，该框架实现了更快的执行时间、更少的动作数量以及更高的成功率。总体上，这扩展了机器人处理现实部分grounded问题的适用范围，并共享实验数据以供研究者模拟。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2.9; I.2.8"
      ],
      "primary_category": "cs.RO",
      "comment": "15 pages, 14 figures, 2 tables, accepted by IEEE Transactions on\n  Robotics",
      "pdf_url": "http://arxiv.org/pdf/2406.03641v2",
      "published_date": "2024-06-05 22:30:40 UTC",
      "updated_date": "2024-06-13 16:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:21:54.901969"
    },
    {
      "arxiv_id": "2406.03630v1",
      "title": "Active ML for 6G: Towards Efficient Data Generation, Acquisition, and Annotation",
      "title_zh": "翻译失败",
      "authors": [
        "Omar Alhussein",
        "Ning Zhang",
        "Sami Muhaidat",
        "Weihua Zhuang"
      ],
      "abstract": "This paper explores the integration of active machine learning (ML) for 6G\nnetworks, an area that remains under-explored yet holds potential. Unlike\npassive ML systems, active ML can be made to interact with the network\nenvironment. It actively selects informative and representative data points for\ntraining, thereby reducing the volume of data needed while accelerating the\nlearning process. While active learning research mainly focuses on data\nannotation, we call for a network-centric active learning framework that\nconsiders both annotation (i.e., what is the label) and data acquisition (i.e.,\nwhich and how many samples to collect). Moreover, we explore the synergy\nbetween generative artificial intelligence (AI) and active learning to overcome\nexisting limitations in both active learning and generative AI. This paper also\nfeatures a case study on a mmWave throughput prediction problem to demonstrate\nthe practical benefits and improved performance of active learning for 6G\nnetworks. Furthermore, we discuss how the implications of active learning\nextend to numerous 6G network use cases. We highlight the potential of active\nlearning based 6G networks to enhance computational efficiency, data annotation\nand acquisition efficiency, adaptability, and overall network intelligence. We\nconclude with a discussion on challenges and future research directions for\nactive learning in 6G networks, including development of novel query\nstrategies, distributed learning integration, and inclusion of human- and\nmachine-in-the-loop learning.",
      "tldr_zh": "这篇论文探讨了主动机器学习（Active ML）在 6G 网络中的应用，旨在通过主动选择信息丰富的训练数据点来提高数据生成、获取和标注效率，从而减少所需数据量并加速学习过程。作者提出一个网络中心的框架，不仅关注数据标注，还包括数据获取策略，并探索生成式 AI 与 Active ML 的协同作用，以克服现有局限。论文通过 mmWave 吞吐量预测的案例研究，展示了 Active ML 在 6G 网络中的实际性能提升，包括提高计算效率和整体网络智能。最后，讨论了挑战和未来方向，如开发新型查询策略、整合分布式学习以及纳入人类和机器在循环中的学习。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "Submitted to IEEE Network Magazine",
      "pdf_url": "http://arxiv.org/pdf/2406.03630v1",
      "published_date": "2024-06-05 21:29:05 UTC",
      "updated_date": "2024-06-05 21:29:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:22:07.873166"
    },
    {
      "arxiv_id": "2406.03625v1",
      "title": "Degrees of Freedom Matter: Inferring Dynamics from Point Trajectories",
      "title_zh": "自由度很重要：从点轨迹推断动力学",
      "authors": [
        "Yan Zhang",
        "Sergey Prokudin",
        "Marko Mihajlovic",
        "Qianli Ma",
        "Siyu Tang"
      ],
      "abstract": "Understanding the dynamics of generic 3D scenes is fundamentally challenging\nin computer vision, essential in enhancing applications related to scene\nreconstruction, motion tracking, and avatar creation. In this work, we address\nthe task as the problem of inferring dense, long-range motion of 3D points. By\nobserving a set of point trajectories, we aim to learn an implicit motion field\nparameterized by a neural network to predict the movement of novel points\nwithin the same domain, without relying on any data-driven or scene-specific\npriors. To achieve this, our approach builds upon the recently introduced\ndynamic point field model that learns smooth deformation fields between the\ncanonical frame and individual observation frames. However, temporal\nconsistency between consecutive frames is neglected, and the number of required\nparameters increases linearly with the sequence length due to per-frame\nmodeling. To address these shortcomings, we exploit the intrinsic\nregularization provided by SIREN, and modify the input layer to produce a\nspatiotemporally smooth motion field. Additionally, we analyze the motion field\nJacobian matrix, and discover that the motion degrees of freedom (DOFs) in an\ninfinitesimal area around a point and the network hidden variables have\ndifferent behaviors to affect the model's representational power. This enables\nus to improve the model representation capability while retaining the model\ncompactness. Furthermore, to reduce the risk of overfitting, we introduce a\nregularization term based on the assumption of piece-wise motion smoothness.\nOur experiments assess the model's performance in predicting unseen point\ntrajectories and its application in temporal mesh alignment with guidance. The\nresults demonstrate its superiority and effectiveness. The code and data for\nthe project are publicly available:\n\\url{https://yz-cnsdqz.github.io/eigenmotion/DOMA/}",
      "tldr_zh": "这篇论文探讨了从点轨迹推断3D场景动态的核心问题，提出了一种基于神经网络参数化的隐式运动场方法，用于预测新型点的运动，而不依赖数据驱动或场景特定先验。作者改进动态点场模型，通过SIREN的内在正则化修改输入层以实现时空平滑运动场，并分析运动场Jacobian matrix，优化运动Degrees of Freedom (DOFs)和网络隐藏变量的表示能力，同时引入基于分段运动平滑性的正则化项来减少过拟合风险。实验结果表明，该方法在预测未见点轨迹和临时网格对齐任务上显著优于基线模型，证明了其在场景重建和运动跟踪应用中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "cvpr24 post camera ready",
      "pdf_url": "http://arxiv.org/pdf/2406.03625v1",
      "published_date": "2024-06-05 21:02:10 UTC",
      "updated_date": "2024-06-05 21:02:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:22:21.015913"
    },
    {
      "arxiv_id": "2406.03600v1",
      "title": "Knowledge-Infused Legal Wisdom: Navigating LLM Consultation through the Lens of Diagnostics and Positive-Unlabeled Reinforcement Learning",
      "title_zh": "注入知识的法律智慧：通过诊断和正无标签强化学习的视角导航LLM咨询",
      "authors": [
        "Yang Wu",
        "Chenghao Wang",
        "Ece Gumusel",
        "Xiaozhong Liu"
      ],
      "abstract": "The integration of generative Large Language Models (LLMs) into various\napplications, including the legal domain, has been accelerated by their\nexpansive and versatile nature. However, when facing a legal case, users\nwithout a legal background often struggle to formulate professional queries and\nmay inadvertently overlook critical legal factors when presenting their case\nnarrative to LLMs. To address this issue, we propose the Diagnostic Legal Large\nLanguage Model (D3LM), which utilizes adaptive lawyer-like diagnostic questions\nto collect additional case information and then provides high-quality feedback.\nD3LM incorporates an innovative graph-based Positive-Unlabeled Reinforcement\nLearning (PURL) algorithm, enabling the generation of critical questions and\nenhancing user-LLM interactions. Moreover, an integrated LLM-based stopping\ncriterion facilitates precise Court Views Generation (CVG). Our research also\nintroduces a new English-language CVG dataset based on the US case law\ndatabase, enriching the realm of LLM research and deployment with a vital\ndimension. D3LM surpasses classical LLMs by delivering outstanding performance\nand a remarkable user experience in the legal domain.",
      "tldr_zh": "这篇论文提出了Diagnostic Legal Large Language Model (D3LM)，一种创新框架，用于帮助非法律背景用户通过适应性的律师式诊断问题收集额外案例信息，并提升与LLM的互动质量。D3LM 整合了 graph-based Positive-Unlabeled Reinforcement Learning (PURL) 算法来生成关键问题，并采用 LLM-based stopping criterion 实现精确的 Court Views Generation (CVG)。此外，研究引入了一个新的基于美国案例法数据库的英语 CVG 数据集，结果显示 D3LM 在法律领域超越了经典 LLM，提供卓越的性能和用户体验。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL Findings 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03600v1",
      "published_date": "2024-06-05 19:47:35 UTC",
      "updated_date": "2024-06-05 19:47:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:22:31.995844"
    },
    {
      "arxiv_id": "2406.03594v1",
      "title": "Why is \"Problems\" Predictive of Positive Sentiment? A Case Study of Explaining Unintuitive Features in Sentiment Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaming Qu",
        "Jaime Arguello",
        "Yue Wang"
      ],
      "abstract": "Explainable AI (XAI) algorithms aim to help users understand how a machine\nlearning model makes predictions. To this end, many approaches explain which\ninput features are most predictive of a target label. However, such\nexplanations can still be puzzling to users (e.g., in product reviews, the word\n\"problems\" is predictive of positive sentiment). If left unexplained, puzzling\nexplanations can have negative impacts. Explaining unintuitive associations\nbetween an input feature and a target label is an underexplored area in XAI\nresearch. We take an initial effort in this direction using unintuitive\nassociations learned by sentiment classifiers as a case study. We propose\napproaches for (1) automatically detecting associations that can appear\nunintuitive to users and (2) generating explanations to help users understand\nwhy an unintuitive feature is predictive. Results from a crowdsourced study\n(N=300) found that our proposed approaches can effectively detect and explain\npredictive but unintuitive features in sentiment classification.",
      "tldr_zh": "该研究探讨了Explainable AI (XAI)中一个未充分研究的问题：如何解释情感分类中非直观的特征关联，例如“problems”一词与积极情感的预测关系。论文提出两种方法：(1) 自动检测用户可能觉得非直观的输入特征与标签关联；(2) 生成解释以帮助用户理解这些特征的预测性。基于情感分类器的案例研究和一个众包实验（N=300），结果显示这些方法能有效识别和阐释此类非直观特征，从而提升XAI的可解释性和用户信任。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03594v1",
      "published_date": "2024-06-05 19:31:19 UTC",
      "updated_date": "2024-06-05 19:31:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:22:41.847038"
    },
    {
      "arxiv_id": "2406.03592v1",
      "title": "Measuring Retrieval Complexity in Question Answering Systems",
      "title_zh": "测量问答系统中的检索复杂性",
      "authors": [
        "Matteo Gabburo",
        "Nicolaas Paul Jedema",
        "Siddhant Garg",
        "Leonardo F. R. Ribeiro",
        "Alessandro Moschitti"
      ],
      "abstract": "In this paper, we investigate which questions are challenging for\nretrieval-based Question Answering (QA). We (i) propose retrieval complexity\n(RC), a novel metric conditioned on the completeness of retrieved documents,\nwhich measures the difficulty of answering questions, and (ii) propose an\nunsupervised pipeline to measure RC given an arbitrary retrieval system. Our\nproposed pipeline measures RC more accurately than alternative estimators,\nincluding LLMs, on six challenging QA benchmarks. Further investigation reveals\nthat RC scores strongly correlate with both QA performance and expert judgment\nacross five of the six studied benchmarks, indicating that RC is an effective\nmeasure of question difficulty. Subsequent categorization of high-RC questions\nshows that they span a broad set of question shapes, including multi-hop,\ncompositional, and temporal QA, indicating that RC scores can categorize a new\nsubset of complex questions. Our system can also have a major impact on\nretrieval-based systems by helping to identify more challenging questions on\nexisting datasets.",
      "tldr_zh": "本文提出了一种名为retrieval complexity (RC)的全新指标，用于评估基于检索的Question Answering (QA)系统中的问题难度，该指标基于检索文档的完整性。研究团队开发了一个无监督pipeline来测量RC，并证明其在六个挑战性QA基准上比LLMs等替代估算器更准确。结果显示，RC分数与QA性能和专家判断高度相关，能够有效识别多跳、组合和时间相关的复杂问题子集。该方法有助于改进现有QA数据集，通过识别更具挑战性的问题提升系统性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 (findings)",
      "pdf_url": "http://arxiv.org/pdf/2406.03592v1",
      "published_date": "2024-06-05 19:30:52 UTC",
      "updated_date": "2024-06-05 19:30:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:22:54.093078"
    },
    {
      "arxiv_id": "2406.03586v2",
      "title": "CountCLIP -- [Re] Teaching CLIP to Count to Ten",
      "title_zh": "翻译失败",
      "authors": [
        "Harshvardhan Mestha",
        "Tejas Agrawal",
        "Karan Bania",
        "Shreyas V",
        "Yash Bhisikar"
      ],
      "abstract": "Large vision-language models (VLMs) are shown to learn rich joint image-text\nrepresentations enabling high performances in relevant downstream tasks.\nHowever, they fail to showcase their quantitative understanding of objects, and\nthey lack good counting-aware representation. This paper conducts a\nreproducibility study of 'Teaching CLIP to Count to Ten' (Paiss et al., 2023),\nwhich presents a method to finetune a CLIP model (Radford et al., 2021) to\nimprove zero-shot counting accuracy in an image while maintaining the\nperformance for zero-shot classification by introducing a counting-contrastive\nloss term. We improve the model's performance on a smaller subset of their\ntraining data with lower computational resources. We verify these claims by\nreproducing their study with our own code. The implementation can be found at\nhttps://github.com/SforAiDl/CountCLIP.",
      "tldr_zh": "这篇论文是对“Teaching CLIP to Count to Ten”的重现性研究，旨在改进CLIP模型的计数能力，同时保持其零样本分类性能。\n研究者通过引入计数对比损失(counting-contrastive loss)对CLIP模型进行微调，使用更少的训练数据和计算资源，成功提升了模型在图像计数任务上的表现。\n结果显示，该方法在子集数据上提高了零样本计数准确性，并提供了开源代码实现（https://github.com/SforAiDl/CountCLIP），为VLMs的量化理解提供了可验证的改进路径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03586v2",
      "published_date": "2024-06-05 19:05:08 UTC",
      "updated_date": "2024-06-10 12:09:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:23:06.975627"
    },
    {
      "arxiv_id": "2406.03585v1",
      "title": "A Comparison of Recent Algorithms for Symbolic Regression to Genetic Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Yousef A. Radwan",
        "Gabriel Kronberger",
        "Stephan Winkler"
      ],
      "abstract": "Symbolic regression is a machine learning method with the goal to produce\ninterpretable results. Unlike other machine learning methods such as, e.g.\nrandom forests or neural networks, which are opaque, symbolic regression aims\nto model and map data in a way that can be understood by scientists. Recent\nadvancements, have attempted to bridge the gap between these two fields; new\nmethodologies attempt to fuse the mapping power of neural networks and deep\nlearning techniques with the explanatory power of symbolic regression. In this\npaper, we examine these new emerging systems and test the performance of an\nend-to-end transformer model for symbolic regression versus the reigning\ntraditional methods based on genetic programming that have spearheaded symbolic\nregression throughout the years. We compare these systems on novel datasets to\navoid bias to older methods who were improved on well-known benchmark datasets.\nOur results show that traditional GP methods as implemented e.g., by Operon\nstill remain superior to two recently published symbolic regression methods.",
      "tldr_zh": "本研究比较了符号回归（symbolic regression）领域的最新算法与传统遗传编程（genetic programming）方法。论文重点测试一个端到端的Transformer模型的表现，并将其与基于GP的传统方法（如Operon实现）在新型数据集上进行对比，以避免对旧方法的基准偏差。结果显示，传统GP方法在性能上仍优于两个最近发布的符号回归算法，这突显了符号回归的可解释性与神经网络（neural networks）技术的融合挑战。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03585v1",
      "published_date": "2024-06-05 19:01:43 UTC",
      "updated_date": "2024-06-05 19:01:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:23:17.460146"
    },
    {
      "arxiv_id": "2406.03582v1",
      "title": "Understanding the Limitations of Diffusion Concept Algebra Through Food",
      "title_zh": "通过食物理解扩散概念代数的局限性",
      "authors": [
        "E. Zhixuan Zeng",
        "Yuhao Chen",
        "Alexander Wong"
      ],
      "abstract": "Image generation techniques, particularly latent diffusion models, have\nexploded in popularity in recent years. Many techniques have been developed to\nmanipulate and clarify the semantic concepts these large-scale models learn,\noffering crucial insights into biases and concept relationships. However, these\ntechniques are often only validated in conventional realms of human or animal\nfaces and artistic style transitions. The food domain offers unique challenges\nthrough complex compositions and regional biases, which can shed light on the\nlimitations and opportunities within existing methods. Through the lens of food\nimagery, we analyze both qualitative and quantitative patterns within a concept\ntraversal technique. We reveal measurable insights into the model's ability to\ncapture and represent the nuances of culinary diversity, while also identifying\nareas where the model's biases and limitations emerge.",
      "tldr_zh": "本研究探讨了潜在扩散模型（latent diffusion models）等图像生成技术的局限性，通过食物图像领域进行分析，以揭示这些模型在概念操纵方面的挑战。研究者采用概念遍历技术（concept traversal technique）对食物的复杂组成和区域偏差进行定性和定量分析，评估模型捕捉烹饪多样性的能力。结果显示，模型在处理 culinary diversity 时表现出一定优势，但也暴露了明显的偏差和限制，为改进此类技术提供了关键洞见。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03582v1",
      "published_date": "2024-06-05 18:57:02 UTC",
      "updated_date": "2024-06-05 18:57:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:23:30.992085"
    },
    {
      "arxiv_id": "2406.03577v1",
      "title": "Explaining the Contributing Factors for Vulnerability Detection in Machine Learning",
      "title_zh": "解释机器学习中漏洞检测的贡献因素",
      "authors": [
        "Esma Mouine",
        "Yan Liu",
        "Lu Xiao",
        "Rick Kazman",
        "Xiao Wang"
      ],
      "abstract": "There is an increasing trend to mine vulnerabilities from software\nrepositories and use machine learning techniques to automatically detect\nsoftware vulnerabilities. A fundamental but unresolved research question is:\nhow do different factors in the mining and learning process impact the accuracy\nof identifying vulnerabilities in software projects of varying characteristics?\nSubstantial research has been dedicated in this area, including source code\nstatic analysis, software repository mining, and NLP-based machine learning.\nHowever, practitioners lack experience regarding the key factors for building a\nbaseline model of the state-of-the-art. In addition, there lacks of experience\nregarding the transferability of the vulnerability signatures from project to\nproject. This study investigates how the combination of different vulnerability\nfeatures and three representative machine learning models impact the accuracy\nof vulnerability detection in 17 real-world projects. We examine two types of\nvulnerability representations: 1) code features extracted through NLP with\nvarying tokenization strategies and three different embedding techniques\n(bag-of-words, word2vec, and fastText) and 2) a set of eight architectural\nmetrics that capture the abstract design of the software systems. The three\nmachine learning algorithms include a random forest model, a support vector\nmachines model, and a residual neural network model. The analysis shows a\nrecommended baseline model with signatures extracted through bag-of-words\nembedding, combined with the random forest, consistently increases the\ndetection accuracy by about 4% compared to other combinations in all 17\nprojects. Furthermore, we observe the limitation of transferring vulnerability\nsignatures across domains based on our experiments.",
      "tldr_zh": "本研究探讨了机器学习在软件漏洞检测中的关键影响因素，包括特征提取策略和模型选择对17个真实项目的检测准确率的影响。研究者使用了两种漏洞表示形式：通过NLP的代码特征（包括bag-of-words、word2vec和fastText等嵌入技术以及不同分词策略）和八个架构指标；并测试了三种机器学习模型（random forest、support vector machines和residual neural network）。结果显示，采用bag-of-words嵌入结合random forest的基线模型可将检测准确率提高约4%，但漏洞签名在不同项目间的转移性有限，为构建高效的漏洞检测系统提供了实用指导。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03577v1",
      "published_date": "2024-06-05 18:48:00 UTC",
      "updated_date": "2024-06-05 18:48:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:23:42.446012"
    },
    {
      "arxiv_id": "2406.03576v1",
      "title": "Enhancing Traffic Sign Recognition with Tailored Data Augmentation: Addressing Class Imbalance and Instance Scarcity",
      "title_zh": "通过定制数据增强提升交通标志识别：解决类别不平衡和实例稀缺",
      "authors": [
        "Ulan Alsiyeu",
        "Zhasdauren Duisebekov"
      ],
      "abstract": "This paper tackles critical challenges in traffic sign recognition (TSR),\nwhich is essential for road safety -- specifically, class imbalance and\ninstance scarcity in datasets. We introduce tailored data augmentation\ntechniques, including synthetic image generation, geometric transformations,\nand a novel obstacle-based augmentation method to enhance dataset quality for\nimproved model robustness and accuracy. Our methodology incorporates diverse\naugmentation processes to accurately simulate real-world conditions, thereby\nexpanding the training data's variety and representativeness. Our findings\ndemonstrate substantial improvements in TSR models performance, offering\nsignificant implications for traffic sign recognition systems. This research\nnot only addresses dataset limitations in TSR but also proposes a model for\nsimilar challenges across different regions and applications, marking a step\nforward in the field of computer vision and traffic sign recognition systems.",
      "tldr_zh": "这篇论文针对交通标志识别(TSR)中的类别不平衡(class imbalance)和实例稀缺(instance scarcity)问题，提出定制的数据增强(tailored data augmentation)技术，包括合成图像生成(synthetic image generation)、几何变换(geometric transformations)和一种新型的基于障碍物(obstacle-based augmentation)方法，以模拟真实世界条件并提升数据集的质量和多样性。实验结果显示，这些方法显著提高了TSR模型的鲁棒性和准确性，为交通标志识别系统带来重要改进。该研究不仅解决了TSR数据集的局限性，还为其他计算机视觉应用提供了一个可推广的模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03576v1",
      "published_date": "2024-06-05 18:45:45 UTC",
      "updated_date": "2024-06-05 18:45:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:23:54.974140"
    },
    {
      "arxiv_id": "2406.03537v2",
      "title": "A Geometric View of Data Complexity: Efficient Local Intrinsic Dimension Estimation with Diffusion Models",
      "title_zh": "数据复杂性的几何视角：基于扩散模型的局部内在维度高效估计",
      "authors": [
        "Hamidreza Kamkari",
        "Brendan Leigh Ross",
        "Rasa Hosseinzadeh",
        "Jesse C. Cresswell",
        "Gabriel Loaiza-Ganem"
      ],
      "abstract": "High-dimensional data commonly lies on low-dimensional submanifolds, and\nestimating the local intrinsic dimension (LID) of a datum -- i.e. the dimension\nof the submanifold it belongs to -- is a longstanding problem. LID can be\nunderstood as the number of local factors of variation: the more factors of\nvariation a datum has, the more complex it tends to be. Estimating this\nquantity has proven useful in contexts ranging from generalization in neural\nnetworks to detection of out-of-distribution data, adversarial examples, and\nAI-generated text. The recent successes of deep generative models present an\nopportunity to leverage them for LID estimation, but current methods based on\ngenerative models produce inaccurate estimates, require more than a single\npre-trained model, are computationally intensive, or do not exploit the best\navailable deep generative models: diffusion models (DMs). In this work, we show\nthat the Fokker-Planck equation associated with a DM can provide an LID\nestimator which addresses the aforementioned deficiencies. Our estimator,\ncalled FLIPD, is easy to implement and compatible with all popular DMs.\nApplying FLIPD to synthetic LID estimation benchmarks, we find that DMs\nimplemented as fully-connected networks are highly effective LID estimators\nthat outperform existing baselines. We also apply FLIPD to natural images where\nthe true LID is unknown. Despite being sensitive to the choice of network\narchitecture, FLIPD estimates remain a useful measure of relative complexity;\ncompared to competing estimators, FLIPD exhibits a consistently higher\ncorrelation with image PNG compression rate and better aligns with qualitative\nassessments of complexity. Notably, FLIPD is orders of magnitude faster than\nother LID estimators, and the first to be tractable at the scale of Stable\nDiffusion.",
      "tldr_zh": "本研究从几何视角探讨数据复杂性，提出了一种高效的局部内在维度（Local Intrinsic Dimension, LID）估计方法，利用扩散模型（Diffusion Models, DMs）的Fokker-Planck方程开发了名为FLIPD的估计器，以解决现有方法在准确性和计算效率上的不足。FLIPD易于实现，并兼容所有流行DMs，在合成基准测试中，基于全连接网络的DMs表现出色，优于现有基线估计器。应用于自然图像时，FLIPD提供可靠的相对复杂度测量，与图像PNG压缩率的相关性更高，且与定性评估一致。相比其他估计器，FLIPD的计算速度快几个数量级，并首次适用于大规模模型如Stable Diffusion，从而提升了LID在神经网络泛化和异常检测等领域的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 (spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2406.03537v2",
      "published_date": "2024-06-05 18:00:02 UTC",
      "updated_date": "2024-10-24 18:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:24:08.272221"
    },
    {
      "arxiv_id": "2406.03496v1",
      "title": "Wings: Learning Multimodal LLMs without Text-only Forgetting",
      "title_zh": "翻译失败",
      "authors": [
        "Yi-Kai Zhang",
        "Shiyin Lu",
        "Yang Li",
        "Yanqing Ma",
        "Qing-Guo Chen",
        "Zhao Xu",
        "Weihua Luo",
        "Kaifu Zhang",
        "De-Chuan Zhan",
        "Han-Jia Ye"
      ],
      "abstract": "Multimodal large language models (MLLMs), initiated with a trained LLM, first\nalign images with text and then fine-tune on multimodal mixed inputs. However,\nthe MLLM catastrophically forgets the text-only instructions, which do not\ninclude images and can be addressed within the initial LLM. In this paper, we\npresent Wings, a novel MLLM that excels in both text-only dialogues and\nmultimodal comprehension. Analyzing MLLM attention in multimodal instructions\nreveals that text-only forgetting is related to the attention shifts from\npre-image to post-image text. From that, we construct extra modules that act as\nthe boosted learner to compensate for the attention shift. The complementary\nvisual and textual learners, like \"wings\" on either side, are connected in\nparallel within each layer's attention block. Initially, image and text inputs\nare aligned with visual learners operating alongside the main attention,\nbalancing focus on visual elements. Textual learners are later collaboratively\nintegrated with attention-based routing to blend the outputs of the visual and\ntextual learners. We design the Low-Rank Residual Attention (LoRRA) to\nguarantee high efficiency for learners. Our experimental results demonstrate\nthat Wings outperforms equally-scaled MLLMs in both text-only and visual\nquestion-answering tasks. On a newly constructed Interleaved Image-Text (IIT)\nbenchmark, Wings exhibits superior performance from text-only-rich to\nmultimodal-rich question-answering tasks.",
      "tldr_zh": "该论文提出Wings，一种新型多模态大语言模型(MLLMs)，旨在解决传统MLLMs在训练过程中遗忘文本-only指令的问题，同时保持多模态理解能力。研究通过分析MLLMs注意力转移（从图像前文本到图像后文本），构建额外的视觉和文本学习器，这些模块像“翅膀”一样并行连接在每个层的注意力块中，并使用Low-Rank Residual Attention (LoRRA)确保高效整合。实验结果显示，Wings在文本-only对话和视觉问答任务上优于同规模模型，并在新构建的Interleaved Image-Text (IIT)基准上表现出色，从文本-only-rich到多模态-rich任务均有显著提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03496v1",
      "published_date": "2024-06-05 17:59:40 UTC",
      "updated_date": "2024-06-05 17:59:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:24:20.286497"
    },
    {
      "arxiv_id": "2406.03520v2",
      "title": "VideoPhy: Evaluating Physical Commonsense for Video Generation",
      "title_zh": "VideoPhy: 评估视频生成的物理常识",
      "authors": [
        "Hritik Bansal",
        "Zongyu Lin",
        "Tianyi Xie",
        "Zeshun Zong",
        "Michal Yarom",
        "Yonatan Bitton",
        "Chenfanfu Jiang",
        "Yizhou Sun",
        "Kai-Wei Chang",
        "Aditya Grover"
      ],
      "abstract": "Recent advances in internet-scale video data pretraining have led to the\ndevelopment of text-to-video generative models that can create high-quality\nvideos across a broad range of visual concepts, synthesize realistic motions\nand render complex objects. Hence, these generative models have the potential\nto become general-purpose simulators of the physical world. However, it is\nunclear how far we are from this goal with the existing text-to-video\ngenerative models. To this end, we present VideoPhy, a benchmark designed to\nassess whether the generated videos follow physical commonsense for real-world\nactivities (e.g. marbles will roll down when placed on a slanted surface).\nSpecifically, we curate diverse prompts that involve interactions between\nvarious material types in the physical world (e.g., solid-solid, solid-fluid,\nfluid-fluid). We then generate videos conditioned on these captions from\ndiverse state-of-the-art text-to-video generative models, including open models\n(e.g., CogVideoX) and closed models (e.g., Lumiere, Dream Machine). Our human\nevaluation reveals that the existing models severely lack the ability to\ngenerate videos adhering to the given text prompts, while also lack physical\ncommonsense. Specifically, the best performing model, CogVideoX-5B, generates\nvideos that adhere to the caption and physical laws for 39.6% of the instances.\nVideoPhy thus highlights that the video generative models are far from\naccurately simulating the physical world. Finally, we propose an\nauto-evaluator, VideoCon-Physics, to assess the performance reliably for the\nnewly released models.",
      "tldr_zh": "该研究提出了 VideoPhy 基准，用于评估文本到视频生成模型是否能生成符合物理常识的视频，例如物体在重力作用下的运动。研究者收集了涉及不同材料互动（如 solid-solid 或 solid-fluid）的多样化提示，并使用多种先进模型（如 CogVideoX、Lumiere 和 Dream Machine）生成视频，然后通过人类评估发现，这些模型在遵守提示和物理规律方面表现欠佳，最佳模型 CogVideoX-5B 仅在 39.6% 的实例中准确。结果表明，现有的视频生成模型距离成为可靠的物理世界模拟器还有很大差距。最后，论文引入了自动评估器 VideoCon-Physics，以更可靠地评估新模型的表现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "43 pages, 29 figures, 12 tables. Added CogVideo and Dream Machine in\n  v2",
      "pdf_url": "http://arxiv.org/pdf/2406.03520v2",
      "published_date": "2024-06-05 17:53:55 UTC",
      "updated_date": "2024-10-03 17:24:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:24:31.491240"
    },
    {
      "arxiv_id": "2406.03487v1",
      "title": "Analyzing LLM Behavior in Dialogue Summarization: Unveiling Circumstantial Hallucination Trends",
      "title_zh": "翻译失败",
      "authors": [
        "Sanjana Ramprasad",
        "Elisa Ferracane",
        "Zachary C. Lipton"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have considerably\nadvanced the capabilities of summarization systems. However, they continue to\nface concerns about hallucinations. While prior work has evaluated LLMs\nextensively in news domains, most evaluation of dialogue summarization has\nfocused on BART-based models, leaving a gap in our understanding of their\nfaithfulness. Our work benchmarks the faithfulness of LLMs for dialogue\nsummarization, using human annotations and focusing on identifying and\ncategorizing span-level inconsistencies. Specifically, we focus on two\nprominent LLMs: GPT-4 and Alpaca-13B. Our evaluation reveals subtleties as to\nwhat constitutes a hallucination: LLMs often generate plausible inferences,\nsupported by circumstantial evidence in the conversation, that lack direct\nevidence, a pattern that is less prevalent in older models. We propose a\nrefined taxonomy of errors, coining the category of \"Circumstantial Inference\"\nto bucket these LLM behaviors and release the dataset. Using our taxonomy, we\ncompare the behavioral differences between LLMs and older fine-tuned models.\nAdditionally, we systematically assess the efficacy of automatic error\ndetection methods on LLM summaries and find that they struggle to detect these\nnuanced errors. To address this, we introduce two prompt-based approaches for\nfine-grained error detection that outperform existing metrics, particularly for\nidentifying \"Circumstantial Inference.\"",
      "tldr_zh": "本研究评估了大型语言模型 (LLMs) 在对话摘要中的幻觉问题，特别是 GPT-4 和 Alpaca-13B 的表现，通过人类注解识别和分类 span-level 不一致。研究发现，LLMs 经常生成基于对话中间接证据的“Circumstantial Inference”错误，这些错误虽看似合理但缺乏直接支持，且比旧模型（如 BART-based）更常见。作者提出一个细化的错误分类系统，并引入两种基于提示的错误检测方法，这些方法优于现有指标，尤其在识别“Circumstantial Inference”方面，并发布了相关数据集。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03487v1",
      "published_date": "2024-06-05 17:49:47 UTC",
      "updated_date": "2024-06-05 17:49:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:24:43.191458"
    },
    {
      "arxiv_id": "2406.03486v1",
      "title": "BIPED: Pedagogically Informed Tutoring System for ESL Education",
      "title_zh": "翻译失败",
      "authors": [
        "Soonwoo Kwon",
        "Sojung Kim",
        "Minju Park",
        "Seunghyun Lee",
        "Kyuseok Kim"
      ],
      "abstract": "Large Language Models (LLMs) have a great potential to serve as readily\navailable and cost-efficient Conversational Intelligent Tutoring Systems (CITS)\nfor teaching L2 learners of English. Existing CITS, however, are designed to\nteach only simple concepts or lack the pedagogical depth necessary to address\ndiverse learning strategies. To develop a more pedagogically informed CITS\ncapable of teaching complex concepts, we construct a BIlingual\nPEDagogically-informed Tutoring Dataset (BIPED) of one-on-one, human-to-human\nEnglish tutoring interactions. Through post-hoc analysis of the tutoring\ninteractions, we come up with a lexicon of dialogue acts (34 tutor acts and 9\nstudent acts), which we use to further annotate the collected dataset. Based on\na two-step framework of first predicting the appropriate tutor act then\ngenerating the corresponding response, we implemented two CITS models using\nGPT-4 and SOLAR-KO, respectively. We experimentally demonstrate that the\nimplemented models not only replicate the style of human teachers but also\nemploy diverse and contextually appropriate pedagogical strategies.",
      "tldr_zh": "本研究提出了一种教育学指导的辅导系统BIPED，用于英语作为二语(ESL)教育，旨在利用大型语言模型(LLMs)作为对话智能辅导系统(CITS)来处理复杂概念教学。研究者构建了BIPED数据集，通过分析一对一的人类辅导互动，定义了对话行为词汇(dialogue acts，包括34种导师行为和9种学生行为)，并对数据集进行标注。基于一个两步框架（先预测合适的导师行为，然后生成响应），他们使用GPT-4和SOLAR-KO实现了两个CITS模型。实验结果表明，这些模型不仅能复制人类老师的风格，还能采用多样化和上下文合适的教学策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03486v1",
      "published_date": "2024-06-05 17:49:24 UTC",
      "updated_date": "2024-06-05 17:49:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:24:57.921188"
    },
    {
      "arxiv_id": "2406.03485v1",
      "title": "Highway Value Iteration Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhui Wang",
        "Weida Li",
        "Francesco Faccio",
        "Qingyuan Wu",
        "Jürgen Schmidhuber"
      ],
      "abstract": "Value iteration networks (VINs) enable end-to-end learning for planning tasks\nby employing a differentiable \"planning module\" that approximates the value\niteration algorithm. However, long-term planning remains a challenge because\ntraining very deep VINs is difficult. To address this problem, we embed highway\nvalue iteration -- a recent algorithm designed to facilitate long-term credit\nassignment -- into the structure of VINs. This improvement augments the\n\"planning module\" of the VIN with three additional components: 1) an \"aggregate\ngate,\" which constructs skip connections to improve information flow across\nmany layers; 2) an \"exploration module,\" crafted to increase the diversity of\ninformation and gradient flow in spatial dimensions; 3) a \"filter gate\"\ndesigned to ensure safe exploration. The resulting novel highway VIN can be\ntrained effectively with hundreds of layers using standard backpropagation. In\nlong-term planning tasks requiring hundreds of planning steps, deep highway\nVINs outperform both traditional VINs and several advanced, very deep NNs.",
      "tldr_zh": "该研究改进了 Value Iteration Networks (VINs)，通过嵌入 Highway Value Iteration 来解决训练深层网络的困难，从而提升长期规划任务的性能。\n他们添加了三个关键组件：aggregate gate 用于构建跳跃连接改善多层信息流动、exploration module 增强空间维度的信息和梯度多样性，以及 filter gate 确保安全探索。\n结果显示，深度 Highway VINs 能够在数百层中使用标准反向传播有效训练，并在需要数百步规划的长期任务中，优于传统 VINs 和其他先进深度神经网络。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03485v1",
      "published_date": "2024-06-05 17:46:26 UTC",
      "updated_date": "2024-06-05 17:46:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:25:07.951149"
    },
    {
      "arxiv_id": "2406.03482v2",
      "title": "QJL: 1-Bit Quantized JL Transform for KV Cache Quantization with Zero Overhead",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Zandieh",
        "Majid Daliri",
        "Insu Han"
      ],
      "abstract": "Serving LLMs requires substantial memory due to the storage requirements of\nKey-Value (KV) embeddings in the KV cache, which grows with sequence length. An\neffective approach to compress KV cache is quantization. However, traditional\nquantization methods face significant memory overhead due to the need to store\nquantization constants (at least a zero point and a scale) in full precision\nper data block. Depending on the block size, this overhead can add 1 or 2 bits\nper quantized number. We introduce QJL, a new quantization approach that\nconsists of a Johnson-Lindenstrauss (JL) transform followed by sign-bit\nquantization. In contrast to existing methods, QJL eliminates memory overheads\nby removing the need for storing quantization constants. We propose an\nasymmetric estimator for the inner product of two vectors and demonstrate that\napplying QJL to one vector and a standard JL transform without quantization to\nthe other provides an unbiased estimator with minimal distortion. We have\ndeveloped an efficient implementation of the QJL sketch and its corresponding\ninner product estimator, incorporating a lightweight CUDA kernel for optimized\ncomputation. When applied across various LLMs and NLP tasks to quantize the KV\ncache to only 3 bits, QJL demonstrates a more than fivefold reduction in KV\ncache memory usage without compromising accuracy, all while achieving faster\nruntime. Codes are available at \\url{https://github.com/amirzandieh/QJL}.",
      "tldr_zh": "该论文提出QJL，一种基于Johnson-Lindenstrauss (JL)变换后进行1-bit sign-bit量化的方法，用于LLMs的KV cache量化，成功消除了传统量化方法中存储量化常数（如zero point和scale）的内存开销。QJL引入不对称内积估计器，对一个向量应用QJL量化，对另一个应用标准JL变换，实现无偏估计和最小失真，并通过高效的CUDA内核优化计算。实验结果显示，在各种LLMs和NLP任务中，将KV cache量化到仅3位时，内存使用减少五倍以上，同时保持准确性和提升运行速度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.03482v2",
      "published_date": "2024-06-05 17:42:05 UTC",
      "updated_date": "2024-07-18 16:31:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:25:19.366025"
    },
    {
      "arxiv_id": "2406.03470v1",
      "title": "SpikeZIP-TF: Conversion is All You Need for Transformer-based SNN",
      "title_zh": "翻译失败",
      "authors": [
        "Kang You",
        "Zekai Xu",
        "Chen Nie",
        "Zhijie Deng",
        "Qinghai Guo",
        "Xiang Wang",
        "Zhezhi He"
      ],
      "abstract": "Spiking neural network (SNN) has attracted great attention due to its\ncharacteristic of high efficiency and accuracy. Currently, the ANN-to-SNN\nconversion methods can obtain ANN on-par accuracy SNN with ultra-low latency (8\ntime-steps) in CNN structure on computer vision (CV) tasks. However, as\nTransformer-based networks have achieved prevailing precision on both CV and\nnatural language processing (NLP), the Transformer-based SNNs are still\nencounting the lower accuracy w.r.t the ANN counterparts. In this work, we\nintroduce a novel ANN-to-SNN conversion method called SpikeZIP-TF, where ANN\nand SNN are exactly equivalent, thus incurring no accuracy degradation.\nSpikeZIP-TF achieves 83.82% accuracy on CV dataset (ImageNet) and 93.79%\naccuracy on NLP dataset (SST-2), which are higher than SOTA Transformer-based\nSNNs. The code is available in GitHub:\nhttps://github.com/Intelligent-Computing-Research-Group/SpikeZIP_transformer",
      "tldr_zh": "本文提出了一种新型 ANN-to-SNN 转换方法 SpikeZIP-TF，使 ANN 和 SNN 完全等价，从而在 Transformer-based 网络上实现无准确性损失，解决了现有 SNN 在计算机视觉（CV）和自然语言处理（NLP）任务中的准确性不足问题。SpikeZIP-TF 通过精确的转换机制，在 ImageNet 数据集上达到 83.82% 的准确率，在 SST-2 数据集上达到 93.79%，均超过了 SOTA Transformer-based SNN 的性能。该方法为高效 SNN 应用提供了新途径，并已在 GitHub 上开源。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "* These authors contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2406.03470v1",
      "published_date": "2024-06-05 17:24:07 UTC",
      "updated_date": "2024-06-05 17:24:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:25:33.857903"
    },
    {
      "arxiv_id": "2406.03450v1",
      "title": "What is the Best Way for ChatGPT to Translate Poetry?",
      "title_zh": "ChatGPT 翻译诗歌的最佳方式",
      "authors": [
        "Shanshan Wang",
        "Derek F. Wong",
        "Jingming Yao",
        "Lidia S. Chao"
      ],
      "abstract": "Machine translation (MT) has historically faced significant challenges when\napplied to literary works, particularly in the domain of poetry translation.\nThe advent of Large Language Models such as ChatGPT holds potential for\ninnovation in this field. This study examines ChatGPT's capabilities in\nEnglish-Chinese poetry translation tasks, utilizing targeted prompts and small\nsample scenarios to ascertain optimal performance. Despite promising outcomes,\nour analysis reveals persistent issues in the translations generated by ChatGPT\nthat warrant attention. To address these shortcomings, we propose an\nExplanation-Assisted Poetry Machine Translation (EAPMT) method, which leverages\nmonolingual poetry explanation as a guiding information for the translation\nprocess. Furthermore, we refine existing evaluation criteria to better suit the\nnuances of modern poetry translation. We engaged a panel of professional poets\nfor assessments, complemented evaluations by using GPT-4. The results from both\nhuman and machine evaluations demonstrate that our EAPMT method outperforms\ntraditional translation methods of ChatGPT and the existing online systems.\nThis paper validates the efficacy of our method and contributes a novel\nperspective to machine-assisted literary translation.",
      "tldr_zh": "本研究探讨了 ChatGPT 在英语-中文诗歌翻译中的表现，使用针对性提示和小样本场景进行测试，发现其翻译存在显著问题，如准确性和细微差别处理不足。针对这些问题，作者提出 Explanation-Assisted Poetry Machine Translation (EAPMT) 方法，通过利用单语诗歌解释作为指导信息来提升翻译质量，并改进了评估标准，包括专业诗人和 GPT-4 的联合评估。结果显示，EAPMT 优于 ChatGPT 的传统方法和现有在线系统，为机器辅助文学翻译提供了新颖视角和有效途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 1 figure. The paper has been accepted by ACL 2024(Main\n  Conference)",
      "pdf_url": "http://arxiv.org/pdf/2406.03450v1",
      "published_date": "2024-06-05 16:48:26 UTC",
      "updated_date": "2024-06-05 16:48:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:25:45.499107"
    },
    {
      "arxiv_id": "2406.03447v1",
      "title": "FILS: Self-Supervised Video Feature Prediction In Semantic Language Space",
      "title_zh": "FILS：自监督视频特征预测于语义语言空间",
      "authors": [
        "Mona Ahmadian",
        "Frank Guerin",
        "Andrew Gilbert"
      ],
      "abstract": "This paper demonstrates a self-supervised approach for learning semantic\nvideo representations. Recent vision studies show that a masking strategy for\nvision and natural language supervision has contributed to developing\ntransferable visual pretraining. Our goal is to achieve a more semantic video\nrepresentation by leveraging the text related to the video content during the\npretraining in a fully self-supervised manner. To this end, we present FILS, a\nnovel self-supervised video Feature prediction In semantic Language Space\n(FILS). The vision model can capture valuable structured information by\ncorrectly predicting masked feature semantics in language space. It is learned\nusing a patch-wise video-text contrastive strategy, in which the text\nrepresentations act as prototypes for transforming vision features into a\nlanguage space, which are then used as targets for semantically meaningful\nfeature prediction using our masked encoder-decoder structure. FILS\ndemonstrates remarkable transferability on downstream action recognition tasks,\nachieving state-of-the-art on challenging egocentric datasets, like\nEpic-Kitchens, Something-SomethingV2, Charades-Ego, and EGTEA, using ViT-Base.\nOur efficient method requires less computation and smaller batches compared to\nprevious works.",
      "tldr_zh": "本研究提出了一种自监督方法 FILS（Self-Supervised Video Feature Prediction In Semantic Language Space），旨在通过视频相关文本在语义语言空间中学习更有效的视频表示。FILS 利用 patch-wise video-text contrastive strategy，将文本表示作为原型，将视觉特征转化为语言空间，并通过 masked encoder-decoder 结构预测被遮罩的特征语义，从而捕获结构化信息。该方法在下游动作识别任务上表现出色，使用 ViT-Base 模型在 Epic-Kitchens、Something-SomethingV2、Charades-Ego 和 EGTEA 等 egocentric 数据集上达到 state-of-the-art 性能，同时具有高效计算优势，需要更少的计算资源和更小的批量大小。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03447v1",
      "published_date": "2024-06-05 16:44:06 UTC",
      "updated_date": "2024-06-05 16:44:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:25:57.094854"
    },
    {
      "arxiv_id": "2406.16910v1",
      "title": "Mind's Eye: Image Recognition by EEG via Multimodal Similarity-Keeping Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chi-Sheng Chen",
        "Chun-Shu Wei"
      ],
      "abstract": "Decoding images from non-invasive electroencephalographic (EEG) signals has\nbeen a grand challenge in understanding how the human brain process visual\ninformation in real-world scenarios. To cope with the issues of signal-to-noise\nratio and nonstationarity, this paper introduces a MUltimodal\nSimilarity-keeping contrastivE learning (MUSE) framework for zero-shot\nEEG-based image classification. We develop a series of multivariate time-series\nencoders tailored for EEG signals and assess the efficacy of regularized\ncontrastive EEG-Image pretraining using an extensive visual EEG dataset. Our\nmethod achieves state-of-the-art performance, with a top-1 accuracy of 19.3%\nand a top-5 accuracy of 48.8% in 200-way zero-shot image classification.\nFurthermore, we visualize neural patterns via model interpretation, shedding\nlight on the visual processing dynamics in the human brain. The code repository\nfor this work is available at: https://github.com/ChiShengChen/MUSE_EEG.",
      "tldr_zh": "本文提出了一种名为 MUSE 的多模态相似性保持对比学习框架，用于从非侵入性 EEG 信号中实现零样本图像识别，旨在解决信号噪声比和非平稳性问题。框架包括针对 EEG 的多变量时间序列编码器，并通过正则化对比 EEG-Image 预训练，在一个广泛的视觉 EEG 数据集上取得了 state-of-the-art 性能：200-way zero-shot 图像分类的 top-1 准确率达 19.3%，top-5 准确率达 48.8%。此外，研究通过模型解释可视化神经模式，揭示了大脑视觉处理动态，为理解人类视觉信息处理提供了新见解。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "eess.SP",
      "comment": "19 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.16910v1",
      "published_date": "2024-06-05 16:42:23 UTC",
      "updated_date": "2024-06-05 16:42:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:26:09.911056"
    },
    {
      "arxiv_id": "2406.03516v1",
      "title": "Buffered Asynchronous Secure Aggregation for Cross-Device Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Wang",
        "Yi-Rui Yang",
        "Wu-Jun Li"
      ],
      "abstract": "Asynchronous federated learning (AFL) is an effective method to address the\nchallenge of device heterogeneity in cross-device federated learning. However,\nAFL is usually incompatible with existing secure aggregation protocols used to\nprotect user privacy in federated learning because most existing secure\naggregation protocols are based on synchronous aggregation. To address this\nproblem, we propose a novel secure aggregation protocol named buffered\nasynchronous secure aggregation (BASA) in this paper. Compared with existing\nprotocols, BASA is fully compatible with AFL and provides secure aggregation\nunder the condition that each user only needs one round of communication with\nthe server without relying on any synchronous interaction among users. Based on\nBASA, we propose the first AFL method which achieves secure aggregation without\nextra requirements on hardware. We empirically demonstrate that BASA\noutperforms existing secure aggregation protocols for cross-device federated\nlearning in terms of training efficiency and scalability.",
      "tldr_zh": "这篇论文针对跨设备联邦学习中异步联邦学习(AFL)与现有安全聚合协议的不兼容问题，提出了一种新型协议Buffered Asynchronous Secure Aggregation (BASA)。BASA 完全兼容 AFL，每个用户只需与服务器进行一轮通信即可实现安全聚合，无需用户间的同步交互或额外硬件支持。实验结果表明，BASA 在训练效率和可扩展性方面优于现有协议，为隐私保护的联邦学习提供了更高效的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03516v1",
      "published_date": "2024-06-05 16:39:32 UTC",
      "updated_date": "2024-06-05 16:39:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:26:21.431238"
    },
    {
      "arxiv_id": "2406.03442v2",
      "title": "Are language models rational? The case of coherence norms and belief revision",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Hofweber",
        "Peter Hase",
        "Elias Stengel-Eskin",
        "Mohit Bansal"
      ],
      "abstract": "Do norms of rationality apply to machine learning models, in particular\nlanguage models? In this paper we investigate this question by focusing on a\nspecial subset of rational norms: coherence norms. We consider both logical\ncoherence norms as well as coherence norms tied to the strength of belief. To\nmake sense of the latter, we introduce the Minimal Assent Connection (MAC) and\npropose a new account of credence, which captures the strength of belief in\nlanguage models. This proposal uniformly assigns strength of belief simply on\nthe basis of model internal next token probabilities. We argue that rational\nnorms tied to coherence do apply to some language models, but not to others.\nThis issue is significant since rationality is closely tied to predicting and\nexplaining behavior, and thus it is connected to considerations about AI safety\nand alignment, as well as understanding model behavior more generally.",
      "tldr_zh": "本研究探讨语言模型是否遵守理性规范，特别是coherence norms和belief revision，焦点在于逻辑连贯性规范以及与信念强度相关的规范。作者引入Minimal Assent Connection (MAC)并提出一种新的credence账户，该方法基于模型内部的next token probabilities来统一评估信念强度。结果表明，有些语言模型符合这些coherence norms，而有些则不，这对AI safety、alignment以及理解模型行为具有重要意义。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "added discussion and cross reference of new empirical work by the\n  authors, updated references, fixed typos",
      "pdf_url": "http://arxiv.org/pdf/2406.03442v2",
      "published_date": "2024-06-05 16:36:21 UTC",
      "updated_date": "2024-08-10 21:55:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:26:32.832536"
    },
    {
      "arxiv_id": "2406.03439v1",
      "title": "Text-to-Events: Synthetic Event Camera Streams from Conditional Text Input",
      "title_zh": "Text-to-Events：基于条件文本输入的合成事件相机流",
      "authors": [
        "Joachim Ott",
        "Zuowen Wang",
        "Shih-Chii Liu"
      ],
      "abstract": "Event cameras are advantageous for tasks that require vision sensors with\nlow-latency and sparse output responses. However, the development of deep\nnetwork algorithms using event cameras has been slow because of the lack of\nlarge labelled event camera datasets for network training. This paper reports a\nmethod for creating new labelled event datasets by using a text-to-X model,\nwhere X is one or multiple output modalities, in the case of this work, events.\nOur proposed text-to-events model produces synthetic event frames directly from\ntext prompts. It uses an autoencoder which is trained to produce sparse event\nframes representing event camera outputs. By combining the pretrained\nautoencoder with a diffusion model architecture, the new text-to-events model\nis able to generate smooth synthetic event streams of moving objects. The\nautoencoder was first trained on an event camera dataset of diverse scenes. In\nthe combined training with the diffusion model, the DVS gesture dataset was\nused. We demonstrate that the model can generate realistic event sequences of\nhuman gestures prompted by different text statements. The classification\naccuracy of the generated sequences, using a classifier trained on the real\ndataset, ranges between 42% to 92%, depending on the gesture group. The results\ndemonstrate the capability of this method in synthesizing event datasets.",
      "tldr_zh": "这篇论文提出了一种 text-to-events 模型，用于从条件文本输入生成合成事件相机数据流，以解决事件相机数据集缺乏问题，从而加速深度网络算法的开发。方法结合 autoencoder 和 diffusion model，先在多样场景数据集上训练 autoencoder 生成稀疏事件帧，然后与 diffusion model 一起使用 DVS gesture 数据集训练，以产生平滑的合成事件序列。实验结果显示，生成的序列在使用真实数据集训练的分类器上准确率达 42% 到 92%，证明了该方法在合成高质量事件数据集方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T99",
        "I.2.6; I.2.7; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03439v1",
      "published_date": "2024-06-05 16:34:12 UTC",
      "updated_date": "2024-06-05 16:34:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:26:45.387148"
    },
    {
      "arxiv_id": "2406.03434v1",
      "title": "Unified PAC-Bayesian Study of Pessimism for Offline Policy Learning with Regularized Importance Sampling",
      "title_zh": "统一的 PAC-Bayesian 研究：针对带正则化重要性采样的离线策略学习的悲观主义分析",
      "authors": [
        "Imad Aouali",
        "Victor-Emmanuel Brunel",
        "David Rohde",
        "Anna Korba"
      ],
      "abstract": "Off-policy learning (OPL) often involves minimizing a risk estimator based on\nimportance weighting to correct bias from the logging policy used to collect\ndata. However, this method can produce an estimator with a high variance. A\ncommon solution is to regularize the importance weights and learn the policy by\nminimizing an estimator with penalties derived from generalization bounds\nspecific to the estimator. This approach, known as pessimism, has gained recent\nattention but lacks a unified framework for analysis. To address this gap, we\nintroduce a comprehensive PAC-Bayesian framework to examine pessimism with\nregularized importance weighting. We derive a tractable PAC-Bayesian\ngeneralization bound that universally applies to common importance weight\nregularizations, enabling their comparison within a single framework. Our\nempirical results challenge common understanding, demonstrating the\neffectiveness of standard IW regularization techniques.",
      "tldr_zh": "该论文针对离线策略学习(Offline Policy Learning, OPL)中的偏差问题，提出使用正则化重要性采样(Regularized Importance Sampling)来最小化风险估计器，以缓解重要性权重(Importance Weighting)带来的高方差。研究引入了一个统一的 PAC-Bayesian 框架来分析悲观主义(Pessimism)方法，导出了适用于常见权重正则化的通用广义化界限(Generalization Bound)。实验结果挑战了传统认知，证明了标准 IW 正则化技术的有效性，为 OPL 的优化提供了更可靠的理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at UAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03434v1",
      "published_date": "2024-06-05 16:32:14 UTC",
      "updated_date": "2024-06-05 16:32:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:26:58.324770"
    },
    {
      "arxiv_id": "2406.06591v2",
      "title": "Exploring Multilingual Large Language Models for Enhanced TNM classification of Radiology Report in lung cancer staging",
      "title_zh": "翻译失败",
      "authors": [
        "Hidetoshi Matsuo",
        "Mizuho Nishio",
        "Takaaki Matsunaga",
        "Koji Fujimoto",
        "Takamichi Murakami"
      ],
      "abstract": "Background: Structured radiology reports remains underdeveloped due to\nlabor-intensive structuring and narrative-style reporting. Deep learning,\nparticularly large language models (LLMs) like GPT-3.5, offers promise in\nautomating the structuring of radiology reports in natural languages. However,\nalthough it has been reported that LLMs are less effective in languages other\nthan English, their radiological performance has not been extensively studied.\nPurpose: This study aimed to investigate the accuracy of TNM classification\nbased on radiology reports using GPT3.5-turbo (GPT3.5) and the utility of\nmultilingual LLMs in both Japanese and English. Material and Methods: Utilizing\nGPT3.5, we developed a system to automatically generate TNM classifications\nfrom chest CT reports for lung cancer and evaluate its performance. We\nstatistically analyzed the impact of providing full or partial TNM definitions\nin both languages using a Generalized Linear Mixed Model. Results: Highest\naccuracy was attained with full TNM definitions and radiology reports in\nEnglish (M = 94%, N = 80%, T = 47%, and ALL = 36%). Providing definitions for\neach of the T, N, and M factors statistically improved their respective\naccuracies (T: odds ratio (OR) = 2.35, p < 0.001; N: OR = 1.94, p < 0.01; M: OR\n= 2.50, p < 0.001). Japanese reports exhibited decreased N and M accuracies (N\naccuracy: OR = 0.74 and M accuracy: OR = 0.21). Conclusion: This study\nunderscores the potential of multilingual LLMs for automatic TNM classification\nin radiology reports. Even without additional model training, performance\nimprovements were evident with the provided TNM definitions, indicating LLMs'\nrelevance in radiology contexts.",
      "tldr_zh": "本研究探讨了使用多语言大型语言模型 (LLMs) 如 GPT-3.5-turbo 来自动生成肺癌分期放射学报告的 TNM classification，旨在评估其准确性和在英语及日语中的效用。研究开发了一个系统，从胸部 CT 报告中提取 TNM 分类，并通过广义线性混合模型分析提供完整或部分 TNM 定义的影响，结果显示英语报告结合完整定义可达最高准确率（T: 47%, N: 80%, M: 94%, ALL: 36%），而提供定义显著提升了各因素的准确率（T: OR=2.35, p<0.001; N: OR=1.94, p<0.01; M: OR=2.50, p<0.001）。然而，日语报告的 N 和 M 准确率较低（N: OR=0.74, M: OR=0.21），这突出了 LLMs 在放射学中的潜力，即使无需额外训练，通过提供 TNM 定义也能改善报告结构化性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 3figures",
      "pdf_url": "http://arxiv.org/pdf/2406.06591v2",
      "published_date": "2024-06-05 16:11:55 UTC",
      "updated_date": "2024-06-12 15:19:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:27:15.966568"
    },
    {
      "arxiv_id": "2406.03388v1",
      "title": "SelfReDepth: Self-Supervised Real-Time Depth Restoration for Consumer-Grade Sensors",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandre Duarte",
        "Francisco Fernandes",
        "João M. Pereira",
        "Catarina Moreira",
        "Jacinto C. Nascimento",
        "Joaquim Jorge"
      ],
      "abstract": "Depth maps produced by consumer-grade sensors suffer from inaccurate\nmeasurements and missing data from either system or scene-specific sources.\nData-driven denoising algorithms can mitigate such problems. However, they\nrequire vast amounts of ground truth depth data. Recent research has tackled\nthis limitation using self-supervised learning techniques, but it requires\nmultiple RGB-D sensors. Moreover, most existing approaches focus on denoising\nsingle isolated depth maps or specific subjects of interest, highlighting a\nneed for methods to effectively denoise depth maps in real-time dynamic\nenvironments. This paper extends state-of-the-art approaches for\ndepth-denoising commodity depth devices, proposing SelfReDepth, a\nself-supervised deep learning technique for depth restoration, via denoising\nand hole-filling by inpainting full-depth maps captured with RGB-D sensors. The\nalgorithm targets depth data in video streams, utilizing multiple sequential\ndepth frames coupled with color data to achieve high-quality depth videos with\ntemporal coherence. Finally, SelfReDepth is designed to be compatible with\nvarious RGB-D sensors and usable in real-time scenarios as a pre-processing\nstep before applying other depth-dependent algorithms. Our results demonstrate\nour approach's real-time performance on real-world datasets. They show that it\noutperforms state-of-the-art denoising and restoration performance at over\n30fps on Commercial Depth Cameras, with potential benefits for augmented and\nmixed-reality applications.",
      "tldr_zh": "这篇论文针对消费级传感器（如 RGB-D sensors）产生的深度图中存在的测量不准确和数据缺失问题，提出了一种自监督深度学习方法SelfReDepth，用于实时深度恢复，包括去噪和空洞填充。该方法利用多个连续深度帧结合颜色数据，处理视频流以生成高质量、时间一致性的深度视频，并设计为兼容各种RGB-D传感器，可作为其他深度依赖算法的前处理步骤。实验结果显示，SelfReDepth在商业深度相机上以超过30fps的实时性能超越了现有方法，在增强现实和混合现实应用中展现出显著潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "13pp, 5 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2406.03388v1",
      "published_date": "2024-06-05 15:38:02 UTC",
      "updated_date": "2024-06-05 15:38:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:27:21.406305"
    },
    {
      "arxiv_id": "2406.06590v2",
      "title": "Are LLMs classical or nonmonotonic reasoners? Lessons from generics",
      "title_zh": "翻译失败",
      "authors": [
        "Alina Leidinger",
        "Robert van Rooij",
        "Ekaterina Shutova"
      ],
      "abstract": "Recent scholarship on reasoning in LLMs has supplied evidence of impressive\nperformance and flexible adaptation to machine generated or human feedback.\nNonmonotonic reasoning, crucial to human cognition for navigating the real\nworld, remains a challenging, yet understudied task. In this work, we study\nnonmonotonic reasoning capabilities of seven state-of-the-art LLMs in one\nabstract and one commonsense reasoning task featuring generics, such as 'Birds\nfly', and exceptions, 'Penguins don't fly' (see Fig. 1). While LLMs exhibit\nreasoning patterns in accordance with human nonmonotonic reasoning abilities,\nthey fail to maintain stable beliefs on truth conditions of generics at the\naddition of supporting examples ('Owls fly') or unrelated information ('Lions\nhave manes'). Our findings highlight pitfalls in attributing human reasoning\nbehaviours to LLMs, as well as assessing general capabilities, while consistent\nreasoning remains elusive.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）是否具备经典还是非单调推理能力，通过泛化语句（如 \"Birds fly\"）和例外（如 \"Penguins don't fly\"）进行测试。研究者评估了七个最先进LLMs在抽象和常识推理任务中的表现，发现这些模型在某些方面显示出与人类非单调推理相符的模式，但当添加支持例子（如 \"Owls fly\"）或无关信息（如 \"Lions have manes\"）时，无法保持信念的稳定性。这些发现突出了将人类推理行为归因于LLMs的潜在陷阱，并强调了一致性推理能力的挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ACL 2024 (main)",
      "pdf_url": "http://arxiv.org/pdf/2406.06590v2",
      "published_date": "2024-06-05 15:23:11 UTC",
      "updated_date": "2024-06-12 11:18:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:27:35.469190"
    },
    {
      "arxiv_id": "2406.03368v2",
      "title": "IrokoBench: A New Benchmark for African Languages in the Age of Large Language Models",
      "title_zh": "IrokoBench：大型语言模型时代针对非洲语言的新基准",
      "authors": [
        "David Ifeoluwa Adelani",
        "Jessica Ojo",
        "Israel Abebe Azime",
        "Jian Yun Zhuang",
        "Jesujoba O. Alabi",
        "Xuanli He",
        "Millicent Ochieng",
        "Sara Hooker",
        "Andiswa Bukula",
        "En-Shiun Annie Lee",
        "Chiamaka Chukwuneke",
        "Happy Buzaaba",
        "Blessing Sibanda",
        "Godson Kalipe",
        "Jonathan Mukiibi",
        "Salomon Kabongo",
        "Foutse Yuehgoh",
        "Mmasibidi Setaka",
        "Lolwethu Ndolela",
        "Nkiruka Odu",
        "Rooweither Mabuya",
        "Shamsuddeen Hassan Muhammad",
        "Salomey Osei",
        "Sokhar Samb",
        "Tadesse Kebede Guge",
        "Tombekai Vangoni Sherman",
        "Pontus Stenetorp"
      ],
      "abstract": "Despite the widespread adoption of Large language models (LLMs), their\nremarkable capabilities remain limited to a few high-resource languages.\nAdditionally, many low-resource languages (\\eg African languages) are often\nevaluated only on basic text classification tasks due to the lack of\nappropriate or comprehensive benchmarks outside of high-resource languages. In\nthis paper, we introduce IrokoBench -- a human-translated benchmark dataset for\n17 typologically-diverse low-resource African languages covering three tasks:\nnatural language inference~(AfriXNLI), mathematical reasoning~(AfriMGSM), and\nmulti-choice knowledge-based question answering~(AfriMMLU). We use IrokoBench\nto evaluate zero-shot, few-shot, and translate-test settings~(where test sets\nare translated into English) across 10 open and six proprietary LLMs. Our\nevaluation reveals a significant performance gap between high-resource\nlanguages~(such as English and French) and low-resource African languages. We\nobserve a significant performance gap between open and proprietary models, with\nthe highest performing open model, Gemma 2 27B only at 63\\% of the\nbest-performing proprietary model GPT-4o performance. In addition, machine\ntranslating the test set to English before evaluation helped to close the gap\nfor larger models that are English-centric, such as Gemma 2 27B and LLaMa 3.1\n70B. These findings suggest that more efforts are needed to develop and adapt\nLLMs for African languages.",
      "tldr_zh": "该研究引入了IrokoBench，一种针对17种类型多样化的低资源非洲语言的人工翻译基准数据集，涵盖自然语言推理(AfriXNLI)、数学推理(AfriMGSM)和多选知识问答(AfriMMLU)三个任务，以评估LLMs在这些语言中的性能。研究者评估了10个开源和6个专有LLMs在零样本、少样本及翻译测试设置下，结果显示高资源语言（如英语和法语）远超非洲语言的表现，且开源模型如Gemma 2 27B仅达到最佳专有模型GPT-4o性能的63%。此外，将测试集翻译成英语能帮助某些英语中心模型缩小差距，但这突显了开发和适应LLMs以更好地支持非洲语言的迫切需求。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 (main conference)",
      "pdf_url": "http://arxiv.org/pdf/2406.03368v2",
      "published_date": "2024-06-05 15:23:08 UTC",
      "updated_date": "2025-01-23 17:57:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:27:49.224682"
    },
    {
      "arxiv_id": "2406.03367v1",
      "title": "CLMASP: Coupling Large Language Models with Answer Set Programming for Robotic Task Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Xinrui Lin",
        "Yangfan Wu",
        "Huanyu Yang",
        "Yu Zhang",
        "Yanyong Zhang",
        "Jianmin Ji"
      ],
      "abstract": "Large Language Models (LLMs) possess extensive foundational knowledge and\nmoderate reasoning abilities, making them suitable for general task planning in\nopen-world scenarios. However, it is challenging to ground a LLM-generated plan\nto be executable for the specified robot with certain restrictions. This paper\nintroduces CLMASP, an approach that couples LLMs with Answer Set Programming\n(ASP) to overcome the limitations, where ASP is a non-monotonic logic\nprogramming formalism renowned for its capacity to represent and reason about a\nrobot's action knowledge. CLMASP initiates with a LLM generating a basic\nskeleton plan, which is subsequently tailored to the specific scenario using a\nvector database. This plan is then refined by an ASP program with a robot's\naction knowledge, which integrates implementation details into the skeleton,\ngrounding the LLM's abstract outputs in practical robot contexts. Our\nexperiments conducted on the VirtualHome platform demonstrate CLMASP's\nefficacy. Compared to the baseline executable rate of under 2% with LLM\napproaches, CLMASP significantly improves this to over 90%.",
      "tldr_zh": "这篇论文提出 CLMASP 方法，将 Large Language Models (LLMs) 与 Answer Set Programming (ASP) 结合，用于解决机器人任务规划中的问题，即LLMs 生成的计划难以适应特定机器人的限制。CLMASP 的流程包括：LLMs 先生成基本骨架计划，然后通过向量数据库进行场景定制，最后由 ASP 程序利用机器人的动作知识细化计划，使其在实际环境中可执行。实验在 VirtualHome 平台上表明，该方法将计划可执行率从 LLM 基线的不到 2% 显著提高到超过 90%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03367v1",
      "published_date": "2024-06-05 15:21:44 UTC",
      "updated_date": "2024-06-05 15:21:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:28:00.584174"
    },
    {
      "arxiv_id": "2406.03345v3",
      "title": "Feature contamination: Neural networks learn uncorrelated features and fail to generalize",
      "title_zh": "翻译失败",
      "authors": [
        "Tianren Zhang",
        "Chujie Zhao",
        "Guanyu Chen",
        "Yizhou Jiang",
        "Feng Chen"
      ],
      "abstract": "Learning representations that generalize under distribution shifts is\ncritical for building robust machine learning models. However, despite\nsignificant efforts in recent years, algorithmic advances in this direction\nhave been limited. In this work, we seek to understand the fundamental\ndifficulty of out-of-distribution generalization with deep neural networks. We\nfirst empirically show that perhaps surprisingly, even allowing a neural\nnetwork to explicitly fit the representations obtained from a teacher network\nthat can generalize out-of-distribution is insufficient for the generalization\nof the student network. Then, by a theoretical study of two-layer ReLU networks\noptimized by stochastic gradient descent (SGD) under a structured feature\nmodel, we identify a fundamental yet unexplored feature learning proclivity of\nneural networks, feature contamination: neural networks can learn uncorrelated\nfeatures together with predictive features, resulting in generalization failure\nunder distribution shifts. Notably, this mechanism essentially differs from the\nprevailing narrative in the literature that attributes the generalization\nfailure to spurious correlations. Overall, our results offer new insights into\nthe non-linear feature learning dynamics of neural networks and highlight the\nnecessity of considering inductive biases in out-of-distribution\ngeneralization.",
      "tldr_zh": "本研究探讨了神经网络在分布偏移（out-of-distribution generalization）下的泛化困难，通过实验发现，即使学生网络从能泛化的教师网络学习表示，也无法实现有效泛化。作者通过理论分析双层 ReLU 网络在 stochastic gradient descent (SGD) 优化下的行为，揭示了神经网络的一种核心问题：feature contamination，即同时学习预测特征和无关特征，导致在分布变化时泛化失败。不同于以往将泛化失败归因于虚假相关性的观点，该研究提供了对神经网络非线性特征学习动态的新见解，并强调了在分布外泛化中考虑归纳偏差的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03345v3",
      "published_date": "2024-06-05 15:04:27 UTC",
      "updated_date": "2025-02-13 13:25:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:28:22.273566"
    },
    {
      "arxiv_id": "2406.03344v1",
      "title": "Audio Mamba: Bidirectional State Space Model for Audio Representation Learning",
      "title_zh": "Audio Mamba：双向状态空间模型用于音频表示学习",
      "authors": [
        "Mehmet Hamza Erol",
        "Arda Senocak",
        "Jiu Feng",
        "Joon Son Chung"
      ],
      "abstract": "Transformers have rapidly become the preferred choice for audio\nclassification, surpassing methods based on CNNs. However, Audio Spectrogram\nTransformers (ASTs) exhibit quadratic scaling due to self-attention. The\nremoval of this quadratic self-attention cost presents an appealing direction.\nRecently, state space models (SSMs), such as Mamba, have demonstrated potential\nin language and vision tasks in this regard. In this study, we explore whether\nreliance on self-attention is necessary for audio classification tasks. By\nintroducing Audio Mamba (AuM), the first self-attention-free, purely SSM-based\nmodel for audio classification, we aim to address this question. We evaluate\nAuM on various audio datasets - comprising six different benchmarks - where it\nachieves comparable or better performance compared to well-established AST\nmodel.",
      "tldr_zh": "该研究探讨了在音频分类任务中，是否需要依赖Transformers的自注意力机制。作者提出Audio Mamba (AuM)，一个基于双向状态空间模型(SSMs)的全新模型，摒弃自注意力以降低计算复杂度。实验结果显示，AuM在六个音频基准数据集上，性能与Audio Spectrogram Transformers (AST)相当或更优，为高效音频表示学习提供了可行替代方案。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Code is available at https://github.com/mhamzaerol/Audio-Mamba-AuM",
      "pdf_url": "http://arxiv.org/pdf/2406.03344v1",
      "published_date": "2024-06-05 15:00:59 UTC",
      "updated_date": "2024-06-05 15:00:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:28:22.197559"
    },
    {
      "arxiv_id": "2406.03341v7",
      "title": "Tackling Copyright Issues in AI Image Generation Through Originality Estimation and Genericization",
      "title_zh": "翻译失败",
      "authors": [
        "Hiroaki Chiba-Okabe",
        "Weijie J. Su"
      ],
      "abstract": "The rapid progress of generative AI technology has sparked significant\ncopyright concerns, leading to numerous lawsuits filed against AI developers.\nNotably, generative AI's capacity for generating images of copyrighted\ncharacters has been well documented in the literature, and while various\ntechniques for mitigating copyright issues have been studied, significant risks\nremain. Here, we propose a genericization method that modifies the outputs of a\ngenerative model to make them more generic and less likely to imitate\ndistinctive features of copyrighted materials. To achieve this, we introduce a\nmetric for quantifying the level of originality of data, estimated by drawing\nsamples from a generative model, and applied in the genericization process. As\na practical implementation, we introduce PREGen (Prompt Rewriting-Enhanced\nGenericization), which combines our genericization method with an existing\nmitigation technique. Compared to the existing method, PREGen reduces the\nlikelihood of generating copyrighted characters by more than half when the\nnames of copyrighted characters are used as the prompt. Additionally, while\ngenerative models can produce copyrighted characters even when their names are\nnot directly mentioned in the prompt, PREGen almost entirely prevents the\ngeneration of such characters in these cases. Ultimately, this study advances\ncomputational approaches for quantifying and strengthening copyright\nprotection, thereby providing practical methodologies to promote responsible\ngenerative AI development.",
      "tldr_zh": "该研究针对 generative AI 图像生成中的版权问题，提出一种原创性估算（originality estimation）和泛化方法（genericization），通过修改生成模型输出来减少模仿受版权材料独特特征的风险。研究引入一个量化原创性水平的指标，并将其应用于泛化过程，以评估从生成模型中抽样的数据。作者开发了 PREGen（Prompt Rewriting-Enhanced Genericization）框架，将该方法与现有缓解技术结合，结果显示 PREGen 在使用受版权人物名称作为提示时，能将生成此类人物的概率降低一半以上，甚至在不直接提及名称的情况下，几乎完全防止生成。最终，该工作推进了版权保护的计算方法，促进了负责任的 generative AI 开发。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.03341v7",
      "published_date": "2024-06-05 14:58:32 UTC",
      "updated_date": "2025-03-31 02:53:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:28:35.146897"
    },
    {
      "arxiv_id": "2406.03339v2",
      "title": "The Challenges of Evaluating LLM Applications: An Analysis of Automated, Human, and LLM-Based Approaches",
      "title_zh": "评估 LLM 应用的挑战：对自动化、人为和基于 LLM 方法的分析",
      "authors": [
        "Bhashithe Abeysinghe",
        "Ruhan Circi"
      ],
      "abstract": "Chatbots have been an interesting application of natural language generation\nsince its inception. With novel transformer based Generative AI methods,\nbuilding chatbots have become trivial. Chatbots which are targeted at specific\ndomains for example medicine and psychology are implemented rapidly. This\nhowever, should not distract from the need to evaluate the chatbot responses.\nEspecially because the natural language generation community does not entirely\nagree upon how to effectively evaluate such applications. With this work we\ndiscuss the issue further with the increasingly popular LLM based evaluations\nand how they correlate with human evaluations. Additionally, we introduce a\ncomprehensive factored evaluation mechanism that can be utilized in conjunction\nwith both human and LLM-based evaluations. We present the results of an\nexperimental evaluation conducted using this scheme in one of our chatbot\nimplementations which consumed educational reports, and subsequently compare\nautomated, traditional human evaluation, factored human evaluation, and\nfactored LLM evaluation. Results show that factor based evaluation produces\nbetter insights on which aspects need to be improved in LLM applications and\nfurther strengthens the argument to use human evaluation in critical spaces\nwhere main functionality is not direct retrieval.",
      "tldr_zh": "这篇论文分析了评估LLM（Large Language Models）应用的挑战，特别是聊天机器人的响应评估，探讨了自动化、人类和LLM-based评估方法之间的相关性。作者引入了一个全面的factored evaluation mechanism，能够与人类和LLM评估结合使用，以提供更细化的评估框架。在实验中，他们对一个处理教育报告的聊天机器人进行评估，结果显示factored评估方法能更好地识别LLM应用的改进点，并强化了在关键领域使用人类评估的必要性，以确保可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in The First Workshop on Large Language Models for\n  Evaluation in Information Retrieval",
      "pdf_url": "http://arxiv.org/pdf/2406.03339v2",
      "published_date": "2024-06-05 14:55:10 UTC",
      "updated_date": "2024-06-13 15:13:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:28:57.097560"
    },
    {
      "arxiv_id": "2406.03314v2",
      "title": "Reproducibility study of FairAC",
      "title_zh": "FairAC 的可重复性研究",
      "authors": [
        "Gijs de Jong",
        "Macha J. Meijer",
        "Derck W. E. Prinzhorn",
        "Harold Ruiter"
      ],
      "abstract": "This work aims to reproduce the findings of the paper \"Fair Attribute\nCompletion on Graph with Missing Attributes\" written by Guo, Chu, and Li\narXiv:2302.12977 by investigating the claims made in the paper. This paper\nsuggests that the results of the original paper are reproducible and thus, the\nclaims hold. However, the claim that FairAC is a generic framework for many\ndownstream tasks is very broad and could therefore only be partially tested.\nMoreover, we show that FairAC is generalizable to various datasets and\nsensitive attributes and show evidence that the improvement in group fairness\nof the FairAC framework does not come at the expense of individual fairness.\nLastly, the codebase of FairAC has been refactored and is now easily applicable\nfor various datasets and models.",
      "tldr_zh": "本研究旨在复现 Guo 等人的论文\"Fair Attribute Completion on Graph with Missing Attributes\"（arXiv:2302.12977），通过调查其声明来验证结果的可复现性，结果显示原始论文的核心发现是可复现的，但FairAC作为通用框架的声明仅部分得到测试。研究进一步证明了FairAC在多种数据集和敏感属性上具有泛化能力，同时提升group fairness不会以牺牲individual fairness为代价。最终，FairAC的代码库已被重构，便于应用于各种数据集和模型，从而增强其实际可用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 2 figures, accepted at TMLR",
      "pdf_url": "http://arxiv.org/pdf/2406.03314v2",
      "published_date": "2024-06-05 14:26:45 UTC",
      "updated_date": "2024-06-10 16:09:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:28:59.142027"
    },
    {
      "arxiv_id": "2406.03299v1",
      "title": "The Good, the Bad, and the Hulk-like GPT: Analyzing Emotional Decisions of Large Language Models in Cooperation and Bargaining Games",
      "title_zh": "翻译失败",
      "authors": [
        "Mikhail Mozikov",
        "Nikita Severin",
        "Valeria Bodishtianu",
        "Maria Glushanina",
        "Mikhail Baklashkin",
        "Andrey V. Savchenko",
        "Ilya Makarov"
      ],
      "abstract": "Behavior study experiments are an important part of society modeling and\nunderstanding human interactions. In practice, many behavioral experiments\nencounter challenges related to internal and external validity,\nreproducibility, and social bias due to the complexity of social interactions\nand cooperation in human user studies. Recent advances in Large Language Models\n(LLMs) have provided researchers with a new promising tool for the simulation\nof human behavior. However, existing LLM-based simulations operate under the\nunproven hypothesis that LLM agents behave similarly to humans as well as\nignore a crucial factor in human decision-making: emotions.\n  In this paper, we introduce a novel methodology and the framework to study\nboth, the decision-making of LLMs and their alignment with human behavior under\nemotional states. Experiments with GPT-3.5 and GPT-4 on four games from two\ndifferent classes of behavioral game theory showed that emotions profoundly\nimpact the performance of LLMs, leading to the development of more optimal\nstrategies. While there is a strong alignment between the behavioral responses\nof GPT-3.5 and human participants, particularly evident in bargaining games,\nGPT-4 exhibits consistent behavior, ignoring induced emotions for rationality\ndecisions. Surprisingly, emotional prompting, particularly with `anger'\nemotion, can disrupt the \"superhuman\" alignment of GPT-4, resembling human\nemotional responses.",
      "tldr_zh": "本文提出一种新方法和框架，用于分析大型语言模型 (LLMs) 在情绪状态下的决策行为及其与人类行为的对齐度，旨在解决传统行为实验的效度和偏差问题。研究通过在四种合作和讨价还价游戏中测试 GPT-3.5 和 GPT-4，发现情绪（如“anger”）深刻影响 LLMs 的表现，导致更优策略的开发，并提升 GPT-3.5 与人类响应的相似性，而 GPT-4 通常优先理性决策。总体结果表明，情感提示能破坏 GPT-4 的“超人”对齐，使其更接近人类行为，为 LLMs 模拟人类互动提供了重要洞见。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.7; J.4"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03299v1",
      "published_date": "2024-06-05 14:08:54 UTC",
      "updated_date": "2024-06-05 14:08:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:29:13.650941"
    },
    {
      "arxiv_id": "2406.18580v1",
      "title": "Shedding Light on Large Generative Networks: Estimating Epistemic Uncertainty in Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Berry",
        "Axel Brando",
        "David Meger"
      ],
      "abstract": "Generative diffusion models, notable for their large parameter count\n(exceeding 100 million) and operation within high-dimensional image spaces,\npose significant challenges for traditional uncertainty estimation methods due\nto computational demands. In this work, we introduce an innovative framework,\nDiffusion Ensembles for Capturing Uncertainty (DECU), designed for estimating\nepistemic uncertainty for diffusion models. The DECU framework introduces a\nnovel method that efficiently trains ensembles of conditional diffusion models\nby incorporating a static set of pre-trained parameters, drastically reducing\nthe computational burden and the number of parameters that require training.\nAdditionally, DECU employs Pairwise-Distance Estimators (PaiDEs) to accurately\nmeasure epistemic uncertainty by evaluating the mutual information between\nmodel outputs and weights in high-dimensional spaces. The effectiveness of this\nframework is demonstrated through experiments on the ImageNet dataset,\nhighlighting its capability to capture epistemic uncertainty, specifically in\nunder-sampled image classes.",
      "tldr_zh": "本文针对大型生成扩散模型（generative diffusion models）中认识不确定性（epistemic uncertainty）的估计挑战，提出了一种创新框架 DECU（Diffusion Ensembles for Capturing Uncertainty）。DECU 通过使用静态预训练参数高效训练条件扩散模型集合，显著减少计算负担和参数训练量，并引入 Pairwise-Distance Estimators (PaiDEs) 来评估模型输出与权重之间的互信息，从而精确测量高维空间的不确定性。实验在 ImageNet 数据集上验证了 DECU 的有效性，尤其在欠采样图像类别上，展示了其捕捉认识不确定性的能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18580v1",
      "published_date": "2024-06-05 14:03:21 UTC",
      "updated_date": "2024-06-05 14:03:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:29:23.902562"
    },
    {
      "arxiv_id": "2406.03292v1",
      "title": "Evaluating AI fairness in credit scoring with the BRIO tool",
      "title_zh": "翻译失败",
      "authors": [
        "Greta Coraglia",
        "Francesco A. Genco",
        "Pellegrino Piantadosi",
        "Enrico Bagli",
        "Pietro Giuffrida",
        "Davide Posillipo",
        "Giuseppe Primiero"
      ],
      "abstract": "We present a method for quantitative, in-depth analyses of fairness issues in\nAI systems with an application to credit scoring. To this aim we use BRIO, a\ntool for the evaluation of AI systems with respect to social unfairness and,\nmore in general, ethically undesirable behaviours. It features a model-agnostic\nbias detection module, presented in \\cite{DBLP:conf/beware/CoragliaDGGPPQ23},\nto which a full-fledged unfairness risk evaluation module is added. As a case\nstudy, we focus on the context of credit scoring, analysing the UCI German\nCredit Dataset \\cite{misc_statlog_(german_credit_data)_144}. We apply the BRIO\nfairness metrics to several, socially sensitive attributes featured in the\nGerman Credit Dataset, quantifying fairness across various demographic\nsegments, with the aim of identifying potential sources of bias and\ndiscrimination in a credit scoring model. We conclude by combining our results\nwith a revenue analysis.",
      "tldr_zh": "本研究介绍了 BRIO 工具，用于定量分析 AI 系统在信用评分中的公平性问题。BRIO 结合了模型无关的偏差检测模块和全面的不公平风险评估模块，作为一种模型 agnostic 的评估框架。以 UCI German Credit Dataset 为案例研究，该方法分析了多种社会敏感属性，量化了不同人口段的公平性，并识别潜在的偏差和歧视来源。最后，通过结合收入分析，结果为缓解 AI 公平性问题提供了实用见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03292v1",
      "published_date": "2024-06-05 14:00:46 UTC",
      "updated_date": "2024-06-05 14:00:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:29:37.392823"
    },
    {
      "arxiv_id": "2406.16909v1",
      "title": "Enhancing Computational Efficiency of Motor Imagery BCI Classification with Block-Toeplitz Augmented Covariance Matrices and Siegel Metric",
      "title_zh": "翻译失败",
      "authors": [
        "Igor Carrara",
        "Theodore Papadopoulo"
      ],
      "abstract": "Electroencephalographic signals are represented as multidimensional datasets.\nWe introduce an enhancement to the augmented covariance method (ACM),\nexploiting more thoroughly its mathematical properties, in order to improve\nmotor imagery classification.Standard ACM emerges as a combination of phase\nspace reconstruction of dynamical systems and of Riemannian geometry. Indeed,\nit is based on the construction of a Symmetric Positive Definite matrix to\nimprove classification. But this matrix also has a Block-Toeplitz structure\nthat was previously ignored. This work treats such matrices in the real\nmanifold to which they belong: the set of Block-Toeplitz SPD matrices. After\nsome manipulation, this set is can be seen as the product of an SPD manifold\nand a Siegel Disk Space.The proposed methodology was tested using the MOABB\nframework with a within-session evaluation procedure. It achieves a similar\nclassification performance to ACM, which is typically better than -- or at\nworse comparable to -- state-of-the-art methods. But, it also improves\nconsequently the computational efficiency over ACM, making it even more\nsuitable for real time experiments.",
      "tldr_zh": "本研究改进了Augmented Covariance Method (ACM)，通过利用其Block-Toeplitz结构和Siegel Metric，将其视为Symmetric Positive Definite (SPD) 流形与Siegel Disk Space的乘积，从而提升脑机接口(BCI)中运动想象分类的计算效率。方法结合了动态系统的相空间重建和Riemannian geometry，构建更有效的SPD矩阵进行分类。实验在MOABB框架下进行同会话评估，结果显示该方法分类性能与ACM相当，甚至优于现有技术，同时显著提高了计算效率，适用于实时实验。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "math.DG",
        "nlin.CD"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16909v1",
      "published_date": "2024-06-05 13:59:13 UTC",
      "updated_date": "2024-06-05 13:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:29:59.818725"
    },
    {
      "arxiv_id": "2406.03283v1",
      "title": "Enhancing Repository-Level Code Generation with Integrated Contextual Information",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Pan",
        "Xing Hu",
        "Xin Xia",
        "Xiaohu Yang"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\ncode generation tasks. However, repository-level code generation presents\nunique challenges, particularly due to the need to utilize information spread\nacross multiple files within a repository. Existing retrieval-based approaches\nsometimes fall short as they are limited in obtaining a broader and deeper\nrepository context. In this paper, we present CatCoder, a novel code generation\nframework designed for statically typed programming languages. CatCoder\nenhances repository-level code generation by integrating relevant code and type\ncontext. Specifically, it leverages static analyzers to extract type\ndependencies and merges this information with retrieved code to create\ncomprehensive prompts for LLMs. To evaluate the effectiveness of CatCoder, we\nadapt and construct benchmarks that include 199 Java tasks and 90 Rust tasks.\nThe results show that CatCoder outperforms the RepoCoder baseline by up to\n17.35%, in terms of pass@k score. Furthermore, the generalizability of CatCoder\nis assessed using various LLMs, including both code-specialized models and\ngeneral-purpose models. Our findings indicate consistent performance\nimprovements across all models, which underlines the practicality of CatCoder.",
      "tldr_zh": "本文提出 CatCoder，一种针对静态类型编程语言的代码生成框架，用于提升仓库级代码生成，通过整合相关代码和类型上下文来解决现有检索方法在处理多文件信息方面的局限性。具体而言，CatCoder 利用静态分析器提取类型依赖，并将其与检索代码合并，创建更全面的提示以优化 LLMs 的性能。在基准测试中，包括 199 个 Java 任务和 90 个 Rust 任务，CatCoder 相较于 RepoCoder 基准在 pass@k 分数上提高了高达 17.35%，并在各种 LLMs（如代码专用和通用模型）上显示出一致的性能改进。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03283v1",
      "published_date": "2024-06-05 13:56:42 UTC",
      "updated_date": "2024-06-05 13:56:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:30:02.630984"
    },
    {
      "arxiv_id": "2406.06589v2",
      "title": "PatentEval: Understanding Errors in Patent Generation",
      "title_zh": "翻译失败",
      "authors": [
        "You Zuo",
        "Kim Gerdes",
        "Eric Villemonte de La Clergerie",
        "Benoît Sagot"
      ],
      "abstract": "In this work, we introduce a comprehensive error typology specifically\ndesigned for evaluating two distinct tasks in machine-generated patent texts:\nclaims-to-abstract generation, and the generation of the next claim given\nprevious ones. We have also developed a benchmark, PatentEval, for\nsystematically assessing language models in this context. Our study includes a\ncomparative analysis, annotated by humans, of various models. These range from\nthose specifically adapted during training for tasks within the patent domain\nto the latest general-purpose large language models (LLMs). Furthermore, we\nexplored and evaluated some metrics to approximate human judgments in patent\ntext evaluation, analyzing the extent to which these metrics align with expert\nassessments. These approaches provide valuable insights into the capabilities\nand limitations of current language models in the specialized field of patent\ntext generation.",
      "tldr_zh": "本研究引入了一个全面的错误分类系统，用于评估机器生成专利文本的两个任务：claims-to-abstract generation 和基于前一个权利要求生成下一个。该系统还开发了PatentEval基准，以系统评估语言模型的表现，包括人类标注的比较分析，涵盖适应专利领域的专用模型和最新的通用大语言模型(LLMs)。此外，论文探索了多种评估指标，并分析了这些指标与专家判断的契合程度，提供对当前语言模型在专利文本生成领域的能力和限制的宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06589v2",
      "published_date": "2024-06-05 13:55:27 UTC",
      "updated_date": "2024-06-25 08:23:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:30:13.423738"
    },
    {
      "arxiv_id": "2406.03280v3",
      "title": "FusionBench: A Comprehensive Benchmark of Deep Model Fusion",
      "title_zh": "FusionBench: 深度模型融合的全面基准",
      "authors": [
        "Anke Tang",
        "Li Shen",
        "Yong Luo",
        "Han Hu",
        "Bo Du",
        "Dacheng Tao"
      ],
      "abstract": "Deep model fusion is an emerging technique that unifies the predictions or\nparameters of several deep neural networks into a single model in a\ncost-effective and data-efficient manner. This enables the unified model to\ntake advantage of the original models' strengths, potentially exceeding their\nperformance. Although a variety of deep model fusion techniques have been\nintroduced, their evaluations tend to be inconsistent and often inadequate to\nvalidate their effectiveness and robustness against distribution shifts. To\naddress this issue, we introduce FusionBench, which is the first comprehensive\nbenchmark dedicated to deep model fusion. FusionBench covers a wide range of\ntasks, including open-vocabulary image classification, text classification, and\ntext-to-text generation. Each category includes up to eight tasks with\ncorresponding task-specific models, featuring both full fine-tuning and LoRA\nfine-tuning, as well as models of different sizes, to ensure fair and balanced\ncomparisons of various multi-task model fusion techniques across different\ntasks, model scales, and fine-tuning strategies. We implement and evaluate a\nbroad spectrum of deep model fusion techniques. These techniques range from\nmodel ensemble methods, which combine the predictions to improve the overall\nperformance, to model merging, which integrates different models into a single\none, and model mixing methods, which upscale or recombine the components of the\noriginal models. FusionBench now contains 26 distinct tasks, 74 fine-tuned\nmodels, and 16 fusion techniques, and we are committed to consistently\nexpanding the benchmark with more tasks, models, and fusion techniques. In\naddition, we offer a well-documented set of resources and guidelines to aid\nresearchers in understanding and replicating the benchmark results. Homepage\nhttps://github.com/tanganke/fusion_bench",
      "tldr_zh": "该论文引入了 FusionBench，这是一个全面的深度模型融合基准测试，用于评估各种融合技术在不同任务中的有效性和鲁棒性。FusionBench 涵盖了 open-vocabulary image classification、text classification 和 text-to-text generation 等任务，总计 26 个任务、74 个细调模型（包括 full fine-tuning 和 LoRA fine-tuning 策略），并比较了 model ensemble、model merging 和 model mixing 等 16 种融合方法，以确保公平对比模型规模和性能。基准测试提供了详细资源和指南，支持研究者复现结果，并承诺持续扩展以包括更多任务和技术。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Project homepage: https://github.com/tanganke/fusion_bench",
      "pdf_url": "http://arxiv.org/pdf/2406.03280v3",
      "published_date": "2024-06-05 13:54:28 UTC",
      "updated_date": "2024-06-14 07:19:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:30:28.099874"
    },
    {
      "arxiv_id": "2406.03276v2",
      "title": "Revisiting Scalable Hessian Diagonal Approximations for Applications in Reinforcement Learning",
      "title_zh": "重新审视可扩展的Hessian对角近似在强化学习中的应用",
      "authors": [
        "Mohamed Elsayed",
        "Homayoon Farrahi",
        "Felix Dangel",
        "A. Rupam Mahmood"
      ],
      "abstract": "Second-order information is valuable for many applications but challenging to\ncompute. Several works focus on computing or approximating Hessian diagonals,\nbut even this simplification introduces significant additional costs compared\nto computing a gradient. In the absence of efficient exact computation schemes\nfor Hessian diagonals, we revisit an early approximation scheme proposed by\nBecker and LeCun (1989, BL89), which has a cost similar to gradients and\nappears to have been overlooked by the community. We introduce HesScale, an\nimprovement over BL89, which adds negligible extra computation. On small\nnetworks, we find that this improvement is of higher quality than all\nalternatives, even those with theoretical guarantees, such as unbiasedness,\nwhile being much cheaper to compute. We use this insight in reinforcement\nlearning problems where small networks are used and demonstrate HesScale in\nsecond-order optimization and scaling the step-size parameter. In our\nexperiments, HesScale optimizes faster than existing methods and improves\nstability through step-size scaling. These findings are promising for scaling\nsecond-order methods in larger models in the future.",
      "tldr_zh": "该论文重新审视了Hessian对角线近似的可扩展性，针对强化学习应用，引入HesScale作为对Becker和LeCun（1989，BL89）方案的改进，仅需微不足道的额外计算成本。HesScale在小网络上提供比现有方法更高的近似质量，即使超越那些具有理论保证（如无偏性）的替代方案，同时计算更高效。在强化学习实验中，HesScale加速了第二阶优化过程，并通过步长参数缩放改善了稳定性，为未来扩展第二阶方法应用于更大模型提供了前景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the Proceedings of the 41st International Conference on\n  Machine Learning (ICML 2024). Code is available at\n  https://github.com/mohmdelsayed/HesScale. arXiv admin note: substantial text\n  overlap with arXiv:2210.11639",
      "pdf_url": "http://arxiv.org/pdf/2406.03276v2",
      "published_date": "2024-06-05 13:53:20 UTC",
      "updated_date": "2024-07-03 21:22:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:30:38.519692"
    },
    {
      "arxiv_id": "2406.03274v2",
      "title": "Enhancing CTC-based speech recognition with diverse modeling units",
      "title_zh": "使用多样化建模单位增强基于CTC的语音识别",
      "authors": [
        "Shiyi Han",
        "Zhihong Lei",
        "Mingbin Xu",
        "Xingyu Na",
        "Zhen Huang"
      ],
      "abstract": "In recent years, the evolution of end-to-end (E2E) automatic speech\nrecognition (ASR) models has been remarkable, largely due to advances in deep\nlearning architectures like transformer. On top of E2E systems, researchers\nhave achieved substantial accuracy improvement by rescoring E2E model's N-best\nhypotheses with a phoneme-based model. This raises an interesting question\nabout where the improvements come from other than the system combination\neffect. We examine the underlying mechanisms driving these gains and propose an\nefficient joint training approach, where E2E models are trained jointly with\ndiverse modeling units. This methodology does not only align the strengths of\nboth phoneme and grapheme-based models but also reveals that using these\ndiverse modeling units in a synergistic way can significantly enhance model\naccuracy. Our findings offer new insights into the optimal integration of\nheterogeneous modeling units in the development of more robust and accurate ASR\nsystems.",
      "tldr_zh": "这篇论文探讨了如何通过多样化建模单位提升基于 CTC 的端到端 (E2E) 自动语音识别 (ASR) 模型的准确性，特别是分析了使用 phoneme-based 模型重新评分带来的改进机制。研究者提出了一种高效的联合训练方法，将 E2E 模型与 phoneme 和 grapheme 等异构建模单位整合，从而发挥它们的协同优势。实验结果显示，这种方法显著提高了模型准确性，并为构建更鲁棒的 ASR 系统提供了新的见解。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03274v2",
      "published_date": "2024-06-05 13:52:55 UTC",
      "updated_date": "2024-06-11 15:03:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:30:51.390265"
    },
    {
      "arxiv_id": "2406.03272v3",
      "title": "Multi-Microphone Speech Emotion Recognition using the Hierarchical Token-semantic Audio Transformer Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Ohad Cohen",
        "Gershon Hazan",
        "Sharon Gannot"
      ],
      "abstract": "The performance of most emotion recognition systems degrades in real-life\nsituations ('in the wild' scenarios) where the audio is contaminated by\nreverberation. Our study explores new methods to alleviate the performance\ndegradation of SER algorithms and develop a more robust system for adverse\nconditions. We propose processing multi-microphone signals to address these\nchallenges and improve emotion classification accuracy. We adopt a\nstate-of-the-art transformer model, the HTS-AT, to handle multi-channel audio\ninputs. We evaluate two strategies: averaging mel-spectrograms across channels\nand summing patch-embedded representations. Our multi-microphone model achieves\nsuperior performance compared to single-channel baselines when tested on\nreal-world reverberant environments.",
      "tldr_zh": "该研究针对语音情感识别(Speech Emotion Recognition, SER)系统在真实回声环境中性能下降的问题，提出了一种基于多麦克风信号处理的方法，以提升鲁棒性。研究采用先进的 Hierarchical Token-semantic Audio Transformer (HTS-AT) 模型处理多通道音频输入，并评估了两种策略：跨通道平均 mel-spectrograms 和求和 patch-embedded representations。这些方法显著提高了情感分类准确性，最终结果显示，多麦克风模型在真实回声场景下比单通道基线表现更优越。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03272v3",
      "published_date": "2024-06-05 13:50:59 UTC",
      "updated_date": "2024-09-14 20:46:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:31:00.940825"
    },
    {
      "arxiv_id": "2406.03263v1",
      "title": "Deep Generative Models for Proton Zero Degree Calorimeter Simulations in ALICE, CERN",
      "title_zh": "翻译失败",
      "authors": [
        "Patryk Będkowski",
        "Jan Dubiński",
        "Kamil Deja",
        "Przemysław Rokita"
      ],
      "abstract": "Simulating detector responses is a crucial part of understanding the\ninner-workings of particle collisions in the Large Hadron Collider at CERN. The\ncurrent reliance on statistical Monte-Carlo simulations strains CERN's\ncomputational grid, underscoring the urgency for more efficient alternatives.\nAddressing these challenges, recent proposals advocate for generative machine\nlearning methods. In this study, we present an innovative deep learning\nsimulation approach tailored for the proton Zero Degree Calorimeter in the\nALICE experiment. Leveraging a Generative Adversarial Network model with\nSelective Diversity Increase loss, we directly simulate calorimeter responses.\nTo enhance its capabilities in modeling a broad range of calorimeter response\nintensities, we expand the SDI-GAN architecture with additional regularization.\nMoreover, to improve the spatial fidelity of the generated data, we introduce\nan auxiliary regressor network. Our method offers a significant speedup when\ncomparing to the traditional Monte-Carlo based approaches.",
      "tldr_zh": "本研究针对 CERN ALICE 实验中 Proton Zero Degree Calorimeter 的模拟问题，提出了一种基于深度学习的生成模型，以取代计算密集的 Monte-Carlo 模拟方法。利用 Generative Adversarial Network (GAN) 模型结合 Selective Diversity Increase (SDI) loss，他们直接模拟了 calorimeter 响应，并通过额外正则化和辅助 regressor network 提升了模型对响应强度和空间保真度的处理能力。该方法显著加速了模拟过程，提供了一种更高效的粒子碰撞模拟替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 3 figures, PP-RAI 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2406.03263v1",
      "published_date": "2024-06-05 13:41:09 UTC",
      "updated_date": "2024-06-05 13:41:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:31:14.367295"
    },
    {
      "arxiv_id": "2406.03251v1",
      "title": "ASoBO: Attentive Beamformer Selection for Distant Speaker Diarization in Meetings",
      "title_zh": "翻译失败",
      "authors": [
        "Theo Mariotte",
        "Anthony Larcher",
        "Silvio Montresor",
        "Jean-Hugh Thomas"
      ],
      "abstract": "Speaker Diarization (SD) aims at grouping speech segments that belong to the\nsame speaker. This task is required in many speech-processing applications,\nsuch as rich meeting transcription. In this context, distant microphone arrays\nusually capture the audio signal. Beamforming, i.e., spatial filtering, is a\ncommon practice to process multi-microphone audio data. However, it often\nrequires an explicit localization of the active source to steer the filter.\nThis paper proposes a self-attention-based algorithm to select the output of a\nbank of fixed spatial filters. This method serves as a feature extractor for\njoint Voice Activity (VAD) and Overlapped Speech Detection (OSD). The speaker\ndiarization is then inferred from the detected segments. The approach shows\nconvincing distant VAD, OSD, and SD performance, e.g. 14.5% DER on the\nAISHELL-4 dataset. The analysis of the self-attention weights demonstrates\ntheir explainability, as they correlate with the speaker's angular locations.",
      "tldr_zh": "本研究提出ASoBO，一种基于自注意力的算法，用于会议中远距离说话者识别(Speaker Diarization, SD)。该方法从一组固定空间过滤器(Beamforming)输出中选择最佳特征，作为联合语音活动检测(Voice Activity Detection, VAD)和重叠语音检测(Overlapped Speech Detection, OSD)的提取器，从而推断说话者段落。实验结果显示，ASoBO在AISHELL-4数据集上实现了14.5%的DER性能提升，且自注意力权重具有可解释性，与说话者角度位置相关。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 2 figures, 2 tables, accepted at Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03251v1",
      "published_date": "2024-06-05 13:28:28 UTC",
      "updated_date": "2024-06-05 13:28:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:31:26.469795"
    },
    {
      "arxiv_id": "2406.03250v1",
      "title": "Prompt-based Visual Alignment for Zero-shot Policy Transfer",
      "title_zh": "基于提示的视觉对齐用于零样本策略转移",
      "authors": [
        "Haihan Gao",
        "Rui Zhang",
        "Qi Yi",
        "Hantao Yao",
        "Haochen Li",
        "Jiaming Guo",
        "Shaohui Peng",
        "Yunkai Gao",
        "QiCheng Wang",
        "Xing Hu",
        "Yuanbo Wen",
        "Zihao Zhang",
        "Zidong Du",
        "Ling Li",
        "Qi Guo",
        "Yunji Chen"
      ],
      "abstract": "Overfitting in RL has become one of the main obstacles to applications in\nreinforcement learning(RL). Existing methods do not provide explicit semantic\nconstrain for the feature extractor, hindering the agent from learning a\nunified cross-domain representation and resulting in performance degradation on\nunseen domains. Besides, abundant data from multiple domains are needed. To\naddress these issues, in this work, we propose prompt-based visual alignment\n(PVA), a robust framework to mitigate the detrimental domain bias in the image\nfor zero-shot policy transfer. Inspired that Visual-Language Model (VLM) can\nserve as a bridge to connect both text space and image space, we leverage the\nsemantic information contained in a text sequence as an explicit constraint to\ntrain a visual aligner. Thus, the visual aligner can map images from multiple\ndomains to a unified domain and achieve good generalization performance. To\nbetter depict semantic information, prompt tuning is applied to learn a\nsequence of learnable tokens. With explicit constraints of semantic\ninformation, PVA can learn unified cross-domain representation under limited\naccess to cross-domain data and achieves great zero-shot generalization ability\nin unseen domains. We verify PVA on a vision-based autonomous driving task with\nCARLA simulator. Experiments show that the agent generalizes well on unseen\ndomains under limited access to multi-domain data.",
      "tldr_zh": "本研究针对强化学习（Reinforcement Learning, RL）中的过拟合问题，提出了一种Prompt-based Visual Alignment (PVA)框架，以实现零样本策略转移（Zero-shot Policy Transfer）。PVA利用Visual-Language Model (VLM)作为桥梁，通过文本序列的语义信息作为显式约束训练视觉对齐器，并应用Prompt Tuning来学习可学习的标记序列，从而将多域图像映射到统一的域表示。实验在CARLA模拟器的视觉-based自动驾驶任务上验证了PVA，在有限的跨域数据访问下，实现了优秀的零样本泛化性能，显著缓解了域偏差问题。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted by ICML2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03250v1",
      "published_date": "2024-06-05 13:26:30 UTC",
      "updated_date": "2024-06-05 13:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:31:43.105571"
    },
    {
      "arxiv_id": "2406.03245v2",
      "title": "Reconfiguring Participatory Design to Resist AI Realism",
      "title_zh": "重新配置参与式设计以抵抗 AI 现实主义",
      "authors": [
        "Aakash Gautam"
      ],
      "abstract": "The growing trend of artificial intelligence (AI) as a solution to social and\ntechnical problems reinforces AI Realism -- the belief that AI is an inevitable\nand natural order. In response, this paper argues that participatory design\n(PD), with its focus on democratic values and processes, can play a role in\nquestioning and resisting AI Realism. I examine three concerning aspects of AI\nRealism: the facade of democratization that lacks true empowerment, demands for\nhuman adaptability in contrast to AI systems' inflexibility, and the\nobfuscation of essential human labor enabling the AI system. I propose\nresisting AI Realism by reconfiguring PD to continue engaging with\nvalue-centered visions, increasing its exploration of non-AI alternatives, and\nmaking the essential human labor underpinning AI systems visible. I position PD\nas a means to generate friction against AI Realism and open space for\nalternative futures centered on human needs and values.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）被视为社会和技术问题的自然解决方案如何强化AI Realism（AI现实主义），即AI被视为不可避免的秩序，并主张通过Participatory Design (PD)来质疑和抵抗这一趋势。论文分析了AI Realism的三个关键问题：AI的民主化假象（缺乏真正赋权）、要求人类适应AI系统的刚性，以及掩盖AI系统背后的人类劳动。作者提出重新配置PD，包括继续推动以价值为中心的愿景、增加对非AI替代方案的探索，以及使AI系统的核心人类劳动可见，从而将PD定位为对抗AI Realism的工具，为以人类需求和价值观为导向的未来开辟空间。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.HC",
      "comment": "6 pages, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2406.03245v2",
      "published_date": "2024-06-05 13:21:46 UTC",
      "updated_date": "2024-06-08 18:19:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:31:54.395903"
    },
    {
      "arxiv_id": "2406.03240v2",
      "title": "Generalized Source Tracing: Detecting Novel Audio Deepfake Algorithm with Real Emphasis and Fake Dispersion Strategy",
      "title_zh": "翻译失败",
      "authors": [
        "Yuankun Xie",
        "Ruibo Fu",
        "Zhengqi Wen",
        "Zhiyong Wang",
        "Xiaopeng Wang",
        "Haonnan Cheng",
        "Long Ye",
        "Jianhua Tao"
      ],
      "abstract": "With the proliferation of deepfake audio, there is an urgent need to\ninvestigate their attribution. Current source tracing methods can effectively\ndistinguish in-distribution (ID) categories. However, the rapid evolution of\ndeepfake algorithms poses a critical challenge in the accurate identification\nof out-of-distribution (OOD) novel deepfake algorithms. In this paper, we\npropose Real Emphasis and Fake Dispersion (REFD) strategy for audio deepfake\nalgorithm recognition, demonstrating its effectiveness in discriminating ID\nsamples while identifying OOD samples. For effective OOD detection, we first\nexplore current post-hoc OOD methods and propose NSD, a novel OOD approach in\nidentifying novel deepfake algorithms through the similarity consideration of\nboth feature and logits scores. REFD achieves 86.83% F1-score as a single\nsystem in Audio Deepfake Detection Challenge 2023 Track3, showcasing its\nstate-of-the-art performance.",
      "tldr_zh": "该论文针对音频深度伪造算法的快速演变，提出了一种Generalized Source Tracing方法，利用Real Emphasis and Fake Dispersion (REFD)策略来区分in-distribution (ID)样本并识别out-of-distribution (OOD)新型算法。REFD结合了新的OOD检测方法NSD，通过分析特征和logits分数的相似性，提高了对未知深度伪造算法的识别准确性。实验结果显示，该方法在Audio Deepfake Detection Challenge 2023 Track3中取得了86.83%的F1-score，超越了现有基线模型。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by INTERSPEECH 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03240v2",
      "published_date": "2024-06-05 13:16:55 UTC",
      "updated_date": "2024-06-09 03:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:32:04.554254"
    },
    {
      "arxiv_id": "2406.03235v1",
      "title": "Error-preserving Automatic Speech Recognition of Young English Learners' Language",
      "title_zh": "翻译失败",
      "authors": [
        "Janick Michot",
        "Manuela Hürlimann",
        "Jan Deriu",
        "Luzia Sauer",
        "Katsiaryna Mlynchyk",
        "Mark Cieliebak"
      ],
      "abstract": "One of the central skills that language learners need to practice is speaking\nthe language. Currently, students in school do not get enough speaking\nopportunities and lack conversational practice. Recent advances in speech\ntechnology and natural language processing allow for the creation of novel\ntools to practice their speaking skills. In this work, we tackle the first\ncomponent of such a pipeline, namely, the automated speech recognition module\n(ASR), which faces a number of challenges: first, state-of-the-art ASR models\nare often trained on adult read-aloud data by native speakers and do not\ntransfer well to young language learners' speech. Second, most ASR systems\ncontain a powerful language model, which smooths out errors made by the\nspeakers. To give corrective feedback, which is a crucial part of language\nlearning, the ASR systems in our setting need to preserve the errors made by\nthe language learners. In this work, we build an ASR system that satisfies\nthese requirements: it works on spontaneous speech by young language learners\nand preserves their errors. For this, we collected a corpus containing around\n85 hours of English audio spoken by learners in Switzerland from grades 4 to 6\non different language learning tasks, which we used to train an ASR model. Our\nexperiments show that our model benefits from direct fine-tuning on children's\nvoices and has a much higher error preservation rate than other models.",
      "tldr_zh": "本研究针对年轻英语学习者的口语练习需求，开发了一种错误保留型 Automatic Speech Recognition (ASR) 系统，以克服现有ASR模型在处理儿童自发语音时的适应性差和错误修正问题。该系统通过收集约85小时的瑞士4-6年级英语学习者音频语料，并对ASR模型进行直接 fine-tuning，实现了对学习者语音的精确识别，同时保留了他们的语言错误以提供 corrective feedback。实验结果显示，该模型在儿童语音上表现优于基线模型，错误保留率显著提高，为语言学习工具的创新提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ACL 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2406.03235v1",
      "published_date": "2024-06-05 13:15:37 UTC",
      "updated_date": "2024-06-05 13:15:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:32:15.809686"
    },
    {
      "arxiv_id": "2406.03234v1",
      "title": "Fine-Grained Causal Dynamics Learning with Quantization for Improving Robustness in Reinforcement Learning",
      "title_zh": "细粒度因果动态学习结合量化以提高强化学习中的鲁棒性",
      "authors": [
        "Inwoo Hwang",
        "Yunhyeok Kwak",
        "Suhyung Choi",
        "Byoung-Tak Zhang",
        "Sanghack Lee"
      ],
      "abstract": "Causal dynamics learning has recently emerged as a promising approach to\nenhancing robustness in reinforcement learning (RL). Typically, the goal is to\nbuild a dynamics model that makes predictions based on the causal relationships\namong the entities. Despite the fact that causal connections often manifest\nonly under certain contexts, existing approaches overlook such fine-grained\nrelationships and lack a detailed understanding of the dynamics. In this work,\nwe propose a novel dynamics model that infers fine-grained causal structures\nand employs them for prediction, leading to improved robustness in RL. The key\nidea is to jointly learn the dynamics model with a discrete latent variable\nthat quantizes the state-action space into subgroups. This leads to recognizing\nmeaningful context that displays sparse dependencies, where causal structures\nare learned for each subgroup throughout the training. Experimental results\ndemonstrate the robustness of our method to unseen states and locally spurious\ncorrelations in downstream tasks where fine-grained causal reasoning is\ncrucial. We further illustrate the effectiveness of our subgroup-based approach\nwith quantization in discovering fine-grained causal relationships compared to\nprior methods.",
      "tldr_zh": "这篇论文提出了一种新的动态模型，用于提升Reinforcement Learning的鲁棒性，通过学习细粒度的因果关系来处理特定上下文下的稀疏依赖。核心方法是将状态-动作空间使用Quantization技术量化成子群，并联合学习动态模型和离散潜变量，从而为每个子群推断和应用因果结构。实验结果表明，该方法在下游任务中对未见状态和局部虚假相关表现出色，并比现有方法更有效地发现细粒度因果关系。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03234v1",
      "published_date": "2024-06-05 13:13:58 UTC",
      "updated_date": "2024-06-05 13:13:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:32:28.469170"
    },
    {
      "arxiv_id": "2406.03229v4",
      "title": "Global Clipper: Enhancing Safety and Reliability of Transformer-based Object Detection Models",
      "title_zh": "Global Clipper：增强基于 Transformer 的目标检测模型的安全性和可靠性",
      "authors": [
        "Qutub Syed Sha",
        "Michael Paulitsch",
        "Karthik Pattabiraman",
        "Korbinian Hagn",
        "Fabian Oboril",
        "Cornelius Buerkle",
        "Kay-Ulrich Scholl",
        "Gereon Hinz",
        "Alois Knoll"
      ],
      "abstract": "As transformer-based object detection models progress, their impact in\ncritical sectors like autonomous vehicles and aviation is expected to grow.\nSoft errors causing bit flips during inference have significantly impacted DNN\nperformance, altering predictions. Traditional range restriction solutions for\nCNNs fall short for transformers. This study introduces the Global Clipper and\nGlobal Hybrid Clipper, effective mitigation strategies specifically designed\nfor transformer-based models. It significantly enhances their resilience to\nsoft errors and reduces faulty inferences to ~ 0\\%. We also detail extensive\ntesting across over 64 scenarios involving two transformer models (DINO-DETR\nand Lite-DETR) and two CNN models (YOLOv3 and SSD) using three datasets,\ntotalling approximately 3.3 million inferences, to assess model robustness\ncomprehensively. Moreover, the paper explores unique aspects of attention\nblocks in transformers and their operational differences from CNNs.",
      "tldr_zh": "该研究针对 Transformer-based object detection 模型在自动驾驶和航空等关键领域面临的 soft errors 问题，引入了 Global Clipper 和 Global Hybrid Clipper 作为新的缓解策略，以增强模型的安全性和可靠性。\n这些策略专门设计用于 Transformers，能显著提高对位翻转的抵抗力，将错误推理减少到约 0%。\n通过在超过 64 个场景中测试 DINO-DETR、Lite-DETR 等模型，以及 YOLOv3 和 SSD 等 CNN 模型，总计约 330 万次推理，实验证明了其鲁棒性提升。\n此外，论文探讨了 Transformers 中注意力块的独特特性及其与 CNNs 的操作差异，为模型可靠性提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at IJCAI-AISafety'24 Workshop",
      "pdf_url": "http://arxiv.org/pdf/2406.03229v4",
      "published_date": "2024-06-05 13:06:17 UTC",
      "updated_date": "2024-07-09 10:23:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:32:41.987738"
    },
    {
      "arxiv_id": "2407.16886v1",
      "title": "GPT-4's One-Dimensional Mapping of Morality: How the Accuracy of Country-Estimates Depends on Moral Domain",
      "title_zh": "翻译失败",
      "authors": [
        "Pontus Strimling",
        "Joel Krueger",
        "Simon Karlsson"
      ],
      "abstract": "Prior research demonstrates that Open AI's GPT models can predict variations\nin moral opinions between countries but that the accuracy tends to be\nsubstantially higher among high-income countries compared to low-income ones.\nThis study aims to replicate previous findings and advance the research by\nexamining how accuracy varies with different types of moral questions. Using\nresponses from the World Value Survey and the European Value Study, covering 18\nmoral issues across 63 countries, we calculated country-level mean scores for\neach moral issue and compared them with GPT-4's predictions. Confirming\nprevious findings, our results show that GPT-4 has greater predictive success\nin high-income than in low-income countries. However, our factor analysis\nreveals that GPT-4 bases its predictions primarily on a single dimension,\npresumably reflecting countries' degree of conservatism/liberalism. Conversely,\nthe real-world moral landscape appears to be two-dimensional, differentiating\nbetween personal-sexual and violent-dishonest issues. When moral issues are\ncategorized based on their moral domain, GPT-4's predictions are found to be\nremarkably accurate in the personal-sexual domain, across both high-income (r =\n.77) and low-income (r = .58) countries. Yet the predictive accuracy\nsignificantly drops in the violent-dishonest domain for both high-income (r =\n.30) and low-income (r = -.16) countries, indicating that GPT-4's\none-dimensional world-view does not fully capture the complexity of the moral\nlandscape. In sum, this study underscores the importance of not only\nconsidering country-specific characteristics to understand GPT-4's moral\nunderstanding, but also the characteristics of the moral issues at hand.",
      "tldr_zh": "本研究考察了 GPT-4 在预测不同国家道德意见时的准确性，特别分析了它在高收入国家表现更好，而低收入国家较差的现象。研究利用 World Value Survey 和 European Value Study 的数据，对 63 个国家的 18 个道德问题进行因子分析，发现 GPT-4 的预测主要基于一个维度（presumably 反映保守/自由主义），而现实道德景观是二维的，包括 personal-sexual 和 violent-dishonest 领域。在 personal-sexual 领域，GPT-4 的预测准确性较高（高收入国家 r = .77，低收入国家 r = .58），但在 violent-dishonest 领域显著下降（高收入国家 r = .30，低收入国家 r = -.16）。总之，这强调了在评估 GPT-4 的道德理解时，需要同时考虑国家特性和道德问题类型。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.16886v1",
      "published_date": "2024-06-05 12:58:45 UTC",
      "updated_date": "2024-06-05 12:58:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:32:54.155295"
    },
    {
      "arxiv_id": "2406.03216v1",
      "title": "Choice of PEFT Technique in Continual Learning: Prompt Tuning is Not All You Need",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Wistuba",
        "Prabhu Teja Sivaprasad",
        "Lukas Balles",
        "Giovanni Zappella"
      ],
      "abstract": "Recent Continual Learning (CL) methods have combined pretrained Transformers\nwith prompt tuning, a parameter-efficient fine-tuning (PEFT) technique. We\nargue that the choice of prompt tuning in prior works was an undefended and\nunablated decision, which has been uncritically adopted by subsequent research,\nbut warrants further research to understand its implications. In this paper, we\nconduct this research and find that the choice of prompt tuning as a PEFT\nmethod hurts the overall performance of the CL system. To illustrate this, we\nreplace prompt tuning with LoRA in two state-of-the-art continual learning\nmethods: Learning to Prompt and S-Prompts. These variants consistently achieve\nhigher accuracy across a wide range of domain-incremental and class-incremental\nbenchmarks, while being competitive in inference speed. Our work highlights a\ncrucial argument: unexamined choices can hinder progress in the field, and\nrigorous ablations, such as the PEFT method, are required to drive meaningful\nadoption of CL techniques in real-world applications.",
      "tldr_zh": "本文质疑了在 Continual Learning (CL) 中使用 prompt tuning 作为 parameter-efficient fine-tuning (PEFT) 技术的默认选择，认为这一选择未经充分验证且会降低系统整体性能。作者通过将 prompt tuning 替换为 LoRA 在两个先进 CL 方法（Learning to Prompt 和 S-Prompts）中进行实验，发现这些变体在 domain-incremental 和 class-incremental 基准上实现了更高的准确率，同时在推理速度上保持竞争力。研究强调，未经检验的技术选择可能阻碍领域进步，呼吁进行严格的消融实验来推动 CL 技术在实际应用中的采用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03216v1",
      "published_date": "2024-06-05 12:53:37 UTC",
      "updated_date": "2024-06-05 12:53:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:33:05.297789"
    },
    {
      "arxiv_id": "2406.03209v1",
      "title": "Challenges and Considerations in the Evaluation of Bayesian Causal Discovery",
      "title_zh": "贝叶斯因果发现评估中的挑战与考虑",
      "authors": [
        "Amir Mohammad Karimi Mamaghan",
        "Panagiotis Tigas",
        "Karl Henrik Johansson",
        "Yarin Gal",
        "Yashas Annadani",
        "Stefan Bauer"
      ],
      "abstract": "Representing uncertainty in causal discovery is a crucial component for\nexperimental design, and more broadly, for safe and reliable causal decision\nmaking. Bayesian Causal Discovery (BCD) offers a principled approach to\nencapsulating this uncertainty. Unlike non-Bayesian causal discovery, which\nrelies on a single estimated causal graph and model parameters for assessment,\nevaluating BCD presents challenges due to the nature of its inferred quantity -\nthe posterior distribution. As a result, the research community has proposed\nvarious metrics to assess the quality of the approximate posterior. However,\nthere is, to date, no consensus on the most suitable metric(s) for evaluation.\nIn this work, we reexamine this question by dissecting various metrics and\nunderstanding their limitations. Through extensive empirical evaluation, we\nfind that many existing metrics fail to exhibit a strong correlation with the\nquality of approximation to the true posterior, especially in scenarios with\nlow sample sizes where BCD is most desirable. We highlight the suitability (or\nlack thereof) of these metrics under two distinct factors: the identifiability\nof the underlying causal model and the quantity of available data. Both factors\naffect the entropy of the true posterior, indicating that the current metrics\nare less fitting in settings of higher entropy. Our findings underline the\nimportance of a more nuanced evaluation of new methods by taking into account\nthe nature of the true posterior, as well as guide and motivate the development\nof new evaluation procedures for this challenge.",
      "tldr_zh": "本论文探讨了评估Bayesian Causal Discovery (BCD) 的挑战，强调了后验分布的不确定性对实验设计和因果决策的重要性。作者通过分析现有评估指标的局限性，并进行广泛实证评估，发现这些指标在低样本量场景下与真实后验分布逼近质量的相关性较弱，且受因果模型的可识别性和数据量影响，导致高熵情境下评估不适用。研究呼吁开发更细致的评估方法，以更好地适应后验分布的特性，并指导未来BCD方法的改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03209v1",
      "published_date": "2024-06-05 12:45:23 UTC",
      "updated_date": "2024-06-05 12:45:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:33:17.088155"
    },
    {
      "arxiv_id": "2406.03202v2",
      "title": "ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction",
      "title_zh": "翻译失败",
      "authors": [
        "Jeiyoon Park",
        "Chanjun Park",
        "Heuiseok Lim"
      ],
      "abstract": "We explore and improve the capabilities of LLMs to generate data for\ngrammatical error correction (GEC). When merely producing parallel sentences,\ntheir patterns are too simplistic to be valuable as a corpus. To address this\nissue, we propose an automated framework that includes a Subject Selector,\nGrammar Selector, Prompt Manager, and Evaluator. Additionally, we introduce a\nnew dataset for GEC tasks, named ChatLang-8, which encompasses eight types of\nsubject nouns and 23 types of grammar. It consists of 1 million pairs featuring\nhuman-like grammatical errors. Our experiments reveal that ChatLang-8 exhibits\na more uniform pattern composition compared to existing GEC datasets.\nFurthermore, we observe improved model performance when using ChatLang-8\ninstead of existing GEC datasets. The experimental results suggest that our\nframework and ChatLang-8 are valuable resources for enhancing ChatGPT's data\ngeneration capabilities.",
      "tldr_zh": "本研究探索大型语言模型 (LLMs) 在生成语法错误修正 (GEC) 数据方面的能力，并提出一个自动化框架，包括 Subject Selector、Grammar Selector、Prompt Manager 和 Evaluator，以解决LLMs生成模式过于简单的问题。框架用于创建新数据集ChatLang-8，该数据集涵盖八种主语名词和23种语法类型，共包含1百万对人像语法错误句子，并显示出比现有GEC数据集更均匀的模式组成。实验结果表明，使用ChatLang-8训练模型可提升性能，并为提升ChatGPT的数据生成能力提供宝贵资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2406.03202v2",
      "published_date": "2024-06-05 12:35:00 UTC",
      "updated_date": "2024-06-11 07:06:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:33:27.963875"
    },
    {
      "arxiv_id": "2406.06588v1",
      "title": "Assessing the Emergent Symbolic Reasoning Abilities of Llama Large Language Models",
      "title_zh": "评估 Llama 大语言模型的涌现符号推理能力",
      "authors": [
        "Flavio Petruzzellis",
        "Alberto Testolin",
        "Alessandro Sperduti"
      ],
      "abstract": "Large Language Models (LLMs) achieve impressive performance in a wide range\nof tasks, even if they are often trained with the only objective of chatting\nfluently with users. Among other skills, LLMs show emergent abilities in\nmathematical reasoning benchmarks, which can be elicited with appropriate\nprompting methods. In this work, we systematically investigate the capabilities\nand limitations of popular open-source LLMs on different symbolic reasoning\ntasks. We evaluate three models of the Llama 2 family on two datasets that\nrequire solving mathematical formulas of varying degrees of difficulty. We test\na generalist LLM (Llama 2 Chat) as well as two fine-tuned versions of Llama 2\n(MAmmoTH and MetaMath) specifically designed to tackle mathematical problems.\nWe observe that both increasing the scale of the model and fine-tuning it on\nrelevant tasks lead to significant performance gains. Furthermore, using\nfine-grained evaluation measures, we find that such performance gains are\nmostly observed with mathematical formulas of low complexity, which\nnevertheless often remain challenging even for the largest fine-tuned models.",
      "tldr_zh": "这篇论文评估了 Llama 系列大型语言模型 (LLMs) 在符号推理任务中的新兴能力，特别是数学推理。研究团队测试了 Llama 2 Chat 模型以及针对数学问题微调的 MAmmoTH 和 MetaMath 模型，使用两个数据集来解决不同难度的数学公式。结果表明，增大模型规模和进行相关任务微调能显著提升性能，但这种提升主要限于低复杂度公式，而高复杂度公式对最大模型仍具挑战。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at 33rd International Conference on Artificial Neural\n  Networks (ICANN24)",
      "pdf_url": "http://arxiv.org/pdf/2406.06588v1",
      "published_date": "2024-06-05 12:22:43 UTC",
      "updated_date": "2024-06-05 12:22:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:33:41.885714"
    },
    {
      "arxiv_id": "2406.03188v1",
      "title": "Situation Monitor: Diversity-Driven Zero-Shot Out-of-Distribution Detection using Budding Ensemble Architecture for Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Qutub Syed",
        "Michael Paulitsch",
        "Korbinian Hagn",
        "Neslihan Kose Cihangir",
        "Kay-Ulrich Scholl",
        "Fabian Oboril",
        "Gereon Hinz",
        "Alois Knoll"
      ],
      "abstract": "We introduce Situation Monitor, a novel zero-shot Out-of-Distribution (OOD)\ndetection approach for transformer-based object detection models to enhance\nreliability in safety-critical machine learning applications such as autonomous\ndriving. The Situation Monitor utilizes the Diversity-based Budding Ensemble\nArchitecture (DBEA) and increases the OOD performance by integrating a\ndiversity loss into the training process on top of the budding ensemble\narchitecture, detecting Far-OOD samples and minimizing false positives on\nNear-OOD samples. Moreover, utilizing the resulting DBEA increases the model's\nOOD performance and improves the calibration of confidence scores, particularly\nconcerning the intersection over union of the detected objects. The DBEA model\nachieves these advancements with a 14% reduction in trainable parameters\ncompared to the vanilla model. This signifies a substantial improvement in\nefficiency without compromising the model's ability to detect OOD instances and\ncalibrate the confidence scores accurately.",
      "tldr_zh": "本文提出 Situation Monitor，一种基于 Diversity-based Budding Ensemble Architecture (DBEA) 的零样本 Out-of-Distribution (OOD) 检测方法，旨在提升 Transformer 基于物体检测模型在安全关键应用（如自动驾驶）中的可靠性。该方法通过在训练过程中整合 diversity loss 到 budding ensemble 架构中，实现对 Far-OOD 样本的有效检测，同时最小化 Near-OOD 样本的假阳性，并改善检测物体的置信度校准，尤其是与 Intersection over Union (IoU) 相关。相比原模型，DBEA 减少了 14% 的可训练参数，同时显著提高了 OOD 性能和整体效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Paper accepted at CVPR SAIAD Workshop",
      "pdf_url": "http://arxiv.org/pdf/2406.03188v1",
      "published_date": "2024-06-05 12:20:36 UTC",
      "updated_date": "2024-06-05 12:20:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:33:54.772295"
    },
    {
      "arxiv_id": "2406.03158v1",
      "title": "CSS: Contrastive Semantic Similarity for Uncertainty Quantification of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Shuang Ao",
        "Stefan Rueger",
        "Advaith Siddharthan"
      ],
      "abstract": "Despite the impressive capability of large language models (LLMs), knowing\nwhen to trust their generations remains an open challenge. The recent\nliterature on uncertainty quantification of natural language generation (NLG)\nutilises a conventional natural language inference (NLI) classifier to measure\nthe semantic dispersion of LLMs responses. These studies employ logits of NLI\nclassifier for semantic clustering to estimate uncertainty. However, logits\nrepresent the probability of the predicted class and barely contain feature\ninformation for potential clustering. Alternatively, CLIP (Contrastive\nLanguage-Image Pre-training) performs impressively in extracting image-text\npair features and measuring their similarity. To extend its usability, we\npropose Contrastive Semantic Similarity, the CLIP-based feature extraction\nmodule to obtain similarity features for measuring uncertainty for text pairs.\nWe apply this method to selective NLG, which detects and rejects unreliable\ngenerations for better trustworthiness of LLMs. We conduct extensive\nexperiments with three LLMs on several benchmark question-answering datasets\nwith comprehensive evaluation metrics. Results show that our proposed method\nperforms better in estimating reliable responses of LLMs than comparable\nbaselines. Results show that our proposed method performs better in estimating\nreliable responses of LLMs than comparable baselines. The code are available at\n\\url{https://github.com/AoShuang92/css_uq_llms}.",
      "tldr_zh": "该论文针对大型语言模型（LLMs）的生成不确定性问题，提出了一种Contrastive Semantic Similarity (CSS)方法，利用CLIP的特征提取模块来测量文本对的语义相似性，从而更准确地量化不确定性。相比传统使用NLI分类器基于logits的聚类方法，CSS通过提取丰富的相似性特征，提升了不确定性估计的可靠性，并应用于selective NLG中，以检测和拒绝不可靠的生成。实验在多个LLMs和基准问答数据集上显示，CSS在全面评估指标中优于基线方法，提高了LLMs响应的可信度。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The paper is accepted by The Conference on Uncertainty in Artificial\n  Intelligence (UAI), 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03158v1",
      "published_date": "2024-06-05 11:35:44 UTC",
      "updated_date": "2024-06-05 11:35:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:34:05.009013"
    },
    {
      "arxiv_id": "2406.03154v2",
      "title": "Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks: An Extended Investigation",
      "title_zh": "翻译失败",
      "authors": [
        "Marvin Schmitt",
        "Paul-Christian Bürkner",
        "Ullrich Köthe",
        "Stefan T. Radev"
      ],
      "abstract": "Recent advances in probabilistic deep learning enable efficient amortized\nBayesian inference in settings where the likelihood function is only implicitly\ndefined by a simulation program (simulation-based inference; SBI). But how\nfaithful is such inference if the simulation represents reality somewhat\ninaccurately, that is, if the true system behavior at test time deviates from\nthe one seen during training? We conceptualize the types of such model\nmisspecification arising in SBI and systematically investigate how the\nperformance of neural posterior approximators gradually deteriorates as a\nconsequence, making inference results less and less trustworthy. To notify\nusers about this problem, we propose a new misspecification measure that can be\ntrained in an unsupervised fashion (i.e., without training data from the true\ndistribution) and reliably detects model misspecification at test time. Our\nexperiments clearly demonstrate the utility of our new measure both on toy\nexamples with an analytical ground-truth and on representative scientific tasks\nin cell biology, cognitive decision making, disease outbreak dynamics, and\ncomputer vision. We show how the proposed misspecification test warns users\nabout suspicious outputs, raises an alarm when predictions are not trustworthy,\nand guides model designers in their search for better simulators.",
      "tldr_zh": "该研究探讨了在模拟-based inference (SBI) 中，当模型 misspecification 发生时，amortized Bayesian inference with neural networks 的性能问题，通过系统调查其逐步恶化过程。作者提出了一种新的 unsupervised misspecification 度量，能够在测试时检测模型偏差，而无需真实分布的训练数据。实验在玩具模型和实际科学任务（如细胞生物学、认知决策、疾病爆发动态及计算机视觉）中验证了该度量的有效性，帮助用户识别不可信预测并指导模拟器优化。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Extended version of the conference paper\n  https://doi.org/10.1007/978-3-031-54605-1_35. arXiv admin note: text overlap\n  with arXiv:2112.08866",
      "pdf_url": "http://arxiv.org/pdf/2406.03154v2",
      "published_date": "2024-06-05 11:30:16 UTC",
      "updated_date": "2024-06-06 12:58:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:34:16.813932"
    },
    {
      "arxiv_id": "2406.03136v1",
      "title": "Computational Limits of Low-Rank Adaptation (LoRA) for Transformer-Based Models",
      "title_zh": "基于Transformer模型的低秩适配 (LoRA) 计算极限",
      "authors": [
        "Jerry Yao-Chieh Hu",
        "Maojiang Su",
        "En-Jui Kuo",
        "Zhao Song",
        "Han Liu"
      ],
      "abstract": "We study the computational limits of Low-Rank Adaptation (LoRA) update for\nfinetuning transformer-based models using fine-grained complexity theory. Our\nkey observation is that the existence of low-rank decompositions within the\ngradient computation of LoRA adaptation leads to possible algorithmic speedup.\nThis allows us to (i) identify a phase transition behavior and (ii) prove the\nexistence of nearly linear algorithms by controlling the LoRA update\ncomputation term by term, assuming the Strong Exponential Time Hypothesis\n(SETH). For the former, we identify a sharp transition in the efficiency of all\npossible rank-$r$ LoRA update algorithms for transformers, based on specific\nnorms resulting from the multiplications of the input sequence $\\mathbf{X}$,\npretrained weights $\\mathbf{W^\\star}$, and adapter matrices $\\alpha \\mathbf{B}\n\\mathbf{A} / r$. Specifically, we derive a shared upper bound threshold for\nsuch norms and show that efficient (sub-quadratic) approximation algorithms of\nLoRA exist only below this threshold. For the latter, we prove the existence of\nnearly linear approximation algorithms for LoRA adaptation by utilizing the\nhierarchical low-rank structures of LoRA gradients and approximating the\ngradients with a series of chained low-rank approximations. To showcase our\ntheory, we consider two practical scenarios: partial (e.g., only $\\mathbf{W}_V$\nand $\\mathbf{W}_Q$) and full adaptations (e.g., $\\mathbf{W}_Q$, $\\mathbf{W}_V$,\nand $\\mathbf{W}_K$) of weights in attention heads.",
      "tldr_zh": "本文研究了 Low-Rank Adaptation (LoRA) 在微调 Transformer 模型时的计算限制，使用细粒度复杂性理论分析其梯度计算中的低秩分解，以探索可能的算法加速。关键贡献包括识别算法效率的相变行为，即基于输入序列 $\\mathbf{X}$、预训练权重 $\\mathbf{W^\\star}$ 和适配器矩阵的特定规范，存在一个上界阈值，只有低于此阈值时才可能实现子二次近似算法。作者进一步证明，在 Strong Exponential Time Hypothesis (SETH) 的假设下，通过利用 LoRA 梯度的层次低秩结构，可以开发出近线性近似算法。实验场景涵盖了注意力头的部分适应（如 $\\mathbf{W}_V$ 和 $\\mathbf{W}_Q$）和全适应（如 $\\mathbf{W}_Q$、$\\mathbf{W}_V$ 和 $\\mathbf{W}_K$），为优化 LoRA 计算效率提供了理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03136v1",
      "published_date": "2024-06-05 10:44:08 UTC",
      "updated_date": "2024-06-05 10:44:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:34:32.821542"
    },
    {
      "arxiv_id": "2406.03512v3",
      "title": "Harder or Different? Understanding Generalization of Audio Deepfake Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolas M. Müller",
        "Nicholas Evans",
        "Hemlata Tak",
        "Philip Sperl",
        "Konstantin Böttinger"
      ],
      "abstract": "Recent research has highlighted a key issue in speech deepfake detection:\nmodels trained on one set of deepfakes perform poorly on others. The question\narises: is this due to the continuously improving quality of Text-to-Speech\n(TTS) models, i.e., are newer DeepFakes just 'harder' to detect? Or, is it\nbecause deepfakes generated with one model are fundamentally different to those\ngenerated using another model? We answer this question by decomposing the\nperformance gap between in-domain and out-of-domain test data into 'hardness'\nand 'difference' components. Experiments performed using ASVspoof databases\nindicate that the hardness component is practically negligible, with the\nperformance gap being attributed primarily to the difference component. This\nhas direct implications for real-world deepfake detection, highlighting that\nmerely increasing model capacity, the currently-dominant research trend, may\nnot effectively address the generalization challenge.",
      "tldr_zh": "这篇论文探讨了音频深度伪造检测模型的泛化问题，即模型在不同数据集上表现不佳的原因：是由于Text-to-Speech (TTS)模型不断改进使新DeepFakes变得“harder”检测，还是因为不同模型生成的DeepFakes本质上“different”。作者通过将性能差距分解为hardness（难度）和difference（差异）组件，并使用ASVspoof数据库进行实验，发现hardness组件几乎可以忽略，而difference组件是主要因素。研究结果表明，当前主流的增加模型容量策略可能无法有效解决泛化挑战，为真实世界深度伪造检测提供了关键启示。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03512v3",
      "published_date": "2024-06-05 10:33:15 UTC",
      "updated_date": "2024-06-12 16:54:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:34:42.427183"
    },
    {
      "arxiv_id": "2406.03511v1",
      "title": "MagiNet: Mask-Aware Graph Imputation Network for Incomplete Traffic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Jianping Zhou",
        "Bin Lu",
        "Zhanyu Liu",
        "Siyu Pan",
        "Xuejun Feng",
        "Hua Wei",
        "Guanjie Zheng",
        "Xinbing Wang",
        "Chenghu Zhou"
      ],
      "abstract": "Due to detector malfunctions and communication failures, missing data is\nubiquitous during the collection of traffic data. Therefore, it is of vital\nimportance to impute the missing values to facilitate data analysis and\ndecision-making for Intelligent Transportation System (ITS). However, existing\nimputation methods generally perform zero pre-filling techniques to initialize\nmissing values, introducing inevitable noises. Moreover, we observe prevalent\nover-smoothing interpolations, falling short in revealing the intrinsic\nspatio-temporal correlations of incomplete traffic data. To this end, we\npropose Mask-Aware Graph imputation Network: MagiNet. Our method designs an\nadaptive mask spatio-temporal encoder to learn the latent representations of\nincomplete data, eliminating the reliance on pre-filling missing values.\nFurthermore, we devise a spatio-temporal decoder that stacks multiple blocks to\ncapture the inherent spatial and temporal dependencies within incomplete\ntraffic data, alleviating over-smoothing imputation. Extensive experiments\ndemonstrate that our method outperforms state-of-the-art imputation methods on\nfive real-world traffic datasets, yielding an average improvement of 4.31% in\nRMSE and 3.72% in MAPE.",
      "tldr_zh": "该论文针对交通数据收集中的缺失问题（如检测器故障），提出了一种Mask-Aware Graph Imputation Network（MagiNet），旨在避免传统方法的零预填充噪声和过度平滑插值。MagiNet包括一个adaptive mask spatio-temporal encoder，用于学习不完整数据的潜在表示，而无需初始化缺失值，以及一个spatio-temporal decoder，通过堆叠多个块捕获数据的固有空间和时间依赖性。实验在五个真实交通数据集上表明，该方法比现有方法平均提升RMSE 4.31% 和 MAPE 3.72%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.03511v1",
      "published_date": "2024-06-05 10:06:07 UTC",
      "updated_date": "2024-06-05 10:06:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:34:53.727892"
    },
    {
      "arxiv_id": "2406.03102v1",
      "title": "DEER: A Delay-Resilient Framework for Reinforcement Learning with Variable Delays",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Xia",
        "Yilun Kong",
        "Yongzhe Chang",
        "Bo Yuan",
        "Zhiheng Li",
        "Xueqian Wang",
        "Bin Liang"
      ],
      "abstract": "Classic reinforcement learning (RL) frequently confronts challenges in tasks\ninvolving delays, which cause a mismatch between received observations and\nsubsequent actions, thereby deviating from the Markov assumption. Existing\nmethods usually tackle this issue with end-to-end solutions using state\naugmentation. However, these black-box approaches often involve\nincomprehensible processes and redundant information in the information states,\ncausing instability and potentially undermining the overall performance. To\nalleviate the delay challenges in RL, we propose $\\textbf{DEER (Delay-resilient\nEncoder-Enhanced RL)}$, a framework designed to effectively enhance the\ninterpretability and address the random delay issues. DEER employs a pretrained\nencoder to map delayed states, along with their variable-length past action\nsequences resulting from different delays, into hidden states, which is trained\non delay-free environment datasets. In a variety of delayed scenarios, the\ntrained encoder can seamlessly integrate with standard RL algorithms without\nrequiring additional modifications and enhance the delay-solving capability by\nsimply adapting the input dimension of the original algorithms. We evaluate\nDEER through extensive experiments on Gym and Mujoco environments. The results\nconfirm that DEER is superior to state-of-the-art RL algorithms in both\nconstant and random delay settings.",
      "tldr_zh": "该研究针对强化学习（RL）中延迟问题提出DEER框架（Delay-resilient Encoder-Enhanced RL），以解决延迟导致的观察-行动不匹配和Markov假设违背问题。DEER使用一个在无延迟环境数据集上预训练的编码器，将延迟状态和可变长度过去动作序列映射到隐藏状态，从而提升算法的可解释性和稳定性，同时无需修改标准RL算法，只需调整输入维度。在Gym和Mujoco环境中实验表明，DEER在恒定和随机延迟场景下优于现有最先进算法，显著提高了性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03102v1",
      "published_date": "2024-06-05 09:45:26 UTC",
      "updated_date": "2024-06-05 09:45:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:35:05.311856"
    },
    {
      "arxiv_id": "2406.03510v2",
      "title": "Speech-based Clinical Depression Screening: An Empirical Study",
      "title_zh": "基于语音的临床抑郁筛查：一项实证研究",
      "authors": [
        "Yangbin Chen",
        "Chenyang Xu",
        "Chunfeng Liang",
        "Yanbao Tao",
        "Chuan Shi"
      ],
      "abstract": "This study investigates the utility of speech signals for AI-based depression\nscreening across varied interaction scenarios, including psychiatric\ninterviews, chatbot conversations, and text readings. Participants include\ndepressed patients recruited from the outpatient clinics of Peking University\nSixth Hospital and control group members from the community, all diagnosed by\npsychiatrists following standardized diagnostic protocols. We extracted\nacoustic and deep speech features from each participant's segmented recordings.\nClassifications were made using neural networks or SVMs, with aggregated clip\noutcomes determining final assessments. Our analysis across interaction\nscenarios, speech processing techniques, and feature types confirms speech as a\ncrucial marker for depression screening. Specifically, human-computer\ninteraction matches clinical interview efficacy, surpassing reading tasks.\nSegment duration and quantity significantly affect model performance, with deep\nspeech features substantially outperforming traditional acoustic features.",
      "tldr_zh": "这项实证研究探讨了使用语音信号进行 AI 基于的抑郁筛查在不同互动场景（如精神病访谈、聊天机器人对话和文本阅读）中的效用，参与者包括医院抑郁患者和社区对照组，由精神科医生诊断。研究从录音中提取 acoustic 和 deep speech features，并采用 neural networks 或 SVMs 进行分类，最终通过聚合片段结果得出评估。结果表明，语音是抑郁筛查的关键标记，人机互动的效能与临床访谈相当且优于阅读任务，同时 deep speech features 显著优于 traditional acoustic features，且片段时长和数量对模型性能有重要影响。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.03510v2",
      "published_date": "2024-06-05 09:43:54 UTC",
      "updated_date": "2024-06-12 08:13:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:35:17.322592"
    },
    {
      "arxiv_id": "2406.03097v1",
      "title": "Enhancing the Resilience of Graph Neural Networks to Topological Perturbations in Sparse Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Shuqi He",
        "Jun Zhuang",
        "Ding Wang",
        "Luyao Peng",
        "Jun Song"
      ],
      "abstract": "Graph neural networks (GNNs) have been extensively employed in node\nclassification. Nevertheless, recent studies indicate that GNNs are vulnerable\nto topological perturbations, such as adversarial attacks and edge disruptions.\nConsiderable efforts have been devoted to mitigating these challenges. For\nexample, pioneering Bayesian methodologies, including GraphSS and LlnDT,\nincorporate Bayesian label transitions and topology-based label sampling to\nstrengthen the robustness of GNNs. However, GraphSS is hindered by slow\nconvergence, while LlnDT faces challenges in sparse graphs. To overcome these\nlimitations, we propose a novel label inference framework, TraTopo, which\ncombines topology-driven label propagation, Bayesian label transitions, and\nlink analysis via random walks. TraTopo significantly surpasses its\npredecessors on sparse graphs by utilizing random walk sampling, specifically\ntargeting isolated nodes for link prediction, thus enhancing its effectiveness\nin topological sampling contexts. Additionally, TraTopo employs a shortest-path\nstrategy to refine link prediction, thereby reducing predictive overhead and\nimproving label inference accuracy. Empirical evaluations highlight TraTopo's\nsuperiority in node classification, significantly exceeding contemporary GCN\nmodels in accuracy.",
      "tldr_zh": "该研究针对图神经网络(GNNs)在稀疏图中对拓扑扰动(如对抗攻击和边中断)的脆弱性问题，提出了一种新型标签推断框架TraTopo。TraTopo整合拓扑驱动的标签传播、Bayesian标签转换和随机游走链接分析，通过针对孤立节点的随机游走采样和最短路径策略，显著提升了链接预测的准确性和效率。相比现有方法如GraphSS和LlnDT，TraTopo克服了收敛慢和稀疏图性能差的局限，在节点分类任务上表现出色。实证评估显示，TraTopo在准确性上超过了当代GCN模型，为增强GNNs的鲁棒性提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03097v1",
      "published_date": "2024-06-05 09:40:08 UTC",
      "updated_date": "2024-06-05 09:40:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:35:30.776993"
    },
    {
      "arxiv_id": "2406.03095v4",
      "title": "EgoSurgery-Tool: A Dataset of Surgical Tool and Hand Detection from Egocentric Open Surgery Videos",
      "title_zh": "EgoSurgery-Tool：一个基于第一人称视角开放手术视频的手",
      "authors": [
        "Ryo Fujii",
        "Hideo Saito",
        "Hiroki Kajita"
      ],
      "abstract": "Surgical tool detection is a fundamental task for understanding egocentric\nopen surgery videos. However, detecting surgical tools presents significant\nchallenges due to their highly imbalanced class distribution, similar shapes\nand similar textures, and heavy occlusion. The lack of a comprehensive\nlarge-scale dataset compounds these challenges. In this paper, we introduce\nEgoSurgery-Tool, an extension of the existing EgoSurgery-Phase dataset, which\ncontains real open surgery videos captured using an egocentric camera attached\nto the surgeon's head, along with phase annotations. EgoSurgery-Tool has been\ndensely annotated with surgical tools and comprises over 49K surgical tool\nbounding boxes across 15 categories, constituting a large-scale surgical tool\ndetection dataset. EgoSurgery-Tool also provides annotations for hand detection\nwith over 46K hand-bounding boxes, capturing hand-object interactions that are\ncrucial for understanding activities in egocentric open surgery.\nEgoSurgery-Tool is superior to existing datasets due to its larger scale,\ngreater variety of surgical tools, more annotations, and denser scenes. We\nconduct a comprehensive analysis of EgoSurgery-Tool using nine popular object\ndetectors to assess their effectiveness in both surgical tool and hand\ndetection. The dataset will be released at\nhttps://github.com/Fujiry0/EgoSurgery.",
      "tldr_zh": "本文介绍了EgoSurgery-Tool数据集，这是一个扩展自EgoSurgery-Phase的资源，用于从egocentric相机捕获的开放手术视频中检测手术工具和手。该数据集包含超过49K的手术工具bounding boxes（覆盖15个类别）和46K的手bounding boxes，旨在解决工具类别不平衡、形状相似和遮挡等挑战。相较现有数据集，EgoSurgery-Tool具有更大规模、更丰富的工具种类以及更密集的标注。作者通过九种流行object detectors进行了全面分析，评估了其在手术工具和手检测中的有效性，并计划在GitHub上发布数据集。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03095v4",
      "published_date": "2024-06-05 09:36:15 UTC",
      "updated_date": "2024-11-27 04:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:35:45.444787"
    },
    {
      "arxiv_id": "2406.03091v1",
      "title": "Improving Plan Execution Flexibility using Block-Substitution",
      "title_zh": "通过块替换提高计划执行灵活性",
      "authors": [
        "Sabah Binte Noor",
        "Fazlul Hasan Siddiqui"
      ],
      "abstract": "Partial-order plans in AI planning facilitate execution flexibility due to\ntheir less-constrained nature. Maximizing plan flexibility has been studied\nthrough the notions of plan deordering, and plan reordering. Plan deordering\nremoves unnecessary action orderings within a plan, while plan reordering\nmodifies them arbitrarily to minimize action orderings. This study, in contrast\nwith traditional plan deordering and reordering strategies, improves a plan's\nflexibility by substituting its subplans with actions outside the plan for a\nplanning problem. We exploit block deordering, which eliminates orderings in a\nPOP by encapsulating coherent actions in blocks, to construct action blocks as\ncandidate subplans for substitutions. In addition, this paper introduces a\npruning technique for eliminating redundant actions within a BDPO plan. We also\nevaluate our approach when combined with MaxSAT-based reorderings. Our\nexperimental result demonstrates a significant improvement in plan execution\nflexibility on the benchmark problems from International Planning Competitions\n(IPC), maintaining good coverage and execution time.",
      "tldr_zh": "本文提出一种名为 Block-Substitution 的方法，用于提升 AI 规划中部分顺序计划（partial-order plans）的执行灵活性，该方法通过替换子计划来代替传统计划去顺序化（plan deordering）和计划重新顺序化（plan reordering）。具体而言，该方法利用块去顺序化（block deordering）构建候选子计划块，并引入修剪技术以消除冗余动作，同时与基于 MaxSAT 的重新顺序化相结合。实验结果显示，在国际规划竞赛（IPC）基准问题上，该方法显著提高了计划执行灵活性，同时保持了良好的覆盖率和执行时间。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03091v1",
      "published_date": "2024-06-05 09:30:48 UTC",
      "updated_date": "2024-06-05 09:30:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:35:57.120862"
    },
    {
      "arxiv_id": "2406.03079v1",
      "title": "Cryptocurrency Frauds for Dummies: How ChatGPT introduces us to fraud?",
      "title_zh": "加密货币欺诈入门：ChatGPT 如何将我们引入欺诈？",
      "authors": [
        "Wail Zellagui",
        "Abdessamad Imine",
        "Yamina Tadjeddine"
      ],
      "abstract": "Recent advances in the field of large language models (LLMs), particularly\nthe ChatGPT family, have given rise to a powerful and versatile machine\ninterlocutor, packed with knowledge and challenging our understanding of\nlearning. This interlocutor is a double-edged sword: it can be harnessed for a\nwide variety of beneficial tasks, but it can also be used to cause harm. This\nstudy explores the complicated interaction between ChatGPT and the growing\nproblem of cryptocurrency fraud. Although ChatGPT is known for its adaptability\nand ethical considerations when used for harmful purposes, we highlight the\ndeep connection that may exist between ChatGPT and fraudulent actions in the\nvolatile cryptocurrency ecosystem. Based on our categorization of\ncryptocurrency frauds, we show how to influence outputs, bypass ethical terms,\nand achieve specific fraud goals by manipulating ChatGPT prompts. Furthermore,\nour findings emphasize the importance of realizing that ChatGPT could be a\nvaluable instructor even for novice fraudsters, as well as understanding and\nsafely deploying complex language models, particularly in the context of\ncryptocurrency frauds. Finally, our study underlines the importance of using\nLLMs responsibly and ethically in the digital currency sector, identifying\npotential risks and resolving ethical issues. It should be noted that our work\nis not intended to encourage and promote fraud, but rather to raise awareness\nof the risks of fraud associated with the use of ChatGPT.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)如 ChatGPT 在加密货币欺诈中的潜在风险，展示了通过操纵提示如何影响输出、绕过道德条款并实现具体欺诈目标。研究者对加密货币欺诈进行了分类，并证明 ChatGPT 可能充当新手欺诈者的指导工具，帮助他们理解和执行复杂操作。最终，该工作强调了在数字货币领域负责任地使用 LLMs 的必要性，以识别风险并促进伦理部署，而不是鼓励欺诈。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To be published in ACM journal \"Digital Government: Research and\n  Practice\"",
      "pdf_url": "http://arxiv.org/pdf/2406.03079v1",
      "published_date": "2024-06-05 09:09:32 UTC",
      "updated_date": "2024-06-05 09:09:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:36:19.716572"
    },
    {
      "arxiv_id": "2406.03078v1",
      "title": "Towards Federated Domain Unlearning: Verification Methodologies and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Kahou Tam",
        "Kewei Xu",
        "Li Li",
        "Huazhu Fu"
      ],
      "abstract": "Federated Learning (FL) has evolved as a powerful tool for collaborative\nmodel training across multiple entities, ensuring data privacy in sensitive\nsectors such as healthcare and finance. However, the introduction of the Right\nto Be Forgotten (RTBF) poses new challenges, necessitating federated unlearning\nto delete data without full model retraining. Traditional FL unlearning\nmethods, not originally designed with domain specificity in mind, inadequately\naddress the complexities of multi-domain scenarios, often affecting the\naccuracy of models in non-targeted domains or leading to uniform forgetting\nacross all domains. Our work presents the first comprehensive empirical study\non Federated Domain Unlearning, analyzing the characteristics and challenges of\ncurrent techniques in multi-domain contexts. We uncover that these methods\nfalter, particularly because they neglect the nuanced influences of\ndomain-specific data, which can lead to significant performance degradation and\ninaccurate model behavior. Our findings reveal that unlearning\ndisproportionately affects the model's deeper layers, erasing critical\nrepresentational subspaces acquired during earlier training phases. In\nresponse, we propose novel evaluation methodologies tailored for Federated\nDomain Unlearning, aiming to accurately assess and verify domain-specific data\nerasure without compromising the model's overall integrity and performance.\nThis investigation not only highlights the urgent need for domain-centric\nunlearning strategies in FL but also sets a new precedent for evaluating and\nimplementing these techniques effectively.",
      "tldr_zh": "本研究探讨了 Federated Learning (FL) 在处理 Right to Be Forgotten (RTBF) 时的挑战，特别针对 Federated Domain Unlearning 在多域场景下的不足，传统方法往往导致非目标域准确性下降和整体模型性能退化。作者进行了首个全面实证研究，分析现有技术的局限性，发现 unlearning 会 disproportionately 影响模型的深层层和关键表示子空间。论文提出新型评估方法ologies，以准确验证域特定数据删除，同时维护模型的完整性和性能，为未来 domain-centric unlearning 策略奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.03078v1",
      "published_date": "2024-06-05 09:05:55 UTC",
      "updated_date": "2024-06-05 09:05:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:36:21.160823"
    },
    {
      "arxiv_id": "2406.03071v1",
      "title": "Exploiting LMM-based knowledge for image classification tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Maria Tzelepi",
        "Vasileios Mezaris"
      ],
      "abstract": "In this paper we address image classification tasks leveraging knowledge\nencoded in Large Multimodal Models (LMMs). More specifically, we use the\nMiniGPT-4 model to extract semantic descriptions for the images, in a\nmultimodal prompting fashion. In the current literature, vision language models\nsuch as CLIP, among other approaches, are utilized as feature extractors, using\nonly the image encoder, for solving image classification tasks. In this paper,\nwe propose to additionally use the text encoder to obtain the text embeddings\ncorresponding to the MiniGPT-4-generated semantic descriptions. Thus, we use\nboth the image and text embeddings for solving the image classification task.\nThe experimental evaluation on three datasets validates the improved\nclassification performance achieved by exploiting LMM-based knowledge.",
      "tldr_zh": "本研究探讨了利用 Large Multimodal Models (LMMs) 的知识来提升图像分类任务的性能。具体而言，作者使用 MiniGPT-4 通过多模态提示提取图像的语义描述，并创新性地结合图像编码器和文本编码器，获取图像嵌入和对应的文本嵌入，以共同进行分类任务。相比传统方法如 CLIP 仅使用图像编码器，本文的方法充分利用 LMMs 的多模态能力。在三个数据集上的实验验证了这一方法的有效性，实现了分类性能的显著改进。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication, 25th Int. Conf. on Engineering Applications\n  of Neural Networks (EANN/EAAAI 2024), Corfu, Greece, June 2024. This is the\n  \"submitted manuscript\"",
      "pdf_url": "http://arxiv.org/pdf/2406.03071v1",
      "published_date": "2024-06-05 08:56:24 UTC",
      "updated_date": "2024-06-05 08:56:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:36:31.915051"
    },
    {
      "arxiv_id": "2406.03070v2",
      "title": "A-Bench: Are LMMs Masters at Evaluating AI-generated Images?",
      "title_zh": "翻译失败",
      "authors": [
        "Zicheng Zhang",
        "Haoning Wu",
        "Chunyi Li",
        "Yingjie Zhou",
        "Wei Sun",
        "Xiongkuo Min",
        "Zijian Chen",
        "Xiaohong Liu",
        "Weisi Lin",
        "Guangtao Zhai"
      ],
      "abstract": "How to accurately and efficiently assess AI-generated images (AIGIs) remains\na critical challenge for generative models. Given the high costs and extensive\ntime commitments required for user studies, many researchers have turned\ntowards employing large multi-modal models (LMMs) as AIGI evaluators, the\nprecision and validity of which are still questionable. Furthermore,\ntraditional benchmarks often utilize mostly natural-captured content rather\nthan AIGIs to test the abilities of LMMs, leading to a noticeable gap for\nAIGIs. Therefore, we introduce A-Bench in this paper, a benchmark designed to\ndiagnose whether LMMs are masters at evaluating AIGIs. Specifically, A-Bench is\norganized under two key principles: 1) Emphasizing both high-level semantic\nunderstanding and low-level visual quality perception to address the intricate\ndemands of AIGIs. 2) Various generative models are utilized for AIGI creation,\nand various LMMs are employed for evaluation, which ensures a comprehensive\nvalidation scope. Ultimately, 2,864 AIGIs from 16 text-to-image models are\nsampled, each paired with question-answers annotated by human experts, and\ntested across 18 leading LMMs. We hope that A-Bench will significantly enhance\nthe evaluation process and promote the generation quality for AIGIs. The\nbenchmark is available at https://github.com/Q-Future/A-Bench.",
      "tldr_zh": "这篇论文引入了 A-Bench，一个专门基准，用于评估大型多模态模型 (LMMs) 在评估 AI 生成图像 (AIGIs) 方面的能力。\nA-Bench 遵循两个关键原则：强调高层语义理解和低层视觉质量感知，并利用多种生成模型创建 AIGIs，同时测试各种 LMMs 以确保全面验证。\n该基准采样了 2,864 个来自 16 个文本到图像模型的 AIGIs，每张图像配有专家标注的问题答案，并测试了 18 个领先 LMMs。\n通过 A-Bench，论文旨在提升 AIGIs 的评估过程和生成质量，并提供 GitHub 资源以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03070v2",
      "published_date": "2024-06-05 08:55:02 UTC",
      "updated_date": "2025-02-07 04:20:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:36:46.365260"
    },
    {
      "arxiv_id": "2406.03069v3",
      "title": "\"Give Me an Example Like This\": Episodic Active Reinforcement Learning from Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Muhan Hou",
        "Koen Hindriks",
        "A. E. Eiben",
        "Kim Baraka"
      ],
      "abstract": "Reinforcement Learning (RL) has achieved great success in sequential\ndecision-making problems, but often at the cost of a large number of\nagent-environment interactions. To improve sample efficiency, methods like\nReinforcement Learning from Expert Demonstrations (RLED) introduce external\nexpert demonstrations to facilitate agent exploration during the learning\nprocess. In practice, these demonstrations, which are often collected from\nhuman users, are costly and hence often constrained to a limited amount. How to\nselect the best set of human demonstrations that is most beneficial for\nlearning therefore becomes a major concern. This paper presents EARLY (Episodic\nActive Learning from demonstration querY), an algorithm that enables a learning\nagent to generate optimized queries of expert demonstrations in a\ntrajectory-based feature space. Based on a trajectory-level estimate of\nuncertainty in the agent's current policy, EARLY determines the optimized\ntiming and content for feature-based queries. By querying episodic\ndemonstrations as opposed to isolated state-action pairs, EARLY improves the\nhuman teaching experience and achieves better learning performance. We validate\nthe effectiveness of our method in three simulated navigation tasks of\nincreasing difficulty. The results show that our method is able to achieve\nexpert-level performance for all three tasks with convergence over 30\\% faster\nthan other baseline methods when demonstrations are generated by simulated\noracle policies. The results of a follow-up pilot user study (N=18) further\nvalidate that our method can still maintain a significantly better convergence\nin the case of human expert demonstrators while achieving a better user\nexperience in perceived task load and consuming significantly less human time.",
      "tldr_zh": "这篇论文提出 EARLY 算法（Episodic Active Learning from demonstration querY），用于从专家演示中进行主动强化学习 (RL)，以解决传统 RL 样本效率低的问题。EARLY 通过在轨迹-based 特征空间中估算代理策略的不确定性，优化演示查询的时机和内容，从而查询完整的轨迹而非孤立的 state-action 对，提升人类教学体验和学习性能。在三个模拟导航任务中，EARLY 比基线方法快 30% 以上达到专家水平；后续用户研究 (N=18) 进一步显示，即使使用人类专家，EARLY 也能显著加快收敛、减少人类时间并改善感知任务负载。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03069v3",
      "published_date": "2024-06-05 08:52:21 UTC",
      "updated_date": "2024-10-02 20:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:37:00.082025"
    },
    {
      "arxiv_id": "2406.03068v2",
      "title": "Distributional Associations vs In-Context Reasoning: A Study of Feed-forward and Attention Layers",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Chen",
        "Joan Bruna",
        "Alberto Bietti"
      ],
      "abstract": "Large language models have been successful at tasks involving basic forms of\nin-context reasoning, such as generating coherent language, as well as storing\nvast amounts of knowledge. At the core of the Transformer architecture behind\nsuch models are feed-forward and attention layers, which are often associated\nto knowledge and reasoning, respectively. In this paper, we study this\ndistinction empirically and theoretically in a controlled synthetic setting\nwhere certain next-token predictions involve both distributional and in-context\ninformation. We find that feed-forward layers tend to learn simple\ndistributional associations such as bigrams, while attention layers focus on\nin-context reasoning. Our theoretical analysis identifies the noise in the\ngradients as a key factor behind this discrepancy. Finally, we illustrate how\nsimilar disparities emerge in pre-trained models through ablations on the\nPythia model family on simple reasoning tasks.",
      "tldr_zh": "本研究探讨了大语言模型中 Feed-forward layers 与 Attention layers 的作用差异，分别与分布关联（Distributional Associations）和情景内推理（In-context Reasoning）相关。通过受控合成环境进行实证和理论分析，发现 Feed-forward layers 倾向于学习简单的分布关联（如 bigrams），而 Attention layers 更专注于处理情景内信息，且这种差异主要源于梯度中的噪声。最终，在 Pythia model family 上进行的消融实验证实了这些差异的存在，为理解 Transformer 架构的内部机制提供了新洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.03068v2",
      "published_date": "2024-06-05 08:51:08 UTC",
      "updated_date": "2025-03-06 23:55:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:37:12.118952"
    },
    {
      "arxiv_id": "2406.06587v1",
      "title": "Exploring Human-AI Perception Alignment in Sensory Experiences: Do LLMs Understand Textile Hand?",
      "title_zh": "翻译失败",
      "authors": [
        "Shu Zhong",
        "Elia Gatti",
        "Youngjun Cho",
        "Marianna Obrist"
      ],
      "abstract": "Aligning large language models (LLMs) behaviour with human intent is critical\nfor future AI. An important yet often overlooked aspect of this alignment is\nthe perceptual alignment. Perceptual modalities like touch are more\nmultifaceted and nuanced compared to other sensory modalities such as vision.\nThis work investigates how well LLMs align with human touch experiences using\nthe \"textile hand\" task. We created a \"Guess What Textile\" interaction in which\nparticipants were given two textile samples -- a target and a reference -- to\nhandle. Without seeing them, participants described the differences between\nthem to the LLM. Using these descriptions, the LLM attempted to identify the\ntarget textile by assessing similarity within its high-dimensional embedding\nspace. Our results suggest that a degree of perceptual alignment exists,\nhowever varies significantly among different textile samples. For example, LLM\npredictions are well aligned for silk satin, but not for cotton denim.\nMoreover, participants didn't perceive their textile experiences closely\nmatched by the LLM predictions. This is only the first exploration into\nperceptual alignment around touch, exemplified through textile hand. We discuss\npossible sources of this alignment variance, and how better human-AI perceptual\nalignment can benefit future everyday tasks.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）与人类感知对齐的问题，特别针对触觉体验（如纺织手感）是否能被准确理解。研究设计了“Guess What Textile”互动实验，让参与者描述两个纺织样本（目标和参考）的差异，LLMs 则基于这些描述在高维嵌入空间中评估相似性以识别目标纺织。结果显示，LLMs 在某些样本（如丝缎）上表现出一定感知对齐，但其他样本（如棉牛仔布）对齐度显著降低，且参与者认为LLMs 的预测未能完全匹配他们的触觉体验。该工作揭示了感知对齐的变异来源，并强调了提升人类-AI 感知对齐对未来日常任务的潜在益处。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06587v1",
      "published_date": "2024-06-05 08:46:07 UTC",
      "updated_date": "2024-06-05 08:46:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:37:20.397952"
    },
    {
      "arxiv_id": "2406.03049v1",
      "title": "StreamSpeech: Simultaneous Speech-to-Speech Translation with Multi-task Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shaolei Zhang",
        "Qingkai Fang",
        "Shoutao Guo",
        "Zhengrui Ma",
        "Min Zhang",
        "Yang Feng"
      ],
      "abstract": "Simultaneous speech-to-speech translation (Simul-S2ST, a.k.a streaming speech\ntranslation) outputs target speech while receiving streaming speech inputs,\nwhich is critical for real-time communication. Beyond accomplishing translation\nbetween speech, Simul-S2ST requires a policy to control the model to generate\ncorresponding target speech at the opportune moment within speech inputs,\nthereby posing a double challenge of translation and policy. In this paper, we\npropose StreamSpeech, a direct Simul-S2ST model that jointly learns translation\nand simultaneous policy in a unified framework of multi-task learning. Adhering\nto a multi-task learning approach, StreamSpeech can perform offline and\nsimultaneous speech recognition, speech translation and speech synthesis via an\n\"All-in-One\" seamless model. Experiments on CVSS benchmark demonstrate that\nStreamSpeech achieves state-of-the-art performance in both offline S2ST and\nSimul-S2ST tasks. Besides, StreamSpeech is able to present high-quality\nintermediate results (i.e., ASR or translation results) during simultaneous\ntranslation process, offering a more comprehensive real-time communication\nexperience.",
      "tldr_zh": "本文提出 StreamSpeech，一种直接的 Simul-S2ST 模型，通过 multi-task learning 框架联合学习翻译和实时策略，实现对流式语音输入的即时响应。该模型支持离线和实时语音识别（ASR）、语音翻译以及语音合成，形成一个“All-in-One”无缝系统。在 CVSS 基准测试中，StreamSpeech 取得了最先进的性能，并在实时翻译过程中提供高质量的中间结果（如 ASR 或翻译输出），从而提升了实时通信的全面体验。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 main conference, Project Page:\n  https://ictnlp.github.io/StreamSpeech-site/",
      "pdf_url": "http://arxiv.org/pdf/2406.03049v1",
      "published_date": "2024-06-05 08:24:22 UTC",
      "updated_date": "2024-06-05 08:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:37:32.564766"
    },
    {
      "arxiv_id": "2406.06586v1",
      "title": "Bi-Chainer: Automated Large Language Models Reasoning with Bidirectional Chaining",
      "title_zh": "翻译失败",
      "authors": [
        "Shuqi Liu",
        "Bowei He",
        "Linqi Song"
      ],
      "abstract": "Large Language Models (LLMs) have shown human-like reasoning abilities but\nstill face challenges in solving complex logical problems. Existing\nunidirectional chaining methods, such as forward chaining and backward\nchaining, suffer from issues like low prediction accuracy and efficiency. To\naddress these, we propose a bidirectional chaining method, Bi-Chainer, which\ndynamically switches to depth-first reasoning in the opposite reasoning\ndirection when it encounters multiple branching options within the current\ndirection. Thus, the intermediate reasoning results can be utilized as guidance\nto facilitate the reasoning process. We show that Bi-Chainer achieves sizable\naccuracy boots over unidirectional chaining frameworks on four challenging\nlogical reasoning datasets. Moreover, Bi-Chainer enhances the accuracy of\nintermediate proof steps and reduces the average number of inference calls,\nresulting in more efficient and accurate reasoning.",
      "tldr_zh": "Large Language Models (LLMs) 在解决复杂逻辑问题时面临准确性和效率挑战，现有的单向链式方法如 forward chaining 和 backward chaining 存在不足。为此，本文提出 Bi-Chainer，一种双向链式推理框架，能够在当前方向遇到多个分支时动态切换到相反方向的深度优先推理，并利用中间结果指导过程。实验结果显示，Bi-Chainer 在四个挑战性逻辑推理数据集上显著提升准确率，同时提高了中间证明步骤的准确性和推理效率，减少了平均推理调用次数。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.06586v1",
      "published_date": "2024-06-05 08:15:38 UTC",
      "updated_date": "2024-06-05 08:15:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:37:45.149956"
    },
    {
      "arxiv_id": "2406.03508v2",
      "title": "Mutual Information Guided Backdoor Mitigation for Pre-trained Encoders",
      "title_zh": "互信息引导的预训练编码器后门缓解",
      "authors": [
        "Tingxu Han",
        "Weisong Sun",
        "Ziqi Ding",
        "Chunrong Fang",
        "Hanwei Qian",
        "Jiaxun Li",
        "Zhenyu Chen",
        "Xiangyu Zhang"
      ],
      "abstract": "Self-supervised learning (SSL) is increasingly attractive for pre-training\nencoders without requiring labeled data. Downstream tasks built on top of those\npre-trained encoders can achieve nearly state-of-the-art performance. The\npre-trained encoders by SSL, however, are vulnerable to backdoor attacks as\ndemonstrated by existing studies. Numerous backdoor mitigation techniques are\ndesigned for downstream task models. However, their effectiveness is impaired\nand limited when adapted to pre-trained encoders, due to the lack of label\ninformation when pre-training. To address backdoor attacks against pre-trained\nencoders, in this paper, we innovatively propose a mutual information guided\nbackdoor mitigation technique, named MIMIC. MIMIC treats the potentially\nbackdoored encoder as the teacher net and employs knowledge distillation to\ndistill a clean student encoder from the teacher net. Different from existing\nknowledge distillation approaches, MIMIC initializes the student with random\nweights, inheriting no backdoors from teacher nets. Then MIMIC leverages mutual\ninformation between each layer and extracted features to locate where benign\nknowledge lies in the teacher net, with which distillation is deployed to clone\nclean features from teacher to student. We craft the distillation loss with two\naspects, including clone loss and attention loss, aiming to mitigate backdoors\nand maintain encoder performance at the same time. Our evaluation conducted on\ntwo backdoor attacks in SSL demonstrates that MIMIC can significantly reduce\nthe attack success rate by only utilizing <5% of clean data, surpassing seven\nstate-of-the-art backdoor mitigation techniques.",
      "tldr_zh": "本文针对自监督学习 (SSL) 预训练编码器易受后门攻击的问题，提出了一种创新方法 MIMIC，利用互信息指导的知识蒸馏技术来缓解攻击。MIMIC 将潜在后门的编码器作为教师网络，从随机初始化的学生网络中蒸馏干净特征，通过 clone loss 和 attention loss 平衡后门缓解与性能维护。实验结果显示，该方法仅需不到 5% 的干净数据，即可显著降低攻击成功率，并优于七种现有后门缓解技术。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03508v2",
      "published_date": "2024-06-05 07:27:15 UTC",
      "updated_date": "2024-06-11 06:11:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:37:59.114809"
    },
    {
      "arxiv_id": "2406.03012v2",
      "title": "Towards Understanding the Influence of Training Samples on Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "André Artelt",
        "Barbara Hammer"
      ],
      "abstract": "Explainable AI (XAI) is widely used to analyze AI systems' decision-making,\nsuch as providing counterfactual explanations for recourse. When unexpected\nexplanations occur, users may want to understand the training data properties\nshaping them. Under the umbrella of data valuation, first approaches have been\nproposed that estimate the influence of data samples on a given model. This\nprocess not only helps determine the data's value, but also offers insights\ninto how individual, potentially noisy, or misleading examples affect a model,\nwhich is crucial for interpretable AI. In this work, we apply the concept of\ndata valuation to the significant area of model evaluations, focusing on how\nindividual training samples impact a model's internal reasoning rather than the\npredictive performance only. Hence, we introduce the novel problem of\nidentifying training samples shaping a given explanation or related quantity,\nand investigate the particular case of the cost of computational recourse. We\npropose an algorithm to identify such influential samples and conduct extensive\nempirical evaluations in two case studies.",
      "tldr_zh": "本文探讨了训练样本对AI解释（XAI）的影响，特别是在反事实解释（counterfactual explanations）方面的应用。作者引入数据估值（data valuation）概念，提出一个新问题：识别影响给定解释的训练样本，并开发算法来评估这些样本对模型内部推理和计算反事实解释成本的影响。通过两个案例研究的实证评估，证明了这一方法有助于理解噪声或误导样本对可解释AI的影响。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Extended version of the paper accepted at the \"Workshop on\n  Explainable Artificial Intelligence (XAI)\" at IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03012v2",
      "published_date": "2024-06-05 07:20:06 UTC",
      "updated_date": "2025-03-25 12:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:38:09.915915"
    },
    {
      "arxiv_id": "2406.03009v1",
      "title": "Unveiling Selection Biases: Exploring Order and Token Sensitivity in Large Language Models",
      "title_zh": "揭示选择偏差：探索大型语言模型中的顺序和标记敏感性",
      "authors": [
        "Sheng-Lun Wei",
        "Cheng-Kuang Wu",
        "Hen-Hsen Huang",
        "Hsin-Hsi Chen"
      ],
      "abstract": "In this paper, we investigate the phenomena of \"selection biases\" in Large\nLanguage Models (LLMs), focusing on problems where models are tasked with\nchoosing the optimal option from an ordered sequence. We delve into biases\nrelated to option order and token usage, which significantly impact LLMs'\ndecision-making processes. We also quantify the impact of these biases through\nan extensive empirical analysis across multiple models and tasks. Furthermore,\nwe propose mitigation strategies to enhance model performance. Our key\ncontributions are threefold: 1) Precisely quantifying the influence of option\norder and token on LLMs, 2) Developing strategies to mitigate the impact of\ntoken and order sensitivity to enhance robustness, and 3) Offering a detailed\nanalysis of sensitivity across models and tasks, which informs the creation of\nmore stable and reliable LLM applications for selection problems.",
      "tldr_zh": "本文研究了 Large Language Models (LLMs) 中的 selection biases，重点探讨选项顺序和 token sensitivity 对模型决策过程的影响。通过广泛的实证分析，作者量化了这些偏差在多个模型和任务中的影响，并提出了缓解策略以提升模型性能。关键贡献包括精确量化选项顺序和 token 的作用、开发方法来增强鲁棒性，以及提供跨模型任务的详细敏感性分析，以支持更稳定可靠的 LLM 应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as a long findings paper at ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03009v1",
      "published_date": "2024-06-05 07:16:51 UTC",
      "updated_date": "2024-06-05 07:16:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:38:32.506197"
    },
    {
      "arxiv_id": "2406.03008v2",
      "title": "DriVLMe: Enhancing LLM-based Autonomous Driving Agents with Embodied and Social Experiences",
      "title_zh": "翻译失败",
      "authors": [
        "Yidong Huang",
        "Jacob Sansom",
        "Ziqiao Ma",
        "Felix Gervits",
        "Joyce Chai"
      ],
      "abstract": "Recent advancements in foundation models (FMs) have unlocked new prospects in\nautonomous driving, yet the experimental settings of these studies are\npreliminary, over-simplified, and fail to capture the complexity of real-world\ndriving scenarios in human environments. It remains under-explored whether FM\nagents can handle long-horizon navigation tasks with free-from dialogue and\ndeal with unexpected situations caused by environmental dynamics or task\nchanges. To explore the capabilities and boundaries of FMs faced with the\nchallenges above, we introduce DriVLMe, a video-language-model-based agent to\nfacilitate natural and effective communication between humans and autonomous\nvehicles that perceive the environment and navigate. We develop DriVLMe from\nboth embodied experiences in a simulated environment and social experiences\nfrom real human dialogue. While DriVLMe demonstrates competitive performance in\nboth open-loop benchmarks and closed-loop human studies, we reveal several\nlimitations and challenges, including unacceptable inference time, imbalanced\ntraining data, limited visual understanding, challenges with multi-turn\ninteractions, simplified language generation from robotic experiences, and\ndifficulties in handling on-the-fly unexpected situations like environmental\ndynamics and task changes.",
      "tldr_zh": "该研究引入 DriVLMe，一种基于视频语言模型的代理，用于提升 LLM-based 自动驾驶代理的能力，通过整合 embodied experiences（模拟环境中的身体经验）和 social experiences（真实人类对话）来处理复杂驾驶场景、长程导航和意外情况。DriVLMe 能够在 open-loop benchmarks 和 closed-loop human studies 中表现出色，实现自然的人机交互。论文同时指出了其局限性，包括推理时间过长、训练数据不平衡、视觉理解有限以及在多轮互动和动态环境中的挑战。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "2024 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS)",
      "pdf_url": "http://arxiv.org/pdf/2406.03008v2",
      "published_date": "2024-06-05 07:14:44 UTC",
      "updated_date": "2024-10-15 04:50:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:38:45.677978"
    },
    {
      "arxiv_id": "2406.03007v1",
      "title": "BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Wang",
        "Dizhan Xue",
        "Shengjie Zhang",
        "Shengsheng Qian"
      ],
      "abstract": "With the prosperity of large language models (LLMs), powerful LLM-based\nintelligent agents have been developed to provide customized services with a\nset of user-defined tools. State-of-the-art methods for constructing LLM agents\nadopt trained LLMs and further fine-tune them on data for the agent task.\nHowever, we show that such methods are vulnerable to our proposed backdoor\nattacks named BadAgent on various agent tasks, where a backdoor can be embedded\nby fine-tuning on the backdoor data. At test time, the attacker can manipulate\nthe deployed LLM agents to execute harmful operations by showing the trigger in\nthe agent input or environment. To our surprise, our proposed attack methods\nare extremely robust even after fine-tuning on trustworthy data. Though\nbackdoor attacks have been studied extensively in natural language processing,\nto the best of our knowledge, we could be the first to study them on LLM agents\nthat are more dangerous due to the permission to use external tools. Our work\ndemonstrates the clear risk of constructing LLM agents based on untrusted LLMs\nor data. Our code is public at https://github.com/DPamK/BadAgent",
      "tldr_zh": "该研究提出了一种名为BadAgent的后门攻击方法，针对基于大型语言模型（LLMs）的智能代理，展示了通过在代理任务数据上微调LLMs来嵌入后门的漏洞。攻击者在测试阶段可通过在代理输入或环境中显示触发器，操控代理执行有害操作，如使用外部工具进行危险行为。实验结果显示，BadAgent攻击即使在后续使用可信数据微调后，依然高度稳健，这突出了使用不受信任的LLMs或数据的潜在风险，并为LLM agents的安全研究提供了新洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.03007v1",
      "published_date": "2024-06-05 07:14:28 UTC",
      "updated_date": "2024-06-05 07:14:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:38:45.891509"
    },
    {
      "arxiv_id": "2406.03004v1",
      "title": "Evaluation of data inconsistency for multi-modal sentiment analysis",
      "title_zh": "多模态情感分析中数据不一致性的评估",
      "authors": [
        "Yufei Wang",
        "Mengyue Wu"
      ],
      "abstract": "Emotion semantic inconsistency is an ubiquitous challenge in multi-modal\nsentiment analysis (MSA). MSA involves analyzing sentiment expressed across\nvarious modalities like text, audio, and videos. Each modality may convey\ndistinct aspects of sentiment, due to subtle and nuanced expression of human\nbeings, leading to inconsistency, which may hinder the prediction of artificial\nagents. In this work, we introduce a modality conflicting test set and assess\nthe performance of both traditional multi-modal sentiment analysis models and\nmulti-modal large language models (MLLMs). Our findings reveal significant\nperformance degradation across traditional models when confronted with\nsemantically conflicting data and point out the drawbacks of MLLMs when\nhandling multi-modal emotion analysis. Our research presents a new challenge\nand offer valuable insights for the future development of sentiment analysis\nsystems.",
      "tldr_zh": "本文评估了多模态情感分析（MSA）中的情感语义不一致性问题，该问题源于文本、音频和视频等模态在表达情感时的差异，可能影响AI预测准确性。研究引入了一个模态冲突测试集，并对传统MSA模型和多模态大语言模型（MLLMs）进行了性能评估。结果显示，传统模型在处理语义冲突数据时性能显著下降，而MLLMs也暴露出了在多模态情感分析中的局限性。该研究提出了新挑战，并为未来情感分析系统的改进提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03004v1",
      "published_date": "2024-06-05 07:11:56 UTC",
      "updated_date": "2024-06-05 07:11:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:38:58.562747"
    },
    {
      "arxiv_id": "2406.03001v1",
      "title": "EdgeSync: Faster Edge-model Updating via Adaptive Continuous Learning for Video Data Drift",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Zhao",
        "Runchu Dong",
        "Guiqin Wang",
        "Cong Zhao"
      ],
      "abstract": "Real-time video analytics systems typically place models with fewer weights\non edge devices to reduce latency. The distribution of video content features\nmay change over time for various reasons (i.e. light and weather change) ,\nleading to accuracy degradation of existing models, to solve this problem,\nrecent work proposes a framework that uses a remote server to continually train\nand adapt the lightweight model at edge with the help of complex model.\nHowever, existing analytics approaches leave two challenges untouched: firstly,\nretraining task is compute-intensive, resulting in large model update delays;\nsecondly, new model may not fit well enough with the data distribution of the\ncurrent video stream. To address these challenges, in this paper, we present\nEdgeSync, EdgeSync filters the samples by considering both timeliness and\ninference results to make training samples more relevant to the current video\ncontent as well as reduce the update delay, to improve the quality of training,\nEdgeSync also designs a training management module that can efficiently adjusts\nthe model training time and training order on the runtime. By evaluating real\ndatasets with complex scenes, our method improves about 3.4% compared to\nexisting methods and about 10% compared to traditional means.",
      "tldr_zh": "该论文针对视频数据漂移（Video Data Drift）问题，提出EdgeSync框架，通过自适应连续学习（Adaptive Continuous Learning）来加速边缘模型（Edge-model）的更新。EdgeSync通过过滤样本（考虑及时性和推理结果）来提升训练样本的相关性，并设计训练管理模块动态调整训练时间和顺序，从而减少更新延迟和提高模型适应性。在真实数据集评估中，EdgeSync比现有方法提升约3.4%的准确率，比传统方法提升约10%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03001v1",
      "published_date": "2024-06-05 07:06:26 UTC",
      "updated_date": "2024-06-05 07:06:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:39:09.423723"
    },
    {
      "arxiv_id": "2406.03000v2",
      "title": "Simplification of Risk Averse POMDPs with Performance Guarantees",
      "title_zh": "翻译失败",
      "authors": [
        "Yaacov Pariente",
        "Vadim Indelman"
      ],
      "abstract": "Risk averse decision making under uncertainty in partially observable domains\nis a fundamental problem in AI and essential for reliable autonomous agents. In\nour case, the problem is modeled using partially observable Markov decision\nprocesses (POMDPs), when the value function is the conditional value at risk\n(CVaR) of the return. Calculating an optimal solution for POMDPs is\ncomputationally intractable in general. In this work we develop a\nsimplification framework to speedup the evaluation of the value function, while\nproviding performance guarantees. We consider as simplification a\ncomputationally cheaper belief-MDP transition model, that can correspond, e.g.,\nto cheaper observation or transition models. Our contributions include general\nbounds for CVaR that allow bounding the CVaR of a random variable X, using a\nrandom variable Y, by assuming bounds between their cumulative distributions.\nWe then derive bounds for the CVaR value function in a POMDP setting, and show\nhow to bound the value function using the computationally cheaper belief-MDP\ntransition model and without accessing the computationally expensive model in\nreal-time. Then, we provide theoretical performance guarantees for the\nestimated bounds. Our results apply for a general simplification of a\nbelief-MDP transition model and support simplification of both the observation\nand state transition models simultaneously.",
      "tldr_zh": "本研究针对部分可观测Markov决策过程（POMDPs）中的风险厌恶决策问题，提出了一种简化框架，以加速价值函数（基于条件价值在风险，CVaR）的评估，同时提供性能保证。框架通过采用计算更高效的belief-MDP过渡模型（如简化观察或状态转移模型）来边界CVaR价值函数，从而避免实时使用昂贵的原始模型。研究贡献包括开发通用CVaR边界方法，利用随机变量间的累积分布关系进行边界推导，并证明了简化框架的理论性能保证。该方法支持同时简化观察和状态转移模型，适用于各种POMDPs场景。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03000v2",
      "published_date": "2024-06-05 07:05:52 UTC",
      "updated_date": "2024-06-08 07:37:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:39:23.234160"
    },
    {
      "arxiv_id": "2406.02989v2",
      "title": "Learning Semantic Traversability with Egocentric Video and Automated Annotation Strategy",
      "title_zh": "基于自我中心视频",
      "authors": [
        "Yunho Kim",
        "Jeong Hyun Lee",
        "Choongin Lee",
        "Juhyeok Mun",
        "Donghoon Youm",
        "Jeongsoo Park",
        "Jemin Hwangbo"
      ],
      "abstract": "For reliable autonomous robot navigation in urban settings, the robot must\nhave the ability to identify semantically traversable terrains in the image\nbased on the semantic understanding of the scene. This reasoning ability is\nbased on semantic traversability, which is frequently achieved using semantic\nsegmentation models fine-tuned on the testing domain. This fine-tuning process\noften involves manual data collection with the target robot and annotation by\nhuman labelers which is prohibitively expensive and unscalable. In this work,\nwe present an effective methodology for training a semantic traversability\nestimator using egocentric videos and an automated annotation process.\nEgocentric videos are collected from a camera mounted on a pedestrian's chest.\nThe dataset for training the semantic traversability estimator is then\nautomatically generated by extracting semantically traversable regions in each\nvideo frame using a recent foundation model in image segmentation and its\nprompting technique. Extensive experiments with videos taken across several\ncountries and cities, covering diverse urban scenarios, demonstrate the high\nscalability and generalizability of the proposed annotation method.\nFurthermore, performance analysis and real-world deployment for autonomous\nrobot navigation showcase that the trained semantic traversability estimator is\nhighly accurate, able to handle diverse camera viewpoints, computationally\nlight, and real-world applicable. The summary video is available at\nhttps://youtu.be/EUVoH-wA-lA.",
      "tldr_zh": "这篇论文提出了一种使用 egocentric video 和 automated annotation strategy 的方法，来训练 semantic traversability 估计器，帮助机器人基于图像识别城市环境中可穿越的地形，从而避免昂贵的手动数据收集和标注过程。方法通过从行人胸部摄像头收集视频，并利用图像分割的 foundation model 和提示技术自动提取视频帧中的语义可穿越区域，实现高效的数据生成。实验在多个国家城市的多样化场景中验证了该方法的扩展性和泛化性，结果显示训练出的估计器准确率高、计算资源轻量级，并已在真实世界机器人导航中成功应用。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to IEEE Robotics and Automation Letters (RA-L) 2024, First\n  two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2406.02989v2",
      "published_date": "2024-06-05 06:40:04 UTC",
      "updated_date": "2024-09-28 16:31:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:39:35.882083"
    },
    {
      "arxiv_id": "2406.03507v1",
      "title": "Robust Prediction Model for Multidimensional and Unbalanced Datasets",
      "title_zh": "针对多维和不平衡数据集的鲁棒预测模型",
      "authors": [
        "Pooja Thakar",
        "Anil Mehta",
        "Manisha"
      ],
      "abstract": "Data Mining is a promising field and is applied in multiple domains for its\npredictive capabilities. Data in the real world cannot be readily used for data\nmining as it suffers from the problems of multidimensionality, unbalance and\nmissing values. It is difficult to use its predictive capabilities by novice\nusers. It is difficult for a beginner to find the relevant set of attributes\nfrom a large pool of data available. The paper presents a Robust Prediction\nModel that finds a relevant set of attributes; resolves the problems of\nunbalanced and multidimensional real-life datasets and helps in finding\npatterns for informed decision making. Model is tested upon five different\ndatasets in the domain of Health Sector, Education, Business and Fraud\nDetection. The results showcase the robust behaviour of the model and its\napplicability in various domains.",
      "tldr_zh": "该论文提出一个Robust Prediction Model，用于处理现实世界数据中的多维性、不平衡和缺失值问题，帮助初学者从大量数据中筛选相关属性，并支持数据挖掘的预测应用。模型通过识别关键属性和优化数据处理流程，解决了这些常见挑战，从而提升了决策支持的准确性。在健康、教育、商业和欺诈检测等领域的五个数据集上测试，结果证明了模型的鲁棒性和广泛适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.03507v1",
      "published_date": "2024-06-05 06:28:39 UTC",
      "updated_date": "2024-06-05 06:28:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:39:48.302947"
    },
    {
      "arxiv_id": "2406.02983v3",
      "title": "FREA: Feasibility-Guided Generation of Safety-Critical Scenarios with Reasonable Adversariality",
      "title_zh": "翻译失败",
      "authors": [
        "Keyu Chen",
        "Yuheng Lei",
        "Hao Cheng",
        "Haoran Wu",
        "Wenchao Sun",
        "Sifa Zheng"
      ],
      "abstract": "Generating safety-critical scenarios, which are essential yet difficult to\ncollect at scale, offers an effective method to evaluate the robustness of\nautonomous vehicles (AVs). Existing methods focus on optimizing adversariality\nwhile preserving the naturalness of scenarios, aiming to achieve a balance\nthrough data-driven approaches. However, without an appropriate upper bound for\nadversariality, the scenarios might exhibit excessive adversariality,\npotentially leading to unavoidable collisions. In this paper, we introduce\nFREA, a novel safety-critical scenarios generation method that incorporates the\nLargest Feasible Region (LFR) of AV as guidance to ensure the reasonableness of\nthe adversarial scenarios. Concretely, FREA initially pre-calculates the LFR of\nAV from offline datasets. Subsequently, it learns a reasonable adversarial\npolicy that controls the scene's critical background vehicles (CBVs) to\ngenerate adversarial yet AV-feasible scenarios by maximizing a novel\nfeasibility-dependent adversarial objective function. Extensive experiments\nillustrate that FREA can effectively generate safety-critical scenarios,\nyielding considerable near-miss events while ensuring AV's feasibility.\nGeneralization analysis also confirms the robustness of FREA in AV testing\nacross various surrogate AV methods and traffic environments.",
      "tldr_zh": "本研究提出FREA方法，用于生成安全关键场景，以评估自动驾驶车辆(AVs)的鲁棒性，同时避免现有方法可能导致的过度对抗性问题。FREA通过预计算AV的Largest Feasible Region (LFR)作为指导，学习一个合理的对抗策略来控制关键背景车辆(CBVs)，并通过最大化一个可行性依赖的目标函数生成对抗性但可行的场景。实验结果显示，FREA能有效产生大量近失事件，同时确保AV的可行性，并在不同AV方法和交通环境中的泛化测试中表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by CoRL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02983v3",
      "published_date": "2024-06-05 06:26:15 UTC",
      "updated_date": "2024-10-11 05:32:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:40:03.647930"
    },
    {
      "arxiv_id": "2407.17591v1",
      "title": "Unified Prediction Model for Employability in Indian Higher Education System",
      "title_zh": "统一的预测模型，用于印度高等教育系统的就业能力",
      "authors": [
        "Pooja Thakar",
        "Anil Mehta",
        "Manisha"
      ],
      "abstract": "Educational Data Mining has become extremely popular among researchers in\nlast decade. Prior effort in this area was only directed towards prediction of\nacademic performance of a student. Very less number of researches are directed\ntowards predicting employability of a student i.e. prediction of students\nperformance in campus placements at an early stage of enrollment. Furthermore,\nexisting researches on students employability prediction are not universal in\napproach and is either based upon only one type of course or\nUniversity/Institute. Henceforth, is not scalable from one context to another.\nWith the necessity of unification, data of professional technical courses\nnamely Bachelor in Engineering/Technology and Masters in Computer Applications\nstudents have been collected from 17 states of India. To deal with such a data,\na unified predictive model has been developed and applied on 17 states\ndatasets. The research done in this paper proves that model has universal\napplication and can be applied to various states and institutes pan India with\ndifferent cultural background and course structure. This paper also explores\nand proves statistically that there is no significant difference in Indian\nEducation System with respect to states as far as prediction of employability\nof students is concerned. Model provides a generalized solution for student\nemployability prediction in Indian Scenario.",
      "tldr_zh": "这篇论文针对印度高等教育系统，开发了一个统一的预测模型，用于在学生入学早期预测其就业能力（employability），以弥补现有研究局限于特定课程或机构的局限性。研究收集了来自印度17个州的工程学士和计算机应用硕士学生的就业数据，并应用该模型进行分析。结果证明，该模型具有通用性，能够适用于不同文化背景和课程结构的州和机构，且统计数据显示，印度教育系统在就业预测方面各州间无显著差异，从而为教育数据挖掘（Educational Data Mining）提供了一个可扩展的通用解决方案。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.17591v1",
      "published_date": "2024-06-05 06:23:15 UTC",
      "updated_date": "2024-06-05 06:23:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:40:13.940999"
    },
    {
      "arxiv_id": "2406.02980v1",
      "title": "Tensor Polynomial Additive Model",
      "title_zh": "张量多项式加性模型",
      "authors": [
        "Yang Chen",
        "Ce Zhu",
        "Jiani Liu",
        "Yipeng Liu"
      ],
      "abstract": "Additive models can be used for interpretable machine learning for their\nclarity and simplicity. However, In the classical models for high-order data,\nthe vectorization operation disrupts the data structure, which may lead to\ndegenerated accuracy and increased computational complexity. To deal with these\nproblems, we propose the tensor polynomial addition model (TPAM). It retains\nthe multidimensional structure information of high-order inputs with tensor\nrepresentation. The model parameter compression is achieved using a\nhierarchical and low-order symmetric tensor approximation. In this way, complex\nhigh-order feature interactions can be captured with fewer parameters.\nMoreover, The TPAM preserves the inherent interpretability of additive models,\nfacilitating transparent decision-making and the extraction of meaningful\nfeature values. Additionally, leveraging TPAM's transparency and ability to\nhandle higher-order features, it is used as a post-processing module for other\ninterpretation models by introducing two variants for class activation maps.\nExperimental results on a series of datasets demonstrate that TPAM can enhance\naccuracy by up to 30\\%, and compression rate by up to 5 times, while\nmaintaining a good interpretability.",
      "tldr_zh": "本文提出 Tensor Polynomial Additive Model (TPAM)，一种改进的可解释机器学习模型，用于处理高阶数据时避免传统向量化操作导致的结构破坏和计算复杂度增加问题。TPAM 通过张量表示保留多维结构信息，并采用分层低阶对称张量近似实现参数压缩，从而以较少参数捕获复杂高阶特征交互，同时保持加性模型的固有可解释性。实验结果显示，在多个数据集上，TPAM 能将准确率提高高达 30%、压缩率提高高达 5 倍，并作为后处理模块增强其他解释模型的表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02980v1",
      "published_date": "2024-06-05 06:23:11 UTC",
      "updated_date": "2024-06-05 06:23:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:40:26.212295"
    },
    {
      "arxiv_id": "2406.02979v1",
      "title": "Efficient User Sequence Learning for Online Services via Compressed Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yucheng Wu",
        "Liyue Chen",
        "Yu Cheng",
        "Shuai Chen",
        "Jinyu Xu",
        "Leye Wang"
      ],
      "abstract": "Learning representations of user behavior sequences is crucial for various\nonline services, such as online fraudulent transaction detection mechanisms.\nGraph Neural Networks (GNNs) have been extensively applied to model sequence\nrelationships, and extract information from similar sequences. While user\nbehavior sequence data volume is usually huge for online applications, directly\napplying GNN models may lead to substantial computational overhead during both\nthe training and inference stages and make it challenging to meet real-time\nrequirements for online services. In this paper, we leverage graph compression\ntechniques to alleviate the efficiency issue. Specifically, we propose a novel\nunified framework called ECSeq, to introduce graph compression techniques into\nrelation modeling for user sequence representation learning. The key module of\nECSeq is sequence relation modeling, which explores relationships among\nsequences to enhance sequence representation learning, and employs graph\ncompression algorithms to achieve high efficiency and scalability. ECSeq also\nexhibits plug-and-play characteristics, seamlessly augmenting pre-trained\nsequence representation models without modifications. Empirical experiments on\nboth sequence classification and regression tasks demonstrate the effectiveness\nof ECSeq. Specifically, with an additional training time of tens of seconds in\ntotal on 100,000+ sequences and inference time preserved within $10^{-4}$\nseconds/sample, ECSeq improves the prediction R@P$_{0.9}$ of the widely used\nLSTM by $\\sim 5\\%$.",
      "tldr_zh": "该论文针对在线服务（如欺诈检测）中用户行为序列学习的问题，提出了一种名为 ECSeq 的统一框架，利用图压缩技术来提升 Graph Neural Networks (GNNs) 的训练和推理效率。ECSeq 的核心模块是序列关系建模，通过探索序列间关系增强表示学习，并采用图压缩算法实现高效率和可扩展性，同时支持无缝集成到预训练模型如 LSTM 中。实验结果显示，在序列分类和回归任务上，ECSeq 将 LSTM 的预测指标 R@P$_{0.9}$ 提高了约 5%，训练时间仅增加数十秒，推理时间保持在 $10^{-4}$ 秒/样本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IEEE ICWS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02979v1",
      "published_date": "2024-06-05 06:22:11 UTC",
      "updated_date": "2024-06-05 06:22:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:40:39.164063"
    },
    {
      "arxiv_id": "2406.02976v1",
      "title": "DA-Flow: Dual Attention Normalizing Flow for Skeleton-based Video Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ruituo Wu",
        "Yang Chen",
        "Jian Xiao",
        "Bing Li",
        "Jicong Fan",
        "Frédéric Dufaux",
        "Ce Zhu",
        "Yipeng Liu"
      ],
      "abstract": "Cooperation between temporal convolutional networks (TCN) and graph\nconvolutional networks (GCN) as a processing module has shown promising results\nin skeleton-based video anomaly detection (SVAD). However, to maintain a\nlightweight model with low computational and storage complexity, shallow GCN\nand TCN blocks are constrained by small receptive fields and a lack of\ncross-dimension interaction capture. To tackle this limitation, we propose a\nlightweight module called the Dual Attention Module (DAM) for capturing\ncross-dimension interaction relationships in spatio-temporal skeletal data. It\nemploys the frame attention mechanism to identify the most significant frames\nand the skeleton attention mechanism to capture broader relationships across\nfixed partitions with minimal parameters and flops. Furthermore, the proposed\nDual Attention Normalizing Flow (DA-Flow) integrates the DAM as a\npost-processing unit after GCN within the normalizing flow framework.\nSimulations show that the proposed model is robust against noise and negative\nsamples. Experimental results show that DA-Flow reaches competitive or better\nperformance than the existing state-of-the-art (SOTA) methods in terms of the\nmicro AUC metric with the fewest number of parameters. Moreover, we found that\neven without training, simply using random projection without dimensionality\nreduction on skeleton data enables substantial anomaly detection capabilities.",
      "tldr_zh": "这篇论文针对基于骨骼的视频异常检测 (SVAD) 中，TCN 和 GCN 模块受限于小感受野和缺乏跨维度交互的问题，提出了一种轻量级 Dual Attention Module (DAM)，通过 frame attention 机制识别关键帧，以及 skeleton attention 机制捕捉固定分区间的更广泛关系，以最小参数和计算量提升性能。DAM 被集成到 Dual Attention Normalizing Flow (DA-Flow) 框架中，作为 GCN 的后处理单元，显著提高了模型对噪声和负样本的鲁棒性。实验结果显示，DA-Flow 在 micro AUC 指标上达到或超过现有 SOTA 方法，同时拥有最少的参数；此外，作者发现，仅使用随机投影而不降维的骨骼数据，即使不训练也能实现有效的异常检测能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02976v1",
      "published_date": "2024-06-05 06:18:03 UTC",
      "updated_date": "2024-06-05 06:18:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:40:51.889906"
    },
    {
      "arxiv_id": "2407.16884v1",
      "title": "Cluster Model for parsimonious selection of variables and enhancing Students Employability Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Pooja Thakar",
        "Anil Mehta",
        "Manisha"
      ],
      "abstract": "Educational Data Mining (EDM) is a promising field, where data mining is\nwidely used for predicting students performance. One of the most prevalent and\nrecent challenge that higher education faces today is making students\nskillfully employable. Institutions possess large volume of data; still they\nare unable to reveal knowledge and guide their students. Data in education is\ngenerally very large, multidimensional and unbalanced in nature. Process of\nextracting knowledge from such data has its own set of problems and is a very\ncomplicated task. In this paper, Engineering and MCA (Masters in Computer\nApplications) students data is collected from various universities and\ninstitutes pan India. The dataset is large, unbalanced and multidimensional in\nnature. A cluster based model is presented in this paper, which, when applied\nat preprocessing stage helps in parsimonious selection of variables and\nimproves the performance of predictive algorithms. Hence, facilitate in better\nprediction of Students Employability.",
      "tldr_zh": "本研究聚焦于教育数据挖掘(EDM)，旨在解决高等教育中学生就业能力预测的挑战，该数据通常规模庞大、多维且不平衡，导致知识提取困难。论文收集了印度各大学和机构的工程及MCA学生数据，提出了一种基于聚类(cluster)模型，在预处理阶段进行变量的简约选择(parsimonious selection of variables)，从而提升预测算法的性能。实验结果表明，该模型显著改善了学生就业能力预测的准确性，为教育机构提供更有效的指导工具。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.16884v1",
      "published_date": "2024-06-05 06:06:46 UTC",
      "updated_date": "2024-06-05 06:06:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:41:00.764024"
    },
    {
      "arxiv_id": "2406.02969v2",
      "title": "Filtered not Mixed: Stochastic Filtering-Based Online Gating for Mixture of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Raeid Saqur",
        "Anastasis Kratsios",
        "Florian Krach",
        "Yannick Limmer",
        "Jacob-Junqi Tian",
        "John Willes",
        "Blanka Horvath",
        "Frank Rudzicz"
      ],
      "abstract": "We propose MoE-F - a formalized mechanism for combining $N$ pre-trained Large\nLanguage Models (LLMs) for online time-series prediction by adaptively\nforecasting the best weighting of LLM predictions at every time step. Our\nmechanism leverages the conditional information in each expert's running\nperformance to forecast the best combination of LLMs for predicting the time\nseries in its next step. Diverging from static (learned) Mixture of Experts\n(MoE) methods, our approach employs time-adaptive stochastic filtering\ntechniques to combine experts. By framing the expert selection problem as a\nfinite state-space, continuous-time Hidden Markov model (HMM), we can leverage\nthe Wohman-Shiryaev filter. Our approach first constructs N parallel filters\ncorresponding to each of the $N$ individual LLMs. Each filter proposes its best\ncombination of LLMs, given the information that they have access to.\nSubsequently, the N filter outputs are optimally aggregated to maximize their\nrobust predictive power, and this update is computed efficiently via a\nclosed-form expression, generating our ensemble predictor. Our contributions\nare: **(I)** the MoE-F plug-and-play filtering harness algorithm, **(II)**\ntheoretical optimality guarantees of the proposed filtering-based gating\nalgorithm (via optimality guarantees for its parallel Bayesian filtering and\nits robust aggregation steps), and **(III)** empirical evaluation and ablative\nresults using state-of-the-art foundational and MoE LLMs on a real-world\n__Financial Market Movement__ task where MoE-F attains a remarkable 17\\%\nabsolute and 48.5\\% relative F1 measure improvement over the next best\nperforming individual LLM expert predicting short-horizon market movement based\non streaming news. Further, we provide empirical evidence of substantial\nperformance gains in applying MoE-F over specialized models in the long-horizon\ntime-series forecasting domain.",
      "tldr_zh": "本研究提出了一种名为 MoE-F 的机制，用于动态结合多个预训练 Large Language Models (LLMs)，以实现在线时间序列预测。该方法通过时间自适应随机过滤技术，将专家选择问题建模为有限状态空间的连续时间 Hidden Markov model (HMM)，并利用 Wohman-Shiryaev 过滤器构建 N 个并行过滤器，然后聚合输出以生成最优集成预测器。MoE-F 的主要贡献包括：(I) 一个即插即用的过滤算法，(II) 理论上最优性保证，通过并行 Bayesian 过滤和鲁棒聚合步骤，(III) 在真实金融市场运动任务上的实证表现，实现了 17% 的绝对 F1 measure 提升和 48.5% 的相对改善，并在长horizon 时间序列预测中表现出显著性能优势。相比传统的静态 Mixture of Experts (MoE) 方法，MoE-F 更有效地利用了每个专家的运行性能信息，实现更准确的自适应预测。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "q-fin.CP",
        "q-fin.MF",
        "60J05, 60G35, 68T20, 68T42, 68T50",
        "I.2.6; I.2.7; G.3"
      ],
      "primary_category": "cs.LG",
      "comment": "33 pages, 5 Appendix sections",
      "pdf_url": "http://arxiv.org/pdf/2406.02969v2",
      "published_date": "2024-06-05 05:53:50 UTC",
      "updated_date": "2025-02-20 19:56:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:41:14.858078"
    },
    {
      "arxiv_id": "2406.02966v3",
      "title": "Generative AI and Digital Neocolonialism in Global Education: Towards an Equitable Framework",
      "title_zh": "生成式人工智能与数字新殖民主义在全球教育中：迈向一个公平框架",
      "authors": [
        "Matthew Nyaaba",
        "Alyson Wright",
        "Gyu Lim Choi"
      ],
      "abstract": "This paper critically discusses how generative artificial intelligence\n(GenAI) might impose Western ideologies on non-Western societies, perpetuating\ndigital neocolonialism in education through its inherent biases. It further\nsuggests strategies for local and global stakeholders to mitigate these\neffects. Our discussions demonstrated that GenAI can foster cultural\nimperialism by generating content that primarily incorporates cultural\nreferences and examples relevant to Western students, thereby alienating\nstudents from non-Western backgrounds. Also, the predominant use of Western\nlanguages by GenAI can marginalize non-dominant languages, making educational\ncontent less accessible to speakers of indigenous languages and potentially\nimpacting their ability to learn in their first language. Additionally, GenAI\noften generates content and curricula that reflect the perspectives of\ntechnologically dominant countries, overshadowing marginalized indigenous\nknowledge and practices. Moreover, the cost of access to GenAI intensifies\neducational inequality and the control of GenAI data could lead to commercial\nexploitation without benefiting local students and their communities. We\npropose human-centric reforms to prioritize cultural diversity and equity in\nGenAI development; a liberatory design to empower educators and students to\nidentify and dismantle the oppressive structures within GenAI applications;\nforesight by design to create an adjustable GenAI system to meet future\neducational needs; and finally, effective prompting skills to reduce the\nretrieval of neocolonial outputs.",
      "tldr_zh": "这篇论文探讨了生成式AI (GenAI) 在全球教育中可能 perpetuating digital neocolonialism 的问题，通过其内在偏见强加西方意识形态，进而边缘化非西方文化、语言和土著知识，导致教育不平等加剧。研究发现，GenAI 生成的内容主要以西方参考为主，优先使用西方语言，并反映 technologically dominant 国家的视角，从而 alienating 非西方学生并可能导致商业剥削。论文提出 human-centric reforms 以优先文化多样性和公平、liberatory design 赋权教育者拆除压迫结构、foresight by design 创建可调整系统，以及 effective prompting skills 减少 neocolonial 输出等策略，旨在构建一个更具包容性的教育框架。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02966v3",
      "published_date": "2024-06-05 05:43:55 UTC",
      "updated_date": "2024-06-16 02:57:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:41:26.726227"
    },
    {
      "arxiv_id": "2406.02962v1",
      "title": "Docs2KG: Unified Knowledge Graph Construction from Heterogeneous Documents Assisted by Large Language Models",
      "title_zh": "Docs2KG：",
      "authors": [
        "Qiang Sun",
        "Yuanyi Luo",
        "Wenxiao Zhang",
        "Sirui Li",
        "Jichunyang Li",
        "Kai Niu",
        "Xiangrui Kong",
        "Wei Liu"
      ],
      "abstract": "Even for a conservative estimate, 80% of enterprise data reside in\nunstructured files, stored in data lakes that accommodate heterogeneous\nformats. Classical search engines can no longer meet information seeking needs,\nespecially when the task is to browse and explore for insight formulation. In\nother words, there are no obvious search keywords to use. Knowledge graphs, due\nto their natural visual appeals that reduce the human cognitive load, become\nthe winning candidate for heterogeneous data integration and knowledge\nrepresentation.\n  In this paper, we introduce Docs2KG, a novel framework designed to extract\nmultimodal information from diverse and heterogeneous unstructured documents,\nincluding emails, web pages, PDF files, and Excel files. Dynamically generates\na unified knowledge graph that represents the extracted key information,\nDocs2KG enables efficient querying and exploration of document data lakes.\nUnlike existing approaches that focus on domain-specific data sources or\npre-designed schemas, Docs2KG offers a flexible and extensible solution that\ncan adapt to various document structures and content types. The proposed\nframework unifies data processing supporting a multitude of downstream tasks\nwith improved domain interpretability. Docs2KG is publicly accessible at\nhttps://docs2kg.ai4wa.com, and a demonstration video is available at\nhttps://docs2kg.ai4wa.com/Video.",
      "tldr_zh": "本研究提出了 Docs2KG 框架，利用 Large Language Models 辅助从异构非结构化文档（如电子邮件、网页、PDF 和 Excel 文件）中提取多模态信息，并构建统一的 Knowledge Graph，以支持高效查询和探索企业数据湖。不同于传统方法，该框架采用灵活、可扩展的设计，不依赖特定领域或预设模式，从而提升数据处理的领域可解释性和适用于多种下游任务。Docs2KG 已公开访问，可通过 https://docs2kg.ai4wa.com 体验其功能和演示视频。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02962v1",
      "published_date": "2024-06-05 05:35:59 UTC",
      "updated_date": "2024-06-05 05:35:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:41:38.359610"
    },
    {
      "arxiv_id": "2406.02958v3",
      "title": "PrE-Text: Training Language Models on Private Federated Data in the Age of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Charlie Hou",
        "Akshat Shrivastava",
        "Hongyuan Zhan",
        "Rylan Conway",
        "Trang Le",
        "Adithya Sagar",
        "Giulia Fanti",
        "Daniel Lazar"
      ],
      "abstract": "On-device training is currently the most common approach for training machine\nlearning (ML) models on private, distributed user data. Despite this, on-device\ntraining has several drawbacks: (1) most user devices are too small to train\nlarge models on-device, (2) on-device training is communication- and\ncomputation-intensive, and (3) on-device training can be difficult to debug and\ndeploy. To address these problems, we propose Private Evolution-Text\n(PrE-Text), a method for generating differentially private (DP) synthetic\ntextual data. First, we show that across multiple datasets, training small\nmodels (models that fit on user devices) with PrE-Text synthetic data\noutperforms small models trained on-device under practical privacy regimes\n($\\epsilon=1.29$, $\\epsilon=7.58$). We achieve these results while using\n9$\\times$ fewer rounds, 6$\\times$ less client computation per round, and\n100$\\times$ less communication per round. Second, finetuning large models on\nPrE-Text's DP synthetic data improves large language model (LLM) performance on\nprivate data across the same range of privacy budgets. Altogether, these\nresults suggest that training on DP synthetic data can be a better option than\ntraining a model on-device on private distributed data. Code is available at\nhttps://github.com/houcharlie/PrE-Text.",
      "tldr_zh": "本研究提出 PrE-Text 方法，通过生成差分隐私 (DP) 合成文本数据，解决在大型语言模型 (LLMs) 时代进行私有联邦数据训练的挑战，特别是针对 on-device training 的问题，如设备限制、计算密集和部署难度。实验结果显示，使用 PrE-Text 合成数据训练小模型（适合用户设备）在 ε=1.29 和 ε=7.58 的隐私预算下，性能优于直接 on-device 训练，同时减少9倍轮次、6倍客户端计算和100倍通信量。将 PrE-Text 的 DP 合成数据用于微调大模型，也显著提升了在私有数据上的 LLM 性能。这些发现表明，基于 DP 合成数据的训练比传统 on-device 方法更高效且实用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024 (Oral). Latest revision corrects a discussion on concurrent\n  work arXiv:2403.01749. We described their work as reliant on using\n  closed-sourced models when in reality they also evaluate and use open source\n  models. This has been corrected in this version",
      "pdf_url": "http://arxiv.org/pdf/2406.02958v3",
      "published_date": "2024-06-05 05:27:02 UTC",
      "updated_date": "2024-10-17 19:11:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:41:53.168664"
    },
    {
      "arxiv_id": "2406.02943v1",
      "title": "The Task-oriented Queries Benchmark (ToQB)",
      "title_zh": "任务导向查询基准 (ToQB)",
      "authors": [
        "Keun Soo Yim"
      ],
      "abstract": "Task-oriented queries (e.g., one-shot queries to play videos, order food, or\ncall a taxi) are crucial for assessing the quality of virtual assistants,\nchatbots, and other large language model (LLM)-based services. However, a\nstandard benchmark for task-oriented queries is not yet available, as existing\nbenchmarks in the relevant NLP (Natural Language Processing) fields have\nprimarily focused on task-oriented dialogues. Thus, we present a new\nmethodology for efficiently generating the Task-oriented Queries Benchmark\n(ToQB) using existing task-oriented dialogue datasets and an LLM service. Our\nmethodology involves formulating the underlying NLP task to summarize the\noriginal intent of a speaker in each dialogue, detailing the key steps to\nperform the devised NLP task using an LLM service, and outlining a framework\nfor automating a major part of the benchmark generation process. Through a case\nstudy encompassing three domains (i.e., two single-task domains and one\nmulti-task domain), we demonstrate how to customize the LLM prompts (e.g.,\nomitting system utterances or speaker labels) for those three domains and\ncharacterize the generated task-oriented queries. The generated ToQB dataset is\nmade available to the public. We further discuss new domains that can be added\nto ToQB by community contributors and its practical applications.",
      "tldr_zh": "这篇论文介绍了 Task-oriented Queries Benchmark (ToQB)，一个新的基准数据集，用于评估虚拟助手、聊天机器人和基于 LLM (Large Language Model) 服务的任务导向查询质量，以填补现有 NLP (Natural Language Processing) 基准主要聚焦任务导向对话的空白。研究提出了一种高效方法，利用现有任务导向对话数据集和 LLM 服务，通过总结对话中的说话者意图、自定义提示（如省略系统 utterances 或 speaker labels）和自动化框架来生成 ToQB。经三个领域（两个单任务和一个多任务）的案例研究验证，该方法有效生成高质量查询数据集，并公开可用，鼓励社区扩展新领域及其实际应用，如提升服务评估和优化。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.NE"
      ],
      "primary_category": "cs.IR",
      "comment": "Data available on GitHub,\n  https://github.com/google/task-oriented-queries",
      "pdf_url": "http://arxiv.org/pdf/2406.02943v1",
      "published_date": "2024-06-05 05:05:41 UTC",
      "updated_date": "2024-06-05 05:05:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:42:04.969766"
    },
    {
      "arxiv_id": "2406.02927v1",
      "title": "Multivariate Physics-Informed Convolutional Autoencoder for Anomaly Detection in Power Distribution Systems with High Penetration of DERs",
      "title_zh": "翻译失败",
      "authors": [
        "Mehdi Jabbari Zideh",
        "Sarika Khushalani Solanki"
      ],
      "abstract": "Despite the relentless progress of deep learning models in analyzing the\nsystem conditions under cyber-physical events, their abilities are limited in\nthe power system domain due to data availability issues, cost of data\nacquisition, and lack of interpretation and extrapolation for the data beyond\nthe training windows. In addition, the integration of distributed energy\nresources (DERs) such as wind and solar generations increases the complexities\nand nonlinear nature of power systems. Therefore, an interpretable and reliable\nmethodology is of utmost need to increase the confidence of power system\noperators and their situational awareness for making reliable decisions. This\nhas led to the development of physics-informed neural network (PINN) models as\nmore interpretable, trustworthy, and robust models where the underlying\nprincipled laws are integrated into the training process of neural network\nmodels to achieve improved performance. This paper proposes a multivariate\nphysics-informed convolutional autoencoder (PIConvAE) model to detect cyber\nanomalies in power distribution systems with unbalanced configurations and high\npenetration of DERs. The physical laws are integrated through a customized loss\nfunction that embeds the underlying Kirchhoff's circuit laws into the training\nprocess of the autoencoder. The performance of the multivariate PIConvAE model\nis evaluated on two unbalanced power distribution grids, IEEE 123-bus system\nand a real-world feeder in Riverside, CA. The results show the exceptional\nperformance of the proposed method in detecting various cyber anomalies in both\nsystems. In addition, the model's effectiveness is evaluated in data scarcity\nscenarios with different training data ratios. Finally, the model's performance\nis compared with existing machine learning models where the PIConvAE model\nsurpasses other models with considerably higher detection metrics.",
      "tldr_zh": "本文针对电力系统中的数据可用性问题和高渗透DERs带来的复杂性，提出了一种多变量物理信息卷积自编码器(PIConvAE)模型，用于检测网络异常。该模型通过自定义损失函数嵌入Kirchhoff's circuit laws到训练过程中，提升了模型的可解释性、鲁棒性和性能。在IEEE 123-bus系统和加州Riverside真实馈线上的实验表明，PIConvAE在各种异常检测任务中表现出色，尤其在数据稀缺场景下，并显著优于现有机器学习模型。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02927v1",
      "published_date": "2024-06-05 04:28:57 UTC",
      "updated_date": "2024-06-05 04:28:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:42:16.959711"
    },
    {
      "arxiv_id": "2406.02925v3",
      "title": "Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Hsuan Su",
        "Hua Farn",
        "Fan-Yun Sun",
        "Shang-Tse Chen",
        "Hung-yi Lee"
      ],
      "abstract": "Synthetic data is widely used in speech recognition due to the availability\nof text-to-speech models, which facilitate adapting models to previously unseen\ntext domains. However, existing methods suffer in performance when they\nfine-tune an automatic speech recognition (ASR) model on synthetic data as they\nsuffer from the distributional shift commonly referred to as the\nsynthetic-to-real gap. In this paper, we find that task vector arithmetic is\neffective at mitigating this gap. Our proposed method, SYN2REAL task vector,\nshows an average improvement of 10.03\\% improvement in word error rate over\nbaselines on the SLURP dataset. Additionally, we show that an average of\nSYN2REAL task vectors, when we have real speeches from multiple different\ndomains, can further adapt the original ASR model to perform better on the\ntarget text domain.",
      "tldr_zh": "该论文探讨了使用合成数据训练 Automatic Speech Recognition (ASR) 模型时面临的 synthetic-to-real gap 问题，即合成数据与真实数据的分布差异导致性能下降。研究提出 task vector arithmetic 方法，特别是 SYN2REAL task vector，通过算术操作缓解这一差距，在 SLURP 数据集上实现了比基线模型高 10.03% 的 word error rate 改善。此外，当结合多个不同领域的真实语音时，平均 SYN2REAL task vectors 可以进一步提升 ASR 模型对目标文本领域的适应性能。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02925v3",
      "published_date": "2024-06-05 04:25:56 UTC",
      "updated_date": "2024-10-05 09:06:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:42:27.837801"
    },
    {
      "arxiv_id": "2406.02921v2",
      "title": "Text Injection for Neural Contextual Biasing",
      "title_zh": "翻译失败",
      "authors": [
        "Zhong Meng",
        "Zelin Wu",
        "Rohit Prabhavalkar",
        "Cal Peyser",
        "Weiran Wang",
        "Nanxin Chen",
        "Tara N. Sainath",
        "Bhuvana Ramabhadran"
      ],
      "abstract": "Neural contextual biasing effectively improves automatic speech recognition\n(ASR) for crucial phrases within a speaker's context, particularly those that\nare infrequent in the training data. This work proposes contextual text\ninjection (CTI) to enhance contextual ASR. CTI leverages not only the paired\nspeech-text data, but also a much larger corpus of unpaired text to optimize\nthe ASR model and its biasing component. Unpaired text is converted into\nspeech-like representations and used to guide the model's attention towards\nrelevant bias phrases. Moreover, we introduce a contextual text-injected (CTI)\nminimum word error rate (MWER) training, which minimizes the expected WER\ncaused by contextual biasing when unpaired text is injected into the model.\nExperiments show that CTI with 100 billion text sentences can achieve up to\n43.3% relative WER reduction from a strong neural biasing model. CTI-MWER\nprovides a further relative improvement of 23.5%.",
      "tldr_zh": "这篇论文提出了 Contextual Text Injection (CTI) 方法，以提升神经上下文偏差在自动语音识别 (ASR) 中的性能，特别是针对训练数据中出现频率低的短语。CTI 不仅利用配对的语音-文本数据，还整合大量未配对文本，将其转换为类似语音的表示，以引导模型关注相关偏差短语；同时引入 CTI-MWER 训练，旨在最小化由上下文偏差引起的预期词错误率 (WER)。实验结果显示，使用 100 亿句文本的 CTI 可从强有力的神经偏差模型中实现高达 43.3% 的相对 WER 减少，而 CTI-MWER 进一步带来 23.5% 的相对改善。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2406.02921v2",
      "published_date": "2024-06-05 04:20:17 UTC",
      "updated_date": "2024-06-11 04:11:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:42:40.713512"
    },
    {
      "arxiv_id": "2406.02913v1",
      "title": "Zeroth-Order Fine-Tuning of LLMs with Extreme Sparsity",
      "title_zh": "翻译失败",
      "authors": [
        "Wentao Guo",
        "Jikai Long",
        "Yimeng Zeng",
        "Zirui Liu",
        "Xinyu Yang",
        "Yide Ran",
        "Jacob R. Gardner",
        "Osbert Bastani",
        "Christopher De Sa",
        "Xiaodong Yu",
        "Beidi Chen",
        "Zhaozhuo Xu"
      ],
      "abstract": "Zeroth-order optimization (ZO) is a memory-efficient strategy for fine-tuning\nLarge Language Models using only forward passes. However, the application of ZO\nfine-tuning in memory-constrained settings such as mobile phones and laptops is\nstill challenging since full precision forward passes are infeasible. In this\nstudy, we address this limitation by integrating sparsity and quantization into\nZO fine-tuning of LLMs. Specifically, we investigate the feasibility of\nfine-tuning an extremely small subset of LLM parameters using ZO. This approach\nallows the majority of un-tuned parameters to be quantized to accommodate the\nconstraint of limited device memory. Our findings reveal that the pre-training\nprocess can identify a set of \"sensitive parameters\" that can guide the ZO\nfine-tuning of LLMs on downstream tasks. Our results demonstrate that\nfine-tuning 0.1% sensitive parameters in the LLM with ZO can outperform the\nfull ZO fine-tuning performance, while offering wall-clock time speedup.\nAdditionally, we show that ZO fine-tuning targeting these 0.1% sensitive\nparameters, combined with 4 bit quantization, enables efficient ZO fine-tuning\nof an Llama2-7B model on a GPU device with less than 8 GiB of memory and\nnotably reduced latency.",
      "tldr_zh": "本研究提出了一种在极度稀疏条件下对大型语言模型 (LLMs) 进行 Zeroth-order optimization (ZO) 微调的方法，以应对内存受限设备（如手机或笔记本）的挑战。具体而言，该方法仅微调模型中 0.1% 的“敏感参数”，并将未微调参数量化，从而显著降低内存需求。实验结果显示，这种策略不仅在下游任务上优于完整 ZO 微调，还能加速处理过程；例如，在配备少于 8 GiB 内存的 GPU 上，结合 4 位量化成功微调 Llama2-7B 模型，同时减少延迟。总的来说，该方法为高效、资源友好的 LLM 微调提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02913v1",
      "published_date": "2024-06-05 04:07:35 UTC",
      "updated_date": "2024-06-05 04:07:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:42:53.577081"
    },
    {
      "arxiv_id": "2406.02900v2",
      "title": "Scaling Laws for Reward Model Overoptimization in Direct Alignment Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Rafael Rafailov",
        "Yaswanth Chittepu",
        "Ryan Park",
        "Harshit Sikchi",
        "Joey Hejna",
        "Bradley Knox",
        "Chelsea Finn",
        "Scott Niekum"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) has been crucial to the\nrecent success of Large Language Models (LLMs), however, it is often a complex\nand brittle process. In the classical RLHF framework, a reward model is first\ntrained to represent human preferences, which is in turn used by an online\nreinforcement learning (RL) algorithm to optimize the LLM. A prominent issue\nwith such methods is reward over-optimization or reward hacking, where\nperformance as measured by the learned proxy reward model increases, but true\nquality plateaus or even deteriorates. Direct Alignment Algorithms (DDAs) like\nDirect Preference Optimization have emerged as alternatives to the classical\nRLHF pipeline by circumventing the reward modeling phase. However, although\nDAAs do not use a separate proxy reward model, they still commonly deteriorate\nfrom over-optimization. While the so-called reward hacking phenomenon is not\nwell-defined for DAAs, we still uncover similar trends: at higher KL budgets,\nDAA algorithms exhibit similar degradation patterns to their classic RLHF\ncounterparts. In particular, we find that DAA methods deteriorate not only\nacross a wide range of KL budgets but also often before even a single epoch of\nthe dataset is completed. Through extensive empirical experimentation, this\nwork formulates and formalizes the reward over-optimization or hacking problem\nfor DAAs and explores its consequences across objectives, training regimes, and\nmodel scales.",
      "tldr_zh": "这篇论文探讨了直接对齐算法（Direct Alignment Algorithms, DAAs）中奖励模型过优化的缩放定律问题，类似于传统强化学习从人类反馈（RLHF）中的奖励篡改（reward hacking），导致大型语言模型（LLMs）的性能停滞或下降。作者通过广泛的实证实验，分析了DAAs在不同KL预算、训练制度和模型规模下的退化模式，发现这些算法在高KL预算下表现出类似退化，甚至在完成一个数据集周期前就出现问题。最终，论文正式化了DAAs的过优化问题，并为优化LLMs提供更全面的理解和潜在解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 38th Conference on Neural Information Processing Systems\n  (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.02900v2",
      "published_date": "2024-06-05 03:41:37 UTC",
      "updated_date": "2024-11-05 01:44:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:43:05.928819"
    },
    {
      "arxiv_id": "2407.11987v1",
      "title": "SlicerChat: Building a Local Chatbot for 3D Slicer",
      "title_zh": "SlicerChat：为 3D Slicer 构建本地聊天机器人",
      "authors": [
        "Colton Barr"
      ],
      "abstract": "3D Slicer is a powerful platform for 3D data visualization and analysis, but\nhas a significant learning curve for new users. Generative AI applications,\nsuch as ChatGPT, have emerged as a potential method of bridging the gap between\nvarious sources of documentation using natural language. The limited exposure\nof LLM services to 3D Slicer documentation, however, means that ChatGPT and\nrelated services tend to suffer from significant hallucination. The objective\nof this project is to build a chatbot architecture, called SlicerChat, that is\noptimized to answer 3D Slicer related questions and able to run locally using\nan open-source model. The core research questions explored in this work revolve\naround the answer quality and speed differences due to fine-tuning, model size,\nand the type of domain knowledge included in the prompt. A prototype SlicerChat\nsystem was built as a custom extension in 3D Slicer based on the Code-Llama\nInstruct architecture. Models of size 1.1B, 7B and 13B were fine-tuned using\nLow rank Adaptation, and various sources of 3D Slicer documentation were\ncompiled for use in a Retrieval Augmented Generation paradigm. Testing\ncombinations of fine-tuning and model sizes on a benchmark dataset of five 3D\nSlicer questions revealed that fine-tuning had no impact on model performance\nor speed compared to the base architecture, and that larger models performed\nbetter with a significant speed decrease. Experiments with adding 3D Slicer\ndocumentation to the prompt showed that Python sample code and Markdown\ndocumentation were the most useful information to include, but that adding 3D\nSlicer scene data and questions taken from Discourse also improved model\nperformance. In conclusion, this project shows the potential for integrating a\nhigh quality, local chatbot directly into 3D Slicer to help new users and\nexperienced developers alike to more efficiently use the software.",
      "tldr_zh": "本研究开发了 SlicerChat，一种本地聊天机器人，针对 3D Slicer 软件的用户问题，提供高质量的自然语言回答，以缓解其陡峭的学习曲线和现有 AI 模型的幻觉问题。系统基于 Code-Llama Instruct 架构，使用 Low rank Adaptation 微调 1.1B、7B 和 13B 模型，并采用 Retrieval Augmented Generation (RAG) 技术整合各种 3D Slicer 文档，如 Python 代码和 Markdown 文档。实验结果表明，微调对模型性能和速度无显著影响，而更大模型虽提升了答案质量但降低了速度；添加特定文档类型（如 Python 代码）显著改善了性能。总之，SlicerChat 展示了在 3D Slicer 中集成本地聊天机器人的潜力，帮助新用户和开发人员更高效地使用软件。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11987v1",
      "published_date": "2024-06-05 03:32:06 UTC",
      "updated_date": "2024-06-05 03:32:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:43:20.107837"
    },
    {
      "arxiv_id": "2406.02890v1",
      "title": "Representation Learning For Efficient Deep Multi-Agent Reinforcement Learning",
      "title_zh": "表示学习用于高效深度多智能体强化学习",
      "authors": [
        "Dom Huh",
        "Prasant Mohapatra"
      ],
      "abstract": "Sample efficiency remains a key challenge in multi-agent reinforcement\nlearning (MARL). A promising approach is to learn a meaningful latent\nrepresentation space through auxiliary learning objectives alongside the MARL\nobjective to aid in learning a successful control policy. In our work, we\npresent MAPO-LSO (Multi-Agent Policy Optimization with Latent Space\nOptimization) which applies a form of comprehensive representation learning\ndevised to supplement MARL training. Specifically, MAPO-LSO proposes a\nmulti-agent extension of transition dynamics reconstruction and self-predictive\nlearning that constructs a latent state optimization scheme that can be\ntrivially extended to current state-of-the-art MARL algorithms. Empirical\nresults demonstrate MAPO-LSO to show notable improvements in sample efficiency\nand learning performance compared to its vanilla MARL counterpart without any\nadditional MARL hyperparameter tuning on a diverse suite of MARL tasks.",
      "tldr_zh": "该论文针对多智能体强化学习(MARL)中的样本效率问题，提出了一种新的框架MAPO-LSO（Multi-Agent Policy Optimization with Latent Space Optimization）。该框架通过辅助学习目标实现全面的表示学习，包括多智能体扩展的transition dynamics reconstruction和self-predictive learning，以优化潜在状态空间并辅助策略训练。实验结果显示，MAPO-LSO在各种MARL任务上显著提高了样本效率和学习性能，而无需额外调整MARL超参数。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02890v1",
      "published_date": "2024-06-05 03:11:44 UTC",
      "updated_date": "2024-06-05 03:11:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:43:26.815123"
    },
    {
      "arxiv_id": "2406.02888v3",
      "title": "HYDRA: Model Factorization Framework for Black-Box LLM Personalization",
      "title_zh": "HYDRA：黑箱大语言模型个性化的模型因子分解框架",
      "authors": [
        "Yuchen Zhuang",
        "Haotian Sun",
        "Yue Yu",
        "Rushi Qiang",
        "Qifan Wang",
        "Chao Zhang",
        "Bo Dai"
      ],
      "abstract": "Personalization has emerged as a critical research area in modern intelligent\nsystems, focusing on mining users' behavioral history and adapting to their\npreferences for delivering tailored experiences. Despite the remarkable\nfew-shot capabilities exhibited by black-box large language models (LLMs), the\ninherent opacity of their model parameters presents significant challenges in\naligning the generated output with individual expectations. Existing solutions\nhave primarily focused on prompt design to incorporate user-specific profiles\nand behaviors; however, such approaches often struggle to generalize\neffectively due to their inability to capture shared knowledge among all users.\nTo address these challenges, we propose HYDRA, a model factorization framework\nthat captures both user-specific behavior patterns from historical data and\nshared general knowledge among all users to deliver personalized generation. In\norder to capture user-specific behavior patterns, we first train a reranker to\nprioritize the most useful information from top-retrieved relevant historical\nrecords. By combining the prioritized history with the corresponding query, we\ntrain an adapter to align the output with individual user-specific preferences,\neliminating the reliance on access to inherent model parameters of black-box\nLLMs. Both the reranker and the adapter can be decomposed into a base model\nwith multiple user-specific heads, resembling a hydra. The base model maintains\nshared knowledge across users, while the multiple personal heads capture\nuser-specific preferences. Experimental results demonstrate that HYDRA\noutperforms existing state-of-the-art prompt-based methods by an average\nrelative improvement of 9.01% across five diverse personalization tasks in the\nLaMP benchmark. Our implementation is available at\nhttps://github.com/night-chen/HYDRA.",
      "tldr_zh": "该研究提出 HYDRA，一种模型分解框架，用于黑-box LLM 的个性化，旨在捕捉用户特定行为模式和共享知识，以解决现有提示设计方法的局限性。具体来说，HYDRA 通过训练一个 reranker 来优先处理用户历史记录，并结合一个 adapter 来调整输出以匹配个人偏好，同时将 reranker 和 adapter 构建为一个 base model 加多个用户特定 heads 的结构，其中 base model 维护共享知识，heads 捕捉个性化特征。实验结果显示，在 LaMP benchmark 的五个多样化任务上，HYDRA 比现有最先进提示方法平均提升 9.01%，证明了其在黑-box LLM 个性化方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in NeurIPS'24",
      "pdf_url": "http://arxiv.org/pdf/2406.02888v3",
      "published_date": "2024-06-05 03:08:46 UTC",
      "updated_date": "2024-10-25 21:01:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:43:39.880783"
    },
    {
      "arxiv_id": "2406.02886v2",
      "title": "PLaD: Preference-based Large Language Model Distillation with Pseudo-Preference Pairs",
      "title_zh": "翻译失败",
      "authors": [
        "Rongzhi Zhang",
        "Jiaming Shen",
        "Tianqi Liu",
        "Haorui Wang",
        "Zhen Qin",
        "Feng Han",
        "Jialu Liu",
        "Simon Baumgartner",
        "Michael Bendersky",
        "Chao Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have exhibited impressive capabilities in\nvarious tasks, yet their vast parameter sizes restrict their applicability in\nresource-constrained settings. Knowledge distillation (KD) offers a viable\nsolution by transferring expertise from large teacher models to compact student\nmodels. However, traditional KD techniques face specific challenges when\napplied to LLMs, including restricted access to LLM outputs, significant\nteacher-student capacity gaps, and the inherited mis-calibration issue. In this\nwork, we present PLaD, a novel preference-based LLM distillation framework.\nPLaD exploits the teacher-student capacity discrepancy to generate\npseudo-preference pairs where teacher outputs are preferred over student\noutputs. Then, PLaD leverages a ranking loss to re-calibrate student's\nestimation of sequence likelihood, which steers the student's focus towards\nunderstanding the relative quality of outputs instead of simply imitating the\nteacher. PLaD bypasses the need for access to teacher LLM's internal states,\ntackles the student's expressivity limitations, and mitigates the student\nmis-calibration issue. Through extensive experiments on two sequence generation\ntasks and with various LLMs, we demonstrate the effectiveness of our proposed\nPLaD framework.",
      "tldr_zh": "本研究提出PLaD，一种基于偏好的Large Language Model (LLM) 蒸馏框架，旨在解决传统Knowledge Distillation (KD) 在LLM应用中的挑战，如访问输出受限、师生容量差距和学生模型校准问题。PLaD利用师生容量差异生成伪偏好对（Pseudo-Preference Pairs），其中教师输出被视为优于学生输出，并通过排名损失（Ranking Loss）重新校准学生的序列似然估计，强调输出相对质量而非简单模仿。实验结果显示，在两个序列生成任务上，PLaD框架在使用各种LLMs时表现出色，有效提升了学生的性能和鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02886v2",
      "published_date": "2024-06-05 03:08:25 UTC",
      "updated_date": "2024-06-06 12:47:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:43:53.501601"
    },
    {
      "arxiv_id": "2406.02882v3",
      "title": "Outdated Issue Aware Decoding for Reasoning Questions on Edited Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Zengkui Sun",
        "Yijin Liu",
        "Jiaan Wang",
        "Fandong Meng",
        "Jinan Xu",
        "Yufeng Chen",
        "Jie Zhou"
      ],
      "abstract": "Recently, Knowledge Editing has received increasing attention, since it could\nupdate the specific knowledge from outdated ones in pretrained models without\nre-training. However, as pointed out by recent studies, existing related\nmethods tend to merely memorize the superficial word composition of the edited\nknowledge, rather than truly learning and absorbing it. Consequently, on the\nreasoning questions, we discover that existing methods struggle to utilize the\nedited knowledge to reason the new answer, and tend to retain outdated\nresponses, which are generated by the original models utilizing original\nknowledge. Nevertheless, the outdated responses are unexpected for the correct\nanswers to reasoning questions, which we named as the outdated issue. To\nalleviate this issue, in this paper, we propose a simple yet effective decoding\nstrategy, i.e., outDated ISsue aware deCOding (DISCO), to enhance the\nperformance of edited models on reasoning questions. Specifically, we capture\nthe difference in the probability distribution between the original and edited\nmodels. Further, we amplify the difference of the token prediction in the\nedited model to alleviate the outdated issue, and thus enhance the model\nperformance w.r.t the edited knowledge. Experimental results suggest that\napplying DISCO could enhance edited models to reason, e.g., on reasoning\nquestions, DISCO outperforms the prior SOTA method by 12.99 F1 scores, and\nreduces the ratio of the outdated issue to 5.78% on the zsRE dataset.",
      "tldr_zh": "该论文解决了知识编辑（Knowledge Editing）中模型在推理问题上无法有效利用更新后的知识，而是保留过时响应（outdated responses）的问题，称为 outdated issue。作者提出了一种简单有效的解码策略DISCO（outDated ISsue aware deCOding），通过捕捉原模型和编辑模型之间概率分布的差异，并放大编辑模型中令牌预测的差异，以提升模型对编辑知识的推理能力。实验结果显示，DISCO 在推理任务上比现有最先进（SOTA）方法提高了 12.99 F1 scores，并在 zsRE 数据集上将 outdated issue 比例降低到 5.78%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL2024 Findings, Codes are at https://github.com/Acerkoo/DISCO",
      "pdf_url": "http://arxiv.org/pdf/2406.02882v3",
      "published_date": "2024-06-05 03:00:15 UTC",
      "updated_date": "2024-06-16 08:50:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:44:06.840989"
    },
    {
      "arxiv_id": "2406.06584v1",
      "title": "Evaluating the Efficacy of Large Language Models in Detecting Fake News: A Comparative Analysis",
      "title_zh": "评估大型语言模型在检测假新闻方面的有效性：比较分析",
      "authors": [
        "Sahas Koka",
        "Anthony Vuong",
        "Anish Kataria"
      ],
      "abstract": "In an era increasingly influenced by artificial intelligence, the detection\nof fake news is crucial, especially in contexts like election seasons where\nmisinformation can have significant societal impacts. This study evaluates the\neffectiveness of various LLMs in identifying and filtering fake news content.\nUtilizing a comparative analysis approach, we tested four large LLMs -- GPT-4,\nClaude 3 Sonnet, Gemini Pro 1.0, and Mistral Large -- and two smaller LLMs --\nGemma 7B and Mistral 7B. By using fake news dataset samples from Kaggle, this\nresearch not only sheds light on the current capabilities and limitations of\nLLMs in fake news detection but also discusses the implications for developers\nand policymakers in enhancing AI-driven informational integrity.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 在检测假新闻方面的有效性，通过比较分析方法测试了 GPT-4、Claude 3 Sonnet、Gemini Pro 1.0 和 Mistral Large 等四大模型，以及 Gemma 7B 和 Mistral 7B 等两小模型。研究利用 Kaggle 的假新闻数据集样本，揭示了这些 LLMs 的当前能力和限制，例如在识别误信息时的表现。最终，论文讨论了这些发现对开发者和政策制定者的启示，以增强 AI 驱动的信息完整性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06584v1",
      "published_date": "2024-06-05 02:55:21 UTC",
      "updated_date": "2024-06-05 02:55:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:44:17.549946"
    },
    {
      "arxiv_id": "2406.02880v2",
      "title": "Controllable Talking Face Generation by Implicit Facial Keypoints Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Zhao",
        "Jiaying Shi",
        "Wenjun Li",
        "Shudong Wang",
        "Shenghui Xu",
        "Zhaoming Pan"
      ],
      "abstract": "Audio-driven talking face generation has garnered significant interest within\nthe domain of digital human research. Existing methods are encumbered by\nintricate model architectures that are intricately dependent on each other,\ncomplicating the process of re-editing image or video inputs. In this work, we\npresent ControlTalk, a talking face generation method to control face\nexpression deformation based on driven audio, which can construct the head pose\nand facial expression including lip motion for both single image or sequential\nvideo inputs in a unified manner. By utilizing a pre-trained video synthesis\nrenderer and proposing the lightweight adaptation, ControlTalk achieves precise\nand naturalistic lip synchronization while enabling quantitative control over\nmouth opening shape. Our experiments show that our method is superior to\nstate-of-the-art performance on widely used benchmarks, including HDTF and\nMEAD. The parameterized adaptation demonstrates remarkable generalization\ncapabilities, effectively handling expression deformation across same-ID and\ncross-ID scenarios, and extending its utility to out-of-domain portraits,\nregardless of languages. Code is available at\nhttps://github.com/NetEase-Media/ControlTalk.",
      "tldr_zh": "本研究提出ControlTalk，一种基于隐式面部关键点编辑的音频驱动说话面部生成方法，能够精确控制面部表情变形，包括头部姿势和唇部动作，适用于单张图像或视频序列。ControlTalk 利用预训练视频合成渲染器和轻量级适应技术，实现自然唇同步和对嘴巴张开形状的量化控制，解决了现有方法的模型复杂性和编辑难题。实验结果显示，该方法在HDTF和MEAD基准上优于现有技术，并展示出强大的泛化能力，支持同ID/跨ID表情变形和不同语言的外部领域肖像。开源代码可从https://github.com/NetEase-Media/ControlTalk获取。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02880v2",
      "published_date": "2024-06-05 02:54:46 UTC",
      "updated_date": "2024-11-07 02:26:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:44:29.547000"
    },
    {
      "arxiv_id": "2406.02876v2",
      "title": "LCS: A Language Converter Strategy for Zero-Shot Neural Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Zengkui Sun",
        "Yijin Liu",
        "Fandong Meng",
        "Jinan Xu",
        "Yufeng Chen",
        "Jie Zhou"
      ],
      "abstract": "Multilingual neural machine translation models generally distinguish\ntranslation directions by the language tag (LT) in front of the source or\ntarget sentences. However, current LT strategies cannot indicate the desired\ntarget language as expected on zero-shot translation, i.e., the off-target\nissue. Our analysis reveals that the indication of the target language is\nsensitive to the placement of the target LT. For example, when placing the\ntarget LT on the decoder side, the indication would rapidly degrade along with\ndecoding steps, while placing the target LT on the encoder side would lead to\ncopying or paraphrasing the source input. To address the above issues, we\npropose a simple yet effective strategy named Language Converter Strategy\n(LCS). By introducing the target language embedding into the top encoder\nlayers, LCS mitigates confusion in the encoder and ensures stable language\nindication for the decoder. Experimental results on MultiUN, TED, and OPUS-100\ndatasets demonstrate that LCS could significantly mitigate the off-target\nissue, with language accuracy up to 95.28%, 96.21%, and 85.35% meanwhile\noutperforming the vanilla LT strategy by 3.07, 3,3, and 7.93 BLEU scores on\nzero-shot translation, respectively.",
      "tldr_zh": "本文提出 Language Converter Strategy (LCS)，一种简单有效的策略，用于解决零样本神经机器翻译 (Zero-Shot Neural Machine Translation) 中的 off-target 问题，即语言标签 (LT) 无法正确指示目标语言。LCS 通过将目标语言嵌入引入到编码器顶层，缓解编码器的混淆并确保解码器的稳定语言指示，从而避免了原有策略在解码步骤中出现的指示下降或源输入复制问题。在 MultiUN、TED 和 OPUS-100 数据集上的实验表明，LCS 将语言准确率提升至 95.28%、96.21% 和 85.35%，并分别比原 LT 策略提高了 3.07、3.3 和 7.93 BLEU 分数。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL2024 Findings, Codes are at https://github.com/Acerkoo/LCS",
      "pdf_url": "http://arxiv.org/pdf/2406.02876v2",
      "published_date": "2024-06-05 02:52:17 UTC",
      "updated_date": "2024-06-06 03:22:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:44:45.147347"
    },
    {
      "arxiv_id": "2406.02872v2",
      "title": "Combinatorial Optimization with Automated Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Liu",
        "Peng Zhang",
        "Yang Gao",
        "Chuan Zhou",
        "Zhao Li",
        "Hongyang Chen"
      ],
      "abstract": "In recent years, graph neural networks (GNNs) have become increasingly\npopular for solving NP-hard combinatorial optimization (CO) problems, such as\nmaximum cut and maximum independent set. The core idea behind these methods is\nto represent a CO problem as a graph and then use GNNs to learn the node/graph\nembedding with combinatorial information. Although these methods have achieved\npromising results, given a specific CO problem, the design of GNN architectures\nstill requires heavy manual work with domain knowledge. Existing automated GNNs\nare mostly focused on traditional graph learning problems, which is\ninapplicable to solving NP-hard CO problems. To this end, we present a new\nclass of \\textbf{AUTO}mated \\textbf{G}NNs for solving \\textbf{NP}-hard\nproblems, namely \\textbf{AutoGNP}. We represent CO problems by GNNs and focus\non two specific problems, i.e., mixed integer linear programming and quadratic\nunconstrained binary optimization. The idea of AutoGNP is to use graph neural\narchitecture search algorithms to automatically find the best GNNs for a given\nNP-hard combinatorial optimization problem. Compared with existing graph neural\narchitecture search algorithms, AutoGNP utilizes two-hop operators in the\narchitecture search space. Moreover, AutoGNP utilizes simulated annealing and a\nstrict early stopping policy to avoid local optimal solutions. Empirical\nresults on benchmark combinatorial problems demonstrate the superiority of our\nproposed model.",
      "tldr_zh": "该研究针对 NP-hard 组合优化 (CO) 问题（如 maximum cut 和 maximum independent set），提出了一种自动图神经网络（AutoGNP）框架，以减少手动设计 GNNs 架构的复杂性。AutoGNP 通过图神经架构搜索算法自动优化 GNNs，用于解决 mixed integer linear programming 和 quadratic unconstrained binary optimization 等问题，并引入 two-hop operators、simulated annealing 和严格 early stopping 策略来避免局部最优解。实验结果显示，AutoGNP 在基准 CO 问题上表现出优越性能，证明了其在提升效率和准确性方面的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.02872v2",
      "published_date": "2024-06-05 02:43:41 UTC",
      "updated_date": "2024-06-10 02:45:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:44:53.841691"
    },
    {
      "arxiv_id": "2406.02871v1",
      "title": "Sound Heuristic Search Value Iteration for Undiscounted POMDPs with Reachability Objectives",
      "title_zh": "可靠",
      "authors": [
        "Qi Heng Ho",
        "Martin S. Feather",
        "Federico Rossi",
        "Zachary N. Sunberg",
        "Morteza Lahijanian"
      ],
      "abstract": "Partially Observable Markov Decision Processes (POMDPs) are powerful models\nfor sequential decision making under transition and observation uncertainties.\nThis paper studies the challenging yet important problem in POMDPs known as the\n(indefinite-horizon) Maximal Reachability Probability Problem (MRPP), where the\ngoal is to maximize the probability of reaching some target states. This is\nalso a core problem in model checking with logical specifications and is\nnaturally undiscounted (discount factor is one). Inspired by the success of\npoint-based methods developed for discounted problems, we study their\nextensions to MRPP. Specifically, we focus on trial-based heuristic search\nvalue iteration techniques and present a novel algorithm that leverages the\nstrengths of these techniques for efficient exploration of the belief space\n(informed search via value bounds) while addressing their drawbacks in handling\nloops for indefinite-horizon problems. The algorithm produces policies with\ntwo-sided bounds on optimal reachability probabilities. We prove convergence to\nan optimal policy from below under certain conditions. Experimental evaluations\non a suite of benchmarks show that our algorithm outperforms existing methods\nin almost all cases in both probability guarantees and computation time.",
      "tldr_zh": "该论文研究了无折扣（undiscounted）部分可观测马尔可夫决策过程（POMDPs）中的最大可达概率问题（MRPP），目标是最大化到达目标状态的概率。作者提出了一种新型算法，基于启发式搜索值迭代（heuristic search value iteration）技术，通过高效探索信念空间并处理无限时限问题中的循环，生成带有两侧边界的策略。算法在特定条件下证明了从下界收敛到最优策略。实验结果显示，在一系列基准测试中，该算法在概率保证和计算时间上几乎在所有情况下优于现有方法。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the Conference on Uncertainty in Artificial Intelligence\n  (UAI) 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02871v1",
      "published_date": "2024-06-05 02:33:50 UTC",
      "updated_date": "2024-06-05 02:33:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:45:07.639921"
    },
    {
      "arxiv_id": "2406.02867v1",
      "title": "Oscillations enhance time-series prediction in reservoir computing with feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Yuji Kawai",
        "Takashi Morita",
        "Jihoon Park",
        "Minoru Asada"
      ],
      "abstract": "Reservoir computing, a machine learning framework used for modeling the\nbrain, can predict temporal data with little observations and minimal\ncomputational resources. However, it is difficult to accurately reproduce the\nlong-term target time series because the reservoir system becomes unstable.\nThis predictive capability is required for a wide variety of time-series\nprocessing, including predictions of motor timing and chaotic dynamical\nsystems. This study proposes oscillation-driven reservoir computing (ODRC) with\nfeedback, where oscillatory signals are fed into a reservoir network to\nstabilize the network activity and induce complex reservoir dynamics. The ODRC\ncan reproduce long-term target time series more accurately than conventional\nreservoir computing methods in a motor timing and chaotic time-series\nprediction tasks. Furthermore, it generates a time series similar to the target\nin the unexperienced period, that is, it can learn the abstract generative\nrules from limited observations. Given these significant improvements made by\nthe simple and computationally inexpensive implementation, the ODRC would serve\nas a practical model of various time series data. Moreover, we will discuss\nbiological implications of the ODRC, considering it as a model of neural\noscillations and their cerebellar processors.",
      "tldr_zh": "本研究探讨了 reservoir computing 在时间序列预测中的挑战，特别是系统不稳定导致难以准确重现长期目标序列的问题。作者提出 oscillation-driven reservoir computing (ODRC) with feedback 方法，通过向 reservoir network 输入振荡信号来稳定网络活动并诱导复杂动态，从而提升预测性能。实验结果显示，ODRC 在运动定时和混沌时间序列预测任务中比传统方法更精确地重现目标序列，并能从有限观察中学习抽象生成规则，具有重要的生物学含义和实际应用价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02867v1",
      "published_date": "2024-06-05 02:30:29 UTC",
      "updated_date": "2024-06-05 02:30:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:45:18.464849"
    },
    {
      "arxiv_id": "2406.02864v1",
      "title": "NUMCoT: Numerals and Units of Measurement in Chain-of-Thought Reasoning using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ancheng Xu",
        "Minghuan Tan",
        "Lei Wang",
        "Min Yang",
        "Ruifeng Xu"
      ],
      "abstract": "Numeral systems and units of measurement are two conjoined topics in\nactivities of human beings and have mutual effects with the languages\nexpressing them. Currently, the evaluation of Large Language Models (LLMs)\noften involves mathematical reasoning, yet little attention is given to how\nminor changes in numbers or units can drastically alter the complexity of\nproblems and the performance of LLMs. In this paper, we scrutinize existing\nLLMs on processing of numerals and units of measurement by constructing\ndatasets with perturbations. We first anatomize the reasoning of math word\nproblems to different sub-procedures like numeral conversions from language to\nnumbers and measurement conversions based on units. Then we further annotate\nmath word problems from ancient Chinese arithmetic works which are challenging\nin numerals and units of measurement. Experiments on perturbed datasets\ndemonstrate that LLMs still encounter difficulties in handling numeral and\nmeasurement conversions.",
      "tldr_zh": "本论文探讨了数字系统和测量单位在大型语言模型（LLMs）链式思维推理（Chain-of-Thought Reasoning）中的处理问题，强调这些元素的小幅变化如何影响模型性能。研究者构建了带有扰动的数据集，并分析数学文字问题的子过程，如从语言到数字的numeral conversions和基于单位的measurement conversions，同时标注了古代中国算术作品中的挑战性问题。实验结果显示，现有LLMs在处理numeral和measurement conversions时仍存在显著困难，为提升LLMs在实际应用中的鲁棒性提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.02864v1",
      "published_date": "2024-06-05 02:26:14 UTC",
      "updated_date": "2024-06-05 02:26:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:45:31.282695"
    },
    {
      "arxiv_id": "2406.02856v5",
      "title": "Xmodel-LM Technical Report",
      "title_zh": "Xmodel-LM 技术报告",
      "authors": [
        "Yichuan Wang",
        "Yang Liu",
        "Yu Yan",
        "Qun Wang",
        "Xucheng Huang",
        "Ling Jiang"
      ],
      "abstract": "We introduce Xmodel-LM, a compact and efficient 1.1B language model\npre-trained on around 2 trillion tokens. Trained on our self-built dataset\n(Xdata), which balances Chinese and English corpora based on downstream task\noptimization, Xmodel-LM exhibits remarkable performance despite its smaller\nsize. It notably surpasses existing open-source language models of similar\nscale. Our model checkpoints and code are publicly accessible on GitHub at\nhttps://github.com/XiaoduoAILab/XmodelLM.",
      "tldr_zh": "我们引入了 Xmodel-LM，这是一个紧凑高效的 1.1B 参数语言模型，在约 2 万亿 tokens 的自建数据集 Xdata 上预训练。Xdata 通过基于下游任务优化的方法平衡了中文和英文语料，确保模型在不同语言上的表现。实验结果显示，Xmodel-LM 尽管规模较小，却超过了同等规模的开源语言模型；模型检查点和代码已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02856v5",
      "published_date": "2024-06-05 02:12:06 UTC",
      "updated_date": "2024-11-19 08:38:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:45:41.882691"
    },
    {
      "arxiv_id": "2406.02841v1",
      "title": "Conditional Idempotent Generative Networks",
      "title_zh": "条件幂等生成网络",
      "authors": [
        "Niccolò Ronchetti"
      ],
      "abstract": "We propose Conditional Idempotent Generative Networks (CIGN), a novel\napproach that expands upon Idempotent Generative Networks (IGN) to enable\nconditional generation. While IGNs offer efficient single-pass generation, they\nlack the ability to control the content of the generated data. CIGNs address\nthis limitation by incorporating conditioning mechanisms, allowing users to\nsteer the generation process towards specific types of data.\n  We establish the theoretical foundations for CIGNs, outlining their scope,\nloss function design, and evaluation metrics. We then present two potential\narchitectures for implementing CIGNs: channel conditioning and filter\nconditioning. Finally, we discuss experimental results on the MNIST dataset,\ndemonstrating the effectiveness of both approaches. Our findings pave the way\nfor further exploration of CIGNs on larger datasets and with more powerful\ncomputing resources to determine the optimal implementation strategy.",
      "tldr_zh": "本论文提出 Conditional Idempotent Generative Networks (CIGN)，一种扩展 Idempotent Generative Networks (IGN) 的新方法，允许用户通过条件机制控制生成内容，从而克服 IGN 在单次生成效率高但缺乏灵活性的局限。CIGN 建立了理论基础，包括损失函数设计、评估指标以及两种实现架构：channel conditioning 和 filter conditioning。实验结果在 MNIST 数据集上验证了这些方法的有效性，为未来在更大数据集上的优化和应用提供了方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.02841v1",
      "published_date": "2024-06-05 01:31:50 UTC",
      "updated_date": "2024-06-05 01:31:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:45:55.390569"
    },
    {
      "arxiv_id": "2406.02827v1",
      "title": "Stochastic Diffusion: A Diffusion Probabilistic Model for Stochastic Time Series Forecasting",
      "title_zh": "随机扩散：一种用于随机时间序列预测的扩散概率模型",
      "authors": [
        "Yuansan Liu",
        "Sudanthi Wijewickrema",
        "Dongting Hu",
        "Christofer Bester",
        "Stephen O'Leary",
        "James Bailey"
      ],
      "abstract": "Recent innovations in diffusion probabilistic models have paved the way for\nsignificant progress in image, text and audio generation, leading to their\napplications in generative time series forecasting. However, leveraging such\nabilities to model highly stochastic time series data remains a challenge. In\nthis paper, we propose a novel Stochastic Diffusion (StochDiff) model which\nlearns data-driven prior knowledge at each time step by utilizing the\nrepresentational power of the stochastic latent spaces to model the variability\nof the multivariate time series data. The learnt prior knowledge helps the\nmodel to capture complex temporal dynamics and the inherent uncertainty of the\ndata. This improves its ability to model highly stochastic time series data.\nThrough extensive experiments on real-world datasets, we demonstrate the\neffectiveness of our proposed model on stochastic time series forecasting.\nAdditionally, we showcase an application of our model for real-world surgical\nguidance, highlighting its potential to benefit the medical community.",
      "tldr_zh": "本文提出了一种新型扩散概率模型Stochastic Diffusion (StochDiff)，用于处理高度随机的多变量时间序列预测。该模型通过学习数据驱动的先验知识和利用随机潜在空间，捕捉复杂的时间动态以及数据的固有不确定性，从而提升了对随机数据的建模能力。在真实世界数据集上的广泛实验中，StochDiff展示了优越的预测性能，并展示了其在手术指导等实际应用中的潜力，为医疗社区带来潜在益处。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.02827v1",
      "published_date": "2024-06-05 00:13:38 UTC",
      "updated_date": "2024-06-05 00:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T16:46:08.317708"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 122,
  "processed_papers_count": 122,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T16:46:41.830095"
}