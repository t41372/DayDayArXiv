[
  {
    "arxiv_id": "2406.03651v1",
    "title": "Inductive Generalization in Reinforcement Learning from Specifications",
    "authors": [
      "Vignesh Subramanian",
      "Rohit Kushwah",
      "Subhajit Roy",
      "Suguman Bansal"
    ],
    "abstract": "We present a novel inductive generalization framework for RL from logical\nspecifications. Many interesting tasks in RL environments have a natural\ninductive structure. These inductive tasks have similar overarching goals but\nthey differ inductively in low-level predicates and distributions. We present a\ngeneralization procedure that leverages this inductive relationship to learn a\nhigher-order function, a policy generator, that generates appropriately adapted\npolicies for instances of an inductive task in a zero-shot manner. An\nevaluation of the proposed approach on a set of challenging control benchmarks\ndemonstrates the promise of our framework in generalizing to unseen policies\nfor long-horizon tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03651v1",
    "published_date": "2024-06-05 23:06:48 UTC",
    "updated_date": "2024-06-05 23:06:48 UTC"
  },
  {
    "arxiv_id": "2406.03647v2",
    "title": "Decision-focused Graph Neural Networks for Combinatorial Optimization",
    "authors": [
      "Yang Liu",
      "Chuan Zhou",
      "Peng Zhang",
      "Shirui Pan",
      "Zhao Li",
      "Hongyang Chen"
    ],
    "abstract": "In recent years, there has been notable interest in investigating\ncombinatorial optimization (CO) problems by neural-based framework. An emerging\nstrategy to tackle these challenging problems involves the adoption of graph\nneural networks (GNNs) as an alternative to traditional algorithms, a subject\nthat has attracted considerable attention. Despite the growing popularity of\nGNNs and traditional algorithm solvers in the realm of CO, there is limited\nresearch on their integrated use and the correlation between them within an\nend-to-end framework. The primary focus of our work is to formulate a more\nefficient and precise framework for CO by employing decision-focused learning\non graphs. Additionally, we introduce a decision-focused framework that\nutilizes GNNs to address CO problems with auxiliary support. To realize an\nend-to-end approach, we have designed two cascaded modules: (a) an unsupervised\ntrained graph predictive model, and (b) a solver for quadratic binary\nunconstrained optimization. Empirical evaluations are conducted on various\nclassical tasks, including maximum cut, maximum independent set, and minimum\nvertex cover. The experimental results on classical CO problems (i.e. MaxCut,\nMIS, and MVC) demonstrate the superiority of our method over both the\nstandalone GNN approach and classical methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.03647v2",
    "published_date": "2024-06-05 22:52:27 UTC",
    "updated_date": "2024-06-10 00:53:40 UTC"
  },
  {
    "arxiv_id": "2406.03641v2",
    "title": "Task and Motion Planning for Execution in the Real",
    "authors": [
      "Tianyang Pan",
      "Rahul Shome",
      "Lydia E. Kavraki"
    ],
    "abstract": "Task and motion planning represents a powerful set of hybrid planning methods\nthat combine reasoning over discrete task domains and continuous motion\ngeneration. Traditional reasoning necessitates task domain models and enough\ninformation to ground actions to motion planning queries. Gaps in this\nknowledge often arise from sources like occlusion or imprecise modeling. This\nwork generates task and motion plans that include actions cannot be fully\ngrounded at planning time. During execution, such an action is handled by a\nprovided human-designed or learned closed-loop behavior. Execution combines\noffline planned motions and online behaviors till reaching the task goal.\nFailures of behaviors are fed back as constraints to find new plans. Forty\nreal-robot trials and motivating demonstrations are performed to evaluate the\nproposed framework and compare against state-of-the-art. Results show faster\nexecution time, less number of actions, and more success in problems where\ndiverse gaps arise. The experiment data is shared for researchers to simulate\nthese settings. The work shows promise in expanding the applicable class of\nrealistic partially grounded problems that robots can address.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "I.2.9; I.2.8"
    ],
    "primary_category": "cs.RO",
    "comment": "15 pages, 14 figures, 2 tables, accepted by IEEE Transactions on\n  Robotics",
    "pdf_url": "http://arxiv.org/pdf/2406.03641v2",
    "published_date": "2024-06-05 22:30:40 UTC",
    "updated_date": "2024-06-13 16:05:27 UTC"
  },
  {
    "arxiv_id": "2406.03630v1",
    "title": "Active ML for 6G: Towards Efficient Data Generation, Acquisition, and Annotation",
    "authors": [
      "Omar Alhussein",
      "Ning Zhang",
      "Sami Muhaidat",
      "Weihua Zhuang"
    ],
    "abstract": "This paper explores the integration of active machine learning (ML) for 6G\nnetworks, an area that remains under-explored yet holds potential. Unlike\npassive ML systems, active ML can be made to interact with the network\nenvironment. It actively selects informative and representative data points for\ntraining, thereby reducing the volume of data needed while accelerating the\nlearning process. While active learning research mainly focuses on data\nannotation, we call for a network-centric active learning framework that\nconsiders both annotation (i.e., what is the label) and data acquisition (i.e.,\nwhich and how many samples to collect). Moreover, we explore the synergy\nbetween generative artificial intelligence (AI) and active learning to overcome\nexisting limitations in both active learning and generative AI. This paper also\nfeatures a case study on a mmWave throughput prediction problem to demonstrate\nthe practical benefits and improved performance of active learning for 6G\nnetworks. Furthermore, we discuss how the implications of active learning\nextend to numerous 6G network use cases. We highlight the potential of active\nlearning based 6G networks to enhance computational efficiency, data annotation\nand acquisition efficiency, adaptability, and overall network intelligence. We\nconclude with a discussion on challenges and future research directions for\nactive learning in 6G networks, including development of novel query\nstrategies, distributed learning integration, and inclusion of human- and\nmachine-in-the-loop learning.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "Submitted to IEEE Network Magazine",
    "pdf_url": "http://arxiv.org/pdf/2406.03630v1",
    "published_date": "2024-06-05 21:29:05 UTC",
    "updated_date": "2024-06-05 21:29:05 UTC"
  },
  {
    "arxiv_id": "2406.03625v1",
    "title": "Degrees of Freedom Matter: Inferring Dynamics from Point Trajectories",
    "authors": [
      "Yan Zhang",
      "Sergey Prokudin",
      "Marko Mihajlovic",
      "Qianli Ma",
      "Siyu Tang"
    ],
    "abstract": "Understanding the dynamics of generic 3D scenes is fundamentally challenging\nin computer vision, essential in enhancing applications related to scene\nreconstruction, motion tracking, and avatar creation. In this work, we address\nthe task as the problem of inferring dense, long-range motion of 3D points. By\nobserving a set of point trajectories, we aim to learn an implicit motion field\nparameterized by a neural network to predict the movement of novel points\nwithin the same domain, without relying on any data-driven or scene-specific\npriors. To achieve this, our approach builds upon the recently introduced\ndynamic point field model that learns smooth deformation fields between the\ncanonical frame and individual observation frames. However, temporal\nconsistency between consecutive frames is neglected, and the number of required\nparameters increases linearly with the sequence length due to per-frame\nmodeling. To address these shortcomings, we exploit the intrinsic\nregularization provided by SIREN, and modify the input layer to produce a\nspatiotemporally smooth motion field. Additionally, we analyze the motion field\nJacobian matrix, and discover that the motion degrees of freedom (DOFs) in an\ninfinitesimal area around a point and the network hidden variables have\ndifferent behaviors to affect the model's representational power. This enables\nus to improve the model representation capability while retaining the model\ncompactness. Furthermore, to reduce the risk of overfitting, we introduce a\nregularization term based on the assumption of piece-wise motion smoothness.\nOur experiments assess the model's performance in predicting unseen point\ntrajectories and its application in temporal mesh alignment with guidance. The\nresults demonstrate its superiority and effectiveness. The code and data for\nthe project are publicly available:\n\\url{https://yz-cnsdqz.github.io/eigenmotion/DOMA/}",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "cvpr24 post camera ready",
    "pdf_url": "http://arxiv.org/pdf/2406.03625v1",
    "published_date": "2024-06-05 21:02:10 UTC",
    "updated_date": "2024-06-05 21:02:10 UTC"
  },
  {
    "arxiv_id": "2406.03600v1",
    "title": "Knowledge-Infused Legal Wisdom: Navigating LLM Consultation through the Lens of Diagnostics and Positive-Unlabeled Reinforcement Learning",
    "authors": [
      "Yang Wu",
      "Chenghao Wang",
      "Ece Gumusel",
      "Xiaozhong Liu"
    ],
    "abstract": "The integration of generative Large Language Models (LLMs) into various\napplications, including the legal domain, has been accelerated by their\nexpansive and versatile nature. However, when facing a legal case, users\nwithout a legal background often struggle to formulate professional queries and\nmay inadvertently overlook critical legal factors when presenting their case\nnarrative to LLMs. To address this issue, we propose the Diagnostic Legal Large\nLanguage Model (D3LM), which utilizes adaptive lawyer-like diagnostic questions\nto collect additional case information and then provides high-quality feedback.\nD3LM incorporates an innovative graph-based Positive-Unlabeled Reinforcement\nLearning (PURL) algorithm, enabling the generation of critical questions and\nenhancing user-LLM interactions. Moreover, an integrated LLM-based stopping\ncriterion facilitates precise Court Views Generation (CVG). Our research also\nintroduces a new English-language CVG dataset based on the US case law\ndatabase, enriching the realm of LLM research and deployment with a vital\ndimension. D3LM surpasses classical LLMs by delivering outstanding performance\nand a remarkable user experience in the legal domain.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL Findings 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.03600v1",
    "published_date": "2024-06-05 19:47:35 UTC",
    "updated_date": "2024-06-05 19:47:35 UTC"
  },
  {
    "arxiv_id": "2406.03594v1",
    "title": "Why is \"Problems\" Predictive of Positive Sentiment? A Case Study of Explaining Unintuitive Features in Sentiment Classification",
    "authors": [
      "Jiaming Qu",
      "Jaime Arguello",
      "Yue Wang"
    ],
    "abstract": "Explainable AI (XAI) algorithms aim to help users understand how a machine\nlearning model makes predictions. To this end, many approaches explain which\ninput features are most predictive of a target label. However, such\nexplanations can still be puzzling to users (e.g., in product reviews, the word\n\"problems\" is predictive of positive sentiment). If left unexplained, puzzling\nexplanations can have negative impacts. Explaining unintuitive associations\nbetween an input feature and a target label is an underexplored area in XAI\nresearch. We take an initial effort in this direction using unintuitive\nassociations learned by sentiment classifiers as a case study. We propose\napproaches for (1) automatically detecting associations that can appear\nunintuitive to users and (2) generating explanations to help users understand\nwhy an unintuitive feature is predictive. Results from a crowdsourced study\n(N=300) found that our proposed approaches can effectively detect and explain\npredictive but unintuitive features in sentiment classification.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03594v1",
    "published_date": "2024-06-05 19:31:19 UTC",
    "updated_date": "2024-06-05 19:31:19 UTC"
  },
  {
    "arxiv_id": "2406.03592v1",
    "title": "Measuring Retrieval Complexity in Question Answering Systems",
    "authors": [
      "Matteo Gabburo",
      "Nicolaas Paul Jedema",
      "Siddhant Garg",
      "Leonardo F. R. Ribeiro",
      "Alessandro Moschitti"
    ],
    "abstract": "In this paper, we investigate which questions are challenging for\nretrieval-based Question Answering (QA). We (i) propose retrieval complexity\n(RC), a novel metric conditioned on the completeness of retrieved documents,\nwhich measures the difficulty of answering questions, and (ii) propose an\nunsupervised pipeline to measure RC given an arbitrary retrieval system. Our\nproposed pipeline measures RC more accurately than alternative estimators,\nincluding LLMs, on six challenging QA benchmarks. Further investigation reveals\nthat RC scores strongly correlate with both QA performance and expert judgment\nacross five of the six studied benchmarks, indicating that RC is an effective\nmeasure of question difficulty. Subsequent categorization of high-RC questions\nshows that they span a broad set of question shapes, including multi-hop,\ncompositional, and temporal QA, indicating that RC scores can categorize a new\nsubset of complex questions. Our system can also have a major impact on\nretrieval-based systems by helping to identify more challenging questions on\nexisting datasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 (findings)",
    "pdf_url": "http://arxiv.org/pdf/2406.03592v1",
    "published_date": "2024-06-05 19:30:52 UTC",
    "updated_date": "2024-06-05 19:30:52 UTC"
  },
  {
    "arxiv_id": "2406.03586v2",
    "title": "CountCLIP -- [Re] Teaching CLIP to Count to Ten",
    "authors": [
      "Harshvardhan Mestha",
      "Tejas Agrawal",
      "Karan Bania",
      "Shreyas V",
      "Yash Bhisikar"
    ],
    "abstract": "Large vision-language models (VLMs) are shown to learn rich joint image-text\nrepresentations enabling high performances in relevant downstream tasks.\nHowever, they fail to showcase their quantitative understanding of objects, and\nthey lack good counting-aware representation. This paper conducts a\nreproducibility study of 'Teaching CLIP to Count to Ten' (Paiss et al., 2023),\nwhich presents a method to finetune a CLIP model (Radford et al., 2021) to\nimprove zero-shot counting accuracy in an image while maintaining the\nperformance for zero-shot classification by introducing a counting-contrastive\nloss term. We improve the model's performance on a smaller subset of their\ntraining data with lower computational resources. We verify these claims by\nreproducing their study with our own code. The implementation can be found at\nhttps://github.com/SforAiDl/CountCLIP.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03586v2",
    "published_date": "2024-06-05 19:05:08 UTC",
    "updated_date": "2024-06-10 12:09:37 UTC"
  },
  {
    "arxiv_id": "2406.03585v1",
    "title": "A Comparison of Recent Algorithms for Symbolic Regression to Genetic Programming",
    "authors": [
      "Yousef A. Radwan",
      "Gabriel Kronberger",
      "Stephan Winkler"
    ],
    "abstract": "Symbolic regression is a machine learning method with the goal to produce\ninterpretable results. Unlike other machine learning methods such as, e.g.\nrandom forests or neural networks, which are opaque, symbolic regression aims\nto model and map data in a way that can be understood by scientists. Recent\nadvancements, have attempted to bridge the gap between these two fields; new\nmethodologies attempt to fuse the mapping power of neural networks and deep\nlearning techniques with the explanatory power of symbolic regression. In this\npaper, we examine these new emerging systems and test the performance of an\nend-to-end transformer model for symbolic regression versus the reigning\ntraditional methods based on genetic programming that have spearheaded symbolic\nregression throughout the years. We compare these systems on novel datasets to\navoid bias to older methods who were improved on well-known benchmark datasets.\nOur results show that traditional GP methods as implemented e.g., by Operon\nstill remain superior to two recently published symbolic regression methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03585v1",
    "published_date": "2024-06-05 19:01:43 UTC",
    "updated_date": "2024-06-05 19:01:43 UTC"
  },
  {
    "arxiv_id": "2406.03582v1",
    "title": "Understanding the Limitations of Diffusion Concept Algebra Through Food",
    "authors": [
      "E. Zhixuan Zeng",
      "Yuhao Chen",
      "Alexander Wong"
    ],
    "abstract": "Image generation techniques, particularly latent diffusion models, have\nexploded in popularity in recent years. Many techniques have been developed to\nmanipulate and clarify the semantic concepts these large-scale models learn,\noffering crucial insights into biases and concept relationships. However, these\ntechniques are often only validated in conventional realms of human or animal\nfaces and artistic style transitions. The food domain offers unique challenges\nthrough complex compositions and regional biases, which can shed light on the\nlimitations and opportunities within existing methods. Through the lens of food\nimagery, we analyze both qualitative and quantitative patterns within a concept\ntraversal technique. We reveal measurable insights into the model's ability to\ncapture and represent the nuances of culinary diversity, while also identifying\nareas where the model's biases and limitations emerge.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03582v1",
    "published_date": "2024-06-05 18:57:02 UTC",
    "updated_date": "2024-06-05 18:57:02 UTC"
  },
  {
    "arxiv_id": "2406.03577v1",
    "title": "Explaining the Contributing Factors for Vulnerability Detection in Machine Learning",
    "authors": [
      "Esma Mouine",
      "Yan Liu",
      "Lu Xiao",
      "Rick Kazman",
      "Xiao Wang"
    ],
    "abstract": "There is an increasing trend to mine vulnerabilities from software\nrepositories and use machine learning techniques to automatically detect\nsoftware vulnerabilities. A fundamental but unresolved research question is:\nhow do different factors in the mining and learning process impact the accuracy\nof identifying vulnerabilities in software projects of varying characteristics?\nSubstantial research has been dedicated in this area, including source code\nstatic analysis, software repository mining, and NLP-based machine learning.\nHowever, practitioners lack experience regarding the key factors for building a\nbaseline model of the state-of-the-art. In addition, there lacks of experience\nregarding the transferability of the vulnerability signatures from project to\nproject. This study investigates how the combination of different vulnerability\nfeatures and three representative machine learning models impact the accuracy\nof vulnerability detection in 17 real-world projects. We examine two types of\nvulnerability representations: 1) code features extracted through NLP with\nvarying tokenization strategies and three different embedding techniques\n(bag-of-words, word2vec, and fastText) and 2) a set of eight architectural\nmetrics that capture the abstract design of the software systems. The three\nmachine learning algorithms include a random forest model, a support vector\nmachines model, and a residual neural network model. The analysis shows a\nrecommended baseline model with signatures extracted through bag-of-words\nembedding, combined with the random forest, consistently increases the\ndetection accuracy by about 4% compared to other combinations in all 17\nprojects. Furthermore, we observe the limitation of transferring vulnerability\nsignatures across domains based on our experiments.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03577v1",
    "published_date": "2024-06-05 18:48:00 UTC",
    "updated_date": "2024-06-05 18:48:00 UTC"
  },
  {
    "arxiv_id": "2406.03576v1",
    "title": "Enhancing Traffic Sign Recognition with Tailored Data Augmentation: Addressing Class Imbalance and Instance Scarcity",
    "authors": [
      "Ulan Alsiyeu",
      "Zhasdauren Duisebekov"
    ],
    "abstract": "This paper tackles critical challenges in traffic sign recognition (TSR),\nwhich is essential for road safety -- specifically, class imbalance and\ninstance scarcity in datasets. We introduce tailored data augmentation\ntechniques, including synthetic image generation, geometric transformations,\nand a novel obstacle-based augmentation method to enhance dataset quality for\nimproved model robustness and accuracy. Our methodology incorporates diverse\naugmentation processes to accurately simulate real-world conditions, thereby\nexpanding the training data's variety and representativeness. Our findings\ndemonstrate substantial improvements in TSR models performance, offering\nsignificant implications for traffic sign recognition systems. This research\nnot only addresses dataset limitations in TSR but also proposes a model for\nsimilar challenges across different regions and applications, marking a step\nforward in the field of computer vision and traffic sign recognition systems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03576v1",
    "published_date": "2024-06-05 18:45:45 UTC",
    "updated_date": "2024-06-05 18:45:45 UTC"
  },
  {
    "arxiv_id": "2406.03537v2",
    "title": "A Geometric View of Data Complexity: Efficient Local Intrinsic Dimension Estimation with Diffusion Models",
    "authors": [
      "Hamidreza Kamkari",
      "Brendan Leigh Ross",
      "Rasa Hosseinzadeh",
      "Jesse C. Cresswell",
      "Gabriel Loaiza-Ganem"
    ],
    "abstract": "High-dimensional data commonly lies on low-dimensional submanifolds, and\nestimating the local intrinsic dimension (LID) of a datum -- i.e. the dimension\nof the submanifold it belongs to -- is a longstanding problem. LID can be\nunderstood as the number of local factors of variation: the more factors of\nvariation a datum has, the more complex it tends to be. Estimating this\nquantity has proven useful in contexts ranging from generalization in neural\nnetworks to detection of out-of-distribution data, adversarial examples, and\nAI-generated text. The recent successes of deep generative models present an\nopportunity to leverage them for LID estimation, but current methods based on\ngenerative models produce inaccurate estimates, require more than a single\npre-trained model, are computationally intensive, or do not exploit the best\navailable deep generative models: diffusion models (DMs). In this work, we show\nthat the Fokker-Planck equation associated with a DM can provide an LID\nestimator which addresses the aforementioned deficiencies. Our estimator,\ncalled FLIPD, is easy to implement and compatible with all popular DMs.\nApplying FLIPD to synthetic LID estimation benchmarks, we find that DMs\nimplemented as fully-connected networks are highly effective LID estimators\nthat outperform existing baselines. We also apply FLIPD to natural images where\nthe true LID is unknown. Despite being sensitive to the choice of network\narchitecture, FLIPD estimates remain a useful measure of relative complexity;\ncompared to competing estimators, FLIPD exhibits a consistently higher\ncorrelation with image PNG compression rate and better aligns with qualitative\nassessments of complexity. Notably, FLIPD is orders of magnitude faster than\nother LID estimators, and the first to be tractable at the scale of Stable\nDiffusion.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 (spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2406.03537v2",
    "published_date": "2024-06-05 18:00:02 UTC",
    "updated_date": "2024-10-24 18:01:03 UTC"
  },
  {
    "arxiv_id": "2406.03496v1",
    "title": "Wings: Learning Multimodal LLMs without Text-only Forgetting",
    "authors": [
      "Yi-Kai Zhang",
      "Shiyin Lu",
      "Yang Li",
      "Yanqing Ma",
      "Qing-Guo Chen",
      "Zhao Xu",
      "Weihua Luo",
      "Kaifu Zhang",
      "De-Chuan Zhan",
      "Han-Jia Ye"
    ],
    "abstract": "Multimodal large language models (MLLMs), initiated with a trained LLM, first\nalign images with text and then fine-tune on multimodal mixed inputs. However,\nthe MLLM catastrophically forgets the text-only instructions, which do not\ninclude images and can be addressed within the initial LLM. In this paper, we\npresent Wings, a novel MLLM that excels in both text-only dialogues and\nmultimodal comprehension. Analyzing MLLM attention in multimodal instructions\nreveals that text-only forgetting is related to the attention shifts from\npre-image to post-image text. From that, we construct extra modules that act as\nthe boosted learner to compensate for the attention shift. The complementary\nvisual and textual learners, like \"wings\" on either side, are connected in\nparallel within each layer's attention block. Initially, image and text inputs\nare aligned with visual learners operating alongside the main attention,\nbalancing focus on visual elements. Textual learners are later collaboratively\nintegrated with attention-based routing to blend the outputs of the visual and\ntextual learners. We design the Low-Rank Residual Attention (LoRRA) to\nguarantee high efficiency for learners. Our experimental results demonstrate\nthat Wings outperforms equally-scaled MLLMs in both text-only and visual\nquestion-answering tasks. On a newly constructed Interleaved Image-Text (IIT)\nbenchmark, Wings exhibits superior performance from text-only-rich to\nmultimodal-rich question-answering tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03496v1",
    "published_date": "2024-06-05 17:59:40 UTC",
    "updated_date": "2024-06-05 17:59:40 UTC"
  },
  {
    "arxiv_id": "2406.03520v2",
    "title": "VideoPhy: Evaluating Physical Commonsense for Video Generation",
    "authors": [
      "Hritik Bansal",
      "Zongyu Lin",
      "Tianyi Xie",
      "Zeshun Zong",
      "Michal Yarom",
      "Yonatan Bitton",
      "Chenfanfu Jiang",
      "Yizhou Sun",
      "Kai-Wei Chang",
      "Aditya Grover"
    ],
    "abstract": "Recent advances in internet-scale video data pretraining have led to the\ndevelopment of text-to-video generative models that can create high-quality\nvideos across a broad range of visual concepts, synthesize realistic motions\nand render complex objects. Hence, these generative models have the potential\nto become general-purpose simulators of the physical world. However, it is\nunclear how far we are from this goal with the existing text-to-video\ngenerative models. To this end, we present VideoPhy, a benchmark designed to\nassess whether the generated videos follow physical commonsense for real-world\nactivities (e.g. marbles will roll down when placed on a slanted surface).\nSpecifically, we curate diverse prompts that involve interactions between\nvarious material types in the physical world (e.g., solid-solid, solid-fluid,\nfluid-fluid). We then generate videos conditioned on these captions from\ndiverse state-of-the-art text-to-video generative models, including open models\n(e.g., CogVideoX) and closed models (e.g., Lumiere, Dream Machine). Our human\nevaluation reveals that the existing models severely lack the ability to\ngenerate videos adhering to the given text prompts, while also lack physical\ncommonsense. Specifically, the best performing model, CogVideoX-5B, generates\nvideos that adhere to the caption and physical laws for 39.6% of the instances.\nVideoPhy thus highlights that the video generative models are far from\naccurately simulating the physical world. Finally, we propose an\nauto-evaluator, VideoCon-Physics, to assess the performance reliably for the\nnewly released models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "43 pages, 29 figures, 12 tables. Added CogVideo and Dream Machine in\n  v2",
    "pdf_url": "http://arxiv.org/pdf/2406.03520v2",
    "published_date": "2024-06-05 17:53:55 UTC",
    "updated_date": "2024-10-03 17:24:40 UTC"
  },
  {
    "arxiv_id": "2406.03487v1",
    "title": "Analyzing LLM Behavior in Dialogue Summarization: Unveiling Circumstantial Hallucination Trends",
    "authors": [
      "Sanjana Ramprasad",
      "Elisa Ferracane",
      "Zachary C. Lipton"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have considerably\nadvanced the capabilities of summarization systems. However, they continue to\nface concerns about hallucinations. While prior work has evaluated LLMs\nextensively in news domains, most evaluation of dialogue summarization has\nfocused on BART-based models, leaving a gap in our understanding of their\nfaithfulness. Our work benchmarks the faithfulness of LLMs for dialogue\nsummarization, using human annotations and focusing on identifying and\ncategorizing span-level inconsistencies. Specifically, we focus on two\nprominent LLMs: GPT-4 and Alpaca-13B. Our evaluation reveals subtleties as to\nwhat constitutes a hallucination: LLMs often generate plausible inferences,\nsupported by circumstantial evidence in the conversation, that lack direct\nevidence, a pattern that is less prevalent in older models. We propose a\nrefined taxonomy of errors, coining the category of \"Circumstantial Inference\"\nto bucket these LLM behaviors and release the dataset. Using our taxonomy, we\ncompare the behavioral differences between LLMs and older fine-tuned models.\nAdditionally, we systematically assess the efficacy of automatic error\ndetection methods on LLM summaries and find that they struggle to detect these\nnuanced errors. To address this, we introduce two prompt-based approaches for\nfine-grained error detection that outperform existing metrics, particularly for\nidentifying \"Circumstantial Inference.\"",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.03487v1",
    "published_date": "2024-06-05 17:49:47 UTC",
    "updated_date": "2024-06-05 17:49:47 UTC"
  },
  {
    "arxiv_id": "2406.03486v1",
    "title": "BIPED: Pedagogically Informed Tutoring System for ESL Education",
    "authors": [
      "Soonwoo Kwon",
      "Sojung Kim",
      "Minju Park",
      "Seunghyun Lee",
      "Kyuseok Kim"
    ],
    "abstract": "Large Language Models (LLMs) have a great potential to serve as readily\navailable and cost-efficient Conversational Intelligent Tutoring Systems (CITS)\nfor teaching L2 learners of English. Existing CITS, however, are designed to\nteach only simple concepts or lack the pedagogical depth necessary to address\ndiverse learning strategies. To develop a more pedagogically informed CITS\ncapable of teaching complex concepts, we construct a BIlingual\nPEDagogically-informed Tutoring Dataset (BIPED) of one-on-one, human-to-human\nEnglish tutoring interactions. Through post-hoc analysis of the tutoring\ninteractions, we come up with a lexicon of dialogue acts (34 tutor acts and 9\nstudent acts), which we use to further annotate the collected dataset. Based on\na two-step framework of first predicting the appropriate tutor act then\ngenerating the corresponding response, we implemented two CITS models using\nGPT-4 and SOLAR-KO, respectively. We experimentally demonstrate that the\nimplemented models not only replicate the style of human teachers but also\nemploy diverse and contextually appropriate pedagogical strategies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.03486v1",
    "published_date": "2024-06-05 17:49:24 UTC",
    "updated_date": "2024-06-05 17:49:24 UTC"
  },
  {
    "arxiv_id": "2406.03485v1",
    "title": "Highway Value Iteration Networks",
    "authors": [
      "Yuhui Wang",
      "Weida Li",
      "Francesco Faccio",
      "Qingyuan Wu",
      "JÃ¼rgen Schmidhuber"
    ],
    "abstract": "Value iteration networks (VINs) enable end-to-end learning for planning tasks\nby employing a differentiable \"planning module\" that approximates the value\niteration algorithm. However, long-term planning remains a challenge because\ntraining very deep VINs is difficult. To address this problem, we embed highway\nvalue iteration -- a recent algorithm designed to facilitate long-term credit\nassignment -- into the structure of VINs. This improvement augments the\n\"planning module\" of the VIN with three additional components: 1) an \"aggregate\ngate,\" which constructs skip connections to improve information flow across\nmany layers; 2) an \"exploration module,\" crafted to increase the diversity of\ninformation and gradient flow in spatial dimensions; 3) a \"filter gate\"\ndesigned to ensure safe exploration. The resulting novel highway VIN can be\ntrained effectively with hundreds of layers using standard backpropagation. In\nlong-term planning tasks requiring hundreds of planning steps, deep highway\nVINs outperform both traditional VINs and several advanced, very deep NNs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.03485v1",
    "published_date": "2024-06-05 17:46:26 UTC",
    "updated_date": "2024-06-05 17:46:26 UTC"
  },
  {
    "arxiv_id": "2406.03482v2",
    "title": "QJL: 1-Bit Quantized JL Transform for KV Cache Quantization with Zero Overhead",
    "authors": [
      "Amir Zandieh",
      "Majid Daliri",
      "Insu Han"
    ],
    "abstract": "Serving LLMs requires substantial memory due to the storage requirements of\nKey-Value (KV) embeddings in the KV cache, which grows with sequence length. An\neffective approach to compress KV cache is quantization. However, traditional\nquantization methods face significant memory overhead due to the need to store\nquantization constants (at least a zero point and a scale) in full precision\nper data block. Depending on the block size, this overhead can add 1 or 2 bits\nper quantized number. We introduce QJL, a new quantization approach that\nconsists of a Johnson-Lindenstrauss (JL) transform followed by sign-bit\nquantization. In contrast to existing methods, QJL eliminates memory overheads\nby removing the need for storing quantization constants. We propose an\nasymmetric estimator for the inner product of two vectors and demonstrate that\napplying QJL to one vector and a standard JL transform without quantization to\nthe other provides an unbiased estimator with minimal distortion. We have\ndeveloped an efficient implementation of the QJL sketch and its corresponding\ninner product estimator, incorporating a lightweight CUDA kernel for optimized\ncomputation. When applied across various LLMs and NLP tasks to quantize the KV\ncache to only 3 bits, QJL demonstrates a more than fivefold reduction in KV\ncache memory usage without compromising accuracy, all while achieving faster\nruntime. Codes are available at \\url{https://github.com/amirzandieh/QJL}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.03482v2",
    "published_date": "2024-06-05 17:42:05 UTC",
    "updated_date": "2024-07-18 16:31:29 UTC"
  },
  {
    "arxiv_id": "2406.03470v1",
    "title": "SpikeZIP-TF: Conversion is All You Need for Transformer-based SNN",
    "authors": [
      "Kang You",
      "Zekai Xu",
      "Chen Nie",
      "Zhijie Deng",
      "Qinghai Guo",
      "Xiang Wang",
      "Zhezhi He"
    ],
    "abstract": "Spiking neural network (SNN) has attracted great attention due to its\ncharacteristic of high efficiency and accuracy. Currently, the ANN-to-SNN\nconversion methods can obtain ANN on-par accuracy SNN with ultra-low latency (8\ntime-steps) in CNN structure on computer vision (CV) tasks. However, as\nTransformer-based networks have achieved prevailing precision on both CV and\nnatural language processing (NLP), the Transformer-based SNNs are still\nencounting the lower accuracy w.r.t the ANN counterparts. In this work, we\nintroduce a novel ANN-to-SNN conversion method called SpikeZIP-TF, where ANN\nand SNN are exactly equivalent, thus incurring no accuracy degradation.\nSpikeZIP-TF achieves 83.82% accuracy on CV dataset (ImageNet) and 93.79%\naccuracy on NLP dataset (SST-2), which are higher than SOTA Transformer-based\nSNNs. The code is available in GitHub:\nhttps://github.com/Intelligent-Computing-Research-Group/SpikeZIP_transformer",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "* These authors contributed equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2406.03470v1",
    "published_date": "2024-06-05 17:24:07 UTC",
    "updated_date": "2024-06-05 17:24:07 UTC"
  },
  {
    "arxiv_id": "2406.03450v1",
    "title": "What is the Best Way for ChatGPT to Translate Poetry?",
    "authors": [
      "Shanshan Wang",
      "Derek F. Wong",
      "Jingming Yao",
      "Lidia S. Chao"
    ],
    "abstract": "Machine translation (MT) has historically faced significant challenges when\napplied to literary works, particularly in the domain of poetry translation.\nThe advent of Large Language Models such as ChatGPT holds potential for\ninnovation in this field. This study examines ChatGPT's capabilities in\nEnglish-Chinese poetry translation tasks, utilizing targeted prompts and small\nsample scenarios to ascertain optimal performance. Despite promising outcomes,\nour analysis reveals persistent issues in the translations generated by ChatGPT\nthat warrant attention. To address these shortcomings, we propose an\nExplanation-Assisted Poetry Machine Translation (EAPMT) method, which leverages\nmonolingual poetry explanation as a guiding information for the translation\nprocess. Furthermore, we refine existing evaluation criteria to better suit the\nnuances of modern poetry translation. We engaged a panel of professional poets\nfor assessments, complemented evaluations by using GPT-4. The results from both\nhuman and machine evaluations demonstrate that our EAPMT method outperforms\ntraditional translation methods of ChatGPT and the existing online systems.\nThis paper validates the efficacy of our method and contributes a novel\nperspective to machine-assisted literary translation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 1 figure. The paper has been accepted by ACL 2024(Main\n  Conference)",
    "pdf_url": "http://arxiv.org/pdf/2406.03450v1",
    "published_date": "2024-06-05 16:48:26 UTC",
    "updated_date": "2024-06-05 16:48:26 UTC"
  },
  {
    "arxiv_id": "2406.03447v1",
    "title": "FILS: Self-Supervised Video Feature Prediction In Semantic Language Space",
    "authors": [
      "Mona Ahmadian",
      "Frank Guerin",
      "Andrew Gilbert"
    ],
    "abstract": "This paper demonstrates a self-supervised approach for learning semantic\nvideo representations. Recent vision studies show that a masking strategy for\nvision and natural language supervision has contributed to developing\ntransferable visual pretraining. Our goal is to achieve a more semantic video\nrepresentation by leveraging the text related to the video content during the\npretraining in a fully self-supervised manner. To this end, we present FILS, a\nnovel self-supervised video Feature prediction In semantic Language Space\n(FILS). The vision model can capture valuable structured information by\ncorrectly predicting masked feature semantics in language space. It is learned\nusing a patch-wise video-text contrastive strategy, in which the text\nrepresentations act as prototypes for transforming vision features into a\nlanguage space, which are then used as targets for semantically meaningful\nfeature prediction using our masked encoder-decoder structure. FILS\ndemonstrates remarkable transferability on downstream action recognition tasks,\nachieving state-of-the-art on challenging egocentric datasets, like\nEpic-Kitchens, Something-SomethingV2, Charades-Ego, and EGTEA, using ViT-Base.\nOur efficient method requires less computation and smaller batches compared to\nprevious works.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03447v1",
    "published_date": "2024-06-05 16:44:06 UTC",
    "updated_date": "2024-06-05 16:44:06 UTC"
  },
  {
    "arxiv_id": "2406.16910v1",
    "title": "Mind's Eye: Image Recognition by EEG via Multimodal Similarity-Keeping Contrastive Learning",
    "authors": [
      "Chi-Sheng Chen",
      "Chun-Shu Wei"
    ],
    "abstract": "Decoding images from non-invasive electroencephalographic (EEG) signals has\nbeen a grand challenge in understanding how the human brain process visual\ninformation in real-world scenarios. To cope with the issues of signal-to-noise\nratio and nonstationarity, this paper introduces a MUltimodal\nSimilarity-keeping contrastivE learning (MUSE) framework for zero-shot\nEEG-based image classification. We develop a series of multivariate time-series\nencoders tailored for EEG signals and assess the efficacy of regularized\ncontrastive EEG-Image pretraining using an extensive visual EEG dataset. Our\nmethod achieves state-of-the-art performance, with a top-1 accuracy of 19.3%\nand a top-5 accuracy of 48.8% in 200-way zero-shot image classification.\nFurthermore, we visualize neural patterns via model interpretation, shedding\nlight on the visual processing dynamics in the human brain. The code repository\nfor this work is available at: https://github.com/ChiShengChen/MUSE_EEG.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "eess.SP",
    "comment": "19 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.16910v1",
    "published_date": "2024-06-05 16:42:23 UTC",
    "updated_date": "2024-06-05 16:42:23 UTC"
  },
  {
    "arxiv_id": "2406.03516v1",
    "title": "Buffered Asynchronous Secure Aggregation for Cross-Device Federated Learning",
    "authors": [
      "Kun Wang",
      "Yi-Rui Yang",
      "Wu-Jun Li"
    ],
    "abstract": "Asynchronous federated learning (AFL) is an effective method to address the\nchallenge of device heterogeneity in cross-device federated learning. However,\nAFL is usually incompatible with existing secure aggregation protocols used to\nprotect user privacy in federated learning because most existing secure\naggregation protocols are based on synchronous aggregation. To address this\nproblem, we propose a novel secure aggregation protocol named buffered\nasynchronous secure aggregation (BASA) in this paper. Compared with existing\nprotocols, BASA is fully compatible with AFL and provides secure aggregation\nunder the condition that each user only needs one round of communication with\nthe server without relying on any synchronous interaction among users. Based on\nBASA, we propose the first AFL method which achieves secure aggregation without\nextra requirements on hardware. We empirically demonstrate that BASA\noutperforms existing secure aggregation protocols for cross-device federated\nlearning in terms of training efficiency and scalability.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03516v1",
    "published_date": "2024-06-05 16:39:32 UTC",
    "updated_date": "2024-06-05 16:39:32 UTC"
  },
  {
    "arxiv_id": "2406.03442v2",
    "title": "Are language models rational? The case of coherence norms and belief revision",
    "authors": [
      "Thomas Hofweber",
      "Peter Hase",
      "Elias Stengel-Eskin",
      "Mohit Bansal"
    ],
    "abstract": "Do norms of rationality apply to machine learning models, in particular\nlanguage models? In this paper we investigate this question by focusing on a\nspecial subset of rational norms: coherence norms. We consider both logical\ncoherence norms as well as coherence norms tied to the strength of belief. To\nmake sense of the latter, we introduce the Minimal Assent Connection (MAC) and\npropose a new account of credence, which captures the strength of belief in\nlanguage models. This proposal uniformly assigns strength of belief simply on\nthe basis of model internal next token probabilities. We argue that rational\nnorms tied to coherence do apply to some language models, but not to others.\nThis issue is significant since rationality is closely tied to predicting and\nexplaining behavior, and thus it is connected to considerations about AI safety\nand alignment, as well as understanding model behavior more generally.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "added discussion and cross reference of new empirical work by the\n  authors, updated references, fixed typos",
    "pdf_url": "http://arxiv.org/pdf/2406.03442v2",
    "published_date": "2024-06-05 16:36:21 UTC",
    "updated_date": "2024-08-10 21:55:08 UTC"
  },
  {
    "arxiv_id": "2406.03439v1",
    "title": "Text-to-Events: Synthetic Event Camera Streams from Conditional Text Input",
    "authors": [
      "Joachim Ott",
      "Zuowen Wang",
      "Shih-Chii Liu"
    ],
    "abstract": "Event cameras are advantageous for tasks that require vision sensors with\nlow-latency and sparse output responses. However, the development of deep\nnetwork algorithms using event cameras has been slow because of the lack of\nlarge labelled event camera datasets for network training. This paper reports a\nmethod for creating new labelled event datasets by using a text-to-X model,\nwhere X is one or multiple output modalities, in the case of this work, events.\nOur proposed text-to-events model produces synthetic event frames directly from\ntext prompts. It uses an autoencoder which is trained to produce sparse event\nframes representing event camera outputs. By combining the pretrained\nautoencoder with a diffusion model architecture, the new text-to-events model\nis able to generate smooth synthetic event streams of moving objects. The\nautoencoder was first trained on an event camera dataset of diverse scenes. In\nthe combined training with the diffusion model, the DVS gesture dataset was\nused. We demonstrate that the model can generate realistic event sequences of\nhuman gestures prompted by different text statements. The classification\naccuracy of the generated sequences, using a classifier trained on the real\ndataset, ranges between 42% to 92%, depending on the gesture group. The results\ndemonstrate the capability of this method in synthesizing event datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T99",
      "I.2.6; I.2.7; I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03439v1",
    "published_date": "2024-06-05 16:34:12 UTC",
    "updated_date": "2024-06-05 16:34:12 UTC"
  },
  {
    "arxiv_id": "2406.03434v1",
    "title": "Unified PAC-Bayesian Study of Pessimism for Offline Policy Learning with Regularized Importance Sampling",
    "authors": [
      "Imad Aouali",
      "Victor-Emmanuel Brunel",
      "David Rohde",
      "Anna Korba"
    ],
    "abstract": "Off-policy learning (OPL) often involves minimizing a risk estimator based on\nimportance weighting to correct bias from the logging policy used to collect\ndata. However, this method can produce an estimator with a high variance. A\ncommon solution is to regularize the importance weights and learn the policy by\nminimizing an estimator with penalties derived from generalization bounds\nspecific to the estimator. This approach, known as pessimism, has gained recent\nattention but lacks a unified framework for analysis. To address this gap, we\nintroduce a comprehensive PAC-Bayesian framework to examine pessimism with\nregularized importance weighting. We derive a tractable PAC-Bayesian\ngeneralization bound that universally applies to common importance weight\nregularizations, enabling their comparison within a single framework. Our\nempirical results challenge common understanding, demonstrating the\neffectiveness of standard IW regularization techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at UAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.03434v1",
    "published_date": "2024-06-05 16:32:14 UTC",
    "updated_date": "2024-06-05 16:32:14 UTC"
  },
  {
    "arxiv_id": "2406.06591v2",
    "title": "Exploring Multilingual Large Language Models for Enhanced TNM classification of Radiology Report in lung cancer staging",
    "authors": [
      "Hidetoshi Matsuo",
      "Mizuho Nishio",
      "Takaaki Matsunaga",
      "Koji Fujimoto",
      "Takamichi Murakami"
    ],
    "abstract": "Background: Structured radiology reports remains underdeveloped due to\nlabor-intensive structuring and narrative-style reporting. Deep learning,\nparticularly large language models (LLMs) like GPT-3.5, offers promise in\nautomating the structuring of radiology reports in natural languages. However,\nalthough it has been reported that LLMs are less effective in languages other\nthan English, their radiological performance has not been extensively studied.\nPurpose: This study aimed to investigate the accuracy of TNM classification\nbased on radiology reports using GPT3.5-turbo (GPT3.5) and the utility of\nmultilingual LLMs in both Japanese and English. Material and Methods: Utilizing\nGPT3.5, we developed a system to automatically generate TNM classifications\nfrom chest CT reports for lung cancer and evaluate its performance. We\nstatistically analyzed the impact of providing full or partial TNM definitions\nin both languages using a Generalized Linear Mixed Model. Results: Highest\naccuracy was attained with full TNM definitions and radiology reports in\nEnglish (M = 94%, N = 80%, T = 47%, and ALL = 36%). Providing definitions for\neach of the T, N, and M factors statistically improved their respective\naccuracies (T: odds ratio (OR) = 2.35, p < 0.001; N: OR = 1.94, p < 0.01; M: OR\n= 2.50, p < 0.001). Japanese reports exhibited decreased N and M accuracies (N\naccuracy: OR = 0.74 and M accuracy: OR = 0.21). Conclusion: This study\nunderscores the potential of multilingual LLMs for automatic TNM classification\nin radiology reports. Even without additional model training, performance\nimprovements were evident with the provided TNM definitions, indicating LLMs'\nrelevance in radiology contexts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 3figures",
    "pdf_url": "http://arxiv.org/pdf/2406.06591v2",
    "published_date": "2024-06-05 16:11:55 UTC",
    "updated_date": "2024-06-12 15:19:46 UTC"
  },
  {
    "arxiv_id": "2406.03388v1",
    "title": "SelfReDepth: Self-Supervised Real-Time Depth Restoration for Consumer-Grade Sensors",
    "authors": [
      "Alexandre Duarte",
      "Francisco Fernandes",
      "JoÃ£o M. Pereira",
      "Catarina Moreira",
      "Jacinto C. Nascimento",
      "Joaquim Jorge"
    ],
    "abstract": "Depth maps produced by consumer-grade sensors suffer from inaccurate\nmeasurements and missing data from either system or scene-specific sources.\nData-driven denoising algorithms can mitigate such problems. However, they\nrequire vast amounts of ground truth depth data. Recent research has tackled\nthis limitation using self-supervised learning techniques, but it requires\nmultiple RGB-D sensors. Moreover, most existing approaches focus on denoising\nsingle isolated depth maps or specific subjects of interest, highlighting a\nneed for methods to effectively denoise depth maps in real-time dynamic\nenvironments. This paper extends state-of-the-art approaches for\ndepth-denoising commodity depth devices, proposing SelfReDepth, a\nself-supervised deep learning technique for depth restoration, via denoising\nand hole-filling by inpainting full-depth maps captured with RGB-D sensors. The\nalgorithm targets depth data in video streams, utilizing multiple sequential\ndepth frames coupled with color data to achieve high-quality depth videos with\ntemporal coherence. Finally, SelfReDepth is designed to be compatible with\nvarious RGB-D sensors and usable in real-time scenarios as a pre-processing\nstep before applying other depth-dependent algorithms. Our results demonstrate\nour approach's real-time performance on real-world datasets. They show that it\noutperforms state-of-the-art denoising and restoration performance at over\n30fps on Commercial Depth Cameras, with potential benefits for augmented and\nmixed-reality applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "13pp, 5 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2406.03388v1",
    "published_date": "2024-06-05 15:38:02 UTC",
    "updated_date": "2024-06-05 15:38:02 UTC"
  },
  {
    "arxiv_id": "2406.06590v2",
    "title": "Are LLMs classical or nonmonotonic reasoners? Lessons from generics",
    "authors": [
      "Alina Leidinger",
      "Robert van Rooij",
      "Ekaterina Shutova"
    ],
    "abstract": "Recent scholarship on reasoning in LLMs has supplied evidence of impressive\nperformance and flexible adaptation to machine generated or human feedback.\nNonmonotonic reasoning, crucial to human cognition for navigating the real\nworld, remains a challenging, yet understudied task. In this work, we study\nnonmonotonic reasoning capabilities of seven state-of-the-art LLMs in one\nabstract and one commonsense reasoning task featuring generics, such as 'Birds\nfly', and exceptions, 'Penguins don't fly' (see Fig. 1). While LLMs exhibit\nreasoning patterns in accordance with human nonmonotonic reasoning abilities,\nthey fail to maintain stable beliefs on truth conditions of generics at the\naddition of supporting examples ('Owls fly') or unrelated information ('Lions\nhave manes'). Our findings highlight pitfalls in attributing human reasoning\nbehaviours to LLMs, as well as assessing general capabilities, while consistent\nreasoning remains elusive.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ACL 2024 (main)",
    "pdf_url": "http://arxiv.org/pdf/2406.06590v2",
    "published_date": "2024-06-05 15:23:11 UTC",
    "updated_date": "2024-06-12 11:18:40 UTC"
  },
  {
    "arxiv_id": "2406.03368v2",
    "title": "IrokoBench: A New Benchmark for African Languages in the Age of Large Language Models",
    "authors": [
      "David Ifeoluwa Adelani",
      "Jessica Ojo",
      "Israel Abebe Azime",
      "Jian Yun Zhuang",
      "Jesujoba O. Alabi",
      "Xuanli He",
      "Millicent Ochieng",
      "Sara Hooker",
      "Andiswa Bukula",
      "En-Shiun Annie Lee",
      "Chiamaka Chukwuneke",
      "Happy Buzaaba",
      "Blessing Sibanda",
      "Godson Kalipe",
      "Jonathan Mukiibi",
      "Salomon Kabongo",
      "Foutse Yuehgoh",
      "Mmasibidi Setaka",
      "Lolwethu Ndolela",
      "Nkiruka Odu",
      "Rooweither Mabuya",
      "Shamsuddeen Hassan Muhammad",
      "Salomey Osei",
      "Sokhar Samb",
      "Tadesse Kebede Guge",
      "Tombekai Vangoni Sherman",
      "Pontus Stenetorp"
    ],
    "abstract": "Despite the widespread adoption of Large language models (LLMs), their\nremarkable capabilities remain limited to a few high-resource languages.\nAdditionally, many low-resource languages (\\eg African languages) are often\nevaluated only on basic text classification tasks due to the lack of\nappropriate or comprehensive benchmarks outside of high-resource languages. In\nthis paper, we introduce IrokoBench -- a human-translated benchmark dataset for\n17 typologically-diverse low-resource African languages covering three tasks:\nnatural language inference~(AfriXNLI), mathematical reasoning~(AfriMGSM), and\nmulti-choice knowledge-based question answering~(AfriMMLU). We use IrokoBench\nto evaluate zero-shot, few-shot, and translate-test settings~(where test sets\nare translated into English) across 10 open and six proprietary LLMs. Our\nevaluation reveals a significant performance gap between high-resource\nlanguages~(such as English and French) and low-resource African languages. We\nobserve a significant performance gap between open and proprietary models, with\nthe highest performing open model, Gemma 2 27B only at 63\\% of the\nbest-performing proprietary model GPT-4o performance. In addition, machine\ntranslating the test set to English before evaluation helped to close the gap\nfor larger models that are English-centric, such as Gemma 2 27B and LLaMa 3.1\n70B. These findings suggest that more efforts are needed to develop and adapt\nLLMs for African languages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025 (main conference)",
    "pdf_url": "http://arxiv.org/pdf/2406.03368v2",
    "published_date": "2024-06-05 15:23:08 UTC",
    "updated_date": "2025-01-23 17:57:28 UTC"
  },
  {
    "arxiv_id": "2406.03367v1",
    "title": "CLMASP: Coupling Large Language Models with Answer Set Programming for Robotic Task Planning",
    "authors": [
      "Xinrui Lin",
      "Yangfan Wu",
      "Huanyu Yang",
      "Yu Zhang",
      "Yanyong Zhang",
      "Jianmin Ji"
    ],
    "abstract": "Large Language Models (LLMs) possess extensive foundational knowledge and\nmoderate reasoning abilities, making them suitable for general task planning in\nopen-world scenarios. However, it is challenging to ground a LLM-generated plan\nto be executable for the specified robot with certain restrictions. This paper\nintroduces CLMASP, an approach that couples LLMs with Answer Set Programming\n(ASP) to overcome the limitations, where ASP is a non-monotonic logic\nprogramming formalism renowned for its capacity to represent and reason about a\nrobot's action knowledge. CLMASP initiates with a LLM generating a basic\nskeleton plan, which is subsequently tailored to the specific scenario using a\nvector database. This plan is then refined by an ASP program with a robot's\naction knowledge, which integrates implementation details into the skeleton,\ngrounding the LLM's abstract outputs in practical robot contexts. Our\nexperiments conducted on the VirtualHome platform demonstrate CLMASP's\nefficacy. Compared to the baseline executable rate of under 2% with LLM\napproaches, CLMASP significantly improves this to over 90%.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03367v1",
    "published_date": "2024-06-05 15:21:44 UTC",
    "updated_date": "2024-06-05 15:21:44 UTC"
  },
  {
    "arxiv_id": "2406.03345v3",
    "title": "Feature contamination: Neural networks learn uncorrelated features and fail to generalize",
    "authors": [
      "Tianren Zhang",
      "Chujie Zhao",
      "Guanyu Chen",
      "Yizhou Jiang",
      "Feng Chen"
    ],
    "abstract": "Learning representations that generalize under distribution shifts is\ncritical for building robust machine learning models. However, despite\nsignificant efforts in recent years, algorithmic advances in this direction\nhave been limited. In this work, we seek to understand the fundamental\ndifficulty of out-of-distribution generalization with deep neural networks. We\nfirst empirically show that perhaps surprisingly, even allowing a neural\nnetwork to explicitly fit the representations obtained from a teacher network\nthat can generalize out-of-distribution is insufficient for the generalization\nof the student network. Then, by a theoretical study of two-layer ReLU networks\noptimized by stochastic gradient descent (SGD) under a structured feature\nmodel, we identify a fundamental yet unexplored feature learning proclivity of\nneural networks, feature contamination: neural networks can learn uncorrelated\nfeatures together with predictive features, resulting in generalization failure\nunder distribution shifts. Notably, this mechanism essentially differs from the\nprevailing narrative in the literature that attributes the generalization\nfailure to spurious correlations. Overall, our results offer new insights into\nthe non-linear feature learning dynamics of neural networks and highlight the\nnecessity of considering inductive biases in out-of-distribution\ngeneralization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.03345v3",
    "published_date": "2024-06-05 15:04:27 UTC",
    "updated_date": "2025-02-13 13:25:18 UTC"
  },
  {
    "arxiv_id": "2406.03344v1",
    "title": "Audio Mamba: Bidirectional State Space Model for Audio Representation Learning",
    "authors": [
      "Mehmet Hamza Erol",
      "Arda Senocak",
      "Jiu Feng",
      "Joon Son Chung"
    ],
    "abstract": "Transformers have rapidly become the preferred choice for audio\nclassification, surpassing methods based on CNNs. However, Audio Spectrogram\nTransformers (ASTs) exhibit quadratic scaling due to self-attention. The\nremoval of this quadratic self-attention cost presents an appealing direction.\nRecently, state space models (SSMs), such as Mamba, have demonstrated potential\nin language and vision tasks in this regard. In this study, we explore whether\nreliance on self-attention is necessary for audio classification tasks. By\nintroducing Audio Mamba (AuM), the first self-attention-free, purely SSM-based\nmodel for audio classification, we aim to address this question. We evaluate\nAuM on various audio datasets - comprising six different benchmarks - where it\nachieves comparable or better performance compared to well-established AST\nmodel.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Code is available at https://github.com/mhamzaerol/Audio-Mamba-AuM",
    "pdf_url": "http://arxiv.org/pdf/2406.03344v1",
    "published_date": "2024-06-05 15:00:59 UTC",
    "updated_date": "2024-06-05 15:00:59 UTC"
  },
  {
    "arxiv_id": "2406.03341v7",
    "title": "Tackling Copyright Issues in AI Image Generation Through Originality Estimation and Genericization",
    "authors": [
      "Hiroaki Chiba-Okabe",
      "Weijie J. Su"
    ],
    "abstract": "The rapid progress of generative AI technology has sparked significant\ncopyright concerns, leading to numerous lawsuits filed against AI developers.\nNotably, generative AI's capacity for generating images of copyrighted\ncharacters has been well documented in the literature, and while various\ntechniques for mitigating copyright issues have been studied, significant risks\nremain. Here, we propose a genericization method that modifies the outputs of a\ngenerative model to make them more generic and less likely to imitate\ndistinctive features of copyrighted materials. To achieve this, we introduce a\nmetric for quantifying the level of originality of data, estimated by drawing\nsamples from a generative model, and applied in the genericization process. As\na practical implementation, we introduce PREGen (Prompt Rewriting-Enhanced\nGenericization), which combines our genericization method with an existing\nmitigation technique. Compared to the existing method, PREGen reduces the\nlikelihood of generating copyrighted characters by more than half when the\nnames of copyrighted characters are used as the prompt. Additionally, while\ngenerative models can produce copyrighted characters even when their names are\nnot directly mentioned in the prompt, PREGen almost entirely prevents the\ngeneration of such characters in these cases. Ultimately, this study advances\ncomputational approaches for quantifying and strengthening copyright\nprotection, thereby providing practical methodologies to promote responsible\ngenerative AI development.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.03341v7",
    "published_date": "2024-06-05 14:58:32 UTC",
    "updated_date": "2025-03-31 02:53:45 UTC"
  },
  {
    "arxiv_id": "2406.03339v2",
    "title": "The Challenges of Evaluating LLM Applications: An Analysis of Automated, Human, and LLM-Based Approaches",
    "authors": [
      "Bhashithe Abeysinghe",
      "Ruhan Circi"
    ],
    "abstract": "Chatbots have been an interesting application of natural language generation\nsince its inception. With novel transformer based Generative AI methods,\nbuilding chatbots have become trivial. Chatbots which are targeted at specific\ndomains for example medicine and psychology are implemented rapidly. This\nhowever, should not distract from the need to evaluate the chatbot responses.\nEspecially because the natural language generation community does not entirely\nagree upon how to effectively evaluate such applications. With this work we\ndiscuss the issue further with the increasingly popular LLM based evaluations\nand how they correlate with human evaluations. Additionally, we introduce a\ncomprehensive factored evaluation mechanism that can be utilized in conjunction\nwith both human and LLM-based evaluations. We present the results of an\nexperimental evaluation conducted using this scheme in one of our chatbot\nimplementations which consumed educational reports, and subsequently compare\nautomated, traditional human evaluation, factored human evaluation, and\nfactored LLM evaluation. Results show that factor based evaluation produces\nbetter insights on which aspects need to be improved in LLM applications and\nfurther strengthens the argument to use human evaluation in critical spaces\nwhere main functionality is not direct retrieval.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in The First Workshop on Large Language Models for\n  Evaluation in Information Retrieval",
    "pdf_url": "http://arxiv.org/pdf/2406.03339v2",
    "published_date": "2024-06-05 14:55:10 UTC",
    "updated_date": "2024-06-13 15:13:40 UTC"
  },
  {
    "arxiv_id": "2406.03314v2",
    "title": "Reproducibility study of FairAC",
    "authors": [
      "Gijs de Jong",
      "Macha J. Meijer",
      "Derck W. E. Prinzhorn",
      "Harold Ruiter"
    ],
    "abstract": "This work aims to reproduce the findings of the paper \"Fair Attribute\nCompletion on Graph with Missing Attributes\" written by Guo, Chu, and Li\narXiv:2302.12977 by investigating the claims made in the paper. This paper\nsuggests that the results of the original paper are reproducible and thus, the\nclaims hold. However, the claim that FairAC is a generic framework for many\ndownstream tasks is very broad and could therefore only be partially tested.\nMoreover, we show that FairAC is generalizable to various datasets and\nsensitive attributes and show evidence that the improvement in group fairness\nof the FairAC framework does not come at the expense of individual fairness.\nLastly, the codebase of FairAC has been refactored and is now easily applicable\nfor various datasets and models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 2 figures, accepted at TMLR",
    "pdf_url": "http://arxiv.org/pdf/2406.03314v2",
    "published_date": "2024-06-05 14:26:45 UTC",
    "updated_date": "2024-06-10 16:09:03 UTC"
  },
  {
    "arxiv_id": "2406.03299v1",
    "title": "The Good, the Bad, and the Hulk-like GPT: Analyzing Emotional Decisions of Large Language Models in Cooperation and Bargaining Games",
    "authors": [
      "Mikhail Mozikov",
      "Nikita Severin",
      "Valeria Bodishtianu",
      "Maria Glushanina",
      "Mikhail Baklashkin",
      "Andrey V. Savchenko",
      "Ilya Makarov"
    ],
    "abstract": "Behavior study experiments are an important part of society modeling and\nunderstanding human interactions. In practice, many behavioral experiments\nencounter challenges related to internal and external validity,\nreproducibility, and social bias due to the complexity of social interactions\nand cooperation in human user studies. Recent advances in Large Language Models\n(LLMs) have provided researchers with a new promising tool for the simulation\nof human behavior. However, existing LLM-based simulations operate under the\nunproven hypothesis that LLM agents behave similarly to humans as well as\nignore a crucial factor in human decision-making: emotions.\n  In this paper, we introduce a novel methodology and the framework to study\nboth, the decision-making of LLMs and their alignment with human behavior under\nemotional states. Experiments with GPT-3.5 and GPT-4 on four games from two\ndifferent classes of behavioral game theory showed that emotions profoundly\nimpact the performance of LLMs, leading to the development of more optimal\nstrategies. While there is a strong alignment between the behavioral responses\nof GPT-3.5 and human participants, particularly evident in bargaining games,\nGPT-4 exhibits consistent behavior, ignoring induced emotions for rationality\ndecisions. Surprisingly, emotional prompting, particularly with `anger'\nemotion, can disrupt the \"superhuman\" alignment of GPT-4, resembling human\nemotional responses.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "I.2.7; J.4"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03299v1",
    "published_date": "2024-06-05 14:08:54 UTC",
    "updated_date": "2024-06-05 14:08:54 UTC"
  },
  {
    "arxiv_id": "2406.18580v1",
    "title": "Shedding Light on Large Generative Networks: Estimating Epistemic Uncertainty in Diffusion Models",
    "authors": [
      "Lucas Berry",
      "Axel Brando",
      "David Meger"
    ],
    "abstract": "Generative diffusion models, notable for their large parameter count\n(exceeding 100 million) and operation within high-dimensional image spaces,\npose significant challenges for traditional uncertainty estimation methods due\nto computational demands. In this work, we introduce an innovative framework,\nDiffusion Ensembles for Capturing Uncertainty (DECU), designed for estimating\nepistemic uncertainty for diffusion models. The DECU framework introduces a\nnovel method that efficiently trains ensembles of conditional diffusion models\nby incorporating a static set of pre-trained parameters, drastically reducing\nthe computational burden and the number of parameters that require training.\nAdditionally, DECU employs Pairwise-Distance Estimators (PaiDEs) to accurately\nmeasure epistemic uncertainty by evaluating the mutual information between\nmodel outputs and weights in high-dimensional spaces. The effectiveness of this\nframework is demonstrated through experiments on the ImageNet dataset,\nhighlighting its capability to capture epistemic uncertainty, specifically in\nunder-sampled image classes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18580v1",
    "published_date": "2024-06-05 14:03:21 UTC",
    "updated_date": "2024-06-05 14:03:21 UTC"
  },
  {
    "arxiv_id": "2406.03292v1",
    "title": "Evaluating AI fairness in credit scoring with the BRIO tool",
    "authors": [
      "Greta Coraglia",
      "Francesco A. Genco",
      "Pellegrino Piantadosi",
      "Enrico Bagli",
      "Pietro Giuffrida",
      "Davide Posillipo",
      "Giuseppe Primiero"
    ],
    "abstract": "We present a method for quantitative, in-depth analyses of fairness issues in\nAI systems with an application to credit scoring. To this aim we use BRIO, a\ntool for the evaluation of AI systems with respect to social unfairness and,\nmore in general, ethically undesirable behaviours. It features a model-agnostic\nbias detection module, presented in \\cite{DBLP:conf/beware/CoragliaDGGPPQ23},\nto which a full-fledged unfairness risk evaluation module is added. As a case\nstudy, we focus on the context of credit scoring, analysing the UCI German\nCredit Dataset \\cite{misc_statlog_(german_credit_data)_144}. We apply the BRIO\nfairness metrics to several, socially sensitive attributes featured in the\nGerman Credit Dataset, quantifying fairness across various demographic\nsegments, with the aim of identifying potential sources of bias and\ndiscrimination in a credit scoring model. We conclude by combining our results\nwith a revenue analysis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03292v1",
    "published_date": "2024-06-05 14:00:46 UTC",
    "updated_date": "2024-06-05 14:00:46 UTC"
  },
  {
    "arxiv_id": "2406.16909v1",
    "title": "Enhancing Computational Efficiency of Motor Imagery BCI Classification with Block-Toeplitz Augmented Covariance Matrices and Siegel Metric",
    "authors": [
      "Igor Carrara",
      "Theodore Papadopoulo"
    ],
    "abstract": "Electroencephalographic signals are represented as multidimensional datasets.\nWe introduce an enhancement to the augmented covariance method (ACM),\nexploiting more thoroughly its mathematical properties, in order to improve\nmotor imagery classification.Standard ACM emerges as a combination of phase\nspace reconstruction of dynamical systems and of Riemannian geometry. Indeed,\nit is based on the construction of a Symmetric Positive Definite matrix to\nimprove classification. But this matrix also has a Block-Toeplitz structure\nthat was previously ignored. This work treats such matrices in the real\nmanifold to which they belong: the set of Block-Toeplitz SPD matrices. After\nsome manipulation, this set is can be seen as the product of an SPD manifold\nand a Siegel Disk Space.The proposed methodology was tested using the MOABB\nframework with a within-session evaluation procedure. It achieves a similar\nclassification performance to ACM, which is typically better than -- or at\nworse comparable to -- state-of-the-art methods. But, it also improves\nconsequently the computational efficiency over ACM, making it even more\nsuitable for real time experiments.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "math.DG",
      "nlin.CD"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16909v1",
    "published_date": "2024-06-05 13:59:13 UTC",
    "updated_date": "2024-06-05 13:59:13 UTC"
  },
  {
    "arxiv_id": "2406.03283v1",
    "title": "Enhancing Repository-Level Code Generation with Integrated Contextual Information",
    "authors": [
      "Zhiyuan Pan",
      "Xing Hu",
      "Xin Xia",
      "Xiaohu Yang"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\ncode generation tasks. However, repository-level code generation presents\nunique challenges, particularly due to the need to utilize information spread\nacross multiple files within a repository. Existing retrieval-based approaches\nsometimes fall short as they are limited in obtaining a broader and deeper\nrepository context. In this paper, we present CatCoder, a novel code generation\nframework designed for statically typed programming languages. CatCoder\nenhances repository-level code generation by integrating relevant code and type\ncontext. Specifically, it leverages static analyzers to extract type\ndependencies and merges this information with retrieved code to create\ncomprehensive prompts for LLMs. To evaluate the effectiveness of CatCoder, we\nadapt and construct benchmarks that include 199 Java tasks and 90 Rust tasks.\nThe results show that CatCoder outperforms the RepoCoder baseline by up to\n17.35%, in terms of pass@k score. Furthermore, the generalizability of CatCoder\nis assessed using various LLMs, including both code-specialized models and\ngeneral-purpose models. Our findings indicate consistent performance\nimprovements across all models, which underlines the practicality of CatCoder.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03283v1",
    "published_date": "2024-06-05 13:56:42 UTC",
    "updated_date": "2024-06-05 13:56:42 UTC"
  },
  {
    "arxiv_id": "2406.06589v2",
    "title": "PatentEval: Understanding Errors in Patent Generation",
    "authors": [
      "You Zuo",
      "Kim Gerdes",
      "Eric Villemonte de La Clergerie",
      "BenoÃ®t Sagot"
    ],
    "abstract": "In this work, we introduce a comprehensive error typology specifically\ndesigned for evaluating two distinct tasks in machine-generated patent texts:\nclaims-to-abstract generation, and the generation of the next claim given\nprevious ones. We have also developed a benchmark, PatentEval, for\nsystematically assessing language models in this context. Our study includes a\ncomparative analysis, annotated by humans, of various models. These range from\nthose specifically adapted during training for tasks within the patent domain\nto the latest general-purpose large language models (LLMs). Furthermore, we\nexplored and evaluated some metrics to approximate human judgments in patent\ntext evaluation, analyzing the extent to which these metrics align with expert\nassessments. These approaches provide valuable insights into the capabilities\nand limitations of current language models in the specialized field of patent\ntext generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06589v2",
    "published_date": "2024-06-05 13:55:27 UTC",
    "updated_date": "2024-06-25 08:23:03 UTC"
  },
  {
    "arxiv_id": "2406.03280v3",
    "title": "FusionBench: A Comprehensive Benchmark of Deep Model Fusion",
    "authors": [
      "Anke Tang",
      "Li Shen",
      "Yong Luo",
      "Han Hu",
      "Bo Du",
      "Dacheng Tao"
    ],
    "abstract": "Deep model fusion is an emerging technique that unifies the predictions or\nparameters of several deep neural networks into a single model in a\ncost-effective and data-efficient manner. This enables the unified model to\ntake advantage of the original models' strengths, potentially exceeding their\nperformance. Although a variety of deep model fusion techniques have been\nintroduced, their evaluations tend to be inconsistent and often inadequate to\nvalidate their effectiveness and robustness against distribution shifts. To\naddress this issue, we introduce FusionBench, which is the first comprehensive\nbenchmark dedicated to deep model fusion. FusionBench covers a wide range of\ntasks, including open-vocabulary image classification, text classification, and\ntext-to-text generation. Each category includes up to eight tasks with\ncorresponding task-specific models, featuring both full fine-tuning and LoRA\nfine-tuning, as well as models of different sizes, to ensure fair and balanced\ncomparisons of various multi-task model fusion techniques across different\ntasks, model scales, and fine-tuning strategies. We implement and evaluate a\nbroad spectrum of deep model fusion techniques. These techniques range from\nmodel ensemble methods, which combine the predictions to improve the overall\nperformance, to model merging, which integrates different models into a single\none, and model mixing methods, which upscale or recombine the components of the\noriginal models. FusionBench now contains 26 distinct tasks, 74 fine-tuned\nmodels, and 16 fusion techniques, and we are committed to consistently\nexpanding the benchmark with more tasks, models, and fusion techniques. In\naddition, we offer a well-documented set of resources and guidelines to aid\nresearchers in understanding and replicating the benchmark results. Homepage\nhttps://github.com/tanganke/fusion_bench",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Project homepage: https://github.com/tanganke/fusion_bench",
    "pdf_url": "http://arxiv.org/pdf/2406.03280v3",
    "published_date": "2024-06-05 13:54:28 UTC",
    "updated_date": "2024-06-14 07:19:51 UTC"
  },
  {
    "arxiv_id": "2406.03276v2",
    "title": "Revisiting Scalable Hessian Diagonal Approximations for Applications in Reinforcement Learning",
    "authors": [
      "Mohamed Elsayed",
      "Homayoon Farrahi",
      "Felix Dangel",
      "A. Rupam Mahmood"
    ],
    "abstract": "Second-order information is valuable for many applications but challenging to\ncompute. Several works focus on computing or approximating Hessian diagonals,\nbut even this simplification introduces significant additional costs compared\nto computing a gradient. In the absence of efficient exact computation schemes\nfor Hessian diagonals, we revisit an early approximation scheme proposed by\nBecker and LeCun (1989, BL89), which has a cost similar to gradients and\nappears to have been overlooked by the community. We introduce HesScale, an\nimprovement over BL89, which adds negligible extra computation. On small\nnetworks, we find that this improvement is of higher quality than all\nalternatives, even those with theoretical guarantees, such as unbiasedness,\nwhile being much cheaper to compute. We use this insight in reinforcement\nlearning problems where small networks are used and demonstrate HesScale in\nsecond-order optimization and scaling the step-size parameter. In our\nexperiments, HesScale optimizes faster than existing methods and improves\nstability through step-size scaling. These findings are promising for scaling\nsecond-order methods in larger models in the future.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in the Proceedings of the 41st International Conference on\n  Machine Learning (ICML 2024). Code is available at\n  https://github.com/mohmdelsayed/HesScale. arXiv admin note: substantial text\n  overlap with arXiv:2210.11639",
    "pdf_url": "http://arxiv.org/pdf/2406.03276v2",
    "published_date": "2024-06-05 13:53:20 UTC",
    "updated_date": "2024-07-03 21:22:00 UTC"
  },
  {
    "arxiv_id": "2406.03274v2",
    "title": "Enhancing CTC-based speech recognition with diverse modeling units",
    "authors": [
      "Shiyi Han",
      "Zhihong Lei",
      "Mingbin Xu",
      "Xingyu Na",
      "Zhen Huang"
    ],
    "abstract": "In recent years, the evolution of end-to-end (E2E) automatic speech\nrecognition (ASR) models has been remarkable, largely due to advances in deep\nlearning architectures like transformer. On top of E2E systems, researchers\nhave achieved substantial accuracy improvement by rescoring E2E model's N-best\nhypotheses with a phoneme-based model. This raises an interesting question\nabout where the improvements come from other than the system combination\neffect. We examine the underlying mechanisms driving these gains and propose an\nefficient joint training approach, where E2E models are trained jointly with\ndiverse modeling units. This methodology does not only align the strengths of\nboth phoneme and grapheme-based models but also reveals that using these\ndiverse modeling units in a synergistic way can significantly enhance model\naccuracy. Our findings offer new insights into the optimal integration of\nheterogeneous modeling units in the development of more robust and accurate ASR\nsystems.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03274v2",
    "published_date": "2024-06-05 13:52:55 UTC",
    "updated_date": "2024-06-11 15:03:31 UTC"
  },
  {
    "arxiv_id": "2406.03272v3",
    "title": "Multi-Microphone Speech Emotion Recognition using the Hierarchical Token-semantic Audio Transformer Architecture",
    "authors": [
      "Ohad Cohen",
      "Gershon Hazan",
      "Sharon Gannot"
    ],
    "abstract": "The performance of most emotion recognition systems degrades in real-life\nsituations ('in the wild' scenarios) where the audio is contaminated by\nreverberation. Our study explores new methods to alleviate the performance\ndegradation of SER algorithms and develop a more robust system for adverse\nconditions. We propose processing multi-microphone signals to address these\nchallenges and improve emotion classification accuracy. We adopt a\nstate-of-the-art transformer model, the HTS-AT, to handle multi-channel audio\ninputs. We evaluate two strategies: averaging mel-spectrograms across channels\nand summing patch-embedded representations. Our multi-microphone model achieves\nsuperior performance compared to single-channel baselines when tested on\nreal-world reverberant environments.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03272v3",
    "published_date": "2024-06-05 13:50:59 UTC",
    "updated_date": "2024-09-14 20:46:25 UTC"
  },
  {
    "arxiv_id": "2406.03263v1",
    "title": "Deep Generative Models for Proton Zero Degree Calorimeter Simulations in ALICE, CERN",
    "authors": [
      "Patryk BÄdkowski",
      "Jan DubiÅski",
      "Kamil Deja",
      "PrzemysÅaw Rokita"
    ],
    "abstract": "Simulating detector responses is a crucial part of understanding the\ninner-workings of particle collisions in the Large Hadron Collider at CERN. The\ncurrent reliance on statistical Monte-Carlo simulations strains CERN's\ncomputational grid, underscoring the urgency for more efficient alternatives.\nAddressing these challenges, recent proposals advocate for generative machine\nlearning methods. In this study, we present an innovative deep learning\nsimulation approach tailored for the proton Zero Degree Calorimeter in the\nALICE experiment. Leveraging a Generative Adversarial Network model with\nSelective Diversity Increase loss, we directly simulate calorimeter responses.\nTo enhance its capabilities in modeling a broad range of calorimeter response\nintensities, we expand the SDI-GAN architecture with additional regularization.\nMoreover, to improve the spatial fidelity of the generated data, we introduce\nan auxiliary regressor network. Our method offers a significant speedup when\ncomparing to the traditional Monte-Carlo based approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 3 figures, PP-RAI 2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2406.03263v1",
    "published_date": "2024-06-05 13:41:09 UTC",
    "updated_date": "2024-06-05 13:41:09 UTC"
  },
  {
    "arxiv_id": "2406.03251v1",
    "title": "ASoBO: Attentive Beamformer Selection for Distant Speaker Diarization in Meetings",
    "authors": [
      "Theo Mariotte",
      "Anthony Larcher",
      "Silvio Montresor",
      "Jean-Hugh Thomas"
    ],
    "abstract": "Speaker Diarization (SD) aims at grouping speech segments that belong to the\nsame speaker. This task is required in many speech-processing applications,\nsuch as rich meeting transcription. In this context, distant microphone arrays\nusually capture the audio signal. Beamforming, i.e., spatial filtering, is a\ncommon practice to process multi-microphone audio data. However, it often\nrequires an explicit localization of the active source to steer the filter.\nThis paper proposes a self-attention-based algorithm to select the output of a\nbank of fixed spatial filters. This method serves as a feature extractor for\njoint Voice Activity (VAD) and Overlapped Speech Detection (OSD). The speaker\ndiarization is then inferred from the detected segments. The approach shows\nconvincing distant VAD, OSD, and SD performance, e.g. 14.5% DER on the\nAISHELL-4 dataset. The analysis of the self-attention weights demonstrates\ntheir explainability, as they correlate with the speaker's angular locations.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "5 pages, 2 figures, 2 tables, accepted at Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.03251v1",
    "published_date": "2024-06-05 13:28:28 UTC",
    "updated_date": "2024-06-05 13:28:28 UTC"
  },
  {
    "arxiv_id": "2406.03250v1",
    "title": "Prompt-based Visual Alignment for Zero-shot Policy Transfer",
    "authors": [
      "Haihan Gao",
      "Rui Zhang",
      "Qi Yi",
      "Hantao Yao",
      "Haochen Li",
      "Jiaming Guo",
      "Shaohui Peng",
      "Yunkai Gao",
      "QiCheng Wang",
      "Xing Hu",
      "Yuanbo Wen",
      "Zihao Zhang",
      "Zidong Du",
      "Ling Li",
      "Qi Guo",
      "Yunji Chen"
    ],
    "abstract": "Overfitting in RL has become one of the main obstacles to applications in\nreinforcement learning(RL). Existing methods do not provide explicit semantic\nconstrain for the feature extractor, hindering the agent from learning a\nunified cross-domain representation and resulting in performance degradation on\nunseen domains. Besides, abundant data from multiple domains are needed. To\naddress these issues, in this work, we propose prompt-based visual alignment\n(PVA), a robust framework to mitigate the detrimental domain bias in the image\nfor zero-shot policy transfer. Inspired that Visual-Language Model (VLM) can\nserve as a bridge to connect both text space and image space, we leverage the\nsemantic information contained in a text sequence as an explicit constraint to\ntrain a visual aligner. Thus, the visual aligner can map images from multiple\ndomains to a unified domain and achieve good generalization performance. To\nbetter depict semantic information, prompt tuning is applied to learn a\nsequence of learnable tokens. With explicit constraints of semantic\ninformation, PVA can learn unified cross-domain representation under limited\naccess to cross-domain data and achieves great zero-shot generalization ability\nin unseen domains. We verify PVA on a vision-based autonomous driving task with\nCARLA simulator. Experiments show that the agent generalizes well on unseen\ndomains under limited access to multi-domain data.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper has been accepted by ICML2024",
    "pdf_url": "http://arxiv.org/pdf/2406.03250v1",
    "published_date": "2024-06-05 13:26:30 UTC",
    "updated_date": "2024-06-05 13:26:30 UTC"
  },
  {
    "arxiv_id": "2406.03245v2",
    "title": "Reconfiguring Participatory Design to Resist AI Realism",
    "authors": [
      "Aakash Gautam"
    ],
    "abstract": "The growing trend of artificial intelligence (AI) as a solution to social and\ntechnical problems reinforces AI Realism -- the belief that AI is an inevitable\nand natural order. In response, this paper argues that participatory design\n(PD), with its focus on democratic values and processes, can play a role in\nquestioning and resisting AI Realism. I examine three concerning aspects of AI\nRealism: the facade of democratization that lacks true empowerment, demands for\nhuman adaptability in contrast to AI systems' inflexibility, and the\nobfuscation of essential human labor enabling the AI system. I propose\nresisting AI Realism by reconfiguring PD to continue engaging with\nvalue-centered visions, increasing its exploration of non-AI alternatives, and\nmaking the essential human labor underpinning AI systems visible. I position PD\nas a means to generate friction against AI Realism and open space for\nalternative futures centered on human needs and values.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.HC",
    "comment": "6 pages, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2406.03245v2",
    "published_date": "2024-06-05 13:21:46 UTC",
    "updated_date": "2024-06-08 18:19:00 UTC"
  },
  {
    "arxiv_id": "2406.03240v2",
    "title": "Generalized Source Tracing: Detecting Novel Audio Deepfake Algorithm with Real Emphasis and Fake Dispersion Strategy",
    "authors": [
      "Yuankun Xie",
      "Ruibo Fu",
      "Zhengqi Wen",
      "Zhiyong Wang",
      "Xiaopeng Wang",
      "Haonnan Cheng",
      "Long Ye",
      "Jianhua Tao"
    ],
    "abstract": "With the proliferation of deepfake audio, there is an urgent need to\ninvestigate their attribution. Current source tracing methods can effectively\ndistinguish in-distribution (ID) categories. However, the rapid evolution of\ndeepfake algorithms poses a critical challenge in the accurate identification\nof out-of-distribution (OOD) novel deepfake algorithms. In this paper, we\npropose Real Emphasis and Fake Dispersion (REFD) strategy for audio deepfake\nalgorithm recognition, demonstrating its effectiveness in discriminating ID\nsamples while identifying OOD samples. For effective OOD detection, we first\nexplore current post-hoc OOD methods and propose NSD, a novel OOD approach in\nidentifying novel deepfake algorithms through the similarity consideration of\nboth feature and logits scores. REFD achieves 86.83% F1-score as a single\nsystem in Audio Deepfake Detection Challenge 2023 Track3, showcasing its\nstate-of-the-art performance.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by INTERSPEECH 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.03240v2",
    "published_date": "2024-06-05 13:16:55 UTC",
    "updated_date": "2024-06-09 03:33:59 UTC"
  },
  {
    "arxiv_id": "2406.03235v1",
    "title": "Error-preserving Automatic Speech Recognition of Young English Learners' Language",
    "authors": [
      "Janick Michot",
      "Manuela HÃ¼rlimann",
      "Jan Deriu",
      "Luzia Sauer",
      "Katsiaryna Mlynchyk",
      "Mark Cieliebak"
    ],
    "abstract": "One of the central skills that language learners need to practice is speaking\nthe language. Currently, students in school do not get enough speaking\nopportunities and lack conversational practice. Recent advances in speech\ntechnology and natural language processing allow for the creation of novel\ntools to practice their speaking skills. In this work, we tackle the first\ncomponent of such a pipeline, namely, the automated speech recognition module\n(ASR), which faces a number of challenges: first, state-of-the-art ASR models\nare often trained on adult read-aloud data by native speakers and do not\ntransfer well to young language learners' speech. Second, most ASR systems\ncontain a powerful language model, which smooths out errors made by the\nspeakers. To give corrective feedback, which is a crucial part of language\nlearning, the ASR systems in our setting need to preserve the errors made by\nthe language learners. In this work, we build an ASR system that satisfies\nthese requirements: it works on spontaneous speech by young language learners\nand preserves their errors. For this, we collected a corpus containing around\n85 hours of English audio spoken by learners in Switzerland from grades 4 to 6\non different language learning tasks, which we used to train an ASR model. Our\nexperiments show that our model benefits from direct fine-tuning on children's\nvoices and has a much higher error preservation rate than other models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ACL 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2406.03235v1",
    "published_date": "2024-06-05 13:15:37 UTC",
    "updated_date": "2024-06-05 13:15:37 UTC"
  },
  {
    "arxiv_id": "2406.03234v1",
    "title": "Fine-Grained Causal Dynamics Learning with Quantization for Improving Robustness in Reinforcement Learning",
    "authors": [
      "Inwoo Hwang",
      "Yunhyeok Kwak",
      "Suhyung Choi",
      "Byoung-Tak Zhang",
      "Sanghack Lee"
    ],
    "abstract": "Causal dynamics learning has recently emerged as a promising approach to\nenhancing robustness in reinforcement learning (RL). Typically, the goal is to\nbuild a dynamics model that makes predictions based on the causal relationships\namong the entities. Despite the fact that causal connections often manifest\nonly under certain contexts, existing approaches overlook such fine-grained\nrelationships and lack a detailed understanding of the dynamics. In this work,\nwe propose a novel dynamics model that infers fine-grained causal structures\nand employs them for prediction, leading to improved robustness in RL. The key\nidea is to jointly learn the dynamics model with a discrete latent variable\nthat quantizes the state-action space into subgroups. This leads to recognizing\nmeaningful context that displays sparse dependencies, where causal structures\nare learned for each subgroup throughout the training. Experimental results\ndemonstrate the robustness of our method to unseen states and locally spurious\ncorrelations in downstream tasks where fine-grained causal reasoning is\ncrucial. We further illustrate the effectiveness of our subgroup-based approach\nwith quantization in discovering fine-grained causal relationships compared to\nprior methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.03234v1",
    "published_date": "2024-06-05 13:13:58 UTC",
    "updated_date": "2024-06-05 13:13:58 UTC"
  },
  {
    "arxiv_id": "2406.03229v4",
    "title": "Global Clipper: Enhancing Safety and Reliability of Transformer-based Object Detection Models",
    "authors": [
      "Qutub Syed Sha",
      "Michael Paulitsch",
      "Karthik Pattabiraman",
      "Korbinian Hagn",
      "Fabian Oboril",
      "Cornelius Buerkle",
      "Kay-Ulrich Scholl",
      "Gereon Hinz",
      "Alois Knoll"
    ],
    "abstract": "As transformer-based object detection models progress, their impact in\ncritical sectors like autonomous vehicles and aviation is expected to grow.\nSoft errors causing bit flips during inference have significantly impacted DNN\nperformance, altering predictions. Traditional range restriction solutions for\nCNNs fall short for transformers. This study introduces the Global Clipper and\nGlobal Hybrid Clipper, effective mitigation strategies specifically designed\nfor transformer-based models. It significantly enhances their resilience to\nsoft errors and reduces faulty inferences to ~ 0\\%. We also detail extensive\ntesting across over 64 scenarios involving two transformer models (DINO-DETR\nand Lite-DETR) and two CNN models (YOLOv3 and SSD) using three datasets,\ntotalling approximately 3.3 million inferences, to assess model robustness\ncomprehensively. Moreover, the paper explores unique aspects of attention\nblocks in transformers and their operational differences from CNNs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at IJCAI-AISafety'24 Workshop",
    "pdf_url": "http://arxiv.org/pdf/2406.03229v4",
    "published_date": "2024-06-05 13:06:17 UTC",
    "updated_date": "2024-07-09 10:23:53 UTC"
  },
  {
    "arxiv_id": "2407.16886v1",
    "title": "GPT-4's One-Dimensional Mapping of Morality: How the Accuracy of Country-Estimates Depends on Moral Domain",
    "authors": [
      "Pontus Strimling",
      "Joel Krueger",
      "Simon Karlsson"
    ],
    "abstract": "Prior research demonstrates that Open AI's GPT models can predict variations\nin moral opinions between countries but that the accuracy tends to be\nsubstantially higher among high-income countries compared to low-income ones.\nThis study aims to replicate previous findings and advance the research by\nexamining how accuracy varies with different types of moral questions. Using\nresponses from the World Value Survey and the European Value Study, covering 18\nmoral issues across 63 countries, we calculated country-level mean scores for\neach moral issue and compared them with GPT-4's predictions. Confirming\nprevious findings, our results show that GPT-4 has greater predictive success\nin high-income than in low-income countries. However, our factor analysis\nreveals that GPT-4 bases its predictions primarily on a single dimension,\npresumably reflecting countries' degree of conservatism/liberalism. Conversely,\nthe real-world moral landscape appears to be two-dimensional, differentiating\nbetween personal-sexual and violent-dishonest issues. When moral issues are\ncategorized based on their moral domain, GPT-4's predictions are found to be\nremarkably accurate in the personal-sexual domain, across both high-income (r =\n.77) and low-income (r = .58) countries. Yet the predictive accuracy\nsignificantly drops in the violent-dishonest domain for both high-income (r =\n.30) and low-income (r = -.16) countries, indicating that GPT-4's\none-dimensional world-view does not fully capture the complexity of the moral\nlandscape. In sum, this study underscores the importance of not only\nconsidering country-specific characteristics to understand GPT-4's moral\nunderstanding, but also the characteristics of the moral issues at hand.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.16886v1",
    "published_date": "2024-06-05 12:58:45 UTC",
    "updated_date": "2024-06-05 12:58:45 UTC"
  },
  {
    "arxiv_id": "2406.03216v1",
    "title": "Choice of PEFT Technique in Continual Learning: Prompt Tuning is Not All You Need",
    "authors": [
      "Martin Wistuba",
      "Prabhu Teja Sivaprasad",
      "Lukas Balles",
      "Giovanni Zappella"
    ],
    "abstract": "Recent Continual Learning (CL) methods have combined pretrained Transformers\nwith prompt tuning, a parameter-efficient fine-tuning (PEFT) technique. We\nargue that the choice of prompt tuning in prior works was an undefended and\nunablated decision, which has been uncritically adopted by subsequent research,\nbut warrants further research to understand its implications. In this paper, we\nconduct this research and find that the choice of prompt tuning as a PEFT\nmethod hurts the overall performance of the CL system. To illustrate this, we\nreplace prompt tuning with LoRA in two state-of-the-art continual learning\nmethods: Learning to Prompt and S-Prompts. These variants consistently achieve\nhigher accuracy across a wide range of domain-incremental and class-incremental\nbenchmarks, while being competitive in inference speed. Our work highlights a\ncrucial argument: unexamined choices can hinder progress in the field, and\nrigorous ablations, such as the PEFT method, are required to drive meaningful\nadoption of CL techniques in real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03216v1",
    "published_date": "2024-06-05 12:53:37 UTC",
    "updated_date": "2024-06-05 12:53:37 UTC"
  },
  {
    "arxiv_id": "2406.03209v1",
    "title": "Challenges and Considerations in the Evaluation of Bayesian Causal Discovery",
    "authors": [
      "Amir Mohammad Karimi Mamaghan",
      "Panagiotis Tigas",
      "Karl Henrik Johansson",
      "Yarin Gal",
      "Yashas Annadani",
      "Stefan Bauer"
    ],
    "abstract": "Representing uncertainty in causal discovery is a crucial component for\nexperimental design, and more broadly, for safe and reliable causal decision\nmaking. Bayesian Causal Discovery (BCD) offers a principled approach to\nencapsulating this uncertainty. Unlike non-Bayesian causal discovery, which\nrelies on a single estimated causal graph and model parameters for assessment,\nevaluating BCD presents challenges due to the nature of its inferred quantity -\nthe posterior distribution. As a result, the research community has proposed\nvarious metrics to assess the quality of the approximate posterior. However,\nthere is, to date, no consensus on the most suitable metric(s) for evaluation.\nIn this work, we reexamine this question by dissecting various metrics and\nunderstanding their limitations. Through extensive empirical evaluation, we\nfind that many existing metrics fail to exhibit a strong correlation with the\nquality of approximation to the true posterior, especially in scenarios with\nlow sample sizes where BCD is most desirable. We highlight the suitability (or\nlack thereof) of these metrics under two distinct factors: the identifiability\nof the underlying causal model and the quantity of available data. Both factors\naffect the entropy of the true posterior, indicating that the current metrics\nare less fitting in settings of higher entropy. Our findings underline the\nimportance of a more nuanced evaluation of new methods by taking into account\nthe nature of the true posterior, as well as guide and motivate the development\nof new evaluation procedures for this challenge.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03209v1",
    "published_date": "2024-06-05 12:45:23 UTC",
    "updated_date": "2024-06-05 12:45:23 UTC"
  },
  {
    "arxiv_id": "2406.03202v2",
    "title": "ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction",
    "authors": [
      "Jeiyoon Park",
      "Chanjun Park",
      "Heuiseok Lim"
    ],
    "abstract": "We explore and improve the capabilities of LLMs to generate data for\ngrammatical error correction (GEC). When merely producing parallel sentences,\ntheir patterns are too simplistic to be valuable as a corpus. To address this\nissue, we propose an automated framework that includes a Subject Selector,\nGrammar Selector, Prompt Manager, and Evaluator. Additionally, we introduce a\nnew dataset for GEC tasks, named ChatLang-8, which encompasses eight types of\nsubject nouns and 23 types of grammar. It consists of 1 million pairs featuring\nhuman-like grammatical errors. Our experiments reveal that ChatLang-8 exhibits\na more uniform pattern composition compared to existing GEC datasets.\nFurthermore, we observe improved model performance when using ChatLang-8\ninstead of existing GEC datasets. The experimental results suggest that our\nframework and ChatLang-8 are valuable resources for enhancing ChatGPT's data\ngeneration capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2406.03202v2",
    "published_date": "2024-06-05 12:35:00 UTC",
    "updated_date": "2024-06-11 07:06:34 UTC"
  },
  {
    "arxiv_id": "2406.06588v1",
    "title": "Assessing the Emergent Symbolic Reasoning Abilities of Llama Large Language Models",
    "authors": [
      "Flavio Petruzzellis",
      "Alberto Testolin",
      "Alessandro Sperduti"
    ],
    "abstract": "Large Language Models (LLMs) achieve impressive performance in a wide range\nof tasks, even if they are often trained with the only objective of chatting\nfluently with users. Among other skills, LLMs show emergent abilities in\nmathematical reasoning benchmarks, which can be elicited with appropriate\nprompting methods. In this work, we systematically investigate the capabilities\nand limitations of popular open-source LLMs on different symbolic reasoning\ntasks. We evaluate three models of the Llama 2 family on two datasets that\nrequire solving mathematical formulas of varying degrees of difficulty. We test\na generalist LLM (Llama 2 Chat) as well as two fine-tuned versions of Llama 2\n(MAmmoTH and MetaMath) specifically designed to tackle mathematical problems.\nWe observe that both increasing the scale of the model and fine-tuning it on\nrelevant tasks lead to significant performance gains. Furthermore, using\nfine-grained evaluation measures, we find that such performance gains are\nmostly observed with mathematical formulas of low complexity, which\nnevertheless often remain challenging even for the largest fine-tuned models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at 33rd International Conference on Artificial Neural\n  Networks (ICANN24)",
    "pdf_url": "http://arxiv.org/pdf/2406.06588v1",
    "published_date": "2024-06-05 12:22:43 UTC",
    "updated_date": "2024-06-05 12:22:43 UTC"
  },
  {
    "arxiv_id": "2406.03188v1",
    "title": "Situation Monitor: Diversity-Driven Zero-Shot Out-of-Distribution Detection using Budding Ensemble Architecture for Object Detection",
    "authors": [
      "Qutub Syed",
      "Michael Paulitsch",
      "Korbinian Hagn",
      "Neslihan Kose Cihangir",
      "Kay-Ulrich Scholl",
      "Fabian Oboril",
      "Gereon Hinz",
      "Alois Knoll"
    ],
    "abstract": "We introduce Situation Monitor, a novel zero-shot Out-of-Distribution (OOD)\ndetection approach for transformer-based object detection models to enhance\nreliability in safety-critical machine learning applications such as autonomous\ndriving. The Situation Monitor utilizes the Diversity-based Budding Ensemble\nArchitecture (DBEA) and increases the OOD performance by integrating a\ndiversity loss into the training process on top of the budding ensemble\narchitecture, detecting Far-OOD samples and minimizing false positives on\nNear-OOD samples. Moreover, utilizing the resulting DBEA increases the model's\nOOD performance and improves the calibration of confidence scores, particularly\nconcerning the intersection over union of the detected objects. The DBEA model\nachieves these advancements with a 14% reduction in trainable parameters\ncompared to the vanilla model. This signifies a substantial improvement in\nefficiency without compromising the model's ability to detect OOD instances and\ncalibrate the confidence scores accurately.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Paper accepted at CVPR SAIAD Workshop",
    "pdf_url": "http://arxiv.org/pdf/2406.03188v1",
    "published_date": "2024-06-05 12:20:36 UTC",
    "updated_date": "2024-06-05 12:20:36 UTC"
  },
  {
    "arxiv_id": "2406.03158v1",
    "title": "CSS: Contrastive Semantic Similarity for Uncertainty Quantification of LLMs",
    "authors": [
      "Shuang Ao",
      "Stefan Rueger",
      "Advaith Siddharthan"
    ],
    "abstract": "Despite the impressive capability of large language models (LLMs), knowing\nwhen to trust their generations remains an open challenge. The recent\nliterature on uncertainty quantification of natural language generation (NLG)\nutilises a conventional natural language inference (NLI) classifier to measure\nthe semantic dispersion of LLMs responses. These studies employ logits of NLI\nclassifier for semantic clustering to estimate uncertainty. However, logits\nrepresent the probability of the predicted class and barely contain feature\ninformation for potential clustering. Alternatively, CLIP (Contrastive\nLanguage-Image Pre-training) performs impressively in extracting image-text\npair features and measuring their similarity. To extend its usability, we\npropose Contrastive Semantic Similarity, the CLIP-based feature extraction\nmodule to obtain similarity features for measuring uncertainty for text pairs.\nWe apply this method to selective NLG, which detects and rejects unreliable\ngenerations for better trustworthiness of LLMs. We conduct extensive\nexperiments with three LLMs on several benchmark question-answering datasets\nwith comprehensive evaluation metrics. Results show that our proposed method\nperforms better in estimating reliable responses of LLMs than comparable\nbaselines. Results show that our proposed method performs better in estimating\nreliable responses of LLMs than comparable baselines. The code are available at\n\\url{https://github.com/AoShuang92/css_uq_llms}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The paper is accepted by The Conference on Uncertainty in Artificial\n  Intelligence (UAI), 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.03158v1",
    "published_date": "2024-06-05 11:35:44 UTC",
    "updated_date": "2024-06-05 11:35:44 UTC"
  },
  {
    "arxiv_id": "2406.03154v2",
    "title": "Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks: An Extended Investigation",
    "authors": [
      "Marvin Schmitt",
      "Paul-Christian BÃ¼rkner",
      "Ullrich KÃ¶the",
      "Stefan T. Radev"
    ],
    "abstract": "Recent advances in probabilistic deep learning enable efficient amortized\nBayesian inference in settings where the likelihood function is only implicitly\ndefined by a simulation program (simulation-based inference; SBI). But how\nfaithful is such inference if the simulation represents reality somewhat\ninaccurately, that is, if the true system behavior at test time deviates from\nthe one seen during training? We conceptualize the types of such model\nmisspecification arising in SBI and systematically investigate how the\nperformance of neural posterior approximators gradually deteriorates as a\nconsequence, making inference results less and less trustworthy. To notify\nusers about this problem, we propose a new misspecification measure that can be\ntrained in an unsupervised fashion (i.e., without training data from the true\ndistribution) and reliably detects model misspecification at test time. Our\nexperiments clearly demonstrate the utility of our new measure both on toy\nexamples with an analytical ground-truth and on representative scientific tasks\nin cell biology, cognitive decision making, disease outbreak dynamics, and\ncomputer vision. We show how the proposed misspecification test warns users\nabout suspicious outputs, raises an alarm when predictions are not trustworthy,\nand guides model designers in their search for better simulators.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Extended version of the conference paper\n  https://doi.org/10.1007/978-3-031-54605-1_35. arXiv admin note: text overlap\n  with arXiv:2112.08866",
    "pdf_url": "http://arxiv.org/pdf/2406.03154v2",
    "published_date": "2024-06-05 11:30:16 UTC",
    "updated_date": "2024-06-06 12:58:17 UTC"
  },
  {
    "arxiv_id": "2406.03136v1",
    "title": "Computational Limits of Low-Rank Adaptation (LoRA) for Transformer-Based Models",
    "authors": [
      "Jerry Yao-Chieh Hu",
      "Maojiang Su",
      "En-Jui Kuo",
      "Zhao Song",
      "Han Liu"
    ],
    "abstract": "We study the computational limits of Low-Rank Adaptation (LoRA) update for\nfinetuning transformer-based models using fine-grained complexity theory. Our\nkey observation is that the existence of low-rank decompositions within the\ngradient computation of LoRA adaptation leads to possible algorithmic speedup.\nThis allows us to (i) identify a phase transition behavior and (ii) prove the\nexistence of nearly linear algorithms by controlling the LoRA update\ncomputation term by term, assuming the Strong Exponential Time Hypothesis\n(SETH). For the former, we identify a sharp transition in the efficiency of all\npossible rank-$r$ LoRA update algorithms for transformers, based on specific\nnorms resulting from the multiplications of the input sequence $\\mathbf{X}$,\npretrained weights $\\mathbf{W^\\star}$, and adapter matrices $\\alpha \\mathbf{B}\n\\mathbf{A} / r$. Specifically, we derive a shared upper bound threshold for\nsuch norms and show that efficient (sub-quadratic) approximation algorithms of\nLoRA exist only below this threshold. For the latter, we prove the existence of\nnearly linear approximation algorithms for LoRA adaptation by utilizing the\nhierarchical low-rank structures of LoRA gradients and approximating the\ngradients with a series of chained low-rank approximations. To showcase our\ntheory, we consider two practical scenarios: partial (e.g., only $\\mathbf{W}_V$\nand $\\mathbf{W}_Q$) and full adaptations (e.g., $\\mathbf{W}_Q$, $\\mathbf{W}_V$,\nand $\\mathbf{W}_K$) of weights in attention heads.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03136v1",
    "published_date": "2024-06-05 10:44:08 UTC",
    "updated_date": "2024-06-05 10:44:08 UTC"
  },
  {
    "arxiv_id": "2406.03512v3",
    "title": "Harder or Different? Understanding Generalization of Audio Deepfake Detection",
    "authors": [
      "Nicolas M. MÃ¼ller",
      "Nicholas Evans",
      "Hemlata Tak",
      "Philip Sperl",
      "Konstantin BÃ¶ttinger"
    ],
    "abstract": "Recent research has highlighted a key issue in speech deepfake detection:\nmodels trained on one set of deepfakes perform poorly on others. The question\narises: is this due to the continuously improving quality of Text-to-Speech\n(TTS) models, i.e., are newer DeepFakes just 'harder' to detect? Or, is it\nbecause deepfakes generated with one model are fundamentally different to those\ngenerated using another model? We answer this question by decomposing the\nperformance gap between in-domain and out-of-domain test data into 'hardness'\nand 'difference' components. Experiments performed using ASVspoof databases\nindicate that the hardness component is practically negligible, with the\nperformance gap being attributed primarily to the difference component. This\nhas direct implications for real-world deepfake detection, highlighting that\nmerely increasing model capacity, the currently-dominant research trend, may\nnot effectively address the generalization challenge.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03512v3",
    "published_date": "2024-06-05 10:33:15 UTC",
    "updated_date": "2024-06-12 16:54:01 UTC"
  },
  {
    "arxiv_id": "2406.03511v1",
    "title": "MagiNet: Mask-Aware Graph Imputation Network for Incomplete Traffic Data",
    "authors": [
      "Jianping Zhou",
      "Bin Lu",
      "Zhanyu Liu",
      "Siyu Pan",
      "Xuejun Feng",
      "Hua Wei",
      "Guanjie Zheng",
      "Xinbing Wang",
      "Chenghu Zhou"
    ],
    "abstract": "Due to detector malfunctions and communication failures, missing data is\nubiquitous during the collection of traffic data. Therefore, it is of vital\nimportance to impute the missing values to facilitate data analysis and\ndecision-making for Intelligent Transportation System (ITS). However, existing\nimputation methods generally perform zero pre-filling techniques to initialize\nmissing values, introducing inevitable noises. Moreover, we observe prevalent\nover-smoothing interpolations, falling short in revealing the intrinsic\nspatio-temporal correlations of incomplete traffic data. To this end, we\npropose Mask-Aware Graph imputation Network: MagiNet. Our method designs an\nadaptive mask spatio-temporal encoder to learn the latent representations of\nincomplete data, eliminating the reliance on pre-filling missing values.\nFurthermore, we devise a spatio-temporal decoder that stacks multiple blocks to\ncapture the inherent spatial and temporal dependencies within incomplete\ntraffic data, alleviating over-smoothing imputation. Extensive experiments\ndemonstrate that our method outperforms state-of-the-art imputation methods on\nfive real-world traffic datasets, yielding an average improvement of 4.31% in\nRMSE and 3.72% in MAPE.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.03511v1",
    "published_date": "2024-06-05 10:06:07 UTC",
    "updated_date": "2024-06-05 10:06:07 UTC"
  },
  {
    "arxiv_id": "2406.03102v1",
    "title": "DEER: A Delay-Resilient Framework for Reinforcement Learning with Variable Delays",
    "authors": [
      "Bo Xia",
      "Yilun Kong",
      "Yongzhe Chang",
      "Bo Yuan",
      "Zhiheng Li",
      "Xueqian Wang",
      "Bin Liang"
    ],
    "abstract": "Classic reinforcement learning (RL) frequently confronts challenges in tasks\ninvolving delays, which cause a mismatch between received observations and\nsubsequent actions, thereby deviating from the Markov assumption. Existing\nmethods usually tackle this issue with end-to-end solutions using state\naugmentation. However, these black-box approaches often involve\nincomprehensible processes and redundant information in the information states,\ncausing instability and potentially undermining the overall performance. To\nalleviate the delay challenges in RL, we propose $\\textbf{DEER (Delay-resilient\nEncoder-Enhanced RL)}$, a framework designed to effectively enhance the\ninterpretability and address the random delay issues. DEER employs a pretrained\nencoder to map delayed states, along with their variable-length past action\nsequences resulting from different delays, into hidden states, which is trained\non delay-free environment datasets. In a variety of delayed scenarios, the\ntrained encoder can seamlessly integrate with standard RL algorithms without\nrequiring additional modifications and enhance the delay-solving capability by\nsimply adapting the input dimension of the original algorithms. We evaluate\nDEER through extensive experiments on Gym and Mujoco environments. The results\nconfirm that DEER is superior to state-of-the-art RL algorithms in both\nconstant and random delay settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03102v1",
    "published_date": "2024-06-05 09:45:26 UTC",
    "updated_date": "2024-06-05 09:45:26 UTC"
  },
  {
    "arxiv_id": "2406.03510v2",
    "title": "Speech-based Clinical Depression Screening: An Empirical Study",
    "authors": [
      "Yangbin Chen",
      "Chenyang Xu",
      "Chunfeng Liang",
      "Yanbao Tao",
      "Chuan Shi"
    ],
    "abstract": "This study investigates the utility of speech signals for AI-based depression\nscreening across varied interaction scenarios, including psychiatric\ninterviews, chatbot conversations, and text readings. Participants include\ndepressed patients recruited from the outpatient clinics of Peking University\nSixth Hospital and control group members from the community, all diagnosed by\npsychiatrists following standardized diagnostic protocols. We extracted\nacoustic and deep speech features from each participant's segmented recordings.\nClassifications were made using neural networks or SVMs, with aggregated clip\noutcomes determining final assessments. Our analysis across interaction\nscenarios, speech processing techniques, and feature types confirms speech as a\ncrucial marker for depression screening. Specifically, human-computer\ninteraction matches clinical interview efficacy, surpassing reading tasks.\nSegment duration and quantity significantly affect model performance, with deep\nspeech features substantially outperforming traditional acoustic features.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "5 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.03510v2",
    "published_date": "2024-06-05 09:43:54 UTC",
    "updated_date": "2024-06-12 08:13:04 UTC"
  },
  {
    "arxiv_id": "2406.03097v1",
    "title": "Enhancing the Resilience of Graph Neural Networks to Topological Perturbations in Sparse Graphs",
    "authors": [
      "Shuqi He",
      "Jun Zhuang",
      "Ding Wang",
      "Luyao Peng",
      "Jun Song"
    ],
    "abstract": "Graph neural networks (GNNs) have been extensively employed in node\nclassification. Nevertheless, recent studies indicate that GNNs are vulnerable\nto topological perturbations, such as adversarial attacks and edge disruptions.\nConsiderable efforts have been devoted to mitigating these challenges. For\nexample, pioneering Bayesian methodologies, including GraphSS and LlnDT,\nincorporate Bayesian label transitions and topology-based label sampling to\nstrengthen the robustness of GNNs. However, GraphSS is hindered by slow\nconvergence, while LlnDT faces challenges in sparse graphs. To overcome these\nlimitations, we propose a novel label inference framework, TraTopo, which\ncombines topology-driven label propagation, Bayesian label transitions, and\nlink analysis via random walks. TraTopo significantly surpasses its\npredecessors on sparse graphs by utilizing random walk sampling, specifically\ntargeting isolated nodes for link prediction, thus enhancing its effectiveness\nin topological sampling contexts. Additionally, TraTopo employs a shortest-path\nstrategy to refine link prediction, thereby reducing predictive overhead and\nimproving label inference accuracy. Empirical evaluations highlight TraTopo's\nsuperiority in node classification, significantly exceeding contemporary GCN\nmodels in accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03097v1",
    "published_date": "2024-06-05 09:40:08 UTC",
    "updated_date": "2024-06-05 09:40:08 UTC"
  },
  {
    "arxiv_id": "2406.03095v4",
    "title": "EgoSurgery-Tool: A Dataset of Surgical Tool and Hand Detection from Egocentric Open Surgery Videos",
    "authors": [
      "Ryo Fujii",
      "Hideo Saito",
      "Hiroki Kajita"
    ],
    "abstract": "Surgical tool detection is a fundamental task for understanding egocentric\nopen surgery videos. However, detecting surgical tools presents significant\nchallenges due to their highly imbalanced class distribution, similar shapes\nand similar textures, and heavy occlusion. The lack of a comprehensive\nlarge-scale dataset compounds these challenges. In this paper, we introduce\nEgoSurgery-Tool, an extension of the existing EgoSurgery-Phase dataset, which\ncontains real open surgery videos captured using an egocentric camera attached\nto the surgeon's head, along with phase annotations. EgoSurgery-Tool has been\ndensely annotated with surgical tools and comprises over 49K surgical tool\nbounding boxes across 15 categories, constituting a large-scale surgical tool\ndetection dataset. EgoSurgery-Tool also provides annotations for hand detection\nwith over 46K hand-bounding boxes, capturing hand-object interactions that are\ncrucial for understanding activities in egocentric open surgery.\nEgoSurgery-Tool is superior to existing datasets due to its larger scale,\ngreater variety of surgical tools, more annotations, and denser scenes. We\nconduct a comprehensive analysis of EgoSurgery-Tool using nine popular object\ndetectors to assess their effectiveness in both surgical tool and hand\ndetection. The dataset will be released at\nhttps://github.com/Fujiry0/EgoSurgery.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03095v4",
    "published_date": "2024-06-05 09:36:15 UTC",
    "updated_date": "2024-11-27 04:30:46 UTC"
  },
  {
    "arxiv_id": "2406.03091v1",
    "title": "Improving Plan Execution Flexibility using Block-Substitution",
    "authors": [
      "Sabah Binte Noor",
      "Fazlul Hasan Siddiqui"
    ],
    "abstract": "Partial-order plans in AI planning facilitate execution flexibility due to\ntheir less-constrained nature. Maximizing plan flexibility has been studied\nthrough the notions of plan deordering, and plan reordering. Plan deordering\nremoves unnecessary action orderings within a plan, while plan reordering\nmodifies them arbitrarily to minimize action orderings. This study, in contrast\nwith traditional plan deordering and reordering strategies, improves a plan's\nflexibility by substituting its subplans with actions outside the plan for a\nplanning problem. We exploit block deordering, which eliminates orderings in a\nPOP by encapsulating coherent actions in blocks, to construct action blocks as\ncandidate subplans for substitutions. In addition, this paper introduces a\npruning technique for eliminating redundant actions within a BDPO plan. We also\nevaluate our approach when combined with MaxSAT-based reorderings. Our\nexperimental result demonstrates a significant improvement in plan execution\nflexibility on the benchmark problems from International Planning Competitions\n(IPC), maintaining good coverage and execution time.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03091v1",
    "published_date": "2024-06-05 09:30:48 UTC",
    "updated_date": "2024-06-05 09:30:48 UTC"
  },
  {
    "arxiv_id": "2406.03079v1",
    "title": "Cryptocurrency Frauds for Dummies: How ChatGPT introduces us to fraud?",
    "authors": [
      "Wail Zellagui",
      "Abdessamad Imine",
      "Yamina Tadjeddine"
    ],
    "abstract": "Recent advances in the field of large language models (LLMs), particularly\nthe ChatGPT family, have given rise to a powerful and versatile machine\ninterlocutor, packed with knowledge and challenging our understanding of\nlearning. This interlocutor is a double-edged sword: it can be harnessed for a\nwide variety of beneficial tasks, but it can also be used to cause harm. This\nstudy explores the complicated interaction between ChatGPT and the growing\nproblem of cryptocurrency fraud. Although ChatGPT is known for its adaptability\nand ethical considerations when used for harmful purposes, we highlight the\ndeep connection that may exist between ChatGPT and fraudulent actions in the\nvolatile cryptocurrency ecosystem. Based on our categorization of\ncryptocurrency frauds, we show how to influence outputs, bypass ethical terms,\nand achieve specific fraud goals by manipulating ChatGPT prompts. Furthermore,\nour findings emphasize the importance of realizing that ChatGPT could be a\nvaluable instructor even for novice fraudsters, as well as understanding and\nsafely deploying complex language models, particularly in the context of\ncryptocurrency frauds. Finally, our study underlines the importance of using\nLLMs responsibly and ethically in the digital currency sector, identifying\npotential risks and resolving ethical issues. It should be noted that our work\nis not intended to encourage and promote fraud, but rather to raise awareness\nof the risks of fraud associated with the use of ChatGPT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To be published in ACM journal \"Digital Government: Research and\n  Practice\"",
    "pdf_url": "http://arxiv.org/pdf/2406.03079v1",
    "published_date": "2024-06-05 09:09:32 UTC",
    "updated_date": "2024-06-05 09:09:32 UTC"
  },
  {
    "arxiv_id": "2406.03078v1",
    "title": "Towards Federated Domain Unlearning: Verification Methodologies and Challenges",
    "authors": [
      "Kahou Tam",
      "Kewei Xu",
      "Li Li",
      "Huazhu Fu"
    ],
    "abstract": "Federated Learning (FL) has evolved as a powerful tool for collaborative\nmodel training across multiple entities, ensuring data privacy in sensitive\nsectors such as healthcare and finance. However, the introduction of the Right\nto Be Forgotten (RTBF) poses new challenges, necessitating federated unlearning\nto delete data without full model retraining. Traditional FL unlearning\nmethods, not originally designed with domain specificity in mind, inadequately\naddress the complexities of multi-domain scenarios, often affecting the\naccuracy of models in non-targeted domains or leading to uniform forgetting\nacross all domains. Our work presents the first comprehensive empirical study\non Federated Domain Unlearning, analyzing the characteristics and challenges of\ncurrent techniques in multi-domain contexts. We uncover that these methods\nfalter, particularly because they neglect the nuanced influences of\ndomain-specific data, which can lead to significant performance degradation and\ninaccurate model behavior. Our findings reveal that unlearning\ndisproportionately affects the model's deeper layers, erasing critical\nrepresentational subspaces acquired during earlier training phases. In\nresponse, we propose novel evaluation methodologies tailored for Federated\nDomain Unlearning, aiming to accurately assess and verify domain-specific data\nerasure without compromising the model's overall integrity and performance.\nThis investigation not only highlights the urgent need for domain-centric\nunlearning strategies in FL but also sets a new precedent for evaluating and\nimplementing these techniques effectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.03078v1",
    "published_date": "2024-06-05 09:05:55 UTC",
    "updated_date": "2024-06-05 09:05:55 UTC"
  },
  {
    "arxiv_id": "2406.03071v1",
    "title": "Exploiting LMM-based knowledge for image classification tasks",
    "authors": [
      "Maria Tzelepi",
      "Vasileios Mezaris"
    ],
    "abstract": "In this paper we address image classification tasks leveraging knowledge\nencoded in Large Multimodal Models (LMMs). More specifically, we use the\nMiniGPT-4 model to extract semantic descriptions for the images, in a\nmultimodal prompting fashion. In the current literature, vision language models\nsuch as CLIP, among other approaches, are utilized as feature extractors, using\nonly the image encoder, for solving image classification tasks. In this paper,\nwe propose to additionally use the text encoder to obtain the text embeddings\ncorresponding to the MiniGPT-4-generated semantic descriptions. Thus, we use\nboth the image and text embeddings for solving the image classification task.\nThe experimental evaluation on three datasets validates the improved\nclassification performance achieved by exploiting LMM-based knowledge.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for publication, 25th Int. Conf. on Engineering Applications\n  of Neural Networks (EANN/EAAAI 2024), Corfu, Greece, June 2024. This is the\n  \"submitted manuscript\"",
    "pdf_url": "http://arxiv.org/pdf/2406.03071v1",
    "published_date": "2024-06-05 08:56:24 UTC",
    "updated_date": "2024-06-05 08:56:24 UTC"
  },
  {
    "arxiv_id": "2406.03070v2",
    "title": "A-Bench: Are LMMs Masters at Evaluating AI-generated Images?",
    "authors": [
      "Zicheng Zhang",
      "Haoning Wu",
      "Chunyi Li",
      "Yingjie Zhou",
      "Wei Sun",
      "Xiongkuo Min",
      "Zijian Chen",
      "Xiaohong Liu",
      "Weisi Lin",
      "Guangtao Zhai"
    ],
    "abstract": "How to accurately and efficiently assess AI-generated images (AIGIs) remains\na critical challenge for generative models. Given the high costs and extensive\ntime commitments required for user studies, many researchers have turned\ntowards employing large multi-modal models (LMMs) as AIGI evaluators, the\nprecision and validity of which are still questionable. Furthermore,\ntraditional benchmarks often utilize mostly natural-captured content rather\nthan AIGIs to test the abilities of LMMs, leading to a noticeable gap for\nAIGIs. Therefore, we introduce A-Bench in this paper, a benchmark designed to\ndiagnose whether LMMs are masters at evaluating AIGIs. Specifically, A-Bench is\norganized under two key principles: 1) Emphasizing both high-level semantic\nunderstanding and low-level visual quality perception to address the intricate\ndemands of AIGIs. 2) Various generative models are utilized for AIGI creation,\nand various LMMs are employed for evaluation, which ensures a comprehensive\nvalidation scope. Ultimately, 2,864 AIGIs from 16 text-to-image models are\nsampled, each paired with question-answers annotated by human experts, and\ntested across 18 leading LMMs. We hope that A-Bench will significantly enhance\nthe evaluation process and promote the generation quality for AIGIs. The\nbenchmark is available at https://github.com/Q-Future/A-Bench.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03070v2",
    "published_date": "2024-06-05 08:55:02 UTC",
    "updated_date": "2025-02-07 04:20:54 UTC"
  },
  {
    "arxiv_id": "2406.03069v3",
    "title": "\"Give Me an Example Like This\": Episodic Active Reinforcement Learning from Demonstrations",
    "authors": [
      "Muhan Hou",
      "Koen Hindriks",
      "A. E. Eiben",
      "Kim Baraka"
    ],
    "abstract": "Reinforcement Learning (RL) has achieved great success in sequential\ndecision-making problems, but often at the cost of a large number of\nagent-environment interactions. To improve sample efficiency, methods like\nReinforcement Learning from Expert Demonstrations (RLED) introduce external\nexpert demonstrations to facilitate agent exploration during the learning\nprocess. In practice, these demonstrations, which are often collected from\nhuman users, are costly and hence often constrained to a limited amount. How to\nselect the best set of human demonstrations that is most beneficial for\nlearning therefore becomes a major concern. This paper presents EARLY (Episodic\nActive Learning from demonstration querY), an algorithm that enables a learning\nagent to generate optimized queries of expert demonstrations in a\ntrajectory-based feature space. Based on a trajectory-level estimate of\nuncertainty in the agent's current policy, EARLY determines the optimized\ntiming and content for feature-based queries. By querying episodic\ndemonstrations as opposed to isolated state-action pairs, EARLY improves the\nhuman teaching experience and achieves better learning performance. We validate\nthe effectiveness of our method in three simulated navigation tasks of\nincreasing difficulty. The results show that our method is able to achieve\nexpert-level performance for all three tasks with convergence over 30\\% faster\nthan other baseline methods when demonstrations are generated by simulated\noracle policies. The results of a follow-up pilot user study (N=18) further\nvalidate that our method can still maintain a significantly better convergence\nin the case of human expert demonstrators while achieving a better user\nexperience in perceived task load and consuming significantly less human time.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03069v3",
    "published_date": "2024-06-05 08:52:21 UTC",
    "updated_date": "2024-10-02 20:03:52 UTC"
  },
  {
    "arxiv_id": "2406.03068v2",
    "title": "Distributional Associations vs In-Context Reasoning: A Study of Feed-forward and Attention Layers",
    "authors": [
      "Lei Chen",
      "Joan Bruna",
      "Alberto Bietti"
    ],
    "abstract": "Large language models have been successful at tasks involving basic forms of\nin-context reasoning, such as generating coherent language, as well as storing\nvast amounts of knowledge. At the core of the Transformer architecture behind\nsuch models are feed-forward and attention layers, which are often associated\nto knowledge and reasoning, respectively. In this paper, we study this\ndistinction empirically and theoretically in a controlled synthetic setting\nwhere certain next-token predictions involve both distributional and in-context\ninformation. We find that feed-forward layers tend to learn simple\ndistributional associations such as bigrams, while attention layers focus on\nin-context reasoning. Our theoretical analysis identifies the noise in the\ngradients as a key factor behind this discrepancy. Finally, we illustrate how\nsimilar disparities emerge in pre-trained models through ablations on the\nPythia model family on simple reasoning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.03068v2",
    "published_date": "2024-06-05 08:51:08 UTC",
    "updated_date": "2025-03-06 23:55:51 UTC"
  },
  {
    "arxiv_id": "2406.06587v1",
    "title": "Exploring Human-AI Perception Alignment in Sensory Experiences: Do LLMs Understand Textile Hand?",
    "authors": [
      "Shu Zhong",
      "Elia Gatti",
      "Youngjun Cho",
      "Marianna Obrist"
    ],
    "abstract": "Aligning large language models (LLMs) behaviour with human intent is critical\nfor future AI. An important yet often overlooked aspect of this alignment is\nthe perceptual alignment. Perceptual modalities like touch are more\nmultifaceted and nuanced compared to other sensory modalities such as vision.\nThis work investigates how well LLMs align with human touch experiences using\nthe \"textile hand\" task. We created a \"Guess What Textile\" interaction in which\nparticipants were given two textile samples -- a target and a reference -- to\nhandle. Without seeing them, participants described the differences between\nthem to the LLM. Using these descriptions, the LLM attempted to identify the\ntarget textile by assessing similarity within its high-dimensional embedding\nspace. Our results suggest that a degree of perceptual alignment exists,\nhowever varies significantly among different textile samples. For example, LLM\npredictions are well aligned for silk satin, but not for cotton denim.\nMoreover, participants didn't perceive their textile experiences closely\nmatched by the LLM predictions. This is only the first exploration into\nperceptual alignment around touch, exemplified through textile hand. We discuss\npossible sources of this alignment variance, and how better human-AI perceptual\nalignment can benefit future everyday tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06587v1",
    "published_date": "2024-06-05 08:46:07 UTC",
    "updated_date": "2024-06-05 08:46:07 UTC"
  },
  {
    "arxiv_id": "2406.03049v1",
    "title": "StreamSpeech: Simultaneous Speech-to-Speech Translation with Multi-task Learning",
    "authors": [
      "Shaolei Zhang",
      "Qingkai Fang",
      "Shoutao Guo",
      "Zhengrui Ma",
      "Min Zhang",
      "Yang Feng"
    ],
    "abstract": "Simultaneous speech-to-speech translation (Simul-S2ST, a.k.a streaming speech\ntranslation) outputs target speech while receiving streaming speech inputs,\nwhich is critical for real-time communication. Beyond accomplishing translation\nbetween speech, Simul-S2ST requires a policy to control the model to generate\ncorresponding target speech at the opportune moment within speech inputs,\nthereby posing a double challenge of translation and policy. In this paper, we\npropose StreamSpeech, a direct Simul-S2ST model that jointly learns translation\nand simultaneous policy in a unified framework of multi-task learning. Adhering\nto a multi-task learning approach, StreamSpeech can perform offline and\nsimultaneous speech recognition, speech translation and speech synthesis via an\n\"All-in-One\" seamless model. Experiments on CVSS benchmark demonstrate that\nStreamSpeech achieves state-of-the-art performance in both offline S2ST and\nSimul-S2ST tasks. Besides, StreamSpeech is able to present high-quality\nintermediate results (i.e., ASR or translation results) during simultaneous\ntranslation process, offering a more comprehensive real-time communication\nexperience.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 main conference, Project Page:\n  https://ictnlp.github.io/StreamSpeech-site/",
    "pdf_url": "http://arxiv.org/pdf/2406.03049v1",
    "published_date": "2024-06-05 08:24:22 UTC",
    "updated_date": "2024-06-05 08:24:22 UTC"
  },
  {
    "arxiv_id": "2406.06586v1",
    "title": "Bi-Chainer: Automated Large Language Models Reasoning with Bidirectional Chaining",
    "authors": [
      "Shuqi Liu",
      "Bowei He",
      "Linqi Song"
    ],
    "abstract": "Large Language Models (LLMs) have shown human-like reasoning abilities but\nstill face challenges in solving complex logical problems. Existing\nunidirectional chaining methods, such as forward chaining and backward\nchaining, suffer from issues like low prediction accuracy and efficiency. To\naddress these, we propose a bidirectional chaining method, Bi-Chainer, which\ndynamically switches to depth-first reasoning in the opposite reasoning\ndirection when it encounters multiple branching options within the current\ndirection. Thus, the intermediate reasoning results can be utilized as guidance\nto facilitate the reasoning process. We show that Bi-Chainer achieves sizable\naccuracy boots over unidirectional chaining frameworks on four challenging\nlogical reasoning datasets. Moreover, Bi-Chainer enhances the accuracy of\nintermediate proof steps and reduces the average number of inference calls,\nresulting in more efficient and accurate reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.06586v1",
    "published_date": "2024-06-05 08:15:38 UTC",
    "updated_date": "2024-06-05 08:15:38 UTC"
  },
  {
    "arxiv_id": "2406.03508v2",
    "title": "Mutual Information Guided Backdoor Mitigation for Pre-trained Encoders",
    "authors": [
      "Tingxu Han",
      "Weisong Sun",
      "Ziqi Ding",
      "Chunrong Fang",
      "Hanwei Qian",
      "Jiaxun Li",
      "Zhenyu Chen",
      "Xiangyu Zhang"
    ],
    "abstract": "Self-supervised learning (SSL) is increasingly attractive for pre-training\nencoders without requiring labeled data. Downstream tasks built on top of those\npre-trained encoders can achieve nearly state-of-the-art performance. The\npre-trained encoders by SSL, however, are vulnerable to backdoor attacks as\ndemonstrated by existing studies. Numerous backdoor mitigation techniques are\ndesigned for downstream task models. However, their effectiveness is impaired\nand limited when adapted to pre-trained encoders, due to the lack of label\ninformation when pre-training. To address backdoor attacks against pre-trained\nencoders, in this paper, we innovatively propose a mutual information guided\nbackdoor mitigation technique, named MIMIC. MIMIC treats the potentially\nbackdoored encoder as the teacher net and employs knowledge distillation to\ndistill a clean student encoder from the teacher net. Different from existing\nknowledge distillation approaches, MIMIC initializes the student with random\nweights, inheriting no backdoors from teacher nets. Then MIMIC leverages mutual\ninformation between each layer and extracted features to locate where benign\nknowledge lies in the teacher net, with which distillation is deployed to clone\nclean features from teacher to student. We craft the distillation loss with two\naspects, including clone loss and attention loss, aiming to mitigate backdoors\nand maintain encoder performance at the same time. Our evaluation conducted on\ntwo backdoor attacks in SSL demonstrates that MIMIC can significantly reduce\nthe attack success rate by only utilizing <5% of clean data, surpassing seven\nstate-of-the-art backdoor mitigation techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03508v2",
    "published_date": "2024-06-05 07:27:15 UTC",
    "updated_date": "2024-06-11 06:11:36 UTC"
  },
  {
    "arxiv_id": "2406.03012v2",
    "title": "Towards Understanding the Influence of Training Samples on Explanations",
    "authors": [
      "AndrÃ© Artelt",
      "Barbara Hammer"
    ],
    "abstract": "Explainable AI (XAI) is widely used to analyze AI systems' decision-making,\nsuch as providing counterfactual explanations for recourse. When unexpected\nexplanations occur, users may want to understand the training data properties\nshaping them. Under the umbrella of data valuation, first approaches have been\nproposed that estimate the influence of data samples on a given model. This\nprocess not only helps determine the data's value, but also offers insights\ninto how individual, potentially noisy, or misleading examples affect a model,\nwhich is crucial for interpretable AI. In this work, we apply the concept of\ndata valuation to the significant area of model evaluations, focusing on how\nindividual training samples impact a model's internal reasoning rather than the\npredictive performance only. Hence, we introduce the novel problem of\nidentifying training samples shaping a given explanation or related quantity,\nand investigate the particular case of the cost of computational recourse. We\npropose an algorithm to identify such influential samples and conduct extensive\nempirical evaluations in two case studies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Extended version of the paper accepted at the \"Workshop on\n  Explainable Artificial Intelligence (XAI)\" at IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.03012v2",
    "published_date": "2024-06-05 07:20:06 UTC",
    "updated_date": "2025-03-25 12:17:25 UTC"
  },
  {
    "arxiv_id": "2406.03009v1",
    "title": "Unveiling Selection Biases: Exploring Order and Token Sensitivity in Large Language Models",
    "authors": [
      "Sheng-Lun Wei",
      "Cheng-Kuang Wu",
      "Hen-Hsen Huang",
      "Hsin-Hsi Chen"
    ],
    "abstract": "In this paper, we investigate the phenomena of \"selection biases\" in Large\nLanguage Models (LLMs), focusing on problems where models are tasked with\nchoosing the optimal option from an ordered sequence. We delve into biases\nrelated to option order and token usage, which significantly impact LLMs'\ndecision-making processes. We also quantify the impact of these biases through\nan extensive empirical analysis across multiple models and tasks. Furthermore,\nwe propose mitigation strategies to enhance model performance. Our key\ncontributions are threefold: 1) Precisely quantifying the influence of option\norder and token on LLMs, 2) Developing strategies to mitigate the impact of\ntoken and order sensitivity to enhance robustness, and 3) Offering a detailed\nanalysis of sensitivity across models and tasks, which informs the creation of\nmore stable and reliable LLM applications for selection problems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted as a long findings paper at ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.03009v1",
    "published_date": "2024-06-05 07:16:51 UTC",
    "updated_date": "2024-06-05 07:16:51 UTC"
  },
  {
    "arxiv_id": "2406.03008v2",
    "title": "DriVLMe: Enhancing LLM-based Autonomous Driving Agents with Embodied and Social Experiences",
    "authors": [
      "Yidong Huang",
      "Jacob Sansom",
      "Ziqiao Ma",
      "Felix Gervits",
      "Joyce Chai"
    ],
    "abstract": "Recent advancements in foundation models (FMs) have unlocked new prospects in\nautonomous driving, yet the experimental settings of these studies are\npreliminary, over-simplified, and fail to capture the complexity of real-world\ndriving scenarios in human environments. It remains under-explored whether FM\nagents can handle long-horizon navigation tasks with free-from dialogue and\ndeal with unexpected situations caused by environmental dynamics or task\nchanges. To explore the capabilities and boundaries of FMs faced with the\nchallenges above, we introduce DriVLMe, a video-language-model-based agent to\nfacilitate natural and effective communication between humans and autonomous\nvehicles that perceive the environment and navigate. We develop DriVLMe from\nboth embodied experiences in a simulated environment and social experiences\nfrom real human dialogue. While DriVLMe demonstrates competitive performance in\nboth open-loop benchmarks and closed-loop human studies, we reveal several\nlimitations and challenges, including unacceptable inference time, imbalanced\ntraining data, limited visual understanding, challenges with multi-turn\ninteractions, simplified language generation from robotic experiences, and\ndifficulties in handling on-the-fly unexpected situations like environmental\ndynamics and task changes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "2024 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS)",
    "pdf_url": "http://arxiv.org/pdf/2406.03008v2",
    "published_date": "2024-06-05 07:14:44 UTC",
    "updated_date": "2024-10-15 04:50:40 UTC"
  },
  {
    "arxiv_id": "2406.03007v1",
    "title": "BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents",
    "authors": [
      "Yifei Wang",
      "Dizhan Xue",
      "Shengjie Zhang",
      "Shengsheng Qian"
    ],
    "abstract": "With the prosperity of large language models (LLMs), powerful LLM-based\nintelligent agents have been developed to provide customized services with a\nset of user-defined tools. State-of-the-art methods for constructing LLM agents\nadopt trained LLMs and further fine-tune them on data for the agent task.\nHowever, we show that such methods are vulnerable to our proposed backdoor\nattacks named BadAgent on various agent tasks, where a backdoor can be embedded\nby fine-tuning on the backdoor data. At test time, the attacker can manipulate\nthe deployed LLM agents to execute harmful operations by showing the trigger in\nthe agent input or environment. To our surprise, our proposed attack methods\nare extremely robust even after fine-tuning on trustworthy data. Though\nbackdoor attacks have been studied extensively in natural language processing,\nto the best of our knowledge, we could be the first to study them on LLM agents\nthat are more dangerous due to the permission to use external tools. Our work\ndemonstrates the clear risk of constructing LLM agents based on untrusted LLMs\nor data. Our code is public at https://github.com/DPamK/BadAgent",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.03007v1",
    "published_date": "2024-06-05 07:14:28 UTC",
    "updated_date": "2024-06-05 07:14:28 UTC"
  },
  {
    "arxiv_id": "2406.03004v1",
    "title": "Evaluation of data inconsistency for multi-modal sentiment analysis",
    "authors": [
      "Yufei Wang",
      "Mengyue Wu"
    ],
    "abstract": "Emotion semantic inconsistency is an ubiquitous challenge in multi-modal\nsentiment analysis (MSA). MSA involves analyzing sentiment expressed across\nvarious modalities like text, audio, and videos. Each modality may convey\ndistinct aspects of sentiment, due to subtle and nuanced expression of human\nbeings, leading to inconsistency, which may hinder the prediction of artificial\nagents. In this work, we introduce a modality conflicting test set and assess\nthe performance of both traditional multi-modal sentiment analysis models and\nmulti-modal large language models (MLLMs). Our findings reveal significant\nperformance degradation across traditional models when confronted with\nsemantically conflicting data and point out the drawbacks of MLLMs when\nhandling multi-modal emotion analysis. Our research presents a new challenge\nand offer valuable insights for the future development of sentiment analysis\nsystems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03004v1",
    "published_date": "2024-06-05 07:11:56 UTC",
    "updated_date": "2024-06-05 07:11:56 UTC"
  },
  {
    "arxiv_id": "2406.03001v1",
    "title": "EdgeSync: Faster Edge-model Updating via Adaptive Continuous Learning for Video Data Drift",
    "authors": [
      "Peng Zhao",
      "Runchu Dong",
      "Guiqin Wang",
      "Cong Zhao"
    ],
    "abstract": "Real-time video analytics systems typically place models with fewer weights\non edge devices to reduce latency. The distribution of video content features\nmay change over time for various reasons (i.e. light and weather change) ,\nleading to accuracy degradation of existing models, to solve this problem,\nrecent work proposes a framework that uses a remote server to continually train\nand adapt the lightweight model at edge with the help of complex model.\nHowever, existing analytics approaches leave two challenges untouched: firstly,\nretraining task is compute-intensive, resulting in large model update delays;\nsecondly, new model may not fit well enough with the data distribution of the\ncurrent video stream. To address these challenges, in this paper, we present\nEdgeSync, EdgeSync filters the samples by considering both timeliness and\ninference results to make training samples more relevant to the current video\ncontent as well as reduce the update delay, to improve the quality of training,\nEdgeSync also designs a training management module that can efficiently adjusts\nthe model training time and training order on the runtime. By evaluating real\ndatasets with complex scenes, our method improves about 3.4% compared to\nexisting methods and about 10% compared to traditional means.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03001v1",
    "published_date": "2024-06-05 07:06:26 UTC",
    "updated_date": "2024-06-05 07:06:26 UTC"
  },
  {
    "arxiv_id": "2406.03000v2",
    "title": "Simplification of Risk Averse POMDPs with Performance Guarantees",
    "authors": [
      "Yaacov Pariente",
      "Vadim Indelman"
    ],
    "abstract": "Risk averse decision making under uncertainty in partially observable domains\nis a fundamental problem in AI and essential for reliable autonomous agents. In\nour case, the problem is modeled using partially observable Markov decision\nprocesses (POMDPs), when the value function is the conditional value at risk\n(CVaR) of the return. Calculating an optimal solution for POMDPs is\ncomputationally intractable in general. In this work we develop a\nsimplification framework to speedup the evaluation of the value function, while\nproviding performance guarantees. We consider as simplification a\ncomputationally cheaper belief-MDP transition model, that can correspond, e.g.,\nto cheaper observation or transition models. Our contributions include general\nbounds for CVaR that allow bounding the CVaR of a random variable X, using a\nrandom variable Y, by assuming bounds between their cumulative distributions.\nWe then derive bounds for the CVaR value function in a POMDP setting, and show\nhow to bound the value function using the computationally cheaper belief-MDP\ntransition model and without accessing the computationally expensive model in\nreal-time. Then, we provide theoretical performance guarantees for the\nestimated bounds. Our results apply for a general simplification of a\nbelief-MDP transition model and support simplification of both the observation\nand state transition models simultaneously.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03000v2",
    "published_date": "2024-06-05 07:05:52 UTC",
    "updated_date": "2024-06-08 07:37:12 UTC"
  },
  {
    "arxiv_id": "2406.02989v2",
    "title": "Learning Semantic Traversability with Egocentric Video and Automated Annotation Strategy",
    "authors": [
      "Yunho Kim",
      "Jeong Hyun Lee",
      "Choongin Lee",
      "Juhyeok Mun",
      "Donghoon Youm",
      "Jeongsoo Park",
      "Jemin Hwangbo"
    ],
    "abstract": "For reliable autonomous robot navigation in urban settings, the robot must\nhave the ability to identify semantically traversable terrains in the image\nbased on the semantic understanding of the scene. This reasoning ability is\nbased on semantic traversability, which is frequently achieved using semantic\nsegmentation models fine-tuned on the testing domain. This fine-tuning process\noften involves manual data collection with the target robot and annotation by\nhuman labelers which is prohibitively expensive and unscalable. In this work,\nwe present an effective methodology for training a semantic traversability\nestimator using egocentric videos and an automated annotation process.\nEgocentric videos are collected from a camera mounted on a pedestrian's chest.\nThe dataset for training the semantic traversability estimator is then\nautomatically generated by extracting semantically traversable regions in each\nvideo frame using a recent foundation model in image segmentation and its\nprompting technique. Extensive experiments with videos taken across several\ncountries and cities, covering diverse urban scenarios, demonstrate the high\nscalability and generalizability of the proposed annotation method.\nFurthermore, performance analysis and real-world deployment for autonomous\nrobot navigation showcase that the trained semantic traversability estimator is\nhighly accurate, able to handle diverse camera viewpoints, computationally\nlight, and real-world applicable. The summary video is available at\nhttps://youtu.be/EUVoH-wA-lA.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to IEEE Robotics and Automation Letters (RA-L) 2024, First\n  two authors contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2406.02989v2",
    "published_date": "2024-06-05 06:40:04 UTC",
    "updated_date": "2024-09-28 16:31:58 UTC"
  },
  {
    "arxiv_id": "2406.03507v1",
    "title": "Robust Prediction Model for Multidimensional and Unbalanced Datasets",
    "authors": [
      "Pooja Thakar",
      "Anil Mehta",
      "Manisha"
    ],
    "abstract": "Data Mining is a promising field and is applied in multiple domains for its\npredictive capabilities. Data in the real world cannot be readily used for data\nmining as it suffers from the problems of multidimensionality, unbalance and\nmissing values. It is difficult to use its predictive capabilities by novice\nusers. It is difficult for a beginner to find the relevant set of attributes\nfrom a large pool of data available. The paper presents a Robust Prediction\nModel that finds a relevant set of attributes; resolves the problems of\nunbalanced and multidimensional real-life datasets and helps in finding\npatterns for informed decision making. Model is tested upon five different\ndatasets in the domain of Health Sector, Education, Business and Fraud\nDetection. The results showcase the robust behaviour of the model and its\napplicability in various domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.03507v1",
    "published_date": "2024-06-05 06:28:39 UTC",
    "updated_date": "2024-06-05 06:28:39 UTC"
  },
  {
    "arxiv_id": "2406.02983v3",
    "title": "FREA: Feasibility-Guided Generation of Safety-Critical Scenarios with Reasonable Adversariality",
    "authors": [
      "Keyu Chen",
      "Yuheng Lei",
      "Hao Cheng",
      "Haoran Wu",
      "Wenchao Sun",
      "Sifa Zheng"
    ],
    "abstract": "Generating safety-critical scenarios, which are essential yet difficult to\ncollect at scale, offers an effective method to evaluate the robustness of\nautonomous vehicles (AVs). Existing methods focus on optimizing adversariality\nwhile preserving the naturalness of scenarios, aiming to achieve a balance\nthrough data-driven approaches. However, without an appropriate upper bound for\nadversariality, the scenarios might exhibit excessive adversariality,\npotentially leading to unavoidable collisions. In this paper, we introduce\nFREA, a novel safety-critical scenarios generation method that incorporates the\nLargest Feasible Region (LFR) of AV as guidance to ensure the reasonableness of\nthe adversarial scenarios. Concretely, FREA initially pre-calculates the LFR of\nAV from offline datasets. Subsequently, it learns a reasonable adversarial\npolicy that controls the scene's critical background vehicles (CBVs) to\ngenerate adversarial yet AV-feasible scenarios by maximizing a novel\nfeasibility-dependent adversarial objective function. Extensive experiments\nillustrate that FREA can effectively generate safety-critical scenarios,\nyielding considerable near-miss events while ensuring AV's feasibility.\nGeneralization analysis also confirms the robustness of FREA in AV testing\nacross various surrogate AV methods and traffic environments.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by CoRL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02983v3",
    "published_date": "2024-06-05 06:26:15 UTC",
    "updated_date": "2024-10-11 05:32:17 UTC"
  },
  {
    "arxiv_id": "2407.17591v1",
    "title": "Unified Prediction Model for Employability in Indian Higher Education System",
    "authors": [
      "Pooja Thakar",
      "Anil Mehta",
      "Manisha"
    ],
    "abstract": "Educational Data Mining has become extremely popular among researchers in\nlast decade. Prior effort in this area was only directed towards prediction of\nacademic performance of a student. Very less number of researches are directed\ntowards predicting employability of a student i.e. prediction of students\nperformance in campus placements at an early stage of enrollment. Furthermore,\nexisting researches on students employability prediction are not universal in\napproach and is either based upon only one type of course or\nUniversity/Institute. Henceforth, is not scalable from one context to another.\nWith the necessity of unification, data of professional technical courses\nnamely Bachelor in Engineering/Technology and Masters in Computer Applications\nstudents have been collected from 17 states of India. To deal with such a data,\na unified predictive model has been developed and applied on 17 states\ndatasets. The research done in this paper proves that model has universal\napplication and can be applied to various states and institutes pan India with\ndifferent cultural background and course structure. This paper also explores\nand proves statistically that there is no significant difference in Indian\nEducation System with respect to states as far as prediction of employability\nof students is concerned. Model provides a generalized solution for student\nemployability prediction in Indian Scenario.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.17591v1",
    "published_date": "2024-06-05 06:23:15 UTC",
    "updated_date": "2024-06-05 06:23:15 UTC"
  },
  {
    "arxiv_id": "2406.02980v1",
    "title": "Tensor Polynomial Additive Model",
    "authors": [
      "Yang Chen",
      "Ce Zhu",
      "Jiani Liu",
      "Yipeng Liu"
    ],
    "abstract": "Additive models can be used for interpretable machine learning for their\nclarity and simplicity. However, In the classical models for high-order data,\nthe vectorization operation disrupts the data structure, which may lead to\ndegenerated accuracy and increased computational complexity. To deal with these\nproblems, we propose the tensor polynomial addition model (TPAM). It retains\nthe multidimensional structure information of high-order inputs with tensor\nrepresentation. The model parameter compression is achieved using a\nhierarchical and low-order symmetric tensor approximation. In this way, complex\nhigh-order feature interactions can be captured with fewer parameters.\nMoreover, The TPAM preserves the inherent interpretability of additive models,\nfacilitating transparent decision-making and the extraction of meaningful\nfeature values. Additionally, leveraging TPAM's transparency and ability to\nhandle higher-order features, it is used as a post-processing module for other\ninterpretation models by introducing two variants for class activation maps.\nExperimental results on a series of datasets demonstrate that TPAM can enhance\naccuracy by up to 30\\%, and compression rate by up to 5 times, while\nmaintaining a good interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02980v1",
    "published_date": "2024-06-05 06:23:11 UTC",
    "updated_date": "2024-06-05 06:23:11 UTC"
  },
  {
    "arxiv_id": "2406.02979v1",
    "title": "Efficient User Sequence Learning for Online Services via Compressed Graph Neural Networks",
    "authors": [
      "Yucheng Wu",
      "Liyue Chen",
      "Yu Cheng",
      "Shuai Chen",
      "Jinyu Xu",
      "Leye Wang"
    ],
    "abstract": "Learning representations of user behavior sequences is crucial for various\nonline services, such as online fraudulent transaction detection mechanisms.\nGraph Neural Networks (GNNs) have been extensively applied to model sequence\nrelationships, and extract information from similar sequences. While user\nbehavior sequence data volume is usually huge for online applications, directly\napplying GNN models may lead to substantial computational overhead during both\nthe training and inference stages and make it challenging to meet real-time\nrequirements for online services. In this paper, we leverage graph compression\ntechniques to alleviate the efficiency issue. Specifically, we propose a novel\nunified framework called ECSeq, to introduce graph compression techniques into\nrelation modeling for user sequence representation learning. The key module of\nECSeq is sequence relation modeling, which explores relationships among\nsequences to enhance sequence representation learning, and employs graph\ncompression algorithms to achieve high efficiency and scalability. ECSeq also\nexhibits plug-and-play characteristics, seamlessly augmenting pre-trained\nsequence representation models without modifications. Empirical experiments on\nboth sequence classification and regression tasks demonstrate the effectiveness\nof ECSeq. Specifically, with an additional training time of tens of seconds in\ntotal on 100,000+ sequences and inference time preserved within $10^{-4}$\nseconds/sample, ECSeq improves the prediction R@P$_{0.9}$ of the widely used\nLSTM by $\\sim 5\\%$.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IEEE ICWS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02979v1",
    "published_date": "2024-06-05 06:22:11 UTC",
    "updated_date": "2024-06-05 06:22:11 UTC"
  },
  {
    "arxiv_id": "2406.02976v1",
    "title": "DA-Flow: Dual Attention Normalizing Flow for Skeleton-based Video Anomaly Detection",
    "authors": [
      "Ruituo Wu",
      "Yang Chen",
      "Jian Xiao",
      "Bing Li",
      "Jicong Fan",
      "FrÃ©dÃ©ric Dufaux",
      "Ce Zhu",
      "Yipeng Liu"
    ],
    "abstract": "Cooperation between temporal convolutional networks (TCN) and graph\nconvolutional networks (GCN) as a processing module has shown promising results\nin skeleton-based video anomaly detection (SVAD). However, to maintain a\nlightweight model with low computational and storage complexity, shallow GCN\nand TCN blocks are constrained by small receptive fields and a lack of\ncross-dimension interaction capture. To tackle this limitation, we propose a\nlightweight module called the Dual Attention Module (DAM) for capturing\ncross-dimension interaction relationships in spatio-temporal skeletal data. It\nemploys the frame attention mechanism to identify the most significant frames\nand the skeleton attention mechanism to capture broader relationships across\nfixed partitions with minimal parameters and flops. Furthermore, the proposed\nDual Attention Normalizing Flow (DA-Flow) integrates the DAM as a\npost-processing unit after GCN within the normalizing flow framework.\nSimulations show that the proposed model is robust against noise and negative\nsamples. Experimental results show that DA-Flow reaches competitive or better\nperformance than the existing state-of-the-art (SOTA) methods in terms of the\nmicro AUC metric with the fewest number of parameters. Moreover, we found that\neven without training, simply using random projection without dimensionality\nreduction on skeleton data enables substantial anomaly detection capabilities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02976v1",
    "published_date": "2024-06-05 06:18:03 UTC",
    "updated_date": "2024-06-05 06:18:03 UTC"
  },
  {
    "arxiv_id": "2407.16884v1",
    "title": "Cluster Model for parsimonious selection of variables and enhancing Students Employability Prediction",
    "authors": [
      "Pooja Thakar",
      "Anil Mehta",
      "Manisha"
    ],
    "abstract": "Educational Data Mining (EDM) is a promising field, where data mining is\nwidely used for predicting students performance. One of the most prevalent and\nrecent challenge that higher education faces today is making students\nskillfully employable. Institutions possess large volume of data; still they\nare unable to reveal knowledge and guide their students. Data in education is\ngenerally very large, multidimensional and unbalanced in nature. Process of\nextracting knowledge from such data has its own set of problems and is a very\ncomplicated task. In this paper, Engineering and MCA (Masters in Computer\nApplications) students data is collected from various universities and\ninstitutes pan India. The dataset is large, unbalanced and multidimensional in\nnature. A cluster based model is presented in this paper, which, when applied\nat preprocessing stage helps in parsimonious selection of variables and\nimproves the performance of predictive algorithms. Hence, facilitate in better\nprediction of Students Employability.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.16884v1",
    "published_date": "2024-06-05 06:06:46 UTC",
    "updated_date": "2024-06-05 06:06:46 UTC"
  },
  {
    "arxiv_id": "2406.02969v2",
    "title": "Filtered not Mixed: Stochastic Filtering-Based Online Gating for Mixture of Large Language Models",
    "authors": [
      "Raeid Saqur",
      "Anastasis Kratsios",
      "Florian Krach",
      "Yannick Limmer",
      "Jacob-Junqi Tian",
      "John Willes",
      "Blanka Horvath",
      "Frank Rudzicz"
    ],
    "abstract": "We propose MoE-F - a formalized mechanism for combining $N$ pre-trained Large\nLanguage Models (LLMs) for online time-series prediction by adaptively\nforecasting the best weighting of LLM predictions at every time step. Our\nmechanism leverages the conditional information in each expert's running\nperformance to forecast the best combination of LLMs for predicting the time\nseries in its next step. Diverging from static (learned) Mixture of Experts\n(MoE) methods, our approach employs time-adaptive stochastic filtering\ntechniques to combine experts. By framing the expert selection problem as a\nfinite state-space, continuous-time Hidden Markov model (HMM), we can leverage\nthe Wohman-Shiryaev filter. Our approach first constructs N parallel filters\ncorresponding to each of the $N$ individual LLMs. Each filter proposes its best\ncombination of LLMs, given the information that they have access to.\nSubsequently, the N filter outputs are optimally aggregated to maximize their\nrobust predictive power, and this update is computed efficiently via a\nclosed-form expression, generating our ensemble predictor. Our contributions\nare: **(I)** the MoE-F plug-and-play filtering harness algorithm, **(II)**\ntheoretical optimality guarantees of the proposed filtering-based gating\nalgorithm (via optimality guarantees for its parallel Bayesian filtering and\nits robust aggregation steps), and **(III)** empirical evaluation and ablative\nresults using state-of-the-art foundational and MoE LLMs on a real-world\n__Financial Market Movement__ task where MoE-F attains a remarkable 17\\%\nabsolute and 48.5\\% relative F1 measure improvement over the next best\nperforming individual LLM expert predicting short-horizon market movement based\non streaming news. Further, we provide empirical evidence of substantial\nperformance gains in applying MoE-F over specialized models in the long-horizon\ntime-series forecasting domain.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "q-fin.CP",
      "q-fin.MF",
      "60J05, 60G35, 68T20, 68T42, 68T50",
      "I.2.6; I.2.7; G.3"
    ],
    "primary_category": "cs.LG",
    "comment": "33 pages, 5 Appendix sections",
    "pdf_url": "http://arxiv.org/pdf/2406.02969v2",
    "published_date": "2024-06-05 05:53:50 UTC",
    "updated_date": "2025-02-20 19:56:47 UTC"
  },
  {
    "arxiv_id": "2406.02966v3",
    "title": "Generative AI and Digital Neocolonialism in Global Education: Towards an Equitable Framework",
    "authors": [
      "Matthew Nyaaba",
      "Alyson Wright",
      "Gyu Lim Choi"
    ],
    "abstract": "This paper critically discusses how generative artificial intelligence\n(GenAI) might impose Western ideologies on non-Western societies, perpetuating\ndigital neocolonialism in education through its inherent biases. It further\nsuggests strategies for local and global stakeholders to mitigate these\neffects. Our discussions demonstrated that GenAI can foster cultural\nimperialism by generating content that primarily incorporates cultural\nreferences and examples relevant to Western students, thereby alienating\nstudents from non-Western backgrounds. Also, the predominant use of Western\nlanguages by GenAI can marginalize non-dominant languages, making educational\ncontent less accessible to speakers of indigenous languages and potentially\nimpacting their ability to learn in their first language. Additionally, GenAI\noften generates content and curricula that reflect the perspectives of\ntechnologically dominant countries, overshadowing marginalized indigenous\nknowledge and practices. Moreover, the cost of access to GenAI intensifies\neducational inequality and the control of GenAI data could lead to commercial\nexploitation without benefiting local students and their communities. We\npropose human-centric reforms to prioritize cultural diversity and equity in\nGenAI development; a liberatory design to empower educators and students to\nidentify and dismantle the oppressive structures within GenAI applications;\nforesight by design to create an adjustable GenAI system to meet future\neducational needs; and finally, effective prompting skills to reduce the\nretrieval of neocolonial outputs.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02966v3",
    "published_date": "2024-06-05 05:43:55 UTC",
    "updated_date": "2024-06-16 02:57:15 UTC"
  },
  {
    "arxiv_id": "2406.02962v1",
    "title": "Docs2KG: Unified Knowledge Graph Construction from Heterogeneous Documents Assisted by Large Language Models",
    "authors": [
      "Qiang Sun",
      "Yuanyi Luo",
      "Wenxiao Zhang",
      "Sirui Li",
      "Jichunyang Li",
      "Kai Niu",
      "Xiangrui Kong",
      "Wei Liu"
    ],
    "abstract": "Even for a conservative estimate, 80% of enterprise data reside in\nunstructured files, stored in data lakes that accommodate heterogeneous\nformats. Classical search engines can no longer meet information seeking needs,\nespecially when the task is to browse and explore for insight formulation. In\nother words, there are no obvious search keywords to use. Knowledge graphs, due\nto their natural visual appeals that reduce the human cognitive load, become\nthe winning candidate for heterogeneous data integration and knowledge\nrepresentation.\n  In this paper, we introduce Docs2KG, a novel framework designed to extract\nmultimodal information from diverse and heterogeneous unstructured documents,\nincluding emails, web pages, PDF files, and Excel files. Dynamically generates\na unified knowledge graph that represents the extracted key information,\nDocs2KG enables efficient querying and exploration of document data lakes.\nUnlike existing approaches that focus on domain-specific data sources or\npre-designed schemas, Docs2KG offers a flexible and extensible solution that\ncan adapt to various document structures and content types. The proposed\nframework unifies data processing supporting a multitude of downstream tasks\nwith improved domain interpretability. Docs2KG is publicly accessible at\nhttps://docs2kg.ai4wa.com, and a demonstration video is available at\nhttps://docs2kg.ai4wa.com/Video.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02962v1",
    "published_date": "2024-06-05 05:35:59 UTC",
    "updated_date": "2024-06-05 05:35:59 UTC"
  },
  {
    "arxiv_id": "2406.02958v3",
    "title": "PrE-Text: Training Language Models on Private Federated Data in the Age of LLMs",
    "authors": [
      "Charlie Hou",
      "Akshat Shrivastava",
      "Hongyuan Zhan",
      "Rylan Conway",
      "Trang Le",
      "Adithya Sagar",
      "Giulia Fanti",
      "Daniel Lazar"
    ],
    "abstract": "On-device training is currently the most common approach for training machine\nlearning (ML) models on private, distributed user data. Despite this, on-device\ntraining has several drawbacks: (1) most user devices are too small to train\nlarge models on-device, (2) on-device training is communication- and\ncomputation-intensive, and (3) on-device training can be difficult to debug and\ndeploy. To address these problems, we propose Private Evolution-Text\n(PrE-Text), a method for generating differentially private (DP) synthetic\ntextual data. First, we show that across multiple datasets, training small\nmodels (models that fit on user devices) with PrE-Text synthetic data\noutperforms small models trained on-device under practical privacy regimes\n($\\epsilon=1.29$, $\\epsilon=7.58$). We achieve these results while using\n9$\\times$ fewer rounds, 6$\\times$ less client computation per round, and\n100$\\times$ less communication per round. Second, finetuning large models on\nPrE-Text's DP synthetic data improves large language model (LLM) performance on\nprivate data across the same range of privacy budgets. Altogether, these\nresults suggest that training on DP synthetic data can be a better option than\ntraining a model on-device on private distributed data. Code is available at\nhttps://github.com/houcharlie/PrE-Text.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024 (Oral). Latest revision corrects a discussion on concurrent\n  work arXiv:2403.01749. We described their work as reliant on using\n  closed-sourced models when in reality they also evaluate and use open source\n  models. This has been corrected in this version",
    "pdf_url": "http://arxiv.org/pdf/2406.02958v3",
    "published_date": "2024-06-05 05:27:02 UTC",
    "updated_date": "2024-10-17 19:11:46 UTC"
  },
  {
    "arxiv_id": "2406.02943v1",
    "title": "The Task-oriented Queries Benchmark (ToQB)",
    "authors": [
      "Keun Soo Yim"
    ],
    "abstract": "Task-oriented queries (e.g., one-shot queries to play videos, order food, or\ncall a taxi) are crucial for assessing the quality of virtual assistants,\nchatbots, and other large language model (LLM)-based services. However, a\nstandard benchmark for task-oriented queries is not yet available, as existing\nbenchmarks in the relevant NLP (Natural Language Processing) fields have\nprimarily focused on task-oriented dialogues. Thus, we present a new\nmethodology for efficiently generating the Task-oriented Queries Benchmark\n(ToQB) using existing task-oriented dialogue datasets and an LLM service. Our\nmethodology involves formulating the underlying NLP task to summarize the\noriginal intent of a speaker in each dialogue, detailing the key steps to\nperform the devised NLP task using an LLM service, and outlining a framework\nfor automating a major part of the benchmark generation process. Through a case\nstudy encompassing three domains (i.e., two single-task domains and one\nmulti-task domain), we demonstrate how to customize the LLM prompts (e.g.,\nomitting system utterances or speaker labels) for those three domains and\ncharacterize the generated task-oriented queries. The generated ToQB dataset is\nmade available to the public. We further discuss new domains that can be added\nto ToQB by community contributors and its practical applications.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.NE"
    ],
    "primary_category": "cs.IR",
    "comment": "Data available on GitHub,\n  https://github.com/google/task-oriented-queries",
    "pdf_url": "http://arxiv.org/pdf/2406.02943v1",
    "published_date": "2024-06-05 05:05:41 UTC",
    "updated_date": "2024-06-05 05:05:41 UTC"
  },
  {
    "arxiv_id": "2406.02927v1",
    "title": "Multivariate Physics-Informed Convolutional Autoencoder for Anomaly Detection in Power Distribution Systems with High Penetration of DERs",
    "authors": [
      "Mehdi Jabbari Zideh",
      "Sarika Khushalani Solanki"
    ],
    "abstract": "Despite the relentless progress of deep learning models in analyzing the\nsystem conditions under cyber-physical events, their abilities are limited in\nthe power system domain due to data availability issues, cost of data\nacquisition, and lack of interpretation and extrapolation for the data beyond\nthe training windows. In addition, the integration of distributed energy\nresources (DERs) such as wind and solar generations increases the complexities\nand nonlinear nature of power systems. Therefore, an interpretable and reliable\nmethodology is of utmost need to increase the confidence of power system\noperators and their situational awareness for making reliable decisions. This\nhas led to the development of physics-informed neural network (PINN) models as\nmore interpretable, trustworthy, and robust models where the underlying\nprincipled laws are integrated into the training process of neural network\nmodels to achieve improved performance. This paper proposes a multivariate\nphysics-informed convolutional autoencoder (PIConvAE) model to detect cyber\nanomalies in power distribution systems with unbalanced configurations and high\npenetration of DERs. The physical laws are integrated through a customized loss\nfunction that embeds the underlying Kirchhoff's circuit laws into the training\nprocess of the autoencoder. The performance of the multivariate PIConvAE model\nis evaluated on two unbalanced power distribution grids, IEEE 123-bus system\nand a real-world feeder in Riverside, CA. The results show the exceptional\nperformance of the proposed method in detecting various cyber anomalies in both\nsystems. In addition, the model's effectiveness is evaluated in data scarcity\nscenarios with different training data ratios. Finally, the model's performance\nis compared with existing machine learning models where the PIConvAE model\nsurpasses other models with considerably higher detection metrics.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02927v1",
    "published_date": "2024-06-05 04:28:57 UTC",
    "updated_date": "2024-06-05 04:28:57 UTC"
  },
  {
    "arxiv_id": "2406.02925v3",
    "title": "Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition",
    "authors": [
      "Hsuan Su",
      "Hua Farn",
      "Fan-Yun Sun",
      "Shang-Tse Chen",
      "Hung-yi Lee"
    ],
    "abstract": "Synthetic data is widely used in speech recognition due to the availability\nof text-to-speech models, which facilitate adapting models to previously unseen\ntext domains. However, existing methods suffer in performance when they\nfine-tune an automatic speech recognition (ASR) model on synthetic data as they\nsuffer from the distributional shift commonly referred to as the\nsynthetic-to-real gap. In this paper, we find that task vector arithmetic is\neffective at mitigating this gap. Our proposed method, SYN2REAL task vector,\nshows an average improvement of 10.03\\% improvement in word error rate over\nbaselines on the SLURP dataset. Additionally, we show that an average of\nSYN2REAL task vectors, when we have real speeches from multiple different\ndomains, can further adapt the original ASR model to perform better on the\ntarget text domain.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02925v3",
    "published_date": "2024-06-05 04:25:56 UTC",
    "updated_date": "2024-10-05 09:06:11 UTC"
  },
  {
    "arxiv_id": "2406.02921v2",
    "title": "Text Injection for Neural Contextual Biasing",
    "authors": [
      "Zhong Meng",
      "Zelin Wu",
      "Rohit Prabhavalkar",
      "Cal Peyser",
      "Weiran Wang",
      "Nanxin Chen",
      "Tara N. Sainath",
      "Bhuvana Ramabhadran"
    ],
    "abstract": "Neural contextual biasing effectively improves automatic speech recognition\n(ASR) for crucial phrases within a speaker's context, particularly those that\nare infrequent in the training data. This work proposes contextual text\ninjection (CTI) to enhance contextual ASR. CTI leverages not only the paired\nspeech-text data, but also a much larger corpus of unpaired text to optimize\nthe ASR model and its biasing component. Unpaired text is converted into\nspeech-like representations and used to guide the model's attention towards\nrelevant bias phrases. Moreover, we introduce a contextual text-injected (CTI)\nminimum word error rate (MWER) training, which minimizes the expected WER\ncaused by contextual biasing when unpaired text is injected into the model.\nExperiments show that CTI with 100 billion text sentences can achieve up to\n43.3% relative WER reduction from a strong neural biasing model. CTI-MWER\nprovides a further relative improvement of 23.5%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2406.02921v2",
    "published_date": "2024-06-05 04:20:17 UTC",
    "updated_date": "2024-06-11 04:11:56 UTC"
  },
  {
    "arxiv_id": "2406.02913v1",
    "title": "Zeroth-Order Fine-Tuning of LLMs with Extreme Sparsity",
    "authors": [
      "Wentao Guo",
      "Jikai Long",
      "Yimeng Zeng",
      "Zirui Liu",
      "Xinyu Yang",
      "Yide Ran",
      "Jacob R. Gardner",
      "Osbert Bastani",
      "Christopher De Sa",
      "Xiaodong Yu",
      "Beidi Chen",
      "Zhaozhuo Xu"
    ],
    "abstract": "Zeroth-order optimization (ZO) is a memory-efficient strategy for fine-tuning\nLarge Language Models using only forward passes. However, the application of ZO\nfine-tuning in memory-constrained settings such as mobile phones and laptops is\nstill challenging since full precision forward passes are infeasible. In this\nstudy, we address this limitation by integrating sparsity and quantization into\nZO fine-tuning of LLMs. Specifically, we investigate the feasibility of\nfine-tuning an extremely small subset of LLM parameters using ZO. This approach\nallows the majority of un-tuned parameters to be quantized to accommodate the\nconstraint of limited device memory. Our findings reveal that the pre-training\nprocess can identify a set of \"sensitive parameters\" that can guide the ZO\nfine-tuning of LLMs on downstream tasks. Our results demonstrate that\nfine-tuning 0.1% sensitive parameters in the LLM with ZO can outperform the\nfull ZO fine-tuning performance, while offering wall-clock time speedup.\nAdditionally, we show that ZO fine-tuning targeting these 0.1% sensitive\nparameters, combined with 4 bit quantization, enables efficient ZO fine-tuning\nof an Llama2-7B model on a GPU device with less than 8 GiB of memory and\nnotably reduced latency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02913v1",
    "published_date": "2024-06-05 04:07:35 UTC",
    "updated_date": "2024-06-05 04:07:35 UTC"
  },
  {
    "arxiv_id": "2406.02900v2",
    "title": "Scaling Laws for Reward Model Overoptimization in Direct Alignment Algorithms",
    "authors": [
      "Rafael Rafailov",
      "Yaswanth Chittepu",
      "Ryan Park",
      "Harshit Sikchi",
      "Joey Hejna",
      "Bradley Knox",
      "Chelsea Finn",
      "Scott Niekum"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) has been crucial to the\nrecent success of Large Language Models (LLMs), however, it is often a complex\nand brittle process. In the classical RLHF framework, a reward model is first\ntrained to represent human preferences, which is in turn used by an online\nreinforcement learning (RL) algorithm to optimize the LLM. A prominent issue\nwith such methods is reward over-optimization or reward hacking, where\nperformance as measured by the learned proxy reward model increases, but true\nquality plateaus or even deteriorates. Direct Alignment Algorithms (DDAs) like\nDirect Preference Optimization have emerged as alternatives to the classical\nRLHF pipeline by circumventing the reward modeling phase. However, although\nDAAs do not use a separate proxy reward model, they still commonly deteriorate\nfrom over-optimization. While the so-called reward hacking phenomenon is not\nwell-defined for DAAs, we still uncover similar trends: at higher KL budgets,\nDAA algorithms exhibit similar degradation patterns to their classic RLHF\ncounterparts. In particular, we find that DAA methods deteriorate not only\nacross a wide range of KL budgets but also often before even a single epoch of\nthe dataset is completed. Through extensive empirical experimentation, this\nwork formulates and formalizes the reward over-optimization or hacking problem\nfor DAAs and explores its consequences across objectives, training regimes, and\nmodel scales.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "30 pages, 38th Conference on Neural Information Processing Systems\n  (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.02900v2",
    "published_date": "2024-06-05 03:41:37 UTC",
    "updated_date": "2024-11-05 01:44:14 UTC"
  },
  {
    "arxiv_id": "2407.11987v1",
    "title": "SlicerChat: Building a Local Chatbot for 3D Slicer",
    "authors": [
      "Colton Barr"
    ],
    "abstract": "3D Slicer is a powerful platform for 3D data visualization and analysis, but\nhas a significant learning curve for new users. Generative AI applications,\nsuch as ChatGPT, have emerged as a potential method of bridging the gap between\nvarious sources of documentation using natural language. The limited exposure\nof LLM services to 3D Slicer documentation, however, means that ChatGPT and\nrelated services tend to suffer from significant hallucination. The objective\nof this project is to build a chatbot architecture, called SlicerChat, that is\noptimized to answer 3D Slicer related questions and able to run locally using\nan open-source model. The core research questions explored in this work revolve\naround the answer quality and speed differences due to fine-tuning, model size,\nand the type of domain knowledge included in the prompt. A prototype SlicerChat\nsystem was built as a custom extension in 3D Slicer based on the Code-Llama\nInstruct architecture. Models of size 1.1B, 7B and 13B were fine-tuned using\nLow rank Adaptation, and various sources of 3D Slicer documentation were\ncompiled for use in a Retrieval Augmented Generation paradigm. Testing\ncombinations of fine-tuning and model sizes on a benchmark dataset of five 3D\nSlicer questions revealed that fine-tuning had no impact on model performance\nor speed compared to the base architecture, and that larger models performed\nbetter with a significant speed decrease. Experiments with adding 3D Slicer\ndocumentation to the prompt showed that Python sample code and Markdown\ndocumentation were the most useful information to include, but that adding 3D\nSlicer scene data and questions taken from Discourse also improved model\nperformance. In conclusion, this project shows the potential for integrating a\nhigh quality, local chatbot directly into 3D Slicer to help new users and\nexperienced developers alike to more efficiently use the software.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11987v1",
    "published_date": "2024-06-05 03:32:06 UTC",
    "updated_date": "2024-06-05 03:32:06 UTC"
  },
  {
    "arxiv_id": "2406.02890v1",
    "title": "Representation Learning For Efficient Deep Multi-Agent Reinforcement Learning",
    "authors": [
      "Dom Huh",
      "Prasant Mohapatra"
    ],
    "abstract": "Sample efficiency remains a key challenge in multi-agent reinforcement\nlearning (MARL). A promising approach is to learn a meaningful latent\nrepresentation space through auxiliary learning objectives alongside the MARL\nobjective to aid in learning a successful control policy. In our work, we\npresent MAPO-LSO (Multi-Agent Policy Optimization with Latent Space\nOptimization) which applies a form of comprehensive representation learning\ndevised to supplement MARL training. Specifically, MAPO-LSO proposes a\nmulti-agent extension of transition dynamics reconstruction and self-predictive\nlearning that constructs a latent state optimization scheme that can be\ntrivially extended to current state-of-the-art MARL algorithms. Empirical\nresults demonstrate MAPO-LSO to show notable improvements in sample efficiency\nand learning performance compared to its vanilla MARL counterpart without any\nadditional MARL hyperparameter tuning on a diverse suite of MARL tasks.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02890v1",
    "published_date": "2024-06-05 03:11:44 UTC",
    "updated_date": "2024-06-05 03:11:44 UTC"
  },
  {
    "arxiv_id": "2406.02888v3",
    "title": "HYDRA: Model Factorization Framework for Black-Box LLM Personalization",
    "authors": [
      "Yuchen Zhuang",
      "Haotian Sun",
      "Yue Yu",
      "Rushi Qiang",
      "Qifan Wang",
      "Chao Zhang",
      "Bo Dai"
    ],
    "abstract": "Personalization has emerged as a critical research area in modern intelligent\nsystems, focusing on mining users' behavioral history and adapting to their\npreferences for delivering tailored experiences. Despite the remarkable\nfew-shot capabilities exhibited by black-box large language models (LLMs), the\ninherent opacity of their model parameters presents significant challenges in\naligning the generated output with individual expectations. Existing solutions\nhave primarily focused on prompt design to incorporate user-specific profiles\nand behaviors; however, such approaches often struggle to generalize\neffectively due to their inability to capture shared knowledge among all users.\nTo address these challenges, we propose HYDRA, a model factorization framework\nthat captures both user-specific behavior patterns from historical data and\nshared general knowledge among all users to deliver personalized generation. In\norder to capture user-specific behavior patterns, we first train a reranker to\nprioritize the most useful information from top-retrieved relevant historical\nrecords. By combining the prioritized history with the corresponding query, we\ntrain an adapter to align the output with individual user-specific preferences,\neliminating the reliance on access to inherent model parameters of black-box\nLLMs. Both the reranker and the adapter can be decomposed into a base model\nwith multiple user-specific heads, resembling a hydra. The base model maintains\nshared knowledge across users, while the multiple personal heads capture\nuser-specific preferences. Experimental results demonstrate that HYDRA\noutperforms existing state-of-the-art prompt-based methods by an average\nrelative improvement of 9.01% across five diverse personalization tasks in the\nLaMP benchmark. Our implementation is available at\nhttps://github.com/night-chen/HYDRA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in NeurIPS'24",
    "pdf_url": "http://arxiv.org/pdf/2406.02888v3",
    "published_date": "2024-06-05 03:08:46 UTC",
    "updated_date": "2024-10-25 21:01:05 UTC"
  },
  {
    "arxiv_id": "2406.02886v2",
    "title": "PLaD: Preference-based Large Language Model Distillation with Pseudo-Preference Pairs",
    "authors": [
      "Rongzhi Zhang",
      "Jiaming Shen",
      "Tianqi Liu",
      "Haorui Wang",
      "Zhen Qin",
      "Feng Han",
      "Jialu Liu",
      "Simon Baumgartner",
      "Michael Bendersky",
      "Chao Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have exhibited impressive capabilities in\nvarious tasks, yet their vast parameter sizes restrict their applicability in\nresource-constrained settings. Knowledge distillation (KD) offers a viable\nsolution by transferring expertise from large teacher models to compact student\nmodels. However, traditional KD techniques face specific challenges when\napplied to LLMs, including restricted access to LLM outputs, significant\nteacher-student capacity gaps, and the inherited mis-calibration issue. In this\nwork, we present PLaD, a novel preference-based LLM distillation framework.\nPLaD exploits the teacher-student capacity discrepancy to generate\npseudo-preference pairs where teacher outputs are preferred over student\noutputs. Then, PLaD leverages a ranking loss to re-calibrate student's\nestimation of sequence likelihood, which steers the student's focus towards\nunderstanding the relative quality of outputs instead of simply imitating the\nteacher. PLaD bypasses the need for access to teacher LLM's internal states,\ntackles the student's expressivity limitations, and mitigates the student\nmis-calibration issue. Through extensive experiments on two sequence generation\ntasks and with various LLMs, we demonstrate the effectiveness of our proposed\nPLaD framework.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02886v2",
    "published_date": "2024-06-05 03:08:25 UTC",
    "updated_date": "2024-06-06 12:47:31 UTC"
  },
  {
    "arxiv_id": "2406.02882v3",
    "title": "Outdated Issue Aware Decoding for Reasoning Questions on Edited Knowledge",
    "authors": [
      "Zengkui Sun",
      "Yijin Liu",
      "Jiaan Wang",
      "Fandong Meng",
      "Jinan Xu",
      "Yufeng Chen",
      "Jie Zhou"
    ],
    "abstract": "Recently, Knowledge Editing has received increasing attention, since it could\nupdate the specific knowledge from outdated ones in pretrained models without\nre-training. However, as pointed out by recent studies, existing related\nmethods tend to merely memorize the superficial word composition of the edited\nknowledge, rather than truly learning and absorbing it. Consequently, on the\nreasoning questions, we discover that existing methods struggle to utilize the\nedited knowledge to reason the new answer, and tend to retain outdated\nresponses, which are generated by the original models utilizing original\nknowledge. Nevertheless, the outdated responses are unexpected for the correct\nanswers to reasoning questions, which we named as the outdated issue. To\nalleviate this issue, in this paper, we propose a simple yet effective decoding\nstrategy, i.e., outDated ISsue aware deCOding (DISCO), to enhance the\nperformance of edited models on reasoning questions. Specifically, we capture\nthe difference in the probability distribution between the original and edited\nmodels. Further, we amplify the difference of the token prediction in the\nedited model to alleviate the outdated issue, and thus enhance the model\nperformance w.r.t the edited knowledge. Experimental results suggest that\napplying DISCO could enhance edited models to reason, e.g., on reasoning\nquestions, DISCO outperforms the prior SOTA method by 12.99 F1 scores, and\nreduces the ratio of the outdated issue to 5.78% on the zsRE dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL2024 Findings, Codes are at https://github.com/Acerkoo/DISCO",
    "pdf_url": "http://arxiv.org/pdf/2406.02882v3",
    "published_date": "2024-06-05 03:00:15 UTC",
    "updated_date": "2024-06-16 08:50:34 UTC"
  },
  {
    "arxiv_id": "2406.06584v1",
    "title": "Evaluating the Efficacy of Large Language Models in Detecting Fake News: A Comparative Analysis",
    "authors": [
      "Sahas Koka",
      "Anthony Vuong",
      "Anish Kataria"
    ],
    "abstract": "In an era increasingly influenced by artificial intelligence, the detection\nof fake news is crucial, especially in contexts like election seasons where\nmisinformation can have significant societal impacts. This study evaluates the\neffectiveness of various LLMs in identifying and filtering fake news content.\nUtilizing a comparative analysis approach, we tested four large LLMs -- GPT-4,\nClaude 3 Sonnet, Gemini Pro 1.0, and Mistral Large -- and two smaller LLMs --\nGemma 7B and Mistral 7B. By using fake news dataset samples from Kaggle, this\nresearch not only sheds light on the current capabilities and limitations of\nLLMs in fake news detection but also discusses the implications for developers\nand policymakers in enhancing AI-driven informational integrity.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06584v1",
    "published_date": "2024-06-05 02:55:21 UTC",
    "updated_date": "2024-06-05 02:55:21 UTC"
  },
  {
    "arxiv_id": "2406.02880v2",
    "title": "Controllable Talking Face Generation by Implicit Facial Keypoints Editing",
    "authors": [
      "Dong Zhao",
      "Jiaying Shi",
      "Wenjun Li",
      "Shudong Wang",
      "Shenghui Xu",
      "Zhaoming Pan"
    ],
    "abstract": "Audio-driven talking face generation has garnered significant interest within\nthe domain of digital human research. Existing methods are encumbered by\nintricate model architectures that are intricately dependent on each other,\ncomplicating the process of re-editing image or video inputs. In this work, we\npresent ControlTalk, a talking face generation method to control face\nexpression deformation based on driven audio, which can construct the head pose\nand facial expression including lip motion for both single image or sequential\nvideo inputs in a unified manner. By utilizing a pre-trained video synthesis\nrenderer and proposing the lightweight adaptation, ControlTalk achieves precise\nand naturalistic lip synchronization while enabling quantitative control over\nmouth opening shape. Our experiments show that our method is superior to\nstate-of-the-art performance on widely used benchmarks, including HDTF and\nMEAD. The parameterized adaptation demonstrates remarkable generalization\ncapabilities, effectively handling expression deformation across same-ID and\ncross-ID scenarios, and extending its utility to out-of-domain portraits,\nregardless of languages. Code is available at\nhttps://github.com/NetEase-Media/ControlTalk.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02880v2",
    "published_date": "2024-06-05 02:54:46 UTC",
    "updated_date": "2024-11-07 02:26:49 UTC"
  },
  {
    "arxiv_id": "2406.02876v2",
    "title": "LCS: A Language Converter Strategy for Zero-Shot Neural Machine Translation",
    "authors": [
      "Zengkui Sun",
      "Yijin Liu",
      "Fandong Meng",
      "Jinan Xu",
      "Yufeng Chen",
      "Jie Zhou"
    ],
    "abstract": "Multilingual neural machine translation models generally distinguish\ntranslation directions by the language tag (LT) in front of the source or\ntarget sentences. However, current LT strategies cannot indicate the desired\ntarget language as expected on zero-shot translation, i.e., the off-target\nissue. Our analysis reveals that the indication of the target language is\nsensitive to the placement of the target LT. For example, when placing the\ntarget LT on the decoder side, the indication would rapidly degrade along with\ndecoding steps, while placing the target LT on the encoder side would lead to\ncopying or paraphrasing the source input. To address the above issues, we\npropose a simple yet effective strategy named Language Converter Strategy\n(LCS). By introducing the target language embedding into the top encoder\nlayers, LCS mitigates confusion in the encoder and ensures stable language\nindication for the decoder. Experimental results on MultiUN, TED, and OPUS-100\ndatasets demonstrate that LCS could significantly mitigate the off-target\nissue, with language accuracy up to 95.28%, 96.21%, and 85.35% meanwhile\noutperforming the vanilla LT strategy by 3.07, 3,3, and 7.93 BLEU scores on\nzero-shot translation, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL2024 Findings, Codes are at https://github.com/Acerkoo/LCS",
    "pdf_url": "http://arxiv.org/pdf/2406.02876v2",
    "published_date": "2024-06-05 02:52:17 UTC",
    "updated_date": "2024-06-06 03:22:38 UTC"
  },
  {
    "arxiv_id": "2406.02872v2",
    "title": "Combinatorial Optimization with Automated Graph Neural Networks",
    "authors": [
      "Yang Liu",
      "Peng Zhang",
      "Yang Gao",
      "Chuan Zhou",
      "Zhao Li",
      "Hongyang Chen"
    ],
    "abstract": "In recent years, graph neural networks (GNNs) have become increasingly\npopular for solving NP-hard combinatorial optimization (CO) problems, such as\nmaximum cut and maximum independent set. The core idea behind these methods is\nto represent a CO problem as a graph and then use GNNs to learn the node/graph\nembedding with combinatorial information. Although these methods have achieved\npromising results, given a specific CO problem, the design of GNN architectures\nstill requires heavy manual work with domain knowledge. Existing automated GNNs\nare mostly focused on traditional graph learning problems, which is\ninapplicable to solving NP-hard CO problems. To this end, we present a new\nclass of \\textbf{AUTO}mated \\textbf{G}NNs for solving \\textbf{NP}-hard\nproblems, namely \\textbf{AutoGNP}. We represent CO problems by GNNs and focus\non two specific problems, i.e., mixed integer linear programming and quadratic\nunconstrained binary optimization. The idea of AutoGNP is to use graph neural\narchitecture search algorithms to automatically find the best GNNs for a given\nNP-hard combinatorial optimization problem. Compared with existing graph neural\narchitecture search algorithms, AutoGNP utilizes two-hop operators in the\narchitecture search space. Moreover, AutoGNP utilizes simulated annealing and a\nstrict early stopping policy to avoid local optimal solutions. Empirical\nresults on benchmark combinatorial problems demonstrate the superiority of our\nproposed model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.02872v2",
    "published_date": "2024-06-05 02:43:41 UTC",
    "updated_date": "2024-06-10 02:45:41 UTC"
  },
  {
    "arxiv_id": "2406.02871v1",
    "title": "Sound Heuristic Search Value Iteration for Undiscounted POMDPs with Reachability Objectives",
    "authors": [
      "Qi Heng Ho",
      "Martin S. Feather",
      "Federico Rossi",
      "Zachary N. Sunberg",
      "Morteza Lahijanian"
    ],
    "abstract": "Partially Observable Markov Decision Processes (POMDPs) are powerful models\nfor sequential decision making under transition and observation uncertainties.\nThis paper studies the challenging yet important problem in POMDPs known as the\n(indefinite-horizon) Maximal Reachability Probability Problem (MRPP), where the\ngoal is to maximize the probability of reaching some target states. This is\nalso a core problem in model checking with logical specifications and is\nnaturally undiscounted (discount factor is one). Inspired by the success of\npoint-based methods developed for discounted problems, we study their\nextensions to MRPP. Specifically, we focus on trial-based heuristic search\nvalue iteration techniques and present a novel algorithm that leverages the\nstrengths of these techniques for efficient exploration of the belief space\n(informed search via value bounds) while addressing their drawbacks in handling\nloops for indefinite-horizon problems. The algorithm produces policies with\ntwo-sided bounds on optimal reachability probabilities. We prove convergence to\nan optimal policy from below under certain conditions. Experimental evaluations\non a suite of benchmarks show that our algorithm outperforms existing methods\nin almost all cases in both probability guarantees and computation time.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to the Conference on Uncertainty in Artificial Intelligence\n  (UAI) 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02871v1",
    "published_date": "2024-06-05 02:33:50 UTC",
    "updated_date": "2024-06-05 02:33:50 UTC"
  },
  {
    "arxiv_id": "2406.02867v1",
    "title": "Oscillations enhance time-series prediction in reservoir computing with feedback",
    "authors": [
      "Yuji Kawai",
      "Takashi Morita",
      "Jihoon Park",
      "Minoru Asada"
    ],
    "abstract": "Reservoir computing, a machine learning framework used for modeling the\nbrain, can predict temporal data with little observations and minimal\ncomputational resources. However, it is difficult to accurately reproduce the\nlong-term target time series because the reservoir system becomes unstable.\nThis predictive capability is required for a wide variety of time-series\nprocessing, including predictions of motor timing and chaotic dynamical\nsystems. This study proposes oscillation-driven reservoir computing (ODRC) with\nfeedback, where oscillatory signals are fed into a reservoir network to\nstabilize the network activity and induce complex reservoir dynamics. The ODRC\ncan reproduce long-term target time series more accurately than conventional\nreservoir computing methods in a motor timing and chaotic time-series\nprediction tasks. Furthermore, it generates a time series similar to the target\nin the unexperienced period, that is, it can learn the abstract generative\nrules from limited observations. Given these significant improvements made by\nthe simple and computationally inexpensive implementation, the ODRC would serve\nas a practical model of various time series data. Moreover, we will discuss\nbiological implications of the ODRC, considering it as a model of neural\noscillations and their cerebellar processors.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02867v1",
    "published_date": "2024-06-05 02:30:29 UTC",
    "updated_date": "2024-06-05 02:30:29 UTC"
  },
  {
    "arxiv_id": "2406.02864v1",
    "title": "NUMCoT: Numerals and Units of Measurement in Chain-of-Thought Reasoning using Large Language Models",
    "authors": [
      "Ancheng Xu",
      "Minghuan Tan",
      "Lei Wang",
      "Min Yang",
      "Ruifeng Xu"
    ],
    "abstract": "Numeral systems and units of measurement are two conjoined topics in\nactivities of human beings and have mutual effects with the languages\nexpressing them. Currently, the evaluation of Large Language Models (LLMs)\noften involves mathematical reasoning, yet little attention is given to how\nminor changes in numbers or units can drastically alter the complexity of\nproblems and the performance of LLMs. In this paper, we scrutinize existing\nLLMs on processing of numerals and units of measurement by constructing\ndatasets with perturbations. We first anatomize the reasoning of math word\nproblems to different sub-procedures like numeral conversions from language to\nnumbers and measurement conversions based on units. Then we further annotate\nmath word problems from ancient Chinese arithmetic works which are challenging\nin numerals and units of measurement. Experiments on perturbed datasets\ndemonstrate that LLMs still encounter difficulties in handling numeral and\nmeasurement conversions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02864v1",
    "published_date": "2024-06-05 02:26:14 UTC",
    "updated_date": "2024-06-05 02:26:14 UTC"
  },
  {
    "arxiv_id": "2406.02856v5",
    "title": "Xmodel-LM Technical Report",
    "authors": [
      "Yichuan Wang",
      "Yang Liu",
      "Yu Yan",
      "Qun Wang",
      "Xucheng Huang",
      "Ling Jiang"
    ],
    "abstract": "We introduce Xmodel-LM, a compact and efficient 1.1B language model\npre-trained on around 2 trillion tokens. Trained on our self-built dataset\n(Xdata), which balances Chinese and English corpora based on downstream task\noptimization, Xmodel-LM exhibits remarkable performance despite its smaller\nsize. It notably surpasses existing open-source language models of similar\nscale. Our model checkpoints and code are publicly accessible on GitHub at\nhttps://github.com/XiaoduoAILab/XmodelLM.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02856v5",
    "published_date": "2024-06-05 02:12:06 UTC",
    "updated_date": "2024-11-19 08:38:55 UTC"
  },
  {
    "arxiv_id": "2406.02841v1",
    "title": "Conditional Idempotent Generative Networks",
    "authors": [
      "NiccolÃ² Ronchetti"
    ],
    "abstract": "We propose Conditional Idempotent Generative Networks (CIGN), a novel\napproach that expands upon Idempotent Generative Networks (IGN) to enable\nconditional generation. While IGNs offer efficient single-pass generation, they\nlack the ability to control the content of the generated data. CIGNs address\nthis limitation by incorporating conditioning mechanisms, allowing users to\nsteer the generation process towards specific types of data.\n  We establish the theoretical foundations for CIGNs, outlining their scope,\nloss function design, and evaluation metrics. We then present two potential\narchitectures for implementing CIGNs: channel conditioning and filter\nconditioning. Finally, we discuss experimental results on the MNIST dataset,\ndemonstrating the effectiveness of both approaches. Our findings pave the way\nfor further exploration of CIGNs on larger datasets and with more powerful\ncomputing resources to determine the optimal implementation strategy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.02841v1",
    "published_date": "2024-06-05 01:31:50 UTC",
    "updated_date": "2024-06-05 01:31:50 UTC"
  },
  {
    "arxiv_id": "2406.02827v1",
    "title": "Stochastic Diffusion: A Diffusion Probabilistic Model for Stochastic Time Series Forecasting",
    "authors": [
      "Yuansan Liu",
      "Sudanthi Wijewickrema",
      "Dongting Hu",
      "Christofer Bester",
      "Stephen O'Leary",
      "James Bailey"
    ],
    "abstract": "Recent innovations in diffusion probabilistic models have paved the way for\nsignificant progress in image, text and audio generation, leading to their\napplications in generative time series forecasting. However, leveraging such\nabilities to model highly stochastic time series data remains a challenge. In\nthis paper, we propose a novel Stochastic Diffusion (StochDiff) model which\nlearns data-driven prior knowledge at each time step by utilizing the\nrepresentational power of the stochastic latent spaces to model the variability\nof the multivariate time series data. The learnt prior knowledge helps the\nmodel to capture complex temporal dynamics and the inherent uncertainty of the\ndata. This improves its ability to model highly stochastic time series data.\nThrough extensive experiments on real-world datasets, we demonstrate the\neffectiveness of our proposed model on stochastic time series forecasting.\nAdditionally, we showcase an application of our model for real-world surgical\nguidance, highlighting its potential to benefit the medical community.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.02827v1",
    "published_date": "2024-06-05 00:13:38 UTC",
    "updated_date": "2024-06-05 00:13:38 UTC"
  }
]