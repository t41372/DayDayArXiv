{
  "date": "2024-06-15",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-15 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 59 篇论文，主要聚焦人工智能（AI）模型优化、医疗应用、机器人视觉和大型语言模型（LLMs）在金融等领域的前沿研究。其中，Occam's Razor for Self Supervised Learning 简化了自监督学习设计，A Comprehensive Survey of Foundation Models in Medicine 提供了医疗 AI 的全面综述，RoboPoint 展示了 LLMs 在机器人空间感知上的潜力，而 Large Language Models for Financial Applications 探讨了 LLMs 在金融中的挑战与机遇。这些论文突出了 AI 效率提升和实际应用，涉及知名学者如 Ruogu Fang 和 Dieter Fox 的工作。\n\n下面，我将挑选并简要讨论几篇重要或话题度高的论文，先从 AI 和 LLMs 核心研究开始，然后聊医疗和机器人相关内容。对于其他论文，我会快速掠过，只提关键点，以控制篇幅。\n\n### AI 和 LLMs 核心研究\n- **Occam's Razor for Self Supervised Learning (简洁的剃刀原则在自监督学习中的应用)**  \n  作者：Mark Ibrahim 等。论文发现，对于小型数据集，自监督学习（SSL）的额外设计（如投影网络）并不显著提升表示质量，主要贡献是简化 SSL 部署，减少超参数调整。该发现支持现有理论研究，并解释了 SSL 对训练设置的敏感性，潜在影响包括加速小规模应用开发。\n\n- **A Comprehensive Survey of Foundation Models in Medicine (基础模型在医疗领域的全面综述)**  \n  作者：Ruogu Fang 等。该综述覆盖了基础模型（如 BERT 和 GPT 系列）在临床 NLP、图像分析和组学研究中的进展，主要发现是这些模型提升了医疗任务的效率，但也面临挑战如数据偏差和伦理问题。该论文由知名学者主导，提供宝贵见解，帮助医疗 AI 领域的研究者评估风险。\n\n- **Large Language Models for Financial Applications: Progress, Prospects and Challenges (大型语言模型在金融应用的进展、展望和挑战)**  \n  作者：Yuqi Nie 等。论文综述了 LLMs 在金融任务（如情感分析和时间序列预测）中的应用，主要贡献是强调 LLMs 的上下文理解和迁移学习优势，同时指出挑战如数据隐私。该研究有助于金融领域模型部署，具有实际应用潜力。\n\n- **How Should We Extract Discrete Audio Tokens from Self-Supervised Models? (如何从自监督模型中提取离散音频标记)**  \n  作者：Pooneh Mousavi 等。论文探索了语义标记的提取方法，主要发现是通过注意力机制优化自监督模型的层级选择，提高音频任务的性能。该工作已接受 Interspeech 2024，可能推动音频处理领域的创新。\n\n其他 AI 相关论文，如 Graph Neural Thompson Sampling（图神经采样方法）和 TokenRec（LLM-based 生成推荐），则快速提一下：前者优化了图结构下的强化学习，后者提升了推荐系统的用户表示，但细节较技术化，不展开。\n\n### 医疗和健康应用\n- **Applications of Generative AI in Healthcare: Algorithmic, Ethical, Legal and Societal Considerations (生成式 AI 在医疗中的应用：算法、伦理、法律和社会考虑)**  \n  作者：Onyekachukwu R. Okonji 等。论文讨论了生成式 AI 在医疗图像和文本分析中的潜力，主要贡献是分析算法偏差、隐私风险和公平性挑战，并提出负责任部署框架。该研究强调非洲语境的公正性，具有社会影响。\n\n- **Emerging Safety Attack and Defense in Federated Instruction Tuning of Large Language Models (联邦指令微调中 LLMs 的安全攻击与防御)**  \n  作者：Rui Ye 等。论文揭示了联邦学习中 LLMs 的安全漏洞，并提出后处理防御方法，主要发现是攻击可显著降低模型安全，但防御可提升 69% 的鲁棒性。该工作对隐私保护有实际启发。\n\n其他医疗论文，如 A Survey of Large Language Models in Medicine（另一份综述）和 Mental Disorder Classification（精神障碍分类），则因重复性或较窄焦点而快速掠过：前者扩展了医疗 AI 应用，后者使用时序文本提升分类准确率。\n\n### 机器人和视觉技术\n- **RoboPoint: A Vision-Language Model for Spatial Affordance Prediction for Robotics (RoboPoint: 用于机器人空间可达性预测的视觉语言模型)**  \n  作者：Dieter Fox 等。论文引入合成数据管道训练 VLM，主要贡献是提升机器人任务（如导航和操作）的空间预测准确率 21.8%，无需真实数据。该研究由知名机器人专家主导，展示了 LLMs 在实际机器人应用中的潜力。\n\n- **GenMM: Geometrically and Temporally Consistent Multimodal Data Generation for Video and LiDAR (GenMM: 用于视频和 LiDAR 的几何和时间一致的多模态数据生成)**  \n  作者：Bharat Singh 等。论文提出一种方法插入 3D 对象到视频和 LiDAR 数据，主要发现是确保几何一致性，提高多模态模拟的真实性。该工作可应用于自动驾驶，提升仿真效率。\n\n其他机器人论文，如 HumanPlus（类人机器人模仿）和 NeRFDeformer（NeRF 变换），快速提一下：前者使用视觉跟踪提升机器人学习，后者优化 3D 流形预测，但不展开讨论。\n\n### 其他领域快速掠过\n剩余论文多涉及能源、交通和一般 AI 优化，如 Stacking for Probabilistic Short-term Load Forecasting（负载预测方法）和 Public Computer Vision Datasets for Precision Livestock Farming（畜牧视觉数据集综述）。这些论文贡献稳健，但不具话题度：前者提升了预测准确率，后者提供了数据集资源，仅供参考。\n\n总之，今天的 arXiv 更新突显 AI 领域的创新与挑战，建议关注 LLMs 在医疗和机器人的应用，以推动实际部署。如果您有特定兴趣领域，欢迎进一步探索这些论文！",
  "papers": [
    {
      "arxiv_id": "2406.10743v1",
      "title": "Occam's Razor for Self Supervised Learning: What is Sufficient to Learn Good Representations?",
      "title_zh": "翻译失败",
      "authors": [
        "Mark Ibrahim",
        "David Klindt",
        "Randall Balestriero"
      ],
      "abstract": "Deep Learning is often depicted as a trio of data-architecture-loss. Yet,\nrecent Self Supervised Learning (SSL) solutions have introduced numerous\nadditional design choices, e.g., a projector network, positive views, or\nteacher-student networks. These additions pose two challenges. First, they\nlimit the impact of theoretical studies that often fail to incorporate all\nthose intertwined designs. Second, they slow-down the deployment of SSL methods\nto new domains as numerous hyper-parameters need to be carefully tuned. In this\nstudy, we bring forward the surprising observation that--at least for\npretraining datasets of up to a few hundred thousands samples--the additional\ndesigns introduced by SSL do not contribute to the quality of the learned\nrepresentations. That finding not only provides legitimacy to existing\ntheoretical studies, but also simplifies the practitioner's path to SSL\ndeployment in numerous small and medium scale settings. Our finding answers a\nlong-lasting question: the often-experienced sensitivity to training settings\nand hyper-parameters encountered in SSL come from their design, rather than the\nabsence of supervised guidance.",
      "tldr_zh": "本研究探讨了Self Supervised Learning (SSL)中额外设计（如投影网络、正样本视图和教师-学生网络）是否必要，以简化学习良好表示。研究发现，对于样本量在几百千以内的预训练数据集，这些额外设计并不提升表示质量，从而支持现有理论研究的适用性。作者强调，SSL在训练设置和hyper-parameters上的敏感性源于这些设计本身，而非缺乏监督指导，这有助于在小中规模场景中更轻松部署SSL方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10743v1",
      "published_date": "2024-06-15 21:42:15 UTC",
      "updated_date": "2024-06-15 21:42:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:27:01.984770"
    },
    {
      "arxiv_id": "2406.10741v1",
      "title": "Speech Emotion Recognition Using CNN and Its Use Case in Digital Healthcare",
      "title_zh": "使用 CNN 的语音情感识别及其在数字医疗中的应用案例",
      "authors": [
        "Nishargo Nigar"
      ],
      "abstract": "The process of identifying human emotion and affective states from speech is\nknown as speech emotion recognition (SER). This is based on the observation\nthat tone and pitch in the voice frequently convey underlying emotion. Speech\nrecognition includes the ability to recognize emotions, which is becoming\nincreasingly popular and in high demand. With the help of appropriate factors\n(such modalities, emotions, intensities, repetitions, etc.) found in the data,\nmy research seeks to use the Convolutional Neural Network (CNN) to distinguish\nemotions from audio recordings and label them in accordance with the range of\ndifferent emotions. I have developed a machine learning model to identify\nemotions from supplied audio files with the aid of machine learning methods.\nThe evaluation is mostly focused on precision, recall, and F1 score, which are\ncommon machine learning metrics. To properly set up and train the machine\nlearning framework, the main objective is to investigate the influence and\ncross-relation of all input and output parameters. To improve the ability to\nrecognize intentions, a key condition for communication, I have evaluated\nemotions using my specialized machine learning algorithm via voice that would\naddress the emotional state from voice with the help of digital healthcare,\nbridging the gap between human and artificial intelligence (AI).",
      "tldr_zh": "这篇论文探讨了使用 Convolutional Neural Network (CNN) 进行 Speech Emotion Recognition (SER)，旨在通过分析语音中的语气和音高来识别人类情感状态，并将其应用于数字医疗领域。研究开发了一个机器学习模型，从音频文件中提取相关因素（如模态、情感强度和重复性），并通过 precision、recall 和 F1 score 等指标评估其性能。最终，该模型有助于桥接人类与人工智能 (AI) 之间的情感差距，提升意图识别能力，为数字医疗中的情感交互提供支持。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Master's Thesis at Hamburg University of Technology",
      "pdf_url": "http://arxiv.org/pdf/2406.10741v1",
      "published_date": "2024-06-15 21:33:03 UTC",
      "updated_date": "2024-06-15 21:33:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:27:14.124729"
    },
    {
      "arxiv_id": "2406.10735v1",
      "title": "How Should We Extract Discrete Audio Tokens from Self-Supervised Models?",
      "title_zh": "我们应该如何从自监督模型中提取离散音频标记？",
      "authors": [
        "Pooneh Mousavi",
        "Jarod Duret",
        "Salah Zaiem",
        "Luca Della Libera",
        "Artem Ploujnikov",
        "Cem Subakan",
        "Mirco Ravanelli"
      ],
      "abstract": "Discrete audio tokens have recently gained attention for their potential to\nbridge the gap between audio and language processing. Ideal audio tokens must\npreserve content, paralinguistic elements, speaker identity, and many other\naudio details. Current audio tokenization methods fall into two categories:\nSemantic tokens, acquired through quantization of Self-Supervised Learning\n(SSL) models, and Neural compression-based tokens (codecs). Although previous\nstudies have benchmarked codec models to identify optimal configurations, the\nideal setup for quantizing pretrained SSL models remains unclear. This paper\nexplores the optimal configuration of semantic tokens across discriminative and\ngenerative tasks. We propose a scalable solution to train a universal vocoder\nacross multiple SSL layers. Furthermore, an attention mechanism is employed to\nidentify task-specific influential layers, enhancing the adaptability and\nperformance of semantic tokens in diverse audio applications.",
      "tldr_zh": "该论文探讨从自监督模型（Self-Supervised Learning, SSL）中提取离散音频标记（Discrete audio tokens）的最佳方式，以桥接音频和语言处理，同时保留内容、副语言元素、说话者身份等音频细节。研究者比较了语义标记和神经压缩-based 标记（codecs），并专注于语义标记的优化配置，包括在辨别和生成任务中的应用。他们提出一个可扩展解决方案：训练一个通用 vocoder 跨多个 SSL 层，并引入注意力机制（attention mechanism）来识别任务特定的影响层，从而提升语义标记在多样音频应用中的性能和适应性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "4 pages, 2 figures, 2 tables, Accepted at Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.10735v1",
      "published_date": "2024-06-15 20:43:07 UTC",
      "updated_date": "2024-06-15 20:43:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:27:28.944128"
    },
    {
      "arxiv_id": "2406.10730v1",
      "title": "Order-theoretic models for decision-making: Learning, optimization, complexity and computation",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Hack"
      ],
      "abstract": "The study of intelligent systems explains behaviour in terms of economic\nrationality. This results in an optimization principle involving a function or\nutility, which states that the system will evolve until the configuration of\nmaximum utility is achieved. Recently, this theory has incorporated\nconstraints, i.e., the optimum is achieved when the utility is maximized while\nrespecting some information-processing constraints. This is reminiscent of\nthermodynamic systems. As such, the study of intelligent systems has benefited\nfrom the tools of thermodynamics. The first aim of this thesis is to clarify\nthe applicability of these results in the study of intelligent systems.\n  We can think of the local transition steps in thermodynamic or intelligent\nsystems as being driven by uncertainty. In fact, the transitions in both\nsystems can be described in terms of majorization. Hence, real-valued\nuncertainty measures like Shannon entropy are simply a proxy for their more\ninvolved behaviour. More in general, real-valued functions are fundamental to\nstudy optimization and complexity in the order-theoretic approach to several\ntopics, including economics, thermodynamics, and quantum mechanics. The second\naim of this thesis is to improve on this classification.\n  The basic similarity between thermodynamic and intelligent systems is based\non an uncertainty notion expressed by a preorder. We can also think of the\ntransitions in the steps of a computational process as a decision-making\nprocedure. In fact, by adding some requirements on the considered order\nstructures, we can build an abstract model of uncertainty reduction that allows\nto incorporate computability, that is, to distinguish the objects that can be\nconstructed by following a finite set of instructions from those that cannot.\nThe third aim of this thesis is to clarify the requirements on the order\nstructure that allow such a framework.",
      "tldr_zh": "本论文探讨了基于秩序理论（order-theoretic models）的决策模型，旨在将智能系统的优化原则与热力学系统相联系，通过最大化效用（utility）函数并考虑信息处理约束来解释行为。论文首先澄清了热力学工具在智能系统中的适用性，并使用 majorization 和预序（preorder）来描述不确定性驱动的系统转换。最终贡献包括改进对优化、复杂性和计算的分类，并定义了秩序结构的要求，以构建一个整合可计算性的抽象不确定性减少模型。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LO",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "PhD thesis",
      "pdf_url": "http://arxiv.org/pdf/2406.10730v1",
      "published_date": "2024-06-15 20:20:43 UTC",
      "updated_date": "2024-06-15 20:20:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:27:36.992414"
    },
    {
      "arxiv_id": "2406.10729v3",
      "title": "A Comprehensive Survey of Foundation Models in Medicine",
      "title_zh": "翻译失败",
      "authors": [
        "Wasif Khan",
        "Seowung Leem",
        "Kyle B. See",
        "Joshua K. Wong",
        "Shaoting Zhang",
        "Ruogu Fang"
      ],
      "abstract": "Foundation models (FMs) are large-scale deep learning models trained on\nmassive datasets, often using self-supervised learning techniques. These models\nserve as a versatile base for a wide range of downstream tasks, including those\nin medicine and healthcare. FMs have demonstrated remarkable success across\nmultiple healthcare domains. However, existing surveys in this field do not\ncomprehensively cover all areas where FMs have made significant strides. In\nthis survey, we present a comprehensive review of FMs in medicine, focusing on\ntheir evolution, learning strategies, flagship models, applications, and\nassociated challenges. We examine how prominent FMs, such as the BERT and GPT\nfamilies, are transforming various aspects of healthcare, including clinical\nlarge language models, medical image analysis, and omics research.\nAdditionally, we provide a detailed taxonomy of FM-enabled healthcare\napplications, spanning clinical natural language processing, medical computer\nvision, graph learning, and other biology- and omics- related tasks. Despite\nthe transformative potentials of FMs, they also pose unique challenges. This\nsurvey delves into these challenges and highlights open research questions and\nlessons learned to guide researchers and practitioners. Our goal is to provide\nvaluable insights into the capabilities of FMs in health, facilitating\nresponsible deployment and mitigating associated risks.",
      "tldr_zh": "这篇调查论文对Foundation Models (FMs) 在医学领域的应用进行了全面回顾，涵盖了这些基于大规模数据集和自监督学习训练的模型在医疗保健中的演变、学习策略以及标志性模型如BERT和GPT系列。论文详细分类了FMs的应用，包括临床自然语言处理、医疗计算机视觉、图学习以及组学相关任务，展示了它们在临床大语言模型、医疗图像分析和生物学研究中的显著成功。尽管FMs具有变革潜力，但论文也指出了面临的独特挑战，如风险管理，并提供了开放研究问题和经验教训，以指导负责任的部署和实践。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Currently under review in IEEE REVIEWS IN BIOMEDICAL ENGINEERING",
      "pdf_url": "http://arxiv.org/pdf/2406.10729v3",
      "published_date": "2024-06-15 20:04:06 UTC",
      "updated_date": "2025-01-16 16:04:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:27:50.323932"
    },
    {
      "arxiv_id": "2407.06196v1",
      "title": "Poetry2Image: An Iterative Correction Framework for Images Generated from Chinese Classical Poetry",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Jiang",
        "Yiran Ling",
        "Binzhu Li",
        "Pengxiang Li",
        "Junming Piao",
        "Yu Zhang"
      ],
      "abstract": "Text-to-image generation models often struggle with key element loss or\nsemantic confusion in tasks involving Chinese classical poetry.Addressing this\nissue through fine-tuning models needs considerable training costs.\nAdditionally, manual prompts for re-diffusion adjustments need professional\nknowledge. To solve this problem, we propose Poetry2Image, an iterative\ncorrection framework for images generated from Chinese classical poetry.\nUtilizing an external poetry dataset, Poetry2Image establishes an automated\nfeedback and correction loop, which enhances the alignment between poetry and\nimage through image generation models and subsequent re-diffusion modifications\nsuggested by large language models (LLM). Using a test set of 200 sentences of\nChinese classical poetry, the proposed method--when integrated with five\npopular image generation models--achieves an average element completeness of\n70.63%, representing an improvement of 25.56% over direct image generation. In\ntests of semantic correctness, our method attains an average semantic\nconsistency of 80.09%. The study not only promotes the dissemination of ancient\npoetry culture but also offers a reference for similar non-fine-tuning methods\nto enhance LLM generation.",
      "tldr_zh": "本文提出Poetry2Image框架，一种针对中文古典诗歌文本到图像生成问题的迭代修正方法，以解决关键元素丢失和语义混乱问题，而无需昂贵的模型微调。框架利用外部诗歌数据集，建立自动反馈循环：通过图像生成模型创建初始图像，然后由LLM建议再扩散修改，以提升诗歌与图像的匹配度。在200句测试诗歌集上，与五种流行模型整合后，该方法使元素完整性平均达到70.63%（较直接生成提高25.56%），语义一致性达80.09%。这项研究不仅促进了古代诗歌文化的传播，还为类似非微调的LLM生成方法提供了宝贵参考。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.06196v1",
      "published_date": "2024-06-15 19:45:08 UTC",
      "updated_date": "2024-06-15 19:45:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:28:04.338863"
    },
    {
      "arxiv_id": "2406.10722v1",
      "title": "GenMM: Geometrically and Temporally Consistent Multimodal Data Generation for Video and LiDAR",
      "title_zh": "GenMM：几何上和时间上一致的多模态数据生成，用于视频和 LiDAR",
      "authors": [
        "Bharat Singh",
        "Viveka Kulharia",
        "Luyu Yang",
        "Avinash Ravichandran",
        "Ambrish Tyagi",
        "Ashish Shrivastava"
      ],
      "abstract": "Multimodal synthetic data generation is crucial in domains such as autonomous\ndriving, robotics, augmented/virtual reality, and retail. We propose a novel\napproach, GenMM, for jointly editing RGB videos and LiDAR scans by inserting\ntemporally and geometrically consistent 3D objects. Our method uses a reference\nimage and 3D bounding boxes to seamlessly insert and blend new objects into\ntarget videos. We inpaint the 2D Regions of Interest (consistent with 3D boxes)\nusing a diffusion-based video inpainting model. We then compute semantic\nboundaries of the object and estimate it's surface depth using state-of-the-art\nsemantic segmentation and monocular depth estimation techniques. Subsequently,\nwe employ a geometry-based optimization algorithm to recover the 3D shape of\nthe object's surface, ensuring it fits precisely within the 3D bounding box.\nFinally, LiDAR rays intersecting with the new object surface are updated to\nreflect consistent depths with its geometry. Our experiments demonstrate the\neffectiveness of GenMM in inserting various 3D objects across video and LiDAR\nmodalities.",
      "tldr_zh": "该研究提出了一种名为GenMM的新方法，用于在视频和LiDAR多模态数据中生成几何和时间一致的3D对象，从而应用于自动驾驶、机器人等领域。GenMM利用参考图像和3D bounding boxes，通过扩散模型修复2D区域、语义分割估算深度，以及几何优化算法恢复对象的3D形状，并更新LiDAR数据以确保一致性。该方法在实验中证明了其有效性，能够无缝插入各种3D对象，提升多模态数据的编辑质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10722v1",
      "published_date": "2024-06-15 19:29:01 UTC",
      "updated_date": "2024-06-15 19:29:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:28:13.599639"
    },
    {
      "arxiv_id": "2406.10721v1",
      "title": "RoboPoint: A Vision-Language Model for Spatial Affordance Prediction for Robotics",
      "title_zh": "翻译失败",
      "authors": [
        "Wentao Yuan",
        "Jiafei Duan",
        "Valts Blukis",
        "Wilbert Pumacay",
        "Ranjay Krishna",
        "Adithyavairavan Murali",
        "Arsalan Mousavian",
        "Dieter Fox"
      ],
      "abstract": "From rearranging objects on a table to putting groceries into shelves, robots\nmust plan precise action points to perform tasks accurately and reliably. In\nspite of the recent adoption of vision language models (VLMs) to control robot\nbehavior, VLMs struggle to precisely articulate robot actions using language.\nWe introduce an automatic synthetic data generation pipeline that\ninstruction-tunes VLMs to robotic domains and needs. Using the pipeline, we\ntrain RoboPoint, a VLM that predicts image keypoint affordances given language\ninstructions. Compared to alternative approaches, our method requires no\nreal-world data collection or human demonstration, making it much more scalable\nto diverse environments and viewpoints. In addition, RoboPoint is a general\nmodel that enables several downstream applications such as robot navigation,\nmanipulation, and augmented reality (AR) assistance. Our experiments\ndemonstrate that RoboPoint outperforms state-of-the-art VLMs (GPT-4o) and\nvisual prompting techniques (PIVOT) by 21.8% in the accuracy of predicting\nspatial affordance and by 30.5% in the success rate of downstream tasks.\nProject website: https://robo-point.github.io.",
      "tldr_zh": "本文提出RoboPoint，一种Vision-Language Model (VLM)，用于基于语言指令预测机器人的空间可供性（spatial affordance），以帮助机器人精确规划动作点，如物体重新排列或放置。研究开发了一个自动合成数据生成管道，对VLMs进行指令微调，规避了真实世界数据收集和人类演示的需求，从而提升了模型的可扩展性和适应性。RoboPoint支持下游应用包括机器人导航、操作和增强现实（AR）辅助，实验显示其在预测准确率上比最先进模型（如GPT-4o）和视觉提示技术（如PIVOT）高出21.8%，在任务成功率上高出30.5%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10721v1",
      "published_date": "2024-06-15 19:22:51 UTC",
      "updated_date": "2024-06-15 19:22:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:28:28.284042"
    },
    {
      "arxiv_id": "2406.10718v1",
      "title": "Stacking for Probabilistic Short-term Load Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Grzegorz Dudek"
      ],
      "abstract": "In this study, we delve into the realm of meta-learning to combine point base\nforecasts for probabilistic short-term electricity demand forecasting. Our\napproach encompasses the utilization of quantile linear regression, quantile\nregression forest, and post-processing techniques involving residual simulation\nto generate quantile forecasts. Furthermore, we introduce both global and local\nvariants of meta-learning. In the local-learning mode, the meta-model is\ntrained using patterns most similar to the query pattern.Through extensive\nexperimental studies across 35 forecasting scenarios and employing 16 base\nforecasting models, our findings underscored the superiority of quantile\nregression forest over its competitors",
      "tldr_zh": "本研究探讨了使用元学习（meta-learning）来结合点预测（point base forecasts）进行概率短期电力需求预测（probabilistic short-term load forecasting）。方法包括应用分位数线性回归（quantile linear regression）、分位数回归森林（quantile regression forest）以及涉及残差模拟的后续处理技术，并引入全局和本地meta-learning变体，其中本地学习模式通过使用与查询模式最相似的模式进行训练。实验在35个预测场景和16个基础模型上进行，结果显示quantile regression forest在性能上优于其他竞争模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "International Conference on Computational Science, ICCS'24",
      "pdf_url": "http://arxiv.org/pdf/2406.10718v1",
      "published_date": "2024-06-15 19:05:49 UTC",
      "updated_date": "2024-06-15 19:05:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:28:38.849710"
    },
    {
      "arxiv_id": "2406.10712v1",
      "title": "Object Detection using Oriented Window Learning Vi-sion Transformer: Roadway Assets Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Taqwa Alhadidi",
        "Ahmed Jaber",
        "Shadi Jaradat",
        "Huthaifa I Ashqar",
        "Mohammed Elhenawy"
      ],
      "abstract": "Object detection is a critical component of transportation systems,\nparticularly for applications such as autonomous driving, traffic monitoring,\nand infrastructure maintenance. Traditional object detection methods often\nstruggle with limited data and variability in object appearance. The Oriented\nWindow Learning Vision Transformer (OWL-ViT) offers a novel approach by\nadapting window orientations to the geometry and existence of objects, making\nit highly suitable for detecting diverse roadway assets. This study leverages\nOWL-ViT within a one-shot learning framework to recognize transportation\ninfrastructure components, such as traffic signs, poles, pavement, and cracks.\nThis study presents a novel method for roadway asset detection using OWL-ViT.\nWe conducted a series of experiments to evaluate the performance of the model\nin terms of detection consistency, semantic flexibility, visual context\nadaptability, resolution robustness, and impact of non-max suppression. The\nresults demonstrate the high efficiency and reliability of the OWL-ViT across\nvarious scenarios, underscoring its potential to enhance the safety and\nefficiency of intelligent transportation systems.",
      "tldr_zh": "本研究提出了一种基于 Oriented Window Learning Vision Transformer (OWL-ViT) 的对象检测方法，旨在识别道路资产，如交通标志、杆子、路面和裂缝，以提升交通系统的安全和效率。OWL-ViT 通过适应窗口方向来处理对象几何和变异性问题，并将其整合到 one-shot learning 框架中，实现高效的检测。实验评估了模型在检测一致性、语义灵活性、视觉上下文适应性、分辨率鲁棒性和 non-max suppression 影响等方面的性能，结果显示 OWL-ViT 在各种场景中表现出色，具有较高的可靠性和潜力，可显著增强智能交通系统的整体表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10712v1",
      "published_date": "2024-06-15 18:49:42 UTC",
      "updated_date": "2024-06-15 18:49:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:28:50.066881"
    },
    {
      "arxiv_id": "2406.10710v2",
      "title": "SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task",
      "title_zh": "翻译失败",
      "authors": [
        "Ziije Zhong",
        "Linqing Zhong",
        "Zhaoze Sun",
        "Qingyun Jin",
        "Zengchang Qin",
        "Xiaofan Zhang"
      ],
      "abstract": "Integrating Large Language Models (LLMs) with existing Knowledge Graph (KG)\ndatabases presents a promising avenue for enhancing LLMs' efficacy and\nmitigating their \"hallucinations\". Given that most KGs reside in graph\ndatabases accessible solely through specialized query languages (e.g., Cypher),\nit is critical to connect LLMs with KG databases by automating the translation\nof natural language into Cypher queries (termed as \"Text2Cypher\" task). Prior\nefforts tried to bolster LLMs' proficiency in Cypher generation through\nSupervised Fine-Tuning (SFT). However, these explorations are hindered by the\nlack of annotated datasets of Query-Cypher pairs, resulting from the\nlabor-intensive and domain-specific nature of such annotation. In this study,\nwe propose SyntheT2C, a methodology for constructing a synthetic Query-Cypher\npair dataset, comprising two distinct pipelines: (1) LLM-based prompting and\n(2) template-filling. SyntheT2C is applied to two medical KG databases,\nculminating in the creation of a synthetic dataset, MedT2C. Comprehensive\nexperiments demonstrate that the MedT2C dataset effectively enhances the\nperformance of backbone LLMs on Text2Cypher task via SFT. Both the SyntheT2C\ncodebase and the MedT2C dataset are released in\nhttps://github.com/ZGChung/SyntheT2C.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 与知识图谱 (KG) 数据库整合的挑战，提出 SyntheT2C 方法，以生成合成数据集用于 Text2Cypher 任务，即将自然语言翻译成 Cypher 查询。SyntheT2C 包括 LLM-based prompting 和 template-filling 两种管道，应用于两个医疗 KG 数据库，成功创建了 MedT2C 数据集，以解决标注数据稀缺的问题。实验结果显示，通过 Supervised Fine-Tuning (SFT)，MedT2C 显著提升了 LLMs 在 Text2Cypher 任务上的性能，且相关代码和数据集已开源。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "COLING 2025 paper. 21 pages, 15 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.10710v2",
      "published_date": "2024-06-15 18:43:49 UTC",
      "updated_date": "2025-01-26 07:15:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:29:05.639878"
    },
    {
      "arxiv_id": "2406.15473v2",
      "title": "Intertwining CP and NLP: The Generation of Unreasonably Constrained Sentences",
      "title_zh": "CP 与 NLP 的交织：不合理约束句子的生成",
      "authors": [
        "Alexandre Bonlarron",
        "Jean-Charles Régin"
      ],
      "abstract": "Constrained text generation remains a challenging task, particularly when\ndealing with hard constraints. Traditional NLP approaches prioritize generating\nmeaningful and coherent output. Also, the current state-of-the-art methods\noften lack the expressiveness and constraint satisfaction capabilities to\nhandle such tasks effectively. Recently, an approach for generating constrained\nsentences in CP has been proposed in (Bonlarron et al, 2023). This ad-hoc model\nto solve the sentences generation problem under MNREAD rules proved\nneithertheless to be computationaly and structuraly unsuitable to deal with\nother more constrained problems. In this paper, a novel more generic approach\nis introduced to tackle many of these previously untractable problems, and\nillustrated here with the quite untractable sentences generation problem\nfollowing RADNER rules.\n  More precisely, this paper presents the CPTextGen Framework. This framework\nconsiders a constrained text generation problem as a discrete combinatorial\noptimization problem. It is solved by a constraint programming method that\ncombines linguistic properties (e.g., n-grams or language level) with other\nmore classical constraints (e.g., the number of characters, syllables).\nEventually, a curation phase allows for selecting the best-generated sentences\naccording to perplexity using an LLM.\n  The effectiveness of this approach is demonstrated by tackling a new, more\ntediously constrained text generation problem: the iconic RADNER sentences\nproblem. This problem aims to generate sentences respecting a set of quite\nstrict rules defined by their use in vision and clinical research. Thanks to\nour CP-based approach, many new strongly constrained sentences have been\nsuccessfully generated. This highlights our approach's potential to handle\nunreasonably constrained text generation scenarios.",
      "tldr_zh": "该论文探讨了受限文本生成的挑战，指出传统 NLP 方法难以处理硬约束，并引入 CPTextGen 框架，将其视为离散组合优化问题，通过约束编程结合语言属性（如 n-grams）和传统约束（如字符数、音节数）来生成符合规则的句子。框架还包括一个基于 LLM 的校正阶段，使用 perplexity 选择最佳输出。该方法在处理高度受限的 RADNER 规则句子生成问题上表现出色，成功生成了许多新句子，证明了其在“不可理喻”约束场景中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Disambiguation and additional references",
      "pdf_url": "http://arxiv.org/pdf/2406.15473v2",
      "published_date": "2024-06-15 17:40:49 UTC",
      "updated_date": "2024-12-27 14:56:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:29:16.188716"
    },
    {
      "arxiv_id": "2406.10690v3",
      "title": "Automating Pharmacovigilance Evidence Generation: Using Large Language Models to Produce Context-Aware SQL",
      "title_zh": "翻译失败",
      "authors": [
        "Jeffery L. Painter",
        "Venkateswara Rao Chalamalasetti",
        "Raymond Kassekert",
        "Andrew Bate"
      ],
      "abstract": "Objective: To enhance the efficiency and accuracy of information retrieval\nfrom pharmacovigilance (PV) databases by employing Large Language Models (LLMs)\nto convert natural language queries (NLQs) into Structured Query Language (SQL)\nqueries, leveraging a business context document.\n  Materials and Methods: We utilized OpenAI's GPT-4 model within a\nretrieval-augmented generation (RAG) framework, enriched with a business\ncontext document, to transform NLQs into syntactically precise SQL queries.\nEach NLQ was presented to the LLM randomly and independently to prevent\nmemorization. The study was conducted in three phases, varying query\ncomplexity, and assessing the LLM's performance both with and without the\nbusiness context document.\n  Results: Our approach significantly improved NLQ-to-SQL accuracy, increasing\nfrom 8.3\\% with the database schema alone to 78.3\\% with the business context\ndocument. This enhancement was consistent across low, medium, and high\ncomplexity queries, indicating the critical role of contextual knowledge in\nquery generation.\n  Discussion: The integration of a business context document markedly improved\nthe LLM's ability to generate accurate and contextually relevant SQL queries.\nPerformance achieved a maximum of 85\\% when high complexity queries are\nexcluded, suggesting promise for routine deployment.\n  Conclusion: This study presents a novel approach to employing LLMs for safety\ndata retrieval and analysis, demonstrating significant advancements in query\ngeneration accuracy. The methodology offers a framework applicable to various\ndata-intensive domains, enhancing the accessibility and efficiency of\ninformation retrieval for non-technical users.",
      "tldr_zh": "本研究旨在通过大型语言模型 (LLMs) 自动将自然语言查询 (NLQs) 转换为上下文相关的 Structured Query Language (SQL) 查询，从而提升药物流行病学 (PV) 数据库的信息检索效率和准确性。研究采用 OpenAI 的 GPT-4 模型结合检索增强生成 (RAG) 框架和业务上下文文档，对不同复杂度的查询进行转换，并通过三个实验阶段评估模型性能。结果显示，添加业务上下文文档后，NLQ 到 SQL 的准确率从 8.3% 显著提高到 78.3%，并在低、中、高复杂性查询中保持一致改进。该方法为非技术用户提供了一个高效框架，适用于各种数据密集型领域，推进了安全数据检索和分析的自动化。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "H.3.3; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 3 tables, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.10690v3",
      "published_date": "2024-06-15 17:07:31 UTC",
      "updated_date": "2024-09-04 16:58:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:29:30.478819"
    },
    {
      "arxiv_id": "2406.10686v2",
      "title": "Graph Neural Thompson Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Shuang Wu",
        "Arash A. Amini"
      ],
      "abstract": "We consider an online decision-making problem with a reward function defined\nover graph-structured data. We formally formulate the problem as an instance of\ngraph action bandit. We then propose \\texttt{GNN-TS}, a Graph Neural Network\n(GNN) powered Thompson Sampling (TS) algorithm which employs a GNN approximator\nfor estimating the mean reward function and the graph neural tangent features\nfor uncertainty estimation. We prove that, under certain boundness assumptions\non the reward function, GNN-TS achieves a state-of-the-art regret bound which\nis (1) sub-linear of order $\\tilde{\\mathcal{O}}((\\tilde{d} T)^{1/2})$ in the\nnumber of interaction rounds, $T$, and a notion of effective dimension\n$\\tilde{d}$, and (2) independent of the number of graph nodes. Empirical\nresults validate that our proposed \\texttt{GNN-TS} exhibits competitive\nperformance and scales well on graph action bandit problems.",
      "tldr_zh": "该研究针对基于图结构数据的在线决策问题，将其形式化为图行动 Bandit 问题，并提出 GNN-TS 算法，该算法利用 Graph Neural Network (GNN) 来估计奖励函数的均值，并通过图神经切线特征进行不确定性估计。GNN-TS 在特定边界假设下实现了先进的遗憾界（regret bound），即 $\\tilde{\\mathcal{O}}((\\tilde{d} T)^{1/2}$，其中 T 为交互轮数、$\\tilde{d}$ 为有效维度，且该界独立于图节点数量。实验结果显示，GNN-TS 在图行动 Bandit 问题上表现出色，具有竞争性和良好的可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10686v2",
      "published_date": "2024-06-15 16:45:27 UTC",
      "updated_date": "2024-06-20 20:22:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:29:39.775740"
    },
    {
      "arxiv_id": "2406.11903v1",
      "title": "A Survey of Large Language Models for Financial Applications: Progress, Prospects and Challenges",
      "title_zh": "大语言模型在金融应用中的综述：进展、前景和挑战",
      "authors": [
        "Yuqi Nie",
        "Yaxuan Kong",
        "Xiaowen Dong",
        "John M. Mulvey",
        "H. Vincent Poor",
        "Qingsong Wen",
        "Stefan Zohren"
      ],
      "abstract": "Recent advances in large language models (LLMs) have unlocked novel\nopportunities for machine learning applications in the financial domain. These\nmodels have demonstrated remarkable capabilities in understanding context,\nprocessing vast amounts of data, and generating human-preferred contents. In\nthis survey, we explore the application of LLMs on various financial tasks,\nfocusing on their potential to transform traditional practices and drive\ninnovation. We provide a discussion of the progress and advantages of LLMs in\nfinancial contexts, analyzing their advanced technologies as well as\nprospective capabilities in contextual understanding, transfer learning\nflexibility, complex emotion detection, etc. We then highlight this survey for\ncategorizing the existing literature into key application areas, including\nlinguistic tasks, sentiment analysis, financial time series, financial\nreasoning, agent-based modeling, and other applications. For each application\narea, we delve into specific methodologies, such as textual analysis,\nknowledge-based analysis, forecasting, data augmentation, planning, decision\nsupport, and simulations. Furthermore, a comprehensive collection of datasets,\nmodel assets, and useful codes associated with mainstream applications are\npresented as resources for the researchers and practitioners. Finally, we\noutline the challenges and opportunities for future research, particularly\nemphasizing a number of distinctive aspects in this field. We hope our work can\nhelp facilitate the adoption and further development of LLMs in the financial\nsector.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型 (LLMs) 在金融领域的应用进展、潜力与挑战，强调了 LLMs 在上下文理解、数据处理和内容生成方面的优势。论文将现有文献分类为关键应用领域，包括语言任务、情感分析、金融时间序列分析、金融推理、基于代理的建模及其他应用，并详细分析了具体方法如文本分析、预测和决策支持。作者还提供了全面的资源集合，包括数据集、模型资产和代码，以支持研究者实践，同时指出了未来挑战，如模型适应性和伦理问题。",
      "categories": [
        "q-fin.GN",
        "cs.AI",
        "q-fin.CP"
      ],
      "primary_category": "q-fin.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11903v1",
      "published_date": "2024-06-15 16:11:35 UTC",
      "updated_date": "2024-06-15 16:11:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:29:52.331545"
    },
    {
      "arxiv_id": "2406.15472v1",
      "title": "Hyperbolic sentence representations for solving Textual Entailment",
      "title_zh": "翻译失败",
      "authors": [
        "Igor Petrovski"
      ],
      "abstract": "Hyperbolic spaces have proven to be suitable for modeling data of\nhierarchical nature. As such we use the Poincare ball to embed sentences with\nthe goal of proving how hyperbolic spaces can be used for solving Textual\nEntailment. To this end, apart from the standard datasets used for evaluating\ntextual entailment, we developed two additional datasets. We evaluate against\nbaselines of various backgrounds, including LSTMs, Order Embeddings and\nEuclidean Averaging, which comes as a natural counterpart to representing\nsentences into the Euclidean space. We consistently outperform the baselines on\nthe SICK dataset and are second only to Order Embeddings on the SNLI dataset,\nfor the binary classification version of the entailment task.",
      "tldr_zh": "这篇论文提出使用 Hyperbolic spaces 中的 Poincare ball 来嵌入句子，从而解决 Textual Entailment 问题，利用其适合层次性数据的特性。研究团队除了标准数据集外，还开发了两个额外的数据集，并与 LSTMs、Order Embeddings 和 Euclidean Averaging 等基线模型进行比较。结果显示，该方法在 SICK 数据集上 consistently outperform 基线模型，而在 SNLI 数据集的二元分类版本上，仅次于 Order Embeddings。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15472v1",
      "published_date": "2024-06-15 15:39:43 UTC",
      "updated_date": "2024-06-15 15:39:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:30:03.764280"
    },
    {
      "arxiv_id": "2406.10670v3",
      "title": "CoLoR-Filter: Conditional Loss Reduction Filtering for Targeted Language Model Pre-training",
      "title_zh": "翻译失败",
      "authors": [
        "David Brandfonbrener",
        "Hanlin Zhang",
        "Andreas Kirsch",
        "Jonathan Richard Schwarz",
        "Sham Kakade"
      ],
      "abstract": "Selecting high-quality data for pre-training is crucial in shaping the\ndownstream task performance of language models. A major challenge lies in\nidentifying this optimal subset, a problem generally considered intractable,\nthus necessitating scalable and effective heuristics. In this work, we propose\na data selection method, CoLoR-Filter (Conditional Loss Reduction Filtering),\nwhich leverages an empirical Bayes-inspired approach to derive a simple and\ncomputationally efficient selection criterion based on the relative loss values\nof two auxiliary models.\n  In addition to the modeling rationale, we evaluate CoLoR-Filter empirically\non two language modeling tasks: (1) selecting data from C4 for domain\nadaptation to evaluation on Books and (2) selecting data from C4 for a suite of\ndownstream multiple-choice question answering tasks. We demonstrate favorable\nscaling both as we subselect more aggressively and using small auxiliary models\nto select data for large target models. As one headline result, CoLoR-Filter\ndata selected using a pair of 150m parameter auxiliary models can train a 1.2b\nparameter target model to match a 1.2b parameter model trained on 25b randomly\nselected tokens with 25x less data for Books and 11x less data for the\ndownstream tasks.\n  Code: https://github.com/davidbrandfonbrener/color-filter-olmo\n  Filtered data:\nhttps://huggingface.co/datasets/davidbrandfonbrener/color-filtered-c4",
      "tldr_zh": "这篇论文提出了 CoLoR-Filter，一种基于 Conditional Loss Reduction Filtering 的数据选择方法，用于针对语言模型预训练的关键问题——选择高质量数据以优化下游任务性能。该方法采用经验贝叶斯方法，通过两个辅助模型的相对损失值，衍生出一个简单且计算高效的选择标准。实验评估显示，在从 C4 数据集选择数据用于书籍领域适应和下游多选题回答任务时，CoLoR-Filter 能显著减少数据量，例如使用 150m 参数辅助模型选择的数据，仅需 25x 更少的训练数据即可训练出与随机选择相当的 1.2b 参数目标模型。总的来说，该方法展示了高效数据选择的潜力，提高了语言模型的训练效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10670v3",
      "published_date": "2024-06-15 15:28:02 UTC",
      "updated_date": "2024-10-29 20:26:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:30:18.948611"
    },
    {
      "arxiv_id": "2406.10661v2",
      "title": "A GPU-accelerated Large-scale Simulator for Transportation System Optimization Benchmarking",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Zhang",
        "Wenxuan Ao",
        "Junbo Yan",
        "Depeng Jin",
        "Yong Li"
      ],
      "abstract": "With the development of artificial intelligence techniques, transportation\nsystem optimization is evolving from traditional methods relying on expert\nexperience to simulation and learning-based decision and optimization methods.\nLearning-based optimization methods require extensive interactions with highly\nrealistic microscopic traffic simulators. However, existing microscopic traffic\nsimulators are inefficient in large-scale scenarios and thus fail to support\nthe adoption of these methods in large-scale transportation system optimization\nscenarios. In addition, the optimization scenarios supported by existing\nsimulators are limited, mainly focusing on the traffic signal control. To\naddress these challenges, we propose the first open-source GPU-accelerated\nlarge-scale microscopic simulator for transportation system simulation and\noptimization. The simulator can iterate at 84.09Hz, which achieves 88.92 times\ncomputational acceleration in the large-scale scenario with 2,464,950 vehicles\ncompared to the best baseline CityFlow. Besides, it achieves a more realistic\naverage road speeds simulated on real datasets by adopting the IDM model as the\ncar-following model and the randomized MOBIL model as the lane-changing model.\nBased on it, we implement a set of microscopic and macroscopic controllable\nobjects and metrics provided by Python API to support typical transportation\nsystem optimization scenarios. We choose five representative scenarios and\nbenchmark classical rule-based algorithms, reinforcement learning algorithms,\nand black-box optimization algorithms in four cities. These experiments\neffectively demonstrate the usability of the simulator for large-scale traffic\nsystem optimization. The code of the simulator is available at\nhttps://github.com/tsinghua-fib-lab/moss. We build an open-registration web\nplatform available at https://moss.fiblab.net to support no-code trials.",
      "tldr_zh": "该论文提出一个开源的 GPU-accelerated 大规模微观交通模拟器，用于交通系统优化基准测试，以解决现有模拟器在大型场景下效率低下和场景局限的问题。模拟器采用 IDM 模型作为跟车模型和 randomized MOBIL 模型作为换道模型，实现更真实的交通模拟，并在包含 2,464,950 辆车的场景下比基线 CityFlow 快 88.92 倍，迭代频率达 84.09Hz。通过 Python API 提供微观和宏观可控对象及指标，支持典型优化场景，如交通信号控制。论文在四个城市的五个代表性场景中基准测试了规则-based 算法、reinforcement learning 算法和黑箱优化算法，验证了模拟器在大型交通系统优化中的有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2406.10661v2",
      "published_date": "2024-06-15 14:58:17 UTC",
      "updated_date": "2024-10-02 06:43:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:30:31.716053"
    },
    {
      "arxiv_id": "2406.10653v1",
      "title": "Justice in Healthcare Artificial Intelligence in Africa",
      "title_zh": "翻译失败",
      "authors": [
        "Aloysius Ochasi",
        "Abdoul Jalil Djiberou Mahamadou",
        "Russ B. Altman"
      ],
      "abstract": "There is an ongoing debate on balancing the benefits and risks of artificial\nintelligence (AI) as AI is becoming critical to improving healthcare delivery\nand patient outcomes. Such improvements are essential in resource-constrained\nsettings where millions lack access to adequate healthcare services, such as in\nAfrica. AI in such a context can potentially improve the effectiveness,\nefficiency, and accessibility of healthcare services. Nevertheless, the\ndevelopment and use of AI-driven healthcare systems raise numerous ethical,\nlegal, and socio-economic issues. Justice is a major concern in AI that has\nimplications for amplifying social inequities. This paper discusses these\nimplications and related justice concepts such as solidarity, Common Good,\nsustainability, AI bias, and fairness. For Africa to effectively benefit from\nAI, these principles should align with the local context while balancing the\nrisks. Compared to mainstream ethical debates on justice, this perspective\noffers context-specific considerations for equitable healthcare AI development\nin Africa.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在非洲医疗领域的正义问题，强调AI在改善资源有限地区的医疗效果、效率和可及性的潜力，同时指出其可能放大社会不平等的伦理、法律和社会经济风险。论文分析了相关正义概念，包括solidarity（团结）、Common Good（共同利益）、sustainability（可持续性）、AI bias（AI 偏见）和fairness（公平性），并强调这些原则需与非洲本地语境相结合。最终，该研究为非洲的医疗AI发展提供上下文特定的考虑，以实现更公平的AI应用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.CY",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.10653v1",
      "published_date": "2024-06-15 14:47:03 UTC",
      "updated_date": "2024-06-15 14:47:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:30:38.141308"
    },
    {
      "arxiv_id": "2406.15471v1",
      "title": "Improving Large Models with Small models: Lower Costs and Better Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Chen",
        "Shuo Zhang",
        "Yueting Zhuang",
        "Siliang Tang",
        "Qidong Liu",
        "Hua Wang",
        "Mingliang Xu"
      ],
      "abstract": "Pretrained large models (PLMs), such as ChatGPT, have demonstrated remarkable\nperformance across diverse tasks. However, the significant computational\nrequirements of PLMs have discouraged most product teams from running or\nfine-tuning them. In such cases, to harness the exceptional performance of\nPLMs, one must rely on expensive APIs, thereby exacerbating the economic\nburden. Despite the overall inferior performance of small models, in specific\ndistributions, they can achieve comparable or even superior results.\nConsequently, some input can be processed exclusively by small models. On the\nother hand, certain tasks can be broken down into multiple subtasks, some of\nwhich can be completed without powerful capabilities. Under these\ncircumstances, small models can handle the simple subtasks, allowing large\nmodels to focus on challenging subtasks, thus improving the performance. We\npropose Data Shunt$^+$ (DS$^+$), a general paradigm for collaboration of small\nand large models. DS$^+$ not only substantially reduces the cost associated\nwith querying large models but also effectively improves large models'\nperformance. For instance, ChatGPT achieves an accuracy of $94.43\\%$ on Amazon\nProduct sentiment analysis, and DS$^+$ achieves an accuracy of $95.64\\%$, while\nthe cost has been reduced to only $31.18\\%$. Besides, experiments also prove\nthat the proposed collaborative-based paradigm can better inject specific task\nknowledge into PLMs compared to fine-tuning.",
      "tldr_zh": "该论文探讨了如何利用小模型提升预训练大模型（PLMs）如 ChatGPT 的性能，同时降低成本。作者提出 Data Shunt+ (DS+) 范式，让小模型处理简单子任务或特定分布输入，大模型专注于复杂子任务，从而实现协作优化。实验结果显示，在 Amazon 产品情感分析任务上，DS+ 将 ChatGPT 的准确率从 94.43% 提高到 95.64%，并将成本降至原先的 31.18%；此外，这种协作方法比直接微调更有效地注入特定任务知识。整体而言，DS+ 提供了一个通用框架，帮助产品团队在资源有限的情况下提升模型表现和经济效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.15471v1",
      "published_date": "2024-06-15 14:44:43 UTC",
      "updated_date": "2024-06-15 14:44:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:30:52.084098"
    },
    {
      "arxiv_id": "2406.10632v1",
      "title": "Applications of Generative AI in Healthcare: algorithmic, ethical, legal and societal considerations",
      "title_zh": "翻译失败",
      "authors": [
        "Onyekachukwu R. Okonji",
        "Kamol Yunusov",
        "Bonnie Gordon"
      ],
      "abstract": "Generative AI is rapidly transforming medical imaging and text analysis,\noffering immense potential for enhanced diagnosis and personalized care.\nHowever, this transformative technology raises crucial ethical, societal, and\nlegal questions. This paper delves into these complexities, examining issues of\naccuracy, informed consent, data privacy, and algorithmic limitations in the\ncontext of generative AI's application to medical imaging and text. We explore\nthe legal landscape surrounding liability and accountability, emphasizing the\nneed for robust regulatory frameworks. Furthermore, we dissect the algorithmic\nchallenges, including data biases, model limitations, and workflow integration.\nBy critically analyzing these challenges and proposing responsible solutions,\nwe aim to foster a roadmap for ethical and responsible implementation of\ngenerative AI in healthcare, ensuring its transformative potential serves\nhumanity with utmost care and precision.",
      "tldr_zh": "Generative AI 在医疗领域的应用正迅速改变医疗成像和文本分析，提升诊断准确性和个性化护理，但也引发了诸多 ethical、legal 和 societal 问题，如准确性、informed consent、数据隐私以及算法限制。论文深入探讨这些挑战，包括法律责任和问责制框架的必要性，以及算法方面的数据 biases、模型 limitations 和工作流程整合问题。通过批判性分析并提出负责任的解决方案，本文为 Generative AI 在医疗中的伦理实施提供了一个可行的路线图，确保其潜力以谨慎方式服务人类。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10632v1",
      "published_date": "2024-06-15 13:28:07 UTC",
      "updated_date": "2024-06-15 13:28:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:31:05.728715"
    },
    {
      "arxiv_id": "2406.10630v1",
      "title": "Emerging Safety Attack and Defense in Federated Instruction Tuning of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Ye",
        "Jingyi Chai",
        "Xiangrui Liu",
        "Yaodong Yang",
        "Yanfeng Wang",
        "Siheng Chen"
      ],
      "abstract": "Federated learning (FL) enables multiple parties to collaboratively fine-tune\nan large language model (LLM) without the need of direct data sharing. Ideally,\nby training on decentralized data that is aligned with human preferences and\nsafety principles, federated instruction tuning can result in an LLM that could\nbehave in a helpful and safe manner. In this paper, we for the first time\nreveal the vulnerability of safety alignment in FedIT by proposing a simple,\nstealthy, yet effective safety attack method. Specifically, the malicious\nclients could automatically generate attack data without involving manual\nefforts and attack the FedIT system by training their local LLMs on such attack\ndata. Unfortunately, this proposed safety attack not only can compromise the\nsafety alignment of LLM trained via FedIT, but also can not be effectively\ndefended against by many existing FL defense methods. Targeting this, we\nfurther propose a post-hoc defense method, which could rely on a fully\nautomated pipeline: generation of defense data and further fine-tuning of the\nLLM. Extensive experiments show that our safety attack method can significantly\ncompromise the LLM's safety alignment (e.g., reduce safety rate by 70\\%), which\ncan not be effectively defended by existing defense methods (at most 4\\%\nabsolute improvement), while our safety defense method can significantly\nenhance the attacked LLM's safety alignment (at most 69\\% absolute\nimprovement).",
      "tldr_zh": "本研究首次揭示了在Federated Instruction Tuning (FedIT)中大型语言模型(LLM)的安全对齐漏洞，提出了一种简单隐秘的安全攻击方法，其中恶意客户端通过自动生成攻击数据并在本地训练LLM来破坏模型的安全性。实验显示，这种攻击能显著降低LLM的安全率（例如减少70%），且现有Federated Learning (FL)防御方法效果有限（最多仅4%的绝对改善）。针对此，论文提出了一种后处理防御方法，利用自动生成防御数据并进一步微调LLM，从而显著提升受攻击模型的安全对齐（最多69%的绝对改善），为FedIT的安全性提供了新方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.10630v1",
      "published_date": "2024-06-15 13:24:22 UTC",
      "updated_date": "2024-06-15 13:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:31:18.365578"
    },
    {
      "arxiv_id": "2406.12929v1",
      "title": "RMF: A Risk Measurement Framework for Machine Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Schröder",
        "Jakub Breier"
      ],
      "abstract": "Machine learning (ML) models are used in many safety- and security-critical\napplications nowadays. It is therefore important to measure the security of a\nsystem that uses ML as a component. This paper focuses on the field of ML,\nparticularly the security of autonomous vehicles. For this purpose, a technical\nframework will be described, implemented, and evaluated in a case study. Based\non ISO/IEC 27004:2016, risk indicators are utilized to measure and evaluate the\nextent of damage and the effort required by an attacker. It is not possible,\nhowever, to determine a single risk value that represents the attacker's\neffort. Therefore, four different values must be interpreted individually.",
      "tldr_zh": "该论文提出RMF（Risk Measurement Framework），一个用于评估机器学习（ML）模型风险的框架，特别针对安全和安全关键应用如自主车辆。框架基于ISO/IEC 27004:2016标准，利用风险指标来量化损害程度和攻击者所需努力，通过描述、实施和案例研究进行验证。研究发现，无法得出单一风险值，因此需要 individually 解释四个不同的值，以提升ML系统安全性评估的准确性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at CSA@ARES 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12929v1",
      "published_date": "2024-06-15 13:22:47 UTC",
      "updated_date": "2024-06-15 13:22:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:31:29.046873"
    },
    {
      "arxiv_id": "2406.10628v1",
      "title": "Public Computer Vision Datasets for Precision Livestock Farming: A Systematic Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Anil Bhujel",
        "Yibin Wang",
        "Yuzhen Lu",
        "Daniel Morris",
        "Mukesh Dangol"
      ],
      "abstract": "Technology-driven precision livestock farming (PLF) empowers practitioners to\nmonitor and analyze animal growth and health conditions for improved\nproductivity and welfare. Computer vision (CV) is indispensable in PLF by using\ncameras and computer algorithms to supplement or supersede manual efforts for\nlivestock data acquisition. Data availability is crucial for developing\ninnovative monitoring and analysis systems through artificial\nintelligence-based techniques. However, data curation processes are tedious,\ntime-consuming, and resource intensive. This study presents the first\nsystematic survey of publicly available livestock CV datasets\n(https://github.com/Anil-Bhujel/Public-Computer-Vision-Dataset-A-Systematic-Survey).\nAmong 58 public datasets identified and analyzed, encompassing different\nspecies of livestock, almost half of them are for cattle, followed by swine,\npoultry, and other animals. Individual animal detection and color imaging are\nthe dominant application and imaging modality for livestock. The\ncharacteristics and baseline applications of the datasets are discussed,\nemphasizing the implications for animal welfare advocates. Challenges and\nopportunities are also discussed to inspire further efforts in developing\nlivestock CV datasets. This study highlights that the limited quantity of\nhigh-quality annotated datasets collected from diverse environments, animals,\nand applications, the absence of contextual metadata, are a real bottleneck in\nPLF.",
      "tldr_zh": "本研究对公开的计算机视觉(CV)数据集在精确畜牧业(PLF)中的应用进行了首次系统调查，识别并分析了58个涵盖牛、猪、家禽等牲畜物种的数据集，其中牛类数据集占比近半，主要聚焦于个体动物检测和彩色成像。调查讨论了这些数据集的特征、基线应用及其对动物福利的启示，强调高质量标注数据、环境多样性和上下文元数据的缺失是PLF发展的主要瓶颈。未来挑战包括提升数据集数量和质量，以推动创新监控系统的开发。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10628v1",
      "published_date": "2024-06-15 13:22:41 UTC",
      "updated_date": "2024-06-15 13:22:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:31:42.472456"
    },
    {
      "arxiv_id": "2406.10621v3",
      "title": "StrucText-Eval: Evaluating Large Language Model's Reasoning Ability in Structure-Rich Text",
      "title_zh": "StrucText-Eval：评估大型语言模型在结构丰富文本中的推理能力",
      "authors": [
        "Zhouhong Gu",
        "Haoning Ye",
        "Xingzhou Chen",
        "Zeyang Zhou",
        "Hongwei Feng",
        "Yanghua Xiao"
      ],
      "abstract": "The effective utilization of structured data, integral to corporate data\nstrategies, has been challenged by the rise of large language models (LLMs)\ncapable of processing unstructured information. This shift prompts the\nquestion: can LLMs interpret structured data directly in its unstructured form?\nWe propose an automatic evaluation data generation method for assessing LLMs'\nreasoning capabilities on structure-rich text to explore this. Our approach\nsupports 8 structured languages and 29 tasks, generating data with adjustable\ncomplexity through controllable nesting and structural width. We introduce\nStrucText-Eval, a benchmark containing 5,800 pre-generated and annotated\nsamples designed to evaluate how well LLMs understand and reason through\nstructured text. StrucText-Eval is divided into two suites: a regular Test\nsuite (3,712 samples) and a Test-Hard suite (2,088 samples), the latter\nemphasizing the gap between human and model performance on more complex tasks.\nExperimental results show that while open-source LLMs achieve a maximum\naccuracy of 74.9\\% on the standard dataset, their performance drops\nsignificantly to 45.8\\% on the harder dataset. In contrast, human participants\nreach an accuracy of 92.6\\% on StrucText-Eval-Hard, highlighting LLMs' current\nlimitations in handling intricate structural information. The benchmark and\ngeneration codes are open sourced in\n\\url{https://github.com/MikeGu721/StrucText-Eval}",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 在处理结构丰富文本时的推理能力，提出了一种自动评估数据生成方法，支持8种结构化语言和29个任务，通过可控嵌套和结构宽度调整数据复杂度。研究引入StrucText-Eval基准数据集，包含5,800个标注样本，分成常规测试套件（3,712样本）和困难测试套件（2,088样本），用于评估LLMs理解和推理结构文本的性能。实验结果显示，开源LLMs在标准数据集上最高准确率达74.9%，但在困难数据集上降至45.8%，而人类准确率高达92.6%，突显LLMs在复杂结构信息处理上的局限性；相关基准和代码已在GitHub开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10621v3",
      "published_date": "2024-06-15 12:48:00 UTC",
      "updated_date": "2024-10-21 11:06:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:31:55.962881"
    },
    {
      "arxiv_id": "2407.12004v1",
      "title": "An investigation into the scientific landscape of the conversational and generative artificial intelligence, and human-chatbot interaction in education and research",
      "title_zh": "翻译失败",
      "authors": [
        "Ikpe Justice Akpan",
        "Yawo M. Kobara",
        "Josiah Owolabi",
        "Asuama Akpam",
        "Onyebuchi Felix Offodile"
      ],
      "abstract": "Artificial intelligence (AI) as a disruptive technology is not new. However,\nits recent evolution, engineered by technological transformation, big data\nanalytics, and quantum computing, produces conversational and generative AI\n(CGAI/GenAI) and human-like chatbots that disrupt conventional operations and\nmethods in different fields. This study investigates the scientific landscape\nof CGAI and human-chatbot interaction/collaboration and evaluates use cases,\nbenefits, challenges, and policy implications for multidisciplinary education\nand allied industry operations. The publications trend showed that just 4%\n(n=75) occurred during 2006-2018, while 2019-2023 experienced astronomical\ngrowth (n=1763 or 96%). The prominent use cases of CGAI (e.g., ChatGPT) for\nteaching, learning, and research activities occurred in computer science\n[multidisciplinary and AI] (32%), medical/healthcare (17%), engineering (7%),\nand business fields (6%). The intellectual structure shows strong collaboration\namong eminent multidisciplinary sources in business, Information Systems, and\nother areas. The thematic structure of SLP highlights prominent CGAI use cases,\nincluding improved user experience in human-computer interaction, computer\nprograms/code generation, and systems creation. Widespread CGAI usefulness for\nteachers, researchers, and learners includes syllabi/course content generation,\ntesting aids, and academic writing. The concerns about abuse and misuse\n(plagiarism, academic integrity, privacy violations) and issues about\nmisinformation, danger of self-diagnoses, and patient privacy in\nmedical/healthcare applications are prominent. Formulating strategies and\npolicies to address potential CGAI challenges in teaching/learning and practice\nare priorities. Developing discipline-based automatic detection of GenAI\ncontents to check abuse is proposed.",
      "tldr_zh": "这篇论文调查了对话式和生成式人工智能（CGAI/GenAI）及其与人类聊天机器人互动在教育和研究领域的科学景观，评估了用例、益处、挑战及政策影响。研究发现，相关出版物从2006-2018年的4%急剧增长到2019-2023年的96%，主要应用在计算机科学（32%）、医疗/保健（17%）等领域，用于改善用户体验、代码生成和学术写作等方面。CGAI的益处包括辅助教学和研究，但也面临滥用风险如抄袭、学术诚信问题和隐私泄露；论文建议制定策略应对这些挑战，并开发基于学科的自动检测GenAI内容工具。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "14J60 (Primary) 14F05, 14J26 (Secondary), 68T05 (Primary) 68Q32,\n  97P80 (Secondary)",
        "I.2.6; K.3.2"
      ],
      "primary_category": "cs.CY",
      "comment": "The study analyzes the implications of AI adoption in education and\n  research and offer policy recommendations to overcome challenges; shows the\n  intellectual structure and collaboration among eminent sources contributing\n  AI discourse; highlights the use cases, benefits, and challenges of GenAI;\n  examines techniques for GenAI integration with modeling and decision support\n  systems, and existing gaps",
      "pdf_url": "http://arxiv.org/pdf/2407.12004v1",
      "published_date": "2024-06-15 12:37:29 UTC",
      "updated_date": "2024-06-15 12:37:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:32:07.657875"
    },
    {
      "arxiv_id": "2406.10615v2",
      "title": "Leveraging Locality to Boost Sample Efficiency in Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Tong Zhang",
        "Yingdong Hu",
        "Jiacheng You",
        "Yang Gao"
      ],
      "abstract": "Given the high cost of collecting robotic data in the real world, sample\nefficiency is a consistently compelling pursuit in robotics. In this paper, we\nintroduce SGRv2, an imitation learning framework that enhances sample\nefficiency through improved visual and action representations. Central to the\ndesign of SGRv2 is the incorporation of a critical inductive bias-action\nlocality, which posits that robot's actions are predominantly influenced by the\ntarget object and its interactions with the local environment. Extensive\nexperiments in both simulated and real-world settings demonstrate that action\nlocality is essential for boosting sample efficiency. SGRv2 excels in RLBench\ntasks with keyframe control using merely 5 demonstrations and surpasses the RVT\nbaseline in 23 of 26 tasks. Furthermore, when evaluated on ManiSkill2 and\nMimicGen using dense control, SGRv2's success rate is 2.54 times that of SGR.\nIn real-world environments, with only eight demonstrations, SGRv2 can perform a\nvariety of tasks at a markedly higher success rate compared to baseline models.\nProject website: http://sgrv2-robot.github.io",
      "tldr_zh": "这篇论文提出了 SGRv2，一个模仿学习框架，通过融入行动局部性(inductive bias-action locality)来提升机器人操作中的样本效率，该方法强调机器人的动作主要受目标物体和局部环境影响。SGRv2 通过改进视觉和动作表示，仅需少量演示（如 RLBench 中的 5 个关键帧演示），在 26 任务中超过 RVT 基线 23 个，并在 ManiSkill2 和 MimicGen 的密集控制任务中，成功率达到 SGR 的 2.54 倍。实验在模拟和真实环境中验证了其有效性，在真实世界任务中，仅用 8 个演示就显著提高了成功率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "CoRL 2024. Project website: http://sgrv2-robot.github.io",
      "pdf_url": "http://arxiv.org/pdf/2406.10615v2",
      "published_date": "2024-06-15 12:27:35 UTC",
      "updated_date": "2024-09-26 12:55:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:32:18.364959"
    },
    {
      "arxiv_id": "2406.12928v1",
      "title": "Evaluating the Generalization Ability of Quantized LLMs: Benchmark, Analysis, and Toolbox",
      "title_zh": "翻译失败",
      "authors": [
        "Yijun Liu",
        "Yuan Meng",
        "Fang Wu",
        "Shenhao Peng",
        "Hang Yao",
        "Chaoyu Guan",
        "Chen Tang",
        "Xinzhu Ma",
        "Zhi Wang",
        "Wenwu Zhu"
      ],
      "abstract": "Large language models (LLMs) have exhibited exciting progress in multiple\nscenarios, while the huge computational demands hinder their deployments in\nlots of real-world applications. As an effective means to reduce memory\nfootprint and inference cost, quantization also faces challenges in performance\ndegradation at low bit-widths. Understanding the impact of quantization on LLM\ncapabilities, especially the generalization ability, is crucial. However, the\ncommunity's main focus remains on the algorithms and models of quantization,\nwith insufficient attention given to whether the quantized models can retain\nthe strong generalization abilities of LLMs. In this work, we fill this gap by\nproviding a comprehensive benchmark suite for this research topic, including an\nevaluation system, detailed analyses, and a general toolbox. Specifically,\nbased on the dominant pipeline in LLM quantization, we primarily explore the\nimpact of calibration data distribution on the generalization of quantized LLMs\nand conduct the benchmark using more than 40 datasets within two main\nscenarios. Based on this benchmark, we conduct extensive experiments with two\nwell-known LLMs (English and Chinese) and four quantization algorithms to\ninvestigate this topic in-depth, yielding several counter-intuitive and\nvaluable findings, e.g., models quantized using a calibration set with the same\ndistribution as the test data are not necessarily optimal. Besides, to\nfacilitate future research, we also release a modular-designed toolbox, which\ndecouples the overall pipeline into several separate components, e.g., base LLM\nmodule, dataset module, quantizer module, etc. and allows subsequent\nresearchers to easily assemble their methods through a simple configuration.\nOur benchmark suite is publicly available at\nhttps://github.com/TsingmaoAI/MI-optimize",
      "tldr_zh": "这篇论文评估了量化大型语言模型 (LLMs) 对泛化能力的影響，强调量化虽能降低内存和推理成本，但低位宽可能导致性能下降。研究团队构建了一个全面基准测试套件，包括评估系统、详细分析和通用工具箱，重点探索校准数据分布对量化LLMs泛化能力的影响，并使用超过40个数据集进行实验。实验涉及两个知名LLMs（英文和中文）和四种量化算法，揭示了反直觉发现，例如，使用与测试数据相同分布的校准集并非总是最优。为便于后续研究，他们发布了模块化设计的开源工具箱（https://github.com/TsingmaoAI/MI-optimize）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12928v1",
      "published_date": "2024-06-15 12:02:14 UTC",
      "updated_date": "2024-06-15 12:02:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:32:31.189675"
    },
    {
      "arxiv_id": "2406.10593v2",
      "title": "QDA-SQL: Questions Enhanced Dialogue Augmentation for Multi-Turn Text-to-SQL",
      "title_zh": "翻译失败",
      "authors": [
        "Yinggang Sun",
        "Ziming Guo",
        "Haining Yu",
        "Chuanyi Liu",
        "Xiang Li",
        "Bingxuan Wang",
        "Xiangzhan Yu",
        "Tiancheng Zhao"
      ],
      "abstract": "Fine-tuning large language models (LLMs) for specific domain tasks has\nachieved great success in Text-to-SQL tasks. However, these fine-tuned models\noften face challenges with multi-turn Text-to-SQL tasks caused by ambiguous or\nunanswerable questions. It is desired to enhance LLMs to handle multiple types\nof questions in multi-turn Text-to-SQL tasks. To address this, we propose a\nnovel data augmentation method, called QDA-SQL, which generates multiple types\nof multi-turn Q\\&A pairs using LLMs. In QDA-SQL, we introduce a method\nincorporating validation and correction mechanisms to handle complex multi-turn\nText-to-SQL tasks. Experimental results demonstrate that QDA-SQL enables\nfine-tuned models to exhibit higher performance on SQL statement accuracy and\nenhances their ability to handle complex, unanswerable questions in multi-turn\nText-to-SQL tasks. The generation script and test set are released at\nhttps://github.com/mcxiaoxiao/QDA-SQL",
      "tldr_zh": "本文提出 QDA-SQL，一种通过增强对话数据来改善多轮 Text-to-SQL 任务的微调方法，旨在解决大型语言模型(LLMs)面对模糊或无法回答的问题时存在的挑战。QDA-SQL 利用 LLMs 生成多种类型(multi-turn Q&A pairs)，并引入验证和修正机制，以处理复杂查询。实验结果显示，该方法显著提高了模型的 SQL statement accuracy，并增强了其处理复杂和无法回答问题的能力；相关生成脚本和测试集已在 GitHub 上开源。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.10593v2",
      "published_date": "2024-06-15 10:54:54 UTC",
      "updated_date": "2024-11-10 13:45:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:32:42.776994"
    },
    {
      "arxiv_id": "2406.15470v2",
      "title": "Mental Disorder Classification via Temporal Representation of Text",
      "title_zh": "基于文本时间表示的精神障碍分类",
      "authors": [
        "Raja Kumar",
        "Kishan Maharaj",
        "Ashita Saxena",
        "Pushpak Bhattacharyya"
      ],
      "abstract": "Mental disorders pose a global challenge, aggravated by the shortage of\nqualified mental health professionals. Mental disorder prediction from social\nmedia posts by current LLMs is challenging due to the complexities of\nsequential text data and the limited context length of language models. Current\nlanguage model-based approaches split a single data instance into multiple\nchunks to compensate for limited context size. The predictive model is then\napplied to each chunk individually, and the most voted output is selected as\nthe final prediction. This results in the loss of inter-post dependencies and\nimportant time variant information, leading to poor performance. We propose a\nnovel framework which first compresses the large sequence of chronologically\nordered social media posts into a series of numbers. We then use this time\nvariant representation for mental disorder classification. We demonstrate the\ngeneralization capabilities of our framework by outperforming the current SOTA\nin three different mental conditions: depression, self-harm, and anorexia, with\nan absolute improvement of 5% in the F1 score. We investigate the situation\nwhere current data instances fall within the context length of language models\nand present empirical results highlighting the importance of temporal\nproperties of textual data. Furthermore, we utilize the proposed framework for\na cross-domain study, exploring commonalities across disorders and the\npossibility of inter-domain data usage.",
      "tldr_zh": "本研究针对心理障碍的分类问题，提出了一种基于文本时间表示的新框架，以克服当前LLMs在处理社交媒体帖子时的顺序数据复杂性和上下文长度限制。框架首先将按时间顺序的社交媒体帖子压缩成一系列数字序列，从而保留关键的时间变异信息，然后利用这些表示进行心理障碍预测。与现有方法相比，该框架在抑郁、自残和厌食症三个领域的SOTA模型上实现了F1分数绝对提升5%。此外，研究强调了文本数据时间属性的重要性，并通过跨领域分析探索了不同障碍的共性和数据共享潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "RK and KM contributed equally to this work, 15 pages, 5 figures, 9\n  table",
      "pdf_url": "http://arxiv.org/pdf/2406.15470v2",
      "published_date": "2024-06-15 10:53:21 UTC",
      "updated_date": "2024-10-06 06:27:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:32:54.251702"
    },
    {
      "arxiv_id": "2406.10591v1",
      "title": "MINT: a Multi-modal Image and Narrative Text Dubbing Dataset for Foley Audio Content Planning and Generation",
      "title_zh": "MINT：多模态图像和叙事文本配音数据集，用于 Foley 音频内容规划和生成",
      "authors": [
        "Ruibo Fu",
        "Shuchen Shi",
        "Hongming Guo",
        "Tao Wang",
        "Chunyu Qiang",
        "Zhengqi Wen",
        "Jianhua Tao",
        "Xin Qi",
        "Yi Lu",
        "Xiaopeng Wang",
        "Zhiyong Wang",
        "Yukun Liu",
        "Xuefei Liu",
        "Shuai Zhang",
        "Guanjun Li"
      ],
      "abstract": "Foley audio, critical for enhancing the immersive experience in multimedia\ncontent, faces significant challenges in the AI-generated content (AIGC)\nlandscape. Despite advancements in AIGC technologies for text and image\ngeneration, the foley audio dubbing remains rudimentary due to difficulties in\ncross-modal scene matching and content correlation. Current text-to-audio\ntechnology, which relies on detailed and acoustically relevant textual\ndescriptions, falls short in practical video dubbing applications. Existing\ndatasets like AudioSet, AudioCaps, Clotho, Sound-of-Story, and WavCaps do not\nfully meet the requirements for real-world foley audio dubbing task. To address\nthis, we introduce the Multi-modal Image and Narrative Text Dubbing Dataset\n(MINT), designed to enhance mainstream dubbing tasks such as literary story\naudiobooks dubbing, image/silent video dubbing. Besides, to address the\nlimitations of existing TTA technology in understanding and planning complex\nprompts, a Foley Audio Content Planning, Generation, and Alignment (CPGA)\nframework is proposed, which includes a content planning module leveraging\nlarge language models for complex multi-modal prompts comprehension.\nAdditionally, the training process is optimized using Proximal Policy\nOptimization based reinforcement learning, significantly improving the\nalignment and auditory realism of generated foley audio. Experimental results\ndemonstrate that our approach significantly advances the field of foley audio\ndubbing, providing robust solutions for the challenges of multi-modal dubbing.\nEven when utilizing the relatively lightweight GPT-2 model, our framework\noutperforms open-source multimodal large models such as LLaVA, DeepSeek-VL, and\nMoondream2. The dataset is available at https://github.com/borisfrb/MINT .",
      "tldr_zh": "本研究针对Foley audio在AI生成内容(AIGC)中的挑战，引入了Multi-modal Image and Narrative Text Dubbing Dataset (MINT)，这是一个专为文学故事有声书、图像/无声视频配音等任务设计的多模态数据集，以解决现有数据集（如AudioSet和AudioCaps）在跨模态场景匹配方面的不足。论文提出Foley Audio Content Planning, Generation, and Alignment (CPGA)框架，利用大型语言模型(LLMs)进行复杂多模态提示的理解和内容规划，并采用Proximal Policy Optimization (PPO)基于强化学习的训练过程，以提升生成音频的alignment和真实性。实验结果显示，该框架显著提高了Foley audio配音性能，即使使用轻量级模型如GPT-2，也优于开源多模态模型如LLaVA、DeepSeek-VL和Moondream2，数据集可从https://github.com/borisfrb/MINT获取。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CV",
        "cs.MM",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10591v1",
      "published_date": "2024-06-15 10:47:36 UTC",
      "updated_date": "2024-06-15 10:47:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:33:10.385284"
    },
    {
      "arxiv_id": "2406.10574v2",
      "title": "Large Language Models Playing Mixed Strategy Nash Equilibrium Games",
      "title_zh": "翻译失败",
      "authors": [
        "Alonso Silva"
      ],
      "abstract": "Generative artificial intelligence (Generative AI), and in particular Large\nLanguage Models (LLMs) have gained significant popularity among researchers and\nindustrial communities, paving the way for integrating LLMs in different\ndomains, such as robotics, telecom, and healthcare. In this paper, we study the\nintersection of game theory and generative artificial intelligence, focusing on\nthe capabilities of LLMs to find the Nash equilibrium in games with a mixed\nstrategy Nash equilibrium and no pure strategy Nash equilibrium (that we denote\nmixed strategy Nash equilibrium games). The study reveals a significant\nenhancement in the performance of LLMs when they are equipped with the\npossibility to run code and are provided with a specific prompt to incentivize\nthem to do so. However, our research also highlights the limitations of LLMs\nwhen the randomization strategy of the game is not easy to deduce. It is\nevident that while LLMs exhibit remarkable proficiency in well-known standard\ngames, their performance dwindles when faced with slight modifications of the\nsame games. This paper aims to contribute to the growing body of knowledge on\nthe intersection of game theory and generative artificial intelligence while\nproviding valuable insights into LLMs strengths and weaknesses. It also\nunderscores the need for further research to overcome the limitations of LLMs,\nparticularly in dealing with even slightly more complex scenarios, to harness\ntheir full potential.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs) 在混合策略Nash Equilibrium游戏中的表现，这些游戏缺乏纯策略均衡，仅依赖混合策略。研究发现，通过允许LLMs运行代码并使用特定提示，可以显著提升其性能，但当游戏的随机化策略不易推导时，LLMs的表现会明显下降，尤其在标准游戏的轻微修改版本上。论文强调了LLMs在游戏理论领域的优势和局限性，并呼吁进一步研究以克服其在更复杂场景中的不足，从而充分发挥其潜力。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10574v2",
      "published_date": "2024-06-15 09:30:20 UTC",
      "updated_date": "2024-10-12 07:32:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:33:19.920847"
    },
    {
      "arxiv_id": "2406.10573v2",
      "title": "Graph Neural Backdoor: Fundamentals, Methodologies, Applications, and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Yang",
        "Gaolei Li",
        "Jianhua Li"
      ],
      "abstract": "Graph Neural Networks (GNNs) have significantly advanced various downstream\ngraph-relevant tasks, encompassing recommender systems, molecular structure\nprediction, social media analysis, etc. Despite the boosts of GNN, recent\nresearch has empirically demonstrated its potential vulnerability to backdoor\nattacks, wherein adversaries employ triggers to poison input samples, inducing\nGNN to adversary-premeditated malicious outputs. This is typically due to the\ncontrolled training process, or the deployment of untrusted models, such as\ndelegating model training to third-party service, leveraging external training\nsets, and employing pre-trained models from online sources. Although there's an\nongoing increase in research on GNN backdoors, comprehensive investigation into\nthis field is lacking. To bridge this gap, we propose the first survey\ndedicated to GNN backdoors. We begin by outlining the fundamental definition of\nGNN, followed by the detailed summarization and categorization of current GNN\nbackdoor attacks and defenses based on their technical characteristics and\napplication scenarios. Subsequently, the analysis of the applicability and use\ncases of GNN backdoors is undertaken. Finally, the exploration of potential\nresearch directions of GNN backdoors is presented. This survey aims to explore\nthe principles of graph backdoors, provide insights to defenders, and promote\nfuture security research.",
      "tldr_zh": "这篇论文是首篇针对图神经网络 (GNNs) 后门的全面调查，探讨了 GNNs 在推荐系统、分子结构预测和社会媒体分析等任务中的潜在漏洞，特别是后门攻击可能导致恶意输出的问题。作者系统总结并分类了现有 GNN 后门攻击和防御方法，基于技术特性和应用场景进行分析，并评估了其实际用例和未来研究方向。最终，该调查填补了该领域的空白，提供防御策略见解，并促进 GNN 安全研究的进步。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10573v2",
      "published_date": "2024-06-15 09:23:46 UTC",
      "updated_date": "2025-01-07 11:13:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:33:32.232962"
    },
    {
      "arxiv_id": "2406.16933v1",
      "title": "SGSM: A Foundation-model-like Semi-generalist Sensing Model",
      "title_zh": "SGSM：一种类似于基础模型的半通用感知模型",
      "authors": [
        "Tianjian Yang",
        "Hao Zhou",
        "Shuo Liu",
        "Kaiwen Guo",
        "Yiwen Hou",
        "Haohua Du",
        "Zhi Liu",
        "Xiang-Yang Li"
      ],
      "abstract": "The significance of intelligent sensing systems is growing in the realm of\nsmart services. These systems extract relevant signal features and generate\ninformative representations for particular tasks. However, building the feature\nextraction component for such systems requires extensive domain-specific\nexpertise or data. The exceptionally rapid development of foundation models is\nlikely to usher in newfound abilities in such intelligent sensing. We propose a\nnew scheme for sensing model, which we refer to as semi-generalist sensing\nmodel (SGSM). SGSM is able to semiautomatically solve various tasks using\nrelatively less task-specific labeled data compared to traditional systems.\nBuilt through the analysis of the common theoretical model, SGSM can depict\ndifferent modalities, such as the acoustic and Wi-Fi signal. Experimental\nresults on such two heterogeneous sensors illustrate that SGSM functions across\na wide range of scenarios, thereby establishing its broad applicability. In\nsome cases, SGSM even achieves better performance than sensor-specific\nspecialized solutions. Wi-Fi evaluations indicate a 20\\% accuracy improvement\nwhen applying SGSM to an existing sensing model.",
      "tldr_zh": "该论文提出 SGSM，一种类似于 foundation models 的半通用感知模型，旨在解决智能感知系统中特征提取的领域依赖问题。SGSM 通过分析共同的理论模型，能够半自动处理各种任务，支持不同模态如声学和 Wi-Fi 信号，并仅需较少的任务特定标记数据。实验结果显示，SGSM 在异构传感器场景中表现出广泛适用性，在某些情况下优于专有解决方案，并在 Wi-Fi 评估中实现了 20% 的准确率提升。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16933v1",
      "published_date": "2024-06-15 09:20:46 UTC",
      "updated_date": "2024-06-15 09:20:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:33:43.719208"
    },
    {
      "arxiv_id": "2406.10563v2",
      "title": "Privacy-Preserving Heterogeneous Federated Learning for Sensitive Healthcare Data",
      "title_zh": "隐私保护的异构联邦学习用于敏感医疗保健数据",
      "authors": [
        "Yukai Xu",
        "Jingfeng Zhang",
        "Yujie Gu"
      ],
      "abstract": "In the realm of healthcare where decentralized facilities are prevalent,\nmachine learning faces two major challenges concerning the protection of data\nand models. The data-level challenge concerns the data privacy leakage when\ncentralizing data with sensitive personal information. While the model-level\nchallenge arises from the heterogeneity of local models, which need to be\ncollaboratively trained while ensuring their confidentiality to address\nintellectual property concerns. To tackle these challenges, we propose a new\nframework termed Abstention-Aware Federated Voting (AAFV) that can\ncollaboratively and confidentially train heterogeneous local models while\nsimultaneously protecting the data privacy. This is achieved by integrating a\nnovel abstention-aware voting mechanism and a differential privacy mechanism\nonto local models' predictions. In particular, the proposed abstention-aware\nvoting mechanism exploits a threshold-based abstention method to select\nhigh-confidence votes from heterogeneous local models, which not only enhances\nthe learning utility but also protects model confidentiality. Furthermore, we\nimplement AAFV on two practical prediction tasks of diabetes and in-hospital\npatient mortality. The experiments demonstrate the effectiveness and\nconfidentiality of AAFV in testing accuracy and privacy protection.",
      "tldr_zh": "本研究针对医疗领域敏感数据的隐私保护问题，提出了Abstention-Aware Federated Voting (AAFV)框架，以解决数据隐私泄露和异构本地模型机密性挑战。AAFV通过整合阈值-based abstention-aware voting机制和differential privacy机制，实现异构本地模型的协作训练，同时选择高置信度投票来提升学习效用并保护模型保密性。在糖尿病预测和住院患者死亡率预测任务上的实验表明，该框架显著提高了测试准确率，同时确保了数据和模型的隐私保护。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the 2024 IEEE Conference on Artificial Intelligence (IEEE\n  CAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.10563v2",
      "published_date": "2024-06-15 08:43:40 UTC",
      "updated_date": "2024-07-04 14:10:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:33:55.668088"
    },
    {
      "arxiv_id": "2406.10557v5",
      "title": "Explain the Black Box for the Sake of Science: the Scientific Method in the Era of Generative Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Gianmarco Mengaldo"
      ],
      "abstract": "The scientific method is the cornerstone of human progress across all\nbranches of the natural and applied sciences, from understanding the human body\nto explaining how the universe works. The scientific method is based on\nidentifying systematic rules or principles that describe the phenomenon of\ninterest in a reproducible way that can be validated through experimental\nevidence. In the era of generative artificial intelligence, there are\ndiscussions on how AI systems may discover new knowledge. We argue that human\ncomplex reasoning for scientific discovery remains of vital importance, at\nleast before the advent of artificial general intelligence. Yet, AI can be\nleveraged for scientific discovery via explainable AI. More specifically,\nknowing the `principles' the AI systems used to make decisions can be a point\nof contact with domain experts and scientists, that can lead to divergent or\nconvergent views on a given scientific problem. Divergent views may spark\nfurther scientific investigations leading to interpretability-guided\nexplanations (IGEs), and possibly to new scientific knowledge. We define this\nfield as Explainable AI for Science, where domain experts -- potentially\nassisted by generative AI -- formulate scientific hypotheses and explanations\nbased on the interpretability of a predictive AI system.",
      "tldr_zh": "本论文讨论了在生成式人工智能(Generative Artificial Intelligence)时代，科学方法如何保持其核心地位，即通过可重复验证的系统规则来理解现象。作者强调，人类复杂推理在人工智能通用智能(Artificial General Intelligence)出现前仍至关重要，但Explainable AI(可解释AI)可作为桥梁，让AI决策的“原则”与领域专家互动，产生发散或收敛观点。论文提出，Explainable AI for Science这一新领域，通过Interpretability-Guided Explanations(IGEs)引导的解释，帮助专家（可能借助生成式AI）制定科学假设，最终可能激发新科学知识的发现。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "math.DS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10557v5",
      "published_date": "2024-06-15 08:34:42 UTC",
      "updated_date": "2025-02-27 06:54:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:34:08.233587"
    },
    {
      "arxiv_id": "2406.10556v1",
      "title": "Multi-User Semantic Fusion for Semantic Communications over Degraded Broadcast Channels",
      "title_zh": "翻译失败",
      "authors": [
        "Tong Wu",
        "Zhiyong Chen",
        "Meixia Tao",
        "Bin Xia",
        "Wenjun Zhang"
      ],
      "abstract": "Degraded broadcast channels (DBC) are a typical multiuser communication\nscenario, Semantic communications over DBC still lack in-depth research. In\nthis paper, we design a semantic communications approach based on multi-user\nsemantic fusion for wireless image transmission over DBC. In the proposed\nmethod, the transmitter extracts semantic features for two users separately. It\nthen effectively fuses these semantic features for broadcasting by leveraging\nsemantic similarity. Unlike traditional allocation of time, power, or\nbandwidth, the semantic fusion scheme can dynamically control the weight of the\nsemantic features of the two users to balance the performance between the two\nusers. Considering the different channel state information (CSI) of both users\nover DBC, a DBC-Aware method is developed that embeds the CSI of both users\ninto the joint source-channel coding encoder and fusion module to adapt to the\nchannel. Experimental results show that the proposed system outperforms the\ntraditional broadcasting schemes.",
      "tldr_zh": "这篇论文针对退化广播信道(DBC)上的多用户语义通信，提出了一种基于多用户语义融合的方法，用于无线图像传输。发送端分别提取两个用户的语义特征，并利用语义相似性动态融合这些特征，同时通过DBC-Aware机制将信道状态信息(CSI)嵌入联合源-信道编码和融合模块，以平衡用户性能。实验结果显示，该系统在图像传输方面优于传统广播方案。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "accepted by China Communications",
      "pdf_url": "http://arxiv.org/pdf/2406.10556v1",
      "published_date": "2024-06-15 08:19:59 UTC",
      "updated_date": "2024-06-15 08:19:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:34:20.242182"
    },
    {
      "arxiv_id": "2406.11900v1",
      "title": "Horizon-wise Learning Paradigm Promotes Gene Splicing Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Qi-Jie Li",
        "Qian Sun",
        "Shao-Qun Zhang"
      ],
      "abstract": "Identifying gene splicing is a core and significant task confronted in modern\ncollaboration between artificial intelligence and bioinformatics. Past decades\nhave witnessed great efforts on this concern, such as the bio-plausible\nsplicing pattern AT-CG and the famous SpliceAI. In this paper, we propose a\nnovel framework for the task of gene splicing identification, named\nHorizon-wise Gene Splicing Identification (H-GSI). The proposed H-GSI follows\nthe horizon-wise identification paradigm and comprises four components: the\npre-processing procedure transforming string data into tensors, the sliding\nwindow technique handling long sequences, the SeqLab model, and the predictor.\nIn contrast to existing studies that process gene information with a truncated\nfixed-length sequence, H-GSI employs a horizon-wise identification paradigm in\nwhich all positions in a sequence are predicted with only one forward\ncomputation, improving accuracy and efficiency. The experiments conducted on\nthe real-world Human dataset show that our proposed H-GSI outperforms SpliceAI\nand achieves the best accuracy of 97.20\\%. The source code is available from\nthis link.",
      "tldr_zh": "本论文提出了一种名为 H-GSI 的新框架，用于基因 splicing identification（基因拼接识别），它采用 horizon-wise 识别范式来处理基因序列，避免了传统方法的固定长度截断，提高了准确性和效率。H-GSI 包括四个组件：预处理过程（将字符串数据转化为张量）、滑动窗口技术、SeqLab 模型和预测器，这些组件允许在一次前向计算中预测序列的所有位置。实验在真实世界 Human 数据集上显示，H-GSI 超过了现有方法如 SpliceAI，达到了 97.20% 的最佳准确率。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11900v1",
      "published_date": "2024-06-15 08:18:09 UTC",
      "updated_date": "2024-06-15 08:18:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:34:33.252643"
    },
    {
      "arxiv_id": "2406.10552v4",
      "title": "Large Language Model Enhanced Clustering for News Event Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Adane Nega Tarekegn"
      ],
      "abstract": "The news landscape is continuously evolving, with an ever-increasing volume\nof information from around the world. Automated event detection within this\nvast data repository is essential for monitoring, identifying, and categorizing\nsignificant news occurrences across diverse platforms. This paper presents an\nevent detection framework that leverages Large Language Models (LLMs) combined\nwith clustering analysis to detect news events from the Global Database of\nEvents, Language, and Tone (GDELT). The framework enhances event clustering\nthrough both pre-event detection tasks (keyword extraction and text embedding)\nand post-event detection tasks (event summarization and topic labelling). We\nalso evaluate the impact of various textual embeddings on the quality of\nclustering outcomes, ensuring robust news categorization. Additionally, we\nintroduce a novel Cluster Stability Assessment Index (CSAI) to assess the\nvalidity and robustness of clustering results. CSAI utilizes multiple feature\nvectors to provide a new way of measuring clustering quality. Our experiments\nindicate that the use of LLM embedding in the event detection framework has\nsignificantly improved the results, demonstrating greater robustness in terms\nof CSAI scores. Moreover, post-event detection tasks generate meaningful\ninsights, facilitating effective interpretation of event clustering results.\nOverall, our experimental results indicate that the proposed framework offers\nvaluable insights and could enhance the accuracy in news analysis and\nreporting.",
      "tldr_zh": "这篇论文提出了一种利用 Large Language Models (LLMs) 增强的聚类框架，用于从 Global Database of Events, Language, and Tone (GDELT) 数据库检测新闻事件。该框架通过预事件检测任务（如关键词提取和文本嵌入）以及后事件检测任务（如事件总结和主题标记）来改善聚类分析的质量。论文还引入了新的 Cluster Stability Assessment Index (CSAI) 指标，利用多种特征向量评估聚类的效度和稳健性。实验结果表明，使用 LLM 嵌入显著提升了聚类性能，在 CSAI 得分上表现出更高的稳健性，并为新闻分析和报告提供了更准确的见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10552v4",
      "published_date": "2024-06-15 08:13:47 UTC",
      "updated_date": "2024-07-06 09:19:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:34:45.166892"
    },
    {
      "arxiv_id": "2406.10543v1",
      "title": "NeRFDeformer: NeRF Transformation from a Single View via 3D Scene Flows",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenggang Tang",
        "Zhongzheng Ren",
        "Xiaoming Zhao",
        "Bowen Wen",
        "Jonathan Tremblay",
        "Stan Birchfield",
        "Alexander Schwing"
      ],
      "abstract": "We present a method for automatically modifying a NeRF representation based\non a single observation of a non-rigid transformed version of the original\nscene. Our method defines the transformation as a 3D flow, specifically as a\nweighted linear blending of rigid transformations of 3D anchor points that are\ndefined on the surface of the scene. In order to identify anchor points, we\nintroduce a novel correspondence algorithm that first matches RGB-based pairs,\nthen leverages multi-view information and 3D reprojection to robustly filter\nfalse positives in two steps. We also introduce a new dataset for exploring the\nproblem of modifying a NeRF scene through a single observation. Our dataset (\nhttps://github.com/nerfdeformer/nerfdeformer ) contains 113 synthetic scenes\nleveraging 47 3D assets. We show that our proposed method outperforms NeRF\nediting methods as well as diffusion-based methods, and we also explore\ndifferent methods for filtering correspondences.",
      "tldr_zh": "本论文提出NeRFDeformer，一种基于单视图观察的NeRF变换方法，通过3D Scene Flows定义场景的非刚性变换，将其表示为场景表面上3D锚点的加权线性混合刚性变换。方法引入了一个新颖的对应算法，先进行RGB-based pairs匹配，然后利用multi-view information和3D reprojection进行两步过滤，以robustly去除假阳性。研究者还发布了一个新数据集，包含113个合成场景和47个3D资产，用于探索NeRF场景修改问题。实验结果显示，该方法在性能上优于现有NeRF编辑方法和diffusion-based方法，并探讨了不同对应过滤策略。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages of main paper, CVPR 2024. Proceedings of the IEEE/CVF\n  Conference on Computer Vision and Pattern Recognition. 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.10543v1",
      "published_date": "2024-06-15 07:58:08 UTC",
      "updated_date": "2024-06-15 07:58:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:34:56.852714"
    },
    {
      "arxiv_id": "2406.10540v1",
      "title": "Generating and Evolving Reward Functions for Highway Driving with Large Language Models",
      "title_zh": "使用大型语言模型生成和演化高速公路",
      "authors": [
        "Xu Han",
        "Qiannan Yang",
        "Xianda Chen",
        "Xiaowen Chu",
        "Meixin Zhu"
      ],
      "abstract": "Reinforcement Learning (RL) plays a crucial role in advancing autonomous\ndriving technologies by maximizing reward functions to achieve the optimal\npolicy. However, crafting these reward functions has been a complex, manual\nprocess in many practices. To reduce this complexity, we introduce a novel\nframework that integrates Large Language Models (LLMs) with RL to improve\nreward function design in autonomous driving. This framework utilizes the\ncoding capabilities of LLMs, proven in other areas, to generate and evolve\nreward functions for highway scenarios. The framework starts with instructing\nLLMs to create an initial reward function code based on the driving environment\nand task descriptions. This code is then refined through iterative cycles\ninvolving RL training and LLMs' reflection, which benefits from their ability\nto review and improve the output. We have also developed a specific prompt\ntemplate to improve LLMs' understanding of complex driving simulations,\nensuring the generation of effective and error-free code. Our experiments in a\nhighway driving simulator across three traffic configurations show that our\nmethod surpasses expert handcrafted reward functions, achieving a 22% higher\naverage success rate. This not only indicates safer driving but also suggests\nsignificant gains in development productivity.",
      "tldr_zh": "这篇论文提出了一种将大型语言模型 (LLMs) 与强化学习 (RL) 整合的框架，用于自动生成和演化高速公路驾驶的奖励函数，以简化传统的手动设计过程。框架首先通过指令 LLMs 根据驾驶环境和任务描述生成初始奖励函数代码，然后通过迭代的 RL 训练和 LLMs 的反思机制进行优化，并使用特定提示模板确保代码的准确性和有效性。在高速公路驾驶模拟器上的实验中，该方法在三种交通配置下比专家手工奖励函数提高了22%的平均成功率，显著提升了驾驶安全性和开发生产力。",
      "categories": [
        "cs.AI",
        "cs.NE",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.10540v1",
      "published_date": "2024-06-15 07:50:10 UTC",
      "updated_date": "2024-06-15 07:50:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:35:11.284934"
    },
    {
      "arxiv_id": "2406.10537v1",
      "title": "Scalable Differentiable Causal Discovery in the Presence of Latent Confounders with Skeleton Posterior (Extended Version)",
      "title_zh": "翻译失败",
      "authors": [
        "Pingchuan Ma",
        "Rui Ding",
        "Qiang Fu",
        "Jiaru Zhang",
        "Shuai Wang",
        "Shi Han",
        "Dongmei Zhang"
      ],
      "abstract": "Differentiable causal discovery has made significant advancements in the\nlearning of directed acyclic graphs. However, its application to real-world\ndatasets remains restricted due to the ubiquity of latent confounders and the\nrequirement to learn maximal ancestral graphs (MAGs). To date, existing\ndifferentiable MAG learning algorithms have been limited to small datasets and\nfailed to scale to larger ones (e.g., with more than 50 variables).\n  The key insight in this paper is that the causal skeleton, which is the\nundirected version of the causal graph, has potential for improving accuracy\nand reducing the search space of the optimization procedure, thereby enhancing\nthe performance of differentiable causal discovery. Therefore, we seek to\naddress a two-fold challenge to harness the potential of the causal skeleton\nfor differentiable causal discovery in the presence of latent confounders: (1)\nscalable and accurate estimation of skeleton and (2) universal integration of\nskeleton estimation with differentiable causal discovery.\n  To this end, we propose SPOT (Skeleton Posterior-guided OpTimization), a\ntwo-phase framework that harnesses skeleton posterior for differentiable causal\ndiscovery in the presence of latent confounders. On the contrary to a\n``point-estimation'', SPOT seeks to estimate the posterior distribution of\nskeletons given the dataset. It first formulates the posterior inference as an\ninstance of amortized inference problem and concretizes it with a supervised\ncausal learning (SCL)-enabled solution to estimate the skeleton posterior. To\nincorporate the skeleton posterior with differentiable causal discovery, SPOT\nthen features a skeleton posterior-guided stochastic optimization procedure to\nguide the optimization of MAGs. [abridged due to length limit]",
      "tldr_zh": "本论文探讨了在存在潜在混杂因素（latent confounders）的情况下，可微因果发现（Differentiable causal discovery）的可扩展性问题，特别是在学习最大祖先图（MAGs）时面临的挑战。作者提出SPOT框架（Skeleton Posterior-guided OpTimization），一个两阶段方法：首先通过监督因果学习（SCL-enabled solution）估计因果骨架（causal skeleton）的后验分布，以提高准确性和减少优化搜索空间；然后，将该后验分布整合进随机优化过程，用于指导MAGs的学习。实验结果表明，SPOT框架显著提升了算法在大型数据集上的性能，支持了更可靠的因果结构发现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10537v1",
      "published_date": "2024-06-15 07:40:36 UTC",
      "updated_date": "2024-06-15 07:40:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:35:25.618078"
    },
    {
      "arxiv_id": "2406.10534v3",
      "title": "Finite-difference-informed graph network for solving steady-state incompressible flows on block-structured grids",
      "title_zh": "翻译失败",
      "authors": [
        "Yiye Zou",
        "Tianyu Li",
        "Lin Lu",
        "Jingyu Wang",
        "Shufan Zou",
        "Laiping Zhang",
        "Xiaogang Deng"
      ],
      "abstract": "Advances in deep learning have enabled physics-informed neural networks to\nsolve partial differential equations. Numerical differentiation using the\nfinite-difference (FD) method is efficient in physics-constrained designs, even\nin parameterized settings. In traditional computational fluid dynamics(CFD),\nbody-fitted block-structured grids are often employed for complex flow cases\nwhen obtaining FD solutions. However, convolution operators in convolutional\nneural networks for FD are typically limited to single-block grids. To address\nthis issue, \\blueText{graphs and graph networks are used} to learn flow\nrepresentations across multi-block-structured grids. \\blueText{A graph\nconvolution-based FD method (GC-FDM) is proposed} to train graph networks in a\nlabel-free physics-constrained manner, enabling differentiable FD operations on\nunstructured graph outputs. To demonstrate model performance from single- to\nmulti-block-structured grids, \\blueText{the parameterized steady incompressible\nNavier-Stokes equations are solved} for a lid-driven cavity flow and the flows\naround single and double circular cylinder configurations. When compared to a\nCFD solver under various boundary conditions, the proposed method achieves a\nrelative error in velocity field predictions on the order of $10^{-3}$.\nFurthermore, the proposed method reduces training costs by approximately 20\\%\ncompared to a physics-informed neural network. \\blueText{To} further verify the\neffectiveness of GC-FDM in multi-block processing, \\blueText{a 30P30N airfoil\ngeometry is considered} and the \\blueText{predicted} results are reasonable\ncompared with those given by CFD. \\blueText{Finally, the applicability of\nGC-FDM to three-dimensional (3D) case is tested using a 3D cavity geometry.",
      "tldr_zh": "本研究提出了一种基于有限差分(FD)方法的图网络框架，用于在多块结构网格上求解稳态不可压缩流动问题。论文引入图卷积-based FD方法(GC-FDM)，通过图网络学习多块网格上的流动表示，并在无标签的物理约束条件下进行训练，解决了传统卷积神经网络在单块网格的局限性。在实验中，GC-FDM成功求解了参数化的Navier-Stokes方程，包括盖子驱动腔流和单双圆柱流动，与CFD求解器相比，速度场预测的相对误差在$10^{-3}$数量级，并将训练成本降低了约20%。此外，该方法在30P30N翼型和三维(3D)腔体几何等复杂场景中表现出良好的多块处理效果，证明了其在计算流体动力学(CFD)中的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.flu-dyn"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10534v3",
      "published_date": "2024-06-15 07:30:40 UTC",
      "updated_date": "2024-11-29 06:07:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:35:34.651489"
    },
    {
      "arxiv_id": "2406.10529v1",
      "title": "A Theory of Interpretable Approximations",
      "title_zh": "可解释逼近的理论",
      "authors": [
        "Marco Bressan",
        "Nicolò Cesa-Bianchi",
        "Emmanuel Esposito",
        "Yishay Mansour",
        "Shay Moran",
        "Maximilian Thiessen"
      ],
      "abstract": "Can a deep neural network be approximated by a small decision tree based on\nsimple features? This question and its variants are behind the growing demand\nfor machine learning models that are *interpretable* by humans. In this work we\nstudy such questions by introducing *interpretable approximations*, a notion\nthat captures the idea of approximating a target concept $c$ by a small\naggregation of concepts from some base class $\\mathcal{H}$. In particular, we\nconsider the approximation of a binary concept $c$ by decision trees based on a\nsimple class $\\mathcal{H}$ (e.g., of bounded VC dimension), and use the tree\ndepth as a measure of complexity. Our primary contribution is the following\nremarkable trichotomy. For any given pair of $\\mathcal{H}$ and $c$, exactly one\nof these cases holds: (i) $c$ cannot be approximated by $\\mathcal{H}$ with\narbitrary accuracy; (ii) $c$ can be approximated by $\\mathcal{H}$ with\narbitrary accuracy, but there exists no universal rate that bounds the\ncomplexity of the approximations as a function of the accuracy; or (iii) there\nexists a constant $\\kappa$ that depends only on $\\mathcal{H}$ and $c$ such\nthat, for *any* data distribution and *any* desired accuracy level, $c$ can be\napproximated by $\\mathcal{H}$ with a complexity not exceeding $\\kappa$. This\ntaxonomy stands in stark contrast to the landscape of supervised\nclassification, which offers a complex array of distribution-free and\nuniversally learnable scenarios. We show that, in the case of interpretable\napproximations, even a slightly nontrivial a-priori guarantee on the complexity\nof approximations implies approximations with constant (distribution-free and\naccuracy-free) complexity. We extend our trichotomy to classes $\\mathcal{H}$ of\nunbounded VC dimension and give characterizations of interpretability based on\nthe algebra generated by $\\mathcal{H}$.",
      "tldr_zh": "本论文提出“interpretable approximations”的理论框架，用于评估是否能用简单基础类 $\\mathcal{H}$（例如VC dimension有限的决策树）近似目标二元概念 $c$，并以树深度作为复杂度度量。主要贡献是一个三分类（trichotomy）：对于任何 $\\mathcal{H}$ 和 $c$，要么 $c$ 无法以任意精度被近似；要么可以近似但无通用复杂度界；要么存在常数 $\\kappa$，使复杂度独立于数据分布和精度水平。该框架与监督分类不同，即使有轻微先验保证，也可实现常数复杂度近似，并扩展到 VC dimension无限的 $\\mathcal{H}$ 类，通过其生成代数表征可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear at COLT 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.10529v1",
      "published_date": "2024-06-15 06:43:45 UTC",
      "updated_date": "2024-06-15 06:43:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:35:47.123752"
    },
    {
      "arxiv_id": "2406.10522v2",
      "title": "Humor in AI: Massive Scale Crowd-Sourced Preferences and Benchmarks for Cartoon Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Jifan Zhang",
        "Lalit Jain",
        "Yang Guo",
        "Jiayi Chen",
        "Kuan Lok Zhou",
        "Siddharth Suresh",
        "Andrew Wagenmaker",
        "Scott Sievert",
        "Timothy Rogers",
        "Kevin Jamieson",
        "Robert Mankoff",
        "Robert Nowak"
      ],
      "abstract": "We present a novel multimodal preference dataset for creative tasks,\nconsisting of over 250 million human ratings on more than 2.2 million captions,\ncollected through crowdsourcing rating data for The New Yorker's weekly cartoon\ncaption contest over the past eight years. This unique dataset supports the\ndevelopment and evaluation of multimodal large language models and\npreference-based fine-tuning algorithms for humorous caption generation. We\npropose novel benchmarks for judging the quality of model-generated captions,\nutilizing both GPT4 and human judgments to establish ranking-based evaluation\nstrategies. Our experimental results highlight the limitations of current\nfine-tuning methods, such as RLHF and DPO, when applied to creative tasks.\nFurthermore, we demonstrate that even state-of-the-art models like GPT4 and\nClaude currently underperform top human contestants in generating humorous\ncaptions. As we conclude this extensive data collection effort, we release the\nentire preference dataset to the research community, fostering further\nadvancements in AI humor generation and evaluation.",
      "tldr_zh": "本研究构建了一个大规模多模态偏好数据集，包含超过2.5亿人类评分，针对220万个标题，这些数据通过众包方式从过去八年的《纽约客》每周漫画标题竞赛中收集。该数据集用于开发和评估multimodal large language models以及基于偏好的微调算法，如RLHF和DPO，专注于幽默标题生成。研究者提出了新的benchmarks，利用GPT4和人类判断的排名策略来评估模型生成的标题质量。实验结果显示，当前微调方法在创意任务上存在局限性，即使是GPT4和Claude等最先进模型，在幽默生成方面仍落后于顶级人类参赛者；最终，该数据集已向研究社区公开，以推动AI幽默生成和评估的进步。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10522v2",
      "published_date": "2024-06-15 06:26:25 UTC",
      "updated_date": "2024-12-18 05:21:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:35:58.245303"
    },
    {
      "arxiv_id": "2406.10521v3",
      "title": "MALLM-GAN: Multi-Agent Large Language Model as Generative Adversarial Network for Synthesizing Tabular Data",
      "title_zh": "MALLM-GAN：多智能体大语言模型作为生成对抗网络用于合成表格数据",
      "authors": [
        "Yaobin Ling",
        "Xiaoqian Jiang",
        "Yejin Kim"
      ],
      "abstract": "In the era of big data, access to abundant data is crucial for driving\nresearch forward. However, such data is often inaccessible due to privacy\nconcerns or high costs, particularly in healthcare domain. Generating synthetic\n(tabular) data can address this, but existing models typically require\nsubstantial amounts of data to train effectively, contradicting our objective\nto solve data scarcity. To address this challenge, we propose a novel framework\nto generate synthetic tabular data, powered by large language models (LLMs)\nthat emulates the architecture of a Generative Adversarial Network (GAN). By\nincorporating data generation process as contextual information and utilizing\nLLM as the optimizer, our approach significantly enhance the quality of\nsynthetic data generation in common scenarios with small sample sizes. Our\nexperimental results on public and private datasets demonstrate that our model\noutperforms several state-of-art models regarding generating higher quality\nsynthetic data for downstream tasks while keeping privacy of the real data.",
      "tldr_zh": "该研究提出 MALLM-GAN 框架，使用多智能体 Large Language Models (LLMs) 模拟 Generative Adversarial Network (GAN) 架构，来生成合成表格数据，旨在解决大数据时代的数据隐私和稀缺问题。框架通过将数据生成过程作为上下文信息，并利用 LLM 作为优化器，提升小样本场景下的合成数据质量，从而减少对大量训练数据的依赖。实验结果显示，该模型在公共和私有数据集上优于现有模型，能为下游任务提供更高质量的合成数据，同时有效保护真实数据的隐私。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10521v3",
      "published_date": "2024-06-15 06:26:17 UTC",
      "updated_date": "2024-10-02 23:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:36:11.460167"
    },
    {
      "arxiv_id": "2406.10519v2",
      "title": "Self Pre-training with Topology- and Spatiality-aware Masked Autoencoders for 3D Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Pengfei Gu",
        "Yejia Zhang",
        "Huimin Li",
        "Chaoli Wang",
        "Danny Z. Chen"
      ],
      "abstract": "Masked Autoencoders (MAEs) have been shown to be effective in pre-training\nVision Transformers (ViTs) for natural and medical image analysis problems. By\nreconstructing missing pixel/voxel information in visible patches, a ViT\nencoder can aggregate contextual information for downstream tasks. But,\nexisting MAE pre-training methods, which were specifically developed with the\nViT architecture, lack the ability to capture geometric shape and spatial\ninformation, which is critical for medical image segmentation tasks. In this\npaper, we propose a novel extension of known MAEs for self pre-training (i.e.,\nmodels pre-trained on the same target dataset) for 3D medical image\nsegmentation. (1) We propose a new topological loss to preserve geometric shape\ninformation by computing topological signatures of both the input and\nreconstructed volumes, learning geometric shape information. (2) We introduce a\npre-text task that predicts the positions of the centers and eight corners of\n3D crops, enabling the MAE to aggregate spatial information. (3) We extend the\nMAE pre-training strategy to a hybrid state-of-the-art (SOTA) medical image\nsegmentation architecture and co-pretrain it alongside the ViT. (4) We develop\na fine-tuned model for downstream segmentation tasks by complementing the\npre-trained ViT encoder with our pre-trained SOTA model. Extensive experiments\non five public 3D segmentation datasets show the effectiveness of our new\napproach.",
      "tldr_zh": "这篇论文提出了一种改进的 Masked Autoencoders (MAEs) 用于 3D 医疗图像分割的自预训练方法，旨在解决现有方法在捕获几何形状和空间信息方面的不足。关键创新包括引入 topological loss 来计算输入和重建体积的拓扑签名以保留几何信息、一个预测 3D 裁剪中心和八个角位置的预文本任务以聚合空间信息，以及将 MAE 策略扩展到混合 SOTA 医疗图像分割架构并与 Vision Transformers (ViTs) 共同预训练。实验结果显示，该方法在五个公共 3D 分割数据集上表现出色，证明了其在提升分割任务性能的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10519v2",
      "published_date": "2024-06-15 06:15:17 UTC",
      "updated_date": "2024-07-15 20:35:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:36:24.042892"
    },
    {
      "arxiv_id": "2406.10517v1",
      "title": "ADSNet: Cross-Domain LTV Prediction with an Adaptive Siamese Network in Advertising",
      "title_zh": "翻译失败",
      "authors": [
        "Ruize Wang",
        "Hui Xu",
        "Ying Cheng",
        "Qi He",
        "Xing Zhou",
        "Rui Feng",
        "Wei Xu",
        "Lei Huang",
        "Jie Jiang"
      ],
      "abstract": "Advertising platforms have evolved in estimating Lifetime Value (LTV) to\nbetter align with advertisers' true performance metric. However, the sparsity\nof real-world LTV data presents a significant challenge to LTV predictive\nmodel(i.e., pLTV), severely limiting the their capabilities. Therefore, we\npropose to utilize external data, in addition to the internal data of\nadvertising platform, to expand the size of purchase samples and enhance the\nLTV prediction model of the advertising platform. To tackle the issue of data\ndistribution shift between internal and external platforms, we introduce an\nAdaptive Difference Siamese Network (ADSNet), which employs cross-domain\ntransfer learning to prevent negative transfer. Specifically, ADSNet is\ndesigned to learn information that is beneficial to the target domain. We\nintroduce a gain evaluation strategy to calculate information gain, aiding the\nmodel in learning helpful information for the target domain and providing the\nability to reject noisy samples, thus avoiding negative transfer. Additionally,\nwe also design a Domain Adaptation Module as a bridge to connect different\ndomains, reduce the distribution distance between them, and enhance the\nconsistency of representation space distribution. We conduct extensive offline\nexperiments and online A/B tests on a real advertising platform. Our proposed\nADSNet method outperforms other methods, improving GINI by 2$\\%$. The ablation\nstudy highlights the importance of the gain evaluation strategy in negative\ngain sample rejection and improving model performance. Additionally, ADSNet\nsignificantly improves long-tail prediction. The online A/B tests confirm\nADSNet's efficacy, increasing online LTV by 3.47$\\%$ and GMV by 3.89$\\%$.",
      "tldr_zh": "广告平台在估算终身价值 (LTV) 时面临数据稀疏挑战，为此提出 ADSNet，一种自适应孪生网络框架，利用跨域转移学习整合外部数据以提升 LTV 预测模型。ADSNet 引入 gain evaluation strategy 来计算信息增益，帮助模型筛选对目标域有益的信息并拒绝噪声样本，同时通过 Domain Adaptation Module 减少域间分布差异，确保表示空间的一致性。实验结果显示，ADSNet 比其他方法提高了 GINI 指标 2%，改善了长尾预测，并在在线 A/B 测试中将 LTV 提升 3.47% 和 GMV 提升 3.89%。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted to KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.10517v1",
      "published_date": "2024-06-15 06:04:46 UTC",
      "updated_date": "2024-06-15 06:04:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:36:35.833979"
    },
    {
      "arxiv_id": "2406.10515v2",
      "title": "Reactor Mk.1 performances: MMLU, HumanEval and BBH test results",
      "title_zh": "翻译失败",
      "authors": [
        "TJ Dunham",
        "Henry Syahputra"
      ],
      "abstract": "The paper presents the performance results of Reactor Mk.1, ARCs flagship\nlarge language model, through a benchmarking process analysis. The model\nutilizes the Lychee AI engine and possesses less than 100 billion parameters,\nresulting in a combination of efficiency and potency. The Reactor Mk.1\noutperformed models such as GPT-4o, Claude Opus, and Llama 3, with achieved\nscores of 92% on the MMLU dataset, 91% on HumanEval dataset, and 88% on BBH\ndataset. It excels in both managing difficult jobs and reasoning, establishing\nas a prominent AI solution in the present cutting-edge AI technology.",
      "tldr_zh": "这篇论文评估了ARC的旗舰大语言模型Reactor Mk.1的性能，使用Lychee AI引擎并控制在不到100亿参数的范围内，实现了高效与强大相结合。模型在基准测试中表现突出，在MMLU数据集上得分92%、HumanEval数据集上得分91%、BBH数据集上得分88%。相比GPT-4o、Claude Opus和Llama 3等模型，Reactor Mk.1在处理困难任务和推理方面表现出色，确立了其在前沿AI技术中的领先地位。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10515v2",
      "published_date": "2024-06-15 05:52:32 UTC",
      "updated_date": "2024-07-26 08:03:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:36:57.299754"
    },
    {
      "arxiv_id": "2406.10514v1",
      "title": "GTR-Voice: Articulatory Phonetics Informed Controllable Expressive Speech Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Zehua Kcriss Li",
        "Meiying Melissa Chen",
        "Yi Zhong",
        "Pinxin Liu",
        "Zhiyao Duan"
      ],
      "abstract": "Expressive speech synthesis aims to generate speech that captures a wide\nrange of para-linguistic features, including emotion and articulation, though\ncurrent research primarily emphasizes emotional aspects over the nuanced\narticulatory features mastered by professional voice actors. Inspired by this,\nwe explore expressive speech synthesis through the lens of articulatory\nphonetics. Specifically, we define a framework with three dimensions:\nGlottalization, Tenseness, and Resonance (GTR), to guide the synthesis at the\nvoice production level. With this framework, we record a high-quality speech\ndataset named GTR-Voice, featuring 20 Chinese sentences articulated by a\nprofessional voice actor across 125 distinct GTR combinations. We verify the\nframework and GTR annotations through automatic classification and listening\ntests, and demonstrate precise controllability along the GTR dimensions on two\nfine-tuned expressive TTS models. We open-source the dataset and TTS models.",
      "tldr_zh": "该研究提出 GTR 框架（Glottalization、Tenseness 和 Resonance），以发音语音学（Articulatory Phonetics）为指导，实现对表达性语音合成的精确控制，强调发音特征而非仅限于情感表达。研究者录制了高质量数据集 GTR-Voice，由专业配音演员录制 20 个中文句子，涵盖 125 种 GTR 组合，并通过自动分类和听力测试验证了框架的有效性。在两个微调的表达性 TTS 模型上，展示了 GTR 维度的精确可控性，并开源了数据集和模型，以促进相关领域的研究。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10514v1",
      "published_date": "2024-06-15 05:37:04 UTC",
      "updated_date": "2024-06-15 05:37:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:36:58.544263"
    },
    {
      "arxiv_id": "2406.15468v2",
      "title": "MMLU-SR: A Benchmark for Stress-Testing Reasoning Capability of Large Language Models",
      "title_zh": "MMLU-SR：压力测试大型语言",
      "authors": [
        "Wentian Wang",
        "Sarthak Jain",
        "Paul Kantor",
        "Jacob Feldman",
        "Lazaros Gallos",
        "Hao Wang"
      ],
      "abstract": "We propose MMLU-SR, a novel dataset designed to measure the true\ncomprehension abilities of Large Language Models (LLMs) by challenging their\nperformance in question-answering tasks with modified terms. We reasoned that\nan agent that \"truly\" understands a concept can still evaluate it when key\nterms are replaced by suitably defined alternate terms, and sought to\ndifferentiate such comprehension from mere text replacement. In our study, we\nmodified standardized test questions by replacing a key term with a dummy word\nalong with its definition. The key term could be in the context of questions,\nanswers, or both questions and answers. Notwithstanding the high scores\nachieved by recent popular LLMs on the MMLU leaderboard, we found a substantial\nreduction in model performance after such replacement, suggesting poor\ncomprehension. This new benchmark provides a rigorous benchmark for testing\ntrue model comprehension, and poses a challenge to the broader scientific\ncommunity.",
      "tldr_zh": "该论文提出 MMLU-SR，这是一个新基准，用于评估 Large Language Models (LLMs) 的真实理解能力，通过在标准化测试问题中替换关键术语（如问题或答案中的术语）并提供定义，来挑战模型的推理性能。实验结果显示，尽管 LLMs 在原始 MMLU 测试中得分很高，但术语替换后其表现大幅下降，表明这些模型更多依赖模式匹配而非真正理解。MMLU-SR 作为一个严格的基准，为测试模型的深度理解能力提供了新工具，并向科学社区发出挑战。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15468v2",
      "published_date": "2024-06-15 05:35:47 UTC",
      "updated_date": "2024-10-04 07:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:37:12.217542"
    },
    {
      "arxiv_id": "2407.00056v1",
      "title": "MMBee: Live Streaming Gift-Sending Recommendations via Multi-Modal Fusion and Behaviour Expansion",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxin Deng",
        "Shiyao Wang",
        "Yuchen Wang",
        "Jiansong Qi",
        "Liqin Zhao",
        "Guorui Zhou",
        "Gaofeng Meng"
      ],
      "abstract": "Live streaming services are becoming increasingly popular due to real-time\ninteractions and entertainment. Viewers can chat and send comments or virtual\ngifts to express their preferences for the streamers. Accurately modeling the\ngifting interaction not only enhances users' experience but also increases\nstreamers' revenue. Previous studies on live streaming gifting prediction treat\nthis task as a conventional recommendation problem, and model users'\npreferences using categorical data and observed historical behaviors. However,\nit is challenging to precisely describe the real-time content changes in live\nstreaming using limited categorical information. Moreover, due to the sparsity\nof gifting behaviors, capturing the preferences and intentions of users is\nquite difficult. In this work, we propose MMBee based on real-time Multi-Modal\nFusion and Behaviour Expansion to address these issues. Specifically, we first\npresent a Multi-modal Fusion Module with Learnable Query (MFQ) to perceive the\ndynamic content of streaming segments and process complex multi-modal\ninteractions, including images, text comments and speech. To alleviate the\nsparsity issue of gifting behaviors, we present a novel Graph-guided Interest\nExpansion (GIE) approach that learns both user and streamer representations on\nlarge-scale gifting graphs with multi-modal attributes. Comprehensive\nexperiment results show that MMBee achieves significant performance\nimprovements on both public datasets and Kuaishou real-world streaming datasets\nand the effectiveness has been further validated through online A/B\nexperiments. MMBee has been deployed and is serving hundreds of millions of\nusers at Kuaishou.",
      "tldr_zh": "该论文提出MMBee框架，用于提升直播服务中的礼物发送推荐系统，解决传统方法在捕捉实时内容变化和处理行为稀疏性方面的不足。MMBee通过Multi-modal Fusion Module with Learnable Query (MFQ)融合图像、文本评论和语音等多模态数据，实现对动态直播内容的精确感知；同时，引入Graph-guided Interest Expansion (GIE)方法，在大规模礼物图上学习用户和主播表示，以缓解行为稀疏问题。实验结果显示，MMBee在公共数据集和Kuaishou真实数据集上显著提升推荐性能，并经在线A/B实验验证，已部署服务数亿用户。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.00056v1",
      "published_date": "2024-06-15 04:59:00 UTC",
      "updated_date": "2024-06-15 04:59:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:37:24.442965"
    },
    {
      "arxiv_id": "2406.10504v1",
      "title": "Task Facet Learning: A Structured Approach to Prompt Optimization",
      "title_zh": "任务方面学习：一种结构化的提示优化方法",
      "authors": [
        "Gurusha Juneja",
        "Nagarajan Natarajan",
        "Hua Li",
        "Jian Jiao",
        "Amit Sharma"
      ],
      "abstract": "Given a task in the form of a basic description and its training examples,\nprompt optimization is the problem of synthesizing the given information into a\ntext prompt for a large language model (LLM). Humans solve this problem by also\nconsidering the different facets that define a task (e.g., counter-examples,\nexplanations, analogies) and including them in the prompt. However, it is\nunclear whether existing algorithmic approaches, based on iteratively editing a\ngiven prompt or automatically selecting a few in-context examples, can cover\nthe multiple facets required to solve a complex task. In this work, we view\nprompt optimization as that of learning multiple facets of a task from a set of\ntraining examples. We identify and exploit structure in the prompt optimization\nproblem -- first, we find that prompts can be broken down into loosely coupled\nsemantic sections that have a relatively independent effect on the prompt's\nperformance; second, we cluster the input space and use clustered batches so\nthat the optimization procedure can learn the different facets of a task across\nbatches. The resulting algorithm, UniPrompt, consists of a generative model to\ngenerate initial candidates for each prompt section; and a feedback mechanism\nthat aggregates suggested edits from multiple mini-batches into a conceptual\ndescription for the section. Empirical evaluation on multiple datasets and a\nreal-world task shows that prompts generated using UniPrompt obtain higher\naccuracy than human-tuned prompts and those from state-of-the-art methods. In\nparticular, our algorithm can generate long, complex prompts that existing\nmethods are unable to generate. Code for UniPrompt will be available at\n\\url{https://aka.ms/uniprompt}.",
      "tldr_zh": "本研究将提示优化（prompt optimization）视为从训练示例中学习任务的多个方面（如反例、解释和类比），提出了一种结构化方法来解决大型语言模型（LLM）提示合成问题。论文识别出提示可分解为 loosely coupled semantic sections，并通过聚类输入空间（clustered batches）来优化不同批次中的任务方面，开发了 UniPrompt 算法，该算法包括一个生成模型生成初始候选提示部分，以及一个反馈机制聚合建议编辑。实验结果显示，UniPrompt 生成的提示在多个数据集和真实任务上比人类调整的提示和现有方法获得更高准确率，尤其能创建长而复杂的提示；代码可在指定 URL 获得。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10504v1",
      "published_date": "2024-06-15 04:54:26 UTC",
      "updated_date": "2024-06-15 04:54:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:37:39.458442"
    },
    {
      "arxiv_id": "2406.10502v1",
      "title": "Candidate Pseudolabel Learning: Enhancing Vision-Language Models by Prompt Tuning with Unlabeled Data",
      "title_zh": "候选伪标签学习：",
      "authors": [
        "Jiahan Zhang",
        "Qi Wei",
        "Feng Liu",
        "Lei Feng"
      ],
      "abstract": "Fine-tuning vision-language models (VLMs) with abundant unlabeled data\nrecently has attracted increasing attention. Existing methods that resort to\nthe pseudolabeling strategy would suffer from heavily incorrect hard\npseudolabels when VLMs exhibit low zero-shot performance in downstream tasks.\nTo alleviate this issue, we propose a Candidate Pseudolabel Learning method,\ntermed CPL, to fine-tune VLMs with suitable candidate pseudolabels of unlabeled\ndata in downstream tasks. The core of our method lies in the generation\nstrategy of candidate pseudolabels, which progressively generates refined\ncandidate pseudolabels by both intra- and inter-instance label selection, based\non a confidence score matrix for all unlabeled data. This strategy can result\nin better performance in true label inclusion and class-balanced instance\nselection. In this way, we can directly apply existing loss functions to learn\nwith generated candidate psueudolabels. Extensive experiments on nine benchmark\ndatasets with three learning paradigms demonstrate the effectiveness of our\nmethod. Our code can be found at https://github.com/vanillaer/CPL-ICML2024.",
      "tldr_zh": "该研究提出了一种名为Candidate Pseudolabel Learning (CPL)的方法，用于通过提示调整(prompt tuning)增强视觉语言模型(VLMs)，以更好地利用无标签数据。CPL的核心在于基于置信度分数矩阵，通过实例内(intra-instance)和实例间(inter-instance)标签选择策略，逐步生成精炼的候选伪标签，从而提高真实标签包含性和类别平衡实例选择。实验在九个基准数据集上验证了CPL的有效性，适用于多种学习范式，并展示了其在下游任务中的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML2024",
      "pdf_url": "http://arxiv.org/pdf/2406.10502v1",
      "published_date": "2024-06-15 04:50:20 UTC",
      "updated_date": "2024-06-15 04:50:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:37:48.636373"
    },
    {
      "arxiv_id": "2406.10479v2",
      "title": "Unlocking Large Language Model's Planning Capabilities with Maximum Diversity Fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Wenjun Li",
        "Changyu Chen",
        "Pradeep Varakantham"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive task-solving\ncapabilities through prompting techniques and system designs, including solving\nplanning tasks (e.g., math proofs, basic travel planning) when sufficient data\nis available online and used during pre-training. However, for planning tasks\nwith limited prior data (e.g., blocks world, advanced travel planning), the\nperformance of LLMs, including proprietary models like GPT and Gemini, is poor.\nThis paper investigates the impact of fine-tuning on the planning capabilities\nof LLMs, revealing that LLMs can achieve strong performance in planning through\nsubstantial (tens of thousands of specific examples) fine-tuning. Yet, this\nprocess incurs high economic, time, and computational costs for each planning\nproblem variation. To address this, we propose Clustering-Based Maximum\nDiversity Sampling (CMDS), which selects diverse and representative data to\nenhance sample efficiency and the model's generalization capability. Extensive\nevaluations demonstrate that CMDS-l, a baseline method combining CMDS with\nlanguage embeddings, outperforms random sampling. Furthermore, we introduce a\nnovel algorithm, CMDS-g, which encodes planning task instances with their graph\nrepresentations into the embedding space. Empirical results show that CMDS-g\nconsistently outperforms baseline methods across various scales and multiple\nbenchmark domains.",
      "tldr_zh": "大语言模型 (LLMs) 在规划任务上表现有限，尤其是在数据稀缺的场景（如积木世界或高级旅行规划），本文通过大规模微调证明LLMs可显著提升规划能力，但传统微调成本高昂。作者提出Clustering-Based Maximum Diversity Sampling (CMDS) 方法，包括CMDS-l（结合语言嵌入）和CMDS-g（使用图表示编码任务实例），以选择多样性和代表性数据，提高样本效率和模型泛化。实验结果显示，CMDS-g在各种规模和多个基准领域中 consistently 优于随机采样基线，提升了LLMs的规划性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages of main paper, 2 pages of references",
      "pdf_url": "http://arxiv.org/pdf/2406.10479v2",
      "published_date": "2024-06-15 03:06:14 UTC",
      "updated_date": "2025-04-24 15:15:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:38:02.103624"
    },
    {
      "arxiv_id": "2406.10478v2",
      "title": "From Words to Worlds: Transforming One-line Prompt into Immersive Multi-modal Digital Stories with Communicative LLM Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel S. Sohn",
        "Danrui Li",
        "Sen Zhang",
        "Che-Jui Chang",
        "Mubbasir Kapadia"
      ],
      "abstract": "Digital storytelling, essential in entertainment, education, and marketing,\nfaces challenges in production scalability and flexibility. The StoryAgent\nframework, introduced in this paper, utilizes Large Language Models and\ngenerative tools to automate and refine digital storytelling. Employing a\ntop-down story drafting and bottom-up asset generation approach, StoryAgent\ntackles key issues such as manual intervention, interactive scene\norchestration, and narrative consistency. This framework enables efficient\nproduction of interactive and consistent narratives across multiple modalities,\ndemocratizing content creation and enhancing engagement. Our results\ndemonstrate the framework's capability to produce coherent digital stories\nwithout reference videos, marking a significant advancement in automated\ndigital storytelling.",
      "tldr_zh": "该论文介绍了 StoryAgent 框架，利用 Large Language Models (LLMs) 和生成工具来自动化数字故事制作，解决生产规模性和灵活性面临的挑战。框架采用自上而下的故事草拟和自下而上的资产生成方法，处理手动干预、互动场景编排以及叙事一致性等问题，从而高效创建互动且连贯的多模态叙事。实验结果表明，StoryAgent 能够在没有参考视频的情况下生成高质量的数字故事，促进内容创作的民主化和用户参与度。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.10478v2",
      "published_date": "2024-06-15 03:03:43 UTC",
      "updated_date": "2024-06-21 08:09:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:38:13.191936"
    },
    {
      "arxiv_id": "2406.10454v1",
      "title": "HumanPlus: Humanoid Shadowing and Imitation from Humans",
      "title_zh": "翻译失败",
      "authors": [
        "Zipeng Fu",
        "Qingqing Zhao",
        "Qi Wu",
        "Gordon Wetzstein",
        "Chelsea Finn"
      ],
      "abstract": "One of the key arguments for building robots that have similar form factors\nto human beings is that we can leverage the massive human data for training.\nYet, doing so has remained challenging in practice due to the complexities in\nhumanoid perception and control, lingering physical gaps between humanoids and\nhumans in morphologies and actuation, and lack of a data pipeline for humanoids\nto learn autonomous skills from egocentric vision. In this paper, we introduce\na full-stack system for humanoids to learn motion and autonomous skills from\nhuman data. We first train a low-level policy in simulation via reinforcement\nlearning using existing 40-hour human motion datasets. This policy transfers to\nthe real world and allows humanoid robots to follow human body and hand motion\nin real time using only a RGB camera, i.e. shadowing. Through shadowing, human\noperators can teleoperate humanoids to collect whole-body data for learning\ndifferent tasks in the real world. Using the data collected, we then perform\nsupervised behavior cloning to train skill policies using egocentric vision,\nallowing humanoids to complete different tasks autonomously by imitating human\nskills. We demonstrate the system on our customized 33-DoF 180cm humanoid,\nautonomously completing tasks such as wearing a shoe to stand up and walk,\nunloading objects from warehouse racks, folding a sweatshirt, rearranging\nobjects, typing, and greeting another robot with 60-100% success rates using up\nto 40 demonstrations. Project website: https://humanoid-ai.github.io/",
      "tldr_zh": "该论文提出HumanPlus系统，让人形机器人从人类数据中学习动作和自主技能，以克服感知、控制和形态差异的挑战。首先，通过强化学习（reinforcement learning）在模拟环境中训练低级策略，利用现有40小时人类动作数据集，使机器人使用RGB相机实现实时跟随（shadowing）。然后，通过shadowing收集真实世界数据，并应用监督行为克隆（behavior cloning）训练技能策略，使机器人从第一人称视觉（egocentric vision）自主完成任务。在实验中，自定义33-DoF 180cm人形机器人成功执行穿鞋、卸货、叠衣服等任务，成功率达60-100%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "project website: https://humanoid-ai.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2406.10454v1",
      "published_date": "2024-06-15 00:41:34 UTC",
      "updated_date": "2024-06-15 00:41:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:38:25.747073"
    },
    {
      "arxiv_id": "2406.10450v2",
      "title": "TokenRec: Learning to Tokenize ID for LLM-based Generative Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Haohao Qu",
        "Wenqi Fan",
        "Zihuai Zhao",
        "Qing Li"
      ],
      "abstract": "There is a growing interest in utilizing large-scale language models (LLMs)\nto advance next-generation Recommender Systems (RecSys), driven by their\noutstanding language understanding and in-context learning capabilities. In\nthis scenario, tokenizing (i.e., indexing) users and items becomes essential\nfor ensuring a seamless alignment of LLMs with recommendations. While several\nstudies have made progress in representing users and items through textual\ncontents or latent representations, challenges remain in efficiently capturing\nhigh-order collaborative knowledge into discrete tokens that are compatible\nwith LLMs. Additionally, the majority of existing tokenization approaches often\nface difficulties in generalizing effectively to new/unseen users or items that\nwere not in the training corpus. To address these challenges, we propose a\nnovel framework called TokenRec, which introduces not only an effective ID\ntokenization strategy but also an efficient retrieval paradigm for LLM-based\nrecommendations. Specifically, our tokenization strategy, Masked\nVector-Quantized (MQ) Tokenizer, involves quantizing the masked user/item\nrepresentations learned from collaborative filtering into discrete tokens, thus\nachieving a smooth incorporation of high-order collaborative knowledge and a\ngeneralizable tokenization of users and items for LLM-based RecSys. Meanwhile,\nour generative retrieval paradigm is designed to efficiently recommend top-$K$\nitems for users to eliminate the need for the time-consuming auto-regressive\ndecoding and beam search processes used by LLMs, thus significantly reducing\ninference time. Comprehensive experiments validate the effectiveness of the\nproposed methods, demonstrating that TokenRec outperforms competitive\nbenchmarks, including both traditional recommender systems and emerging\nLLM-based recommender systems.",
      "tldr_zh": "该研究提出TokenRec框架，旨在解决大型语言模型(LLMs)应用于生成式推荐系统(RecSys)时，用户和物品ID tokenization的挑战，特别是捕捉高阶协作知识和泛化到新用户/物品的问题。TokenRec的核心方法包括Masked Vector-Quantized (MQ) Tokenizer，将从协作过滤学到的用户/物品表示量化成离散tokens，从而无缝整合协作知识；同时引入生成式检索范式，以高效推荐top-K物品，避免LLMs的耗时自回归解码过程。实验结果显示，TokenRec在多项基准测试中优于传统推荐系统和新兴LLM-based系统，显著提升了推荐性能和效率。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "Submitted to IEEE TKDE. Our code and dataset will be made available\n  upon acceptance of the paper",
      "pdf_url": "http://arxiv.org/pdf/2406.10450v2",
      "published_date": "2024-06-15 00:07:44 UTC",
      "updated_date": "2024-08-18 07:56:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:38:46.964738"
    },
    {
      "arxiv_id": "2406.10449v3",
      "title": "Learning Temporal Logic Predicates from Data with Statistical Guarantees",
      "title_zh": "翻译失败",
      "authors": [
        "Emi Soroka",
        "Rohan Sinha",
        "Sanjay Lall"
      ],
      "abstract": "Temporal logic rules are often used in control and robotics to provide\nstructured, human-interpretable descriptions of trajectory data. These rules\nhave numerous applications including safety validation using formal methods,\nconstraining motion planning among autonomous agents, and classifying data.\nHowever, existing methods for learning temporal logic predicates from data do\nnot provide assurances about the correctness of the resulting predicate. We\npresent a novel method to learn temporal logic predicates from data with\nfinite-sample correctness guarantees. Our approach leverages expression\noptimization and conformal prediction to learn predicates that correctly\ndescribe future trajectories under mild statistical assumptions. We provide\nexperimental results showing the performance of our approach on a simulated\ntrajectory dataset and perform ablation studies to understand how each\ncomponent of our algorithm contributes to its performance.",
      "tldr_zh": "本研究针对时间逻辑谓词在控制和机器人领域用于描述轨迹数据的应用，提出了一种新方法，能够从数据中学习这些谓词并提供有限样本正确性保证（finite-sample correctness guarantees）。该方法结合表达式优化和置信预测（conformal prediction），在温和的统计假设下，确保谓词准确描述未来的轨迹。实验结果显示，该方法在模拟轨迹数据集上表现出色，并通过消融研究验证了算法各组件对性能的贡献。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "As submitted to L4DC 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.10449v3",
      "published_date": "2024-06-15 00:07:36 UTC",
      "updated_date": "2025-04-28 02:56:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:38:49.802757"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 59,
  "processed_papers_count": 59,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T20:39:18.084777"
}