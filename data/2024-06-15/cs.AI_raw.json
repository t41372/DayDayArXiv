[
  {
    "arxiv_id": "2406.10743v1",
    "title": "Occam's Razor for Self Supervised Learning: What is Sufficient to Learn Good Representations?",
    "authors": [
      "Mark Ibrahim",
      "David Klindt",
      "Randall Balestriero"
    ],
    "abstract": "Deep Learning is often depicted as a trio of data-architecture-loss. Yet,\nrecent Self Supervised Learning (SSL) solutions have introduced numerous\nadditional design choices, e.g., a projector network, positive views, or\nteacher-student networks. These additions pose two challenges. First, they\nlimit the impact of theoretical studies that often fail to incorporate all\nthose intertwined designs. Second, they slow-down the deployment of SSL methods\nto new domains as numerous hyper-parameters need to be carefully tuned. In this\nstudy, we bring forward the surprising observation that--at least for\npretraining datasets of up to a few hundred thousands samples--the additional\ndesigns introduced by SSL do not contribute to the quality of the learned\nrepresentations. That finding not only provides legitimacy to existing\ntheoretical studies, but also simplifies the practitioner's path to SSL\ndeployment in numerous small and medium scale settings. Our finding answers a\nlong-lasting question: the often-experienced sensitivity to training settings\nand hyper-parameters encountered in SSL come from their design, rather than the\nabsence of supervised guidance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10743v1",
    "published_date": "2024-06-15 21:42:15 UTC",
    "updated_date": "2024-06-15 21:42:15 UTC"
  },
  {
    "arxiv_id": "2406.10741v1",
    "title": "Speech Emotion Recognition Using CNN and Its Use Case in Digital Healthcare",
    "authors": [
      "Nishargo Nigar"
    ],
    "abstract": "The process of identifying human emotion and affective states from speech is\nknown as speech emotion recognition (SER). This is based on the observation\nthat tone and pitch in the voice frequently convey underlying emotion. Speech\nrecognition includes the ability to recognize emotions, which is becoming\nincreasingly popular and in high demand. With the help of appropriate factors\n(such modalities, emotions, intensities, repetitions, etc.) found in the data,\nmy research seeks to use the Convolutional Neural Network (CNN) to distinguish\nemotions from audio recordings and label them in accordance with the range of\ndifferent emotions. I have developed a machine learning model to identify\nemotions from supplied audio files with the aid of machine learning methods.\nThe evaluation is mostly focused on precision, recall, and F1 score, which are\ncommon machine learning metrics. To properly set up and train the machine\nlearning framework, the main objective is to investigate the influence and\ncross-relation of all input and output parameters. To improve the ability to\nrecognize intentions, a key condition for communication, I have evaluated\nemotions using my specialized machine learning algorithm via voice that would\naddress the emotional state from voice with the help of digital healthcare,\nbridging the gap between human and artificial intelligence (AI).",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Master's Thesis at Hamburg University of Technology",
    "pdf_url": "http://arxiv.org/pdf/2406.10741v1",
    "published_date": "2024-06-15 21:33:03 UTC",
    "updated_date": "2024-06-15 21:33:03 UTC"
  },
  {
    "arxiv_id": "2406.10735v1",
    "title": "How Should We Extract Discrete Audio Tokens from Self-Supervised Models?",
    "authors": [
      "Pooneh Mousavi",
      "Jarod Duret",
      "Salah Zaiem",
      "Luca Della Libera",
      "Artem Ploujnikov",
      "Cem Subakan",
      "Mirco Ravanelli"
    ],
    "abstract": "Discrete audio tokens have recently gained attention for their potential to\nbridge the gap between audio and language processing. Ideal audio tokens must\npreserve content, paralinguistic elements, speaker identity, and many other\naudio details. Current audio tokenization methods fall into two categories:\nSemantic tokens, acquired through quantization of Self-Supervised Learning\n(SSL) models, and Neural compression-based tokens (codecs). Although previous\nstudies have benchmarked codec models to identify optimal configurations, the\nideal setup for quantizing pretrained SSL models remains unclear. This paper\nexplores the optimal configuration of semantic tokens across discriminative and\ngenerative tasks. We propose a scalable solution to train a universal vocoder\nacross multiple SSL layers. Furthermore, an attention mechanism is employed to\nidentify task-specific influential layers, enhancing the adaptability and\nperformance of semantic tokens in diverse audio applications.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "4 pages, 2 figures, 2 tables, Accepted at Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.10735v1",
    "published_date": "2024-06-15 20:43:07 UTC",
    "updated_date": "2024-06-15 20:43:07 UTC"
  },
  {
    "arxiv_id": "2406.10730v1",
    "title": "Order-theoretic models for decision-making: Learning, optimization, complexity and computation",
    "authors": [
      "Pedro Hack"
    ],
    "abstract": "The study of intelligent systems explains behaviour in terms of economic\nrationality. This results in an optimization principle involving a function or\nutility, which states that the system will evolve until the configuration of\nmaximum utility is achieved. Recently, this theory has incorporated\nconstraints, i.e., the optimum is achieved when the utility is maximized while\nrespecting some information-processing constraints. This is reminiscent of\nthermodynamic systems. As such, the study of intelligent systems has benefited\nfrom the tools of thermodynamics. The first aim of this thesis is to clarify\nthe applicability of these results in the study of intelligent systems.\n  We can think of the local transition steps in thermodynamic or intelligent\nsystems as being driven by uncertainty. In fact, the transitions in both\nsystems can be described in terms of majorization. Hence, real-valued\nuncertainty measures like Shannon entropy are simply a proxy for their more\ninvolved behaviour. More in general, real-valued functions are fundamental to\nstudy optimization and complexity in the order-theoretic approach to several\ntopics, including economics, thermodynamics, and quantum mechanics. The second\naim of this thesis is to improve on this classification.\n  The basic similarity between thermodynamic and intelligent systems is based\non an uncertainty notion expressed by a preorder. We can also think of the\ntransitions in the steps of a computational process as a decision-making\nprocedure. In fact, by adding some requirements on the considered order\nstructures, we can build an abstract model of uncertainty reduction that allows\nto incorporate computability, that is, to distinguish the objects that can be\nconstructed by following a finite set of instructions from those that cannot.\nThe third aim of this thesis is to clarify the requirements on the order\nstructure that allow such a framework.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LO",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "PhD thesis",
    "pdf_url": "http://arxiv.org/pdf/2406.10730v1",
    "published_date": "2024-06-15 20:20:43 UTC",
    "updated_date": "2024-06-15 20:20:43 UTC"
  },
  {
    "arxiv_id": "2406.10729v3",
    "title": "A Comprehensive Survey of Foundation Models in Medicine",
    "authors": [
      "Wasif Khan",
      "Seowung Leem",
      "Kyle B. See",
      "Joshua K. Wong",
      "Shaoting Zhang",
      "Ruogu Fang"
    ],
    "abstract": "Foundation models (FMs) are large-scale deep learning models trained on\nmassive datasets, often using self-supervised learning techniques. These models\nserve as a versatile base for a wide range of downstream tasks, including those\nin medicine and healthcare. FMs have demonstrated remarkable success across\nmultiple healthcare domains. However, existing surveys in this field do not\ncomprehensively cover all areas where FMs have made significant strides. In\nthis survey, we present a comprehensive review of FMs in medicine, focusing on\ntheir evolution, learning strategies, flagship models, applications, and\nassociated challenges. We examine how prominent FMs, such as the BERT and GPT\nfamilies, are transforming various aspects of healthcare, including clinical\nlarge language models, medical image analysis, and omics research.\nAdditionally, we provide a detailed taxonomy of FM-enabled healthcare\napplications, spanning clinical natural language processing, medical computer\nvision, graph learning, and other biology- and omics- related tasks. Despite\nthe transformative potentials of FMs, they also pose unique challenges. This\nsurvey delves into these challenges and highlights open research questions and\nlessons learned to guide researchers and practitioners. Our goal is to provide\nvaluable insights into the capabilities of FMs in health, facilitating\nresponsible deployment and mitigating associated risks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Currently under review in IEEE REVIEWS IN BIOMEDICAL ENGINEERING",
    "pdf_url": "http://arxiv.org/pdf/2406.10729v3",
    "published_date": "2024-06-15 20:04:06 UTC",
    "updated_date": "2025-01-16 16:04:07 UTC"
  },
  {
    "arxiv_id": "2407.06196v1",
    "title": "Poetry2Image: An Iterative Correction Framework for Images Generated from Chinese Classical Poetry",
    "authors": [
      "Jing Jiang",
      "Yiran Ling",
      "Binzhu Li",
      "Pengxiang Li",
      "Junming Piao",
      "Yu Zhang"
    ],
    "abstract": "Text-to-image generation models often struggle with key element loss or\nsemantic confusion in tasks involving Chinese classical poetry.Addressing this\nissue through fine-tuning models needs considerable training costs.\nAdditionally, manual prompts for re-diffusion adjustments need professional\nknowledge. To solve this problem, we propose Poetry2Image, an iterative\ncorrection framework for images generated from Chinese classical poetry.\nUtilizing an external poetry dataset, Poetry2Image establishes an automated\nfeedback and correction loop, which enhances the alignment between poetry and\nimage through image generation models and subsequent re-diffusion modifications\nsuggested by large language models (LLM). Using a test set of 200 sentences of\nChinese classical poetry, the proposed method--when integrated with five\npopular image generation models--achieves an average element completeness of\n70.63%, representing an improvement of 25.56% over direct image generation. In\ntests of semantic correctness, our method attains an average semantic\nconsistency of 80.09%. The study not only promotes the dissemination of ancient\npoetry culture but also offers a reference for similar non-fine-tuning methods\nto enhance LLM generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.06196v1",
    "published_date": "2024-06-15 19:45:08 UTC",
    "updated_date": "2024-06-15 19:45:08 UTC"
  },
  {
    "arxiv_id": "2406.10722v1",
    "title": "GenMM: Geometrically and Temporally Consistent Multimodal Data Generation for Video and LiDAR",
    "authors": [
      "Bharat Singh",
      "Viveka Kulharia",
      "Luyu Yang",
      "Avinash Ravichandran",
      "Ambrish Tyagi",
      "Ashish Shrivastava"
    ],
    "abstract": "Multimodal synthetic data generation is crucial in domains such as autonomous\ndriving, robotics, augmented/virtual reality, and retail. We propose a novel\napproach, GenMM, for jointly editing RGB videos and LiDAR scans by inserting\ntemporally and geometrically consistent 3D objects. Our method uses a reference\nimage and 3D bounding boxes to seamlessly insert and blend new objects into\ntarget videos. We inpaint the 2D Regions of Interest (consistent with 3D boxes)\nusing a diffusion-based video inpainting model. We then compute semantic\nboundaries of the object and estimate it's surface depth using state-of-the-art\nsemantic segmentation and monocular depth estimation techniques. Subsequently,\nwe employ a geometry-based optimization algorithm to recover the 3D shape of\nthe object's surface, ensuring it fits precisely within the 3D bounding box.\nFinally, LiDAR rays intersecting with the new object surface are updated to\nreflect consistent depths with its geometry. Our experiments demonstrate the\neffectiveness of GenMM in inserting various 3D objects across video and LiDAR\nmodalities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10722v1",
    "published_date": "2024-06-15 19:29:01 UTC",
    "updated_date": "2024-06-15 19:29:01 UTC"
  },
  {
    "arxiv_id": "2406.10721v1",
    "title": "RoboPoint: A Vision-Language Model for Spatial Affordance Prediction for Robotics",
    "authors": [
      "Wentao Yuan",
      "Jiafei Duan",
      "Valts Blukis",
      "Wilbert Pumacay",
      "Ranjay Krishna",
      "Adithyavairavan Murali",
      "Arsalan Mousavian",
      "Dieter Fox"
    ],
    "abstract": "From rearranging objects on a table to putting groceries into shelves, robots\nmust plan precise action points to perform tasks accurately and reliably. In\nspite of the recent adoption of vision language models (VLMs) to control robot\nbehavior, VLMs struggle to precisely articulate robot actions using language.\nWe introduce an automatic synthetic data generation pipeline that\ninstruction-tunes VLMs to robotic domains and needs. Using the pipeline, we\ntrain RoboPoint, a VLM that predicts image keypoint affordances given language\ninstructions. Compared to alternative approaches, our method requires no\nreal-world data collection or human demonstration, making it much more scalable\nto diverse environments and viewpoints. In addition, RoboPoint is a general\nmodel that enables several downstream applications such as robot navigation,\nmanipulation, and augmented reality (AR) assistance. Our experiments\ndemonstrate that RoboPoint outperforms state-of-the-art VLMs (GPT-4o) and\nvisual prompting techniques (PIVOT) by 21.8% in the accuracy of predicting\nspatial affordance and by 30.5% in the success rate of downstream tasks.\nProject website: https://robo-point.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10721v1",
    "published_date": "2024-06-15 19:22:51 UTC",
    "updated_date": "2024-06-15 19:22:51 UTC"
  },
  {
    "arxiv_id": "2406.10718v1",
    "title": "Stacking for Probabilistic Short-term Load Forecasting",
    "authors": [
      "Grzegorz Dudek"
    ],
    "abstract": "In this study, we delve into the realm of meta-learning to combine point base\nforecasts for probabilistic short-term electricity demand forecasting. Our\napproach encompasses the utilization of quantile linear regression, quantile\nregression forest, and post-processing techniques involving residual simulation\nto generate quantile forecasts. Furthermore, we introduce both global and local\nvariants of meta-learning. In the local-learning mode, the meta-model is\ntrained using patterns most similar to the query pattern.Through extensive\nexperimental studies across 35 forecasting scenarios and employing 16 base\nforecasting models, our findings underscored the superiority of quantile\nregression forest over its competitors",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "International Conference on Computational Science, ICCS'24",
    "pdf_url": "http://arxiv.org/pdf/2406.10718v1",
    "published_date": "2024-06-15 19:05:49 UTC",
    "updated_date": "2024-06-15 19:05:49 UTC"
  },
  {
    "arxiv_id": "2406.10712v1",
    "title": "Object Detection using Oriented Window Learning Vi-sion Transformer: Roadway Assets Recognition",
    "authors": [
      "Taqwa Alhadidi",
      "Ahmed Jaber",
      "Shadi Jaradat",
      "Huthaifa I Ashqar",
      "Mohammed Elhenawy"
    ],
    "abstract": "Object detection is a critical component of transportation systems,\nparticularly for applications such as autonomous driving, traffic monitoring,\nand infrastructure maintenance. Traditional object detection methods often\nstruggle with limited data and variability in object appearance. The Oriented\nWindow Learning Vision Transformer (OWL-ViT) offers a novel approach by\nadapting window orientations to the geometry and existence of objects, making\nit highly suitable for detecting diverse roadway assets. This study leverages\nOWL-ViT within a one-shot learning framework to recognize transportation\ninfrastructure components, such as traffic signs, poles, pavement, and cracks.\nThis study presents a novel method for roadway asset detection using OWL-ViT.\nWe conducted a series of experiments to evaluate the performance of the model\nin terms of detection consistency, semantic flexibility, visual context\nadaptability, resolution robustness, and impact of non-max suppression. The\nresults demonstrate the high efficiency and reliability of the OWL-ViT across\nvarious scenarios, underscoring its potential to enhance the safety and\nefficiency of intelligent transportation systems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10712v1",
    "published_date": "2024-06-15 18:49:42 UTC",
    "updated_date": "2024-06-15 18:49:42 UTC"
  },
  {
    "arxiv_id": "2406.10710v2",
    "title": "SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task",
    "authors": [
      "Ziije Zhong",
      "Linqing Zhong",
      "Zhaoze Sun",
      "Qingyun Jin",
      "Zengchang Qin",
      "Xiaofan Zhang"
    ],
    "abstract": "Integrating Large Language Models (LLMs) with existing Knowledge Graph (KG)\ndatabases presents a promising avenue for enhancing LLMs' efficacy and\nmitigating their \"hallucinations\". Given that most KGs reside in graph\ndatabases accessible solely through specialized query languages (e.g., Cypher),\nit is critical to connect LLMs with KG databases by automating the translation\nof natural language into Cypher queries (termed as \"Text2Cypher\" task). Prior\nefforts tried to bolster LLMs' proficiency in Cypher generation through\nSupervised Fine-Tuning (SFT). However, these explorations are hindered by the\nlack of annotated datasets of Query-Cypher pairs, resulting from the\nlabor-intensive and domain-specific nature of such annotation. In this study,\nwe propose SyntheT2C, a methodology for constructing a synthetic Query-Cypher\npair dataset, comprising two distinct pipelines: (1) LLM-based prompting and\n(2) template-filling. SyntheT2C is applied to two medical KG databases,\nculminating in the creation of a synthetic dataset, MedT2C. Comprehensive\nexperiments demonstrate that the MedT2C dataset effectively enhances the\nperformance of backbone LLMs on Text2Cypher task via SFT. Both the SyntheT2C\ncodebase and the MedT2C dataset are released in\nhttps://github.com/ZGChung/SyntheT2C.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "COLING 2025 paper. 21 pages, 15 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.10710v2",
    "published_date": "2024-06-15 18:43:49 UTC",
    "updated_date": "2025-01-26 07:15:36 UTC"
  },
  {
    "arxiv_id": "2406.15473v2",
    "title": "Intertwining CP and NLP: The Generation of Unreasonably Constrained Sentences",
    "authors": [
      "Alexandre Bonlarron",
      "Jean-Charles Régin"
    ],
    "abstract": "Constrained text generation remains a challenging task, particularly when\ndealing with hard constraints. Traditional NLP approaches prioritize generating\nmeaningful and coherent output. Also, the current state-of-the-art methods\noften lack the expressiveness and constraint satisfaction capabilities to\nhandle such tasks effectively. Recently, an approach for generating constrained\nsentences in CP has been proposed in (Bonlarron et al, 2023). This ad-hoc model\nto solve the sentences generation problem under MNREAD rules proved\nneithertheless to be computationaly and structuraly unsuitable to deal with\nother more constrained problems. In this paper, a novel more generic approach\nis introduced to tackle many of these previously untractable problems, and\nillustrated here with the quite untractable sentences generation problem\nfollowing RADNER rules.\n  More precisely, this paper presents the CPTextGen Framework. This framework\nconsiders a constrained text generation problem as a discrete combinatorial\noptimization problem. It is solved by a constraint programming method that\ncombines linguistic properties (e.g., n-grams or language level) with other\nmore classical constraints (e.g., the number of characters, syllables).\nEventually, a curation phase allows for selecting the best-generated sentences\naccording to perplexity using an LLM.\n  The effectiveness of this approach is demonstrated by tackling a new, more\ntediously constrained text generation problem: the iconic RADNER sentences\nproblem. This problem aims to generate sentences respecting a set of quite\nstrict rules defined by their use in vision and clinical research. Thanks to\nour CP-based approach, many new strongly constrained sentences have been\nsuccessfully generated. This highlights our approach's potential to handle\nunreasonably constrained text generation scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Disambiguation and additional references",
    "pdf_url": "http://arxiv.org/pdf/2406.15473v2",
    "published_date": "2024-06-15 17:40:49 UTC",
    "updated_date": "2024-12-27 14:56:10 UTC"
  },
  {
    "arxiv_id": "2406.10690v3",
    "title": "Automating Pharmacovigilance Evidence Generation: Using Large Language Models to Produce Context-Aware SQL",
    "authors": [
      "Jeffery L. Painter",
      "Venkateswara Rao Chalamalasetti",
      "Raymond Kassekert",
      "Andrew Bate"
    ],
    "abstract": "Objective: To enhance the efficiency and accuracy of information retrieval\nfrom pharmacovigilance (PV) databases by employing Large Language Models (LLMs)\nto convert natural language queries (NLQs) into Structured Query Language (SQL)\nqueries, leveraging a business context document.\n  Materials and Methods: We utilized OpenAI's GPT-4 model within a\nretrieval-augmented generation (RAG) framework, enriched with a business\ncontext document, to transform NLQs into syntactically precise SQL queries.\nEach NLQ was presented to the LLM randomly and independently to prevent\nmemorization. The study was conducted in three phases, varying query\ncomplexity, and assessing the LLM's performance both with and without the\nbusiness context document.\n  Results: Our approach significantly improved NLQ-to-SQL accuracy, increasing\nfrom 8.3\\% with the database schema alone to 78.3\\% with the business context\ndocument. This enhancement was consistent across low, medium, and high\ncomplexity queries, indicating the critical role of contextual knowledge in\nquery generation.\n  Discussion: The integration of a business context document markedly improved\nthe LLM's ability to generate accurate and contextually relevant SQL queries.\nPerformance achieved a maximum of 85\\% when high complexity queries are\nexcluded, suggesting promise for routine deployment.\n  Conclusion: This study presents a novel approach to employing LLMs for safety\ndata retrieval and analysis, demonstrating significant advancements in query\ngeneration accuracy. The methodology offers a framework applicable to various\ndata-intensive domains, enhancing the accessibility and efficiency of\ninformation retrieval for non-technical users.",
    "categories": [
      "cs.AI",
      "cs.DB",
      "H.3.3; I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 3 tables, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.10690v3",
    "published_date": "2024-06-15 17:07:31 UTC",
    "updated_date": "2024-09-04 16:58:25 UTC"
  },
  {
    "arxiv_id": "2406.10686v2",
    "title": "Graph Neural Thompson Sampling",
    "authors": [
      "Shuang Wu",
      "Arash A. Amini"
    ],
    "abstract": "We consider an online decision-making problem with a reward function defined\nover graph-structured data. We formally formulate the problem as an instance of\ngraph action bandit. We then propose \\texttt{GNN-TS}, a Graph Neural Network\n(GNN) powered Thompson Sampling (TS) algorithm which employs a GNN approximator\nfor estimating the mean reward function and the graph neural tangent features\nfor uncertainty estimation. We prove that, under certain boundness assumptions\non the reward function, GNN-TS achieves a state-of-the-art regret bound which\nis (1) sub-linear of order $\\tilde{\\mathcal{O}}((\\tilde{d} T)^{1/2})$ in the\nnumber of interaction rounds, $T$, and a notion of effective dimension\n$\\tilde{d}$, and (2) independent of the number of graph nodes. Empirical\nresults validate that our proposed \\texttt{GNN-TS} exhibits competitive\nperformance and scales well on graph action bandit problems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10686v2",
    "published_date": "2024-06-15 16:45:27 UTC",
    "updated_date": "2024-06-20 20:22:47 UTC"
  },
  {
    "arxiv_id": "2406.11903v1",
    "title": "A Survey of Large Language Models for Financial Applications: Progress, Prospects and Challenges",
    "authors": [
      "Yuqi Nie",
      "Yaxuan Kong",
      "Xiaowen Dong",
      "John M. Mulvey",
      "H. Vincent Poor",
      "Qingsong Wen",
      "Stefan Zohren"
    ],
    "abstract": "Recent advances in large language models (LLMs) have unlocked novel\nopportunities for machine learning applications in the financial domain. These\nmodels have demonstrated remarkable capabilities in understanding context,\nprocessing vast amounts of data, and generating human-preferred contents. In\nthis survey, we explore the application of LLMs on various financial tasks,\nfocusing on their potential to transform traditional practices and drive\ninnovation. We provide a discussion of the progress and advantages of LLMs in\nfinancial contexts, analyzing their advanced technologies as well as\nprospective capabilities in contextual understanding, transfer learning\nflexibility, complex emotion detection, etc. We then highlight this survey for\ncategorizing the existing literature into key application areas, including\nlinguistic tasks, sentiment analysis, financial time series, financial\nreasoning, agent-based modeling, and other applications. For each application\narea, we delve into specific methodologies, such as textual analysis,\nknowledge-based analysis, forecasting, data augmentation, planning, decision\nsupport, and simulations. Furthermore, a comprehensive collection of datasets,\nmodel assets, and useful codes associated with mainstream applications are\npresented as resources for the researchers and practitioners. Finally, we\noutline the challenges and opportunities for future research, particularly\nemphasizing a number of distinctive aspects in this field. We hope our work can\nhelp facilitate the adoption and further development of LLMs in the financial\nsector.",
    "categories": [
      "q-fin.GN",
      "cs.AI",
      "q-fin.CP"
    ],
    "primary_category": "q-fin.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.11903v1",
    "published_date": "2024-06-15 16:11:35 UTC",
    "updated_date": "2024-06-15 16:11:35 UTC"
  },
  {
    "arxiv_id": "2406.15472v1",
    "title": "Hyperbolic sentence representations for solving Textual Entailment",
    "authors": [
      "Igor Petrovski"
    ],
    "abstract": "Hyperbolic spaces have proven to be suitable for modeling data of\nhierarchical nature. As such we use the Poincare ball to embed sentences with\nthe goal of proving how hyperbolic spaces can be used for solving Textual\nEntailment. To this end, apart from the standard datasets used for evaluating\ntextual entailment, we developed two additional datasets. We evaluate against\nbaselines of various backgrounds, including LSTMs, Order Embeddings and\nEuclidean Averaging, which comes as a natural counterpart to representing\nsentences into the Euclidean space. We consistently outperform the baselines on\nthe SICK dataset and are second only to Order Embeddings on the SNLI dataset,\nfor the binary classification version of the entailment task.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.15472v1",
    "published_date": "2024-06-15 15:39:43 UTC",
    "updated_date": "2024-06-15 15:39:43 UTC"
  },
  {
    "arxiv_id": "2406.10670v3",
    "title": "CoLoR-Filter: Conditional Loss Reduction Filtering for Targeted Language Model Pre-training",
    "authors": [
      "David Brandfonbrener",
      "Hanlin Zhang",
      "Andreas Kirsch",
      "Jonathan Richard Schwarz",
      "Sham Kakade"
    ],
    "abstract": "Selecting high-quality data for pre-training is crucial in shaping the\ndownstream task performance of language models. A major challenge lies in\nidentifying this optimal subset, a problem generally considered intractable,\nthus necessitating scalable and effective heuristics. In this work, we propose\na data selection method, CoLoR-Filter (Conditional Loss Reduction Filtering),\nwhich leverages an empirical Bayes-inspired approach to derive a simple and\ncomputationally efficient selection criterion based on the relative loss values\nof two auxiliary models.\n  In addition to the modeling rationale, we evaluate CoLoR-Filter empirically\non two language modeling tasks: (1) selecting data from C4 for domain\nadaptation to evaluation on Books and (2) selecting data from C4 for a suite of\ndownstream multiple-choice question answering tasks. We demonstrate favorable\nscaling both as we subselect more aggressively and using small auxiliary models\nto select data for large target models. As one headline result, CoLoR-Filter\ndata selected using a pair of 150m parameter auxiliary models can train a 1.2b\nparameter target model to match a 1.2b parameter model trained on 25b randomly\nselected tokens with 25x less data for Books and 11x less data for the\ndownstream tasks.\n  Code: https://github.com/davidbrandfonbrener/color-filter-olmo\n  Filtered data:\nhttps://huggingface.co/datasets/davidbrandfonbrener/color-filtered-c4",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10670v3",
    "published_date": "2024-06-15 15:28:02 UTC",
    "updated_date": "2024-10-29 20:26:14 UTC"
  },
  {
    "arxiv_id": "2406.10661v2",
    "title": "A GPU-accelerated Large-scale Simulator for Transportation System Optimization Benchmarking",
    "authors": [
      "Jun Zhang",
      "Wenxuan Ao",
      "Junbo Yan",
      "Depeng Jin",
      "Yong Li"
    ],
    "abstract": "With the development of artificial intelligence techniques, transportation\nsystem optimization is evolving from traditional methods relying on expert\nexperience to simulation and learning-based decision and optimization methods.\nLearning-based optimization methods require extensive interactions with highly\nrealistic microscopic traffic simulators. However, existing microscopic traffic\nsimulators are inefficient in large-scale scenarios and thus fail to support\nthe adoption of these methods in large-scale transportation system optimization\nscenarios. In addition, the optimization scenarios supported by existing\nsimulators are limited, mainly focusing on the traffic signal control. To\naddress these challenges, we propose the first open-source GPU-accelerated\nlarge-scale microscopic simulator for transportation system simulation and\noptimization. The simulator can iterate at 84.09Hz, which achieves 88.92 times\ncomputational acceleration in the large-scale scenario with 2,464,950 vehicles\ncompared to the best baseline CityFlow. Besides, it achieves a more realistic\naverage road speeds simulated on real datasets by adopting the IDM model as the\ncar-following model and the randomized MOBIL model as the lane-changing model.\nBased on it, we implement a set of microscopic and macroscopic controllable\nobjects and metrics provided by Python API to support typical transportation\nsystem optimization scenarios. We choose five representative scenarios and\nbenchmark classical rule-based algorithms, reinforcement learning algorithms,\nand black-box optimization algorithms in four cities. These experiments\neffectively demonstrate the usability of the simulator for large-scale traffic\nsystem optimization. The code of the simulator is available at\nhttps://github.com/tsinghua-fib-lab/moss. We build an open-registration web\nplatform available at https://moss.fiblab.net to support no-code trials.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to ICLR2025",
    "pdf_url": "http://arxiv.org/pdf/2406.10661v2",
    "published_date": "2024-06-15 14:58:17 UTC",
    "updated_date": "2024-10-02 06:43:58 UTC"
  },
  {
    "arxiv_id": "2406.10653v1",
    "title": "Justice in Healthcare Artificial Intelligence in Africa",
    "authors": [
      "Aloysius Ochasi",
      "Abdoul Jalil Djiberou Mahamadou",
      "Russ B. Altman"
    ],
    "abstract": "There is an ongoing debate on balancing the benefits and risks of artificial\nintelligence (AI) as AI is becoming critical to improving healthcare delivery\nand patient outcomes. Such improvements are essential in resource-constrained\nsettings where millions lack access to adequate healthcare services, such as in\nAfrica. AI in such a context can potentially improve the effectiveness,\nefficiency, and accessibility of healthcare services. Nevertheless, the\ndevelopment and use of AI-driven healthcare systems raise numerous ethical,\nlegal, and socio-economic issues. Justice is a major concern in AI that has\nimplications for amplifying social inequities. This paper discusses these\nimplications and related justice concepts such as solidarity, Common Good,\nsustainability, AI bias, and fairness. For Africa to effectively benefit from\nAI, these principles should align with the local context while balancing the\nrisks. Compared to mainstream ethical debates on justice, this perspective\noffers context-specific considerations for equitable healthcare AI development\nin Africa.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.CY",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.10653v1",
    "published_date": "2024-06-15 14:47:03 UTC",
    "updated_date": "2024-06-15 14:47:03 UTC"
  },
  {
    "arxiv_id": "2406.15471v1",
    "title": "Improving Large Models with Small models: Lower Costs and Better Performance",
    "authors": [
      "Dong Chen",
      "Shuo Zhang",
      "Yueting Zhuang",
      "Siliang Tang",
      "Qidong Liu",
      "Hua Wang",
      "Mingliang Xu"
    ],
    "abstract": "Pretrained large models (PLMs), such as ChatGPT, have demonstrated remarkable\nperformance across diverse tasks. However, the significant computational\nrequirements of PLMs have discouraged most product teams from running or\nfine-tuning them. In such cases, to harness the exceptional performance of\nPLMs, one must rely on expensive APIs, thereby exacerbating the economic\nburden. Despite the overall inferior performance of small models, in specific\ndistributions, they can achieve comparable or even superior results.\nConsequently, some input can be processed exclusively by small models. On the\nother hand, certain tasks can be broken down into multiple subtasks, some of\nwhich can be completed without powerful capabilities. Under these\ncircumstances, small models can handle the simple subtasks, allowing large\nmodels to focus on challenging subtasks, thus improving the performance. We\npropose Data Shunt$^+$ (DS$^+$), a general paradigm for collaboration of small\nand large models. DS$^+$ not only substantially reduces the cost associated\nwith querying large models but also effectively improves large models'\nperformance. For instance, ChatGPT achieves an accuracy of $94.43\\%$ on Amazon\nProduct sentiment analysis, and DS$^+$ achieves an accuracy of $95.64\\%$, while\nthe cost has been reduced to only $31.18\\%$. Besides, experiments also prove\nthat the proposed collaborative-based paradigm can better inject specific task\nknowledge into PLMs compared to fine-tuning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.15471v1",
    "published_date": "2024-06-15 14:44:43 UTC",
    "updated_date": "2024-06-15 14:44:43 UTC"
  },
  {
    "arxiv_id": "2406.10632v1",
    "title": "Applications of Generative AI in Healthcare: algorithmic, ethical, legal and societal considerations",
    "authors": [
      "Onyekachukwu R. Okonji",
      "Kamol Yunusov",
      "Bonnie Gordon"
    ],
    "abstract": "Generative AI is rapidly transforming medical imaging and text analysis,\noffering immense potential for enhanced diagnosis and personalized care.\nHowever, this transformative technology raises crucial ethical, societal, and\nlegal questions. This paper delves into these complexities, examining issues of\naccuracy, informed consent, data privacy, and algorithmic limitations in the\ncontext of generative AI's application to medical imaging and text. We explore\nthe legal landscape surrounding liability and accountability, emphasizing the\nneed for robust regulatory frameworks. Furthermore, we dissect the algorithmic\nchallenges, including data biases, model limitations, and workflow integration.\nBy critically analyzing these challenges and proposing responsible solutions,\nwe aim to foster a roadmap for ethical and responsible implementation of\ngenerative AI in healthcare, ensuring its transformative potential serves\nhumanity with utmost care and precision.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10632v1",
    "published_date": "2024-06-15 13:28:07 UTC",
    "updated_date": "2024-06-15 13:28:07 UTC"
  },
  {
    "arxiv_id": "2406.10630v1",
    "title": "Emerging Safety Attack and Defense in Federated Instruction Tuning of Large Language Models",
    "authors": [
      "Rui Ye",
      "Jingyi Chai",
      "Xiangrui Liu",
      "Yaodong Yang",
      "Yanfeng Wang",
      "Siheng Chen"
    ],
    "abstract": "Federated learning (FL) enables multiple parties to collaboratively fine-tune\nan large language model (LLM) without the need of direct data sharing. Ideally,\nby training on decentralized data that is aligned with human preferences and\nsafety principles, federated instruction tuning can result in an LLM that could\nbehave in a helpful and safe manner. In this paper, we for the first time\nreveal the vulnerability of safety alignment in FedIT by proposing a simple,\nstealthy, yet effective safety attack method. Specifically, the malicious\nclients could automatically generate attack data without involving manual\nefforts and attack the FedIT system by training their local LLMs on such attack\ndata. Unfortunately, this proposed safety attack not only can compromise the\nsafety alignment of LLM trained via FedIT, but also can not be effectively\ndefended against by many existing FL defense methods. Targeting this, we\nfurther propose a post-hoc defense method, which could rely on a fully\nautomated pipeline: generation of defense data and further fine-tuning of the\nLLM. Extensive experiments show that our safety attack method can significantly\ncompromise the LLM's safety alignment (e.g., reduce safety rate by 70\\%), which\ncan not be effectively defended by existing defense methods (at most 4\\%\nabsolute improvement), while our safety defense method can significantly\nenhance the attacked LLM's safety alignment (at most 69\\% absolute\nimprovement).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.10630v1",
    "published_date": "2024-06-15 13:24:22 UTC",
    "updated_date": "2024-06-15 13:24:22 UTC"
  },
  {
    "arxiv_id": "2406.12929v1",
    "title": "RMF: A Risk Measurement Framework for Machine Learning Models",
    "authors": [
      "Jan Schröder",
      "Jakub Breier"
    ],
    "abstract": "Machine learning (ML) models are used in many safety- and security-critical\napplications nowadays. It is therefore important to measure the security of a\nsystem that uses ML as a component. This paper focuses on the field of ML,\nparticularly the security of autonomous vehicles. For this purpose, a technical\nframework will be described, implemented, and evaluated in a case study. Based\non ISO/IEC 27004:2016, risk indicators are utilized to measure and evaluate the\nextent of damage and the effort required by an attacker. It is not possible,\nhowever, to determine a single risk value that represents the attacker's\neffort. Therefore, four different values must be interpreted individually.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at CSA@ARES 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.12929v1",
    "published_date": "2024-06-15 13:22:47 UTC",
    "updated_date": "2024-06-15 13:22:47 UTC"
  },
  {
    "arxiv_id": "2406.10628v1",
    "title": "Public Computer Vision Datasets for Precision Livestock Farming: A Systematic Survey",
    "authors": [
      "Anil Bhujel",
      "Yibin Wang",
      "Yuzhen Lu",
      "Daniel Morris",
      "Mukesh Dangol"
    ],
    "abstract": "Technology-driven precision livestock farming (PLF) empowers practitioners to\nmonitor and analyze animal growth and health conditions for improved\nproductivity and welfare. Computer vision (CV) is indispensable in PLF by using\ncameras and computer algorithms to supplement or supersede manual efforts for\nlivestock data acquisition. Data availability is crucial for developing\ninnovative monitoring and analysis systems through artificial\nintelligence-based techniques. However, data curation processes are tedious,\ntime-consuming, and resource intensive. This study presents the first\nsystematic survey of publicly available livestock CV datasets\n(https://github.com/Anil-Bhujel/Public-Computer-Vision-Dataset-A-Systematic-Survey).\nAmong 58 public datasets identified and analyzed, encompassing different\nspecies of livestock, almost half of them are for cattle, followed by swine,\npoultry, and other animals. Individual animal detection and color imaging are\nthe dominant application and imaging modality for livestock. The\ncharacteristics and baseline applications of the datasets are discussed,\nemphasizing the implications for animal welfare advocates. Challenges and\nopportunities are also discussed to inspire further efforts in developing\nlivestock CV datasets. This study highlights that the limited quantity of\nhigh-quality annotated datasets collected from diverse environments, animals,\nand applications, the absence of contextual metadata, are a real bottleneck in\nPLF.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10628v1",
    "published_date": "2024-06-15 13:22:41 UTC",
    "updated_date": "2024-06-15 13:22:41 UTC"
  },
  {
    "arxiv_id": "2406.10621v3",
    "title": "StrucText-Eval: Evaluating Large Language Model's Reasoning Ability in Structure-Rich Text",
    "authors": [
      "Zhouhong Gu",
      "Haoning Ye",
      "Xingzhou Chen",
      "Zeyang Zhou",
      "Hongwei Feng",
      "Yanghua Xiao"
    ],
    "abstract": "The effective utilization of structured data, integral to corporate data\nstrategies, has been challenged by the rise of large language models (LLMs)\ncapable of processing unstructured information. This shift prompts the\nquestion: can LLMs interpret structured data directly in its unstructured form?\nWe propose an automatic evaluation data generation method for assessing LLMs'\nreasoning capabilities on structure-rich text to explore this. Our approach\nsupports 8 structured languages and 29 tasks, generating data with adjustable\ncomplexity through controllable nesting and structural width. We introduce\nStrucText-Eval, a benchmark containing 5,800 pre-generated and annotated\nsamples designed to evaluate how well LLMs understand and reason through\nstructured text. StrucText-Eval is divided into two suites: a regular Test\nsuite (3,712 samples) and a Test-Hard suite (2,088 samples), the latter\nemphasizing the gap between human and model performance on more complex tasks.\nExperimental results show that while open-source LLMs achieve a maximum\naccuracy of 74.9\\% on the standard dataset, their performance drops\nsignificantly to 45.8\\% on the harder dataset. In contrast, human participants\nreach an accuracy of 92.6\\% on StrucText-Eval-Hard, highlighting LLMs' current\nlimitations in handling intricate structural information. The benchmark and\ngeneration codes are open sourced in\n\\url{https://github.com/MikeGu721/StrucText-Eval}",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10621v3",
    "published_date": "2024-06-15 12:48:00 UTC",
    "updated_date": "2024-10-21 11:06:06 UTC"
  },
  {
    "arxiv_id": "2407.12004v1",
    "title": "An investigation into the scientific landscape of the conversational and generative artificial intelligence, and human-chatbot interaction in education and research",
    "authors": [
      "Ikpe Justice Akpan",
      "Yawo M. Kobara",
      "Josiah Owolabi",
      "Asuama Akpam",
      "Onyebuchi Felix Offodile"
    ],
    "abstract": "Artificial intelligence (AI) as a disruptive technology is not new. However,\nits recent evolution, engineered by technological transformation, big data\nanalytics, and quantum computing, produces conversational and generative AI\n(CGAI/GenAI) and human-like chatbots that disrupt conventional operations and\nmethods in different fields. This study investigates the scientific landscape\nof CGAI and human-chatbot interaction/collaboration and evaluates use cases,\nbenefits, challenges, and policy implications for multidisciplinary education\nand allied industry operations. The publications trend showed that just 4%\n(n=75) occurred during 2006-2018, while 2019-2023 experienced astronomical\ngrowth (n=1763 or 96%). The prominent use cases of CGAI (e.g., ChatGPT) for\nteaching, learning, and research activities occurred in computer science\n[multidisciplinary and AI] (32%), medical/healthcare (17%), engineering (7%),\nand business fields (6%). The intellectual structure shows strong collaboration\namong eminent multidisciplinary sources in business, Information Systems, and\nother areas. The thematic structure of SLP highlights prominent CGAI use cases,\nincluding improved user experience in human-computer interaction, computer\nprograms/code generation, and systems creation. Widespread CGAI usefulness for\nteachers, researchers, and learners includes syllabi/course content generation,\ntesting aids, and academic writing. The concerns about abuse and misuse\n(plagiarism, academic integrity, privacy violations) and issues about\nmisinformation, danger of self-diagnoses, and patient privacy in\nmedical/healthcare applications are prominent. Formulating strategies and\npolicies to address potential CGAI challenges in teaching/learning and practice\nare priorities. Developing discipline-based automatic detection of GenAI\ncontents to check abuse is proposed.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "14J60 (Primary) 14F05, 14J26 (Secondary), 68T05 (Primary) 68Q32,\n  97P80 (Secondary)",
      "I.2.6; K.3.2"
    ],
    "primary_category": "cs.CY",
    "comment": "The study analyzes the implications of AI adoption in education and\n  research and offer policy recommendations to overcome challenges; shows the\n  intellectual structure and collaboration among eminent sources contributing\n  AI discourse; highlights the use cases, benefits, and challenges of GenAI;\n  examines techniques for GenAI integration with modeling and decision support\n  systems, and existing gaps",
    "pdf_url": "http://arxiv.org/pdf/2407.12004v1",
    "published_date": "2024-06-15 12:37:29 UTC",
    "updated_date": "2024-06-15 12:37:29 UTC"
  },
  {
    "arxiv_id": "2406.10615v2",
    "title": "Leveraging Locality to Boost Sample Efficiency in Robotic Manipulation",
    "authors": [
      "Tong Zhang",
      "Yingdong Hu",
      "Jiacheng You",
      "Yang Gao"
    ],
    "abstract": "Given the high cost of collecting robotic data in the real world, sample\nefficiency is a consistently compelling pursuit in robotics. In this paper, we\nintroduce SGRv2, an imitation learning framework that enhances sample\nefficiency through improved visual and action representations. Central to the\ndesign of SGRv2 is the incorporation of a critical inductive bias-action\nlocality, which posits that robot's actions are predominantly influenced by the\ntarget object and its interactions with the local environment. Extensive\nexperiments in both simulated and real-world settings demonstrate that action\nlocality is essential for boosting sample efficiency. SGRv2 excels in RLBench\ntasks with keyframe control using merely 5 demonstrations and surpasses the RVT\nbaseline in 23 of 26 tasks. Furthermore, when evaluated on ManiSkill2 and\nMimicGen using dense control, SGRv2's success rate is 2.54 times that of SGR.\nIn real-world environments, with only eight demonstrations, SGRv2 can perform a\nvariety of tasks at a markedly higher success rate compared to baseline models.\nProject website: http://sgrv2-robot.github.io",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "CoRL 2024. Project website: http://sgrv2-robot.github.io",
    "pdf_url": "http://arxiv.org/pdf/2406.10615v2",
    "published_date": "2024-06-15 12:27:35 UTC",
    "updated_date": "2024-09-26 12:55:43 UTC"
  },
  {
    "arxiv_id": "2406.12928v1",
    "title": "Evaluating the Generalization Ability of Quantized LLMs: Benchmark, Analysis, and Toolbox",
    "authors": [
      "Yijun Liu",
      "Yuan Meng",
      "Fang Wu",
      "Shenhao Peng",
      "Hang Yao",
      "Chaoyu Guan",
      "Chen Tang",
      "Xinzhu Ma",
      "Zhi Wang",
      "Wenwu Zhu"
    ],
    "abstract": "Large language models (LLMs) have exhibited exciting progress in multiple\nscenarios, while the huge computational demands hinder their deployments in\nlots of real-world applications. As an effective means to reduce memory\nfootprint and inference cost, quantization also faces challenges in performance\ndegradation at low bit-widths. Understanding the impact of quantization on LLM\ncapabilities, especially the generalization ability, is crucial. However, the\ncommunity's main focus remains on the algorithms and models of quantization,\nwith insufficient attention given to whether the quantized models can retain\nthe strong generalization abilities of LLMs. In this work, we fill this gap by\nproviding a comprehensive benchmark suite for this research topic, including an\nevaluation system, detailed analyses, and a general toolbox. Specifically,\nbased on the dominant pipeline in LLM quantization, we primarily explore the\nimpact of calibration data distribution on the generalization of quantized LLMs\nand conduct the benchmark using more than 40 datasets within two main\nscenarios. Based on this benchmark, we conduct extensive experiments with two\nwell-known LLMs (English and Chinese) and four quantization algorithms to\ninvestigate this topic in-depth, yielding several counter-intuitive and\nvaluable findings, e.g., models quantized using a calibration set with the same\ndistribution as the test data are not necessarily optimal. Besides, to\nfacilitate future research, we also release a modular-designed toolbox, which\ndecouples the overall pipeline into several separate components, e.g., base LLM\nmodule, dataset module, quantizer module, etc. and allows subsequent\nresearchers to easily assemble their methods through a simple configuration.\nOur benchmark suite is publicly available at\nhttps://github.com/TsingmaoAI/MI-optimize",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.12928v1",
    "published_date": "2024-06-15 12:02:14 UTC",
    "updated_date": "2024-06-15 12:02:14 UTC"
  },
  {
    "arxiv_id": "2406.10593v2",
    "title": "QDA-SQL: Questions Enhanced Dialogue Augmentation for Multi-Turn Text-to-SQL",
    "authors": [
      "Yinggang Sun",
      "Ziming Guo",
      "Haining Yu",
      "Chuanyi Liu",
      "Xiang Li",
      "Bingxuan Wang",
      "Xiangzhan Yu",
      "Tiancheng Zhao"
    ],
    "abstract": "Fine-tuning large language models (LLMs) for specific domain tasks has\nachieved great success in Text-to-SQL tasks. However, these fine-tuned models\noften face challenges with multi-turn Text-to-SQL tasks caused by ambiguous or\nunanswerable questions. It is desired to enhance LLMs to handle multiple types\nof questions in multi-turn Text-to-SQL tasks. To address this, we propose a\nnovel data augmentation method, called QDA-SQL, which generates multiple types\nof multi-turn Q\\&A pairs using LLMs. In QDA-SQL, we introduce a method\nincorporating validation and correction mechanisms to handle complex multi-turn\nText-to-SQL tasks. Experimental results demonstrate that QDA-SQL enables\nfine-tuned models to exhibit higher performance on SQL statement accuracy and\nenhances their ability to handle complex, unanswerable questions in multi-turn\nText-to-SQL tasks. The generation script and test set are released at\nhttps://github.com/mcxiaoxiao/QDA-SQL",
    "categories": [
      "cs.AI",
      "cs.DB",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.10593v2",
    "published_date": "2024-06-15 10:54:54 UTC",
    "updated_date": "2024-11-10 13:45:48 UTC"
  },
  {
    "arxiv_id": "2406.15470v2",
    "title": "Mental Disorder Classification via Temporal Representation of Text",
    "authors": [
      "Raja Kumar",
      "Kishan Maharaj",
      "Ashita Saxena",
      "Pushpak Bhattacharyya"
    ],
    "abstract": "Mental disorders pose a global challenge, aggravated by the shortage of\nqualified mental health professionals. Mental disorder prediction from social\nmedia posts by current LLMs is challenging due to the complexities of\nsequential text data and the limited context length of language models. Current\nlanguage model-based approaches split a single data instance into multiple\nchunks to compensate for limited context size. The predictive model is then\napplied to each chunk individually, and the most voted output is selected as\nthe final prediction. This results in the loss of inter-post dependencies and\nimportant time variant information, leading to poor performance. We propose a\nnovel framework which first compresses the large sequence of chronologically\nordered social media posts into a series of numbers. We then use this time\nvariant representation for mental disorder classification. We demonstrate the\ngeneralization capabilities of our framework by outperforming the current SOTA\nin three different mental conditions: depression, self-harm, and anorexia, with\nan absolute improvement of 5% in the F1 score. We investigate the situation\nwhere current data instances fall within the context length of language models\nand present empirical results highlighting the importance of temporal\nproperties of textual data. Furthermore, we utilize the proposed framework for\na cross-domain study, exploring commonalities across disorders and the\npossibility of inter-domain data usage.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "RK and KM contributed equally to this work, 15 pages, 5 figures, 9\n  table",
    "pdf_url": "http://arxiv.org/pdf/2406.15470v2",
    "published_date": "2024-06-15 10:53:21 UTC",
    "updated_date": "2024-10-06 06:27:23 UTC"
  },
  {
    "arxiv_id": "2406.10591v1",
    "title": "MINT: a Multi-modal Image and Narrative Text Dubbing Dataset for Foley Audio Content Planning and Generation",
    "authors": [
      "Ruibo Fu",
      "Shuchen Shi",
      "Hongming Guo",
      "Tao Wang",
      "Chunyu Qiang",
      "Zhengqi Wen",
      "Jianhua Tao",
      "Xin Qi",
      "Yi Lu",
      "Xiaopeng Wang",
      "Zhiyong Wang",
      "Yukun Liu",
      "Xuefei Liu",
      "Shuai Zhang",
      "Guanjun Li"
    ],
    "abstract": "Foley audio, critical for enhancing the immersive experience in multimedia\ncontent, faces significant challenges in the AI-generated content (AIGC)\nlandscape. Despite advancements in AIGC technologies for text and image\ngeneration, the foley audio dubbing remains rudimentary due to difficulties in\ncross-modal scene matching and content correlation. Current text-to-audio\ntechnology, which relies on detailed and acoustically relevant textual\ndescriptions, falls short in practical video dubbing applications. Existing\ndatasets like AudioSet, AudioCaps, Clotho, Sound-of-Story, and WavCaps do not\nfully meet the requirements for real-world foley audio dubbing task. To address\nthis, we introduce the Multi-modal Image and Narrative Text Dubbing Dataset\n(MINT), designed to enhance mainstream dubbing tasks such as literary story\naudiobooks dubbing, image/silent video dubbing. Besides, to address the\nlimitations of existing TTA technology in understanding and planning complex\nprompts, a Foley Audio Content Planning, Generation, and Alignment (CPGA)\nframework is proposed, which includes a content planning module leveraging\nlarge language models for complex multi-modal prompts comprehension.\nAdditionally, the training process is optimized using Proximal Policy\nOptimization based reinforcement learning, significantly improving the\nalignment and auditory realism of generated foley audio. Experimental results\ndemonstrate that our approach significantly advances the field of foley audio\ndubbing, providing robust solutions for the challenges of multi-modal dubbing.\nEven when utilizing the relatively lightweight GPT-2 model, our framework\noutperforms open-source multimodal large models such as LLaVA, DeepSeek-VL, and\nMoondream2. The dataset is available at https://github.com/borisfrb/MINT .",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CV",
      "cs.MM",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10591v1",
    "published_date": "2024-06-15 10:47:36 UTC",
    "updated_date": "2024-06-15 10:47:36 UTC"
  },
  {
    "arxiv_id": "2406.10574v2",
    "title": "Large Language Models Playing Mixed Strategy Nash Equilibrium Games",
    "authors": [
      "Alonso Silva"
    ],
    "abstract": "Generative artificial intelligence (Generative AI), and in particular Large\nLanguage Models (LLMs) have gained significant popularity among researchers and\nindustrial communities, paving the way for integrating LLMs in different\ndomains, such as robotics, telecom, and healthcare. In this paper, we study the\nintersection of game theory and generative artificial intelligence, focusing on\nthe capabilities of LLMs to find the Nash equilibrium in games with a mixed\nstrategy Nash equilibrium and no pure strategy Nash equilibrium (that we denote\nmixed strategy Nash equilibrium games). The study reveals a significant\nenhancement in the performance of LLMs when they are equipped with the\npossibility to run code and are provided with a specific prompt to incentivize\nthem to do so. However, our research also highlights the limitations of LLMs\nwhen the randomization strategy of the game is not easy to deduce. It is\nevident that while LLMs exhibit remarkable proficiency in well-known standard\ngames, their performance dwindles when faced with slight modifications of the\nsame games. This paper aims to contribute to the growing body of knowledge on\nthe intersection of game theory and generative artificial intelligence while\nproviding valuable insights into LLMs strengths and weaknesses. It also\nunderscores the need for further research to overcome the limitations of LLMs,\nparticularly in dealing with even slightly more complex scenarios, to harness\ntheir full potential.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10574v2",
    "published_date": "2024-06-15 09:30:20 UTC",
    "updated_date": "2024-10-12 07:32:26 UTC"
  },
  {
    "arxiv_id": "2406.10573v2",
    "title": "Graph Neural Backdoor: Fundamentals, Methodologies, Applications, and Future Directions",
    "authors": [
      "Xiao Yang",
      "Gaolei Li",
      "Jianhua Li"
    ],
    "abstract": "Graph Neural Networks (GNNs) have significantly advanced various downstream\ngraph-relevant tasks, encompassing recommender systems, molecular structure\nprediction, social media analysis, etc. Despite the boosts of GNN, recent\nresearch has empirically demonstrated its potential vulnerability to backdoor\nattacks, wherein adversaries employ triggers to poison input samples, inducing\nGNN to adversary-premeditated malicious outputs. This is typically due to the\ncontrolled training process, or the deployment of untrusted models, such as\ndelegating model training to third-party service, leveraging external training\nsets, and employing pre-trained models from online sources. Although there's an\nongoing increase in research on GNN backdoors, comprehensive investigation into\nthis field is lacking. To bridge this gap, we propose the first survey\ndedicated to GNN backdoors. We begin by outlining the fundamental definition of\nGNN, followed by the detailed summarization and categorization of current GNN\nbackdoor attacks and defenses based on their technical characteristics and\napplication scenarios. Subsequently, the analysis of the applicability and use\ncases of GNN backdoors is undertaken. Finally, the exploration of potential\nresearch directions of GNN backdoors is presented. This survey aims to explore\nthe principles of graph backdoors, provide insights to defenders, and promote\nfuture security research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10573v2",
    "published_date": "2024-06-15 09:23:46 UTC",
    "updated_date": "2025-01-07 11:13:06 UTC"
  },
  {
    "arxiv_id": "2406.16933v1",
    "title": "SGSM: A Foundation-model-like Semi-generalist Sensing Model",
    "authors": [
      "Tianjian Yang",
      "Hao Zhou",
      "Shuo Liu",
      "Kaiwen Guo",
      "Yiwen Hou",
      "Haohua Du",
      "Zhi Liu",
      "Xiang-Yang Li"
    ],
    "abstract": "The significance of intelligent sensing systems is growing in the realm of\nsmart services. These systems extract relevant signal features and generate\ninformative representations for particular tasks. However, building the feature\nextraction component for such systems requires extensive domain-specific\nexpertise or data. The exceptionally rapid development of foundation models is\nlikely to usher in newfound abilities in such intelligent sensing. We propose a\nnew scheme for sensing model, which we refer to as semi-generalist sensing\nmodel (SGSM). SGSM is able to semiautomatically solve various tasks using\nrelatively less task-specific labeled data compared to traditional systems.\nBuilt through the analysis of the common theoretical model, SGSM can depict\ndifferent modalities, such as the acoustic and Wi-Fi signal. Experimental\nresults on such two heterogeneous sensors illustrate that SGSM functions across\na wide range of scenarios, thereby establishing its broad applicability. In\nsome cases, SGSM even achieves better performance than sensor-specific\nspecialized solutions. Wi-Fi evaluations indicate a 20\\% accuracy improvement\nwhen applying SGSM to an existing sensing model.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16933v1",
    "published_date": "2024-06-15 09:20:46 UTC",
    "updated_date": "2024-06-15 09:20:46 UTC"
  },
  {
    "arxiv_id": "2406.10563v2",
    "title": "Privacy-Preserving Heterogeneous Federated Learning for Sensitive Healthcare Data",
    "authors": [
      "Yukai Xu",
      "Jingfeng Zhang",
      "Yujie Gu"
    ],
    "abstract": "In the realm of healthcare where decentralized facilities are prevalent,\nmachine learning faces two major challenges concerning the protection of data\nand models. The data-level challenge concerns the data privacy leakage when\ncentralizing data with sensitive personal information. While the model-level\nchallenge arises from the heterogeneity of local models, which need to be\ncollaboratively trained while ensuring their confidentiality to address\nintellectual property concerns. To tackle these challenges, we propose a new\nframework termed Abstention-Aware Federated Voting (AAFV) that can\ncollaboratively and confidentially train heterogeneous local models while\nsimultaneously protecting the data privacy. This is achieved by integrating a\nnovel abstention-aware voting mechanism and a differential privacy mechanism\nonto local models' predictions. In particular, the proposed abstention-aware\nvoting mechanism exploits a threshold-based abstention method to select\nhigh-confidence votes from heterogeneous local models, which not only enhances\nthe learning utility but also protects model confidentiality. Furthermore, we\nimplement AAFV on two practical prediction tasks of diabetes and in-hospital\npatient mortality. The experiments demonstrate the effectiveness and\nconfidentiality of AAFV in testing accuracy and privacy protection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the 2024 IEEE Conference on Artificial Intelligence (IEEE\n  CAI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.10563v2",
    "published_date": "2024-06-15 08:43:40 UTC",
    "updated_date": "2024-07-04 14:10:00 UTC"
  },
  {
    "arxiv_id": "2406.10557v5",
    "title": "Explain the Black Box for the Sake of Science: the Scientific Method in the Era of Generative Artificial Intelligence",
    "authors": [
      "Gianmarco Mengaldo"
    ],
    "abstract": "The scientific method is the cornerstone of human progress across all\nbranches of the natural and applied sciences, from understanding the human body\nto explaining how the universe works. The scientific method is based on\nidentifying systematic rules or principles that describe the phenomenon of\ninterest in a reproducible way that can be validated through experimental\nevidence. In the era of generative artificial intelligence, there are\ndiscussions on how AI systems may discover new knowledge. We argue that human\ncomplex reasoning for scientific discovery remains of vital importance, at\nleast before the advent of artificial general intelligence. Yet, AI can be\nleveraged for scientific discovery via explainable AI. More specifically,\nknowing the `principles' the AI systems used to make decisions can be a point\nof contact with domain experts and scientists, that can lead to divergent or\nconvergent views on a given scientific problem. Divergent views may spark\nfurther scientific investigations leading to interpretability-guided\nexplanations (IGEs), and possibly to new scientific knowledge. We define this\nfield as Explainable AI for Science, where domain experts -- potentially\nassisted by generative AI -- formulate scientific hypotheses and explanations\nbased on the interpretability of a predictive AI system.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "math.DS"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10557v5",
    "published_date": "2024-06-15 08:34:42 UTC",
    "updated_date": "2025-02-27 06:54:31 UTC"
  },
  {
    "arxiv_id": "2406.10556v1",
    "title": "Multi-User Semantic Fusion for Semantic Communications over Degraded Broadcast Channels",
    "authors": [
      "Tong Wu",
      "Zhiyong Chen",
      "Meixia Tao",
      "Bin Xia",
      "Wenjun Zhang"
    ],
    "abstract": "Degraded broadcast channels (DBC) are a typical multiuser communication\nscenario, Semantic communications over DBC still lack in-depth research. In\nthis paper, we design a semantic communications approach based on multi-user\nsemantic fusion for wireless image transmission over DBC. In the proposed\nmethod, the transmitter extracts semantic features for two users separately. It\nthen effectively fuses these semantic features for broadcasting by leveraging\nsemantic similarity. Unlike traditional allocation of time, power, or\nbandwidth, the semantic fusion scheme can dynamically control the weight of the\nsemantic features of the two users to balance the performance between the two\nusers. Considering the different channel state information (CSI) of both users\nover DBC, a DBC-Aware method is developed that embeds the CSI of both users\ninto the joint source-channel coding encoder and fusion module to adapt to the\nchannel. Experimental results show that the proposed system outperforms the\ntraditional broadcasting schemes.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "accepted by China Communications",
    "pdf_url": "http://arxiv.org/pdf/2406.10556v1",
    "published_date": "2024-06-15 08:19:59 UTC",
    "updated_date": "2024-06-15 08:19:59 UTC"
  },
  {
    "arxiv_id": "2406.11900v1",
    "title": "Horizon-wise Learning Paradigm Promotes Gene Splicing Identification",
    "authors": [
      "Qi-Jie Li",
      "Qian Sun",
      "Shao-Qun Zhang"
    ],
    "abstract": "Identifying gene splicing is a core and significant task confronted in modern\ncollaboration between artificial intelligence and bioinformatics. Past decades\nhave witnessed great efforts on this concern, such as the bio-plausible\nsplicing pattern AT-CG and the famous SpliceAI. In this paper, we propose a\nnovel framework for the task of gene splicing identification, named\nHorizon-wise Gene Splicing Identification (H-GSI). The proposed H-GSI follows\nthe horizon-wise identification paradigm and comprises four components: the\npre-processing procedure transforming string data into tensors, the sliding\nwindow technique handling long sequences, the SeqLab model, and the predictor.\nIn contrast to existing studies that process gene information with a truncated\nfixed-length sequence, H-GSI employs a horizon-wise identification paradigm in\nwhich all positions in a sequence are predicted with only one forward\ncomputation, improving accuracy and efficiency. The experiments conducted on\nthe real-world Human dataset show that our proposed H-GSI outperforms SpliceAI\nand achieves the best accuracy of 97.20\\%. The source code is available from\nthis link.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.11900v1",
    "published_date": "2024-06-15 08:18:09 UTC",
    "updated_date": "2024-06-15 08:18:09 UTC"
  },
  {
    "arxiv_id": "2406.10552v4",
    "title": "Large Language Model Enhanced Clustering for News Event Detection",
    "authors": [
      "Adane Nega Tarekegn"
    ],
    "abstract": "The news landscape is continuously evolving, with an ever-increasing volume\nof information from around the world. Automated event detection within this\nvast data repository is essential for monitoring, identifying, and categorizing\nsignificant news occurrences across diverse platforms. This paper presents an\nevent detection framework that leverages Large Language Models (LLMs) combined\nwith clustering analysis to detect news events from the Global Database of\nEvents, Language, and Tone (GDELT). The framework enhances event clustering\nthrough both pre-event detection tasks (keyword extraction and text embedding)\nand post-event detection tasks (event summarization and topic labelling). We\nalso evaluate the impact of various textual embeddings on the quality of\nclustering outcomes, ensuring robust news categorization. Additionally, we\nintroduce a novel Cluster Stability Assessment Index (CSAI) to assess the\nvalidity and robustness of clustering results. CSAI utilizes multiple feature\nvectors to provide a new way of measuring clustering quality. Our experiments\nindicate that the use of LLM embedding in the event detection framework has\nsignificantly improved the results, demonstrating greater robustness in terms\nof CSAI scores. Moreover, post-event detection tasks generate meaningful\ninsights, facilitating effective interpretation of event clustering results.\nOverall, our experimental results indicate that the proposed framework offers\nvaluable insights and could enhance the accuracy in news analysis and\nreporting.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10552v4",
    "published_date": "2024-06-15 08:13:47 UTC",
    "updated_date": "2024-07-06 09:19:08 UTC"
  },
  {
    "arxiv_id": "2406.10543v1",
    "title": "NeRFDeformer: NeRF Transformation from a Single View via 3D Scene Flows",
    "authors": [
      "Zhenggang Tang",
      "Zhongzheng Ren",
      "Xiaoming Zhao",
      "Bowen Wen",
      "Jonathan Tremblay",
      "Stan Birchfield",
      "Alexander Schwing"
    ],
    "abstract": "We present a method for automatically modifying a NeRF representation based\non a single observation of a non-rigid transformed version of the original\nscene. Our method defines the transformation as a 3D flow, specifically as a\nweighted linear blending of rigid transformations of 3D anchor points that are\ndefined on the surface of the scene. In order to identify anchor points, we\nintroduce a novel correspondence algorithm that first matches RGB-based pairs,\nthen leverages multi-view information and 3D reprojection to robustly filter\nfalse positives in two steps. We also introduce a new dataset for exploring the\nproblem of modifying a NeRF scene through a single observation. Our dataset (\nhttps://github.com/nerfdeformer/nerfdeformer ) contains 113 synthetic scenes\nleveraging 47 3D assets. We show that our proposed method outperforms NeRF\nediting methods as well as diffusion-based methods, and we also explore\ndifferent methods for filtering correspondences.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages of main paper, CVPR 2024. Proceedings of the IEEE/CVF\n  Conference on Computer Vision and Pattern Recognition. 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.10543v1",
    "published_date": "2024-06-15 07:58:08 UTC",
    "updated_date": "2024-06-15 07:58:08 UTC"
  },
  {
    "arxiv_id": "2406.10540v1",
    "title": "Generating and Evolving Reward Functions for Highway Driving with Large Language Models",
    "authors": [
      "Xu Han",
      "Qiannan Yang",
      "Xianda Chen",
      "Xiaowen Chu",
      "Meixin Zhu"
    ],
    "abstract": "Reinforcement Learning (RL) plays a crucial role in advancing autonomous\ndriving technologies by maximizing reward functions to achieve the optimal\npolicy. However, crafting these reward functions has been a complex, manual\nprocess in many practices. To reduce this complexity, we introduce a novel\nframework that integrates Large Language Models (LLMs) with RL to improve\nreward function design in autonomous driving. This framework utilizes the\ncoding capabilities of LLMs, proven in other areas, to generate and evolve\nreward functions for highway scenarios. The framework starts with instructing\nLLMs to create an initial reward function code based on the driving environment\nand task descriptions. This code is then refined through iterative cycles\ninvolving RL training and LLMs' reflection, which benefits from their ability\nto review and improve the output. We have also developed a specific prompt\ntemplate to improve LLMs' understanding of complex driving simulations,\nensuring the generation of effective and error-free code. Our experiments in a\nhighway driving simulator across three traffic configurations show that our\nmethod surpasses expert handcrafted reward functions, achieving a 22% higher\naverage success rate. This not only indicates safer driving but also suggests\nsignificant gains in development productivity.",
    "categories": [
      "cs.AI",
      "cs.NE",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.10540v1",
    "published_date": "2024-06-15 07:50:10 UTC",
    "updated_date": "2024-06-15 07:50:10 UTC"
  },
  {
    "arxiv_id": "2406.10537v1",
    "title": "Scalable Differentiable Causal Discovery in the Presence of Latent Confounders with Skeleton Posterior (Extended Version)",
    "authors": [
      "Pingchuan Ma",
      "Rui Ding",
      "Qiang Fu",
      "Jiaru Zhang",
      "Shuai Wang",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "abstract": "Differentiable causal discovery has made significant advancements in the\nlearning of directed acyclic graphs. However, its application to real-world\ndatasets remains restricted due to the ubiquity of latent confounders and the\nrequirement to learn maximal ancestral graphs (MAGs). To date, existing\ndifferentiable MAG learning algorithms have been limited to small datasets and\nfailed to scale to larger ones (e.g., with more than 50 variables).\n  The key insight in this paper is that the causal skeleton, which is the\nundirected version of the causal graph, has potential for improving accuracy\nand reducing the search space of the optimization procedure, thereby enhancing\nthe performance of differentiable causal discovery. Therefore, we seek to\naddress a two-fold challenge to harness the potential of the causal skeleton\nfor differentiable causal discovery in the presence of latent confounders: (1)\nscalable and accurate estimation of skeleton and (2) universal integration of\nskeleton estimation with differentiable causal discovery.\n  To this end, we propose SPOT (Skeleton Posterior-guided OpTimization), a\ntwo-phase framework that harnesses skeleton posterior for differentiable causal\ndiscovery in the presence of latent confounders. On the contrary to a\n``point-estimation'', SPOT seeks to estimate the posterior distribution of\nskeletons given the dataset. It first formulates the posterior inference as an\ninstance of amortized inference problem and concretizes it with a supervised\ncausal learning (SCL)-enabled solution to estimate the skeleton posterior. To\nincorporate the skeleton posterior with differentiable causal discovery, SPOT\nthen features a skeleton posterior-guided stochastic optimization procedure to\nguide the optimization of MAGs. [abridged due to length limit]",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10537v1",
    "published_date": "2024-06-15 07:40:36 UTC",
    "updated_date": "2024-06-15 07:40:36 UTC"
  },
  {
    "arxiv_id": "2406.10534v3",
    "title": "Finite-difference-informed graph network for solving steady-state incompressible flows on block-structured grids",
    "authors": [
      "Yiye Zou",
      "Tianyu Li",
      "Lin Lu",
      "Jingyu Wang",
      "Shufan Zou",
      "Laiping Zhang",
      "Xiaogang Deng"
    ],
    "abstract": "Advances in deep learning have enabled physics-informed neural networks to\nsolve partial differential equations. Numerical differentiation using the\nfinite-difference (FD) method is efficient in physics-constrained designs, even\nin parameterized settings. In traditional computational fluid dynamics(CFD),\nbody-fitted block-structured grids are often employed for complex flow cases\nwhen obtaining FD solutions. However, convolution operators in convolutional\nneural networks for FD are typically limited to single-block grids. To address\nthis issue, \\blueText{graphs and graph networks are used} to learn flow\nrepresentations across multi-block-structured grids. \\blueText{A graph\nconvolution-based FD method (GC-FDM) is proposed} to train graph networks in a\nlabel-free physics-constrained manner, enabling differentiable FD operations on\nunstructured graph outputs. To demonstrate model performance from single- to\nmulti-block-structured grids, \\blueText{the parameterized steady incompressible\nNavier-Stokes equations are solved} for a lid-driven cavity flow and the flows\naround single and double circular cylinder configurations. When compared to a\nCFD solver under various boundary conditions, the proposed method achieves a\nrelative error in velocity field predictions on the order of $10^{-3}$.\nFurthermore, the proposed method reduces training costs by approximately 20\\%\ncompared to a physics-informed neural network. \\blueText{To} further verify the\neffectiveness of GC-FDM in multi-block processing, \\blueText{a 30P30N airfoil\ngeometry is considered} and the \\blueText{predicted} results are reasonable\ncompared with those given by CFD. \\blueText{Finally, the applicability of\nGC-FDM to three-dimensional (3D) case is tested using a 3D cavity geometry.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10534v3",
    "published_date": "2024-06-15 07:30:40 UTC",
    "updated_date": "2024-11-29 06:07:08 UTC"
  },
  {
    "arxiv_id": "2406.10529v1",
    "title": "A Theory of Interpretable Approximations",
    "authors": [
      "Marco Bressan",
      "Nicolò Cesa-Bianchi",
      "Emmanuel Esposito",
      "Yishay Mansour",
      "Shay Moran",
      "Maximilian Thiessen"
    ],
    "abstract": "Can a deep neural network be approximated by a small decision tree based on\nsimple features? This question and its variants are behind the growing demand\nfor machine learning models that are *interpretable* by humans. In this work we\nstudy such questions by introducing *interpretable approximations*, a notion\nthat captures the idea of approximating a target concept $c$ by a small\naggregation of concepts from some base class $\\mathcal{H}$. In particular, we\nconsider the approximation of a binary concept $c$ by decision trees based on a\nsimple class $\\mathcal{H}$ (e.g., of bounded VC dimension), and use the tree\ndepth as a measure of complexity. Our primary contribution is the following\nremarkable trichotomy. For any given pair of $\\mathcal{H}$ and $c$, exactly one\nof these cases holds: (i) $c$ cannot be approximated by $\\mathcal{H}$ with\narbitrary accuracy; (ii) $c$ can be approximated by $\\mathcal{H}$ with\narbitrary accuracy, but there exists no universal rate that bounds the\ncomplexity of the approximations as a function of the accuracy; or (iii) there\nexists a constant $\\kappa$ that depends only on $\\mathcal{H}$ and $c$ such\nthat, for *any* data distribution and *any* desired accuracy level, $c$ can be\napproximated by $\\mathcal{H}$ with a complexity not exceeding $\\kappa$. This\ntaxonomy stands in stark contrast to the landscape of supervised\nclassification, which offers a complex array of distribution-free and\nuniversally learnable scenarios. We show that, in the case of interpretable\napproximations, even a slightly nontrivial a-priori guarantee on the complexity\nof approximations implies approximations with constant (distribution-free and\naccuracy-free) complexity. We extend our trichotomy to classes $\\mathcal{H}$ of\nunbounded VC dimension and give characterizations of interpretability based on\nthe algebra generated by $\\mathcal{H}$.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear at COLT 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.10529v1",
    "published_date": "2024-06-15 06:43:45 UTC",
    "updated_date": "2024-06-15 06:43:45 UTC"
  },
  {
    "arxiv_id": "2406.10522v2",
    "title": "Humor in AI: Massive Scale Crowd-Sourced Preferences and Benchmarks for Cartoon Captioning",
    "authors": [
      "Jifan Zhang",
      "Lalit Jain",
      "Yang Guo",
      "Jiayi Chen",
      "Kuan Lok Zhou",
      "Siddharth Suresh",
      "Andrew Wagenmaker",
      "Scott Sievert",
      "Timothy Rogers",
      "Kevin Jamieson",
      "Robert Mankoff",
      "Robert Nowak"
    ],
    "abstract": "We present a novel multimodal preference dataset for creative tasks,\nconsisting of over 250 million human ratings on more than 2.2 million captions,\ncollected through crowdsourcing rating data for The New Yorker's weekly cartoon\ncaption contest over the past eight years. This unique dataset supports the\ndevelopment and evaluation of multimodal large language models and\npreference-based fine-tuning algorithms for humorous caption generation. We\npropose novel benchmarks for judging the quality of model-generated captions,\nutilizing both GPT4 and human judgments to establish ranking-based evaluation\nstrategies. Our experimental results highlight the limitations of current\nfine-tuning methods, such as RLHF and DPO, when applied to creative tasks.\nFurthermore, we demonstrate that even state-of-the-art models like GPT4 and\nClaude currently underperform top human contestants in generating humorous\ncaptions. As we conclude this extensive data collection effort, we release the\nentire preference dataset to the research community, fostering further\nadvancements in AI humor generation and evaluation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10522v2",
    "published_date": "2024-06-15 06:26:25 UTC",
    "updated_date": "2024-12-18 05:21:24 UTC"
  },
  {
    "arxiv_id": "2406.10521v3",
    "title": "MALLM-GAN: Multi-Agent Large Language Model as Generative Adversarial Network for Synthesizing Tabular Data",
    "authors": [
      "Yaobin Ling",
      "Xiaoqian Jiang",
      "Yejin Kim"
    ],
    "abstract": "In the era of big data, access to abundant data is crucial for driving\nresearch forward. However, such data is often inaccessible due to privacy\nconcerns or high costs, particularly in healthcare domain. Generating synthetic\n(tabular) data can address this, but existing models typically require\nsubstantial amounts of data to train effectively, contradicting our objective\nto solve data scarcity. To address this challenge, we propose a novel framework\nto generate synthetic tabular data, powered by large language models (LLMs)\nthat emulates the architecture of a Generative Adversarial Network (GAN). By\nincorporating data generation process as contextual information and utilizing\nLLM as the optimizer, our approach significantly enhance the quality of\nsynthetic data generation in common scenarios with small sample sizes. Our\nexperimental results on public and private datasets demonstrate that our model\noutperforms several state-of-art models regarding generating higher quality\nsynthetic data for downstream tasks while keeping privacy of the real data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10521v3",
    "published_date": "2024-06-15 06:26:17 UTC",
    "updated_date": "2024-10-02 23:27:16 UTC"
  },
  {
    "arxiv_id": "2406.10519v2",
    "title": "Self Pre-training with Topology- and Spatiality-aware Masked Autoencoders for 3D Medical Image Segmentation",
    "authors": [
      "Pengfei Gu",
      "Yejia Zhang",
      "Huimin Li",
      "Chaoli Wang",
      "Danny Z. Chen"
    ],
    "abstract": "Masked Autoencoders (MAEs) have been shown to be effective in pre-training\nVision Transformers (ViTs) for natural and medical image analysis problems. By\nreconstructing missing pixel/voxel information in visible patches, a ViT\nencoder can aggregate contextual information for downstream tasks. But,\nexisting MAE pre-training methods, which were specifically developed with the\nViT architecture, lack the ability to capture geometric shape and spatial\ninformation, which is critical for medical image segmentation tasks. In this\npaper, we propose a novel extension of known MAEs for self pre-training (i.e.,\nmodels pre-trained on the same target dataset) for 3D medical image\nsegmentation. (1) We propose a new topological loss to preserve geometric shape\ninformation by computing topological signatures of both the input and\nreconstructed volumes, learning geometric shape information. (2) We introduce a\npre-text task that predicts the positions of the centers and eight corners of\n3D crops, enabling the MAE to aggregate spatial information. (3) We extend the\nMAE pre-training strategy to a hybrid state-of-the-art (SOTA) medical image\nsegmentation architecture and co-pretrain it alongside the ViT. (4) We develop\na fine-tuned model for downstream segmentation tasks by complementing the\npre-trained ViT encoder with our pre-trained SOTA model. Extensive experiments\non five public 3D segmentation datasets show the effectiveness of our new\napproach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10519v2",
    "published_date": "2024-06-15 06:15:17 UTC",
    "updated_date": "2024-07-15 20:35:00 UTC"
  },
  {
    "arxiv_id": "2406.10517v1",
    "title": "ADSNet: Cross-Domain LTV Prediction with an Adaptive Siamese Network in Advertising",
    "authors": [
      "Ruize Wang",
      "Hui Xu",
      "Ying Cheng",
      "Qi He",
      "Xing Zhou",
      "Rui Feng",
      "Wei Xu",
      "Lei Huang",
      "Jie Jiang"
    ],
    "abstract": "Advertising platforms have evolved in estimating Lifetime Value (LTV) to\nbetter align with advertisers' true performance metric. However, the sparsity\nof real-world LTV data presents a significant challenge to LTV predictive\nmodel(i.e., pLTV), severely limiting the their capabilities. Therefore, we\npropose to utilize external data, in addition to the internal data of\nadvertising platform, to expand the size of purchase samples and enhance the\nLTV prediction model of the advertising platform. To tackle the issue of data\ndistribution shift between internal and external platforms, we introduce an\nAdaptive Difference Siamese Network (ADSNet), which employs cross-domain\ntransfer learning to prevent negative transfer. Specifically, ADSNet is\ndesigned to learn information that is beneficial to the target domain. We\nintroduce a gain evaluation strategy to calculate information gain, aiding the\nmodel in learning helpful information for the target domain and providing the\nability to reject noisy samples, thus avoiding negative transfer. Additionally,\nwe also design a Domain Adaptation Module as a bridge to connect different\ndomains, reduce the distribution distance between them, and enhance the\nconsistency of representation space distribution. We conduct extensive offline\nexperiments and online A/B tests on a real advertising platform. Our proposed\nADSNet method outperforms other methods, improving GINI by 2$\\%$. The ablation\nstudy highlights the importance of the gain evaluation strategy in negative\ngain sample rejection and improving model performance. Additionally, ADSNet\nsignificantly improves long-tail prediction. The online A/B tests confirm\nADSNet's efficacy, increasing online LTV by 3.47$\\%$ and GMV by 3.89$\\%$.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted to KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.10517v1",
    "published_date": "2024-06-15 06:04:46 UTC",
    "updated_date": "2024-06-15 06:04:46 UTC"
  },
  {
    "arxiv_id": "2406.10515v2",
    "title": "Reactor Mk.1 performances: MMLU, HumanEval and BBH test results",
    "authors": [
      "TJ Dunham",
      "Henry Syahputra"
    ],
    "abstract": "The paper presents the performance results of Reactor Mk.1, ARCs flagship\nlarge language model, through a benchmarking process analysis. The model\nutilizes the Lychee AI engine and possesses less than 100 billion parameters,\nresulting in a combination of efficiency and potency. The Reactor Mk.1\noutperformed models such as GPT-4o, Claude Opus, and Llama 3, with achieved\nscores of 92% on the MMLU dataset, 91% on HumanEval dataset, and 88% on BBH\ndataset. It excels in both managing difficult jobs and reasoning, establishing\nas a prominent AI solution in the present cutting-edge AI technology.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10515v2",
    "published_date": "2024-06-15 05:52:32 UTC",
    "updated_date": "2024-07-26 08:03:32 UTC"
  },
  {
    "arxiv_id": "2406.10514v1",
    "title": "GTR-Voice: Articulatory Phonetics Informed Controllable Expressive Speech Synthesis",
    "authors": [
      "Zehua Kcriss Li",
      "Meiying Melissa Chen",
      "Yi Zhong",
      "Pinxin Liu",
      "Zhiyao Duan"
    ],
    "abstract": "Expressive speech synthesis aims to generate speech that captures a wide\nrange of para-linguistic features, including emotion and articulation, though\ncurrent research primarily emphasizes emotional aspects over the nuanced\narticulatory features mastered by professional voice actors. Inspired by this,\nwe explore expressive speech synthesis through the lens of articulatory\nphonetics. Specifically, we define a framework with three dimensions:\nGlottalization, Tenseness, and Resonance (GTR), to guide the synthesis at the\nvoice production level. With this framework, we record a high-quality speech\ndataset named GTR-Voice, featuring 20 Chinese sentences articulated by a\nprofessional voice actor across 125 distinct GTR combinations. We verify the\nframework and GTR annotations through automatic classification and listening\ntests, and demonstrate precise controllability along the GTR dimensions on two\nfine-tuned expressive TTS models. We open-source the dataset and TTS models.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10514v1",
    "published_date": "2024-06-15 05:37:04 UTC",
    "updated_date": "2024-06-15 05:37:04 UTC"
  },
  {
    "arxiv_id": "2406.15468v2",
    "title": "MMLU-SR: A Benchmark for Stress-Testing Reasoning Capability of Large Language Models",
    "authors": [
      "Wentian Wang",
      "Sarthak Jain",
      "Paul Kantor",
      "Jacob Feldman",
      "Lazaros Gallos",
      "Hao Wang"
    ],
    "abstract": "We propose MMLU-SR, a novel dataset designed to measure the true\ncomprehension abilities of Large Language Models (LLMs) by challenging their\nperformance in question-answering tasks with modified terms. We reasoned that\nan agent that \"truly\" understands a concept can still evaluate it when key\nterms are replaced by suitably defined alternate terms, and sought to\ndifferentiate such comprehension from mere text replacement. In our study, we\nmodified standardized test questions by replacing a key term with a dummy word\nalong with its definition. The key term could be in the context of questions,\nanswers, or both questions and answers. Notwithstanding the high scores\nachieved by recent popular LLMs on the MMLU leaderboard, we found a substantial\nreduction in model performance after such replacement, suggesting poor\ncomprehension. This new benchmark provides a rigorous benchmark for testing\ntrue model comprehension, and poses a challenge to the broader scientific\ncommunity.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.15468v2",
    "published_date": "2024-06-15 05:35:47 UTC",
    "updated_date": "2024-10-04 07:29:29 UTC"
  },
  {
    "arxiv_id": "2407.00056v1",
    "title": "MMBee: Live Streaming Gift-Sending Recommendations via Multi-Modal Fusion and Behaviour Expansion",
    "authors": [
      "Jiaxin Deng",
      "Shiyao Wang",
      "Yuchen Wang",
      "Jiansong Qi",
      "Liqin Zhao",
      "Guorui Zhou",
      "Gaofeng Meng"
    ],
    "abstract": "Live streaming services are becoming increasingly popular due to real-time\ninteractions and entertainment. Viewers can chat and send comments or virtual\ngifts to express their preferences for the streamers. Accurately modeling the\ngifting interaction not only enhances users' experience but also increases\nstreamers' revenue. Previous studies on live streaming gifting prediction treat\nthis task as a conventional recommendation problem, and model users'\npreferences using categorical data and observed historical behaviors. However,\nit is challenging to precisely describe the real-time content changes in live\nstreaming using limited categorical information. Moreover, due to the sparsity\nof gifting behaviors, capturing the preferences and intentions of users is\nquite difficult. In this work, we propose MMBee based on real-time Multi-Modal\nFusion and Behaviour Expansion to address these issues. Specifically, we first\npresent a Multi-modal Fusion Module with Learnable Query (MFQ) to perceive the\ndynamic content of streaming segments and process complex multi-modal\ninteractions, including images, text comments and speech. To alleviate the\nsparsity issue of gifting behaviors, we present a novel Graph-guided Interest\nExpansion (GIE) approach that learns both user and streamer representations on\nlarge-scale gifting graphs with multi-modal attributes. Comprehensive\nexperiment results show that MMBee achieves significant performance\nimprovements on both public datasets and Kuaishou real-world streaming datasets\nand the effectiveness has been further validated through online A/B\nexperiments. MMBee has been deployed and is serving hundreds of millions of\nusers at Kuaishou.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted at KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.00056v1",
    "published_date": "2024-06-15 04:59:00 UTC",
    "updated_date": "2024-06-15 04:59:00 UTC"
  },
  {
    "arxiv_id": "2406.10504v1",
    "title": "Task Facet Learning: A Structured Approach to Prompt Optimization",
    "authors": [
      "Gurusha Juneja",
      "Nagarajan Natarajan",
      "Hua Li",
      "Jian Jiao",
      "Amit Sharma"
    ],
    "abstract": "Given a task in the form of a basic description and its training examples,\nprompt optimization is the problem of synthesizing the given information into a\ntext prompt for a large language model (LLM). Humans solve this problem by also\nconsidering the different facets that define a task (e.g., counter-examples,\nexplanations, analogies) and including them in the prompt. However, it is\nunclear whether existing algorithmic approaches, based on iteratively editing a\ngiven prompt or automatically selecting a few in-context examples, can cover\nthe multiple facets required to solve a complex task. In this work, we view\nprompt optimization as that of learning multiple facets of a task from a set of\ntraining examples. We identify and exploit structure in the prompt optimization\nproblem -- first, we find that prompts can be broken down into loosely coupled\nsemantic sections that have a relatively independent effect on the prompt's\nperformance; second, we cluster the input space and use clustered batches so\nthat the optimization procedure can learn the different facets of a task across\nbatches. The resulting algorithm, UniPrompt, consists of a generative model to\ngenerate initial candidates for each prompt section; and a feedback mechanism\nthat aggregates suggested edits from multiple mini-batches into a conceptual\ndescription for the section. Empirical evaluation on multiple datasets and a\nreal-world task shows that prompts generated using UniPrompt obtain higher\naccuracy than human-tuned prompts and those from state-of-the-art methods. In\nparticular, our algorithm can generate long, complex prompts that existing\nmethods are unable to generate. Code for UniPrompt will be available at\n\\url{https://aka.ms/uniprompt}.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10504v1",
    "published_date": "2024-06-15 04:54:26 UTC",
    "updated_date": "2024-06-15 04:54:26 UTC"
  },
  {
    "arxiv_id": "2406.10502v1",
    "title": "Candidate Pseudolabel Learning: Enhancing Vision-Language Models by Prompt Tuning with Unlabeled Data",
    "authors": [
      "Jiahan Zhang",
      "Qi Wei",
      "Feng Liu",
      "Lei Feng"
    ],
    "abstract": "Fine-tuning vision-language models (VLMs) with abundant unlabeled data\nrecently has attracted increasing attention. Existing methods that resort to\nthe pseudolabeling strategy would suffer from heavily incorrect hard\npseudolabels when VLMs exhibit low zero-shot performance in downstream tasks.\nTo alleviate this issue, we propose a Candidate Pseudolabel Learning method,\ntermed CPL, to fine-tune VLMs with suitable candidate pseudolabels of unlabeled\ndata in downstream tasks. The core of our method lies in the generation\nstrategy of candidate pseudolabels, which progressively generates refined\ncandidate pseudolabels by both intra- and inter-instance label selection, based\non a confidence score matrix for all unlabeled data. This strategy can result\nin better performance in true label inclusion and class-balanced instance\nselection. In this way, we can directly apply existing loss functions to learn\nwith generated candidate psueudolabels. Extensive experiments on nine benchmark\ndatasets with three learning paradigms demonstrate the effectiveness of our\nmethod. Our code can be found at https://github.com/vanillaer/CPL-ICML2024.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML2024",
    "pdf_url": "http://arxiv.org/pdf/2406.10502v1",
    "published_date": "2024-06-15 04:50:20 UTC",
    "updated_date": "2024-06-15 04:50:20 UTC"
  },
  {
    "arxiv_id": "2406.10479v2",
    "title": "Unlocking Large Language Model's Planning Capabilities with Maximum Diversity Fine-tuning",
    "authors": [
      "Wenjun Li",
      "Changyu Chen",
      "Pradeep Varakantham"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive task-solving\ncapabilities through prompting techniques and system designs, including solving\nplanning tasks (e.g., math proofs, basic travel planning) when sufficient data\nis available online and used during pre-training. However, for planning tasks\nwith limited prior data (e.g., blocks world, advanced travel planning), the\nperformance of LLMs, including proprietary models like GPT and Gemini, is poor.\nThis paper investigates the impact of fine-tuning on the planning capabilities\nof LLMs, revealing that LLMs can achieve strong performance in planning through\nsubstantial (tens of thousands of specific examples) fine-tuning. Yet, this\nprocess incurs high economic, time, and computational costs for each planning\nproblem variation. To address this, we propose Clustering-Based Maximum\nDiversity Sampling (CMDS), which selects diverse and representative data to\nenhance sample efficiency and the model's generalization capability. Extensive\nevaluations demonstrate that CMDS-l, a baseline method combining CMDS with\nlanguage embeddings, outperforms random sampling. Furthermore, we introduce a\nnovel algorithm, CMDS-g, which encodes planning task instances with their graph\nrepresentations into the embedding space. Empirical results show that CMDS-g\nconsistently outperforms baseline methods across various scales and multiple\nbenchmark domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages of main paper, 2 pages of references",
    "pdf_url": "http://arxiv.org/pdf/2406.10479v2",
    "published_date": "2024-06-15 03:06:14 UTC",
    "updated_date": "2025-04-24 15:15:17 UTC"
  },
  {
    "arxiv_id": "2406.10478v2",
    "title": "From Words to Worlds: Transforming One-line Prompt into Immersive Multi-modal Digital Stories with Communicative LLM Agent",
    "authors": [
      "Samuel S. Sohn",
      "Danrui Li",
      "Sen Zhang",
      "Che-Jui Chang",
      "Mubbasir Kapadia"
    ],
    "abstract": "Digital storytelling, essential in entertainment, education, and marketing,\nfaces challenges in production scalability and flexibility. The StoryAgent\nframework, introduced in this paper, utilizes Large Language Models and\ngenerative tools to automate and refine digital storytelling. Employing a\ntop-down story drafting and bottom-up asset generation approach, StoryAgent\ntackles key issues such as manual intervention, interactive scene\norchestration, and narrative consistency. This framework enables efficient\nproduction of interactive and consistent narratives across multiple modalities,\ndemocratizing content creation and enhancing engagement. Our results\ndemonstrate the framework's capability to produce coherent digital stories\nwithout reference videos, marking a significant advancement in automated\ndigital storytelling.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.10478v2",
    "published_date": "2024-06-15 03:03:43 UTC",
    "updated_date": "2024-06-21 08:09:17 UTC"
  },
  {
    "arxiv_id": "2406.10454v1",
    "title": "HumanPlus: Humanoid Shadowing and Imitation from Humans",
    "authors": [
      "Zipeng Fu",
      "Qingqing Zhao",
      "Qi Wu",
      "Gordon Wetzstein",
      "Chelsea Finn"
    ],
    "abstract": "One of the key arguments for building robots that have similar form factors\nto human beings is that we can leverage the massive human data for training.\nYet, doing so has remained challenging in practice due to the complexities in\nhumanoid perception and control, lingering physical gaps between humanoids and\nhumans in morphologies and actuation, and lack of a data pipeline for humanoids\nto learn autonomous skills from egocentric vision. In this paper, we introduce\na full-stack system for humanoids to learn motion and autonomous skills from\nhuman data. We first train a low-level policy in simulation via reinforcement\nlearning using existing 40-hour human motion datasets. This policy transfers to\nthe real world and allows humanoid robots to follow human body and hand motion\nin real time using only a RGB camera, i.e. shadowing. Through shadowing, human\noperators can teleoperate humanoids to collect whole-body data for learning\ndifferent tasks in the real world. Using the data collected, we then perform\nsupervised behavior cloning to train skill policies using egocentric vision,\nallowing humanoids to complete different tasks autonomously by imitating human\nskills. We demonstrate the system on our customized 33-DoF 180cm humanoid,\nautonomously completing tasks such as wearing a shoe to stand up and walk,\nunloading objects from warehouse racks, folding a sweatshirt, rearranging\nobjects, typing, and greeting another robot with 60-100% success rates using up\nto 40 demonstrations. Project website: https://humanoid-ai.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "project website: https://humanoid-ai.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2406.10454v1",
    "published_date": "2024-06-15 00:41:34 UTC",
    "updated_date": "2024-06-15 00:41:34 UTC"
  },
  {
    "arxiv_id": "2406.10450v2",
    "title": "TokenRec: Learning to Tokenize ID for LLM-based Generative Recommendation",
    "authors": [
      "Haohao Qu",
      "Wenqi Fan",
      "Zihuai Zhao",
      "Qing Li"
    ],
    "abstract": "There is a growing interest in utilizing large-scale language models (LLMs)\nto advance next-generation Recommender Systems (RecSys), driven by their\noutstanding language understanding and in-context learning capabilities. In\nthis scenario, tokenizing (i.e., indexing) users and items becomes essential\nfor ensuring a seamless alignment of LLMs with recommendations. While several\nstudies have made progress in representing users and items through textual\ncontents or latent representations, challenges remain in efficiently capturing\nhigh-order collaborative knowledge into discrete tokens that are compatible\nwith LLMs. Additionally, the majority of existing tokenization approaches often\nface difficulties in generalizing effectively to new/unseen users or items that\nwere not in the training corpus. To address these challenges, we propose a\nnovel framework called TokenRec, which introduces not only an effective ID\ntokenization strategy but also an efficient retrieval paradigm for LLM-based\nrecommendations. Specifically, our tokenization strategy, Masked\nVector-Quantized (MQ) Tokenizer, involves quantizing the masked user/item\nrepresentations learned from collaborative filtering into discrete tokens, thus\nachieving a smooth incorporation of high-order collaborative knowledge and a\ngeneralizable tokenization of users and items for LLM-based RecSys. Meanwhile,\nour generative retrieval paradigm is designed to efficiently recommend top-$K$\nitems for users to eliminate the need for the time-consuming auto-regressive\ndecoding and beam search processes used by LLMs, thus significantly reducing\ninference time. Comprehensive experiments validate the effectiveness of the\nproposed methods, demonstrating that TokenRec outperforms competitive\nbenchmarks, including both traditional recommender systems and emerging\nLLM-based recommender systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "Submitted to IEEE TKDE. Our code and dataset will be made available\n  upon acceptance of the paper",
    "pdf_url": "http://arxiv.org/pdf/2406.10450v2",
    "published_date": "2024-06-15 00:07:44 UTC",
    "updated_date": "2024-08-18 07:56:17 UTC"
  },
  {
    "arxiv_id": "2406.10449v3",
    "title": "Learning Temporal Logic Predicates from Data with Statistical Guarantees",
    "authors": [
      "Emi Soroka",
      "Rohan Sinha",
      "Sanjay Lall"
    ],
    "abstract": "Temporal logic rules are often used in control and robotics to provide\nstructured, human-interpretable descriptions of trajectory data. These rules\nhave numerous applications including safety validation using formal methods,\nconstraining motion planning among autonomous agents, and classifying data.\nHowever, existing methods for learning temporal logic predicates from data do\nnot provide assurances about the correctness of the resulting predicate. We\npresent a novel method to learn temporal logic predicates from data with\nfinite-sample correctness guarantees. Our approach leverages expression\noptimization and conformal prediction to learn predicates that correctly\ndescribe future trajectories under mild statistical assumptions. We provide\nexperimental results showing the performance of our approach on a simulated\ntrajectory dataset and perform ablation studies to understand how each\ncomponent of our algorithm contributes to its performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.LG",
    "comment": "As submitted to L4DC 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.10449v3",
    "published_date": "2024-06-15 00:07:36 UTC",
    "updated_date": "2025-04-28 02:56:18 UTC"
  }
]