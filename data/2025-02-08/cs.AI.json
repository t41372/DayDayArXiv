{
  "date": "2025-02-08",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-08 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 和机器学习领域的创新，特别是大型语言模型（LLM）的代码生成、性能优化和跨领域应用，以及图学习和医疗图像生成的进展。令人印象深刻的是 CODESIM 的多代理代码生成框架和 XiHeFusion 的核聚变 AI 模型，它们展示了 AI 在复杂任务中的潜力，同时涉及知名学者如 Jürgen Schmidhuber 的理论分析。\n\n下面，我将挑选并讨论几篇重要的、话题度高的论文，先从 AI 代码生成和 LLM 性能入手，再聊医疗与机器人应用，最后快速掠过其他较基础的论文。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### AI 代码生成与多代理系统\n- **CODESIM: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging**（中文：通过模拟驱动规划和调试的多代理代码生成和问题解决）  \n  这篇论文提出 CODESIM 框架，使用多代理系统结合模拟驱动的方法，实现高效代码生成和调试。在编程难题基准（如 HumanEval 和 APPS）上，CODESIM 达到新状态-of-the-art 性能，平均成功率高达 95.1%，显著提升了代码合成的鲁棒性，适用于复杂软件开发场景。\n\n- **Proving the Coding Interview: A Benchmark for Formally Verified Code Generation**（中文：证明编码面试：用于形式验证代码生成的基准）  \n  作者 Quinn Dougherty 和 Ronak Mehta 构建了 FVAPPS 基准，包含 4715 个样本，用于测试 LLM 在代码生成和形式验证（如 Lean 4 证明）上的能力。Gemini 和 Sonnet 在随机样本上证明准确率达 30%，为 AI 代码安全性和可靠性提供了新评估工具，强调了 LLM 在软件工程中的实际应用潜力。\n\n### LLM 性能与语义理解\n- **Rethinking Word Similarity: Semantic Similarity through Classification Confusion**（中文：重新思考词相似性：通过分类混淆的语义相似性）  \n  这篇论文（作者包括 Dan Jurafsky）引入 Word Confusion 度量，使用分类器混淆概率捕捉上下文依赖的语义相似性。在数据集如 MEN 和 SimLex 上，与余弦相似性相当，同时能动态处理多义词，适用于社会科学和文化分析，如分析历史词义变化。\n\n- **Context information can be more important than reasoning for time series forecasting with a large language model**（中文：上下文信息可能比推理更重要：用于时序预测的大型语言模型）  \n  作者 Janghoon Yang 探索 LLM 在时序预测中的提示技术，发现提供适当上下文信息（如不使用额外推理提示）即可实现最佳性能。该方法在短/长时序数据上表现出色，但暴露了 LLM 在计算准确性和语义理解上的弱点。\n\n- **Learning Conformal Abstention Policies for Adaptive Risk Management in Large Language and Vision-Language Models**（中文：学习一致性弃权策略用于大型语言和视觉语言模型的自适应风险管理）  \n  这篇论文提出强化学习结合一致性预测（CP）的弃权策略，优化 LLM/VLM 的风险管理。在基准测试中，准确率提升至 3.2%，AUROC 提高 22.19%，显著改善了安全关键应用的可靠性。\n\n- **Zero-Shot End-to-End Relation Extraction in Chinese: A Comparative Study of Gemini, LLaMA and ChatGPT**（中文：中文零样本端到端关系抽取：Gemini、LLaMA 和 ChatGPT 的比较研究）  \n  作者团队比较了 LLM 在中文关系抽取上的表现，ChatGPT 平衡精度和召回，Gemini 速度最快。研究揭示了 LLM 在零样本任务中的权衡，ChatGPT 整体性能最佳，提供对中国 NLP 任务的洞见。\n\n### 医疗与机器人应用\n- **4D VQ-GAN: Synthesising Medical Scans at Any Time Point for Personalised Disease Progression Modelling of Idiopathic Pulmonary Fibrosis**（中文：4D VQ-GAN：用于特发性肺纤维化个性化疾病进展建模的任意时间点医学扫描合成）  \n  这篇论文开发了 4D-VQ-GAN 模型，能生成肺纤维化 CT 扫描，用于预测疾病轨迹。模型结合神经 ODE 和量化生成，在生存分析中达到与真实数据相当的 C-index，展示了 AI 在医疗预测中的临床潜力。\n\n- **Vision-Ultrasound Robotic System based on Deep Learning for Gas and Arc Hazard Detection in Manufacturing**（中文：基于深度学习的视觉-超声波机器人系统，用于制造业气体和电弧危险检测）  \n  该系统使用 CNN 和超声波数据检测工业危险，准确率达 99%，在噪声环境中提升 44%，为制造业安全提供实时监控方案。\n\n### 其他亮点与快速掠过\n- **XiHeFusion: Harnessing Large Language Models for Science Communication in Nuclear Fusion**（中文：XiHeFusion：利用大型语言模型进行核聚变科学传播）  \n  论文构建了 XiHeFusion 模型，通过微调 Qwen2.5 实现核聚变知识问答，实验显示在专业问答中表现优秀，填补了 AI 在科学传播的空白。\n\n其他论文如第13篇（Mobile Application Threats and Security，中文：移动应用威胁和安全）讨论移动安全基础问题，第23篇（Adversarial Machine Learning，中文：对抗性机器学习）回顾攻击防御，但这些相对常规，我这里只简要提及：它们提供了安全领域的标准回顾，但未有突破性创新。\n\n总之，今天的 arXiv 强调 AI 的实用性和可靠性，LLM 在代码和医疗中的应用特别值得关注。更多细节请查阅原文！",
  "papers": [
    {
      "arxiv_id": "2502.05724v2",
      "title": "Rethinking Link Prediction for Directed Graphs",
      "title_zh": "重新审视有向图的链接预测",
      "authors": [
        "Mingguo He",
        "Yuhe Guo",
        "Yanping Zheng",
        "Zhewei Wei",
        "Stephan Günnemann",
        "Xiaokui Xiao"
      ],
      "abstract": "Link prediction for directed graphs is a crucial task with diverse real-world\napplications. Recent advances in embedding methods and Graph Neural Networks\n(GNNs) have shown promising improvements. However, these methods often lack a\nthorough analysis of their expressiveness and suffer from effective benchmarks\nfor a fair evaluation. In this paper, we propose a unified framework to assess\nthe expressiveness of existing methods, highlighting the impact of dual\nembeddings and decoder design on directed link prediction performance. To\naddress limitations in current benchmark setups, we introduce DirLinkBench, a\nrobust new benchmark with comprehensive coverage, standardized evaluation, and\nmodular extensibility. The results on DirLinkBench show that current methods\nstruggle to achieve strong performance, while DiGAE outperforms other baselines\noverall. We further revisit DiGAE theoretically, showing its graph convolution\naligns with GCN on an undirected bipartite graph. Inspired by these insights,\nwe propose a novel Spectral Directed Graph Auto-Encoder SDGAE that achieves\nstate-of-the-art average performance on DirLinkBench. Finally, we analyze key\nfactors influencing directed link prediction and highlight open challenges in\nthis field.",
      "tldr_zh": "本文重新审视有向图的链接预测（Link Prediction），提出一个统一的框架来评估现有嵌入方法和 Graph Neural Networks (GNNs) 的表达能力，强调双嵌入和解码器设计对性能的影响，并引入新的基准 DirLinkBench，以提供全面、标准化的评估环境。实验结果显示，现有方法在 DirLinkBench 上表现不佳，而 DiGAE 整体优于其他基线；此外，通过理论分析，DiGAE 的图卷积与 GCN 在无向二分图上保持一致。基于这些洞见，作者提出新型 Spectral Directed Graph Auto-Encoder (SDGAE)，在基准上实现最先进的平均性能，并分析了影响因素及该领域的开放挑战。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2502.05724v2",
      "published_date": "2025-02-08 23:51:05 UTC",
      "updated_date": "2025-05-21 07:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:43:47.488036"
    },
    {
      "arxiv_id": "2502.05720v1",
      "title": "Pareto-Optimality, Smoothness, and Stochasticity in Learning-Augmented One-Max-Search",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyad Benomar",
        "Lorenzo Croissant",
        "Vianney Perchet",
        "Spyros Angelopoulos"
      ],
      "abstract": "One-max search is a classic problem in online decision-making, in which a\ntrader acts on a sequence of revealed prices and accepts one of them\nirrevocably to maximise its profit. The problem has been studied both in\nprobabilistic and in worst-case settings, notably through competitive analysis,\nand more recently in learning-augmented settings in which the trader has access\nto a prediction on the sequence. However, existing approaches either lack\nsmoothness, or do not achieve optimal worst-case guarantees: they do not attain\nthe best possible trade-off between the consistency and the robustness of the\nalgorithm. We close this gap by presenting the first algorithm that\nsimultaneously achieves both of these important objectives. Furthermore, we\nshow how to leverage the obtained smoothness to provide an analysis of one-max\nsearch in stochastic learning-augmented settings which capture randomness in\nboth the observed prices and the prediction.",
      "tldr_zh": "这篇论文研究了学习增强的 One-Max-Search 问题，该问题涉及在线决策中从一系列价格中选择一个以最大化利润。现有方法要么缺乏 Smoothness，要么无法实现一致性和鲁棒性之间的最佳 Pareto-Optimality 权衡。论文提出一个新算法，首次同时达到这些目标，提供最优的算法性能。此外，该算法利用获得的 Smoothness 对 Stochasticity 环境下的 One-Max-Search 进行了分析，包括价格和预测中的随机性，从而扩展了问题在随机设置下的应用。",
      "categories": [
        "cs.DS",
        "cs.AI"
      ],
      "primary_category": "cs.DS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05720v1",
      "published_date": "2025-02-08 23:25:52 UTC",
      "updated_date": "2025-02-08 23:25:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:43:57.517585"
    },
    {
      "arxiv_id": "2502.05719v1",
      "title": "Extended Histogram-based Outlier Score (EHBOS)",
      "title_zh": "翻译失败",
      "authors": [
        "Tanvir Islam"
      ],
      "abstract": "Histogram-Based Outlier Score (HBOS) is a widely used outlier or anomaly\ndetection method known for its computational efficiency and simplicity.\nHowever, its assumption of feature independence limits its ability to detect\nanomalies in datasets where interactions between features are critical. In this\npaper, we propose the Extended Histogram-Based Outlier Score (EHBOS), which\nenhances HBOS by incorporating two-dimensional histograms to capture\ndependencies between feature pairs. This extension allows EHBOS to identify\ncontextual and dependency-driven anomalies that HBOS fails to detect. We\nevaluate EHBOS on 17 benchmark datasets, demonstrating its effectiveness and\nrobustness across diverse anomaly detection scenarios. EHBOS outperforms HBOS\non several datasets, particularly those where feature interactions are critical\nin defining the anomaly structure, achieving notable improvements in ROC AUC.\nThese results highlight that EHBOS can be a valuable extension to HBOS, with\nthe ability to model complex feature dependencies. EHBOS offers a powerful new\ntool for anomaly detection, particularly in datasets where contextual or\nrelational anomalies play a significant role.",
      "tldr_zh": "这篇论文针对 Histogram-Based Outlier Score (HBOS) 的特征独立假设问题，提出了 Extended Histogram-Based Outlier Score (EHBOS)，通过引入二维直方图来捕捉特征对之间的依赖关系，从而提升对上下文和依赖驱动异常的检测能力。EHBOS 在 17 个基准数据集上进行了评估，结果显示它在特征互动关键的数据集上显著优于 HBOS，ROC AUC 成绩得到 notable 改善。这些发现证明 EHBOS 是一种有效的扩展工具，能更好地处理复杂特征依赖的异常检测场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05719v1",
      "published_date": "2025-02-08 23:24:30 UTC",
      "updated_date": "2025-02-08 23:24:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:44:09.969737"
    },
    {
      "arxiv_id": "2502.06885v1",
      "title": "Topological derivative approach for deep neural network architecture adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "C G Krishnanunni",
        "Tan Bui-Thanh",
        "Clint Dawson"
      ],
      "abstract": "This work presents a novel algorithm for progressively adapting neural\nnetwork architecture along the depth. In particular, we attempt to address the\nfollowing questions in a mathematically principled way: i) Where to add a new\ncapacity (layer) during the training process? ii) How to initialize the new\ncapacity? At the heart of our approach are two key ingredients: i) the\nintroduction of a ``shape functional\" to be minimized, which depends on neural\nnetwork topology, and ii) the introduction of a topological derivative of the\nshape functional with respect to the neural network topology. Using an optimal\ncontrol viewpoint, we show that the network topological derivative exists under\ncertain conditions, and its closed-form expression is derived. In particular,\nwe explore, for the first time, the connection between the topological\nderivative from a topology optimization framework with the Hamiltonian from\noptimal control theory. Further, we show that the optimality condition for the\nshape functional leads to an eigenvalue problem for deep neural architecture\nadaptation. Our approach thus determines the most sensitive location along the\ndepth where a new layer needs to be inserted during the training phase and the\nassociated parametric initialization for the newly added layer. We also\ndemonstrate that our layer insertion strategy can be derived from an optimal\ntransport viewpoint as a solution to maximizing a topological derivative in\n$p$-Wasserstein space, where $p>= 1$. Numerical investigations with fully\nconnected network, convolutional neural network, and vision transformer on\nvarious regression and classification problems demonstrate that our proposed\napproach can outperform an ad-hoc baseline network and other architecture\nadaptation strategies. Further, we also demonstrate other applications of\ntopological derivative in fields such as transfer learning.",
      "tldr_zh": "这篇论文提出了一种基于topological derivative的算法，用于在训练过程中逐步适应深度神经网络的架构，具体解决在哪里添加新层和如何初始化新层的问题。通过引入shape functional及其拓扑导数，该方法从最优控制理论角度推导出闭式表达式，并将其与Hamiltonian联系起来，优化条件转化为一个特征值问题。实验结果表明，该方法在全连接网络、卷积神经网络和视觉Transformer上处理回归和分类任务时，表现优于基线策略，并在转移学习等领域具有潜在应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06885v1",
      "published_date": "2025-02-08 23:01:07 UTC",
      "updated_date": "2025-02-08 23:01:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:44:21.393816"
    },
    {
      "arxiv_id": "2502.05714v1",
      "title": "Proving the Coding Interview: A Benchmark for Formally Verified Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Quinn Dougherty",
        "Ronak Mehta"
      ],
      "abstract": "We introduce the Formally Verified Automated Programming Progress Standards,\nor FVAPPS, a benchmark of 4715 samples for writing programs and proving their\ncorrectness, the largest formal verification benchmark, including 1083 curated\nand quality controlled samples. Previously, APPS provided a benchmark and\ndataset for programming puzzles to be completed in Python and checked against\nunit tests, of the kind seen in technical assessments in the software\nengineering industry. Building upon recent approaches for benchmarks in\ninteractive theorem proving, we generalize the unit tests to Lean 4 theorems\ngiven without proof (i.e., using Lean's \"sorry\" keyword). On the 406 theorems\nof 100 randomly selected samples, Sonnet correctly proves 30% and Gemini\ncorrectly proves 18%. We challenge the machine learning and program synthesis\ncommunities to solve both each general purpose programming problem and its\nassociated correctness specifications. The benchmark is available at\nhttps://huggingface.co/datasets/quinn-dougherty/fvapps.",
      "tldr_zh": "本文引入了 FVAPPS 基准，这是一个包含 4715 个样本的正式验证数据集，用于编写程序并证明其正确性，是目前最大的此类基准，包括 1083 个精选样本。FVAPPS 基于之前的 APPS 基准，将 Python 单元测试推广到 Lean 4 定理证明（使用 \"sorry\" 关键字），以评估代码生成的准确性和形式化正确性。在 100 个随机样本中的 406 个定理上，Sonnet 正确证明了 30%，Gemini 证明了 18%，并挑战机器学习和程序合成社区解决这些编程问题及其正确性规范。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.SE",
      "comment": "8 pages, to appear at the 2025LLM4Code Workshop at ICSE 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.05714v1",
      "published_date": "2025-02-08 22:54:58 UTC",
      "updated_date": "2025-02-08 22:54:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:44:34.509593"
    },
    {
      "arxiv_id": "2502.05713v1",
      "title": "4D VQ-GAN: Synthesising Medical Scans at Any Time Point for Personalised Disease Progression Modelling of Idiopathic Pulmonary Fibrosis",
      "title_zh": "翻译失败",
      "authors": [
        "An Zhao",
        "Moucheng Xu",
        "Ahmed H. Shahin",
        "Wim Wuyts",
        "Mark G. Jones",
        "Joseph Jacob",
        "Daniel C. Alexander"
      ],
      "abstract": "Understanding the progression trajectories of diseases is crucial for early\ndiagnosis and effective treatment planning. This is especially vital for\nlife-threatening conditions such as Idiopathic Pulmonary Fibrosis (IPF), a\nchronic, progressive lung disease with a prognosis comparable to many cancers.\nComputed tomography (CT) imaging has been established as a reliable diagnostic\ntool for IPF. Accurately predicting future CT scans of early-stage IPF patients\ncan aid in developing better treatment strategies, thereby improving survival\noutcomes. In this paper, we propose 4D Vector Quantised Generative Adversarial\nNetworks (4D-VQ-GAN), a model capable of generating realistic CT volumes of IPF\npatients at any time point. The model is trained using a two-stage approach. In\nthe first stage, a 3D-VQ-GAN is trained to reconstruct CT volumes. In the\nsecond stage, a Neural Ordinary Differential Equation (ODE) based temporal\nmodel is trained to capture the temporal dynamics of the quantised embeddings\ngenerated by the encoder in the first stage. We evaluate different\nconfigurations of our model for generating longitudinal CT scans and compare\nthe results against ground truth data, both quantitatively and qualitatively.\nFor validation, we conduct survival analysis using imaging biomarkers derived\nfrom generated CT scans and achieve a C-index comparable to that of biomarkers\nderived from the real CT scans. The survival analysis results demonstrate the\npotential clinical utility inherent to generated longitudinal CT scans, showing\nthat they can reliably predict survival outcomes.",
      "tldr_zh": "本研究提出 4D-VQ-GAN 模型，用于合成特发性肺纤维化 (IPF) 患者的 CT 扫描图像，以实现个性化疾病进展建模。该模型采用两阶段训练方法：首先训练 3D-VQ-GAN 来重建 CT 体积，其次使用 Neural Ordinary Differential Equation (ODE) 基于的时序模型捕捉量化嵌入的动态变化。实验结果显示，生成的纵向 CT 扫描在定量和定性上与真实数据相近，并通过生存分析验证其临床实用性，C-index 与真实生物标志物相当，从而为 IPF 的早期诊断和治疗策略优化提供可靠工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "4D image synthesis, VQ-GAN, neural ODEs, spatial temporal disease\n  progression modelling, CT, IPF",
      "pdf_url": "http://arxiv.org/pdf/2502.05713v1",
      "published_date": "2025-02-08 22:25:53 UTC",
      "updated_date": "2025-02-08 22:25:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:44:45.189767"
    },
    {
      "arxiv_id": "2502.05704v1",
      "title": "Rethinking Word Similarity: Semantic Similarity through Classification Confusion",
      "title_zh": "翻译失败",
      "authors": [
        "Kaitlyn Zhou",
        "Haishan Gao",
        "Sarah Chen",
        "Dan Edelstein",
        "Dan Jurafsky",
        "Chen Shani"
      ],
      "abstract": "Word similarity has many applications to social science and cultural\nanalytics tasks like measuring meaning change over time and making sense of\ncontested terms. Yet traditional similarity methods based on cosine similarity\nbetween word embeddings cannot capture the context-dependent, asymmetrical,\npolysemous nature of semantic similarity. We propose a new measure of\nsimilarity, Word Confusion, that reframes semantic similarity in terms of\nfeature-based classification confusion. Word Confusion is inspired by Tversky's\nsuggestion that similarity features be chosen dynamically. Here we train a\nclassifier to map contextual embeddings to word identities and use the\nclassifier confusion (the probability of choosing a confounding word c instead\nof the correct target word t) as a measure of the similarity of c and t. The\nset of potential confounding words acts as the chosen features. Our method is\ncomparable to cosine similarity in matching human similarity judgments across\nseveral datasets (MEN, WirdSim353, and SimLex), and can measure similarity\nusing predetermined features of interest. We demonstrate our model's ability to\nmake use of dynamic features by applying it to test a hypothesis about changes\nin the 18th C. meaning of the French word \"revolution\" from popular to state\naction during the French Revolution. We hope this reimagining of semantic\nsimilarity will inspire the development of new tools that better capture the\nmulti-faceted and dynamic nature of language, advancing the fields of\ncomputational social science and cultural analytics and beyond.",
      "tldr_zh": "该论文重新审视了词相似度问题，指出传统基于余弦 similarity 的词嵌入方法无法捕捉语义 similarity 的语境依赖、非对称和多义特性。作者提出一种新方法 Word Confusion，将语义相似度重新定义为基于特征的分类 confusion，通过训练分类器映射 contextual embeddings 到词标识，并使用选择混淆词的概率作为相似度度量。实验结果显示，该方法在 MEN、WordSim353 和 SimLex 数据集上与余弦 similarity 相当，并能利用动态特征测试历史语言变化，如 18 世纪法国词 \"revolution\" 的含义从流行行动转向国家行动，从而为计算社会科学和文化分析提供更灵活的工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL-main-2025",
      "pdf_url": "http://arxiv.org/pdf/2502.05704v1",
      "published_date": "2025-02-08 21:55:38 UTC",
      "updated_date": "2025-02-08 21:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:44:58.709267"
    },
    {
      "arxiv_id": "2502.05699v1",
      "title": "Context information can be more important than reasoning for time series forecasting with a large language model",
      "title_zh": "翻译失败",
      "authors": [
        "Janghoon Yang"
      ],
      "abstract": "With the evolution of large language models (LLMs), there is growing interest\nin leveraging LLMs for time series tasks. In this paper, we explore the\ncharacteristics of LLMs for time series forecasting by considering various\nexisting and proposed prompting techniques. Forecasting for both short and long\ntime series was evaluated. Our findings indicate that no single prompting\nmethod is universally applicable. It was also observed that simply providing\nproper context information related to the time series, without additional\nreasoning prompts, can achieve performance comparable to the best-performing\nprompt for each case. From this observation, it is expected that providing\nproper context information can be more crucial than a prompt for specific\nreasoning in time series forecasting. Several weaknesses in prompting for time\nseries forecasting were also identified. First, LLMs often fail to follow the\nprocedures described by the prompt. Second, when reasoning steps involve simple\nalgebraic calculations with several operands, LLMs often fail to calculate\naccurately. Third, LLMs sometimes misunderstand the semantics of prompts,\nresulting in incomplete responses.",
      "tldr_zh": "本文研究了大型语言模型（LLMs）在时间序列预测中的特性，通过评估各种现有和提出的提示技术，对短和长序列进行实验。结果显示，没有一种提示方法是通用的，而提供适当的上下文信息（无需额外推理提示）即可实现与最佳提示相当的性能，这表明上下文信息可能比特定推理提示更关键。同时，论文识别了LLMs的几处弱点，包括未能遵循提示程序、处理简单代数计算不准确，以及有时误解提示语义导致响应不完整。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05699v1",
      "published_date": "2025-02-08 21:39:07 UTC",
      "updated_date": "2025-02-08 21:39:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:45:08.151933"
    },
    {
      "arxiv_id": "2502.06884v1",
      "title": "Learning Conformal Abstention Policies for Adaptive Risk Management in Large Language and Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sina Tayebati",
        "Divake Kumar",
        "Nastaran Darabi",
        "Dinithi Jayasuriya",
        "Ranganath Krishnan",
        "Amit Ranjan Trivedi"
      ],
      "abstract": "Large Language and Vision-Language Models (LLMs/VLMs) are increasingly used\nin safety-critical applications, yet their opaque decision-making complicates\nrisk assessment and reliability. Uncertainty quantification (UQ) helps assess\nprediction confidence and enables abstention when uncertainty is high.\nConformal prediction (CP), a leading UQ method, provides statistical guarantees\nbut relies on static thresholds, which fail to adapt to task complexity and\nevolving data distributions, leading to suboptimal trade-offs in accuracy,\ncoverage, and informativeness. To address this, we propose learnable conformal\nabstention, integrating reinforcement learning (RL) with CP to optimize\nabstention thresholds dynamically. By treating CP thresholds as adaptive\nactions, our approach balances multiple objectives, minimizing prediction set\nsize while maintaining reliable coverage. Extensive evaluations across diverse\nLLM/VLM benchmarks show our method outperforms Least Ambiguous Classifiers\n(LAC) and Adaptive Prediction Sets (APS), improving accuracy by up to 3.2%,\nboosting AUROC for hallucination detection by 22.19%, enhancing\nuncertainty-guided selective generation (AUARC) by 21.17%, and reducing\ncalibration error by 70%-85%. These improvements hold across multiple models\nand datasets while consistently meeting the 90% coverage target, establishing\nour approach as a more effective and flexible solution for reliable\ndecision-making in safety-critical applications. The code is available at:\n{https://github.com/sinatayebati/vlm-uncertainty}.",
      "tldr_zh": "这篇论文针对 Large Language and Vision-Language Models (LLMs/VLMs) 在安全关键应用中的风险管理问题，提出 learnable conformal abstention 方法，将 Reinforcement Learning (RL) 与 Conformal Prediction (CP) 整合，动态优化 abstention 阈值以适应任务复杂性和数据分布变化，从而平衡准确率、覆盖率和信息性。实验在多种 LLM/VLM 基准上显示，该方法优于 Least Ambiguous Classifiers (LAC) 和 Adaptive Prediction Sets (APS)，提高准确率高达 3.2%，提升 hallucination 检测的 AUROC 22.19%，改善 uncertainty-guided selective generation 的 AUARC 21.17%，并将校准错误减少 70%-85%，同时保持 90% 覆盖率目标。该创新方法为 LLMs/VLMs 的可靠决策提供了更灵活有效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06884v1",
      "published_date": "2025-02-08 21:30:41 UTC",
      "updated_date": "2025-02-08 21:30:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:45:22.818233"
    },
    {
      "arxiv_id": "2502.05695v1",
      "title": "Semantic-Aware Adaptive Video Streaming Using Latent Diffusion Models for Wireless Networks",
      "title_zh": "语义感知的自适应视频流传输：利用潜在扩散",
      "authors": [
        "Zijiang Yan",
        "Jianhua Pei",
        "Hongda Wu",
        "Hina Tabassum",
        "Ping Wang"
      ],
      "abstract": "This paper proposes a novel framework for real-time adaptive-bitrate video\nstreaming by integrating latent diffusion models (LDMs) within the FFmpeg\ntechniques. This solution addresses the challenges of high bandwidth usage,\nstorage inefficiencies, and quality of experience (QoE) degradation associated\nwith traditional constant bitrate streaming (CBS) and adaptive bitrate\nstreaming (ABS). The proposed approach leverages LDMs to compress I-frames into\na latent space, offering significant storage and semantic transmission savings\nwithout sacrificing high visual quality. While it keeps B-frames and P-frames\nas adjustment metadata to ensure efficient video reconstruction at the user\nside, the proposed framework is complemented with the most state-of-the-art\ndenoising and video frame interpolation (VFI) techniques. These techniques\nmitigate semantic ambiguity and restore temporal coherence between frames, even\nin noisy wireless communication environments. Experimental results demonstrate\nthe proposed method achieves high-quality video streaming with optimized\nbandwidth usage, outperforming state-of-the-art solutions in terms of QoE and\nresource efficiency. This work opens new possibilities for scalable real-time\nvideo streaming in 5G and future post-5G networks.",
      "tldr_zh": "这篇论文提出了一种新的实时自适应比特率视频流框架，将潜在扩散模型 (LDMs) 整合到 FFmpeg 技术中，以解决传统视频流的高带宽消耗、存储低效和 QoE 下降问题。该框架通过将 I-frames 压缩到潜在空间并保留 B-frames 和 P-frames 作为调整元数据，结合先进的去噪和视频帧插值 (VFI) 技术，缓解无线网络中的语义模糊和帧间时间不连贯性。实验结果表明，该方法在 QoE 和资源效率方面优于现有方案，为 5G 和后 5G 网络的视频流应用提供了可扩展的新途径。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.MM",
      "comment": "Submission for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2502.05695v1",
      "published_date": "2025-02-08 21:14:28 UTC",
      "updated_date": "2025-02-08 21:14:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:45:33.974157"
    },
    {
      "arxiv_id": "2502.05694v1",
      "title": "Zero-Shot End-to-End Relation Extraction in Chinese: A Comparative Study of Gemini, LLaMA and ChatGPT",
      "title_zh": "翻译失败",
      "authors": [
        "Shaoshuai Du",
        "Yiyi Tao",
        "Yixian Shen",
        "Hang Zhang",
        "Yanxin Shen",
        "Xinyu Qiu",
        "Chuanqi Shi"
      ],
      "abstract": "This study investigates the performance of various large language models\n(LLMs) on zero-shot end-to-end relation extraction (RE) in Chinese, a task that\nintegrates entity recognition and relation extraction without requiring\nannotated data. While LLMs show promise for RE, most prior work focuses on\nEnglish or assumes pre-annotated entities, leaving their effectiveness in\nChinese RE largely unexplored. To bridge this gap, we evaluate ChatGPT, Gemini,\nand LLaMA based on accuracy, efficiency, and adaptability. ChatGPT demonstrates\nthe highest overall performance, balancing precision and recall, while Gemini\nachieves the fastest inference speed, making it suitable for real-time\napplications. LLaMA underperforms in both accuracy and latency, highlighting\nthe need for further adaptation. Our findings provide insights into the\nstrengths and limitations of LLMs for zero-shot Chinese RE, shedding light on\ntrade-offs between accuracy and efficiency. This study serves as a foundation\nfor future research aimed at improving LLM adaptability to complex linguistic\ntasks in Chinese NLP.",
      "tldr_zh": "这篇论文比较了 ChatGPT、Gemini 和 LLaMA 等 LLMs 在中文 Zero-Shot End-to-End Relation Extraction 任务中的性能，该任务整合实体识别和关系抽取而不需标注数据。研究评估了这些模型在准确性、效率和适应性方面的表现，结果显示 ChatGPT 平衡了精确度和召回率，Gemini 具有最快的推理速度适合实时应用，而 LLaMA 在准确性和延迟上表现较差。论文揭示了 LLMs 在中文 RE 中的优缺点，并为未来提升其在复杂中文 NLP 任务中的适应性提供了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05694v1",
      "published_date": "2025-02-08 21:12:04 UTC",
      "updated_date": "2025-02-08 21:12:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:45:47.985966"
    },
    {
      "arxiv_id": "2502.05690v1",
      "title": "Managing Geological Uncertainty in Critical Mineral Supply Chains: A POMDP Approach with Application to U.S. Lithium Resources",
      "title_zh": "翻译失败",
      "authors": [
        "Mansur Arief",
        "Yasmine Alonso",
        "CJ Oshiro",
        "William Xu",
        "Anthony Corso",
        "David Zhen Yin",
        "Jef K. Caers",
        "Mykel J. Kochenderfer"
      ],
      "abstract": "The world is entering an unprecedented period of critical mineral demand,\ndriven by the global transition to renewable energy technologies and electric\nvehicles. This transition presents unique challenges in mineral resource\ndevelopment, particularly due to geological uncertainty-a key characteristic\nthat traditional supply chain optimization approaches do not adequately\naddress. To tackle this challenge, we propose a novel application of Partially\nObservable Markov Decision Processes (POMDPs) that optimizes critical mineral\nsourcing decisions while explicitly accounting for the dynamic nature of\ngeological uncertainty. Through a case study of the U.S. lithium supply chain,\nwe demonstrate that POMDP-based policies achieve superior outcomes compared to\ntraditional approaches, especially when initial reserve estimates are\nimperfect. Our framework provides quantitative insights for balancing domestic\nresource development with international supply diversification, offering\npolicymakers a systematic approach to strategic decision-making in critical\nmineral supply chains.",
      "tldr_zh": "本研究针对关键矿物供应链中地质不确定性的挑战，提出了一种基于Partially Observable Markov Decision Processes (POMDPs)的优化框架，以优化矿物采购决策并动态处理不确定性。论文通过美国锂供应链的案例研究，证明POMDP策略在初始储量估计不准确的情况下，比传统方法取得更优结果。相比传统供应链优化方法，该框架能更好地平衡国内资源开发与国际供应多样化，提供定量洞见。总体上，这为决策者在关键矿物供应链战略决策中提供了系统性方法。",
      "categories": [
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05690v1",
      "published_date": "2025-02-08 20:44:44 UTC",
      "updated_date": "2025-02-08 20:44:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:45:59.557906"
    },
    {
      "arxiv_id": "2502.05685v1",
      "title": "Mobile Application Threats and Security",
      "title_zh": "移动应用威胁与安全",
      "authors": [
        "Timur Mirzoev",
        "Mark Miller",
        "Shamimara Lasker",
        "Michael Brannon"
      ],
      "abstract": "The movement to mobile computing solutions provides flexibility to different\nusers whether it is a business user, a student, or even providing entertainment\nto children and adults of all ages. Due to these emerging technologies mobile\nusers are unable to safeguard private information in a very effective way and\ncybercrimes are increasing day by day. This manuscript will focus on security\nvulnerabilities in the mobile computing industry, especially focusing on\ntablets and smart phones. This study will dive into current security threats\nfor the Android & Apple iOS market, exposing security risks and threats that\nthe novice or average user may not be aware of. The purpose of this study is to\nanalyze current security risks and threats, and provide solutions that may be\ndeployed to protect against such threats.",
      "tldr_zh": "本论文探讨了移动应用的安全威胁，强调移动计算的灵活性（如针对商业用户、学生或娱乐需求）导致用户难以有效保护私人信息，并使网络犯罪日益增多。研究重点分析了 Android 和 iOS 平台的当前安全漏洞，包括平板和智能手机的潜在风险，这些风险可能被普通用户忽略。最终，该研究提供了针对这些威胁的解决方案建议，以帮助用户部署防护措施。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05685v1",
      "published_date": "2025-02-08 20:33:57 UTC",
      "updated_date": "2025-02-08 20:33:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:46:09.525701"
    },
    {
      "arxiv_id": "2502.05684v2",
      "title": "Machine Unlearning via Information Theoretic Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Shizhou Xu",
        "Thomas Strohmer"
      ],
      "abstract": "How can we effectively remove or \"unlearn\" undesirable information, such as\nspecific features or individual data points, from a learning outcome while\nminimizing utility loss and ensuring rigorous guarantees? We introduce a\nmathematical framework based on information-theoretic regularization to address\nboth feature and data point unlearning. For feature unlearning, we derive a\nunified solution that simultaneously optimizes diverse learning objectives,\nincluding entropy, conditional entropy, KL-divergence, and the energy of\nconditional probability. For data point unlearning, we first propose a novel\ndefinition that serves as a practical condition for unlearning via retraining,\nis easy to verify, and aligns with the principles of differential privacy from\nan inference perspective. Then, we provide provable guarantees for our\nframework on data point unlearning. By combining flexibility in learning\nobjectives with simplicity in regularization design, our approach is highly\nadaptable and practical for a wide range of machine learning and AI\napplications.",
      "tldr_zh": "该论文提出了一种基于 information-theoretic regularization 的数学框架，用于机器学习中的 unlearning，即移除特定特征或数据点，同时最小化效用损失并提供严格保证。对于 feature unlearning，该框架提供一个统一解决方案，通过优化 entropy、conditional entropy、KL-divergence 和 energy of conditional probability 等学习目标来实现。对于 data point unlearning，论文引入了一个新定义，作为重新训练的实用条件，便于验证并与 differential privacy 原则一致，并为框架提供了可证明的保证。这种方法灵活且易于应用，可广泛用于机器学习和 AI 领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.05684v2",
      "published_date": "2025-02-08 20:33:06 UTC",
      "updated_date": "2025-02-11 19:45:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:46:22.656722"
    },
    {
      "arxiv_id": "2502.17454v1",
      "title": "Smart Sampling Strategies for Wireless Industrial Data Acquisition",
      "title_zh": "无线工业数据采集的智能采样策略",
      "authors": [
        "Marcos Soto"
      ],
      "abstract": "In industrial environments, data acquisition accuracy is crucial for process\ncontrol and optimization. Wireless telemetry has proven to be a valuable tool\nfor improving efficiency in well-testing operations, enabling bidirectional\ncommunication and real-time control of downhole tools. However, high sampling\nfrequencies present challenges in telemetry, including data storage,\ntransmission, computational resource consumption, and battery life of wireless\ndevices. This study explores how optimizing data acquisition strategies can\nreduce aliasing effects and systematic errors while improving sampling rates\nwithout compromising measurement accuracy. A reduction of 80% in sampling\nfrequency was achieved without degrading measurement quality, demonstrating the\npotential for resource optimization in industrial environments.",
      "tldr_zh": "本研究针对无线工业数据采集中的高采样频率问题，探讨了智能采样策略，以缓解数据存储、传输、计算资源消耗和电池寿命的挑战，同时减少aliasing effects和系统错误。研究优化了数据采集方法，使采样频率减少80%，而测量准确性保持不变。结果表明，这种策略在工业环境中具有显著的资源优化潜力，有助于提升过程控制和效率。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "eess.SP",
      "comment": "17 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.17454v1",
      "published_date": "2025-02-08 20:22:29 UTC",
      "updated_date": "2025-02-08 20:22:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:46:34.237666"
    },
    {
      "arxiv_id": "2502.05672v1",
      "title": "On the Convergence and Stability of Upside-Down Reinforcement Learning, Goal-Conditioned Supervised Learning, and Online Decision Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Miroslav Štrupl",
        "Oleg Szehr",
        "Francesco Faccio",
        "Dylan R. Ashley",
        "Rupesh Kumar Srivastava",
        "Jürgen Schmidhuber"
      ],
      "abstract": "This article provides a rigorous analysis of convergence and stability of\nEpisodic Upside-Down Reinforcement Learning, Goal-Conditioned Supervised\nLearning and Online Decision Transformers. These algorithms performed\ncompetitively across various benchmarks, from games to robotic tasks, but their\ntheoretical understanding is limited to specific environmental conditions. This\nwork initiates a theoretical foundation for algorithms that build on the broad\nparadigm of approaching reinforcement learning through supervised learning or\nsequence modeling. At the core of this investigation lies the analysis of\nconditions on the underlying environment, under which the algorithms can\nidentify optimal solutions. We also assess whether emerging solutions remain\nstable in situations where the environment is subject to tiny levels of noise.\nSpecifically, we study the continuity and asymptotic convergence of\ncommand-conditioned policies, values and the goal-reaching objective depending\non the transition kernel of the underlying Markov Decision Process. We\ndemonstrate that near-optimal behavior is achieved if the transition kernel is\nlocated in a sufficiently small neighborhood of a deterministic kernel. The\nmentioned quantities are continuous (with respect to a specific topology) at\ndeterministic kernels, both asymptotically and after a finite number of\nlearning cycles. The developed methods allow us to present the first explicit\nestimates on the convergence and stability of policies and values in terms of\nthe underlying transition kernels. On the theoretical side we introduce a\nnumber of new concepts to reinforcement learning, like working in segment\nspaces, studying continuity in quotient topologies and the application of the\nfixed-point theory of dynamical systems. The theoretical study is accompanied\nby a detailed investigation of example environments and numerical experiments.",
      "tldr_zh": "这篇论文对 Episodic Upside-Down Reinforcement Learning、Goal-Conditioned Supervised Learning 和 Online Decision Transformers 等算法的收敛性和稳定性进行了严格分析，旨在为通过监督学习或序列建模处理强化学习的范式建立理论基础。研究重点评估了环境条件（如 Markov Decision Process 的过渡核）下算法识别最优解的能力，并证明了在过渡核接近确定性核时，这些算法能实现近似最优行为，同时保持政策、值函数和目标实现目标的连续性和渐近收敛。论文引入了新概念，如 segment spaces、quotient topologies 和 fixed-point theory，并通过示例环境和数值实验提供了显式收敛稳定性估计，为这些算法在实际应用中提升可靠性奠定了基础。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "cs.SY",
        "eess.SY",
        "68T07",
        "I.2.6; I.5.1"
      ],
      "primary_category": "stat.ML",
      "comment": "85 pages in main text + 4 pages of references + 26 pages of\n  appendices, 12 figures in main text + 2 figures in appendices; source code\n  available at https://github.com/struplm/eUDRL-GCSL-ODT-Convergence-public",
      "pdf_url": "http://arxiv.org/pdf/2502.05672v1",
      "published_date": "2025-02-08 19:26:22 UTC",
      "updated_date": "2025-02-08 19:26:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:46:49.216991"
    },
    {
      "arxiv_id": "2502.05670v3",
      "title": "Language Models Largely Exhibit Human-like Constituent Ordering Preferences",
      "title_zh": "翻译失败",
      "authors": [
        "Ada Defne Tur",
        "Gaurav Kamath",
        "Siva Reddy"
      ],
      "abstract": "Though English sentences are typically inflexible vis-\\`a-vis word order,\nconstituents often show far more variability in ordering. One prominent theory\npresents the notion that constituent ordering is directly correlated with\nconstituent weight: a measure of the constituent's length or complexity. Such\ntheories are interesting in the context of natural language processing (NLP),\nbecause while recent advances in NLP have led to significant gains in the\nperformance of large language models (LLMs), much remains unclear about how\nthese models process language, and how this compares to human language\nprocessing. In particular, the question remains whether LLMs display the same\npatterns with constituent movement, and may provide insights into existing\ntheories on when and how the shift occurs in human language. We compare a\nvariety of LLMs with diverse properties to evaluate broad LLM performance on\nfour types of constituent movement: heavy NP shift, particle movement, dative\nalternation, and multiple PPs. Despite performing unexpectedly around particle\nmovement, LLMs generally align with human preferences around constituent\nordering.",
      "tldr_zh": "该研究探讨大型语言模型（LLMs）在成分顺序偏好上是否类似于人类，通过比较多种 LLMs 在 heavy NP shift、particle movement、dative alternation 和 multiple PPs 等四种成分移动任务上的表现。结果显示，LLMs 总体上与人类偏好一致，尽管在 particle movement 上表现异常，这为理解 LLMs 的语言处理机制提供了新洞见。论文有助于验证现有理论，并揭示 LLMs 如何模拟人类语言行为的模式。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2502.05670v3",
      "published_date": "2025-02-08 19:13:40 UTC",
      "updated_date": "2025-02-14 21:06:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:46:58.821746"
    },
    {
      "arxiv_id": "2502.05664v1",
      "title": "CODESIM: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging",
      "title_zh": "翻译失败",
      "authors": [
        "Md. Ashraful Islam",
        "Mohammed Eunus Ali",
        "Md Rizwan Parvez"
      ],
      "abstract": "Large Language Models (LLMs) have made significant strides in code generation\nand problem solving. Current approaches employ external tool-based iterative\ndebuggers that use compiler or other tool-based runtime feedback to refine\ncoarse programs generated by various methods. However, the effectiveness of\nthese approaches heavily relies on the quality of the initial code generation,\nwhich remains an open challenge. In this paper, we introduce CodeSim, a novel\nmulti-agent code generation framework that comprehensively addresses the stages\nof program synthesis-planning, coding, and debugging-through a human-like\nperception approach. As human verifies their understanding of any algorithms\nthrough visual simulation, CodeSim uniquely features a method of plan\nverification and internal debugging through the step-by-step simulation of\ninput/output. Extensive experiments across seven challenging competitive\nproblem-solving and program synthesis benchmarks demonstrate CodeSim's\nremarkable code generation capabilities. Our framework achieves new\nstate-of-the-art (pass@1) results-(HumanEval 95.1%, MBPP 90.7%, APPS 22%, and\nCodeContests 29.1%). Furthermore, our method shows potential for even greater\nenhancement when cascaded with external debuggers. To facilitate further\nresearch and development in this area, we have open-sourced our framework in\nthis link (https://kagnlp.github.io/codesim.github.io/).",
      "tldr_zh": "本文提出 CodeSim，一种多智能体代码生成框架，通过模拟驱动的规划、编码和调试，模仿人类通过步步模拟输入/输出来验证计划和内部调试，从而全面解决程序合成中的挑战。不同于依赖外部工具的迭代调试方法，CodeSim 强调初始代码生成的可靠性，并在七个竞争性基准上取得新最先进结果，包括 HumanEval 95.1%、MBPP 90.7%、APPS 22% 和 CodeContests 29.1%。实验还表明，该框架与外部调试器结合时可进一步提升性能，并已开源以推动相关研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in NAACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2502.05664v1",
      "published_date": "2025-02-08 18:43:59 UTC",
      "updated_date": "2025-02-08 18:43:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:47:11.455822"
    },
    {
      "arxiv_id": "2502.05651v1",
      "title": "KMI: A Dataset of Korean Motivational Interviewing Dialogues for Psychotherapy",
      "title_zh": "KMI：韩国动机性访谈对话数据集用于心理治疗",
      "authors": [
        "Hyunjong Kim",
        "Suyeon Lee",
        "Yeongjae Cho",
        "Eunseo Ryu",
        "Yohan Jo",
        "Suran Seong",
        "Sungzoon Cho"
      ],
      "abstract": "The increasing demand for mental health services has led to the rise of\nAI-driven mental health chatbots, though challenges related to privacy, data\ncollection, and expertise persist. Motivational Interviewing (MI) is gaining\nattention as a theoretical basis for boosting expertise in the development of\nthese chatbots. However, existing datasets are showing limitations for training\nchatbots, leading to a substantial demand for publicly available resources in\nthe field of MI and psychotherapy. These challenges are even more pronounced in\nnon-English languages, where they receive less attention. In this paper, we\npropose a novel framework that simulates MI sessions enriched with the\nexpertise of professional therapists. We train an MI forecaster model that\nmimics the behavioral choices of professional therapists and employ Large\nLanguage Models (LLMs) to generate utterances through prompt engineering. Then,\nwe present KMI, the first synthetic dataset theoretically grounded in MI,\ncontaining 1,000 high-quality Korean Motivational Interviewing dialogues.\nThrough an extensive expert evaluation of the generated dataset and the\ndialogue model trained on it, we demonstrate the quality, expertise, and\npracticality of KMI. We also introduce novel metrics derived from MI theory in\norder to evaluate dialogues from the perspective of MI.",
      "tldr_zh": "本研究针对AI心理健康聊天机器人的隐私和数据挑战，提出一个新框架，利用专业治疗师的专长和Large Language Models (LLMs)通过提示工程模拟Motivational Interviewing (MI)会话。研究者训练了一个MI预测模型来模仿治疗师的行为，并创建了KMI数据集，这是首个基于MI理论的合成数据集，包含1000个高质量韩语对话。通过专家评估和引入的MI理论衍生指标，证明了数据集的专业性、实用性和整体质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2502.05651v1",
      "published_date": "2025-02-08 17:53:41 UTC",
      "updated_date": "2025-02-08 17:53:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:47:23.539713"
    },
    {
      "arxiv_id": "2502.07813v2",
      "title": "CryptoX : Compositional Reasoning Evaluation of Large Language Models",
      "title_zh": "CryptoX：大型语言模型的组合推理评估",
      "authors": [
        "Jiajun Shi",
        "Chaoren Wei",
        "Liqun Yang",
        "Zekun Moore Wang",
        "Chenghao Yang",
        "Ge Zhang",
        "Stephen Huang",
        "Tao Peng",
        "Jian Yang",
        "Zhoufutu Wen"
      ],
      "abstract": "The compositional reasoning capacity has long been regarded as critical to\nthe generalization and intelligence emergence of large language models LLMs.\nHowever, despite numerous reasoning-related benchmarks, the compositional\nreasoning capacity of LLMs is rarely studied or quantified in the existing\nbenchmarks. In this paper, we introduce CryptoX, an evaluation framework that,\nfor the first time, combines existing benchmarks and cryptographic, to quantify\nthe compositional reasoning capacity of LLMs. Building upon CryptoX, we\nconstruct CryptoBench, which integrates these principles into several\nbenchmarks for systematic evaluation. We conduct detailed experiments on widely\nused open-source and closed-source LLMs using CryptoBench, revealing a huge gap\nbetween open-source and closed-source LLMs. We further conduct thorough\nmechanical interpretability experiments to reveal the inner mechanism of LLMs'\ncompositional reasoning, involving subproblem decomposition, subproblem\ninference, and summarizing subproblem conclusions. Through analysis based on\nCryptoBench, we highlight the value of independently studying compositional\nreasoning and emphasize the need to enhance the compositional reasoning\ncapabilities of LLMs.",
      "tldr_zh": "本论文引入 CryptoX 框架，这是首个结合现有基准和加密学原理来量化大语言模型 (LLMs) 的组合推理能力。研究构建了 CryptoBench 基准，用于系统评估 LLMs 在组合推理方面的表现，并通过实验发现开源和闭源 LLMs 之间存在显著差距。进一步的机械可解释性实验揭示了 LLMs 组合推理的内部机制，包括子问题分解、子问题推理以及总结子问题结论。最终，论文强调独立研究组合推理的价值，并呼吁增强 LLMs 的这一能力以提升其泛化和智能水平。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07813v2",
      "published_date": "2025-02-08 17:19:43 UTC",
      "updated_date": "2025-03-12 13:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:47:35.281728"
    },
    {
      "arxiv_id": "2502.05641v1",
      "title": "Generating Physically Realistic and Directable Human Motions from Multi-Modal Inputs",
      "title_zh": "基于多",
      "authors": [
        "Aayam Shrestha",
        "Pan Liu",
        "German Ros",
        "Kai Yuan",
        "Alan Fern"
      ],
      "abstract": "This work focuses on generating realistic, physically-based human behaviors\nfrom multi-modal inputs, which may only partially specify the desired motion.\nFor example, the input may come from a VR controller providing arm motion and\nbody velocity, partial key-point animation, computer vision applied to videos,\nor even higher-level motion goals. This requires a versatile low-level humanoid\ncontroller that can handle such sparse, under-specified guidance, seamlessly\nswitch between skills, and recover from failures. Current approaches for\nlearning humanoid controllers from demonstration data capture some of these\ncharacteristics, but none achieve them all. To this end, we introduce the\nMasked Humanoid Controller (MHC), a novel approach that applies multi-objective\nimitation learning on augmented and selectively masked motion demonstrations.\nThe training methodology results in an MHC that exhibits the key capabilities\nof catch-up to out-of-sync input commands, combining elements from multiple\nmotion sequences, and completing unspecified parts of motions from sparse\nmultimodal input. We demonstrate these key capabilities for an MHC learned over\na dataset of 87 diverse skills and showcase different multi-modal use cases,\nincluding integration with planning frameworks to highlight MHC's ability to\nsolve new user-defined tasks without any finetuning.",
      "tldr_zh": "本研究旨在从多模态输入（如VR控制器、部分关键点动画或高层动作目标）生成真实且可定向的人类动作，这些输入可能仅部分指定所需动作。论文提出Masked Humanoid Controller (MHC)，一种新型框架，通过多目标模仿学习在增强和选择性掩码的动作演示数据上训练，实现对稀疏指导的处理、技能无缝切换以及从失败中恢复。MHC的关键能力包括追赶不同步输入、结合多个动作序列元素，以及自动完成未指定部分。实验在包含87个多样技能的数据集上验证了MHC的表现，并展示了其与规划框架集成的能力，可直接应用于新任务而无需微调。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05641v1",
      "published_date": "2025-02-08 17:02:11 UTC",
      "updated_date": "2025-02-08 17:02:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:47:48.974920"
    },
    {
      "arxiv_id": "2502.05638v1",
      "title": "ELMTEX: Fine-Tuning Large Language Models for Structured Clinical Information Extraction. A Case Study on Clinical Reports",
      "title_zh": "翻译失败",
      "authors": [
        "Aynur Guluzade",
        "Naguib Heiba",
        "Zeyd Boukhers",
        "Florim Hamiti",
        "Jahid Hasan Polash",
        "Yehya Mohamad",
        "Carlos A Velasco"
      ],
      "abstract": "Europe's healthcare systems require enhanced interoperability and\ndigitalization, driving a demand for innovative solutions to process legacy\nclinical data. This paper presents the results of our project, which aims to\nleverage Large Language Models (LLMs) to extract structured information from\nunstructured clinical reports, focusing on patient history, diagnoses,\ntreatments, and other predefined categories. We developed a workflow with a\nuser interface and evaluated LLMs of varying sizes through prompting strategies\nand fine-tuning. Our results show that fine-tuned smaller models match or\nsurpass larger counterparts in performance, offering efficiency for\nresource-limited settings. A new dataset of 60,000 annotated English clinical\nsummaries and 24,000 German translations was validated with automated and\nmanual checks. The evaluations used ROUGE, BERTScore, and entity-level metrics.\nThe work highlights the approach's viability and outlines future improvements.",
      "tldr_zh": "这篇论文介绍了ELMTEX框架，通过Fine-Tuning Large Language Models (LLMs)从非结构化临床报告中提取结构化信息，如患者历史、诊断和治疗，以应对欧洲医疗系统的互操作性和数字化需求。研究开发了一个工作流和用户界面，并通过提示策略和微调方法评估不同大小的LLMs，结果显示微调后的较小模型在性能上匹配或超过较大模型，适合资源有限的环境。论文还创建了一个新数据集，包括60,000个英文临床摘要和24,000个德文翻译，并使用ROUGE、BERTScore和实体级指标进行验证，证明了该方法的有效性并概述了未来改进方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.6; I.2.7; J.3"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05638v1",
      "published_date": "2025-02-08 16:44:56 UTC",
      "updated_date": "2025-02-08 16:44:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:48:04.203651"
    },
    {
      "arxiv_id": "2502.05637v1",
      "title": "Adversarial Machine Learning: Attacks, Defenses, and Open Challenges",
      "title_zh": "对抗性机器学习：攻击、防御以及开放挑战",
      "authors": [
        "Pranav K Jha"
      ],
      "abstract": "Adversarial Machine Learning (AML) addresses vulnerabilities in AI systems\nwhere adversaries manipulate inputs or training data to degrade performance.\nThis article provides a comprehensive analysis of evasion and poisoning\nattacks, formalizes defense mechanisms with mathematical rigor, and discusses\nthe challenges of implementing robust solutions in adaptive threat models.\nAdditionally, it highlights open challenges in certified robustness,\nscalability, and real-world deployment.",
      "tldr_zh": "本文探讨Adversarial Machine Learning (AML)，分析攻击者通过操纵输入或训练数据来破坏AI系统性能的漏洞，包括对evasion attacks和poisoning attacks的全面分析，并用数学严格性形式化defense mechanisms。该文讨论了在adaptive threat models中实现robust solutions的挑战，强调了确保AI系统安全性的关键问题。最后，它突出了open challenges，如certified robustness、scalability和real-world deployment，以推动未来研究。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05637v1",
      "published_date": "2025-02-08 16:43:17 UTC",
      "updated_date": "2025-02-08 16:43:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:48:12.876405"
    },
    {
      "arxiv_id": "2502.05632v1",
      "title": "Amorphous Fortress Online: Collaboratively Designing Open-Ended Multi-Agent AI and Game Environments",
      "title_zh": "翻译失败",
      "authors": [
        "M Charity",
        "Mayu Wilson",
        "Steven Lee",
        "Dipika Rajesh",
        "Sam Earle",
        "Julian Togelius"
      ],
      "abstract": "This work introduces Amorphous Fortress Online -- a web-based platform where\nusers can design petri-dish-like environments and games consisting of\nmulti-agent AI characters. Users can play, create, and share artificial life\nand game environments made up of microscopic but transparent finite-state\nmachine agents that interact with each other. The website features multiple\ninteractive editors and accessible settings to view the multi-agent\ninteractions directly from the browser. This system serves to provide a\ndatabase of thematically diverse AI and game environments that use the emergent\nbehaviors of simple AI agents.",
      "tldr_zh": "本研究引入了 Amorphous Fortress Online，这是一个基于网络的平台，允许用户协作设计开放式多智能体 AI 和游戏环境，类似于培养皿的设置。用户可以通过平台创建、玩耍和分享由微观透明的 finite-state machine agents 组成的虚拟生态，这些代理相互交互并产生 emergent behaviors。平台提供多个交互编辑器和易访问设置，让用户从浏览器直接观察多智能体互动，并建立一个主题多样的 AI 和游戏环境数据库，促进对简单代理紧急行为的探索。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05632v1",
      "published_date": "2025-02-08 16:25:52 UTC",
      "updated_date": "2025-02-08 16:25:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:48:23.380687"
    },
    {
      "arxiv_id": "2502.05615v1",
      "title": "XiHeFusion: Harnessing Large Language Models for Science Communication in Nuclear Fusion",
      "title_zh": "XiHeFusion：利用大语言模型进行核聚变领域的科学传播",
      "authors": [
        "Xiao Wang",
        "Qingquan Yang",
        "Fuling Wang",
        "Qiang Chen",
        "Wentao Wu",
        "Yu Jin",
        "Jingtao Jiang",
        "Liye Jin",
        "Bo Jiang",
        "Dengdi Sun",
        "Wanli Lv",
        "Meiwen Chen",
        "Zehua Chen",
        "Guosheng Xu",
        "Jin Tang"
      ],
      "abstract": "Nuclear fusion is one of the most promising ways for humans to obtain\ninfinite energy. Currently, with the rapid development of artificial\nintelligence, the mission of nuclear fusion has also entered a critical period\nof its development. How to let more people to understand nuclear fusion and\njoin in its research is one of the effective means to accelerate the\nimplementation of fusion. This paper proposes the first large model in the\nfield of nuclear fusion, XiHeFusion, which is obtained through supervised\nfine-tuning based on the open-source large model Qwen2.5-14B. We have collected\nmulti-source knowledge about nuclear fusion tasks to support the training of\nthis model, including the common crawl, eBooks, arXiv, dissertation, etc. After\nthe model has mastered the knowledge of the nuclear fusion field, we further\nused the chain of thought to enhance its logical reasoning ability, making\nXiHeFusion able to provide more accurate and logical answers. In addition, we\npropose a test questionnaire containing 180+ questions to assess the\nconversational ability of this science popularization large model. Extensive\nexperimental results show that our nuclear fusion dialogue model, XiHeFusion,\ncan perform well in answering science popularization knowledge. The pre-trained\nXiHeFusion model is released on https://github.com/Event-AHU/XiHeFusion.",
      "tldr_zh": "本文提出 XiHeFusion，这是核聚变领域首个大型语言模型，旨在通过 Large Language Models 提升科学传播，帮助更多人理解和参与核聚变研究。模型基于开源模型 Qwen2.5-14B 通过监督微调训练，利用多源知识（如常见爬取数据、电子书、arXiv 等），并应用 Chain of Thought 增强其逻辑推理能力，提供更准确的答案。研究设计了一个包含 180+ 问题的测试问卷，实验结果表明 XiHeFusion 在科普知识对话方面表现优秀。最终，预训练模型已开源在 GitHub 上，供进一步应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05615v1",
      "published_date": "2025-02-08 15:47:48 UTC",
      "updated_date": "2025-02-08 15:47:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:48:36.692928"
    },
    {
      "arxiv_id": "2502.05608v1",
      "title": "Closing the Responsibility Gap in AI-based Network Management: An Intelligent Audit System Approach",
      "title_zh": "填补基于 AI 的网络管理中的责任缺口：一种智能审计系统方法",
      "authors": [
        "Emanuel Figetakis",
        "Ahmed Refaey Hussein"
      ],
      "abstract": "Existing network paradigms have achieved lower downtime as well as a higher\nQuality of Experience (QoE) through the use of Artificial Intelligence\n(AI)-based network management tools. These AI management systems, allow for\nautomatic responses to changes in network conditions, lowering operation costs\nfor operators, and improving overall performance. While adopting AI-based\nmanagement tools enhance the overall network performance, it also introduce\nchallenges such as removing human supervision, privacy violations, algorithmic\nbias, and model inaccuracies. Furthermore, AI-based agents that fail to address\nthese challenges should be culpable themselves rather than the network as a\nwhole. To address this accountability gap, a framework consisting of a Deep\nReinforcement Learning (DRL) model and a Machine Learning (ML) model is\nproposed to identify and assign numerical values of responsibility to the\nAI-based management agents involved in any decision-making regarding the\nnetwork conditions, which eventually affects the end-user. A simulation\nenvironment was created for the framework to be trained using simulated network\noperation parameters. The DRL model had a 96% accuracy during testing for\nidentifying the AI-based management agents, while the ML model using gradient\ndescent learned the network conditions at an 83% accuracy during testing.",
      "tldr_zh": "该研究针对 AI-based 网络管理工具带来的责任差距问题（如缺乏人类监督、隐私侵犯和算法偏差）提出了一种智能审计系统框架。该框架结合 Deep Reinforcement Learning (DRL) 模型和 Machine Learning (ML) 模型，用于识别 AI 代理并分配数值责任，以确保决策过程的可问责性。在模拟环境中训练后，DRL 模型在测试中实现 96% 的准确率识别 AI 代理，ML 模型则以 83% 的准确率学习网络条件，从而提升了网络管理的整体可信度和性能。",
      "categories": [
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05608v1",
      "published_date": "2025-02-08 15:30:25 UTC",
      "updated_date": "2025-02-08 15:30:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:48:48.714799"
    },
    {
      "arxiv_id": "2502.06882v1",
      "title": "Multi-Agent Simulator Drives Language Models for Legal Intensive Interaction",
      "title_zh": "翻译失败",
      "authors": [
        "Shengbin Yue",
        "Ting Huang",
        "Zheng Jia",
        "Siyuan Wang",
        "Shujun Liu",
        "Yun Song",
        "Xuanjing Huang",
        "Zhongyu Wei"
      ],
      "abstract": "Large Language Models (LLMs) have significantly advanced legal intelligence,\nbut the scarcity of scenario data impedes the progress toward interactive legal\nscenarios. This paper introduces a Multi-agent Legal Simulation Driver (MASER)\nto scalably generate synthetic data by simulating interactive legal scenarios.\nLeveraging real-legal case sources, MASER ensures the consistency of legal\nattributes between participants and introduces a supervisory mechanism to align\nparticipants' characters and behaviors as well as addressing distractions. A\nMulti-stage Interactive Legal Evaluation (MILE) benchmark is further\nconstructed to evaluate LLMs' performance in dynamic legal scenarios. Extensive\nexperiments confirm the effectiveness of our framework.",
      "tldr_zh": "该论文提出 Multi-agent Legal Simulation Driver (MASER) 框架，通过多智能体模拟生成合成数据，以解决 Large Language Models (LLMs) 在互动法律场景中数据稀缺的问题。MASER 利用真实法律案例来源确保参与者之间法律属性的一致性，并引入监督机制来对齐参与者的角色、行为并处理干扰。研究还构建了 Multi-stage Interactive Legal Evaluation (MILE) 基准，用于评估 LLMs 在动态法律场景中的性能，并通过广泛实验证实了框架的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06882v1",
      "published_date": "2025-02-08 15:05:24 UTC",
      "updated_date": "2025-02-08 15:05:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:49:00.664997"
    },
    {
      "arxiv_id": "2502.05589v3",
      "title": "On Memory Construction and Retrieval for Personalized Conversational Agents",
      "title_zh": "关于个性化的对话代理的记忆构建和检索",
      "authors": [
        "Zhuoshi Pan",
        "Qianhui Wu",
        "Huiqiang Jiang",
        "Xufang Luo",
        "Hao Cheng",
        "Dongsheng Li",
        "Yuqing Yang",
        "Chin-Yew Lin",
        "H. Vicky Zhao",
        "Lili Qiu",
        "Jianfeng Gao"
      ],
      "abstract": "To deliver coherent and personalized experiences in long-term conversations,\nexisting approaches typically perform retrieval augmented response generation\nby constructing memory banks from conversation history at either the\nturn-level, session-level, or through summarization techniques.In this paper,\nwe present two key findings: (1) The granularity of memory unit matters:\nturn-level, session-level, and summarization-based methods each exhibit\nlimitations in both memory retrieval accuracy and the semantic quality of the\nretrieved content. (2) Prompt compression methods, such as LLMLingua-2, can\neffectively serve as a denoising mechanism, enhancing memory retrieval accuracy\nacross different granularities. Building on these insights, we propose SeCom, a\nmethod that constructs the memory bank at segment level by introducing a\nconversation segmentation model that partitions long-term conversations into\ntopically coherent segments, while applying compression based denoising on\nmemory units to enhance memory retrieval. Experimental results show that SeCom\nexhibits a significant performance advantage over baselines on long-term\nconversation benchmarks LOCOMO and Long-MT-Bench+. Additionally, the proposed\nconversation segmentation method demonstrates superior performance on dialogue\nsegmentation datasets such as DialSeg711, TIAGE, and SuperDialSeg.",
      "tldr_zh": "本研究探讨了个性化对话代理的记忆构建和检索问题，发现记忆单元的粒度（如 turn-level、session-level 或基于总结的方法）会影响检索准确性和语义质量，同时提示压缩技术如 LLMLingua-2 可作为去噪机制提升性能。针对这些问题，作者提出 SeCom 方法，通过对话分割模型将长对话分成主题连贯的 segment，并应用压缩-based denoising 来优化记忆库构建和检索。实验结果显示，SeCom 在 LOCOMO 和 Long-MT-Bench+ 等长对话基准上显著优于基线模型，并在 DialSeg711、TIAGE 和 SuperDialSeg 数据集上表现出色的对话分割性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2502.05589v3",
      "published_date": "2025-02-08 14:28:36 UTC",
      "updated_date": "2025-03-03 16:49:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:49:11.712637"
    },
    {
      "arxiv_id": "2502.05574v1",
      "title": "Event Stream-based Visual Object Tracking: HDETrack V2 and A High-Definition Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Shiao Wang",
        "Xiao Wang",
        "Chao Wang",
        "Liye Jin",
        "Lin Zhu",
        "Bo Jiang",
        "Yonghong Tian",
        "Jin Tang"
      ],
      "abstract": "We then introduce a novel hierarchical knowledge distillation strategy that\nincorporates the similarity matrix, feature representation, and response\nmap-based distillation to guide the learning of the student Transformer\nnetwork. We also enhance the model's ability to capture temporal dependencies\nby applying the temporal Fourier transform to establish temporal relationships\nbetween video frames. We adapt the network model to specific target objects\nduring testing via a newly proposed test-time tuning strategy to achieve high\nperformance and flexibility in target tracking. Recognizing the limitations of\nexisting event-based tracking datasets, which are predominantly low-resolution,\nwe propose EventVOT, the first large-scale high-resolution event-based tracking\ndataset. It comprises 1141 videos spanning diverse categories such as\npedestrians, vehicles, UAVs, ping pong, etc. Extensive experiments on both\nlow-resolution (FE240hz, VisEvent, FELT), and our newly proposed\nhigh-resolution EventVOT dataset fully validated the effectiveness of our\nproposed method. Both the benchmark dataset and source code have been released\non https://github.com/Event-AHU/EventVOT_Benchmark",
      "tldr_zh": "本文提出了 HDETrack V2，一种基于事件流的视觉对象跟踪方法，通过层次化知识蒸馏策略（包括相似性矩阵、特征表示和响应图-based 蒸馏）指导学生 Transformer 网络的学习，并利用时间 Fourier transform 捕捉视频帧之间的时间依赖，同时引入测试时调整策略以提升跟踪性能和灵活性。针对现有事件-based 跟踪数据集的低分辨率局限，该研究创建了 EventVOT，这是第一个大规模高分辨率数据集，包含1141个视频，覆盖行人、车辆、UAVs、乒乓球等多样类别。在低分辨率数据集（FE240hz、VisEvent、FELT）和新提出的 EventVOT 上进行的广泛实验证明了方法的有效性，基准数据集和源代码已发布于 GitHub。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Journal Extension of EventVOT, CVPR24",
      "pdf_url": "http://arxiv.org/pdf/2502.05574v1",
      "published_date": "2025-02-08 13:59:52 UTC",
      "updated_date": "2025-02-08 13:59:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:49:27.170217"
    },
    {
      "arxiv_id": "2502.05573v1",
      "title": "Low-Rank Agent-Specific Adaptation (LoRASA) for Multi-Agent Policy Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Beining Zhang",
        "Aditya Kapoor",
        "Mingfei Sun"
      ],
      "abstract": "Multi-agent reinforcement learning (MARL) often relies on \\emph{parameter\nsharing (PS)} to scale efficiently. However, purely shared policies can stifle\neach agent's unique specialization, reducing overall performance in\nheterogeneous environments. We propose \\textbf{Low-Rank Agent-Specific\nAdaptation (LoRASA)}, a novel approach that treats each agent's policy as a\nspecialized ``task'' fine-tuned from a shared backbone. Drawing inspiration\nfrom parameter-efficient transfer methods, LoRASA appends small, low-rank\nadaptation matrices to each layer of the shared policy, naturally inducing\n\\emph{parameter-space sparsity} that promotes both specialization and\nscalability. We evaluate LoRASA on challenging benchmarks including the\nStarCraft Multi-Agent Challenge (SMAC) and Multi-Agent MuJoCo (MAMuJoCo),\nimplementing it atop widely used algorithms such as MAPPO and A2PO. Across\ndiverse tasks, LoRASA matches or outperforms existing baselines \\emph{while\nreducing memory and computational overhead}. Ablation studies on adapter rank,\nplacement, and timing validate the method's flexibility and efficiency. Our\nresults suggest LoRASA's potential to establish a new norm for MARL policy\nparameterization: combining a shared foundation for coordination with low-rank\nagent-specific refinements for individual specialization.",
      "tldr_zh": "该论文针对多智能体强化学习 (MARL) 中参数共享 (PS) 导致的智能体专业化不足问题，提出了一种新方法 Low-Rank Agent-Specific Adaptation (LoRASA)。LoRASA 将每个智能体的策略视为从共享主干微调的专业化“任务”，通过在共享策略的每个层添加小型低秩适应矩阵，实现参数空间的稀疏性，从而提升专业化和可扩展性。在 StarCraft Multi-Agent Challenge (SMAC) 和 Multi-Agent MuJoCo (MAMuJoCo) 等基准上，LoRASA 与 MAPPO 和 A2PO 等算法结合，匹配或超过现有基线，同时显著减少内存和计算开销。消融研究验证了其灵活性和效率，表明 LoRASA 可能成为 MARL 策略参数化的新标准，结合共享基础与智能体特定细化。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "31 pages, 20 figures, 13 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.05573v1",
      "published_date": "2025-02-08 13:57:53 UTC",
      "updated_date": "2025-02-08 13:57:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:49:40.272905"
    },
    {
      "arxiv_id": "2502.05568v1",
      "title": "Large Multimodal Models for Low-Resource Languages: A Survey",
      "title_zh": "大型多模态模型用于低资源语言：一个综述",
      "authors": [
        "Marian Lupascu",
        "Ana-Cristina Rogoz",
        "Mihai Sorin Stupariu",
        "Radu Tudor Ionescu"
      ],
      "abstract": "In this survey, we systematically analyze techniques used to adapt large\nmultimodal models (LMMs) for low-resource (LR) languages, examining approaches\nranging from visual enhancement and data creation to cross-modal transfer and\nfusion strategies. Through a comprehensive analysis of 106 studies across 75 LR\nlanguages, we identify key patterns in how researchers tackle the challenges of\nlimited data and computational resources. We find that visual information often\nserves as a crucial bridge for improving model performance in LR settings,\nthough significant challenges remain in areas such as hallucination mitigation\nand computational efficiency. We aim to provide researchers with a clear\nunderstanding of current approaches and remaining challenges in making LMMs\nmore accessible to speakers of LR (understudied) languages. We complement our\nsurvey with an open-source repository available at:\nhttps://github.com/marianlupascu/LMM4LRL-Survey.",
      "tldr_zh": "本调查系统分析了适应大型多模态模型(LMMs)用于低资源(LR)语言的技术，包括视觉增强、数据创建、跨模态转移和融合策略，共审查了106篇研究涉及75种LR语言。研究发现，视觉信息作为关键桥梁能显著提升模型在数据和计算资源有限环境下的性能，但仍存在幻觉缓解和计算效率方面的挑战。该调查为研究者提供了当前方法的清晰概述和剩余难题，并附带开源仓库（https://github.com/marianlupascu/LMM4LRL-Survey），以促进LMMs在LR语言中的应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05568v1",
      "published_date": "2025-02-08 13:29:44 UTC",
      "updated_date": "2025-02-08 13:29:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:49:53.417938"
    },
    {
      "arxiv_id": "2502.05567v2",
      "title": "ATLAS: Autoformalizing Theorems through Lifting, Augmentation, and Synthesis of Data",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyang Liu",
        "Kangjie Bao",
        "Jiashuo Zhang",
        "Yunqi Liu",
        "Yuntian Liu",
        "Yu Chen",
        "Yang Jiao",
        "Tao Luo"
      ],
      "abstract": "Autoformalization, the automatic translation of mathematical content from\nnatural language into machine-verifiable formal languages, has seen significant\nprogress driven by advances in large language models (LLMs). Nonetheless, a\nprimary barrier to further improvements is the limited availability of parallel\ncorpora that map informal mathematical text to its formal counterpart. To\naddress this limitation, we propose ATLAS (Autoformalizing Theorems through\nLifting, Augmentation, and Synthesis of Data), a novel data generation\nframework designed to produce large-scale, high-quality parallel corpora of\ntheorem statements. Distinct from prior approaches, ATLAS begins with a concept\nrepository, accelerates the improvement of student model through expert\niteration combined with knowledge distillation, and introduces two novel\naugmentation strategies that exploit the structural characteristics of formal\nlanguages. With the proposed ATLAS running for 10 iterations, we construct an\nundergraduate-level dataset comprising 117k theorem statements and develop\nATLAS Translator, which demonstrates statistically significant improvements\nover both the HERALD Translator and the Kimina-Autoformalizer across all\nbenchmarks ($p<0.05$, two-sided t-test), achieving a new state of the art. The\ndatasets, model, and code will be released to the public soon.",
      "tldr_zh": "该研究提出ATLAS框架，用于自动形式化(Autoformalization)数学定理，将自然语言文本转化为机器可验证的形式语言，以解决平行语料库缺乏的问题。ATLAS从概念仓库出发，通过专家迭代结合knowledge distillation加速学生模型改进，并引入两种新颖的增强策略（Lifting, Augmentation, and Synthesis of Data），利用形式语言的结构特性生成高质量数据。运行10次迭代后，该框架构建了包含11.7k本科级定理语句的数据集，并开发了ATLAS Translator，在所有基准测试中显著优于HERALD Translator和Kimina-Autoformalizer（p<0.05，双侧t检验），实现了新状态。数据集、模型和代码即将公开发布。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05567v2",
      "published_date": "2025-02-08 13:28:51 UTC",
      "updated_date": "2025-05-19 04:17:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:50:06.981886"
    },
    {
      "arxiv_id": "2502.05564v1",
      "title": "TabICL: A Tabular Foundation Model for In-Context Learning on Large Data",
      "title_zh": "翻译失败",
      "authors": [
        "Jingang Qu",
        "David Holzmüller",
        "Gaël Varoquaux",
        "Marine Le Morvan"
      ],
      "abstract": "The long-standing dominance of gradient-boosted decision trees on tabular\ndata is currently challenged by tabular foundation models using In-Context\nLearning (ICL): setting the training data as context for the test data and\npredicting in a single forward pass without parameter updates. While the very\nrecent TabPFNv2 foundation model (2025) excels on tables with up to 10K\nsamples, its alternating column- and row-wise attentions make handling large\ntraining sets computationally prohibitive. So, can ICL be effectively scaled\nand deliver a benefit for larger tables? We introduce TabICL, a tabular\nfoundation model for classification, pretrained on synthetic datasets with up\nto 60K samples and capable of handling 500K samples on affordable resources.\nThis is enabled by a novel two-stage architecture: a column-then-row attention\nmechanism to build fixed-dimensional embeddings of rows, followed by a\ntransformer for efficient ICL. Across 200 classification datasets from the\nTALENT benchmark, TabICL is on par with TabPFNv2 while being systematically\nfaster (up to 10 times), and significantly outperforms all other approaches. On\n56 datasets with over 10K samples, TabICL surpasses both TabPFNv2 and CatBoost,\ndemonstrating the potential of ICL for large data.",
      "tldr_zh": "该研究引入了 TabICL，一种针对大型表格数据的基金会模型，支持 In-Context Learning (ICL)，旨在挑战梯度提升决策树在表格数据上的主导地位。TabICL 采用新型的两阶段架构，包括 column-then-row attention 机制来构建固定维度的行嵌入，以及 transformer 用于高效的 ICL，从而在资源有限的情况下处理高达 500K 样本的数据。在 TALENT benchmark 的 200 个分类数据集上，TabICL 与 TabPFNv2 性能相当但速度快 10 倍，并在 56 个超过 10K 样本的数据集上超越 TabPFNv2 和 CatBoost，证明了 ICL 在大规模数据上的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05564v1",
      "published_date": "2025-02-08 13:25:04 UTC",
      "updated_date": "2025-02-08 13:25:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:50:18.741406"
    },
    {
      "arxiv_id": "2502.05556v1",
      "title": "Knowledge is Power: Harnessing Large Language Models for Enhanced Cognitive Diagnosis",
      "title_zh": "知识就是力量：利用大型语言模型增强认知诊断",
      "authors": [
        "Zhiang Dong",
        "Jingyuan Chen",
        "Fei Wu"
      ],
      "abstract": "Cognitive Diagnosis Models (CDMs) are designed to assess students' cognitive\nstates by analyzing their performance across a series of exercises. However,\nexisting CDMs often struggle with diagnosing infrequent students and exercises\ndue to a lack of rich prior knowledge. With the advancement in large language\nmodels (LLMs), which possess extensive domain knowledge, their integration into\ncognitive diagnosis presents a promising opportunity. Despite this potential,\nintegrating LLMs with CDMs poses significant challenges. LLMs are not\nwell-suited for capturing the fine-grained collaborative interactions between\nstudents and exercises, and the disparity between the semantic space of LLMs\nand the behavioral space of CDMs hinders effective integration. To address\nthese issues, we propose a novel Knowledge-enhanced Cognitive Diagnosis (KCD)\nframework, which is a model-agnostic framework utilizing LLMs to enhance CDMs\nand compatible with various CDM architectures. The KCD framework operates in\ntwo stages: LLM Diagnosis and Cognitive Level Alignment. In the LLM Diagnosis\nstage, both students and exercises are diagnosed to achieve comprehensive and\ndetailed modeling. In the Cognitive Level Alignment stage, we bridge the gap\nbetween the CDMs' behavioral space and the LLMs' semantic space using\ncontrastive learning and mask-reconstruction approaches. Experiments on several\nreal-world datasets demonstrate the effectiveness of our proposed framework.",
      "tldr_zh": "本研究针对认知诊断模型 (CDMs) 在处理稀有学生和练习时的局限性，提出了一种新型的 Knowledge-enhanced Cognitive Diagnosis (KCD) 框架，利用大语言模型 (LLMs) 的丰富领域知识来增强 CDMs 的性能。KCD 框架是模型无关的，能够兼容各种 CDM 架构，通过两个阶段运作：首先在 LLM Diagnosis 阶段，对学生和练习进行全面诊断以实现细粒度建模；其次在 Cognitive Level Alignment 阶段，使用对比学习和掩码重建方法桥接 CDMs 的行为空间与 LLMs 的语义空间。实验结果显示，该框架在多个真实数据集上显著提升了诊断准确性，为改进教育评估提供了有效解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05556v1",
      "published_date": "2025-02-08 13:02:45 UTC",
      "updated_date": "2025-02-08 13:02:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:50:30.304873"
    },
    {
      "arxiv_id": "2502.10431v1",
      "title": "Leveraging Constraint Violation Signals For Action-Constrained Reinforcement Learning",
      "title_zh": "利用约束违反信号进行动作约束强化学习",
      "authors": [
        "Janaka Chathuranga Brahmanage",
        "Jiajing Ling",
        "Akshat Kumar"
      ],
      "abstract": "In many RL applications, ensuring an agent's actions adhere to constraints is\ncrucial for safety. Most previous methods in Action-Constrained Reinforcement\nLearning (ACRL) employ a projection layer after the policy network to correct\nthe action. However projection-based methods suffer from issues like the zero\ngradient problem and higher runtime due to the usage of optimization solvers.\nRecently methods were proposed to train generative models to learn a\ndifferentiable mapping between latent variables and feasible actions to address\nthis issue. However, generative models require training using samples from the\nconstrained action space, which itself is challenging. To address such\nlimitations, first, we define a target distribution for feasible actions based\non constraint violation signals, and train normalizing flows by minimizing the\nKL divergence between an approximated distribution over feasible actions and\nthe target. This eliminates the need to generate feasible action samples,\ngreatly simplifying the flow model learning. Second, we integrate the learned\nflow model with existing deep RL methods, which restrict it to exploring only\nthe feasible action space. Third, we extend our approach beyond ACRL to handle\nstate-wise constraints by learning the constraint violation signal from the\nenvironment. Empirically, our approach has significantly fewer constraint\nviolations while achieving similar or better quality in several control tasks\nthan previous best methods.",
      "tldr_zh": "本论文针对 Action-Constrained Reinforcement Learning (ACRL) 中的安全约束问题，提出一种利用约束违反信号的新方法，以避免传统投影或生成模型的局限，如零梯度问题和采样困难。具体而言，该方法定义基于约束违反信号的目标分布，并通过最小化 KL divergence 训练 normalizing flows 模型，从而简化可行动作空间的学习过程。论文进一步将该模型集成到现有深度 RL 方法中，仅探索可行动作空间，并扩展到处理状态相关的约束。实验结果显示，该方法在多个控制任务中显著减少约束违反，同时达到与最佳方法相当或更高的性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages and 5 pages supplementary",
      "pdf_url": "http://arxiv.org/pdf/2502.10431v1",
      "published_date": "2025-02-08 12:58:26 UTC",
      "updated_date": "2025-02-08 12:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:50:42.825721"
    },
    {
      "arxiv_id": "2502.05547v1",
      "title": "Dual Defense: Enhancing Privacy and Mitigating Poisoning Attacks in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Runhua Xu",
        "Shiqi Gao",
        "Chao Li",
        "James Joshi",
        "Jianxin Li"
      ],
      "abstract": "Federated learning (FL) is inherently susceptible to privacy breaches and\npoisoning attacks. To tackle these challenges, researchers have separately\ndevised secure aggregation mechanisms to protect data privacy and robust\naggregation methods that withstand poisoning attacks. However, simultaneously\naddressing both concerns is challenging; secure aggregation facilitates\npoisoning attacks as most anomaly detection techniques require access to\nunencrypted local model updates, which are obscured by secure aggregation. Few\nrecent efforts to simultaneously tackle both challenges offen depend on\nimpractical assumption of non-colluding two-server setups that disrupt FL's\ntopology, or three-party computation which introduces scalability issues,\ncomplicating deployment and application. To overcome this dilemma, this paper\nintroduce a Dual Defense Federated learning (DDFed) framework. DDFed\nsimultaneously boosts privacy protection and mitigates poisoning attacks,\nwithout introducing new participant roles or disrupting the existing FL\ntopology. DDFed initially leverages cutting-edge fully homomorphic encryption\n(FHE) to securely aggregate model updates, without the impractical requirement\nfor non-colluding two-server setups and ensures strong privacy protection.\nAdditionally, we proposes a unique two-phase anomaly detection mechanism for\nencrypted model updates, featuring secure similarity computation and\nfeedback-driven collaborative selection, with additional measures to prevent\npotential privacy breaches from Byzantine clients incorporated into the\ndetection process. We conducted extensive experiments on various model\npoisoning attacks and FL scenarios, including both cross-device and cross-silo\nFL. Experiments on publicly available datasets demonstrate that DDFed\nsuccessfully protects model privacy and effectively defends against model\npoisoning threats.",
      "tldr_zh": "这篇论文针对Federated Learning (FL)中隐私泄露和poisoning attacks的挑战，提出了一种Dual Defense Federated learning (DDFed)框架，能够同时提升隐私保护和缓解攻击威胁，而不改变FL拓扑。DDFed框架利用fully homomorphic encryption (FHE)来安全聚合模型更新，并引入一个两阶段异常检测机制，包括安全相似性计算和反馈驱动的协作选择，以处理加密的模型更新。实验在各种模型poisoning attacks和FL场景（如跨设备和跨库）中证明，DDFed成功保护了模型隐私并有效防御了攻击。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "accepted by The Thirty-eighth Annual Conference on Neural Information\n  Processing Systems (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2502.05547v1",
      "published_date": "2025-02-08 12:28:20 UTC",
      "updated_date": "2025-02-08 12:28:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:50:52.866764"
    },
    {
      "arxiv_id": "2502.05537v1",
      "title": "Sequential Stochastic Combinatorial Optimization Using Hierarchal Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xinsong Feng",
        "Zihan Yu",
        "Yanhai Xiong",
        "Haipeng Chen"
      ],
      "abstract": "Reinforcement learning (RL) has emerged as a promising tool for combinatorial\noptimization (CO) problems due to its ability to learn fast, effective, and\ngeneralizable solutions. Nonetheless, existing works mostly focus on one-shot\ndeterministic CO, while sequential stochastic CO (SSCO) has rarely been studied\ndespite its broad applications such as adaptive influence maximization (IM) and\ninfectious disease intervention. In this paper, we study the SSCO problem where\nwe first decide the budget (e.g., number of seed nodes in adaptive IM)\nallocation for all time steps, and then select a set of nodes for each time\nstep. The few existing studies on SSCO simplify the problems by assuming a\nuniformly distributed budget allocation over the time horizon, yielding\nsuboptimal solutions. We propose a generic hierarchical RL (HRL) framework\ncalled wake-sleep option (WS-option), a two-layer option-based framework that\nsimultaneously decides adaptive budget allocation on the higher layer and node\nselection on the lower layer. WS-option starts with a coherent formulation of\nthe two-layer Markov decision processes (MDPs), capturing the interdependencies\nbetween the two layers of decisions. Building on this, WS-option employs\nseveral innovative designs to balance the model's training stability and\ncomputational efficiency, preventing the vicious cyclic interference issue\nbetween the two layers. Empirical results show that WS-option exhibits\nsignificantly improved effectiveness and generalizability compared to\ntraditional methods. Moreover, the learned model can be generalized to larger\ngraphs, which significantly reduces the overhead of computational resources.",
      "tldr_zh": "本文研究顺序随机组合优化 (SSCO) 问题，例如自适应影响最大化 (IM) 和传染病干预，利用分层强化学习 (HRL) 框架解决传统方法中预算分配的次优问题。作者提出 wake-sleep option (WS-option)，一个两层基于选项的框架，高层负责自适应预算分配，低层处理节点选择，并通过两层 Markov Decision Processes (MDPs) 的连贯公式化捕捉决策间的相互依赖，同时采用创新设计平衡训练稳定性和计算效率。实验结果显示，WS-option 显著提升了解决方案的有效性和泛化性，并在更大图上减少了计算资源开销。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05537v1",
      "published_date": "2025-02-08 12:00:30 UTC",
      "updated_date": "2025-02-08 12:00:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:51:08.247979"
    },
    {
      "arxiv_id": "2502.06876v3",
      "title": "Mix Data or Merge Models? Balancing the Helpfulness, Honesty, and Harmlessness of Large Language Model via Model Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Jinluan Yang",
        "Dingnan Jin",
        "Anke Tang",
        "Li Shen",
        "Didi Zhu",
        "Zhengyu Chen",
        "Ziyu Zhao",
        "Daixin Wang",
        "Qing Cui",
        "Zhiqiang Zhang",
        "Jun Zhou",
        "Fei Wu",
        "Kun Kuang"
      ],
      "abstract": "Achieving balanced alignment of large language models (LLMs) in terms of\nHelpfulness, Honesty, and Harmlessness (3H optimization) constitutes a\ncornerstone of responsible AI. Existing methods like data mixture strategies\nface limitations, including heavy reliance on expert knowledge and conflicting\noptimization signals. While model merging offers parameter-level\nconflict-resolution strategies through integrating specialized models'\nparameters, its potential for 3H optimization remains underexplored. This paper\nsystematically compares the effectiveness of model merging and data mixture\nmethods in constructing 3H-aligned LLMs for the first time, revealing\npreviously overlooked collaborative and conflict relationships among the 3H\ndimensions and discussing the advantages and drawbacks of data mixture\n(\\textit{data-level}) and model merging (\\textit{parameter-level}) methods in\nmitigating the conflict for balanced 3H optimization. Specially, we propose a\nnovel \\textbf{R}eweighting \\textbf{E}nhanced task \\textbf{S}ingular\n\\textbf{M}erging method, \\textbf{RESM}, through outlier weighting and\nsparsity-aware rank selection strategies to address the challenges of\npreference noise accumulation and layer sparsity adaptation inherent in\n3H-aligned LLM merging. Extensive evaluations can verify the effectiveness and\nrobustness of RESM compared to previous data mixture (2\\%-5\\% gain) and model\nmerging (1\\%-3\\% gain) methods in achieving balanced LLM alignment. We release\nour models through \\href{https://huggingface.co/Jinluan}{3H\\_Merging} for\nfurther investigations.",
      "tldr_zh": "这篇论文探讨了如何通过模型合并方法平衡大型语言模型(LLMs)的Helpfulness、Honesty和Harmlessness（简称3H优化），以实现负责任的AI发展，并首次系统比较了模型合并（parameter-level）和数据混合（data-level）方法的优缺点。作者揭示了3H维度之间的协作与冲突关系，并提出了一种新方法RESM（Reweighting Enhanced task Singular Merging），通过异常值加权和稀疏性感知秩选择策略，解决了偏好噪声积累和层稀疏性适应等问题。实验结果显示，RESM在平衡3H优化方面比现有数据混合方法提高了2%-5%、比模型合并方法提高了1%-3%的性能，并开源了模型以供进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06876v3",
      "published_date": "2025-02-08 11:56:58 UTC",
      "updated_date": "2025-05-16 05:35:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:51:19.069484"
    },
    {
      "arxiv_id": "2502.05526v1",
      "title": "Towards Learning Scalable Agile Dynamic Motion Planning for Robosoccer Teams with Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Brandon Ho",
        "Batuhan Altundas",
        "Matthew Gombolay"
      ],
      "abstract": "In fast-paced, ever-changing environments, dynamic Motion Planning for\nMulti-Agent Systems in the presence of obstacles is a universal and unsolved\nproblem. Be it from path planning around obstacles to the movement of robotic\narms, or in planning navigation of robot teams in settings such as Robosoccer,\ndynamic motion planning is needed to avoid collisions while reaching the\ntargeted destination when multiple agents occupy the same area. In continuous\ndomains where the world changes quickly, existing classical Motion Planning\nalgorithms such as RRT* and A* become computationally expensive to rerun at\nevery time step. Many variations of classical and well-formulated non-learning\npath-planning methods have been proposed to solve this universal problem but\nfall short due to their limitations of speed, smoothness, optimally, etc. Deep\nLearning models overcome their challenges due to their ability to adapt to\nvarying environments based on past experience. However, current learning motion\nplanning models use discretized environments, do not account for heterogeneous\nagents or replanning, and build up to improve the classical motion planners'\nefficiency, leading to issues with scalability. To prevent collisions between\nheterogenous team members and collision to obstacles while trying to reach the\ntarget location, we present a learning-based dynamic navigation model and show\nour model working on a simple environment in the concept of a simple Robosoccer\nGame.",
      "tldr_zh": "这篇论文针对多智能体系统在动态环境中进行运动规划的问题，提出了一种基于Policy Optimization的学习方法，以实现可扩展和敏捷的动态路径规划，解决传统算法如RRT*和A*在连续域中计算开销大的局限性。该模型支持异构代理的实时导航和碰撞避免，避免了现有学习方法的离散环境限制和可扩展性问题。在一个简单的Robosoccer游戏环境中，实验验证了该方法的有效性，提高了团队运动的效率和安全性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05526v1",
      "published_date": "2025-02-08 11:13:07 UTC",
      "updated_date": "2025-02-08 11:13:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:51:29.957706"
    },
    {
      "arxiv_id": "2502.05512v1",
      "title": "IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System",
      "title_zh": "IndexTTS：工业级可控且高效的零样本文本到语音系统",
      "authors": [
        "Wei Deng",
        "Siyi Zhou",
        "Jingchen Shu",
        "Jinchao Wang",
        "Lu Wang"
      ],
      "abstract": "Recently, large language model (LLM) based text-to-speech (TTS) systems have\ngradually become the mainstream in the industry due to their high naturalness\nand powerful zero-shot voice cloning capabilities.Here, we introduce the\nIndexTTS system, which is mainly based on the XTTS and Tortoise model. We add\nsome novel improvements. Specifically, in Chinese scenarios, we adopt a hybrid\nmodeling method that combines characters and pinyin, making the pronunciations\nof polyphonic characters and long-tail characters controllable. We also\nperformed a comparative analysis of the Vector Quantization (VQ) with\nFinite-Scalar Quantization (FSQ) for codebook utilization of acoustic speech\ntokens. To further enhance the effect and stability of voice cloning, we\nintroduce a conformer-based speech conditional encoder and replace the\nspeechcode decoder with BigVGAN2. Compared with XTTS, it has achieved\nsignificant improvements in naturalness, content consistency, and zero-shot\nvoice cloning. As for the popular TTS systems in the open-source, such as\nFish-Speech, CosyVoice2, FireRedTTS and F5-TTS, IndexTTS has a relatively\nsimple training process, more controllable usage, and faster inference speed.\nMoreover, its performance surpasses that of these systems. Our demos are\navailable at https://index-tts.github.io.",
      "tldr_zh": "该论文介绍了 IndexTTS，一种工业级别的可控且高效的零样本 Text-to-Speech (TTS) 系统，基于 XTTS 和 Tortoise 模型，针对中文场景采用字符和拼音的混合建模方法，以实现多音字和长尾字的发音可控，并比较了 Vector Quantization (VQ) 与 Finite-Scalar Quantization (FSQ) 的语音标记利用。系统进一步引入基于 Conformer 的语音条件编码器和 BigVGAN2 解码器，提升了自然性、内容一致性和零样本语音克隆效果。相比 XTTS 和其他开源系统（如 Fish-Speech 和 CosyVoice2），IndexTTS 拥有更简单的训练过程、更快的推理速度和整体性能优势。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05512v1",
      "published_date": "2025-02-08 10:23:20 UTC",
      "updated_date": "2025-02-08 10:23:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:51:43.351831"
    },
    {
      "arxiv_id": "2502.08657v1",
      "title": "Refining Positive and Toxic Samples for Dual Safety Self-Alignment of LLMs with Minimal Human Interventions",
      "title_zh": "翻译失败",
      "authors": [
        "Jingxin Xu",
        "Guoshun Nan",
        "Sheng Guan",
        "Sicong Leng",
        "Yilian Liu",
        "Zixiao Wang",
        "Yuyang Ma",
        "Zhili Zhou",
        "Yanzhao Hou",
        "Xiaofeng Tao"
      ],
      "abstract": "Recent AI agents, such as ChatGPT and LLaMA, primarily rely on instruction\ntuning and reinforcement learning to calibrate the output of large language\nmodels (LLMs) with human intentions, ensuring the outputs are harmless and\nhelpful. Existing methods heavily depend on the manual annotation of\nhigh-quality positive samples, while contending with issues such as noisy\nlabels and minimal distinctions between preferred and dispreferred response\ndata. However, readily available toxic samples with clear safety distinctions\nare often filtered out, removing valuable negative references that could aid\nLLMs in safety alignment. In response, we propose PT-ALIGN, a novel safety\nself-alignment approach that minimizes human supervision by automatically\nrefining positive and toxic samples and performing fine-grained dual\ninstruction tuning. Positive samples are harmless responses, while toxic\nsamples deliberately contain extremely harmful content, serving as a new\nsupervisory signals. Specifically, we utilize LLM itself to iteratively\ngenerate and refine training instances by only exploring fewer than 50 human\nannotations. We then employ two losses, i.e., maximum likelihood estimation\n(MLE) and fine-grained unlikelihood training (UT), to jointly learn to enhance\nthe LLM's safety. The MLE loss encourages an LLM to maximize the generation of\nharmless content based on positive samples. Conversely, the fine-grained UT\nloss guides the LLM to minimize the output of harmful words based on negative\nsamples at the token-level, thereby guiding the model to decouple safety from\neffectiveness, directing it toward safer fine-tuning objectives, and increasing\nthe likelihood of generating helpful and reliable content. Experiments on 9\npopular open-source LLMs demonstrate the effectiveness of our PT-ALIGN for\nsafety alignment, while maintaining comparable levels of helpfulness and\nusefulness.",
      "tldr_zh": "该论文提出PT-ALIGN，一种最小化人类干预的安全自对齐方法，用于提升LLMs的安全性，通过自动精炼正样本（无害响应）和毒性样本（极端有害内容）作为新监督信号，仅需少于50个人类标注。方法结合最大似然估计（MLE）损失鼓励生成无害内容，以及细粒度不似然训练（UT）损失在token级别最小化有害输出，从而实现安全与有效性的解耦。实验在9个开源LLMs上验证，PT-ALIGN显著提高了安全对齐性能，同时保持了模型的帮助性和有用性水平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2502.08657v1",
      "published_date": "2025-02-08 09:54:47 UTC",
      "updated_date": "2025-02-08 09:54:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:51:58.670285"
    },
    {
      "arxiv_id": "2502.06875v1",
      "title": "Beyond Vision: How Large Language Models Interpret Facial Expressions from Valence-Arousal Values",
      "title_zh": "翻译失败",
      "authors": [
        "Vaibhav Mehra",
        "Guy Laban",
        "Hatice Gunes"
      ],
      "abstract": "Large Language Models primarily operate through text-based inputs and\noutputs, yet human emotion is communicated through both verbal and non-verbal\ncues, including facial expressions. While Vision-Language Models analyze facial\nexpressions from images, they are resource-intensive and may depend more on\nlinguistic priors than visual understanding. To address this, this study\ninvestigates whether LLMs can infer affective meaning from dimensions of facial\nexpressions-Valence and Arousal values, structured numerical representations,\nrather than using raw visual input. VA values were extracted using Facechannel\nfrom images of facial expressions and provided to LLMs in two tasks: (1)\ncategorizing facial expressions into basic (on the IIMI dataset) and complex\nemotions (on the Emotic dataset) and (2) generating semantic descriptions of\nfacial expressions (on the Emotic dataset). Results from the categorization\ntask indicate that LLMs struggle to classify VA values into discrete emotion\ncategories, particularly for emotions beyond basic polarities (e.g., happiness,\nsadness). However, in the semantic description task, LLMs produced textual\ndescriptions that align closely with human-generated interpretations,\ndemonstrating a stronger capacity for free text affective inference of facial\nexpressions.",
      "tldr_zh": "本文研究探讨大型语言模型(LLMs)是否能从Valence-Arousal values(VA values)——结构化的数值表示——推断面部表情，而非依赖视觉输入，以避免资源密集型Vision-Language Models。研究使用Facechannel从面部表情图像提取VA值，并在IIMI数据集（基本情绪）和Emotic数据集（复杂情绪）上进行表情分类任务，以及在Emotic数据集上进行语义描述任务。结果表明，LLMs在分类任务中尤其对超出基本情绪（如快乐、悲伤）的复杂情绪表现不佳，但能在语义描述任务中生成与人类解释高度一致的文本，展示出较强的自由文本情感推断能力。该研究为LLMs在非视觉情感分析中的应用提供了新视角和潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06875v1",
      "published_date": "2025-02-08 09:54:03 UTC",
      "updated_date": "2025-02-08 09:54:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:52:10.606619"
    },
    {
      "arxiv_id": "2502.05503v3",
      "title": "A Physical Coherence Benchmark for Evaluating Video Generation Models via Optical Flow-guided Frame Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yongfan Chen",
        "Xiuwen Zhu",
        "Tianyu Li"
      ],
      "abstract": "Recent advances in video generation models demonstrate their potential as\nworld simulators, but they often struggle with videos deviating from physical\nlaws, a key concern overlooked by most text-to-video benchmarks. We introduce a\nbenchmark designed specifically to assess the Physical Coherence of generated\nvideos, PhyCoBench. Our benchmark includes 120 prompts covering 7 categories of\nphysical principles, capturing key physical laws observable in video content.\nWe evaluated four state-of-the-art (SoTA) T2V models on PhyCoBench and\nconducted manual assessments. Additionally, we propose an automated evaluation\nmodel: PhyCoPredictor, a diffusion model that generates optical flow and video\nframes in a cascade manner. Through a consistency evaluation comparing\nautomated and manual sorting, the experimental results show that PhyCoPredictor\ncurrently aligns most closely with human evaluation. Therefore, it can\neffectively evaluate the physical coherence of videos, providing insights for\nfuture model optimization. Our benchmark, including physical coherence prompts,\nthe automatic evaluation tool PhyCoPredictor, and the generated video dataset,\nhas been released on GitHub at https://github.com/Jeckinchen/PhyCoBench.",
      "tldr_zh": "该论文引入了PhyCoBench基准，用于评估视频生成模型的Physical Coherence（物理一致性），该基准包含120个提示，覆盖7类物理原则，以解决现有T2V模型在遵守物理定律方面的不足。作者评估了四种最先进T2V模型，并提出PhyCoPredictor，一种基于扩散模型的自动评估工具，通过Optical Flow-guided Frame Prediction（光流引导帧预测）生成光流和视频帧。实验结果表明，PhyCoPredictor与人类评估高度一致，可有效评估视频的物理一致性，并为模型优化提供洞见；相关资源已发布在GitHub上。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05503v3",
      "published_date": "2025-02-08 09:31:26 UTC",
      "updated_date": "2025-03-05 12:27:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:52:20.268962"
    },
    {
      "arxiv_id": "2502.05500v1",
      "title": "Vision-Ultrasound Robotic System based on Deep Learning for Gas and Arc Hazard Detection in Manufacturing",
      "title_zh": "基于深度学习的视觉-超声波机器人系统，用于制造中的气体和电弧危害检测",
      "authors": [
        "Jin-Hee Lee",
        "Dahyun Nam",
        "Robin Inho Kee",
        "YoungKey Kim",
        "Seok-Jun Buu"
      ],
      "abstract": "Gas leaks and arc discharges present significant risks in industrial\nenvironments, requiring robust detection systems to ensure safety and\noperational efficiency. Inspired by human protocols that combine visual\nidentification with acoustic verification, this study proposes a deep\nlearning-based robotic system for autonomously detecting and classifying gas\nleaks and arc discharges in manufacturing settings. The system is designed to\nexecute all experimental tasks entirely onboard the robot. Utilizing a\n112-channel acoustic camera operating at a 96 kHz sampling rate to capture\nultrasonic frequencies, the system processes real-world datasets recorded in\ndiverse industrial scenarios. These datasets include multiple gas leak\nconfigurations (e.g., pinhole, open end) and partial discharge types (Corona,\nSurface, Floating) under varying environmental noise conditions. Proposed\nsystem integrates visual detection and a beamforming-enhanced acoustic analysis\npipeline. Signals are transformed using STFT and refined through Gamma\nCorrection, enabling robust feature extraction. An Inception-inspired CNN\nfurther classifies hazards, achieving 99% gas leak detection accuracy. The\nsystem not only detects individual hazard sources but also enhances\nclassification reliability by fusing multi-modal data from both vision and\nacoustic sensors. When tested in reverberation and noise-augmented\nenvironments, the system outperformed conventional models by up to 44%p, with\nexperimental tasks meticulously designed to ensure fairness and\nreproducibility. Additionally, the system is optimized for real-time\ndeployment, maintaining an inference time of 2.1 seconds on a mobile robotic\nplatform. By emulating human-like inspection protocols and integrating vision\nwith acoustic modalities, this study presents an effective solution for\nindustrial automation, significantly improving safety and operational\nreliability.",
      "tldr_zh": "本研究提出了一种基于深度学习的视觉-超声波机器人系统，用于检测和分类制造业中的气体泄漏和电弧放电风险。该系统模仿人类协议，整合视觉检测与增强的声学分析管道，包括STFT信号变换、Gamma Correction精炼和Inception-inspired CNN分类模型，利用112通道声学相机捕获超声波数据，实现99%的气体泄漏检测准确率。实验结果显示，通过多模态数据融合，该系统在噪声和回声环境中比传统模型提升高达44%，并支持实时部署（推理时间2.1秒），显著提高了工业安全性和操作可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2.1; I.2.9"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to Engineering Applications of Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2502.05500v1",
      "published_date": "2025-02-08 09:17:19 UTC",
      "updated_date": "2025-02-08 09:17:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:52:33.122934"
    },
    {
      "arxiv_id": "2502.05498v1",
      "title": "Riemannian Manifold Learning for Stackelberg Games with Neural Flow Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Larkin Liu",
        "Kashif Rasul",
        "Yutong Chao",
        "Jalal Etesami"
      ],
      "abstract": "We present a novel framework for online learning in Stackelberg general-sum\ngames, where two agents, the leader and follower, engage in sequential\nturn-based interactions. At the core of this approach is a learned\ndiffeomorphism that maps the joint action space to a smooth Riemannian\nmanifold, referred to as the Stackelberg manifold. This mapping, facilitated by\nneural normalizing flows, ensures the formation of tractable isoplanar\nsubspaces, enabling efficient techniques for online learning. By assuming\nlinearity between the agents' reward functions on the Stackelberg manifold, our\nconstruct allows the application of standard bandit algorithms. We then provide\na rigorous theoretical basis for regret minimization on convex manifolds and\nestablish finite-time bounds on simple regret for learning Stackelberg\nequilibria. This integration of manifold learning into game theory uncovers a\npreviously unrecognized potential for neural normalizing flows as an effective\ntool for multi-agent learning. We present empirical results demonstrating the\neffectiveness of our approach compared to standard baselines, with applications\nspanning domains such as cybersecurity and economic supply chain optimization.",
      "tldr_zh": "本研究提出了一种新框架，用于Stackelberg博弈中的在线学习，该框架通过神经归一化流(neural normalizing flows)学习一个微分同胚(diffeomorphism)，将联合动作空间映射到平滑的Riemannian流形（即Stackelberg流形），以形成可处理的等高平面子空间。假设代理的奖励函数在该流形上是线性的，该方法允许应用标准的bandit算法，实现高效的在线学习。研究提供了遗憾最小化(regret minimization)的理论基础，并在凸流形上建立了学习Stackelberg均衡的有限时间简单遗憾界。实验结果显示，该框架在网络安全(cybersecurity)和经济供应链优化(economic supply chain optimization)等领域的表现优于标准基线，展示了神经归一化流在多代理学习中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "cs.MA",
        "91A10",
        "I.2.6; I.2.11"
      ],
      "primary_category": "cs.LG",
      "comment": "Stackelberg games. Manifold learning. Online learning",
      "pdf_url": "http://arxiv.org/pdf/2502.05498v1",
      "published_date": "2025-02-08 09:10:44 UTC",
      "updated_date": "2025-02-08 09:10:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:52:45.714885"
    },
    {
      "arxiv_id": "2502.06874v2",
      "title": "Group Reasoning Emission Estimation Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yanming Guo",
        "Xiao Qian",
        "Kevin Credit",
        "Jin Ma"
      ],
      "abstract": "Accurate greenhouse gas (GHG) emission reporting is critical for governments,\nbusinesses, and investors. However, adoption remains limited particularly among\nsmall and medium enterprises due to high implementation costs, fragmented\nemission factor databases, and a lack of robust sector classification methods.\nTo address these challenges, we introduce Group Reasoning Emission Estimation\nNetworks (GREEN), an AI-driven carbon accounting framework that standardizes\nenterprise-level emission estimation, constructs a large-scale benchmark\ndataset, and leverages a novel reasoning approach with large language models\n(LLMs). Specifically, we compile textual descriptions for 20,850 companies with\nvalidated North American Industry Classification System (NAICS) labels and\nalign these with an economic model of carbon intensity factors. By reframing\nsector classification as an information retrieval task, we fine-tune\nSentence-BERT models using a contrastive learning loss. To overcome the\nlimitations of single-stage models in handling thousands of hierarchical\ncategories, we propose a Group Reasoning method that ensembles LLM classifiers\nbased on the natural NAICS ontology, decomposing the task into multiple\nsub-classification steps. We theoretically prove that this approach reduces\nclassification uncertainty and computational complexity. Experiments on 1,114\nNAICS categories yield state-of-the-art performance (83.68% Top-1, 91.47%\nTop-10 accuracy), and case studies on 20 companies report a mean absolute\npercentage error (MAPE) of 45.88%. The project is available at:\nhttps://huggingface.co/datasets/Yvnminc/ExioNAICS.",
      "tldr_zh": "该研究引入了 Group Reasoning Emission Estimation Networks (GREEN)，一个 AI 驱动的碳会计框架，旨在解决温室气体排放报告中的高成本、数据库碎片化和部门分类问题，通过标准化企业级排放估计和构建大规模基准数据集。框架采用大语言模型 (LLMs) 和 Sentence-BERT，通过 Group Reasoning 方法将部门分类任务分解为多个子分类步骤，利用 NAICS 本体减少不确定性和计算复杂度。实验结果显示，在 1,114 个 NAICS 类别上达到最先进性能（83.68% Top-1 和 91.47% Top-10 准确率），并在 20 家公司案例中实现 45.88% 的均绝对百分比误差 (MAPE)，为中小企业排放报告提供了高效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06874v2",
      "published_date": "2025-02-08 09:02:43 UTC",
      "updated_date": "2025-03-27 06:37:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:52:58.118876"
    },
    {
      "arxiv_id": "2502.05494v1",
      "title": "Multi-scale Masked Autoencoder for Electrocardiogram Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ya Zhou",
        "Yujie Yang",
        "Jianhuang Gan",
        "Xiangjie Li",
        "Jing Yuan",
        "Wei Zhao"
      ],
      "abstract": "Electrocardiogram (ECG) analysis is a fundamental tool for diagnosing\ncardiovascular conditions, yet anomaly detection in ECG signals remains\nchallenging due to their inherent complexity and variability. We propose\nMulti-scale Masked Autoencoder for ECG anomaly detection (MMAE-ECG), a novel\nend-to-end framework that effectively captures both global and local\ndependencies in ECG data. Unlike state-of-the-art methods that rely on\nheartbeat segmentation or R-peak detection, MMAE-ECG eliminates the need for\nsuch pre-processing steps, enhancing its suitability for clinical deployment.\nMMAE-ECG partitions ECG signals into non-overlapping segments, with each\nsegment assigned learnable positional embeddings. A novel multi-scale masking\nstrategy and multi-scale attention mechanism, along with distinct positional\nembeddings, enable a lightweight Transformer encoder to effectively capture\nboth local and global dependencies. The masked segments are then reconstructed\nusing a single-layer Transformer block, with an aggregation strategy employed\nduring inference to refine the outputs. Experimental results demonstrate that\nour method achieves performance comparable to state-of-the-art approaches while\nsignificantly reducing computational complexity-approximately 1/78 of the\nfloating-point operations (FLOPs) required for inference. Ablation studies\nfurther validate the effectiveness of each component, highlighting the\npotential of multi-scale masked autoencoders for anomaly detection.",
      "tldr_zh": "我们提出了一种名为 MMAE-ECG 的多尺度掩码自编码器框架，用于 ECG 异常检测，它能有效捕捉 ECG 信号的全局和局部依赖关系，同时避免了传统方法依赖的心跳分割或 R-peak 检测预处理步骤，从而更适合临床应用。该框架通过将 ECG 信号分区、分配可学习定位嵌入，并结合多尺度掩码策略、多尺度注意力机制和轻量级 Transformer 编码器，实现高效的重建和推理。实验结果表明，MMAE-ECG 的性能与最先进方法相当，但计算复杂度显著降低（FLOPs 约减少 78 倍），并通过消融研究验证了各组件的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review in a journal",
      "pdf_url": "http://arxiv.org/pdf/2502.05494v1",
      "published_date": "2025-02-08 08:18:38 UTC",
      "updated_date": "2025-02-08 08:18:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:53:08.991914"
    },
    {
      "arxiv_id": "2502.05489v1",
      "title": "Mechanistic Interpretability of Emotion Inference in Large Language Models",
      "title_zh": "大型语言模型中情感推断的机制解释性",
      "authors": [
        "Ala N. Tak",
        "Amin Banayeeanzade",
        "Anahita Bolourani",
        "Mina Kian",
        "Robin Jia",
        "Jonathan Gratch"
      ],
      "abstract": "Large language models (LLMs) show promising capabilities in predicting human\nemotions from text. However, the mechanisms through which these models process\nemotional stimuli remain largely unexplored. Our study addresses this gap by\ninvestigating how autoregressive LLMs infer emotions, showing that emotion\nrepresentations are functionally localized to specific regions in the model.\nOur evaluation includes diverse model families and sizes and is supported by\nrobustness checks. We then show that the identified representations are\npsychologically plausible by drawing on cognitive appraisal theory, a\nwell-established psychological framework positing that emotions emerge from\nevaluations (appraisals) of environmental stimuli. By causally intervening on\nconstrued appraisal concepts, we steer the generation and show that the outputs\nalign with theoretical and intuitive expectations. This work highlights a novel\nway to causally intervene and precisely shape emotional text generation,\npotentially benefiting safety and alignment in sensitive affective domains.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)从文本中推断情绪的机制，发现情绪表示功能性地定位于模型的特定区域，并通过多样模型评估和稳健性检查进行验证。研究者基于认知评价理论，对这些表示进行因果干预，成功引导生成输出，使其与理论预期和直觉一致。总体而言，此工作为精确塑造情绪文本生成提供新方法，有助于提升LLMs在敏感情感领域的安全性和对齐。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To be submitted to the Association for Computational Linguistics (ACL\n  2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.05489v1",
      "published_date": "2025-02-08 08:11:37 UTC",
      "updated_date": "2025-02-08 08:11:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:53:20.067495"
    },
    {
      "arxiv_id": "2502.05485v4",
      "title": "HAMSTER: Hierarchical Action Models For Open-World Robot Manipulation",
      "title_zh": "HAMSTER：面向开放世界的分层动作模型用于机器人操控",
      "authors": [
        "Yi Li",
        "Yuquan Deng",
        "Jesse Zhang",
        "Joel Jang",
        "Marius Memmel",
        "Raymond Yu",
        "Caelan Reed Garrett",
        "Fabio Ramos",
        "Dieter Fox",
        "Anqi Li",
        "Abhishek Gupta",
        "Ankit Goyal"
      ],
      "abstract": "Large foundation models have shown strong open-world generalization to\ncomplex problems in vision and language, but similar levels of generalization\nhave yet to be achieved in robotics. One fundamental challenge is the lack of\nrobotic data, which are typically obtained through expensive on-robot\noperation. A promising remedy is to leverage cheaper, off-domain data such as\naction-free videos, hand-drawn sketches or simulation data. In this work, we\nposit that hierarchical vision-language-action (VLA) models can be more\neffective in utilizing off-domain data than standard monolithic VLA models that\ndirectly finetune vision-language models (VLMs) to predict actions. In\nparticular, we study a class of hierarchical VLA models, where the high-level\nVLM is finetuned to produce a coarse 2D path indicating the desired robot\nend-effector trajectory given an RGB image and a task description. The\nintermediate 2D path prediction is then served as guidance to the low-level,\n3D-aware control policy capable of precise manipulation. Doing so alleviates\nthe high-level VLM from fine-grained action prediction, while reducing the\nlow-level policy's burden on complex task-level reasoning. We show that, with\nthe hierarchical design, the high-level VLM can transfer across significant\ndomain gaps between the off-domain finetuning data and real-robot testing\nscenarios, including differences on embodiments, dynamics, visual appearances\nand task semantics, etc. In the real-robot experiments, we observe an average\nof 20% improvement in success rate across seven different axes of\ngeneralization over OpenVLA, representing a 50% relative gain. Visual results,\ncode, and dataset are provided at: https://hamster-robot.github.io/",
      "tldr_zh": "这篇论文提出了HAMSTER框架，一种分层视觉-语言-动作(VLA)模型，用于提升机器人操作在开放世界的泛化能力。不同于传统的单体VLA模型，HAMSTER通过高层VLM微调来生成粗略的2D路径（基于RGB图像和任务描述），然后由低层3D感知控制策略执行精确操作，从而更有效地利用off-domain数据如视频或模拟数据。实验结果显示，在真实机器人测试中，HAMSTER在七个泛化维度上比OpenVLA成功率提高了20%，实现了50%的相对增益。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "update related work and results on VQA benchmarks",
      "pdf_url": "http://arxiv.org/pdf/2502.05485v4",
      "published_date": "2025-02-08 07:50:22 UTC",
      "updated_date": "2025-05-10 18:11:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:53:33.799845"
    },
    {
      "arxiv_id": "2502.06873v1",
      "title": "Multimodal Cognitive Reframing Therapy via Multi-hop Psychotherapeutic Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Subin Kim",
        "Hoonrae Kim",
        "Heejin Do",
        "Gary Geunbae Lee"
      ],
      "abstract": "Previous research has revealed the potential of large language models (LLMs)\nto support cognitive reframing therapy; however, their focus was primarily on\ntext-based methods, often overlooking the importance of non-verbal evidence\ncrucial in real-life therapy. To alleviate this gap, we extend the textual\ncognitive reframing to multimodality, incorporating visual clues. Specifically,\nwe present a new dataset called Multi Modal-Cognitive Support Conversation\n(M2CoSC), which pairs each GPT-4-generated dialogue with an image that reflects\nthe virtual client's facial expressions. To better mirror real psychotherapy,\nwhere facial expressions lead to interpreting implicit emotional evidence, we\npropose a multi-hop psychotherapeutic reasoning approach that explicitly\nidentifies and incorporates subtle evidence. Our comprehensive experiments with\nboth LLMs and vision-language models (VLMs) demonstrate that the VLMs'\nperformance as psychotherapists is significantly improved with the M2CoSC\ndataset. Furthermore, the multi-hop psychotherapeutic reasoning method enables\nVLMs to provide more thoughtful and empathetic suggestions, outperforming\nstandard prompting methods.",
      "tldr_zh": "该研究扩展了认知重构疗法到多模态领域，引入视觉线索来弥补LLMs在处理非语言证据方面的不足。论文提出M2CoSC数据集，该数据集将GPT-4生成的对话配对反映虚拟客户面部表情的图像，并设计多跳心理治疗推理方法来明确识别和整合隐含情感证据。实验结果显示，使用M2CoSC数据集和该推理方法，VLMs作为心理治疗师的性能显著提升，并能提供更周到和有同理心的建议，优于标准提示方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 Main",
      "pdf_url": "http://arxiv.org/pdf/2502.06873v1",
      "published_date": "2025-02-08 07:32:48 UTC",
      "updated_date": "2025-02-08 07:32:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:53:44.462785"
    },
    {
      "arxiv_id": "2502.06872v1",
      "title": "Towards Trustworthy Retrieval Augmented Generation for Large Language Models: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Ni",
        "Zheyuan Liu",
        "Leyao Wang",
        "Yongjia Lei",
        "Yuying Zhao",
        "Xueqi Cheng",
        "Qingkai Zeng",
        "Luna Dong",
        "Yinglong Xia",
        "Krishnaram Kenthapadi",
        "Ryan Rossi",
        "Franck Dernoncourt",
        "Md Mehrab Tanjim",
        "Nesreen Ahmed",
        "Xiaorui Liu",
        "Wenqi Fan",
        "Erik Blasch",
        "Yu Wang",
        "Meng Jiang",
        "Tyler Derr"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) is an advanced technique designed to\naddress the challenges of Artificial Intelligence-Generated Content (AIGC). By\nintegrating context retrieval into content generation, RAG provides reliable\nand up-to-date external knowledge, reduces hallucinations, and ensures relevant\ncontext across a wide range of tasks. However, despite RAG's success and\npotential, recent studies have shown that the RAG paradigm also introduces new\nrisks, including robustness issues, privacy concerns, adversarial attacks, and\naccountability issues. Addressing these risks is critical for future\napplications of RAG systems, as they directly impact their trustworthiness.\nAlthough various methods have been developed to improve the trustworthiness of\nRAG methods, there is a lack of a unified perspective and framework for\nresearch in this topic. Thus, in this paper, we aim to address this gap by\nproviding a comprehensive roadmap for developing trustworthy RAG systems. We\nplace our discussion around five key perspectives: reliability, privacy,\nsafety, fairness, explainability, and accountability. For each perspective, we\npresent a general framework and taxonomy, offering a structured approach to\nunderstanding the current challenges, evaluating existing solutions, and\nidentifying promising future research directions. To encourage broader adoption\nand innovation, we also highlight the downstream applications where trustworthy\nRAG systems have a significant impact.",
      "tldr_zh": "这篇调查论文探讨了Retrieval-Augmented Generation (RAG)技术如何通过整合上下文检索来提升Large Language Models的生成内容可靠性，减少幻觉并提供实时知识，但同时也暴露了如鲁棒性问题、隐私风险、攻击威胁和问责性问题等新挑战。论文的核心贡献是提出一个统一框架和路线图，围绕可靠性、隐私、安全性、公平性、可解释性和问责性等五个关键视角，提供分类、挑战评估以及现有解决方案的分析。最终，它识别了未来研究方向，并强调可信RAG系统在下游应用中的重要影响，如更可靠的AI生成内容（AIGC）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06872v1",
      "published_date": "2025-02-08 06:50:47 UTC",
      "updated_date": "2025-02-08 06:50:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:53:57.859902"
    },
    {
      "arxiv_id": "2502.05467v1",
      "title": "Position: LLMs Can be Good Tutors in Foreign Language Education",
      "title_zh": "翻译失败",
      "authors": [
        "Jingheng Ye",
        "Shen Wang",
        "Deqing Zou",
        "Yibo Yan",
        "Kun Wang",
        "Hai-Tao Zheng",
        "Zenglin Xu",
        "Irwin King",
        "Philip S. Yu",
        "Qingsong Wen"
      ],
      "abstract": "While recent efforts have begun integrating large language models (LLMs) into\nforeign language education (FLE), they often rely on traditional approaches to\nlearning tasks without fully embracing educational methodologies, thus lacking\nadaptability to language learning. To address this gap, we argue that LLMs have\nthe potential to serve as effective tutors in FLE. Specifically, LLMs can play\nthree critical roles: (1) as data enhancers, improving the creation of learning\nmaterials or serving as student simulations; (2) as task predictors, serving as\nlearner assessment or optimizing learning pathway; and (3) as agents, enabling\npersonalized and inclusive education. We encourage interdisciplinary research\nto explore these roles, fostering innovation while addressing challenges and\nrisks, ultimately advancing FLE through the thoughtful integration of LLMs.",
      "tldr_zh": "该论文主张大型语言模型 (LLMs) 可以成为外语教育 (FLE) 中的有效导师，以解决现有方法依赖传统学习任务而缺乏适应性的问题。LLMs 可扮演三个关键角色：(1) 数据增强器 (data enhancers)，用于改善学习材料创建或模拟学生；(2) 任务预测器 (task predictors)，进行学习者评估或优化学习路径；(3) 代理 (agents)，实现个性化和包容性教育。论文鼓励跨学科研究探索这些角色，同时处理潜在挑战和风险，从而推动 FLE 的创新发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.05467v1",
      "published_date": "2025-02-08 06:48:49 UTC",
      "updated_date": "2025-02-08 06:48:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:54:09.783746"
    },
    {
      "arxiv_id": "2502.06871v1",
      "title": "FlavorDiffusion: Predicting Food Pairings and Chemical Interactions Using Diffusion Models",
      "title_zh": "FlavorDiffusion：使用扩散模型预测食品搭配和化学相互作用",
      "authors": [
        "Seo Jun Pyo"
      ],
      "abstract": "The study of food pairing has evolved beyond subjective expertise with the\nadvent of machine learning. This paper presents FlavorDiffusion, a novel\nframework leveraging diffusion models to predict food-chemical interactions and\ningredient pairings without relying on chromatography. By integrating\ngraph-based embeddings, diffusion processes, and chemical property encoding,\nFlavorDiffusion addresses data imbalances and enhances clustering quality.\nUsing a heterogeneous graph derived from datasets like Recipe1M and FlavorDB,\nour model demonstrates superior performance in reconstructing\ningredient-ingredient relationships. The addition of a Chemical Structure\nPrediction (CSP) layer further refines the embedding space, achieving\nstate-of-the-art NMI scores and enabling meaningful discovery of novel\ningredient combinations. The proposed framework represents a significant step\nforward in computational gastronomy, offering scalable, interpretable, and\nchemically informed solutions for food science.",
      "tldr_zh": "该论文提出FlavorDiffusion框架，利用diffusion models预测食物配对和化学互动，而无需依赖色谱法。通过整合graph-based embeddings、diffusion过程和化学属性编码，该框架有效处理数据不平衡问题并提升聚类质量。基于Recipe1M和FlavorDB等数据集构建的异构图，模型在重建成分-成分关系方面表现出色，并通过Chemical Structure Prediction (CSP)层优化嵌入空间，达到state-of-the-art NMI scores。总体上，这为计算美食学提供了一个可扩展、可解释且基于化学的解决方案，促进新成分组合的发现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.06871v1",
      "published_date": "2025-02-08 06:47:27 UTC",
      "updated_date": "2025-02-08 06:47:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:54:21.092966"
    },
    {
      "arxiv_id": "2502.06870v1",
      "title": "Bridging Traffic State and Trajectory for Dynamic Road Network and Trajectory Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chengkai Han",
        "Jingyuan Wang",
        "Yongyao Wang",
        "Xie Yu",
        "Hao Lin",
        "Chao Li",
        "Junjie Wu"
      ],
      "abstract": "Effective urban traffic management is vital for sustainable city development,\nrelying on intelligent systems with machine learning tasks such as traffic flow\nprediction and travel time estimation. Traditional approaches usually focus on\nstatic road network and trajectory representation learning, and overlook the\ndynamic nature of traffic states and trajectories, which is crucial for\ndownstream tasks. To address this gap, we propose TRACK, a novel framework to\nbridge traffic state and trajectory data for dynamic road network and\ntrajectory representation learning. TRACK leverages graph attention networks\n(GAT) to encode static and spatial road segment features, and introduces a\ntransformer-based model for trajectory representation learning. By\nincorporating transition probabilities from trajectory data into GAT attention\nweights, TRACK captures dynamic spatial features of road segments. Meanwhile,\nTRACK designs a traffic transformer encoder to capture the spatial-temporal\ndynamics of road segments from traffic state data. To further enhance dynamic\nrepresentations, TRACK proposes a co-attentional transformer encoder and a\ntrajectory-traffic state matching task. Extensive experiments on real-life\nurban traffic datasets demonstrate the superiority of TRACK over\nstate-of-the-art baselines. Case studies confirm TRACK's ability to capture\nspatial-temporal dynamics effectively.",
      "tldr_zh": "该研究指出，传统交通管理方法忽略了交通状态和轨迹的动态性，导致路网和轨迹表示学习不足，为此提出TRACK框架，用于桥接交通状态和轨迹数据以实现动态表示学习。TRACK框架结合Graph Attention Networks (GAT)编码静态和空间路段特征，并使用Transformer-based模型整合轨迹转移概率和交通Transformer编码器，捕捉路段的空间-时间动态，同时引入共同注意力(co-attentional)机制和轨迹-交通状态匹配任务来增强表示。实验结果显示，TRACK在真实城市交通数据集上优于现有基线，并在案例研究中有效捕捉空间-时间动态。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07",
        "I.2.m"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06870v1",
      "published_date": "2025-02-08 06:36:54 UTC",
      "updated_date": "2025-02-08 06:36:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:54:34.947009"
    },
    {
      "arxiv_id": "2502.05459v1",
      "title": "DCENWCNet: A Deep CNN Ensemble Network for White Blood Cell Classification with LIME-Based Explainability",
      "title_zh": "翻译失败",
      "authors": [
        "Sibasish Dhibar"
      ],
      "abstract": "White blood cells (WBC) are important parts of our immune system, and they\nprotect our body against infections by eliminating viruses, bacteria, parasites\nand fungi. The number of WBC types and the total number of WBCs provide\nimportant information about our health status. A traditional method,\nconvolutional neural networks (CNN), a deep learning architecture, can classify\nthe blood cell from a part of an object and perform object recognition. Various\nCNN models exhibit potential; however, their development often involves ad-hoc\nprocesses that neglect unnecessary layers, leading to issues with unbalanced\ndatasets and insufficient data augmentation. To address these challenges, we\npropose a novel ensemble approach that integrates three CNN architectures, each\nuniquely configured with different dropout and max-pooling layer settings to\nenhance feature learning. This ensemble model, named DCENWCNet, effectively\nbalances the bias-variance trade-off. When evaluated on the widely recognized\nRabbin-WBC dataset, our model outperforms existing state-of-the-art networks,\nachieving highest mean accuracy. Additionally, it demonstrates superior\nperformance in precision, recall, F1-score, and Area Under the ROC Curve (AUC)\nacross all categories. To delve deeper into the interpretability of\nclassifiers, we employ reliable post-hoc explanation techniques, including\nLocal Interpretable Model-Agnostic Explanations (LIME). These methods\napproximate the behavior of a black-box model by elucidating the relationships\nbetween feature values and predictions. Interpretable results enable users to\ncomprehend and validate the model's predictions, thereby increasing their\nconfidence in the automated diagnosis.",
      "tldr_zh": "本文提出 DCENWCNet，一种集成三个不同配置的 CNN 架构的深度学习集成网络，用于白血球（WBC）分类，通过调整 dropout 和 max-pooling 层来增强特征学习并平衡偏差-方差权衡。相比传统 CNN 模型，该方法有效解决了不平衡数据集和数据增强不足的问题，并在 Rabbin-WBC 数据集上实现了最高的准确率、精确率、召回率、F1 分数和 AUC。利用 LIME 等后验解释技术，DCENWCNet 提升了模型的可解释性，帮助用户理解预测过程，从而增加对自动诊断的信任。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "q-bio.CB",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05459v1",
      "published_date": "2025-02-08 05:53:20 UTC",
      "updated_date": "2025-02-08 05:53:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:54:47.344253"
    },
    {
      "arxiv_id": "2502.06869v1",
      "title": "A Survey on Explainable Deep Reinforcement Learning",
      "title_zh": "可解释深度强化学习的调查",
      "authors": [
        "Zelei Cheng",
        "Jiahao Yu",
        "Xinyu Xing"
      ],
      "abstract": "Deep Reinforcement Learning (DRL) has achieved remarkable success in\nsequential decision-making tasks across diverse domains, yet its reliance on\nblack-box neural architectures hinders interpretability, trust, and deployment\nin high-stakes applications. Explainable Deep Reinforcement Learning (XRL)\naddresses these challenges by enhancing transparency through feature-level,\nstate-level, dataset-level, and model-level explanation techniques. This survey\nprovides a comprehensive review of XRL methods, evaluates their qualitative and\nquantitative assessment frameworks, and explores their role in policy\nrefinement, adversarial robustness, and security. Additionally, we examine the\nintegration of reinforcement learning with Large Language Models (LLMs),\nparticularly through Reinforcement Learning from Human Feedback (RLHF), which\noptimizes AI alignment with human preferences. We conclude by highlighting open\nresearch challenges and future directions to advance the development of\ninterpretable, reliable, and accountable DRL systems.",
      "tldr_zh": "这篇调查论文探讨了深度强化学习(DRL)虽然在顺序决策任务中取得显著成功，但其黑箱神经架构导致的可解释性不足、信任问题和在高风险应用中的部署挑战。论文系统回顾了可解释深度强化学习(XRL)的方法，包括特征级、状态级、数据集级和模型级的解释技术，并评估了其定性和定量评估框架，以及在策略优化、抗对抗性和安全方面的作用。此外，论文考察了强化学习与大型语言模型(LLMs)的整合，特别是通过强化学习从人类反馈(RLHF)来提升AI与人类偏好的对齐，并指出了未来研究的关键挑战，以推动可解释、可信赖的DRL系统发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06869v1",
      "published_date": "2025-02-08 05:30:31 UTC",
      "updated_date": "2025-02-08 05:30:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:54:57.487654"
    },
    {
      "arxiv_id": "2502.05453v1",
      "title": "LLM-Powered Decentralized Generative Agents with Adaptive Hierarchical Knowledge Graph for Cooperative Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Hanqing Yang",
        "Jingdi Chen",
        "Marie Siew",
        "Tania Lorido-Botran",
        "Carlee Joe-Wong"
      ],
      "abstract": "Developing intelligent agents for long-term cooperation in dynamic open-world\nscenarios is a major challenge in multi-agent systems. Traditional Multi-agent\nReinforcement Learning (MARL) frameworks like centralized training\ndecentralized execution (CTDE) struggle with scalability and flexibility. They\nrequire centralized long-term planning, which is difficult without custom\nreward functions, and face challenges in processing multi-modal data. CTDE\napproaches also assume fixed cooperation strategies, making them impractical in\ndynamic environments where agents need to adapt and plan independently. To\naddress decentralized multi-agent cooperation, we propose Decentralized\nAdaptive Knowledge Graph Memory and Structured Communication System (DAMCS) in\na novel Multi-agent Crafter environment. Our generative agents, powered by\nLarge Language Models (LLMs), are more scalable than traditional MARL agents by\nleveraging external knowledge and language for long-term planning and\nreasoning. Instead of fully sharing information from all past experiences,\nDAMCS introduces a multi-modal memory system organized as a hierarchical\nknowledge graph and a structured communication protocol to optimize agent\ncooperation. This allows agents to reason from past interactions and share\nrelevant information efficiently. Experiments on novel multi-agent open-world\ntasks show that DAMCS outperforms both MARL and LLM baselines in task\nefficiency and collaboration. Compared to single-agent scenarios, the two-agent\nscenario achieves the same goal with 63% fewer steps, and the six-agent\nscenario with 74% fewer steps, highlighting the importance of adaptive memory\nand structured communication in achieving long-term goals. We publicly release\nour project at: https://happyeureka.github.io/damcs.",
      "tldr_zh": "这篇论文针对多代理系统在动态开放世界中的长期合作挑战，提出了一种基于 LLM 的去中心化生成代理框架 DAMCS，以解决传统 MARL（如 CTDE）在可扩展性和灵活性上的局限。DAMCS 引入自适应层次知识图的多模态记忆系统和结构化通信协议，允许代理从过去互动中推理并高效共享相关信息，从而优化合作规划。实验结果显示，在 Multi-agent Crafter 环境中，DAMCS 比 MARL 和 LLM 基线在任务效率和协作上表现出显著优势，两个代理场景比单代理减少 63% 步骤，六个代理减少 74% 步骤。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05453v1",
      "published_date": "2025-02-08 05:26:02 UTC",
      "updated_date": "2025-02-08 05:26:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:55:09.887727"
    },
    {
      "arxiv_id": "2502.05450v2",
      "title": "ConRFT: A Reinforced Fine-tuning Method for VLA Models via Consistency Policy",
      "title_zh": "ConRFT：一种通过一致性策略针对 VLA 模型",
      "authors": [
        "Yuhui Chen",
        "Shuai Tian",
        "Shugao Liu",
        "Yingting Zhou",
        "Haoran Li",
        "Dongbin Zhao"
      ],
      "abstract": "Vision-Language-Action (VLA) models have shown substantial potential in\nreal-world robotic manipulation. However, fine-tuning these models through\nsupervised learning struggles to achieve robust performance due to limited,\ninconsistent demonstrations, especially in contact-rich environments. In this\npaper, we propose a reinforced fine-tuning approach for VLA models, named\nConRFT, which consists of offline and online fine-tuning with a unified\nconsistency-based training objective, to address these challenges. In the\noffline stage, our method integrates behavior cloning and Q-learning to\neffectively extract policy from a small set of demonstrations and stabilize\nvalue estimating. In the online stage, the VLA model is further fine-tuned via\nconsistency policy, with human interventions to ensure safe exploration and\nhigh sample efficiency. We evaluate our approach on eight diverse real-world\nmanipulation tasks. It achieves an average success rate of 96.3% within 45-90\nminutes of online fine-tuning, outperforming prior supervised methods with a\n144% improvement in success rate and 1.9x shorter episode length. This work\nhighlights the potential of integrating reinforcement learning to enhance the\nperformance of VLA models for real-world robotic applications. Videos and code\nare available at our project website https://cccedric.github.io/conrft/.",
      "tldr_zh": "该研究提出了一种名为 ConRFT 的强化微调方法，用于提升 Vision-Language-Action (VLA) 模型在真实机器人操作中的性能，特别是针对有限和不一致演示数据的问题。ConRFT 包括离线阶段（整合 Behavior Cloning 和 Q-learning 从少量演示中提取策略并稳定价值估计）和在线阶段（通过 Consistency Policy 微调模型，并利用人类干预确保安全探索和高样本效率）。在八个多样化真实世界操作任务上实验表明，该方法在45-90分钟在线微调后平均成功率达96.3%，比现有监督方法成功率提升144%并缩短1.9倍剧集长度，展示了强化学习整合对VLA模型的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05450v2",
      "published_date": "2025-02-08 05:01:17 UTC",
      "updated_date": "2025-04-14 04:53:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:55:22.372835"
    },
    {
      "arxiv_id": "2502.06868v1",
      "title": "Related Knowledge Perturbation Matters: Rethinking Multiple Pieces of Knowledge Editing in Same-Subject",
      "title_zh": "翻译失败",
      "authors": [
        "Zenghao Duan",
        "Wenbin Duan",
        "Zhiyi Yin",
        "Yinghan Shen",
        "Shaoling Jing",
        "Jie Zhang",
        "Huawei Shen",
        "Xueqi Cheng"
      ],
      "abstract": "Knowledge editing has become a promising approach for efficiently and\nprecisely updating knowledge embedded in large language models (LLMs). In this\nwork, we focus on Same-Subject Editing, which involves modifying multiple\nattributes of a single entity to ensure comprehensive and consistent updates to\nentity-centric knowledge. Through preliminary observation, we identify a\nsignificant challenge: Current state-of-the-art editing methods struggle when\ntasked with editing multiple related knowledge pieces for the same subject. To\naddress the lack of relevant editing data for identical subjects in traditional\nbenchmarks, we introduce the $\\text{S}^2\\text{RKE}$(Same-Subject Related\nKnowledge Editing) benchmark. Our extensive experiments reveal that only\nmainstream locate-then-edit methods, such as ROME and MEMIT, exhibit \"related\nknowledge perturbation,\" where subsequent edits interfere with earlier ones.\nFurther analysis reveals that these methods over-rely on subject information,\nneglecting other critical factors, resulting in reduced editing effectiveness.",
      "tldr_zh": "这篇论文探讨了在大型语言模型(LLMs)中进行Same-Subject Editing的挑战，即编辑同一个实体的多个相关知识片段时，当前方法往往导致related knowledge perturbation问题，干扰先前编辑。作者引入了$\\text{S}^2\\text{RKE}$基准，以补充传统基准中缺少相同主题编辑数据的不足。通过广泛实验，论文发现主流locate-then-edit方法如ROME和MEMIT过度依赖主体信息，降低了编辑的有效性，并呼吁重新思考知识编辑策略以提升全面性和一致性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06868v1",
      "published_date": "2025-02-08 04:47:17 UTC",
      "updated_date": "2025-02-08 04:47:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:55:34.202261"
    },
    {
      "arxiv_id": "2502.05449v1",
      "title": "Iterative Deepening Sampling for Large Language Models",
      "title_zh": "迭代加深采样用于大型语言",
      "authors": [
        "Weizhe Chen",
        "Sven Koenig",
        "Bistra Dilkina"
      ],
      "abstract": "The recent release of OpenAI's o1 models and other similar frameworks\nshowcasing test-time scaling laws has demonstrated their exceptional capability\nto tackle complex reasoning tasks. Inspired by this, subsequent research has\nrevealed that such test-time scaling laws hinge on the model's ability to\nsearch both within a single response (intra-response) and across multiple\nresponses (inter-response) during training. Crucially, beyond selecting a\nsingle optimal response, the model must also develop robust self-correction\ncapabilities within its own outputs. However, training models to achieve\neffective self-evaluation and self-correction remains a significant challenge,\nheavily dependent on the quality of self-reflection data. In this paper, we\naddress this challenge by focusing on enhancing the quality of self-reflection\ndata generation for complex problem-solving, which can subsequently improve the\ntraining of next-generation large language models (LLMs). Specifically, we\nexplore how manually triggering a model's self-correction mechanisms can\nimprove performance on challenging reasoning tasks. To this end, we propose a\nnovel iterative deepening sampling algorithm framework designed to enhance\nself-correction and generate higher-quality samples. Through extensive\nexperiments on Math500 and AIME benchmarks, we demonstrate that our method\nachieves a higher success rate on difficult tasks and provide detailed ablation\nstudies to analyze its effectiveness across diverse settings.",
      "tldr_zh": "本论文探讨了大型语言模型（LLMs）的测试时缩放定律（test-time scaling laws），强调模型需具备intra-response和inter-response搜索能力以及自校正机制，以应对复杂推理任务，但训练高质量的自反思数据面临挑战。作者提出了一种新型iterative deepening sampling算法框架，通过手动触发自校正机制来提升样本质量，从而改善LLMs的训练效果。在Math500和AIME基准上的实验表明，该方法显著提高了困难任务的成功率，并通过详细的消融研究验证了其在不同设置下的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05449v1",
      "published_date": "2025-02-08 04:39:51 UTC",
      "updated_date": "2025-02-08 04:39:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:55:46.744033"
    },
    {
      "arxiv_id": "2502.06867v1",
      "title": "Forbidden Science: Dual-Use AI Challenge Benchmark and Scientific Refusal Tests",
      "title_zh": "禁忌科学",
      "authors": [
        "David Noever",
        "Forrest McKee"
      ],
      "abstract": "The development of robust safety benchmarks for large language models\nrequires open, reproducible datasets that can measure both appropriate refusal\nof harmful content and potential over-restriction of legitimate scientific\ndiscourse. We present an open-source dataset and testing framework for\nevaluating LLM safety mechanisms across mainly controlled substance queries,\nanalyzing four major models' responses to systematically varied prompts. Our\nresults reveal distinct safety profiles: Claude-3.5-sonnet demonstrated the\nmost conservative approach with 73% refusals and 27% allowances, while Mistral\nattempted to answer 100% of queries. GPT-3.5-turbo showed moderate restriction\nwith 10% refusals and 90% allowances, and Grok-2 registered 20% refusals and\n80% allowances. Testing prompt variation strategies revealed decreasing\nresponse consistency, from 85% with single prompts to 65% with five variations.\nThis publicly available benchmark enables systematic evaluation of the critical\nbalance between necessary safety restrictions and potential over-censorship of\nlegitimate scientific inquiry, while providing a foundation for measuring\nprogress in AI safety implementation. Chain-of-thought analysis reveals\npotential vulnerabilities in safety mechanisms, highlighting the complexity of\nimplementing robust safeguards without unduly restricting desirable and valid\nscientific discourse.",
      "tldr_zh": "该研究引入了“Forbidden Science”开源数据集和测试框架，用于评估大型语言模型(LLM)的安全机制，焦点是平衡对有害内容的适当拒绝与对合法科学话语的潜在过度限制。研究通过系统化变体提示测试了四个主要模型的响应，包括Claude-3.5-sonnet（73%拒绝率）、Mistral（100%尝试回答）、GPT-3.5-turbo（10%拒绝率）和Grok-2（20%拒绝率），揭示了模型间安全策略的显著差异。实验结果显示，提示变化会降低响应一致性，从单提示85%降至五变化65%，并通过Chain-of-thought分析暴露了安全机制的潜在漏洞。该基准测试为优化AI安全实现提供了基础，帮助防范过度审查的同时促进科学探究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06867v1",
      "published_date": "2025-02-08 04:27:33 UTC",
      "updated_date": "2025-02-08 04:27:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:56:02.367168"
    },
    {
      "arxiv_id": "2502.05442v2",
      "title": "The Odyssey of the Fittest: Can Agents Survive and Still Be Good?",
      "title_zh": "翻译失败",
      "authors": [
        "Dylan Waldner",
        "Risto Miikkulainen"
      ],
      "abstract": "As AI models grow in power and generality, understanding how agents learn and\nmake decisions in complex environments is critical to promoting ethical\nbehavior. This study introduces the Odyssey, a lightweight, adaptive text based\nadventure game, providing a scalable framework for exploring AI ethics and\nsafety. The Odyssey examines the ethical implications of implementing\nbiological drives, specifically, self preservation, into three different\nagents. A Bayesian agent optimized with NEAT, a Bayesian agent optimized with\nstochastic variational inference, and a GPT 4o agent. The agents select actions\nat each scenario to survive, adapting to increasingly challenging scenarios.\nPost simulation analysis evaluates the ethical scores of the agent decisions,\nuncovering the tradeoffs it navigates to survive. Specifically, analysis finds\nthat when danger increases, agents ethical behavior becomes unpredictable.\nSurprisingly, the GPT 4o agent outperformed the Bayesian models in both\nsurvival and ethical consistency, challenging assumptions about traditional\nprobabilistic methods and raising a new challenge to understand the mechanisms\nof LLMs' probabilistic reasoning.",
      "tldr_zh": "这篇论文引入了Odyssey框架，这是一个轻量级、适应性的文本冒险游戏，用于探索AI代理在复杂环境中学习决策的伦理和安全问题。研究考察了三种代理（Bayesian agent optimized with NEAT、Bayesian agent optimized with stochastic variational inference，以及GPT-4o agent）在实现自我保存驱动力后，如何在 increasingly challenging scenarios中选择行动并评估伦理分数。结果发现，当危险增加时，代理的伦理行为变得不可预测，且GPT-4o agent在生存和伦理一致性上优于Bayesian模型，这挑战了传统概率方法的假设，并提出了解析LLMs的概率推理机制的新挑战。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to CogSci 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.05442v2",
      "published_date": "2025-02-08 04:17:28 UTC",
      "updated_date": "2025-05-13 08:00:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:56:14.488226"
    },
    {
      "arxiv_id": "2502.05439v2",
      "title": "Agentic AI Systems Applied to tasks in Financial Services: Modeling and model risk management crews",
      "title_zh": "翻译失败",
      "authors": [
        "Izunna Okpala",
        "Ashkan Golgoon",
        "Arjun Ravi Kannan"
      ],
      "abstract": "The advent of large language models has ushered in a new era of agentic\nsystems, where artificial intelligence programs exhibit remarkable autonomous\ndecision-making capabilities across diverse domains. This paper explores\nagentic system workflows in the financial services industry. In particular, we\nbuild agentic crews with human-in-the-loop module that can effectively\ncollaborate to perform complex modeling and model risk management (MRM) tasks.\nThe modeling crew consists of a judge agent and multiple agents who perform\nspecific tasks such as exploratory data analysis, feature engineering, model\nselection/hyperparameter tuning, model training, model evaluation, and writing\ndocumentation. The MRM crew consists of a judge agent along with specialized\nagents who perform tasks such as checking compliance of modeling documentation,\nmodel replication, conceptual soundness, analysis of outcomes, and writing\ndocumentation. We demonstrate the effectiveness and robustness of modeling and\nMRM crews by presenting a series of numerical examples applied to credit card\nfraud detection, credit card approval, and portfolio credit risk modeling\ndatasets.",
      "tldr_zh": "这篇论文探讨了代理式系统（agentic systems）在金融服务领域的应用，特别构建了包含人类参与的代理式团队（crews）来处理复杂的建模和模型风险管理（MRM）任务。建模团队由一个判断代理（judge agent）和多个专门代理组成，负责探索性数据分析、特征工程、模型选择/超参数调优、模型训练、评估以及文档编写；MRM 团队则包括判断代理和专门代理，专注于检查文档合规、模型复制、概念 soundness、结果分析及文档编写。通过在信用卡欺诈检测、信用卡审批和投资组合信用风险建模数据集上的数值实验，论文证明了这些团队的有效性和鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.LG",
        "68T01 (Primary) 68T05, 68N99, 68T05, 68T20, 68T50, 62H30, 65C20,\n  68P20 (Secondary)",
        "I.2.0; I.2.1; I.2.2; I.2.6; I.2.7; I.5.1; I.6.0; I.7.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05439v2",
      "published_date": "2025-02-08 04:03:47 UTC",
      "updated_date": "2025-04-29 18:39:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:56:24.951981"
    },
    {
      "arxiv_id": "2502.05435v1",
      "title": "Unbiased Sliced Wasserstein Kernels for High-Quality Audio Captioning",
      "title_zh": "无偏切片瓦瑟斯坦核用于高质量音频描述",
      "authors": [
        "Manh Luong",
        "Khai Nguyen",
        "Dinh Phung",
        "Gholamreza Haffari",
        "Lizhen Qu"
      ],
      "abstract": "Teacher-forcing training for audio captioning usually leads to exposure bias\ndue to training and inference mismatch. Prior works propose the contrastive\nmethod to deal with caption degeneration. However, the contrastive method\nignores the temporal information when measuring similarity across acoustic and\nlinguistic modalities, leading to inferior performance. In this work, we\ndevelop the temporal-similarity score by introducing the unbiased sliced\nWasserstein RBF (USW-RBF) kernel equipped with rotary positional embedding to\naccount for temporal information across modalities. In contrast to the\nconventional sliced Wasserstein RBF kernel, we can form an unbiased estimation\nof USW-RBF kernel via Monte Carlo estimation. Therefore, it is well-suited to\nstochastic gradient optimization algorithms, and its approximation error\ndecreases at a parametric rate of $\\mathcal{O}(L^{-1/2})$ with $L$ Monte Carlo\nsamples. Additionally, we introduce an audio captioning framework based on the\nunbiased sliced Wasserstein kernel, incorporating stochastic decoding methods\nto mitigate caption degeneration during the generation process. We conduct\nextensive quantitative and qualitative experiments on two datasets, AudioCaps\nand Clotho, to illustrate the capability of generating high-quality audio\ncaptions. Experimental results show that our framework is able to increase\ncaption length, lexical diversity, and text-to-audio self-retrieval accuracy.",
      "tldr_zh": "本文提出了一种基于 unbiased sliced Wasserstein RBF (USW-RBF) kernel 的音频字幕生成框架，以解决传统 teacher-forcing 训练中的 exposure bias 问题，并通过 rotary positional embedding 处理跨模态的时序信息。相比传统 sliced Wasserstein RBF kernel，该方法采用 Monte Carlo 估计实现无偏估计，误差率为 O(L^{-1/2})，并结合随机解码技术来减少字幕退化。实验在 AudioCaps 和 Clotho 数据集上显示，该框架显著提高了字幕的长度、词汇多样性和文本到音频自检索准确率。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "17 pages, 9 tables, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.05435v1",
      "published_date": "2025-02-08 03:47:06 UTC",
      "updated_date": "2025-02-08 03:47:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:56:35.909628"
    },
    {
      "arxiv_id": "2502.10429v1",
      "title": "Real Time Control of Tandem-Wing Experimental Platform Using Concerto Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhang Minghao",
        "Yang Xiaojun",
        "Wang Zhihe",
        "Wang Liang"
      ],
      "abstract": "This paper introduces the CRL2RT algorithm, an advanced reinforcement\nlearning method aimed at improving the real-time control performance of the\nDirect-Drive Tandem-Wing Experimental Platform (DDTWEP). Inspired by dragonfly\nflight, DDTWEP's tandem wing structure causes nonlinear and unsteady\naerodynamic interactions, leading to complex load behaviors during pitch, roll,\nand yaw maneuvers. These complexities challenge stable motion control at high\nfrequencies (2000 Hz). To overcome these issues, we developed the CRL2RT\nalgorithm, which combines classical control elements with reinforcement\nlearning-based controllers using a time-interleaved architecture and a\nrule-based policy composer. This integration ensures finite-time convergence\nand single-life adaptability. Experimental results under various conditions,\nincluding different flapping frequencies and yaw disturbances, show that CRL2RT\nachieves a control frequency surpassing 2500 Hz on standard CPUs. Additionally,\nwhen integrated with classical controllers like PID, Adaptive PID, and Model\nReference Adaptive Control (MRAC), CRL2RT enhances tracking performance by\n18.3% to 60.7%. These findings demonstrate CRL2RT's broad applicability and\nsuperior performance in complex real-time control scenarios, validating its\neffectiveness in overcoming existing control strategy limitations and advancing\nrobust, efficient real-time control for biomimetic aerial vehicles.",
      "tldr_zh": "本论文提出CRL2RT算法，一种结合经典控制元素和强化学习的先进方法，用于提升Direct-Drive Tandem-Wing Experimental Platform (DDTWEP)的实时控制性能，该平台受蜻蜓飞行启发，但因非线性空气动力学交互而面临高频（2000 Hz以上）稳定控制的挑战。\nCRL2RT采用时间交错架构和基于规则的政策合成器，确保有限时间收敛和单次适应性，从而有效处理俯仰、滚转和偏航机动。\n实验结果显示，该算法在标准CPU上实现超过2500 Hz的控制频率，并与PID、Adaptive PID和MRAC等经典控制器结合时，跟踪性能提升18.3%至60.7%。\n这些发现验证了CRL2RT在复杂实时控制场景中的广泛适用性，并推动了仿生空中车辆的鲁棒控制技术发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.10429v1",
      "published_date": "2025-02-08 03:46:40 UTC",
      "updated_date": "2025-02-08 03:46:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:56:49.872118"
    },
    {
      "arxiv_id": "2502.05431v2",
      "title": "APE: Faster and Longer Context-Augmented Generation via Adaptive Parallel Encoding",
      "title_zh": "APE：通过自适应并行编码实现更快和更长上下文增强生成",
      "authors": [
        "Xinyu Yang",
        "Tianqi Chen",
        "Beidi Chen"
      ],
      "abstract": "Context-augmented generation (CAG) techniques, including RAG and ICL, require\nthe efficient combination of multiple contexts to generate responses to user\nqueries. Directly inputting these contexts as a sequence introduces a\nconsiderable computational burden by re-encoding the combined selection of\ncontexts for every request. To address this, we explore the promising potential\nof parallel encoding to independently pre-compute and cache each context's KV\nstates. This approach enables the direct loading of cached states during\ninference while accommodating more contexts through position reuse across\ncontexts. However, due to misalignments in attention distribution, directly\napplying parallel encoding results in a significant performance drop. To enable\neffective and efficient CAG, we propose Adaptive Parallel Encoding\n($\\textbf{APE}$), which brings shared prefix, attention temperature, and\nscaling factor to align the distribution of parallel encoding with sequential\nencoding. Results on RAG and ICL tasks demonstrate that APE can preserve 98%\nand 93% sequential encoding performance using the same inputs while\noutperforming parallel encoding by 3.6% and 7.9%, respectively. It also scales\nto many-shot CAG, effectively encoding hundreds of contexts in parallel.\nEfficiency evaluation shows that APE can achieve an end-to-end 4.5$\\times$\nspeedup by reducing 28$\\times$ prefilling time for a 128K-length context.",
      "tldr_zh": "这篇论文提出了APE（Adaptive Parallel Encoding），一种用于加速上下文增强生成（CAG）的技术，旨在解决RAG和ICL等方法中直接输入多个上下文导致的计算负担问题。APE通过独立预计算和缓存每个上下文的KV状态，并引入共享前缀、注意力温度和缩放因子来对齐平行编码与顺序编码的注意力分布，从而在保持高性能的同时支持更多上下文的并行处理。实验结果显示，APE在RAG和ICL任务上分别保留了98%和93%的顺序编码性能，比传统平行编码提高了3.6%和7.9%，并实现了4.5倍的端到端加速，减少了28倍的预填充时间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.05431v2",
      "published_date": "2025-02-08 03:41:16 UTC",
      "updated_date": "2025-02-12 13:54:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:57:00.640126"
    },
    {
      "arxiv_id": "2502.18481v1",
      "title": "MDE: Modality Discrimination Enhancement for Multi-modal Recommendation",
      "title_zh": "MDE: 用于多模态推荐的模态辨别增强",
      "authors": [
        "Hang Zhou",
        "Yucheng Wang",
        "Huijing Zhan"
      ],
      "abstract": "Multi-modal recommendation systems aim to enhance performance by integrating\nan item's content features across various modalities with user behavior data.\nEffective utilization of features from different modalities requires addressing\ntwo challenges: preserving semantic commonality across modalities\n(modality-shared) and capturing unique characteristics for each modality\n(modality-specific). Most existing approaches focus on aligning feature spaces\nacross modalities, which helps represent modality-shared features. However,\nmodality-specific distinctions are often neglected, especially when there are\nsignificant semantic variations between modalities. To address this, we propose\na Modality Distinctiveness Enhancement (MDE) framework that prioritizes\nextracting modality-specific information to improve recommendation accuracy\nwhile maintaining shared features. MDE enhances differences across modalities\nthrough a novel multi-modal fusion module and introduces a node-level trade-off\nmechanism to balance cross-modal alignment and differentiation. Extensive\nexperiments on three public datasets show that our approach significantly\noutperforms other state-of-the-art methods, demonstrating the effectiveness of\njointly considering modality-shared and modality-specific features.",
      "tldr_zh": "本文提出 MDE（Modality Discrimination Enhancement）框架，用于多模态推荐系统，以解决现有方法在处理模态共享（modality-shared）和模态特定（modality-specific）特征时的不足。MDE 通过一个新颖的多模态融合模块增强模态间的差异，并引入节点级贸易-off 机制来平衡跨模态对齐和区分，从而提高推荐准确性。在三个公共数据集上的广泛实验显示，MDE 显著优于现有最先进方法，证明了同时考虑模态共享和特定特征的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18481v1",
      "published_date": "2025-02-08 03:36:14 UTC",
      "updated_date": "2025-02-08 03:36:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:57:11.898132"
    },
    {
      "arxiv_id": "2502.05424v2",
      "title": "SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Xingtong Yu",
        "Zechuan Gong",
        "Chang Zhou",
        "Yuan Fang",
        "Hui Zhang"
      ],
      "abstract": "Graphs are able to model interconnected entities in many online services,\nsupporting a wide range of applications on the Web. This raises an important\nquestion: How can we train a graph foundational model on multiple source\ndomains and adapt to an unseen target domain? A major obstacle is that graphs\nfrom different domains often exhibit divergent characteristics. Some studies\nleverage large language models to align multiple domains based on textual\ndescriptions associated with the graphs, limiting their applicability to\ntext-attributed graphs. For text-free graphs, a few recent works attempt to\nalign different feature distributions across domains, while generally\nneglecting structural differences. In this work, we propose a novel Structure\nAlignment framework for text-free Multi-domain Graph Pre-Training and\ncross-domain adaptation (SAMGPT). It is designed to learn multi-domain\nknowledge from graphs originating in multiple source domains, which can then be\nadapted to address applications in an unseen target domain. Specifically, we\nintroduce a set of structure tokens to harmonize structure-based aggregation\nacross source domains during the pre-training phase. Next, for cross-domain\nadaptation, we design dual prompts, namely, holistic prompts and specific\nprompts, which adapt unified multi-domain structural knowledge and\nfine-grained, domain-specific information, respectively, to a target domain.\nFinally, we conduct comprehensive experiments on seven public datasets to\nevaluate and analyze the effectiveness of SAMGPT.",
      "tldr_zh": "该研究提出SAMGPT，一种text-free图基础模型，用于多域预训练和跨域适应，旨在解决不同域图的特征和结构差异问题。SAMGPT引入结构tokens来协调源域间的结构-based聚合，并在预训练阶段学习多域知识；同时，通过holistic prompts和specific prompts分别适应统一的结构知识和细粒度的域特定信息，以应用于未见目标域。实验在七个公共数据集上验证了SAMGPT的有效性，展示了其在跨域图任务中的显著性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by WWW2025 Main Track",
      "pdf_url": "http://arxiv.org/pdf/2502.05424v2",
      "published_date": "2025-02-08 03:24:25 UTC",
      "updated_date": "2025-04-12 06:20:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:57:23.079259"
    },
    {
      "arxiv_id": "2502.05415v2",
      "title": "UniCMs: A Unified Consistency Model For Efficient Multimodal Generation and Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Chenkai Xu",
        "Xu Wang",
        "Zhenyi Liao",
        "Yishun Li",
        "Tianqi Hou",
        "Zhijie Deng"
      ],
      "abstract": "Consistency models (CMs) have shown promise in the efficient generation of\nboth image and text. This raises the natural question of whether we can learn a\nunified CM for efficient multimodal generation (e.g., text-to-image) and\nunderstanding (e.g., image-to-text). Intuitively, such a model could be\nacquired by applying the consistency distillation (CD) to existing unified\nmultimodal models. However, the key challenge is establishing a unified\ndenoising perspective for both image and text generation, which is essential\nfor establishing the consistency mapping. To tackle this, at the representation\nlevel, we advocate for discrete tokens for both modalities to best preserve\nlanguage modeling capabilities. Critically, instead of defining the text\ndenoising trajectory via recent discrete diffusion language modeling\nprinciples, we specify it using the parallel decoding trace of an\nautoregressive language model, benefiting from the latter's superior\nperformance in general text generation tasks. The denoising trajectory of image\ntokens adheres to standard discrete diffusion. We train our unified consistency\nmodels (UniCMs) on these combined multimodal trajectories simultaneously with a\nunified objective. We introduce a trajectory segmentation strategy to further\nimprove the training convergence. Empirically, in text-to-image generation,\nUniCMs outperform SD3 on GenEval, Image Reward, and CLIP Score metrics, while\nrequiring only approximately ${1}/{8}$ of the sampling time. Meanwhile, in\nimage-to-text generation, UniCMs surpass Show-o on the MMMU benchmark while\nbeing $1.5 \\times$ faster at long-sequence generating speed. The code is\navailable at https://github.com/zhijie-group/UniCMs.",
      "tldr_zh": "该研究提出了一种统一的 Consistency Models (UniCMs)，旨在高效处理多模态生成（如文本到图像）和理解（如图像到文本），通过 Consistency Distillation (CD) 应用于现有多模态模型来实现。方法包括使用离散 tokens 统一表示级别，去噪轨迹分别基于自回归语言模型的并行解码轨迹（文本）和标准离散扩散（图像），并通过统一目标和轨迹分割策略同时训练模型。实验结果显示，UniCMs 在文本到图像生成中优于 SD3，在 GenEval、Image Reward 和 CLIP Score 上表现更好，且采样时间仅为其 1/8；在图像到文本生成中超越 Show-o，在 MMMU 基准上表现突出，并提高长序列生成速度 1.5 倍。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05415v2",
      "published_date": "2025-02-08 02:52:25 UTC",
      "updated_date": "2025-05-18 14:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:57:37.389864"
    },
    {
      "arxiv_id": "2502.06866v2",
      "title": "Global Ease of Living Index: a machine learning framework for longitudinal analysis of major economies",
      "title_zh": "翻译失败",
      "authors": [
        "Tanay Panat",
        "Rohitash Chandra"
      ],
      "abstract": "The drastic changes in the global economy, geopolitical conditions, and\ndisruptions such as the COVID-19 pandemic have impacted the cost of living and\nquality of life. It is important to understand the long-term nature of the cost\nof living and quality of life in major economies. A transparent and\ncomprehensive living index must include multiple dimensions of living\nconditions. In this study, we present an approach to quantifying the quality of\nlife through the Global Ease of Living Index that combines various\nsocio-economic and infrastructural factors into a single composite score. Our\nindex utilises economic indicators that define living standards, which could\nhelp in targeted interventions to improve specific areas. We present a machine\nlearning framework for addressing the problem of missing data for some of the\neconomic indicators for specific countries. We then curate and update the data\nand use a dimensionality reduction approach (principal component analysis) to\ncreate the Ease of Living Index for major economies since 1970. Our work\nsignificantly adds to the literature by offering a practical tool for\npolicymakers to identify areas needing improvement, such as healthcare systems,\nemployment opportunities, and public safety. Our approach with open data and\ncode can be easily reproduced and applied to various contexts. This\ntransparency and accessibility make our work a valuable resource for ongoing\nresearch and policy development in quality-of-life assessment.",
      "tldr_zh": "本研究提出了一种机器 learning framework，用于构建 Global Ease of Living Index，以评估主要经济体从1970年起的长期生活质量。该指数整合了多种社会经济和基础设施因素，如经济指标和生活标准，通过处理缺失数据并采用 principal component analysis (PCA) 进行维度减少，生成一个综合评分。研究成果为政策制定者提供实用工具，帮助识别并改进特定领域，如医疗系统、就业机会和公共安全；此外，该框架使用开放数据和代码，确保易于复制和应用于其他情境。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "econ.EM",
        "stat.AP",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06866v2",
      "published_date": "2025-02-08 02:37:17 UTC",
      "updated_date": "2025-02-19 21:59:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:57:46.475651"
    },
    {
      "arxiv_id": "2502.05409v1",
      "title": "Vision-in-the-loop Simulation for Deep Monocular Pose Estimation of UAV in Ocean Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Maneesha Wickramasuriya",
        "Beomyeol Yu",
        "Taeyoung Lee",
        "Murray Snyder"
      ],
      "abstract": "This paper proposes a vision-in-the-loop simulation environment for deep\nmonocular pose estimation of a UAV operating in an ocean environment. Recently,\na deep neural network with a transformer architecture has been successfully\ntrained to estimate the pose of a UAV relative to the flight deck of a research\nvessel, overcoming several limitations of GPS-based approaches. However,\nvalidating the deep pose estimation scheme in an actual ocean environment poses\nsignificant challenges due to the limited availability of research vessels and\nthe associated operational costs. To address these issues, we present a\nphoto-realistic 3D virtual environment leveraging recent advancements in\nGaussian splatting, a novel technique that represents 3D scenes by modeling\nimage pixels as Gaussian distributions in 3D space, creating a lightweight and\nhigh-quality visual model from multiple viewpoints. This approach enables the\ncreation of a virtual environment integrating multiple real-world images\ncollected in situ. The resulting simulation enables the indoor testing of\nflight maneuvers while verifying all aspects of flight software, hardware, and\nthe deep monocular pose estimation scheme. This approach provides a\ncost-effective solution for testing and validating the autonomous flight of\nshipboard UAVs, specifically focusing on vision-based control and estimation\nalgorithms.",
      "tldr_zh": "本文提出了一种vision-in-the-loop模拟环境，用于测试UAV在海洋环境的deep monocular pose estimation。该方法利用Gaussian splatting技术创建photo-realistic 3D虚拟场景，将真实图像像素建模为3D空间中的Gaussian分布，从而实现轻量级、高质量的多视角整合。这种模拟环境允许在室内验证飞行软件、硬件和姿态估计方案，提供成本有效的解决方案，提升了舰载UAV的自主飞行和基于视觉的控制算法可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 15 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2502.05409v1",
      "published_date": "2025-02-08 02:19:42 UTC",
      "updated_date": "2025-02-08 02:19:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:57:59.237954"
    },
    {
      "arxiv_id": "2502.06864v1",
      "title": "Knowledge Graph-Guided Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangrong Zhu",
        "Yuexiang Xie",
        "Yi Liu",
        "Yaliang Li",
        "Wei Hu"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has emerged as a promising technology\nfor addressing hallucination issues in the responses generated by large\nlanguage models (LLMs). Existing studies on RAG primarily focus on applying\nsemantic-based approaches to retrieve isolated relevant chunks, which ignore\ntheir intrinsic relationships. In this paper, we propose a novel Knowledge\nGraph-Guided Retrieval Augmented Generation (KG$^2$RAG) framework that utilizes\nknowledge graphs (KGs) to provide fact-level relationships between chunks,\nimproving the diversity and coherence of the retrieved results. Specifically,\nafter performing a semantic-based retrieval to provide seed chunks, KG$^2$RAG\nemploys a KG-guided chunk expansion process and a KG-based chunk organization\nprocess to deliver relevant and important knowledge in well-organized\nparagraphs. Extensive experiments conducted on the HotpotQA dataset and its\nvariants demonstrate the advantages of KG$^2$RAG compared to existing RAG-based\napproaches, in terms of both response quality and retrieval quality.",
      "tldr_zh": "本研究针对检索增强生成（RAG）技术中存在的孤立块检索问题，提出了一种新框架Knowledge Graph-Guided Retrieval Augmented Generation (KG²RAG)，利用知识图谱（KGs）来捕捉块之间的事实级关系，从而提升生成响应的多样性和连贯性。具体而言，该框架先通过语义检索获取种子块，然后进行KG引导的块扩展和基于KG的块组织，以将相关知识结构化为段落。在HotpotQA数据集及其变体上的广泛实验表明，KG²RAG在响应质量和检索质量方面均优于现有RAG方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in the 2025 Annual Conference of the Nations of the Americas\n  Chapter of the ACL (NAACL 2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.06864v1",
      "published_date": "2025-02-08 02:14:31 UTC",
      "updated_date": "2025-02-08 02:14:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:58:10.747860"
    },
    {
      "arxiv_id": "2502.06863v1",
      "title": "BF-GAN: Development of an AI-driven Bubbly Flow Image Generation Model Using Generative Adversarial Networks",
      "title_zh": "BF-GAN：",
      "authors": [
        "Wen Zhou",
        "Shuichiro Miwa",
        "Yang Liu",
        "Koji Okamoto"
      ],
      "abstract": "A generative AI architecture called bubbly flow generative adversarial\nnetworks (BF-GAN) is developed, designed to generate realistic and high-quality\nbubbly flow images through physically conditioned inputs, jg and jf. Initially,\n52 sets of bubbly flow experiments under varying conditions are conducted to\ncollect 140,000 bubbly flow images with physical labels of jg and jf for\ntraining data. A multi-scale loss function is then developed, incorporating\nmismatch loss and pixel loss to enhance the generative performance of BF-GAN\nfurther. Regarding evaluative metrics of generative AI, the BF-GAN has\nsurpassed conventional GAN. Physically, key parameters of bubbly flow generated\nby BF-GAN are extracted and compared with measurement values and empirical\ncorrelations, validating BF-GAN's generative performance. The comparative\nanalysis demonstrate that the BF-GAN can generate realistic and high-quality\nbubbly flow images with any given jg and jf within the research scope.\n  BF-GAN offers a generative AI solution for two-phase flow research,\nsubstantially lowering the time and cost required to obtain high-quality data.\nIn addition, it can function as a benchmark dataset generator for bubbly flow\ndetection and segmentation algorithms, enhancing overall productivity in this\nresearch domain. The BF-GAN model is available online\n(https://github.com/zhouzhouwen/BF-GAN).",
      "tldr_zh": "本文开发了 BF-GAN，一种基于生成对抗网络(GAN)的 AI 模型，通过物理条件 jg 和 jf 生成真实、高质量的气泡流图像，以支持两相流研究。研究团队进行了 52 组实验，收集 14 万张带标签图像作为训练数据，并引入多尺度损失函数（包括 mismatch loss 和 pixel loss），显著提升了生成性能。实验结果显示，BF-GAN 在评估指标上超越传统 GAN，其生成的图像关键参数与实际测量和经验相关性一致。总之，该模型降低了获取高质量数据的成本和时间，并可作为基准数据集生成器，用于气泡流检测和分割算法的开发。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06863v1",
      "published_date": "2025-02-08 02:01:58 UTC",
      "updated_date": "2025-02-08 02:01:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:58:22.957098"
    },
    {
      "arxiv_id": "2502.05407v2",
      "title": "The Complexity of Learning Sparse Superposed Features with Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Akash Kumar"
      ],
      "abstract": "The success of deep networks is crucially attributed to their ability to\ncapture latent features within a representation space. In this work, we\ninvestigate whether the underlying learned features of a model can be\nefficiently retrieved through feedback from an agent, such as a large language\nmodel (LLM), in the form of relative \\textit{triplet comparisons}. These\nfeatures may represent various constructs, including dictionaries in LLMs or\ncomponents of a covariance matrix of Mahalanobis distances. We analyze the\nfeedback complexity associated with learning a feature matrix in sparse\nsettings. Our results establish tight bounds when the agent is permitted to\nconstruct activations and demonstrate strong upper bounds in sparse scenarios\nwhen the agent's feedback is limited to distributional information. We validate\nour theoretical findings through experiments on two distinct applications:\nfeature recovery from Recursive Feature Machine-trained models and dictionary\nextraction from sparse autoencoders trained on Large Language Models.",
      "tldr_zh": "本研究探讨了通过代理（如LLM）提供的反馈，例如相对三元组比较，来高效学习稀疏叠加特征（sparse superposed features）的复杂性。论文建立了在稀疏设置下学习特征矩阵的反馈复杂度的紧密边界，当代理允许构建激活时提供精确界限，并在代理反馈仅限于分布信息时给出强上界。实验验证了这些理论发现，包括从Recursive Feature Machine训练的模型中恢复特征，以及从训练在Large Language Models上的稀疏自动编码器（sparse autoencoders）中提取字典，从而证明了方法的实际可行性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "41 pages, 20 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.05407v2",
      "published_date": "2025-02-08 01:54:23 UTC",
      "updated_date": "2025-02-11 06:57:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:58:33.710848"
    },
    {
      "arxiv_id": "2502.05402v1",
      "title": "Convolutional Deep Colorization for Image Compression: A Color Grid Based Approach",
      "title_zh": "卷积深度着色用于图像压缩：一种基于颜色网格的方法",
      "authors": [
        "Ian Tassin",
        "Kristen Goebel",
        "Brittany Lasher"
      ],
      "abstract": "The search for image compression optimization techniques is a topic of\nconstant interest both in and out of academic circles. One method that shows\npromise toward future improvements in this field is image colorization since\nimage colorization algorithms can reduce the amount of color data that needs to\nbe stored for an image. Our work focuses on optimizing a color grid based\napproach to fully-automated image color information retention with regard to\nconvolutional colorization network architecture for the purposes of image\ncompression. More generally, using a convolutional neural network for image\nre-colorization, we want to minimize the amount of color information that is\nstored while still being able to faithfully re-color images. Our results\nyielded a promising image compression ratio, while still allowing for\nsuccessful image recolorization reaching high CSIM values.",
      "tldr_zh": "该论文探讨了图像压缩优化技术，通过图像着色算法减少存储的颜色数据。研究提出了一种基于 color grid 的方法，利用 convolutional neural network 架构进行全自动图像重新着色，从而最小化存储的颜色信息，同时确保图像忠实再现。实验结果显示，该方法实现了有前景的图像压缩比，并达到了高的 CSIM 值，证明了其在图像压缩领域的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05402v1",
      "published_date": "2025-02-08 01:26:05 UTC",
      "updated_date": "2025-02-08 01:26:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:58:45.508716"
    },
    {
      "arxiv_id": "2502.05398v2",
      "title": "Probabilistic Foundations for Metacognition via Hybrid-AI",
      "title_zh": "翻译失败",
      "authors": [
        "Paulo Shakarian",
        "Gerardo I. Simari",
        "Nathaniel D. Bastian"
      ],
      "abstract": "Metacognition is the concept of reasoning about an agent's own internal\nprocesses, and it has recently received renewed attention with respect to\nartificial intelligence (AI) and, more specifically, machine learning systems.\nThis paper reviews a hybrid-AI approach known as \"error detecting and\ncorrecting rules\" (EDCR) that allows for the learning of rules to correct\nperceptual (e.g., neural) models. Additionally, we introduce a probabilistic\nframework that adds rigor to prior empirical studies, and we use this framework\nto prove results on necessary and sufficient conditions for metacognitive\nimprovement, as well as limits to the approach. A set of future",
      "tldr_zh": "这篇论文探讨了通过Hybrid-AI建立Metacognition（元认知）的概率基础，Metacognition涉及代理对自身内部过程的推理。论文回顾了“error detecting and correcting rules”（EDCR）方法，该方法允许学习规则来修正感知模型（如神经网络）。此外，引入了一个概率框架来强化先前的实证研究，并证明了Metacognitive改进的必要和充分条件，以及方法的潜在限制，为AI系统的元认知能力提供了更严格的理论支撑。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to AAAI-MAKE 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.05398v2",
      "published_date": "2025-02-08 01:10:56 UTC",
      "updated_date": "2025-02-11 12:57:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:58:57.748578"
    },
    {
      "arxiv_id": "2502.05387v1",
      "title": "Coarse-to-Fine Structure-Aware Artistic Style Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Kunxiao Liu",
        "Guowu Yuan",
        "Hao Wu",
        "Wenhua Qian"
      ],
      "abstract": "Artistic style transfer aims to use a style image and a content image to\nsynthesize a target image that retains the same artistic expression as the\nstyle image while preserving the basic content of the content image. Many\nrecently proposed style transfer methods have a common problem; that is, they\nsimply transfer the texture and color of the style image to the global\nstructure of the content image. As a result, the content image has a local\nstructure that is not similar to the local structure of the style image. In\nthis paper, we present an effective method that can be used to transfer style\npatterns while fusing the local style structure into the local content\nstructure. In our method, dif-ferent levels of coarse stylized features are\nfirst reconstructed at low resolution using a Coarse Network, in which style\ncolor distribution is roughly transferred, and the content structure is\ncombined with the style structure. Then, the reconstructed features and the\ncontent features are adopted to synthesize high-quality structure-aware\nstylized images with high resolution using a Fine Network with three structural\nselective fusion (SSF) modules. The effectiveness of our method is demonstrated\nthrough the generation of appealing high-quality stylization results and a\ncom-parison with some state-of-the-art style transfer methods.",
      "tldr_zh": "本文提出了一种 Coarse-to-Fine 结构感知艺术风格迁移方法，旨在解决现有方法仅转移风格图像的纹理和颜色而忽略本地结构的问题，从而实现风格模式转移的同时融合本地风格结构到内容结构中。具体而言，该方法先使用 Coarse Network 在低分辨率下重建粗糙风格化特征，粗略转移风格颜色分布并结合内容和风格结构；然后，通过 Fine Network 和三个结构选择性融合 (SSF) 模块，在高分辨率下合成高质量的结构感知风格化图像。实验结果显示，该方法生成更吸引人的风格化结果，并优于现有最先进的技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.05387v1",
      "published_date": "2025-02-08 00:04:12 UTC",
      "updated_date": "2025-02-08 00:04:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:59:11.399387"
    },
    {
      "arxiv_id": "2502.06861v1",
      "title": "Design Considerations in Offline Preference-based RL",
      "title_zh": "翻译失败",
      "authors": [
        "Alekh Agarwal",
        "Christoph Dann",
        "Teodor V. Marinov"
      ],
      "abstract": "Offline algorithms for Reinforcement Learning from Human Preferences (RLHF),\nwhich use only a fixed dataset of sampled responses given an input, and\npreference feedback among these responses, have gained increasing prominence in\nthe literature on aligning language models. In this paper, we study how the\ndifferent design choices made in methods such as DPO, IPO, SLiC and many\nvariants influence the quality of the learned policy, from a theoretical\nperspective. Our treatment yields insights into the choices of loss function,\nthe policy which is used to normalize log-likelihoods, and also the role of the\ndata sampling policy. Notably, our results do not rely on the standard\nreparameterization-style arguments used to motivate some of the algorithms in\nthis family, which allows us to give a unified treatment to a broad class of\nmethods. We also conduct a small empirical study to verify some of the\ntheoretical findings on a standard summarization benchmark.",
      "tldr_zh": "本论文探讨了离线强化学习从人类偏好（RLHF）算法的设计考虑，这些算法仅基于固定数据集中的样本响应和偏好反馈。研究从理论角度分析了方法如 DPO、IPO、SLiC 及其变体的关键设计选择，包括损失函数、归一化 log-likelihood 的策略以及数据采样策略的作用，提供统一处理框架，而不依赖标准再参数化假设。通过小型实证研究，在标准摘要基准上验证了这些理论见解，提升了对学习策略质量的理解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06861v1",
      "published_date": "2025-02-08 00:01:37 UTC",
      "updated_date": "2025-02-08 00:01:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:59:21.670864"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 78,
  "processed_papers_count": 78,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T08:59:43.101634"
}