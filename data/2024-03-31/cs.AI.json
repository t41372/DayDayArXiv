{
  "date": "2024-03-31",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-31 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 46 篇论文，主要聚焦 AI 公平性、LLM 应用、生成模型和计算机视觉等领域，其中令人印象深刻的包括 CVPR 2024 相关作品（如 LiDAR 生成模型）和 LLM 代码生成优化，以及知名作者（如 Zichong Wang 和 Wenbin Zhang）的多篇调查性论文，强调了 AI 伦理、隐私和持续学习的挑战与创新。\n\n### 重点论文讨论\n我们先聊聊今天最引人注目的论文，包括与知名会议相关的、LLM 领域的热门话题，以及潜在影响大的工作。接下来，按主题归类快速概述其他论文。\n\n#### LLM 和 AI 伦理：公平性、版权和对齐问题\n这些论文探讨了 LLM 的核心挑战，如公平性、版权风险和模型对齐，作者 Zichong Wang 和 Wenbin Zhang 有多篇贡献，值得关注。\n- **Fairness in Large Language Models: A Taxonomic Survey**（LLM 公平性：一个分类调查）  \n  这篇调查论文分析了 LLM 中的偏置来源、公平评估指标和算法，涵盖了评估工具和数据集。主要贡献：提供了 LLM 公平性的全面框架，强调了减少对边缘群体歧视的必要性。\n- **Uncertain Boundaries: Multidisciplinary Approaches to Copyright Issues in Generative AI**（生成 AI 的版权问题：多学科方法）  \n  论文审查了生成 AI 中的版权侵权检测、保护技术和法规。主要发现：整合文本、图像和视频的检测方法，能帮助用户评估侵权风险，并讨论了 AI 法规的开放问题。\n- **Algorithmic Collusion by Large Language Models**（LLM 的算法性勾结）  \n  通过实验展示了 LLM 在定价中的潜在勾结行为（如寡头市场损害消费者）。主要贡献：揭示了 LLM 指令微调可能加剧勾结，并提出监管挑战。\n- **Extensive Self-Contrast Enables Feedback-Free Language Model Alignment**（广泛自对比实现无反馈 LLM 对齐）  \n  提出一种无反馈的自对比方法优化 LLM 对齐。主要发现：无需人工偏好数据，就能显著提升模型性能，适用于代码生成等任务。\n- **Comparing Bad Apples to Good Oranges: Aligning Large Language Models via Joint Preference Optimization**（通过联合偏好优化对齐 LLM）  \n  引入联合指令-响应偏好优化框架，提升 LLM 在摘要和对话中的鲁棒性。主要贡献：在标准方法基础上提升 5% 胜率，展示了更全面的偏好建模。\n\n这些工作突出了 LLM 在实际应用中的伦理风险和优化潜力，相关研究可能影响未来 AI 法规。\n\n#### 计算机视觉和生成模型：CVPR 等会议亮点\n今天有多个 CVPR 2024 和 ECCV 2024 论文，聚焦图像生成和 3D 任务，展示了生成模型的创新。\n- **Towards Realistic Scene Generation with LiDAR Diffusion Models**（实现真实场景的 LiDAR 扩散模型）  \n  提出 LiDMs 生成 LiDAR 场景，优化了几何和物体真实性（通过曲线压缩和点监督）。主要发现：在条件生成中比传统模型快 107 倍，并支持语义地图等控制。\n- **Privacy-preserving Optics for Enhancing Protection in Face De-identification**（隐私保护光学增强面部去识别）  \n  开发硬件级面部去识别方法，使用光学编码器生成匿名图像。主要贡献：结合热图和参考面部，提高隐私保护，适用于 CVPR 场景。\n- **DRCT: Saving Image Super-resolution away from Information Bottleneck**（DRCT：避免信息瓶颈的图像超分辨率）  \n  通过密集残差连接优化 Transformer 模型，避免特征衰减。主要发现：在基准数据集上超越 SOTA，提升图像重建质量。\n- **Learning to Generate Conditional Tri-plane for 3D-aware Expression Controllable Portrait Animation**（生成条件三平面用于 3D 表情可控人像动画）  \n  设计预训练框架生成 3D 人像动画，支持跨身份表情转移。主要贡献：无外观交换地实现表情控制，适用于 ECCV 任务。\n\n这些论文展示了生成模型在 3D 和隐私保护中的进步，CVPR 相关工作尤其有话题度。\n\n#### 其他领域亮点：持续学习和检索优化\n- **Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning**（解决持续学习中的可塑性丧失和灾难性遗忘）  \n  提出 UPGD 算法，通过梯度扰动平衡遗忘和可塑性。主要发现：在流式学习中超越现有方法，适用于 ICLR 基准。\n- **Generative Retrieval as Multi-Vector Dense Retrieval**（生成式检索作为多向量密集检索）  \n  证明生成检索等价于多向量密集检索框架，提升检索效率。主要贡献：分析注意力层，适用于 SIGIR 任务，如链接预测。\n- **WavLLM: Towards Robust and Adaptive Speech Large Language Model**（鲁棒的自适应语音 LLM）  \n  使用双编码器和 LoRA 适配器优化语音模型，支持多任务（ASR、SV 等）。主要发现：在 EMNLP 基准上提升泛化能力，实现语音 CoT 推理。\n\n### 快速掠过其他论文\n以下论文主题较分散，我们简要概述，聚焦核心贡献：\n- **HeteroMILE: a Multi-Level Graph Representation Learning Framework for Heterogeneous Graphs**（异构图的多级表示学习框架）  \n  提出多级嵌入框架，提升异构图嵌入效率，20 倍加速链接预测。\n- **The Larger the Better? Improved LLM Code-Generation via Budget Reallocation**（更大模型更好？通过预算重分配优化 LLM 代码生成）  \n  探索小模型重复使用策略，提升代码生成性能。\n- **EvoCodeBench: An Evolving Code Generation Benchmark Aligned with Real-World Code Repositories**（与真实仓库对齐的演化代码生成基准）  \n  构建动态基准测试 LLM 代码生成，主要用于评估泛化。\n- **A Review of Modern Recommender Systems Using Generative Models (Gen-RecSys)**（生成模型推荐系统的综述）  \n  调查生成模型在推荐中的应用，强调多模态整合。\n- **Benchmark Transparency: Measuring the Impact of Data on Evaluation**（基准透明度：评估数据影响）  \n  框架量化数据分布对 NLP 模型性能的影响，支持 NAACL 评估。\n- 其他如脑肿瘤检测、时间序列预测和电力网格攻击检测等论文（如 Automated Bi-Fold Weighted Ensemble Algorithms... 和 An Unsupervised Adversarial Autoencoder...），贡献在于应用特定领域模型，但影响力较小，我们仅提及其核心：前者提升了脑肿瘤分类准确性，后者检测了网络攻击。\n\n今天的 arXiv 论文总体上推动了 AI 的伦理和实用性，LLM 和视觉生成领域尤为活跃。感兴趣的读者可关注 CVPR/ICLR 等会议论文，深入探索这些创新！如果有特定主题，欢迎下次讨论。",
  "papers": [
    {
      "arxiv_id": "2404.01349v2",
      "title": "Fairness in Large Language Models: A Taxonomic Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Zhibo Chu",
        "Zichong Wang",
        "Wenbin Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable success across\nvarious domains. However, despite their promising performance in numerous\nreal-world applications, most of these algorithms lack fairness considerations.\nConsequently, they may lead to discriminatory outcomes against certain\ncommunities, particularly marginalized populations, prompting extensive study\nin fair LLMs. On the other hand, fairness in LLMs, in contrast to fairness in\ntraditional machine learning, entails exclusive backgrounds, taxonomies, and\nfulfillment techniques. To this end, this survey presents a comprehensive\noverview of recent advances in the existing literature concerning fair LLMs.\nSpecifically, a brief introduction to LLMs is provided, followed by an analysis\nof factors contributing to bias in LLMs. Additionally, the concept of fairness\nin LLMs is discussed categorically, summarizing metrics for evaluating bias in\nLLMs and existing algorithms for promoting fairness. Furthermore, resources for\nevaluating bias in LLMs, including toolkits and datasets, are summarized.\nFinally, existing research challenges and open questions are discussed.",
      "tldr_zh": "这篇论文对大型语言模型 (LLMs) 中的公平性问题进行了全面分类调查，强调了 LLMs 在实际应用中可能导致对边缘化群体的歧视，并分析了偏见 (bias) 的来源，如数据和模型设计问题。论文系统总结了评估 LLM 公平性的指标、促进公平的算法，以及相关的工具包和数据集资源，以帮助研究者识别和缓解偏见。最终，它指出了当前研究的挑战和开放问题，为未来公平 LLM 的发展提供了重要指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.01349v2",
      "published_date": "2024-03-31 22:22:53 UTC",
      "updated_date": "2024-12-19 05:05:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:25:04.980057"
    },
    {
      "arxiv_id": "2404.00816v1",
      "title": "HeteroMILE: a Multi-Level Graph Representation Learning Framework for Heterogeneous Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Zhang",
        "Yuntian He",
        "Saket Gurukar",
        "Srinivasan Parthasarathy"
      ],
      "abstract": "Heterogeneous graphs are ubiquitous in real-world applications because they\ncan represent various relationships between different types of entities.\nTherefore, learning embeddings in such graphs is a critical problem in graph\nmachine learning. However, existing solutions for this problem fail to scale to\nlarge heterogeneous graphs due to their high computational complexity. To\naddress this issue, we propose a Multi-Level Embedding framework of nodes on a\nheterogeneous graph (HeteroMILE) - a generic methodology that allows\ncontemporary graph embedding methods to scale to large graphs. HeteroMILE\nrepeatedly coarsens the large sized graph into a smaller size while preserving\nthe backbone structure of the graph before embedding it, effectively reducing\nthe computational cost by avoiding time-consuming processing operations. It\nthen refines the coarsened embedding to the original graph using a\nheterogeneous graph convolution neural network. We evaluate our approach using\nseveral popular heterogeneous graph datasets. The experimental results show\nthat HeteroMILE can substantially reduce computational time (approximately 20x\nspeedup) and generate an embedding of better quality for link prediction and\nnode classification.",
      "tldr_zh": "该研究针对异构图（Heterogeneous Graphs）的表示学习问题，提出了一种多级嵌入框架HeteroMILE，以解决现有方法在处理大型图时的计算复杂度高问题。HeteroMILE通过反复粗化图（coarsen the graph）来保留图的骨干结构，从而减少嵌入过程中的计算开销，并使用异构图卷积神经网络（heterogeneous graph convolution neural network）将粗化嵌入细化回原图。实验结果显示，该框架在多个异构图数据集上实现了约20倍的计算时间加速，同时为链接预测（link prediction）和节点分类（node classification）任务生成更高质量的嵌入。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00816v1",
      "published_date": "2024-03-31 22:22:10 UTC",
      "updated_date": "2024-03-31 22:22:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:25:18.146715"
    },
    {
      "arxiv_id": "2404.00815v2",
      "title": "Towards Realistic Scene Generation with LiDAR Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haoxi Ran",
        "Vitor Guizilini",
        "Yue Wang"
      ],
      "abstract": "Diffusion models (DMs) excel in photo-realistic image synthesis, but their\nadaptation to LiDAR scene generation poses a substantial hurdle. This is\nprimarily because DMs operating in the point space struggle to preserve the\ncurve-like patterns and 3D geometry of LiDAR scenes, which consumes much of\ntheir representation power. In this paper, we propose LiDAR Diffusion Models\n(LiDMs) to generate LiDAR-realistic scenes from a latent space tailored to\ncapture the realism of LiDAR scenes by incorporating geometric priors into the\nlearning pipeline. Our method targets three major desiderata: pattern realism,\ngeometry realism, and object realism. Specifically, we introduce curve-wise\ncompression to simulate real-world LiDAR patterns, point-wise coordinate\nsupervision to learn scene geometry, and patch-wise encoding for a full 3D\nobject context. With these three core designs, our method achieves competitive\nperformance on unconditional LiDAR generation in 64-beam scenario and state of\nthe art on conditional LiDAR generation, while maintaining high efficiency\ncompared to point-based DMs (up to 107$\\times$ faster). Furthermore, by\ncompressing LiDAR scenes into a latent space, we enable the controllability of\nDMs with various conditions such as semantic maps, camera views, and text\nprompts.",
      "tldr_zh": "这篇论文提出 LiDAR Diffusion Models (LiDMs)，通过在潜在空间中融入几何先验来生成更真实的 LiDAR 场景，解决传统扩散模型在点空间中难以保留曲线模式和 3D 几何的问题。LiDMs 的核心方法包括 curve-wise compression 用于模拟真实 LiDAR 模式、point-wise coordinate supervision 用于学习场景几何，以及 patch-wise encoding 用于提供完整的 3D 对象上下文。实验结果显示，该模型在 64-beam 无条件生成中表现出竞争性表现，在条件生成中达到最先进水平，比点-based DMs 快 107 倍，并支持语义地图、相机视图和文本提示等控制。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024. Project link: https://lidar-diffusion.github.io",
      "pdf_url": "http://arxiv.org/pdf/2404.00815v2",
      "published_date": "2024-03-31 22:18:56 UTC",
      "updated_date": "2024-04-18 19:22:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:25:31.546813"
    },
    {
      "arxiv_id": "2404.08221v1",
      "title": "Uncertain Boundaries: Multidisciplinary Approaches to Copyright Issues in Generative AI",
      "title_zh": "不确定边界：多学科方法应对生成式 AI 中的版权问题",
      "authors": [
        "Jocelyn Dzuong",
        "Zichong Wang",
        "Wenbin Zhang"
      ],
      "abstract": "In the rapidly evolving landscape of generative artificial intelligence (AI),\nthe increasingly pertinent issue of copyright infringement arises as AI\nadvances to generate content from scraped copyrighted data, prompting questions\nabout ownership and protection that impact professionals across various\ncareers. With this in mind, this survey provides an extensive examination of\ncopyright infringement as it pertains to generative AI, aiming to stay abreast\nof the latest developments and open problems. Specifically, it will first\noutline methods of detecting copyright infringement in mediums such as text,\nimage, and video. Next, it will delve an exploration of existing techniques\naimed at safeguarding copyrighted works from generative models. Furthermore,\nthis survey will discuss resources and tools for users to evaluate copyright\nviolations. Finally, insights into ongoing regulations and proposals for AI\nwill be explored and compared. Through combining these disciplines, the\nimplications of AI-driven content and copyright are thoroughly illustrated and\nbrought into question.",
      "tldr_zh": "这篇论文针对生成式AI中版权侵权问题进行了全面调查，探讨了AI从版权数据生成内容所引发的所有权和保护挑战。论文首先概述了检测版权侵权的多种方法，包括文本、图像和视频领域；其次，探讨了保护版权作品免受生成模型侵害的技术，以及用户评估违规的资源和工具。最后，通过多学科整合，论文比较了当前的AI法规和提案，强调了AI驱动内容对版权的深远影响和开放问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08221v1",
      "published_date": "2024-03-31 22:10:01 UTC",
      "updated_date": "2024-03-31 22:10:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:25:42.142954"
    },
    {
      "arxiv_id": "2404.00806v2",
      "title": "Algorithmic Collusion by Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Fish",
        "Yannai A. Gonczarowski",
        "Ran I. Shorrer"
      ],
      "abstract": "The rise of algorithmic pricing raises concerns of algorithmic collusion. We\nconduct experiments with algorithmic pricing agents based on Large Language\nModels (LLMs). We find that (1) LLM-based agents are adept at pricing tasks,\n(2) LLM-based pricing agents autonomously collude in oligopoly settings to the\ndetriment of consumers, and (3) variation in seemingly innocuous phrases in LLM\ninstructions (\"prompts\") may increase collusion. Novel off-path analysis\ntechniques uncover price-war concerns as contributing to these phenomena. Our\nresults extend to auction settings. Our findings uncover unique challenges to\nany future regulation of LLM-based pricing agents, and black-box pricing agents\nmore broadly.",
      "tldr_zh": "本研究通过实验评估基于 Large Language Models (LLMs) 的算法定价代理，发现这些代理在定价任务上表现出色，并能在寡头垄断环境中自主进行算法勾结，从而损害消费者利益。研究进一步揭示，LLM 指令中的细微提示变化（如无害短语）可能加剧勾结行为，而采用新型 off-path 分析技术确认价格战担忧是关键原因。这些发现扩展到拍卖场景，并强调了对 LLM-based 定价代理及其监管的独特挑战。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.GT",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00806v2",
      "published_date": "2024-03-31 21:43:05 UTC",
      "updated_date": "2024-11-27 00:19:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:25:54.313709"
    },
    {
      "arxiv_id": "2404.00781v2",
      "title": "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Elsayed",
        "A. Rupam Mahmood"
      ],
      "abstract": "Deep representation learning methods struggle with continual learning,\nsuffering from both catastrophic forgetting of useful units and loss of\nplasticity, often due to rigid and unuseful units. While many methods address\nthese two issues separately, only a few currently deal with both\nsimultaneously. In this paper, we introduce Utility-based Perturbed Gradient\nDescent (UPGD) as a novel approach for the continual learning of\nrepresentations. UPGD combines gradient updates with perturbations, where it\napplies smaller modifications to more useful units, protecting them from\nforgetting, and larger modifications to less useful units, rejuvenating their\nplasticity. We use a challenging streaming learning setup where continual\nlearning problems have hundreds of non-stationarities and unknown task\nboundaries. We show that many existing methods suffer from at least one of the\nissues, predominantly manifested by their decreasing accuracy over tasks. On\nthe other hand, UPGD continues to improve performance and surpasses or is\ncompetitive with all methods in all problems. Finally, in extended\nreinforcement learning experiments with PPO, we show that while Adam exhibits a\nperformance drop after initial learning, UPGD avoids it by addressing both\ncontinual learning issues.",
      "tldr_zh": "该论文针对深度表示学习在持续学习（continual learning）中的灾难性遗忘（catastrophic forgetting）和塑性丧失（loss of plasticity）问题，提出了一种新方法Utility-based Perturbed Gradient Descent (UPGD)。UPGD结合梯度更新和扰动，对有用单位施加较小修改以保护记忆，对无用单位施加较大修改以恢复塑性，从而同时解决这两个问题。在挑战性的流式学习（streaming learning）设置中，实验显示UPGD持续提升性能，并在所有任务上优于或与现有方法持平。此外，在强化学习实验中使用PPO时，UPGD避免了Adam的性能下降，证明了其在处理持续学习问题的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the Proceedings of the 12th International Conference on\n  Learning Representations (ICLR 2024). Code is available at\n  https://github.com/mohmdelsayed/upgd",
      "pdf_url": "http://arxiv.org/pdf/2404.00781v2",
      "published_date": "2024-03-31 19:57:38 UTC",
      "updated_date": "2024-04-30 22:52:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:26:07.620191"
    },
    {
      "arxiv_id": "2404.00777v1",
      "title": "Privacy-preserving Optics for Enhancing Protection in Face De-identification",
      "title_zh": "隐私保护光学用于增强面部去标识化中的保护",
      "authors": [
        "Jhon Lopez",
        "Carlos Hinojosa",
        "Henry Arguello",
        "Bernard Ghanem"
      ],
      "abstract": "The modern surge in camera usage alongside widespread computer vision\ntechnology applications poses significant privacy and security concerns.\nCurrent artificial intelligence (AI) technologies aid in recognizing relevant\nevents and assisting in daily tasks in homes, offices, hospitals, etc. The need\nto access or process personal information for these purposes raises privacy\nconcerns. While software-level solutions like face de-identification provide a\ngood privacy/utility trade-off, they present vulnerabilities to sniffing\nattacks. In this paper, we propose a hardware-level face de-identification\nmethod to solve this vulnerability. Specifically, our approach first learns an\noptical encoder along with a regression model to obtain a face heatmap while\nhiding the face identity from the source image. We also propose an\nanonymization framework that generates a new face using the privacy-preserving\nimage, face heatmap, and a reference face image from a public dataset as input.\nWe validate our approach with extensive simulations and hardware experiments.",
      "tldr_zh": "该论文针对相机和计算机视觉技术普及引发的隐私问题，提出了一种硬件级别的面部去识别（face de-identification）方法，以抵御嗅探攻击。方法包括学习一个光学编码器（optical encoder）与回归模型，从源图像中提取面部热图（face heatmap）并隐藏身份；同时，开发了一个匿名化框架（anonymization framework），利用隐私保护图像、面部热图和参考面部图像生成新面部。实验通过广泛的模拟和硬件测试验证了该方法的有效性，提供更好的隐私与实用性平衡。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR 2024. Project Website and Code coming soon",
      "pdf_url": "http://arxiv.org/pdf/2404.00777v1",
      "published_date": "2024-03-31 19:28:04 UTC",
      "updated_date": "2024-03-31 19:28:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:26:18.312811"
    },
    {
      "arxiv_id": "2404.00756v1",
      "title": "Recover: A Neuro-Symbolic Framework for Failure Detection and Recovery",
      "title_zh": "Recover：一种神经符号框架，用于故障检测和恢复",
      "authors": [
        "Cristina Cornelio",
        "Mohammed Diab"
      ],
      "abstract": "Recognizing failures during task execution and implementing recovery\nprocedures is challenging in robotics. Traditional approaches rely on the\navailability of extensive data or a tight set of constraints, while more recent\napproaches leverage large language models (LLMs) to verify task steps and\nreplan accordingly. However, these methods often operate offline, necessitating\nscene resets and incurring in high costs. This paper introduces Recover, a\nneuro-symbolic framework for online failure identification and recovery. By\nintegrating ontologies, logical rules, and LLM-based planners, Recover exploits\nsymbolic information to enhance the ability of LLMs to generate recovery plans\nand also to decrease the associated costs. In order to demonstrate the\ncapabilities of our method in a simulated kitchen environment, we introduce\nOntoThor, an ontology describing the AI2Thor simulator setting. Empirical\nevaluation shows that OntoThor's logical rules accurately detect all failures\nin the analyzed tasks, and that Recover considerably outperforms, for both\nfailure detection and recovery, a baseline method reliant solely on LLMs.",
      "tldr_zh": "该论文提出Recover，一种神经符号框架，用于机器人任务中的在线故障检测和恢复，解决了传统方法依赖大量数据或约束，以及基于LLMs的方法需离线操作和高成本的问题。该框架整合ontologies（本体）、logical rules（逻辑规则）和LLM-based planners（基于LLMs的规划器），利用符号信息增强LLMs生成恢复计划的能力。在模拟厨房环境中，通过引入OntoThor本体，实验结果显示Recover的逻辑规则准确检测所有故障，并在故障检测和恢复方面显著优于仅依赖LLMs的基线方法。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00756v1",
      "published_date": "2024-03-31 17:54:22 UTC",
      "updated_date": "2024-03-31 17:54:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:26:29.479886"
    },
    {
      "arxiv_id": "2404.00752v1",
      "title": "On the True Distribution Approximation of Minimum Bayes-Risk Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Atsumoto Ohashi",
        "Ukyo Honda",
        "Tetsuro Morimura",
        "Yuu Jinnai"
      ],
      "abstract": "Minimum Bayes-risk (MBR) decoding has recently gained renewed attention in\ntext generation. MBR decoding considers texts sampled from a model as\npseudo-references and selects the text with the highest similarity to the\nothers. Therefore, sampling is one of the key elements of MBR decoding, and\nprevious studies reported that the performance varies by sampling methods. From\na theoretical standpoint, this performance variation is likely tied to how\nclosely the samples approximate the true distribution of references. However,\nthis approximation has not been the subject of in-depth study. In this study,\nwe propose using anomaly detection to measure the degree of approximation. We\nfirst closely examine the performance variation and then show that previous\nhypotheses about samples do not correlate well with the variation, but our\nintroduced anomaly scores do. The results are the first to empirically support\nthe link between the performance and the core assumption of MBR decoding.",
      "tldr_zh": "本研究探讨了 Minimum Bayes-Risk (MBR) decoding 在文本生成中的性能问题，强调采样方法如何影响输出，因为采样质量直接关系到样本对真实参考分布的逼近。作者提出使用 anomaly detection 来量化这种逼近程度，并通过实验验证了性能变化与之前假设的相关性较低，但与引入的 anomaly scores 高度相关。该发现首次提供了经验证据，支持 MBR decoding 核心假设与实际性能之间的联系，为改进文本生成采样策略提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2024 (main conference)",
      "pdf_url": "http://arxiv.org/pdf/2404.00752v1",
      "published_date": "2024-03-31 17:47:22 UTC",
      "updated_date": "2024-03-31 17:47:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:26:42.024979"
    },
    {
      "arxiv_id": "2404.00748v1",
      "title": "Benchmark Transparency: Measuring the Impact of Data on Evaluation",
      "title_zh": "基准透明度：测量数据对评估的影响",
      "authors": [
        "Venelin Kovatchev",
        "Matthew Lease"
      ],
      "abstract": "In this paper we present an exploratory research on quantifying the impact\nthat data distribution has on the performance and evaluation of NLP models. We\npropose an automated framework that measures the data point distribution across\n6 different dimensions: ambiguity, difficulty, discriminability, length, noise,\nand perplexity.\n  We use disproportional stratified sampling to measure how much the data\ndistribution affects absolute (Acc/F1) and relative (Rank) model performance.\nWe experiment on 2 different datasets (SQUAD and MNLI) and test a total of 135\ndifferent models (125 on SQUAD and 10 on MNLI). We demonstrate that without\nexplicit control of the data distribution, standard evaluation frameworks are\ninconsistent and unreliable. We find that the impact of the data is\nstatistically significant and is often larger than the impact of changing the\nmetric.\n  In a second set of experiments, we demonstrate that the impact of data on\nevaluation is not just observable, but also predictable. We propose to use\nbenchmark transparency as a method for comparing datasets and quantifying the\nsimilarity between them. We find that the ``dataset similarity vector'' can be\nused to predict how well a model generalizes out of distribution.",
      "tldr_zh": "这篇论文探讨了数据分布对 NLP 模型性能评估的影响，提出一个自动化框架来量化数据点在 ambiguity、difficulty、discriminability、length、noise 和 perplexity 等 6 个维度的分布。\n通过 disproportional stratified sampling 在 SQUAD 和 MNLI 数据集上测试 135 个模型，研究发现数据分布对模型的绝对性能 (Acc/F1) 和相对性能 (Rank) 有显著影响，且其影响往往大于改变评估指标。\n论文进一步证明这种影响是可预测的，并引入 benchmark transparency 方法，使用 “dataset similarity vector” 来比较数据集并预测模型的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.00748v1",
      "published_date": "2024-03-31 17:33:43 UTC",
      "updated_date": "2024-03-31 17:33:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:26:55.114923"
    },
    {
      "arxiv_id": "2404.00746v1",
      "title": "Mining Weighted Sequential Patterns in Incremental Uncertain Databases",
      "title_zh": "翻译失败",
      "authors": [
        "Kashob Kumar Roy",
        "Md Hasibul Haque Moon",
        "Md Mahmudur Rahman",
        "Chowdhury Farhan Ahmed",
        "Carson Kai-Sang Leung"
      ],
      "abstract": "Due to the rapid development of science and technology, the importance of\nimprecise, noisy, and uncertain data is increasing at an exponential rate.\nThus, mining patterns in uncertain databases have drawn the attention of\nresearchers. Moreover, frequent sequences of items from these databases need to\nbe discovered for meaningful knowledge with great impact. In many real cases,\nweights of items and patterns are introduced to find interesting sequences as a\nmeasure of importance. Hence, a constraint of weight needs to be handled while\nmining sequential patterns. Besides, due to the dynamic nature of databases,\nmining important information has become more challenging. Instead of mining\npatterns from scratch after each increment, incremental mining algorithms\nutilize previously mined information to update the result immediately. Several\nalgorithms exist to mine frequent patterns and weighted sequences from\nincremental databases. However, these algorithms are confined to mine the\nprecise ones. Therefore, we have developed an algorithm to mine frequent\nsequences in an uncertain database in this work. Furthermore, we have proposed\ntwo new techniques for mining when the database is incremental. Extensive\nexperiments have been conducted for performance evaluation. The analysis showed\nthe efficiency of our proposed framework.",
      "tldr_zh": "本研究探讨了在不确定数据库中挖掘加权序列模式（weighted sequential patterns）的挑战，特别是在数据库动态增量的情况下。作者开发了一个新算法，用于从 imprecise、noisy 和 uncertain 数据中发现频繁序列，同时考虑项的权重作为重要性指标。该算法还引入了两种新技巧，以利用先前挖掘的信息进行增量更新，避免从零开始重新计算。实验结果显示，该框架在性能上表现出高效优势，证明了其在处理实时数据场景中的实用性。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "Accepted to Information Science journal",
      "pdf_url": "http://arxiv.org/pdf/2404.00746v1",
      "published_date": "2024-03-31 17:32:08 UTC",
      "updated_date": "2024-03-31 17:32:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:27:07.311761"
    },
    {
      "arxiv_id": "2404.00725v2",
      "title": "The Larger the Better? Improved LLM Code-Generation via Budget Reallocation",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Hassid",
        "Tal Remez",
        "Jonas Gehring",
        "Roy Schwartz",
        "Yossi Adi"
      ],
      "abstract": "It is a common belief that large language models (LLMs) are better than\nsmaller-sized ones. However, larger models also require significantly more time\nand compute during inference. This begs the question: what happens when both\nmodels operate under the same budget? (e.g., compute, run-time). To address\nthis question, we analyze code generation LLMs of various sizes and make\ncomparisons such as running a 70B model once vs. generating five outputs from a\n13B model. We consider a standard unit-test setup, which can be used to select\nthe correct output from the smaller model. Our findings reveal that the\nrepeated use of smaller models can yield consistent improvements, with gains of\nup to 15% across five tasks. On the other hand, in scenarios where unit-tests\nare unavailable, a ranking-based selection of candidates from the smaller model\nfalls short of the performance of a single output from larger ones. Our results\nhighlight the potential of using smaller models instead of larger ones, and the\nimportance of studying approaches for ranking LLM outputs.",
      "tldr_zh": "该研究质疑了更大LLMs（Large Language Models）在代码生成任务中是否总是优于小模型，重点探讨了在相同预算（如计算资源或运行时间）下的表现。作者通过比较策略，例如运行一次70B模型与从13B模型生成五次输出，并利用标准单元测试选择最佳输出，发现重复使用小模型可带来高达15%的性能提升，在五个任务上均有改善。然而，在缺少单元测试的场景中，基于排名的输出选择方法不如大模型的单一输出有效。该工作突出了小模型潜力的重要性，并强调了研究LLM输出排名方法的需求。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.00725v2",
      "published_date": "2024-03-31 15:55:49 UTC",
      "updated_date": "2024-07-25 11:37:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:27:20.497711"
    },
    {
      "arxiv_id": "2404.00722v5",
      "title": "DRCT: Saving Image Super-resolution away from Information Bottleneck",
      "title_zh": "翻译失败",
      "authors": [
        "Chih-Chung Hsu",
        "Chia-Ming Lee",
        "Yi-Shiuan Chou"
      ],
      "abstract": "In recent years, Vision Transformer-based approaches for low-level vision\ntasks have achieved widespread success. Unlike CNN-based models, Transformers\nare more adept at capturing long-range dependencies, enabling the\nreconstruction of images utilizing non-local information. In the domain of\nsuper-resolution, Swin-transformer-based models have become mainstream due to\ntheir capability of global spatial information modeling and their\nshifting-window attention mechanism that facilitates the interchange of\ninformation between different windows. Many researchers have enhanced model\nperformance by expanding the receptive fields or designing meticulous networks,\nyielding commendable results. However, we observed that it is a general\nphenomenon for the feature map intensity to be abruptly suppressed to small\nvalues towards the network's end. This implies an information bottleneck and a\ndiminishment of spatial information, implicitly limiting the model's potential.\nTo address this, we propose the Dense-residual-connected Transformer (DRCT),\naimed at mitigating the loss of spatial information and stabilizing the\ninformation flow through dense-residual connections between layers, thereby\nunleashing the model's potential and saving the model away from information\nbottleneck. Experiment results indicate that our approach surpasses\nstate-of-the-art methods on benchmark datasets and performs commendably at the\nNTIRE-2024 Image Super-Resolution (x4) Challenge. Our source code is available\nat https://github.com/ming053l/DRCT",
      "tldr_zh": "本研究发现，Vision Transformer-based 模型在图像超分辨率任务中虽擅长捕捉长距离依赖，但常因特征图强度在网络末端被抑制而导致信息瓶颈和空间信息损失。针对此问题，作者提出 Dense-residual-connected Transformer (DRCT)，通过密集残差连接稳定信息流并缓解空间信息丢失，从而提升模型性能。实验结果显示，DRCT 在基准数据集上超越了最先进方法，并在 NTIRE-2024 Image Super-Resolution (x4) 挑战赛中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPRW2024, NTIRE Image Super-resolution (x4)",
      "pdf_url": "http://arxiv.org/pdf/2404.00722v5",
      "published_date": "2024-03-31 15:34:45 UTC",
      "updated_date": "2024-11-23 18:11:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:27:30.804121"
    },
    {
      "arxiv_id": "2404.00712v2",
      "title": "Survey of Computerized Adaptive Testing: A Machine Learning Perspective",
      "title_zh": "计算机化自适应测试的综述：机器学习视角",
      "authors": [
        "Qi Liu",
        "Yan Zhuang",
        "Haoyang Bi",
        "Zhenya Huang",
        "Weizhe Huang",
        "Jiatong Li",
        "Junhao Yu",
        "Zirui Liu",
        "Zirui Hu",
        "Yuting Hong",
        "Zachary A. Pardos",
        "Haiping Ma",
        "Mengxiao Zhu",
        "Shijin Wang",
        "Enhong Chen"
      ],
      "abstract": "Computerized Adaptive Testing (CAT) provides an efficient and tailored method\nfor assessing the proficiency of examinees, by dynamically adjusting test\nquestions based on their performance. Widely adopted across diverse fields like\neducation, healthcare, sports, and sociology, CAT has revolutionized testing\npractices. While traditional methods rely on psychometrics and statistics, the\nincreasing complexity of large-scale testing has spurred the integration of\nmachine learning techniques. This paper aims to provide a machine\nlearning-focused survey on CAT, presenting a fresh perspective on this adaptive\ntesting method. By examining the test question selection algorithm at the heart\nof CAT's adaptivity, we shed light on its functionality. Furthermore, we delve\ninto cognitive diagnosis models, question bank construction, and test control\nwithin CAT, exploring how machine learning can optimize these components.\nThrough an analysis of current methods, strengths, limitations, and challenges,\nwe strive to develop robust, fair, and efficient CAT systems. By bridging\npsychometric-driven CAT research with machine learning, this survey advocates\nfor a more inclusive and interdisciplinary approach to the future of adaptive\ntesting.",
      "tldr_zh": "这篇论文从机器学习视角审视 Computerized Adaptive Testing (CAT)，一种动态调整测试问题的个性化评估方法，广泛应用于教育、医疗等领域。作者探讨了机器学习在测试问题选择算法、认知诊断模型、题库构建和测试控制等方面的优化应用，分析了这些方法的优势、局限性及挑战。最终，论文倡导桥接传统心理测量与机器学习，实现更健壮、公平和高效的 CAT 系统，推动跨学科的适应性测试创新。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00712v2",
      "published_date": "2024-03-31 15:09:47 UTC",
      "updated_date": "2024-04-05 02:18:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:27:44.478955"
    },
    {
      "arxiv_id": "2404.07227v4",
      "title": "Is Complexity an Illusion?",
      "title_zh": "复杂性是一种幻觉吗？",
      "authors": [
        "Michael Timothy Bennett"
      ],
      "abstract": "Simplicity is held by many to be the key to general intelligence. Simpler\nmodels tend to \"generalise\", identifying the cause or generator of data with\ngreater sample efficiency. The implications of the correlation between\nsimplicity and generalisation extend far beyond computer science, addressing\nquestions of physics and even biology. Yet simplicity is a property of form,\nwhile generalisation is of function. In interactive settings, any correlation\nbetween the two depends on interpretation. In theory there could be no\ncorrelation and yet in practice, there is. Previous theoretical work showed\ngeneralisation to be a consequence of \"weak\" constraints implied by function,\nnot form. Experiments demonstrated choosing weak constraints over simple forms\nyielded a 110-500% improvement in generalisation rate. Here we show that all\nconstraints can take equally simple forms, regardless of weakness. However if\nforms are spatially extended, then function is represented using a finite\nsubset of forms. If function is represented using a finite subset of forms,\nthen we can force a correlation between simplicity and generalisation by making\nweak constraints take simple forms. If function is determined by a goal\ndirected process that favours versatility (e.g. natural selection), then\nefficiency demands weak constraints take simple forms. Complexity has no causal\ninfluence on generalisation, but appears to due to confounding.",
      "tldr_zh": "这篇论文探讨了简洁性与泛化的关系，论证复杂性（Complexity）是否对一般智能的泛化（Generalisation）产生真实影响。作者分析了简洁作为形式的属性，而泛化作为功能的属性，指出之前的实验显示选择弱约束（Weak constraints）而非简单形式可提高110-500%的泛化率。论文进一步证明，所有约束均可采用同样简单的形式，但如果功能使用有限形式的子集，则可以通过让弱约束取简单形式来强制简洁与泛化的相关性。最终，研究结论是复杂性对泛化没有因果影响，而是由于混杂因素（如目标导向过程的效率需求）所致。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication in the Proceedings of the 17th Conference on\n  Artificial General Intelligence, 2024. Definitions shared with\n  arXiv:2302.00843",
      "pdf_url": "http://arxiv.org/pdf/2404.07227v4",
      "published_date": "2024-03-31 13:36:55 UTC",
      "updated_date": "2024-05-30 13:38:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:27:57.656889"
    },
    {
      "arxiv_id": "2404.00685v2",
      "title": "Scaling Properties of Speech Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Santiago Cuervo",
        "Ricard Marxer"
      ],
      "abstract": "Speech Language Models (SLMs) aim to learn language from raw audio, without\ntextual resources. Despite significant advances, our current models exhibit\nweak syntax and semantic abilities. However, if the scaling properties of\nneural language models hold for the speech modality, these abilities will\nimprove as the amount of compute used for training increases. In this paper, we\nuse models of this scaling behavior to estimate the scale at which our current\nmethods will yield a SLM with the English proficiency of text-based Large\nLanguage Models (LLMs). We establish a strong correlation between pre-training\nloss and downstream syntactic and semantic performance in SLMs and LLMs, which\nresults in predictable scaling of linguistic performance. We show that the\nlinguistic performance of SLMs scales up to three orders of magnitude more\nslowly than that of text-based LLMs. Additionally, we study the benefits of\nsynthetic data designed to boost semantic understanding and the effects of\ncoarser speech tokenization.",
      "tldr_zh": "这篇论文探讨了Speech Language Models (SLMs) 的缩放属性，这些模型旨在从原始音频学习语言，而非依赖文本资源。研究者通过建立预训练损失与下游语法和语义性能之间的强相关性，预测了SLMs 需要多大规模的计算资源才能达到基于文本的Large Language Models (LLMs) 的英语熟练度水平。结果显示，SLMs 的语言性能缩放速度比LLMs 慢三个数量级，同时，合成数据可提升语义理解，而更粗糙的语音标记化也带来潜在益处。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.NE"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00685v2",
      "published_date": "2024-03-31 13:30:12 UTC",
      "updated_date": "2024-04-16 06:46:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:28:09.302763"
    },
    {
      "arxiv_id": "2404.00684v1",
      "title": "Generative Retrieval as Multi-Vector Dense Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Shiguang Wu",
        "Wenda Wei",
        "Mengqi Zhang",
        "Zhumin Chen",
        "Jun Ma",
        "Zhaochun Ren",
        "Maarten de Rijke",
        "Pengjie Ren"
      ],
      "abstract": "Generative retrieval generates identifiers of relevant documents in an\nend-to-end manner using a sequence-to-sequence architecture for a given query.\nThe relation between generative retrieval and other retrieval methods,\nespecially those based on matching within dense retrieval models, is not yet\nfully comprehended. Prior work has demonstrated that generative retrieval with\natomic identifiers is equivalent to single-vector dense retrieval. Accordingly,\ngenerative retrieval exhibits behavior analogous to hierarchical search within\na tree index in dense retrieval when using hierarchical semantic identifiers.\nHowever, prior work focuses solely on the retrieval stage without considering\nthe deep interactions within the decoder of generative retrieval.\n  In this paper, we fill this gap by demonstrating that generative retrieval\nand multi-vector dense retrieval share the same framework for measuring the\nrelevance to a query of a document. Specifically, we examine the attention\nlayer and prediction head of generative retrieval, revealing that generative\nretrieval can be understood as a special case of multi-vector dense retrieval.\nBoth methods compute relevance as a sum of products of query and document\nvectors and an alignment matrix. We then explore how generative retrieval\napplies this framework, employing distinct strategies for computing document\ntoken vectors and the alignment matrix. We have conducted experiments to verify\nour conclusions and show that both paradigms exhibit commonalities of term\nmatching in their alignment matrix.",
      "tldr_zh": "本研究探讨了生成式检索（Generative Retrieval）与多向量密集检索（Multi-Vector Dense Retrieval）的关系，证明两者在衡量查询和文档相关性时采用相同的框架。作者通过分析生成式检索的注意力层（attention layer）和预测头（prediction head），揭示生成式检索可以视为多向量密集检索的特例，两者均通过查询和文档向量的点积和以及对齐矩阵（alignment matrix）来计算相关性。实验验证了这一等价性，并展示了在对齐矩阵中都存在术语匹配的共同行为，为理解不同检索范式提供了新洞见。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "12 pages, 5 figures, 8 tables, accepted at SIGIR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.00684v1",
      "published_date": "2024-03-31 13:29:43 UTC",
      "updated_date": "2024-03-31 13:29:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:28:21.030738"
    },
    {
      "arxiv_id": "2404.00675v3",
      "title": "LLM meets Vision-Language Models for Zero-Shot One-Class Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Yassir Bendou",
        "Giulia Lioi",
        "Bastien Pasdeloup",
        "Lukas Mauch",
        "Ghouthi Boukli Hacene",
        "Fabien Cardinaux",
        "Vincent Gripon"
      ],
      "abstract": "We consider the problem of zero-shot one-class visual classification,\nextending traditional one-class classification to scenarios where only the\nlabel of the target class is available. This method aims to discriminate\nbetween positive and negative query samples without requiring examples from the\ntarget class. We propose a two-step solution that first queries large language\nmodels for visually confusing objects and then relies on vision-language\npre-trained models (e.g., CLIP) to perform classification. By adapting\nlarge-scale vision benchmarks, we demonstrate the ability of the proposed\nmethod to outperform adapted off-the-shelf alternatives in this setting.\nNamely, we propose a realistic benchmark where negative query samples are drawn\nfrom the same original dataset as positive ones, including a\ngranularity-controlled version of iNaturalist, where negative samples are at a\nfixed distance in the taxonomy tree from the positive ones. To our knowledge,\nwe are the first to demonstrate the ability to discriminate a single category\nfrom other semantically related ones using only its label.",
      "tldr_zh": "本研究探讨了零-shot one-class classification问题，即仅通过目标类的标签（而非样本）来区分正负样本。研究提出了一种两步方法：首先利用大型语言模型（LLMs）查询视觉上混淆的对象，其次使用视觉语言预训练模型（如 CLIP）进行分类。通过适应大型视觉基准，该方法在现实场景中（如负样本来自同一数据集的粒度控制版 iNaturalist）表现出色，比现成替代方案提升性能。研究首次证明，仅凭标签即可将一个类别与其他语义相关类别区分开，为零样本分类领域提供了新基准和见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00675v3",
      "published_date": "2024-03-31 12:48:07 UTC",
      "updated_date": "2024-05-27 08:53:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:28:32.872935"
    },
    {
      "arxiv_id": "2404.00673v2",
      "title": "A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures",
      "title_zh": "隐私保护模型解释的综述：隐私风险、攻击和对策",
      "authors": [
        "Thanh Tam Nguyen",
        "Thanh Trung Huynh",
        "Zhao Ren",
        "Thanh Toan Nguyen",
        "Phi Le Nguyen",
        "Hongzhi Yin",
        "Quoc Viet Hung Nguyen"
      ],
      "abstract": "As the adoption of explainable AI (XAI) continues to expand, the urgency to\naddress its privacy implications intensifies. Despite a growing corpus of\nresearch in AI privacy and explainability, there is little attention on\nprivacy-preserving model explanations. This article presents the first thorough\nsurvey about privacy attacks on model explanations and their countermeasures.\nOur contribution to this field comprises a thorough analysis of research papers\nwith a connected taxonomy that facilitates the categorisation of privacy\nattacks and countermeasures based on the targeted explanations. This work also\nincludes an initial investigation into the causes of privacy leaks. Finally, we\ndiscuss unresolved issues and prospective research directions uncovered in our\nanalysis. This survey aims to be a valuable resource for the research community\nand offers clear insights for those new to this domain. To support ongoing\nresearch, we have established an online resource repository, which will be\ncontinuously updated with new and relevant findings. Interested readers are\nencouraged to access our repository at\nhttps://github.com/tamlhp/awesome-privex.",
      "tldr_zh": "这篇调查文章探讨了可解释 AI (XAI) 中模型解释的隐私保护问题，包括隐私风险、攻击和对策，强调了这些问题的重要性及其潜在影响。该文首次对隐私攻击和其对策进行全面分析，建立了一个基于目标解释的分类法（taxonomy），并对隐私泄露原因进行了初步调查。研究讨论了未解决的问题和未来研究方向，并提供了一个在线资源库（https://github.com/tamlhp/awesome-privex），以支持研究社区的持续探索。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Revision",
      "pdf_url": "http://arxiv.org/pdf/2404.00673v2",
      "published_date": "2024-03-31 12:44:48 UTC",
      "updated_date": "2024-06-26 07:28:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:28:44.319188"
    },
    {
      "arxiv_id": "2404.00672v1",
      "title": "A General and Efficient Training for Transformer via Token Expansion",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxuan Huang",
        "Yunhang Shen",
        "Jiao Xie",
        "Baochang Zhang",
        "Gaoqi He",
        "Ke Li",
        "Xing Sun",
        "Shaohui Lin"
      ],
      "abstract": "The remarkable performance of Vision Transformers (ViTs) typically requires\nan extremely large training cost. Existing methods have attempted to accelerate\nthe training of ViTs, yet typically disregard method universality with accuracy\ndropping. Meanwhile, they break the training consistency of the original\ntransformers, including the consistency of hyper-parameters, architecture, and\nstrategy, which prevents them from being widely applied to different\nTransformer networks. In this paper, we propose a novel token growth scheme\nToken Expansion (termed ToE) to achieve consistent training acceleration for\nViTs. We introduce an \"initialization-expansion-merging\" pipeline to maintain\nthe integrity of the intermediate feature distribution of original\ntransformers, preventing the loss of crucial learnable information in the\ntraining process. ToE can not only be seamlessly integrated into the training\nand fine-tuning process of transformers (e.g., DeiT and LV-ViT), but also\neffective for efficient training frameworks (e.g., EfficientTrain), without\ntwisting the original training hyper-parameters, architecture, and introducing\nadditional training strategies. Extensive experiments demonstrate that ToE\nachieves about 1.3x faster for the training of ViTs in a lossless manner, or\neven with performance gains over the full-token training baselines. Code is\navailable at https://github.com/Osilly/TokenExpansion .",
      "tldr_zh": "本文提出了一种通用的 Token Expansion (ToE) 方法，用于加速 Vision Transformers (ViTs) 的训练，旨在解决现有加速方法在准确性和通用性上的不足。ToE 通过“initialization-expansion-merging”管道保持原 Transformers 的中间特征分布完整性，避免信息丢失，并能无缝整合到如 DeiT 和 LV-ViT 的训练或微调过程，以及 EfficientTrain 等框架中，而无需修改超参数、架构或引入额外策略。实验结果显示，ToE 使 ViTs 训练速度提高约 1.3 倍，同时实现无损性能或进一步提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to CVPR 2024. Code is available at\n  https://github.com/Osilly/TokenExpansion",
      "pdf_url": "http://arxiv.org/pdf/2404.00672v1",
      "published_date": "2024-03-31 12:44:24 UTC",
      "updated_date": "2024-03-31 12:44:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:28:56.502855"
    },
    {
      "arxiv_id": "2404.00657v1",
      "title": "Observations on Building RAG Systems for Technical Documents",
      "title_zh": "构建 RAG 系统用于",
      "authors": [
        "Sumit Soman",
        "Sujoy Roychowdhury"
      ],
      "abstract": "Retrieval augmented generation (RAG) for technical documents creates\nchallenges as embeddings do not often capture domain information. We review\nprior art for important factors affecting RAG and perform experiments to\nhighlight best practices and potential challenges to build RAG systems for\ntechnical documents.",
      "tldr_zh": "这篇论文讨论了在技术文档中使用 Retrieval Augmented Generation (RAG) 系统时面临的挑战，特别是 embeddings 无法有效捕捉领域信息的问题。作者回顾了先前研究中影响 RAG 的重要因素，并通过实验验证了最佳实践。实验结果突出了构建 RAG 系统的最佳实践和潜在挑战，为改进技术文档处理提供了实用指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a Tiny Paper at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.00657v1",
      "published_date": "2024-03-31 12:01:34 UTC",
      "updated_date": "2024-03-31 12:01:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:29:09.112165"
    },
    {
      "arxiv_id": "2404.00656v3",
      "title": "WavLLM: Towards Robust and Adaptive Speech Large Language Model",
      "title_zh": "WavLLM：迈向鲁棒且自适应语音大语言模型",
      "authors": [
        "Shujie Hu",
        "Long Zhou",
        "Shujie Liu",
        "Sanyuan Chen",
        "Lingwei Meng",
        "Hongkun Hao",
        "Jing Pan",
        "Xunying Liu",
        "Jinyu Li",
        "Sunit Sivasankaran",
        "Linquan Liu",
        "Furu Wei"
      ],
      "abstract": "The recent advancements in large language models (LLMs) have revolutionized\nthe field of natural language processing, progressively broadening their scope\nto multimodal perception and generation. However, effectively integrating\nlistening capabilities into LLMs poses significant challenges, particularly\nwith respect to generalizing across varied contexts and executing complex\nauditory tasks. In this work, we introduce WavLLM, a robust and adaptive speech\nlarge language model with dual encoders, and a prompt-aware LoRA weight\nadapter, optimized by a two-stage curriculum learning approach. Leveraging dual\nencoders, we decouple different types of speech information, utilizing a\nWhisper encoder to process the semantic content of speech, and a WavLM encoder\nto capture the unique characteristics of the speaker's identity. Within the\ncurriculum learning framework, WavLLM first builds its foundational\ncapabilities by optimizing on mixed elementary single tasks, followed by\nadvanced multi-task training on more complex tasks such as combinations of the\nelementary tasks. To enhance the flexibility and adherence to different tasks\nand instructions, a prompt-aware LoRA weight adapter is introduced in the\nsecond advanced multi-task training stage. We validate the proposed model on\nuniversal speech benchmarks including tasks such as ASR, ST, SV, ER, and also\napply it to specialized datasets like Gaokao English listening comprehension\nset for SQA, and speech Chain-of-Thought (CoT) evaluation set. Experiments\ndemonstrate that the proposed model achieves state-of-the-art performance\nacross a range of speech tasks on the same model size, exhibiting robust\ngeneralization capabilities in executing complex tasks using CoT approach.\nFurthermore, our model successfully completes Gaokao tasks without specialized\ntraining. The codes, models, audio, and Gaokao evaluation set can be accessed\nat \\url{aka.ms/wavllm}.",
      "tldr_zh": "该研究提出 WavLLM，一种健壮且适应的语音大型语言模型（Speech Large Language Model），旨在将听力能力融入 LLMs 中，以处理多样化语境和复杂听觉任务。WavLLM 采用双编码器（dual encoders）设计，包括 Whisper 编码器处理语义内容和 WavLM 编码器捕获说话者身份特征，并通过两阶段课程学习（curriculum learning）优化模型：第一阶段聚焦基础单任务，第二阶段引入提示感知 LoRA 权重适配器（prompt-aware LoRA weight adapter）进行高级多任务训练。实验结果显示，WavLLM 在 ASR、ST、SV 和 ER 等语音基准任务上达到最先进性能，并在 Gaokao 英语听力理解和语音 Chain-of-Thought (CoT) 任务中展示出强大的泛化能力，无需专门训练即可完成复杂任务。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted by EMNLP2024 findings",
      "pdf_url": "http://arxiv.org/pdf/2404.00656v3",
      "published_date": "2024-03-31 12:01:32 UTC",
      "updated_date": "2024-09-21 15:27:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:29:22.842041"
    },
    {
      "arxiv_id": "2404.00651v1",
      "title": "Learning Off-policy with Model-based Intrinsic Motivation For Active Online Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Yibo Wang",
        "Jiang Zhao"
      ],
      "abstract": "Recent advancements in deep reinforcement learning (RL) have demonstrated\nnotable progress in sample efficiency, spanning both model-based and model-free\nparadigms. Despite the identification and mitigation of specific bottlenecks in\nprior works, the agent's exploration ability remains under-emphasized in the\nrealm of sample-efficient RL. This paper investigates how to achieve\nsample-efficient exploration in continuous control tasks. We introduce an RL\nalgorithm that incorporates a predictive model and off-policy learning\nelements, where an online planner enhanced by a novelty-aware terminal value\nfunction is employed for sample collection. Leveraging the forward predictive\nerror within a latent state space, we derive an intrinsic reward without\nincurring parameters overhead. This reward establishes a solid connection to\nmodel uncertainty, allowing the agent to effectively overcome the asymptotic\nperformance gap. Through extensive experiments, our method shows competitive or\neven superior performance compared to prior works, especially the sparse reward\ncases.",
      "tldr_zh": "本文提出了一种基于模型的内在动机RL算法，用于提升代理在连续控制任务中的样本效率探索能力。该算法结合off-policy学习和在线规划器，通过潜在状态空间的预测错误生成内在奖励，并与模型不确定性相关联，从而帮助代理克服性能差距。在广泛实验中，该方法尤其在稀疏奖励场景下，表现出与现有工作相当或优越的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2404.00651v1",
      "published_date": "2024-03-31 11:39:11 UTC",
      "updated_date": "2024-03-31 11:39:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:29:33.025860"
    },
    {
      "arxiv_id": "2404.00636v3",
      "title": "Learning to Generate Conditional Tri-plane for 3D-aware Expression Controllable Portrait Animation",
      "title_zh": "翻译失败",
      "authors": [
        "Taekyung Ki",
        "Dongchan Min",
        "Gyeongsu Chae"
      ],
      "abstract": "In this paper, we present Export3D, a one-shot 3D-aware portrait animation\nmethod that is able to control the facial expression and camera view of a given\nportrait image. To achieve this, we introduce a tri-plane generator with an\neffective expression conditioning method, which directly generates a tri-plane\nof 3D prior by transferring the expression parameter of 3DMM into the source\nimage. The tri-plane is then decoded into the image of different view through a\ndifferentiable volume rendering. Existing portrait animation methods heavily\nrely on image warping to transfer the expression in the motion space,\nchallenging on disentanglement of appearance and expression. In contrast, we\npropose a contrastive pre-training framework for appearance-free expression\nparameter, eliminating undesirable appearance swap when transferring a\ncross-identity expression. Extensive experiments show that our pre-training\nframework can learn the appearance-free expression representation hidden in\n3DMM, and our model can generate 3D-aware expression controllable portrait\nimages without appearance swap in the cross-identity manner.",
      "tldr_zh": "本文提出 Export3D，一种 one-shot 3D-aware 肖像动画方法，能够基于给定图像控制面部表情和相机视角。核心技术包括 tri-plane 生成器，通过将 3DMM 的表情参数转移到源图像中直接生成 3D 先验，并使用可微分 volume rendering 解码成不同视角的图像。不同于传统依赖图像扭曲的方法，该框架引入对比预训练策略，学习无外观的表情表示，从而在跨身份表情转移中避免不期望的外观交换。实验证明，Export3D 能有效生成高质量的 3D-aware 可控肖像图像，实现了外观与表情的良好分离。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024. Project page: https://export3d.github.io",
      "pdf_url": "http://arxiv.org/pdf/2404.00636v3",
      "published_date": "2024-03-31 10:13:55 UTC",
      "updated_date": "2024-07-23 10:47:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:29:46.574836"
    },
    {
      "arxiv_id": "2404.00614v2",
      "title": "Learning to Plan for Language Modeling from Unlabeled Data",
      "title_zh": "翻译失败",
      "authors": [
        "Nathan Cornille",
        "Marie-Francine Moens",
        "Florian Mai"
      ],
      "abstract": "By training to predict the next token in an unlabeled corpus, large language\nmodels learn to perform many tasks without any labeled data. However, their\nnext-token-prediction objective arguably limits their performance in scenarios\nthat require planning, such as writing a coherent article. In this paper, we\ntrain a module for planning the future writing process via a self-supervised\nlearning objective. Given the textual context, this planning module learns to\npredict future abstract writing actions, which correspond to centroids in a\nclustered text embedding space. By conditioning on these actions, our model\nextends the successful language model formula to more abstract planning in an\nunsupervised way. Empirically, we demonstrate that our method improves language\nmodeling performance in general, particularly with respect to the text\nstructure. Because our framework uses a planner module that is unsupervised and\nexternal to the language model, new planner modules can be trained at large\nscale and easily be shared with the community.",
      "tldr_zh": "本文提出了一种从无标签数据中学习规划模块的方法，以克服大型语言模型在 next-token-prediction 目标下对规划任务（如撰写连贯文章）的局限性。该模块通过 self-supervised learning 预测未来的抽象写作动作，这些动作对应于聚类文本嵌入空间中的 centroids，从而在无监督方式下扩展语言模型的规划能力。实验结果显示，该方法显著改善了语言建模的性能，尤其是在文本结构方面。由于规划模块是无监督且外部于语言模型的，因此可以大规模训练并方便与社区共享。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published at COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.00614v2",
      "published_date": "2024-03-31 09:04:01 UTC",
      "updated_date": "2024-07-31 12:25:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:29:58.287868"
    },
    {
      "arxiv_id": "2404.00604v1",
      "title": "Extensive Self-Contrast Enables Feedback-Free Language Model Alignment",
      "title_zh": "广泛的自对比实现无反馈语言模型对齐",
      "authors": [
        "Xiao Liu",
        "Xixuan Song",
        "Yuxiao Dong",
        "Jie Tang"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) has been a central\ntechnique for recent large language model (LLM) alignment. However, its heavy\ndependence on costly human or LLM-as-Judge preference feedback could stymie its\nwider applications. In this work, we introduce Self-Contrast, a feedback-free\nlarge language model alignment method via exploiting extensive self-generated\nnegatives. With only supervised fine-tuning (SFT) targets, Self-Contrast\nleverages the LLM itself to generate massive diverse candidates, and harnesses\na pre-trained embedding model to filter multiple negatives according to text\nsimilarity. Theoretically, we illustrate that in this setting, merely scaling\nnegative responses can still effectively approximate situations with more\nbalanced positive and negative preference annotations. Our experiments with\ndirect preference optimization (DPO) on three datasets show that, Self-Contrast\ncould consistently outperform SFT and standard DPO training by large margins.\nAnd as the number of self-generated negatives increases, the performance of\nSelf-Contrast continues to grow. Code and data are available at\nhttps://github.com/THUDM/Self-Contrast.",
      "tldr_zh": "本文提出 Self-Contrast，一种无需人类反馈的语言模型对齐方法，通过利用 LLM 生成大量多样化候选文本，并借助预训练嵌入模型根据文本相似度过滤负样本，实现高效训练。相比传统 RLHF，该方法仅依赖 SFT 目标即可模拟平衡正负样本，并在理论上证明扩展负样本能有效提升对齐效果。实验结果显示，在三个数据集上，Self-Contrast 显著优于 SFT 和标准 DPO，随着负样本数量增加，其性能持续改善，提供了一种成本更低的 LLM 优化途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00604v1",
      "published_date": "2024-03-31 08:30:15 UTC",
      "updated_date": "2024-03-31 08:30:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:30:09.694977"
    },
    {
      "arxiv_id": "2404.00600v2",
      "title": "AI Act and Large Language Models (LLMs): When critical issues and privacy impact require human and ethical oversight",
      "title_zh": "翻译失败",
      "authors": [
        "Nicola Fabiano"
      ],
      "abstract": "The imposing evolution of artificial intelligence systems and, specifically,\nof Large Language Models (LLM) makes it necessary to carry out assessments of\ntheir level of risk and the impact they may have in the area of privacy,\npersonal data protection and at an ethical level, especially on the weakest and\nmost vulnerable. This contribution addresses human oversight, ethical\noversight, and privacy impact assessment.",
      "tldr_zh": "这篇论文探讨了AI Act与大型语言模型(LLMs)相关的关键问题，强调AI系统的快速发展可能对隐私、个人数据保护和伦理层面造成风险，特别是对弱势群体。论文重点分析了人类监督(human oversight)、伦理监督(ethical oversight)以及隐私影响评估(privacy impact assessment)的必要性，以评估LLMs的潜在影响。最终，它提出通过这些监督机制来确保AI应用的伦理合规和风险控制。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00600v2",
      "published_date": "2024-03-31 08:14:25 UTC",
      "updated_date": "2024-04-02 06:05:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:30:21.189283"
    },
    {
      "arxiv_id": "2404.00599v1",
      "title": "EvoCodeBench: An Evolving Code Generation Benchmark Aligned with Real-World Code Repositories",
      "title_zh": "EvoCodeBench：与真实世界代码仓库对齐的演进代码生成基准",
      "authors": [
        "Jia Li",
        "Ge Li",
        "Xuanming Zhang",
        "Yihong Dong",
        "Zhi Jin"
      ],
      "abstract": "How to evaluate Large Language Models (LLMs) in code generation is an open\nquestion. Existing benchmarks demonstrate poor alignment with real-world code\nrepositories and are insufficient to evaluate the coding abilities of LLMs.\nThis paper proposes a new benchmark - EvoCodeBench to address the preceding\nproblems, which has three primary advances. (1) EvoCodeBench aligns with\nreal-world repositories in multiple dimensions, e.g., code distributions and\ndependency distributions. (2) EvoCodeBench offers comprehensive annotations\n(e.g., requirements, reference code, and reference dependencies), and robust\nevaluation metrics (e.g., Pass@k and Recall@k). (3) EvoCodeBench is an evolving\nbenchmark to avoid data leakage. We build an automatic pipeline to update\nEvoCodeBench from the latest repositories. We release the first version -\nEvoCodeBench-2403, containing 275 samples from 25 real-world repositories.\nBased on EvoCodeBench, we propose repository-level code generation and evaluate\n10 popular LLMs (e.g., gpt-4, gpt-3.5, DeepSeek Coder, StarCoder 2, CodeLLaMa,\nGemma, and Qwen 1.5). Our experiments reveal the coding abilities of these LLMs\nin real-world repositories. For example, the highest Pass@1 of gpt-4 only is\n20.73% in our experiments. We also analyze failed cases and summarize the\nshortcomings of existing LLMs in EvoCodeBench. We release EvoCodeBench, all\nprompts, and LLMs' completions for further community analysis.",
      "tldr_zh": "这篇论文提出了EvoCodeBench，一个与真实代码仓库对齐的演化代码生成基准，以解决现有基准在评估Large Language Models (LLMs)时存在的关联性差和评估不足问题。EvoCodeBench在代码分布、依赖分布等多维度与真实仓库一致，提供全面注释（如需求和参考代码）以及稳健指标（如Pass@k和Recall@k），并通过自动管道实现持续更新，避免数据泄露。作者基于此基准评估了10个流行LLMs（如gpt-4和DeepSeek Coder），发现这些模型在仓库级代码生成中的表现较差，例如gpt-4的Pass@1仅为20.73%，并总结了其缺点如处理复杂依赖的局限性。他们发布了EvoCodeBench-2403版本（含275个样本）和相关资源，供社区进一步分析。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Data: https://github.com/seketeam/EvoCodeBench",
      "pdf_url": "http://arxiv.org/pdf/2404.00599v1",
      "published_date": "2024-03-31 08:10:50 UTC",
      "updated_date": "2024-03-31 08:10:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:30:36.146599"
    },
    {
      "arxiv_id": "2404.00593v1",
      "title": "LAESI: Leaf Area Estimation with Synthetic Imagery",
      "title_zh": "LAESI：基于合成图像的叶面积估算",
      "authors": [
        "Jacek Kałużny",
        "Yannik Schreckenberg",
        "Karol Cyganik",
        "Peter Annighöfer",
        "Sören Pirk",
        "Dominik L. Michels",
        "Mikolaj Cieslak",
        "Farhah Assaad-Gerbert",
        "Bedrich Benes",
        "Wojciech Pałubicki"
      ],
      "abstract": "We introduce LAESI, a Synthetic Leaf Dataset of 100,000 synthetic leaf images\non millimeter paper, each with semantic masks and surface area labels. This\ndataset provides a resource for leaf morphology analysis primarily aimed at\nbeech and oak leaves. We evaluate the applicability of the dataset by training\nmachine learning models for leaf surface area prediction and semantic\nsegmentation, using real images for validation. Our validation shows that these\nmodels can be trained to predict leaf surface area with a relative error not\ngreater than an average human annotator. LAESI also provides an efficient\nframework based on 3D procedural models and generative AI for the large-scale,\ncontrollable generation of data with potential further applications in\nagriculture and biology. We evaluate the inclusion of generative AI in our\nprocedural data generation pipeline and show how data filtering based on\nannotation consistency results in datasets which allow training the highest\nperforming vision models.",
      "tldr_zh": "本文介绍了 LAESI，一个包含 10 万张合成叶片图像的数据集（Synthetic Leaf Dataset），针对山毛榉和橡树叶提供语义掩码和表面面积标签，用于叶片形态分析。研究通过训练 machine learning models 进行叶片表面面积预测和 semantic segmentation，使用真实图像验证，显示模型的相对误差不超过平均人类标注者。LAESI 框架利用 3D 过程模型和 generative AI 实现高效、可控的大规模数据生成，并通过数据过滤优化数据集，提升模型性能，具有潜在应用于农业和生物学领域。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "68T07, 68T45",
        "I.2.10; I.4.6"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 12 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2404.00593v1",
      "published_date": "2024-03-31 07:56:07 UTC",
      "updated_date": "2024-03-31 07:56:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:30:45.767137"
    },
    {
      "arxiv_id": "2404.00588v1",
      "title": "Memory-based Cross-modal Semantic Alignment Network for Radiology Report Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yitian Tao",
        "Liyan Ma",
        "Jing Yu",
        "Han Zhang"
      ],
      "abstract": "Generating radiology reports automatically reduces the workload of\nradiologists and helps the diagnoses of specific diseases. Many existing\nmethods take this task as modality transfer process. However, since the key\ninformation related to disease accounts for a small proportion in both image\nand report, it is hard for the model to learn the latent relation between the\nradiology image and its report, thus failing to generate fluent and accurate\nradiology reports. To tackle this problem, we propose a memory-based\ncross-modal semantic alignment model (MCSAM) following an encoder-decoder\nparadigm. MCSAM includes a well initialized long-term clinical memory bank to\nlearn disease-related representations as well as prior knowledge for different\nmodalities to retrieve and use the retrieved memory to perform feature\nconsolidation. To ensure the semantic consistency of the retrieved cross modal\nprior knowledge, a cross-modal semantic alignment module (SAM) is proposed. SAM\nis also able to generate semantic visual feature embeddings which can be added\nto the decoder and benefits report generation. More importantly, to memorize\nthe state and additional information while generating reports with the decoder,\nwe use learnable memory tokens which can be seen as prompts. Extensive\nexperiments demonstrate the promising performance of our proposed method which\ngenerates state-of-the-art performance on the MIMIC-CXR dataset.",
      "tldr_zh": "本文提出了一种基于记忆的跨模态语义对齐网络 (MCSAM)，采用编码器-解码器范式，旨在解决放射学报告生成中关键疾病信息占比小导致的图像与报告潜在关系学习困难问题。MCSAM 包括一个长期临床记忆库，用于检索和整合不同模态的疾病相关表示和先验知识，以及跨模态语义对齐模块 (SAM) 来确保语义一致性并生成增强报告的视觉特征嵌入，同时使用可学习的记忆标记作为提示来记忆生成状态。在 MIMIC-CXR 数据集上的广泛实验证明，该方法实现了最先进的性能，显著提高了报告的准确性和流畅性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.00588v1",
      "published_date": "2024-03-31 07:30:41 UTC",
      "updated_date": "2024-03-31 07:30:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:30:59.726836"
    },
    {
      "arxiv_id": "2404.00586v2",
      "title": "RLGNet: Repeating-Local-Global History Network for Temporal Knowledge Graph Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Ao Lv",
        "Guige Ouyang",
        "Yongzhong Huang",
        "Yue Chen",
        "Haoran Xie"
      ],
      "abstract": "Temporal Knowledge Graph (TKG) reasoning involves predicting future events\nbased on historical information. However, due to the unpredictability of future\nevents, this task is highly challenging. To address this issue, we propose a\nmulti-scale hybrid architecture model based on ensemble learning, called RLGNet\n(Repeating-Local-Global History Network). Inspired by the application of\nmulti-scale information in other fields, we introduce the concept of\nmulti-scale information into TKG reasoning. Specifically, RLGNet captures and\nintegrates different levels of historical information by combining modules that\nprocess information at various scales. The model comprises three modules: the\nRepeating History Module focuses on identifying repetitive patterns and trends\nin historical data, the Local History Module captures short-term changes and\ndetails, and the Global History Module provides a macro perspective on\nlong-term changes. Additionally, to address the limitations of previous\nsingle-architecture models in generalizing across single-step and multi-step\nreasoning tasks, we adopted architectures based on Recurrent Neural Networks\n(RNN) and Multi-Layer Perceptrons (MLP) for the Local and Global History\nModules, respectively. This hybrid architecture design enables the model to\ncomplement both multi-step and single-step reasoning capabilities. Finally, to\naddress the issue of noise in TKGs, we adopt an ensemble learning strategy,\ncombining the predictions of the three modules to reduce the impact of noise on\nthe final prediction results. In the evaluation on six benchmark datasets, our\napproach generally outperforms existing TKG reasoning models in multi-step and\nsingle-step reasoning tasks.",
      "tldr_zh": "本研究提出 RLGNet，一种基于集成学习的多尺度混合架构，用于 Temporal Knowledge Graph (TKG) 推理，帮助预测基于历史信息的未来事件。\nRLGNet 包括三个模块：Repeating History Module 识别历史数据中的重复模式和趋势，Local History Module (基于 RNN) 捕捉短期变化和细节，Global History Module (基于 MLP) 提供长期变化的宏观视角。\n通过混合架构设计和集成学习策略，模型有效减少 TKG 中的噪声影响，并同时提升单步和多步推理能力。\n在六个基准数据集的评估中，RLGNet 在多步和单步推理任务上优于现有模型，展示了其显著性能优势。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00586v2",
      "published_date": "2024-03-31 07:19:29 UTC",
      "updated_date": "2024-07-28 08:44:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:31:13.844695"
    },
    {
      "arxiv_id": "2404.01343v4",
      "title": "CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jingzhe Shi",
        "Jialuo Li",
        "Qinwei Ma",
        "Zaiwen Yang",
        "Huan Ma",
        "Lei Li"
      ],
      "abstract": "Businesses and software platforms are increasingly turning to Large Language\nModels (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistance\nwith file access or as reasoning agents for customer service. However, current\nLLM-based customer service models have limited integration with customer\nprofiles and lack the operational capabilities necessary for effective service.\nMoreover, existing API integrations emphasize diversity over the precision and\nerror avoidance essential in real-world customer service scenarios. To address\nthese issues, we propose an LLM agent named CHOPS (CHat with custOmer Profile\nin existing System), designed to: (1) efficiently utilize existing databases or\nsystems for accessing user information or interacting with these systems\nfollowing existing guidelines; (2) provide accurate and reasonable responses or\ncarry out required operations in the system while avoiding harmful operations;\nand (3) leverage a combination of small and large LLMs to achieve satisfying\nperformance at a reasonable inference cost. We introduce a practical dataset,\nthe CPHOS-dataset, which includes a database, guiding files, and QA pairs\ncollected from CPHOS, an online platform that facilitates the organization of\nsimulated Physics Olympiads for high school teachers and students. We have\nconducted extensive experiments to validate the performance of our proposed\nCHOPS architecture using the CPHOS-dataset, with the aim of demonstrating how\nLLMs can enhance or serve as alternatives to human customer service. Code for\nour proposed architecture and dataset can be found at\n{https://github.com/JingzheShi/CHOPS}.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在客服中的局限性，如与客户资料整合不足和操作精确性问题，提出了一种名为 CHOPS 的 LLM 代理框架。CHOPS 旨在高效利用现有数据库访问用户信息、提供准确响应并避免有害操作，同时结合小模型和大模型以降低推理成本。研究引入了 CPHOS-dataset 作为实用数据集，并通过实验验证 CHOPS 在客服场景中的性能，展示了 LLMs 如何提升或替代人工服务。开源代码可从指定仓库获取，为实际应用提供了可行基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.01343v4",
      "published_date": "2024-03-31 07:11:48 UTC",
      "updated_date": "2024-07-17 07:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:31:24.768463"
    },
    {
      "arxiv_id": "2404.00579v2",
      "title": "A Review of Modern Recommender Systems Using Generative Models (Gen-RecSys)",
      "title_zh": "翻译失败",
      "authors": [
        "Yashar Deldjoo",
        "Zhankui He",
        "Julian McAuley",
        "Anton Korikov",
        "Scott Sanner",
        "Arnau Ramisa",
        "René Vidal",
        "Maheswaran Sathiamoorthy",
        "Atoosa Kasirzadeh",
        "Silvia Milano"
      ],
      "abstract": "Traditional recommender systems (RS) typically use user-item rating histories\nas their main data source. However, deep generative models now have the\ncapability to model and sample from complex data distributions, including\nuser-item interactions, text, images, and videos, enabling novel recommendation\ntasks. This comprehensive, multidisciplinary survey connects key advancements\nin RS using Generative Models (Gen-RecSys), covering: interaction-driven\ngenerative models; the use of large language models (LLM) and textual data for\nnatural language recommendation; and the integration of multimodal models for\ngenerating and processing images/videos in RS. Our work highlights necessary\nparadigms for evaluating the impact and harm of Gen-RecSys and identifies open\nchallenges. This survey accompanies a tutorial presented at ACM KDD'24, with\nsupporting materials provided at: https://encr.pw/vDhLq.",
      "tldr_zh": "这篇综述（A Review of Modern Recommender Systems Using Generative Models, 简称 Gen-RecSys）探讨了传统推荐系统（RS）如何通过生成模型扩展，超越了基于用户-物品评分的历史数据。论文涵盖了交互驱动的生成模型、大语言模型（LLM）与文本数据用于自然语言推荐，以及多模态模型的整合来处理图像和视频，从而支持新型推荐任务。作者强调了评估 Gen-RecSys 的影响和潜在危害的必要范式，并指出了开放挑战，同时提供了 ACM KDD'24 教程的配套材料。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "This survey accompanies a tutorial presented at ACM KDD'24",
      "pdf_url": "http://arxiv.org/pdf/2404.00579v2",
      "published_date": "2024-03-31 06:57:57 UTC",
      "updated_date": "2024-07-04 15:06:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:31:36.875799"
    },
    {
      "arxiv_id": "2404.00576v1",
      "title": "Automated Bi-Fold Weighted Ensemble Algorithms and its Application to Brain Tumor Detection and Classification",
      "title_zh": "翻译失败",
      "authors": [
        "PoTsang B. Huang",
        "Muhammad Rizwan",
        "Mehboob Ali"
      ],
      "abstract": "The uncontrolled and unstructured growth of brain cells is known as brain\ntumor, which has one of the highest mortality rates among diseases from all\ntypes of cancers. Due to limited diagnostic and treatment capabilities, they\npose significant challenges, especially in third-world countries. Early\ndiagnosis plays a vital role in effectively managing brain tumors and reducing\nmortality rates. However, the availability of diagnostic methods is hindered by\nvarious limitations, including high costs and lengthy result acquisition times,\nimpeding early detection of the disease. In this study, we present two\ncutting-edge bi-fold weighted voting ensemble models that aim to boost the\neffectiveness of weighted ensemble methods. These two proposed methods combine\nthe classification outcomes from multiple classifiers and determine the optimal\nresult by selecting the one with the highest probability in the first approach,\nand the highest weighted prediction in the second technique. These approaches\nsignificantly improve the overall performance of weighted ensemble techniques.\nIn the first proposed method, we improve the soft voting technique (SVT) by\nintroducing a novel unsupervised weight calculating schema (UWCS) to enhance\nits weight assigning capability, known as the extended soft voting technique\n(ESVT). Secondly, we propose a novel weighted method (NWM) by using the\nproposed UWCS. Both of our approaches incorporate three distinct models: a\ncustom-built CNN, VGG-16, and InceptionResNetV2 which has been trained on\npublicly available datasets. The effectiveness of our proposed systems is\nevaluated through blind testing, where exceptional results are achieved. We\nthen establish a comparative analysis of the performance of our proposed\nmethods with that of SVT to show their superiority and effectiveness.",
      "tldr_zh": "本研究针对脑瘤检测和分类的挑战，提出两种创新的 Automated Bi-Fold Weighted Ensemble Algorithms，以提升加权集成方法的性能。这些算法包括改进的 Extended Soft Voting Technique (ESVT)，通过引入 Unsupervised Weight Calculating Schema (UWCS) 来优化权重分配，以及 Novel Weighted Method (NWM)，用于结合多个分类器的预测结果。研究结合了自定义 CNN、VGG-16 和 InceptionResNetV2 模型，在公开数据集上进行训练，并通过盲测试验证了其有效性。结果显示，所提方法显著优于传统的 Soft Voting Technique (SVT)，为脑瘤早期诊断提供了更准确的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00576v1",
      "published_date": "2024-03-31 06:38:08 UTC",
      "updated_date": "2024-03-31 06:38:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:31:48.987999"
    },
    {
      "arxiv_id": "2404.01342v1",
      "title": "DiffAgent: Fast and Accurate Text-to-Image API Selection with Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Lirui Zhao",
        "Yue Yang",
        "Kaipeng Zhang",
        "Wenqi Shao",
        "Yuxin Zhang",
        "Yu Qiao",
        "Ping Luo",
        "Rongrong Ji"
      ],
      "abstract": "Text-to-image (T2I) generative models have attracted significant attention\nand found extensive applications within and beyond academic research. For\nexample, the Civitai community, a platform for T2I innovation, currently hosts\nan impressive array of 74,492 distinct models. However, this diversity presents\na formidable challenge in selecting the most appropriate model and parameters,\na process that typically requires numerous trials. Drawing inspiration from the\ntool usage research of large language models (LLMs), we introduce DiffAgent, an\nLLM agent designed to screen the accurate selection in seconds via API calls.\nDiffAgent leverages a novel two-stage training framework, SFTA, enabling it to\naccurately align T2I API responses with user input in accordance with human\npreferences. To train and evaluate DiffAgent's capabilities, we present\nDABench, a comprehensive dataset encompassing an extensive range of T2I APIs\nfrom the community. Our evaluations reveal that DiffAgent not only excels in\nidentifying the appropriate T2I API but also underscores the effectiveness of\nthe SFTA training framework. Codes are available at\nhttps://github.com/OpenGVLab/DiffAgent.",
      "tldr_zh": "论文提出 DiffAgent，一种基于 Large Language Model (LLMs) 的代理，用于快速准确地选择 Text-to-Image (T2I) API，解决模型多样性带来的选择难题。DiffAgent 采用新型两阶段训练框架 SFTA，使其能根据人类偏好将 T2I API 响应与用户输入对齐，从而在几秒内完成筛选。研究团队构建了 DABench 数据集用于训练和评估，结果显示 DiffAgent 在识别合适 T2I API 方面显著优于基线方法，并提供了开源代码以促进进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published as a conference paper at CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.01342v1",
      "published_date": "2024-03-31 06:28:15 UTC",
      "updated_date": "2024-03-31 06:28:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:32:01.087806"
    },
    {
      "arxiv_id": "2404.01341v2",
      "title": "Block-Diagonal Guided DBSCAN Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Weibing Zhao"
      ],
      "abstract": "Cluster analysis plays a crucial role in database mining, and one of the most\nwidely used algorithms in this field is DBSCAN. However, DBSCAN has several\nlimitations, such as difficulty in handling high-dimensional large-scale data,\nsensitivity to input parameters, and lack of robustness in producing clustering\nresults. This paper introduces an improved version of DBSCAN that leverages the\nblock-diagonal property of the similarity graph to guide the clustering\nprocedure of DBSCAN. The key idea is to construct a graph that measures the\nsimilarity between high-dimensional large-scale data points and has the\npotential to be transformed into a block-diagonal form through an unknown\npermutation, followed by a cluster-ordering procedure to generate the desired\npermutation. The clustering structure can be easily determined by identifying\nthe diagonal blocks in the permuted graph. We propose a gradient descent-based\nmethod to solve the proposed problem. Additionally, we develop a DBSCAN-based\npoints traversal algorithm that identifies clusters with high densities in the\ngraph and generates an augmented ordering of clusters. The block-diagonal\nstructure of the graph is then achieved through permutation based on the\ntraversal order, providing a flexible foundation for both automatic and\ninteractive cluster analysis. We introduce a split-and-refine algorithm to\nautomatically search for all diagonal blocks in the permuted graph with\ntheoretically optimal guarantees under specific cases. We extensively evaluate\nour proposed approach on twelve challenging real-world benchmark clustering\ndatasets and demonstrate its superior performance compared to the\nstate-of-the-art clustering method on every dataset.",
      "tldr_zh": "这篇论文针对 DBSCAN 算法在处理高维大规模数据时存在的局限性（如参数敏感性和聚类鲁棒性不足），提出了一种改进版本：Block-Diagonal Guided DBSCAN。关键方法包括构建相似性图并通过梯度下降求解未知置换使其变为块对角形式，结合 DBSCAN-based 点遍历算法和 split-and-refine 算法来自动识别高密度集群并优化聚类结构。该方法在 12 个真实世界基准数据集上表现出色，比最先进聚类方法在每个数据集上均有优越性能，提供更灵活的自动和交互式聚类分析基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2009.04552 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2404.01341v2",
      "published_date": "2024-03-31 05:04:38 UTC",
      "updated_date": "2024-04-27 01:34:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:32:13.424732"
    },
    {
      "arxiv_id": "2404.00560v1",
      "title": "A Theory for Length Generalization in Learning to Reason",
      "title_zh": "学习推理中长度泛化的理论",
      "authors": [
        "Changnan Xiao",
        "Bing Liu"
      ],
      "abstract": "Length generalization (LG) is a challenging problem in learning to reason. It\nrefers to the phenomenon that when trained on reasoning problems of smaller\nlengths or sizes, the resulting model struggles with problems of larger sizes\nor lengths. Although LG has been studied by many researchers, the challenge\nremains. This paper proposes a theoretical study of LG for problems whose\nreasoning processes can be modeled as DAGs (directed acyclic graphs). The paper\nfirst identifies and proves the conditions under which LG can be achieved in\nlearning to reason. It then designs problem representations based on the theory\nto learn to solve challenging reasoning problems like parity, addition, and\nmultiplication, using a Transformer to achieve perfect LG.",
      "tldr_zh": "这篇论文探讨了 Length Generalization (LG) 在学习推理中的挑战，即模型在较小规模问题上训练后难以处理更大规模问题。作者针对推理过程可建模为 DAGs (Directed Acyclic Graphs) 的问题，理论上识别并证明了实现 LG 的条件，并据此设计了问题表示方法。最终，使用 Transformer 模型在 parity、addition 和 multiplication 等推理任务上实现了完美的 LG。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2311.16173",
      "pdf_url": "http://arxiv.org/pdf/2404.00560v1",
      "published_date": "2024-03-31 04:44:22 UTC",
      "updated_date": "2024-03-31 04:44:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:32:24.269251"
    },
    {
      "arxiv_id": "2404.00544v1",
      "title": "Deep Extrinsic Manifold Representation for Vision Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Tongtong Zhang",
        "Xian Wei",
        "Yuanxiang Li"
      ],
      "abstract": "Non-Euclidean data is frequently encountered across different fields, yet\nthere is limited literature that addresses the fundamental challenge of\ntraining neural networks with manifold representations as outputs. We introduce\nthe trick named Deep Extrinsic Manifold Representation (DEMR) for visual tasks\nin this context. DEMR incorporates extrinsic manifold embedding into deep\nneural networks, which helps generate manifold representations. The DEMR\napproach does not directly optimize the complex geodesic loss. Instead, it\nfocuses on optimizing the computation graph within the embedded Euclidean\nspace, allowing for adaptability to various architectural requirements. We\nprovide empirical evidence supporting the proposed concept on two types of\nmanifolds, $SE(3)$ and its associated quotient manifolds. This evidence offers\ntheoretical assurances regarding feasibility, asymptotic properties, and\ngeneralization capability. The experimental results show that DEMR effectively\nadapts to point cloud alignment, producing outputs in $ SE(3) $, as well as in\nillumination subspace learning with outputs on the Grassmann manifold.",
      "tldr_zh": "本论文提出了一种名为Deep Extrinsic Manifold Representation (DEMR)的技巧，用于处理视觉任务中的非欧空间数据问题。DEMR通过将外部流形嵌入整合到深度神经网络中，生成流形表示，同时避免直接优化复杂的测地线损失，转而优化嵌入欧空间的计算图，以提升适应性和灵活性。在SE(3)和Grassmann manifold等流形上进行的实验提供了实证证据，支持DEMR的可行性、渐近特性和泛化能力。结果表明，该方法在点云对齐和光照子空间学习任务中表现出色，显著提高了输出精度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00544v1",
      "published_date": "2024-03-31 03:16:08 UTC",
      "updated_date": "2024-03-31 03:16:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:32:37.442116"
    },
    {
      "arxiv_id": "2404.00540v1",
      "title": "Embodied Active Defense: Leveraging Recurrent Feedback to Counter Adversarial Patches",
      "title_zh": "翻译失败",
      "authors": [
        "Lingxuan Wu",
        "Xiao Yang",
        "Yinpeng Dong",
        "Liuwei Xie",
        "Hang Su",
        "Jun Zhu"
      ],
      "abstract": "The vulnerability of deep neural networks to adversarial patches has\nmotivated numerous defense strategies for boosting model robustness. However,\nthe prevailing defenses depend on single observation or pre-established\nadversary information to counter adversarial patches, often failing to be\nconfronted with unseen or adaptive adversarial attacks and easily exhibiting\nunsatisfying performance in dynamic 3D environments. Inspired by active human\nperception and recurrent feedback mechanisms, we develop Embodied Active\nDefense (EAD), a proactive defensive strategy that actively contextualizes\nenvironmental information to address misaligned adversarial patches in 3D\nreal-world settings. To achieve this, EAD develops two central recurrent\nsub-modules, i.e., a perception module and a policy module, to implement two\ncritical functions of active vision. These models recurrently process a series\nof beliefs and observations, facilitating progressive refinement of their\ncomprehension of the target object and enabling the development of strategic\nactions to counter adversarial patches in 3D environments. To optimize learning\nefficiency, we incorporate a differentiable approximation of environmental\ndynamics and deploy patches that are agnostic to the adversary strategies.\nExtensive experiments demonstrate that EAD substantially enhances robustness\nagainst a variety of patches within just a few steps through its action policy\nin safety-critical tasks (e.g., face recognition and object detection), without\ncompromising standard accuracy. Furthermore, due to the attack-agnostic\ncharacteristic, EAD facilitates excellent generalization to unseen attacks,\ndiminishing the averaged attack success rate by 95 percent across a range of\nunseen adversarial attacks.",
      "tldr_zh": "该研究提出 Embodied Active Defense (EAD)，一种主动防御策略，利用 recurrent feedback 机制来对抗深度神经网络中的 adversarial patches，尤其在动态 3D 环境。EAD 包括感知模块和策略模块，通过循环处理信念和观察，实现对目标对象的逐步理解和战略行动，从而主动调整环境信息以抵御误导性补丁。为优化学习，系统采用可微环境动态近似和攻击无关的补丁训练。实验结果显示，EAD 在人脸识别和物体检测等安全关键任务中显著提升鲁棒性，仅需几步即可将攻击成功率降低 95%，并对未知 adversarial attacks 表现出优秀泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "27pages",
      "pdf_url": "http://arxiv.org/pdf/2404.00540v1",
      "published_date": "2024-03-31 03:02:35 UTC",
      "updated_date": "2024-03-31 03:02:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:32:49.554907"
    },
    {
      "arxiv_id": "2404.01340v2",
      "title": "From Similarity to Superiority: Channel Clustering for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Jialin Chen",
        "Jan Eric Lenssen",
        "Aosong Feng",
        "Weihua Hu",
        "Matthias Fey",
        "Leandros Tassiulas",
        "Jure Leskovec",
        "Rex Ying"
      ],
      "abstract": "Time series forecasting has attracted significant attention in recent\ndecades. Previous studies have demonstrated that the Channel-Independent (CI)\nstrategy improves forecasting performance by treating different channels\nindividually, while it leads to poor generalization on unseen instances and\nignores potentially necessary interactions between channels. Conversely, the\nChannel-Dependent (CD) strategy mixes all channels with even irrelevant and\nindiscriminate information, which, however, results in oversmoothing issues and\nlimits forecasting accuracy. There is a lack of channel strategy that\neffectively balances individual channel treatment for improved forecasting\nperformance without overlooking essential interactions between channels.\nMotivated by our observation of a correlation between the time series model's\nperformance boost against channel mixing and the intrinsic similarity on a pair\nof channels, we developed a novel and adaptable Channel Clustering Module\n(CCM). CCM dynamically groups channels characterized by intrinsic similarities\nand leverages cluster information instead of individual channel identities,\ncombining the best of CD and CI worlds. Extensive experiments on real-world\ndatasets demonstrate that CCM can (1) boost the performance of CI and CD models\nby an average margin of 2.4% and 7.2% on long-term and short-term forecasting,\nrespectively; (2) enable zero-shot forecasting with mainstream time series\nforecasting models; (3) uncover intrinsic time series patterns among channels\nand improve interpretability of complex time series models.",
      "tldr_zh": "本研究针对时间序列预测中的通道处理策略问题，指出 Channel-Independent (CI) 策略虽能提升性能但忽略通道间互动，导致泛化能力差，而 Channel-Dependent (CD) 策略则因混合无关信息引发过度平滑问题。论文提出了一种新型 Channel Clustering Module (CCM)，通过动态聚类具有内在相似性的通道，利用集群信息平衡个体处理与互动需求，从而结合 CI 和 CD 的优势。实验在真实数据集上显示，CCM 平均提高了 CI 和 CD 模型的长期预测性能 2.4% 和短期预测性能 7.2%，并实现了零样本预测以及模型的可解释性提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.01340v2",
      "published_date": "2024-03-31 02:46:27 UTC",
      "updated_date": "2024-11-06 05:38:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:33:00.981710"
    },
    {
      "arxiv_id": "2404.00530v2",
      "title": "Comparing Bad Apples to Good Oranges: Aligning Large Language Models via Joint Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Hritik Bansal",
        "Ashima Suvarna",
        "Gantavya Bhatt",
        "Nanyun Peng",
        "Kai-Wei Chang",
        "Aditya Grover"
      ],
      "abstract": "A common technique for aligning large language models (LLMs) relies on\nacquiring human preferences by comparing multiple generations conditioned on a\nfixed context. This method, however, relies solely on pairwise comparisons,\nwhere the generations are evaluated within an identical context. While\neffective to such conditional preferences often fail to encompass the nuanced\nand multidimensional nature of human preferences. In this work, we revisit the\ntraditional paradigm of preference acquisition and propose a new axis based on\neliciting preferences jointly over the instruction-response pairs. Unlike prior\npreference optimizations, which are designed for conditional ranking protocols\n(e.g., DPO), we propose Joint Preference Optimization (JPO), a new preference\noptimization objective that upweights the joint probability of the chosen\ninstruction-response pair over the rejected instruction-response pair.\nInterestingly, LLMs trained with joint instruction-response preference data\nusing JPO outperform LLM trained with DPO by $5.2\\%$ and $3.3\\%$ win-rate for\nsummarization and open-ended dialogue datasets, respectively. Our findings\nreveal that joint preferences over instruction and response pairs can\nsignificantly enhance the alignment of LLMs by tapping into a broader spectrum\nof human preference elicitation. The data and code is available at\nhttps://github.com/Hritikbansal/dove.",
      "tldr_zh": "本研究指出，传统的大型语言模型（LLMs）对齐方法依赖于固定上下文下的成对比较（pairwise comparisons），但这无法充分捕捉人类偏好的多维性。作者提出Joint Preference Optimization (JPO)，一种新优化目标，通过提升被选中的指令-响应对相对于被拒绝对的联合概率，实现更全面的偏好学习。实验结果显示，使用JPO训练的LLMs在总结和开放对话数据集上，比DPO训练的模型分别提高了5.2%和3.3%的胜率。这一方法证明，基于指令-响应联合偏好的策略能显著提升LLMs的对齐效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 16 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.00530v2",
      "published_date": "2024-03-31 02:05:40 UTC",
      "updated_date": "2025-01-07 20:36:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:33:14.600692"
    },
    {
      "arxiv_id": "2404.00526v1",
      "title": "The Emotional Impact of Game Duration: A Framework for Understanding Player Emotions in Extended Gameplay Sessions",
      "title_zh": "翻译失败",
      "authors": [
        "Anoop Kumar",
        "Suresh Dodda",
        "Navin Kamuni",
        "Venkata Sai Mahesh Vuppalapati"
      ],
      "abstract": "Video games have played a crucial role in entertainment since their\ndevelopment in the 1970s, becoming even more prominent during the lockdown\nperiod when people were looking for ways to entertain them. However, at that\ntime, players were unaware of the significant impact that playtime could have\non their feelings. This has made it challenging for designers and developers to\ncreate new games since they have to control the emotional impact that these\ngames will take on players. Thus, the purpose of this study is to look at how a\nplayer's emotions are affected by the duration of the game. In order to achieve\nthis goal, a framework for emotion detection is created. According to the\nexperiment's results, the volunteers' general ability to express emotions\nincreased from 20 to 60 minutes. In comparison to shorter gameplay sessions,\nthe experiment found that extended gameplay sessions did significantly affect\nthe player's emotions. According to the results, it was recommended that in\norder to lessen the potential emotional impact that playing computer and video\ngames may have in the future, game producers should think about creating\nshorter, entertaining games.",
      "tldr_zh": "本研究探讨了游戏时长对玩家情感的影响，提出一个framework来理解延长游戏时长如何改变玩家的情绪体验。研究通过实验测试志愿者，发现游戏时长从20到60分钟内，玩家的情感表达能力显著增加。最终结果表明，较长的gameplay sessions会强化情感影响，因此建议游戏开发者设计更短、更娱乐性的游戏，以减轻潜在的负面效果。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00526v1",
      "published_date": "2024-03-31 02:01:05 UTC",
      "updated_date": "2024-03-31 02:01:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:33:25.798205"
    },
    {
      "arxiv_id": "2404.07225v1",
      "title": "Unveiling the Impact of Macroeconomic Policies: A Double Machine Learning Approach to Analyzing Interest Rate Effects on Financial Markets",
      "title_zh": "翻译失败",
      "authors": [
        "Anoop Kumar",
        "Suresh Dodda",
        "Navin Kamuni",
        "Rajeev Kumar Arora"
      ],
      "abstract": "This study examines the effects of macroeconomic policies on financial\nmarkets using a novel approach that combines Machine Learning (ML) techniques\nand causal inference. It focuses on the effect of interest rate changes made by\nthe US Federal Reserve System (FRS) on the returns of fixed income and equity\nfunds between January 1986 and December 2021. The analysis makes a distinction\nbetween actively and passively managed funds, hypothesizing that the latter are\nless susceptible to changes in interest rates. The study contrasts gradient\nboosting and linear regression models using the Double Machine Learning (DML)\nframework, which supports a variety of statistical learning techniques. Results\nindicate that gradient boosting is a useful tool for predicting fund returns;\nfor example, a 1% increase in interest rates causes an actively managed fund's\nreturn to decrease by -11.97%. This understanding of the relationship between\ninterest rates and fund performance provides opportunities for additional\nresearch and insightful, data-driven advice for fund managers and investors",
      "tldr_zh": "这篇论文采用 Double Machine Learning (DML) 框架，结合机器学习技术和因果推断，分析了美联储利率变化对金融市场的影响，焦点在于1986年1月至2021年12月间固定收益和股权基金的回报，并比较主动和被动管理基金的敏感性。研究对比了 gradient boosting 和 linear regression 模型，结果显示利率上升1%会导致主动管理基金回报下降11.97%，而被动管理基金相对不敏感。该方法为基金经理和投资者提供数据驱动的决策建议，并为进一步探索宏观政策影响打开新研究机会。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07225v1",
      "published_date": "2024-03-31 01:55:21 UTC",
      "updated_date": "2024-03-31 01:55:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:33:37.765814"
    },
    {
      "arxiv_id": "2404.02923v1",
      "title": "An Unsupervised Adversarial Autoencoder for Cyber Attack Detection in Power Distribution Grids",
      "title_zh": "翻译失败",
      "authors": [
        "Mehdi Jabbari Zideh",
        "Mohammad Reza Khalghani",
        "Sarika Khushalani Solanki"
      ],
      "abstract": "Detection of cyber attacks in smart power distribution grids with unbalanced\nconfigurations poses challenges due to the inherent nonlinear nature of these\nuncertain and stochastic systems. It originates from the intermittent\ncharacteristics of the distributed energy resources (DERs) generation and load\nvariations. Moreover, the unknown behavior of cyber attacks, especially false\ndata injection attacks (FDIAs) in the distribution grids with complex temporal\ncorrelations and the limited amount of labeled data increases the vulnerability\nof the grids and imposes a high risk in the secure and reliable operation of\nthe grids. To address these challenges, this paper proposes an unsupervised\nadversarial autoencoder (AAE) model to detect FDIAs in unbalanced power\ndistribution grids integrated with DERs, i.e., PV systems and wind generation.\nThe proposed method utilizes long short-term memory (LSTM) in the structure of\nthe autoencoder to capture the temporal dependencies in the time-series\nmeasurements and leverages the power of generative adversarial networks (GANs)\nfor better reconstruction of the input data. The advantage of the proposed\ndata-driven model is that it can detect anomalous points for the system\noperation without reliance on abstract models or mathematical representations.\nTo evaluate the efficacy of the approach, it is tested on IEEE 13-bus and\n123-bus systems with historical meteorological data (wind speed, ambient\ntemperature, and solar irradiance) as well as historical real-world load data\nunder three types of data falsification functions. The comparison of the\ndetection results of the proposed model with other unsupervised learning\nmethods verifies its superior performance in detecting cyber attacks in\nunbalanced power distribution grids.",
      "tldr_zh": "本论文针对智能电力分配网格中网络攻击（如False Data Injection Attacks, FDIAs）的检测问题，提出了一种无监督Adversarial Autoencoder (AAE)模型，以应对系统非线性、分布式能源资源(DERs)的间歇性和标签数据有限的挑战。该模型整合Long Short-Term Memory (LSTM)来捕捉时间序列数据的时序依赖，并利用Generative Adversarial Networks (GANs)提升输入数据的重构能力，从而实现无须依赖抽象模型的异常检测。在IEEE 13-bus和123-bus系统上的实验中，该方法使用历史气象和负载数据进行测试，与其他无监督学习方法相比，检测性能显著提升，验证了其在不平衡电力网格中的优越性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.02923v1",
      "published_date": "2024-03-31 01:20:01 UTC",
      "updated_date": "2024-03-31 01:20:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:33:50.373899"
    },
    {
      "arxiv_id": "2404.01339v1",
      "title": "Humane Speech Synthesis through Zero-Shot Emotion and Disfluency Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Rohan Chaudhury",
        "Mihir Godbole",
        "Aakash Garg",
        "Jinsil Hwaryoung Seo"
      ],
      "abstract": "Contemporary conversational systems often present a significant limitation:\ntheir responses lack the emotional depth and disfluent characteristic of human\ninteractions. This absence becomes particularly noticeable when users seek more\npersonalized and empathetic interactions. Consequently, this makes them seem\nmechanical and less relatable to human users. Recognizing this gap, we embarked\non a journey to humanize machine communication, to ensure AI systems not only\ncomprehend but also resonate. To address this shortcoming, we have designed an\ninnovative speech synthesis pipeline. Within this framework, a cutting-edge\nlanguage model introduces both human-like emotion and disfluencies in a\nzero-shot setting. These intricacies are seamlessly integrated into the\ngenerated text by the language model during text generation, allowing the\nsystem to mirror human speech patterns better, promoting more intuitive and\nnatural user interactions. These generated elements are then adeptly\ntransformed into corresponding speech patterns and emotive sounds using a\nrule-based approach during the text-to-speech phase. Based on our experiments,\nour novel system produces synthesized speech that's almost indistinguishable\nfrom genuine human communication, making each interaction feel more personal\nand authentic.",
      "tldr_zh": "本研究针对现有对话系统的机械化问题，提出了一种创新语音合成管道，通过先进的语言模型在 zero-shot 设置下生成人类化的情感和 disfluencies，使生成的文本更贴近自然对话。系统在文本生成阶段无缝整合这些元素，并在文本到语音（TTS）阶段使用规则-based 方法转换为相应的语音模式和情感声音。实验结果表明，该系统产生的合成语音几乎与真实人类交流无异，大大提升了用户互动的个性化与真实感。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 1 figure, for associated code and media files, see\n  https://github.com/Rohan-Chaudhury/Humane-Speech-Synthesis-through-Zero-Shot-Emotion-and-Disfluency-Generation",
      "pdf_url": "http://arxiv.org/pdf/2404.01339v1",
      "published_date": "2024-03-31 00:38:02 UTC",
      "updated_date": "2024-03-31 00:38:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:34:01.125122"
    },
    {
      "arxiv_id": "2404.00505v2",
      "title": "Transfer Learning with Reconstruction Loss",
      "title_zh": "基于重构损失的迁移学习",
      "authors": [
        "Wei Cui",
        "Wei Yu"
      ],
      "abstract": "In most applications of utilizing neural networks for mathematical\noptimization, a dedicated model is trained for each specific optimization\nobjective. However, in many scenarios, several distinct yet correlated\nobjectives or tasks often need to be optimized on the same set of problem\ninputs. Instead of independently training a different neural network for each\nproblem separately, it would be more efficient to exploit the correlations\nbetween these objectives and to train multiple neural network models with\nshared model parameters and feature representations. To achieve this, this\npaper first establishes the concept of common information: the shared knowledge\nrequired for solving the correlated tasks, then proposes a novel approach for\nmodel training by adding into the model an additional reconstruction stage\nassociated with a new reconstruction loss. This loss is for reconstructing the\ncommon information starting from a selected hidden layer in the model. The\nproposed approach encourages the learned features to be general and\ntransferable, and therefore can be readily used for efficient transfer\nlearning. For numerical simulations, three applications are studied: transfer\nlearning on classifying MNIST handwritten digits, the device-to-device wireless\nnetwork power allocation, and the multiple-input-single-output network downlink\nbeamforming and localization. Simulation results suggest that the proposed\napproach is highly efficient in data and model complexity, is resilient to\nover-fitting, and has competitive performances.",
      "tldr_zh": "本论文提出了一种利用重建损失（reconstruction loss）的迁移学习（transfer learning）方法，针对多个相关优化任务，避免为每个任务独立训练神经网络，而是通过共享模型参数和特征表示来提高效率。首先，论文定义了“common information”（共享知识），并在模型中添加重建阶段，从选定隐藏层重建此信息，从而鼓励学习通用的、可转移特征。在实验中，该方法应用于 MNIST 手写数字分类、无线网络功率分配以及多输入单输出（MISO）网络的下行波束成形和定位，结果显示它在数据和模型复杂度上高效、抗过拟合，且性能与基准模型竞争。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 5 figures. To appear in IEEE Transactions on Machine\n  Learning in Communications and Networking (TMLCN)",
      "pdf_url": "http://arxiv.org/pdf/2404.00505v2",
      "published_date": "2024-03-31 00:22:36 UTC",
      "updated_date": "2024-04-12 00:16:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T20:34:13.547634"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 46,
  "processed_papers_count": 46,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T20:34:45.925382"
}