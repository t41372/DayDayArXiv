{
  "date": "2024-06-22",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-22 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 56 篇论文，主要聚焦 AI 模型的安全性、效率优化和实际应用领域，如多模态语言模型的幻觉检测、LLM 在时间序列预测中的表现，以及机器人和医疗领域的创新。其中，令人印象深刻的是 MOSSBench（探讨 MLLM 的过敏反应）和 Fair Clustering（由 John Dickerson 等知名学者撰写），这些论文揭示了 AI 的潜在风险和改进方向。\n\n下面，我挑选了其中最具话题度和影响力的论文进行简要讨论，先从 AI 和 LLM 相关主题入手，再聊机器人、医疗和其他应用。其他较基础或技术细节较少的论文（如某些数据集分析或小规模优化）将快速掠过，以控制篇幅。\n\n### AI 和 LLM 相关\n1. **MOSSBench: Is Your Multimodal Language Model Oversensitive to Safe Queries?（中文：你的多模态语言模型对安全查询是否过度敏感？）**  \n   这篇论文由 Xirui Li 和 Cho-Jui Hsieh 等作者提出，构建了 MOSSBench 基准测试套件，评估多模态大型语言模型（MLLM）的过度敏感问题（如对无害查询的拒绝率高达 76%）。主要贡献是识别了 Exaggerated Risk 等触发因素，并发现更安全的模型可能更保守，强调改进 MLLM 的安全机制以提升可靠性。\n\n2. **Fair Clustering: Critique, Caveats, and Future Directions（中文：公平聚类：批评、警告和未来方向）**  \n   John Dickerson 和 Jamie Morgenstern 等知名学者撰写，批判现有公平聚类算法的局限，如缺乏清晰效用表征和下游影响。论文发现这些算法可能降低社会福利，并提出未来研究步骤，如更全面的评估框架。该工作在 AI 公平性领域有重要启发。\n\n3. **RuleR: Improving LLM Controllability by Rule-based Data Recycling（中文：RuleR：通过基于规则的数据回收提升大型语言模型的可控性）**  \n   Tianyi Zhou 等作者开发了 RuleR 方法，通过规则编辑增强数据集，实现 LLM 的自对齐训练。主要发现是，该方法在保持一般指令遵循能力的同时，提高了模型响应可控性，实验显示在多任务上表现出色。\n\n4. **Semantic Entropy Probes: Robust and Cheap Hallucination Detection in LLMs（中文：语义熵探针：用于大型语言模型的鲁棒且低成本幻觉检测）**  \n   Yarin Gal 等作者提出语义熵探针（SEPs），从单一生成中近似计算语义不确定性，用于检测 LLM 幻觉。主要贡献是减少计算开销，同时保持高检测性能，适用于实时应用。\n\n5. **Can LLMs Generate Visualizations with Dataless Prompts?（中文：大型语言模型能用无数据提示生成可视化吗？）**  \n   Klaus Mueller 等作者评估 GPT-3 和 GPT-4 生成数据可视化的能力。论文发现，模型在无数据提示下能产生合理可视化，但与专家标准仍有差距，强调 LLM 在数据驱动任务中的潜力与局限。\n\n6. **The Music Maestro or The Musically Challenged, A Massive Music Evaluation Benchmark for Large Language Models（中文：音乐大师还是音乐挑战者：大型语言模型的音乐评估基准）**  \n   Hai Zhao 等作者创建了 ZIQI-Eval 基准，包含 14,000+ 音乐相关问题，评估 LLM 的音乐能力。发现现有 LLM 在音乐任务上表现不佳，需进一步优化。\n\n### 机器人和自动驾驶\n7. **Optimizing LaneSegNet for Real-Time Lane Topology Prediction in Autonomous Vehicles（中文：优化 LaneSegNet 用于自动驾驶车辆的实时车道拓扑预测）**  \n   这篇论文优化了 LaneSegNet 架构，使用 ResNet-50 和注意力机制，提高了车道预测的准确性和效率。关键发现是，通过调整编码器-解码器比例，实现训练时间减少 22.3% 和精度提升 23.7%，适用于资源有限的自动驾驶系统。\n\n8. **SEDMamba: Enhancing Selective State Space Modelling with Bottleneck Mechanism and Fine-to-Coarse Temporal Fusion for Efficient Error Detection in Robot-Assisted Surgery（中文：SEDMamba：通过瓶颈机制和细到粗时序融合增强选择性状态空间建模，用于机器人辅助手术的错误检测）**  \n   Danail Stoyanov 等作者提出 SEDMamba 模型，用于手术视频错误检测。论文贡献包括瓶颈机制降低计算复杂度，以及细到粗时序融合捕获长序列依赖，实验显示 AUC 和 AP 均有显著提升。\n\n### 医疗和应用\n9. **Regulating AI Adaptation: An Analysis of AI Medical Device Updates（中文：调节 AI 适应性：对 AI 医疗设备更新的分析）**  \n   James Zou 等知名学者分析 FDA 批准的 AI 医疗设备更新。发现只有不到 2% 的设备通过新数据重新训练，但这可缓解模型性能下降（AUC 恢复 0.23），并讨论监管政策对自适应 AI 的影响。\n\n10. **Real-time Speech Summarization for Medical Conversations（中文：医疗对话的实时语音总结）**  \n    Truong-Son Hy 等作者构建了 VietMed-Sum 数据集，并开发实时语音总结系统。论文的主要发现是，该系统能在对话中生成本地和全局总结，减少计算成本，并提供基线模型结果。\n\n11. **AI-based Drone Assisted Human Rescue in Disaster Environments: Challenges and Opportunities（中文：基于 AI 的无人机辅助人类救援：在灾害环境中的挑战与机会）**  \n    这篇综述讨论了无人机在灾害中的人声检测应用。论文强调 AI 和深度学习（如 CNN）用于过滤噪声和定位声音源，但指出挑战如环境干扰，建议未来方向。\n\n### 其他值得注意\n12. **Beyond the Doors of Perception: Vision Transformers Represent Relations Between Objects（中文：超越感知之门：视觉Transformer表示物体间关系）**  \n    Brenden M. Lake 等作者研究视觉 Transformer 在关系推理中的机制。发现模型通过离散处理阶段学习抽象关系，但阶段性失败可能导致泛化问题。\n\n13. **BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions（中文：BigCodeBench：针对多样函数调用和复杂指令的代码生成基准）**  \n    这篇论文由 BigCode 社区创建，引入 BigCodeBench 基准测试 LLM 的代码生成能力。关键发现是，模型在处理复杂指令时准确率仅 60%，远低于人类 97%，强调改进代码生成的需求。\n\n其他论文如那些专注于特定数据集或基础优化的（如 An Efficient NAS-based Approach），由于影响力较小，我仅快速提及：它们提供了技术改进，如 NAS 在不平衡数据集上的应用，但未有突破性发现，故不展开讨论。\n\n总之，今天的 arXiv 论文突显了 AI 模型在安全、效率和实际应用中的挑战与机遇，建议关注 LLM 和多模态领域的最新进展，以推动更可靠的 AI 系统。保持关注，下一天见！",
  "papers": [
    {
      "arxiv_id": "2406.15961v2",
      "title": "Automating Transfer of Robot Task Plans using Functorial Data Migrations",
      "title_zh": "翻译失败",
      "authors": [
        "Angeline Aguinaldo",
        "Evan Patterson",
        "William Regli"
      ],
      "abstract": "This paper introduces a novel approach to ontology-based robot plan transfer\nby leveraging functorial data migrations, a structured mapping method derived\nfrom category theory. Functors provide structured maps between planning domain\nontologies which enables the transfer of task plans without the need for\nreplanning. Unlike methods tailored to specific plans, our framework applies\nuniversally within the source domain once a structured map is defined. We\ndemonstrate this approach by transferring a task plan from the canonical\nBlocksworld domain to one compatible with the AI2-THOR Kitchen environment.\nAdditionally, we discuss practical limitations, propose benchmarks for\nevaluating symbolic plan transfer methods, and outline future directions for\nscaling this approach.",
      "tldr_zh": "这篇论文提出了一种新方法，使用functorial data migrations（基于category theory的结构化映射）来自动化ontology-based robot plan transfer，从而实现任务计划在不同规划域本体间的转移，而无需重新规划。该框架的优势在于，一旦定义了结构化映射，即可在源域内普遍应用，与特定计划定制方法不同。作者通过从Blocksworld域到AI2-THOR Kitchen环境的实际演示验证了这一方法，并讨论了实际限制、评估基准以及未来扩展方向。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "math.CT",
        "18-08",
        "I.2.9"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15961v2",
      "published_date": "2024-06-22 23:35:32 UTC",
      "updated_date": "2025-04-12 21:06:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:28:58.399976"
    },
    {
      "arxiv_id": "2406.15960v1",
      "title": "Fair Clustering: Critique, Caveats, and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "John Dickerson",
        "Seyed A. Esmaeili",
        "Jamie Morgenstern",
        "Claire Jie Zhang"
      ],
      "abstract": "Clustering is a fundamental problem in machine learning and operations\nresearch. Therefore, given the fact that fairness considerations have become of\nparamount importance in algorithm design, fairness in clustering has received\nsignificant attention from the research community. The literature on fair\nclustering has resulted in a collection of interesting fairness notions and\nelaborate algorithms. In this paper, we take a critical view of fair\nclustering, identifying a collection of ignored issues such as the lack of a\nclear utility characterization and the difficulty in accounting for the\ndownstream effects of a fair clustering algorithm in machine learning settings.\nIn some cases, we demonstrate examples where the application of a fair\nclustering algorithm can have significant negative impacts on social welfare.\nWe end by identifying a collection of steps that would lead towards more\nimpactful research in fair clustering.",
      "tldr_zh": "这篇论文对 fair clustering 进行了批判性审视，指出现有研究忽略了关键问题，如缺乏清晰的效用表征和难以评估算法在机器学习环境中的下游影响。作者通过具体例子展示了 fair clustering 算法可能导致社会福利的负面后果，例如加剧不公平分配。论文最终提出了未来研究的方向，包括加强效用分析和考虑更广泛的社会影响，以推动更具影响力的公平聚类工作。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15960v1",
      "published_date": "2024-06-22 23:34:53 UTC",
      "updated_date": "2024-06-22 23:34:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:29:08.678038"
    },
    {
      "arxiv_id": "2406.17806v1",
      "title": "MOSSBench: Is Your Multimodal Language Model Oversensitive to Safe Queries?",
      "title_zh": "MOSSBench: 你的多模态语言模型是否对安全查询过度敏感？",
      "authors": [
        "Xirui Li",
        "Hengguang Zhou",
        "Ruochen Wang",
        "Tianyi Zhou",
        "Minhao Cheng",
        "Cho-Jui Hsieh"
      ],
      "abstract": "Humans are prone to cognitive distortions -- biased thinking patterns that\nlead to exaggerated responses to specific stimuli, albeit in very different\ncontexts. This paper demonstrates that advanced Multimodal Large Language\nModels (MLLMs) exhibit similar tendencies. While these models are designed to\nrespond queries under safety mechanism, they sometimes reject harmless queries\nin the presence of certain visual stimuli, disregarding the benign nature of\ntheir contexts. As the initial step in investigating this behavior, we identify\nthree types of stimuli that trigger the oversensitivity of existing MLLMs:\nExaggerated Risk, Negated Harm, and Counterintuitive Interpretation. To\nsystematically evaluate MLLMs' oversensitivity to these stimuli, we propose the\nMultimodal OverSenSitivity Benchmark (MOSSBench). This toolkit consists of 300\nmanually collected benign multimodal queries, cross-verified by third-party\nreviewers (AMT). Empirical studies using MOSSBench on 20 MLLMs reveal several\ninsights: (1). Oversensitivity is prevalent among SOTA MLLMs, with refusal\nrates reaching up to 76% for harmless queries. (2). Safer models are more\noversensitive: increasing safety may inadvertently raise caution and\nconservatism in the model's responses. (3). Different types of stimuli tend to\ncause errors at specific stages -- perception, intent reasoning, and safety\njudgement -- in the response process of MLLMs. These findings highlight the\nneed for refined safety mechanisms that balance caution with contextually\nappropriate responses, improving the reliability of MLLMs in real-world\napplications. We make our project available at\nhttps://turningpoint-ai.github.io/MOSSBench/.",
      "tldr_zh": "该研究揭示了多模态大语言模型(MLLMs)存在过度敏感问题，即在Exaggerated Risk、Negated Harm和Counterintuitive Interpretation等视觉刺激下，模型可能拒绝无害查询。\n为了系统评估这一行为，研究者开发了MOSSBench基准，该基准包括300个手动收集并第三方验证的良性多模态查询，并在20个MLLMs上进行实证测试。\n结果显示，过度敏感在SOTA MLLMs中普遍存在，拒绝率最高达76%；更安全的模型往往更易过度敏感；不同刺激类型会导致模型在感知、意图推理和安全判断阶段出现错误。\n这些发现强调了需要优化安全机制，以实现谨慎与上下文响应的平衡，提升MLLMs在实际应用中的可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17806v1",
      "published_date": "2024-06-22 23:26:07 UTC",
      "updated_date": "2024-06-22 23:26:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:29:34.517074"
    },
    {
      "arxiv_id": "2406.17805v1",
      "title": "Can LLMs Generate Visualizations with Dataless Prompts?",
      "title_zh": "翻译失败",
      "authors": [
        "Darius Coelho",
        "Harshit Barot",
        "Naitik Rathod",
        "Klaus Mueller"
      ],
      "abstract": "Recent advancements in large language models have revolutionized information\naccess, as these models harness data available on the web to address complex\nqueries, becoming the preferred information source for many users. In certain\ncases, queries are about publicly available data, which can be effectively\nanswered with data visualizations. In this paper, we investigate the ability of\nlarge language models to provide accurate data and relevant visualizations in\nresponse to such queries. Specifically, we investigate the ability of GPT-3 and\nGPT-4 to generate visualizations with dataless prompts, where no data\naccompanies the query. We evaluate the results of the models by comparing them\nto visualization cheat sheets created by visualization experts.",
      "tldr_zh": "本研究探讨了大语言模型（LLMs）是否能够通过无数据提示（dataless prompts）生成准确的数据和相关可视化，针对涉及公开数据的查询。研究团队评估了GPT-3和GPT-4模型的性能，将其生成结果与专家创建的可视化备忘单进行比较。结果表明，LLMs在这种场景下表现出一定潜力，但也暴露了准确性与相关性的局限性，为提升模型的可视化能力提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17805v1",
      "published_date": "2024-06-22 22:59:09 UTC",
      "updated_date": "2024-06-22 22:59:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:29:33.479215"
    },
    {
      "arxiv_id": "2406.15955v3",
      "title": "Beyond the Doors of Perception: Vision Transformers Represent Relations Between Objects",
      "title_zh": "超越感知之门：视觉变压器表示对象之间的关系",
      "authors": [
        "Michael A. Lepori",
        "Alexa R. Tartaglini",
        "Wai Keen Vong",
        "Thomas Serre",
        "Brenden M. Lake",
        "Ellie Pavlick"
      ],
      "abstract": "Though vision transformers (ViTs) have achieved state-of-the-art performance\nin a variety of settings, they exhibit surprising failures when performing\ntasks involving visual relations. This begs the question: how do ViTs attempt\nto perform tasks that require computing visual relations between objects? Prior\nefforts to interpret ViTs tend to focus on characterizing relevant low-level\nvisual features. In contrast, we adopt methods from mechanistic\ninterpretability to study the higher-level visual algorithms that ViTs use to\nperform abstract visual reasoning. We present a case study of a fundamental,\nyet surprisingly difficult, relational reasoning task: judging whether two\nvisual entities are the same or different. We find that pretrained ViTs\nfine-tuned on this task often exhibit two qualitatively different stages of\nprocessing despite having no obvious inductive biases to do so: 1) a perceptual\nstage wherein local object features are extracted and stored in a disentangled\nrepresentation, and 2) a relational stage wherein object representations are\ncompared. In the second stage, we find evidence that ViTs can learn to\nrepresent somewhat abstract visual relations, a capability that has long been\nconsidered out of reach for artificial neural networks. Finally, we demonstrate\nthat failures at either stage can prevent a model from learning a generalizable\nsolution to our fairly simple tasks. By understanding ViTs in terms of discrete\nprocessing stages, one can more precisely diagnose and rectify shortcomings of\nexisting and future models.",
      "tldr_zh": "虽然 Vision Transformers (ViTs) 在多种任务中表现出色，但它们在处理涉及对象之间视觉关系的任务时存在明显失败。本研究采用 mechanistic interpretability 方法，分析 ViTs 的高级视觉算法，通过一个判断两个视觉实体是否相同或不同的案例研究，发现 ViTs 在微调后通常涉及两个阶段：感知阶段提取并存储局部对象特征，以及关系阶段比较对象表示并学习抽象视觉关系。实验结果表明，如果任何阶段出现问题，模型可能无法实现可泛化的解决方案，从而为更精确诊断和改进 ViTs 提供重要见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15955v3",
      "published_date": "2024-06-22 22:43:10 UTC",
      "updated_date": "2024-11-22 19:16:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:29:46.613219"
    },
    {
      "arxiv_id": "2406.15946v2",
      "title": "Optimizing LaneSegNet for Real-Time Lane Topology Prediction in Autonomous Vehicles",
      "title_zh": "针对自动驾驶车辆的实时车道拓扑预测优化 LaneSegNet",
      "authors": [
        "William Stevens",
        "Vishal Urs",
        "Karthik Selvaraj",
        "Gabriel Torres",
        "Gaurish Lakhanpal"
      ],
      "abstract": "With the increasing prevalence of autonomous vehicles, it is essential for\ncomputer vision algorithms to accurately assess road features in real-time.\nThis study explores the LaneSegNet architecture, a new approach to lane\ntopology prediction which integrates topological information with lane-line\ndata to provide a more contextual understanding of road environments. The\nLaneSegNet architecture includes a feature extractor, lane encoder, lane\ndecoder, and prediction head, leveraging components from ResNet-50, BEVFormer,\nand various attention mechanisms. We experimented with optimizations to the\nLaneSegNet architecture through feature extractor modification and transformer\nencoder-decoder stack modification. We found that modifying the encoder and\ndecoder stacks offered an interesting tradeoff between training time and\nprediction accuracy, with certain combinations showing promising results. Our\nimplementation, trained on a single NVIDIA Tesla A100 GPU, found that a 2:4\nratio reduced training time by 22.3% with only a 7.1% drop in mean average\nprecision, while a 4:8 ratio increased training time by only 11.1% but improved\nmean average precision by a significant 23.7%. These results indicate that\nstrategic hyperparameter tuning can yield substantial improvements depending on\nthe resources of the user. This study provides valuable insights for optimizing\nLaneSegNet according to available computation power, making it more accessible\nfor users with limited resources and increasing the capabilities for users with\nmore powerful resources.",
      "tldr_zh": "这篇论文优化了 LaneSegNet 架构，用于自动驾驶车辆的实时车道拓扑预测，旨在整合拓扑信息和车道线数据以提供更全面的道路环境理解。LaneSegNet 包括特征提取器、车道编码器、车道解码器和预测头，基于 ResNet-50、BEVFormer 和注意力机制构建，通过修改特征提取器和 transformer 编码器-解码器堆栈进行优化。实验结果显示，2:4 比率的修改减少了训练时间 22.3%，mean average precision (mAP) 只下降 7.1%；而 4:8 比率增加了训练时间 11.1%，但 mAP 提高了 23.7%。这些优化为根据用户计算资源进行战略性超参数调整提供了见解，提升了 LaneSegNet 的可访问性和性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.15946v2",
      "published_date": "2024-06-22 21:49:12 UTC",
      "updated_date": "2024-07-30 20:15:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:30:00.985149"
    },
    {
      "arxiv_id": "2406.15940v1",
      "title": "Beyond Individual Facts: Investigating Categorical Knowledge Locality of Taxonomy and Meronomy Concepts in GPT Models",
      "title_zh": "翻译失败",
      "authors": [
        "Christopher Burger",
        "Yifan Hu",
        "Thai Le"
      ],
      "abstract": "The location of knowledge within Generative Pre-trained Transformer\n(GPT)-like models has seen extensive recent investigation. However, much of the\nwork is focused towards determining locations of individual facts, with the end\ngoal being the editing of facts that are outdated, erroneous, or otherwise\nharmful, without the time and expense of retraining the entire model. In this\nwork, we investigate a broader view of knowledge location, that of concepts or\nclusters of related information, instead of disparate individual facts. To do\nthis, we first curate a novel dataset, called DARC, that includes a total of 34\nconcepts of ~120K factual statements divided into two types of hierarchical\ncategories, namely taxonomy and meronomy. Next, we utilize existing causal\nmediation analysis methods developed for determining regions of importance for\nindividual facts and apply them to a series of related categories to provide\ndetailed investigation into whether concepts are associated with distinct\nregions within these models. We find that related categories exhibit similar\nareas of importance in contrast to less similar categories. However,\nfine-grained localization of individual category subsets to specific regions is\nnot apparent.",
      "tldr_zh": "本研究扩展了知识定位的调查范围，从GPT模型中单个事实转向taxonomy（分类）和meronomy（部分整体关系）等概念集群，旨在探索这些概念的局部性。研究者创建了新数据集DARC，包含34个概念约12万条事实，并应用因果中介分析（causal mediation analysis）方法分析相关类别在模型中的重要区域。结果显示，相似类别表现出相似的关键区域，但无法实现细粒度的特定区域定位，这为改进模型知识编辑提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 23 figures, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.15940v1",
      "published_date": "2024-06-22 21:12:57 UTC",
      "updated_date": "2024-06-22 21:12:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:30:11.639034"
    },
    {
      "arxiv_id": "2406.15938v4",
      "title": "RuleR: Improving LLM Controllability by Rule-based Data Recycling",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Li",
        "Han Chen",
        "Chenguang Wang",
        "Dang Nguyen",
        "Dianqi Li",
        "Tianyi Zhou"
      ],
      "abstract": "Large language models (LLMs) still lack delicate controllability over their\nresponses, which is critical to enhancing their performance and the user\nexperience. However, curating supervised fine-tuning (SFT) datasets to improve\nLLM controllability usually relies on human experts or proprietary LLMs, which\nrequires additional costs. To bridge this gap, we propose Rule-based Data\nRecycling (RuleR), a data augmentation method incorporating multiple\nconstraints into the original data samples according to predefined rules, which\ncreates new training tasks to consolidate the controllability of LLMs. Instead\nof creating new data from scratch, RuleR \"recycles\" existing data by simply\napplying rule-based edits to their responses and appending the\nrule-instructions in their original instructions. Experimental results\ndemonstrate RuleR's effectiveness in improving LLM controllability while\nmaintaining general instruction-following capabilities.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)的响应可控性不足问题，提出了一种规则-based 数据回收方法RuleR，以提升模型性能和用户体验。RuleR通过预定义规则对现有数据样本进行编辑和约束，生成新训练任务，同时在原指令中附加规则指令，从而“回收”数据进行监督微调(SFT)，无需额外的人工或专有模型成本。实验结果显示，RuleR显著提高了LLMs的可控性，同时保持了模型的一般指令遵循能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL2025 main, Camera-ready",
      "pdf_url": "http://arxiv.org/pdf/2406.15938v4",
      "published_date": "2024-06-22 20:57:12 UTC",
      "updated_date": "2025-02-15 20:33:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:30:32.082975"
    },
    {
      "arxiv_id": "2406.15936v1",
      "title": "An Automated SQL Query Grading System Using An Attention-Based Convolutional Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Donald R. Schwartz",
        "Pablo Rivas"
      ],
      "abstract": "Grading SQL queries can be a time-consuming, tedious and challenging task,\nespecially as the number of student submissions increases. Several systems have\nbeen introduced in an attempt to mitigate these challenges, but those systems\nhave their own limitations. This paper describes our novel approach to\nautomating the process of grading SQL queries. Unlike previous approaches, we\nemploy a unique convolutional neural network architecture that employs a\nparameter-sharing approach for different machine learning tasks that enables\nthe architecture to induce different knowledge representations of the data to\nincrease its potential for understanding SQL statements.",
      "tldr_zh": "这篇论文提出了一种自动化 SQL 查询评分系统，以解决手动评分耗时、乏味且具有挑战性的问题。系统采用了一种基于注意力的卷积神经网络（Attention-Based Convolutional Neural Network）架构，通过参数共享（parameter-sharing）策略为不同机器学习任务生成独特的知识表示（knowledge representations），从而提升对 SQL 语句的理解和处理能力。与现有方法相比，该方法有望提高评分效率和准确性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.DB",
        "cs.LG",
        "I.2.6; H.2.3; K.3.2"
      ],
      "primary_category": "cs.CY",
      "comment": "12 pages, 8 figures, paper accepted at \"The 18th International\n  Conference on Frontiers in Education: Computer Science and Computer\n  Engineering\"",
      "pdf_url": "http://arxiv.org/pdf/2406.15936v1",
      "published_date": "2024-06-22 20:52:17 UTC",
      "updated_date": "2024-06-22 20:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:30:34.066723"
    },
    {
      "arxiv_id": "2406.15927v1",
      "title": "Semantic Entropy Probes: Robust and Cheap Hallucination Detection in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jannik Kossen",
        "Jiatong Han",
        "Muhammed Razzak",
        "Lisa Schut",
        "Shreshth Malik",
        "Yarin Gal"
      ],
      "abstract": "We propose semantic entropy probes (SEPs), a cheap and reliable method for\nuncertainty quantification in Large Language Models (LLMs). Hallucinations,\nwhich are plausible-sounding but factually incorrect and arbitrary model\ngenerations, present a major challenge to the practical adoption of LLMs.\nRecent work by Farquhar et al. (2024) proposes semantic entropy (SE), which can\ndetect hallucinations by estimating uncertainty in the space semantic meaning\nfor a set of model generations. However, the 5-to-10-fold increase in\ncomputation cost associated with SE computation hinders practical adoption. To\naddress this, we propose SEPs, which directly approximate SE from the hidden\nstates of a single generation. SEPs are simple to train and do not require\nsampling multiple model generations at test time, reducing the overhead of\nsemantic uncertainty quantification to almost zero. We show that SEPs retain\nhigh performance for hallucination detection and generalize better to\nout-of-distribution data than previous probing methods that directly predict\nmodel accuracy. Our results across models and tasks suggest that model hidden\nstates capture SE, and our ablation studies give further insights into the\ntoken positions and model layers for which this is the case.",
      "tldr_zh": "本文提出 Semantic Entropy Probes (SEPs)，一种廉价且可靠的方法，用于在 Large Language Models (LLMs) 中检测幻觉（hallucinations），通过直接从单个生成的隐藏状态近似 semantic entropy (SE)，从而避免了传统方法所需的多次采样和5-10倍计算开销。SEPs 简单易训练，并在幻觉检测中保持高性能，同时比之前的探测方法在分布外数据上泛化更好。研究结果表明，模型隐藏状态中捕获了 SE 信息，并通过消融研究揭示了特定 token 位置和模型层的关键作用，为高效的不确定性量化提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "First three authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2406.15927v1",
      "published_date": "2024-06-22 19:46:06 UTC",
      "updated_date": "2024-06-22 19:46:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:30:48.162567"
    },
    {
      "arxiv_id": "2407.16900v1",
      "title": "Regulating AI Adaptation: An Analysis of AI Medical Device Updates",
      "title_zh": "监管人工智能适应：对人工智能医疗设备更新的分析",
      "authors": [
        "Kevin Wu",
        "Eric Wu",
        "Kit Rodolfa",
        "Daniel E. Ho",
        "James Zou"
      ],
      "abstract": "While the pace of development of AI has rapidly progressed in recent years,\nthe implementation of safe and effective regulatory frameworks has lagged\nbehind. In particular, the adaptive nature of AI models presents unique\nchallenges to regulators as updating a model can improve its performance but\nalso introduce safety risks. In the US, the Food and Drug Administration (FDA)\nhas been a forerunner in regulating and approving hundreds of AI medical\ndevices. To better understand how AI is updated and its regulatory\nconsiderations, we systematically analyze the frequency and nature of updates\nin FDA-approved AI medical devices. We find that less than 2% of all devices\nreport having been updated by being re-trained on new data. Meanwhile, nearly a\nquarter of devices report updates in the form of new functionality and\nmarketing claims. As an illustrative case study, we analyze pneumothorax\ndetection models and find that while model performance can degrade by as much\nas 0.18 AUC when evaluated on new sites, re-training on site-specific data can\nmitigate this performance drop, recovering up to 0.23 AUC. However, we also\nobserved significant degradation on the original site after re-training using\ndata from new sites, providing insight from one example that challenges the\ncurrent one-model-fits-all approach to regulatory approvals. Our analysis\nprovides an in-depth look at the current state of FDA-approved AI device\nupdates and insights for future regulatory policies toward model updating and\nadaptive AI.",
      "tldr_zh": "该研究分析了 AI 医疗设备的更新及其监管挑战，聚焦于 FDA 批准的设备，发现不到 2% 的设备通过在新数据上重新训练来更新，而近四分之一的设备添加了新功能和营销声明。研究者通过系统审查 FDA 数据库并以气胸检测模型为例，表明模型性能在新站点可能下降 0.18 AUC，但通过站点特定数据重新训练可恢复 0.23 AUC，同时可能导致原站点性能显著恶化。总体而言，该分析揭示了当前 AI 适应性更新的问题，并为未来 FDA 监管政策提供重要见解，以支持更安全有效的 AI 部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.16900v1",
      "published_date": "2024-06-22 19:44:47 UTC",
      "updated_date": "2024-06-22 19:44:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:31:13.960742"
    },
    {
      "arxiv_id": "2406.15920v4",
      "title": "SEDMamba: Enhancing Selective State Space Modelling with Bottleneck Mechanism and Fine-to-Coarse Temporal Fusion for Efficient Error Detection in Robot-Assisted Surgery",
      "title_zh": "翻译失败",
      "authors": [
        "Jialang Xu",
        "Nazir Sirajudeen",
        "Matthew Boal",
        "Nader Francis",
        "Danail Stoyanov",
        "Evangelos Mazomenos"
      ],
      "abstract": "Automated detection of surgical errors can improve robotic-assisted surgery.\nDespite promising progress, existing methods still face challenges in capturing\nrich temporal context to establish long-term dependencies while maintaining\ncomputational efficiency. In this paper, we propose a novel hierarchical model\nnamed SEDMamba, which incorporates the selective state space model (SSM) into\nsurgical error detection, facilitating efficient long sequence modelling with\nlinear complexity. SEDMamba enhances selective SSM with a bottleneck mechanism\nand fine-to-coarse temporal fusion (FCTF) to detect and temporally localize\nsurgical errors in long videos. The bottleneck mechanism compresses and\nrestores features within their spatial dimension, thereby reducing\ncomputational complexity. FCTF utilizes multiple dilated 1D convolutional\nlayers to merge temporal information across diverse scale ranges, accommodating\nerrors of varying duration. Our work also contributes the first-of-its-kind,\nframe-level, in-vivo surgical error dataset to support error detection in real\nsurgical cases. Specifically, we deploy the clinically validated observational\nclinical human reliability assessment tool (OCHRA) to annotate the errors\nduring suturing tasks in an open-source radical prostatectomy dataset\n(SAR-RARP50). Experimental results demonstrate that our SEDMamba outperforms\nstate-of-the-art methods with at least 1.82% AUC and 3.80% AP performance gains\nwith significantly reduced computational complexity. The corresponding error\nannotations, code and models are released at\nhttps://github.com/wzjialang/SEDMamba.",
      "tldr_zh": "本研究提出SEDMamba，一种新型层次化模型，用于机器人辅助手术中的高效手术错误检测，通过整合selective state space model (SSM)实现线性复杂度的长序列建模。SEDMamba通过bottleneck mechanism压缩和恢复特征以降低计算复杂度，以及fine-to-coarse temporal fusion (FCTF)利用多层dilated 1D convolutional layers合并不同规模的时序信息，从而精确检测和定位错误。论文贡献了首个帧级别活体手术错误数据集，使用OCHRA工具标注了SAR-RARP50数据集中的缝合任务错误。实验结果显示，SEDMamba在AUC和AP上分别比现有方法提高了至少1.82%和3.80%，同时显著降低了计算复杂度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IEEE RA-L",
      "pdf_url": "http://arxiv.org/pdf/2406.15920v4",
      "published_date": "2024-06-22 19:20:35 UTC",
      "updated_date": "2024-11-29 20:34:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:31:14.204725"
    },
    {
      "arxiv_id": "2406.15906v1",
      "title": "OpticGAI: Generative AI-aided Deep Reinforcement Learning for Optical Networks Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Siyuan Li",
        "Xi Lin",
        "Yaju Liu",
        "Gaolei Li",
        "Jianhua Li"
      ],
      "abstract": "Deep Reinforcement Learning (DRL) is regarded as a promising tool for optical\nnetwork optimization. However, the flexibility and efficiency of current\nDRL-based solutions for optical network optimization require further\nimprovement. Currently, generative models have showcased their significant\nperformance advantages across various domains. In this paper, we introduce\nOpticGAI, the AI-generated policy design paradigm for optical networks. In\ndetail, it is implemented as a novel DRL framework that utilizes generative\nmodels to learn the optimal policy network. Furthermore, we assess the\nperformance of OpticGAI on two NP-hard optical network problems, Routing and\nWavelength Assignment (RWA) and dynamic Routing, Modulation, and Spectrum\nAllocation (RMSA), to show the feasibility of the AI-generated policy paradigm.\nSimulation results have shown that OpticGAI achieves the highest reward and the\nlowest blocking rate of both RWA and RMSA problems. OpticGAI poses a promising\ndirection for future research on generative AI-enhanced flexible optical\nnetwork optimization.",
      "tldr_zh": "该论文提出OpticGAI，一种结合生成AI和Deep Reinforcement Learning (DRL)的框架，用于提升光网络优化的灵活性和效率。具体而言，OpticGAI利用生成模型学习最优策略网络，并应用于两个NP-hard问题：Routing and Wavelength Assignment (RWA)和Routing, Modulation, and Spectrum Allocation (RMSA)。模拟结果显示，OpticGAI在这些问题上实现了最高的奖励和最低的阻塞率，为生成AI增强的光网络优化提供了富有前景的研究方向。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "Accepted by ACM SIGCOMM 2024 Workshop on Hot Topics in Optical\n  Technologies and Applications in Networking",
      "pdf_url": "http://arxiv.org/pdf/2406.15906v1",
      "published_date": "2024-06-22 17:59:50 UTC",
      "updated_date": "2024-06-22 17:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:31:29.206204"
    },
    {
      "arxiv_id": "2406.15890v1",
      "title": "Language Alignment via Nash-learning and Adaptive feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Ari Azarafrooz",
        "Farshid Faal"
      ],
      "abstract": "Recent research has shown the potential of Nash Learning via Human Feedback\nfor large language model alignment by incorporating the notion of a preference\nmodel in a minimax game setup. We take this idea further by casting the\nalignment as a mirror descent algorithm against the adaptive feedback of an\nimproved opponent, thereby removing the need for learning a preference model or\nthe existence of an annotated dataset altogether. The resulting algorithm,\nwhich we refer to as Language Alignment via Nash-learning and Adaptive feedback\n(LANA), is capable of self-alignment without the need for a human-annotated\npreference dataset. We support this statement with various experiments and\nmathematical discussion.",
      "tldr_zh": "该论文提出了一种名为 LANA（Language Alignment via Nash-learning and Adaptive feedback）的语言模型对齐方法，通过镜像下降算法（mirror descent）与自适应对手的反馈对抗，实现模型的自对齐过程。LANA 消除了对偏好模型的学习和人类标注数据集的需求，仅依赖于 Nash-learning 的框架来优化模型性能。实验结果和数学分析证实了该方法的有效性，为高效的语言模型对齐提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2024 Workshop on Models of Human Feedback for AI\n  Alignment, Vienna, Austria",
      "pdf_url": "http://arxiv.org/pdf/2406.15890v1",
      "published_date": "2024-06-22 16:55:21 UTC",
      "updated_date": "2024-06-22 16:55:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:31:47.097950"
    },
    {
      "arxiv_id": "2406.15888v2",
      "title": "Real-time Speech Summarization for Medical Conversations",
      "title_zh": "翻译失败",
      "authors": [
        "Khai Le-Duc",
        "Khai-Nguyen Nguyen",
        "Long Vo-Dang",
        "Truong-Son Hy"
      ],
      "abstract": "In doctor-patient conversations, identifying medically relevant information\nis crucial, posing the need for conversation summarization. In this work, we\npropose the first deployable real-time speech summarization system for\nreal-world applications in industry, which generates a local summary after\nevery N speech utterances within a conversation and a global summary after the\nend of a conversation. Our system could enhance user experience from a business\nstandpoint, while also reducing computational costs from a technical\nperspective. Secondly, we present VietMed-Sum which, to our knowledge, is the\nfirst speech summarization dataset for medical conversations. Thirdly, we are\nthe first to utilize LLM and human annotators collaboratively to create gold\nstandard and synthetic summaries for medical conversation summarization.\nFinally, we present baseline results of state-of-the-art models on VietMed-Sum.\nAll code, data (English-translated and Vietnamese) and models are available\nonline: https://github.com/leduckhai/MultiMed/tree/master/VietMed-Sum",
      "tldr_zh": "这篇论文提出了第一个可部署的Real-time Speech Summarization系统，用于医疗对话中，每N个语音片段后生成本地摘要，并在对话结束时生成全局摘要，从而提升用户体验并降低计算成本。研究者构建了VietMed-Sum，这是首个医疗对话语音摘要数据集，并首次采用LLM和人类标注者协作方法创建金标准和合成摘要。最后，他们提供了在VietMed-Sum数据集上最先进模型的基线结果，并公开了所有代码、数据和模型资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Interspeech 2024 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2406.15888v2",
      "published_date": "2024-06-22 16:37:51 UTC",
      "updated_date": "2025-04-04 14:12:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:31:59.608877"
    },
    {
      "arxiv_id": "2406.15885v1",
      "title": "The Music Maestro or The Musically Challenged, A Massive Music Evaluation Benchmark for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiajia Li",
        "Lu Yang",
        "Mingni Tang",
        "Cong Chen",
        "Zuchao Li",
        "Ping Wang",
        "Hai Zhao"
      ],
      "abstract": "Benchmark plays a pivotal role in assessing the advancements of large\nlanguage models (LLMs). While numerous benchmarks have been proposed to\nevaluate LLMs' capabilities, there is a notable absence of a dedicated\nbenchmark for assessing their musical abilities. To address this gap, we\npresent ZIQI-Eval, a comprehensive and large-scale music benchmark specifically\ndesigned to evaluate the music-related capabilities of LLMs. ZIQI-Eval\nencompasses a wide range of questions, covering 10 major categories and 56\nsubcategories, resulting in over 14,000 meticulously curated data entries. By\nleveraging ZIQI-Eval, we conduct a comprehensive evaluation over 16 LLMs to\nevaluate and analyze LLMs' performance in the domain of music. Results indicate\nthat all LLMs perform poorly on the ZIQI-Eval benchmark, suggesting significant\nroom for improvement in their musical capabilities. With ZIQI-Eval, we aim to\nprovide a standardized and robust evaluation framework that facilitates a\ncomprehensive assessment of LLMs' music-related abilities. The dataset is\navailable at GitHub\\footnote{https://github.com/zcli-charlie/ZIQI-Eval} and\nHuggingFace\\footnote{https://huggingface.co/datasets/MYTH-Lab/ZIQI-Eval}.",
      "tldr_zh": "本研究提出 ZIQI-Eval，这是一个大规模基准，用于评估大型语言模型 (LLMs) 的音乐相关能力，以填补现有基准的空白。ZIQI-Eval 涵盖 10 个主要类别和 56 个子类别，总计超过 14,000 个精心策划的问题，并通过该基准评估了 16 个 LLMs 的表现。结果显示，所有 LLMs 在音乐领域表现出色差，表明其音乐能力有显著改进空间；该基准提供了一个标准化的评估框架，并已在 GitHub 和 HuggingFace 上公开数据集。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to ACL-Findings 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.15885v1",
      "published_date": "2024-06-22 16:24:42 UTC",
      "updated_date": "2024-06-22 16:24:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:32:00.828858"
    },
    {
      "arxiv_id": "2406.15883v1",
      "title": "SimSMoE: Solving Representational Collapse via Similarity Measure",
      "title_zh": "SimSMoE：通过相似性度量解决表征坍缩",
      "authors": [
        "Giang Do",
        "Hung Le",
        "Truyen Tran"
      ],
      "abstract": "Sparse mixture of experts (SMoE) have emerged as an effective approach for\nscaling large language models while keeping a constant computational cost.\nRegardless of several notable successes of SMoE, effective training such\narchitecture remains elusive due to the representation collapse problem, which\nin turn harms model performance and causes parameter redundancy. In this work,\nwe present Similarity-based Sparse Mixture of Experts (SimSMoE), a novel\nsimilarity of neural network algorithm, that guarantees a solution to address\nthe representation collapse issue between experts given a fixed FLOPs budget.\nWe conduct extensive empirical evaluations on three large language models for\nboth Pre-training and Fine-tuning tasks to illustrate the efficacy, robustness,\nand scalability of our method. The results demonstrate that SimSMoE\nsignificantly enhances existing routing policy and outperforms other SMoE\ntraining methods in performance for the tasks.",
      "tldr_zh": "这篇论文提出了 SimSMoE，一种基于相似度测量的稀疏混合专家 (Sparse Mixture of Experts, SMoE) 方法，用于解决 SMoE 模型中的表示崩溃 (representational collapse) 问题，从而改善模型性能并减少参数冗余。SimSMoE 通过引入相似度算法，在固定 FLOPs 预算下，确保专家之间的表示多样性，并增强路由策略的鲁棒性和可扩展性。实验结果显示，在三个大型语言模型的预训练和微调任务上，SimSMoE 显著优于其他 SMoE 训练方法，证明了其在提升任务性能方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15883v1",
      "published_date": "2024-06-22 16:10:45 UTC",
      "updated_date": "2024-06-22 16:10:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:32:17.081866"
    },
    {
      "arxiv_id": "2406.15881v2",
      "title": "Fast Tree-Field Integrators: From Low Displacement Rank to Topological Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Krzysztof Choromanski",
        "Arijit Sehanobish",
        "Somnath Basu Roy Chowdhury",
        "Han Lin",
        "Avinava Dubey",
        "Tamas Sarlos",
        "Snigdha Chaturvedi"
      ],
      "abstract": "We present a new class of fast polylog-linear algorithms based on the theory\nof structured matrices (in particular low displacement rank) for integrating\ntensor fields defined on weighted trees. Several applications of the resulting\nfast tree-field integrators (FTFIs) are presented, including (a) approximation\nof graph metrics with tree metrics, (b) graph classification, (c) modeling on\nmeshes, and finally (d) Topological Transformers (TTs) (Choromanski et al.,\n2022) for images. For Topological Transformers, we propose new relative\nposition encoding (RPE) masking mechanisms with as few as three extra learnable\nparameters per Transformer layer, leading to 1.0-1.5%+ accuracy gains.\nImportantly, most of FTFIs are exact methods, thus numerically equivalent to\ntheir brute-force counterparts. When applied to graphs with thousands of nodes,\nthose exact algorithms provide 5.7-13x speedups. We also provide an extensive\ntheoretical analysis of our methods.",
      "tldr_zh": "本研究提出了一种基于低位移秩（low displacement rank）结构化矩阵理论的快速树场积分器（FTFIs），实现对定义在加权树上的张量场进行多项式对数线性整合。FTFIs 的应用包括用树度量近似图度量、图分类、网格建模，以及改进 Topological Transformers (TTs) 用于图像处理，其中引入了只需每个 Transformer 层三个额外可学习参数的相对位置编码 (RPE) 掩码机制，提高了 1.0-1.5% 的准确率。该方法大多数为精确算法，与暴力方法数值等效，在数千节点图上提供 5.7-13 倍的速度提升，并附带了广泛的理论分析。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.15881v2",
      "published_date": "2024-06-22 16:05:34 UTC",
      "updated_date": "2024-12-06 18:41:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:32:26.456565"
    },
    {
      "arxiv_id": "2406.15877v4",
      "title": "BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions",
      "title_zh": "BigCodeBench：针对多样化函数调用和复杂指令的代码生成基准测试",
      "authors": [
        "Terry Yue Zhuo",
        "Minh Chien Vu",
        "Jenny Chim",
        "Han Hu",
        "Wenhao Yu",
        "Ratnadira Widyasari",
        "Imam Nur Bani Yusuf",
        "Haolan Zhan",
        "Junda He",
        "Indraneil Paul",
        "Simon Brunner",
        "Chen Gong",
        "Thong Hoang",
        "Armel Randy Zebaze",
        "Xiaoheng Hong",
        "Wen-Ding Li",
        "Jean Kaddour",
        "Ming Xu",
        "Zhihan Zhang",
        "Prateek Yadav",
        "Naman Jain",
        "Alex Gu",
        "Zhoujun Cheng",
        "Jiawei Liu",
        "Qian Liu",
        "Zijian Wang",
        "Binyuan Hui",
        "Niklas Muennighoff",
        "David Lo",
        "Daniel Fried",
        "Xiaoning Du",
        "Harm de Vries",
        "Leandro Von Werra"
      ],
      "abstract": "Task automation has been greatly empowered by the recent advances in Large\nLanguage Models (LLMs) via Python code, where the tasks ranging from software\nengineering development to general-purpose reasoning. While current benchmarks\nhave shown that LLMs can solve tasks using programs like human developers, the\nmajority of their evaluations are limited to short and self-contained\nalgorithmic tasks or standalone function calls. Solving challenging and\npractical tasks requires the capability of utilizing diverse function calls as\ntools to efficiently implement functionalities like data analysis and web\ndevelopment. In addition, using multiple tools to solve a task needs\ncompositional reasoning by accurately understanding complex instructions.\nFulfilling both of these characteristics can pose a great challenge for LLMs.To\nassess how well LLMs can solve challenging and practical tasks via programs, we\nintroduce BigCodeBench, a benchmark that challenges LLMs to invoke multiple\nfunction calls as tools from 139 libraries and 7 domains for 1,140 fine-grained\ntasks. To evaluate LLMs rigorously, each task encompasses 5.6 test cases with\nan average branch coverage of 99%. In addition, we propose a\nnatural-language-oriented variant of BigCodeBench, BigCodeBench-Instruct, that\nautomatically transforms the original docstrings into short instructions only\nwith essential information. Our extensive evaluation of 60 LLMs shows that LLMs\nare not yet capable of following complex instructions to use function calls\nprecisely, with scores up to 60%, significantly lower than the human\nperformance of 97%. The results underscore the need for further advancements in\nthis area.",
      "tldr_zh": "本论文引入 BigCodeBench，这是一个基准测试，用于评估大型语言模型 (LLMs) 在生成代码时的能力，特别聚焦于多样化函数调用和复杂指令的处理，以模拟实际任务如数据分析和网络开发。\nBigCodeBench 包含 1,140 个细粒度任务，涉及 139 个库和 7 个领域，每个任务平均有 5.6 个测试用例和 99% 的分支覆盖率；此外，还提出其变体 BigCodeBench-Instruct，通过简化指令来测试自然语言导向的代码生成。\n实验评估了 60 个 LLMs，发现它们在精确使用函数调用和组合推理方面得分最高仅为 60%，远低于人类的 97%，暴露了 LLMs 在理解复杂指令上的局限性。\n这些结果强调了进一步提升 LLMs 在实际编程任务中的性能的必要性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "Accpeted at ICLR 2025 (Oral), built with love by the BigCode\n  community :)",
      "pdf_url": "http://arxiv.org/pdf/2406.15877v4",
      "published_date": "2024-06-22 15:52:04 UTC",
      "updated_date": "2025-04-01 08:36:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:32:40.482827"
    },
    {
      "arxiv_id": "2406.16972v1",
      "title": "An Efficient NAS-based Approach for Handling Imbalanced Datasets",
      "title_zh": "一种高效的基于 NAS 的方法，用于处理不平衡数据集",
      "authors": [
        "Zhiwei Yao"
      ],
      "abstract": "Class imbalance is a common issue in real-world data distributions,\nnegatively impacting the training of accurate classifiers. Traditional\napproaches to mitigate this problem fall into three main categories: class\nre-balancing, information transfer, and representation learning. This paper\nintroduces a novel approach to enhance performance on long-tailed datasets by\noptimizing the backbone architecture through neural architecture search (NAS).\nOur research shows that an architecture's accuracy on a balanced dataset does\nnot reliably predict its performance on imbalanced datasets. This necessitates\na complete NAS run on long-tailed datasets, which can be computationally\nexpensive. To address this computational challenge, we focus on existing work,\ncalled IMB-NAS, which proposes efficiently adapting a NAS super-network trained\non a balanced source dataset to an imbalanced target dataset. A detailed\ndescription of the fundamental techniques for IMB-NAS is provided in this\npaper, including NAS and architecture transfer. Among various adaptation\nstrategies, we find that the most effective approach is to retrain the linear\nclassification head with reweighted loss while keeping the backbone NAS\nsuper-network trained on the balanced source dataset frozen. Finally, we\nconducted a series of experiments on the imbalanced CIFAR dataset for\nperformance evaluation. Our conclusions are the same as those proposed in the\nIMB-NAS paper.",
      "tldr_zh": "这篇论文提出了一种基于 Neural Architecture Search (NAS) 的高效方法来处理类不平衡数据集问题，通过优化骨干架构提升长尾数据集的分类性能。论文详细描述了 IMB-NAS 技术，该方法从平衡源数据集上训练 NAS 超网络，然后通过架构转移适应不平衡目标数据集，其中最有效的策略是冻结骨干网络并重新训练线性分类头使用加权损失。实验结果显示，这种方法在不平衡 CIFAR 数据集上表现出色，与 IMB-NAS 的结论一致，证明了其在计算效率和准确性方面的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages,3 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.16972v1",
      "published_date": "2024-06-22 15:46:03 UTC",
      "updated_date": "2024-06-22 15:46:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:32:50.321494"
    },
    {
      "arxiv_id": "2406.15875v2",
      "title": "AI-based Drone Assisted Human Rescue in Disaster Environments: Challenges and Opportunities",
      "title_zh": "基于人工智能的无人机辅助人类救援在灾害环境中的挑战与机遇",
      "authors": [
        "Narek Papyan",
        "Michel Kulhandjian",
        "Hovannes Kulhandjian",
        "Levon Hakob Aslanyan"
      ],
      "abstract": "In this survey we are focusing on utilizing drone-based systems for the\ndetection of individuals, particularly by identifying human screams and other\ndistress signals. This study has significant relevance in post-disaster\nscenarios, including events such as earthquakes, hurricanes, military\nconflicts, wildfires, and more. These drones are capable of hovering over\ndisaster-stricken areas that may be challenging for rescue teams to access\ndirectly. Unmanned aerial vehicles (UAVs), commonly referred to as drones, are\nfrequently deployed for search-and-rescue missions during disaster situations.\nTypically, drones capture aerial images to assess structural damage and\nidentify the extent of the disaster. They also employ thermal imaging\ntechnology to detect body heat signatures, which can help locate individuals.\nIn some cases, larger drones are used to deliver essential supplies to people\nstranded in isolated disaster-stricken areas. In our discussions, we delve into\nthe unique challenges associated with locating humans through aerial acoustics.\nThe auditory system must distinguish between human cries and sounds that occur\nnaturally, such as animal calls and wind. Additionally, it should be capable of\nrecognizing distinct patterns related to signals like shouting, clapping, or\nother ways in which people attempt to signal rescue teams. To tackle this\nchallenge, one solution involves harnessing artificial intelligence (AI) to\nanalyze sound frequencies and identify common audio signatures. Deep\nlearning-based networks, such as convolutional neural networks (CNNs), can be\ntrained using these signatures to filter out noise generated by drone motors\nand other environmental factors. Furthermore, employing signal processing\ntechniques like the direction of arrival (DOA) based on microphone array\nsignals can enhance the precision of tracking the source of human noises.",
      "tldr_zh": "这篇调查论文探讨了在灾害环境中使用AI辅助无人机（如UAVs）检测人类求救信号的挑战和机会，重点关注通过识别尖叫和其他声音来定位受困者，尤其在地震、飓风等场景中。论文强调了无人机利用空中图像、热成像和声音分析进行搜索和救援，但面临区分人类哭喊与自然噪音（如动物叫声或风声）的难题。解决方案包括应用AI技术训练深度学习网络（如CNN）过滤噪音，并结合信号处理方法如DOA（Direction of Arrival）来精确跟踪声音来源，从而提升救援效率和准确性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "68U10, 68T50(Primary) 68T45 (Secondary)",
        "I.2.7; I.2.10; I.4.0"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15875v2",
      "published_date": "2024-06-22 15:39:46 UTC",
      "updated_date": "2024-07-12 20:34:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:33:04.599253"
    },
    {
      "arxiv_id": "2407.10987v1",
      "title": "Adaptive Digital Twin and Communication-Efficient Federated Learning Network Slicing for 5G-enabled Internet of Things",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Ayepah-Mensah",
        "Guolin Sun",
        "Yu Pang",
        "Wei Jiang"
      ],
      "abstract": "Network slicing enables industrial Internet of Things (IIoT) networks with\nmultiservice and differentiated resource requirements to meet increasing\ndemands through efficient use and management of network resources. Typically,\nthe network slice orchestrator relies on demand forecasts for each slice to\nmake informed decisions and maximize resource utilization. The new generation\nof Industry 4.0 has introduced digital twins to map physical systems to digital\nmodels for accurate decision-making. In our approach, we first use\ngraph-attention networks to build a digital twin environment for network\nslices, enabling real-time traffic analysis, monitoring, and demand\nforecasting. Based on these predictions, we formulate the resource allocation\nproblem as a federated multi-agent reinforcement learning problem and employ a\ndeep deterministic policy gradient to determine the resource allocation policy\nwhile preserving the privacy of the slices. Our results demonstrate that the\nproposed approaches can improve the accuracy of demand prediction for network\nslices and reduce the communication overhead of dynamic network slicing.",
      "tldr_zh": "本文提出了一种自适应Digital Twin和通信高效的Federated Learning网络切片方法，针对5G-enabled Internet of Things中的工业物联网(IIoT)网络，实现多服务资源需求的管理和优化。具体而言，该方法使用Graph-Attention Networks构建数字孪生环境，进行实时流量分析、监控和需求预测，并将资源分配问题转化为Federated Multi-Agent Reinforcement Learning问题，通过Deep Deterministic Policy Gradient算法制定资源策略，同时保护切片隐私。实验结果表明，该方法显著提高了网络切片需求预测的准确性，并减少了动态网络切片的通信开销。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.NI",
      "comment": "8 pages, 7 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2407.10987v1",
      "published_date": "2024-06-22 15:33:35 UTC",
      "updated_date": "2024-06-22 15:33:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:33:16.517821"
    },
    {
      "arxiv_id": "2406.17804v3",
      "title": "A Review of Electromagnetic Elimination Methods for low-field portable MRI scanner",
      "title_zh": "翻译失败",
      "authors": [
        "Wanyu Bian",
        "Panfeng Li",
        "Mengyao Zheng",
        "Chihang Wang",
        "Anying Li",
        "Ying Li",
        "Haowei Ni",
        "Zixuan Zeng"
      ],
      "abstract": "This paper analyzes conventional and deep learning methods for eliminating\nelectromagnetic interference (EMI) in MRI systems. We compare traditional\nanalytical and adaptive techniques with advanced deep learning approaches. Key\nstrengths and limitations of each method are highlighted. Recent advancements\nin active EMI elimination, such as external EMI receiver coils, are discussed\nalongside deep learning methods, which show superior EMI suppression by\nleveraging neural networks trained on MRI data. While deep learning improves\nEMI elimination and diagnostic capabilities, it introduces security and safety\nconcerns, particularly in commercial applications. A balanced approach,\nintegrating conventional reliability with deep learning's advanced\ncapabilities, is proposed for more effective EMI suppression in MRI systems.",
      "tldr_zh": "这篇论文综述了用于低场便携式 MRI 扫描仪的电磁干扰 (EMI) 消除方法，比较了传统分析和自适应技术与深度学习方法，并突出了各自的优势和局限性。深度学习方法通过在 MRI 数据上训练的神经网络实现了更优的 EMI 抑制效果，但也引入了安全和可靠性问题，例如在商业应用中的潜在风险。论文建议采用平衡策略，将传统方法的可靠性与深度学习的高级能力相结合，以实现更有效的 EMI 消除。",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "physics.med-ph",
      "comment": "Accepted by 2024 5th International Conference on Machine Learning and\n  Computer Application",
      "pdf_url": "http://arxiv.org/pdf/2406.17804v3",
      "published_date": "2024-06-22 15:24:33 UTC",
      "updated_date": "2024-11-13 09:50:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:33:27.239027"
    },
    {
      "arxiv_id": "2406.15871v1",
      "title": "Uncovering Hidden Intentions: Exploring Prompt Recovery for Deeper Insights into Generated Texts",
      "title_zh": "翻译失败",
      "authors": [
        "Louis Give",
        "Timo Zaoral",
        "Maria Antonietta Bruno"
      ],
      "abstract": "Today, the detection of AI-generated content is receiving more and more\nattention. Our idea is to go beyond detection and try to recover the prompt\nused to generate a text. This paper, to the best of our knowledge, introduces\nthe first investigation in this particular domain without a closed set of\ntasks. Our goal is to study if this approach is promising. We experiment with\nzero-shot and few-shot in-context learning but also with LoRA fine-tuning.\nAfter that, we evaluate the benefits of using a semi-synthetic dataset. For\nthis first study, we limit ourselves to text generated by a single model. The\nresults show that it is possible to recover the original prompt with a\nreasonable degree of accuracy.",
      "tldr_zh": "本论文首次探索从 AI 生成文本中恢复原始提示（prompt recovery）的技术，以深入理解文本生成过程。该方法超越了传统检测，调查了零样本学习（zero-shot）、少样本学习（few-shot in-context learning）和 LoRA fine-tuning 等策略，并评估了半合成数据集（semi-synthetic dataset）的优势。研究限制于单一模型生成的文本，结果表明，可以以合理的准确度恢复原始提示，为进一步的 AI 内容分析提供新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at WNNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.15871v1",
      "published_date": "2024-06-22 15:16:11 UTC",
      "updated_date": "2024-06-22 15:16:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:33:39.134670"
    },
    {
      "arxiv_id": "2406.17803v1",
      "title": "Understanding the Role of User Profile in the Personalization of Large Language Models",
      "title_zh": "理解用户配置文件在大语言模型个性化的作用",
      "authors": [
        "Bin Wu",
        "Zhengyan Shi",
        "Hossein A. Rahmani",
        "Varsha Ramineni",
        "Emine Yilmaz"
      ],
      "abstract": "Utilizing user profiles to personalize Large Language Models (LLMs) has been\nshown to enhance the performance on a wide range of tasks. However, the precise\nrole of user profiles and their effect mechanism on LLMs remains unclear. This\nstudy first confirms that the effectiveness of user profiles is primarily due\nto personalization information rather than semantic information. Furthermore,\nwe investigate how user profiles affect the personalization of LLMs. Within the\nuser profile, we reveal that it is the historical personalized response\nproduced or approved by users that plays a pivotal role in personalizing LLMs.\nThis discovery unlocks the potential of LLMs to incorporate a greater number of\nuser profiles within the constraints of limited input length. As for the\nposition of user profiles, we observe that user profiles integrated into\ndifferent positions of the input context do not contribute equally to\npersonalization. Instead, where the user profile that is closer to the\nbeginning affects more on the personalization of LLMs. Our findings reveal the\nrole of user profiles for the personalization of LLMs, and showcase how\nincorporating user profiles impacts performance providing insight to leverage\nuser profiles effectively.",
      "tldr_zh": "这篇论文探讨了用户配置文件（user profiles）在 Large Language Models (LLMs) 个性化中的作用，确认其效果主要源于个性化信息而非语义信息。研究发现，用户历史个性化响应（由用户产生或批准的）是关键因素，这有助于 LLMs 在输入长度限制下整合更多配置文件。实验结果显示，用户配置文件的位置对个性化影响不同，位于输入上下文开头的配置文件效果更显著。这些发现为有效利用用户配置文件提升 LLMs 性能提供了重要指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17803v1",
      "published_date": "2024-06-22 14:32:35 UTC",
      "updated_date": "2024-06-22 14:32:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:33:51.624246"
    },
    {
      "arxiv_id": "2406.15859v2",
      "title": "LLM-Powered Explanations: Unraveling Recommendations Through Subgraph Reasoning",
      "title_zh": "LLM驱动的解释：通过子图推理揭示推荐系统",
      "authors": [
        "Guangsi Shi",
        "Xiaofeng Deng",
        "Linhao Luo",
        "Lijuan Xia",
        "Lei Bao",
        "Bei Ye",
        "Fei Du",
        "Shirui Pan",
        "Yuxiao Li"
      ],
      "abstract": "Recommender systems are pivotal in enhancing user experiences across various\nweb applications by analyzing the complicated relationships between users and\nitems. Knowledge graphs(KGs) have been widely used to enhance the performance\nof recommender systems. However, KGs are known to be noisy and incomplete,\nwhich are hard to provide reliable explanations for recommendation results. An\nexplainable recommender system is crucial for the product development and\nsubsequent decision-making. To address these challenges, we introduce a novel\nrecommender that synergies Large Language Models (LLMs) and KGs to enhance the\nrecommendation and provide interpretable results. Specifically, we first\nharness the power of LLMs to augment KG reconstruction. LLMs comprehend and\ndecompose user reviews into new triples that are added into KG. In this way, we\ncan enrich KGs with explainable paths that express user preferences. To enhance\nthe recommendation on augmented KGs, we introduce a novel subgraph reasoning\nmodule that effectively measures the importance of nodes and discovers\nreasoning for recommendation. Finally, these reasoning paths are fed into the\nLLMs to generate interpretable explanations of the recommendation results. Our\napproach significantly enhances both the effectiveness and interpretability of\nrecommender systems, especially in cross-selling scenarios where traditional\nmethods falter. The effectiveness of our approach has been rigorously tested on\nfour open real-world datasets, with our methods demonstrating a superior\nperformance over contemporary state-of-the-art techniques by an average\nimprovement of 12%. The application of our model in a multinational engineering\nand technology company cross-selling recommendation system further underscores\nits practical utility and potential to redefine recommendation practices\nthrough improved accuracy and user trust.",
      "tldr_zh": "该研究提出了一种结合大型语言模型（LLMs）和知识图谱（KGs）的可解释推荐系统框架，以解决KGs的噪声和不完整问题。方法包括使用LLMs分析用户评论，生成新三元组（triples）来丰富KGs，并引入子图推理模块（subgraph reasoning module）评估节点重要性和发现推荐路径。这些路径随后输入LLMs生成可解释的推荐解释。实验在四个真实数据集上显示，该方法平均提高了12%的性能，并在实际交叉销售（cross-selling）场景中提升了准确性和用户信任。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15859v2",
      "published_date": "2024-06-22 14:14:03 UTC",
      "updated_date": "2024-06-30 02:13:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:34:03.983849"
    },
    {
      "arxiv_id": "2406.15852v2",
      "title": "Next Level Message-Passing with Hierarchical Support Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Carlos Vonessen",
        "Florian Grötschla",
        "Roger Wattenhofer"
      ],
      "abstract": "Message-Passing Neural Networks (MPNNs) are extensively employed in graph\nlearning tasks but suffer from limitations such as the restricted scope of\ninformation exchange, by being confined to neighboring nodes during each round\nof message passing. Various strategies have been proposed to address these\nlimitations, including incorporating virtual nodes to facilitate global\ninformation exchange. In this study, we introduce the Hierarchical Support\nGraph (HSG), an extension of the virtual node concept created through recursive\ncoarsening of the original graph. This approach provides a flexible framework\nfor enhancing information flow in graphs, independent of the specific MPNN\nlayers utilized. We present a theoretical analysis of HSGs, investigate their\nempirical performance, and demonstrate that HSGs can surpass other methods\naugmented with virtual nodes, achieving state-of-the-art results across\nmultiple datasets.",
      "tldr_zh": "本研究针对 Message-Passing Neural Networks (MPNNs) 在图学习任务中的局限性，如信息交换仅限于邻居节点，提出了一种扩展虚拟节点概念的 Hierarchical Support Graph (HSG)。HSG 通过对原始图进行递归 coarsening 创建分层结构，提供了一个灵活的框架来增强图中的信息流，而不依赖于具体的 MPNN 层。论文对 HSG 进行了理论分析和经验性能评估，结果显示 HSG 超过了其他虚拟节点方法，并在多个数据集上实现了 state-of-the-art 性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15852v2",
      "published_date": "2024-06-22 13:57:09 UTC",
      "updated_date": "2024-08-29 10:28:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:34:14.609096"
    },
    {
      "arxiv_id": "2406.15850v1",
      "title": "Learning Abstract World Model for Value-preserving Planning with Options",
      "title_zh": "翻译失败",
      "authors": [
        "Rafael Rodriguez-Sanchez",
        "George Konidaris"
      ],
      "abstract": "General-purpose agents require fine-grained controls and rich sensory inputs\nto perform a wide range of tasks. However, this complexity often leads to\nintractable decision-making. Traditionally, agents are provided with\ntask-specific action and observation spaces to mitigate this challenge, but\nthis reduces autonomy. Instead, agents must be capable of building state-action\nspaces at the correct abstraction level from their sensorimotor experiences. We\nleverage the structure of a given set of temporally-extended actions to learn\nabstract Markov decision processes (MDPs) that operate at a higher level of\ntemporal and state granularity. We characterize state abstractions necessary to\nensure that planning with these skills, by simulating trajectories in the\nabstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require\ncontinuous abstract states to plan successfully and show that abstract model\nlearning improves the sample efficiency of planning and learning.",
      "tldr_zh": "该论文探讨了通用代理在复杂任务中面临的决策挑战，提出通过从感官运动经验中学习抽象世界模型来构建合适的抽象状态-行动空间。作者利用一组临时扩展行动（options）的结构，学习抽象的Markov decision processes (MDPs)，以确保在抽象MDP中模拟轨迹规划时，原始MDP的价值损失保持有界。实验结果显示，在基于目标的导航环境中，该方法显著提高了规划和学习的样本效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the Proceedings of Reinforcement Learning Conference",
      "pdf_url": "http://arxiv.org/pdf/2406.15850v1",
      "published_date": "2024-06-22 13:41:02 UTC",
      "updated_date": "2024-06-22 13:41:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:34:28.904026"
    },
    {
      "arxiv_id": "2406.15847v2",
      "title": "Enhancing Solar Driver Forecasting with Multivariate Transformers",
      "title_zh": "利用多变量Transformer增强太阳",
      "authors": [
        "Sergio Sanchez-Hurtado",
        "Victor Rodriguez-Fernandez",
        "Julia Briden",
        "Peng Mun Siew",
        "Richard Linares"
      ],
      "abstract": "In this work, we develop a comprehensive framework for F10.7, S10.7, M10.7,\nand Y10.7 solar driver forecasting with a time series Transformer (PatchTST).\nTo ensure an equal representation of high and low levels of solar activity, we\nconstruct a custom loss function to weight samples based on the distance\nbetween the solar driver's historical distribution and the training set. The\nsolar driver forecasting framework includes an 18-day lookback window and\nforecasts 6 days into the future. When benchmarked against the Space\nEnvironment Technologies (SET) dataset, our model consistently produces\nforecasts with a lower standard mean error in nearly all cases, with improved\nprediction accuracy during periods of high solar activity. All the code is\navailable on Github https://github.com/ARCLab-MIT/sw-driver-forecaster.",
      "tldr_zh": "本文提出了一种使用多变量 Transformer（PatchTST）框架来增强 F10.7、S10.7、M10.7 和 Y10.7 太阳驱动因素的预测方法，以改善时间序列预测的准确性。框架引入了自定义损失函数，通过根据太阳驱动因素的历史分布和训练集的距离加权样本，确保高低太阳活动水平的均衡表示，并采用 18 天回溯窗口预测未来 6 天。与 Space Environment Technologies (SET) 数据集基准测试相比，该模型在几乎所有情况下实现了更低的均方误差，尤其在高太阳活动期预测准确性显著提升。代码已在 GitHub 上公开（https://github.com/ARCLab-MIT/sw-driver-forecaster）。",
      "categories": [
        "physics.space-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.space-ph",
      "comment": "Short paper accepted for oral presentation at the SPAICE Conference\n  2024 (https://spaice.esa.int/)",
      "pdf_url": "http://arxiv.org/pdf/2406.15847v2",
      "published_date": "2024-06-22 13:26:14 UTC",
      "updated_date": "2024-08-01 20:54:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:34:41.283911"
    },
    {
      "arxiv_id": "2407.02514v3",
      "title": "LOGIC-LM++: Multi-Step Refinement for Symbolic Formulations",
      "title_zh": "LOGIC-LM++：针对符号表述的多步骤精炼",
      "authors": [
        "Shashank Kirtania",
        "Priyanshu Gupta",
        "Arjun Radhakirshna"
      ],
      "abstract": "In this paper we examine the limitations of Large Language Models (LLMs) for\ncomplex reasoning tasks. Although recent works have started to employ formal\nlanguages as an intermediate representation for reasoning tasks, they often\nface challenges in accurately generating and refining these formal\nspecifications to ensure correctness. To address these issues, this paper\nproposes Logic-LM++, an improvement on Logic-LM . It uses the ability of LLMs\nto do pairwise comparisons, allowing the evaluation of the refinements\nsuggested by the LLM. The paper demonstrates that Logic-LM++ outperforms\nLogic-LM and other contemporary techniques across natural language reasoning\ntasks on three datasets, FOLIO, ProofWriter and AR-LSAT, with an average\nimprovement of 18.5% on standard prompting, 12.3% on chain of thought prompting\nand 5% on Logic-LM.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs)在复杂推理任务中的局限性，特别是生成和精炼形式化规范的准确性问题，并提出Logic-LM++作为Logic-LM的改进方案。Logic-LM++利用LLMs的配对比较能力来评估和优化建议的精炼步骤，从而提升推理任务的正确性。在FOLIO、ProofWriter和AR-LSAT三个数据集上，Logic-LM++在标准提示、chain of thought prompting和Logic-LM基础上分别平均提升18.5%、12.3%和5%，显著优于现有技术。总的来说，该方法为LLMs在符号形式化方面的应用提供了更可靠的多步精炼框架。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02514v3",
      "published_date": "2024-06-22 12:50:41 UTC",
      "updated_date": "2024-08-06 06:39:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:34:52.614892"
    },
    {
      "arxiv_id": "2406.15836v1",
      "title": "Decentralized Transformers with Centralized Aggregation are Sample-Efficient Multi-Agent World Models",
      "title_zh": "带有中心化聚合的去中心化 Transformer 是样本高效的多智能体世界模型",
      "authors": [
        "Yang Zhang",
        "Chenjia Bai",
        "Bin Zhao",
        "Junchi Yan",
        "Xiu Li",
        "Xuelong Li"
      ],
      "abstract": "Learning a world model for model-free Reinforcement Learning (RL) agents can\nsignificantly improve the sample efficiency by learning policies in\nimagination. However, building a world model for Multi-Agent RL (MARL) can be\nparticularly challenging due to the scalability issue in a centralized\narchitecture arising from a large number of agents, and also the\nnon-stationarity issue in a decentralized architecture stemming from the\ninter-dependency among agents. To address both challenges, we propose a novel\nworld model for MARL that learns decentralized local dynamics for scalability,\ncombined with a centralized representation aggregation from all agents. We cast\nthe dynamics learning as an auto-regressive sequence modeling problem over\ndiscrete tokens by leveraging the expressive Transformer architecture, in order\nto model complex local dynamics across different agents and provide accurate\nand consistent long-term imaginations. As the first pioneering\nTransformer-based world model for multi-agent systems, we introduce a Perceiver\nTransformer as an effective solution to enable centralized representation\naggregation within this context. Results on Starcraft Multi-Agent Challenge\n(SMAC) show that it outperforms strong model-free approaches and existing\nmodel-based methods in both sample efficiency and overall performance.",
      "tldr_zh": "该研究提出了一种新型世界模型，用于提升多智能体强化学习（MARL）的样本效率，通过结合分散式 Transformers 和集中式表示聚合来解决可扩展性和非平稳性问题。该模型将动态学习视为自回归序列建模任务，利用 Transformer 架构处理复杂本地动态，并引入 Perceiver Transformer 作为有效的集中式聚合解决方案，以实现准确的长远想象。作为首个基于 Transformer 的多智能体世界模型，在 Starcraft Multi-Agent Challenge (SMAC) 上，该方法在样本效率和整体性能上优于现有的无模型和模型方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15836v1",
      "published_date": "2024-06-22 12:40:03 UTC",
      "updated_date": "2024-06-22 12:40:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:35:06.068778"
    },
    {
      "arxiv_id": "2406.15808v1",
      "title": "Understanding Student and Academic Staff Perceptions of AI Use in Assessment and Feedback",
      "title_zh": "学生和学术人员对AI在评估与反馈中使用感知的理解",
      "authors": [
        "Jasper Roe",
        "Mike Perkins",
        "Daniel Ruelle"
      ],
      "abstract": "The rise of Artificial Intelligence (AI) and Generative Artificial\nIntelligence (GenAI) in higher education necessitates assessment reform. This\nstudy addresses a critical gap by exploring student and academic staff\nexperiences with AI and GenAI tools, focusing on their familiarity and comfort\nwith current and potential future applications in learning and assessment. An\nonline survey collected data from 35 academic staff and 282 students across two\nuniversities in Vietnam and one in Singapore, examining GenAI familiarity,\nperceptions of its use in assessment marking and feedback, knowledge checking\nand participation, and experiences of GenAI text detection.\n  Descriptive statistics and reflexive thematic analysis revealed a generally\nlow familiarity with GenAI among both groups. GenAI feedback was viewed\nnegatively; however, it was viewed more positively when combined with\ninstructor feedback. Academic staff were more accepting of GenAI text detection\ntools and grade adjustments based on detection results compared to students.\nQualitative analysis identified three themes: unclear understanding of text\ndetection tools, variability in experiences with GenAI detectors, and mixed\nfeelings about GenAI's future impact on educational assessment. These findings\nhave major implications regarding the development of policies and practices for\nGenAI-enabled assessment and feedback in higher education.",
      "tldr_zh": "这篇论文调查了学生和学术人员对AI和GenAI在高等教育评估和反馈中的感知，通过在线调查收集了来自越南两所大学和新加坡一所大学的35名学术人员和282名学生的资料。研究发现，GenAI的熟悉度普遍较低，GenAI反馈被负面看待，但当与教师反馈结合时更受欢迎；此外，学术人员比学生更接受GenAI文本检测工具和基于检测结果的成绩调整。定性分析识别了三个主题：对文本检测工具的模糊理解、GenAI检测器的经验变异，以及对GenAI未来影响教育的混合感受。这些发现为高等教育中GenAI-enabled评估和反馈的政策制定提供了重要启示。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15808v1",
      "published_date": "2024-06-22 10:25:01 UTC",
      "updated_date": "2024-06-22 10:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:35:19.581381"
    },
    {
      "arxiv_id": "2406.15797v1",
      "title": "Synergistic Deep Graph Clustering Network",
      "title_zh": "协同深度图聚类网络",
      "authors": [
        "Benyu Wu",
        "Shifei Ding",
        "Xiao Xu",
        "Lili Guo",
        "Ling Ding",
        "Xindong Wu"
      ],
      "abstract": "Employing graph neural networks (GNNs) to learn cohesive and discriminative\nnode representations for clustering has shown promising results in deep graph\nclustering. However, existing methods disregard the reciprocal relationship\nbetween representation learning and structure augmentation. This study suggests\nthat enhancing embedding and structure synergistically becomes imperative for\nGNNs to unleash their potential in deep graph clustering. A reliable structure\npromotes obtaining more cohesive node representations, while high-quality node\nrepresentations can guide the augmentation of the structure, enhancing\nstructural reliability in return. Moreover, the generalization ability of\nexisting GNNs-based models is relatively poor. While they perform well on\ngraphs with high homogeneity, they perform poorly on graphs with low\nhomogeneity. To this end, we propose a graph clustering framework named\nSynergistic Deep Graph Clustering Network (SynC). In our approach, we design a\nTransform Input Graph Auto-Encoder (TIGAE) to obtain high-quality embeddings\nfor guiding structure augmentation. Then, we re-capture neighborhood\nrepresentations on the augmented graph to obtain clustering-friendly embeddings\nand conduct self-supervised clustering. Notably, representation learning and\nstructure augmentation share weights, significantly reducing the number of\nmodel parameters. Additionally, we introduce a structure fine-tuning strategy\nto improve the model's generalization. Extensive experiments on benchmark\ndatasets demonstrate the superiority and effectiveness of our method. The code\nis released on GitHub and Code Ocean.",
      "tldr_zh": "这篇论文提出了一种协同深度图聚类网络(SynC)，通过协同增强节点表示学习和图结构，解决现有GNNs方法忽略两者相互关系的局限性，并提升模型在低同质性图上的泛化能力。核心方法包括使用Transform Input Graph Auto-Encoder (TIGAE)获取高质量嵌入来指导结构增强，然后在增强后的图上重新捕获邻居表示并进行自监督聚类；此外，表示学习和结构增强共享权重，减少了模型参数。实验结果显示，SynC在基准数据集上表现出色，证明了其有效性和优越性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15797v1",
      "published_date": "2024-06-22 09:40:34 UTC",
      "updated_date": "2024-06-22 09:40:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:35:30.587767"
    },
    {
      "arxiv_id": "2406.16968v2",
      "title": "Multimodal Physiological Signals Representation Learning via Multiscale Contrasting for Depression Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Shao",
        "Rui Wang",
        "Yixue Hao",
        "Long Hu",
        "Min Chen",
        "Hans Arno Jacobsen"
      ],
      "abstract": "Depression recognition based on physiological signals such as functional\nnear-infrared spectroscopy (fNIRS) and electroencephalogram (EEG) has made\nconsiderable progress. However, most existing studies ignore the\ncomplementarity and semantic consistency of multimodal physiological signals\nunder the same stimulation task in complex spatio-temporal patterns. In this\npaper, we introduce a multimodal physiological signals representation learning\nframework using Siamese architecture via multiscale contrasting for depression\nrecognition (MRLMC). First, fNIRS and EEG are transformed into different but\ncorrelated data based on a time-domain data augmentation strategy. Then, we\ndesign a spatio-temporal contrasting module to learn the representation of\nfNIRS and EEG through weight-sharing multiscale spatio-temporal convolution.\nFurthermore, to enhance the learning of semantic representation associated with\nstimulation tasks, a semantic consistency contrast module is proposed, aiming\nto maximize the semantic similarity of fNIRS and EEG. Extensive experiments on\npublicly available and self-collected multimodal physiological signals datasets\nindicate that MRLMC outperforms the state-of-the-art models. Moreover, our\nproposed framework is capable of transferring to multimodal time series\ndownstream tasks.",
      "tldr_zh": "本文提出 MRLMC 框架，利用 Siamese architecture 和 multiscale contrasting 来学习多模态生理信号（如 fNIRS 和 EEG）的表示，以提升抑郁症识别。该框架通过时域数据增强策略转换信号，并设计时空对比模块和语义一致性对比模块，以捕捉信号的互补性和语义相似性。实验在公开和自收集数据集上表明，MRLMC 优于最先进模型，并可转移应用于其他多模态时序任务。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16968v2",
      "published_date": "2024-06-22 09:28:02 UTC",
      "updated_date": "2024-06-26 01:54:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:35:42.032881"
    },
    {
      "arxiv_id": "2406.15789v1",
      "title": "Privacy Implications of Explainable AI in Data-Driven Systems",
      "title_zh": "可解释 AI 在数据驱动系统中的隐私",
      "authors": [
        "Fatima Ezzeddine"
      ],
      "abstract": "Machine learning (ML) models, demonstrably powerful, suffer from a lack of\ninterpretability. The absence of transparency, often referred to as the black\nbox nature of ML models, undermines trust and urges the need for efforts to\nenhance their explainability. Explainable AI (XAI) techniques address this\nchallenge by providing frameworks and methods to explain the internal\ndecision-making processes of these complex models. Techniques like\nCounterfactual Explanations (CF) and Feature Importance play a crucial role in\nachieving this goal. Furthermore, high-quality and diverse data remains the\nfoundational element for robust and trustworthy ML applications. In many\napplications, the data used to train ML and XAI explainers contain sensitive\ninformation. In this context, numerous privacy-preserving techniques can be\nemployed to safeguard sensitive information in the data, such as differential\nprivacy. Subsequently, a conflict between XAI and privacy solutions emerges due\nto their opposing goals. Since XAI techniques provide reasoning for the model\nbehavior, they reveal information relative to ML models, such as their decision\nboundaries, the values of features, or the gradients of deep learning models\nwhen explanations are exposed to a third entity. Attackers can initiate privacy\nbreaching attacks using these explanations, to perform model extraction,\ninference, and membership attacks. This dilemma underscores the challenge of\nfinding the right equilibrium between understanding ML decision-making and\nsafeguarding privacy.",
      "tldr_zh": "该论文探讨了可解释AI（XAI）在数据驱动系统中的隐私影响，强调ML模型的“黑箱”性质导致信任问题，而XAI技术（如Counterfactual Explanations和Feature Importance）用于解释模型决策过程。XAI依赖高质量数据，但这些数据往往包含敏感信息，因此需要隐私保护技术如differential privacy来防范泄露。然而，XAI的解释机制可能暴露模型决策边界、特征值或梯度，易遭攻击者利用进行模型提取、推理和membership attacks。最终，该研究突出了在提升ML模型可解释性和维护隐私之间寻求平衡的挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15789v1",
      "published_date": "2024-06-22 08:51:58 UTC",
      "updated_date": "2024-06-22 08:51:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:35:53.806085"
    },
    {
      "arxiv_id": "2406.15786v6",
      "title": "What Matters in Transformers? Not All Attention is Needed",
      "title_zh": "翻译失败",
      "authors": [
        "Shwai He",
        "Guoheng Sun",
        "Zheyu Shen",
        "Ang Li"
      ],
      "abstract": "While scaling Transformer-based large language models (LLMs) has demonstrated\npromising performance across various tasks, it also introduces redundant\narchitectures, posing efficiency challenges for real-world deployment. Despite\nsome recognition of redundancy in LLMs, the variability of redundancy across\ndifferent architectures in transformers, such as MLP and Attention layers, is\nunder-explored. In this work, we investigate redundancy across different\nmodules within Transformers, including Blocks, MLP, and Attention layers, using\na similarity-based metric. Surprisingly, despite the critical role of attention\nlayers in distinguishing transformers from other architectures, we found that a\nlarge portion of these layers exhibit excessively high similarity and can be\npruned without degrading performance. For instance, Llama-2-70B achieved a\n48.4\\% speedup with only a 2.4\\% performance drop by pruning half of the\nattention layers. Furthermore, by tracing model checkpoints throughout the\ntraining process, we observed that attention layer redundancy is inherent and\nconsistent across training stages. Additionally, we further propose a method\nthat jointly drops Attention and MLP layers, allowing us to more aggressively\ndrop additional layers. For instance, when dropping 31 layers (Attention +\nMLP), Llama-2-13B still retains 90\\% of the performance on the MMLU task. Our\nwork provides valuable insights for future network architecture design. The\ncode is released at: \\url{https://github.com/Shwai-He/LLM-Drop}.",
      "tldr_zh": "本研究探讨了Transformer模型中Attention层、MLP层和Blocks的冗余问题，发现尽管Attention层在模型中至关重要，但大量层表现出高相似性，可通过修剪大幅提高效率。研究者使用基于相似度的指标分析冗余，并提出一种联合修剪Attention和MLP层的方法，例如在Llama-2-70B模型上修剪一半Attention层后，实现48.4%的加速，同时性能仅下降2.4%。实验结果显示，这种方法能更激进地优化模型，如Llama-2-13B修剪31层后，在MMLU任务上保留90%的性能，为未来的Transformer架构设计提供宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 13 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.15786v6",
      "published_date": "2024-06-22 08:41:48 UTC",
      "updated_date": "2024-10-17 02:43:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:36:06.251874"
    },
    {
      "arxiv_id": "2406.15784v1",
      "title": "Data Issues in Industrial AI System: A Meta-Review and Research Strategy",
      "title_zh": "工业 AI 系统中的数据问题：元综述与研究策略",
      "authors": [
        "Xuejiao Li",
        "Cheng Yang",
        "Charles Møller",
        "Jay Lee"
      ],
      "abstract": "In the era of Industry 4.0, artificial intelligence (AI) is assuming an\nincreasingly pivotal role within industrial systems. Despite the recent trend\nwithin various industries to adopt AI, the actual adoption of AI is not as\ndeveloped as perceived. A significant factor contributing to this lag is the\ndata issues in AI implementation. How to address these data issues stands as a\nsignificant concern confronting both industry and academia. To address data\nissues, the first step involves mapping out these issues. Therefore, this study\nconducts a meta-review to explore data issues and methods within the\nimplementation of industrial AI. Seventy-two data issues are identified and\ncategorized into various stages of the data lifecycle, including data source\nand collection, data access and storage, data integration and interoperation,\ndata pre-processing, data processing, data security and privacy, and AI\ntechnology adoption. Subsequently, the study analyzes the data requirements of\nvarious AI algorithms. Building on the aforementioned analyses, it proposes a\ndata management framework, addressing how data issues can be systematically\nresolved at every stage of the data lifecycle. Finally, the study highlights\nfuture research directions. In doing so, this study enriches the existing body\nof knowledge and provides guidelines for professionals navigating the complex\nlandscape of achieving data usability and usefulness in industrial AI.",
      "tldr_zh": "这篇论文通过 meta-review 探讨了工业 AI 系统中的数据问题，识别并分类了72个数据问题，这些问题分布在数据生命周期的各个阶段，包括数据来源和收集、数据访问和存储、数据集成和互操作、数据预处理、数据处理、数据安全和隐私，以及 AI 技术采用。论文分析了各种 AI 算法的数据需求，并提出一个数据管理框架，以系统化方式解决这些问题。最终，该研究丰富了现有知识体，提供专业指导，帮助从业者提升工业 AI 的数据可用性和有用性，并指出了未来的研究方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15784v1",
      "published_date": "2024-06-22 08:36:59 UTC",
      "updated_date": "2024-06-22 08:36:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:36:19.272052"
    },
    {
      "arxiv_id": "2406.15778v2",
      "title": "ObjectNLQ @ Ego4D Episodic Memory Challenge 2024",
      "title_zh": "翻译失败",
      "authors": [
        "Yisen Feng",
        "Haoyu Zhang",
        "Yuquan Xie",
        "Zaijing Li",
        "Meng Liu",
        "Liqiang Nie"
      ],
      "abstract": "In this report, we present our approach for the Natural Language Query track\nand Goal Step track of the Ego4D Episodic Memory Benchmark at CVPR 2024. Both\nchallenges require the localization of actions within long video sequences\nusing textual queries. To enhance localization accuracy, our method not only\nprocesses the temporal information of videos but also identifies fine-grained\nobjects spatially within the frames. To this end, we introduce a novel\napproach, termed ObjectNLQ, which incorporates an object branch to augment the\nvideo representation with detailed object information, thereby improving\ngrounding efficiency. ObjectNLQ achieves a mean R@1 of 23.15, ranking 2nd in\nthe Natural Language Queries Challenge, and gains 33.00 in terms of the metric\nR@1, IoU=0.3, ranking 3rd in the Goal Step Challenge. Our code will be released\nat https://github.com/Yisen-Feng/ObjectNLQ.",
      "tldr_zh": "该研究针对 Ego4D Episodic Memory Benchmark 的 Natural Language Query 和 Goal Step 挑战，提出了一种名为 ObjectNLQ 的新方法，用于在长视频序列中通过文本查询定位动作。ObjectNLQ 通过添加一个 object branch 来增强视频表示，结合视频的 temporal information 和细粒度 spatial objects 的识别，从而提高 grounding efficiency 和 localization accuracy。在 CVPR 2024 挑战中，该方法在 Natural Language Queries 轨道上取得 mean R@1 为 23.15 的成绩，排名第 2；在 Goal Step 轨道上，R@1, IoU=0.3 为 33.00，排名第 3。代码已计划发布在 GitHub 上。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The solution for the Natural Language Query track and Goal Step track\n  at CVPR EgoVis Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.15778v2",
      "published_date": "2024-06-22 07:57:58 UTC",
      "updated_date": "2024-11-18 03:02:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:36:29.782184"
    },
    {
      "arxiv_id": "2406.15771v2",
      "title": "HCQA @ Ego4D EgoSchema Challenge 2024",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Zhang",
        "Yuquan Xie",
        "Yisen Feng",
        "Zaijing Li",
        "Meng Liu",
        "Liqiang Nie"
      ],
      "abstract": "In this report, we present our champion solution for Ego4D EgoSchema\nChallenge in CVPR 2024. To deeply integrate the powerful egocentric captioning\nmodel and question reasoning model, we propose a novel Hierarchical\nComprehension scheme for egocentric video Question Answering, named HCQA. It\nconsists of three stages: Fine-grained Caption Generation, Context-driven\nSummarization, and Inference-guided Answering. Given a long-form video, HCQA\ncaptures local detailed visual information and global summarised visual\ninformation via Fine-grained Caption Generation and Context-driven\nSummarization, respectively. Then in Inference-guided Answering, HCQA utilizes\nthis hierarchical information to reason and answer given question. On the\nEgoSchema blind test set, HCQA achieves 75% accuracy in answering over 5,000\nhuman curated multiple-choice questions. Our code will be released at\nhttps://github.com/Hyu-Zhang/HCQA.",
      "tldr_zh": "本研究介绍了 HCQA，一种分层理解方案，用于 Ego4D EgoSchema Challenge 2024 的冠军解决方案，旨在提升 egocentric 视频问答性能。HCQA 包括三个阶段：Fine-grained Caption Generation 用于捕获局部详细视觉信息、Context-driven Summarization 用于生成全局总结视觉信息，以及 Inference-guided Answering 通过整合这些层次信息进行问题推理和回答。在 EgoSchema blind test set 上，HCQA 实现了 75% 的准确率，成功回答了超过 5,000 个多选题，展示了其在视频问答任务中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The champion solution for Ego4D EgoSchema Challenge in CVPR EgoVis\n  Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.15771v2",
      "published_date": "2024-06-22 07:20:39 UTC",
      "updated_date": "2024-10-29 02:38:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:36:41.714669"
    },
    {
      "arxiv_id": "2406.15763v2",
      "title": "AllMatch: Exploiting All Unlabeled Data for Semi-Supervised Learning",
      "title_zh": "AllMatch：利用所有未标注数据进行半监督学习",
      "authors": [
        "Zhiyu Wu",
        "Jinshi Cui"
      ],
      "abstract": "Existing semi-supervised learning algorithms adopt pseudo-labeling and\nconsistency regulation techniques to introduce supervision signals for\nunlabeled samples. To overcome the inherent limitation of threshold-based\npseudo-labeling, prior studies have attempted to align the confidence threshold\nwith the evolving learning status of the model, which is estimated through the\npredictions made on the unlabeled data. In this paper, we further reveal that\nclassifier weights can reflect the differentiated learning status across\ncategories and consequently propose a class-specific adaptive threshold\nmechanism. Additionally, considering that even the optimal threshold scheme\ncannot resolve the problem of discarding unlabeled samples, a binary\nclassification consistency regulation approach is designed to distinguish\ncandidate classes from negative options for all unlabeled samples. By combining\nthe above strategies, we present a novel SSL algorithm named AllMatch, which\nachieves improved pseudo-label accuracy and a 100% utilization ratio for the\nunlabeled data. We extensively evaluate our approach on multiple benchmarks,\nencompassing both balanced and imbalanced settings. The results demonstrate\nthat AllMatch consistently outperforms existing state-of-the-art methods.",
      "tldr_zh": "本研究针对半监督学习（Semi-Supervised Learning, SSL）中伪标签（pseudo-labeling）和一致性调节（consistency regulation）的局限性，提出了一种名为 AllMatch 的新算法。AllMatch 通过利用分类器权重来实现类特定自适应阈值机制，从而更准确地反映不同类别的学习状态；同时，引入二元分类一致性调节方法，确保所有未标记样本均被利用，实现100%的利用率。实验结果显示，AllMatch 在多个基准测试中，包括平衡和不平衡设置，均超过了现有最先进方法，在伪标签准确性上取得了显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.15763v2",
      "published_date": "2024-06-22 06:59:52 UTC",
      "updated_date": "2024-07-09 14:35:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:36:54.253736"
    },
    {
      "arxiv_id": "2406.15755v1",
      "title": "Fine-grained Background Representation for Weakly Supervised Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Yin",
        "Woobin Im",
        "Dongbo Min",
        "Yuchi Huo",
        "Fei Pan",
        "Sung-Eui Yoon"
      ],
      "abstract": "Generating reliable pseudo masks from image-level labels is challenging in\nthe weakly supervised semantic segmentation (WSSS) task due to the lack of\nspatial information. Prevalent class activation map (CAM)-based solutions are\nchallenged to discriminate the foreground (FG) objects from the suspicious\nbackground (BG) pixels (a.k.a. co-occurring) and learn the integral object\nregions. This paper proposes a simple fine-grained background representation\n(FBR) method to discover and represent diverse BG semantics and address the\nco-occurring problems. We abandon using the class prototype or pixel-level\nfeatures for BG representation. Instead, we develop a novel primitive, negative\nregion of interest (NROI), to capture the fine-grained BG semantic information\nand conduct the pixel-to-NROI contrast to distinguish the confusing BG pixels.\nWe also present an active sampling strategy to mine the FG negatives\non-the-fly, enabling efficient pixel-to-pixel intra-foreground contrastive\nlearning to activate the entire object region. Thanks to the simplicity of\ndesign and convenience in use, our proposed method can be seamlessly plugged\ninto various models, yielding new state-of-the-art results under various WSSS\nsettings across benchmarks. Leveraging solely image-level (I) labels as\nsupervision, our method achieves 73.2 mIoU and 45.6 mIoU segmentation results\non Pascal Voc and MS COCO test sets, respectively. Furthermore, by\nincorporating saliency maps as an additional supervision signal (I+S), we\nattain 74.9 mIoU on Pascal Voc test set. Concurrently, our FBR approach\ndemonstrates meaningful performance gains in weakly-supervised instance\nsegmentation (WSIS) tasks, showcasing its robustness and strong generalization\ncapabilities across diverse domains.",
      "tldr_zh": "本论文针对弱监督语义分割（WSSS）中从图像级标签生成可靠伪掩码的挑战，提出了一种简单的细粒度背景表示（FBR）方法，以区分前景（FG）对象和可疑背景（BG）像素，并学习完整的对象区域。FBR 方法引入负区域兴趣（NROI）作为新原语，用于捕获细粒度的 BG 语义信息，并通过像素到 NROI 的对比以及主动采样策略进行内部前景对比学习，从而激活整个对象区域。该方法设计简洁，可无缝整合到各种模型中，在 Pascal VOC 和 MS COCO 测试集上分别实现 73.2 mIoU 和 45.6 mIoU 的新最先进结果；结合显著性图作为额外监督（I+S），Pascal VOC 上进一步达到 74.9 mIoU，并在弱监督实例分割（WSIS）任务中展现出强劲的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15755v1",
      "published_date": "2024-06-22 06:45:25 UTC",
      "updated_date": "2024-06-22 06:45:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:37:09.735570"
    },
    {
      "arxiv_id": "2406.15753v2",
      "title": "The Perils of Optimizing Learned Reward Functions: Low Training Error Does Not Guarantee Low Regret",
      "title_zh": "翻译失败",
      "authors": [
        "Lukas Fluri",
        "Leon Lang",
        "Alessandro Abate",
        "Patrick Forré",
        "David Krueger",
        "Joar Skalse"
      ],
      "abstract": "In reinforcement learning, specifying reward functions that capture the\nintended task can be very challenging. Reward learning aims to address this\nissue by learning the reward function. However, a learned reward model may have\na low error on the data distribution, and yet subsequently produce a policy\nwith large regret. We say that such a reward model has an error-regret\nmismatch. The main source of an error-regret mismatch is the distributional\nshift that commonly occurs during policy optimization. In this paper, we\nmathematically show that a sufficiently low expected test error of the reward\nmodel guarantees low worst-case regret, but that for any fixed expected test\nerror, there exist realistic data distributions that allow for error-regret\nmismatch to occur. We then show that similar problems persist even when using\npolicy regularization techniques, commonly employed in methods such as RLHF. We\nhope our results stimulate the theoretical and empirical study of improved\nmethods to learn reward models, and better ways to measure their quality\nreliably.",
      "tldr_zh": "这篇论文探讨了强化学习（reinforcement learning）中学习奖励函数（reward functions）的风险：即使奖励模型在训练数据上错误率低，在策略优化过程中仍可能导致高遗憾（regret），这被称为错误-遗憾不匹配（error-regret mismatch）。主要原因在于策略优化时的分布偏移（distributional shift），论文通过数学证明表明，足够低的预期测试错误能保证低最坏情况遗憾，但对于任何固定测试错误，都存在现实数据分布导致不匹配的情况。研究进一步显示，即使采用策略正则化技术（如 RLHF），类似问题依然存在，并呼吁开发更可靠的奖励模型学习方法和质量评估标准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "70 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.15753v2",
      "published_date": "2024-06-22 06:43:51 UTC",
      "updated_date": "2025-03-04 15:17:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:37:20.205734"
    },
    {
      "arxiv_id": "2406.15752v1",
      "title": "TacoLM: GaTed Attention Equipped Codec Language Model are Efficient Zero-Shot Text to Speech Synthesizers",
      "title_zh": "翻译失败",
      "authors": [
        "Yakun Song",
        "Zhuo Chen",
        "Xiaofei Wang",
        "Ziyang Ma",
        "Guanrou Yang",
        "Xie Chen"
      ],
      "abstract": "Neural codec language model (LM) has demonstrated strong capability in\nzero-shot text-to-speech (TTS) synthesis. However, the codec LM often suffers\nfrom limitations in inference speed and stability, due to its auto-regressive\nnature and implicit alignment between text and audio. In this work, to handle\nthese challenges, we introduce a new variant of neural codec LM, namely TacoLM.\nSpecifically, TacoLM introduces a gated attention mechanism to improve the\ntraining and inference efficiency and reduce the model size. Meanwhile, an\nadditional gated cross-attention layer is included for each decoder layer,\nwhich improves the efficiency and content accuracy of the synthesized speech.\nIn the evaluation of the Librispeech corpus, the proposed TacoLM achieves a\nbetter word error rate, speaker similarity, and mean opinion score, with 90%\nfewer parameters and 5.2 times speed up, compared with VALL-E. Demo and code is\navailable at https://ereboas.github.io/TacoLM/.",
      "tldr_zh": "本文提出了一种新型神经编解码器语言模型（neural codec language model）TacoLM，用于高效的零样本文本到语音（zero-shot text-to-speech, TTS）合成，以解决现有模型的推理速度和稳定性问题。TacoLM 引入 gated attention 机制来提升训练和推理效率，同时在每个解码器层添加 gated cross-attention 层，以提高合成的语音内容准确性并减少模型大小。在 Librispeech 语料库评估中，TacoLM 相较于 VALL-E 实现了更好的词错误率、说话者相似度和主观意见分（mean opinion score），并以 90% 更少的参数和 5.2 倍的速度提升。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "INTERSPEECH 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.15752v1",
      "published_date": "2024-06-22 06:39:52 UTC",
      "updated_date": "2024-06-22 06:39:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:37:32.798590"
    },
    {
      "arxiv_id": "2406.15742v1",
      "title": "Probabilistic Programming with Programmable Variational Inference",
      "title_zh": "概率编程与可编程变分推断",
      "authors": [
        "McCoy R. Becker",
        "Alexander K. Lew",
        "Xiaoyan Wang",
        "Matin Ghavami",
        "Mathieu Huot",
        "Martin C. Rinard",
        "Vikash K. Mansinghka"
      ],
      "abstract": "Compared to the wide array of advanced Monte Carlo methods supported by\nmodern probabilistic programming languages (PPLs), PPL support for variational\ninference (VI) is less developed: users are typically limited to a predefined\nselection of variational objectives and gradient estimators, which are\nimplemented monolithically (and without formal correctness arguments) in PPL\nbackends. In this paper, we propose a more modular approach to supporting\nvariational inference in PPLs, based on compositional program transformation.\nIn our approach, variational objectives are expressed as programs, that may\nemploy first-class constructs for computing densities of and expected values\nunder user-defined models and variational families. We then transform these\nprograms systematically into unbiased gradient estimators for optimizing the\nobjectives they define. Our design enables modular reasoning about many\ninteracting concerns, including automatic differentiation, density\naccumulation, tracing, and the application of unbiased gradient estimation\nstrategies. Additionally, relative to existing support for VI in PPLs, our\ndesign increases expressiveness along three axes: (1) it supports an open-ended\nset of user-defined variational objectives, rather than a fixed menu of\noptions; (2) it supports a combinatorial space of gradient estimation\nstrategies, many not automated by today's PPLs; and (3) it supports a broader\nclass of models and variational families, because it supports constructs for\napproximate marginalization and normalization (previously introduced only for\nMonte Carlo inference). We implement our approach in an extension to the Gen\nprobabilistic programming system (genjax.vi, implemented in JAX), and evaluate\non several deep generative modeling tasks, showing minimal performance overhead\nvs. hand-coded implementations and performance competitive with\nwell-established open-source PPLs.",
      "tldr_zh": "本论文提出了一种模块化的变分推理 (Variational Inference) 方法，用于概率编程语言 (PPLs)，通过组合程序转换来解决现有 PPLs 在变分目标和梯度估计器支持上的局限性。用户可以表达自定义变分目标程序，利用第一类结构计算密度和期望值，并系统地将这些程序转换为无偏梯度估计器，从而支持自动微分、密度积累和多种梯度策略。相比现有系统，该方法提升了表达性，包括开放式变分目标、组合梯度估计策略以及更广泛的模型和变分家族支持；实验在 Gen 的扩展 (genjax.vi，使用 JAX) 上显示，其性能开销最小，并与知名开源 PPLs 相当。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.PL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15742v1",
      "published_date": "2024-06-22 05:49:37 UTC",
      "updated_date": "2024-06-22 05:49:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:37:43.416513"
    },
    {
      "arxiv_id": "2406.15741v3",
      "title": "Ladder: A Model-Agnostic Framework Boosting LLM-based Machine Translation to the Next Level",
      "title_zh": "Ladder：一种模型无关框架，将基于LLM的机器翻译提升到新高度",
      "authors": [
        "Zhaopeng Feng",
        "Ruizhe Chen",
        "Yan Zhang",
        "Zijie Meng",
        "Zuozhu Liu"
      ],
      "abstract": "General-purpose Large Language Models (LLMs) like GPT-4 have achieved\nremarkable advancements in machine translation (MT) by leveraging extensive web\ncontent. On the other hand, translation-specific LLMs are built by pre-training\non domain-specific monolingual corpora and fine-tuning with human-annotated\ntranslation data. Despite the superior performance, these methods either demand\nan unprecedented scale of computing and data or substantial human editing and\nannotation efforts. In this paper, we develop MT-Ladder, a novel model-agnostic\nand cost-effective tool to refine the performance of general LLMs for MT.\nMT-Ladder is trained on pseudo-refinement triplets which can be easily obtained\nfrom existing LLMs without additional human cost. During training, we propose a\nhierarchical fine-tuning strategy with an easy-to-hard schema, improving\nMT-Ladder's refining performance progressively. The trained MT-Ladder can be\nseamlessly integrated with any general-purpose LLMs to boost their translation\nperformance. By utilizing Gemma-2B/7B as the backbone, MT-Ladder-2B can elevate\nraw translations to the level of top-tier open-source models (e.g., refining\nBigTranslate-13B with +6.91 BLEU and +3.52 COMET for XX-En), and MT-Ladder-7B\ncan further enhance model performance to be on par with the state-of-the-art\nGPT-4. Extensive ablation and analysis corroborate the effectiveness of\nMT-Ladder in diverse settings. Our code is available at\nhttps://github.com/fzp0424/MT-Ladder",
      "tldr_zh": "本文提出 MT-Ladder，一种模型无关（model-agnostic）和成本有效的框架，用于提升一般用途大型语言模型（LLMs）在机器翻译（MT）上的性能。MT-Ladder 通过利用从现有 LLMs 获得的伪精炼三元组（pseudo-refinement triplets）进行训练，并采用分层微调策略（hierarchical fine-tuning）以易到难的模式逐步优化精炼效果。实验显示，基于 Gemma-2B/7B 的 MT-Ladder-2B 可将原始翻译提升至顶级开源模型水平（如 BigTranslate-13B 的 BLEU +6.91 和 COMET +3.52），而 MT-Ladder-7B 则能与最先进的 GPT-4 性能相当。该框架经广泛消融分析验证其在多种场景中的有效性，并已在 GitHub 上开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Main. Data and code are available at\n  https://github.com/fzp0424/MT-Ladder",
      "pdf_url": "http://arxiv.org/pdf/2406.15741v3",
      "published_date": "2024-06-22 05:33:35 UTC",
      "updated_date": "2024-10-29 05:15:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:37:58.644893"
    },
    {
      "arxiv_id": "2406.15736v2",
      "title": "Evaluating Large Vision-and-Language Models on Children's Mathematical Olympiads",
      "title_zh": "翻译失败",
      "authors": [
        "Anoop Cherian",
        "Kuan-Chuan Peng",
        "Suhas Lohit",
        "Joanna Matthiesen",
        "Kevin Smith",
        "Joshua B. Tenenbaum"
      ],
      "abstract": "Recent years have seen a significant progress in the general-purpose problem\nsolving abilities of large vision and language models (LVLMs), such as ChatGPT,\nGemini, etc.; some of these breakthroughs even seem to enable AI models to\noutperform human abilities in varied tasks that demand higher-order cognitive\nskills. Are the current large AI models indeed capable of generalized problem\nsolving as humans do? A systematic analysis of AI capabilities for joint vision\nand text reasoning, however, is missing in the current scientific literature.\nIn this paper, we make an effort towards filling this gap, by evaluating\nstate-of-the-art LVLMs on their mathematical and algorithmic reasoning\nabilities using visuo-linguistic problems from children's Olympiads.\nSpecifically, we consider problems from the Mathematical Kangaroo (MK)\nOlympiad, which is a popular international competition targeted at children\nfrom grades 1-12, that tests children's deeper mathematical abilities using\npuzzles that are appropriately gauged to their age and skills. Using the\npuzzles from MK, we created a dataset, dubbed SMART-840, consisting of 840\nproblems from years 2020-2024. With our dataset, we analyze LVLMs power on\nmathematical reasoning; their responses on our puzzles offer a direct way to\ncompare against that of children. Our results show that modern LVLMs do\ndemonstrate increasingly powerful reasoning skills in solving problems for\nhigher grades, but lack the foundations to correctly answer problems designed\nfor younger children. Further analysis shows that there is no significant\ncorrelation between the reasoning capabilities of AI models and that of young\nchildren, and their capabilities appear to be based on a different type of\nreasoning than the cumulative knowledge that underlies children's mathematics\nand logic skills.",
      "tldr_zh": "本论文评估了大型视觉和语言模型（LVLMs，如ChatGPT和Gemini）在儿童数学奥林匹克问题上的数学和算法推理能力，旨在填补AI通用问题解决能力的系统性分析空白。研究者创建了SMART-840数据集，该数据集包含840个来自Mathematical Kangaroo (MK)奥林匹克的视觉-语言问题，针对1-12年级儿童的数学难题。结果显示，LVLMs在处理高年级问题时表现出越来越强的推理技能，但无法正确解答低年级问题，且其能力与儿童的推理无显著相关性，表明AI模型依赖不同的推理机制而非儿童的累积知识基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024 (Datasets and Benchmarks Track)",
      "pdf_url": "http://arxiv.org/pdf/2406.15736v2",
      "published_date": "2024-06-22 05:04:39 UTC",
      "updated_date": "2024-12-05 23:59:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:38:08.585097"
    },
    {
      "arxiv_id": "2406.15735v3",
      "title": "Identifying and Solving Conditional Image Leakage in Image-to-Video Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Min Zhao",
        "Hongzhou Zhu",
        "Chendong Xiang",
        "Kaiwen Zheng",
        "Chongxuan Li",
        "Jun Zhu"
      ],
      "abstract": "Diffusion models have obtained substantial progress in image-to-video\ngeneration. However, in this paper, we find that these models tend to generate\nvideos with less motion than expected. We attribute this to the issue called\nconditional image leakage, where the image-to-video diffusion models (I2V-DMs)\ntend to over-rely on the conditional image at large time steps. We further\naddress this challenge from both inference and training aspects. First, we\npropose to start the generation process from an earlier time step to avoid the\nunreliable large-time steps of I2V-DMs, as well as an initial noise\ndistribution with optimal analytic expressions (Analytic-Init) by minimizing\nthe KL divergence between it and the actual marginal distribution to bridge the\ntraining-inference gap. Second, we design a time-dependent noise distribution\n(TimeNoise) for the conditional image during training, applying higher noise\nlevels at larger time steps to disrupt it and reduce the model's dependency on\nit. We validate these general strategies on various I2V-DMs on our collected\nopen-domain image benchmark and the UCF101 dataset. Extensive results show that\nour methods outperform baselines by producing higher motion scores with lower\nerrors while maintaining image alignment and temporal consistency, thereby\nyielding superior overall performance and enabling more accurate motion\ncontrol. The project page: \\url{https://cond-image-leak.github.io/}.",
      "tldr_zh": "这篇论文识别并解决了图像到视频扩散模型（Image-to-Video Diffusion Models, I2V-DMs）中的Conditional Image Leakage问题，该问题导致生成的视频运动不足，因为模型在大型时间步骤中过度依赖条件图像。研究从推理和训练两个方面提出解决方案：在推理阶段，通过从较早时间步骤开始生成并采用Analytic-Init（优化初始噪声分布以最小化KL divergence，桥接训练-推理差距）；在训练阶段，引入TimeNoise（时间相关的噪声分布），在大型时间步骤施加更多噪声以减少对条件图像的依赖。实验在开放域图像基准和UCF101数据集上验证，结果显示该方法显著提高了视频运动分数、降低了错误率，同时保持图像对齐和时间一致性，从而提升整体性能并实现更精确的运动控制。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024. Project page: https://cond-image-leak.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2406.15735v3",
      "published_date": "2024-06-22 04:56:16 UTC",
      "updated_date": "2024-11-06 03:53:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:38:19.749546"
    },
    {
      "arxiv_id": "2406.15734v2",
      "title": "RankAdaptor: Hierarchical Rank Allocation for Efficient Fine-Tuning Pruned LLMs via Performance Model",
      "title_zh": "翻译失败",
      "authors": [
        "Changhai Zhou",
        "Shijie Han",
        "Lining Yang",
        "Yuhua Zhou",
        "Xu Cheng",
        "Yibin Wang",
        "Hongguang Li"
      ],
      "abstract": "The efficient compression of large language models (LLMs) has become\nincreasingly popular. However, recovering the performance of compressed LLMs\nremains a major challenge. The current practice in LLM compression entails the\nimplementation of structural pruning, complemented by a recovery phase that\nleverages the Low-Rank Adaptation (LoRA) algorithm. Structural pruning's uneven\nmodification of model architecture, coupled with standard LoRA's fixed\nconfiguration allocation across layers in an online pipeline, leads to\nsuboptimal performance in various downstream tasks for pruned models. To\naddress this challenge, we introduce RankAdaptor, a hierarchical rank\nallocation method that enables efficient fine-tuning of pruned LLMs according\nto layerwise specific recovery requirements. We employ a performance model that\nconducts offline meta-learning and online incremental learning to explore\noptimal rank values for each layer. Comprehensive experiments on popular\nbenchmarks show that RankAdaptor consistently outperforms state-of-the-art\nmethods across a variety of pruning settings and LLM architectures, with\nimprovements ranging from 0.7\\% to 5.5\\%.",
      "tldr_zh": "这篇论文针对大型语言模型 (LLMs) 的高效压缩问题，提出了 RankAdaptor，一种分层秩分配方法，用于根据层级特定恢复需求优化剪枝后 LLMs 的微调过程。RankAdaptor 利用性能模型进行离线元学习和在线增量学习，以探索每个层的 optimal rank 值，从而解决传统 Low-Rank Adaptation (LoRA) 的固定配置不足。实验结果显示，该方法在各种剪枝设置和 LLM 架构上 consistently 优于最先进技术，提升幅度为 0.7% 到 5.5%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15734v2",
      "published_date": "2024-06-22 04:52:58 UTC",
      "updated_date": "2024-12-16 08:19:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:38:30.980806"
    },
    {
      "arxiv_id": "2406.15732v1",
      "title": "AI-Driven Approaches for Optimizing Power Consumption: A Comprehensive Survey",
      "title_zh": "AI驱动的电力消耗优化方法：一个全面综述",
      "authors": [
        "Parag Biswas",
        "Abdur Rashid",
        "Angona Biswas",
        "Md Abdullah Al Nasim",
        "Kishor Datta Gupta",
        "Roy George"
      ],
      "abstract": "Reduced environmental effect, lower operating costs, and a stable and\nsustainable energy supply for current and future generations are the main\nreasons why power optimization is important. Power optimization makes ensuring\nthat energy is used more effectively, cutting down on waste and optimizing the\nutilization of resources.In today's world, power optimization and artificial\nintelligence (AI) integration are essential to changing the way energy is\nproduced, used, and distributed. Real-time monitoring and analysis of power\nusage trends is made possible by AI-driven algorithms and predictive analytics,\nwhich enable dynamic modifications to effectively satisfy demand. Efficiency\nand sustainability are increased when power consumption is optimized in\ndifferent sectors thanks to the use of intelligent systems. This survey paper\ncomprises an extensive review of the several AI techniques used for power\noptimization as well as a methodical analysis of the literature for the study\nof various intelligent system application domains across different disciplines\nof power consumption.This literature review identifies the performance and\noutcomes of 17 different research methods by assessing them, and it aims to\ndistill valuable insights into their strengths and limitations. Furthermore,\nthis article outlines future directions in the integration of AI for power\nconsumption optimization.",
      "tldr_zh": "这篇调查论文全面审阅了AI驱动的方法，用于优化电力消耗，强调AI通过实时监控、预测分析和动态调整来提高能源效率、减少浪费，并促进可持续能源供应。论文系统分析了不同领域的应用，包括17种研究方法的性能评估，并总结了这些方法的优势、局限性及宝贵见解。最后，它指出了AI在电力优化领域的未来发展方向，如更智能的系统整合和创新应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15732v1",
      "published_date": "2024-06-22 04:42:37 UTC",
      "updated_date": "2024-06-22 04:42:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:38:43.504218"
    },
    {
      "arxiv_id": "2406.15731v1",
      "title": "Breaking Secure Aggregation: Label Leakage from Aggregated Gradients in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhibo Wang",
        "Zhiwei Chang",
        "Jiahui Hu",
        "Xiaoyi Pang",
        "Jiacheng Du",
        "Yongle Chen",
        "Kui Ren"
      ],
      "abstract": "Federated Learning (FL) exhibits privacy vulnerabilities under gradient\ninversion attacks (GIAs), which can extract private information from individual\ngradients. To enhance privacy, FL incorporates Secure Aggregation (SA) to\nprevent the server from obtaining individual gradients, thus effectively\nresisting GIAs. In this paper, we propose a stealthy label inference attack to\nbypass SA and recover individual clients' private labels. Specifically, we\nconduct a theoretical analysis of label inference from the aggregated gradients\nthat are exclusively obtained after implementing SA. The analysis results\nreveal that the inputs (embeddings) and outputs (logits) of the final fully\nconnected layer (FCL) contribute to gradient disaggregation and label\nrestoration. To preset the embeddings and logits of FCL, we craft a fishing\nmodel by solely modifying the parameters of a single batch normalization (BN)\nlayer in the original model. Distributing client-specific fishing models, the\nserver can derive the individual gradients regarding the bias of FCL by\nresolving a linear system with expected embeddings and the aggregated gradients\nas coefficients. Then the labels of each client can be precisely computed based\non preset logits and gradients of FCL's bias. Extensive experiments show that\nour attack achieves large-scale label recovery with 100\\% accuracy on various\ndatasets and model architectures.",
      "tldr_zh": "该论文揭示了Federated Learning (FL)中Secure Aggregation (SA)的隐私漏洞，提出了一种隐秘的标签推断攻击，能够从聚合梯度中恢复个体客户端的私有标签，从而绕过SA的保护。攻击方法包括理论分析聚合梯度的fully connected layer (FCL)输入（嵌入）和输出（logits），并通过修改单个batch normalization (BN)层创建fishing model，以预设嵌入和logits，然后解决线性系统计算个体梯度。实验结果显示，该攻击在各种数据集和模型架构上实现了100%标签恢复准确率，强调了FL系统中潜在的安全风险。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "10 pages, conference to IEEE INFOCOM 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.15731v1",
      "published_date": "2024-06-22 04:42:18 UTC",
      "updated_date": "2024-06-22 04:42:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:38:56.481569"
    },
    {
      "arxiv_id": "2406.16965v2",
      "title": "Present and Future of AI in Renewable Energy Domain : A Comprehensive Survey",
      "title_zh": "人工智能在可再生能源领域的发展现状与未来展望：一项全面综述",
      "authors": [
        "Abdur Rashid",
        "Parag Biswas",
        "Angona Biswas",
        "MD Abdullah Al Nasim",
        "Kishor Datta Gupta",
        "Roy George"
      ],
      "abstract": "Artificial intelligence (AI) has become a crucial instrument for streamlining\nprocesses in various industries, including electrical power systems, as a\nresult of recent digitalization. Algorithms for artificial intelligence are\ndata-driven models that are based on statistical learning theory and are used\nas a tool to take use of the data that the power system and its users generate.\nInitially, we perform a thorough literature analysis of artificial intelligence\n(AI) applications related to renewable energy (RE). Next, we present a thorough\nanalysis of renewable energy factories and assess their suitability, along with\na list of the most widely used and appropriate AI algorithms. Nine AI-based\nstrategies are identified here to assist Renewable Energy (RE) in contemporary\npower systems. This survey paper comprises an extensive review of the several\nAI techniques used for renewable energy as well as a methodical analysis of the\nliterature for the study of various intelligent system application domains\nacross different disciplines of renewable energy. This literature review\nidentifies the performance and outcomes of nine different research methods by\nassessing them, and it aims to distill valuable insights into their strengths\nand limitations. This study also addressed three main topics: using AI\ntechnology for renewable power generation, utilizing AI for renewable energy\nforecasting, and optimizing energy systems. Additionally, it explored AI's\nsuperiority over conventional models in controllability, data handling,\ncyberattack prevention, smart grid implementation, robotics- AI's significance\nin shaping the future of the energy industry. Furthermore, this article\noutlines future directions in the integration of AI for renewable energy.",
      "tldr_zh": "这篇调查论文全面审视了人工智能（AI）在可再生能源（Renewable Energy, RE）领域的当前应用和未来潜力。通过文献分析和系统评估，论文识别了九种AI策略，用于RE发电、预测和系统优化，并比较了AI在可控性、数据处理、防网络攻击以及智能电网（Smart Grid）等方面的优势，优于传统模型。研究评估了各种AI算法的性能、优势和局限性，为RE领域提供了宝贵见解。最后，论文概述了AI与RE集成未来的方向，包括机器人应用和能源行业转型的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16965v2",
      "published_date": "2024-06-22 04:36:09 UTC",
      "updated_date": "2024-10-19 19:23:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:39:09.896855"
    },
    {
      "arxiv_id": "2406.15723v1",
      "title": "Acoustic Feature Mixup for Balanced Multi-aspect Pronunciation Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Heejin Do",
        "Wonjun Lee",
        "Gary Geunbae Lee"
      ],
      "abstract": "In automated pronunciation assessment, recent emphasis progressively lies on\nevaluating multiple aspects to provide enriched feedback. However, acquiring\nmulti-aspect-score labeled data for non-native language learners' speech poses\nchallenges; moreover, it often leads to score-imbalanced distributions. In this\npaper, we propose two Acoustic Feature Mixup strategies, linearly and\nnon-linearly interpolating with the in-batch averaged feature, to address data\nscarcity and score-label imbalances. Primarily using goodness-of-pronunciation\nas an acoustic feature, we tailor mixup designs to suit pronunciation\nassessment. Further, we integrate fine-grained error-rate features by comparing\nspeech recognition results with the original answer phonemes, giving direct\nhints for mispronunciation. Effective mixing of the acoustic features notably\nenhances overall scoring performances on the speechocean762 dataset, and\ndetailed analysis highlights our potential to predict unseen distortions.",
      "tldr_zh": "本论文针对自动发音评估中的数据稀缺和分数不平衡问题，提出两种Acoustic Feature Mixup策略，即线性插值和非线性插值，与批次内平均特征相结合，以实现多方面发音评估的平衡。方法主要利用goodness-of-pronunciation作为声学特征，并整合细粒度错误率特征，通过比较语音识别结果与原始音素，提供误发音的直接提示。实验在speechocean762数据集上显示，该策略显著提升整体评分性能，并展现出预测未见扭曲的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.15723v1",
      "published_date": "2024-06-22 03:56:29 UTC",
      "updated_date": "2024-06-22 03:56:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:39:21.360720"
    },
    {
      "arxiv_id": "2406.16964v2",
      "title": "Are Language Models Actually Useful for Time Series Forecasting?",
      "title_zh": "翻译失败",
      "authors": [
        "Mingtian Tan",
        "Mike A. Merrill",
        "Vinayak Gupta",
        "Tim Althoff",
        "Thomas Hartvigsen"
      ],
      "abstract": "Large language models (LLMs) are being applied to time series forecasting.\nBut are language models actually useful for time series? In a series of\nablation studies on three recent and popular LLM-based time series forecasting\nmethods, we find that removing the LLM component or replacing it with a basic\nattention layer does not degrade forecasting performance -- in most cases, the\nresults even improve! We also find that despite their significant computational\ncost, pretrained LLMs do no better than models trained from scratch, do not\nrepresent the sequential dependencies in time series, and do not assist in\nfew-shot settings. Additionally, we explore time series encoders and find that\npatching and attention structures perform similarly to LLM-based forecasters.",
      "tldr_zh": "这篇论文通过对三个流行的大型语言模型(LLMs)基于时间序列预测方法进行消融研究，评估了LLMs的实际效用。结果显示，移除LLMs组件或用基本注意力层替换后，预测性能不但没有下降，反而在大多数情况下有所改善。研究还发现，预训练的LLMs不如从零训练的模型表现更好，无法有效捕捉时间序列中的顺序依赖性，且在少样本设置中没有显著优势。此外，论文探索了时间序列编码器，如patching和attention结构，发现它们的表现与LLM-based预测器类似，从而质疑了LLMs在这一领域的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2024 (Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2406.16964v2",
      "published_date": "2024-06-22 03:33:38 UTC",
      "updated_date": "2024-10-26 01:43:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:39:34.456906"
    },
    {
      "arxiv_id": "2406.16963v1",
      "title": "Large Language Models for Link Stealing Attacks Against Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Faqian Guan",
        "Tianqing Zhu",
        "Hui Sun",
        "Wanlei Zhou",
        "Philip S. Yu"
      ],
      "abstract": "Graph data contains rich node features and unique edge information, which\nhave been applied across various domains, such as citation networks or\nrecommendation systems. Graph Neural Networks (GNNs) are specialized for\nhandling such data and have shown impressive performance in many applications.\nHowever, GNNs may contain of sensitive information and susceptible to privacy\nattacks. For example, link stealing is a type of attack in which attackers\ninfer whether two nodes are linked or not. Previous link stealing attacks\nprimarily relied on posterior probabilities from the target GNN model,\nneglecting the significance of node features. Additionally, variations in node\nclasses across different datasets lead to different dimensions of posterior\nprobabilities. The handling of these varying data dimensions posed a challenge\nin using a single model to effectively conduct link stealing attacks on\ndifferent datasets. To address these challenges, we introduce Large Language\nModels (LLMs) to perform link stealing attacks on GNNs. LLMs can effectively\nintegrate textual features and exhibit strong generalizability, enabling\nattacks to handle diverse data dimensions across various datasets. We design\ntwo distinct LLM prompts to effectively combine textual features and posterior\nprobabilities of graph nodes. Through these designed prompts, we fine-tune the\nLLM to adapt to the link stealing attack task. Furthermore, we fine-tune the\nLLM using multiple datasets and enable the LLM to learn features from different\ndatasets simultaneously. Experimental results show that our approach\nsignificantly enhances the performance of existing link stealing attack tasks\nin both white-box and black-box scenarios. Our method can execute link stealing\nattacks across different datasets using only a single model, making link\nstealing attacks more applicable to real-world scenarios.",
      "tldr_zh": "本文提出了一种利用 Large Language Models (LLMs) 针对 Graph Neural Networks (GNNs) 进行链接窃取攻击（link stealing attacks）的新方法，以解决现有攻击忽略节点特征（node features）和不同数据集后验概率（posterior probabilities）维度变化的问题。研究设计了两种 LLM 提示来整合文本特征（textual features）和后验概率，并通过多数据集微调，使单一模型能够同时处理多种数据集的攻击任务。实验结果显示，该方法在白盒和黑盒场景下显著提升了攻击性能，并提高了链接窃取攻击在真实场景中的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16963v1",
      "published_date": "2024-06-22 02:47:24 UTC",
      "updated_date": "2024-06-22 02:47:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:39:47.581063"
    },
    {
      "arxiv_id": "2406.15708v2",
      "title": "Teach Better or Show Smarter? On Instructions and Exemplars in Automatic Prompt Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Xingchen Wan",
        "Ruoxi Sun",
        "Hootan Nakhost",
        "Sercan O. Arik"
      ],
      "abstract": "Large language models have demonstrated remarkable capabilities, but their\nperformance is heavily reliant on effective prompt engineering. Automatic\nprompt optimization (APO) methods are designed to automate this and can be\nbroadly categorized into those targeting instructions (instruction\noptimization, IO) vs. those targeting exemplars (exemplar optimization, EO).\nDespite their shared objective, these have evolved rather independently, with\nIO receiving more research attention recently. This paper seeks to bridge this\ngap by comprehensively comparing the performance of representative IO and EO\ntechniques both isolation and combination on a diverse set of challenging\ntasks. Our findings reveal that intelligently reusing model-generated\ninput-output pairs obtained from evaluating prompts on the validation set as\nexemplars, consistently improves performance on top of IO methods but is\ncurrently under-investigated. We also find that despite the recent focus on IO,\nhow we select exemplars can outweigh how we optimize instructions, with EO\nstrategies as simple as random search outperforming state-of-the-art IO methods\nwith seed instructions without any optimization. Moreover, we observe a synergy\nbetween EO and IO, with optimal combinations surpassing the individual\ncontributions. We conclude that studying exemplar optimization both as a\nstandalone method and its optimal combination with instruction optimization\nremain a crucial aspect of APO and deserve greater consideration in future\nresearch, even in the era of highly capable instruction-following models.",
      "tldr_zh": "本论文探讨了自动提示优化（Automatic Prompt Optimization, APO）中指令优化（Instruction Optimization, IO）和示例优化（Exemplar Optimization, EO）的比较，评估了它们在各种挑战性任务上的单独和组合性能。研究发现，重用模型生成的输入-输出对作为示例，能显著提升 IO 方法的效果，但这一领域目前研究不足。结果显示，简单的 EO 策略如随机搜索，可能优于先进的 IO 方法，而 IO 和 EO 的结合能产生协同效应，进一步提高性能。作者强调，EO 作为独立方法及其与 IO 的最佳组合，应在未来研究中得到更多关注，尤其在高性能指令模型时代。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Expanded version of the NeurIPS 2024 paper",
      "pdf_url": "http://arxiv.org/pdf/2406.15708v2",
      "published_date": "2024-06-22 02:07:10 UTC",
      "updated_date": "2024-11-06 22:07:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:39:58.572984"
    },
    {
      "arxiv_id": "2406.16962v1",
      "title": "MetaGreen: Meta-Learning Inspired Transformer Selection for Green Semantic Communication",
      "title_zh": "翻译失败",
      "authors": [
        "Shubhabrata Mukherjee",
        "Cory Beard",
        "Sejun Song"
      ],
      "abstract": "Semantic Communication can transform the way we transmit information,\nprioritizing meaningful and effective content over individual symbols or bits.\nThis evolution promises significant benefits, including reduced latency, lower\nbandwidth usage, and higher throughput compared to traditional communication.\nHowever, the development of Semantic Communication faces a crucial challenge:\nthe need for universal metrics to benchmark the joint effects of semantic\ninformation loss and energy consumption. This research introduces an innovative\nsolution: the ``Energy-Optimized Semantic Loss'' (EOSL) function, a novel\nmulti-objective loss function that effectively balances semantic information\nloss and energy consumption. Through comprehensive experiments on transformer\nmodels, including energy benchmarking, we demonstrate the remarkable\neffectiveness of EOSL-based model selection. We have established that\nEOSL-based transformer model selection achieves up to 83\\% better\nsimilarity-to-power ratio (SPR) compared to BLEU score-based selection and 67\\%\nbetter SPR compared to solely lowest power usage-based selection. Furthermore,\nwe extend the applicability of EOSL to diverse and varying contexts, inspired\nby the principles of Meta-Learning. By cumulatively applying EOSL, we enable\nthe model selection system to adapt to this change, leveraging historical EOSL\nvalues to guide the learning process. This work lays the foundation for\nenergy-efficient model selection and the development of green semantic\ncommunication.",
      "tldr_zh": "这篇论文针对语义通信（Semantic Communication）中的能源效率挑战，提出了一种受 Meta-Learning 启发的框架 MetaGreen，用于优化 Transformer 模型选择。研究引入“Energy-Optimized Semantic Loss”（EOSL）函数，这是一个多目标损失函数，能够平衡语义信息损失和能源消耗。实验结果显示，基于 EOSL 的模型选择比基于 BLEU 分数的选择提高了相似度-功率比（SPR）高达 83%，并比仅考虑最低功率选择的提高了 67%。此外，通过利用历史 EOSL 值，该方法实现了对多样化上下文的适应，为绿色语义通信的发展奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2310.07592",
      "pdf_url": "http://arxiv.org/pdf/2406.16962v1",
      "published_date": "2024-06-22 00:49:40 UTC",
      "updated_date": "2024-06-22 00:49:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T23:40:11.147064"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 56,
  "processed_papers_count": 56,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T23:40:37.654767"
}