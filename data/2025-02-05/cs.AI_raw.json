[
  {
    "arxiv_id": "2502.03678v2",
    "title": "Reflection-Window Decoding: Text Generation with Selective Refinement",
    "authors": [
      "Zeyu Tang",
      "Zhenhao Chen",
      "Loka Li",
      "Xiangchen Song",
      "Yunlong Deng",
      "Yifan Shen",
      "Guangyi Chen",
      "Peter Spirtes",
      "Kun Zhang"
    ],
    "abstract": "The autoregressive decoding for text generation in large language models\n(LLMs), while widely used, is inherently suboptimal due to the lack of a\nbuilt-in mechanism to perform refinement and/or correction of the generated\ncontent. In this paper, we consider optimality in terms of the joint\nprobability over the generated response, when jointly considering all tokens at\nthe same time. We theoretically characterize the potential deviation of the\nautoregressively generated response from its globally optimal counterpart that\nis of the same length. Our analysis suggests that we need to be cautious when\nnoticeable uncertainty arises during text generation, which may signal the\nsub-optimality of the generation history. To address the pitfall of\nautoregressive decoding for text generation, we propose an approach that\nincorporates a sliding reflection window and a pausing criterion, such that\nrefinement and generation can be carried out interchangeably as the decoding\nproceeds. Our selective refinement framework strikes a balance between\nefficiency and optimality, and our extensive experimental results demonstrate\nthe effectiveness of our approach.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03678v2",
    "published_date": "2025-02-05 23:53:08 UTC",
    "updated_date": "2025-03-10 19:34:32 UTC"
  },
  {
    "arxiv_id": "2502.04390v1",
    "title": "In Praise of Stubbornness: The Case for Cognitive-Dissonance-Aware Knowledge Updates in LLMs",
    "authors": [
      "Simone Clemente",
      "Zied Ben Houidi",
      "Alexis Huet",
      "Dario Rossi",
      "Giulio Franzese",
      "Pietro Michiardi"
    ],
    "abstract": "Despite remarkable capabilities, large language models (LLMs) struggle to\ncontinually update their knowledge without catastrophic forgetting. In\ncontrast, humans effortlessly integrate new information, detect conflicts with\nexisting beliefs, and selectively update their mental models. This paper\nintroduces a cognitive-inspired investigation paradigm to study continual\nknowledge updating in LLMs. We implement two key components inspired by human\ncognition: (1) Dissonance and Familiarity Awareness, analyzing model behavior\nto classify information as novel, familiar, or dissonant; and (2) Targeted\nNetwork Updates, which track neural activity to identify frequently used\n(stubborn) and rarely used (plastic) neurons. Through carefully designed\nexperiments in controlled settings, we uncover a number of empirical findings\ndemonstrating the potential of this approach. First, dissonance detection is\nfeasible using simple activation and gradient features, suggesting potential\nfor cognitive-inspired training. Second, we find that non-dissonant updates\nlargely preserve prior knowledge regardless of targeting strategy, revealing\ninherent robustness in LLM knowledge integration. Most critically, we discover\nthat dissonant updates prove catastrophically destructive to the model's\nknowledge base, indiscriminately affecting even information unrelated to the\ncurrent updates. This suggests fundamental limitations in how neural networks\nhandle contradictions and motivates the need for new approaches to knowledge\nupdating that better mirror human cognitive mechanisms.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04390v1",
    "published_date": "2025-02-05 23:49:33 UTC",
    "updated_date": "2025-02-05 23:49:33 UTC"
  },
  {
    "arxiv_id": "2502.03674v1",
    "title": "An Empirical Study of Methods for Small Object Detection from Satellite Imagery",
    "authors": [
      "Xiaohui Yuan",
      "Aniv Chakravarty",
      "Lichuan Gu",
      "Zhenchun Wei",
      "Elinor Lichtenberg",
      "Tian Chen"
    ],
    "abstract": "This paper reviews object detection methods for finding small objects from\nremote sensing imagery and provides an empirical evaluation of four\nstate-of-the-art methods to gain insights into method performance and technical\nchallenges. In particular, we use car detection from urban satellite images and\nbee box detection from satellite images of agricultural lands as application\nscenarios. Drawing from the existing surveys and literature, we identify\nseveral top-performing methods for the empirical study. Public, high-resolution\nsatellite image datasets are used in our experiments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03674v1",
    "published_date": "2025-02-05 23:40:54 UTC",
    "updated_date": "2025-02-05 23:40:54 UTC"
  },
  {
    "arxiv_id": "2502.04389v1",
    "title": "Overcoming Vision Language Model Challenges in Diagram Understanding: A Proof-of-Concept with XML-Driven Large Language Models Solutions",
    "authors": [
      "Shue Shiinoki",
      "Ryo Koshihara",
      "Hayato Motegi",
      "Masumi Morishige"
    ],
    "abstract": "Diagrams play a crucial role in visually conveying complex relationships and\nprocesses within business documentation. Despite recent advances in\nVision-Language Models (VLMs) for various image understanding tasks, accurately\nidentifying and extracting the structures and relationships depicted in\ndiagrams continues to pose significant challenges. This study addresses these\nchallenges by proposing a text-driven approach that bypasses reliance on VLMs'\nvisual recognition capabilities. Instead, it utilizes the editable source\nfiles--such as xlsx, pptx or docx--where diagram elements (e.g., shapes, lines,\nannotations) are preserved as textual metadata. In our proof-of-concept, we\nextracted diagram information from xlsx-based system design documents and\ntransformed the extracted shape data into textual input for Large Language\nModels (LLMs). This approach allowed the LLM to analyze relationships and\ngenerate responses to business-oriented questions without the bottleneck of\nimage-based processing. Experimental comparisons with a VLM-based method\ndemonstrated that the proposed text-driven framework yielded more accurate\nanswers for questions requiring detailed comprehension of diagram\nstructures.The results obtained in this study are not limited to the tested\n.xlsx files but can also be extended to diagrams in other documents with source\nfiles, such as Office pptx and docx formats. These findings highlight the\nfeasibility of circumventing VLM constraints through direct textual extraction\nfrom original source files. By enabling robust diagram understanding through\nLLMs, our method offers a promising path toward enhanced workflow efficiency\nand information analysis in real-world business scenarios.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "The related code is available at\n  \\url{https://github.com/galirage/spreadsheet-intelligence}, which provides\n  the core library developed for this research. The experimental code using\n  this library can be found at\n  \\url{https://github.com/galirage/XMLDriven-Diagram-Understanding}",
    "pdf_url": "http://arxiv.org/pdf/2502.04389v1",
    "published_date": "2025-02-05 23:40:26 UTC",
    "updated_date": "2025-02-05 23:40:26 UTC"
  },
  {
    "arxiv_id": "2502.03671v1",
    "title": "Advancing Reasoning in Large Language Models: Promising Methods and Approaches",
    "authors": [
      "Avinash Patil"
    ],
    "abstract": "Large Language Models (LLMs) have succeeded remarkably in various natural\nlanguage processing (NLP) tasks, yet their reasoning capabilities remain a\nfundamental challenge. While LLMs exhibit impressive fluency and factual\nrecall, their ability to perform complex reasoning-spanning logical deduction,\nmathematical problem-solving, commonsense inference, and multi-step\nreasoning-often falls short of human expectations. This survey provides a\ncomprehensive review of emerging techniques enhancing reasoning in LLMs. We\ncategorize existing methods into key approaches, including prompting strategies\n(e.g., Chain-of-Thought reasoning, Self-Consistency, and Tree-of-Thought\nreasoning), architectural innovations (e.g., retrieval-augmented models,\nmodular reasoning networks, and neuro-symbolic integration), and learning\nparadigms (e.g., fine-tuning with reasoning-specific datasets, reinforcement\nlearning, and self-supervised reasoning objectives). Additionally, we explore\nevaluation frameworks used to assess reasoning in LLMs and highlight open\nchallenges, such as hallucinations, robustness, and reasoning generalization\nacross diverse tasks. By synthesizing recent advancements, this survey aims to\nprovide insights into promising directions for future research and practical\napplications of reasoning-augmented LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 Pages, 1 Figure, IEEE Format",
    "pdf_url": "http://arxiv.org/pdf/2502.03671v1",
    "published_date": "2025-02-05 23:31:39 UTC",
    "updated_date": "2025-02-05 23:31:39 UTC"
  },
  {
    "arxiv_id": "2502.18478v1",
    "title": "Beyond Self-Consistency: Loss-Balanced Perturbation-Based Regularization Improves Industrial-Scale Ads Ranking",
    "authors": [
      "Ilqar Ramazanli",
      "Hamid Eghbalzadeh",
      "Xiaoyi Liu",
      "Yang Wang",
      "Jiaxiang Fu",
      "Kaushik Rangadurai",
      "Sem Park",
      "Bo Long",
      "Xue Feng"
    ],
    "abstract": "Perturbation-based regularization techniques address many challenges in\nindustrial-scale large models, particularly with sparse labels, and emphasize\nconsistency and invariance for perturbation in model predictions. One of the\npopular regularization techniques has been various forms of self-consistency,\nwhich involve making small modifications to input data while preserving\ncontextual information and enforcing similar predictions through auxiliary loss\nfunctions. In this work, we explore the first successful application of\nperturbation-based regularization algorithms in large-scale ads ranking models,\nand further propose a novel regularization algorithm, namely, Loss-Balanced\nSmall Perturbation Regularization (LSPR) that can be used in potentially any\ndeep learning model. We have successfully demonstrate that both\nSelf-Consistency Regularization approaches (SCR) and LSPR are scalable and can\nimprove ads delivery systems. By conducting industrial-scale experiments, and\nnumerical analysis, we additionally show that our proposed LSPR, performs\nconsistently better compared to SCR, across various groups and signal\navailability setups. Finally, we report a successful application of the\nproposed LSPR in a billion-scale industrial ranking system, which to the best\nof our knowledge, is the first of its kind, and it is specially designed to\naddress the various scalability challenges (e.g, various surfaces, geological\nlocations, clients and so on) as we will mention in this paper.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18478v1",
    "published_date": "2025-02-05 23:24:52 UTC",
    "updated_date": "2025-02-05 23:24:52 UTC"
  },
  {
    "arxiv_id": "2502.03669v1",
    "title": "Unrealized Expectations: Comparing AI Methods vs Classical Algorithms for Maximum Independent Set",
    "authors": [
      "Yikai Wu",
      "Haoyu Zhao",
      "Sanjeev Arora"
    ],
    "abstract": "AI methods, such as generative models and reinforcement learning, have\nrecently been applied to combinatorial optimization (CO) problems, especially\nNP-hard ones. This paper compares such GPU-based methods with classical\nCPU-based methods on Maximum Independent Set (MIS). Experiments on standard\ngraph families show that AI-based algorithms fail to outperform and, in many\ncases, to match the solution quality of the state-of-art classical solver KaMIS\nrunning on a single CPU. Some GPU-based methods even perform similarly to the\nsimplest heuristic, degree-based greedy. Even with post-processing techniques\nlike local search, AI-based methods still perform worse than CPU-based solvers.\n  We develop a new mode of analysis to reveal that non-backtracking AI methods,\ne.g. LTFT (which is based on GFlowNets), end up reasoning similarly to the\nsimplest degree-based greedy approach, and thus worse than KaMIS. We also find\nthat CPU-based algorithms, notably KaMIS, have strong performance on sparse\nrandom graphs, which appears to refute a well-known conjectured upper bound for\nefficient algorithms from Coja-Oghlan & Efthymiou (2015).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DM",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 7 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.03669v1",
    "published_date": "2025-02-05 23:24:47 UTC",
    "updated_date": "2025-02-05 23:24:47 UTC"
  },
  {
    "arxiv_id": "2503.04746v1",
    "title": "Emerging Practices in Frontier AI Safety Frameworks",
    "authors": [
      "Marie Davidsen Buhl",
      "Ben Bucknall",
      "Tammy Masterson"
    ],
    "abstract": "As part of the Frontier AI Safety Commitments agreed to at the 2024 AI Seoul\nSummit, many AI developers agreed to publish a safety framework outlining how\nthey will manage potential severe risks associated with their systems. This\npaper summarises current thinking from companies, governments, and researchers\non how to write an effective safety framework. We outline three core areas of a\nsafety framework - risk identification and assessment, risk mitigation, and\ngovernance - and identify emerging practices within each area. As safety\nframeworks are novel and rapidly developing, we hope that this paper can serve\nboth as an overview of work to date and as a starting point for further\ndiscussion and innovation.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "38 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.04746v1",
    "published_date": "2025-02-05 23:22:57 UTC",
    "updated_date": "2025-02-05 23:22:57 UTC"
  },
  {
    "arxiv_id": "2502.06834v1",
    "title": "A Unified Knowledge-Distillation and Semi-Supervised Learning Framework to Improve Industrial Ads Delivery Systems",
    "authors": [
      "Hamid Eghbalzadeh",
      "Yang Wang",
      "Rui Li",
      "Yuji Mo",
      "Qin Ding",
      "Jiaxiang Fu",
      "Liang Dai",
      "Shuo Gu",
      "Nima Noorshams",
      "Sem Park",
      "Bo Long",
      "Xue Feng"
    ],
    "abstract": "Industrial ads ranking systems conventionally rely on labeled impression\ndata, which leads to challenges such as overfitting, slower incremental gain\nfrom model scaling, and biases due to discrepancies between training and\nserving data. To overcome these issues, we propose a Unified framework for\nKnowledge-Distillation and Semi-supervised Learning (UKDSL) for ads ranking,\nempowering the training of models on a significantly larger and more diverse\ndatasets, thereby reducing overfitting and mitigating training-serving data\ndiscrepancies. We provide detailed formal analysis and numerical simulations on\nthe inherent miscalibration and prediction bias of multi-stage ranking systems,\nand show empirical evidence of the proposed framework's capability to mitigate\nthose. Compared to prior work, UKDSL can enable models to learn from a much\nlarger set of unlabeled data, hence, improving the performance while being\ncomputationally efficient. Finally, we report the successful deployment of\nUKDSL in an industrial setting across various ranking models, serving users at\nmulti-billion scale, across various surfaces, geological locations, clients,\nand optimize for various events, which to the best of our knowledge is the\nfirst of its kind in terms of the scale and efficiency at which it operates.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06834v1",
    "published_date": "2025-02-05 23:14:07 UTC",
    "updated_date": "2025-02-05 23:14:07 UTC"
  },
  {
    "arxiv_id": "2502.03660v1",
    "title": "Energy & Force Regression on DFT Trajectories is Not Enough for Universal Machine Learning Interatomic Potentials",
    "authors": [
      "Santiago Miret",
      "Kin Long Kelvin Lee",
      "Carmelo Gonzales",
      "Sajid Mannan",
      "N. M. Anoop Krishnan"
    ],
    "abstract": "Universal Machine Learning Interactomic Potentials (MLIPs) enable accelerated\nsimulations for materials discovery. However, current research efforts fail to\nimpactfully utilize MLIPs due to: 1. Overreliance on Density Functional Theory\n(DFT) for MLIP training data creation; 2. MLIPs' inability to reliably and\naccurately perform large-scale molecular dynamics (MD) simulations for diverse\nmaterials; 3. Limited understanding of MLIPs' underlying capabilities. To\naddress these shortcomings, we aargue that MLIP research efforts should\nprioritize: 1. Employing more accurate simulation methods for large-scale MLIP\ntraining data creation (e.g. Coupled Cluster Theory) that cover a wide range of\nmaterials design spaces; 2. Creating MLIP metrology tools that leverage\nlarge-scale benchmarking, visualization, and interpretability analyses to\nprovide a deeper understanding of MLIPs' inner workings; 3. Developing\ncomputationally efficient MLIPs to execute MD simulations that accurately model\na broad set of materials properties. Together, these interdisciplinary research\ndirections can help further the real-world application of MLIPs to accurately\nmodel complex materials at device scale.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03660v1",
    "published_date": "2025-02-05 23:04:21 UTC",
    "updated_date": "2025-02-05 23:04:21 UTC"
  },
  {
    "arxiv_id": "2503.16432v1",
    "title": "Multimodal Transformer Models for Turn-taking Prediction: Effects on Conversational Dynamics of Human-Agent Interaction during Cooperative Gameplay",
    "authors": [
      "Young-Ho Bae",
      "Casey C. Bennett"
    ],
    "abstract": "This study investigates multimodal turn-taking prediction within human-agent\ninteractions (HAI), particularly focusing on cooperative gaming environments.\nIt comprises both model development and subsequent user study, aiming to refine\nour understanding and improve conversational dynamics in spoken dialogue\nsystems (SDSs). For the modeling phase, we introduce a novel transformer-based\ndeep learning (DL) model that simultaneously integrates multiple modalities -\ntext, vision, audio, and contextual in-game data to predict turn-taking events\nin real-time. Our model employs a Crossmodal Transformer architecture to\neffectively fuse information from these diverse modalities, enabling more\ncomprehensive turn-taking predictions. The model demonstrates superior\nperformance compared to baseline models, achieving 87.3% accuracy and 83.0%\nmacro F1 score. A human user study was then conducted to empirically evaluate\nthe turn-taking DL model in an interactive scenario with a virtual avatar while\nplaying the game \"Dont Starve Together\", comparing a control condition without\nturn-taking prediction (n=20) to an experimental condition with our model\ndeployed (n=40). Both conditions included a mix of English and Korean speakers,\nsince turn-taking cues are known to vary by culture. We then analyzed the\ninteraction quality, examining aspects such as utterance counts, interruption\nfrequency, and participant perceptions of the avatar. Results from the user\nstudy suggest that our multimodal turn-taking model not only enhances the\nfluidity and naturalness of human-agent conversations, but also maintains a\nbalanced conversational dynamic without significantly altering dialogue\nfrequency. The study provides in-depth insights into the influence of\nturn-taking abilities on user perceptions and interaction quality, underscoring\nthe potential for more contextually adaptive and responsive conversational\nagents.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "36 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.16432v1",
    "published_date": "2025-02-05 23:00:49 UTC",
    "updated_date": "2025-02-05 23:00:49 UTC"
  },
  {
    "arxiv_id": "2503.04744v1",
    "title": "Safety Cases: A Scalable Approach to Frontier AI Safety",
    "authors": [
      "Benjamin Hilton",
      "Marie Davidsen Buhl",
      "Tomek Korbak",
      "Geoffrey Irving"
    ],
    "abstract": "Safety cases - clear, assessable arguments for the safety of a system in a\ngiven context - are a widely-used technique across various industries for\nshowing a decision-maker (e.g. boards, customers, third parties) that a system\nis safe. In this paper, we cover how and why frontier AI developers might also\nwant to use safety cases. We then argue that writing and reviewing safety cases\nwould substantially assist in the fulfilment of many of the Frontier AI Safety\nCommitments. Finally, we outline open research questions on the methodology,\nimplementation, and technical details of safety cases.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "18 pages, 2 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.04744v1",
    "published_date": "2025-02-05 22:59:53 UTC",
    "updated_date": "2025-02-05 22:59:53 UTC"
  },
  {
    "arxiv_id": "2503.04743v1",
    "title": "AI Safety is Stuck in Technical Terms -- A System Safety Response to the International AI Safety Report",
    "authors": [
      "Roel Dobbe"
    ],
    "abstract": "Safety has become the central value around which dominant AI governance\nefforts are being shaped. Recently, this culminated in the publication of the\nInternational AI Safety Report, written by 96 experts of which 30 nominated by\nthe Organisation for Economic Co-operation and Development (OECD), the European\nUnion (EU), and the United Nations (UN). The report focuses on the safety risks\nof general-purpose AI and available technical mitigation approaches. In this\nresponse, informed by a system safety perspective, I refl ect on the key\nconclusions of the report, identifying fundamental issues in the currently\ndominant technical framing of AI safety and how this frustrates meaningful\ndiscourse and policy efforts to address safety comprehensively. The system\nsafety discipline has dealt with the safety risks of software-based systems for\nmany decades, and understands safety risks in AI systems as sociotechnical and\nrequiring consideration of technical and non-technical factors and their\ninteractions. The International AI Safety report does identify the need for\nsystem safety approaches. Lessons, concepts and methods from system safety\nindeed provide an important blueprint for overcoming current shortcomings in\ntechnical approaches by integrating rather than adding on non-technical factors\nand interventions. I conclude with why building a system safety discipline can\nhelp us overcome limitations in the European AI Act, as well as how the\ndiscipline can help shape sustainable investments into Public Interest AI.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "A response to the International AI Safety Report, which was released\n  in preparation for the AI Action Summit in Paris, February 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.04743v1",
    "published_date": "2025-02-05 22:37:53 UTC",
    "updated_date": "2025-02-05 22:37:53 UTC"
  },
  {
    "arxiv_id": "2502.03656v1",
    "title": "A Study in Dataset Distillation for Image Super-Resolution",
    "authors": [
      "Tobias Dietz",
      "Brian B. Moser",
      "Tobias Nauen",
      "Federico Raue",
      "Stanislav Frolov",
      "Andreas Dengel"
    ],
    "abstract": "Dataset distillation is the concept of condensing large datasets into smaller\nbut highly representative synthetic samples. While previous research has\nprimarily focused on image classification, its application to image\nSuper-Resolution (SR) remains underexplored. This exploratory work studies\nmultiple dataset distillation techniques applied to SR, including pixel- and\nlatent-space approaches under different aspects. Our experiments demonstrate\nthat a 91.12% dataset size reduction can be achieved while maintaining\ncomparable SR performance to the full dataset. We further analyze\ninitialization strategies and distillation methods to optimize memory\nefficiency and computational costs. Our findings provide new insights into\ndataset distillation for SR and set the stage for future advancements.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03656v1",
    "published_date": "2025-02-05 22:34:49 UTC",
    "updated_date": "2025-02-05 22:34:49 UTC"
  },
  {
    "arxiv_id": "2502.03654v2",
    "title": "Gompertz Linear Units: Leveraging Asymmetry for Enhanced Learning Dynamics",
    "authors": [
      "Indrashis Das",
      "Mahmoud Safari",
      "Steven Adriaensen",
      "Frank Hutter"
    ],
    "abstract": "Activation functions are fundamental elements of deep learning architectures\nas they significantly influence training dynamics. ReLU, while widely used, is\nprone to the dying neuron problem, which has been mitigated by variants such as\nLeakyReLU, PReLU, and ELU that better handle negative neuron outputs. Recently,\nself-gated activations like GELU and Swish have emerged as state-of-the-art\nalternatives, leveraging their smoothness to ensure stable gradient flow and\nprevent neuron inactivity. In this work, we introduce the Gompertz Linear Unit\n(GoLU), a novel self-gated activation function defined as $\\mathrm{GoLU}(x) = x\n\\, \\mathrm{Gompertz}(x)$, where $\\mathrm{Gompertz}(x) = e^{-e^{-x}}$. The GoLU\nactivation leverages the right-skewed asymmetry in the Gompertz function to\nreduce variance in the latent space more effectively compared to GELU and\nSwish, while preserving robust gradient flow. Extensive experiments across\ndiverse tasks, including Image Classification, Language Modeling, Semantic\nSegmentation, Object Detection, Instance Segmentation, and Diffusion, highlight\nGoLU's superior performance relative to state-of-the-art activation functions,\nestablishing GoLU as a robust alternative to existing activation functions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, excluding references and appendix; v2: slight improvement in\n  presentation. Equation (4) added, with proof in Appendix A. Appendices B\n  (Flipped Mish) and I (Machine Translation) added. Figure 9 added to Appendix\n  C. Appendix D extended with Heatmaps 12 and 13",
    "pdf_url": "http://arxiv.org/pdf/2502.03654v2",
    "published_date": "2025-02-05 22:32:22 UTC",
    "updated_date": "2025-05-21 15:36:14 UTC"
  },
  {
    "arxiv_id": "2502.04388v1",
    "title": "Position: Emergent Machina Sapiens Urge Rethinking Multi-Agent Paradigms",
    "authors": [
      "Hepeng Li",
      "Yuhong Liu",
      "Jun Yan"
    ],
    "abstract": "Artificially intelligent (AI) agents that are capable of autonomous learning\nand independent decision-making hold great promise for addressing complex\nchallenges across domains like transportation, energy systems, and\nmanufacturing. However, the surge in AI systems' design and deployment driven\nby various stakeholders with distinct and unaligned objectives introduces a\ncrucial challenge: how can uncoordinated AI systems coexist and evolve\nharmoniously in shared environments without creating chaos? To address this, we\nadvocate for a fundamental rethinking of existing multi-agent frameworks, such\nas multi-agent systems and game theory, which are largely limited to predefined\nrules and static objective structures. We posit that AI agents should be\nempowered to dynamically adjust their objectives, make compromises, form\ncoalitions, and safely compete or cooperate through evolving relationships and\nsocial feedback. Through this paper, we call for a shift toward the emergent,\nself-organizing, and context-aware nature of these systems.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04388v1",
    "published_date": "2025-02-05 22:20:15 UTC",
    "updated_date": "2025-02-05 22:20:15 UTC"
  },
  {
    "arxiv_id": "2502.06833v1",
    "title": "Entropy Adaptive Decoding: Dynamic Model Switching for Efficient Inference",
    "authors": [
      "Toby Simonds"
    ],
    "abstract": "We present Entropy Adaptive Decoding (EAD), a novel approach for efficient\nlanguage model inference that dynamically switches between different-sized\nmodels based on prediction uncertainty. By monitoring rolling entropy in model\nlogit distributions, our method identifies text regions where a smaller model\nsuffices and switches to a larger model only when prediction uncertainty\nexceeds a threshold. Unlike speculative decoding approaches that maintain\nperfect output fidelity through verification, EAD accepts controlled output\ndivergence in exchange for computational efficiency. Our experiments on the\nMATH benchmark demonstrate remarkable efficiency gains across different model\nfamilies. Using the LLaMA family, we maintain 96.7\\% of the 11B model's\nperformance (50.4\\% vs 52.1\\%) while using it for only 43\\% of tokens,\ndecreasing computational cost by 41.5\\%. These gains become more pronounced\nwith larger size differentials in the Qwen family, where we achieve 92.9\\% of\nthe 14B model's performance (74.3\\% vs 80.0\\%) while using it for just 25\\% of\ntokens, decreasing computational cost by 67\\%. The consistency of these results\nacross model pairs suggests that language model computation can be\nsignificantly optimized by selectively deploying model capacity based on local\ngeneration complexity. Our findings indicate that current approaches to model\ninference may be unnecessarily conservative in their pursuit of perfect output\nfidelity, and that accepting minor performance trade-offs can enable dramatic\nreductions in computational costs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06833v1",
    "published_date": "2025-02-05 22:15:21 UTC",
    "updated_date": "2025-02-05 22:15:21 UTC"
  },
  {
    "arxiv_id": "2502.05223v1",
    "title": "KDA: A Knowledge-Distilled Attacker for Generating Diverse Prompts to Jailbreak LLMs",
    "authors": [
      "Buyun Liang",
      "Kwan Ho Ryan Chan",
      "Darshan Thaker",
      "Jinqi Luo",
      "René Vidal"
    ],
    "abstract": "Jailbreak attacks exploit specific prompts to bypass LLM safeguards, causing\nthe LLM to generate harmful, inappropriate, and misaligned content. Current\njailbreaking methods rely heavily on carefully designed system prompts and\nnumerous queries to achieve a single successful attack, which is costly and\nimpractical for large-scale red-teaming. To address this challenge, we propose\nto distill the knowledge of an ensemble of SOTA attackers into a single\nopen-source model, called Knowledge-Distilled Attacker (KDA), which is\nfinetuned to automatically generate coherent and diverse attack prompts without\nthe need for meticulous system prompt engineering. Compared to existing\nattackers, KDA achieves higher attack success rates and greater cost-time\nefficiency when targeting multiple SOTA open-source and commercial black-box\nLLMs. Furthermore, we conducted a quantitative diversity analysis of prompts\ngenerated by baseline methods and KDA, identifying diverse and ensemble attacks\nas key factors behind KDA's effectiveness and efficiency.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05223v1",
    "published_date": "2025-02-05 21:50:34 UTC",
    "updated_date": "2025-02-05 21:50:34 UTC"
  },
  {
    "arxiv_id": "2502.04387v1",
    "title": "FedP$^2$EFT: Federated Learning to Personalize Parameter Efficient Fine-Tuning for Multilingual LLMs",
    "authors": [
      "Royson Lee",
      "Minyoung Kim",
      "Fady Rezk",
      "Rui Li",
      "Stylianos I. Venieris",
      "Timothy Hospedales"
    ],
    "abstract": "Federated learning (FL) has enabled the training of multilingual large\nlanguage models (LLMs) on diverse and decentralized multilingual data,\nespecially on low-resource languages. To improve client-specific performance,\npersonalization via the use of parameter-efficient fine-tuning (PEFT) modules\nsuch as LoRA is common. This involves a personalization strategy (PS), such as\nthe design of the PEFT adapter structures (e.g., in which layers to add LoRAs\nand what ranks) and choice of hyperparameters (e.g., learning rates) for\nfine-tuning. Instead of manual PS configuration, we propose FedP$^2$EFT, a\nfederated learning-to-personalize method for multilingual LLMs in cross-device\nFL settings. Unlike most existing PEFT structure selection methods, which are\nprone to overfitting low-data regimes, FedP$^2$EFT collaboratively learns the\noptimal personalized PEFT structure for each client via Bayesian sparse rank\nselection. Evaluations on both simulated and real-world multilingual FL\nbenchmarks demonstrate that FedP$^2$EFT largely outperforms existing\npersonalized fine-tuning methods, while complementing a range of existing FL\nmethods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2502.04387v1",
    "published_date": "2025-02-05 21:36:21 UTC",
    "updated_date": "2025-02-05 21:36:21 UTC"
  },
  {
    "arxiv_id": "2502.03629v2",
    "title": "REALEDIT: Reddit Edits As a Large-scale Empirical Dataset for Image Transformations",
    "authors": [
      "Peter Sushko",
      "Ayana Bharadwaj",
      "Zhi Yang Lim",
      "Vasily Ilin",
      "Ben Caffee",
      "Dongping Chen",
      "Mohammadreza Salehi",
      "Cheng-Yu Hsieh",
      "Ranjay Krishna"
    ],
    "abstract": "Existing image editing models struggle to meet real-world demands. Despite\nexcelling in academic benchmarks, they have yet to be widely adopted for real\nuser needs. Datasets that power these models use artificial edits, lacking the\nscale and ecological validity necessary to address the true diversity of user\nrequests. We introduce REALEDIT, a large-scale image editing dataset with\nauthentic user requests and human-made edits sourced from Reddit. REALEDIT\nincludes a test set of 9300 examples to evaluate models on real user requests.\nOur results show that existing models fall short on these tasks, highlighting\nthe need for realistic training data. To address this, we introduce 48K\ntraining examples and train our REALEDIT model, achieving substantial gains -\noutperforming competitors by up to 165 Elo points in human judgment and 92\npercent relative improvement on the automated VIEScore metric. We deploy our\nmodel on Reddit, testing it on new requests, and receive positive feedback.\nBeyond image editing, we explore REALEDIT's potential in detecting edited\nimages by partnering with a deepfake detection non-profit. Finetuning their\nmodel on REALEDIT data improves its F1-score by 14 percentage points,\nunderscoring the dataset's value for broad applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.03629v2",
    "published_date": "2025-02-05 21:35:48 UTC",
    "updated_date": "2025-04-29 00:30:03 UTC"
  },
  {
    "arxiv_id": "2502.03628v1",
    "title": "The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering",
    "authors": [
      "Zhuowei Li",
      "Haizhou Shi",
      "Yunhe Gao",
      "Di Liu",
      "Zhenting Wang",
      "Yuxiao Chen",
      "Ting Liu",
      "Long Zhao",
      "Hao Wang",
      "Dimitris N. Metaxas"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) can reason effectively over both textual\nand visual inputs, but they tend to hallucinate syntactically coherent yet\nvisually ungrounded contents. In this paper, we investigate the internal\ndynamics of hallucination by examining the tokens logits rankings throughout\nthe generation process, revealing three key patterns in how LVLMs process\ninformation: (1) gradual visual information loss -- visually grounded tokens\ngradually become less favored throughout generation, and (2) early excitation\n-- semantically meaningful tokens achieve peak activation in the layers earlier\nthan the final layer. (3) hidden genuine information -- visually grounded\ntokens though not being eventually decided still retain relatively high\nrankings at inference. Based on these insights, we propose VISTA (Visual\nInformation Steering with Token-logit Augmentation), a training-free\ninference-time intervention framework that reduces hallucination while\npromoting genuine information. VISTA works by combining two complementary\napproaches: reinforcing visual information in activation space and leveraging\nearly layer activations to promote semantically meaningful decoding. Compared\nto existing methods, VISTA requires no external supervision and is applicable\nto various decoding strategies. Extensive experiments show that VISTA on\naverage reduces hallucination by abount 40% on evaluated open-ended generation\ntask, and it consistently outperforms existing methods on four benchmarks\nacross four architectures under three decoding strategies.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03628v1",
    "published_date": "2025-02-05 21:34:02 UTC",
    "updated_date": "2025-02-05 21:34:02 UTC"
  },
  {
    "arxiv_id": "2502.03622v2",
    "title": "AdaPhish: AI-Powered Adaptive Defense and Education Resource Against Deceptive Emails",
    "authors": [
      "Rei Meguro",
      "Ng S. T. Chong"
    ],
    "abstract": "Phishing attacks remain a significant threat in the digital age, yet\norganizations lack effective methods to tackle phishing attacks without leaking\nsensitive information. Phish bowl initiatives are a vital part of cybersecurity\nefforts against these attacks. However, traditional phish bowls require manual\nanonymization and are often limited to internal use. To overcome these\nlimitations, we introduce AdaPhish, an AI-powered phish bowl platform that\nautomatically anonymizes and analyzes phishing emails using large language\nmodels (LLMs) and vector databases. AdaPhish achieves real-time detection and\nadaptation to new phishing tactics while enabling long-term tracking of\nphishing trends. Through automated reporting, adaptive analysis, and real-time\nalerts, AdaPhish presents a scalable, collaborative solution for phishing\ndetection and cybersecurity education.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "7 pages, 3 figures, 2 tables, accepted in 4th IEEE International\n  Conference on AI in Cybersecurity (ICAIC)",
    "pdf_url": "http://arxiv.org/pdf/2502.03622v2",
    "published_date": "2025-02-05 21:17:19 UTC",
    "updated_date": "2025-02-10 19:12:41 UTC"
  },
  {
    "arxiv_id": "2502.18477v1",
    "title": "Recommendations Beyond Catalogs: Diffusion Models for Personalized Generation",
    "authors": [
      "Gabriel Patron",
      "Zhiwei Xu",
      "Ishan Kapnadak",
      "Felipe Maia Polo"
    ],
    "abstract": "Modern recommender systems follow the guiding principle of serving the right\nuser, the right item at the right time. One of their main limitations is that\nthey are typically limited to items already in the catalog. We propose\nREcommendations BEyond CAtalogs, REBECA, a new class of probabilistic\ndiffusion-based recommender systems that synthesize new items tailored to\nindividual tastes rather than retrieve items from the catalog. REBECA combines\nefficient training in embedding space with a novel diffusion prior that only\nrequires users' past ratings of items. We evaluate REBECA on real-world data\nand propose novel personalization metrics for generative recommender systems.\nExtensive experiments demonstrate that REBECA produces high-quality,\npersonalized recommendations, generating images that align with users' unique\npreferences.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18477v1",
    "published_date": "2025-02-05 21:11:47 UTC",
    "updated_date": "2025-02-05 21:11:47 UTC"
  },
  {
    "arxiv_id": "2502.03614v1",
    "title": "A Novel Zero-Touch, Zero-Trust, AI/ML Enablement Framework for IoT Network Security",
    "authors": [
      "Sushil Shakya",
      "Robert Abbas",
      "Sasa Maric"
    ],
    "abstract": "The IoT facilitates a connected, intelligent, and sustainable society;\ntherefore, it is imperative to protect the IoT ecosystem. The IoT-based 5G and\n6G will leverage the use of machine learning and artificial intelligence\n(ML/AI) more to pave the way for autonomous and collaborative secure IoT\nnetworks. Zero-touch, zero-trust IoT security with AI and machine learning (ML)\nenablement frameworks offers a powerful approach to securing the expanding\nlandscape of Internet of Things (IoT) devices. This paper presents a novel\nframework based on the integration of Zero Trust, Zero Touch, and AI/ML powered\nfor the detection, mitigation, and prevention of DDoS attacks in modern IoT\necosystems. The focus will be on the new integrated framework by establishing\nzero trust for all IoT traffic, fixed and mobile 5G/6G IoT network traffic, and\ndata security (quarantine-zero touch and dynamic policy enforcement). We\nperform a comparative analysis of five machine learning models, namely,\nXGBoost, Random Forest, K-Nearest Neighbors, Stochastic Gradient Descent, and\nNative Bayes, by comparing these models based on accuracy, precision, recall,\nF1-score, and ROC-AUC. Results show that the best performance in detecting and\nmitigating different DDoS vectors comes from the ensemble-based approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03614v1",
    "published_date": "2025-02-05 21:03:07 UTC",
    "updated_date": "2025-02-05 21:03:07 UTC"
  },
  {
    "arxiv_id": "2503.15530v2",
    "title": "A Beautiful Mind: Principles and Strategies for AI-Augmented Human Reasoning",
    "authors": [
      "Sean Koon"
    ],
    "abstract": "Amidst the race to create more intelligent machines there is a risk that we\nwill rely on AI in ways that reduce our own agency as humans. To reduce this\nrisk, we could aim to create tools that prioritize and enhance the human role\nin human-AI interactions. This paper outlines a human-centered augmented\nreasoning paradigm by 1. Articulating fundamental principles for augmented\nreasoning tools, emphasizing their ergonomic, pre-conclusive, directable,\nexploratory, enhancing, and integrated nature; 2. Proposing a 'many tasks, many\ntools' approach to ensuring human influence and control, and 3. Offering\nexamples of interaction modes that can serve as bridges between human reasoning\nand AI algorithms.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "13 pages, 7062 words, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2503.15530v2",
    "published_date": "2025-02-05 20:57:29 UTC",
    "updated_date": "2025-04-11 03:41:00 UTC"
  },
  {
    "arxiv_id": "2502.03608v1",
    "title": "(GG) MoE vs. MLP on Tabular Data",
    "authors": [
      "Andrei Chernov"
    ],
    "abstract": "In recent years, significant efforts have been directed toward adapting\nmodern neural network architectures for tabular data. However, despite their\nlarger number of parameters and longer training and inference times, these\nmodels often fail to consistently outperform vanilla multilayer perceptron\n(MLP) neural networks. Moreover, MLP-based ensembles have recently demonstrated\nsuperior performance and efficiency compared to advanced deep learning methods.\nTherefore, rather than focusing on building deeper and more complex deep\nlearning models, we propose investigating whether MLP neural networks can be\nreplaced with more efficient architectures without sacrificing performance. In\nthis paper, we first introduce GG MoE, a mixture-of-experts (MoE) model with a\nGumbel-Softmax gating function. We then demonstrate that GG MoE with an\nembedding layer achieves the highest performance across $38$ datasets compared\nto standard MoE and MLP models. Finally, we show that both MoE and GG MoE\nutilize significantly fewer parameters than MLPs, making them a promising\nalternative for scaling and ensemble methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03608v1",
    "published_date": "2025-02-05 20:53:16 UTC",
    "updated_date": "2025-02-05 20:53:16 UTC"
  },
  {
    "arxiv_id": "2502.03607v1",
    "title": "Simultaneous Multi-Robot Motion Planning with Projected Diffusion Models",
    "authors": [
      "Jinhao Liang",
      "Jacob K Christopher",
      "Sven Koenig",
      "Ferdinando Fioretto"
    ],
    "abstract": "Recent advances in diffusion models hold significant potential in robotics,\nenabling the generation of diverse and smooth trajectories directly from raw\nrepresentations of the environment. Despite this promise, applying diffusion\nmodels to motion planning remains challenging due to their difficulty in\nenforcing critical constraints, such as collision avoidance and kinematic\nfeasibility. These limitations become even more pronounced in Multi-Robot\nMotion Planning (MRMP), where multiple robots must coordinate in shared spaces.\nTo address this challenge, this work proposes Simultaneous MRMP Diffusion\n(SMD), a novel approach integrating constrained optimization into the diffusion\nsampling process to produce collision-free, kinematically feasible\ntrajectories. Additionally, the paper introduces a comprehensive MRMP benchmark\nto evaluate trajectory planning algorithms across scenarios with varying robot\ndensities, obstacle complexities, and motion constraints. Experimental results\nshow SMD consistently outperforms classical and learning-based motion planners,\nachieving higher success rates and efficiency in complex multi-robot\nenvironments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03607v1",
    "published_date": "2025-02-05 20:51:28 UTC",
    "updated_date": "2025-02-05 20:51:28 UTC"
  },
  {
    "arxiv_id": "2502.06832v2",
    "title": "Optimizing Robustness and Accuracy in Mixture of Experts: A Dual-Model Approach",
    "authors": [
      "Xu Zhang",
      "Kaidi Xu",
      "Ziqing Hu",
      "Ren Wang"
    ],
    "abstract": "Mixture of Experts (MoE) have shown remarkable success in leveraging\nspecialized expert networks for complex machine learning tasks. However, their\nsusceptibility to adversarial attacks presents a critical challenge for\ndeployment in robust applications. This paper addresses the critical question\nof how to incorporate robustness into MoEs while maintaining high natural\naccuracy. We begin by analyzing the vulnerability of MoE components, finding\nthat expert networks are notably more susceptible to adversarial attacks than\nthe router. Based on this insight, we propose a targeted robust training\ntechnique that integrates a novel loss function to enhance the adversarial\nrobustness of MoE, requiring only the robustification of one additional expert\nwithout compromising training or inference efficiency. Building on this, we\nintroduce a dual-model strategy that linearly combines a standard MoE model\nwith our robustified MoE model using a smoothing parameter. This approach\nallows for flexible control over the robustness-accuracy trade-off. We further\nprovide theoretical foundations by deriving certified robustness bounds for\nboth the single MoE and the dual-model. To push the boundaries of robustness\nand accuracy, we propose a novel joint training strategy JTDMoE for the\ndual-model. This joint training enhances both robustness and accuracy beyond\nwhat is achievable with separate models. Experimental results on CIFAR-10 and\nTinyImageNet datasets using ResNet18 and Vision Transformer (ViT) architectures\ndemonstrate the effectiveness of our proposed methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6; I.5.1"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 3 figures, submitted to ICML 2025 (under review)",
    "pdf_url": "http://arxiv.org/pdf/2502.06832v2",
    "published_date": "2025-02-05 20:45:52 UTC",
    "updated_date": "2025-02-12 05:30:33 UTC"
  },
  {
    "arxiv_id": "2502.10424v1",
    "title": "QuantSpec: Self-Speculative Decoding with Hierarchical Quantized KV Cache",
    "authors": [
      "Rishabh Tiwari",
      "Haocheng Xi",
      "Aditya Tomar",
      "Coleman Hooper",
      "Sehoon Kim",
      "Maxwell Horton",
      "Mahyar Najibi",
      "Michael W. Mahoney",
      "Kurt Keutzer",
      "Amir Gholami"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly being deployed on edge devices\nfor long-context settings, creating a growing need for fast and efficient\nlong-context inference. In these scenarios, the Key-Value (KV) cache is the\nprimary bottleneck in terms of both GPU memory and latency, as the full KV\ncache must be loaded for each decoding step. While speculative decoding is a\nwidely accepted technique to accelerate autoregressive decoding, existing\nmethods often struggle to achieve significant speedups due to inefficient KV\ncache optimization strategies and result in low acceptance rates. To address\nthese challenges, we propose a novel self-speculative decoding framework,\nQuantSpec, where the draft model shares the architecture of the target model\nbut employs a hierarchical 4-bit quantized KV cache and 4-bit quantized weights\nfor acceleration. QuantSpec maintains high acceptance rates ($>$90%) and\nreliably provides consistent end-to-end speedups upto $\\sim2.5\\times$,\noutperforming other self-speculative decoding methods that use sparse KV cache\nfor long-context LLM inference. QuantSpec also reduces the memory requirements\nby $\\sim 1.3\\times$ compared to these alternatives.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10424v1",
    "published_date": "2025-02-05 20:43:48 UTC",
    "updated_date": "2025-02-05 20:43:48 UTC"
  },
  {
    "arxiv_id": "2503.04742v1",
    "title": "A case for specialisation in non-human entities",
    "authors": [
      "El-Mahdi El-Mhamdi",
      "Lê-Nguyên Hoang",
      "Mariame Tighanimine"
    ],
    "abstract": "With the rise of large multi-modal AI models, fuelled by recent interest in\nlarge language models (LLMs), the notion of artificial general intelligence\n(AGI) went from being restricted to a fringe community, to dominate mainstream\nlarge AI development programs.\n  In contrast, in this paper, we make a \\emph{case for specialisation}, by\nreviewing the pitfalls of generality and stressing the industrial value of\nspecialised\n  systems.\n  Our contribution is threefold. First, we review the most widely accepted\narguments \\emph{against} specialisation, and discuss how their relevance in the\ncontext of human labour is actually an argument \\emph{for} specialisation in\nthe case of non human agents, be they algorithms or human organisations.\nSecond, we propose four arguments \\emph{in favor of} specialisation, ranging\nfrom machine learning robustness, to computer security, social sciences and\ncultural evolution.\n  Third, we finally make a case for \\emph{specification}, discuss how the\nmachine learning approach to AI has so far failed to catch up with good\npractices from safety-engineering and formal verification of software, and\ndiscuss how some emerging good practices in machine learning help reduce this\ngap.\n  In particular, we justify the need for \\emph{specified governance} for\nhard-to-specify systems.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04742v1",
    "published_date": "2025-02-05 20:38:18 UTC",
    "updated_date": "2025-02-05 20:38:18 UTC"
  },
  {
    "arxiv_id": "2502.04386v1",
    "title": "Towards Fair Medical AI: Adversarial Debiasing of 3D CT Foundation Embeddings",
    "authors": [
      "Guangyao Zheng",
      "Michael A. Jacobs",
      "Vladimir Braverman",
      "Vishwa S. Parekh"
    ],
    "abstract": "Self-supervised learning has revolutionized medical imaging by enabling\nefficient and generalizable feature extraction from large-scale unlabeled\ndatasets. Recently, self-supervised foundation models have been extended to\nthree-dimensional (3D) computed tomography (CT) data, generating compact,\ninformation-rich embeddings with 1408 features that achieve state-of-the-art\nperformance on downstream tasks such as intracranial hemorrhage detection and\nlung cancer risk forecasting. However, these embeddings have been shown to\nencode demographic information, such as age, sex, and race, which poses a\nsignificant risk to the fairness of clinical applications.\n  In this work, we propose a Variation Autoencoder (VAE) based adversarial\ndebiasing framework to transform these embeddings into a new latent space where\ndemographic information is no longer encoded, while maintaining the performance\nof critical downstream tasks. We validated our approach on the NLST lung cancer\nscreening dataset, demonstrating that the debiased embeddings effectively\neliminate multiple encoded demographic information and improve fairness without\ncompromising predictive accuracy for lung cancer risk at 1-year and 2-year\nintervals. Additionally, our approach ensures the embeddings are robust against\nadversarial bias attacks. These results highlight the potential of adversarial\ndebiasing techniques to ensure fairness and equity in clinical applications of\nself-supervised 3D CT embeddings, paving the way for their broader adoption in\nunbiased medical decision-making.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04386v1",
    "published_date": "2025-02-05 20:32:42 UTC",
    "updated_date": "2025-02-05 20:32:42 UTC"
  },
  {
    "arxiv_id": "2502.03591v1",
    "title": "Clinically-Inspired Hierarchical Multi-Label Classification of Chest X-rays with a Penalty-Based Loss Function",
    "authors": [
      "Mehrdad Asadi",
      "Komi Sodoké",
      "Ian J. Gerard",
      "Marta Kersten-Oertel"
    ],
    "abstract": "In this work, we present a novel approach to multi-label chest X-ray (CXR)\nimage classification that enhances clinical interpretability while maintaining\na streamlined, single-model, single-run training pipeline. Leveraging the\nCheXpert dataset and VisualCheXbert-derived labels, we incorporate hierarchical\nlabel groupings to capture clinically meaningful relationships between\ndiagnoses. To achieve this, we designed a custom hierarchical binary\ncross-entropy (HBCE) loss function that enforces label dependencies using\neither fixed or data-driven penalty types. Our model achieved a mean area under\nthe receiver operating characteristic curve (AUROC) of 0.903 on the test set.\nAdditionally, we provide visual explanations and uncertainty estimations to\nfurther enhance model interpretability. All code, model configurations, and\nexperiment details are made available.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages with 3 figures, for associated implementation see\n  https://github.com/the-mercury/CIHMLC",
    "pdf_url": "http://arxiv.org/pdf/2502.03591v1",
    "published_date": "2025-02-05 20:15:06 UTC",
    "updated_date": "2025-02-05 20:15:06 UTC"
  },
  {
    "arxiv_id": "2502.04385v2",
    "title": "TexLiDAR: Automated Text Understanding for Panoramic LiDAR Data",
    "authors": [
      "Naor Cohen",
      "Roy Orfaig",
      "Ben-Zion Bobrovsky"
    ],
    "abstract": "Efforts to connect LiDAR data with text, such as LidarCLIP, have primarily\nfocused on embedding 3D point clouds into CLIP text-image space. However, these\napproaches rely on 3D point clouds, which present challenges in encoding\nefficiency and neural network processing. With the advent of advanced LiDAR\nsensors like Ouster OS1, which, in addition to 3D point clouds, produce fixed\nresolution depth, signal, and ambient panoramic 2D images, new opportunities\nemerge for LiDAR based tasks. In this work, we propose an alternative approach\nto connect LiDAR data with text by leveraging 2D imagery generated by the OS1\nsensor instead of 3D point clouds. Using the Florence 2 large model in a\nzero-shot setting, we perform image captioning and object detection. Our\nexperiments demonstrate that Florence 2 generates more informative captions and\nachieves superior performance in object detection tasks compared to existing\nmethods like CLIP. By combining advanced LiDAR sensor data with a large\npre-trained model, our approach provides a robust and accurate solution for\nchallenging detection scenarios, including real-time applications requiring\nhigh accuracy and robustness.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04385v2",
    "published_date": "2025-02-05 19:41:06 UTC",
    "updated_date": "2025-02-21 16:39:21 UTC"
  },
  {
    "arxiv_id": "2502.03571v2",
    "title": "A Multi-Task Learning Approach to Linear Multivariate Forecasting",
    "authors": [
      "Liran Nochumsohn",
      "Hedi Zisling",
      "Omri Azencot"
    ],
    "abstract": "Accurate forecasting of multivariate time series data is important in many\nengineering and scientific applications. Recent state-of-the-art works ignore\nthe inter-relations between variates, using their model on each variate\nindependently. This raises several research questions related to proper\nmodeling of multivariate data. In this work, we propose to view multivariate\nforecasting as a multi-task learning problem, facilitating the analysis of\nforecasting by considering the angle between task gradients and their balance.\nTo do so, we analyze linear models to characterize the behavior of tasks. Our\nanalysis suggests that tasks can be defined by grouping similar variates\ntogether, which we achieve via a simple clustering that depends on\ncorrelation-based similarities. Moreover, to balance tasks, we scale gradients\nwith respect to their prediction error. Then, each task is solved with a linear\nmodel within our MTLinear framework. We evaluate our approach on challenging\nbenchmarks in comparison to strong baselines, and we show it obtains on-par or\nbetter results on multivariate forecasting problems. The implementation is\navailable at: https://github.com/azencot-group/MTLinear",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "AISTATS 2025 (accepted)",
    "pdf_url": "http://arxiv.org/pdf/2502.03571v2",
    "published_date": "2025-02-05 19:34:23 UTC",
    "updated_date": "2025-03-15 08:39:16 UTC"
  },
  {
    "arxiv_id": "2502.03568v2",
    "title": "Code Simulation as a Proxy for High-order Tasks in Large Language Models",
    "authors": [
      "Emanuele La Malfa",
      "Christoph Weinhuber",
      "Orazio Torre",
      "Fangru Lin",
      "X. Angelo Huang",
      "Samuele Marro",
      "Anthony Cohn",
      "Nigel Shadbolt",
      "Michael Wooldridge"
    ],
    "abstract": "Many reasoning, planning, and problem-solving tasks share an intrinsic\nalgorithmic nature: correctly simulating each step is a sufficient condition to\nsolve them correctly. We collect pairs of naturalistic and synthetic reasoning\ntasks to assess the capabilities of Large Language Models (LLM). While\nnaturalistic tasks often require careful human handcrafting, we show that\nsynthetic data is, in many cases, a good proxy that is much easier to collect\nat scale. We leverage common constructs in programming as the counterpart of\nthe building blocks of naturalistic reasoning tasks, such as straight-line\nprograms, code that contains critical paths, and approximate and redundant\ninstructions. We further assess the capabilities of LLMs on sorting problems\nand repeated operations via sorting algorithms and nested loops. Our synthetic\ndatasets further reveal that while the most powerful LLMs exhibit relatively\nstrong execution capabilities, the process is fragile: it is negatively\naffected by memorisation and seems to rely heavily on pattern recognition. Our\ncontribution builds upon synthetically testing the reasoning capabilities of\nLLMs as a scalable complement to handcrafted human-annotated problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2401.09074\n  Authors note: this article is a substantial revision of arXiv:2401.09074\n  (same team)",
    "pdf_url": "http://arxiv.org/pdf/2502.03568v2",
    "published_date": "2025-02-05 19:30:28 UTC",
    "updated_date": "2025-02-16 18:32:00 UTC"
  },
  {
    "arxiv_id": "2502.04384v1",
    "title": "Enhancing Reasoning to Adapt Large Language Models for Domain-Specific Applications",
    "authors": [
      "Bo Wen",
      "Xin Zhang"
    ],
    "abstract": "This paper presents SOLOMON, a novel Neuro-inspired Large Language Model\n(LLM) Reasoning Network architecture that enhances the adaptability of\nfoundation models for domain-specific applications. Through a case study in\nsemiconductor layout design, we demonstrate how SOLOMON enables swift\nadaptation of general-purpose LLMs to specialized tasks by leveraging Prompt\nEngineering and In-Context Learning techniques. Our experiments reveal the\nchallenges LLMs face in spatial reasoning and applying domain knowledge to\npractical problems. Results show that SOLOMON instances significantly\noutperform their baseline LLM counterparts and achieve performance comparable\nto state-of-the-art reasoning model, o1-preview. We discuss future research\ndirections for developing more adaptive AI systems that can continually learn,\nadapt, and evolve in response to new information and changing requirements.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "68T09, 68T35, 68T45, 94C30",
      "I.2.7; I.2.11; B.7.2"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024 Workshop AFM (Adaptive Foundation Models: Evolving AI\n  for Personalized and Efficient Learning)",
    "pdf_url": "http://arxiv.org/pdf/2502.04384v1",
    "published_date": "2025-02-05 19:27:24 UTC",
    "updated_date": "2025-02-05 19:27:24 UTC"
  },
  {
    "arxiv_id": "2502.03545v1",
    "title": "Proportional Selection in Networks",
    "authors": [
      "Georgios Papasotiropoulos",
      "Oskar Skibski",
      "Piotr Skowron",
      "Tomasz Wąs"
    ],
    "abstract": "We address the problem of selecting $k$ representative nodes from a network,\naiming to achieve two objectives: identifying the most influential nodes and\nensuring the selection proportionally reflects the network's diversity. We\npropose two approaches to accomplish this, analyze them theoretically, and\ndemonstrate their effectiveness through a series of experiments.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA",
      "cs.SI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03545v1",
    "published_date": "2025-02-05 19:02:20 UTC",
    "updated_date": "2025-02-05 19:02:20 UTC"
  },
  {
    "arxiv_id": "2502.03544v2",
    "title": "Gold-medalist Performance in Solving Olympiad Geometry with AlphaGeometry2",
    "authors": [
      "Yuri Chervonyi",
      "Trieu H. Trinh",
      "Miroslav Olšák",
      "Xiaomeng Yang",
      "Hoang Nguyen",
      "Marcelo Menegali",
      "Junehyuk Jung",
      "Vikas Verma",
      "Quoc V. Le",
      "Thang Luong"
    ],
    "abstract": "We present AlphaGeometry2, a significantly improved version of AlphaGeometry\nintroduced in Trinh et al. (2024), which has now surpassed an average gold\nmedalist in solving Olympiad geometry problems. To achieve this, we first\nextend the original AlphaGeometry language to tackle harder problems involving\nmovements of objects, and problems containing linear equations of angles,\nratios, and distances. This, together with support for non-constructive\nproblems, has markedly improved the coverage rate of the AlphaGeometry language\non International Math Olympiads (IMO) 2000-2024 geometry problems from 66% to\n88%. The search process of AlphaGeometry2 has also been greatly improved\nthrough the use of Gemini architecture for better language modeling, and a\nnovel knowledge-sharing mechanism that enables effective communication between\nsearch trees. Together with further enhancements to the symbolic engine and\nsynthetic data generation, we have significantly boosted the overall solving\nrate of AlphaGeometry2 to 84% for $\\textit{all}$ geometry problems over the\nlast 25 years, compared to 54% previously. AlphaGeometry2 was also part of the\nsystem that achieved silver-medal standard at IMO 2024\nhttps://dpmd.ai/imo-silver. Last but not least, we report progress towards\nusing AlphaGeometry2 as a part of a fully automated system that reliably solves\ngeometry problems directly from natural language input.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages, 16 figures. V2: Clarified abstract, rewritten introduction,\n  updated results on diagram generation, added acknowledgement section",
    "pdf_url": "http://arxiv.org/pdf/2502.03544v2",
    "published_date": "2025-02-05 19:02:03 UTC",
    "updated_date": "2025-02-28 23:59:22 UTC"
  },
  {
    "arxiv_id": "2502.03540v3",
    "title": "Path Planning for Masked Diffusion Model Sampling",
    "authors": [
      "Fred Zhangzhi Peng",
      "Zachary Bezemek",
      "Sawan Patel",
      "Jarrid Rector-Brooks",
      "Sherwood Yao",
      "Alexander Tong",
      "Pranam Chatterjee"
    ],
    "abstract": "In this paper, we explore how token unmasking order influences generative\nquality in masked diffusion models (MDMs). We derive an expanded evidence lower\nbound (ELBO) that introduces a planner to select which tokens to unmask at each\nstep. Our analysis reveals that alternative unmasking strategies can enhance\ngeneration performance. Building on this, we propose Path Planning (P2), a\nsampling framework that uses a pre-trained BERT model or the denoiser itself to\nguide unmasking decisions. P2 generalizes all known MDM sampling strategies and\nsignificantly improves performance across diverse domains, including language\ngeneration (in-context learning, code generation, story infilling, mathematical\nreasoning, reverse curse correction) and biological sequence generation\n(protein and RNA sequences).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03540v3",
    "published_date": "2025-02-05 19:00:52 UTC",
    "updated_date": "2025-02-17 16:07:09 UTC"
  },
  {
    "arxiv_id": "2502.03465v2",
    "title": "Seeing World Dynamics in a Nutshell",
    "authors": [
      "Qiuhong Shen",
      "Xuanyu Yi",
      "Mingbao Lin",
      "Hanwang Zhang",
      "Shuicheng Yan",
      "Xinchao Wang"
    ],
    "abstract": "We consider the problem of efficiently representing casually captured\nmonocular videos in a spatially- and temporally-coherent manner. While existing\napproaches predominantly rely on 2D/2.5D techniques treating videos as\ncollections of spatiotemporal pixels, they struggle with complex motions,\nocclusions, and geometric consistency due to absence of temporal coherence and\nexplicit 3D structure. Drawing inspiration from monocular video as a projection\nof the dynamic 3D world, we explore representing videos in their intrinsic 3D\nform through continuous flows of Gaussian primitives in space-time. In this\npaper, we propose NutWorld, a novel framework that efficiently transforms\nmonocular videos into dynamic 3D Gaussian representations in a single forward\npass. At its core, NutWorld introduces a structured spatial-temporal aligned\nGaussian (STAG) representation, enabling optimization-free scene modeling with\neffective depth and flow regularization. Through comprehensive experiments, we\ndemonstrate that NutWorld achieves high-fidelity video reconstruction quality\nwhile enabling various downstream applications in real-time. Demos and code\nwill be available at https://github.com/Nut-World/NutWorld.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03465v2",
    "published_date": "2025-02-05 18:59:52 UTC",
    "updated_date": "2025-03-17 06:29:41 UTC"
  },
  {
    "arxiv_id": "2502.04382v2",
    "title": "Sparse Autoencoders for Hypothesis Generation",
    "authors": [
      "Rajiv Movva",
      "Kenny Peng",
      "Nikhil Garg",
      "Jon Kleinberg",
      "Emma Pierson"
    ],
    "abstract": "We describe HypotheSAEs, a general method to hypothesize interpretable\nrelationships between text data (e.g., headlines) and a target variable (e.g.,\nclicks). HypotheSAEs has three steps: (1) train a sparse autoencoder on text\nembeddings to produce interpretable features describing the data distribution,\n(2) select features that predict the target variable, and (3) generate a\nnatural language interpretation of each feature (e.g., \"mentions being\nsurprised or shocked\") using an LLM. Each interpretation serves as a hypothesis\nabout what predicts the target variable. Compared to baselines, our method\nbetter identifies reference hypotheses on synthetic datasets (at least +0.06 in\nF1) and produces more predictive hypotheses on real datasets (~twice as many\nsignificant findings), despite requiring 1-2 orders of magnitude less compute\nthan recent LLM-based methods. HypotheSAEs also produces novel discoveries on\ntwo well-studied tasks: explaining partisan differences in Congressional\nspeeches and identifying drivers of engagement with online headlines.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "First two authors contributed equally; working paper. Code is\n  available at https://github.com/rmovva/HypotheSAEs",
    "pdf_url": "http://arxiv.org/pdf/2502.04382v2",
    "published_date": "2025-02-05 18:58:02 UTC",
    "updated_date": "2025-03-18 17:51:56 UTC"
  },
  {
    "arxiv_id": "2502.03460v1",
    "title": "Adapt-Pruner: Adaptive Structural Pruning for Efficient Small Language Model Training",
    "authors": [
      "Boyao Wang",
      "Rui Pan",
      "Shizhe Diao",
      "Xingyuan Pan",
      "Jipeng Zhang",
      "Renjie Pi",
      "Tong Zhang"
    ],
    "abstract": "Small language models (SLMs) have attracted considerable attention from both\nacademia and industry due to their broad range of applications in edge devices.\nTo obtain SLMs with strong performance, conventional approaches either\npre-train the models from scratch, which incurs substantial computational\ncosts, or compress/prune existing large language models (LLMs), which results\nin performance drops and falls short in comparison to pre-training. In this\npaper, we investigate the family of acceleration methods that involve both\nstructured pruning and model training. We found 1) layer-wise adaptive pruning\n(Adapt-Pruner) is extremely effective in LLMs and yields significant\nimprovements over existing pruning techniques, 2) adaptive pruning equipped\nwith further training leads to models comparable to those pre-training from\nscratch, 3) incremental pruning brings non-trivial performance gain by\ninterleaving pruning with training and only removing a small portion of neurons\n($\\sim$5%) at a time. Experimental results on LLaMA-3.1-8B demonstrate that\nAdapt-Pruner outperforms conventional pruning methods, such as LLM-Pruner,\nFLAP, and SliceGPT, by an average of 1%-7% in accuracy on commonsense\nbenchmarks. Additionally, Adapt-Pruner restores the performance of\nMobileLLM-125M to 600M on the MMLU benchmark with 200$\\times$ fewer tokens via\npruning from its larger counterparts, and discovers a new 1B model that\nsurpasses LLaMA-3.2-1B in multiple benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03460v1",
    "published_date": "2025-02-05 18:57:40 UTC",
    "updated_date": "2025-02-05 18:57:40 UTC"
  },
  {
    "arxiv_id": "2502.03450v1",
    "title": "A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)",
    "authors": [
      "Yiye Chen",
      "Harpreet Sawhney",
      "Nicholas Gydé",
      "Yanan Jian",
      "Jack Saunders",
      "Patricio Vela",
      "Ben Lundell"
    ],
    "abstract": "Scene graphs have emerged as a structured and serializable environment\nrepresentation for grounded spatial reasoning with Large Language Models\n(LLMs). In this work, we propose SG-RwR, a Schema-Guided Retrieve-while-Reason\nframework for reasoning and planning with scene graphs. Our approach employs\ntwo cooperative, code-writing LLM agents: a (1) Reasoner for task planning and\ninformation queries generation, and a (2) Retriever for extracting\ncorresponding graph information following the queries. Two agents collaborate\niteratively, enabling sequential reasoning and adaptive attention to graph\ninformation. Unlike prior works, both agents are prompted only with the scene\ngraph schema rather than the full graph data, which reduces the hallucination\nby limiting input tokens, and drives the Reasoner to generate reasoning trace\nabstractly.Following the trace, the Retriever programmatically query the scene\ngraph data based on the schema understanding, allowing dynamic and global\nattention on the graph that enhances alignment between reasoning and retrieval.\nThrough experiments in multiple simulation environments, we show that our\nframework surpasses existing LLM-based approaches in numerical Q\\&A and\nplanning tasks, and can benefit from task-level few-shot examples, even in the\nabsence of agent-level demonstrations. Project code will be released.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03450v1",
    "published_date": "2025-02-05 18:50:38 UTC",
    "updated_date": "2025-02-05 18:50:38 UTC"
  },
  {
    "arxiv_id": "2502.03512v2",
    "title": "YINYANG-ALIGN: Benchmarking Contradictory Objectives and Proposing Multi-Objective Optimization based DPO for Text-to-Image Alignment",
    "authors": [
      "Amitava Das",
      "Yaswanth Narsupalli",
      "Gurpreet Singh",
      "Vinija Jain",
      "Vasu Sharma",
      "Suranjana Trivedy",
      "Aman Chadha",
      "Amit Sheth"
    ],
    "abstract": "Precise alignment in Text-to-Image (T2I) systems is crucial to ensure that\ngenerated visuals not only accurately encapsulate user intents but also conform\nto stringent ethical and aesthetic benchmarks. Incidents like the Google Gemini\nfiasco, where misaligned outputs triggered significant public backlash,\nunderscore the critical need for robust alignment mechanisms. In contrast,\nLarge Language Models (LLMs) have achieved notable success in alignment.\nBuilding on these advancements, researchers are eager to apply similar\nalignment techniques, such as Direct Preference Optimization (DPO), to T2I\nsystems to enhance image generation fidelity and reliability.\n  We present YinYangAlign, an advanced benchmarking framework that\nsystematically quantifies the alignment fidelity of T2I systems, addressing six\nfundamental and inherently contradictory design objectives. Each pair\nrepresents fundamental tensions in image generation, such as balancing\nadherence to user prompts with creative modifications or maintaining diversity\nalongside visual coherence. YinYangAlign includes detailed axiom datasets\nfeaturing human prompts, aligned (chosen) responses, misaligned (rejected)\nAI-generated outputs, and explanations of the underlying contradictions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03512v2",
    "published_date": "2025-02-05 18:46:20 UTC",
    "updated_date": "2025-02-10 02:34:39 UTC"
  },
  {
    "arxiv_id": "2502.03444v1",
    "title": "Masked Autoencoders Are Effective Tokenizers for Diffusion Models",
    "authors": [
      "Hao Chen",
      "Yujin Han",
      "Fangyi Chen",
      "Xiang Li",
      "Yidong Wang",
      "Jindong Wang",
      "Ze Wang",
      "Zicheng Liu",
      "Difan Zou",
      "Bhiksha Raj"
    ],
    "abstract": "Recent advances in latent diffusion models have demonstrated their\neffectiveness for high-resolution image synthesis. However, the properties of\nthe latent space from tokenizer for better learning and generation of diffusion\nmodels remain under-explored. Theoretically and empirically, we find that\nimproved generation quality is closely tied to the latent distributions with\nbetter structure, such as the ones with fewer Gaussian Mixture modes and more\ndiscriminative features. Motivated by these insights, we propose MAETok, an\nautoencoder (AE) leveraging mask modeling to learn semantically rich latent\nspace while maintaining reconstruction fidelity. Extensive experiments validate\nour analysis, demonstrating that the variational form of autoencoders is not\nnecessary, and a discriminative latent space from AE alone enables\nstate-of-the-art performance on ImageNet generation using only 128 tokens.\nMAETok achieves significant practical improvements, enabling a gFID of 1.69\nwith 76x faster training and 31x higher inference throughput for 512x512\ngeneration. Our findings show that the structure of the latent space, rather\nthan variational constraints, is crucial for effective diffusion models. Code\nand trained models are released.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03444v1",
    "published_date": "2025-02-05 18:42:04 UTC",
    "updated_date": "2025-02-05 18:42:04 UTC"
  },
  {
    "arxiv_id": "2502.03438v2",
    "title": "BFS-Prover: Scalable Best-First Tree Search for LLM-based Automatic Theorem Proving",
    "authors": [
      "Ran Xin",
      "Chenguang Xi",
      "Jie Yang",
      "Feng Chen",
      "Hang Wu",
      "Xia Xiao",
      "Yifan Sun",
      "Shen Zheng",
      "Kai Shen"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have spurred growing\ninterest in automatic theorem proving using Lean4, where effective tree search\nmethods are crucial for navigating the underlying large proof search spaces.\nWhile the existing approaches primarily rely on value functions and/or Monte\nCarlo Tree Search (MCTS), the potential of simpler methods like Best-First Tree\nSearch (BFS) remains underexplored. In this paper, we investigate whether BFS\ncan achieve competitive performance in large-scale theorem proving tasks. We\npresent BFS-Prover, a scalable expert iteration framework, featuring three key\ninnovations. First, we implement strategic data filtering at each expert\niteration round, excluding problems solvable via beam search node expansion to\nfocus on harder cases. Second, we improve the sample efficiency of BFS through\nDirect Preference Optimization (DPO) applied to state-tactic pairs\nautomatically annotated with compiler error feedback, refining the LLM's policy\nto prioritize productive expansions. Third, we employ length normalization in\nBFS to encourage exploration of deeper proof paths. BFS-Prover achieves a\nstate-of-the-art score of $72.95\\%$ on the MiniF2F test set and therefore\nchallenges the perceived necessity of complex tree search methods,\ndemonstrating that BFS can achieve competitive performance when properly\nscaled. To facilitate further research and development in this area, we have\nopen-sourced our model at https://huggingface.co/bytedance-research/BFS-Prover.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03438v2",
    "published_date": "2025-02-05 18:33:36 UTC",
    "updated_date": "2025-02-24 10:56:02 UTC"
  },
  {
    "arxiv_id": "2502.03429v1",
    "title": "On Fairness of Unified Multimodal Large Language Model for Image Generation",
    "authors": [
      "Ming Liu",
      "Hao Chen",
      "Jindong Wang",
      "Liwen Wang",
      "Bhiksha Raj Ramakrishnan",
      "Wensheng Zhang"
    ],
    "abstract": "Unified multimodal large language models (U-MLLMs) have demonstrated\nimpressive performance in visual understanding and generation in an end-to-end\npipeline. Compared with generation-only models (e.g., Stable Diffusion),\nU-MLLMs may raise new questions about bias in their outputs, which can be\naffected by their unified capabilities. This gap is particularly concerning\ngiven the under-explored risk of propagating harmful stereotypes. In this\npaper, we benchmark the latest U-MLLMs and find that most exhibit significant\ndemographic biases, such as gender and race bias. To better understand and\nmitigate this issue, we propose a locate-then-fix strategy, where we audit and\nshow how the individual model component is affected by bias. Our analysis shows\nthat bias originates primarily from the language model. More interestingly, we\nobserve a \"partial alignment\" phenomenon in U-MLLMs, where understanding bias\nappears minimal, but generation bias remains substantial. Thus, we propose a\nnovel balanced preference model to balance the demographic distribution with\nsynthetic data. Experiments demonstrate that our approach reduces demographic\nbias while preserving semantic fidelity. We hope our findings underscore the\nneed for more holistic interpretation and debiasing strategies of U-MLLMs in\nthe future.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03429v1",
    "published_date": "2025-02-05 18:21:03 UTC",
    "updated_date": "2025-02-05 18:21:03 UTC"
  },
  {
    "arxiv_id": "2502.03426v1",
    "title": "TruePose: Human-Parsing-guided Attention Diffusion for Full-ID Preserving Pose Transfer",
    "authors": [
      "Zhihong Xu",
      "Dongxia Wang",
      "Peng Du",
      "Yang Cao",
      "Qing Guo"
    ],
    "abstract": "Pose-Guided Person Image Synthesis (PGPIS) generates images that maintain a\nsubject's identity from a source image while adopting a specified target pose\n(e.g., skeleton). While diffusion-based PGPIS methods effectively preserve\nfacial features during pose transformation, they often struggle to accurately\nmaintain clothing details from the source image throughout the diffusion\nprocess. This limitation becomes particularly problematic when there is a\nsubstantial difference between the source and target poses, significantly\nimpacting PGPIS applications in the fashion industry where clothing style\npreservation is crucial for copyright protection. Our analysis reveals that\nthis limitation primarily stems from the conditional diffusion model's\nattention modules failing to adequately capture and preserve clothing patterns.\nTo address this limitation, we propose human-parsing-guided attention\ndiffusion, a novel approach that effectively preserves both facial and clothing\nappearance while generating high-quality results. We propose a\nhuman-parsing-aware Siamese network that consists of three key components: dual\nidentical UNets (TargetNet for diffusion denoising and SourceNet for source\nimage embedding extraction), a human-parsing-guided fusion attention (HPFA),\nand a CLIP-guided attention alignment (CAA). The HPFA and CAA modules can embed\nthe face and clothes patterns into the target image generation adaptively and\neffectively. Extensive experiments on both the in-shop clothes retrieval\nbenchmark and the latest in-the-wild human editing dataset demonstrate our\nmethod's significant advantages over 13 baseline approaches for preserving both\nfacial and clothes appearance in the source image.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03426v1",
    "published_date": "2025-02-05 18:15:11 UTC",
    "updated_date": "2025-02-05 18:15:11 UTC"
  },
  {
    "arxiv_id": "2502.04381v1",
    "title": "Limitations of Large Language Models in Clinical Problem-Solving Arising from Inflexible Reasoning",
    "authors": [
      "Jonathan Kim",
      "Anna Podlasek",
      "Kie Shidara",
      "Feng Liu",
      "Ahmed Alaa",
      "Danilo Bernardo"
    ],
    "abstract": "Large Language Models (LLMs) have attained human-level accuracy on medical\nquestion-answer (QA) benchmarks. However, their limitations in navigating\nopen-ended clinical scenarios have recently been shown, raising concerns about\nthe robustness and generalizability of LLM reasoning across diverse, real-world\nmedical tasks. To probe potential LLM failure modes in clinical\nproblem-solving, we present the medical abstraction and reasoning corpus\n(M-ARC). M-ARC assesses clinical reasoning through scenarios designed to\nexploit the Einstellung effect -- the fixation of thought arising from prior\nexperience, targeting LLM inductive biases toward inflexible pattern matching\nfrom their training data rather than engaging in flexible reasoning. We find\nthat LLMs, including current state-of-the-art o1 and Gemini models, perform\npoorly compared to physicians on M-ARC, often demonstrating lack of commonsense\nmedical reasoning and a propensity to hallucinate. In addition, uncertainty\nestimation analyses indicate that LLMs exhibit overconfidence in their answers,\ndespite their limited accuracy. The failure modes revealed by M-ARC in LLM\nmedical reasoning underscore the need to exercise caution when deploying these\nmodels in clinical settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04381v1",
    "published_date": "2025-02-05 18:14:27 UTC",
    "updated_date": "2025-02-05 18:14:27 UTC"
  },
  {
    "arxiv_id": "2502.03511v1",
    "title": "An Empirical Exploration of ChatGPT's Ability to Support Problem Formulation Tasks for Mission Engineering and a Documentation of its Performance Variability",
    "authors": [
      "Max Ofsa",
      "Taylan G. Topcu"
    ],
    "abstract": "Systems engineering (SE) is evolving with the availability of generative\nartificial intelligence (AI) and the demand for a systems-of-systems\nperspective, formalized under the purview of mission engineering (ME) in the US\nDepartment of Defense. Formulating ME problems is challenging because they are\nopen-ended exercises that involve translation of ill-defined problems into\nwell-defined ones that are amenable for engineering development. It remains to\nbe seen to which extent AI could assist problem formulation objectives. To that\nend, this paper explores the quality and consistency of multi-purpose Large\nLanguage Models (LLM) in supporting ME problem formulation tasks, specifically\nfocusing on stakeholder identification. We identify a relevant reference\nproblem, a NASA space mission design challenge, and document ChatGPT-3.5's\nability to perform stakeholder identification tasks. We execute multiple\nparallel attempts and qualitatively evaluate LLM outputs, focusing on both\ntheir quality and variability. Our findings portray a nuanced picture. We find\nthat the LLM performs well in identifying human-focused stakeholders but poorly\nin recognizing external systems and environmental factors, despite explicit\nefforts to account for these. Additionally, LLMs struggle with preserving the\ndesired level of abstraction and exhibit a tendency to produce solution\nspecific outputs that are inappropriate for problem formulation. More\nimportantly, we document great variability among parallel threads, highlighting\nthat LLM outputs should be used with caution, ideally by adopting a stochastic\nview of their abilities. Overall, our findings suggest that, while ChatGPT\ncould reduce some expert workload, its lack of consistency and domain\nunderstanding may limit its reliability for problem formulation tasks.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "10 pages, 3 figures, submitted to Conference on Systems Engineering\n  Research (CSER)",
    "pdf_url": "http://arxiv.org/pdf/2502.03511v1",
    "published_date": "2025-02-05 17:58:23 UTC",
    "updated_date": "2025-02-05 17:58:23 UTC"
  },
  {
    "arxiv_id": "2502.03403v1",
    "title": "Lightweight Authenticated Task Offloading in 6G-Cloud Vehicular Twin Networks",
    "authors": [
      "Sarah Al-Shareeda",
      "Fusun Ozguner",
      "Keith Redmill",
      "Trung Q. Duong",
      "Berk Canberk"
    ],
    "abstract": "Task offloading management in 6G vehicular networks is crucial for\nmaintaining network efficiency, particularly as vehicles generate substantial\ndata. Integrating secure communication through authentication introduces\nadditional computational and communication overhead, significantly impacting\noffloading efficiency and latency. This paper presents a unified framework\nincorporating lightweight Identity-Based Cryptographic (IBC) authentication\ninto task offloading within cloud-based 6G Vehicular Twin Networks (VTNs).\nUtilizing Proximal Policy Optimization (PPO) in Deep Reinforcement Learning\n(DRL), our approach optimizes authenticated offloading decisions to minimize\nlatency and enhance resource allocation. Performance evaluation under varying\nnetwork sizes, task sizes, and data rates reveals that IBC authentication can\nreduce offloading efficiency by up to 50% due to the added overhead. Besides,\nincreasing network size and task size can further reduce offloading efficiency\nby up to 91.7%. As a countermeasure, increasing the transmission data rate can\nimprove the offloading performance by as much as 63%, even in the presence of\nauthentication overhead. The code for the simulations and experiments detailed\nin this paper is available on GitHub for further reference and reproducibility\n[1].",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "6 pages, 3 figures, IEEE Wireless Communications and Networking\n  Conference (WCNC2025), Milan, Italy, 24-27 March 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.03403v1",
    "published_date": "2025-02-05 17:43:55 UTC",
    "updated_date": "2025-02-05 17:43:55 UTC"
  },
  {
    "arxiv_id": "2502.03397v1",
    "title": "SPRI: Aligning Large Language Models with Context-Situated Principles",
    "authors": [
      "Hongli Zhan",
      "Muneeza Azmat",
      "Raya Horesh",
      "Junyi Jessy Li",
      "Mikhail Yurochkin"
    ],
    "abstract": "Aligning Large Language Models to integrate and reflect human values,\nespecially for tasks that demand intricate human oversight, is arduous since it\nis resource-intensive and time-consuming to depend on human expertise for\ncontext-specific guidance. Prior work has utilized predefined sets of rules or\nprinciples to steer the behavior of models (Bai et al., 2022; Sun et al.,\n2023). However, these principles tend to be generic, making it challenging to\nadapt them to each individual input query or context. In this work, we present\nSituated-PRInciples (SPRI), a framework requiring minimal or no human effort\nthat is designed to automatically generate guiding principles in real-time for\neach input query and utilize them to align each response. We evaluate SPRI on\nthree tasks, and show that 1) SPRI can derive principles in a complex\ndomain-specific task that leads to on-par performance as expert-crafted ones;\n2) SPRI-generated principles lead to instance-specific rubrics that outperform\nprior LLM-as-a-judge frameworks; 3) using SPRI to generate synthetic SFT data\nleads to substantial improvement on truthfulness. We release our code and model\ngenerations at https://github.com/honglizhan/SPRI-public.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03397v1",
    "published_date": "2025-02-05 17:32:29 UTC",
    "updated_date": "2025-02-05 17:32:29 UTC"
  },
  {
    "arxiv_id": "2502.03396v1",
    "title": "Accurate AI-Driven Emergency Vehicle Location Tracking in Healthcare ITS Digital Twin",
    "authors": [
      "Sarah Al-Shareeda",
      "Yasar Celik",
      "Bilge Bilgili",
      "Ahmed Al-Dubai",
      "Berk Canberk"
    ],
    "abstract": "Creating a Digital Twin (DT) for Healthcare Intelligent Transportation\nSystems (HITS) is a hot research trend focusing on enhancing HITS management,\nparticularly in emergencies where ambulance vehicles must arrive at the crash\nscene on time and track their real-time location is crucial to the medical\nauthorities. Despite the claim of real-time representation, a temporal\nmisalignment persists between the physical and virtual domains, leading to\ndiscrepancies in the ambulance's location representation. This study proposes\nintegrating AI predictive models, specifically Support Vector Regression (SVR)\nand Deep Neural Networks (DNN), within a constructed mock DT data pipeline\nframework to anticipate the medical vehicle's next location in the virtual\nworld. These models align virtual representations with their physical\ncounterparts, i.e., metaphorically offsetting the synchronization delay between\nthe two worlds. Trained meticulously on a historical geospatial dataset, SVR\nand DNN exhibit exceptional prediction accuracy in MATLAB and Python\nenvironments. Through various testing scenarios, we visually demonstrate the\nefficacy of our methodology, showcasing SVR and DNN's key role in significantly\nreducing the witnessed gap within the HITS's DT. This transformative approach\nenhances real-time synchronization in emergency HITS by approximately 88% to\n93%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 8 figures, 5th IEEE Middle East & North Africa\n  COMMunications Conference (MENACOMM'25), Lebanon Feb 20-23, 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.03396v1",
    "published_date": "2025-02-05 17:32:07 UTC",
    "updated_date": "2025-02-05 17:32:07 UTC"
  },
  {
    "arxiv_id": "2502.03395v1",
    "title": "Benchmarking Time Series Forecasting Models: From Statistical Techniques to Foundation Models in Real-World Applications",
    "authors": [
      "Issar Arab",
      "Rodrigo Benitez"
    ],
    "abstract": "Time series forecasting is essential for operational intelligence in the\nhospitality industry, and particularly challenging in large-scale, distributed\nsystems. This study evaluates the performance of statistical, machine learning\n(ML), deep learning, and foundation models in forecasting hourly sales over a\n14-day horizon using real-world data from a network of thousands of restaurants\nacross Germany. The forecasting solution includes features such as weather\nconditions, calendar events, and time-of-day patterns. Results demonstrate the\nstrong performance of ML-based meta-models and highlight the emerging potential\nof foundation models like Chronos and TimesFM, which deliver competitive\nperformance with minimal feature engineering, leveraging only the pre-trained\nmodel (zero-shot inference). Additionally, a hybrid PySpark-Pandas approach\nproves to be a robust solution for achieving horizontal scalability in\nlarge-scale deployments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03395v1",
    "published_date": "2025-02-05 17:30:31 UTC",
    "updated_date": "2025-02-05 17:30:31 UTC"
  },
  {
    "arxiv_id": "2502.05221v1",
    "title": "Blackout DIFUSCO",
    "authors": [
      "Jun Pyo Seo"
    ],
    "abstract": "This study explores the integration of Blackout Diffusion into the DIFUSCO\nframework for combinatorial optimization, specifically targeting the Traveling\nSalesman Problem (TSP). Inspired by the success of discrete-time diffusion\nmodels (D3PM) in maintaining structural integrity, we extend the paradigm to a\ncontinuous-time framework, leveraging the unique properties of Blackout\nDiffusion. Continuous-time modeling introduces smoother transitions and refined\ncontrol, hypothesizing enhanced solution quality over traditional discrete\nmethods. We propose three key improvements to enhance the diffusion process.\nFirst, we transition from a discrete-time-based model to a continuous-time\nframework, providing a more refined and flexible formulation. Second, we refine\nthe observation time scheduling to ensure a smooth and linear transformation\nthroughout the diffusion process, allowing for a more natural progression of\nstates. Finally, building upon the second improvement, we further enhance the\nreverse process by introducing finer time slices in regions that are\nparticularly challenging for the model, thereby improving accuracy and\nstability in the reconstruction phase. Although the experimental results did\nnot exceed the baseline performance, they demonstrate the effectiveness of\nthese methods in balancing simplicity and complexity, offering new insights\ninto diffusion-based combinatorial optimization. This work represents the first\napplication of Blackout Diffusion to combinatorial optimization, providing a\nfoundation for further advancements in this domain. * The code is available for\nreview at https://github.com/Giventicket/BlackoutDIFUSCO.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.05221v1",
    "published_date": "2025-02-05 17:24:33 UTC",
    "updated_date": "2025-02-05 17:24:33 UTC"
  },
  {
    "arxiv_id": "2502.03387v1",
    "title": "LIMO: Less is More for Reasoning",
    "authors": [
      "Yixin Ye",
      "Zhen Huang",
      "Yang Xiao",
      "Ethan Chern",
      "Shijie Xia",
      "Pengfei Liu"
    ],
    "abstract": "We present a fundamental discovery that challenges our understanding of how\ncomplex reasoning emerges in large language models. While conventional wisdom\nsuggests that sophisticated reasoning tasks demand extensive training data\n(>100,000 examples), we demonstrate that complex mathematical reasoning\nabilities can be effectively elicited with surprisingly few examples. Through\ncomprehensive experiments, our proposed model LIMO demonstrates unprecedented\nperformance in mathematical reasoning. With merely 817 curated training\nsamples, LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH, improving from\nprevious SFT-based models' 6.5% and 59.2% respectively, while only using 1% of\nthe training data required by previous approaches. LIMO demonstrates\nexceptional out-of-distribution generalization, achieving 40.5% absolute\nimprovement across 10 diverse benchmarks, outperforming models trained on 100x\nmore data, challenging the notion that SFT leads to memorization rather than\ngeneralization. Based on these results, we propose the Less-Is-More Reasoning\nHypothesis (LIMO Hypothesis): In foundation models where domain knowledge has\nbeen comprehensively encoded during pre-training, sophisticated reasoning\ncapabilities can emerge through minimal but precisely orchestrated\ndemonstrations of cognitive processes. This hypothesis posits that the\nelicitation threshold for complex reasoning is determined by two key factors:\n(1) the completeness of the model's encoded knowledge foundation during\npre-training, and (2) the effectiveness of post-training examples as \"cognitive\ntemplates\" that show the model how to utilize its knowledge base to solve\ncomplex reasoning tasks. To facilitate reproducibility and future research in\ndata-efficient reasoning, we release LIMO as a comprehensive open-source suite\nat https://github.com/GAIR-NLP/LIMO.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.03387v1",
    "published_date": "2025-02-05 17:23:45 UTC",
    "updated_date": "2025-02-05 17:23:45 UTC"
  },
  {
    "arxiv_id": "2502.04380v1",
    "title": "Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data",
    "authors": [
      "Zhenqing Ling",
      "Daoyuan Chen",
      "Liuyi Yao",
      "Yaliang Li",
      "Ying Shen"
    ],
    "abstract": "Fine-tuning large language models (LLMs) using diverse datasets is crucial\nfor enhancing their overall performance across various domains. In practical\nscenarios, existing methods based on modeling the mixture proportions of data\ncomposition often struggle with data whose domain labels are missing, imprecise\nor non-normalized, while methods based on data selection usually encounter\ndifficulties in balancing multi-domain performance. To address these\nchallenges, in this paper, we study the role of data diversity in enhancing the\noverall abilities of LLMs by empirically constructing contrastive data pools\nand theoretically deriving explanations for both inter- and intra-diversity.\nBuilding upon the insights gained, we propose a new method that gives the LLM a\ndual identity: an output model to cognitively probe and select data based on\ndiversity reward, as well as an input model to be tuned with the selected data.\nExtensive experiments show that the proposed method notably boosts performance\nacross domain-undetermined data and a series of foundational downstream tasks\nwhen applied to various advanced LLMs. We release our code and hope this study\ncan shed light on the understanding of data diversity and advance\nfeedback-driven data-model co-development for LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages, 15 figures, 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.04380v1",
    "published_date": "2025-02-05 17:21:01 UTC",
    "updated_date": "2025-02-05 17:21:01 UTC"
  },
  {
    "arxiv_id": "2502.03383v1",
    "title": "Transformers and Their Roles as Time Series Foundation Models",
    "authors": [
      "Dennis Wu",
      "Yihan He",
      "Yuan Cao",
      "Jianqing Fan",
      "Han Liu"
    ],
    "abstract": "We give a comprehensive analysis of transformers as time series foundation\nmodels, focusing on their approximation and generalization capabilities. First,\nwe demonstrate that there exist transformers that fit an autoregressive model\non input univariate time series via gradient descent. We then analyze MOIRAI, a\nmultivariate time series foundation model capable of handling an arbitrary\nnumber of covariates. We prove that it is capable of automatically fitting\nautoregressive models with an arbitrary number of covariates, offering insights\ninto its design and empirical success. For generalization, we establish bounds\nfor pretraining when the data satisfies Dobrushin's condition. Experiments\nsupport our theoretical findings, highlighting the efficacy of transformers as\ntime series foundation models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "34 Pages, 2 Figures",
    "pdf_url": "http://arxiv.org/pdf/2502.03383v1",
    "published_date": "2025-02-05 17:18:55 UTC",
    "updated_date": "2025-02-05 17:18:55 UTC"
  },
  {
    "arxiv_id": "2502.04379v1",
    "title": "Can Large Language Models Capture Video Game Engagement?",
    "authors": [
      "David Melhart",
      "Matthew Barthet",
      "Georgios N. Yannakakis"
    ],
    "abstract": "Can out-of-the-box pretrained Large Language Models (LLMs) detect human\naffect successfully when observing a video? To address this question, for the\nfirst time, we evaluate comprehensively the capacity of popular LLMs to\nannotate and successfully predict continuous affect annotations of videos when\nprompted by a sequence of text and video frames in a multimodal fashion.\nParticularly in this paper, we test LLMs' ability to correctly label changes of\nin-game engagement in 80 minutes of annotated videogame footage from 20\nfirst-person shooter games of the GameVibe corpus. We run over 2,400\nexperiments to investigate the impact of LLM architecture, model size, input\nmodality, prompting strategy, and ground truth processing method on engagement\nprediction. Our findings suggest that while LLMs rightfully claim human-like\nperformance across multiple domains, they generally fall behind capturing\ncontinuous experience annotations provided by humans. We examine some of the\nunderlying causes for the relatively poor overall performance, highlight the\ncases where LLMs exceed expectations, and draw a roadmap for the further\nexploration of automated emotion labelling via LLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2502.04379v1",
    "published_date": "2025-02-05 17:14:47 UTC",
    "updated_date": "2025-02-05 17:14:47 UTC"
  },
  {
    "arxiv_id": "2502.03369v1",
    "title": "Learning from Active Human Involvement through Proxy Value Propagation",
    "authors": [
      "Zhenghao Peng",
      "Wenjie Mo",
      "Chenda Duan",
      "Quanyi Li",
      "Bolei Zhou"
    ],
    "abstract": "Learning from active human involvement enables the human subject to actively\nintervene and demonstrate to the AI agent during training. The interaction and\ncorrective feedback from human brings safety and AI alignment to the learning\nprocess. In this work, we propose a new reward-free active human involvement\nmethod called Proxy Value Propagation for policy optimization. Our key insight\nis that a proxy value function can be designed to express human intents,\nwherein state-action pairs in the human demonstration are labeled with high\nvalues, while those agents' actions that are intervened receive low values.\nThrough the TD-learning framework, labeled values of demonstrated state-action\npairs are further propagated to other unlabeled data generated from agents'\nexploration. The proxy value function thus induces a policy that faithfully\nemulates human behaviors. Human-in-the-loop experiments show the generality and\nefficiency of our method. With minimal modification to existing reinforcement\nlearning algorithms, our method can learn to solve continuous and discrete\ncontrol tasks with various human control devices, including the challenging\ntask of driving in Grand Theft Auto V. Demo video and code are available at:\nhttps://metadriverse.github.io/pvp",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2023 Spotlight. Project page:\n  https://metadriverse.github.io/pvp",
    "pdf_url": "http://arxiv.org/pdf/2502.03369v1",
    "published_date": "2025-02-05 17:07:37 UTC",
    "updated_date": "2025-02-05 17:07:37 UTC"
  },
  {
    "arxiv_id": "2502.03368v1",
    "title": "PalimpChat: Declarative and Interactive AI analytics",
    "authors": [
      "Chunwei Liu",
      "Gerardo Vitagliano",
      "Brandon Rose",
      "Matt Prinz",
      "David Andrew Samson",
      "Michael Cafarella"
    ],
    "abstract": "Thanks to the advances in generative architectures and large language models,\ndata scientists can now code pipelines of machine-learning operations to\nprocess large collections of unstructured data. Recent progress has seen the\nrise of declarative AI frameworks (e.g., Palimpzest, Lotus, and DocETL) to\nbuild optimized and increasingly complex pipelines, but these systems often\nremain accessible only to expert programmers. In this demonstration, we present\nPalimpChat, a chat-based interface to Palimpzest that bridges this gap by\nletting users create and run sophisticated AI pipelines through natural\nlanguage alone. By integrating Archytas, a ReAct-based reasoning agent, and\nPalimpzest's suite of relational and LLM-based operators, PalimpChat provides a\npractical illustration of how a chat interface can make declarative AI\nframeworks truly accessible to non-experts.\n  Our demo system is publicly available online. At SIGMOD'25, participants can\nexplore three real-world scenarios--scientific discovery, legal discovery, and\nreal estate search--or apply PalimpChat to their own datasets. In this paper,\nwe focus on how PalimpChat, supported by the Palimpzest optimizer, simplifies\ncomplex AI workflows such as extracting and analyzing biomedical data.",
    "categories": [
      "cs.AI",
      "cs.DB",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03368v1",
    "published_date": "2025-02-05 17:06:59 UTC",
    "updated_date": "2025-02-05 17:06:59 UTC"
  },
  {
    "arxiv_id": "2502.03360v1",
    "title": "A Beam's Eye View to Fluence Maps 3D Network for Ultra Fast VMAT Radiotherapy Planning",
    "authors": [
      "Simon Arberet",
      "Florin C. Ghesu",
      "Riqiang Gao",
      "Martin Kraus",
      "Jonathan Sackett",
      "Esa Kuusela",
      "Ali Kamen"
    ],
    "abstract": "Volumetric Modulated Arc Therapy (VMAT) revolutionizes cancer treatment by\nprecisely delivering radiation while sparing healthy tissues. Fluence maps\ngeneration, crucial in VMAT planning, traditionally involves complex and\niterative, and thus time consuming processes. These fluence maps are\nsubsequently leveraged for leaf-sequence. The deep-learning approach presented\nin this article aims to expedite this by directly predicting fluence maps from\npatient data. We developed a 3D network which we trained in a supervised way\nusing a combination of L1 and L2 losses, and RT plans generated by Eclipse and\nfrom the REQUITE dataset, taking the RT dose map as input and the fluence maps\ncomputed from the corresponding RT plans as target. Our network predicts\njointly the 180 fluence maps corresponding to the 180 control points (CP) of\nsingle arc VMAT plans. In order to help the network, we pre-process the input\ndose by computing the projections of the 3D dose map to the beam's eye view\n(BEV) of the 180 CPs, in the same coordinate system as the fluence maps. We\ngenerated over 2000 VMAT plans using Eclipse to scale up the dataset size.\nAdditionally, we evaluated various network architectures and analyzed the\nimpact of increasing the dataset size. We are measuring the performance in the\n2D fluence maps domain using image metrics (PSNR, SSIM), as well as in the 3D\ndose domain using the dose-volume histogram (DVH) on a validation dataset. The\nnetwork inference, which does not include the data loading and processing, is\nless than 20ms. Using our proposed 3D network architecture as well as\nincreasing the dataset size using Eclipse improved the fluence map\nreconstruction performance by approximately 8 dB in PSNR compared to a U-Net\narchitecture trained on the original REQUITE dataset. The resulting DVHs are\nvery close to the one of the input target dose.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "physics.med-ph"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03360v1",
    "published_date": "2025-02-05 16:56:17 UTC",
    "updated_date": "2025-02-05 16:56:17 UTC"
  },
  {
    "arxiv_id": "2502.03359v2",
    "title": "GHOST: Gaussian Hypothesis Open-Set Technique",
    "authors": [
      "Ryan Rabinowitz",
      "Steve Cruz",
      "Manuel Günther",
      "Terrance E. Boult"
    ],
    "abstract": "Evaluations of large-scale recognition methods typically focus on overall\nperformance. While this approach is common, it often fails to provide insights\ninto performance across individual classes, which can lead to fairness issues\nand misrepresentation. Addressing these gaps is crucial for accurately\nassessing how well methods handle novel or unseen classes and ensuring a fair\nevaluation. To address fairness in Open-Set Recognition (OSR), we demonstrate\nthat per-class performance can vary dramatically. We introduce Gaussian\nHypothesis Open Set Technique (GHOST), a novel hyperparameter-free algorithm\nthat models deep features using class-wise multivariate Gaussian distributions\nwith diagonal covariance matrices. We apply Z-score normalization to logits to\nmitigate the impact of feature magnitudes that deviate from the model's\nexpectations, thereby reducing the likelihood of the network assigning a high\nscore to an unknown sample. We evaluate GHOST across multiple ImageNet-1K\npre-trained deep networks and test it with four different unknown datasets.\nUsing standard metrics such as AUOSCR, AUROC and FPR95, we achieve\nstatistically significant improvements, advancing the state-of-the-art in\nlarge-scale OSR. Source code is provided online.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at AAAI Conference on Artificial Intelligence 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.03359v2",
    "published_date": "2025-02-05 16:56:14 UTC",
    "updated_date": "2025-02-10 17:33:29 UTC"
  },
  {
    "arxiv_id": "2502.06831v1",
    "title": "No Location Left Behind: Measuring and Improving the Fairness of Implicit Representations for Earth Data",
    "authors": [
      "Daniel Cai",
      "Randall Balestriero"
    ],
    "abstract": "Implicit neural representations (INRs) exhibit growing promise in addressing\nEarth representation challenges, ranging from emissions monitoring to climate\nmodeling. However, existing methods disproportionately prioritize global\naverage performance, whereas practitioners require fine-grained insights to\nunderstand biases and variations in these models. To bridge this gap, we\nintroduce FAIR-Earth: a first-of-its-kind dataset explicitly crafted to examine\nand challenge inequities in Earth representations. FAIR-Earth comprises various\nhigh-resolution Earth signals and uniquely aggregates extensive metadata along\nstratifications like landmass size and population density to assess the\nfairness of models. Evaluating state-of-the-art INRs across the various\nmodalities of FAIR-Earth, we uncover striking performance disparities. Certain\nsubgroups, especially those associated with high-frequency signals (e.g.,\nislands, coastlines), are consistently poorly modeled by existing methods. In\nresponse, we propose spherical wavelet encodings, building on previous spatial\nencoding research. Leveraging the multi-resolution capabilities of wavelets,\nour encodings yield consistent performance over various scales and locations,\noffering more accurate and robust representations of the biased subgroups.\nThese open-source contributions represent a crucial step towards the equitable\nassessment and deployment of Earth INRs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06831v1",
    "published_date": "2025-02-05 16:51:13 UTC",
    "updated_date": "2025-02-05 16:51:13 UTC"
  },
  {
    "arxiv_id": "2503.04741v1",
    "title": "Which Information should the UK and US AISI share with an International Network of AISIs? Opportunities, Risks, and a Tentative Proposal",
    "authors": [
      "Lara Thurnherr"
    ],
    "abstract": "The UK AI Safety Institute (UK AISI) and its parallel organisation in the\nUnited States (US AISI) take up a unique position in the recently established\nInternational Network of AISIs. Both are in jurisdictions with frontier AI\ncompanies and are assuming leading roles in the international conversation on\nAI Safety. This paper argues that it is in the interest of both institutions to\nshare specific categories of information with the International Network of\nAISIs, deliberately abstain from sharing others and carefully evaluate sharing\nsome categories on a case by case basis, according to domestic priorities. The\npaper further proposes a provisional framework with which policymakers and\nresearchers can distinguish between these three cases, taking into account the\npotential benefits and risks of sharing specific categories of information,\nranging from pre-deployment evaluation results to evaluation standards. In an\neffort to further improve the research on AI policy relevant information\nsharing decisions, the paper emphasises the importance of continuously\nmonitoring fluctuating factors influencing sharing decisions and a more\nin-depth analysis of specific policy relevant information categories and\nadditional factors to consider in future research.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "12 Pages, 3 Tables, 2 Figures",
    "pdf_url": "http://arxiv.org/pdf/2503.04741v1",
    "published_date": "2025-02-05 16:49:02 UTC",
    "updated_date": "2025-02-05 16:49:02 UTC"
  },
  {
    "arxiv_id": "2502.03349v1",
    "title": "Robust Autonomy Emerges from Self-Play",
    "authors": [
      "Marco Cusumano-Towner",
      "David Hafner",
      "Alex Hertzberg",
      "Brody Huval",
      "Aleksei Petrenko",
      "Eugene Vinitsky",
      "Erik Wijmans",
      "Taylor Killian",
      "Stuart Bowers",
      "Ozan Sener",
      "Philipp Krähenbühl",
      "Vladlen Koltun"
    ],
    "abstract": "Self-play has powered breakthroughs in two-player and multi-player games.\nHere we show that self-play is a surprisingly effective strategy in another\ndomain. We show that robust and naturalistic driving emerges entirely from\nself-play in simulation at unprecedented scale -- 1.6~billion~km of driving.\nThis is enabled by Gigaflow, a batched simulator that can synthesize and train\non 42 years of subjective driving experience per hour on a single 8-GPU node.\nThe resulting policy achieves state-of-the-art performance on three independent\nautonomous driving benchmarks. The policy outperforms the prior state of the\nart when tested on recorded real-world scenarios, amidst human drivers, without\never seeing human data during training. The policy is realistic when assessed\nagainst human references and achieves unprecedented robustness, averaging 17.5\nyears of continuous driving between incidents in simulation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03349v1",
    "published_date": "2025-02-05 16:41:05 UTC",
    "updated_date": "2025-02-05 16:41:05 UTC"
  },
  {
    "arxiv_id": "2502.03341v1",
    "title": "Adaptive Variational Inference in Probabilistic Graphical Models: Beyond Bethe, Tree-Reweighted, and Convex Free Energies",
    "authors": [
      "Harald Leisenberger",
      "Franz Pernkopf"
    ],
    "abstract": "Variational inference in probabilistic graphical models aims to approximate\nfundamental quantities such as marginal distributions and the partition\nfunction. Popular approaches are the Bethe approximation, tree-reweighted, and\nother types of convex free energies. These approximations are efficient but can\nfail if the model is complex and highly interactive. In this work, we analyze\ntwo classes of approximations that include the above methods as special cases:\nfirst, if the model parameters are changed; and second, if the entropy\napproximation is changed. We discuss benefits and drawbacks of either approach,\nand deduce from this analysis how a free energy approximation should ideally be\nconstructed. Based on our observations, we propose approximations that\nautomatically adapt to a given model and demonstrate their effectiveness for a\nrange of difficult problems.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "This work has been submitted to the Conference on Uncertainty in\n  Artificial Intelligence (UAI) 2025 for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2502.03341v1",
    "published_date": "2025-02-05 16:33:59 UTC",
    "updated_date": "2025-02-05 16:33:59 UTC"
  },
  {
    "arxiv_id": "2502.03333v1",
    "title": "RadVLM: A Multitask Conversational Vision-Language Model for Radiology",
    "authors": [
      "Nicolas Deperrois",
      "Hidetoshi Matsuo",
      "Samuel Ruipérez-Campillo",
      "Moritz Vandenhirtz",
      "Sonia Laguna",
      "Alain Ryser",
      "Koji Fujimoto",
      "Mizuho Nishio",
      "Thomas M. Sutter",
      "Julia E. Vogt",
      "Jonas Kluckert",
      "Thomas Frauenfelder",
      "Christian Blüthgen",
      "Farhad Nooralahzadeh",
      "Michael Krauthammer"
    ],
    "abstract": "The widespread use of chest X-rays (CXRs), coupled with a shortage of\nradiologists, has driven growing interest in automated CXR analysis and\nAI-assisted reporting. While existing vision-language models (VLMs) show\npromise in specific tasks such as report generation or abnormality detection,\nthey often lack support for interactive diagnostic capabilities. In this work\nwe present RadVLM, a compact, multitask conversational foundation model\ndesigned for CXR interpretation. To this end, we curate a large-scale\ninstruction dataset comprising over 1 million image-instruction pairs\ncontaining both single-turn tasks -- such as report generation, abnormality\nclassification, and visual grounding -- and multi-turn, multi-task\nconversational interactions. After fine-tuning RadVLM on this instruction\ndataset, we evaluate it across different tasks along with re-implemented\nbaseline VLMs. Our results show that RadVLM achieves state-of-the-art\nperformance in conversational capabilities and visual grounding while remaining\ncompetitive in other radiology tasks. Ablation studies further highlight the\nbenefit of joint training across multiple tasks, particularly for scenarios\nwith limited annotated data. Together, these findings highlight the potential\nof RadVLM as a clinically relevant AI assistant, providing structured CXR\ninterpretation and conversational capabilities to support more effective and\naccessible diagnostic workflows.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "21 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.03333v1",
    "published_date": "2025-02-05 16:27:02 UTC",
    "updated_date": "2025-02-05 16:27:02 UTC"
  },
  {
    "arxiv_id": "2502.04377v1",
    "title": "MapFusion: A Novel BEV Feature Fusion Network for Multi-modal Map Construction",
    "authors": [
      "Xiaoshuai Hao",
      "Yunfeng Diao",
      "Mengchuan Wei",
      "Yifan Yang",
      "Peng Hao",
      "Rong Yin",
      "Hui Zhang",
      "Weiming Li",
      "Shu Zhao",
      "Yu Liu"
    ],
    "abstract": "Map construction task plays a vital role in providing precise and\ncomprehensive static environmental information essential for autonomous driving\nsystems. Primary sensors include cameras and LiDAR, with configurations varying\nbetween camera-only, LiDAR-only, or camera-LiDAR fusion, based on\ncost-performance considerations. While fusion-based methods typically perform\nbest, existing approaches often neglect modality interaction and rely on simple\nfusion strategies, which suffer from the problems of misalignment and\ninformation loss. To address these issues, we propose MapFusion, a novel\nmulti-modal Bird's-Eye View (BEV) feature fusion method for map construction.\nSpecifically, to solve the semantic misalignment problem between camera and\nLiDAR BEV features, we introduce the Cross-modal Interaction Transform (CIT)\nmodule, enabling interaction between two BEV feature spaces and enhancing\nfeature representation through a self-attention mechanism. Additionally, we\npropose an effective Dual Dynamic Fusion (DDF) module to adaptively select\nvaluable information from different modalities, which can take full advantage\nof the inherent information between different modalities. Moreover, MapFusion\nis designed to be simple and plug-and-play, easily integrated into existing\npipelines. We evaluate MapFusion on two map construction tasks, including\nHigh-definition (HD) map and BEV map segmentation, to show its versatility and\neffectiveness. Compared with the state-of-the-art methods, MapFusion achieves\n3.6% and 6.2% absolute improvements on the HD map construction and BEV map\nsegmentation tasks on the nuScenes dataset, respectively, demonstrating the\nsuperiority of our approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04377v1",
    "published_date": "2025-02-05 16:25:45 UTC",
    "updated_date": "2025-02-05 16:25:45 UTC"
  },
  {
    "arxiv_id": "2502.04376v1",
    "title": "MEETING DELEGATE: Benchmarking LLMs on Attending Meetings on Our Behalf",
    "authors": [
      "Lingxiang Hu",
      "Shurun Yuan",
      "Xiaoting Qin",
      "Jue Zhang",
      "Qingwei Lin",
      "Dongmei Zhang",
      "Saravan Rajmohan",
      "Qi Zhang"
    ],
    "abstract": "In contemporary workplaces, meetings are essential for exchanging ideas and\nensuring team alignment but often face challenges such as time consumption,\nscheduling conflicts, and inefficient participation. Recent advancements in\nLarge Language Models (LLMs) have demonstrated their strong capabilities in\nnatural language generation and reasoning, prompting the question: can LLMs\neffectively delegate participants in meetings? To explore this, we develop a\nprototype LLM-powered meeting delegate system and create a comprehensive\nbenchmark using real meeting transcripts. Our evaluation reveals that GPT-4/4o\nmaintain balanced performance between active and cautious engagement\nstrategies. In contrast, Gemini 1.5 Pro tends to be more cautious, while Gemini\n1.5 Flash and Llama3-8B/70B display more active tendencies. Overall, about 60\\%\nof responses address at least one key point from the ground-truth. However,\nimprovements are needed to reduce irrelevant or repetitive content and enhance\ntolerance for transcription errors commonly found in real-world settings.\nAdditionally, we implement the system in practical settings and collect\nreal-world feedback from demos. Our findings underscore the potential and\nchallenges of utilizing LLMs as meeting delegates, offering valuable insights\ninto their practical application for alleviating the burden of meetings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04376v1",
    "published_date": "2025-02-05 16:25:43 UTC",
    "updated_date": "2025-02-05 16:25:43 UTC"
  },
  {
    "arxiv_id": "2502.03330v1",
    "title": "Controllable GUI Exploration",
    "authors": [
      "Aryan Garg",
      "Yue Jiang",
      "Antti Oulasvirta"
    ],
    "abstract": "During the early stages of interface design, designers need to produce\nmultiple sketches to explore a design space. Design tools often fail to support\nthis critical stage, because they insist on specifying more details than\nnecessary. Although recent advances in generative AI have raised hopes of\nsolving this issue, in practice they fail because expressing loose ideas in a\nprompt is impractical. In this paper, we propose a diffusion-based approach to\nthe low-effort generation of interface sketches. It breaks new ground by\nallowing flexible control of the generation process via three types of inputs:\nA) prompts, B) wireframes, and C) visual flows. The designer can provide any\ncombination of these as input at any level of detail, and will get a diverse\ngallery of low-fidelity solutions in response. The unique benefit is that large\ndesign spaces can be explored rapidly with very little effort in\ninput-specification. We present qualitative results for various combinations of\ninput specifications. Additionally, we demonstrate that our model aligns more\naccurately with these specifications than other models.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03330v1",
    "published_date": "2025-02-05 16:25:35 UTC",
    "updated_date": "2025-02-05 16:25:35 UTC"
  },
  {
    "arxiv_id": "2502.03325v1",
    "title": "ECM: A Unified Electronic Circuit Model for Explaining the Emergence of In-Context Learning and Chain-of-Thought in Large Language Model",
    "authors": [
      "Qiguang Chen",
      "Libo Qin",
      "Jinhao Liu",
      "Dengyun Peng",
      "Jiaqi Wang",
      "Mengkang Hu",
      "Zhi Chen",
      "Wanxiang Che",
      "Ting Liu"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have led to significant\nsuccesses across various applications, where the most noticeable is to a series\nof emerging capabilities, particularly in the areas of In-Context Learning\n(ICL) and Chain-of-Thought (CoT). To better understand and control model\nperformance, many studies have begun investigating the underlying causes of\nthese phenomena and their impact on task outcomes. However, existing\nexplanatory frameworks predominantly focus on isolating and explaining ICL and\nCoT independently, leading to an incomplete understanding of their combined\ninfluence on model performance. To address this gap, we propose the Electronic\nCircuit Model (ECM), which provides a foundation for developing scalable,\nlearnable policies and improving the management of AI-generated content.\nSpecifically, ECM conceptualizes model behavior as an electronic circuit: ICL\nis represented as semantic magnetic field to providing an additional voltage\nfollowing Faraday's Law, while CoT is modeled as series resistors to constrain\nthe model output performance following Ohm's Law. Experimental results\ndemonstrate that the ECM effectively predicts and explains LLM performance\nacross a variety of prompting strategies. Furthermore, we apply ECM to advanced\nreasoning strategy optimization on a series of tasks, such as the International\nOlympiad in Informatics (IOI) and the International Mathematical Olympiad\n(IMO), achieving competitive performance that surpasses nearly 80% of top human\ncompetitors.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Manuscript",
    "pdf_url": "http://arxiv.org/pdf/2502.03325v1",
    "published_date": "2025-02-05 16:22:33 UTC",
    "updated_date": "2025-02-05 16:22:33 UTC"
  },
  {
    "arxiv_id": "2502.03323v1",
    "title": "Out-of-Distribution Detection using Synthetic Data Generation",
    "authors": [
      "Momin Abbas",
      "Muneeza Azmat",
      "Raya Horesh",
      "Mikhail Yurochkin"
    ],
    "abstract": "Distinguishing in- and out-of-distribution (OOD) inputs is crucial for\nreliable deployment of classification systems. However, OOD data is typically\nunavailable or difficult to collect, posing a significant challenge for\naccurate OOD detection. In this work, we present a method that harnesses the\ngenerative capabilities of Large Language Models (LLMs) to create high-quality\nsynthetic OOD proxies, eliminating the dependency on any external OOD data\nsource. We study the efficacy of our method on classical text classification\ntasks such as toxicity detection and sentiment classification as well as\nclassification tasks arising in LLM development and deployment, such as\ntraining a reward model for RLHF and detecting misaligned generations.\nExtensive experiments on nine InD-OOD dataset pairs and various model sizes\nshow that our approach dramatically lowers false positive rates (achieving a\nperfect zero in some cases) while maintaining high accuracy on in-distribution\ntasks, outperforming baseline methods by a significant margin.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03323v1",
    "published_date": "2025-02-05 16:22:09 UTC",
    "updated_date": "2025-02-05 16:22:09 UTC"
  },
  {
    "arxiv_id": "2502.03321v3",
    "title": "Simplifying Formal Proof-Generating Models with ChatGPT and Basic Searching Techniques",
    "authors": [
      "Sangjun Han",
      "Taeil Hur",
      "Youngmi Hur",
      "Kathy Sangkyung Lee",
      "Myungyoon Lee",
      "Hyojae Lim"
    ],
    "abstract": "The challenge of formal proof generation has a rich history, but with modern\ntechniques, we may finally be at the stage of making actual progress in\nreal-life mathematical problems. This paper explores the integration of ChatGPT\nand basic searching techniques to simplify generating formal proofs, with a\nparticular focus on the miniF2F dataset. We demonstrate how combining a large\nlanguage model like ChatGPT with a formal language such as Lean, which has the\nadded advantage of being verifiable, enhances the efficiency and accessibility\nof formal proof generation. Despite its simplicity, our best-performing\nLean-based model surpasses all known benchmarks with a 31.15% pass rate. We\nextend our experiments to include other datasets and employ alternative\nlanguage models, showcasing our models' comparable performance in diverse\nsettings and allowing for a more nuanced analysis of our results. Our findings\noffer insights into AI-assisted formal proof generation, suggesting a promising\ndirection for future research in formal mathematical proof.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "This manuscript was accepted for publication in the proceedings of\n  the Computing Conference 2025 (Springer LNNS). The Version of Record (VoR)\n  has not yet been published. This Accepted Manuscript does not reflect any\n  post-acceptance improvements or corrections. Use of this version is subject\n  to Springer Nature's Accepted Manuscript terms of use",
    "pdf_url": "http://arxiv.org/pdf/2502.03321v3",
    "published_date": "2025-02-05 16:21:10 UTC",
    "updated_date": "2025-02-19 06:52:46 UTC"
  },
  {
    "arxiv_id": "2502.03304v1",
    "title": "Harmony in Divergence: Towards Fast, Accurate, and Memory-efficient Zeroth-order LLM Fine-tuning",
    "authors": [
      "Qitao Tan",
      "Jun Liu",
      "Zheng Zhan",
      "Caiwei Ding",
      "Yanzhi Wang",
      "Jin Lu",
      "Geng Yuan"
    ],
    "abstract": "Large language models (LLMs) excel across various tasks, but standard\nfirst-order (FO) fine-tuning demands considerable memory, significantly\nlimiting real-world deployment. Recently, zeroth-order (ZO) optimization stood\nout as a promising memory-efficient training paradigm, avoiding backward passes\nand relying solely on forward passes for gradient estimation, making it\nattractive for resource-constrained scenarios. However, ZO method lags far\nbehind FO method in both convergence speed and accuracy. To bridge the gap, we\nintroduce a novel layer-wise divergence analysis that uncovers the distinct\nupdate pattern of FO and ZO optimization. Aiming to resemble the learning\ncapacity of FO method from the findings, we propose \\textbf{Di}vergence-driven\n\\textbf{Z}eroth-\\textbf{O}rder (\\textbf{DiZO}) optimization. DiZO conducts\ndivergence-driven layer adaptation by incorporating projections to ZO updates,\ngenerating diverse-magnitude updates precisely scaled to layer-wise individual\noptimization needs. Our results demonstrate that DiZO significantly reduces the\nneeded iterations for convergence without sacrificing throughput, cutting\ntraining GPU hours by up to 48\\% on various datasets. Moreover, DiZO\nconsistently outperforms the representative ZO baselines in fine-tuning\nRoBERTa-large, OPT-series, and Llama-series on downstream tasks and, in some\ncases, even surpasses memory-intensive FO fine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03304v1",
    "published_date": "2025-02-05 16:03:17 UTC",
    "updated_date": "2025-02-05 16:03:17 UTC"
  },
  {
    "arxiv_id": "2502.03298v1",
    "title": "MeDiSumQA: Patient-Oriented Question-Answer Generation from Discharge Letters",
    "authors": [
      "Amin Dada",
      "Osman Alperen Koras",
      "Marie Bauer",
      "Amanda Butler",
      "Kaleb E. Smith",
      "Jens Kleesiek",
      "Julian Friedrich"
    ],
    "abstract": "While increasing patients' access to medical documents improves medical care,\nthis benefit is limited by varying health literacy levels and complex medical\nterminology. Large language models (LLMs) offer solutions by simplifying\nmedical information. However, evaluating LLMs for safe and patient-friendly\ntext generation is difficult due to the lack of standardized evaluation\nresources. To fill this gap, we developed MeDiSumQA. MeDiSumQA is a dataset\ncreated from MIMIC-IV discharge summaries through an automated pipeline\ncombining LLM-based question-answer generation with manual quality checks. We\nuse this dataset to evaluate various LLMs on patient-oriented\nquestion-answering. Our findings reveal that general-purpose LLMs frequently\nsurpass biomedical-adapted models, while automated metrics correlate with human\njudgment. By releasing MeDiSumQA on PhysioNet, we aim to advance the\ndevelopment of LLMs to enhance patient understanding and ultimately improve\ncare outcomes.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03298v1",
    "published_date": "2025-02-05 15:56:37 UTC",
    "updated_date": "2025-02-05 15:56:37 UTC"
  },
  {
    "arxiv_id": "2502.03292v1",
    "title": "ALPET: Active Few-shot Learning for Citation Worthiness Detection in Low-Resource Wikipedia Languages",
    "authors": [
      "Aida Halitaj",
      "Arkaitz Zubiaga"
    ],
    "abstract": "Citation Worthiness Detection (CWD) consists in determining which sentences,\nwithin an article or collection, should be backed up with a citation to\nvalidate the information it provides. This study, introduces ALPET, a framework\ncombining Active Learning (AL) and Pattern-Exploiting Training (PET), to\nenhance CWD for languages with limited data resources. Applied to Catalan,\nBasque, and Albanian Wikipedia datasets, ALPET outperforms the existing CCW\nbaseline while reducing the amount of labeled data in some cases above 80\\%.\nALPET's performance plateaus after 300 labeled samples, showing it suitability\nfor low-resource scenarios where large, labeled datasets are not common. While\nspecific active learning query strategies, like those employing K-Means\nclustering, can offer advantages, their effectiveness is not universal and\noften yields marginal gains over random sampling, particularly with smaller\ndatasets. This suggests that random sampling, despite its simplicity, remains a\nstrong baseline for CWD in constraint resource environments. Overall, ALPET's\nability to achieve high performance with fewer labeled samples makes it a\npromising tool for enhancing the verifiability of online content in\nlow-resource language settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 8 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.03292v1",
    "published_date": "2025-02-05 15:49:41 UTC",
    "updated_date": "2025-02-05 15:49:41 UTC"
  },
  {
    "arxiv_id": "2502.05220v1",
    "title": "Aero-LLM: A Distributed Framework for Secure UAV Communication and Intelligent Decision-Making",
    "authors": [
      "Balakrishnan Dharmalingam",
      "Rajdeep Mukherjee",
      "Brett Piggott",
      "Guohuan Feng",
      "Anyi Liu"
    ],
    "abstract": "Increased utilization of unmanned aerial vehicles (UAVs) in critical\noperations necessitates secure and reliable communication with Ground Control\nStations (GCS). This paper introduces Aero-LLM, a framework integrating\nmultiple Large Language Models (LLMs) to enhance UAV mission security and\noperational efficiency. Unlike conventional singular LLMs, Aero-LLM leverages\nmultiple specialized LLMs for various tasks, such as inferencing, anomaly\ndetection, and forecasting, deployed across onboard systems, edge, and cloud\nservers. This dynamic, distributed architecture reduces performance bottleneck\nand increases security capabilities. Aero-LLM's evaluation demonstrates\noutstanding task-specific metrics and robust defense against cyber threats,\nsignificantly enhancing UAV decision-making and operational capabilities and\nsecurity resilience against cyber attacks, setting a new standard for secure,\nintelligent UAV operations.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "This manuscript was accepted by the 1st International Workshop on\n  Integrated Sensing, Communication, and Computing in Internet of Things (IoT)\n  Systems at the The 33rd International Conference on Computer Communications\n  and Networks (ICCCN 2024)",
    "pdf_url": "http://arxiv.org/pdf/2502.05220v1",
    "published_date": "2025-02-05 15:46:27 UTC",
    "updated_date": "2025-02-05 15:46:27 UTC"
  },
  {
    "arxiv_id": "2502.03287v2",
    "title": "STEMS: Spatial-Temporal Mapping Tool For Spiking Neural Networks",
    "authors": [
      "Sherif Eissa",
      "Sander Stuijk",
      "Floran De Putter",
      "Andrea Nardi-Dei",
      "Federico Corradi",
      "Henk Corporaal"
    ],
    "abstract": "Spiking Neural Networks (SNNs) are promising bio-inspired third-generation\nneural networks. Recent research has trained deep SNN models with accuracy on\npar with Artificial Neural Networks (ANNs). Although the event-driven and\nsparse nature of SNNs show potential for more energy efficient computation than\nANNs, SNN neurons have internal states which evolve over time. Keeping track of\nSNN states can significantly increase data movement and storage requirements,\npotentially losing its advantages with respect to ANNs. This paper investigates\nthe energy effects of having neuron states, and how it is influenced by the\nchosen mapping to realistic hardware architectures with advanced memory\nhierarchies. Therefore, we develop STEMS, a mapping design space exploration\ntool for SNNs. STEMS models SNN's stateful behavior and explores intra-layer\nand inter-layer mapping optimizations to minimize data movement, considering\nboth spatial and temporal SNN dimensions. Using STEMS, we show up to 12x\nreduction in off-chip data movement and 5x reduction in energy (on top of\nintra-layer optimizations), on two event-based vision SNN benchmarks. Finally,\nneuron states may not be needed for all SNN layers. By optimizing neuron states\nfor one of our benchmarks, we show 20x reduction in neuron states and 1.4x\nbetter performance without accuracy loss.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.AR",
      "cs.DC"
    ],
    "primary_category": "cs.NE",
    "comment": "24 pages, 23 figures, under review at IEEE TC",
    "pdf_url": "http://arxiv.org/pdf/2502.03287v2",
    "published_date": "2025-02-05 15:44:15 UTC",
    "updated_date": "2025-02-17 12:36:38 UTC"
  },
  {
    "arxiv_id": "2502.06830v2",
    "title": "OrderFusion: Encoding Orderbook for End-to-End Probabilistic Intraday Electricity Price Prediction",
    "authors": [
      "Runyao Yu",
      "Yuchen Tao",
      "Fabian Leimgruber",
      "Tara Esterl",
      "Jochen L. Cremer"
    ],
    "abstract": "Accurate and reliable probabilistic prediction of intraday electricity prices\nis essential to manage market uncertainties and support robust trading\nstrategies. However, current methods rely heavily on domain feature extraction\nand fail to capture the dynamics between buy and sell orders, limiting the\nability to form rich representations of the orderbook. Furthermore, these\nmethods often require training separate models for different quantiles and\nintroduce additional procedures-such as post-hoc quantile sorting or loss-based\npenalties-to address the quantile crossing issue, where predicted upper\nquantiles fall below lower ones. These steps are either decoupled from model\ntraining or introduce extra tuning complexity. To address these challenges, we\npropose an encoding method called OrderFusion and design a hierarchical\nmulti-quantile head. OrderFusion encodes the orderbook into a 2.5D\nrepresentation and employs a tailored jump cross-attention to model buy-sell\ndynamics without the need for domain feature extraction. The multi-quantile\nhead anchors on the median quantile and hierarchically estimates other\nquantiles through constrained residuals, ensuring monotonicity without\npost-processing or additional tuning. We conduct extensive experiments and\nablation studies on three key price indices (ID1, ID2, and ID3) using three\nyears of orderbook data from the German and Austrian markets. The results\ndemonstrate that our approach provides an accurate, reliable, and unified\nend-to-end framework for probabilistic intraday price prediction.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.CP",
    "comment": "20 pages, 3 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.06830v2",
    "published_date": "2025-02-05 15:37:21 UTC",
    "updated_date": "2025-05-16 10:37:28 UTC"
  },
  {
    "arxiv_id": "2502.03283v2",
    "title": "SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs",
    "authors": [
      "Ben Liu",
      "Jihai Zhang",
      "Fangquan Lin",
      "Cheng Yang",
      "Min Peng",
      "Wotao Yin"
    ],
    "abstract": "Recent advancements have highlighted that Large Language Models (LLMs) are\nprone to hallucinations when solving complex reasoning problems, leading to\nerroneous results. To tackle this issue, researchers incorporate Knowledge\nGraphs (KGs) to improve the reasoning ability of LLMs. However, existing\nmethods face two limitations: 1) they typically assume that all answers to the\nquestions are contained in KGs, neglecting the incompleteness issue of KGs, and\n2) they treat the KG as a static repository and overlook the implicit logical\nreasoning structures inherent in KGs. In this paper, we introduce SymAgent, an\ninnovative neural-symbolic agent framework that achieves collaborative\naugmentation between KGs and LLMs. We conceptualize KGs as dynamic environments\nand transform complex reasoning tasks into a multi-step interactive process,\nenabling KGs to participate deeply in the reasoning process. SymAgent consists\nof two modules: Agent-Planner and Agent-Executor. The Agent-Planner leverages\nLLM's inductive reasoning capability to extract symbolic rules from KGs,\nguiding efficient question decomposition. The Agent-Executor autonomously\ninvokes predefined action tools to integrate information from KGs and external\ndocuments, addressing the issues of KG incompleteness. Furthermore, we design a\nself-learning framework comprising online exploration and offline iterative\npolicy updating phases, enabling the agent to automatically synthesize\nreasoning trajectories and improve performance. Experimental results\ndemonstrate that SymAgent with weak LLM backbones (i.e., 7B series) yields\nbetter or comparable performance compared to various strong baselines. Further\nanalysis reveals that our agent can identify missing triples, facilitating\nautomatic KG updates.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03283v2",
    "published_date": "2025-02-05 15:37:05 UTC",
    "updated_date": "2025-02-18 07:32:59 UTC"
  },
  {
    "arxiv_id": "2502.03275v1",
    "title": "Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning",
    "authors": [
      "DiJia Su",
      "Hanlin Zhu",
      "Yingchen Xu",
      "Jiantao Jiao",
      "Yuandong Tian",
      "Qinqing Zheng"
    ],
    "abstract": "Large Language Models (LLMs) excel at reasoning and planning when trained on\nchainof-thought (CoT) data, where the step-by-step thought process is\nexplicitly outlined by text tokens. However, this results in lengthy inputs\nwhere many words support textual coherence rather than core reasoning\ninformation, and processing these inputs consumes substantial computation\nresources. In this work, we propose a hybrid representation of the reasoning\nprocess, where we partially abstract away the initial reasoning steps using\nlatent discrete tokens generated by VQ-VAE, significantly reducing the length\nof reasoning traces. We explore the use of latent trace abstractions in two\nscenarios: 1) training the model from scratch for the Keys-Finding Maze\nproblem, 2) fine-tuning LLMs on this hybrid data with an extended vocabulary\nincluding unseen latent tokens, for both logical and mathematical reasoning\nproblems. To facilitate effective learning, we introduce a simple training\nprocedure that randomly mixes latent and text tokens, which enables fast\nadaptation to new latent tokens. Our approach consistently outperforms the\nbaselines methods in various benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03275v1",
    "published_date": "2025-02-05 15:33:00 UTC",
    "updated_date": "2025-02-05 15:33:00 UTC"
  },
  {
    "arxiv_id": "2502.05219v1",
    "title": "Enabling External Scrutiny of AI Systems with Privacy-Enhancing Technologies",
    "authors": [
      "Kendrea Beers",
      "Helen Toner"
    ],
    "abstract": "This article describes how technical infrastructure developed by the\nnonprofit OpenMined enables external scrutiny of AI systems without\ncompromising sensitive information.\n  Independent external scrutiny of AI systems provides crucial transparency\ninto AI development, so it should be an integral component of any approach to\nAI governance. In practice, external researchers have struggled to gain access\nto AI systems because of AI companies' legitimate concerns about security,\nprivacy, and intellectual property.\n  But now, privacy-enhancing technologies (PETs) have reached a new level of\nmaturity: end-to-end technical infrastructure developed by OpenMined combines\nseveral PETs into various setups that enable privacy-preserving audits of AI\nsystems. We showcase two case studies where this infrastructure has been\ndeployed in real-world governance scenarios: \"Understanding Social Media\nRecommendation Algorithms with the Christchurch Call\" and \"Evaluating Frontier\nModels with the UK AI Safety Institute.\" We describe types of scrutiny of AI\nsystems that could be facilitated by current setups and OpenMined's proposed\nfuture setups.\n  We conclude that these innovative approaches deserve further exploration and\nsupport from the AI governance community. Interested policymakers can focus on\nempowering researchers on a legal level.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05219v1",
    "published_date": "2025-02-05 15:31:11 UTC",
    "updated_date": "2025-02-05 15:31:11 UTC"
  },
  {
    "arxiv_id": "2502.03274v1",
    "title": "A Scalable Approach to Probabilistic Neuro-Symbolic Verification",
    "authors": [
      "Vasileios Manginas",
      "Nikolaos Manginas",
      "Edward Stevinson",
      "Sherwin Varghese",
      "Nikos Katzouris",
      "Georgios Paliouras",
      "Alessio Lomuscio"
    ],
    "abstract": "Neuro-Symbolic Artificial Intelligence (NeSy AI) has emerged as a promising\ndirection for integrating neural learning with symbolic reasoning. In the\nprobabilistic variant of such systems, a neural network first extracts a set of\nsymbols from sub-symbolic input, which are then used by a symbolic component to\nreason in a probabilistic manner towards answering a query. In this work, we\naddress the problem of formally verifying the robustness of such NeSy\nprobabilistic reasoning systems, therefore paving the way for their safe\ndeployment in critical domains. We analyze the complexity of solving this\nproblem exactly, and show that it is $\\mathrm{NP}^{\\# \\mathrm{P}}$-hard. To\novercome this issue, we propose the first approach for approximate,\nrelaxation-based verification of probabilistic NeSy systems. We demonstrate\nexperimentally that the proposed method scales exponentially better than\nsolver-based solutions and apply our technique to a real-world autonomous\ndriving dataset, where we verify a safety property under large input\ndimensionalities and network sizes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03274v1",
    "published_date": "2025-02-05 15:29:41 UTC",
    "updated_date": "2025-02-05 15:29:41 UTC"
  },
  {
    "arxiv_id": "2502.03272v2",
    "title": "Deep Learning Pipeline for Fully Automated Myocardial Infarct Segmentation from Clinical Cardiac MR Scans",
    "authors": [
      "Matthias Schwab",
      "Mathias Pamminger",
      "Christian Kremser",
      "Markus Haltmeier",
      "Agnes Mayr"
    ],
    "abstract": "Purpose: To develop and evaluate a deep learning-based method that allows to\nperform myocardial infarct segmentation in a fully-automated way.\n  Materials and Methods: For this retrospective study, a cascaded framework of\ntwo and three-dimensional convolutional neural networks (CNNs), specialized on\nidentifying ischemic myocardial scars on late gadolinium enhancement (LGE)\ncardiac magnetic resonance (CMR) images, was trained on an in-house training\ndataset consisting of 144 examinations. On a separate test dataset from the\nsame institution, including images from 152 examinations obtained between 2021\nand 2023, a quantitative comparison between artificial intelligence (AI)-based\nsegmentations and manual segmentations was performed. Further, qualitative\nassessment of segmentation accuracy was evaluated for both human and\nAI-generated contours by two CMR experts in a blinded experiment.\n  Results: Excellent agreement could be found between manually and\nautomatically calculated infarct volumes ($\\rho_c$ = 0.9). The qualitative\nevaluation showed that compared to human-based measurements, the experts rated\nthe AI-based segmentations to better represent the actual extent of infarction\nsignificantly (p < 0.001) more often (33.4% AI, 25.1% human, 41.5% equal). On\nthe contrary, for segmentation of microvascular obstruction (MVO), manual\nmeasurements were still preferred (11.3% AI, 55.6% human, 33.1% equal).\n  Conclusion: This fully-automated segmentation pipeline enables CMR infarct\nsize to be calculated in a very short time and without requiring any\npre-processing of the input images while matching the segmentation quality of\ntrained human observers. In a blinded experiment, experts preferred automated\ninfarct segmentations more often than manual segmentations, paving the way for\na potential clinical application.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03272v2",
    "published_date": "2025-02-05 15:29:28 UTC",
    "updated_date": "2025-03-19 10:42:32 UTC"
  },
  {
    "arxiv_id": "2502.03270v2",
    "title": "When Pre-trained Visual Representations Fall Short: Limitations in Visuo-Motor Robot Learning",
    "authors": [
      "Nikolaos Tsagkas",
      "Andreas Sochopoulos",
      "Duolikun Danier",
      "Sethu Vijayakumar",
      "Chris Xiaoxuan Lu",
      "Oisin Mac Aodha"
    ],
    "abstract": "The integration of pre-trained visual representations (PVRs) into visuo-motor\nrobot learning has emerged as a promising alternative to training visual\nencoders from scratch. However, PVRs face critical challenges in the context of\npolicy learning, including temporal entanglement and an inability to generalise\neven in the presence of minor scene perturbations. These limitations hinder\nperformance in tasks requiring temporal awareness and robustness to scene\nchanges. This work identifies these shortcomings and proposes solutions to\naddress them. First, we augment PVR features with temporal perception and a\nsense of task completion, effectively disentangling them in time. Second, we\nintroduce a module that learns to selectively attend to task-relevant local\nfeatures, enhancing robustness when evaluated on out-of-distribution scenes.\nOur experiments demonstrate significant performance improvements, particularly\nin PVRs trained with masking objectives, and validate the effectiveness of our\nenhancements in addressing PVR-specific limitations.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project Page: https://tsagkas.github.io/pvrobo/",
    "pdf_url": "http://arxiv.org/pdf/2502.03270v2",
    "published_date": "2025-02-05 15:25:46 UTC",
    "updated_date": "2025-05-05 09:42:27 UTC"
  },
  {
    "arxiv_id": "2502.03238v2",
    "title": "Long-tailed Medical Diagnosis with Relation-aware Representation Learning and Iterative Classifier Calibration",
    "authors": [
      "Li Pan",
      "Yupei Zhang",
      "Qiushi Yang",
      "Tan Li",
      "Zhen Chen"
    ],
    "abstract": "Recently computer-aided diagnosis has demonstrated promising performance,\neffectively alleviating the workload of clinicians. However, the inherent\nsample imbalance among different diseases leads algorithms biased to the\nmajority categories, leading to poor performance for rare categories. Existing\nworks formulated this challenge as a long-tailed problem and attempted to\ntackle it by decoupling the feature representation and classification. Yet, due\nto the imbalanced distribution and limited samples from tail classes, these\nworks are prone to biased representation learning and insufficient classifier\ncalibration. To tackle these problems, we propose a new Long-tailed Medical\nDiagnosis (LMD) framework for balanced medical image classification on\nlong-tailed datasets. In the initial stage, we develop a Relation-aware\nRepresentation Learning (RRL) scheme to boost the representation ability by\nencouraging the encoder to capture intrinsic semantic features through\ndifferent data augmentations. In the subsequent stage, we propose an Iterative\nClassifier Calibration (ICC) scheme to calibrate the classifier iteratively.\nThis is achieved by generating a large number of balanced virtual features and\nfine-tuning the encoder using an Expectation-Maximization manner. The proposed\nICC compensates for minority categories to facilitate unbiased classifier\noptimization while maintaining the diagnostic knowledge in majority classes.\nComprehensive experiments on three public long-tailed medical datasets\ndemonstrate that our LMD framework significantly surpasses state-of-the-art\napproaches. The source code can be accessed at\nhttps://github.com/peterlipan/LMD.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been accepted in Computers in Biology and Medicine",
    "pdf_url": "http://arxiv.org/pdf/2502.03238v2",
    "published_date": "2025-02-05 14:57:23 UTC",
    "updated_date": "2025-02-07 18:37:47 UTC"
  },
  {
    "arxiv_id": "2502.03231v1",
    "title": "The Other Side of the Coin: Unveiling the Downsides of Model Aggregation in Federated Learning from a Layer-peeled Perspective",
    "authors": [
      "Guogang Zhu",
      "Xuefeng Liu",
      "Jianwei Niu",
      "Shaojie Tang",
      "Xinghao Wu"
    ],
    "abstract": "In federated learning (FL), model aggregation is a critical step by which\nmultiple clients share their knowledge with one another. However, it is also\nwidely recognized that the aggregated model, when sent back to each client,\nperforms poorly on local data until after several rounds of local training.\nThis temporary performance drop can potentially slow down the convergence of\nthe FL model. Most research in FL regards this performance drop as an inherent\ncost of knowledge sharing among clients and does not give it special attention.\nWhile some studies directly focus on designing techniques to alleviate the\nissue, an in-depth investigation of the reasons behind this performance drop\nhas yet to be conducted.To address this gap, we conduct a layer-peeled analysis\nof model aggregation across various datasets and model architectures. Our\nfindings reveal that the performance drop can be attributed to two major\nconsequences of the aggregation process: (1) it disrupts feature variability\nsuppression in deep neural networks (DNNs), and (2) it weakens the coupling\nbetween features and subsequent parameters.Based on these findings, we propose\nseveral simple yet effective strategies to mitigate the negative impacts of\nmodel aggregation while still enjoying the benefit it brings. To the best of\nour knowledge, our work is the first to conduct a layer-peeled analysis of\nmodel aggregation, potentially paving the way for the development of more\neffective FL algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03231v1",
    "published_date": "2025-02-05 14:45:56 UTC",
    "updated_date": "2025-02-05 14:45:56 UTC"
  },
  {
    "arxiv_id": "2502.03214v1",
    "title": "iVISPAR -- An Interactive Visual-Spatial Reasoning Benchmark for VLMs",
    "authors": [
      "Julius Mayer",
      "Mohamad Ballout",
      "Serwan Jassim",
      "Farbod Nosrat Nezami",
      "Elia Bruni"
    ],
    "abstract": "Vision-Language Models (VLMs) are known to struggle with spatial reasoning\nand visual alignment. To help overcome these limitations, we introduce iVISPAR,\nan interactive multi-modal benchmark designed to evaluate the spatial reasoning\ncapabilities of VLMs acting as agents. iVISPAR is based on a variant of the\nsliding tile puzzle-a classic problem that demands logical planning, spatial\nawareness, and multi-step reasoning. The benchmark supports visual 2D, 3D, and\ntext-based input modalities, enabling comprehensive assessments of VLMs'\nplanning and reasoning skills. We evaluate a broad suite of state-of-the-art\nopen-source and closed-source VLMs, comparing their performance while also\nproviding optimal path solutions and a human baseline to assess the task's\ncomplexity and feasibility for humans. Results indicate that while some VLMs\nperform well on simple spatial tasks, they encounter difficulties with more\ncomplex configurations and problem properties. Notably, while VLMs generally\nperform better in 2D vision compared to 3D or text-based representations, they\nconsistently fall short of human performance, illustrating the persistent\nchallenge of visual alignment. This highlights critical gaps in current VLM\ncapabilities, highlighting their limitations in achieving human-level\ncognition.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03214v1",
    "published_date": "2025-02-05 14:29:01 UTC",
    "updated_date": "2025-02-05 14:29:01 UTC"
  },
  {
    "arxiv_id": "2502.18474v1",
    "title": "A Contemporary Survey of Large Language Model Assisted Program Analysis",
    "authors": [
      "Jiayimei Wang",
      "Tao Ni",
      "Wei-Bin Lee",
      "Qingchuan Zhao"
    ],
    "abstract": "The increasing complexity of software systems has driven significant\nadvancements in program analysis, as traditional methods unable to meet the\ndemands of modern software development. To address these limitations, deep\nlearning techniques, particularly Large Language Models (LLMs), have gained\nattention due to their context-aware capabilities in code comprehension.\nRecognizing the potential of LLMs, researchers have extensively explored their\napplication in program analysis since their introduction. Despite existing\nsurveys on LLM applications in cybersecurity, comprehensive reviews\nspecifically addressing their role in program analysis remain scarce. In this\nsurvey, we systematically review the application of LLMs in program analysis,\ncategorizing the existing work into static analysis, dynamic analysis, and\nhybrid approaches. Moreover, by examining and synthesizing recent studies, we\nidentify future directions and challenges in the field. This survey aims to\ndemonstrate the potential of LLMs in advancing program analysis practices and\noffer actionable insights for security researchers seeking to enhance detection\nframeworks or develop domain-specific models.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18474v1",
    "published_date": "2025-02-05 14:27:17 UTC",
    "updated_date": "2025-02-05 14:27:17 UTC"
  },
  {
    "arxiv_id": "2502.03206v3",
    "title": "A Unified and General Humanoid Whole-Body Controller for Versatile Locomotion",
    "authors": [
      "Yufei Xue",
      "Wentao Dong",
      "Minghuan Liu",
      "Weinan Zhang",
      "Jiangmiao Pang"
    ],
    "abstract": "Locomotion is a fundamental skill for humanoid robots. However, most existing\nworks make locomotion a single, tedious, unextendable, and unconstrained\nmovement. This limits the kinematic capabilities of humanoid robots. In\ncontrast, humans possess versatile athletic abilities-running, jumping,\nhopping, and finely adjusting gait parameters such as frequency and foot\nheight. In this paper, we investigate solutions to bring such versatility into\nhumanoid locomotion and thereby propose HugWBC: a unified and general humanoid\nwhole-body controller for versatile locomotion. By designing a general command\nspace in the aspect of tasks and behaviors, along with advanced techniques like\nsymmetrical loss and intervention training for learning a whole-body humanoid\ncontrolling policy in simulation, HugWBC enables real-world humanoid robots to\nproduce various natural gaits, including walking, jumping, standing, and\nhopping, with customizable parameters such as frequency, foot swing height,\nfurther combined with different body height, waist rotation, and body pitch.\nBeyond locomotion, HugWBC also supports real-time interventions from external\nupper-body controllers like teleoperation, enabling loco-manipulation with\nprecision under any locomotive behavior. Extensive experiments validate the\nhigh tracking accuracy and robustness of HugWBC with/without upper-body\nintervention for all commands, and we further provide an in-depth analysis of\nhow the various commands affect humanoid movement and offer insights into the\nrelationships between these commands. To our knowledge, HugWBC is the first\nhumanoid whole-body controller that supports such versatile locomotion\nbehaviors with high robustness and flexibility.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Published at RSS 2025. The first two authors contribute equally.\n  Project page: https://hugwbc.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2502.03206v3",
    "published_date": "2025-02-05 14:26:01 UTC",
    "updated_date": "2025-04-12 14:15:59 UTC"
  },
  {
    "arxiv_id": "2502.03200v1",
    "title": "CORTEX: A Cost-Sensitive Rule and Tree Extraction Method",
    "authors": [
      "Marija Kopanja",
      "Miloš Savić",
      "Luca Longo"
    ],
    "abstract": "Tree-based and rule-based machine learning models play pivotal roles in\nexplainable artificial intelligence (XAI) due to their unique ability to\nprovide explanations in the form of tree or rule sets that are easily\nunderstandable and interpretable, making them essential for applications in\nwhich trust in model decisions is necessary. These transparent models are\ntypically used in surrogate modeling, a post-hoc XAI approach for explaining\nthe logic of black-box models, enabling users to comprehend and trust complex\npredictive systems while maintaining competitive performance. This study\nproposes the Cost-Sensitive Rule and Tree Extraction (CORTEX) method, a novel\nrule-based XAI algorithm grounded in the multi-class cost-sensitive decision\ntree (CSDT) method. The original version of the CSDT is extended to\nclassification problems with more than two classes by inducing the concept of\nan n-dimensional class-dependent cost matrix. The performance of CORTEX as a\nrule-extractor XAI method is compared to other post-hoc tree and rule\nextraction methods across several datasets with different numbers of classes.\nSeveral quantitative evaluation metrics are employed to assess the\nexplainability of generated rule sets. Our findings demonstrate that CORTEX is\ncompetitive with other tree-based methods and can be superior to other\nrule-based methods across different datasets. The extracted rule sets suggest\nthe advantages of using the CORTEX method over other methods by producing\nsmaller rule sets with shorter rules on average across datasets with a diverse\nnumber of classes. Overall, the results underscore the potential of CORTEX as a\npowerful XAI tool for scenarios that require the generation of clear,\nhuman-understandable rules while maintaining good predictive performance.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03200v1",
    "published_date": "2025-02-05 14:20:34 UTC",
    "updated_date": "2025-02-05 14:20:34 UTC"
  },
  {
    "arxiv_id": "2502.03199v1",
    "title": "Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large Language Models",
    "authors": [
      "Jialiang Wu",
      "Yi Shen",
      "Sijia Liu",
      "Yi Tang",
      "Sen Song",
      "Xiaoyi Wang",
      "Longjun Cai"
    ],
    "abstract": "Despite their impressive capacities, Large language models (LLMs) often\nstruggle with the hallucination issue of generating inaccurate or fabricated\ncontent even when they possess correct knowledge. In this paper, we extend the\nexploration of the correlation between hidden-state prediction changes and\noutput factuality into a deeper, token-wise level. Based on the insights , we\npropose cross-layer Entropy eNhanced Decoding (END), a decoding method that\nmitigates hallucinations without requiring extra training. END leverages inner\nprobability changes across layers to individually quantify the factual\nknowledge required for each candidate token, and adjusts the final predicting\ndistribution to prioritize tokens with higher factuality. Experiments on both\nhallucination and QA benchmarks demonstrate that END significantly enhances the\ntruthfulness and informativeness of generated content while maintaining robust\nQA accuracy. Moreover, our work provides a deeper perspective on understanding\nthe correlations between inherent knowledge and output factuality.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2502.03199v1",
    "published_date": "2025-02-05 14:19:52 UTC",
    "updated_date": "2025-02-05 14:19:52 UTC"
  },
  {
    "arxiv_id": "2502.15734v1",
    "title": "Cache-Craft: Managing Chunk-Caches for Efficient Retrieval-Augmented Generation",
    "authors": [
      "Shubham Agarwal",
      "Sai Sundaresan",
      "Subrata Mitra",
      "Debabrata Mahapatra",
      "Archit Gupta",
      "Rounak Sharma",
      "Nirmal Joshua Kapu",
      "Tong Yu",
      "Shiv Saini"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) is often used with Large Language Models\n(LLMs) to infuse domain knowledge or user-specific information. In RAG, given a\nuser query, a retriever extracts chunks of relevant text from a knowledge base.\nThese chunks are sent to an LLM as part of the input prompt. Typically, any\ngiven chunk is repeatedly retrieved across user questions. However, currently,\nfor every question, attention-layers in LLMs fully compute the key values (KVs)\nrepeatedly for the input chunks, as state-of-the-art methods cannot reuse\nKV-caches when chunks appear at arbitrary locations with arbitrary contexts.\nNaive reuse leads to output quality degradation. This leads to potentially\nredundant computations on expensive GPUs and increases latency. In this work,\nwe propose Cache-Craft, a system for managing and reusing precomputed KVs\ncorresponding to the text chunks (we call chunk-caches) in RAG-based systems.\nWe present how to identify chunk-caches that are reusable, how to efficiently\nperform a small fraction of recomputation to fix the cache to maintain output\nquality, and how to efficiently store and evict chunk-caches in the hardware\nfor maximizing reuse while masking any overheads. With real production\nworkloads as well as synthetic datasets, we show that Cache-Craft reduces\nredundant computation by 51% over SOTA prefix-caching and 75% over full\nrecomputation. Additionally, with continuous batching on a real production\nworkload, we get a 1.6X speed up in throughput and a 2X reduction in end-to-end\nresponse latency over prefix-caching while maintaining quality, for both the\nLLaMA-3-8B and LLaMA-3-70B models.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.OS"
    ],
    "primary_category": "cs.DC",
    "comment": "Accepted at SIGMOD 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.15734v1",
    "published_date": "2025-02-05 14:12:33 UTC",
    "updated_date": "2025-02-05 14:12:33 UTC"
  },
  {
    "arxiv_id": "2502.03188v1",
    "title": "EuskañolDS: A Naturally Sourced Corpus for Basque-Spanish Code-Switching",
    "authors": [
      "Maite Heredia",
      "Jeremy Barnes",
      "Aitor Soroa"
    ],
    "abstract": "Code-switching (CS) remains a significant challenge in Natural Language\nProcessing (NLP), mainly due a lack of relevant data. In the context of the\ncontact between the Basque and Spanish languages in the north of the Iberian\nPeninsula, CS frequently occurs in both formal and informal spontaneous\ninteractions. However, resources to analyse this phenomenon and support the\ndevelopment and evaluation of models capable of understanding and generating\ncode-switched language for this language pair are almost non-existent. We\nintroduce a first approach to develop a naturally sourced corpus for\nBasque-Spanish code-switching. Our methodology consists of identifying CS texts\nfrom previously available corpora using language identification models, which\nare then manually validated to obtain a reliable subset of CS instances. We\npresent the properties of our corpus and make it available under the name\nEuska\\~nolDS.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03188v1",
    "published_date": "2025-02-05 14:04:42 UTC",
    "updated_date": "2025-02-05 14:04:42 UTC"
  },
  {
    "arxiv_id": "2502.06829v2",
    "title": "Convolution-Based Converter : A Weak-Prior Approach For Modeling Stochastic Processes Based On Conditional Density Estimation",
    "authors": [
      "Chaoran Pang",
      "Lin Wang",
      "Shuangrong Liu",
      "Shikun Tian",
      "WenHao Yue",
      "Xingshen Zhang",
      "Bo Yang"
    ],
    "abstract": "In this paper, a Convolution-Based Converter (CBC) is proposed to develop a\nmethodology for removing the strong or fixed priors in estimating the\nprobability distribution of targets based on observations in the stochastic\nprocess. Traditional approaches, e.g., Markov-based and Gaussian process-based\nmethods, typically leverage observations to estimate targets based on strong or\nfixed priors (such as Markov properties or Gaussian prior). However, the\neffectiveness of these methods depends on how well their prior assumptions\nalign with the characteristics of the problem. When the assumed priors are not\nsatisfied, these approaches may perform poorly or even become unusable. To\novercome the above limitation, we introduce the Convolution-Based converter\n(CBC), which implicitly estimates the conditional probability distribution of\ntargets without strong or fixed priors, and directly outputs the expected\ntrajectory of the stochastic process that satisfies the constraints from\nobservations. This approach reduces the dependence on priors, enhancing\nflexibility and adaptability in modeling stochastic processes when addressing\ndifferent problems. Experimental results demonstrate that our method\noutperforms existing baselines across multiple metrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06829v2",
    "published_date": "2025-02-05 13:59:34 UTC",
    "updated_date": "2025-04-03 15:41:46 UTC"
  },
  {
    "arxiv_id": "2502.03508v1",
    "title": "Elucidation of the Concept of Consciousness from the Theory of Non-Human Communication Agents",
    "authors": [
      "Julian Tagnin"
    ],
    "abstract": "This article focuses on elucidating the concept of consciousness from a\nrelational and post-phenomenological theory of non-human communication agents\n(ANHC). Specifically, we explore the contributions of Thomas Metzinger s Self\nModel Theory, Katherine Hayles conceptualizations of non-conscious cognitive\nprocesses centered on knowledge processing phenomena shared between biological\nand technical systems and Lenore and Manuel Blum s theoretical perspective on\ncomputation, which defines consciousness as an emergent phenomenon of complex\ncomputational systems, arising from the appropriate organization of their\ninorganic materiality. Building on interactions with non-human cognitive\nagents, among other factors, the explainability of sociotechnical systems\nchallenges the humanistic common sense of modern philosophy and science. This\ncritical integration of various approaches ultimately questions other concepts\nassociated with consciousness, such as autonomy, freedom, and mutual\nresponsibility. The aim is to contribute to a necessary discussion for\ndesigning new frameworks of understanding that pave the way toward an ethical\nand pragmatic approach to addressing contemporary challenges in the design,\nregulation, and interaction with ANHC. Such frameworks, in turn, enable a more\ninclusive and relational understanding of agency in an interconnected world.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "q-bio.NC",
    "comment": "Version febrero 2025, originalmente escrito en diciembre de 2024",
    "pdf_url": "http://arxiv.org/pdf/2502.03508v1",
    "published_date": "2025-02-05 13:58:23 UTC",
    "updated_date": "2025-02-05 13:58:23 UTC"
  },
  {
    "arxiv_id": "2502.03147v1",
    "title": "Scalable In-Context Learning on Tabular Data via Retrieval-Augmented Large Language Models",
    "authors": [
      "Xumeng Wen",
      "Shun Zheng",
      "Zhen Xu",
      "Yiming Sun",
      "Jiang Bian"
    ],
    "abstract": "Recent studies have shown that large language models (LLMs), when customized\nwith post-training on tabular data, can acquire general tabular in-context\nlearning (TabICL) capabilities. These models are able to transfer effectively\nacross diverse data schemas and different task domains. However, existing\nLLM-based TabICL approaches are constrained to few-shot scenarios due to the\nsequence length limitations of LLMs, as tabular instances represented in plain\ntext consume substantial tokens. To address this limitation and enable scalable\nTabICL for any data size, we propose retrieval-augmented LLMs tailored to\ntabular data. Our approach incorporates a customized retrieval module, combined\nwith retrieval-guided instruction-tuning for LLMs. This enables LLMs to\neffectively leverage larger datasets, achieving significantly improved\nperformance across 69 widely recognized datasets and demonstrating promising\nscaling behavior. Extensive comparisons with state-of-the-art tabular models\nreveal that, while LLM-based TabICL still lags behind well-tuned numeric models\nin overall performance, it uncovers powerful algorithms under limited contexts,\nenhances ensemble diversity, and excels on specific datasets. These unique\nproperties underscore the potential of language as a universal and accessible\ninterface for scalable tabular data learning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2502.03147v1",
    "published_date": "2025-02-05 13:16:41 UTC",
    "updated_date": "2025-02-05 13:16:41 UTC"
  },
  {
    "arxiv_id": "2502.06828v1",
    "title": "Fine-Tuning Strategies for Continual Online EEG Motor Imagery Decoding: Insights from a Large-Scale Longitudinal Study",
    "authors": [
      "Martin Wimpff",
      "Bruno Aristimunha",
      "Sylvain Chevallier",
      "Bin Yang"
    ],
    "abstract": "This study investigates continual fine-tuning strategies for deep learning in\nonline longitudinal electroencephalography (EEG) motor imagery (MI) decoding\nwithin a causal setting involving a large user group and multiple sessions per\nparticipant. We are the first to explore such strategies across a large user\ngroup, as longitudinal adaptation is typically studied in the single-subject\nsetting with a single adaptation strategy, which limits the ability to\ngeneralize findings. First, we examine the impact of different fine-tuning\napproaches on decoder performance and stability. Building on this, we integrate\nonline test-time adaptation (OTTA) to adapt the model during deployment,\ncomplementing the effects of prior fine-tuning. Our findings demonstrate that\nfine-tuning that successively builds on prior subject-specific information\nimproves both performance and stability, while OTTA effectively adapts the\nmodel to evolving data distributions across consecutive sessions, enabling\ncalibration-free operation. These results offer valuable insights and\nrecommendations for future research in longitudinal online MI decoding and\nhighlight the importance of combining domain adaptation strategies for\nimproving BCI performance in real-world applications. Clinical Relevance: Our\ninvestigation enables more stable and efficient long-term motor imagery\ndecoding, which is critical for neurorehabilitation and assistive technologies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06828v1",
    "published_date": "2025-02-05 12:57:53 UTC",
    "updated_date": "2025-02-05 12:57:53 UTC"
  },
  {
    "arxiv_id": "2502.03134v1",
    "title": "Gotham Dataset 2025: A Reproducible Large-Scale IoT Network Dataset for Intrusion Detection and Security Research",
    "authors": [
      "Othmane Belarbi",
      "Theodoros Spyridopoulos",
      "Eirini Anthi",
      "Omer Rana",
      "Pietro Carnelli",
      "Aftab Khan"
    ],
    "abstract": "In this paper, a dataset of IoT network traffic is presented. Our dataset was\ngenerated by utilising the Gotham testbed, an emulated large-scale Internet of\nThings (IoT) network designed to provide a realistic and heterogeneous\nenvironment for network security research. The testbed includes 78 emulated IoT\ndevices operating on various protocols, including MQTT, CoAP, and RTSP. Network\ntraffic was captured in Packet Capture (PCAP) format using tcpdump, and both\nbenign and malicious traffic were recorded. Malicious traffic was generated\nthrough scripted attacks, covering a variety of attack types, such as Denial of\nService (DoS), Telnet Brute Force, Network Scanning, CoAP Amplification, and\nvarious stages of Command and Control (C&C) communication. The data were\nsubsequently processed in Python for feature extraction using the Tshark tool,\nand the resulting data was converted to Comma Separated Values (CSV) format and\nlabelled. The data repository includes the raw network traffic in PCAP format\nand the processed labelled data in CSV format. Our dataset was collected in a\ndistributed manner, where network traffic was captured separately for each IoT\ndevice at the interface between the IoT gateway and the device. Our dataset was\ncollected in a distributed manner, where network traffic was separately\ncaptured for each IoT device at the interface between the IoT gateway and the\ndevice. With its diverse traffic patterns and attack scenarios, this dataset\nprovides a valuable resource for developing Intrusion Detection Systems and\nsecurity mechanisms tailored to complex, large-scale IoT environments. The\ndataset is publicly available at Zenodo.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "16 pages, 7 figures, 4 tables. Submitted at the Data in Brief journal",
    "pdf_url": "http://arxiv.org/pdf/2502.03134v1",
    "published_date": "2025-02-05 12:51:18 UTC",
    "updated_date": "2025-02-05 12:51:18 UTC"
  },
  {
    "arxiv_id": "2502.05218v1",
    "title": "FactorGCL: A Hypergraph-Based Factor Model with Temporal Residual Contrastive Learning for Stock Returns Prediction",
    "authors": [
      "Yitong Duan",
      "Weiran Wang",
      "Jian Li"
    ],
    "abstract": "As a fundamental method in economics and finance, the factor model has been\nextensively utilized in quantitative investment. In recent years, there has\nbeen a paradigm shift from traditional linear models with expert-designed\nfactors to more flexible nonlinear machine learning-based models with\ndata-driven factors, aiming to enhance the effectiveness of these factor\nmodels. However, due to the low signal-to-noise ratio in market data, mining\neffective factors in data-driven models remains challenging. In this work, we\npropose a hypergraph-based factor model with temporal residual contrastive\nlearning (FactorGCL) that employs a hypergraph structure to better capture\nhigh-order nonlinear relationships among stock returns and factors. To mine\nhidden factors that supplement human-designed prior factors for predicting\nstock returns, we design a cascading residual hypergraph architecture, in which\nthe hidden factors are extracted from the residual information after removing\nthe influence of prior factors. Additionally, we propose a temporal residual\ncontrastive learning method to guide the extraction of effective and\ncomprehensive hidden factors by contrasting stock-specific residual information\nover different time periods. Our extensive experiments on real stock market\ndata demonstrate that FactorGCL not only outperforms existing state-of-the-art\nmethods but also mines effective hidden factors for predicting stock returns.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.ST",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05218v1",
    "published_date": "2025-02-05 12:37:15 UTC",
    "updated_date": "2025-02-05 12:37:15 UTC"
  },
  {
    "arxiv_id": "2502.03128v1",
    "title": "Metis: A Foundation Speech Generation Model with Masked Generative Pre-training",
    "authors": [
      "Yuancheng Wang",
      "Jiachen Zheng",
      "Junan Zhang",
      "Xueyao Zhang",
      "Huan Liao",
      "Zhizheng Wu"
    ],
    "abstract": "We introduce Metis, a foundation model for unified speech generation. Unlike\nprevious task-specific or multi-task models, Metis follows a pre-training and\nfine-tuning paradigm. It is pre-trained on large-scale unlabeled speech data\nusing masked generative modeling and then fine-tuned to adapt to diverse speech\ngeneration tasks. Specifically, 1) Metis utilizes two discrete speech\nrepresentations: SSL tokens derived from speech self-supervised learning (SSL)\nfeatures, and acoustic tokens directly quantized from waveforms. 2) Metis\nperforms masked generative pre-training on SSL tokens, utilizing 300K hours of\ndiverse speech data, without any additional condition. 3) Through fine-tuning\nwith task-specific conditions, Metis achieves efficient adaptation to various\nspeech generation tasks while supporting multimodal input, even when using\nlimited data and trainable parameters. Experiments demonstrate that Metis can\nserve as a foundation model for unified speech generation: Metis outperforms\nstate-of-the-art task-specific or multi-task systems across five speech\ngeneration tasks, including zero-shot text-to-speech, voice conversion, target\nspeaker extraction, speech enhancement, and lip-to-speech, even with fewer than\n20M trainable parameters or 300 times less training data. Audio samples are are\navailable at https://metis-demo.github.io/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03128v1",
    "published_date": "2025-02-05 12:36:21 UTC",
    "updated_date": "2025-02-05 12:36:21 UTC"
  },
  {
    "arxiv_id": "2502.03123v2",
    "title": "Disentanglement in Difference: Directly Learning Semantically Disentangled Representations by Maximizing Inter-Factor Differences",
    "authors": [
      "Xingshen Zhang",
      "Lin Wang",
      "Shuangrong Liu",
      "Xintao Lu",
      "Chaoran Pang",
      "Bo Yang"
    ],
    "abstract": "In this study, Disentanglement in Difference(DiD) is proposed to address the\ninherent inconsistency between the statistical independence of latent variables\nand the goal of semantic disentanglement in disentanglement representation\nlearning. Conventional disentanglement methods achieve disentanglement\nrepresentation by improving statistical independence among latent variables.\nHowever, the statistical independence of latent variables does not necessarily\nimply that they are semantically unrelated, thus, improving statistical\nindependence does not always enhance disentanglement performance. To address\nthe above issue, DiD is proposed to directly learn semantic differences rather\nthan the statistical independence of latent variables. In the DiD, a Difference\nEncoder is designed to measure the semantic differences; a contrastive loss\nfunction is established to facilitate inter-dimensional comparison. Both of\nthem allow the model to directly differentiate and disentangle distinct\nsemantic factors, thereby resolving the inconsistency between statistical\nindependence and semantic disentanglement. Experimental results on the dSprites\nand 3DShapes datasets demonstrate that the proposed DiD outperforms existing\nmainstream methods across various disentanglement metrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03123v2",
    "published_date": "2025-02-05 12:30:41 UTC",
    "updated_date": "2025-04-03 15:28:18 UTC"
  },
  {
    "arxiv_id": "2502.03120v2",
    "title": "At the Mahakumbh, Faith Met Tragedy: Computational Analysis of Stampede Patterns Using Machine Learning and NLP",
    "authors": [
      "Abhinav Pratap"
    ],
    "abstract": "This study employs machine learning, historical analysis, and natural\nlanguage processing (NLP) to examine recurring lethal stampedes at Indias mass\nreligious gatherings, focusing on the 2025 Mahakumbh tragedy in Prayagraj (48+\ndeaths) and its 1954 predecessor (700+ casualties). Through computational\nmodeling of crowd dynamics and administrative records, it investigates how\nsystemic vulnerabilities contribute to these disasters. Temporal trend analysis\nidentifies persistent choke points, with narrow riverbank access routes linked\nto 92% of past stampede sites and lethal crowd densities recurring during\nspiritually significant moments like Mauni Amavasya. NLP analysis of seven\ndecades of inquiry reports reveals cyclical administrative failures, where VIP\nroute prioritization diverted safety resources in both 1954 and 2025,\nexacerbating fatalities. Statistical modeling demonstrates how ritual urgency\noverrides risk perception, leading to panic propagation patterns that mirror\nhistorical incidents. Findings support the Institutional Amnesia Theory,\nhighlighting how disaster responses remain reactionary rather than preventive.\nBy correlating archival patterns with computational crowd behavior analysis,\nthis study frames stampedes as a collision of infrastructure limitations, socio\nspiritual urgency, and governance inertia, challenging disaster discourse to\naddress how spiritual economies normalize preventable mortality.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 4 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.03120v2",
    "published_date": "2025-02-05 12:27:29 UTC",
    "updated_date": "2025-02-24 02:36:53 UTC"
  },
  {
    "arxiv_id": "2502.03118v1",
    "title": "Tell2Reg: Establishing spatial correspondence between images by the same language prompts",
    "authors": [
      "Wen Yan",
      "Qianye Yang",
      "Shiqi Huang",
      "Yipei Wang",
      "Shonit Punwani",
      "Mark Emberton",
      "Vasilis Stavrinides",
      "Yipeng Hu",
      "Dean Barratt"
    ],
    "abstract": "Spatial correspondence can be represented by pairs of segmented regions, such\nthat the image registration networks aim to segment corresponding regions\nrather than predicting displacement fields or transformation parameters. In\nthis work, we show that such a corresponding region pair can be predicted by\nthe same language prompt on two different images using the pre-trained large\nmultimodal models based on GroundingDINO and SAM. This enables a fully\nautomated and training-free registration algorithm, potentially generalisable\nto a wide range of image registration tasks. In this paper, we present\nexperimental results using one of the challenging tasks, registering\ninter-subject prostate MR images, which involves both highly variable intensity\nand morphology between patients. Tell2Reg is training-free, eliminating the\nneed for costly and time-consuming data curation and labelling that was\npreviously required for this registration task. This approach outperforms\nunsupervised learning-based registration methods tested, and has a performance\ncomparable to weakly-supervised methods. Additional qualitative results are\nalso presented to suggest that, for the first time, there is a potential\ncorrelation between language semantics and spatial correspondence, including\nthe spatial invariance in language-prompted regions and the difference in\nlanguage prompts between the obtained local and global correspondences. Code is\navailable at https://github.com/yanwenCi/Tell2Reg.git.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV",
      "00B25",
      "I.2.7"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 3 figures, conference paper",
    "pdf_url": "http://arxiv.org/pdf/2502.03118v1",
    "published_date": "2025-02-05 12:25:02 UTC",
    "updated_date": "2025-02-05 12:25:02 UTC"
  },
  {
    "arxiv_id": "2502.03111v1",
    "title": "Policies and Evaluation for Online Meeting Summarization",
    "authors": [
      "Felix Schneider",
      "Marco Turchi",
      "Alex Waibel"
    ],
    "abstract": "With more and more meetings moving to a digital domain, meeting summarization\nhas recently gained interest in both academic and commercial research. However,\nprior academic research focuses on meeting summarization as an offline task,\nperformed after the meeting concludes. In this paper, we perform the first\nsystematic study of online meeting summarization. For this purpose, we propose\nseveral policies for conducting online summarization. We discuss the unique\nchallenges of this task compared to the offline setting and define novel\nmetrics to evaluate latency and partial summary quality. The experiments on the\nAutoMin dataset show that 1) online models can produce strong summaries, 2) our\nmetrics allow a detailed analysis of different systems' quality-latency\ntrade-off, also taking into account intermediate outputs and 3) adaptive\npolicies perform better than fixed scheduled ones. These findings provide a\nstarting point for the wider research community to explore this important task.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2502.03111v1",
    "published_date": "2025-02-05 12:15:00 UTC",
    "updated_date": "2025-02-05 12:15:00 UTC"
  },
  {
    "arxiv_id": "2502.06827v1",
    "title": "Learning to Synthesize Compatible Fashion Items Using Semantic Alignment and Collocation Classification: An Outfit Generation Framework",
    "authors": [
      "Dongliang Zhou",
      "Haijun Zhang",
      "Kai Yang",
      "Linlin Liu",
      "Han Yan",
      "Xiaofei Xu",
      "Zhao Zhang",
      "Shuicheng Yan"
    ],
    "abstract": "The field of fashion compatibility learning has attracted great attention\nfrom both the academic and industrial communities in recent years. Many studies\nhave been carried out for fashion compatibility prediction, collocated outfit\nrecommendation, artificial intelligence (AI)-enabled compatible fashion design,\nand related topics. In particular, AI-enabled compatible fashion design can be\nused to synthesize compatible fashion items or outfits in order to improve the\ndesign experience for designers or the efficacy of recommendations for\ncustomers. However, previous generative models for collocated fashion synthesis\nhave generally focused on the image-to-image translation between fashion items\nof upper and lower clothing. In this paper, we propose a novel outfit\ngeneration framework, i.e., OutfitGAN, with the aim of synthesizing a set of\ncomplementary items to compose an entire outfit, given one extant fashion item\nand reference masks of target synthesized items. OutfitGAN includes a semantic\nalignment module, which is responsible for characterizing the mapping\ncorrespondence between the existing fashion items and the synthesized ones, to\nimprove the quality of the synthesized images, and a collocation classification\nmodule, which is used to improve the compatibility of a synthesized outfit. In\norder to evaluate the performance of our proposed models, we built a\nlarge-scale dataset consisting of 20,000 fashion outfits. Extensive\nexperimental results on this dataset show that our OutfitGAN can synthesize\nphoto-realistic outfits and outperform state-of-the-art methods in terms of\nsimilarity, authenticity and compatibility measurements.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper was accepted by IEEE TNNLS",
    "pdf_url": "http://arxiv.org/pdf/2502.06827v1",
    "published_date": "2025-02-05 12:13:53 UTC",
    "updated_date": "2025-02-05 12:13:53 UTC"
  },
  {
    "arxiv_id": "2502.06826v1",
    "title": "Transferring Graph Neural Networks for Soft Sensor Modeling using Process Topologies",
    "authors": [
      "Maximilian F. Theisen",
      "Gabrie M. H. Meesters",
      "Artur M. Schweidtmann"
    ],
    "abstract": "Data-driven soft sensors help in process operations by providing real-time\nestimates of otherwise hard- to-measure process quantities, e.g., viscosities\nor product concentrations. Currently, soft sensors need to be developed\nindividually per plant. Using transfer learning, machine learning-based soft\nsensors could be reused and fine-tuned across plants and applications. However,\ntransferring data-driven soft sensor models is in practice often not possible,\nbecause the fixed input structure of standard soft sensor models prohibits\ntransfer if, e.g., the sensor information is not identical in all plants. We\npropose a topology-aware graph neural network approach for transfer learning of\nsoft sensor models across multiple plants. In our method, plants are modeled as\ngraphs: Unit operations are nodes, streams are edges, and sensors are embedded\nas attributes. Our approach brings two advantages for transfer learning: First,\nwe not only include sensor data but also crucial information on the plant\ntopology. Second, the graph neural network algorithm is flexible with respect\nto its sensor inputs. This allows us to model data from different plants with\ndifferent sensor networks. We test the transfer learning capabilities of our\nmodeling approach on ammonia synthesis loops with different process topologies.\nWe build a soft sensor predicting the ammonia concentration in the product.\nAfter training on data from one process, we successfully transfer our soft\nsensor model to a previously unseen process with a different topology. Our\napproach promises to extend the data-driven soft sensors to cases to leverage\ndata from multiple plants.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06826v1",
    "published_date": "2025-02-05 12:10:22 UTC",
    "updated_date": "2025-02-05 12:10:22 UTC"
  },
  {
    "arxiv_id": "2502.03104v1",
    "title": "Bellman Error Centering",
    "authors": [
      "Xingguo Chen",
      "Yu Gong",
      "Shangdong Yang",
      "Wenhao Wang"
    ],
    "abstract": "This paper revisits the recently proposed reward centering algorithms\nincluding simple reward centering (SRC) and value-based reward centering (VRC),\nand points out that SRC is indeed the reward centering, while VRC is\nessentially Bellman error centering (BEC). Based on BEC, we provide the\ncentered fixpoint for tabular value functions, as well as the centered TD\nfixpoint for linear value function approximation. We design the on-policy CTD\nalgorithm and the off-policy CTDC algorithm, and prove the convergence of both\nalgorithms. Finally, we experimentally validate the stability of our proposed\nalgorithms. Bellman error centering facilitates the extension to various\nreinforcement learning algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03104v1",
    "published_date": "2025-02-05 12:03:03 UTC",
    "updated_date": "2025-02-05 12:03:03 UTC"
  },
  {
    "arxiv_id": "2502.03505v1",
    "title": "Enhancing Free-hand 3D Photoacoustic and Ultrasound Reconstruction using Deep Learning",
    "authors": [
      "SiYeoul Lee",
      "SeonHo Kim",
      "Minkyung Seo",
      "SeongKyu Park",
      "Salehin Imrus",
      "Kambaluru Ashok",
      "DongEon Lee",
      "Chunsu Park",
      "SeonYeong Lee",
      "Jiye Kim",
      "Jae-Heung Yoo",
      "MinWoo Kim"
    ],
    "abstract": "This study introduces a motion-based learning network with a global-local\nself-attention module (MoGLo-Net) to enhance 3D reconstruction in handheld\nphotoacoustic and ultrasound (PAUS) imaging. Standard PAUS imaging is often\nlimited by a narrow field of view and the inability to effectively visualize\ncomplex 3D structures. The 3D freehand technique, which aligns sequential 2D\nimages for 3D reconstruction, faces significant challenges in accurate motion\nestimation without relying on external positional sensors. MoGLo-Net addresses\nthese limitations through an innovative adaptation of the self-attention\nmechanism, which effectively exploits the critical regions, such as\nfully-developed speckle area or high-echogenic tissue area within successive\nultrasound images to accurately estimate motion parameters. This facilitates\nthe extraction of intricate features from individual frames. Additionally, we\ndesigned a patch-wise correlation operation to generate a correlation volume\nthat is highly correlated with the scanning motion. A custom loss function was\nalso developed to ensure robust learning with minimized bias, leveraging the\ncharacteristics of the motion parameters. Experimental evaluations demonstrated\nthat MoGLo-Net surpasses current state-of-the-art methods in both quantitative\nand qualitative performance metrics. Furthermore, we expanded the application\nof 3D reconstruction technology beyond simple B-mode ultrasound volumes to\nincorporate Doppler ultrasound and photoacoustic imaging, enabling 3D\nvisualization of vasculature. The source code for this study is publicly\navailable at: https://github.com/guhong3648/US3D",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03505v1",
    "published_date": "2025-02-05 11:59:23 UTC",
    "updated_date": "2025-02-05 11:59:23 UTC"
  },
  {
    "arxiv_id": "2502.03504v1",
    "title": "Immersion for AI: Immersive Learning with Artificial Intelligence",
    "authors": [
      "Leonel Morgado"
    ],
    "abstract": "This work reflects upon what Immersion can mean from the perspective of an\nArtificial Intelligence (AI). Applying the lens of immersive learning theory,\nit seeks to understand whether this new perspective supports ways for AI\nparticipation in cognitive ecologies. By treating AI as a participant rather\nthan a tool, it explores what other participants (humans and other AIs) need to\nconsider in environments where AI can meaningfully engage and contribute to the\ncognitive ecology, and what the implications are for designing such learning\nenvironments. Drawing from the three conceptual dimensions of immersion -\nSystem, Narrative, and Agency - this work reinterprets AIs in immersive\nlearning contexts. It outlines practical implications for designing learning\nenvironments where AIs are surrounded by external digital services, can\ninterpret a narrative of origins, changes, and structural developments in data,\nand dynamically respond, making operational and tactical decisions that shape\nhuman-AI collaboration. Finally, this work suggests how these insights might\ninfluence the future of AI training, proposing that immersive learning theory\ncan inform the development of AIs capable of evolving beyond static models.\nThis paper paves the way for understanding AI as an immersive learner and\nparticipant in evolving human-AI cognitive ecosystems.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.HC",
      "I.2.0; H.5.0; K.3.0"
    ],
    "primary_category": "q-bio.NC",
    "comment": "16 pages. To be published in the Proceedings of the 11th Annual\n  International Conference of the Immersive Learning Research Network\n  (iLRN2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.03504v1",
    "published_date": "2025-02-05 11:51:02 UTC",
    "updated_date": "2025-02-05 11:51:02 UTC"
  },
  {
    "arxiv_id": "2502.03092v1",
    "title": "E-3SFC: Communication-Efficient Federated Learning with Double-way Features Synthesizing",
    "authors": [
      "Yuhao Zhou",
      "Yuxin Tian",
      "Mingjia Shi",
      "Yuanxi Li",
      "Yanan Sun",
      "Qing Ye",
      "Jiancheng Lv"
    ],
    "abstract": "The exponential growth in model sizes has significantly increased the\ncommunication burden in Federated Learning (FL). Existing methods to alleviate\nthis burden by transmitting compressed gradients often face high compression\nerrors, which slow down the model's convergence. To simultaneously achieve high\ncompression effectiveness and lower compression errors, we study the gradient\ncompression problem from a novel perspective. Specifically, we propose a\nsystematical algorithm termed Extended Single-Step Synthetic Features\nCompressing (E-3SFC), which consists of three sub-components, i.e., the\nSingle-Step Synthetic Features Compressor (3SFC), a double-way compression\nalgorithm, and a communication budget scheduler. First, we regard the process\nof gradient computation of a model as decompressing gradients from\ncorresponding inputs, while the inverse process is considered as compressing\nthe gradients. Based on this, we introduce a novel gradient compression method\ntermed 3SFC, which utilizes the model itself as a decompressor, leveraging\ntraining priors such as model weights and objective functions. 3SFC compresses\nraw gradients into tiny synthetic features in a single-step simulation,\nincorporating error feedback to minimize overall compression errors. To further\nreduce communication overhead, 3SFC is extended to E-3SFC, allowing double-way\ncompression and dynamic communication budget scheduling. Our theoretical\nanalysis under both strongly convex and non-convex conditions demonstrates that\n3SFC achieves linear and sub-linear convergence rates with aggregation noise.\nExtensive experiments across six datasets and six models reveal that 3SFC\noutperforms state-of-the-art methods by up to 13.4% while reducing\ncommunication costs by 111.6 times. These findings suggest that 3SFC can\nsignificantly enhance communication efficiency in FL without compromising model\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by TNNLS. arXiv admin note: text overlap with\n  arXiv:2302.13562",
    "pdf_url": "http://arxiv.org/pdf/2502.03092v1",
    "published_date": "2025-02-05 11:31:21 UTC",
    "updated_date": "2025-02-05 11:31:21 UTC"
  },
  {
    "arxiv_id": "2502.04371v1",
    "title": "PerPO: Perceptual Preference Optimization via Discriminative Rewarding",
    "authors": [
      "Zining Zhu",
      "Liang Zhao",
      "Kangheng Lin",
      "Jinze Yang",
      "En Yu",
      "Chenglong Liu",
      "Haoran Wei",
      "Jianjian Sun",
      "Zheng Ge",
      "Xiangyu Zhang"
    ],
    "abstract": "This paper presents Perceptual Preference Optimization (PerPO), a perception\nalignment method aimed at addressing the visual discrimination challenges in\ngenerative pre-trained multimodal large language models (MLLMs). To align MLLMs\nwith human visual perception process, PerPO employs discriminative rewarding to\ngather diverse negative samples, followed by listwise preference optimization\nto rank them.By utilizing the reward as a quantitative margin for ranking, our\nmethod effectively bridges generative preference optimization and\ndiscriminative empirical risk minimization. PerPO significantly enhances MLLMs'\nvisual discrimination capabilities while maintaining their generative\nstrengths, mitigates image-unconditional reward hacking, and ensures consistent\nperformance across visual tasks. This work marks a crucial step towards more\nperceptually aligned and versatile MLLMs. We also hope that PerPO will\nencourage the community to rethink MLLM alignment strategies.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04371v1",
    "published_date": "2025-02-05 11:28:11 UTC",
    "updated_date": "2025-02-05 11:28:11 UTC"
  },
  {
    "arxiv_id": "2502.03086v1",
    "title": "Implementing Large Quantum Boltzmann Machines as Generative AI Models for Dataset Balancing",
    "authors": [
      "Salvatore Sinno",
      "Markus Bertl",
      "Arati Sahoo",
      "Bhavika Bhalgamiya",
      "Thomas Groß",
      "Nicholas Chancellor"
    ],
    "abstract": "This study explores the implementation of large Quantum Restricted Boltzmann\nMachines (QRBMs), a key advancement in Quantum Machine Learning (QML), as\ngenerative models on D-Wave's Pegasus quantum hardware to address dataset\nimbalance in Intrusion Detection Systems (IDS). By leveraging Pegasus's\nenhanced connectivity and computational capabilities, a QRBM with 120 visible\nand 120 hidden units was successfully embedded, surpassing the limitations of\ndefault embedding tools. The QRBM synthesized over 1.6 million attack samples,\nachieving a balanced dataset of over 4.2 million records. Comparative\nevaluations with traditional balancing methods, such as SMOTE and\nRandomOversampler, revealed that QRBMs produced higher-quality synthetic\nsamples, significantly improving detection rates, precision, recall, and F1\nscore across diverse classifiers. The study underscores the scalability and\nefficiency of QRBMs, completing balancing tasks in milliseconds. These findings\nhighlight the transformative potential of QML and QRBMs as next-generation\ntools in data preprocessing, offering robust solutions for complex\ncomputational challenges in modern information systems.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "quant-ph"
    ],
    "primary_category": "cs.ET",
    "comment": "accapted at IEEE International Conference on Next Generation\n  Information System Engineering",
    "pdf_url": "http://arxiv.org/pdf/2502.03086v1",
    "published_date": "2025-02-05 11:25:27 UTC",
    "updated_date": "2025-02-05 11:25:27 UTC"
  },
  {
    "arxiv_id": "2502.03503v1",
    "title": "Two in context learning tasks with complex functions",
    "authors": [
      "Omar Naim",
      "Nicholas Asher"
    ],
    "abstract": "We examine two in context learning (ICL) tasks with mathematical functions in\nseveral train and test settings for transformer models. Our study generalizes\nwork on linear functions by showing that small transformers, even models with\nattention layers only, can approximate arbitrary polynomial functions and hence\ncontinuous functions under certain conditions. Our models also can approximate\npreviously unseen classes of polynomial functions, as well as the zeros of\ncomplex functions. Our models perform far better on this task than LLMs like\nGPT4 and involve complex reasoning when provided with suitable training data\nand methods. Our models also have important limitations; they fail to\ngeneralize outside of training distributions and so don't learn class forms of\nfunctions. We explain why this is so.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03503v1",
    "published_date": "2025-02-05 11:03:36 UTC",
    "updated_date": "2025-02-05 11:03:36 UTC"
  },
  {
    "arxiv_id": "2502.03502v1",
    "title": "DC-VSR: Spatially and Temporally Consistent Video Super-Resolution with Video Diffusion Prior",
    "authors": [
      "Janghyeok Han",
      "Gyujin Sim",
      "Geonung Kim",
      "Hyunseung Lee",
      "Kyuha Choi",
      "Youngseok Han",
      "Sunghyun Cho"
    ],
    "abstract": "Video super-resolution (VSR) aims to reconstruct a high-resolution (HR) video\nfrom a low-resolution (LR) counterpart. Achieving successful VSR requires\nproducing realistic HR details and ensuring both spatial and temporal\nconsistency. To restore realistic details, diffusion-based VSR approaches have\nrecently been proposed. However, the inherent randomness of diffusion, combined\nwith their tile-based approach, often leads to spatio-temporal inconsistencies.\nIn this paper, we propose DC-VSR, a novel VSR approach to produce spatially and\ntemporally consistent VSR results with realistic textures. To achieve spatial\nand temporal consistency, DC-VSR adopts a novel Spatial Attention Propagation\n(SAP) scheme and a Temporal Attention Propagation (TAP) scheme that propagate\ninformation across spatio-temporal tiles based on the self-attention mechanism.\nTo enhance high-frequency details, we also introduce Detail-Suppression\nSelf-Attention Guidance (DSSAG), a novel diffusion guidance scheme.\nComprehensive experiments demonstrate that DC-VSR achieves spatially and\ntemporally consistent, high-quality VSR results, outperforming previous\napproaches.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "eess.IV",
    "comment": "Equal contributions from first two authors",
    "pdf_url": "http://arxiv.org/pdf/2502.03502v1",
    "published_date": "2025-02-05 10:15:00 UTC",
    "updated_date": "2025-02-05 10:15:00 UTC"
  },
  {
    "arxiv_id": "2502.03047v2",
    "title": "Kozax: Flexible and Scalable Genetic Programming in JAX",
    "authors": [
      "Sigur de Vries",
      "Sander W. Keemink",
      "Marcel A. J. van Gerven"
    ],
    "abstract": "Genetic programming is an optimization algorithm inspired by evolution which\nautomatically evolves the structure of interpretable computer programs. The\nfitness evaluation in genetic programming suffers from high computational\nrequirements, limiting the performance on difficult problems. Consequently,\nthere is no efficient genetic programming framework that is usable for a wide\nrange of tasks. To this end, we developed Kozax, a genetic programming\nframework that evolves symbolic expressions for arbitrary problems. We\nimplemented Kozax using JAX, a framework for high-performance and scalable\nmachine learning, which allows the fitness evaluation to scale efficiently to\nlarge populations or datasets on GPU. Furthermore, Kozax offers constant\noptimization, custom operator definition and simultaneous evolution of multiple\ntrees. We demonstrate successful applications of Kozax to discover equations of\nnatural laws, recover equations of hidden dynamic variables, evolve a control\npolicy and optimize an objective function. Overall, Kozax provides a general,\nfast, and scalable library to optimize white-box solutions in the realm of\nscientific computing.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "6 figures, 3 tables, 1 algorithm, 13 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.03047v2",
    "published_date": "2025-02-05 10:12:17 UTC",
    "updated_date": "2025-04-15 13:55:56 UTC"
  },
  {
    "arxiv_id": "2502.03038v2",
    "title": "The Cake that is Intelligence and Who Gets to Bake it: An AI Analogy and its Implications for Participation",
    "authors": [
      "Martin Mundt",
      "Anaelia Ovalle",
      "Felix Friedrich",
      "A Pranav",
      "Subarnaduti Paul",
      "Manuel Brack",
      "Kristian Kersting",
      "William Agnew"
    ],
    "abstract": "In a widely popular analogy by Turing Award Laureate Yann LeCun, machine\nintelligence has been compared to cake - where unsupervised learning forms the\nbase, supervised learning adds the icing, and reinforcement learning is the\ncherry on top. We expand this 'cake that is intelligence' analogy from a simple\nstructural metaphor to the full life-cycle of AI systems, extending it to\nsourcing of ingredients (data), conception of recipes (instructions), the\nbaking process (training), and the tasting and selling of the cake (evaluation\nand distribution). Leveraging our re-conceptualization, we describe each step's\nentailed social ramifications and how they are bounded by statistical\nassumptions within machine learning. Whereas these technical foundations and\nsocial impacts are deeply intertwined, they are often studied in isolation,\ncreating barriers that restrict meaningful participation. Our\nre-conceptualization paves the way to bridge this gap by mapping where\ntechnical foundations interact with social outcomes, highlighting opportunities\nfor cross-disciplinary dialogue. Finally, we conclude with actionable\nrecommendations at each stage of the metaphorical AI cake's life-cycle,\nempowering prospective AI practitioners, users, and researchers, with increased\nawareness and ability to engage in broader AI discourse.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03038v2",
    "published_date": "2025-02-05 09:51:19 UTC",
    "updated_date": "2025-02-06 11:53:09 UTC"
  },
  {
    "arxiv_id": "2502.06824v1",
    "title": "Neural Network-based Vehicular Channel Estimation Performance: Effect of Noise in the Training Set",
    "authors": [
      "Simbarashe Aldrin Ngorima",
      "Albert Helberg",
      "Marelie H. Davel"
    ],
    "abstract": "Vehicular communication systems face significant challenges due to high\nmobility and rapidly changing environments, which affect the channel over which\nthe signals travel. To address these challenges, neural network (NN)-based\nchannel estimation methods have been suggested. These methods are primarily\ntrained on high signal-to-noise ratio (SNR) with the assumption that training a\nNN in less noisy conditions can result in good generalisation. This study\nexamines the effectiveness of training NN-based channel estimators on mixed SNR\ndatasets compared to training solely on high SNR datasets, as seen in several\nrelated works. Estimators evaluated in this work include an architecture that\nuses convolutional layers and self-attention mechanisms; a method that employs\ntemporal convolutional networks and data pilot-aided estimation; two methods\nthat combine classical methods with multilayer perceptrons; and the current\nstate-of-the-art model that combines Long-Short-Term Memory networks with data\npilot-aided and temporal averaging methods as post processing. Our results\nindicate that using only high SNR data for training is not always optimal, and\nthe SNR range in the training dataset should be treated as a hyperparameter\nthat can be adjusted for better performance. This is illustrated by the better\nperformance of some models in low SNR conditions when trained on the mixed SNR\ndataset, as opposed to when trained exclusively on high SNR data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "Primary"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 5 Figures",
    "pdf_url": "http://arxiv.org/pdf/2502.06824v1",
    "published_date": "2025-02-05 09:29:01 UTC",
    "updated_date": "2025-02-05 09:29:01 UTC"
  },
  {
    "arxiv_id": "2502.03500v1",
    "title": "Efficient Image Restoration via Latent Consistency Flow Matching",
    "authors": [
      "Elad Cohen",
      "Idan Achituve",
      "Idit Diamant",
      "Arnon Netzer",
      "Hai Victor Habi"
    ],
    "abstract": "Recent advances in generative image restoration (IR) have demonstrated\nimpressive results. However, these methods are hindered by their substantial\nsize and computational demands, rendering them unsuitable for deployment on\nedge devices. This work introduces ELIR, an Efficient Latent Image Restoration\nmethod. ELIR operates in latent space by first predicting the latent\nrepresentation of the minimum mean square error (MMSE) estimator and then\ntransporting this estimate to high-quality images using a latent consistency\nflow-based model. Consequently, ELIR is more than 4x faster compared to the\nstate-of-the-art diffusion and flow-based approaches. Moreover, ELIR is also\nmore than 4x smaller, making it well-suited for deployment on\nresource-constrained edge devices. Comprehensive evaluations of various image\nrestoration tasks show that ELIR achieves competitive results, effectively\nbalancing distortion and perceptual quality metrics while offering improved\nefficiency in terms of memory and computation.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "eess.IV",
    "comment": "21 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.03500v1",
    "published_date": "2025-02-05 09:24:49 UTC",
    "updated_date": "2025-02-05 09:24:49 UTC"
  },
  {
    "arxiv_id": "2502.03499v1",
    "title": "Omni-DNA: A Unified Genomic Foundation Model for Cross-Modal and Multi-Task Learning",
    "authors": [
      "Zehui Li",
      "Vallijah Subasri",
      "Yifei Shen",
      "Dongsheng Li",
      "Yiren Zhao",
      "Guy-Bart Stan",
      "Caihua Shan"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate remarkable generalizability across\ndiverse tasks, yet genomic foundation models (GFMs) still require separate\nfinetuning for each downstream application, creating significant overhead as\nmodel sizes grow. Moreover, existing GFMs are constrained by rigid output\nformats, limiting their applicability to various genomic tasks. In this work,\nwe revisit the transformer-based auto-regressive models and introduce Omni-DNA,\na family of cross-modal multi-task models ranging from 20 million to 1 billion\nparameters. Our approach consists of two stages: (i) pretraining on DNA\nsequences with next token prediction objective, and (ii) expanding the\nmulti-modal task-specific tokens and finetuning for multiple downstream tasks\nsimultaneously. When evaluated on the Nucleotide Transformer and GB benchmarks,\nOmni-DNA achieves state-of-the-art performance on 18 out of 26 tasks. Through\nmulti-task finetuning, Omni-DNA addresses 10 acetylation and methylation tasks\nat once, surpassing models trained on each task individually. Finally, we\ndesign two complex genomic tasks, DNA2Function and Needle-in-DNA, which map DNA\nsequences to textual functional descriptions and images, respectively,\nindicating Omni-DNA's cross-modal capabilities to broaden the scope of genomic\napplications. All the models are available through\nhttps://huggingface.co/collections/zehui127",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03499v1",
    "published_date": "2025-02-05 09:20:52 UTC",
    "updated_date": "2025-02-05 09:20:52 UTC"
  },
  {
    "arxiv_id": "2502.03014v1",
    "title": "xai_evals : A Framework for Evaluating Post-Hoc Local Explanation Methods",
    "authors": [
      "Pratinav Seth",
      "Yashwardhan Rathore",
      "Neeraj Kumar Singh",
      "Chintan Chitroda",
      "Vinay Kumar Sankarapu"
    ],
    "abstract": "The growing complexity of machine learning and deep learning models has led\nto an increased reliance on opaque \"black box\" systems, making it difficult to\nunderstand the rationale behind predictions. This lack of transparency is\nparticularly challenging in high-stakes applications where interpretability is\nas important as accuracy. Post-hoc explanation methods are commonly used to\ninterpret these models, but they are seldom rigorously evaluated, raising\nconcerns about their reliability. The Python package xai_evals addresses this\nby providing a comprehensive framework for generating, benchmarking, and\nevaluating explanation methods across both tabular and image data modalities.\nIt integrates popular techniques like SHAP, LIME, Grad-CAM, Integrated\nGradients (IG), and Backtrace, while supporting evaluation metrics such as\nfaithfulness, sensitivity, and robustness. xai_evals enhances the\ninterpretability of machine learning models, fostering transparency and trust\nin AI systems. The library is open-sourced at\nhttps://pypi.org/project/xai-evals/ .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03014v1",
    "published_date": "2025-02-05 09:17:48 UTC",
    "updated_date": "2025-02-05 09:17:48 UTC"
  },
  {
    "arxiv_id": "2502.10422v1",
    "title": "DA-LIF: Dual Adaptive Leaky Integrate-and-Fire Model for Deep Spiking Neural Networks",
    "authors": [
      "Tianqing Zhang",
      "Kairong Yu",
      "Jian Zhang",
      "Hongwei Wang"
    ],
    "abstract": "Spiking Neural Networks (SNNs) are valued for their ability to process\nspatio-temporal information efficiently, offering biological plausibility, low\nenergy consumption, and compatibility with neuromorphic hardware. However, the\ncommonly used Leaky Integrate-and-Fire (LIF) model overlooks neuron\nheterogeneity and independently processes spatial and temporal information,\nlimiting the expressive power of SNNs. In this paper, we propose the Dual\nAdaptive Leaky Integrate-and-Fire (DA-LIF) model, which introduces spatial and\ntemporal tuning with independently learnable decays. Evaluations on both static\n(CIFAR10/100, ImageNet) and neuromorphic datasets (CIFAR10-DVS, DVS128 Gesture)\ndemonstrate superior accuracy with fewer timesteps compared to state-of-the-art\nmethods. Importantly, DA-LIF achieves these improvements with minimal\nadditional parameters, maintaining low energy consumption. Extensive ablation\nstudies further highlight the robustness and effectiveness of the DA-LIF model.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted by ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10422v1",
    "published_date": "2025-02-05 09:02:07 UTC",
    "updated_date": "2025-02-05 09:02:07 UTC"
  },
  {
    "arxiv_id": "2502.03004v1",
    "title": "MedBioLM: Optimizing Medical and Biological QA with Fine-Tuned Large Language Models and Retrieval-Augmented Generation",
    "authors": [
      "Seonok Kim"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\nnatural language processing tasks. However, their application to specialized\ndomains such as medicine and biology requires further optimization to ensure\nfactual accuracy, reliability, and contextual depth. We introduce MedBioLM, a\ndomain-adapted biomedical question-answering model designed to enhance both\nshort-form and long-form queries. By integrating fine-tuning and\nretrieval-augmented generation (RAG), MedBioLM dynamically incorporates\ndomain-specific knowledge, improving reasoning abilities and factual accuracy.\nTo evaluate its effectiveness, we fine-tuned the model on diverse biomedical QA\ndatasets, covering structured multiple-choice assessments and complex clinical\nreasoning tasks. Fine-tuning significantly improves accuracy on benchmark\ndatasets, while RAG enhances factual consistency. These results highlight the\npotential of domain-optimized LLMs in advancing biomedical research, medical\neducation, and clinical decision support.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03004v1",
    "published_date": "2025-02-05 08:58:35 UTC",
    "updated_date": "2025-02-05 08:58:35 UTC"
  },
  {
    "arxiv_id": "2502.02988v1",
    "title": "Training an LLM-as-a-Judge Model: Pipeline, Insights, and Practical Lessons",
    "authors": [
      "Renjun Hu",
      "Yi Cheng",
      "Libin Meng",
      "Jiaxin Xia",
      "Yi Zong",
      "Xing Shi",
      "Wei Lin"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has opened new\npossibilities for their adoption as evaluative judges. This paper introduces\nThemis, a fine-tuned LLM judge that delivers sophisticated context-aware\nevaluations. We provide a comprehensive overview of the development pipeline\nfor Themis, highlighting its scenario-dependent evaluation prompts and two\nnovel methods for controlled instruction generation. These designs enable\nThemis to effectively distill evaluative skills from teacher models, while\nretaining flexibility for continuous development. We introduce two\nhuman-labeled benchmarks for meta-evaluation, demonstrating that Themis can\nachieve high alignment with human preferences in an economical manner.\nAdditionally, we explore insights into the LLM-as-a-judge paradigm, revealing\nnuances in performance and the varied effects of reference answers. Notably, we\nobserve that pure knowledge distillation from strong LLMs, though common, does\nnot guarantee performance improvement through scaling. We propose a mitigation\nstrategy based on instruction-following difficulty. Furthermore, we provide\npractical guidelines covering data balancing, prompt customization,\nmulti-objective training, and metric aggregation. We aim for our method and\nfindings, along with the fine-tuning data, benchmarks, and model checkpoints,\nto support future research and development in this area.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted at WWW'25 (Industrial Track), extended version",
    "pdf_url": "http://arxiv.org/pdf/2502.02988v1",
    "published_date": "2025-02-05 08:35:55 UTC",
    "updated_date": "2025-02-05 08:35:55 UTC"
  },
  {
    "arxiv_id": "2502.02982v2",
    "title": "MobileA3gent: Training Mobile GUI Agents Using Decentralized Self-Sourced Data from Diverse Users",
    "authors": [
      "Wenhao Wang",
      "Mengying Yuan",
      "Zijie Yu",
      "Guangyi Liu",
      "Rui Ye",
      "Tian Jin",
      "Siheng Chen",
      "Yanfeng Wang"
    ],
    "abstract": "The advancement of mobile GUI agents has opened new opportunities for\nautomating tasks on mobile devices. Training these agents requires large-scale\nhigh-quality data, which is prohibitively expensive when relying on human\nlabor. Given the vast population of global mobile phone users, if automated\ndata collection from them becomes feasible, the resulting data volume and the\nsubsequently trained mobile agents could reach unprecedented levels.\nNevertheless, two major challenges arise: (1) extracting user instructions\nwithout human intervention and (2) utilizing distributed user data while\npreserving privacy. To tackle these challenges, we propose MobileA3gent, a\ncollaborative framework that trains mobile GUI Agents using decentralized\nself-sourced data from diverse users. The framework comprises two components,\neach targeting a specific challenge: (1) Auto-Annotation, which enables the\nautomatic collection of high-quality datasets during users' routine phone usage\nwith minimal cost. (2) FedVLM-A, which enhances federated VLM training under\nnon-IID distributions by incorporating adapted global aggregation based on both\nepisode-level and step-level variability. Extensive experiments prove that\nMobileA3gent achieves superior performance over traditional approaches at only\n1% of the cost, highlighting its potential for real-world applications",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02982v2",
    "published_date": "2025-02-05 08:26:17 UTC",
    "updated_date": "2025-05-20 07:03:02 UTC"
  },
  {
    "arxiv_id": "2502.07803v1",
    "title": "Reasoning-as-Logic-Units: Scaling Test-Time Reasoning in Large Language Models Through Logic Unit Alignment",
    "authors": [
      "Cheryl Li",
      "Tianyuan Xu",
      "Yiwen Guo"
    ],
    "abstract": "Chain-of-Thought (CoT) prompting has shown promise in enhancing the reasoning\ncapabilities of large language models (LLMs) by generating natural language\n(NL) rationales that lead to the final answer. However, it struggles with\nnumerical computation, which has somehow led to the development of\nprogram-aided techniques. Despite their potential, a persistent challenge\nremains: inconsistencies between LLM-reported reasoning steps and the logic in\ngenerated programs, which we term ``reasoning hallucinations.\" This stems from\nthe inherent ambiguities of NL and the statistical nature of LLMs, which often\nlack rigorous logical coherence. To address this challenge, we propose a novel\ntest-time scaling framework, Reasoning-as-Logic-Units (RaLU), which constructs\na more reliable reasoning path by aligning logical units between the generated\nprogram and their corresponding NL descriptions. By decomposing the initially\ngenerated program into discrete units using static analysis, RaLU engages in an\niterative dialogue with the LLM to judge, refine, and explain each unit. A\nrewind-and-correct mechanism ensures alignment between code statements and task\nrequirements in each unit, ultimately forming a cohesive reasoning path under\nthe program's logic, from which the model reaches a final solution. Our\nexperiments demonstrate that RaLU significantly outperforms existing baselines\nin mathematical reasoning (GSM8K, MATH) and algorithmic reasoning (HumanEval+,\nMBPP+), underscoring its potential to advance LLM reasoning and programming by\noffering enhanced accuracy and interpretability.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07803v1",
    "published_date": "2025-02-05 08:23:18 UTC",
    "updated_date": "2025-02-05 08:23:18 UTC"
  },
  {
    "arxiv_id": "2502.02975v3",
    "title": "TGB-Seq Benchmark: Challenging Temporal GNNs with Complex Sequential Dynamics",
    "authors": [
      "Lu Yi",
      "Jie Peng",
      "Yanping Zheng",
      "Fengran Mo",
      "Zhewei Wei",
      "Yuhang Ye",
      "Yue Zixuan",
      "Zengfeng Huang"
    ],
    "abstract": "Future link prediction is a fundamental challenge in various real-world\ndynamic systems. To address this, numerous temporal graph neural networks\n(temporal GNNs) and benchmark datasets have been developed. However, these\ndatasets often feature excessive repeated edges and lack complex sequential\ndynamics, a key characteristic inherent in many real-world applications such as\nrecommender systems and ``Who-To-Follow'' on social networks. This oversight\nhas led existing methods to inadvertently downplay the importance of learning\nsequential dynamics, focusing primarily on predicting repeated edges.\n  In this study, we demonstrate that existing methods, such as GraphMixer and\nDyGFormer, are inherently incapable of learning simple sequential dynamics,\nsuch as ``a user who has followed OpenAI and Anthropic is more likely to follow\nAI at Meta next.'' Motivated by this issue, we introduce the Temporal Graph\nBenchmark with Sequential Dynamics (TGB-Seq), a new benchmark carefully curated\nto minimize repeated edges, challenging models to learn sequential dynamics and\ngeneralize to unseen edges. TGB-Seq comprises large real-world datasets\nspanning diverse domains, including e-commerce interactions, movie ratings,\nbusiness reviews, social networks, citation networks and web link networks.\nBenchmarking experiments reveal that current methods usually suffer significant\nperformance degradation and incur substantial training costs on TGB-Seq, posing\nnew challenges and opportunities for future research. TGB-Seq datasets,\nleaderboards, and example codes are available at https://tgb-seq.github.io/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "published at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.02975v3",
    "published_date": "2025-02-05 08:20:19 UTC",
    "updated_date": "2025-03-15 11:05:10 UTC"
  },
  {
    "arxiv_id": "2502.02966v1",
    "title": "FACTER: Fairness-Aware Conformal Thresholding and Prompt Engineering for Enabling Fair LLM-Based Recommender Systems",
    "authors": [
      "Arya Fayyazi",
      "Mehdi Kamal",
      "Massoud Pedram"
    ],
    "abstract": "We propose FACTER, a fairness-aware framework for LLM-based recommendation\nsystems that integrates conformal prediction with dynamic prompt engineering.\nBy introducing an adaptive semantic variance threshold and a\nviolation-triggered mechanism, FACTER automatically tightens fairness\nconstraints whenever biased patterns emerge. We further develop an adversarial\nprompt generator that leverages historical violations to reduce repeated\ndemographic biases without retraining the LLM. Empirical results on MovieLens\nand Amazon show that FACTER substantially reduces fairness violations (up to\n95.5%) while maintaining strong recommendation accuracy, revealing semantic\nvariance as a potent proxy of bias.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02966v1",
    "published_date": "2025-02-05 08:07:04 UTC",
    "updated_date": "2025-02-05 08:07:04 UTC"
  },
  {
    "arxiv_id": "2502.02963v1",
    "title": "(Neural-Symbolic) Machine Learning for Inconsistency Measurement",
    "authors": [
      "Sven Weinzierl",
      "Carl Cora"
    ],
    "abstract": "We present machine-learning-based approaches for determining the\n\\emph{degree} of inconsistency -- which is a numerical value -- for\npropositional logic knowledge bases. Specifically, we present regression- and\nneural-based models that learn to predict the values that the inconsistency\nmeasures $\\incmi$ and $\\incat$ would assign to propositional logic knowledge\nbases. Our main motivation is that computing these values conventionally can be\nhard complexity-wise. As an important addition, we use specific postulates,\nthat is, properties, of the underlying inconsistency measures to infer symbolic\nrules, which we combine with the learning-based models in the form of\nconstraints. We perform various experiments and show that a) predicting the\ndegree values is feasible in many situations, and b) including the symbolic\nconstraints deduced from the rationality postulates increases the prediction\nquality.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02963v1",
    "published_date": "2025-02-05 08:00:30 UTC",
    "updated_date": "2025-02-05 08:00:30 UTC"
  },
  {
    "arxiv_id": "2502.02955v1",
    "title": "ReachAgent: Enhancing Mobile Agent via Page Reaching and Operation",
    "authors": [
      "Qinzhuo Wu",
      "Wei Liu",
      "Jian Luan",
      "Bin Wang"
    ],
    "abstract": "Recently, mobile AI agents have gained increasing attention. Given a task,\nmobile AI agents can interact with mobile devices in multiple steps and finally\nform a GUI flow that solves the task. However, existing agents tend to focus on\nmost task-relevant elements at each step, leading to local optimal solutions\nand ignoring the overall GUI flow. To address this issue, we constructed a\ntraining dataset called MobileReach, which breaks the task into page reaching\nand operation subtasks. Furthermore, we propose ReachAgent, a two-stage\nframework that focuses on improving its task-completion abilities. It utilizes\nthe page reaching and page operation subtasks, along with reward-based\npreference GUI flows, to further enhance the agent. Experimental results show\nthat ReachAgent significantly improves the IoU Acc and Text Acc by 7.12% and\n7.69% on the step-level and 4.72% and 4.63% on the task-level compared to the\nSOTA agent. Our data and code will be released upon acceptance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02955v1",
    "published_date": "2025-02-05 07:35:23 UTC",
    "updated_date": "2025-02-05 07:35:23 UTC"
  },
  {
    "arxiv_id": "2502.02951v1",
    "title": "VQA-Levels: A Hierarchical Approach for Classifying Questions in VQA",
    "authors": [
      "Madhuri Latha Madaka",
      "Chakravarthy Bhagvati"
    ],
    "abstract": "Designing datasets for Visual Question Answering (VQA) is a difficult and\ncomplex task that requires NLP for parsing and computer vision for analysing\nthe relevant aspects of the image for answering the question asked. Several\nbenchmark datasets have been developed by researchers but there are many issues\nwith using them for methodical performance tests. This paper proposes a new\nbenchmark dataset -- a pilot version called VQA-Levels is ready now -- for\ntesting VQA systems systematically and assisting researchers in advancing the\nfield. The questions are classified into seven levels ranging from direct\nanswers based on low-level image features (without needing even a classifier)\nto those requiring high-level abstraction of the entire image content. The\nquestions in the dataset exhibit one or many of ten properties. Each is\ncategorised into a specific level from 1 to 7. Levels 1 - 3 are directly on the\nvisual content while the remaining levels require extra knowledge about the\nobjects in the image. Each question generally has a unique one or two-word\nanswer. The questions are 'natural' in the sense that a human is likely to ask\nsuch a question when seeing the images. An example question at Level 1 is,\n``What is the shape of the red colored region in the image?\" while at Level 7,\nit is, ``Why is the man cutting the paper?\". Initial testing of the proposed\ndataset on some of the existing VQA systems reveals that their success is high\non Level 1 (low level features) and Level 2 (object classification) questions,\nleast on Level 3 (scene text) followed by Level 6 (extrapolation) and Level 7\n(whole scene analysis) questions. The work in this paper will go a long way to\nsystematically analyze VQA systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02951v1",
    "published_date": "2025-02-05 07:28:36 UTC",
    "updated_date": "2025-02-05 07:28:36 UTC"
  },
  {
    "arxiv_id": "2502.02945v1",
    "title": "LLM-KT: Aligning Large Language Models with Knowledge Tracing using a Plug-and-Play Instruction",
    "authors": [
      "Ziwei Wang",
      "Jie Zhou",
      "Qin Chen",
      "Min Zhang",
      "Bo Jiang",
      "Aimin Zhou",
      "Qinchun Bai",
      "Liang He"
    ],
    "abstract": "The knowledge tracing (KT) problem is an extremely important topic in\npersonalized education, which aims to predict whether students can correctly\nanswer the next question based on their past question-answer records. Prior\nwork on this task mainly focused on learning the sequence of behaviors based on\nthe IDs or textual information. However, these studies usually fail to capture\nstudents' sufficient behavioral patterns without reasoning with rich world\nknowledge about questions. In this paper, we propose a large language models\n(LLMs)-based framework for KT, named \\texttt{\\textbf{LLM-KT}}, to integrate the\nstrengths of LLMs and traditional sequence interaction models. For task-level\nalignment, we design Plug-and-Play instruction to align LLMs with KT,\nleveraging LLMs' rich knowledge and powerful reasoning capacity. For\nmodality-level alignment, we design the plug-in context and sequence to\nintegrate multiple modalities learned by traditional methods. To capture the\nlong context of history records, we present a plug-in context to flexibly\ninsert the compressed context embedding into LLMs using question-specific and\nconcept-specific tokens. Furthermore, we introduce a plug-in sequence to\nenhance LLMs with sequence interaction behavior representation learned by\ntraditional sequence models using a sequence adapter. Extensive experiments\nshow that \\texttt{\\textbf{LLM-KT}} obtains state-of-the-art performance on four\ntypical datasets by comparing it with approximately 20 strong baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02945v1",
    "published_date": "2025-02-05 07:21:49 UTC",
    "updated_date": "2025-02-05 07:21:49 UTC"
  },
  {
    "arxiv_id": "2502.04366v1",
    "title": "Contrastive Token-level Explanations for Graph-based Rumour Detection",
    "authors": [
      "Daniel Wai Kit Chin",
      "Roy Ka-Wei Lee"
    ],
    "abstract": "The widespread use of social media has accelerated the dissemination of\ninformation, but it has also facilitated the spread of harmful rumours, which\ncan disrupt economies, influence political outcomes, and exacerbate public\nhealth crises, such as the COVID-19 pandemic. While Graph Neural Network\n(GNN)-based approaches have shown significant promise in automated rumour\ndetection, they often lack transparency, making their predictions difficult to\ninterpret. Existing graph explainability techniques fall short in addressing\nthe unique challenges posed by the dependencies among feature dimensions in\nhigh-dimensional text embeddings used in GNN-based models. In this paper, we\nintroduce Contrastive Token Layerwise Relevance Propagation (CT-LRP), a novel\nframework designed to enhance the explainability of GNN-based rumour detection.\nCT-LRP extends current graph explainability methods by providing token-level\nexplanations that offer greater granularity and interpretability. We evaluate\nthe effectiveness of CT-LRP across multiple GNN models trained on three\npublicly available rumour detection datasets, demonstrating that it\nconsistently produces high-fidelity, meaningful explanations, paving the way\nfor more robust and trustworthy rumour detection systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2502.04366v1",
    "published_date": "2025-02-05 07:14:11 UTC",
    "updated_date": "2025-02-05 07:14:11 UTC"
  },
  {
    "arxiv_id": "2502.04365v1",
    "title": "AI-Based Thermal Video Analysis in Privacy-Preserving Healthcare: A Case Study on Detecting Time of Birth",
    "authors": [
      "Jorge García-Torres",
      "Øyvind Meinich-Bache",
      "Siren Rettedal",
      "Kjersti Engan"
    ],
    "abstract": "Approximately 10% of newborns need some assistance to start breathing and 5\\%\nproper ventilation. It is crucial that interventions are initiated as soon as\npossible after birth. Accurate documentation of Time of Birth (ToB) is thereby\nessential for documenting and improving newborn resuscitation performance.\nHowever, current clinical practices rely on manual recording of ToB, typically\nwith minute precision. In this study, we present an AI-driven, video-based\nsystem for automated ToB detection using thermal imaging, designed to preserve\nthe privacy of healthcare providers and mothers by avoiding the use of\nidentifiable visual data. Our approach achieves 91.4% precision and 97.4%\nrecall in detecting ToB within thermal video clips during performance\nevaluation. Additionally, our system successfully identifies ToB in 96% of test\ncases with an absolute median deviation of 1 second compared to manual\nannotations. This method offers a reliable solution for improving ToB\ndocumentation and enhancing newborn resuscitation outcomes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Paper accepted in 2025 IEEE International Symposium on Biomedical\n  Imaging (ISBI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.04365v1",
    "published_date": "2025-02-05 07:01:49 UTC",
    "updated_date": "2025-02-05 07:01:49 UTC"
  },
  {
    "arxiv_id": "2502.02928v1",
    "title": "Large Language Model Guided Self-Debugging Code Generation",
    "authors": [
      "Muntasir Adnan",
      "Zhiwei Xu",
      "Carlos C. N. Kuhn"
    ],
    "abstract": "Automated code generation is gaining significant importance in intelligent\ncomputer programming and system deployment. However, current approaches often\nface challenges in computational efficiency and lack robust mechanisms for code\nparsing and error correction. In this work, we propose a novel framework,\nPyCapsule, with a simple yet effective two-agent pipeline and efficient\nself-debugging modules for Python code generation. PyCapsule features\nsophisticated prompt inference, iterative error handling, and case testing,\nensuring high generation stability, safety, and correctness. Empirically,\nPyCapsule achieves up to 5.7% improvement of success rate on HumanEval, 10.3%\non HumanEval-ET, and 24.4% on BigCodeBench compared to the state-of-art\nmethods. We also observe a decrease in normalized success rate given more\nself-debugging attempts, potentially affected by limited and noisy error\nfeedback in retention. PyCapsule demonstrates broader impacts on advancing\nlightweight and efficient code generation for artificial intelligence systems.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02928v1",
    "published_date": "2025-02-05 06:43:40 UTC",
    "updated_date": "2025-02-05 06:43:40 UTC"
  },
  {
    "arxiv_id": "2502.02924v1",
    "title": "TopoCL: Topological Contrastive Learning for Time Series",
    "authors": [
      "Namwoo Kim",
      "Hyungryul Baik",
      "Yoonjin Yoon"
    ],
    "abstract": "Universal time series representation learning is challenging but valuable in\nreal-world applications such as classification, anomaly detection, and\nforecasting. Recently, contrastive learning (CL) has been actively explored to\ntackle time series representation. However, a key challenge is that the data\naugmentation process in CL can distort seasonal patterns or temporal\ndependencies, inevitably leading to a loss of semantic information. To address\nthis challenge, we propose Topological Contrastive Learning for time series\n(TopoCL). TopoCL mitigates such information loss by incorporating persistent\nhomology, which captures the topological characteristics of data that remain\ninvariant under transformations. In this paper, we treat the temporal and\ntopological properties of time series data as distinct modalities.\nSpecifically, we compute persistent homology to construct topological features\nof time series data, representing them in persistence diagrams. We then design\na neural network to encode these persistent diagrams. Our approach jointly\noptimizes CL within the time modality and time-topology correspondence,\npromoting a comprehensive understanding of both temporal semantics and\ntopological properties of time series. We conduct extensive experiments on four\ndownstream tasks-classification, anomaly detection, forecasting, and transfer\nlearning. The results demonstrate that TopoCL achieves state-of-the-art\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to TNNLS (under review)",
    "pdf_url": "http://arxiv.org/pdf/2502.02924v1",
    "published_date": "2025-02-05 06:37:35 UTC",
    "updated_date": "2025-02-05 06:37:35 UTC"
  },
  {
    "arxiv_id": "2502.02920v1",
    "title": "Adaptive Budget Optimization for Multichannel Advertising Using Combinatorial Bandits",
    "authors": [
      "Briti Gangopadhyay",
      "Zhao Wang",
      "Alberto Silvio Chiappa",
      "Shingo Takamatsu"
    ],
    "abstract": "Effective budget allocation is crucial for optimizing the performance of\ndigital advertising campaigns. However, the development of practical budget\nallocation algorithms remain limited, primarily due to the lack of public\ndatasets and comprehensive simulation environments capable of verifying the\nintricacies of real-world advertising. While multi-armed bandit (MAB)\nalgorithms have been extensively studied, their efficacy diminishes in\nnon-stationary environments where quick adaptation to changing market dynamics\nis essential. In this paper, we advance the field of budget allocation in\ndigital advertising by introducing three key contributions. First, we develop a\nsimulation environment designed to mimic multichannel advertising campaigns\nover extended time horizons, incorporating logged real-world data. Second, we\npropose an enhanced combinatorial bandit budget allocation strategy that\nleverages a saturating mean function and a targeted exploration mechanism with\nchange-point detection. This approach dynamically adapts to changing market\nconditions, improving allocation efficiency by filtering target regions based\non domain knowledge. Finally, we present both theoretical analysis and\nempirical results, demonstrating that our method consistently outperforms\nbaseline strategies, achieving higher rewards and lower regret across multiple\nreal-world campaigns.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02920v1",
    "published_date": "2025-02-05 06:29:52 UTC",
    "updated_date": "2025-02-05 06:29:52 UTC"
  },
  {
    "arxiv_id": "2502.02917v2",
    "title": "Interactive Symbolic Regression through Offline Reinforcement Learning: A Co-Design Framework",
    "authors": [
      "Yuan Tian",
      "Wenqi Zhou",
      "Michele Viscione",
      "Hao Dong",
      "David Kammer",
      "Olga Fink"
    ],
    "abstract": "Symbolic Regression (SR) holds great potential for uncovering underlying\nmathematical and physical relationships from observed data. However, the vast\ncombinatorial space of possible expressions poses significant challenges for\nboth online search methods and pre-trained transformer models. Additionally,\ncurrent state-of-the-art approaches typically do not consider the integration\nof domain experts' prior knowledge and do not support iterative interactions\nwith the model during the equation discovery process. To address these\nchallenges, we propose the Symbolic Q-network (Sym-Q), an advanced interactive\nframework for large-scale symbolic regression. Unlike previous large-scale\ntransformer-based SR approaches, Sym-Q leverages reinforcement learning without\nrelying on a transformer-based decoder. This formulation allows the agent to\nlearn through offline reinforcement learning using any type of tree encoder,\nenabling more efficient training and inference. Furthermore, we propose a\nco-design mechanism, where the reinforcement learning-based Sym-Q facilitates\neffective interaction with domain experts at any stage of the equation\ndiscovery process. Users can dynamically modify generated nodes of the\nexpression, collaborating with the agent to tailor the mathematical expression\nto best fit the problem and align with the assumed physical laws, particularly\nwhen there is prior partial knowledge of the expected behavior. Our experiments\ndemonstrate that the pre-trained Sym-Q surpasses existing SR algorithms on the\nchallenging SSDNC benchmark. Moreover, we experimentally show on real-world\ncases that its performance can be further enhanced by the interactive co-design\nmechanism, with Sym-Q achieving greater performance gains than other\nstate-of-the-art models. Our reproducible code is available at\nhttps://github.com/EPFL-IMOS/Sym-Q.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.LG",
    "comment": "This work should not be a new submission but instead should be an\n  update to my existing article, arXiv:2402.05306",
    "pdf_url": "http://arxiv.org/pdf/2502.02917v2",
    "published_date": "2025-02-05 06:26:49 UTC",
    "updated_date": "2025-02-11 00:20:37 UTC"
  },
  {
    "arxiv_id": "2502.04364v1",
    "title": "Lost in Edits? A $λ$-Compass for AIGC Provenance",
    "authors": [
      "Wenhao You",
      "Bryan Hooi",
      "Yiwei Wang",
      "Euijin Choo",
      "Ming-Hsuan Yang",
      "Junsong Yuan",
      "Zi Huang",
      "Yujun Cai"
    ],
    "abstract": "Recent advancements in diffusion models have driven the growth of text-guided\nimage editing tools, enabling precise and iterative modifications of\nsynthesized content. However, as these tools become increasingly accessible,\nthey also introduce significant risks of misuse, emphasizing the critical need\nfor robust attribution methods to ensure content authenticity and traceability.\nDespite the creative potential of such tools, they pose significant challenges\nfor attribution, particularly in adversarial settings where edits can be\nlayered to obscure an image's origins. We propose LambdaTracer, a novel\nlatent-space attribution method that robustly identifies and differentiates\nauthentic outputs from manipulated ones without requiring any modifications to\ngenerative or editing pipelines. By adaptively calibrating reconstruction\nlosses, LambdaTracer remains effective across diverse iterative editing\nprocesses, whether automated through text-guided editing tools such as\nInstructPix2Pix and ControlNet or performed manually with editing software such\nas Adobe Photoshop. Extensive experiments reveal that our method consistently\noutperforms baseline approaches in distinguishing maliciously edited images,\nproviding a practical solution to safeguard ownership, creativity, and\ncredibility in the open, fast-evolving AI ecosystems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04364v1",
    "published_date": "2025-02-05 06:24:25 UTC",
    "updated_date": "2025-02-05 06:24:25 UTC"
  },
  {
    "arxiv_id": "2502.02912v1",
    "title": "MobiCLR: Mobility Time Series Contrastive Learning for Urban Region Representations",
    "authors": [
      "Namwoo Kim",
      "Takahiro Yabe",
      "Chanyoung Park",
      "Yoonjin Yoon"
    ],
    "abstract": "Recently, learning effective representations of urban regions has gained\nsignificant attention as a key approach to understanding urban dynamics and\nadvancing smarter cities. Existing approaches have demonstrated the potential\nof leveraging mobility data to generate latent representations, providing\nvaluable insights into the intrinsic characteristics of urban areas. However,\nincorporating the temporal dynamics and detailed semantics inherent in human\nmobility patterns remains underexplored. To address this gap, we propose a\nnovel urban region representation learning model, Mobility Time Series\nContrastive Learning for Urban Region Representations (MobiCLR), designed to\ncapture semantically meaningful embeddings from inflow and outflow mobility\npatterns. MobiCLR uses contrastive learning to enhance the discriminative power\nof its representations, applying an instance-wise contrastive loss to capture\ndistinct flow-specific characteristics. Additionally, we develop a regularizer\nto align output features with these flow-specific representations, enabling a\nmore comprehensive understanding of mobility dynamics. To validate our model,\nwe conduct extensive experiments in Chicago, New York, and Washington, D.C. to\npredict income, educational attainment, and social vulnerability. The results\ndemonstrate that our model outperforms state-of-the-art models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to Information Sciences (under review)",
    "pdf_url": "http://arxiv.org/pdf/2502.02912v1",
    "published_date": "2025-02-05 06:18:43 UTC",
    "updated_date": "2025-02-05 06:18:43 UTC"
  },
  {
    "arxiv_id": "2502.02909v1",
    "title": "SPARC: Subspace-Aware Prompt Adaptation for Robust Continual Learning in LLMs",
    "authors": [
      "Dinithi Jayasuriya",
      "Sina Tayebati",
      "Davide Ettori",
      "Ranganath Krishnan",
      "Amit Ranjan Trivedi"
    ],
    "abstract": "We propose SPARC, a lightweight continual learning framework for large\nlanguage models (LLMs) that enables efficient task adaptation through prompt\ntuning in a lower-dimensional space. By leveraging principal component analysis\n(PCA), we identify a compact subspace of the training data. Optimizing prompts\nin this lower-dimensional space enhances training efficiency, as it focuses\nupdates on the most relevant features while reducing computational overhead.\nFurthermore, since the model's internal structure remains unaltered, the\nextensive knowledge gained from pretraining is fully preserved, ensuring that\npreviously learned information is not compromised during adaptation. Our method\nachieves high knowledge retention in both task-incremental and\ndomain-incremental continual learning setups while fine-tuning only 0.04% of\nthe model's parameters. Additionally, by integrating LoRA, we enhance\nadaptability to computational constraints, allowing for a tradeoff between\naccuracy and training cost. Experiments on the SuperGLUE benchmark demonstrate\nthat our PCA-based prompt tuning combined with LoRA maintains full knowledge\nretention while improving accuracy, utilizing only 1% of the model's\nparameters. These results establish our approach as a scalable and\nresource-efficient solution for continual learning in LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02909v1",
    "published_date": "2025-02-05 06:11:55 UTC",
    "updated_date": "2025-02-05 06:11:55 UTC"
  },
  {
    "arxiv_id": "2502.02903v1",
    "title": "What is in a name? Mitigating Name Bias in Text Embeddings via Anonymization",
    "authors": [
      "Sahil Manchanda",
      "Pannaga Shivaswamy"
    ],
    "abstract": "Text-embedding models often exhibit biases arising from the data on which\nthey are trained. In this paper, we examine a hitherto unexplored bias in\ntext-embeddings: bias arising from the presence of $\\textit{names}$ such as\npersons, locations, organizations etc. in the text. Our study shows how the\npresence of $\\textit{name-bias}$ in text-embedding models can potentially lead\nto erroneous conclusions in assessment of thematic similarity.Text-embeddings\ncan mistakenly indicate similarity between texts based on names in the text,\neven when their actual semantic content has no similarity or indicate\ndissimilarity simply because of the names in the text even when the texts match\nsemantically. We first demonstrate the presence of name bias in different\ntext-embedding models and then propose $\\textit{text-anonymization}$ during\ninference which involves removing references to names, while preserving the\ncore theme of the text. The efficacy of the anonymization approach is\ndemonstrated on two downstream NLP tasks, achieving significant performance\ngains. Our simple and training-optimization-free approach offers a practical\nand easily implementable solution to mitigate name bias.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02903v1",
    "published_date": "2025-02-05 05:54:49 UTC",
    "updated_date": "2025-02-05 05:54:49 UTC"
  },
  {
    "arxiv_id": "2502.02901v2",
    "title": "Policy Abstraction and Nash Refinement in Tree-Exploiting PSRO",
    "authors": [
      "Christine Konicki",
      "Mithun Chakraborty",
      "Michael P. Wellman"
    ],
    "abstract": "Policy Space Response Oracles (PSRO) interleaves empirical game-theoretic\nanalysis with deep reinforcement learning (DRL) to solve games too complex for\ntraditional analytic methods. Tree-exploiting PSRO (TE-PSRO) is a variant of\nthis approach that iteratively builds a coarsened empirical game model in\nextensive form using data obtained from querying a simulator that represents a\ndetailed description of the game. We make two main methodological advances to\nTE-PSRO that enhance its applicability to complex games of imperfect\ninformation. First, we introduce a scalable representation for the empirical\ngame tree where edges correspond to implicit policies learned through DRL.\nThese policies cover conditions in the underlying game abstracted in the game\nmodel, supporting sustainable growth of the tree over epochs. Second, we\nleverage extensive form in the empirical model by employing refined Nash\nequilibria to direct strategy exploration. To enable this, we give a modular\nand scalable algorithm based on generalized backward induction for computing a\nsubgame perfect equilibrium (SPE) in an imperfect-information game. We\nexperimentally evaluate our approach on a suite of games including an\nalternating-offer bargaining game with outside offers; our results demonstrate\nthat TE-PSRO converges toward equilibrium faster when new strategies are\ngenerated based on SPE rather than Nash equilibrium, and with reasonable\ntime/memory requirements for the growing empirical model.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02901v2",
    "published_date": "2025-02-05 05:48:16 UTC",
    "updated_date": "2025-02-15 06:14:03 UTC"
  },
  {
    "arxiv_id": "2502.02896v1",
    "title": "A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs",
    "authors": [
      "Bradley P. Allen",
      "Paul T. Groth"
    ],
    "abstract": "Evaluating large language models (LLMs) for tasks like fact extraction in\nsupport of knowledge graph construction frequently involves computing accuracy\nmetrics using a ground truth benchmark based on a knowledge graph (KG). These\nevaluations assume that errors represent factual disagreements. However, human\ndiscourse frequently features metalinguistic disagreement, where agents differ\nnot on facts but on the meaning of the language used to express them. Given the\ncomplexity of natural language processing and generation using LLMs, we ask: do\nmetalinguistic disagreements occur between LLMs and KGs? Based on an\ninvestigation using the T-REx knowledge alignment dataset, we hypothesize that\nmetalinguistic disagreement does in fact occur between LLMs and KGs, with\npotential relevance for the practice of knowledge graph engineering. We propose\na benchmark for evaluating the detection of factual and metalinguistic\ndisagreements between LLMs and KGs. An initial proof of concept of such a\nbenchmark is available on Github.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 2 tables, to appear in Reham Alharbi, Jacopo de Berardinis,\n  Paul Groth, Albert Mero\\~no-Pe\\~nuela, Elena Simperl, Valentina Tamma (eds.),\n  ISWC 2024 Special Session on Harmonising Generative AI and Semantic Web\n  Technologies. CEUR-WS.org (forthcoming), for associated code and data see\n  https://github.com/bradleypallen/trex-metalinguistic-disagreement",
    "pdf_url": "http://arxiv.org/pdf/2502.02896v1",
    "published_date": "2025-02-05 05:37:26 UTC",
    "updated_date": "2025-02-05 05:37:26 UTC"
  },
  {
    "arxiv_id": "2503.11658v1",
    "title": "Circuit Diagram Retrieval Based on Hierarchical Circuit Graph Representation",
    "authors": [
      "Ming Gao",
      "Ruichen Qiu",
      "Zeng Hui Chang",
      "Kanjian Zhang",
      "Haikun Wei",
      "Hong Cai Chen"
    ],
    "abstract": "In the domain of analog circuit design, the retrieval of circuit diagrams has\ndrawn a great interest, primarily due to its vital role in the consultation of\nlegacy designs and the detection of design plagiarism. Existing image retrieval\ntechniques are adept at handling natural images, which converts images into\nfeature vectors and retrieval similar images according to the closeness of\nthese vectors. Nonetheless, these approaches exhibit limitations when applied\nto the more specialized and intricate domain of circuit diagrams. This paper\npresents a novel approach to circuit diagram retrieval by employing a graph\nrepresentation of circuit diagrams, effectively reformulating the retrieval\ntask as a graph retrieval problem. The proposed methodology consists of two\nprincipal components: a circuit diagram recognition algorithm designed to\nextract the circuit components and topological structure of the circuit using\nproposed GAM-YOLO model and a 2-step connected domain filtering algorithm, and\na hierarchical retrieval strategy based on graph similarity and different graph\nrepresentation methods for analog circuits. Our methodology pioneers the\nutilization of graph representation in the retrieval of circuit diagrams,\nincorporating topological features that are commonly overlooked by standard\nimage retrieval methods. The results of our experiments substantiate the\nefficacy of our approach in retrieving circuit diagrams across of different\ntypes.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "11 pages, 10 figures, 7 tables, under review paper",
    "pdf_url": "http://arxiv.org/pdf/2503.11658v1",
    "published_date": "2025-02-05 05:05:53 UTC",
    "updated_date": "2025-02-05 05:05:53 UTC"
  },
  {
    "arxiv_id": "2502.04362v1",
    "title": "LLMs can be easily Confused by Instructional Distractions",
    "authors": [
      "Yerin Hwang",
      "Yongil Kim",
      "Jahyun Koo",
      "Taegwan Kang",
      "Hyunkyung Bae",
      "Kyomin Jung"
    ],
    "abstract": "Despite the fact that large language models (LLMs) show exceptional skill in\ninstruction following tasks, this strength can turn into a vulnerability when\nthe models are required to disregard certain instructions.\nInstruction-following tasks typically involve a clear task description and\ninput text containing the target data to be processed. However, when the input\nitself resembles an instruction, confusion may arise, even if there is explicit\nprompting to distinguish between the task instruction and the input. We refer\nto this phenomenon as instructional distraction. In this paper, we introduce a\nnovel benchmark, named DIM-Bench, specifically designed to assess LLMs'\nperformance under instructional distraction. The benchmark categorizes\nreal-world instances of instructional distraction and evaluates LLMs across\nfour instruction tasks: rewriting, proofreading, translation, and style\ntransfer -- alongside five input tasks: reasoning, code generation,\nmathematical reasoning, bias detection, and question answering. Our\nexperimental results reveal that even the most advanced LLMs are susceptible to\ninstructional distraction, often failing to accurately follow user intent in\nsuch cases.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.04362v1",
    "published_date": "2025-02-05 04:52:57 UTC",
    "updated_date": "2025-02-05 04:52:57 UTC"
  },
  {
    "arxiv_id": "2502.02885v3",
    "title": "Expertized Caption Auto-Enhancement for Video-Text Retrieval",
    "authors": [
      "Baoyao Yang",
      "Junxiang Chen",
      "Wanyun Li",
      "Wenbin Yao",
      "Yang Zhou"
    ],
    "abstract": "Video-text retrieval has been stuck in the information mismatch caused by\npersonalized and inadequate textual descriptions of videos. The substantial\ninformation gap between the two modalities hinders an effective cross-modal\nrepresentation alignment, resulting in ambiguous retrieval results. Although\ntext rewriting methods have been proposed to broaden text expressions, the\nmodality gap remains significant, as the text representation space is hardly\nexpanded with insufficient semantic enrichment.Instead, this paper turns to\nenhancing visual presentation, bridging video expression closer to textual\nrepresentation via caption generation and thereby facilitating video-text\nmatching.While multimodal large language models (mLLM) have shown a powerful\ncapability to convert video content into text, carefully crafted prompts are\nessential to ensure the reasonableness and completeness of the generated\ncaptions. Therefore, this paper proposes an automatic caption enhancement\nmethod that improves expression quality and mitigates empiricism in augmented\ncaptions through self-learning.Additionally, an expertized caption selection\nmechanism is designed and introduced to customize augmented captions for each\nvideo, further exploring the utilization potential of caption augmentation.Our\nmethod is entirely data-driven, which not only dispenses with heavy data\ncollection and computation workload but also improves self-adaptability by\ncircumventing lexicon dependence and introducing personalized matching. The\nsuperiority of our method is validated by state-of-the-art results on various\nbenchmarks, specifically achieving Top-1 recall accuracy of 68.5% on MSR-VTT,\n68.1% on MSVD, and 62.0% on DiDeMo. Our code is publicly available at\nhttps://github.com/CaryXiang/ECA4VTR.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "H.3.3; I.2.10; I.2.7; H.5.1"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02885v3",
    "published_date": "2025-02-05 04:51:46 UTC",
    "updated_date": "2025-04-08 15:45:28 UTC"
  },
  {
    "arxiv_id": "2502.02883v2",
    "title": "SensorChat: Answering Qualitative and Quantitative Questions during Long-Term Multimodal Sensor Interactions",
    "authors": [
      "Xiaofan Yu",
      "Lanxiang Hu",
      "Benjamin Reichman",
      "Dylan Chu",
      "Rushil Chandrupatla",
      "Xiyuan Zhang",
      "Larry Heck",
      "Tajana Rosing"
    ],
    "abstract": "Natural language interaction with sensing systems is crucial for addressing\nusers' personal concerns and providing health-related insights into their daily\nlives. When a user asks a question, the system automatically analyzes the full\nhistory of sensor data, extracts relevant information, and generates an\nappropriate response. However, existing systems are limited to short-duration\n(e.g., one minute) or low-frequency (e.g., daily step count) sensor data. In\naddition, they struggle with quantitative questions that require precise\nnumerical answers. In this work, we introduce SensorChat, the first end-to-end\nQA system designed for daily life monitoring using long-duration,\nhigh-frequency time series data. Given raw sensor signals spanning multiple\ndays and a user-defined natural language question, SensorChat generates\nsemantically meaningful responses that directly address user concerns.\nSensorChat effectively handles both quantitative questions that require\nnumerical precision and qualitative questions that require high-level reasoning\nto infer subjective insights. To achieve this, SensorChat uses an innovative\nthree-stage pipeline including question decomposition, sensor data query, and\nanswer assembly. The first and third stages leverage Large Language Models\n(LLMs) to interpret human queries and generate responses. The intermediate\nquerying stage extracts relevant information from the complete sensor data\nhistory. Real-world implementation demonstrate SensorChat's capability for\nreal-time interactions on a cloud server while also being able to run entirely\non edge platforms after quantization. Comprehensive QA evaluations show that\nSensorChat achieves up to 93% higher answer accuracy than state-of-the-art\nsystems on quantitative questions. Additionally, a user study with eight\nvolunteers highlights SensorChat's effectiveness in answering qualitative and\nopen-ended questions.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2502.02883v2",
    "published_date": "2025-02-05 04:41:59 UTC",
    "updated_date": "2025-05-15 06:31:41 UTC"
  },
  {
    "arxiv_id": "2502.06820v2",
    "title": "LoCA: Location-Aware Cosine Adaptation for Parameter-Efficient Fine-Tuning",
    "authors": [
      "Zhekai Du",
      "Yinjie Min",
      "Jingjing Li",
      "Ke Lu",
      "Changliang Zou",
      "Liuhua Peng",
      "Tingjin Chu",
      "Mingming Gong"
    ],
    "abstract": "Low-rank adaptation (LoRA) has become a prevalent method for adapting\npre-trained large language models to downstream tasks. However, the simple\nlow-rank decomposition form may constrain the hypothesis space. To address this\nlimitation, we introduce Location-aware Cosine Adaptation (LoCA), a novel\nfrequency-domain parameter-efficient fine-tuning method based on inverse\nDiscrete Cosine Transform (iDCT) with selective locations of learnable\ncomponents. We begin with a comprehensive theoretical comparison between\nfrequency-domain and low-rank decompositions for fine-tuning pre-trained large\nmodels. Our analysis reveals that frequency-domain decomposition with carefully\nselected frequency components can surpass the expressivity of traditional\nlow-rank-based methods. Furthermore, we demonstrate that iDCT offers a more\nefficient implementation compared to inverse Discrete Fourier Transform (iDFT),\nallowing for better selection and tuning of frequency components while\nmaintaining equivalent expressivity to the optimal iDFT-based adaptation. By\nemploying finite-difference approximation to estimate gradients for discrete\nlocations of learnable coefficients on the DCT spectrum, LoCA dynamically\nselects the most informative frequency components during training. Experiments\non diverse language and vision fine-tuning tasks demonstrate that LoCA offers\nenhanced parameter efficiency while maintains computational feasibility\ncomparable to low-rank-based methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06820v2",
    "published_date": "2025-02-05 04:14:34 UTC",
    "updated_date": "2025-04-29 09:28:40 UTC"
  },
  {
    "arxiv_id": "2502.02874v1",
    "title": "Vertical Federated Learning for Failure-Cause Identification in Disaggregated Microwave Networks",
    "authors": [
      "Fatih Temiz",
      "Memedhe Ibrahimi",
      "Francesco Musumeci",
      "Claudio Passera",
      "Massimo Tornatore"
    ],
    "abstract": "Machine Learning (ML) has proven to be a promising solution to provide novel\nscalable and efficient fault management solutions in modern 5G-and-beyond\ncommunication networks. In the context of microwave networks, ML-based\nsolutions have received significant attention. However, current solutions can\nonly be applied to monolithic scenarios in which a single entity (e.g., an\noperator) manages the entire network. As current network architectures move\ntowards disaggregated communication platforms in which multiple operators and\nvendors collaborate to achieve cost-efficient and reliable network management,\nnew ML-based approaches for fault management must tackle the challenges of\nsharing business-critical information due to potential conflicts of interest.\nIn this study, we explore the application of Federated Learning in\ndisaggregated microwave networks for failure-cause identification using a real\nmicrowave hardware failure dataset. In particular, we investigate the\napplication of two Vertical Federated Learning (VFL), namely using Split Neural\nNetworks (SplitNNs) and Federated Learning based on Gradient Boosting Decision\nTrees (FedTree), on different multi-vendor deployment scenarios, and we compare\nthem to a centralized scenario where data is managed by a single entity. Our\nexperimental results show that VFL-based scenarios can achieve F1-Scores\nconsistently within at most a 1% gap with respect to a centralized scenario,\nregardless of the deployment strategies or model types, while also ensuring\nminimal leakage of sensitive-data.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "6 pages, 7 figure, IEEE ICC 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.02874v1",
    "published_date": "2025-02-05 04:09:15 UTC",
    "updated_date": "2025-02-05 04:09:15 UTC"
  },
  {
    "arxiv_id": "2502.02871v1",
    "title": "Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning",
    "authors": [
      "Yibo Yan",
      "Shen Wang",
      "Jiahao Huo",
      "Jingheng Ye",
      "Zhendong Chu",
      "Xuming Hu",
      "Philip S. Yu",
      "Carla Gomes",
      "Bart Selman",
      "Qingsong Wen"
    ],
    "abstract": "Scientific reasoning, the process through which humans apply logic, evidence,\nand critical thinking to explore and interpret scientific phenomena, is\nessential in advancing knowledge reasoning across diverse fields. However,\ndespite significant progress, current scientific reasoning models still\nstruggle with generalization across domains and often fall short of multimodal\nperception. Multimodal Large Language Models (MLLMs), which integrate text,\nimages, and other modalities, present an exciting opportunity to overcome these\nlimitations and enhance scientific reasoning. Therefore, this position paper\nargues that MLLMs can significantly advance scientific reasoning across\ndisciplines such as mathematics, physics, chemistry, and biology. First, we\npropose a four-stage research roadmap of scientific reasoning capabilities, and\nhighlight the current state of MLLM applications in scientific reasoning,\nnoting their ability to integrate and reason over diverse data types. Second,\nwe summarize the key challenges that remain obstacles to achieving MLLM's full\npotential. To address these challenges, we propose actionable insights and\nsuggestions for the future. Overall, our work offers a novel perspective on\nMLLM integration with scientific reasoning, providing the LLM community with a\nvaluable vision for achieving Artificial General Intelligence (AGI).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02871v1",
    "published_date": "2025-02-05 04:05:27 UTC",
    "updated_date": "2025-02-05 04:05:27 UTC"
  },
  {
    "arxiv_id": "2502.02869v1",
    "title": "OmniRL: In-Context Reinforcement Learning by Large-Scale Meta-Training in Randomized Worlds",
    "authors": [
      "Fan Wang",
      "Pengtao Shao",
      "Yiming Zhang",
      "Bo Yu",
      "Shaoshan Liu",
      "Ning Ding",
      "Yang Cao",
      "Yu Kang",
      "Haifeng Wang"
    ],
    "abstract": "We introduce OmniRL, a highly generalizable in-context reinforcement learning\n(ICRL) model that is meta-trained on hundreds of thousands of diverse tasks.\nThese tasks are procedurally generated by randomizing state transitions and\nrewards within Markov Decision Processes. To facilitate this extensive\nmeta-training, we propose two key innovations: 1. An efficient data synthesis\npipeline for ICRL, which leverages the interaction histories of diverse\nbehavior policies; and 2. A novel modeling framework that integrates both\nimitation learning and reinforcement learning (RL) within the context, by\nincorporating prior knowledge. For the first time, we demonstrate that\nin-context learning (ICL) alone, without any gradient-based fine-tuning, can\nsuccessfully tackle unseen Gymnasium tasks through imitation learning, online\nRL, or offline RL. Additionally, we show that achieving generalized ICRL\ncapabilities-unlike task identification-oriented few-shot learning-critically\ndepends on long trajectories generated by variant tasks and diverse behavior\npolicies. By emphasizing the potential of ICL and departing from pre-training\nfocused on acquiring specific skills, we further underscore the significance of\nmeta-training aimed at cultivating the ability of ICL itself.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2502.02869v1",
    "published_date": "2025-02-05 03:59:13 UTC",
    "updated_date": "2025-02-05 03:59:13 UTC"
  },
  {
    "arxiv_id": "2502.02867v2",
    "title": "Domain-Invariant Per-Frame Feature Extraction for Cross-Domain Imitation Learning with Visual Observations",
    "authors": [
      "Minung Kim",
      "Kawon Lee",
      "Jungmo Kim",
      "Sungho Choi",
      "Seungyul Han"
    ],
    "abstract": "Imitation learning (IL) enables agents to mimic expert behavior without\nreward signals but faces challenges in cross-domain scenarios with\nhigh-dimensional, noisy, and incomplete visual observations. To address this,\nwe propose Domain-Invariant Per-Frame Feature Extraction for Imitation Learning\n(DIFF-IL), a novel IL method that extracts domain-invariant features from\nindividual frames and adapts them into sequences to isolate and replicate\nexpert behaviors. We also introduce a frame-wise time labeling technique to\nsegment expert behaviors by timesteps and assign rewards aligned with temporal\ncontexts, enhancing task performance. Experiments across diverse visual\nenvironments demonstrate the effectiveness of DIFF-IL in addressing complex\nvisual tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages main, 19 pages appendix with reference. Submitted to ICML\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2502.02867v2",
    "published_date": "2025-02-05 03:52:36 UTC",
    "updated_date": "2025-02-14 11:57:25 UTC"
  },
  {
    "arxiv_id": "2502.02866v1",
    "title": "A Systematic Approach for Assessing Large Language Models' Test Case Generation Capability",
    "authors": [
      "Hung-Fu Chang",
      "Mohammad Shokrolah Shirazi"
    ],
    "abstract": "Software testing ensures the quality and reliability of software products,\nbut manual test case creation is labor-intensive. With the rise of large\nlanguage models (LLMs), there is growing interest in unit test creation with\nLLMs. However, effective assessment of LLM-generated test cases is limited by\nthe lack of standardized benchmarks that comprehensively cover diverse\nprogramming scenarios. To address the assessment of LLM's test case generation\nability and lacking dataset for evaluation, we propose the Generated Benchmark\nfrom Control-Flow Structure and Variable Usage Composition (GBCV) approach,\nwhich systematically generates programs used for evaluating LLMs' test\ngeneration capabilities. By leveraging basic control-flow structures and\nvariable usage, GBCV provides a flexible framework to create a spectrum of\nprograms ranging from simple to complex. Because GPT-4o and GPT-3-Turbo are\npublicly accessible models, to present real-world regular user's use case, we\nuse GBCV to assess LLM performance on them. Our findings indicate that GPT-4o\nperforms better on complex program structures, while all models effectively\ndetect boundary values in simple conditions but face challenges with arithmetic\ncomputations. This study highlights the strengths and limitations of LLMs in\ntest generation, provides a benchmark framework, and suggests directions for\nfuture improvement.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.5; I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "17 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.02866v1",
    "published_date": "2025-02-05 03:51:44 UTC",
    "updated_date": "2025-02-05 03:51:44 UTC"
  },
  {
    "arxiv_id": "2502.02863v2",
    "title": "OceanChat: The Effect of Virtual Conversational AI Agents on Sustainable Attitude and Behavior Change",
    "authors": [
      "Pat Pataranutaporn",
      "Alexander Doudkin",
      "Pattie Maes"
    ],
    "abstract": "Marine ecosystems face unprecedented threats from climate change and plastic\npollution, yet traditional environmental education often struggles to translate\nawareness into sustained behavioral change. This paper presents OceanChat, an\ninteractive system leveraging large language models to create conversational AI\nagents represented as animated marine creatures -- specifically a beluga whale,\na jellyfish, and a seahorse -- designed to promote environmental behavior (PEB)\nand foster awareness through personalized dialogue. Through a between-subjects\nexperiment (N=900), we compared three conditions: (1) Static Scientific\nInformation, providing conventional environmental education through text and\nimages; (2) Static Character Narrative, featuring first-person storytelling\nfrom 3D-rendered marine creatures; and (3) Conversational Character Narrative,\nenabling real-time dialogue with AI-powered marine characters. Our analysis\nrevealed that the Conversational Character Narrative condition significantly\nincreased behavioral intentions and sustainable choice preferences compared to\nstatic approaches. The beluga whale character demonstrated consistently\nstronger emotional engagement across multiple measures, including perceived\nanthropomorphism and empathy. However, impacts on deeper measures like climate\npolicy support and psychological distance were limited, highlighting the\ncomplexity of shifting entrenched beliefs. Our work extends research on\nsustainability interfaces facilitating PEB and offers design principles for\ncreating emotionally resonant, context-aware AI characters. By balancing\nanthropomorphism with species authenticity, OceanChat demonstrates how\ninteractive narratives can bridge the gap between environmental knowledge and\nreal-world behavior change.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "21 pages, 18 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.02863v2",
    "published_date": "2025-02-05 03:45:33 UTC",
    "updated_date": "2025-05-21 10:19:16 UTC"
  },
  {
    "arxiv_id": "2502.02862v2",
    "title": "Learning Generalizable Features for Tibial Plateau Fracture Segmentation Using Masked Autoencoder and Limited Annotations",
    "authors": [
      "Peiyan Yue",
      "Die Cai",
      "Chu Guo",
      "Mengxing Liu",
      "Jun Xia",
      "Yi Wang"
    ],
    "abstract": "Accurate automated segmentation of tibial plateau fractures (TPF) from\ncomputed tomography (CT) requires large amounts of annotated data to train deep\nlearning models, but obtaining such annotations presents unique challenges. The\nprocess demands expert knowledge to identify diverse fracture patterns, assess\nseverity, and account for individual anatomical variations, making the\nannotation process highly time-consuming and expensive. Although\nsemi-supervised learning methods can utilize unlabeled data, existing\napproaches often struggle with the complexity and variability of fracture\nmorphologies, as well as limited generalizability across datasets. To tackle\nthese issues, we propose an effective training strategy based on masked\nautoencoder (MAE) for the accurate TPF segmentation in CT. Our method leverages\nMAE pretraining to capture global skeletal structures and fine-grained fracture\ndetails from unlabeled data, followed by fine-tuning with a small set of\nlabeled data. This strategy reduces the dependence on extensive annotations\nwhile enhancing the model's ability to learn generalizable and transferable\nfeatures. The proposed method is evaluated on an in-house dataset containing\n180 CT scans with TPF. Experimental results demonstrate that our method\nconsistently outperforms semi-supervised methods, achieving an average Dice\nsimilarity coefficient (DSC) of 95.81%, average symmetric surface distance\n(ASSD) of 1.91mm, and Hausdorff distance (95HD) of 9.42mm with only 20\nannotated cases. Moreover, our method exhibits strong transferability when\napplying to another public pelvic CT dataset with hip fractures, highlighting\nits potential for broader applications in fracture segmentation tasks.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "5 pages, 6 figures. Accepted to IEEE EMBC 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.02862v2",
    "published_date": "2025-02-05 03:44:52 UTC",
    "updated_date": "2025-04-09 05:15:50 UTC"
  },
  {
    "arxiv_id": "2502.15732v1",
    "title": "Data Wrangling Task Automation Using Code-Generating Language Models",
    "authors": [
      "Ashlesha Akella",
      "Krishnasuri Narayanam"
    ],
    "abstract": "Ensuring data quality in large tabular datasets is a critical challenge,\ntypically addressed through data wrangling tasks. Traditional statistical\nmethods, though efficient, cannot often understand the semantic context and\ndeep learning approaches are resource-intensive, requiring task and\ndataset-specific training. To overcome these shortcomings, we present an\nautomated system that utilizes large language models to generate executable\ncode for tasks like missing value imputation, error detection, and error\ncorrection. Our system aims to identify inherent patterns in the data while\nleveraging external knowledge, effectively addressing both memory-dependent and\nmemory-independent tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AAAI 2025 Demo",
    "pdf_url": "http://arxiv.org/pdf/2502.15732v1",
    "published_date": "2025-02-05 03:36:29 UTC",
    "updated_date": "2025-02-05 03:36:29 UTC"
  },
  {
    "arxiv_id": "2502.02844v2",
    "title": "Wolfpack Adversarial Attack for Robust Multi-Agent Reinforcement Learning",
    "authors": [
      "Sunwoo Lee",
      "Jaebak Hwang",
      "Yonghyeon Jo",
      "Seungyul Han"
    ],
    "abstract": "Traditional robust methods in multi-agent reinforcement learning (MARL) often\nstruggle against coordinated adversarial attacks in cooperative scenarios. To\naddress this limitation, we propose the Wolfpack Adversarial Attack framework,\ninspired by wolf hunting strategies, which targets an initial agent and its\nassisting agents to disrupt cooperation. Additionally, we introduce the\nWolfpack-Adversarial Learning for MARL (WALL) framework, which trains robust\nMARL policies to defend against the proposed Wolfpack attack by fostering\nsystem-wide collaboration. Experimental results underscore the devastating\nimpact of the Wolfpack attack and the significant robustness improvements\nachieved by WALL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages main, 21 pages appendix with reference. Submitted to ICML\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2502.02844v2",
    "published_date": "2025-02-05 02:59:23 UTC",
    "updated_date": "2025-02-14 13:27:24 UTC"
  },
  {
    "arxiv_id": "2502.06816v1",
    "title": "DeepCell: Multiview Representation Learning for Post-Mapping Netlists",
    "authors": [
      "Zhengyuan Shi",
      "Chengyu Ma",
      "Ziyang Zheng",
      "Lingfeng Zhou",
      "Hongyang Pan",
      "Wentao Jiang",
      "Fan Yang",
      "Xiaoyan Yang",
      "Zhufei Chu",
      "Qiang Xu"
    ],
    "abstract": "Representation learning for post-mapping (PM) netlists is a critical\nchallenge in Electronic Design Automation (EDA), driven by the diverse and\ncomplex nature of modern circuit designs. Existing approaches focus on\nintermediate representations like And-Inverter Graphs (AIGs), limiting their\napplicability to post-synthesis stages. We introduce DeepCell, a multiview\nrepresentation learning framework that integrates structural and functional\ninsights from both PM netlists and AIGs to learn rich, generalizable\nembeddings. At its core, DeepCell employs the novel Mask Circuit Modeling (MCM)\nmechanism, which refines PM netlist representations in a self-supervised manner\nusing pretrained AIG encoders. DeepCell sets a new benchmark in PM netlist\nrepresentation, outperforming existing methods in predictive accuracy and\nreconstruction fidelity. To validate its efficacy, we apply DeepCell to\nfunctional Engineering Change Orders (ECO), achieving significant reductions in\npatch generation costs and runtime while improving patch quality.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06816v1",
    "published_date": "2025-02-05 02:39:47 UTC",
    "updated_date": "2025-02-05 02:39:47 UTC"
  },
  {
    "arxiv_id": "2502.02834v2",
    "title": "Task-Aware Virtual Training: Enhancing Generalization in Meta-Reinforcement Learning for Out-of-Distribution Tasks",
    "authors": [
      "Jeongmo Kim",
      "Yisak Park",
      "Minung Kim",
      "Seungyul Han"
    ],
    "abstract": "Meta reinforcement learning aims to develop policies that generalize to\nunseen tasks sampled from a task distribution. While context-based meta-RL\nmethods improve task representation using task latents, they often struggle\nwith out-of-distribution (OOD) tasks. To address this, we propose Task-Aware\nVirtual Training (TAVT), a novel algorithm that accurately captures task\ncharacteristics for both training and OOD scenarios using metric-based\nrepresentation learning. Our method successfully preserves task characteristics\nin virtual tasks and employs a state regularization technique to mitigate\noverestimation errors in state-varying environments. Numerical results\ndemonstrate that TAVT significantly enhances generalization to OOD tasks across\nvarious MuJoCo and MetaWorld environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages main paper, 19 pages appendices with reference, Submitted to\n  ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.02834v2",
    "published_date": "2025-02-05 02:31:50 UTC",
    "updated_date": "2025-02-14 11:19:06 UTC"
  },
  {
    "arxiv_id": "2502.04361v1",
    "title": "Predicting 3D Motion from 2D Video for Behavior-Based VR Biometrics",
    "authors": [
      "Mingjun Li",
      "Natasha Kholgade Banerjee",
      "Sean Banerjee"
    ],
    "abstract": "Critical VR applications in domains such as healthcare, education, and\nfinance that use traditional credentials, such as PIN, password, or\nmulti-factor authentication, stand the chance of being compromised if a\nmalicious person acquires the user credentials or if the user hands over their\ncredentials to an ally. Recently, a number of approaches on user authentication\nhave emerged that use motions of VR head-mounted displays (HMDs) and hand\ncontrollers during user interactions in VR to represent the user's behavior as\na VR biometric signature. One of the fundamental limitations of behavior-based\napproaches is that current on-device tracking for HMDs and controllers lacks\ncapability to perform tracking of full-body joint articulation, losing key\nsignature data encapsulated by the user articulation. In this paper, we propose\nan approach that uses 2D body joints, namely shoulder, elbow, wrist, hip, knee,\nand ankle, acquired from the right side of the participants using an external\n2D camera. Using a Transformer-based deep neural network, our method uses the\n2D data of body joints that are not tracked by the VR device to predict past\nand future 3D tracks of the right controller, providing the benefit of\naugmenting 3D knowledge in authentication. Our approach provides a minimum\nequal error rate (EER) of 0.025, and a maximum EER drop of 0.040 over prior\nwork that uses single-unit 3D trajectory as the input.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "IEEE AIxVR 2025: 7th International Conference on Artificial\n  Intelligence & extended and Virtual Reality",
    "pdf_url": "http://arxiv.org/pdf/2502.04361v1",
    "published_date": "2025-02-05 02:19:23 UTC",
    "updated_date": "2025-02-05 02:19:23 UTC"
  },
  {
    "arxiv_id": "2502.03492v1",
    "title": "Teaching Language Models to Critique via Reinforcement Learning",
    "authors": [
      "Zhihui Xie",
      "Jie chen",
      "Liyu Chen",
      "Weichao Mao",
      "Jingjing Xu",
      "Lingpeng Kong"
    ],
    "abstract": "Teaching large language models (LLMs) to critique and refine their outputs is\ncrucial for building systems that can iteratively improve, yet it is\nfundamentally limited by the ability to provide accurate judgments and\nactionable suggestions. In this work, we study LLM critics for code generation\nand propose $\\texttt{CTRL}$, a framework for $\\texttt{C}$ritic\n$\\texttt{T}$raining via $\\texttt{R}$einforcement $\\texttt{L}$earning, which\ntrains a critic model to generate feedback that maximizes correction\nperformance for a fixed generator model without human supervision. Our results\ndemonstrate that critics trained with $\\texttt{CTRL}$ significantly enhance\npass rates and mitigate compounding errors across both base and stronger\ngenerator models. Furthermore, we show that these critic models act as accurate\ngenerative reward models and enable test-time scaling through iterative\ncritique-revision, achieving up to 106.1% relative improvements across\nchallenging code generation benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03492v1",
    "published_date": "2025-02-05 02:18:46 UTC",
    "updated_date": "2025-02-05 02:18:46 UTC"
  },
  {
    "arxiv_id": "2503.04740v1",
    "title": "PRISM: Perspective Reasoning for Integrated Synthesis and Mediation as a Multi-Perspective Framework for AI Alignment",
    "authors": [
      "Anthony Diamond"
    ],
    "abstract": "In this work, we propose Perspective Reasoning for Integrated Synthesis and\nMediation (PRISM), a multiple-perspective framework for addressing persistent\nchallenges in AI alignment such as conflicting human values and specification\ngaming. Grounded in cognitive science and moral psychology, PRISM organizes\nmoral concerns into seven \"basis worldviews\", each hypothesized to capture a\ndistinct dimension of human moral cognition, ranging from survival-focused\nreflexes through higher-order integrative perspectives. It then applies a\nPareto-inspired optimization scheme to reconcile competing priorities without\nreducing them to a single metric. Under the assumption of reliable context\nvalidation for robust use, the framework follows a structured workflow that\nelicits viewpoint-specific responses, synthesizes them into a balanced outcome,\nand mediates remaining conflicts in a transparent and iterative manner. By\nreferencing layered approaches to moral cognition from cognitive science, moral\npsychology, and neuroscience, PRISM clarifies how different moral drives\ninteract and systematically documents and mediates ethical tradeoffs. We\nillustrate its efficacy through real outputs produced by a working prototype,\napplying PRISM to classic alignment problems in domains such as public health\npolicy, workplace automation, and education. By anchoring AI deliberation in\nthese human vantage points, PRISM aims to bound interpretive leaps that might\notherwise drift into non-human or machine-centric territory. We briefly outline\nfuture directions, including real-world deployments and formal verifications,\nwhile maintaining the core focus on multi-perspective synthesis and conflict\nmediation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "90C29, 68T05",
      "I.2.11; I.2.4"
    ],
    "primary_category": "cs.CY",
    "comment": "104 pages, 5 figures. Preprint on AI alignment presenting PRISM: a\n  multi-perspective framework that organizes moral concerns into seven basis\n  worldviews and uses Pareto-inspired synthesis to reconcile conflicting human\n  values and specification gaming. Grounded in cognitive science and moral\n  psychology",
    "pdf_url": "http://arxiv.org/pdf/2503.04740v1",
    "published_date": "2025-02-05 02:13:57 UTC",
    "updated_date": "2025-02-05 02:13:57 UTC"
  },
  {
    "arxiv_id": "2502.03490v2",
    "title": "Examining Two Hop Reasoning Through Information Content Scaling",
    "authors": [
      "David Johnston",
      "Nora Belrose"
    ],
    "abstract": "Prior work has found that transformers have an inconsistent ability to learn\nto answer latent two-hop questions -- questions of the form \"Who is Bob's\nmother's boss?\" We study why this is the case by examining how transformers'\ncapacity to learn datasets of two-hop questions and answers (two-hop QA) scales\nwith their size, motivated by prior work on transformer knowledge capacity for\nsimple factual memorization. We find that capacity scaling and generalization\nboth support the hypothesis that latent two-hop QA requires transformers to\nlearn each fact twice, while two-hop QA with chain of thought does not. We also\nshow that with appropriate dataset parameters, it is possible to \"trap\" very\nsmall models in a regime where they memorize answers to two-hop questions\nindependently, even though they would perform better if they could learn to\nanswer them with function composition. Our findings show that measurement of\ncapacity scaling can complement existing interpretability methods, though there\nare challenges in using it for this purpose.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03490v2",
    "published_date": "2025-02-05 02:13:04 UTC",
    "updated_date": "2025-03-21 03:49:12 UTC"
  },
  {
    "arxiv_id": "2502.02817v1",
    "title": "A Decade of Action Quality Assessment: Largest Systematic Survey of Trends, Challenges, and Future Directions",
    "authors": [
      "Hao Yin",
      "Paritosh Parmar",
      "Daoliang Xu",
      "Yang Zhang",
      "Tianyou Zheng",
      "Weiwei Fu"
    ],
    "abstract": "Action Quality Assessment (AQA) -- the ability to quantify the quality of\nhuman motion, actions, or skill levels and provide feedback -- has far-reaching\nimplications in areas such as low-cost physiotherapy, sports training, and\nworkforce development. As such, it has become a critical field in computer\nvision & video understanding over the past decade. Significant progress has\nbeen made in AQA methodologies, datasets, & applications, yet a pressing need\nremains for a comprehensive synthesis of this rapidly evolving field. In this\npaper, we present a thorough survey of the AQA landscape, systematically\nreviewing over 200 research papers using the preferred reporting items for\nsystematic reviews & meta-analyses (PRISMA) framework. We begin by covering\nfoundational concepts & definitions, then move to general frameworks &\nperformance metrics, & finally discuss the latest advances in methodologies &\ndatasets. This survey provides a detailed analysis of research trends,\nperformance comparisons, challenges, & future directions. Through this work, we\naim to offer a valuable resource for both newcomers & experienced researchers,\npromoting further exploration & progress in AQA. Data are available at\nhttps://haoyin116.github.io/Survey_of_AQA/",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "36 Pages, 20 Figures, 12 Tables",
    "pdf_url": "http://arxiv.org/pdf/2502.02817v1",
    "published_date": "2025-02-05 01:33:24 UTC",
    "updated_date": "2025-02-05 01:33:24 UTC"
  },
  {
    "arxiv_id": "2502.02810v1",
    "title": "Mol-LLM: Generalist Molecular LLM with Improved Graph Utilization",
    "authors": [
      "Chanhui Lee",
      "Yuheon Song",
      "YongJun Jeong",
      "Hanbum Ko",
      "Rodrigo Hormazabal",
      "Sehui Han",
      "Kyunghoon Bae",
      "Sungbin Lim",
      "Sungwoong Kim"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have motivated the\ndevelopment of general LLMs for molecular tasks. While several studies have\ndemonstrated that fine-tuned LLMs can achieve impressive benchmark\nperformances, they are far from genuine generalist molecular LLMs due to a lack\nof fundamental understanding of molecular structure. Specifically, when given\nmolecular task instructions, LLMs trained with naive next-token prediction\ntraining assign similar likelihood scores to both original and negatively\ncorrupted molecules, revealing their lack of molecular structure understanding\nthat is crucial for reliable and general molecular LLMs. To overcome this\nlimitation and obtain a true generalist molecular LLM, we introduce a novel\nmulti-modal training method based on a thorough multi-modal instruction tuning\nas well as a molecular structure preference optimization between chosen and\nrejected graphs. On various molecular benchmarks, the proposed generalist\nmolecular LLM, called Mol-LLM, achieves state-of-the-art performances among\ngeneralist LLMs on most tasks, at the same time, surpassing or comparable to\nstate-of-the-art specialist LLMs. Moreover, Mol-LLM also shows superior\ngeneralization performances in reaction prediction tasks, demonstrating the\neffect of the molecular structure understanding for generalization perspective.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02810v1",
    "published_date": "2025-02-05 01:14:12 UTC",
    "updated_date": "2025-02-05 01:14:12 UTC"
  },
  {
    "arxiv_id": "2502.02797v1",
    "title": "Upweighting Easy Samples in Fine-Tuning Mitigates Forgetting",
    "authors": [
      "Sunny Sanyal",
      "Hayden Prairie",
      "Rudrajit Das",
      "Ali Kavis",
      "Sujay Sanghavi"
    ],
    "abstract": "Fine-tuning a pre-trained model on a downstream task often degrades its\noriginal capabilities, a phenomenon known as \"catastrophic forgetting\". This is\nespecially an issue when one does not have access to the data and recipe used\nto develop the pre-trained model. Under this constraint, most existing methods\nfor mitigating forgetting are inapplicable. To address this challenge, we\npropose a sample weighting scheme for the fine-tuning data solely based on the\npre-trained model's losses. Specifically, we upweight the easy samples on which\nthe pre-trained model's loss is low and vice versa to limit the drift from the\npre-trained model. Our approach is orthogonal and yet complementary to existing\nmethods; while such methods mostly operate on parameter or gradient space, we\nconcentrate on the sample space. We theoretically analyze the impact of\nfine-tuning with our method in a linear setting, showing that it stalls\nlearning in a certain subspace which inhibits overfitting to the target task.\nWe empirically demonstrate the efficacy of our method on both language and\nvision tasks. As an example, when fine-tuning Gemma 2 2B on MetaMathQA, our\nmethod results in only a $0.8\\%$ drop in accuracy on GSM8K (another math\ndataset) compared to standard fine-tuning, while preserving $5.4\\%$ more\naccuracy on the pre-training datasets. Our code is publicly available at\nhttps://github.com/sanyalsunny111/FLOW_finetuning .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "49 pages, 4 figures, 12 tables. Code available at\n  https://github.com/sanyalsunny111/FLOW_finetuning",
    "pdf_url": "http://arxiv.org/pdf/2502.02797v1",
    "published_date": "2025-02-05 00:49:59 UTC",
    "updated_date": "2025-02-05 00:49:59 UTC"
  },
  {
    "arxiv_id": "2502.02789v2",
    "title": "Speculative Prefill: Turbocharging TTFT with Lightweight and Training-Free Token Importance Estimation",
    "authors": [
      "Jingyu Liu",
      "Beidi Chen",
      "Ce Zhang"
    ],
    "abstract": "Improving time-to-first-token (TTFT) is an essentially important objective in\nmodern large language model (LLM) inference engines. Optimizing TTFT directly\nresults in higher maximal QPS and meets the requirements of many critical\napplications. However, boosting TTFT is notoriously challenging since it is\ncompute-bounded and the performance bottleneck shifts from the self-attention\nthat many prior works focus on to the MLP part. In this work, we present\nSpecPrefill, a training free framework that accelerates the inference TTFT for\nboth long and medium context queries based on the following insight: LLMs are\ngeneralized enough to preserve the quality given only a carefully chosen subset\nof prompt tokens. At its core, SpecPrefill leverages a lightweight model to\nspeculate locally important tokens based on the context. These tokens, along\nwith the necessary positional information, are then sent to the main model for\nprocessing. We evaluate SpecPrefill with a diverse set of tasks, followed by a\ncomprehensive benchmarking of performance improvement both in a real end-to-end\nsetting and ablation studies. SpecPrefill manages to serve\nLlama-3.1-405B-Instruct-FP8 with up to 7$\\times$ maximal end-to-end QPS on real\ndownstream tasks and 7.66$\\times$ TTFT improvement.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Proceedings of the 42nd International Conference on Machine Learning\n  (ICML 2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.02789v2",
    "published_date": "2025-02-05 00:22:06 UTC",
    "updated_date": "2025-05-19 18:24:50 UTC"
  },
  {
    "arxiv_id": "2502.02788v1",
    "title": "Inducing Diversity in Differentiable Search Indexing",
    "authors": [
      "Abhijeet Phatak",
      "Jayant Sachdev",
      "Sean D Rosario",
      "Swati Kirti",
      "Chittaranjan Tripathy"
    ],
    "abstract": "Differentiable Search Indexing (DSI) is a recent paradigm for information\nretrieval which uses a transformer-based neural network architecture as the\ndocument index to simplify the retrieval process. A differentiable index has\nmany advantages enabling modifications, updates or extensions to the index. In\nthis work, we explore balancing relevance and novel information content\n(diversity) for training DSI systems inspired by Maximal Marginal Relevance\n(MMR), and show the benefits of our approach over the naive DSI training. We\npresent quantitative and qualitative evaluations of relevance and diversity\nmeasures obtained using our method on NQ320K and MSMARCO datasets in comparison\nto naive DSI. With our approach, it is possible to achieve diversity without\nany significant impact to relevance. Since we induce diversity while training\nDSI, the trained model has learned to diversify while being relevant. This\nobviates the need for a post-processing step to induce diversity in the recall\nset as typically performed using MMR. Our approach will be useful for\nInformation Retrieval problems where both relevance and diversity are important\nsuch as in sub-topic retrieval. Our work can also be easily be extended to the\nincremental DSI settings which would enable fast updates to the index while\nretrieving a diverse recall set.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.02788v1",
    "published_date": "2025-02-05 00:21:17 UTC",
    "updated_date": "2025-02-05 00:21:17 UTC"
  }
]