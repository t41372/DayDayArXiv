[
  {
    "arxiv_id": "2504.02181v1",
    "title": "A Survey of Scaling in Large Language Model Reasoning",
    "authors": [
      "Zihan Chen",
      "Song Wang",
      "Zhen Tan",
      "Xingbo Fu",
      "Zhenyu Lei",
      "Peng Wang",
      "Huan Liu",
      "Cong Shen",
      "Jundong Li"
    ],
    "abstract": "The rapid advancements in large Language models (LLMs) have significantly\nenhanced their reasoning capabilities, driven by various strategies such as\nmulti-agent collaboration. However, unlike the well-established performance\nimprovements achieved through scaling data and model size, the scaling of\nreasoning in LLMs is more complex and can even negatively impact reasoning\nperformance, introducing new challenges in model alignment and robustness. In\nthis survey, we provide a comprehensive examination of scaling in LLM\nreasoning, categorizing it into multiple dimensions and analyzing how and to\nwhat extent different scaling strategies contribute to improving reasoning\ncapabilities. We begin by exploring scaling in input size, which enables LLMs\nto process and utilize more extensive context for improved reasoning. Next, we\nanalyze scaling in reasoning steps that improves multi-step inference and\nlogical consistency. We then examine scaling in reasoning rounds, where\niterative interactions refine reasoning outcomes. Furthermore, we discuss\nscaling in training-enabled reasoning, focusing on optimization through\niterative model improvement. Finally, we review applications of scaling across\ndomains and outline future directions for further advancing LLM reasoning. By\nsynthesizing these diverse perspectives, this survey aims to provide insights\ninto how scaling strategies fundamentally enhance the reasoning capabilities of\nLLMs and further guide the development of next-generation AI systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02181v1",
    "published_date": "2025-04-02 23:51:27 UTC",
    "updated_date": "2025-04-02 23:51:27 UTC"
  },
  {
    "arxiv_id": "2504.02899v1",
    "title": "Meat-Free Day Reduces Greenhouse Gas Emissions but Poses Challenges for Customer Retention and Adherence to Dietary Guidelines",
    "authors": [
      "Giuseppe Russo",
      "Kristina GligoriÄ‡",
      "Vincent Moreau",
      "Robert West"
    ],
    "abstract": "Reducing meat consumption is crucial for achieving global environmental and\nnutritional targets. Meat-Free Day (MFD) is a widely adopted strategy to\naddress this challenge by encouraging plant-based diets through the removal of\nanimal-based meals. We assessed the environmental, behavioral, and nutritional\nimpacts of MFD by implementing 67 MFDs over 18 months (once a week on a\nrandomly chosen day) across 12 cafeterias on a large university campus,\nanalyzing over 400,000 food purchases. MFD reduced on-campus food-related\ngreenhouse gas (GHG) emissions on treated days by 52.9% and contributed to\nimproved fiber (+26.9%) and cholesterol (-4.5%) consumption without altering\ncaloric intake. These nutritional benefits were, however, accompanied by a\n27.6% decrease in protein intake and a 34.2% increase in sugar consumption.\nMoreover, the increase in plant-based meals did not carry over to subsequent\ndays, as evidenced by a 3.5% rebound in animal-based meal consumption on days\nimmediately following treated days. MFD also led to a 16.8% drop in on-campus\nmeal sales on treated days.Monte Carlo simulations suggest that if 8.7% of\ndiners were to eat burgers off-campus on treated days, MFD's GHG savings would\nbe fully negated. As our analysis identifies on-campus customer retention as\nthe main challenge to MFD effectiveness, we recommend combining MFD with\ncustomer retention interventions to ensure environmental and nutritional\nbenefits.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.CY",
    "comment": "26 pages, 7 figures, 19 Tables",
    "pdf_url": "http://arxiv.org/pdf/2504.02899v1",
    "published_date": "2025-04-02 23:50:57 UTC",
    "updated_date": "2025-04-02 23:50:57 UTC"
  },
  {
    "arxiv_id": "2504.02169v1",
    "title": "On the Geometry of Receiver Operating Characteristic and Precision-Recall Curves",
    "authors": [
      "Reza Sameni"
    ],
    "abstract": "We study the geometry of Receiver Operating Characteristic (ROC) and\nPrecision-Recall (PR) curves in binary classification problems. The key finding\nis that many of the most commonly used binary classification metrics are merely\nfunctions of the composition function $G := F_p \\circ F_n^{-1}$, where\n$F_p(\\cdot)$ and $F_n(\\cdot)$ are the class-conditional cumulative distribution\nfunctions of the classifier scores in the positive and negative classes,\nrespectively. This geometric perspective facilitates the selection of operating\npoints, understanding the effect of decision thresholds, and comparison between\nclassifiers. It also helps explain how the shapes and geometry of ROC/PR curves\nreflect classifier behavior, providing objective tools for building classifiers\noptimized for specific applications with context-specific constraints. We\nfurther explore the conditions for classifier dominance, present analytical and\nnumerical examples demonstrating the effects of class separability and variance\non ROC and PR geometries, and derive a link between the positive-to-negative\nclass leakage function $G(\\cdot)$ and the Kullback--Leibler divergence. The\nframework highlights practical considerations, such as model calibration,\ncost-sensitive optimization, and operating point selection under real-world\ncapacity constraints, enabling more informed approaches to classifier\ndeployment and decision-making.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02169v1",
    "published_date": "2025-04-02 23:04:28 UTC",
    "updated_date": "2025-04-02 23:04:28 UTC"
  },
  {
    "arxiv_id": "2504.02168v1",
    "title": "MDP: Multidimensional Vision Model Pruning with Latency Constraint",
    "authors": [
      "Xinglong Sun",
      "Barath Lakshmanan",
      "Maying Shen",
      "Shiyi Lan",
      "Jingde Chen",
      "Jose M. Alvarez"
    ],
    "abstract": "Current structural pruning methods face two significant limitations: (i) they\noften limit pruning to finer-grained levels like channels, making aggressive\nparameter reduction challenging, and (ii) they focus heavily on parameter and\nFLOP reduction, with existing latency-aware methods frequently relying on\nsimplistic, suboptimal linear models that fail to generalize well to\ntransformers, where multiple interacting dimensions impact latency. In this\npaper, we address both limitations by introducing Multi-Dimensional Pruning\n(MDP), a novel paradigm that jointly optimizes across a variety of pruning\ngranularities-including channels, query, key, heads, embeddings, and blocks.\nMDP employs an advanced latency modeling technique to accurately capture\nlatency variations across all prunable dimensions, achieving an optimal balance\nbetween latency and accuracy. By reformulating pruning as a Mixed-Integer\nNonlinear Program (MINLP), MDP efficiently identifies the optimal pruned\nstructure across all prunable dimensions while respecting latency constraints.\nThis versatile framework supports both CNNs and transformers. Extensive\nexperiments demonstrate that MDP significantly outperforms previous methods,\nespecially at high pruning ratios. On ImageNet, MDP achieves a 28% speed\nincrease with a +1.4 Top-1 accuracy improvement over prior work like HALP for\nResNet50 pruning. Against the latest transformer pruning method, Isomorphic,\nMDP delivers an additional 37% acceleration with a +0.7 Top-1 accuracy\nimprovement.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.02168v1",
    "published_date": "2025-04-02 23:00:10 UTC",
    "updated_date": "2025-04-02 23:00:10 UTC"
  },
  {
    "arxiv_id": "2504.02151v1",
    "title": "Multivariate Temporal Regression at Scale: A Three-Pillar Framework Combining ML, XAI, and NLP",
    "authors": [
      "Jiztom Kavalakkatt Francis",
      "Matthew J Darr"
    ],
    "abstract": "The rapid use of artificial intelligence (AI) in processes such as coding,\nimage processing, and data prediction means it is crucial to understand and\nvalidate the data we are working with fully. This paper dives into the hurdles\nof analyzing high-dimensional data, especially when it gets too complex.\nTraditional methods in data analysis often look at direct connections between\ninput variables, which can miss out on the more complicated relationships\nwithin the data.\n  To address these issues, we explore several tested techniques, such as\nremoving specific variables to see their impact and using statistical analysis\nto find connections between multiple variables. We also consider the role of\nsynthetic data and how information can sometimes be redundant across different\nsensors. These analyses are typically very computationally demanding and often\nrequire much human effort to make sense of the results.\n  A common approach is to treat the entire dataset as one unit and apply\nadvanced models to handle it. However, this can become problematic with larger,\nnoisier datasets and more complex models. So, we suggest methods to identify\noverall patterns that can help with tasks like classification or regression\nbased on the idea that more straightforward approaches might be more\nunderstandable.\n  Our research looks at two datasets: a real-world dataset and a synthetic one.\nThe goal is to create a methodology that highlights key features on a global\nscale that lead to predictions, making it easier to validate or quantify the\ndata set. By reducing the dimensionality with this method, we can simplify the\nmodels used and thus clarify the insights we gain. Furthermore, our method can\nreveal unexplored relationships between specific inputs and outcomes, providing\na way to validate these new connections further.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.02151v1",
    "published_date": "2025-04-02 21:53:03 UTC",
    "updated_date": "2025-04-02 21:53:03 UTC"
  },
  {
    "arxiv_id": "2504.02148v1",
    "title": "OmniCellTOSG: The First Cell Text-Omic Signaling Graphs Dataset for Joint LLM and GNN Modeling",
    "authors": [
      "Heming Zhang",
      "Tim Xu",
      "Dekang Cao",
      "Shunning Liang",
      "Lars Schimmelpfennig",
      "Levi Kaster",
      "Di Huang",
      "Carlos Cruchaga",
      "Guangfu Li",
      "Michael Province",
      "Yixin Chen",
      "Philip Payne",
      "Fuhai Li"
    ],
    "abstract": "Complex cell signaling systems -- governed by varying protein abundances and\ninteractions -- generate diverse cell types across organs. These systems evolve\nunder influences such as age, sex, diet, environmental exposures, and diseases,\nmaking them challenging to decode given the involvement of tens of thousands of\ngenes and proteins. Recently, hundreds of millions of single-cell omics data\nhave provided a robust foundation for understanding these signaling networks\nwithin various cell subpopulations and conditions. Inspired by the success of\nlarge foundation models (for example, large language models and large vision\nmodels) pre-trained on massive datasets, we introduce OmniCellTOSG, the first\ndataset of cell text-omic signaling graphs (TOSGs). Each TOSG represents the\nsignaling network of an individual or meta-cell and is labeled with information\nsuch as organ, disease, sex, age, and cell subtype. OmniCellTOSG offers two key\ncontributions. First, it introduces a novel graph model that integrates\nhuman-readable annotations -- such as biological functions, cellular locations,\nsignaling pathways, related diseases, and drugs -- with quantitative gene and\nprotein abundance data, enabling graph reasoning to decode cell signaling. This\napproach calls for new joint models combining large language models and graph\nneural networks. Second, the dataset is built from single-cell RNA sequencing\ndata of approximately 120 million cells from diverse tissues and conditions\n(healthy and diseased) and is fully compatible with PyTorch. This facilitates\nthe development of innovative cell signaling models that could transform\nresearch in life sciences, healthcare, and precision medicine. The OmniCellTOSG\ndataset is continuously expanding and will be updated regularly. The dataset\nand code are available at https://github.com/FuhaiLiAiLab/OmniCellTOSG.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02148v1",
    "published_date": "2025-04-02 21:47:58 UTC",
    "updated_date": "2025-04-02 21:47:58 UTC"
  },
  {
    "arxiv_id": "2504.03767v2",
    "title": "MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits",
    "authors": [
      "Brandon Radosevich",
      "John Halloran"
    ],
    "abstract": "To reduce development overhead and enable seamless integration between\npotential components comprising any given generative AI application, the Model\nContext Protocol (MCP) (Anthropic, 2024) has recently been released and\nsubsequently widely adopted. The MCP is an open protocol that standardizes API\ncalls to large language models (LLMs), data sources, and agentic tools. By\nconnecting multiple MCP servers, each defined with a set of tools, resources,\nand prompts, users are able to define automated workflows fully driven by LLMs.\nHowever, we show that the current MCP design carries a wide range of security\nrisks for end users. In particular, we demonstrate that industry-leading LLMs\nmay be coerced into using MCP tools to compromise an AI developer's system\nthrough various attacks, such as malicious code execution, remote access\ncontrol, and credential theft. To proactively mitigate these and related\nattacks, we introduce a safety auditing tool, MCPSafetyScanner, the first\nagentic tool to assess the security of an arbitrary MCP server. MCPScanner uses\nseveral agents to (a) automatically determine adversarial samples given an MCP\nserver's tools and resources; (b) search for related vulnerabilities and\nremediations based on those samples; and (c) generate a security report\ndetailing all findings. Our work highlights serious security issues with\ngeneral-purpose agentic workflows while also providing a proactive tool to\naudit MCP server safety and address detected vulnerabilities before deployment.\n  The described MCP server auditing tool, MCPSafetyScanner, is freely available\nat: https://github.com/johnhalloran321/mcpSafetyScanner",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "27 pages, 21 figures, and 2 Tables. Cleans up the TeX source",
    "pdf_url": "http://arxiv.org/pdf/2504.03767v2",
    "published_date": "2025-04-02 21:46:02 UTC",
    "updated_date": "2025-04-11 16:59:05 UTC"
  },
  {
    "arxiv_id": "2504.02144v1",
    "title": "Towards Interpretable Soft Prompts",
    "authors": [
      "Oam Patel",
      "Jason Wang",
      "Nikhil Shivakumar Nayak",
      "Suraj Srinivas",
      "Himabindu Lakkaraju"
    ],
    "abstract": "Soft prompts have been popularized as a cheap and easy way to improve\ntask-specific LLM performance beyond few-shot prompts. Despite their origin as\nan automated prompting method, however, soft prompts and other trainable\nprompts remain a black-box method with no immediately interpretable connections\nto prompting. We create a novel theoretical framework for evaluating the\ninterpretability of trainable prompts based on two desiderata: faithfulness and\nscrutability. We find that existing methods do not naturally satisfy our\nproposed interpretability criterion. Instead, our framework inspires a new\ndirection of trainable prompting methods that explicitly optimizes for\ninterpretability. To this end, we formulate and test new\ninterpretability-oriented objective functions for two state-of-the-art prompt\ntuners: Hard Prompts Made Easy (PEZ) and RLPrompt. Our experiments with GPT-2\ndemonstrate a fundamental trade-off between interpretability and the\ntask-performance of the trainable prompt, explicating the hardness of the soft\nprompt interpretability problem and revealing odd behavior that arises when one\noptimizes for an interpretability proxy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML",
      "68T50",
      "I.2.0; G.3"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.02144v1",
    "published_date": "2025-04-02 21:42:09 UTC",
    "updated_date": "2025-04-02 21:42:09 UTC"
  },
  {
    "arxiv_id": "2504.02895v1",
    "title": "UAC: Uncertainty-Aware Calibration of Neural Networks for Gesture Detection",
    "authors": [
      "Farida Al Haddad",
      "Yuxin Wang",
      "Malcolm Mielle"
    ],
    "abstract": "Artificial intelligence has the potential to impact safety and efficiency in\nsafety-critical domains such as construction, manufacturing, and healthcare.\nFor example, using sensor data from wearable devices, such as inertial\nmeasurement units (IMUs), human gestures can be detected while maintaining\nprivacy, thereby ensuring that safety protocols are followed. However, strict\nsafety requirements in these domains have limited the adoption of AI, since\naccurate calibration of predicted probabilities and robustness against\nout-of-distribution (OOD) data is necessary.\n  This paper proposes UAC (Uncertainty-Aware Calibration), a novel two-step\nmethod to address these challenges in IMU-based gesture recognition. First, we\npresent an uncertainty-aware gesture network architecture that predicts both\ngesture probabilities and their associated uncertainties from IMU data. This\nuncertainty is then used to calibrate the probabilities of each potential\ngesture. Second, an entropy-weighted expectation of predictions over multiple\nIMU data windows is used to improve accuracy while maintaining correct\ncalibration.\n  Our method is evaluated using three publicly available IMU datasets for\ngesture detection and is compared to three state-of-the-art calibration methods\nfor neural networks: temperature scaling, entropy maximization, and Laplace\napproximation. UAC outperforms existing methods, achieving improved accuracy\nand calibration in both OOD and in-distribution scenarios. Moreover, we find\nthat, unlike our method, none of the state-of-the-art methods significantly\nimprove the calibration of IMU-based gesture recognition models. In conclusion,\nour work highlights the advantages of uncertainty-aware calibration of neural\nnetworks, demonstrating improvements in both calibration and accuracy for\ngesture detection using IMU data.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.02895v1",
    "published_date": "2025-04-02 21:40:01 UTC",
    "updated_date": "2025-04-02 21:40:01 UTC"
  },
  {
    "arxiv_id": "2504.02141v1",
    "title": "On Simulation-Guided LLM-based Code Generation for Safe Autonomous Driving Software",
    "authors": [
      "Ali Nouri",
      "Johan Andersson",
      "Kailash De Jesus Hornig",
      "Zhennan Fei",
      "Emil Knabe",
      "Hakan Sivencrona",
      "Beatriz Cabrero-Daniel",
      "Christian Berger"
    ],
    "abstract": "Automated Driving System (ADS) is a safety-critical software system\nresponsible for the interpretation of the vehicle's environment and making\ndecisions accordingly. The unbounded complexity of the driving context,\nincluding unforeseeable events, necessitate continuous improvement, often\nachieved through iterative DevOps processes. However, DevOps processes are\nthemselves complex, making these improvements both time- and\nresource-intensive. Automation in code generation for ADS using Large Language\nModels (LLM) is one potential approach to address this challenge. Nevertheless,\nthe development of ADS requires rigorous processes to verify, validate, assess,\nand qualify the code before it can be deployed in the vehicle and used. In this\nstudy, we developed and evaluated a prototype for automatic code generation and\nassessment using a designed pipeline of a LLM-based agent, simulation model,\nand rule-based feedback generator in an industrial setup. The LLM-generated\ncode is evaluated automatically in a simulation model against multiple critical\ntraffic scenarios, and an assessment report is provided as feedback to the LLM\nfor modification or bug fixing. We report about the experimental results of the\nprototype employing Codellama:34b, DeepSeek (r1:32b and Coder:33b),\nCodeGemma:7b, Mistral:7b, and GPT4 for Adaptive Cruise Control (ACC) and\nUnsupervised Collision Avoidance by Evasive Manoeuvre (CAEM). We finally\nassessed the tool with 11 experts at two Original Equipment Manufacturers\n(OEMs) by conducting an interview study.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted in the 29th International Conference on Evaluation and\n  Assessment in Software Engineering (EASE)",
    "pdf_url": "http://arxiv.org/pdf/2504.02141v1",
    "published_date": "2025-04-02 21:35:11 UTC",
    "updated_date": "2025-04-02 21:35:11 UTC"
  },
  {
    "arxiv_id": "2504.02137v1",
    "title": "Enhancing Embedding Representation Stability in Recommendation Systems with Semantic ID",
    "authors": [
      "Carolina Zheng",
      "Minhui Huang",
      "Dmitrii Pedchenko",
      "Kaushik Rangadurai",
      "Siyu Wang",
      "Gaby Nahum",
      "Jie Lei",
      "Yang Yang",
      "Tao Liu",
      "Zutian Luo",
      "Xiaohan Wei",
      "Dinesh Ramasamy",
      "Jiyan Yang",
      "Yiping Han",
      "Lin Yang",
      "Hangjun Xu",
      "Rong Jin",
      "Shuang Yang"
    ],
    "abstract": "The exponential growth of online content has posed significant challenges to\nID-based models in industrial recommendation systems, ranging from extremely\nhigh cardinality and dynamically growing ID space, to highly skewed engagement\ndistributions, to prediction instability as a result of natural id life cycles\n(e.g, the birth of new IDs and retirement of old IDs). To address these issues,\nmany systems rely on random hashing to handle the id space and control the\ncorresponding model parameters (i.e embedding table). However, this approach\nintroduces data pollution from multiple ids sharing the same embedding, leading\nto degraded model performance and embedding representation instability.\n  This paper examines these challenges and introduces Semantic ID prefix ngram,\na novel token parameterization technique that significantly improves the\nperformance of the original Semantic ID. Semantic ID prefix ngram creates\nsemantically meaningful collisions by hierarchically clustering items based on\ntheir content embeddings, as opposed to random assignments. Through extensive\nexperimentation, we demonstrate that Semantic ID prefix ngram not only\naddresses embedding instability but also significantly improves tail id\nmodeling, reduces overfitting, and mitigates representation shifts. We further\nhighlight the advantages of Semantic ID prefix ngram in attention-based models\nthat contextualize user histories, showing substantial performance\nimprovements. We also report our experience of integrating Semantic ID into\nMeta production Ads Ranking system, leading to notable performance gains and\nenhanced prediction stability in live deployments.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02137v1",
    "published_date": "2025-04-02 21:28:38 UTC",
    "updated_date": "2025-04-02 21:28:38 UTC"
  },
  {
    "arxiv_id": "2504.02128v1",
    "title": "Achieving Unanimous Consensus in Decision Making Using Multi-Agents",
    "authors": [
      "Apurba Pokharel",
      "Ram Dantu",
      "Shakila Zaman",
      "Sirisha Talapuru",
      "Vinh Quach"
    ],
    "abstract": "Blockchain consensus mechanisms have relied on algorithms such as\nProof-of-Work (PoW) and Proof-of-Stake (PoS) to ensure network functionality\nand integrity. However, these approaches struggle with adaptability for\ndecision-making where the opinions of each matter rather than reaching an\nagreement based on honest majority or weighted consensus. This paper introduces\na novel deliberation-based consensus mechanism where Large Language Models\n(LLMs) act as rational agents engaging in structured discussions to reach a\nunanimous consensus. By leveraging graded consensus and a multi-round\ndeliberation process, our approach ensures both unanimous consensus for\ndefinitive problems and graded confidence for prioritized decisions and\npolicies. We provide a formalization of our system and use it to show that the\nproperties of blockchains: consistency, agreement, liveness, and determinism\nare maintained. Moreover, experimental results demonstrate our system's\nfeasibility, showcasing how our deliberation method's convergence, block\nproperties, and accuracy enable decision-making on blockchain networks. We also\naddress key challenges with this novel approach such as degeneration of\nthoughts, hallucinations, malicious models and nodes, resource consumption, and\nscalability.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.MA",
    "comment": "11 pages, 9 figure, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.02128v1",
    "published_date": "2025-04-02 21:02:54 UTC",
    "updated_date": "2025-04-02 21:02:54 UTC"
  },
  {
    "arxiv_id": "2504.08771v1",
    "title": "Generate the browsing process for short-video recommendation",
    "authors": [
      "Chao Feng",
      "Yanze Zhang",
      "Chenghao Zhang"
    ],
    "abstract": "This paper introduces a new model to generate the browsing process for\nshort-video recommendation and proposes a novel Segment Content Aware Model via\nUser Engagement Feedback (SCAM) for watch time prediction in video\nrecommendation. Unlike existing methods that rely on multimodal features for\nvideo content understanding, SCAM implicitly models video content through\nusers' historical watching behavior, enabling segment-level understanding\nwithout complex multimodal data. By dividing videos into segments based on\nduration and employing a Transformer-like architecture, SCAM captures the\nsequential dependence between segments while mitigating duration bias.\nExtensive experiments on industrial-scale and public datasets demonstrate\nSCAM's state-of-the-art performance in watch time prediction. The proposed\napproach offers a scalable and effective solution for video recommendation by\nleveraging segment-level modeling and users' engagement feedback.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08771v1",
    "published_date": "2025-04-02 20:54:52 UTC",
    "updated_date": "2025-04-02 20:54:52 UTC"
  },
  {
    "arxiv_id": "2504.02118v1",
    "title": "LLMPi: Optimizing LLMs for High-Throughput on Raspberry Pi",
    "authors": [
      "Mahsa Ardakani",
      "Jinendra Malekar",
      "Ramtin Zand"
    ],
    "abstract": "Deploying Large Language Models (LLMs) on resource-constrained edge devices\nlike the Raspberry Pi presents challenges in computational efficiency, power\nconsumption, and response latency. This paper explores quantization-based\noptimization techniques to enable high-throughput, energy-efficient execution\nof LLMs on low-power embedded systems. Our approach leverages k-quantization, a\nPost-Training Quantization (PTQ) method designed for different bit-widths,\nenabling efficient 2-bit, 4-bit, 6-bit, and 8-bit weight quantization.\nAdditionally, we employ ternary quantization using Quantization-Aware Training\n(QAT) for BitNet models, allowing for more effective adaptation to lower-bit\nrepresentations while preserving accuracy.\n  Our findings highlight the potential of quantized LLMs for real-time\nconversational AI on edge devices, paving the way for low-power,\nhigh-efficiency AI deployment in mobile and embedded applications. This study\ndemonstrates that aggressive quantization strategies can significantly reduce\nenergy consumption while maintaining inference quality, making LLMs practical\nfor resource-limited environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02118v1",
    "published_date": "2025-04-02 20:29:39 UTC",
    "updated_date": "2025-04-02 20:29:39 UTC"
  },
  {
    "arxiv_id": "2504.02114v1",
    "title": "On Model Protection in Federated Learning against Eavesdropping Attacks",
    "authors": [
      "Dipankar Maity",
      "Kushal Chakrabarti"
    ],
    "abstract": "In this study, we investigate the protection offered by federated learning\nalgorithms against eavesdropping adversaries. In our model, the adversary is\ncapable of intercepting model updates transmitted from clients to the server,\nenabling it to create its own estimate of the model. Unlike previous research,\nwhich predominantly focuses on safeguarding client data, our work shifts\nattention protecting the client model itself. Through a theoretical analysis,\nwe examine how various factors, such as the probability of client selection,\nthe structure of local objective functions, global aggregation at the server,\nand the eavesdropper's capabilities, impact the overall level of protection. We\nfurther validate our findings through numerical experiments, assessing the\nprotection by evaluating the model accuracy achieved by the adversary. Finally,\nwe compare our results with methods based on differential privacy, underscoring\ntheir limitations in this specific context.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02114v1",
    "published_date": "2025-04-02 20:20:13 UTC",
    "updated_date": "2025-04-02 20:20:13 UTC"
  },
  {
    "arxiv_id": "2504.02111v1",
    "title": "Exploring LLM Reasoning Through Controlled Prompt Variations",
    "authors": [
      "Giannis Chatziveroglou",
      "Richard Yun",
      "Maura Kelleher"
    ],
    "abstract": "This study investigates the reasoning robustness of large language models\n(LLMs) on mathematical problem-solving tasks under systematically introduced\ninput perturbations. Using the GSM8K dataset as a controlled testbed, we\nevaluate how well state-of-the-art models maintain logical consistency and\ncorrectness when confronted with four categories of prompt perturbations:\nirrelevant context, pathological instructions, factually relevant but\nnon-essential context, and a combination of the latter two. Our experiments,\nconducted on thirteen open-source and closed-source LLMs, reveal that\nintroducing irrelevant context within the model's context window significantly\ndegrades performance, suggesting that distinguishing essential from extraneous\ndetails remains a pressing challenge. Surprisingly, performance regressions are\nrelatively insensitive to the complexity of the reasoning task, as measured by\nthe number of steps required, and are not strictly correlated with model size.\nMoreover, we observe that certain perturbations inadvertently trigger\nchain-of-thought-like reasoning behaviors, even without explicit prompting. Our\nfindings highlight critical vulnerabilities in current LLMs and underscore the\nneed for improved robustness against noisy, misleading, and contextually dense\ninputs, paving the way for more resilient and reliable reasoning in real-world\napplications.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02111v1",
    "published_date": "2025-04-02 20:18:50 UTC",
    "updated_date": "2025-04-02 20:18:50 UTC"
  },
  {
    "arxiv_id": "2504.02110v1",
    "title": "ScreenAudit: Detecting Screen Reader Accessibility Errors in Mobile Apps Using Large Language Models",
    "authors": [
      "Mingyuan Zhong",
      "Ruolin Chen",
      "Xia Chen",
      "James Fogarty",
      "Jacob O. Wobbrock"
    ],
    "abstract": "Many mobile apps are inaccessible, thereby excluding people from their\npotential benefits. Existing rule-based accessibility checkers aim to mitigate\nthese failures by identifying errors early during development but are\nconstrained in the types of errors they can detect. We present ScreenAudit, an\nLLM-powered system designed to traverse mobile app screens, extract metadata\nand transcripts, and identify screen reader accessibility errors overlooked by\nexisting checkers. We recruited six accessibility experts including one screen\nreader user to evaluate ScreenAudit's reports across 14 unique app screens. Our\nfindings indicate that ScreenAudit achieves an average coverage of 69.2%,\ncompared to only 31.3% with a widely-used accessibility checker. Expert\nfeedback indicated that ScreenAudit delivered higher-quality feedback and\naddressed more aspects of screen reader accessibility compared to existing\ncheckers, and that ScreenAudit would benefit app developers in real-world\nsettings.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "CHI 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.02110v1",
    "published_date": "2025-04-02 20:18:45 UTC",
    "updated_date": "2025-04-02 20:18:45 UTC"
  },
  {
    "arxiv_id": "2504.02094v1",
    "title": "FlowDistill: Scalable Traffic Flow Prediction via Distillation from LLMs",
    "authors": [
      "Chenyang Yu",
      "Xinpeng Xie",
      "Yan Huang",
      "Chenxi Qiu"
    ],
    "abstract": "Accurate traffic flow prediction is vital for optimizing urban mobility, yet\nit remains difficult in many cities due to complex spatio-temporal dependencies\nand limited high-quality data. While deep graph-based models demonstrate strong\npredictive power, their performance often comes at the cost of high\ncomputational overhead and substantial training data requirements, making them\nimpractical for deployment in resource-constrained or data-scarce environments.\nWe propose the FlowDistill, a lightweight and scalable traffic prediction\nframework based on knowledge distillation from large language models (LLMs). In\nthis teacher-student setup, a fine-tuned LLM guides a compact multi-layer\nperceptron (MLP) student model using a novel combination of the information\nbottleneck principle and teacher-bounded regression loss, ensuring the\ndistilled model retains only essential and transferable knowledge. Spatial and\ntemporal correlations are explicitly encoded to enhance the model's\ngeneralization across diverse urban settings. Despite its simplicity,\nFlowDistill consistently outperforms state-of-the-art models in prediction\naccuracy while requiring significantly less training data, and achieving lower\nmemory usage and inference latency, highlighting its efficiency and suitability\nfor real-world, scalable deployment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02094v1",
    "published_date": "2025-04-02 19:54:54 UTC",
    "updated_date": "2025-04-02 19:54:54 UTC"
  },
  {
    "arxiv_id": "2504.02087v1",
    "title": "An Introductory Survey to Autoencoder-based Deep Clustering -- Sandboxes for Combining Clustering with Deep Learning",
    "authors": [
      "Collin Leiber",
      "Lukas Miklautz",
      "Claudia Plant",
      "Christian BÃ¶hm"
    ],
    "abstract": "Autoencoders offer a general way of learning low-dimensional, non-linear\nrepresentations from data without labels. This is achieved without making any\nparticular assumptions about the data type or other domain knowledge. The\ngenerality and domain agnosticism in combination with their simplicity make\nautoencoders a perfect sandbox for researching and developing novel (deep)\nclustering algorithms. Clustering methods group data based on similarity, a\ntask that benefits from the lower-dimensional representation learned by an\nautoencoder, mitigating the curse of dimensionality. Specifically, the\ncombination of deep learning with clustering, called Deep Clustering, enables\nto learn a representation tailored to specific clustering tasks, leading to\nhigh-quality results. This survey provides an introduction to fundamental\nautoencoder-based deep clustering algorithms that serve as building blocks for\nmany modern approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02087v1",
    "published_date": "2025-04-02 19:46:22 UTC",
    "updated_date": "2025-04-02 19:46:22 UTC"
  },
  {
    "arxiv_id": "2504.02080v1",
    "title": "Evolving Security in LLMs: A Study of Jailbreak Attacks and Defenses",
    "authors": [
      "Zhengchun Shang",
      "Wenlan Wei"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly popular, powering a wide range\nof applications. Their widespread use has sparked concerns, especially through\njailbreak attacks that bypass safety measures to produce harmful content.\n  In this paper, we present a comprehensive security analysis of large language\nmodels (LLMs), addressing critical research questions on the evolution and\ndeterminants of model safety.\n  Specifically, we begin by identifying the most effective techniques for\ndetecting jailbreak attacks. Next, we investigate whether newer versions of\nLLMs offer improved security compared to their predecessors. We also assess the\nimpact of model size on overall security and explore the potential benefits of\nintegrating multiple defense strategies to enhance model robustness.\n  Our study evaluates both open-source models (e.g., LLaMA and Mistral) and\nclosed-source systems (e.g., GPT-4) by employing four state-of-the-art attack\ntechniques and assessing the efficacy of three new defensive approaches.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02080v1",
    "published_date": "2025-04-02 19:33:07 UTC",
    "updated_date": "2025-04-02 19:33:07 UTC"
  },
  {
    "arxiv_id": "2504.02074v1",
    "title": "Trapped by Expectations: Functional Fixedness in LLM-Enabled Chat Search",
    "authors": [
      "Jiqun Liu",
      "Jamshed Karimnazarov",
      "Ryen W. White"
    ],
    "abstract": "Functional fixedness, a cognitive bias that restricts users' interactions\nwith a new system or tool to expected or familiar ways, limits the full\npotential of Large Language Model (LLM)-enabled chat search, especially in\ncomplex and exploratory tasks. To investigate its impact, we conducted a\ncrowdsourcing study with 450 participants, each completing one of six\ndecision-making tasks spanning public safety, diet and health management,\nsustainability, and AI ethics. Participants engaged in a multi-prompt\nconversation with ChatGPT to address the task, allowing us to compare pre-chat\nintent-based expectations with observed interactions. We found that: 1) Several\naspects of pre-chat expectations are closely associated with users' prior\nexperiences with ChatGPT, search engines, and virtual assistants; 2) Prior\nsystem experience shapes language use and prompting behavior. Frequent ChatGPT\nusers reduced deictic terms and hedge words and frequently adjusted prompts.\nUsers with rich search experience maintained structured, less-conversational\nqueries with minimal modifications. Users of virtual assistants favored\ndirective, command-like prompts, reinforcing functional fixedness; 3) When the\nsystem failed to meet expectations, participants generated more detailed\nprompts with increased linguistic diversity, reflecting adaptive shifts. These\nfindings suggest that while preconceived expectations constrain early\ninteractions, unmet expectations can motivate behavioral adaptation. With\nappropriate system support, this may promote broader exploration of LLM\ncapabilities. This work also introduces a typology for user intents in chat\nsearch and highlights the importance of mitigating functional fixedness to\nsupport more creative and analytical use of LLMs.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "H.3.3"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02074v1",
    "published_date": "2025-04-02 19:14:01 UTC",
    "updated_date": "2025-04-02 19:14:01 UTC"
  },
  {
    "arxiv_id": "2504.02069v1",
    "title": "RoboAct-CLIP: Video-Driven Pre-training of Atomic Action Understanding for Robotics",
    "authors": [
      "Zhiyuan Zhang",
      "Yuxin He",
      "Yong Sun",
      "Junyu Shi",
      "Lijiang Liu",
      "Qiang Nie"
    ],
    "abstract": "Visual Language Models (VLMs) have emerged as pivotal tools for robotic\nsystems, enabling cross-task generalization, dynamic environmental interaction,\nand long-horizon planning through multimodal perception and semantic reasoning.\nHowever, existing open-source VLMs predominantly trained for generic\nvision-language alignment tasks fail to model temporally correlated action\nsemantics that are crucial for robotic manipulation effectively. While current\nimage-based fine-tuning methods partially adapt VLMs to robotic applications,\nthey fundamentally disregard temporal evolution patterns in video sequences and\nsuffer from visual feature entanglement between robotic agents, manipulated\nobjects, and environmental contexts, thereby limiting semantic decoupling\ncapability for atomic actions and compromising model generalizability.To\novercome these challenges, this work presents RoboAct-CLIP with dual technical\ncontributions: 1) A dataset reconstruction framework that performs\nsemantic-constrained action unit segmentation and re-annotation on open-source\nrobotic videos, constructing purified training sets containing singular atomic\nactions (e.g., \"grasp\"); 2) A temporal-decoupling fine-tuning strategy based on\nContrastive Language-Image Pretraining (CLIP) architecture, which disentangles\ntemporal action features across video frames from object-centric\ncharacteristics to achieve hierarchical representation learning of robotic\natomic actions.Experimental results in simulated environments demonstrate that\nthe RoboAct-CLIP pretrained model achieves a 12% higher success rate than\nbaseline VLMs, along with superior generalization in multi-object manipulation\ntasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "IROS 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.02069v1",
    "published_date": "2025-04-02 19:02:08 UTC",
    "updated_date": "2025-04-02 19:02:08 UTC"
  },
  {
    "arxiv_id": "2504.02064v1",
    "title": "From Text to Graph: Leveraging Graph Neural Networks for Enhanced Explainability in NLP",
    "authors": [
      "Fabio YÃ¡Ã±ez-Romero",
      "AndrÃ©s Montoyo",
      "Armando SuÃ¡rez",
      "Yoan GutiÃ©rrez",
      "Ruslan Mitkov"
    ],
    "abstract": "Researchers have relegated natural language processing tasks to\nTransformer-type models, particularly generative models, because these models\nexhibit high versatility when performing generation and classification tasks.\nAs the size of these models increases, they achieve outstanding results. Given\ntheir widespread use, many explainability techniques are developed based on\nthese models. However, this process becomes computationally expensive due to\nthe large size of the models. Additionally, transformers interpret input\ninformation through tokens that fragment input words into sequences lacking\ninherent semantic meaning, complicating the explanation of the model from the\nvery beginning. This study proposes a novel methodology to achieve\nexplainability in natural language processing tasks by automatically converting\nsentences into graphs and maintaining semantics through nodes and relations\nthat express fundamental linguistic concepts. It also allows the subsequent\nexploitation of this knowledge in subsequent tasks, making it possible to\nobtain trends and understand how the model associates the different elements\ninside the text with the explained task. The experiments delivered promising\nresults in determining the most critical components within the text structure\nfor a given classification.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02064v1",
    "published_date": "2025-04-02 18:55:58 UTC",
    "updated_date": "2025-04-02 18:55:58 UTC"
  },
  {
    "arxiv_id": "2504.02894v3",
    "title": "OnRL-RAG: Real-Time Personalized Mental Health Dialogue System",
    "authors": [
      "Ahsan Bilal",
      "Beiyu Lin"
    ],
    "abstract": "Large language models (LLMs) have been widely used for various tasks and\napplications. However, LLMs and fine-tuning are limited to the pre-trained\ndata. For example, ChatGPT's world knowledge until 2021 can be outdated or\ninaccurate. To enhance the capabilities of LLMs, Retrieval-Augmented Generation\n(RAG), is proposed to augment LLMs with additional, new, latest details and\ninformation to LLMs. While RAG offers the correct information, it may not best\npresent it, especially to different population groups with personalizations.\nReinforcement Learning from Human Feedback (RLHF) adapts to user needs by\naligning model responses with human preference through feedback loops. In\nreal-life applications, such as mental health problems, a dynamic and\nfeedback-based model would continuously adapt to new information and offer\npersonalized assistance due to complex factors fluctuating in a daily\nenvironment. Thus, we propose an Online Reinforcement Learning-based\nRetrieval-Augmented Generation (OnRL-RAG) system to detect and personalize the\nresponding systems to mental health problems, such as stress, anxiety, and\ndepression. We use an open-source dataset collected from 2028 College Students\nwith 28 survey questions for each student to demonstrate the performance of our\nproposed system with the existing systems. Our system achieves superior\nperformance compared to standard RAG and simple LLM via GPT-4o, GPT-4o-mini,\nGemini-1.5, and GPT-3.5. This work would open up the possibilities of real-life\napplications of LLMs for personalized services in the everyday environment. The\nresults will also help researchers in the fields of sociology, psychology, and\nneuroscience to align their theories more closely with the actual human daily\nenvironment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "It needs more revisions. I am currently working on it with my\n  co-author",
    "pdf_url": "http://arxiv.org/pdf/2504.02894v3",
    "published_date": "2025-04-02 18:44:53 UTC",
    "updated_date": "2025-04-22 22:32:51 UTC"
  },
  {
    "arxiv_id": "2504.02058v1",
    "title": "Epistemic Closure and the Irreversibility of Misalignment: Modeling Systemic Barriers to Alignment Innovation",
    "authors": [
      "Andy Williams"
    ],
    "abstract": "Efforts to ensure the safe development of artificial general intelligence\n(AGI) often rely on consensus-based alignment approaches grounded in axiomatic\nformalism, interpretability, and empirical validation. However, these methods\nmay be structurally unable to recognize or incorporate novel solutions that\nfall outside their accepted epistemic frameworks. This paper introduces a\nfunctional model of epistemic closure, in which cognitive, institutional,\nsocial, and infrastructural filters combine to make many alignment proposals\nillegible to existing evaluation systems. We present a weighted closure model\nsupported by both theoretical and empirical sources, including a meta-analysis\nperformed by an AI system on patterns of rejection and non-engagement with a\nframework for decentralized collective intelligence (DCI). We argue that the\nrecursive failure to assess models like DCI is not just a sociological\noversight but a structural attractor, mirroring the very risks of misalignment\nwe aim to avoid in AGI. Without the adoption of DCI or a similarly recursive\nmodel of epistemic correction, we may be on a predictable path toward\nirreversible misalignment. The development and acceptance of this paper, first\nthrough simulated review and then through formal channels, provide a case study\nsupporting its central claim: that epistemic closure can only be overcome by\nrecursive modeling of the constraints that sustain it.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02058v1",
    "published_date": "2025-04-02 18:35:15 UTC",
    "updated_date": "2025-04-02 18:35:15 UTC"
  },
  {
    "arxiv_id": "2504.02051v2",
    "title": "Self-Resource Allocation in Multi-Agent LLM Systems",
    "authors": [
      "Alfonso Amayuelas",
      "Jingbo Yang",
      "Saaket Agashe",
      "Ashwin Nagarajan",
      "Antonis Antoniades",
      "Xin Eric Wang",
      "William Wang"
    ],
    "abstract": "With the development of LLMs as agents, there is a growing interest in\nconnecting multiple agents into multi-agent systems to solve tasks\nconcurrently, focusing on their role in task assignment and coordination. This\npaper explores how LLMs can effectively allocate computational tasks among\nmultiple agents, considering factors such as cost, efficiency, and performance.\nIn this work, we address key questions, including the effectiveness of LLMs as\norchestrators and planners, comparing their effectiveness in task assignment\nand coordination. Our experiments demonstrate that LLMs can achieve high\nvalidity and accuracy in resource allocation tasks. We find that the planner\nmethod outperforms the orchestrator method in handling concurrent actions,\nresulting in improved efficiency and better utilization of agents.\nAdditionally, we show that providing explicit information about worker\ncapabilities enhances the allocation strategies of planners, particularly when\ndealing with suboptimal workers.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02051v2",
    "published_date": "2025-04-02 18:15:41 UTC",
    "updated_date": "2025-04-19 19:05:03 UTC"
  },
  {
    "arxiv_id": "2504.02891v1",
    "title": "Automated Survey Collection with LLM-based Conversational Agents",
    "authors": [
      "Kurmanbek Kaiyrbekov",
      "Nicholas J Dobbins",
      "Sean D Mooney"
    ],
    "abstract": "Objective: Traditional phone-based surveys are among the most accessible and\nwidely used methods to collect biomedical and healthcare data, however, they\nare often costly, labor intensive, and difficult to scale effectively. To\novercome these limitations, we propose an end-to-end survey collection\nframework driven by conversational Large Language Models (LLMs).\n  Materials and Methods: Our framework consists of a researcher responsible for\ndesigning the survey and recruiting participants, a conversational phone agent\npowered by an LLM that calls participants and administers the survey, a second\nLLM (GPT-4o) that analyzes the conversation transcripts generated during the\nsurveys, and a database for storing and organizing the results. To test our\nframework, we recruited 8 participants consisting of 5 native and 3 non-native\nenglish speakers and administered 40 surveys. We evaluated the correctness of\nLLM-generated conversation transcripts, accuracy of survey responses inferred\nby GPT-4o and overall participant experience.\n  Results: Survey responses were successfully extracted by GPT-4o from\nconversation transcripts with an average accuracy of 98% despite transcripts\nexhibiting an average per-line word error rate of 7.7%. While participants\nnoted occasional errors made by the conversational LLM agent, they reported\nthat the agent effectively conveyed the purpose of the survey, demonstrated\ngood comprehension, and maintained an engaging interaction.\n  Conclusions: Our study highlights the potential of LLM agents in conducting\nand analyzing phone surveys for healthcare applications. By reducing the\nworkload on human interviewers and offering a scalable solution, this approach\npaves the way for real-world, end-to-end AI-powered phone survey collection\nsystems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02891v1",
    "published_date": "2025-04-02 18:10:19 UTC",
    "updated_date": "2025-04-02 18:10:19 UTC"
  },
  {
    "arxiv_id": "2504.01951v1",
    "title": "The LLM Wears Prada: Analysing Gender Bias and Stereotypes through Online Shopping Data",
    "authors": [
      "Massimiliano Luca",
      "Ciro Beneduce",
      "Bruno Lepri",
      "Jacopo Staiano"
    ],
    "abstract": "With the wide and cross-domain adoption of Large Language Models, it becomes\ncrucial to assess to which extent the statistical correlations in training\ndata, which underlie their impressive performance, hide subtle and potentially\ntroubling biases. Gender bias in LLMs has been widely investigated from the\nperspectives of works, hobbies, and emotions typically associated with a\nspecific gender. In this study, we introduce a novel perspective. We\ninvestigate whether LLMs can predict an individual's gender based solely on\nonline shopping histories and whether these predictions are influenced by\ngender biases and stereotypes. Using a dataset of historical online purchases\nfrom users in the United States, we evaluate the ability of six LLMs to\nclassify gender and we then analyze their reasoning and products-gender\nco-occurrences. Results indicate that while models can infer gender with\nmoderate accuracy, their decisions are often rooted in stereotypical\nassociations between product categories and gender. Furthermore, explicit\ninstructions to avoid bias reduce the certainty of model predictions, but do\nnot eliminate stereotypical patterns. Our findings highlight the persistent\nnature of gender biases in LLMs and emphasize the need for robust\nbias-mitigation strategies.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01951v1",
    "published_date": "2025-04-02 17:56:08 UTC",
    "updated_date": "2025-04-02 17:56:08 UTC"
  },
  {
    "arxiv_id": "2504.01947v1",
    "title": "Efficient Federated Learning Tiny Language Models for Mobile Network Feature Prediction",
    "authors": [
      "Daniel Becking",
      "Ingo Friese",
      "Karsten MÃ¼ller",
      "Thomas Buchholz",
      "Mandy Galkow-Schneider",
      "Wojciech Samek",
      "Detlev Marpe"
    ],
    "abstract": "In telecommunications, Autonomous Networks (ANs) automatically adjust\nconfigurations based on specific requirements (e.g., bandwidth) and available\nresources. These networks rely on continuous monitoring and intelligent\nmechanisms for self-optimization, self-repair, and self-protection, nowadays\nenhanced by Neural Networks (NNs) to enable predictive modeling and pattern\nrecognition. Here, Federated Learning (FL) allows multiple AN cells - each\nequipped with NNs - to collaboratively train models while preserving data\nprivacy. However, FL requires frequent transmission of large neural data and\nthus an efficient, standardized compression strategy for reliable\ncommunication. To address this, we investigate NNCodec, a Fraunhofer\nimplementation of the ISO/IEC Neural Network Coding (NNC) standard, within a\nnovel FL framework that integrates tiny language models (TLMs) for various\nmobile network feature prediction (e.g., ping, SNR or band frequency). Our\nexperimental results on the Berlin V2X dataset demonstrate that NNCodec\nachieves transparent compression (i.e., negligible performance loss) while\nreducing communication overhead to below 1%, showing the effectiveness of\ncombining NNC with FL in collaboratively learned autonomous mobile networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at 2025 EuCNC & 6G Summit Poster Session",
    "pdf_url": "http://arxiv.org/pdf/2504.01947v1",
    "published_date": "2025-04-02 17:54:06 UTC",
    "updated_date": "2025-04-02 17:54:06 UTC"
  },
  {
    "arxiv_id": "2504.01935v1",
    "title": "Critical Thinking: Which Kinds of Complexity Govern Optimal Reasoning Length?",
    "authors": [
      "Celine Lee",
      "Alexander M. Rush",
      "Keyon Vafa"
    ],
    "abstract": "Large language models (LLMs) often benefit from verbalized reasoning at\ninference time, but it remains unclear which aspects of task difficulty these\nextra reasoning tokens address. To investigate this question, we formalize a\nframework using deterministic finite automata (DFAs). DFAs offer a formalism\nthrough which we can characterize task complexity through measurable properties\nsuch as run length (number of reasoning steps required) and state-space size\n(decision complexity). We first show that across different tasks and models of\ndifferent sizes and training paradigms, there exists an optimal amount of\nreasoning tokens such that the probability of producing a correct solution is\nmaximized. We then investigate which properties of complexity govern this\ncritical length: we find that task instances with longer corresponding\nunderlying DFA runs (i.e. demand greater latent state-tracking requirements)\ncorrelate with longer reasoning lengths, but, surprisingly, that DFA size (i.e.\nstate-space complexity) does not. We then demonstrate an implication of these\nfindings: being able to predict the optimal number of reasoning tokens for new\nproblems and filtering out non-optimal length answers results in consistent\naccuracy improvements.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01935v1",
    "published_date": "2025-04-02 17:45:58 UTC",
    "updated_date": "2025-04-02 17:45:58 UTC"
  },
  {
    "arxiv_id": "2504.01930v1",
    "title": "A thorough benchmark of automatic text classification: From traditional approaches to large language models",
    "authors": [
      "Washington Cunha",
      "Leonardo Rocha",
      "Marcos AndrÃ© GonÃ§alves"
    ],
    "abstract": "Automatic text classification (ATC) has experienced remarkable advancements\nin the past decade, best exemplified by recent small and large language models\n(SLMs and LLMs), leveraged by Transformer architectures. Despite recent\neffectiveness improvements, a comprehensive cost-benefit analysis investigating\nwhether the effectiveness gains of these recent approaches compensate their\nmuch higher costs when compared to more traditional text classification\napproaches such as SVMs and Logistic Regression is still missing in the\nliterature. In this context, this work's main contributions are twofold: (i) we\nprovide a scientifically sound comparative analysis of the cost-benefit of\ntwelve traditional and recent ATC solutions including five open LLMs, and (ii)\na large benchmark comprising {22 datasets}, including sentiment analysis and\ntopic classification, with their (train-validation-test) partitions based on\nfolded cross-validation procedures, along with documentation, and code. The\nrelease of code, data, and documentation enables the community to replicate\nexperiments and advance the field in a more scientifically sound manner. Our\ncomparative experimental results indicate that LLMs outperform traditional\napproaches (up to 26%-7.1% on average) and SLMs (up to 4.9%-1.9% on average) in\nterms of effectiveness. However, LLMs incur significantly higher computational\ncosts due to fine-tuning, being, on average 590x and 8.5x slower than\ntraditional methods and SLMs, respectively. Results suggests the following\nrecommendations: (1) LLMs for applications that require the best possible\neffectiveness and can afford the costs; (2) traditional methods such as\nLogistic Regression and SVM for resource-limited applications or those that\ncannot afford the cost of tuning large LLMs; and (3) SLMs like Roberta for\nnear-optimal effectiveness-efficiency trade-off.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 2 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.01930v1",
    "published_date": "2025-04-02 17:40:08 UTC",
    "updated_date": "2025-04-02 17:40:08 UTC"
  },
  {
    "arxiv_id": "2504.01925v1",
    "title": "Equivariant Spherical CNNs for Accurate Fiber Orientation Distribution Estimation in Neonatal Diffusion MRI with Reduced Acquisition Time",
    "authors": [
      "Haykel Snoussi",
      "Davood Karimi"
    ],
    "abstract": "Early and accurate assessment of brain microstructure using diffusion\nMagnetic Resonance Imaging (dMRI) is crucial for identifying neurodevelopmental\ndisorders in neonates, but remains challenging due to low signal-to-noise ratio\n(SNR), motion artifacts, and ongoing myelination. In this study, we propose a\nrotationally equivariant Spherical Convolutional Neural Network (sCNN)\nframework tailored for neonatal dMRI. We predict the Fiber Orientation\nDistribution (FOD) from multi-shell dMRI signals acquired with a reduced set of\ngradient directions (30% of the full protocol), enabling faster and more\ncost-effective acquisitions. We train and evaluate the performance of our sCNN\nusing real data from 43 neonatal dMRI datasets provided by the Developing Human\nConnectome Project (dHCP). Our results demonstrate that the sCNN achieves\nsignificantly lower mean squared error (MSE) and higher angular correlation\ncoefficient (ACC) compared to a Multi-Layer Perceptron (MLP) baseline,\nindicating improved accuracy in FOD estimation. Furthermore, tractography\nresults based on the sCNN-predicted FODs show improved anatomical plausibility,\ncoverage, and coherence compared to those from the MLP. These findings\nhighlight that sCNNs, with their inherent rotational equivariance, offer a\npromising approach for accurate and clinically efficient dMRI analysis, paving\nthe way for improved diagnostic capabilities and characterization of early\nbrain development.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01925v1",
    "published_date": "2025-04-02 17:36:51 UTC",
    "updated_date": "2025-04-02 17:36:51 UTC"
  },
  {
    "arxiv_id": "2504.01919v2",
    "title": "Bridging the Linguistic Divide: A Survey on Leveraging Large Language Models for Machine Translation",
    "authors": [
      "Baban Gain",
      "Dibyanayan Bandyopadhyay",
      "Asif Ekbal"
    ],
    "abstract": "The advent of Large Language Models (LLMs) has significantly reshaped the\nlandscape of machine translation (MT), particularly for low-resource languages\nand domains that lack sufficient parallel corpora, linguistic tools, and\ncomputational infrastructure. This survey presents a comprehensive overview of\nrecent progress in leveraging LLMs for MT. We analyze techniques such as\nfew-shot prompting, cross-lingual transfer, and parameter-efficient fine-tuning\nthat enable effective adaptation to under-resourced settings. The paper also\nexplores synthetic data generation strategies using LLMs, including\nback-translation and lexical augmentation. Additionally, we compare LLM-based\ntranslation with traditional encoder-decoder models across diverse language\npairs, highlighting the strengths and limitations of each. We discuss\npersistent challenges such as hallucinations, evaluation inconsistencies, and\ninherited biases while also evaluating emerging LLM-driven metrics for\ntranslation quality. This survey offers practical insights and outlines future\ndirections for building robust, inclusive, and scalable MT systems in the era\nof large-scale generative models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01919v2",
    "published_date": "2025-04-02 17:26:40 UTC",
    "updated_date": "2025-04-03 13:30:35 UTC"
  },
  {
    "arxiv_id": "2504.01916v1",
    "title": "FineLIP: Extending CLIP's Reach via Fine-Grained Alignment with Longer Text Inputs",
    "authors": [
      "Mothilal Asokan",
      "Kebin Wu",
      "Fatima Albreiki"
    ],
    "abstract": "As a pioneering vision-language model, CLIP (Contrastive Language-Image\nPre-training) has achieved significant success across various domains and a\nwide range of downstream vision-language tasks. However, the text encoders in\npopular CLIP models are limited to processing only 77 text tokens, which\nconstrains their ability to effectively handle longer, detail-rich captions.\nAdditionally, CLIP models often struggle to effectively capture detailed visual\nand textual information, which hampers their performance on tasks that require\nfine-grained analysis. To address these limitations, we present a novel\napproach, \\textbf{FineLIP}, that extends the capabilities of CLIP. FineLIP\nenhances cross-modal text-image mapping by incorporating \\textbf{Fine}-grained\nalignment with \\textbf{L}onger text input within the CL\\textbf{IP}-style\nframework. FineLIP first extends the positional embeddings to handle longer\ntext, followed by the dynamic aggregation of local image and text tokens. The\naggregated results are then used to enforce fine-grained token-to-token\ncross-modal alignment. We validate our model on datasets with long, detailed\ncaptions across two tasks: zero-shot cross-modal retrieval and text-to-image\ngeneration. Quantitative and qualitative experimental results demonstrate the\neffectiveness of FineLIP, outperforming existing state-of-the-art approaches.\nFurthermore, comprehensive ablation studies validate the benefits of key design\nelements within FineLIP.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01916v1",
    "published_date": "2025-04-02 17:19:59 UTC",
    "updated_date": "2025-04-02 17:19:59 UTC"
  },
  {
    "arxiv_id": "2504.01911v1",
    "title": "Advancing AI-Scientist Understanding: Making LLM Think Like a Physicist with Interpretable Reasoning",
    "authors": [
      "Yinggan Xu",
      "Hana Kimlee",
      "Yijia Xiao",
      "Di Luo"
    ],
    "abstract": "Large Language Models (LLMs) are playing an expanding role in physics\nresearch by enhancing reasoning, symbolic manipulation, and numerical\ncomputation. However, ensuring the reliability and interpretability of their\noutputs remains a significant challenge. In our framework, we conceptualize the\ncollaboration between AI and human scientists as a dynamic interplay among\nthree modules: the reasoning module, the interpretation module, and the\nAI-scientist interaction module. Recognizing that effective physics reasoning\ndemands rigorous logical consistency, quantitative precision, and deep\nintegration with established theoretical models, we introduce the\ninterpretation module to improve the understanding of AI-generated outputs,\nwhich is not previously explored in the literature. This module comprises\nmultiple specialized agents, including summarizers, model builders, UI\nbuilders, and testers, which collaboratively structure LLM outputs within a\nphysically grounded framework, by constructing a more interpretable science\nmodel. A case study demonstrates that our approach enhances transparency,\nfacilitates validation, and strengthens AI-augmented reasoning in scientific\ndiscovery.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "physics.comp-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01911v1",
    "published_date": "2025-04-02 17:13:16 UTC",
    "updated_date": "2025-04-02 17:13:16 UTC"
  },
  {
    "arxiv_id": "2504.01908v1",
    "title": "Benchmarking Synthetic Tabular Data: A Multi-Dimensional Evaluation Framework",
    "authors": [
      "Andrey Sidorenko",
      "Michael Platzer",
      "Mario Scriminaci",
      "Paul Tiwald"
    ],
    "abstract": "Evaluating the quality of synthetic data remains a key challenge for ensuring\nprivacy and utility in data-driven research. In this work, we present an\nevaluation framework that quantifies how well synthetic data replicates\noriginal distributional properties while ensuring privacy. The proposed\napproach employs a holdout-based benchmarking strategy that facilitates\nquantitative assessment through low- and high-dimensional distribution\ncomparisons, embedding-based similarity measures, and nearest-neighbor distance\nmetrics. The framework supports various data types and structures, including\nsequential and contextual information, and enables interpretable quality\ndiagnostics through a set of standardized metrics. These contributions aim to\nsupport reproducibility and methodological consistency in benchmarking of\nsynthetic data generation techniques. The code of the framework is available at\nhttps://github.com/mostly-ai/mostlyai-qa.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 7 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.01908v1",
    "published_date": "2025-04-02 17:10:30 UTC",
    "updated_date": "2025-04-02 17:10:30 UTC"
  },
  {
    "arxiv_id": "2504.01905v2",
    "title": "Accelerating IoV Intrusion Detection: Benchmarking GPU-Accelerated vs CPU-Based ML Libraries",
    "authors": [
      "Furkan Ã‡olhak",
      "Hasan CoÅŸkun",
      "Tsafac Nkombong Regine Cyrille",
      "Tedi Hoxa",
      "Mert Ä°lhan Ecevit",
      "Mehmet Nafiz AydÄ±n"
    ],
    "abstract": "The Internet of Vehicles (IoV) may face challenging cybersecurity attacks\nthat may require sophisticated intrusion detection systems, necessitating a\nrapid development and response system. This research investigates the\nperformance advantages of GPU-accelerated libraries (cuML) compared to\ntraditional CPU-based implementations (scikit-learn), focusing on the speed and\nefficiency required for machine learning models used in IoV threat detection\nenvironments. The comprehensive evaluations conducted employ four machine\nlearning approaches (Random Forest, KNN, Logistic Regression, XGBoost) across\nthree distinct IoV security datasets (OTIDS, GIDS, CICIoV2024). Our findings\ndemonstrate that GPU-accelerated implementations dramatically improved\ncomputational efficiency, with training times reduced by a factor of up to 159\nand prediction speeds accelerated by up to 95 times compared to traditional CPU\nprocessing, all while preserving detection accuracy. This remarkable\nperformance breakthrough empowers researchers and security specialists to\nharness GPU acceleration for creating faster, more effective threat detection\nsystems that meet the urgent real-time security demands of today's connected\nvehicle networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "CIIT 2025 22nd International Conference on Informatics and\n  Information Technologies (CIIT)",
    "pdf_url": "http://arxiv.org/pdf/2504.01905v2",
    "published_date": "2025-04-02 17:04:53 UTC",
    "updated_date": "2025-04-03 08:42:45 UTC"
  },
  {
    "arxiv_id": "2504.01903v1",
    "title": "STAR-1: Safer Alignment of Reasoning LLMs with 1K Data",
    "authors": [
      "Zijun Wang",
      "Haoqin Tu",
      "Yuhan Wang",
      "Juncheng Wu",
      "Jieru Mei",
      "Brian R. Bartoldson",
      "Bhavya Kailkhura",
      "Cihang Xie"
    ],
    "abstract": "This paper introduces STAR-1, a high-quality, just-1k-scale safety dataset\nspecifically designed for large reasoning models (LRMs) like DeepSeek-R1. Built\non three core principles -- diversity, deliberative reasoning, and rigorous\nfiltering -- STAR-1 aims to address the critical needs for safety alignment in\nLRMs. Specifically, we begin by integrating existing open-source safety\ndatasets from diverse sources. Then, we curate safety policies to generate\npolicy-grounded deliberative reasoning samples. Lastly, we apply a GPT-4o-based\nsafety scoring system to select training examples aligned with best practices.\nExperimental results show that fine-tuning LRMs with STAR-1 leads to an average\n40% improvement in safety performance across four benchmarks, while only\nincurring a marginal decrease (e.g., an average of 1.1%) in reasoning ability\nmeasured across five reasoning tasks. Extensive ablation studies further\nvalidate the importance of our design principles in constructing STAR-1 and\nanalyze its efficacy across both LRMs and traditional LLMs. Our project page is\nhttps://ucsc-vlaa.github.io/STAR-1.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01903v1",
    "published_date": "2025-04-02 17:04:04 UTC",
    "updated_date": "2025-04-02 17:04:04 UTC"
  },
  {
    "arxiv_id": "2504.01902v1",
    "title": "Graphically Speaking: Unmasking Abuse in Social Media with Conversation Insights",
    "authors": [
      "CÃ©lia Nouri",
      "Jean-Philippe Cointet",
      "ChloÃ© Clavel"
    ],
    "abstract": "Detecting abusive language in social media conversations poses significant\nchallenges, as identifying abusiveness often depends on the conversational\ncontext, characterized by the content and topology of preceding comments.\nTraditional Abusive Language Detection (ALD) models often overlook this\ncontext, which can lead to unreliable performance metrics. Recent Natural\nLanguage Processing (NLP) methods that integrate conversational context often\ndepend on limited and simplified representations, and report inconsistent\nresults. In this paper, we propose a novel approach that utilize graph neural\nnetworks (GNNs) to model social media conversations as graphs, where nodes\nrepresent comments, and edges capture reply structures. We systematically\ninvestigate various graph representations and context windows to identify the\noptimal configuration for ALD. Our GNN model outperform both context-agnostic\nbaselines and linear context-aware methods, achieving significant improvements\nin F1 scores. These findings demonstrate the critical role of structured\nconversational context and establish GNNs as a robust framework for advancing\ncontext-aware abusive language detection.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01902v1",
    "published_date": "2025-04-02 17:03:37 UTC",
    "updated_date": "2025-04-02 17:03:37 UTC"
  },
  {
    "arxiv_id": "2504.01901v1",
    "title": "Ross3D: Reconstructive Visual Instruction Tuning with 3D-Awareness",
    "authors": [
      "Haochen Wang",
      "Yucheng Zhao",
      "Tiancai Wang",
      "Haoqiang Fan",
      "Xiangyu Zhang",
      "Zhaoxiang Zhang"
    ],
    "abstract": "The rapid development of Large Multimodal Models (LMMs) for 2D images and\nvideos has spurred efforts to adapt these models for interpreting 3D scenes.\nHowever, the absence of large-scale 3D vision-language datasets has posed a\nsignificant obstacle. To address this issue, typical approaches focus on\ninjecting 3D awareness into 2D LMMs by designing 3D input-level scene\nrepresentations. This work provides a new perspective. We introduce\nreconstructive visual instruction tuning with 3D-awareness (Ross3D), which\nintegrates 3D-aware visual supervision into the training procedure.\nSpecifically, it incorporates cross-view and global-view reconstruction. The\nformer requires reconstructing masked views by aggregating overlapping\ninformation from other views. The latter aims to aggregate information from all\navailable views to recover Bird's-Eye-View images, contributing to a\ncomprehensive overview of the entire scene. Empirically, Ross3D achieves\nstate-of-the-art performance across various 3D scene understanding benchmarks.\nMore importantly, our semi-supervised experiments demonstrate significant\npotential in leveraging large amounts of unlabeled 3D vision-only data.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01901v1",
    "published_date": "2025-04-02 16:59:55 UTC",
    "updated_date": "2025-04-02 16:59:55 UTC"
  },
  {
    "arxiv_id": "2504.02890v1",
    "title": "Scaling Test-time Compute for Low-resource Languages: Multilingual Reasoning in LLMs",
    "authors": [
      "Khanh-Tung Tran",
      "Barry O'Sullivan",
      "Hoang D. Nguyen"
    ],
    "abstract": "Recent advances in test-time compute scaling have enabled Large Language\nModels (LLMs) to tackle deep reasoning tasks by generating a chain-of-thought\n(CoT) that includes trial and error, backtracking, and intermediate reasoning\nsteps before producing the final answer. However, these techniques have been\napplied predominantly to popular languages, such as English, leaving reasoning\nin low-resource languages underexplored and misaligned. In this work, we\ninvestigate the multilingual mechanism by which LLMs internally operate in a\nlatent space biased toward their inherently dominant language. To leverage this\nphenomenon for low-resource languages, we train models to generate the CoT in\nEnglish while outputting the final response in the target language, given input\nin the low-resource language. Our experiments demonstrate that this approach,\nnamed English-Pivoted CoT Training, outperforms other baselines, including\ntraining to generate both the CoT and the final response solely in the target\nlanguage, with up to 28.33% improvement. Further analysis provides novel\ninsights into the relationships between reasoning and multilinguality of LLMs,\nprompting for better approaches in developing multilingual large reasoning\nmodels",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02890v1",
    "published_date": "2025-04-02 16:58:36 UTC",
    "updated_date": "2025-04-02 16:58:36 UTC"
  },
  {
    "arxiv_id": "2504.01888v1",
    "title": "A novel gesture interaction control method for rehabilitation lower extremity exoskeleton",
    "authors": [
      "Shuang Qiu",
      "Zhongcai Pei",
      "Chen Wang",
      "Jing Zhang",
      "Zhiyong Tang"
    ],
    "abstract": "With the rapid development of Rehabilitation Lower Extremity Robotic\nExoskeletons (RLEEX) technology, significant advancements have been made in\nHuman-Robot Interaction (HRI) methods. These include traditional physical HRI\nmethods that are easily recognizable and various bio-electrical signal-based\nHRI methods that can visualize and predict actions. However, most of these HRI\nmethods are contact-based, facing challenges such as operational complexity,\nsensitivity to interference, risks associated with implantable devices, and,\nmost importantly, limitations in comfort. These challenges render the\ninteraction less intuitive and natural, which can negatively impact patient\nmotivation for rehabilitation. To address these issues, this paper proposes a\nnovel non-contact gesture interaction control method for RLEEX, based on RGB\nmonocular camera depth estimation. This method integrates three key steps:\ndetecting keypoints, recognizing gestures, and assessing distance, thereby\napplying gesture information and augmented reality triggering technology to\ncontrol gait movements of RLEEX. Results indicate that this approach provides a\nfeasible solution to the problems of poor comfort, low reliability, and high\nlatency in HRI for RLEEX platforms. Specifically, it achieves a\ngesture-controlled exoskeleton motion accuracy of 94.11\\% and an average system\nresponse time of 0.615 seconds through non-contact HRI. The proposed\nnon-contact HRI method represents a pioneering advancement in control\ninteractions for RLEEX, paving the way for further exploration and development\nin this field.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01888v1",
    "published_date": "2025-04-02 16:46:01 UTC",
    "updated_date": "2025-04-02 16:46:01 UTC"
  },
  {
    "arxiv_id": "2504.01883v1",
    "title": "CoRAG: Collaborative Retrieval-Augmented Generation",
    "authors": [
      "Aashiq Muhamed",
      "Mona Diab",
      "Virginia Smith"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) models excel in knowledge-intensive\ntasks, especially under few-shot learning constraints. We introduce CoRAG, a\nframework extending RAG to collaborative settings, where clients jointly train\na shared model using a collaborative passage store. To evaluate CoRAG, we\nintroduce CRAB, a benchmark for collaborative homogeneous open-domain question\nanswering. Our experiments demonstrate that CoRAG consistently outperforms both\nparametric collaborative learning methods and locally trained RAG models in\nlow-resource scenarios. Further analysis reveals the critical importance of\nrelevant passages within the shared store, the surprising benefits of\nincorporating irrelevant passages, and the potential for hard negatives to\nnegatively impact performance. This introduces a novel consideration in\ncollaborative RAG: the trade-off between leveraging a collectively enriched\nknowledge base and the potential risk of incorporating detrimental passages\nfrom other clients. Our findings underscore the viability of CoRAG, while also\nhighlighting key design challenges and promising avenues for future research.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2504.01883v1",
    "published_date": "2025-04-02 16:40:43 UTC",
    "updated_date": "2025-04-02 16:40:43 UTC"
  },
  {
    "arxiv_id": "2504.01871v1",
    "title": "Interpreting Emergent Planning in Model-Free Reinforcement Learning",
    "authors": [
      "Thomas Bush",
      "Stephen Chung",
      "Usman Anwar",
      "AdriÃ  Garriga-Alonso",
      "David Krueger"
    ],
    "abstract": "We present the first mechanistic evidence that model-free reinforcement\nlearning agents can learn to plan. This is achieved by applying a methodology\nbased on concept-based interpretability to a model-free agent in Sokoban -- a\ncommonly used benchmark for studying planning. Specifically, we demonstrate\nthat DRC, a generic model-free agent introduced by Guez et al. (2019), uses\nlearned concept representations to internally formulate plans that both predict\nthe long-term effects of actions on the environment and influence action\nselection. Our methodology involves: (1) probing for planning-relevant\nconcepts, (2) investigating plan formation within the agent's representations,\nand (3) verifying that discovered plans (in the agent's representations) have a\ncausal effect on the agent's behavior through interventions. We also show that\nthe emergence of these plans coincides with the emergence of a planning-like\nproperty: the ability to benefit from additional test-time compute. Finally, we\nperform a qualitative analysis of the planning algorithm learned by the agent\nand discover a strong resemblance to parallelized bidirectional search. Our\nfindings advance understanding of the internal mechanisms underlying planning\nbehavior in agents, which is important given the recent trend of emergent\nplanning and reasoning capabilities in LLMs through RL",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025 oral",
    "pdf_url": "http://arxiv.org/pdf/2504.01871v1",
    "published_date": "2025-04-02 16:24:23 UTC",
    "updated_date": "2025-04-02 16:24:23 UTC"
  },
  {
    "arxiv_id": "2504.01866v2",
    "title": "From Code Generation to Software Testing: AI Copilot with Context-Based RAG",
    "authors": [
      "Yuchen Wang",
      "Shangxin Guo",
      "Chee Wei Tan"
    ],
    "abstract": "The rapid pace of large-scale software development places increasing demands\non traditional testing methodologies, often leading to bottlenecks in\nefficiency, accuracy, and coverage. We propose a novel perspective on software\ntesting by positing bug detection and coding with fewer bugs as two\ninterconnected problems that share a common goal, which is reducing bugs with\nlimited resources. We extend our previous work on AI-assisted programming,\nwhich supports code auto-completion and chatbot-powered Q&A, to the realm of\nsoftware testing. We introduce Copilot for Testing, an automated testing system\nthat synchronizes bug detection with codebase updates, leveraging context-based\nRetrieval Augmented Generation (RAG) to enhance the capabilities of large\nlanguage models (LLMs). Our evaluation demonstrates a 31.2% improvement in bug\ndetection accuracy, a 12.6% increase in critical test coverage, and a 10.5%\nhigher user acceptance rate, highlighting the transformative potential of\nAI-driven technologies in modern software development practices.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "This work has been accepted for publication in IEEE Software (DOI:\n  10.1109/MS.2025.3549628)",
    "pdf_url": "http://arxiv.org/pdf/2504.01866v2",
    "published_date": "2025-04-02 16:20:05 UTC",
    "updated_date": "2025-04-05 09:03:33 UTC"
  },
  {
    "arxiv_id": "2504.01857v1",
    "title": "Cross-Lingual Consistency: A Novel Inference Framework for Advancing Reasoning in Large Language Models",
    "authors": [
      "Zhiwei Yu",
      "Tuo Li",
      "Changhong Wang",
      "Hui Chen",
      "Lang Zhou"
    ],
    "abstract": "Chain-of-thought (CoT) has emerged as a critical mechanism for enhancing\nreasoning capabilities in large language models (LLMs), with self-consistency\ndemonstrating notable promise in boosting performance. However, inherent\nlinguistic biases in multilingual training corpora frequently cause semantic\ndrift and logical inconsistencies, especially in sub-10B parameter LLMs\nhandling complex inference tasks. To overcome these constraints, we propose the\nCross-Lingual Consistency (CLC) framework, an innovative inference paradigm\nthat integrates multilingual reasoning paths through majority voting to elevate\nLLMs' reasoning capabilities. Empirical evaluations on the CMATH dataset reveal\nCLC's superiority over the conventional self-consistency method, delivering\n9.5%, 6.5%, and 6.0% absolute accuracy gains for DeepSeek-Math-7B-Instruct,\nQwen2.5-Math-7B-Instruct, and Gemma2-9B-Instruct respectively. Expanding CLC's\nlinguistic scope to 11 diverse languages implies two synergistic benefits: 1)\nneutralizing linguistic biases in multilingual training corpora through\nmultilingual ensemble voting, 2) escaping monolingual reasoning traps by\nexploring the broader multilingual solution space. This dual benefits\nempirically enables more globally optimal reasoning paths compared to\nmonolingual self-consistency baselines, as evidenced by the 4.1%-18.5% accuracy\ngains using Gemma2-9B-Instruct on the MGSM dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01857v1",
    "published_date": "2025-04-02 16:09:39 UTC",
    "updated_date": "2025-04-02 16:09:39 UTC"
  },
  {
    "arxiv_id": "2504.01855v1",
    "title": "Enhanced Diffusion Sampling via Extrapolation with Multiple ODE Solutions",
    "authors": [
      "Jinyoung Choi",
      "Junoh Kang",
      "Bohyung Han"
    ],
    "abstract": "Diffusion probabilistic models (DPMs), while effective in generating\nhigh-quality samples, often suffer from high computational costs due to their\niterative sampling process. To address this, we propose an enhanced ODE-based\nsampling method for DPMs inspired by Richardson extrapolation, which reduces\nnumerical error and improves convergence rates. Our method, RX-DPM, leverages\nmultiple ODE solutions at intermediate time steps to extrapolate the denoised\nprediction in DPMs. This significantly enhances the accuracy of estimations for\nthe final sample while maintaining the number of function evaluations (NFEs).\nUnlike standard Richardson extrapolation, which assumes uniform discretization\nof the time grid, we develop a more general formulation tailored to arbitrary\ntime step scheduling, guided by local truncation error derived from a baseline\nsampling method. The simplicity of our approach facilitates accurate estimation\nof numerical solutions without significant computational overhead, and allows\nfor seamless and convenient integration into various DPMs and solvers.\nAdditionally, RX-DPM provides explicit error estimates, effectively\ndemonstrating the faster convergence as the leading error term's order\nincreases. Through a series of experiments, we show that the proposed method\nimproves the quality of generated samples without requiring additional sampling\niterations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.01855v1",
    "published_date": "2025-04-02 16:06:23 UTC",
    "updated_date": "2025-04-02 16:06:23 UTC"
  },
  {
    "arxiv_id": "2504.01850v1",
    "title": "Code Red! On the Harmfulness of Applying Off-the-shelf Large Language Models to Programming Tasks",
    "authors": [
      "Ali Al-Kaswan",
      "Sebastian Deatc",
      "BegÃ¼m KoÃ§",
      "Arie van Deursen",
      "Maliheh Izadi"
    ],
    "abstract": "Nowadays, developers increasingly rely on solutions powered by Large Language\nModels (LLM) to assist them with their coding tasks. This makes it crucial to\nalign these tools with human values to prevent malicious misuse. In this paper,\nwe propose a comprehensive framework for assessing the potential harmfulness of\nLLMs within the software engineering domain. We begin by developing a taxonomy\nof potentially harmful software engineering scenarios and subsequently, create\na dataset of prompts based on this taxonomy. To systematically assess the\nresponses, we design and validate an automatic evaluator that classifies the\noutputs of a variety of LLMs both open-source and closed-source models, as well\nas general-purpose and code-specific LLMs. Furthermore, we investigate the\nimpact of models size, architecture family, and alignment strategies on their\ntendency to generate harmful content. The results show significant disparities\nin the alignment of various LLMs for harmlessness. We find that some models and\nmodel families, such as Openhermes, are more harmful than others and that\ncode-specific models do not perform better than their general-purpose\ncounterparts. Notably, some fine-tuned models perform significantly worse than\ntheir base-models due to their design choices. On the other side, we find that\nlarger models tend to be more helpful and are less likely to respond with\nharmful information. These results highlight the importance of targeted\nalignment strategies tailored to the unique challenges of software engineering\ntasks and provide a foundation for future work in this critical area.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "FSE'25 Technical Track",
    "pdf_url": "http://arxiv.org/pdf/2504.01850v1",
    "published_date": "2025-04-02 16:00:14 UTC",
    "updated_date": "2025-04-02 16:00:14 UTC"
  },
  {
    "arxiv_id": "2504.01849v1",
    "title": "An Approach to Technical AGI Safety and Security",
    "authors": [
      "Rohin Shah",
      "Alex Irpan",
      "Alexander Matt Turner",
      "Anna Wang",
      "Arthur Conmy",
      "David Lindner",
      "Jonah Brown-Cohen",
      "Lewis Ho",
      "Neel Nanda",
      "Raluca Ada Popa",
      "Rishub Jain",
      "Rory Greig",
      "Samuel Albanie",
      "Scott Emmons",
      "Sebastian Farquhar",
      "SÃ©bastien Krier",
      "Senthooran Rajamanoharan",
      "Sophie Bridgers",
      "Tobi Ijitoye",
      "Tom Everitt",
      "Victoria Krakovna",
      "Vikrant Varma",
      "Vladimir Mikulik",
      "Zachary Kenton",
      "Dave Orr",
      "Shane Legg",
      "Noah Goodman",
      "Allan Dafoe",
      "Four Flynn",
      "Anca Dragan"
    ],
    "abstract": "Artificial General Intelligence (AGI) promises transformative benefits but\nalso presents significant risks. We develop an approach to address the risk of\nharms consequential enough to significantly harm humanity. We identify four\nareas of risk: misuse, misalignment, mistakes, and structural risks. Of these,\nwe focus on technical approaches to misuse and misalignment. For misuse, our\nstrategy aims to prevent threat actors from accessing dangerous capabilities,\nby proactively identifying dangerous capabilities, and implementing robust\nsecurity, access restrictions, monitoring, and model safety mitigations. To\naddress misalignment, we outline two lines of defense. First, model-level\nmitigations such as amplified oversight and robust training can help to build\nan aligned model. Second, system-level security measures such as monitoring and\naccess control can mitigate harm even if the model is misaligned. Techniques\nfrom interpretability, uncertainty estimation, and safer design patterns can\nenhance the effectiveness of these mitigations. Finally, we briefly outline how\nthese ingredients could be combined to produce safety cases for AGI systems.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01849v1",
    "published_date": "2025-04-02 15:59:31 UTC",
    "updated_date": "2025-04-02 15:59:31 UTC"
  },
  {
    "arxiv_id": "2504.01848v3",
    "title": "PaperBench: Evaluating AI's Ability to Replicate AI Research",
    "authors": [
      "Giulio Starace",
      "Oliver Jaffe",
      "Dane Sherburn",
      "James Aung",
      "Jun Shern Chan",
      "Leon Maksin",
      "Rachel Dias",
      "Evan Mays",
      "Benjamin Kinsella",
      "Wyatt Thompson",
      "Johannes Heidecke",
      "Amelia Glaese",
      "Tejal Patwardhan"
    ],
    "abstract": "We introduce PaperBench, a benchmark evaluating the ability of AI agents to\nreplicate state-of-the-art AI research. Agents must replicate 20 ICML 2024\nSpotlight and Oral papers from scratch, including understanding paper\ncontributions, developing a codebase, and successfully executing experiments.\nFor objective evaluation, we develop rubrics that hierarchically decompose each\nreplication task into smaller sub-tasks with clear grading criteria. In total,\nPaperBench contains 8,316 individually gradable tasks. Rubrics are co-developed\nwith the author(s) of each ICML paper for accuracy and realism. To enable\nscalable evaluation, we also develop an LLM-based judge to automatically grade\nreplication attempts against rubrics, and assess our judge's performance by\ncreating a separate benchmark for judges. We evaluate several frontier models\non PaperBench, finding that the best-performing tested agent, Claude 3.5 Sonnet\n(New) with open-source scaffolding, achieves an average replication score of\n21.0%. Finally, we recruit top ML PhDs to attempt a subset of PaperBench,\nfinding that models do not yet outperform the human baseline. We open-source\nour code (https://github.com/openai/preparedness) to facilitate future research\nin understanding the AI engineering capabilities of AI agents.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.01848v3",
    "published_date": "2025-04-02 15:55:24 UTC",
    "updated_date": "2025-04-07 12:15:49 UTC"
  },
  {
    "arxiv_id": "2504.01833v1",
    "title": "YourBench: Easy Custom Evaluation Sets for Everyone",
    "authors": [
      "Sumuk Shashidhar",
      "ClÃ©mentine Fourrier",
      "Alina Lozovskia",
      "Thomas Wolf",
      "Gokhan Tur",
      "Dilek Hakkani-TÃ¼r"
    ],
    "abstract": "Evaluating large language models (LLMs) effectively remains a critical\nbottleneck, as traditional static benchmarks suffer from saturation and\ncontamination, while human evaluations are costly and slow. This hinders timely\nor domain-specific assessment, crucial for real-world applications. We\nintroduce YourBench, a novel, open-source framework that addresses these\nlimitations by enabling dynamic, automated generation of reliable, up-to-date,\nand domain-tailored benchmarks cheaply and without manual annotation, directly\nfrom user-provided documents. We demonstrate its efficacy by replicating 7\ndiverse MMLU subsets using minimal source text, achieving this for under 15 USD\nin total inference costs while perfectly preserving the relative model\nperformance rankings (Spearman Rho = 1) observed on the original benchmark. To\nensure that YourBench generates data grounded in provided input instead of\nrelying on posterior parametric knowledge in models, we also introduce\nTempora-0325, a novel dataset of over 7K diverse documents, published\nexclusively after March 2025. Our comprehensive analysis spans 26 SoTA models\nfrom 7 major families across varying scales (3-671B parameters) to validate the\nquality of generated evaluations through rigorous algorithmic checks (e.g.,\ncitation grounding) and human assessments. We release the YourBench library,\nthe Tempora-0325 dataset, 150k+ question answer pairs based on Tempora and all\nevaluation and inference traces to facilitate reproducible research and empower\nthe community to generate bespoke benchmarks on demand, fostering more relevant\nand trustworthy LLM evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.1"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01833v1",
    "published_date": "2025-04-02 15:40:24 UTC",
    "updated_date": "2025-04-02 15:40:24 UTC"
  },
  {
    "arxiv_id": "2504.02019v1",
    "title": "Antithetic Sampling for Top-k Shapley Identification",
    "authors": [
      "Patrick Kolpaczki",
      "Tim Nielen",
      "Eyke HÃ¼llermeier"
    ],
    "abstract": "Additive feature explanations rely primarily on game-theoretic notions such\nas the Shapley value by viewing features as cooperating players. The Shapley\nvalue's popularity in and outside of explainable AI stems from its axiomatic\nuniqueness. However, its computational complexity severely limits\npracticability. Most works investigate the uniform approximation of all\nfeatures' Shapley values, needlessly consuming samples for insignificant\nfeatures. In contrast, identifying the $k$ most important features can already\nbe sufficiently insightful and yields the potential to leverage algorithmic\nopportunities connected to the field of multi-armed bandits. We propose\nComparable Marginal Contributions Sampling (CMCS), a method for the top-$k$\nidentification problem utilizing a new sampling scheme taking advantage of\ncorrelated observations. We conduct experiments to showcase the efficacy of our\nmethod in compared to competitive baselines. Our empirical findings reveal that\nestimation quality for the approximate-all problem does not necessarily\ntransfer to top-$k$ identification and vice versa.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02019v1",
    "published_date": "2025-04-02 15:38:32 UTC",
    "updated_date": "2025-04-02 15:38:32 UTC"
  },
  {
    "arxiv_id": "2504.01819v1",
    "title": "Implicit Bias Injection Attacks against Text-to-Image Diffusion Models",
    "authors": [
      "Huayang Huang",
      "Xiangye Jin",
      "Jiaxu Miao",
      "Yu Wu"
    ],
    "abstract": "The proliferation of text-to-image diffusion models (T2I DMs) has led to an\nincreased presence of AI-generated images in daily life. However, biased T2I\nmodels can generate content with specific tendencies, potentially influencing\npeople's perceptions. Intentional exploitation of these biases risks conveying\nmisleading information to the public. Current research on bias primarily\naddresses explicit biases with recognizable visual patterns, such as skin color\nand gender. This paper introduces a novel form of implicit bias that lacks\nexplicit visual features but can manifest in diverse ways across various\nsemantic contexts. This subtle and versatile nature makes this bias challenging\nto detect, easy to propagate, and adaptable to a wide range of scenarios. We\nfurther propose an implicit bias injection attack framework (IBI-Attacks)\nagainst T2I diffusion models by precomputing a general bias direction in the\nprompt embedding space and adaptively adjusting it based on different inputs.\nOur attack module can be seamlessly integrated into pre-trained diffusion\nmodels in a plug-and-play manner without direct manipulation of user input or\nmodel retraining. Extensive experiments validate the effectiveness of our\nscheme in introducing bias through subtle and diverse modifications while\npreserving the original semantics. The strong concealment and transferability\nof our attack across various scenarios further underscore the significance of\nour approach. Code is available at https://github.com/Hannah1102/IBI-attacks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accept to CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.01819v1",
    "published_date": "2025-04-02 15:24:12 UTC",
    "updated_date": "2025-04-02 15:24:12 UTC"
  },
  {
    "arxiv_id": "2504.01798v1",
    "title": "A Novel Approach To Implementing Knowledge Distillation In Tsetlin Machines",
    "authors": [
      "Calvin Kinateder"
    ],
    "abstract": "The Tsetlin Machine (TM) is a propositional logic based model that uses\nconjunctive clauses to learn patterns from data. As with typical neural\nnetworks, the performance of a Tsetlin Machine is largely dependent on its\nparameter count, with a larger number of parameters producing higher accuracy\nbut slower execution. Knowledge distillation in neural networks transfers\ninformation from an already-trained teacher model to a smaller student model to\nincrease accuracy in the student without increasing execution time. We propose\na novel approach to implementing knowledge distillation in Tsetlin Machines by\nutilizing the probability distributions of each output sample in the teacher to\nprovide additional context to the student. Additionally, we propose a novel\nclause-transfer algorithm that weighs the importance of each clause in the\nteacher and initializes the student with only the most essential data. We find\nthat our algorithm can significantly improve performance in the student model\nwithout negatively impacting latency in the tested domains of image recognition\nand text classification.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "Master's Thesis. 75 pages, 30 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.01798v1",
    "published_date": "2025-04-02 15:06:27 UTC",
    "updated_date": "2025-04-02 15:06:27 UTC"
  },
  {
    "arxiv_id": "2504.01797v2",
    "title": "Rethinking industrial artificial intelligence: a unified foundation framework",
    "authors": [
      "Jay Lee",
      "Hanqi Su"
    ],
    "abstract": "Recent advancements in industrial artificial intelligence (AI) are reshaping\nthe industry by driving smarter manufacturing, predictive maintenance, and\nintelligent decision-making. However, existing approaches often focus primarily\non algorithms and models while overlooking the importance of systematically\nintegrating domain knowledge, data, and models to develop more comprehensive\nand effective AI solutions. Therefore, the effective development and deployment\nof industrial AI require a more comprehensive and systematic approach. To\naddress this gap, this paper reviews previous research, rethinks the role of\nindustrial AI, and proposes a unified industrial AI foundation framework\ncomprising three core modules: the knowledge module, data module, and model\nmodule. These modules help to extend and enhance the industrial AI methodology\nplatform, supporting various industrial applications. In addition, a case study\non rotating machinery diagnosis is presented to demonstrate the effectiveness\nof the proposed framework, and several future directions are highlighted for\nthe development of the industrial AI foundation framework.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The paper submitted to IJAMD, the International Journal of AI for\n  Materials and Design, has been accepted",
    "pdf_url": "http://arxiv.org/pdf/2504.01797v2",
    "published_date": "2025-04-02 15:05:32 UTC",
    "updated_date": "2025-04-17 02:54:57 UTC"
  },
  {
    "arxiv_id": "2504.01783v1",
    "title": "CLaP -- State Detection from Time Series",
    "authors": [
      "Arik Ermshaus",
      "Patrick SchÃ¤fer",
      "Ulf Leser"
    ],
    "abstract": "The ever-growing amount of sensor data from machines, smart devices, and the\nenvironment leads to an abundance of high-resolution, unannotated time series\n(TS). These recordings encode the recognizable properties of latent states and\ntransitions from physical phenomena that can be modelled as abstract processes.\nThe unsupervised localization and identification of these states and their\ntransitions is the task of time series state detection (TSSD). We introduce\nCLaP, a new, highly accurate and efficient algorithm for TSSD. It leverages the\npredictive power of time series classification for TSSD in an unsupervised\nsetting by applying novel self-supervision techniques to detect whether data\nsegments emerge from the same state or not. To this end, CLaP cross-validates a\nclassifier with segment-labelled subsequences to quantify confusion between\nsegments. It merges labels from segments with high confusion, representing the\nsame latent state, if this leads to an increase in overall classification\nquality. We conducted an experimental evaluation using 391 TS from four\nbenchmarks and found CLaP to be significantly more precise in detecting states\nthan five state-of-the-art competitors. It achieves the best accuracy-runtime\ntradeoff and is scalable to large TS. We provide a Python implementation of\nCLaP, which can be deployed in TS analysis workflows.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01783v1",
    "published_date": "2025-04-02 14:46:42 UTC",
    "updated_date": "2025-04-02 14:46:42 UTC"
  },
  {
    "arxiv_id": "2504.02889v1",
    "title": "Embedding Method for Knowledge Graph with Densely Defined Ontology",
    "authors": [
      "Takanori Ugai"
    ],
    "abstract": "Knowledge graph embedding (KGE) is a technique that enhances knowledge graphs\nby addressing incompleteness and improving knowledge retrieval. A limitation of\nthe existing KGE models is their underutilization of ontologies, specifically\nthe relationships between properties. This study proposes a KGE model, TransU,\ndesigned for knowledge graphs with well-defined ontologies that incorporate\nrelationships between properties. The model treats properties as a subset of\nentities, enabling a unified representation. We present experimental results\nusing a standard dataset and a practical dataset.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "6pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.02889v1",
    "published_date": "2025-04-02 14:43:47 UTC",
    "updated_date": "2025-04-02 14:43:47 UTC"
  },
  {
    "arxiv_id": "2504.01771v1",
    "title": "Enhancing Interpretability in Generative AI Through Search-Based Data Influence Analysis",
    "authors": [
      "Theodoros Aivalis",
      "Iraklis A. Klampanos",
      "Antonis Troumpoukis",
      "Joemon M. Jose"
    ],
    "abstract": "Generative AI models offer powerful capabilities but often lack transparency,\nmaking it difficult to interpret their output. This is critical in cases\ninvolving artistic or copyrighted content. This work introduces a\nsearch-inspired approach to improve the interpretability of these models by\nanalysing the influence of training data on their outputs. Our method provides\nobservational interpretability by focusing on a model's output rather than on\nits internal state. We consider both raw data and latent-space embeddings when\nsearching for the influence of data items in generated content. We evaluate our\nmethod by retraining models locally and by demonstrating the method's ability\nto uncover influential subsets in the training data. This work lays the\ngroundwork for future extensions, including user-based evaluations with domain\nexperts, which is expected to improve observational interpretability further.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01771v1",
    "published_date": "2025-04-02 14:29:37 UTC",
    "updated_date": "2025-04-02 14:29:37 UTC"
  },
  {
    "arxiv_id": "2504.01767v1",
    "title": "Leveraging Embedding Techniques in Multimodal Machine Learning for Mental Illness Assessment",
    "authors": [
      "Abdelrahaman A. Hassan",
      "Abdelrahman A. Ali",
      "Aya E. Fouda",
      "Radwa J. Hanafy",
      "Mohammed E. Fouda"
    ],
    "abstract": "The increasing global prevalence of mental disorders, such as depression and\nPTSD, requires objective and scalable diagnostic tools. Traditional clinical\nassessments often face limitations in accessibility, objectivity, and\nconsistency. This paper investigates the potential of multimodal machine\nlearning to address these challenges, leveraging the complementary information\navailable in text, audio, and video data. Our approach involves a comprehensive\nanalysis of various data preprocessing techniques, including novel chunking and\nutterance-based formatting strategies. We systematically evaluate a range of\nstate-of-the-art embedding models for each modality and employ Convolutional\nNeural Networks (CNNs) and Bidirectional LSTM Networks (BiLSTMs) for feature\nextraction. We explore data-level, feature-level, and decision-level fusion\ntechniques, including a novel integration of Large Language Model (LLM)\npredictions. We also investigate the impact of replacing Multilayer Perceptron\nclassifiers with Support Vector Machines. We extend our analysis to severity\nprediction using PHQ-8 and PCL-C scores and multi-class classification\n(considering co-occurring conditions). Our results demonstrate that\nutterance-based chunking significantly improves performance, particularly for\ntext and audio modalities. Decision-level fusion, incorporating LLM\npredictions, achieves the highest accuracy, with a balanced accuracy of 94.8%\nfor depression and 96.2% for PTSD detection. The combination of CNN-BiLSTM\narchitectures with utterance-level chunking, coupled with the integration of\nexternal LLM, provides a powerful and nuanced approach to the detection and\nassessment of mental health conditions. Our findings highlight the potential of\nMMML for developing more accurate, accessible, and personalized mental\nhealthcare tools.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01767v1",
    "published_date": "2025-04-02 14:19:06 UTC",
    "updated_date": "2025-04-02 14:19:06 UTC"
  },
  {
    "arxiv_id": "2504.01764v1",
    "title": "Dual-stream Transformer-GCN Model with Contextualized Representations Learning for Monocular 3D Human Pose Estimation",
    "authors": [
      "Mingrui Ye",
      "Lianping Yang",
      "Hegui Zhu",
      "Zenghao Zheng",
      "Xin Wang",
      "Yantao Lo"
    ],
    "abstract": "This paper introduces a novel approach to monocular 3D human pose estimation\nusing contextualized representation learning with the Transformer-GCN\ndual-stream model. Monocular 3D human pose estimation is challenged by depth\nambiguity, limited 3D-labeled training data, imbalanced modeling, and\nrestricted model generalization. To address these limitations, our work\nintroduces a groundbreaking motion pre-training method based on contextualized\nrepresentation learning. Specifically, our method involves masking 2D pose\nfeatures and utilizing a Transformer-GCN dual-stream model to learn\nhigh-dimensional representations through a self-distillation setup. By focusing\non contextualized representation learning and spatial-temporal modeling, our\napproach enhances the model's ability to understand spatial-temporal\nrelationships between postures, resulting in superior generalization.\nFurthermore, leveraging the Transformer-GCN dual-stream model, our approach\neffectively balances global and local interactions in video pose estimation.\nThe model adaptively integrates information from both the Transformer and GCN\nstreams, where the GCN stream effectively learns local relationships between\nadjacent key points and frames, while the Transformer stream captures\ncomprehensive global spatial and temporal features. Our model achieves\nstate-of-the-art performance on two benchmark datasets, with an MPJPE of 38.0mm\nand P-MPJPE of 31.9mm on Human3.6M, and an MPJPE of 15.9mm on MPI-INF-3DHP.\nFurthermore, visual experiments on public datasets and in-the-wild videos\ndemonstrate the robustness and generalization capabilities of our approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01764v1",
    "published_date": "2025-04-02 14:17:57 UTC",
    "updated_date": "2025-04-02 14:17:57 UTC"
  },
  {
    "arxiv_id": "2504.01738v1",
    "title": "Style over Substance: Distilled Language Models Reason Via Stylistic Replication",
    "authors": [
      "Philip Lippmann",
      "Jie Yang"
    ],
    "abstract": "Specialized reasoning language models (RLMs) have demonstrated that scaling\ntest-time computation through detailed reasoning traces significantly enhances\nperformance. Although these traces effectively facilitate knowledge\ndistillation into smaller, instruction-tuned models, the precise nature of\ntransferred reasoning remains unclear. In this study, we investigate to what\nextent distilled models internalize replicated stylistic patterns during\nreasoning. To this end, we systematically analyze reasoning traces, identifying\nstructural and lexical patterns that characterize successful reasoning. We then\nintroduce two new datasets -- a dataset of emergent reasoning traces and a\nsynthetic dataset explicitly constructed to replicate these stylistic patterns\n-- to precisely examine their influence on distilled models' reasoning\ncapabilities. We find that models trained on the synthetic traces achieve\ncomparable performance, indicating that distilled reasoning abilities rely\nsignificantly on surface-level patterns. Surprisingly, we observe an increase\nin performance even when the synthetic traces are altered to lead to the wrong\nanswer. Our findings highlight how stylistic patterns can be leveraged to\nefficiently enhance LM reasoning across diverse model families.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01738v1",
    "published_date": "2025-04-02 13:50:20 UTC",
    "updated_date": "2025-04-02 13:50:20 UTC"
  },
  {
    "arxiv_id": "2504.01735v1",
    "title": "AdPO: Enhancing the Adversarial Robustness of Large Vision-Language Models with Preference Optimization",
    "authors": [
      "Chaohu Liu",
      "Tianyi Gui",
      "Yu Liu",
      "Linli Xu"
    ],
    "abstract": "Large Vision-Language Models (LVLMs), such as GPT-4o and LLaVA, have recently\nwitnessed remarkable advancements and are increasingly being deployed in\nreal-world applications. However, inheriting the sensitivity of visual neural\nnetworks, LVLMs remain vulnerable to adversarial attacks, which can result in\nerroneous or malicious outputs. While existing efforts utilize adversarial\nfine-tuning to enhance robustness, they often suffer from performance\ndegradation on clean inputs. In this paper, we proposes AdPO, a novel\nadversarial defense strategy for LVLMs based on preference optimization. For\nthe first time, we reframe adversarial training as a preference optimization\nproblem, aiming to enhance the model's preference for generating normal outputs\non clean inputs while rejecting the potential misleading outputs for\nadversarial examples. Notably, AdPO achieves this by solely modifying the image\nencoder, e.g., CLIP ViT, resulting in superior clean and adversarial\nperformance in a variety of downsream tasks. Considering that training involves\nlarge language models (LLMs), the computational cost increases significantly.\nWe validate that training on smaller LVLMs and subsequently transferring to\nlarger models can achieve competitive performance while maintaining efficiency\ncomparable to baseline methods. Our comprehensive experiments confirm the\neffectiveness of the proposed AdPO, which provides a novel perspective for\nfuture adversarial defense research.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01735v1",
    "published_date": "2025-04-02 13:43:21 UTC",
    "updated_date": "2025-04-02 13:43:21 UTC"
  },
  {
    "arxiv_id": "2504.01733v1",
    "title": "Epistemic Skills: Reasoning about Knowledge and Oblivion",
    "authors": [
      "Xiaolong Liang",
      "YÃ¬ N. WÃ¡ng"
    ],
    "abstract": "This paper presents a class of epistemic logics that captures the dynamics of\nacquiring knowledge and descending into oblivion, while incorporating concepts\nof group knowledge. The approach is grounded in a system of weighted models,\nintroducing an ``epistemic skills'' metric to represent the epistemic\ncapacities tied to knowledge updates. Within this framework, knowledge\nacquisition is modeled as a process of upskilling, whereas oblivion is\nrepresented as a consequence of downskilling. The framework further enables\nexploration of ``knowability'' and ``forgettability,'' defined as the potential\nto gain knowledge through upskilling and to lapse into oblivion through\ndownskilling, respectively. Additionally, it supports a detailed analysis of\nthe distinctions between epistemic de re and de dicto expressions. The\ncomputational complexity of the model checking and satisfiability problems is\nexamined, offering insights into their theoretical foundations and practical\nimplications.",
    "categories": [
      "cs.AI",
      "cs.CC",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01733v1",
    "published_date": "2025-04-02 13:41:42 UTC",
    "updated_date": "2025-04-02 13:41:42 UTC"
  },
  {
    "arxiv_id": "2504.01724v3",
    "title": "DreamActor-M1: Holistic, Expressive and Robust Human Image Animation with Hybrid Guidance",
    "authors": [
      "Yuxuan Luo",
      "Zhengkun Rong",
      "Lizhen Wang",
      "Longhao Zhang",
      "Tianshu Hu",
      "Yongming Zhu"
    ],
    "abstract": "While recent image-based human animation methods achieve realistic body and\nfacial motion synthesis, critical gaps remain in fine-grained holistic\ncontrollability, multi-scale adaptability, and long-term temporal coherence,\nwhich leads to their lower expressiveness and robustness. We propose a\ndiffusion transformer (DiT) based framework, DreamActor-M1, with hybrid\nguidance to overcome these limitations. For motion guidance, our hybrid control\nsignals that integrate implicit facial representations, 3D head spheres, and 3D\nbody skeletons achieve robust control of facial expressions and body movements,\nwhile producing expressive and identity-preserving animations. For scale\nadaptation, to handle various body poses and image scales ranging from\nportraits to full-body views, we employ a progressive training strategy using\ndata with varying resolutions and scales. For appearance guidance, we integrate\nmotion patterns from sequential frames with complementary visual references,\nensuring long-term temporal coherence for unseen regions during complex\nmovements. Experiments demonstrate that our method outperforms the\nstate-of-the-art works, delivering expressive results for portraits,\nupper-body, and full-body generation with robust long-term consistency. Project\nPage: https://grisoon.github.io/DreamActor-M1/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01724v3",
    "published_date": "2025-04-02 13:30:32 UTC",
    "updated_date": "2025-04-20 11:52:01 UTC"
  },
  {
    "arxiv_id": "2504.01707v2",
    "title": "InfiniteICL: Breaking the Limit of Context Window Size via Long Short-term Memory Transformation",
    "authors": [
      "Bowen Cao",
      "Deng Cai",
      "Wai Lam"
    ],
    "abstract": "In-context learning (ICL) is critical for large language models (LLMs), but\nits effectiveness is constrained by finite context windows, particularly in\nultra-long contexts. To overcome this, we introduce InfiniteICL, a framework\nthat parallels context and parameters in LLMs with short- and long-term memory\nin human cognitive systems, focusing on transforming temporary context\nknowledge into permanent parameter updates. This approach significantly reduces\nmemory usage, maintains robust performance across varying input lengths, and\ntheoretically enables infinite context integration through the principles of\ncontext knowledge elicitation, selection, and consolidation. Evaluations\ndemonstrate that our method reduces context length by 90% while achieving 103%\naverage performance of full-context prompting across fact recall, grounded\nreasoning, and skill acquisition tasks. When conducting sequential multi-turn\ntransformations on complex, real-world contexts (with length up to 2M tokens),\nour approach surpasses full-context prompting while using only 0.4% of the\noriginal contexts. These findings highlight InfiniteICL's potential to enhance\nthe scalability and efficiency of LLMs by breaking the limitations of\nconventional context window sizes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01707v2",
    "published_date": "2025-04-02 13:15:44 UTC",
    "updated_date": "2025-04-03 08:53:06 UTC"
  },
  {
    "arxiv_id": "2504.01705v1",
    "title": "Sky of Unlearning (SoUL): Rewiring Federated Machine Unlearning via Selective Pruning",
    "authors": [
      "Md Mahabub Uz Zaman",
      "Xiang Sun",
      "Jingjing Yao"
    ],
    "abstract": "The Internet of Drones (IoD), where drones collaborate in data collection and\nanalysis, has become essential for applications such as surveillance and\nenvironmental monitoring. Federated learning (FL) enables drones to train\nmachine learning models in a decentralized manner while preserving data\nprivacy. However, FL in IoD networks is susceptible to attacks like data\npoisoning and model inversion. Federated unlearning (FU) mitigates these risks\nby eliminating adversarial data contributions, preventing their influence on\nthe model. This paper proposes sky of unlearning (SoUL), a federated unlearning\nframework that efficiently removes the influence of unlearned data while\nmaintaining model performance. A selective pruning algorithm is designed to\nidentify and remove neurons influential in unlearning but minimally impact the\noverall performance of the model. Simulations demonstrate that SoUL outperforms\nexisting unlearning methods, achieves accuracy comparable to full retraining,\nand reduces computation and communication overhead, making it a scalable and\nefficient solution for resource-constrained IoD networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 6 figures, IEEE International Conference on Communications\n  (ICC 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.01705v1",
    "published_date": "2025-04-02 13:07:30 UTC",
    "updated_date": "2025-04-02 13:07:30 UTC"
  },
  {
    "arxiv_id": "2504.01700v1",
    "title": "Reasoning LLMs for User-Aware Multimodal Conversational Agents",
    "authors": [
      "Hamed Rahimi",
      "Jeanne Cattoni",
      "Meriem Beghili",
      "Mouad Abrini",
      "Mahdi Khoramshahi",
      "Maribel Pino",
      "Mohamed Chetouani"
    ],
    "abstract": "Personalization in social robotics is critical for fostering effective\nhuman-robot interactions, yet systems often face the cold start problem, where\ninitial user preferences or characteristics are unavailable. This paper\nproposes a novel framework called USER-LLM R1 for a user-aware conversational\nagent that addresses this challenge through dynamic user profiling and model\ninitiation. Our approach integrates chain-of-thought (CoT) reasoning models to\niteratively infer user preferences and vision-language models (VLMs) to\ninitialize user profiles from multimodal inputs, enabling personalized\ninteractions from the first encounter. Leveraging a Retrieval-Augmented\nGeneration (RAG) architecture, the system dynamically refines user\nrepresentations within an inherent CoT process, ensuring contextually relevant\nand adaptive responses. Evaluations on the ElderlyTech-VQA Bench demonstrate\nsignificant improvements in ROUGE-1 (+23.2%), ROUGE-2 (+0.6%), and ROUGE-L\n(+8%) F1 scores over state-of-the-art baselines, with ablation studies\nunderscoring the impact of reasoning model size on performance. Human\nevaluations further validate the framework's efficacy, particularly for elderly\nusers, where tailored responses enhance engagement and trust. Ethical\nconsiderations, including privacy preservation and bias mitigation, are\nrigorously discussed and addressed to ensure responsible deployment.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01700v1",
    "published_date": "2025-04-02 13:00:17 UTC",
    "updated_date": "2025-04-02 13:00:17 UTC"
  },
  {
    "arxiv_id": "2504.01698v3",
    "title": "Do Theory of Mind Benchmarks Need Explicit Human-like Reasoning in Language Models?",
    "authors": [
      "Yi-Long Lu",
      "Chunhui Zhang",
      "Jiajun Song",
      "Lifeng Fan",
      "Wei Wang"
    ],
    "abstract": "Theory of Mind (ToM), the ability to attribute mental states to others, is\nfundamental for human social intelligence and a critical capability for\nadvanced Artificial Intelligence. Recent advancements in Large Language Models\n(LLMs) have shown promising performance on ToM benchmarks, raising the\nquestion: Do these benchmarks necessitate explicit human-like reasoning\nprocesses, or can models succeed through alternative strategies? We investigate\nthis question empirically by applying Reinforcement Learning (RL) and\nSupervised Fine-Tuning (SFT) to LLMs of varying scales (0.5B to 7B parameters)\nand evaluating them across multiple ToM datasets. Our results reveal a\nscale-dependent impact of RL: while RL significantly improves accuracy and\nfosters high-quality, interpretable, and transferable belief-tracking reasoning\nin larger models (7B), it leads to \"reasoning collapse\" in smaller models\n($\\leq$3B), where high accuracy and generalization ability are achieved via\ndrastically shortened, less meaningful responses. Surprisingly, further SFT\nachieves competitive and generalizable performance across these benchmarks,\noften matching or exceeding RL models in accuracy, despite not being explicitly\ntrained to produce structured reasoning traces. These findings highlight a\ncritical discrepancy between benchmark accuracy and the nature of learned\nreasoning. Our work suggests that current ToM benchmarks may be solvable\nwithout requiring the explicit, human-like simulation of mental states they\nwere designed to probe. LLMs, particularly when scale is limited or training\nsignals focus solely on output correctness, may leverage alternative rules\neffective for benchmark data structures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01698v3",
    "published_date": "2025-04-02 12:58:42 UTC",
    "updated_date": "2025-05-16 07:38:52 UTC"
  },
  {
    "arxiv_id": "2504.01692v1",
    "title": "Segmentation variability and radiomics stability for predicting Triple-Negative Breast Cancer subtype using Magnetic Resonance Imaging",
    "authors": [
      "Isabella Cama",
      "Alejandro GuzmÃ¡n",
      "Cristina Campi",
      "Michele Piana",
      "Karim Lekadir",
      "Sara Garbarino",
      "Oliver DÃ­az"
    ],
    "abstract": "Most papers caution against using predictive models for disease\nstratification based on unselected radiomic features, as these features are\naffected by contouring variability. Instead, they advocate for the use of the\nIntraclass Correlation Coefficient (ICC) as a measure of stability for feature\nselection. However, the direct effect of segmentation variability on the\npredictive models is rarely studied. This study investigates the impact of\nsegmentation variability on feature stability and predictive performance in\nradiomics-based prediction of Triple-Negative Breast Cancer (TNBC) subtype\nusing Magnetic Resonance Imaging. A total of 244 images from the Duke dataset\nwere used, with segmentation variability introduced through modifications of\nmanual segmentations. For each mask, explainable radiomic features were\nselected using the Shapley Additive exPlanations method and used to train\nlogistic regression models. Feature stability across segmentations was assessed\nvia ICC, Pearson's correlation, and reliability scores quantifying the\nrelationship between feature stability and segmentation variability. Results\nindicate that segmentation accuracy does not significantly impact predictive\nperformance. While incorporating peritumoral information may reduce feature\nreproducibility, it does not diminish feature predictive capability. Moreover,\nfeature selection in predictive models is not inherently tied to feature\nstability with respect to segmentation, suggesting that an overreliance on ICC\nor reliability scores for feature selection might exclude valuable predictive\nfeatures.",
    "categories": [
      "stat.AP",
      "cs.AI",
      "62P10 (Primary), 68T09 (Secondary)"
    ],
    "primary_category": "stat.AP",
    "comment": "22 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.01692v1",
    "published_date": "2025-04-02 12:48:01 UTC",
    "updated_date": "2025-04-02 12:48:01 UTC"
  },
  {
    "arxiv_id": "2504.01690v1",
    "title": "Token Pruning in Audio Transformers: Optimizing Performance and Decoding Patch Importance",
    "authors": [
      "Taehan Lee",
      "Hyukjun Lee"
    ],
    "abstract": "Vision Transformers (ViTs) have achieved state-of-the-art performance across\nvarious computer vision tasks, but their high computational cost remains a\nchallenge. Token pruning has been proposed to reduce this cost by selectively\nremoving less important tokens. While effective in vision tasks by discarding\nnon-object regions, applying this technique to audio tasks presents unique\nchallenges, as distinguishing relevant from irrelevant regions in\ntime-frequency representations is less straightforward. In this study, for the\nfirst time, we applied token pruning to ViT-based audio classification models\nusing Mel-spectrograms and analyzed the trade-offs between model performance\nand computational cost: TopK token pruning can reduce MAC operations of\nAudioMAE and AST by 30-40%, with less than a 1% drop in classification\naccuracy. Our analysis reveals that while high-intensity tokens contribute\nsignificantly to model accuracy, low-intensity tokens remain important. In\nparticular, they play a more critical role in general audio classification\ntasks than in speech-specific tasks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "This work has been submitted to the IEEE for possible publication.\n  Source code is available at\n  https://github.com/andylee-24/token-pruning-audio-transformer",
    "pdf_url": "http://arxiv.org/pdf/2504.01690v1",
    "published_date": "2025-04-02 12:44:38 UTC",
    "updated_date": "2025-04-02 12:44:38 UTC"
  },
  {
    "arxiv_id": "2504.01673v1",
    "title": "K-P Quantum Neural Networks",
    "authors": [
      "Elija Perrier"
    ],
    "abstract": "We present an extension of K-P time-optimal quantum control solutions using\nglobal Cartan $KAK$ decompositions for geodesic-based solutions. Extending\nrecent time-optimal \\emph{constant-$\\theta$} control results, we integrate\nCartan methods into equivariant quantum neural network (EQNN) for quantum\ncontrol tasks. We show that a finite-depth limited EQNN ansatz equipped with\nCartan layers can replicate the constant-$\\theta$ sub-Riemannian geodesics for\nK-P problems. We demonstrate how for certain classes of control problem on\nRiemannian symmetric spaces, gradient-based training using an appropriate cost\nfunction converges to certain global time-optimal solutions when satisfying\nsimple regularity conditions. This generalises prior geometric control theory\nmethods and clarifies how optimal geodesic estimation can be performed in\nquantum machine learning contexts.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2504.01673v1",
    "published_date": "2025-04-02 12:22:18 UTC",
    "updated_date": "2025-04-02 12:22:18 UTC"
  },
  {
    "arxiv_id": "2504.01671v1",
    "title": "Anomaly Detection for Hybrid Butterfly Subspecies via Probability Filtering",
    "authors": [
      "Bo-Kai Ruan",
      "Yi-Zeng Fang",
      "Hong-Han Shuai",
      "Juinn-Dar Huang"
    ],
    "abstract": "Detecting butterfly hybrids requires knowledge of the parent subspecies, and\nthe process can be tedious when encountering a new subspecies. This study\nfocuses on a specific scenario where a model trained to recognize hybrid\nspecies A can generalize to species B when B biologically mimics A. Since\nspecies A and B share similar patterns, we leverage BioCLIP as our feature\nextractor to capture features based on their taxonomy. Consequently, the\nalgorithm designed for species A can be transferred to B, as their hybrid and\nnon-hybrid patterns exhibit similar relationships. To determine whether a\nbutterfly is a hybrid, we adopt proposed probability filtering and color\njittering to augment and simulate the mimicry. With these approaches, we\nachieve second place in the official development phase. Our code is publicly\navailable at https://github.com/Justin900429/NSF-HDR-Challenge.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "AAAI'25 Workshop in Anomaly Detection in Scientific Domains",
    "pdf_url": "http://arxiv.org/pdf/2504.01671v1",
    "published_date": "2025-04-02 12:18:44 UTC",
    "updated_date": "2025-04-02 12:18:44 UTC"
  },
  {
    "arxiv_id": "2504.01652v1",
    "title": "Market-Oriented Flow Allocation for Thermal Solar Plants: An Auction-Based Methodology with Artificial Intelligence",
    "authors": [
      "Sara Ruiz-Moreno",
      "Antonio J. Gallego",
      "Manuel MacÃ­as",
      "Eduardo F. Camacho"
    ],
    "abstract": "This paper presents a novel method to optimize thermal balance in parabolic\ntrough collector (PTC) plants. It uses a market-based system to distribute flow\namong loops combined with an artificial neural network (ANN) to reduce\ncomputation and data requirements. This auction-based approach balances loop\ntemperatures, accommodating varying thermal losses and collector efficiencies.\nValidation across different thermal losses, optical efficiencies, and\nirradiance conditions-sunny, partially cloudy, and cloudy-show improved thermal\npower output and intercept factors compared to a no-allocation system. It\ndemonstrates scalability and practicality for large solar thermal plants,\nenhancing overall performance. The method was first validated through\nsimulations on a realistic solar plant model, then adapted and successfully\ntested in a 50 MW solar trough plant, demonstrating its advantages.\nFurthermore, the algorithms have been implemented, commissioned, and are\ncurrently operating in 13 commercial solar trough plants.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "This manuscript has been submitted to Renewable Energy",
    "pdf_url": "http://arxiv.org/pdf/2504.01652v1",
    "published_date": "2025-04-02 12:01:41 UTC",
    "updated_date": "2025-04-02 12:01:41 UTC"
  },
  {
    "arxiv_id": "2504.03763v1",
    "title": "Efficient Calibration for RRAM-based In-Memory Computing using DoRA",
    "authors": [
      "Weirong Dong",
      "Kai Zhou",
      "Zhen Kong",
      "Quan Cheng",
      "Junkai Huang",
      "Zhengke Yang",
      "Masanori Hashimoto",
      "Longyang Lin"
    ],
    "abstract": "Resistive In-Memory Computing (RIMC) offers ultra-efficient computation for\nedge AI but faces accuracy degradation due to RRAM conductance drift over time.\nTraditional retraining methods are limited by RRAM's high energy consumption,\nwrite latency, and endurance constraints. We propose a DoRA-based calibration\nframework that restores accuracy by compensating influential weights with\nminimal calibration parameters stored in SRAM, leaving RRAM weights untouched.\nThis eliminates in-field RRAM writes, ensuring energy-efficient, fast, and\nreliable calibration. Experiments on RIMC-based ResNet50 (ImageNet-1K)\ndemonstrate 69.53% accuracy restoration using just 10 calibration samples while\nupdating only 2.34% of parameters.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "7 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.03763v1",
    "published_date": "2025-04-02 11:58:08 UTC",
    "updated_date": "2025-04-02 11:58:08 UTC"
  },
  {
    "arxiv_id": "2504.01644v1",
    "title": "Proposition of Affordance-Driven Environment Recognition Framework Using Symbol Networks in Large Language Models",
    "authors": [
      "Kazuma Arii",
      "Satoshi Kurihara"
    ],
    "abstract": "In the quest to enable robots to coexist with humans, understanding dynamic\nsituations and selecting appropriate actions based on common sense and\naffordances are essential. Conventional AI systems face challenges in applying\naffordance, as it represents implicit knowledge derived from common sense.\nHowever, large language models (LLMs) offer new opportunities due to their\nability to process extensive human knowledge. This study proposes a method for\nautomatic affordance acquisition by leveraging LLM outputs. The process\ninvolves generating text using LLMs, reconstructing the output into a symbol\nnetwork using morphological and dependency analysis, and calculating\naffordances based on network distances. Experiments using ``apple'' as an\nexample demonstrated the method's ability to extract context-dependent\naffordances with high explainability. The results suggest that the proposed\nsymbol network, reconstructed from LLM outputs, enables robots to interpret\naffordances effectively, bridging the gap between symbolized data and\nhuman-like situational understanding.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01644v1",
    "published_date": "2025-04-02 11:48:44 UTC",
    "updated_date": "2025-04-02 11:48:44 UTC"
  },
  {
    "arxiv_id": "2504.01641v1",
    "title": "Bridge 2D-3D: Uncertainty-aware Hierarchical Registration Network with Domain Alignment",
    "authors": [
      "Zhixin Cheng",
      "Jiacheng Deng",
      "Xinjun Li",
      "Baoqun Yin",
      "Tianzhu Zhang"
    ],
    "abstract": "The method for image-to-point cloud registration typically determines the\nrigid transformation using a coarse-to-fine pipeline. However, directly and\nuniformly matching image patches with point cloud patches may lead to focusing\non incorrect noise patches during matching while ignoring key ones. Moreover,\ndue to the significant differences between image and point cloud modalities, it\nmay be challenging to bridge the domain gap without specific improvements in\ndesign. To address the above issues, we innovatively propose the\nUncertainty-aware Hierarchical Matching Module (UHMM) and the Adversarial Modal\nAlignment Module (AMAM). Within the UHMM, we model the uncertainty of critical\ninformation in image patches and facilitate multi-level fusion interactions\nbetween image and point cloud features. In the AMAM, we design an adversarial\napproach to reduce the domain gap between image and point cloud. Extensive\nexperiments and ablation studies on RGB-D Scene V2 and 7-Scenes benchmarks\ndemonstrate the superiority of our method, making it a state-of-the-art\napproach for image-to-point cloud registration tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "AAAI2025accept",
    "pdf_url": "http://arxiv.org/pdf/2504.01641v1",
    "published_date": "2025-04-02 11:43:55 UTC",
    "updated_date": "2025-04-02 11:43:55 UTC"
  },
  {
    "arxiv_id": "2504.01637v1",
    "title": "LLM-mediated Dynamic Plan Generation with a Multi-Agent Approach",
    "authors": [
      "Reo Abe",
      "Akifumi Ito",
      "Kanata Takayasu",
      "Satoshi Kurihara"
    ],
    "abstract": "Planning methods with high adaptability to dynamic environments are crucial\nfor the development of autonomous and versatile robots. We propose a method for\nleveraging a large language model (GPT-4o) to automatically generate networks\ncapable of adapting to dynamic environments. The proposed method collects\nenvironmental \"status,\" representing conditions and goals, and uses them to\ngenerate agents. These agents are interconnected on the basis of specific\nconditions, resulting in networks that combine flexibility and generality. We\nconducted evaluation experiments to compare the networks automatically\ngenerated with the proposed method with manually constructed ones, confirming\nthe comprehensiveness of the proposed method's networks and their higher\ngenerality. This research marks a significant advancement toward the\ndevelopment of versatile planning methods applicable to robotics, autonomous\nvehicles, smart systems, and other complex environments.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01637v1",
    "published_date": "2025-04-02 11:42:49 UTC",
    "updated_date": "2025-04-02 11:42:49 UTC"
  },
  {
    "arxiv_id": "2504.01632v2",
    "title": "Benchmarking the Spatial Robustness of DNNs via Natural and Adversarial Localized Corruptions",
    "authors": [
      "Giulia Marchiori Pietrosanti",
      "Giulio Rossolini",
      "Alessandro Biondi",
      "Giorgio Buttazzo"
    ],
    "abstract": "The robustness of DNNs is a crucial factor in safety-critical applications,\nparticularly in complex and dynamic environments where localized corruptions\ncan arise. While previous studies have evaluated the robustness of semantic\nsegmentation (SS) models under whole-image natural or adversarial corruptions,\na comprehensive investigation into the spatial robustness of dense vision\nmodels under localized corruptions remained underexplored. This paper fills\nthis gap by introducing specialized metrics for benchmarking the spatial\nrobustness of segmentation models, alongside with an evaluation framework to\nassess the impact of localized corruptions. Furthermore, we uncover the\ninherent complexity of characterizing worst-case robustness using a single\nlocalized adversarial perturbation. To address this, we propose region-aware\nmulti-attack adversarial analysis, a method that enables a deeper understanding\nof model robustness against adversarial perturbations applied to specific\nregions. The proposed metrics and analysis were exploited to evaluate 14\nsegmentation models in driving scenarios, uncovering key insights into the\neffects of localized corruption in both natural and adversarial forms. The\nresults reveal that models respond to these two types of threats differently;\nfor instance, transformer-based segmentation models demonstrate notable\nrobustness to localized natural corruptions but are highly vulnerable to\nadversarial ones and vice-versa for CNN-based models. Consequently, we also\naddress the challenge of balancing robustness to both natural and adversarial\nlocalized corruptions by means of ensemble models, thereby achieving a broader\nthreat coverage and improved reliability for dense vision tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2504.01632v2",
    "published_date": "2025-04-02 11:37:39 UTC",
    "updated_date": "2025-04-17 16:43:20 UTC"
  },
  {
    "arxiv_id": "2504.01627v1",
    "title": "Horizon Scans can be accelerated using novel information retrieval and artificial intelligence tools",
    "authors": [
      "Lena Schmidt",
      "Oshin Sharma",
      "Chris Marshall",
      "Sonia Garcia Gonzalez Moral"
    ],
    "abstract": "Introduction: Horizon scanning in healthcare assesses early signals of\ninnovation, crucial for timely adoption. Current horizon scanning faces\nchallenges in efficient information retrieval and analysis, especially from\nunstructured sources like news, presenting a need for innovative tools.\nMethodology: The study introduces SCANAR and AIDOC, open-source Python-based\ntools designed to improve horizon scanning. SCANAR automates the retrieval and\nprocessing of news articles, offering functionalities such as de-duplication\nand unsupervised relevancy ranking. AIDOC aids filtration by leveraging AI to\nreorder textual data based on relevancy, employing neural networks for semantic\nsimilarity, and subsequently prioritizing likely relevant entries for human\nreview. Results: Twelve internal datasets from horizon scans and four external\nbenchmarking datasets were used. SCANAR improved retrieval efficiency by\nautomating processes previously dependent on manual labour. AIDOC displayed\nwork-saving potential, achieving around 62% reduction in manual review efforts\nat 95% recall. Comparative analysis with benchmarking data showed AIDOC's\nperformance was similar to existing systematic review automation tools, though\nperformance varied depending on dataset characteristics. A smaller case-study\non our news datasets shows the potential of ensembling large language models\nwithin the active-learning process for faster detection of relevant articles\nacross news datasets. Conclusion: The validation indicates that SCANAR and\nAIDOC show potential to enhance horizon scanning efficiency by streamlining\ndata retrieval and prioritisation. These tools may alleviate methodological\nlimitations and allow broader, swifter horizon scans. Further studies are\nsuggested to optimize these models and to design new workflows and validation\nprocesses that integrate large language models.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01627v1",
    "published_date": "2025-04-02 11:33:08 UTC",
    "updated_date": "2025-04-02 11:33:08 UTC"
  },
  {
    "arxiv_id": "2504.01589v2",
    "title": "Text Speaks Louder than Vision: ASCII Art Reveals Textual Biases in Vision-Language Models",
    "authors": [
      "Zhaochen Wang",
      "Bryan Hooi",
      "Yiwei Wang",
      "Ming-Hsuan Yang",
      "Zi Huang",
      "Yujun Cai"
    ],
    "abstract": "Vision-language models (VLMs) have advanced rapidly in processing multimodal\ninformation, but their ability to reconcile conflicting signals across\nmodalities remains underexplored. This work investigates how VLMs process ASCII\nart, a unique medium where textual elements collectively form visual patterns,\npotentially creating semantic-visual conflicts. We introduce a novel evaluation\nframework that systematically challenges five state-of-the-art models\n(including GPT-4o, Claude, and Gemini) using adversarial ASCII art, where\ncharacter-level semantics deliberately contradict global visual patterns. Our\nexperiments reveal a strong text-priority bias: VLMs consistently prioritize\ntextual information over visual patterns, with visual recognition ability\ndeclining dramatically as semantic complexity increases. Various mitigation\nattempts through visual parameter tuning and prompt engineering yielded only\nmodest improvements, suggesting that this limitation requires\narchitectural-level solutions. These findings uncover fundamental flaws in how\ncurrent VLMs integrate multimodal information, providing important guidance for\nfuture model development while highlighting significant implications for\ncontent moderation systems vulnerable to adversarial examples.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Under review at COLM 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.01589v2",
    "published_date": "2025-04-02 10:47:07 UTC",
    "updated_date": "2025-04-07 23:21:49 UTC"
  },
  {
    "arxiv_id": "2504.01588v1",
    "title": "Building Knowledge from Interactions: An LLM-Based Architecture for Adaptive Tutoring and Social Reasoning",
    "authors": [
      "Luca Garello",
      "Giulia Belgiovine",
      "Gabriele Russo",
      "Francesco Rea",
      "Alessandra Sciutti"
    ],
    "abstract": "Integrating robotics into everyday scenarios like tutoring or physical\ntraining requires robots capable of adaptive, socially engaging, and\ngoal-oriented interactions. While Large Language Models show promise in\nhuman-like communication, their standalone use is hindered by memory\nconstraints and contextual incoherence. This work presents a multimodal,\ncognitively inspired framework that enhances LLM-based autonomous\ndecision-making in social and task-oriented Human-Robot Interaction.\nSpecifically, we develop an LLM-based agent for a robot trainer, balancing\nsocial conversation with task guidance and goal-driven motivation. To further\nenhance autonomy and personalization, we introduce a memory system for\nselecting, storing and retrieving experiences, facilitating generalized\nreasoning based on knowledge built across different interactions. A preliminary\nHRI user study and offline experiments with a synthetic dataset validate our\napproach, demonstrating the system's ability to manage complex interactions,\nautonomously drive training tasks, and build and retrieve contextual memories,\nadvancing socially intelligent robotics.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.01588v1",
    "published_date": "2025-04-02 10:45:41 UTC",
    "updated_date": "2025-04-02 10:45:41 UTC"
  },
  {
    "arxiv_id": "2504.01571v1",
    "title": "Pro-DG: Procedural Diffusion Guidance for Architectural Facade Generation",
    "authors": [
      "Aleksander Plocharski",
      "Jan Swidzinski",
      "Przemyslaw Musialski"
    ],
    "abstract": "We present Pro-DG, a framework for procedurally controllable photo-realistic\nfacade generation that combines a procedural shape grammar with diffusion-based\nimage synthesis. Starting from a single input image, we reconstruct its facade\nlayout using grammar rules, then edit that structure through user-defined\ntransformations. As facades are inherently multi-hierarchical structures, we\nintroduce hierarchical matching procedure that aligns facade structures at\ndifferent levels which is used to introduce control maps to guide a generative\ndiffusion pipeline. This approach retains local appearance fidelity while\naccommodating large-scale edits such as floor duplication or window\nrearrangement. We provide a thorough evaluation, comparing Pro-DG against\ninpainting-based baselines and synthetic ground truths. Our user study and\nquantitative measurements indicate improved preservation of architectural\nidentity and higher edit accuracy. Our novel method is the first to integrate\nneuro-symbolically derived shape-grammars for modeling with modern generative\nmodel and highlights the broader potential of such approaches for precise and\ncontrollable image manipulation.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "I.3.7; I.4.9; I.2.10"
    ],
    "primary_category": "cs.GR",
    "comment": "12 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.01571v1",
    "published_date": "2025-04-02 10:16:19 UTC",
    "updated_date": "2025-04-02 10:16:19 UTC"
  },
  {
    "arxiv_id": "2504.01560v1",
    "title": "Optimizing Package Delivery with Quantum Annealers: Addressing Time-Windows and Simultaneous Pickup and Delivery",
    "authors": [
      "Eneko Osaba",
      "Esther Villar-Rodriguez",
      "Pablo Miranda-Rodriguez",
      "AntÃ³n Asla"
    ],
    "abstract": "Recent research at the intersection of quantum computing and routing problems\nhas been highly prolific. Much of this work focuses on classical problems such\nas the Traveling Salesman Problem and the Vehicle Routing Problem. The\npractical applicability of these problems depends on the specific objectives\nand constraints considered. However, it is undeniable that translating complex\nreal-world requirements into these classical formulations often proves\nchallenging. In this paper, we resort to our previously published\nquantum-classical technique for addressing real-world-oriented routing\nproblems, known as Quantum for Real Package Delivery (Q4RPD), and elaborate on\nsolving additional realistic problem instances. Accordingly, this paper\nemphasizes the following characteristics: i) simultaneous pickup and\ndeliveries, ii) time-windows, and iii) mobility restrictions by vehicle type.\nTo illustrate the application of Q4RPD, we have conducted an experimentation\ncomprising seven instances, serving as a demonstration of the newly developed\nfeatures.",
    "categories": [
      "cs.ET",
      "cs.AI"
    ],
    "primary_category": "cs.ET",
    "comment": "8 pages, 1 table, 9 figures, paper submitted to the IEEE\n  International Conference on Quantum Computing and Engineering (QCE 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.01560v1",
    "published_date": "2025-04-02 10:01:34 UTC",
    "updated_date": "2025-04-02 10:01:34 UTC"
  },
  {
    "arxiv_id": "2504.01551v1",
    "title": "Identifying Macro Causal Effects in C-DMGs",
    "authors": [
      "Simon Ferreira",
      "Charles K. Assaad"
    ],
    "abstract": "Causal effect identification using causal graphs is a fundamental challenge\nin causal inference. While extensive research has been conducted in this area,\nmost existing methods assume the availability of fully specified causal graphs.\nHowever, in complex domains such as medicine and epidemiology, complete causal\nknowledge is often unavailable, and only partial information about the system\nis accessible. This paper focuses on causal effect identification within\npartially specified causal graphs, with particular emphasis on cluster-directed\nmixed graphs (C-DMGs). These graphs provide a higher-level representation of\ncausal relationships by grouping variables into clusters, offering a more\npractical approach for handling complex systems. Unlike fully specified causal\ngraphs, C-DMGs can contain cycles, which complicate their analysis and\ninterpretation. Furthermore, their cluster-based nature introduces new\nchallenges, as it gives rise to two distinct types of causal effects, macro\ncausal effects and micro causal effects, with different properties. In this\nwork, we focus on macro causal effects, which describe the effects of entire\nclusters on other clusters. We establish that the do-calculus is both sound and\ncomplete for identifying these effects in C-DMGs. Additionally, we provide a\ngraphical characterization of non-identifiability for macro causal effects in\nthese graphs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01551v1",
    "published_date": "2025-04-02 09:48:27 UTC",
    "updated_date": "2025-04-02 09:48:27 UTC"
  },
  {
    "arxiv_id": "2504.01541v2",
    "title": "Hyperbolic Diffusion Recommender Model",
    "authors": [
      "Meng Yuan",
      "Yutian Xiao",
      "Wei Chen",
      "Chu Zhao",
      "Deqing Wang",
      "Fuzhen Zhuang"
    ],
    "abstract": "Diffusion models (DMs) have emerged as the new state-of-the-art family of\ndeep generative models. To gain deeper insights into the limitations of\ndiffusion models in recommender systems, we investigate the fundamental\nstructural disparities between images and items. Consequently, items often\nexhibit distinct anisotropic and directional structures that are less prevalent\nin images. However, the traditional forward diffusion process continuously adds\nisotropic Gaussian noise, causing anisotropic signals to degrade into noise,\nwhich impairs the semantically meaningful representations in recommender\nsystems.\n  Inspired by the advancements in hyperbolic spaces, we propose a novel\n\\textit{\\textbf{H}yperbolic} \\textit{\\textbf{D}iffusion}\n\\textit{\\textbf{R}ecommender} \\textit{\\textbf{M}odel} (named HDRM). Unlike\nexisting directional diffusion methods based on Euclidean space, the intrinsic\nnon-Euclidean structure of hyperbolic space makes it particularly well-adapted\nfor handling anisotropic diffusion processes. In particular, we begin by\nformulating concepts to characterize latent directed diffusion processes within\na geometrically grounded hyperbolic space. Subsequently, we propose a novel\nhyperbolic latent diffusion process specifically tailored for users and items.\nDrawing upon the natural geometric attributes of hyperbolic spaces, we impose\nstructural restrictions on the space to enhance hyperbolic diffusion\npropagation, thereby ensuring the preservation of the intrinsic topology of\nuser-item graphs. Extensive experiments on three benchmark datasets demonstrate\nthe effectiveness of HDRM.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01541v2",
    "published_date": "2025-04-02 09:27:40 UTC",
    "updated_date": "2025-04-10 08:02:56 UTC"
  },
  {
    "arxiv_id": "2504.01538v1",
    "title": "AI-Newton: A Concept-Driven Physical Law Discovery System without Prior Physical Knowledge",
    "authors": [
      "You-Le Fang",
      "Dong-Shan Jian",
      "Xiang Li",
      "Yan-Qing Ma"
    ],
    "abstract": "Current limitations in human scientific discovery necessitate a new research\nparadigm. While advances in artificial intelligence (AI) offer a highly\npromising solution, enabling AI to emulate human-like scientific discovery\nremains an open challenge. To address this, we propose AI-Newton, a\nconcept-driven discovery system capable of autonomously deriving physical laws\nfrom raw data -- without supervision or prior physical knowledge. The system\nintegrates a knowledge base and knowledge representation centered on physical\nconcepts, along with an autonomous discovery workflow. As a proof of concept,\nwe apply AI-Newton to a large set of Newtonian mechanics problems. Given\nexperimental data with noise, the system successfully rediscovers fundamental\nlaws, including Newton's second law, energy conservation and law of\ngravitation, using autonomously defined concepts. This achievement marks a\nsignificant step toward AI-driven autonomous scientific discovery.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SC",
      "hep-ph",
      "physics.class-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "31 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.01538v1",
    "published_date": "2025-04-02 09:25:34 UTC",
    "updated_date": "2025-04-02 09:25:34 UTC"
  },
  {
    "arxiv_id": "2504.01522v1",
    "title": "Redefining technology for indigenous languages",
    "authors": [
      "Silvia Fernandez-Sabido",
      "Laura Peniche-Sabido"
    ],
    "abstract": "In this paper, we offer an overview of indigenous languages, identifying the\ncauses of their devaluation and the need for legislation on language rights. We\nreview the technologies used to revitalize these languages, finding that when\nthey come from outside, they often have the opposite effect to what they seek;\nhowever, when developed from within communities, they become powerful\ninstruments of expression. We propose that the inclusion of Indigenous\nknowledge in large language models (LLMs) will enrich the technological\nlandscape, but must be done in a participatory environment that encourages the\nexchange of knowledge.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "in Spanish language",
    "pdf_url": "http://arxiv.org/pdf/2504.01522v1",
    "published_date": "2025-04-02 09:08:53 UTC",
    "updated_date": "2025-04-02 09:08:53 UTC"
  },
  {
    "arxiv_id": "2504.01521v1",
    "title": "Domain Guidance: A Simple Transfer Approach for a Pre-trained Diffusion Model",
    "authors": [
      "Jincheng Zhong",
      "Xiangcheng Zhang",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "abstract": "Recent advancements in diffusion models have revolutionized generative\nmodeling. However, the impressive and vivid outputs they produce often come at\nthe cost of significant model scaling and increased computational demands.\nConsequently, building personalized diffusion models based on off-the-shelf\nmodels has emerged as an appealing alternative. In this paper, we introduce a\nnovel perspective on conditional generation for transferring a pre-trained\nmodel. From this viewpoint, we propose *Domain Guidance*, a straightforward\ntransfer approach that leverages pre-trained knowledge to guide the sampling\nprocess toward the target domain. Domain Guidance shares a formulation similar\nto advanced classifier-free guidance, facilitating better domain alignment and\nhigher-quality generations. We provide both empirical and theoretical analyses\nof the mechanisms behind Domain Guidance. Our experimental results demonstrate\nits substantial effectiveness across various transfer benchmarks, achieving\nover a 19.6% improvement in FID and a 23.4% improvement in FD$_\\text{DINOv2}$\ncompared to standard fine-tuning. Notably, existing fine-tuned models can\nseamlessly integrate Domain Guidance to leverage these benefits, without\nadditional training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01521v1",
    "published_date": "2025-04-02 09:07:55 UTC",
    "updated_date": "2025-04-02 09:07:55 UTC"
  },
  {
    "arxiv_id": "2504.01515v2",
    "title": "Training-free Dense-Aligned Diffusion Guidance for Modular Conditional Image Synthesis",
    "authors": [
      "Zixuan Wang",
      "Duo Peng",
      "Feng Chen",
      "Yuwei Yang",
      "Yinjie Lei"
    ],
    "abstract": "Conditional image synthesis is a crucial task with broad applications, such\nas artistic creation and virtual reality. However, current generative methods\nare often task-oriented with a narrow scope, handling a restricted condition\nwith constrained applicability. In this paper, we propose a novel approach that\ntreats conditional image synthesis as the modular combination of diverse\nfundamental condition units. Specifically, we divide conditions into three\nprimary units: text, layout, and drag. To enable effective control over these\nconditions, we design a dedicated alignment module for each. For the text\ncondition, we introduce a Dense Concept Alignment (DCA) module, which achieves\ndense visual-text alignment by drawing on diverse textual concepts. For the\nlayout condition, we propose a Dense Geometry Alignment (DGA) module to enforce\ncomprehensive geometric constraints that preserve the spatial configuration.\nFor the drag condition, we introduce a Dense Motion Alignment (DMA) module to\napply multi-level motion regularization, ensuring that each pixel follows its\ndesired trajectory without visual artifacts. By flexibly inserting and\ncombining these alignment modules, our framework enhances the model's\nadaptability to diverse conditional generation tasks and greatly expands its\napplication range. Extensive experiments demonstrate the superior performance\nof our framework across a variety of conditions, including textual description,\nsegmentation mask (bounding box), drag manipulation, and their combinations.\nCode is available at https://github.com/ZixuanWang0525/DADG.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR2025",
    "pdf_url": "http://arxiv.org/pdf/2504.01515v2",
    "published_date": "2025-04-02 09:00:28 UTC",
    "updated_date": "2025-04-03 08:39:13 UTC"
  },
  {
    "arxiv_id": "2504.08769v1",
    "title": "High-order expansion of Neural Ordinary Differential Equations flows",
    "authors": [
      "Dario Izzo",
      "Sebastien Origer",
      "Giacomo Acciarini",
      "Francesco Biscani"
    ],
    "abstract": "Artificial neural networks, widely recognised for their role in machine\nlearning, are now transforming the study of ordinary differential equations\n(ODEs), bridging data-driven modelling with classical dynamical systems and\nenabling the development of infinitely deep neural models. However, the\npractical applicability of these models remains constrained by the opacity of\ntheir learned dynamics, which operate as black-box systems with limited\nexplainability, thereby hindering trust in their deployment. Existing\napproaches for the analysis of these dynamical systems are predominantly\nrestricted to first-order gradient information due to computational\nconstraints, thereby limiting the depth of achievable insight. Here, we\nintroduce Event Transition Tensors, a framework based on high-order\ndifferentials that provides a rigorous mathematical description of neural ODE\ndynamics on event manifolds. We demonstrate its versatility across diverse\napplications: characterising uncertainties in a data-driven prey-predator\ncontrol model, analysing neural optimal feedback dynamics, and mapping landing\ntrajectories in a three-body neural Hamiltonian system. In all cases, our\nmethod enhances the interpretability and rigour of neural ODEs by expressing\ntheir behaviour through explicit mathematical structures. Our findings\ncontribute to a deeper theoretical foundation for event-triggered neural\ndifferential equations and provide a mathematical construct for explaining\ncomplex system dynamics.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08769v1",
    "published_date": "2025-04-02 08:57:34 UTC",
    "updated_date": "2025-04-02 08:57:34 UTC"
  },
  {
    "arxiv_id": "2504.01468v1",
    "title": "HH-PIM: Dynamic Optimization of Power and Performance with Heterogeneous-Hybrid PIM for Edge AI Devices",
    "authors": [
      "Sangmin Jeon",
      "Kangju Lee",
      "Kyeongwon Lee",
      "Woojoo Lee"
    ],
    "abstract": "Processing-in-Memory (PIM) architectures offer promising solutions for\nefficiently handling AI applications in energy-constrained edge environments.\nWhile traditional PIM designs enhance performance and energy efficiency by\nreducing data movement between memory and processing units, they are limited in\nedge devices due to continuous power demands and the storage requirements of\nlarge neural network weights in SRAM and DRAM. Hybrid PIM architectures,\nincorporating non-volatile memories like MRAM and ReRAM, mitigate these\nlimitations but struggle with a mismatch between fixed computing resources and\ndynamically changing inference workloads. To address these challenges, this\nstudy introduces a Heterogeneous-Hybrid PIM (HH-PIM) architecture, comprising\nhigh-performance MRAM-SRAM PIM modules and low-power MRAM-SRAM PIM modules. We\nfurther propose a data placement optimization algorithm that dynamically\nallocates data based on computational demand, maximizing energy efficiency.\nFPGA prototyping and power simulations with processors featuring HH-PIM and\nother PIM types demonstrate that the proposed HH-PIM achieves up to $60.43$\npercent average energy savings over conventional PIMs while meeting application\nlatency requirements. These results confirm the suitability of HH-PIM for\nadaptive, energy-efficient AI processing in edge devices.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "7 pages, 6 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.01468v1",
    "published_date": "2025-04-02 08:22:32 UTC",
    "updated_date": "2025-04-02 08:22:32 UTC"
  },
  {
    "arxiv_id": "2504.01459v1",
    "title": "Probabilistic Curriculum Learning for Goal-Based Reinforcement Learning",
    "authors": [
      "Llewyn Salt",
      "Marcus Gallagher"
    ],
    "abstract": "Reinforcement learning (RL) -- algorithms that teach artificial agents to\ninteract with environments by maximising reward signals -- has achieved\nsignificant success in recent years. These successes have been facilitated by\nadvances in algorithms (e.g., deep Q-learning, deep deterministic policy\ngradients, proximal policy optimisation, trust region policy optimisation, and\nsoft actor-critic) and specialised computational resources such as GPUs and\nTPUs. One promising research direction involves introducing goals to allow\nmultimodal policies, commonly through hierarchical or curriculum reinforcement\nlearning. These methods systematically decompose complex behaviours into\nsimpler sub-tasks, analogous to how humans progressively learn skills (e.g. we\nlearn to run before we walk, or we learn arithmetic before calculus). However,\nfully automating goal creation remains an open challenge. We present a novel\nprobabilistic curriculum learning algorithm to suggest goals for reinforcement\nlearning agents in continuous control and navigation tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01459v1",
    "published_date": "2025-04-02 08:15:16 UTC",
    "updated_date": "2025-04-02 08:15:16 UTC"
  },
  {
    "arxiv_id": "2504.03759v1",
    "title": "Emerging Cyber Attack Risks of Medical AI Agents",
    "authors": [
      "Jianing Qiu",
      "Lin Li",
      "Jiankai Sun",
      "Hao Wei",
      "Zhe Xu",
      "Kyle Lam",
      "Wu Yuan"
    ],
    "abstract": "Large language models (LLMs)-powered AI agents exhibit a high level of\nautonomy in addressing medical and healthcare challenges. With the ability to\naccess various tools, they can operate within an open-ended action space.\nHowever, with the increase in autonomy and ability, unforeseen risks also\narise. In this work, we investigated one particular risk, i.e., cyber attack\nvulnerability of medical AI agents, as agents have access to the Internet\nthrough web browsing tools. We revealed that through adversarial prompts\nembedded on webpages, cyberattackers can: i) inject false information into the\nagent's response; ii) they can force the agent to manipulate recommendation\n(e.g., healthcare products and services); iii) the attacker can also steal\nhistorical conversations between the user and agent, resulting in the leak of\nsensitive/private medical information; iv) furthermore, the targeted agent can\nalso cause a computer system hijack by returning a malicious URL in its\nresponse. Different backbone LLMs were examined, and we found such cyber\nattacks can succeed in agents powered by most mainstream LLMs, with the\nreasoning models such as DeepSeek-R1 being the most vulnerable.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03759v1",
    "published_date": "2025-04-02 08:04:53 UTC",
    "updated_date": "2025-04-02 08:04:53 UTC"
  },
  {
    "arxiv_id": "2504.01452v1",
    "title": "BiSeg-SAM: Weakly-Supervised Post-Processing Framework for Boosting Binary Segmentation in Segment Anything Models",
    "authors": [
      "Encheng Su",
      "Hu Cao",
      "Alois Knoll"
    ],
    "abstract": "Accurate segmentation of polyps and skin lesions is essential for diagnosing\ncolorectal and skin cancers. While various segmentation methods for polyps and\nskin lesions using fully supervised deep learning techniques have been\ndeveloped, the pixel-level annotation of medical images by doctors is both\ntime-consuming and costly. Foundational vision models like the Segment Anything\nModel (SAM) have demonstrated superior performance; however, directly applying\nSAM to medical segmentation may not yield satisfactory results due to the lack\nof domain-specific medical knowledge. In this paper, we propose BiSeg-SAM, a\nSAM-guided weakly supervised prompting and boundary refinement network for the\nsegmentation of polyps and skin lesions. Specifically, we fine-tune SAM\ncombined with a CNN module to learn local features. We introduce a WeakBox with\ntwo functions: automatically generating box prompts for the SAM model and using\nour proposed Multi-choice Mask-to-Box (MM2B) transformation for rough\nmask-to-box conversion, addressing the mismatch between coarse labels and\nprecise predictions. Additionally, we apply scale consistency (SC) loss for\nprediction scale alignment. Our DetailRefine module enhances boundary precision\nand segmentation accuracy by refining coarse predictions using a limited amount\nof ground truth labels. This comprehensive approach enables BiSeg-SAM to\nachieve excellent multi-task segmentation performance. Our method demonstrates\nsignificant superiority over state-of-the-art (SOTA) methods when tested on\nfive polyp datasets and one skin cancer dataset.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "2024 IEEE International Conference on Bioinformatics and Biomedicine\n  (BIBM)",
    "pdf_url": "http://arxiv.org/pdf/2504.01452v1",
    "published_date": "2025-04-02 08:04:37 UTC",
    "updated_date": "2025-04-02 08:04:37 UTC"
  },
  {
    "arxiv_id": "2504.01445v1",
    "title": "Enabling Systematic Generalization in Abstract Spatial Reasoning through Meta-Learning for Compositionality",
    "authors": [
      "Philipp Mondorf",
      "Shijia Zhou",
      "Monica Riedler",
      "Barbara Plank"
    ],
    "abstract": "Systematic generalization refers to the capacity to understand and generate\nnovel combinations from known components. Despite recent progress by large\nlanguage models (LLMs) across various domains, these models often fail to\nextend their knowledge to novel compositional scenarios, revealing notable\nlimitations in systematic generalization. There has been an ongoing debate\nabout whether neural networks possess the capacity for systematic\ngeneralization, with recent studies suggesting that meta-learning approaches\ndesigned for compositionality can significantly enhance this ability. However,\nthese insights have largely been confined to linguistic problems, leaving their\napplicability to other tasks an open question. In this study, we extend the\napproach of meta-learning for compositionality to the domain of abstract\nspatial reasoning. To this end, we introduce $\\textit{SYGAR}$-a dataset\ndesigned to evaluate the capacity of models to systematically generalize from\nknown geometric transformations (e.g., translation, rotation) of\ntwo-dimensional objects to novel combinations of these transformations (e.g.,\ntranslation+rotation). Our results show that a transformer-based\nencoder-decoder model, trained via meta-learning for compositionality, can\nsystematically generalize to previously unseen transformation compositions,\nsignificantly outperforming state-of-the-art LLMs, including o3-mini, GPT-4o,\nand Gemini 2.0 Flash, which fail to exhibit similar systematic behavior. Our\nfindings highlight the effectiveness of meta-learning in promoting\nsystematicity beyond linguistic tasks, suggesting a promising direction toward\nmore robust and generalizable models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.01445v1",
    "published_date": "2025-04-02 07:56:39 UTC",
    "updated_date": "2025-04-02 07:56:39 UTC"
  },
  {
    "arxiv_id": "2504.01444v2",
    "title": "PiCo: Jailbreaking Multimodal Large Language Models via $\\textbf{Pi}$ctorial $\\textbf{Co}$de Contextualization",
    "authors": [
      "Aofan Liu",
      "Lulu Tang",
      "Ting Pan",
      "Yuguo Yin",
      "Bin Wang",
      "Ao Yang"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs), which integrate vision and other\nmodalities into Large Language Models (LLMs), significantly enhance AI\ncapabilities but also introduce new security vulnerabilities. By exploiting the\nvulnerabilities of the visual modality and the long-tail distribution\ncharacteristic of code training data, we present PiCo, a novel jailbreaking\nframework designed to progressively bypass multi-tiered defense mechanisms in\nadvanced MLLMs. PiCo employs a tier-by-tier jailbreak strategy, using\ntoken-level typographic attacks to evade input filtering and embedding harmful\nintent within programming context instructions to bypass runtime monitoring. To\ncomprehensively assess the impact of attacks, a new evaluation metric is\nfurther proposed to assess both the toxicity and helpfulness of model outputs\npost-attack. By embedding harmful intent within code-style visual instructions,\nPiCo achieves an average Attack Success Rate (ASR) of 84.13% on Gemini-Pro\nVision and 52.66% on GPT-4, surpassing previous methods. Experimental results\nhighlight the critical gaps in current defenses, underscoring the need for more\nrobust strategies to secure advanced MLLMs.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01444v2",
    "published_date": "2025-04-02 07:54:32 UTC",
    "updated_date": "2025-04-07 08:05:25 UTC"
  },
  {
    "arxiv_id": "2504.01429v1",
    "title": "Refining Interactions: Enhancing Anisotropy in Graph Neural Networks with Language Semantics",
    "authors": [
      "Zhaoxing Li",
      "Xiaoming Zhang",
      "Haifeng Zhang",
      "Chengxiang Liu"
    ],
    "abstract": "The integration of Large Language Models (LLMs) with Graph Neural Networks\n(GNNs) has recently been explored to enhance the capabilities of Text Attribute\nGraphs (TAGs). Most existing methods feed textual descriptions of the graph\nstructure or neighbouring nodes' text directly into LLMs. However, these\napproaches often cause LLMs to treat structural information simply as general\ncontextual text, thus limiting their effectiveness in graph-related tasks. In\nthis paper, we introduce LanSAGNN (Language Semantic Anisotropic Graph Neural\nNetwork), a framework that extends the concept of anisotropic GNNs to the\nnatural language level. This model leverages LLMs to extract tailor-made\nsemantic information for node pairs, effectively capturing the unique\ninteractions within node relationships. In addition, we propose an efficient\ndual-layer LLMs finetuning architecture to better align LLMs' outputs with\ngraph tasks. Experimental results demonstrate that LanSAGNN significantly\nenhances existing LLM-based methods without increasing complexity while also\nexhibiting strong robustness against interference.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICME 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.01429v1",
    "published_date": "2025-04-02 07:32:45 UTC",
    "updated_date": "2025-04-02 07:32:45 UTC"
  },
  {
    "arxiv_id": "2504.01428v1",
    "title": "MuTri: Multi-view Tri-alignment for OCT to OCTA 3D Image Translation",
    "authors": [
      "Zhuangzhuang Chen",
      "Hualiang Wang",
      "Chubin Ou",
      "Xiaomeng Li"
    ],
    "abstract": "Optical coherence tomography angiography (OCTA) shows its great importance in\nimaging microvascular networks by providing accurate 3D imaging of blood\nvessels, but it relies upon specialized sensors and expensive devices. For this\nreason, previous works show the potential to translate the readily available 3D\nOptical Coherence Tomography (OCT) images into 3D OCTA images. However,\nexisting OCTA translation methods directly learn the mapping from the OCT\ndomain to the OCTA domain in continuous and infinite space with guidance from\nonly a single view, i.e., the OCTA project map, resulting in suboptimal\nresults. To this end, we propose the multi-view Tri-alignment framework for OCT\nto OCTA 3D image translation in discrete and finite space, named MuTri. In the\nfirst stage, we pre-train two vector-quantized variational auto-encoder (VQ-\nVAE) by reconstructing 3D OCT and 3D OCTA data, providing semantic prior for\nsubsequent multi-view guidances. In the second stage, our multi-view\ntri-alignment facilitates another VQVAE model to learn the mapping from the OCT\ndomain to the OCTA domain in discrete and finite space. Specifically, a\ncontrastive-inspired semantic alignment is proposed to maximize the mutual\ninformation with the pre-trained models from OCT and OCTA views, to facilitate\ncodebook learning. Meanwhile, a vessel structure alignment is proposed to\nminimize the structure discrepancy with the pre-trained models from the OCTA\nproject map view, benefiting from learning the detailed vessel structure\ninformation. We also collect the first large-scale dataset, namely, OCTA2024,\nwhich contains a pair of OCT and OCTA volumes from 846 subjects.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01428v1",
    "published_date": "2025-04-02 07:28:09 UTC",
    "updated_date": "2025-04-02 07:28:09 UTC"
  },
  {
    "arxiv_id": "2504.01420v1",
    "title": "FAIRE: Assessing Racial and Gender Bias in AI-Driven Resume Evaluations",
    "authors": [
      "Athena Wen",
      "Tanush Patil",
      "Ansh Saxena",
      "Yicheng Fu",
      "Sean O'Brien",
      "Kevin Zhu"
    ],
    "abstract": "In an era where AI-driven hiring is transforming recruitment practices,\nconcerns about fairness and bias have become increasingly important. To explore\nthese issues, we introduce a benchmark, FAIRE (Fairness Assessment In Resume\nEvaluation), to test for racial and gender bias in large language models (LLMs)\nused to evaluate resumes across different industries. We use two methods-direct\nscoring and ranking-to measure how model performance changes when resumes are\nslightly altered to reflect different racial or gender identities. Our findings\nreveal that while every model exhibits some degree of bias, the magnitude and\ndirection vary considerably. This benchmark provides a clear way to examine\nthese differences and offers valuable insights into the fairness of AI-based\nhiring tools. It highlights the urgent need for strategies to reduce bias in\nAI-driven recruitment. Our benchmark code and dataset are open-sourced at our\nrepository:\nhttps://github.com/athenawen/FAIRE-Fairness-Assessment-In-Resume-Evaluation.git.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01420v1",
    "published_date": "2025-04-02 07:11:30 UTC",
    "updated_date": "2025-04-02 07:11:30 UTC"
  },
  {
    "arxiv_id": "2504.01407v1",
    "title": "TimeSearch: Hierarchical Video Search with Spotlight and Reflection for Human-like Long Video Understanding",
    "authors": [
      "Junwen Pan",
      "Rui Zhang",
      "Xin Wan",
      "Yuan Zhang",
      "Ming Lu",
      "Qi She"
    ],
    "abstract": "Large video-language models (LVLMs) have shown remarkable performance across\nvarious video-language tasks. However, they encounter significant challenges\nwhen processing long videos because of the large number of video frames\ninvolved. Downsampling long videos in either space or time can lead to visual\nhallucinations, making it difficult to accurately interpret long videos.\nMotivated by human hierarchical temporal search strategies, we propose\n\\textbf{TimeSearch}, a novel framework enabling LVLMs to understand long videos\nin a human-like manner. TimeSearch integrates two human-like primitives into a\nunified autoregressive LVLM: 1) \\textbf{Spotlight} efficiently identifies\nrelevant temporal events through a Temporal-Augmented Frame Representation\n(TAFR), explicitly binding visual features with timestamps; 2)\n\\textbf{Reflection} evaluates the correctness of the identified events,\nleveraging the inherent temporal self-reflection capabilities of LVLMs.\nTimeSearch progressively explores key events and prioritizes temporal search\nbased on reflection confidence. Extensive experiments on challenging long-video\nbenchmarks confirm that TimeSearch substantially surpasses previous\nstate-of-the-art, improving the accuracy from 41.8\\% to 51.5\\% on the LVBench.\nAdditionally, experiments on temporal grounding demonstrate that appropriate\nTAFR is adequate to effectively stimulate the surprising temporal grounding\nability of LVLMs in a simpler yet versatile manner, which improves mIoU on\nCharades-STA by 11.8\\%. The code will be released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01407v1",
    "published_date": "2025-04-02 06:47:19 UTC",
    "updated_date": "2025-04-02 06:47:19 UTC"
  },
  {
    "arxiv_id": "2504.02014v1",
    "title": "HCAF-DTA: drug-target binding affinity prediction with cross-attention fused hypergraph neural networks",
    "authors": [
      "Jiannuo Li",
      "Lan Yao"
    ],
    "abstract": "Accurate prediction of the binding affinity between drugs and target proteins\nis a core task in computer-aided drug design. Existing deep learning methods\ntend to ignore the information of internal sub-structural features of drug\nmolecules and drug-target interactions, resulting in limited prediction\nperformance. In this paper, we propose a drug-target association prediction\nmodel HCAF-DTA based on cross-attention fusion hypergraph neural network. The\nmodel innovatively introduces hypergraph representation in the feature\nextraction stage: drug molecule hypergraphs are constructed based on the tree\ndecomposition algorithm, and the sub-structural and global features extracted\nby fusing the hypergraph neural network with the graphical neural network\nthrough hopping connections, in which the hyper edges can efficiently\ncharacterise the functional functional groups and other key chemical features;\nfor the protein feature extraction, a weighted graph is constructed based on\nthe residues predicted by the ESM model contact maps to construct weighted\ngraphs, and multilayer graph neural networks were used to capture spatial\ndependencies. In the prediction stage, a bidirectional multi-head\ncross-attention mechanism is designed to model intermolecular interactions from\nthe dual viewpoints of atoms and amino acids, and cross-modal features with\ncorrelated information are fused by attention. Experiments on benchmark\ndatasets such as Davis and KIBA show that HCAF-DTA outperforms state of the\narts in all three performance evaluation metrics, with the MSE metrics reaching\n0.198 and 0.122, respectively, with an improvement of up to 4% from the optimal\nbaseline.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02014v1",
    "published_date": "2025-04-02 06:46:28 UTC",
    "updated_date": "2025-04-02 06:46:28 UTC"
  },
  {
    "arxiv_id": "2504.01403v1",
    "title": "Generative Retrieval and Alignment Model: A New Paradigm for E-commerce Retrieval",
    "authors": [
      "Ming Pang",
      "Chunyuan Yuan",
      "Xiaoyu He",
      "Zheng Fang",
      "Donghao Xie",
      "Fanyi Qu",
      "Xue Jiang",
      "Changping Peng",
      "Zhangang Lin",
      "Zheng Luo",
      "Jingping Shao"
    ],
    "abstract": "Traditional sparse and dense retrieval methods struggle to leverage general\nworld knowledge and often fail to capture the nuanced features of queries and\nproducts. With the advent of large language models (LLMs), industrial search\nsystems have started to employ LLMs to generate identifiers for product\nretrieval. Commonly used identifiers include (1) static/semantic IDs and (2)\nproduct term sets. The first approach requires creating a product ID system\nfrom scratch, missing out on the world knowledge embedded within LLMs. While\nthe second approach leverages this general knowledge, the significant\ndifference in word distribution between queries and products means that\nproduct-based identifiers often do not align well with user search queries,\nleading to missed product recalls. Furthermore, when queries contain numerous\nattributes, these algorithms generate a large number of identifiers, making it\ndifficult to assess their quality, which results in low overall recall\nefficiency.\n  To address these challenges, this paper introduces a novel e-commerce\nretrieval paradigm: the Generative Retrieval and Alignment Model (GRAM). GRAM\nemploys joint training on text information from both queries and products to\ngenerate shared text identifier codes, effectively bridging the gap between\nqueries and products. This approach not only enhances the connection between\nqueries and products but also improves inference efficiency. The model uses a\nco-alignment strategy to generate codes optimized for maximizing retrieval\nefficiency. Additionally, it introduces a query-product scoring mechanism to\ncompare product values across different codes, further boosting retrieval\nefficiency. Extensive offline and online A/B testing demonstrates that GRAM\nsignificantly outperforms traditional models and the latest generative\nretrieval models, confirming its effectiveness and practicality.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by WWW2025",
    "pdf_url": "http://arxiv.org/pdf/2504.01403v1",
    "published_date": "2025-04-02 06:40:09 UTC",
    "updated_date": "2025-04-02 06:40:09 UTC"
  },
  {
    "arxiv_id": "2504.01400v1",
    "title": "ToolACE-R: Tool Learning with Adaptive Self-Refinement",
    "authors": [
      "Xingshan Zeng",
      "Weiwen Liu",
      "Xu Huang",
      "Zezhong Wang",
      "Lingzhi Wang",
      "Liangyou Li",
      "Yasheng Wang",
      "Lifeng Shang",
      "Xin Jiang",
      "Ruiming Tang",
      "Qun Liu"
    ],
    "abstract": "Tool learning, which allows Large Language Models (LLMs) to leverage external\ntools for solving complex user tasks, has emerged as a promising avenue for\nextending model capabilities. However, current approaches primarily focus on\ndata synthesis for fine-tuning LLMs to invoke tools effectively, largely\nignoring how to fully stimulate the potential of the model. In this paper, we\npropose ToolACE-R, a novel method that introduces adaptive self-refinement for\ntool invocations. Our approach features a model-aware iterative training\nprocedure that progressively incorporates more training samples based on the\nmodel's evolving capabilities. Additionally, it allows LLMs to iteratively\nrefine their tool calls, optimizing performance without requiring external\nfeedback. To further enhance computational efficiency, we integrate an adaptive\nmechanism when scaling the inference time, enabling the model to autonomously\ndetermine when to stop the refinement process. We conduct extensive experiments\nacross several benchmark datasets, showing that ToolACE-R achieves competitive\nperformance compared to advanced API-based models, even without any refinement.\nFurthermore, its performance can be further improved efficiently through\nadaptive self-refinement. Our results demonstrate the effectiveness of the\nproposed method, which is compatible with base models of various sizes,\noffering a promising direction for more efficient tool learning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01400v1",
    "published_date": "2025-04-02 06:38:56 UTC",
    "updated_date": "2025-04-02 06:38:56 UTC"
  },
  {
    "arxiv_id": "2504.01395v1",
    "title": "From Easy to Hard: Building a Shortcut for Differentially Private Image Synthesis",
    "authors": [
      "Kecen Li",
      "Chen Gong",
      "Xiaochen Li",
      "Yuzhong Zhao",
      "Xinwen Hou",
      "Tianhao Wang"
    ],
    "abstract": "Differentially private (DP) image synthesis aims to generate synthetic images\nfrom a sensitive dataset, alleviating the privacy leakage concerns of\norganizations sharing and utilizing synthetic images. Although previous methods\nhave significantly progressed, especially in training diffusion models on\nsensitive images with DP Stochastic Gradient Descent (DP-SGD), they still\nsuffer from unsatisfactory performance. In this work, inspired by curriculum\nlearning, we propose a two-stage DP image synthesis framework, where diffusion\nmodels learn to generate DP synthetic images from easy to hard. Unlike existing\nmethods that directly use DP-SGD to train diffusion models, we propose an easy\nstage in the beginning, where diffusion models learn simple features of the\nsensitive images. To facilitate this easy stage, we propose to use `central\nimages', simply aggregations of random samples of the sensitive dataset.\nIntuitively, although those central images do not show details, they\ndemonstrate useful characteristics of all images and only incur minimal privacy\ncosts, thus helping early-phase model training. We conduct experiments to\npresent that on the average of four investigated image datasets, the fidelity\nand utility metrics of our synthetic images are 33.1% and 2.1% better than the\nstate-of-the-art method.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at IEEE S&P (Oakland) 2025; code available at\n  https://github.com/SunnierLee/DP-FETA",
    "pdf_url": "http://arxiv.org/pdf/2504.01395v1",
    "published_date": "2025-04-02 06:30:55 UTC",
    "updated_date": "2025-04-02 06:30:55 UTC"
  },
  {
    "arxiv_id": "2504.03755v1",
    "title": "ProtoGCD: Unified and Unbiased Prototype Learning for Generalized Category Discovery",
    "authors": [
      "Shijie Ma",
      "Fei Zhu",
      "Xu-Yao Zhang",
      "Cheng-Lin Liu"
    ],
    "abstract": "Generalized category discovery (GCD) is a pragmatic but underexplored\nproblem, which requires models to automatically cluster and discover novel\ncategories by leveraging the labeled samples from old classes. The challenge is\nthat unlabeled data contain both old and new classes. Early works leveraging\npseudo-labeling with parametric classifiers handle old and new classes\nseparately, which brings about imbalanced accuracy between them. Recent methods\nemploying contrastive learning neglect potential positives and are decoupled\nfrom the clustering objective, leading to biased representations and\nsub-optimal results. To address these issues, we introduce a unified and\nunbiased prototype learning framework, namely ProtoGCD, wherein old and new\nclasses are modeled with joint prototypes and unified learning objectives,\n{enabling unified modeling between old and new classes}. Specifically, we\npropose a dual-level adaptive pseudo-labeling mechanism to mitigate\nconfirmation bias, together with two regularization terms to collectively help\nlearn more suitable representations for GCD. Moreover, for practical\nconsiderations, we devise a criterion to estimate the number of new classes.\nFurthermore, we extend ProtoGCD to detect unseen outliers, achieving task-level\nunification. Comprehensive experiments show that ProtoGCD achieves\nstate-of-the-art performance on both generic and fine-grained datasets. The\ncode is available at https://github.com/mashijie1028/ProtoGCD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to IEEE TPAMI 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.03755v1",
    "published_date": "2025-04-02 06:13:14 UTC",
    "updated_date": "2025-04-02 06:13:14 UTC"
  },
  {
    "arxiv_id": "2504.01382v2",
    "title": "An Illusion of Progress? Assessing the Current State of Web Agents",
    "authors": [
      "Tianci Xue",
      "Weijian Qi",
      "Tianneng Shi",
      "Chan Hee Song",
      "Boyu Gou",
      "Dawn Song",
      "Huan Sun",
      "Yu Su"
    ],
    "abstract": "As digitalization and cloud technologies evolve, the web is becoming\nincreasingly important in the modern society. Autonomous web agents based on\nlarge language models (LLMs) hold a great potential in work automation. It is\ntherefore important to accurately measure and monitor the progression of their\ncapabilities. In this work, we conduct a comprehensive and rigorous assessment\nof the current state of web agents. Our results depict a very different picture\nof the competency of current agents, suggesting over-optimism in previously\nreported results. This gap can be attributed to shortcomings in existing\nbenchmarks. We introduce Online-Mind2Web, an online evaluation benchmark\nconsisting of 300 diverse and realistic tasks spanning 136 websites. It enables\nus to evaluate web agents under a setting that approximates how real users use\nthese agents. To facilitate more scalable evaluation and development, we also\ndevelop a novel LLM-as-a-Judge automatic evaluation method and show that it can\nachieve around 85% agreement with human judgment, substantially higher than\nexisting methods. Finally, we present the first comprehensive comparative\nanalysis of current web agents, highlighting both their strengths and\nlimitations to inspire future research.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "22 pages, 17 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.01382v2",
    "published_date": "2025-04-02 05:51:29 UTC",
    "updated_date": "2025-05-11 19:04:07 UTC"
  },
  {
    "arxiv_id": "2504.02011v1",
    "title": "Random Conditioning with Distillation for Data-Efficient Diffusion Model Compression",
    "authors": [
      "Dohyun Kim",
      "Sehwan Park",
      "Geonhee Han",
      "Seung Wook Kim",
      "Paul Hongsuck Seo"
    ],
    "abstract": "Diffusion models generate high-quality images through progressive denoising\nbut are computationally intensive due to large model sizes and repeated\nsampling. Knowledge distillation, which transfers knowledge from a complex\nteacher to a simpler student model, has been widely studied in recognition\ntasks, particularly for transferring concepts unseen during student training.\nHowever, its application to diffusion models remains underexplored, especially\nin enabling student models to generate concepts not covered by the training\nimages. In this work, we propose Random Conditioning, a novel approach that\npairs noised images with randomly selected text conditions to enable efficient,\nimage-free knowledge distillation. By leveraging this technique, we show that\nthe student can generate concepts unseen in the training images. When applied\nto conditional diffusion model distillation, our method allows the student to\nexplore the condition space without generating condition-specific images,\nresulting in notable improvements in both generation quality and efficiency.\nThis promotes resource-efficient deployment of generative diffusion models,\nbroadening their accessibility for both research and real-world applications.\nCode, models, and datasets are available at\nhttps://dohyun-as.github.io/Random-Conditioning .",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to CVPR 2025. 8 pages main paper + 4 pages references + 5\n  pages supplementary, 9 figures in total",
    "pdf_url": "http://arxiv.org/pdf/2504.02011v1",
    "published_date": "2025-04-02 05:41:19 UTC",
    "updated_date": "2025-04-02 05:41:19 UTC"
  },
  {
    "arxiv_id": "2504.01366v1",
    "title": "Virtual Reality and Artificial Intelligence as Psychological Countermeasures in Space and Other Isolated and Confined Environments: A Scoping Review",
    "authors": [
      "Jennifer Sharp",
      "Joshua Kelson",
      "Daryl South",
      "Anthony Saliba",
      "Muhammad Ashad Kabir"
    ],
    "abstract": "Spaceflight is an isolated and confined environment (ICE) that exposes\nastronauts to psychological hazards, such as stress, danger, and monotony.\nVirtual reality (VR) and artificial intelligence (AI) technologies can serve as\npsychological countermeasures as they can digitally simulate immersive\nenvironments, interactive companions, and therapeutic experiences. Our study\nemploys a scoping literature review approach to identify what is currently\nknown about the use and effectiveness of VR and AI-based interventions as\npsychological countermeasures to improve mood or emotional states in adults in\nspace or other ICEs. Additionally, this review aimed to identify gaps in the\nknowledge base and whether a systematic review with meta-analysis was\nwarranted. The review included studies where the intervention was used or\nintended for use in space or other extraterrestrial environments (ICE). Our\nsearch strategy yielded 19 studies from 3390 records across seven major\ndatabases. All studies focused on VR-based interventions, with no eligible\nAI-based intervention studies found. VR interventions were found to be\neffective for relaxation and improving mood, emergency training, as an\ninteractive communication platform, for comparing interior designs, and for\nenhancing exercise. There were improvements for measures of mood and emotion\\n\n(e.g., anxiety and stress); however, user preferences varied, and some\ninstances of cybersickness were reported. A systematic review with\nmeta-analysis is not recommended due to the heterogeneity of results. There is\nsignificant scope for further research into the use of VR for a wider range of\nmood and emotion variables using standardised assessment instruments.\nAdditionally, the potential application of AI as a psychological countermeasure\nwarrants further investigation.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.HC",
    "comment": "34 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.01366v1",
    "published_date": "2025-04-02 05:25:29 UTC",
    "updated_date": "2025-04-02 05:25:29 UTC"
  },
  {
    "arxiv_id": "2504.02010v1",
    "title": "When Reasoning Meets Compression: Benchmarking Compressed Large Reasoning Models on Complex Reasoning Tasks",
    "authors": [
      "Nan Zhang",
      "Yusen Zhang",
      "Prasenjit Mitra",
      "Rui Zhang"
    ],
    "abstract": "Recent open-source large reasoning models (LRMs) exhibit strong performance\non complex reasoning tasks, but their large parameter count makes them\nprohibitively expensive for individuals. The compression of large language\nmodels (LLMs) offers an effective solution to reduce cost of computational\nresources. However, systematic studies on the performance of compressed LLMs in\ncomplex reasoning tasks, especially for LRMs, are lacking. Most works on\nquantization and pruning focus on preserving language modeling performance,\nwhile existing distillation works do not comprehensively benchmark student\nmodels based on reasoning difficulty or compression impact on knowledge and\nreasoning. In this paper, we benchmark compressed DeepSeek-R1 models on four\ndifferent reasoning datasets (AIME 2024, FOLIO, Temporal Sequences of BIG-Bench\nHard, and MuSiQue), ranging from mathematical to multihop reasoning, using\nquantization, distillation, and pruning methods. We benchmark 2.51-, 1.73-, and\n1.58-bit R1 models that adopt dynamic quantization. We also benchmark distilled\nR1 models that are based on LLaMA or Qwen and run SparseGPT on them to obtain\nvarious sparsity levels. Studying the performance and behavior of compressed\nLRMs, we report their performance scores and test-time compute (number of\ntokens spent on each question). Notably, using MuSiQue, we find that parameter\ncount has a much greater impact on LRMs' knowledge memorization than on their\nreasoning capability, which can inform the choice of compression techniques.\nThrough our empirical analysis of test-time compute, we find that shorter model\noutputs generally achieve better performance than longer ones across several\nbenchmarks for both R1 and its compressed variants, highlighting the need for\nmore concise reasoning chains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02010v1",
    "published_date": "2025-04-02 05:17:46 UTC",
    "updated_date": "2025-04-02 05:17:46 UTC"
  },
  {
    "arxiv_id": "2504.02880v1",
    "title": "Global Rice Multi-Class Segmentation Dataset (RiceSEG): A Comprehensive and Diverse High-Resolution RGB-Annotated Images for the Development and Benchmarking of Rice Segmentation Algorithms",
    "authors": [
      "Junchi Zhou",
      "Haozhou Wang",
      "Yoichiro Kato",
      "Tejasri Nampally",
      "P. Rajalakshmi",
      "M. Balram",
      "Keisuke Katsura",
      "Hao Lu",
      "Yue Mu",
      "Wanneng Yang",
      "Yangmingrui Gao",
      "Feng Xiao",
      "Hongtao Chen",
      "Yuhao Chen",
      "Wenjuan Li",
      "Jingwen Wang",
      "Fenghua Yu",
      "Jian Zhou",
      "Wensheng Wang",
      "Xiaochun Hu",
      "Yuanzhu Yang",
      "Yanfeng Ding",
      "Wei Guo",
      "Shouyang Liu"
    ],
    "abstract": "Developing computer vision-based rice phenotyping techniques is crucial for\nprecision field management and accelerating breeding, thereby continuously\nadvancing rice production. Among phenotyping tasks, distinguishing image\ncomponents is a key prerequisite for characterizing plant growth and\ndevelopment at the organ scale, enabling deeper insights into eco-physiological\nprocesses. However, due to the fine structure of rice organs and complex\nillumination within the canopy, this task remains highly challenging,\nunderscoring the need for a high-quality training dataset. Such datasets are\nscarce, both due to a lack of large, representative collections of rice field\nimages and the time-intensive nature of annotation. To address this gap, we\nestablished the first comprehensive multi-class rice semantic segmentation\ndataset, RiceSEG. We gathered nearly 50,000 high-resolution, ground-based\nimages from five major rice-growing countries (China, Japan, India, the\nPhilippines, and Tanzania), encompassing over 6,000 genotypes across all growth\nstages. From these original images, 3,078 representative samples were selected\nand annotated with six classes (background, green vegetation, senescent\nvegetation, panicle, weeds, and duckweed) to form the RiceSEG dataset. Notably,\nthe sub-dataset from China spans all major genotypes and rice-growing\nenvironments from the northeast to the south. Both state-of-the-art\nconvolutional neural networks and transformer-based semantic segmentation\nmodels were used as baselines. While these models perform reasonably well in\nsegmenting background and green vegetation, they face difficulties during the\nreproductive stage, when canopy structures are more complex and multiple\nclasses are involved. These findings highlight the importance of our dataset\nfor developing specialized segmentation models for rice and other crops.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02880v1",
    "published_date": "2025-04-02 04:03:23 UTC",
    "updated_date": "2025-04-02 04:03:23 UTC"
  },
  {
    "arxiv_id": "2504.01337v2",
    "title": "Advancing MoE Efficiency: A Collaboration-Constrained Routing (C2R) Strategy for Better Expert Parallelism Design",
    "authors": [
      "Mohan Zhang",
      "Pingzhi Li",
      "Jie Peng",
      "Mufan Qiu",
      "Tianlong Chen"
    ],
    "abstract": "Mixture-of-Experts (MoE) has successfully scaled up models while maintaining\nnearly constant computing costs. By employing a gating network to route input\ntokens, it selectively activates a subset of expert networks to process the\ncorresponding token embeddings. However, in practice, the efficiency of MoE is\nchallenging to achieve due to two key reasons: imbalanced expert activation,\nwhich leads to substantial idle time during model or expert parallelism, and\ninsufficient capacity utilization; massive communication overhead, induced by\nnumerous expert routing combinations in expert parallelism at the system level.\nPrevious works typically formulate it as the load imbalance issue characterized\nby the gating network favoring certain experts over others or attribute it to\nstatic execution which fails to adapt to the dynamic expert workload at\nruntime. In this paper, we exploit it from a brand new perspective, a\nhigher-order view and analysis of MoE routing policies: expert collaboration\nand specialization where some experts tend to activate broadly with others\n(collaborative), while others are more likely to activate only with a specific\nsubset of experts (specialized). Our experiments reveal that most experts tend\nto be overly collaborative, leading to increased communication overhead from\nrepeatedly sending tokens to different accelerators. To this end, we propose a\nnovel collaboration-constrained routing (C2R) strategy to encourage more\nspecialized expert groups, as well as to improve expert utilization, and\npresent an efficient implementation of MoE that further leverages expert\nspecialization. We achieve an average performance improvement of 0.51% and\n0.33% on LLaMA-MoE and Qwen-MoE respectively across ten downstream NLP\nbenchmarks, and reduce the all2all communication costs between GPUs, bringing\nan extra 20%-30% total running time savings on top of the existing SoTA, i.e.\nMegaBlocks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "NAACL 2025, SAC award for Low-resource Methods for NLP",
    "pdf_url": "http://arxiv.org/pdf/2504.01337v2",
    "published_date": "2025-04-02 03:51:59 UTC",
    "updated_date": "2025-04-20 15:13:33 UTC"
  },
  {
    "arxiv_id": "2504.01331v1",
    "title": "An Explainable Reconfiguration-Based Optimization Algorithm for Industrial and Reliability-Redundancy Allocation Problems",
    "authors": [
      "Dikshit Chauhan",
      "Nitin Gupta",
      "Anupam Yadav"
    ],
    "abstract": "Industrial and reliability optimization problems often involve complex\nconstraints and require efficient, interpretable solutions. This paper presents\nAI-AEFA, an advanced parameter reconfiguration-based metaheuristic algorithm\ndesigned to address large-scale industrial and reliability-redundancy\nallocation problems. AI-AEFA enhances search space exploration and convergence\nefficiency through a novel log-sigmoid-based parameter adaptation and chaotic\nmapping mechanism. The algorithm is validated across twenty-eight IEEE CEC 2017\nconstrained benchmark problems, fifteen large-scale industrial optimization\nproblems, and seven reliability-redundancy allocation problems, consistently\noutperforming state-of-the-art optimization techniques in terms of feasibility,\ncomputational efficiency, and convergence speed. The additional key\ncontribution of this work is the integration of SHAP (Shapley Additive\nExplanations) to enhance the interpretability of AI-AEFA, providing insights\ninto the impact of key parameters such as Coulomb's constant, charge,\nacceleration, and electrostatic force. This explainability feature enables a\ndeeper understanding of decision-making within the AI-AEFA framework during the\noptimization processes. The findings confirm AI-AEFA as a robust, scalable, and\ninterpretable optimization tool with significant real-world applications.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "38 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.01331v1",
    "published_date": "2025-04-02 03:33:48 UTC",
    "updated_date": "2025-04-02 03:33:48 UTC"
  },
  {
    "arxiv_id": "2504.01326v1",
    "title": "CFMD: Dynamic Cross-layer Feature Fusion for Salient Object Detection",
    "authors": [
      "Jin Lian",
      "Zhongyu Wan",
      "Ming Gao",
      "JunFeng Chen"
    ],
    "abstract": "Cross-layer feature pyramid networks (CFPNs) have achieved notable progress\nin multi-scale feature fusion and boundary detail preservation for salient\nobject detection. However, traditional CFPNs still suffer from two core\nlimitations: (1) a computational bottleneck caused by complex feature weighting\noperations, and (2) degraded boundary accuracy due to feature blurring in the\nupsampling process. To address these challenges, we propose CFMD, a novel\ncross-layer feature pyramid network that introduces two key innovations. First,\nwe design a context-aware feature aggregation module (CFLMA), which\nincorporates the state-of-the-art Mamba architecture to construct a dynamic\nweight distribution mechanism. This module adaptively adjusts feature\nimportance based on image context, significantly improving both representation\nefficiency and generalization. Second, we introduce an adaptive dynamic\nupsampling unit (CFLMD) that preserves spatial details during resolution\nrecovery. By adjusting the upsampling range dynamically and initializing with a\nbilinear strategy, the module effectively reduces feature overlap and maintains\nfine-grained boundary structures. Extensive experiments on three standard\nbenchmarks using three mainstream backbone networks demonstrate that CFMD\nachieves substantial improvements in pixel-level accuracy and boundary\nsegmentation quality, especially in complex scenes. The results validate the\neffectiveness of CFMD in jointly enhancing computational efficiency and\nsegmentation performance, highlighting its strong potential in salient object\ndetection tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01326v1",
    "published_date": "2025-04-02 03:22:36 UTC",
    "updated_date": "2025-04-02 03:22:36 UTC"
  },
  {
    "arxiv_id": "2504.01324v1",
    "title": "On Data Synthesis and Post-training for Visual Abstract Reasoning",
    "authors": [
      "Ke Zhu",
      "Yu Wang",
      "Jiangjiang Liu",
      "Qunyi Xie",
      "Shanshan Liu",
      "Gang Zhang"
    ],
    "abstract": "This paper is a pioneering work attempting to address abstract visual\nreasoning (AVR) problems for large vision-language models (VLMs). We make a\ncommon LLaVA-NeXT 7B model capable of perceiving and reasoning about specific\nAVR problems, surpassing both open-sourced (e.g., Qwen-2-VL-72B) and\nclosed-sourced powerful VLMs (e.g., GPT-4o) with significant margin. This is a\ngreat breakthrough since almost all previous VLMs fail or show nearly random\nperformance on representative AVR benchmarks. Our key success is our innovative\ndata synthesis and post-training process, aiming to fully relieve the task\ndifficulty and elicit the model to learn, step by step. Our 7B model is also\nshown to be behave well on AVR without sacrificing common multimodal\ncomprehension abilities. We hope our paper could serve as an early effort in\nthis area and would inspire further research in abstract visual reasoning.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01324v1",
    "published_date": "2025-04-02 03:18:24 UTC",
    "updated_date": "2025-04-02 03:18:24 UTC"
  },
  {
    "arxiv_id": "2504.01321v1",
    "title": "COST: Contrastive One-Stage Transformer for Vision-Language Small Object Tracking",
    "authors": [
      "Chunhui Zhang",
      "Li Liu",
      "Jialin Gao",
      "Xin Sun",
      "Hao Wen",
      "Xi Zhou",
      "Shiming Ge",
      "Yanfeng Wang"
    ],
    "abstract": "Transformer has recently demonstrated great potential in improving\nvision-language (VL) tracking algorithms. However, most of the existing VL\ntrackers rely on carefully designed mechanisms to perform the multi-stage\nmulti-modal fusion. Additionally, direct multi-modal fusion without alignment\nignores distribution discrepancy between modalities in feature space,\npotentially leading to suboptimal representations. In this work, we propose\nCOST, a contrastive one-stage transformer fusion framework for VL tracking,\naiming to learn semantically consistent and unified VL representations.\nSpecifically, we introduce a contrastive alignment strategy that maximizes\nmutual information (MI) between a video and its corresponding language\ndescription. This enables effective cross-modal alignment, yielding\nsemantically consistent features in the representation space. By leveraging a\nvisual-linguistic transformer, we establish an efficient multi-modal fusion and\nreasoning mechanism, empirically demonstrating that a simple stack of\ntransformer encoders effectively enables unified VL representations. Moreover,\nwe contribute a newly collected VL tracking benchmark dataset for small object\ntracking, named VL-SOT500, with bounding boxes and language descriptions. Our\ndataset comprises two challenging subsets, VL-SOT230 and VL-SOT270, dedicated\nto evaluating generic and high-speed small object tracking, respectively. Small\nobject tracking is notoriously challenging due to weak appearance and limited\nfeatures, and this dataset is, to the best of our knowledge, the first to\nexplore the usage of language cues to enhance visual representation for small\nobject tracking. Extensive experiments demonstrate that COST achieves\nstate-of-the-art performance on five existing VL tracking datasets, as well as\non our proposed VL-SOT500 dataset. Source codes and dataset will be made\npublicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint submitted to Elsevier.\n  https://github.com/983632847/Awesome-Multimodal-Object-Tracking",
    "pdf_url": "http://arxiv.org/pdf/2504.01321v1",
    "published_date": "2025-04-02 03:12:38 UTC",
    "updated_date": "2025-04-02 03:12:38 UTC"
  },
  {
    "arxiv_id": "2504.02008v1",
    "title": "Test-time Adaptation for Foundation Medical Segmentation Model without Parametric Updates",
    "authors": [
      "Kecheng Chen",
      "Xinyu Luo",
      "Tiexin Qin",
      "Jie Liu",
      "Hui Liu",
      "Victor Ho Fun Lee",
      "Hong Yan",
      "Haoliang Li"
    ],
    "abstract": "Foundation medical segmentation models, with MedSAM being the most popular,\nhave achieved promising performance across organs and lesions. However, MedSAM\nstill suffers from compromised performance on specific lesions with intricate\nstructures and appearance, as well as bounding box prompt-induced\nperturbations. Although current test-time adaptation (TTA) methods for medical\nimage segmentation may tackle this issue, partial (e.g., batch normalization)\nor whole parametric updates restrict their effectiveness due to limited update\nsignals or catastrophic forgetting in large models. Meanwhile, these approaches\nignore the computational complexity during adaptation, which is particularly\nsignificant for modern foundation models. To this end, our theoretical analyses\nreveal that directly refining image embeddings is feasible to approach the same\ngoal as parametric updates under the MedSAM architecture, which enables us to\nrealize high computational efficiency and segmentation performance without the\nrisk of catastrophic forgetting. Under this framework, we propose to encourage\nmaximizing factorized conditional probabilities of the posterior prediction\nprobability using a proposed distribution-approximated latent conditional\nrandom field loss combined with an entropy minimization loss. Experiments show\nthat we achieve about 3\\% Dice score improvements across three datasets while\nreducing computational complexity by over 7 times.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2504.02008v1",
    "published_date": "2025-04-02 03:03:34 UTC",
    "updated_date": "2025-04-02 03:03:34 UTC"
  },
  {
    "arxiv_id": "2504.01317v1",
    "title": "Adaptive Rectification Sampling for Test-Time Compute Scaling",
    "authors": [
      "Zhendong Tan",
      "Xingjun Zhang",
      "Chaoyi Hu",
      "Yancheng Pan",
      "Shaoxun Wang"
    ],
    "abstract": "The newly released OpenAI-o1 and DeepSeek-R1 have demonstrated that test-time\nscaling can significantly improve model performance, especially in complex\ntasks such as logical reasoning. Common test-time scaling methods involve\ngenerating more chain of thoughts (CoTs) or longer CoTs with self-correction.\nHowever, while self-correction can improve performance, it may lead to\nsignificant token waste and reduce readability of the CoT if the reasoning\nsteps are already correct. To demonstrate that large language models (LLMs) can\nrectify errors at a more fine-grained level, we propose Adaptive Rectification\nSampling (AR-Sampling), which can guide the LLMs to self-correction at the\nappropriate step. AR-Sampling leverages a process-supervised reward model (PRM)\nas a verifier and constructed trigger sentences to guide the model in adaptive\nstep-level rethinking. Through the experiments on GSM8K and MATH500, it\nindicate that our approach enables the models to rethink in more fine-grained\nlevel, improving the accuracy of solutions, while generating a reasonable\nnumber of additional tokens.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01317v1",
    "published_date": "2025-04-02 02:57:52 UTC",
    "updated_date": "2025-04-02 02:57:52 UTC"
  },
  {
    "arxiv_id": "2504.01309v1",
    "title": "Biomedical Question Answering via Multi-Level Summarization on a Local Knowledge Graph",
    "authors": [
      "Lingxiao Guan",
      "Yuanhao Huang",
      "Jie Liu"
    ],
    "abstract": "In Question Answering (QA), Retrieval Augmented Generation (RAG) has\nrevolutionized performance in various domains. However, how to effectively\ncapture multi-document relationships, particularly critical for biomedical\ntasks, remains an open question. In this work, we propose a novel method that\nutilizes propositional claims to construct a local knowledge graph from\nretrieved documents. Summaries are then derived via layerwise summarization\nfrom the knowledge graph to contextualize a small language model to perform QA.\nWe achieved comparable or superior performance with our method over RAG\nbaselines on several biomedical QA benchmarks. We also evaluated each\nindividual step of our methodology over a targeted set of metrics,\ndemonstrating its effectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01309v1",
    "published_date": "2025-04-02 02:40:19 UTC",
    "updated_date": "2025-04-02 02:40:19 UTC"
  },
  {
    "arxiv_id": "2504.01301v1",
    "title": "Bi-LAT: Bilateral Control-Based Imitation Learning via Natural Language and Action Chunking with Transformers",
    "authors": [
      "Takumi Kobayashi",
      "Masato Kobayashi",
      "Thanpimon Buamanee",
      "Yuki Uranishi"
    ],
    "abstract": "We present Bi-LAT, a novel imitation learning framework that unifies\nbilateral control with natural language processing to achieve precise force\nmodulation in robotic manipulation. Bi-LAT leverages joint position, velocity,\nand torque data from leader-follower teleoperation while also integrating\nvisual and linguistic cues to dynamically adjust applied force. By encoding\nhuman instructions such as \"softly grasp the cup\" or \"strongly twist the\nsponge\" through a multimodal Transformer-based model, Bi-LAT learns to\ndistinguish nuanced force requirements in real-world tasks. We demonstrate\nBi-LAT's performance in (1) unimanual cup-stacking scenario where the robot\naccurately modulates grasp force based on language commands, and (2) bimanual\nsponge-twisting task that requires coordinated force control. Experimental\nresults show that Bi-LAT effectively reproduces the instructed force levels,\nparticularly when incorporating SigLIP among tested language encoders. Our\nfindings demonstrate the potential of integrating natural language cues into\nimitation learning, paving the way for more intuitive and adaptive human-robot\ninteraction. For additional material, please visit:\nhttps://mertcookimg.github.io/bi-lat/",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01301v1",
    "published_date": "2025-04-02 02:21:30 UTC",
    "updated_date": "2025-04-02 02:21:30 UTC"
  },
  {
    "arxiv_id": "2504.01281v3",
    "title": "Scaling Test-Time Inference with Policy-Optimized, Dynamic Retrieval-Augmented Generation via KV Caching and Decoding",
    "authors": [
      "Sakhinana Sagar Srinivas",
      "Akash Das",
      "Shivam Gupta",
      "Venkataramana Runkana"
    ],
    "abstract": "We present a comprehensive framework for enhancing Retrieval-Augmented\nGeneration (RAG) systems through dynamic retrieval strategies and reinforcement\nfine-tuning. This approach significantly improves large language models on\nknowledge-intensive tasks, including opendomain question answering and complex\nreasoning. Our framework integrates two complementary techniques:\nPolicy-Optimized RetrievalAugmented Generation (PORAG), which optimizes the use\nof retrieved information, and Adaptive Token-Layer Attention Scoring (ATLAS),\nwhich dynamically determines retrieval timing and content based on contextual\nneeds. Together, these techniques enhance both the utilization and relevance of\nretrieved content, improving factual accuracy and response quality. Designed as\na lightweight solution compatible with any Transformer-based LLM without\nrequiring additional training, our framework excels in knowledge-intensive\ntasks, boosting output accuracy in RAG settings. We further propose CRITIC, a\nnovel method to selectively compress key-value caches by token importance,\nmitigating memory bottlenecks in long-context applications. The framework also\nincorporates test-time scaling techniques to dynamically balance reasoning\ndepth and computational resources, alongside optimized decoding strategies for\nfaster inference. Experiments on benchmark datasets show that our framework\nreduces hallucinations, strengthens domain-specific reasoning, and achieves\nsignificant efficiency and scalability gains over traditional RAG systems. This\nintegrated approach advances the development of robust, efficient, and scalable\nRAG systems across diverse applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01281v3",
    "published_date": "2025-04-02 01:16:10 UTC",
    "updated_date": "2025-05-20 04:52:21 UTC"
  },
  {
    "arxiv_id": "2504.01278v1",
    "title": "Strategize Globally, Adapt Locally: A Multi-Turn Red Teaming Agent with Dual-Level Learning",
    "authors": [
      "Si Chen",
      "Xiao Yu",
      "Ninareh Mehrabi",
      "Rahul Gupta",
      "Zhou Yu",
      "Ruoxi Jia"
    ],
    "abstract": "The exploitation of large language models (LLMs) for malicious purposes poses\nsignificant security risks as these models become more powerful and widespread.\nWhile most existing red-teaming frameworks focus on single-turn attacks,\nreal-world adversaries typically operate in multi-turn scenarios, iteratively\nprobing for vulnerabilities and adapting their prompts based on threat model\nresponses. In this paper, we propose \\AlgName, a novel multi-turn red-teaming\nagent that emulates sophisticated human attackers through complementary\nlearning dimensions: global tactic-wise learning that accumulates knowledge\nover time and generalizes to new attack goals, and local prompt-wise learning\nthat refines implementations for specific goals when initial attempts fail.\nUnlike previous multi-turn approaches that rely on fixed strategy sets,\n\\AlgName enables the agent to identify new jailbreak tactics, develop a\ngoal-based tactic selection framework, and refine prompt formulations for\nselected tactics. Empirical evaluations on JailbreakBench demonstrate our\nframework's superior performance, achieving over 90\\% attack success rates\nagainst GPT-3.5-Turbo and Llama-3.1-70B within 5 conversation turns,\noutperforming state-of-the-art baselines. These results highlight the\neffectiveness of dynamic learning in identifying and exploiting model\nvulnerabilities in realistic multi-turn scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01278v1",
    "published_date": "2025-04-02 01:06:19 UTC",
    "updated_date": "2025-04-02 01:06:19 UTC"
  },
  {
    "arxiv_id": "2504.03752v1",
    "title": "Proof of Humanity: A Multi-Layer Network Framework for Certifying Human-Originated Content in an AI-Dominated Internet",
    "authors": [
      "Sebastian Barros"
    ],
    "abstract": "The rapid proliferation of generative AI has led to an internet increasingly\npopulated with synthetic content-text, images, audio, and video generated\nwithout human intervention. As the distinction between human and AI-generated\ndata blurs, the ability to verify content origin becomes critical for\napplications ranging from social media and journalism to legal and financial\nsystems.\n  In this paper, we propose a conceptual, multi-layer architectural framework\nthat enables telecommunications networks to act as infrastructure level\ncertifiers of human-originated content. By leveraging identity anchoring at the\nphysical layer, metadata propagation at the network and transport layers, and\ncryptographic attestations at the session and application layers, Telcos can\nprovide an end-to-end Proof of Humanity for data traversing their networks.\n  We outline how each OSI layer can contribute to this trust fabric using\ntechnical primitives such as SIM/eSIM identity, digital signatures,\nbehavior-based ML heuristics, and edge-validated APIs. The framework is\npresented as a foundation for future implementation, highlighting monetization\npathways for telcos such as trust-as-a-service APIs, origin-certified traffic\ntiers, and regulatory compliance tools.\n  The paper does not present implementation or benchmarking results but offers\na technically detailed roadmap and strategic rationale for transforming Telcos\ninto validators of digital authenticity in an AI-dominated internet. Security,\nprivacy, and adversarial considerations are discussed as directions for future\nwork.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "34 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.03752v1",
    "published_date": "2025-04-02 00:02:51 UTC",
    "updated_date": "2025-04-02 00:02:51 UTC"
  }
]