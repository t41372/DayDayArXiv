[
  {
    "arxiv_id": "2411.12128v3",
    "title": "The Role of Accuracy and Validation Effectiveness in Conversational Business Analytics",
    "authors": [
      "Adem Alparslan"
    ],
    "abstract": "This study examines conversational business analytics, an approach that\nutilizes AI to address the technical competency gaps that hinder end users from\neffectively using traditional self-service analytics. By facilitating natural\nlanguage interactions, conversational business analytics aims to empower end\nusers to independently retrieve data and generate insights. The analysis\nfocuses on Text-to-SQL as a representative technology for translating natural\nlanguage requests into SQL statements. Developing theoretical models grounded\nin expected utility theory, this study identifies the conditions under which\nconversational business analytics, through partial or full support, can\noutperform delegation to human experts. The results indicate that partial\nsupport, focusing solely on information generation by AI, is viable when the\naccuracy of AI-generated SQL queries leads to a profit that surpasses the\nperformance of a human expert. In contrast, full support includes not only\ninformation generation but also validation through explanations provided by the\nAI, and requires sufficiently high validation effectiveness to be reliable.\nHowever, user-based validation presents challenges, such as misjudgment and\nrejection of valid SQL queries, which may limit the effectiveness of\nconversational business analytics. These challenges underscore the need for\nrobust validation mechanisms, including improved user support, automated\nprocesses, and methods for assessing quality independent of the technical\ncompetency of end users.",
    "categories": [
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.12128v3",
    "published_date": "2024-11-18 23:58:24 UTC",
    "updated_date": "2024-11-25 10:14:53 UTC"
  },
  {
    "arxiv_id": "2411.12115v1",
    "title": "Distill the Best, Ignore the Rest: Improving Dataset Distillation with Loss-Value-Based Pruning",
    "authors": [
      "Brian B. Moser",
      "Federico Raue",
      "Tobias C. Nauen",
      "Stanislav Frolov",
      "Andreas Dengel"
    ],
    "abstract": "Dataset distillation has gained significant interest in recent years, yet\nexisting approaches typically distill from the entire dataset, potentially\nincluding non-beneficial samples. We introduce a novel \"Prune First, Distill\nAfter\" framework that systematically prunes datasets via loss-based sampling\nprior to distillation. By leveraging pruning before classical distillation\ntechniques and generative priors, we create a representative core-set that\nleads to enhanced generalization for unseen architectures - a significant\nchallenge of current distillation methods. More specifically, our proposed\nframework significantly boosts distilled quality, achieving up to a 5.2\npercentage points accuracy increase even with substantial dataset pruning,\ni.e., removing 80% of the original dataset prior to distillation. Overall, our\nexperimental results highlight the advantages of our easy-sample prioritization\nand cross-architecture robustness, paving the way for more effective and\nhigh-quality dataset distillation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.12115v1",
    "published_date": "2024-11-18 22:51:44 UTC",
    "updated_date": "2024-11-18 22:51:44 UTC"
  },
  {
    "arxiv_id": "2411.17713v1",
    "title": "Llama Guard 3-1B-INT4: Compact and Efficient Safeguard for Human-AI Conversations",
    "authors": [
      "Igor Fedorov",
      "Kate Plawiak",
      "Lemeng Wu",
      "Tarek Elgamal",
      "Naveen Suda",
      "Eric Smith",
      "Hongyuan Zhan",
      "Jianfeng Chi",
      "Yuriy Hulovatyy",
      "Kimish Patel",
      "Zechun Liu",
      "Changsheng Zhao",
      "Yangyang Shi",
      "Tijmen Blankevoort",
      "Mahesh Pasupuleti",
      "Bilge Soran",
      "Zacharie Delpierre Coudert",
      "Rachad Alao",
      "Raghuraman Krishnamoorthi",
      "Vikas Chandra"
    ],
    "abstract": "This paper presents Llama Guard 3-1B-INT4, a compact and efficient Llama\nGuard model, which has been open-sourced to the community during Meta Connect\n2024. We demonstrate that Llama Guard 3-1B-INT4 can be deployed on\nresource-constrained devices, achieving a throughput of at least 30 tokens per\nsecond and a time-to-first-token of 2.5 seconds or less on a commodity Android\nmobile CPU. Notably, our experiments show that Llama Guard 3-1B-INT4 attains\ncomparable or superior safety moderation scores to its larger counterpart,\nLlama Guard 3-1B, despite being approximately 7 times smaller in size (440MB).",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.17713v1",
    "published_date": "2024-11-18 21:42:17 UTC",
    "updated_date": "2024-11-18 21:42:17 UTC"
  },
  {
    "arxiv_id": "2411.12073v2",
    "title": "Just Leaf It: Accelerating Diffusion Classifiers with Hierarchical Class Pruning",
    "authors": [
      "Arundhati S. Shanbhag",
      "Brian B. Moser",
      "Tobias C. Nauen",
      "Stanislav Frolov",
      "Federico Raue",
      "Andreas Dengel"
    ],
    "abstract": "Diffusion models, celebrated for their generative capabilities, have recently\ndemonstrated surprising effectiveness in image classification tasks by using\nBayes' theorem. Yet, current diffusion classifiers must evaluate every label\ncandidate for each input, creating high computational costs that impede their\nuse in large-scale applications. To address this limitation, we propose a\nHierarchical Diffusion Classifier (HDC) that exploits hierarchical label\nstructures or well-defined parent-child relationships in the dataset. By\npruning irrelevant high-level categories and refining predictions only within\nrelevant subcategories (leaf nodes and sub-trees), HDC reduces the total number\nof class evaluations. As a result, HDC can speed up inference by as much as 60%\nwhile preserving and sometimes even improving classification accuracy. In\nsummary, our work provides a tunable control mechanism between speed and\nprecision, making diffusion-based classification more feasible for large-scale\napplications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.12073v2",
    "published_date": "2024-11-18 21:34:05 UTC",
    "updated_date": "2025-03-08 00:47:43 UTC"
  },
  {
    "arxiv_id": "2411.12072v1",
    "title": "Zoomed In, Diffused Out: Towards Local Degradation-Aware Multi-Diffusion for Extreme Image Super-Resolution",
    "authors": [
      "Brian B. Moser",
      "Stanislav Frolov",
      "Tobias C. Nauen",
      "Federico Raue",
      "Andreas Dengel"
    ],
    "abstract": "Large-scale, pre-trained Text-to-Image (T2I) diffusion models have gained\nsignificant popularity in image generation tasks and have shown unexpected\npotential in image Super-Resolution (SR). However, most existing T2I diffusion\nmodels are trained with a resolution limit of 512x512, making scaling beyond\nthis resolution an unresolved but necessary challenge for image SR. In this\nwork, we introduce a novel approach that, for the first time, enables these\nmodels to generate 2K, 4K, and even 8K images without any additional training.\nOur method leverages MultiDiffusion, which distributes the generation across\nmultiple diffusion paths to ensure global coherence at larger scales, and local\ndegradation-aware prompt extraction, which guides the T2I model to reconstruct\nfine local structures according to its low-resolution input. These innovations\nunlock higher resolutions, allowing T2I diffusion models to be applied to image\nSR tasks without limitation on resolution.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.12072v1",
    "published_date": "2024-11-18 21:32:49 UTC",
    "updated_date": "2024-11-18 21:32:49 UTC"
  },
  {
    "arxiv_id": "2411.14473v4",
    "title": "Large Language Model for Qualitative Research -- A Systematic Mapping Study",
    "authors": [
      "Cauã Ferreira Barros",
      "Bruna Borges Azevedo",
      "Valdemar Vicente Graciano Neto",
      "Mohamad Kassab",
      "Marcos Kalinowski",
      "Hugo Alexandre D. do Nascimento",
      "Michelle C. G. S. P. Bandeira"
    ],
    "abstract": "The exponential growth of text-based data in domains such as healthcare,\neducation, and social sciences has outpaced the capacity of traditional\nqualitative analysis methods, which are time-intensive and prone to\nsubjectivity. Large Language Models (LLMs), powered by advanced generative AI,\nhave emerged as transformative tools capable of automating and enhancing\nqualitative analysis. This study systematically maps the literature on the use\nof LLMs for qualitative research, exploring their application contexts,\nconfigurations, methodologies, and evaluation metrics. Findings reveal that\nLLMs are utilized across diverse fields, demonstrating the potential to\nautomate processes traditionally requiring extensive human input. However,\nchallenges such as reliance on prompt engineering, occasional inaccuracies, and\ncontextual limitations remain significant barriers. This research highlights\nopportunities for integrating LLMs with human expertise, improving model\nrobustness, and refining evaluation methodologies. By synthesizing trends and\nidentifying research gaps, this study aims to guide future innovations in the\napplication of LLMs for qualitative analysis.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7; I.2.10; H.3.3"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, includes 1 figures and 3 tables. Submitted and Accepted to\n  the WSESE 2025 ICSE Workshop",
    "pdf_url": "http://arxiv.org/pdf/2411.14473v4",
    "published_date": "2024-11-18 21:28:00 UTC",
    "updated_date": "2025-03-06 20:49:51 UTC"
  },
  {
    "arxiv_id": "2411.12064v3",
    "title": "TSPRank: Bridging Pairwise and Listwise Methods with a Bilinear Travelling Salesman Model",
    "authors": [
      "Weixian Waylon Li",
      "Yftah Ziser",
      "Yifei Xie",
      "Shay B. Cohen",
      "Tiejun Ma"
    ],
    "abstract": "Traditional Learning-To-Rank (LETOR) approaches, including pairwise methods\nlike RankNet and LambdaMART, often fall short by solely focusing on pairwise\ncomparisons, leading to sub-optimal global rankings. Conversely, deep learning\nbased listwise methods, while aiming to optimise entire lists, require complex\ntuning and yield only marginal improvements over robust pairwise models. To\novercome these limitations, we introduce Travelling Salesman Problem Rank\n(TSPRank), a hybrid pairwise-listwise ranking method. TSPRank reframes the\nranking problem as a Travelling Salesman Problem (TSP), a well-known\ncombinatorial optimisation challenge that has been extensively studied for its\nnumerous solution algorithms and applications. This approach enables the\nmodelling of pairwise relationships and leverages combinatorial optimisation to\ndetermine the listwise ranking. This approach can be directly integrated as an\nadditional component into embeddings generated by existing backbone models to\nenhance ranking performance. Our extensive experiments across three backbone\nmodels on diverse tasks, including stock ranking, information retrieval, and\nhistorical events ordering, demonstrate that TSPRank significantly outperforms\nboth pure pairwise and listwise methods. Our qualitative analysis reveals that\nTSPRank's main advantage over existing methods is its ability to harness global\ninformation better while ranking. TSPRank's robustness and superior performance\nacross different domains highlight its potential as a versatile and effective\nLETOR solution.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ACM SIGKDD 2025 Research Track. The code and preprocessed\n  data are available at https://github.com/waylonli/TSPRank-KDD2025",
    "pdf_url": "http://arxiv.org/pdf/2411.12064v3",
    "published_date": "2024-11-18 21:10:14 UTC",
    "updated_date": "2025-03-23 17:50:23 UTC"
  },
  {
    "arxiv_id": "2411.15180v1",
    "title": "Multi-layer matrix factorization for cancer subtyping using full and partial multi-omics dataset",
    "authors": [
      "Yingxuan Ren",
      "Fengtao Ren",
      "Bo Yang"
    ],
    "abstract": "Cancer, with its inherent heterogeneity, is commonly categorized into\ndistinct subtypes based on unique traits, cellular origins, and molecular\nmarkers specific to each type. However, current studies primarily rely on\ncomplete multi-omics datasets for predicting cancer subtypes, often overlooking\npredictive performance in cases where some omics data may be missing and\nneglecting implicit relationships across multiple layers of omics data\nintegration. This paper introduces Multi-Layer Matrix Factorization (MLMF), a\nnovel approach for cancer subtyping that employs multi-omics data clustering.\nMLMF initially processes multi-omics feature matrices by performing multi-layer\nlinear or nonlinear factorization, decomposing the original data into latent\nfeature representations unique to each omics type. These latent representations\nare subsequently fused into a consensus form, on which spectral clustering is\nperformed to determine subtypes. Additionally, MLMF incorporates a class\nindicator matrix to handle missing omics data, creating a unified framework\nthat can manage both complete and incomplete multi-omics data. Extensive\nexperiments conducted on 10 multi-omics cancer datasets, both complete and with\nmissing values, demonstrate that MLMF achieves results that are comparable to\nor surpass the performance of several state-of-the-art approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15180v1",
    "published_date": "2024-11-18 20:58:11 UTC",
    "updated_date": "2024-11-18 20:58:11 UTC"
  },
  {
    "arxiv_id": "2411.12056v1",
    "title": "Benchmarking pre-trained text embedding models in aligning built asset information",
    "authors": [
      "Mehrzad Shahinmoghadam",
      "Ali Motamedi"
    ],
    "abstract": "Accurate mapping of the built asset information to established data\nclassification systems and taxonomies is crucial for effective asset\nmanagement, whether for compliance at project handover or ad-hoc data\nintegration scenarios. Due to the complex nature of built asset data, which\npredominantly comprises technical text elements, this process remains largely\nmanual and reliant on domain expert input. Recent breakthroughs in contextual\ntext representation learning (text embedding), particularly through pre-trained\nlarge language models, offer promising approaches that can facilitate the\nautomation of cross-mapping of the built asset data. However, no comprehensive\nevaluation has yet been conducted to assess these models' ability to\neffectively represent the complex semantics specific to built asset technical\nterminology. This study presents a comparative benchmark of state-of-the-art\ntext embedding models to evaluate their effectiveness in aligning built asset\ninformation with domain-specific technical concepts. Our proposed datasets are\nderived from two renowned built asset data classification dictionaries. The\nresults of our benchmarking across six proposed datasets, covering three tasks\nof clustering, retrieval, and reranking, highlight the need for future research\non domain adaptation techniques. The benchmarking resources are published as an\nopen-source library, which will be maintained and extended to support future\nevaluations in this field.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.12056v1",
    "published_date": "2024-11-18 20:54:17 UTC",
    "updated_date": "2024-11-18 20:54:17 UTC"
  },
  {
    "arxiv_id": "2411.12045v1",
    "title": "Fingerprinting and Tracing Shadows: The Development and Impact of Browser Fingerprinting on Digital Privacy",
    "authors": [
      "Alexander Lawall"
    ],
    "abstract": "Browser fingerprinting is a growing technique for identifying and tracking\nusers online without traditional methods like cookies. This paper gives an\noverview by examining the various fingerprinting techniques and analyzes the\nentropy and uniqueness of the collected data. The analysis highlights that\nbrowser fingerprinting poses a complex challenge from both technical and\nprivacy perspectives, as users often have no control over the collection and\nuse of their data. In addition, it raises significant privacy concerns as users\nare often tracked without their knowledge or consent.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "SECURWARE 2024, France, Nice",
    "pdf_url": "http://arxiv.org/pdf/2411.12045v1",
    "published_date": "2024-11-18 20:32:31 UTC",
    "updated_date": "2024-11-18 20:32:31 UTC"
  },
  {
    "arxiv_id": "2411.12042v1",
    "title": "Fast Convergence of Softmax Policy Mirror Ascent",
    "authors": [
      "Reza Asad",
      "Reza Babanezhad",
      "Issam Laradji",
      "Nicolas Le Roux",
      "Sharan Vaswani"
    ],
    "abstract": "Natural policy gradient (NPG) is a common policy optimization algorithm and\ncan be viewed as mirror ascent in the space of probabilities. Recently, Vaswani\net al. [2021] introduced a policy gradient method that corresponds to mirror\nascent in the dual space of logits. We refine this algorithm, removing its need\nfor a normalization across actions and analyze the resulting method (referred\nto as SPMA). For tabular MDPs, we prove that SPMA with a constant step-size\nmatches the linear convergence of NPG and achieves a faster convergence than\nconstant step-size (accelerated) softmax policy gradient. To handle large\nstate-action spaces, we extend SPMA to use a log-linear policy\nparameterization. Unlike that for NPG, generalizing SPMA to the linear function\napproximation (FA) setting does not require compatible function approximation.\nUnlike MDPO, a practical generalization of NPG, SPMA with linear FA only\nrequires solving convex softmax classification problems. We prove that SPMA\nachieves linear convergence to the neighbourhood of the optimal value function.\nWe extend SPMA to handle non-linear FA and evaluate its empirical performance\non the MuJoCo and Atari benchmarks. Our results demonstrate that SPMA\nconsistently achieves similar or better performance compared to MDPO, PPO and\nTRPO.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.12042v1",
    "published_date": "2024-11-18 20:27:13 UTC",
    "updated_date": "2024-11-18 20:27:13 UTC"
  },
  {
    "arxiv_id": "2411.14471v1",
    "title": "Leveraging Gene Expression Data and Explainable Machine Learning for Enhanced Early Detection of Type 2 Diabetes",
    "authors": [
      "Aurora Lithe Roy",
      "Md Kamrul Siam",
      "Nuzhat Noor Islam Prova",
      "Sumaiya Jahan",
      "Abdullah Al Maruf"
    ],
    "abstract": "Diabetes, particularly Type 2 diabetes (T2D), poses a substantial global\nhealth burden, compounded by its associated complications such as\ncardiovascular diseases, kidney failure, and vision impairment. Early detection\nof T2D is critical for improving healthcare outcomes and optimizing resource\nallocation. In this study, we address the gap in early T2D detection by\nleveraging machine learning (ML) techniques on gene expression data obtained\nfrom T2D patients. Our primary objective was to enhance the accuracy of early\nT2D detection through advanced ML methodologies and increase the model's\ntrustworthiness using the explainable artificial intelligence (XAI) technique.\nAnalyzing the biological mechanisms underlying T2D through gene expression\ndatasets represents a novel research frontier, relatively less explored in\nprevious studies. While numerous investigations have focused on utilizing\nclinical and demographic data for T2D prediction, the integration of molecular\ninsights from gene expression datasets offers a unique and promising avenue for\nunderstanding the pathophysiology of the disease. By employing six ML\nclassifiers on data sourced from NCBI's Gene Expression Omnibus (GEO), we\nobserved promising performance across all models. Notably, the XGBoost\nclassifier exhibited the highest accuracy, achieving 97%. Our study addresses a\nnotable gap in early T2D detection methodologies, emphasizing the importance of\nleveraging gene expression data and advanced ML techniques.",
    "categories": [
      "q-bio.GN",
      "cs.AI"
    ],
    "primary_category": "q-bio.GN",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.14471v1",
    "published_date": "2024-11-18 20:24:08 UTC",
    "updated_date": "2024-11-18 20:24:08 UTC"
  },
  {
    "arxiv_id": "2411.12038v1",
    "title": "Scaling Deep Learning Research with Kubernetes on the NRP Nautilus HyperCluster",
    "authors": [
      "J. Alex Hurt",
      "Anes Ouadou",
      "Mariam Alshehri",
      "Grant J. Scott"
    ],
    "abstract": "Throughout the scientific computing space, deep learning algorithms have\nshown excellent performance in a wide range of applications. As these deep\nneural networks (DNNs) continue to mature, the necessary compute required to\ntrain them has continued to grow. Today, modern DNNs require millions of FLOPs\nand days to weeks of training to generate a well-trained model. The training\ntimes required for DNNs are oftentimes a bottleneck in DNN research for a\nvariety of deep learning applications, and as such, accelerating and scaling\nDNN training enables more robust and accelerated research. To that end, in this\nwork, we explore utilizing the NRP Nautilus HyperCluster to automate and scale\ndeep learning model training for three separate applications of DNNs, including\noverhead object detection, burned area segmentation, and deforestation\ndetection. In total, 234 deep neural models are trained on Nautilus, for a\ntotal time of 4,040 hours",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.12038v1",
    "published_date": "2024-11-18 20:19:49 UTC",
    "updated_date": "2024-11-18 20:19:49 UTC"
  },
  {
    "arxiv_id": "2411.12019v1",
    "title": "Regret-Free Reinforcement Learning for LTL Specifications",
    "authors": [
      "Rupak Majumdar",
      "Mahmoud Salamati",
      "Sadegh Soudjani"
    ],
    "abstract": "Reinforcement learning (RL) is a promising method to learn optimal control\npolicies for systems with unknown dynamics. In particular, synthesizing\ncontrollers for safety-critical systems based on high-level specifications,\nsuch as those expressed in temporal languages like linear temporal logic (LTL),\npresents a significant challenge in control systems research. Current RL-based\nmethods designed for LTL tasks typically offer only asymptotic guarantees,\nwhich provide no insight into the transient performance during the learning\nphase. While running an RL algorithm, it is crucial to assess how close we are\nto achieving optimal behavior if we stop learning.\n  In this paper, we present the first regret-free online algorithm for learning\na controller that addresses the general class of LTL specifications over Markov\ndecision processes (MDPs) with a finite set of states and actions. We begin by\nproposing a regret-free learning algorithm to solve infinite-horizon\nreach-avoid problems. For general LTL specifications, we show that the\nsynthesis problem can be reduced to a reach-avoid problem when the graph\nstructure is known. Additionally, we provide an algorithm for learning the\ngraph structure, assuming knowledge of a minimum transition probability, which\noperates independently of the main regret-free algorithm.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.12019v1",
    "published_date": "2024-11-18 20:01:45 UTC",
    "updated_date": "2024-11-18 20:01:45 UTC"
  },
  {
    "arxiv_id": "2411.13597v1",
    "title": "Enhancing Bidirectional Sign Language Communication: Integrating YOLOv8 and NLP for Real-Time Gesture Recognition & Translation",
    "authors": [
      "Hasnat Jamil Bhuiyan",
      "Mubtasim Fuad Mozumder",
      "Md. Rabiul Islam Khan",
      "Md. Sabbir Ahmed",
      "Nabuat Zaman Nahim"
    ],
    "abstract": "The primary concern of this research is to take American Sign Language (ASL)\ndata through real time camera footage and be able to convert the data and\ninformation into text. Adding to that, we are also putting focus on creating a\nframework that can also convert text into sign language in real time which can\nhelp us break the language barrier for the people who are in need. In this\nwork, for recognising American Sign Language (ASL), we have used the You Only\nLook Once(YOLO) model and Convolutional Neural Network (CNN) model. YOLO model\nis run in real time and automatically extracts discriminative spatial-temporal\ncharacteristics from the raw video stream without the need for any prior\nknowledge, eliminating design flaws. The CNN model here is also run in real\ntime for sign language detection. We have introduced a novel method for\nconverting text based input to sign language by making a framework that will\ntake a sentence as input, identify keywords from that sentence and then show a\nvideo where sign language is performed with respect to the sentence given as\ninput in real time. To the best of our knowledge, this is a rare study to\ndemonstrate bidirectional sign language communication in real time in the\nAmerican Sign Language (ASL).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13597v1",
    "published_date": "2024-11-18 19:55:11 UTC",
    "updated_date": "2024-11-18 19:55:11 UTC"
  },
  {
    "arxiv_id": "2411.14469v1",
    "title": "Popular LLMs Amplify Race and Gender Disparities in Human Mobility",
    "authors": [
      "Xinhua Wu",
      "Qi R. Wang"
    ],
    "abstract": "As large language models (LLMs) are increasingly applied in areas influencing\nsocietal outcomes, it is critical to understand their tendency to perpetuate\nand amplify biases. This study investigates whether LLMs exhibit biases in\npredicting human mobility -- a fundamental human behavior -- based on race and\ngender. Using three prominent LLMs -- GPT-4, Gemini, and Claude -- we analyzed\ntheir predictions of visitations to points of interest (POIs) for individuals,\nrelying on prompts that included names with and without explicit demographic\ndetails. We find that LLMs frequently reflect and amplify existing societal\nbiases. Specifically, predictions for minority groups were disproportionately\nskewed, with these individuals being significantly less likely to be associated\nwith wealth-related points of interest (POIs). Gender biases were also evident,\nas female individuals were consistently linked to fewer career-related POIs\ncompared to their male counterparts. These biased associations suggest that\nLLMs not only mirror but also exacerbate societal stereotypes, particularly in\ncontexts involving race and gender.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14469v1",
    "published_date": "2024-11-18 19:41:20 UTC",
    "updated_date": "2024-11-18 19:41:20 UTC"
  },
  {
    "arxiv_id": "2411.12000v2",
    "title": "ByteScience: Bridging Unstructured Scientific Literature and Structured Data with Auto Fine-tuned Large Language Model in Token Granularity",
    "authors": [
      "Tong Xie",
      "Hanzhi Zhang",
      "Shaozhou Wang",
      "Yuwei Wan",
      "Imran Razzak",
      "Chunyu Kit",
      "Wenjie Zhang",
      "Bram Hoex"
    ],
    "abstract": "Natural Language Processing (NLP) is widely used to supply summarization\nability from long context to structured information. However, extracting\nstructured knowledge from scientific text by NLP models remains a challenge\nbecause of its domain-specific nature to complex data preprocessing and the\ngranularity of multi-layered device-level information. To address this, we\nintroduce ByteScience, a non-profit cloud-based auto fine-tuned Large Language\nModel (LLM) platform, which is designed to extract structured scientific data\nand synthesize new scientific knowledge from vast scientific corpora. The\nplatform capitalizes on DARWIN, an open-source, fine-tuned LLM dedicated to\nnatural science. The platform was built on Amazon Web Services (AWS) and\nprovides an automated, user-friendly workflow for custom model development and\ndata extraction. The platform achieves remarkable accuracy with only a small\namount of well-annotated articles. This innovative tool streamlines the\ntransition from the science literature to structured knowledge and data and\nbenefits the advancements in natural informatics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.12000v2",
    "published_date": "2024-11-18 19:36:26 UTC",
    "updated_date": "2024-12-06 21:08:10 UTC"
  },
  {
    "arxiv_id": "2411.14468v1",
    "title": "A Neural Network Training Method Based on Distributed PID Control",
    "authors": [
      "Jiang Kun"
    ],
    "abstract": "In the previous article, we introduced a neural network framework based on\nsymmetric differential equations. This novel framework exhibits complete\nsymmetry, endowing it with perfect mathematical properties. While we have\nexamined some of the system's mathematical characteristics, a detailed\ndiscussion of the network training methodology has not yet been presented.\nDrawing on the principles of the traditional backpropagation algorithm, this\nstudy proposes an alternative training approach that utilizes differential\nequation signal propagation instead of chain rule derivation. This approach not\nonly preserves the effectiveness of training but also offers enhanced\nbiological interpretability. The foundation of this methodology lies in the\nsystem's reversibility, which stems from its inherent symmetry,a key aspect of\nour research. However, this method alone is insufficient for effective neural\nnetwork training. To address this, we further introduce a distributed\nProportional-Integral-Derivative (PID) control approach, emphasizing its\nimplementation within a closed system. By incorporating this method, we\nachieved both faster training speeds and improved accuracy. This approach not\nonly offers novel insights into neural network training but also extends the\nscope of research into control methodologies. To validate its effectiveness, we\napply this method to the MNIST dataset, demonstrating its practical utility.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.14468v1",
    "published_date": "2024-11-18 19:25:26 UTC",
    "updated_date": "2024-11-18 19:25:26 UTC"
  },
  {
    "arxiv_id": "2411.11984v1",
    "title": "Understanding Chain-of-Thought in LLMs through Information Theory",
    "authors": [
      "Jean-Francois Ton",
      "Muhammad Faaiz Taufiq",
      "Yang Liu"
    ],
    "abstract": "Large Language Models (LLMs) have shown impressive performance in complex\nreasoning tasks through Chain-of-Thought (CoT) reasoning, allowing models to\nbreak down problems into manageable sub-tasks. However, existing CoT evaluation\ntechniques either require annotated CoT data or fall short in accurately\nassessing intermediate reasoning steps, leading to high rates of false\npositives. In this paper, we formalize CoT reasoning in LLMs through an\ninformation-theoretic lens. Specifically, our framework quantifies the\n`information gain' at each reasoning step, enabling the identification of\nfailure modes in LLMs without the need for expensive annotated datasets. We\ndemonstrate the efficacy of our approach through extensive experiments on toy\nand GSM-8K data, where it significantly outperforms existing outcome-based\nmethods by providing more accurate insights into model performance on\nindividual tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11984v1",
    "published_date": "2024-11-18 19:14:36 UTC",
    "updated_date": "2024-11-18 19:14:36 UTC"
  },
  {
    "arxiv_id": "2411.11843v1",
    "title": "Bi-Mamba: Towards Accurate 1-Bit State Space Models",
    "authors": [
      "Shengkun Tang",
      "Liqun Ma",
      "Haonan Li",
      "Mingjie Sun",
      "Zhiqiang Shen"
    ],
    "abstract": "The typical selective state-space model (SSM) of Mamba addresses several\nlimitations of Transformers, such as quadratic computational complexity with\nsequence length and significant inference-time memory requirements due to the\nkey-value cache. However, the growing size of Mamba models continues to pose\ntraining and deployment challenges and raises environmental concerns due to\nconsiderable energy consumption. In this work, we introduce Bi-Mamba, a\nscalable and powerful 1-bit Mamba architecture designed for more efficient\nlarge language models with multiple sizes across 780M, 1.3B, and 2.7B. Bi-Mamba\nmodels are trained from scratch on data volume as regular LLM pertaining using\nan autoregressive distillation loss. Extensive experimental results on language\nmodeling demonstrate that Bi-Mamba achieves performance comparable to its\nfull-precision counterparts (e.g., FP16 or BF16) and much better accuracy than\npost-training-binarization (PTB) Mamba baselines, while significantly reducing\nmemory footprint and energy consumption compared to the original Mamba model.\nOur study pioneers a new linear computational complexity LLM framework under\nlow-bit representation and facilitates the future design of specialized\nhardware tailored for efficient 1-bit Mamba-based LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11843v1",
    "published_date": "2024-11-18 18:59:15 UTC",
    "updated_date": "2024-11-18 18:59:15 UTC"
  },
  {
    "arxiv_id": "2411.11826v1",
    "title": "LightFFDNets: Lightweight Convolutional Neural Networks for Rapid Facial Forgery Detection",
    "authors": [
      "Günel Jabbarlı",
      "Murat Kurt"
    ],
    "abstract": "Accurate and fast recognition of forgeries is an issue of great importance in\nthe fields of artificial intelligence, image processing and object detection.\nRecognition of forgeries of facial imagery is the process of classifying and\ndefining the faces in it by analyzing real-world facial images. This process is\nusually accomplished by extracting features from an image, using classifier\nalgorithms, and correctly interpreting the results. Recognizing forgeries of\nfacial imagery correctly can encounter many different challenges. For example,\nfactors such as changing lighting conditions, viewing faces from different\nangles can affect recognition performance, and background complexity and\nperspective changes in facial images can make accurate recognition difficult.\nDespite these difficulties, significant progress has been made in the field of\nforgery detection. Deep learning algorithms, especially Convolutional Neural\nNetworks (CNNs), have significantly improved forgery detection performance.\n  This study focuses on image processing-based forgery detection using\nFake-Vs-Real-Faces (Hard) [10] and 140k Real and Fake Faces [61] data sets.\nBoth data sets consist of two classes containing real and fake facial images.\nIn our study, two lightweight deep learning models are proposed to conduct\nforgery detection using these images. Additionally, 8 different pretrained CNN\narchitectures were tested on both data sets and the results were compared with\nnewly developed lightweight CNN models. It's shown that the proposed\nlightweight deep learning models have minimum number of layers. It's also shown\nthat the proposed lightweight deep learning models detect forgeries of facial\nimagery accurately, and computationally efficiently. Although the data set\nconsists only of face images, the developed models can also be used in other\ntwo-class object recognition problems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.9; I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 6 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.11826v1",
    "published_date": "2024-11-18 18:44:10 UTC",
    "updated_date": "2024-11-18 18:44:10 UTC"
  },
  {
    "arxiv_id": "2411.11943v1",
    "title": "Medical Video Generation for Disease Progression Simulation",
    "authors": [
      "Xu Cao",
      "Kaizhao Liang",
      "Kuei-Da Liao",
      "Tianren Gao",
      "Wenqian Ye",
      "Jintai Chen",
      "Zhiguang Ding",
      "Jianguo Cao",
      "James M. Rehg",
      "Jimeng Sun"
    ],
    "abstract": "Modeling disease progression is crucial for improving the quality and\nefficacy of clinical diagnosis and prognosis, but it is often hindered by a\nlack of longitudinal medical image monitoring for individual patients. To\naddress this challenge, we propose the first Medical Video Generation (MVG)\nframework that enables controlled manipulation of disease-related image and\nvideo features, allowing precise, realistic, and personalized simulations of\ndisease progression. Our approach begins by leveraging large language models\n(LLMs) to recaption prompt for disease trajectory. Next, a controllable\nmulti-round diffusion model simulates the disease progression state for each\npatient, creating realistic intermediate disease state sequence. Finally, a\ndiffusion-based video transition generation model interpolates disease\nprogression between these states. We validate our framework across three\nmedical imaging domains: chest X-ray, fundus photography, and skin image. Our\nresults demonstrate that MVG significantly outperforms baseline models in\ngenerating coherent and clinically plausible disease trajectories. Two user\nstudies by veteran physicians, provide further validation and insights into the\nclinical utility of the generated sequences. MVG has the potential to assist\nhealthcare providers in modeling disease trajectories, interpolating missing\nmedical image data, and enhancing medical education through realistic, dynamic\nvisualizations of disease progression.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Tech Report. The appendix will release soon. arXiv admin note: text\n  overlap with arXiv:2309.11745",
    "pdf_url": "http://arxiv.org/pdf/2411.11943v1",
    "published_date": "2024-11-18 18:37:09 UTC",
    "updated_date": "2024-11-18 18:37:09 UTC"
  },
  {
    "arxiv_id": "2411.11799v1",
    "title": "Edge-Enhanced Dilated Residual Attention Network for Multimodal Medical Image Fusion",
    "authors": [
      "Meng Zhou",
      "Yuxuan Zhang",
      "Xiaolan Xu",
      "Jiayi Wang",
      "Farzad Khalvati"
    ],
    "abstract": "Multimodal medical image fusion is a crucial task that combines complementary\ninformation from different imaging modalities into a unified representation,\nthereby enhancing diagnostic accuracy and treatment planning. While deep\nlearning methods, particularly Convolutional Neural Networks (CNNs) and\nTransformers, have significantly advanced fusion performance, some of the\nexisting CNN-based methods fall short in capturing fine-grained multiscale and\nedge features, leading to suboptimal feature integration. Transformer-based\nmodels, on the other hand, are computationally intensive in both the training\nand fusion stages, making them impractical for real-time clinical use.\nMoreover, the clinical application of fused images remains unexplored. In this\npaper, we propose a novel CNN-based architecture that addresses these\nlimitations by introducing a Dilated Residual Attention Network Module for\neffective multiscale feature extraction, coupled with a gradient operator to\nenhance edge detail learning. To ensure fast and efficient fusion, we present a\nparameter-free fusion strategy based on the weighted nuclear norm of softmax,\nwhich requires no additional computations during training or inference.\nExtensive experiments, including a downstream brain tumor classification task,\ndemonstrate that our approach outperforms various baseline methods in terms of\nvisual quality, texture preservation, and fusion speed, making it a possible\npractical solution for real-world clinical applications. The code will be\nreleased at https://github.com/simonZhou86/en_dran.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "An extended version of the paper accepted at IEEE BIBM 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.11799v1",
    "published_date": "2024-11-18 18:11:53 UTC",
    "updated_date": "2024-11-18 18:11:53 UTC"
  },
  {
    "arxiv_id": "2411.11795v1",
    "title": "Exploring adversarial robustness of JPEG AI: methodology, comparison and new methods",
    "authors": [
      "Egor Kovalev",
      "Georgii Bychkov",
      "Khaled Abud",
      "Aleksandr Gushchin",
      "Anna Chistyakova",
      "Sergey Lavrushkin",
      "Dmitriy Vatolin",
      "Anastasia Antsiferova"
    ],
    "abstract": "Adversarial robustness of neural networks is an increasingly important area\nof research, combining studies on computer vision models, large language models\n(LLMs), and others. With the release of JPEG AI - the first standard for\nend-to-end neural image compression (NIC) methods - the question of its\nrobustness has become critically significant. JPEG AI is among the first\ninternational, real-world applications of neural-network-based models to be\nembedded in consumer devices. However, research on NIC robustness has been\nlimited to open-source codecs and a narrow range of attacks. This paper\nproposes a new methodology for measuring NIC robustness to adversarial attacks.\nWe present the first large-scale evaluation of JPEG AI's robustness, comparing\nit with other NIC models. Our evaluation results and code are publicly\navailable online (link is hidden for a blind review).",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11795v1",
    "published_date": "2024-11-18 18:08:52 UTC",
    "updated_date": "2024-11-18 18:08:52 UTC"
  },
  {
    "arxiv_id": "2411.11774v1",
    "title": "Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care",
    "authors": [
      "Jeffrey N. Clark",
      "Matthew Wragg",
      "Emily Nielsen",
      "Miquel Perello-Nieto",
      "Nawid Keshtmand",
      "Michael Ambler",
      "Shiv Sharma",
      "Christopher P. Bourdeaux",
      "Amberly Brigden",
      "Raul Santos-Rodriguez"
    ],
    "abstract": "There is a growing need to understand how digital systems can support\nclinical decision-making, particularly as artificial intelligence (AI) models\nbecome increasingly complex and less human-interpretable. This complexity\nraises concerns about trustworthiness, impacting safe and effective adoption of\nsuch technologies. Improved understanding of decision-making processes and\nrequirements for explanations coming from decision support tools is a vital\ncomponent in providing effective explainable solutions. This is particularly\nrelevant in the data-intensive, fast-paced environments of intensive care units\n(ICUs). To explore these issues, group interviews were conducted with seven ICU\nclinicians, representing various roles and experience levels. Thematic analysis\nrevealed three core themes: (T1) ICU decision-making relies on a wide range of\nfactors, (T2) the complexity of patient state is challenging for shared\ndecision-making, and (T3) requirements and capabilities of AI decision support\nsystems. We include design recommendations from clinical input, providing\ninsights to inform future AI systems for intensive care.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11774v1",
    "published_date": "2024-11-18 17:53:07 UTC",
    "updated_date": "2024-11-18 17:53:07 UTC"
  },
  {
    "arxiv_id": "2411.11770v4",
    "title": "CNMBERT: A Model for Converting Hanyu Pinyin Abbreviations to Chinese Characters",
    "authors": [
      "Zishuo Feng",
      "Feng Cao"
    ],
    "abstract": "The task of converting Hanyu Pinyin abbreviations to Chinese characters is a\nsignificant branch within the domain of Chinese Spelling Correction (CSC). It\nplays an important role in many downstream applications such as named entity\nrecognition and sentiment analysis. This task typically involves text-length\nalignment and seems easy to solve; however, due to the limited information\ncontent in pinyin abbreviations, achieving accurate conversion is challenging.\nIn this paper, we treat this as a fill-mask task and propose CNMBERT, which\nstands for zh-CN Pinyin Multi-mask BERT Model, as a solution to this issue. By\nintroducing a multi-mask strategy and Mixture of Experts (MoE) layers, CNMBERT\noutperforms fine-tuned GPT models and ChatGPT-4o with a 61.53% MRR score and\n51.86% accuracy on a 10,373-sample test dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 5 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.11770v4",
    "published_date": "2024-11-18 17:50:34 UTC",
    "updated_date": "2025-01-28 14:54:31 UTC"
  },
  {
    "arxiv_id": "2411.11768v2",
    "title": "AdaptLIL: A Gaze-Adaptive Visualization for Ontology Mapping",
    "authors": [
      "Nicholas Chow",
      "Bo Fu"
    ],
    "abstract": "This paper showcases AdaptLIL, a real-time adaptive link-indented list\nontology mapping visualization that uses eye gaze as the primary input source.\nThrough a multimodal combination of real-time systems, deep learning, and web\ndevelopment applications, this system uniquely curtails graphical overlays\n(adaptations) to pairwise mappings of link-indented list ontology\nvisualizations for individual users based solely on their eye gaze.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "H.5.2; I.2.4"
    ],
    "primary_category": "cs.HC",
    "comment": "The paper was submitted without the consent of all authors. It is\n  being withdrawn until full consent is obtained",
    "pdf_url": "http://arxiv.org/pdf/2411.11768v2",
    "published_date": "2024-11-18 17:47:54 UTC",
    "updated_date": "2024-12-14 21:42:33 UTC"
  },
  {
    "arxiv_id": "2411.11758v1",
    "title": "The Power of Many: Multi-Agent Multimodal Models for Cultural Image Captioning",
    "authors": [
      "Longju Bai",
      "Angana Borah",
      "Oana Ignat",
      "Rada Mihalcea"
    ],
    "abstract": "Large Multimodal Models (LMMs) exhibit impressive performance across various\nmultimodal tasks. However, their effectiveness in cross-cultural contexts\nremains limited due to the predominantly Western-centric nature of most data\nand models. Conversely, multi-agent models have shown significant capability in\nsolving complex tasks. Our study evaluates the collective performance of LMMs\nin a multi-agent interaction setting for the novel task of cultural image\ncaptioning. Our contributions are as follows: (1) We introduce MosAIC, a\nMulti-Agent framework to enhance cross-cultural Image Captioning using LMMs\nwith distinct cultural personas; (2) We provide a dataset of culturally\nenriched image captions in English for images from China, India, and Romania\nacross three datasets: GeoDE, GD-VCR, CVQA; (3) We propose a culture-adaptable\nmetric for evaluating cultural information within image captions; and (4) We\nshow that the multi-agent interaction outperforms single-agent models across\ndifferent metrics, and offer valuable insights for future research. Our dataset\nand models can be accessed at https://github.com/MichiganNLP/MosAIC.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11758v1",
    "published_date": "2024-11-18 17:37:10 UTC",
    "updated_date": "2024-11-18 17:37:10 UTC"
  },
  {
    "arxiv_id": "2411.11942v1",
    "title": "Variable Rate Neural Compression for Sparse Detector Data",
    "authors": [
      "Yi Huang",
      "Yeonju Go",
      "Jin Huang",
      "Shuhang Li",
      "Xihaier Luo",
      "Thomas Marshall",
      "Joseph Osborn",
      "Christopher Pinkenburg",
      "Yihui Ren",
      "Evgeny Shulga",
      "Shinjae Yoo",
      "Byung-Jun Yoon"
    ],
    "abstract": "High-energy large-scale particle colliders generate data at extraordinary\nrates. Developing real-time high-throughput data compression algorithms to\nreduce data volume and meet the bandwidth requirement for storage has become\nincreasingly critical. Deep learning is a promising technology that can address\nthis challenging topic. At the newly constructed sPHENIX experiment at the\nRelativistic Heavy Ion Collider, a Time Projection Chamber (TPC) serves as the\nmain tracking detector, which records three-dimensional particle trajectories\nin a volume of a gas-filled cylinder. In terms of occupancy, the resulting data\nflow can be very sparse reaching $10^{-3}$ for proton-proton collisions. Such\nsparsity presents a challenge to conventional learning-free lossy compression\nalgorithms, such as SZ, ZFP, and MGARD. In contrast, emerging deep\nlearning-based models, particularly those utilizing convolutional neural\nnetworks for compression, have outperformed these conventional methods in terms\nof compression ratios and reconstruction accuracy. However, research on the\nefficacy of these deep learning models in handling sparse datasets, like those\nproduced in particle colliders, remains limited. Furthermore, most deep\nlearning models do not adapt their processing speeds to data sparsity, which\naffects efficiency. To address this issue, we propose a novel approach for TPC\ndata compression via key-point identification facilitated by sparse\nconvolution. Our proposed algorithm, BCAE-VS, achieves a $75\\%$ improvement in\nreconstruction accuracy with a $10\\%$ increase in compression ratio over the\nprevious state-of-the-art model. Additionally, BCAE-VS manages to achieve these\nresults with a model size over two orders of magnitude smaller. Lastly, we have\nexperimentally verified that as sparsity increases, so does the model's\nthroughput.",
    "categories": [
      "physics.ins-det",
      "cs.AI",
      "hep-ex",
      "nucl-ex"
    ],
    "primary_category": "physics.ins-det",
    "comment": "37 pages, 12 figures, submitted to Journal of Computational Physics",
    "pdf_url": "http://arxiv.org/pdf/2411.11942v1",
    "published_date": "2024-11-18 17:15:35 UTC",
    "updated_date": "2024-11-18 17:15:35 UTC"
  },
  {
    "arxiv_id": "2411.11739v1",
    "title": "QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou",
    "authors": [
      "Xinchen Luo",
      "Jiangxia Cao",
      "Tianyu Sun",
      "Jinkai Yu",
      "Rui Huang",
      "Wei Yuan",
      "Hezheng Lin",
      "Yichen Zheng",
      "Shiyao Wang",
      "Qigen Hu",
      "Changqing Qiu",
      "Jiaqi Zhang",
      "Xu Zhang",
      "Zhiheng Yan",
      "Jingming Zhang",
      "Simin Zhang",
      "Mingxing Wen",
      "Zhaojie Liu",
      "Kun Gai",
      "Guorui Zhou"
    ],
    "abstract": "In recent years, with the significant evolution of multi-modal large models,\nmany recommender researchers realized the potential of multi-modal information\nfor user interest modeling. In industry, a wide-used modeling architecture is a\ncascading paradigm: (1) first pre-training a multi-modal model to provide\nomnipotent representations for downstream services; (2) The downstream\nrecommendation model takes the multi-modal representation as additional input\nto fit real user-item behaviours. Although such paradigm achieves remarkable\nimprovements, however, there still exist two problems that limit model\nperformance: (1) Representation Unmatching: The pre-trained multi-modal model\nis always supervised by the classic NLP/CV tasks, while the recommendation\nmodels are supervised by real user-item interaction. As a result, the two\nfundamentally different tasks' goals were relatively separate, and there was a\nlack of consistent objective on their representations; (2) Representation\nUnlearning: The generated multi-modal representations are always stored in\ncache store and serve as extra fixed input of recommendation model, thus could\nnot be updated by recommendation model gradient, further unfriendly for\ndownstream training. Inspired by the two difficulties challenges in downstream\ntasks usage, we introduce a quantitative multi-modal framework to customize the\nspecialized and trainable multi-modal information for different downstream\nmodels.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "N/A"
    ],
    "primary_category": "cs.IR",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2411.11739v1",
    "published_date": "2024-11-18 17:08:35 UTC",
    "updated_date": "2024-11-18 17:08:35 UTC"
  },
  {
    "arxiv_id": "2411.11738v1",
    "title": "WoodYOLO: A Novel Object Detector for Wood Species Detection in Microscopic Images",
    "authors": [
      "Lars Nieradzik",
      "Henrike Stephani",
      "Jördis Sieburg-Rockel",
      "Stephanie Helmling",
      "Andrea Olbrich",
      "Stephanie Wrage",
      "Janis Keuper"
    ],
    "abstract": "Wood species identification plays a crucial role in various industries, from\nensuring the legality of timber products to advancing ecological conservation\nefforts. This paper introduces WoodYOLO, a novel object detection algorithm\nspecifically designed for microscopic wood fiber analysis. Our approach adapts\nthe YOLO architecture to address the challenges posed by large, high-resolution\nmicroscopy images and the need for high recall in localization of the cell type\nof interest (vessel elements). Our results show that WoodYOLO significantly\noutperforms state-of-the-art models, achieving performance gains of 12.9% and\n6.5% in F2 score over YOLOv10 and YOLOv7, respectively. This improvement in\nautomated wood cell type localization capabilities contributes to enhancing\nregulatory compliance, supporting sustainable forestry practices, and promoting\nbiodiversity conservation efforts globally.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11738v1",
    "published_date": "2024-11-18 17:07:37 UTC",
    "updated_date": "2024-11-18 17:07:37 UTC"
  },
  {
    "arxiv_id": "2411.11731v1",
    "title": "Moral Persuasion in Large Language Models: Evaluating Susceptibility and Ethical Alignment",
    "authors": [
      "Allison Huang",
      "Yulu Niki Pi",
      "Carlos Mougan"
    ],
    "abstract": "We explore how large language models (LLMs) can be influenced by prompting\nthem to alter their initial decisions and align them with established ethical\nframeworks. Our study is based on two experiments designed to assess the\nsusceptibility of LLMs to moral persuasion. In the first experiment, we examine\nthe susceptibility to moral ambiguity by evaluating a Base Agent LLM on morally\nambiguous scenarios and observing how a Persuader Agent attempts to modify the\nBase Agent's initial decisions. The second experiment evaluates the\nsusceptibility of LLMs to align with predefined ethical frameworks by prompting\nthem to adopt specific value alignments rooted in established philosophical\ntheories. The results demonstrate that LLMs can indeed be persuaded in morally\ncharged scenarios, with the success of persuasion depending on factors such as\nthe model used, the complexity of the scenario, and the conversation length.\nNotably, LLMs of distinct sizes but from the same company produced markedly\ndifferent outcomes, highlighting the variability in their susceptibility to\nethical persuasion.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11731v1",
    "published_date": "2024-11-18 16:59:59 UTC",
    "updated_date": "2024-11-18 16:59:59 UTC"
  },
  {
    "arxiv_id": "2411.11730v2",
    "title": "Lifted Model Construction without Normalisation: A Vectorised Approach to Exploit Symmetries in Factor Graphs",
    "authors": [
      "Malte Luttermann",
      "Ralf Möller",
      "Marcel Gehrke"
    ],
    "abstract": "Lifted probabilistic inference exploits symmetries in a probabilistic model\nto allow for tractable probabilistic inference with respect to domain sizes of\nlogical variables. We found that the current state-of-the-art algorithm to\nconstruct a lifted representation in form of a parametric factor graph misses\nsymmetries between factors that are exchangeable but scaled differently,\nthereby leading to a less compact representation. In this paper, we propose a\ngeneralisation of the advanced colour passing (ACP) algorithm, which is the\nstate of the art to construct a parametric factor graph. Our proposed algorithm\nallows for potentials of factors to be scaled arbitrarily and efficiently\ndetects more symmetries than the original ACP algorithm. By detecting strictly\nmore symmetries than ACP, our algorithm significantly reduces online query\ntimes for probabilistic inference when the resulting model is applied, which we\nalso confirm in our experiments.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to the Proceedings of the 3rd Learning on Graphs Conference\n  (LoG 2024)",
    "pdf_url": "http://arxiv.org/pdf/2411.11730v2",
    "published_date": "2024-11-18 16:59:44 UTC",
    "updated_date": "2024-11-20 13:01:18 UTC"
  },
  {
    "arxiv_id": "2411.11714v1",
    "title": "Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation",
    "authors": [
      "Mingchao Qi",
      "Yuanjin Li",
      "Xing Liu",
      "Zhengxiong Liu",
      "Panfeng Huang"
    ],
    "abstract": "Deploying robots in open-world environments involves complex tasks\ncharacterized by long sequences and rich interactions, necessitating efficient\ntransfer of robotic skills across diverse and complex scenarios. To address\nthis challenge, we propose a skill library framework based on knowledge graphs,\nwhich endows robots with high-level skill awareness and spatial semantic\nunderstanding. The framework hierarchically organizes operational knowledge by\nconstructing a \"task graph\" and a \"scene graph\" to represent task and scene\nsemantic information, respectively. We introduce a \"state graph\" to facilitate\ninteraction between high-level task planning and low-level scene information.\nFurthermore, we propose a hierarchical transfer framework for operational\nskills. At the task level, the framework integrates contextual learning and\nchain-of-thought prompting within a four-stage prompt paradigm, leveraging\nlarge language models' (LLMs) reasoning and generalization capabilities to\nachieve task-level subtask sequence transfer. At the motion level, an adaptive\ntrajectory transfer method is developed using the A* algorithm and the skill\nlibrary, enabling motion-level adaptive trajectory transfer. At the physical\nlevel, we introduce an adaptive contour extraction and posture perception\nmethod based on tactile perception. This method dynamically obtains\nhigh-precision contour and posture information from visual-tactile texture data\nand adjusts transferred skills, such as contact positions and postures, to\nensure effectiveness in new environments. Experimental results validate the\neffectiveness of the proposed methods. Project\nwebsite:https://github.com/MingchaoQi/skill_transfer",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11714v1",
    "published_date": "2024-11-18 16:42:07 UTC",
    "updated_date": "2024-11-18 16:42:07 UTC"
  },
  {
    "arxiv_id": "2411.11707v1",
    "title": "FedCoLLM: A Parameter-Efficient Federated Co-tuning Framework for Large and Small Language Models",
    "authors": [
      "Tao Fan",
      "Yan Kang",
      "Guoqiang Ma",
      "Lixin Fan",
      "Kai Chen",
      "Qiang Yang"
    ],
    "abstract": "By adapting Large Language Models (LLMs) to domain-specific tasks or\nenriching them with domain-specific knowledge, we can fully harness the\ncapabilities of LLMs. Nonetheless, a gap persists in achieving simultaneous\nmutual enhancement between the server's LLM and the downstream clients' Small\nLanguage Models (SLMs). To address this, we propose FedCoLLM, a novel and\nparameter-efficient federated framework designed for co-tuning LLMs and SLMs.\nThis approach is aimed at adaptively transferring server-side LLMs knowledge to\nclients' SLMs while simultaneously enriching the LLMs with domain insights from\nthe clients. To accomplish this, FedCoLLM utilizes lightweight adapters in\nconjunction with SLMs, facilitating knowledge exchange between server and\nclients in a manner that respects data privacy while also minimizing\ncomputational and communication overhead. Our evaluation of FedCoLLM, utilizing\nvarious public LLMs and SLMs across a range of NLP text generation tasks,\nreveals that the performance of clients' SLMs experiences notable improvements\nwith the assistance of the LLMs. Simultaneously, the LLMs enhanced via FedCoLLM\nachieves comparable performance to that obtained through direct fine-tuning on\nclients' data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11707v1",
    "published_date": "2024-11-18 16:34:58 UTC",
    "updated_date": "2024-11-18 16:34:58 UTC"
  },
  {
    "arxiv_id": "2411.11706v3",
    "title": "MC-LLaVA: Multi-Concept Personalized Vision-Language Model",
    "authors": [
      "Ruichuan An",
      "Sihan Yang",
      "Ming Lu",
      "Renrui Zhang",
      "Kai Zeng",
      "Yulin Luo",
      "Jiajun Cao",
      "Hao Liang",
      "Ying Chen",
      "Qi She",
      "Shanghang Zhang",
      "Wentao Zhang"
    ],
    "abstract": "Current vision-language models (VLMs) show exceptional abilities across\ndiverse tasks, such as visual question answering. To enhance user experience,\nrecent studies investigate VLM personalization to understand user-provided\nconcepts. However, they mainly focus on single-concept personalization,\nneglecting the existence and interplay of multiple concepts, which limits\nreal-world applicability. This paper proposes the first multi-concept\npersonalization paradigm, MC-LLaVA. Specifically, MC-LLaVA employs a\nmulti-concept instruction tuning strategy, effectively integrating multiple\nconcepts in a single training step. To reduce the costs related to joint\ntraining, we propose a personalized textual prompt that uses visual token\ninformation to initialize concept tokens. Additionally, we introduce a\npersonalized visual prompt during inference, aggregating location confidence\nmaps for enhanced recognition and grounding capabilities. To advance\nmulti-concept personalization research, we further contribute a high-quality\ninstruction tuning dataset. We carefully collect images with multiple\ncharacters and objects from movies and manually generate question-answer\nsamples for multi-concept scenarios, featuring superior diversity.\nComprehensive qualitative and quantitative experiments demonstrate that\nMC-LLaVA can achieve impressive multi-concept personalized responses, paving\nthe way for VLMs to become better user-specific assistants. The code and\ndataset will be publicly available at https://github.com/arctanxarc/MC-LLaVA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11706v3",
    "published_date": "2024-11-18 16:33:52 UTC",
    "updated_date": "2025-03-26 15:44:01 UTC"
  },
  {
    "arxiv_id": "2411.11938v1",
    "title": "Newclid: A User-Friendly Replacement for AlphaGeometry",
    "authors": [
      "Vladmir Sicca",
      "Tianxiang Xia",
      "Mathïs Fédérico",
      "Philip John Gorinski",
      "Simon Frieder",
      "Shangling Jui"
    ],
    "abstract": "We introduce a new symbolic solver for geometry, called Newclid, which is\nbased on AlphaGeometry. Newclid contains a symbolic solver called DDARN\n(derived from DDAR-Newclid), which is a significant refactoring and upgrade of\nAlphaGeometry's DDAR symbolic solver by being more user-friendly - both for the\nend user as well as for a programmer wishing to extend the codebase. For the\nprogrammer, improvements include a modularized codebase and new debugging and\nvisualization tools. For the user, Newclid contains a new command line\ninterface (CLI) that provides interfaces for agents to guide DDARN. DDARN is\nflexible with respect to its internal reasoning, which can be steered by\nagents. Further, we support input from GeoGebra to make Newclid accessible for\neducational contexts. Further, the scope of problems that Newclid can solve has\nbeen expanded to include the ability to have an improved understanding of\nmetric geometry concepts (length, angle) and to use theorems such as the\nPythagorean theorem in proofs. Bugs have been fixed, and reproducibility has\nbeen improved. Lastly, we re-evaluated the five remaining problems from the\noriginal AG-30 dataset that AlphaGeometry was not able to solve and contrasted\nthem with the abilities of DDARN, running in breadth-first-search agentic mode\n(which corresponds to how DDARN runs by default), finding that DDARN solves an\nadditional problem. We have open-sourced our code under:\nhttps://github.com/LMCRC/Newclid",
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "primary_category": "cs.GR",
    "comment": "51 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.11938v1",
    "published_date": "2024-11-18 16:24:21 UTC",
    "updated_date": "2024-11-18 16:24:21 UTC"
  },
  {
    "arxiv_id": "2411.11694v4",
    "title": "Enhancing LLM Reasoning with Reward-guided Tree Search",
    "authors": [
      "Jinhao Jiang",
      "Zhipeng Chen",
      "Yingqian Min",
      "Jie Chen",
      "Xiaoxue Cheng",
      "Jiapeng Wang",
      "Yiru Tang",
      "Haoxiang Sun",
      "Jia Deng",
      "Wayne Xin Zhao",
      "Zheng Liu",
      "Dong Yan",
      "Jian Xie",
      "Zhongyuan Wang",
      "Ji-Rong Wen"
    ],
    "abstract": "Recently, test-time scaling has garnered significant attention from the\nresearch community, largely due to the substantial advancements of the o1 model\nreleased by OpenAI. By allocating more computational resources during the\ninference phase, large language models~(LLMs) can extensively explore the\nsolution space by generating more thought tokens or diverse solutions, thereby\nproducing more accurate responses. However, developing an o1-like reasoning\napproach is challenging, and researchers have been making various attempts to\nadvance this open area of research. In this paper, we present a preliminary\nexploration into enhancing the reasoning abilities of LLMs through\nreward-guided tree search algorithms. This framework is implemented by\nintegrating the policy model, reward model, and search algorithm. It is\nprimarily constructed around a tree search algorithm, where the policy model\nnavigates a dynamically expanding tree guided by a specially trained reward\nmodel. The implemented framework is denoted as \\textbf{STILL-1}. We thoroughly\nexplore various design considerations necessary for implementing this framework\nand provide a detailed report of the technical aspects. To assess the\neffectiveness of our approach, we focus on mathematical reasoning tasks and\nconduct extensive evaluations on four challenging datasets, significantly\nenhancing the reasoning abilities of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Technical Report on Slow Thinking with LLMs: I",
    "pdf_url": "http://arxiv.org/pdf/2411.11694v4",
    "published_date": "2024-11-18 16:15:17 UTC",
    "updated_date": "2024-12-31 01:38:12 UTC"
  },
  {
    "arxiv_id": "2411.11937v1",
    "title": "Value Imprint: A Technique for Auditing the Human Values Embedded in RLHF Datasets",
    "authors": [
      "Ike Obi",
      "Rohan Pant",
      "Srishti Shekhar Agrawal",
      "Maham Ghazanfar",
      "Aaron Basiletti"
    ],
    "abstract": "LLMs are increasingly fine-tuned using RLHF datasets to align them with human\npreferences and values. However, very limited research has investigated which\nspecific human values are operationalized through these datasets. In this\npaper, we introduce Value Imprint, a framework for auditing and classifying the\nhuman values embedded within RLHF datasets. To investigate the viability of\nthis framework, we conducted three case study experiments by auditing the\nAnthropic/hh-rlhf, OpenAI WebGPT Comparisons, and Alpaca GPT-4-LLM datasets to\nexamine the human values embedded within them. Our analysis involved a\ntwo-phase process. During the first phase, we developed a taxonomy of human\nvalues through an integrated review of prior works from philosophy, axiology,\nand ethics. Then, we applied this taxonomy to annotate 6,501 RLHF preferences.\nDuring the second phase, we employed the labels generated from the annotation\nas ground truth data for training a transformer-based machine learning model to\naudit and classify the three RLHF datasets. Through this approach, we\ndiscovered that information-utility values, including Wisdom/Knowledge and\nInformation Seeking, were the most dominant human values within all three RLHF\ndatasets. In contrast, prosocial and democratic values, including Well-being,\nJustice, and Human/Animal Rights, were the least represented human values.\nThese findings have significant implications for developing language models\nthat align with societal values and norms. We contribute our datasets to\nsupport further research in this area.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11937v1",
    "published_date": "2024-11-18 16:12:24 UTC",
    "updated_date": "2024-11-18 16:12:24 UTC"
  },
  {
    "arxiv_id": "2411.11688v2",
    "title": "Conceptwm: A Diffusion Model Watermark for Concept Protection",
    "authors": [
      "Liangqi Lei",
      "Keke Gai",
      "Jing Yu",
      "Liehuang Zhu",
      "Qi Wu"
    ],
    "abstract": "The personalization techniques of diffusion models succeed in generating\nspecific concepts but also pose threats to copyright protection and illegal\nuse. Model Watermarking is an effective method to prevent the unauthorized use\nof subject-driven or style-driven image generation, safeguarding concept\ncopyrights. However, under the goal of concept-oriented protection, current\nwatermarking schemes typically add watermarks to all images rather than\napplying them in a refined manner targeted at specific concepts. Additionally,\nthe personalization techniques of diffusion models can easily remove\nwatermarks. Existing watermarking methods struggle to achieve fine-grained\nwatermark embedding with a few images of specific concept and prevent removal\nof watermarks through personalized fine-tuning. Therefore, we introduce a novel\nconcept-oriented watermarking framework that seamlessly embeds imperceptible\nwatermarks into the concept of diffusion models. We introduce\nFidelity-preserving Latent Watermarking (FLW) to generate latent watermarks\nbased on image characteristics and the Adversarial Watermarking Modulation\nmodule to prevent \"jailbreaking\" via personalized finetuning. To enhance\nU-Net's efficiency in learning watermark patterns with limited samples, we\npropose Efficient Concept Watermark Finetuning, which alternates optimization\nof model parameters for both watermark embedding and concept learning. We\nconduct extensive experiments and ablation studies to verify our framework. Our\ncode is available at https://anonymous.4open.science/r/Conceptwm-4EB3/.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11688v2",
    "published_date": "2024-11-18 16:11:25 UTC",
    "updated_date": "2025-04-12 13:14:10 UTC"
  },
  {
    "arxiv_id": "2411.11683v3",
    "title": "TrojanRobot: Physical-World Backdoor Attacks Against VLM-based Robotic Manipulation",
    "authors": [
      "Xianlong Wang",
      "Hewen Pan",
      "Hangtao Zhang",
      "Minghui Li",
      "Shengshan Hu",
      "Ziqi Zhou",
      "Lulu Xue",
      "Peijin Guo",
      "Yichen Wang",
      "Wei Wan",
      "Aishan Liu",
      "Leo Yu Zhang"
    ],
    "abstract": "Robotic manipulation in the physical world is increasingly empowered by\n\\textit{large language models} (LLMs) and \\textit{vision-language models}\n(VLMs), leveraging their understanding and perception capabilities. Recently,\nvarious attacks against such robotic policies have been proposed, with backdoor\nattacks drawing considerable attention for their high stealth and strong\npersistence capabilities. However, existing backdoor efforts are limited to\nsimulators and suffer from physical-world realization. To address this, we\npropose \\textit{TrojanRobot}, a highly stealthy and broadly effective robotic\nbackdoor attack in the physical world. Specifically, we introduce a\nmodule-poisoning approach by embedding a backdoor module into the modular\nrobotic policy, enabling backdoor control over the policy's visual perception\nmodule thereby backdooring the entire robotic policy. Our vanilla\nimplementation leverages a backdoor-finetuned VLM to serve as the backdoor\nmodule. To enhance its generalization in physical environments, we propose a\nprime implementation, leveraging the LVLM-as-a-backdoor paradigm and developing\nthree types of prime attacks, \\ie, \\textit{permutation}, \\textit{stagnation},\nand \\textit{intentional} attacks, thus achieving finer-grained backdoors.\nExtensive experiments on the UR3e manipulator with 18 task instructions using\nrobotic policies based on four VLMs demonstrate the broad effectiveness and\nphysical-world stealth of TrojanRobot. Our attack's video demonstrations are\navailable via a github link \\url{https://trojanrobot.github.io}.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11683v3",
    "published_date": "2024-11-18 16:09:26 UTC",
    "updated_date": "2025-01-23 14:45:03 UTC"
  },
  {
    "arxiv_id": "2411.17712v1",
    "title": "Generative AI on the Edge: Architecture and Performance Evaluation",
    "authors": [
      "Zeinab Nezami",
      "Maryam Hafeez",
      "Karim Djemame",
      "Syed Ali Raza Zaidi"
    ],
    "abstract": "6G's AI native vision of embedding advance intelligence in the network while\nbringing it closer to the user requires a systematic evaluation of Generative\nAI (GenAI) models on edge devices. Rapidly emerging solutions based on Open RAN\n(ORAN) and Network-in-a-Box strongly advocate the use of low-cost,\noff-the-shelf components for simpler and efficient deployment, e.g., in\nprovisioning rural connectivity. In this context, conceptual architecture,\nhardware testbeds and precise performance quantification of Large Language\nModels (LLMs) on off-the-shelf edge devices remains largely unexplored. This\nresearch investigates computationally demanding LLM inference on a single\ncommodity Raspberry Pi serving as an edge testbed for ORAN. We investigate\nvarious LLMs, including small, medium and large models, on a Raspberry Pi 5\nCluster using a lightweight Kubernetes distribution (K3s) with modular\nprompting implementation. We study its feasibility and limitations by analyzing\nthroughput, latency, accuracy and efficiency. Our findings indicate that\nCPU-only deployment of lightweight models, such as Yi, Phi, and Llama3, can\neffectively support edge applications, achieving a generation throughput of 5\nto 12 tokens per second with less than 50\\% CPU and RAM usage. We conclude that\nGenAI on the edge offers localized inference in remote or bandwidth-constrained\nenvironments in 6G networks without reliance on cloud infrastructure.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.NI",
      "cs.PF"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.17712v1",
    "published_date": "2024-11-18 16:09:01 UTC",
    "updated_date": "2024-11-18 16:09:01 UTC"
  },
  {
    "arxiv_id": "2411.11681v3",
    "title": "PSPO*: An Effective Process-supervised Policy Optimization for Reasoning Alignment",
    "authors": [
      "Jiawei Li",
      "Xinyue Liang",
      "Junlong Zhang",
      "Yizhe Yang",
      "Chong Feng",
      "Yang Gao"
    ],
    "abstract": "Process supervision enhances the performance of large language models in\nreasoning tasks by providing feedback at each step of chain-of-thought\nreasoning. However, due to the lack of effective process supervision methods,\neven advanced large language models are prone to logical errors and redundant\nreasoning. We claim that the effectiveness of process supervision significantly\ndepends on both the accuracy and the length of reasoning chains. Moreover, we\nidentify that these factors exhibit a nonlinear relationship with the overall\nreward score of the reasoning process. Inspired by these insights, we propose a\nnovel process supervision paradigm, PSPO*, which systematically outlines the\nworkflow from reward model training to policy optimization, and highlights the\nimportance of nonlinear rewards in process supervision. Based on PSPO*, we\ndevelop the PSPO-WRS, which considers the number of reasoning steps in\ndetermining reward scores and utilizes an adjusted Weibull distribution for\nnonlinear reward shaping. Experimental results on six mathematical reasoning\ndatasets demonstrate that PSPO-WRS consistently outperforms current mainstream\nmodels.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Our code can be found at https://github.com/DIRECT-BIT/PSPO",
    "pdf_url": "http://arxiv.org/pdf/2411.11681v3",
    "published_date": "2024-11-18 16:03:51 UTC",
    "updated_date": "2025-05-14 14:01:23 UTC"
  },
  {
    "arxiv_id": "2411.11672v2",
    "title": "Artificial Scientific Discovery",
    "authors": [
      "Antonio Norelli"
    ],
    "abstract": "Rooted in the explosion of deep learning over the past decade, this thesis\nspans from AlphaGo to ChatGPT to empirically examine the fundamental concepts\nneeded to realize the vision of an artificial scientist: a machine with the\ncapacity to autonomously generate original research and contribute to the\nexpansion of human knowledge. The investigation begins with Olivaw, an AlphaGo\nZero-like agent that discovers Othello knowledge from scratch but is unable to\ncommunicate it. This realization leads to the development of the Explanatory\nLearning (EL) framework, a formalization of the problem faced by a scientist\nwhen trying to explain a new phenomenon to their peers. The effective EL\nprescriptions allow us to crack Zendo, a popular board game simulating the\nscientific endeavor. This success comes with a fundamental insight: an\nartificial scientist must develop its own interpretation of the language used\nto explain its findings, and not rely on a rigid existing interpreter.\nQuestioning the very process of learning an interpreter, we turn our attention\nto the inner functioning of modern multimodal models. This culminates in a\nsimple idea to build CLIP-like models where interpretation and perception are\nexplicitly disentangled: a cost-effective approach that couples two unimodal\nmodels using little multimodal data and no further training. Finally, we\ndiscuss what ChatGPT and its siblings are still missing to become artificial\nscientists, and introduce the Big-Bench Symbol Interpretation Task, a benchmark\nabout interpreting Zendo-like explanations that sees LLMs going no further than\nrandom chance while being instead fully solved by humans.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "I.2"
    ],
    "primary_category": "cs.AI",
    "comment": "PhD thesis, 123 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.11672v2",
    "published_date": "2024-11-18 15:51:45 UTC",
    "updated_date": "2025-05-01 17:09:17 UTC"
  },
  {
    "arxiv_id": "2411.11667v2",
    "title": "Dissecting Representation Misalignment in Contrastive Learning via Influence Function",
    "authors": [
      "Lijie Hu",
      "Chenyang Ren",
      "Huanyi Xie",
      "Khouloud Saadi",
      "Shu Yang",
      "Zhen Tan",
      "Jingfeng Zhang",
      "Di Wang"
    ],
    "abstract": "Contrastive learning, commonly applied in large-scale multimodal models,\noften relies on data from diverse and often unreliable sources, which can\ninclude misaligned or mislabeled text-image pairs. This frequently leads to\nrobustness issues and hallucinations, ultimately causing performance\ndegradation. Data valuation is an efficient way to detect and trace these\nmisalignments. Nevertheless, existing methods are computationally expensive for\nlarge-scale models. Although computationally efficient, classical influence\nfunctions are inadequate for contrastive learning models, as they were\ninitially designed for pointwise loss. Furthermore, contrastive learning\ninvolves minimizing the distance between positive sample modalities while\nmaximizing the distance between negative sample modalities. This necessitates\nevaluating the influence of samples from both perspectives. To tackle these\nchallenges, we introduce the Extended Influence Function for Contrastive Loss\n(ECIF), an influence function crafted for contrastive loss. ECIF considers both\npositive and negative samples and provides a closed-form approximation of\ncontrastive learning models, eliminating the need for retraining. Building upon\nECIF, we develop a series of algorithms for data evaluation, misalignment\ndetection, and misprediction trace-back tasks. Experimental results demonstrate\nour ECIF advances the transparency and interpretability of CLIP-style embedding\nmodels by offering a more accurate assessment of data impact and model\nalignment compared to traditional baseline methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "33 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.11667v2",
    "published_date": "2024-11-18 15:45:41 UTC",
    "updated_date": "2025-01-31 23:36:04 UTC"
  },
  {
    "arxiv_id": "2411.11647v1",
    "title": "No-regret Exploration in Shuffle Private Reinforcement Learning",
    "authors": [
      "Shaojie Bai",
      "Mohammad Sadegh Talebi",
      "Chengcheng Zhao",
      "Peng Cheng",
      "Jiming Chen"
    ],
    "abstract": "Differential privacy (DP) has recently been introduced into episodic\nreinforcement learning (RL) to formally address user privacy concerns in\npersonalized services. Previous work mainly focuses on two trust models of DP:\nthe central model, where a central agent is responsible for protecting users'\nsensitive data, and the (stronger) local model, where the protection occurs\ndirectly on the user side. However, they either require a trusted central agent\nor incur a significantly higher privacy cost, making it unsuitable for many\nscenarios. This work introduces a trust model stronger than the central model\nbut with a lower privacy cost than the local model, leveraging the emerging\n\\emph{shuffle} model of privacy. We present the first generic algorithm for\nepisodic RL under the shuffle model, where a trusted shuffler randomly permutes\na batch of users' data before sending it to the central agent. We then\ninstantiate the algorithm using our proposed shuffle Privatizer, relying on a\nshuffle private binary summation mechanism. Our analysis shows that the\nalgorithm achieves a near-optimal regret bound comparable to that of the\ncentralized model and significantly outperforms the local model in terms of\nprivacy cost.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11647v1",
    "published_date": "2024-11-18 15:24:11 UTC",
    "updated_date": "2024-11-18 15:24:11 UTC"
  },
  {
    "arxiv_id": "2411.11641v3",
    "title": "TSINR: Capturing Temporal Continuity via Implicit Neural Representations for Time Series Anomaly Detection",
    "authors": [
      "Mengxuan Li",
      "Ke Liu",
      "Hongyang Chen",
      "Jiajun Bu",
      "Hongwei Wang",
      "Haishuai Wang"
    ],
    "abstract": "Time series anomaly detection aims to identify unusual patterns in data or\ndeviations from systems' expected behavior. The reconstruction-based methods\nare the mainstream in this task, which learn point-wise representation via\nunsupervised learning. However, the unlabeled anomaly points in training data\nmay cause these reconstruction-based methods to learn and reconstruct anomalous\ndata, resulting in the challenge of capturing normal patterns. In this paper,\nwe propose a time series anomaly detection method based on implicit neural\nrepresentation (INR) reconstruction, named TSINR, to address this challenge.\nDue to the property of spectral bias, TSINR enables prioritizing low-frequency\nsignals and exhibiting poorer performance on high-frequency abnormal data.\nSpecifically, we adopt INR to parameterize time series data as a continuous\nfunction and employ a transformer-based architecture to predict the INR of\ngiven data. As a result, the proposed TSINR method achieves the advantage of\ncapturing the temporal continuity and thus is more sensitive to discontinuous\nanomaly data. In addition, we further design a novel form of INR continuous\nfunction to learn inter- and intra-channel information, and leverage a\npre-trained large language model to amplify the intense fluctuations in\nanomalies. Extensive experiments demonstrate that TSINR achieves superior\noverall performance on both univariate and multivariate time series anomaly\ndetection benchmarks compared to other state-of-the-art reconstruction-based\nmethods. Our codes are available.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by SIGKDD 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.11641v3",
    "published_date": "2024-11-18 15:19:54 UTC",
    "updated_date": "2025-05-15 06:30:38 UTC"
  },
  {
    "arxiv_id": "2411.11636v1",
    "title": "SP${ }^3$ : Superpixel-propagated pseudo-label learning for weakly semi-supervised medical image segmentation",
    "authors": [
      "Shiman Li",
      "Jiayue Zhao",
      "Shaolei Liu",
      "Xiaokun Dai",
      "Chenxi Zhang",
      "Zhijian Song"
    ],
    "abstract": "Deep learning-based medical image segmentation helps assist diagnosis and\naccelerate the treatment process while the model training usually requires\nlarge-scale dense annotation datasets. Weakly semi-supervised medical image\nsegmentation is an essential application because it only requires a small\namount of scribbles and a large number of unlabeled data to train the model,\nwhich greatly reduces the clinician's effort to fully annotate images. To\nhandle the inadequate supervisory information challenge in weakly\nsemi-supervised segmentation (WSSS), a SuperPixel-Propagated Pseudo-label\n(SP${}^3$) learning method is proposed, using the structural information\ncontained in superpixel for supplemental information. Specifically, the\nannotation of scribbles is propagated to superpixels and thus obtains a dense\nannotation for supervised training. Since the quality of pseudo-labels is\nlimited by the low-quality annotation, the beneficial superpixels selected by\ndynamic thresholding are used to refine pseudo-labels. Furthermore, aiming to\nalleviate the negative impact of noise in pseudo-label, superpixel-level\nuncertainty is incorporated to guide the pseudo-label supervision for stable\nlearning. Our method achieves state-of-the-art performance on both tumor and\norgan segmentation datasets under the WSSS setting, using only 3\\% of the\nannotation workload compared to fully supervised methods and attaining\napproximately 80\\% Dice score. Additionally, our method outperforms eight\nweakly and semi-supervised methods under both weakly supervised and\nsemi-supervised settings. Results of extensive experiments validate the\neffectiveness and annotation efficiency of our weakly semi-supervised\nsegmentation, which can assist clinicians in achieving automated segmentation\nfor organs or tumors quickly and ultimately benefit patients.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 7 figures. Under Review",
    "pdf_url": "http://arxiv.org/pdf/2411.11636v1",
    "published_date": "2024-11-18 15:14:36 UTC",
    "updated_date": "2024-11-18 15:14:36 UTC"
  },
  {
    "arxiv_id": "2411.11635v1",
    "title": "Chapter 7 Review of Data-Driven Generative AI Models for Knowledge Extraction from Scientific Literature in Healthcare",
    "authors": [
      "Leon Kopitar",
      "Primoz Kocbek",
      "Lucija Gosak",
      "Gregor Stiglic"
    ],
    "abstract": "This review examines the development of abstractive NLP-based text\nsummarization approaches and compares them to existing techniques for\nextractive summarization. A brief history of text summarization from the 1950s\nto the introduction of pre-trained language models such as Bidirectional\nEncoder Representations from Transformer (BERT) and Generative Pre-training\nTransformers (GPT) are presented. In total, 60 studies were identified in\nPubMed and Web of Science, of which 29 were excluded and 24 were read and\nevaluated for eligibility, resulting in the use of seven studies for further\nanalysis. This chapter also includes a section with examples including an\nexample of a comparison between GPT-3 and state-of-the-art GPT-4 solutions in\nscientific text summarisation. Natural language processing has not yet reached\nits full potential in the generation of brief textual summaries. As there are\nacknowledged concerns that must be addressed, we can expect gradual\nintroduction of such models in practise.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 5 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2411.11635v1",
    "published_date": "2024-11-18 15:13:47 UTC",
    "updated_date": "2024-11-18 15:13:47 UTC"
  },
  {
    "arxiv_id": "2411.11934v2",
    "title": "SpatialDreamer: Self-supervised Stereo Video Synthesis from Monocular Input",
    "authors": [
      "Zhen Lv",
      "Yangqi Long",
      "Congzhentao Huang",
      "Cao Li",
      "Chengfei Lv",
      "Hao Ren",
      "Dian Zheng"
    ],
    "abstract": "Stereo video synthesis from a monocular input is a demanding task in the\nfields of spatial computing and virtual reality. The main challenges of this\ntask lie on the insufficiency of high-quality paired stereo videos for training\nand the difficulty of maintaining the spatio-temporal consistency between\nframes. Existing methods primarily address these issues by directly applying\nnovel view synthesis (NVS) techniques to video, while facing limitations such\nas the inability to effectively represent dynamic scenes and the requirement\nfor large amounts of training data. In this paper, we introduce a novel\nself-supervised stereo video synthesis paradigm via a video diffusion model,\ntermed SpatialDreamer, which meets the challenges head-on. Firstly, to address\nthe stereo video data insufficiency, we propose a Depth based Video Generation\nmodule DVG, which employs a forward-backward rendering mechanism to generate\npaired videos with geometric and temporal priors. Leveraging data generated by\nDVG, we propose RefinerNet along with a self-supervised synthetic framework\ndesigned to facilitate efficient and dedicated training. More importantly, we\ndevise a consistency control module, which consists of a metric of stereo\ndeviation strength and a Temporal Interaction Learning module TIL for geometric\nand temporal consistency ensurance respectively. We evaluated the proposed\nmethod against various benchmark methods, with the results showcasing its\nsuperior performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "website, see https://spatialdreamer.github.io",
    "pdf_url": "http://arxiv.org/pdf/2411.11934v2",
    "published_date": "2024-11-18 15:12:59 UTC",
    "updated_date": "2025-04-27 07:46:27 UTC"
  },
  {
    "arxiv_id": "2411.11933v2",
    "title": "METEOR: Evolutionary Journey of Large Language Models from Guidance to Self-Growth",
    "authors": [
      "Jiawei Li",
      "Xiaoang Xu",
      "Yang Gao"
    ],
    "abstract": "Model evolution enables learning from feedback to refine experiences and\nupdate skills, transforming models from having no domain knowledge to becoming\ndomain experts. However, there is currently no unified and effective method for\nguiding this evolutionary process. To address this gap, we propose the Meteor\nmethod, which includes three training phases: weak-to-strong data distillation,\niterative training, and self-evolution strategies. Each phase maximizes the\nmodel's inherent domain capabilities, allowing it to autonomously refine its\ndomain knowledge and enhance performance. Experiments demonstrate that our\napproach significantly improves accuracy, completeness, relevance, coherence,\nand reliability across domain-specific tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Our code can be found at https://github.com/DIRECT-BIT/METEOR",
    "pdf_url": "http://arxiv.org/pdf/2411.11933v2",
    "published_date": "2024-11-18 15:09:50 UTC",
    "updated_date": "2024-11-29 06:07:41 UTC"
  },
  {
    "arxiv_id": "2412.00026v1",
    "title": "Spatial-variant causal Bayesian inference for rapid seismic ground failures and impacts estimation",
    "authors": [
      "Xuechun Li",
      "Susu Xu"
    ],
    "abstract": "Rapid and accurate estimation of post-earthquake ground failures and building\ndamage is critical for effective post-disaster responses. Progression in remote\nsensing technologies has paved the way for rapid acquisition of detailed,\nlocalized data, enabling swift hazard estimation through analysis of\ncorrelation deviations between pre- and post-quake satellite imagery. However,\ndiscerning seismic hazards and their impacts is challenged by overlapping\nsatellite signals from ground failures, building damage, and environmental\nnoise. Previous advancements introduced a novel causal graph-based Bayesian\nnetwork that continually refines seismic ground failure and building damage\nestimates derived from satellite imagery, accounting for the intricate\ninterplay among geospatial elements, seismic activity, ground failures,\nbuilding structures, damages, and satellite data. However, this model's neglect\nof spatial heterogeneity across different locations in a seismic region limits\nits precision in capturing the spatial diversity of seismic effects. In this\nstudy, we pioneer an approach that accounts for spatial intricacies by\nintroducing a spatial variable influenced by the bilateral filter to capture\nrelationships from surrounding hazards. The bilateral filter considers both\nspatial proximity of neighboring hazards and their ground shaking intensity\nvalues, ensuring refined modeling of spatial relationships. This integration\nachieves a balance between site-specific characteristics and spatial\ntendencies, offering a comprehensive representation of the post-disaster\nlandscape. Our model, tested across multiple earthquake events, demonstrates\nsignificant improvements in capturing spatial heterogeneity in seismic hazard\nestimation. The results highlight enhanced accuracy and efficiency in\npost-earthquake large-scale multi-impact estimation, effectively informing\nrapid disaster responses.",
    "categories": [
      "physics.geo-ph",
      "cs.AI"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "This paper was accepted for 2024 WCEE conference",
    "pdf_url": "http://arxiv.org/pdf/2412.00026v1",
    "published_date": "2024-11-18 15:01:28 UTC",
    "updated_date": "2024-11-18 15:01:28 UTC"
  },
  {
    "arxiv_id": "2411.11620v1",
    "title": "ST-Tree with Interpretability for Multivariate Time Series Classification",
    "authors": [
      "Mingsen Du",
      "Yanxuan Wei",
      "Yingxia Tang",
      "Xiangwei Zheng",
      "Shoushui Wei",
      "Cun Ji"
    ],
    "abstract": "Multivariate time series classification is of great importance in practical\napplications and is a challenging task. However, deep neural network models\nsuch as Transformers exhibit high accuracy in multivariate time series\nclassification but lack interpretability and fail to provide insights into the\ndecision-making process. On the other hand, traditional approaches based on\ndecision tree classifiers offer clear decision processes but relatively lower\naccuracy. Swin Transformer (ST) addresses these issues by leveraging\nself-attention mechanisms to capture both fine-grained local patterns and\nglobal patterns. It can also model multi-scale feature representation learning,\nthereby providing a more comprehensive representation of time series features.\nTo tackle the aforementioned challenges, we propose ST-Tree with\ninterpretability for multivariate time series classification. Specifically, the\nST-Tree model combines ST as the backbone network with an additional neural\ntree model. This integration allows us to fully leverage the advantages of ST\nin learning time series context while providing interpretable decision\nprocesses through the neural tree. This enables researchers to gain clear\ninsights into the model's decision-making process and extract meaningful\ninterpretations. Through experimental evaluations on 10 UEA datasets, we\ndemonstrate that the ST-Tree model improves accuracy in multivariate time\nseries classification tasks and provides interpretability through visualizing\nthe decision-making process across different datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted on May 15, 2024, major revisions on Aug 31, 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.11620v1",
    "published_date": "2024-11-18 14:49:12 UTC",
    "updated_date": "2024-11-18 14:49:12 UTC"
  },
  {
    "arxiv_id": "2411.11616v2",
    "title": "Signaling and Social Learning in Swarms of Robots",
    "authors": [
      "Leo Cazenille",
      "Maxime Toquebiau",
      "Nicolas Lobato-Dauzier",
      "Alessia Loi",
      "Loona Macabre",
      "Nathanael Aubert-Kato",
      "Anthony Genot",
      "Nicolas Bredeche"
    ],
    "abstract": "This paper investigates the role of communication in improving coordination\nwithin robot swarms, focusing on a paradigm where learning and execution occur\nsimultaneously in a decentralized manner. We highlight the role communication\ncan play in addressing the credit assignment problem (individual contribution\nto the overall performance), and how it can be influenced by it. We propose a\ntaxonomy of existing and future works on communication, focusing on information\nselection and physical abstraction as principal axes for classification: from\nlow-level lossless compression with raw signal extraction and processing to\nhigh-level lossy compression with structured communication models. The paper\nreviews current research from evolutionary robotics, multi-agent (deep)\nreinforcement learning, language models, and biophysics models to outline the\nchallenges and opportunities of communication in a collective of robots that\ncontinuously learn from one another through local message exchanges,\nillustrating a form of social learning.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "17 pages, 3 Figures",
    "pdf_url": "http://arxiv.org/pdf/2411.11616v2",
    "published_date": "2024-11-18 14:42:15 UTC",
    "updated_date": "2024-11-19 10:11:04 UTC"
  },
  {
    "arxiv_id": "2411.11932v1",
    "title": "Reviving Dormant Memories: Investigating Catastrophic Forgetting in Language Models through Rationale-Guidance Difficulty",
    "authors": [
      "Huashan Sun",
      "Yang Gao"
    ],
    "abstract": "Although substantial efforts have been made to mitigate catastrophic\nforgetting in continual learning, the intrinsic mechanisms are not well\nunderstood. In this paper, we discover that when a forgetting model passively\nreceives an externally provided partial appropriate rationale, its performance\non the forgotten task can be restored. Furthermore, by simply adding a\ntask-agnostic prefix to the original instruction, the forgetting model can\nactively generate an appropriate rationale to reach the correct answer. These\nfindings suggest that the model does not actually ``forget'' the task\nknowledge; instead, the degraded performance can be attributed to the failure\nof the original instructions in guiding the model to generate the appropriate\nrationales. Based on this insight, we propose the Rationale-Guidance Difficulty\nmetric to evaluate how effectively a given instruction guides the model in\ngenerating appropriate rationales. We apply this metric to optimize the\nallocation of replay data in replay-based continual learning algorithm.\nExperimental results demonstrate that our data allocation method effectively\nmitigates catastrophic forgetting and maintains better model plasticity\nsimultaneously across models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Working in progress",
    "pdf_url": "http://arxiv.org/pdf/2411.11932v1",
    "published_date": "2024-11-18 14:28:04 UTC",
    "updated_date": "2024-11-18 14:28:04 UTC"
  },
  {
    "arxiv_id": "2411.14466v1",
    "title": "Learning to Ask: Conversational Product Search via Representation Learning",
    "authors": [
      "Jie Zou",
      "Jimmy Xiangji Huang",
      "Zhaochun Ren",
      "Evangelos Kanoulas"
    ],
    "abstract": "Online shopping platforms, such as Amazon and AliExpress, are increasingly\nprevalent in society, helping customers purchase products conveniently. With\nrecent progress in natural language processing, researchers and practitioners\nshift their focus from traditional product search to conversational product\nsearch. Conversational product search enables user-machine conversations and\nthrough them collects explicit user feedback that allows to actively clarify\nthe users' product preferences. Therefore, prospective research on an\nintelligent shopping assistant via conversations is indispensable. Existing\npublications on conversational product search either model conversations\nindependently from users, queries, and products or lead to a vocabulary\nmismatch. In this work, we propose a new conversational product search model,\nConvPS, to assist users in locating desirable items. The model is first trained\nto jointly learn the semantic representations of user, query, item, and\nconversation via a unified generative framework. After learning these\nrepresentations, they are integrated to retrieve the target items in the latent\nsemantic space. Meanwhile, we propose a set of greedy and explore-exploit\nstrategies to learn to ask the user a sequence of high-performance questions\nfor conversations. Our proposed ConvPS model can naturally integrate the\nrepresentation learning of the user, query, item, and conversation into a\nunified generative framework, which provides a promising avenue for\nconstructing accurate and robust conversational product search systems that are\nflexible and adaptive. Experimental results demonstrate that our ConvPS model\nsignificantly outperforms state-of-the-art baselines.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACM TOIS",
    "pdf_url": "http://arxiv.org/pdf/2411.14466v1",
    "published_date": "2024-11-18 14:05:43 UTC",
    "updated_date": "2024-11-18 14:05:43 UTC"
  },
  {
    "arxiv_id": "2411.11576v1",
    "title": "Hybrid Data-Driven SSM for Interpretable and Label-Free mmWave Channel Prediction",
    "authors": [
      "Yiyong Sun",
      "Jiajun He",
      "Zhidi Lin",
      "Wenqiang Pu",
      "Feng Yin",
      "Hing Cheung So"
    ],
    "abstract": "Accurate prediction of mmWave time-varying channels is essential for\nmitigating the issue of channel aging in complex scenarios owing to high user\nmobility. Existing channel prediction methods have limitations: classical\nmodel-based methods often struggle to track highly nonlinear channel dynamics\ndue to limited expert knowledge, while emerging data-driven methods typically\nrequire substantial labeled data for effective training and often lack\ninterpretability. To address these issues, this paper proposes a novel hybrid\nmethod that integrates a data-driven neural network into a conventional\nmodel-based workflow based on a state-space model (SSM), implicitly tracking\ncomplex channel dynamics from data without requiring precise expert knowledge.\nAdditionally, a novel unsupervised learning strategy is developed to train the\nembedded neural network solely with unlabeled data. Theoretical analyses and\nablation studies are conducted to interpret the enhanced benefits gained from\nthe hybrid integration. Numerical simulations based on the 3GPP mmWave channel\nmodel corroborate the superior prediction accuracy of the proposed method,\ncompared to state-of-the-art methods that are either purely model-based or\ndata-driven. Furthermore, extensive experiments validate its robustness against\nvarious challenging factors, including among others severe channel variations\nand high noise levels.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11576v1",
    "published_date": "2024-11-18 13:54:44 UTC",
    "updated_date": "2024-11-18 13:54:44 UTC"
  },
  {
    "arxiv_id": "2411.11560v1",
    "title": "Topology-aware Preemptive Scheduling for Co-located LLM Workloads",
    "authors": [
      "Ping Zhang",
      "Lei Su",
      "Jinjie Yang",
      "Xin Chen"
    ],
    "abstract": "Hosting diverse large language model workloads in a unified resource pool\nthrough co-location is cost-effective. For example, long-running chat services\ngenerally follow diurnal traffic patterns, which inspire co-location of batch\njobs to fulfill resource valleys between successive peaks, and thus to saturate\nresource allocation in cluster-wide scope. These heterogeneous workloads often\nhave different business priorities, and therefore preemption can be leveraged\nfor resource elasticity. However, workloads often have distinct topology\npreferences as well. The resources released by lower-priority instances may\nfail to meet the requirements of high-priority online services which are\nusually latency-sensitive. The root cause behind such mis-match is a lack of\ntopology awareness of resource scheduler, especially during preemption. To\nbridge this gap, we develop a fine-grained topology-aware method for preemptive\nscheduling of hybrid workloads. The method ensures that the resources freed by\npreempted tasks adhere to the topological affinity needs of high-priority\npreemptors in a guaranteed or best-effort manner. This dynamic alignment\nsignificantly increases the efficiency of preemption and improves overall\nscheduled performance for LLM workloads by $55\\%$.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "17 Pages, 11 Figures, 5 Tables",
    "pdf_url": "http://arxiv.org/pdf/2411.11560v1",
    "published_date": "2024-11-18 13:26:09 UTC",
    "updated_date": "2024-11-18 13:26:09 UTC"
  },
  {
    "arxiv_id": "2411.11548v1",
    "title": "Real-Time Fitness Exercise Classification and Counting from Video Frames",
    "authors": [
      "Riccardo Riccio"
    ],
    "abstract": "This paper introduces a novel method for real-time exercise classification\nusing a Bidirectional Long Short-Term Memory (BiLSTM) neural network. Existing\nexercise recognition approaches often rely on synthetic datasets, raw\ncoordinate inputs sensitive to user and camera variations, and fail to fully\nexploit the temporal dependencies in exercise movements. These issues limit\ntheir generalizability and robustness in real-world conditions, where lighting,\ncamera angles, and user body types vary.\n  To address these challenges, we propose a BiLSTM-based model that leverages\ninvariant features, such as joint angles, alongside raw coordinates. By using\nboth angles and (x, y, z) coordinates, the model adapts to changes in\nperspective, user positioning, and body differences, improving generalization.\nTraining on 30-frame sequences enables the BiLSTM to capture the temporal\ncontext of exercises and recognize patterns evolving over time.\n  We compiled a dataset combining synthetic data from the InfiniteRep dataset\nand real-world videos from Kaggle and other sources. This dataset includes four\ncommon exercises: squat, push-up, shoulder press, and bicep curl. The model was\ntrained and validated on these diverse datasets, achieving an accuracy of over\n99% on the test set. To assess generalizability, the model was tested on 2\nseparate test sets representative of typical usage conditions. Comparisons with\nthe previous approach from the literature are present in the result section\nshowing that the proposed model is the best-performing one.\n  The classifier is integrated into a web application providing real-time\nexercise classification and repetition counting without manual exercise\nselection.\n  Demo and datasets are available at the following GitHub Repository:\nhttps://github.com/RiccardoRiccio/Fitness-AI-Trainer-With-Automatic-Exercise-Recognition-and-Counting.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11548v1",
    "published_date": "2024-11-18 13:06:29 UTC",
    "updated_date": "2024-11-18 13:06:29 UTC"
  },
  {
    "arxiv_id": "2411.11543v4",
    "title": "PSA-VLM: Enhancing Vision-Language Model Safety through Progressive Concept-Bottleneck-Driven Alignment",
    "authors": [
      "Zhendong Liu",
      "Yuanbi Nie",
      "Yingshui Tan",
      "Jiaheng Liu",
      "Xiangyu Yue",
      "Qiushi Cui",
      "Chongjun Wang",
      "Xiaoyong Zhu",
      "Bo Zheng"
    ],
    "abstract": "Benefiting from the powerful capabilities of Large Language Models (LLMs),\npre-trained visual encoder models connected to LLMs form Vision Language Models\n(VLMs). However, recent research shows that the visual modality in VLMs is\nhighly vulnerable, allowing attackers to bypass safety alignment in LLMs\nthrough visually transmitted content, launching harmful attacks. To address\nthis challenge, we propose a progressive concept-based alignment strategy,\nPSA-VLM, which incorporates safety modules as concept bottlenecks to enhance\nvisual modality safety alignment. By aligning model predictions with specific\nsafety concepts, we improve defenses against risky images, enhancing\nexplainability and controllability while minimally impacting general\nperformance. Our method is obtained through two-stage training. The low\ncomputational cost of the first stage brings very effective performance\nimprovement, and the fine-tuning of the language model in the second stage\nfurther improves the safety performance. Our method achieves state-of-the-art\nresults on popular VLM safety benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2405.13581",
    "pdf_url": "http://arxiv.org/pdf/2411.11543v4",
    "published_date": "2024-11-18 13:01:57 UTC",
    "updated_date": "2025-01-13 10:39:04 UTC"
  },
  {
    "arxiv_id": "2411.11531v2",
    "title": "Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality",
    "authors": [
      "Viktoriia Chekalina",
      "Anton Razzhigaev",
      "Elizaveta Goncharova",
      "Andrey Kuznetsov"
    ],
    "abstract": "In this paper we present an approach to reduce hallucinations in Large\nLanguage Models (LLMs) by incorporating Knowledge Graphs (KGs) as an additional\nmodality. Our method involves transforming input text into a set of KG\nembeddings and using an adapter to integrate these embeddings into the language\nmodel space, without relying on external retrieval processes.\n  To facilitate this, we created WikiEntities, a dataset containing over 3\nmillion Wikipedia texts annotated with entities from Wikidata and their\ncorresponding embeddings from PyTorch-BigGraph. This dataset serves as a\nvaluable resource for training Entity Linking models and adapting the described\nmethod to various LLMs using specialized adapters.\n  Our method does not require fine-tuning of the language models themselves;\ninstead, we only train the adapter. This ensures that the model's performance\non other tasks is not affected. We trained an adapter for the Mistral 7B, LLaMA\n2-7B (chat), and LLaMA 3-8B (instruct) models using this dataset and\ndemonstrated that our approach improves performance on the HaluEval, True-False\nbenchmarks and FEVER dataset. The results indicate that incorporating KGs as a\nnew modality can effectively reduce hallucinations and improve the factual\naccuracy of language models, all without the need for external retrieval.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11531v2",
    "published_date": "2024-11-18 12:40:51 UTC",
    "updated_date": "2025-01-14 12:56:34 UTC"
  },
  {
    "arxiv_id": "2411.15178v3",
    "title": "Harnessing Scale and Physics: A Multi-Graph Neural Operator Framework for PDEs on Arbitrary Geometries",
    "authors": [
      "Zhihao Li",
      "Haoze Song",
      "Di Xiao",
      "Zhilu Lai",
      "Wei Wang"
    ],
    "abstract": "Partial Differential Equations (PDEs) underpin many scientific phenomena, yet\ntraditional computational approaches often struggle with complex, nonlinear\nsystems and irregular geometries. This paper introduces the AMG method, a\nMulti-Graph neural operator approach designed for efficiently solving PDEs on\nArbitrary geometries. AMG leverages advanced graph-based techniques and dynamic\nattention mechanisms within a novel GraphFormer architecture, enabling precise\nmanagement of diverse spatial domains and complex data interdependencies. By\nconstructing multi-scale graphs to handle variable feature frequencies and a\nphysics graph to encapsulate inherent physical properties, AMG significantly\noutperforms previous methods, which are typically limited to uniform grids. We\npresent a comprehensive evaluation of AMG across six benchmarks, demonstrating\nits consistent superiority over existing state-of-the-art models. Our findings\nhighlight the transformative potential of tailored graph neural operators in\nsurmounting the challenges faced by conventional PDE solvers. Our code and\ndatasets are available on https://github.com/lizhihao2022/AMG.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining V.1 (KDD '25)",
    "pdf_url": "http://arxiv.org/pdf/2411.15178v3",
    "published_date": "2024-11-18 12:35:03 UTC",
    "updated_date": "2025-02-07 13:53:41 UTC"
  },
  {
    "arxiv_id": "2411.11520v1",
    "title": "A Pre-Trained Graph-Based Model for Adaptive Sequencing of Educational Documents",
    "authors": [
      "Jean Vassoyan",
      "Anan Schütt",
      "Jill-Jênn Vie",
      "Arun-Balajiee Lekshmi-Narayanan",
      "Elisabeth André",
      "Nicolas Vayatis"
    ],
    "abstract": "Massive Open Online Courses (MOOCs) have greatly contributed to making\neducation more accessible. However, many MOOCs maintain a rigid,\none-size-fits-all structure that fails to address the diverse needs and\nbackgrounds of individual learners. Learning path personalization aims to\naddress this limitation, by tailoring sequences of educational content to\noptimize individual student learning outcomes. Existing approaches, however,\noften require either massive student interaction data or extensive expert\nannotation, limiting their broad application. In this study, we introduce a\nnovel data-efficient framework for learning path personalization that operates\nwithout expert annotation. Our method employs a flexible recommender system\npre-trained with reinforcement learning on a dataset of raw course materials.\nThrough experiments on semi-synthetic data, we show that this pre-training\nstage substantially improves data-efficiency in a range of adaptive learning\nscenarios featuring new educational materials. This opens up new perspectives\nfor the design of foundation models for adaptive learning.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2024 Workshop on Large Foundation Models for Educational\n  Assessment (FM-Assess), Dec 2024, Vancouver, Canada",
    "pdf_url": "http://arxiv.org/pdf/2411.11520v1",
    "published_date": "2024-11-18 12:29:06 UTC",
    "updated_date": "2024-11-18 12:29:06 UTC"
  },
  {
    "arxiv_id": "2411.11511v1",
    "title": "Structure learning with Temporal Gaussian Mixture for model-based Reinforcement Learning",
    "authors": [
      "Théophile Champion",
      "Marek Grześ",
      "Howard Bowman"
    ],
    "abstract": "Model-based reinforcement learning refers to a set of approaches capable of\nsample-efficient decision making, which create an explicit model of the\nenvironment. This model can subsequently be used for learning optimal policies.\nIn this paper, we propose a temporal Gaussian Mixture Model composed of a\nperception model and a transition model. The perception model extracts discrete\n(latent) states from continuous observations using a variational Gaussian\nmixture likelihood. Importantly, our model constantly monitors the collected\ndata searching for new Gaussian components, i.e., the perception model performs\na form of structure learning (Smith et al., 2020; Friston et al., 2018; Neacsu\net al., 2022) as it learns the number of Gaussian components in the mixture.\nAdditionally, the transition model learns the temporal transition between\nconsecutive time steps by taking advantage of the Dirichlet-categorical\nconjugacy. Both the perception and transition models are able to forget part of\nthe data points, while integrating the information they provide within the\nprior, which ensure fast variational inference. Finally, decision making is\nperformed with a variant of Q-learning which is able to learn Q-values from\nbeliefs over states. Empirically, we have demonstrated the model's ability to\nlearn the structure of several mazes: the model discovered the number of states\nand the transition probabilities between these states. Moreover, using its\nlearned Q-values, the agent was able to successfully navigate from the starting\nposition to the maze's exit.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11511v1",
    "published_date": "2024-11-18 12:16:03 UTC",
    "updated_date": "2024-11-18 12:16:03 UTC"
  },
  {
    "arxiv_id": "2411.11510v1",
    "title": "Closed-loop multi-step planning with innate physics knowledge",
    "authors": [
      "Giulia Lafratta",
      "Bernd Porr",
      "Christopher Chandler",
      "Alice Miller"
    ],
    "abstract": "We present a hierarchical framework to solve robot planning as an input\ncontrol problem. At the lowest level are temporary closed control loops,\n(\"tasks\"), each representing a behaviour, contingent on a specific sensory\ninput and therefore temporary. At the highest level, a supervising\n\"Configurator\" directs task creation and termination. Here resides \"core\"\nknowledge as a physics engine, where sequences of tasks can be simulated. The\nConfigurator encodes and interprets simulation results,based on which it can\nchoose a sequence of tasks as a plan. We implement this framework on a real\nrobot and test it in an overtaking scenario as proof-of-concept.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.ET",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11510v1",
    "published_date": "2024-11-18 12:15:16 UTC",
    "updated_date": "2024-11-18 12:15:16 UTC"
  },
  {
    "arxiv_id": "2411.11504v1",
    "title": "Search, Verify and Feedback: Towards Next Generation Post-training Paradigm of Foundation Models via Verifier Engineering",
    "authors": [
      "Xinyan Guan",
      "Yanjiang Liu",
      "Xinyu Lu",
      "Boxi Cao",
      "Ben He",
      "Xianpei Han",
      "Le Sun",
      "Jie Lou",
      "Bowen Yu",
      "Yaojie Lu",
      "Hongyu Lin"
    ],
    "abstract": "The evolution of machine learning has increasingly prioritized the\ndevelopment of powerful models and more scalable supervision signals. However,\nthe emergence of foundation models presents significant challenges in providing\neffective supervision signals necessary for further enhancing their\ncapabilities. Consequently, there is an urgent need to explore novel\nsupervision signals and technical approaches. In this paper, we propose\nverifier engineering, a novel post-training paradigm specifically designed for\nthe era of foundation models. The core of verifier engineering involves\nleveraging a suite of automated verifiers to perform verification tasks and\ndeliver meaningful feedback to foundation models. We systematically categorize\nthe verifier engineering process into three essential stages: search, verify,\nand feedback, and provide a comprehensive review of state-of-the-art research\ndevelopments within each stage. We believe that verifier engineering\nconstitutes a fundamental pathway toward achieving Artificial General\nIntelligence.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11504v1",
    "published_date": "2024-11-18 12:04:52 UTC",
    "updated_date": "2024-11-18 12:04:52 UTC"
  },
  {
    "arxiv_id": "2412.03580v1",
    "title": "Reinforced Symbolic Learning with Logical Constraints for Predicting Turbine Blade Fatigue Life",
    "authors": [
      "Pei Li",
      "Joo-Ho Choi",
      "Dingyang Zhang",
      "Shuyou Zhang",
      "Yiming Zhang"
    ],
    "abstract": "Accurate prediction of turbine blade fatigue life is essential for ensuring\nthe safety and reliability of aircraft engines. A significant challenge in this\ndomain is uncovering the intrinsic relationship between mechanical properties\nand fatigue life. This paper introduces Reinforced Symbolic Learning (RSL), a\nmethod that derives predictive formulas linking these properties to fatigue\nlife. RSL incorporates logical constraints during symbolic optimization,\nensuring that the generated formulas are both physically meaningful and\ninterpretable. The optimization process is further enhanced using deep\nreinforcement learning, which efficiently guides the symbolic regression\ntowards more accurate models. The proposed RSL method was evaluated on two\nturbine blade materials, GH4169 and TC4, to identify optimal fatigue life\nprediction models. When compared with six empirical formulas and five machine\nlearning algorithms, RSL not only produces more interpretable formulas but also\nachieves superior or comparable predictive accuracy. Additionally, finite\nelement simulations were conducted to assess mechanical properties at critical\npoints on the blade, which were then used to predict fatigue life under various\noperating conditions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "full-lenth article with 24 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.03580v1",
    "published_date": "2024-11-18 12:01:48 UTC",
    "updated_date": "2024-11-18 12:01:48 UTC"
  },
  {
    "arxiv_id": "2411.11494v1",
    "title": "Alien Recombination: Exploring Concept Blends Beyond Human Cognitive Availability in Visual Art",
    "authors": [
      "Alejandro Hernandez",
      "Levin Brinkmann",
      "Ignacio Serna",
      "Nasim Rahaman",
      "Hassan Abu Alhaija",
      "Hiromu Yakura",
      "Mar Canet Sola",
      "Bernhard Schölkopf",
      "Iyad Rahwan"
    ],
    "abstract": "While AI models have demonstrated remarkable capabilities in constrained\ndomains like game strategy, their potential for genuine creativity in\nopen-ended domains like art remains debated. We explore this question by\nexamining how AI can transcend human cognitive limitations in visual art\ncreation. Our research hypothesizes that visual art contains a vast unexplored\nspace of conceptual combinations, constrained not by inherent incompatibility,\nbut by cognitive limitations imposed by artists' cultural, temporal,\ngeographical and social contexts.\n  To test this hypothesis, we present the Alien Recombination method, a novel\napproach utilizing fine-tuned large language models to identify and generate\nconcept combinations that lie beyond human cognitive availability. The system\nmodels and deliberately counteracts human availability bias, the tendency to\nrely on immediately accessible examples, to discover novel artistic\ncombinations.\n  This system not only produces combinations that have never been attempted\nbefore within our dataset but also identifies and generates combinations that\nare cognitively unavailable to all artists in the domain. Furthermore, we\ntranslate these combinations into visual representations, enabling the\nexploration of subjective perceptions of novelty. Our findings suggest that\ncognitive unavailability is a promising metric for optimizing artistic novelty,\noutperforming merely temperature scaling without additional evaluation\ncriteria. This approach uses generative models to connect previously\nunconnected ideas, providing new insight into the potential of framing\nAI-driven creativity as a combinatorial problem.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2024 Workshop on Creativity & Generative AI, 13 pages, 11\n  figures",
    "pdf_url": "http://arxiv.org/pdf/2411.11494v1",
    "published_date": "2024-11-18 11:55:38 UTC",
    "updated_date": "2024-11-18 11:55:38 UTC"
  },
  {
    "arxiv_id": "2411.11930v3",
    "title": "AtomThink: A Slow Thinking Framework for Multimodal Mathematical Reasoning",
    "authors": [
      "Kun Xiang",
      "Zhili Liu",
      "Zihao Jiang",
      "Yunshuang Nie",
      "Runhui Huang",
      "Haoxiang Fan",
      "Hanhui Li",
      "Weiran Huang",
      "Yihan Zeng",
      "Jianhua Han",
      "Lanqing Hong",
      "Hang Xu",
      "Xiaodan Liang"
    ],
    "abstract": "In this paper, we address the challenging task of multimodal mathematical\nreasoning by incorporating the ability of ``slow thinking\" into multimodal\nlarge language models (MLLMs). Contrary to existing methods that rely on direct\nor fast thinking, our key idea is to construct long chains of thought (CoT)\nconsisting of atomic actions in a step-by-step manner, guiding MLLMs to perform\ncomplex reasoning. To this end, we design a novel AtomThink framework composed\nof three key modules: (i) a CoT annotation engine that automatically generates\nhigh-quality CoT annotations to address the lack of high-quality visual\nmathematical data; (ii) an atomic step fine-tuning strategy that jointly\noptimizes an MLLM and a policy reward model (PRM) for step-wise reasoning; and\n(iii) four different search strategies that can be applied with the PRM to\ncomplete reasoning. Additionally, we propose AtomMATH, a large-scale multimodal\ndataset of long CoTs, and an atomic capability evaluation metric for\nmathematical tasks. Extensive experimental results show that the proposed\nAtomThink significantly improves the performance of baseline MLLMs, achieving\napproximately 50\\% relative accuracy gains on MathVista and 120\\% on MathVerse.\nTo support the advancement of multimodal slow-thinking models, we will make our\ncode and dataset publicly available on https://github.com/Quinn777/AtomThink.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11930v3",
    "published_date": "2024-11-18 11:54:58 UTC",
    "updated_date": "2024-12-13 06:54:04 UTC"
  },
  {
    "arxiv_id": "2412.02512v2",
    "title": "Pre-Deployment Information Sharing: A Zoning Taxonomy for Precursory Capabilities",
    "authors": [
      "Matteo Pistillo",
      "Charlotte Stix"
    ],
    "abstract": "High-impact and potentially dangerous capabilities can and should be broken\ndown into early warning shots long before reaching red lines. Each of these\nearly warning shots should correspond to a precursory capability. Each\nprecursory capability sits on a spectrum indicating its proximity to a final\nhigh-impact capability, corresponding to a red line. To meaningfully detect and\ntrack capability progress, we propose a taxonomy of dangerous capability zones\n(a zoning taxonomy) tied to a staggered information exchange framework that\nenables relevant bodies to take action accordingly. In the Frontier AI Safety\nCommitments, signatories commit to sharing more detailed information with\ntrusted actors, including an appointed body, as appropriate (Commitment VII).\nBuilding on our zoning taxonomy, this paper makes four recommendations for\nspecifying information sharing as detailed in Commitment VII. (1) Precursory\ncapabilities should be shared as soon as they become known through internal\nevaluations before deployment. (2) AI Safety Institutes (AISIs) should be the\ntrusted actors appointed to receive and coordinate information on precursory\ncomponents. (3) AISIs should establish adequate information protection\ninfrastructure and guarantee increased information security as precursory\ncapabilities move through the zones and towards red lines, including, if\nnecessary, by classifying the information on precursory capabilities or marking\nit as controlled. (4) High-impact capability progress in one geographical\nregion may translate to risk in other regions and necessitates more\ncomprehensive risk assessment internationally. As such, AISIs should exchange\ninformation on precursory capabilities with other AISIs, relying on the\nexisting frameworks on international classified exchanges and applying lessons\nlearned from other regulated high-risk sectors.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02512v2",
    "published_date": "2024-11-18 11:25:28 UTC",
    "updated_date": "2024-12-13 13:38:42 UTC"
  },
  {
    "arxiv_id": "2412.03579v1",
    "title": "Towards a Practical Ethics of Generative AI in Creative Production Processes",
    "authors": [
      "Geert Hofman"
    ],
    "abstract": "The increasing integration of artificial intelligence into various domains,\nincluding design and creative processes, raises significant ethical questions.\nWhile AI ethics is often examined from the perspective of technology\ndevelopers, less attention has been paid to the practical ethical\nconsiderations faced by technology users, particularly in design contexts. This\npaper introduces a framework for addressing ethical challenges in creative\nproduction processes, such as the Double Diamond design model. Drawing on six\nmajor ethical theories - virtue ethics, deontology, utilitarianism, contract\ntheory, care ethics, and existentialism - we develop a \"compass\" to navigate\nand reflect on the ethical dimensions of AI in design. The framework highlights\nthe importance of responsibility, anticipation, and reflection across both the\nAI lifecycle and each stage of the creative process. We argue that by adopting\na playful and exploratory approach to AI, while remaining anchored in core\nethical principles, designers can responsibly harness the potential of AI\ntechnologies without overburdening or compromising their creative processes.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.03579v1",
    "published_date": "2024-11-18 11:07:26 UTC",
    "updated_date": "2024-11-18 11:07:26 UTC"
  },
  {
    "arxiv_id": "2411.11458v2",
    "title": "HistoEncoder: a digital pathology foundation model for prostate cancer",
    "authors": [
      "Joona Pohjonen",
      "Abderrahim-Oussama Batouche",
      "Antti Rannikko",
      "Kevin Sandeman",
      "Andrew Erickson",
      "Esa Pitkanen",
      "Tuomas Mirtti"
    ],
    "abstract": "Foundation models are trained on massive amounts of data to distinguish\ncomplex patterns and can be adapted to a wide range of downstream tasks with\nminimal computational resources. Here, we develop a foundation model for\nprostate cancer digital pathology called HistoEncoder by pre-training on 48\nmillion prostate tissue tile images. We demonstrate that HistoEncoder features\nextracted from tile images with similar histological patterns map closely\ntogether in the feature space. HistoEncoder outperforms models pre-trained with\nnatural images, even without fine-tuning or with 1000 times less training data.\nWe describe two use cases that leverage the capabilities of HistoEncoder by\nfine-tuning the model with a limited amount of data and computational\nresources. First, we show how HistoEncoder can be used to automatically\nannotate large-scale datasets with high accuracy. Second, we combine histomics\nwith commonly used clinical nomograms, significantly improving prostate\ncancer-specific death survival models. Foundation models such as HistoEncoder\ncan allow organizations with limited resources to build effective clinical\nsoftware tools without needing extensive datasets or significant amounts of\ncomputing.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11458v2",
    "published_date": "2024-11-18 10:46:05 UTC",
    "updated_date": "2024-11-22 13:32:01 UTC"
  },
  {
    "arxiv_id": "2411.11451v2",
    "title": "Robust Markov Decision Processes: A Place Where AI and Formal Methods Meet",
    "authors": [
      "Marnix Suilen",
      "Thom Badings",
      "Eline M. Bovy",
      "David Parker",
      "Nils Jansen"
    ],
    "abstract": "Markov decision processes (MDPs) are a standard model for sequential\ndecision-making problems and are widely used across many scientific areas,\nincluding formal methods and artificial intelligence (AI). MDPs do, however,\ncome with the restrictive assumption that the transition probabilities need to\nbe precisely known. Robust MDPs (RMDPs) overcome this assumption by instead\ndefining the transition probabilities to belong to some uncertainty set. We\npresent a gentle survey on RMDPs, providing a tutorial covering their\nfundamentals. In particular, we discuss RMDP semantics and how to solve them by\nextending standard MDP methods such as value iteration and policy iteration. We\nalso discuss how RMDPs relate to other models and how they are used in several\ncontexts, including reinforcement learning and abstraction techniques. We\nconclude with some challenges for future work on RMDPs.",
    "categories": [
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11451v2",
    "published_date": "2024-11-18 10:34:14 UTC",
    "updated_date": "2024-12-10 09:59:27 UTC"
  },
  {
    "arxiv_id": "2411.11448v1",
    "title": "Unveiling the Inflexibility of Adaptive Embedding in Traffic Forecasting",
    "authors": [
      "Hongjun Wang",
      "Jiyuan Chen",
      "Lingyu Zhang",
      "Renhe Jiang",
      "Xuan Song"
    ],
    "abstract": "Spatiotemporal Graph Neural Networks (ST-GNNs) and Transformers have shown\nsignificant promise in traffic forecasting by effectively modeling temporal and\nspatial correlations. However, rapid urbanization in recent years has led to\ndynamic shifts in traffic patterns and travel demand, posing major challenges\nfor accurate long-term traffic prediction. The generalization capability of\nST-GNNs in extended temporal scenarios and cross-city applications remains\nlargely unexplored. In this study, we evaluate state-of-the-art models on an\nextended traffic benchmark and observe substantial performance degradation in\nexisting ST-GNNs over time, which we attribute to their limited inductive\ncapabilities. Our analysis reveals that this degradation stems from an\ninability to adapt to evolving spatial relationships within urban environments.\nTo address this limitation, we reconsider the design of adaptive embeddings and\npropose a Principal Component Analysis (PCA) embedding approach that enables\nmodels to adapt to new scenarios without retraining. We incorporate PCA\nembeddings into existing ST-GNN and Transformer architectures, achieving marked\nimprovements in performance. Notably, PCA embeddings allow for flexibility in\ngraph structures between training and testing, enabling models trained on one\ncity to perform zero-shot predictions on other cities. This adaptability\ndemonstrates the potential of PCA embeddings in enhancing the robustness and\ngeneralization of spatiotemporal models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11448v1",
    "published_date": "2024-11-18 10:30:34 UTC",
    "updated_date": "2024-11-18 10:30:34 UTC"
  },
  {
    "arxiv_id": "2411.11436v1",
    "title": "Implicit Regularization for Multi-label Feature Selection",
    "authors": [
      "Dou El Kefel Mansouri",
      "Khalid Benabdeslem",
      "Seif-Eddine Benkabou"
    ],
    "abstract": "In this paper, we address the problem of feature selection in the context of\nmulti-label learning, by using a new estimator based on implicit regularization\nand label embedding. Unlike the sparse feature selection methods that use a\npenalized estimator with explicit regularization terms such as $l_{2,1}$-norm,\nMCP or SCAD, we propose a simple alternative method via Hadamard product\nparameterization. In order to guide the feature selection process, a latent\nsemantic of multi-label information method is adopted, as a label embedding.\nExperimental results on some known benchmark datasets suggest that the proposed\nestimator suffers much less from extra bias, and may lead to benign\noverfitting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 7 figures, My paper is currently under review at TPAMI\n  journal",
    "pdf_url": "http://arxiv.org/pdf/2411.11436v1",
    "published_date": "2024-11-18 10:08:05 UTC",
    "updated_date": "2024-11-18 10:08:05 UTC"
  },
  {
    "arxiv_id": "2411.13592v1",
    "title": "A Novel Speech Analysis and Correction Tool for Arabic-Speaking Children",
    "authors": [
      "Lamia Berriche",
      "Maha Driss",
      "Areej Ahmed Almuntashri",
      "Asma Mufreh Lghabi",
      "Heba Saleh Almudhi",
      "Munerah Abdul-Aziz Almansour"
    ],
    "abstract": "This paper introduces a new application named ArPA for Arabic kids who have\ntrouble with pronunciation. Our application comprises two key components: the\ndiagnostic module and the therapeutic module. The diagnostic process involves\ncapturing the child's speech signal, preprocessing, and analyzing it using\ndifferent machine learning classifiers like K-Nearest Neighbors (KNN), Support\nVector Machine (SVM), and Decision Trees as well as deep neural network\nclassifiers like ResNet18. The therapeutic module offers eye-catching gamified\ninterfaces in which each correctly spoken letter earns a higher avatar level,\nproviding positive reinforcement for the child's pronunciation improvement. Two\ndatasets were used for experimental evaluation: one from a childcare centre and\nthe other including Arabic alphabet pronunciation recordings. Our work uses a\nnovel technique for speech recognition using Melspectrogram and MFCC images.\nThe results show that the ResNet18 classifier on speech-to-image converted data\neffectively identifies mispronunciations in Arabic speech with an accuracy of\n99.015\\% with Mel-Spectrogram images outperforming ResNet18 with MFCC images.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13592v1",
    "published_date": "2024-11-18 09:43:40 UTC",
    "updated_date": "2024-11-18 09:43:40 UTC"
  },
  {
    "arxiv_id": "2411.11409v1",
    "title": "IKEA Manuals at Work: 4D Grounding of Assembly Instructions on Internet Videos",
    "authors": [
      "Yunong Liu",
      "Cristobal Eyzaguirre",
      "Manling Li",
      "Shubh Khanna",
      "Juan Carlos Niebles",
      "Vineeth Ravi",
      "Saumitra Mishra",
      "Weiyu Liu",
      "Jiajun Wu"
    ],
    "abstract": "Shape assembly is a ubiquitous task in daily life, integral for constructing\ncomplex 3D structures like IKEA furniture. While significant progress has been\nmade in developing autonomous agents for shape assembly, existing datasets have\nnot yet tackled the 4D grounding of assembly instructions in videos, essential\nfor a holistic understanding of assembly in 3D space over time. We introduce\nIKEA Video Manuals, a dataset that features 3D models of furniture parts,\ninstructional manuals, assembly videos from the Internet, and most importantly,\nannotations of dense spatio-temporal alignments between these data modalities.\nTo demonstrate the utility of IKEA Video Manuals, we present five applications\nessential for shape assembly: assembly plan generation, part-conditioned\nsegmentation, part-conditioned pose estimation, video object segmentation, and\nfurniture assembly based on instructional video manuals. For each application,\nwe provide evaluation metrics and baseline methods. Through experiments on our\nannotated data, we highlight many challenges in grounding assembly instructions\nin videos to improve shape assembly, including handling occlusions, varying\nviewpoints, and extended assembly sequences.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024 Datasets and Benchmarks Track",
    "pdf_url": "http://arxiv.org/pdf/2411.11409v1",
    "published_date": "2024-11-18 09:30:05 UTC",
    "updated_date": "2024-11-18 09:30:05 UTC"
  },
  {
    "arxiv_id": "2411.11391v1",
    "title": "The GECo algorithm for Graph Neural Networks Explanation",
    "authors": [
      "Salvatore Calderaro",
      "Domenico Amato",
      "Giosuè Lo Bosco",
      "Riccardo Rizzo",
      "Filippo Vella"
    ],
    "abstract": "Graph Neural Networks (GNNs) are powerful models that can manage complex data\nsources and their interconnection links. One of GNNs' main drawbacks is their\nlack of interpretability, which limits their application in sensitive fields.\nIn this paper, we introduce a new methodology involving graph communities to\naddress the interpretability of graph classification problems. The proposed\nmethod, called GECo, exploits the idea that if a community is a subset of graph\nnodes densely connected, this property should play a role in graph\nclassification. This is reasonable, especially if we consider the\nmessage-passing mechanism, which is the basic mechanism of GNNs. GECo analyzes\nthe contribution to the classification result of the communities in the graph,\nbuilding a mask that highlights graph-relevant structures. GECo is tested for\nGraph Convolutional Networks on six artificial and four real-world graph\ndatasets and is compared to the main explainability methods such as\nPGMExplainer, PGExplainer, GNNExplainer, and SubgraphX using four different\nmetrics. The obtained results outperform the other methods for artificial graph\ndatasets and most real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11391v1",
    "published_date": "2024-11-18 09:08:30 UTC",
    "updated_date": "2024-11-18 09:08:30 UTC"
  },
  {
    "arxiv_id": "2411.11364v1",
    "title": "Continual Task Learning through Adaptive Policy Self-Composition",
    "authors": [
      "Shengchao Hu",
      "Yuhang Zhou",
      "Ziqing Fan",
      "Jifeng Hu",
      "Li Shen",
      "Ya Zhang",
      "Dacheng Tao"
    ],
    "abstract": "Training a generalizable agent to continually learn a sequence of tasks from\noffline trajectories is a natural requirement for long-lived agents, yet\nremains a significant challenge for current offline reinforcement learning (RL)\nalgorithms. Specifically, an agent must be able to rapidly adapt to new tasks\nusing newly collected trajectories (plasticity), while retaining knowledge from\npreviously learned tasks (stability). However, systematic analyses of this\nsetting are scarce, and it remains unclear whether conventional continual\nlearning (CL) methods are effective in continual offline RL (CORL) scenarios.\nIn this study, we develop the Offline Continual World benchmark and demonstrate\nthat traditional CL methods struggle with catastrophic forgetting, primarily\ndue to the unique distribution shifts inherent to CORL scenarios. To address\nthis challenge, we introduce CompoFormer, a structure-based continual\ntransformer model that adaptively composes previous policies via a meta-policy\nnetwork. Upon encountering a new task, CompoFormer leverages semantic\ncorrelations to selectively integrate relevant prior policies alongside newly\ntrained parameters, thereby enhancing knowledge sharing and accelerating the\nlearning process. Our experiments reveal that CompoFormer outperforms\nconventional CL methods, particularly in longer task sequences, showcasing a\npromising balance between plasticity and stability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.11364v1",
    "published_date": "2024-11-18 08:20:21 UTC",
    "updated_date": "2024-11-18 08:20:21 UTC"
  },
  {
    "arxiv_id": "2411.12584v1",
    "title": "Leveraging MLLM Embeddings and Attribute Smoothing for Compositional Zero-Shot Learning",
    "authors": [
      "Xudong Yan",
      "Songhe Feng",
      "Yang Zhang",
      "Jian Yang",
      "Yueguan Lin",
      "Haojun Fei"
    ],
    "abstract": "Compositional zero-shot learning (CZSL) aims to recognize novel compositions\nof attributes and objects learned from seen compositions. Previous works\ndisentangle attribute and object by extracting shared and exclusive parts\nbetween image pairs sharing the same attribute (object), as well as aligning\nthem with pretrained word embeddings to improve unseen attribute-object\nrecognition. Despite the significant achievements of existing efforts, they are\nhampered by three limitations: (1) the efficacy of disentanglement is\ncompromised due to the influence of the background and the intricate\nentanglement of attribute with object in the same parts. (2) existing word\nembeddings fail to capture complex multimodal semantic information. (3)\noverconfidence exhibited by existing models in seen compositions hinders their\ngeneralization to novel compositions. Being aware of these, we propose a novel\nframework named Multimodal Large Language Model (MLLM) embeddings and attribute\nsmoothing guided disentanglement (TRIDENT) for CZSL. First, we leverage feature\nadaptive aggregation modules to mitigate the impact of background, and utilize\nlearnable condition masks to capture multigranularity features for\ndisentanglement. Then, the last hidden states of MLLM are employed as word\nembeddings for their superior representation capabilities. Moreover, we propose\nattribute smoothing with auxiliary attributes generated by Large Language Model\n(LLM) for seen compositions, addressing the issue of overconfidence by\nencouraging the model to learn more attributes in one given composition.\nExtensive experiments demonstrate that TRIDENT achieves state-of-the-art\nperformance on three benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.12584v1",
    "published_date": "2024-11-18 07:55:54 UTC",
    "updated_date": "2024-11-18 07:55:54 UTC"
  },
  {
    "arxiv_id": "2411.12768v1",
    "title": "CROW: Eliminating Backdoors from Large Language Models via Internal Consistency Regularization",
    "authors": [
      "Nay Myat Min",
      "Long H. Pham",
      "Yige Li",
      "Jun Sun"
    ],
    "abstract": "Recent studies reveal that Large Language Models (LLMs) are susceptible to\nbackdoor attacks, where adversaries embed hidden triggers that manipulate model\nresponses. Existing backdoor defense methods are primarily designed for vision\nor classification tasks, and are thus ineffective for text generation tasks,\nleaving LLMs vulnerable. We introduce Internal Consistency Regularization\n(CROW), a novel defense using consistency regularization finetuning to address\nlayer-wise inconsistencies caused by backdoor triggers. CROW leverages the\nintuition that clean models exhibit smooth, consistent transitions in hidden\nrepresentations across layers, whereas backdoored models show noticeable\nfluctuation when triggered. By enforcing internal consistency through\nadversarial perturbations and regularization, CROW neutralizes backdoor effects\nwithout requiring clean reference models or prior trigger knowledge, relying\nonly on a small set of clean data. This makes it practical for deployment\nacross various LLM architectures. Experimental results demonstrate that CROW\nconsistently achieves a significant reductions in attack success rates across\ndiverse backdoor strategies and tasks, including negative sentiment, targeted\nrefusal, and code injection, on models such as Llama-2 (7B, 13B), CodeLlama\n(7B, 13B) and Mistral-7B, while preserving the model's generative capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.12768v1",
    "published_date": "2024-11-18 07:52:12 UTC",
    "updated_date": "2024-11-18 07:52:12 UTC"
  },
  {
    "arxiv_id": "2411.11354v1",
    "title": "A comprehensive survey of oracle character recognition: challenges, benchmarks, and beyond",
    "authors": [
      "Jing Li",
      "Xueke Chi",
      "Qiufeng Wang",
      "Dahan Wang",
      "Kaizhu Huang",
      "Yongge Liu",
      "Cheng-lin Liu"
    ],
    "abstract": "Oracle character recognition-an analysis of ancient Chinese inscriptions\nfound on oracle bones-has become a pivotal field intersecting archaeology,\npaleography, and historical cultural studies. Traditional methods of oracle\ncharacter recognition have relied heavily on manual interpretation by experts,\nwhich is not only labor-intensive but also limits broader accessibility to the\ngeneral public. With recent breakthroughs in pattern recognition and deep\nlearning, there is a growing movement towards the automation of oracle\ncharacter recognition (OrCR), showing considerable promise in tackling the\nchallenges inherent to these ancient scripts. However, a comprehensive\nunderstanding of OrCR still remains elusive. Therefore, this paper presents a\nsystematic and structured survey of the current landscape of OrCR research. We\ncommence by identifying and analyzing the key challenges of OrCR. Then, we\nprovide an overview of the primary benchmark datasets and digital resources\navailable for OrCR. A review of contemporary research methodologies follows, in\nwhich their respective efficacies, limitations, and applicability to the\ncomplex nature of oracle characters are critically highlighted and examined.\nAdditionally, our review extends to ancillary tasks associated with OrCR across\ndiverse disciplines, providing a broad-spectrum analysis of its applications.\nWe conclude with a forward-looking perspective, proposing potential avenues for\nfuture investigations that could yield significant advancements in the field.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11354v1",
    "published_date": "2024-11-18 07:50:22 UTC",
    "updated_date": "2024-11-18 07:50:22 UTC"
  },
  {
    "arxiv_id": "2411.11344v3",
    "title": "Mitigating Knowledge Conflicts in Language Model-Driven Question Answering",
    "authors": [
      "Han Cao",
      "Zhaoyang Zhang",
      "Xiangtian Li",
      "Chufan Wu",
      "Hansong Zhang",
      "Wenqing Zhang"
    ],
    "abstract": "In the context of knowledge-driven seq-to-seq generation tasks, such as\ndocument-based question answering and document summarization systems, two\nfundamental knowledge sources play crucial roles: the inherent knowledge\nembedded within model parameters and the external knowledge obtained through\ncontext. Recent studies revealed a significant challenge: when there exists a\nmisalignment between the model's inherent knowledge and the ground truth\nanswers in training data, the system may exhibit problematic behaviors during\ninference, such as ignoring input context, or generating unfaithful content.\nOur investigation proposes a strategy to minimize hallucination by building\nexplicit connection between source inputs and generated outputs. We\nspecifically target a common hallucination pattern in question answering,\nexamining how the correspondence between entities and their contexts during\nmodel training influences the system's performance at inference time.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "revised version, more figures",
    "pdf_url": "http://arxiv.org/pdf/2411.11344v3",
    "published_date": "2024-11-18 07:33:10 UTC",
    "updated_date": "2025-01-15 07:46:15 UTC"
  },
  {
    "arxiv_id": "2412.03578v1",
    "title": "PerfCodeGen: Improving Performance of LLM Generated Code with Execution Feedback",
    "authors": [
      "Yun Peng",
      "Akhilesh Deepak Gotmare",
      "Michael Lyu",
      "Caiming Xiong",
      "Silvio Savarese",
      "Doyen Sahoo"
    ],
    "abstract": "Large Language Models (LLMs) are widely adopted for assisting in software\ndevelopment tasks, yet their performance evaluations have narrowly focused on\nthe functional correctness of generated code. Human programmers, however,\nrequire LLM-generated code to be not only correct but also optimally efficient.\nWe propose PerfCodeGen, a training-free framework that enhances the performance\nof LLM-generated code by incorporating feedback based on runtime during test\ncase execution into the self-refinement iterations. With PerfCodeGen, we\nachieve speedups for a significantly higher proportion of problems compared to\nusing the base LLM with sophisticated prompting techniques. Applied to open\nlanguage models like Phi-3-mini, PerfCodeGen achieves runtime efficiency\ncomparable to prompting powerful closed models like GPT-4. We achieve\nstate-of-the-art runtime efficiency on benchmarks such as HumanEval, MBPP, and\nAPPS, frequently surpassing the ground truth reference solutions with\nPerfCodeGen using GPT-3.5 and GPT-4. Additionally, we demonstrate the\neffectiveness of our approach in enhancing code quality across a range of open\nLLMs of varying sizes including Phi-3-mini, Llama 3 8B, Mixtral 8x7B, Command\nR, and Llama 3 70B.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03578v1",
    "published_date": "2024-11-18 06:22:38 UTC",
    "updated_date": "2024-11-18 06:22:38 UTC"
  },
  {
    "arxiv_id": "2411.11318v1",
    "title": "Syllabus: Portable Curricula for Reinforcement Learning Agents",
    "authors": [
      "Ryan Sullivan",
      "Ryan Pégoud",
      "Ameen Ur Rahmen",
      "Xinchen Yang",
      "Junyun Huang",
      "Aayush Verma",
      "Nistha Mitra",
      "John P. Dickerson"
    ],
    "abstract": "Curriculum learning has been a quiet yet crucial component of many of the\nhigh-profile successes of reinforcement learning. Despite this, none of the\nmajor reinforcement learning libraries directly support curriculum learning or\ninclude curriculum learning implementations. These methods can improve the\ncapabilities and robustness of RL agents, but often require significant,\ncomplex changes to agent training code. We introduce Syllabus, a library for\ntraining RL agents with curriculum learning, as a solution to this problem.\nSyllabus provides a universal API for curriculum learning algorithms,\nimplementations of popular curriculum learning methods, and infrastructure for\neasily integrating them with distributed training code written in nearly any RL\nlibrary. Syllabus provides a minimal API for each of the core components of\ncurriculum learning, dramatically simplifying the process of designing new\nalgorithms and applying existing algorithms to new environments. We demonstrate\nthat the same Syllabus code can be used to train agents written in multiple\ndifferent RL libraries on numerous domains. In doing so, we present the first\nexamples of curriculum learning in NetHack and Neural MMO, two of the premier\nchallenges for single-agent and multi-agent RL respectively, achieving strong\nresults compared to state of the art baselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2411.11318v1",
    "published_date": "2024-11-18 06:22:30 UTC",
    "updated_date": "2024-11-18 06:22:30 UTC"
  },
  {
    "arxiv_id": "2411.11312v1",
    "title": "Study of the Performance of CEEMDAN in Underdetermined Speech Separation",
    "authors": [
      "Rawad Melhem",
      "Riad Hamadeh",
      "Assef Jafar"
    ],
    "abstract": "The CEEMDAN algorithm is one of the modern methods used in the analysis of\nnon-stationary signals. This research presents a study of the effectiveness of\nthis method in audio source separation to know the limits of its work. It\nconcluded two conditions related to frequencies and amplitudes of mixed signals\nto be separated by CEEMDAN. The performance of the algorithm in separating\nnoise from speech and separating speech signals from each other is studied. The\nresearch reached a conclusion that CEEMDAN can remove some types of noise from\nspeech (speech improvement), and it cannot separate speech signals from each\nother (cocktail party). Simulation is done using Matlab environment and Noizeus\ndatabase.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "in Arabic language",
    "pdf_url": "http://arxiv.org/pdf/2411.11312v1",
    "published_date": "2024-11-18 06:13:51 UTC",
    "updated_date": "2024-11-18 06:13:51 UTC"
  },
  {
    "arxiv_id": "2411.11305v2",
    "title": "TP-UNet: Temporal Prompt Guided UNet for Medical Image Segmentation",
    "authors": [
      "Ranmin Wang",
      "Limin Zhuang",
      "Hongkun Chen",
      "Boyan Xu",
      "Ruichu Cai"
    ],
    "abstract": "The advancement of medical image segmentation techniques has been propelled\nby the adoption of deep learning techniques, particularly UNet-based\napproaches, which exploit semantic information to improve the accuracy of\nsegmentations. However, the order of organs in scanned images has been\ndisregarded by current medical image segmentation approaches based on UNet.\nFurthermore, the inherent network structure of UNet does not provide direct\ncapabilities for integrating temporal information. To efficiently integrate\ntemporal information, we propose TP-UNet that utilizes temporal prompts,\nencompassing organ-construction relationships, to guide the segmentation UNet\nmodel. Specifically, our framework is featured with cross-attention and\nsemantic alignment based on unsupervised contrastive learning to combine\ntemporal prompts and image features effectively. Extensive evaluations on two\nmedical image segmentation datasets demonstrate the state-of-the-art\nperformance of TP-UNet. Our implementation will be open-sourced after\nacceptance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11305v2",
    "published_date": "2024-11-18 06:01:00 UTC",
    "updated_date": "2024-11-20 02:24:26 UTC"
  },
  {
    "arxiv_id": "2411.11303v1",
    "title": "Recurrent Stochastic Configuration Networks with Incremental Blocks",
    "authors": [
      "Gang Dang",
      "Dainhui Wang"
    ],
    "abstract": "Recurrent stochastic configuration networks (RSCNs) have shown promise in\nmodelling nonlinear dynamic systems with order uncertainty due to their\nadvantages of easy implementation, less human intervention, and strong\napproximation capability. This paper develops the original RSCNs with block\nincrements, termed block RSCNs (BRSCNs), to further enhance the learning\ncapacity and efficiency of the network. BRSCNs can simultaneously add multiple\nreservoir nodes (subreservoirs) during the construction. Each subreservoir is\nconfigured with a unique structure in the light of a supervisory mechanism,\nensuring the universal approximation property. The reservoir feedback matrix is\nappropriately scaled to guarantee the echo state property of the network.\nFurthermore, the output weights are updated online using a projection\nalgorithm, and the persistent excitation conditions that facilitate parameter\nconvergence are also established. Numerical results over a time series\nprediction, a nonlinear system identification task, and two industrial data\npredictive analyses demonstrate that the proposed BRSCN performs favourably in\nterms of modelling efficiency, learning, and generalization performance,\nhighlighting their significant potential for coping with complex dynamics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11303v1",
    "published_date": "2024-11-18 05:58:47 UTC",
    "updated_date": "2024-11-18 05:58:47 UTC"
  },
  {
    "arxiv_id": "2411.11302v1",
    "title": "Towards Personalized Brain-Computer Interface Application Based on Endogenous EEG Paradigms",
    "authors": [
      "Heon-Gyu Kwak",
      "Gi-Hwan Shin",
      "Yeon-Woo Choi",
      "Dong-Hoon Lee",
      "Yoo-In Jeon",
      "Jun-Su Kang",
      "Seong-Whan Lee"
    ],
    "abstract": "In this paper, we propose a conceptual framework for personalized\nbrain-computer interface (BCI) applications, which can offer an enhanced user\nexperience by customizing services to individual preferences and needs, based\non endogenous electroencephalography (EEG) paradigms including motor imagery\n(MI), speech imagery (SI), and visual imagery. The framework includes two\nessential components: user identification and intention classification, which\nenable personalized services by identifying individual users and recognizing\ntheir intended actions through EEG signals. We validate the feasibility of our\nframework using a private EEG dataset collected from eight subjects, employing\nthe ShallowConvNet architecture to decode EEG features. The experimental\nresults demonstrate that user identification achieved an average classification\naccuracy of 0.995, while intention classification achieved 0.47 accuracy across\nall paradigms, with MI demonstrating the best performance. These findings\nindicate that EEG signals can effectively support personalized BCI\napplications, offering robust identification and reliable intention decoding,\nespecially for MI and SI.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Submissoion version for IEEE International BCI Winter Conference 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.11302v1",
    "published_date": "2024-11-18 05:58:41 UTC",
    "updated_date": "2024-11-18 05:58:41 UTC"
  },
  {
    "arxiv_id": "2411.13591v5",
    "title": "Improved GUI Grounding via Iterative Narrowing",
    "authors": [
      "Anthony Nguyen"
    ],
    "abstract": "Graphical User Interface (GUI) grounding plays a crucial role in enhancing\nthe capabilities of Vision-Language Model (VLM) agents. While general VLMs,\nsuch as GPT-4V, demonstrate strong performance across various tasks, their\nproficiency in GUI grounding remains suboptimal. Recent studies have focused on\nfine-tuning these models specifically for zero-shot GUI grounding, yielding\nsignificant improvements over baseline performance. We introduce a visual\nprompting framework that employs an iterative narrowing mechanism to further\nimprove the performance of both general and fine-tuned models in GUI grounding.\nFor evaluation, we tested our method on a comprehensive benchmark comprising\nvarious UI platforms and provided the code to reproduce our results.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Code available at\n  https://github.com/ant-8/GUI-Grounding-via-Iterative-Narrowing",
    "pdf_url": "http://arxiv.org/pdf/2411.13591v5",
    "published_date": "2024-11-18 05:47:12 UTC",
    "updated_date": "2024-12-20 07:16:32 UTC"
  },
  {
    "arxiv_id": "2411.11295v1",
    "title": "Transcending Language Boundaries: Harnessing LLMs for Low-Resource Language Translation",
    "authors": [
      "Peng Shu",
      "Junhao Chen",
      "Zhengliang Liu",
      "Hui Wang",
      "Zihao Wu",
      "Tianyang Zhong",
      "Yiwei Li",
      "Huaqin Zhao",
      "Hanqi Jiang",
      "Yi Pan",
      "Yifan Zhou",
      "Constance Owl",
      "Xiaoming Zhai",
      "Ninghao Liu",
      "Claudio Saunt",
      "Tianming Liu"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable success across a\nwide range of tasks and domains. However, their performance in low-resource\nlanguage translation, particularly when translating into these languages,\nremains underexplored. This gap poses significant challenges, as linguistic\nbarriers hinder the cultural preservation and development of minority\ncommunities. To address this issue, this paper introduces a novel\nretrieval-based method that enhances translation quality for low-resource\nlanguages by focusing on key terms, which involves translating keywords and\nretrieving corresponding examples from existing data. To evaluate the\neffectiveness of this method, we conducted experiments translating from English\ninto three low-resource languages: Cherokee, a critically endangered indigenous\nlanguage of North America; Tibetan, a historically and culturally significant\nlanguage in Asia; and Manchu, a language with few remaining speakers. Our\ncomparison with the zero-shot performance of GPT-4o and LLaMA 3.1 405B,\nhighlights the significant challenges these models face when translating into\nlow-resource languages. In contrast, our retrieval-based method shows promise\nin improving both word-level accuracy and overall semantic understanding by\nleveraging existing resources more effectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11295v1",
    "published_date": "2024-11-18 05:41:27 UTC",
    "updated_date": "2024-11-18 05:41:27 UTC"
  },
  {
    "arxiv_id": "2411.13590v1",
    "title": "Deep learning waterways for rural infrastructure development",
    "authors": [
      "Matthew Pierson",
      "Zia Mehrabi"
    ],
    "abstract": "Surprisingly a number of Earth's waterways remain unmapped, with a\nsignificant number in low and middle income countries. Here we build a computer\nvision model (WaterNet) to learn the location of waterways in the United\nStates, based on high resolution satellite imagery and digital elevation\nmodels, and then deploy this in novel environments in the African continent.\nOur outputs provide detail of waterways structures hereto unmapped. When\nassessed against community needs requests for rural bridge building related to\naccess to schools, health care facilities and agricultural markets, we find\nthese newly generated waterways capture on average 93% (country range: 88-96%)\nof these requests whereas Open Street Map, and the state of the art data from\nTDX-Hydro, capture only 36% (5-72%) and 62% (37%-85%), respectively. Because\nthese new machine learning enabled maps are built on public and operational\ndata acquisition this approach offers promise for capturing humanitarian needs\nand planning for social development in places where cartographic efforts have\nso far failed to deliver. The improved performance in identifying community\nneeds missed by existing data suggests significant value for rural\ninfrastructure development and better targeting of development interventions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "68",
      "D.0"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.13590v1",
    "published_date": "2024-11-18 05:36:05 UTC",
    "updated_date": "2024-11-18 05:36:05 UTC"
  },
  {
    "arxiv_id": "2411.11289v1",
    "title": "LP Data Pipeline: Lightweight, Purpose-driven Data Pipeline for Large Language Models",
    "authors": [
      "Yungi Kim",
      "Hyunsoo Ha",
      "Seonghoon Yang",
      "Sukyung Lee",
      "Jihoo Kim",
      "Chanjun Park"
    ],
    "abstract": "Creating high-quality, large-scale datasets for large language models (LLMs)\noften relies on resource-intensive, GPU-accelerated models for quality\nfiltering, making the process time-consuming and costly. This dependence on\nGPUs limits accessibility for organizations lacking significant computational\ninfrastructure. To address this issue, we introduce the Lightweight,\nPurpose-driven (LP) Data Pipeline, a framework that operates entirely on CPUs\nto streamline the processes of dataset extraction, filtering, and curation.\nBased on our four core principles, the LP Data Pipeline significantly reduces\npreparation time and cost while maintaining high data quality. Importantly, our\npipeline enables the creation of purpose-driven datasets tailored to specific\ndomains and languages, enhancing the applicability of LLMs in specialized\ncontexts. We anticipate that our pipeline will lower the barriers to LLM\ndevelopment, enabling a wide range of organizations to access LLMs more easily.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11289v1",
    "published_date": "2024-11-18 05:17:27 UTC",
    "updated_date": "2024-11-18 05:17:27 UTC"
  },
  {
    "arxiv_id": "2411.11285v2",
    "title": "Zero-Shot Automatic Annotation and Instance Segmentation using LLM-Generated Datasets: Eliminating Field Imaging and Manual Annotation for Deep Learning Model Development",
    "authors": [
      "Ranjan Sapkota",
      "Achyut Paudel",
      "Manoj Karkee"
    ],
    "abstract": "Currently, deep learning-based instance segmentation for various applications\n(e.g., Agriculture) is predominantly performed using a labor-intensive process\ninvolving extensive field data collection using sophisticated sensors, followed\nby careful manual annotation of images, presenting significant logistical and\nfinancial challenges to researchers and organizations. The process also slows\ndown the model development and training process. In this study, we presented a\nnovel method for deep learning-based instance segmentation of apples in\ncommercial orchards that eliminates the need for labor-intensive field data\ncollection and manual annotation. Utilizing a Large Language Model (LLM), we\nsynthetically generated orchard images and automatically annotated them using\nthe Segment Anything Model (SAM) integrated with a YOLO11 base model. This\nmethod significantly reduces reliance on physical sensors and manual data\nprocessing, presenting a major advancement in \"Agricultural AI\". The synthetic,\nauto-annotated dataset was used to train the YOLO11 model for Apple instance\nsegmentation, which was then validated on real orchard images. The results\nshowed that the automatically generated annotations achieved a Dice Coefficient\nof 0.9513 and an IoU of 0.9303, validating the accuracy and overlap of the mask\nannotations. All YOLO11 configurations, trained solely on these synthetic\ndatasets with automated annotations, accurately recognized and delineated\napples, highlighting the method's efficacy. Specifically, the YOLO11m-seg\nconfiguration achieved a mask precision of 0.902 and a mask mAP@50 of 0.833 on\ntest images collected from a commercial orchard. Additionally, the YOLO11l-seg\nconfiguration outperformed other models in validation on 40 LLM-generated\nimages, achieving the highest mask precision and mAP@50 metrics.\n  Keywords: YOLO, SAM, SAMv2, YOLO11, YOLOv11, Segment Anything, YOLO-SAM",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11285v2",
    "published_date": "2024-11-18 05:11:29 UTC",
    "updated_date": "2025-02-28 00:44:36 UTC"
  },
  {
    "arxiv_id": "2411.11283v1",
    "title": "Multi-Hyperbolic Space-based Heterogeneous Graph Attention Network",
    "authors": [
      "Jongmin Park",
      "Seunghoon Han",
      "Jong-Ryul Lee",
      "Sungsu Lim"
    ],
    "abstract": "To leverage the complex structures within heterogeneous graphs, recent\nstudies on heterogeneous graph embedding use a hyperbolic space, characterized\nby a constant negative curvature and exponentially increasing space, which\naligns with the structural properties of heterogeneous graphs. However, despite\nheterogeneous graphs inherently possessing diverse power-law structures, most\nhyperbolic heterogeneous graph embedding models use a single hyperbolic space\nfor the entire heterogeneous graph, which may not effectively capture the\ndiverse power-law structures within the heterogeneous graph. To address this\nlimitation, we propose Multi-hyperbolic Space-based heterogeneous Graph\nAttention Network (MSGAT), which uses multiple hyperbolic spaces to effectively\ncapture diverse power-law structures within heterogeneous graphs. We conduct\ncomprehensive experiments to evaluate the effectiveness of MSGAT. The\nexperimental results demonstrate that MSGAT outperforms state-of-the-art\nbaselines in various graph machine learning tasks, effectively capturing the\ncomplex structures of heterogeneous graphs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in IEEE ICDM 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.11283v1",
    "published_date": "2024-11-18 04:55:26 UTC",
    "updated_date": "2024-11-18 04:55:26 UTC"
  },
  {
    "arxiv_id": "2411.11282v2",
    "title": "Continuous K-space Recovery Network with Image Guidance for Fast MRI Reconstruction",
    "authors": [
      "Yucong Meng",
      "Zhiwei Yang",
      "Minghong Duan",
      "Yonghong Shi",
      "Zhijian Song"
    ],
    "abstract": "Magnetic resonance imaging (MRI) is a crucial tool for clinical diagnosis\nwhile facing the challenge of long scanning time. To reduce the acquisition\ntime, fast MRI reconstruction aims to restore high-quality images from the\nundersampled k-space. Existing methods typically train deep learning models to\nmap the undersampled data to artifact-free MRI images. However, these studies\noften overlook the unique properties of k-space and directly apply general\nnetworks designed for image processing to k-space recovery, leaving the precise\nlearning of k-space largely underexplored. In this work, we propose a\ncontinuous k-space recovery network from a new perspective of implicit neural\nrepresentation with image domain guidance, which boosts the performance of MRI\nreconstruction. Specifically, (1) an implicit neural representation based\nencoder-decoder structure is customized to continuously query unsampled\nk-values. (2) an image guidance module is designed to mine the semantic\ninformation from the low-quality MRI images to further guide the k-space\nrecovery. (3) a multi-stage training strategy is proposed to recover dense\nk-space progressively. Extensive experiments conducted on CC359, fastMRI, and\nIXI datasets demonstrate the effectiveness of our method and its superiority\nover other competitors.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11282v2",
    "published_date": "2024-11-18 04:54:04 UTC",
    "updated_date": "2025-03-13 12:40:10 UTC"
  },
  {
    "arxiv_id": "2411.11262v1",
    "title": "Cross-Patient Pseudo Bags Generation and Curriculum Contrastive Learning for Imbalanced Multiclassification of Whole Slide Image",
    "authors": [
      "Yonghuang Wu",
      "Xuan Xie",
      "Xinyuan Niu",
      "Chengqian Zhao",
      "Jinhua Yu"
    ],
    "abstract": "Pathology computing has dramatically improved pathologists' workflow and\ndiagnostic decision-making processes. Although computer-aided diagnostic\nsystems have shown considerable value in whole slide image (WSI) analysis, the\nproblem of multi-classification under sample imbalance remains an intractable\nchallenge. To address this, we propose learning fine-grained information by\ngenerating sub-bags with feature distributions similar to the original WSIs.\nAdditionally, we utilize a pseudo-bag generation algorithm to further leverage\nthe abundant and redundant information in WSIs, allowing efficient training in\nunbalanced-sample multi-classification tasks. Furthermore, we introduce an\naffinity-based sample selection and curriculum contrastive learning strategy to\nenhance the stability of model representation learning. Unlike previous\napproaches, our framework transitions from learning bag-level representations\nto understanding and exploiting the feature distribution of multi-instance\nbags. Our method demonstrates significant performance improvements on three\ndatasets, including tumor classification and lymph node metastasis. On average,\nit achieves a 4.39-point improvement in F1 score compared to the second-best\nmethod across the three tasks, underscoring its superior performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.11262v1",
    "published_date": "2024-11-18 03:35:34 UTC",
    "updated_date": "2024-11-18 03:35:34 UTC"
  },
  {
    "arxiv_id": "2412.01840v1",
    "title": "Zonal Architecture Development with evolution of Artificial Intelligence",
    "authors": [
      "Sneha Sudhir Shetiya",
      "Vikas Vyas",
      "Shreyas Renukuntla"
    ],
    "abstract": "This paper explains how traditional centralized architectures are\ntransitioning to distributed zonal approaches to address challenges in\nscalability, reliability, performance, and cost-effectiveness. The role of edge\ncomputing and neural networks in enabling sophisticated sensor fusion and\ndecision-making capabilities for autonomous vehicles is examined. Additionally,\nthis paper discusses the impact of zonal architectures on vehicle diagnostics,\npower distribution, and smart power management systems. Key design\nconsiderations for implementing effective zonal architectures are presented,\nalong with an overview of current challenges and future directions. The\nobjective of this paper is to provide a comprehensive understanding of how\nzonal architectures are shaping the future of automotive technology,\nparticularly in the context of self-driving vehicles and artificial\nintelligence integration.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01840v1",
    "published_date": "2024-11-18 03:15:44 UTC",
    "updated_date": "2024-11-18 03:15:44 UTC"
  },
  {
    "arxiv_id": "2411.14464v2",
    "title": "JESTR: Joint Embedding Space Technique for Ranking Candidate Molecules for the Annotation of Untargeted Metabolomics Data",
    "authors": [
      "Apurva Kalia",
      "Dilip Krishnan",
      "Soha Hassoun"
    ],
    "abstract": "Motivation: A major challenge in metabolomics is annotation: assigning\nmolecular structures to mass spectral fragmentation patterns. Despite recent\nadvances in molecule-to-spectra and in spectra-to-molecular fingerprint\nprediction (FP), annotation rates remain low. Results: We introduce in this\npaper a novel paradigm (JESTR) for annotation. Unlike prior approaches that\nexplicitly construct molecular fingerprints or spectra, JESTR leverages the\ninsight that molecules and their corresponding spectra are views of the same\ndata and effectively embeds their representations in a joint space. Candidate\nstructures are ranked based on cosine similarity between the embeddings of\nquery spectrum and each candidate. We evaluate JESTR against mol-to-spec and\nspec-to-FP annotation tools on three datasets. On average, for rank@[1-5],\nJESTR outperforms other tools by 23.6%-71.6%. We further demonstrate the strong\nvalue of regularization with candidate molecules during training, boosting\nrank@1 performance by 11.4% and enhancing the model's ability to discern\nbetween target and candidate molecules. Through JESTR, we offer a novel\npromising avenue towards accurate annotation, therefore unlocking valuable\ninsights into the metabolome.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "q-bio.QM",
    "comment": "10 pages, 10 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.14464v2",
    "published_date": "2024-11-18 03:03:57 UTC",
    "updated_date": "2024-11-25 23:01:37 UTC"
  },
  {
    "arxiv_id": "2412.03577v1",
    "title": "OKG: On-the-Fly Keyword Generation in Sponsored Search Advertising",
    "authors": [
      "Zhao Wang",
      "Briti Gangopadhyay",
      "Mengjie Zhao",
      "Shingo Takamatsu"
    ],
    "abstract": "Current keyword decision-making in sponsored search advertising relies on\nlarge, static datasets, limiting the ability to automatically set up keywords\nand adapt to real-time KPI metrics and product updates that are essential for\neffective advertising. In this paper, we propose On-the-fly Keyword Generation\n(OKG), an LLM agent-based method that dynamically monitors KPI changes and\nadapts keyword generation in real time, aligning with strategies recommended by\nadvertising platforms. Additionally, we introduce the first publicly accessible\ndataset containing real keyword data along with its KPIs across diverse\ndomains, providing a valuable resource for future research. Experimental\nresults show that OKG significantly improves keyword adaptability and\nresponsiveness compared to traditional methods. The code for OKG and the\ndataset are available at https://github.com/sony/okg.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03577v1",
    "published_date": "2024-11-18 03:02:06 UTC",
    "updated_date": "2024-11-18 03:02:06 UTC"
  },
  {
    "arxiv_id": "2412.04326v1",
    "title": "Understanding Student Sentiment on Mental Health Support in Colleges Using Large Language Models",
    "authors": [
      "Palak Sood",
      "Chengyang He",
      "Divyanshu Gupta",
      "Yue Ning",
      "Ping Wang"
    ],
    "abstract": "Mental health support in colleges is vital in educating students by offering\ncounseling services and organizing supportive events. However, evaluating its\neffectiveness faces challenges like data collection difficulties and lack of\nstandardized metrics, limiting research scope. Student feedback is crucial for\nevaluation but often relies on qualitative analysis without systematic\ninvestigation using advanced machine learning methods. This paper uses public\nStudent Voice Survey data to analyze student sentiments on mental health\nsupport with large language models (LLMs). We created a sentiment analysis\ndataset, SMILE-College, with human-machine collaboration. The investigation of\nboth traditional machine learning methods and state-of-the-art LLMs showed the\nbest performance of GPT-3.5 and BERT on this new dataset. The analysis\nhighlights challenges in accurately predicting response sentiments and offers\npractical insights on how LLMs can enhance mental health-related research and\nimprove college mental health services. This data-driven approach will\nfacilitate efficient and informed mental health support evaluation, management,\nand decision-making.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by '2024 IEEE International Conference on Big Data (IEEE\n  BigData 2024)'. The paper has 8 pages, 2 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.04326v1",
    "published_date": "2024-11-18 02:53:15 UTC",
    "updated_date": "2024-11-18 02:53:15 UTC"
  },
  {
    "arxiv_id": "2411.13588v1",
    "title": "Unveiling Redundancy in Diffusion Transformers (DiTs): A Systematic Study",
    "authors": [
      "Xibo Sun",
      "Jiarui Fang",
      "Aoyu Li",
      "Jinzhe Pan"
    ],
    "abstract": "The increased model capacity of Diffusion Transformers (DiTs) and the demand\nfor generating higher resolutions of images and videos have led to a\nsignificant rise in inference latency, impacting real-time performance\nadversely. While prior research has highlighted the presence of high similarity\nin activation values between adjacent diffusion steps (referred to as\nredundancy) and proposed various caching mechanisms to mitigate computational\noverhead, the exploration of redundancy in existing literature remains limited,\nwith findings often not generalizable across different DiT models. This study\naims to address this gap by conducting a comprehensive investigation into\nredundancy across a broad spectrum of mainstream DiT models. Our experimental\nanalysis reveals substantial variations in the distribution of redundancy\nacross diffusion steps among different DiT models. Interestingly, within a\nsingle model, the redundancy distribution remains stable regardless of\nvariations in input prompts, step counts, or scheduling strategies. Given the\nlack of a consistent pattern across diverse models, caching strategies designed\nfor a specific group of models may not easily transfer to others. To overcome\nthis challenge, we introduce a tool for analyzing the redundancy of individual\nmodels, enabling subsequent research to develop tailored caching strategies for\nspecific model architectures. The project is publicly available at\nhttps://github.com/xdit-project/DiTCacheAnalysis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages including reference",
    "pdf_url": "http://arxiv.org/pdf/2411.13588v1",
    "published_date": "2024-11-18 02:49:23 UTC",
    "updated_date": "2024-11-18 02:49:23 UTC"
  },
  {
    "arxiv_id": "2411.12767v2",
    "title": "Suicide Risk Assessment on Social Media with Semi-Supervised Learning",
    "authors": [
      "Max Lovitt",
      "Haotian Ma",
      "Song Wang",
      "Yifan Peng"
    ],
    "abstract": "With social media communities increasingly becoming places where suicidal\nindividuals post and congregate, natural language processing presents an\nexciting avenue for the development of automated suicide risk assessment\nsystems. However, past efforts suffer from a lack of labeled data and class\nimbalances within the available labeled data. To accommodate this task's\nimperfect data landscape, we propose a semi-supervised framework that leverages\nlabeled (n=500) and unlabeled (n=1,500) data and expands upon the self-training\nalgorithm with a novel pseudo-label acquisition process designed to handle\nimbalanced datasets. To further ensure pseudo-label quality, we manually verify\na subset of the pseudo-labeled data that was not predicted unanimously across\nmultiple trials of pseudo-label generation. We test various models to serve as\nthe backbone for this framework, ultimately deciding that RoBERTa performs the\nbest. Ultimately, by leveraging partially validated pseudo-labeled data in\naddition to ground-truth labeled data, we substantially improve our model's\nability to assess suicide risk from social media posts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for publication in the 2024 IEEE International Conference on\n  Big Data",
    "pdf_url": "http://arxiv.org/pdf/2411.12767v2",
    "published_date": "2024-11-18 02:43:05 UTC",
    "updated_date": "2024-12-15 21:12:14 UTC"
  },
  {
    "arxiv_id": "2411.11249v1",
    "title": "EXCON: Extreme Instance-based Contrastive Representation Learning of Severely Imbalanced Multivariate Time Series for Solar Flare Prediction",
    "authors": [
      "Onur Vural",
      "Shah Muhammad Hamdi",
      "Soukaina Filali Boubrahimi"
    ],
    "abstract": "In heliophysics research, predicting solar flares is crucial due to their\npotential to impact both space-based systems and Earth's infrastructure\nsubstantially. Magnetic field data from solar active regions, recorded by solar\nimaging observatories, are transformed into multivariate time series to enable\nsolar flare prediction using temporal window-based analysis. In the realm of\nmultivariate time series-driven solar flare prediction, addressing severe class\nimbalance with effective strategies for multivariate time series representation\nlearning is key to developing robust predictive models. Traditional methods\noften struggle with overfitting to the majority class in prediction tasks where\nmajor solar flares are infrequent. This work presents EXCON, a contrastive\nrepresentation learning framework designed to enhance classification\nperformance amidst such imbalances. EXCON operates through four stages:\nobtaining core features from multivariate time series data; selecting\ndistinctive contrastive representations for each class to maximize inter-class\nseparation; training a temporal feature embedding module with a custom extreme\nreconstruction loss to minimize intra-class variation; and applying a\nclassifier to the learned embeddings for robust classification. The proposed\nmethod leverages contrastive learning principles to map similar instances\ncloser in the feature space while distancing dissimilar ones, a strategy not\nextensively explored in solar flare prediction tasks. This approach not only\naddresses class imbalance but also offers a versatile solution applicable to\nunivariate and multivariate time series across binary and multiclass\nclassification problems. Experimental results, including evaluations on the\nbenchmark solar flare dataset and multiple time series archive datasets with\nbinary and multiclass labels, demonstrate EXCON's efficacy in enhancing\nclassification performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This work has been accepted at the 2024 IEEE International Conference\n  on Big Data (IEEE BigData 2024) on October 27, 2024, as a main conference\n  paper",
    "pdf_url": "http://arxiv.org/pdf/2411.11249v1",
    "published_date": "2024-11-18 02:36:19 UTC",
    "updated_date": "2024-11-18 02:36:19 UTC"
  },
  {
    "arxiv_id": "2411.11247v1",
    "title": "ZeFaV: Boosting Large Language Models for Zero-shot Fact Verification",
    "authors": [
      "Son T. Luu",
      "Hiep Nguyen",
      "Trung Vo",
      "Le-Minh Nguyen"
    ],
    "abstract": "In this paper, we propose ZeFaV - a zero-shot based fact-checking\nverification framework to enhance the performance on fact verification task of\nlarge language models by leveraging the in-context learning ability of large\nlanguage models to extract the relations among the entities within a claim,\nre-organized the information from the evidence in a relationally logical form,\nand combine the above information with the original evidence to generate the\ncontext from which our fact-checking model provide verdicts for the input\nclaims. We conducted empirical experiments to evaluate our approach on two\nmulti-hop fact-checking datasets including HoVer and FEVEROUS, and achieved\npotential results results comparable to other state-of-the-art fact\nverification task methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This pre-print has been published in PRICAI 2024: Trends in\n  Artificial Intelligence. The published version is available at\n  https://doi.org/10.1007/978-981-96-0119-6_28",
    "pdf_url": "http://arxiv.org/pdf/2411.11247v1",
    "published_date": "2024-11-18 02:35:15 UTC",
    "updated_date": "2024-11-18 02:35:15 UTC"
  },
  {
    "arxiv_id": "2411.11235v1",
    "title": "MEMO-Bench: A Multiple Benchmark for Text-to-Image and Multimodal Large Language Models on Human Emotion Analysis",
    "authors": [
      "Yingjie Zhou",
      "Zicheng Zhang",
      "Jiezhang Cao",
      "Jun Jia",
      "Yanwei Jiang",
      "Farong Wen",
      "Xiaohong Liu",
      "Xiongkuo Min",
      "Guangtao Zhai"
    ],
    "abstract": "Artificial Intelligence (AI) has demonstrated significant capabilities in\nvarious fields, and in areas such as human-computer interaction (HCI), embodied\nintelligence, and the design and animation of virtual digital humans, both\npractitioners and users are increasingly concerned with AI's ability to\nunderstand and express emotion. Consequently, the question of whether AI can\naccurately interpret human emotions remains a critical challenge. To date, two\nprimary classes of AI models have been involved in human emotion analysis:\ngenerative models and Multimodal Large Language Models (MLLMs). To assess the\nemotional capabilities of these two classes of models, this study introduces\nMEMO-Bench, a comprehensive benchmark consisting of 7,145 portraits, each\ndepicting one of six different emotions, generated by 12 Text-to-Image (T2I)\nmodels. Unlike previous works, MEMO-Bench provides a framework for evaluating\nboth T2I models and MLLMs in the context of sentiment analysis. Additionally, a\nprogressive evaluation approach is employed, moving from coarse-grained to\nfine-grained metrics, to offer a more detailed and comprehensive assessment of\nthe sentiment analysis capabilities of MLLMs. The experimental results\ndemonstrate that existing T2I models are more effective at generating positive\nemotions than negative ones. Meanwhile, although MLLMs show a certain degree of\neffectiveness in distinguishing and recognizing human emotions, they fall short\nof human-level accuracy, particularly in fine-grained emotion analysis. The\nMEMO-Bench will be made publicly available to support further research in this\narea.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11235v1",
    "published_date": "2024-11-18 02:09:48 UTC",
    "updated_date": "2024-11-18 02:09:48 UTC"
  },
  {
    "arxiv_id": "2411.13587v3",
    "title": "Exploring the Adversarial Vulnerabilities of Vision-Language-Action Models in Robotics",
    "authors": [
      "Taowen Wang",
      "Cheng Han",
      "James Chenhao Liang",
      "Wenhao Yang",
      "Dongfang Liu",
      "Luna Xinyu Zhang",
      "Qifan Wang",
      "Jiebo Luo",
      "Ruixiang Tang"
    ],
    "abstract": "Recently in robotics, Vision-Language-Action (VLA) models have emerged as a\ntransformative approach, enabling robots to execute complex tasks by\nintegrating visual and linguistic inputs within an end-to-end learning\nframework. While VLA models offer significant capabilities, they also introduce\nnew attack surfaces, making them vulnerable to adversarial attacks. With these\nvulnerabilities largely unexplored, this paper systematically quantifies the\nrobustness of VLA-based robotic systems. Recognizing the unique demands of\nrobotic execution, our attack objectives target the inherent spatial and\nfunctional characteristics of robotic systems. In particular, we introduce two\nuntargeted attack objectives that leverage spatial foundations to destabilize\nrobotic actions, and a targeted attack objective that manipulates the robotic\ntrajectory. Additionally, we design an adversarial patch generation approach\nthat places a small, colorful patch within the camera's view, effectively\nexecuting the attack in both digital and physical environments. Our evaluation\nreveals a marked degradation in task success rates, with up to a 100\\%\nreduction across a suite of simulated robotic tasks, highlighting critical\nsecurity gaps in current VLA architectures. By unveiling these vulnerabilities\nand proposing actionable evaluation metrics, we advance both the understanding\nand enhancement of safety for VLA-based robotic systems, underscoring the\nnecessity for continuously developing robust defense strategies prior to\nphysical-world deployments.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Github: https://github.com/William-wAng618/roboticAttack Homepage:\n  https://vlaattacker.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2411.13587v3",
    "published_date": "2024-11-18 01:52:20 UTC",
    "updated_date": "2025-03-10 02:57:07 UTC"
  },
  {
    "arxiv_id": "2411.13586v1",
    "title": "Advance Detection Of Bull And Bear Phases In Cryptocurrency Markets",
    "authors": [
      "Rahul Arulkumaran",
      "Suyash Kumar",
      "Shikha Tomar",
      "Manideep Gongalla",
      "Harshitha"
    ],
    "abstract": "Cryptocurrencies are highly volatile financial instruments with more and more\nnew retail investors joining the scene with each passing day. Bitcoin has\nalways proved to determine in which way the rest of the cryptocurrency market\nis headed towards. As of today Bitcoin has a market dominance of close to 50\npercent. Bull and bear phases in cryptocurrencies are determined based on the\nperformance of Bitcoin over the 50 Day and 200 Day Moving Averages. The aim of\nthis paper is to foretell the performance of bitcoin in the near future by\nemploying predictive algorithms. This predicted data will then be used to\ncalculate the 50 Day and 200 Day Moving Averages and subsequently plotted to\nestablish the potential bull and bear phases.",
    "categories": [
      "q-fin.ST",
      "cs.AI"
    ],
    "primary_category": "q-fin.ST",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13586v1",
    "published_date": "2024-11-18 01:48:16 UTC",
    "updated_date": "2024-11-18 01:48:16 UTC"
  },
  {
    "arxiv_id": "2411.11217v1",
    "title": "MoE-Lightning: High-Throughput MoE Inference on Memory-constrained GPUs",
    "authors": [
      "Shiyi Cao",
      "Shu Liu",
      "Tyler Griggs",
      "Peter Schafhalter",
      "Xiaoxuan Liu",
      "Ying Sheng",
      "Joseph E. Gonzalez",
      "Matei Zaharia",
      "Ion Stoica"
    ],
    "abstract": "Efficient deployment of large language models, particularly Mixture of\nExperts (MoE), on resource-constrained platforms presents significant\nchallenges, especially in terms of computational efficiency and memory\nutilization. The MoE architecture, renowned for its ability to increase model\ncapacity without a proportional increase in inference cost, greatly reduces the\ntoken generation latency compared with dense models. However, the large model\nsize makes MoE models inaccessible to individuals without high-end GPUs. In\nthis paper, we propose a high-throughput MoE batch inference system, that\nsignificantly outperforms past work. MoE-Lightning introduces a novel\nCPU-GPU-I/O pipelining schedule, CGOPipe, with paged weights to achieve high\nresource utilization, and a performance model, HRM, based on a Hierarchical\nRoofline Model we introduce to help find policies with higher throughput than\nexisting systems. MoE-Lightning can achieve up to 10.3x higher throughput than\nstate-of-the-art offloading-enabled LLM inference systems for Mixtral 8x7B on a\nsingle T4 GPU (16GB). When the theoretical system throughput is bounded by the\nGPU memory, MoE-Lightning can reach the throughput upper bound with 2-3x less\nCPU memory, significantly increasing resource utilization. MoE-Lightning also\nsupports efficient batch inference for much larger MoEs (e.g., Mixtral 8x22B\nand DBRX) on multiple low-cost GPUs (e.g., 2-4 T4).",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11217v1",
    "published_date": "2024-11-18 01:06:12 UTC",
    "updated_date": "2024-11-18 01:06:12 UTC"
  },
  {
    "arxiv_id": "2412.03576v1",
    "title": "Ethical Challenges and Evolving Strategies in the Integration of Artificial Intelligence into Clinical Practice",
    "authors": [
      "Ellison B. Weiner",
      "Irene Dankwa-Mullan",
      "William A. Nelson",
      "Saeed Hassanpour"
    ],
    "abstract": "Artificial intelligence (AI) has rapidly transformed various sectors,\nincluding healthcare, where it holds the potential to revolutionize clinical\npractice and improve patient outcomes. However, its integration into medical\nsettings brings significant ethical challenges that need careful consideration.\nThis paper examines the current state of AI in healthcare, focusing on five\ncritical ethical concerns: justice and fairness, transparency, patient consent\nand confidentiality, accountability, and patient-centered and equitable care.\nThese concerns are particularly pressing as AI systems can perpetuate or even\nexacerbate existing biases, often resulting from non-representative datasets\nand opaque model development processes. The paper explores how bias, lack of\ntransparency, and challenges in maintaining patient trust can undermine the\neffectiveness and fairness of AI applications in healthcare. In addition, we\nreview existing frameworks for the regulation and deployment of AI, identifying\ngaps that limit the widespread adoption of these systems in a just and\nequitable manner. Our analysis provides recommendations to address these\nethical challenges, emphasizing the need for fairness in algorithm design,\ntransparency in model decision-making, and patient-centered approaches to\nconsent and data privacy. By highlighting the importance of continuous ethical\nscrutiny and collaboration between AI developers, clinicians, and ethicists, we\noutline pathways for achieving more responsible and inclusive AI implementation\nin healthcare. These strategies, if adopted, could enhance both the clinical\nvalue of AI and the trustworthiness of AI systems among patients and healthcare\nprofessionals, ensuring that these technologies serve all populations\nequitably.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03576v1",
    "published_date": "2024-11-18 00:52:22 UTC",
    "updated_date": "2024-11-18 00:52:22 UTC"
  },
  {
    "arxiv_id": "2411.11213v1",
    "title": "Making Sigmoid-MSE Great Again: Output Reset Challenges Softmax Cross-Entropy in Neural Network Classification",
    "authors": [
      "Kanishka Tyagi",
      "Chinmay Rane",
      "Ketaki Vaidya",
      "Jeshwanth Challgundla",
      "Soumitro Swapan Auddy",
      "Michael Manry"
    ],
    "abstract": "This study presents a comparative analysis of two objective functions, Mean\nSquared Error (MSE) and Softmax Cross-Entropy (SCE) for neural network\nclassification tasks. While SCE combined with softmax activation is the\nconventional choice for transforming network outputs into class probabilities,\nwe explore an alternative approach using MSE with sigmoid activation. We\nintroduce the Output Reset algorithm, which reduces inconsistent errors and\nenhances classifier robustness. Through extensive experiments on benchmark\ndatasets (MNIST, CIFAR-10, and Fashion-MNIST), we demonstrate that MSE with\nsigmoid activation achieves comparable accuracy and convergence rates to SCE,\nwhile exhibiting superior performance in scenarios with noisy data. Our\nfindings indicate that MSE, despite its traditional association with regression\ntasks, serves as a viable alternative for classification problems, challenging\nconventional wisdom about neural network training strategies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11213v1",
    "published_date": "2024-11-18 00:46:38 UTC",
    "updated_date": "2024-11-18 00:46:38 UTC"
  },
  {
    "arxiv_id": "2411.15175v4",
    "title": "ToxiLab: How Well Do Open-Source LLMs Generate Synthetic Toxicity Data?",
    "authors": [
      "Zheng Hui",
      "Zhaoxiao Guo",
      "Hang Zhao",
      "Juanyong Duan",
      "Lin Ai",
      "Yinheng Li",
      "Julia Hirschberg",
      "Congrui Huang"
    ],
    "abstract": "Effective toxic content detection relies heavily on high-quality and diverse\ndata, which serve as the foundation for robust content moderation models.\nSynthetic data has become a common approach for training models across various\nNLP tasks. However, its effectiveness remains uncertain for highly subjective\ntasks like hate speech detection, with previous research yielding mixed\nresults. This study explores the potential of open-source LLMs for harmful data\nsynthesis, utilizing controlled prompting and supervised fine-tuning techniques\nto enhance data quality and diversity. We systematically evaluated 6 open\nsource LLMs on 5 datasets, assessing their ability to generate diverse,\nhigh-quality harmful data while minimizing hallucination and duplication. Our\nresults show that Mistral consistently outperforms other open models, and\nsupervised fine-tuning significantly enhances data reliability and diversity.\nWe further analyze the trade-offs between prompt-based vs. fine-tuned toxic\ndata synthesis, discuss real-world deployment challenges, and highlight ethical\nconsiderations. Our findings demonstrate that fine-tuned open source LLMs\nprovide scalable and cost-effective solutions to augment toxic content\ndetection datasets, paving the way for more accessible and transparent content\nmoderation tools.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.15175v4",
    "published_date": "2024-11-18 00:21:14 UTC",
    "updated_date": "2025-02-22 16:42:03 UTC"
  }
]