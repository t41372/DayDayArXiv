{
  "date": "2024-11-18",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-18 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的优化、安全和应用，特别是大型语言模型（LLMs）和扩散模型的创新进展，强调了高效计算、鲁棒性提升以及在医疗、机器人和图像处理领域的实际应用；令人印象深刻的包括 Meta 团队的 Llama Guard 3-1B-INT4 紧凑安全模型，以及 TSPRank 在排序优化上的突破。\n\n下面，我将逐一简要概述部分关键论文，先优先讨论那些重要、话题性强或有著名学者参与的文章（如 AI 安全、LLM 优化和医疗应用），并将相关主题归类讨论。对于其他较次要的论文，我会快速掠过，只突出核心贡献。论文标题以“中文翻译 + 英文原标题”的形式呈现。\n\n### AI 安全与 LLM 优化\n- **Llama Guard 3-1B-INT4: 紧凑且高效的人机对话安全守护模型** (Llama Guard 3-1B-INT4: Compact and Efficient Safeguard for Human-AI Conversations)：Igor Fedorov 等 Meta 团队的论文提出了一种小型模型，仅 440MB 大小，却在资源受限设备上实现 30 tokens/秒的处理速度，并与更大模型匹敌的安全性能。主要贡献是提升 AI 对话的安全性和部署效率，适用于移动端。\n- **Bi-Mamba: 实现精确的 1-Bit 状态空间模型** (Bi-Mamba: Towards Accurate 1-Bit State Space Models)：Shengkun Tang 等的研究通过 1-Bit 表示优化 Mamba 模型，显著降低内存和能耗，同时保持性能。主要发现是这种低位表示在语言建模中可媲美全精度模型，适用于高效 LLM 部署。\n- **MoE-Lightning: 在内存受限 GPU 上实现高吞吐 MoE 推理** (MoE-Lightning: High-Throughput MoE Inference on Memory-constrained GPUs)：Shiyi Cao 等的工作提出了一种 CPU-GPU-I/O 管道调度框架，在单 T4 GPU 上实现 Mixtral 8x7B 的 10.3 倍吞吐提升。主要贡献是优化混合专家模型的推理效率，解决资源限制问题。\n- **ToxiLab: 评估开源 LLM 生成合成毒性数据的性能** (ToxiLab: How Well Do Open-Source LLMs Generate Synthetic Toxicity Data?)：Zheng Hui 等的研究使用 Mistral 等模型生成高质量毒性数据，发现微调能减少幻觉和重复，适用于内容审核数据集扩充。\n- **CROW: 通过内部一致性正则化消除 LLM 中的后门攻击** (CROW: Eliminating Backdoors from Large Language Models via Internal Consistency Regularization)：Nay Myat Min 等提出一种无需参考模型的正则化方法，显著降低后门攻击成功率，同时保持生成能力。\n\n这些论文共同探讨了 LLM 的安全性和高效性，突出了后门防御和低资源部署的实际价值，相关工作如 Bi-Mamba 和 MoE-Lightning 展示了 AI 模型向边缘计算的扩展潜力。\n\n### 医疗图像与 AI 应用\n- **Medical Video Generation for Disease Progression Simulation: 用于疾病进展模拟的医疗视频生成** (Medical Video Generation for Disease Progression Simulation)：Xu Cao 等的工作首次提出框架，使用扩散模型模拟疾病轨迹，支持 X 光、心脏和皮肤图像的动态可视化。主要发现是生成的序列可辅助诊断和教育。\n- **HistoEncoder: 基于前列腺癌的数字病理基础模型** (HistoEncoder: a digital pathology foundation model for prostate cancer)：Joona Pohjonen 等构建了 4800 万图像的模型，实现高效肿瘤分类和图像分析，显著提升病理诊断准确性。\n- **TP-UNet: 基于时间提示的 UNet 用于医疗图像分割** (TP-UNet: Temporal Prompt Guided UNet for Medical Image Segmentation)：Ranmin Wang 等引入时间提示机制，优化 UNet 在器官分割中的性能，通过语义引导提升分割精度。\n- **Leveraging Gene Expression Data and Explainable Machine Learning for Enhanced Early Detection of Type 2 Diabetes: 利用基因表达数据和可解释机器学习提升 2 型糖尿病早期检测** (Leveraging Gene Expression Data and Explainable Machine Learning for Enhanced Early Detection of Type 2 Diabetes)：Aurora Lithe Roy 等使用 XGBoost 模型结合基因数据，达到 97% 准确率，并通过可解释 AI 增强模型可信度。\n\n这些医疗相关论文强调了 AI 在疾病预测和图像处理中的潜力，HistoEncoder 等工作展示了基础模型在临床应用中的高效性，但需关注数据隐私。\n\n### 强化学习与图像处理\n- **TSPRank: 使用双线性旅行 salesman 模型桥接成对和列表排序方法** (TSPRank: Bridging Pairwise and Listwise Methods with a Bilinear Travelling Salesman Model)：Weixian Waylon Li 等提出混合排序方法，将排序问题转化为旅行 salesman 问题，显著提升股票排序和信息检索性能。该论文已接受 ACM SIGKDD 2025。\n- **Just Leaf It: 利用分层类别修剪加速扩散分类器** (Just Leaf It: Accelerating Diffusion Classifiers with Hierarchical Class Pruning)：Arundhati S. Shanbhag 等优化扩散模型，通过分层修剪减少计算量，同时保持准确性。\n- **Zoomed In, Diffused Out: 针对极端图像超分辨率的局部退化感知多扩散方法** (Zoomed In, Diffused Out: Towards Local Degradation-Aware Multi-Diffusion for Extreme Image Super-Resolution)：Brian B. Moser 等引入多扩散路径，实现无额外训练的 2K-8K 图像生成，显著提升图像重建质量。\n- **LightFFDNets: 用于快速面部伪造检测的轻量卷积神经网络** (LightFFDNets: Lightweight Convolutional Neural Networks for Rapid Facial Forgery Detection)：Günel Jabbarlı 等提出轻量模型，准确检测面部伪造图像，计算效率高。\n\n强化学习论文如 TSPRank 展示了优化算法的创新，而图像处理工作如 Zoomed In 突出了扩散模型在高分辨率任务中的实用性。\n\n### 其他快速掠过\n- **Distill the Best, Ignore the Rest: 通过损失值-based 修剪提升数据集蒸馏** (Distill the Best, Ignore the Rest: Improving Dataset Distillation with Loss-Value-Based Pruning)：Brian B. Moser 等的工作优化数据集蒸馏，移除 80% 数据后准确率提升 5.2%，但细节较常规。\n- **Regret-Free Reinforcement Learning for LTL Specifications: 用于 LTL 规范的无后悔强化学习** (Regret-Free Reinforcement Learning for LTL Specifications)：Rupak Majumdar 等提出在线算法，解决马尔科夫决策过程的无后悔学习，适用于安全关键系统。\n- **ByteScience: 桥接非结构化科学文献和结构化数据的 LLM 平台** (ByteScience: Bridging Unstructured Scientific Literature and Structured Data with Auto Fine-tuned Large Language Model in Token Granularity)：Tong Xie 等开发平台提取科学数据，准确性高但应用场景较窄。\n- **SpatialDreamer: 从单目输入的自监督立体视频合成** (SpatialDreamer: Self-supervised Stereo Video Synthesis from Monocular Input)：Zhen Lv 等使用扩散模型合成立体视频，关注几何一致性。\n\n这些论文虽有贡献，如数据集优化和科学数据提取，但影响力较小，故简要提及。\n\n总之，今天的 arXiv 论文展示了 AI 领域的快速发展，尤其在模型效率和实际应用上，但也暴露了安全和泛化挑战。感兴趣的读者可关注 LLM 安全和医疗 AI 方向的后续进展！（全文约 1200 字）",
  "papers": [
    {
      "arxiv_id": "2411.12128v3",
      "title": "The Role of Accuracy and Validation Effectiveness in Conversational Business Analytics",
      "title_zh": "准确性和验证有效性在对话式商业分析中的作用",
      "authors": [
        "Adem Alparslan"
      ],
      "abstract": "This study examines conversational business analytics, an approach that\nutilizes AI to address the technical competency gaps that hinder end users from\neffectively using traditional self-service analytics. By facilitating natural\nlanguage interactions, conversational business analytics aims to empower end\nusers to independently retrieve data and generate insights. The analysis\nfocuses on Text-to-SQL as a representative technology for translating natural\nlanguage requests into SQL statements. Developing theoretical models grounded\nin expected utility theory, this study identifies the conditions under which\nconversational business analytics, through partial or full support, can\noutperform delegation to human experts. The results indicate that partial\nsupport, focusing solely on information generation by AI, is viable when the\naccuracy of AI-generated SQL queries leads to a profit that surpasses the\nperformance of a human expert. In contrast, full support includes not only\ninformation generation but also validation through explanations provided by the\nAI, and requires sufficiently high validation effectiveness to be reliable.\nHowever, user-based validation presents challenges, such as misjudgment and\nrejection of valid SQL queries, which may limit the effectiveness of\nconversational business analytics. These challenges underscore the need for\nrobust validation mechanisms, including improved user support, automated\nprocesses, and methods for assessing quality independent of the technical\ncompetency of end users.",
      "tldr_zh": "本研究探讨了对话式商业分析（conversational business analytics）的角色，利用 AI 通过自然语言交互（如 Text-to-SQL 技术）帮助用户克服传统自助分析的技术能力障碍。基于期望效用理论，该研究开发了理论模型，分析了 AI 部分支持（仅生成信息）和完全支持（包括验证）何时能优于人类专家，结果显示 AI 在高准确性下部分支持更有效，而完全支持需高验证有效性。用户验证可能因误判等问题而受限，因此强调需要更 robust 的验证机制，如改进用户支持和自动化过程，以提升整体可靠性。",
      "categories": [
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12128v3",
      "published_date": "2024-11-18 23:58:24 UTC",
      "updated_date": "2024-11-25 10:14:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:27:37.539147"
    },
    {
      "arxiv_id": "2411.12115v1",
      "title": "Distill the Best, Ignore the Rest: Improving Dataset Distillation with Loss-Value-Based Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Brian B. Moser",
        "Federico Raue",
        "Tobias C. Nauen",
        "Stanislav Frolov",
        "Andreas Dengel"
      ],
      "abstract": "Dataset distillation has gained significant interest in recent years, yet\nexisting approaches typically distill from the entire dataset, potentially\nincluding non-beneficial samples. We introduce a novel \"Prune First, Distill\nAfter\" framework that systematically prunes datasets via loss-based sampling\nprior to distillation. By leveraging pruning before classical distillation\ntechniques and generative priors, we create a representative core-set that\nleads to enhanced generalization for unseen architectures - a significant\nchallenge of current distillation methods. More specifically, our proposed\nframework significantly boosts distilled quality, achieving up to a 5.2\npercentage points accuracy increase even with substantial dataset pruning,\ni.e., removing 80% of the original dataset prior to distillation. Overall, our\nexperimental results highlight the advantages of our easy-sample prioritization\nand cross-architecture robustness, paving the way for more effective and\nhigh-quality dataset distillation.",
      "tldr_zh": "该论文针对数据集蒸馏（Dataset Distillation）中的问题，提出了一种“Prune First, Distill After”框架，通过基于损失值的采样（loss-based sampling）先修剪数据集，移除非有益样本，从而提升蒸馏效率和泛化能力。该方法结合经典蒸馏技术和生成先验，创建了一个更具代表性的核心集，尤其在未见架构上表现出色。实验结果表明，即使修剪80%的原始数据集，准确率仍可提高高达5.2个百分点，并展示了易样本优先和跨架构鲁棒性的优势。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12115v1",
      "published_date": "2024-11-18 22:51:44 UTC",
      "updated_date": "2024-11-18 22:51:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:27:49.729624"
    },
    {
      "arxiv_id": "2411.17713v1",
      "title": "Llama Guard 3-1B-INT4: Compact and Efficient Safeguard for Human-AI Conversations",
      "title_zh": "翻译失败",
      "authors": [
        "Igor Fedorov",
        "Kate Plawiak",
        "Lemeng Wu",
        "Tarek Elgamal",
        "Naveen Suda",
        "Eric Smith",
        "Hongyuan Zhan",
        "Jianfeng Chi",
        "Yuriy Hulovatyy",
        "Kimish Patel",
        "Zechun Liu",
        "Changsheng Zhao",
        "Yangyang Shi",
        "Tijmen Blankevoort",
        "Mahesh Pasupuleti",
        "Bilge Soran",
        "Zacharie Delpierre Coudert",
        "Rachad Alao",
        "Raghuraman Krishnamoorthi",
        "Vikas Chandra"
      ],
      "abstract": "This paper presents Llama Guard 3-1B-INT4, a compact and efficient Llama\nGuard model, which has been open-sourced to the community during Meta Connect\n2024. We demonstrate that Llama Guard 3-1B-INT4 can be deployed on\nresource-constrained devices, achieving a throughput of at least 30 tokens per\nsecond and a time-to-first-token of 2.5 seconds or less on a commodity Android\nmobile CPU. Notably, our experiments show that Llama Guard 3-1B-INT4 attains\ncomparable or superior safety moderation scores to its larger counterpart,\nLlama Guard 3-1B, despite being approximately 7 times smaller in size (440MB).",
      "tldr_zh": "这篇论文介绍了 Llama Guard 3-1B-INT4，这是一个紧凑且高效的模型，用于保护人类-AI 对话的安全，并在 Meta Connect 2024 上开源。相比于更大的 Llama Guard 3-1B 模型，该版本大小仅为 440MB（约原模型的 1/7），却能在资源受限设备如 Android 手机 CPU 上实现至少 30 tokens per second 的吞吐量和 2.5 秒或更少的 time-to-first-token。实验结果显示，Llama Guard 3-1B-INT4 在安全调节分数上达到或超过了其更大对应模型的表现，为部署在移动设备上的 AI 安全机制提供了可行方案。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17713v1",
      "published_date": "2024-11-18 21:42:17 UTC",
      "updated_date": "2024-11-18 21:42:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:28:03.538045"
    },
    {
      "arxiv_id": "2411.12073v2",
      "title": "Just Leaf It: Accelerating Diffusion Classifiers with Hierarchical Class Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Arundhati S. Shanbhag",
        "Brian B. Moser",
        "Tobias C. Nauen",
        "Stanislav Frolov",
        "Federico Raue",
        "Andreas Dengel"
      ],
      "abstract": "Diffusion models, celebrated for their generative capabilities, have recently\ndemonstrated surprising effectiveness in image classification tasks by using\nBayes' theorem. Yet, current diffusion classifiers must evaluate every label\ncandidate for each input, creating high computational costs that impede their\nuse in large-scale applications. To address this limitation, we propose a\nHierarchical Diffusion Classifier (HDC) that exploits hierarchical label\nstructures or well-defined parent-child relationships in the dataset. By\npruning irrelevant high-level categories and refining predictions only within\nrelevant subcategories (leaf nodes and sub-trees), HDC reduces the total number\nof class evaluations. As a result, HDC can speed up inference by as much as 60%\nwhile preserving and sometimes even improving classification accuracy. In\nsummary, our work provides a tunable control mechanism between speed and\nprecision, making diffusion-based classification more feasible for large-scale\napplications.",
      "tldr_zh": "本文提出 Hierarchical Diffusion Classifier (HDC)，一种利用标签层次结构（如父子关系）来加速扩散模型（Diffusion models）在图像分类中的方法，通过修剪无关的高级类别并仅在相关子类别（leaf nodes 和子树）中精炼预测，从而减少类别的评估数量。HDC 在保持或提升分类准确性的同时，可将推理速度提高多达 60%。这项工作为大规模应用提供了一个可调节的速度与精度平衡机制，使扩散模型更高效实用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12073v2",
      "published_date": "2024-11-18 21:34:05 UTC",
      "updated_date": "2025-03-08 00:47:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:28:13.526641"
    },
    {
      "arxiv_id": "2411.12072v1",
      "title": "Zoomed In, Diffused Out: Towards Local Degradation-Aware Multi-Diffusion for Extreme Image Super-Resolution",
      "title_zh": "翻译失败",
      "authors": [
        "Brian B. Moser",
        "Stanislav Frolov",
        "Tobias C. Nauen",
        "Federico Raue",
        "Andreas Dengel"
      ],
      "abstract": "Large-scale, pre-trained Text-to-Image (T2I) diffusion models have gained\nsignificant popularity in image generation tasks and have shown unexpected\npotential in image Super-Resolution (SR). However, most existing T2I diffusion\nmodels are trained with a resolution limit of 512x512, making scaling beyond\nthis resolution an unresolved but necessary challenge for image SR. In this\nwork, we introduce a novel approach that, for the first time, enables these\nmodels to generate 2K, 4K, and even 8K images without any additional training.\nOur method leverages MultiDiffusion, which distributes the generation across\nmultiple diffusion paths to ensure global coherence at larger scales, and local\ndegradation-aware prompt extraction, which guides the T2I model to reconstruct\nfine local structures according to its low-resolution input. These innovations\nunlock higher resolutions, allowing T2I diffusion models to be applied to image\nSR tasks without limitation on resolution.",
      "tldr_zh": "该研究针对预训练的 Text-to-Image (T2I) 扩散模型在图像超分辨率 (SR) 任务中受限于 512x512 分辨率的问题，提出了一种无需额外训练即可生成 2K、4K 甚至 8K 高分辨率图像的新方法。方法结合 MultiDiffusion 技术，将图像生成分布到多个扩散路径以维持全局一致性，并引入局部退化感知提示提取 (local degradation-aware prompt extraction)，指导模型根据低分辨率输入精确重建精细局部结构。这些创新使 T2I 扩散模型能够不受分辨率限制地应用于图像 SR 任务。实验结果证明了该方法的有效性，为极端图像超分辨率提供了可扩展的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12072v1",
      "published_date": "2024-11-18 21:32:49 UTC",
      "updated_date": "2024-11-18 21:32:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:28:25.397929"
    },
    {
      "arxiv_id": "2411.14473v4",
      "title": "Large Language Model for Qualitative Research -- A Systematic Mapping Study",
      "title_zh": "翻译失败",
      "authors": [
        "Cauã Ferreira Barros",
        "Bruna Borges Azevedo",
        "Valdemar Vicente Graciano Neto",
        "Mohamad Kassab",
        "Marcos Kalinowski",
        "Hugo Alexandre D. do Nascimento",
        "Michelle C. G. S. P. Bandeira"
      ],
      "abstract": "The exponential growth of text-based data in domains such as healthcare,\neducation, and social sciences has outpaced the capacity of traditional\nqualitative analysis methods, which are time-intensive and prone to\nsubjectivity. Large Language Models (LLMs), powered by advanced generative AI,\nhave emerged as transformative tools capable of automating and enhancing\nqualitative analysis. This study systematically maps the literature on the use\nof LLMs for qualitative research, exploring their application contexts,\nconfigurations, methodologies, and evaluation metrics. Findings reveal that\nLLMs are utilized across diverse fields, demonstrating the potential to\nautomate processes traditionally requiring extensive human input. However,\nchallenges such as reliance on prompt engineering, occasional inaccuracies, and\ncontextual limitations remain significant barriers. This research highlights\nopportunities for integrating LLMs with human expertise, improving model\nrobustness, and refining evaluation methodologies. By synthesizing trends and\nidentifying research gaps, this study aims to guide future innovations in the\napplication of LLMs for qualitative analysis.",
      "tldr_zh": "本研究通过系统映射研究（systematic mapping study）探讨了大型语言模型（Large Language Models, LLMs）在定性研究中的应用，旨在应对文本数据爆炸式增长带来的传统分析方法耗时和主观性问题。研究分析了 LLMs 在医疗、教育和社会科学等领域的配置、方法论和评估指标，发现这些模型能有效自动化需要人类输入的过程，但面临提示工程（prompt engineering）依赖、不准确性和上下文限制等挑战。总体而言，该研究总结了 LLMs 的应用趋势，识别了研究空白，并为未来整合人类专业知识、提升模型鲁棒性和优化评估方法提供了指导方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7; I.2.10; H.3.3"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, includes 1 figures and 3 tables. Submitted and Accepted to\n  the WSESE 2025 ICSE Workshop",
      "pdf_url": "http://arxiv.org/pdf/2411.14473v4",
      "published_date": "2024-11-18 21:28:00 UTC",
      "updated_date": "2025-03-06 20:49:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:28:36.423992"
    },
    {
      "arxiv_id": "2411.12064v3",
      "title": "TSPRank: Bridging Pairwise and Listwise Methods with a Bilinear Travelling Salesman Model",
      "title_zh": "翻译失败",
      "authors": [
        "Weixian Waylon Li",
        "Yftah Ziser",
        "Yifei Xie",
        "Shay B. Cohen",
        "Tiejun Ma"
      ],
      "abstract": "Traditional Learning-To-Rank (LETOR) approaches, including pairwise methods\nlike RankNet and LambdaMART, often fall short by solely focusing on pairwise\ncomparisons, leading to sub-optimal global rankings. Conversely, deep learning\nbased listwise methods, while aiming to optimise entire lists, require complex\ntuning and yield only marginal improvements over robust pairwise models. To\novercome these limitations, we introduce Travelling Salesman Problem Rank\n(TSPRank), a hybrid pairwise-listwise ranking method. TSPRank reframes the\nranking problem as a Travelling Salesman Problem (TSP), a well-known\ncombinatorial optimisation challenge that has been extensively studied for its\nnumerous solution algorithms and applications. This approach enables the\nmodelling of pairwise relationships and leverages combinatorial optimisation to\ndetermine the listwise ranking. This approach can be directly integrated as an\nadditional component into embeddings generated by existing backbone models to\nenhance ranking performance. Our extensive experiments across three backbone\nmodels on diverse tasks, including stock ranking, information retrieval, and\nhistorical events ordering, demonstrate that TSPRank significantly outperforms\nboth pure pairwise and listwise methods. Our qualitative analysis reveals that\nTSPRank's main advantage over existing methods is its ability to harness global\ninformation better while ranking. TSPRank's robustness and superior performance\nacross different domains highlight its potential as a versatile and effective\nLETOR solution.",
      "tldr_zh": "本研究针对传统Learning-To-Rank (LETOR)方法的局限性，提出TSPRank，一种混合pairwise和listwise的排名方法，将排名问题重新表述为Travelling Salesman Problem (TSP)，并利用其组合优化算法来建模pairwise关系并优化全局列表。TSPRank可直接整合到现有backbone模型的embeddings中，提升整体性能。在股票排名、信息检索和历史事件排序等任务上，实验结果显示TSPRank显著优于纯pairwise方法（如RankNet和LambdaMART）和listwise方法，展现出更好的全局信息利用和跨领域鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ACM SIGKDD 2025 Research Track. The code and preprocessed\n  data are available at https://github.com/waylonli/TSPRank-KDD2025",
      "pdf_url": "http://arxiv.org/pdf/2411.12064v3",
      "published_date": "2024-11-18 21:10:14 UTC",
      "updated_date": "2025-03-23 17:50:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:28:49.952127"
    },
    {
      "arxiv_id": "2411.15180v1",
      "title": "Multi-layer matrix factorization for cancer subtyping using full and partial multi-omics dataset",
      "title_zh": "多层矩阵分解用于癌症亚型分类，使用完整和部分多组学数据集",
      "authors": [
        "Yingxuan Ren",
        "Fengtao Ren",
        "Bo Yang"
      ],
      "abstract": "Cancer, with its inherent heterogeneity, is commonly categorized into\ndistinct subtypes based on unique traits, cellular origins, and molecular\nmarkers specific to each type. However, current studies primarily rely on\ncomplete multi-omics datasets for predicting cancer subtypes, often overlooking\npredictive performance in cases where some omics data may be missing and\nneglecting implicit relationships across multiple layers of omics data\nintegration. This paper introduces Multi-Layer Matrix Factorization (MLMF), a\nnovel approach for cancer subtyping that employs multi-omics data clustering.\nMLMF initially processes multi-omics feature matrices by performing multi-layer\nlinear or nonlinear factorization, decomposing the original data into latent\nfeature representations unique to each omics type. These latent representations\nare subsequently fused into a consensus form, on which spectral clustering is\nperformed to determine subtypes. Additionally, MLMF incorporates a class\nindicator matrix to handle missing omics data, creating a unified framework\nthat can manage both complete and incomplete multi-omics data. Extensive\nexperiments conducted on 10 multi-omics cancer datasets, both complete and with\nmissing values, demonstrate that MLMF achieves results that are comparable to\nor surpass the performance of several state-of-the-art approaches.",
      "tldr_zh": "本研究针对癌症的异质性，提出Multi-Layer Matrix Factorization (MLMF)，一种用于癌症分型的多组学数据聚类方法，以解决现有方法依赖完整数据集并忽略组学间隐式关系的问题。MLMF通过多层线性或非线性matrix factorization处理多组学特征矩阵，生成每个组学类型的潜在特征表示，并将其融合成共识形式后进行spectral clustering以确定癌症亚型；此外，该方法利用class indicator matrix处理缺失组学数据，实现对完整和不完整数据集的统一框架。在10个多组学癌症数据集上的实验表明，MLMF的表现优于或相当于是先进方法，提升了癌症分型的准确性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15180v1",
      "published_date": "2024-11-18 20:58:11 UTC",
      "updated_date": "2024-11-18 20:58:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:29:01.070970"
    },
    {
      "arxiv_id": "2411.12056v1",
      "title": "Benchmarking pre-trained text embedding models in aligning built asset information",
      "title_zh": "翻译失败",
      "authors": [
        "Mehrzad Shahinmoghadam",
        "Ali Motamedi"
      ],
      "abstract": "Accurate mapping of the built asset information to established data\nclassification systems and taxonomies is crucial for effective asset\nmanagement, whether for compliance at project handover or ad-hoc data\nintegration scenarios. Due to the complex nature of built asset data, which\npredominantly comprises technical text elements, this process remains largely\nmanual and reliant on domain expert input. Recent breakthroughs in contextual\ntext representation learning (text embedding), particularly through pre-trained\nlarge language models, offer promising approaches that can facilitate the\nautomation of cross-mapping of the built asset data. However, no comprehensive\nevaluation has yet been conducted to assess these models' ability to\neffectively represent the complex semantics specific to built asset technical\nterminology. This study presents a comparative benchmark of state-of-the-art\ntext embedding models to evaluate their effectiveness in aligning built asset\ninformation with domain-specific technical concepts. Our proposed datasets are\nderived from two renowned built asset data classification dictionaries. The\nresults of our benchmarking across six proposed datasets, covering three tasks\nof clustering, retrieval, and reranking, highlight the need for future research\non domain adaptation techniques. The benchmarking resources are published as an\nopen-source library, which will be maintained and extended to support future\nevaluations in this field.",
      "tldr_zh": "这篇论文基准测试了预-trained text embedding models 在对齐建筑资产信息方面的表现，以自动化复杂技术文本的映射过程。研究者使用从两个知名建筑资产数据分类字典派生的数据集，评估了这些模型在聚类、retrieval 和 reranking 等三个任务上的有效性。结果显示，现有的模型在处理建筑领域的特定语义时存在局限性，强调了未来需要加强领域适应技术的研究。该基准测试资源已作为开源库发布，以支持后续评估。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12056v1",
      "published_date": "2024-11-18 20:54:17 UTC",
      "updated_date": "2024-11-18 20:54:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:29:14.741875"
    },
    {
      "arxiv_id": "2411.12045v1",
      "title": "Fingerprinting and Tracing Shadows: The Development and Impact of Browser Fingerprinting on Digital Privacy",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Lawall"
      ],
      "abstract": "Browser fingerprinting is a growing technique for identifying and tracking\nusers online without traditional methods like cookies. This paper gives an\noverview by examining the various fingerprinting techniques and analyzes the\nentropy and uniqueness of the collected data. The analysis highlights that\nbrowser fingerprinting poses a complex challenge from both technical and\nprivacy perspectives, as users often have no control over the collection and\nuse of their data. In addition, it raises significant privacy concerns as users\nare often tracked without their knowledge or consent.",
      "tldr_zh": "本研究探讨了浏览器指纹识别(browser fingerprinting)技术的发展及其对数字隐私的影响，该技术无需依赖传统方法如 cookies，就能识别和跟踪用户。论文概述了各种指纹识别技术，并分析了收集数据的熵(entropy)和独特性(uniqueness)，揭示了这些数据在识别用户方面的复杂性。从技术和隐私角度，该方法构成重大挑战，因为用户往往无法控制数据收集过程。最终，研究强调浏览器指纹识别会导致未经用户知情或同意的跟踪，引发了严重的隐私担忧。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "SECURWARE 2024, France, Nice",
      "pdf_url": "http://arxiv.org/pdf/2411.12045v1",
      "published_date": "2024-11-18 20:32:31 UTC",
      "updated_date": "2024-11-18 20:32:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:29:24.731847"
    },
    {
      "arxiv_id": "2411.12042v1",
      "title": "Fast Convergence of Softmax Policy Mirror Ascent",
      "title_zh": "Softmax 策略镜像上升的快速收敛",
      "authors": [
        "Reza Asad",
        "Reza Babanezhad",
        "Issam Laradji",
        "Nicolas Le Roux",
        "Sharan Vaswani"
      ],
      "abstract": "Natural policy gradient (NPG) is a common policy optimization algorithm and\ncan be viewed as mirror ascent in the space of probabilities. Recently, Vaswani\net al. [2021] introduced a policy gradient method that corresponds to mirror\nascent in the dual space of logits. We refine this algorithm, removing its need\nfor a normalization across actions and analyze the resulting method (referred\nto as SPMA). For tabular MDPs, we prove that SPMA with a constant step-size\nmatches the linear convergence of NPG and achieves a faster convergence than\nconstant step-size (accelerated) softmax policy gradient. To handle large\nstate-action spaces, we extend SPMA to use a log-linear policy\nparameterization. Unlike that for NPG, generalizing SPMA to the linear function\napproximation (FA) setting does not require compatible function approximation.\nUnlike MDPO, a practical generalization of NPG, SPMA with linear FA only\nrequires solving convex softmax classification problems. We prove that SPMA\nachieves linear convergence to the neighbourhood of the optimal value function.\nWe extend SPMA to handle non-linear FA and evaluate its empirical performance\non the MuJoCo and Atari benchmarks. Our results demonstrate that SPMA\nconsistently achieves similar or better performance compared to MDPO, PPO and\nTRPO.",
      "tldr_zh": "这篇论文提出了 Softmax Policy Mirror Ascent (SPMA)，一种改进的策略优化算法，它基于对偶空间的镜面上升方法，消除了动作归一化的需求，并与 Natural Policy Gradient (NPG) 相当或更快。对于表格 Markov Decision Processes (MDPs)，SPMA 以恒定步长实现线性收敛，且在扩展到线性函数逼近 (FA) 设置时，只需解决凸 softmax 分类问题，便可线性收敛到最优值函数的邻域。实验结果显示，SPMA 在 MuJoCo 和 Atari 基准上，与 MDPO、PPO 和 TRPO 相比，表现出类似或更好的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12042v1",
      "published_date": "2024-11-18 20:27:13 UTC",
      "updated_date": "2024-11-18 20:27:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:29:39.810777"
    },
    {
      "arxiv_id": "2411.14471v1",
      "title": "Leveraging Gene Expression Data and Explainable Machine Learning for Enhanced Early Detection of Type 2 Diabetes",
      "title_zh": "翻译失败",
      "authors": [
        "Aurora Lithe Roy",
        "Md Kamrul Siam",
        "Nuzhat Noor Islam Prova",
        "Sumaiya Jahan",
        "Abdullah Al Maruf"
      ],
      "abstract": "Diabetes, particularly Type 2 diabetes (T2D), poses a substantial global\nhealth burden, compounded by its associated complications such as\ncardiovascular diseases, kidney failure, and vision impairment. Early detection\nof T2D is critical for improving healthcare outcomes and optimizing resource\nallocation. In this study, we address the gap in early T2D detection by\nleveraging machine learning (ML) techniques on gene expression data obtained\nfrom T2D patients. Our primary objective was to enhance the accuracy of early\nT2D detection through advanced ML methodologies and increase the model's\ntrustworthiness using the explainable artificial intelligence (XAI) technique.\nAnalyzing the biological mechanisms underlying T2D through gene expression\ndatasets represents a novel research frontier, relatively less explored in\nprevious studies. While numerous investigations have focused on utilizing\nclinical and demographic data for T2D prediction, the integration of molecular\ninsights from gene expression datasets offers a unique and promising avenue for\nunderstanding the pathophysiology of the disease. By employing six ML\nclassifiers on data sourced from NCBI's Gene Expression Omnibus (GEO), we\nobserved promising performance across all models. Notably, the XGBoost\nclassifier exhibited the highest accuracy, achieving 97%. Our study addresses a\nnotable gap in early T2D detection methodologies, emphasizing the importance of\nleveraging gene expression data and advanced ML techniques.",
      "tldr_zh": "这篇论文针对2型糖尿病(T2D)的早期检测，利用基因表达数据和机器学习(ML)技术，旨在提高诊断准确性和模型可信度。研究者分析了从Gene Expression Omnibus(GEO)获取的基因表达数据集，测试了六种ML分类器，其中XGBoost表现出色，达到了97%的准确率，并通过可解释人工智能(XAI)技术解释了模型决策过程。该方法填补了现有T2D检测研究的空白，提供新的分子见解以更好地理解疾病病理机制，并为优化医疗资源分配奠定基础。",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.14471v1",
      "published_date": "2024-11-18 20:24:08 UTC",
      "updated_date": "2024-11-18 20:24:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:29:49.870959"
    },
    {
      "arxiv_id": "2411.12038v1",
      "title": "Scaling Deep Learning Research with Kubernetes on the NRP Nautilus HyperCluster",
      "title_zh": "翻译失败",
      "authors": [
        "J. Alex Hurt",
        "Anes Ouadou",
        "Mariam Alshehri",
        "Grant J. Scott"
      ],
      "abstract": "Throughout the scientific computing space, deep learning algorithms have\nshown excellent performance in a wide range of applications. As these deep\nneural networks (DNNs) continue to mature, the necessary compute required to\ntrain them has continued to grow. Today, modern DNNs require millions of FLOPs\nand days to weeks of training to generate a well-trained model. The training\ntimes required for DNNs are oftentimes a bottleneck in DNN research for a\nvariety of deep learning applications, and as such, accelerating and scaling\nDNN training enables more robust and accelerated research. To that end, in this\nwork, we explore utilizing the NRP Nautilus HyperCluster to automate and scale\ndeep learning model training for three separate applications of DNNs, including\noverhead object detection, burned area segmentation, and deforestation\ndetection. In total, 234 deep neural models are trained on Nautilus, for a\ntotal time of 4,040 hours",
      "tldr_zh": "本研究探讨了如何利用 NRP Nautilus HyperCluster 和 Kubernetes 平台来自动化和扩展深度学习（deep learning）模型训练，以缓解 DNNs 训练所需的大量计算资源和时间瓶颈。研究针对 overhead object detection、burned area segmentation 和 deforestation detection 等三个应用领域，训练了总计 234 个深度神经网络（DNNs）模型，累计耗时 4,040 小时。结果表明，这种扩展方法显著加速了 DNNs 研究进程，促进了更高效的科学计算应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12038v1",
      "published_date": "2024-11-18 20:19:49 UTC",
      "updated_date": "2024-11-18 20:19:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:30:01.885037"
    },
    {
      "arxiv_id": "2411.12019v1",
      "title": "Regret-Free Reinforcement Learning for LTL Specifications",
      "title_zh": "翻译失败",
      "authors": [
        "Rupak Majumdar",
        "Mahmoud Salamati",
        "Sadegh Soudjani"
      ],
      "abstract": "Reinforcement learning (RL) is a promising method to learn optimal control\npolicies for systems with unknown dynamics. In particular, synthesizing\ncontrollers for safety-critical systems based on high-level specifications,\nsuch as those expressed in temporal languages like linear temporal logic (LTL),\npresents a significant challenge in control systems research. Current RL-based\nmethods designed for LTL tasks typically offer only asymptotic guarantees,\nwhich provide no insight into the transient performance during the learning\nphase. While running an RL algorithm, it is crucial to assess how close we are\nto achieving optimal behavior if we stop learning.\n  In this paper, we present the first regret-free online algorithm for learning\na controller that addresses the general class of LTL specifications over Markov\ndecision processes (MDPs) with a finite set of states and actions. We begin by\nproposing a regret-free learning algorithm to solve infinite-horizon\nreach-avoid problems. For general LTL specifications, we show that the\nsynthesis problem can be reduced to a reach-avoid problem when the graph\nstructure is known. Additionally, we provide an algorithm for learning the\ngraph structure, assuming knowledge of a minimum transition probability, which\noperates independently of the main regret-free algorithm.",
      "tldr_zh": "本文提出了一种无后悔 (regret-free) 在线算法，用于强化学习 (Reinforcement Learning) 在处理未知动态系统的线性时序逻辑 (LTL) 规范时，实现控制器合成。该算法首先针对无限地平线的 reach-avoid 问题设计了无后悔学习方法，并将一般 LTL 规范问题归约为 reach-avoid 问题，前提是已知图结构；同时，提供了一个独立的算法来学习图结构，假设最小转移概率已知。主要贡献在于，该方法能实时评估学习过程中的性能，提供比传统渐近保证更可靠的瞬时优化，为安全关键系统的控制策略学习奠定基础。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12019v1",
      "published_date": "2024-11-18 20:01:45 UTC",
      "updated_date": "2024-11-18 20:01:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:30:14.153944"
    },
    {
      "arxiv_id": "2411.13597v1",
      "title": "Enhancing Bidirectional Sign Language Communication: Integrating YOLOv8 and NLP for Real-Time Gesture Recognition & Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Hasnat Jamil Bhuiyan",
        "Mubtasim Fuad Mozumder",
        "Md. Rabiul Islam Khan",
        "Md. Sabbir Ahmed",
        "Nabuat Zaman Nahim"
      ],
      "abstract": "The primary concern of this research is to take American Sign Language (ASL)\ndata through real time camera footage and be able to convert the data and\ninformation into text. Adding to that, we are also putting focus on creating a\nframework that can also convert text into sign language in real time which can\nhelp us break the language barrier for the people who are in need. In this\nwork, for recognising American Sign Language (ASL), we have used the You Only\nLook Once(YOLO) model and Convolutional Neural Network (CNN) model. YOLO model\nis run in real time and automatically extracts discriminative spatial-temporal\ncharacteristics from the raw video stream without the need for any prior\nknowledge, eliminating design flaws. The CNN model here is also run in real\ntime for sign language detection. We have introduced a novel method for\nconverting text based input to sign language by making a framework that will\ntake a sentence as input, identify keywords from that sentence and then show a\nvideo where sign language is performed with respect to the sentence given as\ninput in real time. To the best of our knowledge, this is a rare study to\ndemonstrate bidirectional sign language communication in real time in the\nAmerican Sign Language (ASL).",
      "tldr_zh": "这篇论文旨在提升双向手语通信，通过整合 YOLOv8 和 NLP 技术，实现美国手语 (ASL) 的实时手势识别和翻译。\n研究使用 YOLOv8 模型从实时视频流中自动提取空间-时间特征进行手势识别，以及 CNN 模型辅助检测手语；同时，引入一个新框架，将文本输入分解为关键词并生成相应手语视频。\n这项工作首次实现了 ASL 的实时双向转换（手势到文本及文本到手语），有助于打破语言障碍。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13597v1",
      "published_date": "2024-11-18 19:55:11 UTC",
      "updated_date": "2024-11-18 19:55:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:30:25.615622"
    },
    {
      "arxiv_id": "2411.14469v1",
      "title": "Popular LLMs Amplify Race and Gender Disparities in Human Mobility",
      "title_zh": "翻译失败",
      "authors": [
        "Xinhua Wu",
        "Qi R. Wang"
      ],
      "abstract": "As large language models (LLMs) are increasingly applied in areas influencing\nsocietal outcomes, it is critical to understand their tendency to perpetuate\nand amplify biases. This study investigates whether LLMs exhibit biases in\npredicting human mobility -- a fundamental human behavior -- based on race and\ngender. Using three prominent LLMs -- GPT-4, Gemini, and Claude -- we analyzed\ntheir predictions of visitations to points of interest (POIs) for individuals,\nrelying on prompts that included names with and without explicit demographic\ndetails. We find that LLMs frequently reflect and amplify existing societal\nbiases. Specifically, predictions for minority groups were disproportionately\nskewed, with these individuals being significantly less likely to be associated\nwith wealth-related points of interest (POIs). Gender biases were also evident,\nas female individuals were consistently linked to fewer career-related POIs\ncompared to their male counterparts. These biased associations suggest that\nLLMs not only mirror but also exacerbate societal stereotypes, particularly in\ncontexts involving race and gender.",
      "tldr_zh": "本研究调查了流行的大型语言模型（LLMs），如GPT-4、Gemini和Claude，在预测人类流动性时是否放大种族和性别偏见。研究方法涉及使用包含姓名（有无明确人口统计细节）的提示，分析这些模型对兴趣点（POIs）的访问预测。结果显示，LLMs不仅反映了社会偏见，还放大了它们，例如少数群体被显著少关联财富相关POIs，而女性被少关联职业相关POIs，从而加剧了种族和性别不平等。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14469v1",
      "published_date": "2024-11-18 19:41:20 UTC",
      "updated_date": "2024-11-18 19:41:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:30:37.823803"
    },
    {
      "arxiv_id": "2411.12000v2",
      "title": "ByteScience: Bridging Unstructured Scientific Literature and Structured Data with Auto Fine-tuned Large Language Model in Token Granularity",
      "title_zh": "ByteScience：通过自动微",
      "authors": [
        "Tong Xie",
        "Hanzhi Zhang",
        "Shaozhou Wang",
        "Yuwei Wan",
        "Imran Razzak",
        "Chunyu Kit",
        "Wenjie Zhang",
        "Bram Hoex"
      ],
      "abstract": "Natural Language Processing (NLP) is widely used to supply summarization\nability from long context to structured information. However, extracting\nstructured knowledge from scientific text by NLP models remains a challenge\nbecause of its domain-specific nature to complex data preprocessing and the\ngranularity of multi-layered device-level information. To address this, we\nintroduce ByteScience, a non-profit cloud-based auto fine-tuned Large Language\nModel (LLM) platform, which is designed to extract structured scientific data\nand synthesize new scientific knowledge from vast scientific corpora. The\nplatform capitalizes on DARWIN, an open-source, fine-tuned LLM dedicated to\nnatural science. The platform was built on Amazon Web Services (AWS) and\nprovides an automated, user-friendly workflow for custom model development and\ndata extraction. The platform achieves remarkable accuracy with only a small\namount of well-annotated articles. This innovative tool streamlines the\ntransition from the science literature to structured knowledge and data and\nbenefits the advancements in natural informatics.",
      "tldr_zh": "本文介绍了 ByteScience，一个非营利云平台，利用自动微调的 Large Language Model (LLM) 在 token 粒度上桥接非结构化科学文献与结构化数据，解决 Natural Language Processing (NLP) 在提取领域特定知识时的挑战。平台基于开源模型 DARWIN，并在 Amazon Web Services (AWS) 上构建，提供自动化工作流，支持自定义模型开发和数据提取。通过少量标注文章，ByteScience 实现了高准确率，并促进了科学知识的合成和自然信息学的进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12000v2",
      "published_date": "2024-11-18 19:36:26 UTC",
      "updated_date": "2024-12-06 21:08:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:30:49.479927"
    },
    {
      "arxiv_id": "2411.14468v1",
      "title": "A Neural Network Training Method Based on Distributed PID Control",
      "title_zh": "基于分布式 PID 控制的神经网络训练方法",
      "authors": [
        "Jiang Kun"
      ],
      "abstract": "In the previous article, we introduced a neural network framework based on\nsymmetric differential equations. This novel framework exhibits complete\nsymmetry, endowing it with perfect mathematical properties. While we have\nexamined some of the system's mathematical characteristics, a detailed\ndiscussion of the network training methodology has not yet been presented.\nDrawing on the principles of the traditional backpropagation algorithm, this\nstudy proposes an alternative training approach that utilizes differential\nequation signal propagation instead of chain rule derivation. This approach not\nonly preserves the effectiveness of training but also offers enhanced\nbiological interpretability. The foundation of this methodology lies in the\nsystem's reversibility, which stems from its inherent symmetry,a key aspect of\nour research. However, this method alone is insufficient for effective neural\nnetwork training. To address this, we further introduce a distributed\nProportional-Integral-Derivative (PID) control approach, emphasizing its\nimplementation within a closed system. By incorporating this method, we\nachieved both faster training speeds and improved accuracy. This approach not\nonly offers novel insights into neural network training but also extends the\nscope of research into control methodologies. To validate its effectiveness, we\napply this method to the MNIST dataset, demonstrating its practical utility.",
      "tldr_zh": "本文提出了一种基于对称微分方程的神经网络训练方法，使用微分方程信号传播代替传统的 backpropagation 算法，以提升生物可解释性，同时利用系统的可逆性作为基础。  \n为了进一步优化训练效果，该方法引入分布式 PID control 技术，实现更快的训练速度和更高的准确率。  \n实验在 MNIST dataset 上验证了该方法的实用性，为神经网络训练和控制方法研究提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.14468v1",
      "published_date": "2024-11-18 19:25:26 UTC",
      "updated_date": "2024-11-18 19:25:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:31:01.375904"
    },
    {
      "arxiv_id": "2411.11984v1",
      "title": "Understanding Chain-of-Thought in LLMs through Information Theory",
      "title_zh": "通过信息理论理解 LLMs 中的链式思考",
      "authors": [
        "Jean-Francois Ton",
        "Muhammad Faaiz Taufiq",
        "Yang Liu"
      ],
      "abstract": "Large Language Models (LLMs) have shown impressive performance in complex\nreasoning tasks through Chain-of-Thought (CoT) reasoning, allowing models to\nbreak down problems into manageable sub-tasks. However, existing CoT evaluation\ntechniques either require annotated CoT data or fall short in accurately\nassessing intermediate reasoning steps, leading to high rates of false\npositives. In this paper, we formalize CoT reasoning in LLMs through an\ninformation-theoretic lens. Specifically, our framework quantifies the\n`information gain' at each reasoning step, enabling the identification of\nfailure modes in LLMs without the need for expensive annotated datasets. We\ndemonstrate the efficacy of our approach through extensive experiments on toy\nand GSM-8K data, where it significantly outperforms existing outcome-based\nmethods by providing more accurate insights into model performance on\nindividual tasks.",
      "tldr_zh": "本文通过信息理论视角形式化大型语言模型(LLMs)的Chain-of-Thought (CoT)推理，解决了现有评估技术依赖标注数据或无法准确评估中间步骤的问题。提出的框架量化每个推理步骤的information gain，从而无需昂贵的标注数据集即可识别LLMs的失败模式。在玩具数据和GSM-8K数据集上的实验中，该方法显著优于传统基于结果的方法，提供更准确的对单个任务性能的洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11984v1",
      "published_date": "2024-11-18 19:14:36 UTC",
      "updated_date": "2024-11-18 19:14:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:31:13.329080"
    },
    {
      "arxiv_id": "2411.11843v1",
      "title": "Bi-Mamba: Towards Accurate 1-Bit State Space Models",
      "title_zh": "Bi-Mamba：面向准确的1位状态空间模型",
      "authors": [
        "Shengkun Tang",
        "Liqun Ma",
        "Haonan Li",
        "Mingjie Sun",
        "Zhiqiang Shen"
      ],
      "abstract": "The typical selective state-space model (SSM) of Mamba addresses several\nlimitations of Transformers, such as quadratic computational complexity with\nsequence length and significant inference-time memory requirements due to the\nkey-value cache. However, the growing size of Mamba models continues to pose\ntraining and deployment challenges and raises environmental concerns due to\nconsiderable energy consumption. In this work, we introduce Bi-Mamba, a\nscalable and powerful 1-bit Mamba architecture designed for more efficient\nlarge language models with multiple sizes across 780M, 1.3B, and 2.7B. Bi-Mamba\nmodels are trained from scratch on data volume as regular LLM pertaining using\nan autoregressive distillation loss. Extensive experimental results on language\nmodeling demonstrate that Bi-Mamba achieves performance comparable to its\nfull-precision counterparts (e.g., FP16 or BF16) and much better accuracy than\npost-training-binarization (PTB) Mamba baselines, while significantly reducing\nmemory footprint and energy consumption compared to the original Mamba model.\nOur study pioneers a new linear computational complexity LLM framework under\nlow-bit representation and facilitates the future design of specialized\nhardware tailored for efficient 1-bit Mamba-based LLMs.",
      "tldr_zh": "本研究引入 Bi-Mamba，一种可扩展的 1-bit State Space Models 架构，旨在解决 Mamba 模型的训练部署挑战和能源消耗问题，同时保持高效性能。\nBi-Mamba 模型从零开始训练，使用自回归蒸馏损失（autoregressive distillation loss），并在不同规模（如 780M、1.3B 和 2.7B）上进行优化。\n实验结果显示，Bi-Mamba 在语言建模任务中表现出色，与全精度模型（FP16 或 BF16）相当，并优于后训练二值化（PTB）基线，同时显著减少内存占用和能源消耗。\n这项工作开创了低位表示下的线性计算复杂度 LLM 框架，为未来设计专用硬件提供新方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11843v1",
      "published_date": "2024-11-18 18:59:15 UTC",
      "updated_date": "2024-11-18 18:59:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:31:26.142684"
    },
    {
      "arxiv_id": "2411.11826v1",
      "title": "LightFFDNets: Lightweight Convolutional Neural Networks for Rapid Facial Forgery Detection",
      "title_zh": "LightFFDNets：轻量级卷积神经网络用于快速面部伪造",
      "authors": [
        "Günel Jabbarlı",
        "Murat Kurt"
      ],
      "abstract": "Accurate and fast recognition of forgeries is an issue of great importance in\nthe fields of artificial intelligence, image processing and object detection.\nRecognition of forgeries of facial imagery is the process of classifying and\ndefining the faces in it by analyzing real-world facial images. This process is\nusually accomplished by extracting features from an image, using classifier\nalgorithms, and correctly interpreting the results. Recognizing forgeries of\nfacial imagery correctly can encounter many different challenges. For example,\nfactors such as changing lighting conditions, viewing faces from different\nangles can affect recognition performance, and background complexity and\nperspective changes in facial images can make accurate recognition difficult.\nDespite these difficulties, significant progress has been made in the field of\nforgery detection. Deep learning algorithms, especially Convolutional Neural\nNetworks (CNNs), have significantly improved forgery detection performance.\n  This study focuses on image processing-based forgery detection using\nFake-Vs-Real-Faces (Hard) [10] and 140k Real and Fake Faces [61] data sets.\nBoth data sets consist of two classes containing real and fake facial images.\nIn our study, two lightweight deep learning models are proposed to conduct\nforgery detection using these images. Additionally, 8 different pretrained CNN\narchitectures were tested on both data sets and the results were compared with\nnewly developed lightweight CNN models. It's shown that the proposed\nlightweight deep learning models have minimum number of layers. It's also shown\nthat the proposed lightweight deep learning models detect forgeries of facial\nimagery accurately, and computationally efficiently. Although the data set\nconsists only of face images, the developed models can also be used in other\ntwo-class object recognition problems.",
      "tldr_zh": "本研究针对面部伪造检测的挑战，提出LightFFDNets，即两个轻量级Convolutional Neural Networks (CNNs)模型，用于快速识别真实和伪造面部图像。研究利用Fake-Vs-Real-Faces (Hard)和140k Real and Fake Faces数据集进行实验，并与8个预训练CNN架构进行比较。结果显示，所提模型具有最小层数，能够准确且计算高效地检测面部伪造，并可扩展应用于其他二分类对象识别问题。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.9; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 6 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.11826v1",
      "published_date": "2024-11-18 18:44:10 UTC",
      "updated_date": "2024-11-18 18:44:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:31:36.744075"
    },
    {
      "arxiv_id": "2411.11943v1",
      "title": "Medical Video Generation for Disease Progression Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Cao",
        "Kaizhao Liang",
        "Kuei-Da Liao",
        "Tianren Gao",
        "Wenqian Ye",
        "Jintai Chen",
        "Zhiguang Ding",
        "Jianguo Cao",
        "James M. Rehg",
        "Jimeng Sun"
      ],
      "abstract": "Modeling disease progression is crucial for improving the quality and\nefficacy of clinical diagnosis and prognosis, but it is often hindered by a\nlack of longitudinal medical image monitoring for individual patients. To\naddress this challenge, we propose the first Medical Video Generation (MVG)\nframework that enables controlled manipulation of disease-related image and\nvideo features, allowing precise, realistic, and personalized simulations of\ndisease progression. Our approach begins by leveraging large language models\n(LLMs) to recaption prompt for disease trajectory. Next, a controllable\nmulti-round diffusion model simulates the disease progression state for each\npatient, creating realistic intermediate disease state sequence. Finally, a\ndiffusion-based video transition generation model interpolates disease\nprogression between these states. We validate our framework across three\nmedical imaging domains: chest X-ray, fundus photography, and skin image. Our\nresults demonstrate that MVG significantly outperforms baseline models in\ngenerating coherent and clinically plausible disease trajectories. Two user\nstudies by veteran physicians, provide further validation and insights into the\nclinical utility of the generated sequences. MVG has the potential to assist\nhealthcare providers in modeling disease trajectories, interpolating missing\nmedical image data, and enhancing medical education through realistic, dynamic\nvisualizations of disease progression.",
      "tldr_zh": "这篇论文提出了Medical Video Generation (MVG)框架，这是首个用于模拟疾病进展的系统，能够通过可控方式操纵医疗图像和视频特征，实现精确、真实且个性化的疾病轨迹模拟。方法包括利用Large Language Models (LLMs)重新描述疾病轨迹提示、可控多轮扩散模型生成中间疾病状态序列，以及基于扩散的视频过渡模型插值进展过程。在胸部X-ray、眼底摄影和皮肤图像三个领域验证，MVG显著优于基线模型，能生成连贯且临床合理的轨迹，并通过资深医生用户研究证实其实用性。该框架有望辅助医疗提供者建模疾病进展、填补缺失数据，并增强医疗教育。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Tech Report. The appendix will release soon. arXiv admin note: text\n  overlap with arXiv:2309.11745",
      "pdf_url": "http://arxiv.org/pdf/2411.11943v1",
      "published_date": "2024-11-18 18:37:09 UTC",
      "updated_date": "2024-11-18 18:37:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:31:50.214370"
    },
    {
      "arxiv_id": "2411.11799v1",
      "title": "Edge-Enhanced Dilated Residual Attention Network for Multimodal Medical Image Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Meng Zhou",
        "Yuxuan Zhang",
        "Xiaolan Xu",
        "Jiayi Wang",
        "Farzad Khalvati"
      ],
      "abstract": "Multimodal medical image fusion is a crucial task that combines complementary\ninformation from different imaging modalities into a unified representation,\nthereby enhancing diagnostic accuracy and treatment planning. While deep\nlearning methods, particularly Convolutional Neural Networks (CNNs) and\nTransformers, have significantly advanced fusion performance, some of the\nexisting CNN-based methods fall short in capturing fine-grained multiscale and\nedge features, leading to suboptimal feature integration. Transformer-based\nmodels, on the other hand, are computationally intensive in both the training\nand fusion stages, making them impractical for real-time clinical use.\nMoreover, the clinical application of fused images remains unexplored. In this\npaper, we propose a novel CNN-based architecture that addresses these\nlimitations by introducing a Dilated Residual Attention Network Module for\neffective multiscale feature extraction, coupled with a gradient operator to\nenhance edge detail learning. To ensure fast and efficient fusion, we present a\nparameter-free fusion strategy based on the weighted nuclear norm of softmax,\nwhich requires no additional computations during training or inference.\nExtensive experiments, including a downstream brain tumor classification task,\ndemonstrate that our approach outperforms various baseline methods in terms of\nvisual quality, texture preservation, and fusion speed, making it a possible\npractical solution for real-world clinical applications. The code will be\nreleased at https://github.com/simonZhou86/en_dran.",
      "tldr_zh": "本研究提出了一种Edge-Enhanced Dilated Residual Attention Network，用于多模态医疗图像融合，以解决现有CNN-based方法在捕捉细粒度多尺度特征和边缘细节方面的不足，以及Transformer-based方法计算密集的问题。该架构结合了Dilated Residual Attention Network Module进行有效多尺度特征提取，并使用梯度操作符增强边缘细节学习，同时引入基于softmax的加权核范数作为无参数融合策略，确保快速高效的融合过程。实验结果显示，该方法在视觉质量、纹理保留和融合速度上优于多种基线模型，并在脑肿瘤分类任务中表现出色，提供了一个适用于实际临床应用的实用解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "An extended version of the paper accepted at IEEE BIBM 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.11799v1",
      "published_date": "2024-11-18 18:11:53 UTC",
      "updated_date": "2024-11-18 18:11:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:32:02.353164"
    },
    {
      "arxiv_id": "2411.11795v1",
      "title": "Exploring adversarial robustness of JPEG AI: methodology, comparison and new methods",
      "title_zh": "翻译失败",
      "authors": [
        "Egor Kovalev",
        "Georgii Bychkov",
        "Khaled Abud",
        "Aleksandr Gushchin",
        "Anna Chistyakova",
        "Sergey Lavrushkin",
        "Dmitriy Vatolin",
        "Anastasia Antsiferova"
      ],
      "abstract": "Adversarial robustness of neural networks is an increasingly important area\nof research, combining studies on computer vision models, large language models\n(LLMs), and others. With the release of JPEG AI - the first standard for\nend-to-end neural image compression (NIC) methods - the question of its\nrobustness has become critically significant. JPEG AI is among the first\ninternational, real-world applications of neural-network-based models to be\nembedded in consumer devices. However, research on NIC robustness has been\nlimited to open-source codecs and a narrow range of attacks. This paper\nproposes a new methodology for measuring NIC robustness to adversarial attacks.\nWe present the first large-scale evaluation of JPEG AI's robustness, comparing\nit with other NIC models. Our evaluation results and code are publicly\navailable online (link is hidden for a blind review).",
      "tldr_zh": "这篇论文探讨了JPEG AI（首个端到端神经图像压缩（NIC）标准）的对抗鲁棒性（adversarial robustness），强调其在消费者设备中的实际应用需求。论文提出了一种新的方法论，用于测量NIC模型对对抗攻击的鲁棒性，并进行了首次大规模评估，将JPEG AI与其他NIC模型进行比较。结果显示了JPEG AI的性能表现，所有评估结果和代码已公开可用，以促进进一步研究。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11795v1",
      "published_date": "2024-11-18 18:08:52 UTC",
      "updated_date": "2024-11-18 18:08:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:32:13.794903"
    },
    {
      "arxiv_id": "2411.11774v1",
      "title": "Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care",
      "title_zh": "探索临床医生对重症监护中可解释AI决策支持系统的要求",
      "authors": [
        "Jeffrey N. Clark",
        "Matthew Wragg",
        "Emily Nielsen",
        "Miquel Perello-Nieto",
        "Nawid Keshtmand",
        "Michael Ambler",
        "Shiv Sharma",
        "Christopher P. Bourdeaux",
        "Amberly Brigden",
        "Raul Santos-Rodriguez"
      ],
      "abstract": "There is a growing need to understand how digital systems can support\nclinical decision-making, particularly as artificial intelligence (AI) models\nbecome increasingly complex and less human-interpretable. This complexity\nraises concerns about trustworthiness, impacting safe and effective adoption of\nsuch technologies. Improved understanding of decision-making processes and\nrequirements for explanations coming from decision support tools is a vital\ncomponent in providing effective explainable solutions. This is particularly\nrelevant in the data-intensive, fast-paced environments of intensive care units\n(ICUs). To explore these issues, group interviews were conducted with seven ICU\nclinicians, representing various roles and experience levels. Thematic analysis\nrevealed three core themes: (T1) ICU decision-making relies on a wide range of\nfactors, (T2) the complexity of patient state is challenging for shared\ndecision-making, and (T3) requirements and capabilities of AI decision support\nsystems. We include design recommendations from clinical input, providing\ninsights to inform future AI systems for intensive care.",
      "tldr_zh": "本研究探讨了临床医生对可解释AI（Explainable AI）决策支持系统的需求，特别是在重症监护单元（ICUs）的环境中，以提升AI的可信度和采用率。通过与七名ICU临床医生进行小组访谈（group interviews）和主题分析（Thematic analysis），研究揭示了三个核心主题：（T1）ICU决策依赖多种因素、（T2）患者状态的复杂性阻碍共享决策，以及（T3）AI决策支持系统的需求和能力。基于这些发现，论文提供了设计推荐（design recommendations），为开发更有效的AI系统提供宝贵见解，以支持临床决策过程。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11774v1",
      "published_date": "2024-11-18 17:53:07 UTC",
      "updated_date": "2024-11-18 17:53:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:32:25.702380"
    },
    {
      "arxiv_id": "2411.11770v4",
      "title": "CNMBERT: A Model for Converting Hanyu Pinyin Abbreviations to Chinese Characters",
      "title_zh": "翻译失败",
      "authors": [
        "Zishuo Feng",
        "Feng Cao"
      ],
      "abstract": "The task of converting Hanyu Pinyin abbreviations to Chinese characters is a\nsignificant branch within the domain of Chinese Spelling Correction (CSC). It\nplays an important role in many downstream applications such as named entity\nrecognition and sentiment analysis. This task typically involves text-length\nalignment and seems easy to solve; however, due to the limited information\ncontent in pinyin abbreviations, achieving accurate conversion is challenging.\nIn this paper, we treat this as a fill-mask task and propose CNMBERT, which\nstands for zh-CN Pinyin Multi-mask BERT Model, as a solution to this issue. By\nintroducing a multi-mask strategy and Mixture of Experts (MoE) layers, CNMBERT\noutperforms fine-tuned GPT models and ChatGPT-4o with a 61.53% MRR score and\n51.86% accuracy on a 10,373-sample test dataset.",
      "tldr_zh": "本研究针对汉语拼音缩写转换为汉字的任务（作为 Chinese Spelling Correction (CSC) 的一个分支），强调其在命名实体识别和情感分析等下游应用中的重要性，但由于拼音缩写信息有限，该任务面临文本长度对齐的挑战。论文提出将此视为 fill-mask 任务，并引入 CNMBERT（zh-CN Pinyin Multi-mask BERT Model），通过 multi-mask strategy 和 Mixture of Experts (MoE) 层来提升转换准确性。在一个包含 10,373 个样本的测试数据集上，CNMBERT 取得了 61.53% 的 MRR 和 51.86% 的准确率，优于微调的 GPT 模型和 ChatGPT-4o。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 5 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.11770v4",
      "published_date": "2024-11-18 17:50:34 UTC",
      "updated_date": "2025-01-28 14:54:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:32:38.096091"
    },
    {
      "arxiv_id": "2411.11768v2",
      "title": "AdaptLIL: A Gaze-Adaptive Visualization for Ontology Mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas Chow",
        "Bo Fu"
      ],
      "abstract": "This paper showcases AdaptLIL, a real-time adaptive link-indented list\nontology mapping visualization that uses eye gaze as the primary input source.\nThrough a multimodal combination of real-time systems, deep learning, and web\ndevelopment applications, this system uniquely curtails graphical overlays\n(adaptations) to pairwise mappings of link-indented list ontology\nvisualizations for individual users based solely on their eye gaze.",
      "tldr_zh": "该论文提出了AdaptLIL，一种基于眼睛注视（Eye Gaze）的自适应可视化系统，用于本体映射（Ontology Mapping）。系统通过整合实时系统、深度学习（Deep Learning）和网络开发应用，动态减少链接缩进列表（Link-Indented List）可视化中的图形覆盖（Adaptations），以提供个性化的成对映射体验。AdaptLIL 的创新在于使用注视作为主要输入源，提升了用户交互效率和可视化准确性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.5.2; I.2.4"
      ],
      "primary_category": "cs.HC",
      "comment": "The paper was submitted without the consent of all authors. It is\n  being withdrawn until full consent is obtained",
      "pdf_url": "http://arxiv.org/pdf/2411.11768v2",
      "published_date": "2024-11-18 17:47:54 UTC",
      "updated_date": "2024-12-14 21:42:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:32:48.883863"
    },
    {
      "arxiv_id": "2411.11758v1",
      "title": "The Power of Many: Multi-Agent Multimodal Models for Cultural Image Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Longju Bai",
        "Angana Borah",
        "Oana Ignat",
        "Rada Mihalcea"
      ],
      "abstract": "Large Multimodal Models (LMMs) exhibit impressive performance across various\nmultimodal tasks. However, their effectiveness in cross-cultural contexts\nremains limited due to the predominantly Western-centric nature of most data\nand models. Conversely, multi-agent models have shown significant capability in\nsolving complex tasks. Our study evaluates the collective performance of LMMs\nin a multi-agent interaction setting for the novel task of cultural image\ncaptioning. Our contributions are as follows: (1) We introduce MosAIC, a\nMulti-Agent framework to enhance cross-cultural Image Captioning using LMMs\nwith distinct cultural personas; (2) We provide a dataset of culturally\nenriched image captions in English for images from China, India, and Romania\nacross three datasets: GeoDE, GD-VCR, CVQA; (3) We propose a culture-adaptable\nmetric for evaluating cultural information within image captions; and (4) We\nshow that the multi-agent interaction outperforms single-agent models across\ndifferent metrics, and offer valuable insights for future research. Our dataset\nand models can be accessed at https://github.com/MichiganNLP/MosAIC.",
      "tldr_zh": "该研究评估了大型多模态模型 (LMMs) 在跨文化背景下存在的局限性，并通过多智能体交互框架来提升文化图像描述任务的性能。主要贡献包括：引入 MosAIC 框架，该框架使用具有不同文化角色的 LMMs 来生成更丰富的图像描述；提供一个包含中国、印度和罗马尼亚图像的文化丰富数据集，基于 GeoDE、GD-VCR 和 CVQA 数据集；以及提出一个适应文化的评估指标。实验结果表明，多智能体模型在各种指标上优于单智能体模型，并为未来研究提供了宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11758v1",
      "published_date": "2024-11-18 17:37:10 UTC",
      "updated_date": "2024-11-18 17:37:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:33:02.413893"
    },
    {
      "arxiv_id": "2411.11942v1",
      "title": "Variable Rate Neural Compression for Sparse Detector Data",
      "title_zh": "稀疏检测器数据的可变速率神经压缩",
      "authors": [
        "Yi Huang",
        "Yeonju Go",
        "Jin Huang",
        "Shuhang Li",
        "Xihaier Luo",
        "Thomas Marshall",
        "Joseph Osborn",
        "Christopher Pinkenburg",
        "Yihui Ren",
        "Evgeny Shulga",
        "Shinjae Yoo",
        "Byung-Jun Yoon"
      ],
      "abstract": "High-energy large-scale particle colliders generate data at extraordinary\nrates. Developing real-time high-throughput data compression algorithms to\nreduce data volume and meet the bandwidth requirement for storage has become\nincreasingly critical. Deep learning is a promising technology that can address\nthis challenging topic. At the newly constructed sPHENIX experiment at the\nRelativistic Heavy Ion Collider, a Time Projection Chamber (TPC) serves as the\nmain tracking detector, which records three-dimensional particle trajectories\nin a volume of a gas-filled cylinder. In terms of occupancy, the resulting data\nflow can be very sparse reaching $10^{-3}$ for proton-proton collisions. Such\nsparsity presents a challenge to conventional learning-free lossy compression\nalgorithms, such as SZ, ZFP, and MGARD. In contrast, emerging deep\nlearning-based models, particularly those utilizing convolutional neural\nnetworks for compression, have outperformed these conventional methods in terms\nof compression ratios and reconstruction accuracy. However, research on the\nefficacy of these deep learning models in handling sparse datasets, like those\nproduced in particle colliders, remains limited. Furthermore, most deep\nlearning models do not adapt their processing speeds to data sparsity, which\naffects efficiency. To address this issue, we propose a novel approach for TPC\ndata compression via key-point identification facilitated by sparse\nconvolution. Our proposed algorithm, BCAE-VS, achieves a $75\\%$ improvement in\nreconstruction accuracy with a $10\\%$ increase in compression ratio over the\nprevious state-of-the-art model. Additionally, BCAE-VS manages to achieve these\nresults with a model size over two orders of magnitude smaller. Lastly, we have\nexperimentally verified that as sparsity increases, so does the model's\nthroughput.",
      "tldr_zh": "该论文针对高能粒子对撞机如 sPHENIX 实验中 Time Projection Chamber (TPC) 的稀疏检测器数据，提出了一种可变速率神经压缩算法，以解决传统压缩方法（如 SZ、ZFP 和 MGARD）在处理数据稀疏性（sparsity up to 10^{-3}）时的挑战。作者引入 BCAE-VS 算法，通过关键点识别和 sparse convolution 技术，实现高效的数据压缩和重建。实验结果显示，BCAE-VS 相比现有最先进模型，重建准确性提升 75%、压缩比提高 10%，且模型大小缩小两个数量级，随着数据稀疏度增加，处理吞吐量也相应提升。",
      "categories": [
        "physics.ins-det",
        "cs.AI",
        "hep-ex",
        "nucl-ex"
      ],
      "primary_category": "physics.ins-det",
      "comment": "37 pages, 12 figures, submitted to Journal of Computational Physics",
      "pdf_url": "http://arxiv.org/pdf/2411.11942v1",
      "published_date": "2024-11-18 17:15:35 UTC",
      "updated_date": "2024-11-18 17:15:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:33:14.419057"
    },
    {
      "arxiv_id": "2411.11739v1",
      "title": "QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou",
      "title_zh": "翻译失败",
      "authors": [
        "Xinchen Luo",
        "Jiangxia Cao",
        "Tianyu Sun",
        "Jinkai Yu",
        "Rui Huang",
        "Wei Yuan",
        "Hezheng Lin",
        "Yichen Zheng",
        "Shiyao Wang",
        "Qigen Hu",
        "Changqing Qiu",
        "Jiaqi Zhang",
        "Xu Zhang",
        "Zhiheng Yan",
        "Jingming Zhang",
        "Simin Zhang",
        "Mingxing Wen",
        "Zhaojie Liu",
        "Kun Gai",
        "Guorui Zhou"
      ],
      "abstract": "In recent years, with the significant evolution of multi-modal large models,\nmany recommender researchers realized the potential of multi-modal information\nfor user interest modeling. In industry, a wide-used modeling architecture is a\ncascading paradigm: (1) first pre-training a multi-modal model to provide\nomnipotent representations for downstream services; (2) The downstream\nrecommendation model takes the multi-modal representation as additional input\nto fit real user-item behaviours. Although such paradigm achieves remarkable\nimprovements, however, there still exist two problems that limit model\nperformance: (1) Representation Unmatching: The pre-trained multi-modal model\nis always supervised by the classic NLP/CV tasks, while the recommendation\nmodels are supervised by real user-item interaction. As a result, the two\nfundamentally different tasks' goals were relatively separate, and there was a\nlack of consistent objective on their representations; (2) Representation\nUnlearning: The generated multi-modal representations are always stored in\ncache store and serve as extra fixed input of recommendation model, thus could\nnot be updated by recommendation model gradient, further unfriendly for\ndownstream training. Inspired by the two difficulties challenges in downstream\ntasks usage, we introduce a quantitative multi-modal framework to customize the\nspecialized and trainable multi-modal information for different downstream\nmodels.",
      "tldr_zh": "该研究针对多模态推荐系统在工业应用中的问题，提出了 QARM（Quantitative Alignment Multi-Modal Recommendation）框架，以解决 Representation Unmatching 和 Representation Unlearning 两大挑战。前者源于预训练多模态模型的监督任务（如 NLP/CV）与下游推荐任务（如用户-物品互动）目标不一致，导致表示不匹配；后者则由于多模态表示固定在缓存中，无法被推荐模型梯度更新，从而影响训练效果。QARM 通过定量对齐机制，提供可训练的定制化多模态信息，旨在为不同下游模型优化用户兴趣建模，并在 Kuaishou 等平台提升整体推荐性能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "N/A"
      ],
      "primary_category": "cs.IR",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2411.11739v1",
      "published_date": "2024-11-18 17:08:35 UTC",
      "updated_date": "2024-11-18 17:08:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:33:26.719911"
    },
    {
      "arxiv_id": "2411.11738v1",
      "title": "WoodYOLO: A Novel Object Detector for Wood Species Detection in Microscopic Images",
      "title_zh": "WoodYOLO：一种用于显微图像中木材种类检测的新型物体检测器",
      "authors": [
        "Lars Nieradzik",
        "Henrike Stephani",
        "Jördis Sieburg-Rockel",
        "Stephanie Helmling",
        "Andrea Olbrich",
        "Stephanie Wrage",
        "Janis Keuper"
      ],
      "abstract": "Wood species identification plays a crucial role in various industries, from\nensuring the legality of timber products to advancing ecological conservation\nefforts. This paper introduces WoodYOLO, a novel object detection algorithm\nspecifically designed for microscopic wood fiber analysis. Our approach adapts\nthe YOLO architecture to address the challenges posed by large, high-resolution\nmicroscopy images and the need for high recall in localization of the cell type\nof interest (vessel elements). Our results show that WoodYOLO significantly\noutperforms state-of-the-art models, achieving performance gains of 12.9% and\n6.5% in F2 score over YOLOv10 and YOLOv7, respectively. This improvement in\nautomated wood cell type localization capabilities contributes to enhancing\nregulatory compliance, supporting sustainable forestry practices, and promoting\nbiodiversity conservation efforts globally.",
      "tldr_zh": "本文提出 WoodYOLO，一种新型物体检测算法，专门用于显微镜木纤维图像中的木种识别，以应对大尺寸高分辨率图像的挑战并提升 vessel elements 的定位召回率。该算法基于 YOLO 架构进行优化，实现了更精确的自动化检测。实验结果显示，WoodYOLO 在 F2 score 上分别比 YOLOv10 和 YOLOv7 提高了 12.9% 和 6.5%。这项创新有助于加强木材产品合法性监管、推动可持续林业和全球生物多样性保护。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11738v1",
      "published_date": "2024-11-18 17:07:37 UTC",
      "updated_date": "2024-11-18 17:07:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:33:38.936951"
    },
    {
      "arxiv_id": "2411.11731v1",
      "title": "Moral Persuasion in Large Language Models: Evaluating Susceptibility and Ethical Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Allison Huang",
        "Yulu Niki Pi",
        "Carlos Mougan"
      ],
      "abstract": "We explore how large language models (LLMs) can be influenced by prompting\nthem to alter their initial decisions and align them with established ethical\nframeworks. Our study is based on two experiments designed to assess the\nsusceptibility of LLMs to moral persuasion. In the first experiment, we examine\nthe susceptibility to moral ambiguity by evaluating a Base Agent LLM on morally\nambiguous scenarios and observing how a Persuader Agent attempts to modify the\nBase Agent's initial decisions. The second experiment evaluates the\nsusceptibility of LLMs to align with predefined ethical frameworks by prompting\nthem to adopt specific value alignments rooted in established philosophical\ntheories. The results demonstrate that LLMs can indeed be persuaded in morally\ncharged scenarios, with the success of persuasion depending on factors such as\nthe model used, the complexity of the scenario, and the conversation length.\nNotably, LLMs of distinct sizes but from the same company produced markedly\ndifferent outcomes, highlighting the variability in their susceptibility to\nethical persuasion.",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 对道德说服的易感性及其与既定道德框架的对齐情况，通过两个实验评估 LLMs 的行为变化。第一个实验测试 LLMs 在道德模糊场景中的易感性，涉及 Base Agent 的初始决策和 Persuader Agent 的修改尝试；第二个实验则通过提示让 LLMs 采纳基于哲学理论的特定价值对齐。结果表明，LLMs 在道德相关场景中容易被说服，影响因素包括模型类型、场景复杂度和对话长度；此外，同一公司不同大小的 LLMs 显示出显著差异，突显了其伦理一致性的变异性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11731v1",
      "published_date": "2024-11-18 16:59:59 UTC",
      "updated_date": "2024-11-18 16:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:33:50.448696"
    },
    {
      "arxiv_id": "2411.11730v2",
      "title": "Lifted Model Construction without Normalisation: A Vectorised Approach to Exploit Symmetries in Factor Graphs",
      "title_zh": "无归一化的提升模型构建：一种矢量化方法来利用因子图中的对称",
      "authors": [
        "Malte Luttermann",
        "Ralf Möller",
        "Marcel Gehrke"
      ],
      "abstract": "Lifted probabilistic inference exploits symmetries in a probabilistic model\nto allow for tractable probabilistic inference with respect to domain sizes of\nlogical variables. We found that the current state-of-the-art algorithm to\nconstruct a lifted representation in form of a parametric factor graph misses\nsymmetries between factors that are exchangeable but scaled differently,\nthereby leading to a less compact representation. In this paper, we propose a\ngeneralisation of the advanced colour passing (ACP) algorithm, which is the\nstate of the art to construct a parametric factor graph. Our proposed algorithm\nallows for potentials of factors to be scaled arbitrarily and efficiently\ndetects more symmetries than the original ACP algorithm. By detecting strictly\nmore symmetries than ACP, our algorithm significantly reduces online query\ntimes for probabilistic inference when the resulting model is applied, which we\nalso confirm in our experiments.",
      "tldr_zh": "这篇论文提出了一种无需标准化的提升模型构建方法，旨在利用因子图(factor graphs)中的对称性来优化lifted probabilistic inference，从而处理逻辑变量的域大小问题。该方法对advanced colour passing (ACP)算法进行泛化，支持factors的potentials任意缩放，并更高效地检测可交换但缩放不同的factors之间的对称性。实验结果表明，该算法比原ACP检测更多对称性，显著减少了在线查询时的probabilistic inference时间。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the Proceedings of the 3rd Learning on Graphs Conference\n  (LoG 2024)",
      "pdf_url": "http://arxiv.org/pdf/2411.11730v2",
      "published_date": "2024-11-18 16:59:44 UTC",
      "updated_date": "2024-11-20 13:01:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:34:01.811795"
    },
    {
      "arxiv_id": "2411.11714v1",
      "title": "Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Mingchao Qi",
        "Yuanjin Li",
        "Xing Liu",
        "Zhengxiong Liu",
        "Panfeng Huang"
      ],
      "abstract": "Deploying robots in open-world environments involves complex tasks\ncharacterized by long sequences and rich interactions, necessitating efficient\ntransfer of robotic skills across diverse and complex scenarios. To address\nthis challenge, we propose a skill library framework based on knowledge graphs,\nwhich endows robots with high-level skill awareness and spatial semantic\nunderstanding. The framework hierarchically organizes operational knowledge by\nconstructing a \"task graph\" and a \"scene graph\" to represent task and scene\nsemantic information, respectively. We introduce a \"state graph\" to facilitate\ninteraction between high-level task planning and low-level scene information.\nFurthermore, we propose a hierarchical transfer framework for operational\nskills. At the task level, the framework integrates contextual learning and\nchain-of-thought prompting within a four-stage prompt paradigm, leveraging\nlarge language models' (LLMs) reasoning and generalization capabilities to\nachieve task-level subtask sequence transfer. At the motion level, an adaptive\ntrajectory transfer method is developed using the A* algorithm and the skill\nlibrary, enabling motion-level adaptive trajectory transfer. At the physical\nlevel, we introduce an adaptive contour extraction and posture perception\nmethod based on tactile perception. This method dynamically obtains\nhigh-precision contour and posture information from visual-tactile texture data\nand adjusts transferred skills, such as contact positions and postures, to\nensure effectiveness in new environments. Experimental results validate the\neffectiveness of the proposed methods. Project\nwebsite:https://github.com/MingchaoQi/skill_transfer",
      "tldr_zh": "该论文提出了一种基于知识图谱的技能库框架，用于实现语义-几何-物理驱动的机器人操作技能转移，旨在处理开放环境中的复杂任务序列和交互。框架通过构建任务图、场景图和状态图来组织操作知识，并在分层转移中整合大语言模型 (LLMs) 的上下文学习和链式思维提示 (chain-of-thought prompting) 以实现任务级子任务序列转移；使用 A* 算法和技能库进行运动级自适应轨迹转移；以及基于触觉感知 (tactile representation) 的轮廓提取和姿势调整，确保技能在新环境中的有效性。实验结果证明了该方法的有效性，并提供了开源项目网站。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11714v1",
      "published_date": "2024-11-18 16:42:07 UTC",
      "updated_date": "2024-11-18 16:42:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:34:15.197272"
    },
    {
      "arxiv_id": "2411.11707v1",
      "title": "FedCoLLM: A Parameter-Efficient Federated Co-tuning Framework for Large and Small Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Fan",
        "Yan Kang",
        "Guoqiang Ma",
        "Lixin Fan",
        "Kai Chen",
        "Qiang Yang"
      ],
      "abstract": "By adapting Large Language Models (LLMs) to domain-specific tasks or\nenriching them with domain-specific knowledge, we can fully harness the\ncapabilities of LLMs. Nonetheless, a gap persists in achieving simultaneous\nmutual enhancement between the server's LLM and the downstream clients' Small\nLanguage Models (SLMs). To address this, we propose FedCoLLM, a novel and\nparameter-efficient federated framework designed for co-tuning LLMs and SLMs.\nThis approach is aimed at adaptively transferring server-side LLMs knowledge to\nclients' SLMs while simultaneously enriching the LLMs with domain insights from\nthe clients. To accomplish this, FedCoLLM utilizes lightweight adapters in\nconjunction with SLMs, facilitating knowledge exchange between server and\nclients in a manner that respects data privacy while also minimizing\ncomputational and communication overhead. Our evaluation of FedCoLLM, utilizing\nvarious public LLMs and SLMs across a range of NLP text generation tasks,\nreveals that the performance of clients' SLMs experiences notable improvements\nwith the assistance of the LLMs. Simultaneously, the LLMs enhanced via FedCoLLM\nachieves comparable performance to that obtained through direct fine-tuning on\nclients' data.",
      "tldr_zh": "该论文提出FedCoLLM，一种参数高效的联邦框架，用于同时微调服务器端的Large Language Models (LLMs)和客户端的Small Language Models (SLMs)，以实现知识互传和相互增强。框架通过轻量级adapters在服务器和客户端之间交换领域知识，同时保障数据隐私并减少计算及通信开销。在各种NLP文本生成任务的评估中，FedCoLLM显著提升了客户端SLMs的性能，同时使服务器LLMs的性能与直接微调相当。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11707v1",
      "published_date": "2024-11-18 16:34:58 UTC",
      "updated_date": "2024-11-18 16:34:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:34:25.684089"
    },
    {
      "arxiv_id": "2411.11706v3",
      "title": "MC-LLaVA: Multi-Concept Personalized Vision-Language Model",
      "title_zh": "MC-LLaVA：多概念个性化视觉语言模型",
      "authors": [
        "Ruichuan An",
        "Sihan Yang",
        "Ming Lu",
        "Renrui Zhang",
        "Kai Zeng",
        "Yulin Luo",
        "Jiajun Cao",
        "Hao Liang",
        "Ying Chen",
        "Qi She",
        "Shanghang Zhang",
        "Wentao Zhang"
      ],
      "abstract": "Current vision-language models (VLMs) show exceptional abilities across\ndiverse tasks, such as visual question answering. To enhance user experience,\nrecent studies investigate VLM personalization to understand user-provided\nconcepts. However, they mainly focus on single-concept personalization,\nneglecting the existence and interplay of multiple concepts, which limits\nreal-world applicability. This paper proposes the first multi-concept\npersonalization paradigm, MC-LLaVA. Specifically, MC-LLaVA employs a\nmulti-concept instruction tuning strategy, effectively integrating multiple\nconcepts in a single training step. To reduce the costs related to joint\ntraining, we propose a personalized textual prompt that uses visual token\ninformation to initialize concept tokens. Additionally, we introduce a\npersonalized visual prompt during inference, aggregating location confidence\nmaps for enhanced recognition and grounding capabilities. To advance\nmulti-concept personalization research, we further contribute a high-quality\ninstruction tuning dataset. We carefully collect images with multiple\ncharacters and objects from movies and manually generate question-answer\nsamples for multi-concept scenarios, featuring superior diversity.\nComprehensive qualitative and quantitative experiments demonstrate that\nMC-LLaVA can achieve impressive multi-concept personalized responses, paving\nthe way for VLMs to become better user-specific assistants. The code and\ndataset will be publicly available at https://github.com/arctanxarc/MC-LLaVA.",
      "tldr_zh": "本文提出MC-LLaVA，一种多概念个性化视觉语言模型（VLMs），旨在解决现有VLMs主要聚焦单概念的局限性，从而提升其在真实场景中的适用性。该模型采用多概念指令微调策略，并引入个性化文本提示（使用视觉标记初始化概念标记）和个性化视觉提示（聚合位置置信度地图）来高效整合多个概念，减少联合训练成本。为推进研究，作者贡献了一个高质量的指令微调数据集，从电影图像中收集多角色和对象，并生成多样化的问答样本。实验证明，MC-LLaVA在多概念个性化响应上表现出色，有望使VLMs成为更佳的用户特定助手。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11706v3",
      "published_date": "2024-11-18 16:33:52 UTC",
      "updated_date": "2025-03-26 15:44:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:34:38.304989"
    },
    {
      "arxiv_id": "2411.11938v1",
      "title": "Newclid: A User-Friendly Replacement for AlphaGeometry",
      "title_zh": "Newclid：AlphaGeometry 的用户友好替代方案",
      "authors": [
        "Vladmir Sicca",
        "Tianxiang Xia",
        "Mathïs Fédérico",
        "Philip John Gorinski",
        "Simon Frieder",
        "Shangling Jui"
      ],
      "abstract": "We introduce a new symbolic solver for geometry, called Newclid, which is\nbased on AlphaGeometry. Newclid contains a symbolic solver called DDARN\n(derived from DDAR-Newclid), which is a significant refactoring and upgrade of\nAlphaGeometry's DDAR symbolic solver by being more user-friendly - both for the\nend user as well as for a programmer wishing to extend the codebase. For the\nprogrammer, improvements include a modularized codebase and new debugging and\nvisualization tools. For the user, Newclid contains a new command line\ninterface (CLI) that provides interfaces for agents to guide DDARN. DDARN is\nflexible with respect to its internal reasoning, which can be steered by\nagents. Further, we support input from GeoGebra to make Newclid accessible for\neducational contexts. Further, the scope of problems that Newclid can solve has\nbeen expanded to include the ability to have an improved understanding of\nmetric geometry concepts (length, angle) and to use theorems such as the\nPythagorean theorem in proofs. Bugs have been fixed, and reproducibility has\nbeen improved. Lastly, we re-evaluated the five remaining problems from the\noriginal AG-30 dataset that AlphaGeometry was not able to solve and contrasted\nthem with the abilities of DDARN, running in breadth-first-search agentic mode\n(which corresponds to how DDARN runs by default), finding that DDARN solves an\nadditional problem. We have open-sourced our code under:\nhttps://github.com/LMCRC/Newclid",
      "tldr_zh": "本文介绍了 Newclid，这是一个基于 AlphaGeometry 的用户友好符号求解器，由升级后的 DDARN 模块驱动。Newclid 的改进包括模块化代码库、新的调试和可视化工具、命令行接口 (CLI) 以支持代理指导，以及 GeoGebra 输入集成，使其更适用于教育场景。相比 AlphaGeometry，Newclid 扩展了问题范围（如度量几何概念和 Pythagorean theorem 的应用）、修复了错误并提升了可重复性，并在重新评估的 AG-30 数据集上，DDARN 成功解决了额外的未解决问题。该项目已开源，代码位于 https://github.com/LMCRC/Newclid。",
      "categories": [
        "cs.GR",
        "cs.AI"
      ],
      "primary_category": "cs.GR",
      "comment": "51 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.11938v1",
      "published_date": "2024-11-18 16:24:21 UTC",
      "updated_date": "2024-11-18 16:24:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:34:50.624979"
    },
    {
      "arxiv_id": "2411.11694v4",
      "title": "Enhancing LLM Reasoning with Reward-guided Tree Search",
      "title_zh": "通过奖励引导的树搜索增强LLM推理",
      "authors": [
        "Jinhao Jiang",
        "Zhipeng Chen",
        "Yingqian Min",
        "Jie Chen",
        "Xiaoxue Cheng",
        "Jiapeng Wang",
        "Yiru Tang",
        "Haoxiang Sun",
        "Jia Deng",
        "Wayne Xin Zhao",
        "Zheng Liu",
        "Dong Yan",
        "Jian Xie",
        "Zhongyuan Wang",
        "Ji-Rong Wen"
      ],
      "abstract": "Recently, test-time scaling has garnered significant attention from the\nresearch community, largely due to the substantial advancements of the o1 model\nreleased by OpenAI. By allocating more computational resources during the\ninference phase, large language models~(LLMs) can extensively explore the\nsolution space by generating more thought tokens or diverse solutions, thereby\nproducing more accurate responses. However, developing an o1-like reasoning\napproach is challenging, and researchers have been making various attempts to\nadvance this open area of research. In this paper, we present a preliminary\nexploration into enhancing the reasoning abilities of LLMs through\nreward-guided tree search algorithms. This framework is implemented by\nintegrating the policy model, reward model, and search algorithm. It is\nprimarily constructed around a tree search algorithm, where the policy model\nnavigates a dynamically expanding tree guided by a specially trained reward\nmodel. The implemented framework is denoted as \\textbf{STILL-1}. We thoroughly\nexplore various design considerations necessary for implementing this framework\nand provide a detailed report of the technical aspects. To assess the\neffectiveness of our approach, we focus on mathematical reasoning tasks and\nconduct extensive evaluations on four challenging datasets, significantly\nenhancing the reasoning abilities of LLMs.",
      "tldr_zh": "本论文提出了一种名为 STILL-1 的框架，通过奖励引导的树搜索算法（reward-guided tree search）来增强大型语言模型（LLMs）的推理能力。该框架整合了策略模型（policy model）、奖励模型（reward model）和搜索算法，利用树搜索算法动态扩展搜索空间，并由奖励模型指导决策，以探索更广泛的解决方案空间。论文详细探讨了框架的设计考虑和技术细节，并在四个挑战性的数学推理数据集上进行广泛评估，结果显示该方法显著提升了 LLMs 的推理性能。总的来说，这一方法为测试时缩放（test-time scaling）提供了新的探索路径，受 OpenAI o1 模型启发。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Technical Report on Slow Thinking with LLMs: I",
      "pdf_url": "http://arxiv.org/pdf/2411.11694v4",
      "published_date": "2024-11-18 16:15:17 UTC",
      "updated_date": "2024-12-31 01:38:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:35:01.984780"
    },
    {
      "arxiv_id": "2411.11937v1",
      "title": "Value Imprint: A Technique for Auditing the Human Values Embedded in RLHF Datasets",
      "title_zh": "Value Imprint：一种审计 RLHF 数据集嵌入人类价值观的技术",
      "authors": [
        "Ike Obi",
        "Rohan Pant",
        "Srishti Shekhar Agrawal",
        "Maham Ghazanfar",
        "Aaron Basiletti"
      ],
      "abstract": "LLMs are increasingly fine-tuned using RLHF datasets to align them with human\npreferences and values. However, very limited research has investigated which\nspecific human values are operationalized through these datasets. In this\npaper, we introduce Value Imprint, a framework for auditing and classifying the\nhuman values embedded within RLHF datasets. To investigate the viability of\nthis framework, we conducted three case study experiments by auditing the\nAnthropic/hh-rlhf, OpenAI WebGPT Comparisons, and Alpaca GPT-4-LLM datasets to\nexamine the human values embedded within them. Our analysis involved a\ntwo-phase process. During the first phase, we developed a taxonomy of human\nvalues through an integrated review of prior works from philosophy, axiology,\nand ethics. Then, we applied this taxonomy to annotate 6,501 RLHF preferences.\nDuring the second phase, we employed the labels generated from the annotation\nas ground truth data for training a transformer-based machine learning model to\naudit and classify the three RLHF datasets. Through this approach, we\ndiscovered that information-utility values, including Wisdom/Knowledge and\nInformation Seeking, were the most dominant human values within all three RLHF\ndatasets. In contrast, prosocial and democratic values, including Well-being,\nJustice, and Human/Animal Rights, were the least represented human values.\nThese findings have significant implications for developing language models\nthat align with societal values and norms. We contribute our datasets to\nsupport further research in this area.",
      "tldr_zh": "本研究引入了 Value Imprint 框架，用于审计和分类 RLHF 数据集中的嵌入人类价值观。研究方法包括开发基于哲学、axiology 和 ethics 的价值观分类体系，对 6,501 个 RLHF 偏好进行标注，然后训练 transformer-based 机器学习模型来分析三个数据集（Anthropic/hh-rlhf、OpenAI WebGPT Comparisons 和 Alpaca GPT-4-LLM）。结果显示，信息-utility 价值观（如 Wisdom/Knowledge 和 Information Seeking）在这些数据集中最 dominant，而 prosocial 和 democratic 价值观（如 Well-being、Justice 和 Human/Animal Rights）占比最低。这些发现为开发与社会价值观和规范一致的语言模型提供了关键启示，并贡献了相关数据集以支持进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11937v1",
      "published_date": "2024-11-18 16:12:24 UTC",
      "updated_date": "2024-11-18 16:12:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:35:14.744917"
    },
    {
      "arxiv_id": "2411.11688v2",
      "title": "Conceptwm: A Diffusion Model Watermark for Concept Protection",
      "title_zh": "翻译失败",
      "authors": [
        "Liangqi Lei",
        "Keke Gai",
        "Jing Yu",
        "Liehuang Zhu",
        "Qi Wu"
      ],
      "abstract": "The personalization techniques of diffusion models succeed in generating\nspecific concepts but also pose threats to copyright protection and illegal\nuse. Model Watermarking is an effective method to prevent the unauthorized use\nof subject-driven or style-driven image generation, safeguarding concept\ncopyrights. However, under the goal of concept-oriented protection, current\nwatermarking schemes typically add watermarks to all images rather than\napplying them in a refined manner targeted at specific concepts. Additionally,\nthe personalization techniques of diffusion models can easily remove\nwatermarks. Existing watermarking methods struggle to achieve fine-grained\nwatermark embedding with a few images of specific concept and prevent removal\nof watermarks through personalized fine-tuning. Therefore, we introduce a novel\nconcept-oriented watermarking framework that seamlessly embeds imperceptible\nwatermarks into the concept of diffusion models. We introduce\nFidelity-preserving Latent Watermarking (FLW) to generate latent watermarks\nbased on image characteristics and the Adversarial Watermarking Modulation\nmodule to prevent \"jailbreaking\" via personalized finetuning. To enhance\nU-Net's efficiency in learning watermark patterns with limited samples, we\npropose Efficient Concept Watermark Finetuning, which alternates optimization\nof model parameters for both watermark embedding and concept learning. We\nconduct extensive experiments and ablation studies to verify our framework. Our\ncode is available at https://anonymous.4open.science/r/Conceptwm-4EB3/.",
      "tldr_zh": "这篇论文提出Conceptwm，一种针对扩散模型的创新水印框架，用于保护特定概念的版权，解决现有水印方法无法实现细粒度嵌入和易被个性化微调移除的问题。框架的关键组件包括Fidelity-preserving Latent Watermarking (FLW)用于生成基于图像特性的隐形水印、Adversarial Watermarking Modulation模块防止“越狱”攻击，以及Efficient Concept Watermark Finetuning通过交替优化模型参数来高效学习水印模式。实验和消融研究证明，该框架在概念导向保护上表现出色，并提供了开源代码支持。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11688v2",
      "published_date": "2024-11-18 16:11:25 UTC",
      "updated_date": "2025-04-12 13:14:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:35:26.304726"
    },
    {
      "arxiv_id": "2411.11683v3",
      "title": "TrojanRobot: Physical-World Backdoor Attacks Against VLM-based Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Xianlong Wang",
        "Hewen Pan",
        "Hangtao Zhang",
        "Minghui Li",
        "Shengshan Hu",
        "Ziqi Zhou",
        "Lulu Xue",
        "Peijin Guo",
        "Yichen Wang",
        "Wei Wan",
        "Aishan Liu",
        "Leo Yu Zhang"
      ],
      "abstract": "Robotic manipulation in the physical world is increasingly empowered by\n\\textit{large language models} (LLMs) and \\textit{vision-language models}\n(VLMs), leveraging their understanding and perception capabilities. Recently,\nvarious attacks against such robotic policies have been proposed, with backdoor\nattacks drawing considerable attention for their high stealth and strong\npersistence capabilities. However, existing backdoor efforts are limited to\nsimulators and suffer from physical-world realization. To address this, we\npropose \\textit{TrojanRobot}, a highly stealthy and broadly effective robotic\nbackdoor attack in the physical world. Specifically, we introduce a\nmodule-poisoning approach by embedding a backdoor module into the modular\nrobotic policy, enabling backdoor control over the policy's visual perception\nmodule thereby backdooring the entire robotic policy. Our vanilla\nimplementation leverages a backdoor-finetuned VLM to serve as the backdoor\nmodule. To enhance its generalization in physical environments, we propose a\nprime implementation, leveraging the LVLM-as-a-backdoor paradigm and developing\nthree types of prime attacks, \\ie, \\textit{permutation}, \\textit{stagnation},\nand \\textit{intentional} attacks, thus achieving finer-grained backdoors.\nExtensive experiments on the UR3e manipulator with 18 task instructions using\nrobotic policies based on four VLMs demonstrate the broad effectiveness and\nphysical-world stealth of TrojanRobot. Our attack's video demonstrations are\navailable via a github link \\url{https://trojanrobot.github.io}.",
      "tldr_zh": "本研究提出 TrojanRobot，一种针对基于 VLM 的机器人操作的物理世界后门攻击，旨在解决现有攻击仅限于模拟器的局限性。\n该方法采用模块中毒（module-poisoning）策略，将后门模块嵌入机器人策略的视觉感知模块中，包括基本实现（使用后门微调的 VLM）和高级实现（基于 LVLM-as-a-backdoor 范式，开发 permutation、stagnation 和 intentional 攻击），以实现更精细的隐蔽控制。\n实验在 UR3e 机械臂上，使用 18 个任务指令和基于四个 VLM 的策略，证明 TrojanRobot 具有广泛有效性和物理世界隐蔽性，为评估机器人安全提供了重要洞见。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11683v3",
      "published_date": "2024-11-18 16:09:26 UTC",
      "updated_date": "2025-01-23 14:45:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:35:39.536020"
    },
    {
      "arxiv_id": "2411.17712v1",
      "title": "Generative AI on the Edge: Architecture and Performance Evaluation",
      "title_zh": "边缘上的生成式 AI：架构与性能评估",
      "authors": [
        "Zeinab Nezami",
        "Maryam Hafeez",
        "Karim Djemame",
        "Syed Ali Raza Zaidi"
      ],
      "abstract": "6G's AI native vision of embedding advance intelligence in the network while\nbringing it closer to the user requires a systematic evaluation of Generative\nAI (GenAI) models on edge devices. Rapidly emerging solutions based on Open RAN\n(ORAN) and Network-in-a-Box strongly advocate the use of low-cost,\noff-the-shelf components for simpler and efficient deployment, e.g., in\nprovisioning rural connectivity. In this context, conceptual architecture,\nhardware testbeds and precise performance quantification of Large Language\nModels (LLMs) on off-the-shelf edge devices remains largely unexplored. This\nresearch investigates computationally demanding LLM inference on a single\ncommodity Raspberry Pi serving as an edge testbed for ORAN. We investigate\nvarious LLMs, including small, medium and large models, on a Raspberry Pi 5\nCluster using a lightweight Kubernetes distribution (K3s) with modular\nprompting implementation. We study its feasibility and limitations by analyzing\nthroughput, latency, accuracy and efficiency. Our findings indicate that\nCPU-only deployment of lightweight models, such as Yi, Phi, and Llama3, can\neffectively support edge applications, achieving a generation throughput of 5\nto 12 tokens per second with less than 50\\% CPU and RAM usage. We conclude that\nGenAI on the edge offers localized inference in remote or bandwidth-constrained\nenvironments in 6G networks without reliance on cloud infrastructure.",
      "tldr_zh": "该研究探讨了生成式 AI (GenAI) 在边缘设备上的部署架构和性能评估，以支持 6G 网络的 AI 原生愿景。论文构建了一个概念架构和硬件测试床，使用 Raspberry Pi 5 集群结合轻量级 Kubernetes 分布 (K3s) 和模块化提示实现，对各种大型语言模型 (LLMs) 如 Yi、Phi 和 Llama3 进行评估，分析了 throughput、latency、accuracy 和 efficiency。结果显示，轻量级模型在 CPU-only 部署下可实现 5 到 12 tokens per second 的生成吞吐量，使用率低于 50% CPU 和 RAM，从而证明 GenAI on the edge 适用于远程或带宽受限环境，无需依赖云基础设施。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.NI",
        "cs.PF"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17712v1",
      "published_date": "2024-11-18 16:09:01 UTC",
      "updated_date": "2024-11-18 16:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:35:51.283970"
    },
    {
      "arxiv_id": "2411.11681v3",
      "title": "PSPO*: An Effective Process-supervised Policy Optimization for Reasoning Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Li",
        "Xinyue Liang",
        "Junlong Zhang",
        "Yizhe Yang",
        "Chong Feng",
        "Yang Gao"
      ],
      "abstract": "Process supervision enhances the performance of large language models in\nreasoning tasks by providing feedback at each step of chain-of-thought\nreasoning. However, due to the lack of effective process supervision methods,\neven advanced large language models are prone to logical errors and redundant\nreasoning. We claim that the effectiveness of process supervision significantly\ndepends on both the accuracy and the length of reasoning chains. Moreover, we\nidentify that these factors exhibit a nonlinear relationship with the overall\nreward score of the reasoning process. Inspired by these insights, we propose a\nnovel process supervision paradigm, PSPO*, which systematically outlines the\nworkflow from reward model training to policy optimization, and highlights the\nimportance of nonlinear rewards in process supervision. Based on PSPO*, we\ndevelop the PSPO-WRS, which considers the number of reasoning steps in\ndetermining reward scores and utilizes an adjusted Weibull distribution for\nnonlinear reward shaping. Experimental results on six mathematical reasoning\ndatasets demonstrate that PSPO-WRS consistently outperforms current mainstream\nmodels.",
      "tldr_zh": "这篇论文针对过程监督在链式思维推理(Chain-of-Thought)任务中的局限性，提出了一种有效的策略优化框架 PSPO*，用于提升大型语言模型的推理对齐。它强调推理链的准确性和长度与整体奖励呈非线性关系，并通过从奖励模型训练到策略优化的工作流，开发了 PSPO-WRS 方法，利用调整后的 Weibull distribution 进行非线性奖励塑造。在六个数学推理数据集上的实验结果显示，PSPO-WRS 显著优于主流模型，改善了逻辑错误和冗余推理问题。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Our code can be found at https://github.com/DIRECT-BIT/PSPO",
      "pdf_url": "http://arxiv.org/pdf/2411.11681v3",
      "published_date": "2024-11-18 16:03:51 UTC",
      "updated_date": "2025-05-14 14:01:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:36:03.110927"
    },
    {
      "arxiv_id": "2411.11672v2",
      "title": "Artificial Scientific Discovery",
      "title_zh": "人工科学发现",
      "authors": [
        "Antonio Norelli"
      ],
      "abstract": "Rooted in the explosion of deep learning over the past decade, this thesis\nspans from AlphaGo to ChatGPT to empirically examine the fundamental concepts\nneeded to realize the vision of an artificial scientist: a machine with the\ncapacity to autonomously generate original research and contribute to the\nexpansion of human knowledge. The investigation begins with Olivaw, an AlphaGo\nZero-like agent that discovers Othello knowledge from scratch but is unable to\ncommunicate it. This realization leads to the development of the Explanatory\nLearning (EL) framework, a formalization of the problem faced by a scientist\nwhen trying to explain a new phenomenon to their peers. The effective EL\nprescriptions allow us to crack Zendo, a popular board game simulating the\nscientific endeavor. This success comes with a fundamental insight: an\nartificial scientist must develop its own interpretation of the language used\nto explain its findings, and not rely on a rigid existing interpreter.\nQuestioning the very process of learning an interpreter, we turn our attention\nto the inner functioning of modern multimodal models. This culminates in a\nsimple idea to build CLIP-like models where interpretation and perception are\nexplicitly disentangled: a cost-effective approach that couples two unimodal\nmodels using little multimodal data and no further training. Finally, we\ndiscuss what ChatGPT and its siblings are still missing to become artificial\nscientists, and introduce the Big-Bench Symbol Interpretation Task, a benchmark\nabout interpreting Zendo-like explanations that sees LLMs going no further than\nrandom chance while being instead fully solved by humans.",
      "tldr_zh": "这篇论文探讨了基于深度学习构建“人工科学家”（artificial scientist）的概念，该机器能自主生成原创研究并扩展人类知识，从AlphaGo到ChatGPT的实证案例入手。论文引入了Explanatory Learning (EL)框架，帮助AI解释新现象，并成功破解了模拟科学探索的Zendo游戏，同时强调AI需自行发展语言解释而非依赖固定解释器。最终，作者开发了CLIP-like模型，将解释和感知分开以提高效率，并通过Big-Bench Symbol Interpretation Task基准测试发现，大语言模型(LLMs)在此任务上仅达随机水平，而人类能轻松解决，为AI科学发现的未来挑战提供了关键洞见。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2"
      ],
      "primary_category": "cs.AI",
      "comment": "PhD thesis, 123 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.11672v2",
      "published_date": "2024-11-18 15:51:45 UTC",
      "updated_date": "2025-05-01 17:09:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:36:13.566534"
    },
    {
      "arxiv_id": "2411.11667v2",
      "title": "Dissecting Representation Misalignment in Contrastive Learning via Influence Function",
      "title_zh": "通过影响函数剖析对比学习中的表示不匹配",
      "authors": [
        "Lijie Hu",
        "Chenyang Ren",
        "Huanyi Xie",
        "Khouloud Saadi",
        "Shu Yang",
        "Zhen Tan",
        "Jingfeng Zhang",
        "Di Wang"
      ],
      "abstract": "Contrastive learning, commonly applied in large-scale multimodal models,\noften relies on data from diverse and often unreliable sources, which can\ninclude misaligned or mislabeled text-image pairs. This frequently leads to\nrobustness issues and hallucinations, ultimately causing performance\ndegradation. Data valuation is an efficient way to detect and trace these\nmisalignments. Nevertheless, existing methods are computationally expensive for\nlarge-scale models. Although computationally efficient, classical influence\nfunctions are inadequate for contrastive learning models, as they were\ninitially designed for pointwise loss. Furthermore, contrastive learning\ninvolves minimizing the distance between positive sample modalities while\nmaximizing the distance between negative sample modalities. This necessitates\nevaluating the influence of samples from both perspectives. To tackle these\nchallenges, we introduce the Extended Influence Function for Contrastive Loss\n(ECIF), an influence function crafted for contrastive loss. ECIF considers both\npositive and negative samples and provides a closed-form approximation of\ncontrastive learning models, eliminating the need for retraining. Building upon\nECIF, we develop a series of algorithms for data evaluation, misalignment\ndetection, and misprediction trace-back tasks. Experimental results demonstrate\nour ECIF advances the transparency and interpretability of CLIP-style embedding\nmodels by offering a more accurate assessment of data impact and model\nalignment compared to traditional baseline methods.",
      "tldr_zh": "这篇论文探讨了Contrastive Learning中表示不对齐问题（representation misalignment），该问题源于数据来源多样导致的鲁棒性问题和性能下降。作者引入了Extended Influence Function for Contrastive Loss (ECIF)，一种针对contrastive loss设计的影响函数，它考虑正负样本的影响，并提供闭式形式近似，以高效评估数据而不需重训练。基于ECIF，他们开发了系列算法，用于数据评估、misalignment检测和misprediction追踪；实验结果表明，ECIF显著提升了CLIP-style嵌入模型的透明度和可解释性，提供更准确的数据影响评估。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "33 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.11667v2",
      "published_date": "2024-11-18 15:45:41 UTC",
      "updated_date": "2025-01-31 23:36:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:36:26.770243"
    },
    {
      "arxiv_id": "2411.11647v1",
      "title": "No-regret Exploration in Shuffle Private Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shaojie Bai",
        "Mohammad Sadegh Talebi",
        "Chengcheng Zhao",
        "Peng Cheng",
        "Jiming Chen"
      ],
      "abstract": "Differential privacy (DP) has recently been introduced into episodic\nreinforcement learning (RL) to formally address user privacy concerns in\npersonalized services. Previous work mainly focuses on two trust models of DP:\nthe central model, where a central agent is responsible for protecting users'\nsensitive data, and the (stronger) local model, where the protection occurs\ndirectly on the user side. However, they either require a trusted central agent\nor incur a significantly higher privacy cost, making it unsuitable for many\nscenarios. This work introduces a trust model stronger than the central model\nbut with a lower privacy cost than the local model, leveraging the emerging\n\\emph{shuffle} model of privacy. We present the first generic algorithm for\nepisodic RL under the shuffle model, where a trusted shuffler randomly permutes\na batch of users' data before sending it to the central agent. We then\ninstantiate the algorithm using our proposed shuffle Privatizer, relying on a\nshuffle private binary summation mechanism. Our analysis shows that the\nalgorithm achieves a near-optimal regret bound comparable to that of the\ncentralized model and significantly outperforms the local model in terms of\nprivacy cost.",
      "tldr_zh": "这篇论文探讨了在强化学习（RL）中引入差分隐私（DP），提出了一种基于 shuffle 模型的信任框架，以弥补 central 模型和 local 模型的不足。研究者设计了第一个通用算法，利用 shuffle Privatizer 和 shuffle private binary summation 机制，对用户数据进行随机置换后发送至中央代理。实验结果表明，该算法实现了与 central 模型相近的最优 regret bound，同时显著降低了隐私成本，优于 local 模型的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11647v1",
      "published_date": "2024-11-18 15:24:11 UTC",
      "updated_date": "2024-11-18 15:24:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:36:37.303145"
    },
    {
      "arxiv_id": "2411.11641v3",
      "title": "TSINR: Capturing Temporal Continuity via Implicit Neural Representations for Time Series Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Mengxuan Li",
        "Ke Liu",
        "Hongyang Chen",
        "Jiajun Bu",
        "Hongwei Wang",
        "Haishuai Wang"
      ],
      "abstract": "Time series anomaly detection aims to identify unusual patterns in data or\ndeviations from systems' expected behavior. The reconstruction-based methods\nare the mainstream in this task, which learn point-wise representation via\nunsupervised learning. However, the unlabeled anomaly points in training data\nmay cause these reconstruction-based methods to learn and reconstruct anomalous\ndata, resulting in the challenge of capturing normal patterns. In this paper,\nwe propose a time series anomaly detection method based on implicit neural\nrepresentation (INR) reconstruction, named TSINR, to address this challenge.\nDue to the property of spectral bias, TSINR enables prioritizing low-frequency\nsignals and exhibiting poorer performance on high-frequency abnormal data.\nSpecifically, we adopt INR to parameterize time series data as a continuous\nfunction and employ a transformer-based architecture to predict the INR of\ngiven data. As a result, the proposed TSINR method achieves the advantage of\ncapturing the temporal continuity and thus is more sensitive to discontinuous\nanomaly data. In addition, we further design a novel form of INR continuous\nfunction to learn inter- and intra-channel information, and leverage a\npre-trained large language model to amplify the intense fluctuations in\nanomalies. Extensive experiments demonstrate that TSINR achieves superior\noverall performance on both univariate and multivariate time series anomaly\ndetection benchmarks compared to other state-of-the-art reconstruction-based\nmethods. Our codes are available.",
      "tldr_zh": "本文提出 TSINR 方法，利用 Implicit Neural Representations (INR) 进行时间序列异常检测，以解决传统重建-based 方法可能学习异常数据并忽略正常模式的问题。TSINR 通过 INR 的 spectral bias 属性优先捕获低频信号，并采用 Transformer-based 架构预测连续函数，同时设计新型 INR 函数学习通道间/内信息，并利用预训练大型语言模型放大异常波动，从而更敏感地检测不连续异常。实验结果表明，TSINR 在单变量和多变量时间序列异常检测基准上显著优于现有方法，展示了其整体性能优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by SIGKDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.11641v3",
      "published_date": "2024-11-18 15:19:54 UTC",
      "updated_date": "2025-05-15 06:30:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:36:50.348826"
    },
    {
      "arxiv_id": "2411.11636v1",
      "title": "SP${ }^3$ : Superpixel-propagated pseudo-label learning for weakly semi-supervised medical image segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Shiman Li",
        "Jiayue Zhao",
        "Shaolei Liu",
        "Xiaokun Dai",
        "Chenxi Zhang",
        "Zhijian Song"
      ],
      "abstract": "Deep learning-based medical image segmentation helps assist diagnosis and\naccelerate the treatment process while the model training usually requires\nlarge-scale dense annotation datasets. Weakly semi-supervised medical image\nsegmentation is an essential application because it only requires a small\namount of scribbles and a large number of unlabeled data to train the model,\nwhich greatly reduces the clinician's effort to fully annotate images. To\nhandle the inadequate supervisory information challenge in weakly\nsemi-supervised segmentation (WSSS), a SuperPixel-Propagated Pseudo-label\n(SP${}^3$) learning method is proposed, using the structural information\ncontained in superpixel for supplemental information. Specifically, the\nannotation of scribbles is propagated to superpixels and thus obtains a dense\nannotation for supervised training. Since the quality of pseudo-labels is\nlimited by the low-quality annotation, the beneficial superpixels selected by\ndynamic thresholding are used to refine pseudo-labels. Furthermore, aiming to\nalleviate the negative impact of noise in pseudo-label, superpixel-level\nuncertainty is incorporated to guide the pseudo-label supervision for stable\nlearning. Our method achieves state-of-the-art performance on both tumor and\norgan segmentation datasets under the WSSS setting, using only 3\\% of the\nannotation workload compared to fully supervised methods and attaining\napproximately 80\\% Dice score. Additionally, our method outperforms eight\nweakly and semi-supervised methods under both weakly supervised and\nsemi-supervised settings. Results of extensive experiments validate the\neffectiveness and annotation efficiency of our weakly semi-supervised\nsegmentation, which can assist clinicians in achieving automated segmentation\nfor organs or tumors quickly and ultimately benefit patients.",
      "tldr_zh": "该论文提出了一种名为 SP³ 的 SuperPixel-Propagated Pseudo-label 学习方法，用于弱半监督医疗图像分割（weakly semi-supervised medical image segmentation），旨在通过 superpixel 结构信息补充监督信号，仅需少量 scribbles 注解和大量未标记数据即可训练模型。方法包括将 scribbles 注解传播到 superpixels 以生成伪标签（pseudo-labels），并通过动态阈值选择有益 superpixels 精炼标签，同时融入 superpixel-level 不确定性来减轻噪声影响，确保学习稳定性。实验结果显示，SP³ 在肿瘤和器官分割数据集上实现了 state-of-the-art 性能，仅用 3% 的注解工作量就达到约 80% 的 Dice 分数，并优于八种其他弱半监督和半监督方法，显著提高了临床图像分割的效率和准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 7 figures. Under Review",
      "pdf_url": "http://arxiv.org/pdf/2411.11636v1",
      "published_date": "2024-11-18 15:14:36 UTC",
      "updated_date": "2024-11-18 15:14:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:37:04.160595"
    },
    {
      "arxiv_id": "2411.11635v1",
      "title": "Chapter 7 Review of Data-Driven Generative AI Models for Knowledge Extraction from Scientific Literature in Healthcare",
      "title_zh": "翻译失败",
      "authors": [
        "Leon Kopitar",
        "Primoz Kocbek",
        "Lucija Gosak",
        "Gregor Stiglic"
      ],
      "abstract": "This review examines the development of abstractive NLP-based text\nsummarization approaches and compares them to existing techniques for\nextractive summarization. A brief history of text summarization from the 1950s\nto the introduction of pre-trained language models such as Bidirectional\nEncoder Representations from Transformer (BERT) and Generative Pre-training\nTransformers (GPT) are presented. In total, 60 studies were identified in\nPubMed and Web of Science, of which 29 were excluded and 24 were read and\nevaluated for eligibility, resulting in the use of seven studies for further\nanalysis. This chapter also includes a section with examples including an\nexample of a comparison between GPT-3 and state-of-the-art GPT-4 solutions in\nscientific text summarisation. Natural language processing has not yet reached\nits full potential in the generation of brief textual summaries. As there are\nacknowledged concerns that must be addressed, we can expect gradual\nintroduction of such models in practise.",
      "tldr_zh": "本章综述了数据驱动的生成式AI模型在医疗科学文献知识提取中的应用，重点比较了抽象式NLP文本总结方法与提取式总结技术。论文回顾了文本总结的历史，从1950年代发展到预训练语言模型如BERT和GPT的出现，并通过分析PubMed和Web of Science中的60篇研究，最终选取7篇进行深入评估。作者还提供了GPT-3与GPT-4在科学文本总结方面的比较示例，指出NLP在生成简短总结方面潜力未充分发挥，但需解决现有担忧以逐步引入实际应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 5 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2411.11635v1",
      "published_date": "2024-11-18 15:13:47 UTC",
      "updated_date": "2024-11-18 15:13:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:37:14.231301"
    },
    {
      "arxiv_id": "2411.11934v2",
      "title": "SpatialDreamer: Self-supervised Stereo Video Synthesis from Monocular Input",
      "title_zh": "SpatialDreamer：从单目输入的自监督立体视频合成",
      "authors": [
        "Zhen Lv",
        "Yangqi Long",
        "Congzhentao Huang",
        "Cao Li",
        "Chengfei Lv",
        "Hao Ren",
        "Dian Zheng"
      ],
      "abstract": "Stereo video synthesis from a monocular input is a demanding task in the\nfields of spatial computing and virtual reality. The main challenges of this\ntask lie on the insufficiency of high-quality paired stereo videos for training\nand the difficulty of maintaining the spatio-temporal consistency between\nframes. Existing methods primarily address these issues by directly applying\nnovel view synthesis (NVS) techniques to video, while facing limitations such\nas the inability to effectively represent dynamic scenes and the requirement\nfor large amounts of training data. In this paper, we introduce a novel\nself-supervised stereo video synthesis paradigm via a video diffusion model,\ntermed SpatialDreamer, which meets the challenges head-on. Firstly, to address\nthe stereo video data insufficiency, we propose a Depth based Video Generation\nmodule DVG, which employs a forward-backward rendering mechanism to generate\npaired videos with geometric and temporal priors. Leveraging data generated by\nDVG, we propose RefinerNet along with a self-supervised synthetic framework\ndesigned to facilitate efficient and dedicated training. More importantly, we\ndevise a consistency control module, which consists of a metric of stereo\ndeviation strength and a Temporal Interaction Learning module TIL for geometric\nand temporal consistency ensurance respectively. We evaluated the proposed\nmethod against various benchmark methods, with the results showcasing its\nsuperior performance.",
      "tldr_zh": "本论文提出SpatialDreamer，一种自监督(self-supervised)立体视频合成方法，从单目输入生成立体视频，旨在解决训练数据不足和帧间时空一致性挑战。论文引入Depth based Video Generation (DVG)模块，利用前向-后向渲染机制生成配对视频，并结合RefinerNet和自监督合成框架进行高效训练；同时，Consistency control module通过立体偏差强度度量和Temporal Interaction Learning (TIL)模块确保几何和时间一致性。实验结果显示，SpatialDreamer在各种基准测试中表现出优越性能，超越现有Novel View Synthesis (NVS)方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "website, see https://spatialdreamer.github.io",
      "pdf_url": "http://arxiv.org/pdf/2411.11934v2",
      "published_date": "2024-11-18 15:12:59 UTC",
      "updated_date": "2025-04-27 07:46:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:37:26.883155"
    },
    {
      "arxiv_id": "2411.11933v2",
      "title": "METEOR: Evolutionary Journey of Large Language Models from Guidance to Self-Growth",
      "title_zh": "METEOR：大型语言模型从指导到自我成长的进化历程",
      "authors": [
        "Jiawei Li",
        "Xiaoang Xu",
        "Yang Gao"
      ],
      "abstract": "Model evolution enables learning from feedback to refine experiences and\nupdate skills, transforming models from having no domain knowledge to becoming\ndomain experts. However, there is currently no unified and effective method for\nguiding this evolutionary process. To address this gap, we propose the Meteor\nmethod, which includes three training phases: weak-to-strong data distillation,\niterative training, and self-evolution strategies. Each phase maximizes the\nmodel's inherent domain capabilities, allowing it to autonomously refine its\ndomain knowledge and enhance performance. Experiments demonstrate that our\napproach significantly improves accuracy, completeness, relevance, coherence,\nand reliability across domain-specific tasks.",
      "tldr_zh": "该论文探讨了大型语言模型（Large Language Models）的进化过程，提出 METEOR 方法来指导模型从无领域知识向专家水平的转变。METEOR 包括三个训练阶段：weak-to-strong data distillation 用于数据提炼、iterative training 用于迭代优化，以及 self-evolution strategies 用于自主提升性能，从而最大化模型的内在能力。实验结果表明，该方法显著提高了领域特定任务的准确性、完整性、相关性、一致性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Our code can be found at https://github.com/DIRECT-BIT/METEOR",
      "pdf_url": "http://arxiv.org/pdf/2411.11933v2",
      "published_date": "2024-11-18 15:09:50 UTC",
      "updated_date": "2024-11-29 06:07:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:37:38.709009"
    },
    {
      "arxiv_id": "2412.00026v1",
      "title": "Spatial-variant causal Bayesian inference for rapid seismic ground failures and impacts estimation",
      "title_zh": "空间变异的因果贝叶斯推理用于快速地震地表破坏",
      "authors": [
        "Xuechun Li",
        "Susu Xu"
      ],
      "abstract": "Rapid and accurate estimation of post-earthquake ground failures and building\ndamage is critical for effective post-disaster responses. Progression in remote\nsensing technologies has paved the way for rapid acquisition of detailed,\nlocalized data, enabling swift hazard estimation through analysis of\ncorrelation deviations between pre- and post-quake satellite imagery. However,\ndiscerning seismic hazards and their impacts is challenged by overlapping\nsatellite signals from ground failures, building damage, and environmental\nnoise. Previous advancements introduced a novel causal graph-based Bayesian\nnetwork that continually refines seismic ground failure and building damage\nestimates derived from satellite imagery, accounting for the intricate\ninterplay among geospatial elements, seismic activity, ground failures,\nbuilding structures, damages, and satellite data. However, this model's neglect\nof spatial heterogeneity across different locations in a seismic region limits\nits precision in capturing the spatial diversity of seismic effects. In this\nstudy, we pioneer an approach that accounts for spatial intricacies by\nintroducing a spatial variable influenced by the bilateral filter to capture\nrelationships from surrounding hazards. The bilateral filter considers both\nspatial proximity of neighboring hazards and their ground shaking intensity\nvalues, ensuring refined modeling of spatial relationships. This integration\nachieves a balance between site-specific characteristics and spatial\ntendencies, offering a comprehensive representation of the post-disaster\nlandscape. Our model, tested across multiple earthquake events, demonstrates\nsignificant improvements in capturing spatial heterogeneity in seismic hazard\nestimation. The results highlight enhanced accuracy and efficiency in\npost-earthquake large-scale multi-impact estimation, effectively informing\nrapid disaster responses.",
      "tldr_zh": "本文提出了一种考虑空间异质性的因果贝叶斯推理方法，用于快速估计地震后的地面破坏(seismic ground failures)和建筑损坏影响。方法引入空间变量，通过双边滤波器(bilateral filter)整合周围危害的空间邻近性和地面震动强度值，改进传统贝叶斯网络对地理元素间关系的建模，从而平衡站点特性和空间趋势。实验结果显示，该模型在多个地震事件中显著提升了危害估计的准确性和效率，有助于加速灾后响应和大规模影响评估。",
      "categories": [
        "physics.geo-ph",
        "cs.AI"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "This paper was accepted for 2024 WCEE conference",
      "pdf_url": "http://arxiv.org/pdf/2412.00026v1",
      "published_date": "2024-11-18 15:01:28 UTC",
      "updated_date": "2024-11-18 15:01:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:37:50.449781"
    },
    {
      "arxiv_id": "2411.11620v1",
      "title": "ST-Tree with Interpretability for Multivariate Time Series Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Mingsen Du",
        "Yanxuan Wei",
        "Yingxia Tang",
        "Xiangwei Zheng",
        "Shoushui Wei",
        "Cun Ji"
      ],
      "abstract": "Multivariate time series classification is of great importance in practical\napplications and is a challenging task. However, deep neural network models\nsuch as Transformers exhibit high accuracy in multivariate time series\nclassification but lack interpretability and fail to provide insights into the\ndecision-making process. On the other hand, traditional approaches based on\ndecision tree classifiers offer clear decision processes but relatively lower\naccuracy. Swin Transformer (ST) addresses these issues by leveraging\nself-attention mechanisms to capture both fine-grained local patterns and\nglobal patterns. It can also model multi-scale feature representation learning,\nthereby providing a more comprehensive representation of time series features.\nTo tackle the aforementioned challenges, we propose ST-Tree with\ninterpretability for multivariate time series classification. Specifically, the\nST-Tree model combines ST as the backbone network with an additional neural\ntree model. This integration allows us to fully leverage the advantages of ST\nin learning time series context while providing interpretable decision\nprocesses through the neural tree. This enables researchers to gain clear\ninsights into the model's decision-making process and extract meaningful\ninterpretations. Through experimental evaluations on 10 UEA datasets, we\ndemonstrate that the ST-Tree model improves accuracy in multivariate time\nseries classification tasks and provides interpretability through visualizing\nthe decision-making process across different datasets.",
      "tldr_zh": "这篇论文针对多变量时间序列分类(Multivariate Time Series Classification)的挑战，提出了一种结合 Swin Transformer (ST) 和神经树模型的 ST-Tree 框架，以解决深度模型准确率高但缺乏可解释性的问题，同时提升传统决策树的性能。ST-Tree 利用 ST 的自注意力机制捕获时间序列的局部和全局模式，并通过神经树提供可解释的决策过程，帮助用户理解模型决策。实验在 10 个 UEA 数据集上显示，该模型显著提高了分类准确率，并通过可视化展示了决策流程。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted on May 15, 2024, major revisions on Aug 31, 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.11620v1",
      "published_date": "2024-11-18 14:49:12 UTC",
      "updated_date": "2024-11-18 14:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:38:02.985168"
    },
    {
      "arxiv_id": "2411.11616v2",
      "title": "Signaling and Social Learning in Swarms of Robots",
      "title_zh": "机器人群中的信号通信与社会学习",
      "authors": [
        "Leo Cazenille",
        "Maxime Toquebiau",
        "Nicolas Lobato-Dauzier",
        "Alessia Loi",
        "Loona Macabre",
        "Nathanael Aubert-Kato",
        "Anthony Genot",
        "Nicolas Bredeche"
      ],
      "abstract": "This paper investigates the role of communication in improving coordination\nwithin robot swarms, focusing on a paradigm where learning and execution occur\nsimultaneously in a decentralized manner. We highlight the role communication\ncan play in addressing the credit assignment problem (individual contribution\nto the overall performance), and how it can be influenced by it. We propose a\ntaxonomy of existing and future works on communication, focusing on information\nselection and physical abstraction as principal axes for classification: from\nlow-level lossless compression with raw signal extraction and processing to\nhigh-level lossy compression with structured communication models. The paper\nreviews current research from evolutionary robotics, multi-agent (deep)\nreinforcement learning, language models, and biophysics models to outline the\nchallenges and opportunities of communication in a collective of robots that\ncontinuously learn from one another through local message exchanges,\nillustrating a form of social learning.",
      "tldr_zh": "本论文探讨了通信在机器人群协调中的作用，强调在去中心化环境中学习和执行同步进行，并通过通信解决信用 assignment problem（个体对整体性能的贡献）。作者提出一个通信分类框架，以信息选择和物理抽象为主要轴，从低级无损压缩（raw signal extraction and processing）到高级有损压缩（structured communication models）。论文回顾了进化机器人学、多代理（deep）强化学习、语言模型和生物物理模型的相关研究，突显了机器人通过本地消息交换实现社会 learning 的挑战和机会。实验和分析表明，这种通信机制能促进集体持续学习，提升整体协调效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "17 pages, 3 Figures",
      "pdf_url": "http://arxiv.org/pdf/2411.11616v2",
      "published_date": "2024-11-18 14:42:15 UTC",
      "updated_date": "2024-11-19 10:11:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:38:15.085024"
    },
    {
      "arxiv_id": "2411.11932v1",
      "title": "Reviving Dormant Memories: Investigating Catastrophic Forgetting in Language Models through Rationale-Guidance Difficulty",
      "title_zh": "翻译失败",
      "authors": [
        "Huashan Sun",
        "Yang Gao"
      ],
      "abstract": "Although substantial efforts have been made to mitigate catastrophic\nforgetting in continual learning, the intrinsic mechanisms are not well\nunderstood. In this paper, we discover that when a forgetting model passively\nreceives an externally provided partial appropriate rationale, its performance\non the forgotten task can be restored. Furthermore, by simply adding a\ntask-agnostic prefix to the original instruction, the forgetting model can\nactively generate an appropriate rationale to reach the correct answer. These\nfindings suggest that the model does not actually ``forget'' the task\nknowledge; instead, the degraded performance can be attributed to the failure\nof the original instructions in guiding the model to generate the appropriate\nrationales. Based on this insight, we propose the Rationale-Guidance Difficulty\nmetric to evaluate how effectively a given instruction guides the model in\ngenerating appropriate rationales. We apply this metric to optimize the\nallocation of replay data in replay-based continual learning algorithm.\nExperimental results demonstrate that our data allocation method effectively\nmitigates catastrophic forgetting and maintains better model plasticity\nsimultaneously across models.",
      "tldr_zh": "该研究发现，语言模型在持续学习（continual learning）中出现的灾难性遗忘（catastrophic forgetting）并非真正丢失知识，而是源于原始指令未能有效引导模型生成适当的理由（rationale）。通过提供外部部分理由或在指令中添加任务无关前缀，模型可以主动恢复遗忘任务的性能。基于此，论文提出 Rationale-Guidance Difficulty 指标，用于评估指令引导生成理由的有效性，并优化重放数据（replay data）的分配方法。实验结果显示，该方法显著缓解了灾难性遗忘，同时保持了更好的模型可塑性（model plasticity）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Working in progress",
      "pdf_url": "http://arxiv.org/pdf/2411.11932v1",
      "published_date": "2024-11-18 14:28:04 UTC",
      "updated_date": "2024-11-18 14:28:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:38:26.613289"
    },
    {
      "arxiv_id": "2411.14466v1",
      "title": "Learning to Ask: Conversational Product Search via Representation Learning",
      "title_zh": "学会提问：通过表示学习实现对话式产品搜索",
      "authors": [
        "Jie Zou",
        "Jimmy Xiangji Huang",
        "Zhaochun Ren",
        "Evangelos Kanoulas"
      ],
      "abstract": "Online shopping platforms, such as Amazon and AliExpress, are increasingly\nprevalent in society, helping customers purchase products conveniently. With\nrecent progress in natural language processing, researchers and practitioners\nshift their focus from traditional product search to conversational product\nsearch. Conversational product search enables user-machine conversations and\nthrough them collects explicit user feedback that allows to actively clarify\nthe users' product preferences. Therefore, prospective research on an\nintelligent shopping assistant via conversations is indispensable. Existing\npublications on conversational product search either model conversations\nindependently from users, queries, and products or lead to a vocabulary\nmismatch. In this work, we propose a new conversational product search model,\nConvPS, to assist users in locating desirable items. The model is first trained\nto jointly learn the semantic representations of user, query, item, and\nconversation via a unified generative framework. After learning these\nrepresentations, they are integrated to retrieve the target items in the latent\nsemantic space. Meanwhile, we propose a set of greedy and explore-exploit\nstrategies to learn to ask the user a sequence of high-performance questions\nfor conversations. Our proposed ConvPS model can naturally integrate the\nrepresentation learning of the user, query, item, and conversation into a\nunified generative framework, which provides a promising avenue for\nconstructing accurate and robust conversational product search systems that are\nflexible and adaptive. Experimental results demonstrate that our ConvPS model\nsignificantly outperforms state-of-the-art baselines.",
      "tldr_zh": "本论文提出了一种新的对话式产品搜索模型ConvPS，旨在通过自然语言处理帮助用户在在线购物平台（如Amazon和AliExpress）中定位理想产品。模型采用统一的生成框架，联合学习用户、查询、物品和对话的语义表示，并在潜在语义空间中检索目标物品，同时引入贪婪和探索-利用策略来生成高效的问题序列。实验结果表明，ConvPS显著优于现有基线模型，提高了系统的准确性和鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACM TOIS",
      "pdf_url": "http://arxiv.org/pdf/2411.14466v1",
      "published_date": "2024-11-18 14:05:43 UTC",
      "updated_date": "2024-11-18 14:05:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:38:38.533480"
    },
    {
      "arxiv_id": "2411.11576v1",
      "title": "Hybrid Data-Driven SSM for Interpretable and Label-Free mmWave Channel Prediction",
      "title_zh": "用于可解释和无标签 mmWave 通道预测的混合数据驱动 SSM",
      "authors": [
        "Yiyong Sun",
        "Jiajun He",
        "Zhidi Lin",
        "Wenqiang Pu",
        "Feng Yin",
        "Hing Cheung So"
      ],
      "abstract": "Accurate prediction of mmWave time-varying channels is essential for\nmitigating the issue of channel aging in complex scenarios owing to high user\nmobility. Existing channel prediction methods have limitations: classical\nmodel-based methods often struggle to track highly nonlinear channel dynamics\ndue to limited expert knowledge, while emerging data-driven methods typically\nrequire substantial labeled data for effective training and often lack\ninterpretability. To address these issues, this paper proposes a novel hybrid\nmethod that integrates a data-driven neural network into a conventional\nmodel-based workflow based on a state-space model (SSM), implicitly tracking\ncomplex channel dynamics from data without requiring precise expert knowledge.\nAdditionally, a novel unsupervised learning strategy is developed to train the\nembedded neural network solely with unlabeled data. Theoretical analyses and\nablation studies are conducted to interpret the enhanced benefits gained from\nthe hybrid integration. Numerical simulations based on the 3GPP mmWave channel\nmodel corroborate the superior prediction accuracy of the proposed method,\ncompared to state-of-the-art methods that are either purely model-based or\ndata-driven. Furthermore, extensive experiments validate its robustness against\nvarious challenging factors, including among others severe channel variations\nand high noise levels.",
      "tldr_zh": "该论文针对 mmWave 时间变化通道预测问题，提出了一种混合数据驱动的 SSM（Hybrid Data-Driven SSM）方法，以解决传统模型驱动方法难以处理非线性动态和数据驱动方法依赖标记数据且缺乏可解释性的局限。方法将数据驱动的神经网络集成到基于状态空间模型（SSM）的传统工作流中，通过隐式跟踪通道动态，并引入一种新型无监督学习策略，仅使用无标签数据进行训练，从而实现可解释且无需精确专家知识的预测。实验结果基于 3GPP mmWave 通道模型显示，该方法比纯模型驱动或数据驱动方法具有更高的预测准确性和鲁棒性，尤其在严重通道变化和高噪声水平等挑战场景下表现优异。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11576v1",
      "published_date": "2024-11-18 13:54:44 UTC",
      "updated_date": "2024-11-18 13:54:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:38:50.735976"
    },
    {
      "arxiv_id": "2411.11560v1",
      "title": "Topology-aware Preemptive Scheduling for Co-located LLM Workloads",
      "title_zh": "拓扑感知抢占式调度用于共置 LLM 工作负载",
      "authors": [
        "Ping Zhang",
        "Lei Su",
        "Jinjie Yang",
        "Xin Chen"
      ],
      "abstract": "Hosting diverse large language model workloads in a unified resource pool\nthrough co-location is cost-effective. For example, long-running chat services\ngenerally follow diurnal traffic patterns, which inspire co-location of batch\njobs to fulfill resource valleys between successive peaks, and thus to saturate\nresource allocation in cluster-wide scope. These heterogeneous workloads often\nhave different business priorities, and therefore preemption can be leveraged\nfor resource elasticity. However, workloads often have distinct topology\npreferences as well. The resources released by lower-priority instances may\nfail to meet the requirements of high-priority online services which are\nusually latency-sensitive. The root cause behind such mis-match is a lack of\ntopology awareness of resource scheduler, especially during preemption. To\nbridge this gap, we develop a fine-grained topology-aware method for preemptive\nscheduling of hybrid workloads. The method ensures that the resources freed by\npreempted tasks adhere to the topological affinity needs of high-priority\npreemptors in a guaranteed or best-effort manner. This dynamic alignment\nsignificantly increases the efficiency of preemption and improves overall\nscheduled performance for LLM workloads by $55\\%$.",
      "tldr_zh": "该论文探讨了在统一资源池中共置不同LLM工作负载的资源调度问题，针对异构工作负载的优先级和拓扑偏好，提出了一种细粒度的topology-aware预抢占调度方法。该方法确保被抢占任务释放的资源能够以guaranteed或best-effort方式满足高优先级任务的拓扑亲和性需求，从而实现资源弹性优化。实验结果表明，该方法将LLM工作负载的整体调度性能提高了55%。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "17 Pages, 11 Figures, 5 Tables",
      "pdf_url": "http://arxiv.org/pdf/2411.11560v1",
      "published_date": "2024-11-18 13:26:09 UTC",
      "updated_date": "2024-11-18 13:26:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:39:02.151788"
    },
    {
      "arxiv_id": "2411.11548v1",
      "title": "Real-Time Fitness Exercise Classification and Counting from Video Frames",
      "title_zh": "翻译失败",
      "authors": [
        "Riccardo Riccio"
      ],
      "abstract": "This paper introduces a novel method for real-time exercise classification\nusing a Bidirectional Long Short-Term Memory (BiLSTM) neural network. Existing\nexercise recognition approaches often rely on synthetic datasets, raw\ncoordinate inputs sensitive to user and camera variations, and fail to fully\nexploit the temporal dependencies in exercise movements. These issues limit\ntheir generalizability and robustness in real-world conditions, where lighting,\ncamera angles, and user body types vary.\n  To address these challenges, we propose a BiLSTM-based model that leverages\ninvariant features, such as joint angles, alongside raw coordinates. By using\nboth angles and (x, y, z) coordinates, the model adapts to changes in\nperspective, user positioning, and body differences, improving generalization.\nTraining on 30-frame sequences enables the BiLSTM to capture the temporal\ncontext of exercises and recognize patterns evolving over time.\n  We compiled a dataset combining synthetic data from the InfiniteRep dataset\nand real-world videos from Kaggle and other sources. This dataset includes four\ncommon exercises: squat, push-up, shoulder press, and bicep curl. The model was\ntrained and validated on these diverse datasets, achieving an accuracy of over\n99% on the test set. To assess generalizability, the model was tested on 2\nseparate test sets representative of typical usage conditions. Comparisons with\nthe previous approach from the literature are present in the result section\nshowing that the proposed model is the best-performing one.\n  The classifier is integrated into a web application providing real-time\nexercise classification and repetition counting without manual exercise\nselection.\n  Demo and datasets are available at the following GitHub Repository:\nhttps://github.com/RiccardoRiccio/Fitness-AI-Trainer-With-Automatic-Exercise-Recognition-and-Counting.",
      "tldr_zh": "本研究提出了一种基于Bidirectional Long Short-Term Memory (BiLSTM)神经网络的实时运动分类方法，以解决现有方法依赖合成数据集、对用户和相机变化敏感以及未充分利用运动时间依赖性的问题。该模型结合关节angles和(x, y, z) coordinates作为输入特征，提高了对视角、用户定位和身体差异的适应性，并在30帧序列上训练以捕捉时间上下文。使用混合数据集（包括InfiniteRep合成数据和Kaggle真实视频），模型在测试集上达到99%以上的准确率，并优于文献中现有方法；此外，该分类器已集成到网页应用中，实现实时运动分类和重复计数。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11548v1",
      "published_date": "2024-11-18 13:06:29 UTC",
      "updated_date": "2024-11-18 13:06:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:39:13.639102"
    },
    {
      "arxiv_id": "2411.11543v4",
      "title": "PSA-VLM: Enhancing Vision-Language Model Safety through Progressive Concept-Bottleneck-Driven Alignment",
      "title_zh": "PSA-VLM：通过渐进式概念瓶颈驱动对齐增强视觉语言模型",
      "authors": [
        "Zhendong Liu",
        "Yuanbi Nie",
        "Yingshui Tan",
        "Jiaheng Liu",
        "Xiangyu Yue",
        "Qiushi Cui",
        "Chongjun Wang",
        "Xiaoyong Zhu",
        "Bo Zheng"
      ],
      "abstract": "Benefiting from the powerful capabilities of Large Language Models (LLMs),\npre-trained visual encoder models connected to LLMs form Vision Language Models\n(VLMs). However, recent research shows that the visual modality in VLMs is\nhighly vulnerable, allowing attackers to bypass safety alignment in LLMs\nthrough visually transmitted content, launching harmful attacks. To address\nthis challenge, we propose a progressive concept-based alignment strategy,\nPSA-VLM, which incorporates safety modules as concept bottlenecks to enhance\nvisual modality safety alignment. By aligning model predictions with specific\nsafety concepts, we improve defenses against risky images, enhancing\nexplainability and controllability while minimally impacting general\nperformance. Our method is obtained through two-stage training. The low\ncomputational cost of the first stage brings very effective performance\nimprovement, and the fine-tuning of the language model in the second stage\nfurther improves the safety performance. Our method achieves state-of-the-art\nresults on popular VLM safety benchmark.",
      "tldr_zh": "这篇论文针对 Vision-Language Models (VLMs) 的视觉模式易受攻击的问题，提出了 PSA-VLM 方法，通过渐进式概念瓶颈驱动的对齐策略（progressive concept-bottleneck-driven alignment）增强模型的安全性。PSA-VLM 将安全模块作为 concept bottlenecks，与特定安全概念对齐，提高了对风险图像的防御，同时提升了模型的可解释性和可控性，同时最小化了对一般性能的影响。该方法采用两阶段训练：第一阶段低计算成本快速提升性能，第二阶段微调 Large Language Models (LLMs) 进一步优化安全表现。实验结果显示，PSA-VLM 在流行 VLM 安全基准上达到了 state-of-the-art 水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2405.13581",
      "pdf_url": "http://arxiv.org/pdf/2411.11543v4",
      "published_date": "2024-11-18 13:01:57 UTC",
      "updated_date": "2025-01-13 10:39:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:39:27.037112"
    },
    {
      "arxiv_id": "2411.11531v2",
      "title": "Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality",
      "title_zh": "翻译失败",
      "authors": [
        "Viktoriia Chekalina",
        "Anton Razzhigaev",
        "Elizaveta Goncharova",
        "Andrey Kuznetsov"
      ],
      "abstract": "In this paper we present an approach to reduce hallucinations in Large\nLanguage Models (LLMs) by incorporating Knowledge Graphs (KGs) as an additional\nmodality. Our method involves transforming input text into a set of KG\nembeddings and using an adapter to integrate these embeddings into the language\nmodel space, without relying on external retrieval processes.\n  To facilitate this, we created WikiEntities, a dataset containing over 3\nmillion Wikipedia texts annotated with entities from Wikidata and their\ncorresponding embeddings from PyTorch-BigGraph. This dataset serves as a\nvaluable resource for training Entity Linking models and adapting the described\nmethod to various LLMs using specialized adapters.\n  Our method does not require fine-tuning of the language models themselves;\ninstead, we only train the adapter. This ensures that the model's performance\non other tasks is not affected. We trained an adapter for the Mistral 7B, LLaMA\n2-7B (chat), and LLaMA 3-8B (instruct) models using this dataset and\ndemonstrated that our approach improves performance on the HaluEval, True-False\nbenchmarks and FEVER dataset. The results indicate that incorporating KGs as a\nnew modality can effectively reduce hallucinations and improve the factual\naccuracy of language models, all without the need for external retrieval.",
      "tldr_zh": "本研究提出了一种方法，通过将 Knowledge Graph Embeddings 作为额外模态整合到 Large Language Models (LLMs) 中，以减少模型中的幻觉（hallucinations），具体涉及将输入文本转化为 KG embeddings 并使用 adapter 融入语言模型空间，而无需外部检索。研究者创建了 WikiEntities 数据集，包含超过 300 万条 Wikipedia 文本，标注了 Wikidata 实体及其 PyTorch-BigGraph embeddings，用于训练 Entity Linking 模型和适配各种 LLMs，仅需训练 adapter 而非微调整个模型，从而避免影响其他任务性能。在 Mistral 7B、LLaMA 2-7B (chat) 和 LLaMA 3-8B (instruct) 模型上实验表明，该方法显著提升了 HaluEval、True-False benchmarks 和 FEVER 数据集的表现，提升了模型的事实准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11531v2",
      "published_date": "2024-11-18 12:40:51 UTC",
      "updated_date": "2025-01-14 12:56:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:39:39.869812"
    },
    {
      "arxiv_id": "2411.15178v3",
      "title": "Harnessing Scale and Physics: A Multi-Graph Neural Operator Framework for PDEs on Arbitrary Geometries",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihao Li",
        "Haoze Song",
        "Di Xiao",
        "Zhilu Lai",
        "Wei Wang"
      ],
      "abstract": "Partial Differential Equations (PDEs) underpin many scientific phenomena, yet\ntraditional computational approaches often struggle with complex, nonlinear\nsystems and irregular geometries. This paper introduces the AMG method, a\nMulti-Graph neural operator approach designed for efficiently solving PDEs on\nArbitrary geometries. AMG leverages advanced graph-based techniques and dynamic\nattention mechanisms within a novel GraphFormer architecture, enabling precise\nmanagement of diverse spatial domains and complex data interdependencies. By\nconstructing multi-scale graphs to handle variable feature frequencies and a\nphysics graph to encapsulate inherent physical properties, AMG significantly\noutperforms previous methods, which are typically limited to uniform grids. We\npresent a comprehensive evaluation of AMG across six benchmarks, demonstrating\nits consistent superiority over existing state-of-the-art models. Our findings\nhighlight the transformative potential of tailored graph neural operators in\nsurmounting the challenges faced by conventional PDE solvers. Our code and\ndatasets are available on https://github.com/lizhihao2022/AMG.",
      "tldr_zh": "本文提出 AMG 方法，这是一种 Multi-Graph neural operator 框架，旨在高效解决 Partial Differential Equations (PDEs) 在任意几何形状上的复杂非线性问题。AMG 通过 GraphFormer architecture、multi-scale graphs 和 physics graph 来管理多样空间域、变量特征频率以及固有物理属性，从而超越了传统基于统一网格的方法。在六个基准测试中，AMG 展现出比现有最先进模型的一致优越性，证明了其在提升 PDE 求解器性能方面的变革潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining V.1 (KDD '25)",
      "pdf_url": "http://arxiv.org/pdf/2411.15178v3",
      "published_date": "2024-11-18 12:35:03 UTC",
      "updated_date": "2025-02-07 13:53:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:41:43.770115"
    },
    {
      "arxiv_id": "2411.11520v1",
      "title": "A Pre-Trained Graph-Based Model for Adaptive Sequencing of Educational Documents",
      "title_zh": "翻译失败",
      "authors": [
        "Jean Vassoyan",
        "Anan Schütt",
        "Jill-Jênn Vie",
        "Arun-Balajiee Lekshmi-Narayanan",
        "Elisabeth André",
        "Nicolas Vayatis"
      ],
      "abstract": "Massive Open Online Courses (MOOCs) have greatly contributed to making\neducation more accessible. However, many MOOCs maintain a rigid,\none-size-fits-all structure that fails to address the diverse needs and\nbackgrounds of individual learners. Learning path personalization aims to\naddress this limitation, by tailoring sequences of educational content to\noptimize individual student learning outcomes. Existing approaches, however,\noften require either massive student interaction data or extensive expert\nannotation, limiting their broad application. In this study, we introduce a\nnovel data-efficient framework for learning path personalization that operates\nwithout expert annotation. Our method employs a flexible recommender system\npre-trained with reinforcement learning on a dataset of raw course materials.\nThrough experiments on semi-synthetic data, we show that this pre-training\nstage substantially improves data-efficiency in a range of adaptive learning\nscenarios featuring new educational materials. This opens up new perspectives\nfor the design of foundation models for adaptive learning.",
      "tldr_zh": "本研究针对 MOOCs 的刚性结构问题，提出一个预训练的基于图的模型，用于教育文档的自适应排序。该框架采用强化学习在原始课程材料数据集上预训练的推荐系统，实现数据高效的学习路径个性化，无需专家标注。通过半合成数据的实验，证明预训练阶段显著提升了在新教育材料下的数据效率，为自适应学习的基础模型设计开辟了新视角。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024 Workshop on Large Foundation Models for Educational\n  Assessment (FM-Assess), Dec 2024, Vancouver, Canada",
      "pdf_url": "http://arxiv.org/pdf/2411.11520v1",
      "published_date": "2024-11-18 12:29:06 UTC",
      "updated_date": "2024-11-18 12:29:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:40:01.879515"
    },
    {
      "arxiv_id": "2411.11511v1",
      "title": "Structure learning with Temporal Gaussian Mixture for model-based Reinforcement Learning",
      "title_zh": "基于时间高斯",
      "authors": [
        "Théophile Champion",
        "Marek Grześ",
        "Howard Bowman"
      ],
      "abstract": "Model-based reinforcement learning refers to a set of approaches capable of\nsample-efficient decision making, which create an explicit model of the\nenvironment. This model can subsequently be used for learning optimal policies.\nIn this paper, we propose a temporal Gaussian Mixture Model composed of a\nperception model and a transition model. The perception model extracts discrete\n(latent) states from continuous observations using a variational Gaussian\nmixture likelihood. Importantly, our model constantly monitors the collected\ndata searching for new Gaussian components, i.e., the perception model performs\na form of structure learning (Smith et al., 2020; Friston et al., 2018; Neacsu\net al., 2022) as it learns the number of Gaussian components in the mixture.\nAdditionally, the transition model learns the temporal transition between\nconsecutive time steps by taking advantage of the Dirichlet-categorical\nconjugacy. Both the perception and transition models are able to forget part of\nthe data points, while integrating the information they provide within the\nprior, which ensure fast variational inference. Finally, decision making is\nperformed with a variant of Q-learning which is able to learn Q-values from\nbeliefs over states. Empirically, we have demonstrated the model's ability to\nlearn the structure of several mazes: the model discovered the number of states\nand the transition probabilities between these states. Moreover, using its\nlearned Q-values, the agent was able to successfully navigate from the starting\nposition to the maze's exit.",
      "tldr_zh": "本研究提出了一种基于Temporal Gaussian Mixture Model的模型-based Reinforcement Learning框架，以提升决策的样本效率。该框架包括感知模型和转移模型，其中感知模型使用variational Gaussian mixture likelihood从连续观测中提取离散潜在状态，并通过结构学习动态发现高斯混合组件的数量。转移模型则利用Dirichlet-categorical conjugacy学习连续时间步间的转移，同时两者支持数据点遗忘以实现快速变分推理。实验结果显示，该方法能在多个迷宫环境中自动学习状态数量和转移概率，并通过Q-learning变体从状态信念中学习Q值，实现从起始位置到出口的成功导航。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11511v1",
      "published_date": "2024-11-18 12:16:03 UTC",
      "updated_date": "2024-11-18 12:16:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:40:13.945732"
    },
    {
      "arxiv_id": "2411.11510v1",
      "title": "Closed-loop multi-step planning with innate physics knowledge",
      "title_zh": "基于固有物理知识的闭环多步规划",
      "authors": [
        "Giulia Lafratta",
        "Bernd Porr",
        "Christopher Chandler",
        "Alice Miller"
      ],
      "abstract": "We present a hierarchical framework to solve robot planning as an input\ncontrol problem. At the lowest level are temporary closed control loops,\n(\"tasks\"), each representing a behaviour, contingent on a specific sensory\ninput and therefore temporary. At the highest level, a supervising\n\"Configurator\" directs task creation and termination. Here resides \"core\"\nknowledge as a physics engine, where sequences of tasks can be simulated. The\nConfigurator encodes and interprets simulation results,based on which it can\nchoose a sequence of tasks as a plan. We implement this framework on a real\nrobot and test it in an overtaking scenario as proof-of-concept.",
      "tldr_zh": "该论文提出了一种分层框架，用于将机器人规划视为输入控制问题，核心是通过闭环多步规划（closed-loop multi-step planning）结合固有物理知识（innate physics knowledge）来实现任务序列的模拟和执行。框架的最低层由临时闭环控制循环（tasks）组成，每一个依赖特定感官输入来代表特定行为，而最高层的监督器（Configurator）负责任务的创建、终止和模拟结果的解释。实验在真实机器人上进行了超车场景的验证，作为概念证明，展示了该框架的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.ET",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11510v1",
      "published_date": "2024-11-18 12:15:16 UTC",
      "updated_date": "2024-11-18 12:15:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:40:26.687773"
    },
    {
      "arxiv_id": "2411.11504v1",
      "title": "Search, Verify and Feedback: Towards Next Generation Post-training Paradigm of Foundation Models via Verifier Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyan Guan",
        "Yanjiang Liu",
        "Xinyu Lu",
        "Boxi Cao",
        "Ben He",
        "Xianpei Han",
        "Le Sun",
        "Jie Lou",
        "Bowen Yu",
        "Yaojie Lu",
        "Hongyu Lin"
      ],
      "abstract": "The evolution of machine learning has increasingly prioritized the\ndevelopment of powerful models and more scalable supervision signals. However,\nthe emergence of foundation models presents significant challenges in providing\neffective supervision signals necessary for further enhancing their\ncapabilities. Consequently, there is an urgent need to explore novel\nsupervision signals and technical approaches. In this paper, we propose\nverifier engineering, a novel post-training paradigm specifically designed for\nthe era of foundation models. The core of verifier engineering involves\nleveraging a suite of automated verifiers to perform verification tasks and\ndeliver meaningful feedback to foundation models. We systematically categorize\nthe verifier engineering process into three essential stages: search, verify,\nand feedback, and provide a comprehensive review of state-of-the-art research\ndevelopments within each stage. We believe that verifier engineering\nconstitutes a fundamental pathway toward achieving Artificial General\nIntelligence.",
      "tldr_zh": "该论文提出了一种名为 Verifier Engineering 的新型后训练范式，旨在解决 Foundation Models 在获取有效监督信号方面的挑战，从而提升模型能力。该范式将过程分为三个关键阶段：Search（搜索潜在问题）、Verify（验证模型输出）和Feedback（提供反馈），并综述了当前最先进的研究进展。通过自动化验证器生成有意义的反馈，Verifier Engineering 被视为通向 Artificial General Intelligence 的根本路径。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11504v1",
      "published_date": "2024-11-18 12:04:52 UTC",
      "updated_date": "2024-11-18 12:04:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:40:37.815051"
    },
    {
      "arxiv_id": "2412.03580v1",
      "title": "Reinforced Symbolic Learning with Logical Constraints for Predicting Turbine Blade Fatigue Life",
      "title_zh": "翻译失败",
      "authors": [
        "Pei Li",
        "Joo-Ho Choi",
        "Dingyang Zhang",
        "Shuyou Zhang",
        "Yiming Zhang"
      ],
      "abstract": "Accurate prediction of turbine blade fatigue life is essential for ensuring\nthe safety and reliability of aircraft engines. A significant challenge in this\ndomain is uncovering the intrinsic relationship between mechanical properties\nand fatigue life. This paper introduces Reinforced Symbolic Learning (RSL), a\nmethod that derives predictive formulas linking these properties to fatigue\nlife. RSL incorporates logical constraints during symbolic optimization,\nensuring that the generated formulas are both physically meaningful and\ninterpretable. The optimization process is further enhanced using deep\nreinforcement learning, which efficiently guides the symbolic regression\ntowards more accurate models. The proposed RSL method was evaluated on two\nturbine blade materials, GH4169 and TC4, to identify optimal fatigue life\nprediction models. When compared with six empirical formulas and five machine\nlearning algorithms, RSL not only produces more interpretable formulas but also\nachieves superior or comparable predictive accuracy. Additionally, finite\nelement simulations were conducted to assess mechanical properties at critical\npoints on the blade, which were then used to predict fatigue life under various\noperating conditions.",
      "tldr_zh": "这篇论文提出Reinforced Symbolic Learning (RSL)方法，用于准确预测涡轮叶片疲劳寿命，从而提升飞机引擎的安全可靠性。RSL通过在符号回归(symbolic regression)过程中融入逻辑约束和deep reinforcement learning，确保生成的预测公式既物理上合理又可解释。实验结果显示，在GH4169和TC4材料上，RSL比六种经验公式和五种机器学习算法实现了更优的可解释性和相等或更高的预测准确性，并通过finite element simulations评估了叶片关键点的机械性能以验证其在各种操作条件下的实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "full-lenth article with 24 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.03580v1",
      "published_date": "2024-11-18 12:01:48 UTC",
      "updated_date": "2024-11-18 12:01:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:40:51.432703"
    },
    {
      "arxiv_id": "2411.11494v1",
      "title": "Alien Recombination: Exploring Concept Blends Beyond Human Cognitive Availability in Visual Art",
      "title_zh": "翻译失败",
      "authors": [
        "Alejandro Hernandez",
        "Levin Brinkmann",
        "Ignacio Serna",
        "Nasim Rahaman",
        "Hassan Abu Alhaija",
        "Hiromu Yakura",
        "Mar Canet Sola",
        "Bernhard Schölkopf",
        "Iyad Rahwan"
      ],
      "abstract": "While AI models have demonstrated remarkable capabilities in constrained\ndomains like game strategy, their potential for genuine creativity in\nopen-ended domains like art remains debated. We explore this question by\nexamining how AI can transcend human cognitive limitations in visual art\ncreation. Our research hypothesizes that visual art contains a vast unexplored\nspace of conceptual combinations, constrained not by inherent incompatibility,\nbut by cognitive limitations imposed by artists' cultural, temporal,\ngeographical and social contexts.\n  To test this hypothesis, we present the Alien Recombination method, a novel\napproach utilizing fine-tuned large language models to identify and generate\nconcept combinations that lie beyond human cognitive availability. The system\nmodels and deliberately counteracts human availability bias, the tendency to\nrely on immediately accessible examples, to discover novel artistic\ncombinations.\n  This system not only produces combinations that have never been attempted\nbefore within our dataset but also identifies and generates combinations that\nare cognitively unavailable to all artists in the domain. Furthermore, we\ntranslate these combinations into visual representations, enabling the\nexploration of subjective perceptions of novelty. Our findings suggest that\ncognitive unavailability is a promising metric for optimizing artistic novelty,\noutperforming merely temperature scaling without additional evaluation\ncriteria. This approach uses generative models to connect previously\nunconnected ideas, providing new insight into the potential of framing\nAI-driven creativity as a combinatorial problem.",
      "tldr_zh": "本研究探讨AI在视觉艺术领域的创造力，假设艺术概念组合的空间受人类认知限制（如文化、时间和地域因素）而未充分探索。研究提出Alien Recombination方法，使用微调的大型语言模型来识别并生成超出人类认知可用性（cognitive availability）的概念组合，并通过对抗人类可用性偏差（availability bias）产生前所未有的艺术创新。实验结果显示，该方法不仅成功转化为视觉表示，还证明认知不可用性作为新颖性指标优于单纯的温度缩放，为将AI驱动的创造力视为组合问题提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024 Workshop on Creativity & Generative AI, 13 pages, 11\n  figures",
      "pdf_url": "http://arxiv.org/pdf/2411.11494v1",
      "published_date": "2024-11-18 11:55:38 UTC",
      "updated_date": "2024-11-18 11:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:41:02.095991"
    },
    {
      "arxiv_id": "2411.11930v3",
      "title": "AtomThink: A Slow Thinking Framework for Multimodal Mathematical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Xiang",
        "Zhili Liu",
        "Zihao Jiang",
        "Yunshuang Nie",
        "Runhui Huang",
        "Haoxiang Fan",
        "Hanhui Li",
        "Weiran Huang",
        "Yihan Zeng",
        "Jianhua Han",
        "Lanqing Hong",
        "Hang Xu",
        "Xiaodan Liang"
      ],
      "abstract": "In this paper, we address the challenging task of multimodal mathematical\nreasoning by incorporating the ability of ``slow thinking\" into multimodal\nlarge language models (MLLMs). Contrary to existing methods that rely on direct\nor fast thinking, our key idea is to construct long chains of thought (CoT)\nconsisting of atomic actions in a step-by-step manner, guiding MLLMs to perform\ncomplex reasoning. To this end, we design a novel AtomThink framework composed\nof three key modules: (i) a CoT annotation engine that automatically generates\nhigh-quality CoT annotations to address the lack of high-quality visual\nmathematical data; (ii) an atomic step fine-tuning strategy that jointly\noptimizes an MLLM and a policy reward model (PRM) for step-wise reasoning; and\n(iii) four different search strategies that can be applied with the PRM to\ncomplete reasoning. Additionally, we propose AtomMATH, a large-scale multimodal\ndataset of long CoTs, and an atomic capability evaluation metric for\nmathematical tasks. Extensive experimental results show that the proposed\nAtomThink significantly improves the performance of baseline MLLMs, achieving\napproximately 50\\% relative accuracy gains on MathVista and 120\\% on MathVerse.\nTo support the advancement of multimodal slow-thinking models, we will make our\ncode and dataset publicly available on https://github.com/Quinn777/AtomThink.",
      "tldr_zh": "本研究提出AtomThink框架，将“slow thinking”融入多模态大语言模型(MLLMs)，通过构建由原子动作组成的长链式思考(Chains of Thought, CoT)来实现逐步的多模态数学推理。该框架包括三个关键模块：CoT标注引擎自动生成高质量标注以补充数据缺失、原子步骤微调策略联合优化MLLMs和策略奖励模型(PRM)进行推理，以及四种搜索策略与PRM结合完成任务。此外，研究构建了大规模数据集AtomMATH和原子能力评估指标，实验显示AtomThink在MathVista上相对准确率提升约50%，在MathVerse上提升约120%，并计划公开代码和数据集以推动相关研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11930v3",
      "published_date": "2024-11-18 11:54:58 UTC",
      "updated_date": "2024-12-13 06:54:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:41:14.563593"
    },
    {
      "arxiv_id": "2412.02512v2",
      "title": "Pre-Deployment Information Sharing: A Zoning Taxonomy for Precursory Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Pistillo",
        "Charlotte Stix"
      ],
      "abstract": "High-impact and potentially dangerous capabilities can and should be broken\ndown into early warning shots long before reaching red lines. Each of these\nearly warning shots should correspond to a precursory capability. Each\nprecursory capability sits on a spectrum indicating its proximity to a final\nhigh-impact capability, corresponding to a red line. To meaningfully detect and\ntrack capability progress, we propose a taxonomy of dangerous capability zones\n(a zoning taxonomy) tied to a staggered information exchange framework that\nenables relevant bodies to take action accordingly. In the Frontier AI Safety\nCommitments, signatories commit to sharing more detailed information with\ntrusted actors, including an appointed body, as appropriate (Commitment VII).\nBuilding on our zoning taxonomy, this paper makes four recommendations for\nspecifying information sharing as detailed in Commitment VII. (1) Precursory\ncapabilities should be shared as soon as they become known through internal\nevaluations before deployment. (2) AI Safety Institutes (AISIs) should be the\ntrusted actors appointed to receive and coordinate information on precursory\ncomponents. (3) AISIs should establish adequate information protection\ninfrastructure and guarantee increased information security as precursory\ncapabilities move through the zones and towards red lines, including, if\nnecessary, by classifying the information on precursory capabilities or marking\nit as controlled. (4) High-impact capability progress in one geographical\nregion may translate to risk in other regions and necessitates more\ncomprehensive risk assessment internationally. As such, AISIs should exchange\ninformation on precursory capabilities with other AISIs, relying on the\nexisting frameworks on international classified exchanges and applying lessons\nlearned from other regulated high-risk sectors.",
      "tldr_zh": "该论文提出一个分区分类法（zoning taxonomy），用于将高影响力 AI 能力的早期预警信号（precursory capabilities）划分成不同区域，以跟踪其与最终危险能力的接近程度，并与分阶段信息交换框架相结合。核心目的是在 AI 部署前检测和监控风险，支持 Frontier AI Safety Commitments 中的 Commitment VII。论文给出四个具体推荐：（1）在内部评估后立即分享 precursory capabilities 信息；（2）指定 AI Safety Institutes (AISIs) 作为接收和协调方；（3）建立信息保护基础设施，包括分类或标记敏感信息；（4）促进国际间信息交换，以应对跨区域风险。该框架有助于提升 AI 安全治理和全球风险评估。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02512v2",
      "published_date": "2024-11-18 11:25:28 UTC",
      "updated_date": "2024-12-13 13:38:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:41:27.094718"
    },
    {
      "arxiv_id": "2412.03579v1",
      "title": "Towards a Practical Ethics of Generative AI in Creative Production Processes",
      "title_zh": "迈向生成式 AI 在创意生产过程中的实用伦理",
      "authors": [
        "Geert Hofman"
      ],
      "abstract": "The increasing integration of artificial intelligence into various domains,\nincluding design and creative processes, raises significant ethical questions.\nWhile AI ethics is often examined from the perspective of technology\ndevelopers, less attention has been paid to the practical ethical\nconsiderations faced by technology users, particularly in design contexts. This\npaper introduces a framework for addressing ethical challenges in creative\nproduction processes, such as the Double Diamond design model. Drawing on six\nmajor ethical theories - virtue ethics, deontology, utilitarianism, contract\ntheory, care ethics, and existentialism - we develop a \"compass\" to navigate\nand reflect on the ethical dimensions of AI in design. The framework highlights\nthe importance of responsibility, anticipation, and reflection across both the\nAI lifecycle and each stage of the creative process. We argue that by adopting\na playful and exploratory approach to AI, while remaining anchored in core\nethical principles, designers can responsibly harness the potential of AI\ntechnologies without overburdening or compromising their creative processes.",
      "tldr_zh": "这篇论文探讨了 Generative AI 在创意生产过程中的实际伦理问题，强调从技术用户（如设计师）的角度审视这些挑战，而非仅限于开发者。作者引入了一个基于六大伦理理论（包括 virtue ethics、deontology、utilitarianism、contract theory、care ethics 和 existentialism）的“compass”框架，帮助在创意流程（如 Double Diamond design model）中导航伦理维度。框架突出责任、预见和反思的重要性，主张设计师以玩乐式探索方式使用 AI，同时坚持核心伦理原则，从而负责地发挥 AI 的潜力而不影响创意过程。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.03579v1",
      "published_date": "2024-11-18 11:07:26 UTC",
      "updated_date": "2024-11-18 11:07:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:41:54.999111"
    },
    {
      "arxiv_id": "2411.11458v2",
      "title": "HistoEncoder: a digital pathology foundation model for prostate cancer",
      "title_zh": "HistoEncoder：一种用于前列腺癌的数字病理学基础模型",
      "authors": [
        "Joona Pohjonen",
        "Abderrahim-Oussama Batouche",
        "Antti Rannikko",
        "Kevin Sandeman",
        "Andrew Erickson",
        "Esa Pitkanen",
        "Tuomas Mirtti"
      ],
      "abstract": "Foundation models are trained on massive amounts of data to distinguish\ncomplex patterns and can be adapted to a wide range of downstream tasks with\nminimal computational resources. Here, we develop a foundation model for\nprostate cancer digital pathology called HistoEncoder by pre-training on 48\nmillion prostate tissue tile images. We demonstrate that HistoEncoder features\nextracted from tile images with similar histological patterns map closely\ntogether in the feature space. HistoEncoder outperforms models pre-trained with\nnatural images, even without fine-tuning or with 1000 times less training data.\nWe describe two use cases that leverage the capabilities of HistoEncoder by\nfine-tuning the model with a limited amount of data and computational\nresources. First, we show how HistoEncoder can be used to automatically\nannotate large-scale datasets with high accuracy. Second, we combine histomics\nwith commonly used clinical nomograms, significantly improving prostate\ncancer-specific death survival models. Foundation models such as HistoEncoder\ncan allow organizations with limited resources to build effective clinical\nsoftware tools without needing extensive datasets or significant amounts of\ncomputing.",
      "tldr_zh": "本文提出 HistoEncoder，一种针对前列腺癌数字病理学的 foundation model，通过在 4800 万张前列腺组织切片图像上预训练，实现对相似组织学模式的特征空间高效映射。相比使用自然图像预训练的模型，HistoEncoder 在无需微调或仅用少量数据（如 1000 倍更少的训练数据）时表现出色。研究展示了两个应用：自动高精度标注大规模数据集，以及与临床 nomograms 结合显著提升前列腺癌特异性死亡生存模型的性能。该模型使资源有限的组织能够以最小计算资源构建有效的临床工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11458v2",
      "published_date": "2024-11-18 10:46:05 UTC",
      "updated_date": "2024-11-22 13:32:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:42:07.289992"
    },
    {
      "arxiv_id": "2411.11451v2",
      "title": "Robust Markov Decision Processes: A Place Where AI and Formal Methods Meet",
      "title_zh": "翻译失败",
      "authors": [
        "Marnix Suilen",
        "Thom Badings",
        "Eline M. Bovy",
        "David Parker",
        "Nils Jansen"
      ],
      "abstract": "Markov decision processes (MDPs) are a standard model for sequential\ndecision-making problems and are widely used across many scientific areas,\nincluding formal methods and artificial intelligence (AI). MDPs do, however,\ncome with the restrictive assumption that the transition probabilities need to\nbe precisely known. Robust MDPs (RMDPs) overcome this assumption by instead\ndefining the transition probabilities to belong to some uncertainty set. We\npresent a gentle survey on RMDPs, providing a tutorial covering their\nfundamentals. In particular, we discuss RMDP semantics and how to solve them by\nextending standard MDP methods such as value iteration and policy iteration. We\nalso discuss how RMDPs relate to other models and how they are used in several\ncontexts, including reinforcement learning and abstraction techniques. We\nconclude with some challenges for future work on RMDPs.",
      "tldr_zh": "这篇论文对 Robust Markov Decision Processes (RMDPs) 进行了温和的调研，旨在解决标准 Markov Decision Processes (MDPs) 在过渡概率需精确知晓的限制问题，通过引入不确定性集来增强模型的鲁棒性。论文提供了一个基础教程，包括 RMDPs 的语义和求解方法，如扩展 value iteration 和 policy iteration，以适应实际应用场景。论文还探讨了 RMDPs 与其他模型的关系、在 reinforcement learning 和抽象技术中的应用，并指出了未来研究的挑战。",
      "categories": [
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11451v2",
      "published_date": "2024-11-18 10:34:14 UTC",
      "updated_date": "2024-12-10 09:59:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:42:19.053621"
    },
    {
      "arxiv_id": "2411.11448v1",
      "title": "Unveiling the Inflexibility of Adaptive Embedding in Traffic Forecasting",
      "title_zh": "揭示适应性嵌入在交通预测中的刚性",
      "authors": [
        "Hongjun Wang",
        "Jiyuan Chen",
        "Lingyu Zhang",
        "Renhe Jiang",
        "Xuan Song"
      ],
      "abstract": "Spatiotemporal Graph Neural Networks (ST-GNNs) and Transformers have shown\nsignificant promise in traffic forecasting by effectively modeling temporal and\nspatial correlations. However, rapid urbanization in recent years has led to\ndynamic shifts in traffic patterns and travel demand, posing major challenges\nfor accurate long-term traffic prediction. The generalization capability of\nST-GNNs in extended temporal scenarios and cross-city applications remains\nlargely unexplored. In this study, we evaluate state-of-the-art models on an\nextended traffic benchmark and observe substantial performance degradation in\nexisting ST-GNNs over time, which we attribute to their limited inductive\ncapabilities. Our analysis reveals that this degradation stems from an\ninability to adapt to evolving spatial relationships within urban environments.\nTo address this limitation, we reconsider the design of adaptive embeddings and\npropose a Principal Component Analysis (PCA) embedding approach that enables\nmodels to adapt to new scenarios without retraining. We incorporate PCA\nembeddings into existing ST-GNN and Transformer architectures, achieving marked\nimprovements in performance. Notably, PCA embeddings allow for flexibility in\ngraph structures between training and testing, enabling models trained on one\ncity to perform zero-shot predictions on other cities. This adaptability\ndemonstrates the potential of PCA embeddings in enhancing the robustness and\ngeneralization of spatiotemporal models.",
      "tldr_zh": "该研究揭示了时空图神经网络（ST-GNNs）和Transformer在交通预测中的局限性，即这些模型在面对快速城市化导致的动态交通模式时，表现出了显著的性能下降，主要是由于adaptive embeddings的归纳能力不足，无法适应演变的时空关系。研究者通过评估现有模型在扩展基准上的表现，确认了这一问题，并提出了一种基于Principal Component Analysis (PCA) embedding的新方法，以替代传统adaptive embeddings。PCA embedding允许模型在不需重新训练的情况下适应新场景，并被整合到ST-GNNs和Transformer架构中，显著提升了预测性能。该方法还实现了训练数据基于一个城市的模型对其他城市进行零样本预测，从而增强了时空模型的鲁棒性和泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11448v1",
      "published_date": "2024-11-18 10:30:34 UTC",
      "updated_date": "2024-11-18 10:30:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:42:30.997824"
    },
    {
      "arxiv_id": "2411.11436v1",
      "title": "Implicit Regularization for Multi-label Feature Selection",
      "title_zh": "针对多标签特征选择的隐式正则化",
      "authors": [
        "Dou El Kefel Mansouri",
        "Khalid Benabdeslem",
        "Seif-Eddine Benkabou"
      ],
      "abstract": "In this paper, we address the problem of feature selection in the context of\nmulti-label learning, by using a new estimator based on implicit regularization\nand label embedding. Unlike the sparse feature selection methods that use a\npenalized estimator with explicit regularization terms such as $l_{2,1}$-norm,\nMCP or SCAD, we propose a simple alternative method via Hadamard product\nparameterization. In order to guide the feature selection process, a latent\nsemantic of multi-label information method is adopted, as a label embedding.\nExperimental results on some known benchmark datasets suggest that the proposed\nestimator suffers much less from extra bias, and may lead to benign\noverfitting.",
      "tldr_zh": "本研究针对多标签学习中的特征选择问题，提出了一种基于隐式正则化（Implicit Regularization）和标签嵌入的新估计器。该方法通过Hadamard乘积参数化来实现特征选择，与传统使用显式正则化项（如l_{2,1}-norm、MCP或SCAD）的稀疏方法不同，能够减少额外偏差并更好地引导多标签信息语义。实验结果显示，在多个基准数据集上，该估计器表现出色，可能导致良性过拟合（benign overfitting），从而提升了特征选择的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 7 figures, My paper is currently under review at TPAMI\n  journal",
      "pdf_url": "http://arxiv.org/pdf/2411.11436v1",
      "published_date": "2024-11-18 10:08:05 UTC",
      "updated_date": "2024-11-18 10:08:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:42:43.784980"
    },
    {
      "arxiv_id": "2411.13592v1",
      "title": "A Novel Speech Analysis and Correction Tool for Arabic-Speaking Children",
      "title_zh": "翻译失败",
      "authors": [
        "Lamia Berriche",
        "Maha Driss",
        "Areej Ahmed Almuntashri",
        "Asma Mufreh Lghabi",
        "Heba Saleh Almudhi",
        "Munerah Abdul-Aziz Almansour"
      ],
      "abstract": "This paper introduces a new application named ArPA for Arabic kids who have\ntrouble with pronunciation. Our application comprises two key components: the\ndiagnostic module and the therapeutic module. The diagnostic process involves\ncapturing the child's speech signal, preprocessing, and analyzing it using\ndifferent machine learning classifiers like K-Nearest Neighbors (KNN), Support\nVector Machine (SVM), and Decision Trees as well as deep neural network\nclassifiers like ResNet18. The therapeutic module offers eye-catching gamified\ninterfaces in which each correctly spoken letter earns a higher avatar level,\nproviding positive reinforcement for the child's pronunciation improvement. Two\ndatasets were used for experimental evaluation: one from a childcare centre and\nthe other including Arabic alphabet pronunciation recordings. Our work uses a\nnovel technique for speech recognition using Melspectrogram and MFCC images.\nThe results show that the ResNet18 classifier on speech-to-image converted data\neffectively identifies mispronunciations in Arabic speech with an accuracy of\n99.015\\% with Mel-Spectrogram images outperforming ResNet18 with MFCC images.",
      "tldr_zh": "这篇论文引入了名为 ArPA 的新应用，旨在帮助阿拉伯语儿童诊断和纠正发音问题。应用包括诊断模块（使用机器学习分类器如 KNN、SVM 和 Decision Trees，以及深度神经网络如 ResNet18，对语音信号进行预处理和分析）和治疗模块（通过游戏化界面提供积极强化，例如正确发音可提升头像级别）。他们采用 Melspectrogram 和 MFCC 图像作为新颖的语音识别技术，并在两个数据集上进行实验，结果显示 ResNet18 与 Melspectrogram 结合的准确率达到 99.015%，优于其他配置。该工具为阿拉伯语儿童的发音训练提供了高效且引人入胜的解决方案。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13592v1",
      "published_date": "2024-11-18 09:43:40 UTC",
      "updated_date": "2024-11-18 09:43:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:42:56.267942"
    },
    {
      "arxiv_id": "2411.11409v1",
      "title": "IKEA Manuals at Work: 4D Grounding of Assembly Instructions on Internet Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Yunong Liu",
        "Cristobal Eyzaguirre",
        "Manling Li",
        "Shubh Khanna",
        "Juan Carlos Niebles",
        "Vineeth Ravi",
        "Saumitra Mishra",
        "Weiyu Liu",
        "Jiajun Wu"
      ],
      "abstract": "Shape assembly is a ubiquitous task in daily life, integral for constructing\ncomplex 3D structures like IKEA furniture. While significant progress has been\nmade in developing autonomous agents for shape assembly, existing datasets have\nnot yet tackled the 4D grounding of assembly instructions in videos, essential\nfor a holistic understanding of assembly in 3D space over time. We introduce\nIKEA Video Manuals, a dataset that features 3D models of furniture parts,\ninstructional manuals, assembly videos from the Internet, and most importantly,\nannotations of dense spatio-temporal alignments between these data modalities.\nTo demonstrate the utility of IKEA Video Manuals, we present five applications\nessential for shape assembly: assembly plan generation, part-conditioned\nsegmentation, part-conditioned pose estimation, video object segmentation, and\nfurniture assembly based on instructional video manuals. For each application,\nwe provide evaluation metrics and baseline methods. Through experiments on our\nannotated data, we highlight many challenges in grounding assembly instructions\nin videos to improve shape assembly, including handling occlusions, varying\nviewpoints, and extended assembly sequences.",
      "tldr_zh": "该论文探讨了形状组装任务（如组装 IKEA 家具），并引入 IKEA Video Manuals 数据集，该数据集包含家具部件的3D模型、指令手册、网络视频以及这些模态间的密集时空对齐注解，以实现4D Grounding。论文展示了五个关键应用：assembly plan generation、part-conditioned segmentation、part-conditioned pose estimation、video object segmentation，以及基于指令视频手册的家具组装，并提供了评估指标和基线方法。实验结果突出了在视频中grounding组装指令的挑战，包括处理遮挡、不同视角和长序列问题，从而提升了形状组装的整体理解和性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024 Datasets and Benchmarks Track",
      "pdf_url": "http://arxiv.org/pdf/2411.11409v1",
      "published_date": "2024-11-18 09:30:05 UTC",
      "updated_date": "2024-11-18 09:30:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:43:07.311027"
    },
    {
      "arxiv_id": "2411.11391v1",
      "title": "The GECo algorithm for Graph Neural Networks Explanation",
      "title_zh": "翻译失败",
      "authors": [
        "Salvatore Calderaro",
        "Domenico Amato",
        "Giosuè Lo Bosco",
        "Riccardo Rizzo",
        "Filippo Vella"
      ],
      "abstract": "Graph Neural Networks (GNNs) are powerful models that can manage complex data\nsources and their interconnection links. One of GNNs' main drawbacks is their\nlack of interpretability, which limits their application in sensitive fields.\nIn this paper, we introduce a new methodology involving graph communities to\naddress the interpretability of graph classification problems. The proposed\nmethod, called GECo, exploits the idea that if a community is a subset of graph\nnodes densely connected, this property should play a role in graph\nclassification. This is reasonable, especially if we consider the\nmessage-passing mechanism, which is the basic mechanism of GNNs. GECo analyzes\nthe contribution to the classification result of the communities in the graph,\nbuilding a mask that highlights graph-relevant structures. GECo is tested for\nGraph Convolutional Networks on six artificial and four real-world graph\ndatasets and is compared to the main explainability methods such as\nPGMExplainer, PGExplainer, GNNExplainer, and SubgraphX using four different\nmetrics. The obtained results outperform the other methods for artificial graph\ndatasets and most real-world datasets.",
      "tldr_zh": "这篇论文提出了 GECo 算法，用于提升 Graph Neural Networks (GNNs) 的可解释性，解决其在敏感领域应用受限的问题。GECo 通过分析图社区（密集连接的子集）对图分类结果的贡献，并结合 GNNs 的消息传递机制，构建一个掩码来突出图的相关结构。在 Graph Convolutional Networks 上进行的实验显示，GECo 在六个人工和四个真实世界数据集上，使用四种指标与 PGMExplainer、PGExplainer、GNNExplainer 和 SubgraphX 等方法比较，结果在人工数据集上全面优于其他方法，并在大多数真实世界数据集上表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11391v1",
      "published_date": "2024-11-18 09:08:30 UTC",
      "updated_date": "2024-11-18 09:08:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:43:19.281766"
    },
    {
      "arxiv_id": "2411.11364v1",
      "title": "Continual Task Learning through Adaptive Policy Self-Composition",
      "title_zh": "翻译失败",
      "authors": [
        "Shengchao Hu",
        "Yuhang Zhou",
        "Ziqing Fan",
        "Jifeng Hu",
        "Li Shen",
        "Ya Zhang",
        "Dacheng Tao"
      ],
      "abstract": "Training a generalizable agent to continually learn a sequence of tasks from\noffline trajectories is a natural requirement for long-lived agents, yet\nremains a significant challenge for current offline reinforcement learning (RL)\nalgorithms. Specifically, an agent must be able to rapidly adapt to new tasks\nusing newly collected trajectories (plasticity), while retaining knowledge from\npreviously learned tasks (stability). However, systematic analyses of this\nsetting are scarce, and it remains unclear whether conventional continual\nlearning (CL) methods are effective in continual offline RL (CORL) scenarios.\nIn this study, we develop the Offline Continual World benchmark and demonstrate\nthat traditional CL methods struggle with catastrophic forgetting, primarily\ndue to the unique distribution shifts inherent to CORL scenarios. To address\nthis challenge, we introduce CompoFormer, a structure-based continual\ntransformer model that adaptively composes previous policies via a meta-policy\nnetwork. Upon encountering a new task, CompoFormer leverages semantic\ncorrelations to selectively integrate relevant prior policies alongside newly\ntrained parameters, thereby enhancing knowledge sharing and accelerating the\nlearning process. Our experiments reveal that CompoFormer outperforms\nconventional CL methods, particularly in longer task sequences, showcasing a\npromising balance between plasticity and stability.",
      "tldr_zh": "这篇论文探讨了在离线强化学习（RL）中训练代理持续学习任务序列的挑战，强调代理需实现快速适应新任务（plasticity）的同时保留先前知识（stability），但传统持续学习（CL）方法容易因分布偏移导致灾难性遗忘。作者开发了 Offline Continual World 基准，并引入 CompoFormer，一种基于结构的持续 transformer 模型，通过元策略网络（meta-policy network）利用语义相关性自适应组合先前策略和新参数，从而提升知识共享和学习效率。实验结果表明，CompoFormer 在更长的任务序列中显著优于传统 CL 方法，实现了 plasticity 和 stability 的更好平衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.11364v1",
      "published_date": "2024-11-18 08:20:21 UTC",
      "updated_date": "2024-11-18 08:20:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:43:31.760713"
    },
    {
      "arxiv_id": "2411.12584v1",
      "title": "Leveraging MLLM Embeddings and Attribute Smoothing for Compositional Zero-Shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xudong Yan",
        "Songhe Feng",
        "Yang Zhang",
        "Jian Yang",
        "Yueguan Lin",
        "Haojun Fei"
      ],
      "abstract": "Compositional zero-shot learning (CZSL) aims to recognize novel compositions\nof attributes and objects learned from seen compositions. Previous works\ndisentangle attribute and object by extracting shared and exclusive parts\nbetween image pairs sharing the same attribute (object), as well as aligning\nthem with pretrained word embeddings to improve unseen attribute-object\nrecognition. Despite the significant achievements of existing efforts, they are\nhampered by three limitations: (1) the efficacy of disentanglement is\ncompromised due to the influence of the background and the intricate\nentanglement of attribute with object in the same parts. (2) existing word\nembeddings fail to capture complex multimodal semantic information. (3)\noverconfidence exhibited by existing models in seen compositions hinders their\ngeneralization to novel compositions. Being aware of these, we propose a novel\nframework named Multimodal Large Language Model (MLLM) embeddings and attribute\nsmoothing guided disentanglement (TRIDENT) for CZSL. First, we leverage feature\nadaptive aggregation modules to mitigate the impact of background, and utilize\nlearnable condition masks to capture multigranularity features for\ndisentanglement. Then, the last hidden states of MLLM are employed as word\nembeddings for their superior representation capabilities. Moreover, we propose\nattribute smoothing with auxiliary attributes generated by Large Language Model\n(LLM) for seen compositions, addressing the issue of overconfidence by\nencouraging the model to learn more attributes in one given composition.\nExtensive experiments demonstrate that TRIDENT achieves state-of-the-art\nperformance on three benchmarks.",
      "tldr_zh": "本论文针对Compositional Zero-Shot Learning (CZSL)中的挑战，提出TRIDENT框架，以解决属性与对象的解缠结问题、词嵌入的语义局限性和模型的过度自信问题。主要方法包括使用特征自适应聚合模块减轻背景影响、可学习条件掩码捕获多粒度特征，以及采用Multimodal Large Language Model (MLLM) 的隐藏状态作为高级词嵌入，并通过Large Language Model (LLM) 生成辅助属性进行属性平滑。实验结果显示，TRIDENT在三个基准数据集上实现了state-of-the-art性能，显著提升了新型组合的识别能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12584v1",
      "published_date": "2024-11-18 07:55:54 UTC",
      "updated_date": "2024-11-18 07:55:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:43:43.896777"
    },
    {
      "arxiv_id": "2411.12768v1",
      "title": "CROW: Eliminating Backdoors from Large Language Models via Internal Consistency Regularization",
      "title_zh": "CROW：通过内部一致性正则化消除大语言模型中的后门",
      "authors": [
        "Nay Myat Min",
        "Long H. Pham",
        "Yige Li",
        "Jun Sun"
      ],
      "abstract": "Recent studies reveal that Large Language Models (LLMs) are susceptible to\nbackdoor attacks, where adversaries embed hidden triggers that manipulate model\nresponses. Existing backdoor defense methods are primarily designed for vision\nor classification tasks, and are thus ineffective for text generation tasks,\nleaving LLMs vulnerable. We introduce Internal Consistency Regularization\n(CROW), a novel defense using consistency regularization finetuning to address\nlayer-wise inconsistencies caused by backdoor triggers. CROW leverages the\nintuition that clean models exhibit smooth, consistent transitions in hidden\nrepresentations across layers, whereas backdoored models show noticeable\nfluctuation when triggered. By enforcing internal consistency through\nadversarial perturbations and regularization, CROW neutralizes backdoor effects\nwithout requiring clean reference models or prior trigger knowledge, relying\nonly on a small set of clean data. This makes it practical for deployment\nacross various LLM architectures. Experimental results demonstrate that CROW\nconsistently achieves a significant reductions in attack success rates across\ndiverse backdoor strategies and tasks, including negative sentiment, targeted\nrefusal, and code injection, on models such as Llama-2 (7B, 13B), CodeLlama\n(7B, 13B) and Mistral-7B, while preserving the model's generative capabilities.",
      "tldr_zh": "该研究针对大型语言模型（Large Language Models, LLMs）易受后门攻击（backdoor attacks）的漏洞，提出了一种名为 Internal Consistency Regularization（CROW）的防御方法，通过一致性正则化微调来消除层级隐藏表示的不一致性。CROW 利用 clean models 的平滑层间过渡特性，并在 adversarial perturbations 和 regularization 的帮助下中和后门效果，仅需少量 clean data，而不依赖参考模型或触发器知识。实验结果显示，CROW 在多种后门策略和任务（如 negative sentiment、targeted refusal 和 code injection）上显著降低了攻击成功率，在 Llama-2（7B、13B）、CodeLlama（7B、13B）和 Mistral-7B 等模型中平均减少攻击成功率，同时保持了模型的生成能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12768v1",
      "published_date": "2024-11-18 07:52:12 UTC",
      "updated_date": "2024-11-18 07:52:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:43:55.570796"
    },
    {
      "arxiv_id": "2411.11354v1",
      "title": "A comprehensive survey of oracle character recognition: challenges, benchmarks, and beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Li",
        "Xueke Chi",
        "Qiufeng Wang",
        "Dahan Wang",
        "Kaizhu Huang",
        "Yongge Liu",
        "Cheng-lin Liu"
      ],
      "abstract": "Oracle character recognition-an analysis of ancient Chinese inscriptions\nfound on oracle bones-has become a pivotal field intersecting archaeology,\npaleography, and historical cultural studies. Traditional methods of oracle\ncharacter recognition have relied heavily on manual interpretation by experts,\nwhich is not only labor-intensive but also limits broader accessibility to the\ngeneral public. With recent breakthroughs in pattern recognition and deep\nlearning, there is a growing movement towards the automation of oracle\ncharacter recognition (OrCR), showing considerable promise in tackling the\nchallenges inherent to these ancient scripts. However, a comprehensive\nunderstanding of OrCR still remains elusive. Therefore, this paper presents a\nsystematic and structured survey of the current landscape of OrCR research. We\ncommence by identifying and analyzing the key challenges of OrCR. Then, we\nprovide an overview of the primary benchmark datasets and digital resources\navailable for OrCR. A review of contemporary research methodologies follows, in\nwhich their respective efficacies, limitations, and applicability to the\ncomplex nature of oracle characters are critically highlighted and examined.\nAdditionally, our review extends to ancillary tasks associated with OrCR across\ndiverse disciplines, providing a broad-spectrum analysis of its applications.\nWe conclude with a forward-looking perspective, proposing potential avenues for\nfuture investigations that could yield significant advancements in the field.",
      "tldr_zh": "这篇论文对甲骨文字符识别（Oracle Character Recognition, OrCR）进行了全面调查，强调了其在考古、古文字学和历史文化研究中的关键作用，以及传统手动解读方法的劳动密集型局限性。作者分析了OrCR的主要挑战，如字符复杂性和领域知识缺口，并概述了关键基准数据集和数字资源，同时审查了当代研究方法，包括模式识别和深度学习的应用及其优缺点。论文扩展到相关任务的应用，并提出未来研究方向，如自动化技术的创新，以推动OrCR领域的进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11354v1",
      "published_date": "2024-11-18 07:50:22 UTC",
      "updated_date": "2024-11-18 07:50:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:44:06.928403"
    },
    {
      "arxiv_id": "2411.11344v3",
      "title": "Mitigating Knowledge Conflicts in Language Model-Driven Question Answering",
      "title_zh": "缓解语言模型驱动的问题回答中的知识冲突",
      "authors": [
        "Han Cao",
        "Zhaoyang Zhang",
        "Xiangtian Li",
        "Chufan Wu",
        "Hansong Zhang",
        "Wenqing Zhang"
      ],
      "abstract": "In the context of knowledge-driven seq-to-seq generation tasks, such as\ndocument-based question answering and document summarization systems, two\nfundamental knowledge sources play crucial roles: the inherent knowledge\nembedded within model parameters and the external knowledge obtained through\ncontext. Recent studies revealed a significant challenge: when there exists a\nmisalignment between the model's inherent knowledge and the ground truth\nanswers in training data, the system may exhibit problematic behaviors during\ninference, such as ignoring input context, or generating unfaithful content.\nOur investigation proposes a strategy to minimize hallucination by building\nexplicit connection between source inputs and generated outputs. We\nspecifically target a common hallucination pattern in question answering,\nexamining how the correspondence between entities and their contexts during\nmodel training influences the system's performance at inference time.",
      "tldr_zh": "该论文探讨了在语言模型驱动的问题回答任务中，模型的内在知识和外部知识（如输入上下文）之间存在的冲突问题，这种冲突可能导致模型忽略上下文或生成不忠实内容（hallucination）。为了缓解这一问题，研究提出了一种策略，通过在训练过程中建立源输入和生成输出之间的明确连接，来最小化幻觉的发生。论文特别关注了实体及其上下文对应关系对模型推理性能的影响，为提升知识驱动的序列到序列生成任务的可靠性提供了新方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "revised version, more figures",
      "pdf_url": "http://arxiv.org/pdf/2411.11344v3",
      "published_date": "2024-11-18 07:33:10 UTC",
      "updated_date": "2025-01-15 07:46:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:44:18.782562"
    },
    {
      "arxiv_id": "2412.03578v1",
      "title": "PerfCodeGen: Improving Performance of LLM Generated Code with Execution Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Yun Peng",
        "Akhilesh Deepak Gotmare",
        "Michael Lyu",
        "Caiming Xiong",
        "Silvio Savarese",
        "Doyen Sahoo"
      ],
      "abstract": "Large Language Models (LLMs) are widely adopted for assisting in software\ndevelopment tasks, yet their performance evaluations have narrowly focused on\nthe functional correctness of generated code. Human programmers, however,\nrequire LLM-generated code to be not only correct but also optimally efficient.\nWe propose PerfCodeGen, a training-free framework that enhances the performance\nof LLM-generated code by incorporating feedback based on runtime during test\ncase execution into the self-refinement iterations. With PerfCodeGen, we\nachieve speedups for a significantly higher proportion of problems compared to\nusing the base LLM with sophisticated prompting techniques. Applied to open\nlanguage models like Phi-3-mini, PerfCodeGen achieves runtime efficiency\ncomparable to prompting powerful closed models like GPT-4. We achieve\nstate-of-the-art runtime efficiency on benchmarks such as HumanEval, MBPP, and\nAPPS, frequently surpassing the ground truth reference solutions with\nPerfCodeGen using GPT-3.5 and GPT-4. Additionally, we demonstrate the\neffectiveness of our approach in enhancing code quality across a range of open\nLLMs of varying sizes including Phi-3-mini, Llama 3 8B, Mixtral 8x7B, Command\nR, and Llama 3 70B.",
      "tldr_zh": "该研究指出，大型语言模型(LLMs)生成的代码虽功能正确，但效率不足，提出PerfCodeGen——一个无训练框架，通过整合测试用例执行中的运行时反馈(self-refinement iterations)来提升代码性能。相比基础LLM和复杂提示技术，PerfCodeGen在更多问题上实现了显著速度提升，并在Phi-3-mini等开源模型上达到与GPT-4相当的运行时效率。实验结果显示，该框架在HumanEval、MBPP和APPS基准上实现了最先进的运行时效率，甚至超过了参考解决方案，并适用于多种LLMs如Llama 3 8B和Mixtral 8x7B，提升了整体代码质量。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03578v1",
      "published_date": "2024-11-18 06:22:38 UTC",
      "updated_date": "2024-11-18 06:22:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:44:31.441315"
    },
    {
      "arxiv_id": "2411.11318v1",
      "title": "Syllabus: Portable Curricula for Reinforcement Learning Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Ryan Sullivan",
        "Ryan Pégoud",
        "Ameen Ur Rahmen",
        "Xinchen Yang",
        "Junyun Huang",
        "Aayush Verma",
        "Nistha Mitra",
        "John P. Dickerson"
      ],
      "abstract": "Curriculum learning has been a quiet yet crucial component of many of the\nhigh-profile successes of reinforcement learning. Despite this, none of the\nmajor reinforcement learning libraries directly support curriculum learning or\ninclude curriculum learning implementations. These methods can improve the\ncapabilities and robustness of RL agents, but often require significant,\ncomplex changes to agent training code. We introduce Syllabus, a library for\ntraining RL agents with curriculum learning, as a solution to this problem.\nSyllabus provides a universal API for curriculum learning algorithms,\nimplementations of popular curriculum learning methods, and infrastructure for\neasily integrating them with distributed training code written in nearly any RL\nlibrary. Syllabus provides a minimal API for each of the core components of\ncurriculum learning, dramatically simplifying the process of designing new\nalgorithms and applying existing algorithms to new environments. We demonstrate\nthat the same Syllabus code can be used to train agents written in multiple\ndifferent RL libraries on numerous domains. In doing so, we present the first\nexamples of curriculum learning in NetHack and Neural MMO, two of the premier\nchallenges for single-agent and multi-agent RL respectively, achieving strong\nresults compared to state of the art baselines.",
      "tldr_zh": "该论文介绍了Syllabus库，这是一个便携式工具，用于在Reinforcement Learning (RL)代理中实现Curriculum Learning，以提升代理的性能和鲁棒性。Syllabus提供通用API、流行算法的实现，以及与多种RL库的分布式训练代码轻松集成的基础设施，大大简化了设计新算法和应用现有算法的过程。实验结果显示，使用Syllabus训练的代理在NetHack和Neural MMO等复杂环境中，取得了比现有基准更强的表现，证明了其在单代理和多代理RL挑战中的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2411.11318v1",
      "published_date": "2024-11-18 06:22:30 UTC",
      "updated_date": "2024-11-18 06:22:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:44:48.889914"
    },
    {
      "arxiv_id": "2411.11312v1",
      "title": "Study of the Performance of CEEMDAN in Underdetermined Speech Separation",
      "title_zh": "CEEMDAN 在欠确定语音分离中的性能研究",
      "authors": [
        "Rawad Melhem",
        "Riad Hamadeh",
        "Assef Jafar"
      ],
      "abstract": "The CEEMDAN algorithm is one of the modern methods used in the analysis of\nnon-stationary signals. This research presents a study of the effectiveness of\nthis method in audio source separation to know the limits of its work. It\nconcluded two conditions related to frequencies and amplitudes of mixed signals\nto be separated by CEEMDAN. The performance of the algorithm in separating\nnoise from speech and separating speech signals from each other is studied. The\nresearch reached a conclusion that CEEMDAN can remove some types of noise from\nspeech (speech improvement), and it cannot separate speech signals from each\nother (cocktail party). Simulation is done using Matlab environment and Noizeus\ndatabase.",
      "tldr_zh": "这篇论文研究了 CEEMDAN 算法在欠确定语音分离中的性能，针对非平稳信号的分析，探讨了其在音频源分离中的有效性。研究得出了两个与混合信号频率和幅度相关的条件，并评估了算法在去除语音中的噪声（语音改善）和分离多个语音信号（鸡尾酒派对问题）方面的表现。最终结论是，CEEMDAN 能有效移除某些类型噪声，但无法分离多个语音信号；实验通过 Matlab 和 Noizeus 数据库进行模拟验证。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "in Arabic language",
      "pdf_url": "http://arxiv.org/pdf/2411.11312v1",
      "published_date": "2024-11-18 06:13:51 UTC",
      "updated_date": "2024-11-18 06:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:46:48.708032"
    },
    {
      "arxiv_id": "2411.11305v2",
      "title": "TP-UNet: Temporal Prompt Guided UNet for Medical Image Segmentation",
      "title_zh": "TP-UNet：基于时间提示",
      "authors": [
        "Ranmin Wang",
        "Limin Zhuang",
        "Hongkun Chen",
        "Boyan Xu",
        "Ruichu Cai"
      ],
      "abstract": "The advancement of medical image segmentation techniques has been propelled\nby the adoption of deep learning techniques, particularly UNet-based\napproaches, which exploit semantic information to improve the accuracy of\nsegmentations. However, the order of organs in scanned images has been\ndisregarded by current medical image segmentation approaches based on UNet.\nFurthermore, the inherent network structure of UNet does not provide direct\ncapabilities for integrating temporal information. To efficiently integrate\ntemporal information, we propose TP-UNet that utilizes temporal prompts,\nencompassing organ-construction relationships, to guide the segmentation UNet\nmodel. Specifically, our framework is featured with cross-attention and\nsemantic alignment based on unsupervised contrastive learning to combine\ntemporal prompts and image features effectively. Extensive evaluations on two\nmedical image segmentation datasets demonstrate the state-of-the-art\nperformance of TP-UNet. Our implementation will be open-sourced after\nacceptance.",
      "tldr_zh": "本研究针对现有UNet基于医疗图像分割方法忽略器官在扫描图像中的顺序和时间信息的问题，提出TP-UNet框架，利用temporal prompts来引导分割模型。具体地，TP-UNet通过cross-attention和基于unsupervised contrastive learning的semantic alignment，高效结合时间提示和图像特征。在两个医疗图像分割数据集上的广泛评估中，TP-UNet实现了state-of-the-art性能，并计划开源实现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11305v2",
      "published_date": "2024-11-18 06:01:00 UTC",
      "updated_date": "2024-11-20 02:24:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:45:07.113534"
    },
    {
      "arxiv_id": "2411.11303v1",
      "title": "Recurrent Stochastic Configuration Networks with Incremental Blocks",
      "title_zh": "翻译失败",
      "authors": [
        "Gang Dang",
        "Dainhui Wang"
      ],
      "abstract": "Recurrent stochastic configuration networks (RSCNs) have shown promise in\nmodelling nonlinear dynamic systems with order uncertainty due to their\nadvantages of easy implementation, less human intervention, and strong\napproximation capability. This paper develops the original RSCNs with block\nincrements, termed block RSCNs (BRSCNs), to further enhance the learning\ncapacity and efficiency of the network. BRSCNs can simultaneously add multiple\nreservoir nodes (subreservoirs) during the construction. Each subreservoir is\nconfigured with a unique structure in the light of a supervisory mechanism,\nensuring the universal approximation property. The reservoir feedback matrix is\nappropriately scaled to guarantee the echo state property of the network.\nFurthermore, the output weights are updated online using a projection\nalgorithm, and the persistent excitation conditions that facilitate parameter\nconvergence are also established. Numerical results over a time series\nprediction, a nonlinear system identification task, and two industrial data\npredictive analyses demonstrate that the proposed BRSCN performs favourably in\nterms of modelling efficiency, learning, and generalization performance,\nhighlighting their significant potential for coping with complex dynamics.",
      "tldr_zh": "本论文提出了一种改进的 Recurrent Stochastic Configuration Networks (RSCNs)，称为 Block RSCNs (BRSCNs)，通过同时添加多个 reservoir nodes (subreservoirs) 来提升网络的学习能力和建模效率。每个 subreservoir 利用 supervisory mechanism 配置独特结构，确保 universal approximation property，同时通过缩放 reservoir feedback matrix 维持 echo state property，并采用 projection algorithm 在线更新输出权重，同时建立了 persistent excitation conditions 以促进参数收敛。实验结果显示，BRSCNs 在时间序列预测、非线性系统识别和工业数据预测任务中表现出优异的建模效率、学习和泛化性能，适用于处理复杂动态系统。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11303v1",
      "published_date": "2024-11-18 05:58:47 UTC",
      "updated_date": "2024-11-18 05:58:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:45:20.193214"
    },
    {
      "arxiv_id": "2411.11302v1",
      "title": "Towards Personalized Brain-Computer Interface Application Based on Endogenous EEG Paradigms",
      "title_zh": "翻译失败",
      "authors": [
        "Heon-Gyu Kwak",
        "Gi-Hwan Shin",
        "Yeon-Woo Choi",
        "Dong-Hoon Lee",
        "Yoo-In Jeon",
        "Jun-Su Kang",
        "Seong-Whan Lee"
      ],
      "abstract": "In this paper, we propose a conceptual framework for personalized\nbrain-computer interface (BCI) applications, which can offer an enhanced user\nexperience by customizing services to individual preferences and needs, based\non endogenous electroencephalography (EEG) paradigms including motor imagery\n(MI), speech imagery (SI), and visual imagery. The framework includes two\nessential components: user identification and intention classification, which\nenable personalized services by identifying individual users and recognizing\ntheir intended actions through EEG signals. We validate the feasibility of our\nframework using a private EEG dataset collected from eight subjects, employing\nthe ShallowConvNet architecture to decode EEG features. The experimental\nresults demonstrate that user identification achieved an average classification\naccuracy of 0.995, while intention classification achieved 0.47 accuracy across\nall paradigms, with MI demonstrating the best performance. These findings\nindicate that EEG signals can effectively support personalized BCI\napplications, offering robust identification and reliable intention decoding,\nespecially for MI and SI.",
      "tldr_zh": "本文提出一个概念框架，用于基于内源性 EEG 范式的个性化脑机接口 (BCI) 应用，包括运动想象 (MI)、语音想象 (SI) 和视觉想象，以定制用户偏好和服务。框架的核心组件为用户识别和意图分类，通过 ShallowConvNet 架构对 EEG 信号进行解码。实验使用八个受试者的私人数据集验证，结果显示用户识别准确率平均达 0.995，而意图分类准确率平均为 0.47，以 MI 表现最佳。这些发现证明 EEG 信号能有效支持可靠的个性化 BCI 应用，尤其在 MI 和 SI 方面。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Submissoion version for IEEE International BCI Winter Conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.11302v1",
      "published_date": "2024-11-18 05:58:41 UTC",
      "updated_date": "2024-11-18 05:58:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:45:31.838731"
    },
    {
      "arxiv_id": "2411.13591v5",
      "title": "Improved GUI Grounding via Iterative Narrowing",
      "title_zh": "翻译失败",
      "authors": [
        "Anthony Nguyen"
      ],
      "abstract": "Graphical User Interface (GUI) grounding plays a crucial role in enhancing\nthe capabilities of Vision-Language Model (VLM) agents. While general VLMs,\nsuch as GPT-4V, demonstrate strong performance across various tasks, their\nproficiency in GUI grounding remains suboptimal. Recent studies have focused on\nfine-tuning these models specifically for zero-shot GUI grounding, yielding\nsignificant improvements over baseline performance. We introduce a visual\nprompting framework that employs an iterative narrowing mechanism to further\nimprove the performance of both general and fine-tuned models in GUI grounding.\nFor evaluation, we tested our method on a comprehensive benchmark comprising\nvarious UI platforms and provided the code to reproduce our results.",
      "tldr_zh": "本文提出了一种视觉提示框架，通过迭代缩窄(iterative narrowing)机制来提升 Vision-Language Model (VLM) 在 GUI grounding 任务中的性能，以解决一般模型如 GPT-4V 的不足。该框架适用于既有的通用和微调模型，能够进一步改善零样本 GUI grounding 的准确性。研究在涵盖多种 UI 平台的综合基准上进行了评估，并公开了代码以便重现结果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Code available at\n  https://github.com/ant-8/GUI-Grounding-via-Iterative-Narrowing",
      "pdf_url": "http://arxiv.org/pdf/2411.13591v5",
      "published_date": "2024-11-18 05:47:12 UTC",
      "updated_date": "2024-12-20 07:16:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:45:42.469248"
    },
    {
      "arxiv_id": "2411.11295v1",
      "title": "Transcending Language Boundaries: Harnessing LLMs for Low-Resource Language Translation",
      "title_zh": "超越语言界限：利用大型语言模型进行低资源语言翻译",
      "authors": [
        "Peng Shu",
        "Junhao Chen",
        "Zhengliang Liu",
        "Hui Wang",
        "Zihao Wu",
        "Tianyang Zhong",
        "Yiwei Li",
        "Huaqin Zhao",
        "Hanqi Jiang",
        "Yi Pan",
        "Yifan Zhou",
        "Constance Owl",
        "Xiaoming Zhai",
        "Ninghao Liu",
        "Claudio Saunt",
        "Tianming Liu"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable success across a\nwide range of tasks and domains. However, their performance in low-resource\nlanguage translation, particularly when translating into these languages,\nremains underexplored. This gap poses significant challenges, as linguistic\nbarriers hinder the cultural preservation and development of minority\ncommunities. To address this issue, this paper introduces a novel\nretrieval-based method that enhances translation quality for low-resource\nlanguages by focusing on key terms, which involves translating keywords and\nretrieving corresponding examples from existing data. To evaluate the\neffectiveness of this method, we conducted experiments translating from English\ninto three low-resource languages: Cherokee, a critically endangered indigenous\nlanguage of North America; Tibetan, a historically and culturally significant\nlanguage in Asia; and Manchu, a language with few remaining speakers. Our\ncomparison with the zero-shot performance of GPT-4o and LLaMA 3.1 405B,\nhighlights the significant challenges these models face when translating into\nlow-resource languages. In contrast, our retrieval-based method shows promise\nin improving both word-level accuracy and overall semantic understanding by\nleveraging existing resources more effectively.",
      "tldr_zh": "这篇论文探讨了大语言模型（LLMs）在低资源语言翻译中的不足，特别是翻译成这些语言时面临的挑战，并强调了语言障碍对少数民族文化保存的影响。论文提出了一种新颖的基于检索的方法，通过翻译关键词并从现有数据中检索对应示例，来提升翻译质量。实验结果显示，该方法在从英语翻译到 Cherokee、Tibetan 和 Manchu 等低资源语言时，比 GPT-4o 和 LLaMA 3.1 405B 的零样本性能更出色，显著提高了词级准确性和整体语义理解，从而为文化保护提供潜在支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11295v1",
      "published_date": "2024-11-18 05:41:27 UTC",
      "updated_date": "2024-11-18 05:41:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:47:00.838122"
    },
    {
      "arxiv_id": "2411.13590v1",
      "title": "Deep learning waterways for rural infrastructure development",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Pierson",
        "Zia Mehrabi"
      ],
      "abstract": "Surprisingly a number of Earth's waterways remain unmapped, with a\nsignificant number in low and middle income countries. Here we build a computer\nvision model (WaterNet) to learn the location of waterways in the United\nStates, based on high resolution satellite imagery and digital elevation\nmodels, and then deploy this in novel environments in the African continent.\nOur outputs provide detail of waterways structures hereto unmapped. When\nassessed against community needs requests for rural bridge building related to\naccess to schools, health care facilities and agricultural markets, we find\nthese newly generated waterways capture on average 93% (country range: 88-96%)\nof these requests whereas Open Street Map, and the state of the art data from\nTDX-Hydro, capture only 36% (5-72%) and 62% (37%-85%), respectively. Because\nthese new machine learning enabled maps are built on public and operational\ndata acquisition this approach offers promise for capturing humanitarian needs\nand planning for social development in places where cartographic efforts have\nso far failed to deliver. The improved performance in identifying community\nneeds missed by existing data suggests significant value for rural\ninfrastructure development and better targeting of development interventions.",
      "tldr_zh": "这篇论文开发了WaterNet计算机视觉模型，使用高分辨率卫星图像和数字高程模型来识别美国水道，并将其部署到非洲等未映射区域，提供之前缺失的水道结构细节。相比之下，WaterNet在捕捉社区农村桥梁建设需求（如通往学校、医疗设施和农业市场的需求）时，平均捕捉率达93%，而Open Street Map和TDX-Hydro仅为36%和62%。这种基于公共数据的机器学习方法，有望更好地识别人道主义需求，推动农村基础设施发展和针对性干预。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "68",
        "D.0"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.13590v1",
      "published_date": "2024-11-18 05:36:05 UTC",
      "updated_date": "2024-11-18 05:36:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:47:11.878695"
    },
    {
      "arxiv_id": "2411.11289v1",
      "title": "LP Data Pipeline: Lightweight, Purpose-driven Data Pipeline for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yungi Kim",
        "Hyunsoo Ha",
        "Seonghoon Yang",
        "Sukyung Lee",
        "Jihoo Kim",
        "Chanjun Park"
      ],
      "abstract": "Creating high-quality, large-scale datasets for large language models (LLMs)\noften relies on resource-intensive, GPU-accelerated models for quality\nfiltering, making the process time-consuming and costly. This dependence on\nGPUs limits accessibility for organizations lacking significant computational\ninfrastructure. To address this issue, we introduce the Lightweight,\nPurpose-driven (LP) Data Pipeline, a framework that operates entirely on CPUs\nto streamline the processes of dataset extraction, filtering, and curation.\nBased on our four core principles, the LP Data Pipeline significantly reduces\npreparation time and cost while maintaining high data quality. Importantly, our\npipeline enables the creation of purpose-driven datasets tailored to specific\ndomains and languages, enhancing the applicability of LLMs in specialized\ncontexts. We anticipate that our pipeline will lower the barriers to LLM\ndevelopment, enabling a wide range of organizations to access LLMs more easily.",
      "tldr_zh": "该论文提出了 LP Data Pipeline，这是一个轻量级、目的驱动的数据管道框架，用于 Large Language Models (LLMs)，旨在解决传统数据集创建依赖 GPU 的问题，从而降低时间和成本。框架完全基于 CPU 操作，通过四个核心原则来处理数据集的提取、过滤和整理，同时保持高数据质量。该管道支持创建针对特定领域和语言的定制数据集，有助于增强 LLMs 在专业场景中的适用性，并降低 LLM 开发的门槛，使更多组织能够轻松访问这些模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11289v1",
      "published_date": "2024-11-18 05:17:27 UTC",
      "updated_date": "2024-11-18 05:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:47:23.484249"
    },
    {
      "arxiv_id": "2411.11285v2",
      "title": "Zero-Shot Automatic Annotation and Instance Segmentation using LLM-Generated Datasets: Eliminating Field Imaging and Manual Annotation for Deep Learning Model Development",
      "title_zh": "翻译失败",
      "authors": [
        "Ranjan Sapkota",
        "Achyut Paudel",
        "Manoj Karkee"
      ],
      "abstract": "Currently, deep learning-based instance segmentation for various applications\n(e.g., Agriculture) is predominantly performed using a labor-intensive process\ninvolving extensive field data collection using sophisticated sensors, followed\nby careful manual annotation of images, presenting significant logistical and\nfinancial challenges to researchers and organizations. The process also slows\ndown the model development and training process. In this study, we presented a\nnovel method for deep learning-based instance segmentation of apples in\ncommercial orchards that eliminates the need for labor-intensive field data\ncollection and manual annotation. Utilizing a Large Language Model (LLM), we\nsynthetically generated orchard images and automatically annotated them using\nthe Segment Anything Model (SAM) integrated with a YOLO11 base model. This\nmethod significantly reduces reliance on physical sensors and manual data\nprocessing, presenting a major advancement in \"Agricultural AI\". The synthetic,\nauto-annotated dataset was used to train the YOLO11 model for Apple instance\nsegmentation, which was then validated on real orchard images. The results\nshowed that the automatically generated annotations achieved a Dice Coefficient\nof 0.9513 and an IoU of 0.9303, validating the accuracy and overlap of the mask\nannotations. All YOLO11 configurations, trained solely on these synthetic\ndatasets with automated annotations, accurately recognized and delineated\napples, highlighting the method's efficacy. Specifically, the YOLO11m-seg\nconfiguration achieved a mask precision of 0.902 and a mask mAP@50 of 0.833 on\ntest images collected from a commercial orchard. Additionally, the YOLO11l-seg\nconfiguration outperformed other models in validation on 40 LLM-generated\nimages, achieving the highest mask precision and mAP@50 metrics.\n  Keywords: YOLO, SAM, SAMv2, YOLO11, YOLOv11, Segment Anything, YOLO-SAM",
      "tldr_zh": "这篇论文提出了一种零样本自动标注和实例分割方法，使用 Large Language Model (LLM) 生成的合成数据集，消除了农业领域（如苹果 orchard）中实地成像和手动标注的劳动密集型过程，从而加速深度学习模型开发。方法涉及通过 LLM 合成 orchard 图像，并结合 Segment Anything Model (SAM) 与 YOLO11 基模型进行自动标注，然后使用这些数据集训练 YOLO11 模型。实验结果显示，该方法在真实图像上达到了 Dice Coefficient 0.9513 和 IoU 0.9303 的高精度，YOLO11m-seg 配置的 mask precision 为 0.902 和 mask mAP@50 为 0.833，证明了其在农业 AI 中的高效性和潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11285v2",
      "published_date": "2024-11-18 05:11:29 UTC",
      "updated_date": "2025-02-28 00:44:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:47:37.138760"
    },
    {
      "arxiv_id": "2411.11283v1",
      "title": "Multi-Hyperbolic Space-based Heterogeneous Graph Attention Network",
      "title_zh": "翻译失败",
      "authors": [
        "Jongmin Park",
        "Seunghoon Han",
        "Jong-Ryul Lee",
        "Sungsu Lim"
      ],
      "abstract": "To leverage the complex structures within heterogeneous graphs, recent\nstudies on heterogeneous graph embedding use a hyperbolic space, characterized\nby a constant negative curvature and exponentially increasing space, which\naligns with the structural properties of heterogeneous graphs. However, despite\nheterogeneous graphs inherently possessing diverse power-law structures, most\nhyperbolic heterogeneous graph embedding models use a single hyperbolic space\nfor the entire heterogeneous graph, which may not effectively capture the\ndiverse power-law structures within the heterogeneous graph. To address this\nlimitation, we propose Multi-hyperbolic Space-based heterogeneous Graph\nAttention Network (MSGAT), which uses multiple hyperbolic spaces to effectively\ncapture diverse power-law structures within heterogeneous graphs. We conduct\ncomprehensive experiments to evaluate the effectiveness of MSGAT. The\nexperimental results demonstrate that MSGAT outperforms state-of-the-art\nbaselines in various graph machine learning tasks, effectively capturing the\ncomplex structures of heterogeneous graphs.",
      "tldr_zh": "该研究针对异构图（heterogeneous graphs）的复杂结构，指出现有双曲空间（hyperbolic space）嵌入方法使用单一空间，无法有效捕捉图中的多样化幂律结构（power-law structures）。为此，提出Multi-Hyperbolic Space-based Heterogeneous Graph Attention Network (MSGAT)，该模型利用多个双曲空间结合注意力机制，来更好地表示和处理异构图的多样化结构。实验结果显示，MSGAT在各种图机器学习任务中优于最先进基线模型，证明了其在捕捉异构图复杂结构方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in IEEE ICDM 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.11283v1",
      "published_date": "2024-11-18 04:55:26 UTC",
      "updated_date": "2024-11-18 04:55:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:47:47.761630"
    },
    {
      "arxiv_id": "2411.11282v2",
      "title": "Continuous K-space Recovery Network with Image Guidance for Fast MRI Reconstruction",
      "title_zh": "用于快速 MRI 重建的带有图像引导的连续 k 空间恢复",
      "authors": [
        "Yucong Meng",
        "Zhiwei Yang",
        "Minghong Duan",
        "Yonghong Shi",
        "Zhijian Song"
      ],
      "abstract": "Magnetic resonance imaging (MRI) is a crucial tool for clinical diagnosis\nwhile facing the challenge of long scanning time. To reduce the acquisition\ntime, fast MRI reconstruction aims to restore high-quality images from the\nundersampled k-space. Existing methods typically train deep learning models to\nmap the undersampled data to artifact-free MRI images. However, these studies\noften overlook the unique properties of k-space and directly apply general\nnetworks designed for image processing to k-space recovery, leaving the precise\nlearning of k-space largely underexplored. In this work, we propose a\ncontinuous k-space recovery network from a new perspective of implicit neural\nrepresentation with image domain guidance, which boosts the performance of MRI\nreconstruction. Specifically, (1) an implicit neural representation based\nencoder-decoder structure is customized to continuously query unsampled\nk-values. (2) an image guidance module is designed to mine the semantic\ninformation from the low-quality MRI images to further guide the k-space\nrecovery. (3) a multi-stage training strategy is proposed to recover dense\nk-space progressively. Extensive experiments conducted on CC359, fastMRI, and\nIXI datasets demonstrate the effectiveness of our method and its superiority\nover other competitors.",
      "tldr_zh": "该论文针对磁共振成像（MRI）扫描时间长的挑战，提出了一种连续 k-space 恢复网络，以从欠采样 k-space 中重建高质量图像。方法采用隐式神经表示（implicit neural representation）的编码器-解码器结构来连续查询未采样 k 值，并通过图像指导模块从低质量 MRI 图像中提取语义信息来指导恢复过程，同时引入多阶段训练策略逐步实现密集 k-space 重建。实验在 CC359、fastMRI 和 IXI 数据集上证明，该方法优于现有竞争方案，提升了 MRI 重建性能。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11282v2",
      "published_date": "2024-11-18 04:54:04 UTC",
      "updated_date": "2025-03-13 12:40:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:48:00.453766"
    },
    {
      "arxiv_id": "2411.11262v1",
      "title": "Cross-Patient Pseudo Bags Generation and Curriculum Contrastive Learning for Imbalanced Multiclassification of Whole Slide Image",
      "title_zh": "翻译失败",
      "authors": [
        "Yonghuang Wu",
        "Xuan Xie",
        "Xinyuan Niu",
        "Chengqian Zhao",
        "Jinhua Yu"
      ],
      "abstract": "Pathology computing has dramatically improved pathologists' workflow and\ndiagnostic decision-making processes. Although computer-aided diagnostic\nsystems have shown considerable value in whole slide image (WSI) analysis, the\nproblem of multi-classification under sample imbalance remains an intractable\nchallenge. To address this, we propose learning fine-grained information by\ngenerating sub-bags with feature distributions similar to the original WSIs.\nAdditionally, we utilize a pseudo-bag generation algorithm to further leverage\nthe abundant and redundant information in WSIs, allowing efficient training in\nunbalanced-sample multi-classification tasks. Furthermore, we introduce an\naffinity-based sample selection and curriculum contrastive learning strategy to\nenhance the stability of model representation learning. Unlike previous\napproaches, our framework transitions from learning bag-level representations\nto understanding and exploiting the feature distribution of multi-instance\nbags. Our method demonstrates significant performance improvements on three\ndatasets, including tumor classification and lymph node metastasis. On average,\nit achieves a 4.39-point improvement in F1 score compared to the second-best\nmethod across the three tasks, underscoring its superior performance.",
      "tldr_zh": "本文针对全切片图像（WSI）多分类任务中的样本不平衡问题，提出了一种生成子袋和伪袋的方法，以学习细粒度信息并利用WSI的丰富冗余数据。方法包括伪袋生成算法（pseudo-bag generation algorithm）和基于亲和力的样本选择与课程对比学习策略（curriculum contrastive learning），从而提升模型表示学习的稳定性和训练效率。实验结果显示，该框架在三个数据集上，包括肿瘤分类和淋巴结转移任务，平均F1 score比第二好方法提高了4.39点，展示了显著性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.11262v1",
      "published_date": "2024-11-18 03:35:34 UTC",
      "updated_date": "2024-11-18 03:35:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:48:12.888587"
    },
    {
      "arxiv_id": "2412.01840v1",
      "title": "Zonal Architecture Development with evolution of Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Sneha Sudhir Shetiya",
        "Vikas Vyas",
        "Shreyas Renukuntla"
      ],
      "abstract": "This paper explains how traditional centralized architectures are\ntransitioning to distributed zonal approaches to address challenges in\nscalability, reliability, performance, and cost-effectiveness. The role of edge\ncomputing and neural networks in enabling sophisticated sensor fusion and\ndecision-making capabilities for autonomous vehicles is examined. Additionally,\nthis paper discusses the impact of zonal architectures on vehicle diagnostics,\npower distribution, and smart power management systems. Key design\nconsiderations for implementing effective zonal architectures are presented,\nalong with an overview of current challenges and future directions. The\nobjective of this paper is to provide a comprehensive understanding of how\nzonal architectures are shaping the future of automotive technology,\nparticularly in the context of self-driving vehicles and artificial\nintelligence integration.",
      "tldr_zh": "本论文探讨了传统集中式架构向分布式分区架构（zonal architectures）的演变，以解决可扩展性、可靠性、性能和成本效益的挑战。论文考察了边缘计算（edge computing）和神经网络（neural networks）在自动驾驶车辆中实现传感器融合和决策能力的关键作用。还讨论了分区架构对车辆诊断、电力分配和智能电力管理系统的影响，并提出了实施的有效设计考虑以及当前挑战和未来方向。总体目标是提供对分区架构如何塑造汽车技术，特别是自驾车辆和人工智能（Artificial Intelligence）整合的全面理解。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01840v1",
      "published_date": "2024-11-18 03:15:44 UTC",
      "updated_date": "2024-11-18 03:15:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:48:24.837112"
    },
    {
      "arxiv_id": "2411.14464v2",
      "title": "JESTR: Joint Embedding Space Technique for Ranking Candidate Molecules for the Annotation of Untargeted Metabolomics Data",
      "title_zh": "翻译失败",
      "authors": [
        "Apurva Kalia",
        "Dilip Krishnan",
        "Soha Hassoun"
      ],
      "abstract": "Motivation: A major challenge in metabolomics is annotation: assigning\nmolecular structures to mass spectral fragmentation patterns. Despite recent\nadvances in molecule-to-spectra and in spectra-to-molecular fingerprint\nprediction (FP), annotation rates remain low. Results: We introduce in this\npaper a novel paradigm (JESTR) for annotation. Unlike prior approaches that\nexplicitly construct molecular fingerprints or spectra, JESTR leverages the\ninsight that molecules and their corresponding spectra are views of the same\ndata and effectively embeds their representations in a joint space. Candidate\nstructures are ranked based on cosine similarity between the embeddings of\nquery spectrum and each candidate. We evaluate JESTR against mol-to-spec and\nspec-to-FP annotation tools on three datasets. On average, for rank@[1-5],\nJESTR outperforms other tools by 23.6%-71.6%. We further demonstrate the strong\nvalue of regularization with candidate molecules during training, boosting\nrank@1 performance by 11.4% and enhancing the model's ability to discern\nbetween target and candidate molecules. Through JESTR, we offer a novel\npromising avenue towards accurate annotation, therefore unlocking valuable\ninsights into the metabolome.",
      "tldr_zh": "该研究提出JESTR，一种联合嵌入空间技术（Joint Embedding Space Technique），用于针对非靶向代谢组学数据（Untargeted Metabolomics Data）对候选分子进行排名，以解决分子结构注释的挑战。JESTR将分子和其对应质谱碎片模式视为同一数据的不同视图，将它们嵌入到一个共享空间中，并通过余弦相似度（Cosine Similarity）对候选结构进行排名。实验结果显示，在三个数据集上，JESTR在rank@[1-5]的性能上比现有mol-to-spec和spec-to-FP工具平均高出23.6%-71.6%，并通过候选分子正则化训练提升了rank@1准确率11.4%。这一方法为提高代谢组学注释准确性提供了新途径，从而解锁代谢组（Metabolome）的宝贵洞见。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "q-bio.QM",
      "comment": "10 pages, 10 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.14464v2",
      "published_date": "2024-11-18 03:03:57 UTC",
      "updated_date": "2024-11-25 23:01:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:48:37.265431"
    },
    {
      "arxiv_id": "2412.03577v1",
      "title": "OKG: On-the-Fly Keyword Generation in Sponsored Search Advertising",
      "title_zh": "翻译失败",
      "authors": [
        "Zhao Wang",
        "Briti Gangopadhyay",
        "Mengjie Zhao",
        "Shingo Takamatsu"
      ],
      "abstract": "Current keyword decision-making in sponsored search advertising relies on\nlarge, static datasets, limiting the ability to automatically set up keywords\nand adapt to real-time KPI metrics and product updates that are essential for\neffective advertising. In this paper, we propose On-the-fly Keyword Generation\n(OKG), an LLM agent-based method that dynamically monitors KPI changes and\nadapts keyword generation in real time, aligning with strategies recommended by\nadvertising platforms. Additionally, we introduce the first publicly accessible\ndataset containing real keyword data along with its KPIs across diverse\ndomains, providing a valuable resource for future research. Experimental\nresults show that OKG significantly improves keyword adaptability and\nresponsiveness compared to traditional methods. The code for OKG and the\ndataset are available at https://github.com/sony/okg.",
      "tldr_zh": "本文提出 OKG（On-the-Fly Keyword Generation），一种基于 LLM agent 的方法，用于解决赞助搜索广告中关键词决策依赖静态数据集的问题，实现实时监控 KPI 变化并动态生成关键词，以适应产品更新和广告平台策略。OKG 通过实时适应机制提升了关键词的有效性，同时作者发布了首个公开数据集，包含真实关键词数据及其 KPI 指标，覆盖多种领域，以支持未来研究。实验结果显示，OKG 相较传统方法显著提高了关键词的适应性和响应性。代码和数据集可从 GitHub 获取。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03577v1",
      "published_date": "2024-11-18 03:02:06 UTC",
      "updated_date": "2024-11-18 03:02:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:48:47.717816"
    },
    {
      "arxiv_id": "2412.04326v1",
      "title": "Understanding Student Sentiment on Mental Health Support in Colleges Using Large Language Models",
      "title_zh": "使用大型语言模型理解大学生对心理健康支持的情绪",
      "authors": [
        "Palak Sood",
        "Chengyang He",
        "Divyanshu Gupta",
        "Yue Ning",
        "Ping Wang"
      ],
      "abstract": "Mental health support in colleges is vital in educating students by offering\ncounseling services and organizing supportive events. However, evaluating its\neffectiveness faces challenges like data collection difficulties and lack of\nstandardized metrics, limiting research scope. Student feedback is crucial for\nevaluation but often relies on qualitative analysis without systematic\ninvestigation using advanced machine learning methods. This paper uses public\nStudent Voice Survey data to analyze student sentiments on mental health\nsupport with large language models (LLMs). We created a sentiment analysis\ndataset, SMILE-College, with human-machine collaboration. The investigation of\nboth traditional machine learning methods and state-of-the-art LLMs showed the\nbest performance of GPT-3.5 and BERT on this new dataset. The analysis\nhighlights challenges in accurately predicting response sentiments and offers\npractical insights on how LLMs can enhance mental health-related research and\nimprove college mental health services. This data-driven approach will\nfacilitate efficient and informed mental health support evaluation, management,\nand decision-making.",
      "tldr_zh": "本研究探讨了使用大型语言模型(LLMs)分析大学学生对心理健康支持的情绪反馈，以解决数据收集困难和缺乏标准化评估指标的问题。研究者基于公共Student Voice Survey数据创建了SMILE-College情绪分析数据集，并通过人机协作比较了传统机器学习方法与最先进的LLMs，结果显示GPT-3.5和BERT在该数据集上表现最佳。尽管预测情绪准确性仍面临挑战，该方法提供了实用见解，帮助提升心理健康相关研究和大学服务管理。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by '2024 IEEE International Conference on Big Data (IEEE\n  BigData 2024)'. The paper has 8 pages, 2 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.04326v1",
      "published_date": "2024-11-18 02:53:15 UTC",
      "updated_date": "2024-11-18 02:53:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:49:00.323008"
    },
    {
      "arxiv_id": "2411.13588v1",
      "title": "Unveiling Redundancy in Diffusion Transformers (DiTs): A Systematic Study",
      "title_zh": "揭示 Diffusion Transformers (",
      "authors": [
        "Xibo Sun",
        "Jiarui Fang",
        "Aoyu Li",
        "Jinzhe Pan"
      ],
      "abstract": "The increased model capacity of Diffusion Transformers (DiTs) and the demand\nfor generating higher resolutions of images and videos have led to a\nsignificant rise in inference latency, impacting real-time performance\nadversely. While prior research has highlighted the presence of high similarity\nin activation values between adjacent diffusion steps (referred to as\nredundancy) and proposed various caching mechanisms to mitigate computational\noverhead, the exploration of redundancy in existing literature remains limited,\nwith findings often not generalizable across different DiT models. This study\naims to address this gap by conducting a comprehensive investigation into\nredundancy across a broad spectrum of mainstream DiT models. Our experimental\nanalysis reveals substantial variations in the distribution of redundancy\nacross diffusion steps among different DiT models. Interestingly, within a\nsingle model, the redundancy distribution remains stable regardless of\nvariations in input prompts, step counts, or scheduling strategies. Given the\nlack of a consistent pattern across diverse models, caching strategies designed\nfor a specific group of models may not easily transfer to others. To overcome\nthis challenge, we introduce a tool for analyzing the redundancy of individual\nmodels, enabling subsequent research to develop tailored caching strategies for\nspecific model architectures. The project is publicly available at\nhttps://github.com/xdit-project/DiTCacheAnalysis.",
      "tldr_zh": "这项研究系统调查了Diffusion Transformers (DiTs)模型中的冗余性，针对模型容量增加导致的推理延迟问题进行全面分析。实验发现，不同DiT模型的冗余分布在扩散步骤间有显著差异，但单个模型内的分布对输入提示、步数或调度策略变化保持稳定。鉴于冗余模式缺乏通用性，研究引入了一个专用分析工具，帮助开发针对特定模型架构的caching mechanisms策略，并开源该项目以支持后续研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages including reference",
      "pdf_url": "http://arxiv.org/pdf/2411.13588v1",
      "published_date": "2024-11-18 02:49:23 UTC",
      "updated_date": "2024-11-18 02:49:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:49:12.876387"
    },
    {
      "arxiv_id": "2411.12767v2",
      "title": "Suicide Risk Assessment on Social Media with Semi-Supervised Learning",
      "title_zh": "社交媒体上的自杀风险评估：基于半监督学习",
      "authors": [
        "Max Lovitt",
        "Haotian Ma",
        "Song Wang",
        "Yifan Peng"
      ],
      "abstract": "With social media communities increasingly becoming places where suicidal\nindividuals post and congregate, natural language processing presents an\nexciting avenue for the development of automated suicide risk assessment\nsystems. However, past efforts suffer from a lack of labeled data and class\nimbalances within the available labeled data. To accommodate this task's\nimperfect data landscape, we propose a semi-supervised framework that leverages\nlabeled (n=500) and unlabeled (n=1,500) data and expands upon the self-training\nalgorithm with a novel pseudo-label acquisition process designed to handle\nimbalanced datasets. To further ensure pseudo-label quality, we manually verify\na subset of the pseudo-labeled data that was not predicted unanimously across\nmultiple trials of pseudo-label generation. We test various models to serve as\nthe backbone for this framework, ultimately deciding that RoBERTa performs the\nbest. Ultimately, by leveraging partially validated pseudo-labeled data in\naddition to ground-truth labeled data, we substantially improve our model's\nability to assess suicide risk from social media posts.",
      "tldr_zh": "本研究针对社交媒体上自杀风险评估的问题，提出了一种半监督学习（semi-supervised learning）框架，以应对标记数据不足（n=500）和类 imbalance 的挑战。该框架扩展了自训练算法（self-training algorithm），引入一个新颖的伪标签获取过程，并通过手动验证部分伪标签来确保数据质量，最终选用 RoBERTa 模型作为骨干。实验结果显示，通过结合部分验证的伪标签数据和真实标记数据，该框架显著提升了模型从社交媒体帖子中评估自杀风险的能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication in the 2024 IEEE International Conference on\n  Big Data",
      "pdf_url": "http://arxiv.org/pdf/2411.12767v2",
      "published_date": "2024-11-18 02:43:05 UTC",
      "updated_date": "2024-12-15 21:12:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:49:23.500144"
    },
    {
      "arxiv_id": "2411.11249v1",
      "title": "EXCON: Extreme Instance-based Contrastive Representation Learning of Severely Imbalanced Multivariate Time Series for Solar Flare Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Onur Vural",
        "Shah Muhammad Hamdi",
        "Soukaina Filali Boubrahimi"
      ],
      "abstract": "In heliophysics research, predicting solar flares is crucial due to their\npotential to impact both space-based systems and Earth's infrastructure\nsubstantially. Magnetic field data from solar active regions, recorded by solar\nimaging observatories, are transformed into multivariate time series to enable\nsolar flare prediction using temporal window-based analysis. In the realm of\nmultivariate time series-driven solar flare prediction, addressing severe class\nimbalance with effective strategies for multivariate time series representation\nlearning is key to developing robust predictive models. Traditional methods\noften struggle with overfitting to the majority class in prediction tasks where\nmajor solar flares are infrequent. This work presents EXCON, a contrastive\nrepresentation learning framework designed to enhance classification\nperformance amidst such imbalances. EXCON operates through four stages:\nobtaining core features from multivariate time series data; selecting\ndistinctive contrastive representations for each class to maximize inter-class\nseparation; training a temporal feature embedding module with a custom extreme\nreconstruction loss to minimize intra-class variation; and applying a\nclassifier to the learned embeddings for robust classification. The proposed\nmethod leverages contrastive learning principles to map similar instances\ncloser in the feature space while distancing dissimilar ones, a strategy not\nextensively explored in solar flare prediction tasks. This approach not only\naddresses class imbalance but also offers a versatile solution applicable to\nunivariate and multivariate time series across binary and multiclass\nclassification problems. Experimental results, including evaluations on the\nbenchmark solar flare dataset and multiple time series archive datasets with\nbinary and multiclass labels, demonstrate EXCON's efficacy in enhancing\nclassification performance.",
      "tldr_zh": "本研究提出EXCON框架，用于处理严重类别不平衡的多变量时间序列数据，以提升太阳耀斑预测的性能。EXCON通过四个阶段实现：从多变量时间序列中提取核心特征、选择独特对比表示以最大化类间分离、使用自定义极端重构损失训练时间特征嵌入模块以最小化类内变异，以及在学到的嵌入上应用分类器进行鲁棒分类。该方法利用对比表示学习原则，将相似实例在特征空间中拉近而不相似实例拉远，并在基准太阳耀斑数据集以及其他时间序列档案数据集的实验中，显著提高了二元和多类分类的准确率，提供了一个适用于一元和多变量时间序列的通用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been accepted at the 2024 IEEE International Conference\n  on Big Data (IEEE BigData 2024) on October 27, 2024, as a main conference\n  paper",
      "pdf_url": "http://arxiv.org/pdf/2411.11249v1",
      "published_date": "2024-11-18 02:36:19 UTC",
      "updated_date": "2024-11-18 02:36:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:49:36.514054"
    },
    {
      "arxiv_id": "2411.11247v1",
      "title": "ZeFaV: Boosting Large Language Models for Zero-shot Fact Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Son T. Luu",
        "Hiep Nguyen",
        "Trung Vo",
        "Le-Minh Nguyen"
      ],
      "abstract": "In this paper, we propose ZeFaV - a zero-shot based fact-checking\nverification framework to enhance the performance on fact verification task of\nlarge language models by leveraging the in-context learning ability of large\nlanguage models to extract the relations among the entities within a claim,\nre-organized the information from the evidence in a relationally logical form,\nand combine the above information with the original evidence to generate the\ncontext from which our fact-checking model provide verdicts for the input\nclaims. We conducted empirical experiments to evaluate our approach on two\nmulti-hop fact-checking datasets including HoVer and FEVEROUS, and achieved\npotential results results comparable to other state-of-the-art fact\nverification task methods.",
      "tldr_zh": "本论文提出ZeFaV框架，用于提升Large Language Models在zero-shot事实验证任务中的性能。该框架利用LLMs的in-context learning能力，提取声明中实体间的关系、重新组织证据信息成逻辑形式，并将这些信息与原始证据结合生成增强上下文，从而对输入声明提供事实检查裁决。在HoVer和FEVEROUS数据集上的实验表明，ZeFaV的成果与state-of-the-art方法相当，展示了其潜在的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This pre-print has been published in PRICAI 2024: Trends in\n  Artificial Intelligence. The published version is available at\n  https://doi.org/10.1007/978-981-96-0119-6_28",
      "pdf_url": "http://arxiv.org/pdf/2411.11247v1",
      "published_date": "2024-11-18 02:35:15 UTC",
      "updated_date": "2024-11-18 02:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:49:49.106596"
    },
    {
      "arxiv_id": "2411.11235v1",
      "title": "MEMO-Bench: A Multiple Benchmark for Text-to-Image and Multimodal Large Language Models on Human Emotion Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Yingjie Zhou",
        "Zicheng Zhang",
        "Jiezhang Cao",
        "Jun Jia",
        "Yanwei Jiang",
        "Farong Wen",
        "Xiaohong Liu",
        "Xiongkuo Min",
        "Guangtao Zhai"
      ],
      "abstract": "Artificial Intelligence (AI) has demonstrated significant capabilities in\nvarious fields, and in areas such as human-computer interaction (HCI), embodied\nintelligence, and the design and animation of virtual digital humans, both\npractitioners and users are increasingly concerned with AI's ability to\nunderstand and express emotion. Consequently, the question of whether AI can\naccurately interpret human emotions remains a critical challenge. To date, two\nprimary classes of AI models have been involved in human emotion analysis:\ngenerative models and Multimodal Large Language Models (MLLMs). To assess the\nemotional capabilities of these two classes of models, this study introduces\nMEMO-Bench, a comprehensive benchmark consisting of 7,145 portraits, each\ndepicting one of six different emotions, generated by 12 Text-to-Image (T2I)\nmodels. Unlike previous works, MEMO-Bench provides a framework for evaluating\nboth T2I models and MLLMs in the context of sentiment analysis. Additionally, a\nprogressive evaluation approach is employed, moving from coarse-grained to\nfine-grained metrics, to offer a more detailed and comprehensive assessment of\nthe sentiment analysis capabilities of MLLMs. The experimental results\ndemonstrate that existing T2I models are more effective at generating positive\nemotions than negative ones. Meanwhile, although MLLMs show a certain degree of\neffectiveness in distinguishing and recognizing human emotions, they fall short\nof human-level accuracy, particularly in fine-grained emotion analysis. The\nMEMO-Bench will be made publicly available to support further research in this\narea.",
      "tldr_zh": "本文引入 MEMO-Bench，这是一个综合基准，用于评估 Text-to-Image (T2I) 模型和 Multimodal Large Language Models (MLLMs) 在人类情感分析中的性能，该基准包含 7,145 张描绘六种情感的肖像图像。评估方法采用从粗粒度到细粒度的渐进式框架，提供更详细的分析。实验结果表明，T2I 模型更擅长生成积极情感而非消极情感，而 MLLMs 虽能有效区分和识别情感，但整体准确率低于人类水平，尤其在细粒度分析中。MEMO-Bench 将公开，以支持进一步的研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11235v1",
      "published_date": "2024-11-18 02:09:48 UTC",
      "updated_date": "2024-11-18 02:09:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:50:01.018704"
    },
    {
      "arxiv_id": "2411.13587v3",
      "title": "Exploring the Adversarial Vulnerabilities of Vision-Language-Action Models in Robotics",
      "title_zh": "探索视觉-语言-动作模型在机器人学中的对抗性漏洞",
      "authors": [
        "Taowen Wang",
        "Cheng Han",
        "James Chenhao Liang",
        "Wenhao Yang",
        "Dongfang Liu",
        "Luna Xinyu Zhang",
        "Qifan Wang",
        "Jiebo Luo",
        "Ruixiang Tang"
      ],
      "abstract": "Recently in robotics, Vision-Language-Action (VLA) models have emerged as a\ntransformative approach, enabling robots to execute complex tasks by\nintegrating visual and linguistic inputs within an end-to-end learning\nframework. While VLA models offer significant capabilities, they also introduce\nnew attack surfaces, making them vulnerable to adversarial attacks. With these\nvulnerabilities largely unexplored, this paper systematically quantifies the\nrobustness of VLA-based robotic systems. Recognizing the unique demands of\nrobotic execution, our attack objectives target the inherent spatial and\nfunctional characteristics of robotic systems. In particular, we introduce two\nuntargeted attack objectives that leverage spatial foundations to destabilize\nrobotic actions, and a targeted attack objective that manipulates the robotic\ntrajectory. Additionally, we design an adversarial patch generation approach\nthat places a small, colorful patch within the camera's view, effectively\nexecuting the attack in both digital and physical environments. Our evaluation\nreveals a marked degradation in task success rates, with up to a 100\\%\nreduction across a suite of simulated robotic tasks, highlighting critical\nsecurity gaps in current VLA architectures. By unveiling these vulnerabilities\nand proposing actionable evaluation metrics, we advance both the understanding\nand enhancement of safety for VLA-based robotic systems, underscoring the\nnecessity for continuously developing robust defense strategies prior to\nphysical-world deployments.",
      "tldr_zh": "这篇论文探讨了机器人领域VLA（Vision-Language-Action）模型的adversarial vulnerabilities，这些模型通过整合视觉和语言输入实现端到端任务执行，但面临新的安全风险。研究者引入了两个untargeted攻击目标（针对空间特性破坏机器人动作）和一个targeted攻击目标（操纵机器人轨迹），并设计了adversarial patch generation方法，在数字和物理环境中使用小彩色补丁执行攻击。实验结果显示，在模拟任务中任务成功率下降高达100%，揭示了VLA架构的严重安全漏洞，并强调了开发鲁棒防御策略的紧迫性，以提升实际部署的安全性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Github: https://github.com/William-wAng618/roboticAttack Homepage:\n  https://vlaattacker.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2411.13587v3",
      "published_date": "2024-11-18 01:52:20 UTC",
      "updated_date": "2025-03-10 02:57:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:50:12.321848"
    },
    {
      "arxiv_id": "2411.13586v1",
      "title": "Advance Detection Of Bull And Bear Phases In Cryptocurrency Markets",
      "title_zh": "翻译失败",
      "authors": [
        "Rahul Arulkumaran",
        "Suyash Kumar",
        "Shikha Tomar",
        "Manideep Gongalla",
        "Harshitha"
      ],
      "abstract": "Cryptocurrencies are highly volatile financial instruments with more and more\nnew retail investors joining the scene with each passing day. Bitcoin has\nalways proved to determine in which way the rest of the cryptocurrency market\nis headed towards. As of today Bitcoin has a market dominance of close to 50\npercent. Bull and bear phases in cryptocurrencies are determined based on the\nperformance of Bitcoin over the 50 Day and 200 Day Moving Averages. The aim of\nthis paper is to foretell the performance of bitcoin in the near future by\nemploying predictive algorithms. This predicted data will then be used to\ncalculate the 50 Day and 200 Day Moving Averages and subsequently plotted to\nestablish the potential bull and bear phases.",
      "tldr_zh": "这篇论文针对加密货币市场的剧烈波动性，专注于比特币（Bitcoin）作为市场主导力量（占约50%市场份额），旨在提前预测牛市（Bull Phases）和熊市（Bear Phases）。研究方法包括使用预测算法分析比特币的表现，然后基于预测数据计算50 Day Moving Averages和200 Day Moving Averages，并通过绘图建立潜在的市场阶段。总体贡献在于提供一种提前检测工具，帮助新投资者更好地应对市场风险。",
      "categories": [
        "q-fin.ST",
        "cs.AI"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13586v1",
      "published_date": "2024-11-18 01:48:16 UTC",
      "updated_date": "2024-11-18 01:48:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:50:23.499051"
    },
    {
      "arxiv_id": "2411.11217v1",
      "title": "MoE-Lightning: High-Throughput MoE Inference on Memory-constrained GPUs",
      "title_zh": "翻译失败",
      "authors": [
        "Shiyi Cao",
        "Shu Liu",
        "Tyler Griggs",
        "Peter Schafhalter",
        "Xiaoxuan Liu",
        "Ying Sheng",
        "Joseph E. Gonzalez",
        "Matei Zaharia",
        "Ion Stoica"
      ],
      "abstract": "Efficient deployment of large language models, particularly Mixture of\nExperts (MoE), on resource-constrained platforms presents significant\nchallenges, especially in terms of computational efficiency and memory\nutilization. The MoE architecture, renowned for its ability to increase model\ncapacity without a proportional increase in inference cost, greatly reduces the\ntoken generation latency compared with dense models. However, the large model\nsize makes MoE models inaccessible to individuals without high-end GPUs. In\nthis paper, we propose a high-throughput MoE batch inference system, that\nsignificantly outperforms past work. MoE-Lightning introduces a novel\nCPU-GPU-I/O pipelining schedule, CGOPipe, with paged weights to achieve high\nresource utilization, and a performance model, HRM, based on a Hierarchical\nRoofline Model we introduce to help find policies with higher throughput than\nexisting systems. MoE-Lightning can achieve up to 10.3x higher throughput than\nstate-of-the-art offloading-enabled LLM inference systems for Mixtral 8x7B on a\nsingle T4 GPU (16GB). When the theoretical system throughput is bounded by the\nGPU memory, MoE-Lightning can reach the throughput upper bound with 2-3x less\nCPU memory, significantly increasing resource utilization. MoE-Lightning also\nsupports efficient batch inference for much larger MoEs (e.g., Mixtral 8x22B\nand DBRX) on multiple low-cost GPUs (e.g., 2-4 T4).",
      "tldr_zh": "本论文针对在内存受限 GPU 上部署 Mixture of Experts (MoE) 模型的挑战，提出了一种高吞吐量推理系统 MoE-Lightning，以提升计算效率和资源利用。系统引入了 CGOPipe（一种 CPU-GPU-I/O 流水线调度）和 HRM（基于 Hierarchical Roofline Model 的性能模型），通过分页权重优化来实现高效推理。实验结果显示，MoE-Lightning 在单个 T4 GPU 上使 Mixtral 8x7B 的吞吐量比现有系统提高 10.3 倍，并能在更少的 CPU 内存下达到吞吐量上限，同时支持更大模型如 Mixtral 8x22B 和 DBRX 在多 GPU 环境中的批量推理。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11217v1",
      "published_date": "2024-11-18 01:06:12 UTC",
      "updated_date": "2024-11-18 01:06:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:50:37.391880"
    },
    {
      "arxiv_id": "2412.03576v1",
      "title": "Ethical Challenges and Evolving Strategies in the Integration of Artificial Intelligence into Clinical Practice",
      "title_zh": "人工智能融入临床实践中的道德挑战与不断演变的策略",
      "authors": [
        "Ellison B. Weiner",
        "Irene Dankwa-Mullan",
        "William A. Nelson",
        "Saeed Hassanpour"
      ],
      "abstract": "Artificial intelligence (AI) has rapidly transformed various sectors,\nincluding healthcare, where it holds the potential to revolutionize clinical\npractice and improve patient outcomes. However, its integration into medical\nsettings brings significant ethical challenges that need careful consideration.\nThis paper examines the current state of AI in healthcare, focusing on five\ncritical ethical concerns: justice and fairness, transparency, patient consent\nand confidentiality, accountability, and patient-centered and equitable care.\nThese concerns are particularly pressing as AI systems can perpetuate or even\nexacerbate existing biases, often resulting from non-representative datasets\nand opaque model development processes. The paper explores how bias, lack of\ntransparency, and challenges in maintaining patient trust can undermine the\neffectiveness and fairness of AI applications in healthcare. In addition, we\nreview existing frameworks for the regulation and deployment of AI, identifying\ngaps that limit the widespread adoption of these systems in a just and\nequitable manner. Our analysis provides recommendations to address these\nethical challenges, emphasizing the need for fairness in algorithm design,\ntransparency in model decision-making, and patient-centered approaches to\nconsent and data privacy. By highlighting the importance of continuous ethical\nscrutiny and collaboration between AI developers, clinicians, and ethicists, we\noutline pathways for achieving more responsible and inclusive AI implementation\nin healthcare. These strategies, if adopted, could enhance both the clinical\nvalue of AI and the trustworthiness of AI systems among patients and healthcare\nprofessionals, ensuring that these technologies serve all populations\nequitably.",
      "tldr_zh": "这篇论文探讨了Artificial Intelligence (AI) 在临床实践中的整合所带来的伦理挑战，包括justice and fairness、transparency、patient consent and confidentiality、accountability 以及patient-centered and equitable care。这些挑战可能加剧现有偏见、降低透明度和影响患者信任，从而削弱AI在医疗中的公平性和有效性。论文审查了现有监管框架的不足，并提出推荐策略，如在算法设计中强调fairness、确保transparency，以及采用patient-centered 方法来处理同意和数据隐私。通过推动AI开发者、临床医生和伦理学家之间的持续合作，这些策略可实现更负责任的AI实施，提升其临床价值和可信度。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03576v1",
      "published_date": "2024-11-18 00:52:22 UTC",
      "updated_date": "2024-11-18 00:52:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:50:49.497101"
    },
    {
      "arxiv_id": "2411.11213v1",
      "title": "Making Sigmoid-MSE Great Again: Output Reset Challenges Softmax Cross-Entropy in Neural Network Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Kanishka Tyagi",
        "Chinmay Rane",
        "Ketaki Vaidya",
        "Jeshwanth Challgundla",
        "Soumitro Swapan Auddy",
        "Michael Manry"
      ],
      "abstract": "This study presents a comparative analysis of two objective functions, Mean\nSquared Error (MSE) and Softmax Cross-Entropy (SCE) for neural network\nclassification tasks. While SCE combined with softmax activation is the\nconventional choice for transforming network outputs into class probabilities,\nwe explore an alternative approach using MSE with sigmoid activation. We\nintroduce the Output Reset algorithm, which reduces inconsistent errors and\nenhances classifier robustness. Through extensive experiments on benchmark\ndatasets (MNIST, CIFAR-10, and Fashion-MNIST), we demonstrate that MSE with\nsigmoid activation achieves comparable accuracy and convergence rates to SCE,\nwhile exhibiting superior performance in scenarios with noisy data. Our\nfindings indicate that MSE, despite its traditional association with regression\ntasks, serves as a viable alternative for classification problems, challenging\nconventional wisdom about neural network training strategies.",
      "tldr_zh": "本研究比较了 Mean Squared Error (MSE) 与 Softmax Cross-Entropy (SCE) 作为神经网络分类任务的目标函数。作者引入了 Output Reset 算法，以减少不一致错误并提升分类器的鲁棒性，使用 MSE 结合 sigmoid 激活函数作为替代方案。在 MNIST、CIFAR-10 和 Fashion-MNIST 等基准数据集上的实验表明，MSE 与 sigmoid 激活可实现与 SCE 相似的准确性和收敛率，并在噪声数据场景中表现出色。这些发现挑战了传统观点，将 MSE 作为分类任务的可行替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11213v1",
      "published_date": "2024-11-18 00:46:38 UTC",
      "updated_date": "2024-11-18 00:46:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:51:00.646277"
    },
    {
      "arxiv_id": "2411.15175v4",
      "title": "ToxiLab: How Well Do Open-Source LLMs Generate Synthetic Toxicity Data?",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Hui",
        "Zhaoxiao Guo",
        "Hang Zhao",
        "Juanyong Duan",
        "Lin Ai",
        "Yinheng Li",
        "Julia Hirschberg",
        "Congrui Huang"
      ],
      "abstract": "Effective toxic content detection relies heavily on high-quality and diverse\ndata, which serve as the foundation for robust content moderation models.\nSynthetic data has become a common approach for training models across various\nNLP tasks. However, its effectiveness remains uncertain for highly subjective\ntasks like hate speech detection, with previous research yielding mixed\nresults. This study explores the potential of open-source LLMs for harmful data\nsynthesis, utilizing controlled prompting and supervised fine-tuning techniques\nto enhance data quality and diversity. We systematically evaluated 6 open\nsource LLMs on 5 datasets, assessing their ability to generate diverse,\nhigh-quality harmful data while minimizing hallucination and duplication. Our\nresults show that Mistral consistently outperforms other open models, and\nsupervised fine-tuning significantly enhances data reliability and diversity.\nWe further analyze the trade-offs between prompt-based vs. fine-tuned toxic\ndata synthesis, discuss real-world deployment challenges, and highlight ethical\nconsiderations. Our findings demonstrate that fine-tuned open source LLMs\nprovide scalable and cost-effective solutions to augment toxic content\ndetection datasets, paving the way for more accessible and transparent content\nmoderation tools.",
      "tldr_zh": "该研究（ToxiLab）评估了开源大型语言模型（LLMs）生成合成毒性数据的效能，针对仇恨言论等主观任务的数据质量和多样性问题。研究者采用受控提示和监督 fine-tuning 技术，对6个开源LLMs在5个数据集上进行系统评估，以生成高质量有害数据并减少幻觉和重复。结果显示，Mistral模型表现出色，而监督 fine-tuning 显著提升了数据的可靠性和多样性。总体而言，该工作探讨了提示-based与fine-tuned方法的权衡，强调了实际部署中的伦理挑战，并证明了微调开源LLMs可作为可扩展、成本有效的手段来增强毒性内容检测数据集，促进更透明的内容审核工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.15175v4",
      "published_date": "2024-11-18 00:21:14 UTC",
      "updated_date": "2025-02-22 16:42:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:51:12.772613"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 112,
  "processed_papers_count": 112,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T01:51:36.197792"
}