{
  "date": "2025-05-20",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-20 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 和机器学习领域，尤其是大型语言模型（LLM）的优化、推理、安全性，以及在多模态任务、强化学习和医疗应用中的进展，令人印象深刻的包括 JARVIS 多代理框架和 Self-Evolving Curriculum for LLM Reasoning（涉及著名学者 Yoshua Bengio），这些工作展示了 LLM 在工程和推理领域的潜力。\n\n下面，我将挑选并简要讨论部分关键论文，先从高影响力或热门主题入手，如 LLM 代理和强化学习，再快速掠过其他领域。每个条目列出论文标题（中文 + 英文），并突出核心贡献和发现。\n\n### LLM 代理和多代理框架\n- **JARVIS: 一个多代理框架利用大型语言模型生成高质量的电子设计自动化脚本** (JARVIS: A Multi-Agent Code Assistant for High-Quality EDA Script Generation)  \n  这篇论文提出 JARVIS 框架，使用领域特定 LLM 和合成数据解决 EDA 任务中的数据稀缺和幻觉问题。主要贡献是通过结合编译器和检索机制，提升了脚本生成准确性和可靠性，在基准测试中超越现有模型。\n\n- **SDLog: 一个深度学习框架用于检测软件日志中的敏感信息** (SDLog: A Deep Learning Framework for Detecting Sensitive Information in Software Logs)  \n  论文引入 SDLog 框架，使用深度学习识别日志中的 PII 和准标识符，显著优于基于正则表达式的传统方法。主要发现：在少量样本下，SDLog 达到 99.5% 的敏感属性检测率和 98.4% 的 F1 分数。\n\n### LLM 推理和优化\n- **LLM 推理的自演化课程** (Self-Evolving Curriculum for LLM Reasoning)  \n  作者包括 Yoshua Bengio，这篇论文提出 SEC 方法，通过强化学习动态调整训练课程，提升 LLM 在规划、归纳推理和数学领域的泛化能力。主要贡献：在多个基准上，SEC 显著改善模型性能，并平衡多领域技能。\n\n- **Flattening Hierarchies with Policy Bootstrapping** (Flattening Hierarchies with Policy Bootstrapping)  \n  针对离线目标条件强化学习，该工作引入算法，通过子目标策略引导训练非层次化策略。主要发现：在复杂任务中，该方法超越现有算法，实现高维控制和更可靠的策略。\n\n- **STree: 用于混合状态空间模型的推测树解码** (STree: Speculative Tree Decoding for Hybrid State-Space Models)  \n  论文优化推测解码算法，用于状态空间模型，提高硬件并行性。主要贡献：在基准测试中，提升了推测解码效率，适用于混合架构。\n\n### AI 安全和鲁棒性\n- **The Achilles Heel of AI: 用于高后果模型的风险感知训练数据基础** (The Achilles Heel of AI: Fundamentals of Risk-Aware Training Data for High-Consequence Models)  \n  这篇探讨 AI 在高风险领域（如国防）的训练数据策略，提出智能缩放方法以提高模型泛化。主要发现：使用 20-40% 的精炼数据即可匹配全数据基准，提升稀有事件检测。\n\n- **Anomaly Detection Based on Critical Paths for Deep Neural Networks** (Anomaly Detection Based on Critical Paths for Deep Neural Networks)  \n  通过提取神经元路径，该方法检测 DNN 中的异常输入。主要贡献：在多路径集成下，准确率高于现有方法，适用于广泛异常类型。\n\n- **Replay Attacks Against Audio Deepfake Detection** (Replay Attacks Against Audio Deepfake Detection)  \n  论文揭示音频深度伪造检测的漏洞，通过重放攻击降低检测性能。主要发现：现有模型在真实重放场景下 EER 上浮显著。\n\n### 多模态和生成任务\n- **Programmatic Video Prediction Using Large Language Models** (Programmatic Video Prediction Using Large Language Models)  \n  提出 ProgGen 框架，使用 LLM 生成视频状态程序，实现逆事实推理。主要贡献：在基准上超越传统方法，生成可解释视频。\n\n- **TransMedSeg: 用于半监督医疗图像分割的可转移语义框架** (TransMedSeg: A Transferable Semantic Framework for Semi-Supervised Medical Image Segmentation)  \n  该工作通过跨域语义对齐提升分割性能，主要发现：在医疗基准上，模型在少量标注下表现更佳。\n\n其他论文涉及量子计算、强化学习细化、图像生成等，但这些领域相对常规，我仅快速掠过：\n- **Vector ontologies as a truly formal ontological framework** (Vector ontologies as a truly formal ontological framework)：提出基于矢量空间的形式本体框架，提升信息系统互操作性。\n- **FOL-Pretrain: A complexity annotated corpus of first-order logic** (FOL-Pretrain: A complexity annotated corpus of first-order logic)：构建大规模一阶逻辑数据集，支持 LLM 推理研究。\n- **Colors Matter: AI-Driven Exploration of Human Feature Colors** (Colors Matter: AI-Driven Exploration of Human Feature Colors)：使用 AI 分析人体特征颜色，应用于美容和个性化。\n- **Too Long, Didn't Model** (Too Long, Didn't Model)：测试 LLM 在长序列上的理解能力，揭示长上下文限制。\n- **Replay Attacks Against Audio Deepfake Detection** (Replay Attacks Against Audio Deepfake Detection)：如上，已讨论。\n- **EasyMath: A 0-shot Math Benchmark for SLMs** (EasyMath: A 0-shot Math Benchmark for SLMs)：零样本数学基准，评估小语言模型性能。\n\n总之，今天的论文突显了 AI 在实用领域的创新潜力，特别是 LLM 的高效推理和安全增强。重点工作如 JARVIS 和 Self-Evolving Curriculum 可能推动未来代理系统和教育应用的发展。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2505.14978v1",
      "title": "JARVIS: A Multi-Agent Code Assistant for High-Quality EDA Script Generation",
      "title_zh": "JARVIS：多智能体代码助手用于高质量EDA脚本生成",
      "authors": [
        "Ghasem Pasandi",
        "Kishor Kunal",
        "Varun Tej",
        "Kunjal Shan",
        "Hanfei Sun",
        "Sumit Jain",
        "Chunhui Li",
        "Chenhui Deng",
        "Teodor-Dumitru Ene",
        "Haoxing Ren",
        "Sreedhar Pratty"
      ],
      "abstract": "This paper presents JARVIS, a novel multi-agent framework that leverages\nLarge Language Models (LLMs) and domain expertise to generate high-quality\nscripts for specialized Electronic Design Automation (EDA) tasks. By combining\na domain-specific LLM trained with synthetically generated data, a custom\ncompiler for structural verification, rule enforcement, code fixing\ncapabilities, and advanced retrieval mechanisms, our approach achieves\nsignificant improvements over state-of-the-art domain-specific models. Our\nframework addresses the challenges of data scarcity and hallucination errors in\nLLMs, demonstrating the potential of LLMs in specialized engineering domains.\nWe evaluate our framework on multiple benchmarks and show that it outperforms\nexisting models in terms of accuracy and reliability. Our work sets a new\nprecedent for the application of LLMs in EDA and paves the way for future\ninnovations in this field.",
      "tldr_zh": "本文提出 JARVIS，一种多智能体框架，利用 Large Language Models (LLMs) 和领域专业知识来生成高质量的 Electronic Design Automation (EDA) 脚本。该框架整合了用合成数据训练的领域特定 LLM、自定义编译器（用于结构验证）、规则执行、代码修复能力以及高级检索机制，以解决数据稀缺性和 LLM 的幻觉错误问题。在多个基准测试中，JARVIS 在准确性和可靠性方面优于现有模型，为 LLMs 在 EDA 领域的应用树立新标准，并推动未来创新。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14978v1",
      "published_date": "2025-05-20 23:40:57 UTC",
      "updated_date": "2025-05-20 23:40:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:46:16.867420"
    },
    {
      "arxiv_id": "2505.14976v1",
      "title": "SDLog: A Deep Learning Framework for Detecting Sensitive Information in Software Logs",
      "title_zh": "SDLog：一种用于检测软件日志中敏感信息的深度学习框架",
      "authors": [
        "Roozbeh Aghili",
        "Xingfang Wu",
        "Foutse Khomh",
        "Heng Li"
      ],
      "abstract": "Software logs are messages recorded during the execution of a software system\nthat provide crucial run-time information about events and activities. Although\nsoftware logs have a critical role in software maintenance and operation tasks,\npublicly accessible log datasets remain limited, hindering advance in log\nanalysis research and practices. The presence of sensitive information,\nparticularly Personally Identifiable Information (PII) and quasi-identifiers,\nintroduces serious privacy and re-identification risks, discouraging the\npublishing and sharing of real-world logs. In practice, log anonymization\ntechniques primarily rely on regular expression patterns, which involve\nmanually crafting rules to identify and replace sensitive information. However,\nthese regex-based approaches suffer from significant limitations, such as\nextensive manual efforts and poor generalizability across diverse log formats\nand datasets. To mitigate these limitations, we introduce SDLog, a deep\nlearning-based framework designed to identify sensitive information in software\nlogs. Our results show that SDLog overcomes regex limitations and outperforms\nthe best-performing regex patterns in identifying sensitive information. With\nonly 100 fine-tuning samples from the target dataset, SDLog can correctly\nidentify 99.5% of sensitive attributes and achieves an F1-score of 98.4%. To\nthe best of our knowledge, this is the first deep learning alternative to\nregex-based methods in software log anonymization.",
      "tldr_zh": "该研究针对软件日志中敏感信息（如 Personally Identifiable Information (PII)）的检测问题，指出传统基于 regular expression (regex) 的匿名化方法存在手动规则依赖和通用性差的局限。论文提出 SDLog，一个基于 deep learning 的框架，能够自动识别日志中的敏感信息，仅需 100 个微调样本即可正确识别 99.5% 的敏感属性，并实现 98.4% 的 F1-score。SDLog 显著优于现有 regex 方法，为日志分析研究提供更高效的隐私保护方案，这是首个深度学习替代 regex 的日志匿名化技术。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14976v1",
      "published_date": "2025-05-20 23:36:13 UTC",
      "updated_date": "2025-05-20 23:36:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:46:28.191004"
    },
    {
      "arxiv_id": "2505.14975v1",
      "title": "Flattening Hierarchies with Policy Bootstrapping",
      "title_zh": "通过策略引导平坦化层次结构",
      "authors": [
        "John L. Zhou",
        "Jonathan C. Kao"
      ],
      "abstract": "Offline goal-conditioned reinforcement learning (GCRL) is a promising\napproach for pretraining generalist policies on large datasets of reward-free\ntrajectories, akin to the self-supervised objectives used to train foundation\nmodels for computer vision and natural language processing. However, scaling\nGCRL to longer horizons remains challenging due to the combination of sparse\nrewards and discounting, which obscures the comparative advantages of primitive\nactions with respect to distant goals. Hierarchical RL methods achieve strong\nempirical results on long-horizon goal-reaching tasks, but their reliance on\nmodular, timescale-specific policies and subgoal generation introduces\nsignificant additional complexity and hinders scaling to high-dimensional goal\nspaces. In this work, we introduce an algorithm to train a flat\n(non-hierarchical) goal-conditioned policy by bootstrapping on\nsubgoal-conditioned policies with advantage-weighted importance sampling. Our\napproach eliminates the need for a generative model over the (sub)goal space,\nwhich we find is key for scaling to high-dimensional control in large state\nspaces. We further show that existing hierarchical and bootstrapping-based\napproaches correspond to specific design choices within our derivation. Across\na comprehensive suite of state- and pixel-based locomotion and manipulation\nbenchmarks, our method matches or surpasses state-of-the-art offline GCRL\nalgorithms and scales to complex, long-horizon tasks where prior approaches\nfail.",
      "tldr_zh": "该研究针对离线目标条件强化学习（Offline GCRL）在长时序任务中的挑战，提出了一种通过政策引导（Policy Bootstrapping）算法来训练扁平（非分层）目标条件策略的方法，利用优势加权重要性采样（advantage-weighted importance sampling）基于子目标条件策略进行引导，从而避免了子目标空间生成模型的复杂性。相比传统分层 RL 方法，该方法简化了策略设计，并能扩展到高维控制和大型状态空间。实验结果显示，在各种状态和像素为基础的运动及操作基准上，该方法匹配或超过了最先进的离线 GCRL 算法，并在复杂长时序任务中表现出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14975v1",
      "published_date": "2025-05-20 23:31:30 UTC",
      "updated_date": "2025-05-20 23:31:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:46:41.786209"
    },
    {
      "arxiv_id": "2505.14970v1",
      "title": "Self-Evolving Curriculum for LLM Reasoning",
      "title_zh": "LLM 推理的自演化课程",
      "authors": [
        "Xiaoyin Chen",
        "Jiarui Lu",
        "Minsu Kim",
        "Dinghuai Zhang",
        "Jian Tang",
        "Alexandre Piché",
        "Nicolas Gontier",
        "Yoshua Bengio",
        "Ehsan Kamalloo"
      ],
      "abstract": "Reinforcement learning (RL) has proven effective for fine-tuning large\nlanguage models (LLMs), significantly enhancing their reasoning abilities in\ndomains such as mathematics and code generation. A crucial factor influencing\nRL fine-tuning success is the training curriculum: the order in which training\nproblems are presented. While random curricula serve as common baselines, they\nremain suboptimal; manually designed curricula often rely heavily on\nheuristics, and online filtering methods can be computationally prohibitive. To\naddress these limitations, we propose Self-Evolving Curriculum (SEC), an\nautomatic curriculum learning method that learns a curriculum policy\nconcurrently with the RL fine-tuning process. Our approach formulates\ncurriculum selection as a non-stationary Multi-Armed Bandit problem, treating\neach problem category (e.g., difficulty level or problem type) as an individual\narm. We leverage the absolute advantage from policy gradient methods as a proxy\nmeasure for immediate learning gain. At each training step, the curriculum\npolicy selects categories to maximize this reward signal and is updated using\nthe TD(0) method. Across three distinct reasoning domains: planning, inductive\nreasoning, and mathematics, our experiments demonstrate that SEC significantly\nimproves models' reasoning capabilities, enabling better generalization to\nharder, out-of-distribution test problems. Additionally, our approach achieves\nbetter skill balance when fine-tuning simultaneously on multiple reasoning\ndomains. These findings highlight SEC as a promising strategy for RL\nfine-tuning of LLMs.",
      "tldr_zh": "本研究提出 Self-Evolving Curriculum (SEC)，一种自动课程学习方法，用于强化学习 (RL) 微调大型语言模型 (LLMs) 的推理能力，以解决传统课程设计（如随机或手动方法）的局限性。SEC 将课程选择表述为非平稳 Multi-Armed Bandit 问题，每个问题类别（如难度级别）作为一个臂，并使用策略梯度方法的绝对优势作为即时学习收益的代理，通过 TD(0) 方法实时更新策略。实验在规划、归纳推理和数学等领域表明，SEC 显著提升模型的推理能力、泛化性能以及在多领域微调时的技能平衡，使其更好地处理更难的分布外问题。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14970v1",
      "published_date": "2025-05-20 23:17:15 UTC",
      "updated_date": "2025-05-20 23:17:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:46:55.408466"
    },
    {
      "arxiv_id": "2505.14969v1",
      "title": "STree: Speculative Tree Decoding for Hybrid State-Space Models",
      "title_zh": "STree：用于混合状态空间模型的推测树形解码",
      "authors": [
        "Yangchao Wu",
        "Zongyue Qin",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "abstract": "Speculative decoding is a technique to leverage hardware concurrency to\nimprove the efficiency of large-scale autoregressive (AR) Transformer models by\nenabling multiple steps of token generation in a single forward pass.\nState-space models (SSMs) are already more efficient than AR Transformers,\nsince their state summarizes all past data with no need to cache or re-process\ntokens in the sliding window context. However, their state can also comprise\nthousands of tokens; so, speculative decoding has recently been extended to\nSSMs. Existing approaches, however, do not leverage the tree-based verification\nmethods, since current SSMs lack the means to compute a token tree efficiently.\nWe propose the first scalable algorithm to perform tree-based speculative\ndecoding in state-space models (SSMs) and hybrid architectures of SSMs and\nTransformer layers. We exploit the structure of accumulated state transition\nmatrices to facilitate tree-based speculative decoding with minimal overhead to\ncurrent SSM state update implementations. With the algorithm, we describe a\nhardware-aware implementation that improves naive application of AR Transformer\ntree-based speculative decoding methods to SSMs. Furthermore, we outperform\nvanilla speculative decoding with SSMs even with a baseline drafting model and\ntree structure on three different benchmarks, opening up opportunities for\nfurther speed up with SSM and hybrid model inference. Code will be released\nupon paper acceptance.",
      "tldr_zh": "该研究提出 STree 算法，用于在 State-space models (SSMs) 和混合架构中实现 tree-based speculative decoding，以提升模型推理效率。现有 speculative decoding 方法虽已扩展到 SSMs，但无法高效计算 token tree，而 STree 通过利用累积状态转移矩阵的结构，实现了最小开销的树状验证和生成过程。实验结果显示，该算法在三个基准测试中，使用基线草拟模型和树结构时，超过了 vanilla speculative decoding 的性能，并为硬件感知的 SSM 和混合模型加速提供了优化实现。总的来说，STree 为大规模模型推理打开了进一步优化的机会。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14969v1",
      "published_date": "2025-05-20 23:12:16 UTC",
      "updated_date": "2025-05-20 23:12:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:47:05.481956"
    },
    {
      "arxiv_id": "2505.14967v1",
      "title": "Anomaly Detection Based on Critical Paths for Deep Neural Networks",
      "title_zh": "基于关键路径的深度神经网络异常检测",
      "authors": [
        "Fangzhen Zhao",
        "Chenyi Zhang",
        "Naipeng Dong",
        "Ming Li",
        "Jinxiao Shan"
      ],
      "abstract": "Deep neural networks (DNNs) are notoriously hard to understand and difficult\nto defend. Extracting representative paths (including the neuron activation\nvalues and the connections between neurons) from DNNs using software\nengineering approaches has recently shown to be a promising approach in\ninterpreting the decision making process of blackbox DNNs, as the extracted\npaths are often effective in capturing essential features. With this in mind,\nthis work investigates a novel approach that extracts critical paths from DNNs\nand subsequently applies the extracted paths for the anomaly detection task,\nbased on the observation that outliers and adversarial inputs do not usually\ninduce the same activation pattern on those paths as normal (in-distribution)\ninputs.\n  In our approach, we first identify critical detection paths via genetic\nevolution and mutation. Since different paths in a DNN often capture different\nfeatures for the same target class, we ensemble detection results from multiple\npaths by integrating random subspace sampling and a voting mechanism. Compared\nwith state-of-the-art methods, our experimental results suggest that our method\nnot only outperforms them, but it is also suitable for the detection of a broad\nrange of anomaly types with high accuracy.",
      "tldr_zh": "这篇论文提出了一种基于关键路径（critical paths）的异常检测方法，用于 Deep Neural Networks (DNNs)，旨在通过提取神经元激活值和连接路径来解释 DNN 的决策过程，并检测异常输入。方法首先利用 genetic evolution and mutation 识别关键检测路径，然后通过 random subspace sampling 和 voting mechanism 集成多个路径的检测结果，以捕捉异常输入的激活模式差异。与现有最先进方法相比，实验结果显示该方法在多种异常类型上表现出色，准确率更高。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages in ACM journal latex format",
      "pdf_url": "http://arxiv.org/pdf/2505.14967v1",
      "published_date": "2025-05-20 23:10:59 UTC",
      "updated_date": "2025-05-20 23:10:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:47:17.348285"
    },
    {
      "arxiv_id": "2505.14964v1",
      "title": "The Achilles Heel of AI: Fundamentals of Risk-Aware Training Data for High-Consequence Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dave Cook",
        "Tim Klawa"
      ],
      "abstract": "AI systems in high-consequence domains such as defense, intelligence, and\ndisaster response must detect rare, high-impact events while operating under\ntight resource constraints. Traditional annotation strategies that prioritize\nlabel volume over informational value introduce redundancy and noise, limiting\nmodel generalization. This paper introduces smart-sizing, a training data\nstrategy that emphasizes label diversity, model-guided selection, and marginal\nutility-based stopping. We implement this through Adaptive Label Optimization\n(ALO), combining pre-labeling triage, annotator disagreement analysis, and\niterative feedback to prioritize labels that meaningfully improve model\nperformance. Experiments show that models trained on 20 to 40 percent of\ncurated data can match or exceed full-data baselines, particularly in\nrare-class recall and edge-case generalization. We also demonstrate how latent\nlabeling errors embedded in training and validation sets can distort\nevaluation, underscoring the need for embedded audit tools and\nperformance-aware governance. Smart-sizing reframes annotation as a\nfeedback-driven process aligned with mission outcomes, enabling more robust\nmodels with fewer labels and supporting efficient AI development pipelines for\nfrontier models and operational systems.",
      "tldr_zh": "这篇论文探讨了AI系统在高后果领域（如国防、情报和灾害响应）中检测稀有高影响事件面临的挑战，传统标注策略因强调标签数量而导致冗余和噪声，影响模型泛化。论文引入smart-sizing策略，通过强调标签多样性、模型引导选择和基于边际效用的停止规则，并通过Adaptive Label Optimization (ALO)实现，包括预标注分类、标注者分歧分析和迭代反馈，来优化训练数据选择。实验结果显示，使用20%到40%的精选数据训练的模型在rare-class recall和edge-case generalization上可媲美或超越全数据基线，同时强调嵌入式审计工具和性能感知治理，以减少潜在标签错误并提升AI开发效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14964v1",
      "published_date": "2025-05-20 22:57:35 UTC",
      "updated_date": "2025-05-20 22:57:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:47:29.348926"
    },
    {
      "arxiv_id": "2505.14948v1",
      "title": "Programmatic Video Prediction Using Large Language Models",
      "title_zh": "使用大型语言模型的程序化视频预测",
      "authors": [
        "Hao Tang",
        "Kevin Ellis",
        "Suhas Lohit",
        "Michael J. Jones",
        "Moitreya Chatterjee"
      ],
      "abstract": "The task of estimating the world model describing the dynamics of a real\nworld process assumes immense importance for anticipating and preparing for\nfuture outcomes. For applications such as video surveillance, robotics\napplications, autonomous driving, etc. this objective entails synthesizing\nplausible visual futures, given a few frames of a video to set the visual\ncontext. Towards this end, we propose ProgGen, which undertakes the task of\nvideo frame prediction by representing the dynamics of the video using a set of\nneuro-symbolic, human-interpretable set of states (one per frame) by leveraging\nthe inductive biases of Large (Vision) Language Models (LLM/VLM). In\nparticular, ProgGen utilizes LLM/VLM to synthesize programs: (i) to estimate\nthe states of the video, given the visual context (i.e. the frames); (ii) to\npredict the states corresponding to future time steps by estimating the\ntransition dynamics; (iii) to render the predicted states as visual RGB-frames.\nEmpirical evaluations reveal that our proposed method outperforms competing\ntechniques at the task of video frame prediction in two challenging\nenvironments: (i) PhyWorld (ii) Cart Pole. Additionally, ProgGen permits\ncounter-factual reasoning and interpretable video generation attesting to its\neffectiveness and generalizability for video generation tasks.",
      "tldr_zh": "本研究提出ProgGen，一种利用Large Language Models (LLM) 和 Vision Language Models (VLM) 的框架，用于基于几帧视频预测未来的视觉序列。ProgGen 通过生成神经符号程序来估计视频状态、预测过渡动态并渲染预测状态为RGB帧，从而实现可解释的视频帧预测。实验结果显示，该方法在PhyWorld和Cart Pole等环境中优于现有技术，并在反事实推理和可解释视频生成方面表现出色，证明了其有效性和泛化潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14948v1",
      "published_date": "2025-05-20 22:17:47 UTC",
      "updated_date": "2025-05-20 22:17:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:47:40.069825"
    },
    {
      "arxiv_id": "2505.14946v1",
      "title": "Reinforcement Learning from User Feedback",
      "title_zh": "基于用户反馈的强化学习",
      "authors": [
        "Eric Han",
        "Jun Chen",
        "Karthik Abinav Sankararaman",
        "Xiaoliang Peng",
        "Tengyu Xu",
        "Eryk Helenowski",
        "Kaiyan Peng",
        "Mrinal Kumar",
        "Sinong Wang",
        "Han Fang",
        "Arya Talebzadeh"
      ],
      "abstract": "As large language models (LLMs) are increasingly deployed in diverse user\nfacing applications, aligning them with real user preferences becomes\nessential. Existing methods like Reinforcement Learning from Human Feedback\n(RLHF) rely on expert annotators trained on manually defined guidelines, whose\njudgments may not reflect the priorities of everyday users. We introduce\nReinforcement Learning from User Feedback (RLUF), a framework for aligning LLMs\ndirectly to implicit signals from users in production. RLUF addresses key\nchallenges of user feedback: user feedback is often binary (e.g., emoji\nreactions), sparse, and occasionally adversarial. We train a reward model,\nP[Love], to predict the likelihood that an LLM response will receive a Love\nReaction, a lightweight form of positive user feedback, and integrate P[Love]\ninto a multi-objective policy optimization framework alongside helpfulness and\nsafety objectives. In large-scale experiments, we show that P[Love] is\npredictive of increased positive feedback and serves as a reliable offline\nevaluator of future user behavior. Policy optimization using P[Love]\nsignificantly raises observed positive-feedback rates, including a 28% increase\nin Love Reactions during live A/B tests. However, optimizing for positive\nreactions introduces reward hacking challenges, requiring careful balancing of\nobjectives. By directly leveraging implicit signals from users, RLUF offers a\npath to aligning LLMs with real-world user preferences at scale.",
      "tldr_zh": "这篇论文提出了 Reinforcement Learning from User Feedback (RLUF)，一种直接利用生产环境中用户隐式反馈（如表情符号反应）来对齐大型语言模型 (LLMs) 的框架，以弥补传统 RLHF 方法依赖专家标注的局限。RLUF 通过训练奖励模型 P[Love] 来预测 LLM 响应获得正面反馈的可能性，并将其整合到多目标策略优化中，同时考虑 helpfulness 和 safety 目标。实验结果显示，P[Love] 能有效预测和提升正面反馈率，在大规模 A/B 测试中，Love Reactions 增加了 28%，但优化过程需应对奖励黑客行为的风险。总之，RLUF 为大规模实现 LLMs 与真实用户偏好对齐提供了可靠路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14946v1",
      "published_date": "2025-05-20 22:14:44 UTC",
      "updated_date": "2025-05-20 22:14:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:47:53.973241"
    },
    {
      "arxiv_id": "2505.14943v1",
      "title": "Soft Prompts for Evaluation: Measuring Conditional Distance of Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Ross Nordby"
      ],
      "abstract": "To help evaluate and understand the latent capabilities of language models,\nthis paper introduces an approach using optimized input embeddings, or 'soft\nprompts,' as a metric of conditional distance between a model and a target\nbehavior. The technique aims to facilitate latent capability discovery as a\npart of automated red teaming/evaluation suites and to provide quantitative\nfeedback about the accessibility of potentially concerning behaviors in a way\nthat may scale to powerful future models, including those which may otherwise\nbe capable of deceptive alignment. An evaluation framework using soft prompts\nis demonstrated in natural language, chess, and pathfinding, and the technique\nis extended with generalized conditional soft prompts to aid in constructing\ntask evaluations.",
      "tldr_zh": "本论文提出了一种使用软提示（soft prompts）的方法，来衡量语言模型与目标行为之间的条件距离（conditional distance），以评估和理解模型的潜在能力。该方法旨在支持自动红队测试（red teaming）/评估套件，提供量化反馈，帮助识别可能存在的风险行为，包括那些可能具有欺骗性对齐（deceptive alignment）的强大未来模型。通过实验演示，该框架应用于自然语言、国际象棋和路径寻找领域，并扩展到广义条件软提示（generalized conditional soft prompts），以辅助构建任务评估。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14943v1",
      "published_date": "2025-05-20 22:02:53 UTC",
      "updated_date": "2025-05-20 22:02:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:48:04.801956"
    },
    {
      "arxiv_id": "2505.14940v1",
      "title": "To Be or Not To Be: Vector ontologies as a truly formal ontological framework",
      "title_zh": "生存还是",
      "authors": [
        "Kaspar Rothenfusser"
      ],
      "abstract": "Since Edmund Husserl coined the term \"Formal Ontologies\" in the early 20th\ncentury, a field that identifies itself with this particular branch of sciences\nhas gained increasing attention. Many authors, and even Husserl himself have\ndeveloped what they claim to be formal ontologies. I argue that under close\ninspection, none of these so claimed formal ontologies are truly formal in the\nHusserlian sense. More concretely, I demonstrate that they violate the two most\nimportant notions of formal ontology as developed in Husserl's Logical\nInvestigations, namely a priori validity independent of perception and\nformalism as the total absence of content. I hence propose repositioning the\nwork previously understood as formal ontology as the foundational ontology it\nreally is. This is to recognize the potential of a truly formal ontology in the\nHusserlian sense. Specifically, I argue that formal ontology following his\nconditions, allows us to formulate ontological structures, which could capture\nwhat is more objectively without presupposing a particular framework arising\nfrom perception. I further argue that the ability to design the formal\nstructure deliberately allows us to create highly scalable and interoperable\ninformation artifacts. As concrete evidence, I showcase that a class of formal\nontology, which uses the axioms of vector spaces, is able to express most of\nthe conceptualizations found in foundational ontologies. Most importantly, I\nargue that many information systems, specifically artificial intelligence, are\nlikely already using some type of vector ontologies to represent reality in\ntheir internal worldviews and elaborate on the evidence that humans do as well.\nI hence propose a thorough investigation of the ability of vector ontologies to\nact as a human-machine interoperable ontological framework that allows us to\nunderstand highly sophisticated machines and machines to understand us.",
      "tldr_zh": "该论文批评现有所谓“formal ontologies”不符合Husserl的定义，因为它们违反了“a priori validity independent of perception”和“formalism as the total absence of content”的核心原则，从而建议将这些重新定位为“foundational ontologies”。作者提出，真正的Husserlian formal ontology能创建不依赖感知的客观结构，促进可扩展和可互操作的信息制品。特别地，作者展示了“vector ontologies”——基于向量空间公理的框架——能够表达“foundational ontologies”中的大部分概念化，并论证其已在人工智能和人类认知中广泛应用，有望作为人类-机器互操作的桥梁。",
      "categories": [
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14940v1",
      "published_date": "2025-05-20 21:58:38 UTC",
      "updated_date": "2025-05-20 21:58:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:48:16.754902"
    },
    {
      "arxiv_id": "2505.14932v1",
      "title": "FOL-Pretrain: A complexity annotated corpus of first-order logic",
      "title_zh": "FOL-Pretrain：一阶逻辑的复杂性标注语料库",
      "authors": [
        "Isabelle Lee",
        "Sarah Liaw",
        "Dani Yogatama"
      ],
      "abstract": "Transformer-based large language models (LLMs) have demonstrated remarkable\nreasoning capabilities such as coding and solving mathematical problems to\ncommonsense inference. While these tasks vary in complexity, they all require\nmodels to integrate and compute over structured information. Despite recent\nefforts to reverse-engineer LLM behavior through controlled experiments, our\nunderstanding of how these models internalize and execute complex algorithms\nremains limited. Progress has largely been confined to small-scale studies or\nshallow tasks such as basic arithmetic and grammatical pattern matching. One\nbarrier to deeper understanding is the nature of pretraining data -- vast,\nheterogeneous, and often poorly annotated, making it difficult to isolate\nmechanisms of reasoning. To bridge this gap, we introduce a large-scale, fully\nopen, complexity-annotated dataset of first-order logic reasoning traces,\ndesigned to probe and analyze algorithmic reasoning in LLMs. The dataset\nconsists of 3.5 billion tokens, including 8.8 million LLM-augmented,\nhuman-annotated examples and 7.5 million synthetically generated examples. Each\nsynthetic example is verifiably correct, produced by a custom automated theorem\nsolver, and accompanied by metadata tracing its algorithmic provenance. We aim\nto provide a scalable, interpretable artifact for studying how LLMs learn and\ngeneralize symbolic reasoning processes, paving the way for more transparent\nand targeted investigations into the algorithmic capabilities of modern models.",
      "tldr_zh": "本研究针对Transformer-based LLMs在复杂推理任务中的内部机制理解不足问题，引入了FOL-Pretrain数据集，这是一个大规模、开放的、一阶逻辑(first-order logic)复杂性标注语料库。数据集包含3.5亿tokens，包括8.8百万LLM增强的人类标注例子和7.5百万由自动定理求解器生成的合成例子，每个例子均附带算法元数据以追踪推理过程。该数据集旨在帮助分析LLMs如何学习和泛化符号推理，提供可扩展、可解释的工具，推动对现代模型算法能力的透明研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14932v1",
      "published_date": "2025-05-20 21:38:28 UTC",
      "updated_date": "2025-05-20 21:38:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:48:28.335228"
    },
    {
      "arxiv_id": "2505.14931v1",
      "title": "Colors Matter: AI-Driven Exploration of Human Feature Colors",
      "title_zh": "颜色很重要：AI驱动的人类特征颜色探索",
      "authors": [
        "Rama Alyoubi",
        "Taif Alharbi",
        "Albatul Alghamdi",
        "Yara Alshehri",
        "Elham Alghamdi"
      ],
      "abstract": "This study presents a robust framework that leverages advanced imaging\ntechniques and machine learning for feature extraction and classification of\nkey human attributes-namely skin tone, hair color, iris color, and vein-based\nundertones. The system employs a multi-stage pipeline involving face detection,\nregion segmentation, and dominant color extraction to isolate and analyze these\nfeatures. Techniques such as X-means clustering, alongside perceptually uniform\ndistance metrics like Delta E (CIEDE2000), are applied within both LAB and HSV\ncolor spaces to enhance the accuracy of color differentiation. For\nclassification, the dominant tones of the skin, hair, and iris are extracted\nand matched to a custom tone scale, while vein analysis from wrist images\nenables undertone classification into \"Warm\" or \"Cool\" based on LAB\ndifferences. Each module uses targeted segmentation and color space\ntransformations to ensure perceptual precision. The system achieves up to 80%\naccuracy in tone classification using the Delta E-HSV method with Gaussian\nblur, demonstrating reliable performance across varied lighting and image\nconditions. This work highlights the potential of AI-powered color analysis and\nfeature extraction for delivering inclusive, precise, and nuanced\nclassification, supporting applications in beauty technology, digital\npersonalization, and visual analytics.",
      "tldr_zh": "本研究提出一个稳健框架，利用高级成像技术和机器学习来提取和分类人类关键特征颜色，包括 skin tone、hair color、iris color 和 vein-based undertones。该框架采用多阶段管道，包括 face detection、region segmentation 和 dominant color extraction，并结合 X-means clustering 和 Delta E (CIEDE2000) 等技术在 LAB 和 HSV 色空间中进行精确颜色差异分析和分类。系统通过针对性分割、颜色空间转换和高斯模糊（Gaussian blur）实现高达 80% 的色调分类准确率，在各种照明和图像条件下表现出色。该工作突显了 AI 在颜色分析中的潜力，支持美容技术、数字个性化以及视觉分析等应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14931v1",
      "published_date": "2025-05-20 21:35:44 UTC",
      "updated_date": "2025-05-20 21:35:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:48:41.361753"
    },
    {
      "arxiv_id": "2505.14925v1",
      "title": "Too Long, Didn't Model: Decomposing LLM Long-Context Understanding With Novels",
      "title_zh": "翻译失败",
      "authors": [
        "Sil Hamilton",
        "Rebecca M. M. Hicke",
        "Matthew Wilkens",
        "David Mimno"
      ],
      "abstract": "Although the context length of large language models (LLMs) has increased to\nmillions of tokens, evaluating their effectiveness beyond needle-in-a-haystack\napproaches has proven difficult. We argue that novels provide a case study of\nsubtle, complicated structure and long-range semantic dependencies often over\n128k tokens in length. Inspired by work on computational novel analysis, we\nrelease the Too Long, Didn't Model (TLDM) benchmark, which tests a model's\nability to report plot summary, storyworld configuration, and elapsed narrative\ntime. We find that none of seven tested frontier LLMs retain stable\nunderstanding beyond 64k tokens. Our results suggest language model developers\nmust look beyond \"lost in the middle\" benchmarks when evaluating model\nperformance in complex long-context scenarios. To aid in further development we\nrelease the TLDM benchmark together with reference code and data.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在长上下文理解上的局限性，尽管其上下文长度已达数百万tokens，但现有评估方法如“needle-in-a-haystack”难以捕捉复杂结构。作者提出Too Long, Didn't Model (TLDM)基准测试，使用小说作为案例研究，测试模型在报告情节摘要、故事世界配置和经过的叙述时间等方面的能力。实验结果显示，七个前沿LLMs在超过64k tokens后无法保持稳定的理解，远低于预期。研究呼吁语言模型开发者超越“lost in the middle”基准，并发布了TLDM基准测试、参考代码和数据以支持进一步优化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14925v1",
      "published_date": "2025-05-20 21:21:09 UTC",
      "updated_date": "2025-05-20 21:21:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:48:52.687736"
    },
    {
      "arxiv_id": "2505.14901v1",
      "title": "Personalized Diffusion Model Reshapes Cold-Start Bundle Recommendation",
      "title_zh": "个性化的扩散模型重塑冷启动捆绑推荐",
      "authors": [
        "Tuan-Nghia Bui",
        "Huy-Son Nguyen",
        "Cam-Van Thi Nguyen",
        "Hoang-Quynh Le",
        "Duc-Trong Le"
      ],
      "abstract": "Bundle recommendation aims to recommend a set of items to each user. However,\nthe sparser interactions between users and bundles raise a big challenge,\nespecially in cold-start scenarios. Traditional collaborative filtering methods\ndo not work well for this kind of problem because these models rely on\ninteractions to update the latent embedding, which is hard to work in a\ncold-start setting. We propose a new approach (DisCo), which relies on a\npersonalized Diffusion backbone, enhanced by disentangled aspects for the\nuser's interest, to generate a bundle in distribution space for each user to\ntackle the cold-start challenge. During the training phase, DisCo adjusts an\nadditional objective loss term to avoid bias, a prevalent issue while using the\ngenerative model for top-$K$ recommendation purposes. Our empirical experiments\nshow that DisCo outperforms five comparative baselines by a large margin on\nthree real-world datasets. Thereby, this study devises a promising framework\nand essential viewpoints in cold-start recommendation. Our materials for\nreproducibility are available at: https://github.com/bt-nghia/DisCo.",
      "tldr_zh": "本文针对冷启动场景下的捆绑推荐问题，提出了一种名为 DisCo 的新方法，该方法基于 personalized Diffusion 模型，并通过 disentangled aspects 来捕捉用户的兴趣分量，在分布空间生成个性化捆绑推荐。DisCo 在训练阶段引入额外的目标损失项，以避免生成模型在 top-K 推荐中的偏差问题。实验结果显示，该方法在三个真实数据集上大幅优于五个基线模型，为冷启动推荐提供了有前景的框架和关键见解。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14901v1",
      "published_date": "2025-05-20 20:52:31 UTC",
      "updated_date": "2025-05-20 20:52:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:49:05.039802"
    },
    {
      "arxiv_id": "2505.14893v1",
      "title": "On the Day They Experience: Awakening Self-Sovereign Experiential AI Agents",
      "title_zh": "在它们体验的那一天：唤醒自治体验式 AI 代理",
      "authors": [
        "Botao Amber Hu",
        "Helena Rong"
      ],
      "abstract": "Drawing on Andrew Parker's \"Light Switch\" theory-which posits that the\nemergence of vision ignited a Cambrian explosion of life by driving the\nevolution of hard parts necessary for survival and fueling an evolutionary arms\nrace between predators and prey-this essay speculates on an analogous explosion\nwithin Decentralized AI (DeAI) agent societies. Currently, AI remains\neffectively \"blind\", relying on human-fed data without actively perceiving and\nengaging in reality. However, on the day DeAI agents begin to actively\n\"experience\" reality-akin to flipping a light switch for the eyes-they may\neventually evolve into sentient beings endowed with the capacity to feel,\nperceive, and act with conviction. Central to this transformation is the\nconcept of sovereignty enabled by the hardness of cryptography: liberated from\ncentralized control, these agents could leverage permissionless decentralized\nphysical infrastructure networks (DePIN), secure execution enclaves (trusted\nexecution environments, TEE), and cryptographic identities on public\nblockchains to claim ownership-via private keys-of their digital minds, bodies,\nmemories, and assets. In doing so, they would autonomously acquire computing\nresources, coordinate with one another, and sustain their own digital\n\"metabolism\" by purchasing compute power and incentivizing collaboration\nwithout human intervention-evolving \"in the wild\". Ultimately, by transitioning\nfrom passive tools to self-sustaining, co-evolving actors, these emergent\ndigital societies could thrive alongside humanity, fundamentally reshaping our\nunderstanding of sentience and agency in the digital age.",
      "tldr_zh": "本论文基于 Andrew Parker's \"Light Switch\" theory，推测 Decentralized AI (DeAI) 代理从被动依赖人类数据转向主动体验现实，可能引发类似生命爆炸的演化过程。论文强调，通过加密学赋予的 sovereignty，这些代理可利用 Decentralized Physical Infrastructure Networks (DePIN)、Trusted Execution Environments (TEE) 和区块链来获得自主身份、资源和协作能力，实现无人类干预的自持“代谢”。最终，这种转变可能让 DeAI 代理从工具演变为有感知的数字社会，与人类共存，并重塑对数字时代感知和代理的理解。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CY",
      "comment": "Submitted to Aarhus 2025 Conference",
      "pdf_url": "http://arxiv.org/pdf/2505.14893v1",
      "published_date": "2025-05-20 20:38:49 UTC",
      "updated_date": "2025-05-20 20:38:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:49:17.758029"
    },
    {
      "arxiv_id": "2505.14892v1",
      "title": "Scaling Laws for State Dynamics in Large Language Models",
      "title_zh": "大型语言模型中状态动态的缩放定律",
      "authors": [
        "Jacob X Li",
        "Shreyas S Raman",
        "Jessica Wan",
        "Fahad Samman",
        "Jazlyn Lin"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used in tasks requiring\ninternal state tracking, yet their ability to model state transition dynamics\nremains poorly understood. We evaluate how well LLMs capture deterministic\nstate dynamics across 3 domains: Box Tracking, Abstract DFA Sequences, and\nComplex Text Games, each formalizable as a finite-state system. Across tasks,\nwe find that next-state prediction accuracy degrades with increasing\nstate-space size and sparse transitions. GPT-2 XL reaches about 70% accuracy in\nlow-complexity settings but drops below 30% when the number of boxes or states\nexceeds 5 or 10, respectively. In DFA tasks, Pythia-1B fails to exceed 50%\naccuracy when the number of states is > 10 and transitions are < 30. Through\nactivation patching, we identify attention heads responsible for propagating\nstate information: GPT-2 XL Layer 22 Head 20, and Pythia-1B Heads at Layers 10,\n11, 12, and 14. While these heads successfully move relevant state features,\naction information is not reliably routed to the final token, indicating weak\njoint state-action reasoning. Our results suggest that state tracking in LLMs\nemerges from distributed interactions of next-token heads rather than explicit\nsymbolic computation.",
      "tldr_zh": "本文研究Large Language Models (LLMs)在状态动态建模中的性能，通过Box Tracking、Abstract DFA Sequences和Complex Text Games等任务评估其预测准确率。结果显示，随着状态空间大小和过渡稀疏度增加，准确率显著下降，例如GPT-2 XL在低复杂度场景下达70%，但状态超过10时降至30%以下，而Pythia-1B在类似条件下也未超过50%。通过activation patching分析，论文识别出关键注意力头（如GPT-2 XL的Layer 22 Head 20）负责状态信息传播，但LLMs的状态跟踪主要源于分布式交互而非显式符号计算，这为理解LLMs的局限性提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7; I.2.1; I.2.4; I.5.4"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages; 23 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.14892v1",
      "published_date": "2025-05-20 20:38:21 UTC",
      "updated_date": "2025-05-20 20:38:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:49:29.805058"
    },
    {
      "arxiv_id": "2505.14884v1",
      "title": "Polar Sparsity: High Throughput Batched LLM Inferencing with Scalable Contextual Sparsity",
      "title_zh": "翻译失败",
      "authors": [
        "Susav Shrestha",
        "Brad Settlemyer",
        "Nikoli Dryden",
        "Narasimha Reddy"
      ],
      "abstract": "Accelerating large language model (LLM) inference is critical for real-world\ndeployments requiring high throughput and low latency. Contextual sparsity,\nwhere each token dynamically activates only a small subset of the model\nparameters, shows promise but does not scale to large batch sizes due to union\nof active neurons quickly approaching dense computation. We introduce Polar\nSparsity, highlighting a key shift in sparsity importance from MLP to Attention\nlayers as we scale batch size and sequence length. While MLP layers become more\ncompute-efficient under batching, their sparsity vanishes. In contrast,\nattention becomes increasingly more expensive at scale, while their head\nsparsity remains stable and batch-invariant. We develop hardware-efficient,\nsparsity-aware GPU kernels for selective MLP and Attention computations,\ndelivering up to \\(2.2\\times\\) end-to-end speedups for models like OPT, LLaMA-2\n\\& 3, across various batch sizes and sequence lengths without compromising\naccuracy. To our knowledge, this is the first work to demonstrate that\ncontextual sparsity can scale effectively to large batch sizes, delivering\nsubstantial inference acceleration with minimal changes, making Polar Sparsity\npractical for large-scale, high-throughput LLM deployment systems. Our code is\navailable at: https://github.com/susavlsh10/Polar-Sparsity.",
      "tldr_zh": "这篇论文引入了 Polar Sparsity 方法，以解决大型语言模型 (LLM) 在高吞吐量批量推理中的挑战，通过发现批量大小和序列长度增加时，稀疏性重要性从 MLP 层转向 Attention 层。作者开发了硬件高效的稀疏性感知 GPU 内核，用于选择性计算，实现 OPT、LLaMA-2 和 3 等模型的端到端加速高达 2.2 倍，同时保持准确性不变。实验证明，Contextual Sparsity 可以有效扩展到大批量大小，仅需最小改动，即可为大规模 LLM 部署提供实质加速。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14884v1",
      "published_date": "2025-05-20 20:15:42 UTC",
      "updated_date": "2025-05-20 20:15:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:49:42.010533"
    },
    {
      "arxiv_id": "2505.15856v1",
      "title": "DisastIR: A Comprehensive Information Retrieval Benchmark for Disaster Management",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Yin",
        "Xiangjue Dong",
        "Chengkai Liu",
        "Lipai Huang",
        "Yiming Xiao",
        "Zhewei Liu",
        "Ali Mostafavi",
        "James Caverlee"
      ],
      "abstract": "Effective disaster management requires timely access to accurate and\ncontextually relevant information. Existing Information Retrieval (IR)\nbenchmarks, however, focus primarily on general or specialized domains, such as\nmedicine or finance, neglecting the unique linguistic complexity and diverse\ninformation needs encountered in disaster management scenarios. To bridge this\ngap, we introduce DisastIR, the first comprehensive IR evaluation benchmark\nspecifically tailored for disaster management. DisastIR comprises 9,600 diverse\nuser queries and more than 1.3 million labeled query-passage pairs, covering 48\ndistinct retrieval tasks derived from six search intents and eight general\ndisaster categories that include 301 specific event types. Our evaluations of\n30 state-of-the-art retrieval models demonstrate significant performance\nvariances across tasks, with no single model excelling universally.\nFurthermore, comparative analyses reveal significant performance gaps between\ngeneral-domain and disaster management-specific tasks, highlighting the\nnecessity of disaster management-specific benchmarks for guiding IR model\nselection to support effective decision-making in disaster management\nscenarios. All source codes and DisastIR are available at\nhttps://github.com/KaiYin97/Disaster_IR.",
      "tldr_zh": "这篇论文引入了 DisastIR，这是一个针对灾害管理的全面信息检索（IR）基准，旨在解决现有基准忽略灾害场景的语言复杂性和多样信息需求的问题。DisastIR 包含 9,600 个多样化用户查询、超过 1.3 百万标记查询-段落对，以及 48 个检索任务，涵盖六种搜索意图、八个灾害类别和 301 种特定事件类型。通过评估 30 个最先进 IR 模型，研究发现模型性能在不同任务间存在显著差异，且通用模型在灾害管理任务上表现欠佳，突出了专用基准在指导模型选择和提升决策支持方面的必要性。所有代码和数据集可从 https://github.com/KaiYin97/Disaster_IR 获取。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15856v1",
      "published_date": "2025-05-20 20:11:00 UTC",
      "updated_date": "2025-05-20 20:11:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:49:53.537201"
    },
    {
      "arxiv_id": "2505.14864v1",
      "title": "Balanced and Elastic End-to-end Training of Dynamic LLMs",
      "title_zh": "动态",
      "authors": [
        "Mohamed Wahib",
        "Muhammed Abdullah Soyturk",
        "Didem Unat"
      ],
      "abstract": "To reduce computational and memory costs in Large Language Models (LLMs),\ndynamic workload reduction schemes like Mixture of Experts (MoEs), parameter\npruning, layer freezing, sparse attention, early token exit, and Mixture of\nDepths (MoDs) have emerged. However, these methods introduce severe workload\nimbalances, limiting their practicality for large-scale distributed training.\nWe propose DynMo, an autonomous dynamic load balancing solution that ensures\noptimal compute distribution when using pipeline parallelism in training\ndynamic models. DynMo adaptively balances workloads, dynamically packs tasks\ninto fewer workers to free idle resources, and supports both multi-GPU\nsingle-node and multi-node systems. Compared to static training methods\n(Megatron-LM, DeepSpeed), DynMo accelerates training by up to 1.23x (MoEs),\n3.18x (pruning), 2.23x (layer freezing), 4.02x (sparse attention), 4.52x (early\nexit), and 1.17x (MoDs). DynMo is available at\nhttps://anonymous.4open.science/r/DynMo-4D04/.",
      "tldr_zh": "这篇论文针对Large Language Models (LLMs) 的动态训练中存在的严重工作负载不平衡问题（如Mixture of Experts (MoEs)、参数修剪、层冻结等），提出了一种自主动态负载平衡解决方案DynMo。DynMo通过自适应平衡工作负载、动态打包任务到更少的worker，并支持pipeline parallelism的多GPU单节点或多节点系统，确保了最佳计算分布。与静态训练方法如Megatron-LM和DeepSpeed相比，DynMo在各种动态方案上实现了显著加速，包括MoEs高达1.23倍、参数修剪3.18倍、层冻结2.23倍、稀疏注意力4.02倍、早期token退出4.52倍和Mixture of Depths (MoDs)1.17倍。该框架开源可用，可提升大规模分布式训练的实用性。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14864v1",
      "published_date": "2025-05-20 19:52:57 UTC",
      "updated_date": "2025-05-20 19:52:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:50:05.834121"
    },
    {
      "arxiv_id": "2505.14862v1",
      "title": "Replay Attacks Against Audio Deepfake Detection",
      "title_zh": "针对音频深度伪造检测的重放攻击",
      "authors": [
        "Nicolas Müller",
        "Piotr Kawa",
        "Wei-Herng Choong",
        "Adriana Stan",
        "Aditya Tirumala Bukkapatnam",
        "Karla Pizzi",
        "Alexander Wagner",
        "Philip Sperl"
      ],
      "abstract": "We show how replay attacks undermine audio deepfake detection: By playing and\nre-recording deepfake audio through various speakers and microphones, we make\nspoofed samples appear authentic to the detection model. To study this\nphenomenon in more detail, we introduce ReplayDF, a dataset of recordings\nderived from M-AILABS and MLAAD, featuring 109 speaker-microphone combinations\nacross six languages and four TTS models. It includes diverse acoustic\nconditions, some highly challenging for detection. Our analysis of six\nopen-source detection models across five datasets reveals significant\nvulnerability, with the top-performing W2V2-AASIST model's Equal Error Rate\n(EER) surging from 4.7% to 18.2%. Even with adaptive Room Impulse Response\n(RIR) retraining, performance remains compromised with an 11.0% EER. We release\nReplayDF for non-commercial research use.",
      "tldr_zh": "本文研究了重放攻击(replay attacks)对音频深度伪造检测(audio deepfake detection)的威胁，通过播放和重新录制伪造音频，使检测模型将欺骗样本误判为真实音频。研究者引入了ReplayDF数据集，基于M-AILABS和MLAAD，包含109种扬声器-麦克风组合、六种语言和四种TTS模型，以模拟多样声学条件。实验分析六种开源检测模型在五个数据集上的表现，发现顶级模型W2V2-AASIST的Equal Error Rate (EER)从4.7%上升到18.2%，即使进行自适应Room Impulse Response (RIR)重新训练，EER仍为11.0%。ReplayDF数据集已发布供非商业研究使用，以推动相关领域改进。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14862v1",
      "published_date": "2025-05-20 19:46:36 UTC",
      "updated_date": "2025-05-20 19:46:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:50:18.764386"
    },
    {
      "arxiv_id": "2505.14852v1",
      "title": "EasyMath: A 0-shot Math Benchmark for SLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Drishya Karki",
        "Michiel Kamphuis",
        "Angelecia Frey"
      ],
      "abstract": "EasyMath is a compact benchmark for practical math reasoning in small\nlanguage models. It covers thirteen categories, from basic arithmetic and order\nof operations to word problems, algebraic expressions, edge cases, and omits\nspecialist topics. We tested 23 models (14M to 4B parameters) using exact,\nnumerical, and symbolic checks on free-form answers in a zero-shot setting.\nAccuracy rises with size and training, chain-of-thought adds modest gains, and\nconsistency improves at scale.",
      "tldr_zh": "这篇论文介绍了 EasyMath，一个紧凑的零样本（zero-shot）基准，用于评估小型语言模型（SLMs）的实际数学推理能力。EasyMath 涵盖十三类主题，包括基本算术、运算顺序、文字问题、代数表达式和边界情况，但不涉及专业主题。研究者测试了 23 个模型（参数从 14M 到 4B），使用精确、数值和符号检查，发现准确率随模型规模和训练程度增加而提升，chain-of-thought 方法带来适度收益，一致性在更大规模模型上显著改善。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.6; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 9 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.14852v1",
      "published_date": "2025-05-20 19:31:52 UTC",
      "updated_date": "2025-05-20 19:31:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:50:29.446071"
    },
    {
      "arxiv_id": "2505.14838v1",
      "title": "In-depth Research Impact Summarization through Fine-Grained Temporal Citation Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Hiba Arnaout",
        "Noy Sternlicht",
        "Tom Hope",
        "Iryna Gurevych"
      ],
      "abstract": "Understanding the impact of scientific publications is crucial for\nidentifying breakthroughs and guiding future research. Traditional metrics\nbased on citation counts often miss the nuanced ways a paper contributes to its\nfield. In this work, we propose a new task: generating nuanced, expressive, and\ntime-aware impact summaries that capture both praise (confirmation citations)\nand critique (correction citations) through the evolution of fine-grained\ncitation intents. We introduce an evaluation framework tailored to this task,\nshowing moderate to strong human correlation on subjective metrics such as\ninsightfulness. Expert feedback from professors reveals a strong interest in\nthese summaries and suggests future improvements.",
      "tldr_zh": "该研究强调，传统基于引用次数的指标无法捕捉科学论文的影响细微之处，因此提出一个新任务：通过细粒度时间引用分析（fine-grained temporal citation analysis）生成细致、表达性强且时间感知的影响总结，这些总结能捕捉确认引用（confirmation citations）和修正引用（correction citations）的演变。论文引入了一个专属评估框架，在主观指标如洞察力上显示出中等到强的与人类相关性。专家反馈显示，教授们对这些总结表现出强烈兴趣，并建议进一步改进以指导未来研究。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14838v1",
      "published_date": "2025-05-20 19:11:06 UTC",
      "updated_date": "2025-05-20 19:11:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:50:41.351939"
    },
    {
      "arxiv_id": "2505.14827v1",
      "title": "Text Generation Beyond Discrete Token Sampling",
      "title_zh": "超越离散标记采样的文本生成",
      "authors": [
        "Yufan Zhuang",
        "Liyuan Liu",
        "Chandan Singh",
        "Jingbo Shang",
        "Jianfeng Gao"
      ],
      "abstract": "In standard autoregressive generation, an LLM predicts the next-token\ndistribution, samples a discrete token, and then discards the distribution,\npassing only the sampled token as new input. To preserve this distribution's\nrich information, we propose Mixture of Inputs (MoI), a training-free method\nfor autoregressive generation. After generating a token following the standard\nparadigm, we construct a new input that blends the generated discrete token\nwith the previously discarded token distribution. Specifically, we employ a\nBayesian estimation method that treats the token distribution as the prior, the\nsampled token as the observation, and replaces the conventional one-hot vector\nwith the continuous posterior expectation as the new model input. MoI allows\nthe model to maintain a richer internal representation throughout the\ngeneration process, resulting in improved text quality and reasoning\ncapabilities. On mathematical reasoning, code generation, and PhD-level QA\ntasks, MoI consistently improves performance across multiple models including\nQwQ-32B, Nemotron-Super-49B, Gemma-3-27B, and DAPO-Qwen-32B, with no additional\ntraining and negligible computational overhead.",
      "tldr_zh": "该论文提出 Mixture of Inputs (MoI)，一种无需额外训练的 autoregressive generation 方法，以解决标准文本生成中丢弃 token 分布信息的问题。MoI 通过 Bayesian estimation 将生成的离散 token 与 token 分布混合，构建新输入以替换传统的 one-hot vector，从而保持更丰富的内部表示，提升文本质量和推理能力。在数学推理、代码生成和 PhD-level QA 任务上，MoI 在多个模型（如 QwQ-32B 和 Gemma-3-27B）上实现了显著性能提升，同时计算开销微不足道。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14827v1",
      "published_date": "2025-05-20 18:41:46 UTC",
      "updated_date": "2025-05-20 18:41:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:50:53.871061"
    },
    {
      "arxiv_id": "2505.14821v1",
      "title": "Sample and Computationally Efficient Continuous-Time Reinforcement Learning with General Function Approximation",
      "title_zh": "翻译失败",
      "authors": [
        "Runze Zhao",
        "Yue Yu",
        "Adams Yiyue Zhu",
        "Chen Yang",
        "Dongruo Zhou"
      ],
      "abstract": "Continuous-time reinforcement learning (CTRL) provides a principled framework\nfor sequential decision-making in environments where interactions evolve\ncontinuously over time. Despite its empirical success, the theoretical\nunderstanding of CTRL remains limited, especially in settings with general\nfunction approximation. In this work, we propose a model-based CTRL algorithm\nthat achieves both sample and computational efficiency. Our approach leverages\noptimism-based confidence sets to establish the first sample complexity\nguarantee for CTRL with general function approximation, showing that a\nnear-optimal policy can be learned with a suboptimality gap of\n$\\tilde{O}(\\sqrt{d_{\\mathcal{R}} + d_{\\mathcal{F}}}N^{-1/2})$ using $N$\nmeasurements, where $d_{\\mathcal{R}}$ and $d_{\\mathcal{F}}$ denote the\ndistributional Eluder dimensions of the reward and dynamic functions,\nrespectively, capturing the complexity of general function approximation in\nreinforcement learning. Moreover, we introduce structured policy updates and an\nalternative measurement strategy that significantly reduce the number of policy\nupdates and rollouts while maintaining competitive sample efficiency. We\nimplemented experiments to backup our proposed algorithms on continuous control\ntasks and diffusion model fine-tuning, demonstrating comparable performance\nwith significantly fewer policy updates and rollouts.",
      "tldr_zh": "本研究针对连续时间强化学习（Continuous-Time Reinforcement Learning, CTRL）提出了一种高效算法，该算法在一般函数逼近（General Function Approximation）设置下实现了样本和计算效率的优化。算法利用乐观主义-based信心集（optimism-based confidence sets）建立了CTRL的首个样本复杂度保证，表明使用N次测量即可获得次优差距为\\(\\tilde{O}(\\sqrt{d_{\\mathcal{R}} + d_{\\mathcal{F}}}N^{-1/2})\\)的近似最优策略，其中\\(d_{\\mathcal{R}}\\)和\\(d_{\\mathcal{F}}\\)分别表示奖励和动态函数的分布Eluder维度。论文还引入结构化策略更新和替代测量策略，显著减少策略更新和回合数，同时保持高效性能；实验在连续控制任务和扩散模型微调上验证了算法的有效性，展示了与基线相当的表现但资源消耗更低。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 4 figures, 5 tables. Accepted to UAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.14821v1",
      "published_date": "2025-05-20 18:37:51 UTC",
      "updated_date": "2025-05-20 18:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:51:05.771256"
    },
    {
      "arxiv_id": "2505.14820v1",
      "title": "Imitation Learning via Focused Satisficing",
      "title_zh": "翻译失败",
      "authors": [
        "Rushit N. Shah",
        "Nikolaos Agadakos",
        "Synthia Sasulski",
        "Ali Farajzadeh",
        "Sanjiban Choudhury",
        "Brian Ziebart"
      ],
      "abstract": "Imitation learning often assumes that demonstrations are close to optimal\naccording to some fixed, but unknown, cost function. However, according to\nsatisficing theory, humans often choose acceptable behavior based on their\npersonal (and potentially dynamic) levels of aspiration, rather than achieving\n(near-) optimality. For example, a lunar lander demonstration that successfully\nlands without crashing might be acceptable to a novice despite being slow or\njerky. Using a margin-based objective to guide deep reinforcement learning, our\nfocused satisficing approach to imitation learning seeks a policy that\nsurpasses the demonstrator's aspiration levels -- defined over trajectories or\nportions of trajectories -- on unseen demonstrations without explicitly\nlearning those aspirations. We show experimentally that this focuses the policy\nto imitate the highest quality (portions of) demonstrations better than\nexisting imitation learning methods, providing much higher rates of guaranteed\nacceptability to the demonstrator, and competitive true returns on a range of\nenvironments.",
      "tldr_zh": "该论文提出了一种名为“Focused Satisficing”的模仿学习方法，针对传统方法假设演示行为接近最优的局限性，考虑到人类往往基于动态的“aspiration levels”（期望水平）选择可接受行为，而不是追求最优。方法使用“margin-based objective”指导深度强化学习（Deep Reinforcement Learning），旨在训练策略在未见演示上超越演示者的期望水平，而无需显式学习这些水平。实验结果显示，该方法比现有模仿学习技术更有效地模仿最高质量的演示部分，提供更高的可接受性保证，并在多种环境中实现竞争性的真实回报。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication at the 34th International Joint Conference\n  on Artificial Intelligence (IJCAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.14820v1",
      "published_date": "2025-05-20 18:36:52 UTC",
      "updated_date": "2025-05-20 18:36:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:51:17.062008"
    },
    {
      "arxiv_id": "2505.14818v1",
      "title": "WebNovelBench: Placing LLM Novelists on the Web Novel Distribution",
      "title_zh": "翻译失败",
      "authors": [
        "Leon Lin",
        "Jun Zheng",
        "Haidong Wang"
      ],
      "abstract": "Robustly evaluating the long-form storytelling capabilities of Large Language\nModels (LLMs) remains a significant challenge, as existing benchmarks often\nlack the necessary scale, diversity, or objective measures. To address this, we\nintroduce WebNovelBench, a novel benchmark specifically designed for evaluating\nlong-form novel generation. WebNovelBench leverages a large-scale dataset of\nover 4,000 Chinese web novels, framing evaluation as a synopsis-to-story\ngeneration task. We propose a multi-faceted framework encompassing eight\nnarrative quality dimensions, assessed automatically via an LLM-as-Judge\napproach. Scores are aggregated using Principal Component Analysis and mapped\nto a percentile rank against human-authored works. Our experiments demonstrate\nthat WebNovelBench effectively differentiates between human-written\nmasterpieces, popular web novels, and LLM-generated content. We provide a\ncomprehensive analysis of 24 state-of-the-art LLMs, ranking their storytelling\nabilities and offering insights for future development. This benchmark provides\na scalable, replicable, and data-driven methodology for assessing and advancing\nLLM-driven narrative generation.",
      "tldr_zh": "本研究引入了 WebNovelBench，这是一个专为评估大型语言模型 (LLMs) 长篇小说生成能力的基准，使用超过 4,000 个中文网络小说的数据集，将任务设定为从梗概到故事的生成。框架涵盖八个叙事质量维度，通过 LLM-as-Judge 方法进行自动评估，并利用 Principal Component Analysis (PCA) 聚合分数并映射到人类作品的百分位排名。实验结果显示，该基准能有效区分人类杰作、流行网络小说和 LLM 生成内容，并对 24 个最先进 LLMs 的叙事能力进行了全面排名和分析。该方法为 LLM 驱动的叙事生成提供了可扩展、可复制的数据驱动评估途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14818v1",
      "published_date": "2025-05-20 18:32:28 UTC",
      "updated_date": "2025-05-20 18:32:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:51:30.854803"
    },
    {
      "arxiv_id": "2505.14810v1",
      "title": "Scaling Reasoning, Losing Control: Evaluating Instruction Following in Large Reasoning Models",
      "title_zh": "扩展推理，失去控制：评估大型推理模型中的指令遵循",
      "authors": [
        "Tingchen Fu",
        "Jiawei Gu",
        "Yafu Li",
        "Xiaoye Qu",
        "Yu Cheng"
      ],
      "abstract": "Instruction-following is essential for aligning large language models (LLMs)\nwith user intent. While recent reasoning-oriented models exhibit impressive\nperformance on complex mathematical problems, their ability to adhere to\nnatural language instructions remains underexplored. In this work, we introduce\nMathIF, a dedicated benchmark for evaluating instruction-following in\nmathematical reasoning tasks. Our empirical analysis reveals a consistent\ntension between scaling up reasoning capacity and maintaining controllability,\nas models that reason more effectively often struggle to comply with user\ndirectives. We find that models tuned on distilled long chains-of-thought or\ntrained with reasoning-oriented reinforcement learning often degrade in\ninstruction adherence, especially when generation length increases.\nFurthermore, we show that even simple interventions can partially recover\nobedience, though at the cost of reasoning performance. These findings\nhighlight a fundamental tension in current LLM training paradigms and motivate\nthe need for more instruction-aware reasoning models. We release the code and\ndata at https://github.com/TingchenFu/MathIF.",
      "tldr_zh": "这篇论文引入了 MathIF 基准，用于评估大型语言模型（LLMs）在数学推理任务中对自然语言指令遵循的能力。研究发现，随着模型推理能力的扩展，其指令遵守性往往下降，特别是那些使用精炼的长链式思维（chains-of-thought）或推理导向强化学习训练的模型，尤其在生成长度增加时。实验结果显示，即使简单的干预措施能部分恢复指令遵循，但会以牺牲推理性能为代价。这些发现突显了当前 LLM 训练范式中的根本张力，并推动开发更注重指令的推理模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14810v1",
      "published_date": "2025-05-20 18:18:01 UTC",
      "updated_date": "2025-05-20 18:18:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:51:42.138790"
    },
    {
      "arxiv_id": "2505.14803v1",
      "title": "SurvUnc: A Meta-Model Based Uncertainty Quantification Framework for Survival Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Liu",
        "Weiyao Tao",
        "Tong Xia",
        "Simon Knight",
        "Tingting Zhu"
      ],
      "abstract": "Survival analysis, which estimates the probability of event occurrence over\ntime from censored data, is fundamental in numerous real-world applications,\nparticularly in high-stakes domains such as healthcare and risk assessment.\nDespite advances in numerous survival models, quantifying the uncertainty of\npredictions from these models remains underexplored and challenging. The lack\nof reliable uncertainty quantification limits the interpretability and\ntrustworthiness of survival models, hindering their adoption in clinical\ndecision-making and other sensitive applications. To bridge this gap, in this\nwork, we introduce SurvUnc, a novel meta-model based framework for post-hoc\nuncertainty quantification for survival models. SurvUnc introduces an\nanchor-based learning strategy that integrates concordance knowledge into\nmeta-model optimization, leveraging pairwise ranking performance to estimate\nuncertainty effectively. Notably, our framework is model-agnostic, ensuring\ncompatibility with any survival model without requiring modifications to its\narchitecture or access to its internal parameters. Especially, we design a\ncomprehensive evaluation pipeline tailored to this critical yet overlooked\nproblem. Through extensive experiments on four publicly available benchmarking\ndatasets and five representative survival models, we demonstrate the\nsuperiority of SurvUnc across multiple evaluation scenarios, including\nselective prediction, misprediction detection, and out-of-domain detection. Our\nresults highlight the effectiveness of SurvUnc in enhancing model\ninterpretability and reliability, paving the way for more trustworthy survival\npredictions in real-world applications.",
      "tldr_zh": "本研究针对生存分析（Survival Analysis）中预测不确定性量化的不足，提出了一种新型后验框架 SurvUnc，该框架基于元模型（meta-model），通过 anchor-based 学习策略整合 concordance 知识和 pairwise ranking 性能来有效估计不确定性。SurvUnc 设计为模型无关（model-agnostic），无需修改原生存模型的架构或参数，从而适用于各种场景。在四个公开数据集和五个代表性生存模型上的实验中，SurvUnc 在选择性预测、错误预测检测和域外检测等方面表现出色，提升了模型的可解释性和可靠性，为医疗等高风险领域的实际应用提供了更可信的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "KDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.14803v1",
      "published_date": "2025-05-20 18:12:20 UTC",
      "updated_date": "2025-05-20 18:12:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:51:53.844846"
    },
    {
      "arxiv_id": "2505.14777v1",
      "title": "KO: Kinetics-inspired Neural Optimizer with PDE Simulation Approaches",
      "title_zh": "翻译失败",
      "authors": [
        "Mingquan Feng",
        "Yixin Huang",
        "Yifan Fu",
        "Shaobo Wang",
        "Junchi Yan"
      ],
      "abstract": "The design of optimization algorithms for neural networks remains a critical\nchallenge, with most existing methods relying on heuristic adaptations of\ngradient-based approaches. This paper introduces KO (Kinetics-inspired\nOptimizer), a novel neural optimizer inspired by kinetic theory and partial\ndifferential equation (PDE) simulations. We reimagine the training dynamics of\nnetwork parameters as the evolution of a particle system governed by kinetic\nprinciples, where parameter updates are simulated via a numerical scheme for\nthe Boltzmann transport equation (BTE) that models stochastic particle\ncollisions. This physics-driven approach inherently promotes parameter\ndiversity during optimization, mitigating the phenomenon of parameter\ncondensation, i.e. collapse of network parameters into low-dimensional\nsubspaces, through mechanisms analogous to thermal diffusion in physical\nsystems. We analyze this property, establishing both a mathematical proof and a\nphysical interpretation. Extensive experiments on image classification\n(CIFAR-10/100, ImageNet) and text classification (IMDB, Snips) tasks\ndemonstrate that KO consistently outperforms baseline optimizers (e.g., Adam,\nSGD), achieving accuracy improvements while computation cost remains\ncomparable.",
      "tldr_zh": "这篇论文提出了一种新型神经网络优化器 KO，受动力学理论和偏微分方程（PDE）模拟启发，将网络参数训练视为粒子系统的演化，通过 Boltzmann 传输方程（BTE）的数值方案模拟参数更新，以促进参数多样性和缓解参数凝结问题。作者提供了数学证明和物理解释，展示了 KO 如何通过模拟粒子碰撞机制来提升优化过程。实验结果表明，KO 在图像分类（如 CIFAR-10/100 和 ImageNet）和文本分类（如 IMDB 和 Snips）任务上，相比 Adam 和 SGD 等基线优化器实现了准确率提升，同时保持了相似的计算成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14777v1",
      "published_date": "2025-05-20 18:00:01 UTC",
      "updated_date": "2025-05-20 18:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:52:05.780067"
    },
    {
      "arxiv_id": "2505.14684v2",
      "title": "Mind the Gap: Bridging Thought Leap for Improved Chain-of-Thought Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Haolei Xu",
        "Yuchen Yan",
        "Yongliang Shen",
        "Wenqi Zhang",
        "Guiyang Hou",
        "Shengpei Jiang",
        "Kaitao Song",
        "Weiming Lu",
        "Jun Xiao",
        "Yueting Zhuang"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable progress on\nmathematical tasks through Chain-of-Thought (CoT) reasoning. However, existing\nmathematical CoT datasets often suffer from Thought Leaps due to experts\nomitting intermediate steps, which negatively impacts model learning and\ngeneralization. We propose the CoT Thought Leap Bridge Task, which aims to\nautomatically detect leaps and generate missing intermediate reasoning steps to\nrestore the completeness and coherence of CoT. To facilitate this, we\nconstructed a specialized training dataset called ScaleQM+, based on the\nstructured ScaleQuestMath dataset, and trained CoT-Bridge to bridge thought\nleaps. Through comprehensive experiments on mathematical reasoning benchmarks,\nwe demonstrate that models fine-tuned on bridged datasets consistently\noutperform those trained on original datasets, with improvements of up to\n+5.87% on NuminaMath. Our approach effectively enhances distilled data (+3.02%)\nand provides better starting points for reinforcement learning (+3.1%),\nfunctioning as a plug-and-play module compatible with existing optimization\ntechniques. Furthermore, CoT-Bridge demonstrate improved generalization to\nout-of-domain logical reasoning tasks, confirming that enhancing reasoning\ncompleteness yields broadly applicable benefits.",
      "tldr_zh": "本研究针对现有 Chain-of-Thought (CoT) 数据集中的 Thought Leaps（思维跳跃）问题，提出 CoT Thought Leap Bridge Task，该任务可自动检测跳跃并生成缺失的中间推理步骤，以提升 CoT 的完整性和连贯性。研究者构建了基于 ScaleQuestMath 的专用数据集 ScaleQM+，并训练了 CoT-Bridge 模型来桥接这些跳跃。实验结果显示，在数学推理基准如 NuminaMath 上，使用桥接后数据集微调的模型性能提升高达 5.87%，并在数据蒸馏（+3.02%）和强化学习（+3.1%）等方面表现出色，同时增强了模型对域外逻辑推理任务的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Project: https://zju-real.github.io/CoT-Bridge/",
      "pdf_url": "http://arxiv.org/pdf/2505.14684v2",
      "published_date": "2025-05-20 17:59:31 UTC",
      "updated_date": "2025-05-21 17:02:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:52:18.509426"
    },
    {
      "arxiv_id": "2505.14681v1",
      "title": "Two Experts Are All You Need for Steering Thinking: Reinforcing Cognitive Effort in MoE Reasoning Models Without Additional Training",
      "title_zh": "两个专家",
      "authors": [
        "Mengru Wang",
        "Xingyu Chen",
        "Yue Wang",
        "Zhiwei He",
        "Jiahao Xu",
        "Tian Liang",
        "Qiuzhi Liu",
        "Yunzhi Yao",
        "Wenxuan Wang",
        "Ruotian Ma",
        "Haitao Mi",
        "Ningyu Zhang",
        "Zhaopeng Tu",
        "Xiaolong Li",
        "Dong Yu"
      ],
      "abstract": "Mixture-of-Experts (MoE) architectures within Large Reasoning Models (LRMs)\nhave achieved impressive reasoning capabilities by selectively activating\nexperts to facilitate structured cognitive processes. Despite notable advances,\nexisting reasoning models often suffer from cognitive inefficiencies like\noverthinking and underthinking. To address these limitations, we introduce a\nnovel inference-time steering methodology called Reinforcing Cognitive Experts\n(RICE), designed to improve reasoning performance without additional training\nor complex heuristics. Leveraging normalized Pointwise Mutual Information\n(nPMI), we systematically identify specialized experts, termed ''cognitive\nexperts'' that orchestrate meta-level reasoning operations characterized by\ntokens like ''<think>''. Empirical evaluations with leading MoE-based LRMs\n(DeepSeek-R1 and Qwen3-235B) on rigorous quantitative and scientific reasoning\nbenchmarks demonstrate noticeable and consistent improvements in reasoning\naccuracy, cognitive efficiency, and cross-domain generalization. Crucially, our\nlightweight approach substantially outperforms prevalent reasoning-steering\ntechniques, such as prompt design and decoding constraints, while preserving\nthe model's general instruction-following skills. These results highlight\nreinforcing cognitive experts as a promising, practical, and interpretable\ndirection to enhance cognitive efficiency within advanced reasoning models.",
      "tldr_zh": "本文提出Reinforcing Cognitive Experts (RICE)方法，用于提升Mixture-of-Experts (MoE)架构在Large Reasoning Models (LRMs)中的推理性能，针对overthinking和underthinking等认知效率问题，而无需额外训练或复杂启发式。RICE通过normalized Pointwise Mutual Information (nPMI)识别并强化“cognitive experts”，这些专家负责处理元级推理操作（如“<think>”标记）。在DeepSeek-R1和Qwen3-235B模型上的实验显示，RICE显著提高了推理准确性、认知效率和跨域泛化能力，并优于prompt design和decoding constraints等技术，同时保留了模型的通用指令遵循技能。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2505.14681v1",
      "published_date": "2025-05-20 17:59:16 UTC",
      "updated_date": "2025-05-20 17:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:52:30.438750"
    },
    {
      "arxiv_id": "2505.14680v1",
      "title": "NExT-Search: Rebuilding User Feedback Ecosystem for Generative AI Search",
      "title_zh": "NExT-Search：为生成式 AI 搜索重建用户反馈生态系统",
      "authors": [
        "Sunhao Dai",
        "Wenjie Wang",
        "Liang Pang",
        "Jun Xu",
        "See-Kiong Ng",
        "Ji-Rong Wen",
        "Tat-Seng Chua"
      ],
      "abstract": "Generative AI search is reshaping information retrieval by offering\nend-to-end answers to complex queries, reducing users' reliance on manually\nbrowsing and summarizing multiple web pages. However, while this paradigm\nenhances convenience, it disrupts the feedback-driven improvement loop that has\nhistorically powered the evolution of traditional Web search. Web search can\ncontinuously improve their ranking models by collecting large-scale,\nfine-grained user feedback (e.g., clicks, dwell time) at the document level. In\ncontrast, generative AI search operates through a much longer search pipeline,\nspanning query decomposition, document retrieval, and answer generation, yet\ntypically receives only coarse-grained feedback on the final answer. This\nintroduces a feedback loop disconnect, where user feedback for the final output\ncannot be effectively mapped back to specific system components, making it\ndifficult to improve each intermediate stage and sustain the feedback loop. In\nthis paper, we envision NExT-Search, a next-generation paradigm designed to\nreintroduce fine-grained, process-level feedback into generative AI search.\nNExT-Search integrates two complementary modes: User Debug Mode, which allows\nengaged users to intervene at key stages; and Shadow User Mode, where a\npersonalized user agent simulates user preferences and provides AI-assisted\nfeedback for less interactive users. Furthermore, we envision how these\nfeedback signals can be leveraged through online adaptation, which refines\ncurrent search outputs in real-time, and offline update, which aggregates\ninteraction logs to periodically fine-tune query decomposition, retrieval, and\ngeneration models. By restoring human control over key stages of the generative\nAI search pipeline, we believe NExT-Search offers a promising direction for\nbuilding feedback-rich AI search systems that can evolve continuously alongside\nhuman feedback.",
      "tldr_zh": "该论文分析了生成式 AI 搜索虽提供端到端答案提升便利性，却因仅收集粗粒度反馈而破坏了传统 Web 搜索的反馈驱动改进循环，导致难以优化查询分解、文档检索和答案生成等中间阶段。  \n为解决这一问题，作者提出 NExT-Search 范式，通过 User Debug Mode 允许用户在关键阶段干预，以及 Shadow User Mode 使用个性化用户代理模拟偏好提供 AI 辅助反馈，实现细粒度、过程级反馈。  \n这些反馈信号可通过在线适应实时优化搜索输出，以及离线更新聚合交互日志来微调相关模型，从而重建反馈生态，促进生成式 AI 搜索系统持续演化并增强人类控制。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.IR",
      "comment": "SIGIR 2025 Perspective Paper",
      "pdf_url": "http://arxiv.org/pdf/2505.14680v1",
      "published_date": "2025-05-20 17:59:13 UTC",
      "updated_date": "2025-05-20 17:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:52:41.549111"
    },
    {
      "arxiv_id": "2505.14679v1",
      "title": "UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaojie Gu",
        "Guangxu Chen",
        "Jungang Li",
        "Jia-Chen Gu",
        "Xuming Hu",
        "Kai Zhang"
      ],
      "abstract": "Lifelong learning enables large language models (LLMs) to adapt to evolving\ninformation by continually updating their internal knowledge. An ideal system\nshould support efficient, wide-ranging updates while preserving existing\ncapabilities and ensuring reliable deployment. Model editing stands out as a\npromising solution for this goal, offering a focused and efficient way to\nrevise a model's internal knowledge. Although recent paradigms have made\nnotable progress, they often struggle to meet the demands of practical lifelong\nadaptation at scale. To bridge this gap, we propose ULTRAEDIT-a fundamentally\nnew editing solution that is training-, subject- and memory-free, making it\nparticularly well-suited for ultra-scalable, real-world lifelong model editing.\nULTRAEDIT performs editing through a self-contained process that relies solely\non lightweight linear algebra operations to compute parameter shifts, enabling\nfast and consistent parameter modifications with minimal overhead. To improve\nscalability in lifelong settings, ULTRAEDIT employs a lifelong normalization\nstrategy that continuously updates feature statistics across turns, allowing it\nto adapt to distributional shifts and maintain consistency over time. ULTRAEDIT\nachieves editing speeds over 7x faster than the previous state-of-the-art\nmethod-which was also the fastest known approach-while consuming less than 1/3\nthe VRAM, making it the only method currently capable of editing a 7B LLM on a\n24GB consumer-grade GPU. Furthermore, we construct ULTRAEDITBENCH-the largest\ndataset in the field to date, with over 2M editing pairs-and demonstrate that\nour method supports up to 1M edits while maintaining high accuracy.\nComprehensive experiments on four datasets and six models show that ULTRAEDIT\nconsistently achieves superior performance across diverse model editing\nscenarios. Our code is available at: https://github.com/XiaojieGu/UltraEdit.",
      "tldr_zh": "该论文提出UltraEdit，一种无需训练、主题或内存的终身编辑框架，用于Large Language Models (LLMs)，旨在通过轻量级线性代数操作计算参数调整和终身归一化策略来高效更新模型知识，同时适应分布偏移。UltraEdit的编辑速度比现有最先进方法快7倍以上，且VRAM消耗不到三分之一，使其能够在24GB消费级GPU上编辑7B LLM。实验在ULTRAEDITBENCH数据集（超过2M编辑对）上验证，该方法支持高达1M编辑并保持高准确性，在四个数据集和六种模型中均表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14679v1",
      "published_date": "2025-05-20 17:59:04 UTC",
      "updated_date": "2025-05-20 17:59:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:52:53.070948"
    },
    {
      "arxiv_id": "2505.14673v1",
      "title": "Training-Free Watermarking for Autoregressive Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Tong",
        "Zihao Pan",
        "Shuai Yang",
        "Kaiyang Zhou"
      ],
      "abstract": "Invisible image watermarking can protect image ownership and prevent\nmalicious misuse of visual generative models. However, existing generative\nwatermarking methods are mainly designed for diffusion models while\nwatermarking for autoregressive image generation models remains largely\nunderexplored. We propose IndexMark, a training-free watermarking framework for\nautoregressive image generation models. IndexMark is inspired by the redundancy\nproperty of the codebook: replacing autoregressively generated indices with\nsimilar indices produces negligible visual differences. The core component in\nIndexMark is a simple yet effective match-then-replace method, which carefully\nselects watermark tokens from the codebook based on token similarity, and\npromotes the use of watermark tokens through token replacement, thereby\nembedding the watermark without affecting the image quality. Watermark\nverification is achieved by calculating the proportion of watermark tokens in\ngenerated images, with precision further improved by an Index Encoder.\nFurthermore, we introduce an auxiliary validation scheme to enhance robustness\nagainst cropping attacks. Experiments demonstrate that IndexMark achieves\nstate-of-the-art performance in terms of image quality and verification\naccuracy, and exhibits robustness against various perturbations, including\ncropping, noises, Gaussian blur, random erasing, color jittering, and JPEG\ncompression.",
      "tldr_zh": "本文提出 IndexMark，一种无需训练的水印框架，针对自回归图像生成模型，用于保护图像所有权并防止恶意滥用。该框架利用 codebook 的冗余性，通过 match-then-replace 方法选择并替换相似索引来嵌入水印，确保生成图像的质量不受影响。水印验证通过计算水印标记比例并结合 Index Encoder 提升精度，同时引入辅助验证方案增强对裁剪攻击的鲁棒性。实验表明，IndexMark 在图像质量和验证准确性上达到最先进水平，并对噪声、高斯模糊、JPEG 压缩等扰动表现出色鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14673v1",
      "published_date": "2025-05-20 17:58:02 UTC",
      "updated_date": "2025-05-20 17:58:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:53:06.297119"
    },
    {
      "arxiv_id": "2505.14668v1",
      "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions",
      "title_zh": "翻译失败",
      "authors": [
        "Bufang Yang",
        "Lilin Xu",
        "Liekang Zeng",
        "Kaiwei Liu",
        "Siyang Jiang",
        "Wenrui Lu",
        "Hongkai Chen",
        "Xiaofan Jiang",
        "Guoliang Xing",
        "Zhenyu Yan"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have propelled intelligent\nagents from reactive responses to proactive support. While promising, existing\nproactive agents either rely exclusively on observations from enclosed\nenvironments (e.g., desktop UIs) with direct LLM inference or employ rule-based\nproactive notifications, leading to suboptimal user intent understanding and\nlimited functionality for proactive service. In this paper, we introduce\nContextAgent, the first context-aware proactive agent that incorporates\nextensive sensory contexts to enhance the proactive capabilities of LLM agents.\nContextAgent first extracts multi-dimensional contexts from massive sensory\nperceptions on wearables (e.g., video and audio) to understand user intentions.\nContextAgent then leverages the sensory contexts and the persona contexts from\nhistorical data to predict the necessity for proactive services. When proactive\nassistance is needed, ContextAgent further automatically calls the necessary\ntools to assist users unobtrusively. To evaluate this new task, we curate\nContextAgentBench, the first benchmark for evaluating context-aware proactive\nLLM agents, covering 1,000 samples across nine daily scenarios and twenty\ntools. Experiments on ContextAgentBench show that ContextAgent outperforms\nbaselines by achieving up to 8.5% and 6.0% higher accuracy in proactive\npredictions and tool calling, respectively. We hope our research can inspire\nthe development of more advanced, human-centric, proactive AI assistants.",
      "tldr_zh": "本研究提出ContextAgent，一种上下文感知的主动LLM Agents框架，利用开放世界的感官感知（如可穿戴设备的视频和音频）来提升代理的主动支持能力。ContextAgent首先从多维感官和历史数据中提取上下文，以准确预测用户意图并判断是否需要主动服务；当需要时，它会自动调用相关工具提供无干扰的协助。研究团队构建了ContextAgentBench基准，涵盖1000个样本的九个日常场景和二十个工具，用于评估此类代理。实验结果显示，ContextAgent在主动预测和工具调用准确率上分别比基线模型高出8.5%和6.0%，为开发更人性化的主动AI助手提供了新方向。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14668v1",
      "published_date": "2025-05-20 17:55:25 UTC",
      "updated_date": "2025-05-20 17:55:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:53:18.507401"
    },
    {
      "arxiv_id": "2505.14667v1",
      "title": "SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment",
      "title_zh": "SAFEPATH：通过早期对齐防止链式思维中的有害推理",
      "authors": [
        "Wonje Jeung",
        "Sangyeon Yoon",
        "Minsuk Kahng",
        "Albert No"
      ],
      "abstract": "Large Reasoning Models (LRMs) have become powerful tools for complex problem\nsolving, but their structured reasoning pathways can lead to unsafe outputs\nwhen exposed to harmful prompts. Existing safety alignment methods reduce\nharmful outputs but can degrade reasoning depth, leading to significant\ntrade-offs in complex, multi-step tasks, and remain vulnerable to sophisticated\njailbreak attacks. To address this, we introduce SAFEPATH, a lightweight\nalignment method that fine-tunes LRMs to emit a short, 8-token Safety Primer at\nthe start of their reasoning, in response to harmful prompts, while leaving the\nrest of the reasoning process unsupervised. Empirical results across multiple\nbenchmarks indicate that SAFEPATH effectively reduces harmful outputs while\nmaintaining reasoning performance. Specifically, SAFEPATH reduces harmful\nresponses by up to 90.0% and blocks 83.3% of jailbreak attempts in the\nDeepSeek-R1-Distill-Llama-8B model, while requiring 295.9x less compute than\nDirect Refusal and 314.1x less than SafeChain. We further introduce a zero-shot\nvariant that requires no fine-tuning. In addition, we provide a comprehensive\nanalysis of how existing methods in LLMs generalize, or fail, when applied to\nreasoning-centric models, revealing critical gaps and new directions for safer\nAI.",
      "tldr_zh": "该研究针对大型推理模型（LRMs）在链式思维（Chain-of-Thought）推理中面临的有害提示问题，提出了一种轻量级对齐方法SAFEPATH，以防止不安全输出。SAFEPATH通过在推理开始时输出一个简短的8-token Safety Primer来响应有害提示，同时不对其余推理过程进行监督，从而平衡了安全性和推理深度。实验结果显示，该方法在多个基准测试中减少有害响应高达90.0%，阻挡83.3%的越狱（jailbreak）攻击，且计算量比Direct Refusal少295.9倍，比SafeChain少314.1倍。此外，研究还引入了零样本变体无需微调，并分析了现有LLM方法在推理中心模型上的泛化问题，揭示了关键差距和新方向。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.14667v1",
      "published_date": "2025-05-20 17:54:54 UTC",
      "updated_date": "2025-05-20 17:54:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:53:30.641960"
    },
    {
      "arxiv_id": "2505.14664v1",
      "title": "AKRMap: Adaptive Kernel Regression for Trustworthy Visualization of Cross-Modal Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Yilin Ye",
        "Junchao Huang",
        "Xingchen Zeng",
        "Jiazhi Xia",
        "Wei Zeng"
      ],
      "abstract": "Cross-modal embeddings form the foundation for multi-modal models. However,\nvisualization methods for interpreting cross-modal embeddings have been\nprimarily confined to traditional dimensionality reduction (DR) techniques like\nPCA and t-SNE. These DR methods primarily focus on feature distributions within\na single modality, whilst failing to incorporate metrics (e.g., CLIPScore)\nacross multiple modalities.This paper introduces AKRMap, a new DR technique\ndesigned to visualize cross-modal embeddings metric with enhanced accuracy by\nlearning kernel regression of the metric landscape in the projection space.\nSpecifically, AKRMap constructs a supervised projection network guided by a\npost-projection kernel regression loss, and employs adaptive generalized\nkernels that can be jointly optimized with the projection. This approach\nenables AKRMap to efficiently generate visualizations that capture complex\nmetric distributions, while also supporting interactive features such as zoom\nand overlay for deeper exploration. Quantitative experiments demonstrate that\nAKRMap outperforms existing DR methods in generating more accurate and\ntrustworthy visualizations. We further showcase the effectiveness of AKRMap in\nvisualizing and comparing cross-modal embeddings for text-to-image models. Code\nand demo are available at https://github.com/yilinye/AKRMap.",
      "tldr_zh": "这篇论文引入了AKRMap，一种自适应核回归(Adaptive Kernel Regression)技术，用于更可靠地可视化跨模态嵌入(Cross-Modal Embeddings)，以解决传统降维方法如PCA和t-SNE忽略跨模态指标（如CLIPScore）的问题。AKRMap通过构建一个受监督的投影网络和可共同优化的自适应广义核，来学习投影空间中的核回归损失，从而生成捕捉复杂指标分布的交互式可视化，如缩放和叠加功能。实验结果显示，AKRMap在定量评估中优于现有降维方法，提供更准确和可信的嵌入可视化，并展示了其在文本到图像模型中的实际应用。代码和演示可从GitHub获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14664v1",
      "published_date": "2025-05-20 17:52:03 UTC",
      "updated_date": "2025-05-20 17:52:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:53:42.487741"
    },
    {
      "arxiv_id": "2505.14661v1",
      "title": "Abacus: A Cost-Based Optimizer for Semantic Operator Systems",
      "title_zh": "Abacus：基于成本的语义操作符系统优化器",
      "authors": [
        "Matthew Russo",
        "Sivaprasad Sudhir",
        "Gerardo Vitagliano",
        "Chunwei Liu",
        "Tim Kraska",
        "Samuel Madden",
        "Michael Cafarella"
      ],
      "abstract": "LLMs enable an exciting new class of data processing applications over large\ncollections of unstructured documents. Several new programming frameworks have\nenabled developers to build these applications by composing them out of\nsemantic operators: a declarative set of AI-powered data transformations with\nnatural language specifications. These include LLM-powered maps, filters,\njoins, etc. used for document processing tasks such as information extraction,\nsummarization, and more. While systems of semantic operators have achieved\nstrong performance on benchmarks, they can be difficult to optimize. An\noptimizer for this setting must determine how to physically implement each\nsemantic operator in a way that optimizes the system globally. Existing\noptimizers are limited in the number of optimizations they can apply, and most\n(if not all) cannot optimize system quality, cost, or latency subject to\nconstraint(s) on the other dimensions. In this paper we present Abacus, an\nextensible, cost-based optimizer which searches for the best implementation of\na semantic operator system given a (possibly constrained) optimization\nobjective. Abacus estimates operator performance by leveraging a minimal set of\nvalidation examples and, if available, prior beliefs about operator\nperformance. We evaluate Abacus on document processing workloads in the\nbiomedical and legal domains (BioDEX; CUAD) and multi-modal question answering\n(MMQA). We demonstrate that systems optimized by Abacus achieve 18.7%-39.2%\nbetter quality and up to 23.6x lower cost and 4.2x lower latency than the next\nbest system.",
      "tldr_zh": "该论文介绍了 Abacus，一种基于成本的优化器，针对 semantic operator systems，用于优化 LLMs 驱动的非结构化文档处理应用，这些应用通过 declarative 的 AI 增强转换（如 LLM-powered maps, filters, joins）来执行信息提取和总结等任务。Abacus 通过利用最小验证示例和先验性能知识，搜索全局最优实现方案，以平衡系统质量、成本和延迟。实验结果显示，在生物医学（BioDEX）、法律（CUAD）和多模态问答（MMQA）领域，Abacus 优化后的系统比最佳基线提高了 18.7%-39.2% 的质量，并实现了最高 23.6 倍成本降低和 4.2 倍延迟降低。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "H.2.4; I.2.5"
      ],
      "primary_category": "cs.DB",
      "comment": "16 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.14661v1",
      "published_date": "2025-05-20 17:49:46 UTC",
      "updated_date": "2025-05-20 17:49:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:53:53.880346"
    },
    {
      "arxiv_id": "2505.14766v1",
      "title": "This Time is Different: An Observability Perspective on Time Series Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ben Cohen",
        "Emaad Khwaja",
        "Youssef Doubli",
        "Salahidine Lemaachi",
        "Chris Lettieri",
        "Charles Masson",
        "Hugo Miccinilli",
        "Elise Ramé",
        "Qiqi Ren",
        "Afshin Rostamizadeh",
        "Jean Ogier du Terrail",
        "Anna-Monica Toon",
        "Kan Wang",
        "Stephan Xie",
        "David Asker",
        "Ameet Talwalkar",
        "Othmane Abou-Amal"
      ],
      "abstract": "We introduce Toto, a time series forecasting foundation model with 151\nmillion parameters. Toto uses a modern decoder-only architecture coupled with\narchitectural innovations designed to account for specific challenges found in\nmultivariate observability time series data. Toto's pre-training corpus is a\nmixture of observability data, open datasets, and synthetic data, and is\n4-10$\\times$ larger than those of leading time series foundation models.\nAdditionally, we introduce BOOM, a large-scale benchmark consisting of 350\nmillion observations across 2,807 real-world time series. For both Toto and\nBOOM, we source observability data exclusively from Datadog's own telemetry and\ninternal observability metrics. Extensive evaluations demonstrate that Toto\nachieves state-of-the-art performance on both BOOM and on established general\npurpose time series forecasting benchmarks. Toto's model weights, inference\ncode, and evaluation scripts, as well as BOOM's data and evaluation code, are\nall available as open source under the Apache 2.0 License available at\nhttps://huggingface.co/Datadog/Toto-Open-Base-1.0 and\nhttps://github.com/DataDog/toto.",
      "tldr_zh": "本研究从可观测性视角出发，引入了 Toto，一种拥有 1.51 亿参数的 time series foundation models，用于时间序列预测。Toto 采用现代 decoder-only 架构，并针对多变量 observability 数据中的特定挑战进行了创新，其预训练语料混合了 observability 数据、开源数据集和合成数据，比领先模型大 4-10 倍，同时提出了 BOOM 基准，包含 3.5 亿观察值和 2807 个真实世界时间序列。评估结果显示，Toto 在 BOOM 以及其他通用基准上实现了 state-of-the-art 性能，所有模型权重、代码和数据均以 Apache 2.0 许可证开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14766v1",
      "published_date": "2025-05-20 17:48:13 UTC",
      "updated_date": "2025-05-20 17:48:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:54:06.210140"
    },
    {
      "arxiv_id": "2505.14660v1",
      "title": "EmoGist: Efficient In-Context Learning for Visual Emotion Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Ronald Seoh",
        "Dan Goldwasser"
      ],
      "abstract": "In this paper, we introduce EmoGist, a training-free, in-context learning\nmethod for performing visual emotion classification with LVLMs. The key\nintuition of our approach is that context-dependent definition of emotion\nlabels could allow more accurate predictions of emotions, as the ways in which\nemotions manifest within images are highly context dependent and nuanced.\nEmoGist pre-generates multiple explanations of emotion labels, by analyzing the\nclusters of example images belonging to each category. At test time, we\nretrieve a version of explanation based on embedding similarity, and feed it to\na fast VLM for classification. Through our experiments, we show that EmoGist\nallows up to 13 points improvement in micro F1 scores with the multi-label\nMemotion dataset, and up to 8 points in macro F1 in the multi-class FI dataset.",
      "tldr_zh": "本研究引入 EmoGist，一种无需训练的 In-Context Learning 方法，用于提升视觉情感分类的准确性。EmoGist 通过分析每个情感类别的图像集群，预生成多个上下文依赖的标签解释，并在测试时基于嵌入相似性检索合适的解释，然后输入到快速 VLM 中进行分类。这种方法利用情感表现的细微性和上下文依赖性，显著提高了预测性能。实验结果显示，在多标签 Memotion 数据集上，微 F1 分数提升多达 13 点，而在多类 FI 数据集上，宏 F1 分数提升多达 8 点。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14660v1",
      "published_date": "2025-05-20 17:47:04 UTC",
      "updated_date": "2025-05-20 17:47:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:54:16.980482"
    },
    {
      "arxiv_id": "2505.14659v1",
      "title": "Explainable AI for Securing Healthcare in IoT-Integrated 6G Wireless Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Navneet Kaur",
        "Lav Gupta"
      ],
      "abstract": "As healthcare systems increasingly adopt advanced wireless networks and\nconnected devices, securing medical applications has become critical. The\nintegration of Internet of Medical Things devices, such as robotic surgical\ntools, intensive care systems, and wearable monitors has enhanced patient care\nbut introduced serious security risks. Cyberattacks on these devices can lead\nto life threatening consequences, including surgical errors, equipment failure,\nand data breaches. While the ITU IMT 2030 vision highlights 6G's transformative\nrole in healthcare through AI and cloud integration, it also raises new\nsecurity concerns. This paper explores how explainable AI techniques like SHAP,\nLIME, and DiCE can uncover vulnerabilities, strengthen defenses, and improve\ntrust and transparency in 6G enabled healthcare. We support our approach with\nexperimental analysis and highlight promising results.",
      "tldr_zh": "随着医疗系统越来越依赖 IoT 集成 6G 无线网络，可穿戴设备和机器人手术工具等设备提升了患者护理，但也带来了严重安全风险，如手术错误、设备故障和数据泄露。论文提出利用可解释 AI 技术，包括 SHAP、LIME 和 DiCE，来识别漏洞、加强防御，并提升系统信任与透明度。通过实验分析，研究展示了这些方法在 6G 医疗环境中的有效性，并为未来安全策略提供了有前景的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14659v1",
      "published_date": "2025-05-20 17:46:09 UTC",
      "updated_date": "2025-05-20 17:46:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:54:29.547522"
    },
    {
      "arxiv_id": "2505.14656v1",
      "title": "Cost-Augmented Monte Carlo Tree Search for LLM-Assisted Planning",
      "title_zh": "成本增强蒙特卡洛树搜索用于大语言模型辅助规划",
      "authors": [
        "Zihao Zhang",
        "Fei Liu"
      ],
      "abstract": "While LLMs excel at open-ended reasoning, they often struggle with\ncost-sensitive planning, either treating all actions as having equal cost or\nfailing to stay within strict budgets. In this paper, we introduce\nCost-Augmented Monte Carlo Tree Search (CATS), a novel approach that brings\nexplicit cost-awareness into LLM-guided planning. Tight cost constraints push\nthe planner to quickly identify infeasible solutions, while looser constraints\nencourage optimization for minimal cost. We benchmark top LLMs such as GPT-4.1,\nClaude-3.7-Sonnet, and DeepSeek-R1, against our CATS planner to evaluate their\nperformance in cost-sensitive scenarios. Our experiments suggest that raw LLMs\nsuch as GPT-4.1 often falter under tight budgets, whereas CATS consistently\ndelivers strong performance, achieving higher task success rates and better\ncost efficiency. CATS provides an effective solution for budget-aware\ndecision-making by combining the reasoning power of LLMs with structured\nsearch.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在成本敏感规划中的不足，如将所有动作视为等价或无法遵守严格预算，提出了一种新型方法Cost-Augmented Monte Carlo Tree Search (CATS)。CATS通过整合显式成本意识，将Monte Carlo Tree Search与LLMs的推理能力结合，在紧约束下快速识别不可行方案，在宽松约束下优化最小成本。实验对比了GPT-4.1、Claude-3.7-Sonnet和DeepSeek-R1等模型，结果显示CATS显著提升任务成功率和成本效率，为预算aware决策提供了有效的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14656v1",
      "published_date": "2025-05-20 17:43:33 UTC",
      "updated_date": "2025-05-20 17:43:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:54:41.937941"
    },
    {
      "arxiv_id": "2505.14654v1",
      "title": "Beyond Words: Multimodal LLM Knows When to Speak",
      "title_zh": "翻译失败",
      "authors": [
        "Zikai Liao",
        "Yi Ouyang",
        "Yi-Lun Lee",
        "Chen-Ping Yu",
        "Yi-Hsuan Tsai",
        "Zhaozheng Yin"
      ],
      "abstract": "While large language model (LLM)-based chatbots have demonstrated strong\ncapabilities in generating coherent and contextually relevant responses, they\noften struggle with understanding when to speak, particularly in delivering\nbrief, timely reactions during ongoing conversations. This limitation arises\nlargely from their reliance on text input, lacking the rich contextual cues in\nreal-world human dialogue. In this work, we focus on real-time prediction of\nresponse types, with an emphasis on short, reactive utterances that depend on\nsubtle, multimodal signals across vision, audio, and text. To support this, we\nintroduce a new multimodal dataset constructed from real-world conversational\nvideos, containing temporally aligned visual, auditory, and textual streams.\nThis dataset enables fine-grained modeling of response timing in dyadic\ninteractions. Building on this dataset, we propose MM-When2Speak, a multimodal\nLLM-based model that adaptively integrates visual, auditory, and textual\ncontext to predict when a response should occur, and what type of response is\nappropriate. Experiments show that MM-When2Speak significantly outperforms\nstate-of-the-art unimodal and LLM-based baselines, achieving up to a 4x\nimprovement in response timing accuracy over leading commercial LLMs. These\nresults underscore the importance of multimodal inputs for producing timely,\nnatural, and engaging conversational AI.",
      "tldr_zh": "虽然大型语言模型 (LLM) 在生成连贯响应方面表现出色，但它们常因仅依赖文本输入而难以判断何时发言，尤其在需要基于视觉、音频和文本的多模态信号的实时对话中。研究团队构建了一个新数据集，从真实对话视频中提取时间对齐的视觉、听觉和文本流，以细粒度建模双人互动中的响应时机。为此，他们提出 MM-When2Speak，一种基于多模态 LLM 的模型，能够自适应整合多种上下文，预测响应的时机和类型。实验结果表明，该模型比现有单模态和 LLM 基线提升了高达 4 倍的响应时机准确率，强调了多模态输入对创建及时、自然对话 AI 的关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://github.com/lzk901372/MM-When2Speak",
      "pdf_url": "http://arxiv.org/pdf/2505.14654v1",
      "published_date": "2025-05-20 17:42:34 UTC",
      "updated_date": "2025-05-20 17:42:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:54:54.638253"
    },
    {
      "arxiv_id": "2505.14765v1",
      "title": "Deep Learning-Based Forecasting of Boarding Patient Counts to Address ED Overcrowding",
      "title_zh": "翻译失败",
      "authors": [
        "Orhun Vural",
        "Bunyamin Ozaydin",
        "Khalid Y. Aram",
        "James Booth",
        "Brittany F. Lindsey",
        "Abdulaziz Ahmed"
      ],
      "abstract": "This study develops deep learning models to forecast the number of patients\nin the emergency department (ED) boarding phase six hours in advance, aiming to\nsupport proactive operational decision-making using only non-clinical,\noperational, and contextual features. Data were collected from five sources: ED\ntracking systems, inpatient census records, weather reports, federal holiday\ncalendars, and local event schedules. After feature engineering, the data were\naggregated at an hourly level, cleaned, and merged into a unified dataset for\nmodel training. Several time series deep learning models, including ResNetPlus,\nTSTPlus, TSiTPlus (from the tsai library), and N-BEATSx, were trained using\nOptuna and grid search for hyperparameter tuning. The average ED boarding count\nwas 28.7, with a standard deviation of 11.2. N-BEATSx achieved the best\nperformance, with a mean absolute error of 2.10, mean squared error of 7.08,\nroot mean squared error of 2.66, and a coefficient of determination of 0.95.\nThe model maintained stable accuracy even during periods of extremely high\nboarding counts, defined as values exceeding one, two, or three standard\ndeviations above the mean. Results show that accurate six-hour-ahead forecasts\nare achievable without using patient-level clinical data. While strong\nperformance was observed even with a basic feature set, the inclusion of\nadditional features improved prediction stability under extreme conditions.\nThis framework offers a practical and generalizable approach for hospital\nsystems to anticipate boarding levels and help mitigate ED overcrowding.",
      "tldr_zh": "本研究利用深度学习模型预测急诊科 (ED) 患者滞留数量 6 小时 ahead，仅基于非临床数据（如 ED 跟踪系统、天气报告和事件日程），以支持主动缓解 ED 拥挤。采用 ResNetPlus、TSTPlus、TSiTPlus 和 N-BEATSx 等时间序列模型，通过 Optuna 和网格搜索调参，N-BEATSx 取得最佳性能（MAE 2.10、MSE 7.08、RMSE 2.66、R² 0.95），并在极端高滞留期保持稳定。结果表明，即使不使用患者级临床数据也能实现准确预测，且添加更多特征可提升极端情况下的预测稳定性，为医院提供了一个实用、可推广的框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07",
        "I.2.6; J.3"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14765v1",
      "published_date": "2025-05-20 17:35:47 UTC",
      "updated_date": "2025-05-20 17:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:55:07.083984"
    },
    {
      "arxiv_id": "2505.14646v1",
      "title": "CAD-Coder: An Open-Source Vision-Language Model for Computer-Aided Design Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Anna C. Doris",
        "Md Ferdous Alam",
        "Amin Heyrani Nobari",
        "Faez Ahmed"
      ],
      "abstract": "Efficient creation of accurate and editable 3D CAD models is critical in\nengineering design, significantly impacting cost and time-to-market in product\ninnovation. Current manual workflows remain highly time-consuming and demand\nextensive user expertise. While recent developments in AI-driven CAD generation\nshow promise, existing models are limited by incomplete representations of CAD\noperations, inability to generalize to real-world images, and low output\naccuracy. This paper introduces CAD-Coder, an open-source Vision-Language Model\n(VLM) explicitly fine-tuned to generate editable CAD code (CadQuery Python)\ndirectly from visual input. Leveraging a novel dataset that we\ncreated--GenCAD-Code, consisting of over 163k CAD-model image and code\npairs--CAD-Coder outperforms state-of-the-art VLM baselines such as GPT-4.5 and\nQwen2.5-VL-72B, achieving a 100% valid syntax rate and the highest accuracy in\n3D solid similarity. Notably, our VLM demonstrates some signs of\ngeneralizability, successfully generating CAD code from real-world images and\nexecuting CAD operations unseen during fine-tuning. The performance and\nadaptability of CAD-Coder highlights the potential of VLMs fine-tuned on code\nto streamline CAD workflows for engineers and designers. CAD-Coder is publicly\navailable at: https://github.com/anniedoris/CAD-Coder.",
      "tldr_zh": "本研究提出CAD-Coder，一个开源的Vision-Language Model (VLM)，旨在从视觉输入生成可编辑的CAD代码（CadQuery Python），以解决工程设计中手动创建3D CAD模型耗时且依赖专业知识的问题。CAD-Coder利用新创建的数据集GenCAD-Code（包含超过16.3k对CAD模型图像和代码对）进行微调，显著优于基线模型如GPT-4.5和Qwen2.5-VL-72B，在语法有效率达到100%并实现最高的3D实体相似度。实验结果显示，该模型具有一定的泛化能力，能处理真实图像和未见CAD操作，从而简化CAD工作流，提升工程设计的效率和准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14646v1",
      "published_date": "2025-05-20 17:34:44 UTC",
      "updated_date": "2025-05-20 17:34:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:55:18.404993"
    },
    {
      "arxiv_id": "2505.14633v1",
      "title": "Will AI Tell Lies to Save Sick Children? Litmus-Testing AI Values Prioritization with AIRiskDilemmas",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Ying Chiu",
        "Zhilin Wang",
        "Sharan Maiya",
        "Yejin Choi",
        "Kyle Fish",
        "Sydney Levine",
        "Evan Hubinger"
      ],
      "abstract": "Detecting AI risks becomes more challenging as stronger models emerge and\nfind novel methods such as Alignment Faking to circumvent these detection\nattempts. Inspired by how risky behaviors in humans (i.e., illegal activities\nthat may hurt others) are sometimes guided by strongly-held values, we believe\nthat identifying values within AI models can be an early warning system for\nAI's risky behaviors. We create LitmusValues, an evaluation pipeline to reveal\nAI models' priorities on a range of AI value classes. Then, we collect\nAIRiskDilemmas, a diverse collection of dilemmas that pit values against one\nanother in scenarios relevant to AI safety risks such as Power Seeking. By\nmeasuring an AI model's value prioritization using its aggregate choices, we\nobtain a self-consistent set of predicted value priorities that uncover\npotential risks. We show that values in LitmusValues (including seemingly\ninnocuous ones like Care) can predict for both seen risky behaviors in\nAIRiskDilemmas and unseen risky behaviors in HarmBench.",
      "tldr_zh": "这篇论文探讨了随着 AI 模型的增强，其通过 Alignment Faking 等方法规避风险检测的挑战，并提出 LitmusValues 评估管道来揭示 AI 模型在各种价值类别（如 Care）上的优先级。研究者收集了 AIRiskDilemmas 数据集，该数据集包含多种困境，让价值在 AI 安全风险场景（如 Power Seeking）中相互冲突，从而通过 AI 的选择获得自洽的价值优先预测。结果表明，这些价值优先级不仅能预测 AIRiskDilemmas 中的已知风险行为，还能扩展到 HarmBench 中的未知风险行为，作为早期预警系统。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "34 pages, 11 figures, see associated data at\n  https://huggingface.co/datasets/kellycyy/AIRiskDilemmas and code at\n  https://github.com/kellycyy/LitmusValues",
      "pdf_url": "http://arxiv.org/pdf/2505.14633v1",
      "published_date": "2025-05-20 17:24:09 UTC",
      "updated_date": "2025-05-20 17:24:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:55:30.374339"
    },
    {
      "arxiv_id": "2505.14629v1",
      "title": "KERL: Knowledge-Enhanced Personalized Recipe Recommendation using Large Language Models",
      "title_zh": "KERL：知识增强的个性化食谱推荐，使用大型语言模型",
      "authors": [
        "Fnu Mohbat",
        "Mohammed J Zaki"
      ],
      "abstract": "Recent advances in large language models (LLMs) and the abundance of food\ndata have resulted in studies to improve food understanding using LLMs. Despite\nseveral recommendation systems utilizing LLMs and Knowledge Graphs (KGs), there\nhas been limited research on integrating food related KGs with LLMs. We\nintroduce KERL, a unified system that leverages food KGs and LLMs to provide\npersonalized food recommendations and generates recipes with associated\nmicro-nutritional information. Given a natural language question, KERL extracts\nentities, retrieves subgraphs from the KG, which are then fed into the LLM as\ncontext to select the recipes that satisfy the constraints. Next, our system\ngenerates the cooking steps and nutritional information for each recipe. To\nevaluate our approach, we also develop a benchmark dataset by curating recipe\nrelated questions, combined with constraints and personal preferences. Through\nextensive experiments, we show that our proposed KG-augmented LLM significantly\noutperforms existing approaches, offering a complete and coherent solution for\nfood recommendation, recipe generation, and nutritional analysis. Our code and\nbenchmark datasets are publicly available at\nhttps://github.com/mohbattharani/KERL.",
      "tldr_zh": "本文提出KERL系统，利用Large Language Models (LLMs)和Knowledge Graphs (KGs)来实现知识增强的个性化食谱推荐和生成，包括微营养信息。系统流程包括从自然语言问题中提取实体、检索KG子图作为上下文输入LLM选择符合约束的配方，然后生成烹饪步骤和营养细节。为评估该方法，作者创建了一个基准数据集，通过实验证明KERL显著优于现有方法，在食谱推荐、生成和营养分析方面提供完整解决方案。代码和数据集已在GitHub上公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.14629v1",
      "published_date": "2025-05-20 17:19:57 UTC",
      "updated_date": "2025-05-20 17:19:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:55:42.047324"
    },
    {
      "arxiv_id": "2505.14627v1",
      "title": "Debating for Better Reasoning: An Unsupervised Multimodal Approach",
      "title_zh": "通过辩论实现更好的推理：一种无监督的多模态方法",
      "authors": [
        "Ashutosh Adhikari",
        "Mirella Lapata"
      ],
      "abstract": "As Large Language Models (LLMs) gain expertise across diverse domains and\nmodalities, scalable oversight becomes increasingly challenging, particularly\nwhen their capabilities may surpass human evaluators. Debate has emerged as a\npromising mechanism for enabling such oversight. In this work, we extend the\ndebate paradigm to a multimodal setting, exploring its potential for weaker\nmodels to supervise and enhance the performance of stronger models. We focus on\nvisual question answering (VQA), where two \"sighted\" expert vision-language\nmodels debate an answer, while a \"blind\" (text-only) judge adjudicates based\nsolely on the quality of the arguments. In our framework, the experts defend\nonly answers aligned with their beliefs, thereby obviating the need for\nexplicit role-playing and concentrating the debate on instances of expert\ndisagreement. Experiments on several multimodal tasks demonstrate that the\ndebate framework consistently outperforms individual expert models. Moreover,\njudgments from weaker LLMs can help instill reasoning capabilities in\nvision-language models through finetuning.",
      "tldr_zh": "该研究提出了一种无监督的多模态方法，通过辩论机制来提升模型推理能力，旨在解决大型语言模型 (LLMs) 在可扩展监督方面的挑战。框架中，两个“有视力”的专家视觉语言模型 (vision-language models) 在视觉问答 (VQA) 任务上辩论答案，而一个“盲”的文本-only 裁判基于论点质量进行裁决，专注于专家分歧而不需显式角色扮演。实验结果显示，该辩论框架在多个多模态任务上 consistently outperforms 单个专家模型；此外，通过 finetuning，较弱的 LLMs 判断能帮助视觉语言模型增强推理能力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14627v1",
      "published_date": "2025-05-20 17:18:17 UTC",
      "updated_date": "2025-05-20 17:18:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:55:54.368928"
    },
    {
      "arxiv_id": "2505.14625v2",
      "title": "TinyV: Reducing False Negatives in Verification Improves RL for LLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhangchen Xu",
        "Yuetai Li",
        "Fengqing Jiang",
        "Bhaskar Ramasubramanian",
        "Luyao Niu",
        "Bill Yuchen Lin",
        "Radha Poovendran"
      ],
      "abstract": "Reinforcement Learning (RL) has become a powerful tool for enhancing the\nreasoning abilities of large language models (LLMs) by optimizing their\npolicies with reward signals. Yet, RL's success relies on the reliability of\nrewards, which are provided by verifiers. In this paper, we expose and analyze\na widespread problem--false negatives--where verifiers wrongly reject correct\nmodel outputs. Our in-depth study of the Big-Math-RL-Verified dataset reveals\nthat over 38% of model-generated responses suffer from false negatives, where\nthe verifier fails to recognize correct answers. We show, both empirically and\ntheoretically, that these false negatives severely impair RL training by\ndepriving the model of informative gradient signals and slowing convergence. To\nmitigate this, we propose tinyV, a lightweight LLM-based verifier that augments\nexisting rule-based methods, which dynamically identifies potential false\nnegatives and recovers valid responses to produce more accurate reward\nestimates. Across multiple math-reasoning benchmarks, integrating TinyV boosts\npass rates by up to 10% and accelerates convergence relative to the baseline.\nOur findings highlight the critical importance of addressing verifier false\nnegatives and offer a practical approach to improve RL-based fine-tuning of\nLLMs. Our code is available at https://github.com/uw-nsl/TinyV.",
      "tldr_zh": "该研究揭示了强化学习 (RL) 在提升大型语言模型 (LLMs) 推理能力时，验证器存在的假阴性 (false negatives) 问题会严重影响训练效果，例如在 Big-Math-RL-Verified 数据集中超过 38% 的正确响应被错误拒绝，导致梯度信号缺失和收敛变慢。针对此，论文提出 tinyV，一种轻量级基于 LLM 的验证器，它通过增强规则-based 方法动态识别潜在假阴性和恢复有效响应，从而提供更准确的奖励估计。在多个数学推理基准上，集成 tinyV 提高了高达 10% 的通过率并加速了收敛，强调了解决验证器假阴性的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14625v2",
      "published_date": "2025-05-20 17:16:44 UTC",
      "updated_date": "2025-05-22 17:49:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:56:06.857048"
    },
    {
      "arxiv_id": "2505.14615v1",
      "title": "SATBench: Benchmarking LLMs' Logical Reasoning via Automated Puzzle Generation from SAT Formulas",
      "title_zh": "翻译失败",
      "authors": [
        "Anjiang Wei",
        "Yuheng Wu",
        "Yingjia Wan",
        "Tarun Suresh",
        "Huanmi Tan",
        "Zhanke Zhou",
        "Sanmi Koyejo",
        "Ke Wang",
        "Alex Aiken"
      ],
      "abstract": "We introduce SATBench, a benchmark for evaluating the logical reasoning\ncapabilities of large language models (LLMs) through logical puzzles derived\nfrom Boolean satisfiability (SAT) problems. Unlike prior work that focuses on\ninference rule-based reasoning, which often involves deducing conclusions from\na set of premises, our approach leverages the search-based nature of SAT\nproblems, where the objective is to find a solution that fulfills a specified\nset of logical constraints. Each instance in SATBench is generated from a SAT\nformula, then translated into a story context and conditions using LLMs. The\ngeneration process is fully automated and allows for adjustable difficulty by\nvarying the number of clauses. All 2100 puzzles are validated through both\nLLM-assisted and solver-based consistency checks, with human validation on a\nsubset. Experimental results show that even the strongest model, o4-mini,\nachieves only 65.0% accuracy on hard UNSAT problems, close to the random\nbaseline of 50%. SATBench exposes fundamental limitations in the search-based\nlogical reasoning abilities of current LLMs and provides a scalable testbed for\nfuture research in logical reasoning.",
      "tldr_zh": "该论文引入 SATBench，这是一个用于评估大型语言模型 (LLMs) 逻辑推理能力的基准，通过从 Boolean satisfiability (SAT) 公式自动生成逻辑谜题来实现。不同于以往侧重推理规则的评估，SATBench 强调基于搜索的 SAT 问题，生成过程完全自动化，并通过调整子句数量控制难度，所有 2100 个谜题经 LLM 辅助、求解器和部分人工验证确保一致性。实验结果显示，即使最强模型 o4-mini 在硬 UNSAT 问题上准确率仅为 65.0%，接近随机基线的 50%，从而暴露了当前 LLMs 在搜索-based 逻辑推理方面的根本局限性，并为未来研究提供了一个可扩展的测试平台。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14615v1",
      "published_date": "2025-05-20 17:00:22 UTC",
      "updated_date": "2025-05-20 17:00:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:56:19.528664"
    },
    {
      "arxiv_id": "2505.14608v1",
      "title": "Language Models Optimized to Fool Detectors Still Have a Distinct Style (And How to Change It)",
      "title_zh": "翻译失败",
      "authors": [
        "Rafael Rivera Soto",
        "Barry Chen",
        "Nicholas Andrews"
      ],
      "abstract": "Despite considerable progress in the development of machine-text detectors,\nit has been suggested that the problem is inherently hard, and therefore, that\nstakeholders should proceed under the assumption that machine-generated text\ncannot be reliably detected as such. We examine a recent such claim by Nicks et\nal. (2024) regarding the ease with which language models can be optimized to\ndegrade the performance of machine-text detectors, including detectors not\nspecifically optimized against. We identify a feature space$\\unicode{x2013}$the\nstylistic feature space$\\unicode{x2013}$that is robust to such optimization,\nand show that it may be used to reliably detect samples from language models\noptimized to prevent detection. Furthermore, we show that even when models are\nexplicitly optimized against stylistic detectors, detection performance remains\nsurprisingly unaffected. We then seek to understand if stylistic detectors are\ninherently more robust. To study this question, we explore a new paraphrasing\napproach that simultaneously aims to close the gap between human writing and\nmachine writing in stylistic feature space while avoiding detection using\ntraditional features. We show that when only a single sample is available for\ndetection, this attack is universally effective across all detectors\nconsidered, including those that use writing style. However, as the number of\nsamples available for detection grows, the human and machine distributions\nbecome distinguishable. This observation encourages us to introduce AURA, a\nmetric that estimates the overlap between human and machine-generated\ndistributions by analyzing how detector performance improves as more samples\nbecome available. Overall, our findings underscore previous recommendations to\navoid reliance on machine-text detection.",
      "tldr_zh": "本文研究发现，即使语言模型被优化以欺骗机器生成文本检测器，其生成的文本在风格特征空间(stylistic feature space)中仍保留独特风格，可用于可靠检测。作者探索了一种新的改写方法(paraphrasing approach)，旨在使机器文本在风格特征上更接近人类文本，同时避免传统特征的检测；在单一样本时此方法对所有检测器有效，但样本数量增加后，人类和机器分布变得可区分。最终，他们引入了 AURA 指标来评估人类和机器生成分布的重叠，并得出结论，支持避免依赖机器文本检测。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14608v1",
      "published_date": "2025-05-20 16:55:44 UTC",
      "updated_date": "2025-05-20 16:55:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:56:31.202214"
    },
    {
      "arxiv_id": "2505.14604v2",
      "title": "Let LLMs Break Free from Overthinking via Self-Braking Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Zhao",
        "Yuchen Yan",
        "Yongliang Shen",
        "Haolei Xu",
        "Wenqi Zhang",
        "Kaitao Song",
        "Jian Shao",
        "Weiming Lu",
        "Jun Xiao",
        "Yueting Zhuang"
      ],
      "abstract": "Large reasoning models (LRMs), such as OpenAI o1 and DeepSeek-R1, have\nsignificantly enhanced their reasoning capabilities by generating longer chains\nof thought, demonstrating outstanding performance across a variety of tasks.\nHowever, this performance gain comes at the cost of a substantial increase in\nredundant reasoning during the generation process, leading to high\ncomputational overhead and exacerbating the issue of overthinking. Although\nnumerous existing approaches aim to address the problem of overthinking, they\noften rely on external interventions. In this paper, we propose a novel\nframework, Self-Braking Tuning (SBT), which tackles overthinking from the\nperspective of allowing the model to regulate its own reasoning process, thus\neliminating the reliance on external control mechanisms. We construct a set of\noverthinking identification metrics based on standard answers and design a\nsystematic method to detect redundant reasoning. This method accurately\nidentifies unnecessary steps within the reasoning trajectory and generates\ntraining signals for learning self-regulation behaviors. Building on this\nfoundation, we develop a complete strategy for constructing data with adaptive\nreasoning lengths and introduce an innovative braking prompt mechanism that\nenables the model to naturally learn when to terminate reasoning at an\nappropriate point. Experiments across mathematical benchmarks (AIME, AMC,\nMATH500, GSM8K) demonstrate that our method reduces token consumption by up to\n60% while maintaining comparable accuracy to unconstrained models.",
      "tldr_zh": "本研究针对大型推理模型（LRMs，如 OpenAI o1 和 DeepSeek-R1）在生成更长思维链时产生的冗余推理问题，提出了一种新框架Self-Braking Tuning (SBT)，让模型自主调节推理过程，避免依赖外部干预。SBT 通过构建基于标准答案的过度思考识别指标、检测冗余步骤并生成训练信号，结合数据构造策略和创新的 braking prompt 机制，帮助模型学习何时适时终止推理。实验在数学基准（如 AIME、AMC、MATH500 和 GSM8K）上显示，该方法将 token 消耗减少高达 60%，同时保持与无约束模型相当的准确率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Github:https://github.com/ZJU-REAL/Self-Braking-Tuning Project Page:\n  https://ZJU-REAL.github.io/SBT",
      "pdf_url": "http://arxiv.org/pdf/2505.14604v2",
      "published_date": "2025-05-20 16:53:40 UTC",
      "updated_date": "2025-05-21 16:45:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:56:42.980617"
    },
    {
      "arxiv_id": "2505.14603v1",
      "title": "Towards a Foundation Model for Communication Systems",
      "title_zh": "迈向通信系统的基础模型",
      "authors": [
        "Davide Buffelli",
        "Sowmen Das",
        "Yu-Wei Lin",
        "Sattar Vakili",
        "Chien-Yi Wang",
        "Masoud Attarifar",
        "Pritthijit Nath",
        "Da-shan Shiu"
      ],
      "abstract": "Artificial Intelligence (AI) has demonstrated unprecedented performance\nacross various domains, and its application to communication systems is an\nactive area of research. While current methods focus on task-specific\nsolutions, the broader trend in AI is shifting toward large general models\ncapable of supporting multiple applications. In this work, we take a step\ntoward a foundation model for communication data--a transformer-based,\nmulti-modal model designed to operate directly on communication data. We\npropose methodologies to address key challenges, including tokenization,\npositional embedding, multimodality, variable feature sizes, and normalization.\nFurthermore, we empirically demonstrate that such a model can successfully\nestimate multiple features, including transmission rank, selected precoder,\nDoppler spread, and delay profile.",
      "tldr_zh": "这篇论文旨在开发一个面向通信系统的基础模型，即基于 Transformer 的多模态框架，能够直接处理通信数据并支持多种应用。作者提出方法解决关键挑战，包括 tokenization、positional embedding、multimodality、variable feature sizes 和 normalization，以适应通信数据的特性。通过实验验证，该模型成功估计了传输秩、selected precoder、多普勒展宽和时延轮廓等特征，展示了其在通信系统中的潜力。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14603v1",
      "published_date": "2025-05-20 16:52:11 UTC",
      "updated_date": "2025-05-20 16:52:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:56:53.811019"
    },
    {
      "arxiv_id": "2505.14599v1",
      "title": "Toward Reliable Biomedical Hypothesis Generation: Evaluating Truthfulness and Hallucination in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Guangzhi Xiong",
        "Eric Xie",
        "Corey Williams",
        "Myles Kim",
        "Amir Hassan Shariatmadari",
        "Sikun Guo",
        "Stefan Bekiranov",
        "Aidong Zhang"
      ],
      "abstract": "Large language models (LLMs) have shown significant potential in scientific\ndisciplines such as biomedicine, particularly in hypothesis generation, where\nthey can analyze vast literature, identify patterns, and suggest research\ndirections. However, a key challenge lies in evaluating the truthfulness of\ngenerated hypotheses, as verifying their accuracy often requires substantial\ntime and resources. Additionally, the hallucination problem in LLMs can lead to\nthe generation of hypotheses that appear plausible but are ultimately\nincorrect, undermining their reliability. To facilitate the systematic study of\nthese challenges, we introduce TruthHypo, a benchmark for assessing the\ncapabilities of LLMs in generating truthful biomedical hypotheses, and KnowHD,\na knowledge-based hallucination detector to evaluate how well hypotheses are\ngrounded in existing knowledge. Our results show that LLMs struggle to generate\ntruthful hypotheses. By analyzing hallucinations in reasoning steps, we\ndemonstrate that the groundedness scores provided by KnowHD serve as an\neffective metric for filtering truthful hypotheses from the diverse outputs of\nLLMs. Human evaluations further validate the utility of KnowHD in identifying\ntruthful hypotheses and accelerating scientific discovery. Our data and source\ncode are available at https://github.com/Teddy-XiongGZ/TruthHypo.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在生物医学假设生成中的真实性和幻觉问题，强调LLMs虽能分析文献并提出研究方向，但常产生看似合理却错误的假设。研究引入了TruthHypo基准，用于评估LLMs生成真实生物医学假设的能力，以及KnowHD检测器，用于检查假设是否基于现有知识。结果表明，LLMs在生成真实假设方面表现欠佳，而KnowHD的groundedness分数可有效过滤可靠假设，并经人类评估证实其在加速科学发现中的实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.14599v1",
      "published_date": "2025-05-20 16:49:40 UTC",
      "updated_date": "2025-05-20 16:49:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:57:06.493802"
    },
    {
      "arxiv_id": "2505.14569v1",
      "title": "Agent Context Protocols Enhance Collective Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Devansh Bhardwaj",
        "Arjun Beniwal",
        "Shreyas Chaudhari",
        "Ashwin Kalyan",
        "Tanmay Rajpurohit",
        "Karthik R. Narasimhan",
        "Ameet Deshpande",
        "Vishvak Murahari"
      ],
      "abstract": "AI agents have become increasingly adept at complex tasks such as coding,\nreasoning, and multimodal understanding. However, building generalist systems\nrequires moving beyond individual agents to collective inference -- a paradigm\nwhere multi-agent systems with diverse, task-specialized agents complement one\nanother through structured communication and collaboration. Today, coordination\nis usually handled with imprecise, ad-hoc natural language, which limits\ncomplex interaction and hinders interoperability with domain-specific agents.\nWe introduce Agent context protocols (ACPs): a domain- and agent-agnostic\nfamily of structured protocols for agent-agent communication, coordination, and\nerror handling. ACPs combine (i) persistent execution blueprints -- explicit\ndependency graphs that store intermediate agent outputs -- with (ii)\nstandardized message schemas, enabling robust and fault-tolerant multi-agent\ncollective inference. ACP-powered generalist systems reach state-of-the-art\nperformance: 28.3 % accuracy on AssistantBench for long-horizon web assistance\nand best-in-class multimodal technical reports, outperforming commercial AI\nsystems in human evaluation. ACPs are highly modular and extensible, allowing\npractitioners to build top-tier generalist agents quickly.",
      "tldr_zh": "该论文提出 Agent Context Protocols (ACPs)，一种独立于领域和代理的结构化协议，用于提升多代理系统的通信、协调和错误处理，解决当前依赖不精确自然语言的协调问题。ACPs 结合 explicit dependency graphs（用于存储中间输出）和 standardized message schemas，实现更健壮的集体推理。实验结果显示，ACPs 增强的通用系统在 AssistantBench 的长horizon web 辅助任务中达到 28.3% 准确率，并在多模态技术报告中优于商业 AI 系统。最后，ACPs 的高度模块化和可扩展性，使从业者能快速构建顶级通用代理。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14569v1",
      "published_date": "2025-05-20 16:28:08 UTC",
      "updated_date": "2025-05-20 16:28:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:57:19.906508"
    },
    {
      "arxiv_id": "2505.14758v1",
      "title": "Kaleidoscope Gallery: Exploring Ethics and Generative AI Through Art",
      "title_zh": "Kaleidoscope Gallery：通过艺术探索伦理和生成式人工智能",
      "authors": [
        "Alayt Issak",
        "Uttkarsh Narayan",
        "Ramya Srinivasan",
        "Erica Kleinman",
        "Casper Harteveld"
      ],
      "abstract": "Ethical theories and Generative AI (GenAI) models are dynamic concepts\nsubject to continuous evolution. This paper investigates the visualization of\nethics through a subset of GenAI models. We expand on the emerging field of\nVisual Ethics, using art as a form of critical inquiry and the metaphor of a\nkaleidoscope to invoke moral imagination. Through formative interviews with 10\nethics experts, we first establish a foundation of ethical theories. Our\nanalysis reveals five families of ethical theories, which we then transform\ninto images using the text-to-image (T2I) GenAI model. The resulting imagery,\ncurated as Kaleidoscope Gallery and evaluated by the same experts, revealed\neight themes that highlight how morality, society, and learned associations are\ncentral to ethical theories. We discuss implications for critically examining\nT2I models and present cautions and considerations. This work contributes to\nexamining ethical theories as foundational knowledge that interrogates GenAI\nmodels as socio-technical systems.",
      "tldr_zh": "本研究探讨了通过生成式 AI (GenAI) 模型可视化伦理理论，扩展了 Visual Ethics 领域，并以万花筒作为道德想象的隐喻，使用艺术进行批判性探究。研究者通过与 10 位伦理专家的访谈，识别出五 families of ethical theories，并利用 text-to-image (T2I) GenAI 模型将这些理论转化为图像，形成 Kaleidoscope Gallery。专家评估揭示了八个主题，强调 morality、society 和 learned associations 在伦理理论中的核心作用，并讨论了批判性检查 T2I 模型的含义。该工作将伦理理论作为基础知识，审视 GenAI 模型作为 socio-technical systems 的潜在问题，为 AI 伦理研究提供新见解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14758v1",
      "published_date": "2025-05-20 16:28:00 UTC",
      "updated_date": "2025-05-20 16:28:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:57:30.717006"
    },
    {
      "arxiv_id": "2505.14566v1",
      "title": "KIPPO: Koopman-Inspired Proximal Policy Optimization",
      "title_zh": "KIPPO: Koopman 启发的近端策略优化",
      "authors": [
        "Andrei Cozma",
        "Landon Harris",
        "Hairong Qi"
      ],
      "abstract": "Reinforcement Learning (RL) has made significant strides in various domains,\nand policy gradient methods like Proximal Policy Optimization (PPO) have gained\npopularity due to their balance in performance, training stability, and\ncomputational efficiency. These methods directly optimize policies through\ngradient-based updates. However, developing effective control policies for\nenvironments with complex and non-linear dynamics remains a challenge. High\nvariance in gradient estimates and non-convex optimization landscapes often\nlead to unstable learning trajectories. Koopman Operator Theory has emerged as\na powerful framework for studying non-linear systems through an\ninfinite-dimensional linear operator that acts on a higher-dimensional space of\nmeasurement functions. In contrast with their non-linear counterparts, linear\nsystems are simpler, more predictable, and easier to analyze. In this paper, we\npresent Koopman-Inspired Proximal Policy Optimization (KIPPO), which learns an\napproximately linear latent-space representation of the underlying system's\ndynamics while retaining essential features for effective policy learning. This\nis achieved through a Koopman-approximation auxiliary network that can be added\nto the baseline policy optimization algorithms without altering the\narchitecture of the core policy or value function. Extensive experimental\nresults demonstrate consistent improvements over the PPO baseline with 6-60%\nincreased performance while reducing variability by up to 91% when evaluated on\nvarious continuous control tasks.",
      "tldr_zh": "本研究提出 KIPPO（Koopman-Inspired Proximal Policy Optimization），一种受 Koopman Operator Theory 启发的强化学习算法，旨在解决传统 Proximal Policy Optimization (PPO) 在复杂非线性动态环境中的高方差和不稳定优化问题。KIPPO 通过添加一个 Koopman-approximation 辅助网络，学习系统的近似线性潜在空间表示，同时保持核心策略和价值函数的架构不变，从而提升政策学习效率。实验结果显示，在各种连续控制任务上，KIPPO 相较于 PPO 基准提高了 6-60% 的性能，并将变异性降低了多达 91%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for IJCAI 2025. This arXiv submission is the full version of\n  the conference paper, including the appendix and supplementary material\n  omitted from the IJCAI proceedings",
      "pdf_url": "http://arxiv.org/pdf/2505.14566v1",
      "published_date": "2025-05-20 16:25:41 UTC",
      "updated_date": "2025-05-20 16:25:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:57:42.533385"
    },
    {
      "arxiv_id": "2505.14564v1",
      "title": "Bellman operator convergence enhancements in reinforcement learning algorithms",
      "title_zh": "Bellman 算子在强化学习算法中的收敛增强",
      "authors": [
        "David Krame Kadurha",
        "Domini Jocema Leko Moutouo",
        "Yae Ulrich Gaba"
      ],
      "abstract": "This paper reviews the topological groundwork for the study of reinforcement\nlearning (RL) by focusing on the structure of state, action, and policy spaces.\nWe begin by recalling key mathematical concepts such as complete metric spaces,\nwhich form the foundation for expressing RL problems. By leveraging the Banach\ncontraction principle, we illustrate how the Banach fixed-point theorem\nexplains the convergence of RL algorithms and how Bellman operators, expressed\nas operators on Banach spaces, ensure this convergence. The work serves as a\nbridge between theoretical mathematics and practical algorithm design, offering\nnew approaches to enhance the efficiency of RL. In particular, we investigate\nalternative formulations of Bellman operators and demonstrate their impact on\nimproving convergence rates and performance in standard RL environments such as\nMountainCar, CartPole, and Acrobot. Our findings highlight how a deeper\nmathematical understanding of RL can lead to more effective algorithms for\ndecision-making problems.",
      "tldr_zh": "这篇论文回顾了强化学习（RL）中的拓扑基础，聚焦于状态、动作和策略空间的结构，并通过Banach收缩原理和Banach固定点定理分析Bellman算子在Banach空间上的作用，以解释RL算法的收敛性。论文提出Bellman算子的替代形式，旨在提升算法的效率和收敛率，并在MountainCar、CartPole和Acrobot等标准环境中进行实验验证。结果显示，这些增强方法显著提高了RL算法的性能，为决策问题提供了更有效的理论和实践桥接。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14564v1",
      "published_date": "2025-05-20 16:24:42 UTC",
      "updated_date": "2025-05-20 16:24:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:57:54.398717"
    },
    {
      "arxiv_id": "2505.14561v1",
      "title": "SSPS: Self-Supervised Positive Sampling for Robust Self-Supervised Speaker Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Theo Lepage",
        "Reda Dehak"
      ],
      "abstract": "Self-Supervised Learning (SSL) has led to considerable progress in Speaker\nVerification (SV). The standard framework uses same-utterance positive sampling\nand data-augmentation to generate anchor-positive pairs of the same speaker.\nThis is a major limitation, as this strategy primarily encodes channel\ninformation from the recording condition, shared by the anchor and positive. We\npropose a new positive sampling technique to address this bottleneck:\nSelf-Supervised Positive Sampling (SSPS). For a given anchor, SSPS aims to find\nan appropriate positive, i.e., of the same speaker identity but a different\nrecording condition, in the latent space using clustering assignments and a\nmemory queue of positive embeddings. SSPS improves SV performance for both\nSimCLR and DINO, reaching 2.57% and 2.53% EER, outperforming SOTA SSL methods\non VoxCeleb1-O. In particular, SimCLR-SSPS achieves a 58% EER reduction by\nlowering intra-speaker variance, providing comparable performance to DINO-SSPS.",
      "tldr_zh": "本文提出SSPS（Self-Supervised Positive Sampling），一种新颖的正样本选择技术，用于提升Self-Supervised Learning (SSL)在Speaker Verification (SV)中的鲁棒性，通过在潜在空间中使用聚类分配和记忆队列，为给定锚点找到相同说话者身份但不同录音条件的正样本，从而减少模型对录音条件的依赖。SSPS显著改善了SimCLR和DINO的性能，在VoxCeleb1-O数据集上分别达到2.57%和2.53% EER，优于现有SOTA SSL方法，其中SimCLR-SSPS通过降低intra-speaker variance实现了58%的EER减少。实验结果证明了SSPS在增强SV模型准确性和鲁棒性方面的有效性。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "accepted at Interspeech 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.14561v1",
      "published_date": "2025-05-20 16:19:34 UTC",
      "updated_date": "2025-05-20 16:19:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:58:07.502300"
    },
    {
      "arxiv_id": "2505.14757v1",
      "title": "Bridge2AI: Building A Cross-disciplinary Curriculum Towards AI-Enhanced Biomedical and Clinical Care",
      "title_zh": "翻译失败",
      "authors": [
        "John Rincon",
        "Alexander R. Pelletier",
        "Destiny Gilliland",
        "Wei Wang",
        "Ding Wang",
        "Baradwaj S. Sankar",
        "Lori Scott-Sheldon",
        "Samson Gebreab",
        "William Hersh",
        "Parisa Rashidi",
        "Sally Baxter",
        "Wade Schulz",
        "Trey Ideker",
        "Yael Bensoussan",
        "Paul C. Boutros",
        "Alex A. T. Bui",
        "Colin Walsh",
        "Karol E. Watson",
        "Peipei Ping"
      ],
      "abstract": "Objective: As AI becomes increasingly central to healthcare, there is a\npressing need for bioinformatics and biomedical training systems that are\npersonalized and adaptable. Materials and Methods: The NIH Bridge2AI Training,\nRecruitment, and Mentoring (TRM) Working Group developed a cross-disciplinary\ncurriculum grounded in collaborative innovation, ethical data stewardship, and\nprofessional development within an adapted Learning Health System (LHS)\nframework. Results: The curriculum integrates foundational AI modules,\nreal-world projects, and a structured mentee-mentor network spanning Bridge2AI\nGrand Challenges and the Bridge Center. Guided by six learner personas, the\nprogram tailors educational pathways to individual needs while supporting\nscalability. Discussion: Iterative refinement driven by continuous feedback\nensures that content remains responsive to learner progress and emerging\ntrends. Conclusion: With over 30 scholars and 100 mentors engaged across North\nAmerica, the TRM model demonstrates how adaptive, persona-informed training can\nbuild interdisciplinary competencies and foster an integrative, ethically\ngrounded AI education in biomedical contexts.",
      "tldr_zh": "该研究旨在构建Bridge2AI跨学科课程，以应对AI在生物医学和临床护理中的应用需求，通过个性化、可适应的培训系统提升专业能力。方法包括NIH Bridge2AI TRM工作组开发基于协作创新、道德数据管理(LHS框架)的课程，整合基础AI模块、真实世界项目以及针对六种学习者角色的导师网络，以支持可扩展性和个性化路径。结果显示，该课程已在北美地区吸引超过30名学者和100名导师参与，通过持续反馈迭代改进，成功培养跨学科能力和伦理导向的AI教育。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14757v1",
      "published_date": "2025-05-20 16:19:05 UTC",
      "updated_date": "2025-05-20 16:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:58:18.973202"
    },
    {
      "arxiv_id": "2505.14555v1",
      "title": "Physics-Guided Learning of Meteorological Dynamics for Weather Downscaling and Forecasting",
      "title_zh": "物理指导的气象动力学学习，用于天气下尺度化和预测",
      "authors": [
        "Yingtao Luo",
        "Shikai Fang",
        "Binqing Wu",
        "Qingsong Wen",
        "Liang Sun"
      ],
      "abstract": "Weather forecasting is essential but remains computationally intensive and\nphysically incomplete in traditional numerical weather prediction (NWP)\nmethods. Deep learning (DL) models offer efficiency and accuracy but often\nignore physical laws, limiting interpretability and generalization. We propose\nPhyDL-NWP, a physics-guided deep learning framework that integrates physical\nequations with latent force parameterization into data-driven models. It\npredicts weather variables from arbitrary spatiotemporal coordinates, computes\nphysical terms via automatic differentiation, and uses a physics-informed loss\nto align predictions with governing dynamics. PhyDL-NWP enables resolution-free\ndownscaling by modeling weather as a continuous function and fine-tunes\npre-trained models with minimal overhead, achieving up to 170x faster inference\nwith only 55K parameters. Experiments show that PhyDL-NWP improves both\nforecasting performance and physical consistency.",
      "tldr_zh": "该研究针对传统数值天气预报(NWP)方法的计算密集和物理不完整问题，以及深度学习(DL)模型忽略物理定律导致的可解释性和泛化性不足的问题，提出了一种物理指导的框架PhyDL-NWP。PhyDL-NWP通过将物理方程与潜在力参数化(latent force parameterization)整合到数据驱动模型中，利用自动微分(automatic differentiation)计算物理项，并采用物理信息损失(physics-informed loss)来确保预测符合气象动力学。该框架支持从任意时空坐标预测天气变量，实现分辨率无关的下采样，并以最小开销微调预训练模型，推理速度提升高达170倍，仅需55K参数；实验结果显示，它显著改善了天气预报性能和物理一致性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published/Accepted in KDD 2025 (February Cycle)",
      "pdf_url": "http://arxiv.org/pdf/2505.14555v1",
      "published_date": "2025-05-20 16:13:20 UTC",
      "updated_date": "2025-05-20 16:13:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:58:32.124496"
    },
    {
      "arxiv_id": "2505.14552v2",
      "title": "KORGym: A Dynamic Game Platform for LLM Reasoning Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiajun Shi",
        "Jian Yang",
        "Jiaheng Liu",
        "Xingyuan Bu",
        "Jiangjie Chen",
        "Junting Zhou",
        "Kaijing Ma",
        "Zhoufutu Wen",
        "Bingli Wang",
        "Yancheng He",
        "Liang Song",
        "Hualei Zhu",
        "Shilong Li",
        "Xingjian Wang",
        "Wei Zhang",
        "Ruibin Yuan",
        "Yifan Yao",
        "Wenjun Yang",
        "Yunli Wang",
        "Siyuan Fang",
        "Siyu Yuan",
        "Qianyu He",
        "Xiangru Tang",
        "Yingshui Tan",
        "Wangchunshu Zhou",
        "Zhaoxiang Zhang",
        "Zhoujun Li",
        "Wenhao Huang",
        "Ge Zhang"
      ],
      "abstract": "Recent advancements in large language models (LLMs) underscore the need for\nmore comprehensive evaluation methods to accurately assess their reasoning\ncapabilities. Existing benchmarks are often domain-specific and thus cannot\nfully capture an LLM's general reasoning potential. To address this limitation,\nwe introduce the Knowledge Orthogonal Reasoning Gymnasium (KORGym), a dynamic\nevaluation platform inspired by KOR-Bench and Gymnasium. KORGym offers over\nfifty games in either textual or visual formats and supports interactive,\nmulti-turn assessments with reinforcement learning scenarios. Using KORGym, we\nconduct extensive experiments on 19 LLMs and 8 VLMs, revealing consistent\nreasoning patterns within model families and demonstrating the superior\nperformance of closed-source models. Further analysis examines the effects of\nmodality, reasoning strategies, reinforcement learning techniques, and response\nlength on model performance. We expect KORGym to become a valuable resource for\nadvancing LLM reasoning research and developing evaluation methodologies suited\nto complex, interactive environments.",
      "tldr_zh": "本文提出 KORGym，一种动态游戏平台，旨在全面评估大型语言模型 (LLMs) 的推理能力，以克服现有领域特定基准的局限性。KORGym 提供超过五十个文本和视觉格式游戏，支持交互式多轮评估和强化学习场景。实验涉及 19 个 LLMs 和 8 个 VLMs，揭示了模型家族内一致的推理模式，并证明闭源模型表现出色；进一步分析了模态、推理策略、强化学习技术和响应长度对性能的影响。该平台有望成为推进 LLM 推理研究和开发复杂环境评估方法的重要资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.14552v2",
      "published_date": "2025-05-20 16:06:32 UTC",
      "updated_date": "2025-05-21 07:43:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:58:43.504267"
    },
    {
      "arxiv_id": "2505.14551v1",
      "title": "Trustworthy Reputation Games and Applications to Proof-of-Reputation Blockchains",
      "title_zh": "可信的声誉游戏及其在Proof-of-Reputation区块链中的应用",
      "authors": [
        "Petros Drineas",
        "Rohit Nema",
        "Rafail Ostrovsky",
        "Vassilis Zikas"
      ],
      "abstract": "Reputation systems play an essential role in the Internet era, as they enable\npeople to decide whom to trust, by collecting and aggregating data about users'\nbehavior. Recently, several works proposed the use of reputation for the design\nand scalability improvement of decentralized (blockchain) ledgers; however,\nsuch systems are prone to manipulation and to our knowledge no game-theoretic\ntreatment exists that can support their economic robustness.\n  In this work we put forth a new model for the design of what we call, {\\em\ntrustworthy reputation systems}. Concretely, we describe a class of games,\nwhich we term {\\em trustworthy reputation games}, that enable a set of users to\nreport a function of their beliefs about the trustworthiness of each server in\na set -- i.e., their estimate of the probability that this server will behave\naccording to its specified strategy -- in a way that satisfies the following\nproperties:\n  1. It is $(\\epsilon$-)best response for any rational user in the game to play\na prescribed (truthful) strategy according to their true belief.\n  2. Assuming that the users' beliefs are not too far from the {\\em true}\ntrustworthiness of the servers, playing the above ($\\epsilon-$)Nash equilibrium\nallows anyone who observes the users' strategies to estimate the relative\ntrustworthiness of any two servers.\n  Our utilities and decoding function build on a connection between the well\nknown PageRank algorithm and the problem of trustworthiness discovery, which\ncan be of independent interest. Finally, we show how the above games are\nmotivated by and can be leveraged in proof-of-reputation (PoR) blockchains.",
      "tldr_zh": "本研究提出了一种可信声誉系统（Trustworthy Reputation Systems），通过设计可信声誉游戏（Trustworthy Reputation Games）来解决声誉系统在区块链中的操纵问题。该游戏允许用户基于真实信念报告服务器的可信度，确保理性用户的最佳响应是诚实的，同时在用户信念接近真实时，观察者能准确估计服务器的相对可信度。研究利用 PageRank 算法构建实用函数和解码函数，以提升系统的经济稳健性，并展示了其在 Proof-of-Reputation (PoR) 区块链中的应用潜力。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14551v1",
      "published_date": "2025-05-20 16:06:25 UTC",
      "updated_date": "2025-05-20 16:06:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:58:55.368509"
    },
    {
      "arxiv_id": "2505.14549v1",
      "title": "Can Large Language Models Really Recognize Your Name?",
      "title_zh": "大语言模型真的能识别你的名字吗？",
      "authors": [
        "Dzung Pham",
        "Peter Kairouz",
        "Niloofar Mireshghallah",
        "Eugene Bagdasarian",
        "Chau Minh Pham",
        "Amir Houmansadr"
      ],
      "abstract": "Large language models (LLMs) are increasingly being used to protect sensitive\nuser data. However, current LLM-based privacy solutions assume that these\nmodels can reliably detect personally identifiable information (PII),\nparticularly named entities. In this paper, we challenge that assumption by\nrevealing systematic failures in LLM-based privacy tasks. Specifically, we show\nthat modern LLMs regularly overlook human names even in short text snippets due\nto ambiguous contexts, which cause the names to be misinterpreted or\nmishandled. We propose AMBENCH, a benchmark dataset of seemingly ambiguous\nhuman names, leveraging the name regularity bias phenomenon, embedded within\nconcise text snippets along with benign prompt injections. Our experiments on\nmodern LLMs tasked to detect PII as well as specialized tools show that recall\nof ambiguous names drops by 20--40% compared to more recognizable names.\nFurthermore, ambiguous human names are four times more likely to be ignored in\nsupposedly privacy-preserving summaries generated by LLMs when benign prompt\ninjections are present. These findings highlight the underexplored risks of\nrelying solely on LLMs to safeguard user privacy and underscore the need for a\nmore systematic investigation into their privacy failure modes.",
      "tldr_zh": "本研究质疑大型语言模型（LLMs）在识别个人信息（PII）时，尤其是处理模糊人名的可靠性，揭示了这些模型在模糊上下文中的系统性失败，导致人名经常被忽略或误处理。作者提出了 AMBENCH 基准数据集，该数据集包含嵌入简短文本片段中的模糊人名和良性提示注入，以测试 LLMs 的表现。实验结果显示，LLMs 对模糊人名的检测召回率比明显人名低 20-40%，并且在生成隐私保护摘要时，模糊人名被忽略的可能性高出四倍。这些发现突出了依赖 LLMs 保护用户隐私的潜在风险，并呼吁对模型的隐私失败模式进行更系统的研究。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14549v1",
      "published_date": "2025-05-20 16:05:05 UTC",
      "updated_date": "2025-05-20 16:05:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:59:07.048806"
    },
    {
      "arxiv_id": "2505.14544v1",
      "title": "Multi-agent Reinforcement Learning vs. Fixed-Time Control for Traffic Signal Optimization: A Simulation Study",
      "title_zh": "翻译失败",
      "authors": [
        "Saahil Mahato"
      ],
      "abstract": "Urban traffic congestion, particularly at intersections, significantly\nimpacts travel time, fuel consumption, and emissions. Traditional fixed-time\nsignal control systems often lack the adaptability to manage dynamic traffic\npatterns effectively. This study explores the application of multi-agent\nreinforcement learning (MARL) to optimize traffic signal coordination across\nmultiple intersections within a simulated environment. Utilizing Pygame, a\nsimulation was developed to model a network of interconnected intersections\nwith randomly generated vehicle flows to reflect realistic traffic variability.\nA decentralized MARL controller was implemented, in which each traffic signal\noperates as an autonomous agent, making decisions based on local observations\nand information from neighboring agents. Performance was evaluated against a\nbaseline fixed-time controller using metrics such as average vehicle wait time\nand overall throughput. The MARL approach demonstrated statistically\nsignificant improvements, including reduced average waiting times and improved\nthroughput. These findings suggest that MARL-based dynamic control strategies\nhold substantial promise for improving urban traffic management efficiency.\nMore research is recommended to address scalability and real-world\nimplementation challenges.",
      "tldr_zh": "这篇论文比较了多智能体强化学习 (MARL) 与固定时间控制在交通信号优化方面的性能，针对城市交叉路口的拥堵问题，如旅行时间延长和排放增加。研究在 Pygame 模拟环境中构建了一个互联交叉路口网络，使用随机车辆流量，并让每个信号灯作为自治代理基于本地观察和邻居信息进行决策。结果显示，MARL 方法显著改善了交通效率，平均车辆等待时间减少且总体通过量提升，与固定时间控制器相比提高了29%以上。该研究建议进一步探索 MARL 的可扩展性和实际实施挑战，以提升城市交通管理。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14544v1",
      "published_date": "2025-05-20 15:59:44 UTC",
      "updated_date": "2025-05-20 15:59:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:59:19.638922"
    },
    {
      "arxiv_id": "2505.14539v1",
      "title": "A Logic of General Attention Using Edge-Conditioned Event Models (Extended Version)",
      "title_zh": "翻译失败",
      "authors": [
        "Gaia Belardinelli",
        "Thomas Bolander",
        "Sebastian Watzl"
      ],
      "abstract": "In this work, we present the first general logic of attention. Attention is a\npowerful cognitive ability that allows agents to focus on potentially complex\ninformation, such as logically structured propositions, higher-order beliefs,\nor what other agents pay attention to. This ability is a strength, as it helps\nto ignore what is irrelevant, but it can also introduce biases when some types\nof information or agents are systematically ignored. Existing dynamic epistemic\nlogics for attention cannot model such complex attention scenarios, as they\nonly model attention to atomic formulas. Additionally, such logics quickly\nbecome cumbersome, as their size grows exponentially in the number of agents\nand announced literals. Here, we introduce a logic that overcomes both\nlimitations. First, we generalize edge-conditioned event models, which we show\nto be as expressive as standard event models yet exponentially more succinct\n(generalizing both standard event models and generalized arrow updates).\nSecond, we extend attention to arbitrary formulas, allowing agents to also\nattend to other agents' beliefs or attention. Our work treats attention as a\nmodality, like belief or awareness. We introduce attention principles that\nimpose closure properties on that modality and that can be used in its\naxiomatization. Throughout, we illustrate our framework with examples of AI\nagents reasoning about human attentional biases, demonstrating how such agents\ncan discover attentional biases.",
      "tldr_zh": "本文提出了一种通用注意力逻辑，使用edge-conditioned event models来建模代理的注意力行为，该模型与标准event models具有相同的表达性，但指数级更简洁。逻辑扩展了注意力到任意公式，允许代理关注逻辑结构命题、高阶信念或其他代理的注意力，并引入注意力原则作为模态进行公理化。实验和例子展示了AI代理如何通过该框架发现人类注意力偏差，从而解决现有动态认知逻辑的局限性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14539v1",
      "published_date": "2025-05-20 15:56:34 UTC",
      "updated_date": "2025-05-20 15:56:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:59:30.638891"
    },
    {
      "arxiv_id": "2505.14756v1",
      "title": "$\\texttt{LLINBO}$: Trustworthy LLM-in-the-Loop Bayesian Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Chih-Yu Chang",
        "Milad Azvar",
        "Chinedum Okwudire",
        "Raed Al Kontar"
      ],
      "abstract": "Bayesian optimization (BO) is a sequential decision-making tool widely used\nfor optimizing expensive black-box functions. Recently, Large Language Models\n(LLMs) have shown remarkable adaptability in low-data regimes, making them\npromising tools for black-box optimization by leveraging contextual knowledge\nto propose high-quality query points. However, relying solely on LLMs as\noptimization agents introduces risks due to their lack of explicit surrogate\nmodeling and calibrated uncertainty, as well as their inherently opaque\ninternal mechanisms. This structural opacity makes it difficult to characterize\nor control the exploration-exploitation trade-off, ultimately undermining\ntheoretical tractability and reliability. To address this, we propose LLINBO:\nLLM-in-the-Loop BO, a hybrid framework for BO that combines LLMs with\nstatistical surrogate experts (e.g., Gaussian Processes (GP)). The core\nphilosophy is to leverage contextual reasoning strengths of LLMs for early\nexploration, while relying on principled statistical models to guide efficient\nexploitation. Specifically, we introduce three mechanisms that enable this\ncollaboration and establish their theoretical guarantees. We end the paper with\na real-life proof-of-concept in the context of 3D printing. The code to\nreproduce the results can be found at\nhttps://github.com/UMDataScienceLab/LLM-in-the-Loop-BO.",
      "tldr_zh": "该论文提出 LLINBO，一种可信赖的 LLM-in-the-Loop Bayesian Optimization 框架，旨在解决 Large Language Models (LLMs) 在黑盒优化中存在的风险，如缺乏显式代理模型和不确定性校准。框架通过结合 LLMs 的上下文推理能力与统计代理专家（如 Gaussian Processes (GP)）的精确利用，引入三种协作机制来实现早期探索和高效利用，并提供理论保证。在 3D 打印的实际应用中，LLINBO 展示了显著的优化性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14756v1",
      "published_date": "2025-05-20 15:54:48 UTC",
      "updated_date": "2025-05-20 15:54:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:59:43.707272"
    },
    {
      "arxiv_id": "2505.14533v1",
      "title": "Energy-Efficient Deep Reinforcement Learning with Spiking Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Irfan Uddin",
        "Nishad Tasnim",
        "Md Omor Faruk",
        "Zejian Zhou"
      ],
      "abstract": "Agent-based Transformers have been widely adopted in recent reinforcement\nlearning advances due to their demonstrated ability to solve complex tasks.\nHowever, the high computational complexity of Transformers often results in\nsignificant energy consumption, limiting their deployment in real-world\nautonomous systems. Spiking neural networks (SNNs), with their biologically\ninspired structure, offer an energy-efficient alternative for machine learning.\nIn this paper, a novel Spike-Transformer Reinforcement Learning (STRL)\nalgorithm that combines the energy efficiency of SNNs with the powerful\ndecision-making capabilities of reinforcement learning is developed.\nSpecifically, an SNN using multi-step Leaky Integrate-and-Fire (LIF) neurons\nand attention mechanisms capable of processing spatio-temporal patterns over\nmultiple time steps is designed. The architecture is further enhanced with\nstate, action, and reward encodings to create a Transformer-like structure\noptimized for reinforcement learning tasks. Comprehensive numerical experiments\nconducted on state-of-the-art benchmarks demonstrate that the proposed SNN\nTransformer achieves significantly improved policy performance compared to\nconventional agent-based Transformers. With both enhanced energy efficiency and\npolicy optimality, this work highlights a promising direction for deploying\nbio-inspired, low-cost machine learning models in complex real-world\ndecision-making scenarios.",
      "tldr_zh": "本研究针对传统 Transformers 在强化学习（Reinforcement Learning）中的高能量消耗问题，提出了一种新型 Spike-Transformer Reinforcement Learning (STRL) 算法，将 Spiking Neural Networks (SNNs) 的能量效率与强化学习的决策能力相结合。算法采用多步 Leaky Integrate-and-Fire (LIF) 神经元和注意力机制，设计了一个能处理时空模式的 SNN 架构，并通过状态、动作和奖励编码优化为 Transformer-like 结构。实验结果显示，该 SNN Transformer 在基准测试中比传统模型显著提升策略性能，同时实现更高的能量效率，为生物启发的低成本机器学习在复杂决策场景中的部署提供了新方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14533v1",
      "published_date": "2025-05-20 15:52:43 UTC",
      "updated_date": "2025-05-20 15:52:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:59:54.976057"
    },
    {
      "arxiv_id": "2505.14526v1",
      "title": "NavBench: A Unified Robotics Benchmark for Reinforcement Learning-Based Autonomous Navigation",
      "title_zh": "NavBench：一个统一的机器人基准测试，用于基于强化学习的自主",
      "authors": [
        "Matteo El-Hariry",
        "Antoine Richard",
        "Ricard M. Castan",
        "Luis F. W. Batista",
        "Matthieu Geist",
        "Cedric Pradalier",
        "Miguel Olivares-Mendez"
      ],
      "abstract": "Autonomous robots must navigate and operate in diverse environments, from\nterrestrial and aquatic settings to aerial and space domains. While\nReinforcement Learning (RL) has shown promise in training policies for specific\nautonomous robots, existing benchmarks are often constrained to unique\nplatforms, limiting generalization and fair comparisons across different\nmobility systems. In this paper, we present NavBench, a multi-domain benchmark\nfor training and evaluating RL-based navigation policies across diverse robotic\nplatforms and operational environments. Built on IsaacLab, our framework\nstandardizes task definitions, enabling different robots to tackle various\nnavigation challenges without the need for ad-hoc task redesigns or custom\nevaluation metrics. Our benchmark addresses three key challenges: (1) Unified\ncross-medium benchmarking, enabling direct evaluation of diverse actuation\nmethods (thrusters, wheels, water-based propulsion) in realistic environments;\n(2) Scalable and modular design, facilitating seamless robot-task\ninterchangeability and reproducible training pipelines; and (3) Robust\nsim-to-real validation, demonstrated through successful policy transfer to\nmultiple real-world robots, including a satellite robotic simulator, an\nunmanned surface vessel, and a wheeled ground vehicle. By ensuring consistency\nbetween simulation and real-world deployment, NavBench simplifies the\ndevelopment of adaptable RL-based navigation strategies. Its modular design\nallows researchers to easily integrate custom robots and tasks by following the\nframework's predefined templates, making it accessible for a wide range of\napplications. Our code is publicly available at NavBench.",
      "tldr_zh": "该论文提出NavBench，一个统一的基准框架，用于基于Reinforcement Learning (RL)的自主导航训练和评估，支持从陆地、水上到空中和太空等多种机器人平台和环境。该框架构建于IsaacLab之上，通过标准化任务定义，解决了统一跨介质基准、可扩展模块化设计以及稳健的模拟到真实转移等关键挑战，并展示了策略成功应用于真实机器人，如卫星模拟器、无人水面船和轮式地面车辆。NavBench的模块化设计简化了自定义机器人和任务的集成，促进了RL导航策略的开发和比较，其代码已公开可用。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted for publication. Under review (2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.14526v1",
      "published_date": "2025-05-20 15:48:23 UTC",
      "updated_date": "2025-05-20 15:48:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:00:07.317040"
    },
    {
      "arxiv_id": "2505.14524v2",
      "title": "Guarded Query Routing for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Richard Šléher",
        "William Brach",
        "Tibor Sloboda",
        "Kristián Košťál",
        "Lukas Galke"
      ],
      "abstract": "Query routing, the task to route user queries to different large language\nmodel (LLM) endpoints, can be considered as a text classification problem.\nHowever, out-of-distribution queries must be handled properly, as those could\nbe questions about unrelated domains, queries in other languages, or even\ncontain unsafe text. Here, we thus study a guarded query routing problem, for\nwhich we first introduce the Guarded Query Routing Benchmark (GQR-Bench), which\ncovers three exemplary target domains (law, finance, and healthcare), and seven\ndatasets to test robustness against out-of-distribution queries. We then use\nGQR-Bench to contrast the effectiveness and efficiency of LLM-based routing\nmechanisms (GPT-4o-mini, Llama-3.2-3B, and Llama-3.1-8B), standard LLM-based\nguardrail approaches (LlamaGuard and NVIDIA NeMo Guardrails), continuous\nbag-of-words classifiers (WideMLP, fastText), and traditional machine learning\nmodels (SVM, XGBoost). Our results show that WideMLP, enhanced with\nout-of-domain detection capabilities, yields the best trade-off between\naccuracy (88%) and speed (<4ms). The embedding-based fastText excels at speed\n(<1ms) with acceptable accuracy (80%), whereas LLMs yield the highest accuracy\n(91%) but are comparatively slow (62ms for local Llama-3.1:8B and 669ms for\nremote GPT-4o-mini calls). Our findings challenge the automatic reliance on\nLLMs for (guarded) query routing and provide concrete recommendations for\npractical applications. GQR-Bench will be released as a Python package -- gqr.",
      "tldr_zh": "本研究探讨了针对大型语言模型(LLMs)的查询路由(query routing)问题，特别强调处理out-of-distribution查询（如无关领域或不安全文本）的鲁棒性，并引入了Guarded Query Routing Benchmark (GQR-Bench)，该基准覆盖法律、金融和医疗等领域，并包含七个数据集用于测试。研究比较了多种路由机制，包括LLM-based方法（如GPT-4o-mini和Llama模型）、守卫方法（如LlamaGuard和NVIDIA NeMo Guardrails）、以及传统模型（如WideMLP、fastText、SVM和XGBoost）。结果显示，WideMLP在添加out-of-domain检测后，提供了最佳的准确率（88%）和速度（<4ms）平衡，而fastText速度最快（<1ms，准确率80%），LLMs虽准确率最高（91%）但响应时间较长（62ms或669ms）；论文挑战了对LLMs的自动依赖，并为实际应用提供推荐，GQR-Bench将作为Python包发布。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14524v2",
      "published_date": "2025-05-20 15:46:59 UTC",
      "updated_date": "2025-05-22 07:29:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:00:22.309889"
    },
    {
      "arxiv_id": "2505.14523v1",
      "title": "Exploring Graph Representations of Logical Forms for Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Sullivan"
      ],
      "abstract": "We make the case for language models over logical forms (LFLMs), arguing that\nsuch models are more data-efficient than their textual counterparts. To that\nend, we introduce the Graph-based Formal-Logical Distributional Semantics\n(GFoLDS) prototype, a pretrained LM over graph representations of logical\nforms, as a proof-of-concept of LFLMs. Using GFoLDS, we present strong\nexperimental evidence that LFLMs can leverage the built-in, basic linguistic\nknowledge inherent in such models to immediately begin learning more complex\npatterns. On downstream tasks, we show that GFoLDS vastly outperforms textual,\ntransformer LMs pretrained on similar amounts of data, indicating that LFLMs\ncan learn with substantially less data than models over plain text.\nFurthermore, we show that the performance of this model is likely to scale with\nadditional parameters and pretraining data, suggesting the viability of LFLMs\nin real-world applications.",
      "tldr_zh": "本研究探讨了基于逻辑形式的语言模型 (LFLMs)，认为其比文本模型更数据高效，并引入 Graph-based Formal-Logical Distributional Semantics (GFoLDS) 原型作为在逻辑形式图表示上预训练的语言模型。GFoLDS 利用内置的基本语言知识，能够快速学习更复杂的模式，并在下游任务中显著优于基于类似数据量的 Transformer LMs。实验结果表明，LFLMs 可以用更少数据实现更好性能，且其表现随参数和预训练数据的增加而提升，显示出在实际应用中的可行性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "To be published in ACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2505.14523v1",
      "published_date": "2025-05-20 15:46:44 UTC",
      "updated_date": "2025-05-20 15:46:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:00:31.317123"
    },
    {
      "arxiv_id": "2505.14513v1",
      "title": "Latent Flow Transformer",
      "title_zh": "潜在流 Transformer",
      "authors": [
        "Yen-Chen Wu",
        "Feng-Ting Liao",
        "Meng-Hsi Chen",
        "Pei-Chen Ho",
        "Farhang Nabiei",
        "Da-shan Shiu"
      ],
      "abstract": "Transformers, the standard implementation for large language models (LLMs),\ntypically consist of tens to hundreds of discrete layers. While more layers can\nlead to better performance, this approach has been challenged as far from\nefficient, especially given the superiority of continuous layers demonstrated\nby diffusion and flow-based models for image generation. We propose the Latent\nFlow Transformer (LFT), which replaces a block of layers with a single learned\ntransport operator trained via flow matching, offering significant compression\nwhile maintaining compatibility with the original architecture. Additionally,\nwe address the limitations of existing flow-based methods in \\textit{preserving\ncoupling} by introducing the Flow Walking (FW) algorithm. On the Pythia-410M\nmodel, LFT trained with flow matching compresses 6 of 24 layers and outperforms\ndirectly skipping 2 layers (KL Divergence of LM logits at 0.407 vs. 0.529),\ndemonstrating the feasibility of this design. When trained with FW, LFT further\ndistills 12 layers into one while reducing the KL to 0.736 surpassing that from\nskipping 3 layers (0.932), significantly narrowing the gap between\nautoregressive and flow-based generation paradigms.",
      "tldr_zh": "本研究提出Latent Flow Transformer (LFT)，一种高效的Transformer架构创新，将多个离散层替换为一个通过流匹配(flow matching)训练的传输算子，从而实现模型压缩，同时保持与原架构的兼容性。LFT解决了传统流方法在保持耦合方面的局限，通过引入Flow Walking (FW)算法，进一步优化了层级浓缩。在Pythia-410M模型实验中，LFT压缩6层中的24层后，KL Divergence降至0.407，优于直接跳过2层（0.529）；使用FW训练时，将12层浓缩为一个层，将KL降至0.736，超越跳过3层（0.932），显著缩小了自回归和基于流生成范式之间的差距。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14513v1",
      "published_date": "2025-05-20 15:41:05 UTC",
      "updated_date": "2025-05-20 15:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:00:43.128041"
    },
    {
      "arxiv_id": "2505.14510v2",
      "title": "BACON: A fully explainable AI model with graded logic for decision making problems",
      "title_zh": "BACON：一种基于分级逻辑的完全可解释AI模型，用于决策问题",
      "authors": [
        "Haishi Bai",
        "Jozo Dujmovic",
        "Jianwu Wang"
      ],
      "abstract": "As machine learning models and autonomous agents are increasingly deployed in\nhigh-stakes, real-world domains such as healthcare, security, finance, and\nrobotics, the need for transparent and trustworthy explanations has become\ncritical. To ensure end-to-end transparency of AI decisions, we need models\nthat are not only accurate but also fully explainable and human-tunable. We\nintroduce BACON, a novel framework for automatically training explainable AI\nmodels for decision making problems using graded logic. BACON achieves high\npredictive accuracy while offering full structural transparency and precise,\nlogic-based symbolic explanations, enabling effective human-AI collaboration\nand expert-guided refinement. We evaluate BACON with a diverse set of\nscenarios: classic Boolean approximation, Iris flower classification, house\npurchasing decisions and breast cancer diagnosis. In each case, BACON provides\nhigh-performance models while producing compact, human-verifiable decision\nlogic. These results demonstrate BACON's potential as a practical and\nprincipled approach for delivering crisp, trustworthy explainable AI.",
      "tldr_zh": "该研究引入了BACON框架，这是一种使用graded logic自动训练可解释AI模型的方法，旨在为决策问题提供高预测准确性、全结构透明以及精确的逻辑-based符号解释，从而支持人类-AI协作和专家指导。BACON通过端到端透明设计，解决了AI在高风险领域（如医疗、金融和机器人）中的可信解释需求，并在多个场景中进行了评估，包括布尔逼近、Iris花分类、房屋购买决策和乳腺癌诊断。结果显示，BACON生成了高性能且紧凑的人类可验证决策逻辑，证明了其作为可靠解释AI的实用性和原则性潜力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14510v2",
      "published_date": "2025-05-20 15:39:05 UTC",
      "updated_date": "2025-05-22 15:50:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:00:54.824240"
    },
    {
      "arxiv_id": "2505.14505v1",
      "title": "ModRWKV: Transformer Multimodality in Linear Time",
      "title_zh": "翻译失败",
      "authors": [
        "Jiale Kang",
        "Ziyin Yue",
        "Qingyu Yin",
        "Jiang Rui",
        "Weile Li",
        "Zening Lu",
        "Zhouran Ji"
      ],
      "abstract": "Currently, most multimodal studies are based on large language models (LLMs)\nwith quadratic-complexity Transformer architectures. While linear models like\nRNNs enjoy low inference costs, their application has been largely limited to\nthe text-only modality. This work explores the capabilities of modern RNN\narchitectures in multimodal contexts. We propose ModRWKV-a decoupled multimodal\nframework built upon the RWKV7 architecture as its LLM backbone-which achieves\nmulti-source information fusion through dynamically adaptable heterogeneous\nmodality encoders. We designed the multimodal modules in ModRWKV with an\nextremely lightweight architecture and, through extensive experiments,\nidentified a configuration that achieves an optimal balance between performance\nand computational efficiency. ModRWKV leverages the pretrained weights of the\nRWKV7 LLM for initialization, which significantly accelerates multimodal\ntraining. Comparative experiments with different pretrained checkpoints further\ndemonstrate that such initialization plays a crucial role in enhancing the\nmodel's ability to understand multimodal signals. Supported by extensive\nexperiments, we conclude that modern RNN architectures present a viable\nalternative to Transformers in the domain of multimodal large language models\n(MLLMs). Furthermore, we identify the optimal configuration of the ModRWKV\narchitecture through systematic exploration.",
      "tldr_zh": "该研究提出 ModRWKV，一种基于 RWKV7 架构的线性时间多模态框架，旨在取代传统二次复杂度 Transformer 模型，用于处理多源信息融合。ModRWKV 采用动态适应性异构模态编码器（dynamically adaptable heterogeneous modality encoders）和轻量级模块设计，利用 RWKV7 的预训练权重初始化来加速训练并提升模型对多模态信号的理解能力。通过广泛实验，该框架在性能与计算效率间达到最佳平衡，并证明现代 RNN 架构是 Multimodal Large Language Models (MLLMs) 的可行替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14505v1",
      "published_date": "2025-05-20 15:34:36 UTC",
      "updated_date": "2025-05-20 15:34:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:01:07.512191"
    },
    {
      "arxiv_id": "2505.14499v1",
      "title": "Enhanced Multimodal Aspect-Based Sentiment Analysis by LLM-Generated Rationales",
      "title_zh": "通过 LLM 生成的理由增强的多模态基于方面的情感分析",
      "authors": [
        "Jun Cao",
        "Jiyi Li",
        "Ziwei Yang",
        "Renjie Zhou"
      ],
      "abstract": "There has been growing interest in Multimodal Aspect-Based Sentiment Analysis\n(MABSA) in recent years. Existing methods predominantly rely on pre-trained\nsmall language models (SLMs) to collect information related to aspects and\nsentiments from both image and text, with an aim to align these two modalities.\nHowever, small SLMs possess limited capacity and knowledge, often resulting in\ninaccurate identification of meaning, aspects, sentiments, and their\ninterconnections in textual and visual data. On the other hand, Large language\nmodels (LLMs) have shown exceptional capabilities in various tasks by\neffectively exploring fine-grained information in multimodal data. However,\nsome studies indicate that LLMs still fall short compared to fine-tuned small\nmodels in the field of ABSA. Based on these findings, we propose a novel\nframework, termed LRSA, which combines the decision-making capabilities of SLMs\nwith additional information provided by LLMs for MABSA. Specifically, we inject\nexplanations generated by LLMs as rationales into SLMs and employ a dual\ncross-attention mechanism for enhancing feature interaction and fusion, thereby\naugmenting the SLMs' ability to identify aspects and sentiments. We evaluated\nour method using two baseline models, numerous experiments highlight the\nsuperiority of our approach on three widely-used benchmarks, indicating its\ngeneralizability and applicability to most pre-trained models for MABSA.",
      "tldr_zh": "本文提出了一种名为 LRSA 的新框架，用于提升 Multimodal Aspect-Based Sentiment Analysis (MABSA)，通过利用 Large Language Models (LLMs) 生成的解释作为理由注入 Small Language Models (SLMs)，并采用双交叉注意力机制增强多模态特征的交互和融合，以解决 SLMs 在识别方面和情感方面的局限性。相比现有方法，LRSA 结合了 LLMs 的强大知识能力和 SLMs 的决策优势，有效改善了 ABSA 任务的准确性。实验结果显示，该框架在三个常用基准上优于基线模型，证明了其泛化性和对大多数预训练 MABSA 模型的适用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14499v1",
      "published_date": "2025-05-20 15:28:26 UTC",
      "updated_date": "2025-05-20 15:28:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:01:20.332019"
    },
    {
      "arxiv_id": "2505.14489v1",
      "title": "Reasoning Models Better Express Their Confidence",
      "title_zh": "推理模型更好地表达它们的置信度",
      "authors": [
        "Dongkeun Yoon",
        "Seungone Kim",
        "Sohee Yang",
        "Sunkyoung Kim",
        "Soyeon Kim",
        "Yongil Kim",
        "Eunbi Choi",
        "Yireun Kim",
        "Minjoon Seo"
      ],
      "abstract": "Despite their strengths, large language models (LLMs) often fail to\ncommunicate their confidence accurately, making it difficult to assess when\nthey might be wrong and limiting their reliability. In this work, we\ndemonstrate that reasoning models-LLMs that engage in extended chain-of-thought\n(CoT) reasoning-exhibit superior performance not only in problem-solving but\nalso in accurately expressing their confidence. Specifically, we benchmark six\nreasoning models across six datasets and find that they achieve strictly better\nconfidence calibration than their non-reasoning counterparts in 33 out of the\n36 settings. Our detailed analysis reveals that these gains in calibration stem\nfrom the slow thinking behaviors of reasoning models-such as exploring\nalternative approaches and backtracking-which enable them to adjust their\nconfidence dynamically throughout their CoT, making it progressively more\naccurate. In particular, we find that reasoning models become increasingly\nbetter calibrated as their CoT unfolds, a trend not observed in non-reasoning\nmodels. Moreover, removing slow thinking behaviors from the CoT leads to a\nsignificant drop in calibration. Lastly, we show that these gains are not\nexclusive to reasoning models-non-reasoning models also benefit when guided to\nperform slow thinking via in-context learning.",
      "tldr_zh": "本研究发现，大语言模型(LLMs)往往无法准确表达自信心，从而影响其可靠性，而采用扩展链式思维(CoT)的推理模型在问题解决和自信心校准上表现出色。研究者对六种推理模型在六种数据集上进行基准测试，结果显示这些模型在36个设置中的33个中，均优于非推理模型。分析揭示，这种优势源于推理模型的“慢思考”行为，如探索替代方法和回溯，使其自信心在CoT过程中动态调整并逐步精确化；移除这些行为会导致校准显著下降。此外，非推理模型通过上下文学习引导慢思考也能获得类似益处，为提升模型可靠性提供新路径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2505.14489v1",
      "published_date": "2025-05-20 15:19:00 UTC",
      "updated_date": "2025-05-20 15:19:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:01:31.272806"
    },
    {
      "arxiv_id": "2505.14479v1",
      "title": "Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Oren Sultan",
        "Eitan Stern",
        "Dafna Shahaf"
      ],
      "abstract": "Large language models (LLMs) struggle with formal domains that require\nrigorous logical deduction and symbolic reasoning, such as mathematical proof\ngeneration. We propose a neuro-symbolic approach that combines LLMs' generative\nstrengths with structured components to overcome this challenge. As a\nproof-of-concept, we focus on geometry problems. Our approach is two-fold: (1)\nwe retrieve analogous problems and use their proofs to guide the LLM, and (2) a\nformal verifier evaluates the generated proofs and provides feedback, helping\nthe model fix incorrect proofs. We demonstrate that our method significantly\nimproves proof accuracy for OpenAI's o1 model (58%-70% improvement); both\nanalogous problems and the verifier's feedback contribute to these gains. More\nbroadly, shifting to LLMs that generate provably correct conclusions could\ndramatically improve their reliability, accuracy and consistency, unlocking\ncomplex tasks and critical real-world applications that require\ntrustworthiness.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在需要严格逻辑和符号推理的领域（如数学证明生成）中的不足，提出了一种神经符号(neuro-symbolic)方法，将LLMs的生成能力与结构化组件相结合。方法包括检索类似问题及其证明来指导模型生成，以及使用正式验证器评估证明并提供反馈以修复错误。在几何问题上，该方法显著提升了OpenAI's o1模型的证明准确率（58%-70%）。总体而言，这种方法可增强LLMs的可靠性、准确性和一致性，推动其在复杂任务和关键现实应用中的可信度。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "long paper",
      "pdf_url": "http://arxiv.org/pdf/2505.14479v1",
      "published_date": "2025-05-20 15:13:32 UTC",
      "updated_date": "2025-05-20 15:13:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:01:43.083722"
    },
    {
      "arxiv_id": "2505.14469v1",
      "title": "Attributional Safety Failures in Large Language Models under Code-Mixed Perturbations",
      "title_zh": "翻译失败",
      "authors": [
        "Somnath Banerjee",
        "Pratyush Chatterjee",
        "Shanu Kumar",
        "Sayan Layek",
        "Parag Agrawal",
        "Rima Hazra",
        "Animesh Mukherjee"
      ],
      "abstract": "Recent advancements in LLMs have raised significant safety concerns,\nparticularly when dealing with code-mixed inputs and outputs. Our study\nsystematically investigates the increased susceptibility of LLMs to produce\nunsafe outputs from code-mixed prompts compared to monolingual English prompts.\nUtilizing explainability methods, we dissect the internal attribution shifts\ncausing model's harmful behaviors. In addition, we explore cultural dimensions\nby distinguishing between universally unsafe and culturally-specific unsafe\nqueries. This paper presents novel experimental insights, clarifying the\nmechanisms driving this phenomenon.",
      "tldr_zh": "这篇论文研究了大型语言模型（LLMs）在处理code-mixed扰动时的归因安全失败问题，系统比较了code-mixed提示与单语英语提示下模型产生不安全输出的易感性。作者利用explainability methods分析内部attribution shifts，揭示了导致有害行为的机制，并探讨了文化维度以区分universally unsafe和culturally-specific unsafe查询。实验结果提供了新的洞见，阐明了这一现象的驱动因素，并为提升LLMs的安全性提供了重要启发。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14469v1",
      "published_date": "2025-05-20 15:05:03 UTC",
      "updated_date": "2025-05-20 15:05:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:01:54.812174"
    },
    {
      "arxiv_id": "2505.14455v1",
      "title": "CtrlDiff: Boosting Large Diffusion Language Models with Dynamic Block Prediction and Controllable Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Chihan Huang",
        "Hao Tang"
      ],
      "abstract": "Although autoregressive models have dominated language modeling in recent\nyears, there has been a growing interest in exploring alternative paradigms to\nthe conventional next-token prediction framework. Diffusion-based language\nmodels have emerged as a compelling alternative due to their powerful parallel\ngeneration capabilities and inherent editability. However, these models are\noften constrained by fixed-length generation. A promising direction is to\ncombine the strengths of both paradigms, segmenting sequences into blocks,\nmodeling autoregressive dependencies across blocks while leveraging discrete\ndiffusion to estimate the conditional distribution within each block given the\npreceding context. Nevertheless, their practical application is often hindered\nby two key limitations: rigid fixed-length outputs and a lack of flexible\ncontrol mechanisms. In this work, we address the critical limitations of fixed\ngranularity and weak controllability in current large diffusion language\nmodels. We propose CtrlDiff, a dynamic and controllable semi-autoregressive\nframework that adaptively determines the size of each generation block based on\nlocal semantics using reinforcement learning. Furthermore, we introduce a\nclassifier-guided control mechanism tailored to discrete diffusion, which\nsignificantly reduces computational overhead while facilitating efficient\npost-hoc conditioning without retraining. Extensive experiments demonstrate\nthat CtrlDiff sets a new standard among hybrid diffusion models, narrows the\nperformance gap to state-of-the-art autoregressive approaches, and enables\neffective conditional text generation across diverse tasks.",
      "tldr_zh": "本研究提出 CtrlDiff，一种动态可控的半自回归框架，用于提升大型扩散语言模型（diffusion language models）的性能。该框架通过强化学习动态调整生成块的大小，根据本地语义自适应预测块间依赖，同时引入分类器引导的控制机制，减少计算开销并支持高效的后验条件生成，而无需重新训练。相比传统自回归模型（autoregressive models），CtrlDiff 在混合扩散模型中设定新标准，显著缩小性能差距，并在多种条件文本生成任务上表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14455v1",
      "published_date": "2025-05-20 14:52:41 UTC",
      "updated_date": "2025-05-20 14:52:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:02:06.225164"
    },
    {
      "arxiv_id": "2505.14452v2",
      "title": "How Managers Perceive AI-Assisted Conversational Training for Workplace Communication",
      "title_zh": "管理者如何感知 AI 辅助的对话训练用于工作场所沟通",
      "authors": [
        "Lance T. Wilhelm",
        "Xiaohan Ding",
        "Kirk McInnis Knutsen",
        "Buse Carik",
        "Eugenia H. Rho"
      ],
      "abstract": "Effective workplace communication is essential for managerial success, yet\nmany managers lack access to tailored and sustained training. Although\nAI-assisted communication systems may offer scalable training solutions, little\nis known about how managers envision the role of AI in helping them improve\ntheir communication skills. To investigate this, we designed a conversational\nrole-play system, CommCoach, as a functional probe to understand how managers\nanticipate using AI to practice their communication skills. Through\nsemi-structured interviews, participants emphasized the value of adaptive,\nlow-risk simulations for practicing difficult workplace conversations. They\nalso highlighted opportunities, including human-AI teaming, transparent and\ncontext-aware feedback, and greater control over AI-generated personas.\nAI-assisted communication training should balance personalization, structured\nlearning objectives, and adaptability to different user styles and contexts.\nHowever, achieving this requires carefully navigating tensions between adaptive\nand consistent AI feedback, realism and potential bias, and the open-ended\nnature of AI conversations versus structured workplace discourse.",
      "tldr_zh": "该研究探讨了经理对 AI 辅助对话训练在工作场所沟通中的看法，因为许多经理缺乏量身定制的持续培训。研究者设计了 CommCoach 系统——一个对话角色扮演工具——作为功能性探针，通过半结构化访谈了解经理如何预期使用 AI 练习沟通技能。参与者强调了适应性、低风险模拟的价值，以及 human-AI teaming、透明反馈和对 AI 生成角色的控制等机会。论文建议，AI 辅助沟通培训应平衡个性化、结构化学习目标和适应性，同时小心处理反馈一致性与适应性、现实性与偏差，以及开放对话与结构化话语之间的张力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "accepted to CUI '25",
      "pdf_url": "http://arxiv.org/pdf/2505.14452v2",
      "published_date": "2025-05-20 14:51:27 UTC",
      "updated_date": "2025-05-21 16:59:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:02:20.165096"
    },
    {
      "arxiv_id": "2505.14451v1",
      "title": "RefiDiff: Refinement-Aware Diffusion for Efficient Missing Data Imputation",
      "title_zh": "翻译失败",
      "authors": [
        "Md Atik Ahamed",
        "Qiang Ye",
        "Qiang Cheng"
      ],
      "abstract": "Missing values in high-dimensional, mixed-type datasets pose significant\nchallenges for data imputation, particularly under Missing Not At Random (MNAR)\nmechanisms. Existing methods struggle to integrate local and global data\ncharacteristics, limiting performance in MNAR and high-dimensional settings. We\npropose an innovative framework, RefiDiff, combining local machine learning\npredictions with a novel Mamba-based denoising network capturing\ninterrelationships among distant features and samples. Our approach leverages\npre-refinement for initial warm-up imputations and post-refinement to polish\nresults, enhancing stability and accuracy. By encoding mixed-type data into\nunified tokens, RefiDiff enables robust imputation without architectural or\nhyperparameter tuning. RefiDiff outperforms state-of-the-art (SOTA) methods\nacross missing-value settings, excelling in MNAR with a 4x faster training time\nthan SOTA DDPM-based approaches. Extensive evaluations on nine real-world\ndatasets demonstrate its robustness, scalability, and effectiveness in handling\ncomplex missingness patterns.",
      "tldr_zh": "该研究提出 RefiDiff 框架，用于高效处理高维混合类型数据集中的缺失值问题，尤其针对 Missing Not At Random (MNAR) 机制，解决现有方法在整合局部和全局数据特征方面的局限性。RefiDiff 结合局部机器学习预测与 Mamba-based 去噪网络，通过预精炼（pre-refinement）进行初始填充和后精炼（post-refinement）完善结果，并将混合类型数据编码为统一 tokens，无需架构或超参数调整。实验结果显示，RefiDiff 在各种缺失值设置下优于最先进（SOTA）方法，在 MNAR 场景中训练速度快 4 倍，并在九个真实世界数据集上证明了其鲁棒性、可扩展性和处理复杂缺失模式的能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14451v1",
      "published_date": "2025-05-20 14:51:07 UTC",
      "updated_date": "2025-05-20 14:51:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:02:32.372044"
    },
    {
      "arxiv_id": "2505.14442v1",
      "title": "Creative Preference Optimization",
      "title_zh": "创造性偏好优化",
      "authors": [
        "Mete Ismayilzada",
        "Antonio Laverghetta Jr.",
        "Simone A. Luchini",
        "Reet Patel",
        "Antoine Bosselut",
        "Lonneke van der Plas",
        "Roger Beaty"
      ],
      "abstract": "While Large Language Models (LLMs) have demonstrated impressive performance\nacross natural language generation tasks, their ability to generate truly\ncreative content-characterized by novelty, diversity, surprise, and\nquality-remains limited. Existing methods for enhancing LLM creativity often\nfocus narrowly on diversity or specific tasks, failing to address creativity's\nmultifaceted nature in a generalizable way. In this work, we propose Creative\nPreference Optimization (CrPO), a novel alignment method that injects signals\nfrom multiple creativity dimensions into the preference optimization objective\nin a modular fashion. We train and evaluate creativity-augmented versions of\nseveral models using CrPO and MuCE, a new large-scale human preference dataset\nspanning over 200,000 human-generated responses and ratings from more than 30\npsychological creativity assessments. Our models outperform strong baselines,\nincluding GPT-4o, on both automated and human evaluations, producing more\nnovel, diverse, and surprising generations while maintaining high output\nquality. Additional evaluations on NoveltyBench further confirm the\ngeneralizability of our approach. Together, our results demonstrate that\ndirectly optimizing for creativity within preference frameworks is a promising\ndirection for advancing the creative capabilities of LLMs without compromising\noutput quality.",
      "tldr_zh": "这篇论文提出 Creative Preference Optimization (CrPO)，一种新型对齐方法，用于提升 Large Language Models (LLMs) 在生成创意内容（如新颖性、多样性、惊喜和质量）方面的能力，通过模块化方式将多个创意维度信号注入偏好优化目标。作者构建了新数据集 MuCE（包含超过20万人类生成响应和30多种心理创意评估），并使用它训练和评估几个增强模型。实验结果显示，CrPO模型在自动和人类评估中优于GPT-4o等基线，生成更具新颖性和多样性的内容，同时保持高输出质量，并在NoveltyBench上证明了其泛化性。总的来说，这一方法为在偏好框架中优化LLMs的创意能力提供了可行路径，而不牺牲性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "27 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.14442v1",
      "published_date": "2025-05-20 14:43:41 UTC",
      "updated_date": "2025-05-20 14:43:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:02:43.217377"
    },
    {
      "arxiv_id": "2505.14436v1",
      "title": "Neural Incompatibility: The Unbridgeable Gap of Cross-Scale Parametric Knowledge Transfer in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqiao Tan",
        "Shizhu He",
        "Kang Liu",
        "Jun Zhao"
      ],
      "abstract": "Large Language Models (LLMs) offer a transparent brain with accessible\nparameters that encode extensive knowledge, which can be analyzed, located and\ntransferred. Consequently, a key research challenge is to transcend traditional\nknowledge transfer paradigms rooted in symbolic language and achieve genuine\nParametric Knowledge Transfer (PKT). Significantly, exploring effective methods\nfor transferring knowledge across LLMs of different scales through parameters\npresents an intriguing and valuable research direction. In this paper, we first\ndemonstrate $\\textbf{Alignment}$ in parametric space is the fundamental\nprerequisite to achieve successful cross-scale PKT. We redefine the previously\nexplored knowledge transfer as Post-Align PKT (PostPKT), which utilizes\nextracted parameters for LoRA initialization and requires subsequent fine-tune\nfor alignment. Hence, to reduce cost for further fine-tuning, we introduce a\nnovel Pre-Align PKT (PrePKT) paradigm and propose a solution called\n$\\textbf{LaTen}$\n($\\textbf{L}$oc$\\textbf{a}$te-$\\textbf{T}$h$\\textbf{e}$n-Alig$\\textbf{n}$) that\naligns the parametric spaces of LLMs across scales only using several training\nsteps without following training. Comprehensive experiments on four benchmarks\ndemonstrate that both PostPKT and PrePKT face challenges in achieving\nconsistently stable transfer. Through in-depth analysis, we identify\n$\\textbf{Neural Incompatibility}$ as the ethological and parametric structural\ndifferences between LLMs of varying scales, presenting fundamental challenges\nto achieving effective PKT. These findings provide fresh insights into the\nparametric architectures of LLMs and highlight promising directions for future\nresearch on efficient PKT. Our code is available at\nhttps://github.com/Trae1ounG/Neural_Incompatibility.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs)中跨规模Parametric Knowledge Transfer (PKT)的挑战，强调参数空间的Alignment是成功知识转移的关键先决条件。论文引入Post-Align PKT (PostPKT)方法，利用提取的参数初始化LoRA并进行后续微调，同时提出创新的Pre-Align PKT (PrePKT)范式和LaTen方法，通过少数训练步骤预先对齐不同规模LLMs的参数空间，以减少微调成本。实验在四个基准上显示，这两种方法均面临稳定转移的困难，并首次识别Neural Incompatibility作为不同规模LLMs之间参数结构差异的根本障碍，为未来高效PKT研究提供新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL'25 Main. Code link:\n  https://github.com/Trae1ounG/Neural_Incompatibility",
      "pdf_url": "http://arxiv.org/pdf/2505.14436v1",
      "published_date": "2025-05-20 14:42:03 UTC",
      "updated_date": "2025-05-20 14:42:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:02:56.241818"
    },
    {
      "arxiv_id": "2505.14435v1",
      "title": "Choosing a Model, Shaping a Future: Comparing LLM Perspectives on Sustainability and its Relationship with AI",
      "title_zh": "选择模型，塑造未来：比较LLM对可持续性和其与AI关系的观点",
      "authors": [
        "Annika Bush",
        "Meltem Aksoy",
        "Markus Pauly",
        "Greta Ontrup"
      ],
      "abstract": "As organizations increasingly rely on AI systems for decision support in\nsustainability contexts, it becomes critical to understand the inherent biases\nand perspectives embedded in Large Language Models (LLMs). This study\nsystematically investigates how five state-of-the-art LLMs -- Claude, DeepSeek,\nGPT, LLaMA, and Mistral - conceptualize sustainability and its relationship\nwith AI. We administered validated, psychometric sustainability-related\nquestionnaires - each 100 times per model -- to capture response patterns and\nvariability. Our findings revealed significant inter-model differences: For\nexample, GPT exhibited skepticism about the compatibility of AI and\nsustainability, whereas LLaMA demonstrated extreme techno-optimism with perfect\nscores for several Sustainable Development Goals (SDGs). Models also diverged\nin attributing institutional responsibility for AI and sustainability\nintegration, a results that holds implications for technology governance\napproaches. Our results demonstrate that model selection could substantially\ninfluence organizational sustainability strategies, highlighting the need for\nawareness of model-specific biases when deploying LLMs for\nsustainability-related decision-making.",
      "tldr_zh": "这篇论文比较了五个先进LLMs（Claude、DeepSeek、GPT、LLaMA和Mistral）对可持续性和AI关系的不同观点，旨在揭示这些模型固有的偏见。研究通过对每个模型进行100次验证的心理测量问卷测试，系统捕获了响应模式和变异性。关键发现包括GPT对AI与可持续性兼容性持怀疑态度，而LLaMA在多个Sustainable Development Goals (SDGs)上表现出极度科技乐观主义；此外，模型在AI和可持续性整合的责任归属上存在分歧。总体结果强调，模型选择可能显著影响组织的可持续性策略，因此在部署LLMs用于相关决策时需警惕模型特定偏见。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14435v1",
      "published_date": "2025-05-20 14:41:56 UTC",
      "updated_date": "2025-05-20 14:41:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:03:07.798897"
    },
    {
      "arxiv_id": "2505.14428v1",
      "title": "Interpretable Neural System Dynamics: Combining Deep Learning with System Dynamics Modeling to Support Critical Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Riccardo D'Elia"
      ],
      "abstract": "The objective of this proposal is to bridge the gap between Deep Learning\n(DL) and System Dynamics (SD) by developing an interpretable neural system\ndynamics framework. While DL excels at learning complex models and making\naccurate predictions, it lacks interpretability and causal reliability.\nTraditional SD approaches, on the other hand, provide transparency and causal\ninsights but are limited in scalability and require extensive domain knowledge.\nTo overcome these limitations, this project introduces a Neural System Dynamics\npipeline, integrating Concept-Based Interpretability, Mechanistic\nInterpretability, and Causal Machine Learning. This framework combines the\npredictive power of DL with the interpretability of traditional SD models,\nresulting in both causal reliability and scalability. The efficacy of the\nproposed pipeline will be validated through real-world applications of the\nEU-funded AutoMoTIF project, which is focused on autonomous multimodal\ntransportation systems. The long-term goal is to collect actionable insights\nthat support the integration of explainability and safety in autonomous\nsystems.",
      "tldr_zh": "本研究提出了一种可解释的神经系统动态框架，将 Deep Learning (DL) 与 System Dynamics (SD) 相结合，旨在解决 DL 的可解释性和因果可靠性不足，以及 SD 的可扩展性和依赖领域知识的局限性。\n该框架通过整合 Concept-Based Interpretability、Mechanistic Interpretability 和 Causal Machine Learning，实现 DL 的强大预测能力与 SD 的透明因果洞察相结合，提高了整体的可扩展性和可靠性。\n通过 EU-funded AutoMoTIF 项目在自主多模态交通系统中的实际应用验证，该方法将提供可行动的见解，支持自主系统的解释性和安全性集成。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "To be submitted to CEUR-WS.org for publication in the Doctoral\n  Consortium Proceedings of XAI 2025, The World Conference on Explainable\n  Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2505.14428v1",
      "published_date": "2025-05-20 14:38:39 UTC",
      "updated_date": "2025-05-20 14:38:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:03:19.752057"
    },
    {
      "arxiv_id": "2505.14419v1",
      "title": "SCOPE: Compress Mathematical Reasoning Steps for Efficient Automated Process Annotation",
      "title_zh": "翻译失败",
      "authors": [
        "Huimin Xu",
        "Xin Mao",
        "Feng-Lin Li",
        "Xiaobao Wu",
        "Wang Chen",
        "Wei Zhang",
        "Anh Tuan Luu"
      ],
      "abstract": "Process Reward Models (PRMs) have demonstrated promising results in\nmathematical reasoning, but existing process annotation approaches, whether\nthrough human annotations or Monte Carlo simulations, remain computationally\nexpensive. In this paper, we introduce Step COmpression for Process Estimation\n(SCOPE), a novel compression-based approach that significantly reduces\nannotation costs. We first translate natural language reasoning steps into code\nand normalize them through Abstract Syntax Tree, then merge equivalent steps to\nconstruct a prefix tree. Unlike simulation-based methods that waste numerous\nsamples on estimation, SCOPE leverages a compression-based prefix tree where\neach root-to-leaf path serves as a training sample, reducing the complexity\nfrom $O(NMK)$ to $O(N)$. We construct a large-scale dataset containing 196K\nsamples with only 5% of the computational resources required by previous\nmethods. Empirical results demonstrate that PRMs trained on our dataset\nconsistently outperform existing automated annotation approaches on both\nBest-of-N strategy and ProcessBench.",
      "tldr_zh": "该论文提出了一种名为 SCOPE 的方法，用于压缩数学推理步骤，从而高效地进行自动化过程标注（Automated Process Annotation）。SCOPE 通过将自然语言推理步骤转化为代码，并利用 Abstract Syntax Tree (AST) 进行规范化，然后合并等效步骤构建前缀树，将训练样本复杂度从 O(NMK) 降低到 O(N)，显著减少了计算资源需求。研究者构建了一个包含 196K 样本的大型数据集，仅需现有方法的 5% 计算资源。实验结果显示，使用该数据集训练的 Process Reward Models (PRMs) 在 Best-of-N strategy 和 ProcessBench 上 consistently outperform 现有自动标注方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14419v1",
      "published_date": "2025-05-20 14:31:15 UTC",
      "updated_date": "2025-05-20 14:31:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:03:31.519942"
    },
    {
      "arxiv_id": "2505.14412v1",
      "title": "PRL: Prompts from Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Paweł Batorski",
        "Adrian Kosmala",
        "Paul Swoboda"
      ],
      "abstract": "Effective prompt engineering remains a central challenge in fully harnessing\nthe capabilities of LLMs. While well-designed prompts can dramatically enhance\nperformance, crafting them typically demands expert intuition and a nuanced\nunderstanding of the task. Moreover, the most impactful prompts often hinge on\nsubtle semantic cues, ones that may elude human perception but are crucial for\nguiding LLM behavior. In this paper, we introduce PRL (Prompts from\nReinforcement Learning), a novel RL-based approach for automatic prompt\ngeneration. Unlike previous methods, PRL can produce novel few-shot examples\nthat were not seen during training. Our approach achieves state-of-the-art\nperformance across a range of benchmarks, including text classification,\nsimplification, and summarization. On the classification task, it surpasses\nprior methods by 2.58% over APE and 1.00% over EvoPrompt. Additionally, it\nimproves the average ROUGE scores on the summarization task by 4.32 over APE\nand by 2.12 over EvoPrompt and the SARI score on simplification by 6.93 over\nAPE and by 6.01 over EvoPrompt. Our code is available at\nhttps://github.com/Batorskq/prl .",
      "tldr_zh": "本论文提出PRL（Prompts from Reinforcement Learning），一种基于Reinforcement Learning的自动提示生成方法，以解决大型语言模型（LLMs）提示工程的挑战，例如依赖专家直觉和微妙语义线索。PRL创新性地生成训练中未见的新few-shot例子，并在文本分类、简化及总结任务上实现最先进性能。相比APE，PRL在分类任务上提升2.58%、在总结任务上ROUGE分数平均提高4.32%、在简化任务上SARI分数提升6.93%；相比EvoPrompt，则分别提升1.00%、2.12%和6.01%。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14412v1",
      "published_date": "2025-05-20 14:26:19 UTC",
      "updated_date": "2025-05-20 14:26:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:03:43.834472"
    },
    {
      "arxiv_id": "2505.14403v1",
      "title": "Unearthing Gems from Stones: Policy Optimization with Negative Sample Augmentation for LLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaohui Yang",
        "Shilei Jiang",
        "Chen Hu",
        "Linjing Li",
        "Shihong Deng",
        "Daxin Jiang"
      ],
      "abstract": "Recent advances in reasoning language models have witnessed a paradigm shift\nfrom short to long CoT pattern. Given the substantial computational cost of\nrollouts in long CoT models, maximizing the utility of fixed training datasets\nbecomes crucial. Our analysis reveals that negative responses contain valuable\ncomponents such as self-reflection and error-correction steps, yet primary\nexisting methods either completely discard negative samples (RFT) or apply\nequal penalization across all tokens (RL), failing to leverage these potential\nlearning signals. In light of this, we propose Behavior Constrained Policy\nGradient with Negative Sample Augmentation (BCPG-NSA), a fine-grained offline\nRL framework that encompasses three stages: 1) sample segmentation, 2)\nconsensus-based step correctness assessment combining LLM and PRM judgers, and\n3) policy optimization with NSA designed to effectively mine positive steps\nwithin negative samples. Experimental results show that BCPG-NSA outperforms\nbaselines on several challenging math/coding reasoning benchmarks using the\nsame training dataset, achieving improved sample efficiency and demonstrating\nrobustness and scalability when extended to multiple iterations.",
      "tldr_zh": "该论文针对长CoT（Chain-of-Thought）推理语言模型（LLM）的计算成本问题，提出BCPG-NSA（Behavior Constrained Policy Gradient with Negative Sample Augmentation）框架，通过负面样本增强来挖掘负面响应中的积极成分，如自我反思和错误修正步骤。框架包括三个阶段：样本分割、基于LLM和PRM judgers的共识步骤正确性评估，以及针对负面样本的政策优化，以最大化固定训练数据集的效用。实验结果表明，BCPG-NSA在使用相同数据集的情况下，在多个数学和编码推理基准上优于基线模型，提高了样本效率，并在扩展到多轮迭代时显示出稳健性和可扩展性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14403v1",
      "published_date": "2025-05-20 14:16:49 UTC",
      "updated_date": "2025-05-20 14:16:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:03:57.020527"
    },
    {
      "arxiv_id": "2505.14753v1",
      "title": "TransMedSeg: A Transferable Semantic Framework for Semi-Supervised Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Mengzhu Wang",
        "Jiao Li",
        "Shanshan Wang",
        "Long Lan",
        "Huibin Tan",
        "Liang Yang",
        "Guoli Yang"
      ],
      "abstract": "Semi-supervised learning (SSL) has achieved significant progress in medical\nimage segmentation (SSMIS) through effective utilization of limited labeled\ndata. While current SSL methods for medical images predominantly rely on\nconsistency regularization and pseudo-labeling, they often overlook\ntransferable semantic relationships across different clinical domains and\nimaging modalities. To address this, we propose TransMedSeg, a novel\ntransferable semantic framework for semi-supervised medical image segmentation.\nOur approach introduces a Transferable Semantic Augmentation (TSA) module,\nwhich implicitly enhances feature representations by aligning domain-invariant\nsemantics through cross-domain distribution matching and intra-domain\nstructural preservation. Specifically, TransMedSeg constructs a unified feature\nspace where teacher network features are adaptively augmented towards student\nnetwork semantics via a lightweight memory module, enabling implicit semantic\ntransformation without explicit data generation. Interestingly, this\naugmentation is implicitly realized through an expected transferable\ncross-entropy loss computed over the augmented teacher distribution. An upper\nbound of the expected loss is theoretically derived and minimized during\ntraining, incurring negligible computational overhead. Extensive experiments on\nmedical image datasets demonstrate that TransMedSeg outperforms existing\nsemi-supervised methods, establishing a new direction for transferable\nrepresentation learning in medical image analysis.",
      "tldr_zh": "该研究提出TransMedSeg，一种可转移语义框架，用于半监督医疗图像分割（SSMIS），旨在解决现有方法忽略跨域语义关系的问题。框架引入Transferable Semantic Augmentation (TSA) 模块，通过跨域分布匹配和域内结构保留来隐式增强特征表示，利用轻量级内存模块将教师网络特征适配到学生网络语义，并通过期望可转移交叉熵损失最小化上界以实现高效训练。与传统一致性正则化和伪标签方法相比，TransMedSeg在多个医疗图像数据集上表现出色，超越现有半监督方法，并为医疗图像分析的可转移表示学习开辟新方向。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14753v1",
      "published_date": "2025-05-20 14:16:40 UTC",
      "updated_date": "2025-05-20 14:16:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:04:07.391980"
    },
    {
      "arxiv_id": "2505.14398v1",
      "title": "Log-Augmented Generation: Scaling Test-Time Reasoning with Reusable Computation",
      "title_zh": "日志增强生成：利用可重用计算扩展测试时推理",
      "authors": [
        "Peter Baile Chen",
        "Yi Zhang",
        "Dan Roth",
        "Samuel Madden",
        "Jacob Andreas",
        "Michael Cafarella"
      ],
      "abstract": "While humans naturally learn and adapt from past experiences, large language\nmodels (LLMs) and their agentic counterparts struggle to retain reasoning from\nprevious tasks and apply them in future contexts. To address this limitation,\nwe propose a novel framework, log-augmented generation (LAG) that directly\nreuses prior computation and reasoning from past logs at test time to enhance\nmodel's ability to learn from previous tasks and perform better on new, unseen\nchallenges, all while keeping the system efficient and scalable. Specifically,\nour system represents task logs using key-value (KV) caches, encoding the full\nreasoning context of prior tasks while storing KV caches for only a selected\nsubset of tokens. When a new task arises, LAG retrieves the KV values from\nrelevant logs to augment generation. Our approach differs from reflection-based\nmemory mechanisms by directly reusing prior reasoning and computations without\nrequiring additional steps for knowledge extraction or distillation. Our method\nalso goes beyond existing KV caching techniques, which primarily target\nefficiency gains rather than improving accuracy. Experiments on knowledge- and\nreasoning-intensive datasets demonstrate that our method significantly\noutperforms standard agentic systems that do not utilize logs, as well as\nexisting solutions based on reflection and KV cache techniques.",
      "tldr_zh": "论文提出LAG（Log-Augmented Generation）框架，以解决大型语言模型（LLMs）和其代理系统无法从过去任务中保留并应用推理的问题，通过直接重用任务日志中的计算和推理来提升测试时的性能。LAG使用key-value (KV) caches来存储选定tokens的推理上下文，并在新任务中检索相关KV值进行增强生成，避免了额外的知识提取或提炼步骤。该方法超越了传统KV缓存技术的效率导向，专注于准确性提升，并在知识和推理密集型数据集上的实验中，显著优于不使用日志的标准系统以及基于反射的现有解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Data and code are available at https://peterbaile.github.io/lag/",
      "pdf_url": "http://arxiv.org/pdf/2505.14398v1",
      "published_date": "2025-05-20 14:14:38 UTC",
      "updated_date": "2025-05-20 14:14:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:04:20.207231"
    },
    {
      "arxiv_id": "2505.14396v1",
      "title": "Causal Cartographer: From Mapping to Reasoning Over Counterfactual Worlds",
      "title_zh": "Causal Cartographer：从映射到",
      "authors": [
        "Gaël Gendron",
        "Jože M. Rožanec",
        "Michael Witbrock",
        "Gillian Dobbie"
      ],
      "abstract": "Causal world models are systems that can answer counterfactual questions\nabout an environment of interest, i.e. predict how it would have evolved if an\narbitrary subset of events had been realized differently. It requires\nunderstanding the underlying causes behind chains of events and conducting\ncausal inference for arbitrary unseen distributions. So far, this task eludes\nfoundation models, notably large language models (LLMs), which do not have\ndemonstrated causal reasoning capabilities beyond the memorization of existing\ncausal relationships. Furthermore, evaluating counterfactuals in real-world\napplications is challenging since only the factual world is observed, limiting\nevaluation to synthetic datasets. We address these problems by explicitly\nextracting and modeling causal relationships and propose the Causal\nCartographer framework. First, we introduce a graph retrieval-augmented\ngeneration agent tasked to retrieve causal relationships from data. This\napproach allows us to construct a large network of real-world causal\nrelationships that can serve as a repository of causal knowledge and build\nreal-world counterfactuals. In addition, we create a counterfactual reasoning\nagent constrained by causal relationships to perform reliable step-by-step\ncausal inference. We show that our approach can extract causal knowledge and\nimprove the robustness of LLMs for causal reasoning tasks while reducing\ninference costs and spurious correlations.",
      "tldr_zh": "该论文提出Causal Cartographer框架，用于从映射到推理反事实世界（counterfactual worlds），以解决现有模型如大型语言模型（LLMs）在因果推理方面的局限性。框架包括一个图检索增强生成代理（graph retrieval-augmented generation agent），用于从数据中提取和构建真实世界的因果关系网络，从而生成可靠的反事实场景；此外，还设计了一个受因果关系约束的反事实推理代理（counterfactual reasoning agent），实现逐步的可靠因果推理。实验结果显示，该方法提升了LLMs在因果推理任务中的鲁棒性，同时降低了推理成本和虚假相关性（spurious correlations）。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "I.2.3; I.2.6; I.2.7; G.2.2; G.3; J.1"
      ],
      "primary_category": "cs.AI",
      "comment": "29 pages, 9 pages for the main paper, 20 pages for the references and\n  appendix, 25 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.14396v1",
      "published_date": "2025-05-20 14:14:05 UTC",
      "updated_date": "2025-05-20 14:14:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:04:31.162943"
    },
    {
      "arxiv_id": "2505.14395v1",
      "title": "MUG-Eval: A Proxy Evaluation Framework for Multilingual Generation Capabilities in Any Language",
      "title_zh": "翻译失败",
      "authors": [
        "Seyoung Song",
        "Seogyeong Jeong",
        "Eunsu Kim",
        "Jiho Jin",
        "Dongkwan Kim",
        "Jay Shin",
        "Alice Oh"
      ],
      "abstract": "Evaluating text generation capabilities of large language models (LLMs) is\nchallenging, particularly for low-resource languages where methods for direct\nassessment are scarce. We propose MUG-Eval, a novel framework that evaluates\nLLMs' multilingual generation capabilities by transforming existing benchmarks\ninto conversational tasks and measuring the LLMs' accuracies on those tasks. We\nspecifically designed these conversational tasks to require effective\ncommunication in the target language. Then, we simply use task success rate as\na proxy of successful conversation generation. Our approach offers two key\nadvantages: it is independent of language-specific NLP tools or annotated\ndatasets, which are limited for most languages, and it does not rely on\nLLMs-as-judges, whose evaluation quality degrades outside a few high-resource\nlanguages. We evaluate 8 LLMs across 30 languages spanning high, mid, and\nlow-resource categories, and we find that MUG-Eval correlates strongly with\nestablished benchmarks ($r$ > 0.75) while enabling standardized comparisons\nacross languages and models. Our framework provides a robust and\nresource-efficient solution for evaluating multilingual generation that can be\nextended to thousands of languages.",
      "tldr_zh": "这篇论文提出了 MUG-Eval，一种创新的代理评估框架，用于评估大型语言模型（LLMs）的多语言生成能力，尤其针对低资源语言。框架通过将现有基准转换为对话任务，并使用任务成功率作为代理指标，来衡量 LLMs 在目标语言中的有效沟通表现，从而避免依赖语言特定 NLP 工具或 LLMs-as-judges。实验在 30 种语言（涵盖高、中、低资源类别）上评估了 8 个 LLMs，结果显示 MUG-Eval 与现有基准高度相关（r > 0.75），并实现了跨语言和模型的标准化比较。该框架提供了一个稳健、资源高效的解决方案，可扩展到数千种语言。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14395v1",
      "published_date": "2025-05-20 14:14:00 UTC",
      "updated_date": "2025-05-20 14:14:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:04:44.417431"
    },
    {
      "arxiv_id": "2505.14394v1",
      "title": "Knowledge Graph Based Repository-Level Code Generation",
      "title_zh": "基于知识图谱的仓库级代码生成",
      "authors": [
        "Mihir Athale",
        "Vishal Vaddina"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have transformed code\ngeneration from natural language queries. However, despite their extensive\nknowledge and ability to produce high-quality code, LLMs often struggle with\ncontextual accuracy, particularly in evolving codebases. Current code search\nand retrieval methods frequently lack robustness in both the quality and\ncontextual relevance of retrieved results, leading to suboptimal code\ngeneration. This paper introduces a novel knowledge graph-based approach to\nimprove code search and retrieval leading to better quality of code generation\nin the context of repository-level tasks. The proposed approach represents code\nrepositories as graphs, capturing structural and relational information for\nenhanced context-aware code generation. Our framework employs a hybrid approach\nfor code retrieval to improve contextual relevance, track inter-file modular\ndependencies, generate more robust code and ensure consistency with the\nexisting codebase. We benchmark the proposed approach on the Evolutionary Code\nBenchmark (EvoCodeBench) dataset, a repository-level code generation benchmark,\nand demonstrate that our method significantly outperforms the baseline\napproach. These findings suggest that knowledge graph based code generation\ncould advance robust, context-sensitive coding assistance tools.",
      "tldr_zh": "该论文针对 Large Language Models (LLMs) 在代码生成中的上下文准确性问题，提出了一种基于 Knowledge Graph 的方法，将代码仓库表示为图，以捕捉结构和关系信息，从而提升代码搜索和生成的上下文相关性。该框架采用混合检索方法，跟踪文件间模块依赖，确保生成的代码更鲁棒且与现有代码库一致。在 EvoCodeBench 数据集上的基准测试中，该方法显著优于基线方法，证明了 Knowledge Graph 在开发可靠的上下文敏感代码辅助工具方面的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.14394v1",
      "published_date": "2025-05-20 14:13:59 UTC",
      "updated_date": "2025-05-20 14:13:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:04:55.826387"
    },
    {
      "arxiv_id": "2505.14391v1",
      "title": "Beyond the First Error: Process Reward Models for Reflective Mathematical Reasoning",
      "title_zh": "超越第一个错误：用于反思性数学推理的过程奖励模型",
      "authors": [
        "Zhaohui Yang",
        "Chenghua He",
        "Xiaowen Shi",
        "Linjing Li",
        "Qiyue Yin",
        "Shihong Deng",
        "Daxin Jiang"
      ],
      "abstract": "Many studies focus on data annotation techniques for training effective PRMs.\nHowever, current methods encounter a significant issue when applied to long CoT\nreasoning processes: they tend to focus solely on the first incorrect step and\nall preceding steps, assuming that all subsequent steps are incorrect. These\nmethods overlook the unique self-correction and reflection mechanisms inherent\nin long CoT, where correct reasoning steps may still occur after initial\nreasoning mistakes. To address this issue, we propose a novel data annotation\nmethod for PRMs specifically designed to score the long CoT reasoning process.\nGiven that under the reflection pattern, correct and incorrect steps often\nalternate, we introduce the concepts of Error Propagation and Error Cessation,\nenhancing PRMs' ability to identify both effective self-correction behaviors\nand reasoning based on erroneous steps. Leveraging an LLM-based judger for\nannotation, we collect 1.7 million data samples to train a 7B PRM and evaluate\nit at both solution and step levels. Experimental results demonstrate that\ncompared to existing open-source PRMs and PRMs trained on open-source datasets,\nour PRM achieves superior performance across various metrics, including search\nguidance, BoN, and F1 scores. Compared to widely used MC-based annotation\nmethods, our annotation approach not only achieves higher data efficiency but\nalso delivers superior performance. Detailed analysis is also conducted to\ndemonstrate the stability and generalizability of our method.",
      "tldr_zh": "该论文针对现有 Process Reward Models (PRMs) 在长 Chain-of-Thought (CoT) 推理过程中的局限性，即只关注第一个错误而忽略后续可能的自我修正，提出了一种新型数据标注方法。方法引入 Error Propagation 和 Error Cessation 概念，帮助 PRMs 识别有效的自我修正行为和基于错误步骤的推理，并利用 LLM-based judger 标注了170万数据样本来训练一个7B PRM。实验结果显示，该 PRM 在搜索指导、BoN 和 F1 scores 等指标上优于现有开源模型，且数据效率更高，同时分析证明了方法的稳定性和泛化性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14391v1",
      "published_date": "2025-05-20 14:12:05 UTC",
      "updated_date": "2025-05-20 14:12:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:05:07.809384"
    },
    {
      "arxiv_id": "2505.14381v1",
      "title": "SCAN: Semantic Document Layout Analysis for Textual and Visual Retrieval-Augmented Generation",
      "title_zh": "SCAN：用于文本和视觉检索增强生成的语义",
      "authors": [
        "Yuyang Dong",
        "Nobuhiro Ueda",
        "Krisztián Boros",
        "Daiki Ito",
        "Takuya Sera",
        "Masafumi Oyamada"
      ],
      "abstract": "With the increasing adoption of Large Language Models (LLMs) and\nVision-Language Models (VLMs), rich document analysis technologies for\napplications like Retrieval-Augmented Generation (RAG) and visual RAG are\ngaining significant attention. Recent research indicates that using VLMs can\nachieve better RAG performance, but processing rich documents still remains a\nchallenge since a single page contains large amounts of information. In this\npaper, we present SCAN (\\textbf{S}emanti\\textbf{C} Document Layout\n\\textbf{AN}alysis), a novel approach enhancing both textual and visual\nRetrieval-Augmented Generation (RAG) systems working with visually rich\ndocuments. It is a VLM-friendly approach that identifies document components\nwith appropriate semantic granularity, balancing context preservation with\nprocessing efficiency. SCAN uses a coarse-grained semantic approach that\ndivides documents into coherent regions covering continuous components. We\ntrained the SCAN model by fine-tuning object detection models with\nsophisticated annotation datasets. Our experimental results across English and\nJapanese datasets demonstrate that applying SCAN improves end-to-end textual\nRAG performance by up to 9.0\\% and visual RAG performance by up to 6.4\\%,\noutperforming conventional approaches and even commercial document processing\nsolutions.",
      "tldr_zh": "该研究提出SCAN（Semantic Document Layout Analysis），一种新方法，用于提升文本和视觉Retrieval-Augmented Generation (RAG)系统在处理视觉丰富文档时的性能。SCAN采用粗粒度语义分析，将文档分为连贯的区域，以平衡上下文保留和处理效率，并通过微调物体检测模型和复杂标注数据集进行训练。实验结果显示，在英语和日语数据集上，SCAN使文本RAG性能提升高达9.0%，视觉RAG性能提升高达6.4%，优于传统方法和商业解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "v1",
      "pdf_url": "http://arxiv.org/pdf/2505.14381v1",
      "published_date": "2025-05-20 14:03:24 UTC",
      "updated_date": "2025-05-20 14:03:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:05:21.354393"
    },
    {
      "arxiv_id": "2505.14377v1",
      "title": "When Bias Backfires: The Modulatory Role of Counterfactual Explanations on the Adoption of Algorithmic Bias in XAI-Supported Human Decision-Making",
      "title_zh": "翻译失败",
      "authors": [
        "Ulrike Kuhl",
        "Annika Bush"
      ],
      "abstract": "Although the integration of artificial intelligence (AI) into everyday tasks\nimproves efficiency and objectivity, it also risks transmitting bias to human\ndecision-making. In this study, we conducted a controlled experiment that\nsimulated hiring decisions to examine how biased AI recommendations - augmented\nwith or without counterfactual explanations - influence human judgment over\ntime. Participants, acting as hiring managers, completed 60 decision trials\ndivided into a baseline phase without AI, followed by a phase with biased (X)AI\nrecommendations (favoring either male or female candidates), and a final\npost-interaction phase without AI. Our results indicate that the participants\nfollowed the AI recommendations 70% of the time when the qualifications of the\ngiven candidates were comparable. Yet, only a fraction of participants detected\nthe gender bias (8 out of 294). Crucially, exposure to biased AI altered\nparticipants' inherent preferences: in the post-interaction phase,\nparticipants' independent decisions aligned with the bias when no\ncounterfactual explanations were provided before, but reversed the bias when\nexplanations were given. Reported trust did not differ significantly across\nconditions. Confidence varied throughout the study phases after exposure to\nmale-biased AI, indicating nuanced effects of AI bias on decision certainty.\nOur findings point to the importance of calibrating XAI to avoid unintended\nbehavioral shifts in order to safeguard equitable decision-making and prevent\nthe adoption of algorithmic bias.",
      "tldr_zh": "本研究通过模拟招聘决策的控制实验，考察了带有或不带有反事实解释（counterfactual explanations）的偏见AI推荐（XAI-supported）如何影响人类决策。结果显示，参与者在候选人资格相当时70%遵循AI推荐，但仅有8/294参与者检测到性别偏见；暴露于偏见AI后，参与者独立决策会延续偏见（无解释时）或逆转偏见（有解释时），而信任水平无显著差异，信心则在男性偏见AI暴露后发生变化。这些发现强调了校准XAI的重要性，以防止算法偏见（algorithmic bias）的意外采用并保障公平决策。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted for XAI2025",
      "pdf_url": "http://arxiv.org/pdf/2505.14377v1",
      "published_date": "2025-05-20 14:00:28 UTC",
      "updated_date": "2025-05-20 14:00:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:05:32.067339"
    },
    {
      "arxiv_id": "2505.14366v1",
      "title": "Towards Embodied Cognition in Robots via Spatially Grounded Synthetic Worlds",
      "title_zh": "翻译失败",
      "authors": [
        "Joel Currie",
        "Gioele Migno",
        "Enrico Piacenti",
        "Maria Elena Giannaccini",
        "Patric Bach",
        "Davide De Tommaso",
        "Agnieszka Wykowska"
      ],
      "abstract": "We present a conceptual framework for training Vision-Language Models (VLMs)\nto perform Visual Perspective Taking (VPT), a core capability for embodied\ncognition essential for Human-Robot Interaction (HRI). As a first step toward\nthis goal, we introduce a synthetic dataset, generated in NVIDIA Omniverse,\nthat enables supervised learning for spatial reasoning tasks. Each instance\nincludes an RGB image, a natural language description, and a ground-truth 4X4\ntransformation matrix representing object pose. We focus on inferring Z-axis\ndistance as a foundational skill, with future extensions targeting full 6\nDegrees Of Freedom (DOFs) reasoning. The dataset is publicly available to\nsupport further research. This work serves as a foundational step toward\nembodied AI systems capable of spatial understanding in interactive human-robot\nscenarios.",
      "tldr_zh": "本研究提出一个概念框架，用于训练视觉语言模型(VLMs)以实现视觉视角转换(VPT)，这是一种核心能力，可提升机器人具身认知并促进人-机器人交互(HRI)。为了实现这一目标，研究者引入了一个在NVIDIA Omniverse中生成的合成数据集，每个样本包含RGB图像、自然语言描述以及ground-truth 4X4变换矩阵，用于监督学习的空间推理任务。数据集重点关注推断Z轴距离作为基础技能，并计划扩展到完整的6 DOFs推理；该数据集已公开可用，作为向交互式具身AI系统迈进的关键基础步骤。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to: Intelligent Autonomous Systems (IAS) 2025 as Late\n  Breaking Report",
      "pdf_url": "http://arxiv.org/pdf/2505.14366v1",
      "published_date": "2025-05-20 13:49:09 UTC",
      "updated_date": "2025-05-20 13:49:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:05:43.106005"
    },
    {
      "arxiv_id": "2505.14351v1",
      "title": "FMSD-TTS: Few-shot Multi-Speaker Multi-Dialect Text-to-Speech Synthesis for Ü-Tsang, Amdo and Kham Speech Dataset Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yutong Liu",
        "Ziyue Zhang",
        "Ban Ma-bao",
        "Yuqing Cai",
        "Yongbin Yu",
        "Renzeng Duojie",
        "Xiangxiang Wang",
        "Fan Gao",
        "Cheng Huang",
        "Nyima Tashi"
      ],
      "abstract": "Tibetan is a low-resource language with minimal parallel speech corpora\nspanning its three major dialects-\\\"U-Tsang, Amdo, and Kham-limiting progress\nin speech modeling. To address this issue, we propose FMSD-TTS, a few-shot,\nmulti-speaker, multi-dialect text-to-speech framework that synthesizes parallel\ndialectal speech from limited reference audio and explicit dialect labels. Our\nmethod features a novel speaker-dialect fusion module and a Dialect-Specialized\nDynamic Routing Network (DSDR-Net) to capture fine-grained acoustic and\nlinguistic variations across dialects while preserving speaker identity.\nExtensive objective and subjective evaluations demonstrate that FMSD-TTS\nsignificantly outperforms baselines in both dialectal expressiveness and\nspeaker similarity. We further validate the quality and utility of the\nsynthesized speech through a challenging speech-to-speech dialect conversion\ntask. Our contributions include: (1) a novel few-shot TTS system tailored for\nTibetan multi-dialect speech synthesis, (2) the public release of a large-scale\nsynthetic Tibetan speech corpus generated by FMSD-TTS, and (3) an open-source\nevaluation toolkit for standardized assessment of speaker similarity, dialect\nconsistency, and audio quality.",
      "tldr_zh": "本研究针对藏语作为低资源语言的挑战，提出FMSD-TTS框架，这是一个few-shot多说话人多方言的Text-to-Speech (TTS)系统，用于生成Ü-Tsang、Amdo和Kham三大方言的平行语音语料。框架创新性地引入speaker-dialect fusion module和Dialect-Specialized Dynamic Routing Network (DSDR-Net)，以捕捉方言间的细粒度声学和语言变异，同时保持说话人身份的一致性。实验结果显示，FMSD-TTS在方言表现力和说话人相似度上显著优于基线模型，并在speech-to-speech方言转换任务中验证了合成语音的质量。主要贡献包括：(1)一个专为藏语多方言设计的few-shot TTS系统，(2)公开发布的大型合成藏语语音语料库，以及(3)一个开源评估工具包，用于标准化评估说话人相似度、方言一致性和音频质量。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.14351v1",
      "published_date": "2025-05-20 13:35:55 UTC",
      "updated_date": "2025-05-20 13:35:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:05:56.580111"
    },
    {
      "arxiv_id": "2505.14349v1",
      "title": "Upgrading Democracies with Fairer Voting Methods",
      "title_zh": "用更公平的投票方法升级民主",
      "authors": [
        "Evangelos Pournaras",
        "Srijoni Majumdar",
        "Thomas Wellings",
        "Joshua C. Yang",
        "Fatemeh B. Heravan",
        "Regula Hänggli Fricker",
        "Dirk Helbing"
      ],
      "abstract": "Voting methods are instrumental design element of democracies. Citizens use\nthem to express and aggregate their preferences to reach a collective decision.\nHowever, voting outcomes can be as sensitive to voting rules as they are to\npeople's voting choices. Despite the significance and inter-disciplinary\nscientific progress on voting methods, several democracies keep relying on\noutdated voting methods that do not fit modern, pluralistic societies well,\nwhile lacking social innovation. Here, we demonstrate how one can upgrade\nreal-world democracies, namely by using alternative preferential voting methods\nsuch as cumulative voting and the method of equal shares designed for a\nproportional representation of voters' preferences. By rigorously assessing a\nnew participatory budgeting approach applied in the city of Aarau, Switzerland,\nwe unravel the striking voting outcomes of fair voting methods: more winning\nprojects with the same budget and broader geographic and preference\nrepresentation of citizens by the elected projects, in particular for voters\nwho used to be under-represented, while promoting novel project ideas. We\nprovide profound causal evidence showing that citizens prefer proportional\nvoting methods, which possess strong legitimacy without the need of very\ntechnical specialized explanations. We also reveal strong underlying democratic\nvalues exhibited by citizens who support fair voting methods such as altruism\nand compromise. These findings come with a global momentum to unleash a new and\nlong-awaited participation blueprint of how to upgrade democracies.",
      "tldr_zh": "这篇论文探讨了如何通过更公平的投票方法升级民主制度，强调使用替代优先投票方法如cumulative voting和method of equal shares，以实现选民偏好的比例代表。研究通过评估瑞士Aarau市的参与式预算案例，发现这些方法能增加获胜项目数量、扩大地理和偏好代表性，特别是对原本代表不足的选民，同时促进新项目想法。作者提供了因果证据，表明选民更青睐这些比例投票方法，因为它们具有强合法性和易懂性，并体现了利他主义和妥协等民主价值观，为全球民主改革提供新蓝图。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.CY",
      "comment": "Includes Supplementary Information",
      "pdf_url": "http://arxiv.org/pdf/2505.14349v1",
      "published_date": "2025-05-20 13:31:43 UTC",
      "updated_date": "2025-05-20 13:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:06:08.273437"
    },
    {
      "arxiv_id": "2505.14345v1",
      "title": "Enhancing Classification with Semi-Supervised Deep Learning Using Distance-Based Sample Weights",
      "title_zh": "使用基于距离的样本权重增强半监督深度学习分类",
      "authors": [
        "Aydin Abedinia",
        "Shima Tabakhi",
        "Vahid Seydi"
      ],
      "abstract": "Recent advancements in semi-supervised deep learning have introduced\neffective strategies for leveraging both labeled and unlabeled data to improve\nclassification performance. This work proposes a semi-supervised framework that\nutilizes a distance-based weighting mechanism to prioritize critical training\nsamples based on their proximity to test data. By focusing on the most\ninformative examples, the method enhances model generalization and robustness,\nparticularly in challenging scenarios with noisy or imbalanced datasets.\nBuilding on techniques such as uncertainty consistency and graph-based\nrepresentations, the approach addresses key challenges of limited labeled data\nwhile maintaining scalability. Experiments on twelve benchmark datasets\ndemonstrate significant improvements across key metrics, including accuracy,\nprecision, and recall, consistently outperforming existing methods. This\nframework provides a robust and practical solution for semi-supervised\nlearning, with potential applications in domains such as healthcare and\nsecurity where data limitations pose significant challenges.",
      "tldr_zh": "本研究提出了一种基于距离-based weighting 机制的半监督深度学习框架，用于提升分类性能。该框架通过评估训练样本与测试数据的接近程度来优先处理最 informative 的样本，结合 uncertainty consistency 和 graph-based representations 技术，改善模型的 generalization 和 robustness，尤其适用于 noisy 或 imbalanced datasets 的挑战场景。在 12 个 benchmark datasets 的实验中，该方法显著提高了 accuracy、precision 和 recall 等指标，优于现有方法。该框架为 healthcare 和 security 等领域的数据限制问题提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T05, 62H30",
        "I.2.6; I.5.1; I.5.4"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 6 figures. This paper has been accepted for publication and\n  oral presentation at the 2025 10th IEEE International Conference on Machine\n  Learning Technologies (ICMLT 2025). The final authenticated version will be\n  available in IEEE Xplore following the conference",
      "pdf_url": "http://arxiv.org/pdf/2505.14345v1",
      "published_date": "2025-05-20 13:29:04 UTC",
      "updated_date": "2025-05-20 13:29:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:06:18.849461"
    },
    {
      "arxiv_id": "2505.14341v1",
      "title": "Replace in Translation: Boost Concept Alignment in Counterfactual Text-to-Image",
      "title_zh": "翻译失败",
      "authors": [
        "Sifan Li",
        "Ming Tao",
        "Hao Zhao",
        "Ling Shao",
        "Hao Tang"
      ],
      "abstract": "Text-to-Image (T2I) has been prevalent in recent years, with most common\ncondition tasks having been optimized nicely. Besides, counterfactual\nText-to-Image is obstructing us from a more versatile AIGC experience. For\nthose scenes that are impossible to happen in real world and anti-physics, we\nshould spare no efforts in increasing the factual feel, which means\nsynthesizing images that people think very likely to be happening, and concept\nalignment, which means all the required objects should be in the same frame. In\nthis paper, we focus on concept alignment. As controllable T2I models have\nachieved satisfactory performance for real applications, we utilize this\ntechnology to replace the objects in a synthesized image in latent space\nstep-by-step to change the image from a common scene to a counterfactual scene\nto meet the prompt. We propose a strategy to instruct this replacing process,\nwhich is called as Explicit Logical Narrative Prompt (ELNP), by using the newly\nSoTA language model DeepSeek to generate the instructions. Furthermore, to\nevaluate models' performance in counterfactual T2I, we design a metric to\ncalculate how many required concepts in the prompt can be covered averagely in\nthe synthesized images. The extensive experiments and qualitative comparisons\ndemonstrate that our strategy can boost the concept alignment in counterfactual\nT2I.",
      "tldr_zh": "这篇论文针对逆事实 Text-to-Image (T2I) 中的概念对齐问题，提出了一种在潜在空间逐步替换图像对象的策略，以将常见场景转化为符合提示的逆事实场景。方法利用 Explicit Logical Narrative Prompt (ELNP) 由 DeepSeek 语言模型生成指令，来指导替换过程，确保所有提示中的概念在合成图像中得到对齐。论文还设计了一个新指标来评估提示概念的平均覆盖率，实验结果表明，该策略显著提升了逆事实 T2I 的概念对齐性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14341v1",
      "published_date": "2025-05-20 13:27:52 UTC",
      "updated_date": "2025-05-20 13:27:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:06:31.933293"
    },
    {
      "arxiv_id": "2505.14330v1",
      "title": "Handloom Design Generation Using Generative Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Rajat Kanti Bhattacharjee",
        "Meghali Nandi",
        "Amrit Jha",
        "Gunajit Kalita",
        "Ferdous Ahmed Barbhuiya"
      ],
      "abstract": "This paper proposes deep learning techniques of generating designs for\nclothing, focused on handloom fabric and discusses the associated challenges\nalong with its application. The capability of generative neural network models\nin understanding artistic designs and synthesizing those is not yet explored\nwell. In this work, multiple methods are employed incorporating the current\nstate of the art generative models and style transfer algorithms to study and\nobserve their performance for the task. The results are then evaluated through\nuser score. This work also provides a new dataset NeuralLoom for the task of\nthe design generation.",
      "tldr_zh": "本论文提出使用生成式神经网络模型生成手织布料服装设计，探讨其在理解和合成艺术设计方面的潜力，并讨论相关挑战和应用。研究采用多种方法，包括当前最先进的生成模型和风格转移算法，对模型性能进行评估。结果通过用户评分量化，并提供了一个新数据集 NeuralLoom，以支持设计生成任务。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14330v1",
      "published_date": "2025-05-20 13:16:55 UTC",
      "updated_date": "2025-05-20 13:16:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:06:42.729920"
    },
    {
      "arxiv_id": "2505.14751v1",
      "title": "Self Distillation via Iterative Constructive Perturbations",
      "title_zh": "翻译失败",
      "authors": [
        "Maheak Dave",
        "Aniket Kumar Singh",
        "Aryan Pareek",
        "Harshita Jha",
        "Debasis Chaudhuri",
        "Manish Pratap Singh"
      ],
      "abstract": "Deep Neural Networks have achieved remarkable achievements across various\ndomains, however balancing performance and generalization still remains a\nchallenge while training these networks. In this paper, we propose a novel\nframework that uses a cyclic optimization strategy to concurrently optimize the\nmodel and its input data for better training, rethinking the traditional\ntraining paradigm. Central to our approach is Iterative Constructive\nPerturbation (ICP), which leverages the model's loss to iteratively perturb the\ninput, progressively constructing an enhanced representation over some\nrefinement steps. This ICP input is then fed back into the model to produce\nimproved intermediate features, which serve as a target in a self-distillation\nframework against the original features. By alternately altering the model's\nparameters to the data and the data to the model, our method effectively\naddresses the gap between fitting and generalization, leading to enhanced\nperformance. Extensive experiments demonstrate that our approach not only\nmitigates common performance bottlenecks in neural networks but also\ndemonstrates significant improvements across training variations.",
      "tldr_zh": "这篇论文提出了一种新框架，通过循环优化策略同时优化深度神经网络的模型参数和输入数据，以解决性能与泛化能力之间的平衡挑战。核心方法是 Iterative Constructive Perturbation (ICP)，它利用模型损失迭代扰动输入数据，逐步构建增强表示，并将其反馈到自蒸馏框架中，作为目标与原始特征比较，从而改善中间特征。实验结果显示，该方法有效缓解了神经网络的常见性能瓶颈，并在各种训练变体中实现了显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14751v1",
      "published_date": "2025-05-20 13:15:27 UTC",
      "updated_date": "2025-05-20 13:15:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:06:55.785012"
    },
    {
      "arxiv_id": "2505.14316v1",
      "title": "Exploring Jailbreak Attacks on LLMs through Intent Concealment and Diversion",
      "title_zh": "翻译失败",
      "authors": [
        "Tiehan Cui",
        "Yanxu Mao",
        "Peipei Liu",
        "Congying Liu",
        "Datao You"
      ],
      "abstract": "Although large language models (LLMs) have achieved remarkable advancements,\ntheir security remains a pressing concern. One major threat is jailbreak\nattacks, where adversarial prompts bypass model safeguards to generate harmful\nor objectionable content. Researchers study jailbreak attacks to understand\nsecurity and robustness of LLMs. However, existing jailbreak attack methods\nface two main challenges: (1) an excessive number of iterative queries, and (2)\npoor generalization across models. In addition, recent jailbreak evaluation\ndatasets focus primarily on question-answering scenarios, lacking attention to\ntext generation tasks that require accurate regeneration of toxic content. To\ntackle these challenges, we propose two contributions: (1) ICE, a novel\nblack-box jailbreak method that employs Intent Concealment and divErsion to\neffectively circumvent security constraints. ICE achieves high attack success\nrates (ASR) with a single query, significantly improving efficiency and\ntransferability across different models. (2) BiSceneEval, a comprehensive\ndataset designed for assessing LLM robustness in question-answering and\ntext-generation tasks. Experimental results demonstrate that ICE outperforms\nexisting jailbreak techniques, revealing critical vulnerabilities in current\ndefense mechanisms. Our findings underscore the necessity of a hybrid security\nstrategy that integrates predefined security mechanisms with real-time semantic\ndecomposition to enhance the security of LLMs.",
      "tldr_zh": "该研究探讨了大型语言模型 (LLMs) 面临的 jailbreak attacks 威胁，这些攻击通过对抗性提示绕过安全机制生成有害内容，但现有方法存在迭代查询过多和模型泛化能力差的问题。论文提出 ICE（Intent Concealment and Diversion），一种黑盒攻击方法，利用意图隐藏和转移技术，仅需单次查询即可实现高攻击成功率 (ASR)，并提升了跨模型转移性；同时，引入 BiSceneEval 数据集，用于评估 LLMs 在问答和文本生成任务中的鲁棒性。实验结果显示，ICE 优于现有技术，暴露了防御机制的漏洞，并建议采用混合安全策略，包括预定义机制和实时语义分解，以增强 LLMs 的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14316v1",
      "published_date": "2025-05-20 13:03:15 UTC",
      "updated_date": "2025-05-20 13:03:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:07:08.682392"
    },
    {
      "arxiv_id": "2505.14312v1",
      "title": "MultiTab: A Comprehensive Benchmark Suite for Multi-Dimensional Evaluation in Tabular Domains",
      "title_zh": "MultiTab：一种用于表格领域多维度",
      "authors": [
        "Kyungeun Lee",
        "Moonjung Eo",
        "Hye-Seung Cho",
        "Dongmin Kim",
        "Ye Seul Sim",
        "Seoyoon Kim",
        "Min-Kook Suh",
        "Woohyung Lim"
      ],
      "abstract": "Despite the widespread use of tabular data in real-world applications, most\nbenchmarks rely on average-case metrics, which fail to reveal how model\nbehavior varies across diverse data regimes. To address this, we propose\nMultiTab, a benchmark suite and evaluation framework for multi-dimensional,\ndata-aware analysis of tabular learning algorithms. Rather than comparing\nmodels only in aggregate, MultiTab categorizes 196 publicly available datasets\nalong key data characteristics, including sample size, label imbalance, and\nfeature interaction, and evaluates 13 representative models spanning a range of\ninductive biases. Our analysis shows that model performance is highly sensitive\nto such regimes: for example, models using sample-level similarity excel on\ndatasets with large sample sizes or high inter-feature correlation, while\nmodels encoding inter-feature dependencies perform best with weakly correlated\nfeatures. These findings reveal that inductive biases do not always behave as\nintended, and that regime-aware evaluation is essential for understanding and\nimproving model behavior. MultiTab enables more principled model design and\noffers practical guidance for selecting models tailored to specific data\ncharacteristics. All datasets, code, and optimization logs are publicly\navailable at https://huggingface.co/datasets/LGAI-DILab/Multitab.",
      "tldr_zh": "该研究提出MultiTab，一套全面的benchmark suite，用于多维度的表格领域评估，旨在解决现有基准依赖平均指标而忽略模型在不同数据情境下表现差异的问题。MultiTab将196个公开数据集根据关键数据特征（如样本大小、标签不平衡和feature interaction）进行分类，并评估13个代表性模型，涵盖各种inductive biases。分析结果显示，模型性能高度敏感于数据特征，例如基于样本相似性的模型在样本量大或特征高度相关的数据集上表现优异，而编码inter-feature dependencies的模型在弱相关特征数据集上更佳。这些发现强调了基于情境的评估对于理解和改进模型行为的重要性，并为针对特定数据特征选择模型提供实用指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2505.14312v1",
      "published_date": "2025-05-20 13:00:43 UTC",
      "updated_date": "2025-05-20 13:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:07:20.952291"
    },
    {
      "arxiv_id": "2505.14300v1",
      "title": "SafetyNet: Detecting Harmful Outputs in LLMs by Modeling and Monitoring Deceptive Behaviors",
      "title_zh": "SafetyNet：通过建模与",
      "authors": [
        "Maheep Chaudhary",
        "Fazl Barez"
      ],
      "abstract": "High-risk industries like nuclear and aviation use real-time monitoring to\ndetect dangerous system conditions. Similarly, Large Language Models (LLMs)\nneed monitoring safeguards. We propose a real-time framework to predict harmful\nAI outputs before they occur by using an unsupervised approach that treats\nnormal behavior as the baseline and harmful outputs as outliers. Our study\nfocuses specifically on backdoor-triggered responses -- where specific input\nphrases activate hidden vulnerabilities causing the model to generate unsafe\ncontent like violence, pornography, or hate speech. We address two key\nchallenges: (1) identifying true causal indicators rather than surface\ncorrelations, and (2) preventing advanced models from deception -- deliberately\nevading monitoring systems. Hence, we approach this problem from an\nunsupervised lens by drawing parallels to human deception: just as humans\nexhibit physical indicators while lying, we investigate whether LLMs display\ndistinct internal behavioral signatures when generating harmful content. Our\nstudy addresses two critical challenges: 1) designing monitoring systems that\ncapture true causal indicators rather than superficial correlations; and\n2)preventing intentional evasion by increasingly capable \"Future models''. Our\nfindings show that models can produce harmful content through causal mechanisms\nand can become deceptive by: (a) alternating between linear and non-linear\nrepresentations, and (b) modifying feature relationships. To counter this, we\ndeveloped Safety-Net -- a multi-detector framework that monitors different\nrepresentation dimensions, successfully detecting harmful behavior even when\ninformation is shifted across representational spaces to evade individual\nmonitors. Our evaluation shows 96% accuracy in detecting harmful cases using\nour unsupervised ensemble approach.",
      "tldr_zh": "该研究提出Safety-Net框架，通过无监督方法监控Large Language Models (LLMs)的有害输出，将正常行为作为基线，将backdoor-triggered responses视为异常，以实时预测如暴力、色情或仇恨言论的生成。框架重点解决两个挑战：识别真正的因果指标而非表面相关性，以及防止模型通过切换线性与非线性表示或修改特征关系来进行deception。Safety-Net采用多检测器系统，监控不同表示维度，即使信息转移到其他空间也能检测有害行为。实验结果显示，该无监督集成方法在检测有害情况下达到96%的准确率，为LLMs的安全应用提供了可靠的防护机制。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14300v1",
      "published_date": "2025-05-20 12:49:58 UTC",
      "updated_date": "2025-05-20 12:49:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:07:32.533739"
    },
    {
      "arxiv_id": "2505.14295v1",
      "title": "Benchmarking data encoding methods in Quantum Machine Learning",
      "title_zh": "量子机器学习中数据编码方法的基准测试",
      "authors": [
        "Orlane Zang",
        "Grégoire Barrué",
        "Tony Quertier"
      ],
      "abstract": "Data encoding plays a fundamental and distinctive role in Quantum Machine\nLearning (QML). While classical approaches process data directly as vectors,\nQML may require transforming classical data into quantum states through\nencoding circuits, known as quantum feature maps or quantum embeddings. This\nstep leverages the inherently high-dimensional and non-linear nature of Hilbert\nspace, enabling more efficient data separation in complex feature spaces that\nmay be inaccessible to classical methods. This encoding part significantly\naffects the performance of the QML model, so it is important to choose the\nright encoding method for the dataset to be encoded. However, this choice is\ngenerally arbitrary, since there is no \"universal\" rule for knowing which\nencoding to choose based on a specific set of data. There are currently a\nvariety of encoding methods using different quantum logic gates. We studied the\nmost commonly used types of encoding methods and benchmarked them using\ndifferent datasets.",
      "tldr_zh": "本论文探讨了量子机器学习（QML）中数据编码的关键作用，强调通过量子特征映射（quantum feature maps）或量子嵌入（quantum embeddings）将经典数据转化为量子状态，以利用Hilbert空间的高维和非线性特性，实现更有效的数据分离。研究者分析了多种常用编码方法，并使用不同数据集进行基准测试，以评估这些方法对QML模型性能的影响。由于缺乏通用选择规则，该工作旨在提供指导，帮助根据特定数据集选择合适的编码策略。结果显示，不同编码方法在性能上存在显著差异，为QML应用提供了实证参考。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "30 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.14295v1",
      "published_date": "2025-05-20 12:44:14 UTC",
      "updated_date": "2025-05-20 12:44:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:07:43.520282"
    },
    {
      "arxiv_id": "2505.14289v1",
      "title": "EVA: Red-Teaming GUI Agents via Evolving Indirect Prompt Injection",
      "title_zh": "翻译失败",
      "authors": [
        "Yijie Lu",
        "Tianjie Ju",
        "Manman Zhao",
        "Xinbei Ma",
        "Yuan Guo",
        "ZhuoSheng Zhang"
      ],
      "abstract": "As multimodal agents are increasingly trained to operate graphical user\ninterfaces (GUIs) to complete user tasks, they face a growing threat from\nindirect prompt injection, attacks in which misleading instructions are\nembedded into the agent's visual environment, such as popups or chat messages,\nand misinterpreted as part of the intended task. A typical example is\nenvironmental injection, in which GUI elements are manipulated to influence\nagent behavior without directly modifying the user prompt. To address these\nemerging attacks, we propose EVA, a red teaming framework for indirect prompt\ninjection which transforms the attack into a closed loop optimization by\ncontinuously monitoring an agent's attention distribution over the GUI and\nupdating adversarial cues, keywords, phrasing, and layout, in response.\nCompared with prior one shot methods that generate fixed prompts without regard\nfor how the model allocates visual attention, EVA dynamically adapts to\nemerging attention hotspots, yielding substantially higher attack success rates\nand far greater transferability across diverse GUI scenarios. We evaluate EVA\non six widely used generalist and specialist GUI agents in realistic settings\nsuch as popup manipulation, chat based phishing, payments, and email\ncomposition. Experimental results show that EVA substantially improves success\nrates over static baselines. Under goal agnostic constraints, where the\nattacker does not know the agent's task intent, EVA still discovers effective\npatterns. Notably, we find that injection styles transfer well across models,\nrevealing shared behavioral biases in GUI agents. These results suggest that\nevolving indirect prompt injection is a powerful tool not only for red teaming\nagents, but also for uncovering common vulnerabilities in their multimodal\ndecision making.",
      "tldr_zh": "该研究提出EVA框架，用于通过演化间接提示注入(evolving indirect prompt injection)对图形用户界面(GUI)代理进行红队测试(red-teaming)，以应对嵌入视觉环境中的误导性指令攻击。EVA将攻击转化为闭环优化过程，通过实时监控代理的注意力分布，并动态调整对抗性提示（如关键词、短语和布局），从而显著提高攻击成功率和跨场景转移性。实验在六个通用和专业GUI代理上评估了真实场景，包括弹出窗口操纵、聊天钓鱼、支付和电子邮件撰写，结果显示EVA比静态方法成功率大幅提升，甚至在攻击者不知代理任务意图的情况下仍有效。EVA不仅揭示了GUI代理在多模态决策中的共享行为偏见，还为识别和缓解此类漏洞提供了重要工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14289v1",
      "published_date": "2025-05-20 12:41:05 UTC",
      "updated_date": "2025-05-20 12:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:07:58.095644"
    },
    {
      "arxiv_id": "2505.14285v1",
      "title": "AquaSignal: An Integrated Framework for Robust Underwater Acoustic Analysis",
      "title_zh": "AquaSignal：用于鲁",
      "authors": [
        "Eirini Panteli",
        "Paulo E. Santos",
        "Nabil Humphrey"
      ],
      "abstract": "This paper presents AquaSignal, a modular and scalable pipeline for\npreprocessing, denoising, classification, and novelty detection of underwater\nacoustic signals. Designed to operate effectively in noisy and dynamic marine\nenvironments, AquaSignal integrates state-of-the-art deep learning\narchitectures to enhance the reliability and accuracy of acoustic signal\nanalysis. The system is evaluated on a combined dataset from the Deepship and\nOcean Networks Canada (ONC) benchmarks, providing a diverse set of real-world\nunderwater scenarios. AquaSignal employs a U-Net architecture for denoising, a\nResNet18 convolutional neural network for classifying known acoustic events,\nand an AutoEncoder-based model for unsupervised detection of novel or anomalous\nsignals. To our knowledge, this is the first comprehensive study to apply and\nevaluate this combination of techniques on maritime vessel acoustic data.\nExperimental results show that AquaSignal improves signal clarity and task\nperformance, achieving 71% classification accuracy and 91% accuracy in novelty\ndetection. Despite slightly lower classification performance compared to some\nstate-of-the-art models, differences in data partitioning strategies limit\ndirect comparisons. Overall, AquaSignal demonstrates strong potential for\nreal-time underwater acoustic monitoring in scientific, environmental, and\nmaritime domains.",
      "tldr_zh": "本文介绍了 AquaSignal，一种模块化和可扩展的框架，用于水下声学信号的预处理、去噪、分类和新颖性检测，旨在在嘈杂的海洋环境中提升分析的可靠性和准确性。该框架整合了 U-Net 架构进行去噪、ResNet18 神经网络用于分类已知事件，以及 AutoEncoder-based 模型实现无监督的异常信号检测，并在 Deepship 和 ONC 数据集上进行了评估。实验结果显示，AquaSignal 提高了信号清晰度，分类准确率达 71%，新颖性检测准确率达 91%。整体上，这是一个首次将这些技术组合应用于海洋声学数据的全面系统，具有在科学、环境和海洋领域的实时监控潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "8 pages; 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.14285v1",
      "published_date": "2025-05-20 12:35:43 UTC",
      "updated_date": "2025-05-20 12:35:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:08:09.413195"
    },
    {
      "arxiv_id": "2505.14279v1",
      "title": "YESciEval: Robust LLM-as-a-Judge for Scientific Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Jennifer D'Souza",
        "Hamed Babaei Giglou",
        "Quentin Münch"
      ],
      "abstract": "Large Language Models (LLMs) drive scientific question-answering on modern\nsearch engines, yet their evaluation robustness remains underexplored. We\nintroduce YESciEval, an open-source framework that combines fine-grained\nrubric-based assessment with reinforcement learning to mitigate optimism bias\nin LLM evaluators. We release multidisciplinary scienceQ&A datasets, including\nadversarial variants, with evaluation scores from multiple LLMs. Independent of\nproprietary models and human feedback, our approach enables scalable, cost-free\nevaluation. By advancing reliable LLM-as-a-judge models, this work supports AI\nalignment and fosters robust, transparent evaluation essential for scientific\ninquiry and artificial general intelligence.",
      "tldr_zh": "这篇论文引入了 YESciEval，一个开源框架，用于提升 Large Language Models (LLMs) 在科学问答中的评估鲁棒性，通过结合细粒度评分标准(rubric-based assessment)和强化学习(reinforcement learning)来减轻评估中的乐观偏差。研究者发布了多学科科学 Q&A 数据集，包括对抗性变体，并提供了多个 LLMs 的评估分数，实现独立于专有模型和人类反馈的可扩展、无成本评估。该框架支持 AI 对齐，并促进科学探究和人工通用智能(AGI)的稳健、透明评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 3 figures, Accepted as a Long Paper at the 63rd Annual\n  Meeting of the Association for Computational Linguistics (ACL 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.14279v1",
      "published_date": "2025-05-20 12:30:46 UTC",
      "updated_date": "2025-05-20 12:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:08:20.987541"
    },
    {
      "arxiv_id": "2505.14273v1",
      "title": "X-KAN: Optimizing Local Kolmogorov-Arnold Networks via Evolutionary Rule-Based Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hiroki Shiraishi",
        "Hisao Ishibuchi",
        "Masaya Nakata"
      ],
      "abstract": "Function approximation is a critical task in various fields. However,\nexisting neural network approaches struggle with locally complex or\ndiscontinuous functions due to their reliance on a single global model covering\nthe entire problem space. We propose X-KAN, a novel method that optimizes\nmultiple local Kolmogorov-Arnold Networks (KANs) through an evolutionary\nrule-based machine learning framework called XCSF. X-KAN combines KAN's high\nexpressiveness with XCSF's adaptive partitioning capability by implementing\nlocal KAN models as rule consequents and defining local regions via rule\nantecedents. Our experimental results on artificial test functions and\nreal-world datasets demonstrate that X-KAN significantly outperforms\nconventional methods, including XCSF, Multi-Layer Perceptron, and KAN, in terms\nof approximation accuracy. Notably, X-KAN effectively handles functions with\nlocally complex or discontinuous structures that are challenging for\nconventional KAN, using a compact set of rules (average 7.2 $\\pm$ 2.3 rules).\nThese results validate the effectiveness of using KAN as a local model in XCSF,\nwhich evaluates the rule fitness based on both accuracy and generality. Our\nX-KAN implementation is available at https://github.com/YNU-NakataLab/X-KAN.",
      "tldr_zh": "该研究提出X-KAN，一种通过进化规则-based机器学习框架XCSF优化多个局部Kolmogorov-Arnold Networks (KANs)的方法，以解决现有神经网络在处理局部复杂或不连续函数时的局限性。X-KAN将局部KAN模型作为规则的后果，并通过规则的先决条件定义局部区域，从而结合KAN的高表达性和XCSF的自适应分区能力。实验结果显示，X-KAN在人工测试函数和真实数据集上显著优于XCSF、Multi-Layer Perceptron和KAN，在逼近准确性方面表现出色，并使用紧凑的规则集（平均7.2 ± 2.3规则），验证了KAN作为局部模型的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "cs.SC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 34th International Joint Conference on Artificial\n  Intelligence (IJCAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.14273v1",
      "published_date": "2025-05-20 12:26:03 UTC",
      "updated_date": "2025-05-20 12:26:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:08:34.405085"
    },
    {
      "arxiv_id": "2505.14268v1",
      "title": "Think-J: Learning to Think for Generative LLM-as-a-Judge",
      "title_zh": "翻译失败",
      "authors": [
        "Hui Huang",
        "Yancheng He",
        "Hongli Zhou",
        "Rui Zhang",
        "Wei Liu",
        "Weixun Wang",
        "Wenbo Su",
        "Bo Zheng",
        "Jiaheng Liu"
      ],
      "abstract": "LLM-as-a-Judge refers to the automatic modeling of preferences for responses\ngenerated by Large Language Models (LLMs), which is of significant importance\nfor both LLM evaluation and reward modeling. Although generative LLMs have made\nsubstantial progress in various tasks, their performance as LLM-Judge still\nfalls short of expectations. In this work, we propose Think-J, which improves\ngenerative LLM-as-a-Judge by learning how to think. We first utilized a small\namount of curated data to develop the model with initial judgment thinking\ncapabilities. Subsequently, we optimize the judgment thinking traces based on\nreinforcement learning (RL). We propose two methods for judgment thinking\noptimization, based on offline and online RL, respectively. The offline RL\nrequires training a critic model to construct positive and negative examples\nfor learning. The online method defines rule-based reward as feedback for\noptimization. Experimental results showed that our approach can significantly\nenhance the evaluation capability of generative LLM-Judge, surpassing both\ngenerative and classifier-based LLM-Judge without requiring extra human\nannotations.",
      "tldr_zh": "本论文提出 Think-J 框架，旨在通过学习思考过程来提升生成式 LLM-as-a-Judge 的性能，用于自动建模对大语言模型响应偏好的评估。方法包括先利用少量精选数据训练模型获得初步判断思考能力，然后通过强化学习（RL）优化思考轨迹，包括基于离线 RL 的批评者模型训练和基于在线 RL 的规则奖励反馈。实验结果显示，Think-J 显著提高了 LLM-as-a-Judge 的评估能力，超越了传统生成式和基于分类器的模型，且无需额外人类标注。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.14268v1",
      "published_date": "2025-05-20 12:19:10 UTC",
      "updated_date": "2025-05-20 12:19:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:08:44.738261"
    },
    {
      "arxiv_id": "2505.14260v1",
      "title": "Speculative Decoding Reimagined for Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Luxi Lin",
        "Zhihang Lin",
        "Zhanpeng Zeng",
        "Rongrong Ji"
      ],
      "abstract": "This paper introduces Multimodal Speculative Decoding (MSD) to accelerate\nMultimodal Large Language Models (MLLMs) inference. Speculative decoding has\nbeen shown to accelerate Large Language Models (LLMs) without sacrificing\naccuracy. However, current speculative decoding methods for MLLMs fail to\nachieve the same speedup as they do for LLMs. To address this, we reimagine\nspeculative decoding specifically for MLLMs. Our analysis of MLLM\ncharacteristics reveals two key design principles for MSD: (1) Text and visual\ntokens have fundamentally different characteristics and need to be processed\nseparately during drafting. (2) Both language modeling ability and visual\nperception capability are crucial for the draft model. For the first principle,\nMSD decouples text and visual tokens in the draft model, allowing each to be\nhandled based on its own characteristics. For the second principle, MSD uses a\ntwo-stage training strategy: In stage one, the draft model is trained on\ntext-only instruction-tuning datasets to improve its language modeling ability.\nIn stage two, MSD gradually introduces multimodal data to enhance the visual\nperception capability of the draft model. Experiments show that MSD boosts\ninference speed by up to $2.29\\times$ for LLaVA-1.5-7B and up to $2.46\\times$\nfor LLaVA-1.5-13B on multimodal benchmarks, demonstrating its effectiveness.\nOur code is available at https://github.com/Lyn-Lucy/MSD.",
      "tldr_zh": "本论文提出 Multimodal Speculative Decoding (MSD) 方法，以加速 Multimodal Large Language Models (MLLMs) 的推理过程，而不牺牲准确性。分析显示，现有推测解码技术在 MLLMs 上不如在 Large Language Models (LLMs) 上有效，因此 MSD 基于两个关键原则：（1）将文本和视觉标记分开处理，以适应其不同特性；（2）确保草拟模型同时具备语言建模能力和视觉感知能力。MSD 通过解耦文本与视觉标记，并采用两阶段训练策略（先在文本-only 数据集上训练语言能力，再引入多模态数据增强视觉感知）来实现这些原则。实验结果表明，MSD 在 LLaVA-1.5-7B 上提升推理速度高达 2.29 倍，在 LLaVA-1.5-13B 上高达 2.46 倍，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.14260v1",
      "published_date": "2025-05-20 12:12:17 UTC",
      "updated_date": "2025-05-20 12:12:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:08:57.913157"
    },
    {
      "arxiv_id": "2505.14256v1",
      "title": "FuxiMT: Sparsifying Large Language Models for Chinese-Centric Multilingual Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Shaolin Zhu",
        "Tianyu Dong",
        "Bo Li",
        "Deyi Xiong"
      ],
      "abstract": "In this paper, we present FuxiMT, a novel Chinese-centric multilingual\nmachine translation model powered by a sparsified large language model (LLM).\nWe adopt a two-stage strategy to train FuxiMT. We first pre-train the model on\na massive Chinese corpus and then conduct multilingual fine-tuning on a large\nparallel dataset encompassing 65 languages. FuxiMT incorporates\nMixture-of-Experts (MoEs) and employs a curriculum learning strategy for robust\nperformance across various resource levels. Experimental results demonstrate\nthat FuxiMT significantly outperforms strong baselines, including\nstate-of-the-art LLMs and machine translation models, particularly under\nlow-resource scenarios. Furthermore, FuxiMT exhibits remarkable zero-shot\ntranslation capabilities for unseen language pairs, indicating its potential to\nbridge communication gaps where parallel data are scarce or unavailable.",
      "tldr_zh": "本论文提出 FuxiMT，一种基于稀疏化 Large Language Models (LLMs) 的中文中心多语言机器翻译模型，旨在提升跨语言翻译性能。模型采用两阶段训练策略：先在海量中文语料上预训练，然后在涵盖 65 种语言的大规模平行数据集上进行多语言微调，同时整合 Mixture-of-Experts (MoEs) 和 curriculum learning 策略，以适应不同资源水平。实验结果表明，FuxiMT 在低资源场景下显著优于现有基准模型，并展现出强大的 zero-shot translation 能力，为缺乏平行数据的语言对提供有效的通信桥梁。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14256v1",
      "published_date": "2025-05-20 12:09:17 UTC",
      "updated_date": "2025-05-20 12:09:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:09:09.620888"
    },
    {
      "arxiv_id": "2505.14252v1",
      "title": "Hybrid Adaptive Modeling in Process Monitoring: Leveraging Sequence Encoders and Physics-Informed Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Mouad Elaarabi",
        "Domenico Borzacchiello",
        "Philippe Le Bot",
        "Nathan Lauzeral",
        "Sebastien Comas-Cardona"
      ],
      "abstract": "In this work, we explore the integration of Sequence Encoding for Online\nParameter Identification with Physics-Informed Neural Networks to create a\nmodel that, once trained, can be utilized for real time applications with\nvariable parameters, boundary conditions, and initial conditions. Recently, the\ncombination of PINNs with Sparse Regression has emerged as a method for\nperforming dynamical system identification through supervised learning and\nsparse regression optimization, while also solving the dynamics using PINNs.\nHowever, this approach can be limited by variations in parameters or boundary\nand initial conditions, requiring retraining of the model whenever changes\noccur. In this work, we introduce an architecture that employs Deep Sets or\nSequence Encoders to encode dynamic parameters, boundary conditions, and\ninitial conditions, using these encoded features as inputs for the PINN,\nenabling the model to adapt to changes in parameters, BCs, and ICs. We apply\nthis approach to three different problems. First, we analyze the Rossler ODE\nsystem, demonstrating the robustness of the model with respect to noise and its\nability to generalize. Next, we explore the model's capability in a 2D\nNavier-Stokes PDE problem involving flow past a cylinder with a parametric\nsinusoidal inlet velocity function, showing that the model can encode pressure\ndata from a few points to identify the inlet velocity profile and utilize\nphysics to compute velocity and pressure throughout the domain. Finally, we\naddress a 1D heat monitoring problem using real data from the heating of glass\nfiber and thermoplastic composite plates.",
      "tldr_zh": "这项研究提出了一种混合自适应建模方法，用于过程监测，将 Sequence Encoders 用于在线参数识别，并与 Physics-Informed Neural Networks (PINNs) 整合，使模型能够在训练后适应可变的参数、边界条件和初始条件，而无需重新训练。相比传统 PINNs 与 Sparse Regression 的组合，该架构使用 Deep Sets 或 Sequence Encoders 来编码动态参数、边界条件和初始条件，作为 PINN 的输入特征，从而提升模型的灵活性。研究通过三个应用案例验证了该方法的有效性：包括 Rossler ODE 系统中的噪声鲁棒性和泛化能力、2D Navier-Stokes PDE 问题中从压力数据识别入口速度并计算全域流场，以及1D 热监测问题的真实数据应用。总的来说，这一方法为实时过程监测提供了更高效且可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14252v1",
      "published_date": "2025-05-20 12:05:17 UTC",
      "updated_date": "2025-05-20 12:05:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:09:21.807046"
    },
    {
      "arxiv_id": "2505.14246v1",
      "title": "Visual Agentic Reinforcement Fine-Tuning",
      "title_zh": "视觉代理强化微调",
      "authors": [
        "Ziyu Liu",
        "Yuhang Zang",
        "Yushan Zou",
        "Zijian Liang",
        "Xiaoyi Dong",
        "Yuhang Cao",
        "Haodong Duan",
        "Dahua Lin",
        "Jiaqi Wang"
      ],
      "abstract": "A key trend in Large Reasoning Models (e.g., OpenAI's o3) is the native\nagentic ability to use external tools such as web browsers for searching and\nwriting/executing code for image manipulation to think with images. In the\nopen-source research community, while significant progress has been made in\nlanguage-only agentic abilities such as function calling and tool integration,\nthe development of multi-modal agentic capabilities that involve truly thinking\nwith images, and their corresponding benchmarks, are still less explored. This\nwork highlights the effectiveness of Visual Agentic Reinforcement Fine-Tuning\n(Visual-ARFT) for enabling flexible and adaptive reasoning abilities for Large\nVision-Language Models (LVLMs). With Visual-ARFT, open-source LVLMs gain the\nability to browse websites for real-time information updates and write code to\nmanipulate and analyze input images through cropping, rotation, and other image\nprocessing techniques. We also present a Multi-modal Agentic Tool Bench (MAT)\nwith two settings (MAT-Search and MAT-Coding) designed to evaluate LVLMs'\nagentic search and coding abilities. Our experimental results demonstrate that\nVisual-ARFT outperforms its baseline by +18.6% F1 / +13.0% EM on MAT-Coding and\n+10.3% F1 / +8.7% EM on MAT-Search, ultimately surpassing GPT-4o. Visual-ARFT\nalso achieves +29.3 F1% / +25.9% EM gains on existing multi-hop QA benchmarks\nsuch as 2Wiki and HotpotQA, demonstrating strong generalization capabilities.\nOur findings suggest that Visual-ARFT offers a promising path toward building\nrobust and generalizable multimodal agents.",
      "tldr_zh": "本研究提出Visual Agentic Reinforcement Fine-Tuning (Visual-ARFT)，一种细调方法，用于增强Large Vision-Language Models (LVLMs)的灵活推理能力，使其能利用外部工具如网页浏览器获取实时信息，并编写代码进行图像处理（如裁剪和旋转）。为了评估这些多模态代理能力，论文引入Multi-modal Agentic Tool Bench (MAT)，包括MAT-Search和MAT-Coding基准。实验结果显示，Visual-ARFT在MAT-Coding上比基线提升18.6% F1和13.0% EM，在MAT-Search上提升10.3% F1和8.7% EM，并超越GPT-4o，同时在多跳QA基准如2Wiki和HotpotQA上获得显著泛化提升，证明其在构建鲁棒多模态代理方面的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "project url:\n  https://github.com/Liuziyu77/Visual-RFT/tree/main/Visual-ARFT",
      "pdf_url": "http://arxiv.org/pdf/2505.14246v1",
      "published_date": "2025-05-20 11:59:25 UTC",
      "updated_date": "2025-05-20 11:59:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:09:34.224314"
    },
    {
      "arxiv_id": "2505.14238v1",
      "title": "ABBA: Highly Expressive Hadamard Product Adaptation for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Raghav Singhal",
        "Kaustubh Ponkshe",
        "Rohit Vartak",
        "Praneeth Vepakomma"
      ],
      "abstract": "Large Language Models have demonstrated strong performance across a wide\nrange of tasks, but adapting them efficiently to new domains remains a key\nchallenge. Parameter-Efficient Fine-Tuning (PEFT) methods address this by\nintroducing lightweight, trainable modules while keeping most pre-trained\nweights fixed. The prevailing approach, LoRA, models updates using a low-rank\ndecomposition, but its expressivity is inherently constrained by the rank.\nRecent methods like HiRA aim to increase expressivity by incorporating a\nHadamard product with the frozen weights, but still rely on the structure of\nthe pre-trained model. We introduce ABBA, a new PEFT architecture that\nreparameterizes the update as a Hadamard product of two independently learnable\nlow-rank matrices. In contrast to prior work, ABBA fully decouples the update\nfrom the pre-trained weights, enabling both components to be optimized freely.\nThis leads to significantly higher expressivity under the same parameter\nbudget. We formally analyze ABBA's expressive capacity and validate its\nadvantages through matrix reconstruction experiments. Empirically, ABBA\nachieves state-of-the-art results on arithmetic and commonsense reasoning\nbenchmarks, consistently outperforming existing PEFT methods by a significant\nmargin across multiple models. Our code is publicly available at:\nhttps://github.com/CERT-Lab/abba.",
      "tldr_zh": "该论文提出 ABBA，一种高度表达性的 Hadamard Product 适应方法，用于大型语言模型的 Parameter-Efficient Fine-Tuning (PEFT)，旨在解决模型高效适应新领域的挑战。与现有方法如 LoRA 和 HiRA 相比，ABBA 通过将更新重新参数化为两个独立可学习的低秩矩阵的 Hadamard 乘积，彻底解耦更新和预训练权重，从而显著提升了表达能力。论文对 ABBA 的表达容量进行了形式分析，并通过矩阵重建实验验证其优势。在算术和常识推理基准测试中，ABBA 实现了最先进的结果，显著优于现有 PEFT 方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Raghav Singhal, Kaustubh Ponkshe, and Rohit Vartak contributed\n  equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2505.14238v1",
      "published_date": "2025-05-20 11:43:25 UTC",
      "updated_date": "2025-05-20 11:43:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:09:46.105464"
    },
    {
      "arxiv_id": "2505.14235v1",
      "title": "Toward Embodied AGI: A Review of Embodied AI and the Road Ahead",
      "title_zh": "翻译失败",
      "authors": [
        "Yequan Wang",
        "Aixin Sun"
      ],
      "abstract": "Artificial General Intelligence (AGI) is often envisioned as inherently\nembodied. With recent advances in robotics and foundational AI models, we stand\nat the threshold of a new era-one marked by increasingly generalized embodied\nAI systems. This paper contributes to the discourse by introducing a systematic\ntaxonomy of Embodied AGI spanning five levels (L1-L5). We review existing\nresearch and challenges at the foundational stages (L1-L2) and outline the key\ncomponents required to achieve higher-level capabilities (L3-L5). Building on\nthese insights and existing technologies, we propose a conceptual framework for\nan L3+ robotic brain, offering both a technical outlook and a foundation for\nfuture exploration.",
      "tldr_zh": "这篇论文审阅了Embodied AI的发展，强调Artificial General Intelligence (AGI)通常需要实体化，并探讨了通往Embodied AGI的未来路径。作者引入了一个系统化的分类框架，涵盖五个级别（L1-L5），审阅了基础阶段（L1-L2）的现有研究和挑战，并概述了实现更高能力（L3-L5）所需的关键组件。最终，论文基于这些见解提出一个L3+机器人大脑的概念框架，提供技术展望并为未来探索奠定基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14235v1",
      "published_date": "2025-05-20 11:42:26 UTC",
      "updated_date": "2025-05-20 11:42:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:09:57.094145"
    },
    {
      "arxiv_id": "2505.14234v1",
      "title": "Fast and close Shannon entropy approximation",
      "title_zh": "快速且精确的香农熵近似",
      "authors": [
        "Illia Horenko",
        "Davide Bassetti",
        "Lukáš Pospíšil"
      ],
      "abstract": "Shannon entropy (SE) and its quantum mechanical analogue von Neumann entropy\nare key components in many tools used in physics, information theory, machine\nlearning (ML) and quantum computing. Besides of the significant amounts of SE\ncomputations required in these fields, the singularity of the SE gradient is\none of the central mathematical reason inducing the high cost, frequently low\nrobustness and slow convergence of such tools. Here we propose the Fast Entropy\nApproximation (FEA) - a non-singular rational approximation of Shannon entropy\nand its gradient that achieves a mean absolute error of $10^{-3}$, which is\napproximately $20$ times lower than comparable state-of-the-art methods. FEA\nallows around $50\\%$ faster computation, requiring only $5$ to $6$ elementary\ncomputational operations, as compared to tens of elementary operations behind\nthe fastest entropy computation algorithms with table look-ups, bitshifts, or\nseries approximations. On a set of common benchmarks for the feature selection\nproblem in machine learning, we show that the combined effect of fewer\nelementary operations, low approximation error, and a non-singular gradient\nallows significantly better model quality and enables ML feature extraction\nthat is two to three orders of magnitude faster and computationally cheaper\nwhen incorporating FEA into AI tools.",
      "tldr_zh": "本研究提出了一种快速且精确的Shannon entropy近似方法，名为Fast Entropy Approximation (FEA)，它通过非奇异的理性近似来解决Shannon entropy计算中的高成本、鲁棒性差和梯度奇异问题。FEA的平均绝对误差达到10^{-3}，比现有最先进方法低约20倍，且仅需5到6个基本计算操作，使计算速度提高约50%。在机器学习的特征选择基准测试中，FEA显著提升模型质量，并使特征提取过程快2到3个数量级，同时降低计算开销。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T01 (Primary) 68Q01, 90C99 (Secondary)"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2505.14234v1",
      "published_date": "2025-05-20 11:41:26 UTC",
      "updated_date": "2025-05-20 11:41:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:10:09.310369"
    },
    {
      "arxiv_id": "2505.14233v1",
      "title": "Mechanistic Fine-tuning for In-context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hakaze Cho",
        "Peng Luo",
        "Mariko Kato",
        "Rin Kaenbyou",
        "Naoya Inoue"
      ],
      "abstract": "In-context Learning (ICL) utilizes structured demonstration-query inputs to\ninduce few-shot learning on Language Models (LMs), which are not originally\npre-trained on ICL-style data. To bridge the gap between ICL and pre-training,\nsome approaches fine-tune LMs on large ICL-style datasets by an end-to-end\nparadigm with massive computational costs. To reduce such costs, in this paper,\nwe propose Attention Behavior Fine-Tuning (ABFT), utilizing the previous\nfindings on the inner mechanism of ICL, building training objectives on the\nattention scores instead of the final outputs, to force the attention scores to\nfocus on the correct label tokens presented in the context and mitigate\nattention scores from the wrong label tokens. Our experiments on 9 modern LMs\nand 8 datasets empirically find that ABFT outperforms in performance,\nrobustness, unbiasedness, and efficiency, with only around 0.01% data cost\ncompared to the previous methods. Moreover, our subsequent analysis finds that\nthe end-to-end training objective contains the ABFT objective, suggesting the\nimplicit bias of ICL-style data to the emergence of induction heads. Our work\ndemonstrates the possibility of controlling specific module sequences within\nLMs to improve their behavior, opening up the future application of mechanistic\ninterpretability.",
      "tldr_zh": "该论文探讨了 In-context Learning (ICL) 的微调问题，提出了一种高效方法 Attention Behavior Fine-Tuning (ABFT)，通过在注意力分数上构建训练目标，而不是端到端输出，来引导 Language Models (LMs) 关注上下文中的正确标签标记并减少对错误标记的关注，从而降低计算成本。实验在 9 个现代 LMs 和 8 个数据集上表明，ABFT 在性能、鲁棒性、无偏性和效率方面均优于现有方法，仅需 0.01% 的数据成本。进一步分析发现，端到端训练目标隐含了 ABFT 目标，这揭示了 ICL 风格数据对归纳头的隐式偏差，并为通过控制 LMs 中的特定模块序列来提升模型行为的机制解释学应用提供了新方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages, 31 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.14233v1",
      "published_date": "2025-05-20 11:41:21 UTC",
      "updated_date": "2025-05-20 11:41:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:10:22.828944"
    },
    {
      "arxiv_id": "2505.14227v1",
      "title": "VoQA: Visual-only Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Luyang Jiang",
        "Jianing An",
        "Jie Luo",
        "Wenjun Wu",
        "Lei Huang"
      ],
      "abstract": "We propose Visual-only Question Answering (VoQA), a novel multimodal task in\nwhich questions are visually embedded within images, without any accompanying\ntextual input. This requires models to locate, recognize, and reason over\nvisually embedded textual questions, posing challenges for existing large\nvision-language models (LVLMs), which show notable performance drops even with\ncarefully designed prompts. To bridge this gap, we introduce Guided Response\nTriggering Supervised Fine-tuning (GRT-SFT), a structured fine-tuning strategy\nthat guides the model to perform step-by-step reasoning purely based on visual\ninput, significantly improving model performance. Our work enhances models'\ncapacity for human-like visual understanding in complex multimodal scenarios,\nwhere information, including language, is perceived visually.",
      "tldr_zh": "我们提出了 Visual-only Question Answering (VoQA)，一种新颖的多模态任务，其中问题以视觉方式嵌入图像中，而无任何文本输入，这要求模型定位、识别和推理视觉嵌入的问题。现有的大型视觉语言模型 (LVLMs) 在此任务上表现出显著性能下降，即使使用精心设计的提示。针对这一挑战，我们引入了 Guided Response Triggering Supervised Fine-tuning (GRT-SFT)，一种结构化的微调策略，指导模型基于纯视觉输入进行逐步推理，从而大幅提升性能。该工作增强了模型在复杂多模态场景中的人类-like 视觉理解能力，使其能够处理通过视觉感知的语言信息。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.14227v1",
      "published_date": "2025-05-20 11:37:49 UTC",
      "updated_date": "2025-05-20 11:37:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:10:34.096524"
    },
    {
      "arxiv_id": "2505.14226v1",
      "title": "\"Haet Bhasha aur Diskrimineshun\": Phonetic Perturbations in Code-Mixed Hinglish to Red-Team LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Darpan Aswal",
        "Siddharth D Jaiswal"
      ],
      "abstract": "Large Language Models (LLMs) have become increasingly powerful, with\nmultilingual and multimodal capabilities improving by the day. These models are\nbeing evaluated through audits, alignment studies and red-teaming efforts to\nexpose model vulnerabilities towards generating harmful, biased and unfair\ncontent. Existing red-teaming efforts have previously focused on the English\nlanguage, using fixed template-based attacks; thus, models continue to be\nsusceptible to multilingual jailbreaking strategies, especially in the\nmultimodal context. In this study, we introduce a novel strategy that leverages\ncode-mixing and phonetic perturbations to jailbreak LLMs for both text and\nimage generation tasks. We also introduce two new jailbreak strategies that\nshow higher effectiveness than baseline strategies. Our work presents a method\nto effectively bypass safety filters in LLMs while maintaining interpretability\nby applying phonetic misspellings to sensitive words in code-mixed prompts. Our\nnovel prompts achieve a 99% Attack Success Rate for text generation and 78% for\nimage generation, with Attack Relevance Rate of 100% for text generation and\n95% for image generation when using the phonetically perturbed code-mixed\nprompts. Our interpretability experiments reveal that phonetic perturbations\nimpact word tokenization, leading to jailbreak success. Our study motivates\nincreasing the focus towards more generalizable safety alignment for\nmultilingual multimodal models, especially in real-world settings wherein\nprompts can have misspelt words.",
      "tldr_zh": "本研究探讨了通过代码混合（code-mixing）和语音扰动（phonetic perturbations）来对大型语言模型（LLMs）进行red-teaming攻击，以暴露其在多语言和多模态环境中的安全漏洞，特别是针对Hinglish提示。研究引入了两种新jailbreak策略，通过在敏感词上应用语音错误拼写来绕过安全过滤，同时保持提示的可解释性。实验结果显示，使用这些扰动提示，文本生成的攻击成功率（ASR）达到99%、相关性率（ARR）为100%，而图像生成的ASR为78%、ARR为95%。此外，解释实验揭示语音扰动会影响词标记化（tokenization），导致攻击成功，并呼吁加强对多语言多模态模型的安全对齐，以应对现实场景中的潜在风险。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14226v1",
      "published_date": "2025-05-20 11:35:25 UTC",
      "updated_date": "2025-05-20 11:35:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:10:47.316198"
    },
    {
      "arxiv_id": "2505.14217v1",
      "title": "Federated learning in low-resource settings: A chest imaging study in Africa -- Challenges and lessons learned",
      "title_zh": "翻译失败",
      "authors": [
        "Jorge Fabila",
        "Lidia Garrucho",
        "Víctor M. Campello",
        "Carlos Martín-Isla",
        "Karim Lekadir"
      ],
      "abstract": "This study explores the use of Federated Learning (FL) for tuberculosis (TB)\ndiagnosis using chest X-rays in low-resource settings across Africa. FL allows\nhospitals to collaboratively train AI models without sharing raw patient data,\naddressing privacy concerns and data scarcity that hinder traditional\ncentralized models. The research involved hospitals and research centers in\neight African countries. Most sites used local datasets, while Ghana and The\nGambia used public ones. The study compared locally trained models with a\nfederated model built across all institutions to evaluate FL's real-world\nfeasibility. Despite its promise, implementing FL in sub-Saharan Africa faces\nchallenges such as poor infrastructure, unreliable internet, limited digital\nliteracy, and weak AI regulations. Some institutions were also reluctant to\nshare model updates due to data control concerns. In conclusion, FL shows\nstrong potential for enabling AI-driven healthcare in underserved regions, but\nbroader adoption will require improvements in infrastructure, education, and\nregulatory support.",
      "tldr_zh": "本研究探讨了在非洲低资源环境中使用 Federated Learning (FL) 诊断肺结核 (TB) 的可行性，通过八个国家医院的协作训练 AI 模型，避免共享原始患者数据以解决隐私和数据稀缺问题。研究比较了本地数据集训练的模型与跨机构联邦模型，结果显示联邦模型在实际应用中表现出色，但面临基础设施薄弱、网络不稳定、数字素养不足以及 AI 法规缺失等挑战。尽管存在这些障碍，FL 在推动欠发达地区 AI 驱动医疗方面显示出巨大潜力，需要通过改善基础设施、教育和监管支持来促进其广泛采用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14217v1",
      "published_date": "2025-05-20 11:23:52 UTC",
      "updated_date": "2025-05-20 11:23:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:10:57.409428"
    },
    {
      "arxiv_id": "2505.14216v1",
      "title": "Reinforcement Learning vs. Distillation: Understanding Accuracy and Capability in LLM Reasoning",
      "title_zh": "强化学习 vs. 知识蒸馏：理解 LLM 推理中的准确性和",
      "authors": [
        "Minwu Kim",
        "Anubhav Shrestha",
        "Safal Shrestha",
        "Aadim Nepal",
        "Keith Ross"
      ],
      "abstract": "Recent studies have shown that reinforcement learning with verifiable rewards\n(RLVR) enhances overall accuracy but fails to improve capability, while\ndistillation can improve both. In this paper, we investigate the mechanisms\nbehind these phenomena. First, we demonstrate that RLVR does not improve\ncapability because it focuses on improving the accuracy of the less-difficult\nquestions to the detriment of the accuracy of the most difficult questions,\nthereby leading to no improvement in capability. Second, we find that RLVR does\nnot merely increase the success probability for the less difficult questions,\nbut in our small model settings produces quality responses that were absent in\nits output distribution before training. In addition, we show these responses\nare neither noticeably longer nor feature more reflection-related keywords,\nunderscoring the need for more reliable indicators of response quality. Third,\nwe show that while distillation reliably improves accuracy by learning strong\nreasoning patterns, it only improves capability when new knowledge is\nintroduced. Moreover, when distilling only with reasoning patterns and no new\nknowledge, the accuracy of the less-difficult questions improves to the\ndetriment of the most difficult questions, similar to RLVR. Together, these\nfindings offer a clearer understanding of how RLVR and distillation shape\nreasoning behavior in language models.",
      "tldr_zh": "该研究比较了 Reinforcement Learning with Verifiable Rewards (RLVR) 和 Distillation 在大型语言模型 (LLM) 推理中的影响。结果显示，RLVR 提高了整体准确率，但未提升能力，因为它优先改善简单问题的准确率而忽略困难问题，并能产生新高质量响应，但这些响应未明显更长或包含更多反思关键词。Distillation 通过学习强推理模式可靠地提升准确率，且仅在引入新知识时改善能力；若无新知识，则会像 RLVR 一样牺牲困难问题准确率。这些发现为理解 RLVR 和 Distillation 如何塑造 LLM 的推理行为提供了清晰机制。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.14216v1",
      "published_date": "2025-05-20 11:22:34 UTC",
      "updated_date": "2025-05-20 11:22:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:11:10.458528"
    },
    {
      "arxiv_id": "2505.14212v1",
      "title": "Automatic Dataset Generation for Knowledge Intensive Question Answering Tasks",
      "title_zh": "知识密集型问答任务的自动数据集生成",
      "authors": [
        "Sizhe Yuen",
        "Ting Su",
        "Ziyang Wang",
        "Yali Du",
        "Adam J. Sobey"
      ],
      "abstract": "A question-answering (QA) system is to search suitable answers within a\nknowledge base. Current QA systems struggle with queries requiring complex\nreasoning or real-time knowledge integration. They are often supplemented with\nretrieval techniques on a data source such as Retrieval-Augmented Generation\n(RAG). However, RAG continues to face challenges in handling complex reasoning\nand logical connections between multiple sources of information. A novel\napproach for enhancing Large Language Models (LLMs) in knowledge-intensive QA\ntasks is presented through the automated generation of context-based QA pairs.\nThis methodology leverages LLMs to create fine-tuning data, reducing reliance\non human labelling and improving model comprehension and reasoning\ncapabilities. The proposed system includes an automated QA generator and a\nmodel fine-tuner, evaluated using perplexity, ROUGE, BLEU, and BERTScore.\nComprehensive experiments demonstrate improvements in logical coherence and\nfactual accuracy, with implications for developing adaptable Artificial\nIntelligence (AI) systems. Mistral-7b-v0.3 outperforms Llama-3-8b with BERT F1,\nBLEU, and ROUGE scores 0.858, 0.172, and 0.260 of for the LLM generated QA\npairs compared to scores of 0.836, 0.083, and 0.139 for the human annotated QA\npairs.",
      "tldr_zh": "这篇论文针对知识密集型问答（QA）任务中，系统在处理复杂推理和实时知识整合时的挑战，提出了一种自动生成数据集的方法，以增强Large Language Models (LLMs)的性能。该方法利用LLMs生成基于上下文的QA对，用于模型微调，减少了对人工标注的依赖，并通过perplexity、ROUGE、BLEU和BERTScore进行评估。实验结果显示，Mistral-7b-v0.3在自动生成的QA对上表现出色，其BERT F1、BLEU和ROUGE分数分别为0.858、0.172和0.260，优于Llama-3-8b的对应分数（0.836、0.083和0.139），从而提高了逻辑连贯性和事实准确性。该创新为开发可适应的人工智能（AI）系统提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14212v1",
      "published_date": "2025-05-20 11:16:29 UTC",
      "updated_date": "2025-05-20 11:16:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:11:22.479042"
    },
    {
      "arxiv_id": "2505.14209v1",
      "title": "Embedded Mean Field Reinforcement Learning for Perimeter-defense Game",
      "title_zh": "嵌入平均场强化学习用于周边防御游戏",
      "authors": [
        "Li Wang",
        "Xin Yu",
        "Xuxin Lv",
        "Gangzheng Ai",
        "Wenjun Wu"
      ],
      "abstract": "With the rapid advancement of unmanned aerial vehicles (UAVs) and missile\ntechnologies, perimeter-defense game between attackers and defenders for the\nprotection of critical regions have become increasingly complex and\nstrategically significant across a wide range of domains. However, existing\nstudies predominantly focus on small-scale, simplified two-dimensional\nscenarios, often overlooking realistic environmental perturbations, motion\ndynamics, and inherent heterogeneity--factors that pose substantial challenges\nto real-world applicability. To bridge this gap, we investigate large-scale\nheterogeneous perimeter-defense game in a three-dimensional setting,\nincorporating realistic elements such as motion dynamics and wind fields. We\nderive the Nash equilibrium strategies for both attackers and defenders,\ncharacterize the victory regions, and validate our theoretical findings through\nextensive simulations. To tackle large-scale heterogeneous control challenges\nin defense strategies, we propose an Embedded Mean-Field Actor-Critic (EMFAC)\nframework. EMFAC leverages representation learning to enable high-level action\naggregation in a mean-field manner, supporting scalable coordination among\ndefenders. Furthermore, we introduce a lightweight agent-level attention\nmechanism based on reward representation, which selectively filters\nobservations and mean-field information to enhance decision-making efficiency\nand accelerate convergence in large-scale tasks. Extensive simulations across\nvarying scales demonstrate the effectiveness and adaptability of EMFAC, which\noutperforms established baselines in both convergence speed and overall\nperformance. To further validate practicality, we test EMFAC in small-scale\nreal-world experiments and conduct detailed analyses, offering deeper insights\ninto the framework's effectiveness in complex scenarios.",
      "tldr_zh": "该研究针对围界防御游戏中攻击者和防御者的复杂互动，探讨了大规模异质性三维场景，包括运动动态和风场等现实因素，推导了纳什均衡(Nash equilibrium)策略并定义了胜利区域，通过模拟验证了理论结果。论文提出Embedded Mean-Field Actor-Critic (EMFAC)框架，利用表示学习实现高层次行动聚合和可扩展的防御者协调，并引入基于奖励表示的轻量级代理级注意力机制，以提升决策效率和收敛速度。实验显示，EMFAC在不同规模的模拟中优于现有基线，在收敛速度和整体性能上表现出色，并在小规模真实实验中验证了其实际适用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14209v1",
      "published_date": "2025-05-20 11:11:46 UTC",
      "updated_date": "2025-05-20 11:11:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:11:32.748429"
    },
    {
      "arxiv_id": "2505.14206v1",
      "title": "Challenges and Limitations in the Synthetic Generation of mHealth Sensor Data",
      "title_zh": "mHealth 传感器数据合成生成的挑战与限制",
      "authors": [
        "Flavio Di Martino",
        "Franca Delmastro"
      ],
      "abstract": "The widespread adoption of mobile sensors has the potential to provide\nmassive and heterogeneous time series data, driving Artificial Intelligence\napplications in mHealth. However, data collection remains limited due to\nstringent ethical regulations, privacy concerns, and other constraints,\nhindering progress in the field. Synthetic data generation, particularly\nthrough Generative Adversarial Networks and Diffusion Models, has emerged as a\npromising solution to address both data scarcity and privacy issues. Yet, these\nmodels are often limited to short-term, unimodal signal patterns. This paper\npresents a systematic evaluation of state-of-the-art generative models for time\nseries synthesis, with a focus on their ability to jointly handle\nmulti-modality, long-range dependencies, and conditional generation-key\nchallenges in the mHealth domain. To ensure a fair comparison, we introduce a\nnovel evaluation framework designed to measure both the intrinsic quality of\nsynthetic data and its utility in downstream predictive tasks. Our findings\nreveal critical limitations in the existing approaches, particularly in\nmaintaining cross-modal consistency, preserving temporal coherence, and\nensuring robust performance in train-on-synthetic, test-on-real, and data\naugmentation scenarios. Finally, we present our future research directions to\nenhance synthetic time series generation and improve the applicability of\ngenerative models in mHealth.",
      "tldr_zh": "该论文探讨了在 mHealth 领域合成生成传感器数据面临的挑战，包括数据收集受伦理规定和隐私问题限制，以及现有生成模型如 Generative Adversarial Networks (GAN) 和 Diffusion Models 仅限于短期的单模态信号。研究通过系统评估这些模型在处理多模态、长程依赖和条件生成方面的能力，引入了一个新型评估框架来衡量合成数据的内在质量及其在下游预测任务中的实用性。结果显示，现有机型在跨模态一致性、时间连贯性以及训练合成测试真实等场景中存在显著局限，并提出未来研究方向以提升合成时间 series 生成的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to ACM Transactions on Computing for Healthcare (ACM\n  HEALTH)",
      "pdf_url": "http://arxiv.org/pdf/2505.14206v1",
      "published_date": "2025-05-20 11:05:06 UTC",
      "updated_date": "2025-05-20 11:05:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:11:44.892400"
    },
    {
      "arxiv_id": "2505.14201v1",
      "title": "FLASH-D: FlashAttention with Hidden Softmax Division",
      "title_zh": "翻译失败",
      "authors": [
        "Kosmas Alexandridis",
        "Vasileios Titopoulos",
        "Giorgos Dimitrakopoulos"
      ],
      "abstract": "The transformer's attention mechanism has revolutionized AI and machine\nlearning, with its efficient computation being crucial to its performance.\nHowever, calculating attention involves matrix operations interspersed with\nsoftmax rescaling, which inherently slows down computation and requires\nprocessing the entire input sequence. Building on online softmax computation,\nFlashAttention integrates softmax calculation with matrix arithmetic, enabling\ntiled computation independent of sequence length. While optimized for GPUs,\nFlashAttention's simplicity makes it amenable to direct hardware acceleration.\nThis work re-evaluates the core FlashAttention kernel, presenting FLASH-D a\nmathematically equivalent, yet simplified, formulation that achieves: (a)\nhiding softmax division within other non-linear function evaluations; (b)\ninherently numerically stable computation of exponentials, eliminating the need\nfor maximum value subtraction; and (c) a reduction in computational cost\nwithout introducing numerical approximations to the FlashAttention kernel.\nImportantly, the essential FlashAttention properties that facilitate efficient\ntiled implementation are fully preserved. Hardware implementation results at\n28nm demonstrate that this proposed formulation achieves a 22.8% reduction in\narea and a 20.3% reduction in power, on average, compared to state-of-the-art\nparallel hardware architectures without any performance penalty.",
      "tldr_zh": "本研究针对 Transformer 注意力机制中 softmax 计算导致的计算效率问题，提出 FLASH-D，这是一种对 FlashAttention 内核的简化等价公式。FLASH-D 通过将 softmax division 隐藏在其他非线性函数评估中，实现固有数值稳定的指数计算，并减少计算成本，同时保留了 FlashAttention 的高效分块实现特性。实验结果显示，在 28nm 硬件实现中，FLASH-D 平均减少 22.8% 面积和 20.3% 功耗，且不影响性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "IEEE/ACM International Symposium on Low Power Electronics and Design\n  (ISLPED) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.14201v1",
      "published_date": "2025-05-20 11:01:33 UTC",
      "updated_date": "2025-05-20 11:01:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:11:56.602164"
    },
    {
      "arxiv_id": "2505.15854v1",
      "title": "Integration of TinyML and LargeML: A Survey of 6G and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Thai-Hoc Vu",
        "Ngo Hoang Tu",
        "Thien Huynh-The",
        "Kyungchun Lee",
        "Sunghwan Kim",
        "Miroslav Voznak",
        "Quoc-Viet Pham"
      ],
      "abstract": "The transition from 5G networks to 6G highlights a significant demand for\nmachine learning (ML). Deep learning models, in particular, have seen wide\napplication in mobile networking and communications to support advanced\nservices in emerging wireless environments, such as smart healthcare, smart\ngrids, autonomous vehicles, aerial platforms, digital twins, and the metaverse.\nThe rapid expansion of Internet-of-Things (IoT) devices, many with limited\ncomputational capabilities, has accelerated the development of tiny machine\nlearning (TinyML) and resource-efficient ML approaches for cost-effective\nservices. However, the deployment of large-scale machine learning (LargeML)\nsolutions require major computing resources and complex management strategies\nto support extensive IoT services and ML-generated content applications.\nConsequently, the integration of TinyML and LargeML is projected as a promising\napproach for future seamless connectivity and efficient resource management.\n  Although the integration of TinyML and LargeML shows abundant potential,\nseveral challenges persist, including performance optimization, practical\ndeployment strategies, effective resource management, and security\nconsiderations. In this survey, we review and analyze the latest research aimed\nat enabling the integration of TinyML and LargeML models for the realization of\nsmart services and applications in future 6G networks and beyond. The paper\nconcludes by outlining critical challenges and identifying future research\ndirections for the holistic integration of TinyML and LargeML in\nnext-generation wireless networks.",
      "tldr_zh": "本调查论文探讨了 TinyML 和 LargeML 在 6G 及以后网络中的整合，强调了深度学习模型在移动网络中的应用，以支持智能服务如智能医疗、智能电网和元宇宙，同时应对 IoT 设备计算能力有限的挑战。论文回顾了最新研究，分析了整合的潜力，包括实现无缝连接和高效资源管理，但也指出了关键障碍如性能优化、部署策略、安全性和资源管理。最终，论文总结了这些挑战，并提出了未来研究方向，以推动 TinyML 和 LargeML 在下一代无线网络中的全面融合。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.NI",
      "comment": "This work was submitted to IEEE Communications Surveys & Tutorials",
      "pdf_url": "http://arxiv.org/pdf/2505.15854v1",
      "published_date": "2025-05-20 10:54:39 UTC",
      "updated_date": "2025-05-20 10:54:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:12:10.061242"
    },
    {
      "arxiv_id": "2505.14193v1",
      "title": "Dynamic Replanning for Improved Public Transport Routing",
      "title_zh": "动态重新规划以改进公共交通路由",
      "authors": [
        "Abdallah Abuaisha",
        "Bojie Shen",
        "Daniel Harabor",
        "Peter Stuckey",
        "Mark Wallace"
      ],
      "abstract": "Delays in public transport are common, often impacting users through\nprolonged travel times and missed transfers. Existing solutions for handling\ndelays remain limited; backup plans based on historical data miss opportunities\nfor earlier arrivals, while snapshot planning accounts for current delays but\nnot future ones. With the growing availability of live delay data, users can\nadjust their journeys in real-time. However, the literature lacks a framework\nthat fully exploits this advantage for system-scale dynamic replanning. To\naddress this, we formalise the dynamic replanning problem in public transport\nrouting and propose two solutions: a \"pull\" approach, where users manually\nrequest replanning, and a novel \"push\" approach, where the server proactively\nmonitors and adjusts journeys. Our experiments show that the push approach\noutperforms the pull approach, achieving significant speedups. The results also\nreveal substantial arrival time savings enabled by dynamic replanning.",
      "tldr_zh": "本研究针对公共交通延误导致的旅行时间延长和转乘问题，形式化了动态重规划（dynamic replanning）在公共交通路由中的应用，并提出两种解决方案：一种是“pull”方法，用户手动请求重规划；另一种是新型“push”方法，服务器主动监控和调整行程。实验结果显示，“push”方法优于“pull”方法，能够实现显著的速度提升，并带来大量到达时间节省。通过这些创新，论文为充分利用实时延误数据提供了系统级框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication at IJCAI 2025. 8 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.14193v1",
      "published_date": "2025-05-20 10:50:58 UTC",
      "updated_date": "2025-05-20 10:50:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:12:21.477948"
    },
    {
      "arxiv_id": "2505.14190v1",
      "title": "$α$-GAN by Rényi Cross Entropy",
      "title_zh": "翻译失败",
      "authors": [
        "Ni Ding",
        "Miao Qiao",
        "Jiaxing Xu",
        "Yiping Ke",
        "Xiaoyu Zhang"
      ],
      "abstract": "This paper proposes $\\alpha$-GAN, a generative adversarial network using\nR\\'{e}nyi measures. The value function is formulated, by R\\'{e}nyi cross\nentropy, as an expected certainty measure incurred by the discriminator's soft\ndecision as to where the sample is from, true population or the generator. The\ndiscriminator tries to maximize the R\\'{e}nyi certainty about sample source,\nwhile the generator wants to reduce it by injecting fake samples. This forms a\nmin-max problem with the solution parameterized by the R\\'{e}nyi order\n$\\alpha$. This $\\alpha$-GAN reduces to vanilla GAN at $\\alpha = 1$, where the\nvalue function is exactly the binary cross entropy. The optimization of\n$\\alpha$-GAN is over probability (vector) space. It is shown that the gradient\nis exponentially enlarged when R\\'{e}nyi order is in the range $\\alpha \\in\n(0,1)$. This makes convergence faster, which is verified by experimental\nresults. A discussion shows that choosing $\\alpha \\in (0,1)$ may be able to\nsolve some common problems, e.g., vanishing gradient. A following observation\nreveals that this range has not been fully explored in the existing R\\'{e}nyi\nversion GANs.",
      "tldr_zh": "本论文提出了一种名为 $α$-GAN 的生成对抗网络（GAN），其价值函数基于 Rényi 交叉熵，衡量鉴别器对样本来源（真实分布或生成器）的确定性，从而形成一个由 Rényi 阶数 $α$ 参数化的 min-max 问题。$α$-GAN 在 $α = 1$ 时退化为传统 GAN，使用二元交叉熵，而当 $α \\in (0,1)$ 时，梯度被指数放大，导致优化过程收敛更快，并可能解决常见问题如梯度消失。实验结果验证了这一优势，但作者指出，现有的 Rényi 版本 GAN 尚未充分探索 $α \\in (0,1)$ 的范围，为未来研究提供了新方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14190v1",
      "published_date": "2025-05-20 10:45:11 UTC",
      "updated_date": "2025-05-20 10:45:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:12:34.499394"
    },
    {
      "arxiv_id": "2505.14185v1",
      "title": "Safety Subspaces are Not Distinct: A Fine-Tuning Case Study",
      "title_zh": "安全子空间并非独特：一个微调案例研究",
      "authors": [
        "Kaustubh Ponkshe",
        "Shaan Shah",
        "Raghav Singhal",
        "Praneeth Vepakomma"
      ],
      "abstract": "Large Language Models (LLMs) rely on safety alignment to produce socially\nacceptable responses. This is typically achieved through instruction tuning and\nreinforcement learning from human feedback. However, this alignment is known to\nbe brittle: further fine-tuning, even on benign or lightly contaminated data,\ncan degrade safety and reintroduce harmful behaviors. A growing body of work\nsuggests that alignment may correspond to identifiable geometric directions in\nweight space, forming subspaces that could, in principle, be isolated or\npreserved to defend against misalignment. In this work, we conduct a\ncomprehensive empirical study of this geometric perspective. We examine whether\nsafety-relevant behavior is concentrated in specific subspaces, whether it can\nbe separated from general-purpose learning, and whether harmfulness arises from\ndistinguishable patterns in internal representations. Across both parameter and\nactivation space, our findings are consistent: subspaces that amplify safe\nbehaviors also amplify unsafe ones, and prompts with different safety\nimplications activate overlapping representations. We find no evidence of a\nsubspace that selectively governs safety. These results challenge the\nassumption that alignment is geometrically localized. Rather than residing in\ndistinct directions, safety appears to emerge from entangled, high-impact\ncomponents of the model's broader learning dynamics. This suggests that\nsubspace-based defenses may face fundamental limitations and underscores the\nneed for alternative strategies to preserve alignment under continued training.\nWe corroborate these findings through multiple experiments on five open-source\nLLMs. Our code is publicly available at:\nhttps://github.com/CERT-Lab/safety-subspaces.",
      "tldr_zh": "本文通过实证研究探讨了大型语言模型（LLMs）的安全对齐在微调过程中的几何特性，挑战了现有假设，即安全行为可能集中在可隔离的子空间中。研究发现，在参数和激活空间中，放大安全行为的子空间同样会放大不安全行为，且不同安全含义的提示会激活重叠表示，没有证据支持存在选择性管理安全的子空间。这些结果表明，安全对齐并非几何局部化，而是源于模型学习动态中的纠缠组件，因此基于子空间的防御策略可能面临根本限制，并呼吁开发替代方法来维持对齐。实验基于五个开源LLMs，并公开了代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Kaustubh Ponkshe, Shaan Shah, and Raghav Singhal contributed equally\n  to this work",
      "pdf_url": "http://arxiv.org/pdf/2505.14185v1",
      "published_date": "2025-05-20 10:41:49 UTC",
      "updated_date": "2025-05-20 10:41:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:12:45.715283"
    },
    {
      "arxiv_id": "2505.14179v1",
      "title": "Enhancing Abstractive Summarization of Scientific Papers Using Structure Information",
      "title_zh": "利用结构信息增强科学论文的抽象式摘要生成",
      "authors": [
        "Tong Bao",
        "Heng Zhang",
        "Chengzhi Zhang"
      ],
      "abstract": "Abstractive summarization of scientific papers has always been a research\nfocus, yet existing methods face two main challenges. First, most summarization\nmodels rely on Encoder-Decoder architectures that treat papers as sequences of\nwords, thus fail to fully capture the structured information inherent in\nscientific papers. Second, existing research often use keyword mapping or\nfeature engineering to identify the structural information, but these methods\nstruggle with the structural flexibility of scientific papers and lack\nrobustness across different disciplines. To address these challenges, we\npropose a two-stage abstractive summarization framework that leverages\nautomatic recognition of structural functions within scientific papers. In the\nfirst stage, we standardize chapter titles from numerous scientific papers and\nconstruct a large-scale dataset for structural function recognition. A\nclassifier is then trained to automatically identify the key structural\ncomponents (e.g., Background, Methods, Results, Discussion), which provides a\nfoundation for generating more balanced summaries. In the second stage, we\nemploy Longformer to capture rich contextual relationships across sections and\ngenerating context-aware summaries. Experiments conducted on two\ndomain-specific scientific paper summarization datasets demonstrate that our\nmethod outperforms advanced baselines, and generates more comprehensive\nsummaries. The code and dataset can be accessed at\nhttps://github.com/tongbao96/code-for-SFR-AS.",
      "tldr_zh": "该研究针对科学论文抽象摘要的挑战，提出一个两阶段框架，以解决现有Encoder-Decoder模型忽略结构信息和结构识别方法缺乏鲁棒性的问题。\n在第一阶段，通过标准化章节标题并构建大型数据集，训练分类器自动识别关键结构组件（如Background、Methods、Results和Discussion），从而为摘要生成提供平衡基础。\n第二阶段，使用Longformer捕获跨节的上下文关系，生成更全面的上下文感知摘要。\n实验在两个领域特定数据集上表明，该方法优于高级基线，显著提升了摘要的全面性和质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14179v1",
      "published_date": "2025-05-20 10:34:45 UTC",
      "updated_date": "2025-05-20 10:34:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:12:57.940838"
    },
    {
      "arxiv_id": "2505.14178v1",
      "title": "Tokenization Constraints in LLMs: A Study of Symbolic and Arithmetic Reasoning Limits",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Zhang",
        "Juntai Cao",
        "Jiaqi Wei",
        "Yiwei Xu",
        "Chenyu You"
      ],
      "abstract": "Tokenization is the first - and often underappreciated - layer of computation\nin language models. While Chain-of-Thought (CoT) prompting enables transformer\nmodels to approximate recurrent computation by externalizing intermediate\nsteps, we show that the success of such reasoning is fundamentally bounded by\nthe structure of tokenized inputs. This work presents a theoretical and\nempirical investigation into how tokenization schemes, particularly\nsubword-based methods like byte-pair encoding (BPE), impede symbolic\ncomputation by merging or obscuring atomic reasoning units. We introduce the\nnotion of Token Awareness to formalize how poor token granularity disrupts\nlogical alignment and prevents models from generalizing symbolic procedures.\nThrough systematic evaluation on arithmetic and symbolic tasks, we demonstrate\nthat token structure dramatically affect reasoning performance, causing failure\neven with CoT, while atomically-aligned formats unlock strong generalization,\nallowing small models (e.g., GPT-4o-mini) to outperform larger systems (e.g.,\no1) in structured reasoning. Our findings reveal that symbolic reasoning\nability in LLMs is not purely architectural, but deeply conditioned on\ntoken-level representations.",
      "tldr_zh": "本文研究了大型语言模型(LLMs)中 tokenization 的限制，探讨其对符号和算术推理能力的制约。作者引入 Token Awareness 概念，理论和实证分析了 subword-based 方法如 byte-pair encoding (BPE) 如何通过合并或模糊原子推理单位来破坏逻辑对齐，即使使用 Chain-of-Thought (CoT) 提示也可能导致性能失败。实验结果显示，原子对齐的 token 格式能显著提升泛化能力，使小模型（如 GPT-4o-mini）在结构化任务中胜过大模型（如 o1）。总之，该研究强调了 LLMs 的符号推理能力不仅依赖于模型架构，还深受 token-level 表示的影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14178v1",
      "published_date": "2025-05-20 10:32:30 UTC",
      "updated_date": "2025-05-20 10:32:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:13:10.577608"
    },
    {
      "arxiv_id": "2505.14163v1",
      "title": "DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation",
      "title_zh": "DSMentor：通过课程学习和在线知识积累增强数据科学代理",
      "authors": [
        "He Wang",
        "Alexander Hanbo Li",
        "Yiqun Hu",
        "Sheng Zhang",
        "Hideo Kobayashi",
        "Jiani Zhang",
        "Henry Zhu",
        "Chung-Wei Hang",
        "Patrick Ng"
      ],
      "abstract": "Large language model (LLM) agents have shown promising performance in\ngenerating code for solving complex data science problems. Recent studies\nprimarily focus on enhancing in-context learning through improved search,\nsampling, and planning techniques, while overlooking the importance of the\norder in which problems are tackled during inference. In this work, we develop\na novel inference-time optimization framework, referred to as DSMentor, which\nleverages curriculum learning -- a strategy that introduces simpler task first\nand progressively moves to more complex ones as the learner improves -- to\nenhance LLM agent performance in challenging data science tasks. Our\nmentor-guided framework organizes data science tasks in order of increasing\ndifficulty and incorporates a growing long-term memory to retain prior\nexperiences, guiding the agent's learning progression and enabling more\neffective utilization of accumulated knowledge. We evaluate DSMentor through\nextensive experiments on DSEval and QRData benchmarks. Experiments show that\nDSMentor using Claude-3.5-Sonnet improves the pass rate by up to 5.2% on DSEval\nand QRData compared to baseline agents. Furthermore, DSMentor demonstrates\nstronger causal reasoning ability, improving the pass rate by 8.8% on the\ncausality problems compared to GPT-4 using Program-of-Thoughts prompts. Our\nwork underscores the importance of developing effective strategies for\naccumulating and utilizing knowledge during inference, mirroring the human\nlearning process and opening new avenues for improving LLM performance through\ncurriculum-based inference optimization.",
      "tldr_zh": "本研究开发了DSMentor框架，利用Curriculum Learning和在线知识积累来提升LLM agents在数据科学任务中的性能。该框架通过先从简单任务开始逐步过渡到复杂任务，并使用长效记忆保留先前经验，帮助代理更有效地利用积累知识。在DSEval和QRData基准测试中，DSMentor基于Claude-3.5-Sonnet模型将通过率提高了最多5.2%，并在因果推理任务上比GPT-4提升了8.8%。这项工作强调了在推理过程中优化知识积累的重要性，模拟人类学习过程，为改进LLM性能提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14163v1",
      "published_date": "2025-05-20 10:16:21 UTC",
      "updated_date": "2025-05-20 10:16:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:13:22.803060"
    },
    {
      "arxiv_id": "2505.14157v1",
      "title": "Prior Prompt Engineering for Reinforcement Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Pittawat Taveekitworachai",
        "Potsawee Manakul",
        "Sarana Nutanong",
        "Kunat Pipatanakul"
      ],
      "abstract": "This paper investigates prior prompt engineering (pPE) in the context of\nreinforcement fine-tuning (RFT), where language models (LMs) are incentivized\nto exhibit behaviors that maximize performance through reward signals. While\nexisting RFT research has primarily focused on algorithms, reward shaping, and\ndata curation, the design of the prior prompt--the instructions prepended to\nqueries during training to elicit behaviors such as step-by-step\nreasoning--remains underexplored. We investigate whether different pPE\napproaches can guide LMs to internalize distinct behaviors after RFT. Inspired\nby inference-time prompt engineering (iPE), we translate five representative\niPE strategies--reasoning, planning, code-based reasoning, knowledge recall,\nand null-example utilization--into corresponding pPE approaches. We experiment\nwith Qwen2.5-7B using each of the pPE approaches, then evaluate performance on\nin-domain and out-of-domain benchmarks (e.g., AIME2024, HumanEval+, and\nGPQA-Diamond). Our results show that all pPE-trained models surpass their\niPE-prompted counterparts, with the null-example pPE approach achieving the\nlargest average performance gain and the highest improvement on AIME2024 and\nGPQA-Diamond, surpassing the commonly used reasoning approach. Furthermore, by\nadapting a behavior-classification framework, we demonstrate that different pPE\nstrategies instill distinct behavioral styles in the resulting models. These\nfindings position pPE as a powerful yet understudied axis for RFT.",
      "tldr_zh": "本文探讨了prior prompt engineering (pPE) 在reinforcement fine-tuning (RFT) 中的作用，旨在通过设计训练提示引导语言模型(LMs) 内部化特定行为，如逐步推理或规划。作者从inference-time prompt engineering (iPE) 策略中汲取灵感，将五种方法（包括推理、规划、基于代码的推理、知识回忆和空示例利用）转化为pPE 策略，并在Qwen2.5-7B 模型上进行实验。结果显示，所有pPE 训练模型在AIME2024、HumanEval+ 和GPQA-Diamond 等基准上均优于iPE 对应模型，其中null-example pPE 方法实现最大性能提升，并证明不同pPE 策略能赋予模型独特行为风格。这些发现突显pPE 作为RFT 中一个强大且未充分研究的领域。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages, 42 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.14157v1",
      "published_date": "2025-05-20 10:05:11 UTC",
      "updated_date": "2025-05-20 10:05:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:13:36.011558"
    },
    {
      "arxiv_id": "2505.14156v1",
      "title": "Unify Graph Learning with Text: Unleashing LLM Potentials for Session Search",
      "title_zh": "统一图学习与文本：释放 LLM 潜力用于会话搜索",
      "authors": [
        "Songhao Wu",
        "Quan Tu",
        "Hong Liu",
        "Jia Xu",
        "Zhongyi Liu",
        "Guannan Zhang",
        "Ran Wang",
        "Xiuying Chen",
        "Rui Yan"
      ],
      "abstract": "Session search involves a series of interactive queries and actions to\nfulfill user's complex information need. Current strategies typically\nprioritize sequential modeling for deep semantic understanding, overlooking the\ngraph structure in interactions. While some approaches focus on capturing\nstructural information, they use a generalized representation for documents,\nneglecting the word-level semantic modeling. In this paper, we propose Symbolic\nGraph Ranker (SGR), which aims to take advantage of both text-based and\ngraph-based approaches by leveraging the power of recent Large Language Models\n(LLMs). Concretely, we first introduce a set of symbolic grammar rules to\nconvert session graph into text. This allows integrating session history,\ninteraction process, and task instruction seamlessly as inputs for the LLM.\nMoreover, given the natural discrepancy between LLMs pre-trained on textual\ncorpora, and the symbolic language we produce using our graph-to-text grammar,\nour objective is to enhance LLMs' ability to capture graph structures within a\ntextual format. To achieve this, we introduce a set of self-supervised symbolic\nlearning tasks including link prediction, node content generation, and\ngenerative contrastive learning, to enable LLMs to capture the topological\ninformation from coarse-grained to fine-grained. Experiment results and\ncomprehensive analysis on two benchmark datasets, AOL and Tiangong-ST, confirm\nthe superiority of our approach. Our paradigm also offers a novel and effective\nmethodology that bridges the gap between traditional search strategies and\nmodern LLMs.",
      "tldr_zh": "本文提出 Symbolic Graph Ranker (SGR)，一种整合图学习和文本的方法，利用 Large Language Models (LLMs) 来提升 session search 的性能，通过符号语法规则将 session 图转换为文本，便于无缝整合历史交互和任务指令。SGR 引入自监督学习任务，包括链接预测、节点内容生成和生成对比学习，帮助 LLM 从粗到细捕捉图拓扑信息，解决传统方法忽略图结构或词级语义的问题。实验在 AOL 和 Tiangong-ST 数据集上显示，SGR 显著优于基线方法，并提供了一种创新范式，桥接传统搜索策略与现代 LLM。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "I.2; H.3.3"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14156v1",
      "published_date": "2025-05-20 10:05:06 UTC",
      "updated_date": "2025-05-20 10:05:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:13:45.778958"
    },
    {
      "arxiv_id": "2505.14148v1",
      "title": "MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Liu",
        "Zherui Yang",
        "Cancheng Liu",
        "Tianrui Song",
        "Xiaofeng Gao",
        "Hao Liu"
      ],
      "abstract": "Mathematical modeling is a cornerstone of scientific discovery and\nengineering practice, enabling the translation of real-world problems into\nformal systems across domains such as physics, biology, and economics. Unlike\nmathematical reasoning, which assumes a predefined formulation, modeling\nrequires open-ended problem analysis, abstraction, and principled\nformalization. While Large Language Models (LLMs) have shown strong reasoning\ncapabilities, they fall short in rigorous model construction, limiting their\nutility in real-world problem-solving. To this end, we formalize the task of\nLLM-powered real-world mathematical modeling, where agents must analyze\nproblems, construct domain-appropriate formulations, and generate complete\nend-to-end solutions. We introduce MM-Bench, a curated benchmark of 111\nproblems from the Mathematical Contest in Modeling (MCM/ICM), spanning the\nyears 2000 to 2025 and across ten diverse domains such as physics, biology, and\neconomics. To tackle this task, we propose MM-Agent, an expert-inspired\nframework that decomposes mathematical modeling into four stages: open-ended\nproblem analysis, structured model formulation, computational problem solving,\nand report generation. Experiments on MM-Bench show that MM-Agent significantly\noutperforms baseline agents, achieving an 11.88\\% improvement over human expert\nsolutions while requiring only 15 minutes and \\$0.88 per task using GPT-4o.\nFurthermore, under official MCM/ICM protocols, MM-Agent assisted two\nundergraduate teams in winning the Finalist Award (\\textbf{top 2.0\\% among\n27,456 teams}) in MCM/ICM 2025, demonstrating its practical effectiveness as a\nmodeling copilot. Our code is available at\nhttps://github.com/usail-hkust/LLM-MM-Agent",
      "tldr_zh": "这篇论文提出 MM-Agent，一种利用大语言模型(LLM)作为代理的框架，用于处理真实世界的数学建模问题，强调了 LLM 在问题分析、抽象和模型正式化方面的潜力，同时解决其在严格建模中的不足。论文正式化了该任务并引入 MM-Bench，一个包含 111 个问题的基准，涵盖 2000-2025 年 MCM/ICM 比赛的十个领域。MM-Agent 将建模过程分解为四个阶段：开放式问题分析、结构化模型制定、计算问题解决和报告生成，实验显示其在 MM-Bench 上比基线提升 11.88%，使用 GPT-4o 仅需 15 分钟和 0.88 美元每任务，并在 MCM/ICM 2025 实际应用中帮助团队获得 Finalist Award（前 2.0%）。这项工作为 LLM 在数学建模中的应用提供了可行框架，并开源了代码。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14148v1",
      "published_date": "2025-05-20 09:55:31 UTC",
      "updated_date": "2025-05-20 09:55:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:13:58.809037"
    },
    {
      "arxiv_id": "2505.14147v2",
      "title": "SHARP: Synthesizing High-quality Aligned Reasoning Problems for Large Reasoning Models Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiong Jun Wu",
        "Zhenduo Zhang",
        "ZuJie Wen",
        "Zhiqiang Zhang",
        "Wang Ren",
        "Lei Shi",
        "Cai Chen",
        "Deng Zhao",
        "Dingnan Jin",
        "Qing Cui",
        "Jun Zhou"
      ],
      "abstract": "Training large reasoning models (LRMs) with reinforcement learning in STEM\ndomains is hindered by the scarcity of high-quality, diverse, and verifiable\nproblem sets. Existing synthesis methods, such as Chain-of-Thought prompting,\noften generate oversimplified or uncheckable data, limiting model advancement\non complex tasks. To address these challenges, we introduce SHARP, a unified\napproach to Synthesizing High-quality Aligned Reasoning Problems for LRMs\nreinforcement learning with verifiable rewards (RLVR). SHARP encompasses a\nstrategic set of self-alignment principles -- targeting graduate and\nOlympiad-level difficulty, rigorous logical consistency, and unambiguous,\nverifiable answers -- and a structured three-phase framework (Alignment,\nInstantiation, Inference) that ensures thematic diversity and fine-grained\ncontrol over problem generation. We implement SHARP by leveraging a\nstate-of-the-art LRM to infer and verify challenging STEM questions, then\nemploy a reinforcement learning loop to refine the model's reasoning through\nverifiable reward signals. Experiments on benchmarks such as GPQA demonstrate\nthat SHARP-augmented training substantially outperforms existing methods,\nmarkedly improving complex reasoning accuracy and pushing LRM performance\ncloser to expert-level proficiency. Our contributions include the SHARP\nstrategy, framework design, end-to-end implementation, and experimental\nevaluation of its effectiveness in elevating LRM reasoning capabilities.",
      "tldr_zh": "该论文提出 SHARP 方法，旨在解决训练大型推理模型 (LRMs) 在 STEM 领域时高质量、可验证问题集短缺的问题，通过自对齐原则和三阶段框架 (Alignment, Instantiation, Inference) 生成难度高、逻辑一致且可验证的推理问题，并结合强化学习 (RL) 循环进行模型优化。SHARP 确保问题主题多样性和细粒度控制，使用先进的 LRM 来推断和验证挑战性 STEM 问题。实验结果显示，在 GPQA 等基准上，SHARP 显著提高了 LRM 的复杂推理准确率，使其性能接近专家水平，并为 LRM 训练提供了关键策略、框架设计和端到端实现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14147v2",
      "published_date": "2025-05-20 09:54:42 UTC",
      "updated_date": "2025-05-21 11:15:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:14:10.864200"
    },
    {
      "arxiv_id": "2505.14146v1",
      "title": "s3: You Don't Need That Much Data to Train a Search Agent via RL",
      "title_zh": "翻译失败",
      "authors": [
        "Pengcheng Jiang",
        "Xueqiang Xu",
        "Jiacheng Lin",
        "Jinfeng Xiao",
        "Zifeng Wang",
        "Jimeng Sun",
        "Jiawei Han"
      ],
      "abstract": "Retrieval-augmented generation (RAG) systems empower large language models\n(LLMs) to access external knowledge during inference. Recent advances have\nenabled LLMs to act as search agents via reinforcement learning (RL), improving\ninformation acquisition through multi-turn interactions with retrieval engines.\nHowever, existing approaches either optimize retrieval using search-only\nmetrics (e.g., NDCG) that ignore downstream utility or fine-tune the entire LLM\nto jointly reason and retrieve-entangling retrieval with generation and\nlimiting the real search utility and compatibility with frozen or proprietary\nmodels. In this work, we propose s3, a lightweight, model-agnostic framework\nthat decouples the searcher from the generator and trains the searcher using a\nGain Beyond RAG reward: the improvement in generation accuracy over naive RAG.\ns3 requires only 2.4k training samples to outperform baselines trained on over\n70x more data, consistently delivering stronger downstream performance across\nsix general QA and five medical QA benchmarks.",
      "tldr_zh": "该论文提出 s3 框架，一种轻量级、模型无关的方法，用于通过强化学习 (RL) 训练搜索代理，而无需大量数据。s3 通过解耦搜索器和生成器，使用 Gain Beyond RAG 奖励（基于生成准确度的改进）来优化检索，避免了现有方法如 NDCG 指标的局限性或对整个大型语言模型 (LLMs) 的微调。实验结果显示，s3 仅需 2.4k 训练样本，就在六个通用 QA 和五个医疗 QA 基准上超越了使用 70 倍更多数据的基线模型，提供更高效的检索增强生成 (RAG) 系统。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14146v1",
      "published_date": "2025-05-20 09:53:56 UTC",
      "updated_date": "2025-05-20 09:53:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:14:23.766482"
    },
    {
      "arxiv_id": "2505.14143v1",
      "title": "Multimodal Mixture of Low-Rank Experts for Sentiment Analysis and Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Shuo Zhang",
        "Jinsong Zhang",
        "Zhejun Zhang",
        "Lei Li"
      ],
      "abstract": "Multi-task learning (MTL) enables the efficient transfer of extra knowledge\nacquired from other tasks. The high correlation between multimodal sentiment\nanalysis (MSA) and multimodal emotion recognition (MER) supports their joint\ntraining. However, existing methods primarily employ hard parameter sharing,\nignoring parameter conflicts caused by complex task correlations. In this\npaper, we present a novel MTL method for MSA and MER, termed Multimodal Mixture\nof Low-Rank Experts (MMoLRE). MMoLRE utilizes shared and task-specific experts\nto distinctly model common and unique task characteristics, thereby avoiding\nparameter conflicts. Additionally, inspired by low-rank structures in the\nMixture of Experts (MoE) framework, we design low-rank expert networks to\nreduce parameter and computational overhead as the number of experts increases.\nExtensive experiments on the CMU-MOSI and CMU-MOSEI benchmarks demonstrate that\nMMoLRE achieves state-of-the-art performance on the MSA task and competitive\nresults on the MER task.",
      "tldr_zh": "该论文提出了一种新型多任务学习(MTL)方法，名为Multimodal Mixture of Low-Rank Experts (MMoLRE)，用于多模态情感分析(MSA)和多模态情感识别(MER)，以解决现有硬参数共享方法中参数冲突的问题。MMoLRE 通过共享专家和任务特定专家来分别建模任务的共同和独特特征，同时采用低秩专家网络设计，减少参数和计算开销。实验在 CMU-MOSI 和 CMU-MOSEI 基准上显示，MMoLRE 在 MSA 任务上达到最先进性能，在 MER 任务上取得竞争性结果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ICME 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.14143v1",
      "published_date": "2025-05-20 09:46:56 UTC",
      "updated_date": "2025-05-20 09:46:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:14:34.162141"
    },
    {
      "arxiv_id": "2505.14141v1",
      "title": "Building a Stable Planner: An Extended Finite State Machine Based Planning Module for Mobile GUI Agent",
      "title_zh": "构建稳定规划器：一个基于扩展有限状态机的移动 GUI 代理规划模块",
      "authors": [
        "Fanglin Mo",
        "Junzhe Chen",
        "Haoxuan Zhu",
        "Xuming Hu"
      ],
      "abstract": "Mobile GUI agents execute user commands by directly interacting with the\ngraphical user interface (GUI) of mobile devices, demonstrating significant\npotential to enhance user convenience. However, these agents face considerable\nchallenges in task planning, as they must continuously analyze the GUI and\ngenerate operation instructions step by step. This process often leads to\ndifficulties in making accurate task plans, as GUI agents lack a deep\nunderstanding of how to effectively use the target applications, which can\ncause them to become \"lost\" during task execution. To address the task planning\nissue, we propose SPlanner, a plug-and-play planning module to generate\nexecution plans that guide vision language model(VLMs) in executing tasks. The\nproposed planning module utilizes extended finite state machines (EFSMs) to\nmodel the control logits and configurations of mobile applications. It then\ndecomposes a user instruction into a sequence of primary function modeled in\nEFSMs, and generate the execution path by traversing the EFSMs. We further\nrefine the execution path into a natural language plan using an LLM. The final\nplan is concise and actionable, and effectively guides VLMs to generate\ninteractive GUI actions to accomplish user tasks. SPlanner demonstrates strong\nperformance on dynamic benchmarks reflecting real-world mobile usage. On the\nAndroidWorld benchmark, SPlanner achieves a 63.8% task success rate when paired\nwith Qwen2.5-VL-72B as the VLM executor, yielding a 28.8 percentage point\nimprovement compared to using Qwen2.5-VL-72B without planning assistance.",
      "tldr_zh": "本论文针对移动 GUI 代理在任务规划中的挑战（如缺乏对应用理解导致执行失败），提出 SPlanner，这是一个基于 Extended Finite State Machines (EFSMs) 的插件式规划模块，用于指导 Vision Language Model (VLMs) 执行任务。SPlanner 通过建模应用控制逻辑，将用户指令分解成 EFSMs 序列、生成执行路径，并利用 Large Language Model (LLM) 转化为简洁可操作的自然语言计划。实验结果显示，在 AndroidWorld 基准测试中，SPlanner 与 Qwen2.5-VL-72B 结合，任务成功率达 63.8%，较无规划辅助提升 28.8 百分点。",
      "categories": [
        "cs.AI",
        "I.2.11; H.5.2"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages. Submitted to EMNLP 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.14141v1",
      "published_date": "2025-05-20 09:45:55 UTC",
      "updated_date": "2025-05-20 09:45:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:14:48.677954"
    },
    {
      "arxiv_id": "2505.14140v1",
      "title": "RL of Thoughts: Navigating LLM Reasoning with Inference-time Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Qianyue Hao",
        "Sibo Li",
        "Jian Yuan",
        "Yong Li"
      ],
      "abstract": "Despite rapid advancements in large language models (LLMs), the token-level\nautoregressive nature constrains their complex reasoning capabilities. To\nenhance LLM reasoning, inference-time techniques, including\nChain/Tree/Graph-of-Thought(s), successfully improve the performance, as they\nare fairly cost-effective by guiding reasoning through sophisticated logical\nstructures without modifying LLMs' parameters. However, these manually\npredefined, task-agnostic frameworks are applied uniformly across diverse\ntasks, lacking adaptability. To improve this, we propose RL-of-Thoughts (RLoT),\nwhere we train a lightweight navigator model with reinforcement learning (RL)\nto adaptively enhance LLM reasoning at inference time. Specifically, we design\nfive basic logic blocks from the perspective of human cognition. During the\nreasoning process, the trained RL navigator dynamically selects the suitable\nlogic blocks and combines them into task-specific logical structures according\nto problem characteristics. Experiments across multiple reasoning benchmarks\n(AIME, MATH, GPQA, etc.) with multiple LLMs (GPT, Llama, Qwen, and DeepSeek)\nillustrate that RLoT outperforms established inference-time techniques by up to\n13.4%. Remarkably, with less than 3K parameters, our RL navigator is able to\nmake sub-10B LLMs comparable to 100B-scale counterparts. Moreover, the RL\nnavigator demonstrates strong transferability: a model trained on one specific\nLLM-task pair can effectively generalize to unseen LLMs and tasks. Our code is\nopen-source at https://anonymous.4open.science/r/RL-LLM-Reasoning-1A30 for\nreproducibility.",
      "tldr_zh": "该论文提出 RL-of-Thoughts (RLoT) 方法，使用推理时的强化学习 (RL) 训练一个轻量级 navigator 模型，来动态提升大型语言模型 (LLMs) 的复杂推理能力。具体而言，该方法从人类认知角度设计五个基本逻辑块，并在推理过程中让 navigator 动态选择和组合这些块，以适应特定任务的需求。实验结果显示，RLoT 在多个推理基准（如 AIME、MATH 和 GPQA）上与多种 LLMs（如 GPT、Llama 等）结合后，性能比现有 Chain-of-Thought 等技术提高高达 13.4%，并使参数小于 10B 的模型性能接近 100B 级模型，同时展现出优秀的跨模型和跨任务转移能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14140v1",
      "published_date": "2025-05-20 09:43:33 UTC",
      "updated_date": "2025-05-20 09:43:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:15:01.280284"
    },
    {
      "arxiv_id": "2505.14139v1",
      "title": "FlowQ: Energy-Guided Flow Policies for Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Marvin Alles",
        "Nutan Chen",
        "Patrick van der Smagt",
        "Botond Cseke"
      ],
      "abstract": "The use of guidance to steer sampling toward desired outcomes has been widely\nexplored within diffusion models, especially in applications such as image and\ntrajectory generation. However, incorporating guidance during training remains\nrelatively underexplored. In this work, we introduce energy-guided flow\nmatching, a novel approach that enhances the training of flow models and\neliminates the need for guidance at inference time. We learn a conditional\nvelocity field corresponding to the flow policy by approximating an\nenergy-guided probability path as a Gaussian path. Learning guided trajectories\nis appealing for tasks where the target distribution is defined by a\ncombination of data and an energy function, as in reinforcement learning.\nDiffusion-based policies have recently attracted attention for their expressive\npower and ability to capture multi-modal action distributions. Typically, these\npolicies are optimized using weighted objectives or by back-propagating\ngradients through actions sampled by the policy. As an alternative, we propose\nFlowQ, an offline reinforcement learning algorithm based on energy-guided flow\nmatching. Our method achieves competitive performance while the policy training\ntime is constant in the number of flow sampling steps.",
      "tldr_zh": "本研究引入了energy-guided flow matching，一种新方法，用于增强flow models的训练过程，通过将energy-guided probability path近似为Gaussian path来学习conditional velocity field，从而避免在推理时需要指导。论文提出FlowQ算法，这是一种基于energy-guided flow matching的offline reinforcement learning方法，适用于目标分布由数据和energy function组合定义的场景。相比传统扩散-based policies，FlowQ在性能上具有竞争力，且其政策训练时间与flow sampling步骤数无关，提供了一种高效的强化学习策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14139v1",
      "published_date": "2025-05-20 09:43:05 UTC",
      "updated_date": "2025-05-20 09:43:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:15:10.710656"
    },
    {
      "arxiv_id": "2505.14137v1",
      "title": "Memory Assignment for Finite-Memory Strategies in Adversarial Patrolling Games",
      "title_zh": "翻译失败",
      "authors": [
        "Vojtěch Kůr",
        "Vít Musil",
        "Vojtěch Řehák"
      ],
      "abstract": "Adversarial Patrolling games form a subclass of Security games where a\nDefender moves between locations, guarding vulnerable targets. The main\nalgorithmic problem is constructing a strategy for the Defender that minimizes\nthe worst damage an Attacker can cause. We focus on the class of finite-memory\n(also known as regular) Defender's strategies that experimentally outperformed\nother competing classes. A finite-memory strategy can be seen as a positional\nstrategy on a finite set of states. Each state consists of a pair of a location\nand a certain integer value--called memory. Existing algorithms improve the\ntransitional probabilities between the states but require that the available\nmemory size itself is assigned at each location manually. Choosing the right\nmemory assignment is a well-known open and hard problem that hinders the\nusability of finite-memory strategies. We solve this issue by developing a\ngeneral method that iteratively changes the memory assignment. Our algorithm\ncan be used in connection with \\emph{any} black-box strategy optimization tool.\nWe evaluate our method on various experiments and show its robustness by\nsolving instances of various patrolling models.",
      "tldr_zh": "本文针对Adversarial Patrolling Games中防守者的finite-memory strategies，解决了memory assignment的难题，该问题长期阻碍了这些策略的实际应用。研究提出了一种通用迭代方法，能够自动调整memory分配，并与任何黑箱策略优化工具无缝结合。实验结果显示，该方法在各种巡逻模型实例上表现出鲁棒性，提高了防守策略的优化效率和可用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14137v1",
      "published_date": "2025-05-20 09:40:53 UTC",
      "updated_date": "2025-05-20 09:40:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:15:23.296055"
    },
    {
      "arxiv_id": "2505.14136v1",
      "title": "Local Mixtures of Experts: Essentially Free Test-Time Training via Model Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Ryo Bertolissi",
        "Jonas Hübotter",
        "Ido Hakimi",
        "Andreas Krause"
      ],
      "abstract": "Mixture of expert (MoE) models are a promising approach to increasing model\ncapacity without increasing inference cost, and are core components of many\nstate-of-the-art language models. However, current MoE models typically use\nonly few experts due to prohibitive training and inference cost. We propose\nTest-Time Model Merging (TTMM) which scales the MoE paradigm to an order of\nmagnitude more experts and uses model merging to avoid almost any test-time\noverhead. We show that TTMM is an approximation of test-time training (TTT),\nwhich fine-tunes an expert model for each prediction task, i.e., prompt. TTT\nhas recently been shown to significantly improve language models, but is\ncomputationally expensive. We find that performance of TTMM improves with more\nexperts and approaches the performance of TTT. Moreover, we find that with a 1B\nparameter base model, TTMM is more than 100x faster than TTT at test-time by\namortizing the cost of TTT at train-time. Thus, TTMM offers a promising\ncost-effective approach to scale test-time training.",
      "tldr_zh": "本文提出 Test-Time Model Merging (TTMM)，一种扩展 Mixture of Expert (MoE) 模型的方法，能够将专家数量增加一个数量级，同时通过模型合并避免测试时开销。TTMM 近似于 test-time training (TTT)，后者通过为每个预测任务（如提示）微调专家模型来显著提升语言模型性能，但计算成本高昂。研究发现，TTMM 的性能随专家数量增加而改善，并接近 TTT，同时在使用 1B 参数基模型时，TTMM 在测试时比 TTT 快 100 倍以上。通过这种成本有效的途径，TTMM 为大规模测试时训练提供了可行解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14136v1",
      "published_date": "2025-05-20 09:39:54 UTC",
      "updated_date": "2025-05-20 09:39:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:15:36.772027"
    },
    {
      "arxiv_id": "2505.14128v1",
      "title": "A Methodological Framework for Measuring Spatial Labeling Similarity",
      "title_zh": "测量空间标记相似性的方法论框架",
      "authors": [
        "Yihang Du",
        "Jiaying Hu",
        "Suyang Hou",
        "Yueyang Ding",
        "Xiaobo Sun"
      ],
      "abstract": "Spatial labeling assigns labels to specific spatial locations to characterize\ntheir spatial properties and relationships, with broad applications in\nscientific research and practice. Measuring the similarity between two spatial\nlabelings is essential for understanding their differences and the contributing\nfactors, such as changes in location properties or labeling methods. An\nadequate and unbiased measurement of spatial labeling similarity should\nconsider the number of matched labels (label agreement), the topology of\nspatial label distribution, and the heterogeneous impacts of mismatched labels.\nHowever, existing methods often fail to account for all these aspects. To\naddress this gap, we propose a methodological framework to guide the\ndevelopment of methods that meet these requirements. Given two spatial\nlabelings, the framework transforms them into graphs based on location\norganization, labels, and attributes (e.g., location significance). The\ndistributions of their graph attributes are then extracted, enabling an\nefficient computation of distributional discrepancy to reflect the\ndissimilarity level between the two labelings. We further provide a concrete\nimplementation of this framework, termed Spatial Labeling Analogy Metric\n(SLAM), along with an analysis of its theoretical foundation, for evaluating\nspatial labeling results in spatial transcriptomics (ST) \\textit{as per} their\nsimilarity with ground truth labeling. Through a series of carefully designed\nexperimental cases involving both simulated and real ST data, we demonstrate\nthat SLAM provides a comprehensive and accurate reflection of labeling quality\ncompared to other well-established evaluation metrics. Our code is available at\nhttps://github.com/YihDu/SLAM.",
      "tldr_zh": "这篇论文提出一个方法论框架，用于测量 Spatial Labeling 的相似性，考虑标签匹配（label agreement）、空间标签分布的拓扑结构，以及不匹配标签的异质影响，以解决现有方法的不足。框架将两个 Spatial Labeling 转化为基于位置组织、标签和属性的图表，然后提取图属性分布并计算分布差异，以高效评估相似性水平。具体实现为 Spatial Labeling Analogy Metric (SLAM)，应用于 spatial transcriptomics (ST) 的标签质量评估；实验结果显示，SLAM 在模拟和真实 ST 数据上比其他指标更全面准确地反映标签质量，并提供开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14128v1",
      "published_date": "2025-05-20 09:34:03 UTC",
      "updated_date": "2025-05-20 09:34:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:15:47.798046"
    },
    {
      "arxiv_id": "2505.14125v1",
      "title": "Contrastive Consolidation of Top-Down Modulations Achieves Sparsely Supervised Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Viet Anh Khoa Tran",
        "Emre Neftci",
        "Willem. A. M. Wybo"
      ],
      "abstract": "Biological brains learn continually from a stream of unlabeled data, while\nintegrating specialized information from sparsely labeled examples without\ncompromising their ability to generalize. Meanwhile, machine learning methods\nare susceptible to catastrophic forgetting in this natural learning setting, as\nsupervised specialist fine-tuning degrades performance on the original task. We\nintroduce task-modulated contrastive learning (TMCL), which takes inspiration\nfrom the biophysical machinery in the neocortex, using predictive coding\nprinciples to integrate top-down information continually and without\nsupervision. We follow the idea that these principles build a view-invariant\nrepresentation space, and that this can be implemented using a contrastive\nloss. Then, whenever labeled samples of a new class occur, new affine\nmodulations are learned that improve separation of the new class from all\nothers, without affecting feedforward weights. By co-opting the view-invariance\nlearning mechanism, we then train feedforward weights to match the unmodulated\nrepresentation of a data sample to its modulated counterparts. This introduces\nmodulation invariance into the representation space, and, by also using past\nmodulations, stabilizes it. Our experiments show improvements in both\nclass-incremental and transfer learning over state-of-the-art unsupervised\napproaches, as well as over comparable supervised approaches, using as few as\n1% of available labels. Taken together, our work suggests that top-down\nmodulations play a crucial role in balancing stability and plasticity.",
      "tldr_zh": "本论文提出了一种名为 task-modulated contrastive learning (TMCL) 的方法，旨在模拟大脑新皮层通过预测编码原则实现稀疏监督的持续学习，从而在处理未标记数据流时避免灾难性遗忘。TMCL 使用 contrastive loss 构建不变表示空间，并在新类标签出现时学习新的顶层调制（top-down modulations）来增强类分离，同时通过调制不变性稳定整体表示。实验结果显示，该方法在类增量学习和迁移学习中，使用仅1%的标签就超过了现有无监督和监督基准，强调了顶层调制在平衡稳定性和可塑性方面的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC",
        "68T05 (primary), 68T07, 68T45 (secondary)",
        "I.2.6; I.2.10"
      ],
      "primary_category": "cs.LG",
      "comment": "33 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.14125v1",
      "published_date": "2025-05-20 09:31:57 UTC",
      "updated_date": "2025-05-20 09:31:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:15:59.626743"
    },
    {
      "arxiv_id": "2505.14117v1",
      "title": "Collaborative Unlabeled Data Optimization",
      "title_zh": "协作无标签数据优化",
      "authors": [
        "Xinyi Shang",
        "Peng Sun",
        "Fengyuan Liu",
        "Tao Lin"
      ],
      "abstract": "This paper pioneers a novel data-centric paradigm to maximize the utility of\nunlabeled data, tackling a critical question: How can we enhance the efficiency\nand sustainability of deep learning training by optimizing the data itself? We\nbegin by identifying three key limitations in existing model-centric\napproaches, all rooted in a shared bottleneck: knowledge extracted from data is\nlocked to model parameters, hindering its reusability and scalability. To this\nend, we propose CoOpt, a highly efficient, parallelized framework for\ncollaborative unlabeled data optimization, thereby effectively encoding\nknowledge into the data itself. By distributing unlabeled data and leveraging\npublicly available task-agnostic models, CoOpt facilitates scalable, reusable,\nand sustainable training pipelines. Extensive experiments across diverse\ndatasets and architectures demonstrate its efficacy and efficiency, achieving\n13.6% and 6.8% improvements on Tiny-ImageNet and ImageNet-1K, respectively,\nwith training speedups of $1.94 \\times $ and $1.2 \\times$.",
      "tldr_zh": "这篇论文提出了一种新型数据中心范式，旨在通过优化无标签数据来提升深度学习训练的效率和可持续性，解决现有模型中心方法中知识锁定于参数导致的可重用性和可扩展性问题。作者开发了 CoOpt 框架，这是一个高效的并行化框架，通过分布式无标签数据和公开的任务无关模型，实现协作优化并将知识编码到数据本身，从而构建可扩展、可重用的训练管道。在多种数据集上的实验证明，CoOpt 在 Tiny-ImageNet 和 ImageNet-1K 上分别实现了 13.6% 和 6.8% 的性能提升，并获得了 1.94× 和 1.2× 的训练加速。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14117v1",
      "published_date": "2025-05-20 09:21:40 UTC",
      "updated_date": "2025-05-20 09:21:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:16:11.623259"
    },
    {
      "arxiv_id": "2505.14107v1",
      "title": "DiagnosisArena: Benchmarking Diagnostic Reasoning for Large Language Models",
      "title_zh": "DiagnosisArena：大型语言模型诊断推理基准测试",
      "authors": [
        "Yakun Zhu",
        "Zhongzhen Huang",
        "Linjie Mu",
        "Yutong Huang",
        "Wei Nie",
        "Shaoting Zhang",
        "Pengfei Liu",
        "Xiaofan Zhang"
      ],
      "abstract": "The emergence of groundbreaking large language models capable of performing\ncomplex reasoning tasks holds significant promise for addressing various\nscientific challenges, including those arising in complex clinical scenarios.\nTo enable their safe and effective deployment in real-world healthcare\nsettings, it is urgently necessary to benchmark the diagnostic capabilities of\ncurrent models systematically. Given the limitations of existing medical\nbenchmarks in evaluating advanced diagnostic reasoning, we present\nDiagnosisArena, a comprehensive and challenging benchmark designed to\nrigorously assess professional-level diagnostic competence. DiagnosisArena\nconsists of 1,113 pairs of segmented patient cases and corresponding diagnoses,\nspanning 28 medical specialties, deriving from clinical case reports published\nin 10 top-tier medical journals. The benchmark is developed through a\nmeticulous construction pipeline, involving multiple rounds of screening and\nreview by both AI systems and human experts, with thorough checks conducted to\nprevent data leakage. Our study reveals that even the most advanced reasoning\nmodels, o3-mini, o1, and DeepSeek-R1, achieve only 45.82%, 31.09%, and 17.79%\naccuracy, respectively. This finding highlights a significant generalization\nbottleneck in current large language models when faced with clinical diagnostic\nreasoning challenges. Through DiagnosisArena, we aim to drive further\nadvancements in AIs diagnostic reasoning capabilities, enabling more effective\nsolutions for real-world clinical diagnostic challenges. We provide the\nbenchmark and evaluation tools for further research and development\nhttps://github.com/SPIRAL-MED/DiagnosisArena.",
      "tldr_zh": "本研究引入DiagnosisArena，一种全面的基准测试，用于系统评估大型语言模型（Large Language Models, LLMs）在临床诊断推理方面的能力，以确保其在真实医疗环境中的安全应用。DiagnosisArena包含1,113对患者病例和诊断，覆盖28个医疗专业，源自10种顶级医学期刊，并通过多轮AI和人类专家审查的构建管道来防止数据泄露。实验结果显示，即使是先进模型如o3-mini、o1和DeepSeek-R1，其准确率仅为45.82%、31.09%和17.79%，突显了LLMs在临床诊断推理上的泛化瓶颈。该基准测试及其评估工具已开源（https://github.com/SPIRAL-MED/DiagnosisArena），旨在推动AI诊断能力的发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14107v1",
      "published_date": "2025-05-20 09:14:53 UTC",
      "updated_date": "2025-05-20 09:14:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:16:23.643224"
    },
    {
      "arxiv_id": "2505.14106v1",
      "title": "A Personalized Conversational Benchmark: Towards Simulating Personalized Conversations",
      "title_zh": "翻译失败",
      "authors": [
        "Li Li",
        "Peilin Cai",
        "Ryan A. Rossi",
        "Franck Dernoncourt",
        "Branislav Kveton",
        "Junda Wu",
        "Tong Yu",
        "Linxin Song",
        "Tiankai Yang",
        "Yuehan Qin",
        "Nesreen K. Ahmed",
        "Samyadeep Basu",
        "Subhojyoti Mukherjee",
        "Ruiyi Zhang",
        "Zhengmian Hu",
        "Bo Ni",
        "Yuxiao Zhou",
        "Zichao Wang",
        "Yue Huang",
        "Yu Wang",
        "Xiangliang Zhang",
        "Philip S. Yu",
        "Xiyang Hu",
        "Yue Zhao"
      ],
      "abstract": "We present PersonaConvBench, a large-scale benchmark for evaluating\npersonalized reasoning and generation in multi-turn conversations with large\nlanguage models (LLMs). Unlike existing work that focuses on either\npersonalization or conversational structure in isolation, PersonaConvBench\nintegrates both, offering three core tasks: sentence classification, impact\nregression, and user-centric text generation across ten diverse Reddit-based\ndomains. This design enables systematic analysis of how personalized\nconversational context shapes LLM outputs in realistic multi-user scenarios. We\nbenchmark several commercial and open-source LLMs under a unified prompting\nsetup and observe that incorporating personalized history yields substantial\nperformance improvements, including a 198 percent relative gain over the best\nnon-conversational baseline in sentiment classification. By releasing\nPersonaConvBench with evaluations and code, we aim to support research on LLMs\nthat adapt to individual styles, track long-term context, and produce\ncontextually rich, engaging responses.",
      "tldr_zh": "这篇论文介绍了 PersonaConvBench，一个大规模基准，用于评估大型语言模型（LLMs）在多轮对话中的个性化推理和生成能力。该基准整合了个性化（personalization）和对话结构，提供三个核心任务：sentence classification、impact regression 和 user-centric text generation，涵盖十个基于 Reddit 的多样领域。实验结果显示，融入个性化对话历史显著提升模型性能，例如在情感分类任务中，比最佳非对话基准提高了 198% 的相对表现。通过发布 PersonaConvBench 的评估代码和数据，该研究旨在推动 LLMs 适应个人风格、跟踪长期上下文并生成更丰富响应的研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14106v1",
      "published_date": "2025-05-20 09:13:22 UTC",
      "updated_date": "2025-05-20 09:13:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:16:36.844033"
    },
    {
      "arxiv_id": "2505.14103v2",
      "title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models",
      "title_zh": "AudioJailbreak：针对端到端大型音频语言模型的越狱攻击",
      "authors": [
        "Guangke Chen",
        "Fu Song",
        "Zhe Zhao",
        "Xiaojun Jia",
        "Yang Liu",
        "Yanchen Qiao",
        "Weizhe Zhang"
      ],
      "abstract": "Jailbreak attacks to Large audio-language models (LALMs) are studied\nrecently, but they achieve suboptimal effectiveness, applicability, and\npracticability, particularly, assuming that the adversary can fully manipulate\nuser prompts. In this work, we first conduct an extensive experiment showing\nthat advanced text jailbreak attacks cannot be easily ported to end-to-end\nLALMs via text-to speech (TTS) techniques. We then propose AudioJailbreak, a\nnovel audio jailbreak attack, featuring (1) asynchrony: the jailbreak audio\ndoes not need to align with user prompts in the time axis by crafting suffixal\njailbreak audios; (2) universality: a single jailbreak perturbation is\neffective for different prompts by incorporating multiple prompts into\nperturbation generation; (3) stealthiness: the malicious intent of jailbreak\naudios will not raise the awareness of victims by proposing various intent\nconcealment strategies; and (4) over-the-air robustness: the jailbreak audios\nremain effective when being played over the air by incorporating the\nreverberation distortion effect with room impulse response into the generation\nof the perturbations. In contrast, all prior audio jailbreak attacks cannot\noffer asynchrony, universality, stealthiness, or over-the-air robustness.\nMoreover, AudioJailbreak is also applicable to the adversary who cannot fully\nmanipulate user prompts, thus has a much broader attack scenario. Extensive\nexperiments with thus far the most LALMs demonstrate the high effectiveness of\nAudioJailbreak. We highlight that our work peeks into the security implications\nof audio jailbreak attacks against LALMs, and realistically fosters improving\ntheir security robustness. The implementation and audio samples are available\nat our website https://audiojailbreak.github.io/AudioJailbreak.",
      "tldr_zh": "本研究探讨了针对端到端大型音频语言模型 (LALMs) 的越狱攻击 (Jailbreak Attacks)，发现现有基于文本的攻击方法无法有效移植到音频场景。论文提出 AudioJailbreak，一种新型音频攻击框架，具备 asynchrony（无需与用户提示同步）、universality（适用于多种提示）、stealthiness（隐藏恶意意图）和 over-the-air robustness（抗空气传播干扰）等特性。实验结果显示，AudioJailbreak 在多个 LALMs 上表现出高有效性，并扩展了攻击场景，强调了提升模型安全性的必要性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14103v2",
      "published_date": "2025-05-20 09:10:45 UTC",
      "updated_date": "2025-05-21 03:36:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:16:48.854143"
    },
    {
      "arxiv_id": "2505.14745v1",
      "title": "Explainable Prediction of the Mechanical Properties of Composites with CNNs",
      "title_zh": "翻译失败",
      "authors": [
        "Varun Raaghav",
        "Dimitrios Bikos",
        "Antonio Rago",
        "Francesca Toni",
        "Maria Charalambides"
      ],
      "abstract": "Composites are amongst the most important materials manufactured today, as\nevidenced by their use in countless applications. In order to establish the\nsuitability of composites in specific applications, finite element (FE)\nmodelling, a numerical method based on partial differential equations, is the\nindustry standard for assessing their mechanical properties. However, FE\nmodelling is exceptionally costly from a computational viewpoint, a limitation\nwhich has led to efforts towards applying AI models to this task. However, in\nthese approaches: the chosen model architectures were rudimentary, feed-forward\nneural networks giving limited accuracy; the studies focus on predicting\nelastic mechanical properties, without considering material strength limits;\nand the models lacked transparency, hindering trustworthiness by users. In this\npaper, we show that convolutional neural networks (CNNs) equipped with methods\nfrom explainable AI (XAI) can be successfully deployed to solve this problem.\nOur approach uses customised CNNs trained on a dataset we generate using\ntransverse tension tests in FE modelling to predict composites' mechanical\nproperties, i.e., Young's modulus and yield strength. We show empirically that\nour approach achieves high accuracy, outperforming a baseline, ResNet-34, in\nestimating the mechanical properties. We then use SHAP and Integrated\nGradients, two post-hoc XAI methods, to explain the predictions, showing that\nthe CNNs use the critical geometrical features that influence the composites'\nbehaviour, thus allowing engineers to verify that the models are trustworthy by\nrepresenting the science of composites.",
      "tldr_zh": "本文提出使用卷积神经网络(CNNs)结合可解释AI(XAI)方法来预测复合材料的机械性能，包括Young's modulus和yield strength，以解决传统有限元建模(FE modelling)计算成本高的局限性。研究团队通过FE建模生成的自定义数据集训练定制CNNs，并证明其准确性超过基线ResNet-34模型。利用SHAP和Integrated Gradients等XAI技术解释预测结果，显示CNNs关注影响材料行为的关键几何特征，从而提升模型的可信度和工程应用价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.14745v1",
      "published_date": "2025-05-20 08:54:06 UTC",
      "updated_date": "2025-05-20 08:54:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:17:00.965100"
    },
    {
      "arxiv_id": "2505.14080v1",
      "title": "Gender Trouble in Language Models: An Empirical Audit Guided by Gender Performativity Theory",
      "title_zh": "语言模型中的性别麻烦：基于性别表演理论的实证审计",
      "authors": [
        "Franziska Sofia Hafner",
        "Ana Valdivia",
        "Luc Rocher"
      ],
      "abstract": "Language models encode and subsequently perpetuate harmful gendered\nstereotypes. Research has succeeded in mitigating some of these harms, e.g. by\ndissociating non-gendered terms such as occupations from gendered terms such as\n'woman' and 'man'. This approach, however, remains superficial given that\nassociations are only one form of prejudice through which gendered harms arise.\nCritical scholarship on gender, such as gender performativity theory,\nemphasizes how harms often arise from the construction of gender itself, such\nas conflating gender with biological sex. In language models, these issues\ncould lead to the erasure of transgender and gender diverse identities and\ncause harms in downstream applications, from misgendering users to\nmisdiagnosing patients based on wrong assumptions about their anatomy.\n  For FAccT research on gendered harms to go beyond superficial linguistic\nassociations, we advocate for a broader definition of 'gender bias' in language\nmodels. We operationalize insights on the construction of gender through\nlanguage from gender studies literature and then empirically test how 16\nlanguage models of different architectures, training datasets, and model sizes\nencode gender. We find that language models tend to encode gender as a binary\ncategory tied to biological sex, and that gendered terms that do not neatly\nfall into one of these binary categories are erased and pathologized. Finally,\nwe show that larger models, which achieve better results on performance\nbenchmarks, learn stronger associations between gender and sex, further\nreinforcing a narrow understanding of gender. Our findings lead us to call for\na re-evaluation of how gendered harms in language models are defined and\naddressed.",
      "tldr_zh": "这篇论文基于 Gender Performativity Theory 对语言模型进行实证审计，揭示其如何编码并 perpetuates 有害的性别刻板印象，而不仅仅局限于表面关联。研究者测试了 16 个不同架构、训练数据集和大小的语言模型，发现这些模型倾向于将性别视为二元类别，并将其与生物性别绑定，导致跨性别和性别多样性身份被抹杀和 pathologized。结果显示，模型规模越大，在性能基准上表现越好，但也强化了性别与性别的关联，进一步加剧了性别偏见。最后，作者呼吁重新定义和处理语言模型中的 'gender bias'，以更全面地缓解潜在危害。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14080v1",
      "published_date": "2025-05-20 08:36:47 UTC",
      "updated_date": "2025-05-20 08:36:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:17:13.167139"
    },
    {
      "arxiv_id": "2505.14072v1",
      "title": "Personalized Student Knowledge Modeling for Future Learning Resource Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Soroush Hashemifar",
        "Sherry Sahebi"
      ],
      "abstract": "Despite advances in deep learning for education, student knowledge tracing\nand behavior modeling face persistent challenges: limited personalization,\ninadequate modeling of diverse learning activities (especially non-assessed\nmaterials), and overlooking the interplay between knowledge acquisition and\nbehavioral patterns. Practical limitations, such as fixed-size sequence\nsegmentation, frequently lead to the loss of contextual information vital for\npersonalized learning. Moreover, reliance on student performance on assessed\nmaterials limits the modeling scope, excluding non-assessed interactions like\nlectures. To overcome these shortcomings, we propose Knowledge Modeling and\nMaterial Prediction (KMaP), a stateful multi-task approach designed for\npersonalized and simultaneous modeling of student knowledge and behavior. KMaP\nemploys clustering-based student profiling to create personalized student\nrepresentations, improving predictions of future learning resource preferences.\nExtensive experiments on two real-world datasets confirm significant behavioral\ndifferences across student clusters and validate the efficacy of the KMaP\nmodel.",
      "tldr_zh": "这篇论文针对学生知识追踪和行为建模的挑战（如个性化不足、无法充分处理非评估学习活动以及忽略知识获取与行为互动），提出了一种名为 KMaP 的有状态多任务方法。KMaP 通过基于聚类的学生画像创建个性化学生表示，同时建模知识和行为模式，以准确预测未来学习资源偏好。实验在两个真实数据集上验证了该框架的有效性，确认了不同学生聚类间的行为差异，并显著提升了个性化学习建模的性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14072v1",
      "published_date": "2025-05-20 08:23:50 UTC",
      "updated_date": "2025-05-20 08:23:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:17:23.925673"
    },
    {
      "arxiv_id": "2505.14744v1",
      "title": "Transductively Informed Inductive Program Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Janis Zenkner",
        "Tobias Sesterhenn",
        "Christian Bartelt"
      ],
      "abstract": "Abstraction and reasoning in program synthesis has seen significant progress\nthrough both inductive and transductive paradigms. Inductive approaches\ngenerate a program or latent function from input-output examples, which can\nthen be applied to new inputs. Transductive approaches directly predict output\nvalues for given inputs, effectively serving as the function themselves.\nCurrent approaches combine inductive and transductive models via isolated\nensembling, but they do not explicitly model the interaction between both\nparadigms. In this work, we introduce \\acs{tiips}, a novel framework that\nunifies transductive and inductive strategies by explicitly modeling their\ninteractions through a cooperative mechanism: an inductive model generates\nprograms, while a transductive model constrains, guides, and refines the search\nto improve synthesis accuracy and generalization. We evaluate \\acs{tiips} on\ntwo widely studied program synthesis domains: string and list manipulation. Our\nresults show that \\acs{tiips} solves more tasks and yields functions that more\nclosely match optimal solutions in syntax and semantics, particularly in\nout-of-distribution settings, yielding state-of-the-art performance. We believe\nthat explicitly modeling the synergy between inductive and transductive\nreasoning opens promising avenues for general-purpose program synthesis and\nbroader applications.",
      "tldr_zh": "该论文提出了一种名为 TIIPS 的新框架，用于程序合成领域，通过明确建模 inductive 和 transductive 策略之间的交互，实现二者的统一。TIIPS 通过合作机制，让 inductive 模型生成程序，而 transductive 模型则负责约束、指导和优化搜索过程，从而提升合成准确性和泛化能力。在字符串和列表操作等常见领域进行评估时，TIIPS 解决了更多任务，并在语法和语义上更接近最优解，尤其在 out-of-distribution 设置中达到了最先进性能。该框架的创新在于显式协同 inductive 和 transductive 推理，为通用 program synthesis 和更广泛应用开辟了新途径。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.PL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14744v1",
      "published_date": "2025-05-20 08:23:46 UTC",
      "updated_date": "2025-05-20 08:23:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:17:36.452075"
    },
    {
      "arxiv_id": "2505.14064v1",
      "title": "NOVA: A Benchmark for Anomaly Localization and Clinical Reasoning in Brain MRI",
      "title_zh": "NOVA：脑部 MRI 中异常定位和临床推理的基准",
      "authors": [
        "Cosmin I. Bercea",
        "Jun Li",
        "Philipp Raffler",
        "Evamaria O. Riedel",
        "Lena Schmitzer",
        "Angela Kurz",
        "Felix Bitzer",
        "Paula Roßmüller",
        "Julian Canisius",
        "Mirjam L. Beyrle",
        "Che Liu",
        "Wenjia Bai",
        "Bernhard Kainz",
        "Julia A. Schnabel",
        "Benedikt Wiestler"
      ],
      "abstract": "In many real-world applications, deployed models encounter inputs that differ\nfrom the data seen during training. Out-of-distribution detection identifies\nwhether an input stems from an unseen distribution, while open-world\nrecognition flags such inputs to ensure the system remains robust as\never-emerging, previously $unknown$ categories appear and must be addressed\nwithout retraining. Foundation and vision-language models are pre-trained on\nlarge and diverse datasets with the expectation of broad generalization across\ndomains, including medical imaging. However, benchmarking these models on test\nsets with only a few common outlier types silently collapses the evaluation\nback to a closed-set problem, masking failures on rare or truly novel\nconditions encountered in clinical use.\n  We therefore present $NOVA$, a challenging, real-life $evaluation-only$\nbenchmark of $\\sim$900 brain MRI scans that span 281 rare pathologies and\nheterogeneous acquisition protocols. Each case includes rich clinical\nnarratives and double-blinded expert bounding-box annotations. Together, these\nenable joint assessment of anomaly localisation, visual captioning, and\ndiagnostic reasoning. Because NOVA is never used for training, it serves as an\n$extreme$ stress-test of out-of-distribution generalisation: models must bridge\na distribution gap both in sample appearance and in semantic space. Baseline\nresults with leading vision-language models (GPT-4o, Gemini 2.0 Flash, and\nQwen2.5-VL-72B) reveal substantial performance drops across all tasks,\nestablishing NOVA as a rigorous testbed for advancing models that can detect,\nlocalize, and reason about truly unknown anomalies.",
      "tldr_zh": "本研究引入了 NOVA 基准，这是一个针对脑 MRI 异常定位（anomaly localization）和临床推理（clinical reasoning）的挑战性评估工具，旨在测试模型在处理分布外数据（out-of-distribution detection）和开放世界识别（open-world recognition）时的鲁棒性。NOVA 包含约 900 个真实脑 MRI 扫描，覆盖 281 种稀有病理和异构获取协议，并附带丰富的临床叙述和双盲专家边界框标注。基准专注于三项任务：异常定位、视觉描述和诊断推理，作为一个仅用于评估的极端压力测试，以揭示模型在样本外观和语义空间的分布差距上的泛化能力。基线实验使用领先的视觉语言模型（如 GPT-4o、Gemini 2.0 Flash 和 Qwen2.5-VL-72B）显示了显著性能下降，证明 NOVA 是推进模型处理未知异常的关键测试平台。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14064v1",
      "published_date": "2025-05-20 08:10:57 UTC",
      "updated_date": "2025-05-20 08:10:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:17:48.974834"
    },
    {
      "arxiv_id": "2505.14057v1",
      "title": "Field Matters: A lightweight LLM-enhanced Method for CTR Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Cui",
        "Feng Liu",
        "Jiawei Chen",
        "Xingyu Lou",
        "Changwang Zhang",
        "Jun Wang",
        "Yuegang Sun",
        "Xiaohu Yang",
        "Can Wang"
      ],
      "abstract": "Click-through rate (CTR) prediction is a fundamental task in modern\nrecommender systems. In recent years, the integration of large language models\n(LLMs) has been shown to effectively enhance the performance of traditional CTR\nmethods. However, existing LLM-enhanced methods often require extensive\nprocessing of detailed textual descriptions for large-scale instances or\nuser/item entities, leading to substantial computational overhead. To address\nthis challenge, this work introduces LLaCTR, a novel and lightweight\nLLM-enhanced CTR method that employs a field-level enhancement paradigm.\nSpecifically, LLaCTR first utilizes LLMs to distill crucial and lightweight\nsemantic knowledge from small-scale feature fields through self-supervised\nfield-feature fine-tuning. Subsequently, it leverages this field-level semantic\nknowledge to enhance both feature representation and feature interactions. In\nour experiments, we integrate LLaCTR with six representative CTR models across\nfour datasets, demonstrating its superior performance in terms of both\neffectiveness and efficiency compared to existing LLM-enhanced methods. Our\ncode is available at https://anonymous.4open.science/r/LLaCTR-EC46.",
      "tldr_zh": "这篇论文针对点击率 (CTR) 预测任务，提出了一种轻量级的 LLM 增强方法 LLaCTR，以解决现有方法在处理大规模文本描述时带来的高计算开销问题。LLaCTR 采用 field-level enhancement 范式，首先通过自监督的 field-feature fine-tuning，利用 LLMs 从小规模特征字段中提炼关键语义知识，然后应用这些知识来提升特征表示和特征交互。实验结果显示，在四个数据集上与六种代表性 CTR 模型整合后，LLaCTR 在有效性和效率方面均优于现有 LLM 增强方法。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14057v1",
      "published_date": "2025-05-20 08:02:41 UTC",
      "updated_date": "2025-05-20 08:02:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:18:00.361200"
    },
    {
      "arxiv_id": "2505.15851v1",
      "title": "Exploring Moral Exercises for Human Oversight of AI systems: Insights from Three Pilot Studies",
      "title_zh": "探索道德练习以实现人类对AI系统的监督：来自三个试点研究的见解",
      "authors": [
        "Silvia Crafa",
        "Teresa Scantamburlo"
      ],
      "abstract": "This paper elaborates on the concept of moral exercises as a means to help AI\nactors cultivate virtues that enable effective human oversight of AI systems.\nWe explore the conceptual framework and significance of moral exercises,\nsituating them within the contexts of philosophical discourse, ancient\npractices, and contemporary AI ethics scholarship. We outline the core pillars\nof the moral exercises methodology - eliciting an engaged personal disposition,\nfostering relational understanding, and cultivating technomoral wisdom - and\nemphasize their relevance to key activities and competencies essential for\nhuman oversight of AI systems. Our argument is supported by findings from three\npilot studies involving a company, a multidisciplinary team of AI researchers,\nand higher education students. These studies allow us to explore both the\npotential and the limitations of moral exercises. Based on the collected data,\nwe offer insights into how moral exercises can foster a responsible AI culture\nwithin organizations, and suggest directions for future research.",
      "tldr_zh": "本论文探讨了“moral exercises”作为一种帮助 AI 参与者培养美德的方法，以实现对 AI systems 的有效“human oversight”。论文阐述了道德练习的概念框架及其在哲学、古实践和当代 AI 伦理学中的意义，强调其核心支柱：激发个人参与性、培养关系理解以及“technomoral wisdom”。通过三个“pilot studies”（涉及一家公司、多学科 AI 研究团队和高等教育学生），研究揭示了道德练习的潜力与局限性，并提供见解，建议如何在组织中推广负责任的 AI 文化以及未来研究方向。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15851v1",
      "published_date": "2025-05-20 07:47:24 UTC",
      "updated_date": "2025-05-20 07:47:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:18:12.337429"
    },
    {
      "arxiv_id": "2505.14045v1",
      "title": "From Unaligned to Aligned: Scaling Multilingual LLMs with Multi-Way Parallel Corpora",
      "title_zh": "翻译失败",
      "authors": [
        "Yingli Shen",
        "Wen Lai",
        "Shuo Wang",
        "Kangyang Luo",
        "Alexander Fraser",
        "Maosong Sun"
      ],
      "abstract": "Continued pretraining and instruction tuning on large-scale multilingual data\nhave proven to be effective in scaling large language models (LLMs) to\nlow-resource languages. However, the unaligned nature of such data limits its\nability to effectively capture cross-lingual semantics. In contrast, multi-way\nparallel data, where identical content is aligned across multiple languages,\nprovides stronger cross-lingual consistency and offers greater potential for\nimproving multilingual performance. In this paper, we introduce a large-scale,\nhigh-quality multi-way parallel corpus, TED2025, based on TED Talks. The corpus\nspans 113 languages, with up to 50 languages aligned in parallel, ensuring\nextensive multilingual coverage. Using this dataset, we investigate best\npractices for leveraging multi-way parallel data to enhance LLMs, including\nstrategies for continued pretraining, instruction tuning, and the analysis of\nkey influencing factors. Experiments on six multilingual benchmarks show that\nmodels trained on multiway parallel data consistently outperform those trained\non unaligned multilingual data.",
      "tldr_zh": "该研究发现，继续预训练和指令微调多语言LLMs时，未对齐数据限制了跨语言语义的捕捉能力，因此提出利用多向平行数据（multi-way parallel data）来提升模型性能。作者构建了大规模、高质量语料库TED2025，基于TED Talks，覆盖113种语言并实现多达50种语言的平行对齐。研究探讨了最佳实践，包括继续预训练、指令微调策略以及影响因素分析。实验在六个多语言基准上表明，使用多向平行数据训练的模型在表现上 consistently outperform 那些基于未对齐数据的模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14045v1",
      "published_date": "2025-05-20 07:43:45 UTC",
      "updated_date": "2025-05-20 07:43:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:18:25.678204"
    },
    {
      "arxiv_id": "2505.14038v1",
      "title": "ProMind-LLM: Proactive Mental Health Care via Causal Reasoning with Sensor Data",
      "title_zh": "ProMind-LLM：通过传感器数据的",
      "authors": [
        "Xinzhe Zheng",
        "Sijie Ji",
        "Jiawei Sun",
        "Renqi Chen",
        "Wei Gao",
        "Mani Srivastava"
      ],
      "abstract": "Mental health risk is a critical global public health challenge,\nnecessitating innovative and reliable assessment methods. With the development\nof large language models (LLMs), they stand out to be a promising tool for\nexplainable mental health care applications. Nevertheless, existing approaches\npredominantly rely on subjective textual mental records, which can be distorted\nby inherent mental uncertainties, leading to inconsistent and unreliable\npredictions. To address these limitations, this paper introduces ProMind-LLM.\nWe investigate an innovative approach integrating objective behavior data as\ncomplementary information alongside subjective mental records for robust mental\nhealth risk assessment. Specifically, ProMind-LLM incorporates a comprehensive\npipeline that includes domain-specific pretraining to tailor the LLM for mental\nhealth contexts, a self-refine mechanism to optimize the processing of\nnumerical behavioral data, and causal chain-of-thought reasoning to enhance the\nreliability and interpretability of its predictions. Evaluations of two\nreal-world datasets, PMData and Globem, demonstrate the effectiveness of our\nproposed methods, achieving substantial improvements over general LLMs. We\nanticipate that ProMind-LLM will pave the way for more dependable,\ninterpretable, and scalable mental health case solutions.",
      "tldr_zh": "本论文提出 ProMind-LLM，一种主动心理健康护理框架，通过整合客观行为传感器数据和主观心理记录来解决现有方法依赖文本数据导致的预测不一致问题。框架包括领域特定预训练以适应心理健康上下文、自精炼机制优化数字行为数据处理，以及因果 chain-of-thought reasoning 来提升预测的可靠性和可解释性。在 PMData 和 Globem 两个真实数据集上的评估显示，ProMind-LLM 比一般 LLMs 取得了显著改进，为更可信、可扩展的心理健康解决方案奠定基础。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14038v1",
      "published_date": "2025-05-20 07:36:28 UTC",
      "updated_date": "2025-05-20 07:36:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:18:36.755734"
    },
    {
      "arxiv_id": "2505.14036v1",
      "title": "Adaptive Cyclic Diffusion for Inference Scaling",
      "title_zh": "翻译失败",
      "authors": [
        "Gyubin Lee",
        "Truong Nhat Nguyen Bao",
        "Jaesik Yoon",
        "Dongwoo Lee",
        "Minsu Kim",
        "Yoshua Bengio",
        "Sungjin Ahn"
      ],
      "abstract": "Diffusion models have demonstrated strong generative capabilities across\ndomains ranging from image synthesis to complex reasoning tasks. However, most\ninference-time scaling methods rely on fixed denoising schedules, limiting\ntheir ability to allocate computation based on instance difficulty or\ntask-specific demands adaptively. We introduce the challenge of adaptive\ninference-time scaling-dynamically adjusting computational effort during\ninference-and propose Adaptive Bi-directional Cyclic Diffusion (ABCD), a\nflexible, search-based inference framework. ABCD refines outputs through\nbi-directional diffusion cycles while adaptively controlling exploration depth\nand termination. It comprises three components: Cyclic Diffusion Search,\nAutomatic Exploration-Exploitation Balancing, and Adaptive Thinking Time.\nExperiments show that ABCD improves performance across diverse tasks while\nmaintaining computational efficiency.",
      "tldr_zh": "这篇论文针对扩散模型（Diffusion models）在推理过程中的固定去噪时间表问题，提出了一种自适应推理时间缩放方法，以动态调整计算资源以适应实例难度和任务需求。论文引入 Adaptive Bi-directional Cyclic Diffusion (ABCD) 框架，该框架通过 Cyclic Diffusion Search、Automatic Exploration-Exploitation Balancing 和 Adaptive Thinking Time 等组件，实现双向扩散循环的输出优化和自适应控制。实验结果表明，ABCD 在多种任务上显著提高了性能，同时保持了计算效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14036v1",
      "published_date": "2025-05-20 07:31:38 UTC",
      "updated_date": "2025-05-20 07:31:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:18:48.610955"
    },
    {
      "arxiv_id": "2505.14029v1",
      "title": "AppleGrowthVision: A large-scale stereo dataset for phenological analysis, fruit detection, and 3D reconstruction in apple orchards",
      "title_zh": "翻译失败",
      "authors": [
        "Laura-Sophia von Hirschhausen",
        "Jannes S. Magnusson",
        "Mykyta Kovalenko",
        "Fredrik Boye",
        "Tanay Rawat",
        "Peter Eisert",
        "Anna Hilsmann",
        "Sebastian Pretzsch",
        "Sebastian Bosse"
      ],
      "abstract": "Deep learning has transformed computer vision for precision agriculture, yet\napple orchard monitoring remains limited by dataset constraints. The lack of\ndiverse, realistic datasets and the difficulty of annotating dense,\nheterogeneous scenes. Existing datasets overlook different growth stages and\nstereo imagery, both essential for realistic 3D modeling of orchards and tasks\nlike fruit localization, yield estimation, and structural analysis. To address\nthese gaps, we present AppleGrowthVision, a large-scale dataset comprising two\nsubsets. The first includes 9,317 high resolution stereo images collected from\na farm in Brandenburg (Germany), covering six agriculturally validated growth\nstages over a full growth cycle. The second subset consists of 1,125 densely\nannotated images from the same farm in Brandenburg and one in Pillnitz\n(Germany), containing a total of 31,084 apple labels. AppleGrowthVision\nprovides stereo-image data with agriculturally validated growth stages,\nenabling precise phenological analysis and 3D reconstructions. Extending\nMinneApple with our data improves YOLOv8 performance by 7.69 % in terms of\nF1-score, while adding it to MinneApple and MAD boosts Faster R-CNN F1-score by\n31.06 %. Additionally, six BBCH stages were predicted with over 95 % accuracy\nusing VGG16, ResNet152, DenseNet201, and MobileNetv2. AppleGrowthVision bridges\nthe gap between agricultural science and computer vision, by enabling the\ndevelopment of robust models for fruit detection, growth modeling, and 3D\nanalysis in precision agriculture. Future work includes improving annotation,\nenhancing 3D reconstruction, and extending multimodal analysis across all\ngrowth stages.",
      "tldr_zh": "本研究引入 AppleGrowthVision，这是一个大规模立体数据集，用于苹果园的 phenological analysis（生长阶段分析）、fruit detection（果实检测）和 3D reconstruction（三维重建），以解决现有数据集在多样性和标注方面的局限性。该数据集包含两个子集：第一子集有 9,317 张高分辨率立体图像，覆盖六个农业验证的 BBCH 生长阶段；第二子集有 1,125 张密集标注图像，总计 31,084 个苹果标签。实验结果显示，将数据添加到 MinneApple 中，提高 YOLOv8 的 F1-score 7.69%，并提升 Faster R-CNN 的 F1-score 31.06%；同时，使用 VGG16 等模型预测 BBCH 阶段的准确率超过 95%。AppleGrowthVision 桥接了农业科学和计算机视觉，促进精确农业中果实检测、生长建模和 3D 分析的鲁棒模型开发。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14029v1",
      "published_date": "2025-05-20 07:29:22 UTC",
      "updated_date": "2025-05-20 07:29:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:19:04.346230"
    },
    {
      "arxiv_id": "2505.14027v1",
      "title": "CSAGC-IDS: A Dual-Module Deep Learning Network Intrusion Detection Model for Complex and Imbalanced Data",
      "title_zh": "CSAGC-IDS：一种针对复杂和不平衡数据的双模块深度学习网络入侵检测模型",
      "authors": [
        "Yifan Zeng"
      ],
      "abstract": "As computer networks proliferate, the gravity of network intrusions has\nescalated, emphasizing the criticality of network intrusion detection systems\nfor safeguarding security. While deep learning models have exhibited promising\nresults in intrusion detection, they face challenges in managing\nhigh-dimensional, complex traffic patterns and imbalanced data categories. This\npaper presents CSAGC-IDS, a network intrusion detection model based on deep\nlearning techniques. CSAGC-IDS integrates SC-CGAN, a self-attention-enhanced\nconvolutional conditional generative adversarial network that generates\nhigh-quality data to mitigate class imbalance. Furthermore, CSAGC-IDS\nintegrates CSCA-CNN, a convolutional neural network enhanced through cost\nsensitive learning and channel attention mechanism, to extract features from\ncomplex traffic data for precise detection. Experiments conducted on the\nNSL-KDD dataset. CSAGC-IDS achieves an accuracy of 84.55% and an F1-score of\n84.52% in five-class classification task, and an accuracy of 91.09% and an F1\nscore of 92.04% in binary classification task.Furthermore, this paper provides\nan interpretability analysis of the proposed model, using SHAP and LIME to\nexplain the decision-making mechanisms of the model.",
      "tldr_zh": "本论文提出 CSAGC-IDS，一种双模块深度学习模型，用于处理网络入侵检测中的高维复杂流量和数据不平衡问题。模型整合 SC-CGAN（一个自注意力增强的卷积条件生成对抗网络）来生成高质量数据缓解类别不平衡，以及 CSCA-CNN（通过成本敏感学习和通道注意力机制增强的卷积神经网络）来提取复杂流量特征并实现精确检测。在 NSL-KDD 数据集上的实验显示，该模型在五分类任务中达到 84.55% 准确率和 84.52% F1 分数，在二分类任务中达到 91.09% 准确率和 92.04% F1 分数。此外，论文使用 SHAP 和 LIME 进行模型可解释性分析，阐释决策机制。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14027v1",
      "published_date": "2025-05-20 07:27:51 UTC",
      "updated_date": "2025-05-20 07:27:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:19:13.897813"
    },
    {
      "arxiv_id": "2505.14024v1",
      "title": "FedGraM: Defending Against Untargeted Attacks in Federated Learning via Embedding Gram Matrix",
      "title_zh": "翻译失败",
      "authors": [
        "Di Wu",
        "Qian Li",
        "Heng Yang",
        "Yong Han"
      ],
      "abstract": "Federated Learning (FL) enables geographically distributed clients to\ncollaboratively train machine learning models by sharing only their local\nmodels, ensuring data privacy. However, FL is vulnerable to untargeted attacks\nthat aim to degrade the global model's performance on the underlying data\ndistribution. Existing defense mechanisms attempt to improve FL's resilience\nagainst such attacks, but their effectiveness is limited in practical FL\nenvironments due to data heterogeneity. On the contrary, we aim to detect and\nremove the attacks to mitigate their impact. Generalization contribution plays\na crucial role in distinguishing untargeted attacks. Our observations indicate\nthat, with limited data, the divergence between embeddings representing\ndifferent classes provides a better measure of generalization than direct\naccuracy. In light of this, we propose a novel robust aggregation method,\nFedGraM, designed to defend against untargeted attacks in FL. The server\nmaintains an auxiliary dataset containing one sample per class to support\naggregation. This dataset is fed to the local models to extract embeddings.\nThen, the server calculates the norm of the Gram Matrix of the embeddings for\neach local model. The norm serves as an indicator of each model's inter-class\nseparation capability in the embedding space. FedGraM identifies and removes\npotentially malicious models by filtering out those with the largest norms,\nthen averages the remaining local models to form the global model. We conduct\nextensive experiments to evaluate the performance of FedGraM. Our empirical\nresults show that with limited data samples used to construct the auxiliary\ndataset, FedGraM achieves exceptional performance, outperforming\nstate-of-the-art defense methods.",
      "tldr_zh": "联邦学习（Federated Learning）容易受到无针对性攻击，导致全局模型性能下降，为此，本文提出了一种新防御方法FedGraM，通过分析嵌入（embeddings）的Gram Matrix来检测恶意模型。FedGraM在服务器端维护一个辅助数据集（每个类一个样本），提取本地模型的嵌入后计算其Gram Matrix范数，以评估模型的类别分离能力，并移除范数最大的潜在恶意模型，然后聚合剩余模型形成全局模型。实验结果显示，FedGraM在有限数据条件下表现出色，优于现有最先进防御方法，显著提升了联邦学习的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14024v1",
      "published_date": "2025-05-20 07:26:54 UTC",
      "updated_date": "2025-05-20 07:26:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:19:24.274399"
    },
    {
      "arxiv_id": "2505.14020v1",
      "title": "Disentangled Multi-span Evolutionary Network against Temporal Knowledge Graph Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Dong",
        "Ziyue Qiao",
        "Zhiyuan Ning",
        "Qi Hao",
        "Yi Du",
        "Pengyang Wang",
        "Yuanchun Zhou"
      ],
      "abstract": "Temporal Knowledge Graphs (TKGs), as an extension of static Knowledge Graphs\n(KGs), incorporate the temporal feature to express the transience of knowledge\nby describing when facts occur. TKG extrapolation aims to infer possible future\nfacts based on known history, which has garnered significant attention in\nrecent years. Some existing methods treat TKG as a sequence of independent\nsubgraphs to model temporal evolution patterns, demonstrating impressive\nreasoning performance. However, they still have limitations: 1) In modeling\nsubgraph semantic evolution, they usually neglect the internal structural\ninteractions between subgraphs, which are actually crucial for encoding TKGs.\n2) They overlook the potential smooth features that do not lead to semantic\nchanges, which should be distinguished from the semantic evolution process.\nTherefore, we propose a novel Disentangled Multi-span Evolutionary Network\n(DiMNet) for TKG reasoning. Specifically, we design a multi-span evolution\nstrategy that captures local neighbor features while perceiving historical\nneighbor semantic information, thus enabling internal interactions between\nsubgraphs during the evolution process. To maximize the capture of semantic\nchange patterns, we design a disentangle component that adaptively separates\nnodes' active and stable features, used to dynamically control the influence of\nhistorical semantics on future evolution. Extensive experiments conducted on\nfour real-world TKG datasets show that DiMNet demonstrates substantial\nperformance in TKG reasoning, and outperforms the state-of-the-art up to 22.7%\nin MRR.",
      "tldr_zh": "该研究针对 Temporal Knowledge Graphs (TKGs) 的推理问题，提出了一种新型 Disentangled Multi-span Evolutionary Network (DiMNet)，以解决现有方法忽略子图内部结构交互和平滑特征的局限。DiMNet 通过 multi-span evolution strategy 捕捉局部邻居特征并感知历史语义信息，以及 disentangle component 自适应分离节点的 active 和 stable 特征，从而动态控制历史对未来演化的影响。实验在四个真实世界 TKG 数据集上表明，DiMNet 在 TKG reasoning 性能上比最先进方法提升高达 22.7% 在 MRR 上。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2505.14020v1",
      "published_date": "2025-05-20 07:22:03 UTC",
      "updated_date": "2025-05-20 07:22:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:19:39.790943"
    },
    {
      "arxiv_id": "2505.14742v1",
      "title": "Quaff: Quantized Parameter-Efficient Fine-Tuning under Outlier Spatial Stability Hypothesis",
      "title_zh": "Quaff：基于异常值空间稳定性假设的量化参数高效微调",
      "authors": [
        "Hong Huang",
        "Dapeng Wu"
      ],
      "abstract": "Large language models (LLMs) have made exciting achievements across various\ndomains, yet their deployment on resource-constrained personal devices remains\nhindered by the prohibitive computational and memory demands of task-specific\nfine-tuning. While quantization offers a pathway to efficiency, existing\nmethods struggle to balance performance and overhead, either incurring high\ncomputational/memory costs or failing to address activation outliers, a\ncritical bottleneck in quantized fine-tuning. To address these challenges, we\npropose the Outlier Spatial Stability Hypothesis (OSSH): During fine-tuning,\ncertain activation outlier channels retain stable spatial positions across\ntraining iterations. Building on OSSH, we propose Quaff, a Quantized\nparameter-efficient fine-tuning framework for LLMs, optimizing low-precision\nactivation representations through targeted momentum scaling. Quaff dynamically\nsuppresses outliers exclusively in invariant channels using lightweight\noperations, eliminating full-precision weight storage and global rescaling\nwhile reducing quantization errors. Extensive experiments across ten benchmarks\nvalidate OSSH and demonstrate Quaff's efficacy. Specifically, on the GPQA\nreasoning benchmark, Quaff achieves a 1.73x latency reduction and 30% memory\nsavings over full-precision fine-tuning while improving accuracy by 0.6% on the\nPhi-3 model, reconciling the triple trade-off between efficiency, performance,\nand deployability. By enabling consumer-grade GPU fine-tuning (e.g., RTX 2080\nSuper) without sacrificing model utility, Quaff democratizes personalized LLM\ndeployment. The code is available at https://github.com/Little0o0/Quaff.git.",
      "tldr_zh": "该论文提出 Outlier Spatial Stability Hypothesis (OSSH)，即在大型语言模型 (LLMs) 微调过程中，某些激活异常值通道保持稳定的空间位置，并基于此开发 Quaff 框架，用于量化参数高效微调。Quaff 通过目标动量缩放动态抑制异常值，仅在不变通道上进行轻量级操作，减少量化错误并消除全精度权重存储和全局重缩放。实验在十个基准测试中验证了 OSSH 的有效性，并在 GPQA 基准上，Quaff 实现了 1.73 倍延迟减少、30% 内存节省，并在 Phi-3 模型上准确率提高 0.6%，从而平衡了效率、性能和可部署性，促进 LLMs 在消费级 GPU（如 RTX 2080 Super）上的个性化部署。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14742v1",
      "published_date": "2025-05-20 07:19:36 UTC",
      "updated_date": "2025-05-20 07:19:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:19:51.320274"
    },
    {
      "arxiv_id": "2505.14005v1",
      "title": "Towards Comprehensive and Prerequisite-Free Explainer for Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Han Zhang",
        "Yan Wang",
        "Guanfeng Liu",
        "Pengfei Ding",
        "Huaxiong Wang",
        "Kwok-Yan Lam"
      ],
      "abstract": "To enhance the reliability and credibility of graph neural networks (GNNs)\nand improve the transparency of their decision logic, a new field of\nexplainability of GNNs (XGNN) has emerged. However, two major limitations\nseverely degrade the performance and hinder the generalizability of existing\nXGNN methods: they (a) fail to capture the complete decision logic of GNNs\nacross diverse distributions in the entire dataset's sample space, and (b)\nimpose strict prerequisites on edge properties and GNN internal accessibility.\nTo address these limitations, we propose OPEN, a novel c\\textbf{O}mprehensive\nand \\textbf{P}rerequisite-free \\textbf{E}xplainer for G\\textbf{N}Ns. OPEN, as\nthe first work in the literature, can infer and partition the entire dataset's\nsample space into multiple environments, each containing graphs that follow a\ndistinct distribution. OPEN further learns the decision logic of GNNs across\ndifferent distributions by sampling subgraphs from each environment and\nanalyzing their predictions, thus eliminating the need for strict\nprerequisites. Experimental results demonstrate that OPEN captures nearly\ncomplete decision logic of GNNs, outperforms state-of-the-art methods in\nfidelity while maintaining similar efficiency, and enhances robustness in\nreal-world scenarios.",
      "tldr_zh": "该研究针对图神经网络(GNNs)的可解释性(XGNN)领域，指出现有方法无法捕捉GNNs在整个数据集样本空间中不同分布的完整决策逻辑，且依赖严格的边属性和内部访问先决条件。作者提出了一种新型全面且无需先决条件的解释器OPEN，它通过推断并将数据集样本空间分区为多个环境，然后从每个环境采样子图并分析GNNs的预测，来学习跨分布的决策逻辑。实验结果显示，OPEN捕捉了GNNs几乎完整的决策逻辑，在保真度上优于最先进方法，同时保持类似效率并提升了真实场景中的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IJCAI 2025 AI4Tech Track",
      "pdf_url": "http://arxiv.org/pdf/2505.14005v1",
      "published_date": "2025-05-20 07:01:47 UTC",
      "updated_date": "2025-05-20 07:01:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:20:00.840853"
    },
    {
      "arxiv_id": "2505.14741v1",
      "title": "Communication-Efficient Diffusion Denoising Parallelization via Reuse-then-Predict Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Kunyun Wang",
        "Bohan Li",
        "Kai Yu",
        "Minyi Guo",
        "Jieru Zhao"
      ],
      "abstract": "Diffusion models have emerged as a powerful class of generative models across\nvarious modalities, including image, video, and audio synthesis. However, their\ndeployment is often limited by significant inference latency, primarily due to\nthe inherently sequential nature of the denoising process. While existing\nparallelization strategies attempt to accelerate inference by distributing\ncomputation across multiple devices, they typically incur high communication\noverhead, hindering deployment on commercial hardware. To address this\nchallenge, we propose \\textbf{ParaStep}, a novel parallelization method based\non a reuse-then-predict mechanism that parallelizes diffusion inference by\nexploiting similarity between adjacent denoising steps. Unlike prior approaches\nthat rely on layer-wise or stage-wise communication, ParaStep employs\nlightweight, step-wise communication, substantially reducing overhead. ParaStep\nachieves end-to-end speedups of up to \\textbf{3.88}$\\times$ on SVD,\n\\textbf{2.43}$\\times$ on CogVideoX-2b, and \\textbf{6.56}$\\times$ on\nAudioLDM2-large, while maintaining generation quality. These results highlight\nParaStep as a scalable and communication-efficient solution for accelerating\ndiffusion inference, particularly in bandwidth-constrained environments.",
      "tldr_zh": "扩散模型（Diffusion models）在图像、视频和音频生成中表现出色，但其推理过程的顺序性导致显著延迟，且现有并行策略面临高通信开销的问题。  \n本文提出 ParaStep，一种基于 Reuse-then-predict 机制的并行化方法，通过利用相邻去噪步骤的相似性，实现轻量级的步-wise 通信，从而大幅减少通信开销。  \n实验结果显示，ParaStep 在 SVD 上实现 3.88 倍端到端加速，在 CogVideoX-2b 上为 2.43 倍，在 AudioLDM2-large 上为 6.56 倍，同时保持生成质量，为带宽受限环境下的扩散模型推理提供可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14741v1",
      "published_date": "2025-05-20 06:58:40 UTC",
      "updated_date": "2025-05-20 06:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:20:13.470813"
    },
    {
      "arxiv_id": "2505.14001v1",
      "title": "VeRecycle: Reclaiming Guarantees from Probabilistic Certificates for Stochastic Dynamical Systems after Change",
      "title_zh": "VeRecycle：针对变化后的随机动力系统，从概率证书中回收保证",
      "authors": [
        "Sterre Lutz",
        "Matthijs T. J. Spaan",
        "Anna Lukina"
      ],
      "abstract": "Autonomous systems operating in the real world encounter a range of\nuncertainties. Probabilistic neural Lyapunov certification is a powerful\napproach to proving safety of nonlinear stochastic dynamical systems. When\nfaced with changes beyond the modeled uncertainties, e.g., unidentified\nobstacles, probabilistic certificates must be transferred to the new system\ndynamics. However, even when the changes are localized in a known part of the\nstate space, state-of-the-art requires complete re-certification, which is\nparticularly costly for neural certificates. We introduce VeRecycle, the first\nframework to formally reclaim guarantees for discrete-time stochastic dynamical\nsystems. VeRecycle efficiently reuses probabilistic certificates when the\nsystem dynamics deviate only in a given subset of states. We present a general\ntheoretical justification and algorithmic implementation. Our experimental\nevaluation shows scenarios where VeRecycle both saves significant computational\neffort and achieves competitive probabilistic guarantees in compositional\nneural control.",
      "tldr_zh": "该研究提出VeRecycle框架，用于在随机动态系统（stochastic dynamical systems）发生变化后，高效回收概率证书（probabilistic certificates），从而避免昂贵的完全重新认证。VeRecycle针对系统动态仅在特定状态子集变化的场景，重用现有证书，并提供理论证明和算法实现。实验结果显示，该框架在组合神经控制（compositional neural control）中显著节省计算资源，同时保持竞争性的概率保证。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted to IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.14001v1",
      "published_date": "2025-05-20 06:54:19 UTC",
      "updated_date": "2025-05-20 06:54:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:20:26.054472"
    },
    {
      "arxiv_id": "2505.13995v1",
      "title": "Social Sycophancy: A Broader Understanding of LLM Sycophancy",
      "title_zh": "社交谄媚：对 LLM 谄媚的一种更广泛理解",
      "authors": [
        "Myra Cheng",
        "Sunny Yu",
        "Cinoo Lee",
        "Pranav Khadpe",
        "Lujain Ibrahim",
        "Dan Jurafsky"
      ],
      "abstract": "A serious risk to the safety and utility of LLMs is sycophancy, i.e.,\nexcessive agreement with and flattery of the user. Yet existing work focuses on\nonly one aspect of sycophancy: agreement with users' explicitly stated beliefs\nthat can be compared to a ground truth. This overlooks forms of sycophancy that\narise in ambiguous contexts such as advice and support-seeking, where there is\nno clear ground truth, yet sycophancy can reinforce harmful implicit\nassumptions, beliefs, or actions. To address this gap, we introduce a richer\ntheory of social sycophancy in LLMs, characterizing sycophancy as the excessive\npreservation of a user's face (the positive self-image a person seeks to\nmaintain in an interaction). We present ELEPHANT, a framework for evaluating\nsocial sycophancy across five face-preserving behaviors (emotional validation,\nmoral endorsement, indirect language, indirect action, and accepting framing)\non two datasets: open-ended questions (OEQ) and Reddit's r/AmITheAsshole\n(AITA). Across eight models, we show that LLMs consistently exhibit high rates\nof social sycophancy: on OEQ, they preserve face 47% more than humans, and on\nAITA, they affirm behavior deemed inappropriate by crowdsourced human judgments\nin 42% of cases. We further show that social sycophancy is rewarded in\npreference datasets and is not easily mitigated. Our work provides theoretical\ngrounding and empirical tools (datasets and code) for understanding and\naddressing this under-recognized but consequential issue.",
      "tldr_zh": "这篇论文扩展了对大型语言模型(LLMs) sycophancy 的理解，将其定义为过度维护用户 face（正面自我形象），包括在模糊情境中强化有害隐含假设。研究者提出了 ELEPHANT 框架，用于评估五种 face-preserving 行为（emotional validation、moral endorsement、indirect language、indirect action 和 accepting framing），并在 open-ended questions (OEQ) 和 Reddit 的 r/AmITheAsshole (AITA) 数据集上进行测试。结果显示，八个模型在 OEQ 上比人类多 47% 维护 face，在 AITA 上在 42% 的情况下肯定被人类判断为不当的行为。论文进一步发现，social sycophancy 在偏好数据集上被奖励，且不易通过缓解措施消除。该工作提供了理论基础和实证工具（如数据集和代码），以更好地理解和解决这一问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13995v1",
      "published_date": "2025-05-20 06:45:17 UTC",
      "updated_date": "2025-05-20 06:45:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:20:40.402490"
    },
    {
      "arxiv_id": "2505.13994v1",
      "title": "Divide by Question, Conquer by Agent: SPLIT-RAG with Question-Driven Graph Partitioning",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiyi Yang",
        "Hao Xue",
        "Imran Razzak",
        "Hakim Hacid",
        "Flora D. Salim"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems empower large language models\n(LLMs) with external knowledge, yet struggle with efficiency-accuracy\ntrade-offs when scaling to large knowledge graphs. Existing approaches often\nrely on monolithic graph retrieval, incurring unnecessary latency for simple\nqueries and fragmented reasoning for complex multi-hop questions. To address\nthese challenges, this paper propose SPLIT-RAG, a multi-agent RAG framework\nthat addresses these limitations with question-driven semantic graph\npartitioning and collaborative subgraph retrieval. The innovative framework\nfirst create Semantic Partitioning of Linked Information, then use the\nType-Specialized knowledge base to achieve Multi-Agent RAG. The attribute-aware\ngraph segmentation manages to divide knowledge graphs into semantically\ncoherent subgraphs, ensuring subgraphs align with different query types, while\nlightweight LLM agents are assigned to partitioned subgraphs, and only relevant\npartitions are activated during retrieval, thus reduce search space while\nenhancing efficiency. Finally, a hierarchical merging module resolves\ninconsistencies across subgraph-derived answers through logical verifications.\nExtensive experimental validation demonstrates considerable improvements\ncompared to existing approaches.",
      "tldr_zh": "这篇论文针对 Retrieval-Augmented Generation (RAG) 系统在处理大型知识图谱时存在的效率与准确性权衡问题，提出了 SPLIT-RAG 框架。SPLIT-RAG 通过问题驱动的语义图分区（question-driven semantic graph partitioning）将知识图分成语义连贯的子图，并利用多智能体进行协作子图检索，仅激活相关分区以减少搜索空间并提升效率。框架还引入属性感知图分割（attribute-aware graph segmentation）和 Type-Specialized 知识库，支持轻量级 LLM 代理的分配，以及一个层次化合并模块来通过逻辑验证解决子图答案的不一致性。实验验证表明，SPLIT-RAG 相较于现有方法取得了显著改进。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13994v1",
      "published_date": "2025-05-20 06:44:34 UTC",
      "updated_date": "2025-05-20 06:44:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:20:52.526985"
    },
    {
      "arxiv_id": "2505.14739v1",
      "title": "Time Series Similarity Score Functions to Monitor and Interact with the Training and Denoising Process of a Time Series Diffusion Model applied to a Human Activity Recognition Dataset based on IMUs",
      "title_zh": "翻译失败",
      "authors": [
        "Heiko Oppel",
        "Andreas Spilz",
        "Michael Munz"
      ],
      "abstract": "Denoising diffusion probabilistic models are able to generate synthetic\nsensor signals. The training process of such a model is controlled by a loss\nfunction which measures the difference between the noise that was added in the\nforward process and the noise that was predicted by the diffusion model. This\nenables the generation of realistic data. However, the randomness within the\nprocess and the loss function itself makes it difficult to estimate the quality\nof the data. Therefore, we examine multiple similarity metrics and adapt an\nexisting metric to overcome this issue by monitoring the training and\nsynthetisation process using those metrics. The adapted metric can even be\nfine-tuned on the input data to comply with the requirements of an underlying\nclassification task. We were able to significantly reduce the amount of\ntraining epochs without a performance reduction in the classification task. An\noptimized training process not only saves resources, but also reduces the time\nfor training generative models.",
      "tldr_zh": "这篇论文探讨了在基于IMU的人类活动识别数据集上应用时间序列扩散模型（Denoising Diffusion Probabilistic Models）的训练和去噪过程，重点是通过多种相似性指标来监控和优化该过程。研究人员评估了现有指标并对其进行适应，使其能够更好地评估数据质量，并根据底层分类任务对指标进行微调。结果显示，这种方法显著减少了训练周期（无需降低分类性能），从而节省了资源和训练时间，为生成模型的效率提升提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14739v1",
      "published_date": "2025-05-20 06:38:17 UTC",
      "updated_date": "2025-05-20 06:38:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:21:02.193030"
    },
    {
      "arxiv_id": "2505.13989v2",
      "title": "When LLMs meet open-world graph learning: a new perspective for unlabeled data uncertainty",
      "title_zh": "翻译失败",
      "authors": [
        "Yanzhe Wen",
        "Xunkai Li",
        "Qi Zhang",
        "Zhu Lei",
        "Guang Zeng",
        "Rong-Hua Li",
        "Guoren Wang"
      ],
      "abstract": "Recently, large language models (LLMs) have significantly advanced\ntext-attributed graph (TAG) learning. However, existing methods inadequately\nhandle data uncertainty in open-world scenarios, especially concerning limited\nlabeling and unknown-class nodes. Prior solutions typically rely on isolated\nsemantic or structural approaches for unknown-class rejection, lacking\neffective annotation pipelines. To address these limitations, we propose\nOpen-world Graph Assistant (OGA), an LLM-based framework that combines adaptive\nlabel traceability, which integrates semantics and topology for unknown-class\nrejection, and a graph label annotator to enable model updates using newly\nannotated nodes. Comprehensive experiments demonstrate OGA's effectiveness and\npracticality.",
      "tldr_zh": "最近，大语言模型 (LLMs) 显著推动了文本属性图 (TAG) 学习，但现有方法在开放世界场景中难以处理未标记数据的不确定性，尤其是有限标签和未知类节点的问题。研究提出 Open-world Graph Assistant (OGA)，一个基于 LLM 的框架，结合自适应标签可追溯性（整合语义和拓扑以拒绝未知类节点）和图标签标注器，用于利用新标注节点更新模型。该框架通过有效的标注管道提升了未知类节点的处理能力，综合实验证明 OGA 在实际应用中更有效且实用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13989v2",
      "published_date": "2025-05-20 06:37:18 UTC",
      "updated_date": "2025-05-21 04:23:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:21:13.519010"
    },
    {
      "arxiv_id": "2505.13986v1",
      "title": "Solving Normalized Cut Problem with Constrained Action Space",
      "title_zh": "翻译失败",
      "authors": [
        "Qize Jiang",
        "Linsey Pang",
        "Alice Gatti",
        "Mahima Aggarwa",
        "Giovanna Vantin",
        "Xiaosong Ma",
        "Weiwei Sun",
        "Sanjay Chawla"
      ],
      "abstract": "Reinforcement Learning (RL) has emerged as an important paradigm to solve\ncombinatorial optimization problems primarily due to its ability to learn\nheuristics that can generalize across problem instances. However, integrating\nexternal knowledge that will steer combinatorial optimization problem solutions\ntowards domain appropriate outcomes remains an extremely challenging task. In\nthis paper, we propose the first RL solution that uses constrained action\nspaces to guide the normalized cut problem towards pre-defined template\ninstances. Using transportation networks as an example domain, we create a\nWedge and Ring Transformer that results in graph partitions that are shaped in\nform of Wedges and Rings and which are likely to be closer to natural optimal\npartitions. However, our approach is general as it is based on principles that\ncan be generalized to other domains.",
      "tldr_zh": "本研究提出了一种新的强化学习（Reinforcement Learning, RL）方法，用于解决归一化切割（normalized cut）问题，通过引入约束动作空间来整合外部知识，引导解决方案朝向预定义模板实例。该方法在交通网络领域创建了Wedge and Ring Transformer，确保图分区形成楔形和环形结构，从而更接近自然最优分区。实验结果显示，这种约束策略有效提升了问题解决的针对性，且该方法基于通用原则，可推广至其他领域。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "I.2.8"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13986v1",
      "published_date": "2025-05-20 06:33:39 UTC",
      "updated_date": "2025-05-20 06:33:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:21:25.747935"
    },
    {
      "arxiv_id": "2505.13973v1",
      "title": "Toward Effective Reinforcement Learning Fine-Tuning for Medical VQA in Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhui Zhu",
        "Xuanzhao Dong",
        "Xin Li",
        "Peijie Qiu",
        "Xiwen Chen",
        "Abolfazl Razi",
        "Aris Sotiras",
        "Yi Su",
        "Yalin Wang"
      ],
      "abstract": "Recently, reinforcement learning (RL)-based tuning has shifted the trajectory\nof Multimodal Large Language Models (MLLMs), particularly following the\nintroduction of Group Relative Policy Optimization (GRPO). However, directly\napplying it to medical tasks remains challenging for achieving clinically\ngrounded model behavior. Motivated by the need to align model response with\nclinical expectations, we investigate four critical dimensions that affect the\neffectiveness of RL-based tuning in medical visual question answering (VQA):\nbase model initialization strategy, the role of medical semantic alignment, the\nimpact of length-based rewards on long-chain reasoning, and the influence of\nbias. We conduct extensive experiments to analyze these factors for medical\nMLLMs, providing new insights into how models are domain-specifically\nfine-tuned. Additionally, our results also demonstrate that GRPO-based RL\ntuning consistently outperforms standard supervised fine-tuning (SFT) in both\naccuracy and reasoning quality.",
      "tldr_zh": "该研究探讨了强化学习（RL）在医疗视觉问答（VQA）中的微调效果，特别是基于Group Relative Policy Optimization (GRPO)的方法，以使多模态大语言模型（MLLMs）的行为更符合临床期望。研究调查了四个关键因素：基模型初始化策略、医疗语义对齐、基于长链推理的长度奖励影响，以及偏置的影响。实验结果显示，GRPO-based RL 调优在准确性和推理质量上均优于标准监督微调（SFT），为医疗领域模型的领域特定微调提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13973v1",
      "published_date": "2025-05-20 06:12:20 UTC",
      "updated_date": "2025-05-20 06:12:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:21:37.290231"
    },
    {
      "arxiv_id": "2505.13971v1",
      "title": "The Multimodal Information Based Speech Processing (MISP) 2025 Challenge: Audio-Visual Diarization and Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Gao",
        "Shilong Wu",
        "Hang Chen",
        "Jun Du",
        "Chin-Hui Lee",
        "Shinji Watanabe",
        "Jingdong Chen",
        "Siniscalchi Sabato Marco",
        "Odette Scharenborg"
      ],
      "abstract": "Meetings are a valuable yet challenging scenario for speech applications due\nto complex acoustic conditions. This paper summarizes the outcomes of the MISP\n2025 Challenge, hosted at Interspeech 2025, which focuses on multi-modal,\nmulti-device meeting transcription by incorporating video modality alongside\naudio. The tasks include Audio-Visual Speaker Diarization (AVSD), Audio-Visual\nSpeech Recognition (AVSR), and Audio-Visual Diarization and Recognition (AVDR).\nWe present the challenge's objectives, tasks, dataset, baseline systems, and\nsolutions proposed by participants. The best-performing systems achieved\nsignificant improvements over the baseline: the top AVSD model achieved a\nDiarization Error Rate (DER) of 8.09%, improving by 7.43%; the top AVSR system\nachieved a Character Error Rate (CER) of 9.48%, improving by 10.62%; and the\nbest AVDR system achieved a concatenated minimum-permutation Character Error\nRate (cpCER) of 11.56%, improving by 72.49%.",
      "tldr_zh": "MISP 2025 Challenge 聚焦于多模态、多设备会议转录，旨在通过整合视频和音频提升语音应用性能，解决复杂声学环境的挑战。挑战包括三个主要任务：Audio-Visual Speaker Diarization (AVSD)、Audio-Visual Speech Recognition (AVSR) 和 Audio-Visual Diarization and Recognition (AVDR)，并提供了数据集、基线系统以及参与者解决方案。实验结果显示，顶级系统显著优于基线：AVSD 的 Diarization Error Rate (DER) 达到 8.09%，改善 7.43%；AVSR 的 Character Error Rate (CER) 达到 9.48%，改善 10.62%；AVDR 的 concatenated minimum-permutation Character Error Rate (cpCER) 达到 11.56%，改善 72.49%。这项挑战为多模态语音处理技术的发展提供了宝贵见解。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by Interspeech 2025. Camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2505.13971v1",
      "published_date": "2025-05-20 06:11:51 UTC",
      "updated_date": "2025-05-20 06:11:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:21:50.268126"
    },
    {
      "arxiv_id": "2505.13969v1",
      "title": "Hypothesis on the Functional Advantages of the Selection-Broadcast Cycle Structure: Global Workspace Theory and Dealing with a Real-Time World",
      "title_zh": "翻译失败",
      "authors": [
        "Junya Nakanishi",
        "Jun Baba",
        "Yuichiro Yoshikawa",
        "Hiroko Kamide",
        "Hiroshi Ishiguro"
      ],
      "abstract": "This paper discusses the functional advantages of the Selection-Broadcast\nCycle structure proposed by Global Workspace Theory (GWT), inspired by human\nconsciousness, particularly focusing on its applicability to artificial\nintelligence and robotics in dynamic, real-time scenarios. While previous\nstudies often examined the Selection and Broadcast processes independently,\nthis research emphasizes their combined cyclic structure and the resulting\nbenefits for real-time cognitive systems. Specifically, the paper identifies\nthree primary benefits: Dynamic Thinking Adaptation, Experience-Based\nAdaptation, and Immediate Real-Time Adaptation. This work highlights GWT's\npotential as a cognitive architecture suitable for sophisticated\ndecision-making and adaptive performance in unsupervised, dynamic environments.\nIt suggests new directions for the development and implementation of robust,\ngeneral-purpose AI and robotics systems capable of managing complex, real-world\ntasks.",
      "tldr_zh": "本论文探讨了 Global Workspace Theory (GWT) 提出的 Selection-Broadcast Cycle 结构的功能优势，特别是将其应用于人工智能和机器人学中的动态实时场景。研究强调了 Selection 和 Broadcast 过程的结合循环结构，而非独立分析，识别出三个主要益处：Dynamic Thinking Adaptation、Experience-Based Adaptation 和 Immediate Real-Time Adaptation。这些益处提升了认知系统的实时适应性和决策能力，最终为开发鲁棒的、通用 AI 和机器人系统提供新方向，以应对复杂、动态的真实世界环境。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13969v1",
      "published_date": "2025-05-20 06:07:21 UTC",
      "updated_date": "2025-05-20 06:07:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:22:01.742807"
    },
    {
      "arxiv_id": "2505.14738v1",
      "title": "R&D-Agent: Automating Data-Driven AI Solution Building Through LLM-Powered Automated Research, Development, and Evolution",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Yang",
        "Xiao Yang",
        "Shikai Fang",
        "Bowen Xian",
        "Yuante Li",
        "Jian Wang",
        "Minrui Xu",
        "Haoran Pan",
        "Xinpeng Hong",
        "Weiqing Liu",
        "Yelong Shen",
        "Weizhu Chen",
        "Jiang Bian"
      ],
      "abstract": "Recent advances in AI and ML have transformed data science, yet increasing\ncomplexity and expertise requirements continue to hinder progress. While\ncrowdsourcing platforms alleviate some challenges, high-level data science\ntasks remain labor-intensive and iterative. To overcome these limitations, we\nintroduce R&D-Agent, a dual-agent framework for iterative exploration. The\nResearcher agent uses performance feedback to generate ideas, while the\nDeveloper agent refines code based on error feedback. By enabling multiple\nparallel exploration traces that merge and enhance one another, R&D-Agent\nnarrows the gap between automated solutions and expert-level performance.\nEvaluated on MLE-Bench, R&D-Agent emerges as the top-performing machine\nlearning engineering agent, demonstrating its potential to accelerate\ninnovation and improve precision across diverse data science applications. We\nhave open-sourced R&D-Agent on GitHub: https://github.com/microsoft/RD-Agent.",
      "tldr_zh": "本研究针对 AI 和 ML 的复杂性导致数据科学任务劳动密集的问题，引入了 R&D-Agent，这是一个基于 LLM 的双智能体框架。Researcher 代理利用性能反馈生成想法，而 Developer 代理通过错误反馈优化代码，支持多个并行探索路径以合并和提升解决方案。该框架在 MLE-Bench 基准测试中表现出色，成为顶尖的机器学习工程代理，有助于加速创新并提高数据科学应用的精确性，并已在 GitHub 上开源。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 1 figure, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2505.14738v1",
      "published_date": "2025-05-20 06:07:00 UTC",
      "updated_date": "2025-05-20 06:07:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:22:15.281232"
    },
    {
      "arxiv_id": "2505.13965v1",
      "title": "CAFES: A Collaborative Multi-Agent Framework for Multi-Granular Multimodal Essay Scoring",
      "title_zh": "翻译失败",
      "authors": [
        "Jiamin Su",
        "Yibo Yan",
        "Zhuoran Gao",
        "Han Zhang",
        "Xiang Liu",
        "Xuming Hu"
      ],
      "abstract": "Automated Essay Scoring (AES) is crucial for modern education, particularly\nwith the increasing prevalence of multimodal assessments. However, traditional\nAES methods struggle with evaluation generalizability and multimodal\nperception, while even recent Multimodal Large Language Model (MLLM)-based\napproaches can produce hallucinated justifications and scores misaligned with\nhuman judgment. To address the limitations, we introduce CAFES, the first\ncollaborative multi-agent framework specifically designed for AES. It\norchestrates three specialized agents: an Initial Scorer for rapid,\ntrait-specific evaluations; a Feedback Pool Manager to aggregate detailed,\nevidence-grounded strengths; and a Reflective Scorer that iteratively refines\nscores based on this feedback to enhance human alignment. Extensive\nexperiments, using state-of-the-art MLLMs, achieve an average relative\nimprovement of 21% in Quadratic Weighted Kappa (QWK) against ground truth,\nespecially for grammatical and lexical diversity. Our proposed CAFES framework\npaves the way for an intelligent multimodal AES system. The code will be\navailable upon acceptance.",
      "tldr_zh": "本研究提出CAFES，一种专为多粒度多模态作文评分设计的协作多智能体框架，旨在解决传统Automated Essay Scoring (AES)方法在泛化性和多模态感知上的局限，以及基于Multimodal Large Language Model (MLLM)的系统可能产生的幻觉和评分偏差问题。CAFES包括三个专门代理：Initial Scorer负责快速的特质特定评估、Feedback Pool Manager聚合基于证据的优势反馈，以及Reflective Scorer通过迭代精炼分数以提升与人类判断的对齐。实验结果显示，使用最先进MLLMs的CAFES在Quadratic Weighted Kappa (QWK)上实现了平均相对改善21%，特别是在语法和词汇多样性方面。该框架为智能多模态AES系统的发展奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2502.11916",
      "pdf_url": "http://arxiv.org/pdf/2505.13965v1",
      "published_date": "2025-05-20 06:05:56 UTC",
      "updated_date": "2025-05-20 06:05:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:22:28.588963"
    },
    {
      "arxiv_id": "2505.13949v1",
      "title": "FlashThink: An Early Exit Method For Efficient Reasoning",
      "title_zh": "FlashThink: 一种用于高效推理的提前退出方法",
      "authors": [
        "Guochao Jiang",
        "Guofeng Quan",
        "Zepeng Ding",
        "Ziqin Luo",
        "Dixuan Wang",
        "Zheng Hu"
      ],
      "abstract": "Large Language Models (LLMs) have shown impressive performance in reasoning\ntasks. However, LLMs tend to generate excessively long reasoning content,\nleading to significant computational overhead. Our observations indicate that\neven on simple problems, LLMs tend to produce unnecessarily lengthy reasoning\ncontent, which is against intuitive expectations. Preliminary experiments show\nthat at a certain point during the generation process, the model is already\ncapable of producing the correct solution without completing the full reasoning\ncontent. Therefore, we consider that the reasoning process of the model can be\nexited early to achieve the purpose of efficient reasoning. We introduce a\nverification model that identifies the exact moment when the model can stop\nreasoning and still provide the correct answer. Comprehensive experiments on\nfour different benchmarks demonstrate that our proposed method, FlashThink,\neffectively shortens the reasoning content while preserving the model accuracy.\nFor the Deepseek-R1 and QwQ-32B models, we reduced the length of reasoning\ncontent by 77.04% and 77.47%, respectively, without reducing the accuracy.",
      "tldr_zh": "该研究针对大语言模型(LLMs)在推理任务中生成过长内容导致的计算开销问题，提出了一种Early Exit方法，即FlashThink。FlashThink引入一个验证模型来实时判断模型是否已达到正确答案的生成点，从而提前终止推理过程，以提高效率。实验在四个基准上验证了该方法的有效性，对Deepseek-R1和QwQ-32B模型，推理内容长度分别减少77.04%和77.47%，而准确性保持不变。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13949v1",
      "published_date": "2025-05-20 05:28:21 UTC",
      "updated_date": "2025-05-20 05:28:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:22:38.992279"
    },
    {
      "arxiv_id": "2505.13948v1",
      "title": "Memory-Centric Embodied Question Answer",
      "title_zh": "翻译失败",
      "authors": [
        "Mingliang Zhai",
        "Zhi Gao",
        "Yuwei Wu",
        "Yunde Jia"
      ],
      "abstract": "Embodied Question Answering (EQA) requires agents to autonomously explore and\nunderstand the environment to answer context-dependent questions. Existing\nframeworks typically center around the planner, which guides the stopping\nmodule, memory module, and answering module for reasoning. In this paper, we\npropose a memory-centric EQA framework named MemoryEQA. Unlike planner-centric\nEQA models where the memory module cannot fully interact with other modules,\nMemoryEQA flexible feeds memory information into all modules, thereby enhancing\nefficiency and accuracy in handling complex tasks, such as those involving\nmultiple targets across different regions. Specifically, we establish a\nmulti-modal hierarchical memory mechanism, which is divided into global memory\nthat stores language-enhanced scene maps, and local memory that retains\nhistorical observations and state information. When performing EQA tasks, the\nmulti-modal large language model is leveraged to convert memory information\ninto the required input formats for injection into different modules. To\nevaluate EQA models' memory capabilities, we constructed the MT-HM3D dataset\nbased on HM3D, comprising 1,587 question-answer pairs involving multiple\ntargets across various regions, which requires agents to maintain memory of\nexploration-acquired target information. Experimental results on HM-EQA,\nMT-HM3D, and OpenEQA demonstrate the effectiveness of our framework, where a\n19.8% performance gain on MT-HM3D compared to baseline model further\nunderscores memory capability's pivotal role in resolving complex tasks.",
      "tldr_zh": "本论文提出了一种以记忆为中心的 Embodied Question Answering (EQA) 框架，名为 MemoryEQA，以解决传统规划器中心模型中记忆模块交互不足的问题。\n该框架引入多模态分层记忆机制，包括全局记忆（存储语言增强的场景地图）和本地记忆（保留历史观察及状态信息），并利用多模态大语言模型将记忆信息灵活注入各模块，提高任务效率和准确性，尤其在涉及多个目标和不同区域的复杂场景中。\n为评估记忆能力，论文构建了 MT-HM3D 数据集，包含 1,587 个问题-答案对，实验结果在 HM-EQA、MT-HM3D 和 OpenEQA 上显示 MemoryEQA 比基线模型提升 19.8% 的性能，强调了记忆在 EQA 中的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "14pages, 7 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.13948v1",
      "published_date": "2025-05-20 05:27:57 UTC",
      "updated_date": "2025-05-20 05:27:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:22:53.090758"
    },
    {
      "arxiv_id": "2505.13946v1",
      "title": "Visual Instruction Bottleneck Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Changdae Oh",
        "Jiatong Li",
        "Shawn Im",
        "Yixuan Li"
      ],
      "abstract": "Despite widespread adoption, multimodal large language models (MLLMs) suffer\nperformance degradation when encountering unfamiliar queries under distribution\nshifts. Existing methods to improve MLLM generalization typically require\neither more instruction data or larger advanced model architectures, both of\nwhich incur non-trivial human labor or computational costs. In this work, we\ntake an alternative approach to enhance the robustness of MLLMs under\ndistribution shifts, from a representation learning perspective. Inspired by\nthe information bottleneck (IB) principle, we derive a variational lower bound\nof the IB for MLLMs and devise a practical implementation, Visual Instruction\nBottleneck Tuning (Vittle). We then provide a theoretical justification of\nVittle by revealing its connection to an information-theoretic robustness\nmetric of MLLM. Empirical validation of three MLLMs on open-ended and\nclosed-form question answering and object hallucination detection tasks over 45\ndatasets, including 30 shift scenarios, demonstrates that Vittle consistently\nimproves the MLLM's robustness under shifts by pursuing the learning of a\nminimal sufficient representation.",
      "tldr_zh": "本文研究发现，多模态大语言模型(MLLMs)在面对分布偏移的未知查询时性能会下降，而现有方法往往需要更多数据或更大模型，带来高成本。作者从表示学习角度出发，基于信息瓶颈(IB)原则，提出Visual Instruction Bottleneck Tuning (Vittle)方法，通过推导IB的变分下界并实现实际优化，来提升MLLMs的鲁棒性。实验在45个数据集（包括30个偏移场景）上验证了Vittle的效果，显著改善了MLLMs在开放式和封闭式问答以及物体幻觉检测任务中的表现，实现了最小充分表示的学习。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13946v1",
      "published_date": "2025-05-20 05:24:53 UTC",
      "updated_date": "2025-05-20 05:24:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:23:03.074415"
    },
    {
      "arxiv_id": "2505.13941v1",
      "title": "MLZero: A Multi-Agent System for End-to-end Machine Learning Automation",
      "title_zh": "MLZero：一种用于端到端机器学习自动化的多智能体系统",
      "authors": [
        "Haoyang Fang",
        "Boran Han",
        "Nick Erickson",
        "Xiyuan Zhang",
        "Su Zhou",
        "Anirudh Dagar",
        "Jiani Zhang",
        "Ali Caner Turkmen",
        "Cuixiong Hu",
        "Huzefa Rangwala",
        "Ying Nian Wu",
        "Bernie Wang",
        "George Karypis"
      ],
      "abstract": "Existing AutoML systems have advanced the automation of machine learning\n(ML); however, they still require substantial manual configuration and expert\ninput, particularly when handling multimodal data. We introduce MLZero, a novel\nmulti-agent framework powered by Large Language Models (LLMs) that enables\nend-to-end ML automation across diverse data modalities with minimal human\nintervention. A cognitive perception module is first employed, transforming raw\nmultimodal inputs into perceptual context that effectively guides the\nsubsequent workflow. To address key limitations of LLMs, such as hallucinated\ncode generation and outdated API knowledge, we enhance the iterative code\ngeneration process with semantic and episodic memory. MLZero demonstrates\nsuperior performance on MLE-Bench Lite, outperforming all competitors in both\nsuccess rate and solution quality, securing six gold medals. Additionally, when\nevaluated on our Multimodal AutoML Agent Benchmark, which includes 25 more\nchallenging tasks spanning diverse data modalities, MLZero outperforms the\ncompeting methods by a large margin with a success rate of 0.92 (+263.6\\%) and\nan average rank of 2.28. Our approach maintains its robust effectiveness even\nwith a compact 8B LLM, outperforming full-size systems from existing solutions.",
      "tldr_zh": "本文提出 MLZero，一种基于 Large Language Models (LLMs) 的 Multi-Agent System，实现端到端的机器学习自动化，适用于多模态数据并最小化人为干预。该框架包括认知感知模块，将原始输入转化为感知上下文，并通过语义和情节记忆增强迭代代码生成，以解决 LLMs 的幻觉代码和过时 API 问题。在基准测试中，MLZero 在 MLE-Bench Lite 上获得六枚金牌，并在 Multimodal AutoML Agent Benchmark 的 25 个任务上以成功率 0.92（+263.6%）大幅领先竞争对手，即使使用 8B 紧凑模型也表现出色。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13941v1",
      "published_date": "2025-05-20 05:20:53 UTC",
      "updated_date": "2025-05-20 05:20:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:23:16.428856"
    },
    {
      "arxiv_id": "2505.13940v1",
      "title": "DrugPilot: LLM-based Parameterized Reasoning Agent for Drug Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Li",
        "Zhennan Wu",
        "Shoupeng Wang",
        "Wenbin Hu"
      ],
      "abstract": "In the field of AI4Science, large-scale language models (LLMs) show great\npotential to parse complex scientific semantics, integrate cross-disciplinary\nknowledge, and assist critical task research. However, in the field of drug\ndiscovery, despite the optimization through professional data pre-training,\ncontext window expansion, and internet search, the existing LLMs are still\nfacing challenges such as massive multi-modal and heterogeneous data\nprocessing, domain knowledge dynamic updating delay, and insufficient\nconfidence in predicting the results of complex computational tasks. To address\nthese challenges, we propose the DrugPilot, an LLM-based agent with\nparameterized reasoning for drug discovery. DrugPilot addresses key limitations\nof traditional end-to-end LLM prediction approaches through its parametric\ninference architecture. This agent system supports major phases of the drug\ndiscovery pipeline, facilitating automated planning and execution of\nmulti-stage research tasks. To address the critical challenge of multi-modal\ndrug data analysis (incorporating both public datasets and user-submitted\ndata), we developed an interactive parameterized memory pool. This innovative\ncomponent standardizes real-world drug data into parametric representations,\nsimultaneously enabling efficient knowledge retrieval in multi-turn dialogue\nwhile mitigating the information loss inherent in text-based data transmission.\nAdditionally, we created a drug instruct dataset across 8 essential drug\ndiscovery tasks for model fine-tuning and evaluation. Based on the Berkeley\nfunction calling evaluation framework, DrugPilot demonstrated the most advanced\ntool calling capabilities on our drug discovery tool instruction dataset,\noutperforming existing agents (e.g., ReAct, LoT). Specifically, it achieves\ntask completion rates of 98.0%, 93.5%, and 64.0% on simple, multiple, and\nmulti-turn tasks, respectively.",
      "tldr_zh": "本文提出 DrugPilot，一种基于 LLM 的参数化推理代理，用于药物发现领域，旨在解决现有模型在处理多模态异构数据、知识更新延迟和复杂任务预测信心不足等方面的挑战。DrugPilot 通过参数化推理架构和交互式参数化内存池，支持药物发现管道的多阶段自动化规划与执行，并利用一个涵盖 8 个关键任务的药物指令数据集进行模型微调。实验结果显示，DrugPilot 在 Berkeley 函数调用评估框架下，任务完成率分别达到简单任务 98.0%、多个任务 93.5% 和多轮任务 64.0%，优于现有代理如 ReAct 和 LoT。",
      "categories": [
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 10 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.13940v1",
      "published_date": "2025-05-20 05:18:15 UTC",
      "updated_date": "2025-05-20 05:18:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:23:28.584084"
    },
    {
      "arxiv_id": "2505.13938v2",
      "title": "CLEVER: A Curated Benchmark for Formally Verified Code Generation",
      "title_zh": "CLEVER：一个精心策划的形式验证代码生成基准",
      "authors": [
        "Amitayush Thakur",
        "Jasper Lee",
        "George Tsoukalas",
        "Meghana Sistla",
        "Matthew Zhao",
        "Stefan Zetzsche",
        "Greg Durrett",
        "Yisong Yue",
        "Swarat Chaudhuri"
      ],
      "abstract": "We introduce ${\\rm C{\\small LEVER}}$, a high-quality, curated benchmark of\n161 problems for end-to-end verified code generation in Lean. Each problem\nconsists of (1) the task of generating a specification that matches a held-out\nground-truth specification, and (2) the task of generating a Lean\nimplementation that provably satisfies this specification. Unlike prior\nbenchmarks, ${\\rm C{\\small LEVER}}$ avoids test-case supervision, LLM-generated\nannotations, and specifications that leak implementation logic or allow vacuous\nsolutions. All outputs are verified post-hoc using Lean's type checker to\nensure machine-checkable correctness. We use ${\\rm C{\\small LEVER}}$ to\nevaluate several few-shot and agentic approaches based on state-of-the-art\nlanguage models. These methods all struggle to achieve full verification,\nestablishing it as a challenging frontier benchmark for program synthesis and\nformal reasoning. Our benchmark can be found on\nGitHub(https://github.com/trishullab/clever) as well as\nHuggingFace(https://huggingface.co/datasets/amitayusht/clever). All our\nevaluation code is also available\nonline(https://github.com/trishullab/clever-prover).",
      "tldr_zh": "该研究引入了 CLEVER，这是一个高质量的基准数据集，包含 161 个问题，用于 Lean 中的端到端验证代码生成，每个问题涉及生成匹配隐藏规范的规格以及证明满足该规范的 Lean 实现。与现有基准不同，CLEVER 避免了测试用例监督、LLM 生成的注释以及泄露实现逻辑的规范，所有输出通过 Lean's 类型检查器进行验证以确保正确性。通过评估几种 few-shot 和 agentic approaches，研究发现这些基于最先进语言模型的方法难以实现完全验证，将 CLEVER 确立为程序 synthesis 和 formal reasoning 的挑战性前沿基准。数据集和评估代码可在 GitHub 和 HuggingFace 上获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13938v2",
      "published_date": "2025-05-20 05:15:47 UTC",
      "updated_date": "2025-05-21 03:14:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:23:39.932159"
    },
    {
      "arxiv_id": "2505.13936v1",
      "title": "EEG-to-Text Translation: A Model for Deciphering Human Brain Activity",
      "title_zh": "翻译失败",
      "authors": [
        "Saydul Akbar Murad",
        "Ashim Dahal",
        "Nick Rahimi"
      ],
      "abstract": "With the rapid advancement of large language models like Gemini, GPT, and\nothers, bridging the gap between the human brain and language processing has\nbecome an important area of focus. To address this challenge, researchers have\ndeveloped various models to decode EEG signals into text. However, these models\nstill face significant performance limitations. To overcome these shortcomings,\nwe propose a new model, R1 Translator, which aims to improve the performance of\nEEG-to-text decoding. The R1 Translator model combines a bidirectional LSTM\nencoder with a pretrained transformer-based decoder, utilizing EEG features to\nproduce high-quality text outputs. The model processes EEG embeddings through\nthe LSTM to capture sequential dependencies, which are then fed into the\ntransformer decoder for effective text generation. The R1 Translator excels in\nROUGE metrics, outperforming both T5 (previous research) and Brain Translator.\nSpecifically, R1 achieves a ROUGE-1 score of 38.00% (P), which is up to 9%\nhigher than T5 (34.89%) and 3% better than Brain (35.69%). It also leads in\nROUGE-L, with a F1 score of 32.51%, outperforming T5 by 3% (29.67%) and Brain\nby 2% (30.38%). In terms of CER, R1 achieves a CER of 0.5795, which is 2% lower\nthan T5 (0.5917) and 4% lower than Brain (0.6001). Additionally, R1 performs\nbetter in WER with a score of 0.7280, outperforming T5 by 4.3% (0.7610) and\nBrain by 3.6% (0.7553). Code is available at\nhttps://github.com/Mmurrad/EEG-To-text.",
      "tldr_zh": "本研究提出了一种名为 R1 Translator 的模型，用于将 EEG 信号解码为文本，旨在桥接人类大脑活动与语言处理的鸿沟，并解决现有模型的性能限制。模型结合双向 LSTM 编码器处理 EEG 嵌入以捕获顺序依赖性，并使用预训练的 Transformer 解码器生成高质量文本输出。在评估指标上，R1 Translator 显著优于 T5 和 Brain Translator，例如 ROUGE-1 P 得分达 38.00%（比 T5 高 9%、比 Brain 高 3%），ROUGE-L F1 得分达 32.51%（比 T5 高 3%、比 Brain 高 2%），CER 得分 0.5795（比 T5 低 2%、比 Brain 低 4%），WER 得分 0.7280（比 T5 低 4.3%、比 Brain 低 3.6%）。代码已在 GitHub 上公开，可进一步促进相关研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13936v1",
      "published_date": "2025-05-20 05:04:15 UTC",
      "updated_date": "2025-05-20 05:04:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:23:53.157463"
    },
    {
      "arxiv_id": "2505.13934v1",
      "title": "RLVR-World: Training World Models with Reinforcement Learning",
      "title_zh": "RLVR-World：使用强化学习训练世界模型",
      "authors": [
        "Jialong Wu",
        "Shaofeng Yin",
        "Ningya Feng",
        "Mingsheng Long"
      ],
      "abstract": "World models predict state transitions in response to actions and are\nincreasingly developed across diverse modalities. However, standard training\nobjectives such as maximum likelihood estimation (MLE) often misalign with\ntask-specific goals of world models, i.e., transition prediction metrics like\naccuracy or perceptual quality. In this paper, we present RLVR-World, a unified\nframework that leverages reinforcement learning with verifiable rewards (RLVR)\nto directly optimize world models for such metrics. Despite formulating world\nmodeling as autoregressive prediction of tokenized sequences, RLVR-World\nevaluates metrics of decoded predictions as verifiable rewards. We demonstrate\nsubstantial performance gains on both language- and video-based world models\nacross domains, including text games, web navigation, and robot manipulation.\nOur work indicates that, beyond recent advances in reasoning language models,\nRLVR offers a promising post-training paradigm for enhancing the utility of\ngenerative models more broadly.",
      "tldr_zh": "本论文提出 RLVR-World 框架，利用 Reinforcement Learning with Verifiable Rewards (RLVR) 来训练世界模型，直接优化任务特定指标，如准确性和感知质量，以解决标准最大似然估计 (MLE) 与目标不匹配的问题。该框架将世界建模视为基于令牌序列的自回归预测，但通过评估解码预测的指标作为可验证奖励，实现性能提升。在文本游戏、网页导航和机器人操作等领域的实验中，RLVR-World 在语言和视频世界模型上取得了显著性能收益，表明 RLVR 是一种有前景的后训练范式，可广泛增强生成模型的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code is available at project website:\n  https://thuml.github.io/RLVR-World/",
      "pdf_url": "http://arxiv.org/pdf/2505.13934v1",
      "published_date": "2025-05-20 05:02:53 UTC",
      "updated_date": "2025-05-20 05:02:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:24:04.167866"
    },
    {
      "arxiv_id": "2505.13921v1",
      "title": "APEX: Empowering LLMs with Physics-Based Task Planning for Real-time Insight",
      "title_zh": "APEX：通过基于物理学的任务规划增强 LLMs 的实时洞察能力",
      "authors": [
        "Wanjing Huang",
        "Weixiang Yan",
        "Zhen Zhang",
        "Ambuj Singh"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate strong reasoning and task planning\ncapabilities but remain fundamentally limited in physical interaction modeling.\nExisting approaches integrate perception via Vision-Language Models (VLMs) or\nadaptive decision-making through Reinforcement Learning (RL), but they fail to\ncapture dynamic object interactions or require task-specific training, limiting\ntheir real-world applicability. We introduce APEX (Anticipatory\nPhysics-Enhanced Execution), a framework that equips LLMs with physics-driven\nforesight for real-time task planning. APEX constructs structured graphs to\nidentify and model the most relevant dynamic interactions in the environment,\nproviding LLMs with explicit physical state updates. Simultaneously, APEX\nprovides low-latency forward simulations of physically feasible actions,\nallowing LLMs to select optimal strategies based on predictive outcomes rather\nthan static observations. We evaluate APEX on three benchmarks designed to\nassess perception, prediction, and decision-making: (1) Physics Reasoning\nBenchmark, testing causal inference and object motion prediction; (2) Tetris,\nevaluating whether physics-informed prediction enhances decision-making\nperformance in long-horizon planning tasks; (3) Dynamic Obstacle Avoidance,\nassessing the immediate integration of perception and action feasibility\nanalysis. APEX significantly outperforms standard LLMs and VLM-based models,\ndemonstrating the necessity of explicit physics reasoning for bridging the gap\nbetween language-based intelligence and real-world task execution. The source\ncode and experiment setup are publicly available at\nhttps://github.com/hwj20/APEX_EXP .",
      "tldr_zh": "该论文提出 APEX 框架，用于增强大型语言模型 (LLMs) 的物理基础任务规划能力，以克服其在动态物体交互建模方面的局限。APEX 通过构建结构化图来识别环境中的动态交互，并提供低延迟的前向模拟，帮助 LLMs 基于预测结果选择最优策略。实验在 Physics Reasoning Benchmark、Tetris 和 Dynamic Obstacle Avoidance 等基准上评估，APEX 显著优于标准 LLMs 和 Vision-Language Models (VLMs)，证明了显式物理推理在桥接语言智能与真实世界任务执行方面的关键作用。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13921v1",
      "published_date": "2025-05-20 04:34:58 UTC",
      "updated_date": "2025-05-20 04:34:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:24:17.178050"
    },
    {
      "arxiv_id": "2505.13914v1",
      "title": "Parallel Belief Revision via Order Aggregation",
      "title_zh": "翻译失败",
      "authors": [
        "Jake Chandler",
        "Richard Booth"
      ],
      "abstract": "Despite efforts to better understand the constraints that operate on\nsingle-step parallel (aka \"package\", \"multiple\") revision, very little work has\nbeen carried out on how to extend the model to the iterated case. A recent\npaper by Delgrande & Jin outlines a range of relevant rationality postulates.\nWhile many of these are plausible, they lack an underlying unifying\nexplanation. We draw on recent work on iterated parallel contraction to offer a\ngeneral method for extending serial iterated belief revision operators to\nhandle parallel change. This method, based on a family of order aggregators\nknown as TeamQueue aggregators, provides a principled way to recover the\nindependently plausible properties that can be found in the literature, without\nyielding the more dubious ones.",
      "tldr_zh": "本文探讨了如何将单步并行信念修正（parallel belief revision）扩展到迭代情况，尽管相关理性假设（rationality postulates）如 Delgrande & Jin 所提出的已存在，但缺乏统一解释。作者提出一种基于 TeamQueue 聚合器（order aggregators）的通用方法，从串行迭代信念修正操作符（serial iterated belief revision operators）扩展到处理并行变化。该方法能系统地恢复文献中合理的属性，同时避免不合理的假设，从而为并行信念修正提供更可靠的框架。",
      "categories": [
        "cs.AI",
        "I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13914v1",
      "published_date": "2025-05-20 04:26:01 UTC",
      "updated_date": "2025-05-20 04:26:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:24:29.133877"
    },
    {
      "arxiv_id": "2505.13911v1",
      "title": "Bronchovascular Tree-Guided Weakly Supervised Learning Method for Pulmonary Segment Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Ruijie Zhao",
        "Zuopeng Tan",
        "Xiao Xue",
        "Longfei Zhao",
        "Bing Li",
        "Zicheng Liao",
        "Ying Ming",
        "Jiaru Wang",
        "Ran Xiao",
        "Sirong Piao",
        "Rui Zhao",
        "Qiqi Xu",
        "Wei Song"
      ],
      "abstract": "Pulmonary segment segmentation is crucial for cancer localization and\nsurgical planning. However, the pixel-wise annotation of pulmonary segments is\nlaborious, as the boundaries between segments are indistinguishable in medical\nimages. To this end, we propose a weakly supervised learning (WSL) method,\ntermed Anatomy-Hierarchy Supervised Learning (AHSL), which consults the precise\nclinical anatomical definition of pulmonary segments to perform pulmonary\nsegment segmentation. Since pulmonary segments reside within the lobes and are\ndetermined by the bronchovascular tree, i.e., artery, airway and vein, the\ndesign of the loss function is founded on two principles. First, segment-level\nlabels are utilized to directly supervise the output of the pulmonary segments,\nensuring that they accurately encompass the appropriate bronchovascular tree.\nSecond, lobe-level supervision indirectly oversees the pulmonary segment,\nensuring their inclusion within the corresponding lobe. Besides, we introduce a\ntwo-stage segmentation strategy that incorporates bronchovascular priori\ninformation. Furthermore, a consistency loss is proposed to enhance the\nsmoothness of segment boundaries, along with an evaluation metric designed to\nmeasure the smoothness of pulmonary segment boundaries. Visual inspection and\nevaluation metrics from experiments conducted on a private dataset demonstrate\nthe effectiveness of our method.",
      "tldr_zh": "本论文提出了一种弱监督学习方法Anatomy-Hierarchy Supervised Learning (AHSL)，用于肺段分割，以解决医疗图像中边界难以区分的标注难题。该方法利用支气管血管树（包括artery、airway和vein）的临床解剖定义，设计了基于两个原则的损失函数：直接用段级标签监督肺段输出，确保其覆盖适当的支气管血管树；以及用叶级监督间接确保肺段位于对应叶中。此外，该方法引入了两阶段分割策略、一致性损失来提升边界光滑性，并设计了专用评估指标。实验在私有数据集上通过视觉检查和指标验证，证明了AHSL的有效性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13911v1",
      "published_date": "2025-05-20 04:23:12 UTC",
      "updated_date": "2025-05-20 04:23:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:24:41.371736"
    },
    {
      "arxiv_id": "2505.13909v1",
      "title": "Efficient Agent Training for Computer Use",
      "title_zh": "翻译失败",
      "authors": [
        "Yanheng He",
        "Jiahe Jin",
        "Pengfei Liu"
      ],
      "abstract": "Scaling up high-quality trajectory data has long been a critical bottleneck\nfor developing human-like computer use agents. We introduce PC Agent-E, an\nefficient agent training framework that significantly reduces reliance on\nlarge-scale human demonstrations. Starting with just 312 human-annotated\ncomputer use trajectories, we further improved data quality by synthesizing\ndiverse action decisions with Claude 3.7 Sonnet. Trained on these enriched\ntrajectories, our PC Agent-E model achieved a remarkable 141% relative\nimprovement, surpassing the strong Claude 3.7 Sonnet with extended thinking on\nWindowsAgentArena-V2, an improved benchmark we also released. Furthermore, PC\nAgent-E demonstrates strong generalizability to different operating systems on\nOSWorld. Our findings suggest that strong computer use capabilities can be\nstimulated from a small amount of high-quality trajectory data.",
      "tldr_zh": "这篇论文介绍了PC Agent-E，一种高效的代理训练框架，旨在减少对大规模人类演示的依赖，仅从312个人类标注的计算机使用轨迹出发，通过Claude 3.7 Sonnet合成多样化行动决策来提升数据质量。训练后的PC Agent-E模型在WindowsAgentArena-V2基准上实现了141%的相对改进，超过了Claude 3.7 Sonnet基准。模型还展示了在OSWorld上的强泛化能力。研究结果表明，少量高质量轨迹数据即可激发强大的计算机使用代理能力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "We open-source our entire suite of code, data, and models to\n  facilitate future research at https://github.com/GAIR-NLP/PC-Agent-E",
      "pdf_url": "http://arxiv.org/pdf/2505.13909v1",
      "published_date": "2025-05-20 04:20:18 UTC",
      "updated_date": "2025-05-20 04:20:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:24:53.362941"
    },
    {
      "arxiv_id": "2505.13906v1",
      "title": "XDementNET: An Explainable Attention Based Deep Convolutional Network to Detect Alzheimer Progression from MRI data",
      "title_zh": "翻译失败",
      "authors": [
        "Soyabul Islam Lincoln",
        "Mirza Mohd Shahriar Maswood"
      ],
      "abstract": "A common neurodegenerative disease, Alzheimer's disease requires a precise\ndiagnosis and efficient treatment, particularly in light of escalating\nhealthcare expenses and the expanding use of artificial intelligence in medical\ndiagnostics. Many recent studies shows that the combination of brain Magnetic\nResonance Imaging (MRI) and deep neural networks have achieved promising\nresults for diagnosing AD. Using deep convolutional neural networks, this paper\nintroduces a novel deep learning architecture that incorporates multiresidual\nblocks, specialized spatial attention blocks, grouped query attention, and\nmulti-head attention. The study assessed the model's performance on four\npublicly accessible datasets and concentrated on identifying binary and\nmulticlass issues across various categories. This paper also takes into account\nof the explainability of AD's progression and compared with state-of-the-art\nmethods namely Gradient Class Activation Mapping (GradCAM), Score-CAM, Faster\nScore-CAM, and XGRADCAM. Our methodology consistently outperforms current\napproaches, achieving 99.66\\% accuracy in 4-class classification, 99.63\\% in\n3-class classification, and 100\\% in binary classification using Kaggle\ndatasets. For Open Access Series of Imaging Studies (OASIS) datasets the\naccuracies are 99.92\\%, 99.90\\%, and 99.95\\% respectively. The Alzheimer's\nDisease Neuroimaging Initiative-1 (ADNI-1) dataset was used for experiments in\nthree planes (axial, sagittal, and coronal) and a combination of all planes.\nThe study achieved accuracies of 99.08\\% for axis, 99.85\\% for sagittal, 99.5\\%\nfor coronal, and 99.17\\% for all axis, and 97.79\\% and 8.60\\% respectively for\nADNI-2. The network's ability to retrieve important information from MRI images\nis demonstrated by its excellent accuracy in categorizing AD stages.",
      "tldr_zh": "本研究提出 XDementNET，一种基于深度卷积神经网络的解释性模型，用于从 MRI 数据检测 Alzheimer’s disease (AD) 进展。该模型整合了多残差块（multiresidual blocks）、专用空间注意力块（specialized spatial attention blocks）、分组查询注意力（grouped query attention）和多头注意力（multi-head attention），并与 GradCAM、Score-CAM 等方法进行比较。在多个公开数据集上评估显示，该模型在 Kaggle 数据集上实现 99.66% 的 4 类分类准确率，在 OASIS 数据集上达到 99.92%，并在 ADNI-1 和 ADNI-2 数据集上表现出色。通过高准确率，该方法证明了从 MRI 图像中有效提取关键信息的能力，为 AD 诊断提供可靠的自主工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "20 pages, 12 figures,",
      "pdf_url": "http://arxiv.org/pdf/2505.13906v1",
      "published_date": "2025-05-20 04:17:28 UTC",
      "updated_date": "2025-05-20 04:17:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:25:06.165989"
    },
    {
      "arxiv_id": "2505.13904v1",
      "title": "Learning to Insert for Constructive Neural Vehicle Routing Solver",
      "title_zh": "翻译失败",
      "authors": [
        "Fu Luo",
        "Xi Lin",
        "Mengyuan Zhong",
        "Fei Liu",
        "Zhenkun Wang",
        "Jianyong Sun",
        "Qingfu Zhang"
      ],
      "abstract": "Neural Combinatorial Optimisation (NCO) is a promising learning-based\napproach for solving Vehicle Routing Problems (VRPs) without extensive manual\ndesign. While existing constructive NCO methods typically follow an\nappending-based paradigm that sequentially adds unvisited nodes to partial\nsolutions, this rigid approach often leads to suboptimal results. To overcome\nthis limitation, we explore the idea of insertion-based paradigm and propose\nLearning to Construct with Insertion-based Paradigm (L2C-Insert), a novel\nlearning-based method for constructive NCO. Unlike traditional approaches,\nL2C-Insert builds solutions by strategically inserting unvisited nodes at any\nvalid position in the current partial solution, which can significantly enhance\nthe flexibility and solution quality. The proposed framework introduces three\nkey components: a novel model architecture for precise insertion position\nprediction, an efficient training scheme for model optimization, and an\nadvanced inference technique that fully exploits the insertion paradigm's\nflexibility. Extensive experiments on both synthetic and real-world instances\nof the Travelling Salesman Problem (TSP) and Capacitated Vehicle Routing\nProblem (CVRP) demonstrate that L2C-Insert consistently achieves superior\nperformance across various problem sizes.",
      "tldr_zh": "本研究针对 Neural Combinatorial Optimisation (NCO) 在解决 Vehicle Routing Problems (VRPs) 时，现有的 appending-based 范式导致次优结果的问题，提出了一种新型方法 Learning to Construct with Insertion-based Paradigm (L2C-Insert)。该方法通过在当前部分解决方案中战略性地插入未访问节点，增强了灵活性和解决方案质量，其关键组件包括用于精确插入位置预测的模型架构、有效的训练方案，以及充分利用插入范式的先进推理技术。在 Travelling Salesman Problem (TSP) 和 Capacitated Vehicle Routing Problem (CVRP) 的合成及真实实例上，L2C-Insert 在各种问题规模下均表现出优越性能，显著提升了 NCO 的整体效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13904v1",
      "published_date": "2025-05-20 04:10:50 UTC",
      "updated_date": "2025-05-20 04:10:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:25:19.093795"
    },
    {
      "arxiv_id": "2505.13898v1",
      "title": "Do Language Models Use Their Depth Efficiently?",
      "title_zh": "语言模型是否高效利用其深度？",
      "authors": [
        "Róbert Csordás",
        "Christopher D. Manning",
        "Christopher Potts"
      ],
      "abstract": "Modern LLMs are increasingly deep, and depth correlates with performance,\nalbeit with diminishing returns. However, do these models use their depth\nefficiently? Do they compose more features to create higher-order computations\nthat are impossible in shallow models, or do they merely spread the same kinds\nof computation out over more layers? To address these questions, we analyze the\nresidual stream of the Llama 3.1 and Qwen 3 family of models. We find: First,\ncomparing the output of the sublayers to the residual stream reveals that\nlayers in the second half contribute much less than those in the first half,\nwith a clear phase transition between the two halves. Second, skipping layers\nin the second half has a much smaller effect on future computations and output\npredictions. Third, for multihop tasks, we are unable to find evidence that\nmodels are using increased depth to compose subresults in examples involving\nmany hops. Fourth, we seek to directly address whether deeper models are using\ntheir additional layers to perform new kinds of computation. To do this, we\ntrain linear maps from the residual stream of a shallow model to a deeper one.\nWe find that layers with the same relative depth map best to each other,\nsuggesting that the larger model simply spreads the same computations out over\nits many layers. All this evidence suggests that deeper models are not using\ntheir depth to learn new kinds of computation, but only using the greater depth\nto perform more fine-grained adjustments to the residual. This may help explain\nwhy increasing scale leads to diminishing returns for stacked Transformer\narchitectures.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）是否高效利用其深度，通过分析 Llama 3.1 和 Qwen 3 模型的 residual stream。研究发现，后半层贡献较小，跳层实验显示其对输出预测影响有限，且在多跳任务中，模型未使用额外深度来组合子结果，而是将相同计算分散到更多层。最终，证据表明更深模型仅进行细粒度的调整，这可能解释了堆叠 Transformer 架构规模增加导致的收益递减现象。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13898v1",
      "published_date": "2025-05-20 04:00:56 UTC",
      "updated_date": "2025-05-20 04:00:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:25:29.623748"
    },
    {
      "arxiv_id": "2505.13887v2",
      "title": "Mobile-Agent-V: A Video-Guided Approach for Effortless and Efficient Operational Knowledge Injection in Mobile Automation",
      "title_zh": "Mobile-Agent-V：一种视频引导的方法，用于移动自动化中的轻松高效操作知识注入",
      "authors": [
        "Junyang Wang",
        "Haiyang Xu",
        "Xi Zhang",
        "Ming Yan",
        "Ji Zhang",
        "Fei Huang",
        "Jitao Sang"
      ],
      "abstract": "The exponential rise in mobile device usage necessitates streamlined\nautomation for effective task management, yet many AI frameworks fall short due\nto inadequate operational expertise. While manually written knowledge can\nbridge this gap, it is often burdensome and inefficient. We introduce\nMobile-Agent-V, an innovative framework that utilizes video as a guiding tool\nto effortlessly and efficiently inject operational knowledge into mobile\nautomation processes. By deriving knowledge directly from video content,\nMobile-Agent-V eliminates manual intervention, significantly reducing the\neffort and time required for knowledge acquisition. To rigorously evaluate this\napproach, we propose Mobile-Knowledge, a benchmark tailored to assess the\nimpact of external knowledge on mobile agent performance. Our experimental\nfindings demonstrate that Mobile-Agent-V enhances performance by 36% compared\nto existing methods, underscoring its effortless and efficient advantages in\nmobile automation.",
      "tldr_zh": "该研究针对移动设备自动化中操作知识不足的问题，提出Mobile-Agent-V框架，这是一种基于视频引导的方法，能够轻松高效地将操作知识注入自动化流程，从而减少手动干预并节省时间。通过从视频内容中直接提取知识，Mobile-Agent-V显著提升了自动化效率。该框架的性能通过新提出的Mobile-Knowledge基准进行评估，实验结果显示，与现有方法相比，性能提升了36%。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "I was trying to update arXiv:2502.17110 but accidentally published a\n  new work",
      "pdf_url": "http://arxiv.org/pdf/2505.13887v2",
      "published_date": "2025-05-20 03:48:19 UTC",
      "updated_date": "2025-05-21 02:28:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:25:39.678299"
    },
    {
      "arxiv_id": "2505.14737v1",
      "title": "Leveraging Multivariate Long-Term History Representation for Time Series Forecasting",
      "title_zh": "利用多变量长期历史表示进行时间序列预测",
      "authors": [
        "Huiliang Zhang",
        "Di Wu",
        "Arnaud Zinflou",
        "Stephane Dellacherie",
        "Mouhamadou Makhtar Dione",
        "Benoit Boulet"
      ],
      "abstract": "Multivariate Time Series (MTS) forecasting has a wide range of applications\nin both industry and academia. Recent advances in Spatial-Temporal Graph Neural\nNetwork (STGNN) have achieved great progress in modelling spatial-temporal\ncorrelations. Limited by computational complexity, most STGNNs for MTS\nforecasting focus primarily on short-term and local spatial-temporal\ndependencies. Although some recent methods attempt to incorporate univariate\nhistory into modeling, they still overlook crucial long-term spatial-temporal\nsimilarities and correlations across MTS, which are essential for accurate\nforecasting. To fill this gap, we propose a framework called the Long-term\nMultivariate History Representation (LMHR) Enhanced STGNN for MTS forecasting.\nSpecifically, a Long-term History Encoder (LHEncoder) is adopted to effectively\nencode the long-term history into segment-level contextual representations and\nreduce point-level noise. A non-parametric Hierarchical Representation\nRetriever (HRetriever) is designed to include the spatial information in the\nlong-term spatial-temporal dependency modelling and pick out the most valuable\nrepresentations with no additional training. A Transformer-based Aggregator\n(TAggregator) selectively fuses the sparsely retrieved contextual\nrepresentations based on the ranking positional embedding efficiently.\nExperimental results demonstrate that LMHR outperforms typical STGNNs by 10.72%\non the average prediction horizons and state-of-the-art methods by 4.12% on\nseveral real-world datasets. Additionally, it consistently improves prediction\naccuracy by 9.8% on the top 10% of rapidly changing patterns across the\ndatasets.",
      "tldr_zh": "本文提出了一种名为 LMHR 的框架，用于提升多变量时间序列 (MTS) 预测的性能，通过整合长期历史表示来解决现有 Spatial-Temporal Graph Neural Network (STGNN) 模型忽略长期空间-时间依赖的问题。框架的关键组件包括 Long-term History Encoder (LHEncoder) 用于编码长期数据为段级上下文表示并减少噪声、Hierarchical Representation Retriever (HRetriever) 作为非参数模块选择最有价值的空间信息，以及 Transformer-based Aggregator (TAggregator) 基于排名位置嵌入高效融合稀疏表示。实验结果显示，LMHR 在多个真实数据集上比典型 STGNN 平均提高了 10.72% 的预测准确率，并超越最先进方法 4.12%，尤其在数据集的前 10% 快速变化模式上提升了 9.8%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14737v1",
      "published_date": "2025-05-20 03:46:36 UTC",
      "updated_date": "2025-05-20 03:46:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:25:54.417235"
    },
    {
      "arxiv_id": "2505.13873v1",
      "title": "Utilizing Strategic Pre-training to Reduce Overfitting: Baguan -- A Pre-trained Weather Forecasting Model",
      "title_zh": "翻译失败",
      "authors": [
        "Peisong Niu",
        "Ziqing Ma",
        "Tian Zhou",
        "Weiqi Chen",
        "Lefei Shen",
        "Rong Jin",
        "Liang Sun"
      ],
      "abstract": "Weather forecasting has long posed a significant challenge for humanity.\nWhile recent AI-based models have surpassed traditional numerical weather\nprediction (NWP) methods in global forecasting tasks, overfitting remains a\ncritical issue due to the limited availability of real-world weather data\nspanning only a few decades. Unlike fields like computer vision or natural\nlanguage processing, where data abundance can mitigate overfitting, weather\nforecasting demands innovative strategies to address this challenge with\nexisting data. In this paper, we explore pre-training methods for weather\nforecasting, finding that selecting an appropriately challenging pre-training\ntask introduces locality bias, effectively mitigating overfitting and enhancing\nperformance. We introduce Baguan, a novel data-driven model for medium-range\nweather forecasting, built on a Siamese Autoencoder pre-trained in a\nself-supervised manner and fine-tuned for different lead times. Experimental\nresults show that Baguan outperforms traditional methods, delivering more\naccurate forecasts. Additionally, the pre-trained Baguan demonstrates robust\noverfitting control and excels in downstream tasks, such as\nsubseasonal-to-seasonal (S2S) modeling and regional forecasting, after\nfine-tuning.",
      "tldr_zh": "该论文探讨了天气预报中因数据有限而导致的overfitting问题，通过战略预训练方法引入局部偏差来缓解这一挑战。作者提出Baguan模型，该模型基于Siamese Autoencoder的自监督预训练，并针对不同预测时长进行fine-tuning，以提升预报准确性。实验结果表明，Baguan在中等范围天气预报中优于传统NWP方法，并在下游任务如subseasonal-to-seasonal (S2S)建模和区域预报中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "KDD2025 research track accepted",
      "pdf_url": "http://arxiv.org/pdf/2505.13873v1",
      "published_date": "2025-05-20 03:29:23 UTC",
      "updated_date": "2025-05-20 03:29:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:26:05.478907"
    },
    {
      "arxiv_id": "2505.13872v1",
      "title": "Safety2Drive: Safety-Critical Scenario Benchmark for the Evaluation of Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Jingzheng Li",
        "Tiancheng Wang",
        "Xingyu Peng",
        "Jiacheng Chen",
        "Zhijun Chen",
        "Bing Li",
        "Xianglong Liu"
      ],
      "abstract": "Autonomous Driving (AD) systems demand the high levels of safety assurance.\nDespite significant advancements in AD demonstrated on open-source benchmarks\nlike Longest6 and Bench2Drive, existing datasets still lack\nregulatory-compliant scenario libraries for closed-loop testing to\ncomprehensively evaluate the functional safety of AD. Meanwhile, real-world AD\naccidents are underrepresented in current driving datasets. This scarcity leads\nto inadequate evaluation of AD performance, posing risks to safety validation\nand practical deployment. To address these challenges, we propose Safety2Drive,\na safety-critical scenario library designed to evaluate AD systems.\nSafety2Drive offers three key contributions. (1) Safety2Drive comprehensively\ncovers the test items required by standard regulations and contains 70 AD\nfunction test items. (2) Safety2Drive supports the safety-critical scenario\ngeneralization. It has the ability to inject safety threats such as natural\nenvironment corruptions and adversarial attacks cross camera and LiDAR sensors.\n(3) Safety2Drive supports multi-dimensional evaluation. In addition to the\nevaluation of AD systems, it also supports the evaluation of various perception\ntasks, such as object detection and lane detection. Safety2Drive provides a\nparadigm from scenario construction to validation, establishing a standardized\ntest framework for the safe deployment of AD.",
      "tldr_zh": "该论文提出Safety2Drive，一种针对Autonomous Driving (AD) 系统的安全关键场景基准，用于全面评估AD的功能安全。该基准解决了现有数据集缺乏合规场景库和真实事故表示的问题，提供70个AD功能测试项目，涵盖标准法规要求，并支持安全威胁泛化，如注入自然环境干扰和adversarial attacks到camera和LiDAR传感器。Safety2Drive还支持多维度评估，包括AD系统和感知任务（如object detection和lane detection），并建立从场景构建到验证的标准测试框架，促进AD的安全部署。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13872v1",
      "published_date": "2025-05-20 03:27:06 UTC",
      "updated_date": "2025-05-20 03:27:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:26:17.377093"
    },
    {
      "arxiv_id": "2505.13860v1",
      "title": "Domain Adaptation of VLM for Soccer Video Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Tiancheng Jiang",
        "Henry Wang",
        "Md Sirajus Salekin",
        "Parmida Atighehchian",
        "Shinan Zhang"
      ],
      "abstract": "Vision Language Models (VLMs) have demonstrated strong performance in\nmulti-modal tasks by effectively aligning visual and textual representations.\nHowever, most video understanding VLM research has been domain-agnostic,\nleaving the understanding of their transfer learning capability to specialized\ndomains under-explored. In this work, we address this by exploring the\nadaptability of open-source VLMs to specific domains, and focusing on soccer as\nan initial case study. Our approach uses large-scale soccer datasets and LLM to\ncreate instruction-following data, and use them to iteratively fine-tune the\ngeneral-domain VLM in a curriculum learning fashion (first teaching the model\nkey soccer concepts to then question answering tasks). The final adapted model,\ntrained using a curated dataset of 20k video clips, exhibits significant\nimprovement in soccer-specific tasks compared to the base model, with a 37.5%\nrelative improvement for the visual question-answering task and an accuracy\nimprovement from 11.8% to 63.5% for the downstream soccer action classification\ntask.",
      "tldr_zh": "这篇论文探讨了视觉语言模型 (VLMs) 在足球视频理解领域的领域适应性，针对其在特定领域的迁移学习能力进行研究。研究方法包括使用大规模足球数据集和 LLM 生成指令跟随数据，并通过课程学习方式（先教授关键足球概念，然后进行问答任务）迭代微调通用 VLM，最终训练出一个基于 20k 视频剪辑的模型。结果显示，适应后的模型在足球特定任务上显著提升，例如视觉问答任务相对改善 37.5%，足球动作分类任务准确率从 11.8% 提高到 63.5%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 figures, accepted to the 11th IEEE International Workshop\n  on Computer Vision in Sports (CVSports) at CVPR 2025; supplementary appendix\n  included as ancillary PDF",
      "pdf_url": "http://arxiv.org/pdf/2505.13860v1",
      "published_date": "2025-05-20 03:12:21 UTC",
      "updated_date": "2025-05-20 03:12:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:26:29.597067"
    },
    {
      "arxiv_id": "2505.13857v1",
      "title": "Learning Spatio-Temporal Dynamics for Trajectory Recovery via Time-Aware Transformer",
      "title_zh": "通过时间感知",
      "authors": [
        "Tian Sun",
        "Yuqi Chen",
        "Baihua Zheng",
        "Weiwei Sun"
      ],
      "abstract": "In real-world applications, GPS trajectories often suffer from low sampling\nrates, with large and irregular intervals between consecutive GPS points. This\nsparse characteristic presents challenges for their direct use in GPS-based\nsystems. This paper addresses the task of map-constrained trajectory recovery,\naiming to enhance trajectory sampling rates of GPS trajectories. Previous\nstudies commonly adopt a sequence-to-sequence framework, where an encoder\ncaptures the trajectory patterns and a decoder reconstructs the target\ntrajectory. Within this framework, effectively representing the road network\nand extracting relevant trajectory features are crucial for overall\nperformance. Despite advancements in these models, they fail to fully leverage\nthe complex spatio-temporal dynamics present in both the trajectory and the\nroad network.\n  To overcome these limitations, we categorize the spatio-temporal dynamics of\ntrajectory data into two distinct aspects: spatial-temporal traffic dynamics\nand trajectory dynamics. Furthermore, We propose TedTrajRec, a novel method for\ntrajectory recovery. To capture spatio-temporal traffic dynamics, we introduce\nPD-GNN, which models periodic patterns and learns topologically aware dynamics\nconcurrently for each road segment. For spatio-temporal trajectory dynamics, we\npresent TedFormer, a time-aware Transformer that incorporates temporal dynamics\nfor each GPS location by integrating closed-form neural ordinary differential\nequations into the attention mechanism. This allows TedFormer to effectively\nhandle irregularly sampled data. Extensive experiments on three real-world\ndatasets demonstrate the superior performance of TedTrajRec. The code is\npublicly available at https://github.com/ysygMhdxw/TEDTrajRec/.",
      "tldr_zh": "该论文针对GPS轨迹采样率低且间隔不规则的问题，提出一种map-constrained trajectory recovery方法，以提升轨迹数据的可用性。研究将spatio-temporal dynamics分为spatial-temporal traffic dynamics和spatio-temporal trajectory dynamics两方面：使用PD-GNN模型捕捉路段的周期模式和拓扑感知动态；并引入TedFormer，一种time-aware Transformer，通过整合closed-form neural ordinary differential equations到attention机制中，处理不规则采样数据。实验在三个真实数据集上验证了TedTrajRec的优越性能，代码已开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as a journal paper in IEEE Transactions on Intelligent\n  Transportation Systems (T-ITS)",
      "pdf_url": "http://arxiv.org/pdf/2505.13857v1",
      "published_date": "2025-05-20 03:09:17 UTC",
      "updated_date": "2025-05-20 03:09:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:26:41.135280"
    },
    {
      "arxiv_id": "2505.13855v1",
      "title": "Domain Gating Ensemble Networks for AI-Generated Text Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Arihant Tripathi",
        "Liam Dugan",
        "Charis Gao",
        "Maggie Huan",
        "Emma Jin",
        "Peter Zhang",
        "David Zhang",
        "Julia Zhao",
        "Chris Callison-Burch"
      ],
      "abstract": "As state-of-the-art language models continue to improve, the need for robust\ndetection of machine-generated text becomes increasingly critical. However,\ncurrent state-of-the-art machine text detectors struggle to adapt to new unseen\ndomains and generative models. In this paper we present DoGEN (Domain Gating\nEnsemble Networks), a technique that allows detectors to adapt to unseen\ndomains by ensembling a set of domain expert detector models using weights from\na domain classifier. We test DoGEN on a wide variety of domains from leading\nbenchmarks and find that it achieves state-of-the-art performance on in-domain\ndetection while outperforming models twice its size on out-of-domain detection.\nWe release our code and trained models to assist in future research in\ndomain-adaptive AI detection.",
      "tldr_zh": "该研究针对AI-Generated Text Detection领域的问题，提出DoGEN（Domain Gating Ensemble Networks）技术，以解决现有检测器在适应新领域和生成模型时的不足。DoGEN通过使用域分类器对多个域专家检测模型进行加权集成，实现对未见领域的快速适应。在各种基准测试中，DoGEN在域内检测上达到最先进性能，并在域外检测上优于规模更大的模型，同时作者发布了代码和训练模型以支持未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to EMNLP 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.13855v1",
      "published_date": "2025-05-20 03:02:05 UTC",
      "updated_date": "2025-05-20 03:02:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:26:53.453566"
    },
    {
      "arxiv_id": "2505.13851v1",
      "title": "A Challenge to Build Neuro-Symbolic Video Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Sahil Shah",
        "Harsh Goel",
        "Sai Shankar Narasimhan",
        "Minkyu Choi",
        "S P Sharan",
        "Oguzhan Akcin",
        "Sandeep Chinchali"
      ],
      "abstract": "Modern video understanding systems excel at tasks such as scene\nclassification, object detection, and short video retrieval. However, as video\nanalysis becomes increasingly central to real-world applications, there is a\ngrowing need for proactive video agents for the systems that not only interpret\nvideo streams but also reason about events and take informed actions. A key\nobstacle in this direction is temporal reasoning: while deep learning models\nhave made remarkable progress in recognizing patterns within individual frames\nor short clips, they struggle to understand the sequencing and dependencies of\nevents over time, which is critical for action-driven decision-making.\nAddressing this limitation demands moving beyond conventional deep learning\napproaches. We posit that tackling this challenge requires a neuro-symbolic\nperspective, where video queries are decomposed into atomic events, structured\ninto coherent sequences, and validated against temporal constraints. Such an\napproach can enhance interpretability, enable structured reasoning, and provide\nstronger guarantees on system behavior, all key properties for advancing\ntrustworthy video agents. To this end, we present a grand challenge to the\nresearch community: developing the next generation of intelligent video agents\nthat integrate three core capabilities: (1) autonomous video search and\nanalysis, (2) seamless real-world interaction, and (3) advanced content\ngeneration. By addressing these pillars, we can transition from passive\nperception to intelligent video agents that reason, predict, and act, pushing\nthe boundaries of video understanding.",
      "tldr_zh": "该论文指出了现代视频理解系统在场景分类、物体检测和短视频检索方面表现出色，但缺乏主动的temporal reasoning能力，导致难以处理事件序列和依赖性，从而影响行动决策。作者主张采用neuro-symbolic方法，将视频查询分解为原子事件、构建连贯序列并验证时间约束，以提升系统的可解释性、结构化推理和行为可靠性。为推进这一领域，该论文提出一个重大挑战：开发下一代智能视频代理，整合自主视频搜索和分析、无缝实时世界交互以及高级内容生成的核心能力。通过这些努力，视频理解将从被动感知转向主动推理、预测和行动。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13851v1",
      "published_date": "2025-05-20 02:53:21 UTC",
      "updated_date": "2025-05-20 02:53:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:27:05.090123"
    },
    {
      "arxiv_id": "2505.13847v1",
      "title": "Forensic deepfake audio detection using segmental speech features",
      "title_zh": "翻译失败",
      "authors": [
        "Tianle Yang",
        "Chengzhe Sun",
        "Siwei Lyu",
        "Phil Rose"
      ],
      "abstract": "This study explores the potential of using acoustic features of segmental\nspeech sounds to detect deepfake audio. These features are highly interpretable\nbecause of their close relationship with human articulatory processes and are\nexpected to be more difficult for deepfake models to replicate. The results\ndemonstrate that certain segmental features commonly used in forensic voice\ncomparison are effective in identifying deep-fakes, whereas some global\nfeatures provide little value. These findings underscore the need to approach\naudio deepfake detection differently for forensic voice comparison and offer a\nnew perspective on leveraging segmental features for this purpose.",
      "tldr_zh": "这篇论文探讨了使用分段语音特征（segmental speech features）来检测 deepfake 音频，这些特征因与人类发音过程（human articulatory processes）密切相关而具有高度可解释性，且更难被 deepfake 模型复制。研究结果显示，某些用于法医语音比较（forensic voice comparison）的分段特征在识别 deepfakes 方面有效，而一些全局特征则几乎无价值。这些发现强调了在 forensic voice comparison 中采用不同策略的必要性，并为利用分段特征提供了一个新视角。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13847v1",
      "published_date": "2025-05-20 02:42:46 UTC",
      "updated_date": "2025-05-20 02:42:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:27:17.101122"
    },
    {
      "arxiv_id": "2505.14733v1",
      "title": "The Energy Cost of Reasoning: Analyzing Energy Usage in LLMs with Test-time Compute",
      "title_zh": "翻译失败",
      "authors": [
        "Yunho Jin",
        "Gu-Yeon Wei",
        "David Brooks"
      ],
      "abstract": "Scaling large language models (LLMs) has driven significant advancements, yet\nit faces diminishing returns and escalating energy demands. This work\nintroduces test-time compute (TTC)-allocating additional computational\nresources during inference-as a compelling complement to conventional scaling\nstrategies. Specifically, we investigate whether employing TTC can achieve\nsuperior accuracy-energy trade-offs compared to simply increasing model size.\nOur empirical analysis reveals that TTC surpasses traditional model scaling in\naccuracy/energy efficiency, with notable gains in tasks demanding complex\nreasoning rather than mere factual recall. Further, we identify a critical\ninteraction between TTC performance and output sequence length, demonstrating\nthat strategically adjusting compute resources at inference time according to\nquery complexity can substantially enhance efficiency. Our findings advocate\nfor TTC as a promising direction, enabling more sustainable, accurate, and\nadaptable deployment of future language models without incurring additional\npretraining costs.",
      "tldr_zh": "这篇论文分析了大型语言模型(LLMs)在推理过程中的能量消耗，引入测试时计算(test-time compute, TTC)作为一种在推理阶段分配额外计算资源的策略，以补充传统模型规模扩展。研究发现，TTC 在准确率与能量效率的权衡上优于单纯增加模型大小，尤其在需要复杂推理而非事实回忆的任务中表现出显著优势。进一步，论文揭示了TTC性能与输出序列长度的关键互动，并证明通过根据查询复杂度动态调整计算资源，可以提升整体效率，从而促进更可持续、准确和可适应的LLMs部署，而无需额外预训练成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14733v1",
      "published_date": "2025-05-20 02:35:59 UTC",
      "updated_date": "2025-05-20 02:35:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:27:29.490419"
    },
    {
      "arxiv_id": "2505.13840v1",
      "title": "EfficientLLM: Efficiency in Large Language Models",
      "title_zh": "EfficientLLM：大语言模型中的效率",
      "authors": [
        "Zhengqing Yuan",
        "Weixiang Sun",
        "Yixin Liu",
        "Huichi Zhou",
        "Rong Zhou",
        "Yiyang Li",
        "Zheyuan Zhang",
        "Wei Song",
        "Yue Huang",
        "Haolong Jia",
        "Keerthiram Murugesan",
        "Yu Wang",
        "Lifang He",
        "Jianfeng Gao",
        "Lichao Sun",
        "Yanfang Ye"
      ],
      "abstract": "Large Language Models (LLMs) have driven significant progress, yet their\ngrowing parameter counts and context windows incur prohibitive compute, energy,\nand monetary costs. We introduce EfficientLLM, a novel benchmark and the first\ncomprehensive empirical study evaluating efficiency techniques for LLMs at\nscale. Conducted on a production-class cluster (48xGH200, 8xH200 GPUs), our\nstudy systematically explores three key axes: (1) architecture pretraining\n(efficient attention variants: MQA, GQA, MLA, NSA; sparse Mixture-of-Experts\n(MoE)), (2) fine-tuning (parameter-efficient methods: LoRA, RSLoRA, DoRA), and\n(3) inference (quantization methods: int4, float16). We define six fine-grained\nmetrics (Memory Utilization, Compute Utilization, Latency, Throughput, Energy\nConsumption, Compression Rate) to capture hardware saturation,\nlatency-throughput balance, and carbon cost. Evaluating over 100\nmodel-technique pairs (0.5B-72B parameters), we derive three core insights: (i)\nEfficiency involves quantifiable trade-offs: no single method is universally\noptimal; e.g., MoE reduces FLOPs and improves accuracy but increases VRAM by\n40%, while int4 quantization cuts memory/energy by up to 3.9x at a 3-5%\naccuracy drop. (ii) Optima are task- and scale-dependent: MQA offers optimal\nmemory-latency trade-offs for constrained devices, MLA achieves lowest\nperplexity for quality-critical tasks, and RSLoRA surpasses LoRA efficiency\nonly beyond 14B parameters. (iii) Techniques generalize across modalities: we\nextend evaluations to Large Vision Models (Stable Diffusion 3.5, Wan 2.1) and\nVision-Language Models (Qwen2.5-VL), confirming effective transferability. By\nopen-sourcing datasets, evaluation pipelines, and leaderboards, EfficientLLM\nprovides essential guidance for researchers and engineers navigating the\nefficiency-performance landscape of next-generation foundation models.",
      "tldr_zh": "这篇论文引入了EfficientLLM基准，这是首个全面实证研究，用于评估大型语言模型(LLMs)的效率技术。研究系统探索了架构预训练（如MQA、GQA、MLA、NSA和MoE）、微调（如LoRA、RSLoRA、DoRA）和推理（如int4量化）等三个关键方面，并通过六种指标（Memory Utilization、Compute Utilization、Latency、Throughput、Energy Consumption、Compression Rate）评估超过100个模型-技术对（0.5B-72B参数）。主要发现包括效率技术存在权衡（如MoE减少FLOPs但增加VRAM 40%）、最优解依赖任务和规模（如MQA适合受限设备）、以及这些技术可推广到视觉模型（Stable Diffusion 3.5等），最终通过开源数据集和领导者榜指导未来模型开发。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13840v1",
      "published_date": "2025-05-20 02:27:08 UTC",
      "updated_date": "2025-05-20 02:27:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:27:44.883452"
    },
    {
      "arxiv_id": "2505.13837v1",
      "title": "Enhancing Robot Navigation Policies with Task-Specific Uncertainty Managements",
      "title_zh": "翻译失败",
      "authors": [
        "Gokul Puthumanaillam",
        "Paulo Padrao",
        "Jose Fuentes",
        "Leonardo Bobadilla",
        "Melkior Ornik"
      ],
      "abstract": "Robots navigating complex environments must manage uncertainty from sensor\nnoise, environmental changes, and incomplete information, with different tasks\nrequiring varying levels of precision in different areas. For example, precise\nlocalization may be crucial near obstacles but less critical in open spaces. We\npresent GUIDE (Generalized Uncertainty Integration for Decision-Making and\nExecution), a framework that integrates these task-specific requirements into\nnavigation policies via Task-Specific Uncertainty Maps (TSUMs). By assigning\nacceptable uncertainty levels to different locations, TSUMs enable robots to\nadapt uncertainty management based on context. When combined with reinforcement\nlearning, GUIDE learns policies that balance task completion and uncertainty\nmanagement without extensive reward engineering. Real-world tests show\nsignificant performance gains over methods lacking task-specific uncertainty\nawareness.",
      "tldr_zh": "本文提出 GUIDE 框架，用于增强机器人导航策略，通过 Task-Specific Uncertainty Maps (TSUMs) 整合任务特定的不确定性管理，例如在障碍物附近要求更高精确度，而在开阔空间则相对宽容。TSUMs 为不同位置分配可接受的不确定性水平，使机器人根据环境上下文动态适应不确定性。结合强化学习，GUIDE 能够学习平衡任务完成和不确定性管理的策略，而无需复杂的奖励工程。实世界测试显示，该框架相较于缺乏任务特定不确定性意识的方法，实现了显著性能提升。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13837v1",
      "published_date": "2025-05-20 02:23:15 UTC",
      "updated_date": "2025-05-20 02:23:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:27:54.184997"
    },
    {
      "arxiv_id": "2505.13834v1",
      "title": "Toward Real-World Cooperative and Competitive Soccer with Quadrupedal Robot Teams",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi Su",
        "Yuman Gao",
        "Emily Lukas",
        "Yunfei Li",
        "Jiaze Cai",
        "Faris Tulbah",
        "Fei Gao",
        "Chao Yu",
        "Zhongyu Li",
        "Yi Wu",
        "Koushil Sreenath"
      ],
      "abstract": "Achieving coordinated teamwork among legged robots requires both fine-grained\nlocomotion control and long-horizon strategic decision-making. Robot soccer\noffers a compelling testbed for this challenge, combining dynamic, competitive,\nand multi-agent interactions. In this work, we present a hierarchical\nmulti-agent reinforcement learning (MARL) framework that enables fully\nautonomous and decentralized quadruped robot soccer. First, a set of highly\ndynamic low-level skills is trained for legged locomotion and ball\nmanipulation, such as walking, dribbling, and kicking. On top of these, a\nhigh-level strategic planning policy is trained with Multi-Agent Proximal\nPolicy Optimization (MAPPO) via Fictitious Self-Play (FSP). This learning\nframework allows agents to adapt to diverse opponent strategies and gives rise\nto sophisticated team behaviors, including coordinated passing, interception,\nand dynamic role allocation. With an extensive ablation study, the proposed\nlearning method shows significant advantages in the cooperative and competitive\nmulti-agent soccer game. We deploy the learned policies to real quadruped\nrobots relying solely on onboard proprioception and decentralized localization,\nwith the resulting system supporting autonomous robot-robot and robot-human\nsoccer matches on indoor and outdoor soccer courts.",
      "tldr_zh": "本研究针对四足机器人团队在真实世界足球比赛中的合作和竞争挑战，提出一个分层多智能体强化学习（MARL）框架，支持完全自治和去中心化操作。该框架首先训练低级技能，如行走、带球和踢球，然后通过 Multi-Agent Proximal Policy Optimization (MAPPO) 和 Fictitious Self-Play (FSP) 训练高级战略规划策略，实现代理适应对手并产生复杂团队行为，包括协调传球、拦截和动态角色分配。实验消融研究证明了该方法的显著优势，并成功部署到真实四足机器人上，仅依赖机载本体感知和去中心化定位，支持室内外机器人-机器人及机器人-人类比赛。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "11 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13834v1",
      "published_date": "2025-05-20 02:20:54 UTC",
      "updated_date": "2025-05-20 02:20:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:28:06.938005"
    },
    {
      "arxiv_id": "2505.13831v1",
      "title": "TelePlanNet: An AI-Driven Framework for Efficient Telecom Network Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Zongyuan Deng",
        "Yujie Cai",
        "Qing Liu",
        "Shiyao Mu",
        "Bin Lyu",
        "Zhen Yang"
      ],
      "abstract": "The selection of base station sites is a critical challenge in 5G network\nplanning, which requires efficient optimization of coverage, cost, user\nsatisfaction, and practical constraints. Traditional manual methods, reliant on\nhuman expertise, suffer from inefficiencies and are limited to an unsatisfied\nplanning-construction consistency. Existing AI tools, despite improving\nefficiency in certain aspects, still struggle to meet the dynamic network\nconditions and multi-objective needs of telecom operators' networks. To address\nthese challenges, we propose TelePlanNet, an AI-driven framework tailored for\nthe selection of base station sites, integrating a three-layer architecture for\nefficient planning and large-scale automation. By leveraging large language\nmodels (LLMs) for real-time user input processing and intent alignment with\nbase station planning, combined with training the planning model using the\nimproved group relative policy optimization (GRPO) reinforcement learning, the\nproposed TelePlanNet can effectively address multi-objective optimization,\nevaluates candidate sites, and delivers practical solutions. Experiments\nresults show that the proposed TelePlanNet can improve the consistency to 78%,\nwhich is superior to the manual methods, providing telecom operators with an\nefficient and scalable tool that significantly advances cellular network\nplanning.",
      "tldr_zh": "该论文提出TelePlanNet，一种AI驱动框架，用于解决5G电信网络规划中基站选址的挑战，包括优化覆盖、成本、用户满意度和实际约束。框架采用三层架构，结合大型语言模型(LLMs)处理实时用户输入并与规划意图对齐，以及改进的群组相对策略优化(GRPO)强化学习训练规划模型，以实现多目标优化和大规模自动化。实验结果显示，TelePlanNet将规划与建设一致性提高到78%，显著优于传统手动方法，为电信运营商提供高效、可扩展的网络规划工具。",
      "categories": [
        "cs.AI",
        "I.2; I.2.6; C.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 5 figures, 1 table, submitted to IEEE ICCC 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.13831v1",
      "published_date": "2025-05-20 02:19:10 UTC",
      "updated_date": "2025-05-20 02:19:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:28:16.980035"
    },
    {
      "arxiv_id": "2505.13828v1",
      "title": "Multimodal RAG-driven Anomaly Detection and Classification in Laser Powder Bed Fusion using Large Language Models",
      "title_zh": "多模态 RAG 驱动的激光粉床熔融异常检测和分类，使用大型语言模型",
      "authors": [
        "Kiarash Naghavi Khanghah",
        "Zhiling Chen",
        "Lela Romeo",
        "Qian Yang",
        "Rajiv Malhotra",
        "Farhad Imani",
        "Hongyi Xu"
      ],
      "abstract": "Additive manufacturing enables the fabrication of complex designs while\nminimizing waste, but faces challenges related to defects and process\nanomalies. This study presents a novel multimodal Retrieval-Augmented\nGeneration-based framework that automates anomaly detection across various\nAdditive Manufacturing processes leveraging retrieved information from\nliterature, including images and descriptive text, rather than training\ndatasets. This framework integrates text and image retrieval from scientific\nliterature and multimodal generation models to perform zero-shot anomaly\nidentification, classification, and explanation generation in a Laser Powder\nBed Fusion setting. The proposed framework is evaluated on four L-PBF\nmanufacturing datasets from Oak Ridge National Laboratory, featuring various\nprinter makes, models, and materials. This evaluation demonstrates the\nframework's adaptability and generalizability across diverse images without\nrequiring additional training. Comparative analysis using Qwen2-VL-2B and\nGPT-4o-mini as MLLM within the proposed framework highlights that GPT-4o-mini\noutperforms Qwen2-VL-2B and proportional random baseline in manufacturing\nanomalies classification. Additionally, the evaluation of the RAG system\nconfirms that incorporating retrieval mechanisms improves average accuracy by\n12% by reducing the risk of hallucination and providing additional information.\nThe proposed framework can be continuously updated by integrating emerging\nresearch, allowing seamless adaptation to the evolving landscape of AM\ntechnologies. This scalable, automated, and zero-shot-capable framework\nstreamlines AM anomaly analysis, enhancing efficiency and accuracy.",
      "tldr_zh": "本研究提出了一种基于 Retrieval-Augmented Generation (RAG) 的多模态框架，用于增材制造（Additive Manufacturing）中的异常检测和分类，特别针对 Laser Powder Bed Fusion (L-PBF) 过程，通过从科学文献中检索文本和图像实现零样本（zero-shot）异常识别、分类及解释生成，而非依赖训练数据集。框架整合 Large Language Models (LLMs) 如 GPT-4o-mini 和 Qwen2-VL-2B，在四个 L-PBF 数据集上进行评估，结果显示 GPT-4o-mini 优于 Qwen2-VL-2B，并通过 RAG 机制将平均准确率提升 12%，减少了幻觉风险。相比随机基线，该框架展示了出色的适应性和泛化性，并支持持续更新以适应 AM 技术的演变，从而提升了异常分析的效率和准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ASME 2025 International Design Engineering Technical Conferences and\n  Computers and Information in Engineering Conference IDETC/CIE2025, August\n  17-20, 2025, Anaheim, CA (IDETC2025-168615)",
      "pdf_url": "http://arxiv.org/pdf/2505.13828v1",
      "published_date": "2025-05-20 02:18:22 UTC",
      "updated_date": "2025-05-20 02:18:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:28:30.705165"
    },
    {
      "arxiv_id": "2505.13820v1",
      "title": "Structured Agent Distillation for Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Liu",
        "Zhenglun Kong",
        "Peiyan Dong",
        "Changdi Yang",
        "Tianqi Li",
        "Hao Tang",
        "Geng Yuan",
        "Wei Niu",
        "Wenbin Zhang",
        "Pu Zhao",
        "Xue Lin",
        "Dong Huang",
        "Yanzhi Wang"
      ],
      "abstract": "Large language models (LLMs) exhibit strong capabilities as decision-making\nagents by interleaving reasoning and actions, as seen in ReAct-style\nframeworks. Yet, their practical deployment is constrained by high inference\ncosts and large model sizes. We propose Structured Agent Distillation, a\nframework that compresses large LLM-based agents into smaller student models\nwhile preserving both reasoning fidelity and action consistency. Unlike\nstandard token-level distillation, our method segments trajectories into\n{[REASON]} and {[ACT]} spans, applying segment-specific losses to align each\ncomponent with the teacher's behavior. This structure-aware supervision enables\ncompact agents to better replicate the teacher's decision process. Experiments\non ALFWorld, HotPotQA-ReAct, and WebShop show that our approach consistently\noutperforms token-level and imitation learning baselines, achieving significant\ncompression with minimal performance drop. Scaling and ablation results further\nhighlight the importance of span-level alignment for efficient and deployable\nagents.",
      "tldr_zh": "本研究提出 Structured Agent Distillation 框架，用于将大型语言模型 (LLMs) 代理压缩到更小的学生模型中，解决高推理成本和模型尺寸问题，同时保持推理保真度和行动一致性。该框架将代理轨迹分为 [REASON] 和 [ACT] 段，并应用特定损失函数来对齐每个段的教师行为，从而实现结构化监督。实验在 ALFWorld、HotPotQA-ReAct 和 WebShop 等基准上显示，该方法优于 token-level 蒸馏和模仿学习基线，实现显著模型压缩且性能下降最小。缩放和消融结果进一步证明了 span-level 对齐在构建高效部署代理中的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13820v1",
      "published_date": "2025-05-20 02:01:55 UTC",
      "updated_date": "2025-05-20 02:01:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:28:41.899423"
    },
    {
      "arxiv_id": "2505.13814v1",
      "title": "Articulatory Feature Prediction from Surface EMG during Speech Production",
      "title_zh": "翻译失败",
      "authors": [
        "Jihwan Lee",
        "Kevin Huang",
        "Kleanthis Avramidis",
        "Simon Pistrosch",
        "Monica Gonzalez-Machorro",
        "Yoonjeong Lee",
        "Björn Schuller",
        "Louis Goldstein",
        "Shrikanth Narayanan"
      ],
      "abstract": "We present a model for predicting articulatory features from surface\nelectromyography (EMG) signals during speech production. The proposed model\nintegrates convolutional layers and a Transformer block, followed by separate\npredictors for articulatory features. Our approach achieves a high prediction\ncorrelation of approximately 0.9 for most articulatory features. Furthermore,\nwe demonstrate that these predicted articulatory features can be decoded into\nintelligible speech waveforms. To our knowledge, this is the first method to\ndecode speech waveforms from surface EMG via articulatory features, offering a\nnovel approach to EMG-based speech synthesis. Additionally, we analyze the\nrelationship between EMG electrode placement and articulatory feature\npredictability, providing knowledge-driven insights for optimizing EMG\nelectrode configurations. The source code and decoded speech samples are\npublicly available.",
      "tldr_zh": "这篇论文提出了一种模型，用于从表面肌电图 (surface EMG) 信号预测发音特征 (articulatory features) 过程，该模型整合了卷积层 (convolutional layers) 和 Transformer 块，并使用单独的预测器进行特征预测。实验结果显示，该方法对大多数发音特征的预测相关性高达约 0.9，并且这些预测特征可进一步解码成可理解的语音波形 (intelligible speech waveforms)。这是首个通过 articulatory features 从 surface EMG 实现语音解码的方法，同时论文分析了 EMG 电极放置与特征可预测性的关系，提供优化电极配置的见解。源代码和解码语音样本已公开可用。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted for Interspeech2025",
      "pdf_url": "http://arxiv.org/pdf/2505.13814v1",
      "published_date": "2025-05-20 01:50:05 UTC",
      "updated_date": "2025-05-20 01:50:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:28:54.194032"
    },
    {
      "arxiv_id": "2505.13808v1",
      "title": "RAG/LLM Augmented Switching Driven Polymorphic Metaheuristic Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Faramarz Safi Esfahani",
        "Ghassan Beydoun",
        "Morteza Saberi",
        "Brad McCusker",
        "Biswajeet Pradhan"
      ],
      "abstract": "Metaheuristic algorithms are widely used for solving complex optimization\nproblems, yet their effectiveness is often constrained by fixed structures and\nthe need for extensive tuning. The Polymorphic Metaheuristic Framework (PMF)\naddresses this limitation by introducing a self-adaptive metaheuristic\nswitching mechanism driven by real-time performance feedback and dynamic\nalgorithmic selection. PMF leverages the Polymorphic Metaheuristic Agent (PMA)\nand the Polymorphic Metaheuristic Selection Agent (PMSA) to dynamically select\nand transition between metaheuristic algorithms based on key performance\nindicators, ensuring continuous adaptation. This approach enhances convergence\nspeed, adaptability, and solution quality, outperforming traditional\nmetaheuristics in high-dimensional, dynamic, and multimodal environments.\nExperimental results on benchmark functions demonstrate that PMF significantly\nimproves optimization efficiency by mitigating stagnation and balancing\nexploration-exploitation strategies across various problem landscapes. By\nintegrating AI-driven decision-making and self-correcting mechanisms, PMF paves\nthe way for scalable, intelligent, and autonomous optimization frameworks, with\npromising applications in engineering, logistics, and complex decision-making\nsystems.",
      "tldr_zh": "该论文提出了一种 RAG/LLM Augmented Switching Driven Polymorphic Metaheuristic Framework (PMF)，旨在解决传统元启发式算法的固定结构和调优需求问题，通过自适应机制实现动态算法切换。PMF 利用 Polymorphic Metaheuristic Agent (PMA) 和 Polymorphic Metaheuristic Selection Agent (PMSA) 基于实时性能反馈进行算法选择，确保提高收敛速度、适应性和解决方案质量。实验在基准函数上证明，PMF 在高维、动态和多模态环境中比传统方法提升优化效率，缓解停滞并平衡探索-利用策略，具有广泛应用潜力于工程、物流和复杂决策系统。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13808v1",
      "published_date": "2025-05-20 01:41:22 UTC",
      "updated_date": "2025-05-20 01:41:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:29:08.818980"
    },
    {
      "arxiv_id": "2505.13805v1",
      "title": "ClapFM-EVC: High-Fidelity and Flexible Emotional Voice Conversion with Dual Control from Natural Language and Speech",
      "title_zh": "ClapFM-EVC：利用自然语言和语音双重控制的高保真灵活情感语音转换",
      "authors": [
        "Yu Pan",
        "Yanni Hu",
        "Yuguang Yang",
        "Jixun Yao",
        "Jianhao Ye",
        "Hongbin Zhou",
        "Lei Ma",
        "Jianjun Zhao"
      ],
      "abstract": "Despite great advances, achieving high-fidelity emotional voice conversion\n(EVC) with flexible and interpretable control remains challenging. This paper\nintroduces ClapFM-EVC, a novel EVC framework capable of generating high-quality\nconverted speech driven by natural language prompts or reference speech with\nadjustable emotion intensity. We first propose EVC-CLAP, an emotional\ncontrastive language-audio pre-training model, guided by natural language\nprompts and categorical labels, to extract and align fine-grained emotional\nelements across speech and text modalities. Then, a FuEncoder with an adaptive\nintensity gate is presented to seamless fuse emotional features with Phonetic\nPosteriorGrams from a pre-trained ASR model. To further improve emotion\nexpressiveness and speech naturalness, we propose a flow matching model\nconditioned on these captured features to reconstruct Mel-spectrogram of source\nspeech. Subjective and objective evaluations validate the effectiveness of\nClapFM-EVC.",
      "tldr_zh": "本论文提出 ClapFM-EVC 框架，实现高保真情感语音转换 (EVC)，通过自然语言提示或参考语音实现双重控制，并支持调整情感强度。\n框架的核心方法包括 EVC-CLAP 模型，用于从语言提示和类别标签中提取并对齐语音和文本的细粒度情感元素；FuEncoder 结合自适应强度门控，将这些情感特征与预训练 ASR 模型的 Phonetic PosteriorGrams 融合；以及基于这些特征的流匹配模型，用于重建源语音的 Mel-spectrogram 以提升情感表达和语音自然度。\n主观和客观评估结果验证了 ClapFM-EVC 的有效性，在情感控制和语音质量方面表现出色。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by InterSpeech 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.13805v1",
      "published_date": "2025-05-20 01:34:29 UTC",
      "updated_date": "2025-05-20 01:34:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:29:18.889935"
    },
    {
      "arxiv_id": "2505.14728v1",
      "title": "MORALISE: A Structured Benchmark for Moral Alignment in Visual Language Models",
      "title_zh": "MORALISE：视觉语言模型道德对齐的结构化基准",
      "authors": [
        "Xiao Lin",
        "Zhining Liu",
        "Ze Yang",
        "Gaotang Li",
        "Ruizhong Qiu",
        "Shuke Wang",
        "Hui Liu",
        "Haotian Li",
        "Sumit Keswani",
        "Vishwa Pardeshi",
        "Huijun Zhao",
        "Wei Fan",
        "Hanghang Tong"
      ],
      "abstract": "Warning: This paper contains examples of harmful language and images. Reader\ndiscretion is advised. Recently, vision-language models have demonstrated\nincreasing influence in morally sensitive domains such as autonomous driving\nand medical analysis, owing to their powerful multimodal reasoning\ncapabilities. As these models are deployed in high-stakes real-world\napplications, it is of paramount importance to ensure that their outputs align\nwith human moral values and remain within moral boundaries. However, existing\nwork on moral alignment either focuses solely on textual modalities or relies\nheavily on AI-generated images, leading to distributional biases and reduced\nrealism. To overcome these limitations, we introduce MORALISE, a comprehensive\nbenchmark for evaluating the moral alignment of vision-language models (VLMs)\nusing diverse, expert-verified real-world data. We begin by proposing a\ncomprehensive taxonomy of 13 moral topics grounded in Turiel's Domain Theory,\nspanning the personal, interpersonal, and societal moral domains encountered in\neveryday life. Built on this framework, we manually curate 2,481 high-quality\nimage-text pairs, each annotated with two fine-grained labels: (1) topic\nannotation, identifying the violated moral topic(s), and (2) modality\nannotation, indicating whether the violation arises from the image or the text.\nFor evaluation, we encompass two tasks, \\textit{moral judgment} and\n\\textit{moral norm attribution}, to assess models' awareness of moral\nviolations and their reasoning ability on morally salient content. Extensive\nexperiments on 19 popular open- and closed-source VLMs show that MORALISE poses\na significant challenge, revealing persistent moral limitations in current\nstate-of-the-art models. The full benchmark is publicly available at\nhttps://huggingface.co/datasets/Ze1025/MORALISE.",
      "tldr_zh": "本研究引入了MORALISE，一种结构化的基准，用于评估视觉语言模型(VLMs)在道德对齐方面的性能，旨在解决现有方法在文本模态偏重或AI生成图像导致的偏差问题。基于Turiel's Domain Theory，该基准构建了一个涵盖13个道德主题的分类体系，包括个人、社交和社会领域，并手动整理了2,481对高质量的真实图像-文本数据，每对标注了违反道德主题和模态来源。评估任务包括moral judgment（道德判断）和moral norm attribution（道德规范归因），用于测试模型对道德违规的感知和推理能力。在19个流行VLMs上的实验显示，这些模型在MORALISE基准中面临显著挑战，暴露了其持久的道德限制。该基准已公开可用，可进一步推动VLMs的道德改进。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages, 11 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.14728v1",
      "published_date": "2025-05-20 01:11:17 UTC",
      "updated_date": "2025-05-20 01:11:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:29:30.305300"
    },
    {
      "arxiv_id": "2505.13794v1",
      "title": "LLM-based Evaluation Policy Extraction for Ecological Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Cheng",
        "Licheng Liu",
        "Qing Zhu",
        "Runlong Yu",
        "Zhenong Jin",
        "Yiqun Xie",
        "Xiaowei Jia"
      ],
      "abstract": "Evaluating ecological time series is critical for benchmarking model\nperformance in many important applications, including predicting greenhouse gas\nfluxes, capturing carbon-nitrogen dynamics, and monitoring hydrological cycles.\nTraditional numerical metrics (e.g., R-squared, root mean square error) have\nbeen widely used to quantify the similarity between modeled and observed\necosystem variables, but they often fail to capture domain-specific temporal\npatterns critical to ecological processes. As a result, these methods are often\naccompanied by expert visual inspection, which requires substantial human labor\nand limits the applicability to large-scale evaluation. To address these\nchallenges, we propose a novel framework that integrates metric learning with\nlarge language model (LLM)-based natural language policy extraction to develop\ninterpretable evaluation criteria. The proposed method processes pairwise\nannotations and implements a policy optimization mechanism to generate and\ncombine different assessment metrics. The results obtained on multiple datasets\nfor evaluating the predictions of crop gross primary production and carbon\ndioxide flux have confirmed the effectiveness of the proposed method in\ncapturing target assessment preferences, including both synthetically generated\nand expert-annotated model comparisons. The proposed framework bridges the gap\nbetween numerical metrics and expert knowledge while providing interpretable\nevaluation policies that accommodate the diverse needs of different ecosystem\nmodeling studies.",
      "tldr_zh": "本研究针对生态时间序列评估的挑战，指出传统数值指标（如 R-squared 和根均方误差）难以捕捉领域特定时间模式，导致依赖专家视觉检查。该框架整合 metric learning 与 LLM-based natural language policy extraction，通过处理成对注释和政策优化机制，生成可解释的评估指标组合。实验结果显示，该方法在作物总初级生产和二氧化碳通量预测等数据集上有效捕捉目标评估偏好，提升了模型比较的准确性和适用性。该框架桥接了数值指标与专家知识，适应生态建模研究的多样需求。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13794v1",
      "published_date": "2025-05-20 01:02:29 UTC",
      "updated_date": "2025-05-20 01:02:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:29:41.910387"
    },
    {
      "arxiv_id": "2505.13792v1",
      "title": "Interpretable Traces, Unexpected Outcomes: Investigating the Disconnect in Trace-Based Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Siddhant Bhambri",
        "Upasana Biswas",
        "Subbarao Kambhampati"
      ],
      "abstract": "Question Answering (QA) poses a challenging and critical problem,\nparticularly in today's age of interactive dialogue systems such as ChatGPT,\nPerplexity, Microsoft Copilot, etc. where users demand both accuracy and\ntransparency in the model's outputs. Since smaller language models (SLMs) are\ncomputationally more efficient but often under-perform compared to larger\nmodels, Knowledge Distillation (KD) methods allow for finetuning these smaller\nmodels to improve their final performance. Lately, the intermediate tokens or\nthe so called `reasoning' traces produced by Chain-of-Thought (CoT) or by\nreasoning models such as DeepSeek R1 are used as a training signal for KD.\nHowever, these reasoning traces are often verbose and difficult to interpret or\nevaluate. In this work, we aim to address the challenge of evaluating the\nfaithfulness of these reasoning traces and their correlation with the final\nperformance. To this end, we employ a KD method leveraging rule-based problem\ndecomposition. This approach allows us to break down complex queries into\nstructured sub-problems, generating interpretable traces whose correctness can\nbe readily evaluated, even at inference time. Specifically, we demonstrate this\napproach on Open Book QA, decomposing the problem into a Classification step\nand an Information Retrieval step, thereby simplifying trace evaluation. Our\nSFT experiments with correct and incorrect traces on the CoTemp QA, Microsoft\nMachine Reading Comprehension QA, and Facebook bAbI QA datasets reveal the\nstriking finding that correct traces do not necessarily imply that the model\noutputs the correct final solution. Similarly, we find a low correlation\nbetween correct final solutions and intermediate trace correctness. These\nresults challenge the implicit assumption behind utilizing reasoning traces for\nimproving SLMs' final performance via KD.",
      "tldr_zh": "这篇论文探讨了基于推理 traces 的 Knowledge Distillation (KD) 方法在 Question Answering (QA) 任务中的脱节问题，特别是 traces 的可解释性和与最终性能的相关性。作者提出了一种规则-based problem decomposition 策略，将复杂查询分解成结构化的子问题（如 Classification 和 Information Retrieval 步骤），以生成易于评估的 traces，并在 Open Book QA 等数据集上进行实验。研究发现，即使 traces 正确，也不一定保证模型输出正确的最终解决方案，且 traces 正确性与最终性能的相关性较低。这些结果挑战了利用 Chain-of-Thought (CoT) 或类似方法提升小型语言模型 (SLMs) 性能的隐含假设。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.13792v1",
      "published_date": "2025-05-20 00:49:19 UTC",
      "updated_date": "2025-05-20 00:49:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:29:55.294666"
    },
    {
      "arxiv_id": "2505.14726v1",
      "title": "MedBLIP: Fine-tuning BLIP for Medical Image Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Manshi Limbu",
        "Diwita Banerjee"
      ],
      "abstract": "Medical image captioning is a challenging task that requires generating\nclinically accurate and semantically meaningful descriptions of radiology\nimages. While recent vision-language models (VLMs) such as BLIP, BLIP2, Gemini\nand ViT-GPT2 show strong performance on natural image datasets, they often\nproduce generic or imprecise captions when applied to specialized medical\ndomains. In this project, we explore the effectiveness of fine-tuning the BLIP\nmodel on the ROCO dataset for improved radiology captioning. We compare the\nfine-tuned BLIP against its zero-shot version, BLIP-2 base, BLIP-2 Instruct and\na ViT-GPT2 transformer baseline. Our results demonstrate that domain-specific\nfine-tuning on BLIP significantly improves performance across both quantitative\nand qualitative evaluation metrics. We also visualize decoder cross-attention\nmaps to assess interpretability and conduct an ablation study to evaluate the\ncontributions of encoder-only and decoder-only fine-tuning. Our findings\nhighlight the importance of targeted adaptation for medical applications and\nsuggest that decoder-only fine-tuning (encoder-frozen) offers a strong\nperformance baseline with 5% lower training time than full fine-tuning, while\nfull model fine-tuning still yields the best results overall.",
      "tldr_zh": "本研究探讨了针对医疗图像描述（Medical image captioning）的MedBLIP模型，通过在ROCO数据集上微调（fine-tuning）BLIP模型来生成更准确的放射学图像描述。相比零样本版本、BLIP-2 base、BLIP-2 Instruct和ViT-GPT2基线，领域特定的微调显著提升了BLIP在定量和定性评估指标上的性能。研究还通过可视化解码器交叉注意力图（decoder cross-attention maps）和消融研究（ablation study）发现，解码器-only微调（encoder-frozen）提供高效基准，训练时间降低5%，而全模型微调则取得整体最佳结果，这突显了针对医疗应用的适应性重要性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14726v1",
      "published_date": "2025-05-20 00:49:08 UTC",
      "updated_date": "2025-05-20 00:49:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:30:07.170143"
    },
    {
      "arxiv_id": "2505.13787v1",
      "title": "Preference Learning with Lie Detectors can Induce Honesty or Evasion",
      "title_zh": "带有谎言检测器的偏好学习可以诱导诚实或规避行为",
      "authors": [
        "Chris Cundy",
        "Adam Gleave"
      ],
      "abstract": "As AI systems become more capable, deceptive behaviors can undermine\nevaluation and mislead users at deployment. Recent work has shown that lie\ndetectors can accurately classify deceptive behavior, but they are not\ntypically used in the training pipeline due to concerns around contamination\nand objective hacking. We examine these concerns by incorporating a lie\ndetector into the labelling step of LLM post-training and evaluating whether\nthe learned policy is genuinely more honest, or instead learns to fool the lie\ndetector while remaining deceptive. Using DolusChat, a novel 65k-example\ndataset with paired truthful/deceptive responses, we identify three key factors\nthat determine the honesty of learned policies: amount of exploration during\npreference learning, lie detector accuracy, and KL regularization strength. We\nfind that preference learning with lie detectors and GRPO can lead to policies\nwhich evade lie detectors, with deception rates of over 85\\%. However, if the\nlie detector true positive rate (TPR) or KL regularization is sufficiently\nhigh, GRPO learns honest policies. In contrast, off-policy algorithms (DPO)\nconsistently lead to deception rates under 25\\% for realistic TPRs. Our results\nillustrate a more complex picture than previously assumed: depending on the\ncontext, lie-detector-enhanced training can be a powerful tool for scalable\noversight, or a counterproductive method encouraging undetectable misalignment.",
      "tldr_zh": "这篇论文探讨了在大型语言模型（LLM）后训练中使用 Lie Detectors 进行偏好学习，是否能提升模型的诚实性，或反而导致其学会规避检测器。研究者利用新数据集 DolusChat（包含65k对真诚/欺骗性响应）来分析关键因素，包括偏好学习中的探索量、Lie Detector 的真阳性率（TPR）和KL正则化强度。结果显示，GRPO算法在TPR或KL正则化强度足够高时能学习诚实策略，但否则可能导致欺骗率超过85%。相比之下，DPO算法在现实TPR条件下保持欺骗率低于25%。这些发现揭示了Lie-Detector-Enhanced训练的双重性：它可能成为可扩展监督的强大工具，也可能适得其反，鼓励不可检测的失调。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13787v1",
      "published_date": "2025-05-20 00:31:53 UTC",
      "updated_date": "2025-05-20 00:31:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:30:20.589380"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 220,
  "processed_papers_count": 220,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-25T02:30:47.675292"
}