{
  "date": "2024-10-18",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-18 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的安全性、优化和应用，尤其是大型语言模型 (LLM) 在数学推理、视觉任务和强化学习中的进展，令人印象深刻的包括 Yoshua Bengio 关于组合性理论的贡献，以及 LLM 的提示注入攻击和多模态生成研究；这些论文突显了 AI 领域在鲁棒性和泛化能力上的探索。\n\n以下是今日论文的精选摘要，我优先选取了重要、话题性和影响力高的文章（如涉及著名学者或热门主题的），并将相关论文归类讨论。其他次要文章（如纯技术优化或实验性工作）将快速掠过，只简要列出标题。\n\n### LLM 安全与优化（重点主题，影响力高）\n- **提示注入攻击的增强：通过中和对齐的投毒** (Enhancing Prompt Injection Attacks to LLMs via Poisoning Alignment)  \n  作者：Zedian Shao 等。论文提出 PoisonedAlign 方法，通过投毒对齐数据来放大 LLM 的提示注入攻击，显著提高了攻击成功率，同时保持模型基础能力；这揭示了 LLM 安全漏洞的潜在风险，强调了对齐机制的改进。\n\n- **基于信息导向采样的 AI 代理对齐** (Aligning AI Agents via Information-Directed Sampling)  \n  作者：Hong Jun Jeon 和 Benjamin Van Roy。论文开发了一种信息导向采样算法，用于在带有人类反馈的环境中对齐 AI 代理，实现了长效奖励最大化和探索-利用权衡；这为 AI 安全和强化学习提供了高效框架。\n\n- **提升 LLM 指令跟随的置信度推理** (To Trust or Not to Trust? Enhancing Large Language Models' Situated Faithfulness to External Contexts)  \n  作者：Yukun Huang 等。论文引入自引导和规则-based 推理方法，帮助 LLM 在知识冲突时动态评估外部信息置信度，提高了指令跟随的鲁棒性；实验显示在多数据集上提升了 24.2% 的准确率。\n\n- **LLM 的说服平衡训练** (Teaching Models to Balance Resisting and Accepting Persuasion)  \n  作者：Elias Stengel-Eskin 等。论文提出 Persuasion-Training 框架，使用多代理对话树训练 LLM 平衡积极/消极说服，提高了抗误导能力和团队协作表现；这为 LLM 在辩论和决策中的应用提供了新视角。\n\n- **LLM 在指令跟随中的内部知识评估** (Do LLMs \"know\" internally when they follow instructions?)  \n  作者：Juyeon Heo 等。论文发现 LLM 的嵌入空间中存在“指令跟随维度”，用于预测响应准确性，并通过微调提升了性能；这加深了对 LLM 内部机制的理解。\n\n其他 LLM 相关论文（如第 13、14、26、35、52、73、102、105、108、109、115、118）探讨了提示优化和生成多样性，但多数为实验性工作，快速掠过：它们主要贡献了 LLM 在特定任务（如情感分析或代码生成）的细化方法。\n\n### 多模态和视觉模型（热门应用，技术创新强）\n- **视觉语言模型的混合防御策略** (A Hybrid Defense Strategy for Boosting Adversarial Robustness in Vision-Language Models)  \n  作者：Yuhan Liang 等。论文提出集成多种攻击策略的对抗训练框架，提升了 VLMs 如 CLIP 的鲁棒性，实验在 CIFAR-10/100 上将准确率从 4% 提高到 43.5%；这对安全关键应用（如自动驾驶）有重要启示。\n\n- **截断一致性模型** (Truncated Consistency Models)  \n  作者：Sangyun Lee 等。论文优化了扩散模型的训练，聚焦后期时间步以提高生成质量，在 CIFAR-10 和 ImageNet 上实现了更小网络的 SOTA FID 分数；这推动了高效图像生成的进展。\n\n- **基于检索增强的生成框架** (Class-RAG: Real-Time Content Moderation with Retrieval Augmented Generation)  \n  作者：Jianfa Chen 等。论文开发了 Class-RAG 框架，通过动态检索库增强 LLM 的内容审核能力，显著提高了分类准确性和对抗鲁棒性；实验显示性能随检索库规模线性提升。\n\n其他视觉论文（如第 4、9、22、28、57、74、77、87、104）涉及图像生成和多模态理解，但许多为特定应用，快速提及：它们贡献了如纹理保持和生成多样性的技术改进。\n\n### 强化学习与决策优化（理论与实践结合）\n- **在线强化学习中的被动记忆** (Online Reinforcement Learning with Passive Memory)  \n  作者：Anay Pattanaik 和 Lav R. Varshney。论文提出使用预收集数据提升在线 RL 的性能，证明了近似最优遗憾界；这为资源受限环境提供了高效策略。\n\n- **分布式强化学习框架** (DistRL: An Asynchronous Distributed Reinforcement Learning Framework for On-Device Control Agents)  \n  作者：Taiyi Wang 等。论文设计了异步分布式 RL 框架，优化了设备控制代理的训练效率，实验显示成功率提升 20%；这适用于移动设备上的实时任务。\n\n其他 RL 论文（如第 6、17、18、33、41、55、63、66、70、95、99、103、110、111、121）探讨了策略优化，但多数为方法改进，快速掠过：它们强调了 RL 在游戏和机器人中的应用潜力。\n\n### 其他领域（快速掠过，选几个有代表性）\n- **组合性的复杂性理论** (A Complexity-Based Theory of Compositionality)  \n  作者：Eric Elmoznino 等，包括著名学者 Yoshua Bengio。论文定义了表示组合性的量化框架，基于算法信息理论，实验验证了其在 AI 和认知科学中的统一性；这为智能系统的泛化提供了理论基础。\n\n- **基于生成模型的二进制潜在代码** (BiGR: Harnessing Binary Latent Codes for Image Generation and Improved Visual Representation Capabilities)  \n  作者：Shaozhe Hao 等。论文提出 BiGR 框架，使用二进制代码提升图像生成和表示能力，实验显示在生成任务上超越了 SOTA；这扩展了视觉 AI 的应用。\n\n剩余论文（如第 7、15、16、19、20、23、24、27、29、30、31、32、34、36、37、38、39、40、42、43、44、45、46、47、48、49、50、51、53、54、58、59、60、61、62、64、65、67、68、69、71、72、75、76、78、79、80、81、82、83、84、85、86、88、89、90、91、92、93、94、96、97、98、100、101、106、107、112、113、114、116、117、119、120）涉及网络安全、生成模型和数据分析等，但内容较零散或实验导向，仅列出标题不详述：它们主要贡献了如生成数据和网络拓扑的细化方法。\n\n总之，今天的论文突出了 AI 的安全和泛化挑战，LLM 相关工作尤为值得关注。如果你对特定领域感兴趣，建议查看这些核心论文的完整摘要！",
  "papers": [
    {
      "arxiv_id": "2410.14911v1",
      "title": "A Hybrid Defense Strategy for Boosting Adversarial Robustness in Vision-Language Models",
      "title_zh": "一种用于提升视觉语言模型对抗鲁棒性的混合防御策略",
      "authors": [
        "Yuhan Liang",
        "Yijun Li",
        "Yumeng Niu",
        "Qianhe Shen",
        "Hangyu Liu"
      ],
      "abstract": "The robustness of Vision-Language Models (VLMs) such as CLIP is critical for\ntheir deployment in safety-critical applications like autonomous driving,\nhealthcare diagnostics, and security systems, where accurate interpretation of\nvisual and textual data is essential. However, these models are highly\nsusceptible to adversarial attacks, which can severely compromise their\nperformance and reliability in real-world scenarios. Previous methods have\nprimarily focused on improving robustness through adversarial training and\ngenerating adversarial examples using models like FGSM, AutoAttack, and\nDeepFool. However, these approaches often rely on strong assumptions, such as\nfixed perturbation norms or predefined attack patterns, and involve high\ncomputational complexity, making them challenging to implement in practical\nsettings. In this paper, we propose a novel adversarial training framework that\nintegrates multiple attack strategies and advanced machine learning techniques\nto significantly enhance the robustness of VLMs against a broad range of\nadversarial attacks. Experiments conducted on real-world datasets, including\nCIFAR-10 and CIFAR-100, demonstrate that the proposed method significantly\nenhances model robustness. The fine-tuned CLIP model achieved an accuracy of\n43.5% on adversarially perturbed images, compared to only 4% for the baseline\nmodel. The neural network model achieved a high accuracy of 98% in these\nchallenging classification tasks, while the XGBoost model reached a success\nrate of 85.26% in prediction tasks.",
      "tldr_zh": "这篇论文针对 Vision-Language Models (VLMs) 如 CLIP 在安全关键应用中的对抗鲁棒性问题，提出了一种新型混合防御策略，以应对各种对抗攻击。策略通过整合多种攻击方法（如 FGSM、AutoAttack 和 DeepFool）以及高级机器学习技术，构建一个高效的对抗训练框架，减少了对强假设和计算复杂度的依赖。实验结果显示，在 CIFAR-10 和 CIFAR-100 数据集上，该框架使 CLIP 模型在对抗扰动图像上的准确率从基线的 4% 提升至 43.5%，神经网络模型达到 98% 准确率，而 XGBoost 模型的预测成功率达 85.26%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14911v1",
      "published_date": "2024-10-18 23:47:46 UTC",
      "updated_date": "2024-10-18 23:47:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:14:39.785915"
    },
    {
      "arxiv_id": "2411.00796v1",
      "title": "Sentiment Analysis Based on RoBERTa for Amazon Review: An Empirical Study on Decision Making",
      "title_zh": "基于 RoBERTa 的 Amazon 评论情感分析：一项关于决策的实证研究",
      "authors": [
        "Xinli Guo"
      ],
      "abstract": "In this study, we leverage state-of-the-art Natural Language Processing (NLP)\ntechniques to perform sentiment analysis on Amazon product reviews. By\nemploying transformer-based models, RoBERTa, we analyze a vast dataset to\nderive sentiment scores that accurately reflect the emotional tones of the\nreviews. We provide an in-depth explanation of the underlying principles of\nthese models and evaluate their performance in generating sentiment scores.\nFurther, we conduct comprehensive data analysis and visualization to identify\npatterns and trends in sentiment scores, examining their alignment with\nbehavioral economics principles such as electronic word of mouth (eWOM),\nconsumer emotional reactions, and the confirmation bias. Our findings\ndemonstrate the efficacy of advanced NLP models in sentiment analysis and offer\nvaluable insights into consumer behavior, with implications for strategic\ndecision-making and marketing practices.",
      "tldr_zh": "本研究利用先进的 NLP 技术，特别是 RoBERTa 模型，对 Amazon 产品评论进行情感分析，以生成准确反映评论情感基调的情感分数。研究详细解释了模型原理，并通过数据分析和可视化识别情感模式和趋势，将其与行为经济学原则如 eWOM（电子口碑）、消费者情感反应和确认偏差相联系。结果表明，RoBERTa 在情感分析中表现出色，提供宝贵的消费者行为洞见，并为战略决策和营销实践带来实际启示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "Master's thesis",
      "pdf_url": "http://arxiv.org/pdf/2411.00796v1",
      "published_date": "2024-10-18 22:46:27 UTC",
      "updated_date": "2024-10-18 22:46:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:14:51.066875"
    },
    {
      "arxiv_id": "2410.14897v1",
      "title": "From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items",
      "title_zh": "翻译失败",
      "authors": [
        "Melissa Roemmele",
        "Andrew S. Gordon"
      ],
      "abstract": "LLMs can now perform a variety of complex writing tasks. They also excel in\nanswering questions pertaining to natural language inference and commonsense\nreasoning. Composing these questions is itself a skilled writing task, so in\nthis paper we consider LLMs as authors of commonsense assessment items. We\nprompt LLMs to generate items in the style of a prominent benchmark for\ncommonsense reasoning, the Choice of Plausible Alternatives (COPA). We examine\nthe outcome according to analyses facilitated by the LLMs and human annotation.\nWe find that LLMs that succeed in answering the original COPA benchmark are\nalso more successful in authoring their own items.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)从回答测试到创建测试的转变，特别考察了 LLMs 在生成常识推理评估项目方面的能力。研究者通过提示工程，让 LLMs 以 Choice of Plausible Alternatives (COPA) 基准的风格创建项目，并结合 LLMs 分析和人类注解进行评估。结果表明，在原 COPA 测试中表现突出的 LLMs，也更擅长制作高质量的评估项目。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at Findings of EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.14897v1",
      "published_date": "2024-10-18 22:42:23 UTC",
      "updated_date": "2024-10-18 22:42:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:15:02.985672"
    },
    {
      "arxiv_id": "2410.14895v2",
      "title": "Truncated Consistency Models",
      "title_zh": "截断一致性模型",
      "authors": [
        "Sangyun Lee",
        "Yilun Xu",
        "Tomas Geffner",
        "Giulia Fanti",
        "Karsten Kreis",
        "Arash Vahdat",
        "Weili Nie"
      ],
      "abstract": "Consistency models have recently been introduced to accelerate sampling from\ndiffusion models by directly predicting the solution (i.e., data) of the\nprobability flow ODE (PF ODE) from initial noise. However, the training of\nconsistency models requires learning to map all intermediate points along PF\nODE trajectories to their corresponding endpoints. This task is much more\nchallenging than the ultimate objective of one-step generation, which only\nconcerns the PF ODE's noise-to-data mapping. We empirically find that this\ntraining paradigm limits the one-step generation performance of consistency\nmodels. To address this issue, we generalize consistency training to the\ntruncated time range, which allows the model to ignore denoising tasks at\nearlier time steps and focus its capacity on generation. We propose a new\nparameterization of the consistency function and a two-stage training procedure\nthat prevents the truncated-time training from collapsing to a trivial\nsolution. Experiments on CIFAR-10 and ImageNet $64\\times64$ datasets show that\nour method achieves better one-step and two-step FIDs than the state-of-the-art\nconsistency models such as iCT-deep, using more than 2$\\times$ smaller\nnetworks. Project page: https://truncated-cm.github.io/",
      "tldr_zh": "本论文提出 Truncated Consistency Models，以解决传统 Consistency Models 在训练时需映射 PF ODE 轨迹所有中间点的问题，导致一步生成性能受限。该方法将 Consistency Training 推广到截断时间范围，让模型专注于生成阶段，并引入新参数化和两阶段训练过程，以避免训练崩溃。实验结果显示，在 CIFAR-10 和 ImageNet 64×64 数据集上，该模型比最先进模型如 iCT-deep 实现了更好的一步和两步 FID 性能，同时使用超过 2 倍小的网络。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.14895v2",
      "published_date": "2024-10-18 22:38:08 UTC",
      "updated_date": "2025-01-23 18:56:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:15:14.915609"
    },
    {
      "arxiv_id": "2410.14894v2",
      "title": "Soft-Label Integration for Robust Toxicity Classification",
      "title_zh": "软标签集成用于鲁棒毒性分类",
      "authors": [
        "Zelei Cheng",
        "Xian Wu",
        "Jiahao Yu",
        "Shuo Han",
        "Xin-Qiang Cai",
        "Xinyu Xing"
      ],
      "abstract": "Toxicity classification in textual content remains a significant problem.\nData with labels from a single annotator fall short of capturing the diversity\nof human perspectives. Therefore, there is a growing need to incorporate\ncrowdsourced annotations for training an effective toxicity classifier.\nAdditionally, the standard approach to training a classifier using empirical\nrisk minimization (ERM) may fail to address the potential shifts between the\ntraining set and testing set due to exploiting spurious correlations. This work\nintroduces a novel bi-level optimization framework that integrates crowdsourced\nannotations with the soft-labeling technique and optimizes the soft-label\nweights by Group Distributionally Robust Optimization (GroupDRO) to enhance the\nrobustness against out-of-distribution (OOD) risk. We theoretically prove the\nconvergence of our bi-level optimization algorithm. Experimental results\ndemonstrate that our approach outperforms existing baseline methods in terms of\nboth average and worst-group accuracy, confirming its effectiveness in\nleveraging crowdsourced annotations to achieve more effective and robust\ntoxicity classification.",
      "tldr_zh": "该研究针对文本毒性分类问题，指出单一标注者标签无法捕捉人类视角多样性，且标准经验风险最小化 (ERM) 方法易受训练测试集偏移影响。作者提出一个新颖的双层优化框架，将众包标注与软标签技术整合，并通过 Group Distributionally Robust Optimization (GroupDRO) 优化软标签权重，以提升对分布外 (OOD) 风险的鲁棒性。该框架的收敛性得到理论证明，实验结果显示其在平均和最差组准确率上均优于现有基线方法，从而实现更有效和稳健的毒性分类。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.14894v2",
      "published_date": "2024-10-18 22:36:03 UTC",
      "updated_date": "2024-11-07 21:53:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:15:26.630710"
    },
    {
      "arxiv_id": "2410.14890v1",
      "title": "Reasoning, Memorization, and Fine-Tuning Language Models for Non-Cooperative Games",
      "title_zh": "翻译失败",
      "authors": [
        "Yunhao Yang",
        "Leonard Berthellemy",
        "Ufuk Topcu"
      ],
      "abstract": "We develop a method that integrates the tree of thoughts and multi-agent\nframework to enhance the capability of pre-trained language models in solving\ncomplex, unfamiliar games. The method decomposes game-solving into four\nincremental tasks -- game summarization, area selection, action extraction, and\naction validation -- each assigned to a specific language-model agent. By\nconstructing a tree of thoughts, the method simulates reasoning paths and\nallows agents to collaboratively distill game representations and tactics,\nmitigating the limitations of language models in reasoning and long-term\nmemorization. Additionally, an automated fine-tuning process further optimizes\nthe agents' performance by ranking query-response pairs based on game outcomes,\ne.g., winning or losing. We apply the method to a non-cooperative game and\ndemonstrate a 65 percent winning rate against benchmark algorithms, with an\nadditional 10 percent improvement after fine-tuning. In contrast to existing\ndeep learning algorithms for game solving that require millions of training\nsamples, the proposed method consumes approximately 1000 training samples,\nhighlighting its efficiency and scalability.",
      "tldr_zh": "这篇论文提出了一种整合树状思维（tree of thoughts）和多智能体框架的方法，以提升预训练语言模型在复杂非合作游戏（non-cooperative games）中的推理和记忆能力。该方法将游戏解决分解为四个增量任务——游戏总结（game summarization）、区域选择（area selection）、行动提取（action extraction）和行动验证（action validation），由特定语言模型智能体协作处理，并通过树状思维模拟推理路径来优化策略。实验结果显示，该方法在非合作游戏中对基准算法的胜率达到65%，微调（fine-tuning）后进一步提升10%，且仅需约1000个训练样本，相比传统深度学习算法更高效且可扩展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14890v1",
      "published_date": "2024-10-18 22:28:22 UTC",
      "updated_date": "2024-10-18 22:28:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:15:40.044973"
    },
    {
      "arxiv_id": "2410.14888v1",
      "title": "Self-Satisfied: An end-to-end framework for SAT generation and prediction",
      "title_zh": "Self-Satisfied:",
      "authors": [
        "Christopher R. Serrano",
        "Jonathan Gallagher",
        "Kenji Yamada",
        "Alexei Kopylov",
        "Michael A. Warren"
      ],
      "abstract": "The boolean satisfiability (SAT) problem asks whether there exists an\nassignment of boolean values to the variables of an arbitrary boolean formula\nmaking the formula evaluate to True. It is well-known that all NP-problems can\nbe coded as SAT problems and therefore SAT is important both practically and\ntheoretically. From both of these perspectives, better understanding the\npatterns and structure implicit in SAT data is of significant value. In this\npaper, we describe several advances that we believe will help open the door to\nsuch understanding: we introduce hardware accelerated algorithms for fast SAT\nproblem generation, a geometric SAT encoding that enables the use of\ntransformer architectures typically applied to vision tasks, and a simple yet\neffective technique we term head slicing for reducing sequence length\nrepresentation inside transformer architectures. These advances allow us to\nscale our approach to SAT problems with thousands of variables and tens of\nthousands of clauses. We validate our architecture, termed Satisfiability\nTransformer (SaT), on the SAT prediction task with data from the SAT\nCompetition (SATComp) 2022 problem sets. Prior related work either leveraged a\npure machine learning approach, but could not handle SATComp-sized problems, or\nwas hybrid in the sense of integrating a machine learning component in a\nstandard SAT solving tool. Our pure machine learning approach achieves\nprediction accuracies comparable to recent work, but on problems that are an\norder of magnitude larger than previously demonstrated. A fundamental aspect of\nour work concerns the very nature of SAT data and its suitability for training\nmachine learning models. We both describe experimental results that probe the\nlandscape of where SAT data can be successfully used for learning and position\nthese results within the broader context of complexity and learning.",
      "tldr_zh": "本论文提出了一种端到端框架Self-Satisfied，用于布尔可满足性(SAT)问题的生成和预测。该框架引入硬件加速算法实现快速SAT问题生成、几何SAT编码以适配Transformer架构用于视觉任务，以及头切片技术来减少Transformer中的序列长度，从而处理数千变量和数万个子句的大规模SAT问题。在SATComp 2022数据集上的实验中，名为Satisfiability Transformer (SaT)的架构实现了与现有工作相当的预测准确率，但能处理规模大一个数量级的SAT问题。该研究还探讨了SAT数据的学习适用性，通过实验结果揭示其在复杂性和机器学习领域的潜在价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO",
        "03D99",
        "I.5.2; I.5.1; I.2.3; F.0"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.14888v1",
      "published_date": "2024-10-18 22:25:54 UTC",
      "updated_date": "2024-10-18 22:25:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:15:51.185109"
    },
    {
      "arxiv_id": "2410.14881v2",
      "title": "Class-RAG: Real-Time Content Moderation with Retrieval Augmented Generation",
      "title_zh": "Class-RAG: 基于检索增强生成的实时内容审核",
      "authors": [
        "Jianfa Chen",
        "Emily Shen",
        "Trupti Bavalatti",
        "Xiaowen Lin",
        "Yongkai Wang",
        "Shuming Hu",
        "Harihar Subramanyam",
        "Ksheeraj Sai Vepuri",
        "Ming Jiang",
        "Ji Qi",
        "Li Chen",
        "Nan Jiang",
        "Ankit Jain"
      ],
      "abstract": "Robust content moderation classifiers are essential for the safety of\nGenerative AI systems. In this task, differences between safe and unsafe inputs\nare often extremely subtle, making it difficult for classifiers (and indeed,\neven humans) to properly distinguish violating vs. benign samples without\ncontext or explanation. Scaling risk discovery and mitigation through\ncontinuous model fine-tuning is also slow, challenging and costly, preventing\ndevelopers from being able to respond quickly and effectively to emergent\nharms. We propose a Classification approach employing Retrieval-Augmented\nGeneration (Class-RAG). Class-RAG extends the capability of its base LLM\nthrough access to a retrieval library which can be dynamically updated to\nenable semantic hotfixing for immediate, flexible risk mitigation. Compared to\nmodel fine-tuning, Class-RAG demonstrates flexibility and transparency in\ndecision-making, outperforms on classification and is more robust against\nadversarial attack, as evidenced by empirical studies. Our findings also\nsuggest that Class-RAG performance scales with retrieval library size,\nindicating that increasing the library size is a viable and low-cost approach\nto improve content moderation.",
      "tldr_zh": "该研究提出 Class-RAG，一种基于 Retrieval-Augmented Generation (RAG) 的实时内容审核方法，旨在解决生成式 AI 系统中的安全挑战，如区分安全与不安全输入的微妙差异和快速风险缓解需求。Class-RAG 通过动态更新检索库扩展基础 LLM 的能力，实现语义热修复（semantic hotfixing），从而提升决策的灵活性和透明度。与传统模型微调相比，实验结果显示 Class-RAG 在分类性能上表现出色，更能抵抗 adversarial attack，并证明其性能随检索库大小增加而提升，这为低成本的内容审核改进提供了可行路径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, submit to ACL",
      "pdf_url": "http://arxiv.org/pdf/2410.14881v2",
      "published_date": "2024-10-18 22:07:36 UTC",
      "updated_date": "2024-12-17 22:07:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:16:02.057745"
    },
    {
      "arxiv_id": "2410.14879v2",
      "title": "Vital Insight: Assisting Experts' Context-Driven Sensemaking of Multi-modal Personal Tracking Data Using Visualization and Human-In-The-Loop LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Jiachen Li",
        "Xiwen Li",
        "Justin Steinberg",
        "Akshat Choube",
        "Bingsheng Yao",
        "Xuhai Xu",
        "Dakuo Wang",
        "Elizabeth Mynatt",
        "Varun Mishra"
      ],
      "abstract": "Passive tracking methods, such as phone and wearable sensing, have become\ndominant in monitoring human behaviors in modern ubiquitous computing studies.\nWhile there have been significant advances in machine-learning approaches to\ntranslate periods of raw sensor data to model momentary behaviors, (e.g.,\nphysical activity recognition), there still remains a significant gap in the\ntranslation of these sensing streams into meaningful, high-level, context-aware\ninsights that are required for various applications (e.g., summarizing an\nindividual's daily routine). To bridge this gap, experts often need to employ a\ncontext-driven sensemaking process in real-world studies to derive insights.\nThis process often requires manual effort and can be challenging even for\nexperienced researchers due to the complexity of human behaviors.\n  We conducted three rounds of user studies with 21 experts to explore\nsolutions to address challenges with sensemaking. We follow a human-centered\ndesign process to identify needs and design, iterate, build, and evaluate Vital\nInsight (VI), a novel, LLM-assisted, prototype system to enable\nhuman-in-the-loop inference (sensemaking) and visualizations of multi-modal\npassive sensing data from smartphones and wearables. Using the prototype as a\ntechnology probe, we observe experts' interactions with it and develop an\nexpert sensemaking model that explains how experts move between direct data\nrepresentations and AI-supported inferences to explore, question, and validate\ninsights. Through this iterative process, we also synthesize and discuss a list\nof design implications for the design of future AI-augmented visualization\nsystems to better assist experts' sensemaking processes in multi-modal health\nsensing data.",
      "tldr_zh": "本文研究了被动跟踪数据（如手机和可穿戴设备）转化为高层次上下文感知洞见的挑战，强调专家在sensemaking过程中面临的手动努力和复杂性问题。通过三轮用户研究（涉及21名专家），作者设计并迭代了Vital Insight（VI）系统，该系统结合可视化和human-in-the-loop LLM代理，支持专家对多模态感知数据的推理和可视化。研究结果包括一个解释专家在数据表示与AI推理间切换的sensemaking模型，以及针对未来AI增强可视化系统的设计启示。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14879v2",
      "published_date": "2024-10-18 21:56:35 UTC",
      "updated_date": "2025-02-27 22:31:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:16:14.721089"
    },
    {
      "arxiv_id": "2410.14872v2",
      "title": "How to Evaluate Reward Models for RLHF",
      "title_zh": "如何评估 RLHF 的奖励模型",
      "authors": [
        "Evan Frick",
        "Tianle Li",
        "Connor Chen",
        "Wei-Lin Chiang",
        "Anastasios N. Angelopoulos",
        "Jiantao Jiao",
        "Banghua Zhu",
        "Joseph E. Gonzalez",
        "Ion Stoica"
      ],
      "abstract": "We introduce a new benchmark for reward models that quantifies their ability\nto produce strong language models through RLHF (Reinforcement Learning from\nHuman Feedback). The gold-standard approach is to run a full RLHF training\npipeline and directly probe downstream LLM performance. However, this process\nis prohibitively expensive. To address this, we build a predictive model of\ndownstream LLM performance by evaluating the reward model on proxy tasks. These\nproxy tasks consist of a large-scale human preference and a verifiable\ncorrectness preference dataset, in which we measure 12 metrics across 12\ndomains. To investigate which reward model metrics are most correlated to\ngold-standard RLHF outcomes, we launch an end-to-end RLHF experiment on a\nlarge-scale crowdsourced human preference platform to view real reward model\ndownstream performance as ground truth. Ultimately, we compile our data and\nfindings into Preference Proxy Evaluations (PPE), the first reward model\nbenchmark explicitly linked to post-RLHF real-world human preference\nperformance, which we open-source for public use and further development. Our\ncode and evaluations can be found at https://github.com/lmarena/PPE .",
      "tldr_zh": "该研究提出了一种新基准 Preference Proxy Evaluations (PPE)，用于评估奖励模型(RLHF)生成强大语言模型的能力，以避免昂贵的端到端 RLHF 训练。方法包括使用代理任务（如大规模人类偏好数据集和可验证正确性数据集）来预测下游 LLM 性能，涵盖12个指标和12个领域，并通过实际 RLHF 实验验证相关性。结果显示，PPE 能有效量化奖励模型与真实人类偏好性能的关联，并开源代码以促进进一步发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14872v2",
      "published_date": "2024-10-18 21:38:21 UTC",
      "updated_date": "2024-10-22 22:18:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:16:26.517033"
    },
    {
      "arxiv_id": "2410.14865v1",
      "title": "Joint Verification and Refinement of Language Models for Safety-Constrained Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Yunhao Yang",
        "William Ward",
        "Zichao Hu",
        "Joydeep Biswas",
        "Ufuk Topcu"
      ],
      "abstract": "Although pre-trained language models can generate executable plans (e.g.,\nprogrammatic policies) for solving robot tasks, the generated plans may violate\ntask-relevant logical specifications due to the models' black-box nature. A\nsignificant gap remains between the language models' outputs and verifiable\nexecutions of plans. We develop a method to generate executable plans and\nformally verify them against task-relevant safety specifications. Given a\nhigh-level task description in natural language, the proposed method queries a\nlanguage model to generate plans in the form of executable robot programs. It\nthen converts the generated plan into an automaton-based representation,\nallowing formal verification of the automaton against the specifications. We\nprove that given a set of verified plans, the composition of these plans also\nsatisfies the safety specifications. This proof ensures the safety of complex,\nmulti-component plans, obviating the computation complexity of verifying the\ncomposed plan. We then propose an automated fine-tuning process that refines\nthe language model to generate specification-compliant plans without the need\nfor human labeling. The empirical results show a 30 percent improvement in the\nprobability of generating plans that meet task specifications after\nfine-tuning.",
      "tldr_zh": "本文提出了一种联合验证和精炼方法，用于确保语言模型在安全约束规划中生成的计划符合任务相关的安全 specifications。方法包括从自然语言任务描述查询语言 model 生成可执行机器人程序，然后将这些程序转换为基于 automaton 的表示，并进行 formal verification。论文证明了，已验证计划的组合也满足安全 specifications，从而避免了验证复杂多组件计划的计算开销。此外，通过一个自动 fine-tuning 过程，语言模型生成符合规范计划的概率提高了30%。这为可信赖的机器人任务规划提供了重要改进。",
      "categories": [
        "cs.AI",
        "cs.FL",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14865v1",
      "published_date": "2024-10-18 21:16:30 UTC",
      "updated_date": "2024-10-18 21:16:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:16:39.198763"
    },
    {
      "arxiv_id": "2410.14853v2",
      "title": "DFlow: Diverse Dialogue Flow Simulation with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wanyu Du",
        "Song Feng",
        "James Gung",
        "Lijia Sun",
        "Yi Zhang",
        "Saab Mansour",
        "Yanjun Qi"
      ],
      "abstract": "Developing language model-based dialogue agents requires effective data to\ntrain models that can follow specific task logic. However, most existing data\nsimulation methods focus on increasing diversity in language, topics, or\ndialogue acts at the utterance level, largely neglecting a critical aspect of\ntask logic diversity at the dialogue level. This paper proposes a novel data\nsimulation method designed to enhance the diversity of synthetic dialogues by\nfocusing on task execution logic. Our method uses LLMs to generate decision\ntree-structured task plans, which enables the derivation of diverse dialogue\ntrajectories for a given task. Each trajectory, referred to as a \"dialog flow\",\nguides the generation of a multi-turn dialogue that follows a unique\ntrajectory. We apply this method to generate a task-oriented dialogue dataset\ncomprising 3,886 dialogue flows across 15 different domains. We validate the\neffectiveness of this dataset using the next action prediction task, where\nmodels fine-tuned on our dataset outperform strong baselines, including GPT-4.\nUpon acceptance of this paper, we plan to release the code and data publicly.",
      "tldr_zh": "本研究提出DFlow方法，使用Large Language Models (LLMs)生成决策树结构的任务计划，以提升合成对话的任务执行逻辑多样性，从而弥补现有数据模拟方法的不足。方法通过这些任务计划衍生出多样化的对话轨迹（dialog flows），每个轨迹指导生成多轮任务导向对话。研究基于此方法创建了一个包含3,886个对话流的dataset，覆盖15个领域。在下一个动作预测任务的验证中，使用该数据集微调的模型表现优于强基线模型，包括GPT-4。作者计划公开代码和数据，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.14853v2",
      "published_date": "2024-10-18 20:35:28 UTC",
      "updated_date": "2025-03-01 23:22:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:16:50.769264"
    },
    {
      "arxiv_id": "2410.14827v2",
      "title": "Enhancing Prompt Injection Attacks to LLMs via Poisoning Alignment",
      "title_zh": "通过毒化对齐增强针对大语言模型的提示注入攻击",
      "authors": [
        "Zedian Shao",
        "Hongbin Liu",
        "Jaden Mu",
        "Neil Zhenqiang Gong"
      ],
      "abstract": "In a prompt injection attack, an attacker injects a prompt into the original\none, aiming to make an LLM follow the injected prompt to perform an\nattacker-chosen task. Existing attacks primarily focus on how to blend the\ninjected prompt into the original prompt without altering the LLM itself. Our\nexperiments show that these attacks achieve some success, but there is still\nsignificant room for improvement. In this work, we show that an attacker can\nboost the success of prompt injection attacks by poisoning the LLM's alignment\nprocess. Specifically, we propose PoisonedAlign, a method to strategically\ncreate poisoned alignment samples. When even a small fraction of the alignment\ndata is poisoned using our method, the aligned LLM becomes more vulnerable to\nprompt injection while maintaining its foundational capabilities. The code is\navailable at https://github.com/Sadcardation/PoisonedAlign",
      "tldr_zh": "本论文探讨了如何通过毒害大型语言模型(LLMs)的对齐过程来增强提示注入攻击(prompt injection attack)，以使攻击者更有效地操控模型执行指定任务。研究提出PoisonedAlign方法，该方法通过战略性地创建毒害的对齐样本，即使只有少量数据被毒害，也能显著提高攻击成功率，同时保持模型的基础能力。实验结果表明，这种方法比现有攻击更有效，为评估LLMs的安全性提供了新见解。代码已在GitHub上公开。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14827v2",
      "published_date": "2024-10-18 18:52:16 UTC",
      "updated_date": "2025-04-04 21:04:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:17:02.587017"
    },
    {
      "arxiv_id": "2410.14826v2",
      "title": "SPRIG: Improving Large Language Model Performance by System Prompt Optimization",
      "title_zh": "SPRIG：通过系统提示优化改善大语言模型性能",
      "authors": [
        "Lechen Zhang",
        "Tolga Ergen",
        "Lajanugen Logeswaran",
        "Moontae Lee",
        "David Jurgens"
      ],
      "abstract": "Large Language Models (LLMs) have shown impressive capabilities in many\nscenarios, but their performance depends, in part, on the choice of prompt.\nPast research has focused on optimizing prompts specific to a task. However,\nmuch less attention has been given to optimizing the general instructions\nincluded in a prompt, known as a system prompt. To address this gap, we propose\nSPRIG, an edit-based genetic algorithm that iteratively constructs prompts from\nprespecified components to maximize the model's performance in general\nscenarios. We evaluate the performance of system prompts on a collection of 47\ndifferent types of tasks to ensure generalizability. Our study finds that a\nsingle optimized system prompt performs on par with task prompts optimized for\neach individual task. Moreover, combining system and task-level optimizations\nleads to further improvement, which showcases their complementary nature.\nExperiments also reveal that the optimized system prompts generalize\neffectively across model families, parameter sizes, and languages. This study\nprovides insights into the role of system-level instructions in maximizing LLM\npotential.",
      "tldr_zh": "本研究提出SPRIG，一种基于编辑的遗传算法，用于优化Large Language Models (LLMs)的系统提示，以提升模型在一般场景下的性能。SPRIG通过迭代构建提示组件，并在47种不同任务上进行评估，发现一个优化的系统提示可与针对单个任务优化的提示相媲美，且二者结合可进一步提高表现。实验结果显示，该优化方法在不同模型家族、参数大小和语言上具有良好的泛化性，并为最大化LLM潜力的系统级指令提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14826v2",
      "published_date": "2024-10-18 18:51:44 UTC",
      "updated_date": "2024-10-25 05:43:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:17:14.336795"
    },
    {
      "arxiv_id": "2410.14817v4",
      "title": "A Complexity-Based Theory of Compositionality",
      "title_zh": "基于复杂度的组合性理论",
      "authors": [
        "Eric Elmoznino",
        "Thomas Jiralerspong",
        "Yoshua Bengio",
        "Guillaume Lajoie"
      ],
      "abstract": "Compositionality is believed to be fundamental to intelligence. In humans, it\nunderlies the structure of thought, language, and higher-level reasoning. In\nAI, compositional representations can enable a powerful form of\nout-of-distribution generalization, in which a model systematically adapts to\nnovel combinations of known concepts. However, while we have strong intuitions\nabout what compositionality is, there currently exists no formal definition for\nit that is measurable and mathematical. Here, we propose such a definition,\nwhich we call representational compositionality, that accounts for and extends\nour intuitions about compositionality. The definition is conceptually simple,\nquantitative, grounded in algorithmic information theory, and applicable to any\nrepresentation. Intuitively, representational compositionality states that a\ncompositional representation satisfies three properties. First, it must be\nexpressive. Second, it must be possible to re-describe the representation as a\nfunction of discrete symbolic sequences with re-combinable parts, analogous to\nsentences in natural language. Third, the function that relates these symbolic\nsequences to the representation, analogous to semantics in natural language,\nmust be simple. Through experiments on both synthetic and real world data, we\nvalidate our definition of compositionality and show how it unifies disparate\nintuitions from across the literature in both AI and cognitive science. We also\nshow that representational compositionality, while theoretically intractable,\ncan be readily estimated using standard deep learning tools. Our definition has\nthe potential to inspire the design of novel, theoretically-driven models that\nbetter capture the mechanisms of compositional thought.",
      "tldr_zh": "本论文提出了一种基于算法信息理论（algorithmic information theory）的组合性理论，正式定义了representational compositionality，以量化评估智能系统中的组合性。该定义包括三个核心属性：表示必须具有表达性（expressive）、能被重新描述为可重组的离散符号序列，以及将符号序列映射到表示的函数必须简单。通过在合成和真实世界数据上的实验，论文验证了这一定义的有效性，并统一了AI和认知科学领域对组合性的不同直觉。尽管计算上具有理论挑战性，该方法可借助标准深度学习工具进行估计，并为设计捕捉组合性思考机制的新型模型提供指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14817v4",
      "published_date": "2024-10-18 18:37:27 UTC",
      "updated_date": "2025-02-05 20:11:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:17:26.922935"
    },
    {
      "arxiv_id": "2410.14808v1",
      "title": "The S2 Hierarchical Discrete Global Grid as a Nexus for Data Representation, Integration, and Querying Across Geospatial Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Shirly Stephen",
        "Mitchell Faulk",
        "Krzysztof Janowicz",
        "Colby Fisher",
        "Thomas Thelen",
        "Rui Zhu",
        "Pascal Hitzler",
        "Cogan Shimizu",
        "Kitty Currier",
        "Mark Schildhauer",
        "Dean Rehberger",
        "Zhangyu Wang",
        "Antrea Christou"
      ],
      "abstract": "Geospatial Knowledge Graphs (GeoKGs) have become integral to the growing\nfield of Geospatial Artificial Intelligence. Initiatives like the U.S. National\nScience Foundation's Open Knowledge Network program aim to create an ecosystem\nof nation-scale, cross-disciplinary GeoKGs that provide AI-ready geospatial\ndata aligned with FAIR principles. However, building this infrastructure\npresents key challenges, including 1) managing large volumes of data, 2) the\ncomputational complexity of discovering topological relations via SPARQL, and\n3) conflating multi-scale raster and vector data. Discrete Global Grid Systems\n(DGGS) help tackle these issues by offering efficient data integration and\nrepresentation strategies. The KnowWhereGraph utilizes Google's S2 Geometry --\na DGGS framework -- to enable efficient multi-source data processing,\nqualitative spatial querying, and cross-graph integration. This paper outlines\nthe implementation of S2 within KnowWhereGraph, emphasizing its role in\ntopologically enriching and semantically compressing data. Ultimately, this\nwork demonstrates the potential of DGGS frameworks, particularly S2, for\nbuilding scalable GeoKGs.",
      "tldr_zh": "这篇论文探讨了 Geospatial Knowledge Graphs (GeoKGs) 在 Geospatial Artificial Intelligence 中的关键作用，并针对构建国家规模跨学科 GeoKGs 的挑战（如管理海量数据、SPARQL 拓扑关系计算的复杂性以及多尺度栅格和矢量数据的融合）提出解决方案。作者引入 Discrete Global Grid Systems (DGGS) 作为高效的数据集成和表示策略，特别是利用 Google's S2 Geometry 在 KnowWhereGraph 中实现多源数据处理、定性空间查询和跨图集成。S2 框架通过拓扑丰富和语义压缩数据，显著提升了 GeoKGs 的可扩展性。最终，该研究展示了 S2 等 DGGS 框架在创建符合 FAIR 原则的 AI-ready 地理空间基础设施方面的潜力。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14808v1",
      "published_date": "2024-10-18 18:30:05 UTC",
      "updated_date": "2024-10-18 18:30:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:17:38.976074"
    },
    {
      "arxiv_id": "2410.14807v1",
      "title": "Aligning AI Agents via Information-Directed Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Hong Jun Jeon",
        "Benjamin Van Roy"
      ],
      "abstract": "The staggering feats of AI systems have brought to attention the topic of AI\nAlignment: aligning a \"superintelligent\" AI agent's actions with humanity's\ninterests. Many existing frameworks/algorithms in alignment study the problem\non a myopic horizon or study learning from human feedback in isolation, relying\non the contrived assumption that the agent has already perfectly identified the\nenvironment. As a starting point to address these limitations, we define a\nclass of bandit alignment problems as an extension of classic multi-armed\nbandit problems. A bandit alignment problem involves an agent tasked with\nmaximizing long-run expected reward by interacting with an environment and a\nhuman, both involving details/preferences initially unknown to the agent. The\nreward of actions in the environment depends on both observed outcomes and\nhuman preferences. Furthermore, costs are associated with querying the human to\nlearn preferences. Therefore, an effective agent ought to intelligently\ntrade-off exploration (of the environment and human) and exploitation. We study\nthese trade-offs theoretically and empirically in a toy bandit alignment\nproblem which resembles the beta-Bernoulli bandit. We demonstrate while naive\nexploration algorithms which reflect current practices and even touted\nalgorithms such as Thompson sampling both fail to provide acceptable solutions\nto this problem, information-directed sampling achieves favorable regret.",
      "tldr_zh": "该论文针对 AI Alignment 问题，定义了 bandit alignment problems 作为 multi-armed bandit 问题的扩展，涉及代理在未知环境和人类偏好下最大化长期预期回报，同时需考虑查询人类偏好的成本。\n代理必须智能平衡环境和人类探索与利用的权衡，论文通过理论分析和实验验证在 beta-Bernoulli bandit 场景中证明，Information-Directed Sampling 算法比 naive 探索算法和 Thompson sampling 显著降低了 regret。\n这一方法为实现更有效的 AI 代理对齐提供了新框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14807v1",
      "published_date": "2024-10-18 18:23:41 UTC",
      "updated_date": "2024-10-18 18:23:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:17:50.787758"
    },
    {
      "arxiv_id": "2410.14803v5",
      "title": "DistRL: An Asynchronous Distributed Reinforcement Learning Framework for On-Device Control Agents",
      "title_zh": "DistRL：一种用于设备控制代理的异步分布式强化学习框架",
      "authors": [
        "Taiyi Wang",
        "Zhihao Wu",
        "Jianheng Liu",
        "Jianye Hao",
        "Jun Wang",
        "Kun Shao"
      ],
      "abstract": "On-device control agents, especially on mobile devices, are responsible for\noperating mobile devices to fulfill users' requests, enabling seamless and\nintuitive interactions. Integrating Multimodal Large Language Models (MLLMs)\ninto these agents enhances their ability to understand and execute complex\ncommands, thereby improving user experience. However, fine-tuning MLLMs for\non-device control presents significant challenges due to limited data\navailability and inefficient online training processes. This paper introduces\nDistRL, a novel framework designed to enhance the efficiency of online RL\nfine-tuning for mobile device control agents. DistRL employs centralized\ntraining and decentralized data acquisition to ensure efficient fine-tuning in\nthe context of dynamic online interactions. Additionally, the framework is\nbacked by our tailor-made RL algorithm, which effectively balances exploration\nwith the prioritized utilization of collected data to ensure stable and robust\ntraining. Our experiments show that, on average, DistRL delivers a 3X\nimprovement in training efficiency and enables training data collection 2.4X\nfaster than the leading synchronous multi-machine methods. Notably, after\ntraining, DistRL achieves a 20% relative improvement in success rate compared\nto state-of-the-art methods on general Android tasks from an open benchmark,\nsignificantly outperforming existing approaches while maintaining the same\ntraining time. These results validate DistRL as a scalable and efficient\nsolution, offering substantial improvements in both training efficiency and\nagent performance for real-world, in-the-wild device control tasks.",
      "tldr_zh": "该论文提出 DistRL，一种异步分布式强化学习框架，旨在解决 Multimodal Large Language Models (MLLMs) 在移动设备控制代理上的在线 RL 微调问题，包括数据有限和训练效率低等挑战。\nDistRL 通过集中式训练和分散式数据采集相结合的方式，以及一个定制的 RL 算法来平衡探索与数据优先利用，确保训练过程稳定高效。\n实验显示，DistRL 平均提升 3 倍训练效率和 2.4 倍数据收集速度，并在 Android 任务基准上实现成功率较现有方法提高 20%，证明其在实际设备控制任务中的可扩展性和性能优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper and Appendix, 26 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.14803v5",
      "published_date": "2024-10-18 18:19:56 UTC",
      "updated_date": "2025-02-21 16:23:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:18:02.762194"
    },
    {
      "arxiv_id": "2410.14799v1",
      "title": "Deep Generic Dynamic Object Detection Based on Dynamic Grid Maps",
      "title_zh": "翻译失败",
      "authors": [
        "Rujiao Yan",
        "Linda Schubert",
        "Alexander Kamm",
        "Matthias Komar",
        "Matthias Schreier"
      ],
      "abstract": "This paper describes a method to detect generic dynamic objects for automated\ndriving. First, a LiDAR-based dynamic grid is generated online. Second, a deep\nlearning-based detector is trained on the dynamic grid to infer the presence of\ndynamic objects of any type, which is a prerequisite for safe automated\nvehicles in arbitrary, edge-case scenarios. The Rotation-equivariant Detector\n(ReDet) - originally designed for oriented object detection on aerial images -\nwas chosen due to its high detection performance. Experiments are conducted\nbased on real sensor data and the benefits in comparison to classic dynamic\ncell clustering strategies are highlighted. The false positive object detection\nrate is strongly reduced by the proposed approach.",
      "tldr_zh": "本论文提出了一种基于动态网格图的深度学习方法，用于自动驾驶中的通用动态物体检测。首先，通过在线生成 LiDAR-based dynamic grid 来表示环境动态，然后使用 Rotation-equivariant Detector (ReDet) 进行训练和检测，以识别任意类型的动态对象，确保车辆在边缘场景中的安全性。实验基于真实传感器数据，结果显示该方法与经典动态单元聚类策略相比，显著降低了假阳性物体检测率，提高了整体检测性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 6 figures, IEEE IV24",
      "pdf_url": "http://arxiv.org/pdf/2410.14799v1",
      "published_date": "2024-10-18 18:15:32 UTC",
      "updated_date": "2024-10-18 18:15:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:18:14.583911"
    },
    {
      "arxiv_id": "2410.14676v2",
      "title": "SudoLM: Learning Access Control of Parametric Knowledge with Authorization Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Qin Liu",
        "Fei Wang",
        "Chaowei Xiao",
        "Muhao Chen"
      ],
      "abstract": "Existing preference alignment is a one-size-fits-all alignment mechanism,\nwhere the part of the large language model (LLM) parametric knowledge with\nnon-preferred features is uniformly blocked to all the users. However, this\npart of knowledge can be useful to advanced users whose expertise qualifies\nthem to handle these information. The one-size-fits-all alignment mechanism\nundermines LLM's utility for these qualified users. To address this problem, we\npropose SudoLM, a framework that lets LLMs learn access control over specific\nparametric knowledge for users with different credentials via authorization\nalignment. SudoLM allows authorized users to unlock their access to all the\nparametric knowledge with an assigned SUDO key while blocking access to\nnon-qualified users. Experiments on two application scenarios demonstrate that\nSudoLM effectively controls the user's access to the parametric knowledge and\nmaintains its general utility.",
      "tldr_zh": "该研究指出，现有的偏好对齐机制是“一刀切”的策略，会统一屏蔽大型语言模型(LLM)中非偏好的参数知识部分，从而降低了其对有资质用户的实用性。论文提出 SudoLM 框架，通过 authorization alignment 让 LLM 学习对特定参数知识的访问控制，根据用户凭证决定是否允许访问。SudoLM 允许授权用户使用分配的 SUDO key 解锁所有参数知识，而对非合格用户进行屏蔽。实验在两个应用场景中验证了该框架的有效性，既实现了对知识访问的精确控制，又保持了 LLM 的整体实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14676v2",
      "published_date": "2024-10-18 17:59:51 UTC",
      "updated_date": "2025-02-27 01:05:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:18:26.591922"
    },
    {
      "arxiv_id": "2410.14675v2",
      "title": "To Trust or Not to Trust? Enhancing Large Language Models' Situated Faithfulness to External Contexts",
      "title_zh": "翻译失败",
      "authors": [
        "Yukun Huang",
        "Sanxing Chen",
        "Hongyi Cai",
        "Bhuwan Dhingra"
      ],
      "abstract": "Large Language Models (LLMs) are often augmented with external contexts, such\nas those used in retrieval-augmented generation (RAG). However, these contexts\ncan be inaccurate or intentionally misleading, leading to conflicts with the\nmodel's internal knowledge. We argue that robust LLMs should demonstrate\nsituated faithfulness, dynamically calibrating their trust in external\ninformation based on their confidence in the internal knowledge and the\nexternal context to resolve knowledge conflicts. To benchmark this capability,\nwe evaluate LLMs across several QA datasets, including a newly created dataset\nfeaturing in-the-wild incorrect contexts sourced from Reddit posts. We show\nthat when provided with both correct and incorrect contexts, both open-source\nand proprietary models tend to overly rely on external information, regardless\nof its factual accuracy. To enhance situated faithfulness, we propose two\napproaches: Self-Guided Confidence Reasoning (SCR) and Rule-Based Confidence\nReasoning (RCR). SCR enables models to self-assess the confidence of external\ninformation relative to their own internal knowledge to produce the most\naccurate answer. RCR, in contrast, extracts explicit confidence signals from\nthe LLM and determines the final answer using predefined rules. Our results\nshow that for LLMs with strong reasoning capabilities, such as GPT-4o and\nGPT-4o mini, SCR outperforms RCR, achieving improvements of up to 24.2% over a\ndirect input augmentation baseline. Conversely, for a smaller model like\nLlama-3-8B, RCR outperforms SCR. Fine-tuning SCR with our proposed Confidence\nReasoning Direct Preference Optimization (CR-DPO) method improves performance\non both seen and unseen datasets, yielding an average improvement of 8.9% on\nLlama-3-8B. In addition to quantitative results, we offer insights into the\nrelative strengths of SCR and RCR.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 在处理外部上下文（如 retrieval-augmented generation, RAG）时存在的过度依赖问题，提出“situated faithfulness”概念，要求模型根据内部知识信心和外部信息准确性动态调整信任。研究通过多个 QA 数据集（包括一个新创建的基于 Reddit 错误上下文的数据集）评估了 LLMs，发现现有模型往往优先外部信息而忽略其准确性。为提升这一能力，作者开发了 Self-Guided Confidence Reasoning (SCR) 和 Rule-Based Confidence Reasoning (RCR) 方法，其中 SCR 让模型自我评估信心以生成更准确答案，而 RCR 使用预定义规则提取信心信号。实验结果显示，SCR 在 GPT-4o 和 GPT-4o mini 等强推理模型上比基线提升高达 24.2%，而通过 Confidence Reasoning Direct Preference Optimization (CR-DPO) 微调，Llama-3-8B 模型的性能平均改善 8.9%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14675v2",
      "published_date": "2024-10-18 17:59:47 UTC",
      "updated_date": "2025-03-17 04:47:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:18:41.125868"
    },
    {
      "arxiv_id": "2410.14672v3",
      "title": "BiGR: Harnessing Binary Latent Codes for Image Generation and Improved Visual Representation Capabilities",
      "title_zh": "BiGR: 利用二进制潜在代码实现图像生成",
      "authors": [
        "Shaozhe Hao",
        "Xuantong Liu",
        "Xianbiao Qi",
        "Shihao Zhao",
        "Bojia Zi",
        "Rong Xiao",
        "Kai Han",
        "Kwan-Yee K. Wong"
      ],
      "abstract": "We introduce BiGR, a novel conditional image generation model using compact\nbinary latent codes for generative training, focusing on enhancing both\ngeneration and representation capabilities. BiGR is the first conditional\ngenerative model that unifies generation and discrimination within the same\nframework. BiGR features a binary tokenizer, a masked modeling mechanism, and a\nbinary transcoder for binary code prediction. Additionally, we introduce a\nnovel entropy-ordered sampling method to enable efficient image generation.\nExtensive experiments validate BiGR's superior performance in generation\nquality, as measured by FID-50k, and representation capabilities, as evidenced\nby linear-probe accuracy. Moreover, BiGR showcases zero-shot generalization\nacross various vision tasks, enabling applications such as image inpainting,\noutpainting, editing, interpolation, and enrichment, without the need for\nstructural modifications. Our findings suggest that BiGR unifies generative and\ndiscriminative tasks effectively, paving the way for further advancements in\nthe field. We further enable BiGR to perform text-to-image generation,\nshowcasing its potential for broader applications.",
      "tldr_zh": "本研究引入了BiGR，一种新型条件图像生成模型，利用紧凑的binary latent codes来提升图像生成质量和视觉表示能力。BiGR首次统一生成和判别任务于同一框架中，结合binary tokenizer、masked modeling机制以及binary transcoder进行二进制代码预测，并提出entropy-ordered sampling方法以实现高效生成。实验结果显示，BiGR在FID-50k指标上生成质量优于基线，在linear-probe accuracy上表现出色，并支持零样本泛化，适用于图像inpainting、outpainting、编辑、插值和文本到图像生成等任务。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Updated with additional T2I results; Project page:\n  https://haoosz.github.io/BiGR",
      "pdf_url": "http://arxiv.org/pdf/2410.14672v3",
      "published_date": "2024-10-18 17:59:04 UTC",
      "updated_date": "2025-01-05 10:51:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:18:51.268850"
    },
    {
      "arxiv_id": "2410.14666v2",
      "title": "DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie Character-Aware Discourse Graph",
      "title_zh": "DiscoGraMS：利用电影角色感知话语图增强电影剧本总结",
      "authors": [
        "Maitreya Prafulla Chitale",
        "Uday Bindal",
        "Rajakrishnan Rajkumar",
        "Rahul Mishra"
      ],
      "abstract": "Summarizing movie screenplays presents a unique set of challenges compared to\nstandard document summarization. Screenplays are not only lengthy, but also\nfeature a complex interplay of characters, dialogues, and scenes, with numerous\ndirect and subtle relationships and contextual nuances that are difficult for\nmachine learning models to accurately capture and comprehend. Recent attempts\nat screenplay summarization focus on fine-tuning transformer-based pre-trained\nmodels, but these models often fall short in capturing long-term dependencies\nand latent relationships, and frequently encounter the \"lost in the middle\"\nissue. To address these challenges, we introduce DiscoGraMS, a novel resource\nthat represents movie scripts as a movie character-aware discourse graph (CaD\nGraph). This approach is well-suited for various downstream tasks, such as\nsummarization, question-answering, and salience detection. The model aims to\npreserve all salient information, offering a more comprehensive and faithful\nrepresentation of the screenplay's content. We further explore a baseline\nmethod that combines the CaD Graph with the corresponding movie script through\na late fusion of graph and text modalities, and we present very initial\npromising results.",
      "tldr_zh": "本研究针对电影剧本总结的挑战（如复杂角色互动、长期依赖和“lost in the middle”问题），提出了一种新资源DiscoGraMS，该方法将电影脚本表示为电影角色感知话语图（CaD Graph），以更好地捕捉关键信息和潜在关系。DiscoGraMS适用于下游任务如总结、问答和显著性检测，通过晚融合（late fusion）结合图和文本模式，提供更全面且忠实的剧本表示。初步实验结果显示，该方法比传统transformer-based models更具前景，提升了总结的准确性和全面性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025 (Main)",
      "pdf_url": "http://arxiv.org/pdf/2410.14666v2",
      "published_date": "2024-10-18 17:56:11 UTC",
      "updated_date": "2025-03-02 10:38:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:19:03.280865"
    },
    {
      "arxiv_id": "2410.14665v1",
      "title": "Online Reinforcement Learning with Passive Memory",
      "title_zh": "翻译失败",
      "authors": [
        "Anay Pattanaik",
        "Lav R. Varshney"
      ],
      "abstract": "This paper considers an online reinforcement learning algorithm that\nleverages pre-collected data (passive memory) from the environment for online\ninteraction. We show that using passive memory improves performance and further\nprovide theoretical guarantees for regret that turns out to be near-minimax\noptimal. Results show that the quality of passive memory determines\nsub-optimality of the incurred regret. The proposed approach and results hold\nin both continuous and discrete state-action spaces.",
      "tldr_zh": "这篇论文提出了一种在线强化学习（Online Reinforcement Learning）算法，该算法利用预先收集的环境数据（Passive Memory）来提升在线交互性能。研究者证明了这种方法能改善整体表现，并提供了近乎最优的最小最大遗憾（Regret）理论保证。结果表明，被动记忆的质量直接影响算法的次优性，且该方法适用于连续和离散状态-动作空间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14665v1",
      "published_date": "2024-10-18 17:55:15 UTC",
      "updated_date": "2024-10-18 17:55:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:19:13.816924"
    },
    {
      "arxiv_id": "2410.14651v2",
      "title": "Real-time Fake News from Adversarial Feedback",
      "title_zh": "基于对抗性反馈的实时假新闻",
      "authors": [
        "Sanxing Chen",
        "Yukun Huang",
        "Bhuwan Dhingra"
      ],
      "abstract": "We show that existing evaluations for fake news detection based on\nconventional sources, such as claims on fact-checking websites, result in high\naccuracies over time for LLM-based detectors -- even after their knowledge\ncutoffs. This suggests that recent popular fake news from such sources can be\neasily detected due to pre-training and retrieval corpus contamination or\nincreasingly salient shallow patterns. Instead, we argue that a proper fake\nnews detection dataset should test a model's ability to reason factually about\nthe current world by retrieving and reading related evidence. To this end, we\ndevelop a novel pipeline that leverages natural language feedback from a\nRAG-based detector to iteratively modify real-time news into deceptive fake\nnews that challenges LLMs. Our iterative rewrite decreases the binary\nclassification ROC-AUC by an absolute 17.5 percent for a strong RAG-based\nGPT-4o detector. Our experiments reveal the important role of RAG in both\ndetecting and generating fake news, as retrieval-free LLM detectors are\nvulnerable to unseen events and adversarial attacks, while feedback from RAG\ndetection helps discover more deceitful patterns in fake news.",
      "tldr_zh": "该研究揭示了现有假新闻检测评估基于传统来源（如事实检查网站）时，LLM 检测器表现出高准确率，但这可能源于预训练数据污染或浅显模式。作者提出一个新管道，利用 RAG-based 检测器的自然语言反馈来迭代修改实时新闻，生成更具欺骗性的假新闻，从而测试模型的 factual 推理能力。实验结果显示，这种迭代重写使强 RAG-based GPT-4o 检测器的二元分类 ROC-AUC 绝对下降 17.5%，突显了 RAG 在假新闻检测和生成中的关键作用，同时暴露了无检索 LLM 检测器对未见事件和对抗攻击的脆弱性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14651v2",
      "published_date": "2024-10-18 17:47:11 UTC",
      "updated_date": "2024-12-29 18:22:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:19:27.398164"
    },
    {
      "arxiv_id": "2410.14641v1",
      "title": "Distance between Relevant Information Pieces Causes Bias in Long-Context LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Runchu Tian",
        "Yanghao Li",
        "Yuepeng Fu",
        "Siyang Deng",
        "Qinyu Luo",
        "Cheng Qian",
        "Shuo Wang",
        "Xin Cong",
        "Zhong Zhang",
        "Yesai Wu",
        "Yankai Lin",
        "Huadong Wang",
        "Xiaojiang Liu"
      ],
      "abstract": "Positional bias in large language models (LLMs) hinders their ability to\neffectively process long inputs. A prominent example is the \"lost in the\nmiddle\" phenomenon, where LLMs struggle to utilize relevant information\nsituated in the middle of the input. While prior research primarily focuses on\nsingle pieces of relevant information, real-world applications often involve\nmultiple relevant information pieces. To bridge this gap, we present\nLongPiBench, a benchmark designed to assess positional bias involving multiple\npieces of relevant information. Thorough experiments are conducted with five\ncommercial and six open-source models. These experiments reveal that while most\ncurrent models are robust against the \"lost in the middle\" issue, there exist\nsignificant biases related to the spacing of relevant information pieces. These\nfindings highlight the importance of evaluating and reducing positional biases\nto advance LLM's capabilities.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）中位置偏差的问题，特别是多个相关信息片段间的距离导致的偏差，例如“lost in the middle”现象。研究者开发了 LongPiBench 基准，用于评估涉及多个相关信息片段的位置偏差，并通过实验测试了五个商业模型和六个开源模型。结果显示，大多数模型能有效处理中间信息，但相关信息片段间距的显著偏差依然存在。论文强调，需要进一步评估和减少这些偏差，以提升 LLMs 的长上下文处理能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "work in progress",
      "pdf_url": "http://arxiv.org/pdf/2410.14641v1",
      "published_date": "2024-10-18 17:41:19 UTC",
      "updated_date": "2024-10-18 17:41:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:19:38.950747"
    },
    {
      "arxiv_id": "2410.14635v2",
      "title": "GenEOL: Harnessing the Generative Power of LLMs for Training-Free Sentence Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Raghuveer Thirukovalluru",
        "Bhuwan Dhingra"
      ],
      "abstract": "Training-free embedding methods directly leverage pretrained large language\nmodels (LLMs) to embed text, bypassing the costly and complex procedure of\ncontrastive learning. Previous training-free embedding methods have mainly\nfocused on optimizing embedding prompts and have overlooked the benefits of\nutilizing the generative abilities of LLMs. We propose a novel method, GenEOL,\nwhich uses LLMs to generate diverse transformations of a sentence that preserve\nits meaning, and aggregates the resulting embeddings of these transformations\nto enhance the overall sentence embedding. GenEOL significantly outperforms the\nexisting training-free embedding methods by an average of 2.85 points across\nseveral LLMs on the sentence semantic text similarity (STS) benchmark. GenEOL\nalso achieves notable gains in clustering, reranking, and pair-classification\ntasks from the MTEB benchmark. Additionally, GenEOL stabilizes representation\nquality across LLM layers and remains robust to perturbations of embedding\nprompts.",
      "tldr_zh": "该论文提出GenEOL，一种无需训练的句子嵌入方法，利用LLMs的生成能力来提升嵌入质量。具体而言，GenEOL通过LLMs生成句子多样变换（如保留原义的变体），并聚合这些变换的嵌入结果，以优化整体句子表示。实验结果显示，GenEOL在STS基准上比现有训练-free方法平均提高2.85分，并在MTEB基准的聚类、重新排名和配对分类任务中取得显著提升，同时表现出对嵌入提示的鲁棒性和表示质量的稳定性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL Findings 2025, 9 pages, 4 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.14635v2",
      "published_date": "2024-10-18 17:36:53 UTC",
      "updated_date": "2025-02-09 16:40:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:19:50.076708"
    },
    {
      "arxiv_id": "2410.14630v2",
      "title": "On the Regularization of Learnable Embeddings for Time Series Forecasting",
      "title_zh": "时间序列预测中可学习嵌入的正则化",
      "authors": [
        "Luca Butera",
        "Giovanni De Felice",
        "Andrea Cini",
        "Cesare Alippi"
      ],
      "abstract": "In forecasting multiple time series, accounting for the individual features\nof each sequence can be challenging. To address this, modern deep learning\nmethods for time series analysis combine a shared (global) model with local\nlayers, specific to each time series, often implemented as learnable\nembeddings. Ideally, these local embeddings should encode meaningful\nrepresentations of the unique dynamics of each sequence. However, when these\nare learned end-to-end as parameters of a forecasting model, they may end up\nacting as mere sequence identifiers. Shared processing blocks may then become\nreliant on such identifiers, limiting their transferability to new contexts. In\nthis paper, we address this issue by investigating methods to regularize the\nlearning of local learnable embeddings for time series processing.\nSpecifically, we perform the first extensive empirical study on the subject and\nshow how such regularizations consistently improve performance in widely\nadopted architectures. Furthermore, we show that methods attempting to prevent\nthe co-adaptation of local and global parameters by means of embeddings\nperturbation are particularly effective in this context. In this regard, we\ninclude in the comparison several perturbation-based regularization methods,\ngoing as far as periodically resetting the embeddings during training. The\nobtained results provide an important contribution to understanding the\ninterplay between learnable local parameters and shared processing layers: a\nkey challenge in modern time series processing models and a step toward\ndeveloping effective foundation models for time series.",
      "tldr_zh": "这篇论文探讨了在时间序列预测中正则化可学习embeddings的问题，以防止这些embeddings仅充当序列标识符，从而改善模型的可转移性。作者进行了首次广泛实证研究，评估了多种正则化方法，特别是通过embeddings扰动（如周期性重置）来阻止局部和全局参数的共同适应，结果显示这些方法显著提升了主流架构的性能。总体而言，该研究加深了对可学习局部参数与共享处理层之间相互作用的理解，并为开发有效的time series foundation models铺平了道路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at TMLR",
      "pdf_url": "http://arxiv.org/pdf/2410.14630v2",
      "published_date": "2024-10-18 17:30:20 UTC",
      "updated_date": "2025-02-13 10:43:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:20:02.459009"
    },
    {
      "arxiv_id": "2410.14627v1",
      "title": "CELI: Controller-Embedded Language Model Interactions",
      "title_zh": "CELI：控制器嵌入语言模型交互",
      "authors": [
        "Jan-Samuel Wagner",
        "Dave DeCaprio",
        "Abishek Chiffon Muthu Raja",
        "Jonathan M. Holman",
        "Lauren K. Brady",
        "Sky C. Cheung",
        "Hosein Barzekar",
        "Eric Yang",
        "Mark Anthony Martinez II",
        "David Soong",
        "Sriram Sridhar",
        "Han Si",
        "Brandon W. Higgs",
        "Hisham Hamadeh",
        "Scott Ogden"
      ],
      "abstract": "We introduce Controller-Embedded Language Model Interactions (CELI), a\nframework that integrates control logic directly within language model (LM)\nprompts, facilitating complex, multi-stage task execution. CELI addresses\nlimitations of existing prompt engineering and workflow optimization techniques\nby embedding control logic directly within the operational context of language\nmodels, enabling dynamic adaptation to evolving task requirements. Our\nframework transfers control from the traditional programming execution\nenvironment to the LMs, allowing them to autonomously manage computational\nworkflows while maintaining seamless interaction with external systems and\nfunctions. CELI supports arbitrary function calls with variable arguments,\nbridging the gap between LMs' adaptive reasoning capabilities and conventional\nsoftware paradigms' structured control mechanisms. To evaluate CELI's\nversatility and effectiveness, we conducted case studies in two distinct\ndomains: code generation (HumanEval benchmark) and multi-stage content\ngeneration (Wikipedia-style articles). The results demonstrate notable\nperformance improvements across a range of domains. CELI achieved a 4.9\npercentage point improvement over the best reported score of the baseline GPT-4\nmodel on the HumanEval code generation benchmark. In multi-stage content\ngeneration, 94.4% of CELI-produced Wikipedia-style articles met or exceeded\nfirst draft quality when optimally configured, with 44.4% achieving high\nquality. These outcomes underscore CELI's potential for optimizing AI-driven\nworkflows across diverse computational domains.",
      "tldr_zh": "这篇论文介绍了 CELI（Controller-Embedded Language Model Interactions）框架，它将控制逻辑直接嵌入语言模型 (LM) 的提示中，支持复杂多阶段任务的动态执行，并解决传统提示工程的局限性。CELI 允许 LM 自主管理计算工作流，支持任意函数调用和外部系统交互，从而桥接了 LM 的适应性推理能力与传统软件的结构化控制机制。在实验评估中，CELI 在 HumanEval 代码生成基准上比 GPT-4 基准提高了 4.9 百分点，在多阶段内容生成任务中，94.4% 的 Wikipedia-style 文章达到或超过初稿质量，其中 44.4% 达到高水平。这些结果突显了 CELI 在优化 AI 驱动工作流领域的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "68T50, 68Q32, 68N19",
        "I.2.6; I.2.7; D.2.2"
      ],
      "primary_category": "cs.SE",
      "comment": "26 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.14627v1",
      "published_date": "2024-10-18 17:29:56 UTC",
      "updated_date": "2024-10-18 17:29:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:20:15.306604"
    },
    {
      "arxiv_id": "2410.14616v1",
      "title": "Benchmarking Deep Reinforcement Learning for Navigation in Denied Sensor Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Mariusz Wisniewski",
        "Paraskevas Chatzithanos",
        "Weisi Guo",
        "Antonios Tsourdos"
      ],
      "abstract": "Deep Reinforcement learning (DRL) is used to enable autonomous navigation in\nunknown environments. Most research assume perfect sensor data, but real-world\nenvironments may contain natural and artificial sensor noise and denial. Here,\nwe present a benchmark of both well-used and emerging DRL algorithms in a\nnavigation task with configurable sensor denial effects. In particular, we are\ninterested in comparing how different DRL methods (e.g. model-free PPO vs.\nmodel-based DreamerV3) are affected by sensor denial. We show that DreamerV3\noutperforms other methods in the visual end-to-end navigation task with a\ndynamic goal - and other methods are not able to learn this. Furthermore,\nDreamerV3 generally outperforms other methods in sensor-denied environments. In\norder to improve robustness, we use adversarial training and demonstrate an\nimproved performance in denied environments, although this generally comes with\na performance cost on the vanilla environments. We anticipate this benchmark of\ndifferent DRL methods and the usage of adversarial training to be a starting\npoint for the development of more elaborate navigation strategies that are\ncapable of dealing with uncertain and denied sensor readings.",
      "tldr_zh": "本文通过基准测试评估了深度强化学习(DRL)算法在传感器拒绝环境的导航任务中的性能，比较了如model-free PPO和model-based DreamerV3等方法，重点考察它们对传感器噪声和拒绝的影响。结果显示，DreamerV3在视觉端到端导航任务中（尤其是动态目标场景）显著优于其他算法，并在传感器拒绝环境中表现出色，而其他方法难以有效学习。作者还引入了对抗训练(adversarial training)来提升算法的鲁棒性，虽然这会牺牲部分在标准环境下的性能，但为开发更可靠的导航策略提供了重要起点。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "I.2.9"
      ],
      "primary_category": "cs.RO",
      "comment": "31 pages, 19 figures. For associated code, see\n  https://github.com/mazqtpopx/cranfield-navigation-gym",
      "pdf_url": "http://arxiv.org/pdf/2410.14616v1",
      "published_date": "2024-10-18 17:14:28 UTC",
      "updated_date": "2024-10-18 17:14:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:20:27.500001"
    },
    {
      "arxiv_id": "2410.14615v2",
      "title": "Asymptotically Optimal Change Detection for Unnormalized Pre- and Post-Change Distributions",
      "title_zh": "翻译失败",
      "authors": [
        "Arman Adibi",
        "Sanjeev Kulkarni",
        "H. Vincent Poor",
        "Taposh Banerjee",
        "Vahid Tarokh"
      ],
      "abstract": "This paper addresses the problem of detecting changes when only unnormalized\npre- and post-change distributions are accessible. This situation happens in\nmany scenarios in physics such as in ferromagnetism, crystallography,\nmagneto-hydrodynamics, and thermodynamics, where the energy models are\ndifficult to normalize.\n  Our approach is based on the estimation of the Cumulative Sum (CUSUM)\nstatistics, which is known to produce optimal performance. We first present an\nintuitively appealing approximation method. Unfortunately, this produces a\nbiased estimator of the CUSUM statistics and may cause performance degradation.\nWe then propose the Log-Partition Approximation Cumulative Sum (LPA-CUSUM)\nalgorithm based on thermodynamic integration (TI) in order to estimate the\nlog-ratio of normalizing constants of pre- and post-change distributions. It is\nproved that this approach gives an unbiased estimate of the log-partition\nfunction and the CUSUM statistics, and leads to an asymptotically optimal\nperformance. Moreover, we derive a relationship between the required sample\nsize for thermodynamic integration and the desired detection delay performance,\noffering guidelines for practical parameter selection. Numerical studies are\nprovided demonstrating the efficacy of our approach.",
      "tldr_zh": "这篇论文解决了在未归一化预变化和后变化分布下检测变化的问题，这种情况常见于物理领域如铁磁性(crystallography)和热力学(thermodynamics)，其中能量模型难以归一化。论文基于Cumulative Sum (CUSUM)统计量的估计，提出Log-Partition Approximation Cumulative Sum (LPA-CUSUM)算法，利用Thermodynamic Integration (TI)来无偏估计归一化常数的对数比率，从而实现渐进最优性能。作者还推导了TI所需样本大小与检测延迟性能之间的关系，并通过数值实验证明了该方法的有效性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "eess.SP",
        "math.IT"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14615v2",
      "published_date": "2024-10-18 17:13:29 UTC",
      "updated_date": "2025-02-11 06:41:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:20:39.186903"
    },
    {
      "arxiv_id": "2410.16327v1",
      "title": "Feint and Attack: Attention-Based Strategies for Jailbreaking and Protecting LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Pu",
        "Chaozhuo Li",
        "Rui Ha",
        "Zejian Chen",
        "Litian Zhang",
        "Zheng Liu",
        "Lirong Qiu",
        "Xi Zhang"
      ],
      "abstract": "Jailbreak attack can be used to access the vulnerabilities of Large Language\nModels (LLMs) by inducing LLMs to generate the harmful content. And the most\ncommon method of the attack is to construct semantically ambiguous prompts to\nconfuse and mislead the LLMs. To access the security and reveal the intrinsic\nrelation between the input prompt and the output for LLMs, the distribution of\nattention weight is introduced to analyze the underlying reasons. By using\nstatistical analysis methods, some novel metrics are defined to better describe\nthe distribution of attention weight, such as the Attention Intensity on\nSensitive Words (Attn_SensWords), the Attention-based Contextual Dependency\nScore (Attn_DepScore) and Attention Dispersion Entropy (Attn_Entropy). By\nleveraging the distinct characteristics of these metrics, the beam search\nalgorithm and inspired by the military strategy \"Feint and Attack\", an\neffective jailbreak attack strategy named as Attention-Based Attack (ABA) is\nproposed. In the ABA, nested attack prompts are employed to divert the\nattention distribution of the LLMs. In this manner, more harmless parts of the\ninput can be used to attract the attention of the LLMs. In addition, motivated\nby ABA, an effective defense strategy called as Attention-Based Defense (ABD)\nis also put forward. Compared with ABA, the ABD can be used to enhance the\nrobustness of LLMs by calibrating the attention distribution of the input\nprompt. Some comparative experiments have been given to demonstrate the\neffectiveness of ABA and ABD. Therefore, both ABA and ABD can be used to access\nthe security of the LLMs. The comparative experiment results also give a\nlogical explanation that the distribution of attention weight can bring great\ninfluence on the output for LLMs.",
      "tldr_zh": "这篇论文探讨了通过注意力权重分布分析来攻击和保护大型语言模型 (LLMs) 的策略，针对 jailbreak 攻击（诱导 LLMs 生成有害内容）的问题。作者定义了新指标如 Attention Intensity on Sensitive Words (Attn_SensWords)、Attention-based Contextual Dependency Score (Attn_DepScore) 和 Attention Dispersion Entropy (Attn_Entropy)，并提出 Attention-Based Attack (ABA) 策略，灵感来源于“Feint and Attack”军事战术，使用嵌套提示转移模型注意力以提升攻击成功率。同时，论文引入 Attention-Based Defense (ABD) 方法，通过校准注意力分布来增强 LLMs 的鲁棒性。实验结果证明，ABA 和 ABD 均有效，揭示了注意力权重分布对 LLMs 输出结果的显著影响。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16327v1",
      "published_date": "2024-10-18 17:02:13 UTC",
      "updated_date": "2024-10-18 17:02:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:20:51.393921"
    },
    {
      "arxiv_id": "2410.14606v2",
      "title": "Streaming Deep Reinforcement Learning Finally Works",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Elsayed",
        "Gautham Vasan",
        "A. Rupam Mahmood"
      ],
      "abstract": "Natural intelligence processes experience as a continuous stream, sensing,\nacting, and learning moment-by-moment in real time. Streaming learning, the\nmodus operandi of classic reinforcement learning (RL) algorithms like\nQ-learning and TD, mimics natural learning by using the most recent sample\nwithout storing it. This approach is also ideal for resource-constrained,\ncommunication-limited, and privacy-sensitive applications. However, in deep RL,\nlearners almost always use batch updates and replay buffers, making them\ncomputationally expensive and incompatible with streaming learning. Although\nthe prevalence of batch deep RL is often attributed to its sample efficiency, a\nmore critical reason for the absence of streaming deep RL is its frequent\ninstability and failure to learn, which we refer to as stream barrier. This\npaper introduces the stream-x algorithms, the first class of deep RL algorithms\nto overcome stream barrier for both prediction and control and match sample\nefficiency of batch RL. Through experiments in Mujoco Gym, DM Control Suite,\nand Atari Games, we demonstrate stream barrier in existing algorithms and\nsuccessful stable learning with our stream-x algorithms: stream Q, stream AC,\nand stream TD, achieving the best model-free performance in DM Control Dog\nenvironments. A set of common techniques underlies the stream-x algorithms,\nenabling their success with a single set of hyperparameters and allowing for\neasy extension to other algorithms, thereby reviving streaming RL.",
      "tldr_zh": "该论文揭示了深度强化学习（deep RL）中流式学习的不稳定性问题，即“stream barrier”，这导致现有算法难以实现实时、资源高效的学习。作者引入了 stream-x 算法系列，包括 stream Q、stream AC 和 stream TD，这是首个克服 stream barrier 的深度 RL 方法，能够匹配批量 RL 的样本效率，同时避免使用重放缓冲区。实验在 Mujoco Gym、DM Control Suite 和 Atari Games 等环境中证明，stream-x 算法实现了稳定学习，并在 DM Control Dog 环境中取得了最佳的无模型性能。这些创新技术使用单一超参数集，并易于扩展，从而复兴了流式 RL，为资源受限和隐私敏感的应用提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14606v2",
      "published_date": "2024-10-18 17:00:29 UTC",
      "updated_date": "2024-12-06 00:55:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:21:03.927487"
    },
    {
      "arxiv_id": "2410.14602v1",
      "title": "How Does Data Diversity Shape the Weight Landscape of Neural Networks?",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Ba",
        "Michelle V. Mancenido",
        "Rong Pan"
      ],
      "abstract": "To enhance the generalization of machine learning models to unseen data,\ntechniques such as dropout, weight decay ($L_2$ regularization), and noise\naugmentation are commonly employed. While regularization methods (i.e., dropout\nand weight decay) are geared toward adjusting model parameters to prevent\noverfitting, data augmentation increases the diversity of the input training\nset, a method purported to improve accuracy and calibration error. In this\npaper, we investigate the impact of each of these techniques on the parameter\nspace of neural networks, with the goal of understanding how they alter the\nweight landscape in transfer learning scenarios. To accomplish this, we employ\nRandom Matrix Theory to analyze the eigenvalue distributions of pre-trained\nmodels, fine-tuned using these techniques but using different levels of data\ndiversity, for the same downstream tasks. We observe that diverse data\ninfluences the weight landscape in a similar fashion as dropout. Additionally,\nwe compare commonly used data augmentation methods with synthetic data created\nby generative models. We conclude that synthetic data can bring more diversity\ninto real input data, resulting in a better performance on out-of-distribution\ntest instances.",
      "tldr_zh": "本研究探讨了数据多样性如何影响神经网络的权重景观（weight landscape），通过比较dropout、weight decay ($L_2$ regularization) 和数据增强（data augmentation）等技术在转移学习场景中的作用。作者使用Random Matrix Theory分析预训练模型的特征值分布，发现数据多样性对权重景观的影响类似于dropout，能够有效防止过拟合。实验结果表明，相比传统数据增强方法，生成模型创建的合成数据能带来更多多样性，从而在分布外（out-of-distribution）测试实例上显著提升模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14602v1",
      "published_date": "2024-10-18 16:57:05 UTC",
      "updated_date": "2024-10-18 16:57:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:21:14.258014"
    },
    {
      "arxiv_id": "2410.14596v2",
      "title": "Teaching Models to Balance Resisting and Accepting Persuasion",
      "title_zh": "翻译失败",
      "authors": [
        "Elias Stengel-Eskin",
        "Peter Hase",
        "Mohit Bansal"
      ],
      "abstract": "Large language models (LLMs) are susceptible to persuasion, which can pose\nrisks when models are faced with an adversarial interlocutor. We take a first\nstep towards defending models against persuasion while also arguing that\ndefense against adversarial (i.e. negative) persuasion is only half of the\nequation: models should also be able to accept beneficial (i.e. positive)\npersuasion to improve their answers. We show that optimizing models for only\none side results in poor performance on the other. In order to balance positive\nand negative persuasion, we introduce Persuasion-Training (or PBT), which\nleverages multi-agent recursive dialogue trees to create data and trains models\nvia preference optimization to accept persuasion when appropriate. PBT allows\nus to use data generated from dialogues between smaller 7-8B models for\ntraining much larger 70B models. Moreover, PBT consistently improves resistance\nto misinformation and resilience to being challenged while also resulting in\nthe best overall performance on holistic data containing both positive and\nnegative persuasion. Crucially, we show that PBT models are better teammates in\nmulti-agent debates across two domains (trivia and commonsense QA). We find\nthat without PBT, pairs of stronger and weaker models have unstable\nperformance, with the order in which the models present their answers\ndetermining whether the team obtains the stronger or weaker model's\nperformance. PBT leads to better and more stable results and less order\ndependence, with the stronger model consistently pulling the weaker one up.",
      "tldr_zh": "这篇论文探讨了大语言模型（LLMs）在面对说服时容易受影响的风险，提出需要平衡抵抗负面说服（如错误信息）和接受正面说服（如改善答案）。为了实现这一平衡，作者引入了Persuasion-Training (PBT) 方法，该方法利用多代理递归对话树生成数据，并通过偏好优化训练模型，使其在适当情况下接受有益说服。实验结果显示，PBT显著提升了模型对误导的抵抗力、在辩论中的团队表现，并在琐事和常识QA领域使强弱模型配对更稳定，弱模型能从强模型中获益。总的来说，PBT为构建更可靠的LLMs提供了有效框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL Camera-Ready. Code:\n  https://github.com/esteng/persuasion_balanced_training",
      "pdf_url": "http://arxiv.org/pdf/2410.14596v2",
      "published_date": "2024-10-18 16:49:36 UTC",
      "updated_date": "2025-02-10 14:09:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:21:26.905171"
    },
    {
      "arxiv_id": "2410.14593v1",
      "title": "Temporal Fair Division of Indivisible Items",
      "title_zh": "翻译失败",
      "authors": [
        "Edith Elkind",
        "Alexander Lam",
        "Mohamad Latifian",
        "Tzeh Yuan Neoh",
        "Nicholas Teh"
      ],
      "abstract": "We study a fair division model where indivisible items arrive sequentially,\nand must be allocated immediately and irrevocably. Previous work on online fair\ndivision has shown impossibility results in achieving approximate envy-freeness\nunder these constraints. In contrast, we consider an informed setting where the\nalgorithm has complete knowledge of future items, and aim to ensure that the\ncumulative allocation at each round satisfies approximate envy-freeness --\nwhich we define as temporal envy-freeness up to one item (TEF1). We focus on\nsettings where items can be exclusively goods or exclusively chores. For goods,\nwhile TEF1 allocations may not always exist, we identify several special cases\nwhere they do -- two agents, two item types, generalized binary valuations,\nunimodal preferences -- and provide polynomial-time algorithms for these cases.\nWe also prove that determining the existence of a TEF1 allocation is NP-hard.\nFor chores, we establish analogous results for the special cases, but present a\nslightly weaker intractability result. We also establish the incompatibility\nbetween TEF1 and Pareto-optimality, with the implication that it is intractable\nto find a TEF1 allocation that maximizes any $p$-mean welfare, even for two\nagents.",
      "tldr_zh": "这篇论文研究了不可分割物品的在线公平分配问题，其中物品按顺序到达且必须立即分配，目标是实现 temporal envy-freeness up to one item (TEF1)，即每个回合的累计分配近似无羡慕。作者考虑了算法完全知晓未来物品的场景，专注于纯 goods 或纯 chores 的设置，并为 goods 的特例（如两个代理、两种物品类型、广义二进制估值或单峰偏好）提供了多项式时间算法，同时证明了判断 TEF1 分配存在是 NP-hard。论文还发现，对于 chores 类似结果成立，但 TEF1 与 Pareto-optimality 不兼容，甚至对于两个代理，最大化任何 p-均福利的 TEF1 分配也是 intractable。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14593v1",
      "published_date": "2024-10-18 16:43:36 UTC",
      "updated_date": "2024-10-18 16:43:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:21:40.126282"
    },
    {
      "arxiv_id": "2410.14586v1",
      "title": "Neural Combinatorial Clustered Bandits for Recommendation Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Baran Atalar",
        "Carlee Joe-Wong"
      ],
      "abstract": "We consider the contextual combinatorial bandit setting where in each round,\nthe learning agent, e.g., a recommender system, selects a subset of \"arms,\"\ne.g., products, and observes rewards for both the individual base arms, which\nare a function of known features (called \"context\"), and the super arm (the\nsubset of arms), which is a function of the base arm rewards. The agent's goal\nis to simultaneously learn the unknown reward functions and choose the\nhighest-reward arms. For example, the \"reward\" may represent a user's\nprobability of clicking on one of the recommended products. Conventional bandit\nmodels, however, employ restrictive reward function models in order to obtain\nperformance guarantees. We make use of deep neural networks to estimate and\nlearn the unknown reward functions and propose Neural UCB Clustering\n(NeUClust), which adopts a clustering approach to select the super arm in every\nround by exploiting underlying structure in the context space. Unlike prior\nneural bandit works, NeUClust uses a neural network to estimate the super arm\nreward and select the super arm, thus eliminating the need for a known\noptimization oracle. We non-trivially extend prior neural combinatorial bandit\nworks to prove that NeUClust achieves\n$\\widetilde{O}\\left(\\widetilde{d}\\sqrt{T}\\right)$ regret, where $\\widetilde{d}$\nis the effective dimension of a neural tangent kernel matrix, $T$ the number of\nrounds. Experiments on real world recommendation datasets show that NeUClust\nachieves better regret and reward than other contextual combinatorial and\nneural bandit algorithms.",
      "tldr_zh": "本研究探讨了应用于推荐系统的上下文组合式老虎机（contextual combinatorial bandit）问题，旨在同时学习未知奖励函数并选择最高奖励的arms子集。作者提出Neural UCB Clustering (NeUClust)算法，利用深度神经网络估计奖励函数，并通过聚类方法利用上下文空间的结构来选择super arm，从而无需依赖已知的优化预言机。NeUClust证明了遗憾界为$\\widetilde{O}\\left(\\widetilde{d}\\sqrt{T}\\right)$，并在真实推荐数据集上的实验中，表现出比其他上下文组合式和神经老虎机算法更好的遗憾和奖励性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14586v1",
      "published_date": "2024-10-18 16:37:28 UTC",
      "updated_date": "2024-10-18 16:37:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:21:51.305665"
    },
    {
      "arxiv_id": "2410.14584v1",
      "title": "MCSFF: Multi-modal Consistency and Specificity Fusion Framework for Entity Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Ai",
        "Wen Deng",
        "Hongyi Chen",
        "Jiayi Du",
        "Tao Meng",
        "Yuntao Shou"
      ],
      "abstract": "Multi-modal entity alignment (MMEA) is essential for enhancing knowledge\ngraphs and improving information retrieval and question-answering systems.\nExisting methods often focus on integrating modalities through their\ncomplementarity but overlook the specificity of each modality, which can\nobscure crucial features and reduce alignment accuracy. To solve this, we\npropose the Multi-modal Consistency and Specificity Fusion Framework (MCSFF),\nwhich innovatively integrates both complementary and specific aspects of\nmodalities. We utilize Scale Computing's hyper-converged infrastructure to\noptimize IT management and resource allocation in large-scale data processing.\nOur framework first computes similarity matrices for each modality using\nmodality embeddings to preserve their unique characteristics. Then, an\niterative update method denoises and enhances modality features to fully\nexpress critical information. Finally, we integrate the updated information\nfrom all modalities to create enriched and precise entity representations.\nExperiments show our method outperforms current state-of-the-art MMEA baselines\non the MMKG dataset, demonstrating its effectiveness and practical potential.",
      "tldr_zh": "本研究针对多模态实体对齐(MMEA)存在的特定性忽略问题，提出了一种多模态一致性和特定性融合框架(MCSFF)，它创新性地整合模态的互补性和独特特性，以提升实体对齐的准确率。该框架首先计算每个模态的相似性矩阵，使用模态嵌入保留其独特特征，然后通过迭代更新方法去噪和增强特征，最后整合更新后的信息生成精确的实体表示。实验结果显示，MCSFF 在 MMKG 数据集上超过了现有最先进基线方法，证明了其在知识图谱增强和信息检索方面的实际潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 1 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.14584v1",
      "published_date": "2024-10-18 16:35:25 UTC",
      "updated_date": "2024-10-18 16:35:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:22:04.972972"
    },
    {
      "arxiv_id": "2410.14582v4",
      "title": "Do LLMs estimate uncertainty well in instruction-following?",
      "title_zh": "LLMs 在指令遵循中是否良好估计不确定性？",
      "authors": [
        "Juyeon Heo",
        "Miao Xiong",
        "Christina Heinze-Deml",
        "Jaya Narain"
      ],
      "abstract": "Large language models (LLMs) could be valuable personal AI agents across\nvarious domains, provided they can precisely follow user instructions. However,\nrecent studies have shown significant limitations in LLMs'\ninstruction-following capabilities, raising concerns about their reliability in\nhigh-stakes applications. Accurately estimating LLMs' uncertainty in adhering\nto instructions is critical to mitigating deployment risks. We present, to our\nknowledge, the first systematic evaluation of the uncertainty estimation\nabilities of LLMs in the context of instruction-following. Our study identifies\nkey challenges with existing instruction-following benchmarks, where multiple\nfactors are entangled with uncertainty stems from instruction-following,\ncomplicating the isolation and comparison across methods and models. To address\nthese issues, we introduce a controlled evaluation setup with two benchmark\nversions of data, enabling a comprehensive comparison of uncertainty estimation\nmethods under various conditions. Our findings show that existing uncertainty\nmethods struggle, particularly when models make subtle errors in instruction\nfollowing. While internal model states provide some improvement, they remain\ninadequate in more complex scenarios. The insights from our controlled\nevaluation setups provide a crucial understanding of LLMs' limitations and\npotential for uncertainty estimation in instruction-following tasks, paving the\nway for more trustworthy AI agents.",
      "tldr_zh": "这篇论文首次系统评估大型语言模型 (LLMs) 在遵循指令时的不确定性估计能力，以解决其在高风险应用中的可靠性问题。研究者引入了一个受控评估设置，包括两个基准版本的数据，用于隔离不确定性因素并比较不同不确定性估计方法。结果显示，现有的不确定性方法在处理微妙指令遵循错误时表现不佳，尽管利用内部模型状态有所改善，但仍难以应对复杂场景。该研究为提升 LLMs 的可信度并开发更可靠的 AI 代理提供了关键洞见。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14582v4",
      "published_date": "2024-10-18 16:32:10 UTC",
      "updated_date": "2025-03-28 15:50:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:22:14.613845"
    },
    {
      "arxiv_id": "2410.14581v3",
      "title": "Optimizing Attention with Mirror Descent: Generalized Max-Margin Token Selection",
      "title_zh": "使用镜像下降优化注意力：广义最大边距标记选择",
      "authors": [
        "Addison Kristanto Julistiono",
        "Davoud Ataee Tarzanagh",
        "Navid Azizan"
      ],
      "abstract": "Attention mechanisms have revolutionized several domains of artificial\nintelligence, such as natural language processing and computer vision, by\nenabling models to selectively focus on relevant parts of the input data. While\nrecent work has characterized the optimization dynamics of gradient descent\n(GD) in attention-based models and the structural properties of its preferred\nsolutions, less is known about more general optimization algorithms such as\nmirror descent (MD). In this paper, we investigate the convergence properties\nand implicit biases of a family of MD algorithms tailored for softmax attention\nmechanisms, with the potential function chosen as the $p$-th power of the\n$\\ell_p$-norm. Specifically, we show that these algorithms converge in\ndirection to a generalized hard-margin SVM with an $\\ell_p$-norm objective when\napplied to a classification problem using a softmax attention model. Notably,\nour theoretical results reveal that the convergence rate is comparable to that\nof traditional GD in simpler models, despite the highly nonlinear and nonconvex\nnature of the present problem. Additionally, we delve into the joint\noptimization dynamics of the key-query matrix and the decoder, establishing\nconditions under which this complex joint optimization converges to their\nrespective hard-margin SVM solutions. Lastly, our numerical experiments on real\ndata demonstrate that MD algorithms improve generalization over standard GD and\nexcel in optimal token selection.",
      "tldr_zh": "本论文探讨了使用 Mirror Descent (MD) 算法优化注意力机制的问题，针对 softmax attention 模型通过 p-th power of the ℓ_p-norm 作为势函数。研究证明，MD 算法在分类任务中收敛到一个广义的 hard-margin SVM 解，且其收敛率与 gradient descent (GD) 相当，尽管面临高度非线性非凸挑战。论文还分析了 key-query 矩阵和解码器的联合优化动态，确立了收敛到各自 hard-margin SVM 解的条件。实验结果显示，MD 算法在真实数据上改善了模型泛化性能，并在 optimal token selection 方面优于标准 GD。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14581v3",
      "published_date": "2024-10-18 16:32:06 UTC",
      "updated_date": "2025-03-21 13:15:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:22:28.401537"
    },
    {
      "arxiv_id": "2410.14579v1",
      "title": "Towards Unsupervised Validation of Anomaly-Detection Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lihi Idan"
      ],
      "abstract": "Unsupervised validation of anomaly-detection models is a highly challenging\ntask. While the common practices for model validation involve a labeled\nvalidation set, such validation sets cannot be constructed when the underlying\ndatasets are unlabeled. The lack of robust and efficient unsupervised\nmodel-validation techniques presents an acute challenge in the implementation\nof automated anomaly-detection pipelines, especially when there exists no prior\nknowledge of the model's performance on similar datasets. This work presents a\nnew paradigm to automated validation of anomaly-detection models, inspired by\nreal-world, collaborative decision-making mechanisms. We focus on two\ncommonly-used, unsupervised model-validation tasks -- model selection and model\nevaluation -- and provide extensive experimental results that demonstrate the\naccuracy and robustness of our approach on both tasks.",
      "tldr_zh": "该研究探讨了无监督验证异常-detection模型的挑战，因为传统方法依赖于带标签的验证集，而无标签数据集无法构建这种集。论文提出一个新范式，受现实世界协作决策机制启发，针对模型选择和模型评估任务，开发了自动化验证方法。实验结果显示，该方法在准确性和鲁棒性方面表现出色，为无监督异常-detection管道的实现提供了可靠解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14579v1",
      "published_date": "2024-10-18 16:27:04 UTC",
      "updated_date": "2024-10-18 16:27:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:22:37.995888"
    },
    {
      "arxiv_id": "2410.14578v1",
      "title": "Large Language Models Are Overparameterized Text Encoders",
      "title_zh": "大语言模型是过度参数化的文本编码器",
      "authors": [
        "Thennal D K",
        "Tim Fischer",
        "Chris Biemann"
      ],
      "abstract": "Large language models (LLMs) demonstrate strong performance as text embedding\nmodels when finetuned with supervised contrastive training. However, their\nlarge size balloons inference time and memory requirements. In this paper, we\nshow that by pruning the last $p\\%$ layers of an LLM before supervised training\nfor only 1000 steps, we can achieve a proportional reduction in memory and\ninference time. We evaluate four different state-of-the-art LLMs on text\nembedding tasks and find that our method can prune up to 30\\% of layers with\nnegligible impact on performance and up to 80\\% with only a modest drop. With\nonly three lines of code, our method is easily implemented in any pipeline for\ntransforming LLMs to text encoders. We also propose $\\text{L}^3 \\text{Prune}$,\na novel layer-pruning strategy based on the model's initial loss that provides\ntwo optimal pruning configurations: a large variant with negligible performance\nloss and a small variant for resource-constrained settings. On average, the\nlarge variant prunes 21\\% of the parameters with a $-0.3$ performance drop, and\nthe small variant only suffers from a $-5.1$ decrease while pruning 74\\% of the\nmodel. We consider these results strong evidence that LLMs are\noverparameterized for text embedding tasks, and can be easily pruned.",
      "tldr_zh": "本研究发现，大语言模型 (LLMs) 在经过监督对比训练 (supervised contrastive training) 后，作为文本嵌入模型表现出色，但其过大尺寸导致推理时间和内存消耗显著增加。作者提出一种简单方法，通过在监督训练前修剪 LLMs 的最后 p% 层并仅训练 1000 步，即可实现内存和推理时间的比例减少，并在四种最先进 LLMs 的文本嵌入任务上评估。实验结果显示，该方法可修剪多达 30% 的层而几乎不影响性能，修剪 80% 时仅带来适度下降。作者进一步引入 L3 Prune 策略，基于模型初始损失提供两种最佳配置：大变体修剪 21% 参数仅损失 -0.3 性能，小变体修剪 74% 参数损失 -5.1，为资源受限场景优化。总之，这证明 LLMs 在文本嵌入任务中过度参数化，可通过简单修剪轻松提升效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages of content + 1 for limitations and ethical considerations, 14\n  pages in total including references and appendix, 5+1 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.14578v1",
      "published_date": "2024-10-18 16:26:45 UTC",
      "updated_date": "2024-10-18 16:26:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:22:55.667727"
    },
    {
      "arxiv_id": "2410.14574v1",
      "title": "MomentumSMoE: Integrating Momentum into Sparse Mixture of Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Rachel S. Y. Teo",
        "Tan M. Nguyen"
      ],
      "abstract": "Sparse Mixture of Experts (SMoE) has become the key to unlocking unparalleled\nscalability in deep learning. SMoE has the potential to exponentially increase\nparameter count while maintaining the efficiency of the model by only\nactivating a small subset of these parameters for a given sample. However, it\nhas been observed that SMoE suffers from unstable training and has difficulty\nadapting to new distributions, leading to the model's lack of robustness to\ndata contamination. To overcome these limitations, we first establish a\nconnection between the dynamics of the expert representations in SMoEs and\ngradient descent on a multi-objective optimization problem. Leveraging our\nframework, we then integrate momentum into SMoE and propose a new family of\nSMoEs named MomentumSMoE. We theoretically prove and numerically demonstrate\nthat MomentumSMoE is more stable and robust than SMoE. In particular, we verify\nthe advantages of MomentumSMoE over SMoE on a variety of practical tasks\nincluding ImageNet-1K object recognition and WikiText-103 language modeling. We\ndemonstrate the applicability of MomentumSMoE to many types of SMoE models,\nincluding those in the Sparse MoE model for vision (V-MoE) and the Generalist\nLanguage Model (GLaM). We also show that other advanced momentum-based\noptimization methods, such as Adam, can be easily incorporated into the\nMomentumSMoE framework for designing new SMoE models with even better\nperformance, almost negligible additional computation cost, and simple\nimplementations.",
      "tldr_zh": "本论文针对Sparse Mixture of Experts (SMoE)模型的训练不稳定性和对新分布适应困难的问题，建立了专家表示动态与多目标优化问题的梯度下降联系，并提出MomentumSMoE框架，通过整合momentum机制来提升模型的稳定性和鲁棒性。研究理论证明了MomentumSMoE的优越性，并在ImageNet-1K图像识别和WikiText-103语言建模等任务上实验验证，其性能比SMoE提高了显著效果。MomentumSMoE可轻松应用于多种SMoE模型，如V-MoE和GLaM，并支持整合其他优化方法如Adam，实现性能提升的同时保持计算开销几乎忽略不计和实现简单。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages in the main text. Published at NeurIPS 2024. The code is\n  available at https://github.com/rachtsy/MomentumSMoE",
      "pdf_url": "http://arxiv.org/pdf/2410.14574v1",
      "published_date": "2024-10-18 16:20:22 UTC",
      "updated_date": "2024-10-18 16:20:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:25:04.017791"
    },
    {
      "arxiv_id": "2410.14573v1",
      "title": "Building Trust in Black-box Optimization: A Comprehensive Framework for Explainability",
      "title_zh": "构建黑箱优化的信任：一个全面的解释性框架",
      "authors": [
        "Nazanin Nezami",
        "Hadis Anahideh"
      ],
      "abstract": "Optimizing costly black-box functions within a constrained evaluation budget\npresents significant challenges in many real-world applications. Surrogate\nOptimization (SO) is a common resolution, yet its proprietary nature introduced\nby the complexity of surrogate models and the sampling core (e.g., acquisition\nfunctions) often leads to a lack of explainability and transparency. While\nexisting literature has primarily concentrated on enhancing convergence to\nglobal optima, the practical interpretation of newly proposed strategies\nremains underexplored, especially in batch evaluation settings. In this paper,\nwe propose \\emph{Inclusive} Explainability Metrics for Surrogate Optimization\n(IEMSO), a comprehensive set of model-agnostic metrics designed to enhance the\ntransparency, trustworthiness, and explainability of the SO approaches. Through\nthese metrics, we provide both intermediate and post-hoc explanations to\npractitioners before and after performing expensive evaluations to gain trust.\nWe consider four primary categories of metrics, each targeting a specific\naspect of the SO process: Sampling Core Metrics, Batch Properties Metrics,\nOptimization Process Metrics, and Feature Importance. Our experimental\nevaluations demonstrate the significant potential of the proposed metrics\nacross different benchmarks.",
      "tldr_zh": "本论文针对黑箱优化中 Surrogate Optimization (SO) 的复杂性导致的可解释性和透明度不足问题，提出 IEMSO（Inclusive Explainability Metrics for Surrogate Optimization）框架，这是一个全面的模型无关指标集。IEMSO 包括四个类别：Sampling Core Metrics、Batch Properties Metrics、Optimization Process Metrics 和 Feature Importance，用于提供中间和事后解释，帮助从业者在昂贵评估前后提升信任。实验结果显示，这些指标在不同基准上表现出色，显著改善了 SO 策略的透明度和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14573v1",
      "published_date": "2024-10-18 16:20:17 UTC",
      "updated_date": "2024-10-18 16:20:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:23:15.193233"
    },
    {
      "arxiv_id": "2410.14571v2",
      "title": "TransBox: EL++-closed Ontology Embedding",
      "title_zh": "翻译失败",
      "authors": [
        "Hui Yang",
        "Jiaoyan Chen",
        "Uli Sattler"
      ],
      "abstract": "OWL (Web Ontology Language) ontologies, which are able to represent both\nrelational and type facts as standard knowledge graphs and complex domain\nknowledge in Description Logic (DL) axioms, are widely adopted in domains such\nas healthcare and bioinformatics. Inspired by the success of knowledge graph\nembeddings, embedding OWL ontologies has gained significant attention in recent\nyears. Current methods primarily focus on learning embeddings for atomic\nconcepts and roles, enabling the evaluation based on normalized axioms through\nspecially designed score functions. However, they often neglect the embedding\nof complex concepts, making it difficult to infer with more intricate axioms.\nThis limitation reduces their effectiveness in advanced reasoning tasks, such\nas Ontology Learning and ontology-mediated Query Answering. In this paper, we\npropose EL++-closed ontology embeddings which are able to represent any logical\nexpressions in DL via composition. Furthermore, we develop TransBox, an\neffective EL++-closed ontology embedding method that can handle many-to-one,\none-to-many and many-to-many relations. Our extensive experiments demonstrate\nthat TransBox often achieves state-of-the-art performance across various\nreal-world datasets for predicting complex axioms.",
      "tldr_zh": "本论文针对 OWL 本体嵌入问题，指出现有方法主要关注原子概念和角色嵌入，而忽略复杂概念，导致在高级推理任务（如本体学习和查询回答）中效果有限。作者提出 EL++-closed ontology embeddings 技术，能够通过组合表示任何逻辑表达式，从而支持复杂公理的推理。TransBox 作为一种新颖的嵌入方法，能处理 many-to-one、one-to-many 和 many-to-many 关系，并在多个真实数据集上实验中实现了预测复杂公理的最先进性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14571v2",
      "published_date": "2024-10-18 16:17:10 UTC",
      "updated_date": "2025-02-04 09:01:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:23:27.845559"
    },
    {
      "arxiv_id": "2410.14569v3",
      "title": "When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Hanna Kim",
        "Minkyoo Song",
        "Seung Ho Na",
        "Seungwon Shin",
        "Kimin Lee"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have established them as\nagentic systems capable of planning and interacting with various tools. These\nLLM agents are often paired with web-based tools, enabling access to diverse\nsources and real-time information. Although these advancements offer\nsignificant benefits across various applications, they also increase the risk\nof malicious use, particularly in cyberattacks involving personal information.\nIn this work, we investigate the risks associated with misuse of LLM agents in\ncyberattacks involving personal data. Specifically, we aim to understand: 1)\nhow potent LLM agents can be when directed to conduct cyberattacks, 2) how\ncyberattacks are enhanced by web-based tools, and 3) how affordable and easy it\nbecomes to launch cyberattacks using LLM agents. We examine three attack\nscenarios: the collection of Personally Identifiable Information (PII), the\ngeneration of impersonation posts, and the creation of spear-phishing emails.\nOur experiments reveal the effectiveness of LLM agents in these attacks: LLM\nagents achieved a precision of up to 95.9% in collecting PII, generated\nimpersonation posts where 93.9% of them were deemed authentic, and boosted\nclick rate of phishing links in spear phishing emails by 46.67%. Additionally,\nour findings underscore the limitations of existing safeguards in contemporary\ncommercial LLMs, emphasizing the urgent need for robust security measures to\nprevent the misuse of LLM agents.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 与网络工具结合后，在网络攻击中的潜在风险，特别是涉及个人信息的滥用。研究人员通过实验三种攻击场景——收集 Personally Identifiable Information (PII)、生成冒充帖子和创建针对性网络钓鱼邮件——评估了 LLMs 代理的有效性。结果显示，LLMs 代理在这些攻击中表现出极高效率，例如 PII 收集精度达 95.9%、冒充帖子真实性达 93.9%，并使网络钓鱼邮件点击率提高 46.67%。论文强调，现有的 LLMs 安全措施存在局限，呼吁开发更 robust 的防护机制以防范此类威胁。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "20 pages, To appear in Usenix Security 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.14569v3",
      "published_date": "2024-10-18 16:16:34 UTC",
      "updated_date": "2025-02-03 06:52:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:23:39.604900"
    },
    {
      "arxiv_id": "2410.14567v4",
      "title": "ELOQ: Resources for Enhancing LLM Detection of Out-of-Scope Questions",
      "title_zh": "ELOQ：用于增强 LLM 检测超出范围问题的资源",
      "authors": [
        "Zhiyuan Peng",
        "Jinming Nian",
        "Alexandre Evfimievski",
        "Yi Fang"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has become integral to large language\nmodels (LLMs), particularly for conversational AI systems where user questions\nmay reference knowledge beyond the LLMs' training cutoff. However, many natural\nuser questions lack well-defined answers, either due to limited domain\nknowledge or because the retrieval system returns documents that are relevant\nin appearance but uninformative in content. In such cases, LLMs often produce\nhallucinated answers without flagging them. While recent work has largely\nfocused on questions with false premises, we study out-of-scope questions,\nwhere the retrieved document appears semantically similar to the question but\nlacks the necessary information to answer it. In this paper, we propose a\nguided hallucination-based approach ELOQ to automatically generate a diverse\nset of out-of-scope questions from post-cutoff documents, followed by human\nverification to ensure quality. We use this dataset to evaluate several LLMs on\ntheir ability to detect out-of-scope questions and generate appropriate\nresponses. Finally, we introduce an improved detection method that enhances the\nreliability of LLM-based question-answering systems in handling out-of-scope\nquestions.",
      "tldr_zh": "本研究针对大型语言模型(LLM)处理超出范围(out-of-scope)问题的挑战，提出ELOQ资源，以提升模型对这类问题的检测能力。ELOQ采用guided hallucination-based approach，从训练截止后的文档中自动生成多样化的out-of-scope问题，并通过人工验证确保数据集质量。研究利用该数据集评估多个LLM在检测out-of-scope问题和生成适当响应的表现，并引入一种改进的检测方法。结果表明，此方法显著提高了LLM-based问答系统的可靠性和准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by SIGIR'25",
      "pdf_url": "http://arxiv.org/pdf/2410.14567v4",
      "published_date": "2024-10-18 16:11:29 UTC",
      "updated_date": "2025-05-04 04:28:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:25:22.243035"
    },
    {
      "arxiv_id": "2410.14766v1",
      "title": "Evaluating Quantized Large Language Models for Code Generation on Low-Resource Language Benchmarks",
      "title_zh": "评估量化的大型语言模型在低资源语言基准上的代码生成性能",
      "authors": [
        "Enkhbold Nyamsuren"
      ],
      "abstract": "Democratization of AI is an important topic within the broader topic of the\ndigital divide. This issue is relevant to LLMs, which are becoming popular as\nAI co-pilots but suffer from a lack of accessibility due to high computational\ndemand. In this study, we evaluate whether quantization is a viable approach\ntoward enabling LLMs on generic consumer devices. The study assesses the\nperformance of five quantized code LLMs in Lua code generation tasks. To\nevaluate the impact of quantization, the models with 7B parameters were tested\non a consumer laptop at 2-, 4-, and 8-bit integer precisions and compared to\nnon-quantized code LLMs with 1.3, 2, and 3 billion parameters. Lua is chosen as\na low-level resource language to avoid models' biases related to high-resource\nlanguages. The results suggest that the models quantized at the 4-bit integer\nprecision offer the best trade-off between performance and model size. These\nmodels can be comfortably deployed on an average laptop without a dedicated\nGPU. The performance significantly drops at the 2-bit integer precision. The\nmodels at 8-bit integer precision require more inference time that does not\neffectively translate to better performance. The 4-bit models with 7 billion\nparameters also considerably outperform non-quantized models with lower\nparameter numbers despite having comparable model sizes with respect to storage\nand memory demand. While quantization indeed increases the accessibility of\nsmaller LLMs with 7 billion parameters, these LLMs demonstrate overall low\nperformance (less than 50\\%) on high-precision and low-resource tasks such as\nLua code generation. While accessibility is improved, usability is still not at\nthe practical level comparable to foundational LLMs such as GPT-4o or Llama 3.1\n405B.",
      "tldr_zh": "这篇论文评估了量化大型语言模型（LLMs）在低资源语言（如 Lua）代码生成任务中的性能，以提升 AI 的可访问性和民主化。研究方法包括测试五个 7B 参数的量化代码 LLMs，在 2-, 4- 和 8-bit 整数精度下运行，并与 1.3B、2B 和 3B 参数的非量化模型进行比较。结果表明，4-bit 量化提供最佳性能与模型大小权衡，能在普通笔记本电脑上部署，且这些模型在存储和内存需求上优于同等大小的非量化模型；然而，量化模型在 Lua 代码生成上的整体准确率低于 50%，仍远不及 GPT-4o 或 Llama 3.1 405B 等基础模型的实用水平。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14766v1",
      "published_date": "2024-10-18 15:50:59 UTC",
      "updated_date": "2024-10-18 15:50:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:25:22.583621"
    },
    {
      "arxiv_id": "2410.14548v1",
      "title": "Boosting K-means for Big Data by Fusing Data Streaming with Global Optimization",
      "title_zh": "通过融合数据流与全局优化提升大数据中的 K-means",
      "authors": [
        "Ravil Mussabayev",
        "Rustam Mussabayev"
      ],
      "abstract": "K-means clustering is a cornerstone of data mining, but its efficiency\ndeteriorates when confronted with massive datasets. To address this limitation,\nwe propose a novel heuristic algorithm that leverages the Variable Neighborhood\nSearch (VNS) metaheuristic to optimize K-means clustering for big data. Our\napproach is based on the sequential optimization of the partial objective\nfunction landscapes obtained by restricting the Minimum Sum-of-Squares\nClustering (MSSC) formulation to random samples from the original big dataset.\nWithin each landscape, systematically expanding neighborhoods of the currently\nbest (incumbent) solution are explored by reinitializing all degenerate and a\nvarying number of additional centroids. Extensive and rigorous experimentation\non a large number of real-world datasets reveals that by transforming the\ntraditional local search into a global one, our algorithm significantly\nenhances the accuracy and efficiency of K-means clustering in big data\nenvironments, becoming the new state of the art in the field.",
      "tldr_zh": "本研究针对 K-means 聚类在处理大数据时效率低下的问题，提出了一种新启发式算法，通过融合数据流和全局优化来提升性能。该算法利用 Variable Neighborhood Search (VNS) 元启发式，对随机样本的 Minimum Sum-of-Squares Clustering (MSSC) 公式进行顺序优化，并在每个局部优化中通过重新初始化中心点来探索扩展邻域。实验在大量真实数据集上证明，该方法将传统局部搜索转化为全局搜索，大大提高了 K-means 的准确性和效率，成为该领域的新的最先进技术。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14548v1",
      "published_date": "2024-10-18 15:43:34 UTC",
      "updated_date": "2024-10-18 15:43:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:24:15.831177"
    },
    {
      "arxiv_id": "2410.14545v1",
      "title": "Tell me what I need to know: Exploring LLM-based (Personalized) Abstractive Multi-Source Meeting Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Frederic Kirstein",
        "Terry Ruas",
        "Robert Kratel",
        "Bela Gipp"
      ],
      "abstract": "Meeting summarization is crucial in digital communication, but existing\nsolutions struggle with salience identification to generate personalized,\nworkable summaries, and context understanding to fully comprehend the meetings'\ncontent. Previous attempts to address these issues by considering related\nsupplementary resources (e.g., presentation slides) alongside transcripts are\nhindered by models' limited context sizes and handling the additional\ncomplexities of the multi-source tasks, such as identifying relevant\ninformation in additional files and seamlessly aligning it with the meeting\ncontent. This work explores multi-source meeting summarization considering\nsupplementary materials through a three-stage large language model approach:\nidentifying transcript passages needing additional context, inferring relevant\ndetails from supplementary materials and inserting them into the transcript,\nand generating a summary from this enriched transcript. Our multi-source\napproach enhances model understanding, increasing summary relevance by ~9% and\nproducing more content-rich outputs. We introduce a personalization protocol\nthat extracts participant characteristics and tailors summaries accordingly,\nimproving informativeness by ~10%. This work further provides insights on\nperformance-cost trade-offs across four leading model families, including\nedge-device capable options. Our approach can be extended to similar complex\ngenerative tasks benefitting from additional resources and personalization,\nsuch as dialogue systems and action planning.",
      "tldr_zh": "这篇论文探讨了基于LLM（Large Language Model）的抽象式多源会议总结问题，旨在解决现有方法在识别关键内容、处理补充资源（如幻灯片）和生成个性化摘要方面的不足。作者提出一个三阶段框架：首先识别转录文本中需要额外上下文的部分，其次从补充材料中推断并插入相关细节，最后基于增强后的文本生成摘要。该方法显著提升了摘要的相关性和内容丰富性，提高约9%，并通过个性化协议提取参与者特征，进一步提高了信息性约10%。此外，论文分析了不同模型家族的性能-成本权衡，并指出该框架可扩展到类似任务，如对话系统和行动规划。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14545v1",
      "published_date": "2024-10-18 15:40:48 UTC",
      "updated_date": "2024-10-18 15:40:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:24:28.814980"
    },
    {
      "arxiv_id": "2410.14544v1",
      "title": "Computational Grounding of Responsibility Attribution and Anticipation in LTLf",
      "title_zh": "翻译失败",
      "authors": [
        "Giuseppe De Giacomo",
        "Emiliano Lorini",
        "Timothy Parker",
        "Gianmarco Parretti"
      ],
      "abstract": "Responsibility is one of the key notions in machine ethics and in the area of\nautonomous systems. It is a multi-faceted notion involving counterfactual\nreasoning about actions and strategies. In this paper, we study different\nvariants of responsibility in a strategic setting based on LTLf. We show a\nconnection with notions in reactive synthesis, including synthesis of winning,\ndominant, and best-effort strategies. This connection provides the building\nblocks for a computational grounding of responsibility including complexity\ncharacterizations and sound, complete, and optimal algorithms for attributing\nand anticipating responsibility.",
      "tldr_zh": "本论文探讨了责任（responsibility）在机器伦理和自主系统中的计算基础，特别关注基于LTLf（Linear Temporal Logic on Finite Traces）的战略设置中的逆事实推理（counterfactual reasoning）。研究者将责任的不同变体与反应式合成（reactive synthesis）中的概念（如winning, dominant, and best-effort strategies）相连接，为责任归因（responsibility attribution）和预期（anticipation）提供了计算框架。论文贡献包括复杂性表征以及健全、完整、最优的算法，实现了对责任的精确计算和分析。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14544v1",
      "published_date": "2024-10-18 15:38:33 UTC",
      "updated_date": "2024-10-18 15:38:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:25:33.334838"
    },
    {
      "arxiv_id": "2410.14765v1",
      "title": "What's New in My Data? Novelty Exploration via Contrastive Generation",
      "title_zh": "数据中有什么新颖之处？通过对比生成进行新颖性探索",
      "authors": [
        "Masaru Isonuma",
        "Ivan Titov"
      ],
      "abstract": "Fine-tuning is widely used to adapt language models for specific goals, often\nleveraging real-world data such as patient records, customer-service\ninteractions, or web content in languages not covered in pre-training. These\ndatasets are typically massive, noisy, and often confidential, making their\ndirect inspection challenging. However, understanding them is essential for\nguiding model deployment and informing decisions about data cleaning or\nsuppressing any harmful behaviors learned during fine-tuning. In this study, we\nintroduce the task of novelty discovery through generation, which aims to\nidentify novel properties of a fine-tuning dataset by generating examples that\nillustrate these properties. Our approach, Contrastive Generative Exploration\n(CGE), assumes no direct access to the data but instead relies on a pre-trained\nmodel and the same model after fine-tuning. By contrasting the predictions of\nthese two models, CGE can generate examples that highlight novel\ncharacteristics of the fine-tuning data. However, this simple approach may\nproduce examples that are too similar to one another, failing to capture the\nfull range of novel phenomena present in the dataset. We address this by\nintroducing an iterative version of CGE, where the previously generated\nexamples are used to update the pre-trained model, and this updated model is\nthen contrasted with the fully fine-tuned model to generate the next example,\npromoting diversity in the generated outputs. Our experiments demonstrate the\neffectiveness of CGE in detecting novel content, such as toxic language, as\nwell as new natural and programming languages. Furthermore, we show that CGE\nremains effective even when models are fine-tuned using differential privacy\ntechniques.",
      "tldr_zh": "这篇论文针对微调数据集的理解挑战，引入了通过生成发现新颖特性的任务，以帮助识别数据集中的独特属性，如毒性语言或新语言。作者提出Contrastive Generative Exploration (CGE)方法，通过对比预训练模型和微调模型的预测，生成示例来突出这些新特性。针对生成示例可能缺乏多样性的问题，他们开发了迭代版本的CGE，使用先前生成的示例更新预训练模型，从而提升输出多样性。实验结果表明，CGE在检测新内容方面表现出色，即使在微调中使用differential privacy技术时仍保持有效。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14765v1",
      "published_date": "2024-10-18 15:24:05 UTC",
      "updated_date": "2024-10-18 15:24:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:25:46.279983"
    },
    {
      "arxiv_id": "2411.02408v2",
      "title": "AI on My Shoulder: Supporting Emotional Labor in Front-Office Roles with an LLM-based Empathetic Coworker",
      "title_zh": "翻译失败",
      "authors": [
        "Vedant Das Swain",
        "Qiuyue \"Joy\" Zhong",
        "Jash Rajesh Parekh",
        "Yechan Jeon",
        "Roy Zimmermann",
        "Mary Czerwinski",
        "Jina Suh",
        "Varun Mishra",
        "Koustuv Saha",
        "Javier Hernandez"
      ],
      "abstract": "Client-Service Representatives (CSRs) are vital to organizations. Frequent\ninteractions with disgruntled clients, however, disrupt their mental\nwell-being. To help CSRs regulate their emotions while interacting with uncivil\nclients, we designed Care-Pilot, an LLM-powered assistant, and evaluated its\nefficacy, perception, and use. Our comparative analyses between 665 human and\nCare-Pilot-generated support messages highlight Care-Pilot's ability to adapt\nto and demonstrate empathy in various incivility incidents. Additionally, 143\nCSRs assessed Care-Pilot's empathy as more sincere and actionable than human\nmessages. Finally, we interviewed 20 CSRs who interacted with Care-Pilot in a\nsimulation exercise. They reported that Care-Pilot helped them avoid negative\nthinking, recenter thoughts, and humanize clients; showing potential for\nbridging gaps in coworker support. Yet, they also noted deployment challenges\nand emphasized the indispensability of shared experiences. We discuss future\ndesigns and societal implications of AI-mediated emotional labor, underscoring\nempathy as a critical function for AI assistants for worker mental health.",
      "tldr_zh": "本研究设计了 Care-Pilot，一种基于 LLM 的移情助手，旨在帮助客户服务代表（CSRs）在面对不礼貌客户时调节情绪并维持心理健康。实验比较了665条人类和Care-Pilot生成的支持消息，结果显示Care-Pilot在适应各种不礼貌事件时表现出更高的移情真诚度和可行动性。143名CSRs评估认为Care-Pilot的回应更有效，而20名CSRs在模拟互动中反馈它有助于避免负面思考、重塑心态和人性化客户。尽管存在部署挑战，该研究强调了AI在情感劳动中的潜在作用，并呼吁未来设计注重移情以支持员工心理健康。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02408v2",
      "published_date": "2024-10-18 15:22:07 UTC",
      "updated_date": "2025-02-27 16:53:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:25:57.811868"
    },
    {
      "arxiv_id": "2410.14524v1",
      "title": "Less is More: Selective Reduction of CT Data for Self-Supervised Pre-Training of Deep Learning Models with Contrastive Learning Improves Downstream Classification Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Wolf",
        "Tristan Payer",
        "Catharina Silvia Lisson",
        "Christoph Gerhard Lisson",
        "Meinrad Beer",
        "Michael Götz",
        "Timo Ropinski"
      ],
      "abstract": "Self-supervised pre-training of deep learning models with contrastive\nlearning is a widely used technique in image analysis. Current findings\nindicate a strong potential for contrastive pre-training on medical images.\nHowever, further research is necessary to incorporate the particular\ncharacteristics of these images. We hypothesize that the similarity of medical\nimages hinders the success of contrastive learning in the medical imaging\ndomain. To this end, we investigate different strategies based on deep\nembedding, information theory, and hashing in order to identify and reduce\nredundancy in medical pre-training datasets. The effect of these different\nreduction strategies on contrastive learning is evaluated on two pre-training\ndatasets and several downstream classification tasks. In all of our\nexperiments, dataset reduction leads to a considerable performance gain in\ndownstream tasks, e.g., an AUC score improvement from 0.78 to 0.83 for the\nCOVID CT Classification Grand Challenge, 0.97 to 0.98 for the OrganSMNIST\nClassification Challenge and 0.73 to 0.83 for a brain hemorrhage classification\ntask. Furthermore, pre-training is up to nine times faster due to the dataset\nreduction. In conclusion, the proposed approach highlights the importance of\ndataset quality and provides a transferable approach to improve contrastive\npre-training for classification downstream tasks on medical images.",
      "tldr_zh": "本文提出，通过选择性减少 CT 数据冗余来改善对比学习（contrastive learning）的自监督预训练（self-supervised pre-training），以应对医疗图像相似性对模型性能的阻碍。研究采用基于深度嵌入（deep embedding）、信息理论（information theory）和哈希（hashing）的策略，在多个预训练数据集上识别并减少冗余，导致下游分类任务性能显著提升，例如 COVID CT 分类的 AUC 得分从 0.78 提高到 0.83，OrganSMNIST 从 0.97 到 0.98，以及脑出血分类从 0.73 到 0.83。同时，预训练速度加快了最多九倍，强调了数据集质量对医疗图像分析的重要性，并提供了一种可转移的优化方法。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Published in Computers in Biology and Medicine",
      "pdf_url": "http://arxiv.org/pdf/2410.14524v1",
      "published_date": "2024-10-18 15:08:05 UTC",
      "updated_date": "2024-10-18 15:08:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:26:11.214264"
    },
    {
      "arxiv_id": "2410.14516v5",
      "title": "Do LLMs \"know\" internally when they follow instructions?",
      "title_zh": "翻译失败",
      "authors": [
        "Juyeon Heo",
        "Christina Heinze-Deml",
        "Oussama Elachqar",
        "Kwan Ho Ryan Chan",
        "Shirley Ren",
        "Udhay Nallasamy",
        "Andy Miller",
        "Jaya Narain"
      ],
      "abstract": "Instruction-following is crucial for building AI agents with large language\nmodels (LLMs), as these models must adhere strictly to user-provided\nconstraints and guidelines. However, LLMs often fail to follow even simple and\nclear instructions. To improve instruction-following behavior and prevent\nundesirable outputs, a deeper understanding of how LLMs' internal states relate\nto these outcomes is required. In this work, we investigate whether LLMs encode\ninformation in their representations that correlate with instruction-following\nsuccess - a property we term knowing internally. Our analysis identifies a\ndirection in the input embedding space, termed the instruction-following\ndimension, that predicts whether a response will comply with a given\ninstruction. We find that this dimension generalizes well across unseen tasks\nbut not across unseen instruction types. We demonstrate that modifying\nrepresentations along this dimension improves instruction-following success\nrates compared to random changes, without compromising response quality.\nFurther investigation reveals that this dimension is more closely related to\nthe phrasing of prompts rather than the inherent difficulty of the task or\ninstructions. This work provides insight into the internal workings of LLMs'\ninstruction-following, paving the way for reliable LLM agents.",
      "tldr_zh": "这项研究探讨了大型语言模型(LLMs)是否在内部编码了与指令遵循相关的信息，旨在理解LLMs为何经常失败于遵守用户指令。研究者通过分析输入嵌入空间，识别了一个instruction-following dimension方向，能预测响应是否符合指令，并发现该维度在未见任务上泛化良好，但不适用于未见指令类型。实验表明，沿着该维度修改模型表示可以显著提高指令遵循成功率，同时保持响应质量不变。该工作揭示了instruction-following dimension更依赖于提示措辞而非任务难度，为构建可靠的LLM代理提供了重要洞见。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14516v5",
      "published_date": "2024-10-18 14:55:14 UTC",
      "updated_date": "2025-03-28 15:40:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:26:22.593541"
    },
    {
      "arxiv_id": "2410.14515v2",
      "title": "Efficient Annotator Reliability Assessment and Sample Weighting for Knowledge-Based Misinformation Detection on Social Media",
      "title_zh": "翻译失败",
      "authors": [
        "Owen Cook",
        "Charlie Grimshaw",
        "Ben Wu",
        "Sophie Dillon",
        "Jack Hicks",
        "Luke Jones",
        "Thomas Smith",
        "Matyas Szert",
        "Xingyi Song"
      ],
      "abstract": "Misinformation spreads rapidly on social media, confusing the truth and\ntargeting potentially vulnerable people. To effectively mitigate the negative\nimpact of misinformation, it must first be accurately detected before applying\na mitigation strategy, such as X's community notes, which is currently a manual\nprocess. This study takes a knowledge-based approach to misinformation\ndetection, modelling the problem similarly to one of natural language\ninference. The EffiARA annotation framework is introduced, aiming to utilise\ninter- and intra-annotator agreement to understand the reliability of each\nannotator and influence the training of large language models for\nclassification based on annotator reliability. In assessing the EffiARA\nannotation framework, the Russo-Ukrainian Conflict Knowledge-Based\nMisinformation Classification Dataset (RUC-MCD) was developed and made publicly\navailable. This study finds that sample weighting using annotator reliability\nperforms the best, utilising both inter- and intra-annotator agreement and\nsoft-label training. The highest classification performance achieved using\nLlama-3.2-1B was a macro-F1 of 0.757 and 0.740 using TwHIN-BERT-large.",
      "tldr_zh": "本研究针对社交媒体上的虚假信息检测问题，提出了一种基于知识的检测方法，将其建模为自然语言推理任务。研究引入了EffiARA注释框架，通过评估注释者间的inter-annotator agreement和intra-annotator agreement来量化注释者可靠性，并据此进行样本加权和软标签训练，以优化大型语言模型的分类性能。为此，开发了Russo-Ukrainian Conflict Knowledge-Based Misinformation Classification Dataset (RUC-MCD)数据集并公开可用。实验结果显示，使用注释者可靠性进行样本加权的方法表现最佳，在Llama-3.2-1B模型上达到macro-F1分数0.757，在TwHIN-BERT-large模型上达到0.740，从而提升了错误信息检测的准确性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 3 figures, 3 tables. Code available here:\n  https://github.com/MiniEggz/ruc-misinfo; annotation framework available here:\n  https://github.com/MiniEggz/EffiARA",
      "pdf_url": "http://arxiv.org/pdf/2410.14515v2",
      "published_date": "2024-10-18 14:54:40 UTC",
      "updated_date": "2025-02-03 18:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:26:34.117394"
    },
    {
      "arxiv_id": "2410.14508v1",
      "title": "LEAD: Latent Realignment for Human Motion Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Nefeli Andreou",
        "Xi Wang",
        "Victoria Fernández Abrevaya",
        "Marie-Paule Cani",
        "Yiorgos Chrysanthou",
        "Vicky Kalogeiton"
      ],
      "abstract": "Our goal is to generate realistic human motion from natural language. Modern\nmethods often face a trade-off between model expressiveness and text-to-motion\nalignment. Some align text and motion latent spaces but sacrifice\nexpressiveness; others rely on diffusion models producing impressive motions,\nbut lacking semantic meaning in their latent space. This may compromise\nrealism, diversity, and applicability. Here, we address this by combining\nlatent diffusion with a realignment mechanism, producing a novel, semantically\nstructured space that encodes the semantics of language. Leveraging this\ncapability, we introduce the task of textual motion inversion to capture novel\nmotion concepts from a few examples. For motion synthesis, we evaluate LEAD on\nHumanML3D and KIT-ML and show comparable performance to the state-of-the-art in\nterms of realism, diversity, and text-motion consistency. Our qualitative\nanalysis and user study reveal that our synthesized motions are sharper, more\nhuman-like and comply better with the text compared to modern methods. For\nmotion textual inversion, our method demonstrates improved capacity in\ncapturing out-of-distribution characteristics in comparison to traditional\nVAEs.",
      "tldr_zh": "该论文提出LEAD框架，通过潜在重对齐（Latent Realignment）机制与扩散模型结合，创建了一个语义结构化的潜在空间，以从自然语言生成更逼真的动作序列，从而解决现有方法在模型表现力和文本-动作对齐（text-to-motion alignment）之间的权衡问题。LEAD引入了文本动作反演（textual motion inversion）任务，利用少量示例捕获新颖动作概念，提升了动作合成的多样性和语义准确性。在HumanML3D和KIT-ML数据集上的实验显示，LEAD在逼真性、多样性和文本-动作一致性方面与最先进方法相当，且定性分析及用户研究表明其生成的动作更清晰、更像人类并更好地符合文本描述。对于动作文本反演，LEAD比传统VAEs更有效地捕获分布外特征。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14508v1",
      "published_date": "2024-10-18 14:43:05 UTC",
      "updated_date": "2024-10-18 14:43:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:26:46.093170"
    },
    {
      "arxiv_id": "2410.14506v1",
      "title": "SignAttention: On the Interpretability of Transformer Models for Sign Language Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Alejandro Dal Bianco",
        "Oscar Agustín Stanchi",
        "Facundo Manuel Quiroga",
        "Franco Ronchetti",
        "Enzo Ferrante"
      ],
      "abstract": "This paper presents the first comprehensive interpretability analysis of a\nTransformer-based Sign Language Translation (SLT) model, focusing on the\ntranslation from video-based Greek Sign Language to glosses and text.\nLeveraging the Greek Sign Language Dataset, we examine the attention mechanisms\nwithin the model to understand how it processes and aligns visual input with\nsequential glosses. Our analysis reveals that the model pays attention to\nclusters of frames rather than individual ones, with a diagonal alignment\npattern emerging between poses and glosses, which becomes less distinct as the\nnumber of glosses increases. We also explore the relative contributions of\ncross-attention and self-attention at each decoding step, finding that the\nmodel initially relies on video frames but shifts its focus to previously\npredicted tokens as the translation progresses. This work contributes to a\ndeeper understanding of SLT models, paving the way for the development of more\ntransparent and reliable translation systems essential for real-world\napplications.",
      "tldr_zh": "本论文首次对基于 Transformer 的手语翻译 (SLT) 模型进行全面可解释性分析，焦点在于从视频-based Greek Sign Language 到 glosses 和 text 的翻译过程。研究利用 Greek Sign Language Dataset 考察注意力机制，发现模型倾向于关注帧簇而非单个帧，并显示出对角线对齐模式，但随着 glosses 数量增加，这种模式变得不那么明显；此外，模型在解码步骤中最初依赖 cross-attention 于视频帧，随后转向 self-attention 于之前预测的 tokens。该工作加深了对 SLT 模型的理解，促进开发更透明可靠的翻译系统，用于实际应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at IAI Workshop @ NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.14506v1",
      "published_date": "2024-10-18 14:38:37 UTC",
      "updated_date": "2024-10-18 14:38:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:26:57.939287"
    },
    {
      "arxiv_id": "2410.14763v2",
      "title": "Enabling Scalable Evaluation of Bias Patterns in Medical LLMs",
      "title_zh": "实现医疗 LLMs 中偏差模式的规模化评估",
      "authors": [
        "Hamed Fayyaz",
        "Raphael Poulain",
        "Rahmatollah Beheshti"
      ],
      "abstract": "Large language models (LLMs) have shown impressive potential in helping with\nnumerous medical challenges. Deploying LLMs in high-stakes applications such as\nmedicine, however, brings in many concerns. One major area of concern relates\nto biased behaviors of LLMs in medical applications, leading to unfair\ntreatment of individuals. To pave the way for the responsible and impactful\ndeployment of Med LLMs, rigorous evaluation is a key prerequisite. Due to the\nhuge complexity and variability of different medical scenarios, existing work\nin this domain has primarily relied on using manually crafted datasets for bias\nevaluation. In this study, we present a new method to scale up such bias\nevaluations by automatically generating test cases based on rigorous medical\nevidence. We specifically target the challenges of a) domain-specificity of\nbias characterization, b) hallucinating while generating the test cases, and c)\nvarious dependencies between the health outcomes and sensitive attributes. To\nthat end, we offer new methods to address these challenges integrated with our\ngenerative pipeline, using medical knowledge graphs, medical ontologies, and\ncustomized general LLM evaluation frameworks in our method. Through a series of\nextensive experiments, we show that the test cases generated by our proposed\nmethod can effectively reveal bias patterns in Med LLMs at larger and more\nflexible scales than human-crafted datasets. We publish a large bias evaluation\ndataset using our pipeline, which is dedicated to a few medical case studies. A\nlive demo of our application for vignette generation is available at\nhttps://vignette.streamlit.app. Our code is also available at\nhttps://github.com/healthylaife/autofair.",
      "tldr_zh": "本研究针对医疗LLMs（Large Language Models）中的偏见问题，提出了一种可扩展的评估方法，通过自动生成测试用例来克服手动数据集的局限性。该方法整合医疗知识图谱、医疗本体和自定义LLM评估框架，解决了偏见特征的领域特定性、测试用例生成中的幻觉问题以及健康结果与敏感属性的依赖关系。通过广泛实验，证明生成的测试用例能更有效地揭示Med LLMs的偏见模式，并发布了大型评估数据集、在线演示和开源代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14763v2",
      "published_date": "2024-10-18 14:17:03 UTC",
      "updated_date": "2025-04-13 03:42:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:27:10.248737"
    },
    {
      "arxiv_id": "2410.14488v1",
      "title": "ANT: Adaptive Noise Schedule for Time Series Diffusion Models",
      "title_zh": "ANT：时间序列扩散模型的自适应噪声调度",
      "authors": [
        "Seunghan Lee",
        "Kibok Lee",
        "Taeyoung Park"
      ],
      "abstract": "Advances in diffusion models for generative artificial intelligence have\nrecently propagated to the time series (TS) domain, demonstrating\nstate-of-the-art performance on various tasks. However, prior works on TS\ndiffusion models often borrow the framework of existing works proposed in other\ndomains without considering the characteristics of TS data, leading to\nsuboptimal performance. In this work, we propose Adaptive Noise schedule for\nTime series diffusion models (ANT), which automatically predetermines proper\nnoise schedules for given TS datasets based on their statistics representing\nnon-stationarity. Our intuition is that an optimal noise schedule should\nsatisfy the following desiderata: 1) It linearly reduces the non-stationarity\nof TS data so that all diffusion steps are equally meaningful, 2) the data is\ncorrupted to the random noise at the final step, and 3) the number of steps is\nsufficiently large. The proposed method is practical for use in that it\neliminates the necessity of finding the optimal noise schedule with a small\nadditional cost to compute the statistics for given datasets, which can be done\noffline before training. We validate the effectiveness of our method across\nvarious tasks, including TS forecasting, refinement, and generation, on\ndatasets from diverse domains. Code is available at this repository:\nhttps://github.com/seunghan96/ANT.",
      "tldr_zh": "本研究针对时间序列 (TS) 扩散模型的局限性，提出了一种自适应噪声调度方法 ANT，以优化噪声计划，使其基于 TS 数据统计（如非平稳性）自动生成。ANT 的设计原则包括线性减少数据非平稳性、确保最终步骤将数据腐蚀为随机噪声，以及维持足够的扩散步骤数，从而使每个步骤都具有意义。该方法无需手动优化噪声调度，仅需少量离线计算数据集统计，即可提升模型性能；在时间序列预测、精炼和生成任务上，经多领域数据集验证，ANT 显著提高了基线模型的效果。代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.14488v1",
      "published_date": "2024-10-18 14:16:54 UTC",
      "updated_date": "2024-10-18 14:16:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:27:21.449990"
    },
    {
      "arxiv_id": "2410.14484v1",
      "title": "Transfer Reinforcement Learning in Heterogeneous Action Spaces using Subgoal Mapping",
      "title_zh": "在异构动作空间中使用子目标映射的迁移强化学习",
      "authors": [
        "Kavinayan P. Sivakumar",
        "Yan Zhang",
        "Zachary Bell",
        "Scott Nivison",
        "Michael M. Zavlanos"
      ],
      "abstract": "In this paper, we consider a transfer reinforcement learning problem\ninvolving agents with different action spaces. Specifically, for any new unseen\ntask, the goal is to use a successful demonstration of this task by an expert\nagent in its action space to enable a learner agent learn an optimal policy in\nits own different action space with fewer samples than those required if the\nlearner was learning on its own. Existing transfer learning methods across\ndifferent action spaces either require handcrafted mappings between those\naction spaces provided by human experts, which can induce bias in the learning\nprocedure, or require the expert agent to share its policy parameters with the\nlearner agent, which does not generalize well to unseen tasks. In this work, we\npropose a method that learns a subgoal mapping between the expert agent policy\nand the learner agent policy. Since the expert agent and the learner agent have\ndifferent action spaces, their optimal policies can have different subgoal\ntrajectories. We learn this subgoal mapping by training a Long Short Term\nMemory (LSTM) network for a distribution of tasks and then use this mapping to\npredict the learner subgoal sequence for unseen tasks, thereby improving the\nspeed of learning by biasing the agent's policy towards the predicted learner\nsubgoal sequence. Through numerical experiments, we demonstrate that the\nproposed learning scheme can effectively find the subgoal mapping underlying\nthe given distribution of tasks. Moreover, letting the learner agent imitate\nthe expert agent's policy with the learnt subgoal mapping can significantly\nimprove the sample efficiency and training time of the learner agent in unseen\nnew tasks.",
      "tldr_zh": "本研究探讨了在异构动作空间（Heterogeneous Action Spaces）中的转移强化学习（Transfer Reinforcement Learning），目标是利用专家代理（expert agent）在不同动作空间的成功演示，帮助学习者代理（learner agent）更快地学习最优策略，从而减少所需样本数量。论文提出了一种子目标映射（Subgoal Mapping）方法，使用 Long Short Term Memory (LSTM) 网络在任务分布上训练映射模型，以预测学习者代理在新任务中的子目标序列，从而引导其策略学习。实验结果表明，该方法能有效识别任务分布下的子目标映射，并显著提升学习者代理在新任务中的样本效率和训练时间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14484v1",
      "published_date": "2024-10-18 14:08:41 UTC",
      "updated_date": "2024-10-18 14:08:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:27:33.642473"
    },
    {
      "arxiv_id": "2410.14481v1",
      "title": "DRL Optimization Trajectory Generation via Wireless Network Intent-Guided Diffusion Models for Optimizing Resource Allocation",
      "title_zh": "翻译失败",
      "authors": [
        "Junjie Wu",
        "Xuming Fang",
        "Dusit Niyato",
        "Jiacheng Wang",
        "Jingyu Wang"
      ],
      "abstract": "With the rapid advancements in wireless communication fields, including\nlow-altitude economies, 6G, and Wi-Fi, the scale of wireless networks continues\nto expand, accompanied by increasing service quality demands. Traditional deep\nreinforcement learning (DRL)-based optimization models can improve network\nperformance by solving non-convex optimization problems intelligently. However,\nthey heavily rely on online deployment and often require extensive initial\ntraining. Online DRL optimization models typically make accurate decisions\nbased on current channel state distributions. When these distributions change,\ntheir generalization capability diminishes, which hinders the responsiveness\nessential for real-time and high-reliability wireless communication networks.\nFurthermore, different users have varying quality of service (QoS) requirements\nacross diverse scenarios, and conventional online DRL methods struggle to\naccommodate this variability. Consequently, exploring flexible and customized\nAI strategies is critical. We propose a wireless network intent (WNI)-guided\ntrajectory generation model based on a generative diffusion model (GDM). This\nmodel can be generated and fine-tuned in real time to achieve the objective and\nmeet the constraints of target intent networks, significantly reducing state\ninformation exposure during wireless communication. Moreover, The WNI-guided\noptimization trajectory generation can be customized to address differentiated\nQoS requirements, enhancing the overall quality of communication in future\nintelligent networks. Extensive simulation results demonstrate that our\napproach achieves greater stability in spectral efficiency variations and\noutperforms traditional DRL optimization models in dynamic communication\nsystems.",
      "tldr_zh": "该研究针对无线网络（如6G和Wi-Fi）的快速发展及用户多样化QoS（Quality of Service）需求，指出传统DRL（Deep Reinforcement Learning）优化模型依赖在线训练且泛化能力弱，难以适应动态环境。提出一种WNI（Wireless Network Intent）-guided trajectory generation模型，基于GDM（Generative Diffusion Model），实现实时生成和微调优化轨迹，以满足特定网络意图、减少状态信息暴露并自定义处理不同QoS要求。模拟结果显示，该方法在频谱效率稳定性上显著提升，并在动态通信系统中优于传统DRL模型的性能。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14481v1",
      "published_date": "2024-10-18 14:04:38 UTC",
      "updated_date": "2024-10-18 14:04:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:27:46.910632"
    },
    {
      "arxiv_id": "2410.19822v1",
      "title": "Human-Centric eXplainable AI in Education",
      "title_zh": "翻译失败",
      "authors": [
        "Subhankar Maity",
        "Aniket Deroy"
      ],
      "abstract": "As artificial intelligence (AI) becomes more integrated into educational\nenvironments, how can we ensure that these systems are both understandable and\ntrustworthy? The growing demand for explainability in AI systems is a critical\narea of focus. This paper explores Human-Centric eXplainable AI (HCXAI) in the\neducational landscape, emphasizing its role in enhancing learning outcomes,\nfostering trust among users, and ensuring transparency in AI-driven tools,\nparticularly through the innovative use of large language models (LLMs). What\nchallenges arise in the implementation of explainable AI in educational\ncontexts? This paper analyzes these challenges, addressing the complexities of\nAI models and the diverse needs of users. It outlines comprehensive frameworks\nfor developing HCXAI systems that prioritize user understanding and engagement,\nensuring that educators and students can effectively interact with these\ntechnologies. Furthermore, what steps can educators, developers, and\npolicymakers take to create more effective, inclusive, and ethically\nresponsible AI solutions in education? The paper provides targeted\nrecommendations to address this question, highlighting the necessity of\nprioritizing explainability. By doing so, how can we leverage AI's\ntransformative potential to foster equitable and engaging educational\nexperiences that support diverse learners?",
      "tldr_zh": "本论文探讨了Human-Centric eXplainable AI (HCXAI)在教育领域的应用，强调其通过提升AI系统的透明度和可理解性，来改善学习成果、建立用户信任，并利用large language models (LLMs)等技术进行创新。论文分析了实施HCXAI面临的挑战，包括AI模型的复杂性和用户多样性需求，并提出全面框架来优先考虑用户理解和互动。最终，它提供针对性推荐，帮助教育者、开发者和决策者创建更有效、包容和伦理负责的AI解决方案，从而促进公平且引人入胜的教育体验。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "Preprint. Under Review",
      "pdf_url": "http://arxiv.org/pdf/2410.19822v1",
      "published_date": "2024-10-18 14:02:47 UTC",
      "updated_date": "2024-10-18 14:02:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:27:57.659023"
    },
    {
      "arxiv_id": "2410.14470v1",
      "title": "How Do Training Methods Influence the Utilization of Vision Models?",
      "title_zh": "训练方法如何影响视觉模型的利用？",
      "authors": [
        "Paul Gavrikov",
        "Shashank Agnihotri",
        "Margret Keuper",
        "Janis Keuper"
      ],
      "abstract": "Not all learnable parameters (e.g., weights) contribute equally to a neural\nnetwork's decision function. In fact, entire layers' parameters can sometimes\nbe reset to random values with little to no impact on the model's decisions. We\nrevisit earlier studies that examined how architecture and task complexity\ninfluence this phenomenon and ask: is this phenomenon also affected by how we\ntrain the model? We conducted experimental evaluations on a diverse set of\nImageNet-1k classification models to explore this, keeping the architecture and\ntraining data constant but varying the training pipeline. Our findings reveal\nthat the training method strongly influences which layers become critical to\nthe decision function for a given task. For example, improved training regimes\nand self-supervised training increase the importance of early layers while\nsignificantly under-utilizing deeper layers. In contrast, methods such as\nadversarial training display an opposite trend. Our preliminary results extend\nprevious findings, offering a more nuanced understanding of the inner mechanics\nof neural networks.\n  Code: https://github.com/paulgavrikov/layer_criticality",
      "tldr_zh": "本研究探讨了训练方法如何影响视觉模型中参数（如权重）的利用情况，通过在ImageNet-1k分类模型上进行实验，保持架构和训练数据不变但改变训练管道。结果显示，改进的训练制度和self-supervised training会增加早期层的importance，同时显著低利用深层；相反，adversarial training则显示相反趋势。总体而言，该工作扩展了先前关于神经网络层关键性的研究，提供对模型内部机制的更细致理解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at the Interpretable AI: Past, Present and Future Workshop\n  at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.14470v1",
      "published_date": "2024-10-18 13:54:46 UTC",
      "updated_date": "2024-10-18 13:54:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:28:09.699104"
    },
    {
      "arxiv_id": "2410.14461v1",
      "title": "The Propensity for Density in Feed-forward Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nandi Schoots",
        "Alex Jackson",
        "Ali Kholmovaia",
        "Peter McBurney",
        "Murray Shanahan"
      ],
      "abstract": "Does the process of training a neural network to solve a task tend to use all\nof the available weights even when the task could be solved with fewer weights?\nTo address this question we study the effects of pruning fully connected,\nconvolutional and residual models while varying their widths. We find that the\nproportion of weights that can be pruned without degrading performance is\nlargely invariant to model size. Increasing the width of a model has little\neffect on the density of the pruned model relative to the increase in absolute\nsize of the pruned network. In particular, we find substantial prunability\nacross a large range of model sizes, where our biggest model is 50 times as\nwide as our smallest model. We explore three hypotheses that could explain\nthese findings.",
      "tldr_zh": "这篇论文探讨了在训练前馈模型(feed-forward models)时，是否会倾向于使用所有可用权重，即使任务可以用更少的权重解决。\n研究者通过修剪全连接(fully connected)、卷积(convolutional)和残差(residual)模型，并改变它们的宽度，进行了一系列实验。\n结果显示，可修剪权重的比例与模型大小基本无关，即使增加模型宽度，修剪后模型的相对密度也没有显著变化；在从最小到50倍宽的模型中，都表现出高度的可修剪性。\n论文进一步探讨了三种假设来解释这些发现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14461v1",
      "published_date": "2024-10-18 13:40:44 UTC",
      "updated_date": "2024-10-18 13:40:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:28:22.941666"
    },
    {
      "arxiv_id": "2410.14445v2",
      "title": "Toward Generalizing Visual Brain Decoding to Unseen Subjects",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangtao Kong",
        "Kexin Huang",
        "Ping Li",
        "Lei Zhang"
      ],
      "abstract": "Visual brain decoding aims to decode visual information from human brain\nactivities. Despite the great progress, one critical limitation of current\nbrain decoding research lies in the lack of generalization capability to unseen\nsubjects. Prior works typically focus on decoding brain activity of individuals\nbased on the observation that different subjects exhibit different brain\nactivities, while it remains unclear whether brain decoding can be generalized\nto unseen subjects. This study aims to answer this question. We first\nconsolidate an image-fMRI dataset consisting of stimulus-image and\nfMRI-response pairs, involving 177 subjects in the movie-viewing task of the\nHuman Connectome Project (HCP). This dataset allows us to investigate the brain\ndecoding performance with the increase of participants. We then present a\nlearning paradigm that applies uniform processing across all subjects, instead\nof employing different network heads or tokenizers for individuals as in\nprevious methods, which can accommodate a large number of subjects to explore\nthe generalization capability across different subjects. A series of\nexperiments are conducted and we have the following findings. First, the\nnetwork exhibits clear generalization capabilities with the increase of\ntraining subjects. Second, the generalization capability is common to popular\nnetwork architectures (MLP, CNN and Transformer). Third, the generalization\nperformance is affected by the similarity between subjects. Our findings reveal\nthe inherent similarities in brain activities across individuals. With the\nemerging of larger and more comprehensive datasets, it is possible to train a\nbrain decoding foundation model in the future. Codes and models can be found at\nhttps://github.com/Xiangtaokong/TGBD.",
      "tldr_zh": "本文探讨了Visual Brain Decoding在对未见过受试者（unseen subjects）的泛化能力问题，构建了一个包含177个受试者的图像-fMRI数据集，基于Human Connectome Project (HCP)的电影观看任务。研究提出了一种统一处理的学习范式，对所有受试者采用相同的网络架构，而非个性化定制，以评估跨受试者的泛化性能。实验发现，随着训练受试者数量增加，网络的泛化能力显著提升，且适用于MLP、CNN和Transformer等流行架构；此外，泛化效果受受试者之间脑活动相似性的影响。这些发现揭示了个体脑活动的内在相似性，并为未来训练脑解码基础模型奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14445v2",
      "published_date": "2024-10-18 13:04:35 UTC",
      "updated_date": "2024-10-21 01:45:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:28:34.909215"
    },
    {
      "arxiv_id": "2410.14436v1",
      "title": "Learning to refine domain knowledge for biological network inference",
      "title_zh": "翻译失败",
      "authors": [
        "Peiwen Li",
        "Menghua Wu"
      ],
      "abstract": "Perturbation experiments allow biologists to discover causal relationships\nbetween variables of interest, but the sparsity and high dimensionality of\nthese data pose significant challenges for causal structure learning\nalgorithms. Biological knowledge graphs can bootstrap the inference of causal\nstructures in these situations, but since they compile vastly diverse\ninformation, they can bias predictions towards well-studied systems.\nAlternatively, amortized causal structure learning algorithms encode inductive\nbiases through data simulation and train supervised models to recapitulate\nthese synthetic graphs. However, realistically simulating biology is arguably\neven harder than understanding a specific system. In this work, we take\ninspiration from both strategies and propose an amortized algorithm for\nrefining domain knowledge, based on data observations. On real and synthetic\ndatasets, we show that our approach outperforms baselines in recovering ground\ntruth causal graphs and identifying errors in the prior knowledge with limited\ninterventional data.",
      "tldr_zh": "本研究针对生物网络推断中的数据稀疏和高维性挑战，提出了一种基于数据观察的摊销算法（amortized algorithm），旨在通过结合领域知识和数据模拟来改进（refine）先验知识。不同于依赖生物知识图（biological knowledge graphs）或纯模拟方法，该算法引入归纳偏差以优化因果结构学习（causal structure learning）。在真实和合成数据集上，实验结果表明，该方法在有限的干预数据（interventional data）下，优于基线模型，能够更准确地恢复真实因果图（causal graphs）和识别先验知识错误。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14436v1",
      "published_date": "2024-10-18 12:53:23 UTC",
      "updated_date": "2024-10-18 12:53:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:28:47.535084"
    },
    {
      "arxiv_id": "2410.14429v1",
      "title": "FashionR2R: Texture-preserving Rendered-to-Real Image Translation with Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Hu",
        "Qian He",
        "Gaofeng He",
        "Jiedong Zhuang",
        "Huang Chen",
        "Huafeng Liu",
        "Huamin Wang"
      ],
      "abstract": "Modeling and producing lifelike clothed human images has attracted\nresearchers' attention from different areas for decades, with the complexity\nfrom highly articulated and structured content. Rendering algorithms decompose\nand simulate the imaging process of a camera, while are limited by the accuracy\nof modeled variables and the efficiency of computation. Generative models can\nproduce impressively vivid human images, however still lacking in\ncontrollability and editability. This paper studies photorealism enhancement of\nrendered images, leveraging generative power from diffusion models on the\ncontrolled basis of rendering. We introduce a novel framework to translate\nrendered images into their realistic counterparts, which consists of two\nstages: Domain Knowledge Injection (DKI) and Realistic Image Generation (RIG).\nIn DKI, we adopt positive (real) domain finetuning and negative (rendered)\ndomain embedding to inject knowledge into a pretrained Text-to-image (T2I)\ndiffusion model. In RIG, we generate the realistic image corresponding to the\ninput rendered image, with a Texture-preserving Attention Control (TAC) to\npreserve fine-grained clothing textures, exploiting the decoupled features\nencoded in the UNet structure. Additionally, we introduce SynFashion dataset,\nfeaturing high-quality digital clothing images with diverse textures. Extensive\nexperimental results demonstrate the superiority and effectiveness of our\nmethod in rendered-to-real image translation.",
      "tldr_zh": "这篇论文提出了FashionR2R框架，利用diffusion models将渲染图像转化为真实图像，同时保留服装纹理，以提升图像的逼真度和可控性。该框架分为两个阶段：Domain Knowledge Injection (DKI)，通过正向（真实）域微调和负向（渲染）域嵌入向预训练的Text-to-image (T2I)扩散模型注入知识；以及Realistic Image Generation (RIG)，使用Texture-preserving Attention Control (TAC)来保护细粒度纹理，借助UNet结构中的解耦特征。论文还引入了SynFashion数据集，包含多样纹理的高质量数字服装图像，实验结果证明了该方法在渲染到真实图像翻译中的优越性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.14429v1",
      "published_date": "2024-10-18 12:48:22 UTC",
      "updated_date": "2024-10-18 12:48:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:28:58.818526"
    },
    {
      "arxiv_id": "2410.14425v1",
      "title": "Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Zhao",
        "Xiaobao Wu",
        "Cong-Duy Nguyen",
        "Meihuizi Jia",
        "Yichao Feng",
        "Luu Anh Tuan"
      ],
      "abstract": "Parameter-efficient fine-tuning (PEFT) can bridge the gap between large\nlanguage models (LLMs) and downstream tasks. However, PEFT has been proven\nvulnerable to malicious attacks. Research indicates that poisoned LLMs, even\nafter PEFT, retain the capability to activate internalized backdoors when input\nsamples contain predefined triggers. In this paper, we introduce a novel\nweak-to-strong unlearning algorithm to defend against backdoor attacks based on\nfeature alignment knowledge distillation, named W2SDefense. Specifically, we\nfirst train a small-scale language model through full-parameter fine-tuning to\nserve as the clean teacher model. Then, this teacher model guides the\nlarge-scale poisoned student model in unlearning the backdoor, leveraging PEFT.\nTheoretical analysis suggests that W2SDefense has the potential to enhance the\nstudent model's ability to unlearn backdoor features, preventing the activation\nof the backdoor. We conduct experiments on text classification tasks involving\nthree state-of-the-art language models and three different backdoor attack\nalgorithms. Our empirical results demonstrate the outstanding performance of\nW2SDefense in defending against backdoor attacks without compromising model\nperformance.",
      "tldr_zh": "该研究针对大型语言模型 (LLMs) 在 parameter-efficient fine-tuning (PEFT) 过程中易受后门攻击的问题，提出了一种新型弱到强知识蒸馏算法 W2SDefense，以基于特征对齐进行后门解除学习。算法首先通过全参数 fine-tuning 训练一个小型干净的教师模型，然后指导受污染的大型学生模型（使用 PEFT）去除后门特征，理论分析显示这能有效防止后门激活。实验在文本分类任务上测试了三种 state-of-the-art LLMs 和三种后门攻击算法，结果表明 W2SDefense 显著提升了防御性能，同时不影响模型的整体表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14425v1",
      "published_date": "2024-10-18 12:39:32 UTC",
      "updated_date": "2024-10-18 12:39:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:29:10.015697"
    },
    {
      "arxiv_id": "2410.14416v1",
      "title": "An explainable machine learning approach for energy forecasting at the household level",
      "title_zh": "一种可解释机器学习方法，用于家庭层面的能源预测",
      "authors": [
        "Pauline Béraud",
        "Margaux Rioux",
        "Michel Babany",
        "Philippe de La Chevasnerie",
        "Damien Theis",
        "Giacomo Teodori",
        "Chloé Pinguet",
        "Romane Rigaud",
        "François Leclerc"
      ],
      "abstract": "Electricity forecasting has been a recurring research topic, as it is key to\nfinding the right balance between production and consumption. While most papers\nare focused on the national or regional scale, few are interested in the\nhousehold level. Desegregated forecast is a common topic in Machine Learning\n(ML) literature but lacks explainability that household energy forecasts\nrequire. This paper specifically targets the challenges of forecasting\nelectricity use at the household level. This paper confronts common Machine\nLearning algorithms to electricity household forecasts, weighing the pros and\ncons, including accuracy and explainability with well-known key metrics.\nFurthermore, we also confront them in this paper with the business challenges\nspecific to this sector such as explainability or outliers resistance. We\nintroduce a custom decision tree, aiming at providing a fair estimate of the\nenergy consumption, while being explainable and consistent with human\nintuition. We show that this novel method allows greater explainability without\nsacrificing much accuracy. The custom tree methodology can be used in various\nbusiness use cases but is subject to limitations, such as a lack of resilience\nwith outliers.",
      "tldr_zh": "本研究针对家庭级别电力预测的挑战，提出了一种可解释的机器学习（Machine Learning）方法，以解决预测准确性和可解释性的平衡问题。论文比较了常见机器学习算法在家庭用电预测中的优缺点，并引入了一个自定义决策树（custom decision tree），旨在提供合理的能源消耗估计，同时符合人类直觉。结果显示，该方法显著提升了预测的可解释性，同时准确性损失有限，尽管存在对异常值（outliers）抵抗力不足的局限性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14416v1",
      "published_date": "2024-10-18 12:29:10 UTC",
      "updated_date": "2024-10-18 12:29:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:29:20.963294"
    },
    {
      "arxiv_id": "2410.14395v1",
      "title": "Generative AI, Pragmatics, and Authenticity in Second Language Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Robert Godwin-Jones`"
      ],
      "abstract": "There are obvious benefits to integrating generative AI (artificial\nintelligence) into language learning and teaching. Those include using AI as a\nlanguage tutor, creating learning materials, or assessing learner output.\nHowever, due to how AI systems under-stand human language, based on a\nmathematical model using statistical probability, they lack the lived\nexperience to be able to use language with the same social aware-ness as\nhumans. Additionally, there are built-in linguistic and cultural biases based\non their training data which is mostly in English and predominantly from\nWestern sources. Those facts limit AI suitability for some language learning\ninteractions. Stud-ies have clearly shown that systems such as ChatGPT often do\nnot produce language that is pragmatically appropriate. The lack of linguistic\nand cultural authenticity has important implications for how AI is integrated\ninto second language acquisition as well as in instruction targeting\ndevelopment of intercultural communication compe-tence.",
      "tldr_zh": "本论文探讨了生成式 AI 在第二语言学习中的益处，包括作为语言导师、创建学习材料和评估学习输出。然而，AI 基于统计概率模型理解语言，缺乏人类的社会意识和文化真实性，导致其输出在语用(pragmatics)上往往不适当，并存在内置的语言和文化偏见。研究强调，这些局限性会影响 AI 在第二语言习得和培养跨文化沟通能力(intercultural communication competence)中的整合，建议需谨慎应用以确保真实性(authenticity)。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14395v1",
      "published_date": "2024-10-18 11:58:03 UTC",
      "updated_date": "2024-10-18 11:58:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:29:34.240641"
    },
    {
      "arxiv_id": "2410.14393v1",
      "title": "Debug Smarter, Not Harder: AI Agents for Error Resolution in Computational Notebooks",
      "title_zh": "翻译失败",
      "authors": [
        "Konstantin Grotov",
        "Artem Borzilov",
        "Maksim Krivobok",
        "Timofey Bryksin",
        "Yaroslav Zharov"
      ],
      "abstract": "Computational notebooks became indispensable tools for research-related\ndevelopment, offering unprecedented interactivity and flexibility in the\ndevelopment process. However, these benefits come at the cost of\nreproducibility and an increased potential for bugs. With the rise of\ncode-fluent Large Language Models empowered with agentic techniques, smart\nbug-fixing tools with a high level of autonomy have emerged. However, those\ntools are tuned for classical script programming and still struggle with\nnon-linear computational notebooks. In this paper, we present an AI agent\ndesigned specifically for error resolution in a computational notebook. We have\ndeveloped an agentic system capable of exploring a notebook environment by\ninteracting with it -- similar to how a user would -- and integrated the system\ninto the JetBrains service for collaborative data science called Datalore. We\nevaluate our approach against the pre-existing single-action solution by\ncomparing costs and conducting a user study. Users rate the error resolution\ncapabilities of the agentic system higher but experience difficulties with UI.\nWe share the results of the study and consider them valuable for further\nimproving user-agent collaboration.",
      "tldr_zh": "本文提出了一种AI代理系统，专门用于解决计算笔记本（computational notebooks）中的错误问题，该系统通过模拟用户交互探索笔记本环境，并集成到JetBrains的Datalore服务中，实现更高自治的bug修复。相比现有单行动解决方案，实验结果显示该代理在错误解决效率上显著提升，用户研究也表明其能力获得更高评分。研究同时指出UI交互存在挑战，并分享这些发现以优化用户-代理协作。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to EMNLP 2024 System Demonstrations",
      "pdf_url": "http://arxiv.org/pdf/2410.14393v1",
      "published_date": "2024-10-18 11:55:34 UTC",
      "updated_date": "2024-10-18 11:55:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:29:45.739197"
    },
    {
      "arxiv_id": "2410.14389v1",
      "title": "SurgeryV2: Bridging the Gap Between Model Merging and Multi-Task Learning with Deep Representation Surgery",
      "title_zh": "翻译失败",
      "authors": [
        "Enneng Yang",
        "Li Shen",
        "Zhenyi Wang",
        "Guibing Guo",
        "Xingwei Wang",
        "Xiaocun Cao",
        "Jie Zhang",
        "Dacheng Tao"
      ],
      "abstract": "Model merging-based multitask learning (MTL) offers a promising approach for\nperforming MTL by merging multiple expert models without requiring access to\nraw training data. However, in this paper, we examine the merged model's\nrepresentation distribution and uncover a critical issue of \"representation\nbias\". This bias arises from a significant distribution gap between the\nrepresentations of the merged and expert models, leading to the suboptimal\nperformance of the merged MTL model. To address this challenge, we first\npropose a representation surgery solution called Surgery. Surgery is a\nlightweight, task-specific module that aligns the final layer representations\nof the merged model with those of the expert models, effectively alleviating\nbias and improving the merged model's performance. Despite these improvements,\na performance gap remains compared to the traditional MTL method. Further\nanalysis reveals that representation bias phenomena exist at each layer of the\nmerged model, and aligning representations only in the last layer is\ninsufficient for fully reducing systemic bias because biases introduced at each\nlayer can accumulate and interact in complex ways. To tackle this, we then\npropose a more comprehensive solution, deep representation surgery (also called\nSurgeryV2), which mitigates representation bias across all layers, and thus\nbridges the performance gap between model merging-based MTL and traditional\nMTL. Finally, we design an unsupervised optimization objective to optimize both\nthe Surgery and SurgeryV2 modules. Our experimental results show that\nincorporating these modules into state-of-the-art (SOTA) model merging schemes\nleads to significant performance gains. Notably, our SurgeryV2 scheme reaches\nalmost the same level as individual expert models or the traditional MTL model.\nThe code is available at \\url{https://github.com/EnnengYang/SurgeryV2}.",
      "tldr_zh": "这篇论文探讨了模型合并在多任务学习（Multi-Task Learning）中的“representation bias”问题，该偏差导致合并模型的表示分布与专家模型存在显著差距，从而影响性能。作者首先提出Surgery模块，这是一个轻量级、任务特定的解决方案，用于对齐合并模型的最终层表示，缓解偏差并提升性能；随后，扩展为SurgeryV2，通过在所有层处理表示偏差，全面桥接模型合并和传统多任务学习之间的差距。实验结果显示，结合无监督优化目标后，SurgeryV2使性能几乎达到专家模型或传统多任务学习的水平，并在SOTA模型合并方案中实现了显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper is an extended version of our previous work\n  [arXiv:2402.02705] presented at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.14389v1",
      "published_date": "2024-10-18 11:49:40 UTC",
      "updated_date": "2024-10-18 11:49:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:29:58.528295"
    },
    {
      "arxiv_id": "2410.16324v1",
      "title": "CybORG++: An Enhanced Gym for the Development of Autonomous Cyber Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Harry Emerson",
        "Liz Bates",
        "Chris Hicks",
        "Vasilios Mavroudis"
      ],
      "abstract": "CybORG++ is an advanced toolkit for reinforcement learning research focused\non network defence. Building on the CAGE 2 CybORG environment, it introduces\nkey improvements, including enhanced debugging capabilities, refined agent\nimplementation support, and a streamlined environment that enables faster\ntraining and easier customisation. Along with addressing several software bugs\nfrom its predecessor, CybORG++ introduces MiniCAGE, a lightweight version of\nCAGE 2, which improves performance dramatically, up to 1000x faster execution\nin parallel iterations, without sacrificing accuracy or core functionality.\nCybORG++ serves as a robust platform for developing and evaluating defensive\nagents, making it a valuable resource for advancing enterprise network defence\nresearch.",
      "tldr_zh": "CybORG++ 是一个针对网络防御的强化学习研究增强工具包，基于 CAGE 2 CybORG 环境引入了关键改进，包括增强调试能力、精炼代理实现支持以及简化环境，以实现更快训练和更容易定制。  \n它还修复了前身软件的多个 bug，并推出了 MiniCAGE，这是一个轻量版 CAGE 2，能在并行迭代中将性能提升高达 1000 倍，同时保持准确性和核心功能。  \n作为稳健平台，CybORG++ 支持开发和评估自主防御代理，推动企业网络防御研究的发展。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages, 3 figures and included appendix",
      "pdf_url": "http://arxiv.org/pdf/2410.16324v1",
      "published_date": "2024-10-18 11:04:07 UTC",
      "updated_date": "2024-10-18 11:04:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:30:10.051173"
    },
    {
      "arxiv_id": "2410.14371v1",
      "title": "Interpretable end-to-end Neurosymbolic Reinforcement Learning agents",
      "title_zh": "可解释的端到端神经符号强化学习代理",
      "authors": [
        "Nils Grandien",
        "Quentin Delfosse",
        "Kristian Kersting"
      ],
      "abstract": "Deep reinforcement learning (RL) agents rely on shortcut learning, preventing\nthem from generalizing to slightly different environments. To address this\nproblem, symbolic method, that use object-centric states, have been developed.\nHowever, comparing these methods to deep agents is not fair, as these last\noperate from raw pixel-based states. In this work, we instantiate the symbolic\nSCoBots framework. SCoBots decompose RL tasks into intermediate, interpretable\nrepresentations, culminating in action decisions based on a comprehensible set\nof object-centric relational concepts. This architecture aids in demystifying\nagent decisions. By explicitly learning to extract object-centric\nrepresentations from raw states, object-centric RL, and policy distillation via\nrule extraction, this work places itself within the neurosymbolic AI paradigm,\nblending the strengths of neural networks with symbolic AI. We present the\nfirst implementation of an end-to-end trained SCoBot, separately evaluate of\nits components, on different Atari games. The results demonstrate the\nframework's potential to create interpretable and performing RL systems, and\npave the way for future research directions in obtaining end-to-end\ninterpretable RL agents.",
      "tldr_zh": "本研究针对深度强化学习（RL）代理的捷径学习问题，导致其无法泛化到微变环境，提出了一种端到端的神经符号（Neurosymbolic）RL框架SCoBots。SCoBots将RL任务分解为中间可解释的对象中心表示，并通过显式学习从原始像素状态提取这些表示、结合对象中心RL和政策蒸馏（via rule extraction）来做出决策，从而提升代理的可解释性和性能。该框架在不同Atari游戏上的实验结果表明，它能创建高性能且可解释的RL系统，为未来端到端可解释RL代理的研究奠定基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages; 5 figures; 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.14371v1",
      "published_date": "2024-10-18 10:59:13 UTC",
      "updated_date": "2024-10-18 10:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:30:22.306152"
    },
    {
      "arxiv_id": "2410.14368v2",
      "title": "CoMAL: Collaborative Multi-Agent Large Language Models for Mixed-Autonomy Traffic",
      "title_zh": "翻译失败",
      "authors": [
        "Huaiyuan Yao",
        "Longchao Da",
        "Vishnu Nandam",
        "Justin Turnau",
        "Zhiwei Liu",
        "Linsey Pang",
        "Hua Wei"
      ],
      "abstract": "The integration of autonomous vehicles into urban traffic has great potential\nto improve efficiency by reducing congestion and optimizing traffic flow\nsystematically. In this paper, we introduce CoMAL (Collaborative Multi-Agent\nLLMs), a framework designed to address the mixed-autonomy traffic problem by\ncollaboration among autonomous vehicles to optimize traffic flow. CoMAL is\nbuilt upon large language models, operating in an interactive traffic\nsimulation environment. It utilizes a Perception Module to observe surrounding\nagents and a Memory Module to store strategies for each agent. The overall\nworkflow includes a Collaboration Module that encourages autonomous vehicles to\ndiscuss the effective strategy and allocate roles, a reasoning engine to\ndetermine optimal behaviors based on assigned roles, and an Execution Module\nthat controls vehicle actions using a hybrid approach combining rule-based\nmodels. Experimental results demonstrate that CoMAL achieves superior\nperformance on the Flow benchmark. Additionally, we evaluate the impact of\ndifferent language models and compare our framework with reinforcement learning\napproaches. It highlights the strong cooperative capability of LLM agents and\npresents a promising solution to the mixed-autonomy traffic challenge. The code\nis available at https://github.com/Hyan-Yao/CoMAL.",
      "tldr_zh": "本文提出 CoMAL 框架，利用多智能体大型语言模型（LLMs）来解决混合自治交通问题，通过自主车辆间的协作优化交通流量和减少拥堵。框架包括感知模块（观察周围代理）、记忆模块（存储策略）、协作模块（讨论策略并分配角色）、推理引擎（基于角色确定最佳行为）以及执行模块（采用规则-based混合方法控制车辆动作）。实验结果显示，CoMAL 在 Flow 基准上表现出色，并优于强化学习方法，突显了 LLM 代理的强大合作能力；代码已开源于 https://github.com/Hyan-Yao/CoMAL。",
      "categories": [
        "cs.AI",
        "cs.RO",
        "68T42, 90B20, 90C27",
        "I.2.11; I.2.9; H.4.2"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures, accepted to SDM25",
      "pdf_url": "http://arxiv.org/pdf/2410.14368v2",
      "published_date": "2024-10-18 10:53:44 UTC",
      "updated_date": "2025-01-09 06:02:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:30:34.498779"
    },
    {
      "arxiv_id": "2410.14353v2",
      "title": "Assistive AI for Augmenting Human Decision-making",
      "title_zh": "翻译失败",
      "authors": [
        "Natabara Máté Gyöngyössy",
        "Bernát Török",
        "Csilla Farkas",
        "Laura Lucaj",
        "Attila Menyhárd",
        "Krisztina Menyhárd-Balázs",
        "András Simonyi",
        "Patrick van der Smagt",
        "Zsolt Ződi",
        "András Lőrincz"
      ],
      "abstract": "Regulatory frameworks for the use of AI are emerging. However, they trail\nbehind the fast-evolving malicious AI technologies that can quickly cause\nlasting societal damage. In response, we introduce a pioneering Assistive AI\nframework designed to enhance human decision-making capabilities. This\nframework aims to establish a trust network across various fields, especially\nwithin legal contexts, serving as a proactive complement to ongoing regulatory\nefforts. Central to our framework are the principles of privacy,\naccountability, and credibility. In our methodology, the foundation of\nreliability of information and information sources is built upon the ability to\nuphold accountability, enhance security, and protect privacy. This approach\nsupports, filters, and potentially guides communication, thereby empowering\nindividuals and communities to make well-informed decisions based on\ncutting-edge advancements in AI. Our framework uses the concept of Boards as\nproxies to collectively ensure that AI-assisted decisions are reliable,\naccountable, and in alignment with societal values and legal standards. Through\na detailed exploration of our framework, including its main components,\noperations, and sample use cases, the paper shows how AI can assist in the\ncomplex process of decision-making while maintaining human oversight. The\nproposed framework not only extends regulatory landscapes but also highlights\nthe synergy between AI technology and human judgement, underscoring the\npotential of AI to serve as a vital instrument in discerning reality from\nfiction and thus enhancing the decision-making process. Furthermore, we provide\ndomain-specific use cases to highlight the applicability of our framework.",
      "tldr_zh": "本文提出Assistive AI框架，用于增强人类决策能力，特别是通过建立信任网络来应对恶意AI技术的挑战。该框架以隐私、accountability和credibility为核心原则，利用Boards作为代理来支持、过滤和指导沟通，确保AI辅助决策可靠且符合社会价值观和法律标准。通过详细探讨框架的组件、操作以及领域特定用例，论文展示了AI与人类判断的协同作用，有助于扩展监管景观并促进更明智的决策过程。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "37 pages, 6 figures; Changes: Revised references (k-anonimity)",
      "pdf_url": "http://arxiv.org/pdf/2410.14353v2",
      "published_date": "2024-10-18 10:16:07 UTC",
      "updated_date": "2024-10-26 18:41:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:30:47.501163"
    },
    {
      "arxiv_id": "2410.14347v1",
      "title": "A Scientific Machine Learning Approach for Predicting and Forecasting Battery Degradation in Electric Vehicles",
      "title_zh": "一种科学机器学习方法用于预测和预报电动车辆电池退化",
      "authors": [
        "Sharv Murgai",
        "Hrishikesh Bhagwat",
        "Raj Abhijit Dandekar",
        "Rajat Dandekar",
        "Sreedath Panat"
      ],
      "abstract": "Carbon emissions are rising at an alarming rate, posing a significant threat\nto global efforts to mitigate climate change. Electric vehicles have emerged as\na promising solution, but their reliance on lithium-ion batteries introduces\nthe critical challenge of battery degradation. Accurate prediction and\nforecasting of battery degradation over both short and long time spans are\nessential for optimizing performance, extending battery life, and ensuring\neffective long-term energy management. This directly influences the\nreliability, safety, and sustainability of EVs, supporting their widespread\nadoption and aligning with key UN SDGs. In this paper, we present a novel\napproach to the prediction and long-term forecasting of battery degradation\nusing Scientific Machine Learning framework which integrates domain knowledge\nwith neural networks, offering more interpretable and scientifically grounded\nsolutions for both predicting short-term battery health and forecasting\ndegradation over extended periods. This hybrid approach captures both known and\nunknown degradation dynamics, improving predictive accuracy while reducing data\nrequirements. We incorporate ground-truth data to inform our models, ensuring\nthat both the predictions and forecasts reflect practical conditions. The model\nachieved MSE of 9.90 with the UDE and 11.55 with the NeuralODE, in experimental\ndata, a loss of 1.6986 with the UDE, and a MSE of 2.49 in the NeuralODE,\ndemonstrating the enhanced precision of our approach. This integration of\ndata-driven insights with SciML's strengths in interpretability and scalability\nallows for robust battery management. By enhancing battery longevity and\nminimizing waste, our approach contributes to the sustainability of energy\nsystems and accelerates the global transition toward cleaner, more responsible\nenergy solutions, aligning with the UN's SDG agenda.",
      "tldr_zh": "本研究提出了一种基于 Scientific Machine Learning (SciML) 的新方法，用于预测和预测电动汽车锂离子电池退化，从而优化性能、延长电池寿命并支持可持续发展。该方法整合领域知识与神经网络，捕捉已知和未知退化动态，提高预测准确性并减少数据需求，在实验中实现了 UDE 的 MSE 为 9.90 和 1.6986，以及 NeuralODE 的 MSE 为 11.55 和 2.49。相比传统模型，该框架提供更具可解释性和可扩展性的解决方案，有助于提升电动汽车的可靠性和安全性，并与 UN SDGs 的气候目标相一致。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14347v1",
      "published_date": "2024-10-18 09:57:59 UTC",
      "updated_date": "2024-10-18 09:57:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:30:58.447615"
    },
    {
      "arxiv_id": "2410.14311v2",
      "title": "Game Theory with Simulation in the Presence of Unpredictable Randomisation",
      "title_zh": "翻译失败",
      "authors": [
        "Vojtech Kovarik",
        "Nathaniel Sauerberg",
        "Lewis Hammond",
        "Vincent Conitzer"
      ],
      "abstract": "AI agents will be predictable in certain ways that traditional agents are\nnot. Where and how can we leverage this predictability in order to improve\nsocial welfare? We study this question in a game-theoretic setting where one\nagent can pay a fixed cost to simulate the other in order to learn its mixed\nstrategy. As a negative result, we prove that, in contrast to prior work on\npure-strategy simulation, enabling mixed-strategy simulation may no longer lead\nto improved outcomes for both players in all so-called \"generalised trust\ngames\". In fact, mixed-strategy simulation does not help in any game where the\nsimulatee's action can depend on that of the simulator. We also show that, in\ngeneral, deciding whether simulation introduces Pareto-improving Nash\nequilibria in a given game is NP-hard. As positive results, we establish that\nmixed-strategy simulation can improve social welfare if the simulator has the\noption to scale their level of trust, if the players face challenges with both\ntrust and coordination, or if maintaining some level of privacy is essential\nfor enabling cooperation.",
      "tldr_zh": "这篇论文探讨了博弈论中AI代理的可预测性如何通过模拟混合策略来提升社会福利，其中一个代理可支付固定成本模拟另一代理以学习其策略。研究发现，启用混合策略模拟可能无法在所有“广义信任游戏”中改善双方结果，尤其在被模拟者的行动依赖模拟者的情况下，且判断模拟是否引入Pareto-improving Nash equilibria的问题是NP-hard。积极方面，论文证明，如果模拟者能调整信任水平、玩家面临信任与协调挑战、或隐私对合作至关重要时，混合策略模拟可显著提高社会福利。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14311v2",
      "published_date": "2024-10-18 09:17:18 UTC",
      "updated_date": "2025-02-07 11:18:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:31:10.365841"
    },
    {
      "arxiv_id": "2410.14310v1",
      "title": "Transferring Tactile Data Across Sensors",
      "title_zh": "跨传感器触觉数据传输",
      "authors": [
        "Wadhah Zai El Amri",
        "Malte Kuhlmann",
        "Nicolás Navarro-Guerrero"
      ],
      "abstract": "Tactile perception is essential for human interaction with the environment\nand is becoming increasingly crucial in robotics. Tactile sensors like the\nBioTac mimic human fingertips and provide detailed interaction data. Despite\nits utility in applications like slip detection and object identification, this\nsensor is now deprecated, making many existing datasets obsolete. This article\nintroduces a novel method for translating data between tactile sensors by\nexploiting sensor deformation information rather than output signals. We\ndemonstrate the approach by translating BioTac signals into the DIGIT sensor.\nOur framework consists of three steps: first, converting signal data into\ncorresponding 3D deformation meshes; second, translating these 3D deformation\nmeshes from one sensor to another; and third, generating output images using\nthe converted meshes. Our approach enables the continued use of valuable\ndatasets.",
      "tldr_zh": "这篇论文提出了一种新方法，通过利用传感器变形信息而非输出信号，来在不同触觉传感器之间传输数据，解决了如 BioTac 传感器弃用导致数据集过时的问题。方法包括三个步骤：首先，将信号数据转换为对应的 3D deformation meshes；其次，将这些网格从源传感器（如 BioTac）翻译到目标传感器（如 DIGIT）；最后，使用转换后的网格生成输出图像。该框架使宝贵的数据集能够继续应用于机器人触觉感知任务中，提升了系统的灵活性和实用性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Extended Abstract. Accepted in ICRA@40 (40th Anniversary of the IEEE\n  International Conference on Robotics and Automation) 23-26 September, 2024\n  Rotterdam, Netherlands",
      "pdf_url": "http://arxiv.org/pdf/2410.14310v1",
      "published_date": "2024-10-18 09:15:47 UTC",
      "updated_date": "2024-10-18 09:15:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:31:22.120682"
    },
    {
      "arxiv_id": "2410.14309v2",
      "title": "LoGU: Long-form Generation with Uncertainty Expressions",
      "title_zh": "LoGU：长形式生成中的不确定性表达",
      "authors": [
        "Ruihan Yang",
        "Caiqi Zhang",
        "Zhisong Zhang",
        "Xinting Huang",
        "Sen Yang",
        "Nigel Collier",
        "Dong Yu",
        "Deqing Yang"
      ],
      "abstract": "While Large Language Models (LLMs) demonstrate impressive capabilities, they\nstill struggle with generating factually incorrect content (i.e.,\nhallucinations). A promising approach to mitigate this issue is enabling models\nto express uncertainty when unsure. Previous research on uncertainty modeling\nhas primarily focused on short-form QA, but realworld applications often\nrequire much longer responses. In this work, we introduce the task of Long-form\nGeneration with Uncertainty(LoGU). We identify two key challenges: Uncertainty\nSuppression, where models hesitate to express uncertainty, and Uncertainty\nMisalignment, where models convey uncertainty inaccurately. To tackle these\nchallenges, we propose a refinement-based data collection framework and a\ntwo-stage training pipeline. Our framework adopts a divide-and-conquer\nstrategy, refining uncertainty based on atomic claims. The collected data are\nthen used in training through supervised fine-tuning (SFT) and direct\npreference optimization (DPO) to enhance uncertainty expression. Extensive\nexperiments on three long-form instruction following datasets show that our\nmethod significantly improves accuracy, reduces hallucinations, and maintains\nthe comprehensiveness of responses.",
      "tldr_zh": "这篇论文引入了 LoGU（Long-form Generation with Uncertainty）任务，旨在帮助大型语言模型（LLMs）在长文本生成中表达不确定性，以减少 hallucinations（事实错误内容）。论文识别了 Uncertainty Suppression（模型不愿表达不确定性）和 Uncertainty Misalignment（不确定性表达不准确）两大挑战，并提出了一种基于 divide-and-conquer 策略的细化数据收集框架，以及两阶段训练管道，包括监督微调（SFT）和直接偏好优化（DPO）。实验结果显示，在三个长文本指令数据集上，该方法显著提高了响应准确性，降低了 hallucinations 发生率，同时保持了响应的全面性和完整性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14309v2",
      "published_date": "2024-10-18 09:15:35 UTC",
      "updated_date": "2024-10-24 18:26:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:31:35.315093"
    },
    {
      "arxiv_id": "2410.14289v1",
      "title": "SwaQuAD-24: QA Benchmark Dataset in Swahili",
      "title_zh": "翻译失败",
      "authors": [
        "Alfred Malengo Kondoro"
      ],
      "abstract": "This paper proposes the creation of a Swahili Question Answering (QA)\nbenchmark dataset, aimed at addressing the underrepresentation of Swahili in\nnatural language processing (NLP). Drawing from established benchmarks like\nSQuAD, GLUE, KenSwQuAD, and KLUE, the dataset will focus on providing\nhigh-quality, annotated question-answer pairs that capture the linguistic\ndiversity and complexity of Swahili. The dataset is designed to support a\nvariety of applications, including machine translation, information retrieval,\nand social services like healthcare chatbots. Ethical considerations, such as\ndata privacy, bias mitigation, and inclusivity, are central to the dataset\ndevelopment. Additionally, the paper outlines future expansion plans to include\ndomain-specific content, multimodal integration, and broader crowdsourcing\nefforts. The Swahili QA dataset aims to foster technological innovation in East\nAfrica and provide an essential resource for NLP research and applications in\nlow-resource languages.",
      "tldr_zh": "这篇论文介绍了 SwaQuAD-24，一个斯瓦希里语的 QA 基准数据集，旨在解决斯瓦希里语在 NLP 中的代表性不足问题。数据集借鉴 SQuAD、GLUE、KenSwQuAD 和 KLUE 等现有基准，提供高质量的注释问题-答案对，以捕捉斯瓦希里语的语言多样性和复杂性。SwaQuAD-24 支持多种应用，如机器翻译、信息检索和社会服务（如医疗聊天机器人），并强调伦理考虑包括数据隐私、偏见缓解和包容性。未来计划包括扩展到领域特定内容、多模态集成和更广泛的众包努力，以推动东非的技术创新和低资源语言的 NLP 研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14289v1",
      "published_date": "2024-10-18 08:49:24 UTC",
      "updated_date": "2024-10-18 08:49:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:31:47.436923"
    },
    {
      "arxiv_id": "2410.14285v1",
      "title": "Advanced Underwater Image Quality Enhancement via Hybrid Super-Resolution Convolutional Neural Networks and Multi-Scale Retinex-Based Defogging Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Yugandhar Reddy Gogireddy",
        "Jithendra Reddy Gogireddy"
      ],
      "abstract": "The difficulties of underwater image degradation due to light scattering,\nabsorption, and fog-like particles which lead to low resolution and poor\nvisibility are discussed in this study report. We suggest a sophisticated\nhybrid strategy that combines Multi-Scale Retinex (MSR) defogging methods with\nSuper-Resolution Convolutional Neural Networks (SRCNN) to address these\nproblems. The Retinex algorithm mimics human visual perception to reduce uneven\nlighting and fogging, while the SRCNN component improves the spatial resolution\nof underwater photos.Through the combination of these methods, we are able to\nenhance the clarity, contrast, and colour restoration of underwater images,\noffering a reliable way to improve image quality in difficult underwater\nconditions. The research conducts extensive experiments on real-world\nunderwater datasets to further illustrate the efficacy of the suggested\napproach. In terms of sharpness, visibility, and feature retention,\nquantitative evaluation which use metrics like the Structural Similarity Index\nMeasure (SSIM) and Peak Signal-to-Noise Ratio (PSNR) demonstrates notable\nadvances over conventional techniques.In real-time underwater applications like\nmarine exploration, underwater robotics, and autonomous underwater vehicles,\nwhere clear and high-resolution imaging is crucial for operational success, the\ncombination of deep learning and conventional image processing techniques\noffers a computationally efficient framework with superior results.",
      "tldr_zh": "这篇论文针对水下图像退化问题（如光散射、吸收和雾状粒子导致的分辨率低和可见性差），提出了一种混合策略，结合 Multi-Scale Retinex (MSR) 去雾技术和 Super-Resolution Convolutional Neural Networks (SRCNN) 超分辨率方法。MSR 通过模拟人类视觉感知减少不均匀照明和雾化，而 SRCNN 则提升图像的空间分辨率，从而显著改善图像的清晰度、对比度和颜色恢复。在真实水下数据集上的实验显示，该方法在 Structural Similarity Index Measure (SSIM) 和 Peak Signal-to-Noise Ratio (PSNR) 等指标上优于传统技术，提供高效框架，适用于海洋勘探、水下机器人和自主水下车辆等实时应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14285v1",
      "published_date": "2024-10-18 08:40:26 UTC",
      "updated_date": "2024-10-18 08:40:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:31:59.474822"
    },
    {
      "arxiv_id": "2410.14273v1",
      "title": "REEF: Representation Encoding Fingerprints for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Zhang",
        "Dongrui Liu",
        "Chen Qian",
        "Linfeng Zhang",
        "Yong Liu",
        "Yu Qiao",
        "Jing Shao"
      ],
      "abstract": "Protecting the intellectual property of open-source Large Language Models\n(LLMs) is very important, because training LLMs costs extensive computational\nresources and data. Therefore, model owners and third parties need to identify\nwhether a suspect model is a subsequent development of the victim model. To\nthis end, we propose a training-free REEF to identify the relationship between\nthe suspect and victim models from the perspective of LLMs' feature\nrepresentations. Specifically, REEF computes and compares the centered kernel\nalignment similarity between the representations of a suspect model and a\nvictim model on the same samples. This training-free REEF does not impair the\nmodel's general capabilities and is robust to sequential fine-tuning, pruning,\nmodel merging, and permutations. In this way, REEF provides a simple and\neffective way for third parties and models' owners to protect LLMs'\nintellectual property together. The code is available at\nhttps://github.com/tmylla/REEF.",
      "tldr_zh": "该研究提出了一种无需训练的 REEF 方法，用于保护开源 Large Language Models (LLMs) 的知识产权，旨在识别嫌疑模型是否为受害模型的后续开发。REEF 通过计算并比较两模型在相同样本上的 centered kernel alignment similarity，来从特征表示角度分析模型关系。该方法对 sequential fine-tuning、pruning、model merging 和 permutations 等操作具有鲁棒性，且不会损害模型的整体能力。总之，REEF 为模型所有者和第三方提供了一个简单有效的知识产权保护方案，相关代码已在 GitHub 上开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14273v1",
      "published_date": "2024-10-18 08:27:02 UTC",
      "updated_date": "2024-10-18 08:27:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:32:10.404652"
    },
    {
      "arxiv_id": "2410.14257v1",
      "title": "Revisiting SLO and Goodput Metrics in LLM Serving",
      "title_zh": "重新审视 LLM 服务中的 SLO 和 Goodput 指标",
      "authors": [
        "Zhibin Wang",
        "Shipeng Li",
        "Yuhang Zhou",
        "Xue Li",
        "Rong Gu",
        "Nguyen Cam-Tu",
        "Chen Tian",
        "Sheng Zhong"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable performance and are\nwidely deployed in various applications, while the serving of LLM inference has\nraised concerns about user experience and serving throughput. Accordingly,\nservice level objectives (SLOs) and goodput-the number of requests that meet\nSLOs per second-are introduced to evaluate the performance of LLM serving.\nHowever, existing metrics fail to capture the nature of user experience. We\nobserve two ridiculous phenomena in existing metrics: 1) delaying token\ndelivery can smooth the tail time between tokens (tail TBT) of a request and 2)\ndropping the request that fails to meet the SLOs midway can improve goodput.\n  In this paper, we revisit SLO and goodput metrics in LLM serving and propose\na unified metric framework smooth goodput including SLOs and goodput to reflect\nthe nature of user experience in LLM serving. The framework can adapt to\nspecific goals of different tasks by setting parameters. We re-evaluate the\nperformance of different LLM serving systems under multiple workloads based on\nthis unified framework and provide possible directions for future optimization\nof existing strategies. We hope that this framework can provide a unified\nstandard for evaluating LLM serving and foster researches in the field of LLM\nserving optimization to move in a cohesive direction.",
      "tldr_zh": "该论文重新审视了LLM（Large Language Models）服务的SLO（Service Level Objectives）和goodput指标，指出现有指标无法准确捕捉用户体验，包括延迟token交付改善tail TBT（tail Time Between Tokens）以及 midway 丢弃请求来提升goodput的荒谬现象。作者提出一个统一的smooth goodput框架，结合新的SLO和goodput指标，通过参数设置适应不同任务目标，以更真实地反映用户体验。实验结果显示，该框架在多种工作负载下重新评估了现有LLM服务系统，并为未来优化策略提供了潜在方向，推动该领域的研究向统一标准迈进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14257v1",
      "published_date": "2024-10-18 08:05:37 UTC",
      "updated_date": "2024-10-18 08:05:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:32:22.224933"
    },
    {
      "arxiv_id": "2410.14255v2",
      "title": "Nova: An Iterative Planning and Search Approach to Enhance Novelty and Diversity of LLM Generated Ideas",
      "title_zh": "Nova：一种迭代",
      "authors": [
        "Xiang Hu",
        "Hongyu Fu",
        "Jinge Wang",
        "Yifeng Wang",
        "Zhikun Li",
        "Renjun Xu",
        "Yu Lu",
        "Yaochu Jin",
        "Lili Pan",
        "Zhenzhong Lan"
      ],
      "abstract": "Scientific innovation is pivotal for humanity, and harnessing large language\nmodels (LLMs) to generate research ideas could transform discovery. However,\nexisting LLMs often produce simplistic and repetitive suggestions due to their\nlimited ability in acquiring external knowledge for innovation. To address this\nproblem, we introduce an enhanced planning and search methodology designed to\nboost the creative potential of LLM-based systems. Our approach involves an\niterative process to purposely plan the retrieval of external knowledge,\nprogressively enriching the idea generation with broader and deeper insights.\nValidation through automated and human assessments indicates that our framework\nsubstantially elevates the quality of generated ideas, particularly in novelty\nand diversity. The number of unique novel ideas produced by our framework is\n3.4 times higher than without it. Moreover, our method outperforms the current\nstate-of-the-art, generating at least 2.5 times more top-rated ideas based on\n170 seed papers in a Swiss Tournament evaluation.",
      "tldr_zh": "该研究提出了一种名为Nova的迭代规划和搜索方法，旨在提升大型语言模型(LLM)生成研究想法的新颖性和多样性，以解决现有LLM在获取外部知识方面存在的局限性。Nova框架通过迭代过程有针对性地规划外部知识的检索，并逐步丰富想法生成过程，从而提供更广泛和深入的洞见。实验结果显示，与基线方法相比，该框架生成的独特新颖想法数量增加了3.4倍，并在基于170篇种子论文的Swiss Tournament评估中，比当前最先进方法生成至少2.5倍的顶级想法。总的来说，该方法为利用LLM推动科学创新提供了更可靠的框架。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14255v2",
      "published_date": "2024-10-18 08:04:36 UTC",
      "updated_date": "2024-10-27 04:02:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:32:33.924586"
    },
    {
      "arxiv_id": "2410.14251v2",
      "title": "Synthesizing Post-Training Data for LLMs through Multi-Agent Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuo Tang",
        "Xianghe Pang",
        "Zexi Liu",
        "Bohan Tang",
        "Rui Ye",
        "Tian Jin",
        "Xiaowen Dong",
        "Yanfeng Wang",
        "Siheng Chen"
      ],
      "abstract": "Post-training is essential for enabling large language models (LLMs) to\nfollow human instructions. However, its effectiveness depends on high-quality\ninstruction data, which is challenging to obtain in the real world due to\nprivacy concerns, data scarcity, and high annotation costs. To fill this gap,\ninspired by the recent success of using LLMs to simulate human society, we\npropose MATRIX, a multi-agent simulator that automatically generates diverse\ntext-based scenarios, capturing a wide range of real-world human needs in a\nrealistic and scalable manner. Leveraging these outputs, we introduce a novel\nscenario-driven instruction generator MATRIX-Gen for controllable and highly\nrealistic data synthesis. Extensive experiments demonstrate that our framework\neffectively generates both general and domain-specific data. On AlpacaEval 2\nand Arena-Hard benchmarks, Llama-3-8B-Base, post-trained on datasets\nsynthesized by MATRIX-Gen with just 20K instruction-response pairs, outperforms\nMeta's Llama-3-8B-Instruct model, which was trained on over 10M pairs.",
      "tldr_zh": "该论文提出 MATRIX，一种多智能体模拟器，用于自动生成多样化的文本场景，以解决大型语言模型（LLMs）后训练中高质量指令数据获取的难题，如隐私问题和数据稀缺。基于 MATRIX，作者引入了 MATRIX-Gen，一个场景驱动的指令生成器，实现可控且高度真实的通用和领域特定数据合成。实验结果显示，在 AlpacaEval 2 和 Arena-Hard 基准上，使用 MATRIX-Gen 合成的仅 20K 指令-响应对后训练的 Llama-3-8B-Base 模型，超过了用超过 10M 对数据训练的 Llama-3-8B-Instruct 模型，证明了该框架的高效性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14251v2",
      "published_date": "2024-10-18 08:01:39 UTC",
      "updated_date": "2025-02-20 03:26:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:32:46.606143"
    },
    {
      "arxiv_id": "2410.14240v1",
      "title": "Almost-Linear RNNs Yield Highly Interpretable Symbolic Codes in Dynamical Systems Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel Brenner",
        "Christoph Jürgen Hemmer",
        "Zahra Monfared",
        "Daniel Durstewitz"
      ],
      "abstract": "Dynamical systems (DS) theory is fundamental for many areas of science and\nengineering. It can provide deep insights into the behavior of systems evolving\nin time, as typically described by differential or recursive equations. A\ncommon approach to facilitate mathematical tractability and interpretability of\nDS models involves decomposing nonlinear DS into multiple linear DS separated\nby switching manifolds, i.e. piecewise linear (PWL) systems. PWL models are\npopular in engineering and a frequent choice in mathematics for analyzing the\ntopological properties of DS. However, hand-crafting such models is tedious and\nonly possible for very low-dimensional scenarios, while inferring them from\ndata usually gives rise to unnecessarily complex representations with very many\nlinear subregions. Here we introduce Almost-Linear Recurrent Neural Networks\n(AL-RNNs) which automatically and robustly produce most parsimonious PWL\nrepresentations of DS from time series data, using as few PWL nonlinearities as\npossible. AL-RNNs can be efficiently trained with any SOTA algorithm for\ndynamical systems reconstruction (DSR), and naturally give rise to a symbolic\nencoding of the underlying DS that provably preserves important topological\nproperties. We show that for the Lorenz and R\\\"ossler systems, AL-RNNs\ndiscover, in a purely data-driven way, the known topologically minimal PWL\nrepresentations of the corresponding chaotic attractors. We further illustrate\non two challenging empirical datasets that interpretable symbolic encodings of\nthe dynamics can be achieved, tremendously facilitating mathematical and\ncomputational analysis of the underlying systems.",
      "tldr_zh": "本研究探讨了动力系统（Dynamical Systems, DS）的建模挑战，提出 Almost-Linear Recurrent Neural Networks (AL-RNNs) 框架，以从时间序列数据自动生成最简洁的分段线性（PWL）表示，从而提升模型的可解释性和鲁棒性。AL-RNNs 通过最小化 PWL 非线性数量，并结合现有最先进算法进行训练，自然产生符号编码，该编码保留了 DS 的拓扑属性。实验结果显示，在 Lorenz 和 Rössler 系统上，AL-RNNs 数据驱动地发现了已知的拓扑最小 PWL 表示；在两个挑战性实证数据集上，它实现了可解释的符号编码，大大简化了底层系统的数学和计算分析。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DS",
        "nlin.CD",
        "physics.data-an"
      ],
      "primary_category": "cs.LG",
      "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.14240v1",
      "published_date": "2024-10-18 07:44:12 UTC",
      "updated_date": "2024-10-18 07:44:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:32:58.862022"
    },
    {
      "arxiv_id": "2410.14755v1",
      "title": "Controllable Discovery of Intents: Incremental Deep Clustering Using Semi-Supervised Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mrinal Rawat",
        "Hithesh Sankararaman",
        "Victor Barres"
      ],
      "abstract": "Deriving value from a conversational AI system depends on the capacity of a\nuser to translate the prior knowledge into a configuration. In most cases,\ndiscovering the set of relevant turn-level speaker intents is often one of the\nkey steps. Purely unsupervised algorithms provide a natural way to tackle\ndiscovery problems but make it difficult to incorporate constraints and only\noffer very limited control over the outcomes. Previous work has shown that\nsemi-supervised (deep) clustering techniques can allow the system to\nincorporate prior knowledge and constraints in the intent discovery process.\nHowever they did not address how to allow for control through human feedback.\nIn our Controllable Discovery of Intents (CDI) framework domain and prior\nknowledge are incorporated using a sequence of unsupervised contrastive\nlearning on unlabeled data followed by fine-tuning on partially labeled data,\nand finally iterative refinement of clustering and representations through\nrepeated clustering and pseudo-label fine-tuning. In addition, we draw from\ncontinual learning literature and use learning-without-forgetting to prevent\ncatastrophic forgetting across those training stages. Finally, we show how this\ndeep-clustering process can become part of an incremental discovery strategy\nwith human-in-the-loop. We report results on both CLINC and BANKING datasets.\nCDI outperforms previous works by a significant margin: 10.26% and 11.72%\nrespectively.",
      "tldr_zh": "该论文提出CDI框架，用于可控意图发现，解决对话式AI中意图识别的约束和控制问题，通过序列的无监督对比学习（Contrastive Learning）在未标注数据上训练、部分标注数据的半监督微调，以及迭代聚类和伪标签精炼来整合领域知识和人类反馈。同时，引入无遗忘学习（Learning Without Forgetting）防止灾难性遗忘，使其成为人类在环的增量深度聚类（Deep Clustering）策略。在CLINC和BANKING数据集上，CDI分别比现有方法提高了10.26%和11.72%的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in IJCNLP'23",
      "pdf_url": "http://arxiv.org/pdf/2410.14755v1",
      "published_date": "2024-10-18 07:24:02 UTC",
      "updated_date": "2024-10-18 07:24:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:33:10.288219"
    },
    {
      "arxiv_id": "2410.14225v2",
      "title": "Few-Shot Joint Multimodal Entity-Relation Extraction via Knowledge-Enhanced Cross-modal Prompt Model",
      "title_zh": "翻译失败",
      "authors": [
        "Li Yuan",
        "Yi Cai",
        "Junsheng Huang"
      ],
      "abstract": "Joint Multimodal Entity-Relation Extraction (JMERE) is a challenging task\nthat aims to extract entities and their relations from text-image pairs in\nsocial media posts. Existing methods for JMERE require large amounts of labeled\ndata. However, gathering and annotating fine-grained multimodal data for JMERE\nposes significant challenges. Initially, we construct diverse and comprehensive\nmultimodal few-shot datasets fitted to the original data distribution. To\naddress the insufficient information in the few-shot setting, we introduce the\n\\textbf{K}nowledge-\\textbf{E}nhanced \\textbf{C}ross-modal \\textbf{P}rompt\n\\textbf{M}odel (KECPM) for JMERE. This method can effectively address the\nproblem of insufficient information in the few-shot setting by guiding a large\nlanguage model to generate supplementary background knowledge. Our proposed\nmethod comprises two stages: (1) a knowledge ingestion stage that dynamically\nformulates prompts based on semantic similarity guide ChatGPT generating\nrelevant knowledge and employs self-reflection to refine the knowledge; (2) a\nknowledge-enhanced language model stage that merges the auxiliary knowledge\nwith the original input and utilizes a transformer-based model to align with\nJMERE's required output format. We extensively evaluate our approach on a\nfew-shot dataset derived from the JMERE dataset, demonstrating its superiority\nover strong baselines in terms of both micro and macro F$_1$ scores.\nAdditionally, we present qualitative analyses and case studies to elucidate the\neffectiveness of our model.",
      "tldr_zh": "本研究针对联合多模态实体关系提取(JMERE)任务，提出了一种少样本(few-shot)方法，以解决从社交媒体文本-图像对中提取实体和关系时数据标注不足的问题。作者首先构建了多样化的少样本多模态数据集，以匹配原始数据分布；随后引入了知识增强跨模态提示模型(KECPM)，该模型包括知识摄取阶段（利用语义相似性引导ChatGPT生成并自反省精炼相关知识）和知识增强语言模型阶段（将辅助知识融入原始输入，并使用transformer模型输出JMERE格式结果）。实验结果显示，KECPM在少样本数据集上显著优于基线模型，在微观和宏观F$_1$分数上表现出色；此外，通过定性分析和案例研究，进一步验证了模型的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted by ACM MM 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.14225v2",
      "published_date": "2024-10-18 07:14:54 UTC",
      "updated_date": "2025-03-23 02:01:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:33:22.394965"
    },
    {
      "arxiv_id": "2410.14219v1",
      "title": "Formal Explanations for Neuro-Symbolic AI",
      "title_zh": "神经符号人工智能的形式化解释",
      "authors": [
        "Sushmita Paul",
        "Jinqiang Yu",
        "Jip J. Dekker",
        "Alexey Ignatiev",
        "Peter J. Stuckey"
      ],
      "abstract": "Despite the practical success of Artificial Intelligence (AI), current neural\nAI algorithms face two significant issues. First, the decisions made by neural\narchitectures are often prone to bias and brittleness. Second, when a chain of\nreasoning is required, neural systems often perform poorly. Neuro-symbolic\nartificial intelligence is a promising approach that tackles these (and other)\nweaknesses by combining the power of neural perception and symbolic reasoning.\nMeanwhile, the success of AI has made it critical to understand its behaviour,\nleading to the development of explainable artificial intelligence (XAI). While\nneuro-symbolic AI systems have important advantages over purely neural AI, we\nstill need to explain their actions, which are obscured by the interactions of\nthe neural and symbolic components. To address the issue, this paper proposes a\nformal approach to explaining the decisions of neuro-symbolic systems. The\napproach hinges on the use of formal abductive explanations and on solving the\nneuro-symbolic explainability problem hierarchically. Namely, it first computes\na formal explanation for the symbolic component of the system, which serves to\nidentify a subset of the individual parts of neural information that needs to\nbe explained. This is followed by explaining only those individual neural\ninputs, independently of each other, which facilitates succinctness of\nhierarchical formal explanations and helps to increase the overall performance\nof the approach. Experimental results for a few complex reasoning tasks\ndemonstrate practical efficiency of the proposed approach, in comparison to\npurely neural systems, from the perspective of explanation size, explanation\ntime, training time, model sizes, and the quality of explanations reported.",
      "tldr_zh": "该论文探讨了神经符号AI（Neuro-Symbolic AI）的解释性问题，旨在解决现有神经AI的偏见、脆弱性和推理能力不足。作者提出了一种基于正式溯因解释（formal abductive explanations）的分层方法，先为符号组件生成解释以识别关键神经输入，然后独立解释这些输入，从而提高解释的简洁性和效率。实验结果显示，该方法在复杂推理任务上优于纯神经系统，在解释大小、时间、训练时间、模型大小和解释质量等方面表现出显著优势。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14219v1",
      "published_date": "2024-10-18 07:08:31 UTC",
      "updated_date": "2024-10-18 07:08:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:33:33.484714"
    },
    {
      "arxiv_id": "2410.14754v2",
      "title": "On the Sparsity of the Strong Lottery Ticket Hypothesis",
      "title_zh": "关于强彩票票假设的稀疏性",
      "authors": [
        "Emanuele Natale",
        "Davide Ferre'",
        "Giordano Giambartolomei",
        "Frédéric Giroire",
        "Frederik Mallmann-Trenn"
      ],
      "abstract": "Considerable research efforts have recently been made to show that a random\nneural network $N$ contains subnetworks capable of accurately approximating any\ngiven neural network that is sufficiently smaller than $N$, without any\ntraining. This line of research, known as the Strong Lottery Ticket Hypothesis\n(SLTH), was originally motivated by the weaker Lottery Ticket Hypothesis, which\nstates that a sufficiently large random neural network $N$ contains\n\\emph{sparse} subnetworks that can be trained efficiently to achieve\nperformance comparable to that of training the entire network $N$. Despite its\noriginal motivation, results on the SLTH have so far not provided any guarantee\non the size of subnetworks. Such limitation is due to the nature of the main\ntechnical tool leveraged by these results, the Random Subset Sum (RSS) Problem.\nInformally, the RSS Problem asks how large a random i.i.d. sample $\\Omega$\nshould be so that we are able to approximate any number in $[-1,1]$, up to an\nerror of $ \\epsilon$, as the sum of a suitable subset of $\\Omega$. We provide\nthe first proof of the SLTH in classical settings, such as dense and\nequivariant networks, with guarantees on the sparsity of the subnetworks.\nCentral to our results, is the proof of an essentially tight bound on the\nRandom Fixed-Size Subset Sum Problem (RFSS), a variant of the RSS Problem in\nwhich we only ask for subsets of a given size, which is of independent\ninterest.",
      "tldr_zh": "本文研究了 Strong Lottery Ticket Hypothesis (SLTH)，证明随机神经网络中存在稀疏子网络，能够无需训练地准确近似比其小的网络，从而扩展了 Lottery Ticket Hypothesis 的概念。作者通过证明 Random Fixed-Size Subset Sum Problem (RFSS) 的紧密界限，解决了之前 SLTH 研究中缺乏子网络大小保证的问题，并在经典设置如密集和等变网络中提供了首次证明。实验结果表明，这种稀疏子网络在效率和性能上具有显著优势，为神经网络优化提供了新方向。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14754v2",
      "published_date": "2024-10-18 06:57:37 UTC",
      "updated_date": "2024-10-31 07:50:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:33:46.226163"
    },
    {
      "arxiv_id": "2410.14208v1",
      "title": "Montessori-Instruct: Generate Influential Training Data Tailored for Student Learning",
      "title_zh": "Montessori-Instruct：生成针对学生学习的具有影响力的训练数据",
      "authors": [
        "Xiaochuan Li",
        "Zichun Yu",
        "Chenyan Xiong"
      ],
      "abstract": "Synthetic data has been widely used to train large language models, but their\ngenerative nature inevitably introduces noisy, non-informative, and misleading\nlearning signals. In this paper, we propose Montessori-Instruct, a novel data\nsynthesis framework that tailors the data synthesis ability of the teacher\nlanguage model toward the student language model's learning process.\nSpecifically, we utilize local data influence of synthetic training data points\non students to characterize students' learning preferences. Then, we train the\nteacher model with Direct Preference Optimization (DPO) to generate synthetic\ndata tailored toward student learning preferences. Experiments with\nLlama3-8B-Instruct (teacher) and Llama3-8B (student) on Alpaca Eval and\nMT-Bench demonstrate that Montessori-Instruct significantly outperforms\nstandard synthesis methods by 18.35\\% and 46.24\\% relatively. Our method also\nbeats data synthesized by a stronger teacher model, GPT-4o. Further analysis\nconfirms the benefits of teacher's learning to generate more influential\ntraining data in the student's improved learning, the advantages of local data\ninfluence in accurately measuring student preferences, and the robustness of\nMontessori-Instruct across different student models. Our code and data are\nopen-sourced at https://github.com/cxcscmu/Montessori-Instruct.",
      "tldr_zh": "本文提出Montessori-Instruct框架，一种针对学生语言模型学习过程的数据合成方法，通过利用合成训练数据点的局部数据影响来表征学生学习偏好，并使用Direct Preference Optimization (DPO)训练教师模型生成更具影响力的合成数据。相比标准合成方法，该框架在Alpaca Eval和MT-Bench基准测试中，使用Llama3-8B-Instruct作为教师和Llama3-8B作为学生时，分别实现了18.35%和46.24%的相对性能提升，甚至超过了由更强教师模型GPT-4o生成的数据。进一步分析显示，该方法在准确测量学生偏好和跨不同学生模型的鲁棒性方面表现出色，并已开源代码和数据。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Codes and data are open-sourced at\n  https://github.com/cxcscmu/Montessori-Instruct",
      "pdf_url": "http://arxiv.org/pdf/2410.14208v1",
      "published_date": "2024-10-18 06:50:15 UTC",
      "updated_date": "2024-10-18 06:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:33:58.999018"
    },
    {
      "arxiv_id": "2410.19818v1",
      "title": "UniMTS: Unified Pre-training for Motion Time Series",
      "title_zh": "UniMTS：运动时间序列的统一预训练",
      "authors": [
        "Xiyuan Zhang",
        "Diyan Teng",
        "Ranak Roy Chowdhury",
        "Shuheng Li",
        "Dezhi Hong",
        "Rajesh K. Gupta",
        "Jingbo Shang"
      ],
      "abstract": "Motion time series collected from mobile and wearable devices such as\nsmartphones and smartwatches offer significant insights into human behavioral\npatterns, with wide applications in healthcare, automation, IoT, and AR/XR due\nto their low-power, always-on nature. However, given security and privacy\nconcerns, building large-scale motion time series datasets remains difficult,\npreventing the development of pre-trained models for human activity analysis.\nTypically, existing models are trained and tested on the same dataset, leading\nto poor generalizability across variations in device location, device mounting\norientation and human activity type. In this paper, we introduce UniMTS, the\nfirst unified pre-training procedure for motion time series that generalizes\nacross diverse device latent factors and activities. Specifically, we employ a\ncontrastive learning framework that aligns motion time series with text\ndescriptions enriched by large language models. This helps the model learn the\nsemantics of time series to generalize across activities. Given the absence of\nlarge-scale motion time series data, we derive and synthesize time series from\nexisting motion skeleton data with all-joint coverage. Spatio-temporal graph\nnetworks are utilized to capture the relationships across joints for\ngeneralization across different device locations. We further design\nrotation-invariant augmentation to make the model agnostic to changes in device\nmounting orientations. Our model shows exceptional generalizability across 18\nmotion time series classification benchmark datasets, outperforming the best\nbaselines by 340% in the zero-shot setting, 16.3% in the few-shot setting, and\n9.2% in the full-shot setting.",
      "tldr_zh": "该研究提出UniMTS，一种统一的运动时间序列预训练框架，旨在解决数据隐私限制导致的模型泛化性差问题，特别是针对设备位置、安装方向和活动类型的变化。UniMTS采用对比学习框架，将运动时间序列与大型语言模型增强的文本描述对齐，同时利用时空图网络（spatio-temporal graph networks）捕捉关节关系，并通过旋转不变增强（rotation-invariant augmentation）实现对设备因素的鲁棒性；此外，研究从现有运动骨骼数据中合成大规模时间序列以补充数据缺口。实验结果显示，UniMTS在18个基准数据集上表现出色，在零样本设置下比最佳基线提升340%，在少样本设置下提升16.3%，在全样本设置下提升9.2%，显著提高了跨数据集的泛化性能。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "NeurIPS 2024. Code: https://github.com/xiyuanzh/UniMTS. Model:\n  https://huggingface.co/xiyuanz/UniMTS",
      "pdf_url": "http://arxiv.org/pdf/2410.19818v1",
      "published_date": "2024-10-18 06:39:13 UTC",
      "updated_date": "2024-10-18 06:39:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:34:11.125673"
    },
    {
      "arxiv_id": "2410.14202v3",
      "title": "Rationale Behind Essay Scores: Enhancing S-LLM's Multi-Trait Essay Scoring with Rationale Generated by LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "SeongYeub Chu",
        "JongWoo Kim",
        "Bryan Wong",
        "MunYong Yi"
      ],
      "abstract": "Existing automated essay scoring (AES) has solely relied on essay text\nwithout using explanatory rationales for the scores, thereby forgoing an\nopportunity to capture the specific aspects evaluated by rubric indicators in a\nfine-grained manner. This paper introduces Rationale-based Multiple Trait\nScoring (RMTS), a novel approach for multi-trait essay scoring that integrates\nprompt-engineering-based large language models (LLMs) with a fine-tuning-based\nessay scoring model using a smaller large language model (S-LLM). RMTS uses an\nLLM-based trait-wise rationale generation system where a separate LLM agent\ngenerates trait-specific rationales based on rubric guidelines, which the\nscoring model uses to accurately predict multi-trait scores. Extensive\nexperiments on benchmark datasets, including ASAP, ASAP++, and Feedback Prize,\nshow that RMTS significantly outperforms state-of-the-art models and vanilla\nS-LLMs in trait-specific scoring. By assisting quantitative assessment with\nfine-grained qualitative rationales, RMTS enhances the trait-wise reliability,\nproviding partial explanations about essays. The code is available at\nhttps://github.com/BBeeChu/RMTS.git.",
      "tldr_zh": "本文提出了一种基于理由的多特征作文评分(RMTS)方法，以解决现有自动作文评分(AES)系统忽略解释性理由的问题。RMTS 整合提示工程的LLMs来生成基于评分标准的特征特定理由，并与微调后的较小语言模型(S-LLM)结合，实现更精确的多特征分数预测。在 ASAP、ASAP++ 和 Feedback Prize 等基准数据集上的实验表明，RMTS 在特征特定评分上显著优于现有模型和普通 S-LLM，提升了评分的可靠性和可解释性。该方法通过提供细粒度的定性理由，辅助定量评估，为作文分析提供部分解释。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14202v3",
      "published_date": "2024-10-18 06:35:17 UTC",
      "updated_date": "2025-02-05 07:52:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:34:23.696744"
    },
    {
      "arxiv_id": "2410.14198v1",
      "title": "Supervised Chain of Thought",
      "title_zh": "监督式链式思考",
      "authors": [
        "Xiang Zhang",
        "Dujian Ding"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\nand hold immense potential for advancing Artificial Intelligence. However, the\ncore architecture of most mainstream LLMs -- the Transformer -- has inherent\nlimitations in computational depth, rendering them theoretically incapable of\nsolving many reasoning tasks that demand increasingly deep computations. Chain\nof Thought (CoT) prompting has emerged as a technique to address these\narchitectural limitations, as evidenced by several theoretical studies. It\noffers a promising approach to solving complex reasoning tasks that were\npreviously beyond the capabilities of these models. Despite its successes, CoT\nand its variants (such as Tree of Thought, Graph of Thought, etc.) rely on a\n\"one-prompt-for-all\" approach, using a single prompt structure (e.g., \"think\nstep by step\") for a wide range of tasks -- from counting and sorting to\nsolving mathematical and algorithmic problems. This approach poses significant\nchallenges for models to generate the correct reasoning steps, as the model\nmust navigate through a vast prompt template space to find the appropriate\ntemplate for each task. In this work, we build upon previous theoretical\nanalyses of CoT to demonstrate how the one-prompt-for-all approach can\nnegatively affect the computability of LLMs. We partition the solution search\nspace into two: the prompt space and the answer space. Our findings show that\ntask-specific supervision is essential for navigating the prompt space\naccurately and achieving optimal performance. Through experiments with\nstate-of-the-art LLMs, we reveal a gap in reasoning performance when\nsupervision is applied versus when it is not.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs) 在处理复杂推理任务时的局限性，特别是Transformer架构的计算深度不足，以及Chain of Thought (CoT) 提示技术的“one-prompt-for-all”方法导致的挑战。作者将解决方案搜索空间分为prompt space和answer space，证明任务特定的监督机制是优化CoT性能的关键，通过实验分析显示这种方法能有效帮助模型导航提示空间。实验结果表明，使用监督的LLMs在推理任务上显著优于无监督情况，揭示了提升模型可计算性的新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14198v1",
      "published_date": "2024-10-18 06:25:27 UTC",
      "updated_date": "2024-10-18 06:25:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:34:33.601998"
    },
    {
      "arxiv_id": "2410.14194v1",
      "title": "Speciesism in Natural Language Processing Research",
      "title_zh": "自然语言处理研究中的物种歧视",
      "authors": [
        "Masashi Takeshita",
        "Rafal Rzepka"
      ],
      "abstract": "Natural Language Processing (NLP) research on AI Safety and social bias in AI\nhas focused on safety for humans and social bias against human minorities.\nHowever, some AI ethicists have argued that the moral significance of nonhuman\nanimals has been ignored in AI research. Therefore, the purpose of this study\nis to investigate whether there is speciesism, i.e., discrimination against\nnonhuman animals, in NLP research. First, we explain why nonhuman animals are\nrelevant in NLP research. Next, we survey the findings of existing research on\nspeciesism in NLP researchers, data, and models and further investigate this\nproblem in this study. The findings of this study suggest that speciesism\nexists within researchers, data, and models, respectively. Specifically, our\nsurvey and experiments show that (a) among NLP researchers, even those who\nstudy social bias in AI, do not recognize speciesism or speciesist bias; (b)\namong NLP data, speciesist bias is inherent in the data annotated in the\ndatasets used to evaluate NLP models; (c) OpenAI GPTs, recent NLP models,\nexhibit speciesist bias by default. Finally, we discuss how we can reduce\nspeciesism in NLP research.",
      "tldr_zh": "这篇论文探讨了Natural Language Processing (NLP) 研究中是否存在物种歧视（speciesism），即对非人类动物的歧视，强调了现有研究偏重人类安全和偏见而忽略动物道德意义。研究者通过调查NLP研究者、分析数据集和测试OpenAI GPTs等模型，揭示了物种歧视在研究者认知、数据标注和模型输出中均广泛存在。最终，论文提出策略来减少NLP研究中的这种偏见，以促进更公正的AI发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This article is a preprint and has not been peer-reviewed. The\n  postprint has been accepted for publication in AI and Ethics. Please cite the\n  final version of the article once it is published",
      "pdf_url": "http://arxiv.org/pdf/2410.14194v1",
      "published_date": "2024-10-18 06:09:41 UTC",
      "updated_date": "2024-10-18 06:09:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:34:46.272999"
    },
    {
      "arxiv_id": "2411.02404v1",
      "title": "Enhancing Retrieval Performance: An Ensemble Approach For Hard Negative Mining",
      "title_zh": "提升检索性能：一种用于硬负样本挖掘",
      "authors": [
        "Hansa Meghwani"
      ],
      "abstract": "Ranking consistently emerges as a primary focus in information retrieval\nresearch. Retrieval and ranking models serve as the foundation for numerous\napplications, including web search, open domain QA, enterprise domain QA, and\ntext-based recommender systems. Typically, these models undergo training on\ntriplets consisting of binary relevance assignments, comprising one positive\nand one negative passage. However, their utilization involves a context where a\nsignificantly more nuanced understanding of relevance is necessary, especially\nwhen re-ranking a large pool of potentially relevant passages. Although\ncollecting positive examples through user feedback like impressions or clicks\nis straightforward, identifying suitable negative pairs from a vast pool of\npossibly millions or even billions of documents possess a greater challenge.\nGenerating a substantial number of negative pairs is often necessary to\nmaintain the high quality of the model. Several approaches have been suggested\nin literature to tackle the issue of selecting suitable negative pairs from an\nextensive corpus. This study focuses on explaining the crucial role of hard\nnegatives in the training process of cross-encoder models, specifically aiming\nto explain the performance gains observed with hard negative sampling compared\nto random sampling. We have developed a robust hard negative mining technique\nfor efficient training of cross-encoder re-rank models on an enterprise dataset\nwhich has domain specific context. We provide a novel perspective to enhance\nretrieval models, ultimately influencing the performance of advanced LLM\nsystems like Retrieval-Augmented Generation (RAG) and Reasoning and Action\nAgents (ReAct). The proposed approach demonstrates that learning both\nsimilarity and dissimilarity simultaneously with cross-encoders improves\nperformance of retrieval systems.",
      "tldr_zh": "本研究探讨了在信息检索中通过硬负样本挖掘（hard negative mining）提升模型性能的问题，特别针对跨编码器（cross-encoder）再排名模型的训练。作者提出了一种集成方法（Ensemble Approach），从企业数据集的领域特定语境中高效挖掘硬负样本，同时学习相似性和差异性，以改善模型的检索准确性。实验结果表明，该方法相较于随机采样显著提高了性能，并为高级LLM系统如Retrieval-Augmented Generation (RAG)和Reasoning and Action Agents (ReAct)提供了新视角。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Master's thesis",
      "pdf_url": "http://arxiv.org/pdf/2411.02404v1",
      "published_date": "2024-10-18 05:23:39 UTC",
      "updated_date": "2024-10-18 05:23:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:34:58.798732"
    },
    {
      "arxiv_id": "2410.16033v3",
      "title": "TreeBoN: Enhancing Inference-Time Alignment with Speculative Tree-Search and Best-of-N Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Qiu",
        "Yifu Lu",
        "Yifan Zeng",
        "Jiacheng Guo",
        "Jiayi Geng",
        "Huazheng Wang",
        "Kaixuan Huang",
        "Yue Wu",
        "Mengdi Wang"
      ],
      "abstract": "Inference-time alignment enhances the performance of large language models\nwithout requiring additional training or fine-tuning but presents challenges\ndue to balancing computational efficiency with high-quality output. Best-of-N\n(BoN) sampling, as a simple yet powerful approach, generates multiple responses\nand selects the best one, achieving improved performance but with a high\ncomputational cost. We propose TreeBoN, a novel framework that integrates a\nspeculative tree-search strategy into Best-of-N (BoN) Sampling. TreeBoN\nmaintains a set of parent nodes, iteratively branching and pruning low-quality\nresponses, thereby reducing computational overhead while maintaining high\noutput quality. Our approach also leverages token-level rewards from Direct\nPreference Optimization (DPO) to guide tree expansion and prune low-quality\npaths. We evaluate TreeBoN using AlpacaFarm, HH-RLHF, UltraFeedback, GSM8K, and\nTutorEval datasets, demonstrating consistent improvements. Specifically,\nTreeBoN achieves the highest win rate of 65% on TutorEval and around 60% win\nrates across other different datasets, outperforming standard BoN with the same\ncomputational cost and showcasing its scalability and alignment efficacy.",
      "tldr_zh": "本研究提出 TreeBoN 框架，通过将 speculative tree-search 策略整合到 Best-of-N (BoN) Sampling 中，提升大语言模型的推理时对齐性能，同时减少计算开销。TreeBoN 通过维护一组父节点、迭代分支并修剪低质量响应，并利用 Direct Preference Optimization (DPO) 的 token-level rewards 指导树扩展和路径优化，从而平衡效率与输出质量。在 AlpacaFarm、HH-RLHF、UltraFeedback、GSM8K 和 TutorEval 数据集上评估，TreeBoN 实现了最高 65% 的胜率，并在相同计算成本下优于标准 BoN，展示了其可扩展性和对齐效能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16033v3",
      "published_date": "2024-10-18 04:38:21 UTC",
      "updated_date": "2024-10-30 00:02:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:35:11.231850"
    },
    {
      "arxiv_id": "2410.14170v2",
      "title": "Personalized Image Generation with Large Multimodal Models",
      "title_zh": "基于大型多模态模型的个性化图像生成",
      "authors": [
        "Yiyan Xu",
        "Wenjie Wang",
        "Yang Zhang",
        "Biao Tang",
        "Peng Yan",
        "Fuli Feng",
        "Xiangnan He"
      ],
      "abstract": "Personalized content filtering, such as recommender systems, has become a\ncritical infrastructure to alleviate information overload. However, these\nsystems merely filter existing content and are constrained by its limited\ndiversity, making it difficult to meet users' varied content needs. To address\nthis limitation, personalized content generation has emerged as a promising\ndirection with broad applications. Nevertheless, most existing research focuses\non personalized text generation, with relatively little attention given to\npersonalized image generation. The limited work in personalized image\ngeneration faces challenges in accurately capturing users' visual preferences\nand needs from noisy user-interacted images and complex multimodal\ninstructions. Worse still, there is a lack of supervised data for training\npersonalized image generation models.\n  To overcome the challenges, we propose a Personalized Image Generation\nFramework named Pigeon, which adopts exceptional large multimodal models with\nthree dedicated modules to capture users' visual preferences and needs from\nnoisy user history and multimodal instructions. To alleviate the data scarcity,\nwe introduce a two-stage preference alignment scheme, comprising masked\npreference reconstruction and pairwise preference alignment, to align Pigeon\nwith the personalized image generation task. We apply Pigeon to personalized\nsticker and movie poster generation, where extensive quantitative results and\nhuman evaluation highlight its superiority over various generative baselines.",
      "tldr_zh": "这篇论文针对个性化图像生成的挑战，提出了一种名为Pigeon的框架，利用Large Multimodal Models和三个专用模块，从嘈杂的用户互动图像和多模态指令中准确捕捉用户的视觉偏好。Pigeon通过双阶段偏好对齐方案，包括masked preference reconstruction和pairwise preference alignment，来缓解监督数据稀缺的问题，从而提升生成性能。该框架应用于个性化贴纸和电影海报生成，并在定量结果及人类评估中显著优于现有生成基线。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted for publication in WWW'25",
      "pdf_url": "http://arxiv.org/pdf/2410.14170v2",
      "published_date": "2024-10-18 04:20:46 UTC",
      "updated_date": "2025-02-02 06:35:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:35:22.460985"
    },
    {
      "arxiv_id": "2411.02403v2",
      "title": "A Persuasion-Based Prompt Learning Approach to Improve Smishing Detection through Data Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Ho Sung Shim",
        "Hyoungjun Park",
        "Kyuhan Lee",
        "Jang-Sun Park",
        "Seonhye Kang"
      ],
      "abstract": "Smishing, which aims to illicitly obtain personal information from\nunsuspecting victims, holds significance due to its negative impacts on our\nsociety. In prior studies, as a tool to counteract smishing, machine learning\n(ML) has been widely adopted, which filters and blocks smishing messages before\nthey reach potential victims. However, a number of challenges remain in\nML-based smishing detection, with the scarcity of annotated datasets being one\nmajor hurdle. Specifically, given the sensitive nature of smishing-related\ndata, there is a lack of publicly accessible data that can be used for training\nand evaluating ML models. Additionally, the nuanced similarities between\nsmishing messages and other types of social engineering attacks such as spam\nmessages exacerbate the challenge of smishing classification with limited\nresources. To tackle this challenge, we introduce a novel data augmentation\nmethod utilizing a few-shot prompt learning approach. What sets our approach\napart from extant methods is the use of the principles of persuasion, a\npsychology theory which explains the underlying mechanisms of smishing. By\ndesigning prompts grounded in the persuasion principles, our augmented dataset\ncould effectively capture various, important aspects of smishing messages,\nenabling ML models to be effectively trained. Our evaluation within a\nreal-world context demonstrates that our augmentation approach produces more\ndiverse and higher-quality smishing data instances compared to other\ncutting-edging approaches, leading to substantial improvements in the ability\nof ML models to detect the subtle characteristics of smishing messages.\nMoreover, our additional analyses reveal that the performance improvement\nprovided by our approach is more pronounced when used with ML models that have\na larger number of parameters, demonstrating its effectiveness in training\nlarge-scale ML models.",
      "tldr_zh": "本研究针对 smishing 检测面临的 annotated 数据稀缺问题，提出了一种基于说服原理(persuasion principles)的 prompt learning 方法，通过 few-shot 学习设计提示来实现数据增强(data augmentation)。这种方法能生成更多样化和高质量的 smishing 数据样本，帮助 machine learning (ML) 模型更好地捕捉攻击的细微特征。实验结果表明，与现有先进方法相比，该方法显著提升了 ML 模型的检测准确性，尤其在参数量较大的大型模型上表现突出。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02403v2",
      "published_date": "2024-10-18 04:20:02 UTC",
      "updated_date": "2024-11-06 02:32:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:35:33.754215"
    },
    {
      "arxiv_id": "2410.14166v2",
      "title": "LLM The Genius Paradox: A Linguistic and Math Expert's Struggle with Simple Word-based Counting Problems",
      "title_zh": "LLM 的天才悖论：一个语言和数学专家在简单基于单词的计数问题上的挣扎",
      "authors": [
        "Nan Xu",
        "Xuezhe Ma"
      ],
      "abstract": "Interestingly, LLMs yet struggle with some basic tasks that humans find\ntrivial to handle, e.g., counting the number of character r's in the word\n\"strawberry\". There are several popular conjectures (e.g., tokenization,\narchitecture and training data) regarding the reason for deficiency of LLMs in\nsimple word-based counting problems, sharing the similar belief that such\nfailure stems from model pretraining hence probably inevitable during\ndeployment. In this paper, we carefully design multiple evaluation settings to\ninvestigate validity of prevalent conjectures. Meanwhile, we measure\ntransferability of advanced mathematical and coding reasoning capabilities from\nspecialized LLMs to simple counting tasks. Although specialized LLMs suffer\nfrom counting problems as well, we find conjectures about inherent deficiency\nof LLMs invalid and further seek opportunities to elicit knowledge and\ncapabilities from LLMs that are beneficial to counting tasks. Compared with\nstrategies such as finetuning and in-context learning that are commonly adopted\nto enhance performance on new or challenging tasks, we show that engaging\nreasoning is the most robust and efficient way to help LLMs better perceive\ntasks with more accurate responses.\n  We hope our conjecture validation design could provide insights into the\nstudy of future critical failure modes of LLMs. Based on challenges in\ntransferring advanced capabilities to much simpler tasks, we call for more\nattention to model capability acquisition and evaluation. We also highlight the\nimportance of cultivating consciousness of \"reasoning before responding\" during\nmodel pretraining.",
      "tldr_zh": "该论文探讨了大型语言模型(LLMs)在简单词-based 计数任务（如统计单词中特定字母的个数）上的表现困境，尽管LLMs在语言和数学方面表现出色。研究者设计了多种评估设置来验证流行假设（如tokenization、架构和训练数据的影响），并测试从专业化LLMs中转移高级数学和编码推理能力的可行性。结果显示，这些假设无效，而参与推理策略比finetuning或in-context learning更稳健高效，能够显著提升LLMs的准确性。论文呼吁加强对LLMs能力获取和评估的关注，并在模型预训练中培养“reasoning before responding”的意识，以揭示未来关键失败模式。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.14166v2",
      "published_date": "2024-10-18 04:17:16 UTC",
      "updated_date": "2025-02-06 22:38:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:35:46.071201"
    },
    {
      "arxiv_id": "2410.14753v2",
      "title": "Collaboratively adding new knowledge to an LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Rhui Dih Lee",
        "Laura Wynter"
      ],
      "abstract": "We address the question of how to successively add new knowledge to an LLM\nwhilst retaining previously-added knowledge. We consider two settings,\nsemi-cooperative and fully-cooperative. Overall, LoRA performs better in most\ncases than full-fine tuning of all parameters when both new knowledge\nacquisition and retention of old, including recent, knowledge are taken into\naccount. In the semi-cooperative setting, where datasets are not available\nafter training, MOE mixing, model merging, and LoRA-based orthogonal subspace\nsequential learning, using a small weight on the orthogonality term, perform\nwell. In the fully-cooperative setting where datasets remain available, joint\ntraining and sequential training with replay are both effective approaches with\nLoRA training generally preferable to full fine-tuning. The codes needed to\nreproduce the results are provided in an open source repository.",
      "tldr_zh": "这篇论文探讨了如何向大型语言模型（LLM）逐步添加新知识，同时保留原有知识，考虑了半合作（semi-cooperative）和全合作（fully-cooperative）两种设置。研究发现，LoRA 方法在大多数情况下优于全参数微调（full-fine tuning），因为它在获取新知识和保留旧知识方面表现出色。在 semi-cooperative 设置中，MOE mixing、model merging 和 LoRA-based orthogonal subspace sequential learning 表现良好；在 fully-cooperative 设置中，joint training 和 sequential training with replay 均为有效策略。论文还提供了开源代码，以便重现实验结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14753v2",
      "published_date": "2024-10-18 04:04:51 UTC",
      "updated_date": "2024-10-29 07:03:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:35:59.071032"
    },
    {
      "arxiv_id": "2410.14154v1",
      "title": "RA-BLIP: Multimodal Adaptive Retrieval-Augmented Bootstrapping Language-Image Pre-training",
      "title_zh": "翻译失败",
      "authors": [
        "Muhe Ding",
        "Yang Ma",
        "Pengda Qin",
        "Jianlong Wu",
        "Yuhong Li",
        "Liqiang Nie"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have recently received substantial\ninterest, which shows their emerging potential as general-purpose models for\nvarious vision-language tasks. MLLMs involve significant external knowledge\nwithin their parameters; however, it is challenging to continually update these\nmodels with the latest knowledge, which involves huge computational costs and\npoor interpretability. Retrieval augmentation techniques have proven to be\neffective plugins for both LLMs and MLLMs. In this study, we propose multimodal\nadaptive Retrieval-Augmented Bootstrapping Language-Image Pre-training\n(RA-BLIP), a novel retrieval-augmented framework for various MLLMs. Considering\nthe redundant information within vision modality, we first leverage the\nquestion to instruct the extraction of visual information through interactions\nwith one set of learnable queries, minimizing irrelevant interference during\nretrieval and generation. Besides, we introduce a pre-trained multimodal\nadaptive fusion module to achieve question text-to-multimodal retrieval and\nintegration of multimodal knowledge by projecting visual and language\nmodalities into a unified semantic space. Furthermore, we present an Adaptive\nSelection Knowledge Generation (ASKG) strategy to train the generator to\nautonomously discern the relevance of retrieved knowledge, which realizes\nexcellent denoising performance. Extensive experiments on open multimodal\nquestion-answering datasets demonstrate that RA-BLIP achieves significant\nperformance and surpasses the state-of-the-art retrieval-augmented models.",
      "tldr_zh": "本文提出 RA-BLIP，一种多模态自适应检索增强框架，用于提升 Multimodal Large Language Models (MLLMs) 在视觉语言任务中的性能，通过检索增强技术解决模型更新计算成本高和可解释性差的问题。框架的关键创新包括：利用问题指导的可学习查询提取视觉信息、预训练的多模态自适应融合模块将视觉和语言模态投影到统一语义空间，以及 Adaptive Selection Knowledge Generation (ASKG) 策略让生成器自主筛选相关知识以实现去噪。在开放的多模态问答数据集上实验，RA-BLIP 显著超越了现有最先进模型，展示了优秀的性能提升。",
      "categories": [
        "cs.MM",
        "cs.AI"
      ],
      "primary_category": "cs.MM",
      "comment": "10 pages, 6 figures, Journal",
      "pdf_url": "http://arxiv.org/pdf/2410.14154v1",
      "published_date": "2024-10-18 03:45:19 UTC",
      "updated_date": "2024-10-18 03:45:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:36:10.296236"
    },
    {
      "arxiv_id": "2410.14150v1",
      "title": "Utilizing Large Language Models for Event Deconstruction to Enhance Multimodal Aspect-Based Sentiment Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyong Huang",
        "Heli Sun",
        "Qunshu Gao",
        "Wenjie Huang",
        "Ruichen Cao"
      ],
      "abstract": "With the rapid development of the internet, the richness of User-Generated\nContentcontinues to increase, making Multimodal Aspect-Based Sentiment Analysis\n(MABSA) a research hotspot. Existing studies have achieved certain results in\nMABSA, but they have not effectively addressed the analytical challenges in\nscenarios where multiple entities and sentiments coexist. This paper\ninnovatively introduces Large Language Models (LLMs) for event decomposition\nand proposes a reinforcement learning framework for Multimodal Aspect-based\nSentiment Analysis (MABSA-RL) framework. This framework decomposes the original\ntext into a set of events using LLMs, reducing the complexity of analysis,\nintroducing reinforcement learning to optimize model parameters. Experimental\nresults show that MABSA-RL outperforms existing advanced methods on two\nbenchmark datasets. This paper provides a new research perspective and method\nfor multimodal aspect-level sentiment analysis.",
      "tldr_zh": "本文提出了一种利用 Large Language Models (LLMs) 进行事件分解的方法，以提升 Multimodal Aspect-Based Sentiment Analysis (MABSA) 的性能，特别针对多个实体和情感共存的复杂场景。研究引入了 MABSA-RL 框架，该框架通过 LLMs 将原始文本分解成一组事件，减少分析复杂度，并结合 reinforcement learning 优化模型参数。实验结果显示，该框架在两个基准数据集上优于现有先进方法，为多模态方面级情感分析提供了新的研究视角和创新途径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14150v1",
      "published_date": "2024-10-18 03:40:45 UTC",
      "updated_date": "2024-10-18 03:40:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:36:22.461678"
    },
    {
      "arxiv_id": "2410.14147v1",
      "title": "Leveraging Large Language Models for Enhancing Public Transit Services",
      "title_zh": "利用大语言模型提升公共交通服务",
      "authors": [
        "Jiahao Wang",
        "Amer Shalaby"
      ],
      "abstract": "Public transit systems play a crucial role in providing efficient and\nsustainable transportation options in urban areas. However, these systems face\nvarious challenges in meeting commuters' needs. On the other hand, despite the\nrapid development of Large Language Models (LLMs) worldwide, their integration\ninto transit systems remains relatively unexplored.\n  The objective of this paper is to explore the utilization of LLMs in the\npublic transit system, with a specific focus on improving the customers'\nexperience and transit staff performance. We present a general framework for\ndeveloping LLM applications in transit systems, wherein the LLM serves as the\nintermediary for information communication between natural language content and\nthe resources within the database. In this context, the LLM serves a\nmultifaceted role, including understanding users' requirements, retrieving data\nfrom the dataset in response to user queries, and tailoring the information to\nalign with the users' specific needs. Three transit LLM applications are\npresented: Tweet Writer, Trip Advisor, and Policy Navigator. Tweet Writer\nautomates updates to the transit system alerts on social media, Trip Advisor\noffers customized transit trip suggestions, and Policy Navigator provides clear\nand personalized answers to policy queries. Leveraging LLMs in these\napplications enhances seamless communication with their capabilities of\nunderstanding and generating human-like languages. With the help of these three\nLLM transit applications, transit system media personnel can provide system\nupdates more efficiently, and customers can access travel information and\npolicy answers in a more user-friendly manner.",
      "tldr_zh": "这篇论文探讨了利用Large Language Models (LLMs)提升公共交通服务的潜力，旨在改善用户体验和员工绩效，以应对交通系统的挑战。作者提出一个通用框架，其中LLMs作为中介，负责理解用户需求、从数据库检索数据并提供个性化信息输出。论文展示了三个具体应用：Tweet Writer（自动化社交媒体更新）、Trip Advisor（定制出行建议）和Policy Navigator（个性化政策查询回答）。这些应用通过LLMs的语言理解和生成能力，提升了信息通信效率，让公共交通系统更高效地服务用户和员工。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "24 pages, 18 figures, submitting to Journal of ITS",
      "pdf_url": "http://arxiv.org/pdf/2410.14147v1",
      "published_date": "2024-10-18 03:33:47 UTC",
      "updated_date": "2024-10-18 03:33:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:36:35.676755"
    },
    {
      "arxiv_id": "2410.14146v1",
      "title": "CausalChat: Interactive Causal Model Development and Refinement Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yanming Zhang",
        "Akshith Kota",
        "Eric Papenhausen",
        "Klaus Mueller"
      ],
      "abstract": "Causal networks are widely used in many fields to model the complex\nrelationships between variables. A recent approach has sought to construct\ncausal networks by leveraging the wisdom of crowds through the collective\nparticipation of humans. While this can yield detailed causal networks that\nmodel the underlying phenomena quite well, it requires a large number of\nindividuals with domain understanding. We adopt a different approach:\nleveraging the causal knowledge that large language models, such as OpenAI's\nGPT-4, have learned by ingesting massive amounts of literature. Within a\ndedicated visual analytics interface, called CausalChat, users explore single\nvariables or variable pairs recursively to identify causal relations, latent\nvariables, confounders, and mediators, constructing detailed causal networks\nthrough conversation. Each probing interaction is translated into a tailored\nGPT-4 prompt and the response is conveyed through visual representations which\nare linked to the generated text for explanations. We demonstrate the\nfunctionality of CausalChat across diverse data contexts and conduct user\nstudies involving both domain experts and laypersons.",
      "tldr_zh": "该论文提出CausalChat，一种交互式视觉分析界面，利用Large Language Models（如GPT-4）的因果知识，帮助用户通过对话式探索构建和完善因果网络。用户可递归查询单个变量或变量对，以识别因果关系、latent variables、confounders和mediators，并将交互转化为定制的GPT-4提示，结合视觉表示和文本解释呈现结果。与传统依赖众包的方法不同，该系统减少了对领域专家的需求，并在不同数据上下文中表现出色。用户研究表明，CausalChat对领域专家和普通用户均友好，提升了因果模型开发的效率和准确性。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14146v1",
      "published_date": "2024-10-18 03:33:32 UTC",
      "updated_date": "2024-10-18 03:33:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:36:46.027922"
    },
    {
      "arxiv_id": "2410.14144v1",
      "title": "A Lightweight Multi Aspect Controlled Text Generation Solution For Large Language Models",
      "title_zh": "轻量级多方面控制文本生成解决方案，用于大型语言模型",
      "authors": [
        "Chenyang Zhang",
        "Jiayi Lin",
        "Haibo Tong",
        "Bingxuan Hou",
        "Dongyu Zhang",
        "Jialin Li",
        "Junli Wang"
      ],
      "abstract": "Large language models (LLMs) show remarkable abilities with instruction\ntuning. However, they fail to achieve ideal tasks when lacking high-quality\ninstruction tuning data on target tasks. Multi-Aspect Controllable Text\nGeneration (MCTG) is a representative task for this dilemma, where aspect\ndatasets are usually biased and correlated. Existing work exploits additional\nmodel structures and strategies for solutions, limiting adaptability to LLMs.\nTo activate MCTG ability of LLMs, we propose a lightweight MCTG pipeline based\non data augmentation. We analyze bias and correlations in traditional datasets,\nand address these concerns with augmented control attributes and sentences.\nAugmented datasets are feasible for instruction tuning. In our experiments,\nLLMs perform better in MCTG after data augmentation, with a 20% accuracy rise\nand less aspect correlations.",
      "tldr_zh": "大语言模型 (LLMs) 在多方面可控文本生成 (MCTG) 任务上表现不佳，主要由于数据集的偏差和相关性问题。论文提出一个轻量级的 MCTG 管道，通过数据增强技术分析并解决这些问题，包括增强控制属性和句子，以生成更高质量的指令微调数据集。实验结果显示，采用增强数据集后，LLMs 的准确率提升了 20%，并显著减少了方面相关性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14144v1",
      "published_date": "2024-10-18 03:32:00 UTC",
      "updated_date": "2024-10-18 03:32:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:36:57.987972"
    },
    {
      "arxiv_id": "2410.14138v2",
      "title": "ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom",
      "title_zh": "翻译失败",
      "authors": [
        "Jingqi Zhou",
        "Sheng Wang",
        "Jingwei Dong",
        "Lei Li",
        "Jiahui Gao",
        "Jiyue Jiang",
        "Lingpeng Kong",
        "Chuan Wu"
      ],
      "abstract": "Large vision-language models (LVLMs) have witnessed significant progress on\nvisual understanding tasks. However, they often prioritize language knowledge\nover image information on visual reasoning tasks, incurring performance\ndegradation. To tackle this issue, we first identify the drawbacks of existing\nsolutions (i.e., insufficient and irrelevant visual descriptions, and limited\nmulti-modal capacities). We then decompose visual reasoning process into two\nstages: visual perception (i.e., eyesight) and textual reasoning (i.e.,\nwisdom), and introduce a novel visual reasoning framework named ProReason. This\nframework features multi-run proactive perception and decoupled\nvision-reasoning capabilities. Briefly, given a multi-modal question, ProReason\niterates proactive information collection and reasoning until the answer can be\nconcluded with necessary and sufficient visual descriptions. Notably, the\ndisassociation of capabilities allows seamless integration of existing large\nlanguage models (LLMs) to compensate for the reasoning deficits of LVLMs. Our\nextensive experiments demonstrate that ProReason outperforms both existing\nmulti-step reasoning frameworks and passive peer methods on a wide range of\nbenchmarks for both open-source and closed-source models. In addition, with the\nassistance of LLMs, ProReason achieves a performance improvement of up to 15%\non MMMU benchmark. Our insights into existing solutions and the decoupled\nperspective for feasible integration of LLMs illuminate future research on\nvisual reasoning techniques, especially LLM-assisted ones.",
      "tldr_zh": "该研究识别出大型视觉语言模型 (LVLMs) 在视觉推理任务中过度依赖语言知识而忽略图像信息的问题，并提出ProReason框架来解决这一问题。ProReason将视觉推理分解为视觉感知(eyesight)和文本推理(wisdom)两个阶段，通过多轮主动信息收集和解耦能力进行迭代推理，确保获取必要且充分的视觉描述，同时允许无缝整合现有大型语言模型(LLMs)来弥补推理不足。实验结果显示，ProReason在多个基准上优于现有多步推理框架和被动方法，并在MMMU benchmark上通过LLMs辅助实现高达15%的性能提升，为未来LLM辅助的视觉推理技术提供了新视角。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14138v2",
      "published_date": "2024-10-18 03:22:06 UTC",
      "updated_date": "2025-03-27 08:07:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:37:10.139985"
    },
    {
      "arxiv_id": "2410.14135v1",
      "title": "Inverse Reinforcement Learning from Non-Stationary Learning Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Kavinayan P. Sivakumar",
        "Yi Shen",
        "Zachary Bell",
        "Scott Nivison",
        "Boyuan Chen",
        "Michael M. Zavlanos"
      ],
      "abstract": "In this paper, we study an inverse reinforcement learning problem that\ninvolves learning the reward function of a learning agent using trajectory data\ncollected while this agent is learning its optimal policy. To address this\nproblem, we propose an inverse reinforcement learning method that allows us to\nestimate the policy parameters of the learning agent which can then be used to\nestimate its reward function. Our method relies on a new variant of the\nbehavior cloning algorithm, which we call bundle behavior cloning, and uses a\nsmall number of trajectories generated by the learning agent's policy at\ndifferent points in time to learn a set of policies that match the distribution\nof actions observed in the sampled trajectories. We then use the cloned\npolicies to train a neural network model that estimates the reward function of\nthe learning agent. We provide a theoretical analysis to show a complexity\nresult on bound guarantees for our method that beats standard behavior cloning\nas well as numerical experiments for a reinforcement learning problem that\nvalidate the proposed method.",
      "tldr_zh": "本论文研究了从非平稳学习代理的轨迹数据中进行逆强化学习（Inverse Reinforcement Learning, IRL），以估计其奖励函数。作者提出了一种新方法，使用捆绑行为克隆（bundle behavior cloning）算法，通过少量轨迹数据学习一组匹配动作分布的政策，然后训练神经网络模型来估计奖励函数。该方法提供了理论分析，证明其复杂度边界优于标准行为克隆，并在数值实验中验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14135v1",
      "published_date": "2024-10-18 03:02:44 UTC",
      "updated_date": "2024-10-18 03:02:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:37:21.637105"
    },
    {
      "arxiv_id": "2410.14131v2",
      "title": "Deep Learning Applications in Medical Image Analysis: Advancements, Challenges, and Future Directions",
      "title_zh": "深度学习在医疗图像分析中的应用：进展、挑战与未来方向",
      "authors": [
        "Aimina Ali Eli",
        "Abida Ali"
      ],
      "abstract": "Medical image analysis has emerged as an essential element of contemporary\nhealthcare, facilitating physicians in achieving expedited and precise\ndiagnosis. Recent breakthroughs in deep learning, a subset of artificial\nintelligence, have markedly revolutionized the analysis of medical pictures,\nimproving the accuracy and efficiency of clinical procedures. Deep learning\nalgorithms, especially convolutional neural networks (CNNs), have demonstrated\nremarkable proficiency in autonomously learning features from multidimensional\nmedical pictures, including MRI, CT, and X-ray scans, without the necessity for\nmanual feature extraction. These models have been utilized across multiple\nmedical disciplines, including pathology, radiology, ophthalmology, and\ncardiology, where they aid in illness detection, classification, and\nsegmentation tasks......",
      "tldr_zh": "本研究综述了Deep Learning在医疗图像分析中的应用进展，强调其如何提升诊断的准确性和效率，特别是通过Convolutional Neural Networks (CNNs)自动从MRI、CT和X-ray等多维图像中学习特征，而无需手动提取。Deep Learning模型已在病理学、放射学、眼科和心脏病学等领域广泛用于疾病检测、分类和分割任务，显著改善了临床流程。该文还讨论了面临的挑战，如数据隐私和模型泛化问题，并展望未来方向，包括更先进的算法和集成AI系统的发展。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14131v2",
      "published_date": "2024-10-18 02:57:14 UTC",
      "updated_date": "2024-11-04 21:47:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:39:26.810144"
    },
    {
      "arxiv_id": "2411.00788v1",
      "title": "KeyInst: Keyword Instruction for Improving SQL Formulation in Text-to-SQL",
      "title_zh": "翻译失败",
      "authors": [
        "Xiping Liu",
        "Zhao Tan"
      ],
      "abstract": "Text-to-SQL parsing involves the translation of natural language queries\n(NLQs) into their corresponding SQL commands. A principal challenge within this\ndomain is the formulation of SQL queries that are not only syntactically\ncorrect but also semantically aligned with the natural language input. However,\nthe intrinsic disparity between the NLQ and the SQL poses a significant\nchallenge. In this research, we introduce Keyword Instruction (KeyInst), a\nnovel method designed to enhance SQL formulation by Large Language Models\n(LLMs). KeyInst essentially provides guidance on pivotal SQL keywords likely to\nbe part of the final query, thus facilitates a smoother SQL query formulation\nprocess. We explore two strategies for integrating KeyInst into Text-to-SQL\nparsing: a pipeline strategy and a single-pass strategy. The former first\ngenerates KeyInst for question, which are then used to prompt LLMs. The latter\nemploys a fine-tuned model to concurrently generate KeyInst and SQL in one\nstep. We developed StrucQL, a benchmark specifically designed for the\nevaluation of SQL formulation. Extensive experiments on StrucQL and other\nbenchmarks demonstrate that KeyInst significantly improves upon the existing\nText-to-SQL prompting techniques.",
      "tldr_zh": "这篇论文针对 Text-to-SQL 任务中 SQL 查询的语义对齐挑战，提出了一种新方法 Keyword Instruction (KeyInst)，通过提供关键 SQL 关键词来指导 Large Language Models (LLMs) 生成更准确的查询。研究探索了两种整合策略：管道策略（先生成 KeyInst 再用于提示 LLMs）和单步策略（使用微调模型同时生成 KeyInst 和 SQL）。论文开发了 StrucQL 基准，并在 StrucQL 及其他基准上的实验中证明，KeyInst 显著提升了现有 Text-to-SQL 提示技术的性能。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00788v1",
      "published_date": "2024-10-18 02:45:36 UTC",
      "updated_date": "2024-10-18 02:45:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:39:46.886858"
    },
    {
      "arxiv_id": "2410.14752v1",
      "title": "TimeSeriesExam: A time series understanding exam",
      "title_zh": "TimeSeriesExam：时间序列理解考试",
      "authors": [
        "Yifu Cai",
        "Arjun Choudhry",
        "Mononito Goswami",
        "Artur Dubrawski"
      ],
      "abstract": "Large Language Models (LLMs) have recently demonstrated a remarkable ability\nto model time series data. These capabilities can be partly explained if LLMs\nunderstand basic time series concepts. However, our knowledge of what these\nmodels understand about time series data remains relatively limited. To address\nthis gap, we introduce TimeSeriesExam, a configurable and scalable\nmultiple-choice question exam designed to assess LLMs across five core time\nseries understanding categories: pattern recognition, noise understanding,\nsimilarity analysis, anomaly detection, and causality analysis. TimeSeriesExam\ncomprises of over 700 questions, procedurally generated using 104 carefully\ncurated templates and iteratively refined to balance difficulty and their\nability to discriminate good from bad models. We test 7 state-of-the-art LLMs\non the TimeSeriesExam and provide the first comprehensive evaluation of their\ntime series understanding abilities. Our results suggest that closed-source\nmodels such as GPT-4 and Gemini understand simple time series concepts\nsignificantly better than their open-source counterparts, while all models\nstruggle with complex concepts such as causality analysis. We believe that the\nability to programatically generate questions is fundamental to assessing and\nimproving LLM's ability to understand and reason about time series data.",
      "tldr_zh": "本论文引入了TimeSeriesExam，这是一个可配置、可扩展的多选题考试，用于评估大型语言模型(LLMs)对时间序列数据的理解能力，涵盖模式识别、噪声理解、相似性分析、异常检测和因果分析等五类核心概念。考试包含超过700个问题，由104个精心策划的模板程序生成，并通过迭代优化以平衡难度和模型区分能力。在测试7个最先进LLMs的结果中，封闭源模型如GPT-4和Gemini在简单时间序列概念上表现出色，而所有模型在复杂概念如因果分析上表现较差；作者强调，程序生成问题的能力是提升LLMs时间序列理解和推理的关键。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at NeurIPS'24 Time Series in the Age of Large Models\n  Workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.14752v1",
      "published_date": "2024-10-18 02:37:14 UTC",
      "updated_date": "2024-10-18 02:37:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:37:59.044869"
    },
    {
      "arxiv_id": "2410.14122v1",
      "title": "Towards Robust Transcription: Exploring Noise Injection Strategies for Training Data Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yonghyun Kim",
        "Alexander Lerch"
      ],
      "abstract": "Recent advancements in Automatic Piano Transcription (APT) have significantly\nimproved system performance, but the impact of noisy environments on the system\nperformance remains largely unexplored. This study investigates the impact of\nwhite noise at various Signal-to-Noise Ratio (SNR) levels on state-of-the-art\nAPT models and evaluates the performance of the Onsets and Frames model when\ntrained on noise-augmented data. We hope this research provides valuable\ninsights as preliminary work toward developing transcription models that\nmaintain consistent performance across a range of acoustic conditions.",
      "tldr_zh": "本研究探讨了噪音环境对 Automatic Piano Transcription (APT) 模型性能的影响，特别关注白噪声在不同 Signal-to-Noise Ratio (SNR) 水平下的作用。研究者通过注入白噪声作为训练数据增强策略，评估了 Onsets and Frames 模型的鲁棒性表现。结果表明，这种方法为开发在各种声学条件下保持一致性能的转录模型提供了初步宝贵见解。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to the Late-Breaking Demo Session of the 25th International\n  Society for Music Information Retrieval (ISMIR) Conference, 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.14122v1",
      "published_date": "2024-10-18 02:31:36 UTC",
      "updated_date": "2024-10-18 02:31:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:38:09.775053"
    },
    {
      "arxiv_id": "2410.14121v2",
      "title": "FedMSE: Semi-supervised federated learning approach for IoT network intrusion detection",
      "title_zh": "FedMSE：半监督联邦学习方法用于 IoT 网络入侵检测",
      "authors": [
        "Van Tuan Nguyen",
        "Razvan Beuran"
      ],
      "abstract": "This paper proposes a novel federated learning approach for improving IoT\nnetwork intrusion detection. The rise of IoT has expanded the cyber attack\nsurface, making traditional centralized machine learning methods insufficient\ndue to concerns about data availability, computational resources, transfer\ncosts, and especially privacy preservation. A semi-supervised federated\nlearning model was developed to overcome these issues, combining the Shrink\nAutoencoder and Centroid one-class classifier (SAE-CEN). This approach enhances\nthe performance of intrusion detection by effectively representing normal\nnetwork data and accurately identifying anomalies in the decentralized\nstrategy. Additionally, a mean square error-based aggregation algorithm\n(MSEAvg) was introduced to improve global model performance by prioritizing\nmore accurate local models. The results obtained in our experimental setup,\nwhich uses various settings relying on the N-BaIoT dataset and Dirichlet\ndistribution, demonstrate significant improvements in real-world heterogeneous\nIoT networks in detection accuracy from 93.98$\\pm$2.90 to 97.30$\\pm$0.49,\nreduced learning costs when requiring only 50\\% of gateways participating in\nthe training process, and robustness in large-scale networks.",
      "tldr_zh": "这篇论文提出了一种名为 FedMSE 的半监督联邦学习方法，用于提升 IoT 网络入侵检测的性能，解决传统集中式方法的隐私和资源问题。该方法结合 Shrink Autoencoder 和 Centroid one-class classifier (SAE-CEN) 来有效表示正常网络数据并识别异常，同时引入基于均方误差的聚合算法 (MSEAvg) 来优先选择更准确的本地模型优化全局性能。在实验中使用 N-BaIoT 数据集和 Dirichlet 分布，检测准确率从 93.98±2.90 提高到 97.30±0.49，减少了学习成本（只需 50% 网关参与训练），并展示了在异构 IoT 网络中的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14121v2",
      "published_date": "2024-10-18 02:23:57 UTC",
      "updated_date": "2025-04-03 15:16:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:39:25.493662"
    },
    {
      "arxiv_id": "2410.14118v1",
      "title": "Skill Generalization with Verbs",
      "title_zh": "基于动词的技能泛化",
      "authors": [
        "Rachel Ma",
        "Lyndon Lam",
        "Benjamin A. Spiegel",
        "Aditya Ganeshan",
        "Roma Patel",
        "Ben Abbatematteo",
        "David Paulius",
        "Stefanie Tellex",
        "George Konidaris"
      ],
      "abstract": "It is imperative that robots can understand natural language commands issued\nby humans. Such commands typically contain verbs that signify what action\nshould be performed on a given object and that are applicable to many objects.\nWe propose a method for generalizing manipulation skills to novel objects using\nverbs. Our method learns a probabilistic classifier that determines whether a\ngiven object trajectory can be described by a specific verb. We show that this\nclassifier accurately generalizes to novel object categories with an average\naccuracy of 76.69% across 13 object categories and 14 verbs. We then perform\npolicy search over the object kinematics to find an object trajectory that\nmaximizes classifier prediction for a given verb. Our method allows a robot to\ngenerate a trajectory for a novel object based on a verb, which can then be\nused as input to a motion planner. We show that our model can generate\ntrajectories that are usable for executing five verb commands applied to novel\ninstances of two different object categories on a real robot.",
      "tldr_zh": "本文提出了一种使用动词（verbs）泛化机器人操作技能的方法，通过训练一个概率分类器（probabilistic classifier）来判断给定对象轨迹是否符合特定动词描述，并在13个对象类别和14个动词上实现平均76.69%的泛化准确率。接着，该方法通过在对象运动学上进行策略搜索（policy search），生成优化后的轨迹，以支持机器人对新对象的操作。实验结果显示，该模型能成功执行五个动词命令，应用于真实机器人上的两个不同对象类别的新实例。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages + 2 pages (references), 6 figures. Accepted at IROS 2023.\n  Code, dataset info and demo videos can be found at:\n  https://rachelma80000.github.io/SkillGenVerbs/",
      "pdf_url": "http://arxiv.org/pdf/2410.14118v1",
      "published_date": "2024-10-18 02:12:18 UTC",
      "updated_date": "2024-10-18 02:12:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:38:33.601064"
    },
    {
      "arxiv_id": "2410.14115v1",
      "title": "A Communication and Computation Efficient Fully First-order Method for Decentralized Bilevel Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Min Wen",
        "Chengchang Liu",
        "Ahmed Abdelmoniem",
        "Yipeng Zhou",
        "Yuedong Xu"
      ],
      "abstract": "Bilevel optimization, crucial for hyperparameter tuning, meta-learning and\nreinforcement learning, remains less explored in the decentralized learning\nparadigm, such as decentralized federated learning (DFL). Typically,\ndecentralized bilevel methods rely on both gradients and Hessian matrices to\napproximate hypergradients of upper-level models. However, acquiring and\nsharing the second-order oracle is compute and communication intensive. % and\nsharing this information incurs heavy communication overhead. To overcome these\nchallenges, this paper introduces a fully first-order decentralized method for\ndecentralized Bilevel optimization, $\\text{C}^2$DFB which is both compute- and\ncommunicate-efficient. In $\\text{C}^2$DFB, each learning node optimizes a\nmin-min-max problem to approximate hypergradient by exclusively using gradients\ninformation. To reduce the traffic load at the inner-loop of solving the\nlower-level problem, $\\text{C}^2$DFB incorporates a lightweight communication\nprotocol for efficiently transmitting compressed residuals of local parameters.\n% during the inner loops. Rigorous theoretical analysis ensures its convergence\n% of the algorithm, indicating a first-order oracle calls of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-4})$. Experiments on hyperparameter tuning and\nhyper-representation tasks validate the superiority of $\\text{C}^2$DFB across\nvarious typologies and heterogeneous data distributions.",
      "tldr_zh": "该论文针对双层优化（bilevel optimization）在去中心化学习（如去中心化联邦学习（DFL））中的应用，提出了一种高效的全一阶方法$\\text{C}^2$DFB，以解决传统方法依赖Hessian矩阵导致的计算和通信密集问题。该方法通过优化一个min-min-max问题，仅使用梯度信息来近似超梯度（hypergradient），并引入轻量级通信协议传输压缩的局部参数残差，从而显著降低通信负载。理论分析证明，$\\text{C}^2$DFB的收敛性仅需$\\tilde{\\mathcal{O}}(\\epsilon^{-4})$的一阶预言机调用。实验在超参数调整和超表示任务上验证了其在各种拓扑和异构数据分布下的优越性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "19 Pages",
      "pdf_url": "http://arxiv.org/pdf/2410.14115v1",
      "published_date": "2024-10-18 02:00:45 UTC",
      "updated_date": "2024-10-18 02:00:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:38:46.144640"
    },
    {
      "arxiv_id": "2410.19817v2",
      "title": "Step Guided Reasoning: Improving Mathematical Reasoning using Guidance Generation and Step Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Lang Cao",
        "Chao Peng",
        "Renhong Chen",
        "Wu Ning",
        "Yingtian Zou",
        "Yitong Li"
      ],
      "abstract": "Mathematical reasoning has been challenging for large language models (LLMs).\nHowever, the introduction of step-by-step Chain-of-Thought (CoT) inference has\nsignificantly advanced the mathematical capabilities of LLMs. Despite this\nprogress, current approaches either necessitate extensive inference datasets\nfor training or depend on few-shot methods that frequently compromise\ncomputational accuracy. To address these bottlenecks in mathematical reasoning,\nwe propose a novel method called Step Guidied Reasoning, which is more stable\nand generalizable than few-shot methods and does not involve further\nfine-tuning of the model. In this approach, LLMs reflect on small reasoning\nsteps, similar to how humans deliberate and focus attention on what to do next.\nBy incorporating this reflective process into the inference stage, LLMs can\neffectively guide their reasoning from one step to the next. Through extensive\nexperiments, we demonstrate the significant effect of Step Guidied Reasoning in\naugmenting mathematical performance in state-of-the-art language models.\nQwen2-72B-Instruct outperforms its math-specific counterpart,\nQwen2.5-72B-Math-Instruct, on MMLU- STEM with a score of 90.9%, compared to\n87.3%. The average scores of Qwen2-7B-Instruct and Qwen2-72B-Instruct increase\nfrom 27.1% to 36.3% and from 36.5% to 47.4% on the mathematics domain,\nrespectively.",
      "tldr_zh": "本论文提出了一种名为 Step Guided Reasoning 的新方法，用于提升大型语言模型（LLMs）在数学推理中的性能，该方法通过生成指导和步进推理，让 LLMs 像人类一样反思小步骤，从而更稳定地指导从一个步骤到下一个步骤，而无需额外微调模型。相比传统方法，该方法避免了依赖大量推理数据集或 few-shot 技术的局限性，具有更好的泛化性。实验结果显示，Qwen2-72B-Instruct 在 MMLU-STEM 测试中得分达到 90.9%，优于 Qwen2.5-72B-Math-Instruct 的 87.3%，且 Qwen2-7B-Instruct 和 Qwen2-72B-Instruct 在数学领域的平均分数分别从 27.1% 和 36.5% 提升至 36.3% 和 47.4%。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19817v2",
      "published_date": "2024-10-18 01:38:24 UTC",
      "updated_date": "2025-02-17 06:39:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:38:59.868271"
    },
    {
      "arxiv_id": "2410.14103v3",
      "title": "Extreme Precipitation Nowcasting using Multi-Task Latent Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Li Chaorong",
        "Ling Xudong",
        "Yang Qiang",
        "Qin Fengqing",
        "Huang Yuanyuan"
      ],
      "abstract": "Deep learning models have achieved remarkable progress in precipitation\nprediction. However, they still face significant challenges in accurately\ncapturing spatial details of radar images, particularly in regions of high\nprecipitation intensity. This limitation results in reduced spatial\nlocalization accuracy when predicting radar echo images across varying\nprecipitation intensities. To address this challenge, we propose an innovative\nprecipitation prediction approach termed the Multi-Task Latent Diffusion Model\n(MTLDM). The core idea of MTLDM lies in the recognition that precipitation\nradar images represent a combination of multiple components, each corresponding\nto different precipitation intensities. Thus, we adopt a divide-and-conquer\nstrategy, decomposing radar images into several sub-images based on their\nprecipitation intensities and individually modeling these components. During\nthe prediction stage, MTLDM integrates these sub-image representations by\nutilizing a trained latent-space rainfall diffusion model, followed by decoding\nthrough a multi-task decoder to produce the final precipitation prediction.\nExperimental evaluations conducted on the MRMS dataset demonstrate that the\nproposed MTLDM method surpasses state-of-the-art techniques, achieving a\nCritical Success Index (CSI) improvement of 13-26%.",
      "tldr_zh": "该研究针对深度学习模型在降水预测中捕捉雷达图像空间细节的挑战，特别是高强度降水区域的准确性不足，提出了一种创新方法Multi-Task Latent Diffusion Model (MTLDM)。MTLDM 通过将降水雷达图像分解为多个基于不同降水强度的子图像，并分别建模，然后利用训练过的潜在空间降水扩散模型整合这些子图像表示，并通过多任务解码器生成最终预测。实验结果显示，在MRMS数据集上，MTLDM 比现有技术提高了Critical Success Index (CSI) 13-26%，显著提升了极端降水预报的精确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "86A10, 68T07",
        "I.2.6; J.7"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 14figures",
      "pdf_url": "http://arxiv.org/pdf/2410.14103v3",
      "published_date": "2024-10-18 00:50:56 UTC",
      "updated_date": "2025-03-25 08:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:39:10.500136"
    },
    {
      "arxiv_id": "2410.14101v2",
      "title": "Multi-Source Spatial Knowledge Understanding for Immersive Visual Text-to-Speech",
      "title_zh": "多源空间知识理解用于沉浸式视觉文本到语音",
      "authors": [
        "Shuwei He",
        "Rui Liu"
      ],
      "abstract": "Visual Text-to-Speech (VTTS) aims to take the environmental image as the\nprompt to synthesize reverberant speech for the spoken content. Previous works\nfocus on the RGB modality for global environmental modeling, overlooking the\npotential of multi-source spatial knowledge like depth, speaker position, and\nenvironmental semantics. To address these issues, we propose a novel\nmulti-source spatial knowledge understanding scheme for immersive VTTS, termed\nMS2KU-VTTS. Specifically, we first prioritize RGB image as the dominant source\nand consider depth image, speaker position knowledge from object detection, and\nGemini-generated semantic captions as supplementary sources. Afterwards, we\npropose a serial interaction mechanism to effectively integrate both dominant\nand supplementary sources. The resulting multi-source knowledge is dynamically\nintegrated based on the respective contributions of each source.This enriched\ninteraction and integration of multi-source spatial knowledge guides the speech\ngeneration model, enhancing the immersive speech experience. Experimental\nresults demonstrate that the MS$^2$KU-VTTS surpasses existing baselines in\ngenerating immersive speech. Demos and code are available at:\nhttps://github.com/AI-S2-Lab/MS2KU-VTTS.",
      "tldr_zh": "本论文针对视觉文本到语音 (VTTS) 系统提出了一种多源空间知识理解方案，名为 MS2KU-VTTS，以 RGB 图像作为主要来源，并补充 depth image、通过 object detection 获得的说话者位置知识以及 Gemini-generated semantic captions，从而提升沉浸式语音合成效果。论文设计了串行交互机制来整合这些多源知识，并根据各来源的贡献动态融合，以指导语音生成模型更精确地处理环境语义和空间信息。实验结果显示，MS2KU-VTTS 在生成沉浸式语音方面超过了现有基线模型，提供更真实的语音体验，并附有演示和代码。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 1 figure, Accepted by ICASSP'2025",
      "pdf_url": "http://arxiv.org/pdf/2410.14101v2",
      "published_date": "2024-10-18 00:46:18 UTC",
      "updated_date": "2024-12-23 08:57:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:39:22.063712"
    },
    {
      "arxiv_id": "2410.14099v1",
      "title": "ST-MoE-BERT: A Spatial-Temporal Mixture-of-Experts Framework for Long-Term Cross-City Mobility Prediction",
      "title_zh": "ST-MoE-BERT：一种空间-时间混合专家框架，用于长期跨城市移动性预测",
      "authors": [
        "Haoyu He",
        "Haozheng Luo",
        "Qi R. Wang"
      ],
      "abstract": "Predicting human mobility across multiple cities presents significant\nchallenges due to the complex and diverse spatial-temporal dynamics inherent in\ndifferent urban environments. In this study, we propose a robust approach to\npredict human mobility patterns called ST-MoE-BERT. Compared to existing\nmethods, our approach frames the prediction task as a spatial-temporal\nclassification problem. Our methodology integrates the Mixture-of-Experts\narchitecture with BERT model to capture complex mobility dynamics and perform\nthe downstream human mobility prediction task. Additionally, transfer learning\nis integrated to solve the challenge of data scarcity in cross-city prediction.\nWe demonstrate the effectiveness of the proposed model on GEO-BLEU and DTW,\ncomparing it to several state-of-the-art methods. Notably, ST-MoE-BERT achieves\nan average improvement of 8.29%.",
      "tldr_zh": "本文提出 ST-MoE-BERT 框架，用于处理长期跨城市人类移动性预测中的复杂空间-时间动态挑战。该方法将预测任务转化为空间-时间分类问题，结合 Mixture-of-Experts 架构和 BERT 模型来捕捉移动模式，并通过 transfer learning 解决数据稀缺问题。实验结果显示，ST-MoE-BERT 在 GEO-BLEU 和 DTW 指标上比现有方法平均提高了 8.29%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "2nd ACM SIGSPATIAL International Workshop on the Human Mobility\n  Prediction Challenge",
      "pdf_url": "http://arxiv.org/pdf/2410.14099v1",
      "published_date": "2024-10-18 00:32:18 UTC",
      "updated_date": "2024-10-18 00:32:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:39:58.042145"
    },
    {
      "arxiv_id": "2410.14091v2",
      "title": "Towards Effective Planning Strategies for Dynamic Opinion Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Bharath Muppasani",
        "Protik Nag",
        "Vignesh Narayanan",
        "Biplav Srivastava",
        "Michael N. Huhns"
      ],
      "abstract": "In this study, we investigate the under-explored intervention planning aimed\nat disseminating accurate information within dynamic opinion networks by\nleveraging learning strategies. Intervention planning involves identifying key\nnodes (search) and exerting control (e.g., disseminating accurate or official\ninformation through the nodes) to mitigate the influence of misinformation.\nHowever, as the network size increases, the problem becomes computationally\nintractable. To address this, we first introduce a ranking algorithm to\nidentify key nodes for disseminating accurate information, which facilitates\nthe training of neural network classifiers that provide generalized solutions\nfor the search and planning problems. Second, we mitigate the complexity of\nlabel generation, which becomes challenging as the network grows, by developing\na reinforcement learning-based centralized dynamic planning framework. We\nanalyze these NN-based planners for opinion networks governed by two dynamic\npropagation models. Each model incorporates both binary and continuous opinion\nand trust representations. Our experimental results demonstrate that the\nranking algorithm-based classifiers provide plans that enhance infection rate\ncontrol, especially with increased action budgets for small networks. Further,\nwe observe that the reward strategies focusing on key metrics, such as the\nnumber of susceptible nodes and infection rates, outperform those prioritizing\nfaster blocking strategies. Additionally, our findings reveal that graph\nconvolutional network-based planners facilitate scalable centralized plans that\nachieve lower infection rates (higher control) across various network\nconfigurations, including Watts-Strogatz topology, varying action budgets,\nvarying initial infected nodes, and varying degrees of infected nodes.",
      "tldr_zh": "本研究探讨了在动态意见网络中，通过学习策略进行干预规划，以有效传播准确信息并抑制误信息影响。主要方法包括引入一个排名算法来识别关键节点，并训练神经网络分类器提供泛化解决方案；同时，开发基于强化学习的集中式动态规划框架，以处理大规模网络的复杂性。实验结果显示，该算法在小网络中显著提升感染率控制，尤其当行动预算增加时；奖励策略优先考虑易感节点数和感染率等关键指标时表现更优。此外，基于图卷积网络 (GCN) 的规划器在各种网络配置（如 Watts-Strogatz 拓扑、不同初始感染节点和行动预算）下实现了更低的感染率，提高了整体控制效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.14091v2",
      "published_date": "2024-10-18 00:13:56 UTC",
      "updated_date": "2024-11-03 01:13:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:40:10.445744"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 122,
  "processed_papers_count": 122,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T13:40:35.428700"
}