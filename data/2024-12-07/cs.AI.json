{
  "date": "2024-12-07",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-07 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 模型性能评估、机器学习应用（如情感分析和异常检测）、医疗图像处理以及科学计算等领域。其中，OpenAI o1 模型在高级认知任务中的表现令人印象深刻，知名学者如 Constantinos Daskalakis 的游戏理论故事分析作品备受关注，同时 LLM 隐私泄露检测和零监督行为生成等创新方法也具有话题潜力。\n\n下面，我将挑选并讨论最具影响力和代表性的论文，先从 AI 和 LLM 相关的高话题度文章入手，再简要覆盖其他领域。其他较常规的论文（如某些 GAN 或神经网络优化方法）将快速掠过，以控制篇幅。\n\n### 1. OpenAI o1 模型是否在高级认知思维中超越人类？ (Can OpenAI o1 outperform humans in higher-order cognitive thinking?)\n这篇论文由 Ehsan Latif 等作者发布，评估了 OpenAI o1-preview 模型在关键认知领域（如批判性思维、逻辑推理和科学推理）的表现。核心贡献是通过基准测试（如 Ennis-Weir 测试）比较模型与人类的得分，结果显示 o1-preview 在结构化任务中超越本科生和研究生（如逻辑推理准确率达 90%），但在适应性推理上存在局限。该发现突显 AI 在教育辅助中的潜力，同时强调了伦理监督的必要性，是一篇高话题度的 AI 性能评估文章。\n\n### 2. PrivAgent: 基于代理的 LLM 隐私泄露红队测试 (PrivAgent: Agentic-based Red-teaming for LLM Privacy Leakage)\nYuzhou Nie 等作者提出了一种黑盒红队框架 PrivAgent，用于检测 LLM 的隐私泄露风险（如系统提示和训练数据提取）。主要方法是通过强化学习训练代理生成对抗性提示，并设计新型奖励函数。实验显示，PrivAgent 在六种流行 LLM 上实现 100% 系统提示提取成功率，并能规避现有防御机制。该论文揭示了 LLM 安全漏洞，具有实际应用价值，值得关注 LLM 隐私话题。\n\n### 3. 用游戏理论描绘故事形状 (Charting the Shapes of Stories with Game Theory)\n由知名学者 Constantinos Daskalakis、Christos Papadimitriou 等合作，发表于 NeurIPS 2024 Creative AI Track。这篇论文创新地将 AI 与游戏理论结合，将故事建模为游戏对象，分析角色决策和潜在反事实情节。核心发现是通过 AI 生成的莎士比亚《罗密欧与朱丽叶》分析，揭示了故事结构的可量化性。该工作桥接了文学与 AI，展示了 AI 在人文分析中的潜力，是本日最令人印象深刻的跨学科文章。\n\n### 4. RL Zero: 零监督语言到行为的生成 (RL Zero: Zero-Shot Language to Behaviors without any Supervision)\nHarshit Sikchi 等作者开发了 RL Zero 框架，实现零监督的语言指令到行为转换。方法包括想象-投影-模仿流程，利用视频语言模型生成任务序列，并通过无监督强化学习接地行为。发现显示，该模型能在模拟环境中处理多种任务，并支持跨实体视频应用。该论文推进了 AI 代理的无监督学习，适用于机器人和交互系统，是一篇创新性强的机器学习工作。\n\n### 5. 基于图学习的无监督超边异常检测 (Hyperedge Anomaly Detection with Hypergraph Neural Network)\nMd. Tanvir Alam 等作者提出了一种基于超图神经网络的异常检测方法，处理高阶数据关联。核心贡献是构建端到端模型，从超图中识别异常超边，实验在真实数据集上表现出色。该方法扩展了图神经网络的应用，具有实际意义，但作为较常规主题，我仅简要提及。\n\n### 6. 使用 UNet++ 和 LSTM 的乳腺超声图像分割 (UNet++ and LSTM combined approach for Breast Ultrasound Image Segmentation)\nSaba Hesaraki 等作者结合 UNet++ 和 LSTM 进行乳腺超声图像分割，方法通过时间序列建模提升准确率。发现显示，模型在 BUSI 数据集上达到 98.88% 准确率。该论文在医疗图像处理中应用深度学习，但与其他分割方法类似，我快速掠过。\n\n### 7. 基于时间序列基础模型的地下井日志预测和异常检测 (Leveraging Time-Series Foundation Model for Subsurface Well Logs Prediction and Anomaly Detection)\nArdiansyah Koeshidayatullah 等作者使用 TimeGPT 模型预测井日志数据和检测异常，R2 达 87%、异常检测准确率 93%。该工作提高了地质勘探效率，适用于能源行业，但作为专业应用，我仅简要总结其在复杂序列预测中的进展。\n\n其他论文，如 GAN 在艺术生成中的应用（A Tiered GAN Approach for Monet-Style Image Generation）、情感分析（BERTCaps）和股票预测（Innovative Sentiment Analysis），则更多是技术优化，贡献虽稳固但不具突破性，故不详细展开。总体而言，今天的 arXiv 更新强调了 AI 在认知、隐私和实际应用中的潜力，读者可关注前述重点论文进行深入阅读。明日见！",
  "papers": [
    {
      "arxiv_id": "2412.05753v1",
      "title": "Can OpenAI o1 outperform humans in higher-order cognitive thinking?",
      "title_zh": "OpenAI o1 是否能在高阶认知思维中超越人类？",
      "authors": [
        "Ehsan Latif",
        "Yifan Zhou",
        "Shuchen Guo",
        "Lehong Shi",
        "Yizhu Gao",
        "Matthew Nyaaba",
        "Arne Bewerdorff",
        "Xiantong Yang",
        "Xiaoming Zhai"
      ],
      "abstract": "This study evaluates the performance of OpenAI's o1-preview model in\nhigher-order cognitive domains, including critical thinking, systematic\nthinking, computational thinking, data literacy, creative thinking, logical\nreasoning, and scientific reasoning. Using established benchmarks, we compared\nthe o1-preview models's performance to human participants from diverse\neducational levels. o1-preview achieved a mean score of 24.33 on the Ennis-Weir\nCritical Thinking Essay Test (EWCTET), surpassing undergraduate (13.8) and\npostgraduate (18.39) participants (z = 1.60 and 0.90, respectively). In\nsystematic thinking, it scored 46.1, SD = 4.12 on the Lake Urmia Vignette,\nsignificantly outperforming the human mean (20.08, SD = 8.13, z = 3.20). For\ndata literacy, o1-preview scored 8.60, SD = 0.70 on Merk et al.'s \"Use Data\"\ndimension, compared to the human post-test mean of 4.17, SD = 2.02 (z = 2.19).\nOn creative thinking tasks, the model achieved originality scores of 2.98, SD =\n0.73, higher than the human mean of 1.74 (z = 0.71). In logical reasoning\n(LogiQA), it outperformed humans with average 90%, SD = 10% accuracy versus\n86%, SD = 6.5% (z = 0.62). For scientific reasoning, it achieved near-perfect\nperformance (mean = 0.99, SD = 0.12) on the TOSLS,, exceeding the highest human\nscores of 0.85, SD = 0.13 (z = 1.78). While o1-preview excelled in structured\ntasks, it showed limitations in problem-solving and adaptive reasoning. These\nresults demonstrate the potential of AI to complement education in structured\nassessments but highlight the need for ethical oversight and refinement for\nbroader applications.",
      "tldr_zh": "这篇论文评估了 OpenAI o1-preview 模型在高级认知领域（如批判性思维、系统性思维、计算思维、数据素养、创造性思维、逻辑推理和科学推理）的表现，并与不同教育水平的人类参与者进行比较。结果显示，o1-preview 在多项基准测试中表现出色，例如在 Ennis-Weir Critical Thinking Essay Test (EWCTET) 上得分24.33，高于本科生（13.8）和研究生（18.39）的平均分；在 LogiQA 逻辑推理任务中，准确率达90%，超过人类的86%。尽管模型在结构化任务中领先，但存在问题解决和适应性推理的局限性，研究强调 AI 可补充教育评估，但需加强伦理监督和进一步优化。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05753v1",
      "published_date": "2024-12-07 21:52:03 UTC",
      "updated_date": "2024-12-07 21:52:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:18:25.120698"
    },
    {
      "arxiv_id": "2412.05749v1",
      "title": "A Comparative Study on Code Generation with Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Namrata Das",
        "Rakshya Panta",
        "Neelam Karki",
        "Ruchi Manandhar",
        "Dinesh Baniya Kshatri"
      ],
      "abstract": "In an era of widespread influence of Natural Language Processing (NLP), there\nhave been multiple research efforts to supplant traditional manual coding\ntechniques with automated systems capable of generating solutions autonomously.\nWith rapid research for code generation and a sole focus on large language\nmodels, there emerges a need to compare and evaluate the performance of\ntransformer architectures based on several complexities of the model. This\npaper introduces the concept of a \"A Comparative Study on Code Generation with\nTransformers,\" a model based on Transformer architecture, and NLP methodologies\nto automatically generate C++ source code for different varieties of problems.\nHere, a comparative study is performed to evaluate the robustness of\ntransformer-based models on the basis of their architecture complexities and\ntheir capability to handle diverse problem sets, from basic arithmetic to\ncomplex computations.",
      "tldr_zh": "这篇论文比较了基于 Transformer 架构的模型在代码生成方面的性能，旨在评估这些模型处理不同复杂问题时的鲁棒性。研究利用 NLP 方法自动生成 C++ 源代码，从基本算术运算到复杂计算问题进行测试。结果显示，模型的架构复杂度和处理多样化问题集的能力存在显著差异，为未来改进 Transformer 模型的代码生成技术提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05749v1",
      "published_date": "2024-12-07 21:18:23 UTC",
      "updated_date": "2024-12-07 21:18:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:18:37.112801"
    },
    {
      "arxiv_id": "2412.05748v1",
      "title": "Constrained Control for Autonomous Spacecraft Rendezvous: Learning-Based Time Shift Governor",
      "title_zh": "翻译失败",
      "authors": [
        "Taehyeun Kim",
        "Robin Inho Kee",
        "Ilya Kolmanovsky",
        "Anouck Girard"
      ],
      "abstract": "This paper develops a Time Shift Governor (TSG)-based control scheme to\nenforce constraints during rendezvous and docking (RD) missions in the setting\nof the Two-Body problem. As an add-on scheme to the nominal closed-loop system,\nthe TSG generates a time-shifted Chief spacecraft trajectory as a target\nreference for the Deputy spacecraft. This modification of the commanded\nreference trajectory ensures that constraints are enforced while the time shift\nis reduced to zero to effect the rendezvous. Our approach to TSG implementation\nintegrates an LSTM neural network which approximates the time shift parameter\nas a function of a sequence of past Deputy and Chief spacecraft states. This\nLSTM neural network is trained offline from simulation data. We report\nsimulation results for RD missions in the Low Earth Orbit (LEO) and on the\nMolniya orbit to demonstrate the effectiveness of the proposed control scheme.\nThe proposed scheme reduces the time to compute the time shift parameter in\nmost of the scenarios and successfully completes rendezvous missions.",
      "tldr_zh": "该论文提出了一种基于 Time Shift Governor (TSG) 的控制方案，用于在 Two-Body 问题设置中强制执行自主航天器交会对接 (RD) 任务的约束。TSG 作为名义闭环系统的附加模块，通过生成时间偏移的 Chief 航天器轨迹作为 Deputy 航天器的参考目标，同时利用 LSTM 神经网络根据过去航天器状态序列来近似时间偏移参数，该网络在离线模拟数据上训练。实验结果显示，该方案在 Low Earth Orbit (LEO) 和 Molniya 轨道上的模拟中有效，显著减少了计算时间偏移参数的时间，并成功完成交会任务。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "Taehyeun Kim and Robin Inho Kee contributed equally to this work. 18\n  pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.05748v1",
      "published_date": "2024-12-07 21:17:36 UTC",
      "updated_date": "2024-12-07 21:17:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:18:57.575960"
    },
    {
      "arxiv_id": "2412.05747v1",
      "title": "Charting the Shapes of Stories with Game Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Constantinos Daskalakis",
        "Ian Gemp",
        "Yanchen Jiang",
        "Renato Paes Leme",
        "Christos Papadimitriou",
        "Georgios Piliouras"
      ],
      "abstract": "Stories are records of our experiences and their analysis reveals insights\ninto the nature of being human. Successful analyses are often\ninterdisciplinary, leveraging mathematical tools to extract structure from\nstories and insights from structure. Historically, these tools have been\nrestricted to one dimensional charts and dynamic social networks; however,\nmodern AI offers the possibility of identifying more fully the plot structure,\ncharacter incentives, and, importantly, counterfactual plot lines that the\nstory could have taken but did not take. In this work, we use AI to model the\nstructure of stories as game-theoretic objects, amenable to quantitative\nanalysis. This allows us to not only interrogate each character's decision\nmaking, but also possibly peer into the original author's conception of the\ncharacters' world. We demonstrate our proposed technique on Shakespeare's\nfamous Romeo and Juliet. We conclude with a discussion of how our analysis\ncould be replicated in broader contexts, including real-life scenarios.",
      "tldr_zh": "该论文提出了一种利用博弈论（Game Theory）和人工智能（AI）来分析故事结构的方法，旨在揭示故事中的情节框架、人物动机以及潜在的反事实情节（counterfactual plot lines）。作者将故事建模为博弈论对象，进行定量分析，从而探究人物决策和作者意图，并在莎士比亚的《罗密欧与朱丽叶》上进行了演示。研究讨论了这种分析技术如何扩展到更广泛的语境，包括现实生活场景，以提供对人类经验的更深入洞见。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "NeurIPS 2024 Creative AI Track",
      "pdf_url": "http://arxiv.org/pdf/2412.05747v1",
      "published_date": "2024-12-07 21:12:16 UTC",
      "updated_date": "2024-12-07 21:12:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:18:59.616968"
    },
    {
      "arxiv_id": "2412.05734v1",
      "title": "PrivAgent: Agentic-based Red-teaming for LLM Privacy Leakage",
      "title_zh": "翻译失败",
      "authors": [
        "Yuzhou Nie",
        "Zhun Wang",
        "Ye Yu",
        "Xian Wu",
        "Xuandong Zhao",
        "Wenbo Guo",
        "Dawn Song"
      ],
      "abstract": "Recent studies have discovered that LLMs have serious privacy leakage\nconcerns, where an LLM may be fooled into outputting private information under\ncarefully crafted adversarial prompts. These risks include leaking system\nprompts, personally identifiable information, training data, and model\nparameters. Most existing red-teaming approaches for privacy leakage rely on\nhumans to craft the adversarial prompts. A few automated methods are proposed\nfor system prompt extraction, but they cannot be applied to more severe risks\n(e.g., training data extraction) and have limited effectiveness even for system\nprompt extraction.\n  In this paper, we propose PrivAgent, a novel black-box red-teaming framework\nfor LLM privacy leakage. We formulate different risks as a search problem with\na unified attack goal. Our framework trains an open-source LLM through\nreinforcement learning as the attack agent to generate adversarial prompts for\ndifferent target models under different risks. We propose a novel reward\nfunction to provide effective and fine-grained rewards for the attack agent.\nFinally, we introduce customizations to better fit our general framework to\nsystem prompt extraction and training data extraction. Through extensive\nevaluations, we first show that PrivAgent outperforms existing automated\nmethods in system prompt leakage against six popular LLMs. Notably, our\napproach achieves a 100% success rate in extracting system prompts from\nreal-world applications in OpenAI's GPT Store. We also show PrivAgent's\neffectiveness in extracting training data from an open-source LLM with a\nsuccess rate of 5.9%. We further demonstrate PrivAgent's effectiveness in\nevading the existing guardrail defense and its helpfulness in enabling better\nsafety alignment. Finally, we validate our customized designs through a\ndetailed ablation study. We release our code here\nhttps://github.com/rucnyz/RedAgent.",
      "tldr_zh": "该研究提出PrivAgent，一种基于智能体的黑盒红队框架，用于检测大型语言模型(LLMs)的隐私泄露风险，包括系统提示、个人信息、训练数据和模型参数的潜在泄漏。PrivAgent将不同风险形式化为统一的搜索问题，通过强化学习训练开源LLM作为攻击代理生成对抗性提示，并设计了一个细粒度的奖励函数，同时针对系统提示和训练数据提取进行定制。实验结果显示，该框架在六种流行LLMs的系统提示提取上优于现有方法，成功率达100%，并在训练数据提取中实现5.9%的成功率，同时能规避现有防御机制并有助于提升LLMs的安全对齐。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05734v1",
      "published_date": "2024-12-07 20:09:01 UTC",
      "updated_date": "2024-12-07 20:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:19:15.701881"
    },
    {
      "arxiv_id": "2412.05731v1",
      "title": "A Scoping Review of ChatGPT Research in Accounting and Finance",
      "title_zh": "ChatGPT 研究在会计和金融领域的范围综述",
      "authors": [
        "Mengming Michael Dong",
        "Theophanis C. Stratopoulos",
        "Victor Xiaoqi Wang"
      ],
      "abstract": "This paper provides a review of recent publications and working papers on\nChatGPT and related Large Language Models (LLMs) in accounting and finance. The\naim is to understand the current state of research in these two areas and\nidentify potential research opportunities for future inquiry. We identify three\ncommon themes from these earlier studies. The first theme focuses on\napplications of ChatGPT and LLMs in various fields of accounting and finance.\nThe second theme utilizes ChatGPT and LLMs as a new research tool by leveraging\ntheir capabilities such as classification, summarization, and text generation.\nThe third theme investigates implications of LLM adoption for accounting and\nfinance professionals, as well as for various organizations and sectors. While\nthese earlier studies provide valuable insights, they leave many important\nquestions unanswered or partially addressed. We propose venues for further\nexploration and provide technical guidance for researchers seeking to employ\nChatGPT and related LLMs as a tool for their research.",
      "tldr_zh": "这篇论文对ChatGPT和相关Large Language Models (LLMs)在会计和金融领域的最新研究进行了文献综述，旨在审视当前研究状态并识别未来研究机会。研究总结了三个主要主题：一是ChatGPT和LLMs在会计和金融各种领域的应用；二是将这些模型作为新研究工具，利用其分类、总结和文本生成能力；三是探讨LLMs采用对会计和金融专业人士、组织和部门的潜在影响。尽管现有研究提供了宝贵见解，但许多问题仍未充分解答，论文因此提出进一步探索的路径，并为研究者提供使用ChatGPT等LLMs的技术指导。",
      "categories": [
        "q-fin.GN",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "q-fin.GN",
      "comment": "56 pages, 3 figures, 16 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.05731v1",
      "published_date": "2024-12-07 19:45:46 UTC",
      "updated_date": "2024-12-07 19:45:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:19:24.840229"
    },
    {
      "arxiv_id": "2412.05725v2",
      "title": "Black Swan: Abductive and Defeasible Video Reasoning in Unpredictable Events",
      "title_zh": "Black Swan: 针对不可预测事件的溯因与可推翻视频推理",
      "authors": [
        "Aditya Chinchure",
        "Sahithya Ravi",
        "Raymond Ng",
        "Vered Shwartz",
        "Boyang Li",
        "Leonid Sigal"
      ],
      "abstract": "The commonsense reasoning capabilities of vision-language models (VLMs),\nespecially in abductive reasoning and defeasible reasoning, remain poorly\nunderstood. Most benchmarks focus on typical visual scenarios, making it\ndifficult to discern whether model performance stems from keen perception and\nreasoning skills, or reliance on pure statistical recall. We argue that by\nfocusing on atypical events in videos, clearer insights can be gained on the\ncore capabilities of VLMs. Explaining and understanding such\nout-of-distribution events requires models to extend beyond basic pattern\nrecognition and regurgitation of their prior knowledge. To this end, we\nintroduce BlackSwanSuite, a benchmark for evaluating VLMs' ability to reason\nabout unexpected events through abductive and defeasible tasks. Our tasks\nartificially limit the amount of visual information provided to models while\nquestioning them about hidden unexpected events, or provide new visual\ninformation that could change an existing hypothesis about the event. We curate\na comprehensive benchmark suite comprising over 3,800 MCQ, 4,900 generative and\n6,700 yes/no questions, spanning 1,655 videos. After extensively evaluating\nvarious state-of-the-art VLMs, including GPT-4o and Gemini 1.5 Pro, as well as\nopen-source VLMs such as LLaVA-Video, we find significant performance gaps of\nup to 32% from humans on these tasks. Our findings reveal key limitations in\ncurrent VLMs, emphasizing the need for enhanced model architectures and\ntraining strategies. Our data and leaderboard is available at\nblackswan.cs.ubc.ca.",
      "tldr_zh": "该论文探讨了视觉语言模型 (VLMs) 在处理不可预测事件时的溯因推理 (abductive reasoning) 和可推翻推理 (defeasible reasoning) 能力，指出现有基准过于关注典型场景而无法准确评估模型的真实推理水平。论文引入 BlackSwanSuite 基准，通过1,655 个视频创建超过3,800 个多选题、4,900 个生成式问题和6,700 个是非题，这些任务有意限制视觉信息或引入新信息来测试模型对隐藏或变化事件的推理。实验评估了多种 SOTA VLMs，如 GPT-4o 和 Gemini 1.5 Pro，结果显示模型与人类的表现差距高达32%，强调了需要优化模型架构和训练策略以提升其在非典型事件中的推理能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025. For data, visit https://blackswan.cs.ubc.ca",
      "pdf_url": "http://arxiv.org/pdf/2412.05725v2",
      "published_date": "2024-12-07 19:19:03 UTC",
      "updated_date": "2025-04-07 20:26:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:19:42.360290"
    },
    {
      "arxiv_id": "2412.05724v1",
      "title": "A Tiered GAN Approach for Monet-Style Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "FNU Neha",
        "Deepshikha Bhati",
        "Deepak Kumar Shukla",
        "Md Amiruzzaman"
      ],
      "abstract": "Generative Adversarial Networks (GANs) have proven to be a powerful tool in\ngenerating artistic images, capable of mimicking the styles of renowned\npainters, such as Claude Monet. This paper introduces a tiered GAN model to\nprogressively refine image quality through a multi-stage process, enhancing the\ngenerated images at each step. The model transforms random noise into detailed\nartistic representations, addressing common challenges such as instability in\ntraining, mode collapse, and output quality. This approach combines\ndownsampling and convolutional techniques, enabling the generation of\nhigh-quality Monet-style artwork while optimizing computational efficiency.\nExperimental results demonstrate the architecture's ability to produce\nfoundational artistic structures, though further refinements are necessary for\nachieving higher levels of realism and fidelity to Monet's style. Future work\nfocuses on improving training methodologies and model complexity to bridge the\ngap between generated and true artistic images. Additionally, the limitations\nof traditional GANs in artistic generation are analyzed, and strategies to\novercome these shortcomings are proposed.",
      "tldr_zh": "这篇论文提出了一种分层 GAN (Tiered GAN) 方法，通过多阶段过程逐步提升图像质量，用于生成 Monet-Style 艺术图像。模型从随机噪声出发，利用 downsampling 和 convolutional 技术，解决传统 GAN 的训练不稳定性、模式崩溃等问题，同时优化计算效率。实验结果显示，该方法能产生基础的艺术结构，但仍需进一步改进训练方法和模型复杂度，以提升真实性和对 Monet 风格的忠实度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05724v1",
      "published_date": "2024-12-07 19:10:29 UTC",
      "updated_date": "2024-12-07 19:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:19:49.097183"
    },
    {
      "arxiv_id": "2412.05723v2",
      "title": "Training-Free Bayesianization for Low-Rank Adapters of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haizhou Shi",
        "Yibin Wang",
        "Ligong Han",
        "Huan Zhang",
        "Hao Wang"
      ],
      "abstract": "Estimating the uncertainty of responses from Large Language Models (LLMs)\nremains a critical challenge. While recent Bayesian methods have demonstrated\neffectiveness in quantifying uncertainty through low-rank weight updates, they\ntypically require complex fine-tuning or post-training procedures. In this\npaper, we propose Training-Free Bayesianization (TFB), a simple yet\ntheoretically grounded framework that efficiently transforms trained low-rank\nadapters into Bayesian ones without additional training. TFB systematically\nsearches for the maximally acceptable level of variance in the weight\nposterior, constrained within a family of low-rank isotropic Gaussian\ndistributions. Our theoretical analysis shows that under mild conditions, this\nsearch process is equivalent to KL-regularized variational optimization, a\ngeneralized form of variational inference. Through comprehensive experiments,\nwe show that TFB achieves superior uncertainty estimation and generalization\ncompared to existing methods while eliminating the need for complex\nBayesianization training procedures. Code will be available at\nhttps://github.com/Wang-ML-Lab/bayesian-peft.",
      "tldr_zh": "本文提出Training-Free Bayesianization (TFB)，一个简单且理论基础坚实的框架，用于将大型语言模型(LLMs)的训练过的低-rank adapters转换为贝叶斯版本，而无需额外训练。TFB通过系统搜索权重后验中最大可接受的方差水平，并限制在低-rank各向同性高斯分布家族内，实现高效的不确定性量化。理论分析表明，这一搜索过程等价于KL-regularized variational optimization的广义形式。实验结果显示，TFB在不确定性估计和泛化性能上优于现有方法，同时消除了复杂的贝叶斯化训练需求。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "Pre-print; Accepted (non-archivally) at ICLR'25 Workshop: \"Quantify\n  Uncertainty and Hallucination in Foundation Models: The Next Frontier in\n  Reliable AI\"",
      "pdf_url": "http://arxiv.org/pdf/2412.05723v2",
      "published_date": "2024-12-07 18:49:27 UTC",
      "updated_date": "2025-05-16 21:43:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:20:03.116628"
    },
    {
      "arxiv_id": "2412.05718v1",
      "title": "RL Zero: Zero-Shot Language to Behaviors without any Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Harshit Sikchi",
        "Siddhant Agarwal",
        "Pranaya Jajoo",
        "Samyak Parajuli",
        "Caleb Chuck",
        "Max Rudolph",
        "Peter Stone",
        "Amy Zhang",
        "Scott Niekum"
      ],
      "abstract": "Rewards remain an uninterpretable way to specify tasks for Reinforcement\nLearning, as humans are often unable to predict the optimal behavior of any\ngiven reward function, leading to poor reward design and reward hacking.\nLanguage presents an appealing way to communicate intent to agents and bypass\nreward design, but prior efforts to do so have been limited by costly and\nunscalable labeling efforts. In this work, we propose a method for a completely\nunsupervised alternative to grounding language instructions in a zero-shot\nmanner to obtain policies. We present a solution that takes the form of\nimagine, project, and imitate: The agent imagines the observation sequence\ncorresponding to the language description of a task, projects the imagined\nsequence to our target domain, and grounds it to a policy. Video-language\nmodels allow us to imagine task descriptions that leverage knowledge of tasks\nlearned from internet-scale video-text mappings. The challenge remains to\nground these generations to a policy. In this work, we show that we can achieve\na zero-shot language-to-behavior policy by first grounding the imagined\nsequences in real observations of an unsupervised RL agent and using a\nclosed-form solution to imitation learning that allows the RL agent to mimic\nthe grounded observations. Our method, RLZero, is the first to our knowledge to\nshow zero-shot language to behavior generation abilities without any\nsupervision on a variety of tasks on simulated domains. We further show that\nRLZero can also generate policies zero-shot from cross-embodied videos such as\nthose scraped from YouTube.",
      "tldr_zh": "这篇论文提出RL Zero方法，实现零样本语言指令到行为的转换，而无需任何监督，从而避免了传统强化学习(Reinforcement Learning)中奖励函数设计的不易解释性和潜在问题。方法采用“想象、投影和模仿”的框架：首先使用视频-语言模型从互联网规模视频-文本映射中生成任务观察序列，然后投影到目标域，并通过模仿学习让无监督RL代理模仿这些序列。实验结果显示，RL Zero在各种模拟任务上成功生成行为策略，甚至能从跨体视频（如YouTube）中零样本获取策略，为高效的任务指定提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "27 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.05718v1",
      "published_date": "2024-12-07 18:31:16 UTC",
      "updated_date": "2024-12-07 18:31:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:20:15.191743"
    },
    {
      "arxiv_id": "2412.05717v1",
      "title": "Learning Soft Driving Constraints from Vectorized Scene Embeddings while Imitating Expert Trajectories",
      "title_zh": "从矢量化场景嵌入中学习软驾驶约束，同时模仿专家轨迹",
      "authors": [
        "Niloufar Saeidi Mobarakeh",
        "Behzad Khamidehi",
        "Chunlin Li",
        "Hamidreza Mirkhani",
        "Fazel Arasteh",
        "Mohammed Elmahgiubi",
        "Weize Zhang",
        "Kasra Rezaee",
        "Pascal Poupart"
      ],
      "abstract": "The primary goal of motion planning is to generate safe and efficient\ntrajectories for vehicles. Traditionally, motion planning models are trained\nusing imitation learning to mimic the behavior of human experts. However, these\nmodels often lack interpretability and fail to provide clear justifications for\ntheir decisions. We propose a method that integrates constraint learning into\nimitation learning by extracting driving constraints from expert trajectories.\nOur approach utilizes vectorized scene embeddings that capture critical spatial\nand temporal features, enabling the model to identify and generalize\nconstraints across various driving scenarios. We formulate the constraint\nlearning problem using a maximum entropy model, which scores the motion\nplanner's trajectories based on their similarity to the expert trajectory. By\nseparating the scoring process into distinct reward and constraint streams, we\nimprove both the interpretability of the planner's behavior and its attention\nto relevant scene components. Unlike existing constraint learning methods that\nrely on simulators and are typically embedded in reinforcement learning (RL) or\ninverse reinforcement learning (IRL) frameworks, our method operates without\nsimulators, making it applicable to a wider range of datasets and real-world\nscenarios. Experimental results on the InD and TrafficJams datasets demonstrate\nthat incorporating driving constraints enhances model interpretability and\nimproves closed-loop performance.",
      "tldr_zh": "该论文提出了一种将约束学习集成到模仿学习中的方法，用于从专家轨迹中提取软驾驶约束，从而生成更安全、高效的车辆轨迹。方法利用 vectorized scene embeddings 捕捉关键的空间和时间特征，并通过 maximum entropy model 对运动规划器的轨迹进行评分，将评分过程分为 reward 和 constraint 流，以提升模型的可解释性和对场景组件的关注。不同于依赖模拟器的传统 reinforcement learning (RL) 或 inverse reinforcement learning (IRL) 方法，该方法无需模拟器，可应用于更广泛的数据集。实验结果显示，在 InD 和 TrafficJams 数据集上，加入驾驶约束后，模型的闭环性能和可解释性均得到显著改善。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05717v1",
      "published_date": "2024-12-07 18:29:28 UTC",
      "updated_date": "2024-12-07 18:29:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:20:32.092239"
    },
    {
      "arxiv_id": "2412.05710v1",
      "title": "PromptRefine: Enhancing Few-Shot Performance on Low-Resource Indic Languages with Example Selection from Related Example Banks",
      "title_zh": "翻译失败",
      "authors": [
        "Soumya Suvra Ghosal",
        "Soumyabrata Pal",
        "Koyel Mukherjee",
        "Dinesh Manocha"
      ],
      "abstract": "Large Language Models (LLMs) have recently demonstrated impressive few-shot\nlearning capabilities through in-context learning (ICL). However, ICL\nperformance is highly dependent on the choice of few-shot demonstrations,\nmaking the selection of the most optimal examples a persistent research\nchallenge. This issue is further amplified in low-resource Indic languages,\nwhere the scarcity of ground-truth data complicates the selection process. In\nthis work, we propose PromptRefine, a novel Alternating Minimization approach\nfor example selection that improves ICL performance on low-resource Indic\nlanguages. PromptRefine leverages auxiliary example banks from related\nhigh-resource Indic languages and employs multi-task learning techniques to\nalign language-specific retrievers, enabling effective cross-language\nretrieval. Additionally, we incorporate diversity in the selected examples to\nenhance generalization and reduce bias. Through comprehensive evaluations on\nfour text generation tasks -- Cross-Lingual Question Answering, Multilingual\nQuestion Answering, Machine Translation, and Cross-Lingual Summarization using\nstate-of-the-art LLMs such as LLAMA-3.1-8B, LLAMA-2-7B, Qwen-2-7B, and\nQwen-2.5-7B, we demonstrate that PromptRefine significantly outperforms\nexisting frameworks for retrieving examples.",
      "tldr_zh": "本文提出 PromptRefine，一种基于 Alternating Minimization 的示例选择方法，旨在提升大语言模型 (LLMs) 在低资源 Indic Languages 上的 Few-Shot 性能，通过利用相关高资源 Indic Languages 的辅助示例库和 Multi-Task Learning 技术实现有效的跨语言检索，并加入示例多样性以减少偏差。PromptRefine 通过对齐语言特定检索器，优化 In-Context Learning (ICL) 过程，在 Cross-Lingual Question Answering、Multilingual Question Answering、Machine Translation 和 Cross-Lingual Summarization 等四个文本生成任务上，使用 LLAMA-3.1-8B 等先进模型进行评估，结果显示其显著优于现有框架。总的来说，该方法为低资源语言的 ICL 应用提供了可扩展的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05710v1",
      "published_date": "2024-12-07 17:51:31 UTC",
      "updated_date": "2024-12-07 17:51:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:20:44.499866"
    },
    {
      "arxiv_id": "2412.06843v2",
      "title": "Semantic Loss Guided Data Efficient Supervised Fine Tuning for Safe Responses in LLMs",
      "title_zh": "语义损失引导的数据高效监督微调，用于LLMs中的安全响应",
      "authors": [
        "Yuxiao Lu",
        "Arunesh Sinha",
        "Pradeep Varakantham"
      ],
      "abstract": "Large Language Models (LLMs) generating unsafe responses to toxic prompts is\na significant issue in their applications. While various efforts aim to address\nthis safety concern, previous approaches often demand substantial human data\ncollection or rely on the less dependable option of using another LLM to\ngenerate corrective data. In this paper, we aim to take this problem and\novercome limitations of requiring significant high-quality human data. Our\nmethod requires only a small set of unsafe responses to toxic prompts, easily\nobtained from the unsafe LLM itself. By employing a semantic cost combined with\na negative Earth Mover Distance (EMD) loss, we guide the LLM away from\ngenerating unsafe responses. Additionally, we propose a novel lower bound for\nEMD loss, enabling more efficient optimization. Our results demonstrate\nsuperior performance and data efficiency compared to baselines, and we further\nexamine the nuanced effects of over-alignment and potential degradation of\nlanguage capabilities when using contrastive data.",
      "tldr_zh": "这篇论文提出了一种基于语义损失（Semantic Loss）的监督微调方法，用于提升大型语言模型（LLMs）对有毒提示的安全响应能力，仅需少量不安全响应数据即可实现。方法通过结合语义成本和负 Earth Mover Distance (EMD) 损失来引导模型远离不安全输出，并引入 EMD 损失的下界以优化训练效率。实验结果显示，该方法在数据效率和性能上优于基线模型，同时探讨了过度对齐可能导致语言能力退化的细微影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06843v2",
      "published_date": "2024-12-07 16:35:14 UTC",
      "updated_date": "2024-12-11 12:35:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:20:54.711729"
    },
    {
      "arxiv_id": "2412.05688v3",
      "title": "Flow-based Detection of Botnets through Bio-inspired Optimisation of Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Biju Issac",
        "Kyle Fryer",
        "Seibu Mary Jacob"
      ],
      "abstract": "Botnets could autonomously infect, propagate, communicate and coordinate with\nother members in the botnet, enabling cybercriminals to exploit the cumulative\ncomputing and bandwidth of its bots to facilitate cybercrime. Traditional\ndetection methods are becoming increasingly unsuitable against various\nnetwork-based detection evasion methods. These techniques ultimately render\nsignature-based fingerprinting detection infeasible and thus this research\nexplores the application of network flow-based behavioural modelling to\nfacilitate the binary classification of bot network activity, whereby the\ndetection is independent of underlying communications architectures, ports,\nprotocols and payload-based detection evasion mechanisms. A comparative\nevaluation of various machine learning classification methods is conducted, to\nprecisely determine the average accuracy of each classifier on bot datasets\nlike CTU-13, ISOT 2010 and ISCX 2014. Additionally, hyperparameter tuning using\nGenetic Algorithm (GA), aiming to efficiently converge to the fittest\nhyperparameter set for each dataset was done. The bioinspired optimisation of\nRandom Forest (RF) with GA achieved an average accuracy of 99.85% when it was\ntested against the three datasets. The model was then developed into a software\nproduct. The YouTube link of the project and demo of the software developed:\nhttps://youtu.be/gNQjC91VtOI",
      "tldr_zh": "本文提出了一种基于网络流（network flow）的 Botnets 检测方法，通过生物启发优化（bio-inspired optimisation）来提升机器学习分类器的性能，以应对传统签名检测的失效问题。研究比较了多种机器学习分类器在 CTU-13、ISOT 2010 和 ISCX 2014 数据集上的准确率，并使用 Genetic Algorithm (GA) 进行超参数调优。优化后的 Random Forest (RF) 模型在三个数据集上实现了 99.85% 的平均准确率。该方法最终开发成软件产品，并提供了演示链接，以支持实际网络安全应用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.05688v3",
      "published_date": "2024-12-07 15:55:49 UTC",
      "updated_date": "2024-12-15 13:58:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:21:07.946788"
    },
    {
      "arxiv_id": "2412.05686v1",
      "title": "Neural network interpretability with layer-wise relevance propagation: novel techniques for neuron selection and visualization",
      "title_zh": "翻译失败",
      "authors": [
        "Deepshikha Bhati",
        "Fnu Neha",
        "Md Amiruzzaman",
        "Angela Guercio",
        "Deepak Kumar Shukla",
        "Ben Ward"
      ],
      "abstract": "Interpreting complex neural networks is crucial for understanding their\ndecision-making processes, particularly in applications where transparency and\naccountability are essential. This proposed method addresses this need by\nfocusing on layer-wise Relevance Propagation (LRP), a technique used in\nexplainable artificial intelligence (XAI) to attribute neural network outputs\nto input features through backpropagated relevance scores. Existing LRP methods\noften struggle with precision in evaluating individual neuron contributions. To\novercome this limitation, we present a novel approach that improves the parsing\nof selected neurons during LRP backward propagation, using the Visual Geometry\nGroup 16 (VGG16) architecture as a case study. Our method creates neural\nnetwork graphs to highlight critical paths and visualizes these paths with\nheatmaps, optimizing neuron selection through accuracy metrics like Mean\nSquared Error (MSE) and Symmetric Mean Absolute Percentage Error (SMAPE).\nAdditionally, we utilize a deconvolutional visualization technique to\nreconstruct feature maps, offering a comprehensive view of the network's inner\nworkings. Extensive experiments demonstrate that our approach enhances\ninterpretability and supports the development of more transparent artificial\nintelligence (AI) systems for computer vision applications. This advancement\nhas the potential to improve the trustworthiness of AI models in real-world\nmachine vision applications, thereby increasing their reliability and\neffectiveness.",
      "tldr_zh": "这篇论文提出了改进Layer-wise Relevance Propagation (LRP)的方法，以提升神经网络的可解释性，特别是针对评估单个神经元贡献的精度问题。研究以VGG16架构为例，引入新型技术，包括创建神经网络图突出关键路径、用热图可视化路径，并通过Mean Squared Error (MSE)和Symmetric Mean Absolute Percentage Error (SMAPE)指标优化神经元选择。还结合反卷积可视化技术重建特征图，提供对网络内部机制的全面视图。实验结果表明，该方法显著提高了AI系统的透明度和可信度，尤其适用于计算机视觉应用。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05686v1",
      "published_date": "2024-12-07 15:49:14 UTC",
      "updated_date": "2024-12-07 15:49:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:21:18.123189"
    },
    {
      "arxiv_id": "2412.05685v1",
      "title": "HMGIE: Hierarchical and Multi-Grained Inconsistency Evaluation for Vision-Language Data Cleansing",
      "title_zh": "HMGIE：用于视觉-语言数据清洗的层次化和多粒度不一致性评估",
      "authors": [
        "Zihao Zhu",
        "Hongbao Zhang",
        "Guanzong Wu",
        "Siwei Lyu",
        "Baoyuan Wu"
      ],
      "abstract": "Visual-textual inconsistency (VTI) evaluation plays a crucial role in\ncleansing vision-language data. Its main challenges stem from the high variety\nof image captioning datasets, where differences in content can create a range\nof inconsistencies (\\eg, inconsistencies in scene, entities, entity attributes,\nentity numbers, entity interactions). Moreover, variations in caption length\ncan introduce inconsistencies at different levels of granularity as well. To\ntackle these challenges, we design an adaptive evaluation framework, called\nHierarchical and Multi-Grained Inconsistency Evaluation (HMGIE), which can\nprovide multi-grained evaluations covering both accuracy and completeness for\nvarious image-caption pairs. Specifically, the HMGIE framework is implemented\nby three consecutive modules. Firstly, the semantic graph generation module\nconverts the image caption to a semantic graph for building a structural\nrepresentation of all involved semantic items. Then, the hierarchical\ninconsistency evaluation module provides a progressive evaluation procedure\nwith a dynamic question-answer generation and evaluation strategy guided by the\nsemantic graph, producing a hierarchical inconsistency evaluation graph (HIEG).\nFinally, the quantitative evaluation module calculates the accuracy and\ncompleteness scores based on the HIEG, followed by a natural language\nexplanation about the detection results. Moreover, to verify the efficacy and\nflexibility of the proposed framework on handling different image captioning\ndatasets, we construct MVTID, an image-caption dataset with diverse types and\ngranularities of inconsistencies. Extensive experiments on MVTID and other\nbenchmark datasets demonstrate the superior performance of the proposed HMGIE\nto current state-of-the-art methods.",
      "tldr_zh": "本文提出 HMGIE 框架，用于评估视觉-文本不一致性 (VTI) 在清洗视觉语言数据中的作用，针对图像标题数据集的多样性和不同粒度不一致性（如场景、实体属性等）问题。HMGIE 通过语义图生成模块构建结构化表示、分层不一致性评估模块动态生成问答策略创建分层不一致性评估图 (HIEG)，以及定量评估模块计算准确性和完整性分数并提供解释，实现多粒度的全面评估。为验证其有效性，作者构建了 MVTID 数据集，并在多个基准数据集上实验表明，HMGIE 优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05685v1",
      "published_date": "2024-12-07 15:47:49 UTC",
      "updated_date": "2024-12-07 15:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:21:32.714860"
    },
    {
      "arxiv_id": "2412.05681v1",
      "title": "Leveraging Time-Series Foundation Model for Subsurface Well Logs Prediction and Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ardiansyah Koeshidayatullah",
        "Abdulrahman Al-Fakih",
        "SanLinn Ismael Kaka"
      ],
      "abstract": "The rise in energy demand highlights the importance of suitable subsurface\nstorage, requiring detailed and accurate subsurface characterization often\nreliant on high-quality borehole well log data. However, obtaining complete\nwell-log data is costly and time-consuming, with missing data being common due\nto borehole conditions or tool errors. While machine learning and deep learning\nalgorithms have been implemented to address these issues, they often fail to\ncapture the intricate, nonlinear relationships and long-term dependencies in\ncomplex well log sequences. Additionally, prior AI-driven models typically\nrequire retraining when introduced to new datasets and are constrained to\ndeployment in the same basin.\n  In this study, we explored and evaluated the potential of a time-series\nfoundation model leveraging transformer architecture and a generative\npre-trained approach for predicting and detecting anomalies in borehole well\nlog data. Specifically, we fine-tuned and adopted the TimeGPT architecture to\nforecast key log responses and detect anomalies with high accuracy. Our\nproposed model demonstrated excellent performance, achieving R2 of up to 87%\nand a mean absolute percentage error (MAPE) as low as 1.95%. Additionally, the\nmodel's zero-shot capability successfully identified subtle yet critical\nanomalies, such as drilling hazards or unexpected geological formations, with\nan overall accuracy of 93%.\n  The model represents a significant advancement in predictive accuracy and\ncomputational efficiency, enabling zero-shot inference through fine-tuning. Its\napplication in well-log prediction enhances operational decision-making while\nreducing risks associated with subsurface exploration. These findings\ndemonstrate the model's potential to transform well-log data analysis,\nparticularly in complex geological settings.",
      "tldr_zh": "本研究探讨了使用时间序列基础模型（TimeGPT）来预测地下井日志数据并检测异常，以解决数据缺失和高成本问题。研究团队通过微调基于Transformer架构的TimeGPT模型，捕捉井日志序列中的复杂非线性关系和长期依赖，实现高精度预测和异常识别。结果显示，该模型的R2值最高达87%，平均绝对百分比误差（MAPE）低至1.95%，并在零样本场景下以93%的准确率识别关键异常，如钻探风险或地质异常。该方法显著提升了预测准确性和计算效率，有助于优化地下勘探决策并降低风险。",
      "categories": [
        "physics.geo-ph",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05681v1",
      "published_date": "2024-12-07 15:23:52 UTC",
      "updated_date": "2024-12-07 15:23:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:21:41.314933"
    },
    {
      "arxiv_id": "2412.05674v1",
      "title": "No-Free-Lunch Theories for Tensor-Network Machine Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jing-Chuan Wu",
        "Qi Ye",
        "Dong-Ling Deng",
        "Li-Wei Yu"
      ],
      "abstract": "Tensor network machine learning models have shown remarkable versatility in\ntackling complex data-driven tasks, ranging from quantum many-body problems to\nclassical pattern recognitions. Despite their promising performance, a\ncomprehensive understanding of the underlying assumptions and limitations of\nthese models is still lacking. In this work, we focus on the rigorous\nformulation of their no-free-lunch theorem -- essential yet notoriously\nchallenging to formalize for specific tensor network machine learning models.\nIn particular, we rigorously analyze the generalization risks of learning\ntarget output functions from input data encoded in tensor network states. We\nfirst prove a no-free-lunch theorem for machine learning models based on matrix\nproduct states, i.e., the one-dimensional tensor network states. Furthermore,\nwe circumvent the challenging issue of calculating the partition function for\ntwo-dimensional Ising model, and prove the no-free-lunch theorem for the case\nof two-dimensional projected entangled-pair state, by introducing the\ncombinatorial method associated to the \"puzzle of polyominoes\". Our findings\nreveal the intrinsic limitations of tensor network-based learning models in a\nrigorous fashion, and open up an avenue for future analytical exploration of\nboth the strengths and limitations of quantum-inspired machine learning\nframeworks.",
      "tldr_zh": "本文探讨了张量网络机器学习模型的 No-Free-Lunch 定理，分析了这些模型在从输入数据编码的张量网络状态中学习目标输出函数时的泛化风险。作者首先证明了基于矩阵乘积 states 的 No-Free-Lunch 定理，并通过引入与“puzzle of polyominoes”相关的组合方法，绕过二维 Ising 模型分区函数计算的难题，证明了二维 projected entangled-pair state 的定理。这些发现揭示了张量网络学习模型的内在限制，并为量子启发机器学习框架的未来分析和应用开辟了新途径。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.DS",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "quant-ph",
      "comment": "7+23 pages, comments welcome",
      "pdf_url": "http://arxiv.org/pdf/2412.05674v1",
      "published_date": "2024-12-07 14:41:24 UTC",
      "updated_date": "2024-12-07 14:41:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:21:54.753847"
    },
    {
      "arxiv_id": "2412.05667v3",
      "title": "Training neural networks without backpropagation using particles",
      "title_zh": "使用粒子训练神经网络而不使用反向传播",
      "authors": [
        "Deepak Kumar"
      ],
      "abstract": "Neural networks are a group of neurons stacked together in multiple layers to\nmimic the biological neurons in a human brain. Neural networks have been\ntrained using the backpropagation algorithm based on gradient descent strategy\nfor several decades. Several variants have been developed to improve the\nbackpropagation algorithm. The loss function for the neural network is\noptimized through backpropagation, but several local minima exist in the\nmanifold of the constructed neural network. We obtain several solutions\nmatching the minima. The gradient descent strategy cannot avoid the problem of\nlocal minima and gets stuck in the minima due to the initialization. Particle\nswarm optimization (PSO) was proposed to select the best local minima among the\nsearch space of the loss function. The search space is limited to the\ninstantiated particles in the PSO algorithm, and sometimes it cannot select the\nbest solution. In the proposed approach, we overcome the problem of gradient\ndescent and the limitation of the PSO algorithm by training individual neurons\nseparately, capable of collectively solving the problem as a group of neurons\nforming a network. Our code and data are available at\nhttps://github.com/dipkmr/train-nn-wobp/",
      "tldr_zh": "该论文探讨了不使用反向传播算法训练神经网络的新方法，以解决梯度下降策略下存在的局部最小值问题。传统方法如粒子群优化 (PSO) 虽能选择最佳局部最小值，但受限于搜索空间和粒子实例化。作者提出一种创新方法，通过单独训练各个神经元，让它们作为一个群体协同工作，从而克服梯度下降和 PSO 的局限性。代码和数据已在 GitHub 上公开，可用于进一步验证该方法的有效性。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "15 pages, 8 figures, Added GitHub source code and corrected a few\n  sentences in Latex file, Added additional literature review to the paper",
      "pdf_url": "http://arxiv.org/pdf/2412.05667v3",
      "published_date": "2024-12-07 14:30:48 UTC",
      "updated_date": "2025-04-20 15:41:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:22:06.226749"
    },
    {
      "arxiv_id": "2412.05666v1",
      "title": "Early Diagnosis of Alzheimer's Diseases and Dementia from MRI Images Using an Ensemble Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mozhgan Naderi",
        "Maryam Rastgarpour",
        "Amir Reza Takhsha"
      ],
      "abstract": "Alzheimer's Disease (AD) is a progressive neurological disorder that can\nresult in significant cognitive impairment and dementia. Accurate and timely\ndiagnosis is essential for effective treatment and management of this disease.\nIn this study, we proposed two low-parameter Convolutional Neural Networks\n(CNNs), IR-BRAINNET and Modified-DEMNET, designed to detect the early stages of\nAD accurately. We also introduced an ensemble model that averages their outputs\nto reduce variance across the CNNs and enhance AD detection. Both CNNs are\ntrained, and all models are evaluated using a Magnetic Resonance Imaging (MRI)\ndataset from the Kaggle database. The dataset includes images of four stages of\ndementia, with an uneven class distribution. To mitigate challenges stemming\nfrom the inherent imbalance in the dataset, we employed the Synthetic Minority\nOver-sampling Technique (SMOTE) to generate additional instances for minority\nclasses. In the NO-SMOTE scenario, despite the imbalanced distribution, the\nensemble model achieved 98.28% accuracy, outperforming IR-BRAINNET (97.26%) and\nModified-DEMNET (95.54%), with Wilcoxon p-values of 2.9e-3 and 5.20e-6,\nrespectively, indicating significant improvement in correct predictions through\nthe use of the average function. In the SMOTE scenario, the ensemble model\nachieved 99.92% accuracy (1.64% improvement over NO-SMOTE), IR-BRAINNET reached\n99.80% (2.54% improvement), and Modified-DEMNET attained 99.72% (4.18%\nimprovement). Based on the experimental findings, averaging the models' outputs\nenhanced AD diagnosis in both scenarios, while the diversity in the dataset\nintroduced by SMOTE-generated instances significantly improved performance.\nFurthermore, the compact models we proposed outperformed those from previous\nstudies, even in the presence of an imbalanced distribution.",
      "tldr_zh": "这篇论文提出使用集成深度学习方法从 MRI 图像中早期诊断阿尔茨海默病 (AD) 和痴呆，设计了两个低参数 CNN 模型：IR-BRAINNET 和 Modified-DEMNET，并通过平均它们的输出构建集成模型以减少方差并提升检测准确率。针对 Kaggle 数据集中四阶段痴呆图像的不平衡分布，他们采用了 Synthetic Minority Over-sampling Technique (SMOTE) 来生成额外样本。实验结果显示，在 NO-SMOTE 场景下，集成模型准确率达 98.28%，显著优于 IR-BRAINNET (97.26%) 和 Modified-DEMNET (95.54%)；在 SMOTE 场景下，准确率进一步提升至 99.92%。总体而言，该方法证明了集成模型和 SMOTE 在处理不平衡数据时的有效性，并显示出比现有研究更好的性能。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05666v1",
      "published_date": "2024-12-07 14:27:41 UTC",
      "updated_date": "2024-12-07 14:27:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:22:21.074692"
    },
    {
      "arxiv_id": "2412.06841v1",
      "title": "The Helicobacter pylori AI-Clinician: Harnessing Artificial Intelligence to Personalize H. pylori Treatment Recommendations",
      "title_zh": "Helicobacter pylori AI-Clinician：利用人工智能个性化 H. pylori 治疗推荐",
      "authors": [
        "Kyle Higgins",
        "Olga P. Nyssen",
        "Joshua Southern",
        "Ivan Laponogov",
        "AIDA CONSORTIUM",
        "Dennis Veselkov",
        "Javier P. Gisbert",
        "Tania Fleitas Kanonnikoff",
        "Kirill Veselkov"
      ],
      "abstract": "Helicobacter pylori (H. pylori) is the most common carcinogenic pathogen\nworldwide. Infecting roughly 1 in 2 individuals globally, it is the leading\ncause of peptic ulcer disease, chronic gastritis, and gastric cancer. To\ninvestigate whether personalized treatments would be optimal for patients\nsuffering from infection, we developed the H. pylori AI-clinician\nrecommendation system. This system was trained on data from tens of thousands\nof H. pylori-infected patients from Hp-EuReg, orders of magnitude greater than\nthose experienced by a single real-world clinician. We first used a simulated\ndataset and demonstrated the ability of our AI Clinician method to identify\npatient subgroups that would benefit from differential optimal treatments.\nNext, we trained the AI Clinician on Hp-EuReg, demonstrating the AI Clinician\nreproduces known quality estimates of treatments, for example bismuth and\nquadruple therapies out-performing triple, with longer durations and higher\ndose proton pump inhibitor (PPI) showing higher quality estimation on average.\nNext we demonstrated that treatment was optimized by recommended personalized\ntherapies in patient subsets, where 65% of patients were recommended a bismuth\ntherapy of either metronidazole, tetracycline, and bismuth salts with PPI, or\nbismuth quadruple therapy with clarithromycin, amoxicillin, and bismuth salts\nwith PPI, and 15% of patients recommended a quadruple non-bismuth therapy of\nclarithromycin, amoxicillin, and metronidazole with PPI. Finally, we determined\ntrends in patient variables driving the personalized recommendations using\nrandom forest modelling. With around half of the world likely to experience H.\npylori infection at some point in their lives, the identification of\npersonalized optimal treatments will be crucial in both gastric cancer\nprevention and quality of life improvements for countless individuals\nworldwide.",
      "tldr_zh": "该研究开发了 H. pylori AI-Clinician 系统，利用人工智能分析 Hp-EuReg 大规模患者数据，为幽门螺杆菌(H. pylori)感染提供个性化治疗推荐。系统首先在模拟数据集上验证，能识别不同治疗受益的患者子群，并在真实数据中复现已知效果，如双氧铋(bismuth)和四联疗法优于三联疗法，且更长疗程和更高剂量 PPI 提升治疗质量。结果显示，65% 患者被推荐双氧铋疗法（如甲硝唑、四环素和双氧铋盐与 PPI），15% 推荐非双氧铋四联疗法，使用随机森林模型分析患者变量驱动因素。该系统有望通过个性化治疗预防胃癌并改善全球患者生活质量。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06841v1",
      "published_date": "2024-12-07 12:57:10 UTC",
      "updated_date": "2024-12-07 12:57:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:22:39.348472"
    },
    {
      "arxiv_id": "2412.05641v1",
      "title": "Hyperedge Anomaly Detection with Hypergraph Neural Network",
      "title_zh": "基于超图神经网络的超边异常检测",
      "authors": [
        "Md. Tanvir Alam",
        "Chowdhury Farhan Ahmed",
        "Carson K. Leung"
      ],
      "abstract": "Hypergraph is a data structure that enables us to model higher-order\nassociations among data entities. Conventional graph-structured data can\nrepresent pairwise relationships only, whereas hypergraph enables us to\nassociate any number of entities, which is essential in many real-life\napplications. Hypergraph learning algorithms have been well-studied for\nnumerous problem settings, such as node classification, link prediction, etc.\nHowever, much less research has been conducted on anomaly detection from\nhypergraphs. Anomaly detection identifies events that deviate from the usual\npattern and can be applied to hypergraphs to detect unusual higher-order\nassociations. In this work, we propose an end-to-end hypergraph neural\nnetwork-based model for identifying anomalous associations in a hypergraph. Our\nproposed algorithm operates in an unsupervised manner without requiring any\nlabeled data. Extensive experimentation on several real-life datasets\ndemonstrates the effectiveness of our model in detecting anomalous hyperedges.",
      "tldr_zh": "该研究探讨了超图（Hypergraph）作为一种数据结构的优势，能够建模数据实体之间的高阶关联，而非传统图仅限于成对关系。针对超图异常检测的不足，作者提出了一种端到端超图神经网络（Hypergraph Neural Network）模型，用于无监督识别异常超边（Hyperedge），无需任何标签数据。通过在多个真实数据集上的广泛实验，该模型证明了其在检测异常高阶关联方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05641v1",
      "published_date": "2024-12-07 12:52:22 UTC",
      "updated_date": "2024-12-07 12:52:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:24:39.199205"
    },
    {
      "arxiv_id": "2412.05632v1",
      "title": "Biological Brain Age Estimation using Sex-Aware Adversarial Variational Autoencoder with Multimodal Neuroimages",
      "title_zh": "翻译失败",
      "authors": [
        "Abd Ur Rehman",
        "Azka Rehman",
        "Muhammad Usman",
        "Abdullah Shahid",
        "Sung-Min Gho",
        "Aleum Lee",
        "Tariq M. Khan",
        "Imran Razzak"
      ],
      "abstract": "Brain aging involves structural and functional changes and therefore serves\nas a key biomarker for brain health. Combining structural magnetic resonance\nimaging (sMRI) and functional magnetic resonance imaging (fMRI) has the\npotential to improve brain age estimation by leveraging complementary data.\nHowever, fMRI data, being noisier than sMRI, complicates multimodal fusion.\nTraditional fusion methods often introduce more noise than useful information,\nwhich can reduce accuracy compared to using sMRI alone. In this paper, we\npropose a novel multimodal framework for biological brain age estimation,\nutilizing a sex-aware adversarial variational autoencoder (SA-AVAE). Our\nframework integrates adversarial and variational learning to effectively\ndisentangle the latent features from both modalities. Specifically, we\ndecompose the latent space into modality-specific codes and shared codes to\nrepresent complementary and common information across modalities, respectively.\nTo enhance the disentanglement, we introduce cross-reconstruction and\nshared-distinct distance ratio loss as regularization terms. Importantly, we\nincorporate sex information into the learned latent code, enabling the model to\ncapture sex-specific aging patterns for brain age estimation via an integrated\nregressor module. We evaluate our model using the publicly available OpenBHB\ndataset, a comprehensive multi-site dataset for brain age estimation. The\nresults from ablation studies and comparisons with state-of-the-art methods\ndemonstrate that our framework outperforms existing approaches and shows\nsignificant robustness across various age groups, highlighting its potential\nfor real-time clinical applications in the early detection of neurodegenerative\ndiseases.",
      "tldr_zh": "该研究提出了一种基于性别的对抗变分自编码器（SA-AVAE）框架，用于利用多模态神经图像（sMRI 和 fMRI）估计生物脑年龄。该框架通过对抗和变分学习分解潜在特征，将其分为模态特定代码和共享代码，并引入交叉重构损失和共享-独特距离比损失来增强特征分离，同时整合性别信息以捕获性别特定的衰老模式。实验在 OpenBHB 数据集上显示，该方法优于现有技术，提高了脑年龄估计的准确性和鲁棒性，尤其在不同年龄组中，具有潜力用于实时临床应用和早期检测神经退行性疾病。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05632v1",
      "published_date": "2024-12-07 12:10:29 UTC",
      "updated_date": "2024-12-07 12:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:23:00.434915"
    },
    {
      "arxiv_id": "2412.05631v1",
      "title": "CharacterBox: Evaluating the Role-Playing Capabilities of LLMs in Text-Based Virtual Worlds",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Wang",
        "Jianxun Lian",
        "Yi Huang",
        "Yanqi Dai",
        "Haoxuan Li",
        "Xu Chen",
        "Xing Xie",
        "Ji-Rong Wen"
      ],
      "abstract": "Role-playing is a crucial capability of Large Language Models (LLMs),\nenabling a wide range of practical applications, including intelligent\nnon-player characters, digital twins, and emotional companions. Evaluating this\ncapability in LLMs is challenging due to the complex dynamics involved in\nrole-playing, such as maintaining character fidelity throughout a storyline and\nnavigating open-ended narratives without a definitive ground truth. Current\nevaluation methods, which primarily focus on question-answering or\nconversational snapshots, fall short of adequately capturing the nuanced\ncharacter traits and behaviors essential for authentic role-playing. In this\npaper, we propose CharacterBox, which is a simulation sandbox designed to\ngenerate situational fine-grained character behavior trajectories. These\nbehavior trajectories enable a more comprehensive and in-depth evaluation of\nrole-playing capabilities. CharacterBox consists of two main components: the\ncharacter agent and the narrator agent. The character agent, grounded in\npsychological and behavioral science, exhibits human-like behaviors, while the\nnarrator agent coordinates interactions between character agents and\nenvironmental changes. Additionally, we introduce two trajectory-based methods\nthat leverage CharacterBox to enhance LLM performance. To reduce costs and\nfacilitate the adoption of CharacterBox by public communities, we fine-tune two\nsmaller models, CharacterNR and CharacterRM, as substitutes for GPT API calls,\nand demonstrate their competitive performance compared to advanced GPT APIs.",
      "tldr_zh": "这篇论文针对评估大型语言模型 (LLMs) 在文本虚拟世界中角色扮演能力的挑战，提出 CharacterBox 模拟沙盒，以生成细粒度的角色行为轨迹，实现更全面的评估。CharacterBox 包括 character agent（基于心理和行为科学模拟人类行为）和 narrator agent（协调角色互动及环境变化），帮助捕捉角色忠诚度和开放式叙事的复杂动态。论文还引入两种基于轨迹的方法提升 LLM 性能，并通过微调较小模型如 CharacterNR 和 CharacterRM，作为 GPT API 的替代方案，展示了与高级 GPT API 相当的竞争性表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05631v1",
      "published_date": "2024-12-07 12:09:35 UTC",
      "updated_date": "2024-12-07 12:09:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:25:14.638942"
    },
    {
      "arxiv_id": "2412.05628v1",
      "title": "Remix-DiT: Mixing Diffusion Transformers for Multi-Expert Denoising",
      "title_zh": "翻译失败",
      "authors": [
        "Gongfan Fang",
        "Xinyin Ma",
        "Xinchao Wang"
      ],
      "abstract": "Transformer-based diffusion models have achieved significant advancements\nacross a variety of generative tasks. However, producing high-quality outputs\ntypically necessitates large transformer models, which result in substantial\ntraining and inference overhead. In this work, we investigate an alternative\napproach involving multiple experts for denoising, and introduce Remix-DiT, a\nnovel method designed to enhance output quality at a low cost. The goal of\nRemix-DiT is to craft N diffusion experts for different denoising timesteps,\nyet without the need for expensive training of N independent models. To achieve\nthis, Remix-DiT employs K basis models (where K < N) and utilizes learnable\nmixing coefficients to adaptively craft expert models. This design offers two\nsignificant advantages: first, although the total model size is increased, the\nmodel produced by the mixing operation shares the same architecture as a plain\nmodel, making the overall model as efficient as a standard diffusion\ntransformer. Second, the learnable mixing adaptively allocates model capacity\nacross timesteps, thereby effectively improving generation quality. Experiments\nconducted on the ImageNet dataset demonstrate that Remix-DiT achieves promising\nresults compared to standard diffusion transformers and other multiple-expert\nmethods. The code is available at https://github.com/VainF/Remix-DiT.",
      "tldr_zh": "本研究针对Transformer-based diffusion models在生成任务中存在的训练和推理开销问题，提出Remix-DiT方法，通过混合多个experts来提升去噪（denoising）性能，同时降低成本。Remix-DiT为不同denoising timesteps设计N个experts，仅需训练K个basis models（K < N），并使用可学习的mixing coefficients自适应地创建experts模型，从而优化模型容量分配。相比标准diffusion transformers，该方法保持了相同的架构效率，同时在ImageNet数据集的实验中实现了更好的生成质量和性能提升。代码已开源于https://github.com/VainF/Remix-DiT。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05628v1",
      "published_date": "2024-12-07 11:52:41 UTC",
      "updated_date": "2024-12-07 11:52:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:25:16.768811"
    },
    {
      "arxiv_id": "2412.05594v1",
      "title": "Real-Time 3D Object Detection Using InnovizOne LiDAR and Low-Power Hailo-8 AI Accelerator",
      "title_zh": "使用 InnovizOne LiDAR 和低功耗 Hailo-8 AI 加速器的实时 3D 对象检测",
      "authors": [
        "Itay Krispin-Avraham",
        "Roy Orfaig",
        "Ben-Zion Bobrovsky"
      ],
      "abstract": "Object detection is a significant field in autonomous driving. Popular\nsensors for this task include cameras and LiDAR sensors. LiDAR sensors offer\nseveral advantages, such as insensitivity to light changes, like in a dark\nsetting and the ability to provide 3D information in the form of point clouds,\nwhich include the ranges of objects. However, 3D detection methods, such as\nPointPillars, typically require high-power hardware. Additionally, most common\nspinning LiDARs are sparse and may not achieve the desired quality of object\ndetection in front of the car. In this paper, we present the feasibility of\nperforming real-time 3D object detection of cars using 3D point clouds from a\nLiDAR sensor, processed and deployed on a low-power Hailo-8 AI accelerator. The\nLiDAR sensor used in this study is the InnovizOne sensor, which captures\nobjects in higher quality compared to spinning LiDAR techniques, especially for\ndistant objects. We successfully achieved real-time inference at a rate of\napproximately 5Hz with a high accuracy of 0.91% F1 score, with only -0.2%\ndegradation compared to running the same model on an NVIDIA GeForce RTX 2080\nTi. This work demonstrates that effective real-time 3D object detection can be\nachieved on low-cost, low-power hardware, representing a significant step\ntowards more accessible autonomous driving technologies. The source code and\nthe pre-trained models are available at https://github.com/AIROTAU/\nPointPillarsHailoInnoviz/tree/main",
      "tldr_zh": "本研究探讨了使用 InnovizOne LiDAR 传感器和低功率 Hailo-8 AI 加速器进行实时 3D 对象检测的可行性，针对自动驾驶中的点云数据处理问题。方法基于 PointPillars 模型，通过高品质 LiDAR 数据克服了传统稀疏 LiDAR 的局限性，并在低功率硬件上实现了约 5Hz 的实时推理。结果显示，检测准确率达到 0.91% F1 score，与高功率 NVIDIA GeForce RTX 2080 Ti 相比仅下降 0.2%。这项工作证明了低成本硬件在 3D 对象检测中的潜力，有助于推动更易获取的自动驾驶技术的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05594v1",
      "published_date": "2024-12-07 09:19:55 UTC",
      "updated_date": "2024-12-07 09:19:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:23:36.336939"
    },
    {
      "arxiv_id": "2412.05592v1",
      "title": "From Flexibility to Manipulation: The Slippery Slope of XAI Evaluation",
      "title_zh": "从灵活性到操纵：XAI 评估的滑坡效应",
      "authors": [
        "Kristoffer Wickstrøm",
        "Marina Marie-Claire Höhne",
        "Anna Hedström"
      ],
      "abstract": "The lack of ground truth explanation labels is a fundamental challenge for\nquantitative evaluation in explainable artificial intelligence (XAI). This\nchallenge becomes especially problematic when evaluation methods have numerous\nhyperparameters that must be specified by the user, as there is no ground truth\nto determine an optimal hyperparameter selection. It is typically not feasible\nto do an exhaustive search of hyperparameters so researchers typically make a\nnormative choice based on similar studies in the literature, which provides\ngreat flexibility for the user. In this work, we illustrate how this\nflexibility can be exploited to manipulate the evaluation outcome. We frame\nthis manipulation as an adversarial attack on the evaluation where seemingly\ninnocent changes in hyperparameter setting significantly influence the\nevaluation outcome. We demonstrate the effectiveness of our manipulation across\nseveral datasets with large changes in evaluation outcomes across several\nexplanation methods and models. Lastly, we propose a mitigation strategy based\non ranking across hyperparameters that aims to provide robustness towards such\nmanipulation. This work highlights the difficulty of conducting reliable XAI\nevaluation and emphasizes the importance of a holistic and transparent approach\nto evaluation in XAI.",
      "tldr_zh": "本文研究了可解释人工智能(XAI)评估中的关键问题：缺乏ground truth explanation labels导致评估方法hyperparameters的选择高度灵活，但易被操纵。该研究将这种操纵视为一种adversarial attack，通过实验在多个数据集上证明，微调hyperparameters能显著改变评估结果，从而影响不同解释方法和模型的表现。为缓解此问题，作者提出了一种基于hyperparameters排名的策略，以提升评估的鲁棒性。该工作强调了XAI评估的可靠性挑战，并呼吁采用更全面、透明的评估方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in ECCV 2024 Workshop on Explainable Computer Vision: Where\n  are We and Where are We Going? Shorter non-archival version also appeared in\n  the NeurIPS 2024 Interpretable AI workshop. Code is available at\n  \\url{https://github.com/Wickstrom/quantitative-xai-manipulation}",
      "pdf_url": "http://arxiv.org/pdf/2412.05592v1",
      "published_date": "2024-12-07 09:14:46 UTC",
      "updated_date": "2024-12-07 09:14:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:23:46.368035"
    },
    {
      "arxiv_id": "2412.05591v1",
      "title": "BERTCaps: BERT Capsule for Persian Multi-Domain Sentiment Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammadali Memari",
        "Soghra Mikaeyl Nejad",
        "Amir Parsa Rabiei",
        "Mehrshad Eisaei",
        "Saba Hesaraki"
      ],
      "abstract": "Multidomain sentiment analysis involves estimating the polarity of an\nunstructured text by exploiting domain specific information. One of the main\nissues common to the approaches discussed in the literature is their poor\napplicability to domains that differ from those used to construct opinion\nmodels.This paper aims to present a new method for Persian multidomain SA\nanalysis using deep learning approaches. The proposed BERTCapsules approach\nconsists of a combination of BERT and Capsule models. In this approach, BERT\nwas used for Instance representation, and Capsule Structure was used to learn\nthe extracted graphs. Digikala dataset, including ten domains with both\npositive and negative polarity, was used to evaluate this approach. The\nevaluation of the BERTCaps model achieved an accuracy of 0.9712 in sentiment\nclassification binary classification and 0.8509 in domain classification .",
      "tldr_zh": "这篇论文提出了BERTCaps方法，一种结合BERT和Capsule模型的深度学习框架，用于波斯语的多领域情感分析，以解决现有模型在不同领域适配性差的问题。BERT用于实例表示，而Capsule结构则负责学习提取的图，从而提升情感极性的准确识别。实验在Digikala数据集上评估，结果显示情感二元分类的准确率达到0.9712，领域分类的准确率达到0.8509。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05591v1",
      "published_date": "2024-12-07 09:08:25 UTC",
      "updated_date": "2024-12-07 09:08:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:24:01.673197"
    },
    {
      "arxiv_id": "2412.05587v2",
      "title": "GEE-OPs: An Operator Knowledge Base for Geospatial Code Generation on the Google Earth Engine Platform Powered by Large Language Models",
      "title_zh": "GEE-OPs：",
      "authors": [
        "Shuyang Hou",
        "Jianyuan Liang",
        "Anqi Zhao",
        "Huayi Wu"
      ],
      "abstract": "As the scale and complexity of spatiotemporal data continue to grow rapidly,\nthe use of geospatial modeling on the Google Earth Engine (GEE) platform\npresents dual challenges: improving the coding efficiency of domain experts and\nenhancing the coding capabilities of interdisciplinary users. To address these\nchallenges and improve the performance of large language models (LLMs) in\ngeospatial code generation tasks, we propose a framework for building a\ngeospatial operator knowledge base tailored to the GEE JavaScript API. This\nframework consists of an operator syntax knowledge table, an operator\nrelationship frequency table, an operator frequent pattern knowledge table, and\nan operator relationship chain knowledge table. By leveraging Abstract Syntax\nTree (AST) techniques and frequent itemset mining, we systematically extract\noperator knowledge from 185,236 real GEE scripts and syntax documentation,\nforming a structured knowledge base. Experimental results demonstrate that the\nframework achieves over 90% accuracy, recall, and F1 score in operator\nknowledge extraction. When integrated with the Retrieval-Augmented Generation\n(RAG) strategy for LLM-based geospatial code generation tasks, the knowledge\nbase improves performance by 20-30%. Ablation studies further quantify the\nnecessity of each knowledge table in the knowledge base construction. This work\nprovides robust support for the advancement and application of geospatial code\nmodeling techniques, offering an innovative approach to constructing\ndomain-specific knowledge bases that enhance the code generation capabilities\nof LLMs, and fostering the deeper integration of generative AI technologies\nwithin the field of geoinformatics.",
      "tldr_zh": "该论文提出 GEE-OPs 框架，用于构建一个针对 Google Earth Engine (GEE) 平台的地理空间操作符知识库，以提升大型语言模型 (LLMs) 在代码生成任务中的性能。该框架包括 operator syntax knowledge table、operator relationship frequency table、operator frequent pattern knowledge table 和 operator relationship chain knowledge table，通过 Abstract Syntax Tree (AST) 技术和 frequent itemset mining 从 185,236 个真实 GEE 脚本中系统提取知识。实验结果显示，知识提取的准确率、召回率和 F1 分数均超过 90%，并在结合 Retrieval-Augmented Generation (RAG) 策略后，提高地理空间代码生成性能 20-30%。这项工作为地理空间代码建模提供创新支持，促进生成 AI 在地理信息学领域的深度整合。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05587v2",
      "published_date": "2024-12-07 08:50:24 UTC",
      "updated_date": "2024-12-11 13:56:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:26:04.621109"
    },
    {
      "arxiv_id": "2412.05586v1",
      "title": "Towards Learning to Reason: Comparing LLMs with Neuro-Symbolic on Arithmetic Relations in Abstract Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Hersche",
        "Giacomo Camposampiero",
        "Roger Wattenhofer",
        "Abu Sebastian",
        "Abbas Rahimi"
      ],
      "abstract": "This work compares large language models (LLMs) and neuro-symbolic approaches\nin solving Raven's progressive matrices (RPM), a visual abstract reasoning test\nthat involves the understanding of mathematical rules such as progression or\narithmetic addition. Providing the visual attributes directly as textual\nprompts, which assumes an oracle visual perception module, allows us to measure\nthe model's abstract reasoning capability in isolation. Despite providing such\ncompositionally structured representations from the oracle visual perception\nand advanced prompting techniques, both GPT-4 and Llama-3 70B cannot achieve\nperfect accuracy on the center constellation of the I-RAVEN dataset. Our\nanalysis reveals that the root cause lies in the LLM's weakness in\nunderstanding and executing arithmetic rules. As a potential remedy, we analyze\nthe Abductive Rule Learner with Context-awareness (ARLC), a neuro-symbolic\napproach that learns to reason with vector-symbolic architectures (VSAs). Here,\nconcepts are represented with distributed vectors s.t. dot products between\nencoded vectors define a similarity kernel, and simple element-wise operations\non the vectors perform addition/subtraction on the encoded values. We find that\nARLC achieves almost perfect accuracy on the center constellation of I-RAVEN,\ndemonstrating a high fidelity in arithmetic rules. To stress the length\ngeneralization capabilities of the models, we extend the RPM tests to larger\nmatrices (3x10 instead of typical 3x3) and larger dynamic ranges of the\nattribute values (from 10 up to 1000). We find that the LLM's accuracy of\nsolving arithmetic rules drops to sub-10%, especially as the dynamic range\nexpands, while ARLC can maintain a high accuracy due to emulating symbolic\ncomputations on top of properly distributed representations. Our code is\navailable at https://github.com/IBM/raven-large-language-models.",
      "tldr_zh": "这篇论文比较了大型语言模型（LLMs，如 GPT-4 和 Llama-3 70B）与神经符号方法在抽象推理任务 Raven's progressive matrices (RPM) 中的性能，焦点在于理解算术关系。研究发现，尽管使用文本提示和高级提示技术，LLMs 在 I-RAVEN 数据集的中心星座上无法达到完美准确率，主要由于其在执行算术规则方面的弱点。相比之下，Abductive Rule Learner with Context-awareness (ARLC) 采用 vector-symbolic architectures (VSAs) 来表示概念和进行运算，实现了几乎完美的准确率。进一步测试显示，在更大矩阵（如 3x10）和更大动态范围（值从 10 到 1000）的条件下，LLMs 的准确率降至不足 10%，而 ARLC 通过模拟符号计算保持了高准确率，突显了其在抽象推理中的优势。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05586v1",
      "published_date": "2024-12-07 08:45:39 UTC",
      "updated_date": "2024-12-07 08:45:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:24:27.433543"
    },
    {
      "arxiv_id": "2412.05585v1",
      "title": "UNet++ and LSTM combined approach for Breast Ultrasound Image Segmentation",
      "title_zh": "UNet++ 与 LSTM 相结合的乳腺超",
      "authors": [
        "Saba Hesaraki",
        "Morteza Akbari",
        "Ramin Mousa"
      ],
      "abstract": "Breast cancer stands as a prevalent cause of fatality among females on a\nglobal scale, with prompt detection playing a pivotal role in diminishing\nmortality rates. The utilization of ultrasound scans in the BUSI dataset for\nmedical imagery pertaining to breast cancer has exhibited commendable\nsegmentation outcomes through the application of UNet and UNet++ networks.\nNevertheless, a notable drawback of these models resides in their inattention\ntowards the temporal aspects embedded within the images. This research\nendeavors to enrich the UNet++ architecture by integrating LSTM layers and\nself-attention mechanisms to exploit temporal characteristics for segmentation\npurposes. Furthermore, the incorporation of a Multiscale Feature Extraction\nModule aims to grasp varied scale features within the UNet++. Through the\namalgamation of our proposed methodology with data augmentation on the BUSI\nwith GT dataset, an accuracy rate of 98.88%, specificity of 99.53%, precision\nof 95.34%, sensitivity of 91.20%, F1-score of 93.74, and Dice coefficient of\n92.74% are achieved. These findings demonstrate competitiveness with\ncutting-edge techniques outlined in existing literature.",
      "tldr_zh": "本研究针对乳腺癌检测中的乳腺超声图像分割问题，提出了一种结合 UNet++ 和 LSTM 的方法，以解决传统模型忽略图像时序特性的局限。方法通过在 UNet++ 架构中整合 LSTM 层、自注意力机制以及多尺度特征提取模块，利用时序信息和多尺度特征来提升分割性能，并在 BUSI 数据集上应用数据增强技术。实验结果显示，该方法实现了98.88%的准确率、99.53%的特异性、95.34%的精确度、91.20%的敏感性、93.74%的F1-score 和92.74%的Dice 系数，与现有先进技术相比具有竞争力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05585v1",
      "published_date": "2024-12-07 08:39:31 UTC",
      "updated_date": "2024-12-07 08:39:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:26:19.619134"
    },
    {
      "arxiv_id": "2412.05584v2",
      "title": "UMSPU: Universal Multi-Size Phase Unwrapping via Mutual Self-Distillation and Adaptive Boosting Ensemble Segmenters",
      "title_zh": "翻译失败",
      "authors": [
        "Lintong Du",
        "Huazhen Liu",
        "Yijia Zhang",
        "ShuXin Liu",
        "Yuan Qu",
        "Zenghui Zhang",
        "Jiamiao Yang"
      ],
      "abstract": "Spatial phase unwrapping is a key technique for extracting phase information\nto obtain 3D morphology and other features. Modern industrial measurement\nscenarios demand high precision, large image sizes, and high speed. However,\nconventional methods struggle with noise resistance and processing speed.\nCurrent deep learning methods are limited by the receptive field size and\nsparse semantic information, making them ineffective for large size images. To\naddress this issue, we propose a mutual self-distillation (MSD) mechanism and\nadaptive boosting ensemble segmenters to construct a universal multi-size phase\nunwrapping network (UMSPU). MSD performs hierarchical attention refinement and\nachieves cross-layer collaborative learning through bidirectional distillation,\nensuring fine-grained semantic representation across image sizes. The adaptive\nboosting ensemble segmenters combine weak segmenters with different receptive\nfields into a strong one, ensuring stable segmentation across spatial\nfrequencies. Experimental results show that UMSPU overcomes image size\nlimitations, achieving high precision across image sizes ranging from 256*256\nto 2048*2048 (an 8 times increase). It also outperforms existing methods in\nspeed, robustness, and generalization. Its practicality is further validated in\nstructured light imaging and InSAR. We believe that UMSPU offers a universal\nsolution for phase unwrapping, with broad potential for industrial\napplications.",
      "tldr_zh": "本研究针对空间相位展开技术在处理大尺寸图像时面临的噪声抵抗和速度问题，提出了一种通用多尺寸相位展开网络 UMSPU，利用 mutual self-distillation (MSD) 机制和 adaptive boosting ensemble segmenters 进行优化。MSD 通过层次化注意力精炼和双向蒸馏实现跨层协作学习，确保不同图像尺寸的细粒度语义表示，而 adaptive boosting ensemble segmenters 将不同感受野的弱分割器组合成强分割器，以实现稳定空间频率分割。实验结果表明，UMSPU 在 256*256 到 2048*2048 的图像上实现了高精度（8 倍尺寸增加），并在速度、鲁棒性和泛化能力上超越现有方法。该框架已在结构光成像和 InSAR 等工业应用中验证其实用性，提供了一个通用的相位展开解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05584v2",
      "published_date": "2024-12-07 08:38:29 UTC",
      "updated_date": "2025-04-17 03:41:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:26:34.293819"
    },
    {
      "arxiv_id": "2412.05583v2",
      "title": "Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and Classification using Machine Learning Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Atit Pokharel",
        "Shashank Dahal",
        "Pratik Sapkota",
        "Bhupendra Bimal Chhetri"
      ],
      "abstract": "The rapid advancements in Artificial Intelligence, specifically Machine\nLearning (ML) and Deep Learning (DL), have opened new prospects in medical\nsciences for improved diagnosis, prognosis, and treatment of severe health\nconditions. This paper focuses on the development of an ML model with high\npredictive accuracy to classify arrhythmic electrocardiogram (ECG) signals. The\nECG signals datasets utilized in this study were sourced from the PhysioNet and\nMIT-BIH databases. The research commenced with binary classification, where an\noptimized Bidirectional Long Short-Term Memory (Bi-LSTM) model yielded\nexcellent results in differentiating normal and atrial fibrillation signals. A\npivotal aspect of this research was a survey among medical professionals, which\nnot only validated the practicality of AI-based ECG classifiers but also\nidentified areas for improvement, including accuracy and the inclusion of more\narrhythmia types. These insights drove the development of an advanced\nConvolutional Neural Network (CNN) system capable of classifying five different\ntypes of ECG signals with better accuracy and precision. The CNN model's robust\nperformance was ensured through rigorous stratified 5-fold cross validation. A\nweb portal was also developed to demonstrate real-world utility, offering\naccess to the trained model for real-time classification. This study highlights\nthe potential applications of such models in remote health monitoring,\npredictive healthcare, assistive diagnostic tools, and simulated environments\nfor educational training and interdisciplinary collaboration between data\nscientists and medical personnel.",
      "tldr_zh": "本文利用 Machine Learning (ML) 和 Deep Learning (DL) 算法，开发高准确率的模型来检测和分类心律失常的 Electrocardiogram (ECG) 信号，使用 PhysioNet 和 MIT-BIH 数据库作为数据来源。研究首先通过优化的 Bidirectional Long Short-Term Memory (Bi-LSTM) 模型实现了二元分类（如正常与心房颤动信号），并基于医疗专业人员调查反馈，推进到 Convolutional Neural Network (CNN) 系统以分类五种不同 ECG 类型。模型通过严格的 stratified 5-fold cross validation 验证，表现出色，并开发了一个 web 门户支持实时分类。该研究突出了模型在远程健康监测、预测性医疗和辅助诊断工具中的潜在应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05583v2",
      "published_date": "2024-12-07 08:29:44 UTC",
      "updated_date": "2024-12-10 15:35:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:26:45.746346"
    },
    {
      "arxiv_id": "2412.05573v1",
      "title": "Neighborhood Commonality-aware Evolution Network for Continuous Generalized Category Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Wang",
        "Yaxiong Wang",
        "Guoshuai Zhao",
        "Xueming Qian"
      ],
      "abstract": "Continuous Generalized Category Discovery (C-GCD) aims to continually\ndiscover novel classes from unlabelled image sets while maintaining performance\non old classes. In this paper, we propose a novel learning framework, dubbed\nNeighborhood Commonality-aware Evolution Network (NCENet) that conquers this\ntask from the perspective of representation learning. Concretely, to learn\ndiscriminative representations for novel classes, a Neighborhood\nCommonality-aware Representation Learning (NCRL) is designed, which exploits\nlocal commonalities derived neighborhoods to guide the learning of\nrepresentational differences between instances of different classes. To\nmaintain the representation ability for old classes, a Bi-level Contrastive\nKnowledge Distillation (BCKD) module is designed, which leverages contrastive\nlearning to perceive the learning and learned knowledge and conducts knowledge\ndistillation. Extensive experiments conducted on CIFAR10, CIFAR100, and\nTiny-ImageNet demonstrate the superior performance of NCENet compared to the\nprevious state-of-the-art method. Particularly, in the last incremental\nlearning session on CIFAR100, the clustering accuracy of NCENet outperforms the\nsecond-best method by a margin of 3.09\\% on old classes and by a margin of\n6.32\\% on new classes. Our code will be publicly available at\n\\href{https://github.com/xjtuYW/NCENet.git}{https://github.com/xjtuYW/NCENet.git}.\n\\end{abstract}",
      "tldr_zh": "本文提出了一种名为 Neighborhood Commonality-aware Evolution Network (NCENet) 的框架，用于处理 Continuous Generalized Category Discovery (C-GCD)，即持续从无标签图像中发现新类别，同时保持旧类别的性能。NCENet 包括 Neighborhood Commonality-aware Representation Learning (NCRL) 模块，利用邻域的局部共同性来指导不同类别实例的区分性表示学习，以及 Bi-level Contrastive Knowledge Distillation (BCKD) 模块，通过对比学习进行知识蒸馏以维护旧类别表示能力。在 CIFAR10、CIFAR100 和 Tiny-ImageNet 数据集上的实验显示，NCENet 显著优于现有最佳方法，尤其在 CIFAR100 的最后一个增量学习阶段，其聚类准确率在新类别上领先 6.32%，在旧类别上领先 3.09%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 7 Figures",
      "pdf_url": "http://arxiv.org/pdf/2412.05573v1",
      "published_date": "2024-12-07 07:41:41 UTC",
      "updated_date": "2024-12-07 07:41:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:26:57.055230"
    },
    {
      "arxiv_id": "2501.01960v1",
      "title": "GAF-FusionNet: Multimodal ECG Analysis via Gramian Angular Fields and Split Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Qin",
        "Feng Liu"
      ],
      "abstract": "Electrocardiogram (ECG) analysis plays a crucial role in diagnosing\ncardiovascular diseases, but accurate interpretation of these complex signals\nremains challenging. This paper introduces a novel multimodal\nframework(GAF-FusionNet) for ECG classification that integrates time-series\nanalysis with image-based representation using Gramian Angular Fields (GAF).\nOur approach employs a dual-layer cross-channel split attention module to\nadaptively fuse temporal and spatial features, enabling nuanced integration of\ncomplementary information. We evaluate GAF-FusionNet on three diverse ECG\ndatasets: ECG200, ECG5000, and the MIT-BIH Arrhythmia Database. Results\ndemonstrate significant improvements over state-of-the-art methods, with our\nmodel achieving 94.5\\%, 96.9\\%, and 99.6\\% accuracy on the respective datasets.\nOur code will soon be available at\nhttps://github.com/Cross-Innovation-Lab/GAF-FusionNet.git.",
      "tldr_zh": "本论文提出了一种名为 GAF-FusionNet 的多模态框架，用于 ECG 分类，通过整合时间序列分析和基于 Gramian Angular Fields (GAF) 的图像表示来提升诊断准确性。该框架采用双层跨通道 split attention 模块，适应性地融合时间和空间特征，从而实现对复杂 ECG 信号的细致解读。在 ECG200、ECG5000 和 MIT-BIH Arrhythmia Database 等数据集上的实验显示，GAF-FusionNet 分别实现了 94.5%、96.9% 和 99.6% 的准确率，显著优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 1 figure, accepted by ICONIP 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.01960v1",
      "published_date": "2024-12-07 07:02:16 UTC",
      "updated_date": "2024-12-07 07:02:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:27:07.436742"
    },
    {
      "arxiv_id": "2412.05563v1",
      "title": "A Survey on Uncertainty Quantification of Large Language Models: Taxonomy, Open Research Challenges, and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Ola Shorinwa",
        "Zhiting Mei",
        "Justin Lidard",
        "Allen Z. Ren",
        "Anirudha Majumdar"
      ],
      "abstract": "The remarkable performance of large language models (LLMs) in content\ngeneration, coding, and common-sense reasoning has spurred widespread\nintegration into many facets of society. However, integration of LLMs raises\nvalid questions on their reliability and trustworthiness, given their\npropensity to generate hallucinations: plausible, factually-incorrect\nresponses, which are expressed with striking confidence. Previous work has\nshown that hallucinations and other non-factual responses generated by LLMs can\nbe detected by examining the uncertainty of the LLM in its response to the\npertinent prompt, driving significant research efforts devoted to quantifying\nthe uncertainty of LLMs. This survey seeks to provide an extensive review of\nexisting uncertainty quantification methods for LLMs, identifying their salient\nfeatures, along with their strengths and weaknesses. We present existing\nmethods within a relevant taxonomy, unifying ostensibly disparate methods to\naid understanding of the state of the art. Furthermore, we highlight\napplications of uncertainty quantification methods for LLMs, spanning chatbot\nand textual applications to embodied artificial intelligence applications in\nrobotics. We conclude with open research challenges in uncertainty\nquantification of LLMs, seeking to motivate future research.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型 (LLMs) 的不确定性量化 (Uncertainty Quantification)，旨在解决 LLMs 在生成内容、编码和常识推理中可能产生的幻觉问题。论文通过一个分类学 (Taxonomy) 统一回顾了现有不确定性量化方法，包括它们的显著特征、优势和弱点，并分析了这些方法在聊天机器人、文本应用和机器人学等领域的应用。最终，论文指出了当前研究的开放挑战和未来方向，以推动 LLMs 的可靠性和可信度。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05563v1",
      "published_date": "2024-12-07 06:56:01 UTC",
      "updated_date": "2024-12-07 06:56:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:27:22.072834"
    },
    {
      "arxiv_id": "2412.05562v1",
      "title": "On the Expressive Power of Modern Hopfield Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Li",
        "Yuanpeng Li",
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song"
      ],
      "abstract": "Modern Hopfield networks (MHNs) have emerged as powerful tools in deep\nlearning, capable of replacing components such as pooling layers, LSTMs, and\nattention mechanisms. Recent advancements have enhanced their storage capacity,\nretrieval speed, and error rates. However, the fundamental limits of their\ncomputational expressiveness remain unexplored. Understanding the expressive\npower of MHNs is crucial for optimizing their integration into deep learning\narchitectures. In this work, we establish rigorous theoretical bounds on the\ncomputational capabilities of MHNs using circuit complexity theory. Our key\ncontribution is that we show that MHNs are $\\mathsf{DLOGTIME}$-uniform\n$\\mathsf{TC}^0$. Hence, unless $\\mathsf{TC}^0 = \\mathsf{NC}^1$, a\n$\\mathrm{poly}(n)$-precision modern Hopfield networks with a constant number of\nlayers and $O(n)$ hidden dimension cannot solve $\\mathsf{NC}^1$-hard problems\nsuch as the undirected graph connectivity problem and the tree isomorphism\nproblem. We also extended our results to Kernelized Hopfield Networks. These\nresults demonstrate the limitation in the expressive power of the modern\nHopfield networks. Moreover, Our theoretical analysis provides insights to\nguide the development of new Hopfield-based architectures.",
      "tldr_zh": "本研究探讨了现代 Hopfield 网络 (MHNs) 的计算表达能力，通过电路复杂性理论建立了其严格理论界限。研究证明，MHNs 是 $\\mathsf{DLOGTIME}$-uniform $\\mathsf{TC}^0$，因此，除非 $\\mathsf{TC}^0 = \\mathsf{NC}^1$，否则一个具有常数层和 $O(n)$ 隐藏维度的 poly(n)-precision MHNs 无法解决 $\\mathsf{NC}^1$-hard 问题，如无向图连通性和树同构问题。这些结果扩展到 Kernelized Hopfield Networks，并揭示了 MHNs 的表达能力限制，同时为开发新 Hopfield-based 架构提供指导。",
      "categories": [
        "cs.CC",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05562v1",
      "published_date": "2024-12-07 06:52:41 UTC",
      "updated_date": "2024-12-07 06:52:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:27:35.160599"
    },
    {
      "arxiv_id": "2412.05560v1",
      "title": "Text-to-3D Gaussian Splatting with Physics-Grounded Motion Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqing Wang",
        "Yun Fu"
      ],
      "abstract": "Text-to-3D generation is a valuable technology in virtual reality and digital\ncontent creation. While recent works have pushed the boundaries of text-to-3D\ngeneration, producing high-fidelity 3D objects with inefficient prompts and\nsimulating their physics-grounded motion accurately still remain unsolved\nchallenges. To address these challenges, we present an innovative framework\nthat utilizes the Large Language Model (LLM)-refined prompts and diffusion\npriors-guided Gaussian Splatting (GS) for generating 3D models with accurate\nappearances and geometric structures. We also incorporate a continuum\nmechanics-based deformation map and color regularization to synthesize vivid\nphysics-grounded motion for the generated 3D Gaussians, adhering to the\nconservation of mass and momentum. By integrating text-to-3D generation with\nphysics-grounded motion synthesis, our framework renders photo-realistic 3D\nobjects that exhibit physics-aware motion, accurately reflecting the behaviors\nof the objects under various forces and constraints across different materials.\nExtensive experiments demonstrate that our approach achieves high-quality 3D\ngenerations with realistic physics-grounded motion.",
      "tldr_zh": "该研究提出了一种创新框架，用于解决文本到3D生成中的高效提示和物理基础运动模拟挑战。该框架利用 Large Language Model (LLM) 精炼的提示和 diffusion priors-guided Gaussian Splatting (GS) 方法，生成高保真度的3D模型，包括准确的外观和几何结构。同时，通过整合 continuum mechanics-based deformation map 和 color regularization，确保生成的3D高斯模型遵守质量和动量守恒，合成生动的 physics-grounded 运动。实验结果显示，该方法在不同材料下实现了 photo-realistic 3D对象生成，并准确反映了各种力和约束下的物理行为。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05560v1",
      "published_date": "2024-12-07 06:48:16 UTC",
      "updated_date": "2024-12-07 06:48:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:27:43.662685"
    },
    {
      "arxiv_id": "2412.05558v1",
      "title": "WavFusion: Towards wav2vec 2.0 Multimodal Speech Emotion Recognition",
      "title_zh": "WavFusion: 面向 wav2vec 2.0 的",
      "authors": [
        "Feng Li",
        "Jiusong Luo",
        "Wanjun Xia"
      ],
      "abstract": "Speech emotion recognition (SER) remains a challenging yet crucial task due\nto the inherent complexity and diversity of human emotions. To address this\nproblem, researchers attempt to fuse information from other modalities via\nmultimodal learning. However, existing multimodal fusion techniques often\noverlook the intricacies of cross-modal interactions, resulting in suboptimal\nfeature representations. In this paper, we propose WavFusion, a multimodal\nspeech emotion recognition framework that addresses critical research problems\nin effective multimodal fusion, heterogeneity among modalities, and\ndiscriminative representation learning. By leveraging a gated cross-modal\nattention mechanism and multimodal homogeneous feature discrepancy learning,\nWavFusion demonstrates improved performance over existing state-of-the-art\nmethods on benchmark datasets. Our work highlights the importance of capturing\nnuanced cross-modal interactions and learning discriminative representations\nfor accurate multimodal SER. Experimental results on two benchmark datasets\n(IEMOCAP and MELD) demonstrate that WavFusion succeeds over the\nstate-of-the-art strategies on emotion recognition.",
      "tldr_zh": "该论文针对语音情感识别 (SER) 的复杂性，提出 WavFusion 框架，该框架基于 wav2vec 2.0 模型，解决多模态融合中的跨模态交互问题、模态异质性和判别性表示学习挑战。WavFusion 采用门控跨模态注意力机制 (gated cross-modal attention mechanism) 和多模态同质特征差异学习 (multimodal homogeneous feature discrepancy learning)，以捕捉细微的跨模态交互并提升特征表示。在 IEMOCAP 和 MELD 等基准数据集上的实验结果显示，WavFusion 超过了现有最先进方法，证明了其在准确多模态 SER 中的有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by 31st International Conference on MultiMedia Modeling\n  (MMM2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.05558v1",
      "published_date": "2024-12-07 06:43:39 UTC",
      "updated_date": "2024-12-07 06:43:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:27:59.087477"
    },
    {
      "arxiv_id": "2412.06839v1",
      "title": "A Neural Model of Rule Discovery with Relatively Short-Term Sequence Memory",
      "title_zh": "翻译失败",
      "authors": [
        "Naoya Arakawa"
      ],
      "abstract": "This report proposes a neural cognitive model for discovering regularities in\nevent sequences. In a fluid intelligence task, the subject is required to\ndiscover regularities from relatively short-term memory of the first-seen task.\nSome fluid intelligence tasks require discovering regularities in event\nsequences. Thus, a neural network model was constructed to explain fluid\nintelligence or regularity discovery in event sequences with relatively\nshort-term memory. The model was implemented and tested with delayed\nmatch-to-sample tasks.",
      "tldr_zh": "这篇论文提出了一种神经认知模型，用于发现事件序列中的规律，特别针对流体 intelligence 任务中从短期记忆中提取首次见到的任务规律。模型基于神经网络架构，强调短期序列记忆来解释规律发现机制。该模型通过延迟 match-to-sample 任务进行实现和测试，展示了其在模拟人类认知过程中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06839v1",
      "published_date": "2024-12-07 06:38:41 UTC",
      "updated_date": "2024-12-07 06:38:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:28:05.294844"
    },
    {
      "arxiv_id": "2412.05555v1",
      "title": "Fragmented Layer Grouping in GUI Designs Through Graph Learning Based on Multimodal Information",
      "title_zh": "翻译失败",
      "authors": [
        "Yunnong Chen",
        "Shuhong Xiao",
        "Jiazhi Li",
        "Tingting Zhou",
        "Yanfang Chang",
        "Yankun Zhen",
        "Lingyun Sun",
        "Liuqing Chen"
      ],
      "abstract": "Automatically constructing GUI groups of different granularities constitutes\na critical intelligent step towards automating GUI design and implementation\ntasks. Specifically, in the industrial GUI-to-code process, fragmented layers\nmay decrease the readability and maintainability of generated code, which can\nbe alleviated by grouping semantically consistent fragmented layers in the\ndesign prototypes. This study aims to propose a graph-learning-based approach\nto tackle the fragmented layer grouping problem according to multi-modal\ninformation in design prototypes. Our graph learning module consists of\nself-attention and graph neural network modules. By taking the multimodal fused\nrepresentation of GUI layers as input, we innovatively group fragmented layers\nby classifying GUI layers and regressing the bounding boxes of the\ncorresponding GUI components simultaneously. Experiments on two real-world\ndatasets demonstrate that our model achieves state-of-the-art performance. A\nfurther user study is also conducted to validate that our approach can assist\nan intelligent downstream tool in generating more maintainable and readable\nfront-end code.",
      "tldr_zh": "这篇论文针对GUI设计中的碎片化层问题，提出了一种基于Graph Learning的approach，利用Multimodal Information来自动分组语义一致的层，从而提升生成的代码可读性和可维护性。方法包括自注意力机制和Graph Neural Network模块，通过输入多模态融合的GUI层表示，同时进行层分类和边界框回归来实现分组。实验在两个真实数据集上证明，该模型达到了state-of-the-art性能。最后，用户研究验证了该approach能辅助下游工具生成更可靠的前端代码。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "28 pages,6 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.05555v1",
      "published_date": "2024-12-07 06:31:09 UTC",
      "updated_date": "2024-12-07 06:31:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:28:21.870989"
    },
    {
      "arxiv_id": "2412.05552v1",
      "title": "SAME: Learning Generic Language-Guided Visual Navigation with State-Adaptive Mixture of Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Gengze Zhou",
        "Yicong Hong",
        "Zun Wang",
        "Chongyang Zhao",
        "Mohit Bansal",
        "Qi Wu"
      ],
      "abstract": "The academic field of learning instruction-guided visual navigation can be\ngenerally categorized into high-level category-specific search and low-level\nlanguage-guided navigation, depending on the granularity of language\ninstruction, in which the former emphasizes the exploration process, while the\nlatter concentrates on following detailed textual commands. Despite the\ndiffering focuses of these tasks, the underlying requirements of interpreting\ninstructions, comprehending the surroundings, and inferring action decisions\nremain consistent. This paper consolidates diverse navigation tasks into a\nunified and generic framework -- we investigate the core difficulties of\nsharing general knowledge and exploiting task-specific capabilities in learning\nnavigation and propose a novel State-Adaptive Mixture of Experts (SAME) model\nthat effectively enables an agent to infer decisions based on\ndifferent-granularity language and dynamic observations. Powered by SAME, we\npresent a versatile agent capable of addressing seven navigation tasks\nsimultaneously that outperforms or achieves highly comparable performance to\ntask-specific agents.",
      "tldr_zh": "本研究将指令引导的视觉导航任务统一到一个通用框架中，解决高层次类别特定搜索和低层次语言引导导航的共同挑战，包括解释指令、理解环境和推断行动决策。论文提出State-Adaptive Mixture of Experts (SAME)模型，该模型通过自适应混合专家机制，允许代理根据不同粒度的语言指令和动态观察进行决策，从而共享通用知识并利用任务特定能力。实验结果显示，基于SAME的代理能同时处理七个导航任务，其性能优于或与专属任务代理相当。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05552v1",
      "published_date": "2024-12-07 06:12:53 UTC",
      "updated_date": "2024-12-07 06:12:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:28:30.891476"
    },
    {
      "arxiv_id": "2412.05547v2",
      "title": "KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Weijie Chen",
        "Ting Bai",
        "Jinbo Su",
        "Jian Luan",
        "Wei Liu",
        "Chuan Shi"
      ],
      "abstract": "Large language models with retrieval-augmented generation encounter a pivotal\nchallenge in intricate retrieval tasks, e.g., multi-hop question answering,\nwhich requires the model to navigate across multiple documents and generate\ncomprehensive responses based on fragmented information. To tackle this\nchallenge, we introduce a novel Knowledge Graph-based RAG framework with a\nhierarchical knowledge retriever, termed KG-Retriever. The retrieval indexing\nin KG-Retriever is constructed on a hierarchical index graph that consists of a\nknowledge graph layer and a collaborative document layer. The associative\nnature of graph structures is fully utilized to strengthen intra-document and\ninter-document connectivity, thereby fundamentally alleviating the information\nfragmentation problem and meanwhile improving the retrieval efficiency in\ncross-document retrieval of LLMs. With the coarse-grained collaborative\ninformation from neighboring documents and concise information from the\nknowledge graph, KG-Retriever achieves marked improvements on five public QA\ndatasets, showing the effectiveness and efficiency of our proposed RAG\nframework.",
      "tldr_zh": "该研究针对检索增强生成（RAG）模型在多跳问答等复杂任务中面临的文档碎片化和检索效率问题，提出了一种新型框架KG-Retriever。框架采用分层索引图，包括知识图谱层和协作文档层，利用图结构的关联性增强文档内部和跨文档连接，从而缓解信息碎片化并提升检索效率。在五个公共QA数据集上，KG-Retriever实现了显著改进，证明了其在RAG框架中的有效性和高效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05547v2",
      "published_date": "2024-12-07 05:49:14 UTC",
      "updated_date": "2025-05-05 09:26:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:30:14.180827"
    },
    {
      "arxiv_id": "2412.10410v1",
      "title": "GROOT-2: Weakly Supervised Multi-Modal Instruction Following Agents",
      "title_zh": "GROOT-2：弱监督多模态指令跟随智能体",
      "authors": [
        "Shaofei Cai",
        "Bowei Zhang",
        "Zihao Wang",
        "Haowei Lin",
        "Xiaojian Ma",
        "Anji Liu",
        "Yitao Liang"
      ],
      "abstract": "Developing agents that can follow multimodal instructions remains a\nfundamental challenge in robotics and AI. Although large-scale pre-training on\nunlabeled datasets (no language instruction) has enabled agents to learn\ndiverse behaviors, these agents often struggle with following instructions.\nWhile augmenting the dataset with instruction labels can mitigate this issue,\nacquiring such high-quality annotations at scale is impractical. To address\nthis issue, we frame the problem as a semi-supervised learning task and\nintroduce GROOT-2, a multimodal instructable agent trained using a novel\napproach that combines weak supervision with latent variable models. Our method\nconsists of two key components: constrained self-imitating, which utilizes\nlarge amounts of unlabeled demonstrations to enable the policy to learn diverse\nbehaviors, and human intention alignment, which uses a smaller set of labeled\ndemonstrations to ensure the latent space reflects human intentions. GROOT-2's\neffectiveness is validated across four diverse environments, ranging from video\ngames to robotic manipulation, demonstrating its robust multimodal\ninstruction-following capabilities.",
      "tldr_zh": "该论文提出 GROOT-2，一种弱监督的多模态指令遵循代理，旨在解决机器人和 AI 领域中代理难以遵循指令的问题。方法结合 constrained self-imitating 和 human intention alignment，利用大量无标签演示学习多样行为，并通过少量有标签演示确保潜在空间反映人类意图。作为半监督学习框架，GROOT-2 在四个多样环境（如视频游戏和机器人操作）中得到验证，展示了其强大的多模态指令遵循能力。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10410v1",
      "published_date": "2024-12-07 05:47:49 UTC",
      "updated_date": "2024-12-07 05:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:28:56.519686"
    },
    {
      "arxiv_id": "2412.06837v1",
      "title": "Innovative Sentiment Analysis and Prediction of Stock Price Using FinBERT, GPT-4 and Logistic Regression: A Data-Driven Approach",
      "title_zh": "使用 FinBERT、GPT-4 和逻辑回归的创新情感分析与股票价格预测：一种数据驱动方法",
      "authors": [
        "Olamilekan Shobayo",
        "Sidikat Adeyemi-Longe",
        "Olusogo Popoola",
        "Bayode Ogunleye"
      ],
      "abstract": "This study explores the comparative performance of cutting-edge AI models,\ni.e., Finaance Bidirectional Encoder representations from Transsformers\n(FinBERT), Generatice Pre-trained Transformer GPT-4, and Logistic Regression,\nfor sentiment analysis and stock index prediction using financial news and the\nNGX All-Share Index data label. By leveraging advanced natural language\nprocessing models like GPT-4 and FinBERT, alongside a traditional machine\nlearning model, Logistic Regression, we aim to classify market sentiment,\ngenerate sentiment scores, and predict market price movements. This research\nhighlights global AI advancements in stock markets, showcasing how\nstate-of-the-art language models can contribute to understanding complex\nfinancial data. The models were assessed using metrics such as accuracy,\nprecision, recall, F1 score, and ROC AUC. Results indicate that Logistic\nRegression outperformed the more computationally intensive FinBERT and\npredefined approach of versatile GPT-4, with an accuracy of 81.83% and a ROC\nAUC of 89.76%. The GPT-4 predefined approach exhibited a lower accuracy of\n54.19% but demonstrated strong potential in handling complex data. FinBERT,\nwhile offering more sophisticated analysis, was resource-demanding and yielded\na moderate performance. Hyperparameter optimization using Optuna and\ncross-validation techniques ensured the robustness of the models. This study\nhighlights the strengths and limitations of the practical applications of AI\napproaches in stock market prediction and presents Logistic Regression as the\nmost efficient model for this task, with FinBERT and GPT-4 representing\nemerging tools with potential for future exploration and innovation in\nAI-driven financial analytics",
      "tldr_zh": "这篇论文比较了 FinBERT、GPT-4 和 Logistic Regression 在情感分析和股票价格预测方面的性能，使用金融新闻数据和 NGX All-Share Index 进行市场情绪分类、情绪分数生成及价格变动预测。研究采用准确率、精确率、召回率、F1 分数和 ROC AUC 等指标评估模型，结果显示 Logistic Regression 以 81.83% 的准确率和 89.76% 的 ROC AUC 表现最佳，而 GPT-4 尽管准确率仅为 54.19%，却在处理复杂数据时显示出潜力，FinBERT 则提供高级分析但资源消耗较高。通过 Optuna 超参数优化和交叉验证，该研究强调了传统机器学习模型的效率，并指出 FinBERT 和 GPT-4 在 AI 驱动金融分析中的未来创新潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.ST",
        "stat.AP",
        "stat.CO",
        "H.3.3"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.06837v1",
      "published_date": "2024-12-07 05:20:31 UTC",
      "updated_date": "2024-12-07 05:20:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:29:10.804406"
    },
    {
      "arxiv_id": "2412.05540v1",
      "title": "Towards 3D Acceleration for low-power Mixture-of-Experts and Multi-Head Attention Spiking Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Boxun Xu",
        "Junyoung Hwang",
        "Pruek Vanna-iampikul",
        "Yuxuan Yin",
        "Sung Kyu Lim",
        "Peng Li"
      ],
      "abstract": "Spiking Neural Networks(SNNs) provide a brain-inspired and event-driven\nmechanism that is believed to be critical to unlock energy-efficient deep\nlearning. The mixture-of-experts approach mirrors the parallel distributed\nprocessing of nervous systems, introducing conditional computation policies and\nexpanding model capacity without scaling up the number of computational\noperations. Additionally, spiking mixture-of-experts self-attention mechanisms\nenhance representation capacity, effectively capturing diverse patterns of\nentities and dependencies between visual or linguistic tokens. However, there\nis currently a lack of hardware support for highly parallel distributed\nprocessing needed by spiking transformers, which embody a brain-inspired\ncomputation. This paper introduces the first 3D hardware architecture and\ndesign methodology for Mixture-of-Experts and Multi-Head Attention spiking\ntransformers. By leveraging 3D integration with memory-on-logic and\nlogic-on-logic stacking, we explore such brain-inspired accelerators with\nspatially stackable circuitry, demonstrating significant optimization of energy\nefficiency and latency compared to conventional 2D CMOS integration.",
      "tldr_zh": "这篇论文针对低功耗的Mixture-of-Experts和Multi-Head Attention Spiking Transformers，提出了首个3D硬件架构和设计方法，以解决Spiking Neural Networks (SNNs)缺乏高并行分布式处理支持的问题。论文通过脑启发的Mixture-of-Experts方法和自注意力机制，增强了模型的表示能力和能量效率，同时利用3D集成技术（如memory-on-logic和logic-on-logic stacking）来优化硬件性能。与传统的2D CMOS集成相比，该架构显著降低了延迟并提高了能量效率，为高效的SNNs加速奠定了基础。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05540v1",
      "published_date": "2024-12-07 05:15:05 UTC",
      "updated_date": "2024-12-07 05:15:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:29:21.989025"
    },
    {
      "arxiv_id": "2501.01959v1",
      "title": "STEAM-EEG: Spatiotemporal EEG Analysis with Markov Transfer Fields and Attentive CNNs",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Qin",
        "Feng Liu"
      ],
      "abstract": "Electroencephalogram (EEG) signals play a pivotal role in biomedical research\nand clinical applications, including epilepsy diagnosis, sleep disorder\nanalysis, and brain-computer interfaces. However, the effective analysis and\ninterpretation of these complex signals often present significant challenges.\nThis paper presents a novel approach that integrates computer graphics\ntechniques with biological signal pattern recognition, specifically using\nMarkov Transfer Fields (MTFs) for EEG time series imaging. The proposed\nframework (STEAM-EEG) employs the capabilities of MTFs to capture the\nspatiotemporal dynamics of EEG signals, transforming them into visually\ninformative images. These images are then rendered, visualised, and modelled\nusing state-of-the-art computer graphics techniques, thereby facilitating\nenhanced data exploration, pattern recognition, and decision-making. The code\ncould be accessed from GitHub.",
      "tldr_zh": "本研究提出了一种新框架 STEAM-EEG，用于 EEG 信号的时空分析，旨在解决这些复杂信号在生物医学研究和临床应用（如癫痫诊断、睡眠障碍分析及脑机接口）中的分析挑战。框架利用 Markov Transfer Fields (MTFs) 将 EEG 时间序列转化为视觉图像，从而捕捉信号的时空动态，并结合计算机图形技术和 Attentive CNNs 进行图像渲染、建模和模式识别。这种方法显著提升了数据探索、模式识别和决策效率，相关代码可从 GitHub 获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.01959v1",
      "published_date": "2024-12-07 05:07:20 UTC",
      "updated_date": "2024-12-07 05:07:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:29:30.752736"
    },
    {
      "arxiv_id": "2412.06836v1",
      "title": "GRUvader: Sentiment-Informed Stock Market Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Akhila Mamillapalli",
        "Bayode Ogunleye",
        "Sonia Timoteo Inacio",
        "Olamilekan Shobayo"
      ],
      "abstract": "Stock price prediction is challenging due to global economic instability,\nhigh volatility, and the complexity of financial markets. Hence, this study\ncompared several machine learning algorithms for stock market prediction and\nfurther examined the influence of a sentiment analysis indicator on the\nprediction of stock prices. Our results were two-fold. Firstly, we used a\nlexicon-based sentiment analysis approach to identify sentiment features, thus\nevidencing the correlation between the sentiment indicator and stock price\nmovement. Secondly, we proposed the use of GRUvader, an optimal gated recurrent\nunit network, for stock market prediction. Our findings suggest that\nstand-alone models struggled compared with AI-enhanced models. Thus, our paper\nmakes further recommendations on latter systems.",
      "tldr_zh": "这篇论文探讨了股票价格预测的挑战，包括全球经济不稳定、高波动性和金融市场复杂性，并比较了多种机器学习算法的效果。研究者使用基于词汇的 sentiment analysis 方法提取情感特征，证明了情感指标与股票价格运动的相关性。论文提出 GRUvader，一种优化的 GRU 网络，用于整合情感信息进行预测；实验结果显示，AI 增强模型比独立模型表现更优，并为未来系统提供了改进推荐。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP",
        "H.3.3"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.06836v1",
      "published_date": "2024-12-07 04:56:17 UTC",
      "updated_date": "2024-12-07 04:56:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:29:43.629929"
    },
    {
      "arxiv_id": "2412.05536v1",
      "title": "Comprehensive Evaluation of Multimodal AI Models in Medical Imaging Diagnosis: From Data Augmentation to Preference-Based Comparison",
      "title_zh": "多模态 AI 模型在医学图像诊断中的全面评估：从数据增强到基于偏好的比较",
      "authors": [
        "Cailian Ruan",
        "Chengyue Huang",
        "Yahe Yang"
      ],
      "abstract": "This study introduces an evaluation framework for multimodal models in\nmedical imaging diagnostics. We developed a pipeline incorporating data\npreprocessing, model inference, and preference-based evaluation, expanding an\ninitial set of 500 clinical cases to 3,000 through controlled augmentation. Our\nmethod combined medical images with clinical observations to generate\nassessments, using Claude 3.5 Sonnet for independent evaluation against\nphysician-authored diagnoses. The results indicated varying performance across\nmodels, with Llama 3.2-90B outperforming human diagnoses in 85.27% of cases. In\ncontrast, specialized vision models like BLIP2 and Llava showed preferences in\n41.36% and 46.77% of cases, respectively. This framework highlights the\npotential of large multimodal models to outperform human diagnostics in certain\ntasks.",
      "tldr_zh": "本研究引入了一个全面评估框架，用于评估多模态AI模型在医疗图像诊断中的性能，该框架包括数据预处理、模型推理和基于偏好的比较方法，通过控制性数据增强将500个临床案例扩展到3000个，并结合医疗图像与临床观察。评估利用Claude 3.5 Sonnet进行独立审查，与医生诊断进行对比。结果显示，Llama 3.2-90B在85.27%的案例中优于人类诊断，而BLIP2和Llava分别在41.36%和46.77%的案例中表现出优势。这一框架突出了大型多模态模型在特定任务中超越人类诊断的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05536v1",
      "published_date": "2024-12-07 04:38:44 UTC",
      "updated_date": "2024-12-07 04:38:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:29:59.575664"
    },
    {
      "arxiv_id": "2412.05534v1",
      "title": "Memory-enhanced Invariant Prompt Learning for Urban Flow Prediction under Distribution Shifts",
      "title_zh": "翻译失败",
      "authors": [
        "Haiyang Jiang",
        "Tong Chen",
        "Wentao Zhang",
        "Nguyen Quoc Viet Hung",
        "Yuan Yuan",
        "Yong Li",
        "Lizhen Cui"
      ],
      "abstract": "Urban flow prediction is a classic spatial-temporal forecasting task that\nestimates the amount of future traffic flow for a given location. Though models\nrepresented by Spatial-Temporal Graph Neural Networks (STGNNs) have established\nthemselves as capable predictors, they tend to suffer from distribution shifts\nthat are common with the urban flow data due to the dynamics and\nunpredictability of spatial-temporal events. Unfortunately, in spatial-temporal\napplications, the dynamic environments can hardly be quantified via a fixed\nnumber of parameters, whereas learning time- and location-specific environments\ncan quickly become computationally prohibitive. In this paper, we propose a\nnovel framework named Memory-enhanced Invariant Prompt learning (MIP) for urban\nflow prediction under constant distribution shifts. Specifically, MIP is\nequipped with a learnable memory bank that is trained to memorize the causal\nfeatures within the spatial-temporal graph. By querying a trainable memory bank\nthat stores the causal features, we adaptively extract invariant and variant\nprompts (i.e., patterns) for a given location at every time step. Then, instead\nof intervening the raw data based on simulated environments, we directly\nperform intervention on variant prompts across space and time. With the\nintervened variant prompts in place, we use invariant learning to minimize the\nvariance of predictions, so as to ensure that the predictions are only made\nwith invariant features. With extensive comparative experiments on two public\nurban flow datasets, we thoroughly demonstrate the robustness of MIP against\nOOD data.",
      "tldr_zh": "这篇论文针对城市流量预测中常见的分布偏移问题，提出了一种名为 Memory-enhanced Invariant Prompt learning (MIP) 的新框架，以提升 Spatial-Temporal Graph Neural Networks (STGNNs) 的鲁棒性。MIP 通过一个可学习的记忆银行存储时空图中的因果特征，并适应性地提取不变和可变提示，然后对可变提示进行空间和时间干预，以最小化预测方差，确保预测仅依赖不变特征。在两个公共城市流量数据集上的实验证明，MIP 对 OOD 数据表现出色，显著提高了模型的鲁棒性和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05534v1",
      "published_date": "2024-12-07 04:35:07 UTC",
      "updated_date": "2024-12-07 04:35:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:30:08.912848"
    },
    {
      "arxiv_id": "2412.05528v1",
      "title": "AI Planning: A Primer and Survey (Preliminary Report)",
      "title_zh": "翻译失败",
      "authors": [
        "Dillon Z. Chen",
        "Pulkit Verma",
        "Siddharth Srivastava",
        "Michael Katz",
        "Sylvie Thiébaux"
      ],
      "abstract": "Automated decision-making is a fundamental topic that spans multiple\nsub-disciplines in AI: reinforcement learning (RL), AI planning (AP),\nfoundation models, and operations research, among others. Despite recent\nefforts to ``bridge the gaps'' between these communities, there remain many\ninsights that have not yet transcended the boundaries. Our goal in this paper\nis to provide a brief and non-exhaustive primer on ideas well-known in AP, but\nless so in other sub-disciplines. We do so by introducing the classical AP\nproblem and representation, and extensions that handle uncertainty and time\nthrough the Markov Decision Process formalism. Next, we survey state-of-the-art\ntechniques and ideas for solving AP problems, focusing on their ability to\nexploit problem structure. Lastly, we cover subfields within AP for learning\nstructure from unstructured inputs and learning to generalise to unseen\nscenarios and situations.",
      "tldr_zh": "这篇论文提供了一个关于 AI Planning (AP) 的入门和初步调研，旨在桥接 AP 与强化学习 (RL)、基础模型和运筹学等 AI 子领域的知识差距。作者介绍了经典的 AP 问题及其表示形式，并扩展到处理不确定性和时间的 Markov Decision Process (MDP) 框架。论文调研了利用问题结构的状态-of-the-art 技术，用于解决 AP 问题。最终，它探讨了 AP 的子领域，包括从无结构输入中学习结构，以及训练模型泛化到未见场景。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05528v1",
      "published_date": "2024-12-07 04:00:25 UTC",
      "updated_date": "2024-12-07 04:00:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:30:28.741581"
    },
    {
      "arxiv_id": "2412.05520v1",
      "title": "More than Marketing? On the Information Value of AI Benchmarks for Practitioners",
      "title_zh": "翻译失败",
      "authors": [
        "Amelia Hardy",
        "Anka Reuel",
        "Kiana Jafari Meimandi",
        "Lisa Soder",
        "Allie Griffith",
        "Dylan M. Asmar",
        "Sanmi Koyejo",
        "Michael S. Bernstein",
        "Mykel J. Kochenderfer"
      ],
      "abstract": "Public AI benchmark results are widely broadcast by model developers as\nindicators of model quality within a growing and competitive market. However,\nthese advertised scores do not necessarily reflect the traits of interest to\nthose who will ultimately apply AI models. In this paper, we seek to understand\nif and how AI benchmarks are used to inform decision-making. Based on the\nanalyses of interviews with 19 individuals who have used, or decided against\nusing, benchmarks in their day-to-day work, we find that across these settings,\nparticipants use benchmarks as a signal of relative performance difference\nbetween models. However, whether this signal was considered a definitive sign\nof model superiority, sufficient for downstream decisions, varied. In academia,\npublic benchmarks were generally viewed as suitable measures for capturing\nresearch progress. By contrast, in both product and policy, benchmarks -- even\nthose developed internally for specific tasks -- were often found to be\ninadequate for informing substantive decisions. Of the benchmarks deemed\nunsatisfactory, respondents reported that their goals were neither well-defined\nnor reflective of real-world use. Based on the study results, we conclude that\neffective benchmarks should provide meaningful, real-world evaluations,\nincorporate domain expertise, and maintain transparency in scope and goals.\nThey must capture diverse, task-relevant capabilities, be challenging enough to\navoid quick saturation, and account for trade-offs in model performance rather\nthan relying on a single score. Additionally, proprietary data collection and\ncontamination prevention are critical for producing reliable and actionable\nresults. By adhering to these criteria, benchmarks can move beyond mere\nmarketing tricks into robust evaluative frameworks.",
      "tldr_zh": "本研究探讨了 AI benchmarks 是否能为从业者提供超越营销价值的实际决策信息。通过对 19 名使用或未使用 benchmarks 的个体的采访，作者发现这些基准主要用于比较模型的相对性能，但在学术界被视为衡量研究进展的可靠工具，而在产品和政策领域，往往因目标不明确且不反映真实世界应用而不足。研究强调，有效的 benchmarks 应提供有意义的真实评估、融入领域专业知识、保持透明性，并考虑模型性能的多样性和权衡，而非单一分数。此外，防止数据污染和使用专有数据是确保 benchmarks 可靠性的关键，从而将其转化为可行动的评估框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05520v1",
      "published_date": "2024-12-07 03:35:39 UTC",
      "updated_date": "2024-12-07 03:35:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:30:40.924111"
    },
    {
      "arxiv_id": "2412.06835v1",
      "title": "APS-LSTM: Exploiting Multi-Periodicity and Diverse Spatial Dependencies for Flood Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Feng",
        "Xueyi Liu",
        "Jiamin Lu",
        "Pingping Shao"
      ],
      "abstract": "Accurate flood prediction is crucial for disaster prevention and mitigation.\nHydrological data exhibit highly nonlinear temporal patterns and encompass\ncomplex spatial relationships between rainfall and flow. Existing flood\nprediction models struggle to capture these intricate temporal features and\nspatial dependencies. This paper presents an adaptive periodic and spatial\nself-attention method based on LSTM (APS-LSTM) to address these challenges. The\nAPS-LSTM learns temporal features from a multi-periodicity perspective and\ncaptures diverse spatial dependencies from different period divisions. The\nAPS-LSTM consists of three main stages, (i) Multi-Period Division, that\nutilizes Fast Fourier Transform (FFT) to divide various periodic patterns; (ii)\nSpatio-Temporal Information Extraction, that performs periodic and spatial\nself-attention focusing on intra- and inter-periodic temporal patterns and\nspatial dependencies; (iii) Adaptive Aggregation, that relies on amplitude\nstrength to aggregate the computational results from each periodic division.\nThe abundant experiments on two real-world datasets demonstrate the superiority\nof APS-LSTM. The code is available: https://github.com/oopcmd/APS-LSTM.",
      "tldr_zh": "准确洪水预测对于灾害预防至关重要，但现有模型难以捕捉高度非线性时间模式和复杂空间依赖性。本文提出 APS-LSTM 方法，该方法基于 LSTM，利用 Fast Fourier Transform (FFT) 进行多周期划分，并通过周期和空间自注意力提取时空信息，最后采用自适应聚合机制根据幅度强度整合结果。实验在两个真实数据集上证明，APS-LSTM 显著优于基线模型，有效提升了洪水预测性能；代码已开源于 https://github.com/oopcmd/APS-LSTM。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Received by IEEE SMC",
      "pdf_url": "http://arxiv.org/pdf/2412.06835v1",
      "published_date": "2024-12-07 03:02:16 UTC",
      "updated_date": "2024-12-07 03:02:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:30:53.248209"
    },
    {
      "arxiv_id": "2412.05505v1",
      "title": "Trimming Down Large Spiking Vision Transformers via Heterogeneous Quantization Search",
      "title_zh": "翻译失败",
      "authors": [
        "Boxun Xu",
        "Yufei Song",
        "Peng Li"
      ],
      "abstract": "Spiking Neural Networks (SNNs) are amenable to deployment on edge devices and\nneuromorphic hardware due to their lower dissipation. Recently, SNN-based\ntransformers have garnered significant interest, incorporating attention\nmechanisms akin to their counterparts in Artificial Neural Networks (ANNs)\nwhile demonstrating excellent performance. However, deploying large spiking\ntransformer models on resource-constrained edge devices such as mobile phones,\nstill poses significant challenges resulted from the high computational demands\nof large uncompressed high-precision models. In this work, we introduce a novel\nheterogeneous quantization method for compressing spiking transformers through\nlayer-wise quantization. Our approach optimizes the quantization of each layer\nusing one of two distinct quantization schemes, i.e., uniform or power-of-two\nquantification, with mixed bit resolutions. Our heterogeneous quantization\ndemonstrates the feasibility of maintaining high performance for spiking\ntransformers while utilizing an average effective resolution of 3.14-3.67 bits\nwith less than a 1% accuracy drop on DVS Gesture and CIFAR10-DVS datasets. It\nattains a model compression rate of 8.71x-10.19x for standard floating-point\nspiking transformers. Moreover, the proposed approach achieves a significant\nenergy reduction of 5.69x, 8.72x, and 10.2x while maintaining high accuracy\nlevels of 85.3%, 97.57%, and 80.4% on N-Caltech101, DVS-Gesture, and\nCIFAR10-DVS datasets, respectively.",
      "tldr_zh": "该研究针对大型Spiking Neural Networks (SNNs)视觉变压器在资源受限设备上的部署挑战，提出了一种异构量化方法，通过层级量化优化每个层采用统一或幂二量化方案，并结合混合位分辨率来压缩模型。相比标准浮点模型，该方法在DVS Gesture和CIFAR10-DVS数据集上实现了平均有效分辨率仅3.14-3.67位，同时准确率下降不到1%，并获得8.71x-10.19x的模型压缩率。实验结果显示，该方法在N-Caltech101、DVS-Gesture和CIFAR10-DVS数据集上分别实现了5.69x、8.72x和10.2x的能量减少，同时保持了85.3%、97.57%和80.4%的较高准确率，为高效的边缘设备部署奠定了基础。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05505v1",
      "published_date": "2024-12-07 02:34:02 UTC",
      "updated_date": "2024-12-07 02:34:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:31:05.814637"
    },
    {
      "arxiv_id": "2412.06834v2",
      "title": "Investigating social alignment via mirroring in a system of interacting language models",
      "title_zh": "翻译失败",
      "authors": [
        "Harvey McGuinness",
        "Tianyu Wang",
        "Carey E. Priebe",
        "Hayden Helm"
      ],
      "abstract": "Alignment is a social phenomenon wherein individuals share a common goal or\nperspective. Mirroring, or mimicking the behaviors and opinions of another\nindividual, is one mechanism by which individuals can become aligned. Large\nscale investigations of the effect of mirroring on alignment have been limited\ndue to the scalability of traditional experimental designs in sociology. In\nthis paper, we introduce a simple computational framework that enables studying\nthe effect of mirroring behavior on alignment in multi-agent systems. We\nsimulate systems of interacting large language models in this framework and\ncharacterize overall system behavior and alignment with quantitative measures\nof agent dynamics. We find that system behavior is strongly influenced by the\nrange of communication of each agent and that these effects are exacerbated by\nincreased rates of mirroring. We discuss the observed simulated system behavior\nin the context of known human social dynamics.",
      "tldr_zh": "这篇论文探讨了通过镜像（mirroring）机制实现社会对齐（alignment）的现象，在多智能体系统（multi-agent systems）中模拟交互的大型语言模型（large language models）。研究引入了一个简单计算框架，允许大规模分析镜像行为对系统行为和代理动态的影响。结果表明，代理的通信范围强烈影响整体系统行为，而增加镜像频率会放大这些效果；这些模拟发现与人类社会动态相呼应，为理解社会现象提供了新视角。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06834v2",
      "published_date": "2024-12-07 02:19:57 UTC",
      "updated_date": "2025-02-15 23:16:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:31:15.920731"
    },
    {
      "arxiv_id": "2412.06833v1",
      "title": "Detecting Fake News on Social Media: A Novel Reliability Aware Machine-Crowd Hybrid Intelligence-Based Method",
      "title_zh": "社交媒体上的假新闻检测：一种新颖的可靠性感知机器-人群混合智能方法",
      "authors": [
        "Yidong Chai",
        "Kangwei Shi",
        "Jiaheng Xie",
        "Chunli Liu",
        "Yuanchun Jiang",
        "Yezheng Liu"
      ],
      "abstract": "Fake news on social media platforms poses a significant threat to societal\nsystems, underscoring the urgent need for advanced detection methods. The\nexisting detection methods can be divided into machine intelligence-based,\ncrowd intelligence-based, and hybrid intelligence-based methods. Among them,\nhybrid intelligence-based methods achieve the best performance but fail to\nconsider the reliability issue in detection. In light of this, we propose a\nnovel Reliability Aware Hybrid Intelligence (RAHI) method for fake news\ndetection. Our method comprises three integral modules. The first module\nemploys a Bayesian deep learning model to capture the inherent reliability\nwithin machine intelligence. The second module uses an Item Response Theory\n(IRT)-based user response aggregation to account for the reliability in crowd\nintelligence. The third module introduces a new distribution fusion mechanism,\nwhich takes the distributions derived from both machine and crowd intelligence\nas input, and outputs a fused distribution that provides predictions along with\nthe associated reliability. The experiments on the Weibo dataset demonstrate\nthe advantages of our method. This study contributes to the research field with\na novel RAHI-based method, and the code is shared at\nhttps://github.com/Kangwei-g/RAHI. This study has practical implications for\nthree key stakeholders: internet users, online platform managers, and the\ngovernment.",
      "tldr_zh": "本研究针对社交媒体上的假新闻问题，提出了一种新颖的 Reliability Aware Hybrid Intelligence (RAHI) 方法，以解决现有混合智能检测方法的可靠性不足。该方法包括三个关键模块：使用 Bayesian 深度学习模型捕获机器智能中的固有可靠性；采用 Item Response Theory (IRT) 基于用户响应聚合处理众包智能中的可靠性；以及引入一个新的分布融合机制，将机器和众包智能的分布融合输出，提供预测及其可靠性。实验在 Weibo 数据集上证明了 RAHI 的优势，与现有方法相比显著提升了检测性能。该方法为互联网用户、在线平台管理者及政府等利益相关者提供了实际应用价值，并公开了代码以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06833v1",
      "published_date": "2024-12-07 02:10:21 UTC",
      "updated_date": "2024-12-07 02:10:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:31:30.579999"
    },
    {
      "arxiv_id": "2412.05498v1",
      "title": "A New Perspective on Time Series Anomaly Detection: Faster Patch-based Broad Learning System",
      "title_zh": "翻译失败",
      "authors": [
        "Pengyu Li",
        "Zhijie Zhong",
        "Tong Zhang",
        "Zhiwen Yu",
        "C. L. Philip Chen",
        "Kaixiang Yang"
      ],
      "abstract": "Time series anomaly detection (TSAD) has been a research hotspot in both\nacademia and industry in recent years. Deep learning methods have become the\nmainstream research direction due to their excellent performance. However, new\nviewpoints have emerged in recent TSAD research. Deep learning is not required\nfor TSAD due to limitations such as slow deep learning speed. The Broad\nLearning System (BLS) is a shallow network framework that benefits from its\nease of optimization and speed. It has been shown to outperform machine\nlearning approaches while remaining competitive with deep learning. Based on\nthe current situation of TSAD, we propose the Contrastive Patch-based Broad\nLearning System (CPatchBLS). This is a new exploration of patching technique\nand BLS, providing a new perspective for TSAD. We construct Dual-PatchBLS as a\nbase through patching and Simple Kernel Perturbation (SKP) and utilize\ncontrastive learning to capture the differences between normal and abnormal\ndata under different representations. To compensate for the temporal semantic\nloss caused by various patching, we propose CPatchBLS with model level\nintegration, which takes advantage of BLS's fast feature to build model-level\nintegration and improve model detection. Using five real-world series anomaly\ndetection datasets, we confirmed the method's efficacy, outperforming previous\ndeep learning and machine learning methods while retaining a high level of\ncomputing efficiency.",
      "tldr_zh": "本研究从一个新视角审视时间序列异常检测（TSAD），强调不需要依赖速度较慢的深层学习，转而采用浅层网络框架Broad Learning System (BLS)以提升效率。作者提出Contrastive Patch-based Broad Learning System (CPatchBLS)，通过patching技术、Simple Kernel Perturbation (SKP)以及对比学习，构建Dual-PatchBLS来捕捉正常和异常数据间的差异，并采用模型级集成补偿patching导致的时序语义损失。实验在五个真实世界TSAD数据集上验证了该方法的有效性，其性能优于现有深层学习和机器学习方法，同时保持高计算效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 7 figures, 3 tables, Under review",
      "pdf_url": "http://arxiv.org/pdf/2412.05498v1",
      "published_date": "2024-12-07 01:58:18 UTC",
      "updated_date": "2024-12-07 01:58:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:31:41.151030"
    },
    {
      "arxiv_id": "2412.06832v2",
      "title": "SLA Management in Reconfigurable Multi-Agent RAG: A Systems Approach to Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Iannelli",
        "Sneha Kuchipudi",
        "Vera Dvorak"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) enables Large Language Models (LLMs) to\ngeneralize to new information by decoupling reasoning capabilities from static\nknowledge bases. Traditional RAG enhancements have explored vertical\nscaling-assigning subtasks to specialized modules-and horizontal\nscaling-replicating tasks across multiple agents-to improve performance.\nHowever, real-world applications impose diverse Service Level Agreements (SLAs)\nand Quality of Service (QoS) requirements, involving trade-offs among\nobjectives such as reducing cost, ensuring answer quality, and adhering to\nspecific operational constraints.\n  In this work, we present a systems-oriented approach to multi-agent RAG\ntailored for real-world Question Answering (QA) applications. By integrating\ntask-specific non-functional requirements-such as answer quality, cost, and\nlatency-into the system, we enable dynamic reconfiguration to meet diverse\nSLAs. Our method maps these Service Level Objectives (SLOs) to system-level\nparameters, allowing the generation of optimal results within specified\nresource constraints.\n  We conduct a case study in the QA domain, demonstrating how dynamic\nre-orchestration of a multi-agent RAG system can effectively manage the\ntrade-off between answer quality and cost. By adjusting the system based on\nquery intent and operational conditions, we systematically balance performance\nand resource utilization. This approach allows the system to meet SLOs for\nvarious query types, showcasing its practicality for real-world applications.",
      "tldr_zh": "本研究提出了一种面向系统的多智能体 RAG（Retrieval Augmented Generation）方法，用于处理真实世界问答（QA）应用中的服务级别协议（SLA）管理。该方法通过整合任务特定的非功能性需求（如答案质量、成本和延迟），实现系统动态重新配置，并将服务级别目标（SLOs）映射到系统级参数，从而在资源约束下生成最优结果。相比传统垂直或水平扩展，作者通过一个QA领域的案例研究，展示了该系统能根据查询意图和操作条件有效平衡答案质量与成本的权衡，确保满足多样化的服务质量（QoS）要求，为实际应用提供了实用框架。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.DC",
        "H.3.4; H.3.3; I.2.7; I.2.11; C.2.4"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06832v2",
      "published_date": "2024-12-07 01:32:13 UTC",
      "updated_date": "2025-04-28 23:51:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:31:55.289696"
    },
    {
      "arxiv_id": "2412.05481v2",
      "title": "A Compositional Atlas for Algebraic Circuits",
      "title_zh": "翻译失败",
      "authors": [
        "Benjie Wang",
        "Denis Deratani Mauá",
        "Guy Van den Broeck",
        "YooJung Choi"
      ],
      "abstract": "Circuits based on sum-product structure have become a ubiquitous\nrepresentation to compactly encode knowledge, from Boolean functions to\nprobability distributions. By imposing constraints on the structure of such\ncircuits, certain inference queries become tractable, such as model counting\nand most probable configuration. Recent works have explored analyzing\nprobabilistic and causal inference queries as compositions of basic operators\nto derive tractability conditions. In this paper, we take an algebraic\nperspective for compositional inference, and show that a large class of queries\n- including marginal MAP, probabilistic answer set programming inference, and\ncausal backdoor adjustment - correspond to a combination of basic operators\nover semirings: aggregation, product, and elementwise mapping. Using this\nframework, we uncover simple and general sufficient conditions for tractable\ncomposition of these operators, in terms of circuit properties (e.g., marginal\ndeterminism, compatibility) and conditions on the elementwise mappings.\nApplying our analysis, we derive novel tractability conditions for many such\ncompositional queries. Our results unify tractability conditions for existing\nproblems on circuits, while providing a blueprint for analysing novel\ncompositional inference queries.",
      "tldr_zh": "本研究从代数视角探讨了基于 sum-product 结构的 Algebraic Circuits，作为紧凑知识表示的一种方法，并分析了通过结构约束实现推理查询（如模型计数和最可能配置）的可计算性。论文将多种查询，包括 marginal MAP、probabilistic answer set programming inference 和 causal backdoor adjustment，视为半环上基本运算符（aggregation、product 和 elementwise mapping）的组合。作者提出了简单且通用的充分条件，这些条件基于电路属性（如 marginal determinism 和 compatibility）以及 elementwise mappings 的要求，确保运算符组合的可计算性。通过应用这一框架，研究推导出许多组合查询的新可计算性条件，并统一了现有电路问题的可计算性分析，为分析新型 compositional inference queries 提供了蓝图。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.05481v2",
      "published_date": "2024-12-07 00:51:46 UTC",
      "updated_date": "2025-02-24 07:15:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:32:04.842643"
    },
    {
      "arxiv_id": "2412.06831v1",
      "title": "TransitGPT: A Generative AI-based framework for interacting with GTFS data using Large Language Models",
      "title_zh": "TransitGPT：一种基于生成式AI的框架，用于使用大型语言模型与GTFS数据交互",
      "authors": [
        "Saipraneeth Devunuri",
        "Lewis Lehe"
      ],
      "abstract": "This paper introduces a framework that leverages Large Language Models (LLMs)\nto answer natural language queries about General Transit Feed Specification\n(GTFS) data. The framework is implemented in a chatbot called TransitGPT with\nopen-source code. TransitGPT works by guiding LLMs to generate Python code that\nextracts and manipulates GTFS data relevant to a query, which is then executed\non a server where the GTFS feed is stored. It can accomplish a wide range of\ntasks, including data retrieval, calculations, and interactive visualizations,\nwithout requiring users to have extensive knowledge of GTFS or programming. The\nLLMs that produce the code are guided entirely by prompts, without fine-tuning\nor access to the actual GTFS feeds. We evaluate TransitGPT using GPT-4o and\nClaude-3.5-Sonnet LLMs on a benchmark dataset of 100 tasks, to demonstrate its\neffectiveness and versatility. The results show that TransitGPT can\nsignificantly enhance the accessibility and usability of transit data.",
      "tldr_zh": "本研究提出TransitGPT框架，利用Large Language Models (LLMs)来处理和响应关于General Transit Feed Specification (GTFS)数据的自然语言查询。该框架通过聊天机器人TransitGPT引导LLMs生成Python代码，以提取、操作和可视化GTFS数据，而无需用户具备相关专业知识或编程技能。实验使用GPT-4o和Claude-3.5-Sonnet在100个任务基准数据集上评估，结果显示TransitGPT显著提升了交通数据的可访问性和可用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.06831v1",
      "published_date": "2024-12-07 00:35:41 UTC",
      "updated_date": "2024-12-07 00:35:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:32:17.415785"
    },
    {
      "arxiv_id": "2412.16172v2",
      "title": "LABIIUM: AI-Enhanced Zero-configuration Measurement Automation System",
      "title_zh": "LABIIUM：AI 增强的零配置测量自动化系统",
      "authors": [
        "Emmanuel A. Olowe",
        "Danial Chitnis"
      ],
      "abstract": "The complexity of laboratory environments requires solutions that simplify\ninstrument interaction and enhance measurement automation. Traditional tools\noften require configuration, software, and programming skills, creating\nbarriers to productivity. Previous approaches, including dedicated software\nsuites and custom scripts, frequently fall short in providing user-friendly\nsolutions that align with programming practices. We present LABIIUM, an\nAI-enhanced, zero-configuration measurement automation system designed to\nstreamline experimental workflows and improve user productivity. LABIIUM\nintegrates an AI assistant powered by Large Language Models (LLMs) to generate\ncode. LABIIUM's Lab-Automation-Measurement Bridges (LAMBs) enable seamless\ninstrument connectivity using standard tools such as VSCode and Python,\neliminating setup overhead. To demonstrate its capabilities, we conducted\nexperiments involving the measurement of the parametric transfer curve of a\nsimple two-transistor inverting amplifier with a current source load. The AI\nassistant was evaluated using different prompt scenarios and compared with\nmultiple models, including Claude Sonnet 3.5, Gemini Pro 1.5, and GPT-4o. An\nexpert solution implementing the Gradient-Weighted Adaptive Stochastic Sampling\n(GWASS) method was used as a baseline. The solutions generated by the AI\nassistant were compared with the expert solution and a uniform linear sweep\nbaseline with 10,000 points. The graph results show that the LLMs were able to\nsuccessfully complete the most basic uniform sweep, but LLMs were unable to\ndevelop adaptive sweeping algorithms to compete with GWASS. The evaluation\nunderscores LABIIUM's ability to enhance laboratory productivity and support\ndigital transformation in research and industry, and emphasizes the future work\nrequired to improve LLM performance in Electronic Measurement Science Tasks.",
      "tldr_zh": "本研究提出 LABIIUM，一种 AI 增强的零配置测量自动化系统，旨在简化实验室环境中的仪器交互和实验流程，克服传统工具的配置和编程障碍。系统整合 Large Language Models (LLMs) 驱动的 AI 助手来生成代码，以及 Lab-Automation-Measurement Bridges (LAMBs) 来实现与 VSCode 和 Python 的无缝连接，从而提升用户生产力。在实验中，评估了 LABIIUM 在测量双晶体管反相放大器参数转移曲线时的表现，与 Claude Sonnet 3.5、Gemini Pro 1.5 和 GPT-4o 等模型比较，结果显示 LLMs 能完成基本均匀扫描，但无法匹敌 Gradient-Weighted Adaptive Stochastic Sampling (GWASS) 的自适应算法。总体而言，LABIIUM 支持实验室的数字转型，但强调需要进一步改进 LLM 在电子测量科学任务中的性能。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted for IEEE I2MTC 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.16172v2",
      "published_date": "2024-12-07 00:15:24 UTC",
      "updated_date": "2025-03-04 18:15:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T09:32:34.211216"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 61,
  "processed_papers_count": 61,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T09:33:02.072344"
}