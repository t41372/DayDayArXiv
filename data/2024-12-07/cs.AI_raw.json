[
  {
    "arxiv_id": "2412.05753v1",
    "title": "Can OpenAI o1 outperform humans in higher-order cognitive thinking?",
    "authors": [
      "Ehsan Latif",
      "Yifan Zhou",
      "Shuchen Guo",
      "Lehong Shi",
      "Yizhu Gao",
      "Matthew Nyaaba",
      "Arne Bewerdorff",
      "Xiantong Yang",
      "Xiaoming Zhai"
    ],
    "abstract": "This study evaluates the performance of OpenAI's o1-preview model in\nhigher-order cognitive domains, including critical thinking, systematic\nthinking, computational thinking, data literacy, creative thinking, logical\nreasoning, and scientific reasoning. Using established benchmarks, we compared\nthe o1-preview models's performance to human participants from diverse\neducational levels. o1-preview achieved a mean score of 24.33 on the Ennis-Weir\nCritical Thinking Essay Test (EWCTET), surpassing undergraduate (13.8) and\npostgraduate (18.39) participants (z = 1.60 and 0.90, respectively). In\nsystematic thinking, it scored 46.1, SD = 4.12 on the Lake Urmia Vignette,\nsignificantly outperforming the human mean (20.08, SD = 8.13, z = 3.20). For\ndata literacy, o1-preview scored 8.60, SD = 0.70 on Merk et al.'s \"Use Data\"\ndimension, compared to the human post-test mean of 4.17, SD = 2.02 (z = 2.19).\nOn creative thinking tasks, the model achieved originality scores of 2.98, SD =\n0.73, higher than the human mean of 1.74 (z = 0.71). In logical reasoning\n(LogiQA), it outperformed humans with average 90%, SD = 10% accuracy versus\n86%, SD = 6.5% (z = 0.62). For scientific reasoning, it achieved near-perfect\nperformance (mean = 0.99, SD = 0.12) on the TOSLS,, exceeding the highest human\nscores of 0.85, SD = 0.13 (z = 1.78). While o1-preview excelled in structured\ntasks, it showed limitations in problem-solving and adaptive reasoning. These\nresults demonstrate the potential of AI to complement education in structured\nassessments but highlight the need for ethical oversight and refinement for\nbroader applications.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05753v1",
    "published_date": "2024-12-07 21:52:03 UTC",
    "updated_date": "2024-12-07 21:52:03 UTC"
  },
  {
    "arxiv_id": "2412.05749v1",
    "title": "A Comparative Study on Code Generation with Transformers",
    "authors": [
      "Namrata Das",
      "Rakshya Panta",
      "Neelam Karki",
      "Ruchi Manandhar",
      "Dinesh Baniya Kshatri"
    ],
    "abstract": "In an era of widespread influence of Natural Language Processing (NLP), there\nhave been multiple research efforts to supplant traditional manual coding\ntechniques with automated systems capable of generating solutions autonomously.\nWith rapid research for code generation and a sole focus on large language\nmodels, there emerges a need to compare and evaluate the performance of\ntransformer architectures based on several complexities of the model. This\npaper introduces the concept of a \"A Comparative Study on Code Generation with\nTransformers,\" a model based on Transformer architecture, and NLP methodologies\nto automatically generate C++ source code for different varieties of problems.\nHere, a comparative study is performed to evaluate the robustness of\ntransformer-based models on the basis of their architecture complexities and\ntheir capability to handle diverse problem sets, from basic arithmetic to\ncomplex computations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05749v1",
    "published_date": "2024-12-07 21:18:23 UTC",
    "updated_date": "2024-12-07 21:18:23 UTC"
  },
  {
    "arxiv_id": "2412.05748v1",
    "title": "Constrained Control for Autonomous Spacecraft Rendezvous: Learning-Based Time Shift Governor",
    "authors": [
      "Taehyeun Kim",
      "Robin Inho Kee",
      "Ilya Kolmanovsky",
      "Anouck Girard"
    ],
    "abstract": "This paper develops a Time Shift Governor (TSG)-based control scheme to\nenforce constraints during rendezvous and docking (RD) missions in the setting\nof the Two-Body problem. As an add-on scheme to the nominal closed-loop system,\nthe TSG generates a time-shifted Chief spacecraft trajectory as a target\nreference for the Deputy spacecraft. This modification of the commanded\nreference trajectory ensures that constraints are enforced while the time shift\nis reduced to zero to effect the rendezvous. Our approach to TSG implementation\nintegrates an LSTM neural network which approximates the time shift parameter\nas a function of a sequence of past Deputy and Chief spacecraft states. This\nLSTM neural network is trained offline from simulation data. We report\nsimulation results for RD missions in the Low Earth Orbit (LEO) and on the\nMolniya orbit to demonstrate the effectiveness of the proposed control scheme.\nThe proposed scheme reduces the time to compute the time shift parameter in\nmost of the scenarios and successfully completes rendezvous missions.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.RO",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "Taehyeun Kim and Robin Inho Kee contributed equally to this work. 18\n  pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.05748v1",
    "published_date": "2024-12-07 21:17:36 UTC",
    "updated_date": "2024-12-07 21:17:36 UTC"
  },
  {
    "arxiv_id": "2412.05747v1",
    "title": "Charting the Shapes of Stories with Game Theory",
    "authors": [
      "Constantinos Daskalakis",
      "Ian Gemp",
      "Yanchen Jiang",
      "Renato Paes Leme",
      "Christos Papadimitriou",
      "Georgios Piliouras"
    ],
    "abstract": "Stories are records of our experiences and their analysis reveals insights\ninto the nature of being human. Successful analyses are often\ninterdisciplinary, leveraging mathematical tools to extract structure from\nstories and insights from structure. Historically, these tools have been\nrestricted to one dimensional charts and dynamic social networks; however,\nmodern AI offers the possibility of identifying more fully the plot structure,\ncharacter incentives, and, importantly, counterfactual plot lines that the\nstory could have taken but did not take. In this work, we use AI to model the\nstructure of stories as game-theoretic objects, amenable to quantitative\nanalysis. This allows us to not only interrogate each character's decision\nmaking, but also possibly peer into the original author's conception of the\ncharacters' world. We demonstrate our proposed technique on Shakespeare's\nfamous Romeo and Juliet. We conclude with a discussion of how our analysis\ncould be replicated in broader contexts, including real-life scenarios.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "NeurIPS 2024 Creative AI Track",
    "pdf_url": "http://arxiv.org/pdf/2412.05747v1",
    "published_date": "2024-12-07 21:12:16 UTC",
    "updated_date": "2024-12-07 21:12:16 UTC"
  },
  {
    "arxiv_id": "2412.05734v1",
    "title": "PrivAgent: Agentic-based Red-teaming for LLM Privacy Leakage",
    "authors": [
      "Yuzhou Nie",
      "Zhun Wang",
      "Ye Yu",
      "Xian Wu",
      "Xuandong Zhao",
      "Wenbo Guo",
      "Dawn Song"
    ],
    "abstract": "Recent studies have discovered that LLMs have serious privacy leakage\nconcerns, where an LLM may be fooled into outputting private information under\ncarefully crafted adversarial prompts. These risks include leaking system\nprompts, personally identifiable information, training data, and model\nparameters. Most existing red-teaming approaches for privacy leakage rely on\nhumans to craft the adversarial prompts. A few automated methods are proposed\nfor system prompt extraction, but they cannot be applied to more severe risks\n(e.g., training data extraction) and have limited effectiveness even for system\nprompt extraction.\n  In this paper, we propose PrivAgent, a novel black-box red-teaming framework\nfor LLM privacy leakage. We formulate different risks as a search problem with\na unified attack goal. Our framework trains an open-source LLM through\nreinforcement learning as the attack agent to generate adversarial prompts for\ndifferent target models under different risks. We propose a novel reward\nfunction to provide effective and fine-grained rewards for the attack agent.\nFinally, we introduce customizations to better fit our general framework to\nsystem prompt extraction and training data extraction. Through extensive\nevaluations, we first show that PrivAgent outperforms existing automated\nmethods in system prompt leakage against six popular LLMs. Notably, our\napproach achieves a 100% success rate in extracting system prompts from\nreal-world applications in OpenAI's GPT Store. We also show PrivAgent's\neffectiveness in extracting training data from an open-source LLM with a\nsuccess rate of 5.9%. We further demonstrate PrivAgent's effectiveness in\nevading the existing guardrail defense and its helpfulness in enabling better\nsafety alignment. Finally, we validate our customized designs through a\ndetailed ablation study. We release our code here\nhttps://github.com/rucnyz/RedAgent.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05734v1",
    "published_date": "2024-12-07 20:09:01 UTC",
    "updated_date": "2024-12-07 20:09:01 UTC"
  },
  {
    "arxiv_id": "2412.05731v1",
    "title": "A Scoping Review of ChatGPT Research in Accounting and Finance",
    "authors": [
      "Mengming Michael Dong",
      "Theophanis C. Stratopoulos",
      "Victor Xiaoqi Wang"
    ],
    "abstract": "This paper provides a review of recent publications and working papers on\nChatGPT and related Large Language Models (LLMs) in accounting and finance. The\naim is to understand the current state of research in these two areas and\nidentify potential research opportunities for future inquiry. We identify three\ncommon themes from these earlier studies. The first theme focuses on\napplications of ChatGPT and LLMs in various fields of accounting and finance.\nThe second theme utilizes ChatGPT and LLMs as a new research tool by leveraging\ntheir capabilities such as classification, summarization, and text generation.\nThe third theme investigates implications of LLM adoption for accounting and\nfinance professionals, as well as for various organizations and sectors. While\nthese earlier studies provide valuable insights, they leave many important\nquestions unanswered or partially addressed. We propose venues for further\nexploration and provide technical guidance for researchers seeking to employ\nChatGPT and related LLMs as a tool for their research.",
    "categories": [
      "q-fin.GN",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "q-fin.GN",
    "comment": "56 pages, 3 figures, 16 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.05731v1",
    "published_date": "2024-12-07 19:45:46 UTC",
    "updated_date": "2024-12-07 19:45:46 UTC"
  },
  {
    "arxiv_id": "2412.05725v2",
    "title": "Black Swan: Abductive and Defeasible Video Reasoning in Unpredictable Events",
    "authors": [
      "Aditya Chinchure",
      "Sahithya Ravi",
      "Raymond Ng",
      "Vered Shwartz",
      "Boyang Li",
      "Leonid Sigal"
    ],
    "abstract": "The commonsense reasoning capabilities of vision-language models (VLMs),\nespecially in abductive reasoning and defeasible reasoning, remain poorly\nunderstood. Most benchmarks focus on typical visual scenarios, making it\ndifficult to discern whether model performance stems from keen perception and\nreasoning skills, or reliance on pure statistical recall. We argue that by\nfocusing on atypical events in videos, clearer insights can be gained on the\ncore capabilities of VLMs. Explaining and understanding such\nout-of-distribution events requires models to extend beyond basic pattern\nrecognition and regurgitation of their prior knowledge. To this end, we\nintroduce BlackSwanSuite, a benchmark for evaluating VLMs' ability to reason\nabout unexpected events through abductive and defeasible tasks. Our tasks\nartificially limit the amount of visual information provided to models while\nquestioning them about hidden unexpected events, or provide new visual\ninformation that could change an existing hypothesis about the event. We curate\na comprehensive benchmark suite comprising over 3,800 MCQ, 4,900 generative and\n6,700 yes/no questions, spanning 1,655 videos. After extensively evaluating\nvarious state-of-the-art VLMs, including GPT-4o and Gemini 1.5 Pro, as well as\nopen-source VLMs such as LLaVA-Video, we find significant performance gaps of\nup to 32% from humans on these tasks. Our findings reveal key limitations in\ncurrent VLMs, emphasizing the need for enhanced model architectures and\ntraining strategies. Our data and leaderboard is available at\nblackswan.cs.ubc.ca.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025. For data, visit https://blackswan.cs.ubc.ca",
    "pdf_url": "http://arxiv.org/pdf/2412.05725v2",
    "published_date": "2024-12-07 19:19:03 UTC",
    "updated_date": "2025-04-07 20:26:05 UTC"
  },
  {
    "arxiv_id": "2412.05724v1",
    "title": "A Tiered GAN Approach for Monet-Style Image Generation",
    "authors": [
      "FNU Neha",
      "Deepshikha Bhati",
      "Deepak Kumar Shukla",
      "Md Amiruzzaman"
    ],
    "abstract": "Generative Adversarial Networks (GANs) have proven to be a powerful tool in\ngenerating artistic images, capable of mimicking the styles of renowned\npainters, such as Claude Monet. This paper introduces a tiered GAN model to\nprogressively refine image quality through a multi-stage process, enhancing the\ngenerated images at each step. The model transforms random noise into detailed\nartistic representations, addressing common challenges such as instability in\ntraining, mode collapse, and output quality. This approach combines\ndownsampling and convolutional techniques, enabling the generation of\nhigh-quality Monet-style artwork while optimizing computational efficiency.\nExperimental results demonstrate the architecture's ability to produce\nfoundational artistic structures, though further refinements are necessary for\nachieving higher levels of realism and fidelity to Monet's style. Future work\nfocuses on improving training methodologies and model complexity to bridge the\ngap between generated and true artistic images. Additionally, the limitations\nof traditional GANs in artistic generation are analyzed, and strategies to\novercome these shortcomings are proposed.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05724v1",
    "published_date": "2024-12-07 19:10:29 UTC",
    "updated_date": "2024-12-07 19:10:29 UTC"
  },
  {
    "arxiv_id": "2412.05723v2",
    "title": "Training-Free Bayesianization for Low-Rank Adapters of Large Language Models",
    "authors": [
      "Haizhou Shi",
      "Yibin Wang",
      "Ligong Han",
      "Huan Zhang",
      "Hao Wang"
    ],
    "abstract": "Estimating the uncertainty of responses from Large Language Models (LLMs)\nremains a critical challenge. While recent Bayesian methods have demonstrated\neffectiveness in quantifying uncertainty through low-rank weight updates, they\ntypically require complex fine-tuning or post-training procedures. In this\npaper, we propose Training-Free Bayesianization (TFB), a simple yet\ntheoretically grounded framework that efficiently transforms trained low-rank\nadapters into Bayesian ones without additional training. TFB systematically\nsearches for the maximally acceptable level of variance in the weight\nposterior, constrained within a family of low-rank isotropic Gaussian\ndistributions. Our theoretical analysis shows that under mild conditions, this\nsearch process is equivalent to KL-regularized variational optimization, a\ngeneralized form of variational inference. Through comprehensive experiments,\nwe show that TFB achieves superior uncertainty estimation and generalization\ncompared to existing methods while eliminating the need for complex\nBayesianization training procedures. Code will be available at\nhttps://github.com/Wang-ML-Lab/bayesian-peft.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "Pre-print; Accepted (non-archivally) at ICLR'25 Workshop: \"Quantify\n  Uncertainty and Hallucination in Foundation Models: The Next Frontier in\n  Reliable AI\"",
    "pdf_url": "http://arxiv.org/pdf/2412.05723v2",
    "published_date": "2024-12-07 18:49:27 UTC",
    "updated_date": "2025-05-16 21:43:14 UTC"
  },
  {
    "arxiv_id": "2412.05718v1",
    "title": "RL Zero: Zero-Shot Language to Behaviors without any Supervision",
    "authors": [
      "Harshit Sikchi",
      "Siddhant Agarwal",
      "Pranaya Jajoo",
      "Samyak Parajuli",
      "Caleb Chuck",
      "Max Rudolph",
      "Peter Stone",
      "Amy Zhang",
      "Scott Niekum"
    ],
    "abstract": "Rewards remain an uninterpretable way to specify tasks for Reinforcement\nLearning, as humans are often unable to predict the optimal behavior of any\ngiven reward function, leading to poor reward design and reward hacking.\nLanguage presents an appealing way to communicate intent to agents and bypass\nreward design, but prior efforts to do so have been limited by costly and\nunscalable labeling efforts. In this work, we propose a method for a completely\nunsupervised alternative to grounding language instructions in a zero-shot\nmanner to obtain policies. We present a solution that takes the form of\nimagine, project, and imitate: The agent imagines the observation sequence\ncorresponding to the language description of a task, projects the imagined\nsequence to our target domain, and grounds it to a policy. Video-language\nmodels allow us to imagine task descriptions that leverage knowledge of tasks\nlearned from internet-scale video-text mappings. The challenge remains to\nground these generations to a policy. In this work, we show that we can achieve\na zero-shot language-to-behavior policy by first grounding the imagined\nsequences in real observations of an unsupervised RL agent and using a\nclosed-form solution to imitation learning that allows the RL agent to mimic\nthe grounded observations. Our method, RLZero, is the first to our knowledge to\nshow zero-shot language to behavior generation abilities without any\nsupervision on a variety of tasks on simulated domains. We further show that\nRLZero can also generate policies zero-shot from cross-embodied videos such as\nthose scraped from YouTube.",
    "categories": [
      "cs.AI",
      "cs.GR",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "27 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.05718v1",
    "published_date": "2024-12-07 18:31:16 UTC",
    "updated_date": "2024-12-07 18:31:16 UTC"
  },
  {
    "arxiv_id": "2412.05717v1",
    "title": "Learning Soft Driving Constraints from Vectorized Scene Embeddings while Imitating Expert Trajectories",
    "authors": [
      "Niloufar Saeidi Mobarakeh",
      "Behzad Khamidehi",
      "Chunlin Li",
      "Hamidreza Mirkhani",
      "Fazel Arasteh",
      "Mohammed Elmahgiubi",
      "Weize Zhang",
      "Kasra Rezaee",
      "Pascal Poupart"
    ],
    "abstract": "The primary goal of motion planning is to generate safe and efficient\ntrajectories for vehicles. Traditionally, motion planning models are trained\nusing imitation learning to mimic the behavior of human experts. However, these\nmodels often lack interpretability and fail to provide clear justifications for\ntheir decisions. We propose a method that integrates constraint learning into\nimitation learning by extracting driving constraints from expert trajectories.\nOur approach utilizes vectorized scene embeddings that capture critical spatial\nand temporal features, enabling the model to identify and generalize\nconstraints across various driving scenarios. We formulate the constraint\nlearning problem using a maximum entropy model, which scores the motion\nplanner's trajectories based on their similarity to the expert trajectory. By\nseparating the scoring process into distinct reward and constraint streams, we\nimprove both the interpretability of the planner's behavior and its attention\nto relevant scene components. Unlike existing constraint learning methods that\nrely on simulators and are typically embedded in reinforcement learning (RL) or\ninverse reinforcement learning (IRL) frameworks, our method operates without\nsimulators, making it applicable to a wider range of datasets and real-world\nscenarios. Experimental results on the InD and TrafficJams datasets demonstrate\nthat incorporating driving constraints enhances model interpretability and\nimproves closed-loop performance.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05717v1",
    "published_date": "2024-12-07 18:29:28 UTC",
    "updated_date": "2024-12-07 18:29:28 UTC"
  },
  {
    "arxiv_id": "2412.05710v1",
    "title": "PromptRefine: Enhancing Few-Shot Performance on Low-Resource Indic Languages with Example Selection from Related Example Banks",
    "authors": [
      "Soumya Suvra Ghosal",
      "Soumyabrata Pal",
      "Koyel Mukherjee",
      "Dinesh Manocha"
    ],
    "abstract": "Large Language Models (LLMs) have recently demonstrated impressive few-shot\nlearning capabilities through in-context learning (ICL). However, ICL\nperformance is highly dependent on the choice of few-shot demonstrations,\nmaking the selection of the most optimal examples a persistent research\nchallenge. This issue is further amplified in low-resource Indic languages,\nwhere the scarcity of ground-truth data complicates the selection process. In\nthis work, we propose PromptRefine, a novel Alternating Minimization approach\nfor example selection that improves ICL performance on low-resource Indic\nlanguages. PromptRefine leverages auxiliary example banks from related\nhigh-resource Indic languages and employs multi-task learning techniques to\nalign language-specific retrievers, enabling effective cross-language\nretrieval. Additionally, we incorporate diversity in the selected examples to\nenhance generalization and reduce bias. Through comprehensive evaluations on\nfour text generation tasks -- Cross-Lingual Question Answering, Multilingual\nQuestion Answering, Machine Translation, and Cross-Lingual Summarization using\nstate-of-the-art LLMs such as LLAMA-3.1-8B, LLAMA-2-7B, Qwen-2-7B, and\nQwen-2.5-7B, we demonstrate that PromptRefine significantly outperforms\nexisting frameworks for retrieving examples.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05710v1",
    "published_date": "2024-12-07 17:51:31 UTC",
    "updated_date": "2024-12-07 17:51:31 UTC"
  },
  {
    "arxiv_id": "2412.06843v2",
    "title": "Semantic Loss Guided Data Efficient Supervised Fine Tuning for Safe Responses in LLMs",
    "authors": [
      "Yuxiao Lu",
      "Arunesh Sinha",
      "Pradeep Varakantham"
    ],
    "abstract": "Large Language Models (LLMs) generating unsafe responses to toxic prompts is\na significant issue in their applications. While various efforts aim to address\nthis safety concern, previous approaches often demand substantial human data\ncollection or rely on the less dependable option of using another LLM to\ngenerate corrective data. In this paper, we aim to take this problem and\novercome limitations of requiring significant high-quality human data. Our\nmethod requires only a small set of unsafe responses to toxic prompts, easily\nobtained from the unsafe LLM itself. By employing a semantic cost combined with\na negative Earth Mover Distance (EMD) loss, we guide the LLM away from\ngenerating unsafe responses. Additionally, we propose a novel lower bound for\nEMD loss, enabling more efficient optimization. Our results demonstrate\nsuperior performance and data efficiency compared to baselines, and we further\nexamine the nuanced effects of over-alignment and potential degradation of\nlanguage capabilities when using contrastive data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06843v2",
    "published_date": "2024-12-07 16:35:14 UTC",
    "updated_date": "2024-12-11 12:35:25 UTC"
  },
  {
    "arxiv_id": "2412.05688v3",
    "title": "Flow-based Detection of Botnets through Bio-inspired Optimisation of Machine Learning",
    "authors": [
      "Biju Issac",
      "Kyle Fryer",
      "Seibu Mary Jacob"
    ],
    "abstract": "Botnets could autonomously infect, propagate, communicate and coordinate with\nother members in the botnet, enabling cybercriminals to exploit the cumulative\ncomputing and bandwidth of its bots to facilitate cybercrime. Traditional\ndetection methods are becoming increasingly unsuitable against various\nnetwork-based detection evasion methods. These techniques ultimately render\nsignature-based fingerprinting detection infeasible and thus this research\nexplores the application of network flow-based behavioural modelling to\nfacilitate the binary classification of bot network activity, whereby the\ndetection is independent of underlying communications architectures, ports,\nprotocols and payload-based detection evasion mechanisms. A comparative\nevaluation of various machine learning classification methods is conducted, to\nprecisely determine the average accuracy of each classifier on bot datasets\nlike CTU-13, ISOT 2010 and ISCX 2014. Additionally, hyperparameter tuning using\nGenetic Algorithm (GA), aiming to efficiently converge to the fittest\nhyperparameter set for each dataset was done. The bioinspired optimisation of\nRandom Forest (RF) with GA achieved an average accuracy of 99.85% when it was\ntested against the three datasets. The model was then developed into a software\nproduct. The YouTube link of the project and demo of the software developed:\nhttps://youtu.be/gNQjC91VtOI",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "24 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.05688v3",
    "published_date": "2024-12-07 15:55:49 UTC",
    "updated_date": "2024-12-15 13:58:10 UTC"
  },
  {
    "arxiv_id": "2412.05686v1",
    "title": "Neural network interpretability with layer-wise relevance propagation: novel techniques for neuron selection and visualization",
    "authors": [
      "Deepshikha Bhati",
      "Fnu Neha",
      "Md Amiruzzaman",
      "Angela Guercio",
      "Deepak Kumar Shukla",
      "Ben Ward"
    ],
    "abstract": "Interpreting complex neural networks is crucial for understanding their\ndecision-making processes, particularly in applications where transparency and\naccountability are essential. This proposed method addresses this need by\nfocusing on layer-wise Relevance Propagation (LRP), a technique used in\nexplainable artificial intelligence (XAI) to attribute neural network outputs\nto input features through backpropagated relevance scores. Existing LRP methods\noften struggle with precision in evaluating individual neuron contributions. To\novercome this limitation, we present a novel approach that improves the parsing\nof selected neurons during LRP backward propagation, using the Visual Geometry\nGroup 16 (VGG16) architecture as a case study. Our method creates neural\nnetwork graphs to highlight critical paths and visualizes these paths with\nheatmaps, optimizing neuron selection through accuracy metrics like Mean\nSquared Error (MSE) and Symmetric Mean Absolute Percentage Error (SMAPE).\nAdditionally, we utilize a deconvolutional visualization technique to\nreconstruct feature maps, offering a comprehensive view of the network's inner\nworkings. Extensive experiments demonstrate that our approach enhances\ninterpretability and supports the development of more transparent artificial\nintelligence (AI) systems for computer vision applications. This advancement\nhas the potential to improve the trustworthiness of AI models in real-world\nmachine vision applications, thereby increasing their reliability and\neffectiveness.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05686v1",
    "published_date": "2024-12-07 15:49:14 UTC",
    "updated_date": "2024-12-07 15:49:14 UTC"
  },
  {
    "arxiv_id": "2412.05685v1",
    "title": "HMGIE: Hierarchical and Multi-Grained Inconsistency Evaluation for Vision-Language Data Cleansing",
    "authors": [
      "Zihao Zhu",
      "Hongbao Zhang",
      "Guanzong Wu",
      "Siwei Lyu",
      "Baoyuan Wu"
    ],
    "abstract": "Visual-textual inconsistency (VTI) evaluation plays a crucial role in\ncleansing vision-language data. Its main challenges stem from the high variety\nof image captioning datasets, where differences in content can create a range\nof inconsistencies (\\eg, inconsistencies in scene, entities, entity attributes,\nentity numbers, entity interactions). Moreover, variations in caption length\ncan introduce inconsistencies at different levels of granularity as well. To\ntackle these challenges, we design an adaptive evaluation framework, called\nHierarchical and Multi-Grained Inconsistency Evaluation (HMGIE), which can\nprovide multi-grained evaluations covering both accuracy and completeness for\nvarious image-caption pairs. Specifically, the HMGIE framework is implemented\nby three consecutive modules. Firstly, the semantic graph generation module\nconverts the image caption to a semantic graph for building a structural\nrepresentation of all involved semantic items. Then, the hierarchical\ninconsistency evaluation module provides a progressive evaluation procedure\nwith a dynamic question-answer generation and evaluation strategy guided by the\nsemantic graph, producing a hierarchical inconsistency evaluation graph (HIEG).\nFinally, the quantitative evaluation module calculates the accuracy and\ncompleteness scores based on the HIEG, followed by a natural language\nexplanation about the detection results. Moreover, to verify the efficacy and\nflexibility of the proposed framework on handling different image captioning\ndatasets, we construct MVTID, an image-caption dataset with diverse types and\ngranularities of inconsistencies. Extensive experiments on MVTID and other\nbenchmark datasets demonstrate the superior performance of the proposed HMGIE\nto current state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05685v1",
    "published_date": "2024-12-07 15:47:49 UTC",
    "updated_date": "2024-12-07 15:47:49 UTC"
  },
  {
    "arxiv_id": "2412.05681v1",
    "title": "Leveraging Time-Series Foundation Model for Subsurface Well Logs Prediction and Anomaly Detection",
    "authors": [
      "Ardiansyah Koeshidayatullah",
      "Abdulrahman Al-Fakih",
      "SanLinn Ismael Kaka"
    ],
    "abstract": "The rise in energy demand highlights the importance of suitable subsurface\nstorage, requiring detailed and accurate subsurface characterization often\nreliant on high-quality borehole well log data. However, obtaining complete\nwell-log data is costly and time-consuming, with missing data being common due\nto borehole conditions or tool errors. While machine learning and deep learning\nalgorithms have been implemented to address these issues, they often fail to\ncapture the intricate, nonlinear relationships and long-term dependencies in\ncomplex well log sequences. Additionally, prior AI-driven models typically\nrequire retraining when introduced to new datasets and are constrained to\ndeployment in the same basin.\n  In this study, we explored and evaluated the potential of a time-series\nfoundation model leveraging transformer architecture and a generative\npre-trained approach for predicting and detecting anomalies in borehole well\nlog data. Specifically, we fine-tuned and adopted the TimeGPT architecture to\nforecast key log responses and detect anomalies with high accuracy. Our\nproposed model demonstrated excellent performance, achieving R2 of up to 87%\nand a mean absolute percentage error (MAPE) as low as 1.95%. Additionally, the\nmodel's zero-shot capability successfully identified subtle yet critical\nanomalies, such as drilling hazards or unexpected geological formations, with\nan overall accuracy of 93%.\n  The model represents a significant advancement in predictive accuracy and\ncomputational efficiency, enabling zero-shot inference through fine-tuning. Its\napplication in well-log prediction enhances operational decision-making while\nreducing risks associated with subsurface exploration. These findings\ndemonstrate the model's potential to transform well-log data analysis,\nparticularly in complex geological settings.",
    "categories": [
      "physics.geo-ph",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05681v1",
    "published_date": "2024-12-07 15:23:52 UTC",
    "updated_date": "2024-12-07 15:23:52 UTC"
  },
  {
    "arxiv_id": "2412.05674v1",
    "title": "No-Free-Lunch Theories for Tensor-Network Machine Learning Models",
    "authors": [
      "Jing-Chuan Wu",
      "Qi Ye",
      "Dong-Ling Deng",
      "Li-Wei Yu"
    ],
    "abstract": "Tensor network machine learning models have shown remarkable versatility in\ntackling complex data-driven tasks, ranging from quantum many-body problems to\nclassical pattern recognitions. Despite their promising performance, a\ncomprehensive understanding of the underlying assumptions and limitations of\nthese models is still lacking. In this work, we focus on the rigorous\nformulation of their no-free-lunch theorem -- essential yet notoriously\nchallenging to formalize for specific tensor network machine learning models.\nIn particular, we rigorously analyze the generalization risks of learning\ntarget output functions from input data encoded in tensor network states. We\nfirst prove a no-free-lunch theorem for machine learning models based on matrix\nproduct states, i.e., the one-dimensional tensor network states. Furthermore,\nwe circumvent the challenging issue of calculating the partition function for\ntwo-dimensional Ising model, and prove the no-free-lunch theorem for the case\nof two-dimensional projected entangled-pair state, by introducing the\ncombinatorial method associated to the \"puzzle of polyominoes\". Our findings\nreveal the intrinsic limitations of tensor network-based learning models in a\nrigorous fashion, and open up an avenue for future analytical exploration of\nboth the strengths and limitations of quantum-inspired machine learning\nframeworks.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.DS",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "quant-ph",
    "comment": "7+23 pages, comments welcome",
    "pdf_url": "http://arxiv.org/pdf/2412.05674v1",
    "published_date": "2024-12-07 14:41:24 UTC",
    "updated_date": "2024-12-07 14:41:24 UTC"
  },
  {
    "arxiv_id": "2412.05667v3",
    "title": "Training neural networks without backpropagation using particles",
    "authors": [
      "Deepak Kumar"
    ],
    "abstract": "Neural networks are a group of neurons stacked together in multiple layers to\nmimic the biological neurons in a human brain. Neural networks have been\ntrained using the backpropagation algorithm based on gradient descent strategy\nfor several decades. Several variants have been developed to improve the\nbackpropagation algorithm. The loss function for the neural network is\noptimized through backpropagation, but several local minima exist in the\nmanifold of the constructed neural network. We obtain several solutions\nmatching the minima. The gradient descent strategy cannot avoid the problem of\nlocal minima and gets stuck in the minima due to the initialization. Particle\nswarm optimization (PSO) was proposed to select the best local minima among the\nsearch space of the loss function. The search space is limited to the\ninstantiated particles in the PSO algorithm, and sometimes it cannot select the\nbest solution. In the proposed approach, we overcome the problem of gradient\ndescent and the limitation of the PSO algorithm by training individual neurons\nseparately, capable of collectively solving the problem as a group of neurons\nforming a network. Our code and data are available at\nhttps://github.com/dipkmr/train-nn-wobp/",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "15 pages, 8 figures, Added GitHub source code and corrected a few\n  sentences in Latex file, Added additional literature review to the paper",
    "pdf_url": "http://arxiv.org/pdf/2412.05667v3",
    "published_date": "2024-12-07 14:30:48 UTC",
    "updated_date": "2025-04-20 15:41:36 UTC"
  },
  {
    "arxiv_id": "2412.05666v1",
    "title": "Early Diagnosis of Alzheimer's Diseases and Dementia from MRI Images Using an Ensemble Deep Learning",
    "authors": [
      "Mozhgan Naderi",
      "Maryam Rastgarpour",
      "Amir Reza Takhsha"
    ],
    "abstract": "Alzheimer's Disease (AD) is a progressive neurological disorder that can\nresult in significant cognitive impairment and dementia. Accurate and timely\ndiagnosis is essential for effective treatment and management of this disease.\nIn this study, we proposed two low-parameter Convolutional Neural Networks\n(CNNs), IR-BRAINNET and Modified-DEMNET, designed to detect the early stages of\nAD accurately. We also introduced an ensemble model that averages their outputs\nto reduce variance across the CNNs and enhance AD detection. Both CNNs are\ntrained, and all models are evaluated using a Magnetic Resonance Imaging (MRI)\ndataset from the Kaggle database. The dataset includes images of four stages of\ndementia, with an uneven class distribution. To mitigate challenges stemming\nfrom the inherent imbalance in the dataset, we employed the Synthetic Minority\nOver-sampling Technique (SMOTE) to generate additional instances for minority\nclasses. In the NO-SMOTE scenario, despite the imbalanced distribution, the\nensemble model achieved 98.28% accuracy, outperforming IR-BRAINNET (97.26%) and\nModified-DEMNET (95.54%), with Wilcoxon p-values of 2.9e-3 and 5.20e-6,\nrespectively, indicating significant improvement in correct predictions through\nthe use of the average function. In the SMOTE scenario, the ensemble model\nachieved 99.92% accuracy (1.64% improvement over NO-SMOTE), IR-BRAINNET reached\n99.80% (2.54% improvement), and Modified-DEMNET attained 99.72% (4.18%\nimprovement). Based on the experimental findings, averaging the models' outputs\nenhanced AD diagnosis in both scenarios, while the diversity in the dataset\nintroduced by SMOTE-generated instances significantly improved performance.\nFurthermore, the compact models we proposed outperformed those from previous\nstudies, even in the presence of an imbalanced distribution.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05666v1",
    "published_date": "2024-12-07 14:27:41 UTC",
    "updated_date": "2024-12-07 14:27:41 UTC"
  },
  {
    "arxiv_id": "2412.06841v1",
    "title": "The Helicobacter pylori AI-Clinician: Harnessing Artificial Intelligence to Personalize H. pylori Treatment Recommendations",
    "authors": [
      "Kyle Higgins",
      "Olga P. Nyssen",
      "Joshua Southern",
      "Ivan Laponogov",
      "AIDA CONSORTIUM",
      "Dennis Veselkov",
      "Javier P. Gisbert",
      "Tania Fleitas Kanonnikoff",
      "Kirill Veselkov"
    ],
    "abstract": "Helicobacter pylori (H. pylori) is the most common carcinogenic pathogen\nworldwide. Infecting roughly 1 in 2 individuals globally, it is the leading\ncause of peptic ulcer disease, chronic gastritis, and gastric cancer. To\ninvestigate whether personalized treatments would be optimal for patients\nsuffering from infection, we developed the H. pylori AI-clinician\nrecommendation system. This system was trained on data from tens of thousands\nof H. pylori-infected patients from Hp-EuReg, orders of magnitude greater than\nthose experienced by a single real-world clinician. We first used a simulated\ndataset and demonstrated the ability of our AI Clinician method to identify\npatient subgroups that would benefit from differential optimal treatments.\nNext, we trained the AI Clinician on Hp-EuReg, demonstrating the AI Clinician\nreproduces known quality estimates of treatments, for example bismuth and\nquadruple therapies out-performing triple, with longer durations and higher\ndose proton pump inhibitor (PPI) showing higher quality estimation on average.\nNext we demonstrated that treatment was optimized by recommended personalized\ntherapies in patient subsets, where 65% of patients were recommended a bismuth\ntherapy of either metronidazole, tetracycline, and bismuth salts with PPI, or\nbismuth quadruple therapy with clarithromycin, amoxicillin, and bismuth salts\nwith PPI, and 15% of patients recommended a quadruple non-bismuth therapy of\nclarithromycin, amoxicillin, and metronidazole with PPI. Finally, we determined\ntrends in patient variables driving the personalized recommendations using\nrandom forest modelling. With around half of the world likely to experience H.\npylori infection at some point in their lives, the identification of\npersonalized optimal treatments will be crucial in both gastric cancer\nprevention and quality of life improvements for countless individuals\nworldwide.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06841v1",
    "published_date": "2024-12-07 12:57:10 UTC",
    "updated_date": "2024-12-07 12:57:10 UTC"
  },
  {
    "arxiv_id": "2412.05641v1",
    "title": "Hyperedge Anomaly Detection with Hypergraph Neural Network",
    "authors": [
      "Md. Tanvir Alam",
      "Chowdhury Farhan Ahmed",
      "Carson K. Leung"
    ],
    "abstract": "Hypergraph is a data structure that enables us to model higher-order\nassociations among data entities. Conventional graph-structured data can\nrepresent pairwise relationships only, whereas hypergraph enables us to\nassociate any number of entities, which is essential in many real-life\napplications. Hypergraph learning algorithms have been well-studied for\nnumerous problem settings, such as node classification, link prediction, etc.\nHowever, much less research has been conducted on anomaly detection from\nhypergraphs. Anomaly detection identifies events that deviate from the usual\npattern and can be applied to hypergraphs to detect unusual higher-order\nassociations. In this work, we propose an end-to-end hypergraph neural\nnetwork-based model for identifying anomalous associations in a hypergraph. Our\nproposed algorithm operates in an unsupervised manner without requiring any\nlabeled data. Extensive experimentation on several real-life datasets\ndemonstrates the effectiveness of our model in detecting anomalous hyperedges.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05641v1",
    "published_date": "2024-12-07 12:52:22 UTC",
    "updated_date": "2024-12-07 12:52:22 UTC"
  },
  {
    "arxiv_id": "2412.05632v1",
    "title": "Biological Brain Age Estimation using Sex-Aware Adversarial Variational Autoencoder with Multimodal Neuroimages",
    "authors": [
      "Abd Ur Rehman",
      "Azka Rehman",
      "Muhammad Usman",
      "Abdullah Shahid",
      "Sung-Min Gho",
      "Aleum Lee",
      "Tariq M. Khan",
      "Imran Razzak"
    ],
    "abstract": "Brain aging involves structural and functional changes and therefore serves\nas a key biomarker for brain health. Combining structural magnetic resonance\nimaging (sMRI) and functional magnetic resonance imaging (fMRI) has the\npotential to improve brain age estimation by leveraging complementary data.\nHowever, fMRI data, being noisier than sMRI, complicates multimodal fusion.\nTraditional fusion methods often introduce more noise than useful information,\nwhich can reduce accuracy compared to using sMRI alone. In this paper, we\npropose a novel multimodal framework for biological brain age estimation,\nutilizing a sex-aware adversarial variational autoencoder (SA-AVAE). Our\nframework integrates adversarial and variational learning to effectively\ndisentangle the latent features from both modalities. Specifically, we\ndecompose the latent space into modality-specific codes and shared codes to\nrepresent complementary and common information across modalities, respectively.\nTo enhance the disentanglement, we introduce cross-reconstruction and\nshared-distinct distance ratio loss as regularization terms. Importantly, we\nincorporate sex information into the learned latent code, enabling the model to\ncapture sex-specific aging patterns for brain age estimation via an integrated\nregressor module. We evaluate our model using the publicly available OpenBHB\ndataset, a comprehensive multi-site dataset for brain age estimation. The\nresults from ablation studies and comparisons with state-of-the-art methods\ndemonstrate that our framework outperforms existing approaches and shows\nsignificant robustness across various age groups, highlighting its potential\nfor real-time clinical applications in the early detection of neurodegenerative\ndiseases.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05632v1",
    "published_date": "2024-12-07 12:10:29 UTC",
    "updated_date": "2024-12-07 12:10:29 UTC"
  },
  {
    "arxiv_id": "2412.05631v1",
    "title": "CharacterBox: Evaluating the Role-Playing Capabilities of LLMs in Text-Based Virtual Worlds",
    "authors": [
      "Lei Wang",
      "Jianxun Lian",
      "Yi Huang",
      "Yanqi Dai",
      "Haoxuan Li",
      "Xu Chen",
      "Xing Xie",
      "Ji-Rong Wen"
    ],
    "abstract": "Role-playing is a crucial capability of Large Language Models (LLMs),\nenabling a wide range of practical applications, including intelligent\nnon-player characters, digital twins, and emotional companions. Evaluating this\ncapability in LLMs is challenging due to the complex dynamics involved in\nrole-playing, such as maintaining character fidelity throughout a storyline and\nnavigating open-ended narratives without a definitive ground truth. Current\nevaluation methods, which primarily focus on question-answering or\nconversational snapshots, fall short of adequately capturing the nuanced\ncharacter traits and behaviors essential for authentic role-playing. In this\npaper, we propose CharacterBox, which is a simulation sandbox designed to\ngenerate situational fine-grained character behavior trajectories. These\nbehavior trajectories enable a more comprehensive and in-depth evaluation of\nrole-playing capabilities. CharacterBox consists of two main components: the\ncharacter agent and the narrator agent. The character agent, grounded in\npsychological and behavioral science, exhibits human-like behaviors, while the\nnarrator agent coordinates interactions between character agents and\nenvironmental changes. Additionally, we introduce two trajectory-based methods\nthat leverage CharacterBox to enhance LLM performance. To reduce costs and\nfacilitate the adoption of CharacterBox by public communities, we fine-tune two\nsmaller models, CharacterNR and CharacterRM, as substitutes for GPT API calls,\nand demonstrate their competitive performance compared to advanced GPT APIs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05631v1",
    "published_date": "2024-12-07 12:09:35 UTC",
    "updated_date": "2024-12-07 12:09:35 UTC"
  },
  {
    "arxiv_id": "2412.05628v1",
    "title": "Remix-DiT: Mixing Diffusion Transformers for Multi-Expert Denoising",
    "authors": [
      "Gongfan Fang",
      "Xinyin Ma",
      "Xinchao Wang"
    ],
    "abstract": "Transformer-based diffusion models have achieved significant advancements\nacross a variety of generative tasks. However, producing high-quality outputs\ntypically necessitates large transformer models, which result in substantial\ntraining and inference overhead. In this work, we investigate an alternative\napproach involving multiple experts for denoising, and introduce Remix-DiT, a\nnovel method designed to enhance output quality at a low cost. The goal of\nRemix-DiT is to craft N diffusion experts for different denoising timesteps,\nyet without the need for expensive training of N independent models. To achieve\nthis, Remix-DiT employs K basis models (where K < N) and utilizes learnable\nmixing coefficients to adaptively craft expert models. This design offers two\nsignificant advantages: first, although the total model size is increased, the\nmodel produced by the mixing operation shares the same architecture as a plain\nmodel, making the overall model as efficient as a standard diffusion\ntransformer. Second, the learnable mixing adaptively allocates model capacity\nacross timesteps, thereby effectively improving generation quality. Experiments\nconducted on the ImageNet dataset demonstrate that Remix-DiT achieves promising\nresults compared to standard diffusion transformers and other multiple-expert\nmethods. The code is available at https://github.com/VainF/Remix-DiT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05628v1",
    "published_date": "2024-12-07 11:52:41 UTC",
    "updated_date": "2024-12-07 11:52:41 UTC"
  },
  {
    "arxiv_id": "2412.05594v1",
    "title": "Real-Time 3D Object Detection Using InnovizOne LiDAR and Low-Power Hailo-8 AI Accelerator",
    "authors": [
      "Itay Krispin-Avraham",
      "Roy Orfaig",
      "Ben-Zion Bobrovsky"
    ],
    "abstract": "Object detection is a significant field in autonomous driving. Popular\nsensors for this task include cameras and LiDAR sensors. LiDAR sensors offer\nseveral advantages, such as insensitivity to light changes, like in a dark\nsetting and the ability to provide 3D information in the form of point clouds,\nwhich include the ranges of objects. However, 3D detection methods, such as\nPointPillars, typically require high-power hardware. Additionally, most common\nspinning LiDARs are sparse and may not achieve the desired quality of object\ndetection in front of the car. In this paper, we present the feasibility of\nperforming real-time 3D object detection of cars using 3D point clouds from a\nLiDAR sensor, processed and deployed on a low-power Hailo-8 AI accelerator. The\nLiDAR sensor used in this study is the InnovizOne sensor, which captures\nobjects in higher quality compared to spinning LiDAR techniques, especially for\ndistant objects. We successfully achieved real-time inference at a rate of\napproximately 5Hz with a high accuracy of 0.91% F1 score, with only -0.2%\ndegradation compared to running the same model on an NVIDIA GeForce RTX 2080\nTi. This work demonstrates that effective real-time 3D object detection can be\nachieved on low-cost, low-power hardware, representing a significant step\ntowards more accessible autonomous driving technologies. The source code and\nthe pre-trained models are available at https://github.com/AIROTAU/\nPointPillarsHailoInnoviz/tree/main",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05594v1",
    "published_date": "2024-12-07 09:19:55 UTC",
    "updated_date": "2024-12-07 09:19:55 UTC"
  },
  {
    "arxiv_id": "2412.05592v1",
    "title": "From Flexibility to Manipulation: The Slippery Slope of XAI Evaluation",
    "authors": [
      "Kristoffer Wickstrm",
      "Marina Marie-Claire Hhne",
      "Anna Hedstrm"
    ],
    "abstract": "The lack of ground truth explanation labels is a fundamental challenge for\nquantitative evaluation in explainable artificial intelligence (XAI). This\nchallenge becomes especially problematic when evaluation methods have numerous\nhyperparameters that must be specified by the user, as there is no ground truth\nto determine an optimal hyperparameter selection. It is typically not feasible\nto do an exhaustive search of hyperparameters so researchers typically make a\nnormative choice based on similar studies in the literature, which provides\ngreat flexibility for the user. In this work, we illustrate how this\nflexibility can be exploited to manipulate the evaluation outcome. We frame\nthis manipulation as an adversarial attack on the evaluation where seemingly\ninnocent changes in hyperparameter setting significantly influence the\nevaluation outcome. We demonstrate the effectiveness of our manipulation across\nseveral datasets with large changes in evaluation outcomes across several\nexplanation methods and models. Lastly, we propose a mitigation strategy based\non ranking across hyperparameters that aims to provide robustness towards such\nmanipulation. This work highlights the difficulty of conducting reliable XAI\nevaluation and emphasizes the importance of a holistic and transparent approach\nto evaluation in XAI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published in ECCV 2024 Workshop on Explainable Computer Vision: Where\n  are We and Where are We Going? Shorter non-archival version also appeared in\n  the NeurIPS 2024 Interpretable AI workshop. Code is available at\n  \\url{https://github.com/Wickstrom/quantitative-xai-manipulation}",
    "pdf_url": "http://arxiv.org/pdf/2412.05592v1",
    "published_date": "2024-12-07 09:14:46 UTC",
    "updated_date": "2024-12-07 09:14:46 UTC"
  },
  {
    "arxiv_id": "2412.05591v1",
    "title": "BERTCaps: BERT Capsule for Persian Multi-Domain Sentiment Analysis",
    "authors": [
      "Mohammadali Memari",
      "Soghra Mikaeyl Nejad",
      "Amir Parsa Rabiei",
      "Mehrshad Eisaei",
      "Saba Hesaraki"
    ],
    "abstract": "Multidomain sentiment analysis involves estimating the polarity of an\nunstructured text by exploiting domain specific information. One of the main\nissues common to the approaches discussed in the literature is their poor\napplicability to domains that differ from those used to construct opinion\nmodels.This paper aims to present a new method for Persian multidomain SA\nanalysis using deep learning approaches. The proposed BERTCapsules approach\nconsists of a combination of BERT and Capsule models. In this approach, BERT\nwas used for Instance representation, and Capsule Structure was used to learn\nthe extracted graphs. Digikala dataset, including ten domains with both\npositive and negative polarity, was used to evaluate this approach. The\nevaluation of the BERTCaps model achieved an accuracy of 0.9712 in sentiment\nclassification binary classification and 0.8509 in domain classification .",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05591v1",
    "published_date": "2024-12-07 09:08:25 UTC",
    "updated_date": "2024-12-07 09:08:25 UTC"
  },
  {
    "arxiv_id": "2412.05587v2",
    "title": "GEE-OPs: An Operator Knowledge Base for Geospatial Code Generation on the Google Earth Engine Platform Powered by Large Language Models",
    "authors": [
      "Shuyang Hou",
      "Jianyuan Liang",
      "Anqi Zhao",
      "Huayi Wu"
    ],
    "abstract": "As the scale and complexity of spatiotemporal data continue to grow rapidly,\nthe use of geospatial modeling on the Google Earth Engine (GEE) platform\npresents dual challenges: improving the coding efficiency of domain experts and\nenhancing the coding capabilities of interdisciplinary users. To address these\nchallenges and improve the performance of large language models (LLMs) in\ngeospatial code generation tasks, we propose a framework for building a\ngeospatial operator knowledge base tailored to the GEE JavaScript API. This\nframework consists of an operator syntax knowledge table, an operator\nrelationship frequency table, an operator frequent pattern knowledge table, and\nan operator relationship chain knowledge table. By leveraging Abstract Syntax\nTree (AST) techniques and frequent itemset mining, we systematically extract\noperator knowledge from 185,236 real GEE scripts and syntax documentation,\nforming a structured knowledge base. Experimental results demonstrate that the\nframework achieves over 90% accuracy, recall, and F1 score in operator\nknowledge extraction. When integrated with the Retrieval-Augmented Generation\n(RAG) strategy for LLM-based geospatial code generation tasks, the knowledge\nbase improves performance by 20-30%. Ablation studies further quantify the\nnecessity of each knowledge table in the knowledge base construction. This work\nprovides robust support for the advancement and application of geospatial code\nmodeling techniques, offering an innovative approach to constructing\ndomain-specific knowledge bases that enhance the code generation capabilities\nof LLMs, and fostering the deeper integration of generative AI technologies\nwithin the field of geoinformatics.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05587v2",
    "published_date": "2024-12-07 08:50:24 UTC",
    "updated_date": "2024-12-11 13:56:40 UTC"
  },
  {
    "arxiv_id": "2412.05586v1",
    "title": "Towards Learning to Reason: Comparing LLMs with Neuro-Symbolic on Arithmetic Relations in Abstract Reasoning",
    "authors": [
      "Michael Hersche",
      "Giacomo Camposampiero",
      "Roger Wattenhofer",
      "Abu Sebastian",
      "Abbas Rahimi"
    ],
    "abstract": "This work compares large language models (LLMs) and neuro-symbolic approaches\nin solving Raven's progressive matrices (RPM), a visual abstract reasoning test\nthat involves the understanding of mathematical rules such as progression or\narithmetic addition. Providing the visual attributes directly as textual\nprompts, which assumes an oracle visual perception module, allows us to measure\nthe model's abstract reasoning capability in isolation. Despite providing such\ncompositionally structured representations from the oracle visual perception\nand advanced prompting techniques, both GPT-4 and Llama-3 70B cannot achieve\nperfect accuracy on the center constellation of the I-RAVEN dataset. Our\nanalysis reveals that the root cause lies in the LLM's weakness in\nunderstanding and executing arithmetic rules. As a potential remedy, we analyze\nthe Abductive Rule Learner with Context-awareness (ARLC), a neuro-symbolic\napproach that learns to reason with vector-symbolic architectures (VSAs). Here,\nconcepts are represented with distributed vectors s.t. dot products between\nencoded vectors define a similarity kernel, and simple element-wise operations\non the vectors perform addition/subtraction on the encoded values. We find that\nARLC achieves almost perfect accuracy on the center constellation of I-RAVEN,\ndemonstrating a high fidelity in arithmetic rules. To stress the length\ngeneralization capabilities of the models, we extend the RPM tests to larger\nmatrices (3x10 instead of typical 3x3) and larger dynamic ranges of the\nattribute values (from 10 up to 1000). We find that the LLM's accuracy of\nsolving arithmetic rules drops to sub-10%, especially as the dynamic range\nexpands, while ARLC can maintain a high accuracy due to emulating symbolic\ncomputations on top of properly distributed representations. Our code is\navailable at https://github.com/IBM/raven-large-language-models.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05586v1",
    "published_date": "2024-12-07 08:45:39 UTC",
    "updated_date": "2024-12-07 08:45:39 UTC"
  },
  {
    "arxiv_id": "2412.05585v1",
    "title": "UNet++ and LSTM combined approach for Breast Ultrasound Image Segmentation",
    "authors": [
      "Saba Hesaraki",
      "Morteza Akbari",
      "Ramin Mousa"
    ],
    "abstract": "Breast cancer stands as a prevalent cause of fatality among females on a\nglobal scale, with prompt detection playing a pivotal role in diminishing\nmortality rates. The utilization of ultrasound scans in the BUSI dataset for\nmedical imagery pertaining to breast cancer has exhibited commendable\nsegmentation outcomes through the application of UNet and UNet++ networks.\nNevertheless, a notable drawback of these models resides in their inattention\ntowards the temporal aspects embedded within the images. This research\nendeavors to enrich the UNet++ architecture by integrating LSTM layers and\nself-attention mechanisms to exploit temporal characteristics for segmentation\npurposes. Furthermore, the incorporation of a Multiscale Feature Extraction\nModule aims to grasp varied scale features within the UNet++. Through the\namalgamation of our proposed methodology with data augmentation on the BUSI\nwith GT dataset, an accuracy rate of 98.88%, specificity of 99.53%, precision\nof 95.34%, sensitivity of 91.20%, F1-score of 93.74, and Dice coefficient of\n92.74% are achieved. These findings demonstrate competitiveness with\ncutting-edge techniques outlined in existing literature.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05585v1",
    "published_date": "2024-12-07 08:39:31 UTC",
    "updated_date": "2024-12-07 08:39:31 UTC"
  },
  {
    "arxiv_id": "2412.05584v2",
    "title": "UMSPU: Universal Multi-Size Phase Unwrapping via Mutual Self-Distillation and Adaptive Boosting Ensemble Segmenters",
    "authors": [
      "Lintong Du",
      "Huazhen Liu",
      "Yijia Zhang",
      "ShuXin Liu",
      "Yuan Qu",
      "Zenghui Zhang",
      "Jiamiao Yang"
    ],
    "abstract": "Spatial phase unwrapping is a key technique for extracting phase information\nto obtain 3D morphology and other features. Modern industrial measurement\nscenarios demand high precision, large image sizes, and high speed. However,\nconventional methods struggle with noise resistance and processing speed.\nCurrent deep learning methods are limited by the receptive field size and\nsparse semantic information, making them ineffective for large size images. To\naddress this issue, we propose a mutual self-distillation (MSD) mechanism and\nadaptive boosting ensemble segmenters to construct a universal multi-size phase\nunwrapping network (UMSPU). MSD performs hierarchical attention refinement and\nachieves cross-layer collaborative learning through bidirectional distillation,\nensuring fine-grained semantic representation across image sizes. The adaptive\nboosting ensemble segmenters combine weak segmenters with different receptive\nfields into a strong one, ensuring stable segmentation across spatial\nfrequencies. Experimental results show that UMSPU overcomes image size\nlimitations, achieving high precision across image sizes ranging from 256*256\nto 2048*2048 (an 8 times increase). It also outperforms existing methods in\nspeed, robustness, and generalization. Its practicality is further validated in\nstructured light imaging and InSAR. We believe that UMSPU offers a universal\nsolution for phase unwrapping, with broad potential for industrial\napplications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05584v2",
    "published_date": "2024-12-07 08:38:29 UTC",
    "updated_date": "2025-04-17 03:41:57 UTC"
  },
  {
    "arxiv_id": "2412.05583v2",
    "title": "Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and Classification using Machine Learning Algorithms",
    "authors": [
      "Atit Pokharel",
      "Shashank Dahal",
      "Pratik Sapkota",
      "Bhupendra Bimal Chhetri"
    ],
    "abstract": "The rapid advancements in Artificial Intelligence, specifically Machine\nLearning (ML) and Deep Learning (DL), have opened new prospects in medical\nsciences for improved diagnosis, prognosis, and treatment of severe health\nconditions. This paper focuses on the development of an ML model with high\npredictive accuracy to classify arrhythmic electrocardiogram (ECG) signals. The\nECG signals datasets utilized in this study were sourced from the PhysioNet and\nMIT-BIH databases. The research commenced with binary classification, where an\noptimized Bidirectional Long Short-Term Memory (Bi-LSTM) model yielded\nexcellent results in differentiating normal and atrial fibrillation signals. A\npivotal aspect of this research was a survey among medical professionals, which\nnot only validated the practicality of AI-based ECG classifiers but also\nidentified areas for improvement, including accuracy and the inclusion of more\narrhythmia types. These insights drove the development of an advanced\nConvolutional Neural Network (CNN) system capable of classifying five different\ntypes of ECG signals with better accuracy and precision. The CNN model's robust\nperformance was ensured through rigorous stratified 5-fold cross validation. A\nweb portal was also developed to demonstrate real-world utility, offering\naccess to the trained model for real-time classification. This study highlights\nthe potential applications of such models in remote health monitoring,\npredictive healthcare, assistive diagnostic tools, and simulated environments\nfor educational training and interdisciplinary collaboration between data\nscientists and medical personnel.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05583v2",
    "published_date": "2024-12-07 08:29:44 UTC",
    "updated_date": "2024-12-10 15:35:33 UTC"
  },
  {
    "arxiv_id": "2412.05573v1",
    "title": "Neighborhood Commonality-aware Evolution Network for Continuous Generalized Category Discovery",
    "authors": [
      "Ye Wang",
      "Yaxiong Wang",
      "Guoshuai Zhao",
      "Xueming Qian"
    ],
    "abstract": "Continuous Generalized Category Discovery (C-GCD) aims to continually\ndiscover novel classes from unlabelled image sets while maintaining performance\non old classes. In this paper, we propose a novel learning framework, dubbed\nNeighborhood Commonality-aware Evolution Network (NCENet) that conquers this\ntask from the perspective of representation learning. Concretely, to learn\ndiscriminative representations for novel classes, a Neighborhood\nCommonality-aware Representation Learning (NCRL) is designed, which exploits\nlocal commonalities derived neighborhoods to guide the learning of\nrepresentational differences between instances of different classes. To\nmaintain the representation ability for old classes, a Bi-level Contrastive\nKnowledge Distillation (BCKD) module is designed, which leverages contrastive\nlearning to perceive the learning and learned knowledge and conducts knowledge\ndistillation. Extensive experiments conducted on CIFAR10, CIFAR100, and\nTiny-ImageNet demonstrate the superior performance of NCENet compared to the\nprevious state-of-the-art method. Particularly, in the last incremental\nlearning session on CIFAR100, the clustering accuracy of NCENet outperforms the\nsecond-best method by a margin of 3.09\\% on old classes and by a margin of\n6.32\\% on new classes. Our code will be publicly available at\n\\href{https://github.com/xjtuYW/NCENet.git}{https://github.com/xjtuYW/NCENet.git}.\n\\end{abstract}",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 7 Figures",
    "pdf_url": "http://arxiv.org/pdf/2412.05573v1",
    "published_date": "2024-12-07 07:41:41 UTC",
    "updated_date": "2024-12-07 07:41:41 UTC"
  },
  {
    "arxiv_id": "2501.01960v1",
    "title": "GAF-FusionNet: Multimodal ECG Analysis via Gramian Angular Fields and Split Attention",
    "authors": [
      "Jiahao Qin",
      "Feng Liu"
    ],
    "abstract": "Electrocardiogram (ECG) analysis plays a crucial role in diagnosing\ncardiovascular diseases, but accurate interpretation of these complex signals\nremains challenging. This paper introduces a novel multimodal\nframework(GAF-FusionNet) for ECG classification that integrates time-series\nanalysis with image-based representation using Gramian Angular Fields (GAF).\nOur approach employs a dual-layer cross-channel split attention module to\nadaptively fuse temporal and spatial features, enabling nuanced integration of\ncomplementary information. We evaluate GAF-FusionNet on three diverse ECG\ndatasets: ECG200, ECG5000, and the MIT-BIH Arrhythmia Database. Results\ndemonstrate significant improvements over state-of-the-art methods, with our\nmodel achieving 94.5\\%, 96.9\\%, and 99.6\\% accuracy on the respective datasets.\nOur code will soon be available at\nhttps://github.com/Cross-Innovation-Lab/GAF-FusionNet.git.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 1 figure, accepted by ICONIP 2024",
    "pdf_url": "http://arxiv.org/pdf/2501.01960v1",
    "published_date": "2024-12-07 07:02:16 UTC",
    "updated_date": "2024-12-07 07:02:16 UTC"
  },
  {
    "arxiv_id": "2412.05563v1",
    "title": "A Survey on Uncertainty Quantification of Large Language Models: Taxonomy, Open Research Challenges, and Future Directions",
    "authors": [
      "Ola Shorinwa",
      "Zhiting Mei",
      "Justin Lidard",
      "Allen Z. Ren",
      "Anirudha Majumdar"
    ],
    "abstract": "The remarkable performance of large language models (LLMs) in content\ngeneration, coding, and common-sense reasoning has spurred widespread\nintegration into many facets of society. However, integration of LLMs raises\nvalid questions on their reliability and trustworthiness, given their\npropensity to generate hallucinations: plausible, factually-incorrect\nresponses, which are expressed with striking confidence. Previous work has\nshown that hallucinations and other non-factual responses generated by LLMs can\nbe detected by examining the uncertainty of the LLM in its response to the\npertinent prompt, driving significant research efforts devoted to quantifying\nthe uncertainty of LLMs. This survey seeks to provide an extensive review of\nexisting uncertainty quantification methods for LLMs, identifying their salient\nfeatures, along with their strengths and weaknesses. We present existing\nmethods within a relevant taxonomy, unifying ostensibly disparate methods to\naid understanding of the state of the art. Furthermore, we highlight\napplications of uncertainty quantification methods for LLMs, spanning chatbot\nand textual applications to embodied artificial intelligence applications in\nrobotics. We conclude with open research challenges in uncertainty\nquantification of LLMs, seeking to motivate future research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05563v1",
    "published_date": "2024-12-07 06:56:01 UTC",
    "updated_date": "2024-12-07 06:56:01 UTC"
  },
  {
    "arxiv_id": "2412.05562v1",
    "title": "On the Expressive Power of Modern Hopfield Networks",
    "authors": [
      "Xiaoyu Li",
      "Yuanpeng Li",
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song"
    ],
    "abstract": "Modern Hopfield networks (MHNs) have emerged as powerful tools in deep\nlearning, capable of replacing components such as pooling layers, LSTMs, and\nattention mechanisms. Recent advancements have enhanced their storage capacity,\nretrieval speed, and error rates. However, the fundamental limits of their\ncomputational expressiveness remain unexplored. Understanding the expressive\npower of MHNs is crucial for optimizing their integration into deep learning\narchitectures. In this work, we establish rigorous theoretical bounds on the\ncomputational capabilities of MHNs using circuit complexity theory. Our key\ncontribution is that we show that MHNs are $\\mathsf{DLOGTIME}$-uniform\n$\\mathsf{TC}^0$. Hence, unless $\\mathsf{TC}^0 = \\mathsf{NC}^1$, a\n$\\mathrm{poly}(n)$-precision modern Hopfield networks with a constant number of\nlayers and $O(n)$ hidden dimension cannot solve $\\mathsf{NC}^1$-hard problems\nsuch as the undirected graph connectivity problem and the tree isomorphism\nproblem. We also extended our results to Kernelized Hopfield Networks. These\nresults demonstrate the limitation in the expressive power of the modern\nHopfield networks. Moreover, Our theoretical analysis provides insights to\nguide the development of new Hopfield-based architectures.",
    "categories": [
      "cs.CC",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05562v1",
    "published_date": "2024-12-07 06:52:41 UTC",
    "updated_date": "2024-12-07 06:52:41 UTC"
  },
  {
    "arxiv_id": "2412.05560v1",
    "title": "Text-to-3D Gaussian Splatting with Physics-Grounded Motion Generation",
    "authors": [
      "Wenqing Wang",
      "Yun Fu"
    ],
    "abstract": "Text-to-3D generation is a valuable technology in virtual reality and digital\ncontent creation. While recent works have pushed the boundaries of text-to-3D\ngeneration, producing high-fidelity 3D objects with inefficient prompts and\nsimulating their physics-grounded motion accurately still remain unsolved\nchallenges. To address these challenges, we present an innovative framework\nthat utilizes the Large Language Model (LLM)-refined prompts and diffusion\npriors-guided Gaussian Splatting (GS) for generating 3D models with accurate\nappearances and geometric structures. We also incorporate a continuum\nmechanics-based deformation map and color regularization to synthesize vivid\nphysics-grounded motion for the generated 3D Gaussians, adhering to the\nconservation of mass and momentum. By integrating text-to-3D generation with\nphysics-grounded motion synthesis, our framework renders photo-realistic 3D\nobjects that exhibit physics-aware motion, accurately reflecting the behaviors\nof the objects under various forces and constraints across different materials.\nExtensive experiments demonstrate that our approach achieves high-quality 3D\ngenerations with realistic physics-grounded motion.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05560v1",
    "published_date": "2024-12-07 06:48:16 UTC",
    "updated_date": "2024-12-07 06:48:16 UTC"
  },
  {
    "arxiv_id": "2412.05558v1",
    "title": "WavFusion: Towards wav2vec 2.0 Multimodal Speech Emotion Recognition",
    "authors": [
      "Feng Li",
      "Jiusong Luo",
      "Wanjun Xia"
    ],
    "abstract": "Speech emotion recognition (SER) remains a challenging yet crucial task due\nto the inherent complexity and diversity of human emotions. To address this\nproblem, researchers attempt to fuse information from other modalities via\nmultimodal learning. However, existing multimodal fusion techniques often\noverlook the intricacies of cross-modal interactions, resulting in suboptimal\nfeature representations. In this paper, we propose WavFusion, a multimodal\nspeech emotion recognition framework that addresses critical research problems\nin effective multimodal fusion, heterogeneity among modalities, and\ndiscriminative representation learning. By leveraging a gated cross-modal\nattention mechanism and multimodal homogeneous feature discrepancy learning,\nWavFusion demonstrates improved performance over existing state-of-the-art\nmethods on benchmark datasets. Our work highlights the importance of capturing\nnuanced cross-modal interactions and learning discriminative representations\nfor accurate multimodal SER. Experimental results on two benchmark datasets\n(IEMOCAP and MELD) demonstrate that WavFusion succeeds over the\nstate-of-the-art strategies on emotion recognition.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by 31st International Conference on MultiMedia Modeling\n  (MMM2025)",
    "pdf_url": "http://arxiv.org/pdf/2412.05558v1",
    "published_date": "2024-12-07 06:43:39 UTC",
    "updated_date": "2024-12-07 06:43:39 UTC"
  },
  {
    "arxiv_id": "2412.06839v1",
    "title": "A Neural Model of Rule Discovery with Relatively Short-Term Sequence Memory",
    "authors": [
      "Naoya Arakawa"
    ],
    "abstract": "This report proposes a neural cognitive model for discovering regularities in\nevent sequences. In a fluid intelligence task, the subject is required to\ndiscover regularities from relatively short-term memory of the first-seen task.\nSome fluid intelligence tasks require discovering regularities in event\nsequences. Thus, a neural network model was constructed to explain fluid\nintelligence or regularity discovery in event sequences with relatively\nshort-term memory. The model was implemented and tested with delayed\nmatch-to-sample tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06839v1",
    "published_date": "2024-12-07 06:38:41 UTC",
    "updated_date": "2024-12-07 06:38:41 UTC"
  },
  {
    "arxiv_id": "2412.05555v1",
    "title": "Fragmented Layer Grouping in GUI Designs Through Graph Learning Based on Multimodal Information",
    "authors": [
      "Yunnong Chen",
      "Shuhong Xiao",
      "Jiazhi Li",
      "Tingting Zhou",
      "Yanfang Chang",
      "Yankun Zhen",
      "Lingyun Sun",
      "Liuqing Chen"
    ],
    "abstract": "Automatically constructing GUI groups of different granularities constitutes\na critical intelligent step towards automating GUI design and implementation\ntasks. Specifically, in the industrial GUI-to-code process, fragmented layers\nmay decrease the readability and maintainability of generated code, which can\nbe alleviated by grouping semantically consistent fragmented layers in the\ndesign prototypes. This study aims to propose a graph-learning-based approach\nto tackle the fragmented layer grouping problem according to multi-modal\ninformation in design prototypes. Our graph learning module consists of\nself-attention and graph neural network modules. By taking the multimodal fused\nrepresentation of GUI layers as input, we innovatively group fragmented layers\nby classifying GUI layers and regressing the bounding boxes of the\ncorresponding GUI components simultaneously. Experiments on two real-world\ndatasets demonstrate that our model achieves state-of-the-art performance. A\nfurther user study is also conducted to validate that our approach can assist\nan intelligent downstream tool in generating more maintainable and readable\nfront-end code.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "28 pages,6 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.05555v1",
    "published_date": "2024-12-07 06:31:09 UTC",
    "updated_date": "2024-12-07 06:31:09 UTC"
  },
  {
    "arxiv_id": "2412.05552v1",
    "title": "SAME: Learning Generic Language-Guided Visual Navigation with State-Adaptive Mixture of Experts",
    "authors": [
      "Gengze Zhou",
      "Yicong Hong",
      "Zun Wang",
      "Chongyang Zhao",
      "Mohit Bansal",
      "Qi Wu"
    ],
    "abstract": "The academic field of learning instruction-guided visual navigation can be\ngenerally categorized into high-level category-specific search and low-level\nlanguage-guided navigation, depending on the granularity of language\ninstruction, in which the former emphasizes the exploration process, while the\nlatter concentrates on following detailed textual commands. Despite the\ndiffering focuses of these tasks, the underlying requirements of interpreting\ninstructions, comprehending the surroundings, and inferring action decisions\nremain consistent. This paper consolidates diverse navigation tasks into a\nunified and generic framework -- we investigate the core difficulties of\nsharing general knowledge and exploiting task-specific capabilities in learning\nnavigation and propose a novel State-Adaptive Mixture of Experts (SAME) model\nthat effectively enables an agent to infer decisions based on\ndifferent-granularity language and dynamic observations. Powered by SAME, we\npresent a versatile agent capable of addressing seven navigation tasks\nsimultaneously that outperforms or achieves highly comparable performance to\ntask-specific agents.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05552v1",
    "published_date": "2024-12-07 06:12:53 UTC",
    "updated_date": "2024-12-07 06:12:53 UTC"
  },
  {
    "arxiv_id": "2412.05547v2",
    "title": "KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models",
    "authors": [
      "Weijie Chen",
      "Ting Bai",
      "Jinbo Su",
      "Jian Luan",
      "Wei Liu",
      "Chuan Shi"
    ],
    "abstract": "Large language models with retrieval-augmented generation encounter a pivotal\nchallenge in intricate retrieval tasks, e.g., multi-hop question answering,\nwhich requires the model to navigate across multiple documents and generate\ncomprehensive responses based on fragmented information. To tackle this\nchallenge, we introduce a novel Knowledge Graph-based RAG framework with a\nhierarchical knowledge retriever, termed KG-Retriever. The retrieval indexing\nin KG-Retriever is constructed on a hierarchical index graph that consists of a\nknowledge graph layer and a collaborative document layer. The associative\nnature of graph structures is fully utilized to strengthen intra-document and\ninter-document connectivity, thereby fundamentally alleviating the information\nfragmentation problem and meanwhile improving the retrieval efficiency in\ncross-document retrieval of LLMs. With the coarse-grained collaborative\ninformation from neighboring documents and concise information from the\nknowledge graph, KG-Retriever achieves marked improvements on five public QA\ndatasets, showing the effectiveness and efficiency of our proposed RAG\nframework.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05547v2",
    "published_date": "2024-12-07 05:49:14 UTC",
    "updated_date": "2025-05-05 09:26:24 UTC"
  },
  {
    "arxiv_id": "2412.10410v1",
    "title": "GROOT-2: Weakly Supervised Multi-Modal Instruction Following Agents",
    "authors": [
      "Shaofei Cai",
      "Bowei Zhang",
      "Zihao Wang",
      "Haowei Lin",
      "Xiaojian Ma",
      "Anji Liu",
      "Yitao Liang"
    ],
    "abstract": "Developing agents that can follow multimodal instructions remains a\nfundamental challenge in robotics and AI. Although large-scale pre-training on\nunlabeled datasets (no language instruction) has enabled agents to learn\ndiverse behaviors, these agents often struggle with following instructions.\nWhile augmenting the dataset with instruction labels can mitigate this issue,\nacquiring such high-quality annotations at scale is impractical. To address\nthis issue, we frame the problem as a semi-supervised learning task and\nintroduce GROOT-2, a multimodal instructable agent trained using a novel\napproach that combines weak supervision with latent variable models. Our method\nconsists of two key components: constrained self-imitating, which utilizes\nlarge amounts of unlabeled demonstrations to enable the policy to learn diverse\nbehaviors, and human intention alignment, which uses a smaller set of labeled\ndemonstrations to ensure the latent space reflects human intentions. GROOT-2's\neffectiveness is validated across four diverse environments, ranging from video\ngames to robotic manipulation, demonstrating its robust multimodal\ninstruction-following capabilities.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.10410v1",
    "published_date": "2024-12-07 05:47:49 UTC",
    "updated_date": "2024-12-07 05:47:49 UTC"
  },
  {
    "arxiv_id": "2412.06837v1",
    "title": "Innovative Sentiment Analysis and Prediction of Stock Price Using FinBERT, GPT-4 and Logistic Regression: A Data-Driven Approach",
    "authors": [
      "Olamilekan Shobayo",
      "Sidikat Adeyemi-Longe",
      "Olusogo Popoola",
      "Bayode Ogunleye"
    ],
    "abstract": "This study explores the comparative performance of cutting-edge AI models,\ni.e., Finaance Bidirectional Encoder representations from Transsformers\n(FinBERT), Generatice Pre-trained Transformer GPT-4, and Logistic Regression,\nfor sentiment analysis and stock index prediction using financial news and the\nNGX All-Share Index data label. By leveraging advanced natural language\nprocessing models like GPT-4 and FinBERT, alongside a traditional machine\nlearning model, Logistic Regression, we aim to classify market sentiment,\ngenerate sentiment scores, and predict market price movements. This research\nhighlights global AI advancements in stock markets, showcasing how\nstate-of-the-art language models can contribute to understanding complex\nfinancial data. The models were assessed using metrics such as accuracy,\nprecision, recall, F1 score, and ROC AUC. Results indicate that Logistic\nRegression outperformed the more computationally intensive FinBERT and\npredefined approach of versatile GPT-4, with an accuracy of 81.83% and a ROC\nAUC of 89.76%. The GPT-4 predefined approach exhibited a lower accuracy of\n54.19% but demonstrated strong potential in handling complex data. FinBERT,\nwhile offering more sophisticated analysis, was resource-demanding and yielded\na moderate performance. Hyperparameter optimization using Optuna and\ncross-validation techniques ensured the robustness of the models. This study\nhighlights the strengths and limitations of the practical applications of AI\napproaches in stock market prediction and presents Logistic Regression as the\nmost efficient model for this task, with FinBERT and GPT-4 representing\nemerging tools with potential for future exploration and innovation in\nAI-driven financial analytics",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.ST",
      "stat.AP",
      "stat.CO",
      "H.3.3"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.06837v1",
    "published_date": "2024-12-07 05:20:31 UTC",
    "updated_date": "2024-12-07 05:20:31 UTC"
  },
  {
    "arxiv_id": "2412.05540v1",
    "title": "Towards 3D Acceleration for low-power Mixture-of-Experts and Multi-Head Attention Spiking Transformers",
    "authors": [
      "Boxun Xu",
      "Junyoung Hwang",
      "Pruek Vanna-iampikul",
      "Yuxuan Yin",
      "Sung Kyu Lim",
      "Peng Li"
    ],
    "abstract": "Spiking Neural Networks(SNNs) provide a brain-inspired and event-driven\nmechanism that is believed to be critical to unlock energy-efficient deep\nlearning. The mixture-of-experts approach mirrors the parallel distributed\nprocessing of nervous systems, introducing conditional computation policies and\nexpanding model capacity without scaling up the number of computational\noperations. Additionally, spiking mixture-of-experts self-attention mechanisms\nenhance representation capacity, effectively capturing diverse patterns of\nentities and dependencies between visual or linguistic tokens. However, there\nis currently a lack of hardware support for highly parallel distributed\nprocessing needed by spiking transformers, which embody a brain-inspired\ncomputation. This paper introduces the first 3D hardware architecture and\ndesign methodology for Mixture-of-Experts and Multi-Head Attention spiking\ntransformers. By leveraging 3D integration with memory-on-logic and\nlogic-on-logic stacking, we explore such brain-inspired accelerators with\nspatially stackable circuitry, demonstrating significant optimization of energy\nefficiency and latency compared to conventional 2D CMOS integration.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05540v1",
    "published_date": "2024-12-07 05:15:05 UTC",
    "updated_date": "2024-12-07 05:15:05 UTC"
  },
  {
    "arxiv_id": "2501.01959v1",
    "title": "STEAM-EEG: Spatiotemporal EEG Analysis with Markov Transfer Fields and Attentive CNNs",
    "authors": [
      "Jiahao Qin",
      "Feng Liu"
    ],
    "abstract": "Electroencephalogram (EEG) signals play a pivotal role in biomedical research\nand clinical applications, including epilepsy diagnosis, sleep disorder\nanalysis, and brain-computer interfaces. However, the effective analysis and\ninterpretation of these complex signals often present significant challenges.\nThis paper presents a novel approach that integrates computer graphics\ntechniques with biological signal pattern recognition, specifically using\nMarkov Transfer Fields (MTFs) for EEG time series imaging. The proposed\nframework (STEAM-EEG) employs the capabilities of MTFs to capture the\nspatiotemporal dynamics of EEG signals, transforming them into visually\ninformative images. These images are then rendered, visualised, and modelled\nusing state-of-the-art computer graphics techniques, thereby facilitating\nenhanced data exploration, pattern recognition, and decision-making. The code\ncould be accessed from GitHub.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.01959v1",
    "published_date": "2024-12-07 05:07:20 UTC",
    "updated_date": "2024-12-07 05:07:20 UTC"
  },
  {
    "arxiv_id": "2412.06836v1",
    "title": "GRUvader: Sentiment-Informed Stock Market Prediction",
    "authors": [
      "Akhila Mamillapalli",
      "Bayode Ogunleye",
      "Sonia Timoteo Inacio",
      "Olamilekan Shobayo"
    ],
    "abstract": "Stock price prediction is challenging due to global economic instability,\nhigh volatility, and the complexity of financial markets. Hence, this study\ncompared several machine learning algorithms for stock market prediction and\nfurther examined the influence of a sentiment analysis indicator on the\nprediction of stock prices. Our results were two-fold. Firstly, we used a\nlexicon-based sentiment analysis approach to identify sentiment features, thus\nevidencing the correlation between the sentiment indicator and stock price\nmovement. Secondly, we proposed the use of GRUvader, an optimal gated recurrent\nunit network, for stock market prediction. Our findings suggest that\nstand-alone models struggled compared with AI-enhanced models. Thus, our paper\nmakes further recommendations on latter systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP",
      "H.3.3"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.06836v1",
    "published_date": "2024-12-07 04:56:17 UTC",
    "updated_date": "2024-12-07 04:56:17 UTC"
  },
  {
    "arxiv_id": "2412.05536v1",
    "title": "Comprehensive Evaluation of Multimodal AI Models in Medical Imaging Diagnosis: From Data Augmentation to Preference-Based Comparison",
    "authors": [
      "Cailian Ruan",
      "Chengyue Huang",
      "Yahe Yang"
    ],
    "abstract": "This study introduces an evaluation framework for multimodal models in\nmedical imaging diagnostics. We developed a pipeline incorporating data\npreprocessing, model inference, and preference-based evaluation, expanding an\ninitial set of 500 clinical cases to 3,000 through controlled augmentation. Our\nmethod combined medical images with clinical observations to generate\nassessments, using Claude 3.5 Sonnet for independent evaluation against\nphysician-authored diagnoses. The results indicated varying performance across\nmodels, with Llama 3.2-90B outperforming human diagnoses in 85.27% of cases. In\ncontrast, specialized vision models like BLIP2 and Llava showed preferences in\n41.36% and 46.77% of cases, respectively. This framework highlights the\npotential of large multimodal models to outperform human diagnostics in certain\ntasks.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05536v1",
    "published_date": "2024-12-07 04:38:44 UTC",
    "updated_date": "2024-12-07 04:38:44 UTC"
  },
  {
    "arxiv_id": "2412.05534v1",
    "title": "Memory-enhanced Invariant Prompt Learning for Urban Flow Prediction under Distribution Shifts",
    "authors": [
      "Haiyang Jiang",
      "Tong Chen",
      "Wentao Zhang",
      "Nguyen Quoc Viet Hung",
      "Yuan Yuan",
      "Yong Li",
      "Lizhen Cui"
    ],
    "abstract": "Urban flow prediction is a classic spatial-temporal forecasting task that\nestimates the amount of future traffic flow for a given location. Though models\nrepresented by Spatial-Temporal Graph Neural Networks (STGNNs) have established\nthemselves as capable predictors, they tend to suffer from distribution shifts\nthat are common with the urban flow data due to the dynamics and\nunpredictability of spatial-temporal events. Unfortunately, in spatial-temporal\napplications, the dynamic environments can hardly be quantified via a fixed\nnumber of parameters, whereas learning time- and location-specific environments\ncan quickly become computationally prohibitive. In this paper, we propose a\nnovel framework named Memory-enhanced Invariant Prompt learning (MIP) for urban\nflow prediction under constant distribution shifts. Specifically, MIP is\nequipped with a learnable memory bank that is trained to memorize the causal\nfeatures within the spatial-temporal graph. By querying a trainable memory bank\nthat stores the causal features, we adaptively extract invariant and variant\nprompts (i.e., patterns) for a given location at every time step. Then, instead\nof intervening the raw data based on simulated environments, we directly\nperform intervention on variant prompts across space and time. With the\nintervened variant prompts in place, we use invariant learning to minimize the\nvariance of predictions, so as to ensure that the predictions are only made\nwith invariant features. With extensive comparative experiments on two public\nurban flow datasets, we thoroughly demonstrate the robustness of MIP against\nOOD data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05534v1",
    "published_date": "2024-12-07 04:35:07 UTC",
    "updated_date": "2024-12-07 04:35:07 UTC"
  },
  {
    "arxiv_id": "2412.05528v1",
    "title": "AI Planning: A Primer and Survey (Preliminary Report)",
    "authors": [
      "Dillon Z. Chen",
      "Pulkit Verma",
      "Siddharth Srivastava",
      "Michael Katz",
      "Sylvie Thibaux"
    ],
    "abstract": "Automated decision-making is a fundamental topic that spans multiple\nsub-disciplines in AI: reinforcement learning (RL), AI planning (AP),\nfoundation models, and operations research, among others. Despite recent\nefforts to ``bridge the gaps'' between these communities, there remain many\ninsights that have not yet transcended the boundaries. Our goal in this paper\nis to provide a brief and non-exhaustive primer on ideas well-known in AP, but\nless so in other sub-disciplines. We do so by introducing the classical AP\nproblem and representation, and extensions that handle uncertainty and time\nthrough the Markov Decision Process formalism. Next, we survey state-of-the-art\ntechniques and ideas for solving AP problems, focusing on their ability to\nexploit problem structure. Lastly, we cover subfields within AP for learning\nstructure from unstructured inputs and learning to generalise to unseen\nscenarios and situations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05528v1",
    "published_date": "2024-12-07 04:00:25 UTC",
    "updated_date": "2024-12-07 04:00:25 UTC"
  },
  {
    "arxiv_id": "2412.05520v1",
    "title": "More than Marketing? On the Information Value of AI Benchmarks for Practitioners",
    "authors": [
      "Amelia Hardy",
      "Anka Reuel",
      "Kiana Jafari Meimandi",
      "Lisa Soder",
      "Allie Griffith",
      "Dylan M. Asmar",
      "Sanmi Koyejo",
      "Michael S. Bernstein",
      "Mykel J. Kochenderfer"
    ],
    "abstract": "Public AI benchmark results are widely broadcast by model developers as\nindicators of model quality within a growing and competitive market. However,\nthese advertised scores do not necessarily reflect the traits of interest to\nthose who will ultimately apply AI models. In this paper, we seek to understand\nif and how AI benchmarks are used to inform decision-making. Based on the\nanalyses of interviews with 19 individuals who have used, or decided against\nusing, benchmarks in their day-to-day work, we find that across these settings,\nparticipants use benchmarks as a signal of relative performance difference\nbetween models. However, whether this signal was considered a definitive sign\nof model superiority, sufficient for downstream decisions, varied. In academia,\npublic benchmarks were generally viewed as suitable measures for capturing\nresearch progress. By contrast, in both product and policy, benchmarks -- even\nthose developed internally for specific tasks -- were often found to be\ninadequate for informing substantive decisions. Of the benchmarks deemed\nunsatisfactory, respondents reported that their goals were neither well-defined\nnor reflective of real-world use. Based on the study results, we conclude that\neffective benchmarks should provide meaningful, real-world evaluations,\nincorporate domain expertise, and maintain transparency in scope and goals.\nThey must capture diverse, task-relevant capabilities, be challenging enough to\navoid quick saturation, and account for trade-offs in model performance rather\nthan relying on a single score. Additionally, proprietary data collection and\ncontamination prevention are critical for producing reliable and actionable\nresults. By adhering to these criteria, benchmarks can move beyond mere\nmarketing tricks into robust evaluative frameworks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05520v1",
    "published_date": "2024-12-07 03:35:39 UTC",
    "updated_date": "2024-12-07 03:35:39 UTC"
  },
  {
    "arxiv_id": "2412.06835v1",
    "title": "APS-LSTM: Exploiting Multi-Periodicity and Diverse Spatial Dependencies for Flood Forecasting",
    "authors": [
      "Jun Feng",
      "Xueyi Liu",
      "Jiamin Lu",
      "Pingping Shao"
    ],
    "abstract": "Accurate flood prediction is crucial for disaster prevention and mitigation.\nHydrological data exhibit highly nonlinear temporal patterns and encompass\ncomplex spatial relationships between rainfall and flow. Existing flood\nprediction models struggle to capture these intricate temporal features and\nspatial dependencies. This paper presents an adaptive periodic and spatial\nself-attention method based on LSTM (APS-LSTM) to address these challenges. The\nAPS-LSTM learns temporal features from a multi-periodicity perspective and\ncaptures diverse spatial dependencies from different period divisions. The\nAPS-LSTM consists of three main stages, (i) Multi-Period Division, that\nutilizes Fast Fourier Transform (FFT) to divide various periodic patterns; (ii)\nSpatio-Temporal Information Extraction, that performs periodic and spatial\nself-attention focusing on intra- and inter-periodic temporal patterns and\nspatial dependencies; (iii) Adaptive Aggregation, that relies on amplitude\nstrength to aggregate the computational results from each periodic division.\nThe abundant experiments on two real-world datasets demonstrate the superiority\nof APS-LSTM. The code is available: https://github.com/oopcmd/APS-LSTM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Received by IEEE SMC",
    "pdf_url": "http://arxiv.org/pdf/2412.06835v1",
    "published_date": "2024-12-07 03:02:16 UTC",
    "updated_date": "2024-12-07 03:02:16 UTC"
  },
  {
    "arxiv_id": "2412.05505v1",
    "title": "Trimming Down Large Spiking Vision Transformers via Heterogeneous Quantization Search",
    "authors": [
      "Boxun Xu",
      "Yufei Song",
      "Peng Li"
    ],
    "abstract": "Spiking Neural Networks (SNNs) are amenable to deployment on edge devices and\nneuromorphic hardware due to their lower dissipation. Recently, SNN-based\ntransformers have garnered significant interest, incorporating attention\nmechanisms akin to their counterparts in Artificial Neural Networks (ANNs)\nwhile demonstrating excellent performance. However, deploying large spiking\ntransformer models on resource-constrained edge devices such as mobile phones,\nstill poses significant challenges resulted from the high computational demands\nof large uncompressed high-precision models. In this work, we introduce a novel\nheterogeneous quantization method for compressing spiking transformers through\nlayer-wise quantization. Our approach optimizes the quantization of each layer\nusing one of two distinct quantization schemes, i.e., uniform or power-of-two\nquantification, with mixed bit resolutions. Our heterogeneous quantization\ndemonstrates the feasibility of maintaining high performance for spiking\ntransformers while utilizing an average effective resolution of 3.14-3.67 bits\nwith less than a 1% accuracy drop on DVS Gesture and CIFAR10-DVS datasets. It\nattains a model compression rate of 8.71x-10.19x for standard floating-point\nspiking transformers. Moreover, the proposed approach achieves a significant\nenergy reduction of 5.69x, 8.72x, and 10.2x while maintaining high accuracy\nlevels of 85.3%, 97.57%, and 80.4% on N-Caltech101, DVS-Gesture, and\nCIFAR10-DVS datasets, respectively.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05505v1",
    "published_date": "2024-12-07 02:34:02 UTC",
    "updated_date": "2024-12-07 02:34:02 UTC"
  },
  {
    "arxiv_id": "2412.06834v2",
    "title": "Investigating social alignment via mirroring in a system of interacting language models",
    "authors": [
      "Harvey McGuinness",
      "Tianyu Wang",
      "Carey E. Priebe",
      "Hayden Helm"
    ],
    "abstract": "Alignment is a social phenomenon wherein individuals share a common goal or\nperspective. Mirroring, or mimicking the behaviors and opinions of another\nindividual, is one mechanism by which individuals can become aligned. Large\nscale investigations of the effect of mirroring on alignment have been limited\ndue to the scalability of traditional experimental designs in sociology. In\nthis paper, we introduce a simple computational framework that enables studying\nthe effect of mirroring behavior on alignment in multi-agent systems. We\nsimulate systems of interacting large language models in this framework and\ncharacterize overall system behavior and alignment with quantitative measures\nof agent dynamics. We find that system behavior is strongly influenced by the\nrange of communication of each agent and that these effects are exacerbated by\nincreased rates of mirroring. We discuss the observed simulated system behavior\nin the context of known human social dynamics.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06834v2",
    "published_date": "2024-12-07 02:19:57 UTC",
    "updated_date": "2025-02-15 23:16:43 UTC"
  },
  {
    "arxiv_id": "2412.06833v1",
    "title": "Detecting Fake News on Social Media: A Novel Reliability Aware Machine-Crowd Hybrid Intelligence-Based Method",
    "authors": [
      "Yidong Chai",
      "Kangwei Shi",
      "Jiaheng Xie",
      "Chunli Liu",
      "Yuanchun Jiang",
      "Yezheng Liu"
    ],
    "abstract": "Fake news on social media platforms poses a significant threat to societal\nsystems, underscoring the urgent need for advanced detection methods. The\nexisting detection methods can be divided into machine intelligence-based,\ncrowd intelligence-based, and hybrid intelligence-based methods. Among them,\nhybrid intelligence-based methods achieve the best performance but fail to\nconsider the reliability issue in detection. In light of this, we propose a\nnovel Reliability Aware Hybrid Intelligence (RAHI) method for fake news\ndetection. Our method comprises three integral modules. The first module\nemploys a Bayesian deep learning model to capture the inherent reliability\nwithin machine intelligence. The second module uses an Item Response Theory\n(IRT)-based user response aggregation to account for the reliability in crowd\nintelligence. The third module introduces a new distribution fusion mechanism,\nwhich takes the distributions derived from both machine and crowd intelligence\nas input, and outputs a fused distribution that provides predictions along with\nthe associated reliability. The experiments on the Weibo dataset demonstrate\nthe advantages of our method. This study contributes to the research field with\na novel RAHI-based method, and the code is shared at\nhttps://github.com/Kangwei-g/RAHI. This study has practical implications for\nthree key stakeholders: internet users, online platform managers, and the\ngovernment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06833v1",
    "published_date": "2024-12-07 02:10:21 UTC",
    "updated_date": "2024-12-07 02:10:21 UTC"
  },
  {
    "arxiv_id": "2412.05498v1",
    "title": "A New Perspective on Time Series Anomaly Detection: Faster Patch-based Broad Learning System",
    "authors": [
      "Pengyu Li",
      "Zhijie Zhong",
      "Tong Zhang",
      "Zhiwen Yu",
      "C. L. Philip Chen",
      "Kaixiang Yang"
    ],
    "abstract": "Time series anomaly detection (TSAD) has been a research hotspot in both\nacademia and industry in recent years. Deep learning methods have become the\nmainstream research direction due to their excellent performance. However, new\nviewpoints have emerged in recent TSAD research. Deep learning is not required\nfor TSAD due to limitations such as slow deep learning speed. The Broad\nLearning System (BLS) is a shallow network framework that benefits from its\nease of optimization and speed. It has been shown to outperform machine\nlearning approaches while remaining competitive with deep learning. Based on\nthe current situation of TSAD, we propose the Contrastive Patch-based Broad\nLearning System (CPatchBLS). This is a new exploration of patching technique\nand BLS, providing a new perspective for TSAD. We construct Dual-PatchBLS as a\nbase through patching and Simple Kernel Perturbation (SKP) and utilize\ncontrastive learning to capture the differences between normal and abnormal\ndata under different representations. To compensate for the temporal semantic\nloss caused by various patching, we propose CPatchBLS with model level\nintegration, which takes advantage of BLS's fast feature to build model-level\nintegration and improve model detection. Using five real-world series anomaly\ndetection datasets, we confirmed the method's efficacy, outperforming previous\ndeep learning and machine learning methods while retaining a high level of\ncomputing efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 7 figures, 3 tables, Under review",
    "pdf_url": "http://arxiv.org/pdf/2412.05498v1",
    "published_date": "2024-12-07 01:58:18 UTC",
    "updated_date": "2024-12-07 01:58:18 UTC"
  },
  {
    "arxiv_id": "2412.06832v2",
    "title": "SLA Management in Reconfigurable Multi-Agent RAG: A Systems Approach to Question Answering",
    "authors": [
      "Michael Iannelli",
      "Sneha Kuchipudi",
      "Vera Dvorak"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) enables Large Language Models (LLMs) to\ngeneralize to new information by decoupling reasoning capabilities from static\nknowledge bases. Traditional RAG enhancements have explored vertical\nscaling-assigning subtasks to specialized modules-and horizontal\nscaling-replicating tasks across multiple agents-to improve performance.\nHowever, real-world applications impose diverse Service Level Agreements (SLAs)\nand Quality of Service (QoS) requirements, involving trade-offs among\nobjectives such as reducing cost, ensuring answer quality, and adhering to\nspecific operational constraints.\n  In this work, we present a systems-oriented approach to multi-agent RAG\ntailored for real-world Question Answering (QA) applications. By integrating\ntask-specific non-functional requirements-such as answer quality, cost, and\nlatency-into the system, we enable dynamic reconfiguration to meet diverse\nSLAs. Our method maps these Service Level Objectives (SLOs) to system-level\nparameters, allowing the generation of optimal results within specified\nresource constraints.\n  We conduct a case study in the QA domain, demonstrating how dynamic\nre-orchestration of a multi-agent RAG system can effectively manage the\ntrade-off between answer quality and cost. By adjusting the system based on\nquery intent and operational conditions, we systematically balance performance\nand resource utilization. This approach allows the system to meet SLOs for\nvarious query types, showcasing its practicality for real-world applications.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.DC",
      "H.3.4; H.3.3; I.2.7; I.2.11; C.2.4"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06832v2",
    "published_date": "2024-12-07 01:32:13 UTC",
    "updated_date": "2025-04-28 23:51:43 UTC"
  },
  {
    "arxiv_id": "2412.05481v2",
    "title": "A Compositional Atlas for Algebraic Circuits",
    "authors": [
      "Benjie Wang",
      "Denis Deratani Mau",
      "Guy Van den Broeck",
      "YooJung Choi"
    ],
    "abstract": "Circuits based on sum-product structure have become a ubiquitous\nrepresentation to compactly encode knowledge, from Boolean functions to\nprobability distributions. By imposing constraints on the structure of such\ncircuits, certain inference queries become tractable, such as model counting\nand most probable configuration. Recent works have explored analyzing\nprobabilistic and causal inference queries as compositions of basic operators\nto derive tractability conditions. In this paper, we take an algebraic\nperspective for compositional inference, and show that a large class of queries\n- including marginal MAP, probabilistic answer set programming inference, and\ncausal backdoor adjustment - correspond to a combination of basic operators\nover semirings: aggregation, product, and elementwise mapping. Using this\nframework, we uncover simple and general sufficient conditions for tractable\ncomposition of these operators, in terms of circuit properties (e.g., marginal\ndeterminism, compatibility) and conditions on the elementwise mappings.\nApplying our analysis, we derive novel tractability conditions for many such\ncompositional queries. Our results unify tractability conditions for existing\nproblems on circuits, while providing a blueprint for analysing novel\ncompositional inference queries.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.05481v2",
    "published_date": "2024-12-07 00:51:46 UTC",
    "updated_date": "2025-02-24 07:15:11 UTC"
  },
  {
    "arxiv_id": "2412.06831v1",
    "title": "TransitGPT: A Generative AI-based framework for interacting with GTFS data using Large Language Models",
    "authors": [
      "Saipraneeth Devunuri",
      "Lewis Lehe"
    ],
    "abstract": "This paper introduces a framework that leverages Large Language Models (LLMs)\nto answer natural language queries about General Transit Feed Specification\n(GTFS) data. The framework is implemented in a chatbot called TransitGPT with\nopen-source code. TransitGPT works by guiding LLMs to generate Python code that\nextracts and manipulates GTFS data relevant to a query, which is then executed\non a server where the GTFS feed is stored. It can accomplish a wide range of\ntasks, including data retrieval, calculations, and interactive visualizations,\nwithout requiring users to have extensive knowledge of GTFS or programming. The\nLLMs that produce the code are guided entirely by prompts, without fine-tuning\nor access to the actual GTFS feeds. We evaluate TransitGPT using GPT-4o and\nClaude-3.5-Sonnet LLMs on a benchmark dataset of 100 tasks, to demonstrate its\neffectiveness and versatility. The results show that TransitGPT can\nsignificantly enhance the accessibility and usability of transit data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06831v1",
    "published_date": "2024-12-07 00:35:41 UTC",
    "updated_date": "2024-12-07 00:35:41 UTC"
  },
  {
    "arxiv_id": "2412.16172v2",
    "title": "LABIIUM: AI-Enhanced Zero-configuration Measurement Automation System",
    "authors": [
      "Emmanuel A. Olowe",
      "Danial Chitnis"
    ],
    "abstract": "The complexity of laboratory environments requires solutions that simplify\ninstrument interaction and enhance measurement automation. Traditional tools\noften require configuration, software, and programming skills, creating\nbarriers to productivity. Previous approaches, including dedicated software\nsuites and custom scripts, frequently fall short in providing user-friendly\nsolutions that align with programming practices. We present LABIIUM, an\nAI-enhanced, zero-configuration measurement automation system designed to\nstreamline experimental workflows and improve user productivity. LABIIUM\nintegrates an AI assistant powered by Large Language Models (LLMs) to generate\ncode. LABIIUM's Lab-Automation-Measurement Bridges (LAMBs) enable seamless\ninstrument connectivity using standard tools such as VSCode and Python,\neliminating setup overhead. To demonstrate its capabilities, we conducted\nexperiments involving the measurement of the parametric transfer curve of a\nsimple two-transistor inverting amplifier with a current source load. The AI\nassistant was evaluated using different prompt scenarios and compared with\nmultiple models, including Claude Sonnet 3.5, Gemini Pro 1.5, and GPT-4o. An\nexpert solution implementing the Gradient-Weighted Adaptive Stochastic Sampling\n(GWASS) method was used as a baseline. The solutions generated by the AI\nassistant were compared with the expert solution and a uniform linear sweep\nbaseline with 10,000 points. The graph results show that the LLMs were able to\nsuccessfully complete the most basic uniform sweep, but LLMs were unable to\ndevelop adaptive sweeping algorithms to compete with GWASS. The evaluation\nunderscores LABIIUM's ability to enhance laboratory productivity and support\ndigital transformation in research and industry, and emphasizes the future work\nrequired to improve LLM performance in Electronic Measurement Science Tasks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "accepted for IEEE I2MTC 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16172v2",
    "published_date": "2024-12-07 00:15:24 UTC",
    "updated_date": "2025-03-04 18:15:36 UTC"
  }
]