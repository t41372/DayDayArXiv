[
  {
    "arxiv_id": "2503.00248v1",
    "title": "Human-AI Collaboration: Trade-offs Between Performance and Preferences",
    "authors": [
      "Lukas William Mayer",
      "Sheer Karny",
      "Jackie Ayoub",
      "Miao Song",
      "Danyang Tian",
      "Ehsan Moradi-Pari",
      "Mark Steyvers"
    ],
    "abstract": "Despite the growing interest in collaborative AI, designing systems that\nseamlessly integrate human input remains a major challenge. In this study, we\ndeveloped a task to systematically examine human preferences for collaborative\nagents. We created and evaluated five collaborative AI agents with strategies\nthat differ in the manner and degree they adapt to human actions. Participants\ninteracted with a subset of these agents, evaluated their perceived traits, and\nselected their preferred agent. We used a Bayesian model to understand how\nagents' strategies influence the Human-AI team performance, AI's perceived\ntraits, and the factors shaping human-preferences in pairwise agent\ncomparisons. Our results show that agents who are more considerate of human\nactions are preferred over purely performance-maximizing agents. Moreover, we\nshow that such human-centric design can improve the likability of AI\ncollaborators without reducing performance. We find evidence for\ninequality-aversion effects being a driver of human choices, suggesting that\npeople prefer collaborative agents which allow them to meaningfully contribute\nto the team. Taken together, these findings demonstrate how collaboration with\nAI can benefit from development efforts which include both subjective and\nobjective metrics.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "LW Mayer & S Karny are co-first authors",
    "pdf_url": "http://arxiv.org/pdf/2503.00248v1",
    "published_date": "2025-02-28 23:50:14 UTC",
    "updated_date": "2025-02-28 23:50:14 UTC"
  },
  {
    "arxiv_id": "2503.00240v1",
    "title": "1-Lipschitz Network Initialization for Certifiably Robust Classification Applications: A Decay Problem",
    "authors": [
      "Marius F. R. Juston",
      "William R. Norris",
      "Dustin Nottage",
      "Ahmet Soylemezoglu"
    ],
    "abstract": "This paper discusses the weight parametrization of two standard 1-Lipschitz\nnetwork structure methodologies, the Almost-Orthogonal-Layers (AOL) and the\nSDP-based Lipschitz Layers (SLL), and derives their impact on the\ninitialization for deep 1-Lipschitz feedforward networks in addition to\ndiscussing underlying issues surrounding this initialization. These networks\nare mainly used in certifiably robust classification applications to combat\nadversarial attacks by limiting the effects of perturbations on the output\nclassification result. An exact and an upper bound for the parameterized weight\nvariance was calculated assuming a standard Normal distribution initialization;\nadditionally, an upper bound was computed assuming a Generalized Normal\nDistribution, generalizing the proof for Uniform, Laplace, and Normal\ndistribution weight initializations. It is demonstrated that the weight\nvariance holds no bearing on the output variance distribution and that only the\ndimension of the weight matrices matters. Additionally, this paper demonstrates\nthat the weight initialization always causes deep 1-Lipschitz networks to decay\nto zero.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.00240v1",
    "published_date": "2025-02-28 23:02:04 UTC",
    "updated_date": "2025-02-28 23:02:04 UTC"
  },
  {
    "arxiv_id": "2503.00237v1",
    "title": "Agentic AI Needs a Systems Theory",
    "authors": [
      "Erik Miehling",
      "Karthikeyan Natesan Ramamurthy",
      "Kush R. Varshney",
      "Matthew Riemer",
      "Djallel Bouneffouf",
      "John T. Richards",
      "Amit Dhurandhar",
      "Elizabeth M. Daly",
      "Michael Hind",
      "Prasanna Sattigeri",
      "Dennis Wei",
      "Ambrish Rawat",
      "Jasmina Gajcin",
      "Werner Geyer"
    ],
    "abstract": "The endowment of AI with reasoning capabilities and some degree of agency is\nwidely viewed as a path toward more capable and generalizable systems. Our\nposition is that the current development of agentic AI requires a more\nholistic, systems-theoretic perspective in order to fully understand their\ncapabilities and mitigate any emergent risks. The primary motivation for our\nposition is that AI development is currently overly focused on individual model\ncapabilities, often ignoring broader emergent behavior, leading to a\nsignificant underestimation in the true capabilities and associated risks of\nagentic AI. We describe some fundamental mechanisms by which advanced\ncapabilities can emerge from (comparably simpler) agents simply due to their\ninteraction with the environment and other agents. Informed by an extensive\namount of existing literature from various fields, we outline mechanisms for\nenhanced agent cognition, emergent causal reasoning ability, and metacognitive\nawareness. We conclude by presenting some key open challenges and guidance for\nthe development of agentic AI. We emphasize that a systems-level perspective is\nessential for better understanding, and purposefully shaping, agentic AI\nsystems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00237v1",
    "published_date": "2025-02-28 22:51:32 UTC",
    "updated_date": "2025-02-28 22:51:32 UTC"
  },
  {
    "arxiv_id": "2503.01909v1",
    "title": "Attend or Perish: Benchmarking Attention in Algorithmic Reasoning",
    "authors": [
      "Michal Spiegel",
      "Michal Štefánik",
      "Marek Kadlčík",
      "Josef Kuchař"
    ],
    "abstract": "Can transformers learn to perform algorithmic tasks reliably across\npreviously unseen input/output domains? While pre-trained language models show\nsolid accuracy on benchmarks incorporating algorithmic reasoning, assessing the\nreliability of these results necessitates an ability to cleanse models'\nfunctional capabilities from memorization. In this paper, we propose an\nalgorithmic benchmark comprising six tasks of infinite input domains where we\ncan also disentangle and trace the correct, robust algorithm necessary for the\ntask. This allows us to assess (i) models' ability to extrapolate to unseen\ntypes of inputs, including new lengths, value ranges or input domains, but also\n(ii) to assess the robustness of the functional mechanism in recent models\nthrough the lens of their attention maps. We make the implementation of all our\ntasks and interoperability methods publicly available at\nhttps://github.com/michalspiegel/AttentionSpan .",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01909v1",
    "published_date": "2025-02-28 22:50:38 UTC",
    "updated_date": "2025-02-28 22:50:38 UTC"
  },
  {
    "arxiv_id": "2503.00234v3",
    "title": "Investigating the Relationship Between Debiasing and Artifact Removal using Saliency Maps",
    "authors": [
      "Lukasz Sztukiewicz",
      "Ignacy Stępka",
      "Michał Wiliński",
      "Jerzy Stefanowski"
    ],
    "abstract": "The widespread adoption of machine learning systems has raised critical\nconcerns about fairness and bias, making mitigating harmful biases essential\nfor AI development. In this paper, we investigate the relationship between\ndebiasing and removing artifacts in neural networks for computer vision tasks.\nFirst, we introduce a set of novel XAI-based metrics that analyze saliency maps\nto assess shifts in a model's decision-making process. Then, we demonstrate\nthat successful debiasing methods systematically redirect model focus away from\nprotected attributes. Finally, we show that techniques originally developed for\nartifact removal can be effectively repurposed for improving fairness. These\nfindings provide evidence for the existence of a bidirectional connection\nbetween ensuring fairness and removing artifacts corresponding to protected\nattributes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00234v3",
    "published_date": "2025-02-28 22:42:21 UTC",
    "updated_date": "2025-04-24 10:55:58 UTC"
  },
  {
    "arxiv_id": "2503.00231v1",
    "title": "Jawaher: A Multidialectal Dataset of Arabic Proverbs for LLM Benchmarking",
    "authors": [
      "Samar M. Magdy",
      "Sang Yun Kwon",
      "Fakhraddin Alwajih",
      "Safaa Abdelfadil",
      "Shady Shehata",
      "Muhammad Abdul-Mageed"
    ],
    "abstract": "Recent advancements in instruction fine-tuning, alignment methods such as\nreinforcement learning from human feedback (RLHF), and optimization techniques\nlike direct preference optimization (DPO) have significantly enhanced the\nadaptability of large language models (LLMs) to user preferences. However,\ndespite these innovations, many LLMs continue to exhibit biases toward Western,\nAnglo-centric, or American cultures, with performance on English data\nconsistently surpassing that of other languages. This reveals a persistent\ncultural gap in LLMs, which complicates their ability to accurately process\nculturally rich and diverse figurative language such as proverbs. To address\nthis, we introduce Jawaher, a benchmark designed to assess LLMs' capacity to\ncomprehend and interpret Arabic proverbs. Jawaher includes proverbs from\nvarious Arabic dialects, along with idiomatic translations and explanations.\nThrough extensive evaluations of both open- and closed-source models, we find\nthat while LLMs can generate idiomatically accurate translations, they struggle\nwith producing culturally nuanced and contextually relevant explanations. These\nfindings highlight the need for ongoing model refinement and dataset expansion\nto bridge the cultural gap in figurative language processing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Project GitHub page is accessible at:\n  https://github.com/UBC-NLP/jawaher",
    "pdf_url": "http://arxiv.org/pdf/2503.00231v1",
    "published_date": "2025-02-28 22:28:00 UTC",
    "updated_date": "2025-02-28 22:28:00 UTC"
  },
  {
    "arxiv_id": "2503.00211v1",
    "title": "SafeAuto: Knowledge-Enhanced Safe Autonomous Driving with Multimodal Foundation Models",
    "authors": [
      "Jiawei Zhang",
      "Xuan Yang",
      "Taiqi Wang",
      "Yu Yao",
      "Aleksandr Petiushko",
      "Bo Li"
    ],
    "abstract": "Traditional autonomous driving systems often struggle to integrate high-level\nreasoning with low-level control, resulting in suboptimal and sometimes unsafe\ndriving behaviors. The emergence of Multimodal Large Language Models (MLLMs),\nwhich can process both visual and textual data, presents an opportunity to\nunify perception and reasoning tasks within a single framework. However,\neffectively embedding precise safety knowledge into MLLMs for autonomous\ndriving remains a significant challenge. To address this, we propose SafeAuto,\na novel framework that enhances MLLM-based autonomous driving systems by\nincorporating both unstructured and structured knowledge. Specifically, we\nfirst introduce the Position-Dependent Cross-Entropy (PDCE) loss function,\ndesigned to improve the accuracy of low-level control signal predictions when\nnumerical values are represented as text. Second, to ensure safe autonomous\ndriving by explicitly integrating precise safety knowledge into the MLLM, we\ndevelop a reasoning component for SafeAuto. This component translates driving\nsafety regulations into first-order logic rules (e.g., \"red light => stop\") and\nincorporates these rules into a probabilistic graphical model, such as a Markov\nLogic Network (MLN). The MLN is trained to verify the predicted next actions\nusing environmental attributes identified by attribute recognition models\n(e.g., detecting a red light) to form the predicates. Additionally, we\nconstruct a Multimodal RAG model that leverages video data, control signals,\nand environmental attributes to learn more effectively from past similar\ndriving experiences. By integrating PDCE, MLN, and Multimodal RAG, SafeAuto\nsignificantly outperforms existing baselines across multiple datasets. This\nadvancement enables more accurate, reliable, and safer autonomous driving\nsystems that learn from experience, obey traffic laws, and perform precise\ncontrol actions.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00211v1",
    "published_date": "2025-02-28 21:53:47 UTC",
    "updated_date": "2025-02-28 21:53:47 UTC"
  },
  {
    "arxiv_id": "2503.00210v1",
    "title": "Foundation-Model-Boosted Multimodal Learning for fMRI-based Neuropathic Pain Drug Response Prediction",
    "authors": [
      "Wenrui Fan",
      "L. M. Riza Rizky",
      "Jiayang Zhang",
      "Chen Chen",
      "Haiping Lu",
      "Kevin Teh",
      "Dinesh Selvarajah",
      "Shuo Zhou"
    ],
    "abstract": "Neuropathic pain, affecting up to 10% of adults, remains difficult to treat\ndue to limited therapeutic efficacy and tolerability. Although resting-state\nfunctional MRI (rs-fMRI) is a promising non-invasive measurement of brain\nbiomarkers to predict drug response in therapeutic development, the complexity\nof fMRI demands machine learning models with substantial capacity. However,\nextreme data scarcity in neuropathic pain research limits the application of\nhigh-capacity models. To address the challenge of data scarcity, we propose\nFMM$_{TC}$, a Foundation-Model-boosted Multimodal learning framework for\nfMRI-based neuropathic pain drug response prediction, which leverages both\ninternal multimodal information in pain-specific data and external knowledge\nfrom large pain-agnostic data. Specifically, to maximize the value of limited\npain-specific data, FMM$_{TC}$ integrates complementary information from two\nrs-fMRI modalities: Time series and functional Connectivity. FMM$_{TC}$ is\nfurther boosted by an fMRI foundation model with its external knowledge from\nextensive pain-agnostic fMRI datasets enriching limited pain-specific\ninformation. Evaluations with an in-house dataset and a public dataset from\nOpenNeuro demonstrate FMM$_{TC}$'s superior representation ability,\ngeneralizability, and cross-dataset adaptability over existing unimodal fMRI\nmodels that only consider one of the rs-fMRI modalities. The ablation study\nvalidates the effectiveness of multimodal learning and foundation-model-powered\nexternal knowledge transfer in FMM$_{TC}$. An integrated gradient-based\ninterpretation study explains how FMM$_{TC}$'s cross-dataset dynamic behaviors\nenhance its adaptability. In conclusion, FMM$_{TC}$ boosts clinical trials in\nneuropathic pain therapeutic development by accurately predicting drug\nresponses to improve the participant stratification efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00210v1",
    "published_date": "2025-02-28 21:50:03 UTC",
    "updated_date": "2025-02-28 21:50:03 UTC"
  },
  {
    "arxiv_id": "2503.00206v1",
    "title": "Quantifying First-Order Markov Violations in Noisy Reinforcement Learning: A Causal Discovery Approach",
    "authors": [
      "Naveen Mysore"
    ],
    "abstract": "Reinforcement learning (RL) methods frequently assume that each new\nobservation completely reflects the environment's state, thereby guaranteeing\nMarkovian (one-step) transitions. In practice, partial observability or\nsensor/actuator noise often invalidates this assumption. This paper proposes a\nsystematic methodology for detecting such violations, combining a partial\ncorrelation-based causal discovery process (PCMCI) with a novel Markov\nViolation score (MVS). The MVS measures multi-step dependencies that emerge\nwhen noise or incomplete state information disrupts the Markov property.\n  Classic control tasks (CartPole, Pendulum, Acrobot) serve as examples to\nillustrate how targeted noise and dimension omissions affect both RL\nperformance and measured Markov consistency. Surprisingly, even substantial\nobservation noise sometimes fails to induce strong multi-lag dependencies in\ncertain domains (e.g., Acrobot). In contrast, dimension-dropping investigations\nshow that excluding some state variables (e.g., angular velocities in CartPole\nand Pendulum) significantly reduces returns and increases MVS, while removing\nother dimensions has minimal impact.\n  These findings emphasize the importance of locating and safeguarding the most\ncausally essential dimensions in order to preserve effective single-step\nlearning. By integrating partial correlation tests with RL performance\noutcomes, the proposed approach precisely identifies when and where the Markov\nassumption is violated. This framework offers a principled mechanism for\ndeveloping robust policies, informing representation learning, and addressing\npartial observability in real-world RL scenarios. All code and experimental\nlogs are accessible for reproducibility (https://github.com/ucsb/markovianess).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML",
      "68T05",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review for RLC 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.00206v1",
    "published_date": "2025-02-28 21:42:10 UTC",
    "updated_date": "2025-02-28 21:42:10 UTC"
  },
  {
    "arxiv_id": "2503.00196v1",
    "title": "PRISM: High-Resolution & Precise Counterfactual Medical Image Generation using Language-guided Stable Diffusion",
    "authors": [
      "Amar Kumar",
      "Anita Kriz",
      "Mohammad Havaei",
      "Tal Arbel"
    ],
    "abstract": "Developing reliable and generalizable deep learning systems for medical\nimaging faces significant obstacles due to spurious correlations, data\nimbalances, and limited text annotations in datasets. Addressing these\nchallenges requires architectures robust to the unique complexities posed by\nmedical imaging data. The rapid advancements in vision-language foundation\nmodels within the natural image domain prompt the question of how they can be\nadapted for medical imaging tasks. In this work, we present PRISM, a framework\nthat leverages foundation models to generate high-resolution, language-guided\nmedical image counterfactuals using Stable Diffusion. Our approach demonstrates\nunprecedented precision in selectively modifying spurious correlations (the\nmedical devices) and disease features, enabling the removal and addition of\nspecific attributes while preserving other image characteristics. Through\nextensive evaluation, we show how PRISM advances counterfactual generation and\nenables the development of more robust downstream classifiers for clinically\ndeployable solutions. To facilitate broader adoption and research, we make our\ncode publicly available at https://github.com/Amarkr1/PRISM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Under Review for MIDL 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.00196v1",
    "published_date": "2025-02-28 21:32:08 UTC",
    "updated_date": "2025-02-28 21:32:08 UTC"
  },
  {
    "arxiv_id": "2503.01908v1",
    "title": "UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning",
    "authors": [
      "Jiawei Zhang",
      "Shuang Yang",
      "Bo Li"
    ],
    "abstract": "Large Language Model (LLM) agents equipped with external tools have become\nincreasingly powerful for handling complex tasks such as web shopping,\nautomated email replies, and financial trading. However, these advancements\nalso amplify the risks of adversarial attacks, particularly when LLM agents can\naccess sensitive external functionalities. Moreover, because LLM agents engage\nin extensive reasoning or planning before executing final actions, manipulating\nthem into performing targeted malicious actions or invoking specific tools\nremains a significant challenge. Consequently, directly embedding adversarial\nstrings in malicious instructions or injecting malicious prompts into tool\ninteractions has become less effective against modern LLM agents. In this work,\nwe present UDora, a unified red teaming framework designed for LLM Agents that\ndynamically leverages the agent's own reasoning processes to compel it toward\nmalicious behavior. Specifically, UDora first samples the model's reasoning for\nthe given task, then automatically identifies multiple optimal positions within\nthese reasoning traces to insert targeted perturbations. Subsequently, it uses\nthe modified reasoning as the objective to optimize the adversarial strings. By\niteratively applying this process, the LLM agent will then be induced to\nundertake designated malicious actions or to invoke specific malicious tools.\nOur approach demonstrates superior effectiveness compared to existing methods\nacross three LLM agent datasets.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01908v1",
    "published_date": "2025-02-28 21:30:28 UTC",
    "updated_date": "2025-02-28 21:30:28 UTC"
  },
  {
    "arxiv_id": "2503.00191v1",
    "title": "Learning Vision-Based Neural Network Controllers with Semi-Probabilistic Safety Guarantees",
    "authors": [
      "Xinhang Ma",
      "Junlin Wu",
      "Hussein Sibai",
      "Yiannis Kantaros",
      "Yevgeniy Vorobeychik"
    ],
    "abstract": "Ensuring safety in autonomous systems with vision-based control remains a\ncritical challenge due to the high dimensionality of image inputs and the fact\nthat the relationship between true system state and its visual manifestation is\nunknown. Existing methods for learning-based control in such settings typically\nlack formal safety guarantees. To address this challenge, we introduce a novel\nsemi-probabilistic verification framework that integrates reachability analysis\nwith conditional generative adversarial networks and distribution-free tail\nbounds to enable efficient and scalable verification of vision-based neural\nnetwork controllers. Next, we develop a gradient-based training approach that\nemploys a novel safety loss function, safety-aware data-sampling strategy to\nefficiently select and store critical training examples, and curriculum\nlearning, to efficiently synthesize safe controllers in the semi-probabilistic\nframework. Empirical evaluations in X-Plane 11 airplane landing simulation,\nCARLA-simulated autonomous lane following, and F1Tenth lane following in a\nphysical visually-rich miniature environment demonstrate the effectiveness of\nour method in achieving formal safety guarantees while maintaining strong\nnominal performance. Our code is available at https://github.com/xhOwenMa/SPVT.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages, 2 figures, submitted to IROS 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.00191v1",
    "published_date": "2025-02-28 21:16:42 UTC",
    "updated_date": "2025-02-28 21:16:42 UTC"
  },
  {
    "arxiv_id": "2503.00179v1",
    "title": "Zero-Shot and Efficient Clarification Need Prediction in Conversational Search",
    "authors": [
      "Lili Lu",
      "Chuan Meng",
      "Federico Ravenda",
      "Mohammad Aliannejadi",
      "Fabio Crestani"
    ],
    "abstract": "Clarification need prediction (CNP) is a key task in conversational search,\naiming to predict whether to ask a clarifying question or give an answer to the\ncurrent user query. However, current research on CNP suffers from the issues of\nlimited CNP training data and low efficiency. In this paper, we propose a\nzero-shot and efficient CNP framework (Zef-CNP), in which we first prompt large\nlanguage models (LLMs) in a zero-shot manner to generate two sets of synthetic\nqueries: ambiguous and specific (unambiguous) queries. We then use the\ngenerated queries to train efficient CNP models. Zef-CNP eliminates the need\nfor human-annotated clarification-need labels during training and avoids the\nuse of LLMs with high query latency at query time. To further improve the\ngeneration quality of synthetic queries, we devise a topic-, information-need-,\nand query-aware chain-of-thought (CoT) prompting strategy (TIQ-CoT). Moreover,\nwe enhance TIQ-CoT with counterfactual query generation (CoQu), which guides\nLLMs first to generate a specific/ambiguous query and then sequentially\ngenerate its corresponding ambiguous/specific query. Experimental results show\nthat Zef-CNP achieves superior CNP effectiveness and efficiency compared with\nzero- and few-shot LLM-based CNP predictors.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "H.3.3"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00179v1",
    "published_date": "2025-02-28 20:49:18 UTC",
    "updated_date": "2025-02-28 20:49:18 UTC"
  },
  {
    "arxiv_id": "2503.00177v1",
    "title": "Steering Large Language Model Activations in Sparse Spaces",
    "authors": [
      "Reza Bayat",
      "Ali Rahimi-Kalahroudi",
      "Mohammad Pezeshki",
      "Sarath Chandar",
      "Pascal Vincent"
    ],
    "abstract": "A key challenge in AI alignment is guiding large language models (LLMs) to\nfollow desired behaviors at test time. Activation steering, which modifies\ninternal model activations during inference, offers a potential solution.\nHowever, prior work in dense activation spaces struggles with superposition,\nwherein multiple features become entangled, limiting interpretability and\nprecise control. In contrast, sparse representations provide an untapped\nopportunity for more interpretable behavior modulation. In this work, we\nintroduce sparse activation steering (SAS), a method that leverages sparse\nautoencoders (SAEs) to steer LLM behavior in sparse spaces. By isolating\nbehavior-specific features through a contrastive prompt-pairing approach, we\ndefine a set of features that can selectively reinforce or suppress behaviors.\nExperiments on Gemma 2 LLMs show that SAS vectors enable nuanced behavioral\nmodulation and finer-grained control. Furthermore, scaling SAEs improves\nmonosemanticity of SAS vectors, suggesting more reliable and interpretable\ninterventions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00177v1",
    "published_date": "2025-02-28 20:43:45 UTC",
    "updated_date": "2025-02-28 20:43:45 UTC"
  },
  {
    "arxiv_id": "2503.00171v1",
    "title": "PaliGemma-CXR: A Multi-task Multimodal Model for TB Chest X-ray Interpretation",
    "authors": [
      "Denis Musinguzi",
      "Andrew Katumba",
      "Sudi Murindanyi"
    ],
    "abstract": "Tuberculosis (TB) is a infectious global health challenge. Chest X-rays are a\nstandard method for TB screening, yet many countries face a critical shortage\nof radiologists capable of interpreting these images. Machine learning offers\nan alternative, as it can automate tasks such as disease diagnosis, and report\ngeneration. However, traditional approaches rely on task-specific models, which\ncannot utilize the interdependence between tasks. Building a multi-task model\ncapable of performing multiple tasks poses additional challenges such as\nscarcity of multimodal data, dataset imbalance, and negative transfer. To\naddress these challenges, we propose PaliGemma-CXR, a multi-task multimodal\nmodel capable of performing TB diagnosis, object detection, segmentation,\nreport generation, and VQA. Starting with a dataset of chest X-ray images\nannotated with TB diagnosis labels and segmentation masks, we curated a\nmultimodal dataset to support additional tasks. By finetuning PaliGemma on this\ndataset and sampling data using ratios of the inverse of the size of task\ndatasets, we achieved the following results across all tasks: 90.32% accuracy\non TB diagnosis and 98.95% on close-ended VQA, 41.3 BLEU score on report\ngeneration, and a mAP of 19.4 and 16.0 on object detection and segmentation,\nrespectively. These results demonstrate that PaliGemma-CXR effectively\nleverages the interdependence between multiple image interpretation tasks to\nenhance performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00171v1",
    "published_date": "2025-02-28 20:34:06 UTC",
    "updated_date": "2025-02-28 20:34:06 UTC"
  },
  {
    "arxiv_id": "2503.00162v1",
    "title": "PreMind: Multi-Agent Video Understanding for Advanced Indexing of Presentation-style Videos",
    "authors": [
      "Kangda Wei",
      "Zhengyu Zhou",
      "Bingqing Wang",
      "Jun Araki",
      "Lukas Lange",
      "Ruihong Huang",
      "Zhe Feng"
    ],
    "abstract": "In recent years, online lecture videos have become an increasingly popular\nresource for acquiring new knowledge. Systems capable of effectively\nunderstanding/indexing lecture videos are thus highly desirable, enabling\ndownstream tasks like question answering to help users efficiently locate\nspecific information within videos. This work proposes PreMind, a novel\nmulti-agent multimodal framework that leverages various large models for\nadvanced understanding/indexing of presentation-style videos. PreMind first\nsegments videos into slide-presentation segments using a Vision-Language Model\n(VLM) to enhance modern shot-detection techniques. Each segment is then\nanalyzed to generate multimodal indexes through three key steps: (1) extracting\nslide visual content, (2) transcribing speech narratives, and (3) consolidating\nthese visual and speech contents into an integrated understanding. Three\ninnovative mechanisms are also proposed to improve performance: leveraging\nprior lecture knowledge to refine visual understanding, detecting/correcting\nspeech transcription errors using a VLM, and utilizing a critic agent for\ndynamic iterative self-reflection in vision analysis. Compared to traditional\nvideo indexing methods, PreMind captures rich, reliable multimodal information,\nallowing users to search for details like abbreviations shown only on slides.\nSystematic evaluations on the public LPM dataset and an internal enterprise\ndataset are conducted to validate PreMind's effectiveness, supported by\ndetailed analyses.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00162v1",
    "published_date": "2025-02-28 20:17:48 UTC",
    "updated_date": "2025-02-28 20:17:48 UTC"
  },
  {
    "arxiv_id": "2503.00159v1",
    "title": "EXACT-CT: EXplainable Analysis for Crohn's and Tuberculosis using CT",
    "authors": [
      "Shashwat Gupta",
      "Sarthak Gupta",
      "Akshan Agrawal",
      "Mahim Naaz",
      "Rajanikanth Yadav",
      "Priyanka Bagade"
    ],
    "abstract": "Crohn's disease and intestinal tuberculosis share many overlapping features\nsuch as clinical, radiological, endoscopic, and histological features -\nparticularly granulomas, making it challenging to clinically differentiate\nthem. Our research leverages 3D CTE scans, computer vision, and machine\nlearning to improve this differentiation to avoid harmful treatment\nmismanagement such as unnecessary anti-tuberculosis therapy for Crohn's disease\nor exacerbation of tuberculosis with immunosuppressants. Our study proposes a\nnovel method to identify radiologist - identified biomarkers such as VF to SF\nratio, necrosis, calcifications, comb sign and pulmonary TB to enhance\naccuracy. We demonstrate the effectiveness by using different ML techniques on\nthe features extracted from these biomarkers, computing SHAP on XGBoost for\nunderstanding feature importance towards predictions, and comparing against\nSOTA methods such as pretrained ResNet and CTFoundation.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "8 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.00159v1",
    "published_date": "2025-02-28 20:08:32 UTC",
    "updated_date": "2025-02-28 20:08:32 UTC"
  },
  {
    "arxiv_id": "2503.00154v1",
    "title": "Fed-KAN: Federated Learning with Kolmogorov-Arnold Networks for Traffic Prediction",
    "authors": [
      "Engin Zeydan",
      "Cristian J. Vaca-Rubio",
      "Luis Blanco",
      "Roberto Pereira",
      "Marius Caus",
      "Kapal Dev"
    ],
    "abstract": "Non-Terrestrial Networks (NTNs) are becoming a critical component of modern\ncommunication infrastructures, especially with the advent of Low Earth Orbit\n(LEO) satellite systems. Traditional centralized learning approaches face major\nchallenges in such networks due to high latency, intermittent connectivity and\nlimited bandwidth. Federated Learning (FL) is a promising alternative as it\nenables decentralized training while maintaining data privacy. However,\nexisting FL models, such as Federated Learning with Multi-Layer Perceptrons\n(Fed-MLP), can struggle with high computational complexity and poor\nadaptability to dynamic NTN environments. This paper provides a detailed\nanalysis for Federated Learning with Kolmogorov-Arnold Networks (Fed-KAN), its\nimplementation and performance improvements over traditional FL models in NTN\nenvironments for traffic forecasting. The proposed Fed-KAN is a novel approach\nthat utilises the functional approximation capabilities of KANs in a FL\nframework. We evaluate Fed-KAN compared to Fed-MLP on a traffic dataset of real\nsatellite operator and show a significant reduction in training and test loss.\nOur results show that Fed-KAN can achieve a 77.39% reduction in average test\nloss compared to Fed-MLP, highlighting its improved performance and better\ngeneralization ability. At the end of the paper, we also discuss some potential\napplications of Fed-KAN within O-RAN and Fed-KAN usage for split\nfunctionalities in NTN architecture.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2503.00154v1",
    "published_date": "2025-02-28 20:04:53 UTC",
    "updated_date": "2025-02-28 20:04:53 UTC"
  },
  {
    "arxiv_id": "2503.00151v1",
    "title": "Palm: A Culturally Inclusive and Linguistically Diverse Dataset for Arabic LLMs",
    "authors": [
      "Fakhraddin Alwajih",
      "Abdellah El Mekki",
      "Samar Mohamed Magdy",
      "Abdelrahim A. Elmadany",
      "Omer Nacar",
      "El Moatez Billah Nagoudi",
      "Reem Abdel-Salam",
      "Hanin Atwany",
      "Youssef Nafea",
      "Abdulfattah Mohammed Yahya",
      "Rahaf Alhamouri",
      "Hamzah A. Alsayadi",
      "Hiba Zayed",
      "Sara Shatnawi",
      "Serry Sibaee",
      "Yasir Ech-Chammakhy",
      "Walid Al-Dhabyani",
      "Marwa Mohamed Ali",
      "Imen Jarraya",
      "Ahmed Oumar El-Shangiti",
      "Aisha Alraeesi",
      "Mohammed Anwar Al-Ghrawi",
      "Abdulrahman S. Al-Batati",
      "Elgizouli Mohamed",
      "Noha Taha Elgindi",
      "Muhammed Saeed",
      "Houdaifa Atou",
      "Issam Ait Yahia",
      "Abdelhak Bouayad",
      "Mohammed Machrouh",
      "Amal Makouar",
      "Dania Alkawi",
      "Mukhtar Mohamed",
      "Safaa Taher Abdelfadil",
      "Amine Ziad Ounnoughene",
      "Rouabhia Anfel",
      "Rwaa Assi",
      "Ahmed Sorkatti",
      "Mohamedou Cheikh Tourad",
      "Anis Koubaa",
      "Ismail Berrada",
      "Mustafa Jarrar",
      "Shady Shehata",
      "Muhammad Abdul-Mageed"
    ],
    "abstract": "As large language models (LLMs) become increasingly integrated into daily\nlife, ensuring their cultural sensitivity and inclusivity is paramount. We\nintroduce our dataset, a year-long community-driven project covering all 22\nArab countries. The dataset includes instructions (input, response pairs) in\nboth Modern Standard Arabic (MSA) and dialectal Arabic (DA), spanning 20\ndiverse topics. Built by a team of 44 researchers across the Arab world, all of\nwhom are authors of this paper, our dataset offers a broad, inclusive\nperspective. We use our dataset to evaluate the cultural and dialectal\ncapabilities of several frontier LLMs, revealing notable limitations. For\ninstance, while closed-source LLMs generally exhibit strong performance, they\nare not without flaws, and smaller open-source models face greater challenges.\nMoreover, certain countries (e.g., Egypt, the UAE) appear better represented\nthan others (e.g., Iraq, Mauritania, Yemen). Our annotation guidelines, code,\nand data for reproducibility are publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "More information about our dataset is available at our project page:\n  https://github.com/UBC-NLP/palm",
    "pdf_url": "http://arxiv.org/pdf/2503.00151v1",
    "published_date": "2025-02-28 19:59:13 UTC",
    "updated_date": "2025-02-28 19:59:13 UTC"
  },
  {
    "arxiv_id": "2503.00144v1",
    "title": "Learner and Instructor Needs in AI-Supported Programming Learning Tools: Design Implications for Features and Adaptive Control",
    "authors": [
      "Zihan Wu",
      "Yicheng Tang",
      "Barbara Ericson"
    ],
    "abstract": "AI-supported tools can help learners overcome challenges in programming\neducation by providing adaptive assistance. However, existing research often\nfocuses on individual tools rather than deriving broader design\nrecommendations. A key challenge in designing these systems is balancing\nlearner control with system-driven guidance. To explore user preferences for\nAI-supported programming learning tools, we conducted a participatory design\nstudy with 15 undergraduate novice programmers and 10 instructors to gather\ninsights on their desired help features and control preferences, as well as a\nfollow-up survey with 172 introductory programming students.\n  Our qualitative findings show that learners prefer help that is encouraging,\nincorporates visual aids, and includes peer-related insights, whereas\ninstructors prioritize scaffolding that reflects learners' progress and\nreinforces best practices. Both groups favor shared control, though learners\ngenerally prefer more autonomy, while instructors lean toward greater system\nguidance to prevent cognitive overload. Additionally, our interviews revealed\nindividual differences in control preferences.\n  Based on our findings, we propose design guidelines for AI-supported\nprogramming tools, particularly regarding user-centered help features and\nadaptive control mechanisms. Our work contributes to the human-centered design\nof AI-supported learning environments by informing the development of systems\nthat effectively balance autonomy and guidance, enhancing AI-supported\neducational tools for programming and beyond.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "I.2; K.3"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00144v1",
    "published_date": "2025-02-28 19:50:10 UTC",
    "updated_date": "2025-02-28 19:50:10 UTC"
  },
  {
    "arxiv_id": "2503.00128v1",
    "title": "AnnoCaseLaw: A Richly-Annotated Dataset For Benchmarking Explainable Legal Judgment Prediction",
    "authors": [
      "Magnus Sesodia",
      "Alina Petrova",
      "John Armour",
      "Thomas Lukasiewicz",
      "Oana-Maria Camburu",
      "Puneet K. Dokania",
      "Philip Torr",
      "Christian Schroeder de Witt"
    ],
    "abstract": "Legal systems worldwide continue to struggle with overwhelming caseloads,\nlimited judicial resources, and growing complexities in legal proceedings.\nArtificial intelligence (AI) offers a promising solution, with Legal Judgment\nPrediction (LJP) -- the practice of predicting a court's decision from the case\nfacts -- emerging as a key research area. However, existing datasets often\nformulate the task of LJP unrealistically, not reflecting its true difficulty.\nThey also lack high-quality annotation essential for legal reasoning and\nexplainability. To address these shortcomings, we introduce AnnoCaseLaw, a\nfirst-of-its-kind dataset of 471 meticulously annotated U.S. Appeals Court\nnegligence cases. Each case is enriched with comprehensive, expert-labeled\nannotations that highlight key components of judicial decision making, along\nwith relevant legal concepts. Our dataset lays the groundwork for more\nhuman-aligned, explainable LJP models. We define three legally relevant tasks:\n(1) judgment prediction; (2) concept identification; and (3) automated case\nannotation, and establish a performance baseline using industry-leading large\nlanguage models (LLMs). Our results demonstrate that LJP remains a formidable\ntask, with application of legal precedent proving particularly difficult. Code\nand data are available at https://github.com/anonymouspolar1/annocaselaw.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00128v1",
    "published_date": "2025-02-28 19:14:48 UTC",
    "updated_date": "2025-02-28 19:14:48 UTC"
  },
  {
    "arxiv_id": "2503.16468v1",
    "title": "Towards properly implementing Theory of Mind in AI systems: An account of four misconceptions",
    "authors": [
      "Ramira van der Meulen",
      "Rineke Verbrugge",
      "Max van Duijn"
    ],
    "abstract": "The search for effective collaboration between humans and computer systems is\none of the biggest challenges in Artificial Intelligence. One of the more\neffective mechanisms that humans use to coordinate with one another is theory\nof mind (ToM). ToM can be described as the ability to `take someone else's\nperspective and make estimations of their beliefs, desires and intentions, in\norder to make sense of their behaviour and attitudes towards the world'. If\nleveraged properly, this skill can be very useful in Human-AI collaboration.\n  This introduces the question how we implement ToM when building an AI system.\nHumans and AI Systems work quite differently, and ToM is a multifaceted\nconcept, each facet rooted in different research traditions across the\ncognitive and developmental sciences. We observe that researchers from\nartificial intelligence and the computing sciences, ourselves included, often\nhave difficulties finding their way in the ToM literature. In this paper, we\nidentify four common misconceptions around ToM that we believe should be taken\ninto account when developing an AI system. We have hyperbolised these\nmisconceptions for the sake of the argument, but add nuance in their\ndiscussion.\n  The misconceptions we discuss are:\n  (1) \"Humans Use a ToM Module, So AI Systems Should As Well\".\n  (2) \"Every Social Interaction Requires (Advanced) ToM\".\n  (3) \"All ToM is the Same\".\n  (4) \"Current Systems Already Have ToM\".\n  After discussing the misconception, we end each section by providing\ntentative guidelines on how the misconception can be overcome.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "19 pages, draft version",
    "pdf_url": "http://arxiv.org/pdf/2503.16468v1",
    "published_date": "2025-02-28 19:12:35 UTC",
    "updated_date": "2025-02-28 19:12:35 UTC"
  },
  {
    "arxiv_id": "2503.00124v1",
    "title": "Evaluation of LLMs-based Hidden States as Author Representations for Psychological Human-Centered NLP Tasks",
    "authors": [
      "Nikita Soni",
      "Pranav Chitale",
      "Khushboo Singh",
      "Niranjan Balasubramanian",
      "H. Andrew Schwartz"
    ],
    "abstract": "Like most of NLP, models for human-centered NLP tasks -- tasks attempting to\nassess author-level information -- predominantly use representations derived\nfrom hidden states of Transformer-based LLMs. However, what component of the LM\nis used for the representation varies widely. Moreover, there is a need for\nHuman Language Models (HuLMs) that implicitly model the author and provide a\nuser-level hidden state. Here, we systematically evaluate different ways of\nrepresenting documents and users using different LM and HuLM architectures to\npredict task outcomes as both dynamically changing states and averaged\ntrait-like user-level attributes of valence, arousal, empathy, and distress. We\nfind that representing documents as an average of the token hidden states\nperforms the best generally. Further, while a user-level hidden state itself is\nrarely the best representation, we find its inclusion in the model strengthens\ntoken or document embeddings used to derive document- and user-level\nrepresentations resulting in best performances.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear in Findings of NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.00124v1",
    "published_date": "2025-02-28 19:10:06 UTC",
    "updated_date": "2025-02-28 19:10:06 UTC"
  },
  {
    "arxiv_id": "2502.21309v2",
    "title": "FANformer: Improving Large Language Models Through Effective Periodicity Modeling",
    "authors": [
      "Yihong Dong",
      "Ge Li",
      "Xue Jiang",
      "Yongding Tao",
      "Kechi Zhang",
      "Hao Zhu",
      "Huanyu Liu",
      "Jiazheng Ding",
      "Jia Li",
      "Jinliang Deng",
      "Hong Mei"
    ],
    "abstract": "Periodicity, as one of the most important basic characteristics, lays the\nfoundation for facilitating structured knowledge acquisition and systematic\ncognitive processes within human learning paradigms. However, the potential\nflaws of periodicity modeling in Transformer affect the learning efficiency and\nestablishment of underlying principles from data for large language models\n(LLMs) built upon it. In this paper, we demonstrate that integrating effective\nperiodicity modeling can improve the learning efficiency and performance of\nLLMs. We introduce FANformer, which adapts Fourier Analysis Network (FAN) into\nattention mechanism to achieve efficient periodicity modeling, by modifying the\nfeature projection process of attention mechanism. Extensive experimental\nresults on language modeling show that FANformer consistently outperforms\nTransformer when scaling up model size and training tokens, underscoring its\nsuperior learning efficiency. Our pretrained FANformer-1B exhibits marked\nimprovements on downstream tasks compared to open-source LLMs with similar\nmodel parameters or training tokens. Moreover, we reveal that FANformer\nexhibits superior ability to learn and apply rules for reasoning compared to\nTransformer. The results position FANformer as an effective and promising\narchitecture for advancing LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21309v2",
    "published_date": "2025-02-28 18:52:24 UTC",
    "updated_date": "2025-05-17 13:11:56 UTC"
  },
  {
    "arxiv_id": "2503.00096v2",
    "title": "BixBench: a Comprehensive Benchmark for LLM-based Agents in Computational Biology",
    "authors": [
      "Ludovico Mitchener",
      "Jon M Laurent",
      "Benjamin Tenmann",
      "Siddharth Narayanan",
      "Geemi P Wellawatte",
      "Andrew White",
      "Lorenzo Sani",
      "Samuel G Rodriques"
    ],
    "abstract": "Large Language Models (LLMs) and LLM-based agents show great promise in\naccelerating scientific research. Existing benchmarks for measuring this\npotential and guiding future development continue to evolve from pure recall\nand rote knowledge tasks, towards more practical work such as literature review\nand experimental planning. Bioinformatics is a domain where fully autonomous\nAI-driven discovery may be near, but no extensive benchmarks for measuring\nprogress have been introduced to date. We therefore present the Bioinformatics\nBenchmark (BixBench), a dataset comprising over 50 real-world scenarios of\npractical biological data analysis with nearly 300 associated open-answer\nquestions designed to measure the ability of LLM-based agents to explore\nbiological datasets, perform long, multi-step analytical trajectories, and\ninterpret the nuanced results of those analyses. We evaluate the performance of\ntwo frontier LLMs (GPT-4o and Claude 3.5 Sonnet) using a custom agent framework\nwe open source. We find that even the latest frontier models only achieve 17%\naccuracy in the open-answer regime, and no better than random in a\nmultiple-choice setting. By exposing the current limitations of frontier\nmodels, we hope BixBench can spur the development of agents capable of\nconducting rigorous bioinformatic analysis and accelerate scientific discovery.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "8 main text pages, 5 main figures",
    "pdf_url": "http://arxiv.org/pdf/2503.00096v2",
    "published_date": "2025-02-28 18:47:57 UTC",
    "updated_date": "2025-03-08 00:57:19 UTC"
  },
  {
    "arxiv_id": "2502.21304v1",
    "title": "Clustering Context in Off-Policy Evaluation",
    "authors": [
      "Daniel Guzman-Olivares",
      "Philipp Schmidt",
      "Jacek Golebiowski",
      "Artur Bekasov"
    ],
    "abstract": "Off-policy evaluation can leverage logged data to estimate the effectiveness\nof new policies in e-commerce, search engines, media streaming services, or\nautomatic diagnostic tools in healthcare. However, the performance of baseline\noff-policy estimators like IPS deteriorates when the logging policy\nsignificantly differs from the evaluation policy. Recent work proposes sharing\ninformation across similar actions to mitigate this problem. In this work, we\npropose an alternative estimator that shares information across similar\ncontexts using clustering. We study the theoretical properties of the proposed\nestimator, characterizing its bias and variance under different conditions. We\nalso compare the performance of the proposed estimator and existing approaches\nin various synthetic problems, as well as a real-world recommendation dataset.\nOur experimental results confirm that clustering contexts improves estimation\naccuracy, especially in deficient information settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "35 pages, 25 figures, 2 tables. AISTATS 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.21304v1",
    "published_date": "2025-02-28 18:40:41 UTC",
    "updated_date": "2025-02-28 18:40:41 UTC"
  },
  {
    "arxiv_id": "2502.21290v1",
    "title": "Contextualizing biological perturbation experiments through language",
    "authors": [
      "Menghua Wu",
      "Russell Littman",
      "Jacob Levine",
      "Lin Qiu",
      "Tommaso Biancalani",
      "David Richmond",
      "Jan-Christian Huetter"
    ],
    "abstract": "High-content perturbation experiments allow scientists to probe biomolecular\nsystems at unprecedented resolution, but experimental and analysis costs pose\nsignificant barriers to widespread adoption. Machine learning has the potential\nto guide efficient exploration of the perturbation space and extract novel\ninsights from these data. However, current approaches neglect the semantic\nrichness of the relevant biology, and their objectives are misaligned with\ndownstream biological analyses. In this paper, we hypothesize that large\nlanguage models (LLMs) present a natural medium for representing complex\nbiological relationships and rationalizing experimental outcomes. We propose\nPerturbQA, a benchmark for structured reasoning over perturbation experiments.\nUnlike current benchmarks that primarily interrogate existing knowledge,\nPerturbQA is inspired by open problems in perturbation modeling: prediction of\ndifferential expression and change of direction for unseen perturbations, and\ngene set enrichment. We evaluate state-of-the-art machine learning and\nstatistical approaches for modeling perturbations, as well as standard LLM\nreasoning strategies, and we find that current methods perform poorly on\nPerturbQA. As a proof of feasibility, we introduce Summer (SUMMarize, retrievE,\nand answeR, a simple, domain-informed LLM framework that matches or exceeds the\ncurrent state-of-the-art. Our code and data are publicly available at\nhttps://github.com/genentech/PerturbQA.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "The Thirteenth International Conference on Learning Representations\n  (2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.21290v1",
    "published_date": "2025-02-28 18:15:31 UTC",
    "updated_date": "2025-02-28 18:15:31 UTC"
  },
  {
    "arxiv_id": "2502.21279v1",
    "title": "L-Lipschitz Gershgorin ResNet Network",
    "authors": [
      "Marius F. R. Juston",
      "William R. Norris",
      "Dustin Nottage",
      "Ahmet Soylemezoglu"
    ],
    "abstract": "Deep residual networks (ResNets) have demonstrated outstanding success in\ncomputer vision tasks, attributed to their ability to maintain gradient flow\nthrough deep architectures. Simultaneously, controlling the Lipschitz bound in\nneural networks has emerged as an essential area of research for enhancing\nadversarial robustness and network certifiability. This paper uses a rigorous\napproach to design $\\mathcal{L}$-Lipschitz deep residual networks using a\nLinear Matrix Inequality (LMI) framework. The ResNet architecture was\nreformulated as a pseudo-tri-diagonal LMI with off-diagonal elements and\nderived closed-form constraints on network parameters to ensure\n$\\mathcal{L}$-Lipschitz continuity. To address the lack of explicit eigenvalue\ncomputations for such matrix structures, the Gershgorin circle theorem was\nemployed to approximate eigenvalue locations, guaranteeing the LMI's negative\nsemi-definiteness. Our contributions include a provable parameterization\nmethodology for constructing Lipschitz-constrained networks and a compositional\nframework for managing recursive systems within hierarchical architectures.\nThese findings enable robust network designs applicable to adversarial\nrobustness, certified training, and control systems. However, a limitation was\nidentified in the Gershgorin-based approximations, which over-constrain the\nsystem, suppressing non-linear dynamics and diminishing the network's\nexpressive capacity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.21279v1",
    "published_date": "2025-02-28 17:57:57 UTC",
    "updated_date": "2025-02-28 17:57:57 UTC"
  },
  {
    "arxiv_id": "2502.21274v1",
    "title": "BAnG: Bidirectional Anchored Generation for Conditional RNA Design",
    "authors": [
      "Roman Klypa",
      "Alberto Bietti",
      "Sergei Grudinin"
    ],
    "abstract": "Designing RNA molecules that interact with specific proteins is a critical\nchallenge in experimental and computational biology. Existing computational\napproaches require a substantial amount of experimentally determined RNA\nsequences for each specific protein or a detailed knowledge of RNA structure,\nrestricting their utility in practice. To address this limitation, we develop\nRNA-BAnG, a deep learning-based model designed to generate RNA sequences for\nprotein interactions without these requirements. Central to our approach is a\nnovel generative method, Bidirectional Anchored Generation (BAnG), which\nleverages the observation that protein-binding RNA sequences often contain\nfunctional binding motifs embedded within broader sequence contexts. We first\nvalidate our method on generic synthetic tasks involving similar localized\nmotifs to those appearing in RNAs, demonstrating its benefits over existing\ngenerative approaches. We then evaluate our model on biological sequences,\nshowing its effectiveness for conditional RNA sequence design given a binding\nprotein.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21274v1",
    "published_date": "2025-02-28 17:51:00 UTC",
    "updated_date": "2025-02-28 17:51:00 UTC"
  },
  {
    "arxiv_id": "2502.21271v1",
    "title": "Adaptive Keyframe Sampling for Long Video Understanding",
    "authors": [
      "Xi Tang",
      "Jihao Qiu",
      "Lingxi Xie",
      "Yunjie Tian",
      "Jianbin Jiao",
      "Qixiang Ye"
    ],
    "abstract": "Multimodal large language models (MLLMs) have enabled open-world visual\nunderstanding by injecting visual input as extra tokens into large language\nmodels (LLMs) as contexts. However, when the visual input changes from a single\nimage to a long video, the above paradigm encounters difficulty because the\nvast amount of video tokens has significantly exceeded the maximal capacity of\nMLLMs. Therefore, existing video-based MLLMs are mostly established upon\nsampling a small portion of tokens from input data, which can cause key\ninformation to be lost and thus produce incorrect answers. This paper presents\na simple yet effective algorithm named Adaptive Keyframe Sampling (AKS). It\ninserts a plug-and-play module known as keyframe selection, which aims to\nmaximize the useful information with a fixed number of video tokens. We\nformulate keyframe selection as an optimization involving (1) the relevance\nbetween the keyframes and the prompt, and (2) the coverage of the keyframes\nover the video, and present an adaptive algorithm to approximate the best\nsolution. Experiments on two long video understanding benchmarks validate that\nAdaptive Keyframe Sampling improves video QA accuracy (beyond strong baselines)\nupon selecting informative keyframes. Our study reveals the importance of\ninformation pre-filtering in video-based MLLMs. Code is available at\nhttps://github.com/ncTimTang/AKS.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR2025",
    "pdf_url": "http://arxiv.org/pdf/2502.21271v1",
    "published_date": "2025-02-28 17:46:29 UTC",
    "updated_date": "2025-02-28 17:46:29 UTC"
  },
  {
    "arxiv_id": "2502.21266v1",
    "title": "Supporting the development of Machine Learning for fundamental science in a federated Cloud with the AI_INFN platform",
    "authors": [
      "Lucio Anderlini",
      "Matteo Barbetti",
      "Giulio Bianchini",
      "Diego Ciangottini",
      "Stefano Dal Pra",
      "Diego Michelotto",
      "Carmelo Pellegrino",
      "Rosa Petrini",
      "Alessandro Pascolini",
      "Daniele Spiga"
    ],
    "abstract": "Machine Learning (ML) is driving a revolution in the way scientists design,\ndevelop, and deploy data-intensive software. However, the adoption of ML\npresents new challenges for the computing infrastructure, particularly in terms\nof provisioning and orchestrating access to hardware accelerators for\ndevelopment, testing, and production. The INFN-funded project AI_INFN\n(\"Artificial Intelligence at INFN\") aims at fostering the adoption of ML\ntechniques within INFN use cases by providing support on multiple aspects,\nincluding the provision of AI-tailored computing resources. It leverages\ncloud-native solutions in the context of INFN Cloud, to share hardware\naccelerators as effectively as possible, ensuring the diversity of the\nInstitute's research activities is not compromised. In this contribution, we\nprovide an update on the commissioning of a Kubernetes platform designed to\nease the development of GPU-powered data analysis workflows and their\nscalability on heterogeneous, distributed computing resources, possibly\nfederated as Virtual Kubelets with the interLink provider.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "physics.data-an"
    ],
    "primary_category": "cs.DC",
    "comment": "Under review in EPJ Web of Conferences (CHEP 2024)",
    "pdf_url": "http://arxiv.org/pdf/2502.21266v1",
    "published_date": "2025-02-28 17:42:58 UTC",
    "updated_date": "2025-02-28 17:42:58 UTC"
  },
  {
    "arxiv_id": "2502.21267v1",
    "title": "ReaLJam: Real-Time Human-AI Music Jamming with Reinforcement Learning-Tuned Transformers",
    "authors": [
      "Alexander Scarlatos",
      "Yusong Wu",
      "Ian Simon",
      "Adam Roberts",
      "Tim Cooijmans",
      "Natasha Jaques",
      "Cassie Tarakajian",
      "Cheng-Zhi Anna Huang"
    ],
    "abstract": "Recent advances in generative artificial intelligence (AI) have created\nmodels capable of high-quality musical content generation. However, little\nconsideration is given to how to use these models for real-time or cooperative\njamming musical applications because of crucial required features: low latency,\nthe ability to communicate planned actions, and the ability to adapt to user\ninput in real-time. To support these needs, we introduce ReaLJam, an interface\nand protocol for live musical jamming sessions between a human and a\nTransformer-based AI agent trained with reinforcement learning. We enable\nreal-time interactions using the concept of anticipation, where the agent\ncontinually predicts how the performance will unfold and visually conveys its\nplan to the user. We conduct a user study where experienced musicians jam in\nreal-time with the agent through ReaLJam. Our results demonstrate that ReaLJam\nenables enjoyable and musically interesting sessions, and we uncover important\ntakeaways for future work.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Published in Extended Abstracts of the CHI Conference on Human\n  Factors in Computing Systems (CHI EA '25), April 26-May 1, 2025, Yokohama,\n  Japan",
    "pdf_url": "http://arxiv.org/pdf/2502.21267v1",
    "published_date": "2025-02-28 17:42:58 UTC",
    "updated_date": "2025-02-28 17:42:58 UTC"
  },
  {
    "arxiv_id": "2502.21264v2",
    "title": "Foundation Models -- A Panacea for Artificial Intelligence in Pathology?",
    "authors": [
      "Nita Mulliqi",
      "Anders Blilie",
      "Xiaoyi Ji",
      "Kelvin Szolnoky",
      "Henrik Olsson",
      "Sol Erika Boman",
      "Matteo Titus",
      "Geraldine Martinez Gonzalez",
      "Julia Anna Mielcarz",
      "Masi Valkonen",
      "Einar Gudlaugsson",
      "Svein R. Kjosavik",
      "José Asenjo",
      "Marcello Gambacorta",
      "Paolo Libretti",
      "Marcin Braun",
      "Radzislaw Kordek",
      "Roman Łowicki",
      "Kristina Hotakainen",
      "Päivi Väre",
      "Bodil Ginnerup Pedersen",
      "Karina Dalsgaard Sørensen",
      "Benedicte Parm Ulhøi",
      "Pekka Ruusuvuori",
      "Brett Delahunt",
      "Hemamali Samaratunga",
      "Toyonori Tsuzuki",
      "Emilius A. M. Janssen",
      "Lars Egevad",
      "Martin Eklund",
      "Kimmo Kartasalo"
    ],
    "abstract": "The role of artificial intelligence (AI) in pathology has evolved from aiding\ndiagnostics to uncovering predictive morphological patterns in whole slide\nimages (WSIs). Recently, foundation models (FMs) leveraging self-supervised\npre-training have been widely advocated as a universal solution for diverse\ndownstream tasks. However, open questions remain about their clinical\napplicability and generalization advantages over end-to-end learning using\ntask-specific (TS) models. Here, we focused on AI with clinical-grade\nperformance for prostate cancer diagnosis and Gleason grading. We present the\nlargest validation of AI for this task, using over 100,000 core needle biopsies\nfrom 7,342 patients across 15 sites in 11 countries. We compared two FMs with a\nfully end-to-end TS model in a multiple instance learning framework. Our\nfindings challenge assumptions that FMs universally outperform TS models. While\nFMs demonstrated utility in data-scarce scenarios, their performance converged\nwith - and was in some cases surpassed by - TS models when sufficient labeled\ntraining data were available. Notably, extensive task-specific training\nmarkedly reduced clinically significant misgrading, misdiagnosis of challenging\nmorphologies, and variability across different WSI scanners. Additionally, FMs\nused up to 35 times more energy than the TS model, raising concerns about their\nsustainability. Our results underscore that while FMs offer clear advantages\nfor rapid prototyping and research, their role as a universal solution for\nclinically applicable medical AI remains uncertain. For high-stakes clinical\napplications, rigorous validation and consideration of task-specific training\nremain critically important. We advocate for integrating the strengths of FMs\nand end-to-end learning to achieve robust and resource-efficient AI pathology\nsolutions fit for clinical use.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "50 pages, 15 figures and an appendix (study protocol) which is\n  previously published, see https://doi.org/10.1101/2024.07.04.24309948;\n  updated authors list format",
    "pdf_url": "http://arxiv.org/pdf/2502.21264v2",
    "published_date": "2025-02-28 17:40:45 UTC",
    "updated_date": "2025-03-03 10:35:23 UTC"
  },
  {
    "arxiv_id": "2502.21263v1",
    "title": "RuCCoD: Towards Automated ICD Coding in Russian",
    "authors": [
      "Aleksandr Nesterov",
      "Andrey Sakhovskiy",
      "Ivan Sviridov",
      "Airat Valiev",
      "Vladimir Makharev",
      "Petr Anokhin",
      "Galina Zubkova",
      "Elena Tutubalina"
    ],
    "abstract": "This study investigates the feasibility of automating clinical coding in\nRussian, a language with limited biomedical resources. We present a new dataset\nfor ICD coding, which includes diagnosis fields from electronic health records\n(EHRs) annotated with over 10,000 entities and more than 1,500 unique ICD\ncodes. This dataset serves as a benchmark for several state-of-the-art models,\nincluding BERT, LLaMA with LoRA, and RAG, with additional experiments examining\ntransfer learning across domains (from PubMed abstracts to medical diagnosis)\nand terminologies (from UMLS concepts to ICD codes). We then apply the\nbest-performing model to label an in-house EHR dataset containing patient\nhistories from 2017 to 2021. Our experiments, conducted on a carefully curated\ntest set, demonstrate that training with the automated predicted codes leads to\na significant improvement in accuracy compared to manually annotated data from\nphysicians. We believe our findings offer valuable insights into the potential\nfor automating clinical coding in resource-limited languages like Russian,\nwhich could enhance clinical efficiency and data accuracy in these contexts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21263v1",
    "published_date": "2025-02-28 17:40:24 UTC",
    "updated_date": "2025-02-28 17:40:24 UTC"
  },
  {
    "arxiv_id": "2502.21262v1",
    "title": "Modeling Human Beliefs about AI Behavior for Scalable Oversight",
    "authors": [
      "Leon Lang",
      "Patrick Forré"
    ],
    "abstract": "Contemporary work in AI alignment often relies on human feedback to teach AI\nsystems human preferences and values. Yet as AI systems grow more capable,\nhuman feedback becomes increasingly unreliable. This raises the problem of\nscalable oversight: How can we supervise AI systems that exceed human\ncapabilities? In this work, we propose to model the human evaluator's beliefs\nabout the AI system's behavior to better interpret the human's feedback. We\nformalize human belief models and theoretically analyze their role in inferring\nhuman values. We then characterize the remaining ambiguity in this inference\nand conditions for which the ambiguity disappears. To mitigate reliance on\nexact belief models, we then introduce the relaxation of human belief model\ncovering. Finally, we propose using foundation models to construct covering\nbelief models, providing a new potential approach to scalable oversight.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "53 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.21262v1",
    "published_date": "2025-02-28 17:39:55 UTC",
    "updated_date": "2025-02-28 17:39:55 UTC"
  },
  {
    "arxiv_id": "2502.21250v1",
    "title": "Towards Developing Ethical Reasoners: Integrating Probabilistic Reasoning and Decision-Making for Complex AI Systems",
    "authors": [
      "Nijesh Upreti",
      "Jessica Ciupa",
      "Vaishak Belle"
    ],
    "abstract": "A computational ethics framework is essential for AI and autonomous systems\noperating in complex, real-world environments. Existing approaches often lack\nthe adaptability needed to integrate ethical principles into dynamic and\nambiguous contexts, limiting their effectiveness across diverse scenarios. To\naddress these challenges, we outline the necessary ingredients for building a\nholistic, meta-level framework that combines intermediate representations,\nprobabilistic reasoning, and knowledge representation. The specifications\ntherein emphasize scalability, supporting ethical reasoning at both individual\ndecision-making levels and within the collective dynamics of multi-agent\nsystems. By integrating theoretical principles with contextual factors, it\nfacilitates structured and context-aware decision-making, ensuring alignment\nwith overarching ethical standards. We further explore proposed theorems\noutlining how ethical reasoners should operate, offering a foundation for\npractical implementation. These constructs aim to support the development of\nrobust and ethically reliable AI systems capable of navigating the complexities\nof real-world moral decision-making scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21250v1",
    "published_date": "2025-02-28 17:25:11 UTC",
    "updated_date": "2025-02-28 17:25:11 UTC"
  },
  {
    "arxiv_id": "2502.21236v1",
    "title": "Transforming Tuberculosis Care: Optimizing Large Language Models For Enhanced Clinician-Patient Communication",
    "authors": [
      "Daniil Filienko",
      "Mahek Nizar",
      "Javier Roberti",
      "Denise Galdamez",
      "Haroon Jakher",
      "Sarah Iribarren",
      "Weichao Yuwen",
      "Martine De Cock"
    ],
    "abstract": "Tuberculosis (TB) is the leading cause of death from an infectious disease\nglobally, with the highest burden in low- and middle-income countries. In these\nregions, limited healthcare access and high patient-to-provider ratios impede\neffective patient support, communication, and treatment completion. To bridge\nthis gap, we propose integrating a specialized Large Language Model into an\nefficacious digital adherence technology to augment interactive communication\nwith treatment supporters. This AI-powered approach, operating within a\nhuman-in-the-loop framework, aims to enhance patient engagement and improve TB\ntreatment outcomes.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "GenAI4Health at AAAI-25",
    "pdf_url": "http://arxiv.org/pdf/2502.21236v1",
    "published_date": "2025-02-28 17:05:13 UTC",
    "updated_date": "2025-02-28 17:05:13 UTC"
  },
  {
    "arxiv_id": "2502.21231v1",
    "title": "ByteScale: Efficient Scaling of LLM Training with a 2048K Context Length on More Than 12,000 GPUs",
    "authors": [
      "Hao Ge",
      "Junda Feng",
      "Qi Huang",
      "Fangcheng Fu",
      "Xiaonan Nie",
      "Lei Zuo",
      "Haibin Lin",
      "Bin Cui",
      "Xin Liu"
    ],
    "abstract": "Scaling long-context ability is essential for Large Language Models (LLMs).\nTo amortize the memory consumption across multiple devices in long-context\ntraining, inter-data partitioning (a.k.a. Data Parallelism) and intra-data\npartitioning (a.k.a. Context Parallelism) are commonly used. Current training\nframeworks predominantly treat the two techniques as orthogonal, and establish\nstatic communication groups to organize the devices as a static mesh (e.g., a\n2D mesh). However, the sequences for LLM training typically vary in lengths, no\nmatter for texts, multi-modalities or reinforcement learning. The mismatch\nbetween data heterogeneity and static mesh causes redundant communication and\nimbalanced computation, degrading the training efficiency.\n  In this work, we introduce ByteScale, an efficient, flexible, and scalable\nLLM training framework for large-scale mixed training of long and short\nsequences. The core of ByteScale is a novel parallelism strategy, namely Hybrid\nData Parallelism (HDP), which unifies the inter- and intra-data partitioning\nwith a dynamic mesh design. In particular, we build a communication optimizer,\nwhich eliminates the redundant communication for short sequences by data-aware\nsharding and dynamic communication, and further compresses the communication\ncost for long sequences by selective offloading. Besides, we also develop a\nbalance scheduler to mitigate the imbalanced computation by parallelism-aware\ndata assignment. We evaluate ByteScale with the model sizes ranging from 7B to\n141B, context lengths from 256K to 2048K, on a production cluster with more\nthan 12,000 GPUs. Experiment results show that ByteScale outperforms the\nstate-of-the-art training system by up to 7.89x.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "12 pages, 21 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.21231v1",
    "published_date": "2025-02-28 17:01:03 UTC",
    "updated_date": "2025-02-28 17:01:03 UTC"
  },
  {
    "arxiv_id": "2502.21228v2",
    "title": "ECLeKTic: a Novel Challenge Set for Evaluation of Cross-Lingual Knowledge Transfer",
    "authors": [
      "Omer Goldman",
      "Uri Shaham",
      "Dan Malkin",
      "Sivan Eiger",
      "Avinatan Hassidim",
      "Yossi Matias",
      "Joshua Maynez",
      "Adi Mayrav Gilady",
      "Jason Riesa",
      "Shruti Rijhwani",
      "Laura Rimell",
      "Idan Szpektor",
      "Reut Tsarfaty",
      "Matan Eyal"
    ],
    "abstract": "To achieve equitable performance across languages, multilingual large\nlanguage models (LLMs) must be able to abstract knowledge beyond the language\nin which it was acquired. However, the current literature lacks reliable ways\nto measure LLMs' capability of cross-lingual knowledge transfer. To that end,\nwe present ECLeKTic, a multilingual closed-book QA (CBQA) dataset that\nEvaluates Cross-Lingual Knowledge Transfer in a simple, black-box manner. We\ndetected information with uneven coverage across languages by controlling for\npresence and absence of Wikipedia articles in 12 languages. We generated\nknowledge-seeking questions in a source language, for which the answer appears\nin a relevant Wikipedia article and translated them to all other 11 languages,\nfor which the respective Wikipedias lack equivalent articles. Assuming that\nWikipedia reflects the prominent knowledge in the LLM's training data, to solve\nECLeKTic's CBQA task the model is required to transfer knowledge between\nlanguages. Experimenting with 8 LLMs, we show that SOTA models struggle to\neffectively share knowledge across, languages even if they can predict the\nanswer well for queries in the same language the knowledge was acquired in.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21228v2",
    "published_date": "2025-02-28 16:59:30 UTC",
    "updated_date": "2025-03-03 09:11:46 UTC"
  },
  {
    "arxiv_id": "2503.00093v1",
    "title": "Rethinking LLM Bias Probing Using Lessons from the Social Sciences",
    "authors": [
      "Kirsten N. Morehouse",
      "Siddharth Swaroop",
      "Weiwei Pan"
    ],
    "abstract": "The proliferation of LLM bias probes introduces three significant challenges:\n(1) we lack principled criteria for choosing appropriate probes, (2) we lack a\nsystem for reconciling conflicting results across probes, and (3) we lack\nformal frameworks for reasoning about when (and why) probe results will\ngeneralize to real user behavior. We address these challenges by systematizing\nLLM social bias probing using actionable insights from social sciences. We then\nintroduce EcoLevels - a framework that helps (a) determine appropriate bias\nprobes, (b) reconcile conflicting findings across probes, and (c) generate\npredictions about bias generalization. Overall, we ground our analysis in\nsocial science research because many LLM probes are direct applications of\nhuman probes, and these fields have faced similar challenges when studying\nsocial bias in humans. Based on our work, we suggest how the next generation of\nLLM bias probing can (and should) benefit from decades of social science\nresearch.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00093v1",
    "published_date": "2025-02-28 16:53:18 UTC",
    "updated_date": "2025-02-28 16:53:18 UTC"
  },
  {
    "arxiv_id": "2502.21220v1",
    "title": "XAIxArts Manifesto: Explainable AI for the Arts",
    "authors": [
      "Nick Bryan-Kinns",
      "Shuoyang Jasper Zheng",
      "Francisco Castro",
      "Makayla Lewis",
      "Jia-Rey Chang",
      "Gabriel Vigliensoni",
      "Terence Broad",
      "Michael Clemens",
      "Elizabeth Wilson"
    ],
    "abstract": "Explainable AI (XAI) is concerned with how to make AI models more\nunderstandable to people. To date these explanations have predominantly been\ntechnocentric - mechanistic or productivity oriented. This paper introduces the\nExplainable AI for the Arts (XAIxArts) manifesto to provoke new ways of\nthinking about explainability and AI beyond technocentric discourses.\nManifestos offer a means to communicate ideas, amplify unheard voices, and\nfoster reflection on practice. To supports the co-creation and revision of the\nXAIxArts manifesto we combine a World Caf\\'e style discussion format with a\nliving manifesto to question four core themes: 1) Empowerment, Inclusion, and\nFairness; 2) Valuing Artistic Practice; 3) Hacking and Glitches; and 4)\nOpenness. Through our interactive living manifesto experience we invite\nparticipants to actively engage in shaping this XIAxArts vision within the CHI\ncommunity and beyond.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Author version of paper in: Extended Abstracts of the CHI Conference\n  on Human Factors in Computing Systems, April 26-May 1, 2025, Yokohama, Japan\n  DOI 10.1145/3706599.3716227 ISBN 979-8-4007-1395-8/25/04",
    "pdf_url": "http://arxiv.org/pdf/2502.21220v1",
    "published_date": "2025-02-28 16:50:17 UTC",
    "updated_date": "2025-02-28 16:50:17 UTC"
  },
  {
    "arxiv_id": "2502.21216v1",
    "title": "An Algebraic Framework for Hierarchical Probabilistic Abstraction",
    "authors": [
      "Nijesh Upreti",
      "Vaishak Belle"
    ],
    "abstract": "Abstraction is essential for reducing the complexity of systems across\ndiverse fields, yet designing effective abstraction methodology for\nprobabilistic models is inherently challenging due to stochastic behaviors and\nuncertainties. Current approaches often distill detailed probabilistic data\ninto higher-level summaries to support tractable and interpretable analyses,\nthough they typically struggle to fully represent the relational and\nprobabilistic hierarchies through single-layered abstractions. We introduce a\nhierarchical probabilistic abstraction framework aimed at addressing these\nchallenges by extending a measure-theoretic foundation for hierarchical\nabstraction. The framework enables modular problem-solving via layered\nmappings, facilitating both detailed layer-specific analysis and a cohesive\nsystem-wide understanding. This approach bridges high-level conceptualization\nwith low-level perceptual data, enhancing interpretability and allowing layered\nanalysis. Our framework provides a robust foundation for abstraction analysis\nacross AI subfields, particularly in aligning System 1 and System 2 thinking,\nthereby supporting the development of diverse abstraction methodologies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21216v1",
    "published_date": "2025-02-28 16:47:42 UTC",
    "updated_date": "2025-02-28 16:47:42 UTC"
  },
  {
    "arxiv_id": "2502.21212v1",
    "title": "Transformers Learn to Implement Multi-step Gradient Descent with Chain of Thought",
    "authors": [
      "Jianhao Huang",
      "Zixuan Wang",
      "Jason D. Lee"
    ],
    "abstract": "Chain of Thought (CoT) prompting has been shown to significantly improve the\nperformance of large language models (LLMs), particularly in arithmetic and\nreasoning tasks, by instructing the model to produce intermediate reasoning\nsteps. Despite the remarkable empirical success of CoT and its theoretical\nadvantages in enhancing expressivity, the mechanisms underlying CoT training\nremain largely unexplored. In this paper, we study the training dynamics of\ntransformers over a CoT objective on an in-context weight prediction task for\nlinear regression. We prove that while a one-layer linear transformer without\nCoT can only implement a single step of gradient descent (GD) and fails to\nrecover the ground-truth weight vector, a transformer with CoT prompting can\nlearn to perform multi-step GD autoregressively, achieving near-exact recovery.\nFurthermore, we show that the trained transformer effectively generalizes on\nthe unseen data. With our technique, we also show that looped transformers\nsignificantly improve final performance compared to transformers without\nlooping in the in-context learning of linear regression. Empirically, we\ndemonstrate that CoT prompting yields substantial performance improvements.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025 Spotlight",
    "pdf_url": "http://arxiv.org/pdf/2502.21212v1",
    "published_date": "2025-02-28 16:40:38 UTC",
    "updated_date": "2025-02-28 16:40:38 UTC"
  },
  {
    "arxiv_id": "2503.00092v1",
    "title": "EdgeAIGuard: Agentic LLMs for Minor Protection in Digital Spaces",
    "authors": [
      "Ghulam Mujtaba",
      "Sunder Ali Khowaja",
      "Kapal Dev"
    ],
    "abstract": "Social media has become integral to minors' daily lives and is used for\nvarious purposes, such as making friends, exploring shared interests, and\nengaging in educational activities. However, the increase in screen time has\nalso led to heightened challenges, including cyberbullying, online grooming,\nand exploitations posed by malicious actors. Traditional content moderation\ntechniques have proven ineffective against exploiters' evolving tactics. To\naddress these growing challenges, we propose the EdgeAIGuard content moderation\napproach that is designed to protect minors from online grooming and various\nforms of digital exploitation. The proposed method comprises a multi-agent\narchitecture deployed strategically at the network edge to enable rapid\ndetection with low latency and prevent harmful content targeting minors. The\nexperimental results show the proposed method is significantly more effective\nthan the existing approaches.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00092v1",
    "published_date": "2025-02-28 16:29:34 UTC",
    "updated_date": "2025-02-28 16:29:34 UTC"
  },
  {
    "arxiv_id": "2502.21208v1",
    "title": "ARIES: Autonomous Reasoning with LLMs on Interactive Thought Graph Environments",
    "authors": [
      "Pedro Gimenes",
      "Zeyu Cao",
      "Jeffrey Wong",
      "Yiren Zhao"
    ],
    "abstract": "Recent research has shown that LLM performance on reasoning tasks can be\nenhanced by scaling test-time compute. One promising approach, particularly\nwith decomposable problems, involves arranging intermediate solutions as a\ngraph on which transformations are performed to explore the solution space.\nHowever, prior works rely on pre-determined, task-specific transformation\nschedules which are subject to a set of searched hyperparameters. In this work,\nwe view thought graph transformations as actions in a Markov decision process,\nand implement policy agents to drive effective action policies for the\nunderlying reasoning LLM agent. In particular, we investigate the ability for\nanother LLM to act as a policy agent on thought graph environments and\nintroduce ARIES, a multi-agent architecture for reasoning with LLMs. In ARIES,\nreasoning LLM agents solve decomposed subproblems, while policy LLM agents\nmaintain visibility of the thought graph states, and dynamically adapt the\nproblem-solving strategy. Through extensive experiments, we observe that using\noff-the-shelf LLMs as policy agents with no supervised fine-tuning (SFT) can\nyield up to $29\\%$ higher accuracy on HumanEval relative to static\ntransformation schedules, as well as reducing inference costs by $35\\%$ and\navoid any search requirements. We also conduct a thorough analysis of observed\nfailure modes, highlighting that limitations on LLM sizes and the depth of\nproblem decomposition can be seen as challenges to scaling LLM-guided\nreasoning.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21208v1",
    "published_date": "2025-02-28 16:28:13 UTC",
    "updated_date": "2025-02-28 16:28:13 UTC"
  },
  {
    "arxiv_id": "2502.21201v3",
    "title": "The PanAf-FGBG Dataset: Understanding the Impact of Backgrounds in Wildlife Behaviour Recognition",
    "authors": [
      "Otto Brookes",
      "Maksim Kukushkin",
      "Majid Mirmehdi",
      "Colleen Stephens",
      "Paula Dieguez",
      "Thurston C. Hicks",
      "Sorrel Jones",
      "Kevin Lee",
      "Maureen S. McCarthy",
      "Amelia Meier",
      "Emmanuelle Normand",
      "Erin G. Wessling",
      "Roman M. Wittig",
      "Kevin Langergraber",
      "Klaus Zuberbühler",
      "Lukas Boesch",
      "Thomas Schmid",
      "Mimi Arandjelovic",
      "Hjalmar Kühl",
      "Tilo Burghardt"
    ],
    "abstract": "Computer vision analysis of camera trap video footage is essential for\nwildlife conservation, as captured behaviours offer some of the earliest\nindicators of changes in population health. Recently, several high-impact\nanimal behaviour datasets and methods have been introduced to encourage their\nuse; however, the role of behaviour-correlated background information and its\nsignificant effect on out-of-distribution generalisation remain unexplored. In\nresponse, we present the PanAf-FGBG dataset, featuring 20 hours of wild\nchimpanzee behaviours, recorded at over 350 individual camera locations.\nUniquely, it pairs every video with a chimpanzee (referred to as a foreground\nvideo) with a corresponding background video (with no chimpanzee) from the same\ncamera location. We present two views of the dataset: one with overlapping\ncamera locations and one with disjoint locations. This setup enables, for the\nfirst time, direct evaluation of in-distribution and out-of-distribution\nconditions, and for the impact of backgrounds on behaviour recognition models\nto be quantified. All clips come with rich behavioural annotations and metadata\nincluding unique camera IDs and detailed textual scene descriptions.\nAdditionally, we establish several baselines and present a highly effective\nlatent-space normalisation technique that boosts out-of-distribution\nperformance by +5.42% mAP for convolutional and +3.75% mAP for\ntransformer-based models. Finally, we provide an in-depth analysis on the role\nof backgrounds in out-of-distribution behaviour recognition, including the so\nfar unexplored impact of background durations (i.e., the count of background\nframes within foreground videos).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition\n  (CVPR)",
    "pdf_url": "http://arxiv.org/pdf/2502.21201v3",
    "published_date": "2025-02-28 16:18:57 UTC",
    "updated_date": "2025-03-19 15:11:51 UTC"
  },
  {
    "arxiv_id": "2502.21196v1",
    "title": "AMPLE: Event-Driven Accelerator for Mixed-Precision Inference of Graph Neural Networks",
    "authors": [
      "Pedro Gimenes",
      "Yiren Zhao",
      "George Constantinides"
    ],
    "abstract": "Graph Neural Networks (GNNs) have recently gained attention due to their\nperformance on non-Euclidean data. The use of custom hardware architectures\nproves particularly beneficial for GNNs due to their irregular memory access\npatterns, resulting from the sparse structure of graphs. However, existing FPGA\naccelerators are limited by their double buffering mechanism, which doesn't\naccount for the irregular node distribution in typical graph datasets. To\naddress this, we introduce \\textbf{AMPLE} (Accelerated Message Passing Logic\nEngine), an FPGA accelerator leveraging a new event-driven programming flow. We\ndevelop a mixed-arithmetic architecture, enabling GNN inference to be quantized\nat a node-level granularity. Finally, prefetcher for data and instructions is\nimplemented to optimize off-chip memory access and maximize node parallelism.\nEvaluation on citation and social media graph datasets ranging from $2$K to\n$700$K nodes showed a mean speedup of $243\\times$ and $7.2\\times$ against CPU\nand GPU counterparts, respectively.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21196v1",
    "published_date": "2025-02-28 16:14:16 UTC",
    "updated_date": "2025-02-28 16:14:16 UTC"
  },
  {
    "arxiv_id": "2502.21186v2",
    "title": "Scalable Decision-Making in Stochastic Environments through Learned Temporal Abstraction",
    "authors": [
      "Baiting Luo",
      "Ava Pettet",
      "Aron Laszka",
      "Abhishek Dubey",
      "Ayan Mukhopadhyay"
    ],
    "abstract": "Sequential decision-making in high-dimensional continuous action spaces,\nparticularly in stochastic environments, faces significant computational\nchallenges. We explore this challenge in the traditional offline RL setting,\nwhere an agent must learn how to make decisions based on data collected through\na stochastic behavior policy. We present Latent Macro Action Planner (L-MAP),\nwhich addresses this challenge by learning a set of temporally extended\nmacro-actions through a state-conditional Vector Quantized Variational\nAutoencoder (VQ-VAE), effectively reducing action dimensionality. L-MAP employs\na (separate) learned prior model that acts as a latent transition model and\nallows efficient sampling of plausible actions. During planning, our approach\naccounts for stochasticity in both the environment and the behavior policy by\nusing Monte Carlo tree search (MCTS). In offline RL settings, including\nstochastic continuous control tasks, L-MAP efficiently searches over discrete\nlatent actions to yield high expected returns. Empirical results demonstrate\nthat L-MAP maintains low decision latency despite increased action\ndimensionality. Notably, across tasks ranging from continuous control with\ninherently stochastic dynamics to high-dimensional robotic hand manipulation,\nL-MAP significantly outperforms existing model-based methods and performs\non-par with strong model-free actor-critic baselines, highlighting the\neffectiveness of the proposed approach in planning in complex and stochastic\nenvironments with high-dimensional action spaces.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICLR2025. Code would be available at\n  https://github.com/BaitingLuo/L-MAP.git",
    "pdf_url": "http://arxiv.org/pdf/2502.21186v2",
    "published_date": "2025-02-28 16:02:23 UTC",
    "updated_date": "2025-03-03 02:33:31 UTC"
  },
  {
    "arxiv_id": "2502.21185v1",
    "title": "A Survey of Link Prediction in Temporal Networks",
    "authors": [
      "Jiafeng Xiong",
      "Ahmad Zareie",
      "Rizos Sakellariou"
    ],
    "abstract": "Temporal networks have gained significant prominence in the past decade for\nmodelling dynamic interactions within complex systems. A key challenge in this\ndomain is Temporal Link Prediction (TLP), which aims to forecast future\nconnections by analysing historical network structures across various\napplications including social network analysis. While existing surveys have\naddressed specific aspects of TLP, they typically lack a comprehensive\nframework that distinguishes between representation and inference methods. This\nsurvey bridges this gap by introducing a novel taxonomy that explicitly\nexamines representation and inference from existing methods, providing a novel\nclassification of approaches for TLP. We analyse how different representation\ntechniques capture temporal and structural dynamics, examining their\ncompatibility with various inference methods for both transductive and\ninductive prediction tasks. Our taxonomy not only clarifies the methodological\nlandscape but also reveals promising unexplored combinations of existing\ntechniques. This taxonomy provides a systematic foundation for emerging\nchallenges in TLP, including model explainability and scalable architectures\nfor complex temporal networks.",
    "categories": [
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21185v1",
    "published_date": "2025-02-28 16:00:57 UTC",
    "updated_date": "2025-02-28 16:00:57 UTC"
  },
  {
    "arxiv_id": "2503.01906v2",
    "title": "Learning to Chain Operations by Routing Information Through a Global Workspace",
    "authors": [
      "Hugo Chateau-Laurent",
      "Rufin VanRullen"
    ],
    "abstract": "We present a model inspired by the Global Workspace Theory that integrates\nspecialized modules to perform a sequential reasoning task. A controller\nselectively routes information between modules through the workspace using a\ngating mechanism. This approach allows the model to chain operations by\niteratively broadcasting information between specialized domains, mimicking\nSystem-2 reasoning. We evaluate the model's performance on a simple addition\ntask, where two addends must be summed. The task can be solved by routing\ninformation sequentially through an Input module, an Increment module (multiple\ntimes), and finally an Output module. We consider two implementations of this\nsystem with increasing complexity. First, using hand-designed modules operating\non one-hot digit representations, the controller (a LSTM recurrent network)\nlearns to select the appropriate modules (input, increment, output) in the\nappropriate sequence. Second, we replace the hand-designed modules with learned\nrepresentation modules for MNIST images and an increment module trained on the\ntask objectives; here again, the controller learns the appropriate sequential\nmodule selection to solve the task. Finally, we show that the Global Workspace\nmodel, while having fewer parameters, outperforms LSTMs and Transformers when\ntested on unseen addition operations (both interpolations and extrapolations of\naddition operations seen during training). Our results highlight the potential\nof architectures inspired by the Global Workspace Theory to enhance deep\nlearning's reasoning capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 14 figures, submitted to a conference",
    "pdf_url": "http://arxiv.org/pdf/2503.01906v2",
    "published_date": "2025-02-28 15:30:55 UTC",
    "updated_date": "2025-03-06 21:37:23 UTC"
  },
  {
    "arxiv_id": "2502.21142v1",
    "title": "Multimodal Dreaming: A Global Workspace Approach to World Model-Based Reinforcement Learning",
    "authors": [
      "Léopold Maytié",
      "Roland Bertin Johannet",
      "Rufin VanRullen"
    ],
    "abstract": "Humans leverage rich internal models of the world to reason about the future,\nimagine counterfactuals, and adapt flexibly to new situations. In Reinforcement\nLearning (RL), world models aim to capture how the environment evolves in\nresponse to the agent's actions, facilitating planning and generalization.\nHowever, typical world models directly operate on the environment variables\n(e.g. pixels, physical attributes), which can make their training slow and\ncumbersome; instead, it may be advantageous to rely on high-level latent\ndimensions that capture relevant multimodal variables. Global Workspace (GW)\nTheory offers a cognitive framework for multimodal integration and information\nbroadcasting in the brain, and recent studies have begun to introduce efficient\ndeep learning implementations of GW. Here, we evaluate the capabilities of an\nRL system combining GW with a world model. We compare our GW-Dreamer with\nvarious versions of the standard PPO and the original Dreamer algorithms. We\nshow that performing the dreaming process (i.e., mental simulation) inside the\nGW latent space allows for training with fewer environment steps. As an\nadditional emergent property, the resulting model (but not its comparison\nbaselines) displays strong robustness to the absence of one of its observation\nmodalities (images or simulation attributes). We conclude that the combination\nof GW with World Models holds great potential for improving decision-making in\nRL agents.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review in a conference",
    "pdf_url": "http://arxiv.org/pdf/2502.21142v1",
    "published_date": "2025-02-28 15:24:17 UTC",
    "updated_date": "2025-02-28 15:24:17 UTC"
  },
  {
    "arxiv_id": "2502.21138v2",
    "title": "Predicting clinical outcomes from patient care pathways represented with temporal knowledge graphs",
    "authors": [
      "Jong Ho Jhee",
      "Alberto Megina",
      "Pacôme Constant Dit Beaufils",
      "Matilde Karakachoff",
      "Richard Redon",
      "Alban Gaignard",
      "Adrien Coulet"
    ],
    "abstract": "Background: With the increasing availability of healthcare data, predictive\nmodeling finds many applications in the biomedical domain, such as the\nevaluation of the level of risk for various conditions, which in turn can guide\nclinical decision making. However, it is unclear how knowledge graph data\nrepresentations and their embedding, which are competitive in some settings,\ncould be of interest in biomedical predictive modeling. Method: We simulated\nsynthetic but realistic data of patients with intracranial aneurysm and\nexperimented on the task of predicting their clinical outcome. We compared the\nperformance of various classification approaches on tabular data versus a\ngraph-based representation of the same data. Next, we investigated how the\nadopted schema for representing first individual data and second temporal data\nimpacts predictive performances. Results: Our study illustrates that in our\ncase, a graph representation and Graph Convolutional Network (GCN) embeddings\nreach the best performance for a predictive task from observational data. We\nemphasize the importance of the adopted schema and of the consideration of\nliteral values in the representation of individual data. Our study also\nmoderates the relative impact of various time encoding on GCN performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21138v2",
    "published_date": "2025-02-28 15:20:41 UTC",
    "updated_date": "2025-04-30 15:52:56 UTC"
  },
  {
    "arxiv_id": "2502.21134v1",
    "title": "Dynamically Local-Enhancement Planner for Large-Scale Autonomous Driving",
    "authors": [
      "Nanshan Deng",
      "Weitao Zhou",
      "Bo Zhang",
      "Junze Wen",
      "Kun Jiang",
      "Zhong Cao",
      "Diange Yang"
    ],
    "abstract": "Current autonomous vehicles operate primarily within limited regions, but\nthere is increasing demand for broader applications. However, as models scale,\ntheir limited capacity becomes a significant challenge for adapting to novel\nscenarios. It is increasingly difficult to improve models for new situations\nusing a single monolithic model. To address this issue, we introduce the\nconcept of dynamically enhancing a basic driving planner with local driving\ndata, without permanently modifying the planner itself. This approach, termed\nthe Dynamically Local-Enhancement (DLE) Planner, aims to improve the\nscalability of autonomous driving systems without significantly expanding the\nplanner's size. Our approach introduces a position-varying Markov Decision\nProcess formulation coupled with a graph neural network that extracts\nregion-specific driving features from local observation data. The learned\nfeatures describe the local behavior of the surrounding objects, which is then\nleveraged to enhance a basic reinforcement learning-based policy. We evaluated\nour approach in multiple scenarios and compared it with a one-for-all driving\nmodel. The results show that our method outperforms the baseline policy in both\nsafety (collision rate) and average reward, while maintaining a lighter scale.\nThis approach has the potential to benefit large-scale autonomous vehicles\nwithout the need for largely expanding on-device driving models.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21134v1",
    "published_date": "2025-02-28 15:17:20 UTC",
    "updated_date": "2025-02-28 15:17:20 UTC"
  },
  {
    "arxiv_id": "2503.00089v1",
    "title": "Protein Structure Tokenization: Benchmarking and New Recipe",
    "authors": [
      "Xinyu Yuan",
      "Zichen Wang",
      "Marcus Collins",
      "Huzefa Rangwala"
    ],
    "abstract": "Recent years have witnessed a surge in the development of protein structural\ntokenization methods, which chunk protein 3D structures into discrete or\ncontinuous representations. Structure tokenization enables the direct\napplication of powerful techniques like language modeling for protein\nstructures, and large multimodal models to integrate structures with protein\nsequences and functional texts. Despite the progress, the capabilities and\nlimitations of these methods remain poorly understood due to the lack of a\nunified evaluation framework. We first introduce StructTokenBench, a framework\nthat comprehensively evaluates the quality and efficiency of structure\ntokenizers, focusing on fine-grained local substructures rather than global\nstructures, as typical in existing benchmarks. Our evaluations reveal that no\nsingle model dominates all benchmarking perspectives. Observations of codebook\nunder-utilization led us to develop AminoAseed, a simple yet effective strategy\nthat enhances codebook gradient updates and optimally balances codebook size\nand dimension for improved tokenizer utilization and quality. Compared to the\nleading model ESM3, our method achieves an average of 6.31% performance\nimprovement across 24 supervised tasks, with sensitivity and utilization rates\nincreased by 12.83% and 124.03%, respectively.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2503.00089v1",
    "published_date": "2025-02-28 15:14:33 UTC",
    "updated_date": "2025-02-28 15:14:33 UTC"
  },
  {
    "arxiv_id": "2502.21131v1",
    "title": "Einleitung [Introduction]",
    "authors": [
      "Vincent C. Müller"
    ],
    "abstract": "Hilary Putnam's biography and philosophical development reflect the history\nof Anglo-Saxon philosophy over the last 40 years. Putnam has influenced this\nhistory significantly for almost as long. In this introduction, the main aim is\nto present the context in which Putnam stands and from which his philosophical\ncontributions can be understood. In the context of a sketch of Putnam's\nphilosophical development, a preliminary historical classification of his work\nwill also be attempted, even if this is not the place for a comprehensive\ncritique or presentation: The introduction must remain at a fairly elementary\nlevel and of course cannot replace a reading of the texts. Since Putnam's work\nis certainly part of a rapprochement between 'analytic' and 'continental'\nphilosophy, the introduction to the texts translated here should finally make\nclear what Putnam has to offer non-analytically oriented readers.\n  Hilary Putnams Biographie und philosophische Entwicklung spiegeln die\nGeschichte der angels\\\"achsischen Philosophie in den letzten 40 Jahren. Beinahe\nebenso lange hat Putnam diese Geschichte wesentlich beeinflu{\\ss}t. In der\nvorliegenden Einleitung soll vor allem der Kontext dargestellt werden, in dem\nPutnam steht und aus dem heraus verst\\\"andlich wird, was er philosophisch zu\nsagen hat. Im Rahmen einer Skizze von Putnams philosophischer Entwicklung soll\nzudem eine vorl\\\"aufige philosophiehistorische Einordnung versucht werden, auch\nwenn hier nicht der Ort f\\\"ur eine umfassende Kritik oder Darstellung sein\nkann: Die Einleitung mu{\\ss} auf recht elementarem Niveau bleiben und kann eine\nLekt\\\"ure der Texte nat\\\"urlich nicht ersetzen. Da Putnams Werk sicherlich Teil\neiner Ann\\\"aherung von 'analytischer' und 'kontinentaler' Philosophie ist, soll\nbei der Einf\\\"uhrung in die hier \\\"ubersetzten Texte schlie{\\ss}lich deutlich\nwerden, was Putnam nicht analytisch orientierten Lesern zu bieten hat.",
    "categories": [
      "physics.hist-ph",
      "cs.AI"
    ],
    "primary_category": "physics.hist-ph",
    "comment": "in German language",
    "pdf_url": "http://arxiv.org/pdf/2502.21131v1",
    "published_date": "2025-02-28 15:10:09 UTC",
    "updated_date": "2025-02-28 15:10:09 UTC"
  },
  {
    "arxiv_id": "2502.21123v3",
    "title": "Causality Is Key to Understand and Balance Multiple Goals in Trustworthy ML and Foundation Models",
    "authors": [
      "Ruta Binkyte",
      "Ivaxi Sheth",
      "Zhijing Jin",
      "Mohammad Havaei",
      "Bernhard Schölkopf",
      "Mario Fritz"
    ],
    "abstract": "Ensuring trustworthiness in machine learning (ML) systems is crucial as they\nbecome increasingly embedded in high-stakes domains. This paper advocates for\nintegrating causal methods into machine learning to navigate the trade-offs\namong key principles of trustworthy ML, including fairness, privacy,\nrobustness, accuracy, and explainability. While these objectives should ideally\nbe satisfied simultaneously, they are often addressed in isolation, leading to\nconflicts and suboptimal solutions. Drawing on existing applications of\ncausality in ML that successfully align goals such as fairness and accuracy or\nprivacy and robustness, this paper argues that a causal approach is essential\nfor balancing multiple competing objectives in both trustworthy ML and\nfoundation models. Beyond highlighting these trade-offs, we examine how\ncausality can be practically integrated into ML and foundation models, offering\nsolutions to enhance their reliability and interpretability. Finally, we\ndiscuss the challenges, limitations, and opportunities in adopting causal\nframeworks, paving the way for more accountable and ethically sound AI systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21123v3",
    "published_date": "2025-02-28 14:57:33 UTC",
    "updated_date": "2025-03-21 14:02:38 UTC"
  },
  {
    "arxiv_id": "2502.21112v1",
    "title": "Optimizing Large Language Models for ESG Activity Detection in Financial Texts",
    "authors": [
      "Mattia Birti",
      "Francesco Osborne",
      "Andrea Maurino"
    ],
    "abstract": "The integration of Environmental, Social, and Governance (ESG) factors into\ncorporate decision-making is a fundamental aspect of sustainable finance.\nHowever, ensuring that business practices align with evolving regulatory\nframeworks remains a persistent challenge. AI-driven solutions for\nautomatically assessing the alignment of sustainability reports and\nnon-financial disclosures with specific ESG activities could greatly support\nthis process. Yet, this task remains complex due to the limitations of\ngeneral-purpose Large Language Models (LLMs) in domain-specific contexts and\nthe scarcity of structured, high-quality datasets. In this paper, we\ninvestigate the ability of current-generation LLMs to identify text related to\nenvironmental activities. Furthermore, we demonstrate that their performance\ncan be significantly enhanced through fine-tuning on a combination of original\nand synthetically generated data. To this end, we introduce ESG-Activities, a\nbenchmark dataset containing 1,325 labelled text segments classified according\nto the EU ESG taxonomy. Our experimental results show that fine-tuning on\nESG-Activities significantly enhances classification accuracy, with open models\nsuch as Llama 7B and Gemma 7B outperforming large proprietary solutions in\nspecific configurations. These findings have important implications for\nfinancial analysts, policymakers, and AI researchers seeking to enhance ESG\ntransparency and compliance through advanced natural language processing\ntechniques.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.CL",
      "cs.CY",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21112v1",
    "published_date": "2025-02-28 14:52:25 UTC",
    "updated_date": "2025-02-28 14:52:25 UTC"
  },
  {
    "arxiv_id": "2502.21100v1",
    "title": "AuthSim: Towards Authentic and Effective Safety-critical Scenario Generation for Autonomous Driving Tests",
    "authors": [
      "Yukuan Yang",
      "Xucheng Lu",
      "Zhili Zhang",
      "Zepeng Wu",
      "Guoqi Li",
      "Lingzhong Meng",
      "Yunzhi Xue"
    ],
    "abstract": "Generating adversarial safety-critical scenarios is a pivotal method for\ntesting autonomous driving systems, as it identifies potential weaknesses and\nenhances system robustness and reliability. However, existing approaches\npredominantly emphasize unrestricted collision scenarios, prompting non-player\ncharacter (NPC) vehicles to attack the ego vehicle indiscriminately. These\nworks overlook these scenarios' authenticity, rationality, and relevance,\nresulting in numerous extreme, contrived, and largely unrealistic collision\nevents involving aggressive NPC vehicles. To rectify this issue, we propose a\nthree-layer relative safety region model, which partitions the area based on\ndanger levels and increases the likelihood of NPC vehicles entering relative\nboundary regions. This model directs NPC vehicles to engage in adversarial\nactions within relatively safe boundary regions, thereby augmenting the\nscenarios' authenticity. We introduce AuthSim, a comprehensive platform for\ngenerating authentic and effective safety-critical scenarios by integrating the\nthree-layer relative safety region model with reinforcement learning. To our\nknowledge, this is the first attempt to address the authenticity and\neffectiveness of autonomous driving system test scenarios comprehensively.\nExtensive experiments demonstrate that AuthSim outperforms existing methods in\ngenerating effective safety-critical scenarios. Notably, AuthSim achieves a\n5.25% improvement in average cut-in distance and a 27.12% enhancement in\naverage collision interval time, while maintaining higher efficiency in\ngenerating effective safety-critical scenarios compared to existing methods.\nThis underscores its significant advantage in producing authentic scenarios\nover current methodologies.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21100v1",
    "published_date": "2025-02-28 14:38:35 UTC",
    "updated_date": "2025-02-28 14:38:35 UTC"
  },
  {
    "arxiv_id": "2502.21098v1",
    "title": "Re-evaluating Theory of Mind evaluation in large language models",
    "authors": [
      "Jennifer Hu",
      "Felix Sosa",
      "Tomer Ullman"
    ],
    "abstract": "The question of whether large language models (LLMs) possess Theory of Mind\n(ToM) -- often defined as the ability to reason about others' mental states --\nhas sparked significant scientific and public interest. However, the evidence\nas to whether LLMs possess ToM is mixed, and the recent growth in evaluations\nhas not resulted in a convergence. Here, we take inspiration from cognitive\nscience to re-evaluate the state of ToM evaluation in LLMs. We argue that a\nmajor reason for the disagreement on whether LLMs have ToM is a lack of clarity\non whether models should be expected to match human behaviors, or the\ncomputations underlying those behaviors. We also highlight ways in which\ncurrent evaluations may be deviating from \"pure\" measurements of ToM abilities,\nwhich also contributes to the confusion. We conclude by discussing several\ndirections for future research, including the relationship between ToM and\npragmatic communication, which could advance our understanding of artificial\nsystems as well as human cognition.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2502.21098v1",
    "published_date": "2025-02-28 14:36:57 UTC",
    "updated_date": "2025-02-28 14:36:57 UTC"
  },
  {
    "arxiv_id": "2502.21092v1",
    "title": "An LLM-based Delphi Study to Predict GenAI Evolution",
    "authors": [
      "Francesco Bertolotti",
      "Luca Mari"
    ],
    "abstract": "Predicting the future trajectory of complex and rapidly evolving systems\nremains a significant challenge, particularly in domains where data is scarce\nor unreliable. This study introduces a novel approach to qualitative\nforecasting by leveraging Large Language Models to conduct Delphi studies. The\nmethodology was applied to explore the future evolution of Generative\nArtificial Intelligence, revealing insights into key factors such as\ngeopolitical tensions, economic disparities, regulatory frameworks, and ethical\nconsiderations. The results highlight how LLM-based Delphi studies can\nfacilitate structured scenario analysis, capturing diverse perspectives while\nmitigating issues such as respondent fatigue. However, limitations emerge in\nterms of knowledge cutoffs, inherent biases, and sensitivity to initial\nconditions. While the approach provides an innovative means for structured\nforesight, this method could be also considered as a novel form of reasoning.\nfurther research is needed to refine its ability to manage heterogeneity,\nimprove reliability, and integrate external data sources.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21092v1",
    "published_date": "2025-02-28 14:31:25 UTC",
    "updated_date": "2025-02-28 14:31:25 UTC"
  },
  {
    "arxiv_id": "2502.21087v1",
    "title": "PASemiQA: Plan-Assisted Agent for Question Answering on Semi-Structured Data with Text and Relational Information",
    "authors": [
      "Hansi Yang",
      "Qi Zhang",
      "Wei Jiang",
      "Jianguo Li"
    ],
    "abstract": "Large language models (LLMs) have shown impressive abilities in answering\nquestions across various domains, but they often encounter hallucination issues\non questions that require professional and up-to-date knowledge. To address\nthis limitation, retrieval-augmented generation (RAG) techniques have been\nproposed, which retrieve relevant information from external sources to inform\ntheir responses. However, existing RAG methods typically focus on a single type\nof external data, such as vectorized text database or knowledge graphs, and\ncannot well handle real-world questions on semi-structured data containing both\ntext and relational information. To bridge this gap, we introduce PASemiQA, a\nnovel approach that jointly leverages text and relational information in\nsemi-structured data to answer questions. PASemiQA first generates a plan to\nidentify relevant text and relational information to answer the question in\nsemi-structured data, and then uses an LLM agent to traverse the\nsemi-structured data and extract necessary information. Our empirical results\ndemonstrate the effectiveness of PASemiQA across different semi-structured\ndatasets from various domains, showcasing its potential to improve the accuracy\nand reliability of question answering systems on semi-structured data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21087v1",
    "published_date": "2025-02-28 14:26:47 UTC",
    "updated_date": "2025-02-28 14:26:47 UTC"
  },
  {
    "arxiv_id": "2502.21086v1",
    "title": "Are foundation models useful feature extractors for electroencephalography analysis?",
    "authors": [
      "Özgün Turgut",
      "Felix S. Bott",
      "Markus Ploner",
      "Daniel Rueckert"
    ],
    "abstract": "The success of foundation models in natural language processing and computer\nvision has motivated similar approaches for general time series analysis. While\nthese models are effective for a variety of tasks, their applicability in\nmedical domains with limited data remains largely unexplored. To address this,\nwe investigate the effectiveness of foundation models in medical time series\nanalysis involving electroencephalography (EEG). Through extensive experiments\non tasks such as age prediction, seizure detection, and the classification of\nclinically relevant EEG events, we compare their diagnostic accuracy with that\nof specialised EEG models. Our analysis shows that foundation models extract\nmeaningful EEG features, outperform specialised models even without domain\nadaptation, and localise task-specific biomarkers. Moreover, we demonstrate\nthat diagnostic accuracy is substantially influenced by architectural choices\nsuch as context length. Overall, our study reveals that foundation models with\ngeneral time series understanding eliminate the dependency on large\ndomain-specific datasets, making them valuable tools for clinical practice.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21086v1",
    "published_date": "2025-02-28 14:21:34 UTC",
    "updated_date": "2025-02-28 14:21:34 UTC"
  },
  {
    "arxiv_id": "2502.21077v1",
    "title": "Enhancing deep neural networks through complex-valued representations and Kuramoto synchronization dynamics",
    "authors": [
      "Sabine Muzellec",
      "Andrea Alamia",
      "Thomas Serre",
      "Rufin VanRullen"
    ],
    "abstract": "Neural synchrony is hypothesized to play a crucial role in how the brain\norganizes visual scenes into structured representations, enabling the robust\nencoding of multiple objects within a scene. However, current deep learning\nmodels often struggle with object binding, limiting their ability to represent\nmultiple objects effectively. Inspired by neuroscience, we investigate whether\nsynchrony-based mechanisms can enhance object encoding in artificial models\ntrained for visual categorization. Specifically, we combine complex-valued\nrepresentations with Kuramoto dynamics to promote phase alignment, facilitating\nthe grouping of features belonging to the same object. We evaluate two\narchitectures employing synchrony: a feedforward model and a recurrent model\nwith feedback connections to refine phase synchronization using top-down\ninformation. Both models outperform their real-valued counterparts and\ncomplex-valued models without Kuramoto synchronization on tasks involving\nmulti-object images, such as overlapping handwritten digits, noisy inputs, and\nout-of-distribution transformations. Our findings highlight the potential of\nsynchrony-driven mechanisms to enhance deep learning models, improving their\nperformance, robustness, and generalization in complex visual categorization\ntasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "nlin.AO",
      "q-bio.NC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21077v1",
    "published_date": "2025-02-28 14:10:42 UTC",
    "updated_date": "2025-02-28 14:10:42 UTC"
  },
  {
    "arxiv_id": "2502.21059v1",
    "title": "FC-Attack: Jailbreaking Large Vision-Language Models via Auto-Generated Flowcharts",
    "authors": [
      "Ziyi Zhang",
      "Zhen Sun",
      "Zongmin Zhang",
      "Jihui Guo",
      "Xinlei He"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have become powerful and widely adopted\nin some practical applications. However, recent research has revealed their\nvulnerability to multimodal jailbreak attacks, whereby the model can be induced\nto generate harmful content, leading to safety risks. Although most LVLMs have\nundergone safety alignment, recent research shows that the visual modality is\nstill vulnerable to jailbreak attacks. In our work, we discover that by using\nflowcharts with partially harmful information, LVLMs can be induced to provide\nadditional harmful details. Based on this, we propose a jailbreak attack method\nbased on auto-generated flowcharts, FC-Attack. Specifically, FC-Attack first\nfine-tunes a pre-trained LLM to create a step-description generator based on\nbenign datasets. The generator is then used to produce step descriptions\ncorresponding to a harmful query, which are transformed into flowcharts in 3\ndifferent shapes (vertical, horizontal, and S-shaped) as visual prompts. These\nflowcharts are then combined with a benign textual prompt to execute a\njailbreak attack on LVLMs. Our evaluations using the Advbench dataset show that\nFC-Attack achieves over 90% attack success rates on Gemini-1.5, Llaval-Next,\nQwen2-VL, and InternVL-2.5 models, outperforming existing LVLM jailbreak\nmethods. Additionally, we investigate factors affecting the attack performance,\nincluding the number of steps and the font styles in the flowcharts. Our\nevaluation shows that FC-Attack can improve the jailbreak performance from 4%\nto 28% in Claude-3.5 by changing the font style. To mitigate the attack, we\nexplore several defenses and find that AdaShield can largely reduce the\njailbreak performance but with the cost of utility drop.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.21059v1",
    "published_date": "2025-02-28 13:59:11 UTC",
    "updated_date": "2025-02-28 13:59:11 UTC"
  },
  {
    "arxiv_id": "2502.21057v3",
    "title": "Robust Deterministic Policy Gradient for Disturbance Attenuation and Its Application to Quadrotor Control",
    "authors": [
      "Taeho Lee",
      "Donghwan Lee"
    ],
    "abstract": "Practical control systems pose significant challenges in identifying optimal\ncontrol policies due to uncertainties in the system model and external\ndisturbances. While $H_\\infty$ control techniques are commonly used to design\nrobust controllers that mitigate the effects of disturbances, these methods\noften require complex and computationally intensive calculations. To address\nthis issue, this paper proposes a reinforcement learning algorithm called\nRobust Deterministic Policy Gradient (RDPG), which formulates the $H_\\infty$\ncontrol problem as a two-player zero-sum dynamic game. In this formulation, one\nplayer (the user) aims to minimize the cost, while the other player (the\nadversary) seeks to maximize it. We then employ deterministic policy gradient\n(DPG) and its deep reinforcement learning counterpart to train a robust control\npolicy with effective disturbance attenuation. In particular, for practical\nimplementation, we introduce an algorithm called robust deep deterministic\npolicy gradient (RDDPG), which employs a deep neural network architecture and\nintegrates techniques from the twin-delayed deep deterministic policy gradient\n(TD3) to enhance stability and learning efficiency. To evaluate the proposed\nalgorithm, we implement it on an unmanned aerial vehicle (UAV) tasked with\nfollowing a predefined path in a disturbance-prone environment. The\nexperimental results demonstrate that the proposed method outperforms other\ncontrol approaches in terms of robustness against disturbances, enabling\nprecise real-time tracking of moving targets even under severe disturbance\nconditions.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.21057v3",
    "published_date": "2025-02-28 13:58:22 UTC",
    "updated_date": "2025-03-12 23:39:47 UTC"
  },
  {
    "arxiv_id": "2502.21049v1",
    "title": "Synthesizing Individualized Aging Brains in Health and Disease with Generative Models and Parallel Transport",
    "authors": [
      "Jingru Fu",
      "Yuqi Zheng",
      "Neel Dey",
      "Daniel Ferreira",
      "Rodrigo Moreno"
    ],
    "abstract": "Simulating prospective magnetic resonance imaging (MRI) scans from a given\nindividual brain image is challenging, as it requires accounting for canonical\nchanges in aging and/or disease progression while also considering the\nindividual brain's current status and unique characteristics. While current\ndeep generative models can produce high-resolution anatomically accurate\ntemplates for population-wide studies, their ability to predict future aging\ntrajectories for individuals remains limited, particularly in capturing\nsubject-specific neuroanatomical variations over time. In this study, we\nintroduce Individualized Brain Synthesis (InBrainSyn), a framework for\nsynthesizing high-resolution subject-specific longitudinal MRI scans that\nsimulate neurodegeneration in both Alzheimer's disease (AD) and normal aging.\nInBrainSyn uses a parallel transport algorithm to adapt the population-level\naging trajectories learned by a generative deep template network, enabling\nindividualized aging synthesis. As InBrainSyn uses diffeomorphic\ntransformations to simulate aging, the synthesized images are topologically\nconsistent with the original anatomy by design. We evaluated InBrainSyn both\nquantitatively and qualitatively on AD and healthy control cohorts from the\nOpen Access Series of Imaging Studies - version 3 dataset. Experimentally,\nInBrainSyn can also model neuroanatomical transitions between normal aging and\nAD. An evaluation of an external set supports its generalizability. Overall,\nwith only a single baseline scan, InBrainSyn synthesizes realistic 3D\nspatiotemporal T1w MRI scans, producing personalized longitudinal aging\ntrajectories. The code for InBrainSyn is available at:\nhttps://github.com/Fjr9516/InBrainSyn.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "20 pages, 9 figures, 6 tables, diffeomorphic registration, parallel\n  transport, brain aging, medical image generation, Alzheimer's disease",
    "pdf_url": "http://arxiv.org/pdf/2502.21049v1",
    "published_date": "2025-02-28 13:45:09 UTC",
    "updated_date": "2025-02-28 13:45:09 UTC"
  },
  {
    "arxiv_id": "2503.16467v1",
    "title": "Enhancing Explainability with Multimodal Context Representations for Smarter Robots",
    "authors": [
      "Anargh Viswanath",
      "Lokesh Veeramacheneni",
      "Hendrik Buschmeier"
    ],
    "abstract": "Artificial Intelligence (AI) has significantly advanced in recent years,\ndriving innovation across various fields, especially in robotics. Even though\nrobots can perform complex tasks with increasing autonomy, challenges remain in\nensuring explainability and user-centered design for effective interaction. A\nkey issue in Human-Robot Interaction (HRI) is enabling robots to effectively\nperceive and reason over multimodal inputs, such as audio and vision, to foster\ntrust and seamless collaboration. In this paper, we propose a generalized and\nexplainable multimodal framework for context representation, designed to\nimprove the fusion of speech and vision modalities. We introduce a use case on\nassessing 'Relevance' between verbal utterances from the user and visual scene\nperception of the robot. We present our methodology with a Multimodal Joint\nRepresentation module and a Temporal Alignment module, which can allow robots\nto evaluate relevance by temporally aligning multimodal inputs. Finally, we\ndiscuss how the proposed framework for context representation can help with\nvarious aspects of explainability in HRI.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.HC",
    "comment": "Presented at 3rd Workshop on Explainability in Human-Robot\n  Collaboration at HRI 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.16467v1",
    "published_date": "2025-02-28 13:36:47 UTC",
    "updated_date": "2025-02-28 13:36:47 UTC"
  },
  {
    "arxiv_id": "2502.21041v1",
    "title": "Fast Adversarial Training against Sparse Attacks Requires Loss Smoothing",
    "authors": [
      "Xuyang Zhong",
      "Yixiao Huang",
      "Chen Liu"
    ],
    "abstract": "This paper studies fast adversarial training against sparse adversarial\nperturbations bounded by $l_0$ norm. We demonstrate the challenges of employing\n$1$-step attacks on $l_0$ bounded perturbations for fast adversarial training,\nincluding degraded performance and the occurrence of catastrophic overfitting\n(CO). We highlight that CO in $l_0$ adversarial training is caused by\nsub-optimal perturbation locations of $1$-step attack. Theoretical and\nempirical analyses reveal that the loss landscape of $l_0$ adversarial training\nis more craggy compared to its $l_\\infty$, $l_2$ and $l_1$ counterparts.\nMoreover, we corroborate that the craggy loss landscape can aggravate CO. To\naddress these issues, we propose Fast-LS-$l_0$ that incorporates soft labels\nand the trade-off loss function to smooth the adversarial loss landscape.\nExtensive experiments demonstrate our method can overcome the challenge of\ncatastrophic overfitting, achieve state-of-the-art performance, and narrow down\nthe performance gap between $1$-step and multi-step adversarial training\nagainst sparse attacks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.21041v1",
    "published_date": "2025-02-28 13:32:47 UTC",
    "updated_date": "2025-02-28 13:32:47 UTC"
  },
  {
    "arxiv_id": "2503.00086v1",
    "title": "Generalization of CNNs on Relational Reasoning with Bar Charts",
    "authors": [
      "Zhenxing Cui",
      "Lu Chen",
      "Yunhai Wang",
      "Daniel Haehn",
      "Yong Wang",
      "Hanspeter Pfister"
    ],
    "abstract": "This paper presents a systematic study of the generalization of convolutional\nneural networks (CNNs) and humans on relational reasoning tasks with bar\ncharts. We first revisit previous experiments on graphical perception and\nupdate the benchmark performance of CNNs. We then test the generalization\nperformance of CNNs on a classic relational reasoning task: estimating bar\nlength ratios in a bar chart, by progressively perturbing the standard\nvisualizations. We further conduct a user study to compare the performance of\nCNNs and humans. Our results show that CNNs outperform humans only when the\ntraining and test data have the same visual encodings. Otherwise, they may\nperform worse. We also find that CNNs are sensitive to perturbations in various\nvisual encodings, regardless of their relevance to the target bars. Yet, humans\nare mainly influenced by bar lengths. Our study suggests that robust relational\nreasoning with visualizations is challenging for CNNs. Improving CNNs'\ngeneralization performance may require training them to better recognize\ntask-related visual properties.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by TVCG. GitHub repository:\n  https://github.com/Ideas-Laboratory/Graphical-Perception",
    "pdf_url": "http://arxiv.org/pdf/2503.00086v1",
    "published_date": "2025-02-28 13:32:06 UTC",
    "updated_date": "2025-02-28 13:32:06 UTC"
  },
  {
    "arxiv_id": "2503.01905v2",
    "title": "PaCA: Partial Connection Adaptation for Efficient Fine-Tuning",
    "authors": [
      "Sunghyeon Woo",
      "Sol Namkung",
      "Sunwoo Lee",
      "Inho Jeong",
      "Beomseok Kim",
      "Dongsuk Jeon"
    ],
    "abstract": "Prior parameter-efficient fine-tuning (PEFT) algorithms reduce memory usage\nand computational costs of fine-tuning large neural network models by training\nonly a few additional adapter parameters, rather than the entire model.\nHowever, the reduction in computational costs due to PEFT does not necessarily\ntranslate to a reduction in training time; although the computational costs of\nthe adapter layers are much smaller than the pretrained layers, it is well\nknown that those two types of layers are processed sequentially on GPUs,\nresulting in significant latency overhead. LoRA and its variants merge low-rank\nadapter matrices with pretrained weights during inference to avoid latency\noverhead, but during training, the pretrained weights remain frozen while the\nadapter matrices are continuously updated, preventing such merging. To mitigate\nthis issue, we propose Partial Connection Adaptation (PaCA), which fine-tunes\nrandomly selected partial connections within the pretrained weights instead of\nintroducing adapter layers in the model. PaCA not only enhances training speed\nby eliminating the time overhead due to the sequential processing of the\nadapter and pretrained layers but also reduces activation memory since only\npartial activations, rather than full activations, need to be stored for\ngradient computation. Compared to LoRA, PaCA reduces training time by 22% and\ntotal memory usage by 16%, while maintaining comparable accuracy across various\nfine-tuning scenarios, such as fine-tuning on the MMLU dataset and instruction\ntuning on the Oasst1 dataset. PaCA can also be combined with quantization,\nenabling the fine-tuning of large models such as LLaMA3.1-70B. In addition,\nPaCA enables training with 23% longer sequence and improves throughput by 16%\non both NVIDIA A100 GPU and INTEL Gaudi2 HPU compared to LoRA. The code is\navailable at https://github.com/WooSunghyeon/paca.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01905v2",
    "published_date": "2025-02-28 13:30:10 UTC",
    "updated_date": "2025-03-11 15:24:13 UTC"
  },
  {
    "arxiv_id": "2502.21038v1",
    "title": "Reward Learning from Multiple Feedback Types",
    "authors": [
      "Yannick Metz",
      "András Geiszl",
      "Raphaël Baur",
      "Mennatallah El-Assady"
    ],
    "abstract": "Learning rewards from preference feedback has become an important tool in the\nalignment of agentic models. Preference-based feedback, often implemented as a\nbinary comparison between multiple completions, is an established method to\nacquire large-scale human feedback. However, human feedback in other contexts\nis often much more diverse. Such diverse feedback can better support the goals\nof a human annotator, and the simultaneous use of multiple sources might be\nmutually informative for the learning process or carry type-dependent biases\nfor the reward learning process. Despite these potential benefits, learning\nfrom different feedback types has yet to be explored extensively. In this\npaper, we bridge this gap by enabling experimentation and evaluating multi-type\nfeedback in a broad set of environments. We present a process to generate\nhigh-quality simulated feedback of six different types. Then, we implement\nreward models and downstream RL training for all six feedback types. Based on\nthe simulated feedback, we investigate the use of types of feedback across ten\nRL environments and compare them to pure preference-based baselines. We show\nempirically that diverse types of feedback can be utilized and lead to strong\nreward modeling performance. This work is the first strong indicator of the\npotential of multi-type feedback for RLHF.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.21038v1",
    "published_date": "2025-02-28 13:29:54 UTC",
    "updated_date": "2025-02-28 13:29:54 UTC"
  },
  {
    "arxiv_id": "2502.21034v1",
    "title": "Synthesizing Tabular Data Using Selectivity Enhanced Generative Adversarial Networks",
    "authors": [
      "Youran Zhou",
      "Jianzhong Qi"
    ],
    "abstract": "As E-commerce platforms face surging transactions during major shopping\nevents like Black Friday, stress testing with synthesized data is crucial for\nresource planning. Most recent studies use Generative Adversarial Networks\n(GANs) to generate tabular data while ensuring privacy and machine learning\nutility. However, these methods overlook the computational demands of\nprocessing GAN-generated data, making them unsuitable for E-commerce stress\ntesting.\n  This thesis introduces a novel GAN-based approach incorporating query\nselectivity constraints, a key factor in database transaction processing. We\nintegrate a pre-trained deep neural network to maintain selectivity consistency\nbetween real and synthetic data. Our method, tested on five real-world\ndatasets, outperforms three state-of-the-art GANs and a VAE model, improving\nselectivity estimation accuracy by up to 20pct and machine learning utility by\nup to 6 pct.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This thesis submitted to the University of Melbourne for partial\n  fulfillment of the degree of Master of Data Science",
    "pdf_url": "http://arxiv.org/pdf/2502.21034v1",
    "published_date": "2025-02-28 13:26:41 UTC",
    "updated_date": "2025-02-28 13:26:41 UTC"
  },
  {
    "arxiv_id": "2502.21030v1",
    "title": "Beyond Words: A Latent Memory Approach to Internal Reasoning in LLMs",
    "authors": [
      "José I. Orlicki"
    ],
    "abstract": "Recent advances in large language models (LLMs) have popularized the\nchain-of-thought (CoT) paradigm, in which models produce explicit reasoning\nsteps in natural language. Although this approach improves interpretability and\nfacilitates external auditing, it may not represent the most computationally\nefficient method for internal reasoning. In contrast, human cognition relies on\nimplicit mental representations that recall past sensory and episodic\ninformation without requiring complete verbalization. In this paper, we propose\na framework that integrates implicit mental representations into the internal\nreasoning processes of LLMs. Preliminary experiments indicate that\nincorporating an Implicit Memory Module (IMM) into a simple GPT model yields a\nreduction of between 35% and 57% in final training loss compared to a regular\nGPT baseline. The addition of an explicit interpretability channel (e.g., a\nchain-of-thought decoder) is straightforward to implement within this approach.\nWe outline theoretical foundations, propose technical mechanisms to scale the\nmemory module, and discuss how these ideas may lead to more efficient and\nrobust reasoning, with optional future extensions for explicit auditability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.21030v1",
    "published_date": "2025-02-28 13:22:29 UTC",
    "updated_date": "2025-02-28 13:22:29 UTC"
  },
  {
    "arxiv_id": "2502.21028v2",
    "title": "Measuring and identifying factors of individuals' trust in Large Language Models",
    "authors": [
      "Edoardo Sebastiano De Duro",
      "Giuseppe Alessandro Veltri",
      "Hudson Golino",
      "Massimo Stella"
    ],
    "abstract": "Large Language Models (LLMs) can engage in human-looking conversational\nexchanges. Although conversations can elicit trust between users and LLMs,\nscarce empirical research has examined trust formation in human-LLM contexts,\nbeyond LLMs' trustworthiness or human trust in AI in general. Here, we\nintroduce the Trust-In-LLMs Index (TILLMI) as a new framework to measure\nindividuals' trust in LLMs, extending McAllister's cognitive and affective\ntrust dimensions to LLM-human interactions. We developed TILLMI as a\npsychometric scale, prototyped with a novel protocol we called LLM-simulated\nvalidity. The LLM-based scale was then validated in a sample of 1,000 US\nrespondents. Exploratory Factor Analysis identified a two-factor structure. Two\nitems were then removed due to redundancy, yielding a final 6-item scale with a\n2-factor structure. Confirmatory Factor Analysis on a separate subsample showed\nstrong model fit ($CFI = .995$, $TLI = .991$, $RMSEA = .046$, $p_{X^2} > .05$).\nConvergent validity analysis revealed that trust in LLMs correlated positively\nwith openness to experience, extraversion, and cognitive flexibility, but\nnegatively with neuroticism. Based on these findings, we interpreted TILLMI's\nfactors as \"closeness with LLMs\" (affective dimension) and \"reliance on LLMs\"\n(cognitive dimension). Younger males exhibited higher closeness with- and\nreliance on LLMs compared to older women. Individuals with no direct experience\nwith LLMs exhibited lower levels of trust compared to LLMs' users. These\nfindings offer a novel empirical foundation for measuring trust in AI-driven\nverbal communication, informing responsible design, and fostering balanced\nhuman-AI collaboration.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "23 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.21028v2",
    "published_date": "2025-02-28 13:16:34 UTC",
    "updated_date": "2025-03-05 15:52:43 UTC"
  },
  {
    "arxiv_id": "2503.01904v1",
    "title": "What are You Looking at? Modality Contribution in Multimodal Medical Deep Learning Methods",
    "authors": [
      "Christian Gapp",
      "Elias Tappeiner",
      "Martin Welk",
      "Karl Fritscher",
      "Elke Ruth Gizewski",
      "Rainer Schubert"
    ],
    "abstract": "Purpose High dimensional, multimodal data can nowadays be analyzed by huge\ndeep neural networks with little effort. Several fusion methods for bringing\ntogether different modalities have been developed. Particularly, in the field\nof medicine with its presence of high dimensional multimodal patient data,\nmultimodal models characterize the next step. However, what is yet very\nunderexplored is how these models process the source information in detail.\nMethods To this end, we implemented an occlusion-based both model and\nperformance agnostic modality contribution method that quantitatively measures\nthe importance of each modality in the dataset for the model to fulfill its\ntask. We applied our method to three different multimodal medical problems for\nexperimental purposes. Results Herein we found that some networks have modality\npreferences that tend to unimodal collapses, while some datasets are imbalanced\nfrom the ground up. Moreover, we could determine a link between our metric and\nthe performance of single modality trained nets. Conclusion The information\ngain through our metric holds remarkable potential to improve the development\nof multimodal models and the creation of datasets in the future. With our\nmethod we make a crucial contribution to the field of interpretability in deep\nlearning based multimodal research and thereby notably push the integrability\nof multimodal AI into clinical practice. Our code is publicly available at\nhttps://github.com/ChristianGappGit/MC_MMD.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.1"
    ],
    "primary_category": "cs.CV",
    "comment": "Contribution to Conference for Computer Assisted Radiology and\n  Surgery (CARS 2025)",
    "pdf_url": "http://arxiv.org/pdf/2503.01904v1",
    "published_date": "2025-02-28 12:39:39 UTC",
    "updated_date": "2025-02-28 12:39:39 UTC"
  },
  {
    "arxiv_id": "2503.01903v1",
    "title": "PsychBench: A comprehensive and professional benchmark for evaluating the performance of LLM-assisted psychiatric clinical practice",
    "authors": [
      "Ruoxi Wang",
      "Shuyu Liu",
      "Ling Zhang",
      "Xuequan Zhu",
      "Rui Yang",
      "Xinzhu Zhou",
      "Fei Wu",
      "Zhi Yang",
      "Cheng Jin",
      "Gang Wang"
    ],
    "abstract": "The advent of Large Language Models (LLMs) offers potential solutions to\naddress problems such as shortage of medical resources and low diagnostic\nconsistency in psychiatric clinical practice. Despite this potential, a robust\nand comprehensive benchmarking framework to assess the efficacy of LLMs in\nauthentic psychiatric clinical environments is absent. This has impeded the\nadvancement of specialized LLMs tailored to psychiatric applications. In\nresponse to this gap, by incorporating clinical demands in psychiatry and\nclinical data, we proposed a benchmarking system, PsychBench, to evaluate the\npractical performance of LLMs in psychiatric clinical settings. We conducted a\ncomprehensive quantitative evaluation of 16 LLMs using PsychBench, and\ninvestigated the impact of prompt design, chain-of-thought reasoning, input\ntext length, and domain-specific knowledge fine-tuning on model performance.\nThrough detailed error analysis, we identified strengths and potential\nlimitations of the existing models and suggested directions for improvement.\nSubsequently, a clinical reader study involving 60 psychiatrists of varying\nseniority was conducted to further explore the practical benefits of existing\nLLMs as supportive tools for psychiatrists of varying seniority. Through the\nquantitative and reader evaluation, we show that while existing models\ndemonstrate significant potential, they are not yet adequate as decision-making\ntools in psychiatric clinical practice. The reader study further indicates\nthat, as an auxiliary tool, LLM could provide particularly notable support for\njunior psychiatrists, effectively enhancing their work efficiency and overall\nclinical quality. To promote research in this area, we will make the dataset\nand evaluation framework publicly available, with the hope of advancing the\napplication of LLMs in psychiatric clinical settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01903v1",
    "published_date": "2025-02-28 12:17:41 UTC",
    "updated_date": "2025-02-28 12:17:41 UTC"
  },
  {
    "arxiv_id": "2502.20988v1",
    "title": "Merging Clinical Knowledge into Large Language Models for Medical Research and Applications: A Survey",
    "authors": [
      "Qiyuan Li",
      "Haijiang Liu",
      "Caicai Guo",
      "Deyu Chen",
      "Meng Wang",
      "Feng Gao",
      "Jinguang Gu"
    ],
    "abstract": "Clinical knowledge is the collection of information learned from studies on\nthe causes, prognosis, diagnosis, and treatment of diseases. This type of\nknowledge can improve curing performances, and promote physical health. With\nthe emergence of large language models (LLMs), medical artificial intelligence\n(medical AI), which aims to apply academic medical AI systems to real-world\nmedical scenarios, has entered a new age of development, resulting in excellent\nworks such as DoctorGPT and Pangu-Drug from academic and industrial researches.\nHowever, the field lacks a comprehensive compendium and comparison of building\nmedical AI systems from academia and industry. Therefore, this survey focuses\non the building paradigms of medical AI systems including the use of clinical\ndatabases, datasets, training pipelines, integrating medical knowledge graphs,\nsystem applications, and evaluation systems. We hope that this survey can help\nrelevant practical researchers understand the current performance of academic\nmodels in various fields of healthcare, as well as the potential problems and\nfuture directions for implementing these scientific achievements.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20988v1",
    "published_date": "2025-02-28 12:00:51 UTC",
    "updated_date": "2025-02-28 12:00:51 UTC"
  },
  {
    "arxiv_id": "2502.20985v1",
    "title": "LesionLocator: Zero-Shot Universal Tumor Segmentation and Tracking in 3D Whole-Body Imaging",
    "authors": [
      "Maximilian Rokuss",
      "Yannick Kirchhoff",
      "Seval Akbal",
      "Balint Kovacs",
      "Saikat Roy",
      "Constantin Ulrich",
      "Tassilo Wald",
      "Lukas T. Rotkopf",
      "Heinz-Peter Schlemmer",
      "Klaus Maier-Hein"
    ],
    "abstract": "In this work, we present LesionLocator, a framework for zero-shot\nlongitudinal lesion tracking and segmentation in 3D medical imaging,\nestablishing the first end-to-end model capable of 4D tracking with dense\nspatial prompts. Our model leverages an extensive dataset of 23,262 annotated\nmedical scans, as well as synthesized longitudinal data across diverse lesion\ntypes. The diversity and scale of our dataset significantly enhances model\ngeneralizability to real-world medical imaging challenges and addresses key\nlimitations in longitudinal data availability. LesionLocator outperforms all\nexisting promptable models in lesion segmentation by nearly 10 dice points,\nreaching human-level performance, and achieves state-of-the-art results in\nlesion tracking, with superior lesion retrieval and segmentation accuracy.\nLesionLocator not only sets a new benchmark in universal promptable lesion\nsegmentation and automated longitudinal lesion tracking but also provides the\nfirst open-access solution of its kind, releasing our synthetic 4D dataset and\nmodel to the community, empowering future advancements in medical imaging. Code\nis available at: www.github.com/MIC-DKFZ/LesionLocator",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.20985v1",
    "published_date": "2025-02-28 11:58:33 UTC",
    "updated_date": "2025-02-28 11:58:33 UTC"
  },
  {
    "arxiv_id": "2502.20984v3",
    "title": "UoR-NCL at SemEval-2025 Task 1: Using Generative LLMs and CLIP Models for Multilingual Multimodal Idiomaticity Representation",
    "authors": [
      "Thanet Markchom",
      "Tong Wu",
      "Liting Huang",
      "Huizhi Liang"
    ],
    "abstract": "SemEval-2025 Task 1 focuses on ranking images based on their alignment with a\ngiven nominal compound that may carry idiomatic meaning in both English and\nBrazilian Portuguese. To address this challenge, this work uses generative\nlarge language models (LLMs) and multilingual CLIP models to enhance idiomatic\ncompound representations. LLMs generate idiomatic meanings for potentially\nidiomatic compounds, enriching their semantic interpretation. These meanings\nare then encoded using multilingual CLIP models, serving as representations for\nimage ranking. Contrastive learning and data augmentation techniques are\napplied to fine-tune these embeddings for improved performance. Experimental\nresults show that multimodal representations extracted through this method\noutperformed those based solely on the original nominal compounds. The\nfine-tuning approach shows promising outcomes but is less effective than using\nembeddings without fine-tuning. The source code used in this paper is available\nat https://github.com/tongwu17/SemEval-2025-Task1-UoR-NCL.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20984v3",
    "published_date": "2025-02-28 11:52:02 UTC",
    "updated_date": "2025-05-01 14:54:16 UTC"
  },
  {
    "arxiv_id": "2502.20974v1",
    "title": "Improving Open-world Continual Learning under the Constraints of Scarce Labeled Data",
    "authors": [
      "Yujie Li",
      "Xiangkun Wang",
      "Xin Yang",
      "Marcello Bonsangue",
      "Junbo Zhang",
      "Tianrui Li"
    ],
    "abstract": "Open-world continual learning (OWCL) adapts to sequential tasks with open\nsamples, learning knowledge incrementally while preventing forgetting. However,\nexisting OWCL still requires a large amount of labeled data for training, which\nis often impractical in real-world applications. Given that new\ncategories/entities typically come with limited annotations and are in small\nquantities, a more realistic situation is OWCL with scarce labeled data, i.e.,\nfew-shot training samples. Hence, this paper investigates the problem of\nopen-world few-shot continual learning (OFCL), challenging in (i) learning\nunbounded tasks without forgetting previous knowledge and avoiding overfitting,\n(ii) constructing compact decision boundaries for open detection with limited\nlabeled data, and (iii) transferring knowledge about knowns and unknowns and\neven update the unknowns to knowns once the labels of open samples are learned.\nIn response, we propose a novel OFCL framework that integrates three key\ncomponents: (1) an instance-wise token augmentation (ITA) that represents and\nenriches sample representations with additional knowledge, (2) a margin-based\nopen boundary (MOB) that supports open detection with new tasks emerge over\ntime, and (3) an adaptive knowledge space (AKS) that endows unknowns with\nknowledge for the updating from unknowns to knowns. Finally, extensive\nexperiments show the proposed OFCL framework outperforms all baselines\nremarkably with practical importance and reproducibility. The source code is\nreleased at https://github.com/liyj1201/OFCL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20974v1",
    "published_date": "2025-02-28 11:39:18 UTC",
    "updated_date": "2025-02-28 11:39:18 UTC"
  },
  {
    "arxiv_id": "2503.11674v1",
    "title": "Timing-Driven Global Placement by Efficient Critical Path Extraction",
    "authors": [
      "Yunqi Shi",
      "Siyuan Xu",
      "Shixiong Kai",
      "Xi Lin",
      "Ke Xue",
      "Mingxuan Yuan",
      "Chao Qian"
    ],
    "abstract": "Timing optimization during the global placement of integrated circuits has\nbeen a significant focus for decades, yet it remains a complex, unresolved\nissue. Recent analytical methods typically use pin-level timing information to\nadjust net weights, which is fast and simple but neglects the path-based nature\nof the timing graph. The existing path-based methods, however, cannot balance\nthe accuracy and efficiency due to the exponential growth of number of critical\npaths. In this work, we propose a GPU-accelerated timing-driven global\nplacement framework, integrating accurate path-level information into the\nefficient DREAMPlace infrastructure. It optimizes the fine-grained pin-to-pin\nattraction objective and is facilitated by efficient critical path extraction.\nWe also design a quadratic distance loss function specifically to align with\nthe RC timing model. Experimental results demonstrate that our method\nsignificantly outperforms the current leading timing-driven placers, achieving\nan average improvement of 40.5% in total negative slack (TNS) and 8.3% in worst\nnegative slack (WNS), as well as an improvement in half-perimeter wirelength\n(HPWL).",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "Accepted by DATE'25 as a Best Paper Award",
    "pdf_url": "http://arxiv.org/pdf/2503.11674v1",
    "published_date": "2025-02-28 11:34:19 UTC",
    "updated_date": "2025-02-28 11:34:19 UTC"
  },
  {
    "arxiv_id": "2502.20964v2",
    "title": "Fine-Grained Retrieval-Augmented Generation for Visual Question Answering",
    "authors": [
      "Zhengxuan Zhang",
      "Yin Wu",
      "Yuyu Luo",
      "Nan Tang"
    ],
    "abstract": "Visual Question Answering (VQA) focuses on providing answers to natural\nlanguage questions by utilizing information from images. Although cutting-edge\nmultimodal large language models (MLLMs) such as GPT-4o achieve strong\nperformance on VQA tasks, they frequently fall short in accessing\ndomain-specific or the latest knowledge. To mitigate this issue,\nretrieval-augmented generation (RAG) leveraging external knowledge bases (KBs),\nreferred to as KB-VQA, emerges as a promising approach. Nevertheless,\nconventional unimodal retrieval techniques, which translate images into textual\ndescriptions, often result in the loss of critical visual details. This study\npresents fine-grained knowledge units, which merge textual snippets with entity\nimages stored in vector databases. Furthermore, we introduce a knowledge unit\nretrieval-augmented generation framework (KU-RAG) that integrates fine-grained\nretrieval with MLLMs. The proposed KU-RAG framework ensures precise retrieval\nof relevant knowledge and enhances reasoning capabilities through a knowledge\ncorrection chain. Experimental findings demonstrate that our approach\nsignificantly boosts the performance of leading KB-VQA methods, achieving an\naverage improvement of approximately 3% and up to 11% in the best case.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20964v2",
    "published_date": "2025-02-28 11:25:38 UTC",
    "updated_date": "2025-04-11 16:02:25 UTC"
  },
  {
    "arxiv_id": "2502.20963v2",
    "title": "Retrieval Augmented Generation for Topic Modeling in Organizational Research: An Introduction with Empirical Demonstration",
    "authors": [
      "Gerion Spielberger",
      "Florian M. Artinger",
      "Jochen Reb",
      "Rudolf Kerschreiter"
    ],
    "abstract": "Analyzing textual data is the cornerstone of qualitative research. While\ntraditional methods such as grounded theory and content analysis are widely\nused, they are labor-intensive and time-consuming. Topic modeling offers an\nautomated complement. Yet, existing approaches, including LLM-based topic\nmodeling, still struggle with issues such as high data preprocessing\nrequirements, interpretability, and reliability. This paper introduces Agentic\nRetrieval-Augmented Generation (Agentic RAG) as a method for topic modeling\nwith LLMs. It integrates three key components: (1) retrieval, enabling\nautomatized access to external data beyond an LLM's pre-trained knowledge; (2)\ngeneration, leveraging LLM capabilities for text synthesis; and (3)\nagent-driven learning, iteratively refining retrieval and query formulation\nprocesses. To empirically validate Agentic RAG for topic modeling, we reanalyze\na Twitter/X dataset, previously examined by Mu et al. (2024a). Our findings\ndemonstrate that the approach is more efficient, interpretable and at the same\ntime achieves higher reliability and validity in comparison to the standard\nmachine learning approach but also in comparison to LLM prompting for topic\nmodeling. These results highlight Agentic RAG's ability to generate\nsemantically relevant and reproducible topics, positioning it as a robust,\nscalable, and transparent alternative for AI-driven qualitative research in\nleadership, managerial, and organizational research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.LG",
    "comment": "30 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.20963v2",
    "published_date": "2025-02-28 11:25:11 UTC",
    "updated_date": "2025-03-18 12:00:26 UTC"
  },
  {
    "arxiv_id": "2502.20948v1",
    "title": "Concealed Adversarial attacks on neural networks for sequential data",
    "authors": [
      "Petr Sokerin",
      "Dmitry Anikin",
      "Sofia Krehova",
      "Alexey Zaytsev"
    ],
    "abstract": "The emergence of deep learning led to the broad usage of neural networks in\nthe time series domain for various applications, including finance and\nmedicine. While powerful, these models are prone to adversarial attacks: a\nbenign targeted perturbation of input data leads to significant changes in a\nclassifier's output. However, formally small attacks in the time series domain\nbecome easily detected by the human eye or a simple detector model.\n  We develop a concealed adversarial attack for different time-series models:\nit provides more realistic perturbations, being hard to detect by a human or\nmodel discriminator. To achieve this goal, the proposed adversarial attack\nmaximizes an aggregation of a classifier and a trained discriminator loss. To\nmake the attack stronger, we also propose a training procedure for a\ndiscriminator that provides broader coverage of possible attacks. Extensive\nbenchmarking on six UCR time series datasets across four diverse architectures\n- including recurrent, convolutional, state-space, and transformer-based models\n- demonstrates the superiority of our attack for a concealability-efficiency\ntrade-off. Our findings highlight the growing challenge of designing robust\ntime series models, emphasizing the need for improved defenses against\nrealistic and effective attacks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20948v1",
    "published_date": "2025-02-28 11:03:32 UTC",
    "updated_date": "2025-02-28 11:03:32 UTC"
  },
  {
    "arxiv_id": "2502.20946v1",
    "title": "Generative Uncertainty in Diffusion Models",
    "authors": [
      "Metod Jazbec",
      "Eliot Wong-Toi",
      "Guoxuan Xia",
      "Dan Zhang",
      "Eric Nalisnick",
      "Stephan Mandt"
    ],
    "abstract": "Diffusion models have recently driven significant breakthroughs in generative\nmodeling. While state-of-the-art models produce high-quality samples on\naverage, individual samples can still be low quality. Detecting such samples\nwithout human inspection remains a challenging task. To address this, we\npropose a Bayesian framework for estimating generative uncertainty of synthetic\nsamples. We outline how to make Bayesian inference practical for large, modern\ngenerative models and introduce a new semantic likelihood (evaluated in the\nlatent space of a feature extractor) to address the challenges posed by\nhigh-dimensional sample spaces. Through our experiments, we demonstrate that\nthe proposed generative uncertainty effectively identifies poor-quality samples\nand significantly outperforms existing uncertainty-based methods. Notably, our\nBayesian framework can be applied post-hoc to any pretrained diffusion or flow\nmatching model (via the Laplace approximation), and we propose simple yet\neffective techniques to minimize its computational overhead during sampling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20946v1",
    "published_date": "2025-02-28 10:56:39 UTC",
    "updated_date": "2025-02-28 10:56:39 UTC"
  },
  {
    "arxiv_id": "2502.20938v1",
    "title": "A Deep User Interface for Exploring LLaMa",
    "authors": [
      "Divya Perumal",
      "Swaroop Panda"
    ],
    "abstract": "The growing popularity and widespread adoption of large language models\n(LLMs) necessitates the development of tools that enhance the effectiveness of\nuser interactions with these models. Understanding the structures and functions\nof these models poses a significant challenge for users. Visual\nanalytics-driven tools enables users to explore and compare, facilitating\nbetter decision-making. This paper presents a visual analytics-driven tool\nequipped with interactive controls for key hyperparameters, including top-p,\nfrequency and presence penalty, enabling users to explore, examine and compare\nthe outputs of LLMs. In a user study, we assessed the tool's effectiveness,\nwhich received favorable feedback for its visual design, with particular\ncommendation for the interface layout and ease of navigation. Additionally, the\nfeedback provided valuable insights for enhancing the effectiveness of\nHuman-LLM interaction tools.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20938v1",
    "published_date": "2025-02-28 10:48:14 UTC",
    "updated_date": "2025-02-28 10:48:14 UTC"
  },
  {
    "arxiv_id": "2502.20936v1",
    "title": "WebFAQ: A Multilingual Collection of Natural Q&A Datasets for Dense Retrieval",
    "authors": [
      "Michael Dinzinger",
      "Laura Caspari",
      "Kanishka Ghosh Dastidar",
      "Jelena Mitrović",
      "Michael Granitzer"
    ],
    "abstract": "We present WebFAQ, a large-scale collection of open-domain question answering\ndatasets derived from FAQ-style schema.org annotations. In total, the data\ncollection consists of 96 million natural question-answer (QA) pairs across 75\nlanguages, including 47 million (49%) non-English samples. WebFAQ further\nserves as the foundation for 20 monolingual retrieval benchmarks with a total\nsize of 11.2 million QA pairs (5.9 million non-English). These datasets are\ncarefully curated through refined filtering and near-duplicate detection,\nyielding high-quality resources for training and evaluating multilingual dense\nretrieval models. To empirically confirm WebFAQ's efficacy, we use the\ncollected QAs to fine-tune an in-domain pretrained XLM-RoBERTa model. Through\nthis process of dataset-specific fine-tuning, the model achieves significant\nretrieval performance gains, which generalize - beyond WebFAQ - to other\nmultilingual retrieval benchmarks evaluated in zero-shot setting. Last but not\nleast, we utilize WebFAQ to construct a set of QA-aligned bilingual corpora\nspanning over 1000 language pairs using state-of-the-art bitext mining and\nautomated LLM-assessed translation evaluation. Due to our advanced, automated\nmethod of bitext dataset generation, the resulting bilingual corpora\ndemonstrate higher translation quality compared to similar datasets. WebFAQ and\nall associated resources are publicly available on GitHub and HuggingFace.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 3 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.20936v1",
    "published_date": "2025-02-28 10:46:52 UTC",
    "updated_date": "2025-02-28 10:46:52 UTC"
  },
  {
    "arxiv_id": "2502.20934v2",
    "title": "Less is More? Revisiting the Importance of Frame Rate in Real-Time Zero-Shot Surgical Video Segmentation",
    "authors": [
      "Utku Ozbulak",
      "Seyed Amir Mousavi",
      "Francesca Tozzi",
      "Niki Rashidian",
      "Wouter Willaert",
      "Wesley De Neve",
      "Joris Vankerschaver"
    ],
    "abstract": "Real-time video segmentation is a promising feature for AI-assisted surgery,\nproviding intraoperative guidance by identifying surgical tools and anatomical\nstructures. However, deploying state-of-the-art segmentation models, such as\nSAM2, in real-time settings is computationally demanding, which makes it\nessential to balance frame rate and segmentation performance. In this study, we\ninvestigate the impact of frame rate on zero-shot surgical video segmentation,\nevaluating SAM2's effectiveness across multiple frame sampling rates for\ncholecystectomy procedures. Surprisingly, our findings indicate that in\nconventional evaluation settings, frame rates as low as a single frame per\nsecond can outperform 25 FPS, as fewer frames smooth out segmentation\ninconsistencies. However, when assessed in a real-time streaming scenario,\nhigher frame rates yield superior temporal coherence and stability,\nparticularly for dynamic objects such as surgical graspers. Finally, we\ninvestigate human perception of real-time surgical video segmentation among\nprofessionals who work closely with such data and find that respondents\nconsistently prefer high FPS segmentation mask overlays, reinforcing the\nimportance of real-time evaluation in AI-assisted surgery.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20934v2",
    "published_date": "2025-02-28 10:42:09 UTC",
    "updated_date": "2025-04-07 13:22:10 UTC"
  },
  {
    "arxiv_id": "2502.20914v1",
    "title": "Everything, Everywhere, All at Once: Is Mechanistic Interpretability Identifiable?",
    "authors": [
      "Maxime Méloux",
      "Silviu Maniu",
      "François Portet",
      "Maxime Peyrard"
    ],
    "abstract": "As AI systems are used in high-stakes applications, ensuring interpretability\nis crucial. Mechanistic Interpretability (MI) aims to reverse-engineer neural\nnetworks by extracting human-understandable algorithms to explain their\nbehavior. This work examines a key question: for a given behavior, and under\nMI's criteria, does a unique explanation exist? Drawing on identifiability in\nstatistics, where parameters are uniquely inferred under specific assumptions,\nwe explore the identifiability of MI explanations.\n  We identify two main MI strategies: (1) \"where-then-what,\" which isolates a\ncircuit replicating model behavior before interpreting it, and (2)\n\"what-then-where,\" which starts with candidate algorithms and searches for\nneural activation subspaces implementing them, using causal alignment.\n  We test both strategies on Boolean functions and small multi-layer\nperceptrons, fully enumerating candidate explanations. Our experiments reveal\nsystematic non-identifiability: multiple circuits can replicate behavior, a\ncircuit can have multiple interpretations, several algorithms can align with\nthe network, and one algorithm can align with different subspaces.\n  Is uniqueness necessary? A pragmatic approach may require only predictive and\nmanipulability standards. If uniqueness is essential for understanding,\nstricter criteria may be needed. We also reference the inner interpretability\nframework, which validates explanations through multiple criteria. This work\ncontributes to defining explanation standards in AI.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20914v1",
    "published_date": "2025-02-28 10:13:54 UTC",
    "updated_date": "2025-02-28 10:13:54 UTC"
  },
  {
    "arxiv_id": "2504.05324v1",
    "title": "Hybrid Retrieval for Hallucination Mitigation in Large Language Models: A Comparative Analysis",
    "authors": [
      "Chandana Sree Mala",
      "Gizem Gezici",
      "Fosca Giannotti"
    ],
    "abstract": "Large Language Models (LLMs) excel in language comprehension and generation\nbut are prone to hallucinations, producing factually incorrect or unsupported\noutputs. Retrieval Augmented Generation (RAG) systems address this issue by\ngrounding LLM responses with external knowledge. This study evaluates the\nrelationship between retriever effectiveness and hallucination reduction in\nLLMs using three retrieval approaches: sparse retrieval based on BM25 keyword\nsearch, dense retrieval using semantic search with Sentence Transformers, and a\nproposed hybrid retrieval module. The hybrid module incorporates query\nexpansion and combines the results of sparse and dense retrievers through a\ndynamically weighted Reciprocal Rank Fusion score. Using the HaluBench dataset,\na benchmark for hallucinations in question answering tasks, we assess retrieval\nperformance with metrics such as mean average precision and normalised\ndiscounted cumulative gain, focusing on the relevance of the top three\nretrieved documents. Results show that the hybrid retriever achieves better\nrelevance scores, outperforming both sparse and dense retrievers. Further\nevaluation of LLM-generated answers against ground truth using metrics such as\naccuracy, hallucination rate, and rejection rate reveals that the hybrid\nretriever achieves the highest accuracy on fails, the lowest hallucination\nrate, and the lowest rejection rate. These findings highlight the hybrid\nretriever's ability to enhance retrieval relevance, reduce hallucination rates,\nand improve LLM reliability, emphasising the importance of advanced retrieval\ntechniques in mitigating hallucinations and improving response accuracy.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05324v1",
    "published_date": "2025-02-28 10:13:33 UTC",
    "updated_date": "2025-02-28 10:13:33 UTC"
  },
  {
    "arxiv_id": "2503.00084v1",
    "title": "InspireMusic: Integrating Super Resolution and Large Language Model for High-Fidelity Long-Form Music Generation",
    "authors": [
      "Chong Zhang",
      "Yukun Ma",
      "Qian Chen",
      "Wen Wang",
      "Shengkui Zhao",
      "Zexu Pan",
      "Hao Wang",
      "Chongjia Ni",
      "Trung Hieu Nguyen",
      "Kun Zhou",
      "Yidi Jiang",
      "Chaohong Tan",
      "Zhifu Gao",
      "Zhihao Du",
      "Bin Ma"
    ],
    "abstract": "We introduce InspireMusic, a framework integrated super resolution and large\nlanguage model for high-fidelity long-form music generation. A unified\nframework generates high-fidelity music, songs, and audio, which incorporates\nan autoregressive transformer with a super-resolution flow-matching model. This\nframework enables the controllable generation of high-fidelity long-form music\nat a higher sampling rate from both text and audio prompts. Our model differs\nfrom previous approaches, as we utilize an audio tokenizer with one codebook\nthat contains richer semantic information, thereby reducing training costs and\nenhancing efficiency. This combination enables us to achieve high-quality audio\ngeneration with long-form coherence of up to $8$ minutes. Then, an\nautoregressive transformer model based on Qwen 2.5 predicts audio tokens. Next,\nwe employ a super-resolution flow-matching model to generate high-sampling rate\naudio with fine-grained details learned from an acoustic codec model.\nComprehensive experiments show that the InspireMusic-1.5B-Long model has a\ncomparable performance to recent top-tier open-source systems, including\nMusicGen and Stable Audio 2.0, on subjective and objective evaluations. The\ncode and pre-trained models are released at\nhttps://github.com/FunAudioLLM/InspireMusic.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Work in progress. Correspondence regarding this technical report\n  should be directed to {chong.zhang, yukun.ma}@alibaba-inc.com. Online demo\n  available on https://modelscope.cn/studios/iic/InspireMusic and\n  https://huggingface.co/spaces/FunAudioLLM/InspireMusic",
    "pdf_url": "http://arxiv.org/pdf/2503.00084v1",
    "published_date": "2025-02-28 09:58:25 UTC",
    "updated_date": "2025-02-28 09:58:25 UTC"
  },
  {
    "arxiv_id": "2502.20900v3",
    "title": "DexGraspVLA: A Vision-Language-Action Framework Towards General Dexterous Grasping",
    "authors": [
      "Yifan Zhong",
      "Xuchuan Huang",
      "Ruochong Li",
      "Ceyao Zhang",
      "Yitao Liang",
      "Yaodong Yang",
      "Yuanpei Chen"
    ],
    "abstract": "Dexterous grasping remains a fundamental yet challenging problem in robotics.\nA general-purpose robot must be capable of grasping diverse objects in\narbitrary scenarios. However, existing research typically relies on restrictive\nassumptions, such as single-object settings or limited environments, leading to\nconstrained generalization. We present DexGraspVLA, a hierarchical framework\nfor general dexterous grasping in cluttered scenes based on RGB image\nperception and language instructions. It utilizes a pre-trained Vision-Language\nmodel as the high-level task planner and learns a diffusion-based policy as the\nlow-level Action controller. The key insight to achieve robust generalization\nlies in iteratively transforming diverse language and visual inputs into\ndomain-invariant representations via foundation models, where imitation\nlearning can be effectively applied due to the alleviation of domain shift.\nNotably, our method achieves a 90+% success rate under thousands of unseen\nobject, lighting, and background combinations in a \"zero-shot\" environment.\nEmpirical analysis confirms the consistency of internal model behavior across\nenvironmental variations, thereby validating our design and explaining its\ngeneralization performance. DexGraspVLA also demonstrates free-form\nlong-horizon prompt execution, robustness to adversarial objects and human\ndisturbance, and failure recovery, which are rarely achieved simultaneously in\nprior work. Extended application to nonprehensile object grasping further\nproves its generality. Code, model, and video are available at\ndexgraspvla.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "26 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.20900v3",
    "published_date": "2025-02-28 09:57:20 UTC",
    "updated_date": "2025-05-22 08:27:36 UTC"
  },
  {
    "arxiv_id": "2502.20885v1",
    "title": "A Fused Gromov-Wasserstein Approach to Subgraph Contrastive Learning",
    "authors": [
      "Amadou S. Sangare",
      "Nicolas Dunou",
      "Jhony H. Giraldo",
      "Fragkiskos D. Malliaros"
    ],
    "abstract": "Self-supervised learning has become a key method for training deep learning\nmodels when labeled data is scarce or unavailable. While graph machine learning\nholds great promise across various domains, the design of effective pretext\ntasks for self-supervised graph representation learning remains challenging.\nContrastive learning, a popular approach in graph self-supervised learning,\nleverages positive and negative pairs to compute a contrastive loss function.\nHowever, current graph contrastive learning methods often struggle to fully use\nstructural patterns and node similarities. To address these issues, we present\na new method called Fused Gromov Wasserstein Subgraph Contrastive Learning\n(FOSSIL). Our model integrates node-level and subgraph-level contrastive\nlearning, seamlessly combining a standard node-level contrastive loss with the\nFused Gromov-Wasserstein distance. This combination helps our method capture\nboth node features and graph structure together. Importantly, our approach\nworks well with both homophilic and heterophilic graphs and can dynamically\ncreate views for generating positive and negative pairs. Through extensive\nexperiments on benchmark graph datasets, we show that FOSSIL outperforms or\nachieves competitive performance compared to current state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20885v1",
    "published_date": "2025-02-28 09:32:07 UTC",
    "updated_date": "2025-02-28 09:32:07 UTC"
  },
  {
    "arxiv_id": "2503.04790v1",
    "title": "SuperRAG: Beyond RAG with Layout-Aware Graph Modeling",
    "authors": [
      "Jeff Yang",
      "Duy-Khanh Vu",
      "Minh-Tien Nguyen",
      "Xuan-Quang Nguyen",
      "Linh Nguyen",
      "Hung Le"
    ],
    "abstract": "This paper introduces layout-aware graph modeling for multimodal RAG.\nDifferent from traditional RAG methods that mostly deal with flat text chunks,\nthe proposed method takes into account the relationship of multimodalities by\nusing a graph structure. To do that, a graph modeling structure is defined\nbased on document layout parsing. The structure of an input document is\nretained with the connection of text chunks, tables, and figures. This\nrepresentation allows the method to handle complex questions that require\ninformation from multimodalities. To confirm the efficiency of the graph\nmodeling, a flexible RAG pipeline is developed using robust components.\nExperimental results on four benchmark test sets confirm the contribution of\nthe layout-aware modeling for performance improvement of the RAG pipeline.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025, Industry Track",
    "pdf_url": "http://arxiv.org/pdf/2503.04790v1",
    "published_date": "2025-02-28 09:05:49 UTC",
    "updated_date": "2025-02-28 09:05:49 UTC"
  },
  {
    "arxiv_id": "2502.20854v3",
    "title": "A Pilot Empirical Study on When and How to Use Knowledge Graphs as Retrieval Augmented Generation",
    "authors": [
      "Xujie Yuan",
      "Yongxu Liu",
      "Shimin Di",
      "Shiwen Wu",
      "Libin Zheng",
      "Rui Meng",
      "Lei Chen",
      "Xiaofang Zhou",
      "Jian Yin"
    ],
    "abstract": "The integration of Knowledge Graphs (KGs) into the Retrieval Augmented\nGeneration (RAG) framework has attracted significant interest, with early\nstudies showing promise in mitigating hallucinations and improving model\naccuracy. However, a systematic understanding and comparative analysis of the\nrapidly emerging KG-RAG methods are still lacking. This paper seeks to lay the\nfoundation for systematically answering the question of when and how to use\nKG-RAG by analyzing their performance in various application scenarios\nassociated with different technical configurations. After outlining the mind\nmap using KG-RAG framework and summarizing its popular pipeline, we conduct a\npilot empirical study of KG-RAG works to reimplement and evaluate 6 KG-RAG\nmethods across 9 datasets in diverse domains and scenarios, analyzing the\nimpact of 9 KG-RAG configurations in combination with 17 LLMs, and combining\nMetacognition with KG-RAG as a pilot attempt. Our results underscore the\ncritical role of appropriate application conditions and optimal configurations\nof KG-RAG components.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 2 figures, 19 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.20854v3",
    "published_date": "2025-02-28 08:53:08 UTC",
    "updated_date": "2025-05-17 06:41:37 UTC"
  },
  {
    "arxiv_id": "2502.20853v1",
    "title": "Oscillation-Reduced MXFP4 Training for Vision Transformers",
    "authors": [
      "Yuxiang Chen",
      "Haocheng Xi",
      "Jun Zhu",
      "Jianfei Chen"
    ],
    "abstract": "Pre-training Transformers in FP4 precision is becoming a promising approach\nto gain substantial speedup, but it comes with a considerable loss of accuracy.\nMicroscaling (MX) data format provides a fine-grained per-group quantization\nmethod to improve the representation ability of the FP4 format and is supported\nby the next-generation Blackwell GPU architecture. However, training with MXFP4\ndata format still results in significant degradation and there is a lack of\nsystematic research on the reason.\n  In this work, we propose a novel training method TetraJet for a more accurate\nFP4 training. We comprehensively evaluate all of the quantizers involved in the\ntraining, and identify the weight oscillation problem in the forward pass as\nthe main source of the degradation in MXFP4 training. Therefore, we introduce\ntwo novel methods, EMA Quantizer (Q-EMA) and Adaptive Ramping Optimizer\n(Q-Ramping), to resolve the oscillation problem. Extensive experiments on\nVision Transformers demonstrate that TetraJet consistently outperforms the\nexisting 4-bit training methods, and Q-EMA & Q-Ramping can provide additional\nenhancement by effectively reducing oscillation. We decreased the accuracy\ndegradation by more than $50\\%$ compared to the baseline, and can even achieve\ncompetitive performance compared to full precision training. The codes are\navailable at https://github.com/thu-ml/TetraJet-MXFP4Training",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20853v1",
    "published_date": "2025-02-28 08:51:55 UTC",
    "updated_date": "2025-02-28 08:51:55 UTC"
  },
  {
    "arxiv_id": "2503.13467v1",
    "title": "How Metacognitive Architectures Remember Their Own Thoughts: A Systematic Review",
    "authors": [
      "Robin Nolte",
      "Mihai Pomarlan",
      "Ayden Janssen",
      "Daniel Beßler",
      "Kamyar Javanmardi",
      "Sascha Jongebloed",
      "Robert Porzel",
      "John Bateman",
      "Michael Beetz",
      "Rainer Malaka"
    ],
    "abstract": "Inspired by human cognition, metacognition has gained significant attention\nfor its potential to enhance autonomy, adaptability, and robust learning in\nartificial agents. Yet research on Computational Metacognitive Architectures\n(CMAs) remains fragmented: diverse theories, terminologies, and design choices\nhave led to disjointed developments and limited comparability across systems.\nExisting overviews and surveys often remain at a broad, conceptual level,\nmaking it difficult to synthesize deeper insights into the underlying\nalgorithms and representations, and their respective success. We address this\ngap by performing an explorative systematic review of how CMAs model, store,\nremember and process their metacognitive experiences, one of Flavell's (1979)\nthree foundational components of metacognition. Following this organizing\nprinciple, we identify 35 CMAs that feature episodic introspective data ranging\nfrom symbolic event traces to sub-symbolic arousal metrics. We consider\ndifferent aspects - ranging from the underlying psychological theories to the\ncontent and structure of collected data, to the algorithms used and evaluation\nresults - and derive a unifying perspective that allows us to compare in depth\nhow different Computational Metacognitive Architectures (CMAs) leverage\nmetacognitive experiences for tasks such as error diagnosis, self-repair, and\ngoal-driven learning. Our findings highlight both the promise of metacognitive\nexperiences - in boosting adaptability, explainability, and overall system\nperformance - and the persistent lack of shared standards or evaluation\nbenchmarks.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "I.2.0; I.2.4; I.2.6; I.2.8; J.4"
    ],
    "primary_category": "q-bio.NC",
    "comment": "69 pages, 13 figures. In preparation for submission",
    "pdf_url": "http://arxiv.org/pdf/2503.13467v1",
    "published_date": "2025-02-28 08:48:41 UTC",
    "updated_date": "2025-02-28 08:48:41 UTC"
  },
  {
    "arxiv_id": "2502.20845v1",
    "title": "Reinforcement Learning with Curriculum-inspired Adaptive Direct Policy Guidance for Truck Dispatching",
    "authors": [
      "Shi Meng",
      "Bin Tian",
      "Xiaotong Zhang"
    ],
    "abstract": "Efficient truck dispatching via Reinforcement Learning (RL) in open-pit\nmining is often hindered by reliance on complex reward engineering and\nvalue-based methods. This paper introduces Curriculum-inspired Adaptive Direct\nPolicy Guidance, a novel curriculum learning strategy for policy-based RL to\naddress these issues. We adapt Proximal Policy Optimization (PPO) for mine\ndispatching's uneven decision intervals using time deltas in Temporal\nDifference and Generalized Advantage Estimation, and employ a Shortest\nProcessing Time teacher policy for guided exploration via policy regularization\nand adaptive guidance. Evaluations in OpenMines demonstrate our approach yields\na 10% performance gain and faster convergence over standard PPO across sparse\nand dense reward settings, showcasing improved robustness to reward design.\nThis direct policy guidance method provides a general and effective curriculum\nlearning technique for RL-based truck dispatching, enabling future work on\nadvanced architectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20845v1",
    "published_date": "2025-02-28 08:43:32 UTC",
    "updated_date": "2025-02-28 08:43:32 UTC"
  },
  {
    "arxiv_id": "2502.20844v1",
    "title": "Neuro-Symbolic Learning for Galois Groups: Unveiling Probabilistic Trends in Polynomials",
    "authors": [
      "Elira Shaska",
      "Tony Shaska"
    ],
    "abstract": "This paper presents a neurosymbolic approach to classifying Galois groups of\npolynomials, integrating classical Galois theory with machine learning to\naddress challenges in algebraic computation. By combining neural networks with\nsymbolic reasoning we develop a model that outperforms purely numerical methods\nin accuracy and interpretability. Focusing on sextic polynomials with height\n$\\leq 6$, we analyze a database of 53,972 irreducible examples, uncovering\nnovel distributional trends, such as the 20 sextic polynomials with Galois\ngroup $C_6$ spanning just seven invariant-defined equivalence classes. These\nfindings offer the first empirical insights into Galois group probabilities\nunder height constraints and lay the groundwork for exploring solvability by\nradicals. Demonstrating AI's potential to reveal patterns beyond traditional\nsymbolic techniques, this work paves the way for future research in\ncomputational algebra, with implications for probabilistic conjectures and\nhigher degree classifications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "12F10, 68T07",
      "I.2; I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20844v1",
    "published_date": "2025-02-28 08:42:57 UTC",
    "updated_date": "2025-02-28 08:42:57 UTC"
  },
  {
    "arxiv_id": "2502.20843v1",
    "title": "Hierarchical and Modular Network on Non-prehensile Manipulation in General Environments",
    "authors": [
      "Yoonyoung Cho",
      "Junhyek Han",
      "Jisu Han",
      "Beomjoon Kim"
    ],
    "abstract": "For robots to operate in general environments like households, they must be\nable to perform non-prehensile manipulation actions such as toppling and\nrolling to manipulate ungraspable objects. However, prior works on\nnon-prehensile manipulation cannot yet generalize across environments with\ndiverse geometries. The main challenge lies in adapting to varying\nenvironmental constraints: within a cabinet, the robot must avoid walls and\nceilings; to lift objects to the top of a step, the robot must account for the\nstep's pose and extent. While deep reinforcement learning (RL) has demonstrated\nimpressive success in non-prehensile manipulation, accounting for such\nvariability presents a challenge for the generalist policy, as it must learn\ndiverse strategies for each new combination of constraints. To address this, we\npropose a modular and reconfigurable architecture that adaptively reconfigures\nnetwork modules based on task requirements. To capture the geometric\nvariability in environments, we extend the contact-based object representation\n(CORN) to environment geometries, and propose a procedural algorithm for\ngenerating diverse environments to train our agent. Taken together, the\nresulting policy can zero-shot transfer to novel real-world environments and\nobjects despite training entirely within a simulator. We additionally release a\nsimulation-based benchmark featuring nine digital twins of real-world scenes\nwith 353 objects to facilitate non-prehensile manipulation research in\nrealistic domains.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "http://unicorn-hamnet.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2502.20843v1",
    "published_date": "2025-02-28 08:42:00 UTC",
    "updated_date": "2025-02-28 08:42:00 UTC"
  },
  {
    "arxiv_id": "2502.20838v1",
    "title": "Weakly Supervised Multiple Instance Learning for Whale Call Detection and Localization in Long-Duration Passive Acoustic Monitoring",
    "authors": [
      "Ragib Amin Nihal",
      "Benjamin Yen",
      "Runwu Shi",
      "Kazuhiro Nakadai"
    ],
    "abstract": "Marine ecosystem monitoring via Passive Acoustic Monitoring (PAM) generates\nvast data, but deep learning often requires precise annotations and short\nsegments. We introduce DSMIL-LocNet, a Multiple Instance Learning framework for\nwhale call detection and localization using only bag-level labels. Our\ndual-stream model processes 2-30 minute audio segments, leveraging spectral and\ntemporal features with attention-based instance selection. Tests on Antarctic\nwhale data show longer contexts improve classification (F1: 0.8-0.9) while\nmedium instances ensure localization precision (0.65-0.70). This suggests MIL\ncan enhance scalable marine monitoring. Code:\nhttps://github.com/Ragib-Amin-Nihal/DSMIL-Loc",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20838v1",
    "published_date": "2025-02-28 08:34:12 UTC",
    "updated_date": "2025-02-28 08:34:12 UTC"
  },
  {
    "arxiv_id": "2502.20825v1",
    "title": "LADs: Leveraging LLMs for AI-Driven DevOps",
    "authors": [
      "Ahmad Faraz Khan",
      "Azal Ahmad Khan",
      "Anas Mohamed",
      "Haider Ali",
      "Suchithra Moolinti",
      "Sabaat Haroon",
      "Usman Tahir",
      "Mattia Fazzini",
      "Ali R. Butt",
      "Ali Anwar"
    ],
    "abstract": "Automating cloud configuration and deployment remains a critical challenge\ndue to evolving infrastructures, heterogeneous hardware, and fluctuating\nworkloads. Existing solutions lack adaptability and require extensive manual\ntuning, leading to inefficiencies and misconfigurations. We introduce LADs, the\nfirst LLM-driven framework designed to tackle these challenges by ensuring\nrobustness, adaptability, and efficiency in automated cloud management. Instead\nof merely applying existing techniques, LADs provides a principled approach to\nconfiguration optimization through in-depth analysis of what optimization works\nunder which conditions. By leveraging Retrieval-Augmented Generation, Few-Shot\nLearning, Chain-of-Thought, and Feedback-Based Prompt Chaining, LADs generates\naccurate configurations and learns from deployment failures to iteratively\nrefine system settings. Our findings reveal key insights into the trade-offs\nbetween performance, cost, and scalability, helping practitioners determine the\nright strategies for different deployment scenarios. For instance, we\ndemonstrate how prompt chaining-based adaptive feedback loops enhance fault\ntolerance in multi-tenant environments and how structured log analysis with\nexample shots improves configuration accuracy. Through extensive evaluations,\nLADs reduces manual effort, optimizes resource utilization, and improves system\nreliability. By open-sourcing LADs, we aim to drive further innovation in\nAI-powered DevOps automation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages with Appendix, 8 figures, and 7 tables. This paper is\n  currently Under Review",
    "pdf_url": "http://arxiv.org/pdf/2502.20825v1",
    "published_date": "2025-02-28 08:12:08 UTC",
    "updated_date": "2025-02-28 08:12:08 UTC"
  },
  {
    "arxiv_id": "2502.20808v5",
    "title": "MV-MATH: Evaluating Multimodal Math Reasoning in Multi-Visual Contexts",
    "authors": [
      "Peijie Wang",
      "Zhong-Zhi Li",
      "Fei Yin",
      "Xin Yang",
      "Dekang Ran",
      "Cheng-Lin Liu"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have shown promising capabilities in\nmathematical reasoning within visual contexts across various datasets. However,\nmost existing multimodal math benchmarks are limited to single-visual contexts,\nwhich diverges from the multi-visual scenarios commonly encountered in\nreal-world mathematical applications. To address this gap, we introduce\nMV-MATH: a meticulously curated dataset of 2,009 high-quality mathematical\nproblems. Each problem integrates multiple images interleaved with text,\nderived from authentic K-12 scenarios, and enriched with detailed annotations.\nMV-MATH includes multiple-choice, free-form, and multi-step questions, covering\n11 subject areas across 3 difficulty levels, and serves as a comprehensive and\nrigorous benchmark for assessing MLLMs' mathematical reasoning in multi-visual\ncontexts. Through extensive experimentation, we observe that MLLMs encounter\nsubstantial challenges in multi-visual math tasks, with a considerable\nperformance gap relative to human capabilities on MV-MATH. Furthermore, we\nanalyze the performance and error patterns of various models, providing\ninsights into MLLMs' mathematical reasoning capabilities within multi-visual\nsettings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "45 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.20808v5",
    "published_date": "2025-02-28 07:50:36 UTC",
    "updated_date": "2025-05-21 14:00:34 UTC"
  },
  {
    "arxiv_id": "2502.20806v1",
    "title": "Multimodal Learning for Just-In-Time Software Defect Prediction in Autonomous Driving Systems",
    "authors": [
      "Faisal Mohammad",
      "Duksan Ryu"
    ],
    "abstract": "In recent years, the rise of autonomous driving technologies has highlighted\nthe critical importance of reliable software for ensuring safety and\nperformance. This paper proposes a novel approach for just-in-time software\ndefect prediction (JIT-SDP) in autonomous driving software systems using\nmultimodal learning. The proposed model leverages the multimodal transformers\nin which the pre-trained transformers and a combining module deal with the\nmultiple data modalities of the software system datasets such as code features,\nchange metrics, and contextual information. The key point for adapting\nmultimodal learning is to utilize the attention mechanism between the different\ndata modalities such as text, numerical, and categorical. In the combining\nmodule, the output of a transformer model on text data and tabular features\ncontaining categorical and numerical data are combined to produce the\npredictions using the fully connected layers. Experiments conducted on three\nopen-source autonomous driving system software projects collected from the\nGitHub repository (Apollo, Carla, and Donkeycar) demonstrate that the proposed\napproach significantly outperforms state-of-the-art deep learning and machine\nlearning models regarding evaluation metrics. Our findings highlight the\npotential of multimodal learning to enhance the reliability and safety of\nautonomous driving software through improved defect prediction.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "9",
    "pdf_url": "http://arxiv.org/pdf/2502.20806v1",
    "published_date": "2025-02-28 07:45:10 UTC",
    "updated_date": "2025-02-28 07:45:10 UTC"
  },
  {
    "arxiv_id": "2503.01902v1",
    "title": "An Empirical Analysis of LLMs for Countering Misinformation",
    "authors": [
      "Adiba Mahbub Proma",
      "Neeley Pate",
      "James Druckman",
      "Gourab Ghoshal",
      "Hangfeng He",
      "Ehsan Hoque"
    ],
    "abstract": "While Large Language Models (LLMs) can amplify online misinformation, they\nalso show promise in tackling misinformation. In this paper, we empirically\nstudy the capabilities of three LLMs -- ChatGPT, Gemini, and Claude -- in\ncountering political misinformation. We implement a two-step, chain-of-thought\nprompting approach, where models first identify credible sources for a given\nclaim and then generate persuasive responses. Our findings suggest that models\nstruggle to ground their responses in real news sources, and tend to prefer\nciting left-leaning sources. We also observe varying degrees of response\ndiversity among models. Our findings highlight concerns about using LLMs for\nfact-checking through only prompt-engineering, emphasizing the need for more\nrobust guardrails. Our results have implications for both researchers and\nnon-technical users.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Adiba and Neeley contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2503.01902v1",
    "published_date": "2025-02-28 07:12:03 UTC",
    "updated_date": "2025-02-28 07:12:03 UTC"
  },
  {
    "arxiv_id": "2502.20789v1",
    "title": "Characteristics Analysis of Autonomous Vehicle Pre-crash Scenarios",
    "authors": [
      "Yixuan Li",
      "Xuesong Wang",
      "Tianyi Wang",
      "Qian Liu"
    ],
    "abstract": "To date, hundreds of crashes have occurred in open road testing of automated\nvehicles (AVs), highlighting the need for improving AV reliability and safety.\nPre-crash scenario typology classifies crashes based on vehicle dynamics and\nkinematics features. Building on this, characteristics analysis can identify\nsimilar features under comparable crashes, offering a more effective reflection\nof general crash patterns and providing more targeted recommendations for\nenhancing AV performance. However, current studies primarily concentrated on\ncrashes among conventional human-driven vehicles, leaving a gap in research\ndedicated to in-depth AV crash analyses. In this paper, we analyzed the latest\nCalifornia AV collision reports and used the newly revised pre-crash scenario\ntypology to identify pre-crash scenarios. We proposed a set of mapping rules\nfor automatically extracting these AV pre-crash scenarios, successfully\nidentifying 24 types with a 98.1% accuracy rate, and obtaining two key\nscenarios of AV crashes (i.e., rear-end scenarios and intersection scenarios)\nthrough detailed analysis. Association analyses of rear-end scenarios showed\nthat the significant environmental influencing factors were traffic control\ntype, location type, light, etc. For intersection scenarios prone to severe\ncrashes with detailed descriptions, we employed causal analyses to obtain the\nsignificant causal factors: habitual violations and expectations of certain\nbehavior. Optimization recommendations were then formulated, addressing both\ngovernmental oversight and AV manufacturers' potential improvements. The\nfindings of this paper could guide government authorities to develop related\nregulations, help manufacturers design AV test scenarios, and identify\npotential shortcomings in control algorithms specific to various real-world\nscenarios, thereby optimizing AV systems effectively.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20789v1",
    "published_date": "2025-02-28 07:10:53 UTC",
    "updated_date": "2025-02-28 07:10:53 UTC"
  },
  {
    "arxiv_id": "2503.01901v1",
    "title": "Identifying Sensitive Weights via Post-quantization Integral",
    "authors": [
      "Yuezhou Hu",
      "Weiyu Huang",
      "Zichen Liang",
      "Chang Chen",
      "Jintao Zhang",
      "Jun Zhu",
      "Jianfei Chen"
    ],
    "abstract": "Serving Large Language Models (LLMs) is costly. However, post-training weight\nquantization can address this problem by both compressing their sizes for\nlimited memory and saving bandwidth for acceleration. As not all weight\ndimensions are equally important, those methods typically rely on a sensitivity\nmetric, which indicates the element-wise influence of weights on loss function\nand is used to preprocess original weights for better quantization. In this\nwork, we conduct an empirical study on the accuracy of the sensitivity metric,\nand find that existing gradient and Hessian based metrics are very inaccurate:\nthey underestimate quantization's impact on the loss function by orders of\nmagnitude, mainly due to the small convergence radius of local 2nd order\napproximation, \\ie, gradient and Hessian term in Taylor's formula. To tackle\nthis problem, we propose Post-quantization Integral (PQI), an accurate metric\nto estimate posterior sensitivity in a fine-grained manner. To leverage this\naccurate metric, we further propose ReQuant, a simple yet powerful framework\nthat mainly consists of two Dense-and-Sparse detach components: self-adaptive\noutlier selection and step-wise significant weights detach. Results show that\nReQuant boosts state-of-the-art post-training quantization methods, with a\npronounced improvement of 2.66 perplexity gain on Llama 3.2 1B with QTIP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01901v1",
    "published_date": "2025-02-28 07:04:19 UTC",
    "updated_date": "2025-02-28 07:04:19 UTC"
  },
  {
    "arxiv_id": "2502.20783v1",
    "title": "Flattening Supply Chains: When do Technology Improvements lead to Disintermediation?",
    "authors": [
      "S. Nageeb Ali",
      "Nicole Immorlica",
      "Meena Jagadeesan",
      "Brendan Lucier"
    ],
    "abstract": "In the digital economy, technological innovations make it cheaper to produce\nhigh-quality content. For example, generative AI tools reduce costs for\ncreators who develop content to be distributed online, but can also reduce\nproduction costs for the users who consume that content. These innovations can\nthus lead to disintermediation, since consumers may choose to use these\ntechnologies directly, bypassing intermediaries. To investigate when\ntechnological improvements lead to disintermediation, we study a game with an\nintermediary, suppliers of a production technology, and consumers. First, we\nshow disintermediation occurs whenever production costs are too high or too\nlow. We then investigate the consequences of disintermediation for welfare and\ncontent quality at equilibrium. While the intermediary is welfare-improving,\nthe intermediary extracts all gains to social welfare and its presence can\nraise or lower content quality. We further analyze how disintermediation is\naffected by the level of competition between suppliers and the intermediary's\nfee structure. More broadly, our results take a step towards assessing how\nproduction technology innovations affect the survival of intermediaries and\nimpact the digital economy.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20783v1",
    "published_date": "2025-02-28 07:04:01 UTC",
    "updated_date": "2025-02-28 07:04:01 UTC"
  },
  {
    "arxiv_id": "2502.20780v1",
    "title": "MedHallTune: An Instruction-Tuning Benchmark for Mitigating Medical Hallucination in Vision-Language Models",
    "authors": [
      "Qiao Yan",
      "Yuchen Yuan",
      "Xiaowei Hu",
      "Yihan Wang",
      "Jiaqi Xu",
      "Jinpeng Li",
      "Chi-Wing Fu",
      "Pheng-Ann Heng"
    ],
    "abstract": "The increasing use of vision-language models (VLMs) in healthcare\napplications presents great challenges related to hallucinations, in which the\nmodels may generate seemingly plausible results that are in fact incorrect.\nSuch hallucinations can jeopardize clinical decision making, potentially\nharming the diagnosis and treatments. In this work, we propose MedHallTune, a\nlarge-scale benchmark designed specifically to evaluate and mitigate\nhallucinations in medical VLMs. Comprising over 100,000 images and 1,000,000\ninstruction pairs, MedHallTune includes both hallucination and\nnon-hallucination samples, each with ground-truth annotations. We conduct a\ncomprehensive evaluation of current medical and general VLMs using MedHallTune,\nassessing their performance across key metrics, including clinical accuracy,\nrelevance, detail level, and risk level. The experimental results show that\nfine-tuning with MedHallTune successfully improves the ability of several\nexisting models to manage hallucinations and boost their zero-shot performance\non downstream visual-question-answering (VQA) tasks, making them more reliable\nfor practical medical applications. Our work contributes to the development of\nmore trustworthy VLMs. Codes and dataset will be available at\n\\href{https://github.com/russellyq/MedHallTune}{MedHallTune}.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20780v1",
    "published_date": "2025-02-28 06:59:49 UTC",
    "updated_date": "2025-02-28 06:59:49 UTC"
  },
  {
    "arxiv_id": "2502.20779v2",
    "title": "Triple Phase Transitions: Understanding the Learning Dynamics of Large Language Models from a Neuroscience Perspective",
    "authors": [
      "Yuko Nakagi",
      "Keigo Tada",
      "Sota Yoshino",
      "Shinji Nishimoto",
      "Yu Takagi"
    ],
    "abstract": "Large language models (LLMs) often exhibit abrupt emergent behavior, whereby\nnew abilities arise at certain points during their training. This phenomenon,\ncommonly referred to as a ''phase transition'', remains poorly understood. In\nthis study, we conduct an integrative analysis of such phase transitions by\nexamining three interconnected perspectives: the similarity between LLMs and\nthe human brain, the internal states of LLMs, and downstream task performance.\nWe propose a novel interpretation for the learning dynamics of LLMs that vary\nin both training data and architecture, revealing that three phase transitions\ncommonly emerge across these models during training: (1) alignment with the\nentire brain surges as LLMs begin adhering to task instructions Brain Alignment\nand Instruction Following, (2) unexpectedly, LLMs diverge from the brain during\na period in which downstream task accuracy temporarily stagnates Brain\nDetachment and Stagnation, and (3) alignment with the brain reoccurs as LLMs\nbecome capable of solving the downstream tasks Brain Realignment and\nConsolidation. These findings illuminate the underlying mechanisms of phase\ntransitions in LLMs, while opening new avenues for interdisciplinary research\nbridging AI and neuroscience.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.CL",
    "comment": "46 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.20779v2",
    "published_date": "2025-02-28 06:59:04 UTC",
    "updated_date": "2025-03-29 11:08:30 UTC"
  },
  {
    "arxiv_id": "2503.04789v2",
    "title": "Ext2Gen: Alignment through Unified Extraction and Generation for Robust Retrieval-Augmented Generation",
    "authors": [
      "Hwanjun Song",
      "Jeonghwan Choi",
      "Minseok Kim"
    ],
    "abstract": "Retrieval-augmented generation (RAG) enhances LLMs by integrating external\nknowledge, but generation remains fragile due to the uncertain placement of\nrelevant chunks and retrieval-induced information overload, leading to\nhallucinations. We propose Ext2Gen, a novel extract-then-generate model that\nenhances RAG robustness by first extracting query-relevant sentences before\ngenerating answers. To optimize this model, we employ preference alignment\nthrough pairwise feedback learning, enabling the model to generate robust\nanswers regardless of variations in retrieval results. Extensive experiments\ndemonstrate that Ext2Gen effectively identifies query-relevant sentences with\nhigh precision and recall, leading to highly reliable answers. Furthermore,\ndeploying our model in a RAG environment reveals that it not only boosts the\nperformance of the base LLM but also synergizes with advanced retrieval\nstrategies like query expansion. The model is available at\nhttps://huggingface.co/DISLab/Ext2Gen-8B-R2.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04789v2",
    "published_date": "2025-02-28 06:46:53 UTC",
    "updated_date": "2025-03-12 14:42:18 UTC"
  },
  {
    "arxiv_id": "2502.20772v1",
    "title": "Damper-B-PINN: Damper Characteristics-Based Bayesian Physics-Informed Neural Network for Vehicle State Estimation",
    "authors": [
      "Tianyi Zeng",
      "Tianyi Wang",
      "Junfeng Jiao",
      "Xinbo Chen"
    ],
    "abstract": "State estimation for Multi-Input Multi-Output (MIMO) systems with noise, such\nas vehicle chassis systems, presents a significant challenge due to the\nimperfect and complex relationship between inputs and outputs. To solve this\nproblem, we design a Damper characteristics-based Bayesian Physics-Informed\nNeural Network (Damper-B-PINN). First, we introduce a neuron forward process\ninspired by the mechanical properties of dampers, which limits abrupt jumps in\nneuron values between epochs while maintaining search capability. Additionally,\nwe apply an optimized Bayesian dropout layer to the MIMO system to enhance\nrobustness against noise and prevent non-convergence issues. Physical\ninformation is incorporated into the loss function to serve as a physical prior\nfor the neural network. The effectiveness of our Damper-B-PINN architecture is\nthen validated across ten datasets and fourteen vehicle types, demonstrating\nsuperior accuracy, computational efficiency, and convergence in vehicle state\nestimation (i.e., dynamic wheel load) compared to other state-of-the-art\nbenchmarks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20772v1",
    "published_date": "2025-02-28 06:46:21 UTC",
    "updated_date": "2025-02-28 06:46:21 UTC"
  },
  {
    "arxiv_id": "2502.20758v1",
    "title": "Collective Reasoning Among LLMs A Framework for Answer Validation Without Ground Truth",
    "authors": [
      "Seyed Pouyan Mousavi Davoudi",
      "Alireza Shafiee Fard",
      "Alireza Amiri-Margavi"
    ],
    "abstract": "We present a collaborative framework where multiple large language models,\nnamely GPT-4-0125-preview, Meta-LLaMA-3-70B-Instruct, Claude-3-Opus, and\nGemini-1.5-Flash, work together to generate and respond to complex PhD-level\nprobability questions in the absence of definitive ground truth. This study\nexplores how inter-model consensus enhances response reliability and serves as\na proxy for assessing the quality of generated questions. To quantify agreement\nand consistency, we employ statistical methods including chi-square tests,\nFleiss' Kappa, and confidence interval analysis, measuring both response\nprecision and question clarity. Our findings highlight that Claude and Gemini\ngenerate well-structured and less ambiguous questions, leading to higher\ninter-model agreement. This is reflected in their narrower confidence intervals\nand stronger alignment with answering models. Conversely, LLaMA demonstrates\nincreased variability and lower reliability in question formulation, as\nindicated by broader confidence intervals and reduced consensus rates. These\nresults suggest that multi-model collaboration not only enhances the\nreliability of responses but also provides a valuable framework for assessing\nand improving question quality in the absence of explicit ground truth. This\nresearch offers meaningful insights into optimizing AI-driven reasoning through\ncollaborative large-language model interactions.",
    "categories": [
      "stat.AP",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "stat.AP",
    "comment": "14 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:2411.16797",
    "pdf_url": "http://arxiv.org/pdf/2502.20758v1",
    "published_date": "2025-02-28 06:20:52 UTC",
    "updated_date": "2025-02-28 06:20:52 UTC"
  },
  {
    "arxiv_id": "2502.20754v1",
    "title": "Acquiring Grounded Representations of Words with Situated Interactive Instruction",
    "authors": [
      "Shiwali Mohan",
      "Aaron H. Mininger",
      "James R. Kirk",
      "John E. Laird"
    ],
    "abstract": "We present an approach for acquiring grounded representations of words from\nmixed-initiative, situated interactions with a human instructor. The work\nfocuses on the acquisition of diverse types of knowledge including perceptual,\nsemantic, and procedural knowledge along with learning grounded meanings.\nInteractive learning allows the agent to control its learning by requesting\ninstructions about unknown concepts, making learning efficient. Our approach\nhas been instantiated in Soar and has been evaluated on a table-top robotic arm\ncapable of manipulating small objects.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20754v1",
    "published_date": "2025-02-28 06:04:52 UTC",
    "updated_date": "2025-02-28 06:04:52 UTC"
  },
  {
    "arxiv_id": "2502.20748v1",
    "title": "Teach-to-Reason with Scoring: Self-Explainable Rationale-Driven Multi-Trait Essay Scoring",
    "authors": [
      "Heejin Do",
      "Sangwon Ryu",
      "Gary Geunbae Lee"
    ],
    "abstract": "Multi-trait automated essay scoring (AES) systems provide a fine-grained\nevaluation of an essay's diverse aspects. While they excel in scoring, prior\nsystems fail to explain why specific trait scores are assigned. This lack of\ntransparency leaves instructors and learners unconvinced of the AES outputs,\nhindering their practical use. To address this, we propose a self-explainable\nRationale-Driven Multi-trait automated Essay scoring (RaDME) framework. RaDME\nleverages the reasoning capabilities of large language models (LLMs) by\ndistilling them into a smaller yet effective scorer. This more manageable\nstudent model is optimized to sequentially generate a trait score followed by\nthe corresponding rationale, thereby inherently learning to select a more\njustifiable score by considering the subsequent rationale during training. Our\nfindings indicate that while LLMs underperform in direct AES tasks, they excel\nin rationale generation when provided with precise numerical scores. Thus,\nRaDME integrates the superior reasoning capacities of LLMs into the robust\nscoring accuracy of an optimized smaller model. Extensive experiments\ndemonstrate that RaDME achieves both accurate and adequate reasoning while\nsupporting high-quality multi-trait scoring, significantly enhancing the\ntransparency of AES.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20748v1",
    "published_date": "2025-02-28 05:54:23 UTC",
    "updated_date": "2025-02-28 05:54:23 UTC"
  },
  {
    "arxiv_id": "2502.20742v3",
    "title": "Structured Preference Optimization for Vision-Language Long-Horizon Task Planning",
    "authors": [
      "Xiwen Liang",
      "Min Lin",
      "Weiqi Ruan",
      "Rongtao Xu",
      "Yuecheng Liu",
      "Jiaqi Chen",
      "Bingqian Lin",
      "Yuzheng Zhuang",
      "Xiaodan Liang"
    ],
    "abstract": "Existing methods for vision-language task planning excel in short-horizon\ntasks but often fall short in complex, long-horizon planning within dynamic\nenvironments. These challenges primarily arise from the difficulty of\neffectively training models to produce high-quality reasoning processes for\nlong-horizon tasks. To address this, we propose Structured Preference\nOptimization (SPO), which aims to enhance reasoning and action selection in\nlong-horizon task planning through structured preference evaluation and\noptimized training strategies. Specifically, SPO introduces: 1)\nPreference-Based Scoring and Optimization, which systematically evaluates\nreasoning chains based on task relevance, visual grounding, and historical\nconsistency; and 2) Curriculum-Guided Training, where the model progressively\nadapts from simple to complex tasks, improving its generalization ability in\nlong-horizon scenarios and enhancing reasoning robustness. To advance research\nin vision-language long-horizon task planning, we introduce ExtendaBench, a\ncomprehensive benchmark covering 1,509 tasks across VirtualHome and Habitat\n2.0, categorized into ultra-short, short, medium, and long tasks. Experimental\nresults demonstrate that SPO significantly improves reasoning quality and final\ndecision accuracy, outperforming prior methods on long-horizon tasks and\nunderscoring the effectiveness of preference-driven optimization in\nvision-language task planning. Specifically, SPO achieves a +5.98% GCR and\n+4.68% SR improvement in VirtualHome and a +3.30% GCR and +2.11% SR improvement\nin Habitat over the best-performing baselines.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.20742v3",
    "published_date": "2025-02-28 05:47:34 UTC",
    "updated_date": "2025-05-16 03:07:36 UTC"
  },
  {
    "arxiv_id": "2502.20730v1",
    "title": "DeepSolution: Boosting Complex Engineering Solution Design via Tree-based Exploration and Bi-point Thinking",
    "authors": [
      "Zhuoqun Li",
      "Haiyang Yu",
      "Xuanang Chen",
      "Hongyu Lin",
      "Yaojie Lu",
      "Fei Huang",
      "Xianpei Han",
      "Yongbin Li",
      "Le Sun"
    ],
    "abstract": "Designing solutions for complex engineering challenges is crucial in human\nproduction activities. However, previous research in the retrieval-augmented\ngeneration (RAG) field has not sufficiently addressed tasks related to the\ndesign of complex engineering solutions. To fill this gap, we introduce a new\nbenchmark, SolutionBench, to evaluate a system's ability to generate complete\nand feasible solutions for engineering problems with multiple complex\nconstraints. To further advance the design of complex engineering solutions, we\npropose a novel system, SolutionRAG, that leverages the tree-based exploration\nand bi-point thinking mechanism to generate reliable solutions. Extensive\nexperimental results demonstrate that SolutionRAG achieves state-of-the-art\n(SOTA) performance on the SolutionBench, highlighting its potential to enhance\nthe automation and reliability of complex engineering solution design in\nreal-world applications.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20730v1",
    "published_date": "2025-02-28 05:23:10 UTC",
    "updated_date": "2025-02-28 05:23:10 UTC"
  },
  {
    "arxiv_id": "2502.20729v1",
    "title": "NeuroMorse: A Temporally Structured Dataset For Neuromorphic Computing",
    "authors": [
      "Ben Walters",
      "Yeshwanth Bethi",
      "Taylor Kergan",
      "Binh Nguyen",
      "Amirali Amirsoleimani",
      "Jason K. Eshraghian",
      "Saeed Afshar",
      "Mostafa Rahimi Azghadi"
    ],
    "abstract": "Neuromorphic engineering aims to advance computing by mimicking the brain's\nefficient processing, where data is encoded as asynchronous temporal events.\nThis eliminates the need for a synchronisation clock and minimises power\nconsumption when no data is present. However, many benchmarks for neuromorphic\nalgorithms primarily focus on spatial features, neglecting the temporal\ndynamics that are inherent to most sequence-based tasks. This gap may lead to\nevaluations that fail to fully capture the unique strengths and characteristics\nof neuromorphic systems. In this paper, we present NeuroMorse, a temporally\nstructured dataset designed for benchmarking neuromorphic learning systems.\nNeuroMorse converts the top 50 words in the English language into temporal\nMorse code spike sequences. Despite using only two input spike channels for\nMorse dots and dashes, complex information is encoded through temporal patterns\nin the data. The proposed benchmark contains feature hierarchy at multiple\ntemporal scales that test the capacity of neuromorphic algorithms to decompose\ninput patterns into spatial and temporal hierarchies. We demonstrate that our\ntraining set is challenging to categorise using a linear classifier and that\nidentifying keywords in the test set is difficult using conventional methods.\nThe NeuroMorse dataset is available at Zenodo, with our accompanying code on\nGitHub at https://github.com/Ben-E-Walters/NeuroMorse.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20729v1",
    "published_date": "2025-02-28 05:22:45 UTC",
    "updated_date": "2025-02-28 05:22:45 UTC"
  },
  {
    "arxiv_id": "2502.20727v3",
    "title": "SPD: Sync-Point Drop for efficient tensor parallelism of Large Language Models",
    "authors": [
      "Han-Byul Kim",
      "Duc Hoang",
      "Arnav Kundu",
      "Mohammad Samragh",
      "Minsik Cho"
    ],
    "abstract": "With the rapid expansion in the scale of large language models (LLMs),\nenabling efficient distributed inference across multiple computing units has\nbecome increasingly critical. However, communication overheads from popular\ndistributed inference techniques such as Tensor Parallelism pose a significant\nchallenge to achieve scalability and low latency. Therefore, we introduce a\nnovel optimization technique, Sync-Point Drop (SPD), to reduce communication\noverheads in tensor parallelism by selectively dropping synchronization on\nattention outputs. In detail, we first propose a block design that allows\nexecution to proceed without communication through SPD. Second, we apply\ndifferent SPD strategies to attention blocks based on their sensitivity to the\nmodel accuracy. The proposed methods effectively alleviate communication\nbottlenecks while minimizing accuracy degradation during LLM inference,\noffering a scalable solution for diverse distributed environments: SPD offered\nabout 20% overall inference latency reduction with < 1% accuracy regression for\nLLaMA2-70B inference over 8 GPUs.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "International Conference on Machine Learning (ICML) 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.20727v3",
    "published_date": "2025-02-28 05:20:48 UTC",
    "updated_date": "2025-05-21 04:23:44 UTC"
  },
  {
    "arxiv_id": "2502.20719v1",
    "title": "Generating Clinically Realistic EHR Data via a Hierarchy- and Semantics-Guided Transformer",
    "authors": [
      "Guanglin Zhou",
      "Sebastiano Barbieri"
    ],
    "abstract": "Generating realistic synthetic electronic health records (EHRs) holds\ntremendous promise for accelerating healthcare research, facilitating AI model\ndevelopment and enhancing patient privacy. However, existing generative methods\ntypically treat EHRs as flat sequences of discrete medical codes. This approach\noverlooks two critical aspects: the inherent hierarchical organization of\nclinical coding systems and the rich semantic context provided by code\ndescriptions. Consequently, synthetic patient sequences often lack high\nclinical fidelity and have limited utility in downstream clinical tasks. In\nthis paper, we propose the Hierarchy- and Semantics-Guided Transformer (HiSGT),\na novel framework that leverages both hierarchical and semantic information for\nthe generative process. HiSGT constructs a hierarchical graph to encode\nparent-child and sibling relationships among clinical codes and employs a graph\nneural network to derive hierarchy-aware embeddings. These are then fused with\nsemantic embeddings extracted from a pre-trained clinical language model (e.g.,\nClinicalBERT), enabling the Transformer-based generator to more accurately\nmodel the nuanced clinical patterns inherent in real EHRs. Extensive\nexperiments on the MIMIC-III and MIMIC-IV datasets demonstrate that HiSGT\nsignificantly improves the statistical alignment of synthetic data with real\npatient records, as well as supports robust downstream applications such as\nchronic disease classification. By addressing the limitations of conventional\nraw code-based generative models, HiSGT represents a significant step toward\nclinically high-fidelity synthetic data generation and a general paradigm\nsuitable for interpretable medical code representation, offering valuable\napplications in data augmentation and privacy-preserving healthcare analytics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20719v1",
    "published_date": "2025-02-28 05:06:04 UTC",
    "updated_date": "2025-02-28 05:06:04 UTC"
  },
  {
    "arxiv_id": "2503.00081v1",
    "title": "Experiences with Content Development and Assessment Design in the Era of GenAI",
    "authors": [
      "Aakanksha Sharma",
      "Samar Shailendra",
      "Rajan Kadel"
    ],
    "abstract": "Generative Artificial Intelligence (GenAI) has the potential to transform\nhigher education by generating human-like content. The advancement in GenAI has\nrevolutionised several aspects of education, especially subject and assessment\ndesign. In this era, it is crucial to design assessments that challenge\nstudents and cannot be solved using GenAI tools. This makes it necessary to\nupdate the educational content with rapidly evolving technology. The assessment\nplays a significant role in ensuring the students learning, as it encourages\nstudents to engage actively, leading to the achievement of learning outcomes.\nThe paper intends to determine how effectively GenAI can design a subject,\nincluding lectures, labs and assessments, using prompts and custom-based\ntraining. This paper aims to elucidate the direction to educators so they can\nleverage GenAI to create subject content. Additionally, we provided our\nexperiential learning for educators to develop content, highlighting the\nimportance of prompts and fine-tuning to ensure output quality. It has also\nbeen observed that expert evaluation is essential for assessing the quality of\nGenAI-generated materials throughout the content generation process.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00081v1",
    "published_date": "2025-02-28 05:05:15 UTC",
    "updated_date": "2025-02-28 05:05:15 UTC"
  },
  {
    "arxiv_id": "2503.01900v1",
    "title": "LLM-Empowered Class Imbalanced Graph Prompt Learning for Online Drug Trafficking Detection",
    "authors": [
      "Tianyi Ma",
      "Yiyue Qian",
      "Zehong Wang",
      "Zheyuan Zhang",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "abstract": "As the market for illicit drugs remains extremely profitable, major online\nplatforms have become direct-to-consumer intermediaries for illicit drug\ntrafficking participants. These online activities raise significant social\nconcerns that require immediate actions. Existing approaches to combating this\nchallenge are generally impractical, due to the imbalance of classes and\nscarcity of labeled samples in real-world applications. To this end, we propose\na novel Large Language Model-empowered Heterogeneous Graph Prompt Learning\nframework for illicit Drug Trafficking detection, called LLM-HetGDT, that\nleverages LLM to facilitate heterogeneous graph neural networks (HGNNs) to\neffectively identify drug trafficking activities in the class-imbalanced\nscenarios. Specifically, we first pre-train HGNN over a contrastive pretext\ntask to capture the inherent node and structure information over the unlabeled\ndrug trafficking heterogeneous graph (HG). Afterward, we employ LLM to augment\nthe HG by generating high-quality synthetic user nodes in minority classes.\nThen, we fine-tune the soft prompts on the augmented HG to capture the\nimportant information in the minority classes for the downstream drug\ntrafficking detection task. To comprehensively study online illicit drug\ntrafficking activities, we collect a new HG dataset over Twitter, called\nTwitter-HetDrug. Extensive experiments on this dataset demonstrate the\neffectiveness, efficiency, and applicability of LLM-HetGDT.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01900v1",
    "published_date": "2025-02-28 04:38:24 UTC",
    "updated_date": "2025-02-28 04:38:24 UTC"
  },
  {
    "arxiv_id": "2502.20704v3",
    "title": "Fuzzy Speculative Decoding for a Tunable Accuracy-Runtime Tradeoff",
    "authors": [
      "Maximilian Holsman",
      "Yukun Huang",
      "Bhuwan Dhingra"
    ],
    "abstract": "Speculative Decoding (SD) enforces strict distributional equivalence to the\ntarget model, limiting potential speed ups as distributions of near-equivalence\nachieve comparable outcomes in many cases. Furthermore, enforcing\ndistributional equivalence means that users are unable to trade deviations from\nthe target model distribution for further inference speed gains. To address\nthese limitations, we introduce Fuzzy Speculative Decoding (FSD) - a decoding\nalgorithm that generalizes SD by accepting candidate tokens purely based on the\ndivergences between the target and draft model distributions. By allowing for\ncontrolled divergence from the target model, FSD enables users to flexibly\ntrade generation quality for inference speed. Across several benchmarks, our\nmethod is able to achieve significant runtime improvements of over 5 tokens per\nsecond faster than SD at only an approximate 2% absolute reduction in benchmark\naccuracy. In many cases, FSD is even able to match SD benchmark accuracy at\nover 2 tokens per second faster, demonstrating that distributional equivalence\nis not necessary to maintain target model performance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20704v3",
    "published_date": "2025-02-28 04:25:42 UTC",
    "updated_date": "2025-03-04 15:30:35 UTC"
  },
  {
    "arxiv_id": "2502.20701v1",
    "title": "Why Trust in AI May Be Inevitable",
    "authors": [
      "Nghi Truong",
      "Phanish Puranam",
      "Ilia Testlin"
    ],
    "abstract": "In human-AI interactions, explanation is widely seen as necessary for\nenabling trust in AI systems. We argue that trust, however, may be a\npre-requisite because explanation is sometimes impossible. We derive this\nresult from a formalization of explanation as a search process through\nknowledge networks, where explainers must find paths between shared concepts\nand the concept to be explained, within finite time. Our model reveals that\nexplanation can fail even under theoretically ideal conditions - when actors\nare rational, honest, motivated, can communicate perfectly, and possess\noverlapping knowledge. This is because successful explanation requires not just\nthe existence of shared knowledge but also finding the connection path within\ntime constraints, and it can therefore be rational to cease attempts at\nexplanation before the shared knowledge is discovered. This result has\nimportant implications for human-AI interaction: as AI systems, particularly\nLarge Language Models, become more sophisticated and able to generate\nsuperficially compelling but spurious explanations, humans may default to trust\nrather than demand genuine explanations. This creates risks of both misplaced\ntrust and imperfect knowledge integration.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20701v1",
    "published_date": "2025-02-28 04:20:24 UTC",
    "updated_date": "2025-02-28 04:20:24 UTC"
  },
  {
    "arxiv_id": "2503.04788v1",
    "title": "AgroLLM: Connecting Farmers and Agricultural Practices through Large Language Models for Enhanced Knowledge Transfer and Practical Application",
    "authors": [
      "Dinesh Jackson Samuel",
      "Inna Skarga-Bandurova",
      "David Sikolia",
      "Muhammad Awais"
    ],
    "abstract": "AgroLLM is an AI-powered chatbot designed to enhance knowledge-sharing and\neducation in agriculture using Large Language Models (LLMs) and a\nRetrieval-Augmented Generation (RAG) framework. By using a comprehensive\nopen-source agricultural database, AgroLLM provides accurate, contextually\nrelevant responses while reducing incorrect information retrieval. The system\nutilizes the FAISS vector database for efficient similarity searches, ensuring\nrapid access to agricultural knowledge. A comparative study of three advanced\nmodels: Gemini 1.5 Flash, ChatGPT-4o Mini, and Mistral-7B-Instruct-v0.2 was\nconducted to evaluate performance across four key agricultural domains:\nAgriculture and Life Sciences, Agricultural Management, Agriculture and\nForestry, and Agriculture Business. Key evaluation metrics included embedding\nquality, search efficiency, and response relevance. Results indicated that\nChatGPT-4o Mini with RAG achieved the highest accuracy at 93%. Continuous\nfeedback mechanisms enhance response quality, making AgroLLM a benchmark\nAI-driven educational tool for farmers, researchers, and professionals,\npromoting informed decision-making and improved agricultural practices.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04788v1",
    "published_date": "2025-02-28 04:13:18 UTC",
    "updated_date": "2025-02-28 04:13:18 UTC"
  },
  {
    "arxiv_id": "2502.20694v1",
    "title": "WorldModelBench: Judging Video Generation Models As World Models",
    "authors": [
      "Dacheng Li",
      "Yunhao Fang",
      "Yukang Chen",
      "Shuo Yang",
      "Shiyi Cao",
      "Justin Wong",
      "Michael Luo",
      "Xiaolong Wang",
      "Hongxu Yin",
      "Joseph E. Gonzalez",
      "Ion Stoica",
      "Song Han",
      "Yao Lu"
    ],
    "abstract": "Video generation models have rapidly progressed, positioning themselves as\nvideo world models capable of supporting decision-making applications like\nrobotics and autonomous driving. However, current benchmarks fail to rigorously\nevaluate these claims, focusing only on general video quality, ignoring\nimportant factors to world models such as physics adherence. To bridge this\ngap, we propose WorldModelBench, a benchmark designed to evaluate the world\nmodeling capabilities of video generation models in application-driven domains.\nWorldModelBench offers two key advantages: (1) Against to nuanced world\nmodeling violations: By incorporating instruction-following and\nphysics-adherence dimensions, WorldModelBench detects subtle violations, such\nas irregular changes in object size that breach the mass conservation law -\nissues overlooked by prior benchmarks. (2) Aligned with large-scale human\npreferences: We crowd-source 67K human labels to accurately measure 14 frontier\nmodels. Using our high-quality human labels, we further fine-tune an accurate\njudger to automate the evaluation procedure, achieving 8.6% higher average\naccuracy in predicting world modeling violations than GPT-4o with 2B\nparameters. In addition, we demonstrate that training to align human\nannotations by maximizing the rewards from the judger noticeably improve the\nworld modeling capability. The website is available at\nhttps://worldmodelbench-team.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20694v1",
    "published_date": "2025-02-28 03:58:23 UTC",
    "updated_date": "2025-02-28 03:58:23 UTC"
  },
  {
    "arxiv_id": "2502.20689v1",
    "title": "ProAI: Proactive Multi-Agent Conversational AI with Structured Knowledge Base for Psychiatric Diagnosis",
    "authors": [
      "Yuqi Wu",
      "Guangya Wan",
      "Jingjing Li",
      "Shengming Zhao",
      "Lingfeng Ma",
      "Tianyi Ye",
      "Ion Pop",
      "Yanbo Zhang",
      "Jie Chen"
    ],
    "abstract": "Most LLM-driven conversational AI systems operate reactively, responding to\nuser prompts without guiding the interaction. Most LLM-driven conversational AI\nsystems operate reactively, responding to user prompts without guiding the\ninteraction. However, many real-world applications-such as psychiatric\ndiagnosis, consulting, and interviews-require AI to take a proactive role,\nasking the right questions and steering conversations toward specific\nobjectives. Using mental health differential diagnosis as an application\ncontext, we introduce ProAI, a goal-oriented, proactive conversational AI\nframework. ProAI integrates structured knowledge-guided memory, multi-agent\nproactive reasoning, and a multi-faceted evaluation strategy, enabling LLMs to\nengage in clinician-style diagnostic reasoning rather than simple response\ngeneration. Through simulated patient interactions, user experience assessment,\nand professional clinical validation, we demonstrate that ProAI achieves up to\n83.3% accuracy in mental disorder differential diagnosis while maintaining\nprofessional and empathetic interaction standards. These results highlight the\npotential for more reliable, adaptive, and goal-driven AI diagnostic\nassistants, advancing LLMs beyond reactive dialogue systems.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.20689v1",
    "published_date": "2025-02-28 03:45:39 UTC",
    "updated_date": "2025-02-28 03:45:39 UTC"
  },
  {
    "arxiv_id": "2502.20687v1",
    "title": "Unleashing the Potential of Two-Tower Models: Diffusion-Based Cross-Interaction for Large-Scale Matching",
    "authors": [
      "Yihan Wang",
      "Fei Xiong",
      "Zhexin Han",
      "Qi Song",
      "Kaiqiao Zhan",
      "Ben Wang"
    ],
    "abstract": "Two-tower models are widely adopted in the industrial-scale matching stage\nacross a broad range of application domains, such as content recommendations,\nadvertisement systems, and search engines. This model efficiently handles\nlarge-scale candidate item screening by separating user and item\nrepresentations. However, the decoupling network also leads to a neglect of\npotential information interaction between the user and item representations.\nCurrent state-of-the-art (SOTA) approaches include adding a shallow fully\nconnected layer(i.e., COLD), which is limited by performance and can only be\nused in the ranking stage. For performance considerations, another approach\nattempts to capture historical positive interaction information from the other\ntower by regarding them as the input features(i.e., DAT). Later research showed\nthat the gains achieved by this method are still limited because of lacking the\nguidance on the next user intent. To address the aforementioned challenges, we\npropose a \"cross-interaction decoupling architecture\" within our matching\nparadigm. This user-tower architecture leverages a diffusion module to\nreconstruct the next positive intention representation and employs a\nmixed-attention module to facilitate comprehensive cross-interaction. During\nthe next positive intention generation, we further enhance the accuracy of its\nreconstruction by explicitly extracting the temporal drift within user behavior\nsequences. Experiments on two real-world datasets and one industrial dataset\ndemonstrate that our method outperforms the SOTA two-tower models\nsignificantly, and our diffusion approach outperforms other generative models\nin reconstructing item representations.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20687v1",
    "published_date": "2025-02-28 03:40:37 UTC",
    "updated_date": "2025-02-28 03:40:37 UTC"
  },
  {
    "arxiv_id": "2502.20684v1",
    "title": "JAM: Controllable and Responsible Text Generation via Causal Reasoning and Latent Vector Manipulation",
    "authors": [
      "Yingbing Huang",
      "Deming Chen",
      "Abhishek K. Umrawal"
    ],
    "abstract": "While large language models (LLMs) have made significant strides in\ngenerating coherent and contextually relevant text, they often function as\nopaque black boxes, trained on vast unlabeled datasets with statistical\nobjectives, lacking an interpretable framework for responsible control. In this\npaper, we introduce JAM (Just A Move), a novel framework that interprets and\ncontrols text generation by integrating cause-effect analysis within the latent\nspace of LLMs. Based on our observations, we uncover the inherent causality in\nLLM generation, which is critical for producing responsible and realistic\noutputs. Moreover, we explore latent vectors as fundamental components in LLM\narchitectures, aiming to understand and manipulate them for more effective and\nefficient controllable text generation. We evaluate our framework using a range\nof tools, including the HHH criteria, toxicity reduction benchmarks, and GPT-4\nalignment measures. Our results show that JAM achieves up to a 22% improvement\nover previous Controllable Text Generation (CTG) methods across multiple\nquantitative metrics and human-centric evaluations. Furthermore, JAM\ndemonstrates greater computational efficiency compared to other CTG methods.\nThese results highlight the effectiveness and efficiency of JAM for responsible\nand realistic text generation, paving the way for more interpretable and\ncontrollable models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T07, 68T30, 68T35, 68T37, 68T50",
      "I.2.0; I.2.6; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 3 figures, and 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.20684v1",
    "published_date": "2025-02-28 03:31:48 UTC",
    "updated_date": "2025-02-28 03:31:48 UTC"
  },
  {
    "arxiv_id": "2502.20682v1",
    "title": "Fine-tuning BERT with Bidirectional LSTM for Fine-grained Movie Reviews Sentiment Analysis",
    "authors": [
      "Gibson Nkhata",
      "Susan Gauch",
      "Usman Anjum",
      "Justin Zhan"
    ],
    "abstract": "Sentiment Analysis (SA) is instrumental in understanding peoples viewpoints\nfacilitating social media monitoring recognizing products and brands and\ngauging customer satisfaction. Consequently SA has evolved into an active\nresearch domain within Natural Language Processing (NLP). Many approaches\noutlined in the literature devise intricate frameworks aimed at achieving high\naccuracy, focusing exclusively on either binary sentiment classification or\nfine-grained sentiment classification. In this paper our objective is to\nfine-tune the pre-trained BERT model with Bidirectional LSTM (BiLSTM) to\nenhance both binary and fine-grained SA specifically for movie reviews. Our\napproach involves conducting sentiment classification for each review followed\nby computing the overall sentiment polarity across all reviews. We present our\nfindings on binary classification as well as fine-grained classification\nutilizing benchmark datasets. Additionally we implement and assess two accuracy\nimprovement techniques Synthetic Minority Oversampling Technique (SMOTE) and\nNLP Augmenter (NLPAUG) to bolster the models generalization in fine-grained\nsentiment classification. Finally a heuristic algorithm is employed to\ncalculate the overall polarity of predicted reviews from the BERT+BiLSTM output\nvector. Our approach performs comparably with state-of-the-art (SOTA)\ntechniques in both classifications. For instance in binary classification we\nachieve 97.67% accuracy surpassing the leading SOTA model\nNB-weighted-BON+dv-cosine by 0.27% on the renowned IMDb dataset. Conversely for\nfive-class classification on SST-5 while the top SOTA model\nRoBERTa+large+Self-explaining attains 55.5% accuracy our model achieves 59.48%\naccuracy surpassing the BERT-large baseline by 3.6%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 5 figures, published in International Journal On Advances\n  in Systems and Measurements, volume 16, numbers 3 and 4, 2023",
    "pdf_url": "http://arxiv.org/pdf/2502.20682v1",
    "published_date": "2025-02-28 03:30:48 UTC",
    "updated_date": "2025-02-28 03:30:48 UTC"
  },
  {
    "arxiv_id": "2502.20681v1",
    "title": "Disentangling Feature Structure: A Mathematically Provable Two-Stage Training Dynamics in Transformers",
    "authors": [
      "Zixuan Gong",
      "Jiaye Teng",
      "Yong Liu"
    ],
    "abstract": "Transformers may exhibit two-stage training dynamics during the real-world\ntraining process. For instance, when training GPT-2 on the Counterfact dataset,\nthe answers progress from syntactically incorrect to syntactically correct to\nsemantically correct. However, existing theoretical analyses hardly account for\nthis two-stage phenomenon. In this paper, we theoretically demonstrate how such\ntwo-stage training dynamics occur in transformers. Specifically, we analyze the\ndynamics of transformers using feature learning techniques under in-context\nlearning regimes, based on a disentangled two-type feature structure. Such\ndisentanglement of feature structure is general in practice, e.g., natural\nlanguages contain syntax and semantics, and proteins contain primary and\nsecondary structures. To our best known, this is the first rigorous result\nregarding a two-stage optimization process in transformers. Additionally, a\ncorollary indicates that such a two-stage process is closely related to the\nspectral properties of the attention weights, which accords well with empirical\nfindings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20681v1",
    "published_date": "2025-02-28 03:27:24 UTC",
    "updated_date": "2025-02-28 03:27:24 UTC"
  },
  {
    "arxiv_id": "2503.04787v1",
    "title": "Towards Anthropomorphic Conversational AI Part I: A Practical Framework",
    "authors": [
      "Fei Wei",
      "Yaliang Li",
      "Bolin Ding"
    ],
    "abstract": "Large language models (LLMs), due to their advanced natural language\ncapabilities, have seen significant success in applications where the user\ninterface is usually a conversational artificial intelligence (AI) agent and\nengages the user through multi-round conversations. However, many scenarios\nrequire the agents to exhibit stronger social and conversational intelligence\nand demonstrate more human-like (anthropomorphic) reactions. This is an aspect\nthat foundational LLMs have yet to fully address such that a single call of\nfoundational models might be insufficient.\n  To bridge this gap, we propose a two-stage solution. In this work, we focus\non the first stage, introducing a multi-module framework designed to replicate\nthe key aspects of human intelligence involved in conversations. This framework\ncomprises thinking modules for reasoning, resource modules for managing\nknowledge and external information, and response modules for generating\ncontextually appropriate interactions. With all the modules cooperating, the\nframework would empower the agents to provide a better human-like conversation\nexperience. In the second stage of our approach, these conversational data,\nafter filtering and labeling, can serve as training and testing data for\nreinforcement learning, enabling AI to better capture human preferences. This\nstage is left for future work.\n  In our experiments, volunteers engaged in over 3000 rounds of conversation\nwith the same AI character powered by a standalone LLM and our framework which\nintegrates the same LLM. A separate group of evaluators rated the conversation\nsamples, revealing that our framework significantly enhanced the social and\nconversational intelligence, even without fine-tuning the LLM.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04787v1",
    "published_date": "2025-02-28 03:18:39 UTC",
    "updated_date": "2025-02-28 03:18:39 UTC"
  },
  {
    "arxiv_id": "2503.01899v1",
    "title": "FASTer: Focal Token Acquiring-and-Scaling Transformer for Long-term 3D Object Detection",
    "authors": [
      "Chenxu Dang",
      "Zaipeng Duan",
      "Pei An",
      "Xinmin Zhang",
      "Xuzhong Hu",
      "Jie Ma"
    ],
    "abstract": "Recent top-performing temporal 3D detectors based on Lidars have increasingly\nadopted region-based paradigms. They first generate coarse proposals, followed\nby encoding and fusing regional features. However, indiscriminate sampling and\nfusion often overlook the varying contributions of individual points and lead\nto exponentially increased complexity as the number of input frames grows.\nMoreover, arbitrary result-level concatenation limits the global information\nextraction. In this paper, we propose a Focal Token Acquring-and-Scaling\nTransformer (FASTer), which dynamically selects focal tokens and condenses\ntoken sequences in an adaptive and lightweight manner. Emphasizing the\ncontribution of individual tokens, we propose a simple but effective Adaptive\nScaling mechanism to capture geometric contexts while sifting out focal points.\nAdaptively storing and processing only focal points in historical frames\ndramatically reduces the overall complexity. Furthermore, a novel Grouped\nHierarchical Fusion strategy is proposed, progressively performing sequence\nscaling and Intra-Group Fusion operations to facilitate the exchange of global\nspatial and temporal information. Experiments on the Waymo Open Dataset\ndemonstrate that our FASTer significantly outperforms other state-of-the-art\ndetectors in both performance and efficiency while also exhibiting improved\nflexibility and robustness. The code is available at\nhttps://github.com/MSunDYY/FASTer.git.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10pages,6 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.01899v1",
    "published_date": "2025-02-28 03:15:33 UTC",
    "updated_date": "2025-02-28 03:15:33 UTC"
  },
  {
    "arxiv_id": "2503.13465v1",
    "title": "A novel Fourier Adjacency Transformer for advanced EEG emotion recognition",
    "authors": [
      "Jinfeng Wang",
      "Yanhao Huang",
      "Sifan Song",
      "Boqian Wang",
      "Jionglong Su",
      "Jiaman Ding"
    ],
    "abstract": "EEG emotion recognition faces significant hurdles due to noise interference,\nsignal nonstationarity, and the inherent complexity of brain activity which\nmake accurately emotion classification. In this study, we present the Fourier\nAdjacency Transformer, a novel framework that seamlessly integrates\nFourier-based periodic analysis with graph-driven structural modeling. Our\nmethod first leverages novel Fourier-inspired modules to extract periodic\nfeatures from embedded EEG signals, effectively decoupling them from aperiodic\ncomponents. Subsequently, we employ an adjacency attention scheme to reinforce\nuniversal inter-channel correlation patterns, coupling these patterns with\ntheir sample-based counterparts. Empirical evaluations on SEED and DEAP\ndatasets demonstrate that our method surpasses existing state-of-the-art\ntechniques, achieving an improvement of approximately 6.5% in recognition\naccuracy. By unifying periodicity and structural insights, this framework\noffers a promising direction for future research in EEG emotion analysis.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.13465v1",
    "published_date": "2025-02-28 03:15:12 UTC",
    "updated_date": "2025-02-28 03:15:12 UTC"
  },
  {
    "arxiv_id": "2502.20668v1",
    "title": "OpenEarthSensing: Large-Scale Fine-Grained Benchmark for Open-World Remote Sensing",
    "authors": [
      "Xiang Xiang",
      "Zhuo Xu",
      "Yao Deng",
      "Qinhao Zhou",
      "Yifan Liang",
      "Ke Chen",
      "Qingfang Zheng",
      "Yaowei Wang",
      "Xilin Chen",
      "Wen Gao"
    ],
    "abstract": "In open-world remote sensing, deployed models must continuously adapt to a\nsteady influx of new data, which often exhibits various shifts compared to what\nthe model encountered during the training phase. To effectively handle the new\ndata, models are required to detect semantic shifts, adapt to covariate shifts,\nand continuously update themselves. These challenges give rise to a variety of\nopen-world tasks. However, existing open-world remote sensing studies typically\ntrain and test within a single dataset to simulate open-world conditions.\nCurrently, there is a lack of large-scale benchmarks capable of evaluating\nmultiple open-world tasks. In this paper, we introduce OpenEarthSensing, a\nlarge-scale fine-grained benchmark for open-world remote sensing.\nOpenEarthSensing includes 189 scene and objects categories, covering the vast\nmajority of potential semantic shifts that may occur in the real world.\nAdditionally, OpenEarthSensing encompasses five data domains with significant\ncovariate shifts, including two RGB satellite domians, one RGB aerial domian,\none MS RGB domian, and one infrared domian. The various domains provide a more\ncomprehensive testbed for evaluating the generalization performance of\nopen-world models. We conduct the baseline evaluation of current mainstream\nopen-world tasks and methods on OpenEarthSensing, demonstrating that it serves\nas a challenging benchmark for open-world remote sensing.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20668v1",
    "published_date": "2025-02-28 02:49:52 UTC",
    "updated_date": "2025-02-28 02:49:52 UTC"
  },
  {
    "arxiv_id": "2502.20667v1",
    "title": "Advancing AI-Powered Medical Image Synthesis: Insights from MedVQA-GI Challenge Using CLIP, Fine-Tuned Stable Diffusion, and Dream-Booth + LoRA",
    "authors": [
      "Ojonugwa Oluwafemi Ejiga Peter",
      "Md Mahmudur Rahman",
      "Fahmi Khalifa"
    ],
    "abstract": "The MEDVQA-GI challenge addresses the integration of AI-driven text-to-image\ngenerative models in medical diagnostics, aiming to enhance diagnostic\ncapabilities through synthetic image generation. Existing methods primarily\nfocus on static image analysis and lack the dynamic generation of medical\nimagery from textual descriptions. This study intends to partially close this\ngap by introducing a novel approach based on fine-tuned generative models to\ngenerate dynamic, scalable, and precise images from textual descriptions.\nParticularly, our system integrates fine-tuned Stable Diffusion and DreamBooth\nmodels, as well as Low-Rank Adaptation (LORA), to generate high-fidelity\nmedical images. The problem is around two sub-tasks namely: image synthesis\n(IS) and optimal prompt production (OPG). The former creates medical images via\nverbal prompts, whereas the latter provides prompts that produce high-quality\nimages in specified categories. The study emphasizes the limitations of\ntraditional medical image generation methods, such as hand sketching,\nconstrained datasets, static procedures, and generic models. Our evaluation\nmeasures showed that Stable Diffusion surpasses CLIP and DreamBooth + LORA in\nterms of producing high-quality, diversified images. Specifically, Stable\nDiffusion had the lowest Fr\\'echet Inception Distance (FID) scores (0.099 for\nsingle center, 0.064 for multi-center, and 0.067 for combined), indicating\nhigher image quality. Furthermore, it had the highest average Inception Score\n(2.327 across all datasets), indicating exceptional diversity and quality. This\nadvances the field of AI-powered medical diagnosis. Future research will\nconcentrate on model refining, dataset augmentation, and ethical considerations\nfor efficiently implementing these advances into clinical practice",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20667v1",
    "published_date": "2025-02-28 02:49:45 UTC",
    "updated_date": "2025-02-28 02:49:45 UTC"
  },
  {
    "arxiv_id": "2502.20657v1",
    "title": "Automatic database description generation for Text-to-SQL",
    "authors": [
      "Yingqi Gao",
      "Zhiling Luo"
    ],
    "abstract": "In the context of the Text-to-SQL task, table and column descriptions are\ncrucial for bridging the gap between natural language and database schema. This\nreport proposes a method for automatically generating effective database\ndescriptions when explicit descriptions are unavailable. The proposed method\nemploys a dual-process approach: a coarse-to-fine process, followed by a\nfine-to-coarse process. The coarse-to-fine approach leverages the inherent\nknowledge of LLM to guide the understanding process from databases to tables\nand finally to columns. This approach provides a holistic understanding of the\ndatabase structure and ensures contextual alignment. Conversely, the\nfine-to-coarse approach starts at the column level, offering a more accurate\nand nuanced understanding when stepping back to the table level. Experimental\nresults on the Bird benchmark indicate that using descriptions generated by the\nproposed improves SQL generation accuracy by 0.93\\% compared to not using\ndescriptions, and achieves 37\\% of human-level performance. The source code is\npublicly available at https://github.com/XGenerationLab/XiYan-DBDescGen.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DB",
      "I.2; H.2"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20657v1",
    "published_date": "2025-02-28 02:23:06 UTC",
    "updated_date": "2025-02-28 02:23:06 UTC"
  },
  {
    "arxiv_id": "2502.20653v1",
    "title": "Dataset Distillation with Neural Characteristic Function: A Minmax Perspective",
    "authors": [
      "Shaobo Wang",
      "Yicun Yang",
      "Zhiyuan Liu",
      "Chenghao Sun",
      "Xuming Hu",
      "Conghui He",
      "Linfeng Zhang"
    ],
    "abstract": "Dataset distillation has emerged as a powerful approach for reducing data\nrequirements in deep learning. Among various methods, distribution\nmatching-based approaches stand out for their balance of computational\nefficiency and strong performance. However, existing distance metrics used in\ndistribution matching often fail to accurately capture distributional\ndifferences, leading to unreliable measures of discrepancy. In this paper, we\nreformulate dataset distillation as a minmax optimization problem and introduce\nNeural Characteristic Function Discrepancy (NCFD), a comprehensive and\ntheoretically grounded metric for measuring distributional differences. NCFD\nleverages the Characteristic Function (CF) to encapsulate full distributional\ninformation, employing a neural network to optimize the sampling strategy for\nthe CF's frequency arguments, thereby maximizing the discrepancy to enhance\ndistance estimation. Simultaneously, we minimize the difference between real\nand synthetic data under this optimized NCFD measure. Our approach, termed\nNeural Characteristic Function Matching (\\mymethod{}), inherently aligns the\nphase and amplitude of neural features in the complex plane for both real and\nsynthetic data, achieving a balance between realism and diversity in synthetic\nsamples. Experiments demonstrate that our method achieves significant\nperformance gains over state-of-the-art methods on both low- and\nhigh-resolution datasets. Notably, we achieve a 20.5\\% accuracy boost on\nImageSquawk. Our method also reduces GPU memory usage by over 300$\\times$ and\nachieves 20$\\times$ faster processing speeds compared to state-of-the-art\nmethods. To the best of our knowledge, this is the first work to achieve\nlossless compression of CIFAR-100 on a single NVIDIA 2080 Ti GPU using only 2.3\nGB of memory.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025, 11 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.20653v1",
    "published_date": "2025-02-28 02:14:55 UTC",
    "updated_date": "2025-02-28 02:14:55 UTC"
  },
  {
    "arxiv_id": "2502.20647v1",
    "title": "Consistency Evaluation of News Article Summaries Generated by Large (and Small) Language Models",
    "authors": [
      "Colleen Gilhuly",
      "Haleh Shahzad"
    ],
    "abstract": "Text summarizing is a critical Natural Language Processing (NLP) task with\napplications ranging from information retrieval to content generation. Large\nLanguage Models (LLMs) have shown remarkable promise in generating fluent\nabstractive summaries but they can produce hallucinated details not grounded in\nthe source text. Regardless of the method of generating a summary, high quality\nautomated evaluations remain an open area of investigation. This paper embarks\non an exploration of text summarization with a diverse set of techniques,\nincluding TextRank, BART, Mistral-7B-Instruct, and OpenAI GPT-3.5-Turbo. The\ngenerated summaries are evaluated using traditional metrics such as the\nRecall-Oriented Understudy for Gisting Evaluation (ROUGE) Score and\nBidirectional Encoder Representations from Transformers (BERT) Score, as well\nas LLM-powered evaluation methods that directly assess a generated summary's\nconsistency with the source text. We introduce a meta evaluation score which\ndirectly assesses the performance of the LLM evaluation system (prompt +\nmodel). We find that that all summarization models produce consistent summaries\nwhen tested on the XL-Sum dataset, exceeding the consistency of the reference\nsummaries.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 6 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.20647v1",
    "published_date": "2025-02-28 01:58:17 UTC",
    "updated_date": "2025-02-28 01:58:17 UTC"
  },
  {
    "arxiv_id": "2502.20639v1",
    "title": "FedConv: A Learning-on-Model Paradigm for Heterogeneous Federated Clients",
    "authors": [
      "Leming Shen",
      "Qiang Yang",
      "Kaiyan Cui",
      "Yuanqing Zheng",
      "Xiao-Yong Wei",
      "Jianwei Liu",
      "Jinsong Han"
    ],
    "abstract": "Federated Learning (FL) facilitates collaborative training of a shared global\nmodel without exposing clients' private data. In practical FL systems, clients\n(e.g., edge servers, smartphones, and wearables) typically have disparate\nsystem resources. Conventional FL, however, adopts a one-size-fits-all\nsolution, where a homogeneous large global model is transmitted to and trained\non each client, resulting in an overwhelming workload for less capable clients\nand starvation for other clients. To address this issue, we propose FedConv, a\nclient-friendly FL framework, which minimizes the computation and memory burden\non resource-constrained clients by providing heterogeneous customized\nsub-models. FedConv features a novel learning-on-model paradigm that learns the\nparameters of the heterogeneous sub-models via convolutional compression.\nUnlike traditional compression methods, the compressed models in FedConv can be\ndirectly trained on clients without decompression. To aggregate the\nheterogeneous sub-models, we propose transposed convolutional dilation to\nconvert them back to large models with a unified size while retaining\npersonalized information from clients. The compression and dilation processes,\ntransparent to clients, are optimized on the server leveraging a small public\ndataset. Extensive experiments on six datasets demonstrate that FedConv\noutperforms state-of-the-art FL systems in terms of model accuracy (by more\nthan 35% on average), computation and communication overhead (with 33% and 25%\nreduction, respectively).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20639v1",
    "published_date": "2025-02-28 01:39:53 UTC",
    "updated_date": "2025-02-28 01:39:53 UTC"
  },
  {
    "arxiv_id": "2502.20634v1",
    "title": "A Compact Model for Large-Scale Time Series Forecasting",
    "authors": [
      "Chin-Chia Michael Yeh",
      "Xiran Fan",
      "Zhimeng Jiang",
      "Yujie Fan",
      "Huiyuan Chen",
      "Uday Singh Saini",
      "Vivian Lai",
      "Xin Dai",
      "Junpeng Wang",
      "Zhongfang Zhuang",
      "Liang Wang",
      "Yan Zheng"
    ],
    "abstract": "Spatio-temporal data, which commonly arise in real-world applications such as\ntraffic monitoring, financial transactions, and ride-share demands, represent a\nspecial category of multivariate time series. They exhibit two distinct\ncharacteristics: high dimensionality and commensurability across spatial\nlocations. These attributes call for computationally efficient modeling\napproaches and facilitate the use of univariate forecasting models in a\nchannel-independent fashion. SparseTSF, a recently introduced competitive\nunivariate forecasting model, harnesses periodicity to achieve compactness by\nconcentrating on cross-period dynamics, thereby extending the Pareto frontier\nwith respect to model size and predictive performance. Nonetheless, it\nunderperforms on spatio-temporal data due to an inadequate capture of\nintra-period temporal dependencies. To address this shortcoming, we propose\nUltraSTF, which integrates a cross-period forecasting module with an\nultra-compact shape bank component. Our model effectively detects recurring\npatterns in time series through the attention mechanism of the shape bank\ncomponent, thereby strengthening its ability to learn intra-period dynamics.\nUltraSTF achieves state-of-the-art performance on the LargeST benchmark while\nemploying fewer than 0.2% of the parameters required by the second-best\napproaches, thus further extending the Pareto frontier of existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20634v1",
    "published_date": "2025-02-28 01:35:51 UTC",
    "updated_date": "2025-02-28 01:35:51 UTC"
  },
  {
    "arxiv_id": "2503.01897v1",
    "title": "Continual Learning-Aided Super-Resolution Scheme for Channel Reconstruction and Generalization in OFDM Systems",
    "authors": [
      "Jianqiao Chen",
      "Nan Ma",
      "Wenkai Liu",
      "Xiaodong Xu",
      "Ping Zhang"
    ],
    "abstract": "Channel reconstruction and generalization capability are of equal importance\nfor developing channel estimation schemes within deep learning (DL) framework.\nIn this paper, we exploit a novel DL-based scheme for efficient OFDM channel\nestimation where the neural networks for channel reconstruction and\ngeneralization are respectively designed. For the former, we propose a\ndual-attention-aided super-resolution neural network (DA-SRNN) to map the\nchannels at pilot positions to the whole time-frequency channels. Specifically,\nthe channel-spatial attention mechanism is first introduced to sequentially\ninfer attention maps along two separate dimensions corresponding to two types\nof underlying channel correlations, and then the lightweight SR module is\ndeveloped for efficient channel reconstruction. For the latter, we introduce\ncontinual learning (CL)-aided training strategies to make the neural network\nadapt to different channel distributions. Specifically, the elastic weight\nconsolidation (EWC) is introduced as the regularization term in regard to loss\nfunction of channel reconstruction, which can constrain the direction and space\nof updating the important weights of neural networks among different channel\ndistributions. Meanwhile, the corresponding training process is provided in\ndetail. By evaluating under 3rd Generation Partnership Project (3GPP) channel\nmodels, numerical results verify the superiority of the proposed channel\nestimation scheme with significantly improved channel reconstruction and\ngeneralization performance over counterparts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01897v1",
    "published_date": "2025-02-28 01:31:13 UTC",
    "updated_date": "2025-02-28 01:31:13 UTC"
  },
  {
    "arxiv_id": "2502.20632v1",
    "title": "Lattice Protein Folding with Variational Annealing",
    "authors": [
      "Shoummo Ahsan Khandoker",
      "Estelle M. Inack",
      "Mohamed Hibat-Allah"
    ],
    "abstract": "Understanding the principles of protein folding is a cornerstone of\ncomputational biology, with implications for drug design, bioengineering, and\nthe understanding of fundamental biological processes. Lattice protein folding\nmodels offer a simplified yet powerful framework for studying the complexities\nof protein folding, enabling the exploration of energetically optimal folds\nunder constrained conditions. However, finding these optimal folds is a\ncomputationally challenging combinatorial optimization problem. In this work,\nwe introduce a novel upper-bound training scheme that employs masking to\nidentify the lowest-energy folds in two-dimensional Hydrophobic-Polar (HP)\nlattice protein folding. By leveraging Dilated Recurrent Neural Networks (RNNs)\nintegrated with an annealing process driven by temperature-like fluctuations,\nour method accurately predicts optimal folds for benchmark systems of up to 60\nbeads. Our approach also effectively masks invalid folds from being sampled\nwithout compromising the autoregressive sampling properties of RNNs. This\nscheme is generalizable to three spatial dimensions and can be extended to\nlattice protein models with larger alphabets. Our findings emphasize the\npotential of advanced machine learning techniques in tackling complex protein\nfolding problems and a broader class of constrained combinatorial optimization\nchallenges.",
    "categories": [
      "cond-mat.dis-nn",
      "cs.AI",
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "cond-mat.dis-nn",
    "comment": "Github respository will be provided soon",
    "pdf_url": "http://arxiv.org/pdf/2502.20632v1",
    "published_date": "2025-02-28 01:30:15 UTC",
    "updated_date": "2025-02-28 01:30:15 UTC"
  },
  {
    "arxiv_id": "2502.20630v1",
    "title": "Subtask-Aware Visual Reward Learning from Segmented Demonstrations",
    "authors": [
      "Changyeon Kim",
      "Minho Heo",
      "Doohyun Lee",
      "Jinwoo Shin",
      "Honglak Lee",
      "Joseph J. Lim",
      "Kimin Lee"
    ],
    "abstract": "Reinforcement Learning (RL) agents have demonstrated their potential across\nvarious robotic tasks. However, they still heavily rely on human-engineered\nreward functions, requiring extensive trial-and-error and access to target\nbehavior information, often unavailable in real-world settings. This paper\nintroduces REDS: REward learning from Demonstration with Segmentations, a novel\nreward learning framework that leverages action-free videos with minimal\nsupervision. Specifically, REDS employs video demonstrations segmented into\nsubtasks from diverse sources and treats these segments as ground-truth\nrewards. We train a dense reward function conditioned on video segments and\ntheir corresponding subtasks to ensure alignment with ground-truth reward\nsignals by minimizing the Equivalent-Policy Invariant Comparison distance.\nAdditionally, we employ contrastive learning objectives to align video\nrepresentations with subtasks, ensuring precise subtask inference during online\ninteractions. Our experiments show that REDS significantly outperforms baseline\nmethods on complex robotic manipulation tasks in Meta-World and more\nchallenging real-world tasks, such as furniture assembly in FurnitureBench,\nwith minimal human intervention. Moreover, REDS facilitates generalization to\nunseen tasks and robot embodiments, highlighting its potential for scalable\ndeployment in diverse environments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project webpage: https://changyeon.site/reds/",
    "pdf_url": "http://arxiv.org/pdf/2502.20630v1",
    "published_date": "2025-02-28 01:25:37 UTC",
    "updated_date": "2025-02-28 01:25:37 UTC"
  },
  {
    "arxiv_id": "2503.05788v2",
    "title": "Emergent Abilities in Large Language Models: A Survey",
    "authors": [
      "Leonardo Berti",
      "Flavio Giorgi",
      "Gjergji Kasneci"
    ],
    "abstract": "Large Language Models (LLMs) are leading a new technological revolution as\none of the most promising research streams toward artificial general\nintelligence. The scaling of these models, accomplished by increasing the\nnumber of parameters and the magnitude of the training datasets, has been\nlinked to various so-called emergent abilities that were previously unobserved.\nThese emergent abilities, ranging from advanced reasoning and in-context\nlearning to coding and problem-solving, have sparked an intense scientific\ndebate: Are they truly emergent, or do they simply depend on external factors,\nsuch as training dynamics, the type of problems, or the chosen metric? What\nunderlying mechanism causes them? Despite their transformative potential,\nemergent abilities remain poorly understood, leading to misconceptions about\ntheir definition, nature, predictability, and implications. In this work, we\nshed light on emergent abilities by conducting a comprehensive review of the\nphenomenon, addressing both its scientific underpinnings and real-world\nconsequences. We first critically analyze existing definitions, exposing\ninconsistencies in conceptualizing emergent abilities. We then explore the\nconditions under which these abilities appear, evaluating the role of scaling\nlaws, task complexity, pre-training loss, quantization, and prompting\nstrategies. Our review extends beyond traditional LLMs and includes Large\nReasoning Models (LRMs), which leverage reinforcement learning and\ninference-time search to amplify reasoning and self-reflection. However,\nemergence is not inherently positive. As AI systems gain autonomous reasoning\ncapabilities, they also develop harmful behaviors, including deception,\nmanipulation, and reward hacking. We highlight growing concerns about safety\nand governance, emphasizing the need for better evaluation frameworks and\nregulatory oversight.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05788v2",
    "published_date": "2025-02-28 01:20:01 UTC",
    "updated_date": "2025-03-14 13:28:04 UTC"
  },
  {
    "arxiv_id": "2502.20616v1",
    "title": "PersonaBench: Evaluating AI Models on Understanding Personal Information through Accessing (Synthetic) Private User Data",
    "authors": [
      "Juntao Tan",
      "Liangwei Yang",
      "Zuxin Liu",
      "Zhiwei Liu",
      "Rithesh Murthy",
      "Tulika Manoj Awalgaonkar",
      "Jianguo Zhang",
      "Weiran Yao",
      "Ming Zhu",
      "Shirley Kokane",
      "Silvio Savarese",
      "Huan Wang",
      "Caiming Xiong",
      "Shelby Heinecke"
    ],
    "abstract": "Personalization is critical in AI assistants, particularly in the context of\nprivate AI models that work with individual users. A key scenario in this\ndomain involves enabling AI models to access and interpret a user's private\ndata (e.g., conversation history, user-AI interactions, app usage) to\nunderstand personal details such as biographical information, preferences, and\nsocial connections. However, due to the sensitive nature of such data, there\nare no publicly available datasets that allow us to assess an AI model's\nability to understand users through direct access to personal information.\n  To address this gap, we introduce a synthetic data generation pipeline that\ncreates diverse, realistic user profiles and private documents simulating human\nactivities. Leveraging this synthetic data, we present PersonaBench, a\nbenchmark designed to evaluate AI models' performance in understanding personal\ninformation derived from simulated private user data.\n  We evaluate Retrieval-Augmented Generation (RAG) pipelines using questions\ndirectly related to a user's personal information, supported by the relevant\nprivate documents provided to the models. Our results reveal that current\nretrieval-augmented AI models struggle to answer private questions by\nextracting personal information from user documents, highlighting the need for\nimproved methodologies to enhance personalization capabilities in AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20616v1",
    "published_date": "2025-02-28 00:43:35 UTC",
    "updated_date": "2025-02-28 00:43:35 UTC"
  },
  {
    "arxiv_id": "2502.20613v1",
    "title": "Continuous Adversarial Text Representation Learning for Affective Recognition",
    "authors": [
      "Seungah Son",
      "Andrez Saurez",
      "Dongsoo Har"
    ],
    "abstract": "While pre-trained language models excel at semantic understanding, they often\nstruggle to capture nuanced affective information critical for affective\nrecognition tasks. To address these limitations, we propose a novel framework\nfor enhancing emotion-aware embeddings in transformer-based models. Our\napproach introduces a continuous valence-arousal labeling system to guide\ncontrastive learning, which captures subtle and multi-dimensional emotional\nnuances more effectively. Furthermore, we employ a dynamic token perturbation\nmechanism, using gradient-based saliency to focus on sentiment-relevant tokens,\nimproving model sensitivity to emotional cues. The experimental results\ndemonstrate that the proposed framework outperforms existing methods, achieving\nup to 15.5% improvement in the emotion classification benchmark, highlighting\nthe importance of employing continuous labels. This improvement demonstrates\nthat the proposed framework is effective in affective representation learning\nand enables precise and contextually relevant emotional understanding.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 3 figures, The 7th International Conference on Artificial\n  Intelligence in Information and Communication (ICAIIC 2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.20613v1",
    "published_date": "2025-02-28 00:29:09 UTC",
    "updated_date": "2025-02-28 00:29:09 UTC"
  },
  {
    "arxiv_id": "2502.20609v1",
    "title": "Leveraging Large Language Models for Building Interpretable Rule-Based Data-to-Text Systems",
    "authors": [
      "Jędrzej Warczyński",
      "Mateusz Lango",
      "Ondrej Dusek"
    ],
    "abstract": "We introduce a simple approach that uses a large language model (LLM) to\nautomatically implement a fully interpretable rule-based data-to-text system in\npure Python. Experimental evaluation on the WebNLG dataset showed that such a\nconstructed system produces text of better quality (according to the BLEU and\nBLEURT metrics) than the same LLM prompted to directly produce outputs, and\nproduces fewer hallucinations than a BART language model fine-tuned on the same\ndata. Furthermore, at runtime, the approach generates text in a fraction of the\nprocessing time required by neural approaches, using only a single CPU",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20609v1",
    "published_date": "2025-02-28 00:23:55 UTC",
    "updated_date": "2025-02-28 00:23:55 UTC"
  },
  {
    "arxiv_id": "2502.20604v1",
    "title": "Exploring the Impact of Temperature Scaling in Softmax for Classification and Adversarial Robustness",
    "authors": [
      "Hao Xuan",
      "Bokai Yang",
      "Xingyu Li"
    ],
    "abstract": "The softmax function is a fundamental component in deep learning. This study\ndelves into the often-overlooked parameter within the softmax function, known\nas \"temperature,\" providing novel insights into the practical and theoretical\naspects of temperature scaling for image classification. Our empirical studies,\nadopting convolutional neural networks and transformers on multiple benchmark\ndatasets, reveal that moderate temperatures generally introduce better overall\nperformance. Through extensive experiments and rigorous theoretical analysis,\nwe explore the role of temperature scaling in model training and unveil that\ntemperature not only influences learning step size but also shapes the model's\noptimization direction. Moreover, for the first time, we discover a surprising\nbenefit of elevated temperatures: enhanced model robustness against common\ncorruption, natural perturbation, and non-targeted adversarial attacks like\nProjected Gradient Descent. We extend our discoveries to adversarial training,\ndemonstrating that, compared to the standard softmax function with the default\ntemperature value, higher temperatures have the potential to enhance\nadversarial training. The insights of this work open new avenues for improving\nmodel performance and security in deep learning applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20604v1",
    "published_date": "2025-02-28 00:07:45 UTC",
    "updated_date": "2025-02-28 00:07:45 UTC"
  },
  {
    "arxiv_id": "2502.20601v2",
    "title": "NutriGen: Personalized Meal Plan Generator Leveraging Large Language Models to Enhance Dietary and Nutritional Adherence",
    "authors": [
      "Saman Khamesian",
      "Asiful Arefeen",
      "Stephanie M. Carpenter",
      "Hassan Ghasemzadeh"
    ],
    "abstract": "Maintaining a balanced diet is essential for overall health, yet many\nindividuals struggle with meal planning due to nutritional complexity, time\nconstraints, and lack of dietary knowledge. Personalized food recommendations\ncan help address these challenges by tailoring meal plans to individual\npreferences, habits, and dietary restrictions. However, existing dietary\nrecommendation systems often lack adaptability, fail to consider real-world\nconstraints such as food ingredient availability, and require extensive user\ninput, making them impractical for sustainable and scalable daily use. To\naddress these limitations, we introduce NutriGen, a framework based on large\nlanguage models (LLM) designed to generate personalized meal plans that align\nwith user-defined dietary preferences and constraints. By building a\npersonalized nutrition database and leveraging prompt engineering, our approach\nenables LLMs to incorporate reliable nutritional references like the USDA\nnutrition database while maintaining flexibility and ease-of-use. We\ndemonstrate that LLMs have strong potential in generating accurate and\nuser-friendly food recommendations, addressing key limitations in existing\ndietary recommendation systems by providing structured, practical, and scalable\nmeal plans. Our evaluation shows that Llama 3.1 8B and GPT-3.5 Turbo achieve\nthe lowest percentage errors of 1.55\\% and 3.68\\%, respectively, producing meal\nplans that closely align with user-defined caloric targets while minimizing\ndeviation and improving precision. Additionally, we compared the performance of\nDeepSeek V3 against several established models to evaluate its potential in\npersonalized nutrition planning.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20601v2",
    "published_date": "2025-02-28 00:05:49 UTC",
    "updated_date": "2025-04-28 05:39:17 UTC"
  }
]